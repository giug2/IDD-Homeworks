<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application</title>
<!--Generated on Wed May 15 17:30:07 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="Large-Language Model,  Sequential Recommendation,  Recommendation" lang="en" name="keywords"/>
<base href="/html/2405.03988v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S1" title="In Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S2" title="In Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Relate Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S2.SS1" title="In 2. Relate Work ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Content-based Recommendation.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S2.SS2" title="In 2. Relate Work ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>LLM-based Recommendation.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S3" title="In Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S3.SS1" title="In 3. Method ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Content Embedding of LLM</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S3.SS2" title="In 3. Method ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Model Architecture</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S3.SS2.SSS1" title="In 3.2. Model Architecture ‣ 3. Method ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>User Tower</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S3.SS2.SSS2" title="In 3.2. Model Architecture ‣ 3. Method ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>Item Tower</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S3.SS2.SSS3" title="In 3.2. Model Architecture ‣ 3. Method ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.3 </span>Training Target of Recommendation Domain</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4" title="In Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>EXPERIMENTS</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.SS1" title="In 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Offline Dataset</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.SS2" title="In 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Offline Experimental Settings</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.SS2.SSS1" title="In 4.2. Offline Experimental Settings ‣ 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Implementation Details</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.SS3" title="In 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Offline Results</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.SS3.SSS1" title="In 4.3. Offline Results ‣ 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.1 </span>Comparison of embedding types (<span class="ltx_text ltx_font_bold">RQ1</span>)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.SS3.SSS2" title="In 4.3. Offline Results ‣ 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.2 </span>Comparison with previous ”Rec-to-LLM” method (<span class="ltx_text ltx_font_bold">RQ2</span>)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.SS3.SSS3" title="In 4.3. Offline Results ‣ 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.3 </span>Comparison with SOTA models proposed for industry scenarios (<span class="ltx_text ltx_font_bold">RQ3</span>)</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.SS3.SSS4" title="In 4.3. Offline Results ‣ 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.4 </span>Ablation studies of modules within the LEARN framework (<span class="ltx_text ltx_font_bold">RQ4</span>)</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.SS4" title="In 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Ranking A/B Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.SS4.SSS1" title="In 4.4. Ranking A/B Experiments ‣ 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4.1 </span>Model Structure</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.SS4.SSS2" title="In 4.4. Ranking A/B Experiments ‣ 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4.2 </span>AUC Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.SS4.SSS3" title="In 4.4. Ranking A/B Experiments ‣ 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4.3 </span>Online Revenue Improvement</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S5" title="In Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jian Jia
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:jian.jia@outlook.com">jian.jia@outlook.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id1.1.id1">Kuaishou Technology</span><span class="ltx_text ltx_affiliation_city" id="id2.2.id2">Beijing</span><span class="ltx_text ltx_affiliation_country" id="id3.3.id3">China</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yipei Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:220213711@seu.edu.cn">220213711@seu.edu.cn</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id4.1.id1">Southeast University</span><span class="ltx_text ltx_affiliation_city" id="id5.2.id2">Nanjing</span><span class="ltx_text ltx_affiliation_country" id="id6.3.id3">China</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yan Li
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:yan.li@cripac.ia.ac.cn">yan.li@cripac.ia.ac.cn</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id7.1.id1">Kuaishou Technology</span><span class="ltx_text ltx_affiliation_city" id="id8.2.id2">Beijing</span><span class="ltx_text ltx_affiliation_country" id="id9.3.id3">China</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Honggang Chen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:yuanhong.chg@gmail.com">yuanhong.chg@gmail.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id10.1.id1">Kuaishou Technology</span><span class="ltx_text ltx_affiliation_city" id="id11.2.id2">Beijing</span><span class="ltx_text ltx_affiliation_country" id="id12.3.id3">China</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xuehan Bai
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:baixuehanmiao@gmail.com">baixuehanmiao@gmail.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id13.1.id1">Kuaishou Technology</span><span class="ltx_text ltx_affiliation_city" id="id14.2.id2">Beijing</span><span class="ltx_text ltx_affiliation_country" id="id15.3.id3">China</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhaocheng Liu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:lio.h.zen@gmail.com">lio.h.zen@gmail.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id16.1.id1">Kuaishou Technology</span><span class="ltx_text ltx_affiliation_city" id="id17.2.id2">Beijing</span><span class="ltx_text ltx_affiliation_country" id="id18.3.id3">China</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jian Liang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:liangjianzb12@gmail.com">liangjianzb12@gmail.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id19.1.id1">Kuaishou Technology</span><span class="ltx_text ltx_affiliation_city" id="id20.2.id2">Beijing</span><span class="ltx_text ltx_affiliation_country" id="id21.3.id3">China</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Quan Chen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:myctllmail@163.com">myctllmail@163.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id22.1.id1">Kuaishou Technology</span><span class="ltx_text ltx_affiliation_city" id="id23.2.id2">Beijing</span><span class="ltx_text ltx_affiliation_country" id="id24.3.id3">China</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Han Li
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:lee.han06@gmail.com">lee.han06@gmail.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id25.1.id1">Kuaishou Technology</span><span class="ltx_text ltx_affiliation_city" id="id26.2.id2">Beijing</span><span class="ltx_text ltx_affiliation_country" id="id27.3.id3">China</span>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Peng Jiang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:jp2006@139.com">jp2006@139.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id28.1.id1">Kuaishou Technology</span><span class="ltx_text ltx_affiliation_city" id="id29.2.id2">Beijing</span><span class="ltx_text ltx_affiliation_country" id="id30.3.id3">China</span>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kun Gai
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:gai.kun@qq.com">gai.kun@qq.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span class="ltx_text ltx_affiliation_institution" id="id31.1.id1">Unaffliate</span><span class="ltx_text ltx_affiliation_city" id="id32.2.id2">Beijing</span><span class="ltx_text ltx_affiliation_country" id="id33.3.id3">China</span>
</span></span></span>
</div>
<div class="ltx_dates">(2018)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p class="ltx_p" id="id34.id1">Contemporary recommender systems predominantly rely on collaborative filtering techniques, employing ID-embedding to capture latent associations among users and items. However, this approach overlooks the wealth of semantic information embedded within textual descriptions of items, leading to suboptimal performance in cold-start scenarios and long-tail user recommendations. Leveraging the capabilities of Large Language Models (LLMs) pretrained on massive text corpus presents a promising avenue for enhancing recommender systems by integrating open-world domain knowledge. In this paper, we propose an Llm-driven knowlEdge Adaptive RecommeNdation (LEARN) framework that synergizes open-world knowledge with collaborative knowledge. We address computational complexity concerns by utilizing pretrained LLMs as item encoders and freezing LLM parameters to avoid catastrophic forgetting and preserve open-world knowledge. To bridge the gap between the open-world and collaborative domains, we design a twin-tower structure supervised by the recommendation task and tailored for practical industrial application. Through offline experiments on the large-scale industrial dataset and online experiments on A/B tests, we demonstrate the efficacy of our approach.</p>
</div>
<div class="ltx_keywords">Large-Language Model, Sequential Recommendation, Recommendation
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_copyright" id="id1"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_journalyear" id="id2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2018</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_doi" id="id3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>XXXXXXX.XXXXXXX</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_conference" id="id4"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>Make sure to enter the correct
conference title from your rights confirmation emai; June 03–05,
2018; Woodstock, NY</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_isbn" id="id5"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>978-1-4503-XXXX-X/18/06</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_ccs" id="id6"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Information systems Recommender systems</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Recommendation systems (RS) have become indispensable tools in various online platforms, facilitating personalized recommendations to users amidst the overwhelming abundance of content.
Contemporary RS represents user and item features by distinct ID-embedding, which is learned based on the interactions between users and items and is effective in capturing latent associations among users and items.
However, ID-embedding based RS overlooks the wealth of semantic information contained in textual descriptions of items.
Consequently, the acquired recommendation model struggles to generalize to unseen data, resulting in suboptimal performance, particularly in cold-start scenarios and long-tail user recommendations.
Thus, to provide incremental information to the current RS, how to explore the content descriptions of items attracts attention from academics and industry.</p>
</div>
<figure class="ltx_figure" id="S1.F1">
<div class="ltx_block" id="S1.F1.1">
<img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S1.F1.g1" src=""/><span class="ltx_ERROR ltx_centering undefined" id="S1.F1.1.1">\Description</span>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Illustration of proposed LEARN framework and previous ”Rec-to-LLM” methods. Previous methods textualize the recommendation data to natural language conversations, which are the input of LLM to get the text predictions. In contrast, our method LEARN transforms the text information of items into embedding, which is projected into the collaborative domain to achieve alignment with industry recommendation tasks.</figcaption>
</figure>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">With the attention towards the power demonstrated by LLM in natural language processing (NLP) <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib35" title="">2023</a>; Chiang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib6" title="">2023</a>; Baichuan, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib2" title="">2023</a>)</cite>, <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">e.g.</span>, rich open-world domain knowledge or great logical reasoning ability, etc., it shows a novel path for the development of recommender systems, that is to get recommender systems to embrace LLM and leverage the open-world domain knowledge of LLM <cite class="ltx_cite ltx_citemacro_citep">(Fan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib10" title="">2023a</a>; Lin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib24" title="">2023a</a>)</cite>. In this work, we aim to explore the learning of user and item embeddings for recommender systems from LLM-based content representations. Owing to pretraining on extensive general textual corpora, content embeddings derived from Large Language Models (LLMs) by comprehending and reasoning about textual descriptions are categorized within the general knowledge domain. In contrast, ID embeddings learned from RS fall within the collaborative knowledge domain. Therefore, bridging the gap between the general and recommendation-specific domains is crucial. This enables the leveraging of LLM’s open-world knowledge to provide a substantial informational increment to existing RS, enhancing their effectiveness and generalization.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Prior research on integrating LLMs with RS can be broadly categorized into two approaches. The first approach freezes the LLM parameters and adapts the recommendation domain data into conversational formats. These methods leverage the LLM’s comprehension and reasoning capabilities, transforming user-item interaction data into textual sentences. This data is then processed by the LLM using various prompts to perform tasks like generating top-K recommendations, sequence recommendations, and explanations for recommendations <cite class="ltx_cite ltx_citemacro_citep">(Lyu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib28" title="">2023</a>; Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib26" title="">2023a</a>; Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib45" title="">2023</a>; Gao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib12" title="">2023</a>; Sanner et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib32" title="">2023</a>; Hou et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib19" title="">2024</a>)</cite>. The second approach fine-tunes the LLM on specially prepared textual datasets from the recommendation domain <cite class="ltx_cite ltx_citemacro_citep">(Liao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib23" title="">2023</a>; Bao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib4" title="">2023b</a>; Yuan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib42" title="">2023</a>; Bao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib3" title="">2023a</a>; Lin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib25" title="">2023b</a>)</cite>. By utilizing prompt design, these methods enable the LLM to learn latent relationships between users and items through the next token prediction task.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Both discussed methods convert user-item interactions from the recommendation domain into the textual data format of the open-world domain, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">1</span></a>. These methods utilize the LLM to deliver personalized recommendations, aligning the input organization and target tasks with those of the LLM’s pretraining stage. We define this process as ”Rec-to-LLM adaptation”, a form of domain adaptation from the recommendation domain (target domain) to the open-world domain of LLMs (source domain). However, our empirical investigations reveal that the ”Rec-to-LLM” adaptation fails to yield practical benefits in real-world industry applications. This inefficacy can be attributed to the inherent shortcomings of this approach, which include the following key aspects:</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">1) <span class="ltx_text ltx_font_bold" id="S1.p5.1.1">Inference LLM or finetuning LLM with the user history interactions is impractical in industry scenarios</span>.
Handling a user interaction sequence that comprises hundreds or thousands of items annually poses significant computational challenges. Given the input constraints of LLMs limited to 2K or 4K tokens <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib35" title="">2023</a>; Baichuan, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib2" title="">2023</a>)</cite>, accommodating such extensive data within a single input is impractical. Moreover, the computational complexity of LLMs increases quadratically with the length of the input sequence. Therefore, handling the global history interactions of users with LLM poses significant computational burdens.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">2) <span class="ltx_text ltx_font_bold" id="S1.p6.1.1">Finetuning LLM for recommendation systems often leads to catastrophic forgetting and suboptimal performance.</span>
Despite computational feasibility, finetuning Large Language Models (LLMs) with full parameters on extensive recommendation data typically results in catastrophic forgetting of open-world knowledge, leading to suboptimal outcomes. Even partial parameter tuning like LoRA <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib20" title="">2021</a>)</cite> often fails to achieve satisfactory performance.
Two primary issues contribute to these challenges.
One is the domain gap. There is a profound gap between the collaborative knowledge required in the recommendation domain and the general open-world knowledge held by LLMs, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">1</span></a>. Research in continual learning indicates that when pretrained LLMs are adapted for specific tasks, they frequently suffer significant performance degradation in their original knowledge domains <cite class="ltx_cite ltx_citemacro_citep">(Shi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib33" title="">2024</a>)</cite>. This results in severe catastrophic forgetting during extensive finetuning with full parameters.
The other is the misalignment of training objectives. LLMs are generally pretrained to focus on the next token prediction, a task that develops a broad comprehension of general knowledge from large text corpora. In contrast, finetuning for recommendation systems emphasizes retrieval-oriented tasks that heavily depend on collaborative signals from user-item interactions. Both issues hamper our efforts to harness the LLM’s open-world knowledge to augment the existing RS with valuable incremental information.</p>
</div>
<div class="ltx_para" id="S1.p7">
<p class="ltx_p" id="S1.p7.1">To overcome the noted limitations, we introduce the Llm-driven knowlEdge Adaptive RecommeNdation (LEARN) approach, designed to synergize the open-world knowledge of LLMs with the collaborative knowledge of recommendation systems. Contrary to previous methods following ”Rec-to-LLM” adaptation, our approach adapts knowledge from LLM to recommendation (LLM-to-Rec). We employ the LLM as a content extractor, with the recommendation task serving as the training target. This strategy not only facilitates a seamless transition from the open-world domain of the LLM to the collaborative domain of RS but also ensures a better alignment with the practical needs of industrial online RS. The distinct advantages of our method compared to previous ”Rec-to-LLM” approaches are depicted in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div class="ltx_para" id="S1.p8">
<p class="ltx_p" id="S1.p8.1">Specifically, the proposed LEARN framework adopts a twin-tower structure: user and item tower. Both towers consist of the Content-Embedding Generation (CEG) and Preference CompreHension (PCH) modules. To address the computational challenges associated with processing extensive user history interaction, the CEG module employs the pretrained LLM (Baichuan2-7B <cite class="ltx_cite ltx_citemacro_citep">(Yang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib41" title="">2023</a>)</cite>) as an item encoder rather than as a user preference encoder to reduce computational overhead. This LLM extracts content embeddings from item descriptions, including title, category, caption, price, and attributes. To prevent catastrophic forgetting of open-world knowledge, we freeze the LLM during the training stage.
Furthermore, to bridge the domain gap between open-world and collaborative knowledge as shown in Fig <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">1</span></a>, we designed the PCH module and adopted the self-supervised training target of the recommendation task to guide model optimization.
The PCH module utilizes a sequence of content embeddings from items that a user has interacted with as input and generates a user embedding as output for RS. Self-supervised contrastive learning is adopted as the training target to effectively enhance the discrimination of the model in distinguishing between preferred and non-preferred items.</p>
</div>
<div class="ltx_para" id="S1.p9">
<p class="ltx_p" id="S1.p9.1">To validate the effectiveness of the proposed method, we build a large-scale recommendation dataset collected from the real recommendation scenario. Our data contains over 31 million items interacted with by 12 million users over a 10-month period.
We deploy our method on the real recommendation system and validate the efficacy of our approach in A/B experiments, which shows substantial improvements. We also achieve state-of-the-art (SOTA) performance on the public large-scale dataset Amazon Reviews (Books), surpassing the HSTU <cite class="ltx_cite ltx_citemacro_citep">(Zhai et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib44" title="">2024</a>)</cite> approach proposed by Meta.</p>
</div>
<div class="ltx_para" id="S1.p10">
<p class="ltx_p" id="S1.p10.1">We conclude our contributions as follows:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We propose the Llm-driven knowlEdge Adaptive RecommeNdation (LEARN) framework to efficiently aggregate the open-world knowledge encapsulated within LLMs into RS.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We propose the CEG and PCH modules to solve the catastrophic forgetting of open-world knowledge and bridge the domain gap between open-world and collaborative knowledge.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We verify the effectiveness of our method by achieving SOTA performance on the large-scale practical industrial scenario and the public recommendation dataset. To the best of our knowledge, we are pioneers in successfully deploying LLM in industrial recommendation scenarios and achieving profitability.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Relate Work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Content-based Recommendation.</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Traditional RS predominantly rely on ID-based embeddings, which frequently suffer from limited generalizability. To address this, extensive research has focused on deepening the understanding of user and item content to bring incremental information and enhance the generalization capabilities for online RS. Wu <span class="ltx_text ltx_font_italic" id="S2.SS1.p1.1.1">et al.</span> developed the large-scale MIND text dataset <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib39" title="">2020</a>)</cite> specifically for news recommendation, advancing research into the impact of text content understanding on recommendation systems. Following this, various studies have leveraged the BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib8" title="">2018</a>)</cite> model to improve content understanding. Examples include UNBERT <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib46" title="">2021</a>)</cite> and PLM-NR <cite class="ltx_cite ltx_citemacro_citep">(Wu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib38" title="">2021</a>)</cite>, which fully fine-tune BERT. Additionally, TBIN <cite class="ltx_cite ltx_citemacro_citep">(Chen et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib5" title="">2023</a>)</cite> utilizes pretrained BERT to encode textual descriptions within user behavior data. Beyond text, MoRec <cite class="ltx_cite ltx_citemacro_citep">(Yuan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib42" title="">2023</a>)</cite> and MISSRec <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib36" title="">2023b</a>)</cite> incorporate visual content from item images using ResNet <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib15" title="">2016</a>)</cite> and ViT <cite class="ltx_cite ltx_citemacro_citep">(Dosovitskiy et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib9" title="">2020</a>)</cite> for sequential modeling. With the recognized scaling laws and emergent behaviors of LLMs, LLM2BERT4Rec <cite class="ltx_cite ltx_citemacro_citep">(Harte et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib14" title="">2023</a>)</cite> substitutes BERT4REC’s item ID embedding with LLM embeddings processed through PCA for dimension reduction.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>LLM-based Recommendation.</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Due to the powerful capabilities demonstrated by Large Language Models (LLMs) in understanding textual content and reasoning with common sense, an increasing number of studies are exploring the integration of LLMs into recommender systems (RS) <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib24" title="">2023a</a>; Fan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib11" title="">2023b</a>)</cite>. Prior research can be categorized into two types, and both types adapt the recommendation domain data into conversational formats. The first type freezes the LLM parameters and takes the LLM as a recommender (LLM-as-Rec). Some works <cite class="ltx_cite ltx_citemacro_citep">(Gao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib12" title="">2023</a>; Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib26" title="">2023a</a>; Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib45" title="">2023</a>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib47" title="">2024</a>; Hou et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib19" title="">2024</a>; Xi et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib40" title="">2023</a>)</cite> proposed the task-specific prompt to construct recommendation dialogues and used ChatGPT to generate the candidates. Sanner <span class="ltx_text ltx_font_italic" id="S2.SS2.p1.1.1">et al.</span> <cite class="ltx_cite ltx_citemacro_citep">(Sanner et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib32" title="">2023</a>)</cite> adopted the PaLM <cite class="ltx_cite ltx_citemacro_citep">(Chowdhery et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib7" title="">2023</a>)</cite> as a cold-start recommender. RLMRec <cite class="ltx_cite ltx_citemacro_citep">(Ren et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib31" title="">2023</a>)</cite> utilized ChatGPT to generate user/item profiles.
RecMind <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib37" title="">2023a</a>)</cite> proposed an LLM-powered autonomous agent for various recommendation tasks. The second type fine-tunes the LLM on specially prepared textual datasets from the recommendation domain. GPT4Rec <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib22" title="">2023</a>)</cite> combined the GPT-2 with BM25 search engine to predict multiple candidatea and retrieval top-k items for each candidate. LlamaRec <cite class="ltx_cite ltx_citemacro_citep">(Yue et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib43" title="">2023</a>)</cite> took the item title as the textual data and optimized the LLM by the ranking scores. TALLRec <cite class="ltx_cite ltx_citemacro_citep">(Bao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib4" title="">2023b</a>)</cite> proposed a two-stage tuning framework and finetunes the LLM with LoRA <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib20" title="">2021</a>)</cite> for few-shot recommendation. LLaRA <cite class="ltx_cite ltx_citemacro_citep">(Liao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib23" title="">2023</a>)</cite> combined the LLM prompt with ID embeddings to align the LLM and the well-established sequential recommenders. ReLLa <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib25" title="">2023b</a>)</cite> proposed a retrieval-enhanced instruction tuning method and finetuned the Vicuna <cite class="ltx_cite ltx_citemacro_citep">(Chiang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib6" title="">2023</a>)</cite> on a mixed dataset.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Method</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we first verify the discrimination of item content embedding generated by LLM and confirm the feasibility of content embedding applied to recommendation system (RS). Then, we introduce the proposed Llm-driven knowlEdge Adaptive RecommeNdation (LEARN) framework following a twin-tower structure.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Content Embedding of LLM</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Integrating content-based embeddings into existing RS is a key focus in both academic and industrial research, given the advanced content comprehension and reasoning capabilities of LLMs. By processing textual inputs with carefully constructed prompts, LLMs can summarize user interests <cite class="ltx_cite ltx_citemacro_citep">(He et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib17" title="">2023</a>)</cite>, extract product information keywords <cite class="ltx_cite ltx_citemacro_citep">(Tan et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib34" title="">2024</a>)</cite>, and identify related products <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib22" title="">2023</a>)</cite>. However, this textual information must be transformed into embeddings to be utilized in industrial RS. We propose using the output embeddings from LLM as representations of input textual information, rather than using output words predicted by LLM. Given the limited research on the effectiveness of LLM-generated embeddings, particularly with models primarily using decoder architectures, we devise an item-to-item (I2I) retrieval experiment. This experiment involves a gallery set of 1 million items to assess the utility of LLM embeddings.</p>
</div>
<figure class="ltx_figure" id="S3.F2">
<div class="ltx_block" id="S3.F2.1">
<figure class="ltx_figure ltx_align_center" id="S3.F2.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_missing ltx_missing_image" id="S3.F2.sf1.g1" src=""/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Retrieval results of an ”Earring”.</figcaption>
</figure>
<figure class="ltx_figure ltx_align_center" id="S3.F2.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_missing ltx_missing_image" id="S3.F2.sf2.g1" src=""/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Retrieval results of a ”Building Block Puzzle”.</figcaption>
</figure>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Results of ANN retrieval based on LLM content embedding. The query and retrieved top 3 items are listed. Results show that the LLM embeddings are discriminative. </figcaption>
</figure>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F3.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>Illustration of our Llm-driven knowlEdge Adaptive RecommeNdation (LEARN) framework. The LEARN framework employs a twin-tower architecture comprising a user tower and an item tower. The user tower processes history interactions to generate user embeddings <math alttext="E^{user}" class="ltx_Math" display="inline" id="S3.F3.3.m1.1"><semantics id="S3.F3.3.m1.1b"><msup id="S3.F3.3.m1.1.1" xref="S3.F3.3.m1.1.1.cmml"><mi id="S3.F3.3.m1.1.1.2" xref="S3.F3.3.m1.1.1.2.cmml">E</mi><mrow id="S3.F3.3.m1.1.1.3" xref="S3.F3.3.m1.1.1.3.cmml"><mi id="S3.F3.3.m1.1.1.3.2" xref="S3.F3.3.m1.1.1.3.2.cmml">u</mi><mo id="S3.F3.3.m1.1.1.3.1" xref="S3.F3.3.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.F3.3.m1.1.1.3.3" xref="S3.F3.3.m1.1.1.3.3.cmml">s</mi><mo id="S3.F3.3.m1.1.1.3.1b" xref="S3.F3.3.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.F3.3.m1.1.1.3.4" xref="S3.F3.3.m1.1.1.3.4.cmml">e</mi><mo id="S3.F3.3.m1.1.1.3.1c" xref="S3.F3.3.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.F3.3.m1.1.1.3.5" xref="S3.F3.3.m1.1.1.3.5.cmml">r</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.F3.3.m1.1c"><apply id="S3.F3.3.m1.1.1.cmml" xref="S3.F3.3.m1.1.1"><csymbol cd="ambiguous" id="S3.F3.3.m1.1.1.1.cmml" xref="S3.F3.3.m1.1.1">superscript</csymbol><ci id="S3.F3.3.m1.1.1.2.cmml" xref="S3.F3.3.m1.1.1.2">𝐸</ci><apply id="S3.F3.3.m1.1.1.3.cmml" xref="S3.F3.3.m1.1.1.3"><times id="S3.F3.3.m1.1.1.3.1.cmml" xref="S3.F3.3.m1.1.1.3.1"></times><ci id="S3.F3.3.m1.1.1.3.2.cmml" xref="S3.F3.3.m1.1.1.3.2">𝑢</ci><ci id="S3.F3.3.m1.1.1.3.3.cmml" xref="S3.F3.3.m1.1.1.3.3">𝑠</ci><ci id="S3.F3.3.m1.1.1.3.4.cmml" xref="S3.F3.3.m1.1.1.3.4">𝑒</ci><ci id="S3.F3.3.m1.1.1.3.5.cmml" xref="S3.F3.3.m1.1.1.3.5">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.3.m1.1d">E^{user}</annotation><annotation encoding="application/x-llamapun" id="S3.F3.3.m1.1e">italic_E start_POSTSUPERSCRIPT italic_u italic_s italic_e italic_r end_POSTSUPERSCRIPT</annotation></semantics></math>, while the item tower handles target interactions to produce item embeddings <math alttext="E^{item}" class="ltx_Math" display="inline" id="S3.F3.4.m2.1"><semantics id="S3.F3.4.m2.1b"><msup id="S3.F3.4.m2.1.1" xref="S3.F3.4.m2.1.1.cmml"><mi id="S3.F3.4.m2.1.1.2" xref="S3.F3.4.m2.1.1.2.cmml">E</mi><mrow id="S3.F3.4.m2.1.1.3" xref="S3.F3.4.m2.1.1.3.cmml"><mi id="S3.F3.4.m2.1.1.3.2" xref="S3.F3.4.m2.1.1.3.2.cmml">i</mi><mo id="S3.F3.4.m2.1.1.3.1" xref="S3.F3.4.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.F3.4.m2.1.1.3.3" xref="S3.F3.4.m2.1.1.3.3.cmml">t</mi><mo id="S3.F3.4.m2.1.1.3.1b" xref="S3.F3.4.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.F3.4.m2.1.1.3.4" xref="S3.F3.4.m2.1.1.3.4.cmml">e</mi><mo id="S3.F3.4.m2.1.1.3.1c" xref="S3.F3.4.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.F3.4.m2.1.1.3.5" xref="S3.F3.4.m2.1.1.3.5.cmml">m</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.F3.4.m2.1c"><apply id="S3.F3.4.m2.1.1.cmml" xref="S3.F3.4.m2.1.1"><csymbol cd="ambiguous" id="S3.F3.4.m2.1.1.1.cmml" xref="S3.F3.4.m2.1.1">superscript</csymbol><ci id="S3.F3.4.m2.1.1.2.cmml" xref="S3.F3.4.m2.1.1.2">𝐸</ci><apply id="S3.F3.4.m2.1.1.3.cmml" xref="S3.F3.4.m2.1.1.3"><times id="S3.F3.4.m2.1.1.3.1.cmml" xref="S3.F3.4.m2.1.1.3.1"></times><ci id="S3.F3.4.m2.1.1.3.2.cmml" xref="S3.F3.4.m2.1.1.3.2">𝑖</ci><ci id="S3.F3.4.m2.1.1.3.3.cmml" xref="S3.F3.4.m2.1.1.3.3">𝑡</ci><ci id="S3.F3.4.m2.1.1.3.4.cmml" xref="S3.F3.4.m2.1.1.3.4">𝑒</ci><ci id="S3.F3.4.m2.1.1.3.5.cmml" xref="S3.F3.4.m2.1.1.3.5">𝑚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F3.4.m2.1d">E^{item}</annotation><annotation encoding="application/x-llamapun" id="S3.F3.4.m2.1e">italic_E start_POSTSUPERSCRIPT italic_i italic_t italic_e italic_m end_POSTSUPERSCRIPT</annotation></semantics></math>. User Tower and Item Tower (a) employ the causal attention mechanism, focusing solely on past items to model sequential dependencies. Item Tower (b) utilizes a self-attention mechanism that concentrates exclusively on the item itself. Item Tower (c) operates without the PCH module, directly using the content embedding as the item embedding.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">We first collect the content description of items from the online platform. An item is characterized by up to 6 aspects: title, category, brand, price, keywords, and attribute. A simple prompt is constructed to concatenate the 6 types of information into one content-descriptive sentence, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S3.F4" title="Figure 4 ‣ 3.2.3. Training Target of Recommendation Domain ‣ 3.2. Model Architecture ‣ 3. Method ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">4</span></a>. Then, the content sentence is tokenized into discrete indices and sent to LLM (Baichuan2-7B <cite class="ltx_cite ltx_citemacro_citep">(Baichuan, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib2" title="">2023</a>)</cite>). The output embeddings of token indices are average-pooled into one content embedding. We believe that this embedding encapsulates the understanding and reasoning of LLM regarding the textual information about item content.
Finally, we normalize the generated content embedding for an approximate nearest neighbor (ANN) retrieval. The results in Figure <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S3.F2" title="Figure 2 ‣ 3.1. Content Embedding of LLM ‣ 3. Method ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">2</span></a> indicate that the LLM-generated embedding is discriminative and semantically aligned with the item’s content. While we also test using the last token embedding as the content representation, average pooling yields superior retrieval performance and is therefore adopted as our default implementation.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Model Architecture</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.9">Our goal is to learn a recommendation model that understands the user’s interests from the history interaction and predicts the next item the user is interested in.
We construct history interactions <math alttext="U^{hist}" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><msup id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.1.1.2" xref="S3.SS2.p1.1.m1.1.1.2.cmml">U</mi><mrow id="S3.SS2.p1.1.m1.1.1.3" xref="S3.SS2.p1.1.m1.1.1.3.cmml"><mi id="S3.SS2.p1.1.m1.1.1.3.2" xref="S3.SS2.p1.1.m1.1.1.3.2.cmml">h</mi><mo id="S3.SS2.p1.1.m1.1.1.3.1" xref="S3.SS2.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p1.1.m1.1.1.3.3" xref="S3.SS2.p1.1.m1.1.1.3.3.cmml">i</mi><mo id="S3.SS2.p1.1.m1.1.1.3.1a" xref="S3.SS2.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p1.1.m1.1.1.3.4" xref="S3.SS2.p1.1.m1.1.1.3.4.cmml">s</mi><mo id="S3.SS2.p1.1.m1.1.1.3.1b" xref="S3.SS2.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p1.1.m1.1.1.3.5" xref="S3.SS2.p1.1.m1.1.1.3.5.cmml">t</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><apply id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.p1.1.m1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.1.1.2">𝑈</ci><apply id="S3.SS2.p1.1.m1.1.1.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3"><times id="S3.SS2.p1.1.m1.1.1.3.1.cmml" xref="S3.SS2.p1.1.m1.1.1.3.1"></times><ci id="S3.SS2.p1.1.m1.1.1.3.2.cmml" xref="S3.SS2.p1.1.m1.1.1.3.2">ℎ</ci><ci id="S3.SS2.p1.1.m1.1.1.3.3.cmml" xref="S3.SS2.p1.1.m1.1.1.3.3">𝑖</ci><ci id="S3.SS2.p1.1.m1.1.1.3.4.cmml" xref="S3.SS2.p1.1.m1.1.1.3.4">𝑠</ci><ci id="S3.SS2.p1.1.m1.1.1.3.5.cmml" xref="S3.SS2.p1.1.m1.1.1.3.5">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">U^{hist}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">italic_U start_POSTSUPERSCRIPT italic_h italic_i italic_s italic_t end_POSTSUPERSCRIPT</annotation></semantics></math> and target interactions <math alttext="U^{tar}" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><msup id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml"><mi id="S3.SS2.p1.2.m2.1.1.2" xref="S3.SS2.p1.2.m2.1.1.2.cmml">U</mi><mrow id="S3.SS2.p1.2.m2.1.1.3" xref="S3.SS2.p1.2.m2.1.1.3.cmml"><mi id="S3.SS2.p1.2.m2.1.1.3.2" xref="S3.SS2.p1.2.m2.1.1.3.2.cmml">t</mi><mo id="S3.SS2.p1.2.m2.1.1.3.1" xref="S3.SS2.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p1.2.m2.1.1.3.3" xref="S3.SS2.p1.2.m2.1.1.3.3.cmml">a</mi><mo id="S3.SS2.p1.2.m2.1.1.3.1a" xref="S3.SS2.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p1.2.m2.1.1.3.4" xref="S3.SS2.p1.2.m2.1.1.3.4.cmml">r</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><apply id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.p1.2.m2.1.1.2.cmml" xref="S3.SS2.p1.2.m2.1.1.2">𝑈</ci><apply id="S3.SS2.p1.2.m2.1.1.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3"><times id="S3.SS2.p1.2.m2.1.1.3.1.cmml" xref="S3.SS2.p1.2.m2.1.1.3.1"></times><ci id="S3.SS2.p1.2.m2.1.1.3.2.cmml" xref="S3.SS2.p1.2.m2.1.1.3.2">𝑡</ci><ci id="S3.SS2.p1.2.m2.1.1.3.3.cmml" xref="S3.SS2.p1.2.m2.1.1.3.3">𝑎</ci><ci id="S3.SS2.p1.2.m2.1.1.3.4.cmml" xref="S3.SS2.p1.2.m2.1.1.3.4">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">U^{tar}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">italic_U start_POSTSUPERSCRIPT italic_t italic_a italic_r end_POSTSUPERSCRIPT</annotation></semantics></math> in chronological order. The user’s chronological sequence of interactions is divided into two parts according to a certain timestamp, the first part as the history interaction sequence and the second part as the target sequence. The history and target interactions of the <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><mi id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><ci id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">italic_i</annotation></semantics></math>-user are denoted as <math alttext="U^{hist}_{i}" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.1"><semantics id="S3.SS2.p1.4.m4.1a"><msubsup id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml"><mi id="S3.SS2.p1.4.m4.1.1.2.2" xref="S3.SS2.p1.4.m4.1.1.2.2.cmml">U</mi><mi id="S3.SS2.p1.4.m4.1.1.3" xref="S3.SS2.p1.4.m4.1.1.3.cmml">i</mi><mrow id="S3.SS2.p1.4.m4.1.1.2.3" xref="S3.SS2.p1.4.m4.1.1.2.3.cmml"><mi id="S3.SS2.p1.4.m4.1.1.2.3.2" xref="S3.SS2.p1.4.m4.1.1.2.3.2.cmml">h</mi><mo id="S3.SS2.p1.4.m4.1.1.2.3.1" xref="S3.SS2.p1.4.m4.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS2.p1.4.m4.1.1.2.3.3" xref="S3.SS2.p1.4.m4.1.1.2.3.3.cmml">i</mi><mo id="S3.SS2.p1.4.m4.1.1.2.3.1a" xref="S3.SS2.p1.4.m4.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS2.p1.4.m4.1.1.2.3.4" xref="S3.SS2.p1.4.m4.1.1.2.3.4.cmml">s</mi><mo id="S3.SS2.p1.4.m4.1.1.2.3.1b" xref="S3.SS2.p1.4.m4.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS2.p1.4.m4.1.1.2.3.5" xref="S3.SS2.p1.4.m4.1.1.2.3.5.cmml">t</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><apply id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.4.m4.1.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1">subscript</csymbol><apply id="S3.SS2.p1.4.m4.1.1.2.cmml" xref="S3.SS2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.4.m4.1.1.2.1.cmml" xref="S3.SS2.p1.4.m4.1.1">superscript</csymbol><ci id="S3.SS2.p1.4.m4.1.1.2.2.cmml" xref="S3.SS2.p1.4.m4.1.1.2.2">𝑈</ci><apply id="S3.SS2.p1.4.m4.1.1.2.3.cmml" xref="S3.SS2.p1.4.m4.1.1.2.3"><times id="S3.SS2.p1.4.m4.1.1.2.3.1.cmml" xref="S3.SS2.p1.4.m4.1.1.2.3.1"></times><ci id="S3.SS2.p1.4.m4.1.1.2.3.2.cmml" xref="S3.SS2.p1.4.m4.1.1.2.3.2">ℎ</ci><ci id="S3.SS2.p1.4.m4.1.1.2.3.3.cmml" xref="S3.SS2.p1.4.m4.1.1.2.3.3">𝑖</ci><ci id="S3.SS2.p1.4.m4.1.1.2.3.4.cmml" xref="S3.SS2.p1.4.m4.1.1.2.3.4">𝑠</ci><ci id="S3.SS2.p1.4.m4.1.1.2.3.5.cmml" xref="S3.SS2.p1.4.m4.1.1.2.3.5">𝑡</ci></apply></apply><ci id="S3.SS2.p1.4.m4.1.1.3.cmml" xref="S3.SS2.p1.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">U^{hist}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.m4.1d">italic_U start_POSTSUPERSCRIPT italic_h italic_i italic_s italic_t end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> = <math alttext="\{Item_{i,1},Item_{i,2},\dots,Item_{i,H}\}" class="ltx_Math" display="inline" id="S3.SS2.p1.5.m5.10"><semantics id="S3.SS2.p1.5.m5.10a"><mrow id="S3.SS2.p1.5.m5.10.10.3" xref="S3.SS2.p1.5.m5.10.10.4.cmml"><mo id="S3.SS2.p1.5.m5.10.10.3.4" stretchy="false" xref="S3.SS2.p1.5.m5.10.10.4.cmml">{</mo><mrow id="S3.SS2.p1.5.m5.8.8.1.1" xref="S3.SS2.p1.5.m5.8.8.1.1.cmml"><mi id="S3.SS2.p1.5.m5.8.8.1.1.2" xref="S3.SS2.p1.5.m5.8.8.1.1.2.cmml">I</mi><mo id="S3.SS2.p1.5.m5.8.8.1.1.1" xref="S3.SS2.p1.5.m5.8.8.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p1.5.m5.8.8.1.1.3" xref="S3.SS2.p1.5.m5.8.8.1.1.3.cmml">t</mi><mo id="S3.SS2.p1.5.m5.8.8.1.1.1a" xref="S3.SS2.p1.5.m5.8.8.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p1.5.m5.8.8.1.1.4" xref="S3.SS2.p1.5.m5.8.8.1.1.4.cmml">e</mi><mo id="S3.SS2.p1.5.m5.8.8.1.1.1b" xref="S3.SS2.p1.5.m5.8.8.1.1.1.cmml">⁢</mo><msub id="S3.SS2.p1.5.m5.8.8.1.1.5" xref="S3.SS2.p1.5.m5.8.8.1.1.5.cmml"><mi id="S3.SS2.p1.5.m5.8.8.1.1.5.2" xref="S3.SS2.p1.5.m5.8.8.1.1.5.2.cmml">m</mi><mrow id="S3.SS2.p1.5.m5.2.2.2.4" xref="S3.SS2.p1.5.m5.2.2.2.3.cmml"><mi id="S3.SS2.p1.5.m5.1.1.1.1" xref="S3.SS2.p1.5.m5.1.1.1.1.cmml">i</mi><mo id="S3.SS2.p1.5.m5.2.2.2.4.1" xref="S3.SS2.p1.5.m5.2.2.2.3.cmml">,</mo><mn id="S3.SS2.p1.5.m5.2.2.2.2" xref="S3.SS2.p1.5.m5.2.2.2.2.cmml">1</mn></mrow></msub></mrow><mo id="S3.SS2.p1.5.m5.10.10.3.5" xref="S3.SS2.p1.5.m5.10.10.4.cmml">,</mo><mrow id="S3.SS2.p1.5.m5.9.9.2.2" xref="S3.SS2.p1.5.m5.9.9.2.2.cmml"><mi id="S3.SS2.p1.5.m5.9.9.2.2.2" xref="S3.SS2.p1.5.m5.9.9.2.2.2.cmml">I</mi><mo id="S3.SS2.p1.5.m5.9.9.2.2.1" xref="S3.SS2.p1.5.m5.9.9.2.2.1.cmml">⁢</mo><mi id="S3.SS2.p1.5.m5.9.9.2.2.3" xref="S3.SS2.p1.5.m5.9.9.2.2.3.cmml">t</mi><mo id="S3.SS2.p1.5.m5.9.9.2.2.1a" xref="S3.SS2.p1.5.m5.9.9.2.2.1.cmml">⁢</mo><mi id="S3.SS2.p1.5.m5.9.9.2.2.4" xref="S3.SS2.p1.5.m5.9.9.2.2.4.cmml">e</mi><mo id="S3.SS2.p1.5.m5.9.9.2.2.1b" xref="S3.SS2.p1.5.m5.9.9.2.2.1.cmml">⁢</mo><msub id="S3.SS2.p1.5.m5.9.9.2.2.5" xref="S3.SS2.p1.5.m5.9.9.2.2.5.cmml"><mi id="S3.SS2.p1.5.m5.9.9.2.2.5.2" xref="S3.SS2.p1.5.m5.9.9.2.2.5.2.cmml">m</mi><mrow id="S3.SS2.p1.5.m5.4.4.2.4" xref="S3.SS2.p1.5.m5.4.4.2.3.cmml"><mi id="S3.SS2.p1.5.m5.3.3.1.1" xref="S3.SS2.p1.5.m5.3.3.1.1.cmml">i</mi><mo id="S3.SS2.p1.5.m5.4.4.2.4.1" xref="S3.SS2.p1.5.m5.4.4.2.3.cmml">,</mo><mn id="S3.SS2.p1.5.m5.4.4.2.2" xref="S3.SS2.p1.5.m5.4.4.2.2.cmml">2</mn></mrow></msub></mrow><mo id="S3.SS2.p1.5.m5.10.10.3.6" xref="S3.SS2.p1.5.m5.10.10.4.cmml">,</mo><mi id="S3.SS2.p1.5.m5.7.7" mathvariant="normal" xref="S3.SS2.p1.5.m5.7.7.cmml">…</mi><mo id="S3.SS2.p1.5.m5.10.10.3.7" xref="S3.SS2.p1.5.m5.10.10.4.cmml">,</mo><mrow id="S3.SS2.p1.5.m5.10.10.3.3" xref="S3.SS2.p1.5.m5.10.10.3.3.cmml"><mi id="S3.SS2.p1.5.m5.10.10.3.3.2" xref="S3.SS2.p1.5.m5.10.10.3.3.2.cmml">I</mi><mo id="S3.SS2.p1.5.m5.10.10.3.3.1" xref="S3.SS2.p1.5.m5.10.10.3.3.1.cmml">⁢</mo><mi id="S3.SS2.p1.5.m5.10.10.3.3.3" xref="S3.SS2.p1.5.m5.10.10.3.3.3.cmml">t</mi><mo id="S3.SS2.p1.5.m5.10.10.3.3.1a" xref="S3.SS2.p1.5.m5.10.10.3.3.1.cmml">⁢</mo><mi id="S3.SS2.p1.5.m5.10.10.3.3.4" xref="S3.SS2.p1.5.m5.10.10.3.3.4.cmml">e</mi><mo id="S3.SS2.p1.5.m5.10.10.3.3.1b" xref="S3.SS2.p1.5.m5.10.10.3.3.1.cmml">⁢</mo><msub id="S3.SS2.p1.5.m5.10.10.3.3.5" xref="S3.SS2.p1.5.m5.10.10.3.3.5.cmml"><mi id="S3.SS2.p1.5.m5.10.10.3.3.5.2" xref="S3.SS2.p1.5.m5.10.10.3.3.5.2.cmml">m</mi><mrow id="S3.SS2.p1.5.m5.6.6.2.4" xref="S3.SS2.p1.5.m5.6.6.2.3.cmml"><mi id="S3.SS2.p1.5.m5.5.5.1.1" xref="S3.SS2.p1.5.m5.5.5.1.1.cmml">i</mi><mo id="S3.SS2.p1.5.m5.6.6.2.4.1" xref="S3.SS2.p1.5.m5.6.6.2.3.cmml">,</mo><mi id="S3.SS2.p1.5.m5.6.6.2.2" xref="S3.SS2.p1.5.m5.6.6.2.2.cmml">H</mi></mrow></msub></mrow><mo id="S3.SS2.p1.5.m5.10.10.3.8" stretchy="false" xref="S3.SS2.p1.5.m5.10.10.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.10b"><set id="S3.SS2.p1.5.m5.10.10.4.cmml" xref="S3.SS2.p1.5.m5.10.10.3"><apply id="S3.SS2.p1.5.m5.8.8.1.1.cmml" xref="S3.SS2.p1.5.m5.8.8.1.1"><times id="S3.SS2.p1.5.m5.8.8.1.1.1.cmml" xref="S3.SS2.p1.5.m5.8.8.1.1.1"></times><ci id="S3.SS2.p1.5.m5.8.8.1.1.2.cmml" xref="S3.SS2.p1.5.m5.8.8.1.1.2">𝐼</ci><ci id="S3.SS2.p1.5.m5.8.8.1.1.3.cmml" xref="S3.SS2.p1.5.m5.8.8.1.1.3">𝑡</ci><ci id="S3.SS2.p1.5.m5.8.8.1.1.4.cmml" xref="S3.SS2.p1.5.m5.8.8.1.1.4">𝑒</ci><apply id="S3.SS2.p1.5.m5.8.8.1.1.5.cmml" xref="S3.SS2.p1.5.m5.8.8.1.1.5"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.8.8.1.1.5.1.cmml" xref="S3.SS2.p1.5.m5.8.8.1.1.5">subscript</csymbol><ci id="S3.SS2.p1.5.m5.8.8.1.1.5.2.cmml" xref="S3.SS2.p1.5.m5.8.8.1.1.5.2">𝑚</ci><list id="S3.SS2.p1.5.m5.2.2.2.3.cmml" xref="S3.SS2.p1.5.m5.2.2.2.4"><ci id="S3.SS2.p1.5.m5.1.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1.1">𝑖</ci><cn id="S3.SS2.p1.5.m5.2.2.2.2.cmml" type="integer" xref="S3.SS2.p1.5.m5.2.2.2.2">1</cn></list></apply></apply><apply id="S3.SS2.p1.5.m5.9.9.2.2.cmml" xref="S3.SS2.p1.5.m5.9.9.2.2"><times id="S3.SS2.p1.5.m5.9.9.2.2.1.cmml" xref="S3.SS2.p1.5.m5.9.9.2.2.1"></times><ci id="S3.SS2.p1.5.m5.9.9.2.2.2.cmml" xref="S3.SS2.p1.5.m5.9.9.2.2.2">𝐼</ci><ci id="S3.SS2.p1.5.m5.9.9.2.2.3.cmml" xref="S3.SS2.p1.5.m5.9.9.2.2.3">𝑡</ci><ci id="S3.SS2.p1.5.m5.9.9.2.2.4.cmml" xref="S3.SS2.p1.5.m5.9.9.2.2.4">𝑒</ci><apply id="S3.SS2.p1.5.m5.9.9.2.2.5.cmml" xref="S3.SS2.p1.5.m5.9.9.2.2.5"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.9.9.2.2.5.1.cmml" xref="S3.SS2.p1.5.m5.9.9.2.2.5">subscript</csymbol><ci id="S3.SS2.p1.5.m5.9.9.2.2.5.2.cmml" xref="S3.SS2.p1.5.m5.9.9.2.2.5.2">𝑚</ci><list id="S3.SS2.p1.5.m5.4.4.2.3.cmml" xref="S3.SS2.p1.5.m5.4.4.2.4"><ci id="S3.SS2.p1.5.m5.3.3.1.1.cmml" xref="S3.SS2.p1.5.m5.3.3.1.1">𝑖</ci><cn id="S3.SS2.p1.5.m5.4.4.2.2.cmml" type="integer" xref="S3.SS2.p1.5.m5.4.4.2.2">2</cn></list></apply></apply><ci id="S3.SS2.p1.5.m5.7.7.cmml" xref="S3.SS2.p1.5.m5.7.7">…</ci><apply id="S3.SS2.p1.5.m5.10.10.3.3.cmml" xref="S3.SS2.p1.5.m5.10.10.3.3"><times id="S3.SS2.p1.5.m5.10.10.3.3.1.cmml" xref="S3.SS2.p1.5.m5.10.10.3.3.1"></times><ci id="S3.SS2.p1.5.m5.10.10.3.3.2.cmml" xref="S3.SS2.p1.5.m5.10.10.3.3.2">𝐼</ci><ci id="S3.SS2.p1.5.m5.10.10.3.3.3.cmml" xref="S3.SS2.p1.5.m5.10.10.3.3.3">𝑡</ci><ci id="S3.SS2.p1.5.m5.10.10.3.3.4.cmml" xref="S3.SS2.p1.5.m5.10.10.3.3.4">𝑒</ci><apply id="S3.SS2.p1.5.m5.10.10.3.3.5.cmml" xref="S3.SS2.p1.5.m5.10.10.3.3.5"><csymbol cd="ambiguous" id="S3.SS2.p1.5.m5.10.10.3.3.5.1.cmml" xref="S3.SS2.p1.5.m5.10.10.3.3.5">subscript</csymbol><ci id="S3.SS2.p1.5.m5.10.10.3.3.5.2.cmml" xref="S3.SS2.p1.5.m5.10.10.3.3.5.2">𝑚</ci><list id="S3.SS2.p1.5.m5.6.6.2.3.cmml" xref="S3.SS2.p1.5.m5.6.6.2.4"><ci id="S3.SS2.p1.5.m5.5.5.1.1.cmml" xref="S3.SS2.p1.5.m5.5.5.1.1">𝑖</ci><ci id="S3.SS2.p1.5.m5.6.6.2.2.cmml" xref="S3.SS2.p1.5.m5.6.6.2.2">𝐻</ci></list></apply></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.10c">\{Item_{i,1},Item_{i,2},\dots,Item_{i,H}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.5.m5.10d">{ italic_I italic_t italic_e italic_m start_POSTSUBSCRIPT italic_i , 1 end_POSTSUBSCRIPT , italic_I italic_t italic_e italic_m start_POSTSUBSCRIPT italic_i , 2 end_POSTSUBSCRIPT , … , italic_I italic_t italic_e italic_m start_POSTSUBSCRIPT italic_i , italic_H end_POSTSUBSCRIPT }</annotation></semantics></math> and <math alttext="U^{tar}_{i}" class="ltx_Math" display="inline" id="S3.SS2.p1.6.m6.1"><semantics id="S3.SS2.p1.6.m6.1a"><msubsup id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml"><mi id="S3.SS2.p1.6.m6.1.1.2.2" xref="S3.SS2.p1.6.m6.1.1.2.2.cmml">U</mi><mi id="S3.SS2.p1.6.m6.1.1.3" xref="S3.SS2.p1.6.m6.1.1.3.cmml">i</mi><mrow id="S3.SS2.p1.6.m6.1.1.2.3" xref="S3.SS2.p1.6.m6.1.1.2.3.cmml"><mi id="S3.SS2.p1.6.m6.1.1.2.3.2" xref="S3.SS2.p1.6.m6.1.1.2.3.2.cmml">t</mi><mo id="S3.SS2.p1.6.m6.1.1.2.3.1" xref="S3.SS2.p1.6.m6.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS2.p1.6.m6.1.1.2.3.3" xref="S3.SS2.p1.6.m6.1.1.2.3.3.cmml">a</mi><mo id="S3.SS2.p1.6.m6.1.1.2.3.1a" xref="S3.SS2.p1.6.m6.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS2.p1.6.m6.1.1.2.3.4" xref="S3.SS2.p1.6.m6.1.1.2.3.4.cmml">r</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><apply id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.1.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1">subscript</csymbol><apply id="S3.SS2.p1.6.m6.1.1.2.cmml" xref="S3.SS2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.6.m6.1.1.2.1.cmml" xref="S3.SS2.p1.6.m6.1.1">superscript</csymbol><ci id="S3.SS2.p1.6.m6.1.1.2.2.cmml" xref="S3.SS2.p1.6.m6.1.1.2.2">𝑈</ci><apply id="S3.SS2.p1.6.m6.1.1.2.3.cmml" xref="S3.SS2.p1.6.m6.1.1.2.3"><times id="S3.SS2.p1.6.m6.1.1.2.3.1.cmml" xref="S3.SS2.p1.6.m6.1.1.2.3.1"></times><ci id="S3.SS2.p1.6.m6.1.1.2.3.2.cmml" xref="S3.SS2.p1.6.m6.1.1.2.3.2">𝑡</ci><ci id="S3.SS2.p1.6.m6.1.1.2.3.3.cmml" xref="S3.SS2.p1.6.m6.1.1.2.3.3">𝑎</ci><ci id="S3.SS2.p1.6.m6.1.1.2.3.4.cmml" xref="S3.SS2.p1.6.m6.1.1.2.3.4">𝑟</ci></apply></apply><ci id="S3.SS2.p1.6.m6.1.1.3.cmml" xref="S3.SS2.p1.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">U^{tar}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.6.m6.1d">italic_U start_POSTSUPERSCRIPT italic_t italic_a italic_r end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> = <math alttext="\{Item_{i,H+1},Item_{i,H+2},\dots,Item_{i,H+T}\}" class="ltx_Math" display="inline" id="S3.SS2.p1.7.m7.10"><semantics id="S3.SS2.p1.7.m7.10a"><mrow id="S3.SS2.p1.7.m7.10.10.3" xref="S3.SS2.p1.7.m7.10.10.4.cmml"><mo id="S3.SS2.p1.7.m7.10.10.3.4" stretchy="false" xref="S3.SS2.p1.7.m7.10.10.4.cmml">{</mo><mrow id="S3.SS2.p1.7.m7.8.8.1.1" xref="S3.SS2.p1.7.m7.8.8.1.1.cmml"><mi id="S3.SS2.p1.7.m7.8.8.1.1.2" xref="S3.SS2.p1.7.m7.8.8.1.1.2.cmml">I</mi><mo id="S3.SS2.p1.7.m7.8.8.1.1.1" xref="S3.SS2.p1.7.m7.8.8.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p1.7.m7.8.8.1.1.3" xref="S3.SS2.p1.7.m7.8.8.1.1.3.cmml">t</mi><mo id="S3.SS2.p1.7.m7.8.8.1.1.1a" xref="S3.SS2.p1.7.m7.8.8.1.1.1.cmml">⁢</mo><mi id="S3.SS2.p1.7.m7.8.8.1.1.4" xref="S3.SS2.p1.7.m7.8.8.1.1.4.cmml">e</mi><mo id="S3.SS2.p1.7.m7.8.8.1.1.1b" xref="S3.SS2.p1.7.m7.8.8.1.1.1.cmml">⁢</mo><msub id="S3.SS2.p1.7.m7.8.8.1.1.5" xref="S3.SS2.p1.7.m7.8.8.1.1.5.cmml"><mi id="S3.SS2.p1.7.m7.8.8.1.1.5.2" xref="S3.SS2.p1.7.m7.8.8.1.1.5.2.cmml">m</mi><mrow id="S3.SS2.p1.7.m7.2.2.2.2" xref="S3.SS2.p1.7.m7.2.2.2.3.cmml"><mi id="S3.SS2.p1.7.m7.1.1.1.1" xref="S3.SS2.p1.7.m7.1.1.1.1.cmml">i</mi><mo id="S3.SS2.p1.7.m7.2.2.2.2.2" xref="S3.SS2.p1.7.m7.2.2.2.3.cmml">,</mo><mrow id="S3.SS2.p1.7.m7.2.2.2.2.1" xref="S3.SS2.p1.7.m7.2.2.2.2.1.cmml"><mi id="S3.SS2.p1.7.m7.2.2.2.2.1.2" xref="S3.SS2.p1.7.m7.2.2.2.2.1.2.cmml">H</mi><mo id="S3.SS2.p1.7.m7.2.2.2.2.1.1" xref="S3.SS2.p1.7.m7.2.2.2.2.1.1.cmml">+</mo><mn id="S3.SS2.p1.7.m7.2.2.2.2.1.3" xref="S3.SS2.p1.7.m7.2.2.2.2.1.3.cmml">1</mn></mrow></mrow></msub></mrow><mo id="S3.SS2.p1.7.m7.10.10.3.5" xref="S3.SS2.p1.7.m7.10.10.4.cmml">,</mo><mrow id="S3.SS2.p1.7.m7.9.9.2.2" xref="S3.SS2.p1.7.m7.9.9.2.2.cmml"><mi id="S3.SS2.p1.7.m7.9.9.2.2.2" xref="S3.SS2.p1.7.m7.9.9.2.2.2.cmml">I</mi><mo id="S3.SS2.p1.7.m7.9.9.2.2.1" xref="S3.SS2.p1.7.m7.9.9.2.2.1.cmml">⁢</mo><mi id="S3.SS2.p1.7.m7.9.9.2.2.3" xref="S3.SS2.p1.7.m7.9.9.2.2.3.cmml">t</mi><mo id="S3.SS2.p1.7.m7.9.9.2.2.1a" xref="S3.SS2.p1.7.m7.9.9.2.2.1.cmml">⁢</mo><mi id="S3.SS2.p1.7.m7.9.9.2.2.4" xref="S3.SS2.p1.7.m7.9.9.2.2.4.cmml">e</mi><mo id="S3.SS2.p1.7.m7.9.9.2.2.1b" xref="S3.SS2.p1.7.m7.9.9.2.2.1.cmml">⁢</mo><msub id="S3.SS2.p1.7.m7.9.9.2.2.5" xref="S3.SS2.p1.7.m7.9.9.2.2.5.cmml"><mi id="S3.SS2.p1.7.m7.9.9.2.2.5.2" xref="S3.SS2.p1.7.m7.9.9.2.2.5.2.cmml">m</mi><mrow id="S3.SS2.p1.7.m7.4.4.2.2" xref="S3.SS2.p1.7.m7.4.4.2.3.cmml"><mi id="S3.SS2.p1.7.m7.3.3.1.1" xref="S3.SS2.p1.7.m7.3.3.1.1.cmml">i</mi><mo id="S3.SS2.p1.7.m7.4.4.2.2.2" xref="S3.SS2.p1.7.m7.4.4.2.3.cmml">,</mo><mrow id="S3.SS2.p1.7.m7.4.4.2.2.1" xref="S3.SS2.p1.7.m7.4.4.2.2.1.cmml"><mi id="S3.SS2.p1.7.m7.4.4.2.2.1.2" xref="S3.SS2.p1.7.m7.4.4.2.2.1.2.cmml">H</mi><mo id="S3.SS2.p1.7.m7.4.4.2.2.1.1" xref="S3.SS2.p1.7.m7.4.4.2.2.1.1.cmml">+</mo><mn id="S3.SS2.p1.7.m7.4.4.2.2.1.3" xref="S3.SS2.p1.7.m7.4.4.2.2.1.3.cmml">2</mn></mrow></mrow></msub></mrow><mo id="S3.SS2.p1.7.m7.10.10.3.6" xref="S3.SS2.p1.7.m7.10.10.4.cmml">,</mo><mi id="S3.SS2.p1.7.m7.7.7" mathvariant="normal" xref="S3.SS2.p1.7.m7.7.7.cmml">…</mi><mo id="S3.SS2.p1.7.m7.10.10.3.7" xref="S3.SS2.p1.7.m7.10.10.4.cmml">,</mo><mrow id="S3.SS2.p1.7.m7.10.10.3.3" xref="S3.SS2.p1.7.m7.10.10.3.3.cmml"><mi id="S3.SS2.p1.7.m7.10.10.3.3.2" xref="S3.SS2.p1.7.m7.10.10.3.3.2.cmml">I</mi><mo id="S3.SS2.p1.7.m7.10.10.3.3.1" xref="S3.SS2.p1.7.m7.10.10.3.3.1.cmml">⁢</mo><mi id="S3.SS2.p1.7.m7.10.10.3.3.3" xref="S3.SS2.p1.7.m7.10.10.3.3.3.cmml">t</mi><mo id="S3.SS2.p1.7.m7.10.10.3.3.1a" xref="S3.SS2.p1.7.m7.10.10.3.3.1.cmml">⁢</mo><mi id="S3.SS2.p1.7.m7.10.10.3.3.4" xref="S3.SS2.p1.7.m7.10.10.3.3.4.cmml">e</mi><mo id="S3.SS2.p1.7.m7.10.10.3.3.1b" xref="S3.SS2.p1.7.m7.10.10.3.3.1.cmml">⁢</mo><msub id="S3.SS2.p1.7.m7.10.10.3.3.5" xref="S3.SS2.p1.7.m7.10.10.3.3.5.cmml"><mi id="S3.SS2.p1.7.m7.10.10.3.3.5.2" xref="S3.SS2.p1.7.m7.10.10.3.3.5.2.cmml">m</mi><mrow id="S3.SS2.p1.7.m7.6.6.2.2" xref="S3.SS2.p1.7.m7.6.6.2.3.cmml"><mi id="S3.SS2.p1.7.m7.5.5.1.1" xref="S3.SS2.p1.7.m7.5.5.1.1.cmml">i</mi><mo id="S3.SS2.p1.7.m7.6.6.2.2.2" xref="S3.SS2.p1.7.m7.6.6.2.3.cmml">,</mo><mrow id="S3.SS2.p1.7.m7.6.6.2.2.1" xref="S3.SS2.p1.7.m7.6.6.2.2.1.cmml"><mi id="S3.SS2.p1.7.m7.6.6.2.2.1.2" xref="S3.SS2.p1.7.m7.6.6.2.2.1.2.cmml">H</mi><mo id="S3.SS2.p1.7.m7.6.6.2.2.1.1" xref="S3.SS2.p1.7.m7.6.6.2.2.1.1.cmml">+</mo><mi id="S3.SS2.p1.7.m7.6.6.2.2.1.3" xref="S3.SS2.p1.7.m7.6.6.2.2.1.3.cmml">T</mi></mrow></mrow></msub></mrow><mo id="S3.SS2.p1.7.m7.10.10.3.8" stretchy="false" xref="S3.SS2.p1.7.m7.10.10.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m7.10b"><set id="S3.SS2.p1.7.m7.10.10.4.cmml" xref="S3.SS2.p1.7.m7.10.10.3"><apply id="S3.SS2.p1.7.m7.8.8.1.1.cmml" xref="S3.SS2.p1.7.m7.8.8.1.1"><times id="S3.SS2.p1.7.m7.8.8.1.1.1.cmml" xref="S3.SS2.p1.7.m7.8.8.1.1.1"></times><ci id="S3.SS2.p1.7.m7.8.8.1.1.2.cmml" xref="S3.SS2.p1.7.m7.8.8.1.1.2">𝐼</ci><ci id="S3.SS2.p1.7.m7.8.8.1.1.3.cmml" xref="S3.SS2.p1.7.m7.8.8.1.1.3">𝑡</ci><ci id="S3.SS2.p1.7.m7.8.8.1.1.4.cmml" xref="S3.SS2.p1.7.m7.8.8.1.1.4">𝑒</ci><apply id="S3.SS2.p1.7.m7.8.8.1.1.5.cmml" xref="S3.SS2.p1.7.m7.8.8.1.1.5"><csymbol cd="ambiguous" id="S3.SS2.p1.7.m7.8.8.1.1.5.1.cmml" xref="S3.SS2.p1.7.m7.8.8.1.1.5">subscript</csymbol><ci id="S3.SS2.p1.7.m7.8.8.1.1.5.2.cmml" xref="S3.SS2.p1.7.m7.8.8.1.1.5.2">𝑚</ci><list id="S3.SS2.p1.7.m7.2.2.2.3.cmml" xref="S3.SS2.p1.7.m7.2.2.2.2"><ci id="S3.SS2.p1.7.m7.1.1.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1.1.1">𝑖</ci><apply id="S3.SS2.p1.7.m7.2.2.2.2.1.cmml" xref="S3.SS2.p1.7.m7.2.2.2.2.1"><plus id="S3.SS2.p1.7.m7.2.2.2.2.1.1.cmml" xref="S3.SS2.p1.7.m7.2.2.2.2.1.1"></plus><ci id="S3.SS2.p1.7.m7.2.2.2.2.1.2.cmml" xref="S3.SS2.p1.7.m7.2.2.2.2.1.2">𝐻</ci><cn id="S3.SS2.p1.7.m7.2.2.2.2.1.3.cmml" type="integer" xref="S3.SS2.p1.7.m7.2.2.2.2.1.3">1</cn></apply></list></apply></apply><apply id="S3.SS2.p1.7.m7.9.9.2.2.cmml" xref="S3.SS2.p1.7.m7.9.9.2.2"><times id="S3.SS2.p1.7.m7.9.9.2.2.1.cmml" xref="S3.SS2.p1.7.m7.9.9.2.2.1"></times><ci id="S3.SS2.p1.7.m7.9.9.2.2.2.cmml" xref="S3.SS2.p1.7.m7.9.9.2.2.2">𝐼</ci><ci id="S3.SS2.p1.7.m7.9.9.2.2.3.cmml" xref="S3.SS2.p1.7.m7.9.9.2.2.3">𝑡</ci><ci id="S3.SS2.p1.7.m7.9.9.2.2.4.cmml" xref="S3.SS2.p1.7.m7.9.9.2.2.4">𝑒</ci><apply id="S3.SS2.p1.7.m7.9.9.2.2.5.cmml" xref="S3.SS2.p1.7.m7.9.9.2.2.5"><csymbol cd="ambiguous" id="S3.SS2.p1.7.m7.9.9.2.2.5.1.cmml" xref="S3.SS2.p1.7.m7.9.9.2.2.5">subscript</csymbol><ci id="S3.SS2.p1.7.m7.9.9.2.2.5.2.cmml" xref="S3.SS2.p1.7.m7.9.9.2.2.5.2">𝑚</ci><list id="S3.SS2.p1.7.m7.4.4.2.3.cmml" xref="S3.SS2.p1.7.m7.4.4.2.2"><ci id="S3.SS2.p1.7.m7.3.3.1.1.cmml" xref="S3.SS2.p1.7.m7.3.3.1.1">𝑖</ci><apply id="S3.SS2.p1.7.m7.4.4.2.2.1.cmml" xref="S3.SS2.p1.7.m7.4.4.2.2.1"><plus id="S3.SS2.p1.7.m7.4.4.2.2.1.1.cmml" xref="S3.SS2.p1.7.m7.4.4.2.2.1.1"></plus><ci id="S3.SS2.p1.7.m7.4.4.2.2.1.2.cmml" xref="S3.SS2.p1.7.m7.4.4.2.2.1.2">𝐻</ci><cn id="S3.SS2.p1.7.m7.4.4.2.2.1.3.cmml" type="integer" xref="S3.SS2.p1.7.m7.4.4.2.2.1.3">2</cn></apply></list></apply></apply><ci id="S3.SS2.p1.7.m7.7.7.cmml" xref="S3.SS2.p1.7.m7.7.7">…</ci><apply id="S3.SS2.p1.7.m7.10.10.3.3.cmml" xref="S3.SS2.p1.7.m7.10.10.3.3"><times id="S3.SS2.p1.7.m7.10.10.3.3.1.cmml" xref="S3.SS2.p1.7.m7.10.10.3.3.1"></times><ci id="S3.SS2.p1.7.m7.10.10.3.3.2.cmml" xref="S3.SS2.p1.7.m7.10.10.3.3.2">𝐼</ci><ci id="S3.SS2.p1.7.m7.10.10.3.3.3.cmml" xref="S3.SS2.p1.7.m7.10.10.3.3.3">𝑡</ci><ci id="S3.SS2.p1.7.m7.10.10.3.3.4.cmml" xref="S3.SS2.p1.7.m7.10.10.3.3.4">𝑒</ci><apply id="S3.SS2.p1.7.m7.10.10.3.3.5.cmml" xref="S3.SS2.p1.7.m7.10.10.3.3.5"><csymbol cd="ambiguous" id="S3.SS2.p1.7.m7.10.10.3.3.5.1.cmml" xref="S3.SS2.p1.7.m7.10.10.3.3.5">subscript</csymbol><ci id="S3.SS2.p1.7.m7.10.10.3.3.5.2.cmml" xref="S3.SS2.p1.7.m7.10.10.3.3.5.2">𝑚</ci><list id="S3.SS2.p1.7.m7.6.6.2.3.cmml" xref="S3.SS2.p1.7.m7.6.6.2.2"><ci id="S3.SS2.p1.7.m7.5.5.1.1.cmml" xref="S3.SS2.p1.7.m7.5.5.1.1">𝑖</ci><apply id="S3.SS2.p1.7.m7.6.6.2.2.1.cmml" xref="S3.SS2.p1.7.m7.6.6.2.2.1"><plus id="S3.SS2.p1.7.m7.6.6.2.2.1.1.cmml" xref="S3.SS2.p1.7.m7.6.6.2.2.1.1"></plus><ci id="S3.SS2.p1.7.m7.6.6.2.2.1.2.cmml" xref="S3.SS2.p1.7.m7.6.6.2.2.1.2">𝐻</ci><ci id="S3.SS2.p1.7.m7.6.6.2.2.1.3.cmml" xref="S3.SS2.p1.7.m7.6.6.2.2.1.3">𝑇</ci></apply></list></apply></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m7.10c">\{Item_{i,H+1},Item_{i,H+2},\dots,Item_{i,H+T}\}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.7.m7.10d">{ italic_I italic_t italic_e italic_m start_POSTSUBSCRIPT italic_i , italic_H + 1 end_POSTSUBSCRIPT , italic_I italic_t italic_e italic_m start_POSTSUBSCRIPT italic_i , italic_H + 2 end_POSTSUBSCRIPT , … , italic_I italic_t italic_e italic_m start_POSTSUBSCRIPT italic_i , italic_H + italic_T end_POSTSUBSCRIPT }</annotation></semantics></math>. <math alttext="H" class="ltx_Math" display="inline" id="S3.SS2.p1.8.m8.1"><semantics id="S3.SS2.p1.8.m8.1a"><mi id="S3.SS2.p1.8.m8.1.1" xref="S3.SS2.p1.8.m8.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.8.m8.1b"><ci id="S3.SS2.p1.8.m8.1.1.cmml" xref="S3.SS2.p1.8.m8.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.8.m8.1c">H</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.8.m8.1d">italic_H</annotation></semantics></math> and <math alttext="T" class="ltx_Math" display="inline" id="S3.SS2.p1.9.m9.1"><semantics id="S3.SS2.p1.9.m9.1a"><mi id="S3.SS2.p1.9.m9.1.1" xref="S3.SS2.p1.9.m9.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.9.m9.1b"><ci id="S3.SS2.p1.9.m9.1.1.cmml" xref="S3.SS2.p1.9.m9.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.9.m9.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.9.m9.1d">italic_T</annotation></semantics></math> denote the length of history and target interactions, respectively. The subscripts of user index are ignored in the following sections for simplicity.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1. </span>User Tower</h4>
<div class="ltx_para" id="S3.SS2.SSS1.p1">
<p class="ltx_p" id="S3.SS2.SSS1.p1.1">The user tower consists of a Content-Embedding Generation (CEG) module and a Preference CompreHension (PCH) Module, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S3.F4" title="Figure 4 ‣ 3.2.3. Training Target of Recommendation Domain ‣ 3.2. Model Architecture ‣ 3. Method ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">4</span></a>(a) and Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S3.F4" title="Figure 4 ‣ 3.2.3. Training Target of Recommendation Domain ‣ 3.2. Model Architecture ‣ 3. Method ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">4</span></a>(b).</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p2">
<p class="ltx_p" id="S3.SS2.SSS1.p2.2">Our CEG module employs a pretrained LLM as the backbone network where the parameters are frozen during training. We discard the linear classifier layer (lm_head) and instead use the hidden states from the final decoder layer to generate token embeddings. The LLM processes textual descriptions by tokenizing the input sentences and producing token embeddings. The textual description for each item is detailed in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S3.F4" title="Figure 4 ‣ 3.2.3. Training Target of Recommendation Domain ‣ 3.2. Model Architecture ‣ 3. Method ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">4</span></a> and referred to as <math alttext="Item^{T}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p2.1.m1.1"><semantics id="S3.SS2.SSS1.p2.1.m1.1a"><mrow id="S3.SS2.SSS1.p2.1.m1.1.1" xref="S3.SS2.SSS1.p2.1.m1.1.1.cmml"><mi id="S3.SS2.SSS1.p2.1.m1.1.1.2" xref="S3.SS2.SSS1.p2.1.m1.1.1.2.cmml">I</mi><mo id="S3.SS2.SSS1.p2.1.m1.1.1.1" xref="S3.SS2.SSS1.p2.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p2.1.m1.1.1.3" xref="S3.SS2.SSS1.p2.1.m1.1.1.3.cmml">t</mi><mo id="S3.SS2.SSS1.p2.1.m1.1.1.1a" xref="S3.SS2.SSS1.p2.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p2.1.m1.1.1.4" xref="S3.SS2.SSS1.p2.1.m1.1.1.4.cmml">e</mi><mo id="S3.SS2.SSS1.p2.1.m1.1.1.1b" xref="S3.SS2.SSS1.p2.1.m1.1.1.1.cmml">⁢</mo><msup id="S3.SS2.SSS1.p2.1.m1.1.1.5" xref="S3.SS2.SSS1.p2.1.m1.1.1.5.cmml"><mi id="S3.SS2.SSS1.p2.1.m1.1.1.5.2" xref="S3.SS2.SSS1.p2.1.m1.1.1.5.2.cmml">m</mi><mi id="S3.SS2.SSS1.p2.1.m1.1.1.5.3" xref="S3.SS2.SSS1.p2.1.m1.1.1.5.3.cmml">T</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.1.m1.1b"><apply id="S3.SS2.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1"><times id="S3.SS2.SSS1.p2.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1.1"></times><ci id="S3.SS2.SSS1.p2.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1.2">𝐼</ci><ci id="S3.SS2.SSS1.p2.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1.3">𝑡</ci><ci id="S3.SS2.SSS1.p2.1.m1.1.1.4.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1.4">𝑒</ci><apply id="S3.SS2.SSS1.p2.1.m1.1.1.5.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1.5"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.1.m1.1.1.5.1.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1.5">superscript</csymbol><ci id="S3.SS2.SSS1.p2.1.m1.1.1.5.2.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1.5.2">𝑚</ci><ci id="S3.SS2.SSS1.p2.1.m1.1.1.5.3.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1.5.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.1.m1.1c">Item^{T}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p2.1.m1.1d">italic_I italic_t italic_e italic_m start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT</annotation></semantics></math>. The prompt is designed concisely to verify the effects of the content information. An average pooling layer is applied to aggregate all token embeddings into the content embedding <math alttext="emb^{c}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p2.2.m2.1"><semantics id="S3.SS2.SSS1.p2.2.m2.1a"><mrow id="S3.SS2.SSS1.p2.2.m2.1.1" xref="S3.SS2.SSS1.p2.2.m2.1.1.cmml"><mi id="S3.SS2.SSS1.p2.2.m2.1.1.2" xref="S3.SS2.SSS1.p2.2.m2.1.1.2.cmml">e</mi><mo id="S3.SS2.SSS1.p2.2.m2.1.1.1" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p2.2.m2.1.1.3" xref="S3.SS2.SSS1.p2.2.m2.1.1.3.cmml">m</mi><mo id="S3.SS2.SSS1.p2.2.m2.1.1.1a" xref="S3.SS2.SSS1.p2.2.m2.1.1.1.cmml">⁢</mo><msup id="S3.SS2.SSS1.p2.2.m2.1.1.4" xref="S3.SS2.SSS1.p2.2.m2.1.1.4.cmml"><mi id="S3.SS2.SSS1.p2.2.m2.1.1.4.2" xref="S3.SS2.SSS1.p2.2.m2.1.1.4.2.cmml">b</mi><mi id="S3.SS2.SSS1.p2.2.m2.1.1.4.3" xref="S3.SS2.SSS1.p2.2.m2.1.1.4.3.cmml">c</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.2.m2.1b"><apply id="S3.SS2.SSS1.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1"><times id="S3.SS2.SSS1.p2.2.m2.1.1.1.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.1"></times><ci id="S3.SS2.SSS1.p2.2.m2.1.1.2.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.2">𝑒</ci><ci id="S3.SS2.SSS1.p2.2.m2.1.1.3.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.3">𝑚</ci><apply id="S3.SS2.SSS1.p2.2.m2.1.1.4.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.4"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.2.m2.1.1.4.1.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.4">superscript</csymbol><ci id="S3.SS2.SSS1.p2.2.m2.1.1.4.2.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.4.2">𝑏</ci><ci id="S3.SS2.SSS1.p2.2.m2.1.1.4.3.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1.4.3">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.2.m2.1c">emb^{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p2.2.m2.1d">italic_e italic_m italic_b start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT</annotation></semantics></math> for each item, as shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S3.F4" title="Figure 4 ‣ 3.2.3. Training Target of Recommendation Domain ‣ 3.2. Model Architecture ‣ 3. Method ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">4</span></a>(a). All items share the same CEG module.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS1.p3">
<p class="ltx_p" id="S3.SS2.SSS1.p3.4">The Preference CompreHension (PCH) module generates user embeddings that reflect user preferences based on the content embeddings of each item. For user history interaction sequence <math alttext="U^{hist}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.1.m1.1"><semantics id="S3.SS2.SSS1.p3.1.m1.1a"><msup id="S3.SS2.SSS1.p3.1.m1.1.1" xref="S3.SS2.SSS1.p3.1.m1.1.1.cmml"><mi id="S3.SS2.SSS1.p3.1.m1.1.1.2" xref="S3.SS2.SSS1.p3.1.m1.1.1.2.cmml">U</mi><mrow id="S3.SS2.SSS1.p3.1.m1.1.1.3" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.cmml"><mi id="S3.SS2.SSS1.p3.1.m1.1.1.3.2" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.2.cmml">h</mi><mo id="S3.SS2.SSS1.p3.1.m1.1.1.3.1" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.1.m1.1.1.3.3" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.3.cmml">i</mi><mo id="S3.SS2.SSS1.p3.1.m1.1.1.3.1a" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.1.m1.1.1.3.4" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.4.cmml">s</mi><mo id="S3.SS2.SSS1.p3.1.m1.1.1.3.1b" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.1.m1.1.1.3.5" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.5.cmml">t</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.1.m1.1b"><apply id="S3.SS2.SSS1.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.SSS1.p3.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.2">𝑈</ci><apply id="S3.SS2.SSS1.p3.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.3"><times id="S3.SS2.SSS1.p3.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.1"></times><ci id="S3.SS2.SSS1.p3.1.m1.1.1.3.2.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.2">ℎ</ci><ci id="S3.SS2.SSS1.p3.1.m1.1.1.3.3.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.3">𝑖</ci><ci id="S3.SS2.SSS1.p3.1.m1.1.1.3.4.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.4">𝑠</ci><ci id="S3.SS2.SSS1.p3.1.m1.1.1.3.5.cmml" xref="S3.SS2.SSS1.p3.1.m1.1.1.3.5">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.1.m1.1c">U^{hist}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.1.m1.1d">italic_U start_POSTSUPERSCRIPT italic_h italic_i italic_s italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>, we convert each item’s textual description into a content embedding <math alttext="E^{c}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.2.m2.1"><semantics id="S3.SS2.SSS1.p3.2.m2.1a"><msup id="S3.SS2.SSS1.p3.2.m2.1.1" xref="S3.SS2.SSS1.p3.2.m2.1.1.cmml"><mi id="S3.SS2.SSS1.p3.2.m2.1.1.2" xref="S3.SS2.SSS1.p3.2.m2.1.1.2.cmml">E</mi><mi id="S3.SS2.SSS1.p3.2.m2.1.1.3" xref="S3.SS2.SSS1.p3.2.m2.1.1.3.cmml">c</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.2.m2.1b"><apply id="S3.SS2.SSS1.p3.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.2.m2.1.1.1.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.SSS1.p3.2.m2.1.1.2.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1.2">𝐸</ci><ci id="S3.SS2.SSS1.p3.2.m2.1.1.3.cmml" xref="S3.SS2.SSS1.p3.2.m2.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.2.m2.1c">E^{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.2.m2.1d">italic_E start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT</annotation></semantics></math>, forming an embedding sequence <math alttext="\hat{U}^{hist}={E^{c}_{0},E^{c}_{1},\dots,E^{c}_{H}}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.3.m3.4"><semantics id="S3.SS2.SSS1.p3.3.m3.4a"><mrow id="S3.SS2.SSS1.p3.3.m3.4.4" xref="S3.SS2.SSS1.p3.3.m3.4.4.cmml"><msup id="S3.SS2.SSS1.p3.3.m3.4.4.5" xref="S3.SS2.SSS1.p3.3.m3.4.4.5.cmml"><mover accent="true" id="S3.SS2.SSS1.p3.3.m3.4.4.5.2" xref="S3.SS2.SSS1.p3.3.m3.4.4.5.2.cmml"><mi id="S3.SS2.SSS1.p3.3.m3.4.4.5.2.2" xref="S3.SS2.SSS1.p3.3.m3.4.4.5.2.2.cmml">U</mi><mo id="S3.SS2.SSS1.p3.3.m3.4.4.5.2.1" xref="S3.SS2.SSS1.p3.3.m3.4.4.5.2.1.cmml">^</mo></mover><mrow id="S3.SS2.SSS1.p3.3.m3.4.4.5.3" xref="S3.SS2.SSS1.p3.3.m3.4.4.5.3.cmml"><mi id="S3.SS2.SSS1.p3.3.m3.4.4.5.3.2" xref="S3.SS2.SSS1.p3.3.m3.4.4.5.3.2.cmml">h</mi><mo id="S3.SS2.SSS1.p3.3.m3.4.4.5.3.1" xref="S3.SS2.SSS1.p3.3.m3.4.4.5.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.3.m3.4.4.5.3.3" xref="S3.SS2.SSS1.p3.3.m3.4.4.5.3.3.cmml">i</mi><mo id="S3.SS2.SSS1.p3.3.m3.4.4.5.3.1a" xref="S3.SS2.SSS1.p3.3.m3.4.4.5.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.3.m3.4.4.5.3.4" xref="S3.SS2.SSS1.p3.3.m3.4.4.5.3.4.cmml">s</mi><mo id="S3.SS2.SSS1.p3.3.m3.4.4.5.3.1b" xref="S3.SS2.SSS1.p3.3.m3.4.4.5.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.3.m3.4.4.5.3.5" xref="S3.SS2.SSS1.p3.3.m3.4.4.5.3.5.cmml">t</mi></mrow></msup><mo id="S3.SS2.SSS1.p3.3.m3.4.4.4" xref="S3.SS2.SSS1.p3.3.m3.4.4.4.cmml">=</mo><mrow id="S3.SS2.SSS1.p3.3.m3.4.4.3.3" xref="S3.SS2.SSS1.p3.3.m3.4.4.3.4.cmml"><msubsup id="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1" xref="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1.cmml"><mi id="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1.2.2" xref="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1.2.2.cmml">E</mi><mn id="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1.3" xref="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1.3.cmml">0</mn><mi id="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1.2.3" xref="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1.2.3.cmml">c</mi></msubsup><mo id="S3.SS2.SSS1.p3.3.m3.4.4.3.3.4" xref="S3.SS2.SSS1.p3.3.m3.4.4.3.4.cmml">,</mo><msubsup id="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2" xref="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2.cmml"><mi id="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2.2.2" xref="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2.2.2.cmml">E</mi><mn id="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2.3" xref="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2.3.cmml">1</mn><mi id="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2.2.3" xref="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2.2.3.cmml">c</mi></msubsup><mo id="S3.SS2.SSS1.p3.3.m3.4.4.3.3.5" xref="S3.SS2.SSS1.p3.3.m3.4.4.3.4.cmml">,</mo><mi id="S3.SS2.SSS1.p3.3.m3.1.1" mathvariant="normal" xref="S3.SS2.SSS1.p3.3.m3.1.1.cmml">…</mi><mo id="S3.SS2.SSS1.p3.3.m3.4.4.3.3.6" xref="S3.SS2.SSS1.p3.3.m3.4.4.3.4.cmml">,</mo><msubsup id="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3" xref="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3.cmml"><mi id="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3.2.2" xref="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3.2.2.cmml">E</mi><mi id="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3.3" xref="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3.3.cmml">H</mi><mi id="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3.2.3" xref="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3.2.3.cmml">c</mi></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.3.m3.4b"><apply id="S3.SS2.SSS1.p3.3.m3.4.4.cmml" xref="S3.SS2.SSS1.p3.3.m3.4.4"><eq id="S3.SS2.SSS1.p3.3.m3.4.4.4.cmml" xref="S3.SS2.SSS1.p3.3.m3.4.4.4"></eq><apply id="S3.SS2.SSS1.p3.3.m3.4.4.5.cmml" xref="S3.SS2.SSS1.p3.3.m3.4.4.5"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.3.m3.4.4.5.1.cmml" xref="S3.SS2.SSS1.p3.3.m3.4.4.5">superscript</csymbol><apply id="S3.SS2.SSS1.p3.3.m3.4.4.5.2.cmml" xref="S3.SS2.SSS1.p3.3.m3.4.4.5.2"><ci id="S3.SS2.SSS1.p3.3.m3.4.4.5.2.1.cmml" xref="S3.SS2.SSS1.p3.3.m3.4.4.5.2.1">^</ci><ci id="S3.SS2.SSS1.p3.3.m3.4.4.5.2.2.cmml" xref="S3.SS2.SSS1.p3.3.m3.4.4.5.2.2">𝑈</ci></apply><apply id="S3.SS2.SSS1.p3.3.m3.4.4.5.3.cmml" xref="S3.SS2.SSS1.p3.3.m3.4.4.5.3"><times id="S3.SS2.SSS1.p3.3.m3.4.4.5.3.1.cmml" xref="S3.SS2.SSS1.p3.3.m3.4.4.5.3.1"></times><ci id="S3.SS2.SSS1.p3.3.m3.4.4.5.3.2.cmml" xref="S3.SS2.SSS1.p3.3.m3.4.4.5.3.2">ℎ</ci><ci id="S3.SS2.SSS1.p3.3.m3.4.4.5.3.3.cmml" xref="S3.SS2.SSS1.p3.3.m3.4.4.5.3.3">𝑖</ci><ci id="S3.SS2.SSS1.p3.3.m3.4.4.5.3.4.cmml" xref="S3.SS2.SSS1.p3.3.m3.4.4.5.3.4">𝑠</ci><ci id="S3.SS2.SSS1.p3.3.m3.4.4.5.3.5.cmml" xref="S3.SS2.SSS1.p3.3.m3.4.4.5.3.5">𝑡</ci></apply></apply><list id="S3.SS2.SSS1.p3.3.m3.4.4.3.4.cmml" xref="S3.SS2.SSS1.p3.3.m3.4.4.3.3"><apply id="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1.cmml" xref="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1.1.cmml" xref="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1">subscript</csymbol><apply id="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1.2.cmml" xref="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1.2.1.cmml" xref="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1">superscript</csymbol><ci id="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1.2.2.cmml" xref="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1.2.2">𝐸</ci><ci id="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1.2.3.cmml" xref="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1.2.3">𝑐</ci></apply><cn id="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS2.SSS1.p3.3.m3.2.2.1.1.1.3">0</cn></apply><apply id="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2.cmml" xref="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2.1.cmml" xref="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2">subscript</csymbol><apply id="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2.2.cmml" xref="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2.2.1.cmml" xref="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2">superscript</csymbol><ci id="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2.2.2.cmml" xref="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2.2.2">𝐸</ci><ci id="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2.2.3.cmml" xref="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2.2.3">𝑐</ci></apply><cn id="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS2.SSS1.p3.3.m3.3.3.2.2.2.3">1</cn></apply><ci id="S3.SS2.SSS1.p3.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p3.3.m3.1.1">…</ci><apply id="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3.cmml" xref="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3.1.cmml" xref="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3">subscript</csymbol><apply id="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3.2.cmml" xref="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3.2.1.cmml" xref="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3">superscript</csymbol><ci id="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3.2.2.cmml" xref="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3.2.2">𝐸</ci><ci id="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3.2.3.cmml" xref="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3.2.3">𝑐</ci></apply><ci id="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3.3.cmml" xref="S3.SS2.SSS1.p3.3.m3.4.4.3.3.3.3">𝐻</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.3.m3.4c">\hat{U}^{hist}={E^{c}_{0},E^{c}_{1},\dots,E^{c}_{H}}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.3.m3.4d">over^ start_ARG italic_U end_ARG start_POSTSUPERSCRIPT italic_h italic_i italic_s italic_t end_POSTSUPERSCRIPT = italic_E start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT , italic_E start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , … , italic_E start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_H end_POSTSUBSCRIPT</annotation></semantics></math>.
The PCH module utilizes this sequence as input, starting with a content projection layer for dimension transformation. Subsequently, a 12-layer transformer, similar to the BERT-base <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib8" title="">2018</a>)</cite> model, serves as the backbone network. This transformer is specifically designed to learn implicit item relationships and model user preferences. Unlike bidirectional attention in BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib8" title="">2018</a>)</cite>, which considers all items regardless of their sequence, our module employs the causal attention mechanism. This allows the PCH to focus attention on past items in the sequence, aligning with the chronological nature of user preferences.
The output embeddings from our transformer are further processed through linear layers to produce user embeddings <math alttext="E^{user}\in R^{64}" class="ltx_Math" display="inline" id="S3.SS2.SSS1.p3.4.m4.1"><semantics id="S3.SS2.SSS1.p3.4.m4.1a"><mrow id="S3.SS2.SSS1.p3.4.m4.1.1" xref="S3.SS2.SSS1.p3.4.m4.1.1.cmml"><msup id="S3.SS2.SSS1.p3.4.m4.1.1.2" xref="S3.SS2.SSS1.p3.4.m4.1.1.2.cmml"><mi id="S3.SS2.SSS1.p3.4.m4.1.1.2.2" xref="S3.SS2.SSS1.p3.4.m4.1.1.2.2.cmml">E</mi><mrow id="S3.SS2.SSS1.p3.4.m4.1.1.2.3" xref="S3.SS2.SSS1.p3.4.m4.1.1.2.3.cmml"><mi id="S3.SS2.SSS1.p3.4.m4.1.1.2.3.2" xref="S3.SS2.SSS1.p3.4.m4.1.1.2.3.2.cmml">u</mi><mo id="S3.SS2.SSS1.p3.4.m4.1.1.2.3.1" xref="S3.SS2.SSS1.p3.4.m4.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.4.m4.1.1.2.3.3" xref="S3.SS2.SSS1.p3.4.m4.1.1.2.3.3.cmml">s</mi><mo id="S3.SS2.SSS1.p3.4.m4.1.1.2.3.1a" xref="S3.SS2.SSS1.p3.4.m4.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.4.m4.1.1.2.3.4" xref="S3.SS2.SSS1.p3.4.m4.1.1.2.3.4.cmml">e</mi><mo id="S3.SS2.SSS1.p3.4.m4.1.1.2.3.1b" xref="S3.SS2.SSS1.p3.4.m4.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS1.p3.4.m4.1.1.2.3.5" xref="S3.SS2.SSS1.p3.4.m4.1.1.2.3.5.cmml">r</mi></mrow></msup><mo id="S3.SS2.SSS1.p3.4.m4.1.1.1" xref="S3.SS2.SSS1.p3.4.m4.1.1.1.cmml">∈</mo><msup id="S3.SS2.SSS1.p3.4.m4.1.1.3" xref="S3.SS2.SSS1.p3.4.m4.1.1.3.cmml"><mi id="S3.SS2.SSS1.p3.4.m4.1.1.3.2" xref="S3.SS2.SSS1.p3.4.m4.1.1.3.2.cmml">R</mi><mn id="S3.SS2.SSS1.p3.4.m4.1.1.3.3" xref="S3.SS2.SSS1.p3.4.m4.1.1.3.3.cmml">64</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p3.4.m4.1b"><apply id="S3.SS2.SSS1.p3.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1"><in id="S3.SS2.SSS1.p3.4.m4.1.1.1.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1.1"></in><apply id="S3.SS2.SSS1.p3.4.m4.1.1.2.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.4.m4.1.1.2.1.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1.2">superscript</csymbol><ci id="S3.SS2.SSS1.p3.4.m4.1.1.2.2.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1.2.2">𝐸</ci><apply id="S3.SS2.SSS1.p3.4.m4.1.1.2.3.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1.2.3"><times id="S3.SS2.SSS1.p3.4.m4.1.1.2.3.1.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1.2.3.1"></times><ci id="S3.SS2.SSS1.p3.4.m4.1.1.2.3.2.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1.2.3.2">𝑢</ci><ci id="S3.SS2.SSS1.p3.4.m4.1.1.2.3.3.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1.2.3.3">𝑠</ci><ci id="S3.SS2.SSS1.p3.4.m4.1.1.2.3.4.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1.2.3.4">𝑒</ci><ci id="S3.SS2.SSS1.p3.4.m4.1.1.2.3.5.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1.2.3.5">𝑟</ci></apply></apply><apply id="S3.SS2.SSS1.p3.4.m4.1.1.3.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p3.4.m4.1.1.3.1.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1.3">superscript</csymbol><ci id="S3.SS2.SSS1.p3.4.m4.1.1.3.2.cmml" xref="S3.SS2.SSS1.p3.4.m4.1.1.3.2">𝑅</ci><cn id="S3.SS2.SSS1.p3.4.m4.1.1.3.3.cmml" type="integer" xref="S3.SS2.SSS1.p3.4.m4.1.1.3.3">64</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p3.4.m4.1c">E^{user}\in R^{64}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS1.p3.4.m4.1d">italic_E start_POSTSUPERSCRIPT italic_u italic_s italic_e italic_r end_POSTSUPERSCRIPT ∈ italic_R start_POSTSUPERSCRIPT 64 end_POSTSUPERSCRIPT</annotation></semantics></math>, which are directly utilized in our online recommendation system (detailed in Sec.<a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.SS4" title="4.4. Ranking A/B Experiments ‣ 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">4.4</span></a>). These user embeddings are optimized towards the recommendation task, as outlined in Sec.<a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S3.SS2.SSS3" title="3.2.3. Training Target of Recommendation Domain ‣ 3.2. Model Architecture ‣ 3. Method ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">3.2.3</span></a>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2. </span>Item Tower</h4>
<div class="ltx_para" id="S3.SS2.SSS2.p1">
<p class="ltx_p" id="S3.SS2.SSS2.p1.1">The item tower processes textual descriptions of item content and outputs item embedding specifically tailored for the recommendation domain. As depicted in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S3.F3" title="Figure 3 ‣ 3.1. Content Embedding of LLM ‣ 3. Method ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">3</span></a>, we propose three model variants of the item tower.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.p2">
<p class="ltx_p" id="S3.SS2.SSS2.p2.2"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS2.p2.2.1">Variant 1.</span> As illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S3.F3" title="Figure 3 ‣ 3.1. Content Embedding of LLM ‣ 3. Method ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">3</span></a>(a), the item tower adopts the same architecture and model weights as the user tower. However, instead of processing user history interactions <math alttext="U^{hist}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.1.m1.1"><semantics id="S3.SS2.SSS2.p2.1.m1.1a"><msup id="S3.SS2.SSS2.p2.1.m1.1.1" xref="S3.SS2.SSS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.SSS2.p2.1.m1.1.1.2" xref="S3.SS2.SSS2.p2.1.m1.1.1.2.cmml">U</mi><mrow id="S3.SS2.SSS2.p2.1.m1.1.1.3" xref="S3.SS2.SSS2.p2.1.m1.1.1.3.cmml"><mi id="S3.SS2.SSS2.p2.1.m1.1.1.3.2" xref="S3.SS2.SSS2.p2.1.m1.1.1.3.2.cmml">h</mi><mo id="S3.SS2.SSS2.p2.1.m1.1.1.3.1" xref="S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS2.p2.1.m1.1.1.3.3" xref="S3.SS2.SSS2.p2.1.m1.1.1.3.3.cmml">i</mi><mo id="S3.SS2.SSS2.p2.1.m1.1.1.3.1a" xref="S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS2.p2.1.m1.1.1.3.4" xref="S3.SS2.SSS2.p2.1.m1.1.1.3.4.cmml">s</mi><mo id="S3.SS2.SSS2.p2.1.m1.1.1.3.1b" xref="S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS2.p2.1.m1.1.1.3.5" xref="S3.SS2.SSS2.p2.1.m1.1.1.3.5.cmml">t</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.1.m1.1b"><apply id="S3.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1.2">𝑈</ci><apply id="S3.SS2.SSS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1.3"><times id="S3.SS2.SSS2.p2.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1.3.1"></times><ci id="S3.SS2.SSS2.p2.1.m1.1.1.3.2.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1.3.2">ℎ</ci><ci id="S3.SS2.SSS2.p2.1.m1.1.1.3.3.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1.3.3">𝑖</ci><ci id="S3.SS2.SSS2.p2.1.m1.1.1.3.4.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1.3.4">𝑠</ci><ci id="S3.SS2.SSS2.p2.1.m1.1.1.3.5.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1.3.5">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.1.m1.1c">U^{hist}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.1.m1.1d">italic_U start_POSTSUPERSCRIPT italic_h italic_i italic_s italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>, the item tower utilizes user target interactions <math alttext="U^{tar}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p2.2.m2.1"><semantics id="S3.SS2.SSS2.p2.2.m2.1a"><msup id="S3.SS2.SSS2.p2.2.m2.1.1" xref="S3.SS2.SSS2.p2.2.m2.1.1.cmml"><mi id="S3.SS2.SSS2.p2.2.m2.1.1.2" xref="S3.SS2.SSS2.p2.2.m2.1.1.2.cmml">U</mi><mrow id="S3.SS2.SSS2.p2.2.m2.1.1.3" xref="S3.SS2.SSS2.p2.2.m2.1.1.3.cmml"><mi id="S3.SS2.SSS2.p2.2.m2.1.1.3.2" xref="S3.SS2.SSS2.p2.2.m2.1.1.3.2.cmml">t</mi><mo id="S3.SS2.SSS2.p2.2.m2.1.1.3.1" xref="S3.SS2.SSS2.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS2.p2.2.m2.1.1.3.3" xref="S3.SS2.SSS2.p2.2.m2.1.1.3.3.cmml">a</mi><mo id="S3.SS2.SSS2.p2.2.m2.1.1.3.1a" xref="S3.SS2.SSS2.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS2.p2.2.m2.1.1.3.4" xref="S3.SS2.SSS2.p2.2.m2.1.1.3.4.cmml">r</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.2.m2.1b"><apply id="S3.SS2.SSS2.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.2">𝑈</ci><apply id="S3.SS2.SSS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.3"><times id="S3.SS2.SSS2.p2.2.m2.1.1.3.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.3.1"></times><ci id="S3.SS2.SSS2.p2.2.m2.1.1.3.2.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.3.2">𝑡</ci><ci id="S3.SS2.SSS2.p2.2.m2.1.1.3.3.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.3.3">𝑎</ci><ci id="S3.SS2.SSS2.p2.2.m2.1.1.3.4.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.3.4">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.2.m2.1c">U^{tar}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p2.2.m2.1d">italic_U start_POSTSUPERSCRIPT italic_t italic_a italic_r end_POSTSUPERSCRIPT</annotation></semantics></math> as inputs. This approach enhances the alignment between user and item embeddings by employing the same causal attention mechanism used in the user tower, effectively improving the relevance of recommendations. Due to the superior performance in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.T4" title="Table 4 ‣ 4.3.4. Ablation studies of modules within the LEARN framework (RQ4) ‣ 4.3. Offline Results ‣ 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">4</span></a>, Variant 1 is adopted as the default setting.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.p3">
<p class="ltx_p" id="S3.SS2.SSS2.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS2.p3.1.1">Variant 2.</span> Contrasting with the causal attention mechanism used in Variant 1, this variant, depicted in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S3.F3" title="Figure 3 ‣ 3.1. Content Embedding of LLM ‣ 3. Method ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">3</span></a>(b), employs a self-attention mechanism where each item attends to its own content exclusively. This approach treats the content information of each item as an independent input. Although Variant 2 also achieves the projection from the content domain to the collaborative domain, its performance is not as well as Variant 1, which utilizes the causal attention mechanism.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.SSS2.p4">
<p class="ltx_p" id="S3.SS2.SSS2.p4.2"><span class="ltx_text ltx_font_bold" id="S3.SS2.SSS2.p4.2.1">Variant 3.</span> Both Variant 1 and Variant 2 are designed to project the content embeddings from the open-world domain of LLMs into the collaborative domain of the RS. In contrast, Variant 3 takes a distinct approach by directly using the content embedding <math alttext="E^{c}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p4.1.m1.1"><semantics id="S3.SS2.SSS2.p4.1.m1.1a"><msup id="S3.SS2.SSS2.p4.1.m1.1.1" xref="S3.SS2.SSS2.p4.1.m1.1.1.cmml"><mi id="S3.SS2.SSS2.p4.1.m1.1.1.2" xref="S3.SS2.SSS2.p4.1.m1.1.1.2.cmml">E</mi><mi id="S3.SS2.SSS2.p4.1.m1.1.1.3" xref="S3.SS2.SSS2.p4.1.m1.1.1.3.cmml">c</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.1.m1.1b"><apply id="S3.SS2.SSS2.p4.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p4.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.p4.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1.2">𝐸</ci><ci id="S3.SS2.SSS2.p4.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.1.m1.1c">E^{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p4.1.m1.1d">italic_E start_POSTSUPERSCRIPT italic_c end_POSTSUPERSCRIPT</annotation></semantics></math>, as the item embedding <math alttext="E^{item}" class="ltx_Math" display="inline" id="S3.SS2.SSS2.p4.2.m2.1"><semantics id="S3.SS2.SSS2.p4.2.m2.1a"><msup id="S3.SS2.SSS2.p4.2.m2.1.1" xref="S3.SS2.SSS2.p4.2.m2.1.1.cmml"><mi id="S3.SS2.SSS2.p4.2.m2.1.1.2" xref="S3.SS2.SSS2.p4.2.m2.1.1.2.cmml">E</mi><mrow id="S3.SS2.SSS2.p4.2.m2.1.1.3" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.cmml"><mi id="S3.SS2.SSS2.p4.2.m2.1.1.3.2" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.2.cmml">i</mi><mo id="S3.SS2.SSS2.p4.2.m2.1.1.3.1" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS2.p4.2.m2.1.1.3.3" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.3.cmml">t</mi><mo id="S3.SS2.SSS2.p4.2.m2.1.1.3.1a" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS2.p4.2.m2.1.1.3.4" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.4.cmml">e</mi><mo id="S3.SS2.SSS2.p4.2.m2.1.1.3.1b" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS2.p4.2.m2.1.1.3.5" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.5.cmml">m</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.2.m2.1b"><apply id="S3.SS2.SSS2.p4.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p4.2.m2.1.1.1.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1">superscript</csymbol><ci id="S3.SS2.SSS2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.2">𝐸</ci><apply id="S3.SS2.SSS2.p4.2.m2.1.1.3.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.3"><times id="S3.SS2.SSS2.p4.2.m2.1.1.3.1.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.1"></times><ci id="S3.SS2.SSS2.p4.2.m2.1.1.3.2.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.2">𝑖</ci><ci id="S3.SS2.SSS2.p4.2.m2.1.1.3.3.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.3">𝑡</ci><ci id="S3.SS2.SSS2.p4.2.m2.1.1.3.4.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.4">𝑒</ci><ci id="S3.SS2.SSS2.p4.2.m2.1.1.3.5.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.5">𝑚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.2.m2.1c">E^{item}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS2.p4.2.m2.1d">italic_E start_POSTSUPERSCRIPT italic_i italic_t italic_e italic_m end_POSTSUPERSCRIPT</annotation></semantics></math>, for the recommendation task, bypassing the alignment process.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS2.p5">
<p class="ltx_p" id="S3.SS2.SSS2.p5.1">In the training stage, Variant 1 takes the user target interaction sequence as input, while Variant 2 and Variant 3 take an individual item independently. In the inference stage, all variants only take text descriptions of one item as the input and output item embedding independently.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS2.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3. </span>Training Target of Recommendation Domain</h4>
<div class="ltx_para" id="S3.SS2.SSS3.p1">
<p class="ltx_p" id="S3.SS2.SSS3.p1.1">To bridge the gap between the content embedding in the open-world domain of LLM and user (item) embedding in the collaborative domain of RS, we adopt the recommendation task as the training target.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS3.p2">
<p class="ltx_p" id="S3.SS2.SSS3.p2.1">In the online RS, the ranking model computes similarities between the user embedding and embeddings of all items in the gallery. The top K items with the highest similarity scores are identified as those of interest to the user. To align with the goals of the online RS, we utilize the self-supervised contrastive learning mechanism to model user preferences. This approach is designed to maximize the similarity between the user embedding and the item embeddings of interest, while minimizing the similarities from other items.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS3.p3">
<p class="ltx_p" id="S3.SS2.SSS3.p3.3">We adopt the InfoNCE loss <cite class="ltx_cite ltx_citemacro_citep">(Oord et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib29" title="">2018</a>)</cite> to guide the LEARN framework training. The user embedding, <math alttext="E^{user}" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.1.m1.1"><semantics id="S3.SS2.SSS3.p3.1.m1.1a"><msup id="S3.SS2.SSS3.p3.1.m1.1.1" xref="S3.SS2.SSS3.p3.1.m1.1.1.cmml"><mi id="S3.SS2.SSS3.p3.1.m1.1.1.2" xref="S3.SS2.SSS3.p3.1.m1.1.1.2.cmml">E</mi><mrow id="S3.SS2.SSS3.p3.1.m1.1.1.3" xref="S3.SS2.SSS3.p3.1.m1.1.1.3.cmml"><mi id="S3.SS2.SSS3.p3.1.m1.1.1.3.2" xref="S3.SS2.SSS3.p3.1.m1.1.1.3.2.cmml">u</mi><mo id="S3.SS2.SSS3.p3.1.m1.1.1.3.1" xref="S3.SS2.SSS3.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p3.1.m1.1.1.3.3" xref="S3.SS2.SSS3.p3.1.m1.1.1.3.3.cmml">s</mi><mo id="S3.SS2.SSS3.p3.1.m1.1.1.3.1a" xref="S3.SS2.SSS3.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p3.1.m1.1.1.3.4" xref="S3.SS2.SSS3.p3.1.m1.1.1.3.4.cmml">e</mi><mo id="S3.SS2.SSS3.p3.1.m1.1.1.3.1b" xref="S3.SS2.SSS3.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p3.1.m1.1.1.3.5" xref="S3.SS2.SSS3.p3.1.m1.1.1.3.5.cmml">r</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.1.m1.1b"><apply id="S3.SS2.SSS3.p3.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p3.1.m1.1.1.1.cmml" xref="S3.SS2.SSS3.p3.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.SSS3.p3.1.m1.1.1.2.cmml" xref="S3.SS2.SSS3.p3.1.m1.1.1.2">𝐸</ci><apply id="S3.SS2.SSS3.p3.1.m1.1.1.3.cmml" xref="S3.SS2.SSS3.p3.1.m1.1.1.3"><times id="S3.SS2.SSS3.p3.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS3.p3.1.m1.1.1.3.1"></times><ci id="S3.SS2.SSS3.p3.1.m1.1.1.3.2.cmml" xref="S3.SS2.SSS3.p3.1.m1.1.1.3.2">𝑢</ci><ci id="S3.SS2.SSS3.p3.1.m1.1.1.3.3.cmml" xref="S3.SS2.SSS3.p3.1.m1.1.1.3.3">𝑠</ci><ci id="S3.SS2.SSS3.p3.1.m1.1.1.3.4.cmml" xref="S3.SS2.SSS3.p3.1.m1.1.1.3.4">𝑒</ci><ci id="S3.SS2.SSS3.p3.1.m1.1.1.3.5.cmml" xref="S3.SS2.SSS3.p3.1.m1.1.1.3.5">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.1.m1.1c">E^{user}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.1.m1.1d">italic_E start_POSTSUPERSCRIPT italic_u italic_s italic_e italic_r end_POSTSUPERSCRIPT</annotation></semantics></math>, is derived from embedding sequence <math alttext="\hat{U}^{hist}" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.2.m2.1"><semantics id="S3.SS2.SSS3.p3.2.m2.1a"><msup id="S3.SS2.SSS3.p3.2.m2.1.1" xref="S3.SS2.SSS3.p3.2.m2.1.1.cmml"><mover accent="true" id="S3.SS2.SSS3.p3.2.m2.1.1.2" xref="S3.SS2.SSS3.p3.2.m2.1.1.2.cmml"><mi id="S3.SS2.SSS3.p3.2.m2.1.1.2.2" xref="S3.SS2.SSS3.p3.2.m2.1.1.2.2.cmml">U</mi><mo id="S3.SS2.SSS3.p3.2.m2.1.1.2.1" xref="S3.SS2.SSS3.p3.2.m2.1.1.2.1.cmml">^</mo></mover><mrow id="S3.SS2.SSS3.p3.2.m2.1.1.3" xref="S3.SS2.SSS3.p3.2.m2.1.1.3.cmml"><mi id="S3.SS2.SSS3.p3.2.m2.1.1.3.2" xref="S3.SS2.SSS3.p3.2.m2.1.1.3.2.cmml">h</mi><mo id="S3.SS2.SSS3.p3.2.m2.1.1.3.1" xref="S3.SS2.SSS3.p3.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p3.2.m2.1.1.3.3" xref="S3.SS2.SSS3.p3.2.m2.1.1.3.3.cmml">i</mi><mo id="S3.SS2.SSS3.p3.2.m2.1.1.3.1a" xref="S3.SS2.SSS3.p3.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p3.2.m2.1.1.3.4" xref="S3.SS2.SSS3.p3.2.m2.1.1.3.4.cmml">s</mi><mo id="S3.SS2.SSS3.p3.2.m2.1.1.3.1b" xref="S3.SS2.SSS3.p3.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p3.2.m2.1.1.3.5" xref="S3.SS2.SSS3.p3.2.m2.1.1.3.5.cmml">t</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.2.m2.1b"><apply id="S3.SS2.SSS3.p3.2.m2.1.1.cmml" xref="S3.SS2.SSS3.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p3.2.m2.1.1.1.cmml" xref="S3.SS2.SSS3.p3.2.m2.1.1">superscript</csymbol><apply id="S3.SS2.SSS3.p3.2.m2.1.1.2.cmml" xref="S3.SS2.SSS3.p3.2.m2.1.1.2"><ci id="S3.SS2.SSS3.p3.2.m2.1.1.2.1.cmml" xref="S3.SS2.SSS3.p3.2.m2.1.1.2.1">^</ci><ci id="S3.SS2.SSS3.p3.2.m2.1.1.2.2.cmml" xref="S3.SS2.SSS3.p3.2.m2.1.1.2.2">𝑈</ci></apply><apply id="S3.SS2.SSS3.p3.2.m2.1.1.3.cmml" xref="S3.SS2.SSS3.p3.2.m2.1.1.3"><times id="S3.SS2.SSS3.p3.2.m2.1.1.3.1.cmml" xref="S3.SS2.SSS3.p3.2.m2.1.1.3.1"></times><ci id="S3.SS2.SSS3.p3.2.m2.1.1.3.2.cmml" xref="S3.SS2.SSS3.p3.2.m2.1.1.3.2">ℎ</ci><ci id="S3.SS2.SSS3.p3.2.m2.1.1.3.3.cmml" xref="S3.SS2.SSS3.p3.2.m2.1.1.3.3">𝑖</ci><ci id="S3.SS2.SSS3.p3.2.m2.1.1.3.4.cmml" xref="S3.SS2.SSS3.p3.2.m2.1.1.3.4">𝑠</ci><ci id="S3.SS2.SSS3.p3.2.m2.1.1.3.5.cmml" xref="S3.SS2.SSS3.p3.2.m2.1.1.3.5">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.2.m2.1c">\hat{U}^{hist}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.2.m2.1d">over^ start_ARG italic_U end_ARG start_POSTSUPERSCRIPT italic_h italic_i italic_s italic_t end_POSTSUPERSCRIPT</annotation></semantics></math> of user history interactions through the user tower, whereas the item embedding, <math alttext="E^{item}" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.3.m3.1"><semantics id="S3.SS2.SSS3.p3.3.m3.1a"><msup id="S3.SS2.SSS3.p3.3.m3.1.1" xref="S3.SS2.SSS3.p3.3.m3.1.1.cmml"><mi id="S3.SS2.SSS3.p3.3.m3.1.1.2" xref="S3.SS2.SSS3.p3.3.m3.1.1.2.cmml">E</mi><mrow id="S3.SS2.SSS3.p3.3.m3.1.1.3" xref="S3.SS2.SSS3.p3.3.m3.1.1.3.cmml"><mi id="S3.SS2.SSS3.p3.3.m3.1.1.3.2" xref="S3.SS2.SSS3.p3.3.m3.1.1.3.2.cmml">i</mi><mo id="S3.SS2.SSS3.p3.3.m3.1.1.3.1" xref="S3.SS2.SSS3.p3.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p3.3.m3.1.1.3.3" xref="S3.SS2.SSS3.p3.3.m3.1.1.3.3.cmml">t</mi><mo id="S3.SS2.SSS3.p3.3.m3.1.1.3.1a" xref="S3.SS2.SSS3.p3.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p3.3.m3.1.1.3.4" xref="S3.SS2.SSS3.p3.3.m3.1.1.3.4.cmml">e</mi><mo id="S3.SS2.SSS3.p3.3.m3.1.1.3.1b" xref="S3.SS2.SSS3.p3.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p3.3.m3.1.1.3.5" xref="S3.SS2.SSS3.p3.3.m3.1.1.3.5.cmml">m</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.3.m3.1b"><apply id="S3.SS2.SSS3.p3.3.m3.1.1.cmml" xref="S3.SS2.SSS3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p3.3.m3.1.1.1.cmml" xref="S3.SS2.SSS3.p3.3.m3.1.1">superscript</csymbol><ci id="S3.SS2.SSS3.p3.3.m3.1.1.2.cmml" xref="S3.SS2.SSS3.p3.3.m3.1.1.2">𝐸</ci><apply id="S3.SS2.SSS3.p3.3.m3.1.1.3.cmml" xref="S3.SS2.SSS3.p3.3.m3.1.1.3"><times id="S3.SS2.SSS3.p3.3.m3.1.1.3.1.cmml" xref="S3.SS2.SSS3.p3.3.m3.1.1.3.1"></times><ci id="S3.SS2.SSS3.p3.3.m3.1.1.3.2.cmml" xref="S3.SS2.SSS3.p3.3.m3.1.1.3.2">𝑖</ci><ci id="S3.SS2.SSS3.p3.3.m3.1.1.3.3.cmml" xref="S3.SS2.SSS3.p3.3.m3.1.1.3.3">𝑡</ci><ci id="S3.SS2.SSS3.p3.3.m3.1.1.3.4.cmml" xref="S3.SS2.SSS3.p3.3.m3.1.1.3.4">𝑒</ci><ci id="S3.SS2.SSS3.p3.3.m3.1.1.3.5.cmml" xref="S3.SS2.SSS3.p3.3.m3.1.1.3.5">𝑚</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.3.m3.1c">E^{item}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.3.m3.1d">italic_E start_POSTSUPERSCRIPT italic_i italic_t italic_e italic_m end_POSTSUPERSCRIPT</annotation></semantics></math>, is obtained from user target interactions through the item tower. Positive sample pairs consist of the user embedding and the item embedding from the same user’s target interactions, whereas negative pairs comprise the user embedding and item embeddings from different users. The loss function is formulated as follows:</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="S5.EGx1">
<tbody id="S3.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\mathcal{L}=-\sum_{i=1}^{N_{u}}\sum_{j=1}^{H}\sum_{k=1}^{T}\log%
\frac{e^{s(E^{user}_{i,j},E^{item}_{i,k})}}{e^{s(E^{user}_{i,j},E^{item}_{i,k}%
)}+\sum_{z\neq i}\sum_{k}e^{s(E^{user}_{i,j},E^{item}_{z,k})}}," class="ltx_Math" display="inline" id="S3.E1.m1.19"><semantics id="S3.E1.m1.19a"><mrow id="S3.E1.m1.19.19.1" xref="S3.E1.m1.19.19.1.1.cmml"><mrow id="S3.E1.m1.19.19.1.1" xref="S3.E1.m1.19.19.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.19.19.1.1.2" xref="S3.E1.m1.19.19.1.1.2.cmml">ℒ</mi><mo id="S3.E1.m1.19.19.1.1.1" xref="S3.E1.m1.19.19.1.1.1.cmml">=</mo><mrow id="S3.E1.m1.19.19.1.1.3" xref="S3.E1.m1.19.19.1.1.3.cmml"><mo id="S3.E1.m1.19.19.1.1.3a" xref="S3.E1.m1.19.19.1.1.3.cmml">−</mo><mrow id="S3.E1.m1.19.19.1.1.3.2" xref="S3.E1.m1.19.19.1.1.3.2.cmml"><mstyle displaystyle="true" id="S3.E1.m1.19.19.1.1.3.2.1" xref="S3.E1.m1.19.19.1.1.3.2.1.cmml"><munderover id="S3.E1.m1.19.19.1.1.3.2.1a" xref="S3.E1.m1.19.19.1.1.3.2.1.cmml"><mo id="S3.E1.m1.19.19.1.1.3.2.1.2.2" movablelimits="false" xref="S3.E1.m1.19.19.1.1.3.2.1.2.2.cmml">∑</mo><mrow id="S3.E1.m1.19.19.1.1.3.2.1.2.3" xref="S3.E1.m1.19.19.1.1.3.2.1.2.3.cmml"><mi id="S3.E1.m1.19.19.1.1.3.2.1.2.3.2" xref="S3.E1.m1.19.19.1.1.3.2.1.2.3.2.cmml">i</mi><mo id="S3.E1.m1.19.19.1.1.3.2.1.2.3.1" xref="S3.E1.m1.19.19.1.1.3.2.1.2.3.1.cmml">=</mo><mn id="S3.E1.m1.19.19.1.1.3.2.1.2.3.3" xref="S3.E1.m1.19.19.1.1.3.2.1.2.3.3.cmml">1</mn></mrow><msub id="S3.E1.m1.19.19.1.1.3.2.1.3" xref="S3.E1.m1.19.19.1.1.3.2.1.3.cmml"><mi id="S3.E1.m1.19.19.1.1.3.2.1.3.2" xref="S3.E1.m1.19.19.1.1.3.2.1.3.2.cmml">N</mi><mi id="S3.E1.m1.19.19.1.1.3.2.1.3.3" xref="S3.E1.m1.19.19.1.1.3.2.1.3.3.cmml">u</mi></msub></munderover></mstyle><mrow id="S3.E1.m1.19.19.1.1.3.2.2" xref="S3.E1.m1.19.19.1.1.3.2.2.cmml"><mstyle displaystyle="true" id="S3.E1.m1.19.19.1.1.3.2.2.1" xref="S3.E1.m1.19.19.1.1.3.2.2.1.cmml"><munderover id="S3.E1.m1.19.19.1.1.3.2.2.1a" xref="S3.E1.m1.19.19.1.1.3.2.2.1.cmml"><mo id="S3.E1.m1.19.19.1.1.3.2.2.1.2.2" movablelimits="false" xref="S3.E1.m1.19.19.1.1.3.2.2.1.2.2.cmml">∑</mo><mrow id="S3.E1.m1.19.19.1.1.3.2.2.1.2.3" xref="S3.E1.m1.19.19.1.1.3.2.2.1.2.3.cmml"><mi id="S3.E1.m1.19.19.1.1.3.2.2.1.2.3.2" xref="S3.E1.m1.19.19.1.1.3.2.2.1.2.3.2.cmml">j</mi><mo id="S3.E1.m1.19.19.1.1.3.2.2.1.2.3.1" xref="S3.E1.m1.19.19.1.1.3.2.2.1.2.3.1.cmml">=</mo><mn id="S3.E1.m1.19.19.1.1.3.2.2.1.2.3.3" xref="S3.E1.m1.19.19.1.1.3.2.2.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.19.19.1.1.3.2.2.1.3" xref="S3.E1.m1.19.19.1.1.3.2.2.1.3.cmml">H</mi></munderover></mstyle><mrow id="S3.E1.m1.19.19.1.1.3.2.2.2" xref="S3.E1.m1.19.19.1.1.3.2.2.2.cmml"><mstyle displaystyle="true" id="S3.E1.m1.19.19.1.1.3.2.2.2.1" xref="S3.E1.m1.19.19.1.1.3.2.2.2.1.cmml"><munderover id="S3.E1.m1.19.19.1.1.3.2.2.2.1a" xref="S3.E1.m1.19.19.1.1.3.2.2.2.1.cmml"><mo id="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.2" movablelimits="false" xref="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.2.cmml">∑</mo><mrow id="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.3" xref="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.3.cmml"><mi id="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.3.2" xref="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.3.2.cmml">k</mi><mo id="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.3.1" xref="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.3.1.cmml">=</mo><mn id="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.3.3" xref="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.19.19.1.1.3.2.2.2.1.3" xref="S3.E1.m1.19.19.1.1.3.2.2.2.1.3.cmml">T</mi></munderover></mstyle><mrow id="S3.E1.m1.19.19.1.1.3.2.2.2.2" xref="S3.E1.m1.19.19.1.1.3.2.2.2.2.cmml"><mi id="S3.E1.m1.19.19.1.1.3.2.2.2.2.1" xref="S3.E1.m1.19.19.1.1.3.2.2.2.2.1.cmml">log</mi><mo id="S3.E1.m1.19.19.1.1.3.2.2.2.2a" lspace="0.167em" xref="S3.E1.m1.19.19.1.1.3.2.2.2.2.cmml">⁡</mo><mstyle displaystyle="true" id="S3.E1.m1.18.18" xref="S3.E1.m1.18.18.cmml"><mfrac id="S3.E1.m1.18.18a" xref="S3.E1.m1.18.18.cmml"><msup id="S3.E1.m1.6.6.6" xref="S3.E1.m1.6.6.6.cmml"><mi id="S3.E1.m1.6.6.6.8" xref="S3.E1.m1.6.6.6.8.cmml">e</mi><mrow id="S3.E1.m1.6.6.6.6.6" xref="S3.E1.m1.6.6.6.6.6.cmml"><mi id="S3.E1.m1.6.6.6.6.6.8" xref="S3.E1.m1.6.6.6.6.6.8.cmml">s</mi><mo id="S3.E1.m1.6.6.6.6.6.7" xref="S3.E1.m1.6.6.6.6.6.7.cmml">⁢</mo><mrow id="S3.E1.m1.6.6.6.6.6.6.2" xref="S3.E1.m1.6.6.6.6.6.6.3.cmml"><mo id="S3.E1.m1.6.6.6.6.6.6.2.3" stretchy="false" xref="S3.E1.m1.6.6.6.6.6.6.3.cmml">(</mo><msubsup id="S3.E1.m1.5.5.5.5.5.5.1.1" xref="S3.E1.m1.5.5.5.5.5.5.1.1.cmml"><mi id="S3.E1.m1.5.5.5.5.5.5.1.1.2.2" xref="S3.E1.m1.5.5.5.5.5.5.1.1.2.2.cmml">E</mi><mrow id="S3.E1.m1.2.2.2.2.2.2.2.4" xref="S3.E1.m1.2.2.2.2.2.2.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml">i</mi><mo id="S3.E1.m1.2.2.2.2.2.2.2.4.1" xref="S3.E1.m1.2.2.2.2.2.2.2.3.cmml">,</mo><mi id="S3.E1.m1.2.2.2.2.2.2.2.2" xref="S3.E1.m1.2.2.2.2.2.2.2.2.cmml">j</mi></mrow><mrow id="S3.E1.m1.5.5.5.5.5.5.1.1.2.3" xref="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.cmml"><mi id="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.2" xref="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.2.cmml">u</mi><mo id="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.1" xref="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.3" xref="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.3.cmml">s</mi><mo id="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.1a" xref="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.4" xref="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.4.cmml">e</mi><mo id="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.1b" xref="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.5" xref="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.5.cmml">r</mi></mrow></msubsup><mo id="S3.E1.m1.6.6.6.6.6.6.2.4" xref="S3.E1.m1.6.6.6.6.6.6.3.cmml">,</mo><msubsup id="S3.E1.m1.6.6.6.6.6.6.2.2" xref="S3.E1.m1.6.6.6.6.6.6.2.2.cmml"><mi id="S3.E1.m1.6.6.6.6.6.6.2.2.2.2" xref="S3.E1.m1.6.6.6.6.6.6.2.2.2.2.cmml">E</mi><mrow id="S3.E1.m1.4.4.4.4.4.4.2.4" xref="S3.E1.m1.4.4.4.4.4.4.2.3.cmml"><mi id="S3.E1.m1.3.3.3.3.3.3.1.1" xref="S3.E1.m1.3.3.3.3.3.3.1.1.cmml">i</mi><mo id="S3.E1.m1.4.4.4.4.4.4.2.4.1" xref="S3.E1.m1.4.4.4.4.4.4.2.3.cmml">,</mo><mi id="S3.E1.m1.4.4.4.4.4.4.2.2" xref="S3.E1.m1.4.4.4.4.4.4.2.2.cmml">k</mi></mrow><mrow id="S3.E1.m1.6.6.6.6.6.6.2.2.2.3" xref="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.cmml"><mi id="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.2" xref="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.2.cmml">i</mi><mo id="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.1" xref="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.3" xref="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.3.cmml">t</mi><mo id="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.1a" xref="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.4" xref="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.4.cmml">e</mi><mo id="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.1b" xref="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.5" xref="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.5.cmml">m</mi></mrow></msubsup><mo id="S3.E1.m1.6.6.6.6.6.6.2.5" stretchy="false" xref="S3.E1.m1.6.6.6.6.6.6.3.cmml">)</mo></mrow></mrow></msup><mrow id="S3.E1.m1.18.18.18" xref="S3.E1.m1.18.18.18.cmml"><msup id="S3.E1.m1.18.18.18.14" xref="S3.E1.m1.18.18.18.14.cmml"><mi id="S3.E1.m1.18.18.18.14.2" xref="S3.E1.m1.18.18.18.14.2.cmml">e</mi><mrow id="S3.E1.m1.12.12.12.6.6" xref="S3.E1.m1.12.12.12.6.6.cmml"><mi id="S3.E1.m1.12.12.12.6.6.8" xref="S3.E1.m1.12.12.12.6.6.8.cmml">s</mi><mo id="S3.E1.m1.12.12.12.6.6.7" xref="S3.E1.m1.12.12.12.6.6.7.cmml">⁢</mo><mrow id="S3.E1.m1.12.12.12.6.6.6.2" xref="S3.E1.m1.12.12.12.6.6.6.3.cmml"><mo id="S3.E1.m1.12.12.12.6.6.6.2.3" stretchy="false" xref="S3.E1.m1.12.12.12.6.6.6.3.cmml">(</mo><msubsup id="S3.E1.m1.11.11.11.5.5.5.1.1" xref="S3.E1.m1.11.11.11.5.5.5.1.1.cmml"><mi id="S3.E1.m1.11.11.11.5.5.5.1.1.2.2" xref="S3.E1.m1.11.11.11.5.5.5.1.1.2.2.cmml">E</mi><mrow id="S3.E1.m1.8.8.8.2.2.2.2.4" xref="S3.E1.m1.8.8.8.2.2.2.2.3.cmml"><mi id="S3.E1.m1.7.7.7.1.1.1.1.1" xref="S3.E1.m1.7.7.7.1.1.1.1.1.cmml">i</mi><mo id="S3.E1.m1.8.8.8.2.2.2.2.4.1" xref="S3.E1.m1.8.8.8.2.2.2.2.3.cmml">,</mo><mi id="S3.E1.m1.8.8.8.2.2.2.2.2" xref="S3.E1.m1.8.8.8.2.2.2.2.2.cmml">j</mi></mrow><mrow id="S3.E1.m1.11.11.11.5.5.5.1.1.2.3" xref="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.cmml"><mi id="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.2" xref="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.2.cmml">u</mi><mo id="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.1" xref="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.3" xref="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.3.cmml">s</mi><mo id="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.1a" xref="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.4" xref="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.4.cmml">e</mi><mo id="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.1b" xref="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.5" xref="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.5.cmml">r</mi></mrow></msubsup><mo id="S3.E1.m1.12.12.12.6.6.6.2.4" xref="S3.E1.m1.12.12.12.6.6.6.3.cmml">,</mo><msubsup id="S3.E1.m1.12.12.12.6.6.6.2.2" xref="S3.E1.m1.12.12.12.6.6.6.2.2.cmml"><mi id="S3.E1.m1.12.12.12.6.6.6.2.2.2.2" xref="S3.E1.m1.12.12.12.6.6.6.2.2.2.2.cmml">E</mi><mrow id="S3.E1.m1.10.10.10.4.4.4.2.4" xref="S3.E1.m1.10.10.10.4.4.4.2.3.cmml"><mi id="S3.E1.m1.9.9.9.3.3.3.1.1" xref="S3.E1.m1.9.9.9.3.3.3.1.1.cmml">i</mi><mo id="S3.E1.m1.10.10.10.4.4.4.2.4.1" xref="S3.E1.m1.10.10.10.4.4.4.2.3.cmml">,</mo><mi id="S3.E1.m1.10.10.10.4.4.4.2.2" xref="S3.E1.m1.10.10.10.4.4.4.2.2.cmml">k</mi></mrow><mrow id="S3.E1.m1.12.12.12.6.6.6.2.2.2.3" xref="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.cmml"><mi id="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.2" xref="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.2.cmml">i</mi><mo id="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.1" xref="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.3" xref="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.3.cmml">t</mi><mo id="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.1a" xref="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.4" xref="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.4.cmml">e</mi><mo id="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.1b" xref="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.5" xref="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.5.cmml">m</mi></mrow></msubsup><mo id="S3.E1.m1.12.12.12.6.6.6.2.5" stretchy="false" xref="S3.E1.m1.12.12.12.6.6.6.3.cmml">)</mo></mrow></mrow></msup><mo id="S3.E1.m1.18.18.18.13" rspace="0.055em" xref="S3.E1.m1.18.18.18.13.cmml">+</mo><mrow id="S3.E1.m1.18.18.18.15" xref="S3.E1.m1.18.18.18.15.cmml"><msub id="S3.E1.m1.18.18.18.15.1" xref="S3.E1.m1.18.18.18.15.1.cmml"><mo id="S3.E1.m1.18.18.18.15.1.2" rspace="0em" xref="S3.E1.m1.18.18.18.15.1.2.cmml">∑</mo><mrow id="S3.E1.m1.18.18.18.15.1.3" xref="S3.E1.m1.18.18.18.15.1.3.cmml"><mi id="S3.E1.m1.18.18.18.15.1.3.2" xref="S3.E1.m1.18.18.18.15.1.3.2.cmml">z</mi><mo id="S3.E1.m1.18.18.18.15.1.3.1" xref="S3.E1.m1.18.18.18.15.1.3.1.cmml">≠</mo><mi id="S3.E1.m1.18.18.18.15.1.3.3" xref="S3.E1.m1.18.18.18.15.1.3.3.cmml">i</mi></mrow></msub><mrow id="S3.E1.m1.18.18.18.15.2" xref="S3.E1.m1.18.18.18.15.2.cmml"><msub id="S3.E1.m1.18.18.18.15.2.1" xref="S3.E1.m1.18.18.18.15.2.1.cmml"><mo id="S3.E1.m1.18.18.18.15.2.1.2" xref="S3.E1.m1.18.18.18.15.2.1.2.cmml">∑</mo><mi id="S3.E1.m1.18.18.18.15.2.1.3" xref="S3.E1.m1.18.18.18.15.2.1.3.cmml">k</mi></msub><msup id="S3.E1.m1.18.18.18.15.2.2" xref="S3.E1.m1.18.18.18.15.2.2.cmml"><mi id="S3.E1.m1.18.18.18.15.2.2.2" xref="S3.E1.m1.18.18.18.15.2.2.2.cmml">e</mi><mrow id="S3.E1.m1.18.18.18.12.6" xref="S3.E1.m1.18.18.18.12.6.cmml"><mi id="S3.E1.m1.18.18.18.12.6.8" xref="S3.E1.m1.18.18.18.12.6.8.cmml">s</mi><mo id="S3.E1.m1.18.18.18.12.6.7" xref="S3.E1.m1.18.18.18.12.6.7.cmml">⁢</mo><mrow id="S3.E1.m1.18.18.18.12.6.6.2" xref="S3.E1.m1.18.18.18.12.6.6.3.cmml"><mo id="S3.E1.m1.18.18.18.12.6.6.2.3" stretchy="false" xref="S3.E1.m1.18.18.18.12.6.6.3.cmml">(</mo><msubsup id="S3.E1.m1.17.17.17.11.5.5.1.1" xref="S3.E1.m1.17.17.17.11.5.5.1.1.cmml"><mi id="S3.E1.m1.17.17.17.11.5.5.1.1.2.2" xref="S3.E1.m1.17.17.17.11.5.5.1.1.2.2.cmml">E</mi><mrow id="S3.E1.m1.14.14.14.8.2.2.2.4" xref="S3.E1.m1.14.14.14.8.2.2.2.3.cmml"><mi id="S3.E1.m1.13.13.13.7.1.1.1.1" xref="S3.E1.m1.13.13.13.7.1.1.1.1.cmml">i</mi><mo id="S3.E1.m1.14.14.14.8.2.2.2.4.1" xref="S3.E1.m1.14.14.14.8.2.2.2.3.cmml">,</mo><mi id="S3.E1.m1.14.14.14.8.2.2.2.2" xref="S3.E1.m1.14.14.14.8.2.2.2.2.cmml">j</mi></mrow><mrow id="S3.E1.m1.17.17.17.11.5.5.1.1.2.3" xref="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.cmml"><mi id="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.2" xref="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.2.cmml">u</mi><mo id="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.1" xref="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.3" xref="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.3.cmml">s</mi><mo id="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.1a" xref="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.4" xref="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.4.cmml">e</mi><mo id="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.1b" xref="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.5" xref="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.5.cmml">r</mi></mrow></msubsup><mo id="S3.E1.m1.18.18.18.12.6.6.2.4" xref="S3.E1.m1.18.18.18.12.6.6.3.cmml">,</mo><msubsup id="S3.E1.m1.18.18.18.12.6.6.2.2" xref="S3.E1.m1.18.18.18.12.6.6.2.2.cmml"><mi id="S3.E1.m1.18.18.18.12.6.6.2.2.2.2" xref="S3.E1.m1.18.18.18.12.6.6.2.2.2.2.cmml">E</mi><mrow id="S3.E1.m1.16.16.16.10.4.4.2.4" xref="S3.E1.m1.16.16.16.10.4.4.2.3.cmml"><mi id="S3.E1.m1.15.15.15.9.3.3.1.1" xref="S3.E1.m1.15.15.15.9.3.3.1.1.cmml">z</mi><mo id="S3.E1.m1.16.16.16.10.4.4.2.4.1" xref="S3.E1.m1.16.16.16.10.4.4.2.3.cmml">,</mo><mi id="S3.E1.m1.16.16.16.10.4.4.2.2" xref="S3.E1.m1.16.16.16.10.4.4.2.2.cmml">k</mi></mrow><mrow id="S3.E1.m1.18.18.18.12.6.6.2.2.2.3" xref="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.cmml"><mi id="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.2" xref="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.2.cmml">i</mi><mo id="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.1" xref="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.3" xref="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.3.cmml">t</mi><mo id="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.1a" xref="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.4" xref="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.4.cmml">e</mi><mo id="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.1b" xref="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.1.cmml">⁢</mo><mi id="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.5" xref="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.5.cmml">m</mi></mrow></msubsup><mo id="S3.E1.m1.18.18.18.12.6.6.2.5" stretchy="false" xref="S3.E1.m1.18.18.18.12.6.6.3.cmml">)</mo></mrow></mrow></msup></mrow></mrow></mrow></mfrac></mstyle></mrow></mrow></mrow></mrow></mrow></mrow><mo id="S3.E1.m1.19.19.1.2" xref="S3.E1.m1.19.19.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.19b"><apply id="S3.E1.m1.19.19.1.1.cmml" xref="S3.E1.m1.19.19.1"><eq id="S3.E1.m1.19.19.1.1.1.cmml" xref="S3.E1.m1.19.19.1.1.1"></eq><ci id="S3.E1.m1.19.19.1.1.2.cmml" xref="S3.E1.m1.19.19.1.1.2">ℒ</ci><apply id="S3.E1.m1.19.19.1.1.3.cmml" xref="S3.E1.m1.19.19.1.1.3"><minus id="S3.E1.m1.19.19.1.1.3.1.cmml" xref="S3.E1.m1.19.19.1.1.3"></minus><apply id="S3.E1.m1.19.19.1.1.3.2.cmml" xref="S3.E1.m1.19.19.1.1.3.2"><apply id="S3.E1.m1.19.19.1.1.3.2.1.cmml" xref="S3.E1.m1.19.19.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.19.19.1.1.3.2.1.1.cmml" xref="S3.E1.m1.19.19.1.1.3.2.1">superscript</csymbol><apply id="S3.E1.m1.19.19.1.1.3.2.1.2.cmml" xref="S3.E1.m1.19.19.1.1.3.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.19.19.1.1.3.2.1.2.1.cmml" xref="S3.E1.m1.19.19.1.1.3.2.1">subscript</csymbol><sum id="S3.E1.m1.19.19.1.1.3.2.1.2.2.cmml" xref="S3.E1.m1.19.19.1.1.3.2.1.2.2"></sum><apply id="S3.E1.m1.19.19.1.1.3.2.1.2.3.cmml" xref="S3.E1.m1.19.19.1.1.3.2.1.2.3"><eq id="S3.E1.m1.19.19.1.1.3.2.1.2.3.1.cmml" xref="S3.E1.m1.19.19.1.1.3.2.1.2.3.1"></eq><ci id="S3.E1.m1.19.19.1.1.3.2.1.2.3.2.cmml" xref="S3.E1.m1.19.19.1.1.3.2.1.2.3.2">𝑖</ci><cn id="S3.E1.m1.19.19.1.1.3.2.1.2.3.3.cmml" type="integer" xref="S3.E1.m1.19.19.1.1.3.2.1.2.3.3">1</cn></apply></apply><apply id="S3.E1.m1.19.19.1.1.3.2.1.3.cmml" xref="S3.E1.m1.19.19.1.1.3.2.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.19.19.1.1.3.2.1.3.1.cmml" xref="S3.E1.m1.19.19.1.1.3.2.1.3">subscript</csymbol><ci id="S3.E1.m1.19.19.1.1.3.2.1.3.2.cmml" xref="S3.E1.m1.19.19.1.1.3.2.1.3.2">𝑁</ci><ci id="S3.E1.m1.19.19.1.1.3.2.1.3.3.cmml" xref="S3.E1.m1.19.19.1.1.3.2.1.3.3">𝑢</ci></apply></apply><apply id="S3.E1.m1.19.19.1.1.3.2.2.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2"><apply id="S3.E1.m1.19.19.1.1.3.2.2.1.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.19.19.1.1.3.2.2.1.1.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2.1">superscript</csymbol><apply id="S3.E1.m1.19.19.1.1.3.2.2.1.2.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.19.19.1.1.3.2.2.1.2.1.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2.1">subscript</csymbol><sum id="S3.E1.m1.19.19.1.1.3.2.2.1.2.2.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2.1.2.2"></sum><apply id="S3.E1.m1.19.19.1.1.3.2.2.1.2.3.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2.1.2.3"><eq id="S3.E1.m1.19.19.1.1.3.2.2.1.2.3.1.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2.1.2.3.1"></eq><ci id="S3.E1.m1.19.19.1.1.3.2.2.1.2.3.2.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2.1.2.3.2">𝑗</ci><cn id="S3.E1.m1.19.19.1.1.3.2.2.1.2.3.3.cmml" type="integer" xref="S3.E1.m1.19.19.1.1.3.2.2.1.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.19.19.1.1.3.2.2.1.3.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2.1.3">𝐻</ci></apply><apply id="S3.E1.m1.19.19.1.1.3.2.2.2.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2.2"><apply id="S3.E1.m1.19.19.1.1.3.2.2.2.1.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.19.19.1.1.3.2.2.2.1.1.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2.2.1">superscript</csymbol><apply id="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.1.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2.2.1">subscript</csymbol><sum id="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.2.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.2"></sum><apply id="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.3.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.3"><eq id="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.3.1.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.3.1"></eq><ci id="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.3.2.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.3.2">𝑘</ci><cn id="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.3.3.cmml" type="integer" xref="S3.E1.m1.19.19.1.1.3.2.2.2.1.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.19.19.1.1.3.2.2.2.1.3.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2.2.1.3">𝑇</ci></apply><apply id="S3.E1.m1.19.19.1.1.3.2.2.2.2.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2.2.2"><log id="S3.E1.m1.19.19.1.1.3.2.2.2.2.1.cmml" xref="S3.E1.m1.19.19.1.1.3.2.2.2.2.1"></log><apply id="S3.E1.m1.18.18.cmml" xref="S3.E1.m1.18.18"><divide id="S3.E1.m1.18.18.19.cmml" xref="S3.E1.m1.18.18"></divide><apply id="S3.E1.m1.6.6.6.cmml" xref="S3.E1.m1.6.6.6"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.6.7.cmml" xref="S3.E1.m1.6.6.6">superscript</csymbol><ci id="S3.E1.m1.6.6.6.8.cmml" xref="S3.E1.m1.6.6.6.8">𝑒</ci><apply id="S3.E1.m1.6.6.6.6.6.cmml" xref="S3.E1.m1.6.6.6.6.6"><times id="S3.E1.m1.6.6.6.6.6.7.cmml" xref="S3.E1.m1.6.6.6.6.6.7"></times><ci id="S3.E1.m1.6.6.6.6.6.8.cmml" xref="S3.E1.m1.6.6.6.6.6.8">𝑠</ci><interval closure="open" id="S3.E1.m1.6.6.6.6.6.6.3.cmml" xref="S3.E1.m1.6.6.6.6.6.6.2"><apply id="S3.E1.m1.5.5.5.5.5.5.1.1.cmml" xref="S3.E1.m1.5.5.5.5.5.5.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.5.5.5.5.1.1.1.cmml" xref="S3.E1.m1.5.5.5.5.5.5.1.1">subscript</csymbol><apply id="S3.E1.m1.5.5.5.5.5.5.1.1.2.cmml" xref="S3.E1.m1.5.5.5.5.5.5.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.5.5.5.5.5.5.1.1.2.1.cmml" xref="S3.E1.m1.5.5.5.5.5.5.1.1">superscript</csymbol><ci id="S3.E1.m1.5.5.5.5.5.5.1.1.2.2.cmml" xref="S3.E1.m1.5.5.5.5.5.5.1.1.2.2">𝐸</ci><apply id="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.cmml" xref="S3.E1.m1.5.5.5.5.5.5.1.1.2.3"><times id="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.1.cmml" xref="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.1"></times><ci id="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.2.cmml" xref="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.2">𝑢</ci><ci id="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.3.cmml" xref="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.3">𝑠</ci><ci id="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.4.cmml" xref="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.4">𝑒</ci><ci id="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.5.cmml" xref="S3.E1.m1.5.5.5.5.5.5.1.1.2.3.5">𝑟</ci></apply></apply><list id="S3.E1.m1.2.2.2.2.2.2.2.3.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.4"><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1">𝑖</ci><ci id="S3.E1.m1.2.2.2.2.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2.2.2.2.2">𝑗</ci></list></apply><apply id="S3.E1.m1.6.6.6.6.6.6.2.2.cmml" xref="S3.E1.m1.6.6.6.6.6.6.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.6.6.6.6.2.2.1.cmml" xref="S3.E1.m1.6.6.6.6.6.6.2.2">subscript</csymbol><apply id="S3.E1.m1.6.6.6.6.6.6.2.2.2.cmml" xref="S3.E1.m1.6.6.6.6.6.6.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.6.6.6.6.6.6.2.2.2.1.cmml" xref="S3.E1.m1.6.6.6.6.6.6.2.2">superscript</csymbol><ci id="S3.E1.m1.6.6.6.6.6.6.2.2.2.2.cmml" xref="S3.E1.m1.6.6.6.6.6.6.2.2.2.2">𝐸</ci><apply id="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.cmml" xref="S3.E1.m1.6.6.6.6.6.6.2.2.2.3"><times id="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.1.cmml" xref="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.1"></times><ci id="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.2.cmml" xref="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.2">𝑖</ci><ci id="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.3.cmml" xref="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.3">𝑡</ci><ci id="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.4.cmml" xref="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.4">𝑒</ci><ci id="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.5.cmml" xref="S3.E1.m1.6.6.6.6.6.6.2.2.2.3.5">𝑚</ci></apply></apply><list id="S3.E1.m1.4.4.4.4.4.4.2.3.cmml" xref="S3.E1.m1.4.4.4.4.4.4.2.4"><ci id="S3.E1.m1.3.3.3.3.3.3.1.1.cmml" xref="S3.E1.m1.3.3.3.3.3.3.1.1">𝑖</ci><ci id="S3.E1.m1.4.4.4.4.4.4.2.2.cmml" xref="S3.E1.m1.4.4.4.4.4.4.2.2">𝑘</ci></list></apply></interval></apply></apply><apply id="S3.E1.m1.18.18.18.cmml" xref="S3.E1.m1.18.18.18"><plus id="S3.E1.m1.18.18.18.13.cmml" xref="S3.E1.m1.18.18.18.13"></plus><apply id="S3.E1.m1.18.18.18.14.cmml" xref="S3.E1.m1.18.18.18.14"><csymbol cd="ambiguous" id="S3.E1.m1.18.18.18.14.1.cmml" xref="S3.E1.m1.18.18.18.14">superscript</csymbol><ci id="S3.E1.m1.18.18.18.14.2.cmml" xref="S3.E1.m1.18.18.18.14.2">𝑒</ci><apply id="S3.E1.m1.12.12.12.6.6.cmml" xref="S3.E1.m1.12.12.12.6.6"><times id="S3.E1.m1.12.12.12.6.6.7.cmml" xref="S3.E1.m1.12.12.12.6.6.7"></times><ci id="S3.E1.m1.12.12.12.6.6.8.cmml" xref="S3.E1.m1.12.12.12.6.6.8">𝑠</ci><interval closure="open" id="S3.E1.m1.12.12.12.6.6.6.3.cmml" xref="S3.E1.m1.12.12.12.6.6.6.2"><apply id="S3.E1.m1.11.11.11.5.5.5.1.1.cmml" xref="S3.E1.m1.11.11.11.5.5.5.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.11.11.11.5.5.5.1.1.1.cmml" xref="S3.E1.m1.11.11.11.5.5.5.1.1">subscript</csymbol><apply id="S3.E1.m1.11.11.11.5.5.5.1.1.2.cmml" xref="S3.E1.m1.11.11.11.5.5.5.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.11.11.11.5.5.5.1.1.2.1.cmml" xref="S3.E1.m1.11.11.11.5.5.5.1.1">superscript</csymbol><ci id="S3.E1.m1.11.11.11.5.5.5.1.1.2.2.cmml" xref="S3.E1.m1.11.11.11.5.5.5.1.1.2.2">𝐸</ci><apply id="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.cmml" xref="S3.E1.m1.11.11.11.5.5.5.1.1.2.3"><times id="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.1.cmml" xref="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.1"></times><ci id="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.2.cmml" xref="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.2">𝑢</ci><ci id="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.3.cmml" xref="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.3">𝑠</ci><ci id="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.4.cmml" xref="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.4">𝑒</ci><ci id="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.5.cmml" xref="S3.E1.m1.11.11.11.5.5.5.1.1.2.3.5">𝑟</ci></apply></apply><list id="S3.E1.m1.8.8.8.2.2.2.2.3.cmml" xref="S3.E1.m1.8.8.8.2.2.2.2.4"><ci id="S3.E1.m1.7.7.7.1.1.1.1.1.cmml" xref="S3.E1.m1.7.7.7.1.1.1.1.1">𝑖</ci><ci id="S3.E1.m1.8.8.8.2.2.2.2.2.cmml" xref="S3.E1.m1.8.8.8.2.2.2.2.2">𝑗</ci></list></apply><apply id="S3.E1.m1.12.12.12.6.6.6.2.2.cmml" xref="S3.E1.m1.12.12.12.6.6.6.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.12.12.12.6.6.6.2.2.1.cmml" xref="S3.E1.m1.12.12.12.6.6.6.2.2">subscript</csymbol><apply id="S3.E1.m1.12.12.12.6.6.6.2.2.2.cmml" xref="S3.E1.m1.12.12.12.6.6.6.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.12.12.12.6.6.6.2.2.2.1.cmml" xref="S3.E1.m1.12.12.12.6.6.6.2.2">superscript</csymbol><ci id="S3.E1.m1.12.12.12.6.6.6.2.2.2.2.cmml" xref="S3.E1.m1.12.12.12.6.6.6.2.2.2.2">𝐸</ci><apply id="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.cmml" xref="S3.E1.m1.12.12.12.6.6.6.2.2.2.3"><times id="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.1.cmml" xref="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.1"></times><ci id="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.2.cmml" xref="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.2">𝑖</ci><ci id="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.3.cmml" xref="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.3">𝑡</ci><ci id="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.4.cmml" xref="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.4">𝑒</ci><ci id="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.5.cmml" xref="S3.E1.m1.12.12.12.6.6.6.2.2.2.3.5">𝑚</ci></apply></apply><list id="S3.E1.m1.10.10.10.4.4.4.2.3.cmml" xref="S3.E1.m1.10.10.10.4.4.4.2.4"><ci id="S3.E1.m1.9.9.9.3.3.3.1.1.cmml" xref="S3.E1.m1.9.9.9.3.3.3.1.1">𝑖</ci><ci id="S3.E1.m1.10.10.10.4.4.4.2.2.cmml" xref="S3.E1.m1.10.10.10.4.4.4.2.2">𝑘</ci></list></apply></interval></apply></apply><apply id="S3.E1.m1.18.18.18.15.cmml" xref="S3.E1.m1.18.18.18.15"><apply id="S3.E1.m1.18.18.18.15.1.cmml" xref="S3.E1.m1.18.18.18.15.1"><csymbol cd="ambiguous" id="S3.E1.m1.18.18.18.15.1.1.cmml" xref="S3.E1.m1.18.18.18.15.1">subscript</csymbol><sum id="S3.E1.m1.18.18.18.15.1.2.cmml" xref="S3.E1.m1.18.18.18.15.1.2"></sum><apply id="S3.E1.m1.18.18.18.15.1.3.cmml" xref="S3.E1.m1.18.18.18.15.1.3"><neq id="S3.E1.m1.18.18.18.15.1.3.1.cmml" xref="S3.E1.m1.18.18.18.15.1.3.1"></neq><ci id="S3.E1.m1.18.18.18.15.1.3.2.cmml" xref="S3.E1.m1.18.18.18.15.1.3.2">𝑧</ci><ci id="S3.E1.m1.18.18.18.15.1.3.3.cmml" xref="S3.E1.m1.18.18.18.15.1.3.3">𝑖</ci></apply></apply><apply id="S3.E1.m1.18.18.18.15.2.cmml" xref="S3.E1.m1.18.18.18.15.2"><apply id="S3.E1.m1.18.18.18.15.2.1.cmml" xref="S3.E1.m1.18.18.18.15.2.1"><csymbol cd="ambiguous" id="S3.E1.m1.18.18.18.15.2.1.1.cmml" xref="S3.E1.m1.18.18.18.15.2.1">subscript</csymbol><sum id="S3.E1.m1.18.18.18.15.2.1.2.cmml" xref="S3.E1.m1.18.18.18.15.2.1.2"></sum><ci id="S3.E1.m1.18.18.18.15.2.1.3.cmml" xref="S3.E1.m1.18.18.18.15.2.1.3">𝑘</ci></apply><apply id="S3.E1.m1.18.18.18.15.2.2.cmml" xref="S3.E1.m1.18.18.18.15.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.18.18.18.15.2.2.1.cmml" xref="S3.E1.m1.18.18.18.15.2.2">superscript</csymbol><ci id="S3.E1.m1.18.18.18.15.2.2.2.cmml" xref="S3.E1.m1.18.18.18.15.2.2.2">𝑒</ci><apply id="S3.E1.m1.18.18.18.12.6.cmml" xref="S3.E1.m1.18.18.18.12.6"><times id="S3.E1.m1.18.18.18.12.6.7.cmml" xref="S3.E1.m1.18.18.18.12.6.7"></times><ci id="S3.E1.m1.18.18.18.12.6.8.cmml" xref="S3.E1.m1.18.18.18.12.6.8">𝑠</ci><interval closure="open" id="S3.E1.m1.18.18.18.12.6.6.3.cmml" xref="S3.E1.m1.18.18.18.12.6.6.2"><apply id="S3.E1.m1.17.17.17.11.5.5.1.1.cmml" xref="S3.E1.m1.17.17.17.11.5.5.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.17.17.17.11.5.5.1.1.1.cmml" xref="S3.E1.m1.17.17.17.11.5.5.1.1">subscript</csymbol><apply id="S3.E1.m1.17.17.17.11.5.5.1.1.2.cmml" xref="S3.E1.m1.17.17.17.11.5.5.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.17.17.17.11.5.5.1.1.2.1.cmml" xref="S3.E1.m1.17.17.17.11.5.5.1.1">superscript</csymbol><ci id="S3.E1.m1.17.17.17.11.5.5.1.1.2.2.cmml" xref="S3.E1.m1.17.17.17.11.5.5.1.1.2.2">𝐸</ci><apply id="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.cmml" xref="S3.E1.m1.17.17.17.11.5.5.1.1.2.3"><times id="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.1.cmml" xref="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.1"></times><ci id="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.2.cmml" xref="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.2">𝑢</ci><ci id="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.3.cmml" xref="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.3">𝑠</ci><ci id="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.4.cmml" xref="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.4">𝑒</ci><ci id="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.5.cmml" xref="S3.E1.m1.17.17.17.11.5.5.1.1.2.3.5">𝑟</ci></apply></apply><list id="S3.E1.m1.14.14.14.8.2.2.2.3.cmml" xref="S3.E1.m1.14.14.14.8.2.2.2.4"><ci id="S3.E1.m1.13.13.13.7.1.1.1.1.cmml" xref="S3.E1.m1.13.13.13.7.1.1.1.1">𝑖</ci><ci id="S3.E1.m1.14.14.14.8.2.2.2.2.cmml" xref="S3.E1.m1.14.14.14.8.2.2.2.2">𝑗</ci></list></apply><apply id="S3.E1.m1.18.18.18.12.6.6.2.2.cmml" xref="S3.E1.m1.18.18.18.12.6.6.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.18.18.18.12.6.6.2.2.1.cmml" xref="S3.E1.m1.18.18.18.12.6.6.2.2">subscript</csymbol><apply id="S3.E1.m1.18.18.18.12.6.6.2.2.2.cmml" xref="S3.E1.m1.18.18.18.12.6.6.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.18.18.18.12.6.6.2.2.2.1.cmml" xref="S3.E1.m1.18.18.18.12.6.6.2.2">superscript</csymbol><ci id="S3.E1.m1.18.18.18.12.6.6.2.2.2.2.cmml" xref="S3.E1.m1.18.18.18.12.6.6.2.2.2.2">𝐸</ci><apply id="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.cmml" xref="S3.E1.m1.18.18.18.12.6.6.2.2.2.3"><times id="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.1.cmml" xref="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.1"></times><ci id="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.2.cmml" xref="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.2">𝑖</ci><ci id="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.3.cmml" xref="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.3">𝑡</ci><ci id="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.4.cmml" xref="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.4">𝑒</ci><ci id="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.5.cmml" xref="S3.E1.m1.18.18.18.12.6.6.2.2.2.3.5">𝑚</ci></apply></apply><list id="S3.E1.m1.16.16.16.10.4.4.2.3.cmml" xref="S3.E1.m1.16.16.16.10.4.4.2.4"><ci id="S3.E1.m1.15.15.15.9.3.3.1.1.cmml" xref="S3.E1.m1.15.15.15.9.3.3.1.1">𝑧</ci><ci id="S3.E1.m1.16.16.16.10.4.4.2.2.cmml" xref="S3.E1.m1.16.16.16.10.4.4.2.2">𝑘</ci></list></apply></interval></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.19c">\displaystyle\mathcal{L}=-\sum_{i=1}^{N_{u}}\sum_{j=1}^{H}\sum_{k=1}^{T}\log%
\frac{e^{s(E^{user}_{i,j},E^{item}_{i,k})}}{e^{s(E^{user}_{i,j},E^{item}_{i,k}%
)}+\sum_{z\neq i}\sum_{k}e^{s(E^{user}_{i,j},E^{item}_{z,k})}},</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.19d">caligraphic_L = - ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_N start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT end_POSTSUPERSCRIPT ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_H end_POSTSUPERSCRIPT ∑ start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT roman_log divide start_ARG italic_e start_POSTSUPERSCRIPT italic_s ( italic_E start_POSTSUPERSCRIPT italic_u italic_s italic_e italic_r end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT , italic_E start_POSTSUPERSCRIPT italic_i italic_t italic_e italic_m end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT end_ARG start_ARG italic_e start_POSTSUPERSCRIPT italic_s ( italic_E start_POSTSUPERSCRIPT italic_u italic_s italic_e italic_r end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT , italic_E start_POSTSUPERSCRIPT italic_i italic_t italic_e italic_m end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT + ∑ start_POSTSUBSCRIPT italic_z ≠ italic_i end_POSTSUBSCRIPT ∑ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT italic_e start_POSTSUPERSCRIPT italic_s ( italic_E start_POSTSUPERSCRIPT italic_u italic_s italic_e italic_r end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT , italic_E start_POSTSUPERSCRIPT italic_i italic_t italic_e italic_m end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_z , italic_k end_POSTSUBSCRIPT ) end_POSTSUPERSCRIPT end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.SSS3.p3.16">where <math alttext="E^{user}_{i,j}" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.4.m1.2"><semantics id="S3.SS2.SSS3.p3.4.m1.2a"><msubsup id="S3.SS2.SSS3.p3.4.m1.2.3" xref="S3.SS2.SSS3.p3.4.m1.2.3.cmml"><mi id="S3.SS2.SSS3.p3.4.m1.2.3.2.2" xref="S3.SS2.SSS3.p3.4.m1.2.3.2.2.cmml">E</mi><mrow id="S3.SS2.SSS3.p3.4.m1.2.2.2.4" xref="S3.SS2.SSS3.p3.4.m1.2.2.2.3.cmml"><mi id="S3.SS2.SSS3.p3.4.m1.1.1.1.1" xref="S3.SS2.SSS3.p3.4.m1.1.1.1.1.cmml">i</mi><mo id="S3.SS2.SSS3.p3.4.m1.2.2.2.4.1" xref="S3.SS2.SSS3.p3.4.m1.2.2.2.3.cmml">,</mo><mi id="S3.SS2.SSS3.p3.4.m1.2.2.2.2" xref="S3.SS2.SSS3.p3.4.m1.2.2.2.2.cmml">j</mi></mrow><mrow id="S3.SS2.SSS3.p3.4.m1.2.3.2.3" xref="S3.SS2.SSS3.p3.4.m1.2.3.2.3.cmml"><mi id="S3.SS2.SSS3.p3.4.m1.2.3.2.3.2" xref="S3.SS2.SSS3.p3.4.m1.2.3.2.3.2.cmml">u</mi><mo id="S3.SS2.SSS3.p3.4.m1.2.3.2.3.1" xref="S3.SS2.SSS3.p3.4.m1.2.3.2.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p3.4.m1.2.3.2.3.3" xref="S3.SS2.SSS3.p3.4.m1.2.3.2.3.3.cmml">s</mi><mo id="S3.SS2.SSS3.p3.4.m1.2.3.2.3.1a" xref="S3.SS2.SSS3.p3.4.m1.2.3.2.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p3.4.m1.2.3.2.3.4" xref="S3.SS2.SSS3.p3.4.m1.2.3.2.3.4.cmml">e</mi><mo id="S3.SS2.SSS3.p3.4.m1.2.3.2.3.1b" xref="S3.SS2.SSS3.p3.4.m1.2.3.2.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p3.4.m1.2.3.2.3.5" xref="S3.SS2.SSS3.p3.4.m1.2.3.2.3.5.cmml">r</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.4.m1.2b"><apply id="S3.SS2.SSS3.p3.4.m1.2.3.cmml" xref="S3.SS2.SSS3.p3.4.m1.2.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p3.4.m1.2.3.1.cmml" xref="S3.SS2.SSS3.p3.4.m1.2.3">subscript</csymbol><apply id="S3.SS2.SSS3.p3.4.m1.2.3.2.cmml" xref="S3.SS2.SSS3.p3.4.m1.2.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p3.4.m1.2.3.2.1.cmml" xref="S3.SS2.SSS3.p3.4.m1.2.3">superscript</csymbol><ci id="S3.SS2.SSS3.p3.4.m1.2.3.2.2.cmml" xref="S3.SS2.SSS3.p3.4.m1.2.3.2.2">𝐸</ci><apply id="S3.SS2.SSS3.p3.4.m1.2.3.2.3.cmml" xref="S3.SS2.SSS3.p3.4.m1.2.3.2.3"><times id="S3.SS2.SSS3.p3.4.m1.2.3.2.3.1.cmml" xref="S3.SS2.SSS3.p3.4.m1.2.3.2.3.1"></times><ci id="S3.SS2.SSS3.p3.4.m1.2.3.2.3.2.cmml" xref="S3.SS2.SSS3.p3.4.m1.2.3.2.3.2">𝑢</ci><ci id="S3.SS2.SSS3.p3.4.m1.2.3.2.3.3.cmml" xref="S3.SS2.SSS3.p3.4.m1.2.3.2.3.3">𝑠</ci><ci id="S3.SS2.SSS3.p3.4.m1.2.3.2.3.4.cmml" xref="S3.SS2.SSS3.p3.4.m1.2.3.2.3.4">𝑒</ci><ci id="S3.SS2.SSS3.p3.4.m1.2.3.2.3.5.cmml" xref="S3.SS2.SSS3.p3.4.m1.2.3.2.3.5">𝑟</ci></apply></apply><list id="S3.SS2.SSS3.p3.4.m1.2.2.2.3.cmml" xref="S3.SS2.SSS3.p3.4.m1.2.2.2.4"><ci id="S3.SS2.SSS3.p3.4.m1.1.1.1.1.cmml" xref="S3.SS2.SSS3.p3.4.m1.1.1.1.1">𝑖</ci><ci id="S3.SS2.SSS3.p3.4.m1.2.2.2.2.cmml" xref="S3.SS2.SSS3.p3.4.m1.2.2.2.2">𝑗</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.4.m1.2c">E^{user}_{i,j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.4.m1.2d">italic_E start_POSTSUPERSCRIPT italic_u italic_s italic_e italic_r end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT</annotation></semantics></math> denotes the <math alttext="j" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.5.m2.1"><semantics id="S3.SS2.SSS3.p3.5.m2.1a"><mi id="S3.SS2.SSS3.p3.5.m2.1.1" xref="S3.SS2.SSS3.p3.5.m2.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.5.m2.1b"><ci id="S3.SS2.SSS3.p3.5.m2.1.1.cmml" xref="S3.SS2.SSS3.p3.5.m2.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.5.m2.1c">j</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.5.m2.1d">italic_j</annotation></semantics></math>-th embedding of the <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.6.m3.1"><semantics id="S3.SS2.SSS3.p3.6.m3.1a"><mi id="S3.SS2.SSS3.p3.6.m3.1.1" xref="S3.SS2.SSS3.p3.6.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.6.m3.1b"><ci id="S3.SS2.SSS3.p3.6.m3.1.1.cmml" xref="S3.SS2.SSS3.p3.6.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.6.m3.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.6.m3.1d">italic_i</annotation></semantics></math>-th user generated from the user history interaction of length <math alttext="H" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.7.m4.1"><semantics id="S3.SS2.SSS3.p3.7.m4.1a"><mi id="S3.SS2.SSS3.p3.7.m4.1.1" xref="S3.SS2.SSS3.p3.7.m4.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.7.m4.1b"><ci id="S3.SS2.SSS3.p3.7.m4.1.1.cmml" xref="S3.SS2.SSS3.p3.7.m4.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.7.m4.1c">H</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.7.m4.1d">italic_H</annotation></semantics></math> and <math alttext="E^{item}_{i,k}" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.8.m5.2"><semantics id="S3.SS2.SSS3.p3.8.m5.2a"><msubsup id="S3.SS2.SSS3.p3.8.m5.2.3" xref="S3.SS2.SSS3.p3.8.m5.2.3.cmml"><mi id="S3.SS2.SSS3.p3.8.m5.2.3.2.2" xref="S3.SS2.SSS3.p3.8.m5.2.3.2.2.cmml">E</mi><mrow id="S3.SS2.SSS3.p3.8.m5.2.2.2.4" xref="S3.SS2.SSS3.p3.8.m5.2.2.2.3.cmml"><mi id="S3.SS2.SSS3.p3.8.m5.1.1.1.1" xref="S3.SS2.SSS3.p3.8.m5.1.1.1.1.cmml">i</mi><mo id="S3.SS2.SSS3.p3.8.m5.2.2.2.4.1" xref="S3.SS2.SSS3.p3.8.m5.2.2.2.3.cmml">,</mo><mi id="S3.SS2.SSS3.p3.8.m5.2.2.2.2" xref="S3.SS2.SSS3.p3.8.m5.2.2.2.2.cmml">k</mi></mrow><mrow id="S3.SS2.SSS3.p3.8.m5.2.3.2.3" xref="S3.SS2.SSS3.p3.8.m5.2.3.2.3.cmml"><mi id="S3.SS2.SSS3.p3.8.m5.2.3.2.3.2" xref="S3.SS2.SSS3.p3.8.m5.2.3.2.3.2.cmml">i</mi><mo id="S3.SS2.SSS3.p3.8.m5.2.3.2.3.1" xref="S3.SS2.SSS3.p3.8.m5.2.3.2.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p3.8.m5.2.3.2.3.3" xref="S3.SS2.SSS3.p3.8.m5.2.3.2.3.3.cmml">t</mi><mo id="S3.SS2.SSS3.p3.8.m5.2.3.2.3.1a" xref="S3.SS2.SSS3.p3.8.m5.2.3.2.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p3.8.m5.2.3.2.3.4" xref="S3.SS2.SSS3.p3.8.m5.2.3.2.3.4.cmml">e</mi><mo id="S3.SS2.SSS3.p3.8.m5.2.3.2.3.1b" xref="S3.SS2.SSS3.p3.8.m5.2.3.2.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p3.8.m5.2.3.2.3.5" xref="S3.SS2.SSS3.p3.8.m5.2.3.2.3.5.cmml">m</mi></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.8.m5.2b"><apply id="S3.SS2.SSS3.p3.8.m5.2.3.cmml" xref="S3.SS2.SSS3.p3.8.m5.2.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p3.8.m5.2.3.1.cmml" xref="S3.SS2.SSS3.p3.8.m5.2.3">subscript</csymbol><apply id="S3.SS2.SSS3.p3.8.m5.2.3.2.cmml" xref="S3.SS2.SSS3.p3.8.m5.2.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p3.8.m5.2.3.2.1.cmml" xref="S3.SS2.SSS3.p3.8.m5.2.3">superscript</csymbol><ci id="S3.SS2.SSS3.p3.8.m5.2.3.2.2.cmml" xref="S3.SS2.SSS3.p3.8.m5.2.3.2.2">𝐸</ci><apply id="S3.SS2.SSS3.p3.8.m5.2.3.2.3.cmml" xref="S3.SS2.SSS3.p3.8.m5.2.3.2.3"><times id="S3.SS2.SSS3.p3.8.m5.2.3.2.3.1.cmml" xref="S3.SS2.SSS3.p3.8.m5.2.3.2.3.1"></times><ci id="S3.SS2.SSS3.p3.8.m5.2.3.2.3.2.cmml" xref="S3.SS2.SSS3.p3.8.m5.2.3.2.3.2">𝑖</ci><ci id="S3.SS2.SSS3.p3.8.m5.2.3.2.3.3.cmml" xref="S3.SS2.SSS3.p3.8.m5.2.3.2.3.3">𝑡</ci><ci id="S3.SS2.SSS3.p3.8.m5.2.3.2.3.4.cmml" xref="S3.SS2.SSS3.p3.8.m5.2.3.2.3.4">𝑒</ci><ci id="S3.SS2.SSS3.p3.8.m5.2.3.2.3.5.cmml" xref="S3.SS2.SSS3.p3.8.m5.2.3.2.3.5">𝑚</ci></apply></apply><list id="S3.SS2.SSS3.p3.8.m5.2.2.2.3.cmml" xref="S3.SS2.SSS3.p3.8.m5.2.2.2.4"><ci id="S3.SS2.SSS3.p3.8.m5.1.1.1.1.cmml" xref="S3.SS2.SSS3.p3.8.m5.1.1.1.1">𝑖</ci><ci id="S3.SS2.SSS3.p3.8.m5.2.2.2.2.cmml" xref="S3.SS2.SSS3.p3.8.m5.2.2.2.2">𝑘</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.8.m5.2c">E^{item}_{i,k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.8.m5.2d">italic_E start_POSTSUPERSCRIPT italic_i italic_t italic_e italic_m end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i , italic_k end_POSTSUBSCRIPT</annotation></semantics></math> denotes the <math alttext="k" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.9.m6.1"><semantics id="S3.SS2.SSS3.p3.9.m6.1a"><mi id="S3.SS2.SSS3.p3.9.m6.1.1" xref="S3.SS2.SSS3.p3.9.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.9.m6.1b"><ci id="S3.SS2.SSS3.p3.9.m6.1.1.cmml" xref="S3.SS2.SSS3.p3.9.m6.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.9.m6.1c">k</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.9.m6.1d">italic_k</annotation></semantics></math>-th embedding of the <math alttext="i" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.10.m7.1"><semantics id="S3.SS2.SSS3.p3.10.m7.1a"><mi id="S3.SS2.SSS3.p3.10.m7.1.1" xref="S3.SS2.SSS3.p3.10.m7.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.10.m7.1b"><ci id="S3.SS2.SSS3.p3.10.m7.1.1.cmml" xref="S3.SS2.SSS3.p3.10.m7.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.10.m7.1c">i</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.10.m7.1d">italic_i</annotation></semantics></math>-th user from the target interaction of length <math alttext="T" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.11.m8.1"><semantics id="S3.SS2.SSS3.p3.11.m8.1a"><mi id="S3.SS2.SSS3.p3.11.m8.1.1" xref="S3.SS2.SSS3.p3.11.m8.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.11.m8.1b"><ci id="S3.SS2.SSS3.p3.11.m8.1.1.cmml" xref="S3.SS2.SSS3.p3.11.m8.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.11.m8.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.11.m8.1d">italic_T</annotation></semantics></math>. <math alttext="N_{u}" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.12.m9.1"><semantics id="S3.SS2.SSS3.p3.12.m9.1a"><msub id="S3.SS2.SSS3.p3.12.m9.1.1" xref="S3.SS2.SSS3.p3.12.m9.1.1.cmml"><mi id="S3.SS2.SSS3.p3.12.m9.1.1.2" xref="S3.SS2.SSS3.p3.12.m9.1.1.2.cmml">N</mi><mi id="S3.SS2.SSS3.p3.12.m9.1.1.3" xref="S3.SS2.SSS3.p3.12.m9.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.12.m9.1b"><apply id="S3.SS2.SSS3.p3.12.m9.1.1.cmml" xref="S3.SS2.SSS3.p3.12.m9.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p3.12.m9.1.1.1.cmml" xref="S3.SS2.SSS3.p3.12.m9.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p3.12.m9.1.1.2.cmml" xref="S3.SS2.SSS3.p3.12.m9.1.1.2">𝑁</ci><ci id="S3.SS2.SSS3.p3.12.m9.1.1.3.cmml" xref="S3.SS2.SSS3.p3.12.m9.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.12.m9.1c">N_{u}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.12.m9.1d">italic_N start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math> represents the total number of users in the training set. As depicted in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S3.F3" title="Figure 3 ‣ 3.1. Content Embedding of LLM ‣ 3. Method ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">3</span></a>, given the interaction lengths <math alttext="H" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.13.m10.1"><semantics id="S3.SS2.SSS3.p3.13.m10.1a"><mi id="S3.SS2.SSS3.p3.13.m10.1.1" xref="S3.SS2.SSS3.p3.13.m10.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.13.m10.1b"><ci id="S3.SS2.SSS3.p3.13.m10.1.1.cmml" xref="S3.SS2.SSS3.p3.13.m10.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.13.m10.1c">H</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.13.m10.1d">italic_H</annotation></semantics></math> and <math alttext="T" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.14.m11.1"><semantics id="S3.SS2.SSS3.p3.14.m11.1a"><mi id="S3.SS2.SSS3.p3.14.m11.1.1" xref="S3.SS2.SSS3.p3.14.m11.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.14.m11.1b"><ci id="S3.SS2.SSS3.p3.14.m11.1.1.cmml" xref="S3.SS2.SSS3.p3.14.m11.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.14.m11.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.14.m11.1d">italic_T</annotation></semantics></math>, we generate <math alttext="H" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.15.m12.1"><semantics id="S3.SS2.SSS3.p3.15.m12.1a"><mi id="S3.SS2.SSS3.p3.15.m12.1.1" xref="S3.SS2.SSS3.p3.15.m12.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.15.m12.1b"><ci id="S3.SS2.SSS3.p3.15.m12.1.1.cmml" xref="S3.SS2.SSS3.p3.15.m12.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.15.m12.1c">H</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.15.m12.1d">italic_H</annotation></semantics></math> user embeddings and <math alttext="T" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p3.16.m13.1"><semantics id="S3.SS2.SSS3.p3.16.m13.1a"><mi id="S3.SS2.SSS3.p3.16.m13.1.1" xref="S3.SS2.SSS3.p3.16.m13.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p3.16.m13.1b"><ci id="S3.SS2.SSS3.p3.16.m13.1.1.cmml" xref="S3.SS2.SSS3.p3.16.m13.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p3.16.m13.1c">T</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p3.16.m13.1d">italic_T</annotation></semantics></math> item embeddings, respectively.</p>
</div>
<div class="ltx_para" id="S3.SS2.SSS3.p4">
<p class="ltx_p" id="S3.SS2.SSS3.p4.3">For an individual user, we construct <math alttext="N_{hist}\times N_{tar}" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p4.1.m1.1"><semantics id="S3.SS2.SSS3.p4.1.m1.1a"><mrow id="S3.SS2.SSS3.p4.1.m1.1.1" xref="S3.SS2.SSS3.p4.1.m1.1.1.cmml"><msub id="S3.SS2.SSS3.p4.1.m1.1.1.2" xref="S3.SS2.SSS3.p4.1.m1.1.1.2.cmml"><mi id="S3.SS2.SSS3.p4.1.m1.1.1.2.2" xref="S3.SS2.SSS3.p4.1.m1.1.1.2.2.cmml">N</mi><mrow id="S3.SS2.SSS3.p4.1.m1.1.1.2.3" xref="S3.SS2.SSS3.p4.1.m1.1.1.2.3.cmml"><mi id="S3.SS2.SSS3.p4.1.m1.1.1.2.3.2" xref="S3.SS2.SSS3.p4.1.m1.1.1.2.3.2.cmml">h</mi><mo id="S3.SS2.SSS3.p4.1.m1.1.1.2.3.1" xref="S3.SS2.SSS3.p4.1.m1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p4.1.m1.1.1.2.3.3" xref="S3.SS2.SSS3.p4.1.m1.1.1.2.3.3.cmml">i</mi><mo id="S3.SS2.SSS3.p4.1.m1.1.1.2.3.1a" xref="S3.SS2.SSS3.p4.1.m1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p4.1.m1.1.1.2.3.4" xref="S3.SS2.SSS3.p4.1.m1.1.1.2.3.4.cmml">s</mi><mo id="S3.SS2.SSS3.p4.1.m1.1.1.2.3.1b" xref="S3.SS2.SSS3.p4.1.m1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p4.1.m1.1.1.2.3.5" xref="S3.SS2.SSS3.p4.1.m1.1.1.2.3.5.cmml">t</mi></mrow></msub><mo id="S3.SS2.SSS3.p4.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.SS2.SSS3.p4.1.m1.1.1.1.cmml">×</mo><msub id="S3.SS2.SSS3.p4.1.m1.1.1.3" xref="S3.SS2.SSS3.p4.1.m1.1.1.3.cmml"><mi id="S3.SS2.SSS3.p4.1.m1.1.1.3.2" xref="S3.SS2.SSS3.p4.1.m1.1.1.3.2.cmml">N</mi><mrow id="S3.SS2.SSS3.p4.1.m1.1.1.3.3" xref="S3.SS2.SSS3.p4.1.m1.1.1.3.3.cmml"><mi id="S3.SS2.SSS3.p4.1.m1.1.1.3.3.2" xref="S3.SS2.SSS3.p4.1.m1.1.1.3.3.2.cmml">t</mi><mo id="S3.SS2.SSS3.p4.1.m1.1.1.3.3.1" xref="S3.SS2.SSS3.p4.1.m1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p4.1.m1.1.1.3.3.3" xref="S3.SS2.SSS3.p4.1.m1.1.1.3.3.3.cmml">a</mi><mo id="S3.SS2.SSS3.p4.1.m1.1.1.3.3.1a" xref="S3.SS2.SSS3.p4.1.m1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p4.1.m1.1.1.3.3.4" xref="S3.SS2.SSS3.p4.1.m1.1.1.3.3.4.cmml">r</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.1.m1.1b"><apply id="S3.SS2.SSS3.p4.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1"><times id="S3.SS2.SSS3.p4.1.m1.1.1.1.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.1"></times><apply id="S3.SS2.SSS3.p4.1.m1.1.1.2.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.1.m1.1.1.2.1.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS2.SSS3.p4.1.m1.1.1.2.2.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.2.2">𝑁</ci><apply id="S3.SS2.SSS3.p4.1.m1.1.1.2.3.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.2.3"><times id="S3.SS2.SSS3.p4.1.m1.1.1.2.3.1.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.2.3.1"></times><ci id="S3.SS2.SSS3.p4.1.m1.1.1.2.3.2.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.2.3.2">ℎ</ci><ci id="S3.SS2.SSS3.p4.1.m1.1.1.2.3.3.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.2.3.3">𝑖</ci><ci id="S3.SS2.SSS3.p4.1.m1.1.1.2.3.4.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.2.3.4">𝑠</ci><ci id="S3.SS2.SSS3.p4.1.m1.1.1.2.3.5.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.2.3.5">𝑡</ci></apply></apply><apply id="S3.SS2.SSS3.p4.1.m1.1.1.3.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.1.m1.1.1.3.1.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS3.p4.1.m1.1.1.3.2.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.3.2">𝑁</ci><apply id="S3.SS2.SSS3.p4.1.m1.1.1.3.3.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.3.3"><times id="S3.SS2.SSS3.p4.1.m1.1.1.3.3.1.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.3.3.1"></times><ci id="S3.SS2.SSS3.p4.1.m1.1.1.3.3.2.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.3.3.2">𝑡</ci><ci id="S3.SS2.SSS3.p4.1.m1.1.1.3.3.3.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.3.3.3">𝑎</ci><ci id="S3.SS2.SSS3.p4.1.m1.1.1.3.3.4.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1.3.3.4">𝑟</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.1.m1.1c">N_{hist}\times N_{tar}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p4.1.m1.1d">italic_N start_POSTSUBSCRIPT italic_h italic_i italic_s italic_t end_POSTSUBSCRIPT × italic_N start_POSTSUBSCRIPT italic_t italic_a italic_r end_POSTSUBSCRIPT</annotation></semantics></math> positive pairs and <math alttext="N_{hist}\times(bs-1)\times N_{tar}" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p4.2.m2.1"><semantics id="S3.SS2.SSS3.p4.2.m2.1a"><mrow id="S3.SS2.SSS3.p4.2.m2.1.1" xref="S3.SS2.SSS3.p4.2.m2.1.1.cmml"><msub id="S3.SS2.SSS3.p4.2.m2.1.1.3" xref="S3.SS2.SSS3.p4.2.m2.1.1.3.cmml"><mi id="S3.SS2.SSS3.p4.2.m2.1.1.3.2" xref="S3.SS2.SSS3.p4.2.m2.1.1.3.2.cmml">N</mi><mrow id="S3.SS2.SSS3.p4.2.m2.1.1.3.3" xref="S3.SS2.SSS3.p4.2.m2.1.1.3.3.cmml"><mi id="S3.SS2.SSS3.p4.2.m2.1.1.3.3.2" xref="S3.SS2.SSS3.p4.2.m2.1.1.3.3.2.cmml">h</mi><mo id="S3.SS2.SSS3.p4.2.m2.1.1.3.3.1" xref="S3.SS2.SSS3.p4.2.m2.1.1.3.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p4.2.m2.1.1.3.3.3" xref="S3.SS2.SSS3.p4.2.m2.1.1.3.3.3.cmml">i</mi><mo id="S3.SS2.SSS3.p4.2.m2.1.1.3.3.1a" xref="S3.SS2.SSS3.p4.2.m2.1.1.3.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p4.2.m2.1.1.3.3.4" xref="S3.SS2.SSS3.p4.2.m2.1.1.3.3.4.cmml">s</mi><mo id="S3.SS2.SSS3.p4.2.m2.1.1.3.3.1b" xref="S3.SS2.SSS3.p4.2.m2.1.1.3.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p4.2.m2.1.1.3.3.5" xref="S3.SS2.SSS3.p4.2.m2.1.1.3.3.5.cmml">t</mi></mrow></msub><mo id="S3.SS2.SSS3.p4.2.m2.1.1.2" lspace="0.222em" rspace="0.222em" xref="S3.SS2.SSS3.p4.2.m2.1.1.2.cmml">×</mo><mrow id="S3.SS2.SSS3.p4.2.m2.1.1.1.1" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.cmml"><mo id="S3.SS2.SSS3.p4.2.m2.1.1.1.1.2" stretchy="false" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.cmml">(</mo><mrow id="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.cmml"><mrow id="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.2" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.2.cmml"><mi id="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.2.2" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.2.2.cmml">b</mi><mo id="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.2.1" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.2.3" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.2.3.cmml">s</mi></mrow><mo id="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.1" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.1.cmml">−</mo><mn id="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.3" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.3.cmml">1</mn></mrow><mo id="S3.SS2.SSS3.p4.2.m2.1.1.1.1.3" rspace="0.055em" stretchy="false" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.SS2.SSS3.p4.2.m2.1.1.2a" rspace="0.222em" xref="S3.SS2.SSS3.p4.2.m2.1.1.2.cmml">×</mo><msub id="S3.SS2.SSS3.p4.2.m2.1.1.4" xref="S3.SS2.SSS3.p4.2.m2.1.1.4.cmml"><mi id="S3.SS2.SSS3.p4.2.m2.1.1.4.2" xref="S3.SS2.SSS3.p4.2.m2.1.1.4.2.cmml">N</mi><mrow id="S3.SS2.SSS3.p4.2.m2.1.1.4.3" xref="S3.SS2.SSS3.p4.2.m2.1.1.4.3.cmml"><mi id="S3.SS2.SSS3.p4.2.m2.1.1.4.3.2" xref="S3.SS2.SSS3.p4.2.m2.1.1.4.3.2.cmml">t</mi><mo id="S3.SS2.SSS3.p4.2.m2.1.1.4.3.1" xref="S3.SS2.SSS3.p4.2.m2.1.1.4.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p4.2.m2.1.1.4.3.3" xref="S3.SS2.SSS3.p4.2.m2.1.1.4.3.3.cmml">a</mi><mo id="S3.SS2.SSS3.p4.2.m2.1.1.4.3.1a" xref="S3.SS2.SSS3.p4.2.m2.1.1.4.3.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p4.2.m2.1.1.4.3.4" xref="S3.SS2.SSS3.p4.2.m2.1.1.4.3.4.cmml">r</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.2.m2.1b"><apply id="S3.SS2.SSS3.p4.2.m2.1.1.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1"><times id="S3.SS2.SSS3.p4.2.m2.1.1.2.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.2"></times><apply id="S3.SS2.SSS3.p4.2.m2.1.1.3.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.2.m2.1.1.3.1.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS3.p4.2.m2.1.1.3.2.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.3.2">𝑁</ci><apply id="S3.SS2.SSS3.p4.2.m2.1.1.3.3.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.3.3"><times id="S3.SS2.SSS3.p4.2.m2.1.1.3.3.1.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.3.3.1"></times><ci id="S3.SS2.SSS3.p4.2.m2.1.1.3.3.2.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.3.3.2">ℎ</ci><ci id="S3.SS2.SSS3.p4.2.m2.1.1.3.3.3.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.3.3.3">𝑖</ci><ci id="S3.SS2.SSS3.p4.2.m2.1.1.3.3.4.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.3.3.4">𝑠</ci><ci id="S3.SS2.SSS3.p4.2.m2.1.1.3.3.5.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.3.3.5">𝑡</ci></apply></apply><apply id="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.1"><minus id="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.1"></minus><apply id="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.2"><times id="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.2.1.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.2.1"></times><ci id="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.2.2.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.2.2">𝑏</ci><ci id="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.2.3.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.2.3">𝑠</ci></apply><cn id="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.3.cmml" type="integer" xref="S3.SS2.SSS3.p4.2.m2.1.1.1.1.1.3">1</cn></apply><apply id="S3.SS2.SSS3.p4.2.m2.1.1.4.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.4"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.2.m2.1.1.4.1.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.4">subscript</csymbol><ci id="S3.SS2.SSS3.p4.2.m2.1.1.4.2.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.4.2">𝑁</ci><apply id="S3.SS2.SSS3.p4.2.m2.1.1.4.3.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.4.3"><times id="S3.SS2.SSS3.p4.2.m2.1.1.4.3.1.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.4.3.1"></times><ci id="S3.SS2.SSS3.p4.2.m2.1.1.4.3.2.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.4.3.2">𝑡</ci><ci id="S3.SS2.SSS3.p4.2.m2.1.1.4.3.3.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.4.3.3">𝑎</ci><ci id="S3.SS2.SSS3.p4.2.m2.1.1.4.3.4.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1.4.3.4">𝑟</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.2.m2.1c">N_{hist}\times(bs-1)\times N_{tar}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p4.2.m2.1d">italic_N start_POSTSUBSCRIPT italic_h italic_i italic_s italic_t end_POSTSUBSCRIPT × ( italic_b italic_s - 1 ) × italic_N start_POSTSUBSCRIPT italic_t italic_a italic_r end_POSTSUBSCRIPT</annotation></semantics></math> negative pairs, where
<math alttext="bs" class="ltx_Math" display="inline" id="S3.SS2.SSS3.p4.3.m3.1"><semantics id="S3.SS2.SSS3.p4.3.m3.1a"><mrow id="S3.SS2.SSS3.p4.3.m3.1.1" xref="S3.SS2.SSS3.p4.3.m3.1.1.cmml"><mi id="S3.SS2.SSS3.p4.3.m3.1.1.2" xref="S3.SS2.SSS3.p4.3.m3.1.1.2.cmml">b</mi><mo id="S3.SS2.SSS3.p4.3.m3.1.1.1" xref="S3.SS2.SSS3.p4.3.m3.1.1.1.cmml">⁢</mo><mi id="S3.SS2.SSS3.p4.3.m3.1.1.3" xref="S3.SS2.SSS3.p4.3.m3.1.1.3.cmml">s</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.3.m3.1b"><apply id="S3.SS2.SSS3.p4.3.m3.1.1.cmml" xref="S3.SS2.SSS3.p4.3.m3.1.1"><times id="S3.SS2.SSS3.p4.3.m3.1.1.1.cmml" xref="S3.SS2.SSS3.p4.3.m3.1.1.1"></times><ci id="S3.SS2.SSS3.p4.3.m3.1.1.2.cmml" xref="S3.SS2.SSS3.p4.3.m3.1.1.2">𝑏</ci><ci id="S3.SS2.SSS3.p4.3.m3.1.1.3.cmml" xref="S3.SS2.SSS3.p4.3.m3.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.3.m3.1c">bs</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.SSS3.p4.3.m3.1d">italic_b italic_s</annotation></semantics></math> is the batch size. The loss function, Eq. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S3.E1" title="In 3.2.3. Training Target of Recommendation Domain ‣ 3.2. Model Architecture ‣ 3. Method ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">1</span></a>, is applied for each positive pair as the dense all-action loss <cite class="ltx_cite ltx_citemacro_citep">(Pancha et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib30" title="">2022</a>)</cite>.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S3.F4.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4. </span>Illustration of the Content-Embedding Generation (CEG) module and Preference CompreHension (PCH) module. The CEG module utilizes a pretrained Large Language Model (LLM) as the backbone network to generate content embeddings from item text descriptions. Subsequently, the Preference CompreHension (PCH) module takes these content embeddings and projects them from the open-world domain into the collaborative domain embeddings used in the online Recommender System (RS).
</figcaption>
</figure>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>EXPERIMENTS</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this section, we first present a large-scale offline dataset collected from the real industry scenario. Then, we conduct various experiments on the proposed dataset to explore ways to effectively incorporate LLM into the recommender system (RS). Finally, we introduce how to deploy our method on the online RS and show the online revenue achieved by our method.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Offline Dataset</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.2">All users and items are collected from the e-commerce platform of the KuaiShou application.
The span of data collection is set to be 10 months, from June 2022 to April 2023.
After filtering out invalid and outlier users, we collected a total of 12 million users.
Items in the user interaction sequence are sampled quarterly by behavior type (item buy, item search, item view, item click), resulting in the collection of 31 million items.
The sample size of each behavior is based on its corresponding 80th percentile. We collect the content information of items from six perspectives, including title, category, brand, price, keywords, and attributes. The attributes refer to the service types supported by the items, such as ”huabei installment plan”, ”return for damaged packages ”, and ”buy now pay later”. In the 10-month user interaction sequence, the first 9 months are designated as the historical interaction <math alttext="U^{hist}" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><msup id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mi id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">U</mi><mrow id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml"><mi id="S4.SS1.p1.1.m1.1.1.3.2" xref="S4.SS1.p1.1.m1.1.1.3.2.cmml">h</mi><mo id="S4.SS1.p1.1.m1.1.1.3.1" xref="S4.SS1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS1.p1.1.m1.1.1.3.3" xref="S4.SS1.p1.1.m1.1.1.3.3.cmml">i</mi><mo id="S4.SS1.p1.1.m1.1.1.3.1a" xref="S4.SS1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS1.p1.1.m1.1.1.3.4" xref="S4.SS1.p1.1.m1.1.1.3.4.cmml">s</mi><mo id="S4.SS1.p1.1.m1.1.1.3.1b" xref="S4.SS1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS1.p1.1.m1.1.1.3.5" xref="S4.SS1.p1.1.m1.1.1.3.5.cmml">t</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">superscript</csymbol><ci id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">𝑈</ci><apply id="S4.SS1.p1.1.m1.1.1.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3"><times id="S4.SS1.p1.1.m1.1.1.3.1.cmml" xref="S4.SS1.p1.1.m1.1.1.3.1"></times><ci id="S4.SS1.p1.1.m1.1.1.3.2.cmml" xref="S4.SS1.p1.1.m1.1.1.3.2">ℎ</ci><ci id="S4.SS1.p1.1.m1.1.1.3.3.cmml" xref="S4.SS1.p1.1.m1.1.1.3.3">𝑖</ci><ci id="S4.SS1.p1.1.m1.1.1.3.4.cmml" xref="S4.SS1.p1.1.m1.1.1.3.4">𝑠</ci><ci id="S4.SS1.p1.1.m1.1.1.3.5.cmml" xref="S4.SS1.p1.1.m1.1.1.3.5">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">U^{hist}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">italic_U start_POSTSUPERSCRIPT italic_h italic_i italic_s italic_t end_POSTSUPERSCRIPT</annotation></semantics></math>, while the last month is designated as the target interaction <math alttext="U^{tar}" class="ltx_Math" display="inline" id="S4.SS1.p1.2.m2.1"><semantics id="S4.SS1.p1.2.m2.1a"><msup id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mi id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml">U</mi><mrow id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3.cmml"><mi id="S4.SS1.p1.2.m2.1.1.3.2" xref="S4.SS1.p1.2.m2.1.1.3.2.cmml">t</mi><mo id="S4.SS1.p1.2.m2.1.1.3.1" xref="S4.SS1.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S4.SS1.p1.2.m2.1.1.3.3" xref="S4.SS1.p1.2.m2.1.1.3.3.cmml">a</mi><mo id="S4.SS1.p1.2.m2.1.1.3.1a" xref="S4.SS1.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S4.SS1.p1.2.m2.1.1.3.4" xref="S4.SS1.p1.2.m2.1.1.3.4.cmml">r</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">superscript</csymbol><ci id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2">𝑈</ci><apply id="S4.SS1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3"><times id="S4.SS1.p1.2.m2.1.1.3.1.cmml" xref="S4.SS1.p1.2.m2.1.1.3.1"></times><ci id="S4.SS1.p1.2.m2.1.1.3.2.cmml" xref="S4.SS1.p1.2.m2.1.1.3.2">𝑡</ci><ci id="S4.SS1.p1.2.m2.1.1.3.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3.3">𝑎</ci><ci id="S4.SS1.p1.2.m2.1.1.3.4.cmml" xref="S4.SS1.p1.2.m2.1.1.3.4">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">U^{tar}</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.2.m2.1d">italic_U start_POSTSUPERSCRIPT italic_t italic_a italic_r end_POSTSUPERSCRIPT</annotation></semantics></math>. We divided the dataset into training and test sets. The training set includes 12 million users, encompassing 25 million items from user history interactions and 12 million items from user target interactions. The test set comprises 240K users with 5 million items from user history interactions, along with a gallery set containing 200K items.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Offline Experimental Settings</h3>
<section class="ltx_subsubsection" id="S4.SS2.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.2.1. </span>Implementation Details</h4>
<div class="ltx_para" id="S4.SS2.SSS1.p1">
<p class="ltx_p" id="S4.SS2.SSS1.p1.1">We adopt the Baichuan2-7B <cite class="ltx_cite ltx_citemacro_citep">(Baichuan, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib2" title="">2023</a>)</cite> as the LLM due to its robust capabilities in understanding Chinese text. The parameters are frozen during the training stage. Adam optimizer is utilized, and the batch size is set to 30. We adopt the cosine learning rate scheduler with a learning rate of 5e-5, and the warm-up parameter is set to 0.1. The model is trained for a total of 10 epochs. All experiments are run on 8 NVIDIA V100 GPUs.
Following previous works <cite class="ltx_cite ltx_citemacro_citep">(Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib27" title="">2023b</a>; Hou et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib18" title="">2022</a>)</cite>, we use the hit rate (H@50, H@100) and recall (R@50, R@100) for performance evaluation. The length of user history and target interaction are set to 80 and 40 as default settings.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Offline Results</h3>
<div class="ltx_para" id="S4.SS3.p1">
<p class="ltx_p" id="S4.SS3.p1.1">To explore the way to incorporate the LLM with the recommender system and demonstrate the superiority of our framework, we conduct experiments by answering research questions as follows.</p>
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1">RQ1:</span>
Does LLM embedding offer advantages over traditional ID embedding and other content embedding?</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1">RQ2:</span>
Does the proposed LEARN framework offer advantages over previous ”Rec-to-LLM” methods?</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i3.p1.1.1">RQ3:</span>
Does the proposed LEARN framework offer advantages over SOTA models proposed for industry scenarios?</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S4.I1.i4.p1">
<p class="ltx_p" id="S4.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i4.p1.1.1">RQ4:</span>
Are all the modules within our proposed LEARN framework indispensable?</p>
</div>
</li>
</ul>
</div>
<section class="ltx_subsubsection" id="S4.SS3.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.1. </span>Comparison of embedding types (<span class="ltx_text ltx_font_bold" id="S4.SS3.SSS1.1.1">RQ1</span>)</h4>
<div class="ltx_para" id="S4.SS3.SSS1.p1">
<p class="ltx_p" id="S4.SS3.SSS1.p1.1">To validate the effectiveness of content embeddings as input, we replaced content embeddings with ID embeddings like the traditional recommendation system. As shown in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.T1" title="Table 1 ‣ 4.3.1. Comparison of embedding types (RQ1) ‣ 4.3. Offline Results ‣ 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">1</span></a>, the content embeddings based on LLM achieved a significant performance improvement, particularly in the H@100 metric, increasing from 0.0370 to 0.0701, representing an enhancement of 89.46%. To further verify the representation of the content embedding, we adopt [CLS] token of BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib8" title="">2018</a>)</cite> to replace the LLM embedding. Compared to content embeddings generated by BERT, the embeddings generated by LLM improve the performance from 0.0576 to 0.0701. Content embeddings generated by LLM contain a greater amount of information and demonstrate stronger capabilities in expressing textual information about items. We attribute this phenomenon to the extensive text corpus utilized during the LLM pre-training stage, enhancing its feature representation capability.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1. </span>Performance comparison of input embedding in the LEARN framework on the offline dataset</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T1.1" style="width:390.3pt;height:111pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(68.6pt,-19.5pt) scale(1.54216941425807,1.54216941425807) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T1.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.1.1.1.1.1">Input Embedding</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.1.1.2">H@50</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.1.1.3">R@50</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.1.1.4">H@100</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.1.1.1.1.5">R@100</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T1.1.1.2.1.1">ID</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.2.1.2">0.0244</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.2.1.3">0.0533</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.2.1.4">0.0370</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.1.1.2.1.5">0.0769</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T1.1.1.3.2.1">BERT</th>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.3.2.2">0.0357</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.3.2.3">0.0552</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.3.2.4">0.0576</td>
<td class="ltx_td ltx_align_center" id="S4.T1.1.1.3.2.5">0.0843</td>
</tr>
<tr class="ltx_tr" id="S4.T1.1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S4.T1.1.1.4.3.1">LLM (Ours)</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.1.1.4.3.2"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.4.3.2.1">0.0440</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.1.1.4.3.3"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.4.3.3.1">0.0610</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.1.1.4.3.4"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.4.3.4.1">0.0701</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T1.1.1.4.3.5"><span class="ltx_text ltx_font_bold" id="S4.T1.1.1.4.3.5.1">0.0905</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.2. </span>Comparison with previous ”Rec-to-LLM” method (<span class="ltx_text ltx_font_bold" id="S4.SS3.SSS2.1.1">RQ2</span>)</h4>
<div class="ltx_para" id="S4.SS3.SSS2.p1">
<p class="ltx_p" id="S4.SS3.SSS2.p1.1">To confirm the gap between the collaborative domain of recommender and the open-world domain of LLM, we propose two baseline approaches: one with frozen LLM parameters and the other with finetuning all parameters of LLM.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p2">
<p class="ltx_p" id="S4.SS3.SSS2.p2.1">The first baseline (Baseline-v1) utilizes pretrained LLM with frozen parameters. Texts of all items from user history interactions are concatenated into a text sequence, serving as the input to LLM. We perform average pooling on the output of the token embedding by LLM to obtain the user embedding. For item embedding, the texts of each item are individually fed into LLM. We evaluate performance using the same user-to-item retrieval setting as in previous experiments. The second baseline (Baseline-v2) adopts the same LLM but with all learnable parameters.
This baseline adopts a similar approach as previous ”Rec-to-LLM” methods <cite class="ltx_cite ltx_citemacro_citep">(Bao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib4" title="">2023b</a>; Liao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib23" title="">2023</a>; Lin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib25" title="">2023b</a>; Gao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib12" title="">2023</a>; Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib26" title="">2023a</a>; Hou et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib19" title="">2024</a>; Ren et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib31" title="">2023</a>)</cite>, which transforms the recommendation data into natural language conversation and is optimized by the next token prediction. We designed a prompt to amalgamate the textual information of history items that interacted with the user into a conversational format.
We take the text information of one item in the user target interaction as the training targets.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2. </span>The quantitative metrics results of LLM-based generative recommendation model.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.1" style="width:433.6pt;height:99pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(59.1pt,-13.5pt) scale(1.37450843596057,1.37450843596057) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T2.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.1.1.1.1.1">Model</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.1.1.1.1.2">LLM Weights</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.1.1.3">H@50</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.1.1.4">R@50</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.1.1.5">H@100</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.1.1.6">R@100</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.1.1.2.1.1">Baseline-v1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T2.1.1.2.1.2">frozen</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2.1.3">0.0069</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2.1.4">0.0154</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2.1.5">0.0101</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.2.1.6">0.0210</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.1.1.3.2.1">Baseline-v2</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T2.1.1.3.2.2">learnable</th>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.3.2.3">0.0134</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.3.2.4">0.0208</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.3.2.5">0.0180</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.1.3.2.6">0.0262</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.1.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S4.T2.1.1.4.3.1">LEARN (Ours)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S4.T2.1.1.4.3.2">frozen</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.1.4.3.3"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.4.3.3.1">0.0440</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.1.4.3.4"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.4.3.4.1">0.0610</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.1.4.3.5"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.4.3.5.1">0.0701</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T2.1.1.4.3.6"><span class="ltx_text ltx_font_bold" id="S4.T2.1.1.4.3.6.1">0.0905</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S4.SS3.SSS2.p3">
<p class="ltx_p" id="S4.SS3.SSS2.p3.1">Experiment results are reported in Tab.<a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.T2" title="Table 2 ‣ 4.3.2. Comparison with previous ”Rec-to-LLM” method (RQ2) ‣ 4.3. Offline Results ‣ 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">2</span></a>. We observed that baseline v1 performed the worst. This can be attributed to the fact that the pre-training data for LLM is sourced from open-world domain text. By directly applying Baseline-v1, which utilizes the output features of LLM with frozen parameters as user embeddings, these embeddings lack collaborative knowledge of the recommendation domain, rendering them unsuitable for recommendation tasks.
Despite the improvement compared to Baseline-v1 on H@100, the performance of Baseline-v2 remains far from our proposed LEARN method after finetuning LLM on conversational text data. We believe that the domain gap between collaborative and open-world knowledge leads to catastrophic forgetting of open-world knowledge when finetuning LLM on large-scale textualized recommendation data. Particularly, our training data is collected from real-world recommendation scenarios in the industry, where a significant amount of noise exists in recommendation data, exacerbating the catastrophic forgetting phenomenon. This is why the performance of baseline v2 is unsatisfactory.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS2.p4">
<p class="ltx_p" id="S4.SS3.SSS2.p4.1">The proposed Baseline-v2 follows a similar pattern to previous works in integrating LLM into recommendation systems. However, we observed that our conclusions differ from those of previous methods. This can be attributed to several reasons. Firstly, previous methods are validated on public datasets such as MovieLens <cite class="ltx_cite ltx_citemacro_citep">(Harper and Konstan, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib13" title="">2015</a>)</cite> and Beauty <cite class="ltx_cite ltx_citemacro_citep">(He and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib16" title="">2016</a>)</cite>, which are relatively small in scale and consist of clean, curated data that may not reflect real-world industrial scenarios. For instance, the MovieLens-1M dataset contains only 6K users and 4K movies <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib25" title="">2023b</a>)</cite>, while the Amazon Beauty dataset contains only 22K users and 12K items <cite class="ltx_cite ltx_citemacro_citep">(Li et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib22" title="">2023</a>; Harte et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib14" title="">2023</a>)</cite>. In contrast, our dataset comprises 31 million items and 12 million users, reflecting a larger and more realistic industrial-scale scenario. Secondly, due to the small scale of the datasets and the cleanliness of the data, finetuning LLM does not lead to catastrophic forgetting. The world knowledge retained in LLM, along with its understanding and reasoning abilities regarding text content, can provide incremental information for traditional ID-based recommendation models. Therefore, sending textualized recommendation data into LLM and obtaining text descriptions of user preferences can enhance the performance of ”Rec-to-LLM” methods <cite class="ltx_cite ltx_citemacro_citep">(Bao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib4" title="">2023b</a>; Liao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib23" title="">2023</a>; Lin et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib25" title="">2023b</a>; Gao et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib12" title="">2023</a>; Liu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib26" title="">2023a</a>; Zhang et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib45" title="">2023</a>; Hou et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib19" title="">2024</a>; Ren et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib31" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.3. </span>Comparison with SOTA models proposed for industry scenarios (<span class="ltx_text ltx_font_bold" id="S4.SS3.SSS3.1.1">RQ3</span>)</h4>
<div class="ltx_para" id="S4.SS3.SSS3.p1">
<p class="ltx_p" id="S4.SS3.SSS3.p1.1">Considering that our method is designed for practical industrial applications, we conduct comparisons with previous SOTA methods aimed at industrial use. To closely approximate real-world industrial scenarios, we chose the Amazon Book Reviews 2014 <span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_href" href="https://jmcauley.ucsd.edu/data/amazon/" title="">https://jmcauley.ucsd.edu/data/amazon/</a></span></span></span>, which comprises 22M reviews of 8M users about 2M books, as the evaluation dataset. To make a fair comparison, we follow the same data processing and evaluation settings as the HSTU <cite class="ltx_cite ltx_citemacro_citep">(Zhai et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib44" title="">2024</a>)</cite>. As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.T3" title="Table 3 ‣ 4.3.3. Comparison with SOTA models proposed for industry scenarios (RQ3) ‣ 4.3. Offline Results ‣ 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">3</span></a>, compared to the SASRec <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib21" title="">2018</a>)</cite>, we achieve significant performance improvement in all six metrics. Compared to the latest method HSTU <cite class="ltx_cite ltx_citemacro_citep">(Zhai et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib44" title="">2024</a>)</cite>, we achieve a 2.92% and 9.72% improvement on H@50 and H@200, a 10.38% and 6.08% improvement on N@50 and N@200, while slight low performance is achieved on H@10 and N@10. The reasons why our LEARN and HSTU <cite class="ltx_cite ltx_citemacro_citep">(Zhai et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib44" title="">2024</a>)</cite> perform differently in the top 10, top 50, and top 200 metrics are as follows.
Models with ID embedding typically capture specific identity information of users or items closely tied to their historical interactions. This method focuses on utilizing historical interaction data, which may yield better predictive outcomes for items that are frequently interacted with, popular, or often engaged by specific user groups. Consequently, for smaller recommendation candidates (such as the top 10), models with ID embedding can more accurately identify items with high relevance. Models with content embeddings focus on the textual descriptions of items. This approach enables the model to understand and recommend items that are content-similar yet may not have been frequently interacted with. This method is particularly effective in larger recommendation lists (such as the top 50 or top 100), as it allows for the exploration of a broader range of items, including those that may receive less user attention but have high content relevance. Compared to SASRec <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib21" title="">2018</a>)</cite> and HSTU <cite class="ltx_cite ltx_citemacro_citep">(Zhai et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib44" title="">2024</a>)</cite> based on ID embeddings, our proposed LEARN shows a significant performance improvement, indicating the effectiveness of our method and the information richness of the content representations generated by LLM.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3. </span>Comparison with SOTA methods. Hit rate (H) and NDCG (N) are adopted as the metrics. We report the performance improvement compared with SASRec.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T3.1" style="width:433.6pt;height:123.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-36.1pt,10.3pt) scale(0.857142848525067,0.857142848525067) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T3.1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T3.1.1.1.1.1">Method</th>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T3.1.1.1.1.2">H@10</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T3.1.1.1.1.3">H@50</td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="S4.T3.1.1.1.1.4">H@200</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.1.1.2.2.1">SASRec <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib21" title="">2018</a>)</cite>
</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.1.2.2.2">0.0306</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.1.2.2.3">0.0754</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.1.2.2.4">0.1431</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T3.1.1.3.3.1">HSTU <cite class="ltx_cite ltx_citemacro_citep">(Zhai et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib44" title="">2024</a>)</cite>
</th>
<td class="ltx_td ltx_align_left" id="S4.T3.1.1.3.3.2">
<span class="ltx_text ltx_font_bold" id="S4.T3.1.1.3.3.2.1">0.0416</span> (+35.95%)</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.1.3.3.3">0.0957 (+26.92%)</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.1.3.3.4">0.1735 (+21.24%)</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.4.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T3.1.1.4.4.1">LEARN (Ours)</th>
<td class="ltx_td ltx_align_left" id="S4.T3.1.1.4.4.2">0.0407 (+33.01%)</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.1.4.4.3">
<span class="ltx_text ltx_font_bold" id="S4.T3.1.1.4.4.3.1">0.0979</span>(+29.84%)</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.1.4.4.4">
<span class="ltx_text ltx_font_bold" id="S4.T3.1.1.4.4.4.1">0.1874</span> (+30.96%)</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.5.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.1.1.5.5.1">–</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.1.5.5.2">N@10</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.1.5.5.3">N@50</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.1.5.5.4">N@200</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.6.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.1.1.6.6.1">SASRec <cite class="ltx_cite ltx_citemacro_citep">(Kang and McAuley, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib21" title="">2018</a>)</cite>
</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.1.6.6.2">0.0164</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.1.6.6.3">0.0260</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.1.6.6.4">0.0362</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.7.7">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T3.1.1.7.7.1">HSTU <cite class="ltx_cite ltx_citemacro_citep">(Zhai et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib44" title="">2024</a>)</cite>
</th>
<td class="ltx_td ltx_align_left" id="S4.T3.1.1.7.7.2">
<span class="ltx_text ltx_font_bold" id="S4.T3.1.1.7.7.2.1">0.0227</span> (+38.41%)</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.1.7.7.3">0.0344 (+32.31%)</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.1.7.7.4">0.0461 (+27.35%)</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.1.8.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T3.1.1.8.8.1">LEARN (Ours)</th>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T3.1.1.8.8.2">0.0224 (+36.59%)</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T3.1.1.8.8.3">
<span class="ltx_text ltx_font_bold" id="S4.T3.1.1.8.8.3.1">0.0371</span> (+42.69%)</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T3.1.1.8.8.4">
<span class="ltx_text ltx_font_bold" id="S4.T3.1.1.8.8.4.1">0.0483</span> (+33.43%)</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS3.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.3.4. </span>Ablation studies of modules within the LEARN framework (<span class="ltx_text ltx_font_bold" id="S4.SS3.SSS4.1.1">RQ4</span>)</h4>
<figure class="ltx_table" id="S4.T4">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4. </span>Ablation studies of item tower in the LEARN framework on the offline dataset. Item tower v1 is adopted as the default settings.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T4.1" style="width:346.9pt;height:100.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(48.9pt,-14.1pt) scale(1.39240161951334,1.39240161951334) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T4.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.1.1.1.1.1">Item Tower</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.1.1.1.1.2">H@50</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.1.1.1.1.3">R@50</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.1.1.1.1.4">H@100</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T4.1.1.1.1.5">R@100</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.1.1.2.1.1">Variant 3</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.2.1.2">NaN</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.2.1.3">NaN</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.2.1.4">NaN</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.1.2.1.5">NaN</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.1.1.3.2.1">Variant 2</th>
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.3.2.2">0.0313</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.3.2.3">0.0488</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.3.2.4">0.0505</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.1.3.2.5">0.0675</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S4.T4.1.1.4.3.1">Variant 1 (Ours)</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.1.1.4.3.2"><span class="ltx_text ltx_font_bold" id="S4.T4.1.1.4.3.2.1">0.0440</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.1.1.4.3.3"><span class="ltx_text ltx_font_bold" id="S4.T4.1.1.4.3.3.1">0.0610</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.1.1.4.3.4"><span class="ltx_text ltx_font_bold" id="S4.T4.1.1.4.3.4.1">0.0701</span></td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T4.1.1.4.3.5"><span class="ltx_text ltx_font_bold" id="S4.T4.1.1.4.3.5.1">0.0905</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S4.SS3.SSS4.p1">
<p class="ltx_p" id="S4.SS3.SSS4.p1.1">We design three variants to verify the necessity of our item tower structure. Experimental results are presented in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.T4" title="Table 4 ‣ 4.3.4. Ablation studies of modules within the LEARN framework (RQ4) ‣ 4.3. Offline Results ‣ 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">4</span></a>. Variant 3, which directly utilizes content embeddings from LLMs as item embeddings, suffers from model non-convergence. This is attributed to significant architectural differences between the user and item towers, as well as the domain gap between the LLM-generated content embeddings and the item embeddings required for recommendation tasks. In contrast, while Variant 2 with the self-attention mechanism performs less effectively, Variant 1, which incorporates the causal attention mechanism, notably enhances the item embedding representation by integrating features from previous item embeddings.
Consequently, we have selected Variant 1, depicted in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S3.F3" title="Figure 3 ‣ 3.1. Content Embedding of LLM ‣ 3. Method ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">3</span></a>(a), as the standard architecture for our LEARN framework.</p>
</div>
<figure class="ltx_table" id="S4.T5">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5. </span>Ablation studies of the PCH module.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T5.1" style="width:433.6pt;height:140.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(41.9pt,-13.6pt) scale(1.23960071708934,1.23960071708934) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T5.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T5.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T5.1.1.1.1.1">
<table class="ltx_tabular ltx_align_middle" id="S4.T5.1.1.1.1.1.1">
<tr class="ltx_tr" id="S4.T5.1.1.1.1.1.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.1.1.1.1.1.1.1.1">Backbone</td>
</tr>
</table>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T5.1.1.1.1.2">
<table class="ltx_tabular ltx_align_middle" id="S4.T5.1.1.1.1.2.1">
<tr class="ltx_tr" id="S4.T5.1.1.1.1.2.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.1.1.1.1.2.1.1.1">Parameter</td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.1.1.1.2.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.1.1.1.1.2.1.2.1">Initialization</td>
</tr>
</table>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T5.1.1.1.1.3">
<table class="ltx_tabular ltx_align_middle" id="S4.T5.1.1.1.1.3.1">
<tr class="ltx_tr" id="S4.T5.1.1.1.1.3.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.1.1.1.1.3.1.1.1">Training</td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.1.1.1.3.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.1.1.1.1.3.1.2.1">mode</td>
</tr>
</table>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T5.1.1.1.1.4">
<table class="ltx_tabular ltx_align_middle" id="S4.T5.1.1.1.1.4.1">
<tr class="ltx_tr" id="S4.T5.1.1.1.1.4.1.1">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.1.1.1.1.4.1.1.1">Trainable</td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.1.1.1.4.1.2">
<td class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T5.1.1.1.1.4.1.2.1">parameters</td>
</tr>
</table>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T5.1.1.1.1.5">H@100</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T5.1.1.1.1.6">R@100</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T5.1.1.2.1">
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T5.1.1.2.1.1" rowspan="3"><span class="ltx_text" id="S4.T5.1.1.2.1.1.1">LLM</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.1.2.1.2" rowspan="3"><span class="ltx_text" id="S4.T5.1.1.2.1.2.1">Pre-train</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.1.2.1.3" rowspan="3"><span class="ltx_text" id="S4.T5.1.1.2.1.3.1">LoRA</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T5.1.1.2.1.4">134M</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.1.2.1.5">0.0376</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.1.1.2.1.6">0.0560</td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.1.3.2">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.1.1.3.2.1">286M</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.1.3.2.2">0.0504</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.1.3.2.3">0.0709</td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.1.4.3">
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.1.1.4.3.1">572M</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.1.4.3.2">0.0513</td>
<td class="ltx_td ltx_align_center" id="S4.T5.1.1.4.3.3">0.0720</td>
</tr>
<tr class="ltx_tr" id="S4.T5.1.1.5.4">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S4.T5.1.1.5.4.1">Transformer</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T5.1.1.5.4.2">Random Init.</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T5.1.1.5.4.3">Finetuning</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="S4.T5.1.1.5.4.4">100M</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T5.1.1.5.4.5"><span class="ltx_text ltx_font_bold" id="S4.T5.1.1.5.4.5.1">0.0701</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T5.1.1.5.4.6"><span class="ltx_text ltx_font_bold" id="S4.T5.1.1.5.4.6.1">0.0905</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S4.SS3.SSS4.p2">
<p class="ltx_p" id="S4.SS3.SSS4.p2.1">Given extensive world knowledge and superior abilities of LLM in text comprehension and common-sense reasoning, we attempted to replace the transformer layers in the PCH module in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S3.F3" title="Figure 3 ‣ 3.1. Content Embedding of LLM ‣ 3. Method ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">3</span></a> with LLM to further explore its utilization. We finetune the LLM with LoRA <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib20" title="">2021</a>)</cite> and make different LoRA <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib20" title="">2021</a>)</cite> settings to change the amount of trainable parameters. The experiment results are shown in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.T5" title="Table 5 ‣ 4.3.4. Ablation studies of modules within the LEARN framework (RQ4) ‣ 4.3. Offline Results ‣ 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">5</span></a>. As the number of trainable parameters increased from 134M to 572M, the performance of finetuning LLM using LoRA improved from 0.0376 to 0.0513, representing a 36.4 % enhancement. However, this performance still exhibits a significant gap compared to using transformer layers as the backbone, which is trained from scratch. The analysis of this discrepancy is as follows. LoRA <cite class="ltx_cite ltx_citemacro_citep">(Hu et al<span class="ltx_text">.</span>, <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#bib.bib20" title="">2021</a>)</cite> introduces additional trainable parameters to generate new features, which are combined with the features obtained from the original parameters to serve as the final feature for the LoRA finetuning model. Consequently, the model’s output feature is a mixture of the original features trained in the open-world domain and the LoRA features trained in the recommendation domain. Additionally, the original features dominate because the LLM has more frozen parameters compared to the trainable LoRA parameters.
However, a substantial domain gap exists between the open-world knowledge embedded in LLM’s original pretrained parameters and the collaborative knowledge in LoRA parameters. We conclude this mixed feature is inferior for recommendation tasks.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4. </span>Ranking A/B Experiments</h3>
<div class="ltx_para" id="S4.SS4.p1">
<p class="ltx_p" id="S4.SS4.p1.1">We test the LEARN framework in A/B experiments of the ranking model, and deploy our method in the short video feed advertising scenario of KuaiShou App since Jan. 2024.</p>
</div>
<section class="ltx_subsubsection" id="S4.SS4.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.1. </span>Model Structure</h4>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S4.F5.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5. </span>Illustration of Online model structure. The LEARN embedding denotes the user and item embedding generated by the proposed LEARN framework. The ID embedding denotes the conventional sparse embedding.</figcaption>
</figure>
<div class="ltx_para" id="S4.SS4.SSS1.p1">
<p class="ltx_p" id="S4.SS4.SSS1.p1.1">To enhance the integration of LLM-based user and item embeddings generated by the LEARN framework with the ID embeddings used in online RS, we have integrated an auxiliary network into the existing online model architecture. This addition aims to merge these diverse embedding types more effectively, enhancing the overall synergy of the system. As illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.F5" title="Figure 5 ‣ 4.4.1. Model Structure ‣ 4.4. Ranking A/B Experiments ‣ 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">5</span></a>, the auxiliary network employs a CVR loss to guide the aggregation of user and item embeddings produced by LEARN approach. These embeddings are then amalgamated with ID embeddings and a fusion embedding – created by the MLP layers of the auxiliary network – as inputs to the main tower of the online RS.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S4.SS4.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.2. </span>AUC Evaluation</h4>
<div class="ltx_para" id="S4.SS4.SSS2.p1">
<p class="ltx_p" id="S4.SS4.SSS2.p1.1">We conduct offline AUC evaluations using a billion-scale dataset from the KuaiShou e-commerce platform. The training dataset, sampled on December 7, 2023, includes interactions involving 300 million users and 10 million e-commerce products, while the testing data is collected the following day. Our evaluation utilizes two metrics: UAUC and WUAUC, where UAUC represents the average AUC for each user with both positive and negative samples, and WUAUC is the weighted average of UAUC based on the sample count per user. We follow the common practice in the industry to adopt UAUC and WUAUC instead of AUC because these metrics can better evaluate the ranking performance for each user and then can better reflect the user experience. Specifically, UAUC further reflects the performances on long-tail
users since it uses uniform weights.</p>
</div>
<figure class="ltx_table" id="S4.T6">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6. </span>The AUC results on KuaiShou App data.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T6.1" style="width:346.9pt;height:72.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(44.4pt,-9.3pt) scale(1.3436923049826,1.3436923049826) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T6.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T6.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T6.1.1.1.1.1">Method</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T6.1.1.1.1.2">UAUC</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T6.1.1.1.1.3">WUAUC</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T6.1.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T6.1.1.2.1.1">Baseline</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.1.1.2.1.2">0.6885</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T6.1.1.2.1.3">0.7002</td>
</tr>
<tr class="ltx_tr" id="S4.T6.1.1.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S4.T6.1.1.3.2.1">LEARN (Ours)</th>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T6.1.1.3.2.2">0.6969 (+0.84pp)</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T6.1.1.3.2.3">0.7078 (+0.76pp)</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S4.SS4.SSS2.p2">
<p class="ltx_p" id="S4.SS4.SSS2.p2.1">As depicted in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.T6" title="Table 6 ‣ 4.4.2. AUC Evaluation ‣ 4.4. Ranking A/B Experiments ‣ 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">6</span></a>, compared to the baseline model, our method achieves improvements of 0.84 percentage points (pp) and 0.76pp in UAUC and WUAUC, respectively. We hypothesize that the observed improvements in UAUC and WUAUC can be attributed to the superior generalization capabilities of the LEARN framework, which effectively captures the interests of long-tail users. To validate this hypothesis, we have implemented a more comprehensive experimental analysis through online A/B testing.</p>
</div>
<figure class="ltx_figure" id="S4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" id="S4.F6.g1" src=""/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6. </span>CVR and Revenue improvements during A/B testing. Compared to the baseline method, our method achieves a steady and significant increase in Revenue and CVR. </figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="S4.SS4.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.3. </span>Online Revenue Improvement</h4>
<div class="ltx_para" id="S4.SS4.SSS3.p1">
<p class="ltx_p" id="S4.SS4.SSS3.p1.1">We conduct an online A/B test on the KuaiShou App, a popular short-video streaming platform with daily active users (DAU) exceeding 300 million.</p>
</div>
<div class="ltx_para" id="S4.SS4.SSS3.p2">
<p class="ltx_p" id="S4.SS4.SSS3.p2.1">We allocate 20% of the platform’s traffic to our proposed and baseline models. The experiments are deployed in a real-time system over a span of 9 days, and the outcomes are depicted in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.F6" title="Figure 6 ‣ 4.4.2. AUC Evaluation ‣ 4.4. Ranking A/B Experiments ‣ 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">6</span></a>. We observe a steady and significant increase in Revenue and CVR. Given that the revenue for online recommendation models is measured in tens of millions, an improvement of just 2% is quite significant.</p>
</div>
<figure class="ltx_table" id="S4.T7">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7. </span>A/B test results for different user and item types. ”Proportion” indicates the percentage of users (items) within each category, relative to the total number of users (items).</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T7.1" style="width:346.9pt;height:174.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(48.2pt,-24.2pt) scale(1.38451025295552,1.38451025295552) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T7.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T7.1.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T7.1.1.1.1.1">Level</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T7.1.1.1.1.2">Type</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T7.1.1.1.1.3">Proportion</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T7.1.1.1.1.4">Revenue</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T7.1.1.1.1.5">AUC</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T7.1.1.2.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T7.1.1.2.1.1" rowspan="3"><span class="ltx_text" id="S4.T7.1.1.2.1.1.1">User</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T7.1.1.2.1.2">cold-start</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.1.1.2.1.3">7.16%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.1.1.2.1.4">+1.56%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.1.1.2.1.5">+0.17pp</td>
</tr>
<tr class="ltx_tr" id="S4.T7.1.1.3.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T7.1.1.3.2.1">long-tail</th>
<td class="ltx_td ltx_align_center" id="S4.T7.1.1.3.2.2">27.54%</td>
<td class="ltx_td ltx_align_center" id="S4.T7.1.1.3.2.3">+5.79%</td>
<td class="ltx_td ltx_align_center" id="S4.T7.1.1.3.2.4">+0.68pp</td>
</tr>
<tr class="ltx_tr" id="S4.T7.1.1.4.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T7.1.1.4.3.1">others</th>
<td class="ltx_td ltx_align_center" id="S4.T7.1.1.4.3.2">65.30%</td>
<td class="ltx_td ltx_align_center" id="S4.T7.1.1.4.3.3">+0.32%</td>
<td class="ltx_td ltx_align_center" id="S4.T7.1.1.4.3.4">+0.021pp</td>
</tr>
<tr class="ltx_tr" id="S4.T7.1.1.5.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r ltx_border_t" id="S4.T7.1.1.5.4.1" rowspan="3"><span class="ltx_text" id="S4.T7.1.1.5.4.1.1">Item</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T7.1.1.5.4.2">cold-start</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.1.1.5.4.3">3.15%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.1.1.5.4.4">+8.77%</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.1.1.5.4.5">+0.29pp</td>
</tr>
<tr class="ltx_tr" id="S4.T7.1.1.6.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T7.1.1.6.5.1">long-tail</th>
<td class="ltx_td ltx_align_center" id="S4.T7.1.1.6.5.2">26.47%</td>
<td class="ltx_td ltx_align_center" id="S4.T7.1.1.6.5.3">+4.63%</td>
<td class="ltx_td ltx_align_center" id="S4.T7.1.1.6.5.4">+0.21pp</td>
</tr>
<tr class="ltx_tr" id="S4.T7.1.1.7.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S4.T7.1.1.7.6.1">others</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T7.1.1.7.6.2">70.38%</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T7.1.1.7.6.3">+0.35%</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T7.1.1.7.6.4">+0.01pp</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_para" id="S4.SS4.SSS3.p3">
<p class="ltx_p" id="S4.SS4.SSS3.p3.1">As illustrated in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.T7" title="Table 7 ‣ 4.4.3. Online Revenue Improvement ‣ 4.4. Ranking A/B Experiments ‣ 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">7</span></a>, we categorize users based on their interaction data over the past six months, including product clicks, impressions, and purchase frequencies. Specifically, users with no recorded interactions are identified as cold-start users, those with 1 to 35 interactions are classified as long-tail users, and those with more than 35 interactions are grouped as others. Our results indicate significant performance enhancements by our proposed LEARN, especially among the cold-start and long-tail user segments.</p>
</div>
<div class="ltx_para" id="S4.SS4.SSS3.p4">
<p class="ltx_p" id="S4.SS4.SSS3.p4.1">We also categorize products into three tiers based on their purchase history: Cold-start products, which have no prior purchases; Long-tail products, purchased no more than 30 times in the past week; Other products, purchased more than 30 times during the same timeframe. As depicted in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2405.03988v1#S4.T7" title="Table 7 ‣ 4.4.3. Online Revenue Improvement ‣ 4.4. Ranking A/B Experiments ‣ 4. EXPERIMENTS ‣ Knowledge Adaptation from Large Language Model to Recommendation for Practical Industrial Application"><span class="ltx_text ltx_ref_tag">7</span></a>, our proposed method significantly improves revenue and AUC performance for cold-start and long-tail products. These enhancements are attributed to the robust representations LEARN generates for products with sparse purchase histories.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this work, we explore the integration of Large Language Models (LLMs) with recommendation systems and develop an approach that successfully combines LLMs with real-world industrial recommendation scenarios, resulting in significant business benefits. We introduce the LEARN framework, which follows a twin-tower structure, and design the CEG module based on LLMs to extract item content embedding from the text description. Additionally, we develop a transformer-based PCH module and adopt recommendation tasks as the training target, facilitating the domain adaptation from open-world knowledge of LLMs to the collaborative knowledge of RS. Our method’s effectiveness is demonstrated through substantial results on the large-scale real-world recommendation dataset and public academic dataset.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baichuan (2023)</span>
<span class="ltx_bibblock">
Baichuan. 2023.

</span>
<span class="ltx_bibblock">Baichuan 2: Open Large-scale Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2309.10305</em> (2023).

</span>
<span class="ltx_bibblock">
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2309.10305" title="">https://arxiv.org/abs/2309.10305</a>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bao et al<span class="ltx_text" id="bib.bib3.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Keqin Bao, Jizhi Zhang, Wenjie Wang, Yang Zhang, Zhengyi Yang, Yancheng Luo, Fuli Feng, Xiangnaan He, and Qi Tian. 2023a.

</span>
<span class="ltx_bibblock">A bi-step grounding paradigm for large language models in recommendation systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.3.1">arXiv preprint arXiv:2308.08434</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bao et al<span class="ltx_text" id="bib.bib4.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Keqin Bao, Jizhi Zhang, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He. 2023b.

</span>
<span class="ltx_bibblock">Tallrec: An effective and efficient tuning framework to align large language model with recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib4.3.1">Proceedings of the 17th ACM Conference on Recommender Systems</em>. 1007–1014.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span class="ltx_text" id="bib.bib5.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Shuwei Chen, Xiang Li, Jian Dong, Jin Zhang, Yongkang Wang, and Xingxing Wang. 2023.

</span>
<span class="ltx_bibblock">TBIN: Modeling Long Textual Behavior Data for CTR Prediction.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.3.1">arXiv preprint arXiv:2308.08483</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chiang et al<span class="ltx_text" id="bib.bib6.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez, et al<span class="ltx_text" id="bib.bib6.3.1">.</span> 2023.

</span>
<span class="ltx_bibblock">Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt quality.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.4.1">See https://vicuna. lmsys. org (accessed 14 April 2023)</em> 2, 3 (2023), 6.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chowdhery et al<span class="ltx_text" id="bib.bib7.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al<span class="ltx_text" id="bib.bib7.3.1">.</span> 2023.

</span>
<span class="ltx_bibblock">Palm: Scaling language modeling with pathways.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.4.1">Journal of Machine Learning Research</em> 24, 240 (2023), 1–113.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al<span class="ltx_text" id="bib.bib8.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.3.1">arXiv preprint arXiv:1810.04805</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dosovitskiy et al<span class="ltx_text" id="bib.bib9.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn, Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg Heigold, Sylvain Gelly, et al<span class="ltx_text" id="bib.bib9.3.1">.</span> 2020.

</span>
<span class="ltx_bibblock">An image is worth 16x16 words: Transformers for image recognition at scale.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.4.1">arXiv preprint arXiv:2010.11929</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan et al<span class="ltx_text" id="bib.bib10.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Wenqi Fan, Zihuai Zhao, Jiatong Li, Yunqing Liu, Xiaowei Mei, Yiqi Wang, Jiliang Tang, and Qing Li. 2023a.

</span>
<span class="ltx_bibblock">Recommender systems in the era of large language models (llms).

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.3.1">arXiv preprint arXiv:2307.02046</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fan et al<span class="ltx_text" id="bib.bib11.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Wenqi Fan, Zihuai Zhao, Jiatong Li, Yunqing Liu, Xiaowei Mei, Yiqi Wang, Jiliang Tang, and Qing Li. 2023b.

</span>
<span class="ltx_bibblock">Recommender systems in the era of large language models (llms).

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.3.1">arXiv preprint arXiv:2307.02046</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al<span class="ltx_text" id="bib.bib12.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yunfan Gao, Tao Sheng, Youlin Xiang, Yun Xiong, Haofen Wang, and Jiawei Zhang. 2023.

</span>
<span class="ltx_bibblock">Chat-rec: Towards interactive and explainable llms-augmented recommender system.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.3.1">arXiv preprint arXiv:2303.14524</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Harper and Konstan (2015)</span>
<span class="ltx_bibblock">
F Maxwell Harper and Joseph A Konstan. 2015.

</span>
<span class="ltx_bibblock">The movielens datasets: History and context.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Acm transactions on interactive intelligent systems (tiis)</em> 5, 4 (2015), 1–19.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Harte et al<span class="ltx_text" id="bib.bib14.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Jesse Harte, Wouter Zorgdrager, Panos Louridas, Asterios Katsifodimos, Dietmar Jannach, and Marios Fragkoulis. 2023.

</span>
<span class="ltx_bibblock">Leveraging large language models for sequential recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib14.3.1">Proceedings of the 17th ACM Conference on Recommender Systems</em>. 1096–1102.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al<span class="ltx_text" id="bib.bib15.2.2.1">.</span> (2016)</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016.

</span>
<span class="ltx_bibblock">Deep residual learning for image recognition. In <em class="ltx_emph ltx_font_italic" id="bib.bib15.3.1">Proceedings of the IEEE conference on computer vision and pattern recognition</em>. 770–778.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He and McAuley (2016)</span>
<span class="ltx_bibblock">
Ruining He and Julian McAuley. 2016.

</span>
<span class="ltx_bibblock">Ups and downs: Modeling the visual evolution of fashion trends with one-class collaborative filtering. In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">proceedings of the 25th international conference on world wide web</em>. 507–517.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al<span class="ltx_text" id="bib.bib17.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Zhankui He, Zhouhang Xie, Rahul Jha, Harald Steck, Dawen Liang, Yesu Feng, Bodhisattwa Prasad Majumder, Nathan Kallus, and Julian McAuley. 2023.

</span>
<span class="ltx_bibblock">Large language models as zero-shot conversational recommenders. In <em class="ltx_emph ltx_font_italic" id="bib.bib17.3.1">Proceedings of the 32nd ACM international conference on information and knowledge management</em>. 720–730.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hou et al<span class="ltx_text" id="bib.bib18.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Yupeng Hou, Shanlei Mu, Wayne Xin Zhao, Yaliang Li, Bolin Ding, and Ji-Rong Wen. 2022.

</span>
<span class="ltx_bibblock">Towards universal sequence representation learning for recommender systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib18.3.1">Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>. 585–593.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hou et al<span class="ltx_text" id="bib.bib19.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Yupeng Hou, Junjie Zhang, Zihan Lin, Hongyu Lu, Ruobing Xie, Julian McAuley, and Wayne Xin Zhao. 2024.

</span>
<span class="ltx_bibblock">Large language models are zero-shot rankers for recommender systems. In <em class="ltx_emph ltx_font_italic" id="bib.bib19.3.1">European Conference on Information Retrieval</em>. Springer, 364–381.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al<span class="ltx_text" id="bib.bib20.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2021.

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.3.1">arXiv preprint arXiv:2106.09685</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kang and McAuley (2018)</span>
<span class="ltx_bibblock">
Wang-Cheng Kang and Julian McAuley. 2018.

</span>
<span class="ltx_bibblock">Self-attentive sequential recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">2018 IEEE international conference on data mining (ICDM)</em>. IEEE, 197–206.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span class="ltx_text" id="bib.bib22.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Jinming Li, Wentao Zhang, Tian Wang, Guanglei Xiong, Alan Lu, and Gerard Medioni. 2023.

</span>
<span class="ltx_bibblock">GPT4Rec: A generative framework for personalized recommendation and user interests interpretation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.3.1">arXiv preprint arXiv:2304.03879</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liao et al<span class="ltx_text" id="bib.bib23.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Jiayi Liao, Sihang Li, Zhengyi Yang, Jiancan Wu, Yancheng Yuan, Xiang Wang, and Xiangnan He. 2023.

</span>
<span class="ltx_bibblock">Llara: Aligning large language models with sequential recommenders.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.3.1">arXiv preprint arXiv:2312.02445</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al<span class="ltx_text" id="bib.bib24.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Jianghao Lin, Xinyi Dai, Yunjia Xi, Weiwen Liu, Bo Chen, Xiangyang Li, Chenxu Zhu, Huifeng Guo, Yong Yu, Ruiming Tang, et al<span class="ltx_text" id="bib.bib24.3.1">.</span> 2023a.

</span>
<span class="ltx_bibblock">How can recommender systems benefit from large language models: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.4.1">arXiv preprint arXiv:2306.05817</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al<span class="ltx_text" id="bib.bib25.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Jianghao Lin, Rong Shan, Chenxu Zhu, Kounianhua Du, Bo Chen, Shigang Quan, Ruiming Tang, Yong Yu, and Weinan Zhang. 2023b.

</span>
<span class="ltx_bibblock">Rella: Retrieval-enhanced large language models for lifelong sequential behavior comprehension in recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.3.1">arXiv preprint arXiv:2308.11131</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span class="ltx_text" id="bib.bib26.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Junling Liu, Chao Liu, Renjie Lv, Kang Zhou, and Yan Zhang. 2023a.

</span>
<span class="ltx_bibblock">Is chatgpt a good recommender? a preliminary study.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.3.1">arXiv preprint arXiv:2304.10149</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span class="ltx_text" id="bib.bib27.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Qiang Liu, Zhaocheng Liu, Zhenxi Zhu, Shu Wu, and Liang Wang. 2023b.

</span>
<span class="ltx_bibblock">Deep Stable Multi-Interest Learning for Out-of-distribution Sequential Recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.3.1">arXiv preprint arXiv:2304.05615</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lyu et al<span class="ltx_text" id="bib.bib28.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Hanjia Lyu, Song Jiang, Hanqing Zeng, Yinglong Xia, and Jiebo Luo. 2023.

</span>
<span class="ltx_bibblock">Llm-rec: Personalized recommendation via prompting large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.3.1">arXiv preprint arXiv:2307.15780</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oord et al<span class="ltx_text" id="bib.bib29.2.2.1">.</span> (2018)</span>
<span class="ltx_bibblock">
Aaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018.

</span>
<span class="ltx_bibblock">Representation learning with contrastive predictive coding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.3.1">arXiv preprint arXiv:1807.03748</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pancha et al<span class="ltx_text" id="bib.bib30.2.2.1">.</span> (2022)</span>
<span class="ltx_bibblock">
Nikil Pancha, Andrew Zhai, Jure Leskovec, and Charles Rosenberg. 2022.

</span>
<span class="ltx_bibblock">PinnerFormer: Sequence Modeling for User Representation at Pinterest. In <em class="ltx_emph ltx_font_italic" id="bib.bib30.3.1">Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em>. 3702–3712.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ren et al<span class="ltx_text" id="bib.bib31.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Xubin Ren, Wei Wei, Lianghao Xia, Lixin Su, Suqi Cheng, Junfeng Wang, Dawei Yin, and Chao Huang. 2023.

</span>
<span class="ltx_bibblock">Representation learning with large language models for recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib31.3.1">arXiv preprint arXiv:2310.15950</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sanner et al<span class="ltx_text" id="bib.bib32.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Scott Sanner, Krisztian Balog, Filip Radlinski, Ben Wedin, and Lucas Dixon. 2023.

</span>
<span class="ltx_bibblock">Large language models are competitive near cold-start recommenders for language-and item-based preferences. In <em class="ltx_emph ltx_font_italic" id="bib.bib32.3.1">Proceedings of the 17th ACM conference on recommender systems</em>. 890–896.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al<span class="ltx_text" id="bib.bib33.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Haizhou Shi, Zihao Xu, Hengyi Wang, Weiyi Qin, Wenyuan Wang, Yibin Wang, and Hao Wang. 2024.

</span>
<span class="ltx_bibblock">Continual Learning of Large Language Models: A Comprehensive Survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.3.1">arXiv preprint arXiv:2404.16789</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan et al<span class="ltx_text" id="bib.bib34.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Juntao Tan, Shuyuan Xu, Wenyue Hua, Yingqiang Ge, Zelong Li, and Yongfeng Zhang. 2024.

</span>
<span class="ltx_bibblock">Towards LLM-RecSys Alignment with Textual ID Learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.3.1">arXiv preprint arXiv:2403.19021</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al<span class="ltx_text" id="bib.bib35.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al<span class="ltx_text" id="bib.bib35.3.1">.</span> 2023.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.4.1">arXiv preprint arXiv:2302.13971</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib36.2.2.1">.</span> (2023b)</span>
<span class="ltx_bibblock">
Jinpeng Wang, Ziyun Zeng, Yunxiao Wang, Yuting Wang, Xingyu Lu, Tianxiang Li, Jun Yuan, Rui Zhang, Hai-Tao Zheng, and Shu-Tao Xia. 2023b.

</span>
<span class="ltx_bibblock">Missrec: Pre-training and transferring multi-modal interest-aware sequence representation for recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib36.3.1">Proceedings of the 31st ACM International Conference on Multimedia</em>. 6548–6557.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span class="ltx_text" id="bib.bib37.2.2.1">.</span> (2023a)</span>
<span class="ltx_bibblock">
Yancheng Wang, Ziyan Jiang, Zheng Chen, Fan Yang, Yingxue Zhou, Eunah Cho, Xing Fan, Xiaojiang Huang, Yanbin Lu, and Yingzhen Yang. 2023a.

</span>
<span class="ltx_bibblock">Recmind: Large language model powered agent for recommendation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.3.1">arXiv preprint arXiv:2308.14296</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span class="ltx_text" id="bib.bib38.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Chuhan Wu, Fangzhao Wu, Tao Qi, and Yongfeng Huang. 2021.

</span>
<span class="ltx_bibblock">Empowering news recommendation with pre-trained language models. In <em class="ltx_emph ltx_font_italic" id="bib.bib38.3.1">Proceedings of the 44th international ACM SIGIR conference on research and development in information retrieval</em>. 1652–1656.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span class="ltx_text" id="bib.bib39.2.2.1">.</span> (2020)</span>
<span class="ltx_bibblock">
Fangzhao Wu, Ying Qiao, Jiun-Hung Chen, Chuhan Wu, Tao Qi, Jianxun Lian, Danyang Liu, Xing Xie, Jianfeng Gao, Winnie Wu, et al<span class="ltx_text" id="bib.bib39.3.1">.</span> 2020.

</span>
<span class="ltx_bibblock">Mind: A large-scale dataset for news recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib39.4.1">Proceedings of the 58th annual meeting of the association for computational linguistics</em>. 3597–3606.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xi et al<span class="ltx_text" id="bib.bib40.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Yunjia Xi, Weiwen Liu, Jianghao Lin, Jieming Zhu, Bo Chen, Ruiming Tang, Weinan Zhang, Rui Zhang, and Yong Yu. 2023.

</span>
<span class="ltx_bibblock">Towards open-world recommendation with knowledge augmentation from large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.3.1">arXiv preprint arXiv:2306.10933</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span class="ltx_text" id="bib.bib41.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Aiyuan Yang, Bin Xiao, Bingning Wang, Borong Zhang, Ce Bian, Chao Yin, Chenxu Lv, Da Pan, Dian Wang, Dong Yan, et al<span class="ltx_text" id="bib.bib41.3.1">.</span> 2023.

</span>
<span class="ltx_bibblock">Baichuan 2: Open large-scale language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.4.1">arXiv preprint arXiv:2309.10305</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan et al<span class="ltx_text" id="bib.bib42.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Zheng Yuan, Fajie Yuan, Yu Song, Youhua Li, Junchen Fu, Fei Yang, Yunzhu Pan, and Yongxin Ni. 2023.

</span>
<span class="ltx_bibblock">Where to go next for recommender systems? id-vs. modality-based recommender models revisited. In <em class="ltx_emph ltx_font_italic" id="bib.bib42.3.1">Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval</em>. 2639–2649.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yue et al<span class="ltx_text" id="bib.bib43.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Zhenrui Yue, Sara Rabhi, Gabriel de Souza Pereira Moreira, Dong Wang, and Even Oldridge. 2023.

</span>
<span class="ltx_bibblock">LlamaRec: Two-stage recommendation using large language models for ranking.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.3.1">arXiv preprint arXiv:2311.02089</em> (2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhai et al<span class="ltx_text" id="bib.bib44.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Jiaqi Zhai, Lucy Liao, Xing Liu, Yueming Wang, Rui Li, Xuan Cao, Leon Gao, Zhaojie Gong, Fangda Gu, Michael He, et al<span class="ltx_text" id="bib.bib44.3.1">.</span> 2024.

</span>
<span class="ltx_bibblock">Actions Speak Louder than Words: Trillion-Parameter Sequential Transducers for Generative Recommendations.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.4.1">arXiv preprint arXiv:2402.17152</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib45.2.2.1">.</span> (2023)</span>
<span class="ltx_bibblock">
Jizhi Zhang, Keqin Bao, Yang Zhang, Wenjie Wang, Fuli Feng, and Xiangnan He. 2023.

</span>
<span class="ltx_bibblock">Is chatgpt fair for recommendation? evaluating fairness in large language model recommendation. In <em class="ltx_emph ltx_font_italic" id="bib.bib45.3.1">Proceedings of the 17th ACM Conference on Recommender Systems</em>. 993–999.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib46.2.2.1">.</span> (2021)</span>
<span class="ltx_bibblock">
Qi Zhang, Jingjie Li, Qinglin Jia, Chuyuan Wang, Jieming Zhu, Zhaowei Wang, and Xiuqiang He. 2021.

</span>
<span class="ltx_bibblock">UNBERT: User-News Matching BERT for News Recommendation.. In <em class="ltx_emph ltx_font_italic" id="bib.bib46.3.1">IJCAI</em>, Vol. 21. 3356–3362.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span class="ltx_text" id="bib.bib47.2.2.1">.</span> (2024)</span>
<span class="ltx_bibblock">
Yabin Zhang, Wenhui Yu, Erhan Zhang, Xu Chen, Lantao Hu, Peng Jiang, and Kun Gai. 2024.

</span>
<span class="ltx_bibblock">RecGPT: Generative Personalized Prompts for Sequential Recommendation via ChatGPT Training Paradigm.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.3.1">arXiv preprint arXiv:2404.08675</em> (2024).

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed May 15 17:30:07 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
