<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2303.14544] Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey</title><meta property="og:description" content="Advancements in wearable medical devices in IoT technology are shaping the modern healthcare system. With the emergence of the Internet of Healthcare Things (IoHT), we are witnessing how efficient healthcare services a…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2303.14544">

<!--Generated on Thu Feb 29 19:02:42 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
Privacy enhancing technologies,  Internet of Healthcare Things,  Federated learning,  Security,  Privacy.
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: 
<br class="ltx_break">A Survey
<br class="ltx_break"><span id="id1.id1" class="ltx_note ltx_role_thanks"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">thanks: </span></span></span></span>
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Fatemeh Mosaiyebzadeh1, Seyedamin Pouriyeh2, Reza M. Parizi3,
Quan Z. Sheng4, Meng Han 5,

<br class="ltx_break">Liang Zhao2,
Giovanna Sannino 6, Daniel Macêdo Batista1
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">1 Department of Computer Science, University of São Paulo, Brazil

<br class="ltx_break"> {fatemehm, batista}@ime.usp.br
</span>
<span class="ltx_contact ltx_role_affiliation">2 Department of Information and Technology, Kennesaw State University, Marietta, GA, USA

<br class="ltx_break"> {spouriye, lzhao10}@kennesaw.edu
</span>
<span class="ltx_contact ltx_role_affiliation">3Decentralized Science Lab, Kennesaw State University, Marietta, GA, USA 
<br class="ltx_break">rparizi1@kennesaw.edu
</span>
<span class="ltx_contact ltx_role_affiliation">4 School of Computing, Macquarie University, Sydney, Australia 
<br class="ltx_break">michael.sheng@mq.edu.au 
</span>
<span class="ltx_contact ltx_role_affiliation">5 Binjiang Institute of Zhejiang University, Hangzhou, Zhejiang, China 
<br class="ltx_break">mhan@zju.edu.cn
</span>
<span class="ltx_contact ltx_role_affiliation">6 Institute of High Performance Computing and Networking, National Research Council, Naples, Italy 
<br class="ltx_break">giovanna.sannino@icar.cnr.it
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">Advancements in wearable medical devices in IoT technology are shaping the modern healthcare system. With the emergence of the Internet of Healthcare Things (IoHT), we are witnessing how efficient healthcare services are provided to patients and how healthcare professionals are effectively used AI-based models to analyze the data collected from IoHT devices for the treatment of various diseases. To avoid privacy breaches, these data must be processed and analyzed in compliance with the legal rules and regulations such as HIPAA and GDPR.
Federated learning is a machine leaning based approach that allows multiple entities to collaboratively train a ML model without sharing their data. This is particularly useful in the healthcare domain where data privacy and security are big concerns.
Even though FL addresses some privacy concerns, there is still no formal proof of privacy guarantees for IoHT data.
</p>
<p id="id3.id2" class="ltx_p">Privacy Enhancing Technologies (PETs) are a set of tools and techniques that are designed to enhance the privacy and security of online communications and data sharing. PETs provide a range of features that help protect users’ personal information and sensitive data from unauthorized access and tracking. This paper reviews PETs in detail and comprehensively in relation to FL in the IoHT setting and identifies several key challenges for future research.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
Privacy enhancing technologies, Internet of Healthcare Things, Federated learning, Security, Privacy.

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">In recent years, we have witnessed an accelerated growth of IoT devices in various domains such as healthcare <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, smart transportations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, smart home and building <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, and smart cities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. In the healthcare domain, IoT technology has shown its capabilities and applications in collecting patients’ data to enable healthcare professionals to analyze the data for better and more efficient treatment of various diseases.
These devices are designed to automatically collect, send, receive, and store data over the networks in order to proactively detect, diagnose, monitor, and treat patients both in and out of the healthcare systems.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Internet of Healthcare Things (IoHT) is a sub-type of the Internet of Things (IoT) oriented to e-health by combining various smart devices such as smart watches, wearable trackers, and other smart connected devices to record various health measures such as heart rate, body temperature, and blood pressure <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.
A huge amount of information collected from those variety of IoHT devices and applications is later employed in data analytics where it is empowered with Artificial Intelligence (AI) and Machine Learning (ML) models to mine such information and improve the health decision making.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Traditionally, healthcare organizations use centralized ML-based models in clouds or data centers to train the data generated by IoHT devices aiming to take reliable decisions in the healthcare domain.
However, such models usually suffer from performance and accuracy issues due to the unavailability of sufficient data to reside centrally on the server side for training due to direct access restrictions/regulations (HIPAA and GDPR) on such data, where all may lead to biased models that cannot be trustworthy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Additionally, even with sufficient data, the training procedure in a centralized setting is time-consuming and expensive tasks make them out of interest of hospitals and research centers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2303.14544/assets/Figures/outline.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="471" height="526" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Outline of the paper.</figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Recently, the Federated Learning (FL) concept has been discovered as a promising way for the eHealth systems to overcome data privacy concerns in IoHT <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. FL is a distributed ML-based approach that maintains patients’ data where they are generated and enables the training of ML models collaboratively on multiple clients’ health data like hospitals or IoHT devices in a decentralized network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. However, recent studies have shown that sometimes FL can not guarantee proper privacy-preserving <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Privacy Enhancing Technologies (PETs) are a set of tools and techniques that are designed to enhance the privacy and security of online communications and data sharing. PETs provide a range of features that help protect users’ personal information and sensitive data from unauthorized access and tracking.
The development of PETs can offer a reliable pathway toward data-driven technologies such as ML-based models while preserving privacy.
PETs are a group of methods, procedures, and techniques to extract value from data, and simultaneously reduce the privacy and security risk to private data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.
PETs are crucial, especially in industries like healthcare that collect and use sensitive data extensively. In healthcare domain, collected patient data allow researchers and healthcare professionals to distinguish disease, drug development, and improve public health. For instance, vaccine development research during the COVID-19 pandemic has shown the importance of information in public health.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">There are various PETs that can be utilized to improve privacy in FL. For example, secure multi-party computation (SMPC) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, syntactic anonymization such as k-anonymity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, homomorphic encryption <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, zero-knowledge proofs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, differential privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>, and blockchain techniques <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> are some of those techniques that are aligned with FL framework and will be discussed in this paper.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">In this paper, we aim to explore the privacy concerns in FL environment from PET perspective and discuss how PETs are integrated into FL to enhance privacy issues.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">To the best of our knowledge, there is no current research to provide a comprehensive survey on FL for the IoHT from a PET perspective. To fill this research gap, we comprehensively reviewed PETs and FL integration in smart healthcare environments. This paper reviews the main topics of privacy and FL in smart healthcare systems. Initially, we reviewed the privacy requirements and the cause of privacy leakage and violation in FL. Then, we review the PETs approach according to four PETs applied to FL. Finally, we summarize the PETs applied to FL and present some open issues.</p>
</div>
<div id="S1.p9" class="ltx_para">
<p id="S1.p9.1" class="ltx_p">The remaining part of this paper is organized as follows. Section <a href="#S2" title="II Related Work ‣ Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> summarizes the surveys similar to ours while highlighting the differences. In Section <a href="#S3" title="III Federated Learning for healthcare ‣ Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>, we provide the general principles of FL and the different sorts of this technique used in smart healthcare environments. We provide the motivations for using the privacy-preserving FL in smart healthcare in Section <a href="#S5" title="V Motivation of using Privacy-Preserving FL in smart healthcare ‣ Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a>. Section <a href="#S6" title="VI Privacy enhancing technologies ‣ Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VI</span></a> is dedicated to a complete literature review of PETs. Section <a href="#S7" title="VII PETs in Federated Learning ‣ Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VII</span></a> presents PET’s application on FL in the smart healthcare environment. Section <a href="#S8" title="VIII Key challenges for future research ‣ Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">VIII</span></a> presents open issues related to PETs in FL and
concluding remarks are given in Section <a href="#S9" title="IX Conclusions ‣ Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IX</span></a>. Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introduction ‣ Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>
depicts a systematic outline of this survey paper.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related Work</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">There are many review papers that cover a wide range of security and privacy challenges in FL environment that are either dedicated in other domains or covered security and privacy issues at the general level. In this section, we tried to discuss the most recent and similar to our work.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, the focus is to
provide an overview of FL, highlighting protocols, platforms, algorithms, market implications, and real-life use-cases, in terms of software and hardware. The advantage related to privacy, brought by FL, is presented in some parts of the work but this is not the main focus of the paper. Some use-cases related to health applications are presented but there are no comments about IoHT (In fact, authors state that IoT is not the focus of the paper).</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> provide a formal definition of FL and review the existing works using FL. The works are evaluated in terms of five aspects and one of these aspects is privacy mechanisms. Three mechanisms are considered: <span id="S2.p3.1.1" class="ltx_text ltx_font_italic">model aggregation</span>, <span id="S2.p3.1.2" class="ltx_text ltx_font_italic">homomorphic encryption</span>, and <span id="S2.p3.1.3" class="ltx_text ltx_font_italic">differential privacy</span>. In our survey, we focus on privacy and
consider a different approach, classifying four techniques: <span id="S2.p3.1.4" class="ltx_text ltx_font_italic">anonymization</span>, <span id="S2.p3.1.5" class="ltx_text ltx_font_italic">cryptography</span>, <span id="S2.p3.1.6" class="ltx_text ltx_font_italic">perturbation method</span>, and <span id="S2.p3.1.7" class="ltx_text ltx_font_italic">blockchain</span>. Similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> some use-cases related to health applications are presented but there are no comments about IoHT.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> review the FL method specifically in terms of both security and privacy. Different implementations of FL are considered and evaluated. Some of the FL threats in terms of security and privacy are similar to those considered in our paper. Some applications are oriented to IoT but there are no comments about IoHT.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, the authors focused on the IoT domain only. Similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, a formal definition of FL is presented. Healthcare applications are considered in the survey but the comparison and analysis of the works do not specify what privacy attacks the works are oriented to and neither the datasets used by them.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">In another effort <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, a number of privacy-preserving mechanisms adopted for FL frameworks are evaluated by the authors, as well as their application to vehicle activity recognition. In this study, they examined the open-source FL frameworks FATE and PFL. The FATE framework uses homomorphic encryption to secure computations and input data, while PFL uses multi-party secure computations and differential privacy to protect the processing of vertically partitioned data and train neural networks for horizontally partitioned data. Similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, there
are no comments about IoHT in the survey.</p>
</div>
<div id="S2.p7" class="ltx_para">
<p id="S2.p7.1" class="ltx_p">Nguyen et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> represent the summary of FL in the Internet of Medical Things (IoMT). In this study, a federated EHR management system, a federated remote monitoring system, a federated COVID-19 detection system, and a federated medical imaging system were discussed. Innovative FL designs for IoMT are investigated, including secure FL, resource-aware FL, and incentive-aware FL. Also, privacy-enhanced FL to protect security is explored, but this is not the main focus of the paper. Similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, among the privacy-enhancing mechanisms, differential privacy method is taken into consideration, while in our survey, we examine four different technologies that enhance privacy.</p>
</div>
<div id="S2.p8" class="ltx_para">
<p id="S2.p8.1" class="ltx_p">To the best of our knowledge, this work is the first survey specifically focused on reviewing Federated Learning applications in IoHT from the perspective of Privacy-Enhancing Technologies. A side-by-side comparison of recent efforts in this domain is shown in Table <a href="#S2.T1" title="TABLE I ‣ II Related Work ‣ Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Comparison to the related works</figcaption>
<table id="S2.T1.21" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T1.21.22.1" class="ltx_tr">
<td id="S2.T1.21.22.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S2.T1.21.22.1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">References</span></td>
<td id="S2.T1.21.22.1.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T1.21.22.1.2.1" class="ltx_text ltx_font_bold" style="font-size:90%;">IoHT environment</span></td>
<td id="S2.T1.21.22.1.3" class="ltx_td ltx_align_center ltx_border_tt"><span id="S2.T1.21.22.1.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Healthcare domain</span></td>
<td id="S2.T1.21.22.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="4"><span id="S2.T1.21.22.1.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Privacy Mechanisms</span></td>
</tr>
<tr id="S2.T1.21.23.2" class="ltx_tr">
<td id="S2.T1.21.23.2.1" class="ltx_td" colspan="2"></td>
<td id="S2.T1.21.23.2.2" class="ltx_td"></td>
<td id="S2.T1.21.23.2.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.21.23.2.3.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Anonymization</span></td>
<td id="S2.T1.21.23.2.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.21.23.2.4.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Cryptography</span></td>
<td id="S2.T1.21.23.2.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.21.23.2.5.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Perturbation</span></td>
<td id="S2.T1.21.23.2.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.21.23.2.6.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Blockchain</span></td>
</tr>
<tr id="S2.T1.5.5" class="ltx_tr">
<td id="S2.T1.5.5.6" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.5.5.6.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">[</span><a href="#bib.bib20" title="" class="ltx_ref">20</a><span id="S2.T1.5.5.6.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">]</span></cite></td>
<td id="S2.T1.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.1.1.1.m1.1a"><mo mathsize="90%" id="S2.T1.1.1.1.m1.1.1" xref="S2.T1.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.1.1.1.m1.1b"><times id="S2.T1.1.1.1.m1.1.1.cmml" xref="S2.T1.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.1.1.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.5.5.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.5.5.7.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S2.T1.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.2.2.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.2.2.2.m1.1a"><mo mathsize="90%" id="S2.T1.2.2.2.m1.1.1" xref="S2.T1.2.2.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.2.2.2.m1.1b"><times id="S2.T1.2.2.2.m1.1.1.cmml" xref="S2.T1.2.2.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.2.2.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.3.3.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.3.3.3.m1.1a"><mo mathsize="90%" id="S2.T1.3.3.3.m1.1.1" xref="S2.T1.3.3.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.3.3.3.m1.1b"><times id="S2.T1.3.3.3.m1.1.1.cmml" xref="S2.T1.3.3.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.3.3.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.4.4.4" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.4.4.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.4.4.4.m1.1a"><mo mathsize="90%" id="S2.T1.4.4.4.m1.1.1" xref="S2.T1.4.4.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.4.4.4.m1.1b"><times id="S2.T1.4.4.4.m1.1.1.cmml" xref="S2.T1.4.4.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.4.4.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.5.5.5" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.5.5.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.5.5.5.m1.1a"><mo mathsize="90%" id="S2.T1.5.5.5.m1.1.1" xref="S2.T1.5.5.5.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.5.5.5.m1.1b"><times id="S2.T1.5.5.5.m1.1.1.cmml" xref="S2.T1.5.5.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.5.5.5.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.9.9" class="ltx_tr">
<td id="S2.T1.9.9.5" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.9.9.5.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">[</span><a href="#bib.bib21" title="" class="ltx_ref">21</a><span id="S2.T1.9.9.5.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">]</span></cite></td>
<td id="S2.T1.6.6.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.6.6.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.6.6.1.m1.1a"><mo mathsize="90%" id="S2.T1.6.6.1.m1.1.1" xref="S2.T1.6.6.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.6.6.1.m1.1b"><times id="S2.T1.6.6.1.m1.1.1.cmml" xref="S2.T1.6.6.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.6.6.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.7.7.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.7.7.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.7.7.2.m1.1a"><mo mathsize="90%" id="S2.T1.7.7.2.m1.1.1" xref="S2.T1.7.7.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.7.7.2.m1.1b"><times id="S2.T1.7.7.2.m1.1.1.cmml" xref="S2.T1.7.7.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.7.7.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.8.8.3" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.8.8.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.8.8.3.m1.1a"><mo mathsize="90%" id="S2.T1.8.8.3.m1.1.1" xref="S2.T1.8.8.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.8.8.3.m1.1b"><times id="S2.T1.8.8.3.m1.1.1.cmml" xref="S2.T1.8.8.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.8.8.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.9.9.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.9.9.6.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S2.T1.9.9.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.9.9.7.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S2.T1.9.9.4" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.9.9.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.9.9.4.m1.1a"><mo mathsize="90%" id="S2.T1.9.9.4.m1.1.1" xref="S2.T1.9.9.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.9.9.4.m1.1b"><times id="S2.T1.9.9.4.m1.1.1.cmml" xref="S2.T1.9.9.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.9.9.4.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.12.12" class="ltx_tr">
<td id="S2.T1.12.12.4" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.12.12.4.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">[</span><a href="#bib.bib22" title="" class="ltx_ref">22</a><span id="S2.T1.12.12.4.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">]</span></cite></td>
<td id="S2.T1.10.10.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.10.10.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.10.10.1.m1.1a"><mo mathsize="90%" id="S2.T1.10.10.1.m1.1.1" xref="S2.T1.10.10.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.10.10.1.m1.1b"><times id="S2.T1.10.10.1.m1.1.1.cmml" xref="S2.T1.10.10.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.10.10.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.11.11.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.11.11.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.11.11.2.m1.1a"><mo mathsize="90%" id="S2.T1.11.11.2.m1.1.1" xref="S2.T1.11.11.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.11.11.2.m1.1b"><times id="S2.T1.11.11.2.m1.1.1.cmml" xref="S2.T1.11.11.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.11.11.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.12.12.3" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.12.12.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.12.12.3.m1.1a"><mo mathsize="90%" id="S2.T1.12.12.3.m1.1.1" xref="S2.T1.12.12.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.12.12.3.m1.1b"><times id="S2.T1.12.12.3.m1.1.1.cmml" xref="S2.T1.12.12.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.12.12.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.12.12.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.12.12.5.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S2.T1.12.12.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.12.12.6.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S2.T1.12.12.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.12.12.7.1" class="ltx_text" style="font-size:90%;">✓</span></td>
</tr>
<tr id="S2.T1.14.14" class="ltx_tr">
<td id="S2.T1.14.14.3" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.14.14.3.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">[</span><a href="#bib.bib23" title="" class="ltx_ref">23</a><span id="S2.T1.14.14.3.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">]</span></cite></td>
<td id="S2.T1.14.14.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.14.14.4.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S2.T1.14.14.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.14.14.5.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S2.T1.13.13.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.13.13.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.13.13.1.m1.1a"><mo mathsize="90%" id="S2.T1.13.13.1.m1.1.1" xref="S2.T1.13.13.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.13.13.1.m1.1b"><times id="S2.T1.13.13.1.m1.1.1.cmml" xref="S2.T1.13.13.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.13.13.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.14.14.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.14.14.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.14.14.2.m1.1a"><mo mathsize="90%" id="S2.T1.14.14.2.m1.1.1" xref="S2.T1.14.14.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.14.14.2.m1.1b"><times id="S2.T1.14.14.2.m1.1.1.cmml" xref="S2.T1.14.14.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.14.14.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.14.14.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.14.14.6.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S2.T1.14.14.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.14.14.7.1" class="ltx_text" style="font-size:90%;">✓</span></td>
</tr>
<tr id="S2.T1.18.18" class="ltx_tr">
<td id="S2.T1.18.18.5" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.18.18.5.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">[</span><a href="#bib.bib24" title="" class="ltx_ref">24</a><span id="S2.T1.18.18.5.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">]</span></cite></td>
<td id="S2.T1.15.15.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.15.15.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.15.15.1.m1.1a"><mo mathsize="90%" id="S2.T1.15.15.1.m1.1.1" xref="S2.T1.15.15.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.15.15.1.m1.1b"><times id="S2.T1.15.15.1.m1.1.1.cmml" xref="S2.T1.15.15.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.15.15.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.16.16.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.16.16.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.16.16.2.m1.1a"><mo mathsize="90%" id="S2.T1.16.16.2.m1.1.1" xref="S2.T1.16.16.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.16.16.2.m1.1b"><times id="S2.T1.16.16.2.m1.1.1.cmml" xref="S2.T1.16.16.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.16.16.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.17.17.3" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.17.17.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.17.17.3.m1.1a"><mo mathsize="90%" id="S2.T1.17.17.3.m1.1.1" xref="S2.T1.17.17.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.17.17.3.m1.1b"><times id="S2.T1.17.17.3.m1.1.1.cmml" xref="S2.T1.17.17.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.17.17.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.18.18.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.18.18.6.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S2.T1.18.18.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.18.18.7.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S2.T1.18.18.4" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.18.18.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.18.18.4.m1.1a"><mo mathsize="90%" id="S2.T1.18.18.4.m1.1.1" xref="S2.T1.18.18.4.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.18.18.4.m1.1b"><times id="S2.T1.18.18.4.m1.1.1.cmml" xref="S2.T1.18.18.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.18.18.4.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.21.21" class="ltx_tr">
<td id="S2.T1.21.21.4" class="ltx_td ltx_align_left ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T1.21.21.4.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">[</span><a href="#bib.bib25" title="" class="ltx_ref">25</a><span id="S2.T1.21.21.4.2.2" class="ltx_text ltx_font_bold" style="font-size:90%;">]</span></cite></td>
<td id="S2.T1.21.21.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.21.21.5.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S2.T1.21.21.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.21.21.6.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S2.T1.19.19.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.19.19.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.19.19.1.m1.1a"><mo mathsize="90%" id="S2.T1.19.19.1.m1.1.1" xref="S2.T1.19.19.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.19.19.1.m1.1b"><times id="S2.T1.19.19.1.m1.1.1.cmml" xref="S2.T1.19.19.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.19.19.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.20.20.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.20.20.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.20.20.2.m1.1a"><mo mathsize="90%" id="S2.T1.20.20.2.m1.1.1" xref="S2.T1.20.20.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.20.20.2.m1.1b"><times id="S2.T1.20.20.2.m1.1.1.cmml" xref="S2.T1.20.20.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.20.20.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S2.T1.21.21.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S2.T1.21.21.7.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S2.T1.21.21.3" class="ltx_td ltx_align_center ltx_border_t"><math id="S2.T1.21.21.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.T1.21.21.3.m1.1a"><mo mathsize="90%" id="S2.T1.21.21.3.m1.1.1" xref="S2.T1.21.21.3.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S2.T1.21.21.3.m1.1b"><times id="S2.T1.21.21.3.m1.1.1.cmml" xref="S2.T1.21.21.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.21.21.3.m1.1c">\times</annotation></semantics></math></td>
</tr>
<tr id="S2.T1.21.24.3" class="ltx_tr">
<td id="S2.T1.21.24.3.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="S2.T1.21.24.3.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Our work</span></td>
<td id="S2.T1.21.24.3.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S2.T1.21.24.3.2.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S2.T1.21.24.3.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S2.T1.21.24.3.3.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S2.T1.21.24.3.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S2.T1.21.24.3.4.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S2.T1.21.24.3.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S2.T1.21.24.3.5.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S2.T1.21.24.3.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S2.T1.21.24.3.6.1" class="ltx_text" style="font-size:90%;">✓</span></td>
<td id="S2.T1.21.24.3.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S2.T1.21.24.3.7.1" class="ltx_text" style="font-size:90%;">✓</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Federated Learning for healthcare</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">The overall FL principle and the many FL types in the context of e-healthcare are discussed in this section.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">Principles of FL for Smart Healthcare</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Privacy breaches
have become a major concern for users’ data. Therefore, governments establish policies to prevent privacy leakage in order to preserve users’ data privacy. Breaching these policies is expensive for companies, and it has boosted the development of FL in 2016 by Google <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. FL or collaborative learning
trains a global machine learning model without explicitly exchanging the local data on multiple parties. In an FL system, clients train local machine-learning models on local datasets and exchange some parameters like gradients or model weights with the central server to obtain a global model.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">In general, the FL process for IoHT consists of the following steps:</p>
</div>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS1.4.1.1" class="ltx_text">III-A</span>1 </span>Initialization</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.1" class="ltx_p">The aggregation server selects data generated by IoHT devices, such as Blood Sample Reader or human motion detection to do the prediction or classification task.
Furthermore, the central server chooses a group of participants to participate in the FL process.</p>
</div>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS2.4.1.1" class="ltx_text">III-A</span>2 </span>Updating Local Training model</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.1" class="ltx_p">The server sends an initial model to the devices to initiate the distributed training after choosing the IoHT devices for the learning process. Each device computes its updated model by training a local model with its own dataset that is kept locally.
Then, each device sends its updated model to central the server in order to aggregate all of the updated models.</p>
</div>
</section>
<section id="S3.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS3.4.1.1" class="ltx_text">III-A</span>3 </span>Model Aggregation</h4>

<div id="S3.SS1.SSS3.p1" class="ltx_para">
<p id="S3.SS1.SSS3.p1.1" class="ltx_p">After receiving the parameters from each IoHT device in the FL process, the aggregation step combines all parameters to generate a global learning model. Federated Averaging (FedAvg) algorithm is an averaging model which we can use to calculate the global model and send it to all IoHT devices for updating the local model.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">FL Types for Smart Healthcare</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Studying the FL methods utilized in various domains shows that based on data partitioning, FL methods can be categorized into Horizontal FL, Vertical FL, and Federated Transfer Learning.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">In horizontal FL, or sample-based federated learning, the datasets of different healthcare clients have the same feature space and different sample space.
Since the local data are in the same feature space, local healthcare participants can train the local model using their local data by the same AI model such as the neural network model. Afterwards, the global model simply can be updated by combining all the local models transmitted from local healthcare organizations or institutions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. A horizontal FL example in smart healthcare can be multiple implanted medical devices from different hospitals as clients,
that collect very similar data but have little to no overlap of patients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">In vertical FL, the datasets of different healthcare organizations have similar sample spaces and different feature spaces. This method can be used to address the overlapping sample at distributed clients. The vertical FL usually utilizes entity alignment techniques to collect the overlapped samples of the hospitals. Then, the overlapped data can be applied to the local training model integrated with encryption techniques <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>. An example of vertical FL in IoHT applications can be the shared learning model between hospitals and cardiologists. Both hospitals and cardiologists with various data features, which have patients with a similar sample space, use a vertical FL for training an AI model by utilizing historical medical records at hospitals and cardiologist data for smart healthcare decisions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">Federated Transfer Learning is an integration of transfer learning into federated learning to handle datasets that have various sample spaces and various feature spaces. In fact, transfer learning is a way to transfer knowledge from one particular problem to another
to decrease the distribution divergence between different domains <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. An example of federated transfer learning in healthcare organizations can be disease diagnosis by collaborating countries with numerous hospitals that have various patients and various therapeutic programs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Privacy requirements for IoHT systems</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">For IoHT devices, privacy requirements are more stringent than for typical IoT infrastructures. IoHT healthcare systems have some privacy requirements, such as data protection privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>.
During the collection and storage of patient data, we must continually take into account ethical privacy regulations throughout the entire data lifecycle. For instance, Privacy policies such as GDRP and HIPAA are laws for preserving privacy at the data level <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. According to privacy policies, only authorized individuals can have access to patient health data. In fact, data privacy protection is a way to preserve personal data from unauthorized use and manipulation.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">Thus, to protect the privacy of patient data, the IoHT system should be designed to guarantee the following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>:</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p">Preserve the privacy of patients and the confidentiality of patient health care data (prevention of unauthorized access to health information).</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p">The integrity of healthcare data (prevention of unauthorized data manipulation).</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p">The availability of health data for authorized people.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Motivation of using Privacy-Preserving FL in smart healthcare</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In the next two sections, we will summarily cover the benefit FL and the potential threats of using FL in smart healthcare.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.4.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.5.2" class="ltx_text ltx_font_italic">Benefits of FL in IoHT</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">Due to various characteristics of FL such as privacy-preserving, and collaborative learning in a distributed data environment bring many advantages to the IoHT domain that will be discussed briefly in the next subsections.</p>
</div>
<section id="S5.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS1.SSS1.4.1.1" class="ltx_text">V-A</span>1 </span>Improving the privacy of user data</h4>

<div id="S5.SS1.SSS1.p1" class="ltx_para">
<p id="S5.SS1.SSS1.p1.1" class="ltx_p">With increasing the number of IoHT devices and publicly available medical datasets generated by IoHT devices, privacy concerns are also growing in the e-healthcare systems. Collected data by IoHT devices, such as heartbeat, blood pressure, and glucose level, is more sensitive compared to other types of data. According to data privacy protection legislation, private patient data is the most sensitive data and is restricted by government laws. To address data privacy challenges in the e-healthcare domain, FL offers a decentralized training mechanism where each client or institution can control private data and define a privacy-preservation policy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>.
In the FL framework, the raw health data are stored at a medical devices or local site and do not leave the IoHT devices during the federated data training process. During model training, only the local updates like model gradients need to be sent to the central server, which reduces the risk of sensitive and personal data leakage and ensures a high level of patient data privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>.</p>
</div>
</section>
<section id="S5.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS1.SSS2.4.1.1" class="ltx_text">V-A</span>2 </span>Less biased model</h4>

<div id="S5.SS1.SSS2.p1" class="ltx_para">
<p id="S5.SS1.SSS2.p1.1" class="ltx_p">Because a centralized model can only be trained using limited data from a single hospital, the result may be biased in the predictions. Therefore, mitigation bias recently gains a lot of attention in modern machine learning techniques <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>. Thus, for models to be more generalizable, more data must be used, which can be achieved through data sharing between organizations. However, exchanging patients’ electronic health data between hospitals is against their data security and privacy because healthcare data is sensitive <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>. Under these circumstances, to address the bias issue, federated learning has emerged as an option for building a collaborative learning model for healthcare data and producing models that yield unbiased results. The trained model is less biased and smarter as different datasets from various sources are integrated into the learning process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>.</p>
</div>
</section>
<section id="S5.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S5.SS1.SSS3.4.1.1" class="ltx_text">V-A</span>3 </span>Improving the scalability</h4>

<div id="S5.SS1.SSS3.p1" class="ltx_para">
<p id="S5.SS1.SSS3.p1.1" class="ltx_p">In the centralized model, uploading all of the healthcare data to the server leads to a waste of computing resources, breaches privacy, and puts more pressure on the wireless communication network, which declines the network’s scalability.
However, FL’s distributed nature enables the scalability of IoHT networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>. In fact, FL has the ability to use the computational resources located at multiple IoHT devices across different hospitals located in different geographic regions in a parallel manner. For instance, when new hospitals or healthcare institutions participate, they add more computational resources in the federated learning process. Therefore, these more computational resources allow federated learning to enhance performance. Moreover, the FL architecture avoids sending the massive amounts of IoHT data gathered to the cloud, which can result in significant network bandwidth saving and drastically reduce communication costs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS2.4.1.1" class="ltx_text">V-B</span> </span><span id="S5.SS2.5.2" class="ltx_text ltx_font_italic">Privacy Leakage and Potential Threats in Federated Learning</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Although FL provides a privacy-aware framework to train a global model without sharing data and allows clients to use the framework using their local dataset,
recent works have shown that FL can face privacy breaches and information leakage.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">The FL frameworks restrict sharing data on local devices with third-party or central servers. Nonetheless, it is possible to reveal sensitive information through the back-tracing of gradients and update the communication models through the training process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>.
For example, Zhu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> introduces a deep leakage from Gradient (DLG), which shows malicious attackers can steal the training data in a few iterations. In their study, they showed how private training data can be easily leaked because of sharing the gradients. Similarly, Aono et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> reported that accessing a small portion of original gradients may cause leakage in local training data.
Although FL models on decentralized data sources have shown promising results with respect to preserving data privacy. But, it is still vulnerable to several types of attacks
such as poisoning attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>, inference attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>, and backdoor attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p">In a poisoning attack, which occurs during the training time, an attacker tries to manipulate the training data sample by injecting designed samples to compromise the whole learning process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>.
In Poisoning attacks including data poisoning attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> and model poisoning attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> the ultimate goal of attackers is to change the behavior of the target model. A data poisoning attack aims to mislead the global model by manipulating the local training data. The attacker flips the labels of training data and adds noise in order to degrade the quality of models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>. Fig. <a href="#S5.F2" title="Figure 2 ‣ V-B Privacy Leakage and Potential Threats in Federated Learning ‣ V Motivation of using Privacy-Preserving FL in smart healthcare ‣ Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows how an attacker changes the trained model by flipping the data labels.
In the model poisoning attack, the attacker attempts to manipulate local model updates before sending the models to the server. This method includes various techniques to manipulate the FL local training procedure, such as direct gradient manipulation and changing the learning rule <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>.</p>
</div>
<figure id="S5.F2" class="ltx_figure"><img src="/html/2303.14544/assets/Figures/poisoningattack.png" id="S5.F2.g1" class="ltx_graphics ltx_img_square" width="214" height="232" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>An illustration of the poisoning attacks against FL</figcaption>
</figure>
<div id="S5.SS2.p4" class="ltx_para">
<p id="S5.SS2.p4.1" class="ltx_p">In
an
inference attack, the attacker aims to exchange gradients during the FL training process, which can result in serious information leakage about the features of clients’ training data. The inference attack includes inferring class representatives <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, inferring membership <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>, inferring data properties <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>, and inferring samples/labels <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>.
In the inference of class representatives, the adversary creates samples that are not in the original training dataset. Attackers use these false samples to learn sensitive information about the training dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>. The inference of memberships tries to determine whether a given data sample
has
been used for model training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>.
In the property inference attack, the attacker aims to infer the property information of the training dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>. In the inferring samples, the attacker recreates labels from the gradients and recovers the original training samples that
are
used during training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite>. Fig <a href="#S5.F3" title="Figure 3 ‣ V-B Privacy Leakage and Potential Threats in Federated Learning ‣ V Motivation of using Privacy-Preserving FL in smart healthcare ‣ Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows an example of inference attacks.</p>
</div>
<figure id="S5.F3" class="ltx_figure"><img src="/html/2303.14544/assets/Figures/Inferenceattack.png" id="S5.F3.g1" class="ltx_graphics ltx_img_square" width="177" height="219" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>An illustration of the Inference attacks against FL</figcaption>
</figure>
<div id="S5.SS2.p5" class="ltx_para">
<p id="S5.SS2.p5.1" class="ltx_p">In a backdoor attack, the goal of the attacker is to destroy the global FL model and then replace the actual global FL model with the attacker’s model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>. This attack can be also classified as a type of model poisoning attack, but it is
more harmful than poisoning attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>. In fact, the attacker compromises the devices of one or several participants and trains a model using
backdoor data, then submits the resulting model. After federated averaging, the global model is replaced by the backdoored model as shown in Fig. <a href="#S5.F4" title="Figure 4 ‣ V-B Privacy Leakage and Potential Threats in Federated Learning ‣ V Motivation of using Privacy-Preserving FL in smart healthcare ‣ Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. In the backdoor, an adversary can be hidden and has no impact on the accuracy or functionality of the global model like accuracy. As a result, the accuracy of the validation dataset makes it difficult to distinguish the backdoor attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>.</p>
</div>
<figure id="S5.F4" class="ltx_figure"><img src="/html/2303.14544/assets/Figures/Backdoorattack.png" id="S5.F4.g1" class="ltx_graphics ltx_img_square" width="231" height="202" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>An illustration of the Backdoor attacks against FL</figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Privacy enhancing technologies</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Privacy Enhancing Technologies (PETs) are a set of tools and techniques that aim to protect individuals’ privacy. PETs are designed to enable companies to embed privacy-by-design principles into their data governance practices to minimize the amount of personal data they collect, use and share while maximizing data security and privacy. In this context, our objective is to explore how PETs can be utilized to enhance privacy-preserving in FL to improve patient data privacy in IoHT devices and e-healthcare.
Four wide categories of PETs are used to
improve privacy protection, including
(1) anonymization technique <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite>,
(2) cryptographic technique <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite>,
(3) perturbation technique <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite>, and
(4) blockchain technique <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite>.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS1.4.1.1" class="ltx_text">VI-A</span> </span><span id="S6.SS1.5.2" class="ltx_text ltx_font_italic">Anonymization Techniques</span>
</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p">Anonymization techniques are broadly used for privacy enhancing by changing the
state of a data set and removing the identifier from dataset information in a way so
that the dataset is usable and protects the privacy of individual’s personal
information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite>.
Anonymity technology can better avoid the leakage of sensitive patient data and
provide more secure environment for smart healthcare systems. There are several anonymization technologies that are appropriate for big medical data, which are based on three categories of widely used
anonymity protection techniques: <span id="S6.SS1.p1.1.1" class="ltx_text ltx_font_italic">k-anonymity</span>, <span id="S6.SS1.p1.1.2" class="ltx_text ltx_font_italic">l-diversity</span>, and <span id="S6.SS1.p1.1.3" class="ltx_text ltx_font_italic">t-closeness</span> models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite>.</p>
</div>
<div id="S6.SS1.p2" class="ltx_para">
<p id="S6.SS1.p2.2" class="ltx_p">The idea of k-anonymity is to anonymize the quasi-identifier
in the dataset that can be used by attackers to identify
sensitive information about individuals. After selecting the
quasi-identifiers, k-anonymity applies for each sample in
the dataset, which can guarantee that each sample in the
dataset cannot be re-identified from at least <math id="S6.SS1.p2.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S6.SS1.p2.1.m1.1a"><mi id="S6.SS1.p2.1.m1.1.1" xref="S6.SS1.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.1.m1.1b"><ci id="S6.SS1.p2.1.m1.1.1.cmml" xref="S6.SS1.p2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.1.m1.1c">k</annotation></semantics></math>-1
samples <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>]</cite>. l-diversity is an
extension of the k-anonymity mechanism to enhance privacy
against against homogeneity attacks and background knowledge attacks on k-anonymity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>]</cite>.
l-diversity ensures that there are at least <math id="S6.SS1.p2.2.m2.1" class="ltx_Math" alttext="l" display="inline"><semantics id="S6.SS1.p2.2.m2.1a"><mi id="S6.SS1.p2.2.m2.1.1" xref="S6.SS1.p2.2.m2.1.1.cmml">l</mi><annotation-xml encoding="MathML-Content" id="S6.SS1.p2.2.m2.1b"><ci id="S6.SS1.p2.2.m2.1.1.cmml" xref="S6.SS1.p2.2.m2.1.1">𝑙</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p2.2.m2.1c">l</annotation></semantics></math>
“well-performing” values for the sensitive attributes and
protects against attribute
disclosure <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite>.
Finally, t-closeness is
proposed to reduce attacks against
k-anonymity and l-diversity approaches and solve the
attribute disclosure problem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite>.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS2.4.1.1" class="ltx_text">VI-B</span> </span><span id="S6.SS2.5.2" class="ltx_text ltx_font_italic">Cryptographic Techniques</span>
</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">Cryptographic techniques
have been used to avoid privacy disclosure of individual’s private data in federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite>.
These methods consist of <span id="S6.SS2.p1.1.1" class="ltx_text ltx_font_italic">homomorphic encryption</span>, <span id="S6.SS2.p1.1.2" class="ltx_text ltx_font_italic">secure multi-party computation</span>, and <span id="S6.SS2.p1.1.3" class="ltx_text ltx_font_italic">zero-knowledge proofs</span>.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.1" class="ltx_p">Homomorphic encryption is a form of encryption for privacy-enhancing in FL to prevent information leakage during the parameter exchanging process among clients. In this method, parameters are encoded before adding or multiplying operations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite>. There are two main widely used homomorphic encryption methods: fully homomorphic encryption and partially homomorphic encryption. Fully homomorphic encryption supports both additive and multiplicative operations on ciphertext, while partially homomorphic encryption only supports either additive or multiplicative operations on the ciphertext. Compared with partially homomorphic encryption, fully homomorphic encryption provides stronger encryption, and both can be applied to horizontal and vertical federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>.</p>
</div>
<div id="S6.SS2.p3" class="ltx_para">
<p id="S6.SS2.p3.1" class="ltx_p">Secure multi-party computation (SMC) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite> is a sub-field of cryptographic schemes to protect private information. SMC can be used to solve the problem of collaborative computing between all parties such that no party learns anything about other participants’ data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>.
The application of SMC
allows multiple participants
to concentrate on safely calculating a function for various participant
without the requirement of trusted third-parties and revealing input. However, due to the additional encryption and decryption operations, SMC suffers from computational overhead and high communication costs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite>.</p>
</div>
<div id="S6.SS2.p4" class="ltx_para">
<p id="S6.SS2.p4.1" class="ltx_p">Zero-knowledge proofs (ZKP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>]</cite> is a cryptographic system to achieve both input privacy and verifiability in federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>. A zero-knowledge proof involves
a
prover to make sure with another entity called a
verifier
that distinguishes the validity of a given statement. ZKP can be an appropriate method for verification of sensitive healthcare data among collaborators because it allows sharing
data securely and privately between multiple participants <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite>.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS3.4.1.1" class="ltx_text">VI-C</span> </span><span id="S6.SS3.5.2" class="ltx_text ltx_font_italic">Perturbation Techniques</span>
</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">A perturbation method is to protect private data and model privacy by adding random noise to the original data or training data during the training process. The differential privacy technique is a widely used perturbation method implemented in the FL frameworks in medical applications. It is one of the PETs methods and guarantees privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite> using probability statistical models to mask sensitive private data in a dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite> and protect healthcare data against inference attack on FL frameworks. By adding noise to the model parameters or data, data can be deferentially private <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite>, and the parties cannot
realize whether an individual record participates in the learning process or not.</p>
</div>
<div id="S6.SS3.p2" class="ltx_para">
<p id="S6.SS3.p2.1" class="ltx_p">Differential privacy techniques include two categories: <span id="S6.SS3.p2.1.1" class="ltx_text ltx_font_italic">global differential</span> and
<span id="S6.SS3.p2.1.2" class="ltx_text ltx_font_italic">local differential</span> privacy techniques. In the global differential privacy (GDP)
setting, there is a trusted curator
that applies carefully random noise to the real
values returned for a particular query <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib91" title="" class="ltx_ref">91</a>]</cite>. Different
from GDP, a local differential privacy (LDP) technique does not need a trusted
third-party. In fact, LDP allows users to locally perturb the input data, and it
often produces too noisy data, as noise is applied to achieve individual record
privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib92" title="" class="ltx_ref">92</a>]</cite>. As an advantage, the differential privacy technique by adding random noise makes data sets more secure because an attacker cannot distinguish which information is true. Therefore, more noises that are added to the sensitive data have a direct relationship to how the data is hard for an attacker to recognize true information about individuals in the dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite>.</p>
</div>
<figure id="S6.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE II: </span>Summary of anonymization techniques applied in FL for the smart healthcare environment.</figcaption>
<table id="S6.T2.4" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T2.4.5.1" class="ltx_tr">
<td id="S6.T2.4.5.1.1" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T2.4.5.1.1.1" class="ltx_text ltx_font_bold">Ref.</span></td>
<td id="S6.T2.4.5.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T2.4.5.1.2.1" class="ltx_text ltx_font_bold">Aim</span></td>
<td id="S6.T2.4.5.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T2.4.5.1.3.1" class="ltx_text ltx_font_bold">Dataset</span></td>
<td id="S6.T2.4.5.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T2.4.5.1.4.1" class="ltx_text ltx_font_bold">Dataset Available</span></td>
<td id="S6.T2.4.5.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T2.4.5.1.5.1" class="ltx_text ltx_font_bold">Open-Source</span></td>
<td id="S6.T2.4.5.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T2.4.5.1.6.1" class="ltx_text ltx_font_bold">Privacy Attack</span></td>
<td id="S6.T2.4.5.1.7" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T2.4.5.1.7.1" class="ltx_text ltx_font_bold">Privacy-Enhancing Method</span></td>
</tr>
<tr id="S6.T2.1.1" class="ltx_tr">
<td id="S6.T2.1.1.2" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite></td>
<td id="S6.T2.1.1.3" class="ltx_td ltx_align_center ltx_border_t">Maximize data utility</td>
<td id="S6.T2.1.1.4" class="ltx_td ltx_align_center ltx_border_t">MIMIC III</td>
<td id="S6.T2.1.1.5" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S6.T2.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S6.T2.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T2.1.1.1.m1.1a"><mo id="S6.T2.1.1.1.m1.1.1" xref="S6.T2.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T2.1.1.1.m1.1b"><times id="S6.T2.1.1.1.m1.1.1.cmml" xref="S6.T2.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.1.1.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S6.T2.1.1.6" class="ltx_td ltx_align_center ltx_border_t">Inference attack</td>
<td id="S6.T2.1.1.7" class="ltx_td ltx_align_center ltx_border_t">syntactic anonymization</td>
</tr>
<tr id="S6.T2.4.6.2" class="ltx_tr">
<td id="S6.T2.4.6.2.1" class="ltx_td"></td>
<td id="S6.T2.4.6.2.2" class="ltx_td ltx_align_center">&amp;</td>
<td id="S6.T2.4.6.2.3" class="ltx_td"></td>
<td id="S6.T2.4.6.2.4" class="ltx_td"></td>
<td id="S6.T2.4.6.2.5" class="ltx_td"></td>
<td id="S6.T2.4.6.2.6" class="ltx_td"></td>
<td id="S6.T2.4.6.2.7" class="ltx_td"></td>
</tr>
<tr id="S6.T2.4.7.3" class="ltx_tr">
<td id="S6.T2.4.7.3.1" class="ltx_td"></td>
<td id="S6.T2.4.7.3.2" class="ltx_td ltx_align_center">model performance</td>
<td id="S6.T2.4.7.3.3" class="ltx_td"></td>
<td id="S6.T2.4.7.3.4" class="ltx_td"></td>
<td id="S6.T2.4.7.3.5" class="ltx_td"></td>
<td id="S6.T2.4.7.3.6" class="ltx_td"></td>
<td id="S6.T2.4.7.3.7" class="ltx_td"></td>
</tr>
<tr id="S6.T2.2.2" class="ltx_tr">
<td id="S6.T2.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite></td>
<td id="S6.T2.2.2.3" class="ltx_td ltx_align_center ltx_border_t">Applying data privacy</td>
<td id="S6.T2.2.2.4" class="ltx_td ltx_align_center ltx_border_t">Pima Indians</td>
<td id="S6.T2.2.2.5" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S6.T2.2.2.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S6.T2.2.2.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T2.2.2.1.m1.1a"><mo id="S6.T2.2.2.1.m1.1.1" xref="S6.T2.2.2.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T2.2.2.1.m1.1b"><times id="S6.T2.2.2.1.m1.1.1.cmml" xref="S6.T2.2.2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.2.2.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S6.T2.2.2.6" class="ltx_td ltx_align_center ltx_border_t">Poisoning attack</td>
<td id="S6.T2.2.2.7" class="ltx_td ltx_align_center ltx_border_t">k-anonymity</td>
</tr>
<tr id="S6.T2.4.8.4" class="ltx_tr">
<td id="S6.T2.4.8.4.1" class="ltx_td"></td>
<td id="S6.T2.4.8.4.2" class="ltx_td ltx_align_center">engineering without</td>
<td id="S6.T2.4.8.4.3" class="ltx_td ltx_align_center">diabetes</td>
<td id="S6.T2.4.8.4.4" class="ltx_td"></td>
<td id="S6.T2.4.8.4.5" class="ltx_td"></td>
<td id="S6.T2.4.8.4.6" class="ltx_td"></td>
<td id="S6.T2.4.8.4.7" class="ltx_td"></td>
</tr>
<tr id="S6.T2.4.9.5" class="ltx_tr">
<td id="S6.T2.4.9.5.1" class="ltx_td"></td>
<td id="S6.T2.4.9.5.2" class="ltx_td ltx_align_center">reducing the accuracy</td>
<td id="S6.T2.4.9.5.3" class="ltx_td ltx_align_center">&amp;</td>
<td id="S6.T2.4.9.5.4" class="ltx_td"></td>
<td id="S6.T2.4.9.5.5" class="ltx_td"></td>
<td id="S6.T2.4.9.5.6" class="ltx_td"></td>
<td id="S6.T2.4.9.5.7" class="ltx_td"></td>
</tr>
<tr id="S6.T2.4.10.6" class="ltx_tr">
<td id="S6.T2.4.10.6.1" class="ltx_td"></td>
<td id="S6.T2.4.10.6.2" class="ltx_td"></td>
<td id="S6.T2.4.10.6.3" class="ltx_td ltx_align_center">Cleveland</td>
<td id="S6.T2.4.10.6.4" class="ltx_td"></td>
<td id="S6.T2.4.10.6.5" class="ltx_td"></td>
<td id="S6.T2.4.10.6.6" class="ltx_td"></td>
<td id="S6.T2.4.10.6.7" class="ltx_td"></td>
</tr>
<tr id="S6.T2.4.11.7" class="ltx_tr">
<td id="S6.T2.4.11.7.1" class="ltx_td"></td>
<td id="S6.T2.4.11.7.2" class="ltx_td"></td>
<td id="S6.T2.4.11.7.3" class="ltx_td ltx_align_center">heart disease</td>
<td id="S6.T2.4.11.7.4" class="ltx_td"></td>
<td id="S6.T2.4.11.7.5" class="ltx_td"></td>
<td id="S6.T2.4.11.7.6" class="ltx_td"></td>
<td id="S6.T2.4.11.7.7" class="ltx_td"></td>
</tr>
<tr id="S6.T2.3.3" class="ltx_tr">
<td id="S6.T2.3.3.2" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite></td>
<td id="S6.T2.3.3.3" class="ltx_td ltx_align_center ltx_border_t">Preserving private data</td>
<td id="S6.T2.3.3.4" class="ltx_td ltx_align_center ltx_border_t">MNIST</td>
<td id="S6.T2.3.3.5" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S6.T2.3.3.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S6.T2.3.3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T2.3.3.1.m1.1a"><mo id="S6.T2.3.3.1.m1.1.1" xref="S6.T2.3.3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T2.3.3.1.m1.1b"><times id="S6.T2.3.3.1.m1.1.1.cmml" xref="S6.T2.3.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.3.3.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S6.T2.3.3.6" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S6.T2.3.3.7" class="ltx_td ltx_align_center ltx_border_t">Non-negative matrix</td>
</tr>
<tr id="S6.T2.4.12.8" class="ltx_tr">
<td id="S6.T2.4.12.8.1" class="ltx_td"></td>
<td id="S6.T2.4.12.8.2" class="ltx_td ltx_align_center">with high accuracy</td>
<td id="S6.T2.4.12.8.3" class="ltx_td ltx_align_center">HARUS</td>
<td id="S6.T2.4.12.8.4" class="ltx_td"></td>
<td id="S6.T2.4.12.8.5" class="ltx_td"></td>
<td id="S6.T2.4.12.8.6" class="ltx_td"></td>
<td id="S6.T2.4.12.8.7" class="ltx_td ltx_align_center">factorization</td>
</tr>
<tr id="S6.T2.4.4" class="ltx_tr">
<td id="S6.T2.4.4.2" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite></td>
<td id="S6.T2.4.4.3" class="ltx_td ltx_align_center ltx_border_t">Avoiding an attack from</td>
<td id="S6.T2.4.4.4" class="ltx_td ltx_align_center ltx_border_t">eICU</td>
<td id="S6.T2.4.4.5" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S6.T2.4.4.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S6.T2.4.4.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S6.T2.4.4.1.m1.1a"><mo id="S6.T2.4.4.1.m1.1.1" xref="S6.T2.4.4.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S6.T2.4.4.1.m1.1b"><times id="S6.T2.4.4.1.m1.1.1.cmml" xref="S6.T2.4.4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S6.T2.4.4.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S6.T2.4.4.6" class="ltx_td ltx_align_center ltx_border_t">Inference attack</td>
<td id="S6.T2.4.4.7" class="ltx_td ltx_align_center ltx_border_t">Anonymous random</td>
</tr>
<tr id="S6.T2.4.13.9" class="ltx_tr">
<td id="S6.T2.4.13.9.1" class="ltx_td"></td>
<td id="S6.T2.4.13.9.2" class="ltx_td ltx_align_center">an untrustable central</td>
<td id="S6.T2.4.13.9.3" class="ltx_td"></td>
<td id="S6.T2.4.13.9.4" class="ltx_td"></td>
<td id="S6.T2.4.13.9.5" class="ltx_td"></td>
<td id="S6.T2.4.13.9.6" class="ltx_td"></td>
<td id="S6.T2.4.13.9.7" class="ltx_td ltx_align_center">hybridization</td>
</tr>
<tr id="S6.T2.4.14.10" class="ltx_tr">
<td id="S6.T2.4.14.10.1" class="ltx_td"></td>
<td id="S6.T2.4.14.10.2" class="ltx_td ltx_align_center">analyzer in FL</td>
<td id="S6.T2.4.14.10.3" class="ltx_td"></td>
<td id="S6.T2.4.14.10.4" class="ltx_td"></td>
<td id="S6.T2.4.14.10.5" class="ltx_td"></td>
<td id="S6.T2.4.14.10.6" class="ltx_td"></td>
<td id="S6.T2.4.14.10.7" class="ltx_td"></td>
</tr>
<tr id="S6.T2.4.15.11" class="ltx_tr">
<td id="S6.T2.4.15.11.1" class="ltx_td"></td>
<td id="S6.T2.4.15.11.2" class="ltx_td ltx_align_center">&amp;</td>
<td id="S6.T2.4.15.11.3" class="ltx_td"></td>
<td id="S6.T2.4.15.11.4" class="ltx_td"></td>
<td id="S6.T2.4.15.11.5" class="ltx_td"></td>
<td id="S6.T2.4.15.11.6" class="ltx_td"></td>
<td id="S6.T2.4.15.11.7" class="ltx_td"></td>
</tr>
<tr id="S6.T2.4.16.12" class="ltx_tr">
<td id="S6.T2.4.16.12.1" class="ltx_td"></td>
<td id="S6.T2.4.16.12.2" class="ltx_td ltx_align_center">obtain similar performance</td>
<td id="S6.T2.4.16.12.3" class="ltx_td"></td>
<td id="S6.T2.4.16.12.4" class="ltx_td"></td>
<td id="S6.T2.4.16.12.5" class="ltx_td"></td>
<td id="S6.T2.4.16.12.6" class="ltx_td"></td>
<td id="S6.T2.4.16.12.7" class="ltx_td"></td>
</tr>
<tr id="S6.T2.4.17.13" class="ltx_tr">
<td id="S6.T2.4.17.13.1" class="ltx_td"></td>
<td id="S6.T2.4.17.13.2" class="ltx_td ltx_align_center">compared with a centralized</td>
<td id="S6.T2.4.17.13.3" class="ltx_td"></td>
<td id="S6.T2.4.17.13.4" class="ltx_td"></td>
<td id="S6.T2.4.17.13.5" class="ltx_td"></td>
<td id="S6.T2.4.17.13.6" class="ltx_td"></td>
<td id="S6.T2.4.17.13.7" class="ltx_td"></td>
</tr>
<tr id="S6.T2.4.18.14" class="ltx_tr">
<td id="S6.T2.4.18.14.1" class="ltx_td ltx_border_b"></td>
<td id="S6.T2.4.18.14.2" class="ltx_td ltx_align_center ltx_border_b">model</td>
<td id="S6.T2.4.18.14.3" class="ltx_td ltx_border_b"></td>
<td id="S6.T2.4.18.14.4" class="ltx_td ltx_border_b"></td>
<td id="S6.T2.4.18.14.5" class="ltx_td ltx_border_b"></td>
<td id="S6.T2.4.18.14.6" class="ltx_td ltx_border_b"></td>
<td id="S6.T2.4.18.14.7" class="ltx_td ltx_border_b"></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S6.SS4.4.1.1" class="ltx_text">VI-D</span> </span><span id="S6.SS4.5.2" class="ltx_text ltx_font_italic">Blockchain Techniques</span>
</h3>

<div id="S6.SS4.p1" class="ltx_para">
<p id="S6.SS4.p1.1" class="ltx_p">Blockchain is beneficial in many non-financial industries such as healthcare due to its cryptographic security, immutability, and accountability <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite>.
Researchers have recently started implementing blockchain technology to decentralize traditional data management systems. For instance, blockchain-based data management prevents security breaches and assure GDPR compliance <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite>. Therefore, blockchain-based PETs solutions can be used in Medical IoT to safeguard individuals’ rights over their personal data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite>. Accordingly,
Blockchain is a promising technique to improve the security and scalability of the FL system. This technique has provided a high level of security in the domain of healthcare by integrating blockchain into a federated learning to maintain the trained parameters <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite>. The blockchain-based system is effective for decentralized federated learning training without the need for any central server which can mitigate risks of single-point failures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite>. To provide IoHT data provenance, blockchain has shown great promise, and
also provides permission control of the participants
to enhance the security and privacy of
parameters in federated learning.
Blockchain has gained popularity for managing the trust and provenance of trustworthy federated nodes, their datasets, the accuracy of the models, and the immutability of the global model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite>. A blockchain method consists of public (permissionless), private and consortium (permissioned). A public blockchain system allows any client to participate in the decentralized process without the need for authorized permission. In a private and consortium system, only the client with authorized permission can be involved in the block validation and confirmation process.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VII </span><span id="S7.1.1" class="ltx_text ltx_font_smallcaps">PETs in Federated Learning</span>
</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this section, we discuss the security and privacy issues in FL from PETs perspective. The PETs used in FL can be
classified in several categories detailed as follows.</p>
</div>
<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS1.4.1.1" class="ltx_text">VII-A</span> </span><span id="S7.SS1.5.2" class="ltx_text ltx_font_italic">Anonymization Methods</span>
</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.2" class="ltx_p">Several research has been published in the literature that integrates anonymization techniques and FL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib106" title="" class="ltx_ref">106</a>]</cite>, and some of these studies attempt to evaluate the incorporation of FL and anonymization methods in a smart healthcare environment <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite>. For instance, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>, the authors proposed a syntactic anonymity approach to guarantee privacy in federated learning. They used the anonymization based on (<math id="S7.SS1.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S7.SS1.p1.1.m1.1a"><mi id="S7.SS1.p1.1.m1.1.1" xref="S7.SS1.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.1.m1.1b"><ci id="S7.SS1.p1.1.m1.1.1.cmml" xref="S7.SS1.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.1.m1.1c">k</annotation></semantics></math>, <math id="S7.SS1.p1.2.m2.1" class="ltx_Math" alttext="k^{n}" display="inline"><semantics id="S7.SS1.p1.2.m2.1a"><msup id="S7.SS1.p1.2.m2.1.1" xref="S7.SS1.p1.2.m2.1.1.cmml"><mi id="S7.SS1.p1.2.m2.1.1.2" xref="S7.SS1.p1.2.m2.1.1.2.cmml">k</mi><mi id="S7.SS1.p1.2.m2.1.1.3" xref="S7.SS1.p1.2.m2.1.1.3.cmml">n</mi></msup><annotation-xml encoding="MathML-Content" id="S7.SS1.p1.2.m2.1b"><apply id="S7.SS1.p1.2.m2.1.1.cmml" xref="S7.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S7.SS1.p1.2.m2.1.1.1.cmml" xref="S7.SS1.p1.2.m2.1.1">superscript</csymbol><ci id="S7.SS1.p1.2.m2.1.1.2.cmml" xref="S7.SS1.p1.2.m2.1.1.2">𝑘</ci><ci id="S7.SS1.p1.2.m2.1.1.3.cmml" xref="S7.SS1.p1.2.m2.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p1.2.m2.1c">k^{n}</annotation></semantics></math>)-anonymization algorithm. This approach contains two steps. In the first step, the anonymization method is applied to the original private data, which includes relational and a transactional attributes, at the local site and then feeds this anonymized data to a global model. The second step is a global anonymization mapping process, which can be used for the prediction process in the FL global model.
They evaluated the proposed method using Medical Information Mart for Intensive Care (MIMIC III)<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://registry.opendata.aws/mimiciii/</span></span></span> dataset gathered from
one
million patients. The results demonstrated that this approach enhances the level of privacy compared to the differential privacy method in FL.
</p>
</div>
<figure id="S7.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE III: </span>Summary of Cryptographic algorithms applied in FL for the smart healthcare environment</figcaption>
<table id="S7.T3.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S7.T3.5.6.1" class="ltx_tr">
<th id="S7.T3.5.6.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T3.5.6.1.1.1" class="ltx_text ltx_font_bold">Ref.</span></th>
<th id="S7.T3.5.6.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T3.5.6.1.2.1" class="ltx_text ltx_font_bold">Aim</span></th>
<th id="S7.T3.5.6.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T3.5.6.1.3.1" class="ltx_text ltx_font_bold">Dataset</span></th>
<th id="S7.T3.5.6.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T3.5.6.1.4.1" class="ltx_text ltx_font_bold">Dataset Available</span></th>
<th id="S7.T3.5.6.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T3.5.6.1.5.1" class="ltx_text ltx_font_bold">Open-Source</span></th>
<th id="S7.T3.5.6.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T3.5.6.1.6.1" class="ltx_text ltx_font_bold">Privacy Attack</span></th>
<th id="S7.T3.5.6.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T3.5.6.1.7.1" class="ltx_text ltx_font_bold">Privacy-Enhancing Method</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S7.T3.1.1" class="ltx_tr">
<td id="S7.T3.1.1.2" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite></td>
<td id="S7.T3.1.1.3" class="ltx_td ltx_align_center ltx_border_t">Preserving privacy in</td>
<td id="S7.T3.1.1.4" class="ltx_td ltx_align_center ltx_border_t">HAM10000</td>
<td id="S7.T3.1.1.5" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S7.T3.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S7.T3.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S7.T3.1.1.1.m1.1a"><mo id="S7.T3.1.1.1.m1.1.1" xref="S7.T3.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S7.T3.1.1.1.m1.1b"><times id="S7.T3.1.1.1.m1.1.1.cmml" xref="S7.T3.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S7.T3.1.1.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S7.T3.1.1.6" class="ltx_td ltx_align_center ltx_border_t">Inference attack</td>
<td id="S7.T3.1.1.7" class="ltx_td ltx_align_center ltx_border_t">Homomorphic encryption</td>
</tr>
<tr id="S7.T3.5.7.1" class="ltx_tr">
<td id="S7.T3.5.7.1.1" class="ltx_td"></td>
<td id="S7.T3.5.7.1.2" class="ltx_td ltx_align_center">skin cancer detection</td>
<td id="S7.T3.5.7.1.3" class="ltx_td"></td>
<td id="S7.T3.5.7.1.4" class="ltx_td"></td>
<td id="S7.T3.5.7.1.5" class="ltx_td"></td>
<td id="S7.T3.5.7.1.6" class="ltx_td"></td>
<td id="S7.T3.5.7.1.7" class="ltx_td ltx_align_center">&amp;</td>
</tr>
<tr id="S7.T3.5.8.2" class="ltx_tr">
<td id="S7.T3.5.8.2.1" class="ltx_td"></td>
<td id="S7.T3.5.8.2.2" class="ltx_td ltx_align_center">with reliable accuracy</td>
<td id="S7.T3.5.8.2.3" class="ltx_td"></td>
<td id="S7.T3.5.8.2.4" class="ltx_td"></td>
<td id="S7.T3.5.8.2.5" class="ltx_td"></td>
<td id="S7.T3.5.8.2.6" class="ltx_td"></td>
<td id="S7.T3.5.8.2.7" class="ltx_td ltx_align_center">secure multi-party computation</td>
</tr>
<tr id="S7.T3.2.2" class="ltx_tr">
<td id="S7.T3.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite></td>
<td id="S7.T3.2.2.3" class="ltx_td ltx_align_center ltx_border_t">Securing FL environ-</td>
<td id="S7.T3.2.2.4" class="ltx_td ltx_align_center ltx_border_t">UP-FALL</td>
<td id="S7.T3.2.2.5" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S7.T3.2.2.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S7.T3.2.2.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S7.T3.2.2.1.m1.1a"><mo id="S7.T3.2.2.1.m1.1.1" xref="S7.T3.2.2.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S7.T3.2.2.1.m1.1b"><times id="S7.T3.2.2.1.m1.1.1.cmml" xref="S7.T3.2.2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S7.T3.2.2.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S7.T3.2.2.6" class="ltx_td ltx_align_center ltx_border_t">Inference attack</td>
<td id="S7.T3.2.2.7" class="ltx_td ltx_align_center ltx_border_t">xMK-CKKS multi-key</td>
</tr>
<tr id="S7.T3.5.9.3" class="ltx_tr">
<td id="S7.T3.5.9.3.1" class="ltx_td"></td>
<td id="S7.T3.5.9.3.2" class="ltx_td ltx_align_center">ment on IoHT devices</td>
<td id="S7.T3.5.9.3.3" class="ltx_td"></td>
<td id="S7.T3.5.9.3.4" class="ltx_td"></td>
<td id="S7.T3.5.9.3.5" class="ltx_td"></td>
<td id="S7.T3.5.9.3.6" class="ltx_td"></td>
<td id="S7.T3.5.9.3.7" class="ltx_td ltx_align_center">homomorphic encryption</td>
</tr>
<tr id="S7.T3.3.3" class="ltx_tr">
<td id="S7.T3.3.3.2" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib110" title="" class="ltx_ref">110</a>]</cite></td>
<td id="S7.T3.3.3.3" class="ltx_td ltx_align_center ltx_border_t">Enhancing patient’s</td>
<td id="S7.T3.3.3.4" class="ltx_td ltx_align_center ltx_border_t">3D brain MRI</td>
<td id="S7.T3.3.3.5" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S7.T3.3.3.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S7.T3.3.3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S7.T3.3.3.1.m1.1a"><mo id="S7.T3.3.3.1.m1.1.1" xref="S7.T3.3.3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S7.T3.3.3.1.m1.1b"><times id="S7.T3.3.3.1.m1.1.1.cmml" xref="S7.T3.3.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S7.T3.3.3.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S7.T3.3.3.6" class="ltx_td ltx_align_center ltx_border_t">Membership</td>
<td id="S7.T3.3.3.7" class="ltx_td ltx_align_center ltx_border_t">fully homomorphic</td>
</tr>
<tr id="S7.T3.5.10.4" class="ltx_tr">
<td id="S7.T3.5.10.4.1" class="ltx_td"></td>
<td id="S7.T3.5.10.4.2" class="ltx_td ltx_align_center">data privacy</td>
<td id="S7.T3.5.10.4.3" class="ltx_td"></td>
<td id="S7.T3.5.10.4.4" class="ltx_td"></td>
<td id="S7.T3.5.10.4.5" class="ltx_td"></td>
<td id="S7.T3.5.10.4.6" class="ltx_td ltx_align_center">inference attack</td>
<td id="S7.T3.5.10.4.7" class="ltx_td ltx_align_center">encryption (FHE)</td>
</tr>
<tr id="S7.T3.4.4" class="ltx_tr">
<td id="S7.T3.4.4.2" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib111" title="" class="ltx_ref">111</a>]</cite></td>
<td id="S7.T3.4.4.3" class="ltx_td ltx_align_center ltx_border_t">Protect medical data</td>
<td id="S7.T3.4.4.4" class="ltx_td ltx_align_center ltx_border_t">eICU</td>
<td id="S7.T3.4.4.5" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S7.T3.4.4.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S7.T3.4.4.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S7.T3.4.4.1.m1.1a"><mo id="S7.T3.4.4.1.m1.1.1" xref="S7.T3.4.4.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S7.T3.4.4.1.m1.1b"><times id="S7.T3.4.4.1.m1.1.1.cmml" xref="S7.T3.4.4.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S7.T3.4.4.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S7.T3.4.4.6" class="ltx_td ltx_align_center ltx_border_t">Reverse</td>
<td id="S7.T3.4.4.7" class="ltx_td ltx_align_center ltx_border_t">Secure multi-party computation</td>
</tr>
<tr id="S7.T3.5.11.5" class="ltx_tr">
<td id="S7.T3.5.11.5.1" class="ltx_td"></td>
<td id="S7.T3.5.11.5.2" class="ltx_td ltx_align_center">privacy on IoHT devices</td>
<td id="S7.T3.5.11.5.3" class="ltx_td"></td>
<td id="S7.T3.5.11.5.4" class="ltx_td"></td>
<td id="S7.T3.5.11.5.5" class="ltx_td"></td>
<td id="S7.T3.5.11.5.6" class="ltx_td ltx_align_center">engineering</td>
<td id="S7.T3.5.11.5.7" class="ltx_td"></td>
</tr>
<tr id="S7.T3.5.12.6" class="ltx_tr">
<td id="S7.T3.5.12.6.1" class="ltx_td"></td>
<td id="S7.T3.5.12.6.2" class="ltx_td"></td>
<td id="S7.T3.5.12.6.3" class="ltx_td"></td>
<td id="S7.T3.5.12.6.4" class="ltx_td"></td>
<td id="S7.T3.5.12.6.5" class="ltx_td"></td>
<td id="S7.T3.5.12.6.6" class="ltx_td ltx_align_center">attack</td>
<td id="S7.T3.5.12.6.7" class="ltx_td"></td>
</tr>
<tr id="S7.T3.5.5" class="ltx_tr">
<td id="S7.T3.5.5.2" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite></td>
<td id="S7.T3.5.5.3" class="ltx_td ltx_align_center ltx_border_t">Privacy-enhanced</td>
<td id="S7.T3.5.5.4" class="ltx_td ltx_align_center ltx_border_t">Daily and Sports</td>
<td id="S7.T3.5.5.5" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S7.T3.5.5.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S7.T3.5.5.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S7.T3.5.5.1.m1.1a"><mo id="S7.T3.5.5.1.m1.1.1" xref="S7.T3.5.5.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S7.T3.5.5.1.m1.1b"><times id="S7.T3.5.5.1.m1.1.1.cmml" xref="S7.T3.5.5.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S7.T3.5.5.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S7.T3.5.5.6" class="ltx_td ltx_align_center ltx_border_t">Global aggregation</td>
<td id="S7.T3.5.5.7" class="ltx_td ltx_align_center ltx_border_t">Zero-knowledge proofs</td>
</tr>
<tr id="S7.T3.5.13.7" class="ltx_tr">
<td id="S7.T3.5.13.7.1" class="ltx_td"></td>
<td id="S7.T3.5.13.7.2" class="ltx_td ltx_align_center">decentralized</td>
<td id="S7.T3.5.13.7.3" class="ltx_td ltx_align_center">Activities</td>
<td id="S7.T3.5.13.7.4" class="ltx_td"></td>
<td id="S7.T3.5.13.7.5" class="ltx_td"></td>
<td id="S7.T3.5.13.7.6" class="ltx_td ltx_align_center">&amp;</td>
<td id="S7.T3.5.13.7.7" class="ltx_td"></td>
</tr>
<tr id="S7.T3.5.14.8" class="ltx_tr">
<td id="S7.T3.5.14.8.1" class="ltx_td ltx_border_b"></td>
<td id="S7.T3.5.14.8.2" class="ltx_td ltx_align_center ltx_border_b">applications</td>
<td id="S7.T3.5.14.8.3" class="ltx_td ltx_border_b"></td>
<td id="S7.T3.5.14.8.4" class="ltx_td ltx_border_b"></td>
<td id="S7.T3.5.14.8.5" class="ltx_td ltx_border_b"></td>
<td id="S7.T3.5.14.8.6" class="ltx_td ltx_align_center ltx_border_b">poisoning attack</td>
<td id="S7.T3.5.14.8.7" class="ltx_td ltx_border_b"></td>
</tr>
</tbody>
</table>
</figure>
<div id="S7.SS1.p2" class="ltx_para">
<p id="S7.SS1.p2.1" class="ltx_p">Similarly, Grama et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite> presented an adaptive privacy-preserving FL method for healthcare data. In order to enhance privacy, they used the k-anonymity method on top of the FL that can protect data by anonymization. In fact, anonymization by applying the data protection method can cause
information loss.
But, the proposed k-anonymity method in this paper decreases losing data. Similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>, the authors evaluated the performance of the proposed approach based on two health datasets to predict diabetes mellitus onset<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database</span></span></span> and heart failure diseases<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://archive.ics.uci.edu/ml/datasets/heart+disease</span></span></span>. Their results showed that the k-anonymity method using <math id="S7.SS1.p2.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S7.SS1.p2.1.m1.1a"><mi id="S7.SS1.p2.1.m1.1.1" xref="S7.SS1.p2.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S7.SS1.p2.1.m1.1b"><ci id="S7.SS1.p2.1.m1.1.1.cmml" xref="S7.SS1.p2.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S7.SS1.p2.1.m1.1c">k</annotation></semantics></math>=4 can improve the protection of the healthcare data, if it is applied to a dataset that contains an adequate number of samples.</p>
</div>
<div id="S7.SS1.p3" class="ltx_para">
<p id="S7.SS1.p3.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite>, the author presented a federated PF-NMF framework. This FL framework contains multiple local privacy filters (PF), which are used to remove sensitive data to minimize the risk of privacy leakage. In the training phase, PF acts as an encoder. The framework includes a decoder in the testing phase and feeds the test data into the autoencoder.
The author
evaluated the proposed approach on the MNIST <span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>https://www.tensorflow.org/datasets/catalog/mnist</span></span></span> and HARUS dataset (human static and dynamic activities gathered by wearable devices)<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition
+Using+Smartphones</span></span></span>. The results showed that federated PF-NMF achieves better accuracy and enhances the privacy of sensitive data.</p>
</div>
<div id="S7.SS1.p4" class="ltx_para">
<p id="S7.SS1.p4.1" class="ltx_p">In another work<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite>, the authors proposed a new method called federated machine learning with anonymous random hybridization (FeARH) to eliminate the privacy problems in an untrustworthy central analyzer. The hybridization algorithm adds the randomization into the parameter sets shared with other parties. With a hybrid algorithm, the medical data, which is replaced by a randomized parameters,
do not need to be shared with other institutions. They evaluated the proposed approach on eICU dataset<span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>https://eicu-crd.mit.edu/</span></span></span> and the results showed that FeARH achieves similar performance compared with FL and centralizes the machine learning method. Similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite>, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite> the authors use anonymized data in the training phase.
Table <a href="#S6.T2" title="TABLE II ‣ VI-C Perturbation Techniques ‣ VI Privacy enhancing technologies ‣ Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>
summarizes the representative existing anonymization techniques applied for FL in smart healthcare.</p>
</div>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS2.4.1.1" class="ltx_text">VII-B</span> </span><span id="S7.SS2.5.2" class="ltx_text ltx_font_italic">Cryptographic Algorithms</span>
</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p">Cryptographic methods are widely used in several FL methods to preserve data privacy when exchanging intermediate parameters during the FL training process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib115" title="" class="ltx_ref">115</a>]</cite>.
For example, similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite> which covers smart healthcare domain,
Zhang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite> presented the FL mechanism in the Internet of Healthcare Things (IoHT). They applied the cryptographic masking scheme based on homomorphic encryption and the secure multi-party computation to protect private medical data against reconstruction attacks or model inversion attacks. To evaluate the efficiency of the proposed FL model and validity of the privacy-enhancing masking scheme, the authors used real skin cancer datasets<span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/
DVN/DBW86T</span></span></span>. The result showed that the proposed model improves the privacy protection of the medical data and achieves reliable accuracy in skin cancer detection.</p>
</div>
<div id="S7.SS2.p2" class="ltx_para">
<p id="S7.SS2.p2.1" class="ltx_p">Ma et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite> proposed a novel privacy-enhancing FL on a smart healthcare scenario for elderly-fall detection, the authors used UP-FALL Detection dataset<span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>http://sites.google.com/up.edu.mx/har-up/</span></span></span>. Similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite>, they applied homomorphic encryption scheme to FL in order to prevent privacy leakage and achieve secure encryption
and decryption in the FL system. The proposed xMK-CKKS multi-key homomorphic encryption scheme utilizes an aggregated public key to encrypt the model updates before sharing them with a server for aggregation. The model decryption occurs after clients share information of their secret keys. The result showed that the proposed FL scheme using multi-key homomorphic encryption is effective in communication, computational cost, and energy consumption,
while ensuring the implementation of secure FL on IoHT devices.</p>
</div>
<div id="S7.SS2.p3" class="ltx_para">
<p id="S7.SS2.p3.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib110" title="" class="ltx_ref">110</a>]</cite>, the authors combined FL and fully homomorphic encryption (FHE) to define a novel secure FL framework for biomedical data analysis. They used the CKKS homomorphic encryption scheme based on ciphertext packing and rescaling, similarly to the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite>. The authors evaluated the performance of the proposed FL model using a large-scale 3D brain MRI dataset<span id="footnote9" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span>https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/
DVN/2RKAQP</span></span></span> to predict brain age in a secure environment. The result showed that the integration of a FL framework and encryption scheme does not reduce the efficiency of FL, also increases the privacy of the patient’s private data.</p>
</div>
<div id="S7.SS2.p4" class="ltx_para">
<p id="S7.SS2.p4.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib111" title="" class="ltx_ref">111</a>]</cite>, the authors provided a secure and scalable FL framework to implement AI across hospital sites, collaborators, and edge devices. Similarly to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite>, to address privacy challenges, they integrated the proposed FL framework with a secure multi-party computation algorithm to avoid data leakage and reverse engineering attacks via model updates. They evaluated the performance of the SMPC method in FL using the Philips ICU dataset. The results demonstrated that the developed FL framework with a SMPC algorithm can be used in a large ecosystem of the Internet of Healthcare Things (IoHT) and healthcare hospital sites. Moreover, the proposed framework significantly protects medical data privacy.</p>
</div>
<div id="S7.SS2.p5" class="ltx_para">
<p id="S7.SS2.p5.1" class="ltx_p">Heiss et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite> proposed a model for blockchain-based FL that leverages verifiable off-chain computations (VOC) using zero-knowledge proofs (ZKP). The architecture enables the computational correctness of
local learning processes verifiable on
blockchain and provides globally verifiable management of global learning parameters. They evaluated the performance of the architecture through an in-home health monitoring system where sensitive data serve as inputs to the FL system. The author used Daily and Sports Activities dataset<span id="footnote10" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span>https://archive.ics.uci.edu/ml/datasets/daily+and+sports+activities</span></span></span> and the results showed that verifiable off-chain computations (VOC) using zero-knowledge proofs (ZKP) enhances privacy in decentralized applications. Similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib111" title="" class="ltx_ref">111</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite>, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite>, the authors integrated zero-knowledge proofs (ZKP) with FL in order to enhance privacy in IoHT ecosystem. Table <a href="#S7.T3" title="TABLE III ‣ VII-A Anonymization Methods ‣ VII PETs in Federated Learning ‣ Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>
summarizes the cryptographic methods applied for FL in smart healthcare.</p>
</div>
</section>
<section id="S7.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS3.4.1.1" class="ltx_text">VII-C</span> </span><span id="S7.SS3.5.2" class="ltx_text ltx_font_italic">Perturbation Methods</span>
</h3>

<div id="S7.SS3.p1" class="ltx_para">
<p id="S7.SS3.p1.1" class="ltx_p">Similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>]</cite>, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite>, the authors proposed a bandwidth-efficient FL framework in IoHT environment. The framework ensures privacy for FL based on Differential Privacy (DP). They
discovered
that exchanging the model update from a huge amount of IoHT devices needs a significant bandwidth.
Therefore, they proposed the FL-SIGN-DP scheme to reduce communication costs and enhance privacy. Participants in FL-SIGN-DP only transmit the updated model’s sign to the aggregation server. They used the electronic health records of roughly a million patients to assess the performance of the proposed scheme with regard to the in-hospital mortality rate. The proposed scheme is compared with centralized learning, FL-SIGN without using standard FL, differential privacy, and differential privacy with standard FL. The results showed that the FL-SIGN-DP consumes less bandwidth and can guarantee privacy protection.</p>
</div>
<div id="S7.SS3.p2" class="ltx_para">
<p id="S7.SS3.p2.1" class="ltx_p">Islam et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite> proposed
a
FL model to analyze patients’ genomic data and identify the risk of heart failure. To enhance the privacy-preserving of the patient private data sharing among collaborating healthcare organizations in FL framework, they applied differential privacy mechanisms through feature selection based on statistical methods to increase scalability and accuracy in a federated setting where data are vertically partitioned. They evaluated the performance of the proposed FL framework using the IQVIA dataset and BC-TCGA dataset<span id="footnote11" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span>https://www.kaggle.com/datasets/saurabhshahane/gene-expression-profiles-of-breast-cancer</span></span></span>for predicting the causes of certain
heart failure and the BC-TCGA dataset for cancer prediction to compare their proposed FL method. The result demonstrated that their proposed model obtains better accuracy with the highest privacy for the IQVIA and BC-TCGA datasets in a federated training setting.</p>
</div>
<figure id="S7.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE IV: </span>Summary of Perturbation method applied in FL for the smart healthcare environment</figcaption>
<table id="S7.T4.6" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S7.T4.6.7.1" class="ltx_tr">
<th id="S7.T4.6.7.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T4.6.7.1.1.1" class="ltx_text ltx_font_bold">Ref.</span></th>
<th id="S7.T4.6.7.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T4.6.7.1.2.1" class="ltx_text ltx_font_bold">Aim</span></th>
<th id="S7.T4.6.7.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T4.6.7.1.3.1" class="ltx_text ltx_font_bold">Dataset</span></th>
<th id="S7.T4.6.7.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T4.6.7.1.4.1" class="ltx_text ltx_font_bold">Dataset Available</span></th>
<th id="S7.T4.6.7.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T4.6.7.1.5.1" class="ltx_text ltx_font_bold">Open-Source</span></th>
<th id="S7.T4.6.7.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T4.6.7.1.6.1" class="ltx_text ltx_font_bold">Privacy Attack</span></th>
<th id="S7.T4.6.7.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T4.6.7.1.7.1" class="ltx_text ltx_font_bold">Privacy-Enhancing Method</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S7.T4.1.1" class="ltx_tr">
<td id="S7.T4.1.1.2" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite></td>
<td id="S7.T4.1.1.3" class="ltx_td ltx_align_center ltx_border_t">Enhancing privacy</td>
<td id="S7.T4.1.1.4" class="ltx_td ltx_align_center ltx_border_t">Two real-world</td>
<td id="S7.T4.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S7.T4.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S7.T4.1.1.1.m1.1a"><mo id="S7.T4.1.1.1.m1.1.1" xref="S7.T4.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S7.T4.1.1.1.m1.1b"><times id="S7.T4.1.1.1.m1.1.1.cmml" xref="S7.T4.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S7.T4.1.1.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S7.T4.1.1.5" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S7.T4.1.1.6" class="ltx_td ltx_align_center ltx_border_t">Inference attack</td>
<td id="S7.T4.1.1.7" class="ltx_td ltx_align_center ltx_border_t">Differential privacy</td>
</tr>
<tr id="S7.T4.6.8.1" class="ltx_tr">
<td id="S7.T4.6.8.1.1" class="ltx_td"></td>
<td id="S7.T4.6.8.1.2" class="ltx_td ltx_align_center">&amp;</td>
<td id="S7.T4.6.8.1.3" class="ltx_td ltx_align_center">Electronic</td>
<td id="S7.T4.6.8.1.4" class="ltx_td"></td>
<td id="S7.T4.6.8.1.5" class="ltx_td"></td>
<td id="S7.T4.6.8.1.6" class="ltx_td"></td>
<td id="S7.T4.6.8.1.7" class="ltx_td"></td>
</tr>
<tr id="S7.T4.6.9.2" class="ltx_tr">
<td id="S7.T4.6.9.2.1" class="ltx_td"></td>
<td id="S7.T4.6.9.2.2" class="ltx_td ltx_align_center">bandwidth efficiency</td>
<td id="S7.T4.6.9.2.3" class="ltx_td ltx_align_center">Health Records</td>
<td id="S7.T4.6.9.2.4" class="ltx_td"></td>
<td id="S7.T4.6.9.2.5" class="ltx_td"></td>
<td id="S7.T4.6.9.2.6" class="ltx_td"></td>
<td id="S7.T4.6.9.2.7" class="ltx_td"></td>
</tr>
<tr id="S7.T4.2.2" class="ltx_tr">
<td id="S7.T4.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite></td>
<td id="S7.T4.2.2.3" class="ltx_td ltx_align_center ltx_border_t">Preserving privacy and predicting</td>
<td id="S7.T4.2.2.4" class="ltx_td ltx_align_center ltx_border_t">BC-TCGA</td>
<td id="S7.T4.2.2.5" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S7.T4.2.2.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S7.T4.2.2.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S7.T4.2.2.1.m1.1a"><mo id="S7.T4.2.2.1.m1.1.1" xref="S7.T4.2.2.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S7.T4.2.2.1.m1.1b"><times id="S7.T4.2.2.1.m1.1.1.cmml" xref="S7.T4.2.2.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S7.T4.2.2.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S7.T4.2.2.6" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S7.T4.2.2.7" class="ltx_td ltx_align_center ltx_border_t">Differential privacy</td>
</tr>
<tr id="S7.T4.6.10.3" class="ltx_tr">
<td id="S7.T4.6.10.3.1" class="ltx_td"></td>
<td id="S7.T4.6.10.3.2" class="ltx_td ltx_align_center">risk of heart failure</td>
<td id="S7.T4.6.10.3.3" class="ltx_td"></td>
<td id="S7.T4.6.10.3.4" class="ltx_td"></td>
<td id="S7.T4.6.10.3.5" class="ltx_td"></td>
<td id="S7.T4.6.10.3.6" class="ltx_td"></td>
<td id="S7.T4.6.10.3.7" class="ltx_td"></td>
</tr>
<tr id="S7.T4.4.4" class="ltx_tr">
<td id="S7.T4.4.4.3" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>]</cite></td>
<td id="S7.T4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">Avoiding medical data leakage</td>
<td id="S7.T4.4.4.5" class="ltx_td ltx_align_center ltx_border_t">Dataset of a</td>
<td id="S7.T4.3.3.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S7.T4.3.3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S7.T4.3.3.1.m1.1a"><mo id="S7.T4.3.3.1.m1.1.1" xref="S7.T4.3.3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S7.T4.3.3.1.m1.1b"><times id="S7.T4.3.3.1.m1.1.1.cmml" xref="S7.T4.3.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S7.T4.3.3.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S7.T4.4.4.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S7.T4.4.4.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S7.T4.4.4.2.m1.1a"><mo id="S7.T4.4.4.2.m1.1.1" xref="S7.T4.4.4.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S7.T4.4.4.2.m1.1b"><times id="S7.T4.4.4.2.m1.1.1.cmml" xref="S7.T4.4.4.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S7.T4.4.4.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S7.T4.4.4.6" class="ltx_td ltx_align_center ltx_border_t">Adversarial
attack</td>
<td id="S7.T4.4.4.7" class="ltx_td ltx_align_center ltx_border_t">Differential privacy</td>
</tr>
<tr id="S7.T4.6.11.4" class="ltx_tr">
<td id="S7.T4.6.11.4.1" class="ltx_td"></td>
<td id="S7.T4.6.11.4.2" class="ltx_td ltx_align_center">during data exchange</td>
<td id="S7.T4.6.11.4.3" class="ltx_td ltx_align_center">tumor hospitals</td>
<td id="S7.T4.6.11.4.4" class="ltx_td"></td>
<td id="S7.T4.6.11.4.5" class="ltx_td"></td>
<td id="S7.T4.6.11.4.6" class="ltx_td"></td>
<td id="S7.T4.6.11.4.7" class="ltx_td"></td>
</tr>
<tr id="S7.T4.5.5" class="ltx_tr">
<td id="S7.T4.5.5.2" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite></td>
<td id="S7.T4.5.5.3" class="ltx_td ltx_align_center ltx_border_t">privacy-preserving IoHT</td>
<td id="S7.T4.5.5.4" class="ltx_td ltx_align_center ltx_border_t">ADReSS</td>
<td id="S7.T4.5.5.5" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S7.T4.5.5.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S7.T4.5.5.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S7.T4.5.5.1.m1.1a"><mo id="S7.T4.5.5.1.m1.1.1" xref="S7.T4.5.5.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S7.T4.5.5.1.m1.1b"><times id="S7.T4.5.5.1.m1.1.1.cmml" xref="S7.T4.5.5.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S7.T4.5.5.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S7.T4.5.5.6" class="ltx_td ltx_align_center ltx_border_t">Man-in-the-middle</td>
<td id="S7.T4.5.5.7" class="ltx_td ltx_align_center ltx_border_t">Differential privacy</td>
</tr>
<tr id="S7.T4.6.12.5" class="ltx_tr">
<td id="S7.T4.6.12.5.1" class="ltx_td"></td>
<td id="S7.T4.6.12.5.2" class="ltx_td ltx_align_center">Alzheimer’s disease detection</td>
<td id="S7.T4.6.12.5.3" class="ltx_td"></td>
<td id="S7.T4.6.12.5.4" class="ltx_td"></td>
<td id="S7.T4.6.12.5.5" class="ltx_td"></td>
<td id="S7.T4.6.12.5.6" class="ltx_td ltx_align_center">attack</td>
<td id="S7.T4.6.12.5.7" class="ltx_td"></td>
</tr>
<tr id="S7.T4.6.6" class="ltx_tr">
<td id="S7.T4.6.6.2" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib120" title="" class="ltx_ref">120</a>]</cite></td>
<td id="S7.T4.6.6.3" class="ltx_td ltx_align_center ltx_border_t">Preserving privacy and improving</td>
<td id="S7.T4.6.6.4" class="ltx_td ltx_align_center ltx_border_t">DarkCOVID</td>
<td id="S7.T4.6.6.5" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S7.T4.6.6.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S7.T4.6.6.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S7.T4.6.6.1.m1.1a"><mo id="S7.T4.6.6.1.m1.1.1" xref="S7.T4.6.6.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S7.T4.6.6.1.m1.1b"><times id="S7.T4.6.6.1.m1.1.1.cmml" xref="S7.T4.6.6.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S7.T4.6.6.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S7.T4.6.6.6" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S7.T4.6.6.7" class="ltx_td ltx_align_center ltx_border_t">Differential privacy</td>
</tr>
<tr id="S7.T4.6.13.6" class="ltx_tr">
<td id="S7.T4.6.13.6.1" class="ltx_td ltx_border_b"></td>
<td id="S7.T4.6.13.6.2" class="ltx_td ltx_align_center ltx_border_b">COVID19 detection</td>
<td id="S7.T4.6.13.6.3" class="ltx_td ltx_align_center ltx_border_b">ChestCOVID</td>
<td id="S7.T4.6.13.6.4" class="ltx_td ltx_border_b"></td>
<td id="S7.T4.6.13.6.5" class="ltx_td ltx_border_b"></td>
<td id="S7.T4.6.13.6.6" class="ltx_td ltx_border_b"></td>
<td id="S7.T4.6.13.6.7" class="ltx_td ltx_border_b"></td>
</tr>
</tbody>
</table>
</figure>
<div id="S7.SS3.p3" class="ltx_para">
<p id="S7.SS3.p3.1" class="ltx_p">The authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib118" title="" class="ltx_ref">118</a>]</cite> proposed federated adversarial learning (FAL) on biomedical named entity recognition (BioNER). The differential privacy technology is also used to protect the security and privacy of the data, which adds Gaussian noise during the local training and model aggregation process to enhance privacy. More specifically, only the noised parameters with differential privacy are transferred among the server and the client. Therefore, the data leakage possibility has decreased on the local client’s side. The dataset collected from 5 departments of a tumor hospital is used to examine the performance of the proposed scheme. The Result showed that the proposed FAL framework can connect data parties and prevent data leakage during data exchange inside medical institutions.</p>
</div>
<div id="S7.SS3.p4" class="ltx_para">
<p id="S7.SS3.p4.1" class="ltx_p">Similarly to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite>, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib119" title="" class="ltx_ref">119</a>]</cite>, the authors proposed a cost-effective
and privacy-preserving FL framework which is IoHT Alzheimer’s disease detection scheme.
They presented an FL based privacy-preserving
smart healthcare system, namely ADDetector, to detect Alzheimer’s
disease. Moreover, they implemented a differential privacy (DP)
mechanism on the user data to avoid patient’s data leakage during
transferring data to the client and enhance the privacy level
against the attacker. An ADReSS Challenge dataset from INTERSPEECH
2020<span id="footnote12" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span>https://luzs.gitlab.io/adress/</span></span></span> is used to evaluate the performance of the ADDetector FL-based
scheme. The proposed FL-based framework and DP-based mechanism use
the audio from smart devices to detect low-cost Alzheimer’s
disease. The experimental results showed that the ADDETECTOR
FL-based framework achieves better accuracy and low average time
overhead with a high level of privacy and security protection.</p>
</div>
<div id="S7.SS3.p5" class="ltx_para">
<p id="S7.SS3.p5.1" class="ltx_p">Dinh et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib120" title="" class="ltx_ref">120</a>]</cite> proposed an FL framework, called FedGAN, to facilitate COVID-19 detection by enhancing privacy among medical institutions in edge cloud computing. The aim of the framework is to create realistic COVID-19 X-ray data and detect it automatically without the need for sharing COVID-19 image with parties. Additionally, they integrated a differential privacy at each hospital site to increase and guarantee the data privacy in federated COVID-19 data training. To apply the differential privacy, they used both differentially private stochastic gradient descent and a gradient perturbation technique; they also added the Gaussian noises to the gradient during the training. Additionally, they use the FedGAN blockchain-based system for safe COVID-19 data analysis. To evaluate the performance of proposed FedGAN model, they used two popular COVID-19 X-ray data sets for simulations, including a DarkCOVID<span id="footnote13" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span>https://github.com/ieee8023/COVID-chestxray-dataset</span></span></span> and a ChestCOVID<span id="footnote14" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span>https://github.com/ieee8023/covid-chestxray-dataset</span></span></span> dataset. The result demonstrated that FedGAN framework enhances the performance of COVID-19 detection and provides high level of privacy. Table <a href="#S7.T4" title="TABLE IV ‣ VII-C Perturbation Methods ‣ VII PETs in Federated Learning ‣ Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a> presents a summary of the perturbation methods applied for FL in smart healthcare.</p>
</div>
<figure id="S7.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE V: </span>Summary of Blockchain method applied in FL for the smart healthcare environment</figcaption>
<table id="S7.T5.8" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S7.T5.8.9.1" class="ltx_tr">
<th id="S7.T5.8.9.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T5.8.9.1.1.1" class="ltx_text ltx_font_bold">Ref.</span></th>
<th id="S7.T5.8.9.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T5.8.9.1.2.1" class="ltx_text ltx_font_bold">Aim</span></th>
<th id="S7.T5.8.9.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T5.8.9.1.3.1" class="ltx_text ltx_font_bold">Dataset</span></th>
<th id="S7.T5.8.9.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T5.8.9.1.4.1" class="ltx_text ltx_font_bold">Dataset Available</span></th>
<th id="S7.T5.8.9.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T5.8.9.1.5.1" class="ltx_text ltx_font_bold">Open-Source</span></th>
<th id="S7.T5.8.9.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T5.8.9.1.6.1" class="ltx_text ltx_font_bold">Privacy Attack</span></th>
<th id="S7.T5.8.9.1.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S7.T5.8.9.1.7.1" class="ltx_text ltx_font_bold">Privacy-Enhancing Method</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S7.T5.2.2" class="ltx_tr">
<td id="S7.T5.2.2.3" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite></td>
<td id="S7.T5.2.2.4" class="ltx_td ltx_align_center ltx_border_t">IoMT privacy-preserving</td>
<td id="S7.T5.2.2.5" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S7.T5.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S7.T5.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S7.T5.1.1.1.m1.1a"><mo id="S7.T5.1.1.1.m1.1.1" xref="S7.T5.1.1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S7.T5.1.1.1.m1.1b"><times id="S7.T5.1.1.1.m1.1.1.cmml" xref="S7.T5.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.1.1.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S7.T5.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S7.T5.2.2.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S7.T5.2.2.2.m1.1a"><mo id="S7.T5.2.2.2.m1.1.1" xref="S7.T5.2.2.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S7.T5.2.2.2.m1.1b"><times id="S7.T5.2.2.2.m1.1.1.cmml" xref="S7.T5.2.2.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.2.2.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S7.T5.2.2.6" class="ltx_td ltx_align_center ltx_border_t">Backdoors</td>
<td id="S7.T5.2.2.7" class="ltx_td ltx_align_center ltx_border_t">Blockchain</td>
</tr>
<tr id="S7.T5.8.10.1" class="ltx_tr">
<td id="S7.T5.8.10.1.1" class="ltx_td"></td>
<td id="S7.T5.8.10.1.2" class="ltx_td ltx_align_center">&amp;</td>
<td id="S7.T5.8.10.1.3" class="ltx_td"></td>
<td id="S7.T5.8.10.1.4" class="ltx_td"></td>
<td id="S7.T5.8.10.1.5" class="ltx_td"></td>
<td id="S7.T5.8.10.1.6" class="ltx_td ltx_align_center">&amp;</td>
<td id="S7.T5.8.10.1.7" class="ltx_td"></td>
</tr>
<tr id="S7.T5.8.11.2" class="ltx_tr">
<td id="S7.T5.8.11.2.1" class="ltx_td"></td>
<td id="S7.T5.8.11.2.2" class="ltx_td ltx_align_center">predict the COVID-19</td>
<td id="S7.T5.8.11.2.3" class="ltx_td"></td>
<td id="S7.T5.8.11.2.4" class="ltx_td"></td>
<td id="S7.T5.8.11.2.5" class="ltx_td"></td>
<td id="S7.T5.8.11.2.6" class="ltx_td ltx_align_center">Inference attack</td>
<td id="S7.T5.8.11.2.7" class="ltx_td"></td>
</tr>
<tr id="S7.T5.4.4" class="ltx_tr">
<td id="S7.T5.4.4.3" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite></td>
<td id="S7.T5.4.4.4" class="ltx_td ltx_align_center ltx_border_t">Preserving data privacy</td>
<td id="S7.T5.4.4.5" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S7.T5.3.3.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S7.T5.3.3.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S7.T5.3.3.1.m1.1a"><mo id="S7.T5.3.3.1.m1.1.1" xref="S7.T5.3.3.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S7.T5.3.3.1.m1.1b"><times id="S7.T5.3.3.1.m1.1.1.cmml" xref="S7.T5.3.3.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.3.3.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S7.T5.4.4.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S7.T5.4.4.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S7.T5.4.4.2.m1.1a"><mo id="S7.T5.4.4.2.m1.1.1" xref="S7.T5.4.4.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S7.T5.4.4.2.m1.1b"><times id="S7.T5.4.4.2.m1.1.1.cmml" xref="S7.T5.4.4.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.4.4.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S7.T5.4.4.6" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S7.T5.4.4.7" class="ltx_td ltx_align_center ltx_border_t">Blockchain</td>
</tr>
<tr id="S7.T5.8.12.3" class="ltx_tr">
<td id="S7.T5.8.12.3.1" class="ltx_td"></td>
<td id="S7.T5.8.12.3.2" class="ltx_td ltx_align_center">&amp;</td>
<td id="S7.T5.8.12.3.3" class="ltx_td"></td>
<td id="S7.T5.8.12.3.4" class="ltx_td"></td>
<td id="S7.T5.8.12.3.5" class="ltx_td"></td>
<td id="S7.T5.8.12.3.6" class="ltx_td"></td>
<td id="S7.T5.8.12.3.7" class="ltx_td"></td>
</tr>
<tr id="S7.T5.8.13.4" class="ltx_tr">
<td id="S7.T5.8.13.4.1" class="ltx_td"></td>
<td id="S7.T5.8.13.4.2" class="ltx_td ltx_align_center">predicting COVID-19</td>
<td id="S7.T5.8.13.4.3" class="ltx_td"></td>
<td id="S7.T5.8.13.4.4" class="ltx_td"></td>
<td id="S7.T5.8.13.4.5" class="ltx_td"></td>
<td id="S7.T5.8.13.4.6" class="ltx_td"></td>
<td id="S7.T5.8.13.4.7" class="ltx_td"></td>
</tr>
<tr id="S7.T5.6.6" class="ltx_tr">
<td id="S7.T5.6.6.3" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite></td>
<td id="S7.T5.6.6.4" class="ltx_td ltx_align_center ltx_border_t">Fraud-detection for</td>
<td id="S7.T5.6.6.5" class="ltx_td ltx_align_center ltx_border_t">ECG heartbeat</td>
<td id="S7.T5.5.5.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S7.T5.5.5.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S7.T5.5.5.1.m1.1a"><mo id="S7.T5.5.5.1.m1.1.1" xref="S7.T5.5.5.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S7.T5.5.5.1.m1.1b"><times id="S7.T5.5.5.1.m1.1.1.cmml" xref="S7.T5.5.5.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.5.5.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S7.T5.6.6.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S7.T5.6.6.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S7.T5.6.6.2.m1.1a"><mo id="S7.T5.6.6.2.m1.1.1" xref="S7.T5.6.6.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S7.T5.6.6.2.m1.1b"><times id="S7.T5.6.6.2.m1.1.1.cmml" xref="S7.T5.6.6.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.6.6.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S7.T5.6.6.6" class="ltx_td ltx_align_center ltx_border_t">Fraud attack</td>
<td id="S7.T5.6.6.7" class="ltx_td ltx_align_center ltx_border_t">Blockchain</td>
</tr>
<tr id="S7.T5.8.14.5" class="ltx_tr">
<td id="S7.T5.8.14.5.1" class="ltx_td"></td>
<td id="S7.T5.8.14.5.2" class="ltx_td ltx_align_center">IoHT</td>
<td id="S7.T5.8.14.5.3" class="ltx_td ltx_align_center">E-Heart videos</td>
<td id="S7.T5.8.14.5.4" class="ltx_td"></td>
<td id="S7.T5.8.14.5.5" class="ltx_td"></td>
<td id="S7.T5.8.14.5.6" class="ltx_td"></td>
<td id="S7.T5.8.14.5.7" class="ltx_td"></td>
</tr>
<tr id="S7.T5.8.15.6" class="ltx_tr">
<td id="S7.T5.8.15.6.1" class="ltx_td"></td>
<td id="S7.T5.8.15.6.2" class="ltx_td"></td>
<td id="S7.T5.8.15.6.3" class="ltx_td ltx_align_center">Blood pressure</td>
<td id="S7.T5.8.15.6.4" class="ltx_td"></td>
<td id="S7.T5.8.15.6.5" class="ltx_td"></td>
<td id="S7.T5.8.15.6.6" class="ltx_td"></td>
<td id="S7.T5.8.15.6.7" class="ltx_td"></td>
</tr>
<tr id="S7.T5.8.8" class="ltx_tr">
<td id="S7.T5.8.8.3" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite></td>
<td id="S7.T5.8.8.4" class="ltx_td ltx_align_center ltx_border_t">Privacy preserving for</td>
<td id="S7.T5.8.8.5" class="ltx_td ltx_align_center ltx_border_t">Healthcare data</td>
<td id="S7.T5.7.7.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S7.T5.7.7.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S7.T5.7.7.1.m1.1a"><mo id="S7.T5.7.7.1.m1.1.1" xref="S7.T5.7.7.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S7.T5.7.7.1.m1.1b"><times id="S7.T5.7.7.1.m1.1.1.cmml" xref="S7.T5.7.7.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.7.7.1.m1.1c">\times</annotation></semantics></math></td>
<td id="S7.T5.8.8.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S7.T5.8.8.2.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S7.T5.8.8.2.m1.1a"><mo id="S7.T5.8.8.2.m1.1.1" xref="S7.T5.8.8.2.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S7.T5.8.8.2.m1.1b"><times id="S7.T5.8.8.2.m1.1.1.cmml" xref="S7.T5.8.8.2.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S7.T5.8.8.2.m1.1c">\times</annotation></semantics></math></td>
<td id="S7.T5.8.8.6" class="ltx_td ltx_align_center ltx_border_t">Replay attack</td>
<td id="S7.T5.8.8.7" class="ltx_td ltx_align_center ltx_border_t">Blockchain</td>
</tr>
<tr id="S7.T5.8.16.7" class="ltx_tr">
<td id="S7.T5.8.16.7.1" class="ltx_td"></td>
<td id="S7.T5.8.16.7.2" class="ltx_td ltx_align_center">IoHT in cloud</td>
<td id="S7.T5.8.16.7.3" class="ltx_td"></td>
<td id="S7.T5.8.16.7.4" class="ltx_td"></td>
<td id="S7.T5.8.16.7.5" class="ltx_td"></td>
<td id="S7.T5.8.16.7.6" class="ltx_td"></td>
<td id="S7.T5.8.16.7.7" class="ltx_td"></td>
</tr>
<tr id="S7.T5.8.17.8" class="ltx_tr">
<td id="S7.T5.8.17.8.1" class="ltx_td ltx_align_center ltx_border_t"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite></td>
<td id="S7.T5.8.17.8.2" class="ltx_td ltx_align_center ltx_border_t">Preserving the patient’s</td>
<td id="S7.T5.8.17.8.3" class="ltx_td ltx_align_center ltx_border_t">CC-19</td>
<td id="S7.T5.8.17.8.4" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S7.T5.8.17.8.5" class="ltx_td ltx_align_center ltx_border_t">✓</td>
<td id="S7.T5.8.17.8.6" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S7.T5.8.17.8.7" class="ltx_td ltx_align_center ltx_border_t">Blockchain</td>
</tr>
<tr id="S7.T5.8.18.9" class="ltx_tr">
<td id="S7.T5.8.18.9.1" class="ltx_td"></td>
<td id="S7.T5.8.18.9.2" class="ltx_td ltx_align_center">privacy and detection</td>
<td id="S7.T5.8.18.9.3" class="ltx_td"></td>
<td id="S7.T5.8.18.9.4" class="ltx_td"></td>
<td id="S7.T5.8.18.9.5" class="ltx_td"></td>
<td id="S7.T5.8.18.9.6" class="ltx_td"></td>
<td id="S7.T5.8.18.9.7" class="ltx_td"></td>
</tr>
<tr id="S7.T5.8.19.10" class="ltx_tr">
<td id="S7.T5.8.19.10.1" class="ltx_td ltx_border_b"></td>
<td id="S7.T5.8.19.10.2" class="ltx_td ltx_align_center ltx_border_b">COVID-19 CT scan</td>
<td id="S7.T5.8.19.10.3" class="ltx_td ltx_border_b"></td>
<td id="S7.T5.8.19.10.4" class="ltx_td ltx_border_b"></td>
<td id="S7.T5.8.19.10.5" class="ltx_td ltx_border_b"></td>
<td id="S7.T5.8.19.10.6" class="ltx_td ltx_border_b"></td>
<td id="S7.T5.8.19.10.7" class="ltx_td ltx_border_b"></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S7.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S7.SS4.4.1.1" class="ltx_text">VII-D</span> </span><span id="S7.SS4.5.2" class="ltx_text ltx_font_italic">Blockchain Methods</span>
</h3>

<div id="S7.SS4.p1" class="ltx_para">
<p id="S7.SS4.p1.1" class="ltx_p">Blockchain methods have been widely used in many FL methods to provide privacy and security in IoHT (smart healthcare systems).</p>
</div>
<div id="S7.SS4.p2" class="ltx_para">
<p id="S7.SS4.p2.1" class="ltx_p">For smart healthcare systems, the authors of <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite> proposed an infrastructure called FedMedChain, which is based on secure FL and blockchain to predict the COVID-19 for IoMT scenarios, similarly to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib120" title="" class="ltx_ref">120</a>]</cite> which proposes an privacy-preserving FL-based scheme for analysis of COVID-19 data in a secure environment. The proposed system can improve public communication and address the challenges of big data silos and data security. Furthermore, information security and privacy analyses showed that the proposed infrastructure is robust against privacy breaches and can improve information security.</p>
</div>
<div id="S7.SS4.p3" class="ltx_para">
<p id="S7.SS4.p3.1" class="ltx_p">Similarly to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite>, to solve privacy concerns, the authors in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib122" title="" class="ltx_ref">122</a>]</cite> presented a model based on the FL and blockchain,
which is
used to predict COVID-19 symptoms, how it spreads, and speed up using the medical data in research and treatment.
In addition, the combination of FL and blockchain could be useful for real time environment and for organizations that do not want share sensitive data with third parties because of privacy concerns. After analyzing the combination of blockchain and FL solution, the authors noted that the proposed solution securely protects the data access and would help to build a robust model.</p>
</div>
<div id="S7.SS4.p4" class="ltx_para">
<p id="S7.SS4.p4.1" class="ltx_p">Similarly to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite>, Lakhan et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite> proposed a privacy-preserving FL for IoMT system. It is a mathematical model called FL-BETS, which is a FL-based privacy enhancing and malware detection-enable blockchain IoMT system
for
different healthcare
workloads. The aim of this study is to preserve privacy and fraud of data in the local fog nodes and remote clouds network with minimum energy consumption and delay. The performance evaluation of the FL-BETS framework, compared to other existing machine learning and blockchain methods in malware analysis shows the best performance in fraud analysis, data validation, energy and delay constraints for healthcare applications. Also, the model decreases energy consumption by 41%
and delay by 28%.</p>
</div>
<div id="S7.SS4.p5" class="ltx_para">
<p id="S7.SS4.p5.1" class="ltx_p">Similar to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib123" title="" class="ltx_ref">123</a>]</cite>, in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib124" title="" class="ltx_ref">124</a>]</cite>, the authors proposed the model by integrating Blockchain and FL-enabled approaches to provide a secure architecture for privacy preservation in smart healthcare systems. In this model, blockchain-based IoT cloud apps enhance security and privacy by combining FL and blockchain technologies. The proposed model has provided secure data sharing for the IoHT environment with privacy preservation. Organizations can use federated-based blockchain cloud architecture without collaborating sensitive and private healthcare system data in the cloud.</p>
</div>
<div id="S7.SS4.p6" class="ltx_para">
<p id="S7.SS4.p6.1" class="ltx_p">Kumar et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib125" title="" class="ltx_ref">125</a>]</cite> developed an FL blockchain-based approach to train the global model for detection
of
COVID-19 patients based on Computed tomography (CT) slices while preserving the privacy of patients’ private data and the organization, similarly to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib121" title="" class="ltx_ref">121</a>]</cite>. The proposed model evaluated real-life COVID-19 patients’ data<span id="footnote15" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">15</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">15</sup><span class="ltx_tag ltx_tag_note">15</span>https://paperswithcode.com/dataset/cc-19</span></span></span> that were collected from various hospitals with different types of CT scanners and publicly available to the research community. The results showed that the blockchain-based FL smartly detects COVID-19 patients using computed tomography (CT) scans among various hospitals while preserving sensitive data privacy.
Table <a href="#S7.T5" title="TABLE V ‣ VII-C Perturbation Methods ‣ VII PETs in Federated Learning ‣ Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> summarizes
the blockchain methods applied for FL in smart healthcare.</p>
</div>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VIII </span><span id="S8.1.1" class="ltx_text ltx_font_smallcaps">Key challenges for future research</span>
</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">While PETs in FL have many advantages and have been growing rapidly in recent years, some challenges cannot be ignored. Existing frameworks are still at an early stage and need improving methods to enhance data privacy.</p>
</div>
<section id="S8.SS0.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S8.SS0.SSS1.4.1.1" class="ltx_text">VIII-</span>1 </span>Computation cost</h4>

<div id="S8.SS0.SSS1.p1" class="ltx_para">
<p id="S8.SS0.SSS1.p1.1" class="ltx_p">One of the main challenges of FL is represented by privacy-enhancing to prevent data leakage. FL needs multiple iterations to achieve the final global model. Therefore, the number of training iterations has a direct impact on increasing the cost of the training model. As shown in
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib111" title="" class="ltx_ref">111</a>]</cite>, multi-party computation is a way to protect data privacy in FL. Performing experiments with a different number of workers does not impact the computation cost, however, increasing the number of training rounds significantly
boosts
the computation cost. Therefore, the trade-off between privacy risk and computation time has been a promising topic for researchers.</p>
</div>
</section>
<section id="S8.SS0.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S8.SS0.SSS2.4.1.1" class="ltx_text">VIII-</span>2 </span>Privacy and security</h4>

<div id="S8.SS0.SSS2.p1" class="ltx_para">
<p id="S8.SS0.SSS2.p1.1" class="ltx_p">In Section <a href="#S7.SS4" title="VII-D Blockchain Methods ‣ VII PETs in Federated Learning ‣ Privacy-Enhancing Technologies in Federated Learning for the Internet of Healthcare Things: A Survey" class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">VII-D</span></span></a>, some studies show that integration of the blockchain method and FL is a way to enhance privacy in IoHT. However, there is an open issue that may lead to privacy leakage. In the FL, only the central server has information about the sources of the local model updates, and the addresses of the clients are private. However, addresses in blockchain are public, and using blockchain in FL gives the ability to other clients to communicate with each other and obtain the training model based on the public information from the blockchain. Therefore, the risk of data leakage among clients cannot be ignored.</p>
</div>
</section>
<section id="S8.SS0.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S8.SS0.SSS3.4.1.1" class="ltx_text">VIII-</span>3 </span>Linkage attacks</h4>

<div id="S8.SS0.SSS3.p1" class="ltx_para">
<p id="S8.SS0.SSS3.p1.1" class="ltx_p">The k-anonymity technique is a way to preserve the anonymity of individuals. The key idea is how to modify the
attributes of the dataset in a way that each instance has at
least <math id="S8.SS0.SSS3.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S8.SS0.SSS3.p1.1.m1.1a"><mi id="S8.SS0.SSS3.p1.1.m1.1.1" xref="S8.SS0.SSS3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S8.SS0.SSS3.p1.1.m1.1b"><ci id="S8.SS0.SSS3.p1.1.m1.1.1.cmml" xref="S8.SS0.SSS3.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S8.SS0.SSS3.p1.1.m1.1c">k</annotation></semantics></math>-1 other entities with identical quasi-identifiers. Therefore, an identifiable record would link to multiple records in the anonymous dataset. However, k-anonymity cannot avoid privacy leakage against linkage attacks where a sensitive attribute is shared among a group of individuals with the same quasi-identifier.</p>
</div>
</section>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IX </span><span id="S9.1.1" class="ltx_text ltx_font_smallcaps">Conclusions</span>
</h2>

<div id="S9.p1" class="ltx_para">
<p id="S9.p1.1" class="ltx_p">This survey has reviewed nineteen representative works that apply federated learning (FL) in the Internet of Healthcare Things (IoHT) domain in terms of privacy aspects, including attacks and privacy-enhancing technologies (PETs). The datasets used by these works have also been summarized, which are helpful for researchers aiming to reproduce these works.
Some open research issues on the topic still exist, such as the trade-off between privacy risk and computational time, the risk of data leakage among colluding clients, and the sharing of sensitive attributes.
Along with the current research efforts, we encourage more insights into the problems of this area and more efforts in addressing the open research issues identified in this paper.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_font_smallcaps ltx_title_section">Acknowledgments</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This research is part of the INCT of the Future Internet for Smart Cities funded by CNPq proc. 465446/2014-0, Coordenação de Aperfeiçoamento de Pessoal de Nível Superior – Brasil (CAPES) – Finance Code 001, FAPESP proc. 14/50937-1 and proc. 15/24485-9.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
N. Mani, A. Singh, and S. L. Nimmagadda, “An iot guided healthcare monitoring
system for managing real-time notifications by fog computing services,”
<em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Procedia Computer Science</em>, vol. 167, pp. 850–859, 2020.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
J. Cheng, W. Wu, J. Cao, and K. Li, “Fuzzy group-based intersection control
via vehicular networks for smart transportations,” <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions
on Industrial Informatics</em>, vol. 13, no. 2, pp. 751–758, 2016.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
B. L. R. Stojkoska and K. V. Trivodaliev, “A review of internet of things for
smart home: Challenges and solutions,” <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Journal of cleaner production</em>,
vol. 140, pp. 1454–1464, 2017.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Z. Chen, C. Sivaparthipan, and B. Muthu, “Iot based smart and intelligent
smart city energy optimization,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Sustainable Energy Technologies and
Assessments</em>, vol. 49, p. 101724, 2022.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
G. Aceto, V. Persico, and A. Pescapé, “Industry 4.0 and health: Internet
of things, big data, and cloud computing for healthcare 4.0,” <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Journal
of Industrial Information Integration</em>, vol. 18, p. 100129, 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
J.-F. Rajotte, S. Mukherjee, C. Robinson, A. Ortiz, C. West, J. M. L. Ferres,
and R. T. Ng, “Reducing bias and increasing utility by federated generative
modeling of medical images using a centralized adversary,” in
<em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Conference on Information Technology for Social
Good</em>, 2021, pp. 79–84.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
E. Vayena, A. Blasimme, and I. G. Cohen, “Machine learning in medicine:
addressing ethical challenges,” <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">PLoS medicine</em>, vol. 15, no. 11, p.
e1002689, 2018.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
M. Joshi, A. Pal, and M. Sankarasubbu, “Federated learning for healthcare
domain-pipeline, applications and challenges,” <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">ACM Transactions on
Computing for Healthcare</em>, 2022.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
O. Aouedi, A. Sacco, K. Piamrat, and G. Marchetto, “Handling privacy-sensitive
medical data with federated learning: Challenges and future directions,”
<em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">IEEE Journal of Biomedical and Health Informatics</em>, 2022.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Q. Yang, Y. Liu, T. Chen, and Y. Tong, “Federated machine learning: Concept
and applications,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">ACM TIST</em>, vol. 10, no. 2, pp. 1–19, 2019.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
R. S. Antunes, C. André da Costa, A. Küderle, I. A. Yari, and
B. Eskofier, “Federated learning for healthcare: Systematic review and
architecture proposal,” <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">ACM TIST</em>, vol. 13, no. 4, pp. 1–23, 2022.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
M. Asad, A. Moustafa, and C. Yu, “A critical evaluation of privacy and
security threats in federated learning,” <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Sensors</em>, vol. 20, no. 24, p.
7182, 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
G. Danezis, “An introduction to privacy enhancing technologies,” in
<em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Internet Society Geneva’s Monthly Conferences Cycle, Geneva,
Switzerland</em>, 2004.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Z. Abou El Houda, A. S. Hafid, and L. Khoukhi, “Mitfed: A privacy preserving
collaborative network attack mitigation framework based on federated learning
using sdn and blockchain,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Network Science and
Engineering</em>, 2023.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
B. Yu, W. Mao, Y. Lv, C. Zhang, and Y. Xie, “A survey on federated learning in
data mining,” <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Wiley Interdisciplinary Reviews: Data Mining and
Knowledge Discovery</em>, vol. 12, no. 1, p. e1443, 2022.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Z. Xue, P. Zhou, Z. Xu, X. Wang, Y. Xie, X. Ding, and S. Wen, “A
resource-constrained and privacy-preserving edge-computing-enabled clinical
decision system: A federated reinforcement learning approach,” <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">IEEE
Internet of Things Journal</em>, vol. 8, no. 11, pp. 9122–9138, 2021.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
M. Hao, D. Ye, S. Wang, B. Tan, and R. Yu, “Urllc resource slicing and
scheduling for trustworthy 6g vehicular services: A federated reinforcement
learning approach,” <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Physical Communication</em>, vol. 49, p. 101470, 2021.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
L. Zhang, B. Shen, A. Barnawi, S. Xi, N. Kumar, and Y. Wu, “Feddpgan:
federated differentially private generative adversarial networks framework
for the detection of covid-19 pneumonia,” <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Information Systems
Frontiers</em>, vol. 23, no. 6, pp. 1403–1415, 2021.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
G. M. Garrido, J. Sedlmeir, Ö. Uludağ, I. S. Alaoui, A. Luckow, and
F. Matthes, “Revealing the landscape of privacy-enhancing technologies in
the context of data markets for the iot: A systematic literature review,”
<em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Journal of Network and Computer Applications</em>, p. 103465, 2022.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
M. Aledhari, R. Razzak, R. M. Parizi, and F. Saeed, “Federated Learning: A
Survey on Enabling Technologies, Protocols, and Applications,” <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">IEEE
Access</em>, vol. 8, pp. 140 699–140 725, 2020.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
C. Zhang, Y. Xie, H. Bai, B. Yu, W. Li, and Y. Gao, “A survey on federated
learning,” <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Knowledge-Based Systems</em>, vol. 216, p. 106775, 2021.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
V. Mothukuri, R. M. Parizi, S. Pouriyeh, Y. Huang, A. Dehghantanha, and
G. Srivastava, “A Survey on Security and Privacy of Federated Learning,”
<em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Future Generation Computer Systems</em>, vol. 115, pp. 619–640, 2021.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
D. C. Nguyen, M. Ding, P. N. Pathirana, A. Seneviratne, J. Li, and
H. Vincent Poor, “Federated Learning for Internet of Things: A
Comprehensive Survey,” <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">IEEE COMST</em>, vol. 23, no. 3, pp. 1622–1658,
2021.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
E. Novikova, D. Fomichov, I. Kholod, and E. Filippov, “Analysis of
privacy-enhancing technologies in open-source federated learning frameworks
for driver activity recognition,” <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Sensors</em>, vol. 22, no. 8, p. 2983,
2022.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
D. C. Nguyen, Q.-V. Pham, P. N. Pathirana, M. Ding, A. Seneviratne, Z. Lin,
O. Dobre, and W.-J. Hwang, “Federated Learning for Smart Healthcare: A
Survey,” <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">ACM Comput. Surv.</em>, vol. 55, no. 3, feb 2022.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” in <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Artificial intelligence and statistics</em>.   PMLR, 2017, pp. 1273–1282.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
J. Konečnỳ, H. B. McMahan, F. X. Yu, P. Richtárik, A. T. Suresh,
and D. Bacon, “Federated learning: Strategies for improving communication
efficiency,” <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.05492</em>, 2016.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
P. M. Mammen, “Federated learning: opportunities and challenges,” <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv
preprint arXiv:2101.05428</em>, 2021.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
B. Pfitzner, N. Steckhan, and B. Arnrich, “Federated learning in a medical
context: a systematic literature review,” <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">ACM TOIT</em>, vol. 21, no. 2,
pp. 1–31, 2021.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
T. Zhang and S. Mao, “An introduction to the federated learning standard,”
<em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">GetMobile: Mobile Computing and Communications</em>, vol. 25, no. 3, pp.
18–22, 2022.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
C.-R. Shyu, K. T. Putra, H.-C. Chen, Y.-Y. Tsai, K. T. Hossain, W. Jiang, and
Z.-Y. Shae, “A systematic review of federated learning in the healthcare
area: From the perspective of data properties and applications,”
<em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Applied Sciences</em>, vol. 11, no. 23, p. 11191, 2021.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Y. Chen, X. Qin, J. Wang, C. Yu, and W. Gao, “Fedhealth: A federated transfer
learning framework for wearable healthcare,” <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">IEEE Intelligent
Systems</em>, vol. 35, no. 4, pp. 83–93, 2020.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
D. C. Nguyen, Q.-V. Pham, P. N. Pathirana, M. Ding, A. Seneviratne, Z. Lin,
O. Dobre, and W.-J. Hwang, “Federated learning for smart healthcare: A
survey,” <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys (CSUR)</em>, vol. 55, no. 3, pp. 1–37,
2022.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
H. Huang, J. Zhou, W. Li, J. Zhang, X. Zhang, and G. Hou, “Wearable indoor
localisation approach in internet of things,” <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">IET Networks</em>, vol. 5,
no. 5, pp. 122–126, 2016.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
G. Mooney, “Is hipaa compliant with the gdpr?” 2018.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
R. C. Barrows Jr and P. D. Clayton, “Privacy, confidentiality, and electronic
medical records,” <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Journal of the American medical informatics
association</em>, vol. 3, no. 2, pp. 139–148, 1996.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
D. Ng, X. Lan, M. M.-S. Yao, W. P. Chan, and M. Feng, “Federated learning: a
collaborative effort to achieve better medical imaging models for individual
sites that have small labelled datasets,” <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">Quantitative Imaging in
Medicine and Surgery</em>, vol. 11, no. 2, p. 852, 2021.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Y. Zhao, J. Zhao, L. Jiang, R. Tan, D. Niyato, Z. Li, L. Lyu, and Y. Liu,
“Privacy-preserving blockchain-based federated learning for iot devices,”
<em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, vol. 8, no. 3, pp. 1817–1829, 2020.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
O. A. Wahab, A. Mourad, H. Otrok, and T. Taleb, “Federated machine learning:
Survey, multi-level classification, desirable criteria and future directions
in communication and networking systems,” <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys
&amp; Tutorials</em>, vol. 23, no. 2, pp. 1342–1397, 2021.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
M. J. Sheller, B. Edwards, G. A. Reina, J. Martin, S. Pati, A. Kotrotsou,
M. Milchenko, W. Xu, D. Marcus, R. R. Colen <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated
learning in medicine: facilitating multi-institutional collaborations without
sharing patient data,” <em id="bib.bib40.2.2" class="ltx_emph ltx_font_italic">Scientific reports</em>, vol. 10, no. 1, pp. 1–12,
2020.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
N. Rieke, J. Hancox, W. Li, F. Milletari, H. R. Roth, S. Albarqouni, S. Bakas,
M. N. Galtier, B. A. Landman, K. Maier-Hein <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “The future of
digital health with federated learning,” <em id="bib.bib41.2.2" class="ltx_emph ltx_font_italic">NPJ digital medicine</em>,
vol. 3, no. 1, pp. 1–7, 2020.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
W. Y. B. Lim, N. C. Luong, D. T. Hoang, Y. Jiao, Y.-C. Liang, Q. Yang,
D. Niyato, and C. Miao, “Federated learning in mobile edge networks: A
comprehensive survey,” <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">IEEE COMST</em>, vol. 22, no. 3, pp. 2031–2063,
2020.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
L. U. Khan, W. Saad, Z. Han, E. Hossain, and C. S. Hong, “Federated learning
for internet of things: Recent advances, taxonomy, and open challenges,”
<em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">IEEE COMST</em>, 2021.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
L. U. Khan, S. R. Pandey, N. H. Tran, W. Saad, Z. Han, M. N. Nguyen, and C. S.
Hong, “Federated learning for edge networks: Resource optimization and
incentive mechanism,” <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">IEEE COMMAG</em>, vol. 58, no. 10, pp. 88–93, 2020.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
L. Melis, C. Song, E. De Cristofaro, and V. Shmatikov, “Exploiting unintended
feature leakage in collaborative learning,” in <em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">IEEE Symposium on
Security and Privacy</em>, 2019, pp. 691–706.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
A. Bhowmick, J. Duchi, J. Freudiger, G. Kapoor, and R. Rogers, “Protection
against reconstruction and its applications in private federated learning,”
<em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.00984</em>, 2018.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
L. Zhu, Z. Liu, and S. Han, “Deep leakage from gradients,” <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">Advances in
neural information processing systems</em>, vol. 32, 2019.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Y. Aono, T. Hayashi, L. Wang, S. Moriai <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Privacy-preserving
deep learning via additively homomorphic encryption,” <em id="bib.bib48.2.2" class="ltx_emph ltx_font_italic">IEEE
Transactions on Information Forensics and Security</em>, vol. 13, no. 5, pp.
1333–1345, 2017.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
A. N. Bhagoji, S. Chakraborty, P. Mittal, and S. Calo, “Analyzing federated
learning through an adversarial lens,” in <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">International Conference on
Machine Learning</em>.   PMLR, 2019, pp.
634–643.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Z. Ying, Y. Zhang, and X. Liu, “Privacy-preserving in defending against
membership inference attacks,” in <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2020 Workshop on
Privacy-Preserving Machine Learning in Practice</em>, 2020, pp. 61–63.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
E. Bagdasaryan, A. Veit, Y. Hua, D. Estrin, and V. Shmatikov, “How to backdoor
federated learning,” in <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">International Conference on Artificial
Intelligence and Statistics</em>.   PMLR,
2020, pp. 2938–2948.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
X. Zhou, M. Xu, Y. Wu, and N. Zheng, “Deep model poisoning attack on federated
learning,” <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">Future Internet</em>, vol. 13, no. 3, p. 73, 2021.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
V. Tolpegin, S. Truex, M. E. Gursoy, and L. Liu, “Data poisoning attacks
against federated learning systems,” in <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">European Symposium on Research
in Computer Security</em>.   Springer, 2020,
pp. 480–501.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
D. Cao, S. Chang, Z. Lin, G. Liu, and D. Sun, “Understanding distributed
poisoning attack in federated learning,” in <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">IEEE 25th ICPADS</em>, 2019,
pp. 233–239.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
L. Lyu, H. Yu, and Q. Yang, “Threats to federated learning: A survey,”
<em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2003.02133</em>, 2020.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
M. S. Jere, T. Farnan, and F. Koushanfar, “A taxonomy of attacks on federated
learning,” <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">IEEE Security &amp; Privacy</em>, vol. 19, no. 2, pp. 20–28,
2020.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
J. Sun, A. Li, B. Wang, H. Yang, H. Li, and Y. Chen, “Soteria: Provable
defense against privacy leakage in federated learning from representation
perspective,” in <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF conference on computer
vision and pattern recognition</em>, 2021, pp. 9311–9319.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
J. Zhang, J. Zhang, J. Chen, and S. Yu, “Gan enhanced membership inference: A
passive local attack in federated learning,” in <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">ICC 2020-2020 IEEE
International Conference on Communications (ICC)</em>.   IEEE, 2020, pp. 1–6.

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Z. Wang, Y. Huang, M. Song, L. Wu, F. Xue, and K. Ren, “Poisoning-assisted
property inference attack against federated learning,” <em id="bib.bib59.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Dependable and Secure Computing</em>, 2022.

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Q. Duan, S. Hu, R. Deng, and Z. Lu, “Combined federated and split learning in
edge computing for ubiquitous intelligence in internet of things:
State-of-the-art and future directions,” <em id="bib.bib60.1.1" class="ltx_emph ltx_font_italic">Sensors</em>, vol. 22, no. 16, p.
5983, 2022.

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
B. Hitaj, G. Ateniese, and F. Perez-Cruz, “Deep models under the gan:
information leakage from collaborative deep learning,” in <em id="bib.bib61.1.1" class="ltx_emph ltx_font_italic">Proceedings
of the 2017 ACM SIGSAC conference on computer and communications security</em>,
2017, pp. 603–618.

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Z. Wang, M. Song, Z. Zhang, Y. Song, Q. Wang, and H. Qi, “Beyond inferring
class representatives: User-level privacy leakage from federated learning,”
in <em id="bib.bib62.1.1" class="ltx_emph ltx_font_italic">IEEE INFOCOM 2019-IEEE conference on computer communications</em>.   IEEE, 2019, pp. 2512–2520.

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
M. Shen, H. Wang, B. Zhang, L. Zhu, K. Xu, Q. Li, and X. Du, “Exploiting
unintended property leakage in blockchain-assisted federated learning for
intelligent edge computing,” <em id="bib.bib63.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>, vol. 8,
no. 4, pp. 2265–2275, 2020.

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
W. Wei, L. Liu, M. Loper, K.-H. Chow, M. E. Gursoy, S. Truex, and Y. Wu, “A
framework for evaluating client privacy leakages in federated learning,” in
<em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">European Symposium on Research in Computer Security</em>.   Springer, 2020, pp. 545–566.

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
H. Zeng, T. Zhou, X. Wu, and Z. Cai, “Never too late: Tracing and mitigating
backdoor attacks in federated learning,” in <em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">2022 41st International
Symposium on Reliable Distributed Systems (SRDS)</em>.   IEEE, 2022, pp. 69–81.

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Z. Yin, Y. Yuan, P. Guo, and P. Zhou, “Backdoor attacks on federated learning
with lottery ticket hypothesis,” <em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2109.10512</em>,
2021.

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Z. Sun, P. Kairouz, A. T. Suresh, and H. B. McMahan, “Can you really backdoor
federated learning?” <em id="bib.bib67.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1911.07963</em>, 2019.

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
S. Fischer-Hübner, <em id="bib.bib68.1.1" class="ltx_emph ltx_font_italic">IT-security and privacy: design and use of
privacy-enhancing security mechanisms</em>.   Springer, 2001.

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
A. Abbas and S. U. Khan, “A review on the state-of-the-art privacy-preserving
approaches in the e-health clouds,” <em id="bib.bib69.1.1" class="ltx_emph ltx_font_italic">IEEE journal of Biomedical and
health informatics</em>, vol. 18, no. 4, pp. 1431–1441, 2014.

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
J. Parra-Arnau, D. Rebollo-Monedero, and J. Forné, “Privacy-enhancing
technologies and metrics in personalized information systems,” in
<em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">Advanced research in data privacy</em>.   Springer, 2014, pp. 423–442.

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
H. Liu, R. G. Crespo, and O. S. Martínez, “Enhancing privacy and data
security across healthcare applications using blockchain and distributed
ledger concepts,” in <em id="bib.bib71.1.1" class="ltx_emph ltx_font_italic">Healthcare</em>, vol. 8, no. 3.   MDPI, 2020, p. 243.

</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock">
G. Dhiman, S. Juneja, H. Mohafez, I. El-Bayoumy, L. K. Sharma, M. Hadizadeh,
M. A. Islam, W. Viriyasitavat, and M. U. Khandaker, “Federated learning
approach to protect healthcare data over big data scenario,”
<em id="bib.bib72.1.1" class="ltx_emph ltx_font_italic">Sustainability</em>, vol. 14, no. 5, p. 2500, 2022.

</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock">
P. Samarati and L. Sweeney, “Protecting privacy when disclosing information:
k-anonymity and its enforcement through generalization and suppression,”
SRI International, Tech. Rep., 1998.

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock">
O. Choudhury, A. Gkoulalas-Divanis, T. Salonidis, I. Sylla, Y. Park, G. Hsu,
and A. Das, “Anonymizing data for privacy-preserving federated learning,”
<em id="bib.bib74.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.09096</em>, 2020.

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock">
A. Machanavajjhala, D. Kifer, J. Gehrke, and M. Venkitasubramaniam,
“l-diversity: Privacy beyond k-anonymity,” <em id="bib.bib75.1.1" class="ltx_emph ltx_font_italic">ACM TKDD</em>, vol. 1, no. 1,
pp. 3–es, 2007.

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock">
Y. Sei, H. Okumura, T. Takenouchi, and A. Ohsuga, “Anonymization of sensitive
quasi-identifiers for l-diversity and t-closeness,” <em id="bib.bib76.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions
on Dependable and Secure Computing</em>, vol. 16, no. 4, pp. 580–593, 2017.

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock">
J. Domingo-Ferrer and J. Soria-Comas, “From t-closeness to differential
privacy and vice versa in data anonymization,” <em id="bib.bib77.1.1" class="ltx_emph ltx_font_italic">Knowledge-Based
Systems</em>, vol. 74, pp. 151–158, 2015.

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock">
A. Blanco-Justicia, J. Domingo-Ferrer, S. Martínez, D. Sánchez,
A. Flanagan, and K. E. Tan, “Achieving security and privacy in federated
learning systems: Survey, research challenges and future directions,”
<em id="bib.bib78.1.1" class="ltx_emph ltx_font_italic">Engineering Applications of Artificial Intelligence</em>, vol. 106, p.
104468, 2021.

</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock">
L. Li, Y. Fan, M. Tse, and K.-Y. Lin, “A review of applications in federated
learning,” <em id="bib.bib79.1.1" class="ltx_emph ltx_font_italic">Computers &amp; Industrial Engineering</em>, vol. 149, p. 106854,
2020.

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock">
J. Liu, J. Huang, Y. Zhou, X. Li, S. Ji, H. Xiong, and D. Dou, “From
distributed machine learning to federated learning: A survey,”
<em id="bib.bib80.1.1" class="ltx_emph ltx_font_italic">Knowledge and Information Systems</em>, pp. 1–33, 2022.

</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock">
A. C. Yao, “Protocols for secure computations,” in <em id="bib.bib81.1.1" class="ltx_emph ltx_font_italic">23rd Annual
Symposium on Foundations of Computer Science</em>.   IEEE, 1982, pp. 160–164.

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock">
X. Yin, Y. Zhu, and J. Hu, “A comprehensive survey of privacy-preserving
federated learning: A taxonomy, review, and future directions,” <em id="bib.bib82.1.1" class="ltx_emph ltx_font_italic">ACM
Computing Surveys (CSUR)</em>, vol. 54, no. 6, pp. 1–36, 2021.

</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock">
X. Ma, L. Liao, Z. Li, R. X. Lai, and M. Zhang, “Applying federated learning
in software-defined networks: A survey,” <em id="bib.bib83.1.1" class="ltx_emph ltx_font_italic">Symmetry</em>, vol. 14, no. 2, p.
195, 2022.

</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock">
S. Goldwasser, S. Micali, and C. Rackoff, “The knowledge complexity of
interactive proof systems,” <em id="bib.bib84.1.1" class="ltx_emph ltx_font_italic">SIAM Journal on computing</em>, vol. 18,
no. 1, pp. 186–208, 1989.

</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock">
X. Guo, Z. Liu, J. Li, J. Gao, B. Hou, C. Dong, and T. Baker, “V eri fl:
Communication-efficient and fast verifiable aggregation for federated
learning,” <em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Information Forensics and Security</em>,
vol. 16, pp. 1736–1751, 2020.

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock">
W. Liu, X. Wang, and W. Peng, “Secure remote multi-factor authentication
scheme based on chaotic map zero-knowledge proof for crowdsourcing internet
of things,” <em id="bib.bib86.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 8, pp. 8754–8767, 2019.

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock">
Q. Li, Z. Wu, Z. Wen, and B. He, “Privacy-preserving gradient boosting
decision trees,” in <em id="bib.bib87.1.1" class="ltx_emph ltx_font_italic">Proceedings of the AAAI Conference on Artificial
Intelligence</em>, vol. 34, no. 01, 2020, pp. 784–791.

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock">
S. Jordan, C. Fontaine, and R. Hendricks-Sturrup, “Selecting privacy-enhancing
technologies for managing health data use,” <em id="bib.bib88.1.1" class="ltx_emph ltx_font_italic">Frontiers in Public
Health</em>, vol. 10, 2022.

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock">
X. Xiao, G. Wang, and J. Gehrke, “Differential privacy via wavelet
transforms,” <em id="bib.bib89.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on knowledge and data engineering</em>,
vol. 23, no. 8, pp. 1200–1214, 2010.

</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock">
S. Song, K. Chaudhuri, and A. D. Sarwate, “Stochastic gradient descent with
differentially private updates,” in <em id="bib.bib90.1.1" class="ltx_emph ltx_font_italic">IEEE Global Conference on Signal
and Information Processing</em>, 2013, pp. 245–248.

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock">
T.-H. H. Chan, M. Li, E. Shi, and W. Xu, “Differentially private continual
monitoring of heavy hitters from distributed streams,” in
<em id="bib.bib91.1.1" class="ltx_emph ltx_font_italic">International Symposium on Privacy Enhancing Technologies
Symposium</em>.   Springer, 2012, pp.
140–159.

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock">
G. Cormode, S. Jha, T. Kulkarni, N. Li, D. Srivastava, and T. Wang, “Privacy
at scale: Local differential privacy in practice,” in <em id="bib.bib92.1.1" class="ltx_emph ltx_font_italic">Proceedings of
the 2018 International Conference on Management of Data</em>, 2018, pp.
1655–1658.

</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock">
N. Kaaniche, M. Laurent, and S. Belguith, “Privacy enhancing technologies for
solving the privacy-personalization paradox: Taxonomy and survey,”
<em id="bib.bib93.1.1" class="ltx_emph ltx_font_italic">Journal of Network and Computer Applications</em>, vol. 171, p. 102807,
2020.

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock">
O. Choudhury, A. Gkoulalas-Divanis, T. Salonidis, I. Sylla, Y. Park, G. Hsu,
and A. Das, “A syntactic approach for privacy-preserving federated
learning,” in <em id="bib.bib94.1.1" class="ltx_emph ltx_font_italic">ECAI 2020</em>.   IOS
Press, 2020, pp. 1762–1769.

</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock">
M. Grama, M. Musat, L. Muñoz-González, J. Passerat-Palmbach,
D. Rueckert, and A. Alansary, “Robust aggregation for adaptive privacy
preserving federated learning in healthcare,” <em id="bib.bib95.1.1" class="ltx_emph ltx_font_italic">arXiv preprint
arXiv:2009.08294</em>, 2020.

</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock">
Z. Alsulaimawi, “A non-negative matrix factorization framework for
privacy-preserving and federated learning,” in <em id="bib.bib96.1.1" class="ltx_emph ltx_font_italic">IEEE 22nd International
Workshop on Multimedia Signal Processing</em>, 2020, pp. 1–6.

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock">
J. Cui, H. Zhu, H. Deng, Z. Chen, and D. Liu, “Fearh: Federated machine
learning with anonymous random hybridization on electronic medical records,”
<em id="bib.bib97.1.1" class="ltx_emph ltx_font_italic">Journal of Biomedical Informatics</em>, vol. 117, p. 103735, 2021.

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock">
I. T. Javed, F. Alharbi, T. Margaria, N. Crespi, and K. N. Qureshi, “Petchain:
a blockchain-based privacy enhancing technology,” <em id="bib.bib98.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>,
vol. 9, pp. 41 129–41 143, 2021.

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock">
N. B. Truong, K. Sun, G. M. Lee, and Y. Guo, “Gdpr-compliant personal data
management: A blockchain-based solution,” <em id="bib.bib99.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on
Information Forensics and Security</em>, vol. 15, pp. 1746–1761, 2019.

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock">
B. Alamri, I. T. Javed, and T. Margaria, “Preserving patients’ privacy in
medical iot using blockchain,” in <em id="bib.bib100.1.1" class="ltx_emph ltx_font_italic">Edge Computing–EDGE 2020: 4th
International Conference, Held as Part of the Services Conference Federation,
SCF 2020, Honolulu, HI, USA, September 18-20, 2020, Proceedings 4</em>.   Springer, 2020, pp. 103–110.

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock">
Y. Lu, X. Huang, K. Zhang, S. Maharjan, and Y. Zhang, “Blockchain and
federated learning for 5g beyond,” <em id="bib.bib101.1.1" class="ltx_emph ltx_font_italic">IEEE Network</em>, vol. 35, no. 1, pp.
219–225, 2020.

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock">
D. C. Nguyen, M. Ding, Q.-V. Pham, P. N. Pathirana, L. B. Le, A. Seneviratne,
J. Li, D. Niyato, and H. V. Poor, “Federated learning meets blockchain in
edge computing: Opportunities and challenges,” <em id="bib.bib102.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things
Journal</em>, vol. 8, no. 16, pp. 12 806–12 825, 2021.

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock">
R. Hu, Z. Yan, W. Ding, and L. T. Yang, “A survey on data provenance in iot,”
<em id="bib.bib103.1.1" class="ltx_emph ltx_font_italic">World Wide Web</em>, vol. 23, no. 2, pp. 1441–1463, 2020.

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock">
T. Orekondy, S. J. Oh, Y. Zhang, B. Schiele, and M. Fritz, “Gradient-leaks:
Understanding and controlling deanonymization in federated learning,”
<em id="bib.bib104.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1805.05838</em>, 2018.

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock">
W. Hao, N. Mehta, K. J. Liang, P. Cheng, M. El-Khamy, and L. Carin, “Waffle:
Weight anonymized factorization for federated learning,” <em id="bib.bib105.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em>,
vol. 10, pp. 49 207–49 218, 2022.

</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock">
M. Song, Z. Wang, Z. Zhang, Y. Song, Q. Wang, J. Ren, and H. Qi, “Analyzing
user-level privacy attack against federated learning,” <em id="bib.bib106.1.1" class="ltx_emph ltx_font_italic">IEEE JSAC</em>,
vol. 38, no. 10, pp. 2430–2444, 2020.

</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock">
F. Marulli, L. Verde, S. Marrone, R. Barone, and M. S. De Biase, “Evaluating
efficiency and effectiveness of federated learning approaches in knowledge
extraction tasks,” in <em id="bib.bib107.1.1" class="ltx_emph ltx_font_italic">International Joint Conference on Neural
Networks</em>.   IEEE, 2021, pp. 1–6.

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock">
L. Zhang, J. Xu, P. Vijayakumar, P. K. Sharma, and U. Ghosh, “Homomorphic
encryption-based privacy-preserving federated learning in iot-enabled
healthcare system,” <em id="bib.bib108.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Network Science and
Engineering</em>, 2022.

</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock">
J. Ma, S.-A. Naas, S. Sigg, and X. Lyu, “Privacy-preserving federated learning
based on multi-key homomorphic encryption,” <em id="bib.bib109.1.1" class="ltx_emph ltx_font_italic">International Journal of
Intelligent Systems</em>, 2022.

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock">
D. Stripelis, H. Saleem, T. Ghai, N. Dhinagar, U. Gupta, C. Anastasiou,
G. Ver Steeg, S. Ravi, M. Naveed, P. M. Thompson <em id="bib.bib110.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Secure
neuroimaging analysis using federated learning with homomorphic encryption,”
in <em id="bib.bib110.2.2" class="ltx_emph ltx_font_italic">17th International Symposium on Medical Information Processing and
Analysis</em>, vol. 12088.   SPIE, 2021, pp.
351–359.

</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock">
A. S. Rachakonda, B. S. Moorthy, C. A. Jain, D. A. Bukharev, E. A. Bucur, F. F.
Manni, G. T. M. Quiterio, H. L. Joosten, and I. N. I. Mendez, “Privacy
enhancing and scalable federated learning to accelerate ai implementation in
cross-silo and iomt environments,” <em id="bib.bib111.1.1" class="ltx_emph ltx_font_italic">IEEE Journal of Biomedical and
Health Informatics</em>, 2022.

</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock">
J. Heiss, E. Grünewald, N. Haimerl, S. Schulte, and S. Tai, “Advancing
blockchain-based federated learning through verifiable off-chain
computations,” <em id="bib.bib112.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2206.11641</em>, 2022.

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock">
F. Wibawa, F. O. Catak, M. Kuzlu, S. Sarp, and U. Cali, “Homomorphic
encryption and federated learning based privacy-preserving cnn training:
Covid-19 detection use-case,” in <em id="bib.bib113.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 European
Interdisciplinary Cybersecurity Conference</em>, 2022, pp. 85–90.

</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock">
Y. Bai and M. Fan, “A method to improve the privacy and security for federated
learning,” in <em id="bib.bib114.1.1" class="ltx_emph ltx_font_italic">IEEE 6th ICCCS</em>, 2021, pp. 704–708.

</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock">
F. Wibawa, F. O. Catak, S. Sarp, and M. Kuzlu, “Bfv-based homomorphic
encryption for privacy-preserving cnn models,” <em id="bib.bib115.1.1" class="ltx_emph ltx_font_italic">Cryptography</em>, vol. 6,
no. 3, p. 34, 2022.

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock">
R. Kerkouche, G. Acs, C. Castelluccia, and P. Genevès, “Privacy-preserving
and bandwidth-efficient federated learning: An application to in-hospital
mortality prediction,” in <em id="bib.bib116.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Conference on Health,
Inference, and Learning</em>, 2021, pp. 25–35.

</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock">
T. U. Islam, R. Ghasemi, and N. Mohammed, “Privacy-preserving federated
learning model for healthcare data,” in <em id="bib.bib117.1.1" class="ltx_emph ltx_font_italic">IEEE 12th CCWC</em>, 2022, pp.
0281–0287.

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[118]</span>
<span class="ltx_bibblock">
H. Zhao, S. Yuan, N. Xie, J. Leng, and G. Wang, “A federated adversarial
learning method for biomedical named entity recognition,” in <em id="bib.bib118.1.1" class="ltx_emph ltx_font_italic">IEEE
BIBM</em>, 2021, pp. 2962–2969.

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[119]</span>
<span class="ltx_bibblock">
J. Li, Y. Meng, L. Ma, S. Du, H. Zhu, Q. Pei, and X. Shen, “A federated
learning based privacy-preserving smart healthcare system,” <em id="bib.bib119.1.1" class="ltx_emph ltx_font_italic">IEEE
Transactions on Industrial Informatics</em>, vol. 18, no. 3, 2021.

</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[120]</span>
<span class="ltx_bibblock">
D. C. Nguyen, M. Ding, P. N. Pathirana, A. Seneviratne, and A. Y. Zomaya,
“Federated learning for covid-19 detection with generative adversarial
networks in edge cloud computing,” <em id="bib.bib120.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>,
2021.

</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[121]</span>
<span class="ltx_bibblock">
O. Samuel, A. Omojo, A. Onuja, Y. Sunday, P. Tiwari, D. Gupta, G. Hafeez,
A. Yahaya, O. Fatoba, and S. Shamshirband, “Iomt: A covid-19 healthcare
system driven by federated learning and blockchain,” <em id="bib.bib121.1.1" class="ltx_emph ltx_font_italic">IEEE Journal of
Biomedical and Health Informatics</em>, 2022.

</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[122]</span>
<span class="ltx_bibblock">
S. Aich, N. K. Sinai, S. Kumar, M. Ali, Y. R. Choi, M.-I. Joo, and H.-C. Kim,
“Protecting personal healthcare record using blockchain &amp; federated
learning technologies,” in <em id="bib.bib122.1.1" class="ltx_emph ltx_font_italic">24th ICACT</em>.   IEEE, 2022, pp. 109–112.

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[123]</span>
<span class="ltx_bibblock">
A. Lakhan, M. A. Mohammed, J. Nedoma, R. Martinek, P. Tiwari, A. Vidyarthi,
A. Alkhayyat, and W. Wang, “Federated-learning based privacy preservation
and fraud-enabled blockchain iomt system for healthcare,” <em id="bib.bib123.1.1" class="ltx_emph ltx_font_italic">IEEE Journal
of Biomedical and Health Informatics</em>, 2022.

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[124]</span>
<span class="ltx_bibblock">
S. Singh, S. Rathore, O. Alfarraj, A. Tolba, and B. Yoon, “A framework for
privacy-preservation of iot healthcare data using federated learning and
blockchain technology,” <em id="bib.bib124.1.1" class="ltx_emph ltx_font_italic">Future Generation Computer Systems</em>, vol. 129,
pp. 380–388, 2022.

</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[125]</span>
<span class="ltx_bibblock">
R. Kumar, A. A. Khan, J. Kumar, N. A. Golilarz, S. Zhang, Y. Ting, C. Zheng,
W. Wang <em id="bib.bib125.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Blockchain-federated-learning and deep learning
models for covid-19 detection using ct imaging,” <em id="bib.bib125.2.2" class="ltx_emph ltx_font_italic">IEEE Sensors
Journal</em>, vol. 21, no. 14, pp. 16 301–16 314, 2021.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2303.14543" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2303.14544" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2303.14544">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2303.14544" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2303.14545" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 19:02:42 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
