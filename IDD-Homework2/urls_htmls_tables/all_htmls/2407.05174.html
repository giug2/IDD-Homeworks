<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2407.05174] Synthetic Data Aided Federated Learning Using Foundation Models</title><meta property="og:description" content="In heterogeneous scenarios where the data distribution amongst the Federated Learning (FL) participants is Non-Independent and Identically distributed (Non-IID), FL suffers from the well-known problem of data heterogen…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Synthetic Data Aided Federated Learning Using Foundation Models">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Synthetic Data Aided Federated Learning Using Foundation Models">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2407.05174">

<!--Generated on Mon Aug  5 16:19:11 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Synthetic Data Aided Federated Learning Using Foundation Models</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Fatima Abacha<sup id="id8.2.id1" class="ltx_sup">1</sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sin G. Teo<sup id="id9.2.id1" class="ltx_sup">2</sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lucas C. Cordeiro<sup id="id10.6.id1" class="ltx_sup">1</sup> and
Mustafa A. Mustafa<sup id="id11.7.id2" class="ltx_sup"><span id="id11.7.id2.1" class="ltx_text ltx_font_italic">1,3</span></sup>
<sup id="id12.8.id3" class="ltx_sup">1</sup>Department of Computer Science, The University of Manchester, UK
<br class="ltx_break"><sup id="id13.9.id4" class="ltx_sup">2</sup>Institute for Infocomm Research, A*STAR, Singapore
<br class="ltx_break"><sup id="id14.10.id5" class="ltx_sup">3</sup>COSIC, KU Leuven, Belgium
<br class="ltx_break">{fatima.abacha,lucas.cordeiro,mustafa.mustafa}@manchester.ac.uk;
teosg@i2r.a-star.edu.sg
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id15.id1" class="ltx_p">In heterogeneous scenarios where the data distribution amongst the Federated Learning (FL) participants is Non-Independent and Identically distributed (Non-IID), FL suffers from the well-known problem of data heterogeneity. This leads the performance of FL to be significantly degraded, as the global model tends to struggle to converge.
To solve this problem, we propose Differentially Private Synthetic Data Aided Federated Learning Using Foundation Models (DPSDA-FL) – a novel data augmentation strategy that aids in homogenizing the local data present on the clients’ side. DPSDA-FL improves the training of the local models by leveraging differentially private synthetic data generated from foundation models.
We demonstrate the effectiveness of our approach by evaluating it on the benchmark image dataset: CIFAR-10. Our experimental results have shown that DPSDA-FL can improve class recall and classification accuracy of the global model by up to 26% and 9%, respectively, in FL with Non-IID issues.
</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Federated Learning (FL) enables the training of a machine learning model by several parties without sharing their data with each other <cite class="ltx_cite ltx_citemacro_cite">McMahan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib16" title="" class="ltx_ref">2017</a>)</cite>. The training process is orchestrated by a third party, which is usually a central server. In FL, each client uses its private data to train its own model known as the local model, while the server uses an aggregation algorithm to construct a global model from the local models. The entire process runs for several iterations until a global model with the desired performance is achieved <cite class="ltx_cite ltx_citemacro_cite">Shahid <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib21" title="" class="ltx_ref">2021</a>)</cite>. This global model is then broadcast to all the clients to use it for inference on their test dataset.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">FL provides protection against data leakage as the private training data of each client is not disclosed to any other party. It can facilitate collaboration between institutions that deal with sensitive data, such as health and financial data <cite class="ltx_cite ltx_citemacro_cite">Aouedi <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib2" title="" class="ltx_ref">2022</a>)</cite>. Regulations such as the General Data Protection Regulation (GDPR) and Health Insurance Portability and Accountability Act (HIPAA) control how sensitive data are stored and shared within and between institutions in order to protect the privacy of the individuals whose data is captured <cite class="ltx_cite ltx_citemacro_cite">Zhou <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib25" title="" class="ltx_ref">2020</a>)</cite>. FL can aid collaborators in adhering to these regulations, as no data is shared between the clients during the training or inference process.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">However, FL comes with its own challenges, as studies have shown that the global model struggles to converge when the data distribution amongst the clients is statistically heterogeneous <cite class="ltx_cite ltx_citemacro_cite">Zhao <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib24" title="" class="ltx_ref">2018</a>)</cite>, <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib12" title="" class="ltx_ref">2020</a>)</cite>. This implies that the data distribution is Non-Independent and Identically distributed (Non-IID). A client may hold data from some classes, but not all classes present in the global dataset or clients could hold data for all classes but in different quantity. This statistical heterogeneity of local data could result in each local model being very different from other local models, leading to a global model that performs at a subpar level <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib13" title="" class="ltx_ref">2022</a>)</cite>. Also, when clients train their local model on data that does not contain certain classes from the global set or only a few samples from specific classes, the models are likely to be biased towards those underrepresented groups <cite class="ltx_cite ltx_citemacro_cite">Hao <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib10" title="" class="ltx_ref">2021</a>)</cite>. This could lead to devastating consequences when these models are deployed in safety-critical situations such as healthcare and finance.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The presence of biases could also disincentivize clients from participating in FL collaboration as they would lose trust in the system. For instance, imagine a collaboration between pharmaceutical companies training a model to determine the effectiveness of several drugs on an ailment and having the drug from one company consistently being predicted as the most effective because they provide more data as a result of conducting more experiments than the others <cite class="ltx_cite ltx_citemacro_cite">Rance and Svoboda (<a href="#bib.bib19" title="" class="ltx_ref">2023</a>)</cite>. Data heterogeneity, as such, is a challenge that needs to be addressed to obtain trustworthy FL models.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Some existing work <cite class="ltx_cite ltx_citemacro_cite">Zhao <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib24" title="" class="ltx_ref">2018</a>)</cite> have proposed a global data sharing strategy to tackle the challenge of FL with Non-IID data. The server is posited to have a uniformly distributed dataset in its possession. This global data is then shared amongst the clients to harmonize their data distribution to alleviate the impact of data heterogeneity. Other approaches such as FedProx <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib12" title="" class="ltx_ref">2020</a>)</cite> introduce a regularization term to the local model loss function on the client side, this mitigates the effect of data heterogeneity and enhances the convergence of the global model. The work of <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib13" title="" class="ltx_ref">2022</a>)</cite> employs Generative Adversarial Networks (GANs) to produce synthetic data to solve the problem of Non-IID data in FL. The synthetic data is then augmented with the local data of the clients to improve the stability of the FL training process. While these proposed methods have improved the performance of FL with data heterogeneity, they are constrained by certain limitations. The assumption that the server possesses a uniformly distributed global dataset in <cite class="ltx_cite ltx_citemacro_cite">Zhao <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib24" title="" class="ltx_ref">2018</a>)</cite> is impractical in real-world FL scenarios. In contrast, the regularization technique employed by FedProx <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib12" title="" class="ltx_ref">2020</a>)</cite> is not effective in extreme cases of data heterogeneity. On the other hand, solutions such as <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib13" title="" class="ltx_ref">2022</a>)</cite> that utilize GANs may produce low-quality and non-diverse synthetic data, as GANs are known to suffer from instabilities such as mode collapse during training.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Considering the limitations above, we propose a novel and more effective data augmentation process in FL that uses foundation models to generate differentially private synthetic data. To the best of our knowledge, this is the first work that employs pre-trained foundation models to generate differentially private synthetic data to tackle the problem of Non-IID data in FL. Thus, our contributions are as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We propose Differentially Private Synthetic Data Aided Federated Learning Using Foundation Models (DPSDA-FL) – a new data augmentation strategy to enhance the performance of FL with Non-IID data – and show the effectiveness of utilizing differentially private synthetic data generated from foundation models in cross-silo horizontal FL.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We conduct experiments and evaluations on the CIFAR-10 dataset and observe an increase in the recall of the global model by up to 26% and an accuracy enhancement of 9%, demonstrating the efficacy of our approach over the baselines. We also provide an analysis of our results to guide further research.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">The remaining part of the paper is organised as follows. Section <a href="#S2" title="2 Background and Related Work ‣ Synthetic Data Aided Federated Learning Using Foundation Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> discusses related work. Section <a href="#S3" title="3 DPSDA-FL: Differentially Private Synthetic Data Aided Federated Learning Using Foundation Models ‣ Synthetic Data Aided Federated Learning Using Foundation Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> introduces our methodology and proposes a new data augmentation strategy. Section <a href="#S4" title="4 Experiments and Evaluations ‣ Synthetic Data Aided Federated Learning Using Foundation Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> presents our experimental results and evaluations. Finally, Section <a href="#S5" title="5 Conclusion ‣ Synthetic Data Aided Federated Learning Using Foundation Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> concludes the paper with a summary and an outline for future work.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Background and Related Work</h2>

<figure id="S2.F1" class="ltx_figure"><img src="/html/2407.05174/assets/DPSDAv4.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="256" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S2.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S2.F1.3.2" class="ltx_text" style="font-size:90%;">Differentially Private Synthetic Data Aided Federated Learning Using Foundation Models.</span></figcaption>
</figure>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Data Heterogeneity</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Data heterogenity is the degree of diversity in the datasets held by clients participating in FL. Data heterogeneity in FL arises from the differences in data distribution, data quality, and data quantity among participants. It can manifest in various forms in FL. Quantity Skew results from the differences in the amount of data held by clients, while Label Skew results from the differences in the classes of data held by individual clients <cite class="ltx_cite ltx_citemacro_cite">Qu <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib17" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Several techniques have been proposed to address the challenge of data heterogeneity in FL. FedProx <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib12" title="" class="ltx_ref">2020</a>)</cite> addresses heterogeneity in FL by integrating a proximal term into the training process. The proximal term leads to a reduction in the divergence of the local models from the global model by serving as a penalization term for the loss function of the local models. <cite class="ltx_cite ltx_citemacro_cite">Karimireddy <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib11" title="" class="ltx_ref">2021</a>)</cite> developed the stochastic controlled averaging algorithm, a modification of the federated averaging, which incorporates variance reduction to stabilize the local model towards the global model. However, these techniques are not effective in extreme cases of data heterogeneity.
Another line of work uses GANs to mitigate the effects of data heterogeneity by generating additional training data for local data augmentation  <cite class="ltx_cite ltx_citemacro_cite">Razavi-Far <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib20" title="" class="ltx_ref">2022</a>)</cite> of which our method aligns with. However, despite using a similar approach to the GAN-based data augmentation methods, we locally generate differentially private synthetic data using foundation models to mitigate the effects of data heterogeneity, our solution generates more diverse synthetic data that is of higher quality than the GAN-based approaches.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Generative Adversarial Networks</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p"><span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_italic">Generative adversarial networks (GANs)</span> are deep learning models comprising of two networks: the generator and discriminator. The generator produces synthetic data mimicking real data, challenging the discriminator to distinguish between them <cite class="ltx_cite ltx_citemacro_cite">Goodfellow <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib9" title="" class="ltx_ref">2014</a>)</cite>. Synthetic data from GANs share the statistical distribution of real datasets and, as such, can be used for dataset augmentation, enhancing model performance <cite class="ltx_cite ltx_citemacro_cite">Antoniou <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib1" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">Zhang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite> trained a GAN at the server side using FL and then shared the synthetic data across clients to improve the performance of FL. <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib13" title="" class="ltx_ref">2022</a>)</cite> proposed Synthetic Data Aided Federated Learning (SDA-FL), where all clients receive a portion of locally synthetically generated data that is globally shared by the server. Despite the effectiveness of GAN-based methods in combating data heterogeneity problems in FL and enhancing the performance of the global model, these works have limitations. The instability of training GANs can result in low-quality synthetic samples with low utility <cite class="ltx_cite ltx_citemacro_cite">Azizi <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib3" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">Recent works have addressed the underperformance of GANs in generating high-quality synthetic data by adopting diffusion models. Diffusion models are generative deep learning architectures that generate synthetic data by iteratively adding noise to real data and then removing this noise through a reverse diffusion process <cite class="ltx_cite ltx_citemacro_cite">Yang <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib22" title="" class="ltx_ref">2024</a>)</cite>. Diffusion models have been shown to produce high-quality data for computer vision applications <cite class="ltx_cite ltx_citemacro_cite">Dhariwal and Nichol (<a href="#bib.bib5" title="" class="ltx_ref">2021</a>); Azizi <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib3" title="" class="ltx_ref">2023</a>)</cite>. Diffusion models, however, can be challenging to train due to their high computational requirements, which are often beyond the reach of many. However, the emergence of foundation models has made access to pre-trained diffusion models more accessible.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Foundation Models</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">Foundation models are a class of generative AI trained on large-scale data and can be modified to undertake various tasks with high precision <cite class="ltx_cite ltx_citemacro_cite">Zhou <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib26" title="" class="ltx_ref">2023</a>)</cite>. Foundation models like Open AI’s Stable Diffusion and DALL.E <cite class="ltx_cite ltx_citemacro_cite">Ramesh <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib18" title="" class="ltx_ref">2022</a>)</cite> have become widely accessible. These pre-trained models can be used to generate high-utility synthetic data.</p>
</div>
<section id="S2.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.1 </span>Differentially Private Synthetic Data</h4>

<div id="S2.SS3.SSS1.p1" class="ltx_para">
<p id="S2.SS3.SSS1.p1.1" class="ltx_p">Synthetic data has been demonstrated to inadvertently reveal sensitive information about the original dataset it was generated from <cite class="ltx_cite ltx_citemacro_cite">Giomi <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib8" title="" class="ltx_ref">2022</a>)</cite>. Consequently, integrating privacy-preserving techniques into the synthetic data generation process is imperative. Differential Privacy (DP) is a method that introduces randomness while computing statistics to maintain the privacy of the underlying information <cite class="ltx_cite ltx_citemacro_cite">Dwork and Roth (<a href="#bib.bib6" title="" class="ltx_ref">2013</a>)</cite>. It has emerged as the standard approach for enhancing the privacy of synthetic data due to its ability to offer provable privacy guarantees. Consequently, diffusion models can be trained using DP to safeguard the privacy of the synthetic data they produce.</p>
</div>
<div id="S2.SS3.SSS1.p2" class="ltx_para">
<p id="S2.SS3.SSS1.p2.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_cite">Ghalebikesabi <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib7" title="" class="ltx_ref">2023</a>)</cite>, by finetuning pre-trained diffusion models with tens of millions of parameters, high utility data with low Fréchet inception distance were generated privately. The synthetic data was employed for a downstream classification task, and state-of-the-art results were attained. A more recent method, PRIVIMAGE <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib14" title="" class="ltx_ref">2024</a>)</cite>, generates differentially private synthetic images using foundation models by strategically selecting pre-training data. While this approach is effective, it incurs significant memory and time overheads. Another notable technique is Private Evolution (PE) <cite class="ltx_cite ltx_citemacro_cite">Lin <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib15" title="" class="ltx_ref">2024</a>)</cite>, an algorithm that fine-tunes pre-trained diffusion models to generate synthetic data from private datasets while maintaining differential privacy. PE has demonstrated state-of-the-art results in image synthesis and requires no pre-training. In this study, we leverage PE to generate synthetic data for data augmentation.</p>
</div>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>DPSDA-FL: Differentially Private Synthetic Data Aided Federated Learning Using Foundation Models</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">This section proposes our novel technique, DPSDA-FL, that generates differentially private synthetic data for FL using foundation models. Figure <a href="#S2.F1" title="Figure 1 ‣ 2 Background and Related Work ‣ Synthetic Data Aided Federated Learning Using Foundation Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> gives a high-level overview of our proposal. DPSDA-FL works in two main stages, Stage 1 in which each Cross-Silo FL client uses a foundation model to locally generate differentially private synthetic data from their private data and then share part of the synthetic data with the central server to form a global synthetic data which will be utilized in Stage 2. In the next stage, the server distributes the global synthetic data to clients in order to enable them augment their local data with the diverse and high quality synthetic data. This augmentation leads to a less heterogeneous local data distribution by allowing clients to possess synthetic data from classes they do not possess or classes they possess a very limited sample from. This subsequently leads to a more stable local model training that enhances the performance of the global model both in terms of its recall capability and its accuracy.
A more detailed overview of how DPSDA-FL works is presented below:</p>
</div>
<div id="S3.p2" class="ltx_para">
<ol id="S3.I1" class="ltx_enumerate">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Unique label count information sharing:</span> At the start of the training process, clients share their unique label counts with the server to form a globally unique label count. This information will be used to share the synthetic global data with clients to ensure each client receives differentially private synthetic data from the classes they are deficient in.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.2" class="ltx_p"><span id="S3.I1.i2.p1.2.1" class="ltx_text ltx_font_bold">Local clients’ synthetic data generation using foundation models:</span>
To generate our differentially private synthetic data, we utilize the image-guided diffusion model DPSDA <cite class="ltx_cite ltx_citemacro_cite">Lin <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib15" title="" class="ltx_ref">2024</a>)</cite>, as our foundation model. DPSDA is based on improved diffusion <cite class="ltx_cite ltx_citemacro_cite">Dhariwal and Nichol (<a href="#bib.bib5" title="" class="ltx_ref">2021</a>)</cite>. To ensure the privacy of local training data, a local copy of the diffusion model is downloaded and hosted locally on client’s devices. It mitigates privacy risks associated with diffusion models memorizing their training data, as shown in <cite class="ltx_cite ltx_citemacro_cite">Carlini <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib4" title="" class="ltx_ref">2023</a>)</cite>. The local synthetic data <math id="S3.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="D_{csyn}" display="inline"><semantics id="S3.I1.i2.p1.1.m1.1a"><msub id="S3.I1.i2.p1.1.m1.1.1" xref="S3.I1.i2.p1.1.m1.1.1.cmml"><mi id="S3.I1.i2.p1.1.m1.1.1.2" xref="S3.I1.i2.p1.1.m1.1.1.2.cmml">D</mi><mrow id="S3.I1.i2.p1.1.m1.1.1.3" xref="S3.I1.i2.p1.1.m1.1.1.3.cmml"><mi id="S3.I1.i2.p1.1.m1.1.1.3.2" xref="S3.I1.i2.p1.1.m1.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.1.m1.1.1.3.1" xref="S3.I1.i2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.I1.i2.p1.1.m1.1.1.3.3" xref="S3.I1.i2.p1.1.m1.1.1.3.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.1.m1.1.1.3.1a" xref="S3.I1.i2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.I1.i2.p1.1.m1.1.1.3.4" xref="S3.I1.i2.p1.1.m1.1.1.3.4.cmml">y</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.1.m1.1.1.3.1b" xref="S3.I1.i2.p1.1.m1.1.1.3.1.cmml">​</mo><mi id="S3.I1.i2.p1.1.m1.1.1.3.5" xref="S3.I1.i2.p1.1.m1.1.1.3.5.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.1.m1.1b"><apply id="S3.I1.i2.p1.1.m1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.I1.i2.p1.1.m1.1.1.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.I1.i2.p1.1.m1.1.1.2.cmml" xref="S3.I1.i2.p1.1.m1.1.1.2">𝐷</ci><apply id="S3.I1.i2.p1.1.m1.1.1.3.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3"><times id="S3.I1.i2.p1.1.m1.1.1.3.1.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3.1"></times><ci id="S3.I1.i2.p1.1.m1.1.1.3.2.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3.2">𝑐</ci><ci id="S3.I1.i2.p1.1.m1.1.1.3.3.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3.3">𝑠</ci><ci id="S3.I1.i2.p1.1.m1.1.1.3.4.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3.4">𝑦</ci><ci id="S3.I1.i2.p1.1.m1.1.1.3.5.cmml" xref="S3.I1.i2.p1.1.m1.1.1.3.5">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.1.m1.1c">D_{csyn}</annotation></semantics></math> are then shared with the server to construct the global synthetic data <math id="S3.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="D_{Gsyn}" display="inline"><semantics id="S3.I1.i2.p1.2.m2.1a"><msub id="S3.I1.i2.p1.2.m2.1.1" xref="S3.I1.i2.p1.2.m2.1.1.cmml"><mi id="S3.I1.i2.p1.2.m2.1.1.2" xref="S3.I1.i2.p1.2.m2.1.1.2.cmml">D</mi><mrow id="S3.I1.i2.p1.2.m2.1.1.3" xref="S3.I1.i2.p1.2.m2.1.1.3.cmml"><mi id="S3.I1.i2.p1.2.m2.1.1.3.2" xref="S3.I1.i2.p1.2.m2.1.1.3.2.cmml">G</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.2.m2.1.1.3.1" xref="S3.I1.i2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.I1.i2.p1.2.m2.1.1.3.3" xref="S3.I1.i2.p1.2.m2.1.1.3.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.2.m2.1.1.3.1a" xref="S3.I1.i2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.I1.i2.p1.2.m2.1.1.3.4" xref="S3.I1.i2.p1.2.m2.1.1.3.4.cmml">y</mi><mo lspace="0em" rspace="0em" id="S3.I1.i2.p1.2.m2.1.1.3.1b" xref="S3.I1.i2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.I1.i2.p1.2.m2.1.1.3.5" xref="S3.I1.i2.p1.2.m2.1.1.3.5.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.I1.i2.p1.2.m2.1b"><apply id="S3.I1.i2.p1.2.m2.1.1.cmml" xref="S3.I1.i2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.I1.i2.p1.2.m2.1.1.1.cmml" xref="S3.I1.i2.p1.2.m2.1.1">subscript</csymbol><ci id="S3.I1.i2.p1.2.m2.1.1.2.cmml" xref="S3.I1.i2.p1.2.m2.1.1.2">𝐷</ci><apply id="S3.I1.i2.p1.2.m2.1.1.3.cmml" xref="S3.I1.i2.p1.2.m2.1.1.3"><times id="S3.I1.i2.p1.2.m2.1.1.3.1.cmml" xref="S3.I1.i2.p1.2.m2.1.1.3.1"></times><ci id="S3.I1.i2.p1.2.m2.1.1.3.2.cmml" xref="S3.I1.i2.p1.2.m2.1.1.3.2">𝐺</ci><ci id="S3.I1.i2.p1.2.m2.1.1.3.3.cmml" xref="S3.I1.i2.p1.2.m2.1.1.3.3">𝑠</ci><ci id="S3.I1.i2.p1.2.m2.1.1.3.4.cmml" xref="S3.I1.i2.p1.2.m2.1.1.3.4">𝑦</ci><ci id="S3.I1.i2.p1.2.m2.1.1.3.5.cmml" xref="S3.I1.i2.p1.2.m2.1.1.3.5">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.I1.i2.p1.2.m2.1c">D_{Gsyn}</annotation></semantics></math>.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Global synthetic data distribution:</span>
The differentially private synthetic data from the previous step is then shared by the server with the local clients. The local data class information possessed by the server guides effective distribution, so each client only receives data from classes it lacks.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p"><span id="S3.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Local data augmentation:</span> Clients then utilize the received synthetic data to augment their local data and homogenize the local data distribution. These synthetic data are of high quality and can enhance local model training.</p>
</div>
</li>
<li id="S3.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S3.I1.i5.p1" class="ltx_para">
<p id="S3.I1.i5.p1.1" class="ltx_p"><span id="S3.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Federated training:</span>
With more stable local training aided by the augmented local datasets at each client’s side, clients proceed to train a federated global model jointly. Note that DPSDA <cite class="ltx_cite ltx_citemacro_cite">Lin <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib15" title="" class="ltx_ref">2024</a>)</cite> does not necessitate any pre-training to generate the synthetic data, and the clients are assumed to be health institutions that can afford reasonable computational resources.</p>
</div>
</li>
</ol>
</div>
<figure id="alg1" class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.2.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span> DPSDA-FL</figcaption>
<div id="alg1.3" class="ltx_listing ltx_listing">
<div id="alg1.l1" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l1.1.1.1" class="ltx_text" style="font-size:80%;">1:</span></span>  <span id="alg1.l1.2" class="ltx_text ltx_font_bold">Input Parameters:</span>

</div>
<div id="alg1.l2" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l2.1.1.1" class="ltx_text" style="font-size:80%;">2:</span></span>  <math id="alg1.l2.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="alg1.l2.m1.1a"><mi id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><ci id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">N</annotation></semantics></math>: Number of clients.

</div>
<div id="alg1.l3" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l3.1.1.1" class="ltx_text" style="font-size:80%;">3:</span></span>  <math id="alg1.l3.m1.1" class="ltx_Math" alttext="T" display="inline"><semantics id="alg1.l3.m1.1a"><mi id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.1b"><ci id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.1c">T</annotation></semantics></math>: Total number of rounds.

</div>
<div id="alg1.l4" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l4.1.1.1" class="ltx_text" style="font-size:80%;">4:</span></span>  <math id="alg1.l4.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="alg1.l4.m1.1a"><mi id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.1b"><ci id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.1c">\alpha</annotation></semantics></math>: Learning rate.

</div>
<div id="alg1.l5" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l5.1.1.1" class="ltx_text" style="font-size:80%;">5:</span></span>  <math id="alg1.l5.m1.1" class="ltx_Math" alttext="w_{t}" display="inline"><semantics id="alg1.l5.m1.1a"><msub id="alg1.l5.m1.1.1" xref="alg1.l5.m1.1.1.cmml"><mi id="alg1.l5.m1.1.1.2" xref="alg1.l5.m1.1.1.2.cmml">w</mi><mi id="alg1.l5.m1.1.1.3" xref="alg1.l5.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l5.m1.1b"><apply id="alg1.l5.m1.1.1.cmml" xref="alg1.l5.m1.1.1"><csymbol cd="ambiguous" id="alg1.l5.m1.1.1.1.cmml" xref="alg1.l5.m1.1.1">subscript</csymbol><ci id="alg1.l5.m1.1.1.2.cmml" xref="alg1.l5.m1.1.1.2">𝑤</ci><ci id="alg1.l5.m1.1.1.3.cmml" xref="alg1.l5.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l5.m1.1c">w_{t}</annotation></semantics></math>: Initial model parameters.

</div>
<div id="alg1.l6" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l6.1.1.1" class="ltx_text" style="font-size:80%;">6:</span></span>  <math id="alg1.l6.m1.1" class="ltx_Math" alttext="w_{t+1}" display="inline"><semantics id="alg1.l6.m1.1a"><msub id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml"><mi id="alg1.l6.m1.1.1.2" xref="alg1.l6.m1.1.1.2.cmml">w</mi><mrow id="alg1.l6.m1.1.1.3" xref="alg1.l6.m1.1.1.3.cmml"><mi id="alg1.l6.m1.1.1.3.2" xref="alg1.l6.m1.1.1.3.2.cmml">t</mi><mo id="alg1.l6.m1.1.1.3.1" xref="alg1.l6.m1.1.1.3.1.cmml">+</mo><mn id="alg1.l6.m1.1.1.3.3" xref="alg1.l6.m1.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><apply id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1"><csymbol cd="ambiguous" id="alg1.l6.m1.1.1.1.cmml" xref="alg1.l6.m1.1.1">subscript</csymbol><ci id="alg1.l6.m1.1.1.2.cmml" xref="alg1.l6.m1.1.1.2">𝑤</ci><apply id="alg1.l6.m1.1.1.3.cmml" xref="alg1.l6.m1.1.1.3"><plus id="alg1.l6.m1.1.1.3.1.cmml" xref="alg1.l6.m1.1.1.3.1"></plus><ci id="alg1.l6.m1.1.1.3.2.cmml" xref="alg1.l6.m1.1.1.3.2">𝑡</ci><cn type="integer" id="alg1.l6.m1.1.1.3.3.cmml" xref="alg1.l6.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">w_{t+1}</annotation></semantics></math>: Updated model parameters.


</div>
<div id="alg1.l7" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l7.1.1.1" class="ltx_text" style="font-size:80%;">7:</span></span>  <span id="alg1.l7.2" class="ltx_text ltx_font_bold">Initialization</span>

</div>
<div id="alg1.l8" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l8.1.1.1" class="ltx_text" style="font-size:80%;">8:</span></span>  Clients share their unique label counts with the server

</div>
<div id="alg1.l9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l9.1.1.1" class="ltx_text" style="font-size:80%;">9:</span></span>  Clients generate DP synthetic data using Foundation Models

</div>
<div id="alg1.l10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l10.1.1.1" class="ltx_text" style="font-size:80%;">10:</span></span>  <span id="alg1.l10.2" class="ltx_text ltx_font_bold">for</span> <math id="alg1.l10.m1.1" class="ltx_Math" alttext="i=1" display="inline"><semantics id="alg1.l10.m1.1a"><mrow id="alg1.l10.m1.1.1" xref="alg1.l10.m1.1.1.cmml"><mi id="alg1.l10.m1.1.1.2" xref="alg1.l10.m1.1.1.2.cmml">i</mi><mo id="alg1.l10.m1.1.1.1" xref="alg1.l10.m1.1.1.1.cmml">=</mo><mn id="alg1.l10.m1.1.1.3" xref="alg1.l10.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l10.m1.1b"><apply id="alg1.l10.m1.1.1.cmml" xref="alg1.l10.m1.1.1"><eq id="alg1.l10.m1.1.1.1.cmml" xref="alg1.l10.m1.1.1.1"></eq><ci id="alg1.l10.m1.1.1.2.cmml" xref="alg1.l10.m1.1.1.2">𝑖</ci><cn type="integer" id="alg1.l10.m1.1.1.3.cmml" xref="alg1.l10.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m1.1c">i=1</annotation></semantics></math> to <math id="alg1.l10.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="alg1.l10.m2.1a"><mi id="alg1.l10.m2.1.1" xref="alg1.l10.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="alg1.l10.m2.1b"><ci id="alg1.l10.m2.1.1.cmml" xref="alg1.l10.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m2.1c">N</annotation></semantics></math> <span id="alg1.l10.3" class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.l11" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l11.1.1.1" class="ltx_text" style="font-size:80%;">11:</span></span>     Generate <math id="alg1.l11.m1.1" class="ltx_Math" alttext="D_{\text{syn}}^{i}" display="inline"><semantics id="alg1.l11.m1.1a"><msubsup id="alg1.l11.m1.1.1" xref="alg1.l11.m1.1.1.cmml"><mi id="alg1.l11.m1.1.1.2.2" xref="alg1.l11.m1.1.1.2.2.cmml">D</mi><mtext id="alg1.l11.m1.1.1.2.3" xref="alg1.l11.m1.1.1.2.3a.cmml">syn</mtext><mi id="alg1.l11.m1.1.1.3" xref="alg1.l11.m1.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l11.m1.1b"><apply id="alg1.l11.m1.1.1.cmml" xref="alg1.l11.m1.1.1"><csymbol cd="ambiguous" id="alg1.l11.m1.1.1.1.cmml" xref="alg1.l11.m1.1.1">superscript</csymbol><apply id="alg1.l11.m1.1.1.2.cmml" xref="alg1.l11.m1.1.1"><csymbol cd="ambiguous" id="alg1.l11.m1.1.1.2.1.cmml" xref="alg1.l11.m1.1.1">subscript</csymbol><ci id="alg1.l11.m1.1.1.2.2.cmml" xref="alg1.l11.m1.1.1.2.2">𝐷</ci><ci id="alg1.l11.m1.1.1.2.3a.cmml" xref="alg1.l11.m1.1.1.2.3"><mtext mathsize="70%" id="alg1.l11.m1.1.1.2.3.cmml" xref="alg1.l11.m1.1.1.2.3">syn</mtext></ci></apply><ci id="alg1.l11.m1.1.1.3.cmml" xref="alg1.l11.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m1.1c">D_{\text{syn}}^{i}</annotation></semantics></math> from <math id="alg1.l11.m2.1" class="ltx_Math" alttext="D_{c}^{i}" display="inline"><semantics id="alg1.l11.m2.1a"><msubsup id="alg1.l11.m2.1.1" xref="alg1.l11.m2.1.1.cmml"><mi id="alg1.l11.m2.1.1.2.2" xref="alg1.l11.m2.1.1.2.2.cmml">D</mi><mi id="alg1.l11.m2.1.1.2.3" xref="alg1.l11.m2.1.1.2.3.cmml">c</mi><mi id="alg1.l11.m2.1.1.3" xref="alg1.l11.m2.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l11.m2.1b"><apply id="alg1.l11.m2.1.1.cmml" xref="alg1.l11.m2.1.1"><csymbol cd="ambiguous" id="alg1.l11.m2.1.1.1.cmml" xref="alg1.l11.m2.1.1">superscript</csymbol><apply id="alg1.l11.m2.1.1.2.cmml" xref="alg1.l11.m2.1.1"><csymbol cd="ambiguous" id="alg1.l11.m2.1.1.2.1.cmml" xref="alg1.l11.m2.1.1">subscript</csymbol><ci id="alg1.l11.m2.1.1.2.2.cmml" xref="alg1.l11.m2.1.1.2.2">𝐷</ci><ci id="alg1.l11.m2.1.1.2.3.cmml" xref="alg1.l11.m2.1.1.2.3">𝑐</ci></apply><ci id="alg1.l11.m2.1.1.3.cmml" xref="alg1.l11.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m2.1c">D_{c}^{i}</annotation></semantics></math>

</div>
<div id="alg1.l12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l12.1.1.1" class="ltx_text" style="font-size:80%;">12:</span></span>     Send <math id="alg1.l12.m1.1" class="ltx_Math" alttext="D_{\text{syn}}^{i}" display="inline"><semantics id="alg1.l12.m1.1a"><msubsup id="alg1.l12.m1.1.1" xref="alg1.l12.m1.1.1.cmml"><mi id="alg1.l12.m1.1.1.2.2" xref="alg1.l12.m1.1.1.2.2.cmml">D</mi><mtext id="alg1.l12.m1.1.1.2.3" xref="alg1.l12.m1.1.1.2.3a.cmml">syn</mtext><mi id="alg1.l12.m1.1.1.3" xref="alg1.l12.m1.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l12.m1.1b"><apply id="alg1.l12.m1.1.1.cmml" xref="alg1.l12.m1.1.1"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.1.cmml" xref="alg1.l12.m1.1.1">superscript</csymbol><apply id="alg1.l12.m1.1.1.2.cmml" xref="alg1.l12.m1.1.1"><csymbol cd="ambiguous" id="alg1.l12.m1.1.1.2.1.cmml" xref="alg1.l12.m1.1.1">subscript</csymbol><ci id="alg1.l12.m1.1.1.2.2.cmml" xref="alg1.l12.m1.1.1.2.2">𝐷</ci><ci id="alg1.l12.m1.1.1.2.3a.cmml" xref="alg1.l12.m1.1.1.2.3"><mtext mathsize="70%" id="alg1.l12.m1.1.1.2.3.cmml" xref="alg1.l12.m1.1.1.2.3">syn</mtext></ci></apply><ci id="alg1.l12.m1.1.1.3.cmml" xref="alg1.l12.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m1.1c">D_{\text{syn}}^{i}</annotation></semantics></math> to server

</div>
<div id="alg1.l13" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l13.1.1.1" class="ltx_text" style="font-size:80%;">13:</span></span>  <span id="alg1.l13.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l13.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l14" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l14.1.1.1" class="ltx_text" style="font-size:80%;">14:</span></span>  Server forms global <math id="alg1.l14.m1.1" class="ltx_Math" alttext="D_{\text{Gsyn}}" display="inline"><semantics id="alg1.l14.m1.1a"><msub id="alg1.l14.m1.1.1" xref="alg1.l14.m1.1.1.cmml"><mi id="alg1.l14.m1.1.1.2" xref="alg1.l14.m1.1.1.2.cmml">D</mi><mtext id="alg1.l14.m1.1.1.3" xref="alg1.l14.m1.1.1.3a.cmml">Gsyn</mtext></msub><annotation-xml encoding="MathML-Content" id="alg1.l14.m1.1b"><apply id="alg1.l14.m1.1.1.cmml" xref="alg1.l14.m1.1.1"><csymbol cd="ambiguous" id="alg1.l14.m1.1.1.1.cmml" xref="alg1.l14.m1.1.1">subscript</csymbol><ci id="alg1.l14.m1.1.1.2.cmml" xref="alg1.l14.m1.1.1.2">𝐷</ci><ci id="alg1.l14.m1.1.1.3a.cmml" xref="alg1.l14.m1.1.1.3"><mtext mathsize="70%" id="alg1.l14.m1.1.1.3.cmml" xref="alg1.l14.m1.1.1.3">Gsyn</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m1.1c">D_{\text{Gsyn}}</annotation></semantics></math> from <math id="alg1.l14.m2.1" class="ltx_Math" alttext="D_{\text{syn}}^{i}" display="inline"><semantics id="alg1.l14.m2.1a"><msubsup id="alg1.l14.m2.1.1" xref="alg1.l14.m2.1.1.cmml"><mi id="alg1.l14.m2.1.1.2.2" xref="alg1.l14.m2.1.1.2.2.cmml">D</mi><mtext id="alg1.l14.m2.1.1.2.3" xref="alg1.l14.m2.1.1.2.3a.cmml">syn</mtext><mi id="alg1.l14.m2.1.1.3" xref="alg1.l14.m2.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l14.m2.1b"><apply id="alg1.l14.m2.1.1.cmml" xref="alg1.l14.m2.1.1"><csymbol cd="ambiguous" id="alg1.l14.m2.1.1.1.cmml" xref="alg1.l14.m2.1.1">superscript</csymbol><apply id="alg1.l14.m2.1.1.2.cmml" xref="alg1.l14.m2.1.1"><csymbol cd="ambiguous" id="alg1.l14.m2.1.1.2.1.cmml" xref="alg1.l14.m2.1.1">subscript</csymbol><ci id="alg1.l14.m2.1.1.2.2.cmml" xref="alg1.l14.m2.1.1.2.2">𝐷</ci><ci id="alg1.l14.m2.1.1.2.3a.cmml" xref="alg1.l14.m2.1.1.2.3"><mtext mathsize="70%" id="alg1.l14.m2.1.1.2.3.cmml" xref="alg1.l14.m2.1.1.2.3">syn</mtext></ci></apply><ci id="alg1.l14.m2.1.1.3.cmml" xref="alg1.l14.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l14.m2.1c">D_{\text{syn}}^{i}</annotation></semantics></math>

</div>
<div id="alg1.l15" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l15.1.1.1" class="ltx_text" style="font-size:80%;">15:</span></span>  Distribute <math id="alg1.l15.m1.1" class="ltx_Math" alttext="D_{\text{Gsyn}}" display="inline"><semantics id="alg1.l15.m1.1a"><msub id="alg1.l15.m1.1.1" xref="alg1.l15.m1.1.1.cmml"><mi id="alg1.l15.m1.1.1.2" xref="alg1.l15.m1.1.1.2.cmml">D</mi><mtext id="alg1.l15.m1.1.1.3" xref="alg1.l15.m1.1.1.3a.cmml">Gsyn</mtext></msub><annotation-xml encoding="MathML-Content" id="alg1.l15.m1.1b"><apply id="alg1.l15.m1.1.1.cmml" xref="alg1.l15.m1.1.1"><csymbol cd="ambiguous" id="alg1.l15.m1.1.1.1.cmml" xref="alg1.l15.m1.1.1">subscript</csymbol><ci id="alg1.l15.m1.1.1.2.cmml" xref="alg1.l15.m1.1.1.2">𝐷</ci><ci id="alg1.l15.m1.1.1.3a.cmml" xref="alg1.l15.m1.1.1.3"><mtext mathsize="70%" id="alg1.l15.m1.1.1.3.cmml" xref="alg1.l15.m1.1.1.3">Gsyn</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l15.m1.1c">D_{\text{Gsyn}}</annotation></semantics></math> using unique label count

</div>
<div id="alg1.l16" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l16.1.1.1" class="ltx_text" style="font-size:80%;">16:</span></span>  <span id="alg1.l16.2" class="ltx_text ltx_font_bold">for</span> <math id="alg1.l16.m1.1" class="ltx_Math" alttext="t=1" display="inline"><semantics id="alg1.l16.m1.1a"><mrow id="alg1.l16.m1.1.1" xref="alg1.l16.m1.1.1.cmml"><mi id="alg1.l16.m1.1.1.2" xref="alg1.l16.m1.1.1.2.cmml">t</mi><mo id="alg1.l16.m1.1.1.1" xref="alg1.l16.m1.1.1.1.cmml">=</mo><mn id="alg1.l16.m1.1.1.3" xref="alg1.l16.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l16.m1.1b"><apply id="alg1.l16.m1.1.1.cmml" xref="alg1.l16.m1.1.1"><eq id="alg1.l16.m1.1.1.1.cmml" xref="alg1.l16.m1.1.1.1"></eq><ci id="alg1.l16.m1.1.1.2.cmml" xref="alg1.l16.m1.1.1.2">𝑡</ci><cn type="integer" id="alg1.l16.m1.1.1.3.cmml" xref="alg1.l16.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l16.m1.1c">t=1</annotation></semantics></math> to <math id="alg1.l16.m2.1" class="ltx_Math" alttext="T" display="inline"><semantics id="alg1.l16.m2.1a"><mi id="alg1.l16.m2.1.1" xref="alg1.l16.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="alg1.l16.m2.1b"><ci id="alg1.l16.m2.1.1.cmml" xref="alg1.l16.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l16.m2.1c">T</annotation></semantics></math> <span id="alg1.l16.3" class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.l17" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l17.1.1.1" class="ltx_text" style="font-size:80%;">17:</span></span>     Send <math id="alg1.l17.m1.1" class="ltx_Math" alttext="w_{t}" display="inline"><semantics id="alg1.l17.m1.1a"><msub id="alg1.l17.m1.1.1" xref="alg1.l17.m1.1.1.cmml"><mi id="alg1.l17.m1.1.1.2" xref="alg1.l17.m1.1.1.2.cmml">w</mi><mi id="alg1.l17.m1.1.1.3" xref="alg1.l17.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l17.m1.1b"><apply id="alg1.l17.m1.1.1.cmml" xref="alg1.l17.m1.1.1"><csymbol cd="ambiguous" id="alg1.l17.m1.1.1.1.cmml" xref="alg1.l17.m1.1.1">subscript</csymbol><ci id="alg1.l17.m1.1.1.2.cmml" xref="alg1.l17.m1.1.1.2">𝑤</ci><ci id="alg1.l17.m1.1.1.3.cmml" xref="alg1.l17.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l17.m1.1c">w_{t}</annotation></semantics></math> to all clients

</div>
<div id="alg1.l18" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l18.1.1.1" class="ltx_text" style="font-size:80%;">18:</span></span>     <span id="alg1.l18.2" class="ltx_text ltx_font_bold">for</span> <math id="alg1.l18.m1.1" class="ltx_Math" alttext="i=1" display="inline"><semantics id="alg1.l18.m1.1a"><mrow id="alg1.l18.m1.1.1" xref="alg1.l18.m1.1.1.cmml"><mi id="alg1.l18.m1.1.1.2" xref="alg1.l18.m1.1.1.2.cmml">i</mi><mo id="alg1.l18.m1.1.1.1" xref="alg1.l18.m1.1.1.1.cmml">=</mo><mn id="alg1.l18.m1.1.1.3" xref="alg1.l18.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.l18.m1.1b"><apply id="alg1.l18.m1.1.1.cmml" xref="alg1.l18.m1.1.1"><eq id="alg1.l18.m1.1.1.1.cmml" xref="alg1.l18.m1.1.1.1"></eq><ci id="alg1.l18.m1.1.1.2.cmml" xref="alg1.l18.m1.1.1.2">𝑖</ci><cn type="integer" id="alg1.l18.m1.1.1.3.cmml" xref="alg1.l18.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l18.m1.1c">i=1</annotation></semantics></math> to <math id="alg1.l18.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="alg1.l18.m2.1a"><mi id="alg1.l18.m2.1.1" xref="alg1.l18.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="alg1.l18.m2.1b"><ci id="alg1.l18.m2.1.1.cmml" xref="alg1.l18.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l18.m2.1c">N</annotation></semantics></math> <span id="alg1.l18.3" class="ltx_text ltx_font_bold">do</span>



</div>
<div id="alg1.l19" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l19.1.1.1" class="ltx_text" style="font-size:80%;">19:</span></span>        Augment <math id="alg1.l19.m1.1" class="ltx_Math" alttext="D_{c}^{i}" display="inline"><semantics id="alg1.l19.m1.1a"><msubsup id="alg1.l19.m1.1.1" xref="alg1.l19.m1.1.1.cmml"><mi id="alg1.l19.m1.1.1.2.2" xref="alg1.l19.m1.1.1.2.2.cmml">D</mi><mi id="alg1.l19.m1.1.1.2.3" xref="alg1.l19.m1.1.1.2.3.cmml">c</mi><mi id="alg1.l19.m1.1.1.3" xref="alg1.l19.m1.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l19.m1.1b"><apply id="alg1.l19.m1.1.1.cmml" xref="alg1.l19.m1.1.1"><csymbol cd="ambiguous" id="alg1.l19.m1.1.1.1.cmml" xref="alg1.l19.m1.1.1">superscript</csymbol><apply id="alg1.l19.m1.1.1.2.cmml" xref="alg1.l19.m1.1.1"><csymbol cd="ambiguous" id="alg1.l19.m1.1.1.2.1.cmml" xref="alg1.l19.m1.1.1">subscript</csymbol><ci id="alg1.l19.m1.1.1.2.2.cmml" xref="alg1.l19.m1.1.1.2.2">𝐷</ci><ci id="alg1.l19.m1.1.1.2.3.cmml" xref="alg1.l19.m1.1.1.2.3">𝑐</ci></apply><ci id="alg1.l19.m1.1.1.3.cmml" xref="alg1.l19.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l19.m1.1c">D_{c}^{i}</annotation></semantics></math> with <math id="alg1.l19.m2.1" class="ltx_Math" alttext="D_{\text{Gsyn}}" display="inline"><semantics id="alg1.l19.m2.1a"><msub id="alg1.l19.m2.1.1" xref="alg1.l19.m2.1.1.cmml"><mi id="alg1.l19.m2.1.1.2" xref="alg1.l19.m2.1.1.2.cmml">D</mi><mtext id="alg1.l19.m2.1.1.3" xref="alg1.l19.m2.1.1.3a.cmml">Gsyn</mtext></msub><annotation-xml encoding="MathML-Content" id="alg1.l19.m2.1b"><apply id="alg1.l19.m2.1.1.cmml" xref="alg1.l19.m2.1.1"><csymbol cd="ambiguous" id="alg1.l19.m2.1.1.1.cmml" xref="alg1.l19.m2.1.1">subscript</csymbol><ci id="alg1.l19.m2.1.1.2.cmml" xref="alg1.l19.m2.1.1.2">𝐷</ci><ci id="alg1.l19.m2.1.1.3a.cmml" xref="alg1.l19.m2.1.1.3"><mtext mathsize="70%" id="alg1.l19.m2.1.1.3.cmml" xref="alg1.l19.m2.1.1.3">Gsyn</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l19.m2.1c">D_{\text{Gsyn}}</annotation></semantics></math>

</div>
<div id="alg1.l20" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l20.1.1.1" class="ltx_text" style="font-size:80%;">20:</span></span>        Train model <math id="alg1.l20.m1.1" class="ltx_Math" alttext="L_{i}" display="inline"><semantics id="alg1.l20.m1.1a"><msub id="alg1.l20.m1.1.1" xref="alg1.l20.m1.1.1.cmml"><mi id="alg1.l20.m1.1.1.2" xref="alg1.l20.m1.1.1.2.cmml">L</mi><mi id="alg1.l20.m1.1.1.3" xref="alg1.l20.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l20.m1.1b"><apply id="alg1.l20.m1.1.1.cmml" xref="alg1.l20.m1.1.1"><csymbol cd="ambiguous" id="alg1.l20.m1.1.1.1.cmml" xref="alg1.l20.m1.1.1">subscript</csymbol><ci id="alg1.l20.m1.1.1.2.cmml" xref="alg1.l20.m1.1.1.2">𝐿</ci><ci id="alg1.l20.m1.1.1.3.cmml" xref="alg1.l20.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l20.m1.1c">L_{i}</annotation></semantics></math> to update <math id="alg1.l20.m2.1" class="ltx_Math" alttext="w_{t+1}^{i}" display="inline"><semantics id="alg1.l20.m2.1a"><msubsup id="alg1.l20.m2.1.1" xref="alg1.l20.m2.1.1.cmml"><mi id="alg1.l20.m2.1.1.2.2" xref="alg1.l20.m2.1.1.2.2.cmml">w</mi><mrow id="alg1.l20.m2.1.1.2.3" xref="alg1.l20.m2.1.1.2.3.cmml"><mi id="alg1.l20.m2.1.1.2.3.2" xref="alg1.l20.m2.1.1.2.3.2.cmml">t</mi><mo id="alg1.l20.m2.1.1.2.3.1" xref="alg1.l20.m2.1.1.2.3.1.cmml">+</mo><mn id="alg1.l20.m2.1.1.2.3.3" xref="alg1.l20.m2.1.1.2.3.3.cmml">1</mn></mrow><mi id="alg1.l20.m2.1.1.3" xref="alg1.l20.m2.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l20.m2.1b"><apply id="alg1.l20.m2.1.1.cmml" xref="alg1.l20.m2.1.1"><csymbol cd="ambiguous" id="alg1.l20.m2.1.1.1.cmml" xref="alg1.l20.m2.1.1">superscript</csymbol><apply id="alg1.l20.m2.1.1.2.cmml" xref="alg1.l20.m2.1.1"><csymbol cd="ambiguous" id="alg1.l20.m2.1.1.2.1.cmml" xref="alg1.l20.m2.1.1">subscript</csymbol><ci id="alg1.l20.m2.1.1.2.2.cmml" xref="alg1.l20.m2.1.1.2.2">𝑤</ci><apply id="alg1.l20.m2.1.1.2.3.cmml" xref="alg1.l20.m2.1.1.2.3"><plus id="alg1.l20.m2.1.1.2.3.1.cmml" xref="alg1.l20.m2.1.1.2.3.1"></plus><ci id="alg1.l20.m2.1.1.2.3.2.cmml" xref="alg1.l20.m2.1.1.2.3.2">𝑡</ci><cn type="integer" id="alg1.l20.m2.1.1.2.3.3.cmml" xref="alg1.l20.m2.1.1.2.3.3">1</cn></apply></apply><ci id="alg1.l20.m2.1.1.3.cmml" xref="alg1.l20.m2.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l20.m2.1c">w_{t+1}^{i}</annotation></semantics></math>

</div>
<div id="alg1.l21" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l21.1.1.1" class="ltx_text" style="font-size:80%;">21:</span></span>        Server Initializes <math id="alg1.l21.m1.1" class="ltx_Math" alttext="w_{0}" display="inline"><semantics id="alg1.l21.m1.1a"><msub id="alg1.l21.m1.1.1" xref="alg1.l21.m1.1.1.cmml"><mi id="alg1.l21.m1.1.1.2" xref="alg1.l21.m1.1.1.2.cmml">w</mi><mn id="alg1.l21.m1.1.1.3" xref="alg1.l21.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="alg1.l21.m1.1b"><apply id="alg1.l21.m1.1.1.cmml" xref="alg1.l21.m1.1.1"><csymbol cd="ambiguous" id="alg1.l21.m1.1.1.1.cmml" xref="alg1.l21.m1.1.1">subscript</csymbol><ci id="alg1.l21.m1.1.1.2.cmml" xref="alg1.l21.m1.1.1.2">𝑤</ci><cn type="integer" id="alg1.l21.m1.1.1.3.cmml" xref="alg1.l21.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l21.m1.1c">w_{0}</annotation></semantics></math>

</div>
<div id="alg1.l22" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l22.1.1.1" class="ltx_text" style="font-size:80%;">22:</span></span>        Send <math id="alg1.l22.m1.1" class="ltx_Math" alttext="w_{t+1}^{i}" display="inline"><semantics id="alg1.l22.m1.1a"><msubsup id="alg1.l22.m1.1.1" xref="alg1.l22.m1.1.1.cmml"><mi id="alg1.l22.m1.1.1.2.2" xref="alg1.l22.m1.1.1.2.2.cmml">w</mi><mrow id="alg1.l22.m1.1.1.2.3" xref="alg1.l22.m1.1.1.2.3.cmml"><mi id="alg1.l22.m1.1.1.2.3.2" xref="alg1.l22.m1.1.1.2.3.2.cmml">t</mi><mo id="alg1.l22.m1.1.1.2.3.1" xref="alg1.l22.m1.1.1.2.3.1.cmml">+</mo><mn id="alg1.l22.m1.1.1.2.3.3" xref="alg1.l22.m1.1.1.2.3.3.cmml">1</mn></mrow><mi id="alg1.l22.m1.1.1.3" xref="alg1.l22.m1.1.1.3.cmml">i</mi></msubsup><annotation-xml encoding="MathML-Content" id="alg1.l22.m1.1b"><apply id="alg1.l22.m1.1.1.cmml" xref="alg1.l22.m1.1.1"><csymbol cd="ambiguous" id="alg1.l22.m1.1.1.1.cmml" xref="alg1.l22.m1.1.1">superscript</csymbol><apply id="alg1.l22.m1.1.1.2.cmml" xref="alg1.l22.m1.1.1"><csymbol cd="ambiguous" id="alg1.l22.m1.1.1.2.1.cmml" xref="alg1.l22.m1.1.1">subscript</csymbol><ci id="alg1.l22.m1.1.1.2.2.cmml" xref="alg1.l22.m1.1.1.2.2">𝑤</ci><apply id="alg1.l22.m1.1.1.2.3.cmml" xref="alg1.l22.m1.1.1.2.3"><plus id="alg1.l22.m1.1.1.2.3.1.cmml" xref="alg1.l22.m1.1.1.2.3.1"></plus><ci id="alg1.l22.m1.1.1.2.3.2.cmml" xref="alg1.l22.m1.1.1.2.3.2">𝑡</ci><cn type="integer" id="alg1.l22.m1.1.1.2.3.3.cmml" xref="alg1.l22.m1.1.1.2.3.3">1</cn></apply></apply><ci id="alg1.l22.m1.1.1.3.cmml" xref="alg1.l22.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l22.m1.1c">w_{t+1}^{i}</annotation></semantics></math> to server

</div>
<div id="alg1.l23" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l23.1.1.1" class="ltx_text" style="font-size:80%;">23:</span></span>     <span id="alg1.l23.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l23.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l24" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l24.1.1.1" class="ltx_text" style="font-size:80%;">24:</span></span>     Aggregate <math id="alg1.l24.m1.1" class="ltx_Math" alttext="w_{t+1}=\frac{1}{N}\sum_{i=1}^{N}w_{t+1}^{i}" display="inline"><semantics id="alg1.l24.m1.1a"><mrow id="alg1.l24.m1.1.1" xref="alg1.l24.m1.1.1.cmml"><msub id="alg1.l24.m1.1.1.2" xref="alg1.l24.m1.1.1.2.cmml"><mi id="alg1.l24.m1.1.1.2.2" xref="alg1.l24.m1.1.1.2.2.cmml">w</mi><mrow id="alg1.l24.m1.1.1.2.3" xref="alg1.l24.m1.1.1.2.3.cmml"><mi id="alg1.l24.m1.1.1.2.3.2" xref="alg1.l24.m1.1.1.2.3.2.cmml">t</mi><mo id="alg1.l24.m1.1.1.2.3.1" xref="alg1.l24.m1.1.1.2.3.1.cmml">+</mo><mn id="alg1.l24.m1.1.1.2.3.3" xref="alg1.l24.m1.1.1.2.3.3.cmml">1</mn></mrow></msub><mo id="alg1.l24.m1.1.1.1" xref="alg1.l24.m1.1.1.1.cmml">=</mo><mrow id="alg1.l24.m1.1.1.3" xref="alg1.l24.m1.1.1.3.cmml"><mfrac id="alg1.l24.m1.1.1.3.2" xref="alg1.l24.m1.1.1.3.2.cmml"><mn id="alg1.l24.m1.1.1.3.2.2" xref="alg1.l24.m1.1.1.3.2.2.cmml">1</mn><mi id="alg1.l24.m1.1.1.3.2.3" xref="alg1.l24.m1.1.1.3.2.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="alg1.l24.m1.1.1.3.1" xref="alg1.l24.m1.1.1.3.1.cmml">​</mo><mrow id="alg1.l24.m1.1.1.3.3" xref="alg1.l24.m1.1.1.3.3.cmml"><msubsup id="alg1.l24.m1.1.1.3.3.1" xref="alg1.l24.m1.1.1.3.3.1.cmml"><mo id="alg1.l24.m1.1.1.3.3.1.2.2" xref="alg1.l24.m1.1.1.3.3.1.2.2.cmml">∑</mo><mrow id="alg1.l24.m1.1.1.3.3.1.2.3" xref="alg1.l24.m1.1.1.3.3.1.2.3.cmml"><mi id="alg1.l24.m1.1.1.3.3.1.2.3.2" xref="alg1.l24.m1.1.1.3.3.1.2.3.2.cmml">i</mi><mo id="alg1.l24.m1.1.1.3.3.1.2.3.1" xref="alg1.l24.m1.1.1.3.3.1.2.3.1.cmml">=</mo><mn id="alg1.l24.m1.1.1.3.3.1.2.3.3" xref="alg1.l24.m1.1.1.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="alg1.l24.m1.1.1.3.3.1.3" xref="alg1.l24.m1.1.1.3.3.1.3.cmml">N</mi></msubsup><msubsup id="alg1.l24.m1.1.1.3.3.2" xref="alg1.l24.m1.1.1.3.3.2.cmml"><mi id="alg1.l24.m1.1.1.3.3.2.2.2" xref="alg1.l24.m1.1.1.3.3.2.2.2.cmml">w</mi><mrow id="alg1.l24.m1.1.1.3.3.2.2.3" xref="alg1.l24.m1.1.1.3.3.2.2.3.cmml"><mi id="alg1.l24.m1.1.1.3.3.2.2.3.2" xref="alg1.l24.m1.1.1.3.3.2.2.3.2.cmml">t</mi><mo id="alg1.l24.m1.1.1.3.3.2.2.3.1" xref="alg1.l24.m1.1.1.3.3.2.2.3.1.cmml">+</mo><mn id="alg1.l24.m1.1.1.3.3.2.2.3.3" xref="alg1.l24.m1.1.1.3.3.2.2.3.3.cmml">1</mn></mrow><mi id="alg1.l24.m1.1.1.3.3.2.3" xref="alg1.l24.m1.1.1.3.3.2.3.cmml">i</mi></msubsup></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l24.m1.1b"><apply id="alg1.l24.m1.1.1.cmml" xref="alg1.l24.m1.1.1"><eq id="alg1.l24.m1.1.1.1.cmml" xref="alg1.l24.m1.1.1.1"></eq><apply id="alg1.l24.m1.1.1.2.cmml" xref="alg1.l24.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l24.m1.1.1.2.1.cmml" xref="alg1.l24.m1.1.1.2">subscript</csymbol><ci id="alg1.l24.m1.1.1.2.2.cmml" xref="alg1.l24.m1.1.1.2.2">𝑤</ci><apply id="alg1.l24.m1.1.1.2.3.cmml" xref="alg1.l24.m1.1.1.2.3"><plus id="alg1.l24.m1.1.1.2.3.1.cmml" xref="alg1.l24.m1.1.1.2.3.1"></plus><ci id="alg1.l24.m1.1.1.2.3.2.cmml" xref="alg1.l24.m1.1.1.2.3.2">𝑡</ci><cn type="integer" id="alg1.l24.m1.1.1.2.3.3.cmml" xref="alg1.l24.m1.1.1.2.3.3">1</cn></apply></apply><apply id="alg1.l24.m1.1.1.3.cmml" xref="alg1.l24.m1.1.1.3"><times id="alg1.l24.m1.1.1.3.1.cmml" xref="alg1.l24.m1.1.1.3.1"></times><apply id="alg1.l24.m1.1.1.3.2.cmml" xref="alg1.l24.m1.1.1.3.2"><divide id="alg1.l24.m1.1.1.3.2.1.cmml" xref="alg1.l24.m1.1.1.3.2"></divide><cn type="integer" id="alg1.l24.m1.1.1.3.2.2.cmml" xref="alg1.l24.m1.1.1.3.2.2">1</cn><ci id="alg1.l24.m1.1.1.3.2.3.cmml" xref="alg1.l24.m1.1.1.3.2.3">𝑁</ci></apply><apply id="alg1.l24.m1.1.1.3.3.cmml" xref="alg1.l24.m1.1.1.3.3"><apply id="alg1.l24.m1.1.1.3.3.1.cmml" xref="alg1.l24.m1.1.1.3.3.1"><csymbol cd="ambiguous" id="alg1.l24.m1.1.1.3.3.1.1.cmml" xref="alg1.l24.m1.1.1.3.3.1">superscript</csymbol><apply id="alg1.l24.m1.1.1.3.3.1.2.cmml" xref="alg1.l24.m1.1.1.3.3.1"><csymbol cd="ambiguous" id="alg1.l24.m1.1.1.3.3.1.2.1.cmml" xref="alg1.l24.m1.1.1.3.3.1">subscript</csymbol><sum id="alg1.l24.m1.1.1.3.3.1.2.2.cmml" xref="alg1.l24.m1.1.1.3.3.1.2.2"></sum><apply id="alg1.l24.m1.1.1.3.3.1.2.3.cmml" xref="alg1.l24.m1.1.1.3.3.1.2.3"><eq id="alg1.l24.m1.1.1.3.3.1.2.3.1.cmml" xref="alg1.l24.m1.1.1.3.3.1.2.3.1"></eq><ci id="alg1.l24.m1.1.1.3.3.1.2.3.2.cmml" xref="alg1.l24.m1.1.1.3.3.1.2.3.2">𝑖</ci><cn type="integer" id="alg1.l24.m1.1.1.3.3.1.2.3.3.cmml" xref="alg1.l24.m1.1.1.3.3.1.2.3.3">1</cn></apply></apply><ci id="alg1.l24.m1.1.1.3.3.1.3.cmml" xref="alg1.l24.m1.1.1.3.3.1.3">𝑁</ci></apply><apply id="alg1.l24.m1.1.1.3.3.2.cmml" xref="alg1.l24.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="alg1.l24.m1.1.1.3.3.2.1.cmml" xref="alg1.l24.m1.1.1.3.3.2">superscript</csymbol><apply id="alg1.l24.m1.1.1.3.3.2.2.cmml" xref="alg1.l24.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="alg1.l24.m1.1.1.3.3.2.2.1.cmml" xref="alg1.l24.m1.1.1.3.3.2">subscript</csymbol><ci id="alg1.l24.m1.1.1.3.3.2.2.2.cmml" xref="alg1.l24.m1.1.1.3.3.2.2.2">𝑤</ci><apply id="alg1.l24.m1.1.1.3.3.2.2.3.cmml" xref="alg1.l24.m1.1.1.3.3.2.2.3"><plus id="alg1.l24.m1.1.1.3.3.2.2.3.1.cmml" xref="alg1.l24.m1.1.1.3.3.2.2.3.1"></plus><ci id="alg1.l24.m1.1.1.3.3.2.2.3.2.cmml" xref="alg1.l24.m1.1.1.3.3.2.2.3.2">𝑡</ci><cn type="integer" id="alg1.l24.m1.1.1.3.3.2.2.3.3.cmml" xref="alg1.l24.m1.1.1.3.3.2.2.3.3">1</cn></apply></apply><ci id="alg1.l24.m1.1.1.3.3.2.3.cmml" xref="alg1.l24.m1.1.1.3.3.2.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l24.m1.1c">w_{t+1}=\frac{1}{N}\sum_{i=1}^{N}w_{t+1}^{i}</annotation></semantics></math>

</div>
<div id="alg1.l25" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l25.1.1.1" class="ltx_text" style="font-size:80%;">25:</span></span>  <span id="alg1.l25.2" class="ltx_text ltx_font_bold">end</span> <span id="alg1.l25.3" class="ltx_text ltx_font_bold">for</span>
</div>
<div id="alg1.l26" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline"><span id="alg1.l26.1.1.1" class="ltx_text" style="font-size:80%;">26:</span></span>  Repeat until convergence

</div>
</div>
</figure>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.10" class="ltx_p">Algorithm <a href="#alg1" title="Algorithm 1 ‣ 3 DPSDA-FL: Differentially Private Synthetic Data Aided Federated Learning Using Foundation Models ‣ Synthetic Data Aided Federated Learning Using Foundation Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> outlines the pseudocode for DPSDA-FL. We consider a FL setting with a single semi-trusted central server <math id="S3.p3.1.m1.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.p3.1.m1.1a"><mi id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><ci id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">S</annotation></semantics></math> and <math id="S3.p3.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.p3.2.m2.1a"><mi id="S3.p3.2.m2.1.1" xref="S3.p3.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.p3.2.m2.1b"><ci id="S3.p3.2.m2.1.1.cmml" xref="S3.p3.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.2.m2.1c">N</annotation></semantics></math> clients denoted by <math id="S3.p3.3.m3.3" class="ltx_Math" alttext="\{C_{1},C_{2},...C_{N}\}" display="inline"><semantics id="S3.p3.3.m3.3a"><mrow id="S3.p3.3.m3.3.3.3" xref="S3.p3.3.m3.3.3.4.cmml"><mo stretchy="false" id="S3.p3.3.m3.3.3.3.4" xref="S3.p3.3.m3.3.3.4.cmml">{</mo><msub id="S3.p3.3.m3.1.1.1.1" xref="S3.p3.3.m3.1.1.1.1.cmml"><mi id="S3.p3.3.m3.1.1.1.1.2" xref="S3.p3.3.m3.1.1.1.1.2.cmml">C</mi><mn id="S3.p3.3.m3.1.1.1.1.3" xref="S3.p3.3.m3.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.p3.3.m3.3.3.3.5" xref="S3.p3.3.m3.3.3.4.cmml">,</mo><msub id="S3.p3.3.m3.2.2.2.2" xref="S3.p3.3.m3.2.2.2.2.cmml"><mi id="S3.p3.3.m3.2.2.2.2.2" xref="S3.p3.3.m3.2.2.2.2.2.cmml">C</mi><mn id="S3.p3.3.m3.2.2.2.2.3" xref="S3.p3.3.m3.2.2.2.2.3.cmml">2</mn></msub><mo id="S3.p3.3.m3.3.3.3.6" xref="S3.p3.3.m3.3.3.4.cmml">,</mo><mrow id="S3.p3.3.m3.3.3.3.3" xref="S3.p3.3.m3.3.3.3.3.cmml"><mi mathvariant="normal" id="S3.p3.3.m3.3.3.3.3.2" xref="S3.p3.3.m3.3.3.3.3.2.cmml">…</mi><mo lspace="0em" rspace="0em" id="S3.p3.3.m3.3.3.3.3.1" xref="S3.p3.3.m3.3.3.3.3.1.cmml">​</mo><msub id="S3.p3.3.m3.3.3.3.3.3" xref="S3.p3.3.m3.3.3.3.3.3.cmml"><mi id="S3.p3.3.m3.3.3.3.3.3.2" xref="S3.p3.3.m3.3.3.3.3.3.2.cmml">C</mi><mi id="S3.p3.3.m3.3.3.3.3.3.3" xref="S3.p3.3.m3.3.3.3.3.3.3.cmml">N</mi></msub></mrow><mo stretchy="false" id="S3.p3.3.m3.3.3.3.7" xref="S3.p3.3.m3.3.3.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p3.3.m3.3b"><set id="S3.p3.3.m3.3.3.4.cmml" xref="S3.p3.3.m3.3.3.3"><apply id="S3.p3.3.m3.1.1.1.1.cmml" xref="S3.p3.3.m3.1.1.1.1"><csymbol cd="ambiguous" id="S3.p3.3.m3.1.1.1.1.1.cmml" xref="S3.p3.3.m3.1.1.1.1">subscript</csymbol><ci id="S3.p3.3.m3.1.1.1.1.2.cmml" xref="S3.p3.3.m3.1.1.1.1.2">𝐶</ci><cn type="integer" id="S3.p3.3.m3.1.1.1.1.3.cmml" xref="S3.p3.3.m3.1.1.1.1.3">1</cn></apply><apply id="S3.p3.3.m3.2.2.2.2.cmml" xref="S3.p3.3.m3.2.2.2.2"><csymbol cd="ambiguous" id="S3.p3.3.m3.2.2.2.2.1.cmml" xref="S3.p3.3.m3.2.2.2.2">subscript</csymbol><ci id="S3.p3.3.m3.2.2.2.2.2.cmml" xref="S3.p3.3.m3.2.2.2.2.2">𝐶</ci><cn type="integer" id="S3.p3.3.m3.2.2.2.2.3.cmml" xref="S3.p3.3.m3.2.2.2.2.3">2</cn></apply><apply id="S3.p3.3.m3.3.3.3.3.cmml" xref="S3.p3.3.m3.3.3.3.3"><times id="S3.p3.3.m3.3.3.3.3.1.cmml" xref="S3.p3.3.m3.3.3.3.3.1"></times><ci id="S3.p3.3.m3.3.3.3.3.2.cmml" xref="S3.p3.3.m3.3.3.3.3.2">…</ci><apply id="S3.p3.3.m3.3.3.3.3.3.cmml" xref="S3.p3.3.m3.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.p3.3.m3.3.3.3.3.3.1.cmml" xref="S3.p3.3.m3.3.3.3.3.3">subscript</csymbol><ci id="S3.p3.3.m3.3.3.3.3.3.2.cmml" xref="S3.p3.3.m3.3.3.3.3.3.2">𝐶</ci><ci id="S3.p3.3.m3.3.3.3.3.3.3.cmml" xref="S3.p3.3.m3.3.3.3.3.3.3">𝑁</ci></apply></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.3.m3.3c">\{C_{1},C_{2},...C_{N}\}</annotation></semantics></math>. A horizontal FL setup is one where the data across the FL clients is partitioned horizontally, and clients share similar feature sets but different sample spaces. Each client possesses a local dataset <math id="S3.p3.4.m4.1" class="ltx_Math" alttext="D_{c}" display="inline"><semantics id="S3.p3.4.m4.1a"><msub id="S3.p3.4.m4.1.1" xref="S3.p3.4.m4.1.1.cmml"><mi id="S3.p3.4.m4.1.1.2" xref="S3.p3.4.m4.1.1.2.cmml">D</mi><mi id="S3.p3.4.m4.1.1.3" xref="S3.p3.4.m4.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p3.4.m4.1b"><apply id="S3.p3.4.m4.1.1.cmml" xref="S3.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.p3.4.m4.1.1.1.cmml" xref="S3.p3.4.m4.1.1">subscript</csymbol><ci id="S3.p3.4.m4.1.1.2.cmml" xref="S3.p3.4.m4.1.1.2">𝐷</ci><ci id="S3.p3.4.m4.1.1.3.cmml" xref="S3.p3.4.m4.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.4.m4.1c">D_{c}</annotation></semantics></math>, which is a subset of the global dataset <math id="S3.p3.5.m5.1" class="ltx_Math" alttext="D_{G}" display="inline"><semantics id="S3.p3.5.m5.1a"><msub id="S3.p3.5.m5.1.1" xref="S3.p3.5.m5.1.1.cmml"><mi id="S3.p3.5.m5.1.1.2" xref="S3.p3.5.m5.1.1.2.cmml">D</mi><mi id="S3.p3.5.m5.1.1.3" xref="S3.p3.5.m5.1.1.3.cmml">G</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p3.5.m5.1b"><apply id="S3.p3.5.m5.1.1.cmml" xref="S3.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S3.p3.5.m5.1.1.1.cmml" xref="S3.p3.5.m5.1.1">subscript</csymbol><ci id="S3.p3.5.m5.1.1.2.cmml" xref="S3.p3.5.m5.1.1.2">𝐷</ci><ci id="S3.p3.5.m5.1.1.3.cmml" xref="S3.p3.5.m5.1.1.3">𝐺</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.5.m5.1c">D_{G}</annotation></semantics></math>. <math id="S3.p3.6.m6.1" class="ltx_Math" alttext="D_{G}" display="inline"><semantics id="S3.p3.6.m6.1a"><msub id="S3.p3.6.m6.1.1" xref="S3.p3.6.m6.1.1.cmml"><mi id="S3.p3.6.m6.1.1.2" xref="S3.p3.6.m6.1.1.2.cmml">D</mi><mi id="S3.p3.6.m6.1.1.3" xref="S3.p3.6.m6.1.1.3.cmml">G</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p3.6.m6.1b"><apply id="S3.p3.6.m6.1.1.cmml" xref="S3.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S3.p3.6.m6.1.1.1.cmml" xref="S3.p3.6.m6.1.1">subscript</csymbol><ci id="S3.p3.6.m6.1.1.2.cmml" xref="S3.p3.6.m6.1.1.2">𝐷</ci><ci id="S3.p3.6.m6.1.1.3.cmml" xref="S3.p3.6.m6.1.1.3">𝐺</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.6.m6.1c">D_{G}</annotation></semantics></math> follows a normal distribution and consists of <math id="S3.p3.7.m7.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.p3.7.m7.1a"><mi id="S3.p3.7.m7.1.1" xref="S3.p3.7.m7.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.p3.7.m7.1b"><ci id="S3.p3.7.m7.1.1.cmml" xref="S3.p3.7.m7.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.7.m7.1c">k</annotation></semantics></math> classes of data. However, <math id="S3.p3.8.m8.1" class="ltx_Math" alttext="{D_{c}}" display="inline"><semantics id="S3.p3.8.m8.1a"><msub id="S3.p3.8.m8.1.1" xref="S3.p3.8.m8.1.1.cmml"><mi id="S3.p3.8.m8.1.1.2" xref="S3.p3.8.m8.1.1.2.cmml">D</mi><mi id="S3.p3.8.m8.1.1.3" xref="S3.p3.8.m8.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p3.8.m8.1b"><apply id="S3.p3.8.m8.1.1.cmml" xref="S3.p3.8.m8.1.1"><csymbol cd="ambiguous" id="S3.p3.8.m8.1.1.1.cmml" xref="S3.p3.8.m8.1.1">subscript</csymbol><ci id="S3.p3.8.m8.1.1.2.cmml" xref="S3.p3.8.m8.1.1.2">𝐷</ci><ci id="S3.p3.8.m8.1.1.3.cmml" xref="S3.p3.8.m8.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.8.m8.1c">{D_{c}}</annotation></semantics></math> does not follow a normal distribution as the data distribution amongst the clients is Non-IID. Some clients may possess fewer samples than others, leading to quantity skew or some classes of data but not others resulting in label skew. As we are considering a cross-silo FL setup, all the clients participate in training rounds, and each local model <math id="S3.p3.9.m9.1" class="ltx_Math" alttext="L_{n}" display="inline"><semantics id="S3.p3.9.m9.1a"><msub id="S3.p3.9.m9.1.1" xref="S3.p3.9.m9.1.1.cmml"><mi id="S3.p3.9.m9.1.1.2" xref="S3.p3.9.m9.1.1.2.cmml">L</mi><mi id="S3.p3.9.m9.1.1.3" xref="S3.p3.9.m9.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p3.9.m9.1b"><apply id="S3.p3.9.m9.1.1.cmml" xref="S3.p3.9.m9.1.1"><csymbol cd="ambiguous" id="S3.p3.9.m9.1.1.1.cmml" xref="S3.p3.9.m9.1.1">subscript</csymbol><ci id="S3.p3.9.m9.1.1.2.cmml" xref="S3.p3.9.m9.1.1.2">𝐿</ci><ci id="S3.p3.9.m9.1.1.3.cmml" xref="S3.p3.9.m9.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.9.m9.1c">L_{n}</annotation></semantics></math> contributes to the global model aggregation. The objective is to produce a single global model <math id="S3.p3.10.m10.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S3.p3.10.m10.1a"><mi id="S3.p3.10.m10.1.1" xref="S3.p3.10.m10.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S3.p3.10.m10.1b"><ci id="S3.p3.10.m10.1.1.cmml" xref="S3.p3.10.m10.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.10.m10.1c">G</annotation></semantics></math> that performs well on the global test data.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.3.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S3.T1.4.2" class="ltx_text ltx_font_bold" style="font-size:90%;">Experimental Settings</span></figcaption>
<table id="S3.T1.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.5.1.1" class="ltx_tr">
<th id="S3.T1.5.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"><span id="S3.T1.5.1.1.1.1" class="ltx_text ltx_font_bold">Name</span></th>
<th id="S3.T1.5.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt">
<span id="S3.T1.5.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.5.1.1.2.1.1" class="ltx_p" style="width:108.4pt;"><span id="S3.T1.5.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Value</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.5.2.1" class="ltx_tr">
<th id="S3.T1.5.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t">FL architecture</th>
<td id="S3.T1.5.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t">
<span id="S3.T1.5.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.5.2.1.2.1.1" class="ltx_p" style="width:108.4pt;">Cross-Silo Horizontal FL</span>
</span>
</td>
</tr>
<tr id="S3.T1.5.3.2" class="ltx_tr">
<th id="S3.T1.5.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Dataset</th>
<td id="S3.T1.5.3.2.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.5.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.5.3.2.2.1.1" class="ltx_p" style="width:108.4pt;">CIFAR-10</span>
</span>
</td>
</tr>
<tr id="S3.T1.5.4.3" class="ltx_tr">
<th id="S3.T1.5.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">NN architecture</th>
<td id="S3.T1.5.4.3.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.5.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.5.4.3.2.1.1" class="ltx_p" style="width:108.4pt;">CNN</span>
</span>
</td>
</tr>
<tr id="S3.T1.5.5.4" class="ltx_tr">
<th id="S3.T1.5.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Number of clients</th>
<td id="S3.T1.5.5.4.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.5.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.5.5.4.2.1.1" class="ltx_p" style="width:108.4pt;">5</span>
</span>
</td>
</tr>
<tr id="S3.T1.5.6.5" class="ltx_tr">
<th id="S3.T1.5.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Number of local epochs</th>
<td id="S3.T1.5.6.5.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.5.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.5.6.5.2.1.1" class="ltx_p" style="width:108.4pt;">2</span>
</span>
</td>
</tr>
<tr id="S3.T1.5.7.6" class="ltx_tr">
<th id="S3.T1.5.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Number of global rounds</th>
<td id="S3.T1.5.7.6.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.5.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.5.7.6.2.1.1" class="ltx_p" style="width:108.4pt;">20</span>
</span>
</td>
</tr>
<tr id="S3.T1.5.8.7" class="ltx_tr">
<th id="S3.T1.5.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Learning rate</th>
<td id="S3.T1.5.8.7.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.5.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.5.8.7.2.1.1" class="ltx_p" style="width:108.4pt;">0.1</span>
</span>
</td>
</tr>
<tr id="S3.T1.5.9.8" class="ltx_tr">
<th id="S3.T1.5.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r">Batch size</th>
<td id="S3.T1.5.9.8.2" class="ltx_td ltx_align_justify ltx_align_top">
<span id="S3.T1.5.9.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.5.9.8.2.1.1" class="ltx_p" style="width:108.4pt;">32</span>
</span>
</td>
</tr>
<tr id="S3.T1.5.10.9" class="ltx_tr">
<th id="S3.T1.5.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r">Optimizer</th>
<td id="S3.T1.5.10.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb">
<span id="S3.T1.5.10.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.5.10.9.2.1.1" class="ltx_p" style="width:108.4pt;">Stochastic gradient descent</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments and Evaluations</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experimental Setting</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Below we describe the experimental settings used in our evaluation. These settings are also summarised in Table <a href="#S3.T1" title="Table 1 ‣ 3 DPSDA-FL: Differentially Private Synthetic Data Aided Federated Learning Using Foundation Models ‣ Synthetic Data Aided Federated Learning Using Foundation Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.1 </span>Dataset</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">We performed our experiments on the CIFAR-10 dataset, which is a benchmark dataset used for image recognition. It consists of 50,000 training samples and 10,000 testing samples. The dataset is mostly utilized to evaluate the classification accuracy of Convolutional Neural Networks (CNN). We used the entire 10,000 images to test the accuracy of the global model for our approach and the baselines.</p>
</div>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.2 </span>Differentially Private Synthetic Dataset</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">We deployed five pre-trained diffusion models to generate synthetic local data for each client. To limit privacy risks associated with the honest but curious server, we assumed each client only generated and shared at most 50% of its number of classes. We generated 5000 differentially private synthetic images for each class of the CIFAR-10 dataset and selected a subset to be used for augmentation. The generated images were 64 x 64; as such, they were resized to 32 x 32, which is the original size of the CIFAR-10 images.</p>
</div>
</section>
<section id="S4.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.3 </span>Data Distribution</h4>

<div id="S4.SS1.SSS3.p1" class="ltx_para">
<p id="S4.SS1.SSS3.p1.1" class="ltx_p">We evaluated the effectiveness of our approach by simulating real-world FL participants with varying data distributions that follow a Non-IID fashion. In other words, the local data distribution of each client is not representative of the global dataset. To simulate extreme label skew for our experiments, we followed the work <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib12" title="" class="ltx_ref">2020</a>)</cite>; each client received samples from only two classes.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.11.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S4.T2.12.2" class="ltx_text" style="font-size:90%;">Classification Accuracy of the Global Model in FedAvg and FedProx Compared with DPSDA-FL with 5 Clients</span></figcaption>
<table id="S4.T2.9" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.9.10.1" class="ltx_tr">
<th id="S4.T2.9.10.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">Approach</th>
<th id="S4.T2.9.10.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_tt">Data Augmentation</th>
<th id="S4.T2.9.10.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">% of Synthetic Data Shared</th>
<th id="S4.T2.9.10.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Classes/Client</th>
<th id="S4.T2.9.10.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Global Model Accuracy</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.3.3" class="ltx_tr">
<th id="S4.T2.3.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">FedAvg</th>
<th id="S4.T2.3.3.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">No</th>
<td id="S4.T2.1.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T2.1.1.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.T2.1.1.1.m1.1a"><mn id="S4.T2.1.1.1.m1.1.1" xref="S4.T2.1.1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.m1.1b"><cn type="integer" id="S4.T2.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.m1.1.1">0</cn></annotation-xml></semantics></math></td>
<td id="S4.T2.2.2.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T2.2.2.2.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S4.T2.2.2.2.m1.1a"><mn id="S4.T2.2.2.2.m1.1.1" xref="S4.T2.2.2.2.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.m1.1b"><cn type="integer" id="S4.T2.2.2.2.m1.1.1.cmml" xref="S4.T2.2.2.2.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.m1.1c">2</annotation></semantics></math></td>
<td id="S4.T2.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T2.3.3.3.m1.1" class="ltx_Math" alttext="28.30\pm 2.20\%" display="inline"><semantics id="S4.T2.3.3.3.m1.1a"><mrow id="S4.T2.3.3.3.m1.1.1" xref="S4.T2.3.3.3.m1.1.1.cmml"><mn id="S4.T2.3.3.3.m1.1.1.2" xref="S4.T2.3.3.3.m1.1.1.2.cmml">28.30</mn><mo id="S4.T2.3.3.3.m1.1.1.1" xref="S4.T2.3.3.3.m1.1.1.1.cmml">±</mo><mrow id="S4.T2.3.3.3.m1.1.1.3" xref="S4.T2.3.3.3.m1.1.1.3.cmml"><mn id="S4.T2.3.3.3.m1.1.1.3.2" xref="S4.T2.3.3.3.m1.1.1.3.2.cmml">2.20</mn><mo id="S4.T2.3.3.3.m1.1.1.3.1" xref="S4.T2.3.3.3.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.3.m1.1b"><apply id="S4.T2.3.3.3.m1.1.1.cmml" xref="S4.T2.3.3.3.m1.1.1"><csymbol cd="latexml" id="S4.T2.3.3.3.m1.1.1.1.cmml" xref="S4.T2.3.3.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.3.3.3.m1.1.1.2.cmml" xref="S4.T2.3.3.3.m1.1.1.2">28.30</cn><apply id="S4.T2.3.3.3.m1.1.1.3.cmml" xref="S4.T2.3.3.3.m1.1.1.3"><csymbol cd="latexml" id="S4.T2.3.3.3.m1.1.1.3.1.cmml" xref="S4.T2.3.3.3.m1.1.1.3.1">percent</csymbol><cn type="float" id="S4.T2.3.3.3.m1.1.1.3.2.cmml" xref="S4.T2.3.3.3.m1.1.1.3.2">2.20</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.3.m1.1c">28.30\pm 2.20\%</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.6.6" class="ltx_tr">
<th id="S4.T2.6.6.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">FedProx</th>
<th id="S4.T2.6.6.5" class="ltx_td ltx_align_center ltx_th ltx_th_row">No</th>
<td id="S4.T2.4.4.1" class="ltx_td ltx_align_center"><math id="S4.T2.4.4.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.T2.4.4.1.m1.1a"><mn id="S4.T2.4.4.1.m1.1.1" xref="S4.T2.4.4.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.1.m1.1b"><cn type="integer" id="S4.T2.4.4.1.m1.1.1.cmml" xref="S4.T2.4.4.1.m1.1.1">0</cn></annotation-xml></semantics></math></td>
<td id="S4.T2.5.5.2" class="ltx_td ltx_align_center"><math id="S4.T2.5.5.2.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S4.T2.5.5.2.m1.1a"><mn id="S4.T2.5.5.2.m1.1.1" xref="S4.T2.5.5.2.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.2.m1.1b"><cn type="integer" id="S4.T2.5.5.2.m1.1.1.cmml" xref="S4.T2.5.5.2.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.2.m1.1c">2</annotation></semantics></math></td>
<td id="S4.T2.6.6.3" class="ltx_td ltx_align_center"><math id="S4.T2.6.6.3.m1.1" class="ltx_Math" alttext="31.70\pm 2.26\%" display="inline"><semantics id="S4.T2.6.6.3.m1.1a"><mrow id="S4.T2.6.6.3.m1.1.1" xref="S4.T2.6.6.3.m1.1.1.cmml"><mn id="S4.T2.6.6.3.m1.1.1.2" xref="S4.T2.6.6.3.m1.1.1.2.cmml">31.70</mn><mo id="S4.T2.6.6.3.m1.1.1.1" xref="S4.T2.6.6.3.m1.1.1.1.cmml">±</mo><mrow id="S4.T2.6.6.3.m1.1.1.3" xref="S4.T2.6.6.3.m1.1.1.3.cmml"><mn id="S4.T2.6.6.3.m1.1.1.3.2" xref="S4.T2.6.6.3.m1.1.1.3.2.cmml">2.26</mn><mo id="S4.T2.6.6.3.m1.1.1.3.1" xref="S4.T2.6.6.3.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.3.m1.1b"><apply id="S4.T2.6.6.3.m1.1.1.cmml" xref="S4.T2.6.6.3.m1.1.1"><csymbol cd="latexml" id="S4.T2.6.6.3.m1.1.1.1.cmml" xref="S4.T2.6.6.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.6.6.3.m1.1.1.2.cmml" xref="S4.T2.6.6.3.m1.1.1.2">31.70</cn><apply id="S4.T2.6.6.3.m1.1.1.3.cmml" xref="S4.T2.6.6.3.m1.1.1.3"><csymbol cd="latexml" id="S4.T2.6.6.3.m1.1.1.3.1.cmml" xref="S4.T2.6.6.3.m1.1.1.3.1">percent</csymbol><cn type="float" id="S4.T2.6.6.3.m1.1.1.3.2.cmml" xref="S4.T2.6.6.3.m1.1.1.3.2">2.26</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.3.m1.1c">31.70\pm 2.26\%</annotation></semantics></math></td>
</tr>
<tr id="S4.T2.9.9" class="ltx_tr">
<th id="S4.T2.9.9.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">DPSDA-FL</th>
<th id="S4.T2.9.9.5" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb">Yes</th>
<td id="S4.T2.7.7.1" class="ltx_td ltx_align_center ltx_border_bb"><math id="S4.T2.7.7.1.m1.1" class="ltx_Math" alttext="50" display="inline"><semantics id="S4.T2.7.7.1.m1.1a"><mn id="S4.T2.7.7.1.m1.1.1" xref="S4.T2.7.7.1.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S4.T2.7.7.1.m1.1b"><cn type="integer" id="S4.T2.7.7.1.m1.1.1.cmml" xref="S4.T2.7.7.1.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.7.1.m1.1c">50</annotation></semantics></math></td>
<td id="S4.T2.8.8.2" class="ltx_td ltx_align_center ltx_border_bb"><math id="S4.T2.8.8.2.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S4.T2.8.8.2.m1.1a"><mn id="S4.T2.8.8.2.m1.1.1" xref="S4.T2.8.8.2.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S4.T2.8.8.2.m1.1b"><cn type="integer" id="S4.T2.8.8.2.m1.1.1.cmml" xref="S4.T2.8.8.2.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.8.8.2.m1.1c">2</annotation></semantics></math></td>
<td id="S4.T2.9.9.3" class="ltx_td ltx_align_center ltx_border_bb"><math id="S4.T2.9.9.3.m1.1" class="ltx_Math" alttext="37.20\pm 0.44\%" display="inline"><semantics id="S4.T2.9.9.3.m1.1a"><mrow id="S4.T2.9.9.3.m1.1.1" xref="S4.T2.9.9.3.m1.1.1.cmml"><mn id="S4.T2.9.9.3.m1.1.1.2" xref="S4.T2.9.9.3.m1.1.1.2.cmml">37.20</mn><mo id="S4.T2.9.9.3.m1.1.1.1" xref="S4.T2.9.9.3.m1.1.1.1.cmml">±</mo><mrow id="S4.T2.9.9.3.m1.1.1.3" xref="S4.T2.9.9.3.m1.1.1.3.cmml"><mn id="S4.T2.9.9.3.m1.1.1.3.2" xref="S4.T2.9.9.3.m1.1.1.3.2.cmml">0.44</mn><mo id="S4.T2.9.9.3.m1.1.1.3.1" xref="S4.T2.9.9.3.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.9.9.3.m1.1b"><apply id="S4.T2.9.9.3.m1.1.1.cmml" xref="S4.T2.9.9.3.m1.1.1"><csymbol cd="latexml" id="S4.T2.9.9.3.m1.1.1.1.cmml" xref="S4.T2.9.9.3.m1.1.1.1">plus-or-minus</csymbol><cn type="float" id="S4.T2.9.9.3.m1.1.1.2.cmml" xref="S4.T2.9.9.3.m1.1.1.2">37.20</cn><apply id="S4.T2.9.9.3.m1.1.1.3.cmml" xref="S4.T2.9.9.3.m1.1.1.3"><csymbol cd="latexml" id="S4.T2.9.9.3.m1.1.1.3.1.cmml" xref="S4.T2.9.9.3.m1.1.1.3.1">percent</csymbol><cn type="float" id="S4.T2.9.9.3.m1.1.1.3.2.cmml" xref="S4.T2.9.9.3.m1.1.1.3.2">0.44</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.9.9.3.m1.1c">37.20\pm 0.44\%</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.2.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S4.T3.3.2" class="ltx_text" style="font-size:90%;">Recall of the Global Model in FedAvg and FedProxCompared with DPSDA-FL with 5 Clients</span></figcaption>
<table id="S4.T3.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.4.1.1" class="ltx_tr">
<th id="S4.T3.4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Approach</th>
<th id="S4.T3.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Recall of the Plane Class</th>
<th id="S4.T3.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Recall of the Cat Class</th>
<th id="S4.T3.4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Recall of the Ship</th>
<th id="S4.T3.4.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Class Recall of the Truck Class</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.4.2.1" class="ltx_tr">
<td id="S4.T3.4.2.1.1" class="ltx_td ltx_align_center ltx_border_t">FedAvg</td>
<td id="S4.T3.4.2.1.2" class="ltx_td ltx_align_center ltx_border_t">55.9%</td>
<td id="S4.T3.4.2.1.3" class="ltx_td ltx_align_center ltx_border_t">15.6%</td>
<td id="S4.T3.4.2.1.4" class="ltx_td ltx_align_center ltx_border_t">35.1%</td>
<td id="S4.T3.4.2.1.5" class="ltx_td ltx_align_center ltx_border_t">46.5%</td>
</tr>
<tr id="S4.T3.4.3.2" class="ltx_tr">
<td id="S4.T3.4.3.2.1" class="ltx_td ltx_align_center">FedProx</td>
<td id="S4.T3.4.3.2.2" class="ltx_td ltx_align_center">40.6%</td>
<td id="S4.T3.4.3.2.3" class="ltx_td ltx_align_center">19.3%</td>
<td id="S4.T3.4.3.2.4" class="ltx_td ltx_align_center">53.2%</td>
<td id="S4.T3.4.3.2.5" class="ltx_td ltx_align_center">44.6%</td>
</tr>
<tr id="S4.T3.4.4.3" class="ltx_tr">
<td id="S4.T3.4.4.3.1" class="ltx_td ltx_align_center ltx_border_bb">DPSDA-FL</td>
<td id="S4.T3.4.4.3.2" class="ltx_td ltx_align_center ltx_border_bb">58.86%</td>
<td id="S4.T3.4.4.3.3" class="ltx_td ltx_align_center ltx_border_bb">42.4%</td>
<td id="S4.T3.4.4.3.4" class="ltx_td ltx_align_center ltx_border_bb">58.6%</td>
<td id="S4.T3.4.4.3.5" class="ltx_td ltx_align_center ltx_border_bb">56.46.0%</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S4.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.4 </span>Neural Network Architecture</h4>

<div id="S4.SS1.SSS4.p1" class="ltx_para">
<p id="S4.SS1.SSS4.p1.1" class="ltx_p">We used CNN for all our experiments. The CNN includes two convolutional layers, each followed by a ReLU activation and a max-pooling layer. It also includes two fully connected layers followed by a ReLU activation. The final output layer uses a log-softmax activation to produce class probabilities. We used stochastic gradient descent (SGD) and negative log-likelihood as our local model optimizer and loss function.</p>
</div>
</section>
<section id="S4.SS1.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.5 </span>Cross-Silo Horizontal FL</h4>

<div id="S4.SS1.SSS5.p1" class="ltx_para">
<p id="S4.SS1.SSS5.p1.1" class="ltx_p">In cross-silo horizontal FL (HFL), clients are usually smaller in number compared to cross-device horizontal FL, where there are many devices collaboratively training a model. Also, unlike cross-device HFL, where a fraction of clients are selected to participate in each round, in cross-silo HFL, all the clients usually participate in all communication rounds. Cross-silo setups are also traditionally made up of larger institutions with abundant computational resources serving as clients compared to cross-device, where there are typically resource-constrained smaller devices participating in the training process.</p>
</div>
</section>
<section id="S4.SS1.SSS6" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.6 </span>Evaluation Metrics</h4>

<div id="S4.SS1.SSS6.p1" class="ltx_para">
<p id="S4.SS1.SSS6.p1.1" class="ltx_p">We used the top-1 accuracy of the global model to evaluate how effectively our data augmentation technique can enhance FL. We also measured and compared the recall of the global model produced by the baselines and our approach. Recall is an essential metric for machine learning models that are deployed in safety-critical sectors such as healthcare, where FL is a good candidate. This is because false positives in such domains entail significant consequences. We reported the mean and standard deviation of the global model accuracy from running each experiment three times. We also reported the mean of the recall.</p>
</div>
</section>
<section id="S4.SS1.SSS7" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.1.7 </span>Baselines</h4>

<div id="S4.SS1.SSS7.p1" class="ltx_para">
<p id="S4.SS1.SSS7.p1.1" class="ltx_p"><span id="S4.SS1.SSS7.p1.1.1" class="ltx_text ltx_font_bold">Federated Averaging</span>: To compare the effectiveness of our approach, we used federated averaging <cite class="ltx_cite ltx_citemacro_cite">McMahan <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib16" title="" class="ltx_ref">2017</a>)</cite>, which is the vanilla version of FL where clients share their local model parameters with the central server, which is then aggregated to form an updated global model. 
<br class="ltx_break"><span id="S4.SS1.SSS7.p1.1.2" class="ltx_text ltx_font_bold">Federated Optimization (FedProx)</span>: We implemented FedProx <cite class="ltx_cite ltx_citemacro_cite">Li <span class="ltx_text ltx_font_italic">et al.</span> (<a href="#bib.bib12" title="" class="ltx_ref">2020</a>)</cite> with the same number of clients as in our work and used the value of 0.001 for mu, which is the proximal term that aids in combating the effect of data heterogeneity in FL with Non-IID Data.</p>
</div>
<figure id="S4.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F2.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2407.05174/assets/IID_IJCAI.png" id="S4.F2.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="492" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F2.sf1.3.2" class="ltx_text" style="font-size:90%;">Global Model Trained on IID Data Using FedAvg</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F2.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2407.05174/assets/FedAvgIJCAI.png" id="S4.F2.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="491" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F2.sf2.3.2" class="ltx_text" style="font-size:90%;">Global Model Trained on Non-IID Data Using FedAvg</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F2.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/2407.05174/assets/FedProx.png" id="S4.F2.sf3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="490" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S4.F2.sf3.3.2" class="ltx_text" style="font-size:90%;">Global Model Trained on Non-IID Data Using FedProx</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S4.F2.sf4" class="ltx_figure ltx_figure_panel"><img src="/html/2407.05174/assets/DPSDA_IJCAI.png" id="S4.F2.sf4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="491" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S4.F2.sf4.3.2" class="ltx_text" style="font-size:90%;">Global Model Trained on Non-IID Data Using DPSDA FL</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S4.F2.3.2" class="ltx_text ltx_align_center" style="font-size:90%;">Confusion matrices highlighting the correct predictions and misclassifications made by the various approaches.</span></figcaption>
</figure>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Results and Discussion</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Our experimental results are summarised in Tables <a href="#S4.T2" title="Table 2 ‣ 4.1.3 Data Distribution ‣ 4.1 Experimental Setting ‣ 4 Experiments and Evaluations ‣ Synthetic Data Aided Federated Learning Using Foundation Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and <a href="#S4.T3" title="Table 3 ‣ 4.1.3 Data Distribution ‣ 4.1 Experimental Setting ‣ 4 Experiments and Evaluations ‣ Synthetic Data Aided Federated Learning Using Foundation Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, as well as in Figure <a href="#S4.F2" title="Figure 2 ‣ 4.1.7 Baselines ‣ 4.1 Experimental Setting ‣ 4 Experiments and Evaluations ‣ Synthetic Data Aided Federated Learning Using Foundation Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. We visualized our models’ performances using confusion matrices as they provide a clear insight into the model’s ability to make correct predictions for both positive and negative cases. The darker shades of colour in each matrix represent these correct predictions.
Our findings reveal a promising outcome. For the global FL model trained on IID Data using FedAvg, which represents the most ideal case, as depicted in Figure <a href="#S4.F2.sf1" title="In Figure 2 ‣ 4.1.7 Baselines ‣ 4.1 Experimental Setting ‣ 4 Experiments and Evaluations ‣ Synthetic Data Aided Federated Learning Using Foundation Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2(a)</span></a>, the majority of classes were correctly identified, as evidenced by a darkened diagonal. In contrast, the global model trained on Non-IID using FedAvg, where each client possesses data from only 2 classes, struggles to correctly identify positive and negative cases, as shown in Figure <a href="#S4.F2.sf2" title="In Figure 2 ‣ 4.1.7 Baselines ‣ 4.1 Experimental Setting ‣ 4 Experiments and Evaluations ‣ Synthetic Data Aided Federated Learning Using Foundation Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2(b)</span></a>. This struggle highlights the challenge faced by models in such scenarios. The global model trained using FedProx Figure <a href="#S4.F2.sf3" title="In Figure 2 ‣ 4.1.7 Baselines ‣ 4.1 Experimental Setting ‣ 4 Experiments and Evaluations ‣ Synthetic Data Aided Federated Learning Using Foundation Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2(c)</span></a> shows a better performance than FedAvg, due to the proximal term added to the loss function of local clients to prevent significant divergence. However, DPSDA-FL demonstrated an even more accurate and enhanced global model, as shown in Table <a href="#S4.T2" title="Table 2 ‣ 4.1.3 Data Distribution ‣ 4.1 Experimental Setting ‣ 4 Experiments and Evaluations ‣ Synthetic Data Aided Federated Learning Using Foundation Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and Figure <a href="#S4.F2.sf4" title="In Figure 2 ‣ 4.1.7 Baselines ‣ 4.1 Experimental Setting ‣ 4 Experiments and Evaluations ‣ Synthetic Data Aided Federated Learning Using Foundation Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2(d)</span></a>. This can be attributed to the more stable local training for clients aided by the differentially private synthetic data. The recall of the classes for which the differentially private synthetic data generated by the foundation models is shared with other clients tends to improve as well, as shown in Table <a href="#S4.T3" title="Table 3 ‣ 4.1.3 Data Distribution ‣ 4.1 Experimental Setting ‣ 4 Experiments and Evaluations ‣ Synthetic Data Aided Federated Learning Using Foundation Models" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. This suggests that the local models that make up the global model were able to effectively learn features of those classes from the high utility and diverse synthetic data. As such, the global model is able to identify more data samples from those classes and also distinguish the classes more accurately than others, compared to FedAvg and FedProx.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we present a new data augmentation strategy that has the potential to significantly enhance the performance of cross-silo horizontal FL with Non-IID. By mitigating the effect of data heterogeneity, DPSDA-FL, which utilizes differentially private synthetic data generated by pre-trained foundation models, can improve the local training and convergence of the global model. Our experimental results demonstrate that DPSDA-FL can effectively improve the class recall and classification accuracy of the global model in FL with Non-IID issues.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">We plan on evaluating our approach by conducting more experiments and generating local synthetic data using a limited number of private data samples. We also leave experimenting with other datasets that do not overlap with the training datasets of the foundation models for future work. 
<br class="ltx_break"></p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">This work was supported by The University of Manchester and EPSRC through the EnnCore project [EP/T026995/1].</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Antoniou <span id="bib.bib1.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2018]</span>
<span class="ltx_bibblock">
Antreas Antoniou, Amos Storkey, and Harrison Edwards.

</span>
<span class="ltx_bibblock">Data Augmentation Generative Adversarial Networks, March 2018.

</span>
<span class="ltx_bibblock">arXiv:1711.04340 [cs, stat].

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aouedi <span id="bib.bib2.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2022]</span>
<span class="ltx_bibblock">
Ons Aouedi, Alessio Sacco, Kandaraj Piamrat, and Guido Marchetto.

</span>
<span class="ltx_bibblock">Handling Privacy-Sensitive Medical Data With Federated Learning: Challenges and Future Directions.

</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text ltx_font_italic">IEEE Journal of Biomedical and Health Informatics</span>, pages 1–14, 2022.

</span>
<span class="ltx_bibblock">Conference Name: IEEE Journal of Biomedical and Health Informatics.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Azizi <span id="bib.bib3.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2023]</span>
<span class="ltx_bibblock">
Shekoofeh Azizi, Simon Kornblith, Chitwan Saharia, Mohammad Norouzi, and David J. Fleet.

</span>
<span class="ltx_bibblock">Synthetic Data from Diffusion Models Improves ImageNet Classification, April 2023.

</span>
<span class="ltx_bibblock">arXiv:2304.08466 [cs].

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carlini <span id="bib.bib4.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2023]</span>
<span class="ltx_bibblock">
Nicholas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag, Florian Tramèr, Borja Balle, Daphne Ippolito, and Eric Wallace.

</span>
<span class="ltx_bibblock">Extracting Training Data from Diffusion Models, January 2023.

</span>
<span class="ltx_bibblock">arXiv:2301.13188 [cs].

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dhariwal and Nichol [2021]</span>
<span class="ltx_bibblock">
Prafulla Dhariwal and Alexander Nichol.

</span>
<span class="ltx_bibblock">Diffusion Models Beat GANs on Image Synthesis.

</span>
<span class="ltx_bibblock">In <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Advances in Neural Information Processing Systems</span>, volume 34, pages 8780–8794. Curran Associates, Inc., 2021.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork and Roth [2013]</span>
<span class="ltx_bibblock">
Cynthia Dwork and Aaron Roth.

</span>
<span class="ltx_bibblock">The Algorithmic Foundations of Differential Privacy.

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">Foundations and Trends® in Theoretical Computer Science</span>, 9(3-4):211–407, 2013.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghalebikesabi <span id="bib.bib7.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2023]</span>
<span class="ltx_bibblock">
Sahra Ghalebikesabi, Leonard Berrada, Sven Gowal, Ira Ktena, Robert Stanforth, Jamie Hayes, Soham De, Samuel L. Smith, Olivia Wiles, and Borja Balle.

</span>
<span class="ltx_bibblock">Differentially Private Diffusion Models Generate Useful Synthetic Images, February 2023.

</span>
<span class="ltx_bibblock">arXiv:2302.13861 [cs, stat].

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Giomi <span id="bib.bib8.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2022]</span>
<span class="ltx_bibblock">
Matteo Giomi, Franziska Boenisch, Christoph Wehmeyer, and Borbála Tasnádi.

</span>
<span class="ltx_bibblock">A Unified Framework for Quantifying Privacy Risk in Synthetic Data, November 2022.

</span>
<span class="ltx_bibblock">arXiv:2211.10459 [cs].

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow <span id="bib.bib9.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2014]</span>
<span class="ltx_bibblock">
Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">Generative Adversarial Networks, June 2014.

</span>
<span class="ltx_bibblock">arXiv:1406.2661 [cs, stat].

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hao <span id="bib.bib10.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Weituo Hao, Mostafa El-Khamy, Jungwon Lee, Jianyi Zhang, Kevin J Liang, Changyou Chen, and Lawrence Carin.

</span>
<span class="ltx_bibblock">Towards Fair Federated Learning with Zero-Shot Data Augmentation.

</span>
<span class="ltx_bibblock">In <span id="bib.bib10.3.1" class="ltx_text ltx_font_italic">2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)</span>, pages 3305–3314, Nashville, TN, USA, June 2021. IEEE.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karimireddy <span id="bib.bib11.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank J. Reddi, Sebastian U. Stich, and Ananda Theertha Suresh.

</span>
<span class="ltx_bibblock">SCAFFOLD: Stochastic Controlled Averaging for Federated Learning, April 2021.

</span>
<span class="ltx_bibblock">arXiv:1910.06378 [cs, math, stat].

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li <span id="bib.bib12.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia Smith.

</span>
<span class="ltx_bibblock">Federated Optimization in Heterogeneous Networks, April 2020.

</span>
<span class="ltx_bibblock">arXiv:1812.06127 [cs, stat].

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li <span id="bib.bib13.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2022]</span>
<span class="ltx_bibblock">
Zijian Li, Jiawei Shao, Yuyi Mao, Jessie Hui Wang, and Jun Zhang.

</span>
<span class="ltx_bibblock">Federated Learning with GAN-based Data Synthesis for Non-IID Clients, June 2022.

</span>
<span class="ltx_bibblock">arXiv:2206.05507 [cs].

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li <span id="bib.bib14.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2024]</span>
<span class="ltx_bibblock">
Kecen Li, Chen Gong, Zhixiang Li, Yuzhong Zhao, Xinwen Hou, and Tianhao Wang.

</span>
<span class="ltx_bibblock">PrivImage: Differentially Private Synthetic Image Generation using Diffusion Models with Semantic-Aware Pretraining, April 2024.

</span>
<span class="ltx_bibblock">arXiv:2311.12850 [cs].

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin <span id="bib.bib15.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2024]</span>
<span class="ltx_bibblock">
Zinan Lin, Sivakanth Gopi, Janardhan Kulkarni, Harsha Nori, and Sergey Yekhanin.

</span>
<span class="ltx_bibblock">Differentially Private Synthetic Data via Foundation Model APIs 1: Images, February 2024.

</span>
<span class="ltx_bibblock">arXiv:2305.15560 [cs].

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan <span id="bib.bib16.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2017]</span>
<span class="ltx_bibblock">
H Brendan McMahan, Eider Moore, Daniel Ramage, and Seth Hampson.

</span>
<span class="ltx_bibblock">Communication-Efﬁcient Learning of Deep Networks from Decentralized Data.

</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text ltx_font_italic">Proceedings of the 20th International Conference on Artificial Intelligence and Statistics (AISTATS)</span>, 2017.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qu <span id="bib.bib17.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Liangqiong Qu, Niranjan Balachandar, and Daniel L. Rubin.

</span>
<span class="ltx_bibblock">An Experimental Study of Data Heterogeneity in Federated Learning Methods for Medical Imaging, July 2021.

</span>
<span class="ltx_bibblock">arXiv:2107.08371 [cs].

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramesh <span id="bib.bib18.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2022]</span>
<span class="ltx_bibblock">
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.

</span>
<span class="ltx_bibblock">Hierarchical Text-Conditional Image Generation with CLIP Latents, April 2022.

</span>
<span class="ltx_bibblock">arXiv:2204.06125 [cs].

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rance and Svoboda [2023]</span>
<span class="ltx_bibblock">
Joseph Rance and Filip Svoboda.

</span>
<span class="ltx_bibblock">Attacks of fairness in Federated Learning, November 2023.

</span>
<span class="ltx_bibblock">arXiv:2311.12715 [cs].

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Razavi-Far <span id="bib.bib20.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2022]</span>
<span class="ltx_bibblock">
Roozbeh Razavi-Far, Ariel Ruiz-Garcia, Vasile Palade, and Juergen Schmidhuber, editors.

</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text ltx_font_italic">Generative Adversarial Learning: Architectures and Applications</span>, volume 217 of <span id="bib.bib20.4.2" class="ltx_text ltx_font_italic">Intelligent Systems Reference Library</span>.

</span>
<span class="ltx_bibblock">Springer International Publishing, Cham, 2022.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shahid <span id="bib.bib21.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Osama Shahid, Seyedamin Pouriyeh, Reza M. Parizi, Quan Z. Sheng, Gautam Srivastava, and Liang Zhao.

</span>
<span class="ltx_bibblock">Communication Efficiency in Federated Learning: Achievements and Challenges, July 2021.

</span>
<span class="ltx_bibblock">arXiv:2107.10996 [cs].

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang <span id="bib.bib22.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2024]</span>
<span class="ltx_bibblock">
Ling Yang, Zhilong Zhang, Yang Song, Shenda Hong, Runsheng Xu, Yue Zhao, Wentao Zhang, Bin Cui, and Ming-Hsuan Yang.

</span>
<span class="ltx_bibblock">Diffusion Models: A Comprehensive Survey of Methods and Applications.

</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text ltx_font_italic">ACM Computing Surveys</span>, 56(4):1–39, April 2024.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang <span id="bib.bib23.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2021]</span>
<span class="ltx_bibblock">
Longling Zhang, Bochen Shen, Ahmed Barnawi, Shan Xi, Neeraj Kumar, and Yi Wu.

</span>
<span class="ltx_bibblock">FedDPGAN: Federated Differentially Private Generative Adversarial Networks Framework for the Detection of COVID-19 Pneumonia, April 2021.

</span>
<span class="ltx_bibblock">arXiv:2104.12581 [cs, eess].

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao <span id="bib.bib24.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2018]</span>
<span class="ltx_bibblock">
Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra.

</span>
<span class="ltx_bibblock">Federated Learning with Non-IID Data.

</span>
<span class="ltx_bibblock">2018.

</span>
<span class="ltx_bibblock">arXiv:1806.00582 [cs, stat].

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou <span id="bib.bib25.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2020]</span>
<span class="ltx_bibblock">
Chunyi Zhou, Anmin Fu, Shui Yu, Wei Yang, Huaqun Wang, and Yuqing Zhang.

</span>
<span class="ltx_bibblock">Privacy-Preserving Federated Learning in Fog Computing.

</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text ltx_font_italic">IEEE Internet of Things Journal</span>, 7(11):10782–10793, November 2020.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou <span id="bib.bib26.2.2.1" class="ltx_text ltx_font_italic">et al.</span> [2023]</span>
<span class="ltx_bibblock">
Ce Zhou, Qian Li, Chen Li, Jun Yu, Yixin Liu, Guangjing Wang, Kai Zhang, Cheng Ji, Qiben Yan, Lifang He, Hao Peng, Jianxin Li, Jia Wu, Ziwei Liu, Pengtao Xie, Caiming Xiong, Jian Pei, Philip S. Yu, and Lichao Sun.

</span>
<span class="ltx_bibblock">A Comprehensive Survey on Pretrained Foundation Models: A History from BERT to ChatGPT, May 2023.

</span>
<span class="ltx_bibblock">arXiv:2302.09419 [cs].

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2407.05173" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2407.05174" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2407.05174">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2407.05174" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2407.05175" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Aug  5 16:19:11 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
