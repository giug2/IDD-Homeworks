<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[1804.02088] Question Type Guided Attention in Visual Question Answering</title><meta property="og:description" content="Visual Question Answering (VQA) requires integration of feature maps with drastically different structures. Image descriptors have structures at multiple spatial scales, while lexical inputs inherently follow a temporaâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Question Type Guided Attention in Visual Question Answering">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Question Type Guided Attention in Visual Question Answering">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/1804.02088">

<!--Generated on Sun Mar 10 14:40:59 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line" lang="en"><span id="id1" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>University of California, Irvine 
<br class="ltx_break"><span id="id1.1" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span>shiy4@uci.edu</span></span></span>
</span></span></span><span id="id2" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">institutetext: </span>University of Southern California 
<br class="ltx_break"><span id="id2.1" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_note_type">email: </span>furlanel@usc.edu</span></span></span>
</span></span></span><span id="id3" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">institutetext: </span>Amazon AI 
<br class="ltx_break"><span id="id3.1" class="ltx_note ltx_role_email"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_note_type">email: </span>{zhasheng},{anima}@amazon.com</span></span></span>
</span></span></span><span id="id4" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_note_type">institutetext: </span>California Institute of Technology</span></span></span>
<h1 class="ltx_title ltx_title_document">Question Type Guided Attention in Visual Question Answering</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yang Shi
</span><span class="ltx_author_notes">Work partially done while the author was working at Amazon AI11</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tommaso Furlanello
</span><span class="ltx_author_notes">22</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sheng Zha
</span><span class="ltx_author_notes">33</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Animashree Anandkumar
</span><span class="ltx_author_notes">3344</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p"><span id="id1.id1.1" class="ltx_text">Visual Question Answering (VQA) requires integration of feature maps with drastically different structures. Image descriptors have structures at multiple spatial scales, while lexical inputs inherently follow a temporal sequence and naturally cluster into semantically different question types. A lot of previous works use complex models to extract feature representations but neglect to use high-level information summary such as question types in learning.
In this work, we propose Question Type-guided Attention (QTA). It utilizes the information of question type to dynamically balance between bottom-up and top-down visual features, respectively extracted from ResNet and Faster R-CNN networks.
We experiment with multiple VQA architectures with extensive input ablation studies over the TDIUC dataset and show that QTA systematically improves the performance by more than 5% across multiple question type categories such as â€œActivity Recognitionâ€, â€œUtilityâ€ and â€œCountingâ€ on TDIUC dataset compared to the state-of-art. By adding QTA on the state-of-art model MCB, we achieve 3% improvement in overall accuracy.
Finally, we propose a multi-task extension to predict question types which generalizes QTA to applications that lack question type, with a minimal performance loss.</span></p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>
<span id="id2.id1" class="ltx_text">Visual question answering, Attention, Question type, Feature selection, Multi-task</span>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The relative maturity and flexibility of deep learning allow to build upon the success of computer visionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>
and natural languageÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>
to face new complex and multimodal tasks. Visual Question Answering(VQA)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> focus on providing a natural language answer given any image and any free-form natural language question.
To achieve this goal, information from multiple modalities must be integrated. Visual and lexical inputs are first processed using specialized encoding modules and then integrated through differentiable operators.
Image features are usually extracted by convolution neural networksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, while recurrent neural networksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> are used to extract question features.
Additionally, attention mechanismÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> forces the system to <em id="S1.p1.1.1" class="ltx_emph ltx_font_italic">look at</em> informative regions in both text and vision. Attention weight is calculated from the correlation between language and vision features and then is multiplied to the original feature.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Previous works explore new features to represent vision and language.
Pre-trained ResNetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> and VGGÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> are commonly used in VQA vision feature extraction. The authors inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> show that post-processing CNN with region-specific image featuresÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> such as Faster R-CNNÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> can lead to an improvement of VQA performance. Along with generating language feature from either sentence-level or word-level using LSTMÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> or word embedding, Lu <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">et al</span>.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> propose to model the question from word-level, phrase-level, and entire question-level in a hierarchical fashion.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Through extensive experimentation and ablation studies, we notice that the role of â€œrawâ€ visual features from ResNet and processed region-specific features from Faster R-CNN is complementary and leads to improvement over different subsets of question types. However, we also notice that trivial information in VQA dataset: question/answer type is omitted in training. Generally, each sample in any VQA dataset contains one image file, one natural language question/answer and sometimes answer type.
A lot of work use the answer type to analyze accuracy per type in resultÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> but neglect to use it during learning. TDIUCÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> is a recently released dataset that contains question type for each sample. Compared to answer type, question type has less variety and is easier to interpret when we only have the question.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The focus of this work is the development of an attention mechanism that exploits high-level semantic information on the question type to guide the visual encoding process. This procedure introduces information leakage between modalities before the classical integration phase that improves the performance on VQA task. Specifically, We introduce a novel VQA architecture <span id="S1.p4.1.1" class="ltx_text ltx_font_bold">Question Type-guided Attention</span>(QTA) that dynamically gates the contribution of ResNet and Faster R-CNN features based on the question type. Our results with QTA allow us to integrate the information from multiple visual sources and obtain gains across all question types. A general VQA network with our QTA is shown in FigureÂ <a href="#S1.F1" title="Figure 1 â€£ 1 Introduction â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/1804.02088/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="302" height="121" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>General VQA network with QTA</figcaption>
</figure>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The contributions of this paper are:(1) We propose question type-guided attention to balance between bottom-up and top-down visual features, which are respectively extracted from ResNet and Faster R-CNN networks. Our results show that QTA systematically improves the performance by more than 5% across multiple question type categories such as â€œActivity Recognitionâ€, â€œUtilityâ€ and â€œCountingâ€ on TDIUC dataset. By adding QTA to the state-of-art model MCB, we achieve 3% improvement in overall accuracy. (2)
We propose a multi-task extension that is trained to predict question types from the lexical inputs during training time that do not require ground truth labels during inference. We get more than 95% accuracy for the question type prediction while keeping the VQA task accuracy almost same as before. (3) Our analysis reveals some problems in the TDIUC VQA dataset. Though the â€œAbsurdâ€ question is intended to help reduce bias, it contains too many similar questions, specifically, questions regarding color. This will mislead the machine to predict wrong question types. Our QTA model gets 17% improvement on simple accuracy compared to the baseline inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> when we exclude absurd questions in training.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Works</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">VQA task is first proposed inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.
It focuses on providing a natural language answer given any image and any free-form natural language question. Collecting data and solving the task are equally challenging as they require the understanding of the joint relation between image and language without any bias.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Datasets</span>
VQA dataset v1 is first released by Antol <span id="S2.p2.1.2" class="ltx_text ltx_font_italic">et al</span>.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. The dataset consists of two subsets: real images and abstract scenes. However, the inherent structure of our world is biased and it results in a biased dataset. In another word, a specific question tends to have the same answer regardless of the image. For example, when people ask about the color of the sky, the answer is most likely blue or black. It is unusual to see the answer be yellow. This is the bottleneck when we give a yellow color sky and ask the machine to answer it. Goyal <span id="S2.p2.1.3" class="ltx_text ltx_font_italic">et al</span>.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> release VQA dataset v2. This dataset pairs the same question with similar images that lead to different answers to reduce the sample bias.
Agrawal <span id="S2.p2.1.4" class="ltx_text ltx_font_italic">et al</span>.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> also noticed that every question type has different prior distributions of answers. Based on that they propose GVQA and new splits of the VQA v1/v2. In the new split, the distribution of answers per question type is different in the test data compared to the training data.
Zhang <span id="S2.p2.1.5" class="ltx_text ltx_font_italic">et al</span>.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite> also propose a method to reduce bias in abstract scenes dataset at question level. By extracting representative word tuples from questions, they can identify and control the balance for each question.
VizwizÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> is another recently released dataset that uses pictures taken by blind people. Some pictures are of poor quality, and the questions are spoken. These data collection methods help reduce bias in the dataset.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Johnson <span id="S2.p3.1.1" class="ltx_text ltx_font_italic">et al</span>.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> introduce Compositional Language and Elementary Visual Reasoning (CLEVR) diagnostic dataset that focuses on reasoning. Strub <span id="S2.p3.1.2" class="ltx_text ltx_font_italic">et al</span>.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> propose a two-player guessing game: guess a target in a given image with a sequence of questions and answers. This requires both visual question reasoning and spatial reasoning.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">The Task Driven Image Understanding Challenge dataset(TDIUC)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> contains a total of over 1.6 million questions in 12 different types. It contains images and annotations from MSCOCOÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> and Visual genomeÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. The key difference between TDIUC and the previous VQA v1/v2 dataset is the categorization of questions: Each question belongs to one of the 12 categories. This allows a task-oriented evaluation such as per question-type accuracies. They also include an â€œAbsurdâ€ question category in which questions are irrelevant to the image contents to help balance the dataset.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p"><span id="S2.p5.1.1" class="ltx_text ltx_font_bold">Feature Selection</span>
VQA requires solving several tasks at once involving both visual and textual input: visual perception, question understanding, and reasoning. Usually, features are extracted respectively with convolutional neural networksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> from the image, and with recurrent neural networksÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> from the text.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">Pre-trained ResNet and VGG are commonly used in VQA vision feature extraction. The authors inÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> show that post-processing CNN with region-specific image featuresÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> can lead to an improvement of VQA performance. Specifically, they use pre-trained Faster R-CNN model to extract image features for VQA task. They won the VQA challenge 2017.</p>
</div>
<div id="S2.p7" class="ltx_para">
<p id="S2.p7.1" class="ltx_p">On the language side, pre-trained word embeddings such as Word2VecÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> are used for text feature extraction. There is a discussion about the sufficiency of language input for VQA task. Agrawal <span id="S2.p7.1.1" class="ltx_text ltx_font_italic">et al</span>.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> have shown that state-of-art VQA models converge to the same answer even if only given half of the question compared to if given the whole sentence.</p>
</div>
<div id="S2.p8" class="ltx_para">
<p id="S2.p8.1" class="ltx_p"><span id="S2.p8.1.1" class="ltx_text ltx_font_bold">Generic Methods</span>
Information of both modalities are used jointly through means of combination, such as concatenation, product or sum. InÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, authors propose a baseline that combines LSTM embedding of the question and CNN embedding of the image via a point-wise multiplication followed by a multi-layer perceptron classifier.</p>
</div>
<div id="S2.p9" class="ltx_para">
<p id="S2.p9.3" class="ltx_p"><span id="S2.p9.3.1" class="ltx_text ltx_font_bold">Pooling Methods</span>
Pooling methods are widely used in visual tasks to combine information for various streams into one final feature representation. Common pooling methods such as average pooling and max pooling bring the property of translation invariance and robustness to elastic distortions at the cost of spatial locality. Bilinear pooling can preserve spatial information, which is performed with the outer product between two feature maps. However, this operation entails high output dimension(<math id="S2.p9.1.m1.1" class="ltx_Math" alttext="O(MN)" display="inline"><semantics id="S2.p9.1.m1.1a"><mrow id="S2.p9.1.m1.1.1" xref="S2.p9.1.m1.1.1.cmml"><mi id="S2.p9.1.m1.1.1.3" xref="S2.p9.1.m1.1.1.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S2.p9.1.m1.1.1.2" xref="S2.p9.1.m1.1.1.2.cmml">â€‹</mo><mrow id="S2.p9.1.m1.1.1.1.1" xref="S2.p9.1.m1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.p9.1.m1.1.1.1.1.2" xref="S2.p9.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S2.p9.1.m1.1.1.1.1.1" xref="S2.p9.1.m1.1.1.1.1.1.cmml"><mi id="S2.p9.1.m1.1.1.1.1.1.2" xref="S2.p9.1.m1.1.1.1.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.p9.1.m1.1.1.1.1.1.1" xref="S2.p9.1.m1.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S2.p9.1.m1.1.1.1.1.1.3" xref="S2.p9.1.m1.1.1.1.1.1.3.cmml">N</mi></mrow><mo stretchy="false" id="S2.p9.1.m1.1.1.1.1.3" xref="S2.p9.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p9.1.m1.1b"><apply id="S2.p9.1.m1.1.1.cmml" xref="S2.p9.1.m1.1.1"><times id="S2.p9.1.m1.1.1.2.cmml" xref="S2.p9.1.m1.1.1.2"></times><ci id="S2.p9.1.m1.1.1.3.cmml" xref="S2.p9.1.m1.1.1.3">ğ‘‚</ci><apply id="S2.p9.1.m1.1.1.1.1.1.cmml" xref="S2.p9.1.m1.1.1.1.1"><times id="S2.p9.1.m1.1.1.1.1.1.1.cmml" xref="S2.p9.1.m1.1.1.1.1.1.1"></times><ci id="S2.p9.1.m1.1.1.1.1.1.2.cmml" xref="S2.p9.1.m1.1.1.1.1.1.2">ğ‘€</ci><ci id="S2.p9.1.m1.1.1.1.1.1.3.cmml" xref="S2.p9.1.m1.1.1.1.1.1.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p9.1.m1.1c">O(MN)</annotation></semantics></math> for feature maps of dimension <math id="S2.p9.2.m2.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.p9.2.m2.1a"><mi id="S2.p9.2.m2.1.1" xref="S2.p9.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.p9.2.m2.1b"><ci id="S2.p9.2.m2.1.1.cmml" xref="S2.p9.2.m2.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p9.2.m2.1c">M</annotation></semantics></math> and <math id="S2.p9.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.p9.3.m3.1a"><mi id="S2.p9.3.m3.1.1" xref="S2.p9.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.p9.3.m3.1b"><ci id="S2.p9.3.m3.1.1.cmml" xref="S2.p9.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p9.3.m3.1c">N</annotation></semantics></math>). This exponential growth with respect to the number of feature maps renders it too costly to be applied to huge real image datasets. There have been several proposals for new pooling techniques to address this problem:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.6" class="ltx_p">Count sketchÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> is applied as a feature hashing operator to avoid dimension expanding in bilinear pooling.
Given a vector <math id="S2.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="a\in\mathcal{R}^{n}" display="inline"><semantics id="S2.I1.i1.p1.1.m1.1a"><mrow id="S2.I1.i1.p1.1.m1.1.1" xref="S2.I1.i1.p1.1.m1.1.1.cmml"><mi id="S2.I1.i1.p1.1.m1.1.1.2" xref="S2.I1.i1.p1.1.m1.1.1.2.cmml">a</mi><mo id="S2.I1.i1.p1.1.m1.1.1.1" xref="S2.I1.i1.p1.1.m1.1.1.1.cmml">âˆˆ</mo><msup id="S2.I1.i1.p1.1.m1.1.1.3" xref="S2.I1.i1.p1.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I1.i1.p1.1.m1.1.1.3.2" xref="S2.I1.i1.p1.1.m1.1.1.3.2.cmml">â„›</mi><mi id="S2.I1.i1.p1.1.m1.1.1.3.3" xref="S2.I1.i1.p1.1.m1.1.1.3.3.cmml">n</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.1.m1.1b"><apply id="S2.I1.i1.p1.1.m1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1"><in id="S2.I1.i1.p1.1.m1.1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1.1"></in><ci id="S2.I1.i1.p1.1.m1.1.1.2.cmml" xref="S2.I1.i1.p1.1.m1.1.1.2">ğ‘</ci><apply id="S2.I1.i1.p1.1.m1.1.1.3.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.I1.i1.p1.1.m1.1.1.3.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3">superscript</csymbol><ci id="S2.I1.i1.p1.1.m1.1.1.3.2.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.2">â„›</ci><ci id="S2.I1.i1.p1.1.m1.1.1.3.3.cmml" xref="S2.I1.i1.p1.1.m1.1.1.3.3">ğ‘›</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.1.m1.1c">a\in\mathcal{R}^{n}</annotation></semantics></math>,
random hash function <math id="S2.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="f\in\mathcal{R}^{n}" display="inline"><semantics id="S2.I1.i1.p1.2.m2.1a"><mrow id="S2.I1.i1.p1.2.m2.1.1" xref="S2.I1.i1.p1.2.m2.1.1.cmml"><mi id="S2.I1.i1.p1.2.m2.1.1.2" xref="S2.I1.i1.p1.2.m2.1.1.2.cmml">f</mi><mo id="S2.I1.i1.p1.2.m2.1.1.1" xref="S2.I1.i1.p1.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S2.I1.i1.p1.2.m2.1.1.3" xref="S2.I1.i1.p1.2.m2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I1.i1.p1.2.m2.1.1.3.2" xref="S2.I1.i1.p1.2.m2.1.1.3.2.cmml">â„›</mi><mi id="S2.I1.i1.p1.2.m2.1.1.3.3" xref="S2.I1.i1.p1.2.m2.1.1.3.3.cmml">n</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.2.m2.1b"><apply id="S2.I1.i1.p1.2.m2.1.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1"><in id="S2.I1.i1.p1.2.m2.1.1.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1.1"></in><ci id="S2.I1.i1.p1.2.m2.1.1.2.cmml" xref="S2.I1.i1.p1.2.m2.1.1.2">ğ‘“</ci><apply id="S2.I1.i1.p1.2.m2.1.1.3.cmml" xref="S2.I1.i1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S2.I1.i1.p1.2.m2.1.1.3.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1.3">superscript</csymbol><ci id="S2.I1.i1.p1.2.m2.1.1.3.2.cmml" xref="S2.I1.i1.p1.2.m2.1.1.3.2">â„›</ci><ci id="S2.I1.i1.p1.2.m2.1.1.3.3.cmml" xref="S2.I1.i1.p1.2.m2.1.1.3.3">ğ‘›</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.2.m2.1c">f\in\mathcal{R}^{n}</annotation></semantics></math>: <math id="S2.I1.i1.p1.3.m3.2" class="ltx_Math" alttext="[n]\to[b]" display="inline"><semantics id="S2.I1.i1.p1.3.m3.2a"><mrow id="S2.I1.i1.p1.3.m3.2.3" xref="S2.I1.i1.p1.3.m3.2.3.cmml"><mrow id="S2.I1.i1.p1.3.m3.2.3.2.2" xref="S2.I1.i1.p1.3.m3.2.3.2.1.cmml"><mo stretchy="false" id="S2.I1.i1.p1.3.m3.2.3.2.2.1" xref="S2.I1.i1.p1.3.m3.2.3.2.1.1.cmml">[</mo><mi id="S2.I1.i1.p1.3.m3.1.1" xref="S2.I1.i1.p1.3.m3.1.1.cmml">n</mi><mo stretchy="false" id="S2.I1.i1.p1.3.m3.2.3.2.2.2" xref="S2.I1.i1.p1.3.m3.2.3.2.1.1.cmml">]</mo></mrow><mo stretchy="false" id="S2.I1.i1.p1.3.m3.2.3.1" xref="S2.I1.i1.p1.3.m3.2.3.1.cmml">â†’</mo><mrow id="S2.I1.i1.p1.3.m3.2.3.3.2" xref="S2.I1.i1.p1.3.m3.2.3.3.1.cmml"><mo stretchy="false" id="S2.I1.i1.p1.3.m3.2.3.3.2.1" xref="S2.I1.i1.p1.3.m3.2.3.3.1.1.cmml">[</mo><mi id="S2.I1.i1.p1.3.m3.2.2" xref="S2.I1.i1.p1.3.m3.2.2.cmml">b</mi><mo stretchy="false" id="S2.I1.i1.p1.3.m3.2.3.3.2.2" xref="S2.I1.i1.p1.3.m3.2.3.3.1.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.3.m3.2b"><apply id="S2.I1.i1.p1.3.m3.2.3.cmml" xref="S2.I1.i1.p1.3.m3.2.3"><ci id="S2.I1.i1.p1.3.m3.2.3.1.cmml" xref="S2.I1.i1.p1.3.m3.2.3.1">â†’</ci><apply id="S2.I1.i1.p1.3.m3.2.3.2.1.cmml" xref="S2.I1.i1.p1.3.m3.2.3.2.2"><csymbol cd="latexml" id="S2.I1.i1.p1.3.m3.2.3.2.1.1.cmml" xref="S2.I1.i1.p1.3.m3.2.3.2.2.1">delimited-[]</csymbol><ci id="S2.I1.i1.p1.3.m3.1.1.cmml" xref="S2.I1.i1.p1.3.m3.1.1">ğ‘›</ci></apply><apply id="S2.I1.i1.p1.3.m3.2.3.3.1.cmml" xref="S2.I1.i1.p1.3.m3.2.3.3.2"><csymbol cd="latexml" id="S2.I1.i1.p1.3.m3.2.3.3.1.1.cmml" xref="S2.I1.i1.p1.3.m3.2.3.3.2.1">delimited-[]</csymbol><ci id="S2.I1.i1.p1.3.m3.2.2.cmml" xref="S2.I1.i1.p1.3.m3.2.2">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.3.m3.2c">[n]\to[b]</annotation></semantics></math> and binary variable <math id="S2.I1.i1.p1.4.m4.1" class="ltx_Math" alttext="s\in\mathcal{R}^{n}" display="inline"><semantics id="S2.I1.i1.p1.4.m4.1a"><mrow id="S2.I1.i1.p1.4.m4.1.1" xref="S2.I1.i1.p1.4.m4.1.1.cmml"><mi id="S2.I1.i1.p1.4.m4.1.1.2" xref="S2.I1.i1.p1.4.m4.1.1.2.cmml">s</mi><mo id="S2.I1.i1.p1.4.m4.1.1.1" xref="S2.I1.i1.p1.4.m4.1.1.1.cmml">âˆˆ</mo><msup id="S2.I1.i1.p1.4.m4.1.1.3" xref="S2.I1.i1.p1.4.m4.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I1.i1.p1.4.m4.1.1.3.2" xref="S2.I1.i1.p1.4.m4.1.1.3.2.cmml">â„›</mi><mi id="S2.I1.i1.p1.4.m4.1.1.3.3" xref="S2.I1.i1.p1.4.m4.1.1.3.3.cmml">n</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.4.m4.1b"><apply id="S2.I1.i1.p1.4.m4.1.1.cmml" xref="S2.I1.i1.p1.4.m4.1.1"><in id="S2.I1.i1.p1.4.m4.1.1.1.cmml" xref="S2.I1.i1.p1.4.m4.1.1.1"></in><ci id="S2.I1.i1.p1.4.m4.1.1.2.cmml" xref="S2.I1.i1.p1.4.m4.1.1.2">ğ‘ </ci><apply id="S2.I1.i1.p1.4.m4.1.1.3.cmml" xref="S2.I1.i1.p1.4.m4.1.1.3"><csymbol cd="ambiguous" id="S2.I1.i1.p1.4.m4.1.1.3.1.cmml" xref="S2.I1.i1.p1.4.m4.1.1.3">superscript</csymbol><ci id="S2.I1.i1.p1.4.m4.1.1.3.2.cmml" xref="S2.I1.i1.p1.4.m4.1.1.3.2">â„›</ci><ci id="S2.I1.i1.p1.4.m4.1.1.3.3.cmml" xref="S2.I1.i1.p1.4.m4.1.1.3.3">ğ‘›</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.4.m4.1c">s\in\mathcal{R}^{n}</annotation></semantics></math>: <math id="S2.I1.i1.p1.5.m5.1" class="ltx_Math" alttext="[n]\to\pm 1" display="inline"><semantics id="S2.I1.i1.p1.5.m5.1a"><mrow id="S2.I1.i1.p1.5.m5.1.2" xref="S2.I1.i1.p1.5.m5.1.2.cmml"><mrow id="S2.I1.i1.p1.5.m5.1.2.2.2" xref="S2.I1.i1.p1.5.m5.1.2.2.1.cmml"><mo stretchy="false" id="S2.I1.i1.p1.5.m5.1.2.2.2.1" xref="S2.I1.i1.p1.5.m5.1.2.2.1.1.cmml">[</mo><mi id="S2.I1.i1.p1.5.m5.1.1" xref="S2.I1.i1.p1.5.m5.1.1.cmml">n</mi><mo stretchy="false" id="S2.I1.i1.p1.5.m5.1.2.2.2.2" xref="S2.I1.i1.p1.5.m5.1.2.2.1.1.cmml">]</mo></mrow><mo stretchy="false" id="S2.I1.i1.p1.5.m5.1.2.1" xref="S2.I1.i1.p1.5.m5.1.2.1.cmml">â†’</mo><mrow id="S2.I1.i1.p1.5.m5.1.2.3" xref="S2.I1.i1.p1.5.m5.1.2.3.cmml"><mo id="S2.I1.i1.p1.5.m5.1.2.3a" xref="S2.I1.i1.p1.5.m5.1.2.3.cmml">Â±</mo><mn id="S2.I1.i1.p1.5.m5.1.2.3.2" xref="S2.I1.i1.p1.5.m5.1.2.3.2.cmml">1</mn></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.5.m5.1b"><apply id="S2.I1.i1.p1.5.m5.1.2.cmml" xref="S2.I1.i1.p1.5.m5.1.2"><ci id="S2.I1.i1.p1.5.m5.1.2.1.cmml" xref="S2.I1.i1.p1.5.m5.1.2.1">â†’</ci><apply id="S2.I1.i1.p1.5.m5.1.2.2.1.cmml" xref="S2.I1.i1.p1.5.m5.1.2.2.2"><csymbol cd="latexml" id="S2.I1.i1.p1.5.m5.1.2.2.1.1.cmml" xref="S2.I1.i1.p1.5.m5.1.2.2.2.1">delimited-[]</csymbol><ci id="S2.I1.i1.p1.5.m5.1.1.cmml" xref="S2.I1.i1.p1.5.m5.1.1">ğ‘›</ci></apply><apply id="S2.I1.i1.p1.5.m5.1.2.3.cmml" xref="S2.I1.i1.p1.5.m5.1.2.3"><csymbol cd="latexml" id="S2.I1.i1.p1.5.m5.1.2.3.1.cmml" xref="S2.I1.i1.p1.5.m5.1.2.3">plus-or-minus</csymbol><cn type="integer" id="S2.I1.i1.p1.5.m5.1.2.3.2.cmml" xref="S2.I1.i1.p1.5.m5.1.2.3.2">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.5.m5.1c">[n]\to\pm 1</annotation></semantics></math>, the <span id="S2.I1.i1.p1.6.1" class="ltx_text ltx_font_bold">count sketch</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> operator <math id="S2.I1.i1.p1.6.m6.3" class="ltx_Math" alttext="cs(a,h,s)\in\mathcal{R}^{b}" display="inline"><semantics id="S2.I1.i1.p1.6.m6.3a"><mrow id="S2.I1.i1.p1.6.m6.3.4" xref="S2.I1.i1.p1.6.m6.3.4.cmml"><mrow id="S2.I1.i1.p1.6.m6.3.4.2" xref="S2.I1.i1.p1.6.m6.3.4.2.cmml"><mi id="S2.I1.i1.p1.6.m6.3.4.2.2" xref="S2.I1.i1.p1.6.m6.3.4.2.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.6.m6.3.4.2.1" xref="S2.I1.i1.p1.6.m6.3.4.2.1.cmml">â€‹</mo><mi id="S2.I1.i1.p1.6.m6.3.4.2.3" xref="S2.I1.i1.p1.6.m6.3.4.2.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.6.m6.3.4.2.1a" xref="S2.I1.i1.p1.6.m6.3.4.2.1.cmml">â€‹</mo><mrow id="S2.I1.i1.p1.6.m6.3.4.2.4.2" xref="S2.I1.i1.p1.6.m6.3.4.2.4.1.cmml"><mo stretchy="false" id="S2.I1.i1.p1.6.m6.3.4.2.4.2.1" xref="S2.I1.i1.p1.6.m6.3.4.2.4.1.cmml">(</mo><mi id="S2.I1.i1.p1.6.m6.1.1" xref="S2.I1.i1.p1.6.m6.1.1.cmml">a</mi><mo id="S2.I1.i1.p1.6.m6.3.4.2.4.2.2" xref="S2.I1.i1.p1.6.m6.3.4.2.4.1.cmml">,</mo><mi id="S2.I1.i1.p1.6.m6.2.2" xref="S2.I1.i1.p1.6.m6.2.2.cmml">h</mi><mo id="S2.I1.i1.p1.6.m6.3.4.2.4.2.3" xref="S2.I1.i1.p1.6.m6.3.4.2.4.1.cmml">,</mo><mi id="S2.I1.i1.p1.6.m6.3.3" xref="S2.I1.i1.p1.6.m6.3.3.cmml">s</mi><mo stretchy="false" id="S2.I1.i1.p1.6.m6.3.4.2.4.2.4" xref="S2.I1.i1.p1.6.m6.3.4.2.4.1.cmml">)</mo></mrow></mrow><mo id="S2.I1.i1.p1.6.m6.3.4.1" xref="S2.I1.i1.p1.6.m6.3.4.1.cmml">âˆˆ</mo><msup id="S2.I1.i1.p1.6.m6.3.4.3" xref="S2.I1.i1.p1.6.m6.3.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I1.i1.p1.6.m6.3.4.3.2" xref="S2.I1.i1.p1.6.m6.3.4.3.2.cmml">â„›</mi><mi id="S2.I1.i1.p1.6.m6.3.4.3.3" xref="S2.I1.i1.p1.6.m6.3.4.3.3.cmml">b</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.6.m6.3b"><apply id="S2.I1.i1.p1.6.m6.3.4.cmml" xref="S2.I1.i1.p1.6.m6.3.4"><in id="S2.I1.i1.p1.6.m6.3.4.1.cmml" xref="S2.I1.i1.p1.6.m6.3.4.1"></in><apply id="S2.I1.i1.p1.6.m6.3.4.2.cmml" xref="S2.I1.i1.p1.6.m6.3.4.2"><times id="S2.I1.i1.p1.6.m6.3.4.2.1.cmml" xref="S2.I1.i1.p1.6.m6.3.4.2.1"></times><ci id="S2.I1.i1.p1.6.m6.3.4.2.2.cmml" xref="S2.I1.i1.p1.6.m6.3.4.2.2">ğ‘</ci><ci id="S2.I1.i1.p1.6.m6.3.4.2.3.cmml" xref="S2.I1.i1.p1.6.m6.3.4.2.3">ğ‘ </ci><vector id="S2.I1.i1.p1.6.m6.3.4.2.4.1.cmml" xref="S2.I1.i1.p1.6.m6.3.4.2.4.2"><ci id="S2.I1.i1.p1.6.m6.1.1.cmml" xref="S2.I1.i1.p1.6.m6.1.1">ğ‘</ci><ci id="S2.I1.i1.p1.6.m6.2.2.cmml" xref="S2.I1.i1.p1.6.m6.2.2">â„</ci><ci id="S2.I1.i1.p1.6.m6.3.3.cmml" xref="S2.I1.i1.p1.6.m6.3.3">ğ‘ </ci></vector></apply><apply id="S2.I1.i1.p1.6.m6.3.4.3.cmml" xref="S2.I1.i1.p1.6.m6.3.4.3"><csymbol cd="ambiguous" id="S2.I1.i1.p1.6.m6.3.4.3.1.cmml" xref="S2.I1.i1.p1.6.m6.3.4.3">superscript</csymbol><ci id="S2.I1.i1.p1.6.m6.3.4.3.2.cmml" xref="S2.I1.i1.p1.6.m6.3.4.3.2">â„›</ci><ci id="S2.I1.i1.p1.6.m6.3.4.3.3.cmml" xref="S2.I1.i1.p1.6.m6.3.4.3.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.6.m6.3c">cs(a,h,s)\in\mathcal{R}^{b}</annotation></semantics></math> is:</p>
<table id="S6.EGx1" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.E1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.E1.m1.12" class="ltx_Math" alttext="\displaystyle cs(a,f,s)[j]=\sum_{f[i]=j}s[i]a[i],\quad j\in{1,\cdots,b}" display="inline"><semantics id="S2.E1.m1.12a"><mrow id="S2.E1.m1.12.12.2" xref="S2.E1.m1.12.12.3.cmml"><mrow id="S2.E1.m1.11.11.1.1" xref="S2.E1.m1.11.11.1.1.cmml"><mrow id="S2.E1.m1.11.11.1.1.2" xref="S2.E1.m1.11.11.1.1.2.cmml"><mi id="S2.E1.m1.11.11.1.1.2.2" xref="S2.E1.m1.11.11.1.1.2.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.11.11.1.1.2.1" xref="S2.E1.m1.11.11.1.1.2.1.cmml">â€‹</mo><mi id="S2.E1.m1.11.11.1.1.2.3" xref="S2.E1.m1.11.11.1.1.2.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.11.11.1.1.2.1a" xref="S2.E1.m1.11.11.1.1.2.1.cmml">â€‹</mo><mrow id="S2.E1.m1.11.11.1.1.2.4.2" xref="S2.E1.m1.11.11.1.1.2.4.1.cmml"><mo stretchy="false" id="S2.E1.m1.11.11.1.1.2.4.2.1" xref="S2.E1.m1.11.11.1.1.2.4.1.cmml">(</mo><mi id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml">a</mi><mo id="S2.E1.m1.11.11.1.1.2.4.2.2" xref="S2.E1.m1.11.11.1.1.2.4.1.cmml">,</mo><mi id="S2.E1.m1.3.3" xref="S2.E1.m1.3.3.cmml">f</mi><mo id="S2.E1.m1.11.11.1.1.2.4.2.3" xref="S2.E1.m1.11.11.1.1.2.4.1.cmml">,</mo><mi id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml">s</mi><mo stretchy="false" id="S2.E1.m1.11.11.1.1.2.4.2.4" xref="S2.E1.m1.11.11.1.1.2.4.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.11.11.1.1.2.1b" xref="S2.E1.m1.11.11.1.1.2.1.cmml">â€‹</mo><mrow id="S2.E1.m1.11.11.1.1.2.5.2" xref="S2.E1.m1.11.11.1.1.2.5.1.cmml"><mo stretchy="false" id="S2.E1.m1.11.11.1.1.2.5.2.1" xref="S2.E1.m1.11.11.1.1.2.5.1.1.cmml">[</mo><mi id="S2.E1.m1.5.5" xref="S2.E1.m1.5.5.cmml">j</mi><mo stretchy="false" id="S2.E1.m1.11.11.1.1.2.5.2.2" xref="S2.E1.m1.11.11.1.1.2.5.1.1.cmml">]</mo></mrow></mrow><mo id="S2.E1.m1.11.11.1.1.1" xref="S2.E1.m1.11.11.1.1.1.cmml">=</mo><mrow id="S2.E1.m1.11.11.1.1.3" xref="S2.E1.m1.11.11.1.1.3.cmml"><mstyle displaystyle="true" id="S2.E1.m1.11.11.1.1.3.1" xref="S2.E1.m1.11.11.1.1.3.1.cmml"><munder id="S2.E1.m1.11.11.1.1.3.1a" xref="S2.E1.m1.11.11.1.1.3.1.cmml"><mo movablelimits="false" id="S2.E1.m1.11.11.1.1.3.1.2" xref="S2.E1.m1.11.11.1.1.3.1.2.cmml">âˆ‘</mo><mrow id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.3" xref="S2.E1.m1.1.1.1.3.cmml"><mi id="S2.E1.m1.1.1.1.3.2" xref="S2.E1.m1.1.1.1.3.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.3.1" xref="S2.E1.m1.1.1.1.3.1.cmml">â€‹</mo><mrow id="S2.E1.m1.1.1.1.3.3.2" xref="S2.E1.m1.1.1.1.3.3.1.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.1.3.3.2.1" xref="S2.E1.m1.1.1.1.3.3.1.1.cmml">[</mo><mi id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml">i</mi><mo stretchy="false" id="S2.E1.m1.1.1.1.3.3.2.2" xref="S2.E1.m1.1.1.1.3.3.1.1.cmml">]</mo></mrow></mrow><mo id="S2.E1.m1.1.1.1.2" xref="S2.E1.m1.1.1.1.2.cmml">=</mo><mi id="S2.E1.m1.1.1.1.4" xref="S2.E1.m1.1.1.1.4.cmml">j</mi></mrow></munder></mstyle><mrow id="S2.E1.m1.11.11.1.1.3.2" xref="S2.E1.m1.11.11.1.1.3.2.cmml"><mi id="S2.E1.m1.11.11.1.1.3.2.2" xref="S2.E1.m1.11.11.1.1.3.2.2.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.11.11.1.1.3.2.1" xref="S2.E1.m1.11.11.1.1.3.2.1.cmml">â€‹</mo><mrow id="S2.E1.m1.11.11.1.1.3.2.3.2" xref="S2.E1.m1.11.11.1.1.3.2.3.1.cmml"><mo stretchy="false" id="S2.E1.m1.11.11.1.1.3.2.3.2.1" xref="S2.E1.m1.11.11.1.1.3.2.3.1.1.cmml">[</mo><mi id="S2.E1.m1.6.6" xref="S2.E1.m1.6.6.cmml">i</mi><mo stretchy="false" id="S2.E1.m1.11.11.1.1.3.2.3.2.2" xref="S2.E1.m1.11.11.1.1.3.2.3.1.1.cmml">]</mo></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.11.11.1.1.3.2.1a" xref="S2.E1.m1.11.11.1.1.3.2.1.cmml">â€‹</mo><mi id="S2.E1.m1.11.11.1.1.3.2.4" xref="S2.E1.m1.11.11.1.1.3.2.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.11.11.1.1.3.2.1b" xref="S2.E1.m1.11.11.1.1.3.2.1.cmml">â€‹</mo><mrow id="S2.E1.m1.11.11.1.1.3.2.5.2" xref="S2.E1.m1.11.11.1.1.3.2.5.1.cmml"><mo stretchy="false" id="S2.E1.m1.11.11.1.1.3.2.5.2.1" xref="S2.E1.m1.11.11.1.1.3.2.5.1.1.cmml">[</mo><mi id="S2.E1.m1.7.7" xref="S2.E1.m1.7.7.cmml">i</mi><mo stretchy="false" id="S2.E1.m1.11.11.1.1.3.2.5.2.2" xref="S2.E1.m1.11.11.1.1.3.2.5.1.1.cmml">]</mo></mrow></mrow></mrow></mrow><mo rspace="1.167em" id="S2.E1.m1.12.12.2.3" xref="S2.E1.m1.12.12.3a.cmml">,</mo><mrow id="S2.E1.m1.12.12.2.2" xref="S2.E1.m1.12.12.2.2.cmml"><mi id="S2.E1.m1.12.12.2.2.2" xref="S2.E1.m1.12.12.2.2.2.cmml">j</mi><mo id="S2.E1.m1.12.12.2.2.1" xref="S2.E1.m1.12.12.2.2.1.cmml">âˆˆ</mo><mrow id="S2.E1.m1.12.12.2.2.3.2" xref="S2.E1.m1.12.12.2.2.3.1.cmml"><mn id="S2.E1.m1.8.8" xref="S2.E1.m1.8.8.cmml">1</mn><mo id="S2.E1.m1.12.12.2.2.3.2.1" xref="S2.E1.m1.12.12.2.2.3.1.cmml">,</mo><mi mathvariant="normal" id="S2.E1.m1.9.9" xref="S2.E1.m1.9.9.cmml">â‹¯</mi><mo id="S2.E1.m1.12.12.2.2.3.2.2" xref="S2.E1.m1.12.12.2.2.3.1.cmml">,</mo><mi id="S2.E1.m1.10.10" xref="S2.E1.m1.10.10.cmml">b</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.12b"><apply id="S2.E1.m1.12.12.3.cmml" xref="S2.E1.m1.12.12.2"><csymbol cd="ambiguous" id="S2.E1.m1.12.12.3a.cmml" xref="S2.E1.m1.12.12.2.3">formulae-sequence</csymbol><apply id="S2.E1.m1.11.11.1.1.cmml" xref="S2.E1.m1.11.11.1.1"><eq id="S2.E1.m1.11.11.1.1.1.cmml" xref="S2.E1.m1.11.11.1.1.1"></eq><apply id="S2.E1.m1.11.11.1.1.2.cmml" xref="S2.E1.m1.11.11.1.1.2"><times id="S2.E1.m1.11.11.1.1.2.1.cmml" xref="S2.E1.m1.11.11.1.1.2.1"></times><ci id="S2.E1.m1.11.11.1.1.2.2.cmml" xref="S2.E1.m1.11.11.1.1.2.2">ğ‘</ci><ci id="S2.E1.m1.11.11.1.1.2.3.cmml" xref="S2.E1.m1.11.11.1.1.2.3">ğ‘ </ci><vector id="S2.E1.m1.11.11.1.1.2.4.1.cmml" xref="S2.E1.m1.11.11.1.1.2.4.2"><ci id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2">ğ‘</ci><ci id="S2.E1.m1.3.3.cmml" xref="S2.E1.m1.3.3">ğ‘“</ci><ci id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4">ğ‘ </ci></vector><apply id="S2.E1.m1.11.11.1.1.2.5.1.cmml" xref="S2.E1.m1.11.11.1.1.2.5.2"><csymbol cd="latexml" id="S2.E1.m1.11.11.1.1.2.5.1.1.cmml" xref="S2.E1.m1.11.11.1.1.2.5.2.1">delimited-[]</csymbol><ci id="S2.E1.m1.5.5.cmml" xref="S2.E1.m1.5.5">ğ‘—</ci></apply></apply><apply id="S2.E1.m1.11.11.1.1.3.cmml" xref="S2.E1.m1.11.11.1.1.3"><apply id="S2.E1.m1.11.11.1.1.3.1.cmml" xref="S2.E1.m1.11.11.1.1.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.11.11.1.1.3.1.1.cmml" xref="S2.E1.m1.11.11.1.1.3.1">subscript</csymbol><sum id="S2.E1.m1.11.11.1.1.3.1.2.cmml" xref="S2.E1.m1.11.11.1.1.3.1.2"></sum><apply id="S2.E1.m1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"><eq id="S2.E1.m1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.2"></eq><apply id="S2.E1.m1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.3"><times id="S2.E1.m1.1.1.1.3.1.cmml" xref="S2.E1.m1.1.1.1.3.1"></times><ci id="S2.E1.m1.1.1.1.3.2.cmml" xref="S2.E1.m1.1.1.1.3.2">ğ‘“</ci><apply id="S2.E1.m1.1.1.1.3.3.1.cmml" xref="S2.E1.m1.1.1.1.3.3.2"><csymbol cd="latexml" id="S2.E1.m1.1.1.1.3.3.1.1.cmml" xref="S2.E1.m1.1.1.1.3.3.2.1">delimited-[]</csymbol><ci id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1">ğ‘–</ci></apply></apply><ci id="S2.E1.m1.1.1.1.4.cmml" xref="S2.E1.m1.1.1.1.4">ğ‘—</ci></apply></apply><apply id="S2.E1.m1.11.11.1.1.3.2.cmml" xref="S2.E1.m1.11.11.1.1.3.2"><times id="S2.E1.m1.11.11.1.1.3.2.1.cmml" xref="S2.E1.m1.11.11.1.1.3.2.1"></times><ci id="S2.E1.m1.11.11.1.1.3.2.2.cmml" xref="S2.E1.m1.11.11.1.1.3.2.2">ğ‘ </ci><apply id="S2.E1.m1.11.11.1.1.3.2.3.1.cmml" xref="S2.E1.m1.11.11.1.1.3.2.3.2"><csymbol cd="latexml" id="S2.E1.m1.11.11.1.1.3.2.3.1.1.cmml" xref="S2.E1.m1.11.11.1.1.3.2.3.2.1">delimited-[]</csymbol><ci id="S2.E1.m1.6.6.cmml" xref="S2.E1.m1.6.6">ğ‘–</ci></apply><ci id="S2.E1.m1.11.11.1.1.3.2.4.cmml" xref="S2.E1.m1.11.11.1.1.3.2.4">ğ‘</ci><apply id="S2.E1.m1.11.11.1.1.3.2.5.1.cmml" xref="S2.E1.m1.11.11.1.1.3.2.5.2"><csymbol cd="latexml" id="S2.E1.m1.11.11.1.1.3.2.5.1.1.cmml" xref="S2.E1.m1.11.11.1.1.3.2.5.2.1">delimited-[]</csymbol><ci id="S2.E1.m1.7.7.cmml" xref="S2.E1.m1.7.7">ğ‘–</ci></apply></apply></apply></apply><apply id="S2.E1.m1.12.12.2.2.cmml" xref="S2.E1.m1.12.12.2.2"><in id="S2.E1.m1.12.12.2.2.1.cmml" xref="S2.E1.m1.12.12.2.2.1"></in><ci id="S2.E1.m1.12.12.2.2.2.cmml" xref="S2.E1.m1.12.12.2.2.2">ğ‘—</ci><list id="S2.E1.m1.12.12.2.2.3.1.cmml" xref="S2.E1.m1.12.12.2.2.3.2"><cn type="integer" id="S2.E1.m1.8.8.cmml" xref="S2.E1.m1.8.8">1</cn><ci id="S2.E1.m1.9.9.cmml" xref="S2.E1.m1.9.9">â‹¯</ci><ci id="S2.E1.m1.10.10.cmml" xref="S2.E1.m1.10.10">ğ‘</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.12c">\displaystyle cs(a,f,s)[j]=\sum_{f[i]=j}s[i]a[i],\quad j\in{1,\cdots,b}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.I1.i1.p1.9" class="ltx_p">Gao <span id="S2.I1.i1.p1.9.1" class="ltx_text ltx_font_italic">et al</span>.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> use convolution layers from two different neural networks as the local descriptor extractors of the image and combine them using count sketch. â€œ<math id="S2.I1.i1.p1.7.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.I1.i1.p1.7.m1.1a"><mi id="S2.I1.i1.p1.7.m1.1.1" xref="S2.I1.i1.p1.7.m1.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.7.m1.1b"><ci id="S2.I1.i1.p1.7.m1.1.1.cmml" xref="S2.I1.i1.p1.7.m1.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.7.m1.1c">\alpha</annotation></semantics></math>-poolingâ€Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> allows the network to learn the pooling strategy: a continuous transition between linear and polynomial pooling. They show that higher <math id="S2.I1.i1.p1.8.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.I1.i1.p1.8.m2.1a"><mi id="S2.I1.i1.p1.8.m2.1.1" xref="S2.I1.i1.p1.8.m2.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.8.m2.1b"><ci id="S2.I1.i1.p1.8.m2.1.1.cmml" xref="S2.I1.i1.p1.8.m2.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.8.m2.1c">\alpha</annotation></semantics></math> gives larger gain for fine-grained image recognition tasks. However, as <math id="S2.I1.i1.p1.9.m3.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.I1.i1.p1.9.m3.1a"><mi id="S2.I1.i1.p1.9.m3.1.1" xref="S2.I1.i1.p1.9.m3.1.1.cmml">Î±</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.9.m3.1b"><ci id="S2.I1.i1.p1.9.m3.1.1.cmml" xref="S2.I1.i1.p1.9.m3.1.1">ğ›¼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.9.m3.1c">\alpha</annotation></semantics></math> goes up, the computation complexity increases in polynomial order.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.2" class="ltx_p">Fukui <span id="S2.I1.i2.p1.2.1" class="ltx_text ltx_font_italic">et al</span>.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> use count sketch as a pooling method in VQA tasks and obtains the best results on VQA dataset v1 in VQA challenge 2016. They compute count sketch approximation of the visual and textual representation at each spatial location.
Given text feature <math id="S2.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="v\in\mathcal{R}^{L}" display="inline"><semantics id="S2.I1.i2.p1.1.m1.1a"><mrow id="S2.I1.i2.p1.1.m1.1.1" xref="S2.I1.i2.p1.1.m1.1.1.cmml"><mi id="S2.I1.i2.p1.1.m1.1.1.2" xref="S2.I1.i2.p1.1.m1.1.1.2.cmml">v</mi><mo id="S2.I1.i2.p1.1.m1.1.1.1" xref="S2.I1.i2.p1.1.m1.1.1.1.cmml">âˆˆ</mo><msup id="S2.I1.i2.p1.1.m1.1.1.3" xref="S2.I1.i2.p1.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I1.i2.p1.1.m1.1.1.3.2" xref="S2.I1.i2.p1.1.m1.1.1.3.2.cmml">â„›</mi><mi id="S2.I1.i2.p1.1.m1.1.1.3.3" xref="S2.I1.i2.p1.1.m1.1.1.3.3.cmml">L</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.1.m1.1b"><apply id="S2.I1.i2.p1.1.m1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1"><in id="S2.I1.i2.p1.1.m1.1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1.1"></in><ci id="S2.I1.i2.p1.1.m1.1.1.2.cmml" xref="S2.I1.i2.p1.1.m1.1.1.2">ğ‘£</ci><apply id="S2.I1.i2.p1.1.m1.1.1.3.cmml" xref="S2.I1.i2.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S2.I1.i2.p1.1.m1.1.1.3.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1.3">superscript</csymbol><ci id="S2.I1.i2.p1.1.m1.1.1.3.2.cmml" xref="S2.I1.i2.p1.1.m1.1.1.3.2">â„›</ci><ci id="S2.I1.i2.p1.1.m1.1.1.3.3.cmml" xref="S2.I1.i2.p1.1.m1.1.1.3.3">ğ¿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.1.m1.1c">v\in\mathcal{R}^{L}</annotation></semantics></math> and image features <math id="S2.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="I\in\mathcal{R}^{C\times H\times W}" display="inline"><semantics id="S2.I1.i2.p1.2.m2.1a"><mrow id="S2.I1.i2.p1.2.m2.1.1" xref="S2.I1.i2.p1.2.m2.1.1.cmml"><mi id="S2.I1.i2.p1.2.m2.1.1.2" xref="S2.I1.i2.p1.2.m2.1.1.2.cmml">I</mi><mo id="S2.I1.i2.p1.2.m2.1.1.1" xref="S2.I1.i2.p1.2.m2.1.1.1.cmml">âˆˆ</mo><msup id="S2.I1.i2.p1.2.m2.1.1.3" xref="S2.I1.i2.p1.2.m2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I1.i2.p1.2.m2.1.1.3.2" xref="S2.I1.i2.p1.2.m2.1.1.3.2.cmml">â„›</mi><mrow id="S2.I1.i2.p1.2.m2.1.1.3.3" xref="S2.I1.i2.p1.2.m2.1.1.3.3.cmml"><mi id="S2.I1.i2.p1.2.m2.1.1.3.3.2" xref="S2.I1.i2.p1.2.m2.1.1.3.3.2.cmml">C</mi><mo lspace="0.222em" rspace="0.222em" id="S2.I1.i2.p1.2.m2.1.1.3.3.1" xref="S2.I1.i2.p1.2.m2.1.1.3.3.1.cmml">Ã—</mo><mi id="S2.I1.i2.p1.2.m2.1.1.3.3.3" xref="S2.I1.i2.p1.2.m2.1.1.3.3.3.cmml">H</mi><mo lspace="0.222em" rspace="0.222em" id="S2.I1.i2.p1.2.m2.1.1.3.3.1a" xref="S2.I1.i2.p1.2.m2.1.1.3.3.1.cmml">Ã—</mo><mi id="S2.I1.i2.p1.2.m2.1.1.3.3.4" xref="S2.I1.i2.p1.2.m2.1.1.3.3.4.cmml">W</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.2.m2.1b"><apply id="S2.I1.i2.p1.2.m2.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1"><in id="S2.I1.i2.p1.2.m2.1.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1.1"></in><ci id="S2.I1.i2.p1.2.m2.1.1.2.cmml" xref="S2.I1.i2.p1.2.m2.1.1.2">ğ¼</ci><apply id="S2.I1.i2.p1.2.m2.1.1.3.cmml" xref="S2.I1.i2.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.1.1.3.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1.3">superscript</csymbol><ci id="S2.I1.i2.p1.2.m2.1.1.3.2.cmml" xref="S2.I1.i2.p1.2.m2.1.1.3.2">â„›</ci><apply id="S2.I1.i2.p1.2.m2.1.1.3.3.cmml" xref="S2.I1.i2.p1.2.m2.1.1.3.3"><times id="S2.I1.i2.p1.2.m2.1.1.3.3.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1.3.3.1"></times><ci id="S2.I1.i2.p1.2.m2.1.1.3.3.2.cmml" xref="S2.I1.i2.p1.2.m2.1.1.3.3.2">ğ¶</ci><ci id="S2.I1.i2.p1.2.m2.1.1.3.3.3.cmml" xref="S2.I1.i2.p1.2.m2.1.1.3.3.3">ğ»</ci><ci id="S2.I1.i2.p1.2.m2.1.1.3.3.4.cmml" xref="S2.I1.i2.p1.2.m2.1.1.3.3.4">ğ‘Š</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.2.m2.1c">I\in\mathcal{R}^{C\times H\times W}</annotation></semantics></math>, Fukui <span id="S2.I1.i2.p1.2.2" class="ltx_text ltx_font_italic">et al</span>.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> propose <span id="S2.I1.i2.p1.2.3" class="ltx_text ltx_font_bold">MCB</span> as:</p>
<table id="S6.EGx2" class="ltx_equationgroup ltx_eqn_align ltx_eqn_table">

<tbody id="S2.Ex1"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S2.Ex1.m1.1" class="ltx_Math" alttext="\displaystyle MCB" display="inline"><semantics id="S2.Ex1.m1.1a"><mrow id="S2.Ex1.m1.1.1" xref="S2.Ex1.m1.1.1.cmml"><mi id="S2.Ex1.m1.1.1.2" xref="S2.Ex1.m1.1.1.2.cmml">M</mi><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.1.1.1" xref="S2.Ex1.m1.1.1.1.cmml">â€‹</mo><mi id="S2.Ex1.m1.1.1.3" xref="S2.Ex1.m1.1.1.3.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.Ex1.m1.1.1.1a" xref="S2.Ex1.m1.1.1.1.cmml">â€‹</mo><mi id="S2.Ex1.m1.1.1.4" xref="S2.Ex1.m1.1.1.4.cmml">B</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex1.m1.1b"><apply id="S2.Ex1.m1.1.1.cmml" xref="S2.Ex1.m1.1.1"><times id="S2.Ex1.m1.1.1.1.cmml" xref="S2.Ex1.m1.1.1.1"></times><ci id="S2.Ex1.m1.1.1.2.cmml" xref="S2.Ex1.m1.1.1.2">ğ‘€</ci><ci id="S2.Ex1.m1.1.1.3.cmml" xref="S2.Ex1.m1.1.1.3">ğ¶</ci><ci id="S2.Ex1.m1.1.1.4.cmml" xref="S2.Ex1.m1.1.1.4">ğµ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m1.1c">\displaystyle MCB</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.Ex1.m2.7" class="ltx_Math" alttext="\displaystyle(I[:,h,w]\otimes v)[t_{1},h,w]" display="inline"><semantics id="S2.Ex1.m2.7a"><mrow id="S2.Ex1.m2.7.7" xref="S2.Ex1.m2.7.7.cmml"><mrow id="S2.Ex1.m2.6.6.1.1" xref="S2.Ex1.m2.6.6.1.1.1.cmml"><mo stretchy="false" id="S2.Ex1.m2.6.6.1.1.2" xref="S2.Ex1.m2.6.6.1.1.1.cmml">(</mo><mrow id="S2.Ex1.m2.6.6.1.1.1" xref="S2.Ex1.m2.6.6.1.1.1.cmml"><mrow id="S2.Ex1.m2.6.6.1.1.1.2" xref="S2.Ex1.m2.6.6.1.1.1.2.cmml"><mi id="S2.Ex1.m2.6.6.1.1.1.2.2" xref="S2.Ex1.m2.6.6.1.1.1.2.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="S2.Ex1.m2.6.6.1.1.1.2.1" xref="S2.Ex1.m2.6.6.1.1.1.2.1.cmml">â€‹</mo><mrow id="S2.Ex1.m2.6.6.1.1.1.2.3.2" xref="S2.Ex1.m2.6.6.1.1.1.2.3.1.cmml"><mo stretchy="false" id="S2.Ex1.m2.6.6.1.1.1.2.3.2.1" xref="S2.Ex1.m2.6.6.1.1.1.2.3.1.cmml">[</mo><mo rspace="0em" id="S2.Ex1.m2.1.1" xref="S2.Ex1.m2.1.1.cmml">:</mo><mo id="S2.Ex1.m2.6.6.1.1.1.2.3.2.2" xref="S2.Ex1.m2.6.6.1.1.1.2.3.1.cmml">,</mo><mi id="S2.Ex1.m2.2.2" xref="S2.Ex1.m2.2.2.cmml">h</mi><mo id="S2.Ex1.m2.6.6.1.1.1.2.3.2.3" xref="S2.Ex1.m2.6.6.1.1.1.2.3.1.cmml">,</mo><mi id="S2.Ex1.m2.3.3" xref="S2.Ex1.m2.3.3.cmml">w</mi><mo rspace="0.055em" stretchy="false" id="S2.Ex1.m2.6.6.1.1.1.2.3.2.4" xref="S2.Ex1.m2.6.6.1.1.1.2.3.1.cmml">]</mo></mrow></mrow><mo rspace="0.222em" id="S2.Ex1.m2.6.6.1.1.1.1" xref="S2.Ex1.m2.6.6.1.1.1.1.cmml">âŠ—</mo><mi id="S2.Ex1.m2.6.6.1.1.1.3" xref="S2.Ex1.m2.6.6.1.1.1.3.cmml">v</mi></mrow><mo stretchy="false" id="S2.Ex1.m2.6.6.1.1.3" xref="S2.Ex1.m2.6.6.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.Ex1.m2.7.7.3" xref="S2.Ex1.m2.7.7.3.cmml">â€‹</mo><mrow id="S2.Ex1.m2.7.7.2.1" xref="S2.Ex1.m2.7.7.2.2.cmml"><mo stretchy="false" id="S2.Ex1.m2.7.7.2.1.2" xref="S2.Ex1.m2.7.7.2.2.cmml">[</mo><msub id="S2.Ex1.m2.7.7.2.1.1" xref="S2.Ex1.m2.7.7.2.1.1.cmml"><mi id="S2.Ex1.m2.7.7.2.1.1.2" xref="S2.Ex1.m2.7.7.2.1.1.2.cmml">t</mi><mn id="S2.Ex1.m2.7.7.2.1.1.3" xref="S2.Ex1.m2.7.7.2.1.1.3.cmml">1</mn></msub><mo id="S2.Ex1.m2.7.7.2.1.3" xref="S2.Ex1.m2.7.7.2.2.cmml">,</mo><mi id="S2.Ex1.m2.4.4" xref="S2.Ex1.m2.4.4.cmml">h</mi><mo id="S2.Ex1.m2.7.7.2.1.4" xref="S2.Ex1.m2.7.7.2.2.cmml">,</mo><mi id="S2.Ex1.m2.5.5" xref="S2.Ex1.m2.5.5.cmml">w</mi><mo stretchy="false" id="S2.Ex1.m2.7.7.2.1.5" xref="S2.Ex1.m2.7.7.2.2.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex1.m2.7b"><apply id="S2.Ex1.m2.7.7.cmml" xref="S2.Ex1.m2.7.7"><times id="S2.Ex1.m2.7.7.3.cmml" xref="S2.Ex1.m2.7.7.3"></times><apply id="S2.Ex1.m2.6.6.1.1.1.cmml" xref="S2.Ex1.m2.6.6.1.1"><csymbol cd="latexml" id="S2.Ex1.m2.6.6.1.1.1.1.cmml" xref="S2.Ex1.m2.6.6.1.1.1.1">tensor-product</csymbol><apply id="S2.Ex1.m2.6.6.1.1.1.2.cmml" xref="S2.Ex1.m2.6.6.1.1.1.2"><times id="S2.Ex1.m2.6.6.1.1.1.2.1.cmml" xref="S2.Ex1.m2.6.6.1.1.1.2.1"></times><ci id="S2.Ex1.m2.6.6.1.1.1.2.2.cmml" xref="S2.Ex1.m2.6.6.1.1.1.2.2">ğ¼</ci><list id="S2.Ex1.m2.6.6.1.1.1.2.3.1.cmml" xref="S2.Ex1.m2.6.6.1.1.1.2.3.2"><ci id="S2.Ex1.m2.1.1.cmml" xref="S2.Ex1.m2.1.1">:</ci><ci id="S2.Ex1.m2.2.2.cmml" xref="S2.Ex1.m2.2.2">â„</ci><ci id="S2.Ex1.m2.3.3.cmml" xref="S2.Ex1.m2.3.3">ğ‘¤</ci></list></apply><ci id="S2.Ex1.m2.6.6.1.1.1.3.cmml" xref="S2.Ex1.m2.6.6.1.1.1.3">ğ‘£</ci></apply><list id="S2.Ex1.m2.7.7.2.2.cmml" xref="S2.Ex1.m2.7.7.2.1"><apply id="S2.Ex1.m2.7.7.2.1.1.cmml" xref="S2.Ex1.m2.7.7.2.1.1"><csymbol cd="ambiguous" id="S2.Ex1.m2.7.7.2.1.1.1.cmml" xref="S2.Ex1.m2.7.7.2.1.1">subscript</csymbol><ci id="S2.Ex1.m2.7.7.2.1.1.2.cmml" xref="S2.Ex1.m2.7.7.2.1.1.2">ğ‘¡</ci><cn type="integer" id="S2.Ex1.m2.7.7.2.1.1.3.cmml" xref="S2.Ex1.m2.7.7.2.1.1.3">1</cn></apply><ci id="S2.Ex1.m2.4.4.cmml" xref="S2.Ex1.m2.4.4">â„</ci><ci id="S2.Ex1.m2.5.5.cmml" xref="S2.Ex1.m2.5.5">ğ‘¤</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m2.7c">\displaystyle(I[:,h,w]\otimes v)[t_{1},h,w]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.Ex2.m1.12" class="ltx_Math" alttext="\displaystyle=(cs(I[:,h,w],f,s)\star cs(v,f,s))[t_{1},h,w]" display="inline"><semantics id="S2.Ex2.m1.12a"><mrow id="S2.Ex2.m1.12.12" xref="S2.Ex2.m1.12.12.cmml"><mi id="S2.Ex2.m1.12.12.4" xref="S2.Ex2.m1.12.12.4.cmml"></mi><mo id="S2.Ex2.m1.12.12.3" xref="S2.Ex2.m1.12.12.3.cmml">=</mo><mrow id="S2.Ex2.m1.12.12.2" xref="S2.Ex2.m1.12.12.2.cmml"><mrow id="S2.Ex2.m1.11.11.1.1.1" xref="S2.Ex2.m1.11.11.1.1.1.1.cmml"><mo stretchy="false" id="S2.Ex2.m1.11.11.1.1.1.2" xref="S2.Ex2.m1.11.11.1.1.1.1.cmml">(</mo><mrow id="S2.Ex2.m1.11.11.1.1.1.1" xref="S2.Ex2.m1.11.11.1.1.1.1.cmml"><mrow id="S2.Ex2.m1.11.11.1.1.1.1.1" xref="S2.Ex2.m1.11.11.1.1.1.1.1.cmml"><mrow id="S2.Ex2.m1.11.11.1.1.1.1.1.1" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.cmml"><mi id="S2.Ex2.m1.11.11.1.1.1.1.1.1.3" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.Ex2.m1.11.11.1.1.1.1.1.1.2" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S2.Ex2.m1.11.11.1.1.1.1.1.1.4" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.Ex2.m1.11.11.1.1.1.1.1.1.2a" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.2" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.2.cmml">(</mo><mrow id="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.2" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.1" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mrow id="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.3.2" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.3.1.cmml"><mo stretchy="false" id="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.3.2.1" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.3.1.cmml">[</mo><mo rspace="0em" id="S2.Ex2.m1.1.1" xref="S2.Ex2.m1.1.1.cmml">:</mo><mo id="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.3.2.2" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.3.1.cmml">,</mo><mi id="S2.Ex2.m1.2.2" xref="S2.Ex2.m1.2.2.cmml">h</mi><mo id="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.3.2.3" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.3.1.cmml">,</mo><mi id="S2.Ex2.m1.3.3" xref="S2.Ex2.m1.3.3.cmml">w</mi><mo stretchy="false" id="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.3.2.4" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.3.1.cmml">]</mo></mrow></mrow><mo id="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.3" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S2.Ex2.m1.4.4" xref="S2.Ex2.m1.4.4.cmml">f</mi><mo id="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.4" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S2.Ex2.m1.5.5" xref="S2.Ex2.m1.5.5.cmml">s</mi><mo rspace="0.055em" stretchy="false" id="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.5" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo rspace="0.222em" id="S2.Ex2.m1.11.11.1.1.1.1.1.2" xref="S2.Ex2.m1.11.11.1.1.1.1.1.2.cmml">â‹†</mo><mi id="S2.Ex2.m1.11.11.1.1.1.1.1.3" xref="S2.Ex2.m1.11.11.1.1.1.1.1.3.cmml">c</mi></mrow><mo lspace="0em" rspace="0em" id="S2.Ex2.m1.11.11.1.1.1.1.2" xref="S2.Ex2.m1.11.11.1.1.1.1.2.cmml">â€‹</mo><mi id="S2.Ex2.m1.11.11.1.1.1.1.3" xref="S2.Ex2.m1.11.11.1.1.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.Ex2.m1.11.11.1.1.1.1.2a" xref="S2.Ex2.m1.11.11.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.Ex2.m1.11.11.1.1.1.1.4.2" xref="S2.Ex2.m1.11.11.1.1.1.1.4.1.cmml"><mo stretchy="false" id="S2.Ex2.m1.11.11.1.1.1.1.4.2.1" xref="S2.Ex2.m1.11.11.1.1.1.1.4.1.cmml">(</mo><mi id="S2.Ex2.m1.6.6" xref="S2.Ex2.m1.6.6.cmml">v</mi><mo id="S2.Ex2.m1.11.11.1.1.1.1.4.2.2" xref="S2.Ex2.m1.11.11.1.1.1.1.4.1.cmml">,</mo><mi id="S2.Ex2.m1.7.7" xref="S2.Ex2.m1.7.7.cmml">f</mi><mo id="S2.Ex2.m1.11.11.1.1.1.1.4.2.3" xref="S2.Ex2.m1.11.11.1.1.1.1.4.1.cmml">,</mo><mi id="S2.Ex2.m1.8.8" xref="S2.Ex2.m1.8.8.cmml">s</mi><mo stretchy="false" id="S2.Ex2.m1.11.11.1.1.1.1.4.2.4" xref="S2.Ex2.m1.11.11.1.1.1.1.4.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.Ex2.m1.11.11.1.1.1.3" xref="S2.Ex2.m1.11.11.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.Ex2.m1.12.12.2.3" xref="S2.Ex2.m1.12.12.2.3.cmml">â€‹</mo><mrow id="S2.Ex2.m1.12.12.2.2.1" xref="S2.Ex2.m1.12.12.2.2.2.cmml"><mo stretchy="false" id="S2.Ex2.m1.12.12.2.2.1.2" xref="S2.Ex2.m1.12.12.2.2.2.cmml">[</mo><msub id="S2.Ex2.m1.12.12.2.2.1.1" xref="S2.Ex2.m1.12.12.2.2.1.1.cmml"><mi id="S2.Ex2.m1.12.12.2.2.1.1.2" xref="S2.Ex2.m1.12.12.2.2.1.1.2.cmml">t</mi><mn id="S2.Ex2.m1.12.12.2.2.1.1.3" xref="S2.Ex2.m1.12.12.2.2.1.1.3.cmml">1</mn></msub><mo id="S2.Ex2.m1.12.12.2.2.1.3" xref="S2.Ex2.m1.12.12.2.2.2.cmml">,</mo><mi id="S2.Ex2.m1.9.9" xref="S2.Ex2.m1.9.9.cmml">h</mi><mo id="S2.Ex2.m1.12.12.2.2.1.4" xref="S2.Ex2.m1.12.12.2.2.2.cmml">,</mo><mi id="S2.Ex2.m1.10.10" xref="S2.Ex2.m1.10.10.cmml">w</mi><mo stretchy="false" id="S2.Ex2.m1.12.12.2.2.1.5" xref="S2.Ex2.m1.12.12.2.2.2.cmml">]</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex2.m1.12b"><apply id="S2.Ex2.m1.12.12.cmml" xref="S2.Ex2.m1.12.12"><eq id="S2.Ex2.m1.12.12.3.cmml" xref="S2.Ex2.m1.12.12.3"></eq><csymbol cd="latexml" id="S2.Ex2.m1.12.12.4.cmml" xref="S2.Ex2.m1.12.12.4">absent</csymbol><apply id="S2.Ex2.m1.12.12.2.cmml" xref="S2.Ex2.m1.12.12.2"><times id="S2.Ex2.m1.12.12.2.3.cmml" xref="S2.Ex2.m1.12.12.2.3"></times><apply id="S2.Ex2.m1.11.11.1.1.1.1.cmml" xref="S2.Ex2.m1.11.11.1.1.1"><times id="S2.Ex2.m1.11.11.1.1.1.1.2.cmml" xref="S2.Ex2.m1.11.11.1.1.1.1.2"></times><apply id="S2.Ex2.m1.11.11.1.1.1.1.1.cmml" xref="S2.Ex2.m1.11.11.1.1.1.1.1"><ci id="S2.Ex2.m1.11.11.1.1.1.1.1.2.cmml" xref="S2.Ex2.m1.11.11.1.1.1.1.1.2">â‹†</ci><apply id="S2.Ex2.m1.11.11.1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1"><times id="S2.Ex2.m1.11.11.1.1.1.1.1.1.2.cmml" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.2"></times><ci id="S2.Ex2.m1.11.11.1.1.1.1.1.1.3.cmml" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.3">ğ‘</ci><ci id="S2.Ex2.m1.11.11.1.1.1.1.1.1.4.cmml" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.4">ğ‘ </ci><vector id="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1"><apply id="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1"><times id="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.1"></times><ci id="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.2">ğ¼</ci><list id="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.Ex2.m1.11.11.1.1.1.1.1.1.1.1.1.3.2"><ci id="S2.Ex2.m1.1.1.cmml" xref="S2.Ex2.m1.1.1">:</ci><ci id="S2.Ex2.m1.2.2.cmml" xref="S2.Ex2.m1.2.2">â„</ci><ci id="S2.Ex2.m1.3.3.cmml" xref="S2.Ex2.m1.3.3">ğ‘¤</ci></list></apply><ci id="S2.Ex2.m1.4.4.cmml" xref="S2.Ex2.m1.4.4">ğ‘“</ci><ci id="S2.Ex2.m1.5.5.cmml" xref="S2.Ex2.m1.5.5">ğ‘ </ci></vector></apply><ci id="S2.Ex2.m1.11.11.1.1.1.1.1.3.cmml" xref="S2.Ex2.m1.11.11.1.1.1.1.1.3">ğ‘</ci></apply><ci id="S2.Ex2.m1.11.11.1.1.1.1.3.cmml" xref="S2.Ex2.m1.11.11.1.1.1.1.3">ğ‘ </ci><vector id="S2.Ex2.m1.11.11.1.1.1.1.4.1.cmml" xref="S2.Ex2.m1.11.11.1.1.1.1.4.2"><ci id="S2.Ex2.m1.6.6.cmml" xref="S2.Ex2.m1.6.6">ğ‘£</ci><ci id="S2.Ex2.m1.7.7.cmml" xref="S2.Ex2.m1.7.7">ğ‘“</ci><ci id="S2.Ex2.m1.8.8.cmml" xref="S2.Ex2.m1.8.8">ğ‘ </ci></vector></apply><list id="S2.Ex2.m1.12.12.2.2.2.cmml" xref="S2.Ex2.m1.12.12.2.2.1"><apply id="S2.Ex2.m1.12.12.2.2.1.1.cmml" xref="S2.Ex2.m1.12.12.2.2.1.1"><csymbol cd="ambiguous" id="S2.Ex2.m1.12.12.2.2.1.1.1.cmml" xref="S2.Ex2.m1.12.12.2.2.1.1">subscript</csymbol><ci id="S2.Ex2.m1.12.12.2.2.1.1.2.cmml" xref="S2.Ex2.m1.12.12.2.2.1.1.2">ğ‘¡</ci><cn type="integer" id="S2.Ex2.m1.12.12.2.2.1.1.3.cmml" xref="S2.Ex2.m1.12.12.2.2.1.1.3">1</cn></apply><ci id="S2.Ex2.m1.9.9.cmml" xref="S2.Ex2.m1.9.9">â„</ci><ci id="S2.Ex2.m1.10.10.cmml" xref="S2.Ex2.m1.10.10">ğ‘¤</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex2.m1.12c">\displaystyle=(cs(I[:,h,w],f,s)\star cs(v,f,s))[t_{1},h,w]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.Ex3"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.Ex3.m1.11" class="ltx_Math" alttext="\displaystyle=IFFT1(FFT1(cs(I[:,h,w],f,s))[t_{1},h,w]\circ FFT1(cs(v,f,s))[t_{1}])" display="inline"><semantics id="S2.Ex3.m1.11a"><mrow id="S2.Ex3.m1.11.11" xref="S2.Ex3.m1.11.11.cmml"><mi id="S2.Ex3.m1.11.11.3" xref="S2.Ex3.m1.11.11.3.cmml"></mi><mo id="S2.Ex3.m1.11.11.2" xref="S2.Ex3.m1.11.11.2.cmml">=</mo><mrow id="S2.Ex3.m1.11.11.1" xref="S2.Ex3.m1.11.11.1.cmml"><mi id="S2.Ex3.m1.11.11.1.3" xref="S2.Ex3.m1.11.11.1.3.cmml">I</mi><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.11.11.1.2" xref="S2.Ex3.m1.11.11.1.2.cmml">â€‹</mo><mi id="S2.Ex3.m1.11.11.1.4" xref="S2.Ex3.m1.11.11.1.4.cmml">F</mi><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.11.11.1.2a" xref="S2.Ex3.m1.11.11.1.2.cmml">â€‹</mo><mi id="S2.Ex3.m1.11.11.1.5" xref="S2.Ex3.m1.11.11.1.5.cmml">F</mi><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.11.11.1.2b" xref="S2.Ex3.m1.11.11.1.2.cmml">â€‹</mo><mi id="S2.Ex3.m1.11.11.1.6" xref="S2.Ex3.m1.11.11.1.6.cmml">T</mi><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.11.11.1.2c" xref="S2.Ex3.m1.11.11.1.2.cmml">â€‹</mo><mn id="S2.Ex3.m1.11.11.1.7" xref="S2.Ex3.m1.11.11.1.7.cmml">1</mn><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.11.11.1.2d" xref="S2.Ex3.m1.11.11.1.2.cmml">â€‹</mo><mrow id="S2.Ex3.m1.11.11.1.1.1" xref="S2.Ex3.m1.11.11.1.1.1.1.cmml"><mo stretchy="false" id="S2.Ex3.m1.11.11.1.1.1.2" xref="S2.Ex3.m1.11.11.1.1.1.1.cmml">(</mo><mrow id="S2.Ex3.m1.11.11.1.1.1.1" xref="S2.Ex3.m1.11.11.1.1.1.1.cmml"><mrow id="S2.Ex3.m1.11.11.1.1.1.1.2" xref="S2.Ex3.m1.11.11.1.1.1.1.2.cmml"><mrow id="S2.Ex3.m1.11.11.1.1.1.1.2.2" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.cmml"><mi id="S2.Ex3.m1.11.11.1.1.1.1.2.2.4" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.4.cmml">F</mi><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.11.11.1.1.1.1.2.2.3" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.3.cmml">â€‹</mo><mi id="S2.Ex3.m1.11.11.1.1.1.1.2.2.5" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.5.cmml">F</mi><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.11.11.1.1.1.1.2.2.3a" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.3.cmml">â€‹</mo><mi id="S2.Ex3.m1.11.11.1.1.1.1.2.2.6" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.6.cmml">T</mi><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.11.11.1.1.1.1.2.2.3b" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.3.cmml">â€‹</mo><mn id="S2.Ex3.m1.11.11.1.1.1.1.2.2.7" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.7.cmml">1</mn><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.11.11.1.1.1.1.2.2.3c" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.3.cmml">â€‹</mo><mrow id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.2" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.3" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.2" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mi id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.4" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.4.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.2a" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.2.cmml">(</mo><mrow id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">â€‹</mo><mrow id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml"><mo stretchy="false" id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.3.2.1" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">[</mo><mo rspace="0em" id="S2.Ex3.m1.1.1" xref="S2.Ex3.m1.1.1.cmml">:</mo><mo id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">,</mo><mi id="S2.Ex3.m1.2.2" xref="S2.Ex3.m1.2.2.cmml">h</mi><mo id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.3.2.3" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">,</mo><mi id="S2.Ex3.m1.3.3" xref="S2.Ex3.m1.3.3.cmml">w</mi><mo stretchy="false" id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.3.2.4" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml">]</mo></mrow></mrow><mo id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S2.Ex3.m1.4.4" xref="S2.Ex3.m1.4.4.cmml">f</mi><mo id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.4" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S2.Ex3.m1.5.5" xref="S2.Ex3.m1.5.5.cmml">s</mi><mo stretchy="false" id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.5" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.3" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.11.11.1.1.1.1.2.2.3d" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.3.cmml">â€‹</mo><mrow id="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.1" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.2.cmml"><mo stretchy="false" id="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.1.2" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.2.cmml">[</mo><msub id="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.1.1" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.1.1.cmml"><mi id="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.1.1.2" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.1.1.2.cmml">t</mi><mn id="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.1.1.3" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.1.1.3.cmml">1</mn></msub><mo id="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.1.3" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.2.cmml">,</mo><mi id="S2.Ex3.m1.6.6" xref="S2.Ex3.m1.6.6.cmml">h</mi><mo id="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.1.4" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.2.cmml">,</mo><mi id="S2.Ex3.m1.7.7" xref="S2.Ex3.m1.7.7.cmml">w</mi><mo rspace="0.055em" stretchy="false" id="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.1.5" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.2.cmml">]</mo></mrow></mrow><mo rspace="0.222em" id="S2.Ex3.m1.11.11.1.1.1.1.2.3" xref="S2.Ex3.m1.11.11.1.1.1.1.2.3.cmml">âˆ˜</mo><mi id="S2.Ex3.m1.11.11.1.1.1.1.2.4" xref="S2.Ex3.m1.11.11.1.1.1.1.2.4.cmml">F</mi></mrow><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.11.11.1.1.1.1.5" xref="S2.Ex3.m1.11.11.1.1.1.1.5.cmml">â€‹</mo><mi id="S2.Ex3.m1.11.11.1.1.1.1.6" xref="S2.Ex3.m1.11.11.1.1.1.1.6.cmml">F</mi><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.11.11.1.1.1.1.5a" xref="S2.Ex3.m1.11.11.1.1.1.1.5.cmml">â€‹</mo><mi id="S2.Ex3.m1.11.11.1.1.1.1.7" xref="S2.Ex3.m1.11.11.1.1.1.1.7.cmml">T</mi><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.11.11.1.1.1.1.5b" xref="S2.Ex3.m1.11.11.1.1.1.1.5.cmml">â€‹</mo><mn id="S2.Ex3.m1.11.11.1.1.1.1.8" xref="S2.Ex3.m1.11.11.1.1.1.1.8.cmml">1</mn><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.11.11.1.1.1.1.5c" xref="S2.Ex3.m1.11.11.1.1.1.1.5.cmml">â€‹</mo><mrow id="S2.Ex3.m1.11.11.1.1.1.1.3.1" xref="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.cmml"><mo stretchy="false" id="S2.Ex3.m1.11.11.1.1.1.1.3.1.2" xref="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.cmml">(</mo><mrow id="S2.Ex3.m1.11.11.1.1.1.1.3.1.1" xref="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.cmml"><mi id="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.2" xref="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.1" xref="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.1.cmml">â€‹</mo><mi id="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.3" xref="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.1a" xref="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.1.cmml">â€‹</mo><mrow id="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.4.2" xref="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.4.1.cmml"><mo stretchy="false" id="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.4.2.1" xref="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.4.1.cmml">(</mo><mi id="S2.Ex3.m1.8.8" xref="S2.Ex3.m1.8.8.cmml">v</mi><mo id="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.4.2.2" xref="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.4.1.cmml">,</mo><mi id="S2.Ex3.m1.9.9" xref="S2.Ex3.m1.9.9.cmml">f</mi><mo id="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.4.2.3" xref="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.4.1.cmml">,</mo><mi id="S2.Ex3.m1.10.10" xref="S2.Ex3.m1.10.10.cmml">s</mi><mo stretchy="false" id="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.4.2.4" xref="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.4.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S2.Ex3.m1.11.11.1.1.1.1.3.1.3" xref="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.Ex3.m1.11.11.1.1.1.1.5d" xref="S2.Ex3.m1.11.11.1.1.1.1.5.cmml">â€‹</mo><mrow id="S2.Ex3.m1.11.11.1.1.1.1.4.1" xref="S2.Ex3.m1.11.11.1.1.1.1.4.2.cmml"><mo stretchy="false" id="S2.Ex3.m1.11.11.1.1.1.1.4.1.2" xref="S2.Ex3.m1.11.11.1.1.1.1.4.2.1.cmml">[</mo><msub id="S2.Ex3.m1.11.11.1.1.1.1.4.1.1" xref="S2.Ex3.m1.11.11.1.1.1.1.4.1.1.cmml"><mi id="S2.Ex3.m1.11.11.1.1.1.1.4.1.1.2" xref="S2.Ex3.m1.11.11.1.1.1.1.4.1.1.2.cmml">t</mi><mn id="S2.Ex3.m1.11.11.1.1.1.1.4.1.1.3" xref="S2.Ex3.m1.11.11.1.1.1.1.4.1.1.3.cmml">1</mn></msub><mo stretchy="false" id="S2.Ex3.m1.11.11.1.1.1.1.4.1.3" xref="S2.Ex3.m1.11.11.1.1.1.1.4.2.1.cmml">]</mo></mrow></mrow><mo stretchy="false" id="S2.Ex3.m1.11.11.1.1.1.3" xref="S2.Ex3.m1.11.11.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex3.m1.11b"><apply id="S2.Ex3.m1.11.11.cmml" xref="S2.Ex3.m1.11.11"><eq id="S2.Ex3.m1.11.11.2.cmml" xref="S2.Ex3.m1.11.11.2"></eq><csymbol cd="latexml" id="S2.Ex3.m1.11.11.3.cmml" xref="S2.Ex3.m1.11.11.3">absent</csymbol><apply id="S2.Ex3.m1.11.11.1.cmml" xref="S2.Ex3.m1.11.11.1"><times id="S2.Ex3.m1.11.11.1.2.cmml" xref="S2.Ex3.m1.11.11.1.2"></times><ci id="S2.Ex3.m1.11.11.1.3.cmml" xref="S2.Ex3.m1.11.11.1.3">ğ¼</ci><ci id="S2.Ex3.m1.11.11.1.4.cmml" xref="S2.Ex3.m1.11.11.1.4">ğ¹</ci><ci id="S2.Ex3.m1.11.11.1.5.cmml" xref="S2.Ex3.m1.11.11.1.5">ğ¹</ci><ci id="S2.Ex3.m1.11.11.1.6.cmml" xref="S2.Ex3.m1.11.11.1.6">ğ‘‡</ci><cn type="integer" id="S2.Ex3.m1.11.11.1.7.cmml" xref="S2.Ex3.m1.11.11.1.7">1</cn><apply id="S2.Ex3.m1.11.11.1.1.1.1.cmml" xref="S2.Ex3.m1.11.11.1.1.1"><times id="S2.Ex3.m1.11.11.1.1.1.1.5.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.5"></times><apply id="S2.Ex3.m1.11.11.1.1.1.1.2.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.2"><compose id="S2.Ex3.m1.11.11.1.1.1.1.2.3.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.2.3"></compose><apply id="S2.Ex3.m1.11.11.1.1.1.1.2.2.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2"><times id="S2.Ex3.m1.11.11.1.1.1.1.2.2.3.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.3"></times><ci id="S2.Ex3.m1.11.11.1.1.1.1.2.2.4.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.4">ğ¹</ci><ci id="S2.Ex3.m1.11.11.1.1.1.1.2.2.5.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.5">ğ¹</ci><ci id="S2.Ex3.m1.11.11.1.1.1.1.2.2.6.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.6">ğ‘‡</ci><cn type="integer" id="S2.Ex3.m1.11.11.1.1.1.1.2.2.7.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.7">1</cn><apply id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1"><times id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.2"></times><ci id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.3">ğ‘</ci><ci id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.4.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.4">ğ‘ </ci><vector id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1"><apply id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1"><times id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.1"></times><ci id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.2">ğ¼</ci><list id="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.3.2"><ci id="S2.Ex3.m1.1.1.cmml" xref="S2.Ex3.m1.1.1">:</ci><ci id="S2.Ex3.m1.2.2.cmml" xref="S2.Ex3.m1.2.2">â„</ci><ci id="S2.Ex3.m1.3.3.cmml" xref="S2.Ex3.m1.3.3">ğ‘¤</ci></list></apply><ci id="S2.Ex3.m1.4.4.cmml" xref="S2.Ex3.m1.4.4">ğ‘“</ci><ci id="S2.Ex3.m1.5.5.cmml" xref="S2.Ex3.m1.5.5">ğ‘ </ci></vector></apply><list id="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.2.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.1"><apply id="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.1.1.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.1.1"><csymbol cd="ambiguous" id="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.1.1.1.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.1.1">subscript</csymbol><ci id="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.1.1.2.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.1.1.2">ğ‘¡</ci><cn type="integer" id="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.1.1.3.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.2.2.2.1.1.3">1</cn></apply><ci id="S2.Ex3.m1.6.6.cmml" xref="S2.Ex3.m1.6.6">â„</ci><ci id="S2.Ex3.m1.7.7.cmml" xref="S2.Ex3.m1.7.7">ğ‘¤</ci></list></apply><ci id="S2.Ex3.m1.11.11.1.1.1.1.2.4.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.2.4">ğ¹</ci></apply><ci id="S2.Ex3.m1.11.11.1.1.1.1.6.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.6">ğ¹</ci><ci id="S2.Ex3.m1.11.11.1.1.1.1.7.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.7">ğ‘‡</ci><cn type="integer" id="S2.Ex3.m1.11.11.1.1.1.1.8.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.8">1</cn><apply id="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.3.1"><times id="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.1.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.1"></times><ci id="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.2.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.2">ğ‘</ci><ci id="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.3.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.3">ğ‘ </ci><vector id="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.4.1.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.3.1.1.4.2"><ci id="S2.Ex3.m1.8.8.cmml" xref="S2.Ex3.m1.8.8">ğ‘£</ci><ci id="S2.Ex3.m1.9.9.cmml" xref="S2.Ex3.m1.9.9">ğ‘“</ci><ci id="S2.Ex3.m1.10.10.cmml" xref="S2.Ex3.m1.10.10">ğ‘ </ci></vector></apply><apply id="S2.Ex3.m1.11.11.1.1.1.1.4.2.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.4.1"><csymbol cd="latexml" id="S2.Ex3.m1.11.11.1.1.1.1.4.2.1.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.4.1.2">delimited-[]</csymbol><apply id="S2.Ex3.m1.11.11.1.1.1.1.4.1.1.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.4.1.1"><csymbol cd="ambiguous" id="S2.Ex3.m1.11.11.1.1.1.1.4.1.1.1.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.4.1.1">subscript</csymbol><ci id="S2.Ex3.m1.11.11.1.1.1.1.4.1.1.2.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.4.1.1.2">ğ‘¡</ci><cn type="integer" id="S2.Ex3.m1.11.11.1.1.1.1.4.1.1.3.cmml" xref="S2.Ex3.m1.11.11.1.1.1.1.4.1.1.3">1</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex3.m1.11c">\displaystyle=IFFT1(FFT1(cs(I[:,h,w],f,s))[t_{1},h,w]\circ FFT1(cs(v,f,s))[t_{1}])</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
<tbody id="S2.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S2.E2.m1.7" class="ltx_Math" alttext="\displaystyle h\in\{1,\cdots H\},w\in\{1,\cdots W\},t_{1}\in\{1,\cdots,b\}" display="inline"><semantics id="S2.E2.m1.7a"><mrow id="S2.E2.m1.7.7.2" xref="S2.E2.m1.7.7.3.cmml"><mrow id="S2.E2.m1.6.6.1.1" xref="S2.E2.m1.6.6.1.1.cmml"><mi id="S2.E2.m1.6.6.1.1.3" xref="S2.E2.m1.6.6.1.1.3.cmml">h</mi><mo id="S2.E2.m1.6.6.1.1.2" xref="S2.E2.m1.6.6.1.1.2.cmml">âˆˆ</mo><mrow id="S2.E2.m1.6.6.1.1.1.1" xref="S2.E2.m1.6.6.1.1.1.2.cmml"><mo stretchy="false" id="S2.E2.m1.6.6.1.1.1.1.2" xref="S2.E2.m1.6.6.1.1.1.2.cmml">{</mo><mn id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml">1</mn><mo id="S2.E2.m1.6.6.1.1.1.1.3" xref="S2.E2.m1.6.6.1.1.1.2.cmml">,</mo><mrow id="S2.E2.m1.6.6.1.1.1.1.1" xref="S2.E2.m1.6.6.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S2.E2.m1.6.6.1.1.1.1.1.2" xref="S2.E2.m1.6.6.1.1.1.1.1.2.cmml">â‹¯</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.6.6.1.1.1.1.1.1" xref="S2.E2.m1.6.6.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S2.E2.m1.6.6.1.1.1.1.1.3" xref="S2.E2.m1.6.6.1.1.1.1.1.3.cmml">H</mi></mrow><mo stretchy="false" id="S2.E2.m1.6.6.1.1.1.1.4" xref="S2.E2.m1.6.6.1.1.1.2.cmml">}</mo></mrow></mrow><mo id="S2.E2.m1.7.7.2.3" xref="S2.E2.m1.7.7.3a.cmml">,</mo><mrow id="S2.E2.m1.7.7.2.2.2" xref="S2.E2.m1.7.7.2.2.3.cmml"><mrow id="S2.E2.m1.7.7.2.2.1.1" xref="S2.E2.m1.7.7.2.2.1.1.cmml"><mi id="S2.E2.m1.7.7.2.2.1.1.3" xref="S2.E2.m1.7.7.2.2.1.1.3.cmml">w</mi><mo id="S2.E2.m1.7.7.2.2.1.1.2" xref="S2.E2.m1.7.7.2.2.1.1.2.cmml">âˆˆ</mo><mrow id="S2.E2.m1.7.7.2.2.1.1.1.1" xref="S2.E2.m1.7.7.2.2.1.1.1.2.cmml"><mo stretchy="false" id="S2.E2.m1.7.7.2.2.1.1.1.1.2" xref="S2.E2.m1.7.7.2.2.1.1.1.2.cmml">{</mo><mn id="S2.E2.m1.2.2" xref="S2.E2.m1.2.2.cmml">1</mn><mo id="S2.E2.m1.7.7.2.2.1.1.1.1.3" xref="S2.E2.m1.7.7.2.2.1.1.1.2.cmml">,</mo><mrow id="S2.E2.m1.7.7.2.2.1.1.1.1.1" xref="S2.E2.m1.7.7.2.2.1.1.1.1.1.cmml"><mi mathvariant="normal" id="S2.E2.m1.7.7.2.2.1.1.1.1.1.2" xref="S2.E2.m1.7.7.2.2.1.1.1.1.1.2.cmml">â‹¯</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.7.7.2.2.1.1.1.1.1.1" xref="S2.E2.m1.7.7.2.2.1.1.1.1.1.1.cmml">â€‹</mo><mi id="S2.E2.m1.7.7.2.2.1.1.1.1.1.3" xref="S2.E2.m1.7.7.2.2.1.1.1.1.1.3.cmml">W</mi></mrow><mo stretchy="false" id="S2.E2.m1.7.7.2.2.1.1.1.1.4" xref="S2.E2.m1.7.7.2.2.1.1.1.2.cmml">}</mo></mrow></mrow><mo id="S2.E2.m1.7.7.2.2.2.3" xref="S2.E2.m1.7.7.2.2.3a.cmml">,</mo><mrow id="S2.E2.m1.7.7.2.2.2.2" xref="S2.E2.m1.7.7.2.2.2.2.cmml"><msub id="S2.E2.m1.7.7.2.2.2.2.2" xref="S2.E2.m1.7.7.2.2.2.2.2.cmml"><mi id="S2.E2.m1.7.7.2.2.2.2.2.2" xref="S2.E2.m1.7.7.2.2.2.2.2.2.cmml">t</mi><mn id="S2.E2.m1.7.7.2.2.2.2.2.3" xref="S2.E2.m1.7.7.2.2.2.2.2.3.cmml">1</mn></msub><mo id="S2.E2.m1.7.7.2.2.2.2.1" xref="S2.E2.m1.7.7.2.2.2.2.1.cmml">âˆˆ</mo><mrow id="S2.E2.m1.7.7.2.2.2.2.3.2" xref="S2.E2.m1.7.7.2.2.2.2.3.1.cmml"><mo stretchy="false" id="S2.E2.m1.7.7.2.2.2.2.3.2.1" xref="S2.E2.m1.7.7.2.2.2.2.3.1.cmml">{</mo><mn id="S2.E2.m1.3.3" xref="S2.E2.m1.3.3.cmml">1</mn><mo id="S2.E2.m1.7.7.2.2.2.2.3.2.2" xref="S2.E2.m1.7.7.2.2.2.2.3.1.cmml">,</mo><mi mathvariant="normal" id="S2.E2.m1.4.4" xref="S2.E2.m1.4.4.cmml">â‹¯</mi><mo id="S2.E2.m1.7.7.2.2.2.2.3.2.3" xref="S2.E2.m1.7.7.2.2.2.2.3.1.cmml">,</mo><mi id="S2.E2.m1.5.5" xref="S2.E2.m1.5.5.cmml">b</mi><mo stretchy="false" id="S2.E2.m1.7.7.2.2.2.2.3.2.4" xref="S2.E2.m1.7.7.2.2.2.2.3.1.cmml">}</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.7b"><apply id="S2.E2.m1.7.7.3.cmml" xref="S2.E2.m1.7.7.2"><csymbol cd="ambiguous" id="S2.E2.m1.7.7.3a.cmml" xref="S2.E2.m1.7.7.2.3">formulae-sequence</csymbol><apply id="S2.E2.m1.6.6.1.1.cmml" xref="S2.E2.m1.6.6.1.1"><in id="S2.E2.m1.6.6.1.1.2.cmml" xref="S2.E2.m1.6.6.1.1.2"></in><ci id="S2.E2.m1.6.6.1.1.3.cmml" xref="S2.E2.m1.6.6.1.1.3">â„</ci><set id="S2.E2.m1.6.6.1.1.1.2.cmml" xref="S2.E2.m1.6.6.1.1.1.1"><cn type="integer" id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1">1</cn><apply id="S2.E2.m1.6.6.1.1.1.1.1.cmml" xref="S2.E2.m1.6.6.1.1.1.1.1"><times id="S2.E2.m1.6.6.1.1.1.1.1.1.cmml" xref="S2.E2.m1.6.6.1.1.1.1.1.1"></times><ci id="S2.E2.m1.6.6.1.1.1.1.1.2.cmml" xref="S2.E2.m1.6.6.1.1.1.1.1.2">â‹¯</ci><ci id="S2.E2.m1.6.6.1.1.1.1.1.3.cmml" xref="S2.E2.m1.6.6.1.1.1.1.1.3">ğ»</ci></apply></set></apply><apply id="S2.E2.m1.7.7.2.2.3.cmml" xref="S2.E2.m1.7.7.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.7.7.2.2.3a.cmml" xref="S2.E2.m1.7.7.2.2.2.3">formulae-sequence</csymbol><apply id="S2.E2.m1.7.7.2.2.1.1.cmml" xref="S2.E2.m1.7.7.2.2.1.1"><in id="S2.E2.m1.7.7.2.2.1.1.2.cmml" xref="S2.E2.m1.7.7.2.2.1.1.2"></in><ci id="S2.E2.m1.7.7.2.2.1.1.3.cmml" xref="S2.E2.m1.7.7.2.2.1.1.3">ğ‘¤</ci><set id="S2.E2.m1.7.7.2.2.1.1.1.2.cmml" xref="S2.E2.m1.7.7.2.2.1.1.1.1"><cn type="integer" id="S2.E2.m1.2.2.cmml" xref="S2.E2.m1.2.2">1</cn><apply id="S2.E2.m1.7.7.2.2.1.1.1.1.1.cmml" xref="S2.E2.m1.7.7.2.2.1.1.1.1.1"><times id="S2.E2.m1.7.7.2.2.1.1.1.1.1.1.cmml" xref="S2.E2.m1.7.7.2.2.1.1.1.1.1.1"></times><ci id="S2.E2.m1.7.7.2.2.1.1.1.1.1.2.cmml" xref="S2.E2.m1.7.7.2.2.1.1.1.1.1.2">â‹¯</ci><ci id="S2.E2.m1.7.7.2.2.1.1.1.1.1.3.cmml" xref="S2.E2.m1.7.7.2.2.1.1.1.1.1.3">ğ‘Š</ci></apply></set></apply><apply id="S2.E2.m1.7.7.2.2.2.2.cmml" xref="S2.E2.m1.7.7.2.2.2.2"><in id="S2.E2.m1.7.7.2.2.2.2.1.cmml" xref="S2.E2.m1.7.7.2.2.2.2.1"></in><apply id="S2.E2.m1.7.7.2.2.2.2.2.cmml" xref="S2.E2.m1.7.7.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.7.7.2.2.2.2.2.1.cmml" xref="S2.E2.m1.7.7.2.2.2.2.2">subscript</csymbol><ci id="S2.E2.m1.7.7.2.2.2.2.2.2.cmml" xref="S2.E2.m1.7.7.2.2.2.2.2.2">ğ‘¡</ci><cn type="integer" id="S2.E2.m1.7.7.2.2.2.2.2.3.cmml" xref="S2.E2.m1.7.7.2.2.2.2.2.3">1</cn></apply><set id="S2.E2.m1.7.7.2.2.2.2.3.1.cmml" xref="S2.E2.m1.7.7.2.2.2.2.3.2"><cn type="integer" id="S2.E2.m1.3.3.cmml" xref="S2.E2.m1.3.3">1</cn><ci id="S2.E2.m1.4.4.cmml" xref="S2.E2.m1.4.4">â‹¯</ci><ci id="S2.E2.m1.5.5.cmml" xref="S2.E2.m1.5.5">ğ‘</ci></set></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.7c">\displaystyle h\in\{1,\cdots H\},w\in\{1,\cdots W\},t_{1}\in\{1,\cdots,b\}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S2.I1.i2.p1.5" class="ltx_p"><math id="S2.I1.i2.p1.3.m1.1" class="ltx_Math" alttext="\otimes" display="inline"><semantics id="S2.I1.i2.p1.3.m1.1a"><mo id="S2.I1.i2.p1.3.m1.1.1" xref="S2.I1.i2.p1.3.m1.1.1.cmml">âŠ—</mo><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.3.m1.1b"><csymbol cd="latexml" id="S2.I1.i2.p1.3.m1.1.1.cmml" xref="S2.I1.i2.p1.3.m1.1.1">tensor-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.3.m1.1c">\otimes</annotation></semantics></math> denotes outer product. <math id="S2.I1.i2.p1.4.m2.1" class="ltx_Math" alttext="\circ" display="inline"><semantics id="S2.I1.i2.p1.4.m2.1a"><mo id="S2.I1.i2.p1.4.m2.1.1" xref="S2.I1.i2.p1.4.m2.1.1.cmml">âˆ˜</mo><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.4.m2.1b"><compose id="S2.I1.i2.p1.4.m2.1.1.cmml" xref="S2.I1.i2.p1.4.m2.1.1"></compose></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.4.m2.1c">\circ</annotation></semantics></math> denotes element-wise product. <math id="S2.I1.i2.p1.5.m3.1" class="ltx_Math" alttext="\star" display="inline"><semantics id="S2.I1.i2.p1.5.m3.1a"><mo id="S2.I1.i2.p1.5.m3.1.1" xref="S2.I1.i2.p1.5.m3.1.1.cmml">â‹†</mo><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.5.m3.1b"><ci id="S2.I1.i2.p1.5.m3.1.1.cmml" xref="S2.I1.i2.p1.5.m3.1.1">â‹†</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.5.m3.1c">\star</annotation></semantics></math> denotes convolution operator. This procedure preserves spatial information in the image feature.</p>
</div>
</li>
</ul>
<p id="S2.p9.4" class="ltx_p"><span id="S2.p9.4.1" class="ltx_text ltx_font_bold">Attention</span>
Focusing on the objects in the image that are related to the question is the key to understand the correlation between the image and the question. Attention mechanism is used to address this problem. There are soft attention and hard attentionÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite> based on whether the attention term/loss function is differentiable or not. Yang <span id="S2.p9.4.2" class="ltx_text ltx_font_italic">et al</span>.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> and Xu <span id="S2.p9.4.3" class="ltx_text ltx_font_italic">et al</span>.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> propose word guided spatial attention specifically for VQA task. Attention weight at each spatial location is calculated by the correlation between the embedded question feature and the embedded visual features. The attended pixels are at the maximum correlations. Wang <span id="S2.p9.4.4" class="ltx_text ltx_font_italic">et al</span>.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> explore mechanisms of triplet attention that interact between the image, question and candidate answers based on image-question pairs.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Question Type Guided Visual Attention</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Question type is very important in predicting the answer regardless whether we have the corresponding image or not. For example, questions starting with â€œhow manyâ€ will mostly lead to numerical answers. Agrawal <span id="S3.p1.1.1" class="ltx_text ltx_font_italic">et al</span>.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> have shown that state-of-art VQA models converge to the same answer even if only given half of the question compared to if given the whole sentence. Besides that, inspired byÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, we are curious about combining bottom-up and top-down visual features in VQA task. To get a deep understanding of visual feature preference for different questions, we try to find an attention mechanism between these two. Since question type is representing the question, we propose Question Type-guided Attention(QTA).</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.6" class="ltx_p">Given several independent image features <math id="S3.p2.1.m1.3" class="ltx_Math" alttext="F_{1},F_{2},\cdots F_{k}" display="inline"><semantics id="S3.p2.1.m1.3a"><mrow id="S3.p2.1.m1.3.3.3" xref="S3.p2.1.m1.3.3.4.cmml"><msub id="S3.p2.1.m1.1.1.1.1" xref="S3.p2.1.m1.1.1.1.1.cmml"><mi id="S3.p2.1.m1.1.1.1.1.2" xref="S3.p2.1.m1.1.1.1.1.2.cmml">F</mi><mn id="S3.p2.1.m1.1.1.1.1.3" xref="S3.p2.1.m1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.p2.1.m1.3.3.3.4" xref="S3.p2.1.m1.3.3.4.cmml">,</mo><msub id="S3.p2.1.m1.2.2.2.2" xref="S3.p2.1.m1.2.2.2.2.cmml"><mi id="S3.p2.1.m1.2.2.2.2.2" xref="S3.p2.1.m1.2.2.2.2.2.cmml">F</mi><mn id="S3.p2.1.m1.2.2.2.2.3" xref="S3.p2.1.m1.2.2.2.2.3.cmml">2</mn></msub><mo id="S3.p2.1.m1.3.3.3.5" xref="S3.p2.1.m1.3.3.4.cmml">,</mo><mrow id="S3.p2.1.m1.3.3.3.3" xref="S3.p2.1.m1.3.3.3.3.cmml"><mi mathvariant="normal" id="S3.p2.1.m1.3.3.3.3.2" xref="S3.p2.1.m1.3.3.3.3.2.cmml">â‹¯</mi><mo lspace="0em" rspace="0em" id="S3.p2.1.m1.3.3.3.3.1" xref="S3.p2.1.m1.3.3.3.3.1.cmml">â€‹</mo><msub id="S3.p2.1.m1.3.3.3.3.3" xref="S3.p2.1.m1.3.3.3.3.3.cmml"><mi id="S3.p2.1.m1.3.3.3.3.3.2" xref="S3.p2.1.m1.3.3.3.3.3.2.cmml">F</mi><mi id="S3.p2.1.m1.3.3.3.3.3.3" xref="S3.p2.1.m1.3.3.3.3.3.3.cmml">k</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.3b"><list id="S3.p2.1.m1.3.3.4.cmml" xref="S3.p2.1.m1.3.3.3"><apply id="S3.p2.1.m1.1.1.1.1.cmml" xref="S3.p2.1.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.1.m1.1.1.1.1.1.cmml" xref="S3.p2.1.m1.1.1.1.1">subscript</csymbol><ci id="S3.p2.1.m1.1.1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.1.1.2">ğ¹</ci><cn type="integer" id="S3.p2.1.m1.1.1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.1.1.3">1</cn></apply><apply id="S3.p2.1.m1.2.2.2.2.cmml" xref="S3.p2.1.m1.2.2.2.2"><csymbol cd="ambiguous" id="S3.p2.1.m1.2.2.2.2.1.cmml" xref="S3.p2.1.m1.2.2.2.2">subscript</csymbol><ci id="S3.p2.1.m1.2.2.2.2.2.cmml" xref="S3.p2.1.m1.2.2.2.2.2">ğ¹</ci><cn type="integer" id="S3.p2.1.m1.2.2.2.2.3.cmml" xref="S3.p2.1.m1.2.2.2.2.3">2</cn></apply><apply id="S3.p2.1.m1.3.3.3.3.cmml" xref="S3.p2.1.m1.3.3.3.3"><times id="S3.p2.1.m1.3.3.3.3.1.cmml" xref="S3.p2.1.m1.3.3.3.3.1"></times><ci id="S3.p2.1.m1.3.3.3.3.2.cmml" xref="S3.p2.1.m1.3.3.3.3.2">â‹¯</ci><apply id="S3.p2.1.m1.3.3.3.3.3.cmml" xref="S3.p2.1.m1.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.p2.1.m1.3.3.3.3.3.1.cmml" xref="S3.p2.1.m1.3.3.3.3.3">subscript</csymbol><ci id="S3.p2.1.m1.3.3.3.3.3.2.cmml" xref="S3.p2.1.m1.3.3.3.3.3.2">ğ¹</ci><ci id="S3.p2.1.m1.3.3.3.3.3.3.cmml" xref="S3.p2.1.m1.3.3.3.3.3.3">ğ‘˜</ci></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.3c">F_{1},F_{2},\cdots F_{k}</annotation></semantics></math>, such as features from ResNet, VGG or Faster R-CNN, we concatenate them as one image feature: <math id="S3.p2.2.m2.3" class="ltx_Math" alttext="F=[F_{1},F_{2},\cdots F_{k}]\in\mathcal{R}^{M}" display="inline"><semantics id="S3.p2.2.m2.3a"><mrow id="S3.p2.2.m2.3.3" xref="S3.p2.2.m2.3.3.cmml"><mi id="S3.p2.2.m2.3.3.5" xref="S3.p2.2.m2.3.3.5.cmml">F</mi><mo id="S3.p2.2.m2.3.3.6" xref="S3.p2.2.m2.3.3.6.cmml">=</mo><mrow id="S3.p2.2.m2.3.3.3.3" xref="S3.p2.2.m2.3.3.3.4.cmml"><mo stretchy="false" id="S3.p2.2.m2.3.3.3.3.4" xref="S3.p2.2.m2.3.3.3.4.cmml">[</mo><msub id="S3.p2.2.m2.1.1.1.1.1" xref="S3.p2.2.m2.1.1.1.1.1.cmml"><mi id="S3.p2.2.m2.1.1.1.1.1.2" xref="S3.p2.2.m2.1.1.1.1.1.2.cmml">F</mi><mn id="S3.p2.2.m2.1.1.1.1.1.3" xref="S3.p2.2.m2.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S3.p2.2.m2.3.3.3.3.5" xref="S3.p2.2.m2.3.3.3.4.cmml">,</mo><msub id="S3.p2.2.m2.2.2.2.2.2" xref="S3.p2.2.m2.2.2.2.2.2.cmml"><mi id="S3.p2.2.m2.2.2.2.2.2.2" xref="S3.p2.2.m2.2.2.2.2.2.2.cmml">F</mi><mn id="S3.p2.2.m2.2.2.2.2.2.3" xref="S3.p2.2.m2.2.2.2.2.2.3.cmml">2</mn></msub><mo id="S3.p2.2.m2.3.3.3.3.6" xref="S3.p2.2.m2.3.3.3.4.cmml">,</mo><mrow id="S3.p2.2.m2.3.3.3.3.3" xref="S3.p2.2.m2.3.3.3.3.3.cmml"><mi mathvariant="normal" id="S3.p2.2.m2.3.3.3.3.3.2" xref="S3.p2.2.m2.3.3.3.3.3.2.cmml">â‹¯</mi><mo lspace="0em" rspace="0em" id="S3.p2.2.m2.3.3.3.3.3.1" xref="S3.p2.2.m2.3.3.3.3.3.1.cmml">â€‹</mo><msub id="S3.p2.2.m2.3.3.3.3.3.3" xref="S3.p2.2.m2.3.3.3.3.3.3.cmml"><mi id="S3.p2.2.m2.3.3.3.3.3.3.2" xref="S3.p2.2.m2.3.3.3.3.3.3.2.cmml">F</mi><mi id="S3.p2.2.m2.3.3.3.3.3.3.3" xref="S3.p2.2.m2.3.3.3.3.3.3.3.cmml">k</mi></msub></mrow><mo stretchy="false" id="S3.p2.2.m2.3.3.3.3.7" xref="S3.p2.2.m2.3.3.3.4.cmml">]</mo></mrow><mo id="S3.p2.2.m2.3.3.7" xref="S3.p2.2.m2.3.3.7.cmml">âˆˆ</mo><msup id="S3.p2.2.m2.3.3.8" xref="S3.p2.2.m2.3.3.8.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p2.2.m2.3.3.8.2" xref="S3.p2.2.m2.3.3.8.2.cmml">â„›</mi><mi id="S3.p2.2.m2.3.3.8.3" xref="S3.p2.2.m2.3.3.8.3.cmml">M</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.3b"><apply id="S3.p2.2.m2.3.3.cmml" xref="S3.p2.2.m2.3.3"><and id="S3.p2.2.m2.3.3a.cmml" xref="S3.p2.2.m2.3.3"></and><apply id="S3.p2.2.m2.3.3b.cmml" xref="S3.p2.2.m2.3.3"><eq id="S3.p2.2.m2.3.3.6.cmml" xref="S3.p2.2.m2.3.3.6"></eq><ci id="S3.p2.2.m2.3.3.5.cmml" xref="S3.p2.2.m2.3.3.5">ğ¹</ci><list id="S3.p2.2.m2.3.3.3.4.cmml" xref="S3.p2.2.m2.3.3.3.3"><apply id="S3.p2.2.m2.1.1.1.1.1.cmml" xref="S3.p2.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.2.m2.1.1.1.1.1.1.cmml" xref="S3.p2.2.m2.1.1.1.1.1">subscript</csymbol><ci id="S3.p2.2.m2.1.1.1.1.1.2.cmml" xref="S3.p2.2.m2.1.1.1.1.1.2">ğ¹</ci><cn type="integer" id="S3.p2.2.m2.1.1.1.1.1.3.cmml" xref="S3.p2.2.m2.1.1.1.1.1.3">1</cn></apply><apply id="S3.p2.2.m2.2.2.2.2.2.cmml" xref="S3.p2.2.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.p2.2.m2.2.2.2.2.2.1.cmml" xref="S3.p2.2.m2.2.2.2.2.2">subscript</csymbol><ci id="S3.p2.2.m2.2.2.2.2.2.2.cmml" xref="S3.p2.2.m2.2.2.2.2.2.2">ğ¹</ci><cn type="integer" id="S3.p2.2.m2.2.2.2.2.2.3.cmml" xref="S3.p2.2.m2.2.2.2.2.2.3">2</cn></apply><apply id="S3.p2.2.m2.3.3.3.3.3.cmml" xref="S3.p2.2.m2.3.3.3.3.3"><times id="S3.p2.2.m2.3.3.3.3.3.1.cmml" xref="S3.p2.2.m2.3.3.3.3.3.1"></times><ci id="S3.p2.2.m2.3.3.3.3.3.2.cmml" xref="S3.p2.2.m2.3.3.3.3.3.2">â‹¯</ci><apply id="S3.p2.2.m2.3.3.3.3.3.3.cmml" xref="S3.p2.2.m2.3.3.3.3.3.3"><csymbol cd="ambiguous" id="S3.p2.2.m2.3.3.3.3.3.3.1.cmml" xref="S3.p2.2.m2.3.3.3.3.3.3">subscript</csymbol><ci id="S3.p2.2.m2.3.3.3.3.3.3.2.cmml" xref="S3.p2.2.m2.3.3.3.3.3.3.2">ğ¹</ci><ci id="S3.p2.2.m2.3.3.3.3.3.3.3.cmml" xref="S3.p2.2.m2.3.3.3.3.3.3.3">ğ‘˜</ci></apply></apply></list></apply><apply id="S3.p2.2.m2.3.3c.cmml" xref="S3.p2.2.m2.3.3"><in id="S3.p2.2.m2.3.3.7.cmml" xref="S3.p2.2.m2.3.3.7"></in><share href="#S3.p2.2.m2.3.3.3.cmml" id="S3.p2.2.m2.3.3d.cmml" xref="S3.p2.2.m2.3.3"></share><apply id="S3.p2.2.m2.3.3.8.cmml" xref="S3.p2.2.m2.3.3.8"><csymbol cd="ambiguous" id="S3.p2.2.m2.3.3.8.1.cmml" xref="S3.p2.2.m2.3.3.8">superscript</csymbol><ci id="S3.p2.2.m2.3.3.8.2.cmml" xref="S3.p2.2.m2.3.3.8.2">â„›</ci><ci id="S3.p2.2.m2.3.3.8.3.cmml" xref="S3.p2.2.m2.3.3.8.3">ğ‘€</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.3c">F=[F_{1},F_{2},\cdots F_{k}]\in\mathcal{R}^{M}</annotation></semantics></math>. Assume there are <math id="S3.p2.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S3.p2.3.m3.1a"><mi id="S3.p2.3.m3.1.1" xref="S3.p2.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.1b"><ci id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.1c">N</annotation></semantics></math> different question types, QTA is defined as <math id="S3.p2.4.m4.1" class="ltx_Math" alttext="F\circ WQ" display="inline"><semantics id="S3.p2.4.m4.1a"><mrow id="S3.p2.4.m4.1.1" xref="S3.p2.4.m4.1.1.cmml"><mrow id="S3.p2.4.m4.1.1.2" xref="S3.p2.4.m4.1.1.2.cmml"><mi id="S3.p2.4.m4.1.1.2.2" xref="S3.p2.4.m4.1.1.2.2.cmml">F</mi><mo lspace="0.222em" rspace="0.222em" id="S3.p2.4.m4.1.1.2.1" xref="S3.p2.4.m4.1.1.2.1.cmml">âˆ˜</mo><mi id="S3.p2.4.m4.1.1.2.3" xref="S3.p2.4.m4.1.1.2.3.cmml">W</mi></mrow><mo lspace="0em" rspace="0em" id="S3.p2.4.m4.1.1.1" xref="S3.p2.4.m4.1.1.1.cmml">â€‹</mo><mi id="S3.p2.4.m4.1.1.3" xref="S3.p2.4.m4.1.1.3.cmml">Q</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.4.m4.1b"><apply id="S3.p2.4.m4.1.1.cmml" xref="S3.p2.4.m4.1.1"><times id="S3.p2.4.m4.1.1.1.cmml" xref="S3.p2.4.m4.1.1.1"></times><apply id="S3.p2.4.m4.1.1.2.cmml" xref="S3.p2.4.m4.1.1.2"><compose id="S3.p2.4.m4.1.1.2.1.cmml" xref="S3.p2.4.m4.1.1.2.1"></compose><ci id="S3.p2.4.m4.1.1.2.2.cmml" xref="S3.p2.4.m4.1.1.2.2">ğ¹</ci><ci id="S3.p2.4.m4.1.1.2.3.cmml" xref="S3.p2.4.m4.1.1.2.3">ğ‘Š</ci></apply><ci id="S3.p2.4.m4.1.1.3.cmml" xref="S3.p2.4.m4.1.1.3">ğ‘„</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.4.m4.1c">F\circ WQ</annotation></semantics></math>, where <math id="S3.p2.5.m5.1" class="ltx_Math" alttext="Q\in\mathcal{R}^{N}" display="inline"><semantics id="S3.p2.5.m5.1a"><mrow id="S3.p2.5.m5.1.1" xref="S3.p2.5.m5.1.1.cmml"><mi id="S3.p2.5.m5.1.1.2" xref="S3.p2.5.m5.1.1.2.cmml">Q</mi><mo id="S3.p2.5.m5.1.1.1" xref="S3.p2.5.m5.1.1.1.cmml">âˆˆ</mo><msup id="S3.p2.5.m5.1.1.3" xref="S3.p2.5.m5.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p2.5.m5.1.1.3.2" xref="S3.p2.5.m5.1.1.3.2.cmml">â„›</mi><mi id="S3.p2.5.m5.1.1.3.3" xref="S3.p2.5.m5.1.1.3.3.cmml">N</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.5.m5.1b"><apply id="S3.p2.5.m5.1.1.cmml" xref="S3.p2.5.m5.1.1"><in id="S3.p2.5.m5.1.1.1.cmml" xref="S3.p2.5.m5.1.1.1"></in><ci id="S3.p2.5.m5.1.1.2.cmml" xref="S3.p2.5.m5.1.1.2">ğ‘„</ci><apply id="S3.p2.5.m5.1.1.3.cmml" xref="S3.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S3.p2.5.m5.1.1.3.1.cmml" xref="S3.p2.5.m5.1.1.3">superscript</csymbol><ci id="S3.p2.5.m5.1.1.3.2.cmml" xref="S3.p2.5.m5.1.1.3.2">â„›</ci><ci id="S3.p2.5.m5.1.1.3.3.cmml" xref="S3.p2.5.m5.1.1.3.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.5.m5.1c">Q\in\mathcal{R}^{N}</annotation></semantics></math> is the one-hot encoding of the question type, and <math id="S3.p2.6.m6.1" class="ltx_Math" alttext="W\in\mathcal{R}^{M\times N}" display="inline"><semantics id="S3.p2.6.m6.1a"><mrow id="S3.p2.6.m6.1.1" xref="S3.p2.6.m6.1.1.cmml"><mi id="S3.p2.6.m6.1.1.2" xref="S3.p2.6.m6.1.1.2.cmml">W</mi><mo id="S3.p2.6.m6.1.1.1" xref="S3.p2.6.m6.1.1.1.cmml">âˆˆ</mo><msup id="S3.p2.6.m6.1.1.3" xref="S3.p2.6.m6.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p2.6.m6.1.1.3.2" xref="S3.p2.6.m6.1.1.3.2.cmml">â„›</mi><mrow id="S3.p2.6.m6.1.1.3.3" xref="S3.p2.6.m6.1.1.3.3.cmml"><mi id="S3.p2.6.m6.1.1.3.3.2" xref="S3.p2.6.m6.1.1.3.3.2.cmml">M</mi><mo lspace="0.222em" rspace="0.222em" id="S3.p2.6.m6.1.1.3.3.1" xref="S3.p2.6.m6.1.1.3.3.1.cmml">Ã—</mo><mi id="S3.p2.6.m6.1.1.3.3.3" xref="S3.p2.6.m6.1.1.3.3.3.cmml">N</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.6.m6.1b"><apply id="S3.p2.6.m6.1.1.cmml" xref="S3.p2.6.m6.1.1"><in id="S3.p2.6.m6.1.1.1.cmml" xref="S3.p2.6.m6.1.1.1"></in><ci id="S3.p2.6.m6.1.1.2.cmml" xref="S3.p2.6.m6.1.1.2">ğ‘Š</ci><apply id="S3.p2.6.m6.1.1.3.cmml" xref="S3.p2.6.m6.1.1.3"><csymbol cd="ambiguous" id="S3.p2.6.m6.1.1.3.1.cmml" xref="S3.p2.6.m6.1.1.3">superscript</csymbol><ci id="S3.p2.6.m6.1.1.3.2.cmml" xref="S3.p2.6.m6.1.1.3.2">â„›</ci><apply id="S3.p2.6.m6.1.1.3.3.cmml" xref="S3.p2.6.m6.1.1.3.3"><times id="S3.p2.6.m6.1.1.3.3.1.cmml" xref="S3.p2.6.m6.1.1.3.3.1"></times><ci id="S3.p2.6.m6.1.1.3.3.2.cmml" xref="S3.p2.6.m6.1.1.3.3.2">ğ‘€</ci><ci id="S3.p2.6.m6.1.1.3.3.3.cmml" xref="S3.p2.6.m6.1.1.3.3.3">ğ‘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.6.m6.1c">W\in\mathcal{R}^{M\times N}</annotation></semantics></math> is the hidden weight. We can learn the weight by back propagation through the network. In other words, we learn a question type embedding and use it as attention weight.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">QTA can be used in both generic and complex pooling models. In FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3 Question Type Guided Visual Attention â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we show a simple concatenation model with question type as input. We describe it in detail in SectionÂ <a href="#S4" title="4 Experiments â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. To fully exploit image features in different channels and preserve spatial information, we also propose MCB with question type-guided image attention in FigureÂ <a href="#S3.F4" title="Figure 4 â€£ 3 Question Type Guided Visual Attention â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure id="S3.2" class="ltx_figure">
<div id="S3.2.3" class="ltx_block">
<figure id="S3.F2" class="ltx_figure ltx_figure_panel ltx_align_center ltx_align_middle" style="width:216.8pt;"><img src="/html/1804.02088/assets/CAT3LW2V.png" id="S3.1.1.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="236" height="157" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Concatenation model with QTA structure for VQA task(CATL-QTA<sup id="S3.F2.4.1" class="ltx_sup"><span id="S3.F2.4.1.1" class="ltx_text ltx_font_italic">W</span></sup> in SectionÂ <a href="#S4" title="4 Experiments â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>)</figcaption>
</figure>
<figure id="S3.F3" class="ltx_figure ltx_figure_panel ltx_align_center ltx_align_middle" style="width:173.4pt;"><img src="/html/1804.02088/assets/multitask1-CAT3LW2V.png" id="S3.2.2.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="224" height="157" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Concatenation model with QTA structure for multi-task(CATL-QTA-M<sup id="S3.F3.4.1" class="ltx_sup"><span id="S3.F3.4.1.1" class="ltx_text ltx_font_italic">W</span></sup> in SectionÂ <a href="#S4" title="4 Experiments â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>)</figcaption>
</figure>
</div>
</figure>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">One obvious limitation of QTA is that it requires question type label. In the real world scenario, the question type for each question may not be available. In this case, it is still possible to predict the question type from the text, and use it as input to the QTA network. Thus, we propose a multi-task model that focuses on VQA task along with the prediction of the question type in FigureÂ <a href="#S3.F3" title="Figure 3 â€£ 3 Question Type Guided Visual Attention â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. This model operates in the setting where true question type is available only at training time. In SectionÂ <a href="#S5" title="5 Results and Analysis â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we also show through experiment that it is a relatively easy task to predict the question type from question text, and thus making our method generalizable to those VQA settings that lack question type.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="/html/1804.02088/assets/MCB-att-qtype-sim-new.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="471" height="197" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>MCB model with QTA structure(MCB-QTA in SectionÂ <a href="#S4" title="4 Experiments â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>)</figcaption>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In this section, we describe the dataset in SectionÂ <a href="#S4.SS1" title="4.1 Dataset â€£ 4 Experiments â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>, evaluation metrics in SectionÂ <a href="#S4.SS2" title="4.2 Evaluation Metrics â€£ 4 Experiments â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.2</span></a>, model features in SectionÂ <a href="#S4.SS3" title="4.3 Feature Representation â€£ 4 Experiments â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.3</span></a>, and model structures are explained in SectionÂ <a href="#S4.SS4" title="4.4 Models â€£ 4 Experiments â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.4</span></a>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Dataset</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Our experiments are conducted on the Task Driven Image Understanding Challenge dataset(TDIUC)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, which contains over 1.6 million questions in 12 different types. This dataset includes VQA v1 and Visual Genome, with a total of 122429 training images and 57565 test images. The annotation sources are MSCOCO (VQA v1), Visual genome annotations, and manual annotations. TDIUC introduces absurd questions that force an algorithm to determine if a question is valid for a given image. There are 1115299 total training questions and 538543 total test questions. The total number of samples is 3 times larger than that in VQA v1 dataset.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Evaluation Metrics</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">There are total 12 different question types in TDIUC dataset as we mentioned in SectionÂ <a href="#S2" title="2 Related Works â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. We calculate the simple accuracy for each type separately and also report the arithmetic and harmonic means across all per question-type(MPT) accuracies.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Feature Representation</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.3" class="ltx_p"><span id="S4.SS3.p1.3.1" class="ltx_text ltx_font_bold">Image feature</span>
We use the output of â€œpoolâ€ of a 152-layer ResNet as an image feature baseline. The output dimension is <math id="S4.SS3.p1.1.m1.1" class="ltx_Math" alttext="2048\times 14\times 14" display="inline"><semantics id="S4.SS3.p1.1.m1.1a"><mrow id="S4.SS3.p1.1.m1.1.1" xref="S4.SS3.p1.1.m1.1.1.cmml"><mn id="S4.SS3.p1.1.m1.1.1.2" xref="S4.SS3.p1.1.m1.1.1.2.cmml">2048</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.p1.1.m1.1.1.1" xref="S4.SS3.p1.1.m1.1.1.1.cmml">Ã—</mo><mn id="S4.SS3.p1.1.m1.1.1.3" xref="S4.SS3.p1.1.m1.1.1.3.cmml">14</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.p1.1.m1.1.1.1a" xref="S4.SS3.p1.1.m1.1.1.1.cmml">Ã—</mo><mn id="S4.SS3.p1.1.m1.1.1.4" xref="S4.SS3.p1.1.m1.1.1.4.cmml">14</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.1.m1.1b"><apply id="S4.SS3.p1.1.m1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1"><times id="S4.SS3.p1.1.m1.1.1.1.cmml" xref="S4.SS3.p1.1.m1.1.1.1"></times><cn type="integer" id="S4.SS3.p1.1.m1.1.1.2.cmml" xref="S4.SS3.p1.1.m1.1.1.2">2048</cn><cn type="integer" id="S4.SS3.p1.1.m1.1.1.3.cmml" xref="S4.SS3.p1.1.m1.1.1.3">14</cn><cn type="integer" id="S4.SS3.p1.1.m1.1.1.4.cmml" xref="S4.SS3.p1.1.m1.1.1.4">14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.1.m1.1c">2048\times 14\times 14</annotation></semantics></math>.
Faster R-CNNÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> focuses on object detection and classification. Teney <span id="S4.SS3.p1.3.2" class="ltx_text ltx_font_italic">et al</span>.Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> use it to extract object-oriented features for VQA dataset and show better performance compared to the ones using ResNet feature. We fix the number of detected objects to be 36 and extract the image features based on their pre-trained Faster R-CNN model. As a result, the extracted image feature is a <math id="S4.SS3.p1.2.m2.1" class="ltx_Math" alttext="36\times 2048" display="inline"><semantics id="S4.SS3.p1.2.m2.1a"><mrow id="S4.SS3.p1.2.m2.1.1" xref="S4.SS3.p1.2.m2.1.1.cmml"><mn id="S4.SS3.p1.2.m2.1.1.2" xref="S4.SS3.p1.2.m2.1.1.2.cmml">36</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.p1.2.m2.1.1.1" xref="S4.SS3.p1.2.m2.1.1.1.cmml">Ã—</mo><mn id="S4.SS3.p1.2.m2.1.1.3" xref="S4.SS3.p1.2.m2.1.1.3.cmml">2048</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.2.m2.1b"><apply id="S4.SS3.p1.2.m2.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1"><times id="S4.SS3.p1.2.m2.1.1.1.cmml" xref="S4.SS3.p1.2.m2.1.1.1"></times><cn type="integer" id="S4.SS3.p1.2.m2.1.1.2.cmml" xref="S4.SS3.p1.2.m2.1.1.2">36</cn><cn type="integer" id="S4.SS3.p1.2.m2.1.1.3.cmml" xref="S4.SS3.p1.2.m2.1.1.3">2048</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.2.m2.1c">36\times 2048</annotation></semantics></math> matrix. To fit in MCB model, which requires spatial representation, we reshape it into a <math id="S4.SS3.p1.3.m3.1" class="ltx_Math" alttext="6\times 6\times 2048" display="inline"><semantics id="S4.SS3.p1.3.m3.1a"><mrow id="S4.SS3.p1.3.m3.1.1" xref="S4.SS3.p1.3.m3.1.1.cmml"><mn id="S4.SS3.p1.3.m3.1.1.2" xref="S4.SS3.p1.3.m3.1.1.2.cmml">6</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.p1.3.m3.1.1.1" xref="S4.SS3.p1.3.m3.1.1.1.cmml">Ã—</mo><mn id="S4.SS3.p1.3.m3.1.1.3" xref="S4.SS3.p1.3.m3.1.1.3.cmml">6</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS3.p1.3.m3.1.1.1a" xref="S4.SS3.p1.3.m3.1.1.1.cmml">Ã—</mo><mn id="S4.SS3.p1.3.m3.1.1.4" xref="S4.SS3.p1.3.m3.1.1.4.cmml">2048</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p1.3.m3.1b"><apply id="S4.SS3.p1.3.m3.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1"><times id="S4.SS3.p1.3.m3.1.1.1.cmml" xref="S4.SS3.p1.3.m3.1.1.1"></times><cn type="integer" id="S4.SS3.p1.3.m3.1.1.2.cmml" xref="S4.SS3.p1.3.m3.1.1.2">6</cn><cn type="integer" id="S4.SS3.p1.3.m3.1.1.3.cmml" xref="S4.SS3.p1.3.m3.1.1.3">6</cn><cn type="integer" id="S4.SS3.p1.3.m3.1.1.4.cmml" xref="S4.SS3.p1.3.m3.1.1.4">2048</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p1.3.m3.1c">6\times 6\times 2048</annotation></semantics></math> tensor.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p"><span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_bold">Text feature</span>
We use common word embedding library: 300-dim Word2VecÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> as a pre-trained text feature: we sum over the word embeddings for all words in the sentence. A two-layer LSTM is used as an end-to-end text feature extractor. We also use the encoder of google neural machine translation(NMT) systemÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> as a pre-trained text feature and compare it with Word2Vec. The pre-trained NMT model is trained on UN parallel corpus 1.0 in MXnetÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Its BLEU score is 34. The output dimension of the encoder is <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="1024" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mn id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml">1024</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><cn type="integer" id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1">1024</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">1024</annotation></semantics></math>.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Models</h3>

<section id="S4.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.1 </span>Baseline models</h4>

<div id="S4.SS4.SSS1.p1" class="ltx_para">
<p id="S4.SS4.SSS1.p1.1" class="ltx_p">Baseline models are based on a one-layer MLP: A fully connected network classifier with one hidden layer with ReLu non-linearity, followed by a softmax layer. The input is a concatenation of image and text feature. There are 8192 units in the hidden state.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Baseline models</figcaption>
<div id="S4.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:462.6pt;height:120.6pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-12.2pt,3.1pt) scale(0.95,0.95) ;">
<table id="S4.T1.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T1.1.1.1.1" class="ltx_tr">
<td id="S4.T1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Name</span></td>
<td id="S4.T1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Image feature</span></td>
<td id="S4.T1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S4.T1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Text feature</span></td>
<td id="S4.T1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S4.T1.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Modal</span></td>
</tr>
<tr id="S4.T1.1.1.2.2" class="ltx_tr">
<td id="S4.T1.1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.1.1.2.2.1.1" class="ltx_text ltx_font_bold">CAT1</span></td>
<td id="S4.T1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ResNet/Faster R-CNN vector feature</td>
<td id="S4.T1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Skipthought/NMT/Word2Vec pre-trined feature</td>
<td id="S4.T1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">MLP</td>
</tr>
<tr id="S4.T1.1.1.3.3" class="ltx_tr">
<td id="S4.T1.1.1.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.1.1.3.3.1.1" class="ltx_text ltx_font_bold">CAT1L</span></td>
<td id="S4.T1.1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">ResNet/Faster R-CNN vector feature</td>
<td id="S4.T1.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">End-to-end 2-layer LSTMâ€™s last hidden state</td>
<td id="S4.T1.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t">MLP</td>
</tr>
<tr id="S4.T1.1.1.4.4" class="ltx_tr">
<td id="S4.T1.1.1.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T1.1.1.4.4.1.1" class="ltx_text ltx_font_bold">CATL</span></td>
<td id="S4.T1.1.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Concatenation of ResNet</td>
<td id="S4.T1.1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T1.1.1.4.4.3.1" class="ltx_text">End-to-end 2-layer LSTMâ€™s last hidden state</span></td>
<td id="S4.T1.1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T1.1.1.4.4.4.1" class="ltx_text">MLP</span></td>
</tr>
<tr id="S4.T1.1.1.5.5" class="ltx_tr">
<td id="S4.T1.1.1.5.5.1" class="ltx_td ltx_align_center ltx_border_r">and Faster R-CNN vector features</td>
</tr>
<tr id="S4.T1.1.1.6.6" class="ltx_tr">
<td id="S4.T1.1.1.6.6.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T1.1.1.6.6.1.1" class="ltx_text ltx_font_bold">CAT2</span></td>
<td id="S4.T1.1.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Concatenation of ResNet</td>
<td id="S4.T1.1.1.6.6.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T1.1.1.6.6.3.1" class="ltx_text">Skipthought/NMT/Word2Vec pre-trined feature</span></td>
<td id="S4.T1.1.1.6.6.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="2"><span id="S4.T1.1.1.6.6.4.1" class="ltx_text">MLP</span></td>
</tr>
<tr id="S4.T1.1.1.7.7" class="ltx_tr">
<td id="S4.T1.1.1.7.7.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">and Faster R-CNN vector features</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS4.SSS1.p2" class="ltx_para">
<p id="S4.SS4.SSS1.p2.1" class="ltx_p">To compare different image and text feature, we have <span id="S4.SS4.SSS1.p2.1.1" class="ltx_text ltx_font_bold">CAT1</span>, <span id="S4.SS4.SSS1.p2.1.2" class="ltx_text ltx_font_bold">CAT1L</span> and <span id="S4.SS4.SSS1.p2.1.3" class="ltx_text ltx_font_bold">CATL</span>. To check the complementarity of different features between ResNet and Faster R-CNN and show how they perform differently across question types, we set up baseline <span id="S4.SS4.SSS1.p2.1.4" class="ltx_text ltx_font_bold">CAT2</span>. In LSTM, the hidden state length is 1024. The word embedding dimension is 300. Detailed definitions are in TableÂ <a href="#S4.T1" title="Table 1 â€£ 4.4.1 Baseline models â€£ 4.4 Models â€£ 4 Experiments â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div id="S4.SS4.SSS1.p3" class="ltx_para">
<p id="S4.SS4.SSS1.p3.1" class="ltx_p">To further exam and explain our QTA proposal, we use more sophisticate feature integration operators as a strong baseline to compare with.
<span id="S4.SS4.SSS1.p3.1.1" class="ltx_text ltx_font_bold">MCB-A</span>, as we mentioned in SectionÂ <a href="#S2" title="2 Related Works â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, is proposed in Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. <span id="S4.SS4.SSS1.p3.1.2" class="ltx_text ltx_font_bold">RAU</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> is a framework that combines the embedding, attention and predicts operation together inside a recurrent network. We reference results of these two models fromÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.2 </span>QTA models</h4>

<div id="S4.SS4.SSS2.p1" class="ltx_para">
<p id="S4.SS4.SSS2.p1.1" class="ltx_p">From the baseline analysis, we realize that ResNet and Faster R-CNN features are complementary to each other. Using question type as guidance for image feature selection is the key to make image feature stronger. Therefore, we propose QTA networks in MLP model(<span id="S4.SS4.SSS2.p1.1.1" class="ltx_text ltx_font_bold">CATL-QTA</span>) and MCB model(<span id="S4.SS4.SSS2.p1.1.2" class="ltx_text ltx_font_bold">MCB-QTA</span>). The out dimension of the count sketch in the MCB is 8000. The structures are in FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3 Question Type Guided Visual Attention â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, <a href="#S3.F4" title="Figure 4 â€£ 3 Question Type Guided Visual Attention â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. The descriptions are in TableÂ <a href="#S4.T2" title="Table 2 â€£ 4.4.2 QTA models â€£ 4.4 Models â€£ 4 Experiments â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S4.SS4.SSS2.p2" class="ltx_para">
<p id="S4.SS4.SSS2.p2.1" class="ltx_p">To check whether the model benefits from the QTA mechanism or from added question type information itself, we design a network that only uses question type embedding without attention. <span id="S4.SS4.SSS2.p2.1.1" class="ltx_text ltx_font_bold">CAT-QT</span> and <span id="S4.SS4.SSS2.p2.1.2" class="ltx_text ltx_font_bold">CATL-QT</span> are the two proposed network using Word2Vec and LSTM lexical feature.</p>
</div>
<div id="S4.SS4.SSS2.p3" class="ltx_para">
<p id="S4.SS4.SSS2.p3.1" class="ltx_p">As mentions in SectionÂ <a href="#S3" title="3 Question Type Guided Visual Attention â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we propose a multi-task network for QTA in case we donâ€™t have question type label at inference. <span id="S4.SS4.SSS2.p3.1.1" class="ltx_text ltx_font_bold">CATL-QTA-M</span> is a multi-task model based on CATL-QTA. The output of LSTM is connected to a one-layer MLP to predict question type for the input question. The prediction result is then fed into QTA part through argmax. The Multi-task MLP is in FigureÂ <a href="#S3.F3" title="Figure 3 â€£ 3 Question Type Guided Visual Attention â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>QTA models</figcaption>
<div id="S4.T2.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:457.0pt;height:149.3pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-76.2pt,24.8pt) scale(0.75,0.75) ;">
<table id="S4.T2.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.1.1.1.1" class="ltx_tr">
<th id="S4.T2.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S4.T2.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Name</span></th>
<th id="S4.T2.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S4.T2.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Image feature</span></th>
<th id="S4.T2.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt"><span id="S4.T2.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Text feature</span></th>
<th id="S4.T2.1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Modal</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.1.1.2.1" class="ltx_tr">
<td id="S4.T2.1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T2.1.1.2.1.1.1" class="ltx_text ltx_font_bold">CATL-QTA</span></td>
<td id="S4.T2.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">QTA weighted pre-trained vector features</td>
<td id="S4.T2.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T2.1.1.2.1.3.1" class="ltx_text">End-to-end 2-layer LSTMâ€™s last hidden state</span></td>
<td id="S4.T2.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T2.1.1.2.1.4.1" class="ltx_text">MLP</span></td>
</tr>
<tr id="S4.T2.1.1.3.2" class="ltx_tr">
<td id="S4.T2.1.1.3.2.1" class="ltx_td ltx_align_center ltx_border_r">from ResNet and Faster R-CNN</td>
</tr>
<tr id="S4.T2.1.1.4.3" class="ltx_tr">
<td id="S4.T2.1.1.4.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T2.1.1.4.3.1.1" class="ltx_text ltx_font_bold">MCB-QTA</span></td>
<td id="S4.T2.1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">QTA weighted pre-trained spatial features</td>
<td id="S4.T2.1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T2.1.1.4.3.3.1" class="ltx_text">End-to-end 2-layer LSTMâ€™s last hidden state</span></td>
<td id="S4.T2.1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T2.1.1.4.3.4.1" class="ltx_text">MCB</span></td>
</tr>
<tr id="S4.T2.1.1.5.4" class="ltx_tr">
<td id="S4.T2.1.1.5.4.1" class="ltx_td ltx_align_center ltx_border_r">from ResNet and Faster R-CNN</td>
</tr>
<tr id="S4.T2.1.1.6.5" class="ltx_tr">
<td id="S4.T2.1.1.6.5.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.T2.1.1.6.5.1.1" class="ltx_text ltx_font_bold">CAT-QT</span></td>
<td id="S4.T2.1.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">Concatenation of ResNet</td>
<td id="S4.T2.1.1.6.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">Concatenation of Word2Vec pre-trined feature</td>
<td id="S4.T2.1.1.6.5.4" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T2.1.1.6.5.4.1" class="ltx_text">MLP</span></td>
</tr>
<tr id="S4.T2.1.1.7.6" class="ltx_tr">
<td id="S4.T2.1.1.7.6.1" class="ltx_td ltx_align_center ltx_border_r">and Faster R-CNN vector features</td>
<td id="S4.T2.1.1.7.6.2" class="ltx_td ltx_align_center ltx_border_r">and a 1024-dim question type embedding</td>
</tr>
<tr id="S4.T2.1.1.8.7" class="ltx_tr">
<td id="S4.T2.1.1.8.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T2.1.1.8.7.1.1" class="ltx_text ltx_font_bold">CATL-QT</span></td>
<td id="S4.T2.1.1.8.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Concatenation of ResNet</td>
<td id="S4.T2.1.1.8.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Concatenation of end-to-end 2-layer LSTMâ€™s last</td>
<td id="S4.T2.1.1.8.7.4" class="ltx_td ltx_align_center ltx_border_t" rowspan="2"><span id="S4.T2.1.1.8.7.4.1" class="ltx_text">MLP</span></td>
</tr>
<tr id="S4.T2.1.1.9.8" class="ltx_tr">
<td id="S4.T2.1.1.9.8.1" class="ltx_td ltx_align_center ltx_border_r">hidden state and Faster R-CNN vector features</td>
<td id="S4.T2.1.1.9.8.2" class="ltx_td ltx_align_center ltx_border_r">and a 1024-dim question type embedding</td>
</tr>
<tr id="S4.T2.1.1.10.9" class="ltx_tr">
<td id="S4.T2.1.1.10.9.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.T2.1.1.10.9.1.1" class="ltx_text ltx_font_bold">CATL-QTA-M</span></td>
<td id="S4.T2.1.1.10.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">QTA weighted pre-trained spatial features</td>
<td id="S4.T2.1.1.10.9.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r ltx_border_tt" rowspan="2"><span id="S4.T2.1.1.10.9.3.1" class="ltx_text">End-to-end 2-layer LSTMâ€™s last hidden state</span></td>
<td id="S4.T2.1.1.10.9.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_tt" rowspan="2"><span id="S4.T2.1.1.10.9.4.1" class="ltx_text">Multi-task MLP</span></td>
</tr>
<tr id="S4.T2.1.1.11.10" class="ltx_tr">
<td id="S4.T2.1.1.11.10.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_b ltx_border_r">from ResNet and Faster R-CNN</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results and Analysis</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">We first focus in Sections <a href="#S5.SS1" title="5.1 Faster R-CNN and ResNet Features â€£ 5 Results and Analysis â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a> and <a href="#S5.SS2" title="5.2 Pre-trained and Jointly-trained Text Feature Extractors â€£ 5 Results and Analysis â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.2</span></a> on results concerning the complementarity of different features across question category types.
For the visual domain, we explore the use of Faster R-CNN and ResNet features, while for the lexical domain we use NMT, LSTM and pre-trained Word2Vec features.
We then analyze the effect of question type both as input and with QTA in VQA tasks in SectionÂ <a href="#S5.SS3" title="5.3 QTA in concatenation models â€£ 5 Results and Analysis â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.3</span></a>.
Finally, in the remaining subsections, we extend the basic concatenation QTA model to MCB style pooling; introduce question type as both input and output during training such that the network can produce predicted question types during inference; and study more in depth the effect of the question category â€œAbsurdâ€ on the overall model performance across categories.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Faster R-CNN and ResNet Features</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">TableÂ <a href="#S5.T3" title="Table 3 â€£ 5.1 Faster R-CNN and ResNet Features â€£ 5 Results and Analysis â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> reports our extensive ablation analysis of simple concatenation models using multiple visual and lexical feature sources.
From the results in the second and third columns, we see that overall the model with Faster R-CNN features outperform the one using ResNet features when using NMT features.
We show in column 4 that the features sources are complementary, and their combination is better across most categories (in bold) with respect to the single source models in columns 2 and 3.
In columns 5,6; 7,8 and 9,10 we replicate the same comparison between ResNet and R-CNN features using more sophisticate models to embed the lexical information.
We reach more than 10 % accuracy increase, from 69.53 % to 80.16 % using a simple concatenation model with an accurate selection of the feature type.</p>
</div>
<figure id="S5.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Benchmark results of concatenation models on TDIUC dataset using different image features and pre-trained language feature. 1: Use ResNet feature and SkipGram feature 2: Use ResNet feature and NMT feature 3: Use Faster R-CNN feature and NMT feature 4: Use ResNet feature and end-to-end LSTM feature 5: Use Faster R-CNN feature and end-to-end LSTM feature. N denotes that additional NMT embedding is concatenated to LSTM output. W denotes that additional Word2Vec embedding is concatenated to LSTM output(Following tables also use the same notation)</figcaption>
<div id="S5.T3.9.9" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:485.0pt;height:224.1pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-89.7pt,41.3pt) scale(0.73,0.73) ;">
<table id="S5.T3.9.9.9" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T3.9.9.9.10.1" class="ltx_tr">
<td id="S5.T3.9.9.9.10.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">Columns</td>
<td id="S5.T3.9.9.9.10.1.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt">1</td>
<td id="S5.T3.9.9.9.10.1.3" class="ltx_td ltx_align_center ltx_border_tt">2</td>
<td id="S5.T3.9.9.9.10.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">3</td>
<td id="S5.T3.9.9.9.10.1.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt">4</td>
<td id="S5.T3.9.9.9.10.1.6" class="ltx_td ltx_align_center ltx_border_tt">5</td>
<td id="S5.T3.9.9.9.10.1.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt">6</td>
<td id="S5.T3.9.9.9.10.1.8" class="ltx_td ltx_align_center ltx_border_tt">7</td>
<td id="S5.T3.9.9.9.10.1.9" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt">8</td>
<td id="S5.T3.9.9.9.10.1.10" class="ltx_td ltx_align_center ltx_border_tt">9</td>
<td id="S5.T3.9.9.9.10.1.11" class="ltx_td ltx_align_center ltx_border_tt">10</td>
</tr>
<tr id="S5.T3.9.9.9.9" class="ltx_tr">
<td id="S5.T3.9.9.9.9.10" class="ltx_td ltx_align_center ltx_border_r">Accuracy(%)</td>
<td id="S5.T3.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_rr">
<span id="S5.T3.1.1.1.1.1.1" class="ltx_text ltx_font_bold">CAT1<sup id="S5.T3.1.1.1.1.1.1.1" class="ltx_sup"><span id="S5.T3.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1</span></sup></span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>
</td>
<td id="S5.T3.2.2.2.2.2" class="ltx_td ltx_align_center"><span id="S5.T3.2.2.2.2.2.1" class="ltx_text ltx_font_bold">CAT1<sup id="S5.T3.2.2.2.2.2.1.1" class="ltx_sup"><span id="S5.T3.2.2.2.2.2.1.1.1" class="ltx_text ltx_font_medium">2</span></sup></span></td>
<td id="S5.T3.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.3.3.3.3.3.1" class="ltx_text ltx_font_bold">CAT1<sup id="S5.T3.3.3.3.3.3.1.1" class="ltx_sup"><span id="S5.T3.3.3.3.3.3.1.1.1" class="ltx_text ltx_font_medium">3</span></sup></span></td>
<td id="S5.T3.9.9.9.9.11" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.9.11.1" class="ltx_text ltx_font_bold">CAT2</span></td>
<td id="S5.T3.4.4.4.4.4" class="ltx_td ltx_align_center"><span id="S5.T3.4.4.4.4.4.1" class="ltx_text ltx_font_bold">CAT1L<sup id="S5.T3.4.4.4.4.4.1.1" class="ltx_sup"><span id="S5.T3.4.4.4.4.4.1.1.1" class="ltx_text ltx_font_medium">4</span></sup></span></td>
<td id="S5.T3.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.5.5.5.5.5.1" class="ltx_text ltx_font_bold">CAT1L<sup id="S5.T3.5.5.5.5.5.1.1" class="ltx_sup"><span id="S5.T3.5.5.5.5.5.1.1.1" class="ltx_text ltx_font_medium">5</span></sup></span></td>
<td id="S5.T3.6.6.6.6.6" class="ltx_td ltx_align_center"><span id="S5.T3.6.6.6.6.6.1" class="ltx_text ltx_font_bold">CAT1L<sup id="S5.T3.6.6.6.6.6.1.1" class="ltx_sup"><span id="S5.T3.6.6.6.6.6.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">4N</span></sup></span></td>
<td id="S5.T3.7.7.7.7.7" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.7.7.7.7.7.1" class="ltx_text ltx_font_bold">CAT1L<sup id="S5.T3.7.7.7.7.7.1.1" class="ltx_sup"><span id="S5.T3.7.7.7.7.7.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">5N</span></sup></span></td>
<td id="S5.T3.8.8.8.8.8" class="ltx_td ltx_align_center"><span id="S5.T3.8.8.8.8.8.1" class="ltx_text ltx_font_bold">CAT1L<sup id="S5.T3.8.8.8.8.8.1.1" class="ltx_sup"><span id="S5.T3.8.8.8.8.8.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">4W</span></sup></span></td>
<td id="S5.T3.9.9.9.9.9" class="ltx_td ltx_align_center"><span id="S5.T3.9.9.9.9.9.1" class="ltx_text ltx_font_bold">CAT1L<sup id="S5.T3.9.9.9.9.9.1.1" class="ltx_sup"><span id="S5.T3.9.9.9.9.9.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">5W</span></sup></span></td>
</tr>
<tr id="S5.T3.9.9.9.11.2" class="ltx_tr">
<td id="S5.T3.9.9.9.11.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Scene Recognition</td>
<td id="S5.T3.9.9.9.11.2.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">72.19</td>
<td id="S5.T3.9.9.9.11.2.3" class="ltx_td ltx_align_center ltx_border_t">68.51</td>
<td id="S5.T3.9.9.9.11.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">68.81</td>
<td id="S5.T3.9.9.9.11.2.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="S5.T3.9.9.9.11.2.5.1" class="ltx_text ltx_font_bold">69.06</span></td>
<td id="S5.T3.9.9.9.11.2.6" class="ltx_td ltx_align_center ltx_border_t">91.62</td>
<td id="S5.T3.9.9.9.11.2.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="S5.T3.9.9.9.11.2.7.1" class="ltx_text ltx_font_bold">92.27</span></td>
<td id="S5.T3.9.9.9.11.2.8" class="ltx_td ltx_align_center ltx_border_t">91.16</td>
<td id="S5.T3.9.9.9.11.2.9" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="S5.T3.9.9.9.11.2.9.1" class="ltx_text ltx_font_bold">92.33</span></td>
<td id="S5.T3.9.9.9.11.2.10" class="ltx_td ltx_align_center ltx_border_t">91.57</td>
<td id="S5.T3.9.9.9.11.2.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.9.9.9.11.2.11.1" class="ltx_text ltx_font_bold">92.45</span></td>
</tr>
<tr id="S5.T3.9.9.9.12.3" class="ltx_tr">
<td id="S5.T3.9.9.9.12.3.1" class="ltx_td ltx_align_center ltx_border_r">Sport Recognition</td>
<td id="S5.T3.9.9.9.12.3.2" class="ltx_td ltx_align_center ltx_border_rr">85.16</td>
<td id="S5.T3.9.9.9.12.3.3" class="ltx_td ltx_align_center">89.67</td>
<td id="S5.T3.9.9.9.12.3.4" class="ltx_td ltx_align_center ltx_border_r">92.36</td>
<td id="S5.T3.9.9.9.12.3.5" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.12.3.5.1" class="ltx_text ltx_font_bold">93.15</span></td>
<td id="S5.T3.9.9.9.12.3.6" class="ltx_td ltx_align_center">90.94</td>
<td id="S5.T3.9.9.9.12.3.7" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.12.3.7.1" class="ltx_text ltx_font_bold">93.84</span></td>
<td id="S5.T3.9.9.9.12.3.8" class="ltx_td ltx_align_center">89.62</td>
<td id="S5.T3.9.9.9.12.3.9" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.12.3.9.1" class="ltx_text ltx_font_bold">93.52</span></td>
<td id="S5.T3.9.9.9.12.3.10" class="ltx_td ltx_align_center">90.77</td>
<td id="S5.T3.9.9.9.12.3.11" class="ltx_td ltx_align_center"><span id="S5.T3.9.9.9.12.3.11.1" class="ltx_text ltx_font_bold">94.05</span></td>
</tr>
<tr id="S5.T3.9.9.9.13.4" class="ltx_tr">
<td id="S5.T3.9.9.9.13.4.1" class="ltx_td ltx_align_center ltx_border_r">Color Attributes</td>
<td id="S5.T3.9.9.9.13.4.2" class="ltx_td ltx_align_center ltx_border_rr">43.69</td>
<td id="S5.T3.9.9.9.13.4.3" class="ltx_td ltx_align_center">32.90</td>
<td id="S5.T3.9.9.9.13.4.4" class="ltx_td ltx_align_center ltx_border_r">34.35</td>
<td id="S5.T3.9.9.9.13.4.5" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.13.4.5.1" class="ltx_text ltx_font_bold">34.99</span></td>
<td id="S5.T3.9.9.9.13.4.6" class="ltx_td ltx_align_center">45.62</td>
<td id="S5.T3.9.9.9.13.4.7" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.13.4.7.1" class="ltx_text ltx_font_bold">49.43</span></td>
<td id="S5.T3.9.9.9.13.4.8" class="ltx_td ltx_align_center">44.07</td>
<td id="S5.T3.9.9.9.13.4.9" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.13.4.9.1" class="ltx_text ltx_font_bold">47.78</span></td>
<td id="S5.T3.9.9.9.13.4.10" class="ltx_td ltx_align_center">47.33</td>
<td id="S5.T3.9.9.9.13.4.11" class="ltx_td ltx_align_center"><span id="S5.T3.9.9.9.13.4.11.1" class="ltx_text ltx_font_bold">49.47</span></td>
</tr>
<tr id="S5.T3.9.9.9.14.5" class="ltx_tr">
<td id="S5.T3.9.9.9.14.5.1" class="ltx_td ltx_align_center ltx_border_r">Other Attributes</td>
<td id="S5.T3.9.9.9.14.5.2" class="ltx_td ltx_align_center ltx_border_rr">42.89</td>
<td id="S5.T3.9.9.9.14.5.3" class="ltx_td ltx_align_center">38.05</td>
<td id="S5.T3.9.9.9.14.5.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.9.9.9.14.5.4.1" class="ltx_text ltx_font_bold">39.76</span></td>
<td id="S5.T3.9.9.9.14.5.5" class="ltx_td ltx_align_center ltx_border_rr">39.67</td>
<td id="S5.T3.9.9.9.14.5.6" class="ltx_td ltx_align_center">40.89</td>
<td id="S5.T3.9.9.9.14.5.7" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.14.5.7.1" class="ltx_text ltx_font_bold">43.49</span></td>
<td id="S5.T3.9.9.9.14.5.8" class="ltx_td ltx_align_center">39.60</td>
<td id="S5.T3.9.9.9.14.5.9" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.14.5.9.1" class="ltx_text ltx_font_bold">42.35</span></td>
<td id="S5.T3.9.9.9.14.5.10" class="ltx_td ltx_align_center">41.92</td>
<td id="S5.T3.9.9.9.14.5.11" class="ltx_td ltx_align_center"><span id="S5.T3.9.9.9.14.5.11.1" class="ltx_text ltx_font_bold">45.19</span></td>
</tr>
<tr id="S5.T3.9.9.9.15.6" class="ltx_tr">
<td id="S5.T3.9.9.9.15.6.1" class="ltx_td ltx_align_center ltx_border_r">Activity Recognition</td>
<td id="S5.T3.9.9.9.15.6.2" class="ltx_td ltx_align_center ltx_border_rr">24.16</td>
<td id="S5.T3.9.9.9.15.6.3" class="ltx_td ltx_align_center">39.34</td>
<td id="S5.T3.9.9.9.15.6.4" class="ltx_td ltx_align_center ltx_border_r">45.75</td>
<td id="S5.T3.9.9.9.15.6.5" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.15.6.5.1" class="ltx_text ltx_font_bold">46.87</span></td>
<td id="S5.T3.9.9.9.15.6.6" class="ltx_td ltx_align_center">42.95</td>
<td id="S5.T3.9.9.9.15.6.7" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.15.6.7.1" class="ltx_text ltx_font_bold">49.25</span></td>
<td id="S5.T3.9.9.9.15.6.8" class="ltx_td ltx_align_center">40.12</td>
<td id="S5.T3.9.9.9.15.6.9" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.15.6.9.1" class="ltx_text ltx_font_bold">44.11</span></td>
<td id="S5.T3.9.9.9.15.6.10" class="ltx_td ltx_align_center">42.13</td>
<td id="S5.T3.9.9.9.15.6.11" class="ltx_td ltx_align_center"><span id="S5.T3.9.9.9.15.6.11.1" class="ltx_text ltx_font_bold">49.25</span></td>
</tr>
<tr id="S5.T3.9.9.9.16.7" class="ltx_tr">
<td id="S5.T3.9.9.9.16.7.1" class="ltx_td ltx_align_center ltx_border_r">Positional Reasoning</td>
<td id="S5.T3.9.9.9.16.7.2" class="ltx_td ltx_align_center ltx_border_rr">25.15</td>
<td id="S5.T3.9.9.9.16.7.3" class="ltx_td ltx_align_center">25.63</td>
<td id="S5.T3.9.9.9.16.7.4" class="ltx_td ltx_align_center ltx_border_r">27.16</td>
<td id="S5.T3.9.9.9.16.7.5" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.16.7.5.1" class="ltx_text ltx_font_bold">28.02</span></td>
<td id="S5.T3.9.9.9.16.7.6" class="ltx_td ltx_align_center">26.22</td>
<td id="S5.T3.9.9.9.16.7.7" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.16.7.7.1" class="ltx_text ltx_font_bold">29.35</span></td>
<td id="S5.T3.9.9.9.16.7.8" class="ltx_td ltx_align_center">24.17</td>
<td id="S5.T3.9.9.9.16.7.9" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.16.7.9.1" class="ltx_text ltx_font_bold">27.50</span></td>
<td id="S5.T3.9.9.9.16.7.10" class="ltx_td ltx_align_center">25.72</td>
<td id="S5.T3.9.9.9.16.7.11" class="ltx_td ltx_align_center"><span id="S5.T3.9.9.9.16.7.11.1" class="ltx_text ltx_font_bold">28.59</span></td>
</tr>
<tr id="S5.T3.9.9.9.17.8" class="ltx_tr">
<td id="S5.T3.9.9.9.17.8.1" class="ltx_td ltx_align_center ltx_border_r">Sub. Object Recognition</td>
<td id="S5.T3.9.9.9.17.8.2" class="ltx_td ltx_align_center ltx_border_rr">80.92</td>
<td id="S5.T3.9.9.9.17.8.3" class="ltx_td ltx_align_center">83.94</td>
<td id="S5.T3.9.9.9.17.8.4" class="ltx_td ltx_align_center ltx_border_r">85.67</td>
<td id="S5.T3.9.9.9.17.8.5" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.17.8.5.1" class="ltx_text ltx_font_bold">86.78</span></td>
<td id="S5.T3.9.9.9.17.8.6" class="ltx_td ltx_align_center">82.20</td>
<td id="S5.T3.9.9.9.17.8.7" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.17.8.7.1" class="ltx_text ltx_font_bold">85.06</span></td>
<td id="S5.T3.9.9.9.17.8.8" class="ltx_td ltx_align_center">81.85</td>
<td id="S5.T3.9.9.9.17.8.9" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.17.8.9.1" class="ltx_text ltx_font_bold">84.47</span></td>
<td id="S5.T3.9.9.9.17.8.10" class="ltx_td ltx_align_center">82.52</td>
<td id="S5.T3.9.9.9.17.8.11" class="ltx_td ltx_align_center"><span id="S5.T3.9.9.9.17.8.11.1" class="ltx_text ltx_font_bold">85.05</span></td>
</tr>
<tr id="S5.T3.9.9.9.18.9" class="ltx_tr">
<td id="S5.T3.9.9.9.18.9.1" class="ltx_td ltx_align_center ltx_border_r">Absurd</td>
<td id="S5.T3.9.9.9.18.9.2" class="ltx_td ltx_align_center ltx_border_rr">96.96</td>
<td id="S5.T3.9.9.9.18.9.3" class="ltx_td ltx_align_center">94.98</td>
<td id="S5.T3.9.9.9.18.9.4" class="ltx_td ltx_align_center ltx_border_r">94.77</td>
<td id="S5.T3.9.9.9.18.9.5" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.18.9.5.1" class="ltx_text ltx_font_bold">95.82</span></td>
<td id="S5.T3.9.9.9.18.9.6" class="ltx_td ltx_align_center"><span id="S5.T3.9.9.9.18.9.6.1" class="ltx_text ltx_font_bold">90.87</span></td>
<td id="S5.T3.9.9.9.18.9.7" class="ltx_td ltx_align_center ltx_border_rr">87.10</td>
<td id="S5.T3.9.9.9.18.9.8" class="ltx_td ltx_align_center"><span id="S5.T3.9.9.9.18.9.8.1" class="ltx_text ltx_font_bold">95.38</span></td>
<td id="S5.T3.9.9.9.18.9.9" class="ltx_td ltx_align_center ltx_border_rr">93.28</td>
<td id="S5.T3.9.9.9.18.9.10" class="ltx_td ltx_align_center"><span id="S5.T3.9.9.9.18.9.10.1" class="ltx_text ltx_font_bold">93.59</span></td>
<td id="S5.T3.9.9.9.18.9.11" class="ltx_td ltx_align_center">91.95</td>
</tr>
<tr id="S5.T3.9.9.9.19.10" class="ltx_tr">
<td id="S5.T3.9.9.9.19.10.1" class="ltx_td ltx_align_center ltx_border_r">Utility and Affordances</td>
<td id="S5.T3.9.9.9.19.10.2" class="ltx_td ltx_align_center ltx_border_rr">24.56</td>
<td id="S5.T3.9.9.9.19.10.3" class="ltx_td ltx_align_center">25.93</td>
<td id="S5.T3.9.9.9.19.10.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.T3.9.9.9.19.10.4.1" class="ltx_text ltx_font_bold">27.78</span></td>
<td id="S5.T3.9.9.9.19.10.5" class="ltx_td ltx_align_center ltx_border_rr">27.16</td>
<td id="S5.T3.9.9.9.19.10.6" class="ltx_td ltx_align_center">15.43</td>
<td id="S5.T3.9.9.9.19.10.7" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.19.10.7.1" class="ltx_text ltx_font_bold">25.93</span></td>
<td id="S5.T3.9.9.9.19.10.8" class="ltx_td ltx_align_center"><span id="S5.T3.9.9.9.19.10.8.1" class="ltx_text ltx_font_bold">25.31</span></td>
<td id="S5.T3.9.9.9.19.10.9" class="ltx_td ltx_align_center ltx_border_rr">18.52</td>
<td id="S5.T3.9.9.9.19.10.10" class="ltx_td ltx_align_center">16.05</td>
<td id="S5.T3.9.9.9.19.10.11" class="ltx_td ltx_align_center"><span id="S5.T3.9.9.9.19.10.11.1" class="ltx_text ltx_font_bold">17.28</span></td>
</tr>
<tr id="S5.T3.9.9.9.20.11" class="ltx_tr">
<td id="S5.T3.9.9.9.20.11.1" class="ltx_td ltx_align_center ltx_border_r">Object Presence</td>
<td id="S5.T3.9.9.9.20.11.2" class="ltx_td ltx_align_center ltx_border_rr">69.43</td>
<td id="S5.T3.9.9.9.20.11.3" class="ltx_td ltx_align_center">77.21</td>
<td id="S5.T3.9.9.9.20.11.4" class="ltx_td ltx_align_center ltx_border_r">77.90</td>
<td id="S5.T3.9.9.9.20.11.5" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.20.11.5.1" class="ltx_text ltx_font_bold">78.29</span></td>
<td id="S5.T3.9.9.9.20.11.6" class="ltx_td ltx_align_center">89.40</td>
<td id="S5.T3.9.9.9.20.11.7" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.20.11.7.1" class="ltx_text ltx_font_bold">91.14</span></td>
<td id="S5.T3.9.9.9.20.11.8" class="ltx_td ltx_align_center">90.13</td>
<td id="S5.T3.9.9.9.20.11.9" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.20.11.9.1" class="ltx_text ltx_font_bold">91.95</span></td>
<td id="S5.T3.9.9.9.20.11.10" class="ltx_td ltx_align_center">91.08</td>
<td id="S5.T3.9.9.9.20.11.11" class="ltx_td ltx_align_center"><span id="S5.T3.9.9.9.20.11.11.1" class="ltx_text ltx_font_bold">91.81</span></td>
</tr>
<tr id="S5.T3.9.9.9.21.12" class="ltx_tr">
<td id="S5.T3.9.9.9.21.12.1" class="ltx_td ltx_align_center ltx_border_r">Counting</td>
<td id="S5.T3.9.9.9.21.12.2" class="ltx_td ltx_align_center ltx_border_rr">44.82</td>
<td id="S5.T3.9.9.9.21.12.3" class="ltx_td ltx_align_center">48.46</td>
<td id="S5.T3.9.9.9.21.12.4" class="ltx_td ltx_align_center ltx_border_r">52.18</td>
<td id="S5.T3.9.9.9.21.12.5" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.21.12.5.1" class="ltx_text ltx_font_bold">52.57</span></td>
<td id="S5.T3.9.9.9.21.12.6" class="ltx_td ltx_align_center">45.95</td>
<td id="S5.T3.9.9.9.21.12.7" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.21.12.7.1" class="ltx_text ltx_font_bold">50.27</span></td>
<td id="S5.T3.9.9.9.21.12.8" class="ltx_td ltx_align_center">44.26</td>
<td id="S5.T3.9.9.9.21.12.9" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.21.12.9.1" class="ltx_text ltx_font_bold">49.24</span></td>
<td id="S5.T3.9.9.9.21.12.10" class="ltx_td ltx_align_center">44.93</td>
<td id="S5.T3.9.9.9.21.12.11" class="ltx_td ltx_align_center"><span id="S5.T3.9.9.9.21.12.11.1" class="ltx_text ltx_font_bold">51.30</span></td>
</tr>
<tr id="S5.T3.9.9.9.22.13" class="ltx_tr">
<td id="S5.T3.9.9.9.22.13.1" class="ltx_td ltx_align_center ltx_border_r">Sentiment Understanding</td>
<td id="S5.T3.9.9.9.22.13.2" class="ltx_td ltx_align_center ltx_border_rr">53.00</td>
<td id="S5.T3.9.9.9.22.13.3" class="ltx_td ltx_align_center">43.45</td>
<td id="S5.T3.9.9.9.22.13.4" class="ltx_td ltx_align_center ltx_border_r">46.49</td>
<td id="S5.T3.9.9.9.22.13.5" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.22.13.5.1" class="ltx_text ltx_font_bold">47.28</span></td>
<td id="S5.T3.9.9.9.22.13.6" class="ltx_td ltx_align_center">46.49</td>
<td id="S5.T3.9.9.9.22.13.7" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.22.13.7.1" class="ltx_text ltx_font_bold">48.72</span></td>
<td id="S5.T3.9.9.9.22.13.8" class="ltx_td ltx_align_center">41.85</td>
<td id="S5.T3.9.9.9.22.13.9" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.22.13.9.1" class="ltx_text ltx_font_bold">42.81</span></td>
<td id="S5.T3.9.9.9.22.13.10" class="ltx_td ltx_align_center">44.89</td>
<td id="S5.T3.9.9.9.22.13.11" class="ltx_td ltx_align_center"><span id="S5.T3.9.9.9.22.13.11.1" class="ltx_text ltx_font_bold">46.01</span></td>
</tr>
<tr id="S5.T3.9.9.9.23.14" class="ltx_tr">
<td id="S5.T3.9.9.9.23.14.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Overall (Arithmetic MPT)</td>
<td id="S5.T3.9.9.9.23.14.2" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">55.25</td>
<td id="S5.T3.9.9.9.23.14.3" class="ltx_td ltx_align_center ltx_border_t">55.67</td>
<td id="S5.T3.9.9.9.23.14.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">57.57</td>
<td id="S5.T3.9.9.9.23.14.5" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">58.31</td>
<td id="S5.T3.9.9.9.23.14.6" class="ltx_td ltx_align_center ltx_border_t">59.05</td>
<td id="S5.T3.9.9.9.23.14.7" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">62.15</td>
<td id="S5.T3.9.9.9.23.14.8" class="ltx_td ltx_align_center ltx_border_t">58.96</td>
<td id="S5.T3.9.9.9.23.14.9" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">60.66</td>
<td id="S5.T3.9.9.9.23.14.10" class="ltx_td ltx_align_center ltx_border_t">59.38</td>
<td id="S5.T3.9.9.9.23.14.11" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T3.9.9.9.23.14.11.1" class="ltx_text ltx_font_bold">61.80</span></td>
</tr>
<tr id="S5.T3.9.9.9.24.15" class="ltx_tr">
<td id="S5.T3.9.9.9.24.15.1" class="ltx_td ltx_align_center ltx_border_r">Overall (Harmonic MPT)</td>
<td id="S5.T3.9.9.9.24.15.2" class="ltx_td ltx_align_center ltx_border_rr">44.13</td>
<td id="S5.T3.9.9.9.24.15.3" class="ltx_td ltx_align_center">45.37</td>
<td id="S5.T3.9.9.9.24.15.4" class="ltx_td ltx_align_center ltx_border_r">47.99</td>
<td id="S5.T3.9.9.9.24.15.5" class="ltx_td ltx_align_center ltx_border_rr">48.44</td>
<td id="S5.T3.9.9.9.24.15.6" class="ltx_td ltx_align_center">44.09</td>
<td id="S5.T3.9.9.9.24.15.7" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T3.9.9.9.24.15.7.1" class="ltx_text ltx_font_bold">51.66</span></td>
<td id="S5.T3.9.9.9.24.15.8" class="ltx_td ltx_align_center">46.84</td>
<td id="S5.T3.9.9.9.24.15.9" class="ltx_td ltx_align_center ltx_border_rr">46.84</td>
<td id="S5.T3.9.9.9.24.15.10" class="ltx_td ltx_align_center">44.42</td>
<td id="S5.T3.9.9.9.24.15.11" class="ltx_td ltx_align_center">47.70</td>
</tr>
<tr id="S5.T3.9.9.9.25.16" class="ltx_tr">
<td id="S5.T3.9.9.9.25.16.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">Overall Accuracy</td>
<td id="S5.T3.9.9.9.25.16.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr ltx_border_t">69.53</td>
<td id="S5.T3.9.9.9.25.16.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">71.41</td>
<td id="S5.T3.9.9.9.25.16.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">72.44</td>
<td id="S5.T3.9.9.9.25.16.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr ltx_border_t">73.05</td>
<td id="S5.T3.9.9.9.25.16.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">77.55</td>
<td id="S5.T3.9.9.9.25.16.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr ltx_border_t">78.66</td>
<td id="S5.T3.9.9.9.25.16.8" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">78.35</td>
<td id="S5.T3.9.9.9.25.16.9" class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr ltx_border_t">79.94</td>
<td id="S5.T3.9.9.9.25.16.10" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">78.94</td>
<td id="S5.T3.9.9.9.25.16.11" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T3.9.9.9.25.16.11.1" class="ltx_text ltx_font_bold">80.16</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Pre-trained and Jointly-trained Text Feature Extractors</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">The first four columns in TableÂ <a href="#S5.T3" title="Table 3 â€£ 5.1 Faster R-CNN and ResNet Features â€£ 5 Results and Analysis â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> show the results of models with text features from NMT. To fully explore the text feature extractor in VQA system, we substitute the NMT pre-trained language feature extractor with a jointly-trained two layer LSTM model. The improved performance of jointly-training text feature extractor can be appreciated by comparing the results of the 4 left-most and right most columns in TableÂ <a href="#S5.T3" title="Table 3 â€£ 5.1 Faster R-CNN and ResNet Features â€£ 5 Results and Analysis â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. For example, comparing second column and fifth column in TableÂ <a href="#S5.T3" title="Table 3 â€£ 5.1 Faster R-CNN and ResNet Features â€£ 5 Results and Analysis â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we get 6% improvement using LSTM while keeping image feature and network same.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">We obtain the best model by concatenating the output of the LSTM and the pre-trained NMT/Word2Vec feature, as shown in TableÂ <a href="#S5.T3" title="Table 3 â€£ 5.1 Faster R-CNN and ResNet Features â€£ 5 Results and Analysis â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. It gives us <math id="S5.SS2.p2.1.m1.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="S5.SS2.p2.1.m1.1a"><mrow id="S5.SS2.p2.1.m1.1.1" xref="S5.SS2.p2.1.m1.1.1.cmml"><mn id="S5.SS2.p2.1.m1.1.1.2" xref="S5.SS2.p2.1.m1.1.1.2.cmml">10</mn><mo id="S5.SS2.p2.1.m1.1.1.1" xref="S5.SS2.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.1b"><apply id="S5.SS2.p2.1.m1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1"><csymbol cd="latexml" id="S5.SS2.p2.1.m1.1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S5.SS2.p2.1.m1.1.1.2.cmml" xref="S5.SS2.p2.1.m1.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">10\%</annotation></semantics></math> improvement for â€œUtility and Affordancesâ€ when we look at the fifth and seventh column. We find the use of Word2Vec is better than NMT feature in last four columns in TableÂ <a href="#S5.T3" title="Table 3 â€£ 5.1 Faster R-CNN and ResNet Features â€£ 5 Results and Analysis â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. We think the better performance of Word2Vec with respect to the NMT encoder, might be due to the more similar structure of single sentence samples of Word2Vec training set with those from classical VQA dataset with respect to those used for training NMT models.</p>
</div>
<div id="S5.SS2.5" class="ltx_logical-block ltx_minipage ltx_align_middle" style="width:433.6pt;">
<div id="S5.SS2.3.3" class="ltx_logical-block ltx_minipage ltx_align_bottom" style="width:195.1pt;">
<div id="S5.SS2.3.3.p1" class="ltx_para">
<div id="S5.SS2.2.2.2" class="ltx_inline-block ltx_transformed_outer" style="width:211.0pt;height:169.9pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-73.3pt,59.0pt) scale(0.59,0.59) ;">
<table id="S5.SS2.2.2.2.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.SS2.2.2.2.2.2" class="ltx_tr">
<th id="S5.SS2.2.2.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt">Accuracy(%)</th>
<td id="S5.SS2.2.2.2.2.2.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.SS2.2.2.2.2.2.4.1" class="ltx_text ltx_font_bold">CATL</span></td>
<td id="S5.SS2.2.2.2.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S5.SS2.2.2.2.2.2.5.1" class="ltx_text ltx_font_bold">CATL-QTA</span></td>
<td id="S5.SS2.1.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.SS2.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">CATL<sup id="S5.SS2.1.1.1.1.1.1.1.1" class="ltx_sup"><span id="S5.SS2.1.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">W</span></sup></span></td>
<td id="S5.SS2.2.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.SS2.2.2.2.2.2.2.1" class="ltx_text ltx_font_bold">CATL-QTA<sup id="S5.SS2.2.2.2.2.2.2.1.1" class="ltx_sup"><span id="S5.SS2.2.2.2.2.2.2.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">W</span></sup></span></td>
</tr>
<tr id="S5.SS2.2.2.2.2.3.1" class="ltx_tr">
<th id="S5.SS2.2.2.2.2.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Scene Recognition</th>
<td id="S5.SS2.2.2.2.2.3.1.2" class="ltx_td ltx_align_center ltx_border_t">93.18</td>
<td id="S5.SS2.2.2.2.2.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">93.45</td>
<td id="S5.SS2.2.2.2.2.3.1.4" class="ltx_td ltx_align_center ltx_border_t">93.31</td>
<td id="S5.SS2.2.2.2.2.3.1.5" class="ltx_td ltx_align_center ltx_border_t">93.80</td>
</tr>
<tr id="S5.SS2.2.2.2.2.4.2" class="ltx_tr">
<th id="S5.SS2.2.2.2.2.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Sport Recognition</th>
<td id="S5.SS2.2.2.2.2.4.2.2" class="ltx_td ltx_align_center">94.69</td>
<td id="S5.SS2.2.2.2.2.4.2.3" class="ltx_td ltx_align_center ltx_border_r">95.45</td>
<td id="S5.SS2.2.2.2.2.4.2.4" class="ltx_td ltx_align_center">94.96</td>
<td id="S5.SS2.2.2.2.2.4.2.5" class="ltx_td ltx_align_center">95.55</td>
</tr>
<tr id="S5.SS2.2.2.2.2.5.3" class="ltx_tr" style="background-color:#B3B3FF;">
<th id="S5.SS2.2.2.2.2.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.SS2.2.2.2.2.5.3.1.1" class="ltx_text" style="background-color:#B3B3FF;">Color Attributes</span></th>
<td id="S5.SS2.2.2.2.2.5.3.2" class="ltx_td ltx_align_center"><span id="S5.SS2.2.2.2.2.5.3.2.1" class="ltx_text" style="background-color:#B3B3FF;">54.66</span></td>
<td id="S5.SS2.2.2.2.2.5.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.SS2.2.2.2.2.5.3.3.1" class="ltx_text" style="background-color:#B3B3FF;">56.08</span></td>
<td id="S5.SS2.2.2.2.2.5.3.4" class="ltx_td ltx_align_center"><span id="S5.SS2.2.2.2.2.5.3.4.1" class="ltx_text" style="background-color:#B3B3FF;">57.59</span></td>
<td id="S5.SS2.2.2.2.2.5.3.5" class="ltx_td ltx_align_center"><span id="S5.SS2.2.2.2.2.5.3.5.1" class="ltx_text" style="background-color:#B3B3FF;">60.16</span></td>
</tr>
<tr id="S5.SS2.2.2.2.2.6.4" class="ltx_tr">
<th id="S5.SS2.2.2.2.2.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Other Attributes</th>
<td id="S5.SS2.2.2.2.2.6.4.2" class="ltx_td ltx_align_center">48.52</td>
<td id="S5.SS2.2.2.2.2.6.4.3" class="ltx_td ltx_align_center ltx_border_r">50.30</td>
<td id="S5.SS2.2.2.2.2.6.4.4" class="ltx_td ltx_align_center">52.25</td>
<td id="S5.SS2.2.2.2.2.6.4.5" class="ltx_td ltx_align_center">54.36</td>
</tr>
<tr id="S5.SS2.2.2.2.2.7.5" class="ltx_tr" style="background-color:#B3B3FF;">
<th id="S5.SS2.2.2.2.2.7.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.SS2.2.2.2.2.7.5.1.1" class="ltx_text" style="background-color:#B3B3FF;">Activity Recognition</span></th>
<td id="S5.SS2.2.2.2.2.7.5.2" class="ltx_td ltx_align_center"><span id="S5.SS2.2.2.2.2.7.5.2.1" class="ltx_text" style="background-color:#B3B3FF;">53.36</span></td>
<td id="S5.SS2.2.2.2.2.7.5.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.SS2.2.2.2.2.7.5.3.1" class="ltx_text" style="background-color:#B3B3FF;">58.43</span></td>
<td id="S5.SS2.2.2.2.2.7.5.4" class="ltx_td ltx_align_center"><span id="S5.SS2.2.2.2.2.7.5.4.1" class="ltx_text" style="background-color:#B3B3FF;">54.59</span></td>
<td id="S5.SS2.2.2.2.2.7.5.5" class="ltx_td ltx_align_center"><span id="S5.SS2.2.2.2.2.7.5.5.1" class="ltx_text" style="background-color:#B3B3FF;">60.10</span></td>
</tr>
<tr id="S5.SS2.2.2.2.2.8.6" class="ltx_tr">
<th id="S5.SS2.2.2.2.2.8.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Positional Reasoning</th>
<td id="S5.SS2.2.2.2.2.8.6.2" class="ltx_td ltx_align_center">32.73</td>
<td id="S5.SS2.2.2.2.2.8.6.3" class="ltx_td ltx_align_center ltx_border_r">31.94</td>
<td id="S5.SS2.2.2.2.2.8.6.4" class="ltx_td ltx_align_center">33.63</td>
<td id="S5.SS2.2.2.2.2.8.6.5" class="ltx_td ltx_align_center">34.71</td>
</tr>
<tr id="S5.SS2.2.2.2.2.9.7" class="ltx_tr">
<th id="S5.SS2.2.2.2.2.9.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Sub. Object Recognition</th>
<td id="S5.SS2.2.2.2.2.9.7.2" class="ltx_td ltx_align_center">86.56</td>
<td id="S5.SS2.2.2.2.2.9.7.3" class="ltx_td ltx_align_center ltx_border_r">86.76</td>
<td id="S5.SS2.2.2.2.2.9.7.4" class="ltx_td ltx_align_center">86.52</td>
<td id="S5.SS2.2.2.2.2.9.7.5" class="ltx_td ltx_align_center">86.98</td>
</tr>
<tr id="S5.SS2.2.2.2.2.10.8" class="ltx_tr">
<th id="S5.SS2.2.2.2.2.10.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Absurd</th>
<td id="S5.SS2.2.2.2.2.10.8.2" class="ltx_td ltx_align_center">95.03</td>
<td id="S5.SS2.2.2.2.2.10.8.3" class="ltx_td ltx_align_center ltx_border_r">100.00</td>
<td id="S5.SS2.2.2.2.2.10.8.4" class="ltx_td ltx_align_center">98.01</td>
<td id="S5.SS2.2.2.2.2.10.8.5" class="ltx_td ltx_align_center">100.00</td>
</tr>
<tr id="S5.SS2.2.2.2.2.11.9" class="ltx_tr">
<th id="S5.SS2.2.2.2.2.11.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Utility and Affordances</th>
<td id="S5.SS2.2.2.2.2.11.9.2" class="ltx_td ltx_align_center">29.01</td>
<td id="S5.SS2.2.2.2.2.11.9.3" class="ltx_td ltx_align_center ltx_border_r">23.46</td>
<td id="S5.SS2.2.2.2.2.11.9.4" class="ltx_td ltx_align_center">29.01</td>
<td id="S5.SS2.2.2.2.2.11.9.5" class="ltx_td ltx_align_center">31.48</td>
</tr>
<tr id="S5.SS2.2.2.2.2.12.10" class="ltx_tr">
<th id="S5.SS2.2.2.2.2.12.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Object Presence</th>
<td id="S5.SS2.2.2.2.2.12.10.2" class="ltx_td ltx_align_center">93.34</td>
<td id="S5.SS2.2.2.2.2.12.10.3" class="ltx_td ltx_align_center ltx_border_r">93.48</td>
<td id="S5.SS2.2.2.2.2.12.10.4" class="ltx_td ltx_align_center">94.13</td>
<td id="S5.SS2.2.2.2.2.12.10.5" class="ltx_td ltx_align_center">94.55</td>
</tr>
<tr id="S5.SS2.2.2.2.2.13.11" class="ltx_tr">
<th id="S5.SS2.2.2.2.2.13.11.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Counting</th>
<td id="S5.SS2.2.2.2.2.13.11.2" class="ltx_td ltx_align_center">50.08</td>
<td id="S5.SS2.2.2.2.2.13.11.3" class="ltx_td ltx_align_center ltx_border_r">49.93</td>
<td id="S5.SS2.2.2.2.2.13.11.4" class="ltx_td ltx_align_center">52.97</td>
<td id="S5.SS2.2.2.2.2.13.11.5" class="ltx_td ltx_align_center">53.25</td>
</tr>
<tr id="S5.SS2.2.2.2.2.14.12" class="ltx_tr" style="background-color:#B3B3FF;">
<th id="S5.SS2.2.2.2.2.14.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S5.SS2.2.2.2.2.14.12.1.1" class="ltx_text" style="background-color:#B3B3FF;">Sentiment Understanding</span></th>
<td id="S5.SS2.2.2.2.2.14.12.2" class="ltx_td ltx_align_center"><span id="S5.SS2.2.2.2.2.14.12.2.1" class="ltx_text" style="background-color:#B3B3FF;">56.23</span></td>
<td id="S5.SS2.2.2.2.2.14.12.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S5.SS2.2.2.2.2.14.12.3.1" class="ltx_text" style="background-color:#B3B3FF;">56.87</span></td>
<td id="S5.SS2.2.2.2.2.14.12.4" class="ltx_td ltx_align_center"><span id="S5.SS2.2.2.2.2.14.12.4.1" class="ltx_text" style="background-color:#B3B3FF;">62.62</span></td>
<td id="S5.SS2.2.2.2.2.14.12.5" class="ltx_td ltx_align_center"><span id="S5.SS2.2.2.2.2.14.12.5.1" class="ltx_text" style="background-color:#B3B3FF;">64.38</span></td>
</tr>
<tr id="S5.SS2.2.2.2.2.15.13" class="ltx_tr">
<th id="S5.SS2.2.2.2.2.15.13.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Overall (Arithmetic MPT)</th>
<td id="S5.SS2.2.2.2.2.15.13.2" class="ltx_td ltx_align_center ltx_border_t">65.62</td>
<td id="S5.SS2.2.2.2.2.15.13.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">66.34</td>
<td id="S5.SS2.2.2.2.2.15.13.4" class="ltx_td ltx_align_center ltx_border_t">67.46</td>
<td id="S5.SS2.2.2.2.2.15.13.5" class="ltx_td ltx_align_center ltx_border_t">69.11</td>
</tr>
<tr id="S5.SS2.2.2.2.2.16.14" class="ltx_tr">
<th id="S5.SS2.2.2.2.2.16.14.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Overall (Harmonic MPT)</th>
<td id="S5.SS2.2.2.2.2.16.14.2" class="ltx_td ltx_align_center">55.95</td>
<td id="S5.SS2.2.2.2.2.16.14.3" class="ltx_td ltx_align_center ltx_border_r">54.60</td>
<td id="S5.SS2.2.2.2.2.16.14.4" class="ltx_td ltx_align_center">57.83</td>
<td id="S5.SS2.2.2.2.2.16.14.5" class="ltx_td ltx_align_center">60.08</td>
</tr>
<tr id="S5.SS2.2.2.2.2.17.15" class="ltx_tr">
<th id="S5.SS2.2.2.2.2.17.15.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t">Overall Accuracy</th>
<td id="S5.SS2.2.2.2.2.17.15.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">82.23</td>
<td id="S5.SS2.2.2.2.2.17.15.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">83.62</td>
<td id="S5.SS2.2.2.2.2.17.15.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">83.92</td>
<td id="S5.SS2.2.2.2.2.17.15.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">85.03</td>
</tr>
</tbody>
</table>
</span></div>
</div>
<figure id="S5.T4" class="ltx_table ltx_align_center">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>QTA in concatenation models on TDIUC dataset</figcaption>
</figure>
</div>
<div id="S5.SS2.5.5" class="ltx_logical-block ltx_minipage ltx_align_bottom" style="width:238.5pt;">
<div id="S5.SS2.5.5.p1" class="ltx_para">
<img src="/html/1804.02088/assets/information-attention.png" id="S5.SS2.4.4.g1" class="ltx_graphics ltx_img_landscape" width="216" height="157" alt="[Uncaptioned image]">
</div>
<figure id="S5.F5" class="ltx_figure ltx_align_center">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Evaluation of different ways to utilize information from question type</figcaption>
</figure>
</div>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>QTA in concatenation models</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.2" class="ltx_p">We use QTA in concatenation models to study the effect of QTA. The framework is in FigureÂ <a href="#S3.F2" title="Figure 2 â€£ 3 Question Type Guided Visual Attention â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. We compare the network using a weighted feature with the same network using an unweighted concatenated image feature in TableÂ <a href="#S5.T4" title="Table 4 â€£ 5.2 Pre-trained and Jointly-trained Text Feature Extractors â€£ 5 Results and Analysis â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. As we can see, the model using the weighted feature has more power than the one using the unweighted feature. 9 out of 12 categories get improved results. â€œColorâ€ and â€œActivity Recognitionâ€ get around 2<math id="S5.SS3.p1.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S5.SS3.p1.1.m1.1a"><mo id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.1b"><csymbol cd="latexml" id="S5.SS3.p1.1.m1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.1c">\%</annotation></semantics></math> and 6<math id="S5.SS3.p1.2.m2.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S5.SS3.p1.2.m2.1a"><mo id="S5.SS3.p1.2.m2.1.1" xref="S5.SS3.p1.2.m2.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.2.m2.1b"><csymbol cd="latexml" id="S5.SS3.p1.2.m2.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.2.m2.1c">\%</annotation></semantics></math> accuracy increases.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">To ensure that the improvement is not because of the added question type information but the attention mechanism using question type, we show the comparison of QTA with QT in FigureÂ 
<a href="#S5.F5" title="Figure 5 â€£ 5.2 Pre-trained and Jointly-trained Text Feature Extractors â€£ 5 Results and Analysis â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. With same text feature and image feature and approximately same number of parameters in the network, QTA is 3-5<math id="S5.SS3.p2.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S5.SS3.p2.1.m1.1a"><mo id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.1b"><csymbol cd="latexml" id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.1c">\%</annotation></semantics></math> better than QT.</p>
</div>
<div id="S5.SS3.p3" class="ltx_para">
<p id="S5.SS3.p3.1" class="ltx_p">We show the effect of QTA on image feature norms in FigureÂ <a href="#S5.F6" title="Figure 6 â€£ 5.3 QTA in concatenation models â€£ 5 Results and Analysis â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. By weighing the image features by question type, we find that our model relies more on Faster R-CNN features for â€œAbsurdâ€ question samples while it relies more on ResNet features for â€œColorâ€ questions.</p>
</div>
<figure id="S5.F6" class="ltx_figure"><img src="/html/1804.02088/assets/feature_norm.png" id="S5.F6.g1" class="ltx_graphics ltx_centering ltx_img_square" width="275" height="236" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Effects of weighting by QTA. Top: raw feature norms, Middle: feature norms weighted by QTA, Bottom: differences of norms after weighting vs before weighting. For color questions, the feature norms shift towards ResNet features, while for absurd questions they shift towards Faster-RCNN features.</figcaption>
</figure>
<div id="S5.SS3.p4" class="ltx_para">
<p id="S5.SS3.p4.1" class="ltx_p">The best setting we get in concatenation model is using a weighted image feature concatenated with the output of the LSTM and Word2Vec feature(CATL-QTA<sup id="S5.SS3.p4.1.1" class="ltx_sup"><span id="S5.SS3.p4.1.1.1" class="ltx_text ltx_font_italic">W</span></sup>). It gets 5% improvement compared to complicated deep network such as RAU and MCB-A in TableÂ <a href="#S5.T5" title="Table 5 â€£ 5.3 QTA in concatenation models â€£ 5 Results and Analysis â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<figure id="S5.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Results of QTA models on TDIUC dataset compared to state-of-art models</figcaption>
<div id="S5.T5.1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:371.0pt;height:231.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-46.4pt,28.8pt) scale(0.8,0.8) ;">
<table id="S5.T5.1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T5.1.1.1.1" class="ltx_tr">
<th id="S5.T5.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_tt">Accuracy(%)</th>
<td id="S5.T5.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T5.1.1.1.1.1.1" class="ltx_text ltx_font_bold">CATL-QTA<sup id="S5.T5.1.1.1.1.1.1.1" class="ltx_sup"><span id="S5.T5.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">W</span></sup></span></td>
<td id="S5.T5.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt"><span id="S5.T5.1.1.1.1.3.1" class="ltx_text ltx_font_bold">MCB-QTA</span></td>
<td id="S5.T5.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S5.T5.1.1.1.1.4.1" class="ltx_text ltx_font_bold">MCB-A</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>
</td>
<td id="S5.T5.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S5.T5.1.1.1.1.5.1" class="ltx_text ltx_font_bold">RAU</span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>
</td>
</tr>
<tr id="S5.T5.1.1.1.2.1" class="ltx_tr">
<th id="S5.T5.1.1.1.2.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Scene Recognition</th>
<td id="S5.T5.1.1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">93.80</td>
<td id="S5.T5.1.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">93.56</td>
<td id="S5.T5.1.1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">93.06</td>
<td id="S5.T5.1.1.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T5.1.1.1.2.1.5.1" class="ltx_text ltx_font_bold">93.96</span></td>
</tr>
<tr id="S5.T5.1.1.1.3.2" class="ltx_tr">
<th id="S5.T5.1.1.1.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Sport Recognition</th>
<td id="S5.T5.1.1.1.3.2.2" class="ltx_td ltx_align_center">95.55</td>
<td id="S5.T5.1.1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T5.1.1.1.3.2.3.1" class="ltx_text ltx_font_bold">95.70</span></td>
<td id="S5.T5.1.1.1.3.2.4" class="ltx_td ltx_align_center">92.77</td>
<td id="S5.T5.1.1.1.3.2.5" class="ltx_td ltx_align_center">93.47</td>
</tr>
<tr id="S5.T5.1.1.1.4.3" class="ltx_tr">
<th id="S5.T5.1.1.1.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Color Attributes</th>
<td id="S5.T5.1.1.1.4.3.2" class="ltx_td ltx_align_center">60.16</td>
<td id="S5.T5.1.1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_rr">59.82</td>
<td id="S5.T5.1.1.1.4.3.4" class="ltx_td ltx_align_center"><span id="S5.T5.1.1.1.4.3.4.1" class="ltx_text ltx_font_bold">68.54</span></td>
<td id="S5.T5.1.1.1.4.3.5" class="ltx_td ltx_align_center">66.86</td>
</tr>
<tr id="S5.T5.1.1.1.5.4" class="ltx_tr">
<th id="S5.T5.1.1.1.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Other Attributes</th>
<td id="S5.T5.1.1.1.5.4.2" class="ltx_td ltx_align_center">54.36</td>
<td id="S5.T5.1.1.1.5.4.3" class="ltx_td ltx_align_center ltx_border_rr">54.06</td>
<td id="S5.T5.1.1.1.5.4.4" class="ltx_td ltx_align_center"><span id="S5.T5.1.1.1.5.4.4.1" class="ltx_text ltx_font_bold">56.72</span></td>
<td id="S5.T5.1.1.1.5.4.5" class="ltx_td ltx_align_center">56.49</td>
</tr>
<tr id="S5.T5.1.1.1.6.5" class="ltx_tr">
<th id="S5.T5.1.1.1.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Activity Recognition</th>
<td id="S5.T5.1.1.1.6.5.2" class="ltx_td ltx_align_center">60.10</td>
<td id="S5.T5.1.1.1.6.5.3" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T5.1.1.1.6.5.3.1" class="ltx_text ltx_font_bold">60.55</span></td>
<td id="S5.T5.1.1.1.6.5.4" class="ltx_td ltx_align_center">52.35</td>
<td id="S5.T5.1.1.1.6.5.5" class="ltx_td ltx_align_center">51.60</td>
</tr>
<tr id="S5.T5.1.1.1.7.6" class="ltx_tr">
<th id="S5.T5.1.1.1.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Positional Reasoning</th>
<td id="S5.T5.1.1.1.7.6.2" class="ltx_td ltx_align_center">34.71</td>
<td id="S5.T5.1.1.1.7.6.3" class="ltx_td ltx_align_center ltx_border_rr">34.00</td>
<td id="S5.T5.1.1.1.7.6.4" class="ltx_td ltx_align_center"><span id="S5.T5.1.1.1.7.6.4.1" class="ltx_text ltx_font_bold">35.40</span></td>
<td id="S5.T5.1.1.1.7.6.5" class="ltx_td ltx_align_center">35.26</td>
</tr>
<tr id="S5.T5.1.1.1.8.7" class="ltx_tr">
<th id="S5.T5.1.1.1.8.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Sub. Object Recognition</th>
<td id="S5.T5.1.1.1.8.7.2" class="ltx_td ltx_align_center">86.98</td>
<td id="S5.T5.1.1.1.8.7.3" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T5.1.1.1.8.7.3.1" class="ltx_text ltx_font_bold">87.00</span></td>
<td id="S5.T5.1.1.1.8.7.4" class="ltx_td ltx_align_center">85.54</td>
<td id="S5.T5.1.1.1.8.7.5" class="ltx_td ltx_align_center">86.11</td>
</tr>
<tr id="S5.T5.1.1.1.9.8" class="ltx_tr">
<th id="S5.T5.1.1.1.9.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Absurd</th>
<td id="S5.T5.1.1.1.9.8.2" class="ltx_td ltx_align_center"><span id="S5.T5.1.1.1.9.8.2.1" class="ltx_text ltx_font_bold">100.00</span></td>
<td id="S5.T5.1.1.1.9.8.3" class="ltx_td ltx_align_center ltx_border_rr">100.00</td>
<td id="S5.T5.1.1.1.9.8.4" class="ltx_td ltx_align_center">84.82</td>
<td id="S5.T5.1.1.1.9.8.5" class="ltx_td ltx_align_center">96.08</td>
</tr>
<tr id="S5.T5.1.1.1.10.9" class="ltx_tr">
<th id="S5.T5.1.1.1.10.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Utility and Affordances</th>
<td id="S5.T5.1.1.1.10.9.2" class="ltx_td ltx_align_center">31.48</td>
<td id="S5.T5.1.1.1.10.9.3" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T5.1.1.1.10.9.3.1" class="ltx_text ltx_font_bold">37.04</span></td>
<td id="S5.T5.1.1.1.10.9.4" class="ltx_td ltx_align_center">35.09</td>
<td id="S5.T5.1.1.1.10.9.5" class="ltx_td ltx_align_center">31.58</td>
</tr>
<tr id="S5.T5.1.1.1.11.10" class="ltx_tr">
<th id="S5.T5.1.1.1.11.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Object Presence</th>
<td id="S5.T5.1.1.1.11.10.2" class="ltx_td ltx_align_center"><span id="S5.T5.1.1.1.11.10.2.1" class="ltx_text ltx_font_bold">94.55</span></td>
<td id="S5.T5.1.1.1.11.10.3" class="ltx_td ltx_align_center ltx_border_rr">94.34</td>
<td id="S5.T5.1.1.1.11.10.4" class="ltx_td ltx_align_center">93.64</td>
<td id="S5.T5.1.1.1.11.10.5" class="ltx_td ltx_align_center">94.38</td>
</tr>
<tr id="S5.T5.1.1.1.12.11" class="ltx_tr">
<th id="S5.T5.1.1.1.12.11.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Counting</th>
<td id="S5.T5.1.1.1.12.11.2" class="ltx_td ltx_align_center">53.25</td>
<td id="S5.T5.1.1.1.12.11.3" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T5.1.1.1.12.11.3.1" class="ltx_text ltx_font_bold">53.99</span></td>
<td id="S5.T5.1.1.1.12.11.4" class="ltx_td ltx_align_center">51.01</td>
<td id="S5.T5.1.1.1.12.11.5" class="ltx_td ltx_align_center">48.43</td>
</tr>
<tr id="S5.T5.1.1.1.13.12" class="ltx_tr">
<th id="S5.T5.1.1.1.13.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Sentiment Understanding</th>
<td id="S5.T5.1.1.1.13.12.2" class="ltx_td ltx_align_center">64.38</td>
<td id="S5.T5.1.1.1.13.12.3" class="ltx_td ltx_align_center ltx_border_rr">65.65</td>
<td id="S5.T5.1.1.1.13.12.4" class="ltx_td ltx_align_center"><span id="S5.T5.1.1.1.13.12.4.1" class="ltx_text ltx_font_bold">66.25</span></td>
<td id="S5.T5.1.1.1.13.12.5" class="ltx_td ltx_align_center">60.09</td>
</tr>
<tr id="S5.T5.1.1.1.14.13" class="ltx_tr">
<th id="S5.T5.1.1.1.14.13.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Overall (Arithmetic MPT)</th>
<td id="S5.T5.1.1.1.14.13.2" class="ltx_td ltx_align_center ltx_border_t">69.11</td>
<td id="S5.T5.1.1.1.14.13.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t"><span id="S5.T5.1.1.1.14.13.3.1" class="ltx_text ltx_font_bold">69.69</span></td>
<td id="S5.T5.1.1.1.14.13.4" class="ltx_td ltx_align_center ltx_border_t">67.90</td>
<td id="S5.T5.1.1.1.14.13.5" class="ltx_td ltx_align_center ltx_border_t">67.81</td>
</tr>
<tr id="S5.T5.1.1.1.15.14" class="ltx_tr">
<th id="S5.T5.1.1.1.15.14.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Overall (Harmonic MPT)</th>
<td id="S5.T5.1.1.1.15.14.2" class="ltx_td ltx_align_center">60.08</td>
<td id="S5.T5.1.1.1.15.14.3" class="ltx_td ltx_align_center ltx_border_rr"><span id="S5.T5.1.1.1.15.14.3.1" class="ltx_text ltx_font_bold">61.56</span></td>
<td id="S5.T5.1.1.1.15.14.4" class="ltx_td ltx_align_center">60.47</td>
<td id="S5.T5.1.1.1.15.14.5" class="ltx_td ltx_align_center">59.00</td>
</tr>
<tr id="S5.T5.1.1.1.16.15" class="ltx_tr">
<th id="S5.T5.1.1.1.16.15.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t">Overall Accuracy</th>
<td id="S5.T5.1.1.1.16.15.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t"><span id="S5.T5.1.1.1.16.15.2.1" class="ltx_text ltx_font_bold">85.03</span></td>
<td id="S5.T5.1.1.1.16.15.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr ltx_border_t">84.97</td>
<td id="S5.T5.1.1.1.16.15.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">81.86</td>
<td id="S5.T5.1.1.1.16.15.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">84.26</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>QTA in pooling models</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">To show how to combine QTA with more complicated feature integration operator, we propose MCB-QTA structure. Even though MCB-QTA in TableÂ <a href="#S5.T5" title="Table 5 â€£ 5.3 QTA in concatenation models â€£ 5 Results and Analysis â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> doesnâ€™t win with simple accuracy, it shows great performance in many categories such as â€œObject Recognitionâ€ and â€œCountingâ€. Accuracy in â€œUtility and Affordancesâ€ is improved by 6% compared to our CATL-QTA model. It gets 8% improvement in â€œActivity recognitionâ€ compared to state-of-art model MCB-A and also gets the best Arithmetic and Harmonic MPT value.</p>
</div>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Multi-task analysis</h3>

<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.1" class="ltx_p">In this part, we will discuss how we use QTA when we have questions without specific question types.
It is quite easy to predict the question type from the question itself. We use a 2-layer LSTM followed by a classifier and the test accuracy is 96% after 9 epochs. The problem is whether we can predict the question type while keeping the same performance for VQA task or not.
As described in FigureÂ <a href="#S3.F3" title="Figure 3 â€£ 3 Question Type Guided Visual Attention â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we use the predicted question type as input of the QTA network in a multi-task setting. We get 84.33% test simple accuracy for VQA task as shown in TableÂ <a href="#S6.T9" title="Table 9 â€£ 6 Conclusion â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>.
When we compare it to MCB-A or RAU in TableÂ <a href="#S5.T5" title="Table 5 â€£ 5.3 QTA in concatenation models â€£ 5 Results and Analysis â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, though accuracy gets a little affected for most of the categories, we still get 2% improvement in â€œSports Recognitionâ€ and â€œCountingâ€.</p>
</div>
<div id="S5.SS5.p2" class="ltx_para">
<p id="S5.SS5.p2.1" class="ltx_p">We fine-tune our model on VQA v1 using a pre-trained multi-task model that was trained on TDIUC. We use the question type predictor in the multi-task model as the input of QTA. Our modelâ€™s performance is better than MCB in TableÂ <a href="#S5.T6" title="Table 6 â€£ 5.5 Multi-task analysis â€£ 5 Results and Analysis â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> with an approximately same number of parameters in the network.</p>
</div>
<figure id="S5.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Results of test-dev accuracy on VQA v1.
Models are trained on the VQA v1 train split and tested on test-dev</figcaption>
<div id="S5.T6.2.2" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:209.1pt;height:115.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-26.1pt,14.4pt) scale(0.8,0.8) ;">
<table id="S5.T6.2.2.2" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T6.2.2.2.3.1" class="ltx_tr">
<th id="S5.T6.2.2.2.3.1.1" class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_tt"></th>
<th id="S5.T6.2.2.2.3.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt"><span id="S5.T6.2.2.2.3.1.2.1" class="ltx_text ltx_font_bold">Accuracy(%)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T6.2.2.2.4.1" class="ltx_tr">
<td id="S5.T6.2.2.2.4.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Element-wise SumÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>
</td>
<td id="S5.T6.2.2.2.4.1.2" class="ltx_td ltx_align_center ltx_border_t">56.50</td>
</tr>
<tr id="S5.T6.2.2.2.5.2" class="ltx_tr">
<td id="S5.T6.2.2.2.5.2.1" class="ltx_td ltx_align_center ltx_border_r">ConcatenationÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>
</td>
<td id="S5.T6.2.2.2.5.2.2" class="ltx_td ltx_align_center">57.49</td>
</tr>
<tr id="S5.T6.2.2.2.6.3" class="ltx_tr">
<td id="S5.T6.2.2.2.6.3.1" class="ltx_td ltx_align_center ltx_border_r">Concatenation + FCÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>
</td>
<td id="S5.T6.2.2.2.6.3.2" class="ltx_td ltx_align_center">58.40</td>
</tr>
<tr id="S5.T6.2.2.2.7.4" class="ltx_tr">
<td id="S5.T6.2.2.2.7.4.1" class="ltx_td ltx_align_center ltx_border_r">Element-wise ProductÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>
</td>
<td id="S5.T6.2.2.2.7.4.2" class="ltx_td ltx_align_center">58.57</td>
</tr>
<tr id="S5.T6.2.2.2.8.5" class="ltx_tr">
<td id="S5.T6.2.2.2.8.5.1" class="ltx_td ltx_align_center ltx_border_r">Element-wise Product + FCÂ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>
</td>
<td id="S5.T6.2.2.2.8.5.2" class="ltx_td ltx_align_center">56.44</td>
</tr>
<tr id="S5.T6.2.2.2.2" class="ltx_tr">
<td id="S5.T6.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r">MCB(2048 <math id="S5.T6.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S5.T6.1.1.1.1.1.m1.1a"><mo id="S5.T6.1.1.1.1.1.m1.1.1" xref="S5.T6.1.1.1.1.1.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S5.T6.1.1.1.1.1.m1.1b"><times id="S5.T6.1.1.1.1.1.m1.1.1.cmml" xref="S5.T6.1.1.1.1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.1.1.1.1.1.m1.1c">\times</annotation></semantics></math> 2048 <math id="S5.T6.2.2.2.2.2.m2.1" class="ltx_Math" alttext="\rightarrow" display="inline"><semantics id="S5.T6.2.2.2.2.2.m2.1a"><mo stretchy="false" id="S5.T6.2.2.2.2.2.m2.1.1" xref="S5.T6.2.2.2.2.2.m2.1.1.cmml">â†’</mo><annotation-xml encoding="MathML-Content" id="S5.T6.2.2.2.2.2.m2.1b"><ci id="S5.T6.2.2.2.2.2.m2.1.1.cmml" xref="S5.T6.2.2.2.2.2.m2.1.1">â†’</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T6.2.2.2.2.2.m2.1c">\rightarrow</annotation></semantics></math> 16K)Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>
</td>
<td id="S5.T6.2.2.2.2.3" class="ltx_td ltx_align_center">59.83</td>
</tr>
<tr id="S5.T6.2.2.2.9.6" class="ltx_tr">
<td id="S5.T6.2.2.2.9.6.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">CATL-QTA-M + FC</td>
<td id="S5.T6.2.2.2.9.6.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T6.2.2.2.9.6.2.1" class="ltx_text ltx_font_bold">60.32</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S5.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.6 </span>Findings on TDIUC dataset</h3>

<div id="S5.SS6.p1" class="ltx_para">
<p id="S5.SS6.p1.1" class="ltx_p">To further analyze the effects of the question type prediction part in this multi-task framework, we list the confusion matrix for the question type prediction results in TableÂ <a href="#S5.T7" title="Table 7 â€£ 5.6 Findings on TDIUC dataset â€£ 5 Results and Analysis â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. â€œColorâ€ and â€œAbsurdâ€ question type predictions are most often bi-directionally confused. The reason for this is that among all absurd questions, more than 60% are questions start with â€œWhat colorâ€. To avoid this bias, we remove all absurd questions and run our multi-task model again. In this setting, our question type prediction did much better than before. Almost all categories get 99% accuracy as shown in TableÂ <a href="#S6.T8" title="Table 8 â€£ 6 Conclusion â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>.
We also compare our QTA modelsâ€™ performance without absurd questions in TableÂ <a href="#S6.T9" title="Table 9 â€£ 6 Conclusion â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>. In CATL-QTA network, removing absurd questions doesnâ€™t help much because in test we feed in the true question type labels. But it is useful when we consider the multi-task model. From third and fourth columns, we see that without absurd questions, we get improved performance among all categories. This is because we remove the absurd questions that may mislead the network to predict â€œcolorâ€ question type in the test.</p>
</div>
<figure id="S5.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Confusion matrix for test question types prediction in CATL-QTA-M using TDIUC dataset. 1. Other Attributes
2. Sentiment Understanding
3. Sports Recognition
4. Position Reasoning
5. Object Utilities/Affordances
6. Activity Recognition
7. Scene Classification
8. Color
9. Object Recognition
10.Object Presence
11.Counting
12. Absurd</figcaption>
<div id="S5.T7.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:415.3pt;height:202.4pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-51.9pt,25.2pt) scale(0.8,0.8) ;">
<table id="S5.T7.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S5.T7.1.1.1.1" class="ltx_tr">
<th id="S5.T7.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Target</th>
<th id="S5.T7.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="12">Predicted</th>
<th id="S5.T7.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Acc(%)</th>
</tr>
<tr id="S5.T7.1.1.2.2" class="ltx_tr">
<th id="S5.T7.1.1.2.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"></th>
<th id="S5.T7.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">1</th>
<th id="S5.T7.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">2</th>
<th id="S5.T7.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">3</th>
<th id="S5.T7.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">4</th>
<th id="S5.T7.1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">5</th>
<th id="S5.T7.1.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">6</th>
<th id="S5.T7.1.1.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">7</th>
<th id="S5.T7.1.1.2.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">8</th>
<th id="S5.T7.1.1.2.2.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">9</th>
<th id="S5.T7.1.1.2.2.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">10</th>
<th id="S5.T7.1.1.2.2.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">11</th>
<th id="S5.T7.1.1.2.2.13" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">12</th>
<th id="S5.T7.1.1.2.2.14" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">95.66</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S5.T7.1.1.3.1" class="ltx_tr">
<th id="S5.T7.1.1.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">1</th>
<td id="S5.T7.1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#BFFFBF;"><span id="S5.T7.1.1.3.1.2.1" class="ltx_text" style="background-color:#BFFFBF;">77.76</span></td>
<td id="S5.T7.1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t">0.00</td>
<td id="S5.T7.1.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t">0.89</td>
<td id="S5.T7.1.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t">3.20</td>
<td id="S5.T7.1.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t">0.00</td>
<td id="S5.T7.1.1.3.1.7" class="ltx_td ltx_align_center ltx_border_t">0.08</td>
<td id="S5.T7.1.1.3.1.8" class="ltx_td ltx_align_center ltx_border_t">0.42</td>
<td id="S5.T7.1.1.3.1.9" class="ltx_td ltx_align_center ltx_border_t">1.15</td>
<td id="S5.T7.1.1.3.1.10" class="ltx_td ltx_align_center ltx_border_t">0.12</td>
<td id="S5.T7.1.1.3.1.11" class="ltx_td ltx_align_center ltx_border_t">0.00</td>
<td id="S5.T7.1.1.3.1.12" class="ltx_td ltx_align_center ltx_border_t">0.00</td>
<td id="S5.T7.1.1.3.1.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" style="background-color:#FFBFBF;"><span id="S5.T7.1.1.3.1.13.1" class="ltx_text" style="background-color:#FFBFBF;">16.38</span></td>
<td id="S5.T7.1.1.3.1.14" class="ltx_td"></td>
</tr>
<tr id="S5.T7.1.1.4.2" class="ltx_tr">
<th id="S5.T7.1.1.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">2</th>
<td id="S5.T7.1.1.4.2.2" class="ltx_td ltx_align_center">0.80</td>
<td id="S5.T7.1.1.4.2.3" class="ltx_td ltx_align_center" style="background-color:#BFFFBF;"><span id="S5.T7.1.1.4.2.3.1" class="ltx_text" style="background-color:#BFFFBF;">60.51</span></td>
<td id="S5.T7.1.1.4.2.4" class="ltx_td ltx_align_center">1.77</td>
<td id="S5.T7.1.1.4.2.5" class="ltx_td ltx_align_center">8.83</td>
<td id="S5.T7.1.1.4.2.6" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.4.2.7" class="ltx_td ltx_align_center">2.25</td>
<td id="S5.T7.1.1.4.2.8" class="ltx_td ltx_align_center">2.57</td>
<td id="S5.T7.1.1.4.2.9" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.4.2.10" class="ltx_td ltx_align_center">1.44</td>
<td id="S5.T7.1.1.4.2.11" class="ltx_td ltx_align_center">0.96</td>
<td id="S5.T7.1.1.4.2.12" class="ltx_td ltx_align_center">0.16</td>
<td id="S5.T7.1.1.4.2.13" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFBFBF;"><span id="S5.T7.1.1.4.2.13.1" class="ltx_text" style="background-color:#FFBFBF;">20.71</span></td>
<td id="S5.T7.1.1.4.2.14" class="ltx_td"></td>
</tr>
<tr id="S5.T7.1.1.5.3" class="ltx_tr">
<th id="S5.T7.1.1.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">3</th>
<td id="S5.T7.1.1.5.3.2" class="ltx_td ltx_align_center">0.31</td>
<td id="S5.T7.1.1.5.3.3" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.5.3.4" class="ltx_td ltx_align_center" style="background-color:#BFFFBF;"><span id="S5.T7.1.1.5.3.4.1" class="ltx_text" style="background-color:#BFFFBF;">73.08</span></td>
<td id="S5.T7.1.1.5.3.5" class="ltx_td ltx_align_center">0.37</td>
<td id="S5.T7.1.1.5.3.6" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.5.3.7" class="ltx_td ltx_align_center">0.17</td>
<td id="S5.T7.1.1.5.3.8" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.5.3.9" class="ltx_td ltx_align_center">0.03</td>
<td id="S5.T7.1.1.5.3.10" class="ltx_td ltx_align_center">0.02</td>
<td id="S5.T7.1.1.5.3.11" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.5.3.12" class="ltx_td ltx_align_center">0.01</td>
<td id="S5.T7.1.1.5.3.13" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFBFBF;"><span id="S5.T7.1.1.5.3.13.1" class="ltx_text" style="background-color:#FFBFBF;">26.01</span></td>
<td id="S5.T7.1.1.5.3.14" class="ltx_td"></td>
</tr>
<tr id="S5.T7.1.1.6.4" class="ltx_tr">
<th id="S5.T7.1.1.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">4</th>
<td id="S5.T7.1.1.6.4.2" class="ltx_td ltx_align_center">2.95</td>
<td id="S5.T7.1.1.6.4.3" class="ltx_td ltx_align_center">0.02</td>
<td id="S5.T7.1.1.6.4.4" class="ltx_td ltx_align_center">0.01</td>
<td id="S5.T7.1.1.6.4.5" class="ltx_td ltx_align_center" style="background-color:#BFFFBF;"><span id="S5.T7.1.1.6.4.5.1" class="ltx_text" style="background-color:#BFFFBF;">89.52</span></td>
<td id="S5.T7.1.1.6.4.6" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.6.4.7" class="ltx_td ltx_align_center">0.01</td>
<td id="S5.T7.1.1.6.4.8" class="ltx_td ltx_align_center">0.02</td>
<td id="S5.T7.1.1.6.4.9" class="ltx_td ltx_align_center">0.19</td>
<td id="S5.T7.1.1.6.4.10" class="ltx_td ltx_align_center">1.88</td>
<td id="S5.T7.1.1.6.4.11" class="ltx_td ltx_align_center">0.03</td>
<td id="S5.T7.1.1.6.4.12" class="ltx_td ltx_align_center">0.03</td>
<td id="S5.T7.1.1.6.4.13" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFBFBF;"><span id="S5.T7.1.1.6.4.13.1" class="ltx_text" style="background-color:#FFBFBF;">5.35</span></td>
<td id="S5.T7.1.1.6.4.14" class="ltx_td"></td>
</tr>
<tr id="S5.T7.1.1.7.5" class="ltx_tr">
<th id="S5.T7.1.1.7.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">5</th>
<td id="S5.T7.1.1.7.5.2" class="ltx_td ltx_align_center">12.50</td>
<td id="S5.T7.1.1.7.5.3" class="ltx_td ltx_align_center">0.63</td>
<td id="S5.T7.1.1.7.5.4" class="ltx_td ltx_align_center">3.12</td>
<td id="S5.T7.1.1.7.5.5" class="ltx_td ltx_align_center" style="background-color:#FFBFBF;"><span id="S5.T7.1.1.7.5.5.1" class="ltx_text" style="background-color:#FFBFBF;">45.62</span></td>
<td id="S5.T7.1.1.7.5.6" class="ltx_td ltx_align_center" style="background-color:#BFFFBF;"><span id="S5.T7.1.1.7.5.6.1" class="ltx_text" style="background-color:#BFFFBF;">0.00</span></td>
<td id="S5.T7.1.1.7.5.7" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.7.5.8" class="ltx_td ltx_align_center">3.12</td>
<td id="S5.T7.1.1.7.5.9" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.7.5.10" class="ltx_td ltx_align_center">11.25</td>
<td id="S5.T7.1.1.7.5.11" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.7.5.12" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.7.5.13" class="ltx_td ltx_align_center ltx_border_r">23.75</td>
<td id="S5.T7.1.1.7.5.14" class="ltx_td"></td>
</tr>
<tr id="S5.T7.1.1.8.6" class="ltx_tr">
<th id="S5.T7.1.1.8.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">6</th>
<td id="S5.T7.1.1.8.6.2" class="ltx_td ltx_align_center">0.79</td>
<td id="S5.T7.1.1.8.6.3" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.8.6.4" class="ltx_td ltx_align_center">14.56</td>
<td id="S5.T7.1.1.8.6.5" class="ltx_td ltx_align_center">1.76</td>
<td id="S5.T7.1.1.8.6.6" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.8.6.7" class="ltx_td ltx_align_center" style="background-color:#BFFFBF;"><span id="S5.T7.1.1.8.6.7.1" class="ltx_text" style="background-color:#BFFFBF;">13.18</span></td>
<td id="S5.T7.1.1.8.6.8" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.8.6.9" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.8.6.10" class="ltx_td ltx_align_center">2.21</td>
<td id="S5.T7.1.1.8.6.11" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.8.6.12" class="ltx_td ltx_align_center">0.07</td>
<td id="S5.T7.1.1.8.6.13" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFBFBF;"><span id="S5.T7.1.1.8.6.13.1" class="ltx_text" style="background-color:#FFBFBF;">67.43</span></td>
<td id="S5.T7.1.1.8.6.14" class="ltx_td"></td>
</tr>
<tr id="S5.T7.1.1.9.7" class="ltx_tr">
<th id="S5.T7.1.1.9.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">7</th>
<td id="S5.T7.1.1.9.7.2" class="ltx_td ltx_align_center">0.04</td>
<td id="S5.T7.1.1.9.7.3" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.9.7.4" class="ltx_td ltx_align_center">0.04</td>
<td id="S5.T7.1.1.9.7.5" class="ltx_td ltx_align_center" style="background-color:#FFBFBF;"><span id="S5.T7.1.1.9.7.5.1" class="ltx_text" style="background-color:#FFBFBF;">0.40</span></td>
<td id="S5.T7.1.1.9.7.6" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.9.7.7" class="ltx_td ltx_align_center">0.01</td>
<td id="S5.T7.1.1.9.7.8" class="ltx_td ltx_align_center" style="background-color:#BFFFBF;"><span id="S5.T7.1.1.9.7.8.1" class="ltx_text" style="background-color:#BFFFBF;">99.40</span></td>
<td id="S5.T7.1.1.9.7.9" class="ltx_td ltx_align_center">0.02</td>
<td id="S5.T7.1.1.9.7.10" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.9.7.11" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.9.7.12" class="ltx_td ltx_align_center">0.06</td>
<td id="S5.T7.1.1.9.7.13" class="ltx_td ltx_align_center ltx_border_r">0.03</td>
<td id="S5.T7.1.1.9.7.14" class="ltx_td"></td>
</tr>
<tr id="S5.T7.1.1.10.8" class="ltx_tr">
<th id="S5.T7.1.1.10.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">8</th>
<td id="S5.T7.1.1.10.8.2" class="ltx_td ltx_align_center">0.32</td>
<td id="S5.T7.1.1.10.8.3" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.10.8.4" class="ltx_td ltx_align_center">0.18</td>
<td id="S5.T7.1.1.10.8.5" class="ltx_td ltx_align_center">0.13</td>
<td id="S5.T7.1.1.10.8.6" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.10.8.7" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.10.8.8" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.10.8.9" class="ltx_td ltx_align_center" style="background-color:#BFFFBF;"><span id="S5.T7.1.1.10.8.9.1" class="ltx_text" style="background-color:#BFFFBF;">86.10</span></td>
<td id="S5.T7.1.1.10.8.10" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.10.8.11" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.10.8.12" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.10.8.13" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFBFBF;"><span id="S5.T7.1.1.10.8.13.1" class="ltx_text" style="background-color:#FFBFBF;">13.28</span></td>
<td id="S5.T7.1.1.10.8.14" class="ltx_td"></td>
</tr>
<tr id="S5.T7.1.1.11.9" class="ltx_tr">
<th id="S5.T7.1.1.11.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">9</th>
<td id="S5.T7.1.1.11.9.2" class="ltx_td ltx_align_center">0.01</td>
<td id="S5.T7.1.1.11.9.3" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.11.9.4" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.11.9.5" class="ltx_td ltx_align_center">0.31</td>
<td id="S5.T7.1.1.11.9.6" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.11.9.7" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.11.9.8" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.11.9.9" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.11.9.10" class="ltx_td ltx_align_center" style="background-color:#BFFFBF;"><span id="S5.T7.1.1.11.9.10.1" class="ltx_text" style="background-color:#BFFFBF;">98.96</span></td>
<td id="S5.T7.1.1.11.9.11" class="ltx_td ltx_align_center">0.01</td>
<td id="S5.T7.1.1.11.9.12" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.11.9.13" class="ltx_td ltx_align_center ltx_border_r" style="background-color:#FFBFBF;"><span id="S5.T7.1.1.11.9.13.1" class="ltx_text" style="background-color:#FFBFBF;">0.71</span></td>
<td id="S5.T7.1.1.11.9.14" class="ltx_td"></td>
</tr>
<tr id="S5.T7.1.1.12.10" class="ltx_tr">
<th id="S5.T7.1.1.12.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">10</th>
<td id="S5.T7.1.1.12.10.2" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.12.10.3" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.12.10.4" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.12.10.5" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.12.10.6" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.12.10.7" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.12.10.8" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.12.10.9" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.12.10.10" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.12.10.11" class="ltx_td ltx_align_center" style="background-color:#BFFFBF;"><span id="S5.T7.1.1.12.10.11.1" class="ltx_text" style="background-color:#BFFFBF;">100.00</span></td>
<td id="S5.T7.1.1.12.10.12" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.12.10.13" class="ltx_td ltx_align_center ltx_border_r">0.00</td>
<td id="S5.T7.1.1.12.10.14" class="ltx_td"></td>
</tr>
<tr id="S5.T7.1.1.13.11" class="ltx_tr">
<th id="S5.T7.1.1.13.11.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">11</th>
<td id="S5.T7.1.1.13.11.2" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.13.11.3" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.13.11.4" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.13.11.5" class="ltx_td ltx_align_center">0.01</td>
<td id="S5.T7.1.1.13.11.6" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.13.11.7" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.13.11.8" class="ltx_td ltx_align_center">0.02</td>
<td id="S5.T7.1.1.13.11.9" class="ltx_td ltx_align_center">0.00</td>
<td id="S5.T7.1.1.13.11.10" class="ltx_td ltx_align_center">0.02</td>
<td id="S5.T7.1.1.13.11.11" class="ltx_td ltx_align_center" style="background-color:#FFBFBF;"><span id="S5.T7.1.1.13.11.11.1" class="ltx_text" style="background-color:#FFBFBF;">0.05</span></td>
<td id="S5.T7.1.1.13.11.12" class="ltx_td ltx_align_center" style="background-color:#BFFFBF;"><span id="S5.T7.1.1.13.11.12.1" class="ltx_text" style="background-color:#BFFFBF;">99.90</span></td>
<td id="S5.T7.1.1.13.11.13" class="ltx_td ltx_align_center ltx_border_r">0.00</td>
<td id="S5.T7.1.1.13.11.14" class="ltx_td"></td>
</tr>
<tr id="S5.T7.1.1.14.12" class="ltx_tr">
<th id="S5.T7.1.1.14.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">12</th>
<td id="S5.T7.1.1.14.12.2" class="ltx_td ltx_align_center ltx_border_bb">0.35</td>
<td id="S5.T7.1.1.14.12.3" class="ltx_td ltx_align_center ltx_border_bb">0.00</td>
<td id="S5.T7.1.1.14.12.4" class="ltx_td ltx_align_center ltx_border_bb">0.18</td>
<td id="S5.T7.1.1.14.12.5" class="ltx_td ltx_align_center ltx_border_bb">0.41</td>
<td id="S5.T7.1.1.14.12.6" class="ltx_td ltx_align_center ltx_border_bb">0.00</td>
<td id="S5.T7.1.1.14.12.7" class="ltx_td ltx_align_center ltx_border_bb">0.03</td>
<td id="S5.T7.1.1.14.12.8" class="ltx_td ltx_align_center ltx_border_bb">0.00</td>
<td id="S5.T7.1.1.14.12.9" class="ltx_td ltx_align_center ltx_border_bb" style="background-color:#FFBFBF;"><span id="S5.T7.1.1.14.12.9.1" class="ltx_text" style="background-color:#FFBFBF;">3.18</span></td>
<td id="S5.T7.1.1.14.12.10" class="ltx_td ltx_align_center ltx_border_bb">0.40</td>
<td id="S5.T7.1.1.14.12.11" class="ltx_td ltx_align_center ltx_border_bb">0.00</td>
<td id="S5.T7.1.1.14.12.12" class="ltx_td ltx_align_center ltx_border_bb">0.00</td>
<td id="S5.T7.1.1.14.12.13" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" style="background-color:#BFFFBF;"><span id="S5.T7.1.1.14.12.13.1" class="ltx_text" style="background-color:#BFFFBF;">95.46</span></td>
<td id="S5.T7.1.1.14.12.14" class="ltx_td ltx_border_bb"></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We propose a question type-guided visual attention (QTA) network. We show empirically that with the question type information, models can balance between bottom-up and top-down visual features and achieve state-of-the-art performance.</p>
</div>
<figure id="S6.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Confusion matrix for test question types prediction in CATL-QTA-M using TDIUC dataset without absurd questions. Numbers represent same categories as in TableÂ <a href="#S5.T7" title="Table 7 â€£ 5.6 Findings on TDIUC dataset â€£ 5 Results and Analysis â€£ Question Type Guided Attention in Visual Question Answering" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a></figcaption>
<div id="S6.T8.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:363.0pt;height:177.1pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-77.8pt,37.8pt) scale(0.7,0.7) ;">
<table id="S6.T8.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T8.1.1.1.1" class="ltx_tr">
<th id="S6.T8.1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt">Target</th>
<th id="S6.T8.1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="12">Predicted</th>
<th id="S6.T8.1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Acc(%)</th>
</tr>
<tr id="S6.T8.1.1.2.2" class="ltx_tr">
<th id="S6.T8.1.1.2.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt"></th>
<th id="S6.T8.1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">1</th>
<th id="S6.T8.1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">2</th>
<th id="S6.T8.1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">3</th>
<th id="S6.T8.1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">4</th>
<th id="S6.T8.1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">5</th>
<th id="S6.T8.1.1.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">6</th>
<th id="S6.T8.1.1.2.2.8" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">7</th>
<th id="S6.T8.1.1.2.2.9" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">8</th>
<th id="S6.T8.1.1.2.2.10" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">9</th>
<th id="S6.T8.1.1.2.2.11" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">10</th>
<th id="S6.T8.1.1.2.2.12" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">11</th>
<th id="S6.T8.1.1.2.2.13" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt">12</th>
<th id="S6.T8.1.1.2.2.14" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">99.50</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T8.1.1.3.1" class="ltx_tr">
<th id="S6.T8.1.1.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">1</th>
<td id="S6.T8.1.1.3.1.2" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#BFFFBF;"><span id="S6.T8.1.1.3.1.2.1" class="ltx_text" style="background-color:#BFFFBF;">98.39</span></td>
<td id="S6.T8.1.1.3.1.3" class="ltx_td ltx_align_center ltx_border_t">0.00</td>
<td id="S6.T8.1.1.3.1.4" class="ltx_td ltx_align_center ltx_border_t">0.07</td>
<td id="S6.T8.1.1.3.1.5" class="ltx_td ltx_align_center ltx_border_t">0.15</td>
<td id="S6.T8.1.1.3.1.6" class="ltx_td ltx_align_center ltx_border_t">0.00</td>
<td id="S6.T8.1.1.3.1.7" class="ltx_td ltx_align_center ltx_border_t">0.13</td>
<td id="S6.T8.1.1.3.1.8" class="ltx_td ltx_align_center ltx_border_t">0.08</td>
<td id="S6.T8.1.1.3.1.9" class="ltx_td ltx_align_center ltx_border_t" style="background-color:#FFBFBF;"><span id="S6.T8.1.1.3.1.9.1" class="ltx_text" style="background-color:#FFBFBF;">0.63</span></td>
<td id="S6.T8.1.1.3.1.10" class="ltx_td ltx_align_center ltx_border_t">0.55</td>
<td id="S6.T8.1.1.3.1.11" class="ltx_td ltx_align_center ltx_border_t">0.00</td>
<td id="S6.T8.1.1.3.1.12" class="ltx_td ltx_align_center ltx_border_t">0.00</td>
<td id="S6.T8.1.1.3.1.13" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">N/A</td>
<td id="S6.T8.1.1.3.1.14" class="ltx_td"></td>
</tr>
<tr id="S6.T8.1.1.4.2" class="ltx_tr">
<th id="S6.T8.1.1.4.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">2</th>
<td id="S6.T8.1.1.4.2.2" class="ltx_td ltx_align_center">0.16</td>
<td id="S6.T8.1.1.4.2.3" class="ltx_td ltx_align_center" style="background-color:#BFFFBF;"><span id="S6.T8.1.1.4.2.3.1" class="ltx_text" style="background-color:#BFFFBF;">84.03</span></td>
<td id="S6.T8.1.1.4.2.4" class="ltx_td ltx_align_center">3.67</td>
<td id="S6.T8.1.1.4.2.5" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.4.2.6" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.4.2.7" class="ltx_td ltx_align_center">3.35</td>
<td id="S6.T8.1.1.4.2.8" class="ltx_td ltx_align_center" style="background-color:#FFBFBF;"><span id="S6.T8.1.1.4.2.8.1" class="ltx_text" style="background-color:#FFBFBF;">5.59</span></td>
<td id="S6.T8.1.1.4.2.9" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.4.2.10" class="ltx_td ltx_align_center">0.48</td>
<td id="S6.T8.1.1.4.2.11" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.4.2.12" class="ltx_td ltx_align_center">2.72</td>
<td id="S6.T8.1.1.4.2.13" class="ltx_td ltx_align_center ltx_border_r">N/A</td>
<td id="S6.T8.1.1.4.2.14" class="ltx_td"></td>
</tr>
<tr id="S6.T8.1.1.5.3" class="ltx_tr">
<th id="S6.T8.1.1.5.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">3</th>
<td id="S6.T8.1.1.5.3.2" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.5.3.3" class="ltx_td ltx_align_center">0.08</td>
<td id="S6.T8.1.1.5.3.4" class="ltx_td ltx_align_center" style="background-color:#BFFFBF;"><span id="S6.T8.1.1.5.3.4.1" class="ltx_text" style="background-color:#BFFFBF;">97.31</span></td>
<td id="S6.T8.1.1.5.3.5" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.5.3.6" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.5.3.7" class="ltx_td ltx_align_center" style="background-color:#FFBFBF;"><span id="S6.T8.1.1.5.3.7.1" class="ltx_text" style="background-color:#FFBFBF;">2.37</span></td>
<td id="S6.T8.1.1.5.3.8" class="ltx_td ltx_align_center">0.01</td>
<td id="S6.T8.1.1.5.3.9" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.5.3.10" class="ltx_td ltx_align_center">0.10</td>
<td id="S6.T8.1.1.5.3.11" class="ltx_td ltx_align_center">0.02</td>
<td id="S6.T8.1.1.5.3.12" class="ltx_td ltx_align_center">0.11</td>
<td id="S6.T8.1.1.5.3.13" class="ltx_td ltx_align_center ltx_border_r">N/A</td>
<td id="S6.T8.1.1.5.3.14" class="ltx_td"></td>
</tr>
<tr id="S6.T8.1.1.6.4" class="ltx_tr">
<th id="S6.T8.1.1.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">4</th>
<td id="S6.T8.1.1.6.4.2" class="ltx_td ltx_align_center" style="background-color:#FFBFBF;"><span id="S6.T8.1.1.6.4.2.1" class="ltx_text" style="background-color:#FFBFBF;">1.01</span></td>
<td id="S6.T8.1.1.6.4.3" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.6.4.4" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.6.4.5" class="ltx_td ltx_align_center" style="background-color:#BFFFBF;"><span id="S6.T8.1.1.6.4.5.1" class="ltx_text" style="background-color:#BFFFBF;">98.07</span></td>
<td id="S6.T8.1.1.6.4.6" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.6.4.7" class="ltx_td ltx_align_center">0.01</td>
<td id="S6.T8.1.1.6.4.8" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.6.4.9" class="ltx_td ltx_align_center">0.51</td>
<td id="S6.T8.1.1.6.4.10" class="ltx_td ltx_align_center">0.41</td>
<td id="S6.T8.1.1.6.4.11" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.6.4.12" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.6.4.13" class="ltx_td ltx_align_center ltx_border_r">N/A</td>
<td id="S6.T8.1.1.6.4.14" class="ltx_td"></td>
</tr>
<tr id="S6.T8.1.1.7.5" class="ltx_tr">
<th id="S6.T8.1.1.7.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">5</th>
<td id="S6.T8.1.1.7.5.2" class="ltx_td ltx_align_center">8.64</td>
<td id="S6.T8.1.1.7.5.3" class="ltx_td ltx_align_center">3.70</td>
<td id="S6.T8.1.1.7.5.4" class="ltx_td ltx_align_center">14.81</td>
<td id="S6.T8.1.1.7.5.5" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.7.5.6" class="ltx_td ltx_align_center" style="background-color:#BFFFBF;"><span id="S6.T8.1.1.7.5.6.1" class="ltx_text" style="background-color:#BFFFBF;">0.00</span></td>
<td id="S6.T8.1.1.7.5.7" class="ltx_td ltx_align_center" style="background-color:#FFBFBF;"><span id="S6.T8.1.1.7.5.7.1" class="ltx_text" style="background-color:#FFBFBF;">59.26</span></td>
<td id="S6.T8.1.1.7.5.8" class="ltx_td ltx_align_center">7.41</td>
<td id="S6.T8.1.1.7.5.9" class="ltx_td ltx_align_center">1.23</td>
<td id="S6.T8.1.1.7.5.10" class="ltx_td ltx_align_center">4.94</td>
<td id="S6.T8.1.1.7.5.11" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.7.5.12" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.7.5.13" class="ltx_td ltx_align_center ltx_border_r">N/A</td>
<td id="S6.T8.1.1.7.5.14" class="ltx_td"></td>
</tr>
<tr id="S6.T8.1.1.8.6" class="ltx_tr">
<th id="S6.T8.1.1.8.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">6</th>
<td id="S6.T8.1.1.8.6.2" class="ltx_td ltx_align_center">0.45</td>
<td id="S6.T8.1.1.8.6.3" class="ltx_td ltx_align_center">0.15</td>
<td id="S6.T8.1.1.8.6.4" class="ltx_td ltx_align_center" style="background-color:#FFBFBF;"><span id="S6.T8.1.1.8.6.4.1" class="ltx_text" style="background-color:#FFBFBF;">31.42</span></td>
<td id="S6.T8.1.1.8.6.5" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.8.6.6" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.8.6.7" class="ltx_td ltx_align_center" style="background-color:#BFFFBF;"><span id="S6.T8.1.1.8.6.7.1" class="ltx_text" style="background-color:#BFFFBF;">67.39</span></td>
<td id="S6.T8.1.1.8.6.8" class="ltx_td ltx_align_center">0.04</td>
<td id="S6.T8.1.1.8.6.9" class="ltx_td ltx_align_center">0.04</td>
<td id="S6.T8.1.1.8.6.10" class="ltx_td ltx_align_center">0.45</td>
<td id="S6.T8.1.1.8.6.11" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.8.6.12" class="ltx_td ltx_align_center">0.07</td>
<td id="S6.T8.1.1.8.6.13" class="ltx_td ltx_align_center ltx_border_r">N/A</td>
<td id="S6.T8.1.1.8.6.14" class="ltx_td"></td>
</tr>
<tr id="S6.T8.1.1.9.7" class="ltx_tr">
<th id="S6.T8.1.1.9.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">7</th>
<td id="S6.T8.1.1.9.7.2" class="ltx_td ltx_align_center">0.02</td>
<td id="S6.T8.1.1.9.7.3" class="ltx_td ltx_align_center">0.03</td>
<td id="S6.T8.1.1.9.7.4" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.9.7.5" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.9.7.6" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.9.7.7" class="ltx_td ltx_align_center">0.03</td>
<td id="S6.T8.1.1.9.7.8" class="ltx_td ltx_align_center" style="background-color:#BFFFBF;"><span id="S6.T8.1.1.9.7.8.1" class="ltx_text" style="background-color:#BFFFBF;">99.86</span></td>
<td id="S6.T8.1.1.9.7.9" class="ltx_td ltx_align_center">0.02</td>
<td id="S6.T8.1.1.9.7.10" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.9.7.11" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.9.7.12" class="ltx_td ltx_align_center" style="background-color:#FFBFBF;"><span id="S6.T8.1.1.9.7.12.1" class="ltx_text" style="background-color:#FFBFBF;">0.04</span></td>
<td id="S6.T8.1.1.9.7.13" class="ltx_td ltx_align_center ltx_border_r">N/A</td>
<td id="S6.T8.1.1.9.7.14" class="ltx_td"></td>
</tr>
<tr id="S6.T8.1.1.10.8" class="ltx_tr">
<th id="S6.T8.1.1.10.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">8</th>
<td id="S6.T8.1.1.10.8.2" class="ltx_td ltx_align_center">0.06</td>
<td id="S6.T8.1.1.10.8.3" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.10.8.4" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.10.8.5" class="ltx_td ltx_align_center" style="background-color:#FFBFBF;"><span id="S6.T8.1.1.10.8.5.1" class="ltx_text" style="background-color:#FFBFBF;">0.13</span></td>
<td id="S6.T8.1.1.10.8.6" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.10.8.7" class="ltx_td ltx_align_center">0.04</td>
<td id="S6.T8.1.1.10.8.8" class="ltx_td ltx_align_center">0.07</td>
<td id="S6.T8.1.1.10.8.9" class="ltx_td ltx_align_center" style="background-color:#BFFFBF;"><span id="S6.T8.1.1.10.8.9.1" class="ltx_text" style="background-color:#BFFFBF;">99.70</span></td>
<td id="S6.T8.1.1.10.8.10" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.10.8.11" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.10.8.12" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.10.8.13" class="ltx_td ltx_align_center ltx_border_r">N/A</td>
<td id="S6.T8.1.1.10.8.14" class="ltx_td"></td>
</tr>
<tr id="S6.T8.1.1.11.9" class="ltx_tr">
<th id="S6.T8.1.1.11.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">9</th>
<td id="S6.T8.1.1.11.9.2" class="ltx_td ltx_align_center">0.06</td>
<td id="S6.T8.1.1.11.9.3" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.11.9.4" class="ltx_td ltx_align_center" style="background-color:#FFBFBF;"><span id="S6.T8.1.1.11.9.4.1" class="ltx_text" style="background-color:#FFBFBF;">0.13</span></td>
<td id="S6.T8.1.1.11.9.5" class="ltx_td ltx_align_center">0.01</td>
<td id="S6.T8.1.1.11.9.6" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.11.9.7" class="ltx_td ltx_align_center">0.02</td>
<td id="S6.T8.1.1.11.9.8" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.11.9.9" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.11.9.10" class="ltx_td ltx_align_center" style="background-color:#BFFFBF;"><span id="S6.T8.1.1.11.9.10.1" class="ltx_text" style="background-color:#BFFFBF;">99.76</span></td>
<td id="S6.T8.1.1.11.9.11" class="ltx_td ltx_align_center">0.01</td>
<td id="S6.T8.1.1.11.9.12" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.11.9.13" class="ltx_td ltx_align_center ltx_border_r">N/A</td>
<td id="S6.T8.1.1.11.9.14" class="ltx_td"></td>
</tr>
<tr id="S6.T8.1.1.12.10" class="ltx_tr">
<th id="S6.T8.1.1.12.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">10</th>
<td id="S6.T8.1.1.12.10.2" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.12.10.3" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.12.10.4" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.12.10.5" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.12.10.6" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.12.10.7" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.12.10.8" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.12.10.9" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.12.10.10" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.12.10.11" class="ltx_td ltx_align_center" style="background-color:#BFFFBF;"><span id="S6.T8.1.1.12.10.11.1" class="ltx_text" style="background-color:#BFFFBF;">100.00</span></td>
<td id="S6.T8.1.1.12.10.12" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.12.10.13" class="ltx_td ltx_align_center ltx_border_r">N/A</td>
<td id="S6.T8.1.1.12.10.14" class="ltx_td"></td>
</tr>
<tr id="S6.T8.1.1.13.11" class="ltx_tr">
<th id="S6.T8.1.1.13.11.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">11</th>
<td id="S6.T8.1.1.13.11.2" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.13.11.3" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.13.11.4" class="ltx_td ltx_align_center">0.01</td>
<td id="S6.T8.1.1.13.11.5" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.13.11.6" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.13.11.7" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.13.11.8" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.13.11.9" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.13.11.10" class="ltx_td ltx_align_center">0.00</td>
<td id="S6.T8.1.1.13.11.11" class="ltx_td ltx_align_center" style="background-color:#FFBFBF;"><span id="S6.T8.1.1.13.11.11.1" class="ltx_text" style="background-color:#FFBFBF;">0.01</span></td>
<td id="S6.T8.1.1.13.11.12" class="ltx_td ltx_align_center" style="background-color:#BFFFBF;"><span id="S6.T8.1.1.13.11.12.1" class="ltx_text" style="background-color:#BFFFBF;">99.98</span></td>
<td id="S6.T8.1.1.13.11.13" class="ltx_td ltx_align_center ltx_border_r">N/A</td>
<td id="S6.T8.1.1.13.11.14" class="ltx_td"></td>
</tr>
<tr id="S6.T8.1.1.14.12" class="ltx_tr">
<th id="S6.T8.1.1.14.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_bb ltx_border_r">12</th>
<td id="S6.T8.1.1.14.12.2" class="ltx_td ltx_align_center ltx_border_bb">N/A</td>
<td id="S6.T8.1.1.14.12.3" class="ltx_td ltx_align_center ltx_border_bb">N/A</td>
<td id="S6.T8.1.1.14.12.4" class="ltx_td ltx_align_center ltx_border_bb">N/A</td>
<td id="S6.T8.1.1.14.12.5" class="ltx_td ltx_align_center ltx_border_bb">N/A</td>
<td id="S6.T8.1.1.14.12.6" class="ltx_td ltx_align_center ltx_border_bb">N/A</td>
<td id="S6.T8.1.1.14.12.7" class="ltx_td ltx_align_center ltx_border_bb">N/A</td>
<td id="S6.T8.1.1.14.12.8" class="ltx_td ltx_align_center ltx_border_bb">N/A</td>
<td id="S6.T8.1.1.14.12.9" class="ltx_td ltx_align_center ltx_border_bb">N/A</td>
<td id="S6.T8.1.1.14.12.10" class="ltx_td ltx_align_center ltx_border_bb">N/A</td>
<td id="S6.T8.1.1.14.12.11" class="ltx_td ltx_align_center ltx_border_bb">N/A</td>
<td id="S6.T8.1.1.14.12.12" class="ltx_td ltx_align_center ltx_border_bb">N/A</td>
<td id="S6.T8.1.1.14.12.13" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r">N/A</td>
<td id="S6.T8.1.1.14.12.14" class="ltx_td ltx_border_bb"></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S6.T9" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 9: </span>Results of test accuracy when question type is hidden with/without absurd questions in training. We compare them with similar QTA models. * denotes training and testing without absurd questions</figcaption>
<div id="S6.T9.5.5" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:353.7pt;height:173.4pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-117.9pt,57.6pt) scale(0.6,0.6) ;">
<table id="S6.T9.5.5.5" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T9.5.5.5.5" class="ltx_tr">
<td id="S6.T9.5.5.5.5.6" class="ltx_td ltx_border_r ltx_border_tt"></td>
<td id="S6.T9.1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt"><span id="S6.T9.1.1.1.1.1.1" class="ltx_text ltx_font_bold">CATL-QTA<sup id="S6.T9.1.1.1.1.1.1.1" class="ltx_sup"><span id="S6.T9.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">W</span></sup></span></td>
<td id="S6.T9.2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt"><span id="S6.T9.2.2.2.2.2.1" class="ltx_text ltx_font_bold">CATL<sup id="S6.T9.2.2.2.2.2.1.1" class="ltx_sup"><span id="S6.T9.2.2.2.2.2.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">Wâˆ—</span></sup></span></td>
<td id="S6.T9.3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt"><span id="S6.T9.3.3.3.3.3.1" class="ltx_text ltx_font_bold">CATL-QTA<sup id="S6.T9.3.3.3.3.3.1.1" class="ltx_sup"><span id="S6.T9.3.3.3.3.3.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">Wâˆ—</span></sup></span></td>
<td id="S6.T9.5.5.5.5.7" class="ltx_td ltx_align_center ltx_border_tt"><span id="S6.T9.5.5.5.5.7.1" class="ltx_text ltx_font_bold">CATL-QTA-M</span></td>
<td id="S6.T9.4.4.4.4.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_tt"><span id="S6.T9.4.4.4.4.4.1" class="ltx_text ltx_font_bold">CATL-QTA-M<sup id="S6.T9.4.4.4.4.4.1.1" class="ltx_sup"><span id="S6.T9.4.4.4.4.4.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">âˆ—</span></sup></span></td>
<td id="S6.T9.5.5.5.5.5" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S6.T9.5.5.5.5.5.1" class="ltx_text ltx_font_bold">CAT1<sup id="S6.T9.5.5.5.5.5.1.1" class="ltx_sup"><span id="S6.T9.5.5.5.5.5.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">1âˆ—</span></sup></span>Â <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>
</td>
</tr>
<tr id="S6.T9.5.5.5.6.1" class="ltx_tr">
<td id="S6.T9.5.5.5.6.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Scene Recognition</td>
<td id="S6.T9.5.5.5.6.1.2" class="ltx_td ltx_align_center ltx_border_t">93.80</td>
<td id="S6.T9.5.5.5.6.1.3" class="ltx_td ltx_align_center ltx_border_t">93.46</td>
<td id="S6.T9.5.5.5.6.1.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">93.62</td>
<td id="S6.T9.5.5.5.6.1.5" class="ltx_td ltx_align_center ltx_border_t">93.74</td>
<td id="S6.T9.5.5.5.6.1.6" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">93.82</td>
<td id="S6.T9.5.5.5.6.1.7" class="ltx_td ltx_align_center ltx_border_t">72.75</td>
</tr>
<tr id="S6.T9.5.5.5.7.2" class="ltx_tr">
<td id="S6.T9.5.5.5.7.2.1" class="ltx_td ltx_align_center ltx_border_r">Sport Recognition</td>
<td id="S6.T9.5.5.5.7.2.2" class="ltx_td ltx_align_center">95.55</td>
<td id="S6.T9.5.5.5.7.2.3" class="ltx_td ltx_align_center">94.97</td>
<td id="S6.T9.5.5.5.7.2.4" class="ltx_td ltx_align_center ltx_border_rr">95.47</td>
<td id="S6.T9.5.5.5.7.2.5" class="ltx_td ltx_align_center">94.80</td>
<td id="S6.T9.5.5.5.7.2.6" class="ltx_td ltx_align_center ltx_border_rr">95.31</td>
<td id="S6.T9.5.5.5.7.2.7" class="ltx_td ltx_align_center">89.40</td>
</tr>
<tr id="S6.T9.5.5.5.8.3" class="ltx_tr">
<td id="S6.T9.5.5.5.8.3.1" class="ltx_td ltx_align_center ltx_border_r">Color Attributes</td>
<td id="S6.T9.5.5.5.8.3.2" class="ltx_td ltx_align_center">60.16</td>
<td id="S6.T9.5.5.5.8.3.3" class="ltx_td ltx_align_center">57.84</td>
<td id="S6.T9.5.5.5.8.3.4" class="ltx_td ltx_align_center ltx_border_rr">58.63</td>
<td id="S6.T9.5.5.5.8.3.5" class="ltx_td ltx_align_center">57.62</td>
<td id="S6.T9.5.5.5.8.3.6" class="ltx_td ltx_align_center ltx_border_rr">59.73</td>
<td id="S6.T9.5.5.5.8.3.7" class="ltx_td ltx_align_center">50.52</td>
</tr>
<tr id="S6.T9.5.5.5.9.4" class="ltx_tr">
<td id="S6.T9.5.5.5.9.4.1" class="ltx_td ltx_align_center ltx_border_r">Other Attributes</td>
<td id="S6.T9.5.5.5.9.4.2" class="ltx_td ltx_align_center">54.36</td>
<td id="S6.T9.5.5.5.9.4.3" class="ltx_td ltx_align_center">53.90</td>
<td id="S6.T9.5.5.5.9.4.4" class="ltx_td ltx_align_center ltx_border_rr">53.44</td>
<td id="S6.T9.5.5.5.9.4.5" class="ltx_td ltx_align_center">52.05</td>
<td id="S6.T9.5.5.5.9.4.6" class="ltx_td ltx_align_center ltx_border_rr">56.17</td>
<td id="S6.T9.5.5.5.9.4.7" class="ltx_td ltx_align_center">51.47</td>
</tr>
<tr id="S6.T9.5.5.5.10.5" class="ltx_tr">
<td id="S6.T9.5.5.5.10.5.1" class="ltx_td ltx_align_center ltx_border_r">Activity Recognition</td>
<td id="S6.T9.5.5.5.10.5.2" class="ltx_td ltx_align_center">60.10</td>
<td id="S6.T9.5.5.5.10.5.3" class="ltx_td ltx_align_center">57.38</td>
<td id="S6.T9.5.5.5.10.5.4" class="ltx_td ltx_align_center ltx_border_rr">59.43</td>
<td id="S6.T9.5.5.5.10.5.5" class="ltx_td ltx_align_center">53.13</td>
<td id="S6.T9.5.5.5.10.5.6" class="ltx_td ltx_align_center ltx_border_rr">58.61</td>
<td id="S6.T9.5.5.5.10.5.7" class="ltx_td ltx_align_center">48.55</td>
</tr>
<tr id="S6.T9.5.5.5.11.6" class="ltx_tr">
<td id="S6.T9.5.5.5.11.6.1" class="ltx_td ltx_align_center ltx_border_r">Positional Reasoning</td>
<td id="S6.T9.5.5.5.11.6.2" class="ltx_td ltx_align_center">34.71</td>
<td id="S6.T9.5.5.5.11.6.3" class="ltx_td ltx_align_center">33.98</td>
<td id="S6.T9.5.5.5.11.6.4" class="ltx_td ltx_align_center ltx_border_rr">34.63</td>
<td id="S6.T9.5.5.5.11.6.5" class="ltx_td ltx_align_center">33.90</td>
<td id="S6.T9.5.5.5.11.6.6" class="ltx_td ltx_align_center ltx_border_rr">34.70</td>
<td id="S6.T9.5.5.5.11.6.7" class="ltx_td ltx_align_center">27.73</td>
</tr>
<tr id="S6.T9.5.5.5.12.7" class="ltx_tr">
<td id="S6.T9.5.5.5.12.7.1" class="ltx_td ltx_align_center ltx_border_r">Sub. Object Recognition</td>
<td id="S6.T9.5.5.5.12.7.2" class="ltx_td ltx_align_center">86.98</td>
<td id="S6.T9.5.5.5.12.7.3" class="ltx_td ltx_align_center">86.62</td>
<td id="S6.T9.5.5.5.12.7.4" class="ltx_td ltx_align_center ltx_border_rr">86.74</td>
<td id="S6.T9.5.5.5.12.7.5" class="ltx_td ltx_align_center">86.89</td>
<td id="S6.T9.5.5.5.12.7.6" class="ltx_td ltx_align_center ltx_border_rr">86.80</td>
<td id="S6.T9.5.5.5.12.7.7" class="ltx_td ltx_align_center">81.66</td>
</tr>
<tr id="S6.T9.5.5.5.13.8" class="ltx_tr">
<td id="S6.T9.5.5.5.13.8.1" class="ltx_td ltx_align_center ltx_border_r">Absurd</td>
<td id="S6.T9.5.5.5.13.8.2" class="ltx_td ltx_align_center">100.00</td>
<td id="S6.T9.5.5.5.13.8.3" class="ltx_td ltx_align_center">N/A</td>
<td id="S6.T9.5.5.5.13.8.4" class="ltx_td ltx_align_center ltx_border_rr">N/A</td>
<td id="S6.T9.5.5.5.13.8.5" class="ltx_td ltx_align_center">98.57</td>
<td id="S6.T9.5.5.5.13.8.6" class="ltx_td ltx_align_center ltx_border_rr">N/A</td>
<td id="S6.T9.5.5.5.13.8.7" class="ltx_td ltx_align_center">N/A</td>
</tr>
<tr id="S6.T9.5.5.5.14.9" class="ltx_tr">
<td id="S6.T9.5.5.5.14.9.1" class="ltx_td ltx_align_center ltx_border_r">Utility and Affordances</td>
<td id="S6.T9.5.5.5.14.9.2" class="ltx_td ltx_align_center">31.48</td>
<td id="S6.T9.5.5.5.14.9.3" class="ltx_td ltx_align_center">27.78</td>
<td id="S6.T9.5.5.5.14.9.4" class="ltx_td ltx_align_center ltx_border_rr">34.57</td>
<td id="S6.T9.5.5.5.14.9.5" class="ltx_td ltx_align_center">24.07</td>
<td id="S6.T9.5.5.5.14.9.6" class="ltx_td ltx_align_center ltx_border_rr">35.19</td>
<td id="S6.T9.5.5.5.14.9.7" class="ltx_td ltx_align_center">30.99</td>
</tr>
<tr id="S6.T9.5.5.5.15.10" class="ltx_tr">
<td id="S6.T9.5.5.5.15.10.1" class="ltx_td ltx_align_center ltx_border_r">Object Presence</td>
<td id="S6.T9.5.5.5.15.10.2" class="ltx_td ltx_align_center">94.55</td>
<td id="S6.T9.5.5.5.15.10.3" class="ltx_td ltx_align_center">93.87</td>
<td id="S6.T9.5.5.5.15.10.4" class="ltx_td ltx_align_center ltx_border_rr">94.22</td>
<td id="S6.T9.5.5.5.15.10.5" class="ltx_td ltx_align_center">94.57</td>
<td id="S6.T9.5.5.5.15.10.6" class="ltx_td ltx_align_center ltx_border_rr">94.60</td>
<td id="S6.T9.5.5.5.15.10.7" class="ltx_td ltx_align_center">69.50</td>
</tr>
<tr id="S6.T9.5.5.5.16.11" class="ltx_tr">
<td id="S6.T9.5.5.5.16.11.1" class="ltx_td ltx_align_center ltx_border_r">Counting</td>
<td id="S6.T9.5.5.5.16.11.2" class="ltx_td ltx_align_center">53.25</td>
<td id="S6.T9.5.5.5.16.11.3" class="ltx_td ltx_align_center">52.33</td>
<td id="S6.T9.5.5.5.16.11.4" class="ltx_td ltx_align_center ltx_border_rr">52.20</td>
<td id="S6.T9.5.5.5.16.11.5" class="ltx_td ltx_align_center">53.59</td>
<td id="S6.T9.5.5.5.16.11.6" class="ltx_td ltx_align_center ltx_border_rr">55.30</td>
<td id="S6.T9.5.5.5.16.11.7" class="ltx_td ltx_align_center">44.84</td>
</tr>
<tr id="S6.T9.5.5.5.17.12" class="ltx_tr">
<td id="S6.T9.5.5.5.17.12.1" class="ltx_td ltx_align_center ltx_border_r">Sentiment Understanding</td>
<td id="S6.T9.5.5.5.17.12.2" class="ltx_td ltx_align_center">64.38</td>
<td id="S6.T9.5.5.5.17.12.3" class="ltx_td ltx_align_center">64.06</td>
<td id="S6.T9.5.5.5.17.12.4" class="ltx_td ltx_align_center ltx_border_rr">65.81</td>
<td id="S6.T9.5.5.5.17.12.5" class="ltx_td ltx_align_center">60.06</td>
<td id="S6.T9.5.5.5.17.12.6" class="ltx_td ltx_align_center ltx_border_rr">61.31</td>
<td id="S6.T9.5.5.5.17.12.7" class="ltx_td ltx_align_center">59.94</td>
</tr>
<tr id="S6.T9.5.5.5.18.13" class="ltx_tr">
<td id="S6.T9.5.5.5.18.13.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Overall (Arithmetic MPT)</td>
<td id="S6.T9.5.5.5.18.13.2" class="ltx_td ltx_align_center ltx_border_t">69.11</td>
<td id="S6.T9.5.5.5.18.13.3" class="ltx_td ltx_align_center ltx_border_t">65.11</td>
<td id="S6.T9.5.5.5.18.13.4" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">66.25</td>
<td id="S6.T9.5.5.5.18.13.5" class="ltx_td ltx_align_center ltx_border_t">66.92</td>
<td id="S6.T9.5.5.5.18.13.6" class="ltx_td ltx_align_center ltx_border_rr ltx_border_t">66.88</td>
<td id="S6.T9.5.5.5.18.13.7" class="ltx_td ltx_align_center ltx_border_t">57.03</td>
</tr>
<tr id="S6.T9.5.5.5.19.14" class="ltx_tr">
<td id="S6.T9.5.5.5.19.14.1" class="ltx_td ltx_align_center ltx_border_r">Overall (Harmonic MPT)</td>
<td id="S6.T9.5.5.5.19.14.2" class="ltx_td ltx_align_center">60.08</td>
<td id="S6.T9.5.5.5.19.14.3" class="ltx_td ltx_align_center">55.89</td>
<td id="S6.T9.5.5.5.19.14.4" class="ltx_td ltx_align_center ltx_border_rr">58.51</td>
<td id="S6.T9.5.5.5.19.14.5" class="ltx_td ltx_align_center">55.77</td>
<td id="S6.T9.5.5.5.19.14.6" class="ltx_td ltx_align_center ltx_border_rr">58.82</td>
<td id="S6.T9.5.5.5.19.14.7" class="ltx_td ltx_align_center">50.30</td>
</tr>
<tr id="S6.T9.5.5.5.20.15" class="ltx_tr">
<td id="S6.T9.5.5.5.20.15.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t">Simple Accuracy</td>
<td id="S6.T9.5.5.5.20.15.2" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">85.03</td>
<td id="S6.T9.5.5.5.20.15.3" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">79.79</td>
<td id="S6.T9.5.5.5.20.15.4" class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr ltx_border_t">80.13</td>
<td id="S6.T9.5.5.5.20.15.5" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">84.33</td>
<td id="S6.T9.5.5.5.20.15.6" class="ltx_td ltx_align_center ltx_border_bb ltx_border_rr ltx_border_t">80.95</td>
<td id="S6.T9.5.5.5.20.15.7" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t">63.30</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">Our results show that QTA systematically improves the performance by more than 5% across multiple question type categories such as â€œActivity Recognitionâ€, â€œUtilityâ€ and â€œCountingâ€ on TDIUC dataset.
We consider the case when we donâ€™t have question type for test and propose a multi-task model to overcome this limitation by adding question type prediction task in the VQA task. We get around 95% accuracy for the question type prediction while keeping the VQA task accuracy almost same as before.
<br class="ltx_break"><span id="S6.p2.1.1" class="ltx_text ltx_font_bold">Acknowledgements</span>
We thank Amazon AI for providing computing resources. Yang Shi is supported by Air Force Award FA9550-15-1-0221.</p>
<div class="ltx_pagination ltx_role_newpage"></div>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Agrawal, A., Batra, D., Parikh, D.: Analyzing the behavior of visual question
answering models. EMNLP 2016 (2016)

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Agrawal, A., Batra, D., Parikh, D., Kembhavi, A.: Donâ€™t just assume; look and
answer: Overcoming priors for visual question answering. CVPR 2018

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Anderson, P., He, X., Buehler, C., Teney, D., Johnson, M., Gould, S., Zhang,
L.: Bottom-up and top-down attention for image captioning and VQA.
arXiv:1707.07998 (2017), <a target="_blank" href="http://arxiv.org/abs/1707.07998" title="" class="ltx_ref">http://arxiv.org/abs/1707.07998</a>

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Antol, S., Agrawal, A., Lu, J., Mitchell, M., Batra, D., Zitnick, C.L., Parikh,
D.: VQA: Visual Question Answering. In: International Conference on
Computer Vision (ICCV) (2015)

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Charikar, M., Chen, K., Farach-Colton, M.: Finding frequent items in data
streams. In Proceedings of ICALPâ€™02 (2002)

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Chen, T., Li, M., Li, Y., Lin, M., Wang, N., Wang, M., Xiao, T., Xu, B., Zhang,
C., Zhang, Z.: Mxnet: A flexible and efficient machine learning library for
heterogeneous distributed systems. Neural Information Processing Systems,
Workshop on Machine Learning Systems 2015 (2015)

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., Darrell,
T.: Decaf: A deep convolutional activation feature for generic visual
recognition. arXiv:1310.1531 (2013), <a target="_blank" href="http://arxiv.org/abs/1310.1531" title="" class="ltx_ref">http://arxiv.org/abs/1310.1531</a>

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Fukui, A., Park, D.H., Yang, D., Rohrbach, A., Darrell, T., Rohrbach, M.:
Multimodal compact bilinear pooling for visual question answering and visual
grounding. EMNLP 2016 (2016)

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Gao, Y., Beijbom, O., Zhang, N., Darrell, T.: Compact bilinear pooling.
Computer Vision and Pattern Recognition (CVPR), 2016 (2016)

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Goyal, Y., Khot, T., Summers-Stay, D., Batra, D., Parikh, D.: Making the V
in VQA matter: Elevating the role of image understanding in Visual
Question Answering. In: Conference on Computer Vision and Pattern
Recognition (CVPR) (2017)

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Gurari, D., Li, Q., Stangl, A.J., Guo, A., Lin, C., Grauman, K., Luo, J.,
Bigham, J.P.: Vizwiz grand challenge: Answering visual questions from blind
people. arXiv:1802.08218 (2018)

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
He, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image
recognition. In Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition (CVPR).

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Hochreiter, S., Schmidhuber, J.: Long short-term memory. Neural computation
<span id="bib.bib13.1.1" class="ltx_text ltx_font_bold">9</span>(8), 1735â€“1780 (1997)

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Johnson, J., Hariharan, B., vanÂ der Maaten, L., Fei-Fei, L., Zitnick, C.L.,
Girshick, R.B.: CLEVR: A diagnostic dataset for compositional language
and elementary visual reasoning. arXiv:1612.06890 (2016),
<a target="_blank" href="http://arxiv.org/abs/1612.06890" title="" class="ltx_ref">http://arxiv.org/abs/1612.06890</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Kafle, K., Kanan, C.: An analysis of visual question answering algorithms. In:
ICCV (2017)

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Krishna, R., Zhu, Y., Groth, O., Johnson, J., Hata, K., Kravitz, J., Chen, S.,
Kalantidis, Y., Li, L., Shamma, D.A., Bernstein, M.S., Li, F.: Visual genome:
Connecting language and vision using crowdsourced dense image annotations.
arXiv:1602.07332 (2016)

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep
convolutional neural networks. In: Pereira, F., Burges, C.J.C., Bottou, L.,
Weinberger, K.Q. (eds.) Advances in Neural Information Processing Systems 25,
pp. 1097â€“1105. Curran Associates, Inc. (2012)

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Lin, T., Maire, M., Belongie, S.J., Bourdev, L.D., Girshick, R.B., Hays, J.,
Perona, P., Ramanan, D., DollÃ¡r, P., Zitnick, C.L.: Microsoft COCO:
common objects in context. In ECCV (2014)

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Lu, J., Yang, J., Batra, D., Parikh, D.: Hierarchical question-image
co-attention for visual question answering. In NIPS (2016)

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Mikolov, T., Sutskever, I., Chen, K., Corrado, G., Dean, J.: Distributed
representations of words and phrases and their compositionality. Advances in
neural information processing systems pp. 3111â€“3119

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Noh, H., Han, B.: Training recurrent answering units with joint loss
minimization for vqa. arXiv:1606.03647 (2016)

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Ren, S., He, K., Girshick, R.B., Sun, J.: Faster R-CNN: towards real-time
object detection with region proposal networks. arXiv:1506.01497 (2015),
<a target="_blank" href="http://arxiv.org/abs/1506.01497" title="" class="ltx_ref">http://arxiv.org/abs/1506.01497</a>

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Simon, M., Rodner, E., Gao, Y., Darrell, T., Denzler, J.: Generalized orderless
pooling performs implicit salient matching (2017)

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Simonyan, K., Zisserman, A.: Very deep convolutional networks for large-scale
image recognition. arXiv:1409.1556 (2014),
<a target="_blank" href="http://arxiv.org/abs/1409.1556" title="" class="ltx_ref">http://arxiv.org/abs/1409.1556</a>

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Strub, F., deÂ Vries, H., Mary, J., Piot, B., Courville, A.C., Pietquin, O.:
End-to-end optimization of goal-driven and visually grounded dialogue
systems. In: International Joint Conference on Artificial Intelligence
(IJCAI) (2017)

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Sutskever, I., Vinyals, O., Le, Q.V.: Sequence to sequence learning with neural
networks. arXiv:1409.3215 (2014), <a target="_blank" href="http://arxiv.org/abs/1409.3215" title="" class="ltx_ref">http://arxiv.org/abs/1409.3215</a>

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Teney, D., Anderson, P., He, X., vanÂ den Hengel, A.: Tips and tricks for visual
question answering: Learnings from the 2017 challenge. arXiv:1708.02711
(2017), <a target="_blank" href="http://arxiv.org/abs/1708.02711" title="" class="ltx_ref">http://arxiv.org/abs/1708.02711</a>

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Wang, Z., Liu, X., Chen, L., Wang, L., Qiao, Y., Xie, X., Fowlkes, C.:
Structured triplet learning with pos-tag guided attention for visual question
answering. IEEE Winter Conf. on Applications of Computer Vision (2018)

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Wu, Y., Schuster, M., Chen, Z., Le, Q.V., Norouzi, M., Macherey, W., Krikun,
M., Cao, Y., Gao, Q., Macherey, K., Klingner, J., Shah, A., Johnson, M., Liu,
X., Åukasz Kaiser, Gouws, S., Kato, Y., Kudo, T., Kazawa, H., Stevens, K.,
Kurian, G., Patil, N., Wang, W., Young, C., Smith, J., Riesa, J., Rudnick,
A., Vinyals, O., Corrado, G., Hughes, M., Dean, J.: Googleâ€™s neural machine
translation system: Bridging the gap between human and machine translation.
arXiv:1609.08144 (2016), <a target="_blank" href="http://arxiv.org/abs/1609.08144" title="" class="ltx_ref">http://arxiv.org/abs/1609.08144</a>

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Xu, H., Saenko, K.: Ask, attend and answer: Exploring question-guided spatial
attention for visual question answering. European Conference on Computer
Vision 2016 (2016)

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Xu, K., Ba, J., Kiros, R., Courville, A., Salakhutdinov, R., Zemel, R., Bengio,
Y.: Show, attend and tell: Neural image caption generation with visual
attention. International Conference on Machine Learning (2015)

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Yang, Z., He, X., Gao, J., Deng, L., Smola, A.: Stacked attention networks for
image question answering. arXiv:1511.02274 (2015)

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Zhang, P.: Towards Interpretable Vision Systems. Ph.D. thesis, Virginia
Polytechnic Institute and State University (2017)

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Zhang, P., Goyal, Y., Summers-Stay, D., Batra, D., Parikh, D.: Yin and
Yang: Balancing and answering binary visual questions. In: Conference on
Computer Vision and Pattern Recognition (CVPR) (2016)

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/1804.02087" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/1804.02088" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+1804.02088">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/1804.02088" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/1804.02089" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun Mar 10 14:40:59 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
