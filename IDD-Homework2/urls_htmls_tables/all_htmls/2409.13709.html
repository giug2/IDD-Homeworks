<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Column Vocabulary Association (CVA): semantic interpretation of dataless tables</title>
<!--Generated on Fri Sep  6 14:56:27 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.13709v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#S1" title="In Column Vocabulary Association (CVA): semantic interpretation of dataless tables"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#S1.SS1" title="In 1 Introduction ‣ Column Vocabulary Association (CVA): semantic interpretation of dataless tables"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.1 </span>Dataless tables</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#S1.SS2" title="In 1 Introduction ‣ Column Vocabulary Association (CVA): semantic interpretation of dataless tables"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.2 </span>Column Vocabulary Association (CVA)</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#S2" title="In Column Vocabulary Association (CVA): semantic interpretation of dataless tables"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>SemTab Challenge</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#S2.SS1" title="In 2 SemTab Challenge ‣ Column Vocabulary Association (CVA): semantic interpretation of dataless tables"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Metadata to KG - Round 1</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#S2.SS2" title="In 2 SemTab Challenge ‣ Column Vocabulary Association (CVA): semantic interpretation of dataless tables"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Metadata to KG - Round 2</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#S3" title="In Column Vocabulary Association (CVA): semantic interpretation of dataless tables"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methods</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#S3.SS1" title="In 3 Methods ‣ Column Vocabulary Association (CVA): semantic interpretation of dataless tables"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>CVA with LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#S3.SS2" title="In 3 Methods ‣ Column Vocabulary Association (CVA): semantic interpretation of dataless tables"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Semantic similarity using SentenceBERT</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#S3.SS3" title="In 3 Methods ‣ Column Vocabulary Association (CVA): semantic interpretation of dataless tables"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#S4" title="In Column Vocabulary Association (CVA): semantic interpretation of dataless tables"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#S4.SS1" title="In 4 Results ‣ Column Vocabulary Association (CVA): semantic interpretation of dataless tables"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>CVA with LLMs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#S4.SS2" title="In 4 Results ‣ Column Vocabulary Association (CVA): semantic interpretation of dataless tables"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>CVA with SentenceBERT</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#S5" title="In Column Vocabulary Association (CVA): semantic interpretation of dataless tables"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#S6" title="In Column Vocabulary Association (CVA): semantic interpretation of dataless tables"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\copyrightclause</span>
<p class="ltx_p" id="p1.2">Copyright for this paper by its authors.
Use permitted under Creative Commons License Attribution 4.0
International (CC BY 4.0).</p>
</div>
<div class="ltx_para" id="p2">
<span class="ltx_ERROR undefined" id="p2.1">\conference</span>
<p class="ltx_p" id="p2.2">SemTab2024</p>
</div>
<div class="ltx_para" id="p3">
<p class="ltx_p" id="p3.1">[orcid=0000-0001-8004-0464,
email=m.martorana@vu.nl,
]
<span class="ltx_ERROR undefined" id="p3.1.1">\cormark</span>[1]</p>
</div>
<div class="ltx_para" id="p4">
<p class="ltx_p" id="p4.1">[orcid=0000-0002-3736-7047,
email=x.pan2@vu.nl,
]</p>
</div>
<div class="ltx_para" id="p5">
<p class="ltx_p" id="p5.1">[email=b.b.kruit@vu.nl,
]</p>
</div>
<div class="ltx_para" id="p6">
<p class="ltx_p" id="p6.1">[orcid=0000-0002-1267-0234,
email=t.kuhn@vu.nl,
]</p>
</div>
<div class="ltx_para" id="p7">
<p class="ltx_p" id="p7.1">[orcid=0000-0002-7748-4715,
email=j.r.van.ossenbruggen@vu.nl,
]</p>
</div>
<div class="ltx_para" id="p8">
<span class="ltx_ERROR undefined" id="p8.1">\cortext</span>
<p class="ltx_p" id="p8.2">[1]Corresponding author.</p>
</div>
<h1 class="ltx_title ltx_title_document">Column Vocabulary Association (CVA): 
<br class="ltx_break"/>semantic interpretation of dataless tables</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Margherita Martorana
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xueli Pan
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Benno Kruit
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Tobias Kuhn
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jacco van Ossenbruggen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_address">Department of Computer Science, Vrije Universiteit Amsterdam, De Boelelaan 1105, Amsterdam, The Netherlands
</span></span></span>
</div>
<div class="ltx_dates">(2022)</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Traditional Semantic Table Interpretation (STI) methods rely primarily on the underlying table data to create semantic annotations. This year’s SemTab challenge introduced the “Metadata to KG” track, which focuses on performing STI by using only metadata information, without access to the underlying data. In response to this new challenge, we introduce a new term: Column Vocabulary Association (CVA). This term refers to the task of semantic annotation of column headers solely based on metadata information. In this study, we evaluate the performance of various methods in executing the CVA task, including a Large Language Models (LLMs) and Retrieval Augmented Generation (RAG) approach, as well as a more traditional similarity approach with SemanticBERT. Our methodology uses a zero-shot setting, with no pretraining or examples passed to the Large Language Models (LLMs), as we aim to avoid a domain-specific setting.</p>
<p class="ltx_p" id="id2.id2">We investigate a total of 7 different LLMs, of which three commercial GPT models (i.e. <span class="ltx_text ltx_font_typewriter" id="id2.id2.1">gpt-3.5-turbo-0.125</span>, <span class="ltx_text ltx_font_typewriter" id="id2.id2.2">gpt-4o</span> and <span class="ltx_text ltx_font_typewriter" id="id2.id2.3">gpt-4-turbo</span>) and four open source models (i.e. <span class="ltx_text ltx_font_typewriter" id="id2.id2.4">llama3-80b</span>, <span class="ltx_text ltx_font_typewriter" id="id2.id2.5">llama3-7b</span>, <span class="ltx_text ltx_font_typewriter" id="id2.id2.6">gemma-7b</span> and <span class="ltx_text ltx_font_typewriter" id="id2.id2.7">mixtral-8x7b</span>). We integrate this models with RAG systems, and we explore how variations in temperature settings affect performances. Moreover, we continue our investigation by performing the CVA task utilizing SemanticBERT, analyzing how various metadata information influence its performance.</p>
<p class="ltx_p" id="id3.id3">Initial findings indicate that LLMs generally perform well at temperatures below 1.0, achieving an accuracy of 100% in certain cases. Nevertheless, our investigation also reveal that the nature of the data significantly influences CVA task outcomes. In fact, in cases where the input data and glossary are related (for example by being created by the same organizations) traditional methods appear to surpass the performance of LLMs.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>
Large Language Models <span class="ltx_ERROR undefined" id="id4.id1">\sep</span>Metadata Enrichment <span class="ltx_ERROR undefined" id="id5.id2">\sep</span>Retrieval Augmented Generation <span class="ltx_ERROR undefined" id="id6.id3">\sep</span>Semantic Table Interpretation <span class="ltx_ERROR undefined" id="id7.id4">\sep</span>Semantic Web

</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Tabular data is the most common format used for data storage and sharing<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#bib.bib1" title="">1</a>]</cite>. However, tabular data often lacks semantic annotations and can contain inaccurate or missing information. Semantic Table Interpretation (STI) aims to find semantic annotations for table cells and columns, as well as column relationships, using existing Knowledge Graphs (KGs). Semantic annotations are particularly important when used to enrich and augment metadata. In fact, several studies<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#bib.bib2" title="">2</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#bib.bib3" title="">3</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#bib.bib4" title="">4</a>]</cite> have shown that high-quality metadata supports data Findability, Accessibility, Interoperability and Reusability (FAIR Guiding Principles)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#bib.bib5" title="">5</a>]</cite>. Rich metadata plays a critical role when dealing with confidential data, as the underlying data is not commonly openly and freely accessible. Enhancing the FAIRness for this type of data has gained more attention in recent years, and previous work has suggested that high-quality and rich metadata improves the discovery and reuse of these resources<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#bib.bib6" title="">6</a>]</cite>. Nevertheless, the automatic enrichment of metadata when only the metadata is available is a challenging task because much of the contextual information is missing, and the underlying data cannot be used to help find the most appropriate annotations. Large Language Models (LLMs) could be a helpful solution in this by leveraging their training data as background knowledge. Moreover, Retrieval Augmented Generation (RAG) systems could further integrate external knowledge - for example from knowledge graphs, controlled vocabularies and glossaries - to enhance the LLMs flexibility across different domains.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">In this year SemTab challenge, participants in the “Metadata to KG” track aim to annotate tables using only table metadata (e.g. column and table names) without accessing the underlying data. This approach tests the ability to enrich metadata effectively under similar conditions imposed by restricted access data. To guide our investigation we have formulated the following research questions:</p>
</div>
<div class="ltx_para" id="S1.p3">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">How do traditional semantic similarity methods compare to newer methods using Large Language Models (LLMs) in the semantic annotation of table metadata when the underlying data is not available?</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">How does the temperature setting of LLMs impact their performance in this task?</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">How do different combinations of metadata information in traditional methods affect their performance?</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i4.p1">
<p class="ltx_p" id="S1.I1.i4.p1.1">How does the nature of the input data and glossary influence the results?</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In the pages that follow, we further describe the importance of metadata, especially in settings where the underlying data is not available. We also introduce the term “Column Vocabulary Association”, before discussing our main methodology and results.</p>
</div>
<section class="ltx_subsection" id="S1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span>Dataless tables</h3>
<div class="ltx_para" id="S1.SS1.p1">
<p class="ltx_p" id="S1.SS1.p1.1">Recently we have seen more and more solutions for sharing data that is considered confidential or with restricted access. For example, there have been multiple developments of online Open Government Data (OGD) portals- e.g. Central Bureau for Statistics Netherlands (CBS)<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.cbs.nl" title="">https://www.cbs.nl</a></span></span></span>, U.S. Government’s Open Data<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://data.gov" title="">https://data.gov</a></span></span></span> and the Canada’s Open Government Portal<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://search.open.canada.ca/data/" title="">https://search.open.canada.ca/data/</a></span></span></span> portals aimed at enhancing innovation and research, by allowing users to investigate population data. Through OGD portals, the general public and researchers are able to use this data in a variety of fields, such as journalism, software development and research <cite class="ltx_cite ltx_citemacro_citep">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#bib.bib7" title="">7</a>]</cite>. The data in these portals is usually aggregated statistics, yet a significant amount of population data remains inaccessible to the public due to confidentiality concerns. This includes patient data, individual-level statistical data, and other type of data that contains Personable Identifiable Information (PII).</p>
</div>
<div class="ltx_para" id="S1.SS1.p2">
<p class="ltx_p" id="S1.SS1.p2.1">Solutions have been proposed to facilitate the reuse of restricted access data. For instance, the Personal Health Train <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#bib.bib8" title="">8</a>]</cite> allows users to send their algorithms to where the data is stored. In this way the users do not have to store the data in personal devices, and also do not have direct access to it at any point of the analysis. However, users still need to know that the data exists and its structural details. Therefore, comprehensive metadata descriptions have a key role to facilitate this process. In previous research, we have introduced a metadata schema - the DataSet Variable Ontology (DSV) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#bib.bib9" title="">9</a>]</cite> - that captures information both at the dataset and variable levels, demonstrating that high-quality metadata can enable the discovery of restricted access data without compromising confidentiality. This approach involves annotating non-confidential information, such as column descriptions, the structure of the dataset and summary statistics.</p>
</div>
<div class="ltx_para" id="S1.SS1.p3">
<p class="ltx_p" id="S1.SS1.p3.1">The goal of this year SemTab challenge and the “Metadata to KG” track align with this research, as creating annotations is often challenging, requiring domain expertise and difficult to automate.</p>
</div>
</section>
<section class="ltx_subsection" id="S1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2 </span>Column Vocabulary Association (CVA)</h3>
<div class="ltx_para" id="S1.SS2.p1">
<p class="ltx_p" id="S1.SS2.p1.1">In the domain of Semantic Table Interpretation (STI), there are some well known challenged, including the Column Type Annotation (CTA), the Column Entity Annotation (CEA), and the Column Property Annotation (CPA) tasks. The <span class="ltx_text ltx_font_bold" id="S1.SS2.p1.1.1">CTA</span> task involves identifying the semantic type (e.g. dates or geographical locations) of each column in the table. The <span class="ltx_text ltx_font_bold" id="S1.SS2.p1.1.2">CEA</span> task, instead, involves linking each cell to an entity in a knowledge graph: for example, the cell containing the string “New York” to be linked to the WikiData entity for New York City (Q60). <span class="ltx_text ltx_font_bold" id="S1.SS2.p1.1.3">CPA</span> requires the identification of relationships between columns of a table: for example, recognising that the columns with headers “Mayor’s Name” and “City” are related to each other by the property eg:isMayorOf.</p>
</div>
<div class="ltx_para" id="S1.SS2.p2">
<p class="ltx_p" id="S1.SS2.p2.1">In this work we introduce a new term: the Column Vocabulary Association (CVA) task. This task differs significantly from the previous ones because it does not rely on any information from the underlying data within the table. Instead, it aims to associate column headers with entries in controlled vocabularies purely based on semantic similarities. The distinction between the word <span class="ltx_text ltx_font_italic" id="S1.SS2.p2.1.1">association</span> and <span class="ltx_text ltx_font_italic" id="S1.SS2.p2.1.2">annotation</span> is also important in this context. Annotation typically refers to the labelling of data with tags or categories. In contrast, with the term association we refer more on the conceptual linkage between the textual information in a column header, and an external knowledge repository. This approach emphasizes understanding and leveraging the semantic meaning of the column headers themselves, without using any underlying data. By focusing on semantic similarities, we aim to create a method for interpreting and integrating restricted access datasets, to facilitate metadata enrichment and data discovery.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>SemTab Challenge</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Since its inception in 2019, the Semantic Web Challenge on Tabular Data to Knowledge Graph Matching, known as SemTab, has become a competitive event focused on benchmarking systems and approaches that support and enhance Semantic Table Interpretation (STI). The SemTab challenge typically consists of two main tracks: the <span class="ltx_text ltx_font_italic" id="S2.p1.1.1">“Accuracy Track”</span> and the <span class="ltx_text ltx_font_italic" id="S2.p1.1.2">“Dataset Track”</span>.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">The Accuracy Track places participants in a specific context with a predefined set of input data. Participants submit solutions for table annotation tasks, including Column Type Annotation (CTA), Column Entity Annotation (CEA), and Column Property Annotation (CPA). Previous editions of the SemTab challenge have featured interesting solutions. For example, MTab uses a voting algorithm combines with probability models to improve annotations<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#bib.bib10" title="">10</a>]</cite>. Similarly, TorchicTab enables the annotation of tables with diverse structures through the use of an external knowledge graph<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#bib.bib11" title="">11</a>]</cite>. Another example is SemTex, which utilizes a hybrid annotation approach that improves performances, by analyzing relationships between entities in knowledge graphs and integrating them with gradient boosting analysis<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#bib.bib12" title="">12</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">The Dataset Track, on the other hand, involves the submission of new datasets and benchmarks for evaluating various tasks related to the SemTab challenge and tabular data. In previous years, participants have produced versatile datasets applicable across multiple domains. One such example is the ToughTables Dataset, which consists of high-quality manually-curated tables with non-obviously linkable cells, such as those with ambiguous names, typos, and misspelled entity names<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#bib.bib13" title="">13</a>]</cite>. There have also been domain-specific datasets. For example, the BiodivTab benchmark includes 50 datasets based on real-world biodiversity research data, enhanced by manual annotation<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#bib.bib14" title="">14</a>]</cite>. Another example is the TSOTSATable Dataset, that contains annotations of tables made using the FoodOn Ontology<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#bib.bib15" title="">15</a>]</cite>, Open Research Knowledge Graph (ORKG)<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#bib.bib16" title="">16</a>]</cite>, and Wikidata<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#bib.bib17" title="">17</a>]</cite>.</p>
</div>
<div class="ltx_para" id="S2.p4">
<p class="ltx_p" id="S2.p4.1">This year, the SemTab challenge introduced a new track: the <span class="ltx_text ltx_font_italic" id="S2.p4.1.1">“Metadata to KG”</span> track. Participants of this task were asked to map table metadata to KGs without having access to the underlying data. This presents a unique challenge due to the limited available context, making traditional STI methods less applicable, as they typically rely on actual data for annotation. To better define this metadata-only task, we introduce the term <span class="ltx_text ltx_font_bold" id="S2.p4.1.2">Column Vocabulary Association (CVA)</span>. As further described in section <a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#S1.SS2" title="1.2 Column Vocabulary Association (CVA) ‣ 1 Introduction ‣ Column Vocabulary Association (CVA): semantic interpretation of dataless tables"><span class="ltx_text ltx_ref_tag">1.2</span></a>,CVA involves annotating columns using solely KGs table metadata, without utilizing the underlying data. This approach is particularly relevant in scenarios where the data is confidential and cannot be accessed.</p>
</div>
<div class="ltx_para" id="S2.p5">
<p class="ltx_p" id="S2.p5.1">The Metadata to KG track was divided into two rounds. Although the end goal remained the same (i.e. to annotate column headers with the appropriate term from KGs), each round features different input data and KGs. Below, we provide an explanatory summary of the two rounds.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Metadata to KG - Round 1</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Round 1 of the “Metadata to KG” track required participants to map a set of table metadata to DBpedia properties. Participants were provided with tables metadata and DBpedia properties files in both JSONL and OWL formats, all of which were accessible in the following GitHub repository<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/sem-tab-challenge/2024/blob/main/data/metadata2kg/round1/README.md" title="">https://github.com/sem-tab-challenge/2024/blob/main/data/metadata2kg/round1/README.md</a></span></span></span>.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">The tables metadata file included information about 141 columns derived from different tables. For each column, the provided information included the column ID, column label, table ID, table name, and a list of the other column labels within the same table. The DBpedia properties file contained 2,881 properties. For each DBpedia property, the information included the property ID (the actual URI of the property in DBpedia), the property label, and the description. Below, we report examples of a table metadata entry (Listing <a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#LST1" title="Listing 1 ‣ 2.1 Metadata to KG - Round 1 ‣ 2 SemTab Challenge ‣ Column Vocabulary Association (CVA): semantic interpretation of dataless tables"><span class="ltx_text ltx_ref_tag">1</span></a>) and of DBpedia property (Listing <a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#LST2" title="Listing 2 ‣ 2.1 Metadata to KG - Round 1 ‣ 2 SemTab Challenge ‣ Column Vocabulary Association (CVA): semantic interpretation of dataless tables"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
<figure class="ltx_float ltx_lstlisting" id="LST1">
<div class="ltx_listing ltx_lstlisting ltx_framed ltx_framed_rectangle ltx_listing" id="LST1.1">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,ewogICAgImlkIjogIjU4ODkxMjg4XzBfMTExNzU0MTA0NzAxMjQwNTk1OF9EaXJlY3RvcihzKSIsCiAgICAibGFiZWwiOiAiRGlyZWN0b3IocykiLAogICAgInRhYmxlX2lkIjogIjU4ODkxMjg4XzBfMTExNzU0MTA0NzAxMjQwNTk1OCIsCiAgICAidGFibGVfbmFtZSI6ICJGaWxtIiwKICAgICJ0YWJsZV9jb2x1bW5zIjogWyJSYW5rIiwgIlRpdGxlIiwgIlllYXIiLCAiRGlyZWN0b3IocykiLCAiT3ZlcmFsbCBSYW5rIl0KfQ==">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx1">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx1.1" style="font-size:80%;">{</span>
</div>
<div class="ltx_listingline" id="lstnumberx2">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx2.1" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx2.2" style="font-size:80%;color:#0000CD;">"id"</span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx2.3" style="font-size:80%;color:#008000;">:<span class="ltx_text ltx_lst_space" id="lstnumberx2.3.1"> </span>"58891288_0_1117541047012405958_Director(s)",</span>
</div>
<div class="ltx_listingline" id="lstnumberx3">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.1" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx3.2" style="font-size:80%;color:#0000CD;">"label"</span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx3.3" style="font-size:80%;color:#008000;">:<span class="ltx_text ltx_lst_space" id="lstnumberx3.3.1"> </span>"Director(s)",</span>
</div>
<div class="ltx_listingline" id="lstnumberx4">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.1" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx4.2" style="font-size:80%;color:#0000CD;">"table_id"</span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx4.3" style="font-size:80%;color:#008000;">:<span class="ltx_text ltx_lst_space" id="lstnumberx4.3.1"> </span>"58891288_0_1117541047012405958",</span>
</div>
<div class="ltx_listingline" id="lstnumberx5">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx5.1" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx5.2" style="font-size:80%;color:#0000CD;">"table_name"</span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx5.3" style="font-size:80%;color:#008000;">:<span class="ltx_text ltx_lst_space" id="lstnumberx5.3.1"> </span>"Film",</span>
</div>
<div class="ltx_listingline" id="lstnumberx6">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx6.1" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx6.2" style="font-size:80%;color:#0000CD;">"table_columns"</span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx6.3" style="font-size:80%;color:#008000;">:<span class="ltx_text ltx_lst_space" id="lstnumberx6.3.1"> </span>["Rank",<span class="ltx_text ltx_lst_space" id="lstnumberx6.3.2"> </span>"Title",<span class="ltx_text ltx_lst_space" id="lstnumberx6.3.3"> </span>"Year",<span class="ltx_text ltx_lst_space" id="lstnumberx6.3.4"> </span>"Director(s)",<span class="ltx_text ltx_lst_space" id="lstnumberx6.3.5"> </span>"Overall<span class="ltx_text ltx_lst_space" id="lstnumberx6.3.6"> </span>Rank"]</span>
</div>
<div class="ltx_listingline" id="lstnumberx7">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx7.1" style="font-size:80%;">}</span>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float">Listing 1: </span>Example of table metadata</figcaption>
</figure>
<figure class="ltx_float ltx_lstlisting" id="LST2">
<div class="ltx_listing ltx_lstlisting ltx_framed ltx_framed_rectangle ltx_listing" id="LST2.1">
<div class="ltx_listing_data"><a download="" href="data:text/plain;base64,ewogICAgImlkIjogImh0dHA6Ly9kYnBlZGlhLm9yZy9vbnRvbG9neS9kaXJlY3RvciIsCiAgICAibGFiZWwiOiAiZmlsbSBkaXJlY3RvciIsCiAgICAiZGVzYyI6ICJBIGZpbG0gZGlyZWN0b3IgaXMgYSBwZXJzb24gd2hvIGRpcmVjdHMgdGhlIG1ha2luZyBvZiBhIGZpbG0uIgp9">⬇</a></div>
<div class="ltx_listingline" id="lstnumberx8">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx8.1" style="font-size:80%;">{</span>
</div>
<div class="ltx_listingline" id="lstnumberx9">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.1" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx9.2" style="font-size:80%;color:#0000CD;">"id"</span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx9.3" style="font-size:80%;color:#008000;">:<span class="ltx_text ltx_lst_space" id="lstnumberx9.3.1"> </span>"http://dbpedia.org/ontology/director",</span>
</div>
<div class="ltx_listingline" id="lstnumberx10">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.1" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx10.2" style="font-size:80%;color:#0000CD;">"label"</span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx10.3" style="font-size:80%;color:#008000;">:<span class="ltx_text ltx_lst_space" id="lstnumberx10.3.1"> </span>"film<span class="ltx_text ltx_lst_space" id="lstnumberx10.3.2"> </span>director",</span>
</div>
<div class="ltx_listingline" id="lstnumberx11">
<span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.1" style="font-size:80%;"> </span><span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx11.2" style="font-size:80%;color:#0000CD;">"desc"</span><span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx11.3" style="font-size:80%;color:#008000;">:<span class="ltx_text ltx_lst_space" id="lstnumberx11.3.1"> </span>"A<span class="ltx_text ltx_lst_space" id="lstnumberx11.3.2"> </span>film<span class="ltx_text ltx_lst_space" id="lstnumberx11.3.3"> </span>director<span class="ltx_text ltx_lst_space" id="lstnumberx11.3.4"> </span>is<span class="ltx_text ltx_lst_space" id="lstnumberx11.3.5"> </span>a<span class="ltx_text ltx_lst_space" id="lstnumberx11.3.6"> </span>person<span class="ltx_text ltx_lst_space" id="lstnumberx11.3.7"> </span>who<span class="ltx_text ltx_lst_space" id="lstnumberx11.3.8"> </span>directs<span class="ltx_text ltx_lst_space" id="lstnumberx11.3.9"> </span>the<span class="ltx_text ltx_lst_space" id="lstnumberx11.3.10"> </span>making<span class="ltx_text ltx_lst_space" id="lstnumberx11.3.11"> </span>of<span class="ltx_text ltx_lst_space" id="lstnumberx11.3.12"> </span>a<span class="ltx_text ltx_lst_space" id="lstnumberx11.3.13"> </span>film."</span>
</div>
<div class="ltx_listingline" id="lstnumberx12">
<span class="ltx_text ltx_font_typewriter" id="lstnumberx12.1" style="font-size:80%;">}</span>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float">Listing 2: </span>Example of DBpedia property</figcaption>
</figure>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">Additionally, the SemTab organizers supplied a sample table metadata file and a sample ground truth for validation and testing purposes, and a Python evaluation script. The objective was to develop approaches for mapping each table metadata with up to 5 DBpedia properties for each column, based on semantic similarities and relevance, and then rank the mappings from the most to least accurate. The evaluation script assessed the mappings by calculating two metrics: hit@1, which checks if the first mapping is correct, and hit@5, which checks if the correct mapping is within the top five. Participants tested their systems on sample metadata (containing only 9 columns) and submitted their complete results to the track organisers for evaluation against the overall ground truth.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Metadata to KG - Round 2</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Round 2 of the “Metadata to KG” track introduced a level of complexity by using a collection of custom vocabularies for the mapping task. Participants were again provided with tables metadata and custom vocabularies files in JSONL and OWL formats, accessible in the following GitHub repository<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/sem-tab-challenge/2024/blob/main/data/metadata2kg/round2/README.md" title="">https://github.com/sem-tab-challenge/2024/blob/main/data/metadata2kg/round2/README.md</a></span></span></span>.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">In this round, the tables metadata file contained 1181 entries (one entry corresponds to one column) from various datasets, with each column having the same information as in round 1 included: column ID, column label, table ID, table name, and the other columns labels. The custom vocabularies file consisted of 1192 entries, where each entry had, again, the same information as in round 1: ID (in this case not a URI, but a minted ID), label and description. The tables metadata included a very diverse set of topics: including but not limited to: COVID-19 clinical trials, Indian movies ratings and Saudia Arabia stock exchange data. As in Round 1, the SemTab organizers supplied a sample table metadata file and a sample ground truth for validation and testing purposes, alongside a Python evaluation script. The objective was to map each table column metadata to up to 5 relevant custom vocabulary terms based on semantic similarities and relevance, and rank these mappings by accuracy. The evaluation script again used hit@1 and hit@5 metrics to assess the quality of the mappings.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methods</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we outline our methodology, which considers the CVA task as a textual information retrieval challenge. Given that most of the table metadata (including label, table name, and table columns) and glossary information (label and description) are described in text, the goal is to retrieve the most similar glossary entries from the glossary file based on the table metadata.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">Our approach involves two main methods: one utilizing LLMs (both open and commercial) and another employing a traditional semantic similarity method using SentenceBERT. We experimented with three GPT models (<span class="ltx_text ltx_font_typewriter" id="S3.p2.1.1">gpt-3.5-turbo-0125</span> - <span class="ltx_text ltx_font_typewriter" id="S3.p2.1.2">gpt-4o</span> - <span class="ltx_text ltx_font_typewriter" id="S3.p2.1.3">gpt-4-turbo</span>), two LLama models (<span class="ltx_text ltx_font_typewriter" id="S3.p2.1.4">llama3-70b</span> - <span class="ltx_text ltx_font_typewriter" id="S3.p2.1.5">llama3-8b</span>), a Gemma model (<span class="ltx_text ltx_font_typewriter" id="S3.p2.1.6">gemma-7b</span>) and a Mixtral model (<span class="ltx_text ltx_font_typewriter" id="S3.p2.1.7">mixtral-8x7b</span>). Additionally, we varied the temperature settings (0.5, 0.75, 1.0, 1.25, and 1.5) for the LLMs to examine the impact of creativity on task performance.</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">All our tests were conducted in a complete zero-shot setting, with no pretraining of the models and no examples provided through assistant instructions or user prompts. This approach is a key feature of our method. We chose this strategy because we aim to develop a method that is not domain-specific. Pretraining models with specific examples from particular mappings and vocabularies could bias the reported accuracy towards that specific domain. Instead, we aim to propose a method that can be applied more in general settings, regardless of the data domain or vocabulary.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>CVA with LLMs</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p1.1.1">Prompt Engineering
<br class="ltx_break"/></span>Through trial and error, we developed effective prompts, both user queries and assistant instructions. We found that repeating some information from the assistant instructions within the prompt resulted in more precise results by ensuring the models only used the data we provided, thus minimizing hallucinations. Both the prompt and instructions specified to return the 5 most similar glossary entries for each metadata. Below, we show the instructions given to the assistants and the query template for the user prompt used in Round 1 of the SemTab Challenge. The instructions and prompts for Round 2, which are quite similar, can be found on the GitHub page. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<svg class="ltx_picture" height="495.31" id="S3.SS1.p2.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,495.31) matrix(1 0 0 -1 0 0) translate(0,110.3)"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 379.1 C 0 382.36 2.64 385 5.91 385 L 594.09 385 C 597.36 385 600 382.36 600 379.1 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 379.1 C 1.97 381.27 3.73 383.03 5.91 383.03 L 594.09 383.03 C 596.27 383.03 598.03 381.27 598.03 379.1 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 13.78 -110.3)"><foreignobject color="#000000" height="481.53" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="572.44">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="S3.SS1.p2.pic1.1.1.1.1.1" style="width:413.7pt;">
<span class="ltx_p" id="S3.SS1.p2.pic1.1.1.1.1.1.1"><span class="ltx_text ltx_font_typewriter ltx_font_bold" id="S3.SS1.p2.pic1.1.1.1.1.1.1.1" style="font-size:70%;">ASSISTANT INSTRUCTIONS<span class="ltx_text ltx_font_medium" id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.1">
<br class="ltx_break"/>Your task is to match column metadata to DBpedia properties.
<br class="ltx_break"/>The full set of DBpedia properties will be provided in the vector. 
<br class="ltx_break"/>Columns metadata, instead, will be provided by the user and it will contain the following information: column ID, column label, table ID, table name and the labels of the other columns within that table.
The matching between the column and the DBpedia properties is to be made based on the semantic similarities between the metadata (i.e. what the column express), and DBpedia properties. 
<br class="ltx_break"/>You can add multiple properties, but no more 5. 
<br class="ltx_break"/>Return the results in the following format: 
<br class="ltx_break"/>’colID’: ’00000_0_0000_XXX’, ’propID’: [’http://dbpedia.org/ontology/PROPERTY_ID’, ..., ’http://dbpedia.org/ontology/PROPERTY_ID’]. 
<br class="ltx_break"/>Sort the matched DBpedia in descending order of relevance, starting with the most relevant. 
<br class="ltx_break"/>Choose ONLY from the DBpedia properties. 
<br class="ltx_break"/>Return ONLY the results, no other text. 
<br class="ltx_break"/>Return results for each and every single column metadata. 
<br class="ltx_break"/>
<br class="ltx_break"/>
<br class="ltx_break"/></span>QUERY TEMPLATE<span class="ltx_text ltx_font_medium" id="S3.SS1.p2.pic1.1.1.1.1.1.1.1.2">
<br class="ltx_break"/>Based on the instruction given to you, find the most relevant DBpedia property, for each of the following metadata in json format: 
<br class="ltx_break"/>{input_metadata} 
<br class="ltx_break"/>Each json element is an independent column metadata. The metadata do not have any relationship, so the matching with the DBpedia properties should only be based on the information provided within its own metadata. 
<br class="ltx_break"/>You can add multiple properties, but no more 5. 
<br class="ltx_break"/>Return the results in the following format: 
<br class="ltx_break"/>’colID’: ’00000_0_0000_XXX’, ’propID’: [’http://dbpedia.org/ontology/PROPERTY_ID’, ..., ’http://dbpedia.org/ontology/PROPERTY_ID’]. 
<br class="ltx_break"/>Sort the matched DBpedia in descending order of relevance, starting with the most relevant. 
<br class="ltx_break"/>Choose ONLY from the DBpedia properties provided in the vector. 
<br class="ltx_break"/>Return ONLY the results, no other text. 
<br class="ltx_break"/>Return results for each and every single column metadata. 
<br class="ltx_break"/></span></span></span>
</span></foreignobject></g></g></svg>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.1">Model-Temperature Selection</span>
<br class="ltx_break"/>We ran the queries three times for each LLM and temperature combination, then evaluated the preliminary performance using an evaluation script and groundtruth provided by the organisers. Based on these results, we selected the best-performing LLM-temperature combination to compute results on the full dataset. 
<br class="ltx_break"/></p>
</div>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p4.1.1">CVA on Full Metadata Set</span>
<br class="ltx_break"/>In the first round, we input the complete glossary JSON file containing the DBpedia properties into the vector. We then processed 25 metadata entries at a time when using the OpenAI API, while for the open-source LLMs, each metadata entry was added individually. This approach was taken to minimize the cost of running some of the more expensive OpenAI models (4o and 4turbo). In the second round, given the larger size of the glossary, we split it into smaller, topic-based glossaries. We created 75 smaller glossary files and divided the full metadata set into 75 corresponding files. Each metadata file was then processed one at a time against the vector containing the 75 glossary files. 
<br class="ltx_break"/></p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Semantic similarity using SentenceBERT</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Our second method involved computing the semantic similarity between table metadata and glossary entries using SentenceBERT<cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#bib.bib18" title="">18</a>]</cite>. First, we generated a vector representation for each metadata and glossary entry. Next, we calculated the cosine similarity between the embedding of each table metadata and the glossary entries to identify the top 5 glossary entries with the highest cosine similarity scores.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">The initial steps of this method posed two challenges: 1) determining which table metadata and glossary information to use for generating the vectors, and 2) deciding how to vectorize the textual information — whether to concatenate all textual content before vectorization or to vectorize each part separately and then sum the vectors to form the final embedding. To address these questions, we experimented with different combinations of textual information, computed the cosine similarity, and evaluated the results against the groundtruth using the evaluation script provided by the organizers. Based on these findings, we selected the best performing combinations to use across the full metadata set.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Evaluation</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">The evaluation was conducted using a script provided by the track organizers. This script computed the accuracy of the generated mappings for a sample metadata file and a sample ground truth. It calculated two metrics: hit@1 and hit@5. To reiterate, users are supposed to generate the 5 most relevant mapping between the table metadata and the glossary, sorted from the most relevant. Hit@1 checks if the first mapping (thus the one considered to be the most relevant) is correct, while hit@5 checks if the correct mapping is among the top five results. Participants were then asked to generate the mappings for the entire table metadata file and submit them to the organizers. The organizers can then run the evaluation script again using the complete ground truth, which has not yet been shared with the participants.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In the following sections, we present the preliminary challenge’s results. These results show the accuracy scores obtained from the evaluation script on the sample metadata and the sample groundtruth provided. At this point, we are not aware on how our methods performed for the full set of metadata file, as the complete groundtruth has not yet been provided to participants.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>CVA with LLMs</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Here we present the results from our initial analysis using different LLMs and temperature settings. We employed three models from OpenAI and four open-source models, testing them at five different temperatures, as detailed in the table below<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#S4.T1" title="Table 1 ‣ 4.1 CVA with LLMs ‣ 4 Results ‣ Column Vocabulary Association (CVA): semantic interpretation of dataless tables"><span class="ltx_text ltx_ref_tag">1</span></a>. The table shows the average accuracy results for each model-temperature combination, evaluated using the evaluation script with the sample metadata and sample ground truth. Each query was run three times per model-temperature combination, and accuracy results were then averages. The numbers in bold correspond to the best-performing model-temperature combinations. <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p1.1.1">gpt-4o</span> outperformed other models in both Rounds 1 and 2, specifically at temperatures 0.5, 0.75, and 1.0. We observed that the LLMs did not perform very well in Round 2. In the discussion section<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#S5" title="5 Discussion ‣ Column Vocabulary Association (CVA): semantic interpretation of dataless tables"><span class="ltx_text ltx_ref_tag">5</span></a> we explore possible reasons for this outcome.
Based on these preliminary results, for Round 1, we used <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p1.1.2">gpt-4o</span> at temperatures 0.5, 0.75, and 1.0 on the full metadata file for final analysis. For Round 2, we used <span class="ltx_text ltx_font_typewriter" id="S4.SS1.p1.1.3">gpt-4o</span> only at temperatures 0.5 and 0.75.</p>
</div>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Results of different models for sample data in Round 1 and 2. The cells with the “X” refers to tries where the LLM could not compute the task, and either the API was not returning any results over a long period of time or, in the case of <span class="ltx_text ltx_font_typewriter" id="S4.T1.2.1">gemma-7b</span> the model was returning “failure” message. In bold, instead, we show the best performing results. In the table h1 and h5 refers to Hit@1 and Hit@5 metrics from the evaluation script.</figcaption>
<table class="ltx_tabular ltx_align_middle" id="S4.T1.3">
<tr class="ltx_tr" id="S4.T1.3.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T1.3.1.1" rowspan="3"><span class="ltx_text" id="S4.T1.3.1.1.1">
<span class="ltx_tabular ltx_align_middle" id="S4.T1.3.1.1.1.1">
<span class="ltx_tr" id="S4.T1.3.1.1.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T1.3.1.1.1.1.1.1">LLM</span></span>
<span class="ltx_tr" id="S4.T1.3.1.1.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_left" id="S4.T1.3.1.1.1.1.2.1">Models</span></span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="10" id="S4.T1.3.1.2">Round 1</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.2">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S4.T1.3.2.1">0.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S4.T1.3.2.2">0.75</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S4.T1.3.2.3">1.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S4.T1.3.2.4">1.25</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S4.T1.3.2.5">1.5</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.1">h1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.2">h5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.3">h1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.4">h5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.5">h1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.6">h5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.7">h1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.8">h5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.9">h1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.3.10">h5</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.4">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.1">gpt-3.5-turbo-0125</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.2">0.42</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.3">0.42</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.4">0.33</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.5">0.42</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.6">0.47</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.7">0.53</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.8">0.41</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.9">0.41</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.10">0.36</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.4.11">0.36</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.5">
<td class="ltx_td ltx_align_center" id="S4.T1.3.5.1">gpt-4o</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.5.2"><span class="ltx_text ltx_font_bold" id="S4.T1.3.5.2.1">0.59</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.5.3"><span class="ltx_text ltx_font_bold" id="S4.T1.3.5.3.1">0.89</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.5.4"><span class="ltx_text ltx_font_bold" id="S4.T1.3.5.4.1">0.62</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.5.5"><span class="ltx_text ltx_font_bold" id="S4.T1.3.5.5.1">0.81</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.5.6"><span class="ltx_text ltx_font_bold" id="S4.T1.3.5.6.1">0.64</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.5.7"><span class="ltx_text ltx_font_bold" id="S4.T1.3.5.7.1">0.75</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.5.8">0.47</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.5.9">0.67</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.5.10">0.11</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.5.11">0.22</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.6">
<td class="ltx_td ltx_align_center" id="S4.T1.3.6.1">gpt-4-turbo</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.6.2">0.58</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.6.3">0.58</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.6.4">0.56</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.6.5">0.56</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.6.6">0.61</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.6.7">0.61</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.6.8">0.59</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.6.9">0.59</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.6.10">0.36</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.6.11">0.36</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.7">
<td class="ltx_td ltx_align_center" id="S4.T1.3.7.1">llama3-8b</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.7.2">0.22</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.7.3">0.44</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.7.4">0.22</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.7.5">0.44</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.7.6">0.22</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.7.7">0.44</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.7.8">0.33</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.7.9">0.44</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.7.10">0.33</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.7.11">0.33</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.8">
<td class="ltx_td ltx_align_center" id="S4.T1.3.8.1">llama3-70b</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.8.2">0.11</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.8.3">0.11</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.8.4">0.11</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.8.5">0.22</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.8.6">0.11</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.8.7">0.22</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.8.8">0.11</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.8.9">0.22</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.8.10">0.11</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.8.11">0.11</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.9">
<td class="ltx_td ltx_align_center" id="S4.T1.3.9.1">gemma-7b</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.9.2">0.37</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.9.3">0.4</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.9.4">0.44</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.9.5">0.52</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.9.6">0.33</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.9.7">0.47</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.9.8">0.48</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.9.9">0.61</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.9.10">0.37</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.9.11">0.53</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.10">
<td class="ltx_td ltx_align_center" id="S4.T1.3.10.1">mixtral-8x7b</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.10.2">0.33</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.10.3">0.33</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.10.4">0.44</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.10.5">0.56</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.10.6">0.33</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.10.7">0.44</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.10.8">0.44</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.10.9">0.44</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.10.10">0.44</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.10.11">0.44</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.11">
<td class="ltx_td ltx_border_t" id="S4.T1.3.11.1" rowspan="3"></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="10" id="S4.T1.3.11.2">Round 2</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.12">
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S4.T1.3.12.1">0.5</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S4.T1.3.12.2">0.75</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S4.T1.3.12.3">1.0</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S4.T1.3.12.4">1.25</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="2" id="S4.T1.3.12.5">1.5</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.13">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.13.1">h1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.13.2">h5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.13.3">h1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.13.4">h5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.13.5">h1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.13.6">h5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.13.7">h1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.13.8">h5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.13.9">h1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.13.10">h5</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.14">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.14.1">gpt-3.5-turbo-0125</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.14.2">0.67</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.14.3">0.67</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.14.4">0.3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.14.5">0.33</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.14.6">0.63</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.14.7">0.67</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.14.8">0.67</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.14.9">0.67</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.14.10">X</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.3.14.11">X</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.15">
<td class="ltx_td ltx_align_center" id="S4.T1.3.15.1">gpt-4o</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.15.2"><span class="ltx_text ltx_font_bold" id="S4.T1.3.15.2.1">0.73</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.15.3"><span class="ltx_text ltx_font_bold" id="S4.T1.3.15.3.1">1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.15.4"><span class="ltx_text ltx_font_bold" id="S4.T1.3.15.4.1">0.45</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.15.5"><span class="ltx_text ltx_font_bold" id="S4.T1.3.15.5.1">1</span></td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.15.6">0.45</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.15.7">0.58</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.15.8">0.54</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.15.9">0.64</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.15.10">X</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.15.11">X</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.16">
<td class="ltx_td ltx_align_center" id="S4.T1.3.16.1">gpt-4-turbo</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.16.2">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.16.3">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.16.4">X</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.16.5">X</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.16.6">X</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.16.7">X</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.16.8">X</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.16.9">X</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.16.10">X</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.16.11">X</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.17">
<td class="ltx_td ltx_align_center" id="S4.T1.3.17.1">llama3-8b</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.17.2">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.17.3">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.17.4">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.17.5">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.17.6">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.17.7">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.17.8">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.17.9">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.17.10">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.17.11">0</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.18">
<td class="ltx_td ltx_align_center" id="S4.T1.3.18.1">llama3-70b</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.18.2">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.18.3">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.18.4">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.18.5">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.18.6">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.18.7">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.18.8">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.18.9">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.18.10">0</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.18.11">0</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.19">
<td class="ltx_td ltx_align_center" id="S4.T1.3.19.1">gemma-7b</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.19.2">X</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.19.3">X</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.19.4">X</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.19.5">X</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.19.6">X</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.19.7">X</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.19.8">X</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.19.9">X</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.19.10">X</td>
<td class="ltx_td ltx_align_center" id="S4.T1.3.19.11">X</td>
</tr>
<tr class="ltx_tr" id="S4.T1.3.20">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.3.20.1">mixtral-8x7b</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.3.20.2">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.3.20.3">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.3.20.4">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.3.20.5">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.3.20.6">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.3.20.7">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.3.20.8">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.3.20.9">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.3.20.10">0</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.3.20.11">0</td>
</tr>
</table>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>CVA with SentenceBERT</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Below we show the results from our initial analysis with SentenceBERT. Table <a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#S4.T2" title="Table 2 ‣ 4.2 CVA with SentenceBERT ‣ 4 Results ‣ Column Vocabulary Association (CVA): semantic interpretation of dataless tables"><span class="ltx_text ltx_ref_tag">2</span></a> includes the possible combinations of information from the table metadata and the glossary, and the accuracy results for both Round 1 and 2, which we obtained by running the evaluation script against the ground truth for the sample metadata file. We used these results to find the best performing combinations, which were then applied to the full metadata file.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">In Round 1, we did not have a single combination that performed best for both hit@1 and hit@5. The best hit@1 (0.56) is obtained when we use the column label and/or table name to represent the table metadata embedding, and use the property label for the DBpedia property embedding. The best hit@5 (0.67) is obtained when we use the sum of the vectors of the column label and the table name as the table metadata embedding, and use the vector of the property label as the DBpedia property embedding.</p>
</div>
<div class="ltx_para" id="S4.SS2.p3">
<p class="ltx_p" id="S4.SS2.p3.1">For Round 2, the best hit@1 and hit@5 are both obtained when we use the sum of the vectors of the column label and the table name as the table metadata embedding, and encode the vocabulary description as the vocabulary embedding. Based on this results, we did perform SentenceBERT on the full data for Round 1. For Round 2, instead, we sent the results from SentenceBERT for final analysis using the setting with the sum of the vectors of the column label and the table name as the table metadata embeddings.</p>
</div>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Results of different embedding combination for sample data in Round 1 and 2. In bold we are showing the best performing results. In the table h1 and h5 refers to Hit@1 and Hit@5 metrics from the evaluation script.</figcaption>
<table class="ltx_tabular ltx_align_middle" id="S4.T2.1">
<tr class="ltx_tr" id="S4.T2.1.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.1.1" rowspan="2"><span class="ltx_text" id="S4.T2.1.1.1.1">
<span class="ltx_tabular ltx_align_middle" id="S4.T2.1.1.1.1.1">
<span class="ltx_tr" id="S4.T2.1.1.1.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.1.1.1.1.1">Metadata</span></span>
<span class="ltx_tr" id="S4.T2.1.1.1.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.1.1.1.2.1">Embeddings</span></span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.1.2" rowspan="2"><span class="ltx_text" id="S4.T2.1.1.2.1">
<span class="ltx_tabular ltx_align_middle" id="S4.T2.1.1.2.1.1">
<span class="ltx_tr" id="S4.T2.1.1.2.1.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.2.1.1.1.1">Glossary</span></span>
<span class="ltx_tr" id="S4.T2.1.1.2.1.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.T2.1.1.2.1.1.2.1">Embeddings</span></span>
</span></span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T2.1.1.3">Round 1</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T2.1.1.4">Round 2</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.1">h1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.2">h5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.3">h1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.4">h5</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.1">encode(label)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.2">encode(label)</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.3"><span class="ltx_text ltx_font_bold" id="S4.T2.1.3.3.1">0.56</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.4">0.56</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.5">0.36</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.6">0.55</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.4">
<td class="ltx_td ltx_align_center" id="S4.T2.1.4.1">encode(label)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.4.2">encode(lable + desc)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.4.3">0.22</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.4.4">0.56</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.4.5">0.45</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.4.6">0.82</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.5">
<td class="ltx_td ltx_align_center" id="S4.T2.1.5.1">encode(label + table_name)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.5.2">encode(label)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.5.3"><span class="ltx_text ltx_font_bold" id="S4.T2.1.5.3.1">0.56</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.5.4">0.56</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.5.5">0.09</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.5.6">0.27</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.6">
<td class="ltx_td ltx_align_center" id="S4.T2.1.6.1">encode(label + table_name)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.6.2">encode(lable + desc)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.6.3">0.33</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.6.4">0.44</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.6.5">0.64</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.6.6">0.73</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.7">
<td class="ltx_td ltx_align_center" id="S4.T2.1.7.1">encode(label)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.7.2">encode(desc)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.7.3">0.11</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.7.4">0.33</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.7.5">0.45</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.7.6">0.82</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.8">
<td class="ltx_td ltx_align_center" id="S4.T2.1.8.1">encode(label + table_name)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.8.2">encode(desc)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.8.3">0.22</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.8.4">0.44</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.8.5">0.64</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.8.6">0.73</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.9">
<td class="ltx_td ltx_align_center" id="S4.T2.1.9.1">encode(label) + encode(table_name)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.9.2">encode(desc)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.9.3">0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.9.4">0.33</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.9.5"><span class="ltx_text ltx_font_bold" id="S4.T2.1.9.5.1">0.64</span></td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.9.6"><span class="ltx_text ltx_font_bold" id="S4.T2.1.9.6.1">0.91</span></td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.10">
<td class="ltx_td ltx_align_center" id="S4.T2.1.10.1">encode(label) + encode(table_name)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.10.2">encode(desc) + encode(label)</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.10.3">0.22</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.10.4">0.44</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.10.5">0.55</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.10.6">0.91</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.11">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.11.1">encode(label) + encode(table_name)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.11.2">encode(label)</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.11.3">0.44</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.11.4"><span class="ltx_text ltx_font_bold" id="S4.T2.1.11.4.1">0.67</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.11.5">0.27</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T2.1.11.6">0.45</td>
</tr>
</table>
</figure>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">During our analysis, we came across several interesting points that we would like to report in this section. Firstly, regarding the LLM prompt engineering, we found that repeating some of the same sentences in both the assistant instructions and user prompts improved the LLM’s ability to follow instructions more precisely and avoid hallucinations. Specifically, this approach helped prevent the addition of entries not included in the glossaries.</p>
</div>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">Additionally, we observed notable differences in the type of data included between the Round 1 and Round 2 of the challenge. In round 1, there was no clear link between the table metadata file and the glossary. The glossary consisted of DBpedia properties, while the table metadata appeared to be a random collection from various data sources. In round 2, instead, there was a very clear connection between the table metadata and the glossary. It seemed that the table metadata was designed to match the glossary or vice versa, likely because the data was collected from institutions/organizations/repositories that build their own glossaries to describe their data. These differences had an effect in the performances of the methods proposed in this work. LLMs, particularly <span class="ltx_text ltx_font_typewriter" id="S5.p2.1.1">gpt-4o</span>, performed much better in round 1, where it was important to leverage the LLM’s background knowledge to find the most relevant mappings. In round 2, however, the semantic similarities method was sufficient and sometimes even outperformed LLMs. This was due to the high degree of semantic similarity between the column headers and the glossary, as both probably originated from the same institution and were intentionally made to be similar.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">Lastly, we want to highlight differences related to the temperature settings we used for the LLMs. We found that temperatures below 1 performed better than higher temperatures. Temperature regulates the LLM’s creativity, where 0 represents no creativity and 2 indicates full creativity. In many cases, and particularly with <span class="ltx_text ltx_font_typewriter" id="S5.p3.1.1">gpt-4-turbo</span> and <span class="ltx_text ltx_font_typewriter" id="S5.p3.1.2">gemma-7b</span>, a temperature of 1.5 resulted in no outputs or error messages. This suggests that lower temperatures may lead to better performance for these types of tasks, although further investigation is needed.</p>
</div>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">In this study, we investigated different methods for mapping column headers to glossaries when the underlying data is unavailable. Our approach operates in a zero-shot setting, meaning we do not pretrain models or provide examples of correct mappings. This allows us to evaluate model performance across different domains more broadly. We introduce the concept of “Column Vocabulary Association” (CVA) and distinguish it from other STI tasks. Additionally, we analyze how different temperatures of LLMs and the types of input data and glossaries impact the performance in the CVA task.</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">Our findings suggest that LLMs perform well when there are no clear connections between the data and glossaries used for mapping (as observed in Round 1), leveraging their extensive background knowledge. Instead, for CVA tasks where the input metadata and glossaries are closely related (as in Round 2), traditional semantic similarity methods (e.g. SentenceBERT) may perform better than LLMs. Preliminary results indicate that open source models still lag behind commercial ones, with less accurate performance compared to the GPT models. In future work we aim to further evaluate LLM performance by calculating additional metrics introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.13709v1#bib.bib19" title="">19</a>]</cite> to assess the consistency of the LLM performances.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
We acknowledge that ChatGPT was utilized to generate and debug part of the python and latex code utilised in this work. This work is funded by the Netherlands Organisation of Scientific Research (NWO), ODISSEI Roadmap project: 184.035.014.

</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shwartz-Ziv and Armon [2022]</span>
<span class="ltx_bibblock">
R. Shwartz-Ziv, A. Armon,

</span>
<span class="ltx_bibblock">Tabular data: Deep learning is not all you need,

</span>
<span class="ltx_bibblock">Information Fusion 81 (2022) 84–90.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Boeckhout et al. [2018]</span>
<span class="ltx_bibblock">
M. Boeckhout, G. A. Zielhuis, A. L. Bredenoord,

</span>
<span class="ltx_bibblock">The fair guiding principles for data stewardship: fair enough?,

</span>
<span class="ltx_bibblock">European journal of human genetics 26 (2018) 931–936.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mons [2018]</span>
<span class="ltx_bibblock">
B. Mons, Data stewardship for open science: Implementing FAIR principles, Chapman and Hall/CRC, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lamprecht et al. [2020]</span>
<span class="ltx_bibblock">
A.-L. Lamprecht, L. Garcia, M. Kuzak, C. Martinez, R. Arcila, E. Martin Del Pico, V. Dominguez Del Angel, S. Van De Sandt, J. Ison, P. A. Martinez, et al.,

</span>
<span class="ltx_bibblock">Towards fair principles for research software,

</span>
<span class="ltx_bibblock">Data Science 3 (2020) 37–59.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wilkinson et al. [2016]</span>
<span class="ltx_bibblock">
M. D. Wilkinson, M. Dumontier, I. J. Aalbersberg, G. Appleton, M. Axton, A. Baak, N. Blomberg, J.-W. Boiten, L. B. da Silva Santos, P. E. Bourne, et al.,

</span>
<span class="ltx_bibblock">The fair guiding principles for scientific data management and stewardship,

</span>
<span class="ltx_bibblock">Scientific data 3 (2016) 1–9.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Martorana et al. [2022]</span>
<span class="ltx_bibblock">
M. Martorana, T. Kuhn, R. Siebes, J. van Ossenbruggen,

</span>
<span class="ltx_bibblock">Aligning restricted access data with fair: a systematic review,

</span>
<span class="ltx_bibblock">PeerJ Computer Science 8 (2022) e1038.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Begany et al. [2021]</span>
<span class="ltx_bibblock">
G. M. Begany, E. G. Martin, X. J. Yuan,

</span>
<span class="ltx_bibblock">Open government data portals: Predictors of site engagement among early users of health data ny,

</span>
<span class="ltx_bibblock">Government Information Quarterly 38 (2021) 101614.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deist et al. [2020]</span>
<span class="ltx_bibblock">
T. M. Deist, F. J. Dankers, P. Ojha, M. S. Marshall, T. Janssen, C. Faivre-Finn, C. Masciocchi, V. Valentini, J. Wang, J. Chen, et al.,

</span>
<span class="ltx_bibblock">Distributed learning on 20 000+ lung cancer patients–the personal health train,

</span>
<span class="ltx_bibblock">Radiotherapy and Oncology 144 (2020) 189–200.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Martorana et al. [2023]</span>
<span class="ltx_bibblock">
M. Martorana, T. Kuhn, R. Siebes, J. Van Ossenbruggen,

</span>
<span class="ltx_bibblock">Advancing data sharing and reusability for restricted access data on the web: introducing the dataset-variable ontology,

</span>
<span class="ltx_bibblock">in: Proceedings of the 12th Knowledge Capture Conference 2023, 2023, pp. 83–91.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et al. [2019]</span>
<span class="ltx_bibblock">
P. Nguyen, N. Kertkeidkachorn, R. Ichise, H. Takeda,

</span>
<span class="ltx_bibblock">Mtab: Matching tabular data to knowledge graph using probability models,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1910.00246 (2019).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dasoulas et al. [2023]</span>
<span class="ltx_bibblock">
I. Dasoulas, D. Yang, X. Duan, A. Dimou,

</span>
<span class="ltx_bibblock">Torchictab: Semantic table annotation with wikidata and language models,

</span>
<span class="ltx_bibblock">in: CEUR Workshop Proceedings, CEUR Workshop Proceedings, 2023, pp. 21–37.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Henriksen et al. [2023]</span>
<span class="ltx_bibblock">
E. G. Henriksen, A. M. Khorsid, E. Nielsen, A. M. Stück, A. S. Sørensen, O. Pelgrin,

</span>
<span class="ltx_bibblock">Semtex: A hybrid approach for semantic table interpretation.,

</span>
<span class="ltx_bibblock">in: SemTab@ ISWC, 2023, pp. 38–49.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cutrona et al. [2020]</span>
<span class="ltx_bibblock">
V. Cutrona, F. Bianchi, E. Jiménez-Ruiz, M. Palmonari,

</span>
<span class="ltx_bibblock">Tough tables: Carefully evaluating entity linking for tabular data,

</span>
<span class="ltx_bibblock">in: International Semantic Web Conference, Springer, 2020, pp. 328–343.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdelmageed et al. [2021]</span>
<span class="ltx_bibblock">
N. Abdelmageed, S. Schindler, B. König-Ries,

</span>
<span class="ltx_bibblock">Biodivtab: A table annotation benchmark based on biodiversity research data.,

</span>
<span class="ltx_bibblock">in: SemTab@ ISWC, 2021, pp. 13–18.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dooley et al. [2018]</span>
<span class="ltx_bibblock">
D. M. Dooley, E. J. Griffiths, G. S. Gosal, P. L. Buttigieg, R. Hoehndorf, M. C. Lange, L. M. Schriml, F. S. Brinkman, W. W. Hsiao,

</span>
<span class="ltx_bibblock">Foodon: a harmonized food ontology to increase global food traceability, quality control and data integration,

</span>
<span class="ltx_bibblock">npj Science of Food 2 (2018) 23.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Auer et al. [2020]</span>
<span class="ltx_bibblock">
S. Auer, A. Oelen, M. Haris, M. Stocker, J. D’Souza, K. E. Farfar, L. Vogt, M. Prinz, V. Wiens, M. Y. Jaradeh,

</span>
<span class="ltx_bibblock">Improving access to scientific literature with knowledge graphs,

</span>
<span class="ltx_bibblock">Bibliothek Forschung und Praxis 44 (2020) 516–529.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiomekong et al. [2023]</span>
<span class="ltx_bibblock">
A. Jiomekong, U. Melie, H. Tapamo, G. Camara,

</span>
<span class="ltx_bibblock">Semantic annotation of tsotsatable dataset.,

</span>
<span class="ltx_bibblock">in: SemTab@ ISWC, 2023, pp. 15–20.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reimers and Gurevych [2019]</span>
<span class="ltx_bibblock">
N. Reimers, I. Gurevych,

</span>
<span class="ltx_bibblock">Sentence-bert: Sentence embeddings using siamese bert-networks,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:1908.10084 (2019).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Martorana et al. [2024]</span>
<span class="ltx_bibblock">
M. Martorana, T. Kuhn, L. Stork, J. van Ossenbruggen,

</span>
<span class="ltx_bibblock">Text classification of column headers with a controlled vocabulary: leveraging llms for metadata enrichment,

</span>
<span class="ltx_bibblock">arXiv preprint arXiv:2403.00884 (2024).

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Fri Sep  6 14:56:27 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
