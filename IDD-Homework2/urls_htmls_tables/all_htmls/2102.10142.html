<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2102.10142] Making a Case for Federated Learning in the Internet of Vehicles and Intelligent Transportation Systems</title><meta property="og:description" content="With the incoming introduction of 5G networks and the advancement in technologies, such as Network Function Virtualization and Software Defined Networking, new and emerging networking technologies and use cases are tak…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Making a Case for Federated Learning in the Internet of Vehicles and Intelligent Transportation Systems">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Making a Case for Federated Learning in the Internet of Vehicles and Intelligent Transportation Systems">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2102.10142">

<!--Generated on Sat Mar 16 01:11:52 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Making a Case for Federated Learning in the Internet of Vehicles and Intelligent Transportation Systems</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Dimitrios Michael Manias and
Abdallah Shami
</span><span class="ltx_author_notes">Dimitrios Michael Manias and Abdallah Shami are with the Department of Electrical and Computer Engineering at the University of Western Ontario e-mail: {dmanias3, Abdallah.Shami} @uwo.ca</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">With the incoming introduction of 5G networks and the advancement in technologies, such as Network Function Virtualization and Software Defined Networking, new and emerging networking technologies and use cases are taking shape. One such technology is the Internet of Vehicles (IoV), which describes an interconnected system of vehicles and infrastructure. Coupled with recent developments in artificial intelligence and machine learning, the IoV is transformed into an Intelligent Transportation System (ITS). There are, however, several operational considerations that hinder the adoption of ITS systems, including scalability, high availability, and data privacy. To address these challenges, Federated Learning, a collaborative and distributed intelligence technique, is suggested. Through an ITS case study, the ability of a federated model deployed on roadside infrastructure throughout the network to recover from faults by leveraging group intelligence while reducing recovery time and restoring acceptable system performance is highlighted. With a multitude of use cases and benefits, Federated Learning is a key enabler for ITS and is poised to achieve widespread implementation in 5G and beyond networks and applications.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">With recent advancements in networking technologies such as Mobile Edge Computing (MEC) and Network Function Virtualization (NFV) and the incoming introduction of Fifth Generation (5G) networks, a multitude of new applications and use cases are being realized, such as the Internet of Vehicles (IoV). These up-and-coming use cases require stringent Quality of Service (QoS) guarantees and strict Service Level Agreements (SLAs) to ensure network properties such as scalability, flexibility, elasticity, high availability, and performance; however, these properties cannot be realized to their full potential without the use of intelligence techniques such as Machine Learning (ML) and Advanced Analytics (AA). By leveraging the enabling networking technologies to create the IoV and combining it with intelligence techniques, the IoV transforms into an Intelligent Transportation System (ITS).</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS1.5.1.1" class="ltx_text">I-A</span> </span><span id="S1.SS1.6.2" class="ltx_text ltx_font_italic">Mobile Edge Computing</span>
</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">MEC is a technology that pushes cloud computing services to the network edge. By utilizing the network edge, several benefits arise, including ultra-low latency, high bandwidth, and real-time applications. Due to these benefits, MEC has been highlighted as an enabling technology for next-generation networking and applications. Some examples of use cases stemming from MEC implementations include video analytics, location services, IoV and augmented reality <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Another major advantage of MEC implementations is the reduced traffic experienced on core networks, something which is essential given the growing network connectivity demand experienced globally by Network Service Providers (NSPs). When considering use cases such as the IoV, real-time, ultra-low latency processing available at the edge of the network is essential for critical services, including collision avoidance and infotainment services, such as virtual and augmented reality. However, MEC itself requires the virtualization of network infrastructure to enable cloud resource utilization at the network edge.</p>
</div>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS2.5.1.1" class="ltx_text">I-B</span> </span><span id="S1.SS2.6.2" class="ltx_text ltx_font_italic">Network Function Virtualization</span>
</h3>

<div id="S1.SS2.p1" class="ltx_para">
<p id="S1.SS2.p1.1" class="ltx_p">NFV technology was proposed by the European Technical Standards Institute in 2012 and entails the abstraction of network functions from dedicated hardware <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. Once abstracted, the network functions are converted to Virtual Network Functions (VNFs), which are software-based applications that run on universal hardware such as data center servers and edge servers. Through NFV technology, several benefits can be realized, such as reduced capital and operational expenditures, improved network performance and operation, and improved network health <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. When considering NFV technology, one of the greatest challenges is the management and orchestration (MANO) of VNFs, which includes tasks such as the placement of VNFs on network servers, VNF scaling and VNF migration. The increasing complexity of networks, coupled with the NP-hard computational complexity of these problems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, has led NSPs to consider alternate approaches to address NFV MANO.</p>
</div>
</section>
<section id="S1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS3.5.1.1" class="ltx_text">I-C</span> </span><span id="S1.SS3.6.2" class="ltx_text ltx_font_italic">Intelligence and NFV</span>
</h3>

<div id="S1.SS3.p1" class="ltx_para">
<p id="S1.SS3.p1.1" class="ltx_p">Recently, the use of intelligence techniques such as ML and AA have been increasingly popular when considering NFV MANO functionalities. This increase in popularity is attributed in part to a major paradigm shift from analytical network modelling to data-driven network modelling. With the generation of increasing amounts of network data, NSPs are beginning to adopt intelligence technologies that leverage the previously untapped data and extract meaningful information. There are several benefits associated with the use of intelligence and the adoption of data-driven modelling in NFV MANO. Firstly, since network complexity is increasing, analytical system modelling becomes increasingly difficult; by modelling the system directly from the generated data, NSPs can get accurate system models without the need to describe the system mathematically in its entirety. Additionally, in the case of NFV MANO functionalities (<span id="S1.SS3.p1.1.1" class="ltx_text ltx_font_italic">i.e.,</span> VNF Placement), intelligence can be used to learn from past optimal VNF placements and predict future placements in real-time. This ability to predict optimal placements enables real-time optimal decision making, something which was previously not possible due to the complexity of optimization problem formulations and the static nature of near-optimal heuristic solutions. Additionally, the use of intelligence enables a plethora of new and innovative functionalities such as traffic, demand, and latency prediction and forecasting, which can be used to optimize scaling operations. Additionally, one of the main functionalities of 5G and beyond networks is automation in the form of self-healing, self-configuration, and self-optimization; all of these functionalities require extensive use of intelligence for forecasting and prediction thereby making intelligence an essential requirement of all 5G and beyond networks.</p>
</div>
</section>
<section id="S1.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS4.5.1.1" class="ltx_text">I-D</span> </span><span id="S1.SS4.6.2" class="ltx_text ltx_font_italic">Intelligent Transportation Systems</span>
</h3>

<div id="S1.SS4.p1" class="ltx_para">
<p id="S1.SS4.p1.1" class="ltx_p">The combination of MEC, NFV, and intelligence sets the stage for several emerging use cases, most notably, ITS <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. The ITS framework envisions a system of connected vehicles communicating with each other and with Intelligent Infrastructure (II) using dedicated short-range communications. Through ITS connectivity, Vehicular Clients (VCs) will have access to multiple types of services, including traffic, emergency, and infotainment <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. Considering the use of MEC in this system, these services will be provided through NSPs by means of VNFs placed close to the user at the network edge. To enable this, several Roadside Units (RSUs), acting as edge servers, will be placed along roads. These units will have the capability of collecting information such as traffic and weather conditions, locally processing that data, and sending it to various entities within the ITS system. Figure 1 shows a basic ITS system and highlights the various entities previously mentioned (1 – RSU, 2 – VC, 3 – II). Figure 1 also highlights the presence of entities capable of performing local intelligence, marked with the gears.</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<p id="S1.F1.1" class="ltx_p ltx_align_center"><span id="S1.F1.1.1" class="ltx_text"><img src="/html/2102.10142/assets/x1.png" id="S1.F1.1.1.g1" class="ltx_graphics ltx_img_landscape" width="210" height="57" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Basic Intelligent Transportation System Overview</figcaption>
</figure>
</section>
<section id="S1.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS5.5.1.1" class="ltx_text">I-E</span> </span><span id="S1.SS5.6.2" class="ltx_text ltx_font_italic">The Challenges of Machine Learning Implementation in ITS Systems</span>
</h3>

<div id="S1.SS5.p1" class="ltx_para">
<p id="S1.SS5.p1.1" class="ltx_p">There are several challenges regarding the implementation of ML in highly dynamic environments such as the IoV and ITS. These challenges are categorized into four major groupings, system complexity, model performance, privacy, and data management <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. System complexity is a major challenge when considering ITS as it is a very volatile environment; while roadside infrastructure may be constant in nature, vehicular clients are continually entering and leaving the system. This volatility presents a unique challenge regarding ML implementation as the operational domain is continuously changing, something which is not easily handled by traditional ML <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. The shifting operational domain leads to the second major challenge being model performance. As the functional domain changes, the performance of the model is severely impacted. Models using static local intelligence cannot adapt to changing environments and can become ineffective as their performance is severely degraded. Considering the criticality of an ITS system, the safeguard of human life is paramount. Any level of compromise in the system ranging from its infrastructure to its data, can endanger public safety. Finally, with an increasing number of network nodes with processing capabilities, the management of data becomes increasingly critical. Since the roadside infrastructure will have limited resource capacity, special consideration must be made regarding the efficient storage of data. Since the resource capacities of the roadside infrastructure will not allow for the storage of extensive data sets, the training phase of traditional localized ML techniques can be compromised due to the lack of sufficient data.</p>
</div>
</section>
<section id="S1.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS6.5.1.1" class="ltx_text">I-F</span> </span><span id="S1.SS6.6.2" class="ltx_text ltx_font_italic">Why Federated Learning?</span>
</h3>

<div id="S1.SS6.p1" class="ltx_para">
<p id="S1.SS6.p1.1" class="ltx_p">When considering possible methods of advanced intelligence applied to an ITS, Reinforcement Learning (RL) and Federated Learning (FL) are two standout options. RL is an intelligence method capable of learning complex policy decisions in a dynamic environment and has the ability to adapt to a changing domain through continual and experiential learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. However, the success of the computationally intensive training phase of RL is greatly dependent on its simulated training environment, the design of its reward function, and the tuning of its hyperparameters <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. Considering an ITS with multiple light-weight points of presence having limited processing and storage capabilities, the implementation of RL becomes increasingly challenging.</p>
</div>
<div id="S1.SS6.p2" class="ltx_para">
<p id="S1.SS6.p2.1" class="ltx_p">When considering an ITS, security and privacy are paramount; this applies both to vehicles and the data they generate. Since not all intelligence is created equal, a technique that maximizes data privacy while still meeting the required performance is essential to the feasibility of such a system. Furthermore, when considering the system environment, a distributed and communication-efficient intelligence method is required. Additionally, a form of intelligence that can overcome faults and failures quickly, thereby ensuring system resilience and service continuity, is a major contender for implementation. To simultaneously address privacy concerns while ensuring a resilient and intelligent system capable of excellent performance, we make a case for FL in the IoV and ITS. The remainder of this paper is organized as follows. Section II Outlines FL, its advantages, and its benefits. Section III outlines the applications of FL and showcases possible use cases. Finally, Section IV summarizes and concludes the paper.</p>
</div>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Federated Learning</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">FL is a key enabling technology for many emerging use cases. The following section will outline the main aspects of this technology, its benefits, and present a case study illustrating its effectiveness. Table 1 summarizes the various benefits provided by Federated Learning implementations, as outlined throughout this section.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Federated Learning Benefit Summary</figcaption>
<table id="S2.T1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.1.1.1" class="ltx_tr">
<th id="S2.T1.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T1.1.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.1.1.1.1" class="ltx_p" style="width:56.9pt;">Benefit</span>
</span>
</th>
<th id="S2.T1.1.1.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S2.T1.1.1.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.1.1.2.1.1" class="ltx_p" style="width:170.7pt;">Description</span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.1.2.1" class="ltx_tr">
<td id="S2.T1.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T1.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.2.1.1.1.1" class="ltx_p" style="width:56.9pt;">Collaborative Learning</span>
</span>
</td>
<td id="S2.T1.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.2.1.2.1.1" class="ltx_p" style="width:170.7pt;">Enables collaboration between multiple entities for intelligence.</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.3.2" class="ltx_tr">
<td id="S2.T1.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T1.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.3.2.1.1.1" class="ltx_p" style="width:56.9pt;">Distributed Learning</span>
</span>
</td>
<td id="S2.T1.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.3.2.2.1.1" class="ltx_p" style="width:170.7pt;">Enables intelligence across distributed nodes and enables intelligence
in new and emerging use cases.</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.4.3" class="ltx_tr">
<td id="S2.T1.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T1.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.4.3.1.1.1" class="ltx_p" style="width:56.9pt;">Decentralized Learning</span>
</span>
</td>
<td id="S2.T1.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.4.3.2.1.1" class="ltx_p" style="width:170.7pt;">Local nodes can train their own models and can operate independently
without the aggregation agent in failure scenarios.</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.5.4" class="ltx_tr">
<td id="S2.T1.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T1.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.5.4.1.1.1" class="ltx_p" style="width:56.9pt;">Data Availability</span>
</span>
</td>
<td id="S2.T1.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.5.4.2.1.1" class="ltx_p" style="width:170.7pt;">Allows the leveraging insights obtained from massive amounts of data
without the need for locally hosting the data.</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.6.5" class="ltx_tr">
<td id="S2.T1.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T1.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.6.5.1.1.1" class="ltx_p" style="width:56.9pt;">Data Privacy</span>
</span>
</td>
<td id="S2.T1.1.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.6.5.2.1.1" class="ltx_p" style="width:170.7pt;">Data is collected and processed at local nodes and not shared globally.</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.7.6" class="ltx_tr">
<td id="S2.T1.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T1.1.7.6.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.7.6.1.1.1" class="ltx_p" style="width:56.9pt;">Scalability</span>
</span>
</td>
<td id="S2.T1.1.7.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.7.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.7.6.2.1.1" class="ltx_p" style="width:170.7pt;">New nodes can easily be integrated into existing systems.</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.8.7" class="ltx_tr">
<td id="S2.T1.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T1.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.8.7.1.1.1" class="ltx_p" style="width:56.9pt;">Fault Recovery</span>
</span>
</td>
<td id="S2.T1.1.8.7.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.8.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.8.7.2.1.1" class="ltx_p" style="width:170.7pt;">Offers a rapid recovery scheme for nodes experiencing faults.</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.9.8" class="ltx_tr">
<td id="S2.T1.1.9.8.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T1.1.9.8.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.9.8.1.1.1" class="ltx_p" style="width:56.9pt;">High Availability</span>
</span>
</td>
<td id="S2.T1.1.9.8.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S2.T1.1.9.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.9.8.2.1.1" class="ltx_p" style="width:170.7pt;">Offers system continuity during failure scenarios.</span>
</span>
</td>
</tr>
<tr id="S2.T1.1.10.9" class="ltx_tr">
<td id="S2.T1.1.10.9.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T1.1.10.9.1.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.10.9.1.1.1" class="ltx_p" style="width:56.9pt;">Communication Efficiency</span>
</span>
</td>
<td id="S2.T1.1.10.9.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S2.T1.1.10.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S2.T1.1.10.9.2.1.1" class="ltx_p" style="width:170.7pt;">Model updates are sent instead of complete models or data.</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">What is Federated Learning</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">FL is a machine learning technique first proposed by Google in 2017 as a way of providing decentralized and collaborative learning across distributed nodes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Initially, FL was considered for applications relating to smartphones such as text prediction; however, since then, it has been used in fields such as medicine and image recognition. The FL architecture consists of multiple federated nodes and an aggregator agent. Initially, a global model is created by the aggregator agent and is distributed to all the federated nodes. Once received, the nodes begin by training the model on their locally stored data. Since each node is responsible for the collection and/or storage of its own data, each federated node possesses a unique training data set. Once the federated nodes have trained their models for several iterations (pre-defined in the aggregation scheme), the nodes compare the initial global model received to their locally trained model. An update is generated by each federated node, whereby the results of the comparison are stored. It must be noted that this update does not include the locally trained model itself; instead, it lists the discrepancies between the global and local models, thereby highlighting the changes made during the training process. The aggregator agent then samples the nodes according to the aggregation scheme and collected the model updates. Once collected, the updates are used to create a new global model that is distributed to the nodes, and the process repeats itself. Figure 2 outlines the FL process at a high level. However, to fully appreciate the entirety of the FL process, a more granular analysis of the federated nodes and the aggregator agent is required.</p>
</div>
<figure id="S2.F2" class="ltx_figure">
<p id="S2.F2.1" class="ltx_p ltx_align_center"><span id="S2.F2.1.1" class="ltx_text"><img src="/html/2102.10142/assets/x2.png" id="S2.F2.1.1.g1" class="ltx_graphics ltx_img_landscape" width="319" height="179" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Federated Learning High-Level Process Map</figcaption>
</figure>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Federated Nodes</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Federated Nodes are unique and versatile entities capable of data collection and processing, model training, and network communication. When considering federated nodes in IoV and ITS scenarios, the main entities which can be classified as such are VCs, RSUs, and II. In the envisioned ITS scenario, these entities will have various sensors and will be gathering a multitude of data. Each of these entities will have processing and communication capabilities.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.5.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.6.2" class="ltx_text ltx_font_italic">Aggregator Agent</span>
</h3>

<figure id="S2.F3" class="ltx_figure">
<p id="S2.F3.1" class="ltx_p ltx_align_center"><span id="S2.F3.1.1" class="ltx_text"><img src="/html/2102.10142/assets/x3.png" id="S2.F3.1.1.g1" class="ltx_graphics ltx_img_landscape" width="319" height="179" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Aggregation Agent Scheme Considerations</figcaption>
</figure>
<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">The aggregator agent is the main orchestrator behind the FL training process and is responsible for determining how often and how many nodes will be contributing to the global model update based on the aggregation scheme. Developing an aggregation scheme is the main challenge associated with FL as it directly affects the performance of FL process.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">When considering the aggregation scheme, the first decision to be taken is how the model updates received from each of the nodes will be consolidated into a single update used to generate the new global model. Traditionally, averaging has been used to combine all the model updates; however, increasingly, new strategies are emerging which take into consideration individual properties of the federated nodes, including resource availability and node criticality. By creating a more refined update aggregation strategy that captures domain-specific information, model performance can be greatly improved.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">The second consideration which must be made is the frequency of model updates. This frequency is a joint consideration between the number of local training iterations before the update and the time required to locally train the model. This consideration brings to light one of the main attributes of FL data; traditionally, most ML models assume that a dataset is independent and identically distributed (i.i.d.); however, this assumption is invalid for FL as it operates under the assumption that the data is non-i.i.d. When thinking about this intuitively, especially considering an IoV scenario that the data collected will not follow the i.i.d. assumption. Consider a scenario where a group of federated nodes are responsible for training object detection models at given intersections; the busier intersections will have more local data compared to those which are located in low-traffic areas, thereby creating a non-identically distributed scenario. Going back to the aggregation scheme, nodes with more local data will require a longer time to train their models and generate the update. This imbalance in data and, therefore, an imbalance in training time must be taken into consideration when selecting the frequency of model updates.</p>
</div>
<div id="S2.SS3.p4" class="ltx_para">
<p id="S2.SS3.p4.1" class="ltx_p">The final consideration, which must be made regarding the aggregation scheme, is the sampling strategy. Due to the nature of FL, especially in applications such as the IoV, all nodes will be gathering different data. Performing a model update using an insufficient amount of data is a futile task as it will not bring an overall benefit to the global model. Conversely, waiting for a node with an excessive amount of data to finish its training can hold back the training process and drastically reduce the speed at which the global model is trained. Furthermore, due to the dynamic nature of the network supporting MEC implementations, there could be a high volume of traffic resulting in higher communication latency at a given node; using resources to communicate model updates at such a time can further burden the network and have adverse effects on QoS requirements and service delivery. Finally, in the case of a fault or failure, a particular node can go offline; waiting for a model update at this time would be exclusively dependent on the extent of the fault and the ability to recover from the fault, and can greatly reduce the global model’s ability to progress in training. Taking these scenarios into consideration, a sampling of nodes must be conducted to determine which nodes will provide the greatest benefit to the current global model through their updates. This decision is domain-specific as in certain situations, the nodes with the greatest amount of data provide the most benefit, whereas, in other situations, the nodes with a moderate amount of data can speed up the training process and converge to a solution faster. Figure 3 outlines the various aspects of the aggregation scheme previously mentioned.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS4.5.1.1" class="ltx_text">II-D</span> </span><span id="S2.SS4.6.2" class="ltx_text ltx_font_italic">What are the Advantages of Federated Learning?</span>
</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">The main advantage of FL, arising from its decentralized and collaborative learning properties, is the preservation of privacy during the model training process. Since only local model updates are sent to the aggregator agent, the data used to train the local models remains with the local node. The fact that neither the aggregator agent nor the other federated nodes have access to a given node’s individual data unlocks an incredible potential for FL to be used in privacy-sensitive applications. One such privacy-sensitive application which has already begun to implement FL is the intelligent healthcare sector <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> . The most prevalent example in this sector is collaborative model training between hospitals. Traditionally, due to data privacy and patient confidentiality concerns, hospitals had only had access to their local patient data when training models, which created a data-availability bottleneck and was a key deterrent for the use of ML since the local data was insufficient. With FL, several hospitals can contribute to the training of a global model, which leverages updates from all their local models, thereby enabling an individual hospital to use insights from other participating hospitals to improve the performance of their models. This collaboration leads to the second main advantage of FL, data availability. Through the use of FL, not only is it possible to ensure data privacy, but it is also possible to use insights from non-local data, thereby increasing the total amount of data used for model training. This is especially important for nodes with low amounts of local data as an inadequate amount of data can prove to be detrimental to a model’s performance. Additionally, the method by which this data is processed is extremely advantageous as all nodes are solely responsible for processing their local data. The ability to leverage global data but only process local data makes FL especially applicable to resource-constrained nodes with low processing capabilities, such as those found in MEC IoV systems.</p>
</div>
<div id="S2.SS4.p2" class="ltx_para">
<p id="S2.SS4.p2.1" class="ltx_p">Another advantage of FL is the communication efficiencies experienced during the model training. Since there is no data transfer between local nodes and the aggregation agent, and no communication between nodes, FL is very efficient compared to centralized collaborative learning strategies. When considering the complex IoV and ITS network layout, this communication efficiency can alleviate a potential strain on network resources during times of high traffic, something which is increasingly important considering the critical services using the network and its services.</p>
</div>
<div id="S2.SS4.p3" class="ltx_para">
<p id="S2.SS4.p3.1" class="ltx_p">The final key advantage of FL is seen in a fault or failure mitigation scenario. In the case that a local node goes offline or loses connectivity, the FL training process can still continue normally. In the case where a node loses connectivity, it still has its local model to use and, therefore, won’t experience a fault. However, in the case where a node goes offline and loses its local model, once communication is restored, the aggregator agent can quickly push the current global model to the node. Having a global model the node can resume operation and restore performance. Furthermore, having a global model and then applying local training is an incredibly efficient failure mitigation strategy. Firstly, the model has already been developed and trained through a number of iterations. Secondly, local data from the failed node contributed to model development before the failure. Considering the abovementioned points, as soon as the node receives the global mode, it can begin using it, and through a minimal number of local training iterations, pre-failure performance can be quickly restored. The effectiveness of this mitigation strategy is highlighted when compared to alternative schemes, such as complete model retraining and the reinstatement of historical models. The complete model retraining strategy, as the name suggests, requires the entire retraining of the mode from scratchl using local data, something which is very time efficient and can increase downtime. The historical model reinstatement firstly requires the storage of previous models, and secondly, the retraining of these models, which is an improvement to the complete model retraining strategy, however, can prove to be inefficient in a highly dynamic and volatile network scenario. Since the global model is ‘live’ and constantly updating based on incoming data, it is the preferred failure mitigation strategy. To illustrate the capabilities of FL and its advantage over other failure strategies, we present a case study.</p>
</div>
</section>
<section id="S2.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS5.5.1.1" class="ltx_text">II-E</span> </span><span id="S2.SS5.6.2" class="ltx_text ltx_font_italic">Case Study</span>
</h3>

<figure id="S2.F4" class="ltx_figure">
<p id="S2.F4.1" class="ltx_p ltx_align_center"><span id="S2.F4.1.1" class="ltx_text"><img src="/html/2102.10142/assets/Failure_Scenario_Recovery_Strategies_Final.png" id="S2.F4.1.1.g1" class="ltx_graphics ltx_img_landscape" width="497" height="249" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Failure Recovery Strategy Comparisson</figcaption>
</figure>
<div id="S2.SS5.p1" class="ltx_para">
<p id="S2.SS5.p1.1" class="ltx_p"><span id="S2.SS5.p1.1.1" class="ltx_text ltx_font_italic">A Federated Learning – enabled RSU is located in a low traffic area and performs object classification tasks. Due to a recent construction project, the neighbourhood is experiencing a variety of previously unseen traffic. The RSU continually trains its local model to adapt to the changing environment; however, it experiences an outage and loses its local model. It can select one of the previously outline failure recovery strategies. Which one should it choose?</span></p>
</div>
<div id="S2.SS5.p2" class="ltx_para">
<p id="S2.SS5.p2.1" class="ltx_p">To simulate the scenario described above, the MNIST digit dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> was used. Initially, a model is trained on a set number of digits (<span id="S2.SS5.p2.1.1" class="ltx_text ltx_font_italic">i.e.,</span> even), which simulates the operation of the RSU before the construction project. Once the construction project begins, and previously unseen traffic is experienced, odd digits are gradually introduced into the training and testing datasets; however, training of this model is not complete as the fault is experienced. There are three possible fault recovery scenarios outlined:</p>
</div>
<div id="S2.SS5.p3" class="ltx_para">
<p id="S2.SS5.p3.1" class="ltx_p">1. A model is retrained from scratch using the local data available. The training and testing sets of this model will consist of even and odd integers to simulate the moment at which the fault was experienced.</p>
</div>
<div id="S2.SS5.p4" class="ltx_para">
<p id="S2.SS5.p4.1" class="ltx_p">2. A previous model is re-instated, and then training occurs using local data. The dataset used to train this model is the same as scenario 1.</p>
</div>
<div id="S2.SS5.p5" class="ltx_para">
<p id="S2.SS5.p5.1" class="ltx_p">3. A global federated model trained using 10 system nodes representing RSUs spread throughout the network is pushed to the failed node, and is instantly used to resume performance.</p>
</div>
<div id="S2.SS5.p6" class="ltx_para">
<p id="S2.SS5.p6.1" class="ltx_p">A comparison between the three mentioned failure mitigation strategies is exhibited in Figure 4. As seen through this figure, the federated recovery strategy performs the best as it instantly restores normal operation and performance returns to acceptable levels without any additional training iterations.<span id="footnotex1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>code for this use case is available at <a target="_blank" href="https://github.com/Western-OC2-Lab/FL-IOV-ITS.git" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Western-OC2-Lab/FL-IOV-ITS.git</a></span></span></span>
The main advantages of FL described throughout this section encompass many operational benefits, which are summarized in Table 1.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Applications</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">The following section outlines some of the various applications of FL in the IoV and ITS, including RSU Intelligence, NFV Orchestration, and Vehicular Intelligence.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">RSU Intelligence</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">As previously mentioned, ITS have entities known as RSUs, which will be located along roadways. These RSUs will be equipped with sensors to collect data and will possess basic processing capabilities. When considering the general FL application architectures, RSUs perfectly match since they are repeated entities capable of data collection and processing. Since the RSUs will be collecting (and receiving) a variety of different data, they are capable of applying FL in many different scenarios. One of the most important and prevalent applications is image processing. When considering a system of fully autonomous vehicles, image processing is essential both onboard the vehicular clients as well as roadside through the RSUs. Image processing tasks on these entities can range from pedestrian detection to collision reporting. When considering any transportation system, there are differing levels of vehicular traffic experienced throughout the system; this traffic imbalance can put certain RSUs at a great disadvantage as the data collection in low traffic areas will minimal compared to the data collection in high traffic areas. To mitigate this, FL applied across all RSUs can enable the collective use of all RSU data and the distribution of a complete model to RSUs which otherwise wouldn’t have an adequate amount of data to train a local model of their own. Another advantage of using FL for image processing is the ability to leverage the differing conditions (<span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">i.e.,</span> lighting) in RSU-collected images. Some RSUs will be placed in fully lit areas, while others might be placed in neighbourhoods with many trees and shaded regions. To ensure proper object detection, all RSUs should have models capable of operating under varying and changing conditions. Considering the criticality of object detection applications in RSUs, FL is essential for ensuring model performance and, subsequently, the safety of drivers and pedestrians alike.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">NFV Orchestration</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">NFV Orchestration presents a very appealing and intriguing application for FL. The most enticing property of FL, making it a candidate for NFV Orchestration is its privacy and security due to the critical services (<span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_italic">i.e.,</span> financial, emergency) NFV-enabled networks support. When considering the IoV and ITS as an extension of current networks, NFV Orchestration will play a critical role in vehicular service delivery. However, there is one major difference between traditional NFV Orchestration and NFV Orchestration for MEC enabled IoV and ITS. With many delay-sensitive applications ranging from vehicular safety and routing to immersive virtual reality services, NSPs are facing an unprecedented challenge of reducing end-to-end application latencies to less than 1ms for ultra-low latency applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>. To do this, points of presence such as RSUs which are placed at the very edge of the network will act as network nodes capable of hosting VNFs. However, without proper Orchestration, the stringent latency requirements will not be met. Traditionally, NSPs have had to resort to using near-optimal heuristic solutions to address the infeasibility of optimization problem formulations due to their runtime complexity, however, with the adoption of ultra-low latency applications, near-optimal heuristic solutions are also becoming infeasible. To mitigate the infeasibility of traditional NFV Orchestration techniques, NSPs have been exploring ML as an alternative. Already, ML techniques are being applied to NFV Orchestration tasks such as VNF placement <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> and migration <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> with incredible success due to their ability to approach the performance of the optimization model formulations with an incredible reduction in time-complexity.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">When considering ML in the IoV and ITS, the use of FL is the next logical step. Due to the increasing types of services, each with its own complexities coupled with the expansion of traditional networks to MEC enabled networks, NFV Orchestration activities will drastically change. The transition to MEC-enabled networks will usher in the vast expansion of network nodes. This will require the partitioning of current networks into much smaller sub-networks, each with their own NFV Orchestrator. Additionally, incorporating aspects from 5G networking, each of these sub-networks may be further partitioned using network slicing techniques. This increased complexity promotes the use of FL as NFV Orchestrators from different network partitions can use collaborative ML training to create models capable of completing orchestration tasks such as VNF Placement, Scaling, Termination and Migration. Figure 5 illustrates the complexity of vehicular requests in a 5G-enabled ITS.</p>
</div>
<figure id="S3.F5" class="ltx_figure">
<p id="S3.F5.1" class="ltx_p ltx_align_center"><span id="S3.F5.1.1" class="ltx_text"><img src="/html/2102.10142/assets/x4.png" id="S3.F5.1.1.g1" class="ltx_graphics ltx_img_landscape" width="319" height="179" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Vehicular Application Requests in 5G-enabled ITS</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Vehicular Intelligence</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Vehicular intelligence in the IoV and ITS can describe a plethora of applications, including in-vehicle intelligence (<span id="S3.SS3.p1.1.1" class="ltx_text ltx_font_italic">i.e.,</span> communications), image processing (<span id="S3.SS3.p1.1.2" class="ltx_text ltx_font_italic">i.e.,</span> lane detection), and forecasting (<span id="S3.SS3.p1.1.3" class="ltx_text ltx_font_italic">i.e.,</span> road conditions); however, a very interesting use case currently being heavily explored in the manufacturing sector relates to predictive maintenance. Predictive maintenance uses operational data to predict when a specific component will fail and suggests a maintenance schedule that will pro-actively address the failure through planned maintenance. Unplanned maintenance is extremely costly in manufacturing as a break in production can result in the loss of millions in revenue. Additionally, reactive maintenance takes a large toll on assets and reduces their lifespan. Several implementations of predictive maintenance models have shown incredible success; one main example stemming from the oil and gas industry is Royal Shell Corp who has prevented millions of dollars in lost revenue and damages while improving the longevity of their assets <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. The same benefits can be experienced when considering the application of predictive maintenance on vehicular clients in the IoV and ITS. It is estimated that in 2016 there were 1.32B vehicles globally <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, a number which is expected to grow exponentially in the next decades. In an ITS scenario, each of these vehicles would have an extensive log capturing real-time measurements from its various sensors. By leveraging FL, along with this vast collection of data, comprehensive predictive maintenance models can be built. While the mechanics of how to select which data is used to build these models is still an open question (<span id="S3.SS3.p1.1.4" class="ltx_text ltx_font_italic">i.e.,</span> brand-based, location-based, network-based), the impact FL will have on predictive vehicular maintenance is indisputable.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Summary and Conclusion</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">As demonstrated throughout this paper, Federated Learning has incredible potential in terms of its applicability to the Internet of Vehicles and Intelligent Transportation Systems. From the various number of use cases, including Roadside Unit Intelligence, Network Function Virtualization Management and Orchestration, and Vehicular Intelligence to the incredible number of benefits it provides, Federated Learning is a key enabler for next-generation networking technologies.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
ETSI, ”MEC in 5G networks” . [Online]. Available: <a target="_blank" href="https://www.etsi.org/images/files/ETSIWhitePapers/etsi_wp28_mec_in_5G_FINAL.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.etsi.org/images/files/ETSIWhitePapers/etsi_wp28_mec_in_5G_FINAL.pdf</a>

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
ETSI, ”Network Functions Virtualisation: An Introduction, Benefits, Enablers, Challenges and Call for Action” . [Online]. Available: <a target="_blank" href="https://portal.etsi.org/NFV/NFV_White_Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://portal.etsi.org/NFV/NFV_White_Paper.pdf</a>

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
H. Hawilo, A. Shami, M. Mirahmadi and R. Asal, ”NFV: state of the art, challenges, and implementation in next-generation mobile networks (vEPC),” <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">IEEE Network</span>, vol. 28, no. 6, pp. 18-26, 2014.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
D. M. Manias <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">et al.</span>, “Machine Learning for Performance-Aware Virtual Network Function Placement,” <span id="bib.bib4.2.2" class="ltx_text ltx_font_italic">IEEE GlobeCom</span>, Waikoloa, USA, 2019, pp. 1-6.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
<span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Intelligent Transport Systems (ITS); Vehicular Communications; Basic Set of Applications; Definitions</span>, ETSI TR 102 638 V1.1.1, June 2009. [Online]. Available:
<a target="_blank" href="https://www.etsi.org/deliver/etsi_tr/102600_102699/102638/01.01.01_60/tr_102638v010101p.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.etsi.org/deliver/etsi_tr/102600_102699/102638/01.01.01_60/tr_102638v010101p.pdf</a>

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
D. M. Manias and A. Shami, The Need for Advanced Intelligence in NFV Management and Orchestration,” to appear in IEEE Network. 2020.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
J. Konečný, <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">et al.</span>, ”Federated learning: Strategies for improving communication efficiency.” <span id="bib.bib7.2.2" class="ltx_text ltx_font_italic">arXiv</span> preprint, 2016.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
T. S. Brisimi, <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">et al.</span>, ”Federated learning of predictive models from federated electronic health records.” <span id="bib.bib8.2.2" class="ltx_text ltx_font_italic">International journal of medical informatics</span> pp. 59-67, 2018.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner. ”Gradient-based learning applied to document recognition.” <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Proceedings of the IEEE</span>, 86(11):2278-2324, November 1998.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
ETSI, ”5G; Study on scenarios and requirements for next generation access technologies.” [Online]. Available: <a target="_blank" href="https://www.etsi.org/deliver/etsi_tr/138900_138999/138913/14.03.00_60/tr_138913v140300p.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.etsi.org/deliver/etsi_tr/138900_138999/138913/14.03.00_60/tr_138913v140300p.pdf</a>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
H. Hawilo, M. Jammal and A. Shami, ”Network Function Virtualization-Aware Orchestrator for Service Function Chaining Placement in the Cloud,” <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">in IEEE Journal on Selected Areas in Communications</span>, vol. 37, no. 3, pp. 643-655, March 2019.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
D. M. Manias, H. Hawilo, and A. Shami,“A Machine Learning - Based Migration Strategy for Virtual Network Function Instances,” <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">SAI FTC</span>, Vancouver, Canada, pp. 1-16, 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Shell Global, ”The Benefits of Predictive Maintenance.” [Online]. Available: <a target="_blank" href="https://www.shell.com/business-customers/lubricants-for-business/industry-insights/the-benefits-of-predictive-maintenance.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.shell.com/business-customers/lubricants-for-business/industry-insights/the-benefits-of-predictive-maintenance.html</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
OICA, ”Vehicles in Use.”[Online]. Available: <a target="_blank" href="http://www.oica.net/category/vehicles-in-use/" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://www.oica.net/category/vehicles-in-use/</a>

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2102.10141" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2102.10142" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2102.10142">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2102.10142" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2102.10143" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar 16 01:11:52 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
