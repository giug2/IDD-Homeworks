<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG</title>
<!--Generated on Tue Oct  8 12:28:12 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.05983v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S1" title="In Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S2" title="In Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S3" title="In Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Challenges of Long context LLMs in RAG</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S3.SS1" title="In 3 Challenges of Long context LLMs in RAG ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>The Effect of retrieved context size on RAG performance</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S3.SS2" title="In 3 Challenges of Long context LLMs in RAG ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>The interplay of retrieval quality and LLM capabilities</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S3.SS3" title="In 3 Challenges of Long context LLMs in RAG ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>The importance of hard negatives for long-context LLM evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S4" title="In Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Simple and effective training-free RAG improvement</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S5" title="In Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Improving Robustness for RAG via Data-Augmented Fine-Tuning</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S5.SS1" title="In 5 Improving Robustness for RAG via Data-Augmented Fine-Tuning ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Implicitly improving LLM robustness through fine-tuning</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S5.SS2" title="In 5 Improving Robustness for RAG via Data-Augmented Fine-Tuning ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Enhancing relevance identification through reasoning augmentation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S6" title="In Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Data-Centric Perspectives on Fine-tuning LLMs for RAG</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S7" title="In Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A1" title="In Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Retriever performance and similarity</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A2" title="In Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Long context LLMs in RAG analysis on other datasets</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A2.SS1" title="In Appendix B Long context LLMs in RAG analysis on other datasets ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>The Effect of retrieved context size on RAG performance</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A2.SS2" title="In Appendix B Long context LLMs in RAG analysis on other datasets ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>The importance of hard negatives for long-context LLM evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A3" title="In Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Illustration of Section <span class="ltx_text ltx_ref_tag">3.3</span>: Hard negative study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A4" title="In Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Hard negatives case study</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A5" title="In Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Retrieval reordering</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A6" title="In Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F </span>Datasets</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A6.SS1" title="In Appendix F Datasets ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F.1 </span>Training datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A6.SS2" title="In Appendix F Datasets ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F.2 </span>Testing datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A6.SS3" title="In Appendix F Datasets ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F.3 </span>Retrieval corpus</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A7" title="In Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G </span>Implicit RAG Fine-Tuning Experimental Setting</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A7.SS1" title="In Appendix G Implicit RAG Fine-Tuning Experimental Setting ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G.1 </span>Training settings</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A7.SS2" title="In Appendix G Implicit RAG Fine-Tuning Experimental Setting ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G.2 </span>Evaluation Settings</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A8" title="In Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">H </span>RAG Finetuning with Intermediate Reasoning Experimental Setting</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A8.SS1" title="In Appendix H RAG Finetuning with Intermediate Reasoning Experimental Setting ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">H.1 </span>Training settings</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A8.SS2" title="In Appendix H RAG Finetuning with Intermediate Reasoning Experimental Setting ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">H.2 </span>Evaluation settings</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A9" title="In Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">I </span>Data-Augmented RAG Case Studies</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A10" title="In Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">J </span>Data-Augmented RAG Finetuning on Gemma-2-9B</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A11" title="In Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">K </span>Data-Augmented RAG Finetuning on Mistral-Nemo-12B</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A12" title="In Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">L </span>Data-Augmented RAG Finetuning on Gemini-1.0-Pro</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A13" title="In Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">M </span>Training data scaling and RAG performance.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A14" title="In Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">N </span>RAG-specific tuning data inside SFT mixtures</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\pdftrailerid</span>
<p class="ltx_p" id="p1.2">redacted





<span class="ltx_ERROR undefined" id="p1.2.1">\correspondingauthor</span>bowenj4@illinois.edu







</p>
</div>
<h1 class="ltx_title ltx_title_document">Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Bowen Jin
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jinsung Yoon
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Google Cloud AI Research
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jiawei Han
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">University of Illinois at Urbana-Champaign
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Sercan Ö. Arık
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Google Cloud AI Research
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Retrieval-augmented generation (RAG) empowers large language models (LLMs) to utilize external knowledge sources.
The increasing capacity of LLMs to process longer input sequences opens up avenues for providing more retrieved information, to potentially enhance the quality of generated outputs.
It is plausible to assume that a larger retrieval set would contain more relevant information (higher recall), that might result in improved performance.
However, our empirical findings demonstrate that for many long-context LLMs, the quality of generated output initially improves first, but then subsequently declines as the number of retrieved passages increases.
This paper investigates this phenomenon, identifying the detrimental impact of retrieved "hard negatives" as a key contributor.
To mitigate this and enhance the robustness of long-context LLM-based RAG, we propose both training-free and training-based approaches.
We first showcase the effectiveness of retrieval reordering as a simple yet powerful training-free optimization.
Furthermore, we explore training-based methods, specifically RAG-specific implicit LLM fine-tuning and RAG-oriented fine-tuning with intermediate reasoning, demonstrating their capacity for substantial performance gains.
Finally, we conduct a systematic analysis of design choices for these training-based methods, including data distribution, retriever selection, and training context length.</p>
</div>
<section class="ltx_section" id="S1" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Retrieval-augmented generation (RAG) <cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib8" title="">2023</a>)</cite> empowers large language models (LLMs) to utilize external information sources by selecting the most relevant pieces from a large corpus <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib35" title="">2023</a>)</cite>, thereby enhancing their effectiveness, customizability and efficiency in complex problem-solving. RAG can also mitigate issues such as factual inaccuracies <cite class="ltx_cite ltx_citemacro_citep">(Augenstein et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib3" title="">2023</a>)</cite> and hallucinations <cite class="ltx_cite ltx_citemacro_citep">(Huang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib11" title="">2023</a>)</cite>, which LLMs often exhibit when confronted with knowledge-intensive tasks. RAG systems typically employ a retriever to identify relevant information from a corpus, which is then presented in the context of an LLM as the generator.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Recent advances in computational resources and methodological innovations have enabled the development of LLMs that support increasingly longer context <cite class="ltx_cite ltx_citemacro_citep">(Reid et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib21" title="">2024</a>; Dubey et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib7" title="">2024</a>)</cite>.
This has even opened up new avenues for directly inputting entire corpora or knowledge bases into the LLMs.
Yet, it would still not be feasible for large corpora (<span class="ltx_text ltx_font_italic" id="S1.p2.1.1">e.g.</span>, Wikipedia) and can incur higher computational costs.
Despite extensive research on RAG <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib30" title="">2023</a>; Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib18" title="">2024</a>; Lee et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib17" title="">2024</a>)</cite>, the interplay with long-context LLMs, particularly how to optimally design RAG systems using them effectively, remains under-explored.
Existing works <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib19" title="">2024</a>; Asai et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib2" title="">2024</a>; Yoran et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib31" title="">2024</a>)</cite> propose tuning LLMs for RAG, but predominantly focus on a limited number of retrieved passages (fewer than 10).
Intuitively, longer context would allow for the inclusion of more retrieved passages, leading to higher recall and potentially improved performance.
However, our findings reveal that this does not always hold true and highlight the need for a careful re-evaluation of standard RAG designs when utilizing long-context LLMs.
We demonstrate that achieving optimal performance in such systems and to fully utilize the opportunities provided by the LLMs require a holistic rethinking and effective novel approaches to the unique challenges.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">This paper presents comprehensive analyses on long-context LLMs in RAG systems.
Contrary to the suggestions of previous work <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib30" title="">2023</a>; Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib18" title="">2024</a>)</cite>, our research reveals that increasing the number of retrieved passages does not consistently improve performance with long-context LLMs (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S3.SS1" title="3.1 The Effect of retrieved context size on RAG performance ‣ 3 Challenges of Long context LLMs in RAG ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">3.1</span></a>).
Instead, we observe that the generative modeling performance initially increases and then declines – simply providing more retrieved passages does not guarantee better outcomes.
Using stronger retrievers is also not a mitigation mechanism – indeed the performance degradation can even be more severe with them.
For deeper understanding of the phenomenon, we conduct further investigations, which reveal that increasing the number of retrieved passages can introduce irrelevant information (“noise”) that can mislead the LLM generation (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S3.SS2" title="3.2 The interplay of retrieval quality and LLM capabilities ‣ 3 Challenges of Long context LLMs in RAG ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">3.2</span></a>).
We also examine the impact of “hard negatives” of different retrievers on the LLMs, and show that there are scenarios where the ‘hard negatives’ from stronger retrievers might confuse the LLM generation even more than those from weaker retrievers (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S3.SS3" title="3.3 The importance of hard negatives for long-context LLM evaluation ‣ 3 Challenges of Long context LLMs in RAG ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">3.3</span></a>).</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">To address the challenges identified in our analyses, we propose three methods, encompassing both training-free and training-based approaches, to enhance the performance of long-context LLMs in RAG applications:
(1) Retrieval reordering: recognizing the "lost-in-the-middle" phenomenon observed for long-context LLMs <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib20" title="">2024</a>)</cite>, we propose reordering retrieved documents based on their retrieval scores.
By prioritizing documents with higher scores at the beginning and end of the input sequences, we guide the LLMs’ attention towards more relevant information and mitigate the impact of hard negatives.
(2) Implicit robustness fine-tuning: given the ability to handle noisy retrieved context is not explicitly acquired during standard LLM training, we propose tuning the LLMs with the data comprising queries and retrieved documents, including those with potential noise.
This encourages the LLMs to implicitly learn robustness to hard negatives.
(3) Explicit relevance fine-tuning: while the previous method implicitly enhances robustness, it does not explicitly teach the LLMs to identify relevant documents.
Therefore, we propose augmenting the LLM tuning with an intermediate reasoning step, where the LLMs are trained to analyze the retrieved documents and explicitly identify relevant information before generating the final output.
This approach aims to improve the LLMs’ ability to discern relevant information from noise within the retrieved context.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Overall, the main contributions can be summarized as follows:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">Systematic analysis of long-context RAG: we systematically analyze the use of long-context LLMs in RAG systems, specifically examining the impact of retrieved "hard negatives" on performance.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">Novel methods for robust RAG: we propose three methods to improve the robustness of long-context LLMs in RAG: (1) a training-free method based on retrieval reordering, (2) implicit tuning for robustness to hard negatives and (3) explicit tuning with intermediate reasoning for relevance identification. Overall, our proposed approaches show significant accuracy and robustness improvements on long-context RAG performance.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Comprehensive study of RAG-specific LLM tuning: we conduct a thorough investigation into various factors influencing the effectiveness of RAG-specific tuning, including data distribution, the employed retriever, and training context length.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Large language models (LLMs) can be prone to hallucinations especially at knowledge-intensive tasks <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib35" title="">2023</a>; Huang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib11" title="">2023</a>; Augenstein et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib3" title="">2023</a>)</cite>.
Retrieval-augmented generation (RAG) addresses this by incorporating external knowledge sources to provide accurate and relevant information <cite class="ltx_cite ltx_citemacro_citep">(Gao et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib8" title="">2023</a>)</cite>.
Traditional RAG systems comprise a retriever to identify relevant information and a generator to synthesize the answer <cite class="ltx_cite ltx_citemacro_citep">(Zhao et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib36" title="">2024</a>; Zhu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib38" title="">2021</a>)</cite>.
While previous research focused on improving either the retriever <cite class="ltx_cite ltx_citemacro_citep">(Karpukhin et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib15" title="">2020</a>; Izacard et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib12" title="">2021</a>; Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib26" title="">2022</a>)</cite> or the generator <cite class="ltx_cite ltx_citemacro_citep">(Dong et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib6" title="">2022</a>; Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib20" title="">2024</a>; Agarwal et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib1" title="">2024</a>)</cite> in isolation, we take a holistic approach.
Conducting comprehensive analyses of the entire RAG system, we focus on the challenges and opportunities presented by using long-context LLMs as generators. We propose novel solutions to better employ them in long-context RAG.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Increased computational resources and advancements in efficient training methods have pushed LLMs supporting longer inputs <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib27" title="">2024</a>; Zhou et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib37" title="">2024</a>)</cite>.
While long-context LLMs <cite class="ltx_cite ltx_citemacro_citep">(Reid et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib21" title="">2024</a>)</cite> demonstrated impressive performance on benchmarks like "needle-in-the-haystack" <cite class="ltx_cite ltx_citemacro_citep">(Kamradt, <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib14" title="">2023</a>)</cite> and RULER <cite class="ltx_cite ltx_citemacro_citep">(Hsieh et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib9" title="">2024a</a>)</cite>, these benchmarks often rely on random negative examples and do not accurately reflect the challenges posed by the "hard negatives" encountered in real-world RAG scenarios <cite class="ltx_cite ltx_citemacro_citep">(Cuconasu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib5" title="">2024</a>)</cite>.
Furthermore, existing studies on long-context LLMs in multi-document settings <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib20" title="">2024</a>; Shi et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib23" title="">2023</a>)</cite> often assume a single "golden" document and random negatives, which differs from the RAG context where multiple relevant passages and hard negatives may exist <cite class="ltx_cite ltx_citemacro_citep">(Hsieh et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib10" title="">2024b</a>; Cuconasu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib5" title="">2024</a>)</cite>.
Although some research has explored the relationship between RAG and long-context LLMs <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib30" title="">2023</a>; Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib18" title="">2024</a>; Lee et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib17" title="">2024</a>)</cite>, these works take different perspectives.
They mainly focus on studying the (1) trade-offs between RAG and long-context LLMs <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib30" title="">2023</a>)</cite>, (2) routers to manage RAG and long-context LLMs <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib18" title="">2024</a>)</cite>, (3) and the potential for LLMs to replace retrieval entirely <cite class="ltx_cite ltx_citemacro_citep">(Lee et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib17" title="">2024</a>)</cite>, while leaving long-context LLMs as generators in RAG under-explored.
We delve deeper into the potential benefits of long-context LLMs for RAG and investigate how to optimize these LLMs specifically for this application.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Previous research has explored adapting LLMs for RAG using instruction tuning <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib33" title="">2023</a>)</cite>.
RetRobust <cite class="ltx_cite ltx_citemacro_citep">(Yoran et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib31" title="">2024</a>)</cite> fine-tunes LLMs with 1 retrieved relevant passage or random negative passage to make it robust to irrelevant passage.
RA-DIT <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib19" title="">2024</a>)</cite> conducts dual instruction tuning to make the LLM more effectively leverage retrieved information and retriever provide results more aligned with LLM preference.
Self-RAG <cite class="ltx_cite ltx_citemacro_citep">(Asai et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib2" title="">2024</a>)</cite> introduces a framework to train a LM that dynamically retrieves passages, generates content, and evaluates the retrieved passages for improved performance.
RAFT <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib34" title="">2024</a>)</cite> trains the LLMs to improve their ability to answer questions in “open-book” in-domain settings.
More recently, RankRAG <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib32" title="">2024</a>)</cite> tunes a LLM for the dual purpose of context ranking and answer generation in RAG.
InstructRAG <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib29" title="">2024</a>)</cite> finetunes the LLM to generate self-synthesized rationales rather than directly answering the question.
However, these existing efforts primarily focus on tuning with a limited number of retrieved passages (typically fewer than 10) and do not fully leverage the potential of long-context LLMs.
This work aims to address this gap by specifically investigating how to optimize long-context LLMs for large-scale RAG, where the number of retrieved passages can be significantly higher.</p>
</div>
</section>
<section class="ltx_section" id="S3" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Challenges of Long context LLMs in RAG</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">We present a systematic investigation into the challenges of utilizing long-context LLMs in RAG.
Each subsection focuses on a specific research question, outlining corresponding experiments and analyzing the results on the key challenges.
These insights inform the development of targeted solutions for improving RAG performance with long-context LLMs, which are presented in subsequent sections.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>The Effect of retrieved context size on RAG performance</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">This subsection investigates the relationship between the number of retrieved passages and the performance of long-context LLMs in RAG systems.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p2.1.1">Research question.</span>
Long-context LLMs offer the potential to incorporate more retrieved passages into RAG systems. This raises a crucial question:
<span class="ltx_text ltx_font_italic" id="S3.SS1.p2.1.2"> Does a larger volume of retrieved context consistently translate to better performance when using long-context LLMs in RAG?</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p3.1.1">Experimental setting.</span>
We evaluate the performance of RAG systems on the Natural Questions (NQ) <cite class="ltx_cite ltx_citemacro_citep">(Kwiatkowski et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib16" title="">2019</a>)</cite> dataset using two different retrievers (BM25 <cite class="ltx_cite ltx_citemacro_citep">(Robertson et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib22" title="">2009</a>)</cite> and e5 <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib26" title="">2022</a>)</cite>, where e5 exhibits higher performance on NQ (<math alttext="\text{Recall}@40" class="ltx_Math" display="inline" id="S3.SS1.p3.1.m1.1"><semantics id="S3.SS1.p3.1.m1.1a"><mrow id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml"><mtext id="S3.SS1.p3.1.m1.1.1.2" xref="S3.SS1.p3.1.m1.1.1.2a.cmml">Recall</mtext><mo id="S3.SS1.p3.1.m1.1.1.1" xref="S3.SS1.p3.1.m1.1.1.1.cmml">⁢</mo><mi id="S3.SS1.p3.1.m1.1.1.3" mathvariant="normal" xref="S3.SS1.p3.1.m1.1.1.3.cmml">@</mi><mo id="S3.SS1.p3.1.m1.1.1.1a" xref="S3.SS1.p3.1.m1.1.1.1.cmml">⁢</mo><mn id="S3.SS1.p3.1.m1.1.1.4" xref="S3.SS1.p3.1.m1.1.1.4.cmml">40</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><apply id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1"><times id="S3.SS1.p3.1.m1.1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1.1"></times><ci id="S3.SS1.p3.1.m1.1.1.2a.cmml" xref="S3.SS1.p3.1.m1.1.1.2"><mtext id="S3.SS1.p3.1.m1.1.1.2.cmml" xref="S3.SS1.p3.1.m1.1.1.2">Recall</mtext></ci><ci id="S3.SS1.p3.1.m1.1.1.3.cmml" xref="S3.SS1.p3.1.m1.1.1.3">@</ci><cn id="S3.SS1.p3.1.m1.1.1.4.cmml" type="integer" xref="S3.SS1.p3.1.m1.1.1.4">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">\text{Recall}@40</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p3.1.m1.1d">Recall @ 40</annotation></semantics></math> is 0.90 with e5 and 0.73 with BM25)) and four long-context LLMs (Gemma-7B-Chat <cite class="ltx_cite ltx_citemacro_citep">(Team et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib24" title="">2024a</a>)</cite>, Gemma-2-9B-Chat <cite class="ltx_cite ltx_citemacro_citep">(Team et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib25" title="">2024b</a>)</cite>, Mistral-Nemo-12B-Instruct <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib13" title="">2023</a>)</cite> and Gemini-1.5-pro <cite class="ltx_cite ltx_citemacro_citep">(Reid et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib21" title="">2024</a>)</cite>).
We systematically vary the number of passages retrieved by each retriever.</p>
</div>
<figure class="ltx_figure" id="S3.F1">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F1.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="306" id="S3.F1.sf1.g1" src="x1.png" width="408"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F1.sf1.2.1.1" style="font-size:80%;">(a)</span> </span><span class="ltx_text" id="S3.F1.sf1.3.2" style="font-size:80%;">RAG performance with e5 retriever</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F1.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="306" id="S3.F1.sf2.g1" src="x2.png" width="408"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F1.sf2.2.1.1" style="font-size:80%;">(b)</span> </span><span class="ltx_text" id="S3.F1.sf2.3.2" style="font-size:80%;">RAG performance with BM25 retriever</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Impact of retrieved context size on RAG performance with 4 different LLMs on NQ. Increasing the number of retrieved passages initially improves performance but then leads to a decline. This degradation is more pronounced using a retriever (e5) that exhibits higher recall@k on NQ compared to BM25 (<math alttext="\text{Recall}@40" class="ltx_Math" display="inline" id="S3.F1.2.m1.1"><semantics id="S3.F1.2.m1.1b"><mrow id="S3.F1.2.m1.1.1" xref="S3.F1.2.m1.1.1.cmml"><mtext id="S3.F1.2.m1.1.1.2" xref="S3.F1.2.m1.1.1.2a.cmml">Recall</mtext><mo id="S3.F1.2.m1.1.1.1" xref="S3.F1.2.m1.1.1.1.cmml">⁢</mo><mi id="S3.F1.2.m1.1.1.3" mathvariant="normal" xref="S3.F1.2.m1.1.1.3.cmml">@</mi><mo id="S3.F1.2.m1.1.1.1b" xref="S3.F1.2.m1.1.1.1.cmml">⁢</mo><mn id="S3.F1.2.m1.1.1.4" xref="S3.F1.2.m1.1.1.4.cmml">40</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.F1.2.m1.1c"><apply id="S3.F1.2.m1.1.1.cmml" xref="S3.F1.2.m1.1.1"><times id="S3.F1.2.m1.1.1.1.cmml" xref="S3.F1.2.m1.1.1.1"></times><ci id="S3.F1.2.m1.1.1.2a.cmml" xref="S3.F1.2.m1.1.1.2"><mtext id="S3.F1.2.m1.1.1.2.cmml" xref="S3.F1.2.m1.1.1.2">Recall</mtext></ci><ci id="S3.F1.2.m1.1.1.3.cmml" xref="S3.F1.2.m1.1.1.3">@</ci><cn id="S3.F1.2.m1.1.1.4.cmml" type="integer" xref="S3.F1.2.m1.1.1.4">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.2.m1.1d">\text{Recall}@40</annotation><annotation encoding="application/x-llamapun" id="S3.F1.2.m1.1e">Recall @ 40</annotation></semantics></math> is 0.90 with e5 and 0.73 with BM25). The maximum number of retrieved passages varies across LLMs due to differences in their maximum token limits.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p4.1.1">Observations.</span>
Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S3.F1" title="Figure 1 ‣ 3.1 The Effect of retrieved context size on RAG performance ‣ 3 Challenges of Long context LLMs in RAG ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">1</span></a> presents the following key observations:
1) Strong Retriever (e5): Across all LLMs, increasing the number of retrieved passages initially improves performance, but then leads to a sharp decline or plateau.
2) Weak Retriever (BM25): Performance generally exhibits a continuous increase or a slight decrease as the number of retrieved passages increases.
While these observations may appear counter-intuitive - given that one might expect monotonic improvements due to higher recall (<span class="ltx_text ltx_font_italic" id="S3.SS1.p4.1.2">i.e.</span>, a greater chance of retrieving relevant information) - the inclusion of additional documents can reduce precision, with irrelevant or misleading passages detracting LLMs from overall performance.
Comparison of different retrievers and the results on other datasets are shown in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A1" title="Appendix A Retriever performance and similarity ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">A</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A2.SS1" title="B.1 The Effect of retrieved context size on RAG performance ‣ Appendix B Long context LLMs in RAG analysis on other datasets ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">B.1</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p5.1.1">Insights.</span>
The effectiveness of increasing retrieved context size in RAG depends on the strength of the retriever.
With a strong retriever, performance exhibits an “inverted-U pattern”, while a weak retriever shows more consistent, albeit potentially limited, improvement.
This suggests that factors beyond simply the amount of retrieved information are at play.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>The interplay of retrieval quality and LLM capabilities</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">This subsection delves into the factors hindering the performance of long-context LLMs in RAG, aiming to discern whether limitations arise from retrieval quality or the LLM’s ability to process the retrieved information.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p2.1.1">Research question.</span> <span class="ltx_text ltx_font_italic" id="S3.SS2.p2.1.2">Do the observed performance bottlenecks originate from limitations in the retriever’s ability to identify relevant information, or from the long-context LLM’s capacity to effectively utilize the retrieved context?</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.1">Experimental setting.</span>
We analyze the relationship between RAG performance and retrieval quality, specifically recall and precision, using the Gemma-2-9B-Chat LLM with both e5 and BM25 retrievers (Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S3.F2" title="Figure 2 ‣ 3.2 The interplay of retrieval quality and LLM capabilities ‣ 3 Challenges of Long context LLMs in RAG ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">2</span></a>).
Recall@k measures the presence of relevant passages within the top-k retrieved passages, while precision@k quantifies the proportion of relevant passages among them.</p>
</div>
<figure class="ltx_figure" id="S3.F2">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F2.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="306" id="S3.F2.sf1.g1" src="x3.png" width="408"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.sf1.2.1.1" style="font-size:80%;">(a)</span> </span><span class="ltx_text" id="S3.F2.sf1.3.2" style="font-size:80%;">Retrieval with e5 retriever</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F2.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="306" id="S3.F2.sf2.g1" src="x4.png" width="408"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.sf2.2.1.1" style="font-size:80%;">(b)</span> </span><span class="ltx_text" id="S3.F2.sf2.3.2" style="font-size:80%;">Retrieval with BM25 retriever</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Analyzing the relationship between RAG performance and retrieval quality (recall/precision) using Gemma-2-9B-Chat with e5 and BM25 retrievers. (1) Accuracy vs. Recall: RAG accuracy consistently falls below retrieval recall for both retrievers, indicating that the presence of relevant information does not guarantee correct answers. This highlights the detrimental impact of irrelevant passages on LLM performance.
(2) Precision and hard negatives: Despite higher precision with e5, the performance degradation with increasing retrieval size is more pronounced compared to BM25. This demonstrates that precision alone is an insufficient metric for assessing the impact of "hard negatives," as the nature of irrelevant information significantly influences LLM performance.
</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.1">Observations.</span>
Increasing the number of retrieved passages consistently leads to higher recall but lower precision, irrespective of the retriever used.
Crucially, the overall accuracy of the RAG system falls below the recall across all retrieval sizes.
This indicates that even when relevant information is present in the retrieved context, the LLM may fail to generate the correct answer.
This demonstrates that the irrelevant retrieved passages can sometimes mislead the LLM.
Furthermore, despite exhibiting higher precision, the e5 retriever leads to a more pronounced performance degradation as the number of retrieved passages increases compared to BM25.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p5.1.1">Insights.</span>
These observations yield two key insights:
(1) <span class="ltx_text ltx_font_italic" id="S3.SS2.p5.1.2">Influence of irrelevant passages</span>: The discrepancy between retrieval recall and RAG accuracy underscores the detrimental effect of irrelevant retrieved passages ("hard negatives") on the LLMs’ performance.
Even when relevant information is available, the presence of hard negatives can mislead the LLMs and hinder their ability to generate accurate answers.
(2) <span class="ltx_text ltx_font_italic" id="S3.SS2.p5.1.3">Limitations of precision as a metric</span>: The contrasting performance trends observed with e5 and BM25, despite the former’s higher precision, reveal that precision alone is an inadequate measure of retrieval quality in this context, when the end-to-end performance is considered.
The specific characteristics of the irrelevant passages, rather than just their quantity, significantly impact the LLMs’ performance. Retrievers might significantly differ in their way of priorization of them, and that might not be fully captured in metrics like precision.
In this scenario, it is observed that “hard negatives” retrieved by a stronger retriever (e5) might even more detrimental to the LLM than those retrieved by a weaker one (BM25).</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>The importance of hard negatives for long-context LLM evaluation</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">This subsection investigates the impact of "hard negatives" on the performance of long-context LLMs in RAG, highlighting the need for more robust evaluation methodologies.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p2.1.1">Research question.</span>
In long-context RAG scenarios, where a vast knowledge source necessitates retrieving numerous passages, the likelihood of including relevant information (<span class="ltx_text ltx_font_italic" id="S3.SS3.p2.1.2">i.e.</span> obtaining high recall) increases.
However, this also elevates the risk of introducing hard negatives.
This raises two critical questions: (1) <span class="ltx_text ltx_font_italic" id="S3.SS3.p2.1.3">How robust are current long-context LLMs to these hard negatives?</span> and (2) <span class="ltx_text ltx_font_italic" id="S3.SS3.p2.1.4">Does the impact of hard negatives vary with the retriever used?</span></p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p3.1.1">Experimental setting.</span>
This study investigates the effect of hard negative passages on long-context LLM performance in a controlled setting.
We tasked three LLMs (Gemma2-7B-Chat, Mistral-Nemo-12B-Instruct, and Gemini-1.5-Pro) with answering queries based on a context comprising a single golden passage and a varying number of hard negative passages retrieved using different methods (e5, Contriever, BM25, and random sampling).
This synthetic experiment, detailed in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S3.F3" title="Figure 3 ‣ 3.3 The importance of hard negatives for long-context LLM evaluation ‣ 3 Challenges of Long context LLMs in RAG ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">3</span></a>, isolates the impact of hard negatives by holding the golden passage constant and intentionally excluding scenarios with multiple golden passages, which are common in real-world RAG systems.
See Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A3" title="Appendix C Illustration of Section 3.3: Hard negative study ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">C</span></a> for a complete illustration of the experimental setup.</p>
</div>
<figure class="ltx_figure" id="S3.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F3.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="220" id="S3.F3.sf1.g1" src="x5.png" width="201"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F3.sf1.2.1.1" style="font-size:80%;">(a)</span> </span><span class="ltx_text" id="S3.F3.sf1.3.2" style="font-size:80%;">Retrievers</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F3.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="201" id="S3.F3.sf2.g1" src="x6.png" width="201"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F3.sf2.2.1.1" style="font-size:80%;">(b)</span> </span><span class="ltx_text" id="S3.F3.sf2.3.2" style="font-size:80%;">Gemma2-9B-Chat</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F3.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="201" id="S3.F3.sf3.g1" src="x7.png" width="201"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F3.sf3.2.1.1" style="font-size:80%;">(c)</span> </span><span class="ltx_text" id="S3.F3.sf3.3.2" style="font-size:80%;">Mistral-12B-Instruct</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F3.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="201" id="S3.F3.sf4.g1" src="x8.png" width="201"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F3.sf4.2.1.1" style="font-size:80%;">(d)</span> </span><span class="ltx_text" id="S3.F3.sf4.3.2" style="font-size:80%;">Gemini-1.5-Pro</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Evaluating the impact of hard negatives on long-context LLMs. (a) The retriever performance on NQ dataset: e5 &gt; contriever &gt; BM25. (b)(c)(d) For each query, a single golden passage (containing the correct answer) is combined with varying numbers of hard negative passages retrieved by different methods: e5, Contriever, BM25, and random sampling. The LLMs are then tasked with answering the query based on this context. This setup allows us to assess the robustness of LLMs to hard negatives and the influence of retriever characteristics on their overall impact.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p4.1.1">Observations.</span>
(1) Sensitivity to hard negatives: Across all LLMs, increasing the number of hard negative passages generally leads to a decline in RAG answer accuracy.
(2) Retriever strength and hard negative difficulty: The strength of the retriever directly correlates with the difficulty of the retrieved hard negatives. LLMs struggle more with hard negatives from stronger retrievers (<span class="ltx_text ltx_font_italic" id="S3.SS3.p4.1.2">e.g.</span>, e5) compared to those from weaker retrievers (<span class="ltx_text ltx_font_italic" id="S3.SS3.p4.1.3">e.g.</span>, BM25) or random sampling.
(3) Distinguishing random and hard negatives: While Gemini-1.5-Pro demonstrates robustness to random negatives, it remains susceptible to the influence of hard negatives.
More results on other datasets and qualitative studies can be found in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A2.SS2" title="B.2 The importance of hard negatives for long-context LLM evaluation ‣ Appendix B Long context LLMs in RAG analysis on other datasets ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">B.2</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A4" title="Appendix D Hard negatives case study ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">D</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p5">
<p class="ltx_p" id="S3.SS3.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p5.1.1">Insights.</span>
Existing benchmarks for evaluating long-context LLMs, such as "needle-in-the-haystack" <cite class="ltx_cite ltx_citemacro_citep">(Kamradt, <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib14" title="">2023</a>)</cite> and RULER <cite class="ltx_cite ltx_citemacro_citep">(Hsieh et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib9" title="">2024a</a>)</cite>, predominantly utilize random negatives.
Our findings demonstrate that such benchmarks may not adequately capture the challenges posed by hard negatives, which are prevalent in real-world RAG applications. Their takeaways would have limitations.
The need for new evaluation methodologies that incorporate hard negatives (specific to the employed retrievers) is highlighted, to provide a more comprehensive and realistic assessment of long-context LLM performance in RAG.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Simple and effective training-free RAG improvement</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">Building upon the analyses in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S3" title="3 Challenges of Long context LLMs in RAG ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">3</span></a> on the detrimental impact of hard negatives on long-context LLMs in RAG, we focus on the training-free solution, <span class="ltx_text ltx_font_italic" id="S4.p1.1.1">retrieval reordering</span>.
This method leverages the inherent "lost-in-the-middle" phenomenon observed in LLMs to mitigate the negative effects of hard negatives.
As highlighted by <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib20" title="">2024</a>)</cite>, LLMs exhibit a tendency to prioritize information presented at the beginning and end of an input sequence, while paying less attention to the middle.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.8">Exploiting this "lost-in-the-middle" behavior, we consider a simple and effective strategy: reordering the retrieved passages based on their relevance scores calculated by the retriever.
Given a query <math alttext="q" class="ltx_Math" display="inline" id="S4.p2.1.m1.1"><semantics id="S4.p2.1.m1.1a"><mi id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><ci id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="S4.p2.1.m1.1d">italic_q</annotation></semantics></math> and a set of retrieved passages <math alttext="d_{1}" class="ltx_Math" display="inline" id="S4.p2.2.m2.1"><semantics id="S4.p2.2.m2.1a"><msub id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml"><mi id="S4.p2.2.m2.1.1.2" xref="S4.p2.2.m2.1.1.2.cmml">d</mi><mn id="S4.p2.2.m2.1.1.3" xref="S4.p2.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><apply id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p2.2.m2.1.1.1.cmml" xref="S4.p2.2.m2.1.1">subscript</csymbol><ci id="S4.p2.2.m2.1.1.2.cmml" xref="S4.p2.2.m2.1.1.2">𝑑</ci><cn id="S4.p2.2.m2.1.1.3.cmml" type="integer" xref="S4.p2.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">d_{1}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.2.m2.1d">italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="d_{2}" class="ltx_Math" display="inline" id="S4.p2.3.m3.1"><semantics id="S4.p2.3.m3.1a"><msub id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml"><mi id="S4.p2.3.m3.1.1.2" xref="S4.p2.3.m3.1.1.2.cmml">d</mi><mn id="S4.p2.3.m3.1.1.3" xref="S4.p2.3.m3.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><apply id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.p2.3.m3.1.1.1.cmml" xref="S4.p2.3.m3.1.1">subscript</csymbol><ci id="S4.p2.3.m3.1.1.2.cmml" xref="S4.p2.3.m3.1.1.2">𝑑</ci><cn id="S4.p2.3.m3.1.1.3.cmml" type="integer" xref="S4.p2.3.m3.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">d_{2}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.3.m3.1d">italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT</annotation></semantics></math>, …, <math alttext="d_{k}" class="ltx_Math" display="inline" id="S4.p2.4.m4.1"><semantics id="S4.p2.4.m4.1a"><msub id="S4.p2.4.m4.1.1" xref="S4.p2.4.m4.1.1.cmml"><mi id="S4.p2.4.m4.1.1.2" xref="S4.p2.4.m4.1.1.2.cmml">d</mi><mi id="S4.p2.4.m4.1.1.3" xref="S4.p2.4.m4.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.4.m4.1b"><apply id="S4.p2.4.m4.1.1.cmml" xref="S4.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S4.p2.4.m4.1.1.1.cmml" xref="S4.p2.4.m4.1.1">subscript</csymbol><ci id="S4.p2.4.m4.1.1.2.cmml" xref="S4.p2.4.m4.1.1.2">𝑑</ci><ci id="S4.p2.4.m4.1.1.3.cmml" xref="S4.p2.4.m4.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.4.m4.1c">d_{k}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.4.m4.1d">italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math> with decreasing relevance scores, the standard input sequence construction for an LLM with instruction <math alttext="I" class="ltx_Math" display="inline" id="S4.p2.5.m5.1"><semantics id="S4.p2.5.m5.1a"><mi id="S4.p2.5.m5.1.1" xref="S4.p2.5.m5.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S4.p2.5.m5.1b"><ci id="S4.p2.5.m5.1.1.cmml" xref="S4.p2.5.m5.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.5.m5.1c">I</annotation><annotation encoding="application/x-llamapun" id="S4.p2.5.m5.1d">italic_I</annotation></semantics></math> would be: <math alttext="[I,d_{1},d_{2},...,d_{k-1},d_{k},q]" class="ltx_Math" display="inline" id="S4.p2.6.m6.7"><semantics id="S4.p2.6.m6.7a"><mrow id="S4.p2.6.m6.7.7.4" xref="S4.p2.6.m6.7.7.5.cmml"><mo id="S4.p2.6.m6.7.7.4.5" stretchy="false" xref="S4.p2.6.m6.7.7.5.cmml">[</mo><mi id="S4.p2.6.m6.1.1" xref="S4.p2.6.m6.1.1.cmml">I</mi><mo id="S4.p2.6.m6.7.7.4.6" xref="S4.p2.6.m6.7.7.5.cmml">,</mo><msub id="S4.p2.6.m6.4.4.1.1" xref="S4.p2.6.m6.4.4.1.1.cmml"><mi id="S4.p2.6.m6.4.4.1.1.2" xref="S4.p2.6.m6.4.4.1.1.2.cmml">d</mi><mn id="S4.p2.6.m6.4.4.1.1.3" xref="S4.p2.6.m6.4.4.1.1.3.cmml">1</mn></msub><mo id="S4.p2.6.m6.7.7.4.7" xref="S4.p2.6.m6.7.7.5.cmml">,</mo><msub id="S4.p2.6.m6.5.5.2.2" xref="S4.p2.6.m6.5.5.2.2.cmml"><mi id="S4.p2.6.m6.5.5.2.2.2" xref="S4.p2.6.m6.5.5.2.2.2.cmml">d</mi><mn id="S4.p2.6.m6.5.5.2.2.3" xref="S4.p2.6.m6.5.5.2.2.3.cmml">2</mn></msub><mo id="S4.p2.6.m6.7.7.4.8" xref="S4.p2.6.m6.7.7.5.cmml">,</mo><mi id="S4.p2.6.m6.2.2" mathvariant="normal" xref="S4.p2.6.m6.2.2.cmml">…</mi><mo id="S4.p2.6.m6.7.7.4.9" xref="S4.p2.6.m6.7.7.5.cmml">,</mo><msub id="S4.p2.6.m6.6.6.3.3" xref="S4.p2.6.m6.6.6.3.3.cmml"><mi id="S4.p2.6.m6.6.6.3.3.2" xref="S4.p2.6.m6.6.6.3.3.2.cmml">d</mi><mrow id="S4.p2.6.m6.6.6.3.3.3" xref="S4.p2.6.m6.6.6.3.3.3.cmml"><mi id="S4.p2.6.m6.6.6.3.3.3.2" xref="S4.p2.6.m6.6.6.3.3.3.2.cmml">k</mi><mo id="S4.p2.6.m6.6.6.3.3.3.1" xref="S4.p2.6.m6.6.6.3.3.3.1.cmml">−</mo><mn id="S4.p2.6.m6.6.6.3.3.3.3" xref="S4.p2.6.m6.6.6.3.3.3.3.cmml">1</mn></mrow></msub><mo id="S4.p2.6.m6.7.7.4.10" xref="S4.p2.6.m6.7.7.5.cmml">,</mo><msub id="S4.p2.6.m6.7.7.4.4" xref="S4.p2.6.m6.7.7.4.4.cmml"><mi id="S4.p2.6.m6.7.7.4.4.2" xref="S4.p2.6.m6.7.7.4.4.2.cmml">d</mi><mi id="S4.p2.6.m6.7.7.4.4.3" xref="S4.p2.6.m6.7.7.4.4.3.cmml">k</mi></msub><mo id="S4.p2.6.m6.7.7.4.11" xref="S4.p2.6.m6.7.7.5.cmml">,</mo><mi id="S4.p2.6.m6.3.3" xref="S4.p2.6.m6.3.3.cmml">q</mi><mo id="S4.p2.6.m6.7.7.4.12" stretchy="false" xref="S4.p2.6.m6.7.7.5.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.6.m6.7b"><list id="S4.p2.6.m6.7.7.5.cmml" xref="S4.p2.6.m6.7.7.4"><ci id="S4.p2.6.m6.1.1.cmml" xref="S4.p2.6.m6.1.1">𝐼</ci><apply id="S4.p2.6.m6.4.4.1.1.cmml" xref="S4.p2.6.m6.4.4.1.1"><csymbol cd="ambiguous" id="S4.p2.6.m6.4.4.1.1.1.cmml" xref="S4.p2.6.m6.4.4.1.1">subscript</csymbol><ci id="S4.p2.6.m6.4.4.1.1.2.cmml" xref="S4.p2.6.m6.4.4.1.1.2">𝑑</ci><cn id="S4.p2.6.m6.4.4.1.1.3.cmml" type="integer" xref="S4.p2.6.m6.4.4.1.1.3">1</cn></apply><apply id="S4.p2.6.m6.5.5.2.2.cmml" xref="S4.p2.6.m6.5.5.2.2"><csymbol cd="ambiguous" id="S4.p2.6.m6.5.5.2.2.1.cmml" xref="S4.p2.6.m6.5.5.2.2">subscript</csymbol><ci id="S4.p2.6.m6.5.5.2.2.2.cmml" xref="S4.p2.6.m6.5.5.2.2.2">𝑑</ci><cn id="S4.p2.6.m6.5.5.2.2.3.cmml" type="integer" xref="S4.p2.6.m6.5.5.2.2.3">2</cn></apply><ci id="S4.p2.6.m6.2.2.cmml" xref="S4.p2.6.m6.2.2">…</ci><apply id="S4.p2.6.m6.6.6.3.3.cmml" xref="S4.p2.6.m6.6.6.3.3"><csymbol cd="ambiguous" id="S4.p2.6.m6.6.6.3.3.1.cmml" xref="S4.p2.6.m6.6.6.3.3">subscript</csymbol><ci id="S4.p2.6.m6.6.6.3.3.2.cmml" xref="S4.p2.6.m6.6.6.3.3.2">𝑑</ci><apply id="S4.p2.6.m6.6.6.3.3.3.cmml" xref="S4.p2.6.m6.6.6.3.3.3"><minus id="S4.p2.6.m6.6.6.3.3.3.1.cmml" xref="S4.p2.6.m6.6.6.3.3.3.1"></minus><ci id="S4.p2.6.m6.6.6.3.3.3.2.cmml" xref="S4.p2.6.m6.6.6.3.3.3.2">𝑘</ci><cn id="S4.p2.6.m6.6.6.3.3.3.3.cmml" type="integer" xref="S4.p2.6.m6.6.6.3.3.3.3">1</cn></apply></apply><apply id="S4.p2.6.m6.7.7.4.4.cmml" xref="S4.p2.6.m6.7.7.4.4"><csymbol cd="ambiguous" id="S4.p2.6.m6.7.7.4.4.1.cmml" xref="S4.p2.6.m6.7.7.4.4">subscript</csymbol><ci id="S4.p2.6.m6.7.7.4.4.2.cmml" xref="S4.p2.6.m6.7.7.4.4.2">𝑑</ci><ci id="S4.p2.6.m6.7.7.4.4.3.cmml" xref="S4.p2.6.m6.7.7.4.4.3">𝑘</ci></apply><ci id="S4.p2.6.m6.3.3.cmml" xref="S4.p2.6.m6.3.3">𝑞</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.6.m6.7c">[I,d_{1},d_{2},...,d_{k-1},d_{k},q]</annotation><annotation encoding="application/x-llamapun" id="S4.p2.6.m6.7d">[ italic_I , italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_d start_POSTSUBSCRIPT italic_k - 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_q ]</annotation></semantics></math>.
Retrieval reordering modifies this to prioritize passages with higher scores at the beginning and end: <math alttext="[I,d_{1},d_{3},...,d_{4},d_{2},q]" class="ltx_Math" display="inline" id="S4.p2.7.m7.7"><semantics id="S4.p2.7.m7.7a"><mrow id="S4.p2.7.m7.7.7.4" xref="S4.p2.7.m7.7.7.5.cmml"><mo id="S4.p2.7.m7.7.7.4.5" stretchy="false" xref="S4.p2.7.m7.7.7.5.cmml">[</mo><mi id="S4.p2.7.m7.1.1" xref="S4.p2.7.m7.1.1.cmml">I</mi><mo id="S4.p2.7.m7.7.7.4.6" xref="S4.p2.7.m7.7.7.5.cmml">,</mo><msub id="S4.p2.7.m7.4.4.1.1" xref="S4.p2.7.m7.4.4.1.1.cmml"><mi id="S4.p2.7.m7.4.4.1.1.2" xref="S4.p2.7.m7.4.4.1.1.2.cmml">d</mi><mn id="S4.p2.7.m7.4.4.1.1.3" xref="S4.p2.7.m7.4.4.1.1.3.cmml">1</mn></msub><mo id="S4.p2.7.m7.7.7.4.7" xref="S4.p2.7.m7.7.7.5.cmml">,</mo><msub id="S4.p2.7.m7.5.5.2.2" xref="S4.p2.7.m7.5.5.2.2.cmml"><mi id="S4.p2.7.m7.5.5.2.2.2" xref="S4.p2.7.m7.5.5.2.2.2.cmml">d</mi><mn id="S4.p2.7.m7.5.5.2.2.3" xref="S4.p2.7.m7.5.5.2.2.3.cmml">3</mn></msub><mo id="S4.p2.7.m7.7.7.4.8" xref="S4.p2.7.m7.7.7.5.cmml">,</mo><mi id="S4.p2.7.m7.2.2" mathvariant="normal" xref="S4.p2.7.m7.2.2.cmml">…</mi><mo id="S4.p2.7.m7.7.7.4.9" xref="S4.p2.7.m7.7.7.5.cmml">,</mo><msub id="S4.p2.7.m7.6.6.3.3" xref="S4.p2.7.m7.6.6.3.3.cmml"><mi id="S4.p2.7.m7.6.6.3.3.2" xref="S4.p2.7.m7.6.6.3.3.2.cmml">d</mi><mn id="S4.p2.7.m7.6.6.3.3.3" xref="S4.p2.7.m7.6.6.3.3.3.cmml">4</mn></msub><mo id="S4.p2.7.m7.7.7.4.10" xref="S4.p2.7.m7.7.7.5.cmml">,</mo><msub id="S4.p2.7.m7.7.7.4.4" xref="S4.p2.7.m7.7.7.4.4.cmml"><mi id="S4.p2.7.m7.7.7.4.4.2" xref="S4.p2.7.m7.7.7.4.4.2.cmml">d</mi><mn id="S4.p2.7.m7.7.7.4.4.3" xref="S4.p2.7.m7.7.7.4.4.3.cmml">2</mn></msub><mo id="S4.p2.7.m7.7.7.4.11" xref="S4.p2.7.m7.7.7.5.cmml">,</mo><mi id="S4.p2.7.m7.3.3" xref="S4.p2.7.m7.3.3.cmml">q</mi><mo id="S4.p2.7.m7.7.7.4.12" stretchy="false" xref="S4.p2.7.m7.7.7.5.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p2.7.m7.7b"><list id="S4.p2.7.m7.7.7.5.cmml" xref="S4.p2.7.m7.7.7.4"><ci id="S4.p2.7.m7.1.1.cmml" xref="S4.p2.7.m7.1.1">𝐼</ci><apply id="S4.p2.7.m7.4.4.1.1.cmml" xref="S4.p2.7.m7.4.4.1.1"><csymbol cd="ambiguous" id="S4.p2.7.m7.4.4.1.1.1.cmml" xref="S4.p2.7.m7.4.4.1.1">subscript</csymbol><ci id="S4.p2.7.m7.4.4.1.1.2.cmml" xref="S4.p2.7.m7.4.4.1.1.2">𝑑</ci><cn id="S4.p2.7.m7.4.4.1.1.3.cmml" type="integer" xref="S4.p2.7.m7.4.4.1.1.3">1</cn></apply><apply id="S4.p2.7.m7.5.5.2.2.cmml" xref="S4.p2.7.m7.5.5.2.2"><csymbol cd="ambiguous" id="S4.p2.7.m7.5.5.2.2.1.cmml" xref="S4.p2.7.m7.5.5.2.2">subscript</csymbol><ci id="S4.p2.7.m7.5.5.2.2.2.cmml" xref="S4.p2.7.m7.5.5.2.2.2">𝑑</ci><cn id="S4.p2.7.m7.5.5.2.2.3.cmml" type="integer" xref="S4.p2.7.m7.5.5.2.2.3">3</cn></apply><ci id="S4.p2.7.m7.2.2.cmml" xref="S4.p2.7.m7.2.2">…</ci><apply id="S4.p2.7.m7.6.6.3.3.cmml" xref="S4.p2.7.m7.6.6.3.3"><csymbol cd="ambiguous" id="S4.p2.7.m7.6.6.3.3.1.cmml" xref="S4.p2.7.m7.6.6.3.3">subscript</csymbol><ci id="S4.p2.7.m7.6.6.3.3.2.cmml" xref="S4.p2.7.m7.6.6.3.3.2">𝑑</ci><cn id="S4.p2.7.m7.6.6.3.3.3.cmml" type="integer" xref="S4.p2.7.m7.6.6.3.3.3">4</cn></apply><apply id="S4.p2.7.m7.7.7.4.4.cmml" xref="S4.p2.7.m7.7.7.4.4"><csymbol cd="ambiguous" id="S4.p2.7.m7.7.7.4.4.1.cmml" xref="S4.p2.7.m7.7.7.4.4">subscript</csymbol><ci id="S4.p2.7.m7.7.7.4.4.2.cmml" xref="S4.p2.7.m7.7.7.4.4.2">𝑑</ci><cn id="S4.p2.7.m7.7.7.4.4.3.cmml" type="integer" xref="S4.p2.7.m7.7.7.4.4.3">2</cn></apply><ci id="S4.p2.7.m7.3.3.cmml" xref="S4.p2.7.m7.3.3">𝑞</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.7.m7.7c">[I,d_{1},d_{3},...,d_{4},d_{2},q]</annotation><annotation encoding="application/x-llamapun" id="S4.p2.7.m7.7d">[ italic_I , italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 3 end_POSTSUBSCRIPT , … , italic_d start_POSTSUBSCRIPT 4 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_q ]</annotation></semantics></math>
where the position of passage <math alttext="d_{i}" class="ltx_Math" display="inline" id="S4.p2.8.m8.1"><semantics id="S4.p2.8.m8.1a"><msub id="S4.p2.8.m8.1.1" xref="S4.p2.8.m8.1.1.cmml"><mi id="S4.p2.8.m8.1.1.2" xref="S4.p2.8.m8.1.1.2.cmml">d</mi><mi id="S4.p2.8.m8.1.1.3" xref="S4.p2.8.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.8.m8.1b"><apply id="S4.p2.8.m8.1.1.cmml" xref="S4.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S4.p2.8.m8.1.1.1.cmml" xref="S4.p2.8.m8.1.1">subscript</csymbol><ci id="S4.p2.8.m8.1.1.2.cmml" xref="S4.p2.8.m8.1.1.2">𝑑</ci><ci id="S4.p2.8.m8.1.1.3.cmml" xref="S4.p2.8.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.8.m8.1c">d_{i}</annotation><annotation encoding="application/x-llamapun" id="S4.p2.8.m8.1d">italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is determined by</p>
<table class="ltx_equation ltx_eqn_table" id="S4.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\textit{Order}(d_{i})=\begin{cases}\frac{i+1}{2}&amp;\text{if mod($i$, 2) = 1}\\
(k+1)-\frac{i}{2}&amp;\text{if mod($i$, 2) = 0}\end{cases}" class="ltx_Math" display="block" id="S4.E1.m1.5"><semantics id="S4.E1.m1.5a"><mrow id="S4.E1.m1.5.5" xref="S4.E1.m1.5.5.cmml"><mrow id="S4.E1.m1.5.5.1" xref="S4.E1.m1.5.5.1.cmml"><mtext class="ltx_mathvariant_italic" id="S4.E1.m1.5.5.1.3" xref="S4.E1.m1.5.5.1.3a.cmml">Order</mtext><mo id="S4.E1.m1.5.5.1.2" xref="S4.E1.m1.5.5.1.2.cmml">⁢</mo><mrow id="S4.E1.m1.5.5.1.1.1" xref="S4.E1.m1.5.5.1.1.1.1.cmml"><mo id="S4.E1.m1.5.5.1.1.1.2" stretchy="false" xref="S4.E1.m1.5.5.1.1.1.1.cmml">(</mo><msub id="S4.E1.m1.5.5.1.1.1.1" xref="S4.E1.m1.5.5.1.1.1.1.cmml"><mi id="S4.E1.m1.5.5.1.1.1.1.2" xref="S4.E1.m1.5.5.1.1.1.1.2.cmml">d</mi><mi id="S4.E1.m1.5.5.1.1.1.1.3" xref="S4.E1.m1.5.5.1.1.1.1.3.cmml">i</mi></msub><mo id="S4.E1.m1.5.5.1.1.1.3" stretchy="false" xref="S4.E1.m1.5.5.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S4.E1.m1.5.5.2" xref="S4.E1.m1.5.5.2.cmml">=</mo><mrow id="S4.E1.m1.4.4" xref="S4.E1.m1.5.5.3.1.cmml"><mo id="S4.E1.m1.4.4.5" xref="S4.E1.m1.5.5.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" id="S4.E1.m1.4.4.4" rowspacing="0pt" xref="S4.E1.m1.5.5.3.1.cmml"><mtr id="S4.E1.m1.4.4.4a" xref="S4.E1.m1.5.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S4.E1.m1.4.4.4b" xref="S4.E1.m1.5.5.3.1.cmml"><mstyle displaystyle="false" id="S4.E1.m1.3.3.3.3.2.1" xref="S4.E1.m1.3.3.3.3.2.1.cmml"><mfrac id="S4.E1.m1.3.3.3.3.2.1a" xref="S4.E1.m1.3.3.3.3.2.1.cmml"><mrow id="S4.E1.m1.3.3.3.3.2.1.2" xref="S4.E1.m1.3.3.3.3.2.1.2.cmml"><mi id="S4.E1.m1.3.3.3.3.2.1.2.2" xref="S4.E1.m1.3.3.3.3.2.1.2.2.cmml">i</mi><mo id="S4.E1.m1.3.3.3.3.2.1.2.1" xref="S4.E1.m1.3.3.3.3.2.1.2.1.cmml">+</mo><mn id="S4.E1.m1.3.3.3.3.2.1.2.3" xref="S4.E1.m1.3.3.3.3.2.1.2.3.cmml">1</mn></mrow><mn id="S4.E1.m1.3.3.3.3.2.1.3" xref="S4.E1.m1.3.3.3.3.2.1.3.cmml">2</mn></mfrac></mstyle></mtd><mtd class="ltx_align_left" columnalign="left" id="S4.E1.m1.4.4.4c" xref="S4.E1.m1.5.5.3.1.cmml"><mrow id="S4.E1.m1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1c.cmml"><mtext id="S4.E1.m1.1.1.1.1.1.1a" xref="S4.E1.m1.1.1.1.1.1.1c.cmml">if mod(</mtext><mi id="S4.E1.m1.1.1.1.1.1.1.1.1.m1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.1.1.m1.1.1.cmml">i</mi><mtext id="S4.E1.m1.1.1.1.1.1.1b" xref="S4.E1.m1.1.1.1.1.1.1c.cmml">, 2) = 1</mtext></mrow></mtd></mtr><mtr id="S4.E1.m1.4.4.4d" xref="S4.E1.m1.5.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S4.E1.m1.4.4.4e" xref="S4.E1.m1.5.5.3.1.cmml"><mrow id="S4.E1.m1.4.4.4.4.2.1" xref="S4.E1.m1.4.4.4.4.2.1.cmml"><mrow id="S4.E1.m1.4.4.4.4.2.1.1.1" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.cmml"><mo id="S4.E1.m1.4.4.4.4.2.1.1.1.2" stretchy="false" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.cmml">(</mo><mrow id="S4.E1.m1.4.4.4.4.2.1.1.1.1" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.cmml"><mi id="S4.E1.m1.4.4.4.4.2.1.1.1.1.2" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.2.cmml">k</mi><mo id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.cmml">+</mo><mn id="S4.E1.m1.4.4.4.4.2.1.1.1.1.3" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.3.cmml">1</mn></mrow><mo id="S4.E1.m1.4.4.4.4.2.1.1.1.3" stretchy="false" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.cmml">)</mo></mrow><mo id="S4.E1.m1.4.4.4.4.2.1.2" xref="S4.E1.m1.4.4.4.4.2.1.2.cmml">−</mo><mstyle displaystyle="false" id="S4.E1.m1.4.4.4.4.2.1.3" xref="S4.E1.m1.4.4.4.4.2.1.3.cmml"><mfrac id="S4.E1.m1.4.4.4.4.2.1.3a" xref="S4.E1.m1.4.4.4.4.2.1.3.cmml"><mi id="S4.E1.m1.4.4.4.4.2.1.3.2" xref="S4.E1.m1.4.4.4.4.2.1.3.2.cmml">i</mi><mn id="S4.E1.m1.4.4.4.4.2.1.3.3" xref="S4.E1.m1.4.4.4.4.2.1.3.3.cmml">2</mn></mfrac></mstyle></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S4.E1.m1.4.4.4f" xref="S4.E1.m1.5.5.3.1.cmml"><mrow id="S4.E1.m1.2.2.2.2.1.1" xref="S4.E1.m1.2.2.2.2.1.1c.cmml"><mtext id="S4.E1.m1.2.2.2.2.1.1a" xref="S4.E1.m1.2.2.2.2.1.1c.cmml">if mod(</mtext><mi id="S4.E1.m1.2.2.2.2.1.1.1.1.m1.1.1" xref="S4.E1.m1.2.2.2.2.1.1.1.1.m1.1.1.cmml">i</mi><mtext id="S4.E1.m1.2.2.2.2.1.1b" xref="S4.E1.m1.2.2.2.2.1.1c.cmml">, 2) = 0</mtext></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.E1.m1.5b"><apply id="S4.E1.m1.5.5.cmml" xref="S4.E1.m1.5.5"><eq id="S4.E1.m1.5.5.2.cmml" xref="S4.E1.m1.5.5.2"></eq><apply id="S4.E1.m1.5.5.1.cmml" xref="S4.E1.m1.5.5.1"><times id="S4.E1.m1.5.5.1.2.cmml" xref="S4.E1.m1.5.5.1.2"></times><ci id="S4.E1.m1.5.5.1.3a.cmml" xref="S4.E1.m1.5.5.1.3"><mtext class="ltx_mathvariant_italic" id="S4.E1.m1.5.5.1.3.cmml" xref="S4.E1.m1.5.5.1.3">Order</mtext></ci><apply id="S4.E1.m1.5.5.1.1.1.1.cmml" xref="S4.E1.m1.5.5.1.1.1"><csymbol cd="ambiguous" id="S4.E1.m1.5.5.1.1.1.1.1.cmml" xref="S4.E1.m1.5.5.1.1.1">subscript</csymbol><ci id="S4.E1.m1.5.5.1.1.1.1.2.cmml" xref="S4.E1.m1.5.5.1.1.1.1.2">𝑑</ci><ci id="S4.E1.m1.5.5.1.1.1.1.3.cmml" xref="S4.E1.m1.5.5.1.1.1.1.3">𝑖</ci></apply></apply><apply id="S4.E1.m1.5.5.3.1.cmml" xref="S4.E1.m1.4.4"><csymbol cd="latexml" id="S4.E1.m1.5.5.3.1.1.cmml" xref="S4.E1.m1.4.4.5">cases</csymbol><apply id="S4.E1.m1.3.3.3.3.2.1.cmml" xref="S4.E1.m1.3.3.3.3.2.1"><divide id="S4.E1.m1.3.3.3.3.2.1.1.cmml" xref="S4.E1.m1.3.3.3.3.2.1"></divide><apply id="S4.E1.m1.3.3.3.3.2.1.2.cmml" xref="S4.E1.m1.3.3.3.3.2.1.2"><plus id="S4.E1.m1.3.3.3.3.2.1.2.1.cmml" xref="S4.E1.m1.3.3.3.3.2.1.2.1"></plus><ci id="S4.E1.m1.3.3.3.3.2.1.2.2.cmml" xref="S4.E1.m1.3.3.3.3.2.1.2.2">𝑖</ci><cn id="S4.E1.m1.3.3.3.3.2.1.2.3.cmml" type="integer" xref="S4.E1.m1.3.3.3.3.2.1.2.3">1</cn></apply><cn id="S4.E1.m1.3.3.3.3.2.1.3.cmml" type="integer" xref="S4.E1.m1.3.3.3.3.2.1.3">2</cn></apply><ci id="S4.E1.m1.1.1.1.1.1.1c.cmml" xref="S4.E1.m1.1.1.1.1.1.1"><mrow id="S4.E1.m1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1"><mtext id="S4.E1.m1.1.1.1.1.1.1a.cmml" xref="S4.E1.m1.1.1.1.1.1.1">if mod(</mtext><mi id="S4.E1.m1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1.1.1.m1.1.1">i</mi><mtext id="S4.E1.m1.1.1.1.1.1.1b.cmml" xref="S4.E1.m1.1.1.1.1.1.1">, 2) = 1</mtext></mrow></ci><apply id="S4.E1.m1.4.4.4.4.2.1.cmml" xref="S4.E1.m1.4.4.4.4.2.1"><minus id="S4.E1.m1.4.4.4.4.2.1.2.cmml" xref="S4.E1.m1.4.4.4.4.2.1.2"></minus><apply id="S4.E1.m1.4.4.4.4.2.1.1.1.1.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.1"><plus id="S4.E1.m1.4.4.4.4.2.1.1.1.1.1.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.1"></plus><ci id="S4.E1.m1.4.4.4.4.2.1.1.1.1.2.cmml" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.2">𝑘</ci><cn id="S4.E1.m1.4.4.4.4.2.1.1.1.1.3.cmml" type="integer" xref="S4.E1.m1.4.4.4.4.2.1.1.1.1.3">1</cn></apply><apply id="S4.E1.m1.4.4.4.4.2.1.3.cmml" xref="S4.E1.m1.4.4.4.4.2.1.3"><divide id="S4.E1.m1.4.4.4.4.2.1.3.1.cmml" xref="S4.E1.m1.4.4.4.4.2.1.3"></divide><ci id="S4.E1.m1.4.4.4.4.2.1.3.2.cmml" xref="S4.E1.m1.4.4.4.4.2.1.3.2">𝑖</ci><cn id="S4.E1.m1.4.4.4.4.2.1.3.3.cmml" type="integer" xref="S4.E1.m1.4.4.4.4.2.1.3.3">2</cn></apply></apply><ci id="S4.E1.m1.2.2.2.2.1.1c.cmml" xref="S4.E1.m1.2.2.2.2.1.1"><mrow id="S4.E1.m1.2.2.2.2.1.1.cmml" xref="S4.E1.m1.2.2.2.2.1.1"><mtext id="S4.E1.m1.2.2.2.2.1.1a.cmml" xref="S4.E1.m1.2.2.2.2.1.1">if mod(</mtext><mi id="S4.E1.m1.2.2.2.2.1.1.1.1.m1.1.1.cmml" xref="S4.E1.m1.2.2.2.2.1.1.1.1.m1.1.1">i</mi><mtext id="S4.E1.m1.2.2.2.2.1.1b.cmml" xref="S4.E1.m1.2.2.2.2.1.1">, 2) = 0</mtext></mrow></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.5c">\textit{Order}(d_{i})=\begin{cases}\frac{i+1}{2}&amp;\text{if mod($i$, 2) = 1}\\
(k+1)-\frac{i}{2}&amp;\text{if mod($i$, 2) = 0}\end{cases}</annotation><annotation encoding="application/x-llamapun" id="S4.E1.m1.5d">Order ( italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) = { start_ROW start_CELL divide start_ARG italic_i + 1 end_ARG start_ARG 2 end_ARG end_CELL start_CELL if mod( italic_i , 2) = 1 end_CELL end_ROW start_ROW start_CELL ( italic_k + 1 ) - divide start_ARG italic_i end_ARG start_ARG 2 end_ARG end_CELL start_CELL if mod( italic_i , 2) = 0 end_CELL end_ROW</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S4.p2.9">This reordering strategy aims to guide the LLM’s attention towards the most relevant passages, thereby reducing the influence of hard negatives positioned in the middle of the sequence. The pseudo-code for retrieval reordering can be found in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A5" title="Appendix E Retrieval reordering ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">E</span></a>.</p>
</div>
<figure class="ltx_figure" id="S4.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F4.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="155" id="S4.F4.sf1.g1" src="x9.png" width="207"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.sf1.2.1.1" style="font-size:80%;">(a)</span> </span><span class="ltx_text" id="S4.F4.sf1.3.2" style="font-size:80%;">NQ: Gemma2+e5</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F4.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="155" id="S4.F4.sf2.g1" src="x10.png" width="207"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.sf2.2.1.1" style="font-size:80%;">(b)</span> </span><span class="ltx_text" id="S4.F4.sf2.3.2" style="font-size:80%;">NQ: Gemma2+BM25</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F4.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="155" id="S4.F4.sf3.g1" src="x11.png" width="207"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.sf3.2.1.1" style="font-size:80%;">(c)</span> </span><span class="ltx_text" id="S4.F4.sf3.3.2" style="font-size:80%;">NQ: Mistral+e5</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F4.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="155" id="S4.F4.sf4.g1" src="x12.png" width="207"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.sf4.2.1.1" style="font-size:80%;">(d)</span> </span><span class="ltx_text" id="S4.F4.sf4.3.2" style="font-size:80%;">NQ: Mistral+BM25</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F4.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="155" id="S4.F4.sf5.g1" src="x13.png" width="207"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.sf5.2.1.1" style="font-size:80%;">(e)</span> </span><span class="ltx_text" id="S4.F4.sf5.3.2" style="font-size:80%;">PQA: Gemma2+e5</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F4.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="155" id="S4.F4.sf6.g1" src="x14.png" width="207"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.sf6.2.1.1" style="font-size:80%;">(f)</span> </span><span class="ltx_text" id="S4.F4.sf6.3.2" style="font-size:80%;">PQA: Gemma2+BM25</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F4.sf7"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="155" id="S4.F4.sf7.g1" src="x15.png" width="207"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.sf7.2.1.1" style="font-size:80%;">(g)</span> </span><span class="ltx_text" id="S4.F4.sf7.3.2" style="font-size:80%;">PQA: Mistral+e5</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S4.F4.sf8"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="155" id="S4.F4.sf8.g1" src="x16.png" width="207"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F4.sf8.2.1.1" style="font-size:80%;">(h)</span> </span><span class="ltx_text" id="S4.F4.sf8.3.2" style="font-size:80%;">PQA: Mistral+BM25</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Evaluating the effectiveness of retrieval reordering in various RAG configurations.
Results demonstrate that reordering retrieved passages consistently enhances performance, particularly when the number of retrieved passages is large. (Retrievers: e5, BM25; LLMs: Gemma2-9b-Chat, Mistral-Nemo-12B-Instruct; Datasets: NQ, PopQA)</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.p3">
<p class="ltx_p" id="S4.p3.1"><span class="ltx_text ltx_font_bold" id="S4.p3.1.1">Retrieval reordering significantly improves RAG performance, particularly with larger numbers of retrieved passages.</span>
To assess the effectiveness of retrieval reordering, we conduct experiments with two retrievers (e5 and BM25), two long-context LLMs (Gemma-2-9B-Chat and Mistral-Nemo-12B-Instruct), and two datasets (NQ and PopQA).
As illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S4.F4" title="Figure 4 ‣ 4 Simple and effective training-free RAG improvement ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">4</span></a>, retrieval reordering yields negligible improvements with smaller retrieval sets, but significantly and consistently outperforms the original ordering when the number of retrieved passages is large.
This behavior is attributed to the interplay of two factors that become increasingly significant with larger retrieval sets: (1) the amplified "lost-in-the-middle" phenomenon, where LLMs prioritize information at the beginning and end of the input sequence, and (2) the increased prevalence of hard negatives, which can hinder accurate answer generation.
By strategically placing passages, retrieval reordering mitigates these issues, highlighting the potential of <span class="ltx_text ltx_font_italic" id="S4.p3.1.2">position engineering</span> as a complementary technique to prompt engineering for optimizing long-context LLMs in RAG.</p>
</div>
</section>
<section class="ltx_section" id="S5" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Improving Robustness for RAG via Data-Augmented Fine-Tuning</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Implicitly improving LLM robustness through fine-tuning</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">While the <span class="ltx_text ltx_font_italic" id="S5.SS1.p1.1.1">retrieval reordering</span> strategy presented in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S4" title="4 Simple and effective training-free RAG improvement ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">4</span></a> mitigates the detrimental impact of hard negatives, it does not inherently enhance the LLM’s ability to handle such irrelevant information within the context.
To address this, we conduct a systematic investigation into RAG-specific tuning as a means of improving long-context LLMs for RAG applications.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.4">Our tuning paradigm involves training LLM to generate the correct answer (<math alttext="a" class="ltx_Math" display="inline" id="S5.SS1.p2.1.m1.1"><semantics id="S5.SS1.p2.1.m1.1a"><mi id="S5.SS1.p2.1.m1.1.1" xref="S5.SS1.p2.1.m1.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.1.m1.1b"><ci id="S5.SS1.p2.1.m1.1.1.cmml" xref="S5.SS1.p2.1.m1.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.1.m1.1c">a</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.1.m1.1d">italic_a</annotation></semantics></math>) given a comprehensive input comprising an instruction (<math alttext="I" class="ltx_Math" display="inline" id="S5.SS1.p2.2.m2.1"><semantics id="S5.SS1.p2.2.m2.1a"><mi id="S5.SS1.p2.2.m2.1.1" xref="S5.SS1.p2.2.m2.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.2.m2.1b"><ci id="S5.SS1.p2.2.m2.1.1.cmml" xref="S5.SS1.p2.2.m2.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.2.m2.1c">I</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.2.m2.1d">italic_I</annotation></semantics></math>), a query (<math alttext="q" class="ltx_Math" display="inline" id="S5.SS1.p2.3.m3.1"><semantics id="S5.SS1.p2.3.m3.1a"><mi id="S5.SS1.p2.3.m3.1.1" xref="S5.SS1.p2.3.m3.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.3.m3.1b"><ci id="S5.SS1.p2.3.m3.1.1.cmml" xref="S5.SS1.p2.3.m3.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.3.m3.1c">q</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.3.m3.1d">italic_q</annotation></semantics></math>), and a set of retrieved passages <math alttext="(d_{1},d_{2},...,d_{k})" class="ltx_Math" display="inline" id="S5.SS1.p2.4.m4.4"><semantics id="S5.SS1.p2.4.m4.4a"><mrow id="S5.SS1.p2.4.m4.4.4.3" xref="S5.SS1.p2.4.m4.4.4.4.cmml"><mo id="S5.SS1.p2.4.m4.4.4.3.4" stretchy="false" xref="S5.SS1.p2.4.m4.4.4.4.cmml">(</mo><msub id="S5.SS1.p2.4.m4.2.2.1.1" xref="S5.SS1.p2.4.m4.2.2.1.1.cmml"><mi id="S5.SS1.p2.4.m4.2.2.1.1.2" xref="S5.SS1.p2.4.m4.2.2.1.1.2.cmml">d</mi><mn id="S5.SS1.p2.4.m4.2.2.1.1.3" xref="S5.SS1.p2.4.m4.2.2.1.1.3.cmml">1</mn></msub><mo id="S5.SS1.p2.4.m4.4.4.3.5" xref="S5.SS1.p2.4.m4.4.4.4.cmml">,</mo><msub id="S5.SS1.p2.4.m4.3.3.2.2" xref="S5.SS1.p2.4.m4.3.3.2.2.cmml"><mi id="S5.SS1.p2.4.m4.3.3.2.2.2" xref="S5.SS1.p2.4.m4.3.3.2.2.2.cmml">d</mi><mn id="S5.SS1.p2.4.m4.3.3.2.2.3" xref="S5.SS1.p2.4.m4.3.3.2.2.3.cmml">2</mn></msub><mo id="S5.SS1.p2.4.m4.4.4.3.6" xref="S5.SS1.p2.4.m4.4.4.4.cmml">,</mo><mi id="S5.SS1.p2.4.m4.1.1" mathvariant="normal" xref="S5.SS1.p2.4.m4.1.1.cmml">…</mi><mo id="S5.SS1.p2.4.m4.4.4.3.7" xref="S5.SS1.p2.4.m4.4.4.4.cmml">,</mo><msub id="S5.SS1.p2.4.m4.4.4.3.3" xref="S5.SS1.p2.4.m4.4.4.3.3.cmml"><mi id="S5.SS1.p2.4.m4.4.4.3.3.2" xref="S5.SS1.p2.4.m4.4.4.3.3.2.cmml">d</mi><mi id="S5.SS1.p2.4.m4.4.4.3.3.3" xref="S5.SS1.p2.4.m4.4.4.3.3.3.cmml">k</mi></msub><mo id="S5.SS1.p2.4.m4.4.4.3.8" stretchy="false" xref="S5.SS1.p2.4.m4.4.4.4.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p2.4.m4.4b"><vector id="S5.SS1.p2.4.m4.4.4.4.cmml" xref="S5.SS1.p2.4.m4.4.4.3"><apply id="S5.SS1.p2.4.m4.2.2.1.1.cmml" xref="S5.SS1.p2.4.m4.2.2.1.1"><csymbol cd="ambiguous" id="S5.SS1.p2.4.m4.2.2.1.1.1.cmml" xref="S5.SS1.p2.4.m4.2.2.1.1">subscript</csymbol><ci id="S5.SS1.p2.4.m4.2.2.1.1.2.cmml" xref="S5.SS1.p2.4.m4.2.2.1.1.2">𝑑</ci><cn id="S5.SS1.p2.4.m4.2.2.1.1.3.cmml" type="integer" xref="S5.SS1.p2.4.m4.2.2.1.1.3">1</cn></apply><apply id="S5.SS1.p2.4.m4.3.3.2.2.cmml" xref="S5.SS1.p2.4.m4.3.3.2.2"><csymbol cd="ambiguous" id="S5.SS1.p2.4.m4.3.3.2.2.1.cmml" xref="S5.SS1.p2.4.m4.3.3.2.2">subscript</csymbol><ci id="S5.SS1.p2.4.m4.3.3.2.2.2.cmml" xref="S5.SS1.p2.4.m4.3.3.2.2.2">𝑑</ci><cn id="S5.SS1.p2.4.m4.3.3.2.2.3.cmml" type="integer" xref="S5.SS1.p2.4.m4.3.3.2.2.3">2</cn></apply><ci id="S5.SS1.p2.4.m4.1.1.cmml" xref="S5.SS1.p2.4.m4.1.1">…</ci><apply id="S5.SS1.p2.4.m4.4.4.3.3.cmml" xref="S5.SS1.p2.4.m4.4.4.3.3"><csymbol cd="ambiguous" id="S5.SS1.p2.4.m4.4.4.3.3.1.cmml" xref="S5.SS1.p2.4.m4.4.4.3.3">subscript</csymbol><ci id="S5.SS1.p2.4.m4.4.4.3.3.2.cmml" xref="S5.SS1.p2.4.m4.4.4.3.3.2">𝑑</ci><ci id="S5.SS1.p2.4.m4.4.4.3.3.3.cmml" xref="S5.SS1.p2.4.m4.4.4.3.3.3">𝑘</ci></apply></vector></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p2.4.m4.4c">(d_{1},d_{2},...,d_{k})</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p2.4.m4.4d">( italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT )</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S5.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{Input:}\ [I,d_{1},d_{2},...,d_{k-1},d_{k},q]\longrightarrow\text{Output:%
}\ a." class="ltx_Math" display="block" id="S5.E2.m1.4"><semantics id="S5.E2.m1.4a"><mrow id="S5.E2.m1.4.4.1" xref="S5.E2.m1.4.4.1.1.cmml"><mrow id="S5.E2.m1.4.4.1.1" xref="S5.E2.m1.4.4.1.1.cmml"><mrow id="S5.E2.m1.4.4.1.1.4" xref="S5.E2.m1.4.4.1.1.4.cmml"><mtext id="S5.E2.m1.4.4.1.1.4.6" xref="S5.E2.m1.4.4.1.1.4.6a.cmml">Input:</mtext><mo id="S5.E2.m1.4.4.1.1.4.5" lspace="0.500em" xref="S5.E2.m1.4.4.1.1.4.5.cmml">⁢</mo><mrow id="S5.E2.m1.4.4.1.1.4.4.4" xref="S5.E2.m1.4.4.1.1.4.4.5.cmml"><mo id="S5.E2.m1.4.4.1.1.4.4.4.5" stretchy="false" xref="S5.E2.m1.4.4.1.1.4.4.5.cmml">[</mo><mi id="S5.E2.m1.1.1" xref="S5.E2.m1.1.1.cmml">I</mi><mo id="S5.E2.m1.4.4.1.1.4.4.4.6" xref="S5.E2.m1.4.4.1.1.4.4.5.cmml">,</mo><msub id="S5.E2.m1.4.4.1.1.1.1.1.1" xref="S5.E2.m1.4.4.1.1.1.1.1.1.cmml"><mi id="S5.E2.m1.4.4.1.1.1.1.1.1.2" xref="S5.E2.m1.4.4.1.1.1.1.1.1.2.cmml">d</mi><mn id="S5.E2.m1.4.4.1.1.1.1.1.1.3" xref="S5.E2.m1.4.4.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S5.E2.m1.4.4.1.1.4.4.4.7" xref="S5.E2.m1.4.4.1.1.4.4.5.cmml">,</mo><msub id="S5.E2.m1.4.4.1.1.2.2.2.2" xref="S5.E2.m1.4.4.1.1.2.2.2.2.cmml"><mi id="S5.E2.m1.4.4.1.1.2.2.2.2.2" xref="S5.E2.m1.4.4.1.1.2.2.2.2.2.cmml">d</mi><mn id="S5.E2.m1.4.4.1.1.2.2.2.2.3" xref="S5.E2.m1.4.4.1.1.2.2.2.2.3.cmml">2</mn></msub><mo id="S5.E2.m1.4.4.1.1.4.4.4.8" xref="S5.E2.m1.4.4.1.1.4.4.5.cmml">,</mo><mi id="S5.E2.m1.2.2" mathvariant="normal" xref="S5.E2.m1.2.2.cmml">…</mi><mo id="S5.E2.m1.4.4.1.1.4.4.4.9" xref="S5.E2.m1.4.4.1.1.4.4.5.cmml">,</mo><msub id="S5.E2.m1.4.4.1.1.3.3.3.3" xref="S5.E2.m1.4.4.1.1.3.3.3.3.cmml"><mi id="S5.E2.m1.4.4.1.1.3.3.3.3.2" xref="S5.E2.m1.4.4.1.1.3.3.3.3.2.cmml">d</mi><mrow id="S5.E2.m1.4.4.1.1.3.3.3.3.3" xref="S5.E2.m1.4.4.1.1.3.3.3.3.3.cmml"><mi id="S5.E2.m1.4.4.1.1.3.3.3.3.3.2" xref="S5.E2.m1.4.4.1.1.3.3.3.3.3.2.cmml">k</mi><mo id="S5.E2.m1.4.4.1.1.3.3.3.3.3.1" xref="S5.E2.m1.4.4.1.1.3.3.3.3.3.1.cmml">−</mo><mn id="S5.E2.m1.4.4.1.1.3.3.3.3.3.3" xref="S5.E2.m1.4.4.1.1.3.3.3.3.3.3.cmml">1</mn></mrow></msub><mo id="S5.E2.m1.4.4.1.1.4.4.4.10" xref="S5.E2.m1.4.4.1.1.4.4.5.cmml">,</mo><msub id="S5.E2.m1.4.4.1.1.4.4.4.4" xref="S5.E2.m1.4.4.1.1.4.4.4.4.cmml"><mi id="S5.E2.m1.4.4.1.1.4.4.4.4.2" xref="S5.E2.m1.4.4.1.1.4.4.4.4.2.cmml">d</mi><mi id="S5.E2.m1.4.4.1.1.4.4.4.4.3" xref="S5.E2.m1.4.4.1.1.4.4.4.4.3.cmml">k</mi></msub><mo id="S5.E2.m1.4.4.1.1.4.4.4.11" xref="S5.E2.m1.4.4.1.1.4.4.5.cmml">,</mo><mi id="S5.E2.m1.3.3" xref="S5.E2.m1.3.3.cmml">q</mi><mo id="S5.E2.m1.4.4.1.1.4.4.4.12" stretchy="false" xref="S5.E2.m1.4.4.1.1.4.4.5.cmml">]</mo></mrow></mrow><mo id="S5.E2.m1.4.4.1.1.5" stretchy="false" xref="S5.E2.m1.4.4.1.1.5.cmml">⟶</mo><mrow id="S5.E2.m1.4.4.1.1.6" xref="S5.E2.m1.4.4.1.1.6.cmml"><mtext id="S5.E2.m1.4.4.1.1.6.2" xref="S5.E2.m1.4.4.1.1.6.2a.cmml">Output:</mtext><mo id="S5.E2.m1.4.4.1.1.6.1" lspace="0.500em" xref="S5.E2.m1.4.4.1.1.6.1.cmml">⁢</mo><mi id="S5.E2.m1.4.4.1.1.6.3" xref="S5.E2.m1.4.4.1.1.6.3.cmml">a</mi></mrow></mrow><mo id="S5.E2.m1.4.4.1.2" lspace="0em" xref="S5.E2.m1.4.4.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E2.m1.4b"><apply id="S5.E2.m1.4.4.1.1.cmml" xref="S5.E2.m1.4.4.1"><ci id="S5.E2.m1.4.4.1.1.5.cmml" xref="S5.E2.m1.4.4.1.1.5">⟶</ci><apply id="S5.E2.m1.4.4.1.1.4.cmml" xref="S5.E2.m1.4.4.1.1.4"><times id="S5.E2.m1.4.4.1.1.4.5.cmml" xref="S5.E2.m1.4.4.1.1.4.5"></times><ci id="S5.E2.m1.4.4.1.1.4.6a.cmml" xref="S5.E2.m1.4.4.1.1.4.6"><mtext id="S5.E2.m1.4.4.1.1.4.6.cmml" xref="S5.E2.m1.4.4.1.1.4.6">Input:</mtext></ci><list id="S5.E2.m1.4.4.1.1.4.4.5.cmml" xref="S5.E2.m1.4.4.1.1.4.4.4"><ci id="S5.E2.m1.1.1.cmml" xref="S5.E2.m1.1.1">𝐼</ci><apply id="S5.E2.m1.4.4.1.1.1.1.1.1.cmml" xref="S5.E2.m1.4.4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E2.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S5.E2.m1.4.4.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E2.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S5.E2.m1.4.4.1.1.1.1.1.1.2">𝑑</ci><cn id="S5.E2.m1.4.4.1.1.1.1.1.1.3.cmml" type="integer" xref="S5.E2.m1.4.4.1.1.1.1.1.1.3">1</cn></apply><apply id="S5.E2.m1.4.4.1.1.2.2.2.2.cmml" xref="S5.E2.m1.4.4.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S5.E2.m1.4.4.1.1.2.2.2.2.1.cmml" xref="S5.E2.m1.4.4.1.1.2.2.2.2">subscript</csymbol><ci id="S5.E2.m1.4.4.1.1.2.2.2.2.2.cmml" xref="S5.E2.m1.4.4.1.1.2.2.2.2.2">𝑑</ci><cn id="S5.E2.m1.4.4.1.1.2.2.2.2.3.cmml" type="integer" xref="S5.E2.m1.4.4.1.1.2.2.2.2.3">2</cn></apply><ci id="S5.E2.m1.2.2.cmml" xref="S5.E2.m1.2.2">…</ci><apply id="S5.E2.m1.4.4.1.1.3.3.3.3.cmml" xref="S5.E2.m1.4.4.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S5.E2.m1.4.4.1.1.3.3.3.3.1.cmml" xref="S5.E2.m1.4.4.1.1.3.3.3.3">subscript</csymbol><ci id="S5.E2.m1.4.4.1.1.3.3.3.3.2.cmml" xref="S5.E2.m1.4.4.1.1.3.3.3.3.2">𝑑</ci><apply id="S5.E2.m1.4.4.1.1.3.3.3.3.3.cmml" xref="S5.E2.m1.4.4.1.1.3.3.3.3.3"><minus id="S5.E2.m1.4.4.1.1.3.3.3.3.3.1.cmml" xref="S5.E2.m1.4.4.1.1.3.3.3.3.3.1"></minus><ci id="S5.E2.m1.4.4.1.1.3.3.3.3.3.2.cmml" xref="S5.E2.m1.4.4.1.1.3.3.3.3.3.2">𝑘</ci><cn id="S5.E2.m1.4.4.1.1.3.3.3.3.3.3.cmml" type="integer" xref="S5.E2.m1.4.4.1.1.3.3.3.3.3.3">1</cn></apply></apply><apply id="S5.E2.m1.4.4.1.1.4.4.4.4.cmml" xref="S5.E2.m1.4.4.1.1.4.4.4.4"><csymbol cd="ambiguous" id="S5.E2.m1.4.4.1.1.4.4.4.4.1.cmml" xref="S5.E2.m1.4.4.1.1.4.4.4.4">subscript</csymbol><ci id="S5.E2.m1.4.4.1.1.4.4.4.4.2.cmml" xref="S5.E2.m1.4.4.1.1.4.4.4.4.2">𝑑</ci><ci id="S5.E2.m1.4.4.1.1.4.4.4.4.3.cmml" xref="S5.E2.m1.4.4.1.1.4.4.4.4.3">𝑘</ci></apply><ci id="S5.E2.m1.3.3.cmml" xref="S5.E2.m1.3.3">𝑞</ci></list></apply><apply id="S5.E2.m1.4.4.1.1.6.cmml" xref="S5.E2.m1.4.4.1.1.6"><times id="S5.E2.m1.4.4.1.1.6.1.cmml" xref="S5.E2.m1.4.4.1.1.6.1"></times><ci id="S5.E2.m1.4.4.1.1.6.2a.cmml" xref="S5.E2.m1.4.4.1.1.6.2"><mtext id="S5.E2.m1.4.4.1.1.6.2.cmml" xref="S5.E2.m1.4.4.1.1.6.2">Output:</mtext></ci><ci id="S5.E2.m1.4.4.1.1.6.3.cmml" xref="S5.E2.m1.4.4.1.1.6.3">𝑎</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E2.m1.4c">\text{Input:}\ [I,d_{1},d_{2},...,d_{k-1},d_{k},q]\longrightarrow\text{Output:%
}\ a.</annotation><annotation encoding="application/x-llamapun" id="S5.E2.m1.4d">Input: [ italic_I , italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_d start_POSTSUBSCRIPT italic_k - 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_q ] ⟶ Output: italic_a .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S5.SS1.p2.5">This approach aims to implicitly enhance the LLM’s robustness to hard negatives by exposing it to a diverse range of retrieved contexts during fine-tuning, thus enabling it to learn to effectively identify and utilize relevant information even in the presence of noise.</p>
</div>
<figure class="ltx_figure" id="S5.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F5.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="200" id="S5.F5.sf1.g1" src="x17.png" width="267"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F5.sf1.2.1.1" style="font-size:80%;">(a)</span> </span><span class="ltx_text" id="S5.F5.sf1.3.2" style="font-size:80%;">TriviaQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F5.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="200" id="S5.F5.sf2.g1" src="x18.png" width="267"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F5.sf2.2.1.1" style="font-size:80%;">(b)</span> </span><span class="ltx_text" id="S5.F5.sf2.3.2" style="font-size:80%;">PopQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F5.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="200" id="S5.F5.sf3.g1" src="x19.png" width="267"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F5.sf3.2.1.1" style="font-size:80%;">(c)</span> </span><span class="ltx_text" id="S5.F5.sf3.3.2" style="font-size:80%;">HotpotQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F5.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="200" id="S5.F5.sf4.g1" src="x20.png" width="267"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F5.sf4.2.1.1" style="font-size:80%;">(d)</span> </span><span class="ltx_text" id="S5.F5.sf4.3.2" style="font-size:80%;">2wikimultihopqa</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F5.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="200" id="S5.F5.sf5.g1" src="x21.png" width="267"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F5.sf5.2.1.1" style="font-size:80%;">(e)</span> </span><span class="ltx_text" id="S5.F5.sf5.3.2" style="font-size:80%;">Bamboogle</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F5.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="200" id="S5.F5.sf6.g1" src="x22.png" width="267"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F5.sf6.2.1.1" style="font-size:80%;">(f)</span> </span><span class="ltx_text" id="S5.F5.sf6.3.2" style="font-size:80%;">ASQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F5.sf7"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="200" id="S5.F5.sf7.g1" src="x23.png" width="267"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F5.sf7.2.1.1" style="font-size:80%;">(g)</span> </span><span class="ltx_text" id="S5.F5.sf7.3.2" style="font-size:80%;">T-REx</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F5.sf8"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="200" id="S5.F5.sf8.g1" src="x24.png" width="267"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F5.sf8.2.1.1" style="font-size:80%;">(h)</span> </span><span class="ltx_text" id="S5.F5.sf8.3.2" style="font-size:80%;">zsRE</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F5.sf9"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="200" id="S5.F5.sf9.g1" src="x25.png" width="267"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F5.sf9.2.1.1" style="font-size:80%;">(i)</span> </span><span class="ltx_text" id="S5.F5.sf9.3.2" style="font-size:80%;">Legend</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Generalization ability of LLMs fine-tuned with RAG-specific data (RAG FT). RAG FT consistently outperforms the chat LLM w. RAG and the model fine-tuned directly on question-answer pairs (Direct FT). This demonstrates the effectiveness of RAG FT in enabling the LLM to effectively extract knowledge from retrieved context on unseen tasks. Note that Direct FT is evaluated without retrieval to align with its training paradigm and all others are evaluated with retrieval augmentation. (LLMs: Gemma-2-9B-Base, Mistral-Nemo-12B-Base, Gemini-1.0-Pro)</figcaption>
</figure>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1">To assess the generalization capabilities of RAG-tuned LLMs, we fine-tune Gemma-2-9B-Base, Mistral-Nemo-12B-Base and Gemini-1.0-Pro using a diverse dataset comprising NQ, WoW, Fever, and MMLU.
We then evaluate on a range of unseen datasets, including TriviaQA, PopQA, HotpotQA, 2wikimultihopqa, Webquestions, Bamboogle, ASQA, T-REx, and zsRE.
We compare the performance of the RAG-tuned model (RAG FT) with two types of baselines: (1) Chat model with retrieval augmentation: the Gemma-2-9B-Chat/Mistral-Nemo-12B-Instruct/Gemini-1.0-Pro w. RAG; (2) Direct SFT: the ones fine-tuned with standard supervised fine-tuning (SFT) on question-answer pairs without retrieved context (Direct FT w/o RAG). Further details regarding the datasets and experimental setup can be found in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A6" title="Appendix F Datasets ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">F</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A7" title="Appendix G Implicit RAG Fine-Tuning Experimental Setting ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">G</span></a>.</p>
</div>
<div class="ltx_para" id="S5.SS1.p4">
<p class="ltx_p" id="S5.SS1.p4.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S5.F5" title="Figure 5 ‣ 5.1 Implicitly improving LLM robustness through fine-tuning ‣ 5 Improving Robustness for RAG via Data-Augmented Fine-Tuning ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">5</span></a> shows the three key observations:
(1) Consistent improvement over baselines: RAG FT consistently outperforms the chat model w. RAG and the Direct FT model across all evaluated datasets.
(2) Robustness to hard negatives: the curve of RAG FT is generally flatter than that of the chat model, which demonstrates that our finetuned LLM is more robust to the hard negatives as the number of retrieved passages increases.
(3) Superiority over direct fine-tuning: In most cases, RAG FT demonstrates superior performance compared to Direct FT. This indicates that RAG FT not only enables the LLM to "memorize" knowledge during training but also equips it with the ability to effectively "extract" relevant information from retrieved context during inference.
These findings highlight the effectiveness of RAG-specific tuning in enhancing the generalization capabilities of LLMs for knowledge-intensive tasks.
Separate results on those three LLMs are shown in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A10" title="Appendix J Data-Augmented RAG Finetuning on Gemma-2-9B ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">J</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A11" title="Appendix K Data-Augmented RAG Finetuning on Mistral-Nemo-12B ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">K</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A12" title="Appendix L Data-Augmented RAG Finetuning on Gemini-1.0-Pro ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">L</span></a>.
Qualitative studies can be found in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A9" title="Appendix I Data-Augmented RAG Case Studies ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">I</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Enhancing relevance identification through reasoning augmentation</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">While the fine-tuning approach described in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S5.SS1" title="5.1 Implicitly improving LLM robustness through fine-tuning ‣ 5 Improving Robustness for RAG via Data-Augmented Fine-Tuning ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">5.1</span></a> implicitly enhances the LLM’s robustness to hard negatives, it does not explicitly train the model to differentiate between relevant and irrelevant passages within the retrieved context.
To address this, we investigate the effectiveness of incorporating an intermediate reasoning step into the fine-tuning process.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.3">This modified paradigm involves training the LLM to generate both a reasoning paragraph (<math alttext="r" class="ltx_Math" display="inline" id="S5.SS2.p2.1.m1.1"><semantics id="S5.SS2.p2.1.m1.1a"><mi id="S5.SS2.p2.1.m1.1.1" xref="S5.SS2.p2.1.m1.1.1.cmml">r</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.1b"><ci id="S5.SS2.p2.1.m1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1">𝑟</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">r</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.1.m1.1d">italic_r</annotation></semantics></math>) that explicitly identifies the relevant passages for the given query (<math alttext="q" class="ltx_Math" display="inline" id="S5.SS2.p2.2.m2.1"><semantics id="S5.SS2.p2.2.m2.1a"><mi id="S5.SS2.p2.2.m2.1.1" xref="S5.SS2.p2.2.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.2.m2.1b"><ci id="S5.SS2.p2.2.m2.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.2.m2.1c">q</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.2.m2.1d">italic_q</annotation></semantics></math>) and the final answer (<math alttext="a" class="ltx_Math" display="inline" id="S5.SS2.p2.3.m3.1"><semantics id="S5.SS2.p2.3.m3.1a"><mi id="S5.SS2.p2.3.m3.1.1" xref="S5.SS2.p2.3.m3.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.3.m3.1b"><ci id="S5.SS2.p2.3.m3.1.1.cmml" xref="S5.SS2.p2.3.m3.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.3.m3.1c">a</annotation><annotation encoding="application/x-llamapun" id="S5.SS2.p2.3.m3.1d">italic_a</annotation></semantics></math>):</p>
<table class="ltx_equation ltx_eqn_table" id="S5.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\text{Input:}\ [I,d_{1},d_{2},...,d_{k-1},d_{k},q]\longrightarrow\text{Output:%
}\ [r,a]," class="ltx_Math" display="block" id="S5.E3.m1.6"><semantics id="S5.E3.m1.6a"><mrow id="S5.E3.m1.6.6.1" xref="S5.E3.m1.6.6.1.1.cmml"><mrow id="S5.E3.m1.6.6.1.1" xref="S5.E3.m1.6.6.1.1.cmml"><mrow id="S5.E3.m1.6.6.1.1.4" xref="S5.E3.m1.6.6.1.1.4.cmml"><mtext id="S5.E3.m1.6.6.1.1.4.6" xref="S5.E3.m1.6.6.1.1.4.6a.cmml">Input:</mtext><mo id="S5.E3.m1.6.6.1.1.4.5" lspace="0.500em" xref="S5.E3.m1.6.6.1.1.4.5.cmml">⁢</mo><mrow id="S5.E3.m1.6.6.1.1.4.4.4" xref="S5.E3.m1.6.6.1.1.4.4.5.cmml"><mo id="S5.E3.m1.6.6.1.1.4.4.4.5" stretchy="false" xref="S5.E3.m1.6.6.1.1.4.4.5.cmml">[</mo><mi id="S5.E3.m1.1.1" xref="S5.E3.m1.1.1.cmml">I</mi><mo id="S5.E3.m1.6.6.1.1.4.4.4.6" xref="S5.E3.m1.6.6.1.1.4.4.5.cmml">,</mo><msub id="S5.E3.m1.6.6.1.1.1.1.1.1" xref="S5.E3.m1.6.6.1.1.1.1.1.1.cmml"><mi id="S5.E3.m1.6.6.1.1.1.1.1.1.2" xref="S5.E3.m1.6.6.1.1.1.1.1.1.2.cmml">d</mi><mn id="S5.E3.m1.6.6.1.1.1.1.1.1.3" xref="S5.E3.m1.6.6.1.1.1.1.1.1.3.cmml">1</mn></msub><mo id="S5.E3.m1.6.6.1.1.4.4.4.7" xref="S5.E3.m1.6.6.1.1.4.4.5.cmml">,</mo><msub id="S5.E3.m1.6.6.1.1.2.2.2.2" xref="S5.E3.m1.6.6.1.1.2.2.2.2.cmml"><mi id="S5.E3.m1.6.6.1.1.2.2.2.2.2" xref="S5.E3.m1.6.6.1.1.2.2.2.2.2.cmml">d</mi><mn id="S5.E3.m1.6.6.1.1.2.2.2.2.3" xref="S5.E3.m1.6.6.1.1.2.2.2.2.3.cmml">2</mn></msub><mo id="S5.E3.m1.6.6.1.1.4.4.4.8" xref="S5.E3.m1.6.6.1.1.4.4.5.cmml">,</mo><mi id="S5.E3.m1.2.2" mathvariant="normal" xref="S5.E3.m1.2.2.cmml">…</mi><mo id="S5.E3.m1.6.6.1.1.4.4.4.9" xref="S5.E3.m1.6.6.1.1.4.4.5.cmml">,</mo><msub id="S5.E3.m1.6.6.1.1.3.3.3.3" xref="S5.E3.m1.6.6.1.1.3.3.3.3.cmml"><mi id="S5.E3.m1.6.6.1.1.3.3.3.3.2" xref="S5.E3.m1.6.6.1.1.3.3.3.3.2.cmml">d</mi><mrow id="S5.E3.m1.6.6.1.1.3.3.3.3.3" xref="S5.E3.m1.6.6.1.1.3.3.3.3.3.cmml"><mi id="S5.E3.m1.6.6.1.1.3.3.3.3.3.2" xref="S5.E3.m1.6.6.1.1.3.3.3.3.3.2.cmml">k</mi><mo id="S5.E3.m1.6.6.1.1.3.3.3.3.3.1" xref="S5.E3.m1.6.6.1.1.3.3.3.3.3.1.cmml">−</mo><mn id="S5.E3.m1.6.6.1.1.3.3.3.3.3.3" xref="S5.E3.m1.6.6.1.1.3.3.3.3.3.3.cmml">1</mn></mrow></msub><mo id="S5.E3.m1.6.6.1.1.4.4.4.10" xref="S5.E3.m1.6.6.1.1.4.4.5.cmml">,</mo><msub id="S5.E3.m1.6.6.1.1.4.4.4.4" xref="S5.E3.m1.6.6.1.1.4.4.4.4.cmml"><mi id="S5.E3.m1.6.6.1.1.4.4.4.4.2" xref="S5.E3.m1.6.6.1.1.4.4.4.4.2.cmml">d</mi><mi id="S5.E3.m1.6.6.1.1.4.4.4.4.3" xref="S5.E3.m1.6.6.1.1.4.4.4.4.3.cmml">k</mi></msub><mo id="S5.E3.m1.6.6.1.1.4.4.4.11" xref="S5.E3.m1.6.6.1.1.4.4.5.cmml">,</mo><mi id="S5.E3.m1.3.3" xref="S5.E3.m1.3.3.cmml">q</mi><mo id="S5.E3.m1.6.6.1.1.4.4.4.12" stretchy="false" xref="S5.E3.m1.6.6.1.1.4.4.5.cmml">]</mo></mrow></mrow><mo id="S5.E3.m1.6.6.1.1.5" stretchy="false" xref="S5.E3.m1.6.6.1.1.5.cmml">⟶</mo><mrow id="S5.E3.m1.6.6.1.1.6" xref="S5.E3.m1.6.6.1.1.6.cmml"><mtext id="S5.E3.m1.6.6.1.1.6.2" xref="S5.E3.m1.6.6.1.1.6.2a.cmml">Output:</mtext><mo id="S5.E3.m1.6.6.1.1.6.1" lspace="0.500em" xref="S5.E3.m1.6.6.1.1.6.1.cmml">⁢</mo><mrow id="S5.E3.m1.6.6.1.1.6.3.2" xref="S5.E3.m1.6.6.1.1.6.3.1.cmml"><mo id="S5.E3.m1.6.6.1.1.6.3.2.1" stretchy="false" xref="S5.E3.m1.6.6.1.1.6.3.1.cmml">[</mo><mi id="S5.E3.m1.4.4" xref="S5.E3.m1.4.4.cmml">r</mi><mo id="S5.E3.m1.6.6.1.1.6.3.2.2" xref="S5.E3.m1.6.6.1.1.6.3.1.cmml">,</mo><mi id="S5.E3.m1.5.5" xref="S5.E3.m1.5.5.cmml">a</mi><mo id="S5.E3.m1.6.6.1.1.6.3.2.3" stretchy="false" xref="S5.E3.m1.6.6.1.1.6.3.1.cmml">]</mo></mrow></mrow></mrow><mo id="S5.E3.m1.6.6.1.2" xref="S5.E3.m1.6.6.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.E3.m1.6b"><apply id="S5.E3.m1.6.6.1.1.cmml" xref="S5.E3.m1.6.6.1"><ci id="S5.E3.m1.6.6.1.1.5.cmml" xref="S5.E3.m1.6.6.1.1.5">⟶</ci><apply id="S5.E3.m1.6.6.1.1.4.cmml" xref="S5.E3.m1.6.6.1.1.4"><times id="S5.E3.m1.6.6.1.1.4.5.cmml" xref="S5.E3.m1.6.6.1.1.4.5"></times><ci id="S5.E3.m1.6.6.1.1.4.6a.cmml" xref="S5.E3.m1.6.6.1.1.4.6"><mtext id="S5.E3.m1.6.6.1.1.4.6.cmml" xref="S5.E3.m1.6.6.1.1.4.6">Input:</mtext></ci><list id="S5.E3.m1.6.6.1.1.4.4.5.cmml" xref="S5.E3.m1.6.6.1.1.4.4.4"><ci id="S5.E3.m1.1.1.cmml" xref="S5.E3.m1.1.1">𝐼</ci><apply id="S5.E3.m1.6.6.1.1.1.1.1.1.cmml" xref="S5.E3.m1.6.6.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S5.E3.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S5.E3.m1.6.6.1.1.1.1.1.1">subscript</csymbol><ci id="S5.E3.m1.6.6.1.1.1.1.1.1.2.cmml" xref="S5.E3.m1.6.6.1.1.1.1.1.1.2">𝑑</ci><cn id="S5.E3.m1.6.6.1.1.1.1.1.1.3.cmml" type="integer" xref="S5.E3.m1.6.6.1.1.1.1.1.1.3">1</cn></apply><apply id="S5.E3.m1.6.6.1.1.2.2.2.2.cmml" xref="S5.E3.m1.6.6.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S5.E3.m1.6.6.1.1.2.2.2.2.1.cmml" xref="S5.E3.m1.6.6.1.1.2.2.2.2">subscript</csymbol><ci id="S5.E3.m1.6.6.1.1.2.2.2.2.2.cmml" xref="S5.E3.m1.6.6.1.1.2.2.2.2.2">𝑑</ci><cn id="S5.E3.m1.6.6.1.1.2.2.2.2.3.cmml" type="integer" xref="S5.E3.m1.6.6.1.1.2.2.2.2.3">2</cn></apply><ci id="S5.E3.m1.2.2.cmml" xref="S5.E3.m1.2.2">…</ci><apply id="S5.E3.m1.6.6.1.1.3.3.3.3.cmml" xref="S5.E3.m1.6.6.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S5.E3.m1.6.6.1.1.3.3.3.3.1.cmml" xref="S5.E3.m1.6.6.1.1.3.3.3.3">subscript</csymbol><ci id="S5.E3.m1.6.6.1.1.3.3.3.3.2.cmml" xref="S5.E3.m1.6.6.1.1.3.3.3.3.2">𝑑</ci><apply id="S5.E3.m1.6.6.1.1.3.3.3.3.3.cmml" xref="S5.E3.m1.6.6.1.1.3.3.3.3.3"><minus id="S5.E3.m1.6.6.1.1.3.3.3.3.3.1.cmml" xref="S5.E3.m1.6.6.1.1.3.3.3.3.3.1"></minus><ci id="S5.E3.m1.6.6.1.1.3.3.3.3.3.2.cmml" xref="S5.E3.m1.6.6.1.1.3.3.3.3.3.2">𝑘</ci><cn id="S5.E3.m1.6.6.1.1.3.3.3.3.3.3.cmml" type="integer" xref="S5.E3.m1.6.6.1.1.3.3.3.3.3.3">1</cn></apply></apply><apply id="S5.E3.m1.6.6.1.1.4.4.4.4.cmml" xref="S5.E3.m1.6.6.1.1.4.4.4.4"><csymbol cd="ambiguous" id="S5.E3.m1.6.6.1.1.4.4.4.4.1.cmml" xref="S5.E3.m1.6.6.1.1.4.4.4.4">subscript</csymbol><ci id="S5.E3.m1.6.6.1.1.4.4.4.4.2.cmml" xref="S5.E3.m1.6.6.1.1.4.4.4.4.2">𝑑</ci><ci id="S5.E3.m1.6.6.1.1.4.4.4.4.3.cmml" xref="S5.E3.m1.6.6.1.1.4.4.4.4.3">𝑘</ci></apply><ci id="S5.E3.m1.3.3.cmml" xref="S5.E3.m1.3.3">𝑞</ci></list></apply><apply id="S5.E3.m1.6.6.1.1.6.cmml" xref="S5.E3.m1.6.6.1.1.6"><times id="S5.E3.m1.6.6.1.1.6.1.cmml" xref="S5.E3.m1.6.6.1.1.6.1"></times><ci id="S5.E3.m1.6.6.1.1.6.2a.cmml" xref="S5.E3.m1.6.6.1.1.6.2"><mtext id="S5.E3.m1.6.6.1.1.6.2.cmml" xref="S5.E3.m1.6.6.1.1.6.2">Output:</mtext></ci><interval closure="closed" id="S5.E3.m1.6.6.1.1.6.3.1.cmml" xref="S5.E3.m1.6.6.1.1.6.3.2"><ci id="S5.E3.m1.4.4.cmml" xref="S5.E3.m1.4.4">𝑟</ci><ci id="S5.E3.m1.5.5.cmml" xref="S5.E3.m1.5.5">𝑎</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.E3.m1.6c">\text{Input:}\ [I,d_{1},d_{2},...,d_{k-1},d_{k},q]\longrightarrow\text{Output:%
}\ [r,a],</annotation><annotation encoding="application/x-llamapun" id="S5.E3.m1.6d">Input: [ italic_I , italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_d start_POSTSUBSCRIPT italic_k - 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT , italic_q ] ⟶ Output: [ italic_r , italic_a ] ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S5.SS2.p2.4">During training, the LLMs are provided with labeled reasoning paragraphs to guide its learning process.
During inference, the LLMs are instructed to first generate the reasoning paragraph and then utilize this analysis to produce the answer.
This approach aims to explicitly enhance the LLMs’ ability to discern relevant information from noise within the retrieved context, thereby improving its overall performance in RAG.</p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1">We utilize the same training data mixture as in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S5.SS1" title="5.1 Implicitly improving LLM robustness through fine-tuning ‣ 5 Improving Robustness for RAG via Data-Augmented Fine-Tuning ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">5.1</span></a> and augment it with reasoning labels generated by Gemini-1.5-Pro for each question-passage pair. These labels provide explicit guidance on identifying relevant passages. Further details of the experimental setup and the generation of reasoning labels can be found in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A8" title="Appendix H RAG Finetuning with Intermediate Reasoning Experimental Setting ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">H</span></a>.</p>
</div>
<figure class="ltx_figure" id="S5.F6">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F6.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="S5.F6.sf1.g1" src="x26.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F6.sf1.2.1.1" style="font-size:80%;">(a)</span> </span><span class="ltx_text" id="S5.F6.sf1.3.2" style="font-size:80%;">TriviaQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F6.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="S5.F6.sf2.g1" src="x27.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F6.sf2.2.1.1" style="font-size:80%;">(b)</span> </span><span class="ltx_text" id="S5.F6.sf2.3.2" style="font-size:80%;">PopQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F6.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="S5.F6.sf3.g1" src="x28.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F6.sf3.2.1.1" style="font-size:80%;">(c)</span> </span><span class="ltx_text" id="S5.F6.sf3.3.2" style="font-size:80%;">HotpotQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F6.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="S5.F6.sf4.g1" src="x29.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F6.sf4.2.1.1" style="font-size:80%;">(d)</span> </span><span class="ltx_text" id="S5.F6.sf4.3.2" style="font-size:80%;">2wikimultihopqa</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F6.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="S5.F6.sf5.g1" src="x30.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F6.sf5.2.1.1" style="font-size:80%;">(e)</span> </span><span class="ltx_text" id="S5.F6.sf5.3.2" style="font-size:80%;">ASQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S5.F6.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="S5.F6.sf6.g1" src="x31.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S5.F6.sf6.2.1.1" style="font-size:80%;">(f)</span> </span><span class="ltx_text" id="S5.F6.sf6.3.2" style="font-size:80%;">Legend</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Evaluating the impact of intermediate reasoning on the performance of RAG-tuned LLMs. Results demonstrate that fine-tuning with an intermediate reasoning step (RAG FT w. Int) leads to further improvements compared to implicit RAG fine-tuning (RAG FT) and direct fine-tuning (Direct FT). Direct FT is evaluated without retrieval to align with its training and all others are evaluated with retrieval augmentation. Due to the computational complexity of inference with reasoning augmentation, results are shown for 1000 randomly-sampled queries from each dataset. (LLMs: Gemma-2-9B-Base and Gemini-1.0-Pro, more results in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A10" title="Appendix J Data-Augmented RAG Finetuning on Gemma-2-9B ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">J</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A11" title="Appendix K Data-Augmented RAG Finetuning on Mistral-Nemo-12B ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">K</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A12" title="Appendix L Data-Augmented RAG Finetuning on Gemini-1.0-Pro ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">L</span></a>)</figcaption>
</figure>
<div class="ltx_para" id="S5.SS2.p4">
<p class="ltx_p" id="S5.SS2.p4.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S5.F6" title="Figure 6 ‣ 5.2 Enhancing relevance identification through reasoning augmentation ‣ 5 Improving Robustness for RAG via Data-Augmented Fine-Tuning ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">6</span></a> demonstrates the effectiveness of this approach. The LLM fine-tuned with explicit intermediate reasoning consistently outperforms training with implicit RAG data. This improvement can be attributed to two key factors:
(1) Explicit relevance training: Providing intermediate reasoning labels during training explicitly teaches the LLM to differentiate between relevant and irrelevant passages, enhancing its ability to discern crucial information from noise.
(2) Structured reasoning for enhanced understanding: Generating a reasoning paragraph before answering introduces a structured approach to processing the retrieved context. This step, akin to chain-of-thought reasoning <cite class="ltx_cite ltx_citemacro_citep">(Wei et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib28" title="">2022</a>)</cite>, helps decouple the complex information and facilitates a more focused analysis, ultimately leading to improved performance.
These highlight the value of incorporating explicit reasoning mechanisms in RAG tuning to enhance the LLM’s ability to effectively utilize retrieved context.
More results on Gemma-2-9B models, Mistral-Nemo-12B models and Gemini-1.0-Pro models are shown in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A10" title="Appendix J Data-Augmented RAG Finetuning on Gemma-2-9B ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">J</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A11" title="Appendix K Data-Augmented RAG Finetuning on Mistral-Nemo-12B ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">K</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A12" title="Appendix L Data-Augmented RAG Finetuning on Gemini-1.0-Pro ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">L</span></a>.
Qualitative studies can be found in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A9" title="Appendix I Data-Augmented RAG Case Studies ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">I</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Data-Centric Perspectives on Fine-tuning LLMs for RAG</h2>
<div class="ltx_para ltx_noindent" id="S6.p1">
<p class="ltx_p" id="S6.p1.1"><span class="ltx_text ltx_font_bold" id="S6.p1.1.1">Impact of training data distribution on generalization.</span>
We first examine how the distribution of training data affects the generalization of the fine-tuned LLM.
We train LLMs on five different data distributions, each with 50k samples: (1) a mixed dataset comprising NQ, WoW, Fever, and MMLU (12.5k samples from each); (2) NQ only; (3) WoW only; (4) Fever only; and (5) MMLU only.
</p>
</div>
<div class="ltx_para" id="S6.p2">
<p class="ltx_p" id="S6.p2.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S6.F7" title="Figure 7 ‣ 6 Data-Centric Perspectives on Fine-tuning LLMs for RAG ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">7</span></a>(a) demonstrates that a mixed distribution of training data leads to superior generalization performance on unseen RAG tasks compared to training on a single data source.
This highlights the importance of data diversity in enhancing the adaptability of LLMs to new RAG scenarios.</p>
</div>
<div class="ltx_para ltx_noindent" id="S6.p3">
<p class="ltx_p" id="S6.p3.1"><span class="ltx_text ltx_font_bold" id="S6.p3.1.1">Influence of retrievers on generalization.</span>
In real-world RAG deployments, LLMs might be paired with different retrievers depending on specific external knowledge corpus and retrievers’ capabilities. To investigate the impact of different retrievers on fine-tuning, we explore three adaptation scenarios on NQ: fine-tuning with (1) passages retrieved by BM25 (FT w. BM25); (2) passages retrieved by e5 (FT w. e5); and (3) mixture of passages retrieved by both BM25 and e5 (FT w. mix).
We evaluate the performance of these fine-tuned LLMs using both retrievers seen during training (BM25 and e5) and unseen retrievers (Contriever <cite class="ltx_cite ltx_citemacro_citep">(Izacard et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib12" title="">2021</a>)</cite> and BGE <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib4" title="">2024</a>)</cite>).</p>
</div>
<div class="ltx_para" id="S6.p4">
<p class="ltx_p" id="S6.p4.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S6.F7" title="Figure 7 ‣ 6 Data-Centric Perspectives on Fine-tuning LLMs for RAG ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">7</span></a>(b) presents the results, revealing two key findings:
(1) Superiority of mixed retriever training: Fine-tuning with the data corresponding to a mix of retrievers consistently yields the best performance across both seen and unseen retrievers during inference. This suggests that training on a diverse set of retrieved passages enhances the LLMs’ ability to adapt to different retrieval strategies and knowledge sources.
(2) Retriever similarity and generalization: The generalization ability of an LLM fine-tuned with a specific retriever is influenced by the similarity between the training retriever and the inference retriever. For instance, an LLM trained with BM25 generalizes better to Contriever, while an LLM trained with e5 generalizes better to BGE. This observation suggests that "hard negatives" exhibit different characteristics depending on the employed retriever, and training with a specific retriever implicitly equips the LLM to better handle similar types of hard negatives. See Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A1" title="Appendix A Retriever performance and similarity ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">A</span></a> for a detailed analysis of retriever similarity.</p>
</div>
<figure class="ltx_figure" id="S6.F7">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F7.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="S6.F7.sf1.g1" src="x32.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F7.sf1.2.1.1" style="font-size:80%;">(a)</span> </span><span class="ltx_text" id="S6.F7.sf1.3.2" style="font-size:80%;">Analysis of training data distribution. (Test: HotpotQA)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F7.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="S6.F7.sf2.g1" src="x33.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F7.sf2.2.1.1" style="font-size:80%;">(b)</span> </span><span class="ltx_text" id="S6.F7.sf2.3.2" style="font-size:80%;">Influence of retriever variations on fine-tuning effectiveness. (NQ)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S6.F7.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="S6.F7.sf3.g1" src="x34.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S6.F7.sf3.2.1.1" style="font-size:80%;">(c)</span> </span><span class="ltx_text" id="S6.F7.sf3.3.2" style="font-size:80%;">Investigation of the optimal number of passages for training.</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>(a) Impact of training data distribution: A diverse mix of training data sources enhances the generalization ability of the LLM.
(b) Influence of the retriever choice: Fine-tuning with data retrieved from multiple retrievers improves generalization to unseen retrievers during inference.
(c) Effect of training context length: Fine-tuning with the maximum context length yields optimal performance across varying numbers of retrieved passages during inference.
(LLM: Gemma-2-9B-Base)</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S6.p5">
<p class="ltx_p" id="S6.p5.1"><span class="ltx_text ltx_font_bold" id="S6.p5.1.1">Optimizing training for variable retrieval sizes.</span>
In real-world RAG systems, the number of retrieved passages can vary depending on the specific knowledge source and user requirements.
Therefore, it is essential to determine the optimal training strategy for LLMs to ensure robust performance across different retrieval sizes during inference.
We investigate this aspect with the Gemma-2-9B-Base model, which has a maximum input sequence length of 8192 tokens (corresponding to approximately 40 passages).
We evaluate five different training configurations:
(1) Fixed 10 retrieved passages (25% max).
(2) Fixed 20 retrieved passages (50% max).
(3) Fixed 40 retrieved passages (maximum input capacity) (100% max).
(4) Dynamic 0-40 retrieved passages (0-100% max).
(5) Dynamic 20-40 retrieved passages (50-100% max).
</p>
</div>
<div class="ltx_para" id="S6.p6">
<p class="ltx_p" id="S6.p6.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S6.F7" title="Figure 7 ‣ 6 Data-Centric Perspectives on Fine-tuning LLMs for RAG ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">7</span></a>(c) presents the results on NQ, demonstrating that fine-tuning with the maximum number of retrieved passages (100% max) consistently yields the best performance across various retrieval sizes during inference.
This suggests that training with the full context capacity enhances the LLM’s ability to effectively handle varying amounts of retrieved information, leading to improved generalization and robustness.
More analyses of RAG-specific tuning can be found in in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A13" title="Appendix M Training data scaling and RAG performance. ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">M</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A14" title="Appendix N RAG-specific tuning data inside SFT mixtures ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">N</span></a>.</p>
</div>
</section>
<section class="ltx_section" id="S7" lang="en">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusions</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">This paper investigates the impact of increasing the number of retrieved passages on the performance of long-context LLMs in retrieval-augmented generation (RAG) systems.
Contrary to expectations, we observe that performance initially improve but then degrade as more passages are included.
This phenomenon is attributed to the detrimental influence of retrieved "hard negatives".
To mitigate this issue, we propose and evaluate three solutions: training-free retrieval reordering, RAG-specific implicit LLM fine-tuning, and RAG-oriented LLM fine-tuning with intermediate reasoning.
A systematic analysis of the training-based methods explores the effects of data distribution, retriever for training, and training context length.
Interesting future directions include exploring (automated) position optimization with more advanced retrieval ordering methods, and fine-tuning the LLMs for RAG with more fine-grained and multi-step reasoning chains.</p>
</div>
<div class="ltx_para" id="S7.p2">
<span class="ltx_ERROR undefined" id="S7.p2.1">\nobibliography</span>
<p class="ltx_p" id="S7.p2.2">*</p>
</div>
</section>
<section class="ltx_bibliography" id="bib" lang="en">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Agarwal et al. (2024)</span>
<span class="ltx_bibblock">
R. Agarwal, A. Singh, L. M. Zhang, B. Bohnet, S. Chan, A. Anand, Z. Abbas,
A. Nova, J. D. Co-Reyes, E. Chu, et al.

</span>
<span class="ltx_bibblock">Many-shot in-context learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">arXiv preprint arXiv:2404.11018</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Asai et al. (2024)</span>
<span class="ltx_bibblock">
A. Asai, Z. Wu, Y. Wang, A. Sil, and H. Hajishirzi.

</span>
<span class="ltx_bibblock">Self-rag: Learning to retrieve, generate, and critique through
self-reflection.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">The Twelfth International Conference on Learning
Representations</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Augenstein et al. (2023)</span>
<span class="ltx_bibblock">
I. Augenstein, T. Baldwin, M. Cha, T. Chakraborty, G. L. Ciampaglia, D. Corney,
R. DiResta, E. Ferrara, S. Hale, A. Halevy, et al.

</span>
<span class="ltx_bibblock">Factuality challenges in the era of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">arXiv preprint arXiv:2310.05189</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2024)</span>
<span class="ltx_bibblock">
J. Chen, S. Xiao, P. Zhang, K. Luo, D. Lian, and Z. Liu.

</span>
<span class="ltx_bibblock">Bge m3-embedding: Multi-lingual, multi-functionality,
multi-granularity text embeddings through self-knowledge distillation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2402.03216</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cuconasu et al. (2024)</span>
<span class="ltx_bibblock">
F. Cuconasu, G. Trappolini, F. Siciliano, S. Filice, C. Campagnano, Y. Maarek,
N. Tonellotto, and F. Silvestri.

</span>
<span class="ltx_bibblock">The power of noise: Redefining retrieval for rag systems.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the 47th International ACM SIGIR Conference
on Research and Development in Information Retrieval</em>, pages 719–729, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et al. (2022)</span>
<span class="ltx_bibblock">
Q. Dong, L. Li, D. Dai, C. Zheng, Z. Wu, B. Chang, X. Sun, J. Xu, and Z. Sui.

</span>
<span class="ltx_bibblock">A survey on in-context learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2301.00234</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dubey et al. (2024)</span>
<span class="ltx_bibblock">
A. Dubey, A. Jauhri, A. Pandey, A. Kadian, A. Al-Dahle, A. Letman, A. Mathur,
A. Schelten, A. Yang, A. Fan, et al.

</span>
<span class="ltx_bibblock">The llama 3 herd of models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2407.21783</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2023)</span>
<span class="ltx_bibblock">
Y. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan, Y. Bi, Y. Dai, J. Sun, and H. Wang.

</span>
<span class="ltx_bibblock">Retrieval-augmented generation for large language models: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2312.10997</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsieh et al. (2024a)</span>
<span class="ltx_bibblock">
C.-P. Hsieh, S. Sun, S. Kriman, S. Acharya, D. Rekesh, F. Jia, and B. Ginsburg.

</span>
<span class="ltx_bibblock">Ruler: What’s the real context size of your long-context language
models?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2404.06654</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsieh et al. (2024b)</span>
<span class="ltx_bibblock">
C.-Y. Hsieh, Y.-S. Chuang, C.-L. Li, Z. Wang, L. T. Le, A. Kumar, J. Glass,
A. Ratner, C.-Y. Lee, R. Krishna, et al.

</span>
<span class="ltx_bibblock">Found in the middle: Calibrating positional attention bias improves
long context utilization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2406.16008</em>, 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2023)</span>
<span class="ltx_bibblock">
L. Huang, W. Yu, W. Ma, W. Zhong, Z. Feng, H. Wang, Q. Chen, W. Peng, X. Feng,
B. Qin, et al.

</span>
<span class="ltx_bibblock">A survey on hallucination in large language models: Principles,
taxonomy, challenges, and open questions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">arXiv preprint arXiv:2311.05232</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Izacard et al. (2021)</span>
<span class="ltx_bibblock">
G. Izacard, M. Caron, L. Hosseini, S. Riedel, P. Bojanowski, A. Joulin, and
E. Grave.

</span>
<span class="ltx_bibblock">Unsupervised dense information retrieval with contrastive learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2112.09118</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2023)</span>
<span class="ltx_bibblock">
A. Q. Jiang, A. Sablayrolles, A. Mensch, C. Bamford, D. S. Chaplot, D. d. l.
Casas, F. Bressand, G. Lengyel, G. Lample, L. Saulnier, et al.

</span>
<span class="ltx_bibblock">Mistral 7b.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:2310.06825</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kamradt (2023)</span>
<span class="ltx_bibblock">
G. Kamradt.

</span>
<span class="ltx_bibblock">Needle in a haystack - pressure testing llms, 2023.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/gkamradt/LLMTestNeedleInAHaystack/tree/main" title="">https://github.com/gkamradt/LLMTestNeedleInAHaystack/tree/main</a>.

</span>
<span class="ltx_bibblock">Accessed: 2024-09-10.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karpukhin et al. (2020)</span>
<span class="ltx_bibblock">
V. Karpukhin, B. Oğuz, S. Min, P. Lewis, L. Wu, S. Edunov, D. Chen, and
W.-t. Yih.

</span>
<span class="ltx_bibblock">Dense passage retrieval for open-domain question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2004.04906</em>, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwiatkowski et al. (2019)</span>
<span class="ltx_bibblock">
T. Kwiatkowski, J. Palomaki, O. Redfield, M. Collins, A. Parikh, C. Alberti,
D. Epstein, I. Polosukhin, J. Devlin, K. Lee, et al.

</span>
<span class="ltx_bibblock">Natural questions: a benchmark for question answering research.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Transactions of the Association for Computational Linguistics</em>,
7:453–466, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee et al. (2024)</span>
<span class="ltx_bibblock">
J. Lee, A. Chen, Z. Dai, D. Dua, D. S. Sachan, M. Boratko, Y. Luan, S. M.
Arnold, V. Perot, S. Dalmia, et al.

</span>
<span class="ltx_bibblock">Can long-context language models subsume retrieval, rag, sql, and
more?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2406.13121</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2024)</span>
<span class="ltx_bibblock">
Z. Li, C. Li, M. Zhang, Q. Mei, and M. Bendersky.

</span>
<span class="ltx_bibblock">Retrieval augmented generation or long-context llms? a comprehensive
study and hybrid approach.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2407.16833</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2024)</span>
<span class="ltx_bibblock">
X. V. Lin, X. Chen, M. Chen, W. Shi, M. Lomeli, R. James, P. Rodriguez,
J. Kahn, G. Szilvasy, M. Lewis, et al.

</span>
<span class="ltx_bibblock">Ra-dit: Retrieval-augmented dual instruction tuning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">The Twelfth International Conference on Learning
Representations</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2024)</span>
<span class="ltx_bibblock">
N. F. Liu, K. Lin, J. Hewitt, A. Paranjape, M. Bevilacqua, F. Petroni, and
P. Liang.

</span>
<span class="ltx_bibblock">Lost in the middle: How language models use long contexts.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Transactions of the Association for Computational Linguistics</em>,
12:157–173, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reid et al. (2024)</span>
<span class="ltx_bibblock">
M. Reid, N. Savinov, D. Teplyashin, D. Lepikhin, T. Lillicrap, J.-b. Alayrac,
R. Soricut, A. Lazaridou, O. Firat, J. Schrittwieser, et al.

</span>
<span class="ltx_bibblock">Gemini 1.5: Unlocking multimodal understanding across millions of
tokens of context.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2403.05530</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Robertson et al. (2009)</span>
<span class="ltx_bibblock">
S. Robertson, H. Zaragoza, et al.

</span>
<span class="ltx_bibblock">The probabilistic relevance framework: Bm25 and beyond.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Foundations and Trends® in Information
Retrieval</em>, 3(4):333–389, 2009.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al. (2023)</span>
<span class="ltx_bibblock">
F. Shi, X. Chen, K. Misra, N. Scales, D. Dohan, E. H. Chi, N. Schärli, and
D. Zhou.

</span>
<span class="ltx_bibblock">Large language models can be easily distracted by irrelevant context.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">International Conference on Machine Learning</em>, pages
31210–31227. PMLR, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team et al. (2024a)</span>
<span class="ltx_bibblock">
G. Team, T. Mesnard, C. Hardin, R. Dadashi, S. Bhupatiraju, S. Pathak,
L. Sifre, M. Rivière, M. S. Kale, J. Love, et al.

</span>
<span class="ltx_bibblock">Gemma: Open models based on gemini research and technology.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">arXiv preprint arXiv:2403.08295</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team et al. (2024b)</span>
<span class="ltx_bibblock">
G. Team, M. Riviere, S. Pathak, P. G. Sessa, C. Hardin, S. Bhupatiraju,
L. Hussenot, T. Mesnard, B. Shahriari, A. Ramé, et al.

</span>
<span class="ltx_bibblock">Gemma 2: Improving open language models at a practical size.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2408.00118</em>, 2024b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022)</span>
<span class="ltx_bibblock">
L. Wang, N. Yang, X. Huang, B. Jiao, L. Yang, D. Jiang, R. Majumder, and
F. Wei.

</span>
<span class="ltx_bibblock">Text embeddings by weakly-supervised contrastive pre-training.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:2212.03533</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2024)</span>
<span class="ltx_bibblock">
X. Wang, M. Salmani, P. Omidi, X. Ren, M. Rezagholizadeh, and A. Eshaghi.

</span>
<span class="ltx_bibblock">Beyond the limits: A survey of techniques to extend the context
length in large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2402.02244</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2022)</span>
<span class="ltx_bibblock">
J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V. Le, D. Zhou,
et al.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language
models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Advances in neural information processing systems</em>,
35:24824–24837, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2024)</span>
<span class="ltx_bibblock">
Z. Wei, W.-L. Chen, and Y. Meng.

</span>
<span class="ltx_bibblock">Instructrag: Instructing retrieval-augmented generation with explicit
denoising.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">arXiv preprint arXiv:2406.13629</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2023)</span>
<span class="ltx_bibblock">
P. Xu, W. Ping, X. Wu, L. McAfee, C. Zhu, Z. Liu, S. Subramanian,
E. Bakhturina, M. Shoeybi, and B. Catanzaro.

</span>
<span class="ltx_bibblock">Retrieval meets long context large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:2310.03025</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoran et al. (2024)</span>
<span class="ltx_bibblock">
O. Yoran, T. Wolfson, O. Ram, and J. Berant.

</span>
<span class="ltx_bibblock">Making retrieval-augmented language models robust to irrelevant
context.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">The Twelfth International Conference on Learning
Representations</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2024)</span>
<span class="ltx_bibblock">
Y. Yu, W. Ping, Z. Liu, B. Wang, J. You, C. Zhang, M. Shoeybi, and
B. Catanzaro.

</span>
<span class="ltx_bibblock">Rankrag: Unifying context ranking with retrieval-augmented generation
in llms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">arXiv preprint arXiv:2407.02485</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023)</span>
<span class="ltx_bibblock">
S. Zhang, L. Dong, X. Li, S. Zhang, X. Sun, S. Wang, J. Li, R. Hu, T. Zhang,
F. Wu, et al.

</span>
<span class="ltx_bibblock">Instruction tuning for large language models: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2308.10792</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024)</span>
<span class="ltx_bibblock">
T. Zhang, S. G. Patil, N. Jain, S. Shen, M. Zaharia, I. Stoica, and J. E.
Gonzalez.

</span>
<span class="ltx_bibblock">Raft: Adapting language model to domain specific rag.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">arXiv preprint arXiv:2403.10131</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2023)</span>
<span class="ltx_bibblock">
W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou, Y. Min, B. Zhang,
J. Zhang, Z. Dong, et al.

</span>
<span class="ltx_bibblock">A survey of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">arXiv preprint arXiv:2303.18223</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2024)</span>
<span class="ltx_bibblock">
W. X. Zhao, J. Liu, R. Ren, and J.-R. Wen.

</span>
<span class="ltx_bibblock">Dense text retrieval based on pretrained language models: A survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">ACM Transactions on Information Systems</em>, 42(4):1–60, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2024)</span>
<span class="ltx_bibblock">
Z. Zhou, X. Ning, K. Hong, T. Fu, J. Xu, S. Li, Y. Lou, L. Wang, Z. Yuan,
X. Li, et al.

</span>
<span class="ltx_bibblock">A survey on efficient inference for large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">arXiv preprint arXiv:2404.14294</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2021)</span>
<span class="ltx_bibblock">
F. Zhu, W. Lei, C. Wang, J. Zheng, S. Poria, and T.-S. Chua.

</span>
<span class="ltx_bibblock">Retrieving and reading: A comprehensive survey on open-domain
question answering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">arXiv preprint arXiv:2101.00774</em>, 2021.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<section class="ltx_appendix" id="Ax1" lang="en">
<h2 class="ltx_title ltx_title_appendix">Appendix</h2>
</section>
<section class="ltx_appendix" id="A1" lang="en">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Retriever performance and similarity</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">We analyze the performance and similarity of four retrievers (BM25, contriever, e5 and bge) on the NQ dataset shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A1.F8" title="Figure 8 ‣ Appendix A Retriever performance and similarity ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">8</span></a>.
Each data point corresponds to a retrieval (recall, precision) pair for a specific number of retrieved passages.
The overall retrieval performances on NQ are observed as e5 &gt; bge &gt; contriever &gt; bm25, with contriever having a similar performance with BM25 and bge having a similar performance with e5 (as their curves are closer).</p>
</div>
<figure class="ltx_figure" id="A1.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="349" id="A1.F8.g1" src="x35.png" width="581"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Retriever performance on NQ. (1) Retrieval performance: e5 &gt; bge &gt; contriever &gt; BM25; (2) Contriever is more similar to BM25, while bge is more similar to e5 (since their curves are closer respectively).</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A2" lang="en">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Long context LLMs in RAG analysis on other datasets</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">In addition to the analysis presented on the NQ dataset in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S3" title="3 Challenges of Long context LLMs in RAG ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">3</span></a>, we conduct further studies on the PopQA dataset to underscore the generality of our findings.</p>
</div>
<section class="ltx_subsection" id="A2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>The Effect of retrieved context size on RAG performance</h3>
<figure class="ltx_figure" id="A2.F9">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A2.F9.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="306" id="A2.F9.sf1.g1" src="x36.png" width="408"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A2.F9.sf1.2.1.1" style="font-size:80%;">(a)</span> </span><span class="ltx_text" id="A2.F9.sf1.3.2" style="font-size:80%;">RAG performance with e5 retriever</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A2.F9.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="306" id="A2.F9.sf2.g1" src="x37.png" width="408"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A2.F9.sf2.2.1.1" style="font-size:80%;">(b)</span> </span><span class="ltx_text" id="A2.F9.sf2.3.2" style="font-size:80%;">RAG performance with BM25 retriever</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Impact of retrieved context size on RAG performance (on PopQA) with 4 different LLMs. Increasing the number of retrieved passages initially improves performance but then leads to a decline. This degradation is more pronounced using a retriever (e5) that exhibits higher recall@k on PopQA compared to BM25 (<math alttext="\text{Recall}@40" class="ltx_Math" display="inline" id="A2.F9.2.m1.1"><semantics id="A2.F9.2.m1.1b"><mrow id="A2.F9.2.m1.1.1" xref="A2.F9.2.m1.1.1.cmml"><mtext id="A2.F9.2.m1.1.1.2" xref="A2.F9.2.m1.1.1.2a.cmml">Recall</mtext><mo id="A2.F9.2.m1.1.1.1" xref="A2.F9.2.m1.1.1.1.cmml">⁢</mo><mi id="A2.F9.2.m1.1.1.3" mathvariant="normal" xref="A2.F9.2.m1.1.1.3.cmml">@</mi><mo id="A2.F9.2.m1.1.1.1b" xref="A2.F9.2.m1.1.1.1.cmml">⁢</mo><mn id="A2.F9.2.m1.1.1.4" xref="A2.F9.2.m1.1.1.4.cmml">40</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.F9.2.m1.1c"><apply id="A2.F9.2.m1.1.1.cmml" xref="A2.F9.2.m1.1.1"><times id="A2.F9.2.m1.1.1.1.cmml" xref="A2.F9.2.m1.1.1.1"></times><ci id="A2.F9.2.m1.1.1.2a.cmml" xref="A2.F9.2.m1.1.1.2"><mtext id="A2.F9.2.m1.1.1.2.cmml" xref="A2.F9.2.m1.1.1.2">Recall</mtext></ci><ci id="A2.F9.2.m1.1.1.3.cmml" xref="A2.F9.2.m1.1.1.3">@</ci><cn id="A2.F9.2.m1.1.1.4.cmml" type="integer" xref="A2.F9.2.m1.1.1.4">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.F9.2.m1.1d">\text{Recall}@40</annotation><annotation encoding="application/x-llamapun" id="A2.F9.2.m1.1e">Recall @ 40</annotation></semantics></math> is 0.85 with e5 and 0.57 with BM25). The maximum number of retrieved passages varies across LLMs due to differences in their maximum token limits.</figcaption>
</figure>
<div class="ltx_para" id="A2.SS1.p1">
<p class="ltx_p" id="A2.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="A2.SS1.p1.1.1">Observations.</span>
Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A2.F9" title="Figure 9 ‣ B.1 The Effect of retrieved context size on RAG performance ‣ Appendix B Long context LLMs in RAG analysis on other datasets ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">9</span></a> presents the following key observations similar to that in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S3.SS1" title="3.1 The Effect of retrieved context size on RAG performance ‣ 3 Challenges of Long context LLMs in RAG ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">3.1</span></a>:
1) Strong Retriever (e5): Across all LLMs, increasing the number of retrieved passages initially enhances performance, but subsequently results in either a sharp decline or a plateau.
2) Weak Retriever (BM25): Performance generally shows a continuous improvement or a slighter decrease as the number of retrieved passages increases.
While these observations may appear counter-intuitive - given that one might expect monotonic improvements due to higher recall (<span class="ltx_text ltx_font_italic" id="A2.SS1.p1.1.2">i.e.</span>, a greater chance of retrieving relevant information) - the inclusion of additional documents can reduce precision, with irrelevant or misleading passages detracting LLMs from overall performance.</p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>The importance of hard negatives for long-context LLM evaluation</h3>
<figure class="ltx_figure" id="A2.F10">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A2.F10.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="220" id="A2.F10.sf1.g1" src="x38.png" width="201"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A2.F10.sf1.2.1.1" style="font-size:80%;">(a)</span> </span><span class="ltx_text" id="A2.F10.sf1.3.2" style="font-size:80%;">Retrievers</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A2.F10.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="201" id="A2.F10.sf2.g1" src="x39.png" width="201"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A2.F10.sf2.2.1.1" style="font-size:80%;">(b)</span> </span><span class="ltx_text" id="A2.F10.sf2.3.2" style="font-size:80%;">Gemma2-9B-Chat</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A2.F10.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="201" id="A2.F10.sf3.g1" src="x40.png" width="201"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A2.F10.sf3.2.1.1" style="font-size:80%;">(c)</span> </span><span class="ltx_text" id="A2.F10.sf3.3.2" style="font-size:80%;">Mistral-12B-Instruct</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A2.F10.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="201" id="A2.F10.sf4.g1" src="x41.png" width="201"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A2.F10.sf4.2.1.1" style="font-size:80%;">(d)</span> </span><span class="ltx_text" id="A2.F10.sf4.3.2" style="font-size:80%;">Gemini-1.5-Pro</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Evaluating the impact of hard negatives on long-context LLMs. (a) The retriever performance on PopQA dataset: e5 &gt; contriever &gt; BM25. (b)(c)(d) For each query, a single golden passage (containing the correct answer) is combined with varying numbers of hard negative passages retrieved by different methods (e5, Contriever, BM25, and random sampling). The LLMs are then tasked with answering the query based on this context. This setup allows us to assess the robustness of LLMs to hard negatives and the influence of retriever strength on their impact.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A2.SS2.p1">
<p class="ltx_p" id="A2.SS2.p1.1"><span class="ltx_text ltx_font_bold" id="A2.SS2.p1.1.1">Observations.</span> Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A2.F10" title="Figure 10 ‣ B.2 The importance of hard negatives for long-context LLM evaluation ‣ Appendix B Long context LLMs in RAG analysis on other datasets ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">10</span></a> shows the following observations similar to that in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S3.SS3" title="3.3 The importance of hard negatives for long-context LLM evaluation ‣ 3 Challenges of Long context LLMs in RAG ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">3.3</span></a>:
(1) Sensitivity to hard negatives: Across all LLMs, increasing the number of hard negative passages generally results in a decline in RAG answer accuracy.
(2) Retriever strength and hard negative difficulty: The strength of the retriever is directly correlated with the difficulty of the retrieved hard negatives. LLMs struggle more with hard negatives generated by stronger retrievers (<span class="ltx_text ltx_font_italic" id="A2.SS2.p1.1.2">e.g.</span>, e5) compared to those produced by weaker retrievers (<span class="ltx_text ltx_font_italic" id="A2.SS2.p1.1.3">e.g.</span>, BM25) or through random sampling.
(3) Distinguishing random and hard negatives: While all the LLMs demonstrates robustness to random negatives, it remains susceptible to the influence of hard negatives.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_appendix" id="A3" lang="en">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Illustration of Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S3.SS3" title="3.3 The importance of hard negatives for long-context LLM evaluation ‣ 3 Challenges of Long context LLMs in RAG ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">3.3</span></a>: Hard negative study</h2>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg1.2.1.1">Algorithm 1</span> </span> Data Construction for Hard Negative Study</figcaption>
<div class="ltx_listing ltx_listing" id="alg1.3">
<div class="ltx_listingline" id="alg1.l0">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l0.1.1.1" style="font-size:80%;">0:</span></span>  Query <math alttext="q" class="ltx_Math" display="inline" id="alg1.l0.m1.1"><semantics id="alg1.l0.m1.1a"><mi id="alg1.l0.m1.1.1" xref="alg1.l0.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="alg1.l0.m1.1b"><ci id="alg1.l0.m1.1.1.cmml" xref="alg1.l0.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="alg1.l0.m1.1d">italic_q</annotation></semantics></math>, instruction <math alttext="I" class="ltx_Math" display="inline" id="alg1.l0.m2.1"><semantics id="alg1.l0.m2.1a"><mi id="alg1.l0.m2.1.1" xref="alg1.l0.m2.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="alg1.l0.m2.1b"><ci id="alg1.l0.m2.1.1.cmml" xref="alg1.l0.m2.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0.m2.1c">I</annotation><annotation encoding="application/x-llamapun" id="alg1.l0.m2.1d">italic_I</annotation></semantics></math>, golden passage <math alttext="d_{\text{gold}}" class="ltx_Math" display="inline" id="alg1.l0.m3.1"><semantics id="alg1.l0.m3.1a"><msub id="alg1.l0.m3.1.1" xref="alg1.l0.m3.1.1.cmml"><mi id="alg1.l0.m3.1.1.2" xref="alg1.l0.m3.1.1.2.cmml">d</mi><mtext id="alg1.l0.m3.1.1.3" xref="alg1.l0.m3.1.1.3a.cmml">gold</mtext></msub><annotation-xml encoding="MathML-Content" id="alg1.l0.m3.1b"><apply id="alg1.l0.m3.1.1.cmml" xref="alg1.l0.m3.1.1"><csymbol cd="ambiguous" id="alg1.l0.m3.1.1.1.cmml" xref="alg1.l0.m3.1.1">subscript</csymbol><ci id="alg1.l0.m3.1.1.2.cmml" xref="alg1.l0.m3.1.1.2">𝑑</ci><ci id="alg1.l0.m3.1.1.3a.cmml" xref="alg1.l0.m3.1.1.3"><mtext id="alg1.l0.m3.1.1.3.cmml" mathsize="70%" xref="alg1.l0.m3.1.1.3">gold</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0.m3.1c">d_{\text{gold}}</annotation><annotation encoding="application/x-llamapun" id="alg1.l0.m3.1d">italic_d start_POSTSUBSCRIPT gold end_POSTSUBSCRIPT</annotation></semantics></math>, golden answer <math alttext="a" class="ltx_Math" display="inline" id="alg1.l0.m4.1"><semantics id="alg1.l0.m4.1a"><mi id="alg1.l0.m4.1.1" xref="alg1.l0.m4.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="alg1.l0.m4.1b"><ci id="alg1.l0.m4.1.1.cmml" xref="alg1.l0.m4.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0.m4.1c">a</annotation><annotation encoding="application/x-llamapun" id="alg1.l0.m4.1d">italic_a</annotation></semantics></math>, retrieved passages <math alttext="D=[d_{1},d_{2},\dots,d_{N}]" class="ltx_Math" display="inline" id="alg1.l0.m5.4"><semantics id="alg1.l0.m5.4a"><mrow id="alg1.l0.m5.4.4" xref="alg1.l0.m5.4.4.cmml"><mi id="alg1.l0.m5.4.4.5" xref="alg1.l0.m5.4.4.5.cmml">D</mi><mo id="alg1.l0.m5.4.4.4" xref="alg1.l0.m5.4.4.4.cmml">=</mo><mrow id="alg1.l0.m5.4.4.3.3" xref="alg1.l0.m5.4.4.3.4.cmml"><mo id="alg1.l0.m5.4.4.3.3.4" stretchy="false" xref="alg1.l0.m5.4.4.3.4.cmml">[</mo><msub id="alg1.l0.m5.2.2.1.1.1" xref="alg1.l0.m5.2.2.1.1.1.cmml"><mi id="alg1.l0.m5.2.2.1.1.1.2" xref="alg1.l0.m5.2.2.1.1.1.2.cmml">d</mi><mn id="alg1.l0.m5.2.2.1.1.1.3" xref="alg1.l0.m5.2.2.1.1.1.3.cmml">1</mn></msub><mo id="alg1.l0.m5.4.4.3.3.5" xref="alg1.l0.m5.4.4.3.4.cmml">,</mo><msub id="alg1.l0.m5.3.3.2.2.2" xref="alg1.l0.m5.3.3.2.2.2.cmml"><mi id="alg1.l0.m5.3.3.2.2.2.2" xref="alg1.l0.m5.3.3.2.2.2.2.cmml">d</mi><mn id="alg1.l0.m5.3.3.2.2.2.3" xref="alg1.l0.m5.3.3.2.2.2.3.cmml">2</mn></msub><mo id="alg1.l0.m5.4.4.3.3.6" xref="alg1.l0.m5.4.4.3.4.cmml">,</mo><mi id="alg1.l0.m5.1.1" mathvariant="normal" xref="alg1.l0.m5.1.1.cmml">…</mi><mo id="alg1.l0.m5.4.4.3.3.7" xref="alg1.l0.m5.4.4.3.4.cmml">,</mo><msub id="alg1.l0.m5.4.4.3.3.3" xref="alg1.l0.m5.4.4.3.3.3.cmml"><mi id="alg1.l0.m5.4.4.3.3.3.2" xref="alg1.l0.m5.4.4.3.3.3.2.cmml">d</mi><mi id="alg1.l0.m5.4.4.3.3.3.3" xref="alg1.l0.m5.4.4.3.3.3.3.cmml">N</mi></msub><mo id="alg1.l0.m5.4.4.3.3.8" stretchy="false" xref="alg1.l0.m5.4.4.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l0.m5.4b"><apply id="alg1.l0.m5.4.4.cmml" xref="alg1.l0.m5.4.4"><eq id="alg1.l0.m5.4.4.4.cmml" xref="alg1.l0.m5.4.4.4"></eq><ci id="alg1.l0.m5.4.4.5.cmml" xref="alg1.l0.m5.4.4.5">𝐷</ci><list id="alg1.l0.m5.4.4.3.4.cmml" xref="alg1.l0.m5.4.4.3.3"><apply id="alg1.l0.m5.2.2.1.1.1.cmml" xref="alg1.l0.m5.2.2.1.1.1"><csymbol cd="ambiguous" id="alg1.l0.m5.2.2.1.1.1.1.cmml" xref="alg1.l0.m5.2.2.1.1.1">subscript</csymbol><ci id="alg1.l0.m5.2.2.1.1.1.2.cmml" xref="alg1.l0.m5.2.2.1.1.1.2">𝑑</ci><cn id="alg1.l0.m5.2.2.1.1.1.3.cmml" type="integer" xref="alg1.l0.m5.2.2.1.1.1.3">1</cn></apply><apply id="alg1.l0.m5.3.3.2.2.2.cmml" xref="alg1.l0.m5.3.3.2.2.2"><csymbol cd="ambiguous" id="alg1.l0.m5.3.3.2.2.2.1.cmml" xref="alg1.l0.m5.3.3.2.2.2">subscript</csymbol><ci id="alg1.l0.m5.3.3.2.2.2.2.cmml" xref="alg1.l0.m5.3.3.2.2.2.2">𝑑</ci><cn id="alg1.l0.m5.3.3.2.2.2.3.cmml" type="integer" xref="alg1.l0.m5.3.3.2.2.2.3">2</cn></apply><ci id="alg1.l0.m5.1.1.cmml" xref="alg1.l0.m5.1.1">…</ci><apply id="alg1.l0.m5.4.4.3.3.3.cmml" xref="alg1.l0.m5.4.4.3.3.3"><csymbol cd="ambiguous" id="alg1.l0.m5.4.4.3.3.3.1.cmml" xref="alg1.l0.m5.4.4.3.3.3">subscript</csymbol><ci id="alg1.l0.m5.4.4.3.3.3.2.cmml" xref="alg1.l0.m5.4.4.3.3.3.2">𝑑</ci><ci id="alg1.l0.m5.4.4.3.3.3.3.cmml" xref="alg1.l0.m5.4.4.3.3.3.3">𝑁</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0.m5.4c">D=[d_{1},d_{2},\dots,d_{N}]</annotation><annotation encoding="application/x-llamapun" id="alg1.l0.m5.4d">italic_D = [ italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_d start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT ]</annotation></semantics></math> with decreasing retriever relevance scores, desired number of passages <math alttext="K" class="ltx_Math" display="inline" id="alg1.l0.m6.1"><semantics id="alg1.l0.m6.1a"><mi id="alg1.l0.m6.1.1" xref="alg1.l0.m6.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="alg1.l0.m6.1b"><ci id="alg1.l0.m6.1.1.cmml" xref="alg1.l0.m6.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0.m6.1c">K</annotation><annotation encoding="application/x-llamapun" id="alg1.l0.m6.1d">italic_K</annotation></semantics></math> (<math alttext="K\ll N" class="ltx_Math" display="inline" id="alg1.l0.m7.1"><semantics id="alg1.l0.m7.1a"><mrow id="alg1.l0.m7.1.1" xref="alg1.l0.m7.1.1.cmml"><mi id="alg1.l0.m7.1.1.2" xref="alg1.l0.m7.1.1.2.cmml">K</mi><mo id="alg1.l0.m7.1.1.1" xref="alg1.l0.m7.1.1.1.cmml">≪</mo><mi id="alg1.l0.m7.1.1.3" xref="alg1.l0.m7.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l0.m7.1b"><apply id="alg1.l0.m7.1.1.cmml" xref="alg1.l0.m7.1.1"><csymbol cd="latexml" id="alg1.l0.m7.1.1.1.cmml" xref="alg1.l0.m7.1.1.1">much-less-than</csymbol><ci id="alg1.l0.m7.1.1.2.cmml" xref="alg1.l0.m7.1.1.2">𝐾</ci><ci id="alg1.l0.m7.1.1.3.cmml" xref="alg1.l0.m7.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0.m7.1c">K\ll N</annotation><annotation encoding="application/x-llamapun" id="alg1.l0.m7.1d">italic_K ≪ italic_N</annotation></semantics></math>).

</div>
<div class="ltx_listingline" id="alg1.l0a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l0a.1.1.1" style="font-size:80%;">0:</span></span>  Input sequence <math alttext="S" class="ltx_Math" display="inline" id="alg1.l0a.m1.1"><semantics id="alg1.l0a.m1.1a"><mi id="alg1.l0a.m1.1.1" xref="alg1.l0a.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="alg1.l0a.m1.1b"><ci id="alg1.l0a.m1.1.1.cmml" xref="alg1.l0a.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l0a.m1.1c">S</annotation><annotation encoding="application/x-llamapun" id="alg1.l0a.m1.1d">italic_S</annotation></semantics></math>.

</div>
<div class="ltx_listingline" id="alg1.l1">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l1.1.1.1" style="font-size:80%;">1:</span></span>  Initialize list <math alttext="S\leftarrow[d_{\text{gold}}]" class="ltx_Math" display="inline" id="alg1.l1.m1.1"><semantics id="alg1.l1.m1.1a"><mrow id="alg1.l1.m1.1.1" xref="alg1.l1.m1.1.1.cmml"><mi id="alg1.l1.m1.1.1.3" xref="alg1.l1.m1.1.1.3.cmml">S</mi><mo id="alg1.l1.m1.1.1.2" stretchy="false" xref="alg1.l1.m1.1.1.2.cmml">←</mo><mrow id="alg1.l1.m1.1.1.1.1" xref="alg1.l1.m1.1.1.1.2.cmml"><mo id="alg1.l1.m1.1.1.1.1.2" stretchy="false" xref="alg1.l1.m1.1.1.1.2.1.cmml">[</mo><msub id="alg1.l1.m1.1.1.1.1.1" xref="alg1.l1.m1.1.1.1.1.1.cmml"><mi id="alg1.l1.m1.1.1.1.1.1.2" xref="alg1.l1.m1.1.1.1.1.1.2.cmml">d</mi><mtext id="alg1.l1.m1.1.1.1.1.1.3" xref="alg1.l1.m1.1.1.1.1.1.3a.cmml">gold</mtext></msub><mo id="alg1.l1.m1.1.1.1.1.3" stretchy="false" xref="alg1.l1.m1.1.1.1.2.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.l1.m1.1b"><apply id="alg1.l1.m1.1.1.cmml" xref="alg1.l1.m1.1.1"><ci id="alg1.l1.m1.1.1.2.cmml" xref="alg1.l1.m1.1.1.2">←</ci><ci id="alg1.l1.m1.1.1.3.cmml" xref="alg1.l1.m1.1.1.3">𝑆</ci><apply id="alg1.l1.m1.1.1.1.2.cmml" xref="alg1.l1.m1.1.1.1.1"><csymbol cd="latexml" id="alg1.l1.m1.1.1.1.2.1.cmml" xref="alg1.l1.m1.1.1.1.1.2">delimited-[]</csymbol><apply id="alg1.l1.m1.1.1.1.1.1.cmml" xref="alg1.l1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.l1.m1.1.1.1.1.1.1.cmml" xref="alg1.l1.m1.1.1.1.1.1">subscript</csymbol><ci id="alg1.l1.m1.1.1.1.1.1.2.cmml" xref="alg1.l1.m1.1.1.1.1.1.2">𝑑</ci><ci id="alg1.l1.m1.1.1.1.1.1.3a.cmml" xref="alg1.l1.m1.1.1.1.1.1.3"><mtext id="alg1.l1.m1.1.1.1.1.1.3.cmml" mathsize="70%" xref="alg1.l1.m1.1.1.1.1.1.3">gold</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l1.m1.1c">S\leftarrow[d_{\text{gold}}]</annotation><annotation encoding="application/x-llamapun" id="alg1.l1.m1.1d">italic_S ← [ italic_d start_POSTSUBSCRIPT gold end_POSTSUBSCRIPT ]</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l2">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l2.1.1.1" style="font-size:80%;">2:</span></span>  <span class="ltx_text ltx_font_bold" id="alg1.l2.2">for</span> each passage <math alttext="d_{i}" class="ltx_Math" display="inline" id="alg1.l2.m1.1"><semantics id="alg1.l2.m1.1a"><msub id="alg1.l2.m1.1.1" xref="alg1.l2.m1.1.1.cmml"><mi id="alg1.l2.m1.1.1.2" xref="alg1.l2.m1.1.1.2.cmml">d</mi><mi id="alg1.l2.m1.1.1.3" xref="alg1.l2.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l2.m1.1b"><apply id="alg1.l2.m1.1.1.cmml" xref="alg1.l2.m1.1.1"><csymbol cd="ambiguous" id="alg1.l2.m1.1.1.1.cmml" xref="alg1.l2.m1.1.1">subscript</csymbol><ci id="alg1.l2.m1.1.1.2.cmml" xref="alg1.l2.m1.1.1.2">𝑑</ci><ci id="alg1.l2.m1.1.1.3.cmml" xref="alg1.l2.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m1.1c">d_{i}</annotation><annotation encoding="application/x-llamapun" id="alg1.l2.m1.1d">italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> in <math alttext="D" class="ltx_Math" display="inline" id="alg1.l2.m2.1"><semantics id="alg1.l2.m2.1a"><mi id="alg1.l2.m2.1.1" xref="alg1.l2.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="alg1.l2.m2.1b"><ci id="alg1.l2.m2.1.1.cmml" xref="alg1.l2.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l2.m2.1c">D</annotation><annotation encoding="application/x-llamapun" id="alg1.l2.m2.1d">italic_D</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg1.l2.3">do</span>
</div>
<div class="ltx_listingline" id="alg1.l3">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l3.1.1.1" style="font-size:80%;">3:</span></span>     <span class="ltx_text ltx_font_bold" id="alg1.l3.2">if</span> <math alttext="d_{i}\neq d_{\text{gold}}" class="ltx_Math" display="inline" id="alg1.l3.m1.1"><semantics id="alg1.l3.m1.1a"><mrow id="alg1.l3.m1.1.1" xref="alg1.l3.m1.1.1.cmml"><msub id="alg1.l3.m1.1.1.2" xref="alg1.l3.m1.1.1.2.cmml"><mi id="alg1.l3.m1.1.1.2.2" xref="alg1.l3.m1.1.1.2.2.cmml">d</mi><mi id="alg1.l3.m1.1.1.2.3" xref="alg1.l3.m1.1.1.2.3.cmml">i</mi></msub><mo id="alg1.l3.m1.1.1.1" xref="alg1.l3.m1.1.1.1.cmml">≠</mo><msub id="alg1.l3.m1.1.1.3" xref="alg1.l3.m1.1.1.3.cmml"><mi id="alg1.l3.m1.1.1.3.2" xref="alg1.l3.m1.1.1.3.2.cmml">d</mi><mtext id="alg1.l3.m1.1.1.3.3" xref="alg1.l3.m1.1.1.3.3a.cmml">gold</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="alg1.l3.m1.1b"><apply id="alg1.l3.m1.1.1.cmml" xref="alg1.l3.m1.1.1"><neq id="alg1.l3.m1.1.1.1.cmml" xref="alg1.l3.m1.1.1.1"></neq><apply id="alg1.l3.m1.1.1.2.cmml" xref="alg1.l3.m1.1.1.2"><csymbol cd="ambiguous" id="alg1.l3.m1.1.1.2.1.cmml" xref="alg1.l3.m1.1.1.2">subscript</csymbol><ci id="alg1.l3.m1.1.1.2.2.cmml" xref="alg1.l3.m1.1.1.2.2">𝑑</ci><ci id="alg1.l3.m1.1.1.2.3.cmml" xref="alg1.l3.m1.1.1.2.3">𝑖</ci></apply><apply id="alg1.l3.m1.1.1.3.cmml" xref="alg1.l3.m1.1.1.3"><csymbol cd="ambiguous" id="alg1.l3.m1.1.1.3.1.cmml" xref="alg1.l3.m1.1.1.3">subscript</csymbol><ci id="alg1.l3.m1.1.1.3.2.cmml" xref="alg1.l3.m1.1.1.3.2">𝑑</ci><ci id="alg1.l3.m1.1.1.3.3a.cmml" xref="alg1.l3.m1.1.1.3.3"><mtext id="alg1.l3.m1.1.1.3.3.cmml" mathsize="70%" xref="alg1.l3.m1.1.1.3.3">gold</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m1.1c">d_{i}\neq d_{\text{gold}}</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m1.1d">italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ≠ italic_d start_POSTSUBSCRIPT gold end_POSTSUBSCRIPT</annotation></semantics></math>  and <math alttext="a" class="ltx_Math" display="inline" id="alg1.l3.m2.1"><semantics id="alg1.l3.m2.1a"><mi id="alg1.l3.m2.1.1" xref="alg1.l3.m2.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="alg1.l3.m2.1b"><ci id="alg1.l3.m2.1.1.cmml" xref="alg1.l3.m2.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m2.1c">a</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m2.1d">italic_a</annotation></semantics></math> not in <math alttext="d_{i}" class="ltx_Math" display="inline" id="alg1.l3.m3.1"><semantics id="alg1.l3.m3.1a"><msub id="alg1.l3.m3.1.1" xref="alg1.l3.m3.1.1.cmml"><mi id="alg1.l3.m3.1.1.2" xref="alg1.l3.m3.1.1.2.cmml">d</mi><mi id="alg1.l3.m3.1.1.3" xref="alg1.l3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l3.m3.1b"><apply id="alg1.l3.m3.1.1.cmml" xref="alg1.l3.m3.1.1"><csymbol cd="ambiguous" id="alg1.l3.m3.1.1.1.cmml" xref="alg1.l3.m3.1.1">subscript</csymbol><ci id="alg1.l3.m3.1.1.2.cmml" xref="alg1.l3.m3.1.1.2">𝑑</ci><ci id="alg1.l3.m3.1.1.3.cmml" xref="alg1.l3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l3.m3.1c">d_{i}</annotation><annotation encoding="application/x-llamapun" id="alg1.l3.m3.1d">italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg1.l3.3">then</span>
</div>
<div class="ltx_listingline" id="alg1.l4">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l4.1.1.1" style="font-size:80%;">4:</span></span>        Append <math alttext="d_{i}" class="ltx_Math" display="inline" id="alg1.l4.m1.1"><semantics id="alg1.l4.m1.1a"><msub id="alg1.l4.m1.1.1" xref="alg1.l4.m1.1.1.cmml"><mi id="alg1.l4.m1.1.1.2" xref="alg1.l4.m1.1.1.2.cmml">d</mi><mi id="alg1.l4.m1.1.1.3" xref="alg1.l4.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.l4.m1.1b"><apply id="alg1.l4.m1.1.1.cmml" xref="alg1.l4.m1.1.1"><csymbol cd="ambiguous" id="alg1.l4.m1.1.1.1.cmml" xref="alg1.l4.m1.1.1">subscript</csymbol><ci id="alg1.l4.m1.1.1.2.cmml" xref="alg1.l4.m1.1.1.2">𝑑</ci><ci id="alg1.l4.m1.1.1.3.cmml" xref="alg1.l4.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m1.1c">d_{i}</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m1.1d">italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> to <math alttext="S" class="ltx_Math" display="inline" id="alg1.l4.m2.1"><semantics id="alg1.l4.m2.1a"><mi id="alg1.l4.m2.1.1" xref="alg1.l4.m2.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="alg1.l4.m2.1b"><ci id="alg1.l4.m2.1.1.cmml" xref="alg1.l4.m2.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l4.m2.1c">S</annotation><annotation encoding="application/x-llamapun" id="alg1.l4.m2.1d">italic_S</annotation></semantics></math>
</div>
<div class="ltx_listingline" id="alg1.l5">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l5.1.1.1" style="font-size:80%;">5:</span></span>     <span class="ltx_text ltx_font_bold" id="alg1.l5.2">end</span> <span class="ltx_text ltx_font_bold" id="alg1.l5.3">if</span>
</div>
<div class="ltx_listingline" id="alg1.l6">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l6.1.1.1" style="font-size:80%;">6:</span></span>     <span class="ltx_text ltx_font_bold" id="alg1.l6.2">if</span> <math alttext="|S|=K" class="ltx_Math" display="inline" id="alg1.l6.m1.1"><semantics id="alg1.l6.m1.1a"><mrow id="alg1.l6.m1.1.2" xref="alg1.l6.m1.1.2.cmml"><mrow id="alg1.l6.m1.1.2.2.2" xref="alg1.l6.m1.1.2.2.1.cmml"><mo id="alg1.l6.m1.1.2.2.2.1" stretchy="false" xref="alg1.l6.m1.1.2.2.1.1.cmml">|</mo><mi id="alg1.l6.m1.1.1" xref="alg1.l6.m1.1.1.cmml">S</mi><mo id="alg1.l6.m1.1.2.2.2.2" stretchy="false" xref="alg1.l6.m1.1.2.2.1.1.cmml">|</mo></mrow><mo id="alg1.l6.m1.1.2.1" xref="alg1.l6.m1.1.2.1.cmml">=</mo><mi id="alg1.l6.m1.1.2.3" xref="alg1.l6.m1.1.2.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.l6.m1.1b"><apply id="alg1.l6.m1.1.2.cmml" xref="alg1.l6.m1.1.2"><eq id="alg1.l6.m1.1.2.1.cmml" xref="alg1.l6.m1.1.2.1"></eq><apply id="alg1.l6.m1.1.2.2.1.cmml" xref="alg1.l6.m1.1.2.2.2"><abs id="alg1.l6.m1.1.2.2.1.1.cmml" xref="alg1.l6.m1.1.2.2.2.1"></abs><ci id="alg1.l6.m1.1.1.cmml" xref="alg1.l6.m1.1.1">𝑆</ci></apply><ci id="alg1.l6.m1.1.2.3.cmml" xref="alg1.l6.m1.1.2.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.l6.m1.1c">|S|=K</annotation><annotation encoding="application/x-llamapun" id="alg1.l6.m1.1d">| italic_S | = italic_K</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg1.l6.3">then</span>
</div>
<div class="ltx_listingline" id="alg1.l7">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l7.1.1.1" style="font-size:80%;">7:</span></span>        <span class="ltx_text ltx_font_bold" id="alg1.l7.2">break</span>
</div>
<div class="ltx_listingline" id="alg1.l8">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l8.1.1.1" style="font-size:80%;">8:</span></span>     <span class="ltx_text ltx_font_bold" id="alg1.l8.2">end</span> <span class="ltx_text ltx_font_bold" id="alg1.l8.3">if</span>
</div>
<div class="ltx_listingline" id="alg1.l9">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l9.1.1.1" style="font-size:80%;">9:</span></span>  <span class="ltx_text ltx_font_bold" id="alg1.l9.2">end</span> <span class="ltx_text ltx_font_bold" id="alg1.l9.3">for</span>
</div>
<div class="ltx_listingline" id="alg1.l10">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l10.1.1.1" style="font-size:80%;">10:</span></span>  Randomly shuffle <math alttext="S" class="ltx_Math" display="inline" id="alg1.l10.m1.1"><semantics id="alg1.l10.m1.1a"><mi id="alg1.l10.m1.1.1" xref="alg1.l10.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="alg1.l10.m1.1b"><ci id="alg1.l10.m1.1.1.cmml" xref="alg1.l10.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.l10.m1.1c">S</annotation><annotation encoding="application/x-llamapun" id="alg1.l10.m1.1d">italic_S</annotation></semantics></math>.

</div>
<div class="ltx_listingline" id="alg1.l11">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l11.1.1.1" style="font-size:80%;">11:</span></span>  Construct input sequence <math alttext="[I,S[1],S[2],\dots,S[K],q]" class="ltx_Math" display="inline" id="alg1.l11.m1.9"><semantics id="alg1.l11.m1.9a"><mrow id="alg1.l11.m1.9.9.3" xref="alg1.l11.m1.9.9.4.cmml"><mo id="alg1.l11.m1.9.9.3.4" stretchy="false" xref="alg1.l11.m1.9.9.4.cmml">[</mo><mi id="alg1.l11.m1.4.4" xref="alg1.l11.m1.4.4.cmml">I</mi><mo id="alg1.l11.m1.9.9.3.5" xref="alg1.l11.m1.9.9.4.cmml">,</mo><mrow id="alg1.l11.m1.7.7.1.1" xref="alg1.l11.m1.7.7.1.1.cmml"><mi id="alg1.l11.m1.7.7.1.1.2" xref="alg1.l11.m1.7.7.1.1.2.cmml">S</mi><mo id="alg1.l11.m1.7.7.1.1.1" xref="alg1.l11.m1.7.7.1.1.1.cmml">⁢</mo><mrow id="alg1.l11.m1.7.7.1.1.3.2" xref="alg1.l11.m1.7.7.1.1.3.1.cmml"><mo id="alg1.l11.m1.7.7.1.1.3.2.1" stretchy="false" xref="alg1.l11.m1.7.7.1.1.3.1.1.cmml">[</mo><mn id="alg1.l11.m1.1.1" xref="alg1.l11.m1.1.1.cmml">1</mn><mo id="alg1.l11.m1.7.7.1.1.3.2.2" stretchy="false" xref="alg1.l11.m1.7.7.1.1.3.1.1.cmml">]</mo></mrow></mrow><mo id="alg1.l11.m1.9.9.3.6" xref="alg1.l11.m1.9.9.4.cmml">,</mo><mrow id="alg1.l11.m1.8.8.2.2" xref="alg1.l11.m1.8.8.2.2.cmml"><mi id="alg1.l11.m1.8.8.2.2.2" xref="alg1.l11.m1.8.8.2.2.2.cmml">S</mi><mo id="alg1.l11.m1.8.8.2.2.1" xref="alg1.l11.m1.8.8.2.2.1.cmml">⁢</mo><mrow id="alg1.l11.m1.8.8.2.2.3.2" xref="alg1.l11.m1.8.8.2.2.3.1.cmml"><mo id="alg1.l11.m1.8.8.2.2.3.2.1" stretchy="false" xref="alg1.l11.m1.8.8.2.2.3.1.1.cmml">[</mo><mn id="alg1.l11.m1.2.2" xref="alg1.l11.m1.2.2.cmml">2</mn><mo id="alg1.l11.m1.8.8.2.2.3.2.2" stretchy="false" xref="alg1.l11.m1.8.8.2.2.3.1.1.cmml">]</mo></mrow></mrow><mo id="alg1.l11.m1.9.9.3.7" xref="alg1.l11.m1.9.9.4.cmml">,</mo><mi id="alg1.l11.m1.5.5" mathvariant="normal" xref="alg1.l11.m1.5.5.cmml">…</mi><mo id="alg1.l11.m1.9.9.3.8" xref="alg1.l11.m1.9.9.4.cmml">,</mo><mrow id="alg1.l11.m1.9.9.3.3" xref="alg1.l11.m1.9.9.3.3.cmml"><mi id="alg1.l11.m1.9.9.3.3.2" xref="alg1.l11.m1.9.9.3.3.2.cmml">S</mi><mo id="alg1.l11.m1.9.9.3.3.1" xref="alg1.l11.m1.9.9.3.3.1.cmml">⁢</mo><mrow id="alg1.l11.m1.9.9.3.3.3.2" xref="alg1.l11.m1.9.9.3.3.3.1.cmml"><mo id="alg1.l11.m1.9.9.3.3.3.2.1" stretchy="false" xref="alg1.l11.m1.9.9.3.3.3.1.1.cmml">[</mo><mi id="alg1.l11.m1.3.3" xref="alg1.l11.m1.3.3.cmml">K</mi><mo id="alg1.l11.m1.9.9.3.3.3.2.2" stretchy="false" xref="alg1.l11.m1.9.9.3.3.3.1.1.cmml">]</mo></mrow></mrow><mo id="alg1.l11.m1.9.9.3.9" xref="alg1.l11.m1.9.9.4.cmml">,</mo><mi id="alg1.l11.m1.6.6" xref="alg1.l11.m1.6.6.cmml">q</mi><mo id="alg1.l11.m1.9.9.3.10" stretchy="false" xref="alg1.l11.m1.9.9.4.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.l11.m1.9b"><list id="alg1.l11.m1.9.9.4.cmml" xref="alg1.l11.m1.9.9.3"><ci id="alg1.l11.m1.4.4.cmml" xref="alg1.l11.m1.4.4">𝐼</ci><apply id="alg1.l11.m1.7.7.1.1.cmml" xref="alg1.l11.m1.7.7.1.1"><times id="alg1.l11.m1.7.7.1.1.1.cmml" xref="alg1.l11.m1.7.7.1.1.1"></times><ci id="alg1.l11.m1.7.7.1.1.2.cmml" xref="alg1.l11.m1.7.7.1.1.2">𝑆</ci><apply id="alg1.l11.m1.7.7.1.1.3.1.cmml" xref="alg1.l11.m1.7.7.1.1.3.2"><csymbol cd="latexml" id="alg1.l11.m1.7.7.1.1.3.1.1.cmml" xref="alg1.l11.m1.7.7.1.1.3.2.1">delimited-[]</csymbol><cn id="alg1.l11.m1.1.1.cmml" type="integer" xref="alg1.l11.m1.1.1">1</cn></apply></apply><apply id="alg1.l11.m1.8.8.2.2.cmml" xref="alg1.l11.m1.8.8.2.2"><times id="alg1.l11.m1.8.8.2.2.1.cmml" xref="alg1.l11.m1.8.8.2.2.1"></times><ci id="alg1.l11.m1.8.8.2.2.2.cmml" xref="alg1.l11.m1.8.8.2.2.2">𝑆</ci><apply id="alg1.l11.m1.8.8.2.2.3.1.cmml" xref="alg1.l11.m1.8.8.2.2.3.2"><csymbol cd="latexml" id="alg1.l11.m1.8.8.2.2.3.1.1.cmml" xref="alg1.l11.m1.8.8.2.2.3.2.1">delimited-[]</csymbol><cn id="alg1.l11.m1.2.2.cmml" type="integer" xref="alg1.l11.m1.2.2">2</cn></apply></apply><ci id="alg1.l11.m1.5.5.cmml" xref="alg1.l11.m1.5.5">…</ci><apply id="alg1.l11.m1.9.9.3.3.cmml" xref="alg1.l11.m1.9.9.3.3"><times id="alg1.l11.m1.9.9.3.3.1.cmml" xref="alg1.l11.m1.9.9.3.3.1"></times><ci id="alg1.l11.m1.9.9.3.3.2.cmml" xref="alg1.l11.m1.9.9.3.3.2">𝑆</ci><apply id="alg1.l11.m1.9.9.3.3.3.1.cmml" xref="alg1.l11.m1.9.9.3.3.3.2"><csymbol cd="latexml" id="alg1.l11.m1.9.9.3.3.3.1.1.cmml" xref="alg1.l11.m1.9.9.3.3.3.2.1">delimited-[]</csymbol><ci id="alg1.l11.m1.3.3.cmml" xref="alg1.l11.m1.3.3">𝐾</ci></apply></apply><ci id="alg1.l11.m1.6.6.cmml" xref="alg1.l11.m1.6.6">𝑞</ci></list></annotation-xml><annotation encoding="application/x-tex" id="alg1.l11.m1.9c">[I,S[1],S[2],\dots,S[K],q]</annotation><annotation encoding="application/x-llamapun" id="alg1.l11.m1.9d">[ italic_I , italic_S [ 1 ] , italic_S [ 2 ] , … , italic_S [ italic_K ] , italic_q ]</annotation></semantics></math>.

</div>
<div class="ltx_listingline" id="alg1.l12">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg1.l12.1.1.1" style="font-size:80%;">12:</span></span>  <span class="ltx_text ltx_font_bold" id="alg1.l12.2">return</span>  The input sequence <math alttext="[I,S[1],S[2],\dots,S[K],q]" class="ltx_Math" display="inline" id="alg1.l12.m1.9"><semantics id="alg1.l12.m1.9a"><mrow id="alg1.l12.m1.9.9.3" xref="alg1.l12.m1.9.9.4.cmml"><mo id="alg1.l12.m1.9.9.3.4" stretchy="false" xref="alg1.l12.m1.9.9.4.cmml">[</mo><mi id="alg1.l12.m1.4.4" xref="alg1.l12.m1.4.4.cmml">I</mi><mo id="alg1.l12.m1.9.9.3.5" xref="alg1.l12.m1.9.9.4.cmml">,</mo><mrow id="alg1.l12.m1.7.7.1.1" xref="alg1.l12.m1.7.7.1.1.cmml"><mi id="alg1.l12.m1.7.7.1.1.2" xref="alg1.l12.m1.7.7.1.1.2.cmml">S</mi><mo id="alg1.l12.m1.7.7.1.1.1" xref="alg1.l12.m1.7.7.1.1.1.cmml">⁢</mo><mrow id="alg1.l12.m1.7.7.1.1.3.2" xref="alg1.l12.m1.7.7.1.1.3.1.cmml"><mo id="alg1.l12.m1.7.7.1.1.3.2.1" stretchy="false" xref="alg1.l12.m1.7.7.1.1.3.1.1.cmml">[</mo><mn id="alg1.l12.m1.1.1" xref="alg1.l12.m1.1.1.cmml">1</mn><mo id="alg1.l12.m1.7.7.1.1.3.2.2" stretchy="false" xref="alg1.l12.m1.7.7.1.1.3.1.1.cmml">]</mo></mrow></mrow><mo id="alg1.l12.m1.9.9.3.6" xref="alg1.l12.m1.9.9.4.cmml">,</mo><mrow id="alg1.l12.m1.8.8.2.2" xref="alg1.l12.m1.8.8.2.2.cmml"><mi id="alg1.l12.m1.8.8.2.2.2" xref="alg1.l12.m1.8.8.2.2.2.cmml">S</mi><mo id="alg1.l12.m1.8.8.2.2.1" xref="alg1.l12.m1.8.8.2.2.1.cmml">⁢</mo><mrow id="alg1.l12.m1.8.8.2.2.3.2" xref="alg1.l12.m1.8.8.2.2.3.1.cmml"><mo id="alg1.l12.m1.8.8.2.2.3.2.1" stretchy="false" xref="alg1.l12.m1.8.8.2.2.3.1.1.cmml">[</mo><mn id="alg1.l12.m1.2.2" xref="alg1.l12.m1.2.2.cmml">2</mn><mo id="alg1.l12.m1.8.8.2.2.3.2.2" stretchy="false" xref="alg1.l12.m1.8.8.2.2.3.1.1.cmml">]</mo></mrow></mrow><mo id="alg1.l12.m1.9.9.3.7" xref="alg1.l12.m1.9.9.4.cmml">,</mo><mi id="alg1.l12.m1.5.5" mathvariant="normal" xref="alg1.l12.m1.5.5.cmml">…</mi><mo id="alg1.l12.m1.9.9.3.8" xref="alg1.l12.m1.9.9.4.cmml">,</mo><mrow id="alg1.l12.m1.9.9.3.3" xref="alg1.l12.m1.9.9.3.3.cmml"><mi id="alg1.l12.m1.9.9.3.3.2" xref="alg1.l12.m1.9.9.3.3.2.cmml">S</mi><mo id="alg1.l12.m1.9.9.3.3.1" xref="alg1.l12.m1.9.9.3.3.1.cmml">⁢</mo><mrow id="alg1.l12.m1.9.9.3.3.3.2" xref="alg1.l12.m1.9.9.3.3.3.1.cmml"><mo id="alg1.l12.m1.9.9.3.3.3.2.1" stretchy="false" xref="alg1.l12.m1.9.9.3.3.3.1.1.cmml">[</mo><mi id="alg1.l12.m1.3.3" xref="alg1.l12.m1.3.3.cmml">K</mi><mo id="alg1.l12.m1.9.9.3.3.3.2.2" stretchy="false" xref="alg1.l12.m1.9.9.3.3.3.1.1.cmml">]</mo></mrow></mrow><mo id="alg1.l12.m1.9.9.3.9" xref="alg1.l12.m1.9.9.4.cmml">,</mo><mi id="alg1.l12.m1.6.6" xref="alg1.l12.m1.6.6.cmml">q</mi><mo id="alg1.l12.m1.9.9.3.10" stretchy="false" xref="alg1.l12.m1.9.9.4.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="alg1.l12.m1.9b"><list id="alg1.l12.m1.9.9.4.cmml" xref="alg1.l12.m1.9.9.3"><ci id="alg1.l12.m1.4.4.cmml" xref="alg1.l12.m1.4.4">𝐼</ci><apply id="alg1.l12.m1.7.7.1.1.cmml" xref="alg1.l12.m1.7.7.1.1"><times id="alg1.l12.m1.7.7.1.1.1.cmml" xref="alg1.l12.m1.7.7.1.1.1"></times><ci id="alg1.l12.m1.7.7.1.1.2.cmml" xref="alg1.l12.m1.7.7.1.1.2">𝑆</ci><apply id="alg1.l12.m1.7.7.1.1.3.1.cmml" xref="alg1.l12.m1.7.7.1.1.3.2"><csymbol cd="latexml" id="alg1.l12.m1.7.7.1.1.3.1.1.cmml" xref="alg1.l12.m1.7.7.1.1.3.2.1">delimited-[]</csymbol><cn id="alg1.l12.m1.1.1.cmml" type="integer" xref="alg1.l12.m1.1.1">1</cn></apply></apply><apply id="alg1.l12.m1.8.8.2.2.cmml" xref="alg1.l12.m1.8.8.2.2"><times id="alg1.l12.m1.8.8.2.2.1.cmml" xref="alg1.l12.m1.8.8.2.2.1"></times><ci id="alg1.l12.m1.8.8.2.2.2.cmml" xref="alg1.l12.m1.8.8.2.2.2">𝑆</ci><apply id="alg1.l12.m1.8.8.2.2.3.1.cmml" xref="alg1.l12.m1.8.8.2.2.3.2"><csymbol cd="latexml" id="alg1.l12.m1.8.8.2.2.3.1.1.cmml" xref="alg1.l12.m1.8.8.2.2.3.2.1">delimited-[]</csymbol><cn id="alg1.l12.m1.2.2.cmml" type="integer" xref="alg1.l12.m1.2.2">2</cn></apply></apply><ci id="alg1.l12.m1.5.5.cmml" xref="alg1.l12.m1.5.5">…</ci><apply id="alg1.l12.m1.9.9.3.3.cmml" xref="alg1.l12.m1.9.9.3.3"><times id="alg1.l12.m1.9.9.3.3.1.cmml" xref="alg1.l12.m1.9.9.3.3.1"></times><ci id="alg1.l12.m1.9.9.3.3.2.cmml" xref="alg1.l12.m1.9.9.3.3.2">𝑆</ci><apply id="alg1.l12.m1.9.9.3.3.3.1.cmml" xref="alg1.l12.m1.9.9.3.3.3.2"><csymbol cd="latexml" id="alg1.l12.m1.9.9.3.3.3.1.1.cmml" xref="alg1.l12.m1.9.9.3.3.3.2.1">delimited-[]</csymbol><ci id="alg1.l12.m1.3.3.cmml" xref="alg1.l12.m1.3.3">𝐾</ci></apply></apply><ci id="alg1.l12.m1.6.6.cmml" xref="alg1.l12.m1.6.6">𝑞</ci></list></annotation-xml><annotation encoding="application/x-tex" id="alg1.l12.m1.9c">[I,S[1],S[2],\dots,S[K],q]</annotation><annotation encoding="application/x-llamapun" id="alg1.l12.m1.9d">[ italic_I , italic_S [ 1 ] , italic_S [ 2 ] , … , italic_S [ italic_K ] , italic_q ]</annotation></semantics></math>.

</div>
</div>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="A4" lang="en">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Hard negatives case study</h2>
<div class="ltx_para" id="A4.p1">
<p class="ltx_p" id="A4.p1.1">In this section, we provide a case study to compare the hard negatives returned by different retrievers.
We classify the negative passages into two types: (1) <span class="ltx_text ltx_font_italic" id="A4.p1.1.1">Related but Irrelevant</span>: passages related to some entities mentioned in the question but not containing the ground truth answer; (2) <span class="ltx_text ltx_font_italic" id="A4.p1.1.2">Not Related</span>: passages not related to the question at all.
Note that <span class="ltx_text ltx_font_italic" id="A4.p1.1.3">Related but Irrelevant</span> passages are harder and more misleading to the LLMs compared with <span class="ltx_text ltx_font_italic" id="A4.p1.1.4">Not Related</span> passages.
We show the top-5 negatives from each retriever for a random sampled question as below.
From the case study, we can find that the negatives retrieved by e5 contain more <span class="ltx_text ltx_font_italic" id="A4.p1.1.5">Related but Irrelevant</span> passages compared with those retrieved by bm25, while those retrieved by bm25 still have more <span class="ltx_text ltx_font_italic" id="A4.p1.1.6">Related but Irrelevant</span> passages than random sampling.
This qualitatively demonstrates that the hardness of the negatives from different retrievers as e5 &gt; bm25 &gt; random.</p>
</div>
<figure class="ltx_table" id="A4.tab1">
<table class="ltx_tabular ltx_align_middle" id="A4.tab1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A4.tab1.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A4.tab1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A4.tab1.1.1.1.1.1">
<span class="ltx_p" id="A4.tab1.1.1.1.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="A4.tab1.1.1.1.1.1.1.1" style="font-size:90%;">Question</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A4.tab1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A4.tab1.1.1.1.2.1">
<span class="ltx_p" id="A4.tab1.1.1.1.2.1.1" style="width:398.3pt;"><span class="ltx_text" id="A4.tab1.1.1.1.2.1.1.1" style="font-size:90%;">The south west wind blows across Nigeria between?</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.tab1.1.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A4.tab1.1.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A4.tab1.1.2.2.1.1">
<span class="ltx_p" id="A4.tab1.1.2.2.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="A4.tab1.1.2.2.1.1.1.1" style="font-size:90%;">Ground Truth</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A4.tab1.1.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A4.tab1.1.2.2.2.1">
<span class="ltx_p" id="A4.tab1.1.2.2.2.1.1" style="width:398.3pt;"><span class="ltx_text" id="A4.tab1.1.2.2.2.1.1.1" style="font-size:90%;">Till September</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.tab1.1.3.3">
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_t" colspan="2" id="A4.tab1.1.3.3.1">
<span class="ltx_text ltx_font_bold" id="A4.tab1.1.3.3.1.1" style="font-size:90%;">Retrieved Hard Negative Passages</span><span class="ltx_text" id="A4.tab1.1.3.3.1.2" style="font-size:90%;"> (high retrieval score but lacking ground truth answer)</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.tab1.1.4.4">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A4.tab1.1.4.4.1">
<span class="ltx_inline-block ltx_align_top" id="A4.tab1.1.4.4.1.1">
<span class="ltx_p" id="A4.tab1.1.4.4.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="A4.tab1.1.4.4.1.1.1.1" style="font-size:90%;">w. e5</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A4.tab1.1.4.4.2">
<span class="ltx_inline-block ltx_align_top" id="A4.tab1.1.4.4.2.1">
<span class="ltx_p" id="A4.tab1.1.4.4.2.1.1" style="width:398.3pt;"><span class="ltx_text ltx_font_bold" id="A4.tab1.1.4.4.2.1.1.1" style="font-size:90%;">Doc 1</span><span class="ltx_text" id="A4.tab1.1.4.4.2.1.1.2" style="font-size:90%;"> (Title: "Geography of Nigeria") … south atlantic ocean, locally known as the south western wind, or by its main name, The Tropical Maritime (MT) airmass. These two major wind systems in Nigeria are known as the trade winds. The tropical maritime airmass (MT) is responsible for Nigeria’s rainy season. This wind (the tropical maritime airmass) invades the country from February in the southern part of Nigeria while it takes longer for the wind to fully cover the whole of the country, reaching the northern part of Nigeria in June. Its invasion is as a result of the northward retreat, … </span><span class="ltx_text ltx_align_left ltx_font_italic ltx_align_center" id="A4.tab1.1.4.4.2.1.1.3" style="font-size:90%;color:#0000FF;">[Related but Irrelevant]</span><span class="ltx_text" id="A4.tab1.1.4.4.2.1.1.4" style="font-size:90%;"> </span>
<br class="ltx_break ltx_align_left ltx_centering"/><span class="ltx_text ltx_align_left ltx_font_bold ltx_align_center" id="A4.tab1.1.4.4.2.1.1.5" style="font-size:90%;">Doc 2</span><span class="ltx_text" id="A4.tab1.1.4.4.2.1.1.6" style="font-size:90%;"> (Title: "Onikwu") … The dry season is accompanied by a dust laden airmass from the Sahara Desert, locally known as Harmattan, or by its main name, The Tropical Continental (CT) airmass, while the rainy season is heavily influenced by an airmass originating from the south Atlantic Ocean, locally known as the south west wind, or by its main name, The Tropical Maritime (MT) airmass. These two major wind systems in Nigeria are known as the trade winds. The region Onikwu/Ndoni is flood prone communities, this is because the inland part of Rivers state consists of tropical rainforest … </span><span class="ltx_text ltx_align_left ltx_font_italic ltx_align_center" id="A4.tab1.1.4.4.2.1.1.7" style="font-size:90%;color:#0000FF;">[Related but Irrelevant]</span><span class="ltx_text" id="A4.tab1.1.4.4.2.1.1.8" style="font-size:90%;"> </span>
<br class="ltx_break ltx_align_left ltx_centering"/><span class="ltx_text ltx_align_left ltx_font_bold ltx_align_center" id="A4.tab1.1.4.4.2.1.1.9" style="font-size:90%;">Doc 3</span><span class="ltx_text" id="A4.tab1.1.4.4.2.1.1.10" style="font-size:90%;"> (Title: "Geography of Nigeria") … northern end is south of the 15 degrees line at about 14 degrees. Nigeria’s location in the wetter part of the easterly waves south of the 15 degree line creates wetter climatic conditions for Nigeria especially during the monsoons. The Tropical Continental Airmass (CT) locally known as the harmattan, is a wind originating from North Africa which crosses the Sahara Desert into west Africa to Nigeria. This airmass dominates Nigeria’s climate during the dry season from December to March. The Tropical continental airmass is dusty and creates a haze within the atmosphere of west Africa and Nigeria when it predominates. … </span><span class="ltx_text ltx_align_left ltx_font_italic ltx_align_center" id="A4.tab1.1.4.4.2.1.1.11" style="font-size:90%;color:#0000FF;">[Related but Irrelevant]</span><span class="ltx_text" id="A4.tab1.1.4.4.2.1.1.12" style="font-size:90%;"> </span>
<br class="ltx_break ltx_align_left ltx_centering"/><span class="ltx_text ltx_align_left ltx_font_bold ltx_align_center" id="A4.tab1.1.4.4.2.1.1.13" style="font-size:90%;">Doc 4</span><span class="ltx_text" id="A4.tab1.1.4.4.2.1.1.14" style="font-size:90%;"> (Title: "Nigeria") … Niger, Chad, Cameroon, and has a coastline of at least s. Nigeria lies between latitudes 4 and 14N, and longitudes 2 and 15E. The highest point in Nigeria is Chappal Waddi at . The main rivers are the Niger and the Benue, which converge and empty into the Niger Delta. This is one of the world’s largest river deltas, and the location of a large area of Central African mangroves. Nigeria has a varied landscape. The far south is defined by its tropical rainforest climate, where annual rainfall is a year. In the southeast stands the … </span><span class="ltx_text ltx_align_left ltx_font_italic ltx_align_center" id="A4.tab1.1.4.4.2.1.1.15" style="font-size:90%;color:#0000FF;">[Related but Irrelevant]</span><span class="ltx_text" id="A4.tab1.1.4.4.2.1.1.16" style="font-size:90%;"> </span>
<br class="ltx_break ltx_align_left ltx_centering"/></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="A4.tab2">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A4.tab2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A4.tab2.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" id="A4.tab2.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A4.tab2.1.1.1.1.1">
<span class="ltx_p" id="A4.tab2.1.1.1.1.1.1" style="width:42.7pt;"></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column" id="A4.tab2.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A4.tab2.1.1.1.2.1">
<span class="ltx_p" id="A4.tab2.1.1.1.2.1.1" style="width:398.3pt;"><span class="ltx_text ltx_font_bold" id="A4.tab2.1.1.1.2.1.1.1" style="font-size:90%;">Doc 5</span><span class="ltx_text" id="A4.tab2.1.1.1.2.1.1.2" style="font-size:90%;"> (Title: "Geography of Nigeria") … Nigeria, has a temperature range of to , and an annual rainfall of about with a single rainfall maxima in September. The single Dry season experienced in this climate, the tropical savanna climate in central Nigeria beginning from December to march, is hot and dry with the Harmattan wind, a continental tropical (CT) airmass laden with dust from the Sahara Desert prevailing throughout this period. With the Intertropical Convergence Zone (ITCZ) swinging northward over West Africa from the Southern Hemisphere in April, heavy showers coming from pre-monsoonal convective clouds mainly in the form of … </span><span class="ltx_text ltx_align_left ltx_font_italic" id="A4.tab2.1.1.1.2.1.1.3" style="font-size:90%;color:#0000FF;">[Related but Irrelevant]</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A4.tab2.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A4.tab2.1.2.1.1">
<span class="ltx_inline-block ltx_align_top" id="A4.tab2.1.2.1.1.1">
<span class="ltx_p" id="A4.tab2.1.2.1.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="A4.tab2.1.2.1.1.1.1.1" style="font-size:90%;">w. bm25</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A4.tab2.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A4.tab2.1.2.1.2.1">
<span class="ltx_p" id="A4.tab2.1.2.1.2.1.1" style="width:398.3pt;"><span class="ltx_text ltx_font_bold" id="A4.tab2.1.2.1.2.1.1.1" style="font-size:90%;">Doc 1</span><span class="ltx_text" id="A4.tab2.1.2.1.2.1.1.2" style="font-size:90%;"> (Title: "Oron people") … Civil War. Oron is found in the flood plain of South Eastern Nigeria, with the land mainly intersected by numerous streams and tributaries flowing into Cross River. The entire coastline stretches from Uya Oron to Udung Uko. Oron is in the tropical region and has a uniformly high temperature all the year round. The two main seasons are the dry which spans between October and April and wet season which starts around May and ends in September. There are also two prevailing winds – the South-West onshore winds which brings heavy rains and the … </span><span class="ltx_text ltx_align_left ltx_font_italic" id="A4.tab2.1.2.1.2.1.1.3" style="font-size:90%;color:#0000FF;">[Not Related]</span><span class="ltx_text" id="A4.tab2.1.2.1.2.1.1.4" style="font-size:90%;"> </span>
<br class="ltx_break ltx_align_left"/><span class="ltx_text ltx_align_left ltx_font_bold" id="A4.tab2.1.2.1.2.1.1.5" style="font-size:90%;">Doc 2</span><span class="ltx_text" id="A4.tab2.1.2.1.2.1.1.6" style="font-size:90%;"> (Title: "South Equatorial Current") … is driven directly by the trade winds which blow from east to west. In the Indian Ocean, the westward-flowing South Equatorial Current is well-developed only south of the equator. Directly on the equator, the winds reverse twice a year due to the monsoons, and so the surface current can be either eastward or westward. South Equatorial Current Ocean current in the Pacific, Atlantic, and Indian Ocean that flows east-to-west between the equator and about 20 degrees south. In the Pacific and Atlantic Oceans, it extends across the equator to about 5 degrees north. Within the southern hemisphere, the South Equatorial … </span><span class="ltx_text ltx_align_left ltx_font_italic" id="A4.tab2.1.2.1.2.1.1.7" style="font-size:90%;color:#0000FF;">[Related but Irrelevant]</span><span class="ltx_text" id="A4.tab2.1.2.1.2.1.1.8" style="font-size:90%;"> </span>
<br class="ltx_break ltx_align_left"/><span class="ltx_text ltx_align_left ltx_font_bold" id="A4.tab2.1.2.1.2.1.1.9" style="font-size:90%;">Doc 3</span><span class="ltx_text" id="A4.tab2.1.2.1.2.1.1.10" style="font-size:90%;"> (Title: "Wind direction") … Wind direction Wind direction is reported by the direction from which it originates. For example, a ""northerly"" wind blows from the north to the south. Wind direction is usually reported in cardinal directions or in azimuth degrees. Wind direction is measured in degrees clockwise from due north. Consequently, a wind blowing from the north has a wind direction of 0; a wind blowing from the east has a wind direction of 90; a wind blowing from the south has a wind direction of 180; and a wind blowing from the west has a wind direction of 270 … </span><span class="ltx_text ltx_align_left ltx_font_italic" id="A4.tab2.1.2.1.2.1.1.11" style="font-size:90%;color:#0000FF;">[Related but Irrelevant]</span><span class="ltx_text" id="A4.tab2.1.2.1.2.1.1.12" style="font-size:90%;"> </span>
<br class="ltx_break ltx_align_left"/><span class="ltx_text ltx_align_left ltx_font_bold" id="A4.tab2.1.2.1.2.1.1.13" style="font-size:90%;">Doc 4</span><span class="ltx_text" id="A4.tab2.1.2.1.2.1.1.14" style="font-size:90%;"> (Title: "Gulf Stream") … this current interacts with the northeastern coast of South America, the current forks into two branches. One passes into the Caribbean Sea, while a second, the Antilles Current, flows north and east of the West Indies. These two branches rejoin north of the Straits of Florida. The trade winds blow westward in the tropics, and the westerlies blow eastward at mid-latitudes. This wind pattern applies a stress to the subtropical ocean surface with negative curl across the north Atlantic Ocean. The resulting Sverdrup transport is equatorward. Because of conservation of potential vorticity caused by the northward-moving winds on the subtropical … </span><span class="ltx_text ltx_align_left ltx_font_italic" id="A4.tab2.1.2.1.2.1.1.15" style="font-size:90%;color:#0000FF;">[Not Related]</span><span class="ltx_text" id="A4.tab2.1.2.1.2.1.1.16" style="font-size:90%;"> </span>
<br class="ltx_break ltx_align_left"/><span class="ltx_text ltx_align_left ltx_font_bold" id="A4.tab2.1.2.1.2.1.1.17" style="font-size:90%;">Doc 5</span><span class="ltx_text" id="A4.tab2.1.2.1.2.1.1.18" style="font-size:90%;"> (Title: "Climate of the United Kingdom") … climate that western parts of the UK experience. The high latitude and proximity to a large ocean to the west means that the United Kingdom experiences strong winds. The prevailing wind is from the south-west, but it may blow from any direction for sustained periods of time. Winds are strongest near westerly facing coasts and exposed headlands. Gales — which are defined as winds with speeds of — are strongly associated with the passage of deep depressions across the country. The Hebrides experience on average 35 days of gale a year (a day where there are gale-force winds) while inland … </span><span class="ltx_text ltx_align_left ltx_font_italic" id="A4.tab2.1.2.1.2.1.1.19" style="font-size:90%;color:#0000FF;">[Not Related]</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A4.tab2.1.3.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A4.tab2.1.3.2.1">
<span class="ltx_inline-block ltx_align_top" id="A4.tab2.1.3.2.1.1">
<span class="ltx_p" id="A4.tab2.1.3.2.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="A4.tab2.1.3.2.1.1.1.1" style="font-size:90%;">w. random sampling</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A4.tab2.1.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="A4.tab2.1.3.2.2.1">
<span class="ltx_p" id="A4.tab2.1.3.2.2.1.1" style="width:398.3pt;"><span class="ltx_text ltx_font_bold" id="A4.tab2.1.3.2.2.1.1.1" style="font-size:90%;">Doc 1</span><span class="ltx_text" id="A4.tab2.1.3.2.2.1.1.2" style="font-size:90%;"> (Title: "Queen of Peace, Bray") … of Bugisi in Tanzania for a number of years. The parish has a very close relationship with St Cronan’s B.N.S., Scoil Chualann and Gaelscoil Uí Chéadaigh. The parish provides the sacraments of Communion and Confirmation to the children in the schools. They also help to raise funds for the twin parish of Bugisi. Queen of Peace, Bray The Queen of Peace is a Catholic church situated at the junction of the Putland Road and the Vevay Road in Bray, Co. Wicklow, Ireland. The present church was built in 1946 by TJ Macken of St Patrick’s Street, Dún Laoghaire, … </span><span class="ltx_text ltx_align_left ltx_font_italic ltx_align_center" id="A4.tab2.1.3.2.2.1.1.3" style="font-size:90%;color:#0000FF;">[Not Related]</span><span class="ltx_text" id="A4.tab2.1.3.2.2.1.1.4" style="font-size:90%;"> </span>
<br class="ltx_break ltx_align_left ltx_centering"/></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="A4.tab3">
<table class="ltx_tabular ltx_align_middle" id="A4.tab3.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A4.tab3.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A4.tab3.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A4.tab3.1.1.1.1.1">
<span class="ltx_p" id="A4.tab3.1.1.1.1.1.1" style="width:42.7pt;"></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A4.tab3.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A4.tab3.1.1.1.2.1">
<span class="ltx_p" id="A4.tab3.1.1.1.2.1.1" style="width:398.3pt;"><span class="ltx_text ltx_font_bold" id="A4.tab3.1.1.1.2.1.1.1" style="font-size:90%;">Doc 2</span><span class="ltx_text" id="A4.tab3.1.1.1.2.1.1.2" style="font-size:90%;"> (Title: "Cordova Congressional Internship Program") … Puerto Rico’s Constitutional Convention from 1951 to 1952. By 2012, over 670 students from colleges and universities in Puerto Rico had enjoyed internships under the program, and the Spring 2009 class included a record 24 members. A private sector committee, recently headed by Univision Puerto Rico president Larry Sands, provides private funds to supplement the 350,000 annual grant provided by the Puerto Rico Legislative Assembly. Under the auspices of TWC, seventeen states have since established similar legislative-funded Congressional internship programs. The Center established in 2008 the McClintock Award to the State Legislator of the Year … </span><span class="ltx_text ltx_align_left ltx_font_italic ltx_align_center" id="A4.tab3.1.1.1.2.1.1.3" style="font-size:90%;color:#0000FF;">[Not Related]</span><span class="ltx_text" id="A4.tab3.1.1.1.2.1.1.4" style="font-size:90%;"> </span>
<br class="ltx_break ltx_align_left ltx_centering"/><span class="ltx_text ltx_align_left ltx_font_bold ltx_align_center" id="A4.tab3.1.1.1.2.1.1.5" style="font-size:90%;">Doc 3</span><span class="ltx_text" id="A4.tab3.1.1.1.2.1.1.6" style="font-size:90%;"> (Title: "V bomber") … Puerto Rico’s Constitutional Convention from 1951 to 1952. By 2012, over 670 students from colleges and universities in Puerto Rico had enjoyed internships under the program, and the Spring 2009 class included a record 24 members. A private sector committee, recently headed by Univision Puerto Rico president Larry Sands, provides private funds to supplement the 350,000 annual grant provided by the Puerto Rico Legislative Assembly. Under the auspices of TWC, seventeen states have since established similar legislative-funded Congressional internship programs. The Center established in 2008 the McClintock Award to the … </span><span class="ltx_text ltx_align_left ltx_font_italic ltx_align_center" id="A4.tab3.1.1.1.2.1.1.7" style="font-size:90%;color:#0000FF;">[Not Related]</span><span class="ltx_text" id="A4.tab3.1.1.1.2.1.1.8" style="font-size:90%;"> </span>
<br class="ltx_break ltx_align_left ltx_centering"/><span class="ltx_text ltx_align_left ltx_font_bold ltx_align_center" id="A4.tab3.1.1.1.2.1.1.9" style="font-size:90%;">Doc 4</span><span class="ltx_text" id="A4.tab3.1.1.1.2.1.1.10" style="font-size:90%;"> (Title: "Defence Materials and Stores Research and Development Establishment") … materials for the Indian Armed Forces. DMSRDE has developed Nuclear Shielding Pad, Boot Anti Mine, Blast Protection Suit, Bullet Proof Jackets, etc.. ""The Defence Material and Stores Research Development Establishment in Kanpur has developed a new NBC suit that would be proved effective against any kind of dangerous weapons or chemicals and protect soldiers from any sort of attack,"" DMSRDE Director Arvind Kumar Saxena was quoted by media-persons. 40,000 pieces of NBC suits costing about Rs 30,000 had been requested by Indian army. ""the further progress on the other two suits are going on."" further … </span><span class="ltx_text ltx_align_left ltx_font_italic ltx_align_center" id="A4.tab3.1.1.1.2.1.1.11" style="font-size:90%;color:#0000FF;">[Not Related]</span><span class="ltx_text" id="A4.tab3.1.1.1.2.1.1.12" style="font-size:90%;"> </span>
<br class="ltx_break ltx_align_left ltx_centering"/><span class="ltx_text ltx_align_left ltx_font_bold ltx_align_center" id="A4.tab3.1.1.1.2.1.1.13" style="font-size:90%;">Doc 5</span><span class="ltx_text" id="A4.tab3.1.1.1.2.1.1.14" style="font-size:90%;"> (Title: "Chess title") … retain the title of Candidate Master, if it was earned according to criteria above). This is in contrast to international titles awarded by FIDE, which are awarded for life. In European countries the term of ""expert"" is not used. Instead, players of that level are called ""Candidate Masters"", although the FIDE Candidate Master title generally requires a higher rating (2200 FIDE). It is possible (and common), however, for players in the United States to have a rating that places them in the ’expert’ category while still retaining the title of ’Life Master’ or ’National Master’ … </span><span class="ltx_text ltx_align_left ltx_font_italic ltx_align_center" id="A4.tab3.1.1.1.2.1.1.15" style="font-size:90%;color:#0000FF;">[Not Related]</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="A5" lang="en">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Retrieval reordering</h2>
<figure class="ltx_float ltx_float_algorithm ltx_framed ltx_framed_top" id="alg2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span class="ltx_text ltx_font_bold" id="alg2.2.1.1">Algorithm 2</span> </span> Retrieval Reordering Algorithm</figcaption>
<div class="ltx_listing ltx_listing" id="alg2.3">
<div class="ltx_listingline" id="alg2.l0">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l0.1.1.1" style="font-size:80%;">0:</span></span>  Query <math alttext="q" class="ltx_Math" display="inline" id="alg2.l0.m1.1"><semantics id="alg2.l0.m1.1a"><mi id="alg2.l0.m1.1.1" xref="alg2.l0.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="alg2.l0.m1.1b"><ci id="alg2.l0.m1.1.1.cmml" xref="alg2.l0.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l0.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="alg2.l0.m1.1d">italic_q</annotation></semantics></math>, instruction <math alttext="I" class="ltx_Math" display="inline" id="alg2.l0.m2.1"><semantics id="alg2.l0.m2.1a"><mi id="alg2.l0.m2.1.1" xref="alg2.l0.m2.1.1.cmml">I</mi><annotation-xml encoding="MathML-Content" id="alg2.l0.m2.1b"><ci id="alg2.l0.m2.1.1.cmml" xref="alg2.l0.m2.1.1">𝐼</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l0.m2.1c">I</annotation><annotation encoding="application/x-llamapun" id="alg2.l0.m2.1d">italic_I</annotation></semantics></math>, retrieved passages <math alttext="D=[d_{1},d_{2},...,d_{k}]" class="ltx_Math" display="inline" id="alg2.l0.m3.4"><semantics id="alg2.l0.m3.4a"><mrow id="alg2.l0.m3.4.4" xref="alg2.l0.m3.4.4.cmml"><mi id="alg2.l0.m3.4.4.5" xref="alg2.l0.m3.4.4.5.cmml">D</mi><mo id="alg2.l0.m3.4.4.4" xref="alg2.l0.m3.4.4.4.cmml">=</mo><mrow id="alg2.l0.m3.4.4.3.3" xref="alg2.l0.m3.4.4.3.4.cmml"><mo id="alg2.l0.m3.4.4.3.3.4" stretchy="false" xref="alg2.l0.m3.4.4.3.4.cmml">[</mo><msub id="alg2.l0.m3.2.2.1.1.1" xref="alg2.l0.m3.2.2.1.1.1.cmml"><mi id="alg2.l0.m3.2.2.1.1.1.2" xref="alg2.l0.m3.2.2.1.1.1.2.cmml">d</mi><mn id="alg2.l0.m3.2.2.1.1.1.3" xref="alg2.l0.m3.2.2.1.1.1.3.cmml">1</mn></msub><mo id="alg2.l0.m3.4.4.3.3.5" xref="alg2.l0.m3.4.4.3.4.cmml">,</mo><msub id="alg2.l0.m3.3.3.2.2.2" xref="alg2.l0.m3.3.3.2.2.2.cmml"><mi id="alg2.l0.m3.3.3.2.2.2.2" xref="alg2.l0.m3.3.3.2.2.2.2.cmml">d</mi><mn id="alg2.l0.m3.3.3.2.2.2.3" xref="alg2.l0.m3.3.3.2.2.2.3.cmml">2</mn></msub><mo id="alg2.l0.m3.4.4.3.3.6" xref="alg2.l0.m3.4.4.3.4.cmml">,</mo><mi id="alg2.l0.m3.1.1" mathvariant="normal" xref="alg2.l0.m3.1.1.cmml">…</mi><mo id="alg2.l0.m3.4.4.3.3.7" xref="alg2.l0.m3.4.4.3.4.cmml">,</mo><msub id="alg2.l0.m3.4.4.3.3.3" xref="alg2.l0.m3.4.4.3.3.3.cmml"><mi id="alg2.l0.m3.4.4.3.3.3.2" xref="alg2.l0.m3.4.4.3.3.3.2.cmml">d</mi><mi id="alg2.l0.m3.4.4.3.3.3.3" xref="alg2.l0.m3.4.4.3.3.3.3.cmml">k</mi></msub><mo id="alg2.l0.m3.4.4.3.3.8" stretchy="false" xref="alg2.l0.m3.4.4.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg2.l0.m3.4b"><apply id="alg2.l0.m3.4.4.cmml" xref="alg2.l0.m3.4.4"><eq id="alg2.l0.m3.4.4.4.cmml" xref="alg2.l0.m3.4.4.4"></eq><ci id="alg2.l0.m3.4.4.5.cmml" xref="alg2.l0.m3.4.4.5">𝐷</ci><list id="alg2.l0.m3.4.4.3.4.cmml" xref="alg2.l0.m3.4.4.3.3"><apply id="alg2.l0.m3.2.2.1.1.1.cmml" xref="alg2.l0.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="alg2.l0.m3.2.2.1.1.1.1.cmml" xref="alg2.l0.m3.2.2.1.1.1">subscript</csymbol><ci id="alg2.l0.m3.2.2.1.1.1.2.cmml" xref="alg2.l0.m3.2.2.1.1.1.2">𝑑</ci><cn id="alg2.l0.m3.2.2.1.1.1.3.cmml" type="integer" xref="alg2.l0.m3.2.2.1.1.1.3">1</cn></apply><apply id="alg2.l0.m3.3.3.2.2.2.cmml" xref="alg2.l0.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="alg2.l0.m3.3.3.2.2.2.1.cmml" xref="alg2.l0.m3.3.3.2.2.2">subscript</csymbol><ci id="alg2.l0.m3.3.3.2.2.2.2.cmml" xref="alg2.l0.m3.3.3.2.2.2.2">𝑑</ci><cn id="alg2.l0.m3.3.3.2.2.2.3.cmml" type="integer" xref="alg2.l0.m3.3.3.2.2.2.3">2</cn></apply><ci id="alg2.l0.m3.1.1.cmml" xref="alg2.l0.m3.1.1">…</ci><apply id="alg2.l0.m3.4.4.3.3.3.cmml" xref="alg2.l0.m3.4.4.3.3.3"><csymbol cd="ambiguous" id="alg2.l0.m3.4.4.3.3.3.1.cmml" xref="alg2.l0.m3.4.4.3.3.3">subscript</csymbol><ci id="alg2.l0.m3.4.4.3.3.3.2.cmml" xref="alg2.l0.m3.4.4.3.3.3.2">𝑑</ci><ci id="alg2.l0.m3.4.4.3.3.3.3.cmml" xref="alg2.l0.m3.4.4.3.3.3.3">𝑘</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l0.m3.4c">D=[d_{1},d_{2},...,d_{k}]</annotation><annotation encoding="application/x-llamapun" id="alg2.l0.m3.4d">italic_D = [ italic_d start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ]</annotation></semantics></math> with decreasing retriever relevance scores.

</div>
<div class="ltx_listingline" id="alg2.l0a">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l0a.1.1.1" style="font-size:80%;">0:</span></span>  Reordered sequence <math alttext="S" class="ltx_Math" display="inline" id="alg2.l0a.m1.1"><semantics id="alg2.l0a.m1.1a"><mi id="alg2.l0a.m1.1.1" xref="alg2.l0a.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="alg2.l0a.m1.1b"><ci id="alg2.l0a.m1.1.1.cmml" xref="alg2.l0a.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l0a.m1.1c">S</annotation><annotation encoding="application/x-llamapun" id="alg2.l0a.m1.1d">italic_S</annotation></semantics></math>.

</div>
<div class="ltx_listingline" id="alg2.l1">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l1.1.1.1" style="font-size:80%;">1:</span></span>  Initialize an empty list <math alttext="S" class="ltx_Math" display="inline" id="alg2.l1.m1.1"><semantics id="alg2.l1.m1.1a"><mi id="alg2.l1.m1.1.1" xref="alg2.l1.m1.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="alg2.l1.m1.1b"><ci id="alg2.l1.m1.1.1.cmml" xref="alg2.l1.m1.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l1.m1.1c">S</annotation><annotation encoding="application/x-llamapun" id="alg2.l1.m1.1d">italic_S</annotation></semantics></math> of length <math alttext="k" class="ltx_Math" display="inline" id="alg2.l1.m2.1"><semantics id="alg2.l1.m2.1a"><mi id="alg2.l1.m2.1.1" xref="alg2.l1.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg2.l1.m2.1b"><ci id="alg2.l1.m2.1.1.cmml" xref="alg2.l1.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l1.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="alg2.l1.m2.1d">italic_k</annotation></semantics></math>.

</div>
<div class="ltx_listingline" id="alg2.l2">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l2.1.1.1" style="font-size:80%;">2:</span></span>  <span class="ltx_text ltx_font_bold" id="alg2.l2.2">for</span> <math alttext="i=1" class="ltx_Math" display="inline" id="alg2.l2.m1.1"><semantics id="alg2.l2.m1.1a"><mrow id="alg2.l2.m1.1.1" xref="alg2.l2.m1.1.1.cmml"><mi id="alg2.l2.m1.1.1.2" xref="alg2.l2.m1.1.1.2.cmml">i</mi><mo id="alg2.l2.m1.1.1.1" xref="alg2.l2.m1.1.1.1.cmml">=</mo><mn id="alg2.l2.m1.1.1.3" xref="alg2.l2.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg2.l2.m1.1b"><apply id="alg2.l2.m1.1.1.cmml" xref="alg2.l2.m1.1.1"><eq id="alg2.l2.m1.1.1.1.cmml" xref="alg2.l2.m1.1.1.1"></eq><ci id="alg2.l2.m1.1.1.2.cmml" xref="alg2.l2.m1.1.1.2">𝑖</ci><cn id="alg2.l2.m1.1.1.3.cmml" type="integer" xref="alg2.l2.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l2.m1.1c">i=1</annotation><annotation encoding="application/x-llamapun" id="alg2.l2.m1.1d">italic_i = 1</annotation></semantics></math> to <math alttext="k" class="ltx_Math" display="inline" id="alg2.l2.m2.1"><semantics id="alg2.l2.m2.1a"><mi id="alg2.l2.m2.1.1" xref="alg2.l2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="alg2.l2.m2.1b"><ci id="alg2.l2.m2.1.1.cmml" xref="alg2.l2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l2.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="alg2.l2.m2.1d">italic_k</annotation></semantics></math> <span class="ltx_text ltx_font_bold" id="alg2.l2.3">do</span>
</div>
<div class="ltx_listingline" id="alg2.l3">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l3.1.1.1" style="font-size:80%;">3:</span></span>     <span class="ltx_text ltx_font_bold" id="alg2.l3.2">if</span> mod(<math alttext="i" class="ltx_Math" display="inline" id="alg2.l3.m1.1"><semantics id="alg2.l3.m1.1a"><mi id="alg2.l3.m1.1.1" xref="alg2.l3.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="alg2.l3.m1.1b"><ci id="alg2.l3.m1.1.1.cmml" xref="alg2.l3.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l3.m1.1c">i</annotation><annotation encoding="application/x-llamapun" id="alg2.l3.m1.1d">italic_i</annotation></semantics></math>, 2) = 1 <span class="ltx_text ltx_font_bold" id="alg2.l3.3">then</span>
</div>
<div class="ltx_listingline" id="alg2.l4">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l4.1.1.1" style="font-size:80%;">4:</span></span>        <math alttext="\textit{Order}(d_{i})\leftarrow\dfrac{i+1}{2}" class="ltx_Math" display="inline" id="alg2.l4.m1.1"><semantics id="alg2.l4.m1.1a"><mrow id="alg2.l4.m1.1.1" xref="alg2.l4.m1.1.1.cmml"><mrow id="alg2.l4.m1.1.1.1" xref="alg2.l4.m1.1.1.1.cmml"><mtext class="ltx_mathvariant_italic" id="alg2.l4.m1.1.1.1.3" xref="alg2.l4.m1.1.1.1.3a.cmml">Order</mtext><mo id="alg2.l4.m1.1.1.1.2" xref="alg2.l4.m1.1.1.1.2.cmml">⁢</mo><mrow id="alg2.l4.m1.1.1.1.1.1" xref="alg2.l4.m1.1.1.1.1.1.1.cmml"><mo id="alg2.l4.m1.1.1.1.1.1.2" stretchy="false" xref="alg2.l4.m1.1.1.1.1.1.1.cmml">(</mo><msub id="alg2.l4.m1.1.1.1.1.1.1" xref="alg2.l4.m1.1.1.1.1.1.1.cmml"><mi id="alg2.l4.m1.1.1.1.1.1.1.2" xref="alg2.l4.m1.1.1.1.1.1.1.2.cmml">d</mi><mi id="alg2.l4.m1.1.1.1.1.1.1.3" xref="alg2.l4.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="alg2.l4.m1.1.1.1.1.1.3" stretchy="false" xref="alg2.l4.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="alg2.l4.m1.1.1.2" stretchy="false" xref="alg2.l4.m1.1.1.2.cmml">←</mo><mstyle displaystyle="true" id="alg2.l4.m1.1.1.3" xref="alg2.l4.m1.1.1.3.cmml"><mfrac id="alg2.l4.m1.1.1.3a" xref="alg2.l4.m1.1.1.3.cmml"><mrow id="alg2.l4.m1.1.1.3.2" xref="alg2.l4.m1.1.1.3.2.cmml"><mi id="alg2.l4.m1.1.1.3.2.2" xref="alg2.l4.m1.1.1.3.2.2.cmml">i</mi><mo id="alg2.l4.m1.1.1.3.2.1" xref="alg2.l4.m1.1.1.3.2.1.cmml">+</mo><mn id="alg2.l4.m1.1.1.3.2.3" xref="alg2.l4.m1.1.1.3.2.3.cmml">1</mn></mrow><mn id="alg2.l4.m1.1.1.3.3" xref="alg2.l4.m1.1.1.3.3.cmml">2</mn></mfrac></mstyle></mrow><annotation-xml encoding="MathML-Content" id="alg2.l4.m1.1b"><apply id="alg2.l4.m1.1.1.cmml" xref="alg2.l4.m1.1.1"><ci id="alg2.l4.m1.1.1.2.cmml" xref="alg2.l4.m1.1.1.2">←</ci><apply id="alg2.l4.m1.1.1.1.cmml" xref="alg2.l4.m1.1.1.1"><times id="alg2.l4.m1.1.1.1.2.cmml" xref="alg2.l4.m1.1.1.1.2"></times><ci id="alg2.l4.m1.1.1.1.3a.cmml" xref="alg2.l4.m1.1.1.1.3"><mtext class="ltx_mathvariant_italic" id="alg2.l4.m1.1.1.1.3.cmml" xref="alg2.l4.m1.1.1.1.3">Order</mtext></ci><apply id="alg2.l4.m1.1.1.1.1.1.1.cmml" xref="alg2.l4.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg2.l4.m1.1.1.1.1.1.1.1.cmml" xref="alg2.l4.m1.1.1.1.1.1">subscript</csymbol><ci id="alg2.l4.m1.1.1.1.1.1.1.2.cmml" xref="alg2.l4.m1.1.1.1.1.1.1.2">𝑑</ci><ci id="alg2.l4.m1.1.1.1.1.1.1.3.cmml" xref="alg2.l4.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="alg2.l4.m1.1.1.3.cmml" xref="alg2.l4.m1.1.1.3"><divide id="alg2.l4.m1.1.1.3.1.cmml" xref="alg2.l4.m1.1.1.3"></divide><apply id="alg2.l4.m1.1.1.3.2.cmml" xref="alg2.l4.m1.1.1.3.2"><plus id="alg2.l4.m1.1.1.3.2.1.cmml" xref="alg2.l4.m1.1.1.3.2.1"></plus><ci id="alg2.l4.m1.1.1.3.2.2.cmml" xref="alg2.l4.m1.1.1.3.2.2">𝑖</ci><cn id="alg2.l4.m1.1.1.3.2.3.cmml" type="integer" xref="alg2.l4.m1.1.1.3.2.3">1</cn></apply><cn id="alg2.l4.m1.1.1.3.3.cmml" type="integer" xref="alg2.l4.m1.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l4.m1.1c">\textit{Order}(d_{i})\leftarrow\dfrac{i+1}{2}</annotation><annotation encoding="application/x-llamapun" id="alg2.l4.m1.1d">Order ( italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ← divide start_ARG italic_i + 1 end_ARG start_ARG 2 end_ARG</annotation></semantics></math> {<math alttext="i" class="ltx_Math" display="inline" id="alg2.l4.m2.1"><semantics id="alg2.l4.m2.1a"><mi id="alg2.l4.m2.1.1" xref="alg2.l4.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="alg2.l4.m2.1b"><ci id="alg2.l4.m2.1.1.cmml" xref="alg2.l4.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l4.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="alg2.l4.m2.1d">italic_i</annotation></semantics></math> is odd}

</div>
<div class="ltx_listingline" id="alg2.l5">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l5.1.1.1" style="font-size:80%;">5:</span></span>     <span class="ltx_text ltx_font_bold" id="alg2.l5.2">else</span>
</div>
<div class="ltx_listingline" id="alg2.l6">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l6.1.1.1" style="font-size:80%;">6:</span></span>        <math alttext="\textit{Order}(d_{i})\leftarrow k+1-\dfrac{i}{2}" class="ltx_Math" display="inline" id="alg2.l6.m1.1"><semantics id="alg2.l6.m1.1a"><mrow id="alg2.l6.m1.1.1" xref="alg2.l6.m1.1.1.cmml"><mrow id="alg2.l6.m1.1.1.1" xref="alg2.l6.m1.1.1.1.cmml"><mtext class="ltx_mathvariant_italic" id="alg2.l6.m1.1.1.1.3" xref="alg2.l6.m1.1.1.1.3a.cmml">Order</mtext><mo id="alg2.l6.m1.1.1.1.2" xref="alg2.l6.m1.1.1.1.2.cmml">⁢</mo><mrow id="alg2.l6.m1.1.1.1.1.1" xref="alg2.l6.m1.1.1.1.1.1.1.cmml"><mo id="alg2.l6.m1.1.1.1.1.1.2" stretchy="false" xref="alg2.l6.m1.1.1.1.1.1.1.cmml">(</mo><msub id="alg2.l6.m1.1.1.1.1.1.1" xref="alg2.l6.m1.1.1.1.1.1.1.cmml"><mi id="alg2.l6.m1.1.1.1.1.1.1.2" xref="alg2.l6.m1.1.1.1.1.1.1.2.cmml">d</mi><mi id="alg2.l6.m1.1.1.1.1.1.1.3" xref="alg2.l6.m1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo id="alg2.l6.m1.1.1.1.1.1.3" stretchy="false" xref="alg2.l6.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="alg2.l6.m1.1.1.2" stretchy="false" xref="alg2.l6.m1.1.1.2.cmml">←</mo><mrow id="alg2.l6.m1.1.1.3" xref="alg2.l6.m1.1.1.3.cmml"><mrow id="alg2.l6.m1.1.1.3.2" xref="alg2.l6.m1.1.1.3.2.cmml"><mi id="alg2.l6.m1.1.1.3.2.2" xref="alg2.l6.m1.1.1.3.2.2.cmml">k</mi><mo id="alg2.l6.m1.1.1.3.2.1" xref="alg2.l6.m1.1.1.3.2.1.cmml">+</mo><mn id="alg2.l6.m1.1.1.3.2.3" xref="alg2.l6.m1.1.1.3.2.3.cmml">1</mn></mrow><mo id="alg2.l6.m1.1.1.3.1" xref="alg2.l6.m1.1.1.3.1.cmml">−</mo><mstyle displaystyle="true" id="alg2.l6.m1.1.1.3.3" xref="alg2.l6.m1.1.1.3.3.cmml"><mfrac id="alg2.l6.m1.1.1.3.3a" xref="alg2.l6.m1.1.1.3.3.cmml"><mi id="alg2.l6.m1.1.1.3.3.2" xref="alg2.l6.m1.1.1.3.3.2.cmml">i</mi><mn id="alg2.l6.m1.1.1.3.3.3" xref="alg2.l6.m1.1.1.3.3.3.cmml">2</mn></mfrac></mstyle></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg2.l6.m1.1b"><apply id="alg2.l6.m1.1.1.cmml" xref="alg2.l6.m1.1.1"><ci id="alg2.l6.m1.1.1.2.cmml" xref="alg2.l6.m1.1.1.2">←</ci><apply id="alg2.l6.m1.1.1.1.cmml" xref="alg2.l6.m1.1.1.1"><times id="alg2.l6.m1.1.1.1.2.cmml" xref="alg2.l6.m1.1.1.1.2"></times><ci id="alg2.l6.m1.1.1.1.3a.cmml" xref="alg2.l6.m1.1.1.1.3"><mtext class="ltx_mathvariant_italic" id="alg2.l6.m1.1.1.1.3.cmml" xref="alg2.l6.m1.1.1.1.3">Order</mtext></ci><apply id="alg2.l6.m1.1.1.1.1.1.1.cmml" xref="alg2.l6.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg2.l6.m1.1.1.1.1.1.1.1.cmml" xref="alg2.l6.m1.1.1.1.1.1">subscript</csymbol><ci id="alg2.l6.m1.1.1.1.1.1.1.2.cmml" xref="alg2.l6.m1.1.1.1.1.1.1.2">𝑑</ci><ci id="alg2.l6.m1.1.1.1.1.1.1.3.cmml" xref="alg2.l6.m1.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="alg2.l6.m1.1.1.3.cmml" xref="alg2.l6.m1.1.1.3"><minus id="alg2.l6.m1.1.1.3.1.cmml" xref="alg2.l6.m1.1.1.3.1"></minus><apply id="alg2.l6.m1.1.1.3.2.cmml" xref="alg2.l6.m1.1.1.3.2"><plus id="alg2.l6.m1.1.1.3.2.1.cmml" xref="alg2.l6.m1.1.1.3.2.1"></plus><ci id="alg2.l6.m1.1.1.3.2.2.cmml" xref="alg2.l6.m1.1.1.3.2.2">𝑘</ci><cn id="alg2.l6.m1.1.1.3.2.3.cmml" type="integer" xref="alg2.l6.m1.1.1.3.2.3">1</cn></apply><apply id="alg2.l6.m1.1.1.3.3.cmml" xref="alg2.l6.m1.1.1.3.3"><divide id="alg2.l6.m1.1.1.3.3.1.cmml" xref="alg2.l6.m1.1.1.3.3"></divide><ci id="alg2.l6.m1.1.1.3.3.2.cmml" xref="alg2.l6.m1.1.1.3.3.2">𝑖</ci><cn id="alg2.l6.m1.1.1.3.3.3.cmml" type="integer" xref="alg2.l6.m1.1.1.3.3.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l6.m1.1c">\textit{Order}(d_{i})\leftarrow k+1-\dfrac{i}{2}</annotation><annotation encoding="application/x-llamapun" id="alg2.l6.m1.1d">Order ( italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ← italic_k + 1 - divide start_ARG italic_i end_ARG start_ARG 2 end_ARG</annotation></semantics></math> {<math alttext="i" class="ltx_Math" display="inline" id="alg2.l6.m2.1"><semantics id="alg2.l6.m2.1a"><mi id="alg2.l6.m2.1.1" xref="alg2.l6.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="alg2.l6.m2.1b"><ci id="alg2.l6.m2.1.1.cmml" xref="alg2.l6.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l6.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="alg2.l6.m2.1d">italic_i</annotation></semantics></math> is even}

</div>
<div class="ltx_listingline" id="alg2.l7">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l7.1.1.1" style="font-size:80%;">7:</span></span>     <span class="ltx_text ltx_font_bold" id="alg2.l7.2">end</span> <span class="ltx_text ltx_font_bold" id="alg2.l7.3">if</span>
</div>
<div class="ltx_listingline" id="alg2.l8">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l8.1.1.1" style="font-size:80%;">8:</span></span>     Place <math alttext="d_{i}" class="ltx_Math" display="inline" id="alg2.l8.m1.1"><semantics id="alg2.l8.m1.1a"><msub id="alg2.l8.m1.1.1" xref="alg2.l8.m1.1.1.cmml"><mi id="alg2.l8.m1.1.1.2" xref="alg2.l8.m1.1.1.2.cmml">d</mi><mi id="alg2.l8.m1.1.1.3" xref="alg2.l8.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg2.l8.m1.1b"><apply id="alg2.l8.m1.1.1.cmml" xref="alg2.l8.m1.1.1"><csymbol cd="ambiguous" id="alg2.l8.m1.1.1.1.cmml" xref="alg2.l8.m1.1.1">subscript</csymbol><ci id="alg2.l8.m1.1.1.2.cmml" xref="alg2.l8.m1.1.1.2">𝑑</ci><ci id="alg2.l8.m1.1.1.3.cmml" xref="alg2.l8.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l8.m1.1c">d_{i}</annotation><annotation encoding="application/x-llamapun" id="alg2.l8.m1.1d">italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> at position <math alttext="\textit{Order}(d_{i})" class="ltx_Math" display="inline" id="alg2.l8.m2.1"><semantics id="alg2.l8.m2.1a"><mrow id="alg2.l8.m2.1.1" xref="alg2.l8.m2.1.1.cmml"><mtext class="ltx_mathvariant_italic" id="alg2.l8.m2.1.1.3" xref="alg2.l8.m2.1.1.3a.cmml">Order</mtext><mo id="alg2.l8.m2.1.1.2" xref="alg2.l8.m2.1.1.2.cmml">⁢</mo><mrow id="alg2.l8.m2.1.1.1.1" xref="alg2.l8.m2.1.1.1.1.1.cmml"><mo id="alg2.l8.m2.1.1.1.1.2" stretchy="false" xref="alg2.l8.m2.1.1.1.1.1.cmml">(</mo><msub id="alg2.l8.m2.1.1.1.1.1" xref="alg2.l8.m2.1.1.1.1.1.cmml"><mi id="alg2.l8.m2.1.1.1.1.1.2" xref="alg2.l8.m2.1.1.1.1.1.2.cmml">d</mi><mi id="alg2.l8.m2.1.1.1.1.1.3" xref="alg2.l8.m2.1.1.1.1.1.3.cmml">i</mi></msub><mo id="alg2.l8.m2.1.1.1.1.3" stretchy="false" xref="alg2.l8.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg2.l8.m2.1b"><apply id="alg2.l8.m2.1.1.cmml" xref="alg2.l8.m2.1.1"><times id="alg2.l8.m2.1.1.2.cmml" xref="alg2.l8.m2.1.1.2"></times><ci id="alg2.l8.m2.1.1.3a.cmml" xref="alg2.l8.m2.1.1.3"><mtext class="ltx_mathvariant_italic" id="alg2.l8.m2.1.1.3.cmml" xref="alg2.l8.m2.1.1.3">Order</mtext></ci><apply id="alg2.l8.m2.1.1.1.1.1.cmml" xref="alg2.l8.m2.1.1.1.1"><csymbol cd="ambiguous" id="alg2.l8.m2.1.1.1.1.1.1.cmml" xref="alg2.l8.m2.1.1.1.1">subscript</csymbol><ci id="alg2.l8.m2.1.1.1.1.1.2.cmml" xref="alg2.l8.m2.1.1.1.1.1.2">𝑑</ci><ci id="alg2.l8.m2.1.1.1.1.1.3.cmml" xref="alg2.l8.m2.1.1.1.1.1.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg2.l8.m2.1c">\textit{Order}(d_{i})</annotation><annotation encoding="application/x-llamapun" id="alg2.l8.m2.1d">Order ( italic_d start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT )</annotation></semantics></math> in <math alttext="S" class="ltx_Math" display="inline" id="alg2.l8.m3.1"><semantics id="alg2.l8.m3.1a"><mi id="alg2.l8.m3.1.1" xref="alg2.l8.m3.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="alg2.l8.m3.1b"><ci id="alg2.l8.m3.1.1.cmml" xref="alg2.l8.m3.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="alg2.l8.m3.1c">S</annotation><annotation encoding="application/x-llamapun" id="alg2.l8.m3.1d">italic_S</annotation></semantics></math>.

</div>
<div class="ltx_listingline" id="alg2.l9">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l9.1.1.1" style="font-size:80%;">9:</span></span>  <span class="ltx_text ltx_font_bold" id="alg2.l9.2">end</span> <span class="ltx_text ltx_font_bold" id="alg2.l9.3">for</span>
</div>
<div class="ltx_listingline" id="alg2.l10">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l10.1.1.1" style="font-size:80%;">10:</span></span>  Construct input sequence <math alttext="[I,S[1],S[2],...,S[k],q]" class="ltx_Math" display="inline" id="alg2.l10.m1.9"><semantics id="alg2.l10.m1.9a"><mrow id="alg2.l10.m1.9.9.3" xref="alg2.l10.m1.9.9.4.cmml"><mo id="alg2.l10.m1.9.9.3.4" stretchy="false" xref="alg2.l10.m1.9.9.4.cmml">[</mo><mi id="alg2.l10.m1.4.4" xref="alg2.l10.m1.4.4.cmml">I</mi><mo id="alg2.l10.m1.9.9.3.5" xref="alg2.l10.m1.9.9.4.cmml">,</mo><mrow id="alg2.l10.m1.7.7.1.1" xref="alg2.l10.m1.7.7.1.1.cmml"><mi id="alg2.l10.m1.7.7.1.1.2" xref="alg2.l10.m1.7.7.1.1.2.cmml">S</mi><mo id="alg2.l10.m1.7.7.1.1.1" xref="alg2.l10.m1.7.7.1.1.1.cmml">⁢</mo><mrow id="alg2.l10.m1.7.7.1.1.3.2" xref="alg2.l10.m1.7.7.1.1.3.1.cmml"><mo id="alg2.l10.m1.7.7.1.1.3.2.1" stretchy="false" xref="alg2.l10.m1.7.7.1.1.3.1.1.cmml">[</mo><mn id="alg2.l10.m1.1.1" xref="alg2.l10.m1.1.1.cmml">1</mn><mo id="alg2.l10.m1.7.7.1.1.3.2.2" stretchy="false" xref="alg2.l10.m1.7.7.1.1.3.1.1.cmml">]</mo></mrow></mrow><mo id="alg2.l10.m1.9.9.3.6" xref="alg2.l10.m1.9.9.4.cmml">,</mo><mrow id="alg2.l10.m1.8.8.2.2" xref="alg2.l10.m1.8.8.2.2.cmml"><mi id="alg2.l10.m1.8.8.2.2.2" xref="alg2.l10.m1.8.8.2.2.2.cmml">S</mi><mo id="alg2.l10.m1.8.8.2.2.1" xref="alg2.l10.m1.8.8.2.2.1.cmml">⁢</mo><mrow id="alg2.l10.m1.8.8.2.2.3.2" xref="alg2.l10.m1.8.8.2.2.3.1.cmml"><mo id="alg2.l10.m1.8.8.2.2.3.2.1" stretchy="false" xref="alg2.l10.m1.8.8.2.2.3.1.1.cmml">[</mo><mn id="alg2.l10.m1.2.2" xref="alg2.l10.m1.2.2.cmml">2</mn><mo id="alg2.l10.m1.8.8.2.2.3.2.2" stretchy="false" xref="alg2.l10.m1.8.8.2.2.3.1.1.cmml">]</mo></mrow></mrow><mo id="alg2.l10.m1.9.9.3.7" xref="alg2.l10.m1.9.9.4.cmml">,</mo><mi id="alg2.l10.m1.5.5" mathvariant="normal" xref="alg2.l10.m1.5.5.cmml">…</mi><mo id="alg2.l10.m1.9.9.3.8" xref="alg2.l10.m1.9.9.4.cmml">,</mo><mrow id="alg2.l10.m1.9.9.3.3" xref="alg2.l10.m1.9.9.3.3.cmml"><mi id="alg2.l10.m1.9.9.3.3.2" xref="alg2.l10.m1.9.9.3.3.2.cmml">S</mi><mo id="alg2.l10.m1.9.9.3.3.1" xref="alg2.l10.m1.9.9.3.3.1.cmml">⁢</mo><mrow id="alg2.l10.m1.9.9.3.3.3.2" xref="alg2.l10.m1.9.9.3.3.3.1.cmml"><mo id="alg2.l10.m1.9.9.3.3.3.2.1" stretchy="false" xref="alg2.l10.m1.9.9.3.3.3.1.1.cmml">[</mo><mi id="alg2.l10.m1.3.3" xref="alg2.l10.m1.3.3.cmml">k</mi><mo id="alg2.l10.m1.9.9.3.3.3.2.2" stretchy="false" xref="alg2.l10.m1.9.9.3.3.3.1.1.cmml">]</mo></mrow></mrow><mo id="alg2.l10.m1.9.9.3.9" xref="alg2.l10.m1.9.9.4.cmml">,</mo><mi id="alg2.l10.m1.6.6" xref="alg2.l10.m1.6.6.cmml">q</mi><mo id="alg2.l10.m1.9.9.3.10" stretchy="false" xref="alg2.l10.m1.9.9.4.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="alg2.l10.m1.9b"><list id="alg2.l10.m1.9.9.4.cmml" xref="alg2.l10.m1.9.9.3"><ci id="alg2.l10.m1.4.4.cmml" xref="alg2.l10.m1.4.4">𝐼</ci><apply id="alg2.l10.m1.7.7.1.1.cmml" xref="alg2.l10.m1.7.7.1.1"><times id="alg2.l10.m1.7.7.1.1.1.cmml" xref="alg2.l10.m1.7.7.1.1.1"></times><ci id="alg2.l10.m1.7.7.1.1.2.cmml" xref="alg2.l10.m1.7.7.1.1.2">𝑆</ci><apply id="alg2.l10.m1.7.7.1.1.3.1.cmml" xref="alg2.l10.m1.7.7.1.1.3.2"><csymbol cd="latexml" id="alg2.l10.m1.7.7.1.1.3.1.1.cmml" xref="alg2.l10.m1.7.7.1.1.3.2.1">delimited-[]</csymbol><cn id="alg2.l10.m1.1.1.cmml" type="integer" xref="alg2.l10.m1.1.1">1</cn></apply></apply><apply id="alg2.l10.m1.8.8.2.2.cmml" xref="alg2.l10.m1.8.8.2.2"><times id="alg2.l10.m1.8.8.2.2.1.cmml" xref="alg2.l10.m1.8.8.2.2.1"></times><ci id="alg2.l10.m1.8.8.2.2.2.cmml" xref="alg2.l10.m1.8.8.2.2.2">𝑆</ci><apply id="alg2.l10.m1.8.8.2.2.3.1.cmml" xref="alg2.l10.m1.8.8.2.2.3.2"><csymbol cd="latexml" id="alg2.l10.m1.8.8.2.2.3.1.1.cmml" xref="alg2.l10.m1.8.8.2.2.3.2.1">delimited-[]</csymbol><cn id="alg2.l10.m1.2.2.cmml" type="integer" xref="alg2.l10.m1.2.2">2</cn></apply></apply><ci id="alg2.l10.m1.5.5.cmml" xref="alg2.l10.m1.5.5">…</ci><apply id="alg2.l10.m1.9.9.3.3.cmml" xref="alg2.l10.m1.9.9.3.3"><times id="alg2.l10.m1.9.9.3.3.1.cmml" xref="alg2.l10.m1.9.9.3.3.1"></times><ci id="alg2.l10.m1.9.9.3.3.2.cmml" xref="alg2.l10.m1.9.9.3.3.2">𝑆</ci><apply id="alg2.l10.m1.9.9.3.3.3.1.cmml" xref="alg2.l10.m1.9.9.3.3.3.2"><csymbol cd="latexml" id="alg2.l10.m1.9.9.3.3.3.1.1.cmml" xref="alg2.l10.m1.9.9.3.3.3.2.1">delimited-[]</csymbol><ci id="alg2.l10.m1.3.3.cmml" xref="alg2.l10.m1.3.3">𝑘</ci></apply></apply><ci id="alg2.l10.m1.6.6.cmml" xref="alg2.l10.m1.6.6">𝑞</ci></list></annotation-xml><annotation encoding="application/x-tex" id="alg2.l10.m1.9c">[I,S[1],S[2],...,S[k],q]</annotation><annotation encoding="application/x-llamapun" id="alg2.l10.m1.9d">[ italic_I , italic_S [ 1 ] , italic_S [ 2 ] , … , italic_S [ italic_k ] , italic_q ]</annotation></semantics></math>.

</div>
<div class="ltx_listingline" id="alg2.l11">
<span class="ltx_tag ltx_tag_listingline"><span class="ltx_text" id="alg2.l11.1.1.1" style="font-size:80%;">11:</span></span>  <span class="ltx_text ltx_font_bold" id="alg2.l11.2">return</span>  The reordered sequence <math alttext="[I,S[1],S[2],...,S[k],q]" class="ltx_Math" display="inline" id="alg2.l11.m1.9"><semantics id="alg2.l11.m1.9a"><mrow id="alg2.l11.m1.9.9.3" xref="alg2.l11.m1.9.9.4.cmml"><mo id="alg2.l11.m1.9.9.3.4" stretchy="false" xref="alg2.l11.m1.9.9.4.cmml">[</mo><mi id="alg2.l11.m1.4.4" xref="alg2.l11.m1.4.4.cmml">I</mi><mo id="alg2.l11.m1.9.9.3.5" xref="alg2.l11.m1.9.9.4.cmml">,</mo><mrow id="alg2.l11.m1.7.7.1.1" xref="alg2.l11.m1.7.7.1.1.cmml"><mi id="alg2.l11.m1.7.7.1.1.2" xref="alg2.l11.m1.7.7.1.1.2.cmml">S</mi><mo id="alg2.l11.m1.7.7.1.1.1" xref="alg2.l11.m1.7.7.1.1.1.cmml">⁢</mo><mrow id="alg2.l11.m1.7.7.1.1.3.2" xref="alg2.l11.m1.7.7.1.1.3.1.cmml"><mo id="alg2.l11.m1.7.7.1.1.3.2.1" stretchy="false" xref="alg2.l11.m1.7.7.1.1.3.1.1.cmml">[</mo><mn id="alg2.l11.m1.1.1" xref="alg2.l11.m1.1.1.cmml">1</mn><mo id="alg2.l11.m1.7.7.1.1.3.2.2" stretchy="false" xref="alg2.l11.m1.7.7.1.1.3.1.1.cmml">]</mo></mrow></mrow><mo id="alg2.l11.m1.9.9.3.6" xref="alg2.l11.m1.9.9.4.cmml">,</mo><mrow id="alg2.l11.m1.8.8.2.2" xref="alg2.l11.m1.8.8.2.2.cmml"><mi id="alg2.l11.m1.8.8.2.2.2" xref="alg2.l11.m1.8.8.2.2.2.cmml">S</mi><mo id="alg2.l11.m1.8.8.2.2.1" xref="alg2.l11.m1.8.8.2.2.1.cmml">⁢</mo><mrow id="alg2.l11.m1.8.8.2.2.3.2" xref="alg2.l11.m1.8.8.2.2.3.1.cmml"><mo id="alg2.l11.m1.8.8.2.2.3.2.1" stretchy="false" xref="alg2.l11.m1.8.8.2.2.3.1.1.cmml">[</mo><mn id="alg2.l11.m1.2.2" xref="alg2.l11.m1.2.2.cmml">2</mn><mo id="alg2.l11.m1.8.8.2.2.3.2.2" stretchy="false" xref="alg2.l11.m1.8.8.2.2.3.1.1.cmml">]</mo></mrow></mrow><mo id="alg2.l11.m1.9.9.3.7" xref="alg2.l11.m1.9.9.4.cmml">,</mo><mi id="alg2.l11.m1.5.5" mathvariant="normal" xref="alg2.l11.m1.5.5.cmml">…</mi><mo id="alg2.l11.m1.9.9.3.8" xref="alg2.l11.m1.9.9.4.cmml">,</mo><mrow id="alg2.l11.m1.9.9.3.3" xref="alg2.l11.m1.9.9.3.3.cmml"><mi id="alg2.l11.m1.9.9.3.3.2" xref="alg2.l11.m1.9.9.3.3.2.cmml">S</mi><mo id="alg2.l11.m1.9.9.3.3.1" xref="alg2.l11.m1.9.9.3.3.1.cmml">⁢</mo><mrow id="alg2.l11.m1.9.9.3.3.3.2" xref="alg2.l11.m1.9.9.3.3.3.1.cmml"><mo id="alg2.l11.m1.9.9.3.3.3.2.1" stretchy="false" xref="alg2.l11.m1.9.9.3.3.3.1.1.cmml">[</mo><mi id="alg2.l11.m1.3.3" xref="alg2.l11.m1.3.3.cmml">k</mi><mo id="alg2.l11.m1.9.9.3.3.3.2.2" stretchy="false" xref="alg2.l11.m1.9.9.3.3.3.1.1.cmml">]</mo></mrow></mrow><mo id="alg2.l11.m1.9.9.3.9" xref="alg2.l11.m1.9.9.4.cmml">,</mo><mi id="alg2.l11.m1.6.6" xref="alg2.l11.m1.6.6.cmml">q</mi><mo id="alg2.l11.m1.9.9.3.10" stretchy="false" xref="alg2.l11.m1.9.9.4.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="alg2.l11.m1.9b"><list id="alg2.l11.m1.9.9.4.cmml" xref="alg2.l11.m1.9.9.3"><ci id="alg2.l11.m1.4.4.cmml" xref="alg2.l11.m1.4.4">𝐼</ci><apply id="alg2.l11.m1.7.7.1.1.cmml" xref="alg2.l11.m1.7.7.1.1"><times id="alg2.l11.m1.7.7.1.1.1.cmml" xref="alg2.l11.m1.7.7.1.1.1"></times><ci id="alg2.l11.m1.7.7.1.1.2.cmml" xref="alg2.l11.m1.7.7.1.1.2">𝑆</ci><apply id="alg2.l11.m1.7.7.1.1.3.1.cmml" xref="alg2.l11.m1.7.7.1.1.3.2"><csymbol cd="latexml" id="alg2.l11.m1.7.7.1.1.3.1.1.cmml" xref="alg2.l11.m1.7.7.1.1.3.2.1">delimited-[]</csymbol><cn id="alg2.l11.m1.1.1.cmml" type="integer" xref="alg2.l11.m1.1.1">1</cn></apply></apply><apply id="alg2.l11.m1.8.8.2.2.cmml" xref="alg2.l11.m1.8.8.2.2"><times id="alg2.l11.m1.8.8.2.2.1.cmml" xref="alg2.l11.m1.8.8.2.2.1"></times><ci id="alg2.l11.m1.8.8.2.2.2.cmml" xref="alg2.l11.m1.8.8.2.2.2">𝑆</ci><apply id="alg2.l11.m1.8.8.2.2.3.1.cmml" xref="alg2.l11.m1.8.8.2.2.3.2"><csymbol cd="latexml" id="alg2.l11.m1.8.8.2.2.3.1.1.cmml" xref="alg2.l11.m1.8.8.2.2.3.2.1">delimited-[]</csymbol><cn id="alg2.l11.m1.2.2.cmml" type="integer" xref="alg2.l11.m1.2.2">2</cn></apply></apply><ci id="alg2.l11.m1.5.5.cmml" xref="alg2.l11.m1.5.5">…</ci><apply id="alg2.l11.m1.9.9.3.3.cmml" xref="alg2.l11.m1.9.9.3.3"><times id="alg2.l11.m1.9.9.3.3.1.cmml" xref="alg2.l11.m1.9.9.3.3.1"></times><ci id="alg2.l11.m1.9.9.3.3.2.cmml" xref="alg2.l11.m1.9.9.3.3.2">𝑆</ci><apply id="alg2.l11.m1.9.9.3.3.3.1.cmml" xref="alg2.l11.m1.9.9.3.3.3.2"><csymbol cd="latexml" id="alg2.l11.m1.9.9.3.3.3.1.1.cmml" xref="alg2.l11.m1.9.9.3.3.3.2.1">delimited-[]</csymbol><ci id="alg2.l11.m1.3.3.cmml" xref="alg2.l11.m1.3.3">𝑘</ci></apply></apply><ci id="alg2.l11.m1.6.6.cmml" xref="alg2.l11.m1.6.6">𝑞</ci></list></annotation-xml><annotation encoding="application/x-tex" id="alg2.l11.m1.9c">[I,S[1],S[2],...,S[k],q]</annotation><annotation encoding="application/x-llamapun" id="alg2.l11.m1.9d">[ italic_I , italic_S [ 1 ] , italic_S [ 2 ] , … , italic_S [ italic_k ] , italic_q ]</annotation></semantics></math>.

</div>
</div>
</figure>
</section>
<section class="ltx_appendix" id="A6" lang="en">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Datasets</h2>
<div class="ltx_para" id="A6.p1">
<p class="ltx_p" id="A6.p1.1">In this section, we discuss the datasets for RAG-specific LLM training and evaluation.</p>
</div>
<section class="ltx_subsection" id="A6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">F.1 </span>Training datasets</h3>
<figure class="ltx_table" id="A6.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A6.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A6.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="A6.T1.1.1.1.1"><span class="ltx_text" id="A6.T1.1.1.1.1.1" style="font-size:90%;">Dataset</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A6.T1.1.1.1.2"><span class="ltx_text" id="A6.T1.1.1.1.2.1" style="font-size:90%;">the number of instances</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A6.T1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A6.T1.1.2.1.1"><span class="ltx_text" id="A6.T1.1.2.1.1.1" style="font-size:90%;">Natural Question</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T1.1.2.1.2"><span class="ltx_text" id="A6.T1.1.2.1.2.1" style="font-size:90%;">12,500</span></td>
</tr>
<tr class="ltx_tr" id="A6.T1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A6.T1.1.3.2.1"><span class="ltx_text" id="A6.T1.1.3.2.1.1" style="font-size:90%;">Wizard of Wikipedia</span></th>
<td class="ltx_td ltx_align_center" id="A6.T1.1.3.2.2"><span class="ltx_text" id="A6.T1.1.3.2.2.1" style="font-size:90%;">12,500</span></td>
</tr>
<tr class="ltx_tr" id="A6.T1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A6.T1.1.4.3.1"><span class="ltx_text" id="A6.T1.1.4.3.1.1" style="font-size:90%;">FEVER</span></th>
<td class="ltx_td ltx_align_center" id="A6.T1.1.4.3.2"><span class="ltx_text" id="A6.T1.1.4.3.2.1" style="font-size:90%;">12,500</span></td>
</tr>
<tr class="ltx_tr" id="A6.T1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="A6.T1.1.5.4.1"><span class="ltx_text" id="A6.T1.1.5.4.1.1" style="font-size:90%;">MMLU</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T1.1.5.4.2"><span class="ltx_text" id="A6.T1.1.5.4.2.1" style="font-size:90%;">12,500</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1: </span>Training data statistics.</figcaption>
</figure>
<div class="ltx_para" id="A6.SS1.p1">
<p class="ltx_p" id="A6.SS1.p1.1">We select a series of fine-tuning data designed to enhance the model’s robustness to hard negatives in the retrieval context and improve its contextual awareness in generating predictions.
The training data are from four sources with different answer types: Natural Question (short-form), Wizard of Wikipedia (long-form), FEVER (true/false), and MMLU (close-set).
The statistics of the training data mix can be found in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A6.T1" title="Table 1 ‣ F.1 Training datasets ‣ Appendix F Datasets ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="A6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">F.2 </span>Testing datasets</h3>
<div class="ltx_para" id="A6.SS2.p1">
<p class="ltx_p" id="A6.SS2.p1.1">To comprehensively evaluate our methods, we select testing datasets across different tasks including: (1) Question-answering: TriviaQA, PopQA, WebQuestions; (2) Multi-hop tasks: HotpotQA, 2WikiMultiHopQA, Bamboogle; (3) Long-form tasks: ASQA; (4) Slot filling: T-REx, Zero-shot RE.
The statistics of all the datasets can be found in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A6.T2" title="Table 2 ‣ F.2 Testing datasets ‣ Appendix F Datasets ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<figure class="ltx_table" id="A6.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A6.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A6.T2.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="A6.T2.1.1.1.1"><span class="ltx_text" id="A6.T2.1.1.1.1.1" style="font-size:90%;">Dataset</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="A6.T2.1.1.1.2"><span class="ltx_text" id="A6.T2.1.1.1.2.1" style="font-size:90%;">Task</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A6.T2.1.1.1.3"><span class="ltx_text" id="A6.T2.1.1.1.3.1" style="font-size:90%;">the number of instances</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A6.T2.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A6.T2.1.2.1.1"><span class="ltx_text" id="A6.T2.1.2.1.1.1" style="font-size:90%;">TriviaQA</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A6.T2.1.2.1.2"><span class="ltx_text" id="A6.T2.1.2.1.2.1" style="font-size:90%;">QA</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T2.1.2.1.3"><span class="ltx_text" id="A6.T2.1.2.1.3.1" style="font-size:90%;">11,313</span></td>
</tr>
<tr class="ltx_tr" id="A6.T2.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A6.T2.1.3.2.1"><span class="ltx_text" id="A6.T2.1.3.2.1.1" style="font-size:90%;">PopQA</span></th>
<td class="ltx_td ltx_align_center ltx_border_r" id="A6.T2.1.3.2.2"><span class="ltx_text" id="A6.T2.1.3.2.2.1" style="font-size:90%;">QA</span></td>
<td class="ltx_td ltx_align_center" id="A6.T2.1.3.2.3"><span class="ltx_text" id="A6.T2.1.3.2.3.1" style="font-size:90%;">14,267</span></td>
</tr>
<tr class="ltx_tr" id="A6.T2.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A6.T2.1.4.3.1"><span class="ltx_text" id="A6.T2.1.4.3.1.1" style="font-size:90%;">WebQuestions</span></th>
<td class="ltx_td ltx_align_center ltx_border_r" id="A6.T2.1.4.3.2"><span class="ltx_text" id="A6.T2.1.4.3.2.1" style="font-size:90%;">QA</span></td>
<td class="ltx_td ltx_align_center" id="A6.T2.1.4.3.3"><span class="ltx_text" id="A6.T2.1.4.3.3.1" style="font-size:90%;">2,032</span></td>
</tr>
<tr class="ltx_tr" id="A6.T2.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A6.T2.1.5.4.1"><span class="ltx_text" id="A6.T2.1.5.4.1.1" style="font-size:90%;">HotpotQA</span></th>
<td class="ltx_td ltx_align_center ltx_border_r" id="A6.T2.1.5.4.2"><span class="ltx_text" id="A6.T2.1.5.4.2.1" style="font-size:90%;">Multi-Hop QA</span></td>
<td class="ltx_td ltx_align_center" id="A6.T2.1.5.4.3"><span class="ltx_text" id="A6.T2.1.5.4.3.1" style="font-size:90%;">7,405</span></td>
</tr>
<tr class="ltx_tr" id="A6.T2.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A6.T2.1.6.5.1"><span class="ltx_text" id="A6.T2.1.6.5.1.1" style="font-size:90%;">2WikiMultiHopQA</span></th>
<td class="ltx_td ltx_align_center ltx_border_r" id="A6.T2.1.6.5.2"><span class="ltx_text" id="A6.T2.1.6.5.2.1" style="font-size:90%;">Multi-Hop QA</span></td>
<td class="ltx_td ltx_align_center" id="A6.T2.1.6.5.3"><span class="ltx_text" id="A6.T2.1.6.5.3.1" style="font-size:90%;">12,576</span></td>
</tr>
<tr class="ltx_tr" id="A6.T2.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A6.T2.1.7.6.1"><span class="ltx_text" id="A6.T2.1.7.6.1.1" style="font-size:90%;">Bamboogle</span></th>
<td class="ltx_td ltx_align_center ltx_border_r" id="A6.T2.1.7.6.2"><span class="ltx_text" id="A6.T2.1.7.6.2.1" style="font-size:90%;">Multi-Hop QA</span></td>
<td class="ltx_td ltx_align_center" id="A6.T2.1.7.6.3"><span class="ltx_text" id="A6.T2.1.7.6.3.1" style="font-size:90%;">125</span></td>
</tr>
<tr class="ltx_tr" id="A6.T2.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A6.T2.1.8.7.1"><span class="ltx_text" id="A6.T2.1.8.7.1.1" style="font-size:90%;">ASQA</span></th>
<td class="ltx_td ltx_align_center ltx_border_r" id="A6.T2.1.8.7.2"><span class="ltx_text" id="A6.T2.1.8.7.2.1" style="font-size:90%;">Long-form QA</span></td>
<td class="ltx_td ltx_align_center" id="A6.T2.1.8.7.3"><span class="ltx_text" id="A6.T2.1.8.7.3.1" style="font-size:90%;">948</span></td>
</tr>
<tr class="ltx_tr" id="A6.T2.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A6.T2.1.9.8.1"><span class="ltx_text" id="A6.T2.1.9.8.1.1" style="font-size:90%;">T-REx</span></th>
<td class="ltx_td ltx_align_center ltx_border_r" id="A6.T2.1.9.8.2"><span class="ltx_text" id="A6.T2.1.9.8.2.1" style="font-size:90%;">Slot filling</span></td>
<td class="ltx_td ltx_align_center" id="A6.T2.1.9.8.3"><span class="ltx_text" id="A6.T2.1.9.8.3.1" style="font-size:90%;">5,000</span></td>
</tr>
<tr class="ltx_tr" id="A6.T2.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="A6.T2.1.10.9.1"><span class="ltx_text" id="A6.T2.1.10.9.1.1" style="font-size:90%;">Zero-shot RE</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="A6.T2.1.10.9.2"><span class="ltx_text" id="A6.T2.1.10.9.2.1" style="font-size:90%;">Slot filling</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T2.1.10.9.3"><span class="ltx_text" id="A6.T2.1.10.9.3.1" style="font-size:90%;">3,724</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 2: </span>Testing data statistics.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">F.3 </span>Retrieval corpus</h3>
<div class="ltx_para" id="A6.SS3.p1">
<p class="ltx_p" id="A6.SS3.p1.1">Following <cite class="ltx_cite ltx_citemacro_cite">Karpukhin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#bib.bib15" title="">2020</a>)</cite>, we use the text chunks from 2018 Wikipedia dump as the retrieval corpus.
The articles are split by section, where long sections are further split into text chunks of equal sizes and contain less than 100 words, leading to a total of 21M text chunks.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_appendix" id="A7" lang="en">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix G </span>Implicit RAG Fine-Tuning Experimental Setting</h2>
<section class="ltx_subsection" id="A7.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.1 </span>Training settings</h3>
<div class="ltx_para ltx_noindent" id="A7.SS1.p1">
<p class="ltx_p" id="A7.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="A7.SS1.p1.1.1">Hyperparameters.</span>
We use the top-40 retrieved text chunks for a given example to generate the fine-tuning samples and use e5 as the retriever for the main results.
We fine-tune both Gemma-2-9B-Base and Mistral-Nemo-12B-Base using 8 H100 GPUs.
For both models, we use the chat template corresponding to Gemma-2-9B-Chat and Mistral-Nemo-12B-Instruct respectively when tuning the models.
We use the axolotl<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/axolotl-ai-cloud/axolotl" title="">https://github.com/axolotl-ai-cloud/axolotl</a></span></span></span> codebase for their tuning.
For Gemini-1.0-Pro tuning, we use the Google Cloud Tuning API<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/tuning" title="">https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/tuning</a></span></span></span> with the default settings.
The hyperparameters can be found in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A7.T3" title="Table 3 ‣ G.1 Training settings ‣ Appendix G Implicit RAG Fine-Tuning Experimental Setting ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
<figure class="ltx_table" id="A7.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A7.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.T3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" id="A7.T3.1.1.1.1"><span class="ltx_text" id="A7.T3.1.1.1.1.1" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A7.T3.1.1.1.2"><span class="ltx_text" id="A7.T3.1.1.1.2.1" style="font-size:90%;">peak lr</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A7.T3.1.1.1.3"><span class="ltx_text" id="A7.T3.1.1.1.3.1" style="font-size:90%;">lr scheduler</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A7.T3.1.1.1.4"><span class="ltx_text" id="A7.T3.1.1.1.4.1" style="font-size:90%;">warm up</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A7.T3.1.1.1.5"><span class="ltx_text" id="A7.T3.1.1.1.5.1" style="font-size:90%;"># epoch</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A7.T3.1.1.1.6"><span class="ltx_text" id="A7.T3.1.1.1.6.1" style="font-size:90%;">batch size</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A7.T3.1.1.1.7"><span class="ltx_text" id="A7.T3.1.1.1.7.1" style="font-size:90%;">Flash Att</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.T3.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="A7.T3.1.2.1.1"><span class="ltx_text" id="A7.T3.1.2.1.1.1" style="font-size:90%;">Gemma-2-9B-Base</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T3.1.2.1.2"><span class="ltx_text" id="A7.T3.1.2.1.2.1" style="font-size:90%;">1e-6</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T3.1.2.1.3"><span class="ltx_text" id="A7.T3.1.2.1.3.1" style="font-size:90%;">cosine</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T3.1.2.1.4"><span class="ltx_text" id="A7.T3.1.2.1.4.1" style="font-size:90%;">5%</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T3.1.2.1.5"><span class="ltx_text" id="A7.T3.1.2.1.5.1" style="font-size:90%;">4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T3.1.2.1.6"><span class="ltx_text" id="A7.T3.1.2.1.6.1" style="font-size:90%;">64</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T3.1.2.1.7"><span class="ltx_text" id="A7.T3.1.2.1.7.1" style="font-size:90%;">False</span></td>
</tr>
<tr class="ltx_tr" id="A7.T3.1.3.2">
<td class="ltx_td ltx_align_left" id="A7.T3.1.3.2.1"><span class="ltx_text" id="A7.T3.1.3.2.1.1" style="font-size:90%;">Mistral-Nemo-12B-Base</span></td>
<td class="ltx_td ltx_align_center" id="A7.T3.1.3.2.2"><span class="ltx_text" id="A7.T3.1.3.2.2.1" style="font-size:90%;">1e-6</span></td>
<td class="ltx_td ltx_align_center" id="A7.T3.1.3.2.3"><span class="ltx_text" id="A7.T3.1.3.2.3.1" style="font-size:90%;">cosine</span></td>
<td class="ltx_td ltx_align_center" id="A7.T3.1.3.2.4"><span class="ltx_text" id="A7.T3.1.3.2.4.1" style="font-size:90%;">5%</span></td>
<td class="ltx_td ltx_align_center" id="A7.T3.1.3.2.5"><span class="ltx_text" id="A7.T3.1.3.2.5.1" style="font-size:90%;">4</span></td>
<td class="ltx_td ltx_align_center" id="A7.T3.1.3.2.6"><span class="ltx_text" id="A7.T3.1.3.2.6.1" style="font-size:90%;">64</span></td>
<td class="ltx_td ltx_align_center" id="A7.T3.1.3.2.7"><span class="ltx_text" id="A7.T3.1.3.2.7.1" style="font-size:90%;">True</span></td>
</tr>
<tr class="ltx_tr" id="A7.T3.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A7.T3.1.4.3.1"><span class="ltx_text" id="A7.T3.1.4.3.1.1" style="font-size:90%;">Gemini-1.0-Pro</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T3.1.4.3.2"><span class="ltx_text" id="A7.T3.1.4.3.2.1" style="font-size:90%;">default</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T3.1.4.3.3"><span class="ltx_text" id="A7.T3.1.4.3.3.1" style="font-size:90%;">default</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T3.1.4.3.4"><span class="ltx_text" id="A7.T3.1.4.3.4.1" style="font-size:90%;">default</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T3.1.4.3.5"><span class="ltx_text" id="A7.T3.1.4.3.5.1" style="font-size:90%;">1</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T3.1.4.3.6"><span class="ltx_text" id="A7.T3.1.4.3.6.1" style="font-size:90%;">default</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T3.1.4.3.7"><span class="ltx_text" id="A7.T3.1.4.3.7.1" style="font-size:90%;">default</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3: </span>Implicit RAG finetuning hyperparameters.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A7.SS1.p2">
<p class="ltx_p" id="A7.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="A7.SS1.p2.1.1">Training RAG instruction templates.</span> The RAG instruction templates for different training datasets can be found in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A7.T4" title="Table 4 ‣ G.1 Training settings ‣ Appendix G Implicit RAG Fine-Tuning Experimental Setting ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure class="ltx_table" id="A7.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A7.T4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.T4.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A7.T4.1.1.1.1"><span class="ltx_text" id="A7.T4.1.1.1.1.1" style="font-size:90%;">Task</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A7.T4.1.1.1.2"><span class="ltx_text" id="A7.T4.1.1.1.2.1" style="font-size:90%;">Instruction Templates</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.T4.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A7.T4.1.2.1.1"><span class="ltx_text" id="A7.T4.1.2.1.1.1" style="font-size:90%;">NQ</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T4.1.2.1.2"><span class="ltx_text" id="A7.T4.1.2.1.2.1" style="font-size:90%;">Answer the question based on the given document.</span></td>
</tr>
<tr class="ltx_tr" id="A7.T4.1.3.2">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T4.1.3.2.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T4.1.3.2.2"><span class="ltx_text" id="A7.T4.1.3.2.2.1" style="font-size:90%;">Only give me the answer and do not output any other words.</span></td>
</tr>
<tr class="ltx_tr" id="A7.T4.1.4.3">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T4.1.4.3.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T4.1.4.3.2"><span class="ltx_text" id="A7.T4.1.4.3.2.1" style="font-size:90%;">The following are given documents.</span></td>
</tr>
<tr class="ltx_tr" id="A7.T4.1.5.4">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T4.1.5.4.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T4.1.5.4.2"><span class="ltx_text" id="A7.T4.1.5.4.2.1" style="font-size:90%;">{reference}</span></td>
</tr>
<tr class="ltx_tr" id="A7.T4.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A7.T4.1.6.5.1"><span class="ltx_text" id="A7.T4.1.6.5.1.1" style="font-size:90%;">Wizard of Wikipedia</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T4.1.6.5.2"><span class="ltx_text" id="A7.T4.1.6.5.2.1" style="font-size:90%;">Provide a response to the conversation based on the given document.</span></td>
</tr>
<tr class="ltx_tr" id="A7.T4.1.7.6">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T4.1.7.6.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T4.1.7.6.2"><span class="ltx_text" id="A7.T4.1.7.6.2.1" style="font-size:90%;">The following are given documents.</span></td>
</tr>
<tr class="ltx_tr" id="A7.T4.1.8.7">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T4.1.8.7.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T4.1.8.7.2"><span class="ltx_text" id="A7.T4.1.8.7.2.1" style="font-size:90%;">{reference}</span></td>
</tr>
<tr class="ltx_tr" id="A7.T4.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A7.T4.1.9.8.1"><span class="ltx_text" id="A7.T4.1.9.8.1.1" style="font-size:90%;">FEVER</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T4.1.9.8.2"><span class="ltx_text" id="A7.T4.1.9.8.2.1" style="font-size:90%;">Verify a fact based on the given documents</span></td>
</tr>
<tr class="ltx_tr" id="A7.T4.1.10.9">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T4.1.10.9.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T4.1.10.9.2"><span class="ltx_text" id="A7.T4.1.10.9.2.1" style="font-size:90%;">The following are given documents.</span></td>
</tr>
<tr class="ltx_tr" id="A7.T4.1.11.10">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T4.1.11.10.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T4.1.11.10.2"><span class="ltx_text" id="A7.T4.1.11.10.2.1" style="font-size:90%;">{reference}</span></td>
</tr>
<tr class="ltx_tr" id="A7.T4.1.12.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A7.T4.1.12.11.1"><span class="ltx_text" id="A7.T4.1.12.11.1.1" style="font-size:90%;">MMLU</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T4.1.12.11.2"><span class="ltx_text" id="A7.T4.1.12.11.2.1" style="font-size:90%;">Given a question, choose the answer from the options based on the given documents.</span></td>
</tr>
<tr class="ltx_tr" id="A7.T4.1.13.12">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T4.1.13.12.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T4.1.13.12.2"><span class="ltx_text" id="A7.T4.1.13.12.2.1" style="font-size:90%;">The following are given documents.</span></td>
</tr>
<tr class="ltx_tr" id="A7.T4.1.14.13">
<th class="ltx_td ltx_th ltx_th_row ltx_border_bb" id="A7.T4.1.14.13.1"></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T4.1.14.13.2"><span class="ltx_text" id="A7.T4.1.14.13.2.1" style="font-size:90%;">{reference}</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 4: </span>Training instruction templates for implicit RAG tuning.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_para ltx_noindent" id="A7.SS1.p3">
<p class="ltx_p" id="A7.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="A7.SS1.p3.1.1">Training RAG answer templates.</span> The RAG answer templates for different training datasets can be found in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A7.T5" title="Table 5 ‣ G.1 Training settings ‣ Appendix G Implicit RAG Fine-Tuning Experimental Setting ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<figure class="ltx_table" id="A7.T5">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A7.T5.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.T5.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A7.T5.1.1.1.1"><span class="ltx_text" id="A7.T5.1.1.1.1.1" style="font-size:90%;">Task</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A7.T5.1.1.1.2"><span class="ltx_text" id="A7.T5.1.1.1.2.1" style="font-size:90%;">Answer Templates</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.T5.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A7.T5.1.2.1.1"><span class="ltx_text" id="A7.T5.1.2.1.1.1" style="font-size:90%;">NQ</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T5.1.2.1.2"><span class="ltx_text" id="A7.T5.1.2.1.2.1" style="font-size:90%;">Question: {question}</span></td>
</tr>
<tr class="ltx_tr" id="A7.T5.1.3.2">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T5.1.3.2.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T5.1.3.2.2"><span class="ltx_text" id="A7.T5.1.3.2.2.1" style="font-size:90%;">Answer:</span></td>
</tr>
<tr class="ltx_tr" id="A7.T5.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A7.T5.1.4.3.1"><span class="ltx_text" id="A7.T5.1.4.3.1.1" style="font-size:90%;">Wizard of Wikipedia</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T5.1.4.3.2"><span class="ltx_text" id="A7.T5.1.4.3.2.1" style="font-size:90%;">Conversation: {question}</span></td>
</tr>
<tr class="ltx_tr" id="A7.T5.1.5.4">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T5.1.5.4.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T5.1.5.4.2"><span class="ltx_text" id="A7.T5.1.5.4.2.1" style="font-size:90%;">Response:</span></td>
</tr>
<tr class="ltx_tr" id="A7.T5.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A7.T5.1.6.5.1"><span class="ltx_text" id="A7.T5.1.6.5.1.1" style="font-size:90%;">FEVER</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T5.1.6.5.2"><span class="ltx_text" id="A7.T5.1.6.5.2.1" style="font-size:90%;">Return SUPPORTS if it is correct and return REFUTES if it is not correct.</span></td>
</tr>
<tr class="ltx_tr" id="A7.T5.1.7.6">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T5.1.7.6.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T5.1.7.6.2"><span class="ltx_text" id="A7.T5.1.7.6.2.1" style="font-size:90%;">Fact: {question}</span></td>
</tr>
<tr class="ltx_tr" id="A7.T5.1.8.7">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T5.1.8.7.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T5.1.8.7.2"><span class="ltx_text" id="A7.T5.1.8.7.2.1" style="font-size:90%;">Response:</span></td>
</tr>
<tr class="ltx_tr" id="A7.T5.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A7.T5.1.9.8.1"><span class="ltx_text" id="A7.T5.1.9.8.1.1" style="font-size:90%;">MMLU</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T5.1.9.8.2"><span class="ltx_text" id="A7.T5.1.9.8.2.1" style="font-size:90%;">Question: {question}</span></td>
</tr>
<tr class="ltx_tr" id="A7.T5.1.10.9">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T5.1.10.9.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T5.1.10.9.2"><span class="ltx_text" id="A7.T5.1.10.9.2.1" style="font-size:90%;">Options: {choices}</span></td>
</tr>
<tr class="ltx_tr" id="A7.T5.1.11.10">
<th class="ltx_td ltx_th ltx_th_row ltx_border_bb" id="A7.T5.1.11.10.1"></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T5.1.11.10.2"><span class="ltx_text" id="A7.T5.1.11.10.2.1" style="font-size:90%;">Answer:</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 5: </span>Training answer templates for implicit RAG tuning.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A7.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">G.2 </span>Evaluation Settings</h3>
<div class="ltx_para ltx_noindent" id="A7.SS2.p1">
<p class="ltx_p" id="A7.SS2.p1.1"><span class="ltx_text ltx_font_bold" id="A7.SS2.p1.1.1">Hyperparameters.</span> For all the compared LLMs, we conduct top-p sampling (p = 1) and the maximum number of generated token is set to be 32.
For Gemma-2 series models, we use the huggingface inference pipeline<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/docs/transformers/" title="">https://huggingface.co/docs/transformers/</a></span></span></span>.
For Gemini series models, we use Google Cloud Inference API<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference" title="">https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/inference</a></span></span></span>.
While for other series of LLMs, we utilize vLLM<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/vllm-project/vllm" title="">https://github.com/vllm-project/vllm</a></span></span></span> codebase for efficient generation.</p>
</div>
<div class="ltx_para ltx_noindent" id="A7.SS2.p2">
<p class="ltx_p" id="A7.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="A7.SS2.p2.1.1">Evaluation RAG instruction templates.</span> The RAG instruction templates for different testing datasets can be found in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A7.T6" title="Table 6 ‣ G.2 Evaluation Settings ‣ Appendix G Implicit RAG Fine-Tuning Experimental Setting ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<figure class="ltx_table" id="A7.T6">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A7.T6.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A7.T6.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A7.T6.1.1.1.1"><span class="ltx_text" id="A7.T6.1.1.1.1.1" style="font-size:90%;">Task</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A7.T6.1.1.1.2"><span class="ltx_text" id="A7.T6.1.1.1.2.1" style="font-size:90%;">Instruction Templates</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A7.T6.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A7.T6.1.2.1.1"><span class="ltx_text" id="A7.T6.1.2.1.1.1" style="font-size:90%;">QA</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T6.1.2.1.2"><span class="ltx_text" id="A7.T6.1.2.1.2.1" style="font-size:90%;">Answer the question based on the given document.</span></td>
</tr>
<tr class="ltx_tr" id="A7.T6.1.3.2">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T6.1.3.2.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T6.1.3.2.2"><span class="ltx_text" id="A7.T6.1.3.2.2.1" style="font-size:90%;">Only give me the answer and do not output any other words.</span></td>
</tr>
<tr class="ltx_tr" id="A7.T6.1.4.3">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T6.1.4.3.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T6.1.4.3.2"><span class="ltx_text" id="A7.T6.1.4.3.2.1" style="font-size:90%;">The following are given documents.</span></td>
</tr>
<tr class="ltx_tr" id="A7.T6.1.5.4">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T6.1.5.4.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T6.1.5.4.2"><span class="ltx_text" id="A7.T6.1.5.4.2.1" style="font-size:90%;">{reference}</span></td>
</tr>
<tr class="ltx_tr" id="A7.T6.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A7.T6.1.6.5.1"><span class="ltx_text" id="A7.T6.1.6.5.1.1" style="font-size:90%;">Multi-hop</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T6.1.6.5.2"><span class="ltx_text" id="A7.T6.1.6.5.2.1" style="font-size:90%;">Answer the question based on the given document.</span></td>
</tr>
<tr class="ltx_tr" id="A7.T6.1.7.6">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T6.1.7.6.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T6.1.7.6.2"><span class="ltx_text" id="A7.T6.1.7.6.2.1" style="font-size:90%;">Only give me the answer and do not output any other words.</span></td>
</tr>
<tr class="ltx_tr" id="A7.T6.1.8.7">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T6.1.8.7.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T6.1.8.7.2"><span class="ltx_text" id="A7.T6.1.8.7.2.1" style="font-size:90%;">The following are given documents.</span></td>
</tr>
<tr class="ltx_tr" id="A7.T6.1.9.8">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T6.1.9.8.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T6.1.9.8.2"><span class="ltx_text" id="A7.T6.1.9.8.2.1" style="font-size:90%;">{reference}</span></td>
</tr>
<tr class="ltx_tr" id="A7.T6.1.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A7.T6.1.10.9.1"><span class="ltx_text" id="A7.T6.1.10.9.1.1" style="font-size:90%;">Long-form</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T6.1.10.9.2"><span class="ltx_text" id="A7.T6.1.10.9.2.1" style="font-size:90%;">Answer the question based on the given document.</span></td>
</tr>
<tr class="ltx_tr" id="A7.T6.1.11.10">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T6.1.11.10.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T6.1.11.10.2"><span class="ltx_text" id="A7.T6.1.11.10.2.1" style="font-size:90%;">Please give in-depth explanation and avoid only returning the answer.</span></td>
</tr>
<tr class="ltx_tr" id="A7.T6.1.12.11">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T6.1.12.11.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T6.1.12.11.2"><span class="ltx_text" id="A7.T6.1.12.11.2.1" style="font-size:90%;">The following are given documents.</span></td>
</tr>
<tr class="ltx_tr" id="A7.T6.1.13.12">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T6.1.13.12.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T6.1.13.12.2"><span class="ltx_text" id="A7.T6.1.13.12.2.1" style="font-size:90%;">{reference}</span></td>
</tr>
<tr class="ltx_tr" id="A7.T6.1.14.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A7.T6.1.14.13.1"><span class="ltx_text" id="A7.T6.1.14.13.1.1" style="font-size:90%;">Slot filling</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A7.T6.1.14.13.2"><span class="ltx_text" id="A7.T6.1.14.13.2.1" style="font-size:90%;">Given a question, choose the answer from the options based on the given documents.</span></td>
</tr>
<tr class="ltx_tr" id="A7.T6.1.15.14">
<th class="ltx_td ltx_th ltx_th_row" id="A7.T6.1.15.14.1"></th>
<td class="ltx_td ltx_align_center" id="A7.T6.1.15.14.2"><span class="ltx_text" id="A7.T6.1.15.14.2.1" style="font-size:90%;">The following are given documents.</span></td>
</tr>
<tr class="ltx_tr" id="A7.T6.1.16.15">
<th class="ltx_td ltx_th ltx_th_row ltx_border_bb" id="A7.T6.1.16.15.1"></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T6.1.16.15.2"><span class="ltx_text" id="A7.T6.1.16.15.2.1" style="font-size:90%;">{reference}</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 6: </span>Testing instruction templates for implicit RAG tuning.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A7.SS2.p3">
<p class="ltx_p" id="A7.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="A7.SS2.p3.1.1">Evaluation RAG answer templates.</span> The RAG answer templates for different testing datasets are all: "Question: {question}. Answer:"</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_appendix" id="A8" lang="en">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix H </span>RAG Finetuning with Intermediate Reasoning Experimental Setting</h2>
<section class="ltx_subsection" id="A8.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">H.1 </span>Training settings</h3>
<div class="ltx_para ltx_noindent" id="A8.SS1.p1">
<p class="ltx_p" id="A8.SS1.p1.1"><span class="ltx_text ltx_font_bold" id="A8.SS1.p1.1.1">Hyperparameters.</span> The hyperparameter setting is the same to that in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A7.SS1" title="G.1 Training settings ‣ Appendix G Implicit RAG Fine-Tuning Experimental Setting ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">G.1</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="A8.SS1.p2">
<p class="ltx_p" id="A8.SS1.p2.1"><span class="ltx_text ltx_font_bold" id="A8.SS1.p2.1.1">Training RAG instruction templates.</span> The RAG instruction templates with intermediate reasoning for different training datasets can be found in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A8.T7" title="Table 7 ‣ H.1 Training settings ‣ Appendix H RAG Finetuning with Intermediate Reasoning Experimental Setting ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<figure class="ltx_table" id="A8.T7">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A8.T7.1" style="width:433.6pt;height:320.6pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-62.7pt,46.2pt) scale(0.775782399874205,0.775782399874205) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A8.T7.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A8.T7.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A8.T7.1.1.1.1.1">Task</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A8.T7.1.1.1.1.2">Instruction Templates</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A8.T7.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A8.T7.1.1.2.1.1">NQ</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T7.1.1.2.1.2">Answer the question based on the given documents.</td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.1.3.2">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T7.1.1.3.2.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T7.1.1.3.2.2">Please first provide an analysis with clear reasoning details of which documents are relevant to answer the question.</td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.1.4.3">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T7.1.1.4.3.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T7.1.1.4.3.2">Then output a concise answer to the question based on the analysis.</td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.1.5.4">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T7.1.1.5.4.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T7.1.1.5.4.2">The following are given documents.</td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.1.6.5">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T7.1.1.6.5.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T7.1.1.6.5.2">{reference}</td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A8.T7.1.1.7.6.1">Wizard of Wikipedia</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T7.1.1.7.6.2">Provide a response to the conversation based on the given documents.</td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.1.8.7">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T7.1.1.8.7.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T7.1.1.8.7.2">Please first provide an analysis with clear reasoning details of which documents are relevant to provide the response.</td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.1.9.8">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T7.1.1.9.8.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T7.1.1.9.8.2">Then output a concise response to the question based on the analysis.</td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.1.10.9">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T7.1.1.10.9.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T7.1.1.10.9.2">The following are given documents.</td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.1.11.10">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T7.1.1.11.10.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T7.1.1.11.10.2">{reference}</td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.1.12.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A8.T7.1.1.12.11.1">FEVER</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T7.1.1.12.11.2">Verify a fact based on the given documents.</td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.1.13.12">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T7.1.1.13.12.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T7.1.1.13.12.2">Please first provide an analysis with clear reasoning details of which documents are relevant to verify the fact.</td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.1.14.13">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T7.1.1.14.13.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T7.1.1.14.13.2">Then output a concise answer (SUPPORTS or REFUTES) based on the analysis.</td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.1.15.14">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T7.1.1.15.14.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T7.1.1.15.14.2">The following are given documents.</td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.1.16.15">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T7.1.1.16.15.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T7.1.1.16.15.2">{reference}</td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.1.17.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A8.T7.1.1.17.16.1">MMLU</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T7.1.1.17.16.2">Given a question, choose the answer from the options based on the given documents.</td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.1.18.17">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T7.1.1.18.17.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T7.1.1.18.17.2">Please first provide an analysis with clear reasoning details of which documents are relevant to answer the question</td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.1.19.18">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T7.1.1.19.18.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T7.1.1.19.18.2">Then output a concise answer to the question based on the analysis.</td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.1.20.19">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T7.1.1.20.19.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T7.1.1.20.19.2">The following are given documents.</td>
</tr>
<tr class="ltx_tr" id="A8.T7.1.1.21.20">
<th class="ltx_td ltx_th ltx_th_row ltx_border_bb" id="A8.T7.1.1.21.20.1"></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T7.1.1.21.20.2">{reference}</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7: </span>Training instruction templates for RAG tuning with intermediate reasoning.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A8.SS1.p3">
<p class="ltx_p" id="A8.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="A8.SS1.p3.1.1">Training RAG Answer templates.</span> The RAG answer templates for different training datasets can be found in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A8.T8" title="Table 8 ‣ H.1 Training settings ‣ Appendix H RAG Finetuning with Intermediate Reasoning Experimental Setting ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">8</span></a>.</p>
</div>
<figure class="ltx_table" id="A8.T8">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A8.T8.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A8.T8.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A8.T8.1.1.1.1"><span class="ltx_text" id="A8.T8.1.1.1.1.1" style="font-size:90%;">Task</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A8.T8.1.1.1.2"><span class="ltx_text" id="A8.T8.1.1.1.2.1" style="font-size:90%;">Answer Templates</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A8.T8.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A8.T8.1.2.1.1"><span class="ltx_text" id="A8.T8.1.2.1.1.1" style="font-size:90%;">NQ</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T8.1.2.1.2"><span class="ltx_text" id="A8.T8.1.2.1.2.1" style="font-size:90%;">Question: {question}</span></td>
</tr>
<tr class="ltx_tr" id="A8.T8.1.3.2">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T8.1.3.2.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T8.1.3.2.2"><span class="ltx_text" id="A8.T8.1.3.2.2.1" style="font-size:90%;">Answer:</span></td>
</tr>
<tr class="ltx_tr" id="A8.T8.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A8.T8.1.4.3.1"><span class="ltx_text" id="A8.T8.1.4.3.1.1" style="font-size:90%;">Wizard of Wikipedia</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T8.1.4.3.2"><span class="ltx_text" id="A8.T8.1.4.3.2.1" style="font-size:90%;">Conversation: {question}</span></td>
</tr>
<tr class="ltx_tr" id="A8.T8.1.5.4">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T8.1.5.4.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T8.1.5.4.2"><span class="ltx_text" id="A8.T8.1.5.4.2.1" style="font-size:90%;">Response:</span></td>
</tr>
<tr class="ltx_tr" id="A8.T8.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A8.T8.1.6.5.1"><span class="ltx_text" id="A8.T8.1.6.5.1.1" style="font-size:90%;">FEVER</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T8.1.6.5.2"><span class="ltx_text" id="A8.T8.1.6.5.2.1" style="font-size:90%;">Return SUPPORTS if it is correct and return REFUTES if it is not correct.</span></td>
</tr>
<tr class="ltx_tr" id="A8.T8.1.7.6">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T8.1.7.6.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T8.1.7.6.2"><span class="ltx_text" id="A8.T8.1.7.6.2.1" style="font-size:90%;">Fact: {question}</span></td>
</tr>
<tr class="ltx_tr" id="A8.T8.1.8.7">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T8.1.8.7.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T8.1.8.7.2"><span class="ltx_text" id="A8.T8.1.8.7.2.1" style="font-size:90%;">Response:</span></td>
</tr>
<tr class="ltx_tr" id="A8.T8.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A8.T8.1.9.8.1"><span class="ltx_text" id="A8.T8.1.9.8.1.1" style="font-size:90%;">MMLU</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T8.1.9.8.2"><span class="ltx_text" id="A8.T8.1.9.8.2.1" style="font-size:90%;">Question: {question}</span></td>
</tr>
<tr class="ltx_tr" id="A8.T8.1.10.9">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T8.1.10.9.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T8.1.10.9.2"><span class="ltx_text" id="A8.T8.1.10.9.2.1" style="font-size:90%;">Options: {choices}</span></td>
</tr>
<tr class="ltx_tr" id="A8.T8.1.11.10">
<th class="ltx_td ltx_th ltx_th_row ltx_border_bb" id="A8.T8.1.11.10.1"></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T8.1.11.10.2"><span class="ltx_text" id="A8.T8.1.11.10.2.1" style="font-size:90%;">Answer:</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 8: </span>Training answer templates for RAG tuning with intermediate reasoning.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_para ltx_noindent" id="A8.SS1.p4">
<p class="ltx_p" id="A8.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="A8.SS1.p4.1.1">Instructions to generate intermediate reasoning from Gemini-1.5-pro.</span> The prompt that guides Gemini-1.5-pro for intermediate reasoning generation can be found in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A8.T9" title="Table 9 ‣ H.1 Training settings ‣ Appendix H RAG Finetuning with Intermediate Reasoning Experimental Setting ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">9</span></a>.</p>
</div>
<figure class="ltx_table" id="A8.T9">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A8.T9.1" style="width:433.6pt;height:524.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-60.5pt,73.0pt) scale(0.781843681941712,0.781843681941712) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A8.T9.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A8.T9.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A8.T9.1.1.1.1.1">Task</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A8.T9.1.1.1.1.2">Prompts</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A8.T9.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A8.T9.1.1.2.1.1">NQ</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T9.1.1.2.1.2">Read the following documents relevant to the given question: {question}</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.3.2">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.3.2.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.3.2.2">{reference}</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.4.3">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.4.3.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.4.3.2">Please identify documents that are useful to answer the given question: {question},</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.5.4">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.5.4.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.5.4.2">and explain how the contents lead to the answer: {answers}.</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.6.5">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.6.5.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.6.5.2">If none of the documents is aligned with the answer,</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.7.6">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.7.6.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.7.6.2">in that case, you have to explain the answer only based on your own knowledge,</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.8.7">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.8.7.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.8.7.2">without referring to the provided information.</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.9.8">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.9.8.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.9.8.2">Note that the question may be compositional and require intermediate analysis to deduce the final answer.</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.10.9">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.10.9.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.10.9.2">Make sure your response is grounded and provides clear reasoning details followed by a concise conclusion.</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A8.T9.1.1.11.10.1">Wizard of Wikipedia</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T9.1.1.11.10.2">Read the following documents relevant to the given conversation: {question}</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.12.11">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.12.11.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.12.11.2">{reference}</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.13.12">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.13.12.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.13.12.2">Please identify documents that are useful to provide a response to a conversation: {question}</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.14.13">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.14.13.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.14.13.2">and explain how the contents lead to the response: {answers}.</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.15.14">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.15.14.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.15.14.2">If none of the documents is aligned with the response,</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.16.15">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.16.15.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.16.15.2">in that case, you have to explain the response only based on your own knowledge,</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.17.16">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.17.16.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.17.16.2">without referring to the provided information.</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.18.17">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.18.17.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.18.17.2">Make sure your response is grounded and provides clear reasoning details followed by a concise conclusion.</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.19.18">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A8.T9.1.1.19.18.1">FEVER</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T9.1.1.19.18.2">Read the following documents relevant to the given question: {question}</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.20.19">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.20.19.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.20.19.2">{reference}</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.21.20">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.21.20.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.21.20.2">Please identify documents that are useful to verify a fact: {question}</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.22.21">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.22.21.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.22.21.2">(Return SUPPORTS if it is correct and return REFUTES if it is not correct.),</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.23.22">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.23.22.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.23.22.2">and explain how the contents lead to the answer: {answers}.</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.24.23">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.24.23.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.24.23.2">If none of the documents is aligned with the answer,</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.25.24">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.25.24.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.25.24.2">in that case, you have to explain the answer only based on your own knowledge</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.26.25">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.26.25.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.26.25.2">without referring to the provided information.</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.27.26">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.27.26.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.27.26.2">Make sure your response is grounded and provides clear reasoning details followed by a concise conclusion.</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.28.27">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A8.T9.1.1.28.27.1">MMLU</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T9.1.1.28.27.2">Read the following documents relevant to the given question: {question}</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.29.28">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.29.28.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.29.28.2">{reference}</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.30.29">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.30.29.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.30.29.2">Please identify documents that are useful to answer the given question: {question} with options: {choices},</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.31.30">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.31.30.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.31.30.2">and explain how the contents lead to the answer: {answers}.</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.32.31">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.32.31.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.32.31.2">If none of the documents is aligned with the answer,</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.33.32">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.33.32.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.33.32.2">in that case, you have to explain the answer only based on your own knowledge,</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.34.33">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T9.1.1.34.33.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T9.1.1.34.33.2">without referring to the provided information.</td>
</tr>
<tr class="ltx_tr" id="A8.T9.1.1.35.34">
<th class="ltx_td ltx_th ltx_th_row ltx_border_bb" id="A8.T9.1.1.35.34.1"></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T9.1.1.35.34.2">Make sure your response is grounded and provides clear reasoning details followed by a concise conclusion.</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 9: </span>Prompts to guide Gemini-1.5-pro for intermediate reasoning generation.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_subsection" id="A8.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">H.2 </span>Evaluation settings</h3>
<div class="ltx_para ltx_noindent" id="A8.SS2.p1">
<p class="ltx_p" id="A8.SS2.p1.1"><span class="ltx_text ltx_font_bold" id="A8.SS2.p1.1.1">Hyperparameters.</span> For all the compared LLMs, we conduct top-p sampling (p = 1) and the maximum number of generated token is set to be 256. For Gemma-2 series models, we use the huggingface inference pipeline. While for other series of LLMs, we utilize vLLM codebase for efficient generation.</p>
</div>
<div class="ltx_para ltx_noindent" id="A8.SS2.p2">
<p class="ltx_p" id="A8.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="A8.SS2.p2.1.1">Evaluation RAG instruction templates.</span> The RAG instruction templates for different testing datasets can be found in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A8.T10" title="Table 10 ‣ H.2 Evaluation settings ‣ Appendix H RAG Finetuning with Intermediate Reasoning Experimental Setting ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">10</span></a>.</p>
</div>
<figure class="ltx_table" id="A8.T10">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A8.T10.1" style="width:433.6pt;height:393.2pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-39.7pt,35.9pt) scale(0.845307525806778,0.845307525806778) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="A8.T10.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A8.T10.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A8.T10.1.1.1.1.1">Task</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A8.T10.1.1.1.1.2">Instruction Templates</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A8.T10.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A8.T10.1.1.2.1.1">QA</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T10.1.1.2.1.2">Answer the question based on the given documents.</td>
</tr>
<tr class="ltx_tr" id="A8.T10.1.1.3.2">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T10.1.1.3.2.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T10.1.1.3.2.2">Please first provide an analysis with clear reasoning details of which documents are relevant to answer the question</td>
</tr>
<tr class="ltx_tr" id="A8.T10.1.1.4.3">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T10.1.1.4.3.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T10.1.1.4.3.2">Then output a concise answer to the question based on the analysis.</td>
</tr>
<tr class="ltx_tr" id="A8.T10.1.1.5.4">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T10.1.1.5.4.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T10.1.1.5.4.2">The following are given documents.</td>
</tr>
<tr class="ltx_tr" id="A8.T10.1.1.6.5">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T10.1.1.6.5.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T10.1.1.6.5.2">{reference}</td>
</tr>
<tr class="ltx_tr" id="A8.T10.1.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A8.T10.1.1.7.6.1">Multi-hop</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T10.1.1.7.6.2">Answer the question based on the given documents.</td>
</tr>
<tr class="ltx_tr" id="A8.T10.1.1.8.7">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T10.1.1.8.7.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T10.1.1.8.7.2">Please first provide an analysis with clear reasoning details of which documents are relevant to answer the question</td>
</tr>
<tr class="ltx_tr" id="A8.T10.1.1.9.8">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T10.1.1.9.8.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T10.1.1.9.8.2">Then output a concise answer to the question based on the analysis.</td>
</tr>
<tr class="ltx_tr" id="A8.T10.1.1.10.9">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T10.1.1.10.9.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T10.1.1.10.9.2">The following are given documents.</td>
</tr>
<tr class="ltx_tr" id="A8.T10.1.1.11.10">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T10.1.1.11.10.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T10.1.1.11.10.2">{reference}</td>
</tr>
<tr class="ltx_tr" id="A8.T10.1.1.12.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A8.T10.1.1.12.11.1">Long-form</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T10.1.1.12.11.2">Answer the question based on the given document.</td>
</tr>
<tr class="ltx_tr" id="A8.T10.1.1.13.12">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T10.1.1.13.12.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T10.1.1.13.12.2">Please first provide an analysis with clear reasoning details of which documents are relevant to answer the question</td>
</tr>
<tr class="ltx_tr" id="A8.T10.1.1.14.13">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T10.1.1.14.13.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T10.1.1.14.13.2">Then provide an in-depth long-form answer for the question (avoid only returning the answer) based on the analysis.</td>
</tr>
<tr class="ltx_tr" id="A8.T10.1.1.15.14">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T10.1.1.15.14.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T10.1.1.15.14.2">The following are given documents.</td>
</tr>
<tr class="ltx_tr" id="A8.T10.1.1.16.15">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T10.1.1.16.15.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T10.1.1.16.15.2">{reference}</td>
</tr>
<tr class="ltx_tr" id="A8.T10.1.1.17.16">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A8.T10.1.1.17.16.1">Slot filling</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A8.T10.1.1.17.16.2">Provided an answer to the given slot filling question based on the given document.</td>
</tr>
<tr class="ltx_tr" id="A8.T10.1.1.18.17">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T10.1.1.18.17.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T10.1.1.18.17.2">In the question, the words before and after [SEP] correspond to the head entity and relation respectively.</td>
</tr>
<tr class="ltx_tr" id="A8.T10.1.1.19.18">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T10.1.1.19.18.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T10.1.1.19.18.2">You are asked to output the tail entity corresponded to the given head entity and relation.</td>
</tr>
<tr class="ltx_tr" id="A8.T10.1.1.20.19">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T10.1.1.20.19.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T10.1.1.20.19.2">Please first provide an analysis with clear reasoning details of which documents are relevant to answer the question.</td>
</tr>
<tr class="ltx_tr" id="A8.T10.1.1.21.20">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T10.1.1.21.20.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T10.1.1.21.20.2">Then output a concise answer to the question based on the analysis.</td>
</tr>
<tr class="ltx_tr" id="A8.T10.1.1.22.21">
<th class="ltx_td ltx_th ltx_th_row" id="A8.T10.1.1.22.21.1"></th>
<td class="ltx_td ltx_align_center" id="A8.T10.1.1.22.21.2">The following are given documents.</td>
</tr>
<tr class="ltx_tr" id="A8.T10.1.1.23.22">
<th class="ltx_td ltx_th ltx_th_row ltx_border_bb" id="A8.T10.1.1.23.22.1"></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T10.1.1.23.22.2">{reference}</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 10: </span>Testing instruction templates for RAG tuning with intermediate reasoning.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="A8.SS2.p3">
<p class="ltx_p" id="A8.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="A8.SS2.p3.1.1">Evaluation RAG answer templates.</span> The RAG answer templates for different testing datasets are all: "Question: {question}. Answer:"</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section class="ltx_appendix" id="A9" lang="en">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix I </span>Data-Augmented RAG Case Studies</h2>
<figure class="ltx_table" id="A9.tab1">
<table class="ltx_tabular ltx_align_middle" id="A9.tab1.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A9.tab1.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A9.tab1.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A9.tab1.1.1.1.1.1">
<span class="ltx_p" id="A9.tab1.1.1.1.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="A9.tab1.1.1.1.1.1.1.1" style="font-size:90%;">Question</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A9.tab1.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A9.tab1.1.1.1.2.1">
<span class="ltx_p" id="A9.tab1.1.1.1.2.1.1" style="width:369.9pt;"><span class="ltx_text" id="A9.tab1.1.1.1.2.1.1.1" style="font-size:90%;">Which film features the Dawes Tomes Mousley Grubbs Fidelity Fiduciary Bank?</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A9.tab1.1.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.tab1.1.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A9.tab1.1.2.2.1.1">
<span class="ltx_p" id="A9.tab1.1.2.2.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="A9.tab1.1.2.2.1.1.1.1" style="font-size:90%;">Ground Truth</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.tab1.1.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A9.tab1.1.2.2.2.1">
<span class="ltx_p" id="A9.tab1.1.2.2.2.1.1" style="width:369.9pt;"><span class="ltx_text" id="A9.tab1.1.2.2.2.1.1.1" style="font-size:90%;">Mary Poppins</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A9.tab1.1.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.tab1.1.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="A9.tab1.1.3.3.1.1">
<span class="ltx_p" id="A9.tab1.1.3.3.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="A9.tab1.1.3.3.1.1.1.1" style="font-size:90%;">Retrieved Passages</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.tab1.1.3.3.2">
<span class="ltx_inline-block ltx_align_top" id="A9.tab1.1.3.3.2.1">
<span class="ltx_p" id="A9.tab1.1.3.3.2.1.1" style="width:369.9pt;"><span class="ltx_text ltx_font_bold" id="A9.tab1.1.3.3.2.1.1.1" style="font-size:90%;">Doc 1</span><span class="ltx_text" id="A9.tab1.1.3.3.2.1.1.2" style="font-size:90%;"> (Title: "Fidelity Fiduciary Bank") Fidelity Fiduciary Bank ""Fidelity Fiduciary Bank"" is a song from Walt Disney’s film ""Mary Poppins"", and it is composed by Richard M. Sherman and Robert B. Sherman. The song sung by the stodgy old bankers at the ""Dawes, Tomes, Mousely, Grubbs Fidelity Fiduciary Bank"", led by the ""Elder Mr. Dawes"" (Nackvid Keyed), to George Banks’s two children, Jane and Michael, in an attempt to get Michael Banks to invest his tuppence in the bank. As the song continues the pressure is on George, a junior clerk at the bank, to sway Michael. When Michael finally, and ever so slightly, opens … </span>
<br class="ltx_break ltx_align_left"/>
<br class="ltx_break ltx_align_left"/><span class="ltx_text ltx_align_left ltx_font_bold" id="A9.tab1.1.3.3.2.1.1.3" style="font-size:90%;">Doc 2</span><span class="ltx_text" id="A9.tab1.1.3.3.2.1.1.4" style="font-size:90%;"> (Title: "Fidelity Fiduciary Bank") convince Michael to invest his money goes like this: has as its origins an essay by C. C. Turner titled ’Money London’ in the book edited by G. R. Sims called ""Living London"" (London: 1903): Fidelity Fiduciary Bank ""Fidelity Fiduciary Bank"" is a song from Walt Disney’s film ""Mary Poppins"", and it is composed by Richard M. Sherman and Robert B. Sherman. The song sung by the stodgy old bankers at the ""Dawes, Tomes, Mousely, Grubbs Fidelity Fiduciary Bank"", led by the ""Elder Mr. Dawes"" (Nackvid Keyed), to George Banks’s two children, Jane and Michael, in an attempt to get … </span>
<br class="ltx_break ltx_align_left"/><span class="ltx_text" id="A9.tab1.1.3.3.2.1.1.5" style="font-size:90%;">… </span>
<br class="ltx_break ltx_align_left"/><span class="ltx_text ltx_align_left ltx_font_bold" id="A9.tab1.1.3.3.2.1.1.6" style="font-size:90%;">Doc 40</span><span class="ltx_text" id="A9.tab1.1.3.3.2.1.1.7" style="font-size:90%;"> (Title: "The Firm (soundtrack)") The Firm (soundtrack) The Firm is an album by American pianist Dave Grusin released in 1993, recorded for the GRP label. This album is a soundtrack to the Motion Picture ""The Firm"" directed by Sidney Pollack. It reached No. 131 on ""Billboard""’s Contemporary Jazz chart. This soundtrack was a 1993 Academy Award nominee for Best Original Score. All tracks composed by Dave Grusin; except where indicated In 2015 La-La Land Records issued a remastered and expanded edition, featuring the film score on disc one and the 1993 soundtrack album and bonus tracks on disc two. Italicised tracks on disc one …</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A9.tab1.1.4.4">
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_t" colspan="2" id="A9.tab1.1.4.4.1"><span class="ltx_text ltx_font_bold" id="A9.tab1.1.4.4.1.1" style="font-size:90%;">Model Predictions</span></td>
</tr>
<tr class="ltx_tr" id="A9.tab1.1.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.tab1.1.5.5.1">
<span class="ltx_inline-block ltx_align_top" id="A9.tab1.1.5.5.1.1">
<span class="ltx_p" id="A9.tab1.1.5.5.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="A9.tab1.1.5.5.1.1.1.1" style="font-size:90%;">Gemma-2-9B-Chat</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.tab1.1.5.5.2">
<span class="ltx_inline-block ltx_align_top" id="A9.tab1.1.5.5.2.1">
<span class="ltx_p" id="A9.tab1.1.5.5.2.1.1" style="width:369.9pt;"><span class="ltx_text" id="A9.tab1.1.5.5.2.1.1.1" style="font-size:90%;">Fidelity Fiduciary Bank</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A9.tab1.1.6.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.tab1.1.6.6.1">
<span class="ltx_inline-block ltx_align_top" id="A9.tab1.1.6.6.1.1">
<span class="ltx_p" id="A9.tab1.1.6.6.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="A9.tab1.1.6.6.1.1.1.1" style="font-size:90%;">Implicit RAG FT</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.tab1.1.6.6.2">
<span class="ltx_inline-block ltx_align_top" id="A9.tab1.1.6.6.2.1">
<span class="ltx_p" id="A9.tab1.1.6.6.2.1.1" style="width:369.9pt;"><span class="ltx_text ltx_font_italic" id="A9.tab1.1.6.6.2.1.1.1" style="font-size:90%;">Mary Poppins</span><span class="ltx_text" id="A9.tab1.1.6.6.2.1.1.2" style="font-size:90%;"> (1964 film)</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A9.tab1.1.7.7">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A9.tab1.1.7.7.1">
<span class="ltx_inline-block ltx_align_top" id="A9.tab1.1.7.7.1.1">
<span class="ltx_p" id="A9.tab1.1.7.7.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="A9.tab1.1.7.7.1.1.1.1" style="font-size:90%;">RAG FT with Reasoning</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A9.tab1.1.7.7.2">
<span class="ltx_inline-block ltx_align_top" id="A9.tab1.1.7.7.2.1">
<span class="ltx_p" id="A9.tab1.1.7.7.2.1.1" style="width:369.9pt;"><span class="ltx_text" id="A9.tab1.1.7.7.2.1.1.1" style="font-size:90%;">Documents 1 and 2 are useful to answer the question. </span>
<br class="ltx_break ltx_align_left ltx_centering"/>
<br class="ltx_break ltx_align_left ltx_centering"/><span class="ltx_text" id="A9.tab1.1.7.7.2.1.1.2" style="font-size:90%;">Both documents explicitly state that the song "Fidelity Fiduciary Bank" from the musical film *Mary Poppins* features the bank "Dawes, Tomes, Mousely, Grubbs Fidelity Fiduciary Bank". </span>
<br class="ltx_break ltx_align_left ltx_centering"/>
<br class="ltx_break ltx_align_left ltx_centering"/><span class="ltx_text" id="A9.tab1.1.7.7.2.1.1.3" style="font-size:90%;">Therefore, the film that features the mentioned bank is </span><span class="ltx_text ltx_align_left ltx_font_italic ltx_align_center" id="A9.tab1.1.7.7.2.1.1.4" style="font-size:90%;">Mary Poppins</span><span class="ltx_text" id="A9.tab1.1.7.7.2.1.1.5" style="font-size:90%;">.</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table" id="A9.tab2">
<table class="ltx_tabular ltx_align_middle" id="A9.tab2.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A9.tab2.1.1.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A9.tab2.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A9.tab2.1.1.1.1.1">
<span class="ltx_p" id="A9.tab2.1.1.1.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="A9.tab2.1.1.1.1.1.1.1" style="font-size:90%;">Question</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A9.tab2.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A9.tab2.1.1.1.2.1">
<span class="ltx_p" id="A9.tab2.1.1.1.2.1.1" style="width:369.9pt;"><span class="ltx_text" id="A9.tab2.1.1.1.2.1.1.1" style="font-size:90%;">Which English chemist discovered the most elements?</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A9.tab2.1.2.2">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.tab2.1.2.2.1">
<span class="ltx_inline-block ltx_align_top" id="A9.tab2.1.2.2.1.1">
<span class="ltx_p" id="A9.tab2.1.2.2.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="A9.tab2.1.2.2.1.1.1.1" style="font-size:90%;">Ground Truth</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.tab2.1.2.2.2">
<span class="ltx_inline-block ltx_align_top" id="A9.tab2.1.2.2.2.1">
<span class="ltx_p" id="A9.tab2.1.2.2.2.1.1" style="width:369.9pt;"><span class="ltx_text" id="A9.tab2.1.2.2.2.1.1.1" style="font-size:90%;">Humphry Davy</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A9.tab2.1.3.3">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.tab2.1.3.3.1">
<span class="ltx_inline-block ltx_align_top" id="A9.tab2.1.3.3.1.1">
<span class="ltx_p" id="A9.tab2.1.3.3.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="A9.tab2.1.3.3.1.1.1.1" style="font-size:90%;">Retrieved Passages</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.tab2.1.3.3.2">
<span class="ltx_inline-block ltx_align_top" id="A9.tab2.1.3.3.2.1">
<span class="ltx_p" id="A9.tab2.1.3.3.2.1.1" style="width:369.9pt;"><span class="ltx_text ltx_font_bold" id="A9.tab2.1.3.3.2.1.1.1" style="font-size:90%;">Doc 1</span><span class="ltx_text" id="A9.tab2.1.3.3.2.1.1.2" style="font-size:90%;"> (Title: Chemistry) J.J. Thomson of Cambridge University discovered the electron and soon after the French scientist Becquerel as well as the couple Pierre and Marie Curie investigated the phenomenon of radioactivity. In a series of pioneering scattering experiments Ernest Rutherford at the University of Manchester discovered the internal structure of the atom and the existence of the proton, classified and explained the different types of radioactivity and successfully transmuted the first element by bombarding nitrogen with alpha particles. His work on atomic structure was improved on by his students, the Danish physicist Niels Bohr and Henry Moseley. The electronic theory of chemical … </span>
<br class="ltx_break ltx_align_left"/>
<br class="ltx_break ltx_align_left"/><span class="ltx_text ltx_align_left ltx_font_bold" id="A9.tab2.1.3.3.2.1.1.3" style="font-size:90%;">Doc 2</span><span class="ltx_text" id="A9.tab2.1.3.3.2.1.1.4" style="font-size:90%;"> (Title: Chemistry) weights. The development of the electrochemical theory of chemical combinations occurred in the early 19th century as the result of the work of two scientists in particular, J.J. Berzelius and Humphry Davy, made possible by the prior invention of the voltaic pile by Alessandro Volta. Davy discovered nine new elements including the alkali metals by extracting them from their oxides with electric current. British William Prout first proposed ordering all the elements by their atomic weight as all atoms had a weight that was an exact multiple of the atomic weight of hydrogen. J.A.R. Newlands devised an early table of … </span>
<br class="ltx_break ltx_align_left"/><span class="ltx_text" id="A9.tab2.1.3.3.2.1.1.5" style="font-size:90%;">… </span>
<br class="ltx_break ltx_align_left"/><span class="ltx_text ltx_align_left ltx_font_bold" id="A9.tab2.1.3.3.2.1.1.6" style="font-size:90%;">Doc 40</span><span class="ltx_text" id="A9.tab2.1.3.3.2.1.1.7" style="font-size:90%;"> (Title: "History of chemistry") many had already applied the concept of atomism to chemistry. A major example was the ion theory of Svante Arrhenius which anticipated ideas about atomic substructure that did not fully develop until the 20th century. Michael Faraday was another early worker, whose major contribution to chemistry was electrochemistry, in which (among other things) a certain quantity of electricity during electrolysis or electrodeposition of metals was shown to be associated with certain quantities of chemical elements, and fixed quantities of the elements therefore with each other, in specific ratios. These findings, like those of Dalton’s combining ratios, were early clues …</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A9.tab2.1.4.4">
<td class="ltx_td ltx_align_center ltx_align_top ltx_border_t" colspan="2" id="A9.tab2.1.4.4.1"><span class="ltx_text ltx_font_bold" id="A9.tab2.1.4.4.1.1" style="font-size:90%;">Model Predictions</span></td>
</tr>
<tr class="ltx_tr" id="A9.tab2.1.5.5">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.tab2.1.5.5.1">
<span class="ltx_inline-block ltx_align_top" id="A9.tab2.1.5.5.1.1">
<span class="ltx_p" id="A9.tab2.1.5.5.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="A9.tab2.1.5.5.1.1.1.1" style="font-size:90%;">Gemma-2-9B-Chat</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.tab2.1.5.5.2">
<span class="ltx_inline-block ltx_align_top" id="A9.tab2.1.5.5.2.1">
<span class="ltx_p" id="A9.tab2.1.5.5.2.1.1" style="width:369.9pt;"><span class="ltx_text" id="A9.tab2.1.5.5.2.1.1.1" style="font-size:90%;">William Hyde Wollaston</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A9.tab2.1.6.6">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.tab2.1.6.6.1">
<span class="ltx_inline-block ltx_align_top" id="A9.tab2.1.6.6.1.1">
<span class="ltx_p" id="A9.tab2.1.6.6.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="A9.tab2.1.6.6.1.1.1.1" style="font-size:90%;">Implicit RAG FT</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.tab2.1.6.6.2">
<span class="ltx_inline-block ltx_align_top" id="A9.tab2.1.6.6.2.1">
<span class="ltx_p" id="A9.tab2.1.6.6.2.1.1" style="width:369.9pt;"><span class="ltx_text" id="A9.tab2.1.6.6.2.1.1.1" style="font-size:90%;">William Ramsay</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A9.tab2.1.7.7">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A9.tab2.1.7.7.1">
<span class="ltx_inline-block ltx_align_top" id="A9.tab2.1.7.7.1.1">
<span class="ltx_p" id="A9.tab2.1.7.7.1.1.1" style="width:42.7pt;"><span class="ltx_text ltx_font_bold" id="A9.tab2.1.7.7.1.1.1.1" style="font-size:90%;">RAG FT with Reasoning</span></span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A9.tab2.1.7.7.2">
<span class="ltx_inline-block ltx_align_top" id="A9.tab2.1.7.7.2.1">
<span class="ltx_p" id="A9.tab2.1.7.7.2.1.1" style="width:369.9pt;"><span class="ltx_text" id="A9.tab2.1.7.7.2.1.1.1" style="font-size:90%;">The best document to answer this question is **Doc 2(Chemistry)**.</span></span>
<span class="ltx_p" id="A9.tab2.1.7.7.2.1.2"><span class="ltx_text" id="A9.tab2.1.7.7.2.1.2.1" style="font-size:90%;">This document states that **Humphry Davy** "discovered nine new elements including the alkali metals by extracting them from their oxides with electric current."</span></span>
<span class="ltx_p" id="A9.tab2.1.7.7.2.1.3"><span class="ltx_text" id="A9.tab2.1.7.7.2.1.3.1" style="font-size:90%;">Therefore, the answer is </span><span class="ltx_text ltx_font_italic" id="A9.tab2.1.7.7.2.1.3.2" style="font-size:90%;">Humphry Davy</span><span class="ltx_text" id="A9.tab2.1.7.7.2.1.3.3" style="font-size:90%;">.</span></span>
<span class="ltx_p" id="A9.tab2.1.7.7.2.1.4"><span class="ltx_text" id="A9.tab2.1.7.7.2.1.4.1" style="font-size:90%;">While other documents mention chemists and their discoveries, none of them contradict or provide a higher number of discovered elements than Davy’s nine. This makes Doc 2 the most useful in identifying the English chemist who discovered the most elements.</span></span>
<span class="ltx_p" id="A9.tab2.1.7.7.2.1.5"><span class="ltx_text" id="A9.tab2.1.7.7.2.1.5.1" style="font-size:90%;">It’s important to note that this answer is based on Doc 2 alone. If other documents mentioned an English chemist who discovered more than nine elements, they would supersede the information in Doc 2. However, without that information, we can confidently say that based on these documents, Humphry Davy discovered the most elements among the English chemists mentioned.</span></span>
<span class="ltx_p" id="A9.tab2.1.7.7.2.1.6"><span class="ltx_text" id="A9.tab2.1.7.7.2.1.6.1" style="font-size:90%;">**Conclusion:** Based on the given documents, </span><span class="ltx_text ltx_font_italic" id="A9.tab2.1.7.7.2.1.6.2" style="font-size:90%;">Humphry Davy</span><span class="ltx_text" id="A9.tab2.1.7.7.2.1.6.3" style="font-size:90%;"> is the English chemist who discovered the most elements.</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="A10" lang="en">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix J </span>Data-Augmented RAG Finetuning on Gemma-2-9B</h2>
<div class="ltx_para" id="A10.p1">
<p class="ltx_p" id="A10.p1.1">In Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S5.F5" title="Figure 5 ‣ 5.1 Implicitly improving LLM robustness through fine-tuning ‣ 5 Improving Robustness for RAG via Data-Augmented Fine-Tuning ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">5</span></a>, we illustrate the performance of implicit RAG finetuning on eight datasets with three different base models due to the space limitation. The whole results with Gemma-2-9B models can be found in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A10.F11" title="Figure 11 ‣ Appendix J Data-Augmented RAG Finetuning on Gemma-2-9B ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">11</span></a>.</p>
</div>
<figure class="ltx_figure" id="A10.F11">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A10.F11.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A10.F11.sf1.g1" src="x42.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A10.F11.sf1.2.1.1" style="font-size:80%;">(a)</span> </span><span class="ltx_text" id="A10.F11.sf1.3.2" style="font-size:80%;">TriviaQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A10.F11.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A10.F11.sf2.g1" src="x43.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A10.F11.sf2.2.1.1" style="font-size:80%;">(b)</span> </span><span class="ltx_text" id="A10.F11.sf2.3.2" style="font-size:80%;">PopQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A10.F11.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A10.F11.sf3.g1" src="x44.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A10.F11.sf3.2.1.1" style="font-size:80%;">(c)</span> </span><span class="ltx_text" id="A10.F11.sf3.3.2" style="font-size:80%;">HotpotQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A10.F11.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A10.F11.sf4.g1" src="x45.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A10.F11.sf4.2.1.1" style="font-size:80%;">(d)</span> </span><span class="ltx_text" id="A10.F11.sf4.3.2" style="font-size:80%;">2wikimultihopqa</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A10.F11.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A10.F11.sf5.g1" src="x46.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A10.F11.sf5.2.1.1" style="font-size:80%;">(e)</span> </span><span class="ltx_text" id="A10.F11.sf5.3.2" style="font-size:80%;">Webquestions</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A10.F11.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A10.F11.sf6.g1" src="x47.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A10.F11.sf6.2.1.1" style="font-size:80%;">(f)</span> </span><span class="ltx_text" id="A10.F11.sf6.3.2" style="font-size:80%;">Bamboogle</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A10.F11.sf7"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A10.F11.sf7.g1" src="x48.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A10.F11.sf7.2.1.1" style="font-size:80%;">(g)</span> </span><span class="ltx_text" id="A10.F11.sf7.3.2" style="font-size:80%;">ASQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A10.F11.sf8"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A10.F11.sf8.g1" src="x49.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A10.F11.sf8.2.1.1" style="font-size:80%;">(h)</span> </span><span class="ltx_text" id="A10.F11.sf8.3.2" style="font-size:80%;">T-REx</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A10.F11.sf9"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A10.F11.sf9.g1" src="x50.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A10.F11.sf9.2.1.1" style="font-size:80%;">(i)</span> </span><span class="ltx_text" id="A10.F11.sf9.3.2" style="font-size:80%;">zsRE</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Generalization ability of LLMs fine-tuned with RAG-specific data (RAG FT). RAG FT consistently outperforms the chat LLM w. RAG and the model fine-tuned directly on question-answer pairs (Direct FT). This demonstrates the effectiveness of RAG FT in enabling the LLM to effectively extract knowledge from retrieved context on unseen tasks. Note that Direct FT is evaluated without retrieval to align with its training paradigm and all others are evaluated with retrieval augmentation. (LLM: Gemma-2-9B-Base)</figcaption>
</figure>
<div class="ltx_para" id="A10.p2">
<p class="ltx_p" id="A10.p2.1">In Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S5.F6" title="Figure 6 ‣ 5.2 Enhancing relevance identification through reasoning augmentation ‣ 5 Improving Robustness for RAG via Data-Augmented Fine-Tuning ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">6</span></a>, we show the power of RAG finetuning with intermediate reasoning on five datasets because of the space limitation. The whole results on all the nine datasets with Gemma-2-9B models can be found in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A10.F12" title="Figure 12 ‣ Appendix J Data-Augmented RAG Finetuning on Gemma-2-9B ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">12</span></a>.
Note that due to the computational complexity of inference with reasoning augmentation, results are shown for 1000 randomly-sampled queries for each dataset.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<figure class="ltx_figure" id="A10.F12">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A10.F12.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A10.F12.sf1.g1" src="x51.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A10.F12.sf1.2.1.1" style="font-size:80%;">(a)</span> </span><span class="ltx_text" id="A10.F12.sf1.3.2" style="font-size:80%;">TriviaQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A10.F12.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A10.F12.sf2.g1" src="x52.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A10.F12.sf2.2.1.1" style="font-size:80%;">(b)</span> </span><span class="ltx_text" id="A10.F12.sf2.3.2" style="font-size:80%;">PopQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A10.F12.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A10.F12.sf3.g1" src="x53.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A10.F12.sf3.2.1.1" style="font-size:80%;">(c)</span> </span><span class="ltx_text" id="A10.F12.sf3.3.2" style="font-size:80%;">HotpotQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A10.F12.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A10.F12.sf4.g1" src="x54.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A10.F12.sf4.2.1.1" style="font-size:80%;">(d)</span> </span><span class="ltx_text" id="A10.F12.sf4.3.2" style="font-size:80%;">2wikimultihopqa</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A10.F12.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A10.F12.sf5.g1" src="x55.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A10.F12.sf5.2.1.1" style="font-size:80%;">(e)</span> </span><span class="ltx_text" id="A10.F12.sf5.3.2" style="font-size:80%;">Webquestions</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A10.F12.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A10.F12.sf6.g1" src="x56.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A10.F12.sf6.2.1.1" style="font-size:80%;">(f)</span> </span><span class="ltx_text" id="A10.F12.sf6.3.2" style="font-size:80%;">Bamboogle</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A10.F12.sf7"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A10.F12.sf7.g1" src="x57.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A10.F12.sf7.2.1.1" style="font-size:80%;">(g)</span> </span><span class="ltx_text" id="A10.F12.sf7.3.2" style="font-size:80%;">ASQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A10.F12.sf8"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A10.F12.sf8.g1" src="x58.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A10.F12.sf8.2.1.1" style="font-size:80%;">(h)</span> </span><span class="ltx_text" id="A10.F12.sf8.3.2" style="font-size:80%;">T-REx</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A10.F12.sf9"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A10.F12.sf9.g1" src="x59.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A10.F12.sf9.2.1.1" style="font-size:80%;">(i)</span> </span><span class="ltx_text" id="A10.F12.sf9.3.2" style="font-size:80%;">zsRE</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Evaluating the impact of intermediate reasoning on the performance of RAG-tuned LLMs. Results demonstrate that fine-tuning with an intermediate reasoning step (RAG FT w. Int) leads to further improvements compared to implicit RAG fine-tuning (RAG FT) and direct fine-tuning (Direct FT). Direct FT is evaluated without retrieval to align with its training paradigm and all others are evaluated with retrieval augmentation. Due to the computational complexity of inference with reasoning augmentation, results are shown for 1000 randomly-sampled queries from each dataset. (LLM: Gemma-2-9B-Base)</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="A11" lang="en">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix K </span>Data-Augmented RAG Finetuning on Mistral-Nemo-12B</h2>
<div class="ltx_para" id="A11.p1">
<p class="ltx_p" id="A11.p1.1">In addition to the comprehensive data-augmented RAG fine-tuning results with three different base LLMs reported in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S5" title="5 Improving Robustness for RAG via Data-Augmented Fine-Tuning ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">5</span></a>, we also would like to show the results specifically with the Mistral-Nemo-12B models in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A11.F13" title="Figure 13 ‣ Appendix K Data-Augmented RAG Finetuning on Mistral-Nemo-12B ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">13</span></a>.</p>
</div>
<figure class="ltx_figure" id="A11.F13">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A11.F13.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A11.F13.sf1.g1" src="x60.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A11.F13.sf1.2.1.1" style="font-size:80%;">(a)</span> </span><span class="ltx_text" id="A11.F13.sf1.3.2" style="font-size:80%;">TriviaQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A11.F13.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A11.F13.sf2.g1" src="x61.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A11.F13.sf2.2.1.1" style="font-size:80%;">(b)</span> </span><span class="ltx_text" id="A11.F13.sf2.3.2" style="font-size:80%;">PopQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A11.F13.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A11.F13.sf3.g1" src="x62.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A11.F13.sf3.2.1.1" style="font-size:80%;">(c)</span> </span><span class="ltx_text" id="A11.F13.sf3.3.2" style="font-size:80%;">HotpotQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A11.F13.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A11.F13.sf4.g1" src="x63.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A11.F13.sf4.2.1.1" style="font-size:80%;">(d)</span> </span><span class="ltx_text" id="A11.F13.sf4.3.2" style="font-size:80%;">2wikimultihopqa</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A11.F13.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A11.F13.sf5.g1" src="x64.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A11.F13.sf5.2.1.1" style="font-size:80%;">(e)</span> </span><span class="ltx_text" id="A11.F13.sf5.3.2" style="font-size:80%;">Webquestions</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A11.F13.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A11.F13.sf6.g1" src="x65.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A11.F13.sf6.2.1.1" style="font-size:80%;">(f)</span> </span><span class="ltx_text" id="A11.F13.sf6.3.2" style="font-size:80%;">Bamboogle</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A11.F13.sf7"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A11.F13.sf7.g1" src="x66.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A11.F13.sf7.2.1.1" style="font-size:80%;">(g)</span> </span><span class="ltx_text" id="A11.F13.sf7.3.2" style="font-size:80%;">ASQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A11.F13.sf8"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A11.F13.sf8.g1" src="x67.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A11.F13.sf8.2.1.1" style="font-size:80%;">(h)</span> </span><span class="ltx_text" id="A11.F13.sf8.3.2" style="font-size:80%;">T-REx</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A11.F13.sf9"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A11.F13.sf9.g1" src="x68.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A11.F13.sf9.2.1.1" style="font-size:80%;">(i)</span> </span><span class="ltx_text" id="A11.F13.sf9.3.2" style="font-size:80%;">zsRE</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>Evaluating RAG-specific tuning with Mistral-Nemo-12B models. Results demonstrate that fine-tuning with an intermediate reasoning step (RAG FT w. Int) leads to further improvements compared to implicit RAG fine-tuning (RAG FT), while implicit RAG fine-tuning outperforms LLMs without RAG-specific tuning (Mistral-Nemo-12B-Chat) and direct fine-tuning (Direct FT). Direct FT is evaluated without retrieval to align with its training paradigm and all others are evaluated with retrieval augmentation. (LLM: Mistral-Nemo-12B-Base)</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="A12" lang="en">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix L </span>Data-Augmented RAG Finetuning on Gemini-1.0-Pro</h2>
<div class="ltx_para" id="A12.p1">
<p class="ltx_p" id="A12.p1.1">In addition to the comprehensive data-augmented RAG fine-tuning results with three different base LLMs reported in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S5" title="5 Improving Robustness for RAG via Data-Augmented Fine-Tuning ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">5</span></a>, we also would like to show the results specifically with the Gemini-1.0-Pro models in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A12.F14" title="Figure 14 ‣ Appendix L Data-Augmented RAG Finetuning on Gemini-1.0-Pro ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">14</span></a>.
Due to the Gemini-1.0-Pro API call credit limitation, we random sample 1000 queries for each dataset.</p>
</div>
<figure class="ltx_figure" id="A12.F14">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A12.F14.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A12.F14.sf1.g1" src="x69.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A12.F14.sf1.2.1.1" style="font-size:80%;">(a)</span> </span><span class="ltx_text" id="A12.F14.sf1.3.2" style="font-size:80%;">TriviaQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A12.F14.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A12.F14.sf2.g1" src="x70.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A12.F14.sf2.2.1.1" style="font-size:80%;">(b)</span> </span><span class="ltx_text" id="A12.F14.sf2.3.2" style="font-size:80%;">PopQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A12.F14.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A12.F14.sf3.g1" src="x71.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A12.F14.sf3.2.1.1" style="font-size:80%;">(c)</span> </span><span class="ltx_text" id="A12.F14.sf3.3.2" style="font-size:80%;">HotpotQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A12.F14.sf4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A12.F14.sf4.g1" src="x72.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A12.F14.sf4.2.1.1" style="font-size:80%;">(d)</span> </span><span class="ltx_text" id="A12.F14.sf4.3.2" style="font-size:80%;">2wikimultihopqa</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A12.F14.sf5"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A12.F14.sf5.g1" src="x73.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A12.F14.sf5.2.1.1" style="font-size:80%;">(e)</span> </span><span class="ltx_text" id="A12.F14.sf5.3.2" style="font-size:80%;">Webquestions</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A12.F14.sf6"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A12.F14.sf6.g1" src="x74.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A12.F14.sf6.2.1.1" style="font-size:80%;">(f)</span> </span><span class="ltx_text" id="A12.F14.sf6.3.2" style="font-size:80%;">Bamboogle</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A12.F14.sf7"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A12.F14.sf7.g1" src="x75.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A12.F14.sf7.2.1.1" style="font-size:80%;">(g)</span> </span><span class="ltx_text" id="A12.F14.sf7.3.2" style="font-size:80%;">ASQA</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A12.F14.sf8"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A12.F14.sf8.g1" src="x76.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A12.F14.sf8.2.1.1" style="font-size:80%;">(h)</span> </span><span class="ltx_text" id="A12.F14.sf8.3.2" style="font-size:80%;">T-REx</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="A12.F14.sf9"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="204" id="A12.F14.sf9.g1" src="x77.png" width="272"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="A12.F14.sf9.2.1.1" style="font-size:80%;">(i)</span> </span><span class="ltx_text" id="A12.F14.sf9.3.2" style="font-size:80%;">zsRE</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 14: </span>Evaluating RAG-specific tuning with Gemini-1.0-Pro models. Results demonstrate that fine-tuning with an intermediate reasoning step (RAG FT w. Int) leads to further improvements compared to implicit RAG fine-tuning (RAG FT), while implicit RAG fine-tuning outperforms LLMs without RAG-specific tuning (Gemini-1.0-Pro) and direct fine-tuning (Direct FT). Direct FT is evaluated without retrieval to align with its training paradigm and all others are evaluated with retrieval augmentation. Due to the Gemini-1.0-Pro API call credit limitation, results are shown for 1000 randomly-sampled queries from each dataset. (LLM: Gemini-1.0-Pro)</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section class="ltx_appendix" id="A13" lang="en">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix M </span>Training data scaling and RAG performance.</h2>
<figure class="ltx_table" id="A13.T11">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A13.T11.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A13.T11.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A13.T11.1.1.1.1"><span class="ltx_text" id="A13.T11.1.1.1.1.1" style="font-size:90%;">Number of Retrieval Passages</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A13.T11.1.1.1.2"><span class="ltx_text" id="A13.T11.1.1.1.2.1" style="font-size:90%;">5k</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A13.T11.1.1.1.3"><span class="ltx_text" id="A13.T11.1.1.1.3.1" style="font-size:90%;">20k</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A13.T11.1.1.1.4"><span class="ltx_text" id="A13.T11.1.1.1.4.1" style="font-size:90%;">50k</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A13.T11.1.1.1.5"><span class="ltx_text" id="A13.T11.1.1.1.5.1" style="font-size:90%;">200k</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A13.T11.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A13.T11.1.2.1.1"><span class="ltx_text" id="A13.T11.1.2.1.1.1" style="font-size:90%;">10</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A13.T11.1.2.1.2"><span class="ltx_text" id="A13.T11.1.2.1.2.1" style="font-size:90%;">0.5942</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A13.T11.1.2.1.3"><span class="ltx_text" id="A13.T11.1.2.1.3.1" style="font-size:90%;">0.5925</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A13.T11.1.2.1.4"><span class="ltx_text" id="A13.T11.1.2.1.4.1" style="font-size:90%;">0.6058</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A13.T11.1.2.1.5"><span class="ltx_text" id="A13.T11.1.2.1.5.1" style="font-size:90%;">0.6277</span></td>
</tr>
<tr class="ltx_tr" id="A13.T11.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A13.T11.1.3.2.1"><span class="ltx_text" id="A13.T11.1.3.2.1.1" style="font-size:90%;">20</span></th>
<td class="ltx_td ltx_align_center" id="A13.T11.1.3.2.2"><span class="ltx_text" id="A13.T11.1.3.2.2.1" style="font-size:90%;">0.5909</span></td>
<td class="ltx_td ltx_align_center" id="A13.T11.1.3.2.3"><span class="ltx_text" id="A13.T11.1.3.2.3.1" style="font-size:90%;">0.5925</span></td>
<td class="ltx_td ltx_align_center" id="A13.T11.1.3.2.4"><span class="ltx_text" id="A13.T11.1.3.2.4.1" style="font-size:90%;">0.6078</span></td>
<td class="ltx_td ltx_align_center" id="A13.T11.1.3.2.5"><span class="ltx_text" id="A13.T11.1.3.2.5.1" style="font-size:90%;">0.6294</span></td>
</tr>
<tr class="ltx_tr" id="A13.T11.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A13.T11.1.4.3.1"><span class="ltx_text" id="A13.T11.1.4.3.1.1" style="font-size:90%;">30</span></th>
<td class="ltx_td ltx_align_center" id="A13.T11.1.4.3.2"><span class="ltx_text" id="A13.T11.1.4.3.2.1" style="font-size:90%;">0.5787</span></td>
<td class="ltx_td ltx_align_center" id="A13.T11.1.4.3.3"><span class="ltx_text" id="A13.T11.1.4.3.3.1" style="font-size:90%;">0.5792</span></td>
<td class="ltx_td ltx_align_center" id="A13.T11.1.4.3.4"><span class="ltx_text" id="A13.T11.1.4.3.4.1" style="font-size:90%;">0.6072</span></td>
<td class="ltx_td ltx_align_center" id="A13.T11.1.4.3.5"><span class="ltx_text" id="A13.T11.1.4.3.5.1" style="font-size:90%;">0.6150</span></td>
</tr>
<tr class="ltx_tr" id="A13.T11.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="A13.T11.1.5.4.1"><span class="ltx_text" id="A13.T11.1.5.4.1.1" style="font-size:90%;">40</span></th>
<td class="ltx_td ltx_align_center" id="A13.T11.1.5.4.2"><span class="ltx_text" id="A13.T11.1.5.4.2.1" style="font-size:90%;">0.5582</span></td>
<td class="ltx_td ltx_align_center" id="A13.T11.1.5.4.3"><span class="ltx_text" id="A13.T11.1.5.4.3.1" style="font-size:90%;">0.5582</span></td>
<td class="ltx_td ltx_align_center" id="A13.T11.1.5.4.4"><span class="ltx_text" id="A13.T11.1.5.4.4.1" style="font-size:90%;">0.5859</span></td>
<td class="ltx_td ltx_align_center" id="A13.T11.1.5.4.5"><span class="ltx_text" id="A13.T11.1.5.4.5.1" style="font-size:90%;">0.5983</span></td>
</tr>
<tr class="ltx_tr" id="A13.T11.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="A13.T11.1.6.5.1"><span class="ltx_text" id="A13.T11.1.6.5.1.1" style="font-size:90%;">Avg.</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A13.T11.1.6.5.2"><span class="ltx_text" id="A13.T11.1.6.5.2.1" style="font-size:90%;">0.5805</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A13.T11.1.6.5.3"><span class="ltx_text" id="A13.T11.1.6.5.3.1" style="font-size:90%;">0.5806</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A13.T11.1.6.5.4"><span class="ltx_text" id="A13.T11.1.6.5.4.1" style="font-size:90%;">0.6017</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A13.T11.1.6.5.5"><span class="ltx_text" id="A13.T11.1.6.5.5.1" style="font-size:90%;">0.6176</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 11: </span>Impact of RAG-specific training data scale on LLM performance in RAG.</figcaption>
</figure>
<div class="ltx_para" id="A13.p1">
<p class="ltx_p" id="A13.p1.1">To investigate the influence of the size of the training data on the effectiveness of RAG-specific tuning, we fine-tune the Gemma-2-9B-Base model using varying amounts (5k to 200k samples) of mixed training data from NQ, WoW, Fever, and MMLU.
Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A13.T11" title="Table 11 ‣ Appendix M Training data scaling and RAG performance. ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">11</span></a> presents the evaluation results on the NQ dataset, demonstrating a clear positive correlation between the scale of training data and the performance of the resulting LLM in RAG.
Increasing the amount of training data consistently leads to improved accuracy, highlighting the benefits of leveraging larger datasets for fine-tuning LLMs in RAG applications.</p>
</div>
</section>
<section class="ltx_appendix" id="A14" lang="en">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix N </span>RAG-specific tuning data inside SFT mixtures</h2>
<figure class="ltx_table" id="A14.T12">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A14.T12.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A14.T12.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="A14.T12.1.1.1.1"><span class="ltx_text" id="A14.T12.1.1.1.1.1" style="font-size:90%;">Dataset</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A14.T12.1.1.1.2"><span class="ltx_text" id="A14.T12.1.1.1.2.1" style="font-size:90%;">base</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A14.T12.1.1.1.3"><span class="ltx_text" id="A14.T12.1.1.1.3.1" style="font-size:90%;">SFT only</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A14.T12.1.1.1.4"><span class="ltx_text" id="A14.T12.1.1.1.4.1" style="font-size:90%;">SFT + RAG-FT</span></th>
</tr>
<tr class="ltx_tr" id="A14.T12.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t" id="A14.T12.1.2.2.1"><span class="ltx_text" id="A14.T12.1.2.2.1.1" style="font-size:90%;">MT-Bench</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A14.T12.1.2.2.2"><span class="ltx_text" id="A14.T12.1.2.2.2.1" style="font-size:90%;">2.3125</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A14.T12.1.2.2.3"><span class="ltx_text" id="A14.T12.1.2.2.3.1" style="font-size:90%;">5.8969</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="A14.T12.1.2.2.4"><span class="ltx_text" id="A14.T12.1.2.2.4.1" style="font-size:90%;">5.6031</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A14.T12.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="A14.T12.1.3.1.1"><span class="ltx_text" id="A14.T12.1.3.1.1.1" style="font-size:90%;">NQ</span></th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A14.T12.1.3.1.2"><span class="ltx_text" id="A14.T12.1.3.1.2.1" style="font-size:90%;">0.2105</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A14.T12.1.3.1.3"><span class="ltx_text" id="A14.T12.1.3.1.3.1" style="font-size:90%;">0.5687</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A14.T12.1.3.1.4"><span class="ltx_text" id="A14.T12.1.3.1.4.1" style="font-size:90%;">0.6033</span></td>
</tr>
<tr class="ltx_tr" id="A14.T12.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="A14.T12.1.4.2.1"><span class="ltx_text" id="A14.T12.1.4.2.1.1" style="font-size:90%;">TriviaQA</span></th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A14.T12.1.4.2.2"><span class="ltx_text" id="A14.T12.1.4.2.2.1" style="font-size:90%;">0.4940</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A14.T12.1.4.2.3"><span class="ltx_text" id="A14.T12.1.4.2.3.1" style="font-size:90%;">0.7155</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A14.T12.1.4.2.4"><span class="ltx_text" id="A14.T12.1.4.2.4.1" style="font-size:90%;">0.7481</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 12: </span>Combining RAG-specific data with general SFT data for enhanced LLM performance in RAG.</figcaption>
</figure>
<div class="ltx_para" id="A14.p1">
<p class="ltx_p" id="A14.p1.1">Having established the effectiveness of RAG-specific fine-tuning for improving LLM performance in RAG tasks, we now investigate whether combining RAG-specific data with general SFT data can further enhance performance while preserving the LLM’s general capabilities (<span class="ltx_text ltx_font_italic" id="A14.p1.1.1">e.g.</span>, reasoning and long-form generation), as a way to assess the potential of the proposed tuning methods to be useful for construction of foundation models.
We train the Gemma-2-9B model using two different strategies:
(1) SFT data only: The LLM is trained solely on general SFT data (Ultrachat 200k).
(2) SFT data + RAG-specific data: The LLM is trained on a combination of Ultrachat 200k and 50k RAG-specific data (the same data used in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#S5.F5" title="Figure 5 ‣ 5.1 Implicitly improving LLM robustness through fine-tuning ‣ 5 Improving Robustness for RAG via Data-Augmented Fine-Tuning ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">5</span></a>).
We evaluate the resulting models on MT-Bench to assess their general language capabilities and on NQ and TriviaQA to measure their RAG performance.</p>
</div>
<div class="ltx_para" id="A14.p2">
<p class="ltx_p" id="A14.p2.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05983v1#A14.T12" title="Table 12 ‣ Appendix N RAG-specific tuning data inside SFT mixtures ‣ Long-Context LLMs Meet RAG: Overcoming Challenges for Long Inputs in RAG"><span class="ltx_text ltx_ref_tag">12</span></a> presents the results, demonstrating that incorporating RAG-specific data into the SFT process can significantly improve the LLM’s performance on RAG tasks while maintaining its performance on general language tasks.
This finding suggests that combining task-specific and general-purpose data during fine-tuning can be a viable strategy for enhancing LLMs in specialized applications without compromising their overall capabilities.</p>
</div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Oct  8 12:28:12 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
