<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Data Extrapolation for Text-to-image Generation on Small Datasets</title>
<!--Generated on Wed Oct  2 15:05:20 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.01638v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S1" title="In Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S2" title="In Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S2.SS0.SSS0.Px1" title="In 2 Related work ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title">GAN-based text-to-image models.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S2.SS0.SSS0.Px2" title="In 2 Related work ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title">Diffusion-based text-to-image models.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S2.SS0.SSS0.Px3" title="In 2 Related work ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title">Data augmentation methods.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S3" title="In Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span> Linear Extrapolation for Text-to-image Generation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S3.SS1" title="In 3 Linear Extrapolation for Text-to-image Generation ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Collecting Similar and Clean Images</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S3.SS2" title="In 3 Linear Extrapolation for Text-to-image Generation ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Linear Extrapolation on Text Feature Space</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S3.SS3" title="In 3 Linear Extrapolation for Text-to-image Generation ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Recurrent Diffusion Transformer on Latent Space</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S3.SS3.SSS0.Px1" title="In 3.3 Recurrent Diffusion Transformer on Latent Space ‣ 3 Linear Extrapolation for Text-to-image Generation ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title">Network architecture.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S3.SS3.SSS0.Px2" title="In 3.3 Recurrent Diffusion Transformer on Latent Space ‣ 3 Linear Extrapolation for Text-to-image Generation ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title">Early stop of fine-tuning.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S3.SS4" title="In 3 Linear Extrapolation for Text-to-image Generation ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Synthesizing Fake Images</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S3.SS4.SSS0.Px1" title="In 3.4 Synthesizing Fake Images ‣ 3 Linear Extrapolation for Text-to-image Generation ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title">NULL guidance.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4" title="In Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.SS0.SSS0.Px1" title="In 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title">Datasets.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.SS0.SSS0.Px2" title="In 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title">Web images.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.SS0.SSS0.Px3" title="In 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title">Training details.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.SS0.SSS0.Px4" title="In 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title">Evaluation metrics.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.SS0.SSS0.Px5" title="In 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title">Compared models.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.SS1" title="In 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Comparisons with Others</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.SS1.SSS0.Px1" title="In 4.1 Comparisons with Others ‣ 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title">Quantitative results.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.SS1.SSS0.Px2" title="In 4.1 Comparisons with Others ‣ 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title">Qualitative results.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.SS2" title="In 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Ablation Studies</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.SS2.SSS0.Px1" title="In 4.2 Ablation Studies ‣ 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title">Analysis of outlier detectors.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.SS2.SSS0.Px2" title="In 4.2 Ablation Studies ‣ 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title">Analysis of extrapolation quantity.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.SS2.SSS0.Px3" title="In 4.2 Ablation Studies ‣ 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title">Analysis of NULL guidance.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.SS2.SSS0.Px4" title="In 4.2 Ablation Studies ‣ 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title">Analysis of text injection.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.SS2.SSS0.Px5" title="In 4.2 Ablation Studies ‣ 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title">Ablation studies on the MS COCO dataset.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.SS2.SSS0.Px6" title="In 4.2 Ablation Studies ‣ 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title">Diversity.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S5" title="In Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion and Future work</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Data Extrapolation for Text-to-image Generation on Small Datasets</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Senmao Ye
<br class="ltx_break"/>South China University of Technology
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">senmaoy@gmail.com
<br class="ltx_break"/></span>&amp;Fei Liu
<br class="ltx_break"/>South China University of Technology
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id2.2.id2">feiliu@scut.edu.cn
<br class="ltx_break"/></span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id3.id1">Text-to-image generation requires large amount of training data to synthesizing high-quality images. For augmenting training data, previous methods rely on data interpolations like cropping, flipping, and mixing up, which fail to introduce new information and yield only marginal improvements. In this paper, we propose a new data augmentation method for text-to-image generation using linear extrapolation.
Specifically, we apply linear extrapolation only on text feature, and new image data are retrieved from the internet by search engines. For the reliability of new text-image pairs, we design two outlier detectors to purify retrieved images. Based on extrapolation, we construct training samples dozens of times larger than the original dataset, resulting in a significant improvement in text-to-image performance. Moreover, we propose a NULL-guidance to refine score estimation, and apply recurrent affine transformation to fuse text information. Our model achieves FID scores of 7.91, 9.52 and 5.00 on the CUB, Oxford and COCO datasets. The code and data will be available on GitHub.</p>
</div>
<figure class="ltx_figure ltx_align_floatright" id="S0.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="239" id="S0.F1.1.g1" src="x1.png" width="320"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An illustration of data linear extrapolation. We use search engine and outlier detectors to ensure the image similarity. Extrapolation produces much more text-image pairs than the original dataset.</figcaption>
</figure>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para ltx_noindent" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Text-to-image generation aims to synthesize images according to textual descriptions. As the bridge between human language and generative models, text-to-image generation  <cite class="ltx_cite ltx_citemacro_citep">(Reed et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib27" title="">2016b</a>; Ye et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib42" title="">2023</a>; Sauer et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib32" title="">2023</a>; Rombach et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib28" title="">2022</a>; Ramesh et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib25" title="">2022</a>)</cite>is applied to more and more application domains, such as digital human <cite class="ltx_cite ltx_citemacro_citep">(Yin &amp; Li, <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib43" title="">2023</a>)</cite>, image editing <cite class="ltx_cite ltx_citemacro_citep">(Brack et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib3" title="">2024</a>)</cite>, and computer-aided design <cite class="ltx_cite ltx_citemacro_citep">(Liu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib17" title="">2023</a>)</cite>.
The diversity of applications leads to a large number of small datasets, where existing data are not sufficient to train high-quality generative models, and generative large models cannot overcome the long-tail effect of diverse applications.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">To augment training data, existing methods typically rely on data interpolation techniques such as cropping, flipping, and mixing up images <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib46" title="">2017</a>)</cite>. While these methods leverage human knowledge to create new perspectives on existing images or features, they do not introduce new information and yield only marginal improvements. Additionally, Retrieval-base models <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib4" title="">2022</a>; Sheynin et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib33" title="">2022</a>; Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib16" title="">2022</a>)</cite> employs retrieval methods to gather relevant training data from external databases like WikiImages. However, these external databases often contain very few images for specific entries, and their description styles differ significantly from those in text-to-image datasets. Furthermore, VQ-diffusion <cite class="ltx_cite ltx_citemacro_citep">(Gu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib8" title="">2022</a>)</cite> pre-trains its text-to-image model on the Conceptual Caption dataset with 15 million images, but the resulting improvements are not obvious.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In this paper, we explore data linear extrapolation to augment training data. Linear extrapolation can be risky, as similar text-image pairs may not be nearby in Euclidean space. For information reliability, as depicted in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S0.F1" title="Figure 1 ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_tag">1</span></a>, we explore linear extrapolation only on text data, and new image data are retrieved from the internet by search engines. And then outlier detectors are designed to purify retrieved web images. In this way, the reliability of new text-image pairs are guaranteed by search precision and outlier detection.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">To detect outliers from web images, we divide outliers into irrelevant and similar ones. For detecting irrelevant outliers, K-means <cite class="ltx_cite ltx_citemacro_citep">(Lloyd, <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib18" title="">1982</a>)</cite> algorithm is used to cluster noisy web images into similar images and outliers. In the image feature space generated by a CLIP encoder <cite class="ltx_cite ltx_citemacro_citep">(Radford et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib24" title="">2021</a>)</cite>, similar images will be close to dataset images, while outliers will be far away. Based on this observation, we remove images that differ significantly from dataset images. For detecting similar outliers, each web image is assigned a label by a fine-grained classifier trained on the original dataset. If the label does not match the search keyword, the image is considered as an outlier and removed. For every purified web image, we extrapolate a new text descriptions according to the local manifold of dataset images. Based on extrapolation, we construct training samples dozens of times larger than the original dataset.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">Moreover, we propose NULL-condition guidance to refine score estimation for text-to-image generation. Classifier-free guidance <cite class="ltx_cite ltx_citemacro_citep">(Ho &amp; Salimans, <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib10" title="">2022</a>)</cite> uses a dummy label to refine label-conditioned image synthesis. Similarly, in text-to-image generation, such a dummy label can be replaced by a prompt with no new physical meaning. For example, “a picture of bird” provides no information for the CUB dataset “a picture of flower” provides no information for the Oxford dataset). In addition, we apply recurrent affine transformation (RAT) in the diffusion model for handling complex textual information.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">The contributions of this paper are summarized as follows:</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p7">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We propose a new data augmentation method for text-to-image generation using linear extrapolation. Specifically, we apply linear extrapolation only on text feature, and new image data are retrieved from the internet by search engines.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We propose a NULL-condition guidance to refine the score estimation for text-to-image generation. This guidance is also applicable to existing text-to-image models without further training.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para ltx_noindent" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We apply recurrent affine transformation in the diffusion model for handling complex textual information.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">GAN-based text-to-image models.</h4>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">Text-to-image synthesis is a key task within conditional image synthesis <cite class="ltx_cite ltx_citemacro_citep">(Feng et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib5" title="">2022</a>; Tan et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib36" title="">2022</a>; Peng et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib23" title="">2021</a>; Hou et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib12" title="">2022</a>)</cite>. The pioneering work of <cite class="ltx_cite ltx_citemacro_citep">(Reed et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib27" title="">2016b</a>)</cite> first tackled this task using conditional GANs <cite class="ltx_cite ltx_citemacro_citep">(Mirza &amp; Osindero, <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib20" title="">2014</a>)</cite>. To better integrate text information into the synthesis process, DF-GAN <cite class="ltx_cite ltx_citemacro_citep">(Tao et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib37" title="">2022</a>)</cite> introduced a deep fusion method featuring multiple affine layers within a single block. Unlike previous approaches, DF-GAN eliminated the normalization operation without sacrificing performance, thus reducing computational demands and alleviating limitations associated with large batch sizes. Building on DF-GAN, RAT-GAN employed a recurrent neural network to progressively incorporate text information into the synthesized images. GALIP <cite class="ltx_cite ltx_citemacro_citep">(Tao et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib38" title="">2023</a>)</cite> and StyleGAN-T <cite class="ltx_cite ltx_citemacro_citep">(Sauer et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib32" title="">2023</a>)</cite> explore the potential of combining GAN models with transformers for large-scale text-to-image synthesis. However, the aforementioned GAN-based models often struggle to produce high-quality images.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Diffusion-based text-to-image models.</h4>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1">Recently, diffusion models <cite class="ltx_cite ltx_citemacro_citep">(Ho et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib11" title="">2020</a>; Song &amp; Ermon, <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib34" title="">2019</a>; Song et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib35" title="">2021</a>; Hyvärinen, <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib13" title="">2005</a>)</cite> have demonstrated impressive generation performance across various tasks. Building on this success, Imagen <cite class="ltx_cite ltx_citemacro_citep">(Saharia et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib30" title="">2022</a>)</cite> and DALL·E 2 <cite class="ltx_cite ltx_citemacro_citep">(Ramesh et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib25" title="">2022</a>)</cite> can synthesize images that are sufficiently realistic for real-world applications. To alleviate computational burdens, they first generate 64×64 images and then upsample them to high-resolution using another diffusion model. Additionally, the Latent Diffusion Model <cite class="ltx_cite ltx_citemacro_citep">(Rombach et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib28" title="">2022</a>)</cite> encodes high-resolution images into low-resolution latent codes, avoiding the exponential computation costs associated with increased resolution. DiT <cite class="ltx_cite ltx_citemacro_citep">(Peebles &amp; Xie, <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib22" title="">2023</a>)</cite> integrated latent diffusion models and transformers to enhance performance on large datasets. VQ-Diffusion <cite class="ltx_cite ltx_citemacro_citep">(Gu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib8" title="">2022</a>)</cite> pre-train their text-to-image model on the Conceptual Caption dataset, which contains 15 million text-image pairs, and then fine-tune it on smaller datasets like CUB, Oxford, and COCO. Hence, VQ-Diffusion is the work most similar to ours but we use significantly less pre-training data while achieving better results.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Data augmentation methods.</h4>
<div class="ltx_para ltx_noindent" id="S2.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p1.1">Data augmentation increases training data to improve the performance of deep learning applications, from image classification <cite class="ltx_cite ltx_citemacro_citep">(Krizhevsky et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib14" title="">2012</a>)</cite> to speech recognition <cite class="ltx_cite ltx_citemacro_citep">(Graves et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib7" title="">2013</a>; Amodei et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib1" title="">2016</a>)</cite>. Common techniques include rotation, translation, cropping, resizing, flipping <cite class="ltx_cite ltx_citemacro_citep">(LeCun et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib15" title="">2015</a>; Vedaldi &amp; Zisserman, <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib39" title="">2016</a>)</cite>, and random erasing <cite class="ltx_cite ltx_citemacro_citep">(Zhong et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib48" title="">2020</a>)</cite> to promote visually plausible invariances. Similarly, label smoothing is widely used to boost the robustness and accuracy of trained models <cite class="ltx_cite ltx_citemacro_citep">(Müller et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib21" title="">2019</a>; Lukasik et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib19" title="">2020</a>)</cite>. Mixup <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib46" title="">2017</a>)</cite> involves training a neural network on convex combinations of examples and their labels. However, interpolated samples fail to introduce new information and effectively address data scarcity. Hence, Re-imagen <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib4" title="">2022</a>; Sheynin et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib33" title="">2022</a>; Li et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib16" title="">2022</a>)</cite> retrieval relevant training data from external databases to augment training data.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span> Linear Extrapolation for Text-to-image Generation</h2>
<div class="ltx_para ltx_noindent" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we begin by collecting similar images from the internet. Next, we explain how to extrapolate text descriptions. Following that, we use the extrapolated text-image pairs to train a diffusion model with RAT blocks. Finally, we sample images using NULL-condition guidance.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Collecting Similar and Clean Images</h3>
<div class="ltx_para ltx_noindent" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Linear extrapolation requires the images to be sufficiently close in semantic space. Hence, we automatically retrieve similar images by searching for their classification labels. However, search engines return both similar images and outliers. To eliminate unwanted outliers, we employ a cluster detector for irrelevant outliers and a classification detector for similar outliers. For the cluster detector, each image is encoded into a vector using the CLIP image encoder. Images retrieved with the same keyword are then clustered using K-means. If the distance from the cluster center to dataset images exceeds a threshold, this cluster is excluded. For the classification detector, we train a fine-grained classification model on the original dataset, which assigns a label to each web image. If the label does not match with the search keyword, corresponding image is then excluded.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Linear Extrapolation on Text Feature Space</h3>
<div class="ltx_para ltx_noindent" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.3">Here we introduce how to extrapolates text descriptions for web images. Assuming that web images are sufficiently close to dataset images in semantic space, each web image can be represented by nearest k images:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\operatorname*{arg\,min}_{W}|\textbf{f }-\textbf{F}\times\textbf{w}|^{2}," class="ltx_Math" display="block" id="S3.E1.m1.1"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><munder id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml"><mrow id="S3.E1.m1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.2.2.cmml"><mi id="S3.E1.m1.1.1.1.1.2.2.2" xref="S3.E1.m1.1.1.1.1.2.2.2.cmml">arg</mi><mo id="S3.E1.m1.1.1.1.1.2.2.1" lspace="0.170em" xref="S3.E1.m1.1.1.1.1.2.2.1.cmml">⁢</mo><mi id="S3.E1.m1.1.1.1.1.2.2.3" xref="S3.E1.m1.1.1.1.1.2.2.3.cmml">min</mi></mrow><mi id="S3.E1.m1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.2.3.cmml">W</mi></munder><mo id="S3.E1.m1.1.1.1.1a" xref="S3.E1.m1.1.1.1.1.cmml">⁡</mo><msup id="S3.E1.m1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.2.cmml"><mo id="S3.E1.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.2.1.cmml">|</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2a.cmml">f </mtext><mo id="S3.E1.m1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml">−</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.1.1.1.1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.2a.cmml">F</mtext><mo id="S3.E1.m1.1.1.1.1.1.1.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.1.cmml">×</mo><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.1.1.1.1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.3a.cmml">w</mtext></mrow></mrow><mo id="S3.E1.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.1.1.1.1.1.1.2.1.cmml">|</mo></mrow><mn id="S3.E1.m1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.3.cmml">2</mn></msup></mrow><mo id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><apply id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.2">subscript</csymbol><apply id="S3.E1.m1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2"><times id="S3.E1.m1.1.1.1.1.2.2.1.cmml" xref="S3.E1.m1.1.1.1.1.2.2.1"></times><ci id="S3.E1.m1.1.1.1.1.2.2.2.cmml" xref="S3.E1.m1.1.1.1.1.2.2.2">arg</ci><ci id="S3.E1.m1.1.1.1.1.2.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.2.3">min</ci></apply><ci id="S3.E1.m1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.2.3">𝑊</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1">superscript</csymbol><apply id="S3.E1.m1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1"><abs id="S3.E1.m1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2"></abs><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1"><minus id="S3.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.1"></minus><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.2a.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.2">f </mtext></ci><apply id="S3.E1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3"><times id="S3.E1.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.1"></times><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.3.2a.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.2"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.2">F</mtext></ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.1.3.3a.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.3"><mtext class="ltx_mathvariant_bold" id="S3.E1.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1.3.3">w</mtext></ci></apply></apply></apply><cn id="S3.E1.m1.1.1.1.1.1.3.cmml" type="integer" xref="S3.E1.m1.1.1.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">\operatorname*{arg\,min}_{W}|\textbf{f }-\textbf{F}\times\textbf{w}|^{2},</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.1d">start_OPERATOR roman_arg roman_min end_OPERATOR start_POSTSUBSCRIPT italic_W end_POSTSUBSCRIPT | f - F × w | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p1.2">where <math alttext="\textbf{w}=[w_{1},w_{2},...,w_{k}]" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.4"><semantics id="S3.SS2.p1.1.m1.4a"><mrow id="S3.SS2.p1.1.m1.4.4" xref="S3.SS2.p1.1.m1.4.4.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p1.1.m1.4.4.5" xref="S3.SS2.p1.1.m1.4.4.5a.cmml">w</mtext><mo id="S3.SS2.p1.1.m1.4.4.4" xref="S3.SS2.p1.1.m1.4.4.4.cmml">=</mo><mrow id="S3.SS2.p1.1.m1.4.4.3.3" xref="S3.SS2.p1.1.m1.4.4.3.4.cmml"><mo id="S3.SS2.p1.1.m1.4.4.3.3.4" stretchy="false" xref="S3.SS2.p1.1.m1.4.4.3.4.cmml">[</mo><msub id="S3.SS2.p1.1.m1.2.2.1.1.1" xref="S3.SS2.p1.1.m1.2.2.1.1.1.cmml"><mi id="S3.SS2.p1.1.m1.2.2.1.1.1.2" xref="S3.SS2.p1.1.m1.2.2.1.1.1.2.cmml">w</mi><mn id="S3.SS2.p1.1.m1.2.2.1.1.1.3" xref="S3.SS2.p1.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.p1.1.m1.4.4.3.3.5" xref="S3.SS2.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.SS2.p1.1.m1.3.3.2.2.2" xref="S3.SS2.p1.1.m1.3.3.2.2.2.cmml"><mi id="S3.SS2.p1.1.m1.3.3.2.2.2.2" xref="S3.SS2.p1.1.m1.3.3.2.2.2.2.cmml">w</mi><mn id="S3.SS2.p1.1.m1.3.3.2.2.2.3" xref="S3.SS2.p1.1.m1.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S3.SS2.p1.1.m1.4.4.3.3.6" xref="S3.SS2.p1.1.m1.4.4.3.4.cmml">,</mo><mi id="S3.SS2.p1.1.m1.1.1" mathvariant="normal" xref="S3.SS2.p1.1.m1.1.1.cmml">…</mi><mo id="S3.SS2.p1.1.m1.4.4.3.3.7" xref="S3.SS2.p1.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.SS2.p1.1.m1.4.4.3.3.3" xref="S3.SS2.p1.1.m1.4.4.3.3.3.cmml"><mi id="S3.SS2.p1.1.m1.4.4.3.3.3.2" xref="S3.SS2.p1.1.m1.4.4.3.3.3.2.cmml">w</mi><mi id="S3.SS2.p1.1.m1.4.4.3.3.3.3" xref="S3.SS2.p1.1.m1.4.4.3.3.3.3.cmml">k</mi></msub><mo id="S3.SS2.p1.1.m1.4.4.3.3.8" stretchy="false" xref="S3.SS2.p1.1.m1.4.4.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.4b"><apply id="S3.SS2.p1.1.m1.4.4.cmml" xref="S3.SS2.p1.1.m1.4.4"><eq id="S3.SS2.p1.1.m1.4.4.4.cmml" xref="S3.SS2.p1.1.m1.4.4.4"></eq><ci id="S3.SS2.p1.1.m1.4.4.5a.cmml" xref="S3.SS2.p1.1.m1.4.4.5"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p1.1.m1.4.4.5.cmml" xref="S3.SS2.p1.1.m1.4.4.5">w</mtext></ci><list id="S3.SS2.p1.1.m1.4.4.3.4.cmml" xref="S3.SS2.p1.1.m1.4.4.3.3"><apply id="S3.SS2.p1.1.m1.2.2.1.1.1.cmml" xref="S3.SS2.p1.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS2.p1.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS2.p1.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS2.p1.1.m1.2.2.1.1.1.2">𝑤</ci><cn id="S3.SS2.p1.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS2.p1.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS2.p1.1.m1.3.3.2.2.2.cmml" xref="S3.SS2.p1.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS2.p1.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SS2.p1.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS2.p1.1.m1.3.3.2.2.2.2">𝑤</ci><cn id="S3.SS2.p1.1.m1.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS2.p1.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">…</ci><apply id="S3.SS2.p1.1.m1.4.4.3.3.3.cmml" xref="S3.SS2.p1.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p1.1.m1.4.4.3.3.3.1.cmml" xref="S3.SS2.p1.1.m1.4.4.3.3.3">subscript</csymbol><ci id="S3.SS2.p1.1.m1.4.4.3.3.3.2.cmml" xref="S3.SS2.p1.1.m1.4.4.3.3.3.2">𝑤</ci><ci id="S3.SS2.p1.1.m1.4.4.3.3.3.3.cmml" xref="S3.SS2.p1.1.m1.4.4.3.3.3.3">𝑘</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.4c">\textbf{w}=[w_{1},w_{2},...,w_{k}]</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.4d">w = [ italic_w start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_w start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_w start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ]</annotation></semantics></math>are the reconstruction weights and <math alttext="\textbf{F}=[\textbf{f}_{1},\textbf{f}_{2},...,\textbf{f}_{k}]" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.4"><semantics id="S3.SS2.p1.2.m2.4a"><mrow id="S3.SS2.p1.2.m2.4.4" xref="S3.SS2.p1.2.m2.4.4.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p1.2.m2.4.4.5" xref="S3.SS2.p1.2.m2.4.4.5a.cmml">F</mtext><mo id="S3.SS2.p1.2.m2.4.4.4" xref="S3.SS2.p1.2.m2.4.4.4.cmml">=</mo><mrow id="S3.SS2.p1.2.m2.4.4.3.3" xref="S3.SS2.p1.2.m2.4.4.3.4.cmml"><mo id="S3.SS2.p1.2.m2.4.4.3.3.4" stretchy="false" xref="S3.SS2.p1.2.m2.4.4.3.4.cmml">[</mo><msub id="S3.SS2.p1.2.m2.2.2.1.1.1" xref="S3.SS2.p1.2.m2.2.2.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p1.2.m2.2.2.1.1.1.2" xref="S3.SS2.p1.2.m2.2.2.1.1.1.2a.cmml">f</mtext><mn id="S3.SS2.p1.2.m2.2.2.1.1.1.3" xref="S3.SS2.p1.2.m2.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.p1.2.m2.4.4.3.3.5" xref="S3.SS2.p1.2.m2.4.4.3.4.cmml">,</mo><msub id="S3.SS2.p1.2.m2.3.3.2.2.2" xref="S3.SS2.p1.2.m2.3.3.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p1.2.m2.3.3.2.2.2.2" xref="S3.SS2.p1.2.m2.3.3.2.2.2.2a.cmml">f</mtext><mn id="S3.SS2.p1.2.m2.3.3.2.2.2.3" xref="S3.SS2.p1.2.m2.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S3.SS2.p1.2.m2.4.4.3.3.6" xref="S3.SS2.p1.2.m2.4.4.3.4.cmml">,</mo><mi id="S3.SS2.p1.2.m2.1.1" mathvariant="normal" xref="S3.SS2.p1.2.m2.1.1.cmml">…</mi><mo id="S3.SS2.p1.2.m2.4.4.3.3.7" xref="S3.SS2.p1.2.m2.4.4.3.4.cmml">,</mo><msub id="S3.SS2.p1.2.m2.4.4.3.3.3" xref="S3.SS2.p1.2.m2.4.4.3.3.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p1.2.m2.4.4.3.3.3.2" xref="S3.SS2.p1.2.m2.4.4.3.3.3.2a.cmml">f</mtext><mi id="S3.SS2.p1.2.m2.4.4.3.3.3.3" xref="S3.SS2.p1.2.m2.4.4.3.3.3.3.cmml">k</mi></msub><mo id="S3.SS2.p1.2.m2.4.4.3.3.8" stretchy="false" xref="S3.SS2.p1.2.m2.4.4.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.4b"><apply id="S3.SS2.p1.2.m2.4.4.cmml" xref="S3.SS2.p1.2.m2.4.4"><eq id="S3.SS2.p1.2.m2.4.4.4.cmml" xref="S3.SS2.p1.2.m2.4.4.4"></eq><ci id="S3.SS2.p1.2.m2.4.4.5a.cmml" xref="S3.SS2.p1.2.m2.4.4.5"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p1.2.m2.4.4.5.cmml" xref="S3.SS2.p1.2.m2.4.4.5">F</mtext></ci><list id="S3.SS2.p1.2.m2.4.4.3.4.cmml" xref="S3.SS2.p1.2.m2.4.4.3.3"><apply id="S3.SS2.p1.2.m2.2.2.1.1.1.cmml" xref="S3.SS2.p1.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.2.2.1.1.1.1.cmml" xref="S3.SS2.p1.2.m2.2.2.1.1.1">subscript</csymbol><ci id="S3.SS2.p1.2.m2.2.2.1.1.1.2a.cmml" xref="S3.SS2.p1.2.m2.2.2.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p1.2.m2.2.2.1.1.1.2.cmml" xref="S3.SS2.p1.2.m2.2.2.1.1.1.2">f</mtext></ci><cn id="S3.SS2.p1.2.m2.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS2.p1.2.m2.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS2.p1.2.m2.3.3.2.2.2.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.3.3.2.2.2.1.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2.2">subscript</csymbol><ci id="S3.SS2.p1.2.m2.3.3.2.2.2.2a.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p1.2.m2.3.3.2.2.2.2.cmml" xref="S3.SS2.p1.2.m2.3.3.2.2.2.2">f</mtext></ci><cn id="S3.SS2.p1.2.m2.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS2.p1.2.m2.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">…</ci><apply id="S3.SS2.p1.2.m2.4.4.3.3.3.cmml" xref="S3.SS2.p1.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p1.2.m2.4.4.3.3.3.1.cmml" xref="S3.SS2.p1.2.m2.4.4.3.3.3">subscript</csymbol><ci id="S3.SS2.p1.2.m2.4.4.3.3.3.2a.cmml" xref="S3.SS2.p1.2.m2.4.4.3.3.3.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p1.2.m2.4.4.3.3.3.2.cmml" xref="S3.SS2.p1.2.m2.4.4.3.3.3.2">f</mtext></ci><ci id="S3.SS2.p1.2.m2.4.4.3.3.3.3.cmml" xref="S3.SS2.p1.2.m2.4.4.3.3.3.3">𝑘</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.4c">\textbf{F}=[\textbf{f}_{1},\textbf{f}_{2},...,\textbf{f}_{k}]</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.4d">F = [ f start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , f start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , f start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ]</annotation></semantics></math> are the image features of dataset images produced by CLIP image encoder. Since the above equation is a super-determined problem, we solve this coefficient using least squares:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\textbf{w}=(\textbf{F}^{T}\textbf{F})^{-1}\textbf{F}^{T}\textbf{f}." class="ltx_Math" display="block" id="S3.E2.m1.1"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E2.m1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.3a.cmml">w</mtext><mo id="S3.E2.m1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.cmml"><msup id="S3.E2.m1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E2.m1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E2.m1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml"><msup id="S3.E2.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E2.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.2.2a.cmml">F</mtext><mi id="S3.E2.m1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.2.3.cmml">T</mi></msup><mo id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mtext class="ltx_mathvariant_bold" id="S3.E2.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.3a.cmml">F</mtext></mrow><mo id="S3.E2.m1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mrow id="S3.E2.m1.1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.1.3.cmml"><mo id="S3.E2.m1.1.1.1.1.1.1.3a" xref="S3.E2.m1.1.1.1.1.1.1.3.cmml">−</mo><mn id="S3.E2.m1.1.1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.1.1.3.2.cmml">1</mn></mrow></msup><mo id="S3.E2.m1.1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.1.2.cmml">⁢</mo><msup id="S3.E2.m1.1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.1.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E2.m1.1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.1.3.2a.cmml">F</mtext><mi id="S3.E2.m1.1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.1.3.3.cmml">T</mi></msup><mo id="S3.E2.m1.1.1.1.1.1.2a" xref="S3.E2.m1.1.1.1.1.1.2.cmml">⁢</mo><mtext class="ltx_mathvariant_bold" id="S3.E2.m1.1.1.1.1.1.4" xref="S3.E2.m1.1.1.1.1.1.4a.cmml">f</mtext></mrow></mrow><mo id="S3.E2.m1.1.1.1.2" lspace="0em" xref="S3.E2.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><eq id="S3.E2.m1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.2"></eq><ci id="S3.E2.m1.1.1.1.1.3a.cmml" xref="S3.E2.m1.1.1.1.1.3"><mtext class="ltx_mathvariant_bold" id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3">w</mtext></ci><apply id="S3.E2.m1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"><times id="S3.E2.m1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.2"></times><apply id="S3.E2.m1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E2.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1"><times id="S3.E2.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.1"></times><apply id="S3.E2.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.2">superscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.1.2.2a.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.2.2"><mtext class="ltx_mathvariant_bold" id="S3.E2.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.2.2">F</mtext></ci><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.2.3">𝑇</ci></apply><ci id="S3.E2.m1.1.1.1.1.1.1.1.1.1.3a.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.3"><mtext class="ltx_mathvariant_bold" id="S3.E2.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.1.1.1.3">F</mtext></ci></apply><apply id="S3.E2.m1.1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3"><minus id="S3.E2.m1.1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.1.3"></minus><cn id="S3.E2.m1.1.1.1.1.1.1.3.2.cmml" type="integer" xref="S3.E2.m1.1.1.1.1.1.1.3.2">1</cn></apply></apply><apply id="S3.E2.m1.1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.1.3">superscript</csymbol><ci id="S3.E2.m1.1.1.1.1.1.3.2a.cmml" xref="S3.E2.m1.1.1.1.1.1.3.2"><mtext class="ltx_mathvariant_bold" id="S3.E2.m1.1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.1.3.2">F</mtext></ci><ci id="S3.E2.m1.1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.1.3.3">𝑇</ci></apply><ci id="S3.E2.m1.1.1.1.1.1.4a.cmml" xref="S3.E2.m1.1.1.1.1.1.4"><mtext class="ltx_mathvariant_bold" id="S3.E2.m1.1.1.1.1.1.4.cmml" xref="S3.E2.m1.1.1.1.1.1.4">f</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">\textbf{w}=(\textbf{F}^{T}\textbf{F})^{-1}\textbf{F}^{T}\textbf{f}.</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.1d">w = ( F start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT F ) start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT F start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT f .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">We assume that the image feature space and text feature space share the same local manifold. Hence, the image reconstruction efficient <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S3.SS2.p3.1.1">w</span> can be used to compute the text feature of web images:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS2.p4">
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\textbf{s}=\textbf{S}\times\textbf{w}," class="ltx_Math" display="block" id="S3.E3.m1.1"><semantics id="S3.E3.m1.1a"><mrow id="S3.E3.m1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mrow id="S3.E3.m1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.2a.cmml">s</mtext><mo id="S3.E3.m1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E3.m1.1.1.1.1.3" xref="S3.E3.m1.1.1.1.1.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.1.1.1.1.3.2" xref="S3.E3.m1.1.1.1.1.3.2a.cmml">S</mtext><mo id="S3.E3.m1.1.1.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S3.E3.m1.1.1.1.1.3.1.cmml">×</mo><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.1.1.1.1.3.3" xref="S3.E3.m1.1.1.1.1.3.3a.cmml">w</mtext></mrow></mrow><mo id="S3.E3.m1.1.1.1.2" xref="S3.E3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.1b"><apply id="S3.E3.m1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1"><eq id="S3.E3.m1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1"></eq><ci id="S3.E3.m1.1.1.1.1.2a.cmml" xref="S3.E3.m1.1.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.1.1.1.1.2.cmml" xref="S3.E3.m1.1.1.1.1.2">s</mtext></ci><apply id="S3.E3.m1.1.1.1.1.3.cmml" xref="S3.E3.m1.1.1.1.1.3"><times id="S3.E3.m1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.1.1.1.1.3.1"></times><ci id="S3.E3.m1.1.1.1.1.3.2a.cmml" xref="S3.E3.m1.1.1.1.1.3.2"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.1.1.1.1.3.2.cmml" xref="S3.E3.m1.1.1.1.1.3.2">S</mtext></ci><ci id="S3.E3.m1.1.1.1.1.3.3a.cmml" xref="S3.E3.m1.1.1.1.1.3.3"><mtext class="ltx_mathvariant_bold" id="S3.E3.m1.1.1.1.1.3.3.cmml" xref="S3.E3.m1.1.1.1.1.3.3">w</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.1c">\textbf{s}=\textbf{S}\times\textbf{w},</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.1d">s = S × w ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS2.p4.2">where <math alttext="\textbf{S}=[\textbf{s}_{1},\textbf{s}_{2},...,\textbf{s}_{k}]" class="ltx_Math" display="inline" id="S3.SS2.p4.1.m1.4"><semantics id="S3.SS2.p4.1.m1.4a"><mrow id="S3.SS2.p4.1.m1.4.4" xref="S3.SS2.p4.1.m1.4.4.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p4.1.m1.4.4.5" xref="S3.SS2.p4.1.m1.4.4.5a.cmml">S</mtext><mo id="S3.SS2.p4.1.m1.4.4.4" xref="S3.SS2.p4.1.m1.4.4.4.cmml">=</mo><mrow id="S3.SS2.p4.1.m1.4.4.3.3" xref="S3.SS2.p4.1.m1.4.4.3.4.cmml"><mo id="S3.SS2.p4.1.m1.4.4.3.3.4" stretchy="false" xref="S3.SS2.p4.1.m1.4.4.3.4.cmml">[</mo><msub id="S3.SS2.p4.1.m1.2.2.1.1.1" xref="S3.SS2.p4.1.m1.2.2.1.1.1.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p4.1.m1.2.2.1.1.1.2" xref="S3.SS2.p4.1.m1.2.2.1.1.1.2a.cmml">s</mtext><mn id="S3.SS2.p4.1.m1.2.2.1.1.1.3" xref="S3.SS2.p4.1.m1.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S3.SS2.p4.1.m1.4.4.3.3.5" xref="S3.SS2.p4.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.SS2.p4.1.m1.3.3.2.2.2" xref="S3.SS2.p4.1.m1.3.3.2.2.2.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p4.1.m1.3.3.2.2.2.2" xref="S3.SS2.p4.1.m1.3.3.2.2.2.2a.cmml">s</mtext><mn id="S3.SS2.p4.1.m1.3.3.2.2.2.3" xref="S3.SS2.p4.1.m1.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S3.SS2.p4.1.m1.4.4.3.3.6" xref="S3.SS2.p4.1.m1.4.4.3.4.cmml">,</mo><mi id="S3.SS2.p4.1.m1.1.1" mathvariant="normal" xref="S3.SS2.p4.1.m1.1.1.cmml">…</mi><mo id="S3.SS2.p4.1.m1.4.4.3.3.7" xref="S3.SS2.p4.1.m1.4.4.3.4.cmml">,</mo><msub id="S3.SS2.p4.1.m1.4.4.3.3.3" xref="S3.SS2.p4.1.m1.4.4.3.3.3.cmml"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p4.1.m1.4.4.3.3.3.2" xref="S3.SS2.p4.1.m1.4.4.3.3.3.2a.cmml">s</mtext><mi id="S3.SS2.p4.1.m1.4.4.3.3.3.3" xref="S3.SS2.p4.1.m1.4.4.3.3.3.3.cmml">k</mi></msub><mo id="S3.SS2.p4.1.m1.4.4.3.3.8" stretchy="false" xref="S3.SS2.p4.1.m1.4.4.3.4.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p4.1.m1.4b"><apply id="S3.SS2.p4.1.m1.4.4.cmml" xref="S3.SS2.p4.1.m1.4.4"><eq id="S3.SS2.p4.1.m1.4.4.4.cmml" xref="S3.SS2.p4.1.m1.4.4.4"></eq><ci id="S3.SS2.p4.1.m1.4.4.5a.cmml" xref="S3.SS2.p4.1.m1.4.4.5"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p4.1.m1.4.4.5.cmml" xref="S3.SS2.p4.1.m1.4.4.5">S</mtext></ci><list id="S3.SS2.p4.1.m1.4.4.3.4.cmml" xref="S3.SS2.p4.1.m1.4.4.3.3"><apply id="S3.SS2.p4.1.m1.2.2.1.1.1.cmml" xref="S3.SS2.p4.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.2.2.1.1.1.1.cmml" xref="S3.SS2.p4.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.SS2.p4.1.m1.2.2.1.1.1.2a.cmml" xref="S3.SS2.p4.1.m1.2.2.1.1.1.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p4.1.m1.2.2.1.1.1.2.cmml" xref="S3.SS2.p4.1.m1.2.2.1.1.1.2">s</mtext></ci><cn id="S3.SS2.p4.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="S3.SS2.p4.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="S3.SS2.p4.1.m1.3.3.2.2.2.cmml" xref="S3.SS2.p4.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.3.3.2.2.2.1.cmml" xref="S3.SS2.p4.1.m1.3.3.2.2.2">subscript</csymbol><ci id="S3.SS2.p4.1.m1.3.3.2.2.2.2a.cmml" xref="S3.SS2.p4.1.m1.3.3.2.2.2.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p4.1.m1.3.3.2.2.2.2.cmml" xref="S3.SS2.p4.1.m1.3.3.2.2.2.2">s</mtext></ci><cn id="S3.SS2.p4.1.m1.3.3.2.2.2.3.cmml" type="integer" xref="S3.SS2.p4.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="S3.SS2.p4.1.m1.1.1.cmml" xref="S3.SS2.p4.1.m1.1.1">…</ci><apply id="S3.SS2.p4.1.m1.4.4.3.3.3.cmml" xref="S3.SS2.p4.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="S3.SS2.p4.1.m1.4.4.3.3.3.1.cmml" xref="S3.SS2.p4.1.m1.4.4.3.3.3">subscript</csymbol><ci id="S3.SS2.p4.1.m1.4.4.3.3.3.2a.cmml" xref="S3.SS2.p4.1.m1.4.4.3.3.3.2"><mtext class="ltx_mathvariant_bold" id="S3.SS2.p4.1.m1.4.4.3.3.3.2.cmml" xref="S3.SS2.p4.1.m1.4.4.3.3.3.2">s</mtext></ci><ci id="S3.SS2.p4.1.m1.4.4.3.3.3.3.cmml" xref="S3.SS2.p4.1.m1.4.4.3.3.3.3">𝑘</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p4.1.m1.4c">\textbf{S}=[\textbf{s}_{1},\textbf{s}_{2},...,\textbf{s}_{k}]</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p4.1.m1.4d">S = [ s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , s start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , s start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ]</annotation></semantics></math> is the fake sentence features for nearest k dataset images, and <span class="ltx_text ltx_markedasmath ltx_font_bold" id="S3.SS2.p4.2.1">s</span> is the sentence feature for a web image.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Recurrent Diffusion Transformer on Latent Space</h3>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="173" id="S3.F2.g1" src="x2.png" width="761"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span> Latent diffusion model with recurrent affine transformation and NULL-guidance for text-to-image synthesis. The RAT blocks are connected by a recurrent neural network to ensure the global assignment of text information.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">The training objective of the diffusion model is the squared error loss proposed by DDPM <cite class="ltx_cite ltx_citemacro_citep">(Ho et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib11" title="">2020</a>)</cite>:</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.p2">
<table class="ltx_equation ltx_eqn_table" id="S3.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="L(\theta)=\left\|\epsilon-\epsilon_{\theta}\left(\sqrt{\overline{\bar{\alpha}}%
_{t}}\mathrm{x}_{0}+\sqrt{1-\bar{\alpha}_{t}}\epsilon\right)\right\|^{2}," class="ltx_Math" display="block" id="S3.E4.m1.2"><semantics id="S3.E4.m1.2a"><mrow id="S3.E4.m1.2.2.1" xref="S3.E4.m1.2.2.1.1.cmml"><mrow id="S3.E4.m1.2.2.1.1" xref="S3.E4.m1.2.2.1.1.cmml"><mrow id="S3.E4.m1.2.2.1.1.3" xref="S3.E4.m1.2.2.1.1.3.cmml"><mi id="S3.E4.m1.2.2.1.1.3.2" xref="S3.E4.m1.2.2.1.1.3.2.cmml">L</mi><mo id="S3.E4.m1.2.2.1.1.3.1" xref="S3.E4.m1.2.2.1.1.3.1.cmml">⁢</mo><mrow id="S3.E4.m1.2.2.1.1.3.3.2" xref="S3.E4.m1.2.2.1.1.3.cmml"><mo id="S3.E4.m1.2.2.1.1.3.3.2.1" stretchy="false" xref="S3.E4.m1.2.2.1.1.3.cmml">(</mo><mi id="S3.E4.m1.1.1" xref="S3.E4.m1.1.1.cmml">θ</mi><mo id="S3.E4.m1.2.2.1.1.3.3.2.2" stretchy="false" xref="S3.E4.m1.2.2.1.1.3.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.2.2.1.1.2" xref="S3.E4.m1.2.2.1.1.2.cmml">=</mo><msup id="S3.E4.m1.2.2.1.1.1" xref="S3.E4.m1.2.2.1.1.1.cmml"><mrow id="S3.E4.m1.2.2.1.1.1.1.1" xref="S3.E4.m1.2.2.1.1.1.1.2.cmml"><mo id="S3.E4.m1.2.2.1.1.1.1.1.2" xref="S3.E4.m1.2.2.1.1.1.1.2.1.cmml">‖</mo><mrow id="S3.E4.m1.2.2.1.1.1.1.1.1" xref="S3.E4.m1.2.2.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3.cmml">ϵ</mi><mo id="S3.E4.m1.2.2.1.1.1.1.1.1.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2.cmml">−</mo><mrow id="S3.E4.m1.2.2.1.1.1.1.1.1.1" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.cmml"><msub id="S3.E4.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.1.3.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.3.2.cmml">ϵ</mi><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.1.3.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.3.3.cmml">θ</mi></msub><mo id="S3.E4.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml"><msqrt id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.cmml"><msub id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml"><mover accent="true" id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml"><mover accent="true" id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.2.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml"><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.2.2.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.2.2.2.cmml">α</mi><mo id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.2.2.1" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.cmml">¯</mo></mover><mo id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.2.1" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.2.1.cmml">¯</mo></mover><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml">t</mi></msub></msqrt><mo id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.1" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.1.cmml">⁢</mo><msub id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3.2" mathvariant="normal" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3.2.cmml">x</mi><mn id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3.3.cmml">0</mn></msub></mrow><mo id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mrow id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml"><msqrt id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.cmml"><mrow id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml"><mn id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.2.cmml">1</mn><mo id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.1" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.1.cmml">−</mo><msub id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3.cmml"><mover accent="true" id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3.2.cmml"><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3.2.2" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3.2.2.cmml">α</mi><mo id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3.2.1" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3.2.1.cmml">¯</mo></mover><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3.3.cmml">t</mi></msub></mrow></msqrt><mo id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.cmml">ϵ</mi></mrow></mrow><mo id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.3" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E4.m1.2.2.1.1.1.1.1.3" xref="S3.E4.m1.2.2.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S3.E4.m1.2.2.1.1.1.3" xref="S3.E4.m1.2.2.1.1.1.3.cmml">2</mn></msup></mrow><mo id="S3.E4.m1.2.2.1.2" xref="S3.E4.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E4.m1.2b"><apply id="S3.E4.m1.2.2.1.1.cmml" xref="S3.E4.m1.2.2.1"><eq id="S3.E4.m1.2.2.1.1.2.cmml" xref="S3.E4.m1.2.2.1.1.2"></eq><apply id="S3.E4.m1.2.2.1.1.3.cmml" xref="S3.E4.m1.2.2.1.1.3"><times id="S3.E4.m1.2.2.1.1.3.1.cmml" xref="S3.E4.m1.2.2.1.1.3.1"></times><ci id="S3.E4.m1.2.2.1.1.3.2.cmml" xref="S3.E4.m1.2.2.1.1.3.2">𝐿</ci><ci id="S3.E4.m1.1.1.cmml" xref="S3.E4.m1.1.1">𝜃</ci></apply><apply id="S3.E4.m1.2.2.1.1.1.cmml" xref="S3.E4.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.2.cmml" xref="S3.E4.m1.2.2.1.1.1">superscript</csymbol><apply id="S3.E4.m1.2.2.1.1.1.1.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1"><csymbol cd="latexml" id="S3.E4.m1.2.2.1.1.1.1.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.2">norm</csymbol><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1"><minus id="S3.E4.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.2"></minus><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.3">italic-ϵ</ci><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1"><times id="S3.E4.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.2"></times><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.3.2">italic-ϵ</ci><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.3.3">𝜃</ci></apply><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1"><plus id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.1"></plus><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2"><times id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.1"></times><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2"><root id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2a.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2"></root><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.2"><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.2.1">¯</ci><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.2.2"><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.2.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.2.2.1">¯</ci><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.2.2.2">𝛼</ci></apply></apply><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.2.2.3">𝑡</ci></apply></apply><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3.2">x</ci><cn id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3.3.cmml" type="integer" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.2.3.3">0</cn></apply></apply><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3"><times id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.1"></times><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2"><root id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2a.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2"></root><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2"><minus id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.1"></minus><cn id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.2.cmml" type="integer" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.2">1</cn><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3"><csymbol cd="ambiguous" id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3">subscript</csymbol><apply id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3.2"><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3.2.1.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3.2.1">¯</ci><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3.2.2.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3.2.2">𝛼</ci></apply><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.2.2.3.3">𝑡</ci></apply></apply></apply><ci id="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E4.m1.2.2.1.1.1.1.1.1.1.1.1.1.3.3">italic-ϵ</ci></apply></apply></apply></apply></apply><cn id="S3.E4.m1.2.2.1.1.1.3.cmml" type="integer" xref="S3.E4.m1.2.2.1.1.1.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.2c">L(\theta)=\left\|\epsilon-\epsilon_{\theta}\left(\sqrt{\overline{\bar{\alpha}}%
_{t}}\mathrm{x}_{0}+\sqrt{1-\bar{\alpha}_{t}}\epsilon\right)\right\|^{2},</annotation><annotation encoding="application/x-llamapun" id="S3.E4.m1.2d">italic_L ( italic_θ ) = ∥ italic_ϵ - italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( square-root start_ARG over¯ start_ARG over¯ start_ARG italic_α end_ARG end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG roman_x start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT + square-root start_ARG 1 - over¯ start_ARG italic_α end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG italic_ϵ ) ∥ start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p2.4">where <math alttext="\epsilon\in N(0,1)" class="ltx_Math" display="inline" id="S3.SS3.p2.1.m1.2"><semantics id="S3.SS3.p2.1.m1.2a"><mrow id="S3.SS3.p2.1.m1.2.3" xref="S3.SS3.p2.1.m1.2.3.cmml"><mi id="S3.SS3.p2.1.m1.2.3.2" xref="S3.SS3.p2.1.m1.2.3.2.cmml">ϵ</mi><mo id="S3.SS3.p2.1.m1.2.3.1" xref="S3.SS3.p2.1.m1.2.3.1.cmml">∈</mo><mrow id="S3.SS3.p2.1.m1.2.3.3" xref="S3.SS3.p2.1.m1.2.3.3.cmml"><mi id="S3.SS3.p2.1.m1.2.3.3.2" xref="S3.SS3.p2.1.m1.2.3.3.2.cmml">N</mi><mo id="S3.SS3.p2.1.m1.2.3.3.1" xref="S3.SS3.p2.1.m1.2.3.3.1.cmml">⁢</mo><mrow id="S3.SS3.p2.1.m1.2.3.3.3.2" xref="S3.SS3.p2.1.m1.2.3.3.3.1.cmml"><mo id="S3.SS3.p2.1.m1.2.3.3.3.2.1" stretchy="false" xref="S3.SS3.p2.1.m1.2.3.3.3.1.cmml">(</mo><mn id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml">0</mn><mo id="S3.SS3.p2.1.m1.2.3.3.3.2.2" xref="S3.SS3.p2.1.m1.2.3.3.3.1.cmml">,</mo><mn id="S3.SS3.p2.1.m1.2.2" xref="S3.SS3.p2.1.m1.2.2.cmml">1</mn><mo id="S3.SS3.p2.1.m1.2.3.3.3.2.3" stretchy="false" xref="S3.SS3.p2.1.m1.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.2b"><apply id="S3.SS3.p2.1.m1.2.3.cmml" xref="S3.SS3.p2.1.m1.2.3"><in id="S3.SS3.p2.1.m1.2.3.1.cmml" xref="S3.SS3.p2.1.m1.2.3.1"></in><ci id="S3.SS3.p2.1.m1.2.3.2.cmml" xref="S3.SS3.p2.1.m1.2.3.2">italic-ϵ</ci><apply id="S3.SS3.p2.1.m1.2.3.3.cmml" xref="S3.SS3.p2.1.m1.2.3.3"><times id="S3.SS3.p2.1.m1.2.3.3.1.cmml" xref="S3.SS3.p2.1.m1.2.3.3.1"></times><ci id="S3.SS3.p2.1.m1.2.3.3.2.cmml" xref="S3.SS3.p2.1.m1.2.3.3.2">𝑁</ci><interval closure="open" id="S3.SS3.p2.1.m1.2.3.3.3.1.cmml" xref="S3.SS3.p2.1.m1.2.3.3.3.2"><cn id="S3.SS3.p2.1.m1.1.1.cmml" type="integer" xref="S3.SS3.p2.1.m1.1.1">0</cn><cn id="S3.SS3.p2.1.m1.2.2.cmml" type="integer" xref="S3.SS3.p2.1.m1.2.2">1</cn></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.2c">\epsilon\in N(0,1)</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.1.m1.2d">italic_ϵ ∈ italic_N ( 0 , 1 )</annotation></semantics></math> is the score noise injected at every diffusion step, and <math alttext="\epsilon_{\theta}" class="ltx_Math" display="inline" id="S3.SS3.p2.2.m2.1"><semantics id="S3.SS3.p2.2.m2.1a"><msub id="S3.SS3.p2.2.m2.1.1" xref="S3.SS3.p2.2.m2.1.1.cmml"><mi id="S3.SS3.p2.2.m2.1.1.2" xref="S3.SS3.p2.2.m2.1.1.2.cmml">ϵ</mi><mi id="S3.SS3.p2.2.m2.1.1.3" xref="S3.SS3.p2.2.m2.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.2.m2.1b"><apply id="S3.SS3.p2.2.m2.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.2.m2.1.1.1.cmml" xref="S3.SS3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.p2.2.m2.1.1.2.cmml" xref="S3.SS3.p2.2.m2.1.1.2">italic-ϵ</ci><ci id="S3.SS3.p2.2.m2.1.1.3.cmml" xref="S3.SS3.p2.2.m2.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.2.m2.1c">\epsilon_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.2.m2.1d">italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> is the predicted noise by a diffusion network consisted of 12 transformer layers. <math alttext="\overline{\bar{\alpha}}_{t}" class="ltx_Math" display="inline" id="S3.SS3.p2.3.m3.1"><semantics id="S3.SS3.p2.3.m3.1a"><msub id="S3.SS3.p2.3.m3.1.1" xref="S3.SS3.p2.3.m3.1.1.cmml"><mover accent="true" id="S3.SS3.p2.3.m3.1.1.2" xref="S3.SS3.p2.3.m3.1.1.2.cmml"><mover accent="true" id="S3.SS3.p2.3.m3.1.1.2.2" xref="S3.SS3.p2.3.m3.1.1.2.2.cmml"><mi id="S3.SS3.p2.3.m3.1.1.2.2.2" xref="S3.SS3.p2.3.m3.1.1.2.2.2.cmml">α</mi><mo id="S3.SS3.p2.3.m3.1.1.2.2.1" xref="S3.SS3.p2.3.m3.1.1.2.2.1.cmml">¯</mo></mover><mo id="S3.SS3.p2.3.m3.1.1.2.1" xref="S3.SS3.p2.3.m3.1.1.2.1.cmml">¯</mo></mover><mi id="S3.SS3.p2.3.m3.1.1.3" xref="S3.SS3.p2.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.3.m3.1b"><apply id="S3.SS3.p2.3.m3.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.3.m3.1.1.1.cmml" xref="S3.SS3.p2.3.m3.1.1">subscript</csymbol><apply id="S3.SS3.p2.3.m3.1.1.2.cmml" xref="S3.SS3.p2.3.m3.1.1.2"><ci id="S3.SS3.p2.3.m3.1.1.2.1.cmml" xref="S3.SS3.p2.3.m3.1.1.2.1">¯</ci><apply id="S3.SS3.p2.3.m3.1.1.2.2.cmml" xref="S3.SS3.p2.3.m3.1.1.2.2"><ci id="S3.SS3.p2.3.m3.1.1.2.2.1.cmml" xref="S3.SS3.p2.3.m3.1.1.2.2.1">¯</ci><ci id="S3.SS3.p2.3.m3.1.1.2.2.2.cmml" xref="S3.SS3.p2.3.m3.1.1.2.2.2">𝛼</ci></apply></apply><ci id="S3.SS3.p2.3.m3.1.1.3.cmml" xref="S3.SS3.p2.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.3.m3.1c">\overline{\bar{\alpha}}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.3.m3.1d">over¯ start_ARG over¯ start_ARG italic_α end_ARG end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\bar{\alpha}_{t}" class="ltx_Math" display="inline" id="S3.SS3.p2.4.m4.1"><semantics id="S3.SS3.p2.4.m4.1a"><msub id="S3.SS3.p2.4.m4.1.1" xref="S3.SS3.p2.4.m4.1.1.cmml"><mover accent="true" id="S3.SS3.p2.4.m4.1.1.2" xref="S3.SS3.p2.4.m4.1.1.2.cmml"><mi id="S3.SS3.p2.4.m4.1.1.2.2" xref="S3.SS3.p2.4.m4.1.1.2.2.cmml">α</mi><mo id="S3.SS3.p2.4.m4.1.1.2.1" xref="S3.SS3.p2.4.m4.1.1.2.1.cmml">¯</mo></mover><mi id="S3.SS3.p2.4.m4.1.1.3" xref="S3.SS3.p2.4.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.4.m4.1b"><apply id="S3.SS3.p2.4.m4.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.4.m4.1.1.1.cmml" xref="S3.SS3.p2.4.m4.1.1">subscript</csymbol><apply id="S3.SS3.p2.4.m4.1.1.2.cmml" xref="S3.SS3.p2.4.m4.1.1.2"><ci id="S3.SS3.p2.4.m4.1.1.2.1.cmml" xref="S3.SS3.p2.4.m4.1.1.2.1">¯</ci><ci id="S3.SS3.p2.4.m4.1.1.2.2.cmml" xref="S3.SS3.p2.4.m4.1.1.2.2">𝛼</ci></apply><ci id="S3.SS3.p2.4.m4.1.1.3.cmml" xref="S3.SS3.p2.4.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.4.m4.1c">\bar{\alpha}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.4.m4.1d">over¯ start_ARG italic_α end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> are hyper-parameters controlling the speed of diffusion. The work of score mismatching <cite class="ltx_cite ltx_citemacro_citep">(Ye &amp; Liu, <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib41" title="">2024</a>)</cite> shows that predicting the score noise leads to an unbiased estimation.</p>
</div>
<section class="ltx_paragraph" id="S3.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Network architecture.</h4>
<div class="ltx_para ltx_noindent" id="S3.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS3.SSS0.Px1.p1.4">As depicted in Fig <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#A0.F8" title="Figure 8 ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_tag">8</span></a>, the diffusion network consists of transformer blocks. Recurrent affine transformation is used to enhance the consistency between transformer blocks. To avoid directly mixing text embedding and time embedding, we stack four transformer blocks as a RAT block and text embedding is fed into the top of each RAT block.
Each RAT block applies a channel-wise shifting operation on a image feature map:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="c^{\prime}=c+\beta," class="ltx_Math" display="block" id="S3.E5.m1.1"><semantics id="S3.E5.m1.1a"><mrow id="S3.E5.m1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><mrow id="S3.E5.m1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.cmml"><msup id="S3.E5.m1.1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.2.cmml"><mi id="S3.E5.m1.1.1.1.1.2.2" xref="S3.E5.m1.1.1.1.1.2.2.cmml">c</mi><mo id="S3.E5.m1.1.1.1.1.2.3" xref="S3.E5.m1.1.1.1.1.2.3.cmml">′</mo></msup><mo id="S3.E5.m1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E5.m1.1.1.1.1.3" xref="S3.E5.m1.1.1.1.1.3.cmml"><mi id="S3.E5.m1.1.1.1.1.3.2" xref="S3.E5.m1.1.1.1.1.3.2.cmml">c</mi><mo id="S3.E5.m1.1.1.1.1.3.1" xref="S3.E5.m1.1.1.1.1.3.1.cmml">+</mo><mi id="S3.E5.m1.1.1.1.1.3.3" xref="S3.E5.m1.1.1.1.1.3.3.cmml">β</mi></mrow></mrow><mo id="S3.E5.m1.1.1.1.2" xref="S3.E5.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E5.m1.1b"><apply id="S3.E5.m1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1"><eq id="S3.E5.m1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1"></eq><apply id="S3.E5.m1.1.1.1.1.2.cmml" xref="S3.E5.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E5.m1.1.1.1.1.2.1.cmml" xref="S3.E5.m1.1.1.1.1.2">superscript</csymbol><ci id="S3.E5.m1.1.1.1.1.2.2.cmml" xref="S3.E5.m1.1.1.1.1.2.2">𝑐</ci><ci id="S3.E5.m1.1.1.1.1.2.3.cmml" xref="S3.E5.m1.1.1.1.1.2.3">′</ci></apply><apply id="S3.E5.m1.1.1.1.1.3.cmml" xref="S3.E5.m1.1.1.1.1.3"><plus id="S3.E5.m1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.1.1.1.1.3.1"></plus><ci id="S3.E5.m1.1.1.1.1.3.2.cmml" xref="S3.E5.m1.1.1.1.1.3.2">𝑐</ci><ci id="S3.E5.m1.1.1.1.1.3.3.cmml" xref="S3.E5.m1.1.1.1.1.3.3">𝛽</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.1c">c^{\prime}=c+\beta,</annotation><annotation encoding="application/x-llamapun" id="S3.E5.m1.1d">italic_c start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = italic_c + italic_β ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.SSS0.Px1.p1.3">where <math alttext="c" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px1.p1.1.m1.1"><semantics id="S3.SS3.SSS0.Px1.p1.1.m1.1a"><mi id="S3.SS3.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px1.p1.1.m1.1b"><ci id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px1.p1.1.m1.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS0.Px1.p1.1.m1.1d">italic_c</annotation></semantics></math> is the image feature vector and <math alttext="\beta" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px1.p1.2.m2.1"><semantics id="S3.SS3.SSS0.Px1.p1.2.m2.1a"><mi id="S3.SS3.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px1.p1.2.m2.1b"><ci id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px1.p1.2.m2.1c">\beta</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS0.Px1.p1.2.m2.1d">italic_β</annotation></semantics></math> is shifting parameters predicted by a one-hidden-layer multi-layer perception (MLP) conditioned on recurrent neural network hidden state <math alttext="h_{t}" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px1.p1.3.m3.1"><semantics id="S3.SS3.SSS0.Px1.p1.3.m3.1a"><msub id="S3.SS3.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS3.SSS0.Px1.p1.3.m3.1.1.cmml"><mi id="S3.SS3.SSS0.Px1.p1.3.m3.1.1.2" xref="S3.SS3.SSS0.Px1.p1.3.m3.1.1.2.cmml">h</mi><mi id="S3.SS3.SSS0.Px1.p1.3.m3.1.1.3" xref="S3.SS3.SSS0.Px1.p1.3.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px1.p1.3.m3.1b"><apply id="S3.SS3.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS3.SSS0.Px1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S3.SS3.SSS0.Px1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S3.SS3.SSS0.Px1.p1.3.m3.1.1.2">ℎ</ci><ci id="S3.SS3.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S3.SS3.SSS0.Px1.p1.3.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px1.p1.3.m3.1c">h_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS0.Px1.p1.3.m3.1d">italic_h start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.SSS0.Px1.p2">
<p class="ltx_p" id="S3.SS3.SSS0.Px1.p2.3">In each transformer block, we inject time embedding by a channel-wise scaling operation and a channel-wise shifting operation on <math alttext="c" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px1.p2.1.m1.1"><semantics id="S3.SS3.SSS0.Px1.p2.1.m1.1a"><mi id="S3.SS3.SSS0.Px1.p2.1.m1.1.1" xref="S3.SS3.SSS0.Px1.p2.1.m1.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px1.p2.1.m1.1b"><ci id="S3.SS3.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S3.SS3.SSS0.Px1.p2.1.m1.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px1.p2.1.m1.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS0.Px1.p2.1.m1.1d">italic_c</annotation></semantics></math>. At last, the image feature <math alttext="c" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px1.p2.2.m2.1"><semantics id="S3.SS3.SSS0.Px1.p2.2.m2.1a"><mi id="S3.SS3.SSS0.Px1.p2.2.m2.1.1" xref="S3.SS3.SSS0.Px1.p2.2.m2.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px1.p2.2.m2.1b"><ci id="S3.SS3.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S3.SS3.SSS0.Px1.p2.2.m2.1.1">𝑐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px1.p2.2.m2.1c">c</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS0.Px1.p2.2.m2.1d">italic_c</annotation></semantics></math> is multiplied by a scaling parameter <math alttext="\alpha" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px1.p2.3.m3.1"><semantics id="S3.SS3.SSS0.Px1.p2.3.m3.1a"><mi id="S3.SS3.SSS0.Px1.p2.3.m3.1.1" xref="S3.SS3.SSS0.Px1.p2.3.m3.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px1.p2.3.m3.1b"><ci id="S3.SS3.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S3.SS3.SSS0.Px1.p2.3.m3.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px1.p2.3.m3.1c">\alpha</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS0.Px1.p2.3.m3.1d">italic_α</annotation></semantics></math>. This process can be formally expressed as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="c^{\prime}=Transformer((1+\gamma)\cdot c+\beta)\cdot\alpha," class="ltx_Math" display="block" id="S3.E6.m1.1"><semantics id="S3.E6.m1.1a"><mrow id="S3.E6.m1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><mrow id="S3.E6.m1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.cmml"><msup id="S3.E6.m1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.3.cmml"><mi id="S3.E6.m1.1.1.1.1.3.2" xref="S3.E6.m1.1.1.1.1.3.2.cmml">c</mi><mo id="S3.E6.m1.1.1.1.1.3.3" xref="S3.E6.m1.1.1.1.1.3.3.cmml">′</mo></msup><mo id="S3.E6.m1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E6.m1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.cmml"><mrow id="S3.E6.m1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.3.cmml">T</mi><mo id="S3.E6.m1.1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.E6.m1.1.1.1.1.1.1.4" xref="S3.E6.m1.1.1.1.1.1.1.4.cmml">r</mi><mo id="S3.E6.m1.1.1.1.1.1.1.2a" xref="S3.E6.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.E6.m1.1.1.1.1.1.1.5" xref="S3.E6.m1.1.1.1.1.1.1.5.cmml">a</mi><mo id="S3.E6.m1.1.1.1.1.1.1.2b" xref="S3.E6.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.E6.m1.1.1.1.1.1.1.6" xref="S3.E6.m1.1.1.1.1.1.1.6.cmml">n</mi><mo id="S3.E6.m1.1.1.1.1.1.1.2c" xref="S3.E6.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.E6.m1.1.1.1.1.1.1.7" xref="S3.E6.m1.1.1.1.1.1.1.7.cmml">s</mi><mo id="S3.E6.m1.1.1.1.1.1.1.2d" xref="S3.E6.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.E6.m1.1.1.1.1.1.1.8" xref="S3.E6.m1.1.1.1.1.1.1.8.cmml">f</mi><mo id="S3.E6.m1.1.1.1.1.1.1.2e" xref="S3.E6.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.E6.m1.1.1.1.1.1.1.9" xref="S3.E6.m1.1.1.1.1.1.1.9.cmml">o</mi><mo id="S3.E6.m1.1.1.1.1.1.1.2f" xref="S3.E6.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.E6.m1.1.1.1.1.1.1.10" xref="S3.E6.m1.1.1.1.1.1.1.10.cmml">r</mi><mo id="S3.E6.m1.1.1.1.1.1.1.2g" xref="S3.E6.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.E6.m1.1.1.1.1.1.1.11" xref="S3.E6.m1.1.1.1.1.1.1.11.cmml">m</mi><mo id="S3.E6.m1.1.1.1.1.1.1.2h" xref="S3.E6.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.E6.m1.1.1.1.1.1.1.12" xref="S3.E6.m1.1.1.1.1.1.1.12.cmml">e</mi><mo id="S3.E6.m1.1.1.1.1.1.1.2i" xref="S3.E6.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mi id="S3.E6.m1.1.1.1.1.1.1.13" xref="S3.E6.m1.1.1.1.1.1.1.13.cmml">r</mi><mo id="S3.E6.m1.1.1.1.1.1.1.2j" xref="S3.E6.m1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E6.m1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E6.m1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E6.m1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mn id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">γ</mi></mrow><mo id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.3" rspace="0.055em" stretchy="false" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.2" rspace="0.222em" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">⋅</mo><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">c</mi></mrow><mo id="S3.E6.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.2.cmml">+</mo><mi id="S3.E6.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.3.cmml">β</mi></mrow><mo id="S3.E6.m1.1.1.1.1.1.1.1.1.3" rspace="0.055em" stretchy="false" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.1.1.1.1.1.2" rspace="0.222em" xref="S3.E6.m1.1.1.1.1.1.2.cmml">⋅</mo><mi id="S3.E6.m1.1.1.1.1.1.3" xref="S3.E6.m1.1.1.1.1.1.3.cmml">α</mi></mrow></mrow><mo id="S3.E6.m1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E6.m1.1b"><apply id="S3.E6.m1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1"><eq id="S3.E6.m1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.2"></eq><apply id="S3.E6.m1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E6.m1.1.1.1.1.3.1.cmml" xref="S3.E6.m1.1.1.1.1.3">superscript</csymbol><ci id="S3.E6.m1.1.1.1.1.3.2.cmml" xref="S3.E6.m1.1.1.1.1.3.2">𝑐</ci><ci id="S3.E6.m1.1.1.1.1.3.3.cmml" xref="S3.E6.m1.1.1.1.1.3.3">′</ci></apply><apply id="S3.E6.m1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1"><ci id="S3.E6.m1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.2">⋅</ci><apply id="S3.E6.m1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1"><times id="S3.E6.m1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.2"></times><ci id="S3.E6.m1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.3">𝑇</ci><ci id="S3.E6.m1.1.1.1.1.1.1.4.cmml" xref="S3.E6.m1.1.1.1.1.1.1.4">𝑟</ci><ci id="S3.E6.m1.1.1.1.1.1.1.5.cmml" xref="S3.E6.m1.1.1.1.1.1.1.5">𝑎</ci><ci id="S3.E6.m1.1.1.1.1.1.1.6.cmml" xref="S3.E6.m1.1.1.1.1.1.1.6">𝑛</ci><ci id="S3.E6.m1.1.1.1.1.1.1.7.cmml" xref="S3.E6.m1.1.1.1.1.1.1.7">𝑠</ci><ci id="S3.E6.m1.1.1.1.1.1.1.8.cmml" xref="S3.E6.m1.1.1.1.1.1.1.8">𝑓</ci><ci id="S3.E6.m1.1.1.1.1.1.1.9.cmml" xref="S3.E6.m1.1.1.1.1.1.1.9">𝑜</ci><ci id="S3.E6.m1.1.1.1.1.1.1.10.cmml" xref="S3.E6.m1.1.1.1.1.1.1.10">𝑟</ci><ci id="S3.E6.m1.1.1.1.1.1.1.11.cmml" xref="S3.E6.m1.1.1.1.1.1.1.11">𝑚</ci><ci id="S3.E6.m1.1.1.1.1.1.1.12.cmml" xref="S3.E6.m1.1.1.1.1.1.1.12">𝑒</ci><ci id="S3.E6.m1.1.1.1.1.1.1.13.cmml" xref="S3.E6.m1.1.1.1.1.1.1.13">𝑟</ci><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1"><plus id="S3.E6.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.2"></plus><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1"><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.2">⋅</ci><apply id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1"><plus id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.1"></plus><cn id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" type="integer" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">1</cn><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.3">𝛾</ci></apply><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.1.3">𝑐</ci></apply><ci id="S3.E6.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1.1.1.3">𝛽</ci></apply></apply><ci id="S3.E6.m1.1.1.1.1.1.3.cmml" xref="S3.E6.m1.1.1.1.1.1.3">𝛼</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.1c">c^{\prime}=Transformer((1+\gamma)\cdot c+\beta)\cdot\alpha,</annotation><annotation encoding="application/x-llamapun" id="S3.E6.m1.1d">italic_c start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = italic_T italic_r italic_a italic_n italic_s italic_f italic_o italic_r italic_m italic_e italic_r ( ( 1 + italic_γ ) ⋅ italic_c + italic_β ) ⋅ italic_α ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.SSS0.Px1.p3">
<p class="ltx_p" id="S3.SS3.SSS0.Px1.p3.1">where <math alttext="\alpha,\gamma,\beta" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px1.p3.1.m1.3"><semantics id="S3.SS3.SSS0.Px1.p3.1.m1.3a"><mrow id="S3.SS3.SSS0.Px1.p3.1.m1.3.4.2" xref="S3.SS3.SSS0.Px1.p3.1.m1.3.4.1.cmml"><mi id="S3.SS3.SSS0.Px1.p3.1.m1.1.1" xref="S3.SS3.SSS0.Px1.p3.1.m1.1.1.cmml">α</mi><mo id="S3.SS3.SSS0.Px1.p3.1.m1.3.4.2.1" xref="S3.SS3.SSS0.Px1.p3.1.m1.3.4.1.cmml">,</mo><mi id="S3.SS3.SSS0.Px1.p3.1.m1.2.2" xref="S3.SS3.SSS0.Px1.p3.1.m1.2.2.cmml">γ</mi><mo id="S3.SS3.SSS0.Px1.p3.1.m1.3.4.2.2" xref="S3.SS3.SSS0.Px1.p3.1.m1.3.4.1.cmml">,</mo><mi id="S3.SS3.SSS0.Px1.p3.1.m1.3.3" xref="S3.SS3.SSS0.Px1.p3.1.m1.3.3.cmml">β</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px1.p3.1.m1.3b"><list id="S3.SS3.SSS0.Px1.p3.1.m1.3.4.1.cmml" xref="S3.SS3.SSS0.Px1.p3.1.m1.3.4.2"><ci id="S3.SS3.SSS0.Px1.p3.1.m1.1.1.cmml" xref="S3.SS3.SSS0.Px1.p3.1.m1.1.1">𝛼</ci><ci id="S3.SS3.SSS0.Px1.p3.1.m1.2.2.cmml" xref="S3.SS3.SSS0.Px1.p3.1.m1.2.2">𝛾</ci><ci id="S3.SS3.SSS0.Px1.p3.1.m1.3.3.cmml" xref="S3.SS3.SSS0.Px1.p3.1.m1.3.3">𝛽</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px1.p3.1.m1.3c">\alpha,\gamma,\beta</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS0.Px1.p3.1.m1.3d">italic_α , italic_γ , italic_β</annotation></semantics></math> are parameters predicted by two one-hidden-layer MLPs conditioned on time embedding.</p>
</div>
<div class="ltx_para ltx_noindent" id="S3.SS3.SSS0.Px1.p4">
<p class="ltx_p" id="S3.SS3.SSS0.Px1.p4.1">When applied to an image feature map composed of <math alttext="w\times h" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px1.p4.1.m1.1"><semantics id="S3.SS3.SSS0.Px1.p4.1.m1.1a"><mrow id="S3.SS3.SSS0.Px1.p4.1.m1.1.1" xref="S3.SS3.SSS0.Px1.p4.1.m1.1.1.cmml"><mi id="S3.SS3.SSS0.Px1.p4.1.m1.1.1.2" xref="S3.SS3.SSS0.Px1.p4.1.m1.1.1.2.cmml">w</mi><mo id="S3.SS3.SSS0.Px1.p4.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.SS3.SSS0.Px1.p4.1.m1.1.1.1.cmml">×</mo><mi id="S3.SS3.SSS0.Px1.p4.1.m1.1.1.3" xref="S3.SS3.SSS0.Px1.p4.1.m1.1.1.3.cmml">h</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px1.p4.1.m1.1b"><apply id="S3.SS3.SSS0.Px1.p4.1.m1.1.1.cmml" xref="S3.SS3.SSS0.Px1.p4.1.m1.1.1"><times id="S3.SS3.SSS0.Px1.p4.1.m1.1.1.1.cmml" xref="S3.SS3.SSS0.Px1.p4.1.m1.1.1.1"></times><ci id="S3.SS3.SSS0.Px1.p4.1.m1.1.1.2.cmml" xref="S3.SS3.SSS0.Px1.p4.1.m1.1.1.2">𝑤</ci><ci id="S3.SS3.SSS0.Px1.p4.1.m1.1.1.3.cmml" xref="S3.SS3.SSS0.Px1.p4.1.m1.1.1.3">ℎ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px1.p4.1.m1.1c">w\times h</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS0.Px1.p4.1.m1.1d">italic_w × italic_h</annotation></semantics></math> feature vectors, the same affine transformation is repeated for every feature vector.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS3.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Early stop of fine-tuning.</h4>
<div class="ltx_para ltx_noindent" id="S3.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS3.SSS0.Px2.p1.1">Extrapolation may produces training data very close to the original dataset, which makes fine-tuning saturate very quickly.
Excessive fine-tuning epochs would forget knowledge gained from the extrapolated data and overfit small datasets. As a result, the training loss of the diffusion model becomes unreliable. Therefore, fine-tuning should be stopped when the FID score begins to increase.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Synthesizing Fake Images</h3>
<div class="ltx_para ltx_noindent" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">Finally, we introduces how to synthesizing images from scratch. As depicted in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#A0.F8" title="Figure 8 ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_tag">8</span></a>, the synthesis begins with sampling a random vector <math alttext="z" class="ltx_Math" display="inline" id="S3.SS4.p1.1.m1.1"><semantics id="S3.SS4.p1.1.m1.1a"><mi id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><ci id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">z</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.1.m1.1d">italic_z</annotation></semantics></math> from standard Gaussian distribution. And then, this noise is gradually denoised into an image latent code by the diffusion model. The reverse diffusion iterations are formulated as:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathbf{x}_{t-1}=\frac{1}{\sqrt{\alpha_{t}}}\left(\mathbf{x}_{t}-\frac{1-%
\alpha_{t}}{\sqrt{1-\bar{\alpha}_{t}}}\epsilon_{\theta}\left(\mathbf{x}_{t},t%
\right)\right)+\sigma_{t}\mathbf{z}," class="ltx_Math" display="block" id="S3.E7.m1.2"><semantics id="S3.E7.m1.2a"><mrow id="S3.E7.m1.2.2.1" xref="S3.E7.m1.2.2.1.1.cmml"><mrow id="S3.E7.m1.2.2.1.1" xref="S3.E7.m1.2.2.1.1.cmml"><msub id="S3.E7.m1.2.2.1.1.3" xref="S3.E7.m1.2.2.1.1.3.cmml"><mi id="S3.E7.m1.2.2.1.1.3.2" xref="S3.E7.m1.2.2.1.1.3.2.cmml">𝐱</mi><mrow id="S3.E7.m1.2.2.1.1.3.3" xref="S3.E7.m1.2.2.1.1.3.3.cmml"><mi id="S3.E7.m1.2.2.1.1.3.3.2" xref="S3.E7.m1.2.2.1.1.3.3.2.cmml">t</mi><mo id="S3.E7.m1.2.2.1.1.3.3.1" xref="S3.E7.m1.2.2.1.1.3.3.1.cmml">−</mo><mn id="S3.E7.m1.2.2.1.1.3.3.3" xref="S3.E7.m1.2.2.1.1.3.3.3.cmml">1</mn></mrow></msub><mo id="S3.E7.m1.2.2.1.1.2" xref="S3.E7.m1.2.2.1.1.2.cmml">=</mo><mrow id="S3.E7.m1.2.2.1.1.1" xref="S3.E7.m1.2.2.1.1.1.cmml"><mrow id="S3.E7.m1.2.2.1.1.1.1" xref="S3.E7.m1.2.2.1.1.1.1.cmml"><mfrac id="S3.E7.m1.2.2.1.1.1.1.3" xref="S3.E7.m1.2.2.1.1.1.1.3.cmml"><mn id="S3.E7.m1.2.2.1.1.1.1.3.2" xref="S3.E7.m1.2.2.1.1.1.1.3.2.cmml">1</mn><msqrt id="S3.E7.m1.2.2.1.1.1.1.3.3" xref="S3.E7.m1.2.2.1.1.1.1.3.3.cmml"><msub id="S3.E7.m1.2.2.1.1.1.1.3.3.2" xref="S3.E7.m1.2.2.1.1.1.1.3.3.2.cmml"><mi id="S3.E7.m1.2.2.1.1.1.1.3.3.2.2" xref="S3.E7.m1.2.2.1.1.1.1.3.3.2.2.cmml">α</mi><mi id="S3.E7.m1.2.2.1.1.1.1.3.3.2.3" xref="S3.E7.m1.2.2.1.1.1.1.3.3.2.3.cmml">t</mi></msub></msqrt></mfrac><mo id="S3.E7.m1.2.2.1.1.1.1.2" xref="S3.E7.m1.2.2.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E7.m1.2.2.1.1.1.1.1.1" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.cmml"><mo id="S3.E7.m1.2.2.1.1.1.1.1.1.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E7.m1.2.2.1.1.1.1.1.1.1" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.cmml"><msub id="S3.E7.m1.2.2.1.1.1.1.1.1.1.3" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E7.m1.2.2.1.1.1.1.1.1.1.3.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.3.2.cmml">𝐱</mi><mi id="S3.E7.m1.2.2.1.1.1.1.1.1.1.3.3" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.3.3.cmml">t</mi></msub><mo id="S3.E7.m1.2.2.1.1.1.1.1.1.1.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.cmml">−</mo><mrow id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mfrac id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.cmml"><mrow id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.cmml"><mn id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.2.cmml">1</mn><mo id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.1" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.1.cmml">−</mo><msub id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.3" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.cmml"><mi id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.2.cmml">α</mi><mi id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.3" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.3.cmml">t</mi></msub></mrow><msqrt id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.cmml"><mrow id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.cmml"><mn id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.2.cmml">1</mn><mo id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.1" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.1.cmml">−</mo><msub id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.cmml"><mover accent="true" id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.cmml"><mi id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.2.cmml">α</mi><mo id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.1" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.1.cmml">¯</mo></mover><mi id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.3" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.3.cmml">t</mi></msub></mrow></msqrt></mfrac><mo id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><msub id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.4" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.4.cmml"><mi id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.4.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.4.2.cmml">ϵ</mi><mi id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.4.3" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.4.3.cmml">θ</mi></msub><mo id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.2a" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml"><mo id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml">(</mo><msub id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml">𝐱</mi><mi id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml">,</mo><mi id="S3.E7.m1.1.1" xref="S3.E7.m1.1.1.cmml">t</mi><mo id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.4" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E7.m1.2.2.1.1.1.1.1.1.3" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E7.m1.2.2.1.1.1.2" xref="S3.E7.m1.2.2.1.1.1.2.cmml">+</mo><mrow id="S3.E7.m1.2.2.1.1.1.3" xref="S3.E7.m1.2.2.1.1.1.3.cmml"><msub id="S3.E7.m1.2.2.1.1.1.3.2" xref="S3.E7.m1.2.2.1.1.1.3.2.cmml"><mi id="S3.E7.m1.2.2.1.1.1.3.2.2" xref="S3.E7.m1.2.2.1.1.1.3.2.2.cmml">σ</mi><mi id="S3.E7.m1.2.2.1.1.1.3.2.3" xref="S3.E7.m1.2.2.1.1.1.3.2.3.cmml">t</mi></msub><mo id="S3.E7.m1.2.2.1.1.1.3.1" xref="S3.E7.m1.2.2.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E7.m1.2.2.1.1.1.3.3" xref="S3.E7.m1.2.2.1.1.1.3.3.cmml">𝐳</mi></mrow></mrow></mrow><mo id="S3.E7.m1.2.2.1.2" xref="S3.E7.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E7.m1.2b"><apply id="S3.E7.m1.2.2.1.1.cmml" xref="S3.E7.m1.2.2.1"><eq id="S3.E7.m1.2.2.1.1.2.cmml" xref="S3.E7.m1.2.2.1.1.2"></eq><apply id="S3.E7.m1.2.2.1.1.3.cmml" xref="S3.E7.m1.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.1.1.3.1.cmml" xref="S3.E7.m1.2.2.1.1.3">subscript</csymbol><ci id="S3.E7.m1.2.2.1.1.3.2.cmml" xref="S3.E7.m1.2.2.1.1.3.2">𝐱</ci><apply id="S3.E7.m1.2.2.1.1.3.3.cmml" xref="S3.E7.m1.2.2.1.1.3.3"><minus id="S3.E7.m1.2.2.1.1.3.3.1.cmml" xref="S3.E7.m1.2.2.1.1.3.3.1"></minus><ci id="S3.E7.m1.2.2.1.1.3.3.2.cmml" xref="S3.E7.m1.2.2.1.1.3.3.2">𝑡</ci><cn id="S3.E7.m1.2.2.1.1.3.3.3.cmml" type="integer" xref="S3.E7.m1.2.2.1.1.3.3.3">1</cn></apply></apply><apply id="S3.E7.m1.2.2.1.1.1.cmml" xref="S3.E7.m1.2.2.1.1.1"><plus id="S3.E7.m1.2.2.1.1.1.2.cmml" xref="S3.E7.m1.2.2.1.1.1.2"></plus><apply id="S3.E7.m1.2.2.1.1.1.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1"><times id="S3.E7.m1.2.2.1.1.1.1.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.2"></times><apply id="S3.E7.m1.2.2.1.1.1.1.3.cmml" xref="S3.E7.m1.2.2.1.1.1.1.3"><divide id="S3.E7.m1.2.2.1.1.1.1.3.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.3"></divide><cn id="S3.E7.m1.2.2.1.1.1.1.3.2.cmml" type="integer" xref="S3.E7.m1.2.2.1.1.1.1.3.2">1</cn><apply id="S3.E7.m1.2.2.1.1.1.1.3.3.cmml" xref="S3.E7.m1.2.2.1.1.1.1.3.3"><root id="S3.E7.m1.2.2.1.1.1.1.3.3a.cmml" xref="S3.E7.m1.2.2.1.1.1.1.3.3"></root><apply id="S3.E7.m1.2.2.1.1.1.1.3.3.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.1.1.1.1.3.3.2.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.3.3.2">subscript</csymbol><ci id="S3.E7.m1.2.2.1.1.1.1.3.3.2.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.3.3.2.2">𝛼</ci><ci id="S3.E7.m1.2.2.1.1.1.1.3.3.2.3.cmml" xref="S3.E7.m1.2.2.1.1.1.1.3.3.2.3">𝑡</ci></apply></apply></apply><apply id="S3.E7.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1"><minus id="S3.E7.m1.2.2.1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.2"></minus><apply id="S3.E7.m1.2.2.1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E7.m1.2.2.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.3.2">𝐱</ci><ci id="S3.E7.m1.2.2.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.3.3">𝑡</ci></apply><apply id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1"><times id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.2"></times><apply id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3"><divide id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3"></divide><apply id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2"><minus id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.1"></minus><cn id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.2.cmml" type="integer" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.2">1</cn><apply id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.2">𝛼</ci><ci id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.3.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.3.3">𝑡</ci></apply></apply><apply id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3"><root id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3a.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3"></root><apply id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2"><minus id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.1"></minus><cn id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.2.cmml" type="integer" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.2">1</cn><apply id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3">subscript</csymbol><apply id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2"><ci id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.1">¯</ci><ci id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.2.2">𝛼</ci></apply><ci id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.3.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.3.3.2.3.3">𝑡</ci></apply></apply></apply></apply><apply id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.4.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.4">subscript</csymbol><ci id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.4.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.4.2">italic-ϵ</ci><ci id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.4.3.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.4.3">𝜃</ci></apply><interval closure="open" id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1"><apply id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.2">𝐱</ci><ci id="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.2.2.1.1.1.1.1.1.1.1.1.1.1.3">𝑡</ci></apply><ci id="S3.E7.m1.1.1.cmml" xref="S3.E7.m1.1.1">𝑡</ci></interval></apply></apply></apply><apply id="S3.E7.m1.2.2.1.1.1.3.cmml" xref="S3.E7.m1.2.2.1.1.1.3"><times id="S3.E7.m1.2.2.1.1.1.3.1.cmml" xref="S3.E7.m1.2.2.1.1.1.3.1"></times><apply id="S3.E7.m1.2.2.1.1.1.3.2.cmml" xref="S3.E7.m1.2.2.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E7.m1.2.2.1.1.1.3.2.1.cmml" xref="S3.E7.m1.2.2.1.1.1.3.2">subscript</csymbol><ci id="S3.E7.m1.2.2.1.1.1.3.2.2.cmml" xref="S3.E7.m1.2.2.1.1.1.3.2.2">𝜎</ci><ci id="S3.E7.m1.2.2.1.1.1.3.2.3.cmml" xref="S3.E7.m1.2.2.1.1.1.3.2.3">𝑡</ci></apply><ci id="S3.E7.m1.2.2.1.1.1.3.3.cmml" xref="S3.E7.m1.2.2.1.1.1.3.3">𝐳</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.2c">\mathbf{x}_{t-1}=\frac{1}{\sqrt{\alpha_{t}}}\left(\mathbf{x}_{t}-\frac{1-%
\alpha_{t}}{\sqrt{1-\bar{\alpha}_{t}}}\epsilon_{\theta}\left(\mathbf{x}_{t},t%
\right)\right)+\sigma_{t}\mathbf{z},</annotation><annotation encoding="application/x-llamapun" id="S3.E7.m1.2d">bold_x start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT = divide start_ARG 1 end_ARG start_ARG square-root start_ARG italic_α start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG end_ARG ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT - divide start_ARG 1 - italic_α start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG start_ARG square-root start_ARG 1 - over¯ start_ARG italic_α end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG end_ARG italic_ϵ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( bold_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_t ) ) + italic_σ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT bold_z ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS4.p1.5">where, <math alttext="\alpha_{t}" class="ltx_Math" display="inline" id="S3.SS4.p1.2.m1.1"><semantics id="S3.SS4.p1.2.m1.1a"><msub id="S3.SS4.p1.2.m1.1.1" xref="S3.SS4.p1.2.m1.1.1.cmml"><mi id="S3.SS4.p1.2.m1.1.1.2" xref="S3.SS4.p1.2.m1.1.1.2.cmml">α</mi><mi id="S3.SS4.p1.2.m1.1.1.3" xref="S3.SS4.p1.2.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m1.1b"><apply id="S3.SS4.p1.2.m1.1.1.cmml" xref="S3.SS4.p1.2.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.2.m1.1.1.1.cmml" xref="S3.SS4.p1.2.m1.1.1">subscript</csymbol><ci id="S3.SS4.p1.2.m1.1.1.2.cmml" xref="S3.SS4.p1.2.m1.1.1.2">𝛼</ci><ci id="S3.SS4.p1.2.m1.1.1.3.cmml" xref="S3.SS4.p1.2.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m1.1c">\alpha_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.2.m1.1d">italic_α start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="\bar{\alpha}_{t}" class="ltx_Math" display="inline" id="S3.SS4.p1.3.m2.1"><semantics id="S3.SS4.p1.3.m2.1a"><msub id="S3.SS4.p1.3.m2.1.1" xref="S3.SS4.p1.3.m2.1.1.cmml"><mover accent="true" id="S3.SS4.p1.3.m2.1.1.2" xref="S3.SS4.p1.3.m2.1.1.2.cmml"><mi id="S3.SS4.p1.3.m2.1.1.2.2" xref="S3.SS4.p1.3.m2.1.1.2.2.cmml">α</mi><mo id="S3.SS4.p1.3.m2.1.1.2.1" xref="S3.SS4.p1.3.m2.1.1.2.1.cmml">¯</mo></mover><mi id="S3.SS4.p1.3.m2.1.1.3" xref="S3.SS4.p1.3.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.3.m2.1b"><apply id="S3.SS4.p1.3.m2.1.1.cmml" xref="S3.SS4.p1.3.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.3.m2.1.1.1.cmml" xref="S3.SS4.p1.3.m2.1.1">subscript</csymbol><apply id="S3.SS4.p1.3.m2.1.1.2.cmml" xref="S3.SS4.p1.3.m2.1.1.2"><ci id="S3.SS4.p1.3.m2.1.1.2.1.cmml" xref="S3.SS4.p1.3.m2.1.1.2.1">¯</ci><ci id="S3.SS4.p1.3.m2.1.1.2.2.cmml" xref="S3.SS4.p1.3.m2.1.1.2.2">𝛼</ci></apply><ci id="S3.SS4.p1.3.m2.1.1.3.cmml" xref="S3.SS4.p1.3.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.3.m2.1c">\bar{\alpha}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.3.m2.1d">over¯ start_ARG italic_α end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="\sigma_{t}" class="ltx_Math" display="inline" id="S3.SS4.p1.4.m3.1"><semantics id="S3.SS4.p1.4.m3.1a"><msub id="S3.SS4.p1.4.m3.1.1" xref="S3.SS4.p1.4.m3.1.1.cmml"><mi id="S3.SS4.p1.4.m3.1.1.2" xref="S3.SS4.p1.4.m3.1.1.2.cmml">σ</mi><mi id="S3.SS4.p1.4.m3.1.1.3" xref="S3.SS4.p1.4.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.4.m3.1b"><apply id="S3.SS4.p1.4.m3.1.1.cmml" xref="S3.SS4.p1.4.m3.1.1"><csymbol cd="ambiguous" id="S3.SS4.p1.4.m3.1.1.1.cmml" xref="S3.SS4.p1.4.m3.1.1">subscript</csymbol><ci id="S3.SS4.p1.4.m3.1.1.2.cmml" xref="S3.SS4.p1.4.m3.1.1.2">𝜎</ci><ci id="S3.SS4.p1.4.m3.1.1.3.cmml" xref="S3.SS4.p1.4.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.4.m3.1c">\sigma_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.4.m3.1d">italic_σ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> are diffusion hyper-parameters, and <math alttext="z" class="ltx_Math" display="inline" id="S3.SS4.p1.5.m4.1"><semantics id="S3.SS4.p1.5.m4.1a"><mi id="S3.SS4.p1.5.m4.1.1" xref="S3.SS4.p1.5.m4.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.5.m4.1b"><ci id="S3.SS4.p1.5.m4.1.1.cmml" xref="S3.SS4.p1.5.m4.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.5.m4.1c">z</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.p1.5.m4.1d">italic_z</annotation></semantics></math> is a random vector sampled from standard Gaussian distribution. At last, we decode image latent codes into images with the pre-trained decoder from Stable Diffusion <cite class="ltx_cite ltx_citemacro_citep">(Rombach et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib28" title="">2022</a>)</cite>.</p>
</div>
<section class="ltx_paragraph" id="S3.SS4.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">NULL guidance.</h4>
<div class="ltx_para ltx_noindent" id="S3.SS4.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS4.SSS0.Px1.p1.3">A sentence with no new information is able to boost text-to-image performance obviously. This guidance is inspired by Classifier-free diffusion guidance <cite class="ltx_cite ltx_citemacro_citep">(Ho &amp; Salimans, <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib10" title="">2022</a>)</cite> which uses a dummy class label to boost label-to-image performance. Similarly, we design CLIP prompt without obvious visual meaning and embed them into the diffusion model. Specifically, we denote the original score estimation based on text description as <math alttext="\epsilon_{text}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p1.1.m1.1"><semantics id="S3.SS4.SSS0.Px1.p1.1.m1.1a"><msub id="S3.SS4.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.2" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.2.cmml">ϵ</mi><mrow id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.2" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.2.cmml">t</mi><mo id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.1" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.3" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.3.cmml">e</mi><mo id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.1a" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.4" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.4.cmml">x</mi><mo id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.1b" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.5" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.5.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p1.1.m1.1b"><apply id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.2">italic-ϵ</ci><apply id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3"><times id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.2">𝑡</ci><ci id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.3">𝑒</ci><ci id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.4.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.4">𝑥</ci><ci id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.5.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.5">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p1.1.m1.1c">\epsilon_{text}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p1.1.m1.1d">italic_ϵ start_POSTSUBSCRIPT italic_t italic_e italic_x italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and score estimation based on null description as <math alttext="\epsilon_{null}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p1.2.m2.1"><semantics id="S3.SS4.SSS0.Px1.p1.2.m2.1a"><msub id="S3.SS4.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.2.cmml">ϵ</mi><mrow id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.2" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.2.cmml">n</mi><mo id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.1" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.3" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.3.cmml">u</mi><mo id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.1a" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.4" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.4.cmml">l</mi><mo id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.1b" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.5" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.5.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.2">italic-ϵ</ci><apply id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3"><times id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.2">𝑛</ci><ci id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.3">𝑢</ci><ci id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.4.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.4">𝑙</ci><ci id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.5.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.5">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p1.2.m2.1c">\epsilon_{null}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p1.2.m2.1d">italic_ϵ start_POSTSUBSCRIPT italic_n italic_u italic_l italic_l end_POSTSUBSCRIPT</annotation></semantics></math>. Then we mix these two estimations for a more accurate estimation <math alttext="\epsilon^{\prime}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p1.3.m3.1"><semantics id="S3.SS4.SSS0.Px1.p1.3.m3.1a"><msup id="S3.SS4.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1.cmml"><mi id="S3.SS4.SSS0.Px1.p1.3.m3.1.1.2" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1.2.cmml">ϵ</mi><mo id="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p1.3.m3.1b"><apply id="S3.SS4.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1">superscript</csymbol><ci id="S3.SS4.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1.2">italic-ϵ</ci><ci id="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p1.3.m3.1c">\epsilon^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p1.3.m3.1d">italic_ϵ start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E8">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\epsilon^{\prime}=(\epsilon_{text}-\epsilon_{null})\times\eta+\epsilon_{null}," class="ltx_Math" display="block" id="S3.E8.m1.1"><semantics id="S3.E8.m1.1a"><mrow id="S3.E8.m1.1.1.1" xref="S3.E8.m1.1.1.1.1.cmml"><mrow id="S3.E8.m1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.cmml"><msup id="S3.E8.m1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.3.cmml"><mi id="S3.E8.m1.1.1.1.1.3.2" xref="S3.E8.m1.1.1.1.1.3.2.cmml">ϵ</mi><mo id="S3.E8.m1.1.1.1.1.3.3" xref="S3.E8.m1.1.1.1.1.3.3.cmml">′</mo></msup><mo id="S3.E8.m1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.2.cmml">=</mo><mrow id="S3.E8.m1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.cmml"><mrow id="S3.E8.m1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.cmml"><mrow id="S3.E8.m1.1.1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S3.E8.m1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E8.m1.1.1.1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.cmml"><msub id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.2.cmml">ϵ</mi><mrow id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.1" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.3" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.3.cmml">e</mi><mo id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.1a" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.4" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.4.cmml">x</mi><mo id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.1b" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.5" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.5.cmml">t</mi></mrow></msub><mo id="S3.E8.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msub id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.cmml">ϵ</mi><mrow id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.2" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.2.cmml">n</mi><mo id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.1" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.3" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.3.cmml">u</mi><mo id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.1a" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.4" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.4.cmml">l</mi><mo id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.1b" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.5" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.5.cmml">l</mi></mrow></msub></mrow><mo id="S3.E8.m1.1.1.1.1.1.1.1.1.3" rspace="0.055em" stretchy="false" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S3.E8.m1.1.1.1.1.1.1.2" rspace="0.222em" xref="S3.E8.m1.1.1.1.1.1.1.2.cmml">×</mo><mi id="S3.E8.m1.1.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.1.1.3.cmml">η</mi></mrow><mo id="S3.E8.m1.1.1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.1.2.cmml">+</mo><msub id="S3.E8.m1.1.1.1.1.1.3" xref="S3.E8.m1.1.1.1.1.1.3.cmml"><mi id="S3.E8.m1.1.1.1.1.1.3.2" xref="S3.E8.m1.1.1.1.1.1.3.2.cmml">ϵ</mi><mrow id="S3.E8.m1.1.1.1.1.1.3.3" xref="S3.E8.m1.1.1.1.1.1.3.3.cmml"><mi id="S3.E8.m1.1.1.1.1.1.3.3.2" xref="S3.E8.m1.1.1.1.1.1.3.3.2.cmml">n</mi><mo id="S3.E8.m1.1.1.1.1.1.3.3.1" xref="S3.E8.m1.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E8.m1.1.1.1.1.1.3.3.3" xref="S3.E8.m1.1.1.1.1.1.3.3.3.cmml">u</mi><mo id="S3.E8.m1.1.1.1.1.1.3.3.1a" xref="S3.E8.m1.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E8.m1.1.1.1.1.1.3.3.4" xref="S3.E8.m1.1.1.1.1.1.3.3.4.cmml">l</mi><mo id="S3.E8.m1.1.1.1.1.1.3.3.1b" xref="S3.E8.m1.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E8.m1.1.1.1.1.1.3.3.5" xref="S3.E8.m1.1.1.1.1.1.3.3.5.cmml">l</mi></mrow></msub></mrow></mrow><mo id="S3.E8.m1.1.1.1.2" xref="S3.E8.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E8.m1.1b"><apply id="S3.E8.m1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1"><eq id="S3.E8.m1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.2"></eq><apply id="S3.E8.m1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.3.1.cmml" xref="S3.E8.m1.1.1.1.1.3">superscript</csymbol><ci id="S3.E8.m1.1.1.1.1.3.2.cmml" xref="S3.E8.m1.1.1.1.1.3.2">italic-ϵ</ci><ci id="S3.E8.m1.1.1.1.1.3.3.cmml" xref="S3.E8.m1.1.1.1.1.3.3">′</ci></apply><apply id="S3.E8.m1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1"><plus id="S3.E8.m1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.1.2"></plus><apply id="S3.E8.m1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1"><times id="S3.E8.m1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.2"></times><apply id="S3.E8.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1"><minus id="S3.E8.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.1"></minus><apply id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.2">italic-ϵ</ci><apply id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3"><times id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.1"></times><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.2">𝑡</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.3">𝑒</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.4.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.4">𝑥</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.5.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.2.3.5">𝑡</ci></apply></apply><apply id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.2">italic-ϵ</ci><apply id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3"><times id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.1"></times><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.2">𝑛</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.3">𝑢</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.4.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.4">𝑙</ci><ci id="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.5.cmml" xref="S3.E8.m1.1.1.1.1.1.1.1.1.1.3.3.5">𝑙</ci></apply></apply></apply><ci id="S3.E8.m1.1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.1.1.3">𝜂</ci></apply><apply id="S3.E8.m1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E8.m1.1.1.1.1.1.3.1.cmml" xref="S3.E8.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S3.E8.m1.1.1.1.1.1.3.2.cmml" xref="S3.E8.m1.1.1.1.1.1.3.2">italic-ϵ</ci><apply id="S3.E8.m1.1.1.1.1.1.3.3.cmml" xref="S3.E8.m1.1.1.1.1.1.3.3"><times id="S3.E8.m1.1.1.1.1.1.3.3.1.cmml" xref="S3.E8.m1.1.1.1.1.1.3.3.1"></times><ci id="S3.E8.m1.1.1.1.1.1.3.3.2.cmml" xref="S3.E8.m1.1.1.1.1.1.3.3.2">𝑛</ci><ci id="S3.E8.m1.1.1.1.1.1.3.3.3.cmml" xref="S3.E8.m1.1.1.1.1.1.3.3.3">𝑢</ci><ci id="S3.E8.m1.1.1.1.1.1.3.3.4.cmml" xref="S3.E8.m1.1.1.1.1.1.3.3.4">𝑙</ci><ci id="S3.E8.m1.1.1.1.1.1.3.3.5.cmml" xref="S3.E8.m1.1.1.1.1.1.3.3.5">𝑙</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.1c">\epsilon^{\prime}=(\epsilon_{text}-\epsilon_{null})\times\eta+\epsilon_{null},</annotation><annotation encoding="application/x-llamapun" id="S3.E8.m1.1d">italic_ϵ start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = ( italic_ϵ start_POSTSUBSCRIPT italic_t italic_e italic_x italic_t end_POSTSUBSCRIPT - italic_ϵ start_POSTSUBSCRIPT italic_n italic_u italic_l italic_l end_POSTSUBSCRIPT ) × italic_η + italic_ϵ start_POSTSUBSCRIPT italic_n italic_u italic_l italic_l end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS4.SSS0.Px1.p1.5">where, <math alttext="\eta" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p1.4.m1.1"><semantics id="S3.SS4.SSS0.Px1.p1.4.m1.1a"><mi id="S3.SS4.SSS0.Px1.p1.4.m1.1.1" xref="S3.SS4.SSS0.Px1.p1.4.m1.1.1.cmml">η</mi><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p1.4.m1.1b"><ci id="S3.SS4.SSS0.Px1.p1.4.m1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.4.m1.1.1">𝜂</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p1.4.m1.1c">\eta</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p1.4.m1.1d">italic_η</annotation></semantics></math> is the guidance ration controlling the balance of two estimations. When <math alttext="\eta=1" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p1.5.m2.1"><semantics id="S3.SS4.SSS0.Px1.p1.5.m2.1a"><mrow id="S3.SS4.SSS0.Px1.p1.5.m2.1.1" xref="S3.SS4.SSS0.Px1.p1.5.m2.1.1.cmml"><mi id="S3.SS4.SSS0.Px1.p1.5.m2.1.1.2" xref="S3.SS4.SSS0.Px1.p1.5.m2.1.1.2.cmml">η</mi><mo id="S3.SS4.SSS0.Px1.p1.5.m2.1.1.1" xref="S3.SS4.SSS0.Px1.p1.5.m2.1.1.1.cmml">=</mo><mn id="S3.SS4.SSS0.Px1.p1.5.m2.1.1.3" xref="S3.SS4.SSS0.Px1.p1.5.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p1.5.m2.1b"><apply id="S3.SS4.SSS0.Px1.p1.5.m2.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.5.m2.1.1"><eq id="S3.SS4.SSS0.Px1.p1.5.m2.1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.5.m2.1.1.1"></eq><ci id="S3.SS4.SSS0.Px1.p1.5.m2.1.1.2.cmml" xref="S3.SS4.SSS0.Px1.p1.5.m2.1.1.2">𝜂</ci><cn id="S3.SS4.SSS0.Px1.p1.5.m2.1.1.3.cmml" type="integer" xref="S3.SS4.SSS0.Px1.p1.5.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p1.5.m2.1c">\eta=1</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p1.5.m2.1d">italic_η = 1</annotation></semantics></math>, NULL Guidance falls back to an ordinary score estimation. Usually, a NULL prompt with the average meaning of the dataset achieve the best performance.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<figure class="ltx_figure" id="S4.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" id="S4.F3.33" style="width:45.7pt;">A small bird with blue-grey wings, rust colored sides and white collar.</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" id="S4.F3.34" style="width:45.7pt;">This bird is white from crown to belly, with gray wingbars and retrices.</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" id="S4.F3.35" style="width:45.7pt;">This bird is mainly grey, it has brown on the feathers and back of the tail.</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" id="S4.F3.36" style="width:45.7pt;">A bird with blue head, white belly and breast, and the bill is pointed.</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" id="S4.F3.37" style="width:45.7pt;">This flower has a lot of dark red petals and no visible outer stigma or stamen.</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" id="S4.F3.38" style="width:45.7pt;">This flower has petals that are purple and bunched together.</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" id="S4.F3.39" style="width:45.7pt;">This flower has large smooth white petals that turn yellow toward the center.</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" id="S4.F3.40" style="width:45.7pt;">A pale purple five petaled flower with yellow stamen and green stigma.</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_inline-block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle ltx_transformed_outer" id="S4.F3.41" style="width:8.0pt;height:15.1pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:15.1pt;transform:translate(-4.12pt,-4.12pt) rotate(-90deg) ;">
<p class="ltx_p" id="S4.F3.41.1">GT</p>
</span></div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.1" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.1.g1" src="extracted/5896104/fig/fig_1/real/1.jpg" width="548"/>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.2" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.2.g1" src="extracted/5896104/fig/fig_1/real/2_3.jpg" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.3" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.3.g1" src="extracted/5896104/fig/fig_1/real/3.jpg" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.4" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.4.g1" src="extracted/5896104/fig/fig_1/real/4.jpg" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.5" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.5.g1" src="extracted/5896104/fig/fig_f/real/1.jpg" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.6" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.6.g1" src="extracted/5896104/fig/fig_f/real/2.jpg" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.7" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.7.g1" src="extracted/5896104/fig/fig_f/real/3.jpg" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.8" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.8.g1" src="extracted/5896104/fig/fig_f/real/4.jpg" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_inline-block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle ltx_transformed_outer" id="S4.F3.42" style="width:8.0pt;height:40.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:40.3pt;transform:translate(-16.76pt,-16.76pt) rotate(-90deg) ;">
<p class="ltx_p" id="S4.F3.42.1">DF-GAN</p>
</span></div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.9" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.9.g1" src="extracted/5896104/fig/fig_1/dfgan/1.png" width="548"/>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.10" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.10.g1" src="extracted/5896104/fig/fig_1/dfgan/2_3.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.11" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.11.g1" src="extracted/5896104/fig/fig_1/dfgan/3.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.12" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.12.g1" src="extracted/5896104/fig/fig_1/dfgan/4.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.13" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.13.g1" src="extracted/5896104/fig/fig_f/dfgan/1.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.14" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.14.g1" src="extracted/5896104/fig/fig_f/dfgan/2.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.15" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.15.g1" src="extracted/5896104/fig/fig_f/dfgan/3.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.16" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.16.g1" src="extracted/5896104/fig/fig_f/dfgan/4.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_inline-block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle ltx_transformed_outer" id="S4.F3.43" style="width:8.0pt;height:47.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:47.4pt;transform:translate(-20.3pt,-20.3pt) rotate(-90deg) ;">
<p class="ltx_p" id="S4.F3.43.1">RAT-GAN</p>
</span></div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.17" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.17.g1" src="extracted/5896104/fig/fig_1/ours/1.png" width="548"/>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.18" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.18.g1" src="extracted/5896104/fig/fig_1/ours/2_3.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.19" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.19.g1" src="extracted/5896104/fig/fig_1/ours/3.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.20" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.20.g1" src="extracted/5896104/fig/fig_1/ours/4.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.21" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.21.g1" src="extracted/5896104/fig/fig_f/ours/1.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.22" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.22.g1" src="extracted/5896104/fig/fig_f/ours/2.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.23" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.23.g1" src="extracted/5896104/fig/fig_f/ours/33.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.24" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.24.g1" src="extracted/5896104/fig/fig_f/ours/4.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_inline-block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle ltx_transformed_outer" id="S4.F3.44" style="width:8.0pt;height:21.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:21.2pt;transform:translate(-7.18pt,-7.18pt) rotate(-90deg) ;">
<p class="ltx_p" id="S4.F3.44.1">Ours</p>
</span></div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.25" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.25.g1" src="extracted/5896104/fig/fig_1/diff/1.png" width="548"/>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.26" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.26.g1" src="extracted/5896104/fig/fig_1/diff/2.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.27" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.27.g1" src="extracted/5896104/fig/fig_1/diff/3.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.28" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.28.g1" src="extracted/5896104/fig/fig_1/diff/4.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.29" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.29.g1" src="extracted/5896104/fig/fig_f/diff/1.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.30" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.30.g1" src="extracted/5896104/fig/fig_f/diff/2.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.31" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.31.g1" src="extracted/5896104/fig/fig_f/diff/3.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F3.32" style="width:45.7pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F3.32.g1" src="extracted/5896104/fig/fig_f/diff/4.png" width="548"/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Qualitative comparison on the CUB and Oxford dataset. The input text descriptions are given in the first row and the corresponding generated images from different methods are shown in the same column. Best view in color and zoom in.</figcaption>
</figure>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Datasets.</h4>
<div class="ltx_para ltx_noindent" id="S4.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p1.1">We report results on the popular CUB, Oxford-102, and MS COCO datasets. The CUB dataset includes 200 categories with a total of 11,788 bird images, while the Oxford-102 dataset contains 102 categories with 8,189 flower images. Unlike the approaches taken in <cite class="ltx_cite ltx_citemacro_cite">Reed et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib26" title="">2016a</a>; <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib27" title="">b</a>)</cite>, we utilize the entire dataset for both training and testing. Each image is paired with 10 captions. To expand the original datasets, we collect 300,000 bird images and 130,000 flower images. The MS COCO dataset comprises 123,287 images, each with 5 sentence annotations. We use the official training split of COCO for training and the official validation split for testing. During mini-batch selection, a random image view (e.g., crop or flip) is chosen for one of the captions.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Web images.</h4>
<div class="ltx_para ltx_noindent" id="S4.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px2.p1.1">For the CUB and Oxford datasets, we collected 603,484 bird images and 331,602 flower images using search engines, utilizing fine-grained classification labels as search keywords. After removing detected outliers, we retained 399,246 bird images and 132,648 flower images. In the case of the COCO dataset, we gathered 770,059 daily images without applying any outlier detection, as the precise descriptions in COCO allow search engines to retrieve clean images effectively.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Training details.</h4>
<div class="ltx_para ltx_noindent" id="S4.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px3.p1.1">The text encoder is a pre-trained CLIP text encoder with an output of size <math alttext="512" class="ltx_Math" display="inline" id="S4.SS0.SSS0.Px3.p1.1.m1.1"><semantics id="S4.SS0.SSS0.Px3.p1.1.m1.1a"><mn id="S4.SS0.SSS0.Px3.p1.1.m1.1.1" xref="S4.SS0.SSS0.Px3.p1.1.m1.1.1.cmml">512</mn><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px3.p1.1.m1.1b"><cn id="S4.SS0.SSS0.Px3.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS0.SSS0.Px3.p1.1.m1.1.1">512</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px3.p1.1.m1.1c">512</annotation><annotation encoding="application/x-llamapun" id="S4.SS0.SSS0.Px3.p1.1.m1.1d">512</annotation></semantics></math>. The latent encoder and decoder is pre-trained by Stable Diffusion <cite class="ltx_cite ltx_citemacro_citep">(Rombach et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib28" title="">2022</a>)</cite>. We have tried to pre-train new latent encoders on extrapolated data but the results are not satisfying.
Adam optimizer is used to optimize the network with base learning rates of 0.0001 and weight decay of 0. The same as RAT-GAN, we used a mini-batch size of 24 to train the model. Most training and testing of our model are conducted on 2 RTX 3090 Ti and the detailed training consumption is listed in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.T3" title="Table 3 ‣ Analysis of extrapolation quantity. ‣ 4.2 Ablation Studies ‣ 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Evaluation metrics.</h4>
<div class="ltx_para ltx_noindent" id="S4.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px4.p1.1">We adopt the widely used Inception Score (IS) <cite class="ltx_cite ltx_citemacro_citep">(Salimans et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib31" title="">2016</a>)</cite> and Fréchet Inception Distance (FID) <cite class="ltx_cite ltx_citemacro_citep">(Heusel et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib9" title="">2017</a>)</cite> to quantify the performance. On the MS COCO dataset, an Inception-v3 network pre-trained on the ImageNet dataset is used to compute the KL-divergence between the conditional class distribution (generated images) and the marginal class distribution (real images). The presence of a large IS indicates that the generated images are of high quality. The FID computes the Fréchet Distance between the image feature distributions of the generated and real-world images. The image features are extracted by the same pre-trained Inception v3 network. A lower FID implies the generated images are closer to the real images. We only compare the FID on the COCO dataset. On the CUB and Oxford-102 dataset, pre-trained Inception models are fine-tuned on two fine-grained classification tasks <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib45" title="">2019</a>)</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS0.SSS0.Px4.p2">
<p class="ltx_p" id="S4.SS0.SSS0.Px4.p2.1">There are two conflicts in evaluation methods in previous works. First, some studies report Inception Score (IS) using the ImageNet Inception model, while others use a fine-tuned version. Second, some works evaluate using the entire training data, whereas others use only the test split. To address these inconsistencies, we report IS and FID using both Inception models and employ the same Inception model as DM-GAN for consistency. Additionally, to resolve conflicts related to data splits, we report the FID scores of our model and other re-implemented models using the entire dataset for both training and testing. According to results from RAT-GAN <cite class="ltx_cite ltx_citemacro_citep">(Ye et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib42" title="">2023</a>)</cite>, training and testing on the full dataset typically yields the best FID scores. We will also release all evaluation codes on GitHub.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph">Compared models.</h4>
<div class="ltx_para ltx_noindent" id="S4.SS0.SSS0.Px5.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px5.p1.1">We compare our model with recent state-of-the-art methods: StackGAN++ <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib45" title="">2019</a>)</cite>, DM-GAN <cite class="ltx_cite ltx_citemacro_citep">(Zhu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib49" title="">2019</a>)</cite>, DF-GAN <cite class="ltx_cite ltx_citemacro_citep">(Tao et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib37" title="">2022</a>)</cite>, DAE-GAN <cite class="ltx_cite ltx_citemacro_citep">(Ruan et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib29" title="">2021</a>)</cite>, VQ-diffusion <cite class="ltx_cite ltx_citemacro_citep">(Gu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib8" title="">2022</a>)</cite>, AttnGAN <cite class="ltx_cite ltx_citemacro_citep">(Xu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib40" title="">2018</a>)</cite>,
GALIP <cite class="ltx_cite ltx_citemacro_citep">(Zhang &amp; Schomaker, <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib47" title="">2021</a>)</cite>,U-ViT <cite class="ltx_cite ltx_citemacro_citep">(Bao et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib2" title="">2023</a>)</cite>, and RAT-GAN <cite class="ltx_cite ltx_citemacro_citep">(Ye et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib42" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Comparisons with Others</h3>
<figure class="ltx_table" id="S4.T1">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Performance of IS and FID of StackGAN++, AttnGAN, SSGAN, DM-GAN, DTGAN, DF-GAN and our method on the CUB, Oxford and MS COCO datasets. The results are taken from the authors’ own papers.
The best results are in bold.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T1.4" style="width:397.5pt;height:203.5pt;vertical-align:-0.9pt;"><span class="ltx_transformed_inner" style="transform:translate(-13.2pt,6.7pt) scale(0.93792,0.93792) ;">
<p class="ltx_p" id="S4.T1.4.4"><span class="ltx_text" id="S4.T1.4.4.4">
<span class="ltx_inline-block ltx_transformed_outer" id="S4.T1.4.4.4.4" style="width:423.8pt;height:217pt;vertical-align:-1.0pt;"><span class="ltx_transformed_inner" style="transform:translate(0.0pt,0.0pt) scale(1,1) ;">
<span class="ltx_p" id="S4.T1.4.4.4.4.4"><span class="ltx_text" id="S4.T1.4.4.4.4.4.4">
<span class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T1.4.4.4.4.4.4.4">
<span class="ltx_thead">
<span class="ltx_tr" id="S4.T1.4.4.4.4.4.4.4.4">
<span class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt ltx_rowspan ltx_rowspan_2" id="S4.T1.4.4.4.4.4.4.4.4.5"><span class="ltx_text" id="S4.T1.4.4.4.4.4.4.4.4.5.1">Methods</span></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_colspan ltx_colspan_2" id="S4.T1.1.1.1.1.1.1.1.1.1">IS(Fine-tune) <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1"><semantics id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1a"><mo id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1" stretchy="false" xref="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.1.1.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.1.1.1.1.1.1.1.1.1.m1.1d">↑</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_colspan ltx_colspan_2" id="S4.T1.2.2.2.2.2.2.2.2.2">IS(ImageNet) <math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T1.2.2.2.2.2.2.2.2.2.m1.1"><semantics id="S4.T1.2.2.2.2.2.2.2.2.2.m1.1a"><mo id="S4.T1.2.2.2.2.2.2.2.2.2.m1.1.1" stretchy="false" xref="S4.T1.2.2.2.2.2.2.2.2.2.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.2.2.2.2.2.2.m1.1b"><ci id="S4.T1.2.2.2.2.2.2.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.2.2.2.2.2.2.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.2.2.2.2.2.2.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.2.2.2.2.2.2.2.2.2.m1.1d">↑</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_colspan ltx_colspan_2" id="S4.T1.3.3.3.3.3.3.3.3.3">FID(Fine-tune) <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T1.3.3.3.3.3.3.3.3.3.m1.1"><semantics id="S4.T1.3.3.3.3.3.3.3.3.3.m1.1a"><mo id="S4.T1.3.3.3.3.3.3.3.3.3.m1.1.1" stretchy="false" xref="S4.T1.3.3.3.3.3.3.3.3.3.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.3.3.3.3.3.3.m1.1b"><ci id="S4.T1.3.3.3.3.3.3.3.3.3.m1.1.1.cmml" xref="S4.T1.3.3.3.3.3.3.3.3.3.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.3.3.3.3.3.3.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.3.3.3.3.3.3.3.3.3.m1.1d">↓</annotation></semantics></math></span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt ltx_colspan ltx_colspan_3" id="S4.T1.4.4.4.4.4.4.4.4.4">FID(ImageNet) <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T1.4.4.4.4.4.4.4.4.4.m1.1"><semantics id="S4.T1.4.4.4.4.4.4.4.4.4.m1.1a"><mo id="S4.T1.4.4.4.4.4.4.4.4.4.m1.1.1" stretchy="false" xref="S4.T1.4.4.4.4.4.4.4.4.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.4.4.4.4.4.4.4.m1.1b"><ci id="S4.T1.4.4.4.4.4.4.4.4.4.m1.1.1.cmml" xref="S4.T1.4.4.4.4.4.4.4.4.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.4.4.4.4.4.4.4.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.4.4.4.4.4.4.4.4.4.m1.1d">↓</annotation></semantics></math></span></span>
<span class="ltx_tr" id="S4.T1.4.4.4.4.4.4.4.5.1">
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.4.4.4.4.4.4.4.5.1.1">CUB</span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.4.4.4.4.4.4.4.5.1.2">Oxford</span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.4.4.4.4.4.4.4.5.1.3">CUB</span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.4.4.4.4.4.4.4.5.1.4">Oxford</span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.4.4.4.4.4.4.4.5.1.5">CUB</span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.4.4.4.4.4.4.4.5.1.6">Oxford</span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.4.4.4.4.4.4.4.5.1.7">CUB</span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.4.4.4.4.4.4.4.5.1.8">Oxford</span>
<span class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" id="S4.T1.4.4.4.4.4.4.4.5.1.9">COCO</span></span>
</span>
<span class="ltx_tbody">
<span class="ltx_tr" id="S4.T1.4.4.4.4.4.4.4.6.1">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.4.4.4.4.4.4.4.6.1.1">StackGAN++</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.4.4.4.4.4.6.1.2">4.04</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.4.4.4.4.4.6.1.3">3.26</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.4.4.4.4.4.6.1.4">4.04</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.4.4.4.4.4.6.1.5">3.26</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.4.4.4.4.4.6.1.6">23.96</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.4.4.4.4.4.6.1.7">48.68</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.4.4.4.4.4.6.1.8">15.30</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.4.4.4.4.4.6.1.9">32.33</span>
<span class="ltx_td ltx_align_center ltx_border_t" id="S4.T1.4.4.4.4.4.4.4.6.1.10">81.59</span></span>
<span class="ltx_tr" id="S4.T1.4.4.4.4.4.4.4.7.2">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.4.4.4.4.4.4.7.2.1">AttnGAN</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.7.2.2">4.36</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.7.2.3">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.7.2.4">4.36</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.7.2.5">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.7.2.6">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.7.2.7">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.7.2.8">23.98</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.7.2.9">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.7.2.10">35.49</span></span>
<span class="ltx_tr" id="S4.T1.4.4.4.4.4.4.4.8.3">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.4.4.4.4.4.4.8.3.1">DAE-GAN</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.8.3.2">4.42</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.8.3.3">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.8.3.4">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.8.3.5">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.8.3.6">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.8.3.7">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.8.3.8">15.19</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.8.3.9">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.8.3.10">28.12</span></span>
<span class="ltx_tr" id="S4.T1.4.4.4.4.4.4.4.9.4">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.4.4.4.4.4.4.9.4.1">DM-GAN</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.9.4.2">4.75</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.9.4.3">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.9.4.4">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.9.4.5">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.9.4.6">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.9.4.7">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.9.4.8">16.09</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.9.4.9">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.9.4.10">32.64</span></span>
<span class="ltx_tr" id="S4.T1.4.4.4.4.4.4.4.10.5">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.4.4.4.4.4.4.10.5.1">DF-GAN</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.10.5.2">5.10</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.10.5.3">3.80</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.10.5.4">4.96</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.10.5.5">3.92</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.10.5.6">17.23</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.10.5.7">18.90</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.10.5.8">14.81</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.10.5.9">22.56</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.10.5.10">21.42</span></span>
<span class="ltx_tr" id="S4.T1.4.4.4.4.4.4.4.11.6">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.4.4.4.4.4.4.11.6.1">RAT-GAN</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.11.6.2">5.36</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.11.6.3">4.09</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.11.6.4">5.00</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.11.6.5">3.95</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.11.6.6">13.91</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.11.6.7">16.04</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.11.6.8">10.21</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.11.6.9">18.68</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.11.6.10">14.60</span></span>
<span class="ltx_tr" id="S4.T1.4.4.4.4.4.4.4.12.7">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.4.4.4.4.4.4.12.7.1">GALIP</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.12.7.2">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.12.7.3">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.12.7.4">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.12.7.5">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.12.7.6">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.12.7.7">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.12.7.8">10.05</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.12.7.9">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.12.7.10">5.85</span></span>
<span class="ltx_tr" id="S4.T1.4.4.4.4.4.4.4.13.8">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.4.4.4.4.4.4.13.8.1">VQ-Diffusion</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.13.8.2">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.13.8.3">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.13.8.4">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.13.8.5">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.13.8.6">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.13.8.7">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.13.8.8">10.32</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.13.8.9">14.10</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.13.8.10">13.86</span></span>
<span class="ltx_tr" id="S4.T1.4.4.4.4.4.4.4.14.9">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T1.4.4.4.4.4.4.4.14.9.1">U-ViT</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.14.9.2">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.14.9.3">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.14.9.4">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.14.9.5">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.14.9.6">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.14.9.7">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.14.9.8">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.14.9.9">-</span>
<span class="ltx_td ltx_align_center" id="S4.T1.4.4.4.4.4.4.4.14.9.10">5.45</span></span>
<span class="ltx_tr" id="S4.T1.4.4.4.4.4.4.4.15.10">
<span class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T1.4.4.4.4.4.4.4.15.10.1">Ours</span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.4.4.4.4.4.4.4.15.10.2"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.4.4.4.4.4.15.10.2.1">6.56</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.4.4.4.4.4.4.4.15.10.3"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.4.4.4.4.4.15.10.3.1">4.35</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.4.4.4.4.4.4.4.15.10.4"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.4.4.4.4.4.15.10.4.1">6.37</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.4.4.4.4.4.4.4.15.10.5"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.4.4.4.4.4.15.10.5.1">4.11</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.4.4.4.4.4.4.4.15.10.6"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.4.4.4.4.4.15.10.6.1">7.91</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.4.4.4.4.4.4.4.15.10.7"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.4.4.4.4.4.15.10.7.1">8.58</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.4.4.4.4.4.4.4.15.10.8"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.4.4.4.4.4.15.10.8.1">6.36</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.4.4.4.4.4.4.4.15.10.9"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.4.4.4.4.4.15.10.9.1">9.52</span></span>
<span class="ltx_td ltx_align_center ltx_border_bb" id="S4.T1.4.4.4.4.4.4.4.15.10.10"><span class="ltx_text ltx_font_bold" id="S4.T1.4.4.4.4.4.4.4.15.10.10.1">5.00</span></span></span>
</span>
</span></span></span>
</span></span></span></p>
</span></div>
</figure>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Quantitative results.</h4>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">We present results for the CUB dataset of bird images, the Oxford-102 dataset of flower images, and the MS COCO dataset of common objects, as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.T1" title="Table 1 ‣ 4.1 Comparisons with Others ‣ 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_tag">1</span></a>. On the CUB dataset, our model achieve an IS score of 6.56 and an FID score of 6.36, outperforming all the previous models. For the Oxford dataset, we achieve an IS score of 4.35 and an FID score of 6.36, outperforming all the previous models. On the COCO dataset, our model achieves an FID score of 5.00 that is competitive with previous best result.Compared with VQ-Diffusion, our model uses less training data and achieve much better performance. This comparison reveals that pre-training on large datasets can be inefficient and lead to suboptimal results.
Moreover, results in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.T1" title="Table 1 ‣ 4.1 Comparisons with Others ‣ 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_tag">1</span></a> reveal that Inception model pre-trained on ImageNet is less sensitive than fine-tuned on small datasets.
Additionally, the Inception score on the Oxford dataset exceeds that of real images (4.10). Extensive results demonstrate the effectiveness and generalization ability of the proposed data extrapolation method.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Qualitative results.</h4>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">We present qualitative results for the CUB dataset of bird images and the Oxford-102 dataset of flower images. In Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.F3" title="Figure 3 ‣ 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_tag">3</span></a>
, we compare the visualization results of DF-GAN, RAT-GAN, and our model. DF-GAN and RAT-GAN are previous state-of-the-art methods for text-to-image synthesis.
On the CUB dataset, with more clear details such as feathers, eyes, and feet, our model clearly outperforms DF-GAN and RAT-GAN. Additionally, the background in our model’s results is more coherent compared to RAT-GAN. On the Oxford dataset, our model exhibits better texture and more relevant colors than the others. With the proposed text extrapolation, RAT block, and null-guidance, our model demonstrates fewer distorted shapes and more relevant content compared to the other two models.</p>
</div>
<figure class="ltx_figure" id="S4.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" id="S4.F4.11" style="width:71.5pt;">A police man on a motorcycle is idle in front of a bush.</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" id="S4.F4.12" style="width:71.5pt;">A man riding a wave on top of a surfboard.</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" id="S4.F4.13" style="width:71.5pt;">
<p class="ltx_p" id="S4.F4.13.1">Some red and</p>
<p class="ltx_p ltx_align_center" id="S4.F4.13.2">green flower in a room.</p>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" id="S4.F4.14" style="width:71.5pt;">Assorted electronic devices sitting together in a photo.</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" id="S4.F4.15" style="width:71.5pt;">An elephant raising its truck with a tree in background.</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F4.1" style="width:71.5pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F4.1.g1" src="extracted/5896104/fig/fig_coco/ratgan/1.png" width="548"/>
<div class="ltx_inline-block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle ltx_transformed_outer" id="S4.F4.1.1" style="width:4.0pt;height:47.4pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:47.4pt;transform:translate(-20.3pt,-20.3pt) rotate(-90deg) ;">
<p class="ltx_p" id="S4.F4.1.1.1">RAT-GAN</p>
</span></div>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F4.2" style="width:71.5pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F4.2.g1" src="extracted/5896104/fig/fig_coco/ratgan/2.png" width="548"/>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F4.3" style="width:71.5pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F4.3.g1" src="extracted/5896104/fig/fig_coco/ratgan/3.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F4.4" style="width:71.5pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F4.4.g1" src="extracted/5896104/fig/fig_coco/ratgan/4.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F4.5" style="width:71.5pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F4.5.g1" src="extracted/5896104/fig/fig_coco/ratgan/5.png" width="548"/>
<div class="ltx_inline-block ltx_minipage ltx_align_center ltx_align_middle ltx_transformed_outer" id="S4.F4.5.1" style="width:4.0pt;height:21.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="width:21.2pt;transform:translate(-7.18pt,-7.18pt) rotate(-90deg) ;">
<p class="ltx_p" id="S4.F4.5.1.1">Ours</p>
</span></div>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F4.6" style="width:71.5pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F4.6.g1" src="extracted/5896104/fig/fig_coco/ours/1.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F4.7" style="width:71.5pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F4.7.g1" src="extracted/5896104/fig/fig_coco/ours/2.png" width="548"/>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F4.8" style="width:71.5pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F4.8.g1" src="extracted/5896104/fig/fig_coco/ours/3.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F4.9" style="width:71.5pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F4.9.g1" src="extracted/5896104/fig/fig_coco/ours/4.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F4.10" style="width:71.5pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F4.10.g1" src="extracted/5896104/fig/fig_coco/ours/5.png" width="548"/>
</div>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Qualitative comparison of our model with RAT-GAN on the COCO dataset. </figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px2.p2">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p2.1">The qualitative results for the COCO dataset are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.F4" title="Figure 4 ‣ Qualitative results. ‣ 4.1 Comparisons with Others ‣ 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_tag">4</span></a>. The COCO dataset includes a wide variety of common objects, which makes it particularly susceptible to the long-tail problem <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib4" title="">2022</a>)</cite>. With additional training data obtained through extrapolation, our model generates more realistic objects compared to RAT-GAN. However, the collected 770,059 images are still insufficient to cover the entire distribution of images in COCO. As a result, the outputs from COCO are not as realistic as those from the CUB and Oxford datasets.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Ablation Studies</h3>
<figure class="ltx_table" id="S4.T2">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Ablation studies on the CUB dataset. We utilize a NULL-guidance ratio of 1.5 during sampling. The FID score was employed to evaluate generation performance.</figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="S4.T2.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.1.1.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.1.1.1" rowspan="2"><span class="ltx_text" id="S4.T2.1.1.1.1.1">ID</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="4" id="S4.T2.1.1.1.2">Component</td>
<td class="ltx_td ltx_align_center ltx_border_t" colspan="6" id="S4.T2.1.1.1.3">Extrapolation Quantity(k)</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.2.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.2.1">Cluster</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.2.2">Classification</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.2.3">RAT</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.2.2.4">NULL</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.2.2.5">0</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.2.2.6">50</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.2.2.7">100</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.2.2.8">200</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.2.2.9">300</td>
<td class="ltx_td ltx_align_center" id="S4.T2.1.2.2.10">400</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.3.3">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.3.1">0</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.3.2">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.3.3">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.3.4">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.3.5">-</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.3.3.6">16.74</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.3.3.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.3.3.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.3.3.9">-</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.1.3.3.10">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.3.3.11">30.78</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.4.4">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.4.4.1">1</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.4.4.2">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.4.4.3">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.4.4.4">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.4.4.5">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.4.4.6">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.4.4.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.4.4.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.4.4.9">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.4.4.10">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.4.4.11">20.67</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.5.5">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.5.5.1">2</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.5.5.2">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.5.5.3">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.5.5.4">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.5.5.5">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.5.5.6">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.5.5.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.5.5.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.5.5.9">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.5.5.10">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.5.5.11">12.45</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.6.6">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.6.6.1">3</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.6.6.2">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.6.6.3">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.6.6.4">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.6.6.5">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.6.6.6">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.6.6.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.6.6.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.6.6.9">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.6.6.10">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.6.6.11">9.87</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.7.7">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.7.7.1">4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.7.7.2">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.7.7.3">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.7.7.4">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.7.7.5">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.7.7.6">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.7.7.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.7.7.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.7.7.9">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.7.7.10">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.7.7.11">8.76</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.8.8">
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.8.8.1">5</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.8.8.2">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.8.8.3">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.8.8.4">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.8.8.5">✓</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.8.8.6">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.8.8.7">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.8.8.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.8.8.9">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.8.8.10">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.1.8.8.11">7.65</td>
</tr>
<tr class="ltx_tr" id="S4.T2.1.9.9">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.9.9.1">6</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.9.9.2">✓</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.9.9.3">✓</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.9.9.4">✓</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.9.9.5">✓</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.9.9.6">-</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.9.9.7">9.56</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.9.9.8">7.34</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.9.9.9">6.87</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.9.9.10">6.54</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_t" id="S4.T2.1.9.9.11"><span class="ltx_text ltx_font_bold" id="S4.T2.1.9.9.11.1">6.36</span></td>
</tr>
</tbody>
</table>
</figure>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Analysis of outlier detectors.</h4>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px1.p1.1">In Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.T2" title="Table 2 ‣ 4.2 Ablation Studies ‣ 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_tag">2</span></a>, we present text-to-image results without cluster detector or classification detector. According to ID 0,1 and 2, the FID score without outlier detectors degrade severely because noisy images force the diffusion model to generate irrelevant objects. Although fine-tuning on small datasets could alleviate noise pollution but parameters also forget general knowledge at the same time. According to ID 2 and 3, classification detector performs better than cluster detector because it has utilized fine-grained classification labels.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Analysis of extrapolation quantity.</h4>
<div class="ltx_para" id="S4.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px2.p1.1">More images generally lead to improved text-to-image results. however, this trend saturates around 100,000 images, after which the improvement in FID becomes less significant with more training samples. This phenomenon aligns with that diffusion models perform much better than GANs on the COCO dataset (84K images) but exhibit similar performance to GANs on the CUB and Oxford datasets( 10K images). Furthermore, with transformers as core building blocks, GALIP performs similarly to previous models on the CUB dataset. This suggests that transformer architectures exacerbate the need for larger training datasets.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span> Training consumption on the CUB, Oxford and COCO datasets. Fine-tuning is performed on the original dataset until the FID scores increase. </figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.1.1.1.1">Dataset</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.1.2">Device</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.1.3">Original dataset</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.1.4">Extrapolated data</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T3.1.1.1.5">Fine-tuning</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.1.2.1.1">CUB</th>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.2.1.2">2 RTX 3090 Ti</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.2.1.3">5 days/1500 epochs</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.2.1.4">10 days/100 epochs</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T3.1.2.1.5">6 hours/50 epochs</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.1.3.2.1">Oxford</th>
<td class="ltx_td ltx_align_left" id="S4.T3.1.3.2.2">2 RTX 3090 Ti</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.3.2.3">5 days/1500 epochs</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.3.2.4">8 days/200 epochs</td>
<td class="ltx_td ltx_align_left" id="S4.T3.1.3.2.5">6 hours/50 epochs</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S4.T3.1.4.3.1">COCO</th>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T3.1.4.3.2">2 RTX 4090</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T3.1.4.3.3">10 days/125 epochs</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T3.1.4.3.4">20 days/95 epochs</td>
<td class="ltx_td ltx_align_left ltx_border_b" id="S4.T3.1.4.3.5">7 days/70 epochs</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_table ltx_align_floatright" id="S4.T4">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>The impact of various NULL prompts on FID scores in the CUB dataset. </figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T4.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.1.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.1.1.1.1" rowspan="2"><span class="ltx_text" id="S4.T4.1.1.1.1.1">NULL Prompts</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3" id="S4.T4.1.1.1.2">Guidance Ratio</th>
</tr>
<tr class="ltx_tr" id="S4.T4.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.1.2.2.1">1.25</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.1.2.2.2">1.5</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T4.1.2.2.3">2.0</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.1.3.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.1.3.1.1">“Null”</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.3.1.2">7.23</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.3.1.3">7.16</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.1.3.1.4">7.68</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.4.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T4.1.4.2.1">“a picture”</th>
<td class="ltx_td ltx_align_center" id="S4.T4.1.4.2.2">6.89</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.4.2.3">6.54</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.4.2.4">7.14</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.5.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T4.1.5.3.1">“no description”</th>
<td class="ltx_td ltx_align_center" id="S4.T4.1.5.3.2">6.97</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.5.3.3">6.47</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.5.3.4">7.25</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.6.4">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T4.1.6.4.1">“a picture of bird”</th>
<td class="ltx_td ltx_align_center" id="S4.T4.1.6.4.2">6.46</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.6.4.3">6.36</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.6.4.4">6.86</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.7.5">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T4.1.7.5.1">“a picture of flower”</th>
<td class="ltx_td ltx_align_center" id="S4.T4.1.7.5.2">9.04</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.7.5.3">10.6</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.7.5.4">11.4</td>
</tr>
<tr class="ltx_tr" id="S4.T4.1.8.6">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T4.1.8.6.1">“we don’t know what it is”</th>
<td class="ltx_td ltx_align_center" id="S4.T4.1.8.6.2">8.98</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.8.6.3">9.35</td>
<td class="ltx_td ltx_align_center" id="S4.T4.1.8.6.4">9.94</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Analysis of NULL guidance.</h4>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px3.p1.1">The performance of NULL guidance is influenced by both the NULL prompt and the guidance ratio. The results in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.T4" title="Table 4 ‣ Analysis of extrapolation quantity. ‣ 4.2 Ablation Studies ‣ 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_tag">4</span></a> indicate that a NULL prompt reflecting the average meaning of the dataset achieves the best performance. Additionally, a suitable guidance ratio is crucial for optimal results, and we find that a ratio around 1.5 yields the best performance on the CUB and COCO datasets. However, on the Oxford dataset, NULL guidance improves the Inception Score from 4.10 to 4.35 but degrades the FID score from 9.52 to 11.07.</p>
</div>
<figure class="ltx_table" id="S4.T5">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span> Ablation studies on the MS COCO dataset. We adopt “A picture” as the NULL prompt.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T5.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T5.3.4.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t" id="S4.T5.3.4.1.1" rowspan="2"><span class="ltx_text" id="S4.T5.3.4.1.1.1">Training data</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t" colspan="3" id="S4.T5.3.4.1.2">FID score</th>
</tr>
<tr class="ltx_tr" id="S4.T5.3.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T5.1.1.1"><math alttext="\eta=1.0" class="ltx_Math" display="inline" id="S4.T5.1.1.1.m1.1"><semantics id="S4.T5.1.1.1.m1.1a"><mrow id="S4.T5.1.1.1.m1.1.1" xref="S4.T5.1.1.1.m1.1.1.cmml"><mi id="S4.T5.1.1.1.m1.1.1.2" xref="S4.T5.1.1.1.m1.1.1.2.cmml">η</mi><mo id="S4.T5.1.1.1.m1.1.1.1" xref="S4.T5.1.1.1.m1.1.1.1.cmml">=</mo><mn id="S4.T5.1.1.1.m1.1.1.3" xref="S4.T5.1.1.1.m1.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.1.1.1.m1.1b"><apply id="S4.T5.1.1.1.m1.1.1.cmml" xref="S4.T5.1.1.1.m1.1.1"><eq id="S4.T5.1.1.1.m1.1.1.1.cmml" xref="S4.T5.1.1.1.m1.1.1.1"></eq><ci id="S4.T5.1.1.1.m1.1.1.2.cmml" xref="S4.T5.1.1.1.m1.1.1.2">𝜂</ci><cn id="S4.T5.1.1.1.m1.1.1.3.cmml" type="float" xref="S4.T5.1.1.1.m1.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.1.1.1.m1.1c">\eta=1.0</annotation><annotation encoding="application/x-llamapun" id="S4.T5.1.1.1.m1.1d">italic_η = 1.0</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T5.2.2.2"><math alttext="\eta=1.5" class="ltx_Math" display="inline" id="S4.T5.2.2.2.m1.1"><semantics id="S4.T5.2.2.2.m1.1a"><mrow id="S4.T5.2.2.2.m1.1.1" xref="S4.T5.2.2.2.m1.1.1.cmml"><mi id="S4.T5.2.2.2.m1.1.1.2" xref="S4.T5.2.2.2.m1.1.1.2.cmml">η</mi><mo id="S4.T5.2.2.2.m1.1.1.1" xref="S4.T5.2.2.2.m1.1.1.1.cmml">=</mo><mn id="S4.T5.2.2.2.m1.1.1.3" xref="S4.T5.2.2.2.m1.1.1.3.cmml">1.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.2.2.2.m1.1b"><apply id="S4.T5.2.2.2.m1.1.1.cmml" xref="S4.T5.2.2.2.m1.1.1"><eq id="S4.T5.2.2.2.m1.1.1.1.cmml" xref="S4.T5.2.2.2.m1.1.1.1"></eq><ci id="S4.T5.2.2.2.m1.1.1.2.cmml" xref="S4.T5.2.2.2.m1.1.1.2">𝜂</ci><cn id="S4.T5.2.2.2.m1.1.1.3.cmml" type="float" xref="S4.T5.2.2.2.m1.1.1.3">1.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.2.2.2.m1.1c">\eta=1.5</annotation><annotation encoding="application/x-llamapun" id="S4.T5.2.2.2.m1.1d">italic_η = 1.5</annotation></semantics></math></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T5.3.3.3"><math alttext="\eta=2.0" class="ltx_Math" display="inline" id="S4.T5.3.3.3.m1.1"><semantics id="S4.T5.3.3.3.m1.1a"><mrow id="S4.T5.3.3.3.m1.1.1" xref="S4.T5.3.3.3.m1.1.1.cmml"><mi id="S4.T5.3.3.3.m1.1.1.2" xref="S4.T5.3.3.3.m1.1.1.2.cmml">η</mi><mo id="S4.T5.3.3.3.m1.1.1.1" xref="S4.T5.3.3.3.m1.1.1.1.cmml">=</mo><mn id="S4.T5.3.3.3.m1.1.1.3" xref="S4.T5.3.3.3.m1.1.1.3.cmml">2.0</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T5.3.3.3.m1.1b"><apply id="S4.T5.3.3.3.m1.1.1.cmml" xref="S4.T5.3.3.3.m1.1.1"><eq id="S4.T5.3.3.3.m1.1.1.1.cmml" xref="S4.T5.3.3.3.m1.1.1.1"></eq><ci id="S4.T5.3.3.3.m1.1.1.2.cmml" xref="S4.T5.3.3.3.m1.1.1.2">𝜂</ci><cn id="S4.T5.3.3.3.m1.1.1.3.cmml" type="float" xref="S4.T5.3.3.3.m1.1.1.3">2.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.3.3.3.m1.1c">\eta=2.0</annotation><annotation encoding="application/x-llamapun" id="S4.T5.3.3.3.m1.1d">italic_η = 2.0</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T5.3.5.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T5.3.5.1.1">COCO</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.3.5.1.2">11.89</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.3.5.1.3">7.99</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.3.5.1.4">8.43</td>
</tr>
<tr class="ltx_tr" id="S4.T5.3.6.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r" id="S4.T5.3.6.2.1">Extrapolation</th>
<td class="ltx_td ltx_align_center" id="S4.T5.3.6.2.2">12.33</td>
<td class="ltx_td ltx_align_center" id="S4.T5.3.6.2.3">8.41</td>
<td class="ltx_td ltx_align_center" id="S4.T5.3.6.2.4">9.24</td>
</tr>
<tr class="ltx_tr" id="S4.T5.3.7.3">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r" id="S4.T5.3.7.3.1">COCO-ft</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T5.3.7.3.2">8.45</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T5.3.7.3.3">5.00</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T5.3.7.3.4">5.56</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Analysis of text injection.</h4>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS0.Px4.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px4.p1.1">Text injection is crucial for text-to-image generation. As shown in ID 4 and 5 of Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.T2" title="Table 2 ‣ 4.2 Ablation Studies ‣ 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_tag">2</span></a>, RAT significantly improves the FID score. Further experiments indicate that directly mixing text feature with time embedding results in an FID score of 25.41, which is much worse than 16.74 achieved by RAT. This suggests that time embedding provides information very different to text embedding. Additionally, incorporating a scaling operator into RAT can lead to model collapse, as information becomes highly compressed in latent space. Consequently, the mean value of the latent code becomes sensitive, and the scaling operation disrupts the information structure.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph">Ablation studies on the MS COCO dataset.</h4>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS0.Px5.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px5.p1.1">We conduct ablation studies on the MS COCO dataset, as presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.T5" title="Table 5 ‣ Analysis of NULL guidance. ‣ 4.2 Ablation Studies ‣ 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_tag">5</span></a>. The MS COCO dataset differs significantly from the CUB and Oxford datasets in terms of variety and image quantity. Experimental results demonstrate that linear extrapolation and fine-tuning (5.00) outperform the original COCO dataset (7.99). However, unlike CUB and Oxford, fine-tuning on COCO requires much more time, as shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.T3" title="Table 3 ‣ Analysis of extrapolation quantity. ‣ 4.2 Ablation Studies ‣ 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_tag">3</span></a>. Additionally, we observe that early stopping is unnecessary for fine-tuning on the COCO dataset due to its larger image volume compared to CUB and Oxford.</p>
</div>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS0.Px5.p2">
<p class="ltx_p" id="S4.SS2.SSS0.Px5.p2.1">In Table <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.T6" title="Table 6 ‣ Diversity. ‣ 4.2 Ablation Studies ‣ 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_tag">6</span></a>, we compare the pre-training dataset and model parameters with previous models on the MS COCO dataset. The compared models are all pre-trained on external datasets and fine-tuned on MS COCO dataset. Our result outperforms all previous models except for Parti but we use much less pre-training images and parameters than Parti. Moreover, our diffusion model is designed for small datasets and requires very few GPUs for training.</p>
</div>
<figure class="ltx_figure" id="S4.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F5.1" style="width:36.6pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F5.1.g1" src="extracted/5896104/fig/fig_f/variaty/1.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F5.2" style="width:36.6pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F5.2.g1" src="extracted/5896104/fig/fig_f/variaty/2.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F5.3" style="width:36.6pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F5.3.g1" src="extracted/5896104/fig/fig_f/variaty/3.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F5.4" style="width:36.6pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F5.4.g1" src="extracted/5896104/fig/fig_f/variaty/4.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F5.5" style="width:36.6pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F5.5.g1" src="extracted/5896104/fig/fig_f/variaty/5.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F5.6" style="width:36.6pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F5.6.g1" src="extracted/5896104/fig/fig_f/variaty/7.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F5.7" style="width:36.6pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F5.7.g1" src="extracted/5896104/fig/fig_f/variaty/8.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F5.8" style="width:36.6pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F5.8.g1" src="extracted/5896104/fig/fig_f/variaty/9.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F5.9" style="width:36.6pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F5.9.g1" src="extracted/5896104/fig/fig_f/variaty/10.png" width="548"/>
</div>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<div class="ltx_block ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.F5.10" style="width:36.6pt;">
<img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="548" id="S4.F5.10.g1" src="extracted/5896104/fig/fig_f/variaty/6.png" width="548"/>
</div>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p class="ltx_p ltx_figure_panel ltx_minipage ltx_align_center ltx_align_top" id="S4.F5.11" style="width:397.5pt;">This flower is purple and white, and has petals that are bulb shaped and drooping downward.</p>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Randomly generated images from the Oxford dataset. Best view in color and zoom in. </figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px6">
<h4 class="ltx_title ltx_title_paragraph">Diversity.</h4>
<div class="ltx_para ltx_noindent" id="S4.SS2.SSS0.Px6.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px6.p1.1">To qualitatively evaluate the diversity of our proposed model, we generate random images conditioned on the same text description and different random noises. In Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#S4.F5" title="Figure 5 ‣ Ablation studies on the MS COCO dataset. ‣ 4.2 Ablation Studies ‣ 4 Experiments ‣ Data Extrapolation for Text-to-image Generation on Small Datasets"><span class="ltx_text ltx_ref_tag">5</span></a>, we present 10 images generated from the same text. These images exhibit similar foreground elements while showcasing high diversity in spatial structure, demonstrating that our model effectively controls the image content.</p>
</div>
<figure class="ltx_table" id="S4.T6">
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T6.1" style="width:460.3pt;height:91.8pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-40.6pt,8.1pt) scale(0.85,0.85) ;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.T6.1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T6.1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T6.1.1.1.1.1">Model</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T6.1.1.1.1.2">FID</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T6.1.1.1.1.3">Type</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T6.1.1.1.1.4">Pre-training images</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T6.1.1.1.1.5">#Params</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T6.1.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T6.1.1.2.1.1">   Parti <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib44" title="">2022</a>)</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.1.1.2.1.2"><span class="ltx_text ltx_font_bold" id="S4.T6.1.1.2.1.2.1">3.22</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.1.1.2.1.3">Autoregressive</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.1.1.2.1.4">4.8B</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.1.1.2.1.5">20B</td>
</tr>
<tr class="ltx_tr" id="S4.T6.1.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.1.1.3.2.1">   Make-A-Scene <cite class="ltx_cite ltx_citemacro_citep">(Gafni et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib6" title="">2022</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T6.1.1.3.2.2">7.55</td>
<td class="ltx_td ltx_align_center" id="S4.T6.1.1.3.2.3">Autoregressive</td>
<td class="ltx_td ltx_align_center" id="S4.T6.1.1.3.2.4">35M</td>
<td class="ltx_td ltx_align_center" id="S4.T6.1.1.3.2.5">4B</td>
</tr>
<tr class="ltx_tr" id="S4.T6.1.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.1.1.4.3.1">   Re-Imagen <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib4" title="">2022</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T6.1.1.4.3.2">5.25</td>
<td class="ltx_td ltx_align_center" id="S4.T6.1.1.4.3.3">Diffusion</td>
<td class="ltx_td ltx_align_center" id="S4.T6.1.1.4.3.4">50M</td>
<td class="ltx_td ltx_align_center" id="S4.T6.1.1.4.3.5">2.5B</td>
</tr>
<tr class="ltx_tr" id="S4.T6.1.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row" id="S4.T6.1.1.5.4.1">   VQ-Diffusion <cite class="ltx_cite ltx_citemacro_citep">(Gu et al., <a class="ltx_ref" href="https://arxiv.org/html/2410.01638v1#bib.bib8" title="">2022</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T6.1.1.5.4.2">19.75</td>
<td class="ltx_td ltx_align_center" id="S4.T6.1.1.5.4.3">Diffusion</td>
<td class="ltx_td ltx_align_center" id="S4.T6.1.1.5.4.4">15M</td>
<td class="ltx_td ltx_align_center" id="S4.T6.1.1.5.4.5">370M</td>
</tr>
<tr class="ltx_tr" id="S4.T6.1.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b" id="S4.T6.1.1.6.5.1">   Ours</th>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T6.1.1.6.5.2">5.00</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T6.1.1.6.5.3">Diffusion</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T6.1.1.6.5.4">7M</td>
<td class="ltx_td ltx_align_center ltx_border_b" id="S4.T6.1.1.6.5.5">464M</td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Comparison of pre-training dataset and parameter quantity of different models on the MS COCO dataset. Parameters for text encoder, latent encoder and super resolution are not counted. </figcaption>
</figure>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion and Future work</h2>
<div class="ltx_para ltx_noindent" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this paper, we propose a new data augmentation method for text-to-image generation using linear extrapolation. Specifically, we apply linear extrapolation only on text data, and new image data are retrieved from the internet by search engines. For the reliability of new text-image pairs, we design two outlier detectors to purify retrieved images. Based on extrapolation, we construct training samples dozens of times larger than the original dataset, resulting in a significant improvement in text-to-image performance. Moreover, we propose a NULL-condition guidance to refine the score estimation for text-to-image generation. This guidance is also applicable to existing text-to-image models without further training. In the future, linear extrapolation and NULL-condition guidance could be applied to tasks beyond text-to-image generation.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Amodei et al. (2016)</span>
<span class="ltx_bibblock">
Dario Amodei, Sundaram Ananthanarayanan, Rishita Anubhai, Jingliang Bai, Eric Battenberg, Carl Case, Jared Casper, Bryan Catanzaro, Qiang Cheng, Guoliang Chen, et al.

</span>
<span class="ltx_bibblock">Deep speech 2: End-to-end speech recognition in english and mandarin.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">International conference on machine learning</em>, pp.  173–182. PMLR, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bao et al. (2023)</span>
<span class="ltx_bibblock">
Fan Bao, Shen Nie, Kaiwen Xue, Yue Cao, Chongxuan Li, Hang Su, and Jun Zhu.

</span>
<span class="ltx_bibblock">All are worth words: A vit backbone for diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.  22669–22679, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brack et al. (2024)</span>
<span class="ltx_bibblock">
Manuel Brack, Felix Friedrich, Katharia Kornmeier, Linoy Tsaban, Patrick Schramowski, Kristian Kersting, and Apolinário Passos.

</span>
<span class="ltx_bibblock">Ledits++: Limitless image editing using text-to-image models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.  8861–8870, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2022)</span>
<span class="ltx_bibblock">
Wenhu Chen, Hexiang Hu, Chitwan Saharia, and William W Cohen.

</span>
<span class="ltx_bibblock">Re-imagen: Retrieval-augmented text-to-image generator.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">arXiv preprint arXiv:2209.14491</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al. (2022)</span>
<span class="ltx_bibblock">
Fangxiang Feng, Tianrui Niu, Ruifan Li, and Xiaojie Wang.

</span>
<span class="ltx_bibblock">Modality disentangled discriminator for text-to-image synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">IEEE Trans. Multim.</em>, 24:2112–2124, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gafni et al. (2022)</span>
<span class="ltx_bibblock">
Oran Gafni, Adam Polyak, Oron Ashual, Shelly Sheynin, Devi Parikh, and Yaniv Taigman.

</span>
<span class="ltx_bibblock">Make-a-scene: Scene-based text-to-image generation with human priors.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">European Conference on Computer Vision</em>, pp.  89–106. Springer, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Graves et al. (2013)</span>
<span class="ltx_bibblock">
Alex Graves, Abdel-rahman Mohamed, and Geoffrey Hinton.

</span>
<span class="ltx_bibblock">Speech recognition with deep recurrent neural networks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">2013 IEEE international conference on acoustics, speech and signal processing</em>, pp.  6645–6649. Ieee, 2013.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et al. (2022)</span>
<span class="ltx_bibblock">
Shuyang Gu, Dong Chen, Jianmin Bao, Fang Wen, Bo Zhang, Dongdong Chen, Lu Yuan, and Baining Guo.

</span>
<span class="ltx_bibblock">Vector quantized diffusion model for text-to-image synthesis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.  10696–10706, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heusel et al. (2017)</span>
<span class="ltx_bibblock">
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter.

</span>
<span class="ltx_bibblock">Gans trained by a two time-scale update rule converge to a local nash equilibrium.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">NIPS</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho &amp; Salimans (2022)</span>
<span class="ltx_bibblock">
Jonathan Ho and Tim Salimans.

</span>
<span class="ltx_bibblock">Classifier-free diffusion guidance.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2207.12598</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ho et al. (2020)</span>
<span class="ltx_bibblock">
Jonathan Ho, Ajay Jain, and Pieter Abbeel.

</span>
<span class="ltx_bibblock">Denoising diffusion probabilistic models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Advances in Neural Information Processing Systems</em>, 33, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hou et al. (2022)</span>
<span class="ltx_bibblock">
Xianxu Hou, Xiaokang Zhang, Yudong Li, and Linlin Shen.

</span>
<span class="ltx_bibblock">Textface: Text-to-style mapping based face generation and manipulation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">IEEE Transactions on Multimedia</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hyvärinen (2005)</span>
<span class="ltx_bibblock">
Aapo Hyvärinen.

</span>
<span class="ltx_bibblock">Estimation of non-normalized statistical models by score matching.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Journal of Machine Learning Research</em>, 6(Apr):695–709, 2005.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Krizhevsky et al. (2012)</span>
<span class="ltx_bibblock">
Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton.

</span>
<span class="ltx_bibblock">Imagenet classification with deep convolutional neural networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Advances in neural information processing systems</em>, 25, 2012.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">LeCun et al. (2015)</span>
<span class="ltx_bibblock">
Yann LeCun, Yoshua Bengio, and Geoffrey Hinton.

</span>
<span class="ltx_bibblock">Deep learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">nature</em>, 521(7553):436–444, 2015.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2022)</span>
<span class="ltx_bibblock">
Bowen Li, Philip HS Torr, and Thomas Lukasiewicz.

</span>
<span class="ltx_bibblock">Memory-driven text-to-image generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">arXiv preprint arXiv:2208.07022</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023)</span>
<span class="ltx_bibblock">
Vivian Liu, Jo Vermeulen, George Fitzmaurice, and Justin Matejka.

</span>
<span class="ltx_bibblock">3dall-e: Integrating text-to-image ai in 3d design workflows.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Proceedings of the 2023 ACM designing interactive systems conference</em>, pp.  1955–1977, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lloyd (1982)</span>
<span class="ltx_bibblock">
Stuart Lloyd.

</span>
<span class="ltx_bibblock">Least squares quantization in pcm.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">IEEE transactions on information theory</em>, 28(2):129–137, 1982.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lukasik et al. (2020)</span>
<span class="ltx_bibblock">
Michal Lukasik, Srinadh Bhojanapalli, Aditya Menon, and Sanjiv Kumar.

</span>
<span class="ltx_bibblock">Does label smoothing mitigate label noise?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">International Conference on Machine Learning</em>, pp.  6448–6458. PMLR, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mirza &amp; Osindero (2014)</span>
<span class="ltx_bibblock">
Mehdi Mirza and Simon Osindero.

</span>
<span class="ltx_bibblock">Conditional generative adversarial nets.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">CoRR</em>, abs/1411.1784, 2014.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/1411.1784" title="">http://arxiv.org/abs/1411.1784</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Müller et al. (2019)</span>
<span class="ltx_bibblock">
Rafael Müller, Simon Kornblith, and Geoffrey E Hinton.

</span>
<span class="ltx_bibblock">When does label smoothing help?

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Advances in neural information processing systems</em>, 32, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peebles &amp; Xie (2023)</span>
<span class="ltx_bibblock">
William Peebles and Saining Xie.

</span>
<span class="ltx_bibblock">Scalable diffusion models with transformers.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Proceedings of the IEEE/CVF International Conference on Computer Vision</em>, pp.  4195–4205, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et al. (2021)</span>
<span class="ltx_bibblock">
Jun Peng, Yiyi Zhou, Xiaoshuai Sun, Liujuan Cao, Yongjian Wu, Feiyue Huang, and Rongrong Ji.

</span>
<span class="ltx_bibblock">Knowledge-driven generative adversarial network for text-to-image synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">IEEE Transactions on Multimedia</em>, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford et al. (2021)</span>
<span class="ltx_bibblock">
Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, et al.

</span>
<span class="ltx_bibblock">Learning transferable visual models from natural language supervision.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">International conference on machine learning</em>, pp.  8748–8763. PMLR, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramesh et al. (2022)</span>
<span class="ltx_bibblock">
Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen.

</span>
<span class="ltx_bibblock">Hierarchical text-conditional image generation with clip latents.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2204.06125</em>, 1(2):3, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reed et al. (2016a)</span>
<span class="ltx_bibblock">
Scott E Reed, Zeynep Akata, Santosh Mohan, Samuel Tenka, Bernt Schiele, and Honglak Lee.

</span>
<span class="ltx_bibblock">Learning what and where to draw.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">NIPS</em>, 2016a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reed et al. (2016b)</span>
<span class="ltx_bibblock">
Scott E Reed, Zeynep Akata, Xinchen Yan, Lajanugen Logeswaran, Bernt Schiele, and Honglak Lee.

</span>
<span class="ltx_bibblock">Generative adversarial text to image synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">international conference on machine learning</em>, pp.  1060–1069, 2016b.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rombach et al. (2022)</span>
<span class="ltx_bibblock">
Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Björn Ommer.

</span>
<span class="ltx_bibblock">High-resolution image synthesis with latent diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of the IEEE/CVF conference on computer vision and pattern recognition</em>, pp.  10684–10695, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ruan et al. (2021)</span>
<span class="ltx_bibblock">
Shulan Ruan, Yong Zhang, Kun Zhang, Yanbo Fan, Fan Tang, Qi Liu, and Enhong Chen.

</span>
<span class="ltx_bibblock">DAE-GAN: dynamic aspect-aware GAN for text-to-image synthesis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">2021 IEEE/CVF International Conference on Computer Vision, ICCV 2021, Montreal, QC, Canada, October 10-17, 2021</em>, pp.  13940–13949. IEEE, 2021.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/ICCV48922.2021.01370</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/ICCV48922.2021.01370" title="">https://doi.org/10.1109/ICCV48922.2021.01370</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Saharia et al. (2022)</span>
<span class="ltx_bibblock">
Chitwan Saharia, William Chan, Saurabh Saxena, Lala Li, Jay Whang, Emily Denton, Seyed Kamyar Seyed Ghasemipour, Burcu Karagol Ayan, S Sara Mahdavi, Rapha Gontijo Lopes, et al.

</span>
<span class="ltx_bibblock">Photorealistic text-to-image diffusion models with deep language understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">arXiv preprint arXiv:2205.11487</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salimans et al. (2016)</span>
<span class="ltx_bibblock">
Tim Salimans, Ian J. Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen.

</span>
<span class="ltx_bibblock">Improved techniques for training gans.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">NIPS</em>, pp.  2226–2234, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sauer et al. (2023)</span>
<span class="ltx_bibblock">
Axel Sauer, Tero Karras, Samuli Laine, Andreas Geiger, and Timo Aila.

</span>
<span class="ltx_bibblock">Stylegan-t: Unlocking the power of gans for fast large-scale text-to-image synthesis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">International conference on machine learning</em>, pp.  30105–30118. PMLR, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sheynin et al. (2022)</span>
<span class="ltx_bibblock">
Shelly Sheynin, Oron Ashual, Adam Polyak, Uriel Singer, Oran Gafni, Eliya Nachmani, and Yaniv Taigman.

</span>
<span class="ltx_bibblock">Knn-diffusion: Image generation via large-scale retrieval.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2204.02849</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song &amp; Ermon (2019)</span>
<span class="ltx_bibblock">
Yang Song and Stefano Ermon.

</span>
<span class="ltx_bibblock">Generative modeling by estimating gradients of the data distribution.

</span>
<span class="ltx_bibblock">In Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer, Florence d’Alché-Buc, Emily B. Fox, and Roman Garnett (eds.), <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">Advances in Neural Information Processing Systems</em>, pp.  11895–11907, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Song et al. (2021)</span>
<span class="ltx_bibblock">
Yang Song, Jascha Sohl-Dickstein, Diederik P. Kingma, Abhishek Kumar, Stefano Ermon, and Ben Poole.

</span>
<span class="ltx_bibblock">Score-based generative modeling through stochastic differential equations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">9th International Conference on Learning Representations, ICLR</em>. OpenReview.net, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan et al. (2022)</span>
<span class="ltx_bibblock">
Hongchen Tan, Xiuping Liu, Baocai Yin, and Xin Li.

</span>
<span class="ltx_bibblock">Cross-modal semantic matching generative adversarial networks for text-to-image synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">IEEE Trans. Multim.</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tao et al. (2022)</span>
<span class="ltx_bibblock">
Ming Tao, Hao Tang, Fei Wu, Xiaoyuan Jing, Bing-Kun Bao, and Changsheng Xu.

</span>
<span class="ltx_bibblock">DF-GAN: A simple and effective baseline for text-to-image synthesis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022, New Orleans, LA, USA, June 18-24, 2022</em>, pp.  16494–16504. IEEE, 2022.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/CVPR52688.2022.01602</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1109/CVPR52688.2022.01602" title="">https://doi.org/10.1109/CVPR52688.2022.01602</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tao et al. (2023)</span>
<span class="ltx_bibblock">
Ming Tao, Bing-Kun Bao, Hao Tang, and Changsheng Xu.

</span>
<span class="ltx_bibblock">Galip: Generative adversarial clips for text-to-image synthesis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp.  14214–14223, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vedaldi &amp; Zisserman (2016)</span>
<span class="ltx_bibblock">
Andrea Vedaldi and Andrew Zisserman.

</span>
<span class="ltx_bibblock">Vgg convolutional neural networks practical.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Department of Engineering Science, University of Oxford</em>, 66, 2016.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2018)</span>
<span class="ltx_bibblock">
Tao Xu, Pengchuan Zhang, Qiuyuan Huang, Han Zhang, Zhe Gan, Xiaolei Huang, and Xiaodong He.

</span>
<span class="ltx_bibblock">Attngan: Fine-grained text to image generation with attentional generative adversarial networks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">CVPR</em>. Computer Vision Foundation / IEEE Computer Society, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye &amp; Liu (2024)</span>
<span class="ltx_bibblock">
Senmao Ye and Fei Liu.

</span>
<span class="ltx_bibblock">Score mismatching for generative modeling.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Neural Networks</em>, 175:106311, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al. (2023)</span>
<span class="ltx_bibblock">
Senmao Ye, Huan Wang, Mingkui Tan, and Fei Liu.

</span>
<span class="ltx_bibblock">Recurrent affine transformation for text-to-image synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">IEEE Transactions on Multimedia</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin &amp; Li (2023)</span>
<span class="ltx_bibblock">
Ming-Yue Yin and Jian-Guang Li.

</span>
<span class="ltx_bibblock">A systematic review on digital human models in assembly process planning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">The International Journal of Advanced Manufacturing Technology</em>, 125(3):1037–1059, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2022)</span>
<span class="ltx_bibblock">
Jiahui Yu, Yuanzhong Xu, Jing Yu Koh, Thang Luong, Gunjan Baid, Zirui Wang, Vijay Vasudevan, Alexander Ku, Yinfei Yang, Burcu Karagol Ayan, et al.

</span>
<span class="ltx_bibblock">Scaling autoregressive models for content-rich text-to-image generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">arXiv preprint arXiv:2206.10789</em>, 2(3):5, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2019)</span>
<span class="ltx_bibblock">
Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaogang Wang, Xiaolei Huang, and Dimitris N. Metaxas.

</span>
<span class="ltx_bibblock">Stackgan++: Realistic image synthesis with stacked generative adversarial networks.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">IEEE Trans. Pattern Anal. Mach. Intell.</em>, 41(8):1947–1962, 2019.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2017)</span>
<span class="ltx_bibblock">
Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz.

</span>
<span class="ltx_bibblock">mixup: Beyond empirical risk minimization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">arXiv preprint arXiv:1710.09412</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang &amp; Schomaker (2021)</span>
<span class="ltx_bibblock">
Zhenxing Zhang and Lambert Schomaker.

</span>
<span class="ltx_bibblock">DTGAN: dual attention generative adversarial networks for text-to-image generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">IJCNN</em>, pp.  1–8. IEEE, 2021.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong et al. (2020)</span>
<span class="ltx_bibblock">
Zhun Zhong, Liang Zheng, Guoliang Kang, Shaozi Li, and Yi Yang.

</span>
<span class="ltx_bibblock">Random erasing data augmentation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">Proceedings of the AAAI conference on artificial intelligence</em>, volume 34, pp.  13001–13008, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al. (2019)</span>
<span class="ltx_bibblock">
Minfeng Zhu, Pingbo Pan, Wei Chen, and Yi Yang.

</span>
<span class="ltx_bibblock">DM-GAN: dynamic memory generative adversarial networks for text-to-image synthesis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">CVPR</em>, 2019.

</span>
</li>
</ul>
</section>
<figure class="ltx_figure" id="A0.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="452" id="A0.F6.g1" src="x3.png" width="761"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span> More generated images from the CUB dataset. The text descriptions are omitted for simplicity.</figcaption>
</figure>
<figure class="ltx_figure" id="A0.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="464" id="A0.F7.g1" src="x4.png" width="761"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span> More generated images from the Oxford dataset. The text descriptions are omitted for simplicity.</figcaption>
</figure>
<figure class="ltx_figure" id="A0.F8"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="459" id="A0.F8.g1" src="x5.png" width="761"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span> More generated images from the COCO dataset. The text descriptions are omitted for simplicity.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Oct  2 15:05:20 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
