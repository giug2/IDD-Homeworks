<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2403.18144] Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning</title><meta property="og:description" content="Federated learning is a decentralized learning paradigm introduced to preserve privacy of client data. Despite this, prior work has shown that an attacker at the server can still reconstruct the private training data u…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2403.18144">

<!--Generated on Fri Apr  5 13:39:42 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Joshua C. Zhao, Ahaan Dabholkar, Atul Sharma, Saurabh Bagchi
<br class="ltx_break">Purdue University
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">{zhao1207,adabholk,sharm438,sbagchi}@purdue.edu</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">Federated learning is a decentralized learning paradigm introduced to preserve privacy of client data. Despite this, prior work has shown that an attacker at the server can still reconstruct the private training data using only the client updates. These attacks are known as data reconstruction attacks and fall into two major categories: gradient inversion (GI) and linear layer leakage attacks (LLL). However, despite demonstrating the effectiveness of these attacks in breaching privacy, prior work has not investigated the usefulness of the reconstructed data for downstream tasks. In this work, we explore data reconstruction attacks through the lens of training and improving models with leaked data. We demonstrate the effectiveness of both GI and LLL attacks in maliciously training models using the leaked data more accurately than a benign federated learning strategy. Counter-intuitively, this bump in training quality can occur despite limited reconstruction quality or a small total number of leaked images. Finally, we show the limitations of these attacks for downstream training, individually for GI attacks and for LLL attacks.</p>
</div>
<figure id="S0.F1" class="ltx_figure"><img src="/html/2403.18144/assets/x1.png" id="S0.F1.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="207" height="220" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S0.F1.3.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S0.F1.4.2" class="ltx_text" style="font-size:90%;"> Training using leaked data.</span></figcaption>
</figure>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">With growing concerns of data privacy, federated learning (FL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">17</span></a>]</cite> has gained traction as a potential privacy-preserving method for training machine learning models. Compared to centralized learning where training is done on data localized at a central server, FL takes a decentralized approach where participating clients train a model on their local data and send their updates to the server. A typical training round involves a server sending a model to the clients, the clients training the model using their local data, and finally having the clients send their updates to the server for aggregation. However, the privacy-preserving property of FL only holds if the updates cannot be used to extract sensitive information about the local training data.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Despite only sending updates, prior works have shown the ability of attackers to gain information about the private training data through membership inference attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">22</span></a>, <a href="#bib.bib3" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">3</span></a>, <a href="#bib.bib19" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">19</span></a>]</cite>, property-inference attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">18</span></a>, <a href="#bib.bib15" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">15</span></a>]</cite>, or GAN-based methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">9</span></a>, <a href="#bib.bib23" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">23</span></a>]</cite>. Within these privacy attacks, data reconstruction has stood out as the most powerful, allowing attackers to directly recover the training data of clients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">24</span></a>, <a href="#bib.bib20" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">20</span></a>]</cite>. Within data reconstruction attacks, gradient inversion (optimization-based attacks) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">32</span></a>, <a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">26</span></a>, <a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite> and linear layer leakage <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>, <a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>, <a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">1</span></a>]</cite> attacks stand out as the most common.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">While prior works have discussed the power and the limitations of these attacks in the context of an attacker simply breaching privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">29</span></a>, <a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>]</cite>, to the best of our knowledge, none has discussed the effectiveness of using the leaked data for downstream model training. Figure <a href="#S0.F1" title="Figure 1 ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows this process of training using leaked data.
With the onset of deep learning, data has become a valuable commodity. This growth in AI also means that the value of data no longer lies just in breaching privacy of the raw data, but in the ability of the data to be used downstream for creating powerful models. Therefore, one measure of the success of a data reconstruction attack should be whether the leaked data is useful for machine learning training, an aspect omitted in prior work.
</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In order to discuss training on leaked data, we first introduce the attacks. Gradient inversion (GI) attacks typically reconstruct data through an iterative process where the distance between a gradient computed from a dummy image and the ground truth gradient is minimized by an optimizer. Label reconstruction, the process of recovering the batch labels from the client gradient, also plays a critical role in affecting the final reconstruction quality.
These labels are typically leaked prior to optimization from the gradients of the final layer of the network <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">7</span></a>, <a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">26</span></a>, <a href="#bib.bib28" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">28</span></a>, <a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite> and are matched with reconstructed images during the optimization. These attacks have shown success with individual updates of smaller batch sizes, up to 48 on ImageNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">26</span></a>]</cite> or 100 on CIFAR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite>. However, this only considers breaching privacy, as a batch size of 48 on ImageNet or 100 on CIFAR result in low quality reconstructions and/or a very small number of identifiable images. Even for a modest batch size of 8 or 16 on CIFAR-10, some batch reconstructions already fail.
Given the importance of data quality for training models, a sufficient condition for success is no longer if any images are identifiable, but rather the overall usefulness of the leaked data for the downstream training task. Here, even reconstructions with low similarity scores to the ground truth may still positively contribute to training.
</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Compared to GI, linear layer leakage (LLL) does not suffer from problems with reconstruction quality. Using modification of a fully-connected (linear, FC) layer, an attacker can directly recover a proportion of the images of a client batch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>, <a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>, <a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">1</span></a>]</cite>. Reconstructions are done by solving a simple linear equation and have little computation overhead. However, these attacks typically require modification of the model architecture and can add a large overhead in terms of model size <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">29</span></a>]</cite>. While data quality is not an issue, when using the leaked data for training models, labeling the data becomes a problem.
Unlike the optimization attacks, even if labels are known prior to reconstruction, the LLL process does not match them to the leaked images. As a result, after reconstruction there would be a set of leaked images and labels, where the images are not matched with their corresponding label.
Furthermore, because only a proportion of images in the given batch are leaked for LLL, even with a full set of labels, some labels will not have a leaked image to go with. This can lead to a tedious process of manually labeling leaked images.
</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Viewing data reconstruction attacks through the lens of training models brings up many questions. How do models trained with leaked images compare to centralized or federated learning? Does the reconstruction quality impact how well models perform when trained on leaked data? How does the lack of label matching during reconstruction affect linear layer leakage?
In this work we address these largely unanswered questions and highlight the problems that arise in this new setting. Our contributions go as follows:
</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.2" class="ltx_p">We demonstrate the effectiveness of training models using leaked data compared to federated learning and the centralized baselines. Using the data from linear layer leakage and optimization, models trained on leaked data can achieve <math id="S1.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="20.40\%" display="inline"><semantics id="S1.I1.i1.p1.1.m1.1a"><mrow id="S1.I1.i1.p1.1.m1.1.1" xref="S1.I1.i1.p1.1.m1.1.1.cmml"><mn id="S1.I1.i1.p1.1.m1.1.1.2" xref="S1.I1.i1.p1.1.m1.1.1.2.cmml">20.40</mn><mo id="S1.I1.i1.p1.1.m1.1.1.1" xref="S1.I1.i1.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i1.p1.1.m1.1b"><apply id="S1.I1.i1.p1.1.m1.1.1.cmml" xref="S1.I1.i1.p1.1.m1.1.1"><csymbol cd="latexml" id="S1.I1.i1.p1.1.m1.1.1.1.cmml" xref="S1.I1.i1.p1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S1.I1.i1.p1.1.m1.1.1.2.cmml" xref="S1.I1.i1.p1.1.m1.1.1.2">20.40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i1.p1.1.m1.1c">20.40\%</annotation></semantics></math> and <math id="S1.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="17.58\%" display="inline"><semantics id="S1.I1.i1.p1.2.m2.1a"><mrow id="S1.I1.i1.p1.2.m2.1.1" xref="S1.I1.i1.p1.2.m2.1.1.cmml"><mn id="S1.I1.i1.p1.2.m2.1.1.2" xref="S1.I1.i1.p1.2.m2.1.1.2.cmml">17.58</mn><mo id="S1.I1.i1.p1.2.m2.1.1.1" xref="S1.I1.i1.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i1.p1.2.m2.1b"><apply id="S1.I1.i1.p1.2.m2.1.1.cmml" xref="S1.I1.i1.p1.2.m2.1.1"><csymbol cd="latexml" id="S1.I1.i1.p1.2.m2.1.1.1.cmml" xref="S1.I1.i1.p1.2.m2.1.1.1">percent</csymbol><cn type="float" id="S1.I1.i1.p1.2.m2.1.1.2.cmml" xref="S1.I1.i1.p1.2.m2.1.1.2">17.58</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i1.p1.2.m2.1c">17.58\%</annotation></semantics></math> higher accuracy on CIFAR-10 compared to federated learning.
</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.5" class="ltx_p">We show that similarity metrics such as PSNR do not show if reconstructed images are useful for training, as even some of the worst images improve models. Training on CIFAR-10 with bad reconstructions generated by Inverting Gradients (batch size 16) with PSNR <math id="S1.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="&lt;14" display="inline"><semantics id="S1.I1.i2.p1.1.m1.1a"><mrow id="S1.I1.i2.p1.1.m1.1.1" xref="S1.I1.i2.p1.1.m1.1.1.cmml"><mi id="S1.I1.i2.p1.1.m1.1.1.2" xref="S1.I1.i2.p1.1.m1.1.1.2.cmml"></mi><mo id="S1.I1.i2.p1.1.m1.1.1.1" xref="S1.I1.i2.p1.1.m1.1.1.1.cmml">&lt;</mo><mn id="S1.I1.i2.p1.1.m1.1.1.3" xref="S1.I1.i2.p1.1.m1.1.1.3.cmml">14</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i2.p1.1.m1.1b"><apply id="S1.I1.i2.p1.1.m1.1.1.cmml" xref="S1.I1.i2.p1.1.m1.1.1"><lt id="S1.I1.i2.p1.1.m1.1.1.1.cmml" xref="S1.I1.i2.p1.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S1.I1.i2.p1.1.m1.1.1.2.cmml" xref="S1.I1.i2.p1.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S1.I1.i2.p1.1.m1.1.1.3.cmml" xref="S1.I1.i2.p1.1.m1.1.1.3">14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i2.p1.1.m1.1c">&lt;14</annotation></semantics></math> results in a <math id="S1.I1.i2.p1.2.m2.1" class="ltx_Math" alttext="58.29\%" display="inline"><semantics id="S1.I1.i2.p1.2.m2.1a"><mrow id="S1.I1.i2.p1.2.m2.1.1" xref="S1.I1.i2.p1.2.m2.1.1.cmml"><mn id="S1.I1.i2.p1.2.m2.1.1.2" xref="S1.I1.i2.p1.2.m2.1.1.2.cmml">58.29</mn><mo id="S1.I1.i2.p1.2.m2.1.1.1" xref="S1.I1.i2.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i2.p1.2.m2.1b"><apply id="S1.I1.i2.p1.2.m2.1.1.cmml" xref="S1.I1.i2.p1.2.m2.1.1"><csymbol cd="latexml" id="S1.I1.i2.p1.2.m2.1.1.1.cmml" xref="S1.I1.i2.p1.2.m2.1.1.1">percent</csymbol><cn type="float" id="S1.I1.i2.p1.2.m2.1.1.2.cmml" xref="S1.I1.i2.p1.2.m2.1.1.2">58.29</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i2.p1.2.m2.1c">58.29\%</annotation></semantics></math> test accuracy. Removing these images and training only on images <math id="S1.I1.i2.p1.3.m3.1" class="ltx_Math" alttext="&gt;14" display="inline"><semantics id="S1.I1.i2.p1.3.m3.1a"><mrow id="S1.I1.i2.p1.3.m3.1.1" xref="S1.I1.i2.p1.3.m3.1.1.cmml"><mi id="S1.I1.i2.p1.3.m3.1.1.2" xref="S1.I1.i2.p1.3.m3.1.1.2.cmml"></mi><mo id="S1.I1.i2.p1.3.m3.1.1.1" xref="S1.I1.i2.p1.3.m3.1.1.1.cmml">&gt;</mo><mn id="S1.I1.i2.p1.3.m3.1.1.3" xref="S1.I1.i2.p1.3.m3.1.1.3.cmml">14</mn></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i2.p1.3.m3.1b"><apply id="S1.I1.i2.p1.3.m3.1.1.cmml" xref="S1.I1.i2.p1.3.m3.1.1"><gt id="S1.I1.i2.p1.3.m3.1.1.1.cmml" xref="S1.I1.i2.p1.3.m3.1.1.1"></gt><csymbol cd="latexml" id="S1.I1.i2.p1.3.m3.1.1.2.cmml" xref="S1.I1.i2.p1.3.m3.1.1.2">absent</csymbol><cn type="integer" id="S1.I1.i2.p1.3.m3.1.1.3.cmml" xref="S1.I1.i2.p1.3.m3.1.1.3">14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i2.p1.3.m3.1c">&gt;14</annotation></semantics></math> PSNR results in only a minor accuracy decrease from <math id="S1.I1.i2.p1.4.m4.1" class="ltx_Math" alttext="76.83\%" display="inline"><semantics id="S1.I1.i2.p1.4.m4.1a"><mrow id="S1.I1.i2.p1.4.m4.1.1" xref="S1.I1.i2.p1.4.m4.1.1.cmml"><mn id="S1.I1.i2.p1.4.m4.1.1.2" xref="S1.I1.i2.p1.4.m4.1.1.2.cmml">76.83</mn><mo id="S1.I1.i2.p1.4.m4.1.1.1" xref="S1.I1.i2.p1.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i2.p1.4.m4.1b"><apply id="S1.I1.i2.p1.4.m4.1.1.cmml" xref="S1.I1.i2.p1.4.m4.1.1"><csymbol cd="latexml" id="S1.I1.i2.p1.4.m4.1.1.1.cmml" xref="S1.I1.i2.p1.4.m4.1.1.1">percent</csymbol><cn type="float" id="S1.I1.i2.p1.4.m4.1.1.2.cmml" xref="S1.I1.i2.p1.4.m4.1.1.2">76.83</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i2.p1.4.m4.1c">76.83\%</annotation></semantics></math> to <math id="S1.I1.i2.p1.5.m5.1" class="ltx_Math" alttext="75.48\%" display="inline"><semantics id="S1.I1.i2.p1.5.m5.1a"><mrow id="S1.I1.i2.p1.5.m5.1.1" xref="S1.I1.i2.p1.5.m5.1.1.cmml"><mn id="S1.I1.i2.p1.5.m5.1.1.2" xref="S1.I1.i2.p1.5.m5.1.1.2.cmml">75.48</mn><mo id="S1.I1.i2.p1.5.m5.1.1.1" xref="S1.I1.i2.p1.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i2.p1.5.m5.1b"><apply id="S1.I1.i2.p1.5.m5.1.1.cmml" xref="S1.I1.i2.p1.5.m5.1.1"><csymbol cd="latexml" id="S1.I1.i2.p1.5.m5.1.1.1.cmml" xref="S1.I1.i2.p1.5.m5.1.1.1">percent</csymbol><cn type="float" id="S1.I1.i2.p1.5.m5.1.1.2.cmml" xref="S1.I1.i2.p1.5.m5.1.1.2">75.48</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i2.p1.5.m5.1c">75.48\%</annotation></semantics></math>.
</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.2" class="ltx_p">We quantify the effects and highlight the crucial limitations of current data reconstruction attacks when viewed through the lens of downstream model training. While gradient inversion can breach privacy for a batch size of 100 on CIFAR-10, this is impractical for training as even increasing the batch size from 4 to 16 results in a performance drop from <math id="S1.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="90.34\%" display="inline"><semantics id="S1.I1.i3.p1.1.m1.1a"><mrow id="S1.I1.i3.p1.1.m1.1.1" xref="S1.I1.i3.p1.1.m1.1.1.cmml"><mn id="S1.I1.i3.p1.1.m1.1.1.2" xref="S1.I1.i3.p1.1.m1.1.1.2.cmml">90.34</mn><mo id="S1.I1.i3.p1.1.m1.1.1.1" xref="S1.I1.i3.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i3.p1.1.m1.1b"><apply id="S1.I1.i3.p1.1.m1.1.1.cmml" xref="S1.I1.i3.p1.1.m1.1.1"><csymbol cd="latexml" id="S1.I1.i3.p1.1.m1.1.1.1.cmml" xref="S1.I1.i3.p1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S1.I1.i3.p1.1.m1.1.1.2.cmml" xref="S1.I1.i3.p1.1.m1.1.1.2">90.34</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i3.p1.1.m1.1c">90.34\%</annotation></semantics></math> to <math id="S1.I1.i3.p1.2.m2.1" class="ltx_Math" alttext="76.83\%" display="inline"><semantics id="S1.I1.i3.p1.2.m2.1a"><mrow id="S1.I1.i3.p1.2.m2.1.1" xref="S1.I1.i3.p1.2.m2.1.1.cmml"><mn id="S1.I1.i3.p1.2.m2.1.1.2" xref="S1.I1.i3.p1.2.m2.1.1.2.cmml">76.83</mn><mo id="S1.I1.i3.p1.2.m2.1.1.1" xref="S1.I1.i3.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.I1.i3.p1.2.m2.1b"><apply id="S1.I1.i3.p1.2.m2.1.1.cmml" xref="S1.I1.i3.p1.2.m2.1.1"><csymbol cd="latexml" id="S1.I1.i3.p1.2.m2.1.1.1.cmml" xref="S1.I1.i3.p1.2.m2.1.1.1">percent</csymbol><cn type="float" id="S1.I1.i3.p1.2.m2.1.1.2.cmml" xref="S1.I1.i3.p1.2.m2.1.1.2">76.83</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.I1.i3.p1.2.m2.1c">76.83\%</annotation></semantics></math>.
</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.5" class="ltx_p">Gradient inversion (GI) attacks operate under an honest-but-curious threat model where a server only knows the update and model. The method involves feeding a dummy image into a model and computing the subsequent gradient. The dummy image starts out initialized as random noise, and an optimizer iteratively minimizes the distance between the computed gradient and the ground truth client gradient.</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.4" class="ltx_Math" alttext="x^{*}=\arg\min_{x}||\nabla L(x,y,\theta)-\nabla W||_{2}\vspace*{-2mm}" display="block"><semantics id="S2.E1.m1.4a"><mrow id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml"><msup id="S2.E1.m1.4.4.3" xref="S2.E1.m1.4.4.3.cmml"><mi id="S2.E1.m1.4.4.3.2" xref="S2.E1.m1.4.4.3.2.cmml">x</mi><mo id="S2.E1.m1.4.4.3.3" xref="S2.E1.m1.4.4.3.3.cmml">∗</mo></msup><mo id="S2.E1.m1.4.4.2" xref="S2.E1.m1.4.4.2.cmml">=</mo><mrow id="S2.E1.m1.4.4.1" xref="S2.E1.m1.4.4.1.cmml"><mrow id="S2.E1.m1.4.4.1.3" xref="S2.E1.m1.4.4.1.3.cmml"><mi id="S2.E1.m1.4.4.1.3.1" xref="S2.E1.m1.4.4.1.3.1.cmml">arg</mi><mo lspace="0.167em" id="S2.E1.m1.4.4.1.3a" xref="S2.E1.m1.4.4.1.3.cmml">⁡</mo><munder id="S2.E1.m1.4.4.1.3.2" xref="S2.E1.m1.4.4.1.3.2.cmml"><mi id="S2.E1.m1.4.4.1.3.2.2" xref="S2.E1.m1.4.4.1.3.2.2.cmml">min</mi><mi id="S2.E1.m1.4.4.1.3.2.3" xref="S2.E1.m1.4.4.1.3.2.3.cmml">x</mi></munder></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.4.4.1.2" xref="S2.E1.m1.4.4.1.2.cmml">​</mo><msub id="S2.E1.m1.4.4.1.1" xref="S2.E1.m1.4.4.1.1.cmml"><mrow id="S2.E1.m1.4.4.1.1.1.1" xref="S2.E1.m1.4.4.1.1.1.2.cmml"><mo stretchy="false" id="S2.E1.m1.4.4.1.1.1.1.2" xref="S2.E1.m1.4.4.1.1.1.2.1.cmml">‖</mo><mrow id="S2.E1.m1.4.4.1.1.1.1.1" xref="S2.E1.m1.4.4.1.1.1.1.1.cmml"><mrow id="S2.E1.m1.4.4.1.1.1.1.1.2" xref="S2.E1.m1.4.4.1.1.1.1.1.2.cmml"><mrow id="S2.E1.m1.4.4.1.1.1.1.1.2.2" xref="S2.E1.m1.4.4.1.1.1.1.1.2.2.cmml"><mo rspace="0.167em" id="S2.E1.m1.4.4.1.1.1.1.1.2.2.1" xref="S2.E1.m1.4.4.1.1.1.1.1.2.2.1.cmml">∇</mo><mi id="S2.E1.m1.4.4.1.1.1.1.1.2.2.2" xref="S2.E1.m1.4.4.1.1.1.1.1.2.2.2.cmml">L</mi></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.4.4.1.1.1.1.1.2.1" xref="S2.E1.m1.4.4.1.1.1.1.1.2.1.cmml">​</mo><mrow id="S2.E1.m1.4.4.1.1.1.1.1.2.3.2" xref="S2.E1.m1.4.4.1.1.1.1.1.2.3.1.cmml"><mo stretchy="false" id="S2.E1.m1.4.4.1.1.1.1.1.2.3.2.1" xref="S2.E1.m1.4.4.1.1.1.1.1.2.3.1.cmml">(</mo><mi id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">x</mi><mo id="S2.E1.m1.4.4.1.1.1.1.1.2.3.2.2" xref="S2.E1.m1.4.4.1.1.1.1.1.2.3.1.cmml">,</mo><mi id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml">y</mi><mo id="S2.E1.m1.4.4.1.1.1.1.1.2.3.2.3" xref="S2.E1.m1.4.4.1.1.1.1.1.2.3.1.cmml">,</mo><mi id="S2.E1.m1.3.3" xref="S2.E1.m1.3.3.cmml">θ</mi><mo stretchy="false" id="S2.E1.m1.4.4.1.1.1.1.1.2.3.2.4" xref="S2.E1.m1.4.4.1.1.1.1.1.2.3.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.4.4.1.1.1.1.1.1" xref="S2.E1.m1.4.4.1.1.1.1.1.1.cmml">−</mo><mrow id="S2.E1.m1.4.4.1.1.1.1.1.3" xref="S2.E1.m1.4.4.1.1.1.1.1.3.cmml"><mo rspace="0.167em" id="S2.E1.m1.4.4.1.1.1.1.1.3.1" xref="S2.E1.m1.4.4.1.1.1.1.1.3.1.cmml">∇</mo><mi id="S2.E1.m1.4.4.1.1.1.1.1.3.2" xref="S2.E1.m1.4.4.1.1.1.1.1.3.2.cmml">W</mi></mrow></mrow><mo stretchy="false" id="S2.E1.m1.4.4.1.1.1.1.3" xref="S2.E1.m1.4.4.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S2.E1.m1.4.4.1.1.3" xref="S2.E1.m1.4.4.1.1.3.cmml">2</mn></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.4b"><apply id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4"><eq id="S2.E1.m1.4.4.2.cmml" xref="S2.E1.m1.4.4.2"></eq><apply id="S2.E1.m1.4.4.3.cmml" xref="S2.E1.m1.4.4.3"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.3.1.cmml" xref="S2.E1.m1.4.4.3">superscript</csymbol><ci id="S2.E1.m1.4.4.3.2.cmml" xref="S2.E1.m1.4.4.3.2">𝑥</ci><times id="S2.E1.m1.4.4.3.3.cmml" xref="S2.E1.m1.4.4.3.3"></times></apply><apply id="S2.E1.m1.4.4.1.cmml" xref="S2.E1.m1.4.4.1"><times id="S2.E1.m1.4.4.1.2.cmml" xref="S2.E1.m1.4.4.1.2"></times><apply id="S2.E1.m1.4.4.1.3.cmml" xref="S2.E1.m1.4.4.1.3"><arg id="S2.E1.m1.4.4.1.3.1.cmml" xref="S2.E1.m1.4.4.1.3.1"></arg><apply id="S2.E1.m1.4.4.1.3.2.cmml" xref="S2.E1.m1.4.4.1.3.2"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.1.3.2.1.cmml" xref="S2.E1.m1.4.4.1.3.2">subscript</csymbol><min id="S2.E1.m1.4.4.1.3.2.2.cmml" xref="S2.E1.m1.4.4.1.3.2.2"></min><ci id="S2.E1.m1.4.4.1.3.2.3.cmml" xref="S2.E1.m1.4.4.1.3.2.3">𝑥</ci></apply></apply><apply id="S2.E1.m1.4.4.1.1.cmml" xref="S2.E1.m1.4.4.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.1.1.2.cmml" xref="S2.E1.m1.4.4.1.1">subscript</csymbol><apply id="S2.E1.m1.4.4.1.1.1.2.cmml" xref="S2.E1.m1.4.4.1.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.4.4.1.1.1.2.1.cmml" xref="S2.E1.m1.4.4.1.1.1.1.2">norm</csymbol><apply id="S2.E1.m1.4.4.1.1.1.1.1.cmml" xref="S2.E1.m1.4.4.1.1.1.1.1"><minus id="S2.E1.m1.4.4.1.1.1.1.1.1.cmml" xref="S2.E1.m1.4.4.1.1.1.1.1.1"></minus><apply id="S2.E1.m1.4.4.1.1.1.1.1.2.cmml" xref="S2.E1.m1.4.4.1.1.1.1.1.2"><times id="S2.E1.m1.4.4.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.4.4.1.1.1.1.1.2.1"></times><apply id="S2.E1.m1.4.4.1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.4.4.1.1.1.1.1.2.2"><ci id="S2.E1.m1.4.4.1.1.1.1.1.2.2.1.cmml" xref="S2.E1.m1.4.4.1.1.1.1.1.2.2.1">∇</ci><ci id="S2.E1.m1.4.4.1.1.1.1.1.2.2.2.cmml" xref="S2.E1.m1.4.4.1.1.1.1.1.2.2.2">𝐿</ci></apply><vector id="S2.E1.m1.4.4.1.1.1.1.1.2.3.1.cmml" xref="S2.E1.m1.4.4.1.1.1.1.1.2.3.2"><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">𝑥</ci><ci id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2">𝑦</ci><ci id="S2.E1.m1.3.3.cmml" xref="S2.E1.m1.3.3">𝜃</ci></vector></apply><apply id="S2.E1.m1.4.4.1.1.1.1.1.3.cmml" xref="S2.E1.m1.4.4.1.1.1.1.1.3"><ci id="S2.E1.m1.4.4.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.4.4.1.1.1.1.1.3.1">∇</ci><ci id="S2.E1.m1.4.4.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.4.4.1.1.1.1.1.3.2">𝑊</ci></apply></apply></apply><cn type="integer" id="S2.E1.m1.4.4.1.1.3.cmml" xref="S2.E1.m1.4.4.1.1.3">2</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.4c">x^{*}=\arg\min_{x}||\nabla L(x,y,\theta)-\nabla W||_{2}\vspace*{-2mm}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.p1.4" class="ltx_p">The intuition behind these attacks is that a similar computed dummy gradient <math id="S2.p1.1.m1.3" class="ltx_Math" alttext="\nabla L(x,y,\theta)" display="inline"><semantics id="S2.p1.1.m1.3a"><mrow id="S2.p1.1.m1.3.4" xref="S2.p1.1.m1.3.4.cmml"><mrow id="S2.p1.1.m1.3.4.2" xref="S2.p1.1.m1.3.4.2.cmml"><mo rspace="0.167em" id="S2.p1.1.m1.3.4.2.1" xref="S2.p1.1.m1.3.4.2.1.cmml">∇</mo><mi id="S2.p1.1.m1.3.4.2.2" xref="S2.p1.1.m1.3.4.2.2.cmml">L</mi></mrow><mo lspace="0em" rspace="0em" id="S2.p1.1.m1.3.4.1" xref="S2.p1.1.m1.3.4.1.cmml">​</mo><mrow id="S2.p1.1.m1.3.4.3.2" xref="S2.p1.1.m1.3.4.3.1.cmml"><mo stretchy="false" id="S2.p1.1.m1.3.4.3.2.1" xref="S2.p1.1.m1.3.4.3.1.cmml">(</mo><mi id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">x</mi><mo id="S2.p1.1.m1.3.4.3.2.2" xref="S2.p1.1.m1.3.4.3.1.cmml">,</mo><mi id="S2.p1.1.m1.2.2" xref="S2.p1.1.m1.2.2.cmml">y</mi><mo id="S2.p1.1.m1.3.4.3.2.3" xref="S2.p1.1.m1.3.4.3.1.cmml">,</mo><mi id="S2.p1.1.m1.3.3" xref="S2.p1.1.m1.3.3.cmml">θ</mi><mo stretchy="false" id="S2.p1.1.m1.3.4.3.2.4" xref="S2.p1.1.m1.3.4.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.3b"><apply id="S2.p1.1.m1.3.4.cmml" xref="S2.p1.1.m1.3.4"><times id="S2.p1.1.m1.3.4.1.cmml" xref="S2.p1.1.m1.3.4.1"></times><apply id="S2.p1.1.m1.3.4.2.cmml" xref="S2.p1.1.m1.3.4.2"><ci id="S2.p1.1.m1.3.4.2.1.cmml" xref="S2.p1.1.m1.3.4.2.1">∇</ci><ci id="S2.p1.1.m1.3.4.2.2.cmml" xref="S2.p1.1.m1.3.4.2.2">𝐿</ci></apply><vector id="S2.p1.1.m1.3.4.3.1.cmml" xref="S2.p1.1.m1.3.4.3.2"><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">𝑥</ci><ci id="S2.p1.1.m1.2.2.cmml" xref="S2.p1.1.m1.2.2">𝑦</ci><ci id="S2.p1.1.m1.3.3.cmml" xref="S2.p1.1.m1.3.3">𝜃</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.3c">\nabla L(x,y,\theta)</annotation></semantics></math> and ground truth gradient <math id="S2.p1.2.m2.1" class="ltx_Math" alttext="\nabla W" display="inline"><semantics id="S2.p1.2.m2.1a"><mrow id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml"><mo rspace="0.167em" id="S2.p1.2.m2.1.1.1" xref="S2.p1.2.m2.1.1.1.cmml">∇</mo><mi id="S2.p1.2.m2.1.1.2" xref="S2.p1.2.m2.1.1.2.cmml">W</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><apply id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1"><ci id="S2.p1.2.m2.1.1.1.cmml" xref="S2.p1.2.m2.1.1.1">∇</ci><ci id="S2.p1.2.m2.1.1.2.cmml" xref="S2.p1.2.m2.1.1.2">𝑊</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">\nabla W</annotation></semantics></math> will result from similar images. Thus, as the gradients become closer, the final reconstructed image <math id="S2.p1.3.m3.1" class="ltx_Math" alttext="x^{*}" display="inline"><semantics id="S2.p1.3.m3.1a"><msup id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml"><mi id="S2.p1.3.m3.1.1.2" xref="S2.p1.3.m3.1.1.2.cmml">x</mi><mo id="S2.p1.3.m3.1.1.3" xref="S2.p1.3.m3.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><apply id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.p1.3.m3.1.1.1.cmml" xref="S2.p1.3.m3.1.1">superscript</csymbol><ci id="S2.p1.3.m3.1.1.2.cmml" xref="S2.p1.3.m3.1.1.2">𝑥</ci><times id="S2.p1.3.m3.1.1.3.cmml" xref="S2.p1.3.m3.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">x^{*}</annotation></semantics></math> should become close to the ground truth training image. The label <math id="S2.p1.4.m4.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S2.p1.4.m4.1a"><mi id="S2.p1.4.m4.1.1" xref="S2.p1.4.m4.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.1b"><ci id="S2.p1.4.m4.1.1.cmml" xref="S2.p1.4.m4.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m4.1c">y</annotation></semantics></math> is assumed to be known prior to optimization. For a batch reconstruction with multiple labels, the labels are matched with the reconstructed images during optimization (as the loss and gradient are computed with these image-label pairs).
Regularizers have also been introduced to assist the optimization process <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>, <a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">26</span></a>]</cite>. However, these can result in reconstructed image artifacts.</p>
</div>
<div id="S2.p2" class="ltx_para ltx_noindent">
<p id="S2.p2.6" class="ltx_p">Linear layer leakage (LLL) attacks are built on the observation that a fully-connected (FC) layer leaks the input to the layer through the gradients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">21</span></a>, <a href="#bib.bib4" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">4</span></a>]</cite>.</p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.1" class="ltx_Math" alttext="x^{i}=\frac{\delta L}{\delta W^{i}}/\frac{\delta L}{\delta B^{i}}\vspace*{-2mm}" display="block"><semantics id="S2.E2.m1.1a"><mrow id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1.cmml"><msup id="S2.E2.m1.1.1.2" xref="S2.E2.m1.1.1.2.cmml"><mi id="S2.E2.m1.1.1.2.2" xref="S2.E2.m1.1.1.2.2.cmml">x</mi><mi id="S2.E2.m1.1.1.2.3" xref="S2.E2.m1.1.1.2.3.cmml">i</mi></msup><mo id="S2.E2.m1.1.1.1" xref="S2.E2.m1.1.1.1.cmml">=</mo><mrow id="S2.E2.m1.1.1.3" xref="S2.E2.m1.1.1.3.cmml"><mfrac id="S2.E2.m1.1.1.3.2" xref="S2.E2.m1.1.1.3.2.cmml"><mrow id="S2.E2.m1.1.1.3.2.2" xref="S2.E2.m1.1.1.3.2.2.cmml"><mi id="S2.E2.m1.1.1.3.2.2.2" xref="S2.E2.m1.1.1.3.2.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.3.2.2.1" xref="S2.E2.m1.1.1.3.2.2.1.cmml">​</mo><mi id="S2.E2.m1.1.1.3.2.2.3" xref="S2.E2.m1.1.1.3.2.2.3.cmml">L</mi></mrow><mrow id="S2.E2.m1.1.1.3.2.3" xref="S2.E2.m1.1.1.3.2.3.cmml"><mi id="S2.E2.m1.1.1.3.2.3.2" xref="S2.E2.m1.1.1.3.2.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.3.2.3.1" xref="S2.E2.m1.1.1.3.2.3.1.cmml">​</mo><msup id="S2.E2.m1.1.1.3.2.3.3" xref="S2.E2.m1.1.1.3.2.3.3.cmml"><mi id="S2.E2.m1.1.1.3.2.3.3.2" xref="S2.E2.m1.1.1.3.2.3.3.2.cmml">W</mi><mi id="S2.E2.m1.1.1.3.2.3.3.3" xref="S2.E2.m1.1.1.3.2.3.3.3.cmml">i</mi></msup></mrow></mfrac><mo id="S2.E2.m1.1.1.3.1" xref="S2.E2.m1.1.1.3.1.cmml">/</mo><mfrac id="S2.E2.m1.1.1.3.3" xref="S2.E2.m1.1.1.3.3.cmml"><mrow id="S2.E2.m1.1.1.3.3.2" xref="S2.E2.m1.1.1.3.3.2.cmml"><mi id="S2.E2.m1.1.1.3.3.2.2" xref="S2.E2.m1.1.1.3.3.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.3.3.2.1" xref="S2.E2.m1.1.1.3.3.2.1.cmml">​</mo><mi id="S2.E2.m1.1.1.3.3.2.3" xref="S2.E2.m1.1.1.3.3.2.3.cmml">L</mi></mrow><mrow id="S2.E2.m1.1.1.3.3.3" xref="S2.E2.m1.1.1.3.3.3.cmml"><mi id="S2.E2.m1.1.1.3.3.3.2" xref="S2.E2.m1.1.1.3.3.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.3.3.3.1" xref="S2.E2.m1.1.1.3.3.3.1.cmml">​</mo><msup id="S2.E2.m1.1.1.3.3.3.3" xref="S2.E2.m1.1.1.3.3.3.3.cmml"><mi id="S2.E2.m1.1.1.3.3.3.3.2" xref="S2.E2.m1.1.1.3.3.3.3.2.cmml">B</mi><mi id="S2.E2.m1.1.1.3.3.3.3.3" xref="S2.E2.m1.1.1.3.3.3.3.3.cmml">i</mi></msup></mrow></mfrac></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.1b"><apply id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1"><eq id="S2.E2.m1.1.1.1.cmml" xref="S2.E2.m1.1.1.1"></eq><apply id="S2.E2.m1.1.1.2.cmml" xref="S2.E2.m1.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.2.1.cmml" xref="S2.E2.m1.1.1.2">superscript</csymbol><ci id="S2.E2.m1.1.1.2.2.cmml" xref="S2.E2.m1.1.1.2.2">𝑥</ci><ci id="S2.E2.m1.1.1.2.3.cmml" xref="S2.E2.m1.1.1.2.3">𝑖</ci></apply><apply id="S2.E2.m1.1.1.3.cmml" xref="S2.E2.m1.1.1.3"><divide id="S2.E2.m1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.3.1"></divide><apply id="S2.E2.m1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.3.2"><divide id="S2.E2.m1.1.1.3.2.1.cmml" xref="S2.E2.m1.1.1.3.2"></divide><apply id="S2.E2.m1.1.1.3.2.2.cmml" xref="S2.E2.m1.1.1.3.2.2"><times id="S2.E2.m1.1.1.3.2.2.1.cmml" xref="S2.E2.m1.1.1.3.2.2.1"></times><ci id="S2.E2.m1.1.1.3.2.2.2.cmml" xref="S2.E2.m1.1.1.3.2.2.2">𝛿</ci><ci id="S2.E2.m1.1.1.3.2.2.3.cmml" xref="S2.E2.m1.1.1.3.2.2.3">𝐿</ci></apply><apply id="S2.E2.m1.1.1.3.2.3.cmml" xref="S2.E2.m1.1.1.3.2.3"><times id="S2.E2.m1.1.1.3.2.3.1.cmml" xref="S2.E2.m1.1.1.3.2.3.1"></times><ci id="S2.E2.m1.1.1.3.2.3.2.cmml" xref="S2.E2.m1.1.1.3.2.3.2">𝛿</ci><apply id="S2.E2.m1.1.1.3.2.3.3.cmml" xref="S2.E2.m1.1.1.3.2.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.3.2.3.3.1.cmml" xref="S2.E2.m1.1.1.3.2.3.3">superscript</csymbol><ci id="S2.E2.m1.1.1.3.2.3.3.2.cmml" xref="S2.E2.m1.1.1.3.2.3.3.2">𝑊</ci><ci id="S2.E2.m1.1.1.3.2.3.3.3.cmml" xref="S2.E2.m1.1.1.3.2.3.3.3">𝑖</ci></apply></apply></apply><apply id="S2.E2.m1.1.1.3.3.cmml" xref="S2.E2.m1.1.1.3.3"><divide id="S2.E2.m1.1.1.3.3.1.cmml" xref="S2.E2.m1.1.1.3.3"></divide><apply id="S2.E2.m1.1.1.3.3.2.cmml" xref="S2.E2.m1.1.1.3.3.2"><times id="S2.E2.m1.1.1.3.3.2.1.cmml" xref="S2.E2.m1.1.1.3.3.2.1"></times><ci id="S2.E2.m1.1.1.3.3.2.2.cmml" xref="S2.E2.m1.1.1.3.3.2.2">𝛿</ci><ci id="S2.E2.m1.1.1.3.3.2.3.cmml" xref="S2.E2.m1.1.1.3.3.2.3">𝐿</ci></apply><apply id="S2.E2.m1.1.1.3.3.3.cmml" xref="S2.E2.m1.1.1.3.3.3"><times id="S2.E2.m1.1.1.3.3.3.1.cmml" xref="S2.E2.m1.1.1.3.3.3.1"></times><ci id="S2.E2.m1.1.1.3.3.3.2.cmml" xref="S2.E2.m1.1.1.3.3.3.2">𝛿</ci><apply id="S2.E2.m1.1.1.3.3.3.3.cmml" xref="S2.E2.m1.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.3.3.3.3.1.cmml" xref="S2.E2.m1.1.1.3.3.3.3">superscript</csymbol><ci id="S2.E2.m1.1.1.3.3.3.3.2.cmml" xref="S2.E2.m1.1.1.3.3.3.3.2">𝐵</ci><ci id="S2.E2.m1.1.1.3.3.3.3.3.cmml" xref="S2.E2.m1.1.1.3.3.3.3.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.1c">x^{i}=\frac{\delta L}{\delta W^{i}}/\frac{\delta L}{\delta B^{i}}\vspace*{-2mm}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S2.p2.5" class="ltx_p">Here, <math id="S2.p2.1.m1.1" class="ltx_Math" alttext="\frac{\delta L}{\delta W^{i}}" display="inline"><semantics id="S2.p2.1.m1.1a"><mfrac id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml"><mrow id="S2.p2.1.m1.1.1.2" xref="S2.p2.1.m1.1.1.2.cmml"><mi id="S2.p2.1.m1.1.1.2.2" xref="S2.p2.1.m1.1.1.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S2.p2.1.m1.1.1.2.1" xref="S2.p2.1.m1.1.1.2.1.cmml">​</mo><mi id="S2.p2.1.m1.1.1.2.3" xref="S2.p2.1.m1.1.1.2.3.cmml">L</mi></mrow><mrow id="S2.p2.1.m1.1.1.3" xref="S2.p2.1.m1.1.1.3.cmml"><mi id="S2.p2.1.m1.1.1.3.2" xref="S2.p2.1.m1.1.1.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S2.p2.1.m1.1.1.3.1" xref="S2.p2.1.m1.1.1.3.1.cmml">​</mo><msup id="S2.p2.1.m1.1.1.3.3" xref="S2.p2.1.m1.1.1.3.3.cmml"><mi id="S2.p2.1.m1.1.1.3.3.2" xref="S2.p2.1.m1.1.1.3.3.2.cmml">W</mi><mi id="S2.p2.1.m1.1.1.3.3.3" xref="S2.p2.1.m1.1.1.3.3.3.cmml">i</mi></msup></mrow></mfrac><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><apply id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1"><divide id="S2.p2.1.m1.1.1.1.cmml" xref="S2.p2.1.m1.1.1"></divide><apply id="S2.p2.1.m1.1.1.2.cmml" xref="S2.p2.1.m1.1.1.2"><times id="S2.p2.1.m1.1.1.2.1.cmml" xref="S2.p2.1.m1.1.1.2.1"></times><ci id="S2.p2.1.m1.1.1.2.2.cmml" xref="S2.p2.1.m1.1.1.2.2">𝛿</ci><ci id="S2.p2.1.m1.1.1.2.3.cmml" xref="S2.p2.1.m1.1.1.2.3">𝐿</ci></apply><apply id="S2.p2.1.m1.1.1.3.cmml" xref="S2.p2.1.m1.1.1.3"><times id="S2.p2.1.m1.1.1.3.1.cmml" xref="S2.p2.1.m1.1.1.3.1"></times><ci id="S2.p2.1.m1.1.1.3.2.cmml" xref="S2.p2.1.m1.1.1.3.2">𝛿</ci><apply id="S2.p2.1.m1.1.1.3.3.cmml" xref="S2.p2.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S2.p2.1.m1.1.1.3.3.1.cmml" xref="S2.p2.1.m1.1.1.3.3">superscript</csymbol><ci id="S2.p2.1.m1.1.1.3.3.2.cmml" xref="S2.p2.1.m1.1.1.3.3.2">𝑊</ci><ci id="S2.p2.1.m1.1.1.3.3.3.cmml" xref="S2.p2.1.m1.1.1.3.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">\frac{\delta L}{\delta W^{i}}</annotation></semantics></math> is the weight gradient and <math id="S2.p2.2.m2.1" class="ltx_Math" alttext="\frac{\delta L}{\delta B^{i}}" display="inline"><semantics id="S2.p2.2.m2.1a"><mfrac id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml"><mrow id="S2.p2.2.m2.1.1.2" xref="S2.p2.2.m2.1.1.2.cmml"><mi id="S2.p2.2.m2.1.1.2.2" xref="S2.p2.2.m2.1.1.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S2.p2.2.m2.1.1.2.1" xref="S2.p2.2.m2.1.1.2.1.cmml">​</mo><mi id="S2.p2.2.m2.1.1.2.3" xref="S2.p2.2.m2.1.1.2.3.cmml">L</mi></mrow><mrow id="S2.p2.2.m2.1.1.3" xref="S2.p2.2.m2.1.1.3.cmml"><mi id="S2.p2.2.m2.1.1.3.2" xref="S2.p2.2.m2.1.1.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S2.p2.2.m2.1.1.3.1" xref="S2.p2.2.m2.1.1.3.1.cmml">​</mo><msup id="S2.p2.2.m2.1.1.3.3" xref="S2.p2.2.m2.1.1.3.3.cmml"><mi id="S2.p2.2.m2.1.1.3.3.2" xref="S2.p2.2.m2.1.1.3.3.2.cmml">B</mi><mi id="S2.p2.2.m2.1.1.3.3.3" xref="S2.p2.2.m2.1.1.3.3.3.cmml">i</mi></msup></mrow></mfrac><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.1b"><apply id="S2.p2.2.m2.1.1.cmml" xref="S2.p2.2.m2.1.1"><divide id="S2.p2.2.m2.1.1.1.cmml" xref="S2.p2.2.m2.1.1"></divide><apply id="S2.p2.2.m2.1.1.2.cmml" xref="S2.p2.2.m2.1.1.2"><times id="S2.p2.2.m2.1.1.2.1.cmml" xref="S2.p2.2.m2.1.1.2.1"></times><ci id="S2.p2.2.m2.1.1.2.2.cmml" xref="S2.p2.2.m2.1.1.2.2">𝛿</ci><ci id="S2.p2.2.m2.1.1.2.3.cmml" xref="S2.p2.2.m2.1.1.2.3">𝐿</ci></apply><apply id="S2.p2.2.m2.1.1.3.cmml" xref="S2.p2.2.m2.1.1.3"><times id="S2.p2.2.m2.1.1.3.1.cmml" xref="S2.p2.2.m2.1.1.3.1"></times><ci id="S2.p2.2.m2.1.1.3.2.cmml" xref="S2.p2.2.m2.1.1.3.2">𝛿</ci><apply id="S2.p2.2.m2.1.1.3.3.cmml" xref="S2.p2.2.m2.1.1.3.3"><csymbol cd="ambiguous" id="S2.p2.2.m2.1.1.3.3.1.cmml" xref="S2.p2.2.m2.1.1.3.3">superscript</csymbol><ci id="S2.p2.2.m2.1.1.3.3.2.cmml" xref="S2.p2.2.m2.1.1.3.3.2">𝐵</ci><ci id="S2.p2.2.m2.1.1.3.3.3.cmml" xref="S2.p2.2.m2.1.1.3.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.1c">\frac{\delta L}{\delta B^{i}}</annotation></semantics></math> is the bias gradient of a neuron. Neuron <math id="S2.p2.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.p2.3.m3.1a"><mi id="S2.p2.3.m3.1.1" xref="S2.p2.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.1b"><ci id="S2.p2.3.m3.1.1.cmml" xref="S2.p2.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.3.m3.1c">i</annotation></semantics></math> is activated by an image and <math id="S2.p2.4.m4.1" class="ltx_Math" alttext="x^{i}" display="inline"><semantics id="S2.p2.4.m4.1a"><msup id="S2.p2.4.m4.1.1" xref="S2.p2.4.m4.1.1.cmml"><mi id="S2.p2.4.m4.1.1.2" xref="S2.p2.4.m4.1.1.2.cmml">x</mi><mi id="S2.p2.4.m4.1.1.3" xref="S2.p2.4.m4.1.1.3.cmml">i</mi></msup><annotation-xml encoding="MathML-Content" id="S2.p2.4.m4.1b"><apply id="S2.p2.4.m4.1.1.cmml" xref="S2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S2.p2.4.m4.1.1.1.cmml" xref="S2.p2.4.m4.1.1">superscript</csymbol><ci id="S2.p2.4.m4.1.1.2.cmml" xref="S2.p2.4.m4.1.1.2">𝑥</ci><ci id="S2.p2.4.m4.1.1.3.cmml" xref="S2.p2.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.4.m4.1c">x^{i}</annotation></semantics></math> is the respective reconstructed image. However, this assumes that only a single image activated the neuron. If multiple images activate the same neuron, reconstructed image <math id="S2.p2.5.m5.1" class="ltx_Math" alttext="x^{i}" display="inline"><semantics id="S2.p2.5.m5.1a"><msup id="S2.p2.5.m5.1.1" xref="S2.p2.5.m5.1.1.cmml"><mi id="S2.p2.5.m5.1.1.2" xref="S2.p2.5.m5.1.1.2.cmml">x</mi><mi id="S2.p2.5.m5.1.1.3" xref="S2.p2.5.m5.1.1.3.cmml">i</mi></msup><annotation-xml encoding="MathML-Content" id="S2.p2.5.m5.1b"><apply id="S2.p2.5.m5.1.1.cmml" xref="S2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S2.p2.5.m5.1.1.1.cmml" xref="S2.p2.5.m5.1.1">superscript</csymbol><ci id="S2.p2.5.m5.1.1.2.cmml" xref="S2.p2.5.m5.1.1.2">𝑥</ci><ci id="S2.p2.5.m5.1.1.3.cmml" xref="S2.p2.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.5.m5.1c">x^{i}</annotation></semantics></math> becomes a combination of the images.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.2" class="ltx_p">To mitigate this, the methods of trap weights <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">1</span></a>]</cite> and Robbing the Fed <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>]</cite> were proposed. Trap weights initializes the weights of the FC layer randomly as half positive and half negative, where the negative parameters are sampled from a slightly larger magnitude. This method has difficulty with scaling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite> compared to Robbing the Fed, which proposed a method where the FC layer weights are used to measure a property of the images (e.g., average pixel brightness). The biases of the layer were then set to fit the distribution of the dataset and a ReLU activation was used to threshold the activation. Images were reconstructed as</p>
<table id="S2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E3.m1.2" class="ltx_Math" alttext="x^{i}=(\frac{\delta L}{\delta W^{i}}-\frac{\delta L}{\delta W^{i+1}})/(\frac{\delta L}{\delta B^{i}}-\frac{\delta L}{\delta B^{i+1}})\vspace*{-2mm}" display="block"><semantics id="S2.E3.m1.2a"><mrow id="S2.E3.m1.2.2" xref="S2.E3.m1.2.2.cmml"><msup id="S2.E3.m1.2.2.4" xref="S2.E3.m1.2.2.4.cmml"><mi id="S2.E3.m1.2.2.4.2" xref="S2.E3.m1.2.2.4.2.cmml">x</mi><mi id="S2.E3.m1.2.2.4.3" xref="S2.E3.m1.2.2.4.3.cmml">i</mi></msup><mo id="S2.E3.m1.2.2.3" xref="S2.E3.m1.2.2.3.cmml">=</mo><mrow id="S2.E3.m1.2.2.2" xref="S2.E3.m1.2.2.2.cmml"><mrow id="S2.E3.m1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E3.m1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.cmml"><mfrac id="S2.E3.m1.1.1.1.1.1.1.2" xref="S2.E3.m1.1.1.1.1.1.1.2.cmml"><mrow id="S2.E3.m1.1.1.1.1.1.1.2.2" xref="S2.E3.m1.1.1.1.1.1.1.2.2.cmml"><mi id="S2.E3.m1.1.1.1.1.1.1.2.2.2" xref="S2.E3.m1.1.1.1.1.1.1.2.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.1.2.2.1" xref="S2.E3.m1.1.1.1.1.1.1.2.2.1.cmml">​</mo><mi id="S2.E3.m1.1.1.1.1.1.1.2.2.3" xref="S2.E3.m1.1.1.1.1.1.1.2.2.3.cmml">L</mi></mrow><mrow id="S2.E3.m1.1.1.1.1.1.1.2.3" xref="S2.E3.m1.1.1.1.1.1.1.2.3.cmml"><mi id="S2.E3.m1.1.1.1.1.1.1.2.3.2" xref="S2.E3.m1.1.1.1.1.1.1.2.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.1.2.3.1" xref="S2.E3.m1.1.1.1.1.1.1.2.3.1.cmml">​</mo><msup id="S2.E3.m1.1.1.1.1.1.1.2.3.3" xref="S2.E3.m1.1.1.1.1.1.1.2.3.3.cmml"><mi id="S2.E3.m1.1.1.1.1.1.1.2.3.3.2" xref="S2.E3.m1.1.1.1.1.1.1.2.3.3.2.cmml">W</mi><mi id="S2.E3.m1.1.1.1.1.1.1.2.3.3.3" xref="S2.E3.m1.1.1.1.1.1.1.2.3.3.3.cmml">i</mi></msup></mrow></mfrac><mo id="S2.E3.m1.1.1.1.1.1.1.1" xref="S2.E3.m1.1.1.1.1.1.1.1.cmml">−</mo><mfrac id="S2.E3.m1.1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.3.cmml"><mrow id="S2.E3.m1.1.1.1.1.1.1.3.2" xref="S2.E3.m1.1.1.1.1.1.1.3.2.cmml"><mi id="S2.E3.m1.1.1.1.1.1.1.3.2.2" xref="S2.E3.m1.1.1.1.1.1.1.3.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.1.3.2.1" xref="S2.E3.m1.1.1.1.1.1.1.3.2.1.cmml">​</mo><mi id="S2.E3.m1.1.1.1.1.1.1.3.2.3" xref="S2.E3.m1.1.1.1.1.1.1.3.2.3.cmml">L</mi></mrow><mrow id="S2.E3.m1.1.1.1.1.1.1.3.3" xref="S2.E3.m1.1.1.1.1.1.1.3.3.cmml"><mi id="S2.E3.m1.1.1.1.1.1.1.3.3.2" xref="S2.E3.m1.1.1.1.1.1.1.3.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.1.1.1.1.1.1.3.3.1" xref="S2.E3.m1.1.1.1.1.1.1.3.3.1.cmml">​</mo><msup id="S2.E3.m1.1.1.1.1.1.1.3.3.3" xref="S2.E3.m1.1.1.1.1.1.1.3.3.3.cmml"><mi id="S2.E3.m1.1.1.1.1.1.1.3.3.3.2" xref="S2.E3.m1.1.1.1.1.1.1.3.3.3.2.cmml">W</mi><mrow id="S2.E3.m1.1.1.1.1.1.1.3.3.3.3" xref="S2.E3.m1.1.1.1.1.1.1.3.3.3.3.cmml"><mi id="S2.E3.m1.1.1.1.1.1.1.3.3.3.3.2" xref="S2.E3.m1.1.1.1.1.1.1.3.3.3.3.2.cmml">i</mi><mo id="S2.E3.m1.1.1.1.1.1.1.3.3.3.3.1" xref="S2.E3.m1.1.1.1.1.1.1.3.3.3.3.1.cmml">+</mo><mn id="S2.E3.m1.1.1.1.1.1.1.3.3.3.3.3" xref="S2.E3.m1.1.1.1.1.1.1.3.3.3.3.3.cmml">1</mn></mrow></msup></mrow></mfrac></mrow><mo stretchy="false" id="S2.E3.m1.1.1.1.1.1.3" xref="S2.E3.m1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="S2.E3.m1.2.2.2.3" xref="S2.E3.m1.2.2.2.3.cmml">/</mo><mrow id="S2.E3.m1.2.2.2.2.1" xref="S2.E3.m1.2.2.2.2.1.1.cmml"><mo stretchy="false" id="S2.E3.m1.2.2.2.2.1.2" xref="S2.E3.m1.2.2.2.2.1.1.cmml">(</mo><mrow id="S2.E3.m1.2.2.2.2.1.1" xref="S2.E3.m1.2.2.2.2.1.1.cmml"><mfrac id="S2.E3.m1.2.2.2.2.1.1.2" xref="S2.E3.m1.2.2.2.2.1.1.2.cmml"><mrow id="S2.E3.m1.2.2.2.2.1.1.2.2" xref="S2.E3.m1.2.2.2.2.1.1.2.2.cmml"><mi id="S2.E3.m1.2.2.2.2.1.1.2.2.2" xref="S2.E3.m1.2.2.2.2.1.1.2.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.2.2.1.1.2.2.1" xref="S2.E3.m1.2.2.2.2.1.1.2.2.1.cmml">​</mo><mi id="S2.E3.m1.2.2.2.2.1.1.2.2.3" xref="S2.E3.m1.2.2.2.2.1.1.2.2.3.cmml">L</mi></mrow><mrow id="S2.E3.m1.2.2.2.2.1.1.2.3" xref="S2.E3.m1.2.2.2.2.1.1.2.3.cmml"><mi id="S2.E3.m1.2.2.2.2.1.1.2.3.2" xref="S2.E3.m1.2.2.2.2.1.1.2.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.2.2.1.1.2.3.1" xref="S2.E3.m1.2.2.2.2.1.1.2.3.1.cmml">​</mo><msup id="S2.E3.m1.2.2.2.2.1.1.2.3.3" xref="S2.E3.m1.2.2.2.2.1.1.2.3.3.cmml"><mi id="S2.E3.m1.2.2.2.2.1.1.2.3.3.2" xref="S2.E3.m1.2.2.2.2.1.1.2.3.3.2.cmml">B</mi><mi id="S2.E3.m1.2.2.2.2.1.1.2.3.3.3" xref="S2.E3.m1.2.2.2.2.1.1.2.3.3.3.cmml">i</mi></msup></mrow></mfrac><mo id="S2.E3.m1.2.2.2.2.1.1.1" xref="S2.E3.m1.2.2.2.2.1.1.1.cmml">−</mo><mfrac id="S2.E3.m1.2.2.2.2.1.1.3" xref="S2.E3.m1.2.2.2.2.1.1.3.cmml"><mrow id="S2.E3.m1.2.2.2.2.1.1.3.2" xref="S2.E3.m1.2.2.2.2.1.1.3.2.cmml"><mi id="S2.E3.m1.2.2.2.2.1.1.3.2.2" xref="S2.E3.m1.2.2.2.2.1.1.3.2.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.2.2.1.1.3.2.1" xref="S2.E3.m1.2.2.2.2.1.1.3.2.1.cmml">​</mo><mi id="S2.E3.m1.2.2.2.2.1.1.3.2.3" xref="S2.E3.m1.2.2.2.2.1.1.3.2.3.cmml">L</mi></mrow><mrow id="S2.E3.m1.2.2.2.2.1.1.3.3" xref="S2.E3.m1.2.2.2.2.1.1.3.3.cmml"><mi id="S2.E3.m1.2.2.2.2.1.1.3.3.2" xref="S2.E3.m1.2.2.2.2.1.1.3.3.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="S2.E3.m1.2.2.2.2.1.1.3.3.1" xref="S2.E3.m1.2.2.2.2.1.1.3.3.1.cmml">​</mo><msup id="S2.E3.m1.2.2.2.2.1.1.3.3.3" xref="S2.E3.m1.2.2.2.2.1.1.3.3.3.cmml"><mi id="S2.E3.m1.2.2.2.2.1.1.3.3.3.2" xref="S2.E3.m1.2.2.2.2.1.1.3.3.3.2.cmml">B</mi><mrow id="S2.E3.m1.2.2.2.2.1.1.3.3.3.3" xref="S2.E3.m1.2.2.2.2.1.1.3.3.3.3.cmml"><mi id="S2.E3.m1.2.2.2.2.1.1.3.3.3.3.2" xref="S2.E3.m1.2.2.2.2.1.1.3.3.3.3.2.cmml">i</mi><mo id="S2.E3.m1.2.2.2.2.1.1.3.3.3.3.1" xref="S2.E3.m1.2.2.2.2.1.1.3.3.3.3.1.cmml">+</mo><mn id="S2.E3.m1.2.2.2.2.1.1.3.3.3.3.3" xref="S2.E3.m1.2.2.2.2.1.1.3.3.3.3.3.cmml">1</mn></mrow></msup></mrow></mfrac></mrow><mo stretchy="false" id="S2.E3.m1.2.2.2.2.1.3" xref="S2.E3.m1.2.2.2.2.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E3.m1.2b"><apply id="S2.E3.m1.2.2.cmml" xref="S2.E3.m1.2.2"><eq id="S2.E3.m1.2.2.3.cmml" xref="S2.E3.m1.2.2.3"></eq><apply id="S2.E3.m1.2.2.4.cmml" xref="S2.E3.m1.2.2.4"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.4.1.cmml" xref="S2.E3.m1.2.2.4">superscript</csymbol><ci id="S2.E3.m1.2.2.4.2.cmml" xref="S2.E3.m1.2.2.4.2">𝑥</ci><ci id="S2.E3.m1.2.2.4.3.cmml" xref="S2.E3.m1.2.2.4.3">𝑖</ci></apply><apply id="S2.E3.m1.2.2.2.cmml" xref="S2.E3.m1.2.2.2"><divide id="S2.E3.m1.2.2.2.3.cmml" xref="S2.E3.m1.2.2.2.3"></divide><apply id="S2.E3.m1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1"><minus id="S2.E3.m1.1.1.1.1.1.1.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.1"></minus><apply id="S2.E3.m1.1.1.1.1.1.1.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2"><divide id="S2.E3.m1.1.1.1.1.1.1.2.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2"></divide><apply id="S2.E3.m1.1.1.1.1.1.1.2.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.2"><times id="S2.E3.m1.1.1.1.1.1.1.2.2.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.2.1"></times><ci id="S2.E3.m1.1.1.1.1.1.1.2.2.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.2.2">𝛿</ci><ci id="S2.E3.m1.1.1.1.1.1.1.2.2.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.2.3">𝐿</ci></apply><apply id="S2.E3.m1.1.1.1.1.1.1.2.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.3"><times id="S2.E3.m1.1.1.1.1.1.1.2.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.3.1"></times><ci id="S2.E3.m1.1.1.1.1.1.1.2.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.3.2">𝛿</ci><apply id="S2.E3.m1.1.1.1.1.1.1.2.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.3.3"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.2.3.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.3.3">superscript</csymbol><ci id="S2.E3.m1.1.1.1.1.1.1.2.3.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.3.3.2">𝑊</ci><ci id="S2.E3.m1.1.1.1.1.1.1.2.3.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.2.3.3.3">𝑖</ci></apply></apply></apply><apply id="S2.E3.m1.1.1.1.1.1.1.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3"><divide id="S2.E3.m1.1.1.1.1.1.1.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3"></divide><apply id="S2.E3.m1.1.1.1.1.1.1.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3.2"><times id="S2.E3.m1.1.1.1.1.1.1.3.2.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3.2.1"></times><ci id="S2.E3.m1.1.1.1.1.1.1.3.2.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3.2.2">𝛿</ci><ci id="S2.E3.m1.1.1.1.1.1.1.3.2.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3.2.3">𝐿</ci></apply><apply id="S2.E3.m1.1.1.1.1.1.1.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3.3"><times id="S2.E3.m1.1.1.1.1.1.1.3.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3.3.1"></times><ci id="S2.E3.m1.1.1.1.1.1.1.3.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3.3.2">𝛿</ci><apply id="S2.E3.m1.1.1.1.1.1.1.3.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.E3.m1.1.1.1.1.1.1.3.3.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3.3.3">superscript</csymbol><ci id="S2.E3.m1.1.1.1.1.1.1.3.3.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3.3.3.2">𝑊</ci><apply id="S2.E3.m1.1.1.1.1.1.1.3.3.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3.3.3.3"><plus id="S2.E3.m1.1.1.1.1.1.1.3.3.3.3.1.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3.3.3.3.1"></plus><ci id="S2.E3.m1.1.1.1.1.1.1.3.3.3.3.2.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3.3.3.3.2">𝑖</ci><cn type="integer" id="S2.E3.m1.1.1.1.1.1.1.3.3.3.3.3.cmml" xref="S2.E3.m1.1.1.1.1.1.1.3.3.3.3.3">1</cn></apply></apply></apply></apply></apply><apply id="S2.E3.m1.2.2.2.2.1.1.cmml" xref="S2.E3.m1.2.2.2.2.1"><minus id="S2.E3.m1.2.2.2.2.1.1.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.1"></minus><apply id="S2.E3.m1.2.2.2.2.1.1.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.2"><divide id="S2.E3.m1.2.2.2.2.1.1.2.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.2"></divide><apply id="S2.E3.m1.2.2.2.2.1.1.2.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.2.2"><times id="S2.E3.m1.2.2.2.2.1.1.2.2.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.2.2.1"></times><ci id="S2.E3.m1.2.2.2.2.1.1.2.2.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.2.2.2">𝛿</ci><ci id="S2.E3.m1.2.2.2.2.1.1.2.2.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.2.2.3">𝐿</ci></apply><apply id="S2.E3.m1.2.2.2.2.1.1.2.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.2.3"><times id="S2.E3.m1.2.2.2.2.1.1.2.3.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.2.3.1"></times><ci id="S2.E3.m1.2.2.2.2.1.1.2.3.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.2.3.2">𝛿</ci><apply id="S2.E3.m1.2.2.2.2.1.1.2.3.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.2.3.3"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.2.2.1.1.2.3.3.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.2.3.3">superscript</csymbol><ci id="S2.E3.m1.2.2.2.2.1.1.2.3.3.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.2.3.3.2">𝐵</ci><ci id="S2.E3.m1.2.2.2.2.1.1.2.3.3.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.2.3.3.3">𝑖</ci></apply></apply></apply><apply id="S2.E3.m1.2.2.2.2.1.1.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.3"><divide id="S2.E3.m1.2.2.2.2.1.1.3.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.3"></divide><apply id="S2.E3.m1.2.2.2.2.1.1.3.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.3.2"><times id="S2.E3.m1.2.2.2.2.1.1.3.2.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.3.2.1"></times><ci id="S2.E3.m1.2.2.2.2.1.1.3.2.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.3.2.2">𝛿</ci><ci id="S2.E3.m1.2.2.2.2.1.1.3.2.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.3.2.3">𝐿</ci></apply><apply id="S2.E3.m1.2.2.2.2.1.1.3.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.3.3"><times id="S2.E3.m1.2.2.2.2.1.1.3.3.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.3.3.1"></times><ci id="S2.E3.m1.2.2.2.2.1.1.3.3.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.3.3.2">𝛿</ci><apply id="S2.E3.m1.2.2.2.2.1.1.3.3.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.3.3.3"><csymbol cd="ambiguous" id="S2.E3.m1.2.2.2.2.1.1.3.3.3.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.3.3.3">superscript</csymbol><ci id="S2.E3.m1.2.2.2.2.1.1.3.3.3.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.3.3.3.2">𝐵</ci><apply id="S2.E3.m1.2.2.2.2.1.1.3.3.3.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.3.3.3.3"><plus id="S2.E3.m1.2.2.2.2.1.1.3.3.3.3.1.cmml" xref="S2.E3.m1.2.2.2.2.1.1.3.3.3.3.1"></plus><ci id="S2.E3.m1.2.2.2.2.1.1.3.3.3.3.2.cmml" xref="S2.E3.m1.2.2.2.2.1.1.3.3.3.3.2">𝑖</ci><cn type="integer" id="S2.E3.m1.2.2.2.2.1.1.3.3.3.3.3.cmml" xref="S2.E3.m1.2.2.2.2.1.1.3.3.3.3.3">1</cn></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E3.m1.2c">x^{i}=(\frac{\delta L}{\delta W^{i}}-\frac{\delta L}{\delta W^{i+1}})/(\frac{\delta L}{\delta B^{i}}-\frac{\delta L}{\delta B^{i+1}})\vspace*{-2mm}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S2.p3.1" class="ltx_p">where <math id="S2.p3.1.m1.1" class="ltx_Math" alttext="i+1" display="inline"><semantics id="S2.p3.1.m1.1a"><mrow id="S2.p3.1.m1.1.1" xref="S2.p3.1.m1.1.1.cmml"><mi id="S2.p3.1.m1.1.1.2" xref="S2.p3.1.m1.1.1.2.cmml">i</mi><mo id="S2.p3.1.m1.1.1.1" xref="S2.p3.1.m1.1.1.1.cmml">+</mo><mn id="S2.p3.1.m1.1.1.3" xref="S2.p3.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.1b"><apply id="S2.p3.1.m1.1.1.cmml" xref="S2.p3.1.m1.1.1"><plus id="S2.p3.1.m1.1.1.1.cmml" xref="S2.p3.1.m1.1.1.1"></plus><ci id="S2.p3.1.m1.1.1.2.cmml" xref="S2.p3.1.m1.1.1.2">𝑖</ci><cn type="integer" id="S2.p3.1.m1.1.1.3.cmml" xref="S2.p3.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.1.m1.1c">i+1</annotation></semantics></math> indicates the neuron with a bias being the next highest cutoff. This method requires basic knowledge about the input data distribution, but achieves a higher leakage rate compared to trap weights and is scalable to aggregation.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">In the case of FedAvg, the sparse variant of Robbing the Fed utilizes a two-sided activation function (such as Hard tanh) and weight/bias scaling to maintain the same leakage as in FedSGD. However, the sparse variant is not scalable and leads to precision problems when attacking secure aggregation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">2</span></a>]</cite> or larger batches. The LOKI attack addresses the scalability problems of both methods through the introduction of a convolutional layer that splits the scaling between number of clients and batch size in secure aggregation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite>. They further introduce a convolutional scaling factor (CSF) which achieves a higher leakage rate in FedAvg without increasing the FC layer size.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">While there have been many works exploring data reconstruction, prior work has not evaluated these attacks in the context of downstream tasks. The works on GI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">32</span></a>, <a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>, <a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">26</span></a>]</cite> and LLL <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>, <a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">1</span></a>, <a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite> attacks only discuss the reconstruction quality of the methods in terms of standard image metrics such as PSNR (peak signal-to-noise ratio), SSIM (structural similarity index measure), or LPIPS (learned perceptual image patch similarity ).
However, these metrics only measure how similar the reconstruction are to the ground truth and only give a vague sense of how useful the data is for training. Another work discussed the limitations of GI attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>]</cite> measured by image similarity. In <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">29</span></a>]</cite>, LLL attacks were measured in terms of the resource overhead added by the attacks. However, these works also did not discuss the usefulness of reconstructed data post-leakage.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">This work aims to bridge the gap and explore the important facet of training machine learning models on leaked data from reconstruction attacks. Viewing leaked data beyond privacy breach brings to light key weaknesses of current attacks in generating useful data. While LLL reconstructs high quality images, the other important half of data, namely having matching labels, is missing. GI attacks can breach privacy for larger batch sizes, but the quality of the leaked data would be nearly useless for training models. In the age of machine learning and artificial intelligence, the value of data has increased tremendously. Therefore, when looking at leaked data, it is important to measure success in terms of usefulness to model training.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Training on leaked data</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Data reconstruction attacks have largely focused on the quality of the recovered image in gradient inversion (GI) or the efficiency of linear layer leakage (LLL). However, label reconstruction is important for training on leaked data. Within the pipeline of GI attacks, labels are typically recovered prior to reconstruction, as they assist in the optimization problem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">10</span></a>]</cite>. Recent works have shown that label restoration with large batches and duplicate labels is possible <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">7</span></a>, <a href="#bib.bib16" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">16</span></a>]</cite>. More accurate labels and the added flexibility of duplicate class images directly improves prior GI attacks such as Inverting Gradients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite> and GradInversion <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">26</span></a>]</cite>.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">Interestingly, one strength of LLL has been in the ability to reconstruct images without knowledge of the data labels. While the class labels can affect the distribution of the client dataset (e.g., average image brightness can be different between classes) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite>, the labels themselves do not help in the reconstruction. Knowing labels helps guide GI attacks (as gradients are computed from data and label pairs), but for LLL, images activating the neurons are reconstructed using only the weight and bias gradients of the FC layer as with Equation <a href="#S2.E3" title="Equation 3 ‣ 2 Related work ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Labels are necessary to train models using leaked data, but even with a set of recovered labels, the leaked images would still remain unmatched. Unlike GI which matches during optimization, images leaked by LLL would need to be manually matched. For this work, we experiment with cases when all labels are known and matched and alternatively, when only a small portion of labels are known and matched.
Nonetheless, the label leakage and matching issue stands as an open problem for LLL attacks.
</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">Identifying which images are reconstructed correctly is also a challenging problem for LLL. For FedSGD, bins without activation can be identified, as after the subtraction process the reconstruction will be zero. However, if multiple images activate the same bin, the reconstruction is non-zero. By checking for non-zero values, we cannot directly identify whether the reconstruction is a single image or a combination of multiple. Manually filtering this can become a tedious process in practice. This is somewhat mitigated in the FedAvg case by LOKI. Across separate FedAvg local mini-batches, multiple images will <span id="S3.p3.1.1" class="ltx_text ltx_font_italic">not</span> activate the same neuron, resulting in much fewew overlapping reconstructions.
Therefore the only images that can cause multiple activations are within the same mini-batch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite>. In this work, we manually filter out multiple image reconstructions in order to test the quality of the data. However, especially for LLL in FedSGD, the problem of how to automate removal or how to use these multiple image reconstructions for training still remains an important item of future work.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">The goal of our work is to discuss the effectiveness of leaked data when used for the downstream task of image classification. We use centralized training on the entire benign dataset and federated learning (with only updates and no data shared by the clients) as the baselines for comparison. Typically, these serve as the upper bound and the lower bound respectively for the model accuracy. For federated learning, we use two settings of 10 and 50 clients. We use a non-IID bias of 0.5 and FedAvg with 3 local iterations. Additional training results for the IID setting and FedSGD are included in the supplementary.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">We use Inverting Gradients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite> as the gradient inversion (GI) attack. Another candidate is GradInversion, which is a SOTA GI attack (especially for ImageNet-sized images). However, we discarded this as the author code for this attack is not available and the third-party online implementations did not achieve comparable results to the original paper. For linear layer leakage (LLL), we use the LOKI attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite>. We use LOKI as it achieves SOTA FedAvg leakage rate and equivalent SOTA leakage rate in FedSGD compared to Robbing the Fed. Model performance for other LLL methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a>, <a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">1</span></a>]</cite> can be found in the supplementary.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">We use MNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">13</span></a>]</cite>, CIFAR-10 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">11</span></a>]</cite>, and the Tiny ImageNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">12</span></a>]</cite> datasets. For the MNIST dataset, we train using a simple DNN with 2 convolutional layers and 2 FC layers. For CIFAR-10 and Tiny Imagenet, we use a ResNet-18 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">8</span></a>]</cite>. We evaluate on the validation set for Tiny ImageNet because the test set is unlabeled. The plots only show a single run for each setting, but the (numerical) testing performance is reported as an average over 5 runs. We run all experiments on NVIDIA A100 80GB GPUs.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Gradient inversion computation time</h3>

<figure id="S4.T1" class="ltx_table">
<table id="S4.T1.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.2.1.1" class="ltx_tr">
<th id="S4.T1.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" colspan="4"><span id="S4.T1.2.1.1.1.1" class="ltx_text" style="font-size:70%;">MNIST</span></th>
</tr>
<tr id="S4.T1.2.2.2" class="ltx_tr">
<th id="S4.T1.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T1.2.2.2.1.1" class="ltx_text" style="font-size:70%;">Batch size</span></th>
<th id="S4.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T1.2.2.2.2.1" class="ltx_text" style="font-size:70%;">Model</span></th>
<th id="S4.T1.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T1.2.2.2.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.2.2.2.3.1.1" class="ltx_tr">
<td id="S4.T1.2.2.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.2.2.2.3.1.1.1.1" class="ltx_text" style="font-size:70%;">Time per</span></td>
</tr>
<tr id="S4.T1.2.2.2.3.1.2" class="ltx_tr">
<td id="S4.T1.2.2.2.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.2.2.2.3.1.2.1.1" class="ltx_text" style="font-size:70%;">batch (s)</span></td>
</tr>
</table>
</th>
<th id="S4.T1.2.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T1.2.2.2.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.2.2.2.4.1.1" class="ltx_tr">
<td id="S4.T1.2.2.2.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.2.2.2.4.1.1.1.1" class="ltx_text" style="font-size:70%;">Time for entire</span></td>
</tr>
<tr id="S4.T1.2.2.2.4.1.2" class="ltx_tr">
<td id="S4.T1.2.2.2.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.2.2.2.4.1.2.1.1" class="ltx_text" style="font-size:70%;">dataset (days)</span></td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.2.3.1" class="ltx_tr">
<th id="S4.T1.2.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T1.2.3.1.1.1" class="ltx_text" style="font-size:70%;">8</span></th>
<td id="S4.T1.2.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" rowspan="3"><span id="S4.T1.2.3.1.2.1" class="ltx_text" style="font-size:70%;">DNN</span></td>
<td id="S4.T1.2.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.2.3.1.3.1" class="ltx_text" style="font-size:70%;">54.79</span></td>
<td id="S4.T1.2.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.2.3.1.4.1" class="ltx_text" style="font-size:70%;">4.76</span></td>
</tr>
<tr id="S4.T1.2.4.2" class="ltx_tr">
<th id="S4.T1.2.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span id="S4.T1.2.4.2.1.1" class="ltx_text" style="font-size:70%;">16</span></th>
<td id="S4.T1.2.4.2.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.2.4.2.2.1" class="ltx_text" style="font-size:70%;">62.34</span></td>
<td id="S4.T1.2.4.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.2.4.2.3.1" class="ltx_text" style="font-size:70%;">2.71</span></td>
</tr>
<tr id="S4.T1.2.5.3" class="ltx_tr">
<th id="S4.T1.2.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span id="S4.T1.2.5.3.1.1" class="ltx_text" style="font-size:70%;">32</span></th>
<td id="S4.T1.2.5.3.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.2.5.3.2.1" class="ltx_text" style="font-size:70%;">64.32</span></td>
<td id="S4.T1.2.5.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.2.5.3.3.1" class="ltx_text" style="font-size:70%;">1.40</span></td>
</tr>
<tr id="S4.T1.2.6.4" class="ltx_tr">
<th id="S4.T1.2.6.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" colspan="4"><span id="S4.T1.2.6.4.1.1" class="ltx_text" style="font-size:70%;">CIFAR-10</span></th>
</tr>
<tr id="S4.T1.2.7.5" class="ltx_tr">
<th id="S4.T1.2.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T1.2.7.5.1.1" class="ltx_text" style="font-size:70%;">Batch size</span></th>
<th id="S4.T1.2.7.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T1.2.7.5.2.1" class="ltx_text" style="font-size:70%;">Model</span></th>
<th id="S4.T1.2.7.5.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T1.2.7.5.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.2.7.5.3.1.1" class="ltx_tr">
<td id="S4.T1.2.7.5.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.2.7.5.3.1.1.1.1" class="ltx_text" style="font-size:70%;">Time per</span></td>
</tr>
<tr id="S4.T1.2.7.5.3.1.2" class="ltx_tr">
<td id="S4.T1.2.7.5.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.2.7.5.3.1.2.1.1" class="ltx_text" style="font-size:70%;">batch (s)</span></td>
</tr>
</table>
</th>
<th id="S4.T1.2.7.5.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T1.2.7.5.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T1.2.7.5.4.1.1" class="ltx_tr">
<td id="S4.T1.2.7.5.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.2.7.5.4.1.1.1.1" class="ltx_text" style="font-size:70%;">Time for entire</span></td>
</tr>
<tr id="S4.T1.2.7.5.4.1.2" class="ltx_tr">
<td id="S4.T1.2.7.5.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T1.2.7.5.4.1.2.1.1" class="ltx_text" style="font-size:70%;">dataset (days)</span></td>
</tr>
</table>
</th>
</tr>
<tr id="S4.T1.2.8.6" class="ltx_tr">
<th id="S4.T1.2.8.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T1.2.8.6.1.1" class="ltx_text" style="font-size:70%;">4</span></th>
<td id="S4.T1.2.8.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" rowspan="3"><span id="S4.T1.2.8.6.2.1" class="ltx_text" style="font-size:70%;">ResNet-18</span></td>
<td id="S4.T1.2.8.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.2.8.6.3.1" class="ltx_text" style="font-size:70%;">422.81</span></td>
<td id="S4.T1.2.8.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T1.2.8.6.4.1" class="ltx_text" style="font-size:70%;">61.17</span></td>
</tr>
<tr id="S4.T1.2.9.7" class="ltx_tr">
<th id="S4.T1.2.9.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span id="S4.T1.2.9.7.1.1" class="ltx_text" style="font-size:70%;">8</span></th>
<td id="S4.T1.2.9.7.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.2.9.7.2.1" class="ltx_text" style="font-size:70%;">437.54</span></td>
<td id="S4.T1.2.9.7.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T1.2.9.7.3.1" class="ltx_text" style="font-size:70%;">31.65</span></td>
</tr>
<tr id="S4.T1.2.10.8" class="ltx_tr">
<th id="S4.T1.2.10.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r"><span id="S4.T1.2.10.8.1.1" class="ltx_text" style="font-size:70%;">16</span></th>
<td id="S4.T1.2.10.8.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T1.2.10.8.2.1" class="ltx_text" style="font-size:70%;">435.33</span></td>
<td id="S4.T1.2.10.8.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T1.2.10.8.3.1" class="ltx_text" style="font-size:70%;">15.75</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.5.1.1" class="ltx_text" style="font-size:129%;">Table 1</span>: </span><span id="S4.T1.6.2" class="ltx_text" style="font-size:129%;"> Computation time for Inverting Gradients running on a NVIDIA A100 80GB GPU. Small batches have more total batches and take more time for the whole dataset. Computation time is significantly higher for CIFAR-10 given the more complex model.</span></figcaption>
</figure>
<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Compared to LLL attacks, the computational overhead of GI attacks when reconstructing data, while done offline, is still non-negligible. In order to fully evaluate the leaked data, we ran the Inverting Gradients atack on the entire dataset of MNIST with batch sizes of 8, 16, and 32. We also ran over CIFAR-10 with batch sizes of 4, 8, and 16. We run 10,000 iterations of optimization for each batch. We evaluate the Inverting Gradients attack in the best case scenario with an untrained model where <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_italic">all</span> labels are correctly recovered prior to optimization.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">Table <a href="#S4.T1" title="Table 1 ‣ 4.1 Gradient inversion computation time ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the amount of time taken by Inverting Gradients run on a NVIDIA A100 80GB GPU for MNIST and CIFAR-10 on a DNN and ResNet-18 respectively. There is some variance in the average amount of time based on batch size, but when attacking the entire dataset, smaller batch sizes always take longer time as the number of total batches is much larger. CIFAR-10 takes significantly longer to reconstruct each batch given the more complex model of ResNet-18 compared to a DNN. For a batch size of 4, CIFAR-10 takes 422.81 seconds per batch. Iterating across the entire dataset on a single GPU takes 61.17 days.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Leakage statistics</h3>

<figure id="S4.T2" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.T2.st1" class="ltx_table ltx_figure_panel ltx_align_center">
<table id="S4.T2.st1.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.st1.2.1.1" class="ltx_tr">
<th id="S4.T2.st1.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" colspan="3"><span id="S4.T2.st1.2.1.1.1.1" class="ltx_text" style="font-size:70%;">CIFAR-10</span></th>
<th id="S4.T2.st1.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="3"><span id="S4.T2.st1.2.1.1.2.1" class="ltx_text" style="font-size:70%;">MNIST</span></th>
</tr>
<tr id="S4.T2.st1.2.2.2" class="ltx_tr">
<th id="S4.T2.st1.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T2.st1.2.2.2.1.1" class="ltx_text" style="font-size:70%;">Batch size</span></th>
<th id="S4.T2.st1.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.st1.2.2.2.2.1" class="ltx_text" style="font-size:70%;">PSNR</span></th>
<th id="S4.T2.st1.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T2.st1.2.2.2.3.1" class="ltx_text" style="font-size:70%;">SSIM</span></th>
<th id="S4.T2.st1.2.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T2.st1.2.2.2.4.1" class="ltx_text" style="font-size:70%;">Batch size</span></th>
<th id="S4.T2.st1.2.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S4.T2.st1.2.2.2.5.1" class="ltx_text" style="font-size:70%;">PSNR</span></th>
<th id="S4.T2.st1.2.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T2.st1.2.2.2.6.1" class="ltx_text" style="font-size:70%;">SSIM</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.st1.2.3.1" class="ltx_tr">
<td id="S4.T2.st1.2.3.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T2.st1.2.3.1.1.1" class="ltx_text" style="font-size:70%;">4</span></td>
<td id="S4.T2.st1.2.3.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.st1.2.3.1.2.1" class="ltx_text" style="font-size:70%;">27.88</span></td>
<td id="S4.T2.st1.2.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.st1.2.3.1.3.1" class="ltx_text" style="font-size:70%;">0.9067</span></td>
<td id="S4.T2.st1.2.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.st1.2.3.1.4.1" class="ltx_text" style="font-size:70%;">8</span></td>
<td id="S4.T2.st1.2.3.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.st1.2.3.1.5.1" class="ltx_text" style="font-size:70%;">23.16</span></td>
<td id="S4.T2.st1.2.3.1.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.st1.2.3.1.6.1" class="ltx_text" style="font-size:70%;">0.6996</span></td>
</tr>
<tr id="S4.T2.st1.2.4.2" class="ltx_tr">
<td id="S4.T2.st1.2.4.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r"><span id="S4.T2.st1.2.4.2.1.1" class="ltx_text" style="font-size:70%;">8</span></td>
<td id="S4.T2.st1.2.4.2.2" class="ltx_td ltx_align_center"><span id="S4.T2.st1.2.4.2.2.1" class="ltx_text" style="font-size:70%;">20.77</span></td>
<td id="S4.T2.st1.2.4.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.st1.2.4.2.3.1" class="ltx_text" style="font-size:70%;">0.7215</span></td>
<td id="S4.T2.st1.2.4.2.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.st1.2.4.2.4.1" class="ltx_text" style="font-size:70%;">16</span></td>
<td id="S4.T2.st1.2.4.2.5" class="ltx_td ltx_align_center"><span id="S4.T2.st1.2.4.2.5.1" class="ltx_text" style="font-size:70%;">19.15</span></td>
<td id="S4.T2.st1.2.4.2.6" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.st1.2.4.2.6.1" class="ltx_text" style="font-size:70%;">0.6506</span></td>
</tr>
<tr id="S4.T2.st1.2.5.3" class="ltx_tr">
<td id="S4.T2.st1.2.5.3.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r"><span id="S4.T2.st1.2.5.3.1.1" class="ltx_text" style="font-size:70%;">16</span></td>
<td id="S4.T2.st1.2.5.3.2" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T2.st1.2.5.3.2.1" class="ltx_text" style="font-size:70%;">15.94</span></td>
<td id="S4.T2.st1.2.5.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T2.st1.2.5.3.3.1" class="ltx_text" style="font-size:70%;">0.3978</span></td>
<td id="S4.T2.st1.2.5.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T2.st1.2.5.3.4.1" class="ltx_text" style="font-size:70%;">32</span></td>
<td id="S4.T2.st1.2.5.3.5" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T2.st1.2.5.3.5.1" class="ltx_text" style="font-size:70%;">15.78</span></td>
<td id="S4.T2.st1.2.5.3.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T2.st1.2.5.3.6.1" class="ltx_text" style="font-size:70%;">0.4537</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.st1.5.1.1" class="ltx_text" style="font-size:129%;">(a)</span> </span><span id="S4.T2.st1.6.2" class="ltx_text" style="font-size:129%;">Gradient Inversion PSNR/SSIM</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.T2.st2" class="ltx_table ltx_figure_panel ltx_align_center">
<table id="S4.T2.st2.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.st2.2.1.1" class="ltx_tr">
<th id="S4.T2.st2.2.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S4.T2.st2.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2"><span id="S4.T2.st2.2.1.1.2.1" class="ltx_text" style="font-size:70%;">CIFAR-10</span></th>
<th id="S4.T2.st2.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2"><span id="S4.T2.st2.2.1.1.3.1" class="ltx_text" style="font-size:70%;">MNIST</span></th>
<th id="S4.T2.st2.2.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t" colspan="2"><span id="S4.T2.st2.2.1.1.4.1" class="ltx_text" style="font-size:70%;">Tiny ImageNet</span></th>
</tr>
<tr id="S4.T2.st2.2.2.2" class="ltx_tr">
<th id="S4.T2.st2.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t">
<table id="S4.T2.st2.2.2.2.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.st2.2.2.2.1.1.1" class="ltx_tr">
<td id="S4.T2.st2.2.2.2.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S4.T2.st2.2.2.2.1.1.1.1.1" class="ltx_text" style="font-size:70%;">FC</span></td>
</tr>
<tr id="S4.T2.st2.2.2.2.1.1.2" class="ltx_tr">
<td id="S4.T2.st2.2.2.2.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S4.T2.st2.2.2.2.1.1.2.1.1" class="ltx_text" style="font-size:70%;">factor</span></td>
</tr>
</table>
</th>
<th id="S4.T2.st2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<table id="S4.T2.st2.2.2.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.st2.2.2.2.2.1.1" class="ltx_tr">
<td id="S4.T2.st2.2.2.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.st2.2.2.2.2.1.1.1.1" class="ltx_text" style="font-size:70%;">Leaked</span></td>
</tr>
<tr id="S4.T2.st2.2.2.2.2.1.2" class="ltx_tr">
<td id="S4.T2.st2.2.2.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.st2.2.2.2.2.1.2.1.1" class="ltx_text" style="font-size:70%;">images</span></td>
</tr>
</table>
</th>
<th id="S4.T2.st2.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T2.st2.2.2.2.3.1" class="ltx_text" style="font-size:70%;">Percent</span></th>
<th id="S4.T2.st2.2.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<table id="S4.T2.st2.2.2.2.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.st2.2.2.2.4.1.1" class="ltx_tr">
<td id="S4.T2.st2.2.2.2.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.st2.2.2.2.4.1.1.1.1" class="ltx_text" style="font-size:70%;">Leaked</span></td>
</tr>
<tr id="S4.T2.st2.2.2.2.4.1.2" class="ltx_tr">
<td id="S4.T2.st2.2.2.2.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.st2.2.2.2.4.1.2.1.1" class="ltx_text" style="font-size:70%;">images</span></td>
</tr>
</table>
</th>
<th id="S4.T2.st2.2.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T2.st2.2.2.2.5.1" class="ltx_text" style="font-size:70%;">Percent</span></th>
<th id="S4.T2.st2.2.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<table id="S4.T2.st2.2.2.2.6.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T2.st2.2.2.2.6.1.1" class="ltx_tr">
<td id="S4.T2.st2.2.2.2.6.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.st2.2.2.2.6.1.1.1.1" class="ltx_text" style="font-size:70%;">Leaked</span></td>
</tr>
<tr id="S4.T2.st2.2.2.2.6.1.2" class="ltx_tr">
<td id="S4.T2.st2.2.2.2.6.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T2.st2.2.2.2.6.1.2.1.1" class="ltx_text" style="font-size:70%;">images</span></td>
</tr>
</table>
</th>
<th id="S4.T2.st2.2.2.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T2.st2.2.2.2.7.1" class="ltx_text" style="font-size:70%;">Percent</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.st2.2.3.1" class="ltx_tr">
<th id="S4.T2.st2.2.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T2.st2.2.3.1.1.1" class="ltx_text" style="font-size:70%;">8</span></th>
<td id="S4.T2.st2.2.3.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.st2.2.3.1.2.1" class="ltx_text" style="font-size:70%;">43788</span></td>
<td id="S4.T2.st2.2.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.st2.2.3.1.3.1" class="ltx_text" style="font-size:70%;">87.58</span></td>
<td id="S4.T2.st2.2.3.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.st2.2.3.1.4.1" class="ltx_text" style="font-size:70%;">52548</span></td>
<td id="S4.T2.st2.2.3.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.st2.2.3.1.5.1" class="ltx_text" style="font-size:70%;">87.58</span></td>
<td id="S4.T2.st2.2.3.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S4.T2.st2.2.3.1.6.1" class="ltx_text" style="font-size:70%;">85804</span></td>
<td id="S4.T2.st2.2.3.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T2.st2.2.3.1.7.1" class="ltx_text" style="font-size:70%;">85.80</span></td>
</tr>
<tr id="S4.T2.st2.2.4.2" class="ltx_tr">
<th id="S4.T2.st2.2.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span id="S4.T2.st2.2.4.2.1.1" class="ltx_text" style="font-size:70%;">4</span></th>
<td id="S4.T2.st2.2.4.2.2" class="ltx_td ltx_align_center"><span id="S4.T2.st2.2.4.2.2.1" class="ltx_text" style="font-size:70%;">39464</span></td>
<td id="S4.T2.st2.2.4.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.st2.2.4.2.3.1" class="ltx_text" style="font-size:70%;">78.93</span></td>
<td id="S4.T2.st2.2.4.2.4" class="ltx_td ltx_align_center"><span id="S4.T2.st2.2.4.2.4.1" class="ltx_text" style="font-size:70%;">45966</span></td>
<td id="S4.T2.st2.2.4.2.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.st2.2.4.2.5.1" class="ltx_text" style="font-size:70%;">76.61</span></td>
<td id="S4.T2.st2.2.4.2.6" class="ltx_td ltx_align_center"><span id="S4.T2.st2.2.4.2.6.1" class="ltx_text" style="font-size:70%;">75149</span></td>
<td id="S4.T2.st2.2.4.2.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.st2.2.4.2.7.1" class="ltx_text" style="font-size:70%;">75.15</span></td>
</tr>
<tr id="S4.T2.st2.2.5.3" class="ltx_tr">
<th id="S4.T2.st2.2.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span id="S4.T2.st2.2.5.3.1.1" class="ltx_text" style="font-size:70%;">2</span></th>
<td id="S4.T2.st2.2.5.3.2" class="ltx_td ltx_align_center"><span id="S4.T2.st2.2.5.3.2.1" class="ltx_text" style="font-size:70%;">29882</span></td>
<td id="S4.T2.st2.2.5.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.st2.2.5.3.3.1" class="ltx_text" style="font-size:70%;">59.76</span></td>
<td id="S4.T2.st2.2.5.3.4" class="ltx_td ltx_align_center"><span id="S4.T2.st2.2.5.3.4.1" class="ltx_text" style="font-size:70%;">35795</span></td>
<td id="S4.T2.st2.2.5.3.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.st2.2.5.3.5.1" class="ltx_text" style="font-size:70%;">59.66</span></td>
<td id="S4.T2.st2.2.5.3.6" class="ltx_td ltx_align_center"><span id="S4.T2.st2.2.5.3.6.1" class="ltx_text" style="font-size:70%;">58012</span></td>
<td id="S4.T2.st2.2.5.3.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T2.st2.2.5.3.7.1" class="ltx_text" style="font-size:70%;">58.01</span></td>
</tr>
<tr id="S4.T2.st2.2.6.4" class="ltx_tr">
<th id="S4.T2.st2.2.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r"><span id="S4.T2.st2.2.6.4.1.1" class="ltx_text" style="font-size:70%;">1</span></th>
<td id="S4.T2.st2.2.6.4.2" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T2.st2.2.6.4.2.1" class="ltx_text" style="font-size:70%;">18242</span></td>
<td id="S4.T2.st2.2.6.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T2.st2.2.6.4.3.1" class="ltx_text" style="font-size:70%;">36.48</span></td>
<td id="S4.T2.st2.2.6.4.4" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T2.st2.2.6.4.4.1" class="ltx_text" style="font-size:70%;">21815</span></td>
<td id="S4.T2.st2.2.6.4.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T2.st2.2.6.4.5.1" class="ltx_text" style="font-size:70%;">36.36</span></td>
<td id="S4.T2.st2.2.6.4.6" class="ltx_td ltx_align_center ltx_border_b"><span id="S4.T2.st2.2.6.4.6.1" class="ltx_text" style="font-size:70%;">35393</span></td>
<td id="S4.T2.st2.2.6.4.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T2.st2.2.6.4.7.1" class="ltx_text" style="font-size:70%;">35.39</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.st2.5.1.1" class="ltx_text" style="font-size:129%;">(b)</span> </span><span id="S4.T2.st2.6.2" class="ltx_text" style="font-size:129%;">Linear layer attack leakage rate</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.6.3.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="S4.T2.4.2" class="ltx_text" style="font-size:90%;"> (a) Average PSNR<math id="S4.T2.3.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T2.3.1.m1.1b"><mo stretchy="false" id="S4.T2.3.1.m1.1.1" xref="S4.T2.3.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.3.1.m1.1c"><ci id="S4.T2.3.1.m1.1.1.cmml" xref="S4.T2.3.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.1.m1.1d">\uparrow</annotation></semantics></math> / SSIM<math id="S4.T2.4.2.m2.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S4.T2.4.2.m2.1b"><mo stretchy="false" id="S4.T2.4.2.m2.1.1" xref="S4.T2.4.2.m2.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T2.4.2.m2.1c"><ci id="S4.T2.4.2.m2.1.1.cmml" xref="S4.T2.4.2.m2.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.2.m2.1d">\uparrow</annotation></semantics></math> scores of gradient inversion (Inverting Gradients) reconstructions for various batch sizes and (b) number of leaked images/leakage rate of linear layer leakage attack (LOKI) for several FC layer sizes.</span></figcaption>
</figure>
<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">For GI we use Inverting Gradients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite>, and for LLL we use LOKI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite>. For Inverting Grads, we use a batch size of 4, 8, and 16 on CIFAR-10 and 8, 16 and 32 on MNIST. For LOKI, we choose the FC layer size based on the batch size. We vary this with factors of 1, 2, 4 and 8 on CIFAR-10, MNIST, and Tiny ImageNet. We use a client batch size of 64 for all datasets, so an FC size factor of 2 would mean <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="64\cdot 2=128" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mrow id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml"><mn id="S4.SS2.p1.1.m1.1.1.2.2" xref="S4.SS2.p1.1.m1.1.1.2.2.cmml">64</mn><mo lspace="0.222em" rspace="0.222em" id="S4.SS2.p1.1.m1.1.1.2.1" xref="S4.SS2.p1.1.m1.1.1.2.1.cmml">⋅</mo><mn id="S4.SS2.p1.1.m1.1.1.2.3" xref="S4.SS2.p1.1.m1.1.1.2.3.cmml">2</mn></mrow><mo id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">128</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><eq id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1"></eq><apply id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2"><ci id="S4.SS2.p1.1.m1.1.1.2.1.cmml" xref="S4.SS2.p1.1.m1.1.1.2.1">⋅</ci><cn type="integer" id="S4.SS2.p1.1.m1.1.1.2.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2.2">64</cn><cn type="integer" id="S4.SS2.p1.1.m1.1.1.2.3.cmml" xref="S4.SS2.p1.1.m1.1.1.2.3">2</cn></apply><cn type="integer" id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">128</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">64\cdot 2=128</annotation></semantics></math> units in the FC layer.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Table <a href="#S4.T2.st1" title="Table 2(a) ‣ Table 2 ‣ 4.2 Leakage statistics ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2(a)</span></a> gives the average PSNR and SSIM metrics (where a higher score indicates greater similarity with the ground truth) for the reconstructions across the entire dataset of CIFAR-10 and MNIST from Inverting Gradients. Increasing the batch size results in a lower PSNR and SSIM score for both CIFAR-10 and MNIST.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.4" class="ltx_p">Table <a href="#S4.T2.st2" title="Table 2(b) ‣ Table 2 ‣ 4.2 Leakage statistics ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2(b)</span></a> reports the number of leaked images for LOKI. For an FC factor of <math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mn id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><cn type="integer" id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">4</annotation></semantics></math>, LOKI leaks <math id="S4.SS2.p3.2.m2.1" class="ltx_Math" alttext="78.93\%" display="inline"><semantics id="S4.SS2.p3.2.m2.1a"><mrow id="S4.SS2.p3.2.m2.1.1" xref="S4.SS2.p3.2.m2.1.1.cmml"><mn id="S4.SS2.p3.2.m2.1.1.2" xref="S4.SS2.p3.2.m2.1.1.2.cmml">78.93</mn><mo id="S4.SS2.p3.2.m2.1.1.1" xref="S4.SS2.p3.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.2.m2.1b"><apply id="S4.SS2.p3.2.m2.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1"><csymbol cd="latexml" id="S4.SS2.p3.2.m2.1.1.1.cmml" xref="S4.SS2.p3.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS2.p3.2.m2.1.1.2.cmml" xref="S4.SS2.p3.2.m2.1.1.2">78.93</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.2.m2.1c">78.93\%</annotation></semantics></math>, <math id="S4.SS2.p3.3.m3.1" class="ltx_Math" alttext="76.61\%" display="inline"><semantics id="S4.SS2.p3.3.m3.1a"><mrow id="S4.SS2.p3.3.m3.1.1" xref="S4.SS2.p3.3.m3.1.1.cmml"><mn id="S4.SS2.p3.3.m3.1.1.2" xref="S4.SS2.p3.3.m3.1.1.2.cmml">76.61</mn><mo id="S4.SS2.p3.3.m3.1.1.1" xref="S4.SS2.p3.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.3.m3.1b"><apply id="S4.SS2.p3.3.m3.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1"><csymbol cd="latexml" id="S4.SS2.p3.3.m3.1.1.1.cmml" xref="S4.SS2.p3.3.m3.1.1.1">percent</csymbol><cn type="float" id="S4.SS2.p3.3.m3.1.1.2.cmml" xref="S4.SS2.p3.3.m3.1.1.2">76.61</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.3.m3.1c">76.61\%</annotation></semantics></math>, and <math id="S4.SS2.p3.4.m4.1" class="ltx_Math" alttext="75.15\%" display="inline"><semantics id="S4.SS2.p3.4.m4.1a"><mrow id="S4.SS2.p3.4.m4.1.1" xref="S4.SS2.p3.4.m4.1.1.cmml"><mn id="S4.SS2.p3.4.m4.1.1.2" xref="S4.SS2.p3.4.m4.1.1.2.cmml">75.15</mn><mo id="S4.SS2.p3.4.m4.1.1.1" xref="S4.SS2.p3.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.4.m4.1b"><apply id="S4.SS2.p3.4.m4.1.1.cmml" xref="S4.SS2.p3.4.m4.1.1"><csymbol cd="latexml" id="S4.SS2.p3.4.m4.1.1.1.cmml" xref="S4.SS2.p3.4.m4.1.1.1">percent</csymbol><cn type="float" id="S4.SS2.p3.4.m4.1.1.2.cmml" xref="S4.SS2.p3.4.m4.1.1.2">75.15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.4.m4.1c">75.15\%</annotation></semantics></math> of images on the CIFAR-10, MNIST, and Tiny ImageNet datasets. Increasing the FC layer size increases the model size overhead, but results in a higher leakage rate as images are more likely to activate different neurons. Decreasing the size creates a smaller model size overhead but results in lower leakage rate.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Training on leaked data from scratch</h3>

<figure id="S4.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F2.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.18144/assets/x2.png" id="S4.F2.sf1.g1" class="ltx_graphics ltx_img_landscape" width="228" height="152" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F2.sf1.3.2" class="ltx_text" style="font-size:90%;">CIFAR-10</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F2.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.18144/assets/x3.png" id="S4.F2.sf2.g1" class="ltx_graphics ltx_img_landscape" width="228" height="152" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F2.sf2.3.2" class="ltx_text" style="font-size:90%;">MNIST</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.F2.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.18144/assets/x4.png" id="S4.F2.sf3.g1" class="ltx_graphics ltx_img_landscape" width="228" height="152" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S4.F2.sf3.3.2" class="ltx_text" style="font-size:90%;">Tiny ImageNet</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S4.F2.3.2" class="ltx_text" style="font-size:90%;"> Training models on (a) CIFAR-10, (b) MNIST, and (c) Tiny ImageNet with leaked data compared to centralized and federated learning training. Both linear layer leakage and gradient inversion achieve higher accuracy than the federated learning (FedAvg) baseline for CIFAR-10 in all cases. For MNIST, LLL (LOKI) nearly reaches centralized accuracy while GI performs slightly worse than FL. Top-1 validation accuracy used when training models on Tiny ImageNet. Here, LLL performs better with a FC layer size factor of 2 or higher.</span></figcaption>
</figure>
<figure id="S4.T3" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.T3.st1" class="ltx_table ltx_figure_panel ltx_align_center">
<table id="S4.T3.st1.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.st1.2.1.1" class="ltx_tr">
<th id="S4.T3.st1.2.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S4.T3.st1.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T3.st1.2.1.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.st1.2.1.1.2.1.1" class="ltx_tr">
<td id="S4.T3.st1.2.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.st1.2.1.1.2.1.1.1.1" class="ltx_text" style="font-size:70%;">Num. clients /</span></td>
</tr>
<tr id="S4.T3.st1.2.1.1.2.1.2" class="ltx_tr">
<td id="S4.T3.st1.2.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.st1.2.1.1.2.1.2.1.1" class="ltx_text" style="font-size:70%;">Batch size /</span></td>
</tr>
<tr id="S4.T3.st1.2.1.1.2.1.3" class="ltx_tr">
<td id="S4.T3.st1.2.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.st1.2.1.1.2.1.3.1.1" class="ltx_text" style="font-size:70%;">FC factor</span></td>
</tr>
</table>
</th>
<th id="S4.T3.st1.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T3.st1.2.1.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.st1.2.1.1.3.1.1" class="ltx_tr">
<td id="S4.T3.st1.2.1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.st1.2.1.1.3.1.1.1.1" class="ltx_text" style="font-size:70%;">Test</span></td>
</tr>
<tr id="S4.T3.st1.2.1.1.3.1.2" class="ltx_tr">
<td id="S4.T3.st1.2.1.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.st1.2.1.1.3.1.2.1.1" class="ltx_text" style="font-size:70%;">accuracy</span></td>
</tr>
</table>
</th>
</tr>
<tr id="S4.T3.st1.2.2.2" class="ltx_tr">
<th id="S4.T3.st1.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T3.st1.2.2.2.1.1" class="ltx_text" style="font-size:70%;">Centralized</span></th>
<th id="S4.T3.st1.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.st1.2.2.2.2.1" class="ltx_text" style="font-size:70%;">-</span></th>
<th id="S4.T3.st1.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.st1.2.2.2.3.1" class="ltx_text" style="font-size:70%;">94.38</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.st1.2.3.1" class="ltx_tr">
<td id="S4.T3.st1.2.3.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T3.st1.2.3.1.1.1" class="ltx_text" style="font-size:70%;">FedAvg</span></td>
<td id="S4.T3.st1.2.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.st1.2.3.1.2.1" class="ltx_text" style="font-size:70%;">10</span></td>
<td id="S4.T3.st1.2.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.st1.2.3.1.3.1" class="ltx_text" style="font-size:70%;">72.76</span></td>
</tr>
<tr id="S4.T3.st1.2.4.2" class="ltx_tr">
<td id="S4.T3.st1.2.4.2.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st1.2.4.2.1.1" class="ltx_text" style="font-size:70%;">50</span></td>
<td id="S4.T3.st1.2.4.2.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st1.2.4.2.2.1" class="ltx_text" style="font-size:70%;">68.71</span></td>
</tr>
<tr id="S4.T3.st1.2.5.3" class="ltx_tr">
<td id="S4.T3.st1.2.5.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="3"><span id="S4.T3.st1.2.5.3.1.1" class="ltx_text" style="font-size:70%;">
<span id="S4.T3.st1.2.5.3.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.st1.2.5.3.1.1.1.1" class="ltx_tr">
<span id="S4.T3.st1.2.5.3.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Gradient inversion</span></span>
<span id="S4.T3.st1.2.5.3.1.1.1.2" class="ltx_tr">
<span id="S4.T3.st1.2.5.3.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">(Inverting grads <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite>)</span></span>
</span></span></td>
<td id="S4.T3.st1.2.5.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.st1.2.5.3.2.1" class="ltx_text" style="font-size:70%;">4</span></td>
<td id="S4.T3.st1.2.5.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.st1.2.5.3.3.1" class="ltx_text" style="font-size:70%;">90.34</span></td>
</tr>
<tr id="S4.T3.st1.2.6.4" class="ltx_tr">
<td id="S4.T3.st1.2.6.4.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st1.2.6.4.1.1" class="ltx_text" style="font-size:70%;">8</span></td>
<td id="S4.T3.st1.2.6.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st1.2.6.4.2.1" class="ltx_text" style="font-size:70%;">86.16</span></td>
</tr>
<tr id="S4.T3.st1.2.7.5" class="ltx_tr">
<td id="S4.T3.st1.2.7.5.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st1.2.7.5.1.1" class="ltx_text" style="font-size:70%;">16</span></td>
<td id="S4.T3.st1.2.7.5.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st1.2.7.5.2.1" class="ltx_text" style="font-size:70%;">76.83</span></td>
</tr>
<tr id="S4.T3.st1.2.8.6" class="ltx_tr">
<td id="S4.T3.st1.2.8.6.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" rowspan="4"><span id="S4.T3.st1.2.8.6.1.1" class="ltx_text" style="font-size:70%;">
<span id="S4.T3.st1.2.8.6.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.st1.2.8.6.1.1.1.1" class="ltx_tr">
<span id="S4.T3.st1.2.8.6.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Linear layer leakage</span></span>
<span id="S4.T3.st1.2.8.6.1.1.1.2" class="ltx_tr">
<span id="S4.T3.st1.2.8.6.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">(LOKI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite>)</span></span>
</span></span></td>
<td id="S4.T3.st1.2.8.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.st1.2.8.6.2.1" class="ltx_text ltx_font_bold" style="font-size:70%;">8</span></td>
<td id="S4.T3.st1.2.8.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.st1.2.8.6.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">93.16</span></td>
</tr>
<tr id="S4.T3.st1.2.9.7" class="ltx_tr">
<td id="S4.T3.st1.2.9.7.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st1.2.9.7.1.1" class="ltx_text" style="font-size:70%;">4</span></td>
<td id="S4.T3.st1.2.9.7.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st1.2.9.7.2.1" class="ltx_text" style="font-size:70%;">92.94</span></td>
</tr>
<tr id="S4.T3.st1.2.10.8" class="ltx_tr">
<td id="S4.T3.st1.2.10.8.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st1.2.10.8.1.1" class="ltx_text" style="font-size:70%;">2</span></td>
<td id="S4.T3.st1.2.10.8.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st1.2.10.8.2.1" class="ltx_text" style="font-size:70%;">91.90</span></td>
</tr>
<tr id="S4.T3.st1.2.11.9" class="ltx_tr">
<td id="S4.T3.st1.2.11.9.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T3.st1.2.11.9.1.1" class="ltx_text" style="font-size:70%;">1</span></td>
<td id="S4.T3.st1.2.11.9.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T3.st1.2.11.9.2.1" class="ltx_text" style="font-size:70%;">88.86</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.st1.5.1.1" class="ltx_text" style="font-size:129%;">(a)</span> </span><span id="S4.T3.st1.6.2" class="ltx_text" style="font-size:129%;">CIFAR-10</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.T3.st2" class="ltx_table ltx_figure_panel ltx_align_center">
<table id="S4.T3.st2.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.st2.2.1.1" class="ltx_tr">
<th id="S4.T3.st2.2.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S4.T3.st2.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T3.st2.2.1.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.st2.2.1.1.2.1.1" class="ltx_tr">
<td id="S4.T3.st2.2.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.st2.2.1.1.2.1.1.1.1" class="ltx_text" style="font-size:70%;">Num. clients /</span></td>
</tr>
<tr id="S4.T3.st2.2.1.1.2.1.2" class="ltx_tr">
<td id="S4.T3.st2.2.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.st2.2.1.1.2.1.2.1.1" class="ltx_text" style="font-size:70%;">Batch size /</span></td>
</tr>
<tr id="S4.T3.st2.2.1.1.2.1.3" class="ltx_tr">
<td id="S4.T3.st2.2.1.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.st2.2.1.1.2.1.3.1.1" class="ltx_text" style="font-size:70%;">FC factor</span></td>
</tr>
</table>
</th>
<th id="S4.T3.st2.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T3.st2.2.1.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.st2.2.1.1.3.1.1" class="ltx_tr">
<td id="S4.T3.st2.2.1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.st2.2.1.1.3.1.1.1.1" class="ltx_text" style="font-size:70%;">Test</span></td>
</tr>
<tr id="S4.T3.st2.2.1.1.3.1.2" class="ltx_tr">
<td id="S4.T3.st2.2.1.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.st2.2.1.1.3.1.2.1.1" class="ltx_text" style="font-size:70%;">accuracy</span></td>
</tr>
</table>
</th>
</tr>
<tr id="S4.T3.st2.2.2.2" class="ltx_tr">
<th id="S4.T3.st2.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T3.st2.2.2.2.1.1" class="ltx_text" style="font-size:70%;">Centralized</span></th>
<th id="S4.T3.st2.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.st2.2.2.2.2.1" class="ltx_text" style="font-size:70%;">-</span></th>
<th id="S4.T3.st2.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.st2.2.2.2.3.1" class="ltx_text" style="font-size:70%;">98.89</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.st2.2.3.1" class="ltx_tr">
<td id="S4.T3.st2.2.3.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T3.st2.2.3.1.1.1" class="ltx_text" style="font-size:70%;">FedAvg</span></td>
<td id="S4.T3.st2.2.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.st2.2.3.1.2.1" class="ltx_text" style="font-size:70%;">10</span></td>
<td id="S4.T3.st2.2.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.st2.2.3.1.3.1" class="ltx_text" style="font-size:70%;">96.17</span></td>
</tr>
<tr id="S4.T3.st2.2.4.2" class="ltx_tr">
<td id="S4.T3.st2.2.4.2.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st2.2.4.2.1.1" class="ltx_text" style="font-size:70%;">50</span></td>
<td id="S4.T3.st2.2.4.2.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st2.2.4.2.2.1" class="ltx_text" style="font-size:70%;">96.18</span></td>
</tr>
<tr id="S4.T3.st2.2.5.3" class="ltx_tr">
<td id="S4.T3.st2.2.5.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="3"><span id="S4.T3.st2.2.5.3.1.1" class="ltx_text" style="font-size:70%;">
<span id="S4.T3.st2.2.5.3.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.st2.2.5.3.1.1.1.1" class="ltx_tr">
<span id="S4.T3.st2.2.5.3.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Gradient inversion</span></span>
<span id="S4.T3.st2.2.5.3.1.1.1.2" class="ltx_tr">
<span id="S4.T3.st2.2.5.3.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">(Inverting grads <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite>)</span></span>
</span></span></td>
<td id="S4.T3.st2.2.5.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.st2.2.5.3.2.1" class="ltx_text" style="font-size:70%;">8</span></td>
<td id="S4.T3.st2.2.5.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.st2.2.5.3.3.1" class="ltx_text" style="font-size:70%;">95.96</span></td>
</tr>
<tr id="S4.T3.st2.2.6.4" class="ltx_tr">
<td id="S4.T3.st2.2.6.4.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st2.2.6.4.1.1" class="ltx_text" style="font-size:70%;">16</span></td>
<td id="S4.T3.st2.2.6.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st2.2.6.4.2.1" class="ltx_text" style="font-size:70%;">95.50</span></td>
</tr>
<tr id="S4.T3.st2.2.7.5" class="ltx_tr">
<td id="S4.T3.st2.2.7.5.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st2.2.7.5.1.1" class="ltx_text" style="font-size:70%;">32</span></td>
<td id="S4.T3.st2.2.7.5.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st2.2.7.5.2.1" class="ltx_text" style="font-size:70%;">94.29</span></td>
</tr>
<tr id="S4.T3.st2.2.8.6" class="ltx_tr">
<td id="S4.T3.st2.2.8.6.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" rowspan="4"><span id="S4.T3.st2.2.8.6.1.1" class="ltx_text" style="font-size:70%;">
<span id="S4.T3.st2.2.8.6.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.st2.2.8.6.1.1.1.1" class="ltx_tr">
<span id="S4.T3.st2.2.8.6.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Linear layer leakage</span></span>
<span id="S4.T3.st2.2.8.6.1.1.1.2" class="ltx_tr">
<span id="S4.T3.st2.2.8.6.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">(LOKI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite>)</span></span>
</span></span></td>
<td id="S4.T3.st2.2.8.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.st2.2.8.6.2.1" class="ltx_text ltx_font_bold" style="font-size:70%;">8</span></td>
<td id="S4.T3.st2.2.8.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.st2.2.8.6.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">98.82</span></td>
</tr>
<tr id="S4.T3.st2.2.9.7" class="ltx_tr">
<td id="S4.T3.st2.2.9.7.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st2.2.9.7.1.1" class="ltx_text" style="font-size:70%;">4</span></td>
<td id="S4.T3.st2.2.9.7.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st2.2.9.7.2.1" class="ltx_text" style="font-size:70%;">98.70</span></td>
</tr>
<tr id="S4.T3.st2.2.10.8" class="ltx_tr">
<td id="S4.T3.st2.2.10.8.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st2.2.10.8.1.1" class="ltx_text" style="font-size:70%;">2</span></td>
<td id="S4.T3.st2.2.10.8.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st2.2.10.8.2.1" class="ltx_text" style="font-size:70%;">98.72</span></td>
</tr>
<tr id="S4.T3.st2.2.11.9" class="ltx_tr">
<td id="S4.T3.st2.2.11.9.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T3.st2.2.11.9.1.1" class="ltx_text" style="font-size:70%;">1</span></td>
<td id="S4.T3.st2.2.11.9.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T3.st2.2.11.9.2.1" class="ltx_text" style="font-size:70%;">98.46</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.st2.5.1.1" class="ltx_text" style="font-size:129%;">(b)</span> </span><span id="S4.T3.st2.6.2" class="ltx_text" style="font-size:129%;">MNIST</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S4.T3.st3" class="ltx_table ltx_figure_panel ltx_align_center">
<table id="S4.T3.st3.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.st3.2.1.1" class="ltx_tr">
<th id="S4.T3.st3.2.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S4.T3.st3.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T3.st3.2.1.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.st3.2.1.1.2.1.1" class="ltx_tr">
<td id="S4.T3.st3.2.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.st3.2.1.1.2.1.1.1.1" class="ltx_text" style="font-size:70%;">Num. clients /</span></td>
</tr>
<tr id="S4.T3.st3.2.1.1.2.1.2" class="ltx_tr">
<td id="S4.T3.st3.2.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.st3.2.1.1.2.1.2.1.1" class="ltx_text" style="font-size:70%;">FC factor</span></td>
</tr>
</table>
</th>
<th id="S4.T3.st3.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T3.st3.2.1.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T3.st3.2.1.1.3.1.1" class="ltx_tr">
<td id="S4.T3.st3.2.1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.st3.2.1.1.3.1.1.1.1" class="ltx_text" style="font-size:70%;">Validation</span></td>
</tr>
<tr id="S4.T3.st3.2.1.1.3.1.2" class="ltx_tr">
<td id="S4.T3.st3.2.1.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T3.st3.2.1.1.3.1.2.1.1" class="ltx_text" style="font-size:70%;">accuracy</span></td>
</tr>
</table>
</th>
</tr>
<tr id="S4.T3.st3.2.2.2" class="ltx_tr">
<th id="S4.T3.st3.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T3.st3.2.2.2.1.1" class="ltx_text" style="font-size:70%;">Centralized</span></th>
<th id="S4.T3.st3.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.st3.2.2.2.2.1" class="ltx_text" style="font-size:70%;">-</span></th>
<th id="S4.T3.st3.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.st3.2.2.2.3.1" class="ltx_text" style="font-size:70%;">48.55</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.st3.2.3.1" class="ltx_tr">
<th id="S4.T3.st3.2.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T3.st3.2.3.1.1.1" class="ltx_text" style="font-size:70%;">FedAvg</span></th>
<td id="S4.T3.st3.2.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.st3.2.3.1.2.1" class="ltx_text" style="font-size:70%;">10</span></td>
<td id="S4.T3.st3.2.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.st3.2.3.1.3.1" class="ltx_text" style="font-size:70%;">37.00</span></td>
</tr>
<tr id="S4.T3.st3.2.4.2" class="ltx_tr">
<td id="S4.T3.st3.2.4.2.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st3.2.4.2.1.1" class="ltx_text" style="font-size:70%;">50</span></td>
<td id="S4.T3.st3.2.4.2.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st3.2.4.2.2.1" class="ltx_text" style="font-size:70%;">35.06</span></td>
</tr>
<tr id="S4.T3.st3.2.5.3" class="ltx_tr">
<th id="S4.T3.st3.2.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" rowspan="4"><span id="S4.T3.st3.2.5.3.1.1" class="ltx_text" style="font-size:70%;">
<span id="S4.T3.st3.2.5.3.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T3.st3.2.5.3.1.1.1.1" class="ltx_tr">
<span id="S4.T3.st3.2.5.3.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Linear layer leakage</span></span>
<span id="S4.T3.st3.2.5.3.1.1.1.2" class="ltx_tr">
<span id="S4.T3.st3.2.5.3.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">(LOKI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite>)</span></span>
</span></span></th>
<td id="S4.T3.st3.2.5.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.st3.2.5.3.2.1" class="ltx_text ltx_font_bold" style="font-size:70%;">8</span></td>
<td id="S4.T3.st3.2.5.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T3.st3.2.5.3.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">46.70</span></td>
</tr>
<tr id="S4.T3.st3.2.6.4" class="ltx_tr">
<td id="S4.T3.st3.2.6.4.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st3.2.6.4.1.1" class="ltx_text" style="font-size:70%;">4</span></td>
<td id="S4.T3.st3.2.6.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st3.2.6.4.2.1" class="ltx_text" style="font-size:70%;">45.09</span></td>
</tr>
<tr id="S4.T3.st3.2.7.5" class="ltx_tr">
<td id="S4.T3.st3.2.7.5.1" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st3.2.7.5.1.1" class="ltx_text" style="font-size:70%;">2</span></td>
<td id="S4.T3.st3.2.7.5.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T3.st3.2.7.5.2.1" class="ltx_text" style="font-size:70%;">41.15</span></td>
</tr>
<tr id="S4.T3.st3.2.8.6" class="ltx_tr">
<td id="S4.T3.st3.2.8.6.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T3.st3.2.8.6.1.1" class="ltx_text" style="font-size:70%;">1</span></td>
<td id="S4.T3.st3.2.8.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T3.st3.2.8.6.2.1" class="ltx_text" style="font-size:70%;">35.20</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.st3.5.1.1" class="ltx_text" style="font-size:129%;">(c)</span> </span><span id="S4.T3.st3.6.2" class="ltx_text" style="font-size:129%;">Tiny ImageNet</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.2.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="S4.T3.3.2" class="ltx_text" style="font-size:90%;"> (a) CIFAR-10 and (b) MNIST test accuracy, (c) Tiny ImageNet top-1 validation accuracy trained from scratch with leaked data. CIFAR-10 and Tiny ImageNet are trained with a ResNet-18 and MNIST is trained with a DNN. For the two attacks (gradient inversion and linear layer leakage), training happens with leaked data. Second column indicates the number of clients in federated learning (FedAvg), the batch size for the gradient inversion attack, and the fully-connected layer size factor for linear layer leakage. Best accuracy is used for FedAvg and final accuracy for all other settings.</span></figcaption>
</figure>
<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">We start with a discussion on the models that can be trained from the leaked data of both GI and LLL attacks. The attacks are applied under the FedSGD setting. We also start with assuming that <span id="S4.SS3.p1.1.1" class="ltx_text ltx_font_italic">all</span> labels are known prior to training — this is a best case assumption for the downstream training. For CIFAR-10, we train the centralized models using SGD with momentum 0.9 and weight decay 0.0001. We use a batch size of 128 and train for 200 epochs starting with a initial learning rate of 0.1 and a scheduler that decreases on plateau. For MNIST, we use SGD without momentum or weight decay and train for 40 epochs with a LR of 0.01. For Tiny ImageNet we use Adam with learning rate 0.001 and train for 50 epochs with a batch size of 1024. For federated learning, we use 400 training rounds for CIFAR-10 and MNIST and 500 rounds for Tiny ImageNet. Client batch size of 32, 128, and 256 are used for MNIST, CIFAR-10, and Tiny ImageNet. The test accuracy is downsampled to fit on the same axis with centralized training.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.10" class="ltx_p">Table <a href="#S4.T3.st1" title="Table 3(a) ‣ Table 3 ‣ 4.3 Training on leaked data from scratch ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a> and Figure <a href="#S4.F2.sf1" title="Figure 2(a) ‣ Figure 2 ‣ 4.3 Training on leaked data from scratch ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2(a)</span></a> show the results for CIFAR-10 for centralized training, federated learning (FedAvg), and training with leaked data. Centralized training achieves a <math id="S4.SS3.p2.1.m1.1" class="ltx_Math" alttext="94.38\%" display="inline"><semantics id="S4.SS3.p2.1.m1.1a"><mrow id="S4.SS3.p2.1.m1.1.1" xref="S4.SS3.p2.1.m1.1.1.cmml"><mn id="S4.SS3.p2.1.m1.1.1.2" xref="S4.SS3.p2.1.m1.1.1.2.cmml">94.38</mn><mo id="S4.SS3.p2.1.m1.1.1.1" xref="S4.SS3.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.1.m1.1b"><apply id="S4.SS3.p2.1.m1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1"><csymbol cd="latexml" id="S4.SS3.p2.1.m1.1.1.1.cmml" xref="S4.SS3.p2.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p2.1.m1.1.1.2.cmml" xref="S4.SS3.p2.1.m1.1.1.2">94.38</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.1.m1.1c">94.38\%</annotation></semantics></math> accuracy and federated learning achieves a <math id="S4.SS3.p2.2.m2.1" class="ltx_Math" alttext="72.76\%" display="inline"><semantics id="S4.SS3.p2.2.m2.1a"><mrow id="S4.SS3.p2.2.m2.1.1" xref="S4.SS3.p2.2.m2.1.1.cmml"><mn id="S4.SS3.p2.2.m2.1.1.2" xref="S4.SS3.p2.2.m2.1.1.2.cmml">72.76</mn><mo id="S4.SS3.p2.2.m2.1.1.1" xref="S4.SS3.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.2.m2.1b"><apply id="S4.SS3.p2.2.m2.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1"><csymbol cd="latexml" id="S4.SS3.p2.2.m2.1.1.1.cmml" xref="S4.SS3.p2.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p2.2.m2.1.1.2.cmml" xref="S4.SS3.p2.2.m2.1.1.2">72.76</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.2.m2.1c">72.76\%</annotation></semantics></math> and <math id="S4.SS3.p2.3.m3.1" class="ltx_Math" alttext="68.71\%" display="inline"><semantics id="S4.SS3.p2.3.m3.1a"><mrow id="S4.SS3.p2.3.m3.1.1" xref="S4.SS3.p2.3.m3.1.1.cmml"><mn id="S4.SS3.p2.3.m3.1.1.2" xref="S4.SS3.p2.3.m3.1.1.2.cmml">68.71</mn><mo id="S4.SS3.p2.3.m3.1.1.1" xref="S4.SS3.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.3.m3.1b"><apply id="S4.SS3.p2.3.m3.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1"><csymbol cd="latexml" id="S4.SS3.p2.3.m3.1.1.1.cmml" xref="S4.SS3.p2.3.m3.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p2.3.m3.1.1.2.cmml" xref="S4.SS3.p2.3.m3.1.1.2">68.71</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.3.m3.1c">68.71\%</annotation></semantics></math> peak accuracy with 10 and 50 clients respectively. Centralized and FL indeed provide the upper bound and the lower bound of the accuracy here. Across all attack settings, GI and LLL achieve higher model accuracy compared to federated learning. The reconstruction quality of GI is adversely affected by larger batch sizes and in turn also impacts the final model performance. With a batch size of 4, 8, and 16, models trained on the leaked data from GI achieves <math id="S4.SS3.p2.4.m4.1" class="ltx_Math" alttext="90.34\%" display="inline"><semantics id="S4.SS3.p2.4.m4.1a"><mrow id="S4.SS3.p2.4.m4.1.1" xref="S4.SS3.p2.4.m4.1.1.cmml"><mn id="S4.SS3.p2.4.m4.1.1.2" xref="S4.SS3.p2.4.m4.1.1.2.cmml">90.34</mn><mo id="S4.SS3.p2.4.m4.1.1.1" xref="S4.SS3.p2.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.4.m4.1b"><apply id="S4.SS3.p2.4.m4.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1"><csymbol cd="latexml" id="S4.SS3.p2.4.m4.1.1.1.cmml" xref="S4.SS3.p2.4.m4.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p2.4.m4.1.1.2.cmml" xref="S4.SS3.p2.4.m4.1.1.2">90.34</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.4.m4.1c">90.34\%</annotation></semantics></math>, <math id="S4.SS3.p2.5.m5.1" class="ltx_Math" alttext="86.16\%" display="inline"><semantics id="S4.SS3.p2.5.m5.1a"><mrow id="S4.SS3.p2.5.m5.1.1" xref="S4.SS3.p2.5.m5.1.1.cmml"><mn id="S4.SS3.p2.5.m5.1.1.2" xref="S4.SS3.p2.5.m5.1.1.2.cmml">86.16</mn><mo id="S4.SS3.p2.5.m5.1.1.1" xref="S4.SS3.p2.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.5.m5.1b"><apply id="S4.SS3.p2.5.m5.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1"><csymbol cd="latexml" id="S4.SS3.p2.5.m5.1.1.1.cmml" xref="S4.SS3.p2.5.m5.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p2.5.m5.1.1.2.cmml" xref="S4.SS3.p2.5.m5.1.1.2">86.16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.5.m5.1c">86.16\%</annotation></semantics></math>, and <math id="S4.SS3.p2.6.m6.1" class="ltx_Math" alttext="76.83\%" display="inline"><semantics id="S4.SS3.p2.6.m6.1a"><mrow id="S4.SS3.p2.6.m6.1.1" xref="S4.SS3.p2.6.m6.1.1.cmml"><mn id="S4.SS3.p2.6.m6.1.1.2" xref="S4.SS3.p2.6.m6.1.1.2.cmml">76.83</mn><mo id="S4.SS3.p2.6.m6.1.1.1" xref="S4.SS3.p2.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.6.m6.1b"><apply id="S4.SS3.p2.6.m6.1.1.cmml" xref="S4.SS3.p2.6.m6.1.1"><csymbol cd="latexml" id="S4.SS3.p2.6.m6.1.1.1.cmml" xref="S4.SS3.p2.6.m6.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p2.6.m6.1.1.2.cmml" xref="S4.SS3.p2.6.m6.1.1.2">76.83</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.6.m6.1c">76.83\%</annotation></semantics></math> accuracy. With even larger batch sizes, it is likely that the model performance will drop below federated learning. The performance of models using LLL data is more stable. Between an FC layer size of 512 (factor 8) and 64 (factor 1), the accuracy only drops from <math id="S4.SS3.p2.7.m7.1" class="ltx_Math" alttext="93.16\%" display="inline"><semantics id="S4.SS3.p2.7.m7.1a"><mrow id="S4.SS3.p2.7.m7.1.1" xref="S4.SS3.p2.7.m7.1.1.cmml"><mn id="S4.SS3.p2.7.m7.1.1.2" xref="S4.SS3.p2.7.m7.1.1.2.cmml">93.16</mn><mo id="S4.SS3.p2.7.m7.1.1.1" xref="S4.SS3.p2.7.m7.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.7.m7.1b"><apply id="S4.SS3.p2.7.m7.1.1.cmml" xref="S4.SS3.p2.7.m7.1.1"><csymbol cd="latexml" id="S4.SS3.p2.7.m7.1.1.1.cmml" xref="S4.SS3.p2.7.m7.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p2.7.m7.1.1.2.cmml" xref="S4.SS3.p2.7.m7.1.1.2">93.16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.7.m7.1c">93.16\%</annotation></semantics></math> to <math id="S4.SS3.p2.8.m8.1" class="ltx_Math" alttext="88.86\%" display="inline"><semantics id="S4.SS3.p2.8.m8.1a"><mrow id="S4.SS3.p2.8.m8.1.1" xref="S4.SS3.p2.8.m8.1.1.cmml"><mn id="S4.SS3.p2.8.m8.1.1.2" xref="S4.SS3.p2.8.m8.1.1.2.cmml">88.86</mn><mo id="S4.SS3.p2.8.m8.1.1.1" xref="S4.SS3.p2.8.m8.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.8.m8.1b"><apply id="S4.SS3.p2.8.m8.1.1.cmml" xref="S4.SS3.p2.8.m8.1.1"><csymbol cd="latexml" id="S4.SS3.p2.8.m8.1.1.1.cmml" xref="S4.SS3.p2.8.m8.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p2.8.m8.1.1.2.cmml" xref="S4.SS3.p2.8.m8.1.1.2">88.86</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.8.m8.1c">88.86\%</annotation></semantics></math>. This is spite of a large drop in the number of leaked images from 43788 (<math id="S4.SS3.p2.9.m9.1" class="ltx_Math" alttext="87.58\%" display="inline"><semantics id="S4.SS3.p2.9.m9.1a"><mrow id="S4.SS3.p2.9.m9.1.1" xref="S4.SS3.p2.9.m9.1.1.cmml"><mn id="S4.SS3.p2.9.m9.1.1.2" xref="S4.SS3.p2.9.m9.1.1.2.cmml">87.58</mn><mo id="S4.SS3.p2.9.m9.1.1.1" xref="S4.SS3.p2.9.m9.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.9.m9.1b"><apply id="S4.SS3.p2.9.m9.1.1.cmml" xref="S4.SS3.p2.9.m9.1.1"><csymbol cd="latexml" id="S4.SS3.p2.9.m9.1.1.1.cmml" xref="S4.SS3.p2.9.m9.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p2.9.m9.1.1.2.cmml" xref="S4.SS3.p2.9.m9.1.1.2">87.58</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.9.m9.1c">87.58\%</annotation></semantics></math>) to 18242 (<math id="S4.SS3.p2.10.m10.1" class="ltx_Math" alttext="36.48\%" display="inline"><semantics id="S4.SS3.p2.10.m10.1a"><mrow id="S4.SS3.p2.10.m10.1.1" xref="S4.SS3.p2.10.m10.1.1.cmml"><mn id="S4.SS3.p2.10.m10.1.1.2" xref="S4.SS3.p2.10.m10.1.1.2.cmml">36.48</mn><mo id="S4.SS3.p2.10.m10.1.1.1" xref="S4.SS3.p2.10.m10.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p2.10.m10.1b"><apply id="S4.SS3.p2.10.m10.1.1.cmml" xref="S4.SS3.p2.10.m10.1.1"><csymbol cd="latexml" id="S4.SS3.p2.10.m10.1.1.1.cmml" xref="S4.SS3.p2.10.m10.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p2.10.m10.1.1.2.cmml" xref="S4.SS3.p2.10.m10.1.1.2">36.48</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p2.10.m10.1c">36.48\%</annotation></semantics></math>) as shown in Table <a href="#S4.T2.st2" title="Table 2(b) ‣ Table 2 ‣ 4.2 Leakage statistics ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2(b)</span></a>. This is a subtle and consequential result — the downstream training task can still be accomplished despite a big drop in the amount of data leakage. All prior work had stopped at the stage of evaluating the proportion of leakage and therefore had missed out on this insight.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.8" class="ltx_p">Table <a href="#S4.T3.st2" title="Table 3(b) ‣ Table 3 ‣ 4.3 Training on leaked data from scratch ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a> and Figure <a href="#S4.F2.sf2" title="Figure 2(b) ‣ Figure 2 ‣ 4.3 Training on leaked data from scratch ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2(b)</span></a> show the results for MNIST. LLL performs better than the FedAvg baseline in all cases. With an FC size factor of 8, LOKI achieves a <math id="S4.SS3.p3.1.m1.1" class="ltx_Math" alttext="98.82\%" display="inline"><semantics id="S4.SS3.p3.1.m1.1a"><mrow id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml"><mn id="S4.SS3.p3.1.m1.1.1.2" xref="S4.SS3.p3.1.m1.1.1.2.cmml">98.82</mn><mo id="S4.SS3.p3.1.m1.1.1.1" xref="S4.SS3.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><apply id="S4.SS3.p3.1.m1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1"><csymbol cd="latexml" id="S4.SS3.p3.1.m1.1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p3.1.m1.1.1.2.cmml" xref="S4.SS3.p3.1.m1.1.1.2">98.82</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">98.82\%</annotation></semantics></math> test accuracy (nearly the same regardless of the FC size factor), only <math id="S4.SS3.p3.2.m2.1" class="ltx_Math" alttext="0.07\%" display="inline"><semantics id="S4.SS3.p3.2.m2.1a"><mrow id="S4.SS3.p3.2.m2.1.1" xref="S4.SS3.p3.2.m2.1.1.cmml"><mn id="S4.SS3.p3.2.m2.1.1.2" xref="S4.SS3.p3.2.m2.1.1.2.cmml">0.07</mn><mo id="S4.SS3.p3.2.m2.1.1.1" xref="S4.SS3.p3.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.2.m2.1b"><apply id="S4.SS3.p3.2.m2.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1"><csymbol cd="latexml" id="S4.SS3.p3.2.m2.1.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p3.2.m2.1.1.2.cmml" xref="S4.SS3.p3.2.m2.1.1.2">0.07</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.2.m2.1c">0.07\%</annotation></semantics></math> lower than centralized at <math id="S4.SS3.p3.3.m3.1" class="ltx_Math" alttext="98.89\%" display="inline"><semantics id="S4.SS3.p3.3.m3.1a"><mrow id="S4.SS3.p3.3.m3.1.1" xref="S4.SS3.p3.3.m3.1.1.cmml"><mn id="S4.SS3.p3.3.m3.1.1.2" xref="S4.SS3.p3.3.m3.1.1.2.cmml">98.89</mn><mo id="S4.SS3.p3.3.m3.1.1.1" xref="S4.SS3.p3.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.3.m3.1b"><apply id="S4.SS3.p3.3.m3.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1"><csymbol cd="latexml" id="S4.SS3.p3.3.m3.1.1.1.cmml" xref="S4.SS3.p3.3.m3.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p3.3.m3.1.1.2.cmml" xref="S4.SS3.p3.3.m3.1.1.2">98.89</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.3.m3.1c">98.89\%</annotation></semantics></math>. GI performs slightly <span id="S4.SS3.p3.8.1" class="ltx_text ltx_font_italic">worse</span> than federated learning, achieving <math id="S4.SS3.p3.4.m4.1" class="ltx_Math" alttext="95.96\%" display="inline"><semantics id="S4.SS3.p3.4.m4.1a"><mrow id="S4.SS3.p3.4.m4.1.1" xref="S4.SS3.p3.4.m4.1.1.cmml"><mn id="S4.SS3.p3.4.m4.1.1.2" xref="S4.SS3.p3.4.m4.1.1.2.cmml">95.96</mn><mo id="S4.SS3.p3.4.m4.1.1.1" xref="S4.SS3.p3.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.4.m4.1b"><apply id="S4.SS3.p3.4.m4.1.1.cmml" xref="S4.SS3.p3.4.m4.1.1"><csymbol cd="latexml" id="S4.SS3.p3.4.m4.1.1.1.cmml" xref="S4.SS3.p3.4.m4.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p3.4.m4.1.1.2.cmml" xref="S4.SS3.p3.4.m4.1.1.2">95.96</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.4.m4.1c">95.96\%</annotation></semantics></math>, <math id="S4.SS3.p3.5.m5.1" class="ltx_Math" alttext="95.50\%" display="inline"><semantics id="S4.SS3.p3.5.m5.1a"><mrow id="S4.SS3.p3.5.m5.1.1" xref="S4.SS3.p3.5.m5.1.1.cmml"><mn id="S4.SS3.p3.5.m5.1.1.2" xref="S4.SS3.p3.5.m5.1.1.2.cmml">95.50</mn><mo id="S4.SS3.p3.5.m5.1.1.1" xref="S4.SS3.p3.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.5.m5.1b"><apply id="S4.SS3.p3.5.m5.1.1.cmml" xref="S4.SS3.p3.5.m5.1.1"><csymbol cd="latexml" id="S4.SS3.p3.5.m5.1.1.1.cmml" xref="S4.SS3.p3.5.m5.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p3.5.m5.1.1.2.cmml" xref="S4.SS3.p3.5.m5.1.1.2">95.50</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.5.m5.1c">95.50\%</annotation></semantics></math>, and <math id="S4.SS3.p3.6.m6.1" class="ltx_Math" alttext="94.29\%" display="inline"><semantics id="S4.SS3.p3.6.m6.1a"><mrow id="S4.SS3.p3.6.m6.1.1" xref="S4.SS3.p3.6.m6.1.1.cmml"><mn id="S4.SS3.p3.6.m6.1.1.2" xref="S4.SS3.p3.6.m6.1.1.2.cmml">94.29</mn><mo id="S4.SS3.p3.6.m6.1.1.1" xref="S4.SS3.p3.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.6.m6.1b"><apply id="S4.SS3.p3.6.m6.1.1.cmml" xref="S4.SS3.p3.6.m6.1.1"><csymbol cd="latexml" id="S4.SS3.p3.6.m6.1.1.1.cmml" xref="S4.SS3.p3.6.m6.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p3.6.m6.1.1.2.cmml" xref="S4.SS3.p3.6.m6.1.1.2">94.29</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.6.m6.1c">94.29\%</annotation></semantics></math> at batch sizes 8, 16, and 32 compared to <math id="S4.SS3.p3.7.m7.1" class="ltx_Math" alttext="96.17\%" display="inline"><semantics id="S4.SS3.p3.7.m7.1a"><mrow id="S4.SS3.p3.7.m7.1.1" xref="S4.SS3.p3.7.m7.1.1.cmml"><mn id="S4.SS3.p3.7.m7.1.1.2" xref="S4.SS3.p3.7.m7.1.1.2.cmml">96.17</mn><mo id="S4.SS3.p3.7.m7.1.1.1" xref="S4.SS3.p3.7.m7.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.7.m7.1b"><apply id="S4.SS3.p3.7.m7.1.1.cmml" xref="S4.SS3.p3.7.m7.1.1"><csymbol cd="latexml" id="S4.SS3.p3.7.m7.1.1.1.cmml" xref="S4.SS3.p3.7.m7.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p3.7.m7.1.1.2.cmml" xref="S4.SS3.p3.7.m7.1.1.2">96.17</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.7.m7.1c">96.17\%</annotation></semantics></math> and <math id="S4.SS3.p3.8.m8.1" class="ltx_Math" alttext="96.18\%" display="inline"><semantics id="S4.SS3.p3.8.m8.1a"><mrow id="S4.SS3.p3.8.m8.1.1" xref="S4.SS3.p3.8.m8.1.1.cmml"><mn id="S4.SS3.p3.8.m8.1.1.2" xref="S4.SS3.p3.8.m8.1.1.2.cmml">96.18</mn><mo id="S4.SS3.p3.8.m8.1.1.1" xref="S4.SS3.p3.8.m8.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.8.m8.1b"><apply id="S4.SS3.p3.8.m8.1.1.cmml" xref="S4.SS3.p3.8.m8.1.1"><csymbol cd="latexml" id="S4.SS3.p3.8.m8.1.1.1.cmml" xref="S4.SS3.p3.8.m8.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p3.8.m8.1.1.2.cmml" xref="S4.SS3.p3.8.m8.1.1.2">96.18</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.8.m8.1c">96.18\%</annotation></semantics></math> with 10 and 50 clients in FedAvg. We believe this is because the noise in the reconstructions hampers model performance with GI. This affects MNIST more severely than for CIFAR because the MNIST images are more sparse and sensitive to noise.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.5" class="ltx_p">The top-1 validation accuracy for Tiny ImageNet are given in Table <a href="#S4.T3.st3" title="Table 3(c) ‣ Table 3 ‣ 4.3 Training on leaked data from scratch ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(c)</span></a> and Figure <a href="#S4.F2.sf3" title="Figure 2(c) ‣ Figure 2 ‣ 4.3 Training on leaked data from scratch ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2(c)</span></a>. The total number of leaked images hurts LLL more here than in the other two datasets. Between an FC layer size of 512 (factor 8) and 64 (factor 1), the validation accuracy drops from <math id="S4.SS3.p4.1.m1.1" class="ltx_Math" alttext="46.70\%" display="inline"><semantics id="S4.SS3.p4.1.m1.1a"><mrow id="S4.SS3.p4.1.m1.1.1" xref="S4.SS3.p4.1.m1.1.1.cmml"><mn id="S4.SS3.p4.1.m1.1.1.2" xref="S4.SS3.p4.1.m1.1.1.2.cmml">46.70</mn><mo id="S4.SS3.p4.1.m1.1.1.1" xref="S4.SS3.p4.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.1.m1.1b"><apply id="S4.SS3.p4.1.m1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1"><csymbol cd="latexml" id="S4.SS3.p4.1.m1.1.1.1.cmml" xref="S4.SS3.p4.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p4.1.m1.1.1.2.cmml" xref="S4.SS3.p4.1.m1.1.1.2">46.70</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.1.m1.1c">46.70\%</annotation></semantics></math> to <math id="S4.SS3.p4.2.m2.1" class="ltx_Math" alttext="35.20\%" display="inline"><semantics id="S4.SS3.p4.2.m2.1a"><mrow id="S4.SS3.p4.2.m2.1.1" xref="S4.SS3.p4.2.m2.1.1.cmml"><mn id="S4.SS3.p4.2.m2.1.1.2" xref="S4.SS3.p4.2.m2.1.1.2.cmml">35.20</mn><mo id="S4.SS3.p4.2.m2.1.1.1" xref="S4.SS3.p4.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.2.m2.1b"><apply id="S4.SS3.p4.2.m2.1.1.cmml" xref="S4.SS3.p4.2.m2.1.1"><csymbol cd="latexml" id="S4.SS3.p4.2.m2.1.1.1.cmml" xref="S4.SS3.p4.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p4.2.m2.1.1.2.cmml" xref="S4.SS3.p4.2.m2.1.1.2">35.20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.2.m2.1c">35.20\%</annotation></semantics></math>, an <math id="S4.SS3.p4.3.m3.1" class="ltx_Math" alttext="11.5\%" display="inline"><semantics id="S4.SS3.p4.3.m3.1a"><mrow id="S4.SS3.p4.3.m3.1.1" xref="S4.SS3.p4.3.m3.1.1.cmml"><mn id="S4.SS3.p4.3.m3.1.1.2" xref="S4.SS3.p4.3.m3.1.1.2.cmml">11.5</mn><mo id="S4.SS3.p4.3.m3.1.1.1" xref="S4.SS3.p4.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.3.m3.1b"><apply id="S4.SS3.p4.3.m3.1.1.cmml" xref="S4.SS3.p4.3.m3.1.1"><csymbol cd="latexml" id="S4.SS3.p4.3.m3.1.1.1.cmml" xref="S4.SS3.p4.3.m3.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p4.3.m3.1.1.2.cmml" xref="S4.SS3.p4.3.m3.1.1.2">11.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.3.m3.1c">11.5\%</annotation></semantics></math> drop in performance. Federated learning achieves <math id="S4.SS3.p4.4.m4.1" class="ltx_Math" alttext="37.00\%" display="inline"><semantics id="S4.SS3.p4.4.m4.1a"><mrow id="S4.SS3.p4.4.m4.1.1" xref="S4.SS3.p4.4.m4.1.1.cmml"><mn id="S4.SS3.p4.4.m4.1.1.2" xref="S4.SS3.p4.4.m4.1.1.2.cmml">37.00</mn><mo id="S4.SS3.p4.4.m4.1.1.1" xref="S4.SS3.p4.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.4.m4.1b"><apply id="S4.SS3.p4.4.m4.1.1.cmml" xref="S4.SS3.p4.4.m4.1.1"><csymbol cd="latexml" id="S4.SS3.p4.4.m4.1.1.1.cmml" xref="S4.SS3.p4.4.m4.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p4.4.m4.1.1.2.cmml" xref="S4.SS3.p4.4.m4.1.1.2">37.00</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.4.m4.1c">37.00\%</annotation></semantics></math> and <math id="S4.SS3.p4.5.m5.1" class="ltx_Math" alttext="35.06\%" display="inline"><semantics id="S4.SS3.p4.5.m5.1a"><mrow id="S4.SS3.p4.5.m5.1.1" xref="S4.SS3.p4.5.m5.1.1.cmml"><mn id="S4.SS3.p4.5.m5.1.1.2" xref="S4.SS3.p4.5.m5.1.1.2.cmml">35.06</mn><mo id="S4.SS3.p4.5.m5.1.1.1" xref="S4.SS3.p4.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.p4.5.m5.1b"><apply id="S4.SS3.p4.5.m5.1.1.cmml" xref="S4.SS3.p4.5.m5.1.1"><csymbol cd="latexml" id="S4.SS3.p4.5.m5.1.1.1.cmml" xref="S4.SS3.p4.5.m5.1.1.1">percent</csymbol><cn type="float" id="S4.SS3.p4.5.m5.1.1.2.cmml" xref="S4.SS3.p4.5.m5.1.1.2">35.06</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p4.5.m5.1c">35.06\%</annotation></semantics></math> accuracy with 10 and 50 clients respectively. FL with 10 clients has slightly better accuracy than LLL with an FC size factor of 1. However, any LLL setting with a larger FC layer achieves higher accuracy than both settings in federated learning.</p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>FedAvg with leaked images from LOKI</h3>

<figure id="S4.T4" class="ltx_table">
<table id="S4.T4.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T4.4.1.1" class="ltx_tr">
<th id="S4.T4.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t">
<table id="S4.T4.4.1.1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.4.1.1.1.1.1" class="ltx_tr">
<td id="S4.T4.4.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S4.T4.4.1.1.1.1.1.1.1" class="ltx_text" style="font-size:70%;">FC size</span></td>
</tr>
<tr id="S4.T4.4.1.1.1.1.2" class="ltx_tr">
<td id="S4.T4.4.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S4.T4.4.1.1.1.1.2.1.1" class="ltx_text" style="font-size:70%;">factor</span></td>
</tr>
</table>
</th>
<th id="S4.T4.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T4.4.1.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.4.1.1.2.1.1" class="ltx_tr">
<td id="S4.T4.4.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T4.4.1.1.2.1.1.1.1" class="ltx_text" style="font-size:70%;">LOKI</span></td>
</tr>
<tr id="S4.T4.4.1.1.2.1.2" class="ltx_tr">
<td id="S4.T4.4.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T4.4.1.1.2.1.2.1.1" class="ltx_text" style="font-size:70%;">FedSGD</span></td>
</tr>
</table>
</th>
<th id="S4.T4.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T4.4.1.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T4.4.1.1.3.1.1" class="ltx_tr">
<td id="S4.T4.4.1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T4.4.1.1.3.1.1.1.1" class="ltx_text" style="font-size:70%;">LOKI</span></td>
</tr>
<tr id="S4.T4.4.1.1.3.1.2" class="ltx_tr">
<td id="S4.T4.4.1.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T4.4.1.1.3.1.2.1.1" class="ltx_text" style="font-size:70%;">FedAvg</span></td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T4.4.2.1" class="ltx_tr">
<th id="S4.T4.4.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T4.4.2.1.1.1" class="ltx_text" style="font-size:70%;">8</span></th>
<td id="S4.T4.4.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.4.2.1.2.1" class="ltx_text" style="font-size:70%;">87.58 (43788)</span></td>
<td id="S4.T4.4.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.4.2.1.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">92.19 (46097)</span></td>
</tr>
<tr id="S4.T4.4.3.2" class="ltx_tr">
<th id="S4.T4.4.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span id="S4.T4.4.3.2.1.1" class="ltx_text" style="font-size:70%;">4</span></th>
<td id="S4.T4.4.3.2.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T4.4.3.2.2.1" class="ltx_text" style="font-size:70%;">78.93 (39464)</span></td>
<td id="S4.T4.4.3.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T4.4.3.2.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">85.98 (42989)</span></td>
</tr>
<tr id="S4.T4.4.4.3" class="ltx_tr">
<th id="S4.T4.4.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><span id="S4.T4.4.4.3.1.1" class="ltx_text" style="font-size:70%;">2</span></th>
<td id="S4.T4.4.4.3.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T4.4.4.3.2.1" class="ltx_text" style="font-size:70%;">59.76 (29882)</span></td>
<td id="S4.T4.4.4.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T4.4.4.3.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">75.29 (37645)</span></td>
</tr>
<tr id="S4.T4.4.5.4" class="ltx_tr">
<th id="S4.T4.4.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r"><span id="S4.T4.4.5.4.1.1" class="ltx_text" style="font-size:70%;">1</span></th>
<td id="S4.T4.4.5.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T4.4.5.4.2.1" class="ltx_text" style="font-size:70%;">36.48 (18242)</span></td>
<td id="S4.T4.4.5.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T4.4.5.4.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">58.39 (29196)</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.8.2.1" class="ltx_text" style="font-size:129%;">Table 4</span>: </span><span id="S4.T4.2.1" class="ltx_text" style="font-size:129%;"> Leakage rate <math id="S4.T4.2.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S4.T4.2.1.m1.1b"><mo id="S4.T4.2.1.m1.1.1" xref="S4.T4.2.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S4.T4.2.1.m1.1c"><csymbol cd="latexml" id="S4.T4.2.1.m1.1.1.cmml" xref="S4.T4.2.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.1.m1.1d">\%</annotation></semantics></math> (leaked images) of LOKI in FedSGD and FedAvg on CIFAR-10 for several FC layer sizes. FedAvg with half the FC layer size has comparable leakage rate to FedSGD.</span></figcaption>
</figure>
<figure id="S4.T5" class="ltx_table">
<table id="S4.T5.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T5.2.1.1" class="ltx_tr">
<th id="S4.T5.2.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S4.T5.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">
<table id="S4.T5.2.1.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T5.2.1.1.2.1.1" class="ltx_tr">
<td id="S4.T5.2.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T5.2.1.1.2.1.1.1.1" class="ltx_text" style="font-size:70%;">FC factor</span></td>
</tr>
</table>
</th>
<th id="S4.T5.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T5.2.1.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T5.2.1.1.3.1.1" class="ltx_tr">
<td id="S4.T5.2.1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T5.2.1.1.3.1.1.1.1" class="ltx_text" style="font-size:70%;">FedSGD</span></td>
</tr>
<tr id="S4.T5.2.1.1.3.1.2" class="ltx_tr">
<td id="S4.T5.2.1.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T5.2.1.1.3.1.2.1.1" class="ltx_text" style="font-size:70%;">accuracy</span></td>
</tr>
</table>
</th>
<th id="S4.T5.2.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T5.2.1.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T5.2.1.1.4.1.1" class="ltx_tr">
<td id="S4.T5.2.1.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T5.2.1.1.4.1.1.1.1" class="ltx_text" style="font-size:70%;">FedAvg</span></td>
</tr>
<tr id="S4.T5.2.1.1.4.1.2" class="ltx_tr">
<td id="S4.T5.2.1.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T5.2.1.1.4.1.2.1.1" class="ltx_text" style="font-size:70%;">accuracy</span></td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T5.2.2.1" class="ltx_tr">
<th id="S4.T5.2.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" rowspan="4"><span id="S4.T5.2.2.1.1.1" class="ltx_text" style="font-size:70%;">
<span id="S4.T5.2.2.1.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S4.T5.2.2.1.1.1.1.1" class="ltx_tr">
<span id="S4.T5.2.2.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Linear layer</span></span>
<span id="S4.T5.2.2.1.1.1.1.2" class="ltx_tr">
<span id="S4.T5.2.2.1.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">leakage (LOKI <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite>)</span></span>
</span></span></th>
<th id="S4.T5.2.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T5.2.2.1.2.1" class="ltx_text" style="font-size:70%;">8</span></th>
<td id="S4.T5.2.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T5.2.2.1.3.1" class="ltx_text" style="font-size:70%;">93.16</span></td>
<td id="S4.T5.2.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T5.2.2.1.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">93.31</span></td>
</tr>
<tr id="S4.T5.2.3.2" class="ltx_tr">
<th id="S4.T5.2.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S4.T5.2.3.2.1.1" class="ltx_text" style="font-size:70%;">4</span></th>
<td id="S4.T5.2.3.2.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T5.2.3.2.2.1" class="ltx_text ltx_font_bold" style="font-size:70%;">92.94</span></td>
<td id="S4.T5.2.3.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T5.2.3.2.3.1" class="ltx_text" style="font-size:70%;">92.88</span></td>
</tr>
<tr id="S4.T5.2.4.3" class="ltx_tr">
<th id="S4.T5.2.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S4.T5.2.4.3.1.1" class="ltx_text" style="font-size:70%;">2</span></th>
<td id="S4.T5.2.4.3.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T5.2.4.3.2.1" class="ltx_text" style="font-size:70%;">91.90</span></td>
<td id="S4.T5.2.4.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T5.2.4.3.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">92.35</span></td>
</tr>
<tr id="S4.T5.2.5.4" class="ltx_tr">
<th id="S4.T5.2.5.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r"><span id="S4.T5.2.5.4.1.1" class="ltx_text" style="font-size:70%;">1</span></th>
<td id="S4.T5.2.5.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T5.2.5.4.2.1" class="ltx_text" style="font-size:70%;">88.86</span></td>
<td id="S4.T5.2.5.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T5.2.5.4.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">91.11</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.5.1.1" class="ltx_text" style="font-size:129%;">Table 5</span>: </span><span id="S4.T5.6.2" class="ltx_text" style="font-size:129%;"> CIFAR-10 test accuracy with LOKI FedAvg.</span></figcaption>
</figure>
<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">We explore the impact of leaking images using LLL in FedAvg when training models. We use 8 local iterations of mini-batch size 8, a local dataset size of 64, and a learning rate of 1e-4. Following the LOKI attack <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a>]</cite>, CSF<math id="S4.SS4.p1.1.m1.1" class="ltx_Math" alttext="=500" display="inline"><semantics id="S4.SS4.p1.1.m1.1a"><mrow id="S4.SS4.p1.1.m1.1.1" xref="S4.SS4.p1.1.m1.1.1.cmml"><mi id="S4.SS4.p1.1.m1.1.1.2" xref="S4.SS4.p1.1.m1.1.1.2.cmml"></mi><mo id="S4.SS4.p1.1.m1.1.1.1" xref="S4.SS4.p1.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS4.p1.1.m1.1.1.3" xref="S4.SS4.p1.1.m1.1.1.3.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p1.1.m1.1b"><apply id="S4.SS4.p1.1.m1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1"><eq id="S4.SS4.p1.1.m1.1.1.1.cmml" xref="S4.SS4.p1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="S4.SS4.p1.1.m1.1.1.2.cmml" xref="S4.SS4.p1.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S4.SS4.p1.1.m1.1.1.3.cmml" xref="S4.SS4.p1.1.m1.1.1.3">500</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p1.1.m1.1c">=500</annotation></semantics></math> is used to achieve a higher leakage rate and reconstruction quality. Similar to before, we apply the attack across batches covering the entire CIFAR-10 training dataset.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.3" class="ltx_p">Table <a href="#S4.T4" title="Table 4 ‣ 4.4 FedAvg with leaked images from LOKI ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the leakage rate of LOKI in FedAvg compared to FedSGD. Using <math id="S4.SS4.p2.1.m1.1" class="ltx_Math" alttext="\textit{CSF}=500" display="inline"><semantics id="S4.SS4.p2.1.m1.1a"><mrow id="S4.SS4.p2.1.m1.1.1" xref="S4.SS4.p2.1.m1.1.1.cmml"><mtext class="ltx_mathvariant_italic" id="S4.SS4.p2.1.m1.1.1.2" xref="S4.SS4.p2.1.m1.1.1.2a.cmml">CSF</mtext><mo id="S4.SS4.p2.1.m1.1.1.1" xref="S4.SS4.p2.1.m1.1.1.1.cmml">=</mo><mn id="S4.SS4.p2.1.m1.1.1.3" xref="S4.SS4.p2.1.m1.1.1.3.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.1.m1.1b"><apply id="S4.SS4.p2.1.m1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1"><eq id="S4.SS4.p2.1.m1.1.1.1.cmml" xref="S4.SS4.p2.1.m1.1.1.1"></eq><ci id="S4.SS4.p2.1.m1.1.1.2a.cmml" xref="S4.SS4.p2.1.m1.1.1.2"><mtext class="ltx_mathvariant_italic" id="S4.SS4.p2.1.m1.1.1.2.cmml" xref="S4.SS4.p2.1.m1.1.1.2">CSF</mtext></ci><cn type="integer" id="S4.SS4.p2.1.m1.1.1.3.cmml" xref="S4.SS4.p2.1.m1.1.1.3">500</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.1.m1.1c">\textit{CSF}=500</annotation></semantics></math>, the leakage rate of LOKI in FedAvg is substantially higher than the leakage rates in the FedSGD setting. Using an FC layer of half the size, the leakage rate in FedAvg is comparable to that of FedSGD. For example, LOKI FedAvg factor 1 achieves a leakage rate of <math id="S4.SS4.p2.2.m2.1" class="ltx_Math" alttext="58.39\%" display="inline"><semantics id="S4.SS4.p2.2.m2.1a"><mrow id="S4.SS4.p2.2.m2.1.1" xref="S4.SS4.p2.2.m2.1.1.cmml"><mn id="S4.SS4.p2.2.m2.1.1.2" xref="S4.SS4.p2.2.m2.1.1.2.cmml">58.39</mn><mo id="S4.SS4.p2.2.m2.1.1.1" xref="S4.SS4.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.2.m2.1b"><apply id="S4.SS4.p2.2.m2.1.1.cmml" xref="S4.SS4.p2.2.m2.1.1"><csymbol cd="latexml" id="S4.SS4.p2.2.m2.1.1.1.cmml" xref="S4.SS4.p2.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p2.2.m2.1.1.2.cmml" xref="S4.SS4.p2.2.m2.1.1.2">58.39</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.2.m2.1c">58.39\%</annotation></semantics></math> compared to LOKI FedSGD factor 2 which achieves a leakage rate of <math id="S4.SS4.p2.3.m3.1" class="ltx_Math" alttext="59.76\%" display="inline"><semantics id="S4.SS4.p2.3.m3.1a"><mrow id="S4.SS4.p2.3.m3.1.1" xref="S4.SS4.p2.3.m3.1.1.cmml"><mn id="S4.SS4.p2.3.m3.1.1.2" xref="S4.SS4.p2.3.m3.1.1.2.cmml">59.76</mn><mo id="S4.SS4.p2.3.m3.1.1.1" xref="S4.SS4.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p2.3.m3.1b"><apply id="S4.SS4.p2.3.m3.1.1.cmml" xref="S4.SS4.p2.3.m3.1.1"><csymbol cd="latexml" id="S4.SS4.p2.3.m3.1.1.1.cmml" xref="S4.SS4.p2.3.m3.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p2.3.m3.1.1.2.cmml" xref="S4.SS4.p2.3.m3.1.1.2">59.76</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p2.3.m3.1c">59.76\%</annotation></semantics></math>.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.2" class="ltx_p">Table <a href="#S4.T5" title="Table 5 ‣ 4.4 FedAvg with leaked images from LOKI ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> shows the testing accuracy of LOKI FedAvg for the different FC layer sizes. The test accuracies are very comparable to the FedSGD settings. However, with a smaller FC layer size factor, the effect of having a larger total number of leaked images becomes visible. With FC factor 1, LOKI FedAvg achieves <math id="S4.SS4.p3.1.m1.1" class="ltx_Math" alttext="91.11\%" display="inline"><semantics id="S4.SS4.p3.1.m1.1a"><mrow id="S4.SS4.p3.1.m1.1.1" xref="S4.SS4.p3.1.m1.1.1.cmml"><mn id="S4.SS4.p3.1.m1.1.1.2" xref="S4.SS4.p3.1.m1.1.1.2.cmml">91.11</mn><mo id="S4.SS4.p3.1.m1.1.1.1" xref="S4.SS4.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.1.m1.1b"><apply id="S4.SS4.p3.1.m1.1.1.cmml" xref="S4.SS4.p3.1.m1.1.1"><csymbol cd="latexml" id="S4.SS4.p3.1.m1.1.1.1.cmml" xref="S4.SS4.p3.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p3.1.m1.1.1.2.cmml" xref="S4.SS4.p3.1.m1.1.1.2">91.11</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.1.m1.1c">91.11\%</annotation></semantics></math> accuracy while LOKI FedSGD achieves <math id="S4.SS4.p3.2.m2.1" class="ltx_Math" alttext="88.86\%" display="inline"><semantics id="S4.SS4.p3.2.m2.1a"><mrow id="S4.SS4.p3.2.m2.1.1" xref="S4.SS4.p3.2.m2.1.1.cmml"><mn id="S4.SS4.p3.2.m2.1.1.2" xref="S4.SS4.p3.2.m2.1.1.2.cmml">88.86</mn><mo id="S4.SS4.p3.2.m2.1.1.1" xref="S4.SS4.p3.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS4.p3.2.m2.1b"><apply id="S4.SS4.p3.2.m2.1.1.cmml" xref="S4.SS4.p3.2.m2.1.1"><csymbol cd="latexml" id="S4.SS4.p3.2.m2.1.1.1.cmml" xref="S4.SS4.p3.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS4.p3.2.m2.1.1.2.cmml" xref="S4.SS4.p3.2.m2.1.1.2">88.86</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS4.p3.2.m2.1c">88.86\%</annotation></semantics></math>.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Training with semi-supervised learning</h3>

<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.18144/assets/x5.png" id="S4.F3.sf1.g1" class="ltx_graphics ltx_img_landscape" width="230" height="153" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S4.F3.sf1.3.2" class="ltx_text" style="font-size:90%;">Varying leakage rate</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.18144/assets/x6.png" id="S4.F3.sf2.g1" class="ltx_graphics ltx_img_landscape" width="230" height="153" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S4.F3.sf2.3.2" class="ltx_text" style="font-size:90%;">Varying number of labels</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S4.F3.3.2" class="ltx_text" style="font-size:90%;">Semi-supervised learning using CoMatch on CIFAR-10 with a WideResNet with (a) a varying FC size and leakage rate (LR) for LOKI and the known labels fixed at 40 and (b) a fixed number of leaked images and 20, 40, and 250 known labels.</span></figcaption>
</figure>
<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">In order to train machine learning models in a supervised fashion, images leaked through LLL need to be labeled. Previously, we assumed that all labels were known and matched to the images prior to training, but this is impractical. Within a LLL batch reconstruction, the order of images is not preserved. Even if labels were recovered like for GI attacks, this would result in a set of unmatched ground truth labels and images. Manual hand labeling is tedious and this inability to match labels is a weakness of LLL attacks <em id="S4.SS5.p1.1.1" class="ltx_emph ltx_font_italic">only when it comes to downstream tasks.</em></p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.11" class="ltx_p">In this experiment, we assume that only a small portion of images are labeled. This setting is similar to semi-supervised learning (SSL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">25</span></a>, <a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">31</span></a>]</cite> and we use CoMatch <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">14</span></a>]</cite>, a semi-supervised algorithm, to train the models. We use a WideResNet-28-2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">27</span></a>]</cite> and train for 450 epochs on CIFAR-10. Figure <a href="#S4.F3.sf1" title="Figure 3(a) ‣ Figure 3 ‣ 4.5 Training with semi-supervised learning ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a> fixes the number of known labels to be 40 and shows the test accuracy curve with different fully connected layer sizes. We note that when there is only a small proportion of leaked data, this leads to a pronounced decrease in performance in SSL. LOKI with an FC factor of 1 (with <math id="S4.SS5.p2.1.m1.1" class="ltx_Math" alttext="36.48\%" display="inline"><semantics id="S4.SS5.p2.1.m1.1a"><mrow id="S4.SS5.p2.1.m1.1.1" xref="S4.SS5.p2.1.m1.1.1.cmml"><mn id="S4.SS5.p2.1.m1.1.1.2" xref="S4.SS5.p2.1.m1.1.1.2.cmml">36.48</mn><mo id="S4.SS5.p2.1.m1.1.1.1" xref="S4.SS5.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.1.m1.1b"><apply id="S4.SS5.p2.1.m1.1.1.cmml" xref="S4.SS5.p2.1.m1.1.1"><csymbol cd="latexml" id="S4.SS5.p2.1.m1.1.1.1.cmml" xref="S4.SS5.p2.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS5.p2.1.m1.1.1.2.cmml" xref="S4.SS5.p2.1.m1.1.1.2">36.48</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.1.m1.1c">36.48\%</annotation></semantics></math> leakage rate) illustrates this, as it only achieves <math id="S4.SS5.p2.2.m2.1" class="ltx_Math" alttext="78.31\%" display="inline"><semantics id="S4.SS5.p2.2.m2.1a"><mrow id="S4.SS5.p2.2.m2.1.1" xref="S4.SS5.p2.2.m2.1.1.cmml"><mn id="S4.SS5.p2.2.m2.1.1.2" xref="S4.SS5.p2.2.m2.1.1.2.cmml">78.31</mn><mo id="S4.SS5.p2.2.m2.1.1.1" xref="S4.SS5.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.2.m2.1b"><apply id="S4.SS5.p2.2.m2.1.1.cmml" xref="S4.SS5.p2.2.m2.1.1"><csymbol cd="latexml" id="S4.SS5.p2.2.m2.1.1.1.cmml" xref="S4.SS5.p2.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS5.p2.2.m2.1.1.2.cmml" xref="S4.SS5.p2.2.m2.1.1.2">78.31</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.2.m2.1c">78.31\%</annotation></semantics></math> max accuracy compared to the CIFAR-10 40 label baseline of <math id="S4.SS5.p2.3.m3.1" class="ltx_Math" alttext="92.18\%" display="inline"><semantics id="S4.SS5.p2.3.m3.1a"><mrow id="S4.SS5.p2.3.m3.1.1" xref="S4.SS5.p2.3.m3.1.1.cmml"><mn id="S4.SS5.p2.3.m3.1.1.2" xref="S4.SS5.p2.3.m3.1.1.2.cmml">92.18</mn><mo id="S4.SS5.p2.3.m3.1.1.1" xref="S4.SS5.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.3.m3.1b"><apply id="S4.SS5.p2.3.m3.1.1.cmml" xref="S4.SS5.p2.3.m3.1.1"><csymbol cd="latexml" id="S4.SS5.p2.3.m3.1.1.1.cmml" xref="S4.SS5.p2.3.m3.1.1.1">percent</csymbol><cn type="float" id="S4.SS5.p2.3.m3.1.1.2.cmml" xref="S4.SS5.p2.3.m3.1.1.2">92.18</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.3.m3.1c">92.18\%</annotation></semantics></math>. With a factor of 2, the accuracy improves and jumps to <math id="S4.SS5.p2.4.m4.1" class="ltx_Math" alttext="88.91\%" display="inline"><semantics id="S4.SS5.p2.4.m4.1a"><mrow id="S4.SS5.p2.4.m4.1.1" xref="S4.SS5.p2.4.m4.1.1.cmml"><mn id="S4.SS5.p2.4.m4.1.1.2" xref="S4.SS5.p2.4.m4.1.1.2.cmml">88.91</mn><mo id="S4.SS5.p2.4.m4.1.1.1" xref="S4.SS5.p2.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.4.m4.1b"><apply id="S4.SS5.p2.4.m4.1.1.cmml" xref="S4.SS5.p2.4.m4.1.1"><csymbol cd="latexml" id="S4.SS5.p2.4.m4.1.1.1.cmml" xref="S4.SS5.p2.4.m4.1.1.1">percent</csymbol><cn type="float" id="S4.SS5.p2.4.m4.1.1.2.cmml" xref="S4.SS5.p2.4.m4.1.1.2">88.91</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.4.m4.1c">88.91\%</annotation></semantics></math> as the leakage rate also substantially increases to <math id="S4.SS5.p2.5.m5.1" class="ltx_Math" alttext="59.76\%" display="inline"><semantics id="S4.SS5.p2.5.m5.1a"><mrow id="S4.SS5.p2.5.m5.1.1" xref="S4.SS5.p2.5.m5.1.1.cmml"><mn id="S4.SS5.p2.5.m5.1.1.2" xref="S4.SS5.p2.5.m5.1.1.2.cmml">59.76</mn><mo id="S4.SS5.p2.5.m5.1.1.1" xref="S4.SS5.p2.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.5.m5.1b"><apply id="S4.SS5.p2.5.m5.1.1.cmml" xref="S4.SS5.p2.5.m5.1.1"><csymbol cd="latexml" id="S4.SS5.p2.5.m5.1.1.1.cmml" xref="S4.SS5.p2.5.m5.1.1.1">percent</csymbol><cn type="float" id="S4.SS5.p2.5.m5.1.1.2.cmml" xref="S4.SS5.p2.5.m5.1.1.2">59.76</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.5.m5.1c">59.76\%</annotation></semantics></math>.
With factors 4 and 8 (<math id="S4.SS5.p2.6.m6.1" class="ltx_Math" alttext="78.93\%" display="inline"><semantics id="S4.SS5.p2.6.m6.1a"><mrow id="S4.SS5.p2.6.m6.1.1" xref="S4.SS5.p2.6.m6.1.1.cmml"><mn id="S4.SS5.p2.6.m6.1.1.2" xref="S4.SS5.p2.6.m6.1.1.2.cmml">78.93</mn><mo id="S4.SS5.p2.6.m6.1.1.1" xref="S4.SS5.p2.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.6.m6.1b"><apply id="S4.SS5.p2.6.m6.1.1.cmml" xref="S4.SS5.p2.6.m6.1.1"><csymbol cd="latexml" id="S4.SS5.p2.6.m6.1.1.1.cmml" xref="S4.SS5.p2.6.m6.1.1.1">percent</csymbol><cn type="float" id="S4.SS5.p2.6.m6.1.1.2.cmml" xref="S4.SS5.p2.6.m6.1.1.2">78.93</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.6.m6.1c">78.93\%</annotation></semantics></math> and <math id="S4.SS5.p2.7.m7.1" class="ltx_Math" alttext="87.58\%" display="inline"><semantics id="S4.SS5.p2.7.m7.1a"><mrow id="S4.SS5.p2.7.m7.1.1" xref="S4.SS5.p2.7.m7.1.1.cmml"><mn id="S4.SS5.p2.7.m7.1.1.2" xref="S4.SS5.p2.7.m7.1.1.2.cmml">87.58</mn><mo id="S4.SS5.p2.7.m7.1.1.1" xref="S4.SS5.p2.7.m7.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.7.m7.1b"><apply id="S4.SS5.p2.7.m7.1.1.cmml" xref="S4.SS5.p2.7.m7.1.1"><csymbol cd="latexml" id="S4.SS5.p2.7.m7.1.1.1.cmml" xref="S4.SS5.p2.7.m7.1.1.1">percent</csymbol><cn type="float" id="S4.SS5.p2.7.m7.1.1.2.cmml" xref="S4.SS5.p2.7.m7.1.1.2">87.58</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.7.m7.1c">87.58\%</annotation></semantics></math> leakage rate), the accuracy is very close to the baseline at <math id="S4.SS5.p2.8.m8.1" class="ltx_Math" alttext="91.18\%" display="inline"><semantics id="S4.SS5.p2.8.m8.1a"><mrow id="S4.SS5.p2.8.m8.1.1" xref="S4.SS5.p2.8.m8.1.1.cmml"><mn id="S4.SS5.p2.8.m8.1.1.2" xref="S4.SS5.p2.8.m8.1.1.2.cmml">91.18</mn><mo id="S4.SS5.p2.8.m8.1.1.1" xref="S4.SS5.p2.8.m8.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.8.m8.1b"><apply id="S4.SS5.p2.8.m8.1.1.cmml" xref="S4.SS5.p2.8.m8.1.1"><csymbol cd="latexml" id="S4.SS5.p2.8.m8.1.1.1.cmml" xref="S4.SS5.p2.8.m8.1.1.1">percent</csymbol><cn type="float" id="S4.SS5.p2.8.m8.1.1.2.cmml" xref="S4.SS5.p2.8.m8.1.1.2">91.18</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.8.m8.1c">91.18\%</annotation></semantics></math> and <math id="S4.SS5.p2.9.m9.1" class="ltx_Math" alttext="91.84\%" display="inline"><semantics id="S4.SS5.p2.9.m9.1a"><mrow id="S4.SS5.p2.9.m9.1.1" xref="S4.SS5.p2.9.m9.1.1.cmml"><mn id="S4.SS5.p2.9.m9.1.1.2" xref="S4.SS5.p2.9.m9.1.1.2.cmml">91.84</mn><mo id="S4.SS5.p2.9.m9.1.1.1" xref="S4.SS5.p2.9.m9.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.9.m9.1b"><apply id="S4.SS5.p2.9.m9.1.1.cmml" xref="S4.SS5.p2.9.m9.1.1"><csymbol cd="latexml" id="S4.SS5.p2.9.m9.1.1.1.cmml" xref="S4.SS5.p2.9.m9.1.1.1">percent</csymbol><cn type="float" id="S4.SS5.p2.9.m9.1.1.2.cmml" xref="S4.SS5.p2.9.m9.1.1.2">91.84</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.9.m9.1c">91.84\%</annotation></semantics></math> respectively. Figure <a href="#S4.F3.sf2" title="Figure 3(b) ‣ Figure 3 ‣ 4.5 Training with semi-supervised learning ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(b)</span></a> shows the test accuracy plot of LOKI size factor 4 with the number of known labels being 20, 40, and 250. With 20 and 250 labels, LOKI factor 4 achieves <math id="S4.SS5.p2.10.m10.1" class="ltx_Math" alttext="86.69\%" display="inline"><semantics id="S4.SS5.p2.10.m10.1a"><mrow id="S4.SS5.p2.10.m10.1.1" xref="S4.SS5.p2.10.m10.1.1.cmml"><mn id="S4.SS5.p2.10.m10.1.1.2" xref="S4.SS5.p2.10.m10.1.1.2.cmml">86.69</mn><mo id="S4.SS5.p2.10.m10.1.1.1" xref="S4.SS5.p2.10.m10.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.10.m10.1b"><apply id="S4.SS5.p2.10.m10.1.1.cmml" xref="S4.SS5.p2.10.m10.1.1"><csymbol cd="latexml" id="S4.SS5.p2.10.m10.1.1.1.cmml" xref="S4.SS5.p2.10.m10.1.1.1">percent</csymbol><cn type="float" id="S4.SS5.p2.10.m10.1.1.2.cmml" xref="S4.SS5.p2.10.m10.1.1.2">86.69</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.10.m10.1c">86.69\%</annotation></semantics></math> and <math id="S4.SS5.p2.11.m11.1" class="ltx_Math" alttext="91.65\%" display="inline"><semantics id="S4.SS5.p2.11.m11.1a"><mrow id="S4.SS5.p2.11.m11.1.1" xref="S4.SS5.p2.11.m11.1.1.cmml"><mn id="S4.SS5.p2.11.m11.1.1.2" xref="S4.SS5.p2.11.m11.1.1.2.cmml">91.65</mn><mo id="S4.SS5.p2.11.m11.1.1.1" xref="S4.SS5.p2.11.m11.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.p2.11.m11.1b"><apply id="S4.SS5.p2.11.m11.1.1.cmml" xref="S4.SS5.p2.11.m11.1.1"><csymbol cd="latexml" id="S4.SS5.p2.11.m11.1.1.1.cmml" xref="S4.SS5.p2.11.m11.1.1.1">percent</csymbol><cn type="float" id="S4.SS5.p2.11.m11.1.1.2.cmml" xref="S4.SS5.p2.11.m11.1.1.2">91.65</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p2.11.m11.1c">91.65\%</annotation></semantics></math> peak accuracy. We note that there is a greater variability in accuracy with a smaller number of labels, a trend consistent with other SSL methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">14</span></a>, <a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">31</span></a>, <a href="#bib.bib25" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">25</span></a>]</cite>.</p>
</div>
</section>
<section id="S4.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6 </span>Starting training from federated models</h3>

<figure id="S4.F4" class="ltx_figure"><img src="/html/2403.18144/assets/x7.png" id="S4.F4.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="173" height="115" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.3.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S4.F4.4.2" class="ltx_text" style="font-size:90%;"> FL model trained with 50 clients as start point for training with leaked LLL data. Highlighted area indicates improvement above the FL model and training on the leaked data alone.</span></figcaption>
</figure>
<div id="S4.SS6.p1" class="ltx_para">
<p id="S4.SS6.p1.1" class="ltx_p">While the previous experiments worked with leaked data from all batches in the dataset, such large amounts of leaked data may not always be available. For example, LLL attacks may affect model performance due to manipulation of the model parameters and/or architecture. In later rounds when model performance is high, this may be easier to detect. Similarly, GI attacks such as Inverting Gradients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a>]</cite> have better reconstruction quality with an untrained network. In both cases, it is possible that the attack is only applied during a few initial rounds of training and only a small portion of data is leaked. Training from scratch with a small portion of leaked data does not achieve good model performance alone, so instead, we can initialize from the fully trained FL model and then train it centrally using the leaked data.</p>
</div>
<div id="S4.SS6.p2" class="ltx_para">
<p id="S4.SS6.p2.11" class="ltx_p">We use smaller portions of the leaked data from LOKI FC size factor of 8 for this experiment. With only <math id="S4.SS6.p2.1.m1.1" class="ltx_Math" alttext="5\%" display="inline"><semantics id="S4.SS6.p2.1.m1.1a"><mrow id="S4.SS6.p2.1.m1.1.1" xref="S4.SS6.p2.1.m1.1.1.cmml"><mn id="S4.SS6.p2.1.m1.1.1.2" xref="S4.SS6.p2.1.m1.1.1.2.cmml">5</mn><mo id="S4.SS6.p2.1.m1.1.1.1" xref="S4.SS6.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.1.m1.1b"><apply id="S4.SS6.p2.1.m1.1.1.cmml" xref="S4.SS6.p2.1.m1.1.1"><csymbol cd="latexml" id="S4.SS6.p2.1.m1.1.1.1.cmml" xref="S4.SS6.p2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.SS6.p2.1.m1.1.1.2.cmml" xref="S4.SS6.p2.1.m1.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.1.m1.1c">5\%</annotation></semantics></math> (2500) of leaked images in CIFAR-10, a model trained from scratch can only achieve <math id="S4.SS6.p2.2.m2.1" class="ltx_Math" alttext="61.15\%" display="inline"><semantics id="S4.SS6.p2.2.m2.1a"><mrow id="S4.SS6.p2.2.m2.1.1" xref="S4.SS6.p2.2.m2.1.1.cmml"><mn id="S4.SS6.p2.2.m2.1.1.2" xref="S4.SS6.p2.2.m2.1.1.2.cmml">61.15</mn><mo id="S4.SS6.p2.2.m2.1.1.1" xref="S4.SS6.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.2.m2.1b"><apply id="S4.SS6.p2.2.m2.1.1.cmml" xref="S4.SS6.p2.2.m2.1.1"><csymbol cd="latexml" id="S4.SS6.p2.2.m2.1.1.1.cmml" xref="S4.SS6.p2.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS6.p2.2.m2.1.1.2.cmml" xref="S4.SS6.p2.2.m2.1.1.2">61.15</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.2.m2.1c">61.15\%</annotation></semantics></math> test accuracy. With <math id="S4.SS6.p2.3.m3.1" class="ltx_Math" alttext="2\%" display="inline"><semantics id="S4.SS6.p2.3.m3.1a"><mrow id="S4.SS6.p2.3.m3.1.1" xref="S4.SS6.p2.3.m3.1.1.cmml"><mn id="S4.SS6.p2.3.m3.1.1.2" xref="S4.SS6.p2.3.m3.1.1.2.cmml">2</mn><mo id="S4.SS6.p2.3.m3.1.1.1" xref="S4.SS6.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.3.m3.1b"><apply id="S4.SS6.p2.3.m3.1.1.cmml" xref="S4.SS6.p2.3.m3.1.1"><csymbol cd="latexml" id="S4.SS6.p2.3.m3.1.1.1.cmml" xref="S4.SS6.p2.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S4.SS6.p2.3.m3.1.1.2.cmml" xref="S4.SS6.p2.3.m3.1.1.2">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.3.m3.1c">2\%</annotation></semantics></math> (1000 images) of data, the model performance drops to <math id="S4.SS6.p2.4.m4.1" class="ltx_Math" alttext="39.63\%" display="inline"><semantics id="S4.SS6.p2.4.m4.1a"><mrow id="S4.SS6.p2.4.m4.1.1" xref="S4.SS6.p2.4.m4.1.1.cmml"><mn id="S4.SS6.p2.4.m4.1.1.2" xref="S4.SS6.p2.4.m4.1.1.2.cmml">39.63</mn><mo id="S4.SS6.p2.4.m4.1.1.1" xref="S4.SS6.p2.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.4.m4.1b"><apply id="S4.SS6.p2.4.m4.1.1.cmml" xref="S4.SS6.p2.4.m4.1.1"><csymbol cd="latexml" id="S4.SS6.p2.4.m4.1.1.1.cmml" xref="S4.SS6.p2.4.m4.1.1.1">percent</csymbol><cn type="float" id="S4.SS6.p2.4.m4.1.1.2.cmml" xref="S4.SS6.p2.4.m4.1.1.2">39.63</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.4.m4.1c">39.63\%</annotation></semantics></math>. Both cases are below an FL model with 50 clients that achieves a <math id="S4.SS6.p2.5.m5.1" class="ltx_Math" alttext="64.08\%" display="inline"><semantics id="S4.SS6.p2.5.m5.1a"><mrow id="S4.SS6.p2.5.m5.1.1" xref="S4.SS6.p2.5.m5.1.1.cmml"><mn id="S4.SS6.p2.5.m5.1.1.2" xref="S4.SS6.p2.5.m5.1.1.2.cmml">64.08</mn><mo id="S4.SS6.p2.5.m5.1.1.1" xref="S4.SS6.p2.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.5.m5.1b"><apply id="S4.SS6.p2.5.m5.1.1.cmml" xref="S4.SS6.p2.5.m5.1.1"><csymbol cd="latexml" id="S4.SS6.p2.5.m5.1.1.1.cmml" xref="S4.SS6.p2.5.m5.1.1.1">percent</csymbol><cn type="float" id="S4.SS6.p2.5.m5.1.1.2.cmml" xref="S4.SS6.p2.5.m5.1.1.2">64.08</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.5.m5.1c">64.08\%</annotation></semantics></math> final test accuracy. However, by using the FL model as the initial starting point, even a small amount of leaked data allows for an increase in performance. We take the model that has been trained using FL and then additionally train that model centrally. Using only <math id="S4.SS6.p2.6.m6.1" class="ltx_Math" alttext="2\%" display="inline"><semantics id="S4.SS6.p2.6.m6.1a"><mrow id="S4.SS6.p2.6.m6.1.1" xref="S4.SS6.p2.6.m6.1.1.cmml"><mn id="S4.SS6.p2.6.m6.1.1.2" xref="S4.SS6.p2.6.m6.1.1.2.cmml">2</mn><mo id="S4.SS6.p2.6.m6.1.1.1" xref="S4.SS6.p2.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.6.m6.1b"><apply id="S4.SS6.p2.6.m6.1.1.cmml" xref="S4.SS6.p2.6.m6.1.1"><csymbol cd="latexml" id="S4.SS6.p2.6.m6.1.1.1.cmml" xref="S4.SS6.p2.6.m6.1.1.1">percent</csymbol><cn type="integer" id="S4.SS6.p2.6.m6.1.1.2.cmml" xref="S4.SS6.p2.6.m6.1.1.2">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.6.m6.1c">2\%</annotation></semantics></math> and <math id="S4.SS6.p2.7.m7.1" class="ltx_Math" alttext="5\%" display="inline"><semantics id="S4.SS6.p2.7.m7.1a"><mrow id="S4.SS6.p2.7.m7.1.1" xref="S4.SS6.p2.7.m7.1.1.cmml"><mn id="S4.SS6.p2.7.m7.1.1.2" xref="S4.SS6.p2.7.m7.1.1.2.cmml">5</mn><mo id="S4.SS6.p2.7.m7.1.1.1" xref="S4.SS6.p2.7.m7.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.7.m7.1b"><apply id="S4.SS6.p2.7.m7.1.1.cmml" xref="S4.SS6.p2.7.m7.1.1"><csymbol cd="latexml" id="S4.SS6.p2.7.m7.1.1.1.cmml" xref="S4.SS6.p2.7.m7.1.1.1">percent</csymbol><cn type="integer" id="S4.SS6.p2.7.m7.1.1.2.cmml" xref="S4.SS6.p2.7.m7.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.7.m7.1c">5\%</annotation></semantics></math> of the leaked data,
the models are able to achieve <math id="S4.SS6.p2.8.m8.1" class="ltx_Math" alttext="68.25\%" display="inline"><semantics id="S4.SS6.p2.8.m8.1a"><mrow id="S4.SS6.p2.8.m8.1.1" xref="S4.SS6.p2.8.m8.1.1.cmml"><mn id="S4.SS6.p2.8.m8.1.1.2" xref="S4.SS6.p2.8.m8.1.1.2.cmml">68.25</mn><mo id="S4.SS6.p2.8.m8.1.1.1" xref="S4.SS6.p2.8.m8.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.8.m8.1b"><apply id="S4.SS6.p2.8.m8.1.1.cmml" xref="S4.SS6.p2.8.m8.1.1"><csymbol cd="latexml" id="S4.SS6.p2.8.m8.1.1.1.cmml" xref="S4.SS6.p2.8.m8.1.1.1">percent</csymbol><cn type="float" id="S4.SS6.p2.8.m8.1.1.2.cmml" xref="S4.SS6.p2.8.m8.1.1.2">68.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.8.m8.1c">68.25\%</annotation></semantics></math> and <math id="S4.SS6.p2.9.m9.1" class="ltx_Math" alttext="74.25\%" display="inline"><semantics id="S4.SS6.p2.9.m9.1a"><mrow id="S4.SS6.p2.9.m9.1.1" xref="S4.SS6.p2.9.m9.1.1.cmml"><mn id="S4.SS6.p2.9.m9.1.1.2" xref="S4.SS6.p2.9.m9.1.1.2.cmml">74.25</mn><mo id="S4.SS6.p2.9.m9.1.1.1" xref="S4.SS6.p2.9.m9.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.9.m9.1b"><apply id="S4.SS6.p2.9.m9.1.1.cmml" xref="S4.SS6.p2.9.m9.1.1"><csymbol cd="latexml" id="S4.SS6.p2.9.m9.1.1.1.cmml" xref="S4.SS6.p2.9.m9.1.1.1">percent</csymbol><cn type="float" id="S4.SS6.p2.9.m9.1.1.2.cmml" xref="S4.SS6.p2.9.m9.1.1.2">74.25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.9.m9.1c">74.25\%</annotation></semantics></math> final testing accuracy, a <math id="S4.SS6.p2.10.m10.1" class="ltx_Math" alttext="28.62\%" display="inline"><semantics id="S4.SS6.p2.10.m10.1a"><mrow id="S4.SS6.p2.10.m10.1.1" xref="S4.SS6.p2.10.m10.1.1.cmml"><mn id="S4.SS6.p2.10.m10.1.1.2" xref="S4.SS6.p2.10.m10.1.1.2.cmml">28.62</mn><mo id="S4.SS6.p2.10.m10.1.1.1" xref="S4.SS6.p2.10.m10.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.10.m10.1b"><apply id="S4.SS6.p2.10.m10.1.1.cmml" xref="S4.SS6.p2.10.m10.1.1"><csymbol cd="latexml" id="S4.SS6.p2.10.m10.1.1.1.cmml" xref="S4.SS6.p2.10.m10.1.1.1">percent</csymbol><cn type="float" id="S4.SS6.p2.10.m10.1.1.2.cmml" xref="S4.SS6.p2.10.m10.1.1.2">28.62</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.10.m10.1c">28.62\%</annotation></semantics></math> and <math id="S4.SS6.p2.11.m11.1" class="ltx_Math" alttext="13.10\%" display="inline"><semantics id="S4.SS6.p2.11.m11.1a"><mrow id="S4.SS6.p2.11.m11.1.1" xref="S4.SS6.p2.11.m11.1.1.cmml"><mn id="S4.SS6.p2.11.m11.1.1.2" xref="S4.SS6.p2.11.m11.1.1.2.cmml">13.10</mn><mo id="S4.SS6.p2.11.m11.1.1.1" xref="S4.SS6.p2.11.m11.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS6.p2.11.m11.1b"><apply id="S4.SS6.p2.11.m11.1.1.cmml" xref="S4.SS6.p2.11.m11.1.1"><csymbol cd="latexml" id="S4.SS6.p2.11.m11.1.1.1.cmml" xref="S4.SS6.p2.11.m11.1.1.1">percent</csymbol><cn type="float" id="S4.SS6.p2.11.m11.1.1.2.cmml" xref="S4.SS6.p2.11.m11.1.1.2">13.10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.p2.11.m11.1c">13.10\%</annotation></semantics></math> improvement from starting from scratch. Figure <a href="#S4.F4" title="Figure 4 ‣ 4.6 Starting training from federated models ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the improvement in test accuracy achieved by using the trained FL model as initialization instead of starting from scratch. The improvement is especially noticeable with small percentages of leaked data.</p>
</div>
</section>
<section id="S4.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.7 </span>Quality of data reconstruction</h3>

<figure id="S4.T6" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.T6.st1" class="ltx_table ltx_figure_panel ltx_align_center">
<table id="S4.T6.st1.5.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T6.st1.5.5.6.1" class="ltx_tr">
<th id="S4.T6.st1.5.5.6.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T6.st1.5.5.6.1.1.1" class="ltx_text" style="font-size:70%;">PSNR</span></th>
<th id="S4.T6.st1.5.5.6.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T6.st1.5.5.6.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T6.st1.5.5.6.1.2.1.1" class="ltx_tr">
<td id="S4.T6.st1.5.5.6.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T6.st1.5.5.6.1.2.1.1.1.1" class="ltx_text" style="font-size:70%;">% imgs</span></td>
</tr>
<tr id="S4.T6.st1.5.5.6.1.2.1.2" class="ltx_tr">
<td id="S4.T6.st1.5.5.6.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T6.st1.5.5.6.1.2.1.2.1.1" class="ltx_text" style="font-size:70%;">kept</span></td>
</tr>
</table>
</th>
<th id="S4.T6.st1.5.5.6.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T6.st1.5.5.6.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T6.st1.5.5.6.1.3.1.1" class="ltx_tr">
<td id="S4.T6.st1.5.5.6.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T6.st1.5.5.6.1.3.1.1.1.1" class="ltx_text" style="font-size:70%;">Test</span></td>
</tr>
<tr id="S4.T6.st1.5.5.6.1.3.1.2" class="ltx_tr">
<td id="S4.T6.st1.5.5.6.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T6.st1.5.5.6.1.3.1.2.1.1" class="ltx_text" style="font-size:70%;">accuracy</span></td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T6.st1.1.1.1" class="ltx_tr">
<th id="S4.T6.st1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><math id="S4.T6.st1.1.1.1.1.m1.1" class="ltx_Math" alttext="&gt;20" display="inline"><semantics id="S4.T6.st1.1.1.1.1.m1.1a"><mrow id="S4.T6.st1.1.1.1.1.m1.1.1" xref="S4.T6.st1.1.1.1.1.m1.1.1.cmml"><mi id="S4.T6.st1.1.1.1.1.m1.1.1.2" xref="S4.T6.st1.1.1.1.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S4.T6.st1.1.1.1.1.m1.1.1.1" xref="S4.T6.st1.1.1.1.1.m1.1.1.1.cmml">&gt;</mo><mn mathsize="70%" id="S4.T6.st1.1.1.1.1.m1.1.1.3" xref="S4.T6.st1.1.1.1.1.m1.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.st1.1.1.1.1.m1.1b"><apply id="S4.T6.st1.1.1.1.1.m1.1.1.cmml" xref="S4.T6.st1.1.1.1.1.m1.1.1"><gt id="S4.T6.st1.1.1.1.1.m1.1.1.1.cmml" xref="S4.T6.st1.1.1.1.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S4.T6.st1.1.1.1.1.m1.1.1.2.cmml" xref="S4.T6.st1.1.1.1.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S4.T6.st1.1.1.1.1.m1.1.1.3.cmml" xref="S4.T6.st1.1.1.1.1.m1.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.st1.1.1.1.1.m1.1c">&gt;20</annotation></semantics></math></th>
<td id="S4.T6.st1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T6.st1.1.1.1.2.1" class="ltx_text" style="font-size:70%;">15.88</span></td>
<td id="S4.T6.st1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T6.st1.1.1.1.3.1" class="ltx_text" style="font-size:70%;">70.04</span></td>
</tr>
<tr id="S4.T6.st1.2.2.2" class="ltx_tr">
<th id="S4.T6.st1.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S4.T6.st1.2.2.2.1.m1.1" class="ltx_Math" alttext="&gt;18" display="inline"><semantics id="S4.T6.st1.2.2.2.1.m1.1a"><mrow id="S4.T6.st1.2.2.2.1.m1.1.1" xref="S4.T6.st1.2.2.2.1.m1.1.1.cmml"><mi id="S4.T6.st1.2.2.2.1.m1.1.1.2" xref="S4.T6.st1.2.2.2.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S4.T6.st1.2.2.2.1.m1.1.1.1" xref="S4.T6.st1.2.2.2.1.m1.1.1.1.cmml">&gt;</mo><mn mathsize="70%" id="S4.T6.st1.2.2.2.1.m1.1.1.3" xref="S4.T6.st1.2.2.2.1.m1.1.1.3.cmml">18</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.st1.2.2.2.1.m1.1b"><apply id="S4.T6.st1.2.2.2.1.m1.1.1.cmml" xref="S4.T6.st1.2.2.2.1.m1.1.1"><gt id="S4.T6.st1.2.2.2.1.m1.1.1.1.cmml" xref="S4.T6.st1.2.2.2.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S4.T6.st1.2.2.2.1.m1.1.1.2.cmml" xref="S4.T6.st1.2.2.2.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S4.T6.st1.2.2.2.1.m1.1.1.3.cmml" xref="S4.T6.st1.2.2.2.1.m1.1.1.3">18</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.st1.2.2.2.1.m1.1c">&gt;18</annotation></semantics></math></th>
<td id="S4.T6.st1.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.st1.2.2.2.2.1" class="ltx_text" style="font-size:70%;">27.59</span></td>
<td id="S4.T6.st1.2.2.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.st1.2.2.2.3.1" class="ltx_text" style="font-size:70%;">71.52</span></td>
</tr>
<tr id="S4.T6.st1.3.3.3" class="ltx_tr">
<th id="S4.T6.st1.3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S4.T6.st1.3.3.3.1.m1.1" class="ltx_Math" alttext="&gt;16" display="inline"><semantics id="S4.T6.st1.3.3.3.1.m1.1a"><mrow id="S4.T6.st1.3.3.3.1.m1.1.1" xref="S4.T6.st1.3.3.3.1.m1.1.1.cmml"><mi id="S4.T6.st1.3.3.3.1.m1.1.1.2" xref="S4.T6.st1.3.3.3.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S4.T6.st1.3.3.3.1.m1.1.1.1" xref="S4.T6.st1.3.3.3.1.m1.1.1.1.cmml">&gt;</mo><mn mathsize="70%" id="S4.T6.st1.3.3.3.1.m1.1.1.3" xref="S4.T6.st1.3.3.3.1.m1.1.1.3.cmml">16</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.st1.3.3.3.1.m1.1b"><apply id="S4.T6.st1.3.3.3.1.m1.1.1.cmml" xref="S4.T6.st1.3.3.3.1.m1.1.1"><gt id="S4.T6.st1.3.3.3.1.m1.1.1.1.cmml" xref="S4.T6.st1.3.3.3.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S4.T6.st1.3.3.3.1.m1.1.1.2.cmml" xref="S4.T6.st1.3.3.3.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S4.T6.st1.3.3.3.1.m1.1.1.3.cmml" xref="S4.T6.st1.3.3.3.1.m1.1.1.3">16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.st1.3.3.3.1.m1.1c">&gt;16</annotation></semantics></math></th>
<td id="S4.T6.st1.3.3.3.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.st1.3.3.3.2.1" class="ltx_text" style="font-size:70%;">40.78</span></td>
<td id="S4.T6.st1.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.st1.3.3.3.3.1" class="ltx_text" style="font-size:70%;">73.73</span></td>
</tr>
<tr id="S4.T6.st1.4.4.4" class="ltx_tr">
<th id="S4.T6.st1.4.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S4.T6.st1.4.4.4.1.m1.1" class="ltx_Math" alttext="&gt;14" display="inline"><semantics id="S4.T6.st1.4.4.4.1.m1.1a"><mrow id="S4.T6.st1.4.4.4.1.m1.1.1" xref="S4.T6.st1.4.4.4.1.m1.1.1.cmml"><mi id="S4.T6.st1.4.4.4.1.m1.1.1.2" xref="S4.T6.st1.4.4.4.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S4.T6.st1.4.4.4.1.m1.1.1.1" xref="S4.T6.st1.4.4.4.1.m1.1.1.1.cmml">&gt;</mo><mn mathsize="70%" id="S4.T6.st1.4.4.4.1.m1.1.1.3" xref="S4.T6.st1.4.4.4.1.m1.1.1.3.cmml">14</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.st1.4.4.4.1.m1.1b"><apply id="S4.T6.st1.4.4.4.1.m1.1.1.cmml" xref="S4.T6.st1.4.4.4.1.m1.1.1"><gt id="S4.T6.st1.4.4.4.1.m1.1.1.1.cmml" xref="S4.T6.st1.4.4.4.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S4.T6.st1.4.4.4.1.m1.1.1.2.cmml" xref="S4.T6.st1.4.4.4.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S4.T6.st1.4.4.4.1.m1.1.1.3.cmml" xref="S4.T6.st1.4.4.4.1.m1.1.1.3">14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.st1.4.4.4.1.m1.1c">&gt;14</annotation></semantics></math></th>
<td id="S4.T6.st1.4.4.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.st1.4.4.4.2.1" class="ltx_text" style="font-size:70%;">60.22</span></td>
<td id="S4.T6.st1.4.4.4.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.st1.4.4.4.3.1" class="ltx_text" style="font-size:70%;">75.48</span></td>
</tr>
<tr id="S4.T6.st1.5.5.5" class="ltx_tr">
<th id="S4.T6.st1.5.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r"><math id="S4.T6.st1.5.5.5.1.m1.1" class="ltx_Math" alttext="&gt;12" display="inline"><semantics id="S4.T6.st1.5.5.5.1.m1.1a"><mrow id="S4.T6.st1.5.5.5.1.m1.1.1" xref="S4.T6.st1.5.5.5.1.m1.1.1.cmml"><mi id="S4.T6.st1.5.5.5.1.m1.1.1.2" xref="S4.T6.st1.5.5.5.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S4.T6.st1.5.5.5.1.m1.1.1.1" xref="S4.T6.st1.5.5.5.1.m1.1.1.1.cmml">&gt;</mo><mn mathsize="70%" id="S4.T6.st1.5.5.5.1.m1.1.1.3" xref="S4.T6.st1.5.5.5.1.m1.1.1.3.cmml">12</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.st1.5.5.5.1.m1.1b"><apply id="S4.T6.st1.5.5.5.1.m1.1.1.cmml" xref="S4.T6.st1.5.5.5.1.m1.1.1"><gt id="S4.T6.st1.5.5.5.1.m1.1.1.1.cmml" xref="S4.T6.st1.5.5.5.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S4.T6.st1.5.5.5.1.m1.1.1.2.cmml" xref="S4.T6.st1.5.5.5.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S4.T6.st1.5.5.5.1.m1.1.1.3.cmml" xref="S4.T6.st1.5.5.5.1.m1.1.1.3">12</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.st1.5.5.5.1.m1.1c">&gt;12</annotation></semantics></math></th>
<td id="S4.T6.st1.5.5.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T6.st1.5.5.5.2.1" class="ltx_text" style="font-size:70%;">84.42</span></td>
<td id="S4.T6.st1.5.5.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T6.st1.5.5.5.3.1" class="ltx_text" style="font-size:70%;">76.16</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T6.st1.9.1.1" class="ltx_text" style="font-size:129%;">(a)</span> </span><span id="S4.T6.st1.10.2" class="ltx_text" style="font-size:129%;">PSNR above threshold</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S4.T6.st2" class="ltx_table ltx_figure_panel ltx_align_center">
<table id="S4.T6.st2.5.5" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T6.st2.5.5.6.1" class="ltx_tr">
<th id="S4.T6.st2.5.5.6.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T6.st2.5.5.6.1.1.1" class="ltx_text" style="font-size:70%;">PSNR</span></th>
<th id="S4.T6.st2.5.5.6.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T6.st2.5.5.6.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T6.st2.5.5.6.1.2.1.1" class="ltx_tr">
<td id="S4.T6.st2.5.5.6.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T6.st2.5.5.6.1.2.1.1.1.1" class="ltx_text" style="font-size:70%;">% imgs</span></td>
</tr>
<tr id="S4.T6.st2.5.5.6.1.2.1.2" class="ltx_tr">
<td id="S4.T6.st2.5.5.6.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T6.st2.5.5.6.1.2.1.2.1.1" class="ltx_text" style="font-size:70%;">kept</span></td>
</tr>
</table>
</th>
<th id="S4.T6.st2.5.5.6.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S4.T6.st2.5.5.6.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T6.st2.5.5.6.1.3.1.1" class="ltx_tr">
<td id="S4.T6.st2.5.5.6.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T6.st2.5.5.6.1.3.1.1.1.1" class="ltx_text" style="font-size:70%;">Test</span></td>
</tr>
<tr id="S4.T6.st2.5.5.6.1.3.1.2" class="ltx_tr">
<td id="S4.T6.st2.5.5.6.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S4.T6.st2.5.5.6.1.3.1.2.1.1" class="ltx_text" style="font-size:70%;">accuracy</span></td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T6.st2.1.1.1" class="ltx_tr">
<th id="S4.T6.st2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><math id="S4.T6.st2.1.1.1.1.m1.1" class="ltx_Math" alttext="&lt;20" display="inline"><semantics id="S4.T6.st2.1.1.1.1.m1.1a"><mrow id="S4.T6.st2.1.1.1.1.m1.1.1" xref="S4.T6.st2.1.1.1.1.m1.1.1.cmml"><mi id="S4.T6.st2.1.1.1.1.m1.1.1.2" xref="S4.T6.st2.1.1.1.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S4.T6.st2.1.1.1.1.m1.1.1.1" xref="S4.T6.st2.1.1.1.1.m1.1.1.1.cmml">&lt;</mo><mn mathsize="70%" id="S4.T6.st2.1.1.1.1.m1.1.1.3" xref="S4.T6.st2.1.1.1.1.m1.1.1.3.cmml">20</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.st2.1.1.1.1.m1.1b"><apply id="S4.T6.st2.1.1.1.1.m1.1.1.cmml" xref="S4.T6.st2.1.1.1.1.m1.1.1"><lt id="S4.T6.st2.1.1.1.1.m1.1.1.1.cmml" xref="S4.T6.st2.1.1.1.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S4.T6.st2.1.1.1.1.m1.1.1.2.cmml" xref="S4.T6.st2.1.1.1.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S4.T6.st2.1.1.1.1.m1.1.1.3.cmml" xref="S4.T6.st2.1.1.1.1.m1.1.1.3">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.st2.1.1.1.1.m1.1c">&lt;20</annotation></semantics></math></th>
<td id="S4.T6.st2.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T6.st2.1.1.1.2.1" class="ltx_text" style="font-size:70%;">84.12</span></td>
<td id="S4.T6.st2.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T6.st2.1.1.1.3.1" class="ltx_text" style="font-size:70%;">73.03</span></td>
</tr>
<tr id="S4.T6.st2.2.2.2" class="ltx_tr">
<th id="S4.T6.st2.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S4.T6.st2.2.2.2.1.m1.1" class="ltx_Math" alttext="&lt;18" display="inline"><semantics id="S4.T6.st2.2.2.2.1.m1.1a"><mrow id="S4.T6.st2.2.2.2.1.m1.1.1" xref="S4.T6.st2.2.2.2.1.m1.1.1.cmml"><mi id="S4.T6.st2.2.2.2.1.m1.1.1.2" xref="S4.T6.st2.2.2.2.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S4.T6.st2.2.2.2.1.m1.1.1.1" xref="S4.T6.st2.2.2.2.1.m1.1.1.1.cmml">&lt;</mo><mn mathsize="70%" id="S4.T6.st2.2.2.2.1.m1.1.1.3" xref="S4.T6.st2.2.2.2.1.m1.1.1.3.cmml">18</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.st2.2.2.2.1.m1.1b"><apply id="S4.T6.st2.2.2.2.1.m1.1.1.cmml" xref="S4.T6.st2.2.2.2.1.m1.1.1"><lt id="S4.T6.st2.2.2.2.1.m1.1.1.1.cmml" xref="S4.T6.st2.2.2.2.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S4.T6.st2.2.2.2.1.m1.1.1.2.cmml" xref="S4.T6.st2.2.2.2.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S4.T6.st2.2.2.2.1.m1.1.1.3.cmml" xref="S4.T6.st2.2.2.2.1.m1.1.1.3">18</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.st2.2.2.2.1.m1.1c">&lt;18</annotation></semantics></math></th>
<td id="S4.T6.st2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.st2.2.2.2.2.1" class="ltx_text" style="font-size:70%;">72.41</span></td>
<td id="S4.T6.st2.2.2.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.st2.2.2.2.3.1" class="ltx_text" style="font-size:70%;">67.09</span></td>
</tr>
<tr id="S4.T6.st2.3.3.3" class="ltx_tr">
<th id="S4.T6.st2.3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S4.T6.st2.3.3.3.1.m1.1" class="ltx_Math" alttext="&lt;16" display="inline"><semantics id="S4.T6.st2.3.3.3.1.m1.1a"><mrow id="S4.T6.st2.3.3.3.1.m1.1.1" xref="S4.T6.st2.3.3.3.1.m1.1.1.cmml"><mi id="S4.T6.st2.3.3.3.1.m1.1.1.2" xref="S4.T6.st2.3.3.3.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S4.T6.st2.3.3.3.1.m1.1.1.1" xref="S4.T6.st2.3.3.3.1.m1.1.1.1.cmml">&lt;</mo><mn mathsize="70%" id="S4.T6.st2.3.3.3.1.m1.1.1.3" xref="S4.T6.st2.3.3.3.1.m1.1.1.3.cmml">16</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.st2.3.3.3.1.m1.1b"><apply id="S4.T6.st2.3.3.3.1.m1.1.1.cmml" xref="S4.T6.st2.3.3.3.1.m1.1.1"><lt id="S4.T6.st2.3.3.3.1.m1.1.1.1.cmml" xref="S4.T6.st2.3.3.3.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S4.T6.st2.3.3.3.1.m1.1.1.2.cmml" xref="S4.T6.st2.3.3.3.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S4.T6.st2.3.3.3.1.m1.1.1.3.cmml" xref="S4.T6.st2.3.3.3.1.m1.1.1.3">16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.st2.3.3.3.1.m1.1c">&lt;16</annotation></semantics></math></th>
<td id="S4.T6.st2.3.3.3.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.st2.3.3.3.2.1" class="ltx_text" style="font-size:70%;">59.22</span></td>
<td id="S4.T6.st2.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.st2.3.3.3.3.1" class="ltx_text" style="font-size:70%;">63.71</span></td>
</tr>
<tr id="S4.T6.st2.4.4.4" class="ltx_tr">
<th id="S4.T6.st2.4.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S4.T6.st2.4.4.4.1.m1.1" class="ltx_Math" alttext="&lt;14" display="inline"><semantics id="S4.T6.st2.4.4.4.1.m1.1a"><mrow id="S4.T6.st2.4.4.4.1.m1.1.1" xref="S4.T6.st2.4.4.4.1.m1.1.1.cmml"><mi id="S4.T6.st2.4.4.4.1.m1.1.1.2" xref="S4.T6.st2.4.4.4.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S4.T6.st2.4.4.4.1.m1.1.1.1" xref="S4.T6.st2.4.4.4.1.m1.1.1.1.cmml">&lt;</mo><mn mathsize="70%" id="S4.T6.st2.4.4.4.1.m1.1.1.3" xref="S4.T6.st2.4.4.4.1.m1.1.1.3.cmml">14</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.st2.4.4.4.1.m1.1b"><apply id="S4.T6.st2.4.4.4.1.m1.1.1.cmml" xref="S4.T6.st2.4.4.4.1.m1.1.1"><lt id="S4.T6.st2.4.4.4.1.m1.1.1.1.cmml" xref="S4.T6.st2.4.4.4.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S4.T6.st2.4.4.4.1.m1.1.1.2.cmml" xref="S4.T6.st2.4.4.4.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S4.T6.st2.4.4.4.1.m1.1.1.3.cmml" xref="S4.T6.st2.4.4.4.1.m1.1.1.3">14</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.st2.4.4.4.1.m1.1c">&lt;14</annotation></semantics></math></th>
<td id="S4.T6.st2.4.4.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.st2.4.4.4.2.1" class="ltx_text" style="font-size:70%;">39.78</span></td>
<td id="S4.T6.st2.4.4.4.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T6.st2.4.4.4.3.1" class="ltx_text" style="font-size:70%;">58.29</span></td>
</tr>
<tr id="S4.T6.st2.5.5.5" class="ltx_tr">
<th id="S4.T6.st2.5.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r"><math id="S4.T6.st2.5.5.5.1.m1.1" class="ltx_Math" alttext="&lt;12" display="inline"><semantics id="S4.T6.st2.5.5.5.1.m1.1a"><mrow id="S4.T6.st2.5.5.5.1.m1.1.1" xref="S4.T6.st2.5.5.5.1.m1.1.1.cmml"><mi id="S4.T6.st2.5.5.5.1.m1.1.1.2" xref="S4.T6.st2.5.5.5.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S4.T6.st2.5.5.5.1.m1.1.1.1" xref="S4.T6.st2.5.5.5.1.m1.1.1.1.cmml">&lt;</mo><mn mathsize="70%" id="S4.T6.st2.5.5.5.1.m1.1.1.3" xref="S4.T6.st2.5.5.5.1.m1.1.1.3.cmml">12</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.T6.st2.5.5.5.1.m1.1b"><apply id="S4.T6.st2.5.5.5.1.m1.1.1.cmml" xref="S4.T6.st2.5.5.5.1.m1.1.1"><lt id="S4.T6.st2.5.5.5.1.m1.1.1.1.cmml" xref="S4.T6.st2.5.5.5.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S4.T6.st2.5.5.5.1.m1.1.1.2.cmml" xref="S4.T6.st2.5.5.5.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S4.T6.st2.5.5.5.1.m1.1.1.3.cmml" xref="S4.T6.st2.5.5.5.1.m1.1.1.3">12</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T6.st2.5.5.5.1.m1.1c">&lt;12</annotation></semantics></math></th>
<td id="S4.T6.st2.5.5.5.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T6.st2.5.5.5.2.1" class="ltx_text" style="font-size:70%;">15.58</span></td>
<td id="S4.T6.st2.5.5.5.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S4.T6.st2.5.5.5.3.1" class="ltx_text" style="font-size:70%;">45.05</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S4.T6.st2.9.1.1" class="ltx_text" style="font-size:129%;">(b)</span> </span><span id="S4.T6.st2.10.2" class="ltx_text" style="font-size:129%;">PSNR below threshold</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T6.2.1.1" class="ltx_text" style="font-size:90%;">Table 6</span>: </span><span id="S4.T6.3.2" class="ltx_text" style="font-size:90%;"> Training models using CIFAR-10 leaked data from inverting gradients batch size 16. Only the reconstructions with a PSNR (a) above and (b) below the threshold are used in training.</span></figcaption>
</figure>
<div id="S4.SS7.p1" class="ltx_para">
<p id="S4.SS7.p1.1" class="ltx_p">Quality of reconstruction is an important concern for GI attacks. As the batch size continues to increase, the reconstruction quality decreases. Table <a href="#S4.T2.st1" title="Table 2(a) ‣ Table 2 ‣ 4.2 Leakage statistics ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2(a)</span></a> also shows this relationship. From the previous experiments, we also see a negative relationship between the increasing batch size and the usefulness of the leaked data in downstream model training.</p>
</div>
<div id="S4.SS7.p2" class="ltx_para">
<p id="S4.SS7.p2.4" class="ltx_p">Here, we explore whether poor quality reconstructions are still useful for training models. Using the CIFAR-10 leaked dataset created using Inverting Gradients on a batch size of 16, we first sort the reconstructions by their PSNR value. Our first set of experiments removes the worst images from training. Table <a href="#S4.T6.st1" title="Table 6(a) ‣ Table 6 ‣ 4.7 Quality of data reconstruction ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a> shows the percent of images above the PSNR threshold and the final test accuracy when trained on that data. Compared to the baseline accuracy of <math id="S4.SS7.p2.1.m1.1" class="ltx_Math" alttext="76.83\%" display="inline"><semantics id="S4.SS7.p2.1.m1.1a"><mrow id="S4.SS7.p2.1.m1.1.1" xref="S4.SS7.p2.1.m1.1.1.cmml"><mn id="S4.SS7.p2.1.m1.1.1.2" xref="S4.SS7.p2.1.m1.1.1.2.cmml">76.83</mn><mo id="S4.SS7.p2.1.m1.1.1.1" xref="S4.SS7.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS7.p2.1.m1.1b"><apply id="S4.SS7.p2.1.m1.1.1.cmml" xref="S4.SS7.p2.1.m1.1.1"><csymbol cd="latexml" id="S4.SS7.p2.1.m1.1.1.1.cmml" xref="S4.SS7.p2.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS7.p2.1.m1.1.1.2.cmml" xref="S4.SS7.p2.1.m1.1.1.2">76.83</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.p2.1.m1.1c">76.83\%</annotation></semantics></math> achieved by using the entire leaked dataset, even removing the worst images with a PSNR <math id="S4.SS7.p2.2.m2.1" class="ltx_Math" alttext="&lt;12" display="inline"><semantics id="S4.SS7.p2.2.m2.1a"><mrow id="S4.SS7.p2.2.m2.1.1" xref="S4.SS7.p2.2.m2.1.1.cmml"><mi id="S4.SS7.p2.2.m2.1.1.2" xref="S4.SS7.p2.2.m2.1.1.2.cmml"></mi><mo id="S4.SS7.p2.2.m2.1.1.1" xref="S4.SS7.p2.2.m2.1.1.1.cmml">&lt;</mo><mn id="S4.SS7.p2.2.m2.1.1.3" xref="S4.SS7.p2.2.m2.1.1.3.cmml">12</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS7.p2.2.m2.1b"><apply id="S4.SS7.p2.2.m2.1.1.cmml" xref="S4.SS7.p2.2.m2.1.1"><lt id="S4.SS7.p2.2.m2.1.1.1.cmml" xref="S4.SS7.p2.2.m2.1.1.1"></lt><csymbol cd="latexml" id="S4.SS7.p2.2.m2.1.1.2.cmml" xref="S4.SS7.p2.2.m2.1.1.2">absent</csymbol><cn type="integer" id="S4.SS7.p2.2.m2.1.1.3.cmml" xref="S4.SS7.p2.2.m2.1.1.3">12</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.p2.2.m2.1c">&lt;12</annotation></semantics></math> from the training set results in a small but non-zero performance loss.
Then we take a different look at this question by now training on the worst images.
Table <a href="#S4.T6.st2" title="Table 6(b) ‣ Table 6 ‣ 4.7 Quality of data reconstruction ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(b)</span></a> shows the test accuracy of models trained on all images <span id="S4.SS7.p2.4.1" class="ltx_text ltx_font_italic">below</span> a PSNR threshold. Even when training on the lowest quality images with a PSNR <math id="S4.SS7.p2.3.m3.1" class="ltx_Math" alttext="&lt;12" display="inline"><semantics id="S4.SS7.p2.3.m3.1a"><mrow id="S4.SS7.p2.3.m3.1.1" xref="S4.SS7.p2.3.m3.1.1.cmml"><mi id="S4.SS7.p2.3.m3.1.1.2" xref="S4.SS7.p2.3.m3.1.1.2.cmml"></mi><mo id="S4.SS7.p2.3.m3.1.1.1" xref="S4.SS7.p2.3.m3.1.1.1.cmml">&lt;</mo><mn id="S4.SS7.p2.3.m3.1.1.3" xref="S4.SS7.p2.3.m3.1.1.3.cmml">12</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS7.p2.3.m3.1b"><apply id="S4.SS7.p2.3.m3.1.1.cmml" xref="S4.SS7.p2.3.m3.1.1"><lt id="S4.SS7.p2.3.m3.1.1.1.cmml" xref="S4.SS7.p2.3.m3.1.1.1"></lt><csymbol cd="latexml" id="S4.SS7.p2.3.m3.1.1.2.cmml" xref="S4.SS7.p2.3.m3.1.1.2">absent</csymbol><cn type="integer" id="S4.SS7.p2.3.m3.1.1.3.cmml" xref="S4.SS7.p2.3.m3.1.1.3">12</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.p2.3.m3.1c">&lt;12</annotation></semantics></math>, the model achieves a <math id="S4.SS7.p2.4.m4.1" class="ltx_Math" alttext="45.05\%" display="inline"><semantics id="S4.SS7.p2.4.m4.1a"><mrow id="S4.SS7.p2.4.m4.1.1" xref="S4.SS7.p2.4.m4.1.1.cmml"><mn id="S4.SS7.p2.4.m4.1.1.2" xref="S4.SS7.p2.4.m4.1.1.2.cmml">45.05</mn><mo id="S4.SS7.p2.4.m4.1.1.1" xref="S4.SS7.p2.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS7.p2.4.m4.1b"><apply id="S4.SS7.p2.4.m4.1.1.cmml" xref="S4.SS7.p2.4.m4.1.1"><csymbol cd="latexml" id="S4.SS7.p2.4.m4.1.1.1.cmml" xref="S4.SS7.p2.4.m4.1.1.1">percent</csymbol><cn type="float" id="S4.SS7.p2.4.m4.1.1.2.cmml" xref="S4.SS7.p2.4.m4.1.1.2">45.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.p2.4.m4.1c">45.05\%</annotation></semantics></math> final testing accuracy, significantly worse than the baseline, but much above zero.</p>
</div>
<div id="S4.SS7.p3" class="ltx_para">
<p id="S4.SS7.p3.1" class="ltx_p">From the previous results, we see that even leaked data with a low reconstruction quality is still useful to the model training process.
This message is a new insight — all prior works when calculating the leak rate do not count poorly reconstructed images.
We additionally include results using SSIM in the supplementary section. Visual examples of poor quality reconstructions used to train the models are also included in the supplement.</p>
</div>
</section>
<section id="S4.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.8 </span>Observations on reconstruction quality trends</h3>

<figure id="S4.F5" class="ltx_figure"><img src="/html/2403.18144/assets/x8.png" id="S4.F5.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="149" height="45" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.3.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.4.2" class="ltx_text" style="font-size:90%;"> Reconstructions on CIFAR-10 from Inverting Gradients batch size 8. Ground truth images are on top and reconstructions are on the bottom. All labels in the batch are different and reconstructed images are high quality.</span></figcaption>
</figure>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2403.18144/assets/x9.png" id="S4.F6.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="149" height="45" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.3.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.4.2" class="ltx_text" style="font-size:90%;"> Reconstructions on CIFAR-10 from Inverting Gradients batch size 8. Duplicate labels exist between images 0, 4, 7 and images 2, 3. Reconstruction 3 contains parts of the content from both images 2 and 3. Reconstructions 0, 4, and 7 appear almost as noise. However, the other images still have reasonable quality.</span></figcaption>
</figure>
<div id="S4.SS8.p1" class="ltx_para">
<p id="S4.SS8.p1.1" class="ltx_p">We additionally note a few trends manually observed when going through the GI batch reconstructions of CIFAR-10.</p>
</div>
<div id="S4.SS8.p2" class="ltx_para">
<p id="S4.SS8.p2.1" class="ltx_p">While some reconstructions have very low quality, only images of the same label will be swapped within the batch during label matching. This is a desirable property for training on leaked data. As long as the set of labels is leaked correctly, the optimization process will match images to a correct label.
So even though the image quality is poor (and can be entirely unrecognizable), since the label is correctly matched, such an image still does help in the training (this buttresses the message from Tables <a href="#S4.T6.st1" title="Table 6(a) ‣ Table 6 ‣ 4.7 Quality of data reconstruction ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a> and <a href="#S4.T6.st2" title="Table 6(b) ‣ Table 6 ‣ 4.7 Quality of data reconstruction ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(b)</span></a>). Naturally, as the PSNR goes down, the image helps less and less.</p>
</div>
<div id="S4.SS8.p3" class="ltx_para">
<p id="S4.SS8.p3.1" class="ltx_p">We also note that when all labels are different within a batch, the reconstruction quality of the entire batch of images is almost always good. An example on CIFAR-10 is shown in Figure <a href="#S4.F5" title="Figure 5 ‣ 4.8 Observations on reconstruction quality trends ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. Usually when the reconstructions are poor, it occurs between groups of images in the same batch that belong to the same class. Poor reconstructions can appear as almost entirely noise, but occasionally images can have visible pieces of each image from the same class in the batch stitched together. The example batch in Figure <a href="#S4.F6" title="Figure 6 ‣ 4.8 Observations on reconstruction quality trends ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> depicts these properties of poorly reconstructed images. As a side note, we observe that a batch may have a mix of well reconstructed and poorly reconstructed images. We also note that the reverse mapping of the same label images to poor reconstructions is not true — having duplicate labels does not always imply that the reconstructions will be bad.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">As a main goal of our work, we have explored the effect of leaked data through today’s leading data reconstruction attacks on downstream model training. Our main message is that it is important to also consider the use of data beyond reconstruction quality and image similarity. It is important to consider how far these leaked samples help in a downstream training task. From the experiments, we have seen that current reconstruction attacks are powerful, but still lack in several critical areas. For gradient inversion attacks, the reconstruction quality does pose an issue for training models. Another impediment to practical use of this attack type is the time and computational cost.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.3" class="ltx_p">Linear layer leakage attacks do not suffer from reconstruction quality issues and are much lighter weight computationally, but still suffer from other challenges. While LOKI has increased the efficiency of the FC layer leakage in FedAvg, there is still room for improvement (especially in FedSGD). As shown in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">29</span></a>]</cite>, the model size overhead added by these attacks can be very large, especially if secure aggregation is used. Furthermore, the lack of labels poses a large challenge in training models on the data. With a small dataset like CIFAR-10, hand labeling 40 images is not too challenging. However, larger datasets will require more total labels. For example, SimMatch with <math id="S5.p2.1.m1.1" class="ltx_Math" alttext="1\%" display="inline"><semantics id="S5.p2.1.m1.1a"><mrow id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml"><mn id="S5.p2.1.m1.1.1.2" xref="S5.p2.1.m1.1.1.2.cmml">1</mn><mo id="S5.p2.1.m1.1.1.1" xref="S5.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><apply id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1"><csymbol cd="latexml" id="S5.p2.1.m1.1.1.1.cmml" xref="S5.p2.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S5.p2.1.m1.1.1.2.cmml" xref="S5.p2.1.m1.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">1\%</annotation></semantics></math> of labels on ImageNet can achieve <math id="S5.p2.2.m2.1" class="ltx_Math" alttext="67.2\%" display="inline"><semantics id="S5.p2.2.m2.1a"><mrow id="S5.p2.2.m2.1.1" xref="S5.p2.2.m2.1.1.cmml"><mn id="S5.p2.2.m2.1.1.2" xref="S5.p2.2.m2.1.1.2.cmml">67.2</mn><mo id="S5.p2.2.m2.1.1.1" xref="S5.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.2.m2.1b"><apply id="S5.p2.2.m2.1.1.cmml" xref="S5.p2.2.m2.1.1"><csymbol cd="latexml" id="S5.p2.2.m2.1.1.1.cmml" xref="S5.p2.2.m2.1.1.1">percent</csymbol><cn type="float" id="S5.p2.2.m2.1.1.2.cmml" xref="S5.p2.2.m2.1.1.2">67.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.2.m2.1c">67.2\%</annotation></semantics></math> top-1 accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">31</span></a>]</cite>. However, even <math id="S5.p2.3.m3.1" class="ltx_Math" alttext="1\%" display="inline"><semantics id="S5.p2.3.m3.1a"><mrow id="S5.p2.3.m3.1.1" xref="S5.p2.3.m3.1.1.cmml"><mn id="S5.p2.3.m3.1.1.2" xref="S5.p2.3.m3.1.1.2.cmml">1</mn><mo id="S5.p2.3.m3.1.1.1" xref="S5.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.3.m3.1b"><apply id="S5.p2.3.m3.1.1.cmml" xref="S5.p2.3.m3.1.1"><csymbol cd="latexml" id="S5.p2.3.m3.1.1.1.cmml" xref="S5.p2.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S5.p2.3.m3.1.1.2.cmml" xref="S5.p2.3.m3.1.1.2">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.3.m3.1c">1\%</annotation></semantics></math> of the total images in ImageNet-1k is 12,812 images. Even if the images were leaked, hand labeling would be extremely hard. Furthermore, we see from Figure <a href="#S4.F3.sf1" title="Figure 3(a) ‣ Figure 3 ‣ 4.5 Training with semi-supervised learning ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a> that having less total data and fewer labels results in an even steeper decrease in performance.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">While not discussed previously, there are many other aspects that affect data reconstruction attacks when considering training models. For example, how does the non-IID aspect of client data affect reconstruction? Other relevant settings of federated learning such as asynchronous federated learning, client selection, and differential privacy can also affect the final leaked dataset. Centralized training also allows for more complex and larger models without the communication or computational restrictions of clients in federated learning. These topics can be explored in future work.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.6" class="ltx_p">We examine data reconstruction attacks through the lens of training models on the leaked data. While highlighting how the weaknesses of gradient inversion in terms of reconstruction quality affect downstream model training, we also show that even poorly reconstructed images are useful for training. We also discuss how the label matching problem for linear layer leakage can be mitigated through semi-supervised learning. Under ideal conditions, we demonstrate that leaked data from both gradient inversion and linear layer leakage attacks are able to train powerful models comparable to even a centralized baseline. On CIFAR-10, gradient inversion and linear layer leakage attacks achieve <math id="S6.p1.1.m1.1" class="ltx_Math" alttext="90.34\%" display="inline"><semantics id="S6.p1.1.m1.1a"><mrow id="S6.p1.1.m1.1.1" xref="S6.p1.1.m1.1.1.cmml"><mn id="S6.p1.1.m1.1.1.2" xref="S6.p1.1.m1.1.1.2.cmml">90.34</mn><mo id="S6.p1.1.m1.1.1.1" xref="S6.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.p1.1.m1.1b"><apply id="S6.p1.1.m1.1.1.cmml" xref="S6.p1.1.m1.1.1"><csymbol cd="latexml" id="S6.p1.1.m1.1.1.1.cmml" xref="S6.p1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S6.p1.1.m1.1.1.2.cmml" xref="S6.p1.1.m1.1.1.2">90.34</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.m1.1c">90.34\%</annotation></semantics></math> and <math id="S6.p1.2.m2.1" class="ltx_Math" alttext="93.16\%" display="inline"><semantics id="S6.p1.2.m2.1a"><mrow id="S6.p1.2.m2.1.1" xref="S6.p1.2.m2.1.1.cmml"><mn id="S6.p1.2.m2.1.1.2" xref="S6.p1.2.m2.1.1.2.cmml">93.16</mn><mo id="S6.p1.2.m2.1.1.1" xref="S6.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.p1.2.m2.1b"><apply id="S6.p1.2.m2.1.1.cmml" xref="S6.p1.2.m2.1.1"><csymbol cd="latexml" id="S6.p1.2.m2.1.1.1.cmml" xref="S6.p1.2.m2.1.1.1">percent</csymbol><cn type="float" id="S6.p1.2.m2.1.1.2.cmml" xref="S6.p1.2.m2.1.1.2">93.16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.2.m2.1c">93.16\%</annotation></semantics></math> testing accuracy respectively, <math id="S6.p1.3.m3.1" class="ltx_Math" alttext="17.58\%" display="inline"><semantics id="S6.p1.3.m3.1a"><mrow id="S6.p1.3.m3.1.1" xref="S6.p1.3.m3.1.1.cmml"><mn id="S6.p1.3.m3.1.1.2" xref="S6.p1.3.m3.1.1.2.cmml">17.58</mn><mo id="S6.p1.3.m3.1.1.1" xref="S6.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.p1.3.m3.1b"><apply id="S6.p1.3.m3.1.1.cmml" xref="S6.p1.3.m3.1.1"><csymbol cd="latexml" id="S6.p1.3.m3.1.1.1.cmml" xref="S6.p1.3.m3.1.1.1">percent</csymbol><cn type="float" id="S6.p1.3.m3.1.1.2.cmml" xref="S6.p1.3.m3.1.1.2">17.58</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.3.m3.1c">17.58\%</annotation></semantics></math> and <math id="S6.p1.4.m4.1" class="ltx_Math" alttext="20.40\%" display="inline"><semantics id="S6.p1.4.m4.1a"><mrow id="S6.p1.4.m4.1.1" xref="S6.p1.4.m4.1.1.cmml"><mn id="S6.p1.4.m4.1.1.2" xref="S6.p1.4.m4.1.1.2.cmml">20.40</mn><mo id="S6.p1.4.m4.1.1.1" xref="S6.p1.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.p1.4.m4.1b"><apply id="S6.p1.4.m4.1.1.cmml" xref="S6.p1.4.m4.1.1"><csymbol cd="latexml" id="S6.p1.4.m4.1.1.1.cmml" xref="S6.p1.4.m4.1.1.1">percent</csymbol><cn type="float" id="S6.p1.4.m4.1.1.2.cmml" xref="S6.p1.4.m4.1.1.2">20.40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.4.m4.1c">20.40\%</annotation></semantics></math> higher than federated learning and only <math id="S6.p1.5.m5.1" class="ltx_Math" alttext="4.04\%" display="inline"><semantics id="S6.p1.5.m5.1a"><mrow id="S6.p1.5.m5.1.1" xref="S6.p1.5.m5.1.1.cmml"><mn id="S6.p1.5.m5.1.1.2" xref="S6.p1.5.m5.1.1.2.cmml">4.04</mn><mo id="S6.p1.5.m5.1.1.1" xref="S6.p1.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.p1.5.m5.1b"><apply id="S6.p1.5.m5.1.1.cmml" xref="S6.p1.5.m5.1.1"><csymbol cd="latexml" id="S6.p1.5.m5.1.1.1.cmml" xref="S6.p1.5.m5.1.1.1">percent</csymbol><cn type="float" id="S6.p1.5.m5.1.1.2.cmml" xref="S6.p1.5.m5.1.1.2">4.04</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.5.m5.1c">4.04\%</annotation></semantics></math> and <math id="S6.p1.6.m6.1" class="ltx_Math" alttext="1.22\%" display="inline"><semantics id="S6.p1.6.m6.1a"><mrow id="S6.p1.6.m6.1.1" xref="S6.p1.6.m6.1.1.cmml"><mn id="S6.p1.6.m6.1.1.2" xref="S6.p1.6.m6.1.1.2.cmml">1.22</mn><mo id="S6.p1.6.m6.1.1.1" xref="S6.p1.6.m6.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.p1.6.m6.1b"><apply id="S6.p1.6.m6.1.1.cmml" xref="S6.p1.6.m6.1.1"><csymbol cd="latexml" id="S6.p1.6.m6.1.1.1.cmml" xref="S6.p1.6.m6.1.1.1">percent</csymbol><cn type="float" id="S6.p1.6.m6.1.1.2.cmml" xref="S6.p1.6.m6.1.1.2">1.22</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.6.m6.1c">1.22\%</annotation></semantics></math> lower compared to centralized training.</p>
</div>
<div id="S6.p2" class="ltx_para ltx_noindent">
<p id="S6.p2.1" class="ltx_p"><span id="S6.p2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">Acknowledgements.</span><span id="S6.p2.1.2" class="ltx_text" style="font-size:90%;"> This material is based in part upon work supported by Adobe Research, the Army Research Office under Contract number W911NF-2020-221, and the National Science Foundation under Grant Number CCF-1919197. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views of the sponsors.</span><span id="S6.p2.1.3" class="ltx_text"></span></p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib1.5.5.1" class="ltx_text" style="font-size:90%;">Boenisch et al. [2023]</span></span>
<span class="ltx_bibblock"><span id="bib.bib1.7.1" class="ltx_text" style="font-size:90%;">
Franziska Boenisch, Adam Dziedzic, Roei Schuster, Ali Shahin Shamsabadi, Ilia Shumailov, and Nicolas Papernot.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.8.1" class="ltx_text" style="font-size:90%;">When the curious abandon honesty: Federated learning is not private.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib1.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">8th IEEE European Symposium on Security and Privacy (IEEE Euro S&amp;P)</em><span id="bib.bib1.10.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib2.5.5.1" class="ltx_text" style="font-size:90%;">Bonawitz et al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib2.7.1" class="ltx_text" style="font-size:90%;">
Keith Bonawitz, Vladimir Ivanov, Ben Kreuter, Antonio Marcedone, H Brendan McMahan, Sarvar Patel, Daniel Ramage, Aaron Segal, and Karn Seth.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.8.1" class="ltx_text" style="font-size:90%;">Practical secure aggregation for privacy-preserving machine learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib2.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security</em><span id="bib.bib2.11.3" class="ltx_text" style="font-size:90%;">, pages 1175–1191, 2017.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib3.5.5.1" class="ltx_text" style="font-size:90%;">Choquette-Choo et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib3.7.1" class="ltx_text" style="font-size:90%;">
Christopher A Choquette-Choo, Florian Tramer, Nicholas Carlini, and Nicolas Papernot.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.8.1" class="ltx_text" style="font-size:90%;">Label-only membership inference attacks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib3.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International conference on machine learning</em><span id="bib.bib3.11.3" class="ltx_text" style="font-size:90%;">, pages 1964–1974. PMLR, 2021.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib4.5.5.1" class="ltx_text" style="font-size:90%;">Fan et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib4.7.1" class="ltx_text" style="font-size:90%;">
Lixin Fan, Kam Woh Ng, Ce Ju, Tianyu Zhang, Chang Liu, Chee Seng Chan, and Qiang Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.8.1" class="ltx_text" style="font-size:90%;">Rethinking privacy preserving deep learning: How to evaluate and thwart privacy attacks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib4.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Federated Learning</em><span id="bib.bib4.11.3" class="ltx_text" style="font-size:90%;">, pages 32–50. Springer, 2020.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib5.5.5.1" class="ltx_text" style="font-size:90%;">Fowl et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib5.7.1" class="ltx_text" style="font-size:90%;">
Liam H Fowl, Jonas Geiping, Wojciech Czaja, Micah Goldblum, and Tom Goldstein.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.8.1" class="ltx_text" style="font-size:90%;">Robbing the fed: Directly obtaining private data in federated learning with modified models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib5.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Conference on Learning Representations</em><span id="bib.bib5.11.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib6.5.5.1" class="ltx_text" style="font-size:90%;">Geiping et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib6.7.1" class="ltx_text" style="font-size:90%;">
Jonas Geiping, Hartmut Bauermeister, Hannah Dröge, and Michael Moeller.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.8.1" class="ltx_text" style="font-size:90%;">Inverting gradients-how easy is it to break privacy in federated learning?
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib6.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span id="bib.bib6.10.2" class="ltx_text" style="font-size:90%;">, 33:16937–16947, 2020.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib7.5.5.1" class="ltx_text" style="font-size:90%;">Geng et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib7.7.1" class="ltx_text" style="font-size:90%;">
Jiahui Geng, Yongli Mou, Feifei Li, Qing Li, Oya Beyan, Stefan Decker, and Chunming Rong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.8.1" class="ltx_text" style="font-size:90%;">Towards general deep leakage in federated learning.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib7.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2110.09074</em><span id="bib.bib7.10.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib8.5.5.1" class="ltx_text" style="font-size:90%;">He et al. [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib8.7.1" class="ltx_text" style="font-size:90%;">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.8.1" class="ltx_text" style="font-size:90%;">Deep residual learning for image recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib8.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and pattern recognition</em><span id="bib.bib8.11.3" class="ltx_text" style="font-size:90%;">, pages 770–778, 2016.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib9.5.5.1" class="ltx_text" style="font-size:90%;">Hitaj et al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib9.7.1" class="ltx_text" style="font-size:90%;">
Briland Hitaj, Giuseppe Ateniese, and Fernando Perez-Cruz.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.8.1" class="ltx_text" style="font-size:90%;">Deep models under the gan: information leakage from collaborative deep learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib9.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 2017 ACM SIGSAC conference on computer and communications security</em><span id="bib.bib9.11.3" class="ltx_text" style="font-size:90%;">, pages 603–618, 2017.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib10.5.5.1" class="ltx_text" style="font-size:90%;">Huang et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib10.7.1" class="ltx_text" style="font-size:90%;">
Yangsibo Huang, Samyak Gupta, Zhao Song, Kai Li, and Sanjeev Arora.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.8.1" class="ltx_text" style="font-size:90%;">Evaluating gradient inversion attacks and defenses in federated learning.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib10.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems</em><span id="bib.bib10.10.2" class="ltx_text" style="font-size:90%;">, 34:7232–7241, 2021.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib11.5.5.1" class="ltx_text" style="font-size:90%;">Krizhevsky et al. [2009]</span></span>
<span class="ltx_bibblock"><span id="bib.bib11.7.1" class="ltx_text" style="font-size:90%;">
Alex Krizhevsky, Geoffrey Hinton, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.8.1" class="ltx_text" style="font-size:90%;">Learning multiple layers of features from tiny images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.9.1" class="ltx_text" style="font-size:90%;">Master’s thesis, University of Toronto, 2009.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib12.4.4.1" class="ltx_text" style="font-size:90%;">Le and Yang [2015]</span></span>
<span class="ltx_bibblock"><span id="bib.bib12.6.1" class="ltx_text" style="font-size:90%;">
Ya Le and Xuan Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.7.1" class="ltx_text" style="font-size:90%;">Tiny imagenet visual recognition challenge.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib12.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">CS 231N</em><span id="bib.bib12.9.2" class="ltx_text" style="font-size:90%;">, 7(7):3, 2015.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib13.4.4.1" class="ltx_text" style="font-size:90%;">LeCun [1998]</span></span>
<span class="ltx_bibblock"><span id="bib.bib13.6.1" class="ltx_text" style="font-size:90%;">
Yann LeCun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.7.1" class="ltx_text" style="font-size:90%;">The mnist database of handwritten digits.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib13.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">http://yann. lecun. com/exdb/mnist/</em><span id="bib.bib13.9.2" class="ltx_text" style="font-size:90%;">, 1998.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib14.5.5.1" class="ltx_text" style="font-size:90%;">Li et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib14.7.1" class="ltx_text" style="font-size:90%;">
Junnan Li, Caiming Xiong, and Steven CH Hoi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.8.1" class="ltx_text" style="font-size:90%;">Comatch: Semi-supervised learning with contrastive graph regularization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib14.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on Computer Vision</em><span id="bib.bib14.11.3" class="ltx_text" style="font-size:90%;">, pages 9475–9484, 2021.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib15.5.5.1" class="ltx_text" style="font-size:90%;">Luo et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib15.7.1" class="ltx_text" style="font-size:90%;">
Xinjian Luo, Yuncheng Wu, Xiaokui Xiao, and Beng Chin Ooi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.8.1" class="ltx_text" style="font-size:90%;">Feature inference attack on model predictions in vertical federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib15.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2021 IEEE 37th International Conference on Data Engineering (ICDE)</em><span id="bib.bib15.11.3" class="ltx_text" style="font-size:90%;">, pages 181–192. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib16.5.5.1" class="ltx_text" style="font-size:90%;">Ma et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib16.7.1" class="ltx_text" style="font-size:90%;">
Kailang Ma, Yu Sun, Jian Cui, Dawei Li, Zhenyu Guan, and Jianwei Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.8.1" class="ltx_text" style="font-size:90%;">Instance-wise batch label restoration via gradients in federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib16.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">The Eleventh International Conference on Learning Representations</em><span id="bib.bib16.11.3" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib17.5.5.1" class="ltx_text" style="font-size:90%;">McMahan et al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib17.7.1" class="ltx_text" style="font-size:90%;">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.8.1" class="ltx_text" style="font-size:90%;">Communication-efficient learning of deep networks from decentralized data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib17.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Artificial intelligence and statistics</em><span id="bib.bib17.11.3" class="ltx_text" style="font-size:90%;">, pages 1273–1282. PMLR, 2017.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib18.5.5.1" class="ltx_text" style="font-size:90%;">Melis et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib18.7.1" class="ltx_text" style="font-size:90%;">
Luca Melis, Congzheng Song, Emiliano De Cristofaro, and Vitaly Shmatikov.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.8.1" class="ltx_text" style="font-size:90%;">Exploiting unintended feature leakage in collaborative learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib18.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2019 IEEE symposium on security and privacy (SP)</em><span id="bib.bib18.11.3" class="ltx_text" style="font-size:90%;">, pages 691–706. IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib19.5.5.1" class="ltx_text" style="font-size:90%;">Nasr et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib19.7.1" class="ltx_text" style="font-size:90%;">
Milad Nasr, Reza Shokri, and Amir Houmansadr.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.8.1" class="ltx_text" style="font-size:90%;">Comprehensive privacy analysis of deep learning: Passive and active white-box inference attacks against centralized and federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib19.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2019 IEEE symposium on security and privacy (SP)</em><span id="bib.bib19.11.3" class="ltx_text" style="font-size:90%;">, pages 739–753. IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib20.5.5.1" class="ltx_text" style="font-size:90%;">Pasquini et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib20.7.1" class="ltx_text" style="font-size:90%;">
Dario Pasquini, Danilo Francati, and Giuseppe Ateniese.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.8.1" class="ltx_text" style="font-size:90%;">Eluding secure aggregation in federated learning via model inconsistency.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib20.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security</em><span id="bib.bib20.11.3" class="ltx_text" style="font-size:90%;">, pages 2429–2443, 2022.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib21.5.5.1" class="ltx_text" style="font-size:90%;">Phong et al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib21.7.1" class="ltx_text" style="font-size:90%;">
Le Trieu Phong, Yoshinori Aono, Takuya Hayashi, Lihua Wang, and Shiho Moriai.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.8.1" class="ltx_text" style="font-size:90%;">Privacy-preserving deep learning: Revisited and enhanced.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib21.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Conference on Applications and Techniques in Information Security</em><span id="bib.bib21.11.3" class="ltx_text" style="font-size:90%;">, pages 100–110. Springer, 2017.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib22.5.5.1" class="ltx_text" style="font-size:90%;">Shokri et al. [2017]</span></span>
<span class="ltx_bibblock"><span id="bib.bib22.7.1" class="ltx_text" style="font-size:90%;">
Reza Shokri, Marco Stronati, Congzheng Song, and Vitaly Shmatikov.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.8.1" class="ltx_text" style="font-size:90%;">Membership inference attacks against machine learning models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib22.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2017 IEEE symposium on security and privacy (SP)</em><span id="bib.bib22.11.3" class="ltx_text" style="font-size:90%;">, pages 3–18. IEEE, 2017.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib23.5.5.1" class="ltx_text" style="font-size:90%;">Wang et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib23.7.1" class="ltx_text" style="font-size:90%;">
Zhibo Wang, Mengkai Song, Zhifei Zhang, Yang Song, Qian Wang, and Hairong Qi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.8.1" class="ltx_text" style="font-size:90%;">Beyond inferring class representatives: User-level privacy leakage from federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib23.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">IEEE INFOCOM 2019-IEEE Conference on Computer Communications</em><span id="bib.bib23.11.3" class="ltx_text" style="font-size:90%;">, pages 2512–2520. IEEE, 2019.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib24.5.5.1" class="ltx_text" style="font-size:90%;">Wen et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib24.7.1" class="ltx_text" style="font-size:90%;">
Yuxin Wen, Jonas Geiping, Liam Fowl, Micah Goldblum, and Tom Goldstein.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.8.1" class="ltx_text" style="font-size:90%;">Fishing for user data in large-batch federated learning via gradient magnification.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib24.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">International Conference on Machine Learning</em><span id="bib.bib24.10.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib25.5.5.1" class="ltx_text" style="font-size:90%;">Yang et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib25.7.1" class="ltx_text" style="font-size:90%;">
Fan Yang, Kai Wu, Shuyi Zhang, Guannan Jiang, Yong Liu, Feng Zheng, Wei Zhang, Chengjie Wang, and Long Zeng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.8.1" class="ltx_text" style="font-size:90%;">Class-aware contrastive semi-supervised learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib25.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib25.11.3" class="ltx_text" style="font-size:90%;">, pages 14421–14430, 2022.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib26.5.5.1" class="ltx_text" style="font-size:90%;">Yin et al. [2021]</span></span>
<span class="ltx_bibblock"><span id="bib.bib26.7.1" class="ltx_text" style="font-size:90%;">
Hongxu Yin, Arun Mallya, Arash Vahdat, Jose M Alvarez, Jan Kautz, and Pavlo Molchanov.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.8.1" class="ltx_text" style="font-size:90%;">See through gradients: Image batch recovery via gradinversion.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib26.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib26.11.3" class="ltx_text" style="font-size:90%;">, pages 16337–16346, 2021.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib27.4.4.1" class="ltx_text" style="font-size:90%;">Zagoruyko and Komodakis [2016]</span></span>
<span class="ltx_bibblock"><span id="bib.bib27.6.1" class="ltx_text" style="font-size:90%;">
Sergey Zagoruyko and Nikos Komodakis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.7.1" class="ltx_text" style="font-size:90%;">Wide residual networks.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib27.8.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1605.07146</em><span id="bib.bib27.9.2" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib28.5.5.1" class="ltx_text" style="font-size:90%;">Zhao et al. [2020]</span></span>
<span class="ltx_bibblock"><span id="bib.bib28.7.1" class="ltx_text" style="font-size:90%;">
Bo Zhao, Konda Reddy Mopuri, and Hakan Bilen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.8.1" class="ltx_text" style="font-size:90%;">idlg: Improved deep leakage from gradients.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib28.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2001.02610</em><span id="bib.bib28.10.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib29.5.5.1" class="ltx_text" style="font-size:90%;">Zhao et al. [2023a]</span></span>
<span class="ltx_bibblock"><span id="bib.bib29.7.1" class="ltx_text" style="font-size:90%;">
Joshua C Zhao, Ahmed Roushdy Elkordy, Atul Sharma, Yahya H Ezzeldin, Salman Avestimehr, and Saurabh Bagchi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.8.1" class="ltx_text" style="font-size:90%;">The resource problem of using linear layer leakage attack in federated learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib29.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib29.11.3" class="ltx_text" style="font-size:90%;">, pages 3974–3983, 2023a.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib30.5.5.1" class="ltx_text" style="font-size:90%;">Zhao et al. [2023b]</span></span>
<span class="ltx_bibblock"><span id="bib.bib30.7.1" class="ltx_text" style="font-size:90%;">
Joshua Christian Zhao, Atul Sharma, Ahmed Roushdy Elkordy, Yahya H Ezzeldin, Salman Avestimehr, and Saurabh Bagchi.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.8.1" class="ltx_text" style="font-size:90%;">Loki: Large-scale data reconstruction attack against federated learning through model manipulation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib30.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">2024 IEEE Symposium on Security and Privacy (SP)</em><span id="bib.bib30.11.3" class="ltx_text" style="font-size:90%;">, pages 30–30. IEEE Computer Society, 2023b.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib31.5.5.1" class="ltx_text" style="font-size:90%;">Zheng et al. [2022]</span></span>
<span class="ltx_bibblock"><span id="bib.bib31.7.1" class="ltx_text" style="font-size:90%;">
Mingkai Zheng, Shan You, Lang Huang, Fei Wang, Chen Qian, and Chang Xu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.8.1" class="ltx_text" style="font-size:90%;">Simmatch: Semi-supervised learning with similarity matching.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.9.1" class="ltx_text" style="font-size:90%;">In </span><em id="bib.bib31.10.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition</em><span id="bib.bib31.11.3" class="ltx_text" style="font-size:90%;">, pages 14471–14481, 2022.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem"><span id="bib.bib32.5.5.1" class="ltx_text" style="font-size:90%;">Zhu et al. [2019]</span></span>
<span class="ltx_bibblock"><span id="bib.bib32.7.1" class="ltx_text" style="font-size:90%;">
Ligeng Zhu, Zhijian Liu, and Song Han.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.8.1" class="ltx_text" style="font-size:90%;">Deep leakage from gradients.
</span>
</span>
<span class="ltx_bibblock"><em id="bib.bib32.9.1" class="ltx_emph ltx_font_italic" style="font-size:90%;">Advances in neural information processing systems</em><span id="bib.bib32.10.2" class="ltx_text" style="font-size:90%;">, 32, 2019.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="p1" class="ltx_para ltx_noindent">
<span id="p1.1" class="ltx_ERROR undefined">\thetitle</span>
<br class="ltx_break ltx_centering">
<p id="p1.2" class="ltx_p ltx_align_center"><span id="p1.2.1" class="ltx_text" style="font-size:144%;">Supplementary Material 
<br class="ltx_break"></span></p>
</div>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:144%;">
<span class="ltx_tag ltx_tag_section">7 </span>Additional federated learning results</h2>

<figure id="S7.T7" class="ltx_table">
<table id="S7.T7.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S7.T7.4.1.1" class="ltx_tr">
<th id="S7.T7.4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" colspan="4"><span id="S7.T7.4.1.1.1.1" class="ltx_text" style="font-size:70%;">CIFAR-10</span></th>
</tr>
<tr id="S7.T7.4.2.2" class="ltx_tr">
<th id="S7.T7.4.2.2.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S7.T7.4.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">
<table id="S7.T7.4.2.2.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S7.T7.4.2.2.2.1.1" class="ltx_tr">
<td id="S7.T7.4.2.2.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S7.T7.4.2.2.2.1.1.1.1" class="ltx_text" style="font-size:70%;">Number</span></td>
</tr>
<tr id="S7.T7.4.2.2.2.1.2" class="ltx_tr">
<td id="S7.T7.4.2.2.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S7.T7.4.2.2.2.1.2.1.1" class="ltx_text" style="font-size:70%;">of clients</span></td>
</tr>
</table>
</th>
<th id="S7.T7.4.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S7.T7.4.2.2.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S7.T7.4.2.2.3.1.1" class="ltx_tr">
<td id="S7.T7.4.2.2.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S7.T7.4.2.2.3.1.1.1.1" class="ltx_text" style="font-size:70%;">IID (I) or</span></td>
</tr>
<tr id="S7.T7.4.2.2.3.1.2" class="ltx_tr">
<td id="S7.T7.4.2.2.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S7.T7.4.2.2.3.1.2.1.1" class="ltx_text" style="font-size:70%;">Non-IID (N)</span></td>
</tr>
</table>
</th>
<th id="S7.T7.4.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S7.T7.4.2.2.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S7.T7.4.2.2.4.1.1" class="ltx_tr">
<td id="S7.T7.4.2.2.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S7.T7.4.2.2.4.1.1.1.1" class="ltx_text" style="font-size:70%;">Test</span></td>
</tr>
<tr id="S7.T7.4.2.2.4.1.2" class="ltx_tr">
<td id="S7.T7.4.2.2.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S7.T7.4.2.2.4.1.2.1.1" class="ltx_text" style="font-size:70%;">Acc.</span></td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S7.T7.4.3.1" class="ltx_tr">
<th id="S7.T7.4.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S7.T7.4.3.1.1.1" class="ltx_text" style="font-size:70%;">FedAvg</span></th>
<th id="S7.T7.4.3.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S7.T7.4.3.1.2.1" class="ltx_text" style="font-size:70%;">10</span></th>
<td id="S7.T7.4.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.4.3.1.3.1" class="ltx_text" style="font-size:70%;">I</span></td>
<td id="S7.T7.4.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.4.3.1.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">75.13</span></td>
</tr>
<tr id="S7.T7.4.4.2" class="ltx_tr">
<th id="S7.T7.4.4.2.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S7.T7.4.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S7.T7.4.4.2.2.1" class="ltx_text" style="font-size:70%;">10</span></th>
<td id="S7.T7.4.4.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.4.2.3.1" class="ltx_text" style="font-size:70%;">N</span></td>
<td id="S7.T7.4.4.2.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.4.2.4.1" class="ltx_text" style="font-size:70%;">72.76</span></td>
</tr>
<tr id="S7.T7.4.5.3" class="ltx_tr">
<th id="S7.T7.4.5.3.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S7.T7.4.5.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S7.T7.4.5.3.2.1" class="ltx_text" style="font-size:70%;">50</span></th>
<td id="S7.T7.4.5.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.5.3.3.1" class="ltx_text" style="font-size:70%;">I</span></td>
<td id="S7.T7.4.5.3.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.5.3.4.1" class="ltx_text" style="font-size:70%;">71.45</span></td>
</tr>
<tr id="S7.T7.4.6.4" class="ltx_tr">
<th id="S7.T7.4.6.4.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S7.T7.4.6.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S7.T7.4.6.4.2.1" class="ltx_text" style="font-size:70%;">50</span></th>
<td id="S7.T7.4.6.4.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.6.4.3.1" class="ltx_text" style="font-size:70%;">N</span></td>
<td id="S7.T7.4.6.4.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.6.4.4.1" class="ltx_text" style="font-size:70%;">68.71</span></td>
</tr>
<tr id="S7.T7.4.7.5" class="ltx_tr">
<th id="S7.T7.4.7.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S7.T7.4.7.5.1.1" class="ltx_text" style="font-size:70%;">FedSGD</span></th>
<th id="S7.T7.4.7.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S7.T7.4.7.5.2.1" class="ltx_text" style="font-size:70%;">10</span></th>
<td id="S7.T7.4.7.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.4.7.5.3.1" class="ltx_text" style="font-size:70%;">I</span></td>
<td id="S7.T7.4.7.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.4.7.5.4.1" class="ltx_text" style="font-size:70%;">71.24</span></td>
</tr>
<tr id="S7.T7.4.8.6" class="ltx_tr">
<th id="S7.T7.4.8.6.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S7.T7.4.8.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S7.T7.4.8.6.2.1" class="ltx_text" style="font-size:70%;">10</span></th>
<td id="S7.T7.4.8.6.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.8.6.3.1" class="ltx_text" style="font-size:70%;">N</span></td>
<td id="S7.T7.4.8.6.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.8.6.4.1" class="ltx_text" style="font-size:70%;">68.78</span></td>
</tr>
<tr id="S7.T7.4.9.7" class="ltx_tr">
<th id="S7.T7.4.9.7.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S7.T7.4.9.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S7.T7.4.9.7.2.1" class="ltx_text" style="font-size:70%;">50</span></th>
<td id="S7.T7.4.9.7.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.9.7.3.1" class="ltx_text" style="font-size:70%;">I</span></td>
<td id="S7.T7.4.9.7.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.9.7.4.1" class="ltx_text" style="font-size:70%;">65.95</span></td>
</tr>
<tr id="S7.T7.4.10.8" class="ltx_tr">
<th id="S7.T7.4.10.8.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S7.T7.4.10.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S7.T7.4.10.8.2.1" class="ltx_text" style="font-size:70%;">50</span></th>
<td id="S7.T7.4.10.8.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.10.8.3.1" class="ltx_text" style="font-size:70%;">N</span></td>
<td id="S7.T7.4.10.8.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.10.8.4.1" class="ltx_text" style="font-size:70%;">60.88</span></td>
</tr>
<tr id="S7.T7.4.11.9" class="ltx_tr">
<th id="S7.T7.4.11.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" colspan="4"><span id="S7.T7.4.11.9.1.1" class="ltx_text" style="font-size:70%;">MNIST</span></th>
</tr>
<tr id="S7.T7.4.12.10" class="ltx_tr">
<th id="S7.T7.4.12.10.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S7.T7.4.12.10.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">
<table id="S7.T7.4.12.10.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S7.T7.4.12.10.2.1.1" class="ltx_tr">
<td id="S7.T7.4.12.10.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S7.T7.4.12.10.2.1.1.1.1" class="ltx_text" style="font-size:70%;">Number</span></td>
</tr>
<tr id="S7.T7.4.12.10.2.1.2" class="ltx_tr">
<td id="S7.T7.4.12.10.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S7.T7.4.12.10.2.1.2.1.1" class="ltx_text" style="font-size:70%;">of clients</span></td>
</tr>
</table>
</th>
<th id="S7.T7.4.12.10.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S7.T7.4.12.10.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S7.T7.4.12.10.3.1.1" class="ltx_tr">
<td id="S7.T7.4.12.10.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S7.T7.4.12.10.3.1.1.1.1" class="ltx_text" style="font-size:70%;">IID (I) or</span></td>
</tr>
<tr id="S7.T7.4.12.10.3.1.2" class="ltx_tr">
<td id="S7.T7.4.12.10.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S7.T7.4.12.10.3.1.2.1.1" class="ltx_text" style="font-size:70%;">Non-IID (N)</span></td>
</tr>
</table>
</th>
<th id="S7.T7.4.12.10.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S7.T7.4.12.10.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S7.T7.4.12.10.4.1.1" class="ltx_tr">
<td id="S7.T7.4.12.10.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S7.T7.4.12.10.4.1.1.1.1" class="ltx_text" style="font-size:70%;">Test</span></td>
</tr>
<tr id="S7.T7.4.12.10.4.1.2" class="ltx_tr">
<td id="S7.T7.4.12.10.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S7.T7.4.12.10.4.1.2.1.1" class="ltx_text" style="font-size:70%;">Acc.</span></td>
</tr>
</table>
</th>
</tr>
<tr id="S7.T7.4.13.11" class="ltx_tr">
<th id="S7.T7.4.13.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S7.T7.4.13.11.1.1" class="ltx_text" style="font-size:70%;">FedAvg</span></th>
<th id="S7.T7.4.13.11.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S7.T7.4.13.11.2.1" class="ltx_text" style="font-size:70%;">10</span></th>
<td id="S7.T7.4.13.11.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.4.13.11.3.1" class="ltx_text" style="font-size:70%;">I</span></td>
<td id="S7.T7.4.13.11.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.4.13.11.4.1" class="ltx_text" style="font-size:70%;">96.62</span></td>
</tr>
<tr id="S7.T7.4.14.12" class="ltx_tr">
<th id="S7.T7.4.14.12.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S7.T7.4.14.12.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S7.T7.4.14.12.2.1" class="ltx_text" style="font-size:70%;">10</span></th>
<td id="S7.T7.4.14.12.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.14.12.3.1" class="ltx_text" style="font-size:70%;">N</span></td>
<td id="S7.T7.4.14.12.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.14.12.4.1" class="ltx_text" style="font-size:70%;">96.17</span></td>
</tr>
<tr id="S7.T7.4.15.13" class="ltx_tr">
<th id="S7.T7.4.15.13.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S7.T7.4.15.13.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S7.T7.4.15.13.2.1" class="ltx_text" style="font-size:70%;">50</span></th>
<td id="S7.T7.4.15.13.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.15.13.3.1" class="ltx_text" style="font-size:70%;">I</span></td>
<td id="S7.T7.4.15.13.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.15.13.4.1" class="ltx_text" style="font-size:70%;">96.68</span></td>
</tr>
<tr id="S7.T7.4.16.14" class="ltx_tr">
<th id="S7.T7.4.16.14.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S7.T7.4.16.14.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S7.T7.4.16.14.2.1" class="ltx_text" style="font-size:70%;">50</span></th>
<td id="S7.T7.4.16.14.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.16.14.3.1" class="ltx_text" style="font-size:70%;">N</span></td>
<td id="S7.T7.4.16.14.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.16.14.4.1" class="ltx_text" style="font-size:70%;">96.18</span></td>
</tr>
<tr id="S7.T7.4.17.15" class="ltx_tr">
<th id="S7.T7.4.17.15.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S7.T7.4.17.15.1.1" class="ltx_text" style="font-size:70%;">FedSGD</span></th>
<th id="S7.T7.4.17.15.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S7.T7.4.17.15.2.1" class="ltx_text" style="font-size:70%;">10</span></th>
<td id="S7.T7.4.17.15.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.4.17.15.3.1" class="ltx_text" style="font-size:70%;">I</span></td>
<td id="S7.T7.4.17.15.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.4.17.15.4.1" class="ltx_text" style="font-size:70%;">96.68</span></td>
</tr>
<tr id="S7.T7.4.18.16" class="ltx_tr">
<th id="S7.T7.4.18.16.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S7.T7.4.18.16.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S7.T7.4.18.16.2.1" class="ltx_text" style="font-size:70%;">10</span></th>
<td id="S7.T7.4.18.16.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.18.16.3.1" class="ltx_text" style="font-size:70%;">N</span></td>
<td id="S7.T7.4.18.16.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.18.16.4.1" class="ltx_text" style="font-size:70%;">96.76</span></td>
</tr>
<tr id="S7.T7.4.19.17" class="ltx_tr">
<th id="S7.T7.4.19.17.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S7.T7.4.19.17.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S7.T7.4.19.17.2.1" class="ltx_text" style="font-size:70%;">50</span></th>
<td id="S7.T7.4.19.17.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.19.17.3.1" class="ltx_text" style="font-size:70%;">I</span></td>
<td id="S7.T7.4.19.17.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.19.17.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">96.84</span></td>
</tr>
<tr id="S7.T7.4.20.18" class="ltx_tr">
<th id="S7.T7.4.20.18.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S7.T7.4.20.18.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S7.T7.4.20.18.2.1" class="ltx_text" style="font-size:70%;">50</span></th>
<td id="S7.T7.4.20.18.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.20.18.3.1" class="ltx_text" style="font-size:70%;">N</span></td>
<td id="S7.T7.4.20.18.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.20.18.4.1" class="ltx_text" style="font-size:70%;">96.83</span></td>
</tr>
<tr id="S7.T7.4.21.19" class="ltx_tr">
<th id="S7.T7.4.21.19.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t" colspan="4"><span id="S7.T7.4.21.19.1.1" class="ltx_text" style="font-size:70%;">Tiny ImageNet</span></th>
</tr>
<tr id="S7.T7.4.22.20" class="ltx_tr">
<th id="S7.T7.4.22.20.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S7.T7.4.22.20.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">
<table id="S7.T7.4.22.20.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S7.T7.4.22.20.2.1.1" class="ltx_tr">
<td id="S7.T7.4.22.20.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S7.T7.4.22.20.2.1.1.1.1" class="ltx_text" style="font-size:70%;">Number</span></td>
</tr>
<tr id="S7.T7.4.22.20.2.1.2" class="ltx_tr">
<td id="S7.T7.4.22.20.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S7.T7.4.22.20.2.1.2.1.1" class="ltx_text" style="font-size:70%;">of clients</span></td>
</tr>
</table>
</th>
<th id="S7.T7.4.22.20.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S7.T7.4.22.20.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S7.T7.4.22.20.3.1.1" class="ltx_tr">
<td id="S7.T7.4.22.20.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S7.T7.4.22.20.3.1.1.1.1" class="ltx_text" style="font-size:70%;">IID (I) or</span></td>
</tr>
<tr id="S7.T7.4.22.20.3.1.2" class="ltx_tr">
<td id="S7.T7.4.22.20.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S7.T7.4.22.20.3.1.2.1.1" class="ltx_text" style="font-size:70%;">Non-IID (N)</span></td>
</tr>
</table>
</th>
<th id="S7.T7.4.22.20.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S7.T7.4.22.20.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S7.T7.4.22.20.4.1.1" class="ltx_tr">
<td id="S7.T7.4.22.20.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S7.T7.4.22.20.4.1.1.1.1" class="ltx_text" style="font-size:70%;">Test</span></td>
</tr>
<tr id="S7.T7.4.22.20.4.1.2" class="ltx_tr">
<td id="S7.T7.4.22.20.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S7.T7.4.22.20.4.1.2.1.1" class="ltx_text" style="font-size:70%;">Acc.</span></td>
</tr>
</table>
</th>
</tr>
<tr id="S7.T7.4.23.21" class="ltx_tr">
<th id="S7.T7.4.23.21.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S7.T7.4.23.21.1.1" class="ltx_text" style="font-size:70%;">FedAvg</span></th>
<th id="S7.T7.4.23.21.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S7.T7.4.23.21.2.1" class="ltx_text" style="font-size:70%;">10</span></th>
<td id="S7.T7.4.23.21.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.4.23.21.3.1" class="ltx_text" style="font-size:70%;">I</span></td>
<td id="S7.T7.4.23.21.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.4.23.21.4.1" class="ltx_text" style="font-size:70%;">37.18</span></td>
</tr>
<tr id="S7.T7.4.24.22" class="ltx_tr">
<th id="S7.T7.4.24.22.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S7.T7.4.24.22.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S7.T7.4.24.22.2.1" class="ltx_text" style="font-size:70%;">10</span></th>
<td id="S7.T7.4.24.22.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.24.22.3.1" class="ltx_text" style="font-size:70%;">N</span></td>
<td id="S7.T7.4.24.22.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.24.22.4.1" class="ltx_text" style="font-size:70%;">37.00</span></td>
</tr>
<tr id="S7.T7.4.25.23" class="ltx_tr">
<th id="S7.T7.4.25.23.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S7.T7.4.25.23.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S7.T7.4.25.23.2.1" class="ltx_text" style="font-size:70%;">50</span></th>
<td id="S7.T7.4.25.23.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.25.23.3.1" class="ltx_text" style="font-size:70%;">I</span></td>
<td id="S7.T7.4.25.23.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.25.23.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">38.84</span></td>
</tr>
<tr id="S7.T7.4.26.24" class="ltx_tr">
<th id="S7.T7.4.26.24.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S7.T7.4.26.24.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S7.T7.4.26.24.2.1" class="ltx_text" style="font-size:70%;">50</span></th>
<td id="S7.T7.4.26.24.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.26.24.3.1" class="ltx_text" style="font-size:70%;">N</span></td>
<td id="S7.T7.4.26.24.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.26.24.4.1" class="ltx_text" style="font-size:70%;">35.06</span></td>
</tr>
<tr id="S7.T7.4.27.25" class="ltx_tr">
<th id="S7.T7.4.27.25.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S7.T7.4.27.25.1.1" class="ltx_text" style="font-size:70%;">FedSGD</span></th>
<th id="S7.T7.4.27.25.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S7.T7.4.27.25.2.1" class="ltx_text" style="font-size:70%;">10</span></th>
<td id="S7.T7.4.27.25.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.4.27.25.3.1" class="ltx_text" style="font-size:70%;">I</span></td>
<td id="S7.T7.4.27.25.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T7.4.27.25.4.1" class="ltx_text" style="font-size:70%;">35.56</span></td>
</tr>
<tr id="S7.T7.4.28.26" class="ltx_tr">
<th id="S7.T7.4.28.26.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S7.T7.4.28.26.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S7.T7.4.28.26.2.1" class="ltx_text" style="font-size:70%;">10</span></th>
<td id="S7.T7.4.28.26.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.28.26.3.1" class="ltx_text" style="font-size:70%;">N</span></td>
<td id="S7.T7.4.28.26.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.28.26.4.1" class="ltx_text" style="font-size:70%;">34.27</span></td>
</tr>
<tr id="S7.T7.4.29.27" class="ltx_tr">
<th id="S7.T7.4.29.27.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S7.T7.4.29.27.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S7.T7.4.29.27.2.1" class="ltx_text" style="font-size:70%;">50</span></th>
<td id="S7.T7.4.29.27.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.29.27.3.1" class="ltx_text" style="font-size:70%;">I</span></td>
<td id="S7.T7.4.29.27.4" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T7.4.29.27.4.1" class="ltx_text" style="font-size:70%;">32.77</span></td>
</tr>
<tr id="S7.T7.4.30.28" class="ltx_tr">
<th id="S7.T7.4.30.28.1" class="ltx_td ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r"></th>
<th id="S7.T7.4.30.28.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r"><span id="S7.T7.4.30.28.2.1" class="ltx_text" style="font-size:70%;">50</span></th>
<td id="S7.T7.4.30.28.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S7.T7.4.30.28.3.1" class="ltx_text" style="font-size:70%;">N</span></td>
<td id="S7.T7.4.30.28.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S7.T7.4.30.28.4.1" class="ltx_text" style="font-size:70%;">26.56</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S7.T7.8.2.1" class="ltx_text" style="font-size:129%;">Table 7</span>: </span><span id="S7.T7.2.1" class="ltx_text" style="font-size:129%;"> Federated learning test accuracy on CIFAR-10, MNIST, and Tiny ImageNet. A bias of 0.5 is used for the non-IID training. The same settings are used between FedSGD and FedAvg outside of the number of rounds. The number of rounds in FedSGD is <math id="S7.T7.2.1.m1.1" class="ltx_math_unparsed" alttext="3\times" display="inline"><semantics id="S7.T7.2.1.m1.1b"><mrow id="S7.T7.2.1.m1.1c"><mn id="S7.T7.2.1.m1.1.1">3</mn><mo lspace="0.222em" id="S7.T7.2.1.m1.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S7.T7.2.1.m1.1d">3\times</annotation></semantics></math> the number of rounds in FedAvg (3 local iterations in FedAvg).</span></figcaption>
</figure>
<div id="S7.p1" class="ltx_para">
<p id="S7.p1.3" class="ltx_p"><span id="S7.p1.3.1" class="ltx_text" style="font-size:144%;">Table </span><a href="#S7.T7" title="Table 7 ‣ 7 Additional federated learning results ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">7</span></a><span id="S7.p1.3.2" class="ltx_text" style="font-size:144%;"> shows additional test accuracy in federated learning on CIFAR-10, MNIST, and Tiny ImageNet. We include results for both IID and non-IID (with bias</span><math id="S7.p1.1.m1.1" class="ltx_Math" alttext="=0.5" display="inline"><semantics id="S7.p1.1.m1.1a"><mrow id="S7.p1.1.m1.1.1" xref="S7.p1.1.m1.1.1.cmml"><mi id="S7.p1.1.m1.1.1.2" xref="S7.p1.1.m1.1.1.2.cmml"></mi><mo mathsize="144%" id="S7.p1.1.m1.1.1.1" xref="S7.p1.1.m1.1.1.1.cmml">=</mo><mn mathsize="144%" id="S7.p1.1.m1.1.1.3" xref="S7.p1.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S7.p1.1.m1.1b"><apply id="S7.p1.1.m1.1.1.cmml" xref="S7.p1.1.m1.1.1"><eq id="S7.p1.1.m1.1.1.1.cmml" xref="S7.p1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="S7.p1.1.m1.1.1.2.cmml" xref="S7.p1.1.m1.1.1.2">absent</csymbol><cn type="float" id="S7.p1.1.m1.1.1.3.cmml" xref="S7.p1.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.1.m1.1c">=0.5</annotation></semantics></math><span id="S7.p1.3.3" class="ltx_text" style="font-size:144%;">). For FedSGD training, we use </span><math id="S7.p1.2.m2.1" class="ltx_math_unparsed" alttext="3\times" display="inline"><semantics id="S7.p1.2.m2.1a"><mrow id="S7.p1.2.m2.1b"><mn mathsize="144%" id="S7.p1.2.m2.1.1">3</mn><mo lspace="0.222em" mathsize="144%" id="S7.p1.2.m2.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S7.p1.2.m2.1c">3\times</annotation></semantics></math><span id="S7.p1.3.4" class="ltx_text" style="font-size:144%;"> the number of rounds compared to FedAvg (so the models have seen the same amount data in both cases, as we have 3 local iterations in FedAvg). All other settings are the same. An (expected) observed trend is that IID training outperforms non-IID. Both CIFAR-10 and Tiny ImageNet in FedAvg perform better than FedSGD in all settings. For MNIST, the performance is similar regardless of FedAvg or FedSGD, IID or non-IID, achieving around </span><math id="S7.p1.3.m3.1" class="ltx_Math" alttext="96\%" display="inline"><semantics id="S7.p1.3.m3.1a"><mrow id="S7.p1.3.m3.1.1" xref="S7.p1.3.m3.1.1.cmml"><mn mathsize="144%" id="S7.p1.3.m3.1.1.2" xref="S7.p1.3.m3.1.1.2.cmml">96</mn><mo mathsize="144%" id="S7.p1.3.m3.1.1.1" xref="S7.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.p1.3.m3.1b"><apply id="S7.p1.3.m3.1.1.cmml" xref="S7.p1.3.m3.1.1"><csymbol cd="latexml" id="S7.p1.3.m3.1.1.1.cmml" xref="S7.p1.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S7.p1.3.m3.1.1.2.cmml" xref="S7.p1.3.m3.1.1.2">96</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S7.p1.3.m3.1c">96\%</annotation></semantics></math><span id="S7.p1.3.5" class="ltx_text" style="font-size:144%;"> accuracy across the board.</span></p>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:144%;">
<span class="ltx_tag ltx_tag_section">8 </span>Sample reconstructions</h2>

<figure id="S8.F7" class="ltx_figure"><img src="/html/2403.18144/assets/x10.png" id="S8.F7.1.g1" class="ltx_graphics ltx_centering ltx_img_portrait" width="207" height="415" alt="Refer to caption">
<figcaption class="ltx_caption" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S8.F7.11.3.1" class="ltx_text" style="font-size:63%;">Figure 7</span>: </span><span id="S8.F7.5.2" class="ltx_text" style="font-size:63%;"> CIFAR-10 sample reconstructions from Inverting Gradients batch size 16 with a PSNR <math id="S8.F7.4.1.m1.1" class="ltx_Math" alttext="&lt;12" display="inline"><semantics id="S8.F7.4.1.m1.1b"><mrow id="S8.F7.4.1.m1.1.1" xref="S8.F7.4.1.m1.1.1.cmml"><mi id="S8.F7.4.1.m1.1.1.2" xref="S8.F7.4.1.m1.1.1.2.cmml"></mi><mo id="S8.F7.4.1.m1.1.1.1" xref="S8.F7.4.1.m1.1.1.1.cmml">&lt;</mo><mn id="S8.F7.4.1.m1.1.1.3" xref="S8.F7.4.1.m1.1.1.3.cmml">12</mn></mrow><annotation-xml encoding="MathML-Content" id="S8.F7.4.1.m1.1c"><apply id="S8.F7.4.1.m1.1.1.cmml" xref="S8.F7.4.1.m1.1.1"><lt id="S8.F7.4.1.m1.1.1.1.cmml" xref="S8.F7.4.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S8.F7.4.1.m1.1.1.2.cmml" xref="S8.F7.4.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S8.F7.4.1.m1.1.1.3.cmml" xref="S8.F7.4.1.m1.1.1.3">12</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.F7.4.1.m1.1d">&lt;12</annotation></semantics></math>. Each row is a different class. While the images are very noisy, using a set of them for training achieves a model with <math id="S8.F7.5.2.m2.1" class="ltx_Math" alttext="45.05\%" display="inline"><semantics id="S8.F7.5.2.m2.1b"><mrow id="S8.F7.5.2.m2.1.1" xref="S8.F7.5.2.m2.1.1.cmml"><mn id="S8.F7.5.2.m2.1.1.2" xref="S8.F7.5.2.m2.1.1.2.cmml">45.05</mn><mo id="S8.F7.5.2.m2.1.1.1" xref="S8.F7.5.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S8.F7.5.2.m2.1c"><apply id="S8.F7.5.2.m2.1.1.cmml" xref="S8.F7.5.2.m2.1.1"><csymbol cd="latexml" id="S8.F7.5.2.m2.1.1.1.cmml" xref="S8.F7.5.2.m2.1.1.1">percent</csymbol><cn type="float" id="S8.F7.5.2.m2.1.1.2.cmml" xref="S8.F7.5.2.m2.1.1.2">45.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.F7.5.2.m2.1d">45.05\%</annotation></semantics></math> accuracy.</span></figcaption>
</figure>
<figure id="S8.F8" class="ltx_figure"><img src="/html/2403.18144/assets/x11.png" id="S8.F8.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="166" height="166" alt="Refer to caption">
<figcaption class="ltx_caption" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S8.F8.8.2.1" class="ltx_text" style="font-size:63%;">Figure 8</span>: </span><span id="S8.F8.3.1" class="ltx_text" style="font-size:63%;"> LOKI CIFAR-10 reconstructions using CSF<math id="S8.F8.3.1.m1.1" class="ltx_Math" alttext="=500" display="inline"><semantics id="S8.F8.3.1.m1.1b"><mrow id="S8.F8.3.1.m1.1.1" xref="S8.F8.3.1.m1.1.1.cmml"><mi id="S8.F8.3.1.m1.1.1.2" xref="S8.F8.3.1.m1.1.1.2.cmml"></mi><mo id="S8.F8.3.1.m1.1.1.1" xref="S8.F8.3.1.m1.1.1.1.cmml">=</mo><mn id="S8.F8.3.1.m1.1.1.3" xref="S8.F8.3.1.m1.1.1.3.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S8.F8.3.1.m1.1c"><apply id="S8.F8.3.1.m1.1.1.cmml" xref="S8.F8.3.1.m1.1.1"><eq id="S8.F8.3.1.m1.1.1.1.cmml" xref="S8.F8.3.1.m1.1.1.1"></eq><csymbol cd="latexml" id="S8.F8.3.1.m1.1.1.2.cmml" xref="S8.F8.3.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S8.F8.3.1.m1.1.1.3.cmml" xref="S8.F8.3.1.m1.1.1.3">500</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.F8.3.1.m1.1d">=500</annotation></semantics></math> in FedAvg. 54 images out of 64 images are leaked.</span></figcaption>
</figure>
<figure id="S8.F9" class="ltx_figure"><img src="/html/2403.18144/assets/x12.png" id="S8.F9.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="166" height="166" alt="Refer to caption">
<figcaption class="ltx_caption" style="font-size:144%;"><span class="ltx_tag ltx_tag_figure"><span id="S8.F9.5.1.1" class="ltx_text" style="font-size:63%;">Figure 9</span>: </span><span id="S8.F9.6.2" class="ltx_text" style="font-size:63%;"> Ground truth CIFAR-10 images.</span></figcaption>
</figure>
<div id="S8.p1" class="ltx_para">
<p id="S8.p1.2" class="ltx_p"><span id="S8.p1.2.1" class="ltx_text" style="font-size:144%;">For Inverting Gradients, we use a learning rate of </span><math id="S8.p1.1.m1.1" class="ltx_Math" alttext="=0.01" display="inline"><semantics id="S8.p1.1.m1.1a"><mrow id="S8.p1.1.m1.1.1" xref="S8.p1.1.m1.1.1.cmml"><mi id="S8.p1.1.m1.1.1.2" xref="S8.p1.1.m1.1.1.2.cmml"></mi><mo mathsize="144%" id="S8.p1.1.m1.1.1.1" xref="S8.p1.1.m1.1.1.1.cmml">=</mo><mn mathsize="144%" id="S8.p1.1.m1.1.1.3" xref="S8.p1.1.m1.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S8.p1.1.m1.1b"><apply id="S8.p1.1.m1.1.1.cmml" xref="S8.p1.1.m1.1.1"><eq id="S8.p1.1.m1.1.1.1.cmml" xref="S8.p1.1.m1.1.1.1"></eq><csymbol cd="latexml" id="S8.p1.1.m1.1.1.2.cmml" xref="S8.p1.1.m1.1.1.2">absent</csymbol><cn type="float" id="S8.p1.1.m1.1.1.3.cmml" xref="S8.p1.1.m1.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.p1.1.m1.1c">=0.01</annotation></semantics></math><span id="S8.p1.2.2" class="ltx_text" style="font-size:144%;"> and total variation of 1e-6 on CIFAR-10. For MNIST, we use a learning rate of </span><math id="S8.p1.2.m2.1" class="ltx_Math" alttext="=0.01" display="inline"><semantics id="S8.p1.2.m2.1a"><mrow id="S8.p1.2.m2.1.1" xref="S8.p1.2.m2.1.1.cmml"><mi id="S8.p1.2.m2.1.1.2" xref="S8.p1.2.m2.1.1.2.cmml"></mi><mo mathsize="144%" id="S8.p1.2.m2.1.1.1" xref="S8.p1.2.m2.1.1.1.cmml">=</mo><mn mathsize="144%" id="S8.p1.2.m2.1.1.3" xref="S8.p1.2.m2.1.1.3.cmml">0.01</mn></mrow><annotation-xml encoding="MathML-Content" id="S8.p1.2.m2.1b"><apply id="S8.p1.2.m2.1.1.cmml" xref="S8.p1.2.m2.1.1"><eq id="S8.p1.2.m2.1.1.1.cmml" xref="S8.p1.2.m2.1.1.1"></eq><csymbol cd="latexml" id="S8.p1.2.m2.1.1.2.cmml" xref="S8.p1.2.m2.1.1.2">absent</csymbol><cn type="float" id="S8.p1.2.m2.1.1.3.cmml" xref="S8.p1.2.m2.1.1.3">0.01</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.p1.2.m2.1c">=0.01</annotation></semantics></math><span id="S8.p1.2.3" class="ltx_text" style="font-size:144%;"> and a total variation of 0. These parameters achieved the best reconstruction quality for us.</span></p>
</div>
<div id="S8.p2" class="ltx_para">
<p id="S8.p2.5" class="ltx_p"><span id="S8.p2.5.1" class="ltx_text" style="font-size:144%;">Figure </span><a href="#S8.F7" title="Figure 7 ‣ 8 Sample reconstructions ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">7</span></a><span id="S8.p2.5.2" class="ltx_text" style="font-size:144%;"> shows sample reconstructions from Inverting Gradients </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S8.p2.5.3.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib6" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">6</span></a><span id="S8.p2.5.4.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S8.p2.5.5" class="ltx_text" style="font-size:144%;"> batch size 16 with PSNR </span><math id="S8.p2.1.m1.1" class="ltx_Math" alttext="&lt;12" display="inline"><semantics id="S8.p2.1.m1.1a"><mrow id="S8.p2.1.m1.1.1" xref="S8.p2.1.m1.1.1.cmml"><mi id="S8.p2.1.m1.1.1.2" xref="S8.p2.1.m1.1.1.2.cmml"></mi><mo mathsize="144%" id="S8.p2.1.m1.1.1.1" xref="S8.p2.1.m1.1.1.1.cmml">&lt;</mo><mn mathsize="144%" id="S8.p2.1.m1.1.1.3" xref="S8.p2.1.m1.1.1.3.cmml">12</mn></mrow><annotation-xml encoding="MathML-Content" id="S8.p2.1.m1.1b"><apply id="S8.p2.1.m1.1.1.cmml" xref="S8.p2.1.m1.1.1"><lt id="S8.p2.1.m1.1.1.1.cmml" xref="S8.p2.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S8.p2.1.m1.1.1.2.cmml" xref="S8.p2.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S8.p2.1.m1.1.1.3.cmml" xref="S8.p2.1.m1.1.1.3">12</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.p2.1.m1.1c">&lt;12</annotation></semantics></math><span id="S8.p2.5.6" class="ltx_text" style="font-size:144%;">. Each row shows 5 images from each of the classes in CIFAR-10. The rows correspond to airplanes, cars, birds, cats, deer, dogs, frogs, horses, ships, and trucks respectively. While the images are noisy, there is some contextual information that can still be observed in the reconstructions. As discussed in Section </span><a href="#S4.SS7" title="4.7 Quality of data reconstruction ‣ 4 Experiments ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">4.7</span></a><span id="S8.p2.5.7" class="ltx_text" style="font-size:144%;">, removing these images from the training set results in a small decrease in model performance from </span><math id="S8.p2.2.m2.1" class="ltx_Math" alttext="76.83\%" display="inline"><semantics id="S8.p2.2.m2.1a"><mrow id="S8.p2.2.m2.1.1" xref="S8.p2.2.m2.1.1.cmml"><mn mathsize="144%" id="S8.p2.2.m2.1.1.2" xref="S8.p2.2.m2.1.1.2.cmml">76.83</mn><mo mathsize="144%" id="S8.p2.2.m2.1.1.1" xref="S8.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S8.p2.2.m2.1b"><apply id="S8.p2.2.m2.1.1.cmml" xref="S8.p2.2.m2.1.1"><csymbol cd="latexml" id="S8.p2.2.m2.1.1.1.cmml" xref="S8.p2.2.m2.1.1.1">percent</csymbol><cn type="float" id="S8.p2.2.m2.1.1.2.cmml" xref="S8.p2.2.m2.1.1.2">76.83</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.p2.2.m2.1c">76.83\%</annotation></semantics></math><span id="S8.p2.5.8" class="ltx_text" style="font-size:144%;"> to </span><math id="S8.p2.3.m3.1" class="ltx_Math" alttext="76.16\%" display="inline"><semantics id="S8.p2.3.m3.1a"><mrow id="S8.p2.3.m3.1.1" xref="S8.p2.3.m3.1.1.cmml"><mn mathsize="144%" id="S8.p2.3.m3.1.1.2" xref="S8.p2.3.m3.1.1.2.cmml">76.16</mn><mo mathsize="144%" id="S8.p2.3.m3.1.1.1" xref="S8.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S8.p2.3.m3.1b"><apply id="S8.p2.3.m3.1.1.cmml" xref="S8.p2.3.m3.1.1"><csymbol cd="latexml" id="S8.p2.3.m3.1.1.1.cmml" xref="S8.p2.3.m3.1.1.1">percent</csymbol><cn type="float" id="S8.p2.3.m3.1.1.2.cmml" xref="S8.p2.3.m3.1.1.2">76.16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.p2.3.m3.1c">76.16\%</annotation></semantics></math><span id="S8.p2.5.9" class="ltx_text" style="font-size:144%;">. Training on only the set of images with PSNR </span><math id="S8.p2.4.m4.1" class="ltx_Math" alttext="&lt;12" display="inline"><semantics id="S8.p2.4.m4.1a"><mrow id="S8.p2.4.m4.1.1" xref="S8.p2.4.m4.1.1.cmml"><mi id="S8.p2.4.m4.1.1.2" xref="S8.p2.4.m4.1.1.2.cmml"></mi><mo mathsize="144%" id="S8.p2.4.m4.1.1.1" xref="S8.p2.4.m4.1.1.1.cmml">&lt;</mo><mn mathsize="144%" id="S8.p2.4.m4.1.1.3" xref="S8.p2.4.m4.1.1.3.cmml">12</mn></mrow><annotation-xml encoding="MathML-Content" id="S8.p2.4.m4.1b"><apply id="S8.p2.4.m4.1.1.cmml" xref="S8.p2.4.m4.1.1"><lt id="S8.p2.4.m4.1.1.1.cmml" xref="S8.p2.4.m4.1.1.1"></lt><csymbol cd="latexml" id="S8.p2.4.m4.1.1.2.cmml" xref="S8.p2.4.m4.1.1.2">absent</csymbol><cn type="integer" id="S8.p2.4.m4.1.1.3.cmml" xref="S8.p2.4.m4.1.1.3">12</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.p2.4.m4.1c">&lt;12</annotation></semantics></math><span id="S8.p2.5.10" class="ltx_text" style="font-size:144%;"> results in a </span><math id="S8.p2.5.m5.1" class="ltx_Math" alttext="45.05\%" display="inline"><semantics id="S8.p2.5.m5.1a"><mrow id="S8.p2.5.m5.1.1" xref="S8.p2.5.m5.1.1.cmml"><mn mathsize="144%" id="S8.p2.5.m5.1.1.2" xref="S8.p2.5.m5.1.1.2.cmml">45.05</mn><mo mathsize="144%" id="S8.p2.5.m5.1.1.1" xref="S8.p2.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S8.p2.5.m5.1b"><apply id="S8.p2.5.m5.1.1.cmml" xref="S8.p2.5.m5.1.1"><csymbol cd="latexml" id="S8.p2.5.m5.1.1.1.cmml" xref="S8.p2.5.m5.1.1.1">percent</csymbol><cn type="float" id="S8.p2.5.m5.1.1.2.cmml" xref="S8.p2.5.m5.1.1.2">45.05</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.p2.5.m5.1c">45.05\%</annotation></semantics></math><span id="S8.p2.5.11" class="ltx_text" style="font-size:144%;"> test accuracy.</span></p>
</div>
<div id="S8.p3" class="ltx_para">
<p id="S8.p3.2" class="ltx_p"><span id="S8.p3.2.1" class="ltx_text" style="font-size:144%;">Figure  </span><a href="#S8.F8" title="Figure 8 ‣ 8 Sample reconstructions ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">8</span></a><span id="S8.p3.2.2" class="ltx_text" style="font-size:144%;"> shows CIFAR-10 reconstructions from LOKI in FedAvg using CSF</span><math id="S8.p3.1.m1.1" class="ltx_Math" alttext="=500" display="inline"><semantics id="S8.p3.1.m1.1a"><mrow id="S8.p3.1.m1.1.1" xref="S8.p3.1.m1.1.1.cmml"><mi id="S8.p3.1.m1.1.1.2" xref="S8.p3.1.m1.1.1.2.cmml"></mi><mo mathsize="144%" id="S8.p3.1.m1.1.1.1" xref="S8.p3.1.m1.1.1.1.cmml">=</mo><mn mathsize="144%" id="S8.p3.1.m1.1.1.3" xref="S8.p3.1.m1.1.1.3.cmml">500</mn></mrow><annotation-xml encoding="MathML-Content" id="S8.p3.1.m1.1b"><apply id="S8.p3.1.m1.1.1.cmml" xref="S8.p3.1.m1.1.1"><eq id="S8.p3.1.m1.1.1.1.cmml" xref="S8.p3.1.m1.1.1.1"></eq><csymbol cd="latexml" id="S8.p3.1.m1.1.1.2.cmml" xref="S8.p3.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S8.p3.1.m1.1.1.3.cmml" xref="S8.p3.1.m1.1.1.3">500</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.p3.1.m1.1c">=500</annotation></semantics></math><span id="S8.p3.2.3" class="ltx_text" style="font-size:144%;">. Figure </span><a href="#S8.F9" title="Figure 9 ‣ 8 Sample reconstructions ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">9</span></a><span id="S8.p3.2.4" class="ltx_text" style="font-size:144%;"> shows the corresponding ground truth images. For this particular set of images, 54 images out of 64 are leaked (</span><math id="S8.p3.2.m2.1" class="ltx_Math" alttext="84.38\%" display="inline"><semantics id="S8.p3.2.m2.1a"><mrow id="S8.p3.2.m2.1.1" xref="S8.p3.2.m2.1.1.cmml"><mn mathsize="144%" id="S8.p3.2.m2.1.1.2" xref="S8.p3.2.m2.1.1.2.cmml">84.38</mn><mo mathsize="144%" id="S8.p3.2.m2.1.1.1" xref="S8.p3.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S8.p3.2.m2.1b"><apply id="S8.p3.2.m2.1.1.cmml" xref="S8.p3.2.m2.1.1"><csymbol cd="latexml" id="S8.p3.2.m2.1.1.1.cmml" xref="S8.p3.2.m2.1.1.1">percent</csymbol><cn type="float" id="S8.p3.2.m2.1.1.2.cmml" xref="S8.p3.2.m2.1.1.2">84.38</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S8.p3.2.m2.1c">84.38\%</annotation></semantics></math><span id="S8.p3.2.5" class="ltx_text" style="font-size:144%;"> leakage rate).</span></p>
</div>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:144%;">
<span class="ltx_tag ltx_tag_section">9 </span>Linear layer leakage method comparison</h2>

<figure id="S9.T8" class="ltx_table">
<table id="S9.T8.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S9.T8.2.1.1" class="ltx_tr">
<th id="S9.T8.2.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S9.T8.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_t">
<table id="S9.T8.2.1.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S9.T8.2.1.1.2.1.1" class="ltx_tr">
<td id="S9.T8.2.1.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S9.T8.2.1.1.2.1.1.1.1" class="ltx_text" style="font-size:70%;">FC size</span></td>
</tr>
<tr id="S9.T8.2.1.1.2.1.2" class="ltx_tr">
<td id="S9.T8.2.1.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S9.T8.2.1.1.2.1.2.1.1" class="ltx_text" style="font-size:70%;">factor</span></td>
</tr>
</table>
</th>
<th id="S9.T8.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S9.T8.2.1.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S9.T8.2.1.1.3.1.1" class="ltx_tr">
<td id="S9.T8.2.1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S9.T8.2.1.1.3.1.1.1.1" class="ltx_text" style="font-size:70%;">Leakage</span></td>
</tr>
<tr id="S9.T8.2.1.1.3.1.2" class="ltx_tr">
<td id="S9.T8.2.1.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S9.T8.2.1.1.3.1.2.1.1" class="ltx_text" style="font-size:70%;">rate</span></td>
</tr>
</table>
</th>
<th id="S9.T8.2.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S9.T8.2.1.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S9.T8.2.1.1.4.1.1" class="ltx_tr">
<td id="S9.T8.2.1.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S9.T8.2.1.1.4.1.1.1.1" class="ltx_text" style="font-size:70%;">Test</span></td>
</tr>
<tr id="S9.T8.2.1.1.4.1.2" class="ltx_tr">
<td id="S9.T8.2.1.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S9.T8.2.1.1.4.1.2.1.1" class="ltx_text" style="font-size:70%;">accuracy</span></td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S9.T8.2.2.1" class="ltx_tr">
<th id="S9.T8.2.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" rowspan="3"><span id="S9.T8.2.2.1.1.1" class="ltx_text" style="font-size:70%;">LOKI</span></th>
<th id="S9.T8.2.2.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S9.T8.2.2.1.2.1" class="ltx_text" style="font-size:70%;">8</span></th>
<td id="S9.T8.2.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S9.T8.2.2.1.3.1" class="ltx_text" style="font-size:70%;">87.58</span></td>
<td id="S9.T8.2.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S9.T8.2.2.1.4.1" class="ltx_text ltx_font_bold" style="font-size:70%;">93.16</span></td>
</tr>
<tr id="S9.T8.2.3.2" class="ltx_tr">
<th id="S9.T8.2.3.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S9.T8.2.3.2.1.1" class="ltx_text" style="font-size:70%;">4</span></th>
<td id="S9.T8.2.3.2.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S9.T8.2.3.2.2.1" class="ltx_text" style="font-size:70%;">78.93</span></td>
<td id="S9.T8.2.3.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S9.T8.2.3.2.3.1" class="ltx_text" style="font-size:70%;">92.94</span></td>
</tr>
<tr id="S9.T8.2.4.3" class="ltx_tr">
<th id="S9.T8.2.4.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S9.T8.2.4.3.1.1" class="ltx_text" style="font-size:70%;">2</span></th>
<td id="S9.T8.2.4.3.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S9.T8.2.4.3.2.1" class="ltx_text" style="font-size:70%;">59.76</span></td>
<td id="S9.T8.2.4.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S9.T8.2.4.3.3.1" class="ltx_text" style="font-size:70%;">91.90</span></td>
</tr>
<tr id="S9.T8.2.5.4" class="ltx_tr">
<th id="S9.T8.2.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t" rowspan="3"><span id="S9.T8.2.5.4.1.1" class="ltx_text" style="font-size:70%;">
<span id="S9.T8.2.5.4.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S9.T8.2.5.4.1.1.1.1" class="ltx_tr">
<span id="S9.T8.2.5.4.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Robbing</span></span>
<span id="S9.T8.2.5.4.1.1.1.2" class="ltx_tr">
<span id="S9.T8.2.5.4.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">the Fed</span></span>
</span></span></th>
<th id="S9.T8.2.5.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S9.T8.2.5.4.2.1" class="ltx_text" style="font-size:70%;">8</span></th>
<td id="S9.T8.2.5.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S9.T8.2.5.4.3.1" class="ltx_text" style="font-size:70%;">87.50</span></td>
<td id="S9.T8.2.5.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S9.T8.2.5.4.4.1" class="ltx_text" style="font-size:70%;">93.10</span></td>
</tr>
<tr id="S9.T8.2.6.5" class="ltx_tr">
<th id="S9.T8.2.6.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S9.T8.2.6.5.1.1" class="ltx_text" style="font-size:70%;">4</span></th>
<td id="S9.T8.2.6.5.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S9.T8.2.6.5.2.1" class="ltx_text" style="font-size:70%;">78.97</span></td>
<td id="S9.T8.2.6.5.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S9.T8.2.6.5.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">93.02</span></td>
</tr>
<tr id="S9.T8.2.7.6" class="ltx_tr">
<th id="S9.T8.2.7.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S9.T8.2.7.6.1.1" class="ltx_text" style="font-size:70%;">2</span></th>
<td id="S9.T8.2.7.6.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S9.T8.2.7.6.2.1" class="ltx_text" style="font-size:70%;">59.72</span></td>
<td id="S9.T8.2.7.6.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S9.T8.2.7.6.3.1" class="ltx_text ltx_font_bold" style="font-size:70%;">92.12</span></td>
</tr>
<tr id="S9.T8.2.8.7" class="ltx_tr">
<th id="S9.T8.2.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t" rowspan="3"><span id="S9.T8.2.8.7.1.1" class="ltx_text" style="font-size:70%;">
<span id="S9.T8.2.8.7.1.1.1" class="ltx_tabular ltx_align_middle">
<span id="S9.T8.2.8.7.1.1.1.1" class="ltx_tr">
<span id="S9.T8.2.8.7.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Trap</span></span>
<span id="S9.T8.2.8.7.1.1.1.2" class="ltx_tr">
<span id="S9.T8.2.8.7.1.1.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Weights</span></span>
</span></span></th>
<th id="S9.T8.2.8.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S9.T8.2.8.7.2.1" class="ltx_text" style="font-size:70%;">8</span></th>
<td id="S9.T8.2.8.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S9.T8.2.8.7.3.1" class="ltx_text" style="font-size:70%;">58.11</span></td>
<td id="S9.T8.2.8.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S9.T8.2.8.7.4.1" class="ltx_text" style="font-size:70%;">91.84</span></td>
</tr>
<tr id="S9.T8.2.9.8" class="ltx_tr">
<th id="S9.T8.2.9.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r"><span id="S9.T8.2.9.8.1.1" class="ltx_text" style="font-size:70%;">4</span></th>
<td id="S9.T8.2.9.8.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S9.T8.2.9.8.2.1" class="ltx_text" style="font-size:70%;">45.92</span></td>
<td id="S9.T8.2.9.8.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S9.T8.2.9.8.3.1" class="ltx_text" style="font-size:70%;">90.09</span></td>
</tr>
<tr id="S9.T8.2.10.9" class="ltx_tr">
<th id="S9.T8.2.10.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r"><span id="S9.T8.2.10.9.1.1" class="ltx_text" style="font-size:70%;">2</span></th>
<td id="S9.T8.2.10.9.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S9.T8.2.10.9.2.1" class="ltx_text" style="font-size:70%;">30.46</span></td>
<td id="S9.T8.2.10.9.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S9.T8.2.10.9.3.1" class="ltx_text" style="font-size:70%;">86.38</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S9.T8.5.1.1" class="ltx_text" style="font-size:129%;">Table 8</span>: </span><span id="S9.T8.6.2" class="ltx_text" style="font-size:129%;"> Leakage rate and test accuracy on CIFAR-10 for LOKI, Robbing the Fed, and Trap Weights in FedSGD. FC layer size factors of 8, 4, and 2 used with a batch size of 64. Models trained from scratch on leaked data.</span></figcaption>
</figure>
<div id="S9.p1" class="ltx_para">
<p id="S9.p1.1" class="ltx_p"><span id="S9.p1.1.1" class="ltx_text" style="font-size:144%;">Table </span><a href="#S9.T8" title="Table 8 ‣ 9 Linear layer leakage method comparison ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">8</span></a><span id="S9.p1.1.2" class="ltx_text" style="font-size:144%;"> shows the leakage rate and test accuracy on CIFAR-10 for LOKI </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S9.p1.1.3.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib30" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">30</span></a><span id="S9.p1.1.4.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S9.p1.1.5" class="ltx_text" style="font-size:144%;">, Robbing the Fed </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S9.p1.1.6.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib5" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">5</span></a><span id="S9.p1.1.7.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S9.p1.1.8" class="ltx_text" style="font-size:144%;">, and trap weights </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S9.p1.1.9.1" class="ltx_text" style="font-size:144%;">[</span><a href="#bib.bib1" title="" class="ltx_ref"><span class="ltx_text" style="font-size:90%;">1</span></a><span id="S9.p1.1.10.2" class="ltx_text" style="font-size:144%;">]</span></cite><span id="S9.p1.1.11" class="ltx_text" style="font-size:144%;">. Attacks are done in FedSGD with a batch size of 64. LOKI and Robbing the Fed have no additional parameters besides the FC size factor (FC layer size = FC size factor</span><math id="S9.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S9.p1.1.m1.1a"><mo mathsize="144%" id="S9.p1.1.m1.1.1" xref="S9.p1.1.m1.1.1.cmml">×</mo><annotation-xml encoding="MathML-Content" id="S9.p1.1.m1.1b"><times id="S9.p1.1.m1.1.1.cmml" xref="S9.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S9.p1.1.m1.1c">\times</annotation></semantics></math><span id="S9.p1.1.12" class="ltx_text" style="font-size:144%;">batch size). For trap weights, in addition to the FC size factor, a scaling factor of 0.96 achieves the highest leakage rate for each FC size factor (checked by 0.1 increments). LOKI and Robbing the Fed achieve very similar leakage rates and model performances. Trap weights has lower leakage rate than both other methods and, as a result, lower model performance for the same FC size factors.</span></p>
</div>
</section>
<section id="S10" class="ltx_section">
<h2 class="ltx_title ltx_title_section" style="font-size:144%;">
<span class="ltx_tag ltx_tag_section">10 </span>SSIM threshold</h2>

<figure id="S10.T9" class="ltx_table">
<div class="ltx_flex_figure ltx_flex_table">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S10.T9.st1" class="ltx_table ltx_figure_panel ltx_align_center">
<table id="S10.T9.st1.6.6" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S10.T9.st1.6.6.7.1" class="ltx_tr">
<th id="S10.T9.st1.6.6.7.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S10.T9.st1.6.6.7.1.1.1" class="ltx_text" style="font-size:70%;">SSIM</span></th>
<th id="S10.T9.st1.6.6.7.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S10.T9.st1.6.6.7.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S10.T9.st1.6.6.7.1.2.1.1" class="ltx_tr">
<td id="S10.T9.st1.6.6.7.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S10.T9.st1.6.6.7.1.2.1.1.1.1" class="ltx_text" style="font-size:70%;">% imgs</span></td>
</tr>
<tr id="S10.T9.st1.6.6.7.1.2.1.2" class="ltx_tr">
<td id="S10.T9.st1.6.6.7.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S10.T9.st1.6.6.7.1.2.1.2.1.1" class="ltx_text" style="font-size:70%;">kept</span></td>
</tr>
</table>
</th>
<th id="S10.T9.st1.6.6.7.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S10.T9.st1.6.6.7.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S10.T9.st1.6.6.7.1.3.1.1" class="ltx_tr">
<td id="S10.T9.st1.6.6.7.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S10.T9.st1.6.6.7.1.3.1.1.1.1" class="ltx_text" style="font-size:70%;">Test</span></td>
</tr>
<tr id="S10.T9.st1.6.6.7.1.3.1.2" class="ltx_tr">
<td id="S10.T9.st1.6.6.7.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S10.T9.st1.6.6.7.1.3.1.2.1.1" class="ltx_text" style="font-size:70%;">accuracy</span></td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S10.T9.st1.1.1.1" class="ltx_tr">
<th id="S10.T9.st1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><math id="S10.T9.st1.1.1.1.1.m1.1" class="ltx_Math" alttext="&gt;0.7" display="inline"><semantics id="S10.T9.st1.1.1.1.1.m1.1a"><mrow id="S10.T9.st1.1.1.1.1.m1.1.1" xref="S10.T9.st1.1.1.1.1.m1.1.1.cmml"><mi id="S10.T9.st1.1.1.1.1.m1.1.1.2" xref="S10.T9.st1.1.1.1.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S10.T9.st1.1.1.1.1.m1.1.1.1" xref="S10.T9.st1.1.1.1.1.m1.1.1.1.cmml">&gt;</mo><mn mathsize="70%" id="S10.T9.st1.1.1.1.1.m1.1.1.3" xref="S10.T9.st1.1.1.1.1.m1.1.1.3.cmml">0.7</mn></mrow><annotation-xml encoding="MathML-Content" id="S10.T9.st1.1.1.1.1.m1.1b"><apply id="S10.T9.st1.1.1.1.1.m1.1.1.cmml" xref="S10.T9.st1.1.1.1.1.m1.1.1"><gt id="S10.T9.st1.1.1.1.1.m1.1.1.1.cmml" xref="S10.T9.st1.1.1.1.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S10.T9.st1.1.1.1.1.m1.1.1.2.cmml" xref="S10.T9.st1.1.1.1.1.m1.1.1.2">absent</csymbol><cn type="float" id="S10.T9.st1.1.1.1.1.m1.1.1.3.cmml" xref="S10.T9.st1.1.1.1.1.m1.1.1.3">0.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S10.T9.st1.1.1.1.1.m1.1c">&gt;0.7</annotation></semantics></math></th>
<td id="S10.T9.st1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S10.T9.st1.1.1.1.2.1" class="ltx_text" style="font-size:70%;">17.25</span></td>
<td id="S10.T9.st1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S10.T9.st1.1.1.1.3.1" class="ltx_text" style="font-size:70%;">72.32</span></td>
</tr>
<tr id="S10.T9.st1.2.2.2" class="ltx_tr">
<th id="S10.T9.st1.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S10.T9.st1.2.2.2.1.m1.1" class="ltx_Math" alttext="&gt;0.6" display="inline"><semantics id="S10.T9.st1.2.2.2.1.m1.1a"><mrow id="S10.T9.st1.2.2.2.1.m1.1.1" xref="S10.T9.st1.2.2.2.1.m1.1.1.cmml"><mi id="S10.T9.st1.2.2.2.1.m1.1.1.2" xref="S10.T9.st1.2.2.2.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S10.T9.st1.2.2.2.1.m1.1.1.1" xref="S10.T9.st1.2.2.2.1.m1.1.1.1.cmml">&gt;</mo><mn mathsize="70%" id="S10.T9.st1.2.2.2.1.m1.1.1.3" xref="S10.T9.st1.2.2.2.1.m1.1.1.3.cmml">0.6</mn></mrow><annotation-xml encoding="MathML-Content" id="S10.T9.st1.2.2.2.1.m1.1b"><apply id="S10.T9.st1.2.2.2.1.m1.1.1.cmml" xref="S10.T9.st1.2.2.2.1.m1.1.1"><gt id="S10.T9.st1.2.2.2.1.m1.1.1.1.cmml" xref="S10.T9.st1.2.2.2.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S10.T9.st1.2.2.2.1.m1.1.1.2.cmml" xref="S10.T9.st1.2.2.2.1.m1.1.1.2">absent</csymbol><cn type="float" id="S10.T9.st1.2.2.2.1.m1.1.1.3.cmml" xref="S10.T9.st1.2.2.2.1.m1.1.1.3">0.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S10.T9.st1.2.2.2.1.m1.1c">&gt;0.6</annotation></semantics></math></th>
<td id="S10.T9.st1.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S10.T9.st1.2.2.2.2.1" class="ltx_text" style="font-size:70%;">30.26</span></td>
<td id="S10.T9.st1.2.2.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S10.T9.st1.2.2.2.3.1" class="ltx_text" style="font-size:70%;">75.68</span></td>
</tr>
<tr id="S10.T9.st1.3.3.3" class="ltx_tr">
<th id="S10.T9.st1.3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S10.T9.st1.3.3.3.1.m1.1" class="ltx_Math" alttext="&gt;0.5" display="inline"><semantics id="S10.T9.st1.3.3.3.1.m1.1a"><mrow id="S10.T9.st1.3.3.3.1.m1.1.1" xref="S10.T9.st1.3.3.3.1.m1.1.1.cmml"><mi id="S10.T9.st1.3.3.3.1.m1.1.1.2" xref="S10.T9.st1.3.3.3.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S10.T9.st1.3.3.3.1.m1.1.1.1" xref="S10.T9.st1.3.3.3.1.m1.1.1.1.cmml">&gt;</mo><mn mathsize="70%" id="S10.T9.st1.3.3.3.1.m1.1.1.3" xref="S10.T9.st1.3.3.3.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S10.T9.st1.3.3.3.1.m1.1b"><apply id="S10.T9.st1.3.3.3.1.m1.1.1.cmml" xref="S10.T9.st1.3.3.3.1.m1.1.1"><gt id="S10.T9.st1.3.3.3.1.m1.1.1.1.cmml" xref="S10.T9.st1.3.3.3.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S10.T9.st1.3.3.3.1.m1.1.1.2.cmml" xref="S10.T9.st1.3.3.3.1.m1.1.1.2">absent</csymbol><cn type="float" id="S10.T9.st1.3.3.3.1.m1.1.1.3.cmml" xref="S10.T9.st1.3.3.3.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S10.T9.st1.3.3.3.1.m1.1c">&gt;0.5</annotation></semantics></math></th>
<td id="S10.T9.st1.3.3.3.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S10.T9.st1.3.3.3.2.1" class="ltx_text" style="font-size:70%;">44.76</span></td>
<td id="S10.T9.st1.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S10.T9.st1.3.3.3.3.1" class="ltx_text" style="font-size:70%;">75.94</span></td>
</tr>
<tr id="S10.T9.st1.4.4.4" class="ltx_tr">
<th id="S10.T9.st1.4.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S10.T9.st1.4.4.4.1.m1.1" class="ltx_Math" alttext="&gt;0.4" display="inline"><semantics id="S10.T9.st1.4.4.4.1.m1.1a"><mrow id="S10.T9.st1.4.4.4.1.m1.1.1" xref="S10.T9.st1.4.4.4.1.m1.1.1.cmml"><mi id="S10.T9.st1.4.4.4.1.m1.1.1.2" xref="S10.T9.st1.4.4.4.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S10.T9.st1.4.4.4.1.m1.1.1.1" xref="S10.T9.st1.4.4.4.1.m1.1.1.1.cmml">&gt;</mo><mn mathsize="70%" id="S10.T9.st1.4.4.4.1.m1.1.1.3" xref="S10.T9.st1.4.4.4.1.m1.1.1.3.cmml">0.4</mn></mrow><annotation-xml encoding="MathML-Content" id="S10.T9.st1.4.4.4.1.m1.1b"><apply id="S10.T9.st1.4.4.4.1.m1.1.1.cmml" xref="S10.T9.st1.4.4.4.1.m1.1.1"><gt id="S10.T9.st1.4.4.4.1.m1.1.1.1.cmml" xref="S10.T9.st1.4.4.4.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S10.T9.st1.4.4.4.1.m1.1.1.2.cmml" xref="S10.T9.st1.4.4.4.1.m1.1.1.2">absent</csymbol><cn type="float" id="S10.T9.st1.4.4.4.1.m1.1.1.3.cmml" xref="S10.T9.st1.4.4.4.1.m1.1.1.3">0.4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S10.T9.st1.4.4.4.1.m1.1c">&gt;0.4</annotation></semantics></math></th>
<td id="S10.T9.st1.4.4.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S10.T9.st1.4.4.4.2.1" class="ltx_text" style="font-size:70%;">61.71</span></td>
<td id="S10.T9.st1.4.4.4.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S10.T9.st1.4.4.4.3.1" class="ltx_text" style="font-size:70%;">76.61</span></td>
</tr>
<tr id="S10.T9.st1.5.5.5" class="ltx_tr">
<th id="S10.T9.st1.5.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S10.T9.st1.5.5.5.1.m1.1" class="ltx_Math" alttext="&gt;0.3" display="inline"><semantics id="S10.T9.st1.5.5.5.1.m1.1a"><mrow id="S10.T9.st1.5.5.5.1.m1.1.1" xref="S10.T9.st1.5.5.5.1.m1.1.1.cmml"><mi id="S10.T9.st1.5.5.5.1.m1.1.1.2" xref="S10.T9.st1.5.5.5.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S10.T9.st1.5.5.5.1.m1.1.1.1" xref="S10.T9.st1.5.5.5.1.m1.1.1.1.cmml">&gt;</mo><mn mathsize="70%" id="S10.T9.st1.5.5.5.1.m1.1.1.3" xref="S10.T9.st1.5.5.5.1.m1.1.1.3.cmml">0.3</mn></mrow><annotation-xml encoding="MathML-Content" id="S10.T9.st1.5.5.5.1.m1.1b"><apply id="S10.T9.st1.5.5.5.1.m1.1.1.cmml" xref="S10.T9.st1.5.5.5.1.m1.1.1"><gt id="S10.T9.st1.5.5.5.1.m1.1.1.1.cmml" xref="S10.T9.st1.5.5.5.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S10.T9.st1.5.5.5.1.m1.1.1.2.cmml" xref="S10.T9.st1.5.5.5.1.m1.1.1.2">absent</csymbol><cn type="float" id="S10.T9.st1.5.5.5.1.m1.1.1.3.cmml" xref="S10.T9.st1.5.5.5.1.m1.1.1.3">0.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S10.T9.st1.5.5.5.1.m1.1c">&gt;0.3</annotation></semantics></math></th>
<td id="S10.T9.st1.5.5.5.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S10.T9.st1.5.5.5.2.1" class="ltx_text" style="font-size:70%;">80.56</span></td>
<td id="S10.T9.st1.5.5.5.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S10.T9.st1.5.5.5.3.1" class="ltx_text" style="font-size:70%;">77.02</span></td>
</tr>
<tr id="S10.T9.st1.6.6.6" class="ltx_tr">
<th id="S10.T9.st1.6.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r"><math id="S10.T9.st1.6.6.6.1.m1.1" class="ltx_Math" alttext="&gt;0.2" display="inline"><semantics id="S10.T9.st1.6.6.6.1.m1.1a"><mrow id="S10.T9.st1.6.6.6.1.m1.1.1" xref="S10.T9.st1.6.6.6.1.m1.1.1.cmml"><mi id="S10.T9.st1.6.6.6.1.m1.1.1.2" xref="S10.T9.st1.6.6.6.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S10.T9.st1.6.6.6.1.m1.1.1.1" xref="S10.T9.st1.6.6.6.1.m1.1.1.1.cmml">&gt;</mo><mn mathsize="70%" id="S10.T9.st1.6.6.6.1.m1.1.1.3" xref="S10.T9.st1.6.6.6.1.m1.1.1.3.cmml">0.2</mn></mrow><annotation-xml encoding="MathML-Content" id="S10.T9.st1.6.6.6.1.m1.1b"><apply id="S10.T9.st1.6.6.6.1.m1.1.1.cmml" xref="S10.T9.st1.6.6.6.1.m1.1.1"><gt id="S10.T9.st1.6.6.6.1.m1.1.1.1.cmml" xref="S10.T9.st1.6.6.6.1.m1.1.1.1"></gt><csymbol cd="latexml" id="S10.T9.st1.6.6.6.1.m1.1.1.2.cmml" xref="S10.T9.st1.6.6.6.1.m1.1.1.2">absent</csymbol><cn type="float" id="S10.T9.st1.6.6.6.1.m1.1.1.3.cmml" xref="S10.T9.st1.6.6.6.1.m1.1.1.3">0.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S10.T9.st1.6.6.6.1.m1.1c">&gt;0.2</annotation></semantics></math></th>
<td id="S10.T9.st1.6.6.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S10.T9.st1.6.6.6.2.1" class="ltx_text" style="font-size:70%;">95.55</span></td>
<td id="S10.T9.st1.6.6.6.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S10.T9.st1.6.6.6.3.1" class="ltx_text" style="font-size:70%;">77.31</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S10.T9.st1.10.1.1" class="ltx_text" style="font-size:129%;">(a)</span> </span><span id="S10.T9.st1.11.2" class="ltx_text" style="font-size:129%;">PSNR above threshold</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S10.T9.st2" class="ltx_table ltx_figure_panel ltx_align_center">
<table id="S10.T9.st2.6.6" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S10.T9.st2.6.6.7.1" class="ltx_tr">
<th id="S10.T9.st2.6.6.7.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S10.T9.st2.6.6.7.1.1.1" class="ltx_text" style="font-size:70%;">SSIM</span></th>
<th id="S10.T9.st2.6.6.7.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S10.T9.st2.6.6.7.1.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S10.T9.st2.6.6.7.1.2.1.1" class="ltx_tr">
<td id="S10.T9.st2.6.6.7.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S10.T9.st2.6.6.7.1.2.1.1.1.1" class="ltx_text" style="font-size:70%;">% imgs</span></td>
</tr>
<tr id="S10.T9.st2.6.6.7.1.2.1.2" class="ltx_tr">
<td id="S10.T9.st2.6.6.7.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S10.T9.st2.6.6.7.1.2.1.2.1.1" class="ltx_text" style="font-size:70%;">kept</span></td>
</tr>
</table>
</th>
<th id="S10.T9.st2.6.6.7.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<table id="S10.T9.st2.6.6.7.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S10.T9.st2.6.6.7.1.3.1.1" class="ltx_tr">
<td id="S10.T9.st2.6.6.7.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S10.T9.st2.6.6.7.1.3.1.1.1.1" class="ltx_text" style="font-size:70%;">Test</span></td>
</tr>
<tr id="S10.T9.st2.6.6.7.1.3.1.2" class="ltx_tr">
<td id="S10.T9.st2.6.6.7.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S10.T9.st2.6.6.7.1.3.1.2.1.1" class="ltx_text" style="font-size:70%;">accuracy</span></td>
</tr>
</table>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S10.T9.st2.1.1.1" class="ltx_tr">
<th id="S10.T9.st2.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><math id="S10.T9.st2.1.1.1.1.m1.1" class="ltx_Math" alttext="&lt;0.7" display="inline"><semantics id="S10.T9.st2.1.1.1.1.m1.1a"><mrow id="S10.T9.st2.1.1.1.1.m1.1.1" xref="S10.T9.st2.1.1.1.1.m1.1.1.cmml"><mi id="S10.T9.st2.1.1.1.1.m1.1.1.2" xref="S10.T9.st2.1.1.1.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S10.T9.st2.1.1.1.1.m1.1.1.1" xref="S10.T9.st2.1.1.1.1.m1.1.1.1.cmml">&lt;</mo><mn mathsize="70%" id="S10.T9.st2.1.1.1.1.m1.1.1.3" xref="S10.T9.st2.1.1.1.1.m1.1.1.3.cmml">0.7</mn></mrow><annotation-xml encoding="MathML-Content" id="S10.T9.st2.1.1.1.1.m1.1b"><apply id="S10.T9.st2.1.1.1.1.m1.1.1.cmml" xref="S10.T9.st2.1.1.1.1.m1.1.1"><lt id="S10.T9.st2.1.1.1.1.m1.1.1.1.cmml" xref="S10.T9.st2.1.1.1.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S10.T9.st2.1.1.1.1.m1.1.1.2.cmml" xref="S10.T9.st2.1.1.1.1.m1.1.1.2">absent</csymbol><cn type="float" id="S10.T9.st2.1.1.1.1.m1.1.1.3.cmml" xref="S10.T9.st2.1.1.1.1.m1.1.1.3">0.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S10.T9.st2.1.1.1.1.m1.1c">&lt;0.7</annotation></semantics></math></th>
<td id="S10.T9.st2.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S10.T9.st2.1.1.1.2.1" class="ltx_text" style="font-size:70%;">82.75</span></td>
<td id="S10.T9.st2.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S10.T9.st2.1.1.1.3.1" class="ltx_text" style="font-size:70%;">70.94</span></td>
</tr>
<tr id="S10.T9.st2.2.2.2" class="ltx_tr">
<th id="S10.T9.st2.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S10.T9.st2.2.2.2.1.m1.1" class="ltx_Math" alttext="&lt;0.6" display="inline"><semantics id="S10.T9.st2.2.2.2.1.m1.1a"><mrow id="S10.T9.st2.2.2.2.1.m1.1.1" xref="S10.T9.st2.2.2.2.1.m1.1.1.cmml"><mi id="S10.T9.st2.2.2.2.1.m1.1.1.2" xref="S10.T9.st2.2.2.2.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S10.T9.st2.2.2.2.1.m1.1.1.1" xref="S10.T9.st2.2.2.2.1.m1.1.1.1.cmml">&lt;</mo><mn mathsize="70%" id="S10.T9.st2.2.2.2.1.m1.1.1.3" xref="S10.T9.st2.2.2.2.1.m1.1.1.3.cmml">0.6</mn></mrow><annotation-xml encoding="MathML-Content" id="S10.T9.st2.2.2.2.1.m1.1b"><apply id="S10.T9.st2.2.2.2.1.m1.1.1.cmml" xref="S10.T9.st2.2.2.2.1.m1.1.1"><lt id="S10.T9.st2.2.2.2.1.m1.1.1.1.cmml" xref="S10.T9.st2.2.2.2.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S10.T9.st2.2.2.2.1.m1.1.1.2.cmml" xref="S10.T9.st2.2.2.2.1.m1.1.1.2">absent</csymbol><cn type="float" id="S10.T9.st2.2.2.2.1.m1.1.1.3.cmml" xref="S10.T9.st2.2.2.2.1.m1.1.1.3">0.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S10.T9.st2.2.2.2.1.m1.1c">&lt;0.6</annotation></semantics></math></th>
<td id="S10.T9.st2.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S10.T9.st2.2.2.2.2.1" class="ltx_text" style="font-size:70%;">69.74</span></td>
<td id="S10.T9.st2.2.2.2.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S10.T9.st2.2.2.2.3.1" class="ltx_text" style="font-size:70%;">61.66</span></td>
</tr>
<tr id="S10.T9.st2.3.3.3" class="ltx_tr">
<th id="S10.T9.st2.3.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S10.T9.st2.3.3.3.1.m1.1" class="ltx_Math" alttext="&lt;0.5" display="inline"><semantics id="S10.T9.st2.3.3.3.1.m1.1a"><mrow id="S10.T9.st2.3.3.3.1.m1.1.1" xref="S10.T9.st2.3.3.3.1.m1.1.1.cmml"><mi id="S10.T9.st2.3.3.3.1.m1.1.1.2" xref="S10.T9.st2.3.3.3.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S10.T9.st2.3.3.3.1.m1.1.1.1" xref="S10.T9.st2.3.3.3.1.m1.1.1.1.cmml">&lt;</mo><mn mathsize="70%" id="S10.T9.st2.3.3.3.1.m1.1.1.3" xref="S10.T9.st2.3.3.3.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S10.T9.st2.3.3.3.1.m1.1b"><apply id="S10.T9.st2.3.3.3.1.m1.1.1.cmml" xref="S10.T9.st2.3.3.3.1.m1.1.1"><lt id="S10.T9.st2.3.3.3.1.m1.1.1.1.cmml" xref="S10.T9.st2.3.3.3.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S10.T9.st2.3.3.3.1.m1.1.1.2.cmml" xref="S10.T9.st2.3.3.3.1.m1.1.1.2">absent</csymbol><cn type="float" id="S10.T9.st2.3.3.3.1.m1.1.1.3.cmml" xref="S10.T9.st2.3.3.3.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S10.T9.st2.3.3.3.1.m1.1c">&lt;0.5</annotation></semantics></math></th>
<td id="S10.T9.st2.3.3.3.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S10.T9.st2.3.3.3.2.1" class="ltx_text" style="font-size:70%;">55.24</span></td>
<td id="S10.T9.st2.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S10.T9.st2.3.3.3.3.1" class="ltx_text" style="font-size:70%;">57.34</span></td>
</tr>
<tr id="S10.T9.st2.4.4.4" class="ltx_tr">
<th id="S10.T9.st2.4.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S10.T9.st2.4.4.4.1.m1.1" class="ltx_Math" alttext="&lt;0.4" display="inline"><semantics id="S10.T9.st2.4.4.4.1.m1.1a"><mrow id="S10.T9.st2.4.4.4.1.m1.1.1" xref="S10.T9.st2.4.4.4.1.m1.1.1.cmml"><mi id="S10.T9.st2.4.4.4.1.m1.1.1.2" xref="S10.T9.st2.4.4.4.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S10.T9.st2.4.4.4.1.m1.1.1.1" xref="S10.T9.st2.4.4.4.1.m1.1.1.1.cmml">&lt;</mo><mn mathsize="70%" id="S10.T9.st2.4.4.4.1.m1.1.1.3" xref="S10.T9.st2.4.4.4.1.m1.1.1.3.cmml">0.4</mn></mrow><annotation-xml encoding="MathML-Content" id="S10.T9.st2.4.4.4.1.m1.1b"><apply id="S10.T9.st2.4.4.4.1.m1.1.1.cmml" xref="S10.T9.st2.4.4.4.1.m1.1.1"><lt id="S10.T9.st2.4.4.4.1.m1.1.1.1.cmml" xref="S10.T9.st2.4.4.4.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S10.T9.st2.4.4.4.1.m1.1.1.2.cmml" xref="S10.T9.st2.4.4.4.1.m1.1.1.2">absent</csymbol><cn type="float" id="S10.T9.st2.4.4.4.1.m1.1.1.3.cmml" xref="S10.T9.st2.4.4.4.1.m1.1.1.3">0.4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S10.T9.st2.4.4.4.1.m1.1c">&lt;0.4</annotation></semantics></math></th>
<td id="S10.T9.st2.4.4.4.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S10.T9.st2.4.4.4.2.1" class="ltx_text" style="font-size:70%;">38.29</span></td>
<td id="S10.T9.st2.4.4.4.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S10.T9.st2.4.4.4.3.1" class="ltx_text" style="font-size:70%;">51.56</span></td>
</tr>
<tr id="S10.T9.st2.5.5.5" class="ltx_tr">
<th id="S10.T9.st2.5.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r"><math id="S10.T9.st2.5.5.5.1.m1.1" class="ltx_Math" alttext="&lt;0.3" display="inline"><semantics id="S10.T9.st2.5.5.5.1.m1.1a"><mrow id="S10.T9.st2.5.5.5.1.m1.1.1" xref="S10.T9.st2.5.5.5.1.m1.1.1.cmml"><mi id="S10.T9.st2.5.5.5.1.m1.1.1.2" xref="S10.T9.st2.5.5.5.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S10.T9.st2.5.5.5.1.m1.1.1.1" xref="S10.T9.st2.5.5.5.1.m1.1.1.1.cmml">&lt;</mo><mn mathsize="70%" id="S10.T9.st2.5.5.5.1.m1.1.1.3" xref="S10.T9.st2.5.5.5.1.m1.1.1.3.cmml">0.3</mn></mrow><annotation-xml encoding="MathML-Content" id="S10.T9.st2.5.5.5.1.m1.1b"><apply id="S10.T9.st2.5.5.5.1.m1.1.1.cmml" xref="S10.T9.st2.5.5.5.1.m1.1.1"><lt id="S10.T9.st2.5.5.5.1.m1.1.1.1.cmml" xref="S10.T9.st2.5.5.5.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S10.T9.st2.5.5.5.1.m1.1.1.2.cmml" xref="S10.T9.st2.5.5.5.1.m1.1.1.2">absent</csymbol><cn type="float" id="S10.T9.st2.5.5.5.1.m1.1.1.3.cmml" xref="S10.T9.st2.5.5.5.1.m1.1.1.3">0.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S10.T9.st2.5.5.5.1.m1.1c">&lt;0.3</annotation></semantics></math></th>
<td id="S10.T9.st2.5.5.5.2" class="ltx_td ltx_align_center ltx_border_r"><span id="S10.T9.st2.5.5.5.2.1" class="ltx_text" style="font-size:70%;">19.44</span></td>
<td id="S10.T9.st2.5.5.5.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S10.T9.st2.5.5.5.3.1" class="ltx_text" style="font-size:70%;">47.00</span></td>
</tr>
<tr id="S10.T9.st2.6.6.6" class="ltx_tr">
<th id="S10.T9.st2.6.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r"><math id="S10.T9.st2.6.6.6.1.m1.1" class="ltx_Math" alttext="&lt;0.2" display="inline"><semantics id="S10.T9.st2.6.6.6.1.m1.1a"><mrow id="S10.T9.st2.6.6.6.1.m1.1.1" xref="S10.T9.st2.6.6.6.1.m1.1.1.cmml"><mi id="S10.T9.st2.6.6.6.1.m1.1.1.2" xref="S10.T9.st2.6.6.6.1.m1.1.1.2.cmml"></mi><mo mathsize="70%" id="S10.T9.st2.6.6.6.1.m1.1.1.1" xref="S10.T9.st2.6.6.6.1.m1.1.1.1.cmml">&lt;</mo><mn mathsize="70%" id="S10.T9.st2.6.6.6.1.m1.1.1.3" xref="S10.T9.st2.6.6.6.1.m1.1.1.3.cmml">0.2</mn></mrow><annotation-xml encoding="MathML-Content" id="S10.T9.st2.6.6.6.1.m1.1b"><apply id="S10.T9.st2.6.6.6.1.m1.1.1.cmml" xref="S10.T9.st2.6.6.6.1.m1.1.1"><lt id="S10.T9.st2.6.6.6.1.m1.1.1.1.cmml" xref="S10.T9.st2.6.6.6.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S10.T9.st2.6.6.6.1.m1.1.1.2.cmml" xref="S10.T9.st2.6.6.6.1.m1.1.1.2">absent</csymbol><cn type="float" id="S10.T9.st2.6.6.6.1.m1.1.1.3.cmml" xref="S10.T9.st2.6.6.6.1.m1.1.1.3">0.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S10.T9.st2.6.6.6.1.m1.1c">&lt;0.2</annotation></semantics></math></th>
<td id="S10.T9.st2.6.6.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S10.T9.st2.6.6.6.2.1" class="ltx_text" style="font-size:70%;">4.45</span></td>
<td id="S10.T9.st2.6.6.6.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S10.T9.st2.6.6.6.3.1" class="ltx_text" style="font-size:70%;">32.36</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:70%;"><span class="ltx_tag ltx_tag_table"><span id="S10.T9.st2.10.1.1" class="ltx_text" style="font-size:129%;">(b)</span> </span><span id="S10.T9.st2.11.2" class="ltx_text" style="font-size:129%;">PSNR below threshold</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering" style="font-size:144%;"><span class="ltx_tag ltx_tag_table"><span id="S10.T9.4.1.1" class="ltx_text" style="font-size:63%;">Table 9</span>: </span><span id="S10.T9.5.2" class="ltx_text" style="font-size:63%;"> Training models using CIFAR-10 leaked data from inverting gradients batch size 16. Only the reconstructions with an SSIM (a) above and (b) below the threshold are used in training.</span></figcaption>
</figure>
<div id="S10.p1" class="ltx_para">
<p id="S10.p1.5" class="ltx_p"><span id="S10.p1.5.1" class="ltx_text" style="font-size:144%;">Table </span><a href="#S10.T9" title="Table 9 ‣ 10 SSIM threshold ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">9</span></a><span id="S10.p1.5.2" class="ltx_text" style="font-size:144%;"> shows the test accuracy of models trained while removing images based on the SSIM. Table </span><a href="#S10.T9.st1" title="Table 9(a) ‣ Table 9 ‣ 10 SSIM threshold ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">9(a)</span></a><span id="S10.p1.5.3" class="ltx_text" style="font-size:144%;"> shows accuracy when only images </span><span id="S10.p1.5.4" class="ltx_text ltx_font_italic" style="font-size:144%;">above</span><span id="S10.p1.5.5" class="ltx_text" style="font-size:144%;"> an SSIM threshold are used. Table </span><a href="#S10.T9.st2" title="Table 9(b) ‣ Table 9 ‣ 10 SSIM threshold ‣ Leak and Learn: An Attacker’s Cookbook to Train Using Leaked Data from Federated Learning" class="ltx_ref" style="font-size:144%;"><span class="ltx_text ltx_ref_tag">9(b)</span></a><span id="S10.p1.5.6" class="ltx_text" style="font-size:144%;"> shows accuracy when images </span><span id="S10.p1.5.7" class="ltx_text ltx_font_italic" style="font-size:144%;">below</span><span id="S10.p1.5.8" class="ltx_text" style="font-size:144%;"> an SSIM threshold are used. For SSIM, removing a set of the worst images with SSIM </span><math id="S10.p1.1.m1.1" class="ltx_Math" alttext="&lt;0.2" display="inline"><semantics id="S10.p1.1.m1.1a"><mrow id="S10.p1.1.m1.1.1" xref="S10.p1.1.m1.1.1.cmml"><mi id="S10.p1.1.m1.1.1.2" xref="S10.p1.1.m1.1.1.2.cmml"></mi><mo mathsize="144%" id="S10.p1.1.m1.1.1.1" xref="S10.p1.1.m1.1.1.1.cmml">&lt;</mo><mn mathsize="144%" id="S10.p1.1.m1.1.1.3" xref="S10.p1.1.m1.1.1.3.cmml">0.2</mn></mrow><annotation-xml encoding="MathML-Content" id="S10.p1.1.m1.1b"><apply id="S10.p1.1.m1.1.1.cmml" xref="S10.p1.1.m1.1.1"><lt id="S10.p1.1.m1.1.1.1.cmml" xref="S10.p1.1.m1.1.1.1"></lt><csymbol cd="latexml" id="S10.p1.1.m1.1.1.2.cmml" xref="S10.p1.1.m1.1.1.2">absent</csymbol><cn type="float" id="S10.p1.1.m1.1.1.3.cmml" xref="S10.p1.1.m1.1.1.3">0.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S10.p1.1.m1.1c">&lt;0.2</annotation></semantics></math><span id="S10.p1.5.9" class="ltx_text" style="font-size:144%;"> or </span><math id="S10.p1.2.m2.1" class="ltx_Math" alttext="&lt;0.3" display="inline"><semantics id="S10.p1.2.m2.1a"><mrow id="S10.p1.2.m2.1.1" xref="S10.p1.2.m2.1.1.cmml"><mi id="S10.p1.2.m2.1.1.2" xref="S10.p1.2.m2.1.1.2.cmml"></mi><mo mathsize="144%" id="S10.p1.2.m2.1.1.1" xref="S10.p1.2.m2.1.1.1.cmml">&lt;</mo><mn mathsize="144%" id="S10.p1.2.m2.1.1.3" xref="S10.p1.2.m2.1.1.3.cmml">0.3</mn></mrow><annotation-xml encoding="MathML-Content" id="S10.p1.2.m2.1b"><apply id="S10.p1.2.m2.1.1.cmml" xref="S10.p1.2.m2.1.1"><lt id="S10.p1.2.m2.1.1.1.cmml" xref="S10.p1.2.m2.1.1.1"></lt><csymbol cd="latexml" id="S10.p1.2.m2.1.1.2.cmml" xref="S10.p1.2.m2.1.1.2">absent</csymbol><cn type="float" id="S10.p1.2.m2.1.1.3.cmml" xref="S10.p1.2.m2.1.1.3">0.3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S10.p1.2.m2.1c">&lt;0.3</annotation></semantics></math><span id="S10.p1.5.10" class="ltx_text" style="font-size:144%;"> results in a small model performance increase compared to when all images are included (which achieves </span><math id="S10.p1.3.m3.1" class="ltx_Math" alttext="76.83\%" display="inline"><semantics id="S10.p1.3.m3.1a"><mrow id="S10.p1.3.m3.1.1" xref="S10.p1.3.m3.1.1.cmml"><mn mathsize="144%" id="S10.p1.3.m3.1.1.2" xref="S10.p1.3.m3.1.1.2.cmml">76.83</mn><mo mathsize="144%" id="S10.p1.3.m3.1.1.1" xref="S10.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S10.p1.3.m3.1b"><apply id="S10.p1.3.m3.1.1.cmml" xref="S10.p1.3.m3.1.1"><csymbol cd="latexml" id="S10.p1.3.m3.1.1.1.cmml" xref="S10.p1.3.m3.1.1.1">percent</csymbol><cn type="float" id="S10.p1.3.m3.1.1.2.cmml" xref="S10.p1.3.m3.1.1.2">76.83</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S10.p1.3.m3.1c">76.83\%</annotation></semantics></math><span id="S10.p1.5.11" class="ltx_text" style="font-size:144%;">). Similar to PSNR, training on a set of the worst quality reconstructions (SSIM </span><math id="S10.p1.4.m4.1" class="ltx_Math" alttext="&lt;0.2" display="inline"><semantics id="S10.p1.4.m4.1a"><mrow id="S10.p1.4.m4.1.1" xref="S10.p1.4.m4.1.1.cmml"><mi id="S10.p1.4.m4.1.1.2" xref="S10.p1.4.m4.1.1.2.cmml"></mi><mo mathsize="144%" id="S10.p1.4.m4.1.1.1" xref="S10.p1.4.m4.1.1.1.cmml">&lt;</mo><mn mathsize="144%" id="S10.p1.4.m4.1.1.3" xref="S10.p1.4.m4.1.1.3.cmml">0.2</mn></mrow><annotation-xml encoding="MathML-Content" id="S10.p1.4.m4.1b"><apply id="S10.p1.4.m4.1.1.cmml" xref="S10.p1.4.m4.1.1"><lt id="S10.p1.4.m4.1.1.1.cmml" xref="S10.p1.4.m4.1.1.1"></lt><csymbol cd="latexml" id="S10.p1.4.m4.1.1.2.cmml" xref="S10.p1.4.m4.1.1.2">absent</csymbol><cn type="float" id="S10.p1.4.m4.1.1.3.cmml" xref="S10.p1.4.m4.1.1.3">0.2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S10.p1.4.m4.1c">&lt;0.2</annotation></semantics></math><span id="S10.p1.5.12" class="ltx_text" style="font-size:144%;">) achieves </span><math id="S10.p1.5.m5.1" class="ltx_Math" alttext="32.36\%" display="inline"><semantics id="S10.p1.5.m5.1a"><mrow id="S10.p1.5.m5.1.1" xref="S10.p1.5.m5.1.1.cmml"><mn mathsize="144%" id="S10.p1.5.m5.1.1.2" xref="S10.p1.5.m5.1.1.2.cmml">32.36</mn><mo mathsize="144%" id="S10.p1.5.m5.1.1.1" xref="S10.p1.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S10.p1.5.m5.1b"><apply id="S10.p1.5.m5.1.1.cmml" xref="S10.p1.5.m5.1.1"><csymbol cd="latexml" id="S10.p1.5.m5.1.1.1.cmml" xref="S10.p1.5.m5.1.1.1">percent</csymbol><cn type="float" id="S10.p1.5.m5.1.1.2.cmml" xref="S10.p1.5.m5.1.1.2">32.36</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S10.p1.5.m5.1c">32.36\%</annotation></semantics></math><span id="S10.p1.5.13" class="ltx_text" style="font-size:144%;"> accuracy, a higher accuracy than random guessing, but much lower performance compared to the baseline.</span></p>
</div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2403.18143" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2403.18144" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2403.18144">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2403.18144" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2403.18145" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Apr  5 13:39:42 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
