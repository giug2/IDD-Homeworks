<article class="ltx_document ltx_authors_1line">
 <div class="ltx_para" id="p1">
  <span class="ltx_ERROR undefined" id="p1.1">
   \pdfcolInitStack
  </span>
  <p class="ltx_p" id="p1.2">
   tcb@breakable
  </p>
 </div>
 <h1 class="ltx_title ltx_title_document">
  An Embodied Generalist Agent in 3D World
 </h1>
 <div class="ltx_authors">
  <span class="ltx_creator ltx_role_author">
   <span class="ltx_personname">
    Jiangyong Huang
    <sup class="ltx_sup" id="id15.15.id1">
     <span class="ltx_text ltx_font_italic" id="id15.15.id1.1">
      1,2∗
     </span>
    </sup>
    , Silong Yong
    <sup class="ltx_sup" id="id16.16.id2">
     <span class="ltx_text ltx_font_italic" id="id16.16.id2.1">
      1,3∗
     </span>
    </sup>
    , Xiaojian Ma
    <sup class="ltx_sup" id="id17.17.id3">
     <span class="ltx_text ltx_font_italic" id="id17.17.id3.1">
      1∗
     </span>
    </sup>
    , Xiongkun Linghu
    <sup class="ltx_sup" id="id18.18.id4">
     <span class="ltx_text ltx_font_italic" id="id18.18.id4.1">
      1∗
     </span>
    </sup>
    , Puhao Li
    <sup class="ltx_sup" id="id19.19.id5">
     <span class="ltx_text ltx_font_italic" id="id19.19.id5.1">
      1,4
     </span>
    </sup>
    ,
    <br class="ltx_break"/>
    <span class="ltx_text ltx_font_bold" id="id10.10.5">
     Yan Wang
     <sup class="ltx_sup" id="id10.10.5.1">
      <span class="ltx_text ltx_font_medium" id="id10.10.5.1.1">
       1
      </span>
     </sup>
     , Qing Li
     <sup class="ltx_sup" id="id10.10.5.2">
      <span class="ltx_text ltx_font_medium" id="id10.10.5.2.1">
       1
      </span>
     </sup>
     , Song-Chun Zhu
     <sup class="ltx_sup" id="id10.10.5.3">
      <span class="ltx_text ltx_font_medium ltx_font_italic" id="id10.10.5.3.1">
       1,2,4
      </span>
     </sup>
     , Baoxiong Jia
     <sup class="ltx_sup" id="id10.10.5.4">
      <span class="ltx_text ltx_font_medium" id="id10.10.5.4.1">
       1
      </span>
     </sup>
     , Siyuan Huang
     <sup class="ltx_sup" id="id10.10.5.5">
      <span class="ltx_text ltx_font_medium" id="id10.10.5.5.1">
       1
      </span>
     </sup>
    </span>
    <br class="ltx_break"/>
    <sup class="ltx_sup" id="id20.20.id6">
     1
    </sup>
    Beijing Institute for General Artificial Intelligence (BIGAI)
    <br class="ltx_break"/>
    <sup class="ltx_sup" id="id21.21.id7">
     2
    </sup>
    Peking University
    <sup class="ltx_sup" id="id22.22.id8">
     3
    </sup>
    Carnegie Mellon University
    <sup class="ltx_sup" id="id23.23.id9">
     4
    </sup>
    Tsinghua University
    <br class="ltx_break"/>
    <a class="ltx_ref ltx_url ltx_font_typewriter ltx_font_bold" href="https://embodied-generalist.github.io" target="_blank" title="">
     https://embodied-generalist.github.io
    </a>
   </span>
  </span>
 </div>
 <div class="ltx_abstract">
  <h6 class="ltx_title ltx_title_abstract">
   Abstract
  </h6>
  <p class="ltx_p" id="id24.id1">
   Leveraging massive knowledge and learning schemes from large language models (LLMs), recent machine learning models show notable successes in building generalist agents that exhibit the capability of general-purpose task solving in diverse domains, including natural language processing, computer vision, and robotics. However, a significant challenge remains as these models exhibit limited ability in understanding and interacting with the 3D world. We argue this limitation significantly hinders the current models from performing real-world tasks and further achieving general intelligence. To this end, we introduce an embodied multi-modal and multi-task generalist agent that excels in perceiving, grounding, reasoning, planning, and acting in the 3D world. Our proposed agent, referred to as
   <span class="ltx_text ltx_font_smallcaps" id="id24.id1.1">
    LEO
   </span>
   , is trained with shared LLM-based model architectures, objectives, and weights in two stages: (i) 3D vision-language alignment and (ii) 3D vision-language-action instruction tuning. To facilitate the training, we meticulously curate and generate an extensive dataset comprising object-level and scene-level multi-modal tasks with exceeding scale and complexity, necessitating a deep understanding of and interaction with the 3D world. Through rigorous experiments, we demonstrate
   <span class="ltx_text ltx_font_smallcaps" id="id24.id1.2">
    LEO
   </span>
   ’s remarkable proficiency across a wide spectrum of tasks, including 3D captioning, question answering, embodied reasoning, embodied navigation, and robotic manipulation. Our ablation results further provide valuable insights for the development of future embodied generalist agents.
  </p>
 </div>
 <span class="ltx_note ltx_role_footnote" id="footnote1">
  <sup class="ltx_note_mark">
   †
  </sup>
  <span class="ltx_note_outer">
   <span class="ltx_note_content">
    <sup class="ltx_note_mark">
     †
    </sup>
    <sup class="ltx_sup" id="footnote1.1">
     ∗
    </sup>
    indicates equal contribution.
   </span>
  </span>
 </span>
 <section class="ltx_section" id="S1">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    1
   </span>
   Introduction
  </h2>
  <div class="ltx_para ltx_noindent" id="S1.p1">
   <p class="ltx_p" id="S1.p1.1">
    Building one generalist model that can achieve comprehensive tasks like humans has been a long-existing pursuit in artificial intelligence and neuroscience
    <cite class="ltx_cite ltx_citemacro_citep">
     (Lake et al.,
     <a class="ltx_ref" href="#bib.bib39" title="">
      2015
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib40" title="">
      2017
     </a>
     ; Zhu et al.,
     <a class="ltx_ref" href="#bib.bib93" title="">
      2020
     </a>
     ; Mountcastle,
     <a class="ltx_ref" href="#bib.bib53" title="">
      1979
     </a>
     ; Schmidhuber,
     <a class="ltx_ref" href="#bib.bib69" title="">
      2018
     </a>
     ; Huang et al.,
     <a class="ltx_ref" href="#bib.bib32" title="">
      2022a
     </a>
     )
    </cite>
    . Recent advances in
    <span class="ltx_glossaryref" title="large language models">
     <span class="ltx_text ltx_glossary_long">
      large language models
     </span>
    </span>
    (
    <abbr class="ltx_glossaryref" title="large language models">
     <span class="ltx_text ltx_glossary_short">
      LLMs
     </span>
    </abbr>
    )
    <cite class="ltx_cite ltx_citemacro_citep">
     (Brown et al.,
     <a class="ltx_ref" href="#bib.bib10" title="">
      2020
     </a>
     )
    </cite>
    and “foundation model”
    <cite class="ltx_cite ltx_citemacro_citep">
     (Bommasani et al.,
     <a class="ltx_ref" href="#bib.bib7" title="">
      2021
     </a>
     )
    </cite>
    emerge as a promising paradigm in building such generalist models in natural language processing
    <cite class="ltx_cite ltx_citemacro_citep">
     (OpenAI,
     <a class="ltx_ref" href="#bib.bib55" title="">
      2022
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib56" title="">
      2023
     </a>
     )
    </cite>
    , computer vision
    <cite class="ltx_cite ltx_citemacro_citep">
     (Kirillov et al.,
     <a class="ltx_ref" href="#bib.bib37" title="">
      2023
     </a>
     )
    </cite>
    , and robotics
    <cite class="ltx_cite ltx_citemacro_citep">
     (Brohan et al.,
     <a class="ltx_ref" href="#bib.bib8" title="">
      2022
     </a>
     ;
     <a class="ltx_ref" href="#bib.bib9" title="">
      2023
     </a>
     )
    </cite>
    . The keys to the success of this paradigm lie in large-scale internet-level datasets from numerous tasks and domains and scalable Transformer architectures
    <cite class="ltx_cite ltx_citemacro_citep">
     (Vaswani et al.,
     <a class="ltx_ref" href="#bib.bib76" title="">
      2017
     </a>
     )
    </cite>
    that can absorb generalizable and task-agnostic knowledge from the data. Such efforts are further extended to multi-modal
    <cite class="ltx_cite ltx_citemacro_citep">
     (Alayrac et al.,
     <a class="ltx_ref" href="#bib.bib3" title="">
      2022
     </a>
     ; Lu et al.,
     <a class="ltx_ref" href="#bib.bib49" title="">
      2023
     </a>
     ; Li et al.,
     <a class="ltx_ref" href="#bib.bib44" title="">
      2023c
     </a>
     )
    </cite>
    and generalist models
    <cite class="ltx_cite ltx_citemacro_citep">
     (Reed et al.,
     <a class="ltx_ref" href="#bib.bib65" title="">
      2022
     </a>
     ; Driess et al.,
     <a class="ltx_ref" href="#bib.bib23" title="">
      2023
     </a>
     )
    </cite>
    where the agents can solve versatile tasks based on the language-specified task descriptions and show certain generalizability to novel situations. Nonetheless, their abilities are primarily demonstrated within 2D domains, thereby limiting the comprehension of the 3D physical environment that envelops humans and other intelligent species. This limitation acts as an obstacle, preventing current models from successfully executing real-world tasks and the attainment of general intelligence. Therefore, we ask a fundamental question: how to equip the generalist agent with a comprehensive understanding of and the ability to interact with the real 3D world?
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S1.p2">
   <p class="ltx_p" id="S1.p2.1">
    The development of such generalist agents encounters three primary challenges: the creation of suitable datasets, the design of unified models, and the design of effective learning strategies. Despite substantial progresses in scaling up image-text models
    <cite class="ltx_cite ltx_citemacro_citep">
     (Tsimpoukelli et al.,
     <a class="ltx_ref" href="#bib.bib75" title="">
      2021
     </a>
     ; Alayrac et al.,
     <a class="ltx_ref" href="#bib.bib3" title="">
      2022
     </a>
     )
    </cite>
    and the curation of corresponding datasets
    <cite class="ltx_cite ltx_citemacro_citep">
     (Radford et al.,
     <a class="ltx_ref" href="#bib.bib61" title="">
      2021
     </a>
     ; Schuhmann et al.,
     <a class="ltx_ref" href="#bib.bib70" title="">
      2022
     </a>
     )
    </cite>
    , advancements in 3D scene-level understanding have significantly lagged behind. This is largely attributed to the limited scale and manual labeling of 3D datasets
    <cite class="ltx_cite ltx_citemacro_citep">
     (Dai et al.,
     <a class="ltx_ref" href="#bib.bib20" title="">
      2017
     </a>
     ; Wald et al.,
     <a class="ltx_ref" href="#bib.bib77" title="">
      2019
     </a>
     ; Chen et al.,
     <a class="ltx_ref" href="#bib.bib14" title="">
      2020
     </a>
     )
    </cite>
    , given the higher cost associated with collecting 3D data compared to 2D data. Furthermore, previous models have often been designed with strong priors
    <cite class="ltx_cite ltx_citemacro_citep">
     (Zhao et al.,
     <a class="ltx_ref" href="#bib.bib90" title="">
      2021
     </a>
     ; Chen et al.,
     <a class="ltx_ref" href="#bib.bib15" title="">
      2022
     </a>
     )
    </cite>
    , with limited exploration of large-scale unified pretraining and efficient fine-tuning based on
    <abbr class="ltx_glossaryref" title="large language models">
     <span class="ltx_text ltx_glossary_short">
      LLMs
     </span>
    </abbr>
    . Notably, recent works
    <cite class="ltx_cite ltx_citemacro_citep">
     (Zhu et al.,
     <a class="ltx_ref" href="#bib.bib94" title="">
      2023c
     </a>
     ; Hong et al.,
     <a class="ltx_ref" href="#bib.bib30" title="">
      2023
     </a>
     )
    </cite>
    utilize the unified Transformers or
    <abbr class="ltx_glossaryref" title="large language models">
     <span class="ltx_text ltx_glossary_short">
      LLMs
     </span>
    </abbr>
    to enhance the model’s capability in grounded 3D scene understanding. However, they still lack the agency to act within 3D environments and efforts in unleashing
    <abbr class="ltx_glossaryref" title="large language models">
     <span class="ltx_text ltx_glossary_short">
      LLMs
     </span>
    </abbr>
    for 3D
    <span class="ltx_glossaryref" title="vision-language-action">
     <span class="ltx_text ltx_glossary_long">
      vision-language-action
     </span>
    </span>
    (
    <abbr class="ltx_glossaryref" title="vision-language-action">
     <span class="ltx_text ltx_glossary_short">
      VLA
     </span>
    </abbr>
    ) learning.
How to equip the 3D agent with a simple unified architecture and effective learning strategy to establish VLA capability remains rarely explored.
   </p>
  </div>
  <figure class="ltx_figure" id="S1.F1">
   <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="209" id="S1.F1.g1" src="/html/2311.12871/assets/x1.png" width="422"/>
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_figure">
     Figure 1:
    </span>
    <span class="ltx_text ltx_font_bold" id="S1.F1.3.1">
     The proposed embodied generalist agent
     <span class="ltx_text ltx_font_smallcaps" id="S1.F1.3.1.1">
      LEO
     </span>
    </span>
    . It takes egocentric 2D images, 3D point clouds, and texts as input and formulates comprehensive 3D tasks as autoregressive sequence predictions. By fine-tuning
    <span class="ltx_text ltx_font_smallcaps" id="S1.F1.4.2">
     LEO
    </span>
    , it extends the capability of
    <abbr class="ltx_glossaryref" title="large language models">
     <span class="ltx_text ltx_glossary_short">
      LLMs
     </span>
    </abbr>
    to multi-modal vision-language-action tasks with a unified model.
   </figcaption>
  </figure>
  <div class="ltx_para ltx_noindent" id="S1.p3">
   <p class="ltx_p" id="S1.p3.1">
    In this work, we introduce the generalist agent
    <span class="ltx_text ltx_font_smallcaps" id="S1.p3.1.1">
     LEO
    </span>
    , which is generically embodied, multi-modal, and multi-task. It can take egocentric 2D images, 3D point clouds, and texts as task input and achieve comprehensive tasks within the 3D environment. As shown in
    <a class="ltx_ref" href="#S1.F1" title="In 1 Introduction ‣ An Embodied Generalist Agent in 3D World">
     <span class="ltx_text ltx_ref_tag">
      Fig.
     </span>
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    ,
    <span class="ltx_text ltx_font_smallcaps" id="S1.p3.1.2">
     LEO
     <span class="ltx_text ltx_font_italic" id="S1.p3.1.2.1">
      exhibits the capability of perceiving, grounding, reasoning, planning, and acting with shared model architectures and weights.
     </span>
    </span>
    <span class="ltx_text ltx_font_smallcaps" id="S1.p3.1.3">
     LEO
    </span>
    perceives through an egocentric 2D image encoder for the embodied view and an object-centric 3D point cloud encoder for the third-person global view. The 3D encoder generates an object-centric token for each observed entity. Such encoder design can be flexibly adapted to tasks with various embodiments. These output tokens are then interleaved with text tokens to form a scene-grounded instructional task sequence, which further serves as the input to a decoder-only LLM. All the tasks are re-formulated as sequence prediction problems. Therefore,
    <span class="ltx_text ltx_font_smallcaps" id="S1.p3.1.4">
     LEO
    </span>
    can be trained with task-agnostic inputs and outputs using autoregressive training objectives. To accommodate embodied tasks that predict action tokens, we employ a pool of special tokens to represent actions and replace the least used tokens
    <cite class="ltx_cite ltx_citemacro_citep">
     (Brohan et al.,
     <a class="ltx_ref" href="#bib.bib9" title="">
      2023
     </a>
     )
    </cite>
    in LLM. We perform LoRA
    <cite class="ltx_cite ltx_citemacro_citep">
     (Hu et al.,
     <a class="ltx_ref" href="#bib.bib31" title="">
      2022
     </a>
     )
    </cite>
    to fine-tune and adapt the innate knowledge of LLM to the multi-modal generalist.
    <span class="ltx_text ltx_font_smallcaps" id="S1.p3.1.5">
     LEO
    </span>
    demonstrates two essential capabilities: 3D vision-language grounding and 3D
    <abbr class="ltx_glossaryref" title="vision-language-action">
     <span class="ltx_text ltx_glossary_short">
      VLA
     </span>
    </abbr>
    . They are injected with two training stages: 3D vision-language alignment and
    <abbr class="ltx_glossaryref" title="vision-language-action">
     <span class="ltx_text ltx_glossary_short">
      VLA
     </span>
    </abbr>
    instruction-tuning. To facilitate the training, we curate a large-scale dataset with object-level and scene-level tasks by fusing existing datasets with high-quality data prompted from the
    <abbr class="ltx_glossaryref" title="large language models">
     <span class="ltx_text ltx_glossary_short">
      LLMs
     </span>
    </abbr>
    . We propose scene-graph-based prompting and refinement methods, along with
    <span class="ltx_glossaryref" title="Object-centric Chain-of-Thought">
     <span class="ltx_text ltx_glossary_long">
      Object-centric Chain-of-Thought
     </span>
    </span>
    (
    <abbr class="ltx_glossaryref" title="Object-centric Chain-of-Thought">
     <span class="ltx_text ltx_glossary_short">
      O-CoT
     </span>
    </abbr>
    ) for improving the quality of generated data, largely enriching the data scale and diversity, and further eliminating the hallucination of
    <abbr class="ltx_glossaryref" title="large language models">
     <span class="ltx_text ltx_glossary_short">
      LLMs
     </span>
    </abbr>
    .
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S1.p4">
   <p class="ltx_p" id="S1.p4.1">
    We quantitatively evaluate and ablate
    <span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.1">
     LEO
    </span>
    on diverse 3D tasks, including object-level and scene-level captioning
    <cite class="ltx_cite ltx_citemacro_citep">
     (Luo et al.,
     <a class="ltx_ref" href="#bib.bib50" title="">
      2023
     </a>
     ; Chen et al.,
     <a class="ltx_ref" href="#bib.bib17" title="">
      2021
     </a>
     )
    </cite>
    , 3D question answering
    <cite class="ltx_cite ltx_citemacro_citep">
     (Azuma et al.,
     <a class="ltx_ref" href="#bib.bib5" title="">
      2022
     </a>
     )
    </cite>
    , situated question answering
    <cite class="ltx_cite ltx_citemacro_citep">
     (Ma et al.,
     <a class="ltx_ref" href="#bib.bib51" title="">
      2023
     </a>
     )
    </cite>
    , embodied navigation
    <cite class="ltx_cite ltx_citemacro_citep">
     (Ramrakhya et al.,
     <a class="ltx_ref" href="#bib.bib64" title="">
      2022
     </a>
     )
    </cite>
    , and robotic manipulation
    <cite class="ltx_cite ltx_citemacro_citep">
     (Shridhar et al.,
     <a class="ltx_ref" href="#bib.bib72" title="">
      2021
     </a>
     )
    </cite>
    . The results indicate (i)
    <span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.2">
     LEO
    </span>
    achieves state-of-the-art results on most tasks; (ii) through task-agnostic instruction tuning with a unified model,
    <span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.3">
     LEO
    </span>
    outperforms most previous task-specific models on various domains; (iii) the pretraining of 3D vision-language alignment greatly elevates the performance of
    <abbr class="ltx_glossaryref" title="vision-language-action">
     <span class="ltx_text ltx_glossary_short">
      VLA
     </span>
    </abbr>
    instruction-tuning; (iv) scaling up the training data boosts the performance of generalist agent, similar to scaling laws
    <cite class="ltx_cite ltx_citemacro_citep">
     (Kaplan et al.,
     <a class="ltx_ref" href="#bib.bib35" title="">
      2020
     </a>
     ; OpenAI,
     <a class="ltx_ref" href="#bib.bib56" title="">
      2023
     </a>
     )
    </cite>
    in
    <abbr class="ltx_glossaryref" title="large language models">
     <span class="ltx_text ltx_glossary_short">
      LLMs
     </span>
    </abbr>
    and generalist agent
    <cite class="ltx_cite ltx_citemacro_citep">
     (Reed et al.,
     <a class="ltx_ref" href="#bib.bib65" title="">
      2022
     </a>
     )
    </cite>
    . We also show qualitative results of chatting with
    <span class="ltx_text ltx_font_smallcaps" id="S1.p4.1.4">
     LEO
    </span>
    over diverse tasks, demonstrating its capability in scene-aware planning and dialogue.
   </p>
  </div>
  <div class="ltx_para ltx_noindent" id="S1.p5">
   <p class="ltx_p" id="S1.p5.1">
    In summary, our main contributions are: (i) we propose
    <span class="ltx_text ltx_font_smallcaps" id="S1.p5.1.1">
     LEO
    </span>
    , the first generalist agent with the capability to perceive, ground, reason, plan, and act in the 3D world; (ii) we demonstrate that a generalist agent can be built via fine-tuning the LLM with object-centric multi-modal representations and mixing the training data with embodied action sequences, enabling it to excel in embodied tasks; (iii) we meticulously curate a large-scale dataset to train such agent and propose several techniques aimed at enhancing the quality of prompted data from
    <abbr class="ltx_glossaryref" title="large language models">
     <span class="ltx_text ltx_glossary_short">
      LLMs
     </span>
    </abbr>
    ; (iv) we extensively evaluate
    <span class="ltx_text ltx_font_smallcaps" id="S1.p5.1.2">
     LEO
    </span>
    and demonstrate its proficiency on diverse tasks including embodied navigation and robotic manipulation, we also observe consistent performance gains while simply scaling up the training data; (v) we will release the data, code, and model weights to endow the future research of generalist agents.
   </p>
  </div>
 </section>
 <section class="ltx_section" id="S2">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    2
   </span>
   Model
  </h2>
  <div class="ltx_para ltx_noindent" id="S2.p1">
   <p class="ltx_p" id="S2.p1.1">
    The leading design principles of
    <span class="ltx_text ltx_font_smallcaps" id="S2.p1.1.1">
     LEO
    </span>
    are two-fold: 1) It should handle the input of egocentric 2D, global 3D, and textual instruction, and the output of textual response as well as embodied action commands in a unified architecture; 2) It should leverage pretrained large language models (LLMs) as a powerful prior for the downstream tasks. We therefore convert all data of different modalities into a sequence of tokens, illustrated below:
   </p>
   <table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A9.EGx1">
    <tbody id="S2.E1">
     <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
      <td class="ltx_eqn_cell ltx_eqn_center_padleft">
      </td>
      <td class="ltx_td ltx_align_right ltx_eqn_cell">
       <math alttext="\displaystyle\underbrace{\text{{You are...}}}_{\text{system message}}~{}\underbrace{s_{\text{2D}}^{(1)},...,s_{\text{2D}}^{(M)}}_{\begin{subarray}{c}\text{2D image tokens}\\
\text{(optional)}\end{subarray}}\underbrace{s_{\text{3D}}^{(1)},...,s_{\text{3D}}^{(N)}}_{\begin{subarray}{c}\text{object-centric}\\
\text{3D tokens}\end{subarray}}~{}\underbrace{\text{{USER:... ASSISTANT:}}}_{\text{instruction}}~{}\underbrace{s_{\text{res}}^{(1)},...s_{\text{res}}^{(T)}}_{\text{response}}." class="ltx_Math" display="inline" id="S2.E1.m1.17">
        <semantics id="S2.E1.m1.17a">
         <mrow id="S2.E1.m1.17.17.1" xref="S2.E1.m1.17.17.1.1.cmml">
          <mrow id="S2.E1.m1.17.17.1.1" xref="S2.E1.m1.17.17.1.1.cmml">
           <munder id="S2.E1.m1.17.17.1.1.2" xref="S2.E1.m1.17.17.1.1.2.cmml">
            <munder accentunder="true" id="S2.E1.m1.17.17.1.1.2.2" xref="S2.E1.m1.17.17.1.1.2.2.cmml">
             <mtext class="ltx_mathvariant_monospace" id="S2.E1.m1.17.17.1.1.2.2.2" xref="S2.E1.m1.17.17.1.1.2.2.2a.cmml">
              You are...
             </mtext>
             <mo id="S2.E1.m1.17.17.1.1.2.2.1" xref="S2.E1.m1.17.17.1.1.2.2.1.cmml">
              ⏟
             </mo>
            </munder>
            <mtext id="S2.E1.m1.17.17.1.1.2.3" xref="S2.E1.m1.17.17.1.1.2.3a.cmml">
             system message
            </mtext>
           </munder>
           <mo id="S2.E1.m1.17.17.1.1.1" lspace="0.330em" rspace="0em" xref="S2.E1.m1.17.17.1.1.1.cmml">
            ​
           </mo>
           <munder id="S2.E1.m1.17.17.1.1.3" xref="S2.E1.m1.17.17.1.1.3.cmml">
            <munder accentunder="true" id="S2.E1.m1.7.7" xref="S2.E1.m1.7.7.cmml">
             <mrow id="S2.E1.m1.7.7.5.5" xref="S2.E1.m1.7.7.5.6.cmml">
              <msubsup id="S2.E1.m1.6.6.4.4.1" xref="S2.E1.m1.6.6.4.4.1.cmml">
               <mi id="S2.E1.m1.6.6.4.4.1.2.2" xref="S2.E1.m1.6.6.4.4.1.2.2.cmml">
                s
               </mi>
               <mtext id="S2.E1.m1.6.6.4.4.1.2.3" xref="S2.E1.m1.6.6.4.4.1.2.3a.cmml">
                2D
               </mtext>
               <mrow id="S2.E1.m1.3.3.1.1.1.3" xref="S2.E1.m1.6.6.4.4.1.cmml">
                <mo id="S2.E1.m1.3.3.1.1.1.3.1" stretchy="false" xref="S2.E1.m1.6.6.4.4.1.cmml">
                 (
                </mo>
                <mn id="S2.E1.m1.3.3.1.1.1.1" xref="S2.E1.m1.3.3.1.1.1.1.cmml">
                 1
                </mn>
                <mo id="S2.E1.m1.3.3.1.1.1.3.2" stretchy="false" xref="S2.E1.m1.6.6.4.4.1.cmml">
                 )
                </mo>
               </mrow>
              </msubsup>
              <mo id="S2.E1.m1.7.7.5.5.3" xref="S2.E1.m1.7.7.5.6.cmml">
               ,
              </mo>
              <mi id="S2.E1.m1.5.5.3.3" mathvariant="normal" xref="S2.E1.m1.5.5.3.3.cmml">
               …
              </mi>
              <mo id="S2.E1.m1.7.7.5.5.4" xref="S2.E1.m1.7.7.5.6.cmml">
               ,
              </mo>
              <msubsup id="S2.E1.m1.7.7.5.5.2" xref="S2.E1.m1.7.7.5.5.2.cmml">
               <mi id="S2.E1.m1.7.7.5.5.2.2.2" xref="S2.E1.m1.7.7.5.5.2.2.2.cmml">
                s
               </mi>
               <mtext id="S2.E1.m1.7.7.5.5.2.2.3" xref="S2.E1.m1.7.7.5.5.2.2.3a.cmml">
                2D
               </mtext>
               <mrow id="S2.E1.m1.4.4.2.2.1.3" xref="S2.E1.m1.7.7.5.5.2.cmml">
                <mo id="S2.E1.m1.4.4.2.2.1.3.1" stretchy="false" xref="S2.E1.m1.7.7.5.5.2.cmml">
                 (
                </mo>
                <mi id="S2.E1.m1.4.4.2.2.1.1" xref="S2.E1.m1.4.4.2.2.1.1.cmml">
                 M
                </mi>
                <mo id="S2.E1.m1.4.4.2.2.1.3.2" stretchy="false" xref="S2.E1.m1.7.7.5.5.2.cmml">
                 )
                </mo>
               </mrow>
              </msubsup>
             </mrow>
             <mo id="S2.E1.m1.7.7.6" xref="S2.E1.m1.7.7.6.cmml">
              ⏟
             </mo>
            </munder>
            <mtable id="S2.E1.m1.1.1.1.1.1.1" rowspacing="0pt" xref="S2.E1.m1.1.1.1a.2.cmml">
             <mtr id="S2.E1.m1.1.1.1.1.1.1a" xref="S2.E1.m1.1.1.1a.2.cmml">
              <mtd id="S2.E1.m1.1.1.1.1.1.1b" xref="S2.E1.m1.1.1.1a.2.cmml">
               <mtext id="S2.E1.m1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1a.cmml">
                2D image tokens
               </mtext>
              </mtd>
             </mtr>
             <mtr id="S2.E1.m1.1.1.1.1.1.1c" xref="S2.E1.m1.1.1.1a.2.cmml">
              <mtd id="S2.E1.m1.1.1.1.1.1.1d" xref="S2.E1.m1.1.1.1a.2.cmml">
               <mtext id="S2.E1.m1.1.1.1.1.1.1.2.1.1" xref="S2.E1.m1.1.1.1.1.1.1.2.1.1a.cmml">
                (optional)
               </mtext>
              </mtd>
             </mtr>
            </mtable>
           </munder>
           <mo id="S2.E1.m1.17.17.1.1.1a" lspace="0em" rspace="0em" xref="S2.E1.m1.17.17.1.1.1.cmml">
            ​
           </mo>
           <munder id="S2.E1.m1.17.17.1.1.4" xref="S2.E1.m1.17.17.1.1.4.cmml">
            <munder accentunder="true" id="S2.E1.m1.12.12" xref="S2.E1.m1.12.12.cmml">
             <mrow id="S2.E1.m1.12.12.5.5" xref="S2.E1.m1.12.12.5.6.cmml">
              <msubsup id="S2.E1.m1.11.11.4.4.1" xref="S2.E1.m1.11.11.4.4.1.cmml">
               <mi id="S2.E1.m1.11.11.4.4.1.2.2" xref="S2.E1.m1.11.11.4.4.1.2.2.cmml">
                s
               </mi>
               <mtext id="S2.E1.m1.11.11.4.4.1.2.3" xref="S2.E1.m1.11.11.4.4.1.2.3a.cmml">
                3D
               </mtext>
               <mrow id="S2.E1.m1.8.8.1.1.1.3" xref="S2.E1.m1.11.11.4.4.1.cmml">
                <mo id="S2.E1.m1.8.8.1.1.1.3.1" stretchy="false" xref="S2.E1.m1.11.11.4.4.1.cmml">
                 (
                </mo>
                <mn id="S2.E1.m1.8.8.1.1.1.1" xref="S2.E1.m1.8.8.1.1.1.1.cmml">
                 1
                </mn>
                <mo id="S2.E1.m1.8.8.1.1.1.3.2" stretchy="false" xref="S2.E1.m1.11.11.4.4.1.cmml">
                 )
                </mo>
               </mrow>
              </msubsup>
              <mo id="S2.E1.m1.12.12.5.5.3" xref="S2.E1.m1.12.12.5.6.cmml">
               ,
              </mo>
              <mi id="S2.E1.m1.10.10.3.3" mathvariant="normal" xref="S2.E1.m1.10.10.3.3.cmml">
               …
              </mi>
              <mo id="S2.E1.m1.12.12.5.5.4" xref="S2.E1.m1.12.12.5.6.cmml">
               ,
              </mo>
              <msubsup id="S2.E1.m1.12.12.5.5.2" xref="S2.E1.m1.12.12.5.5.2.cmml">
               <mi id="S2.E1.m1.12.12.5.5.2.2.2" xref="S2.E1.m1.12.12.5.5.2.2.2.cmml">
                s
               </mi>
               <mtext id="S2.E1.m1.12.12.5.5.2.2.3" xref="S2.E1.m1.12.12.5.5.2.2.3a.cmml">
                3D
               </mtext>
               <mrow id="S2.E1.m1.9.9.2.2.1.3" xref="S2.E1.m1.12.12.5.5.2.cmml">
                <mo id="S2.E1.m1.9.9.2.2.1.3.1" stretchy="false" xref="S2.E1.m1.12.12.5.5.2.cmml">
                 (
                </mo>
                <mi id="S2.E1.m1.9.9.2.2.1.1" xref="S2.E1.m1.9.9.2.2.1.1.cmml">
                 N
                </mi>
                <mo id="S2.E1.m1.9.9.2.2.1.3.2" stretchy="false" xref="S2.E1.m1.12.12.5.5.2.cmml">
                 )
                </mo>
               </mrow>
              </msubsup>
             </mrow>
             <mo id="S2.E1.m1.12.12.6" xref="S2.E1.m1.12.12.6.cmml">
              ⏟
             </mo>
            </munder>
            <mtable id="S2.E1.m1.2.2.1.1.1.1" rowspacing="0pt" xref="S2.E1.m1.2.2.1a.2.cmml">
             <mtr id="S2.E1.m1.2.2.1.1.1.1a" xref="S2.E1.m1.2.2.1a.2.cmml">
              <mtd id="S2.E1.m1.2.2.1.1.1.1b" xref="S2.E1.m1.2.2.1a.2.cmml">
               <mtext id="S2.E1.m1.2.2.1.1.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1a.cmml">
                object-centric
               </mtext>
              </mtd>
             </mtr>
             <mtr id="S2.E1.m1.2.2.1.1.1.1c" xref="S2.E1.m1.2.2.1a.2.cmml">
              <mtd id="S2.E1.m1.2.2.1.1.1.1d" xref="S2.E1.m1.2.2.1a.2.cmml">
               <mtext id="S2.E1.m1.2.2.1.1.1.1.2.1.1" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1a.cmml">
                3D tokens
               </mtext>
              </mtd>
             </mtr>
            </mtable>
           </munder>
           <mo id="S2.E1.m1.17.17.1.1.1b" lspace="0em" rspace="0em" xref="S2.E1.m1.17.17.1.1.1.cmml">
            ​
           </mo>
           <munder id="S2.E1.m1.17.17.1.1.5" xref="S2.E1.m1.17.17.1.1.5.cmml">
            <munder accentunder="true" id="S2.E1.m1.17.17.1.1.5.2" xref="S2.E1.m1.17.17.1.1.5.2.cmml">
             <mtext class="ltx_mathvariant_monospace" id="S2.E1.m1.17.17.1.1.5.2.2" xref="S2.E1.m1.17.17.1.1.5.2.2a.cmml">
              USER:... ASSISTANT:
             </mtext>
             <mo id="S2.E1.m1.17.17.1.1.5.2.1" xref="S2.E1.m1.17.17.1.1.5.2.1.cmml">
              ⏟
             </mo>
            </munder>
            <mtext id="S2.E1.m1.17.17.1.1.5.3" xref="S2.E1.m1.17.17.1.1.5.3a.cmml">
             instruction
            </mtext>
           </munder>
           <mo id="S2.E1.m1.17.17.1.1.1c" lspace="0em" rspace="0em" xref="S2.E1.m1.17.17.1.1.1.cmml">
            ​
           </mo>
           <munder id="S2.E1.m1.17.17.1.1.6" xref="S2.E1.m1.17.17.1.1.6.cmml">
            <munder accentunder="true" id="S2.E1.m1.16.16" xref="S2.E1.m1.16.16.cmml">
             <mrow id="S2.E1.m1.16.16.4.4" xref="S2.E1.m1.16.16.4.5.cmml">
              <msubsup id="S2.E1.m1.15.15.3.3.1" xref="S2.E1.m1.15.15.3.3.1.cmml">
               <mi id="S2.E1.m1.15.15.3.3.1.2.2" xref="S2.E1.m1.15.15.3.3.1.2.2.cmml">
                s
               </mi>
               <mtext id="S2.E1.m1.15.15.3.3.1.2.3" xref="S2.E1.m1.15.15.3.3.1.2.3a.cmml">
                res
               </mtext>
               <mrow id="S2.E1.m1.13.13.1.1.1.3" xref="S2.E1.m1.15.15.3.3.1.cmml">
                <mo id="S2.E1.m1.13.13.1.1.1.3.1" stretchy="false" xref="S2.E1.m1.15.15.3.3.1.cmml">
                 (
                </mo>
                <mn id="S2.E1.m1.13.13.1.1.1.1" xref="S2.E1.m1.13.13.1.1.1.1.cmml">
                 1
                </mn>
                <mo id="S2.E1.m1.13.13.1.1.1.3.2" stretchy="false" xref="S2.E1.m1.15.15.3.3.1.cmml">
                 )
                </mo>
               </mrow>
              </msubsup>
              <mo id="S2.E1.m1.16.16.4.4.3" xref="S2.E1.m1.16.16.4.5.cmml">
               ,
              </mo>
              <mrow id="S2.E1.m1.16.16.4.4.2" xref="S2.E1.m1.16.16.4.4.2.cmml">
               <mi id="S2.E1.m1.16.16.4.4.2.2" mathvariant="normal" xref="S2.E1.m1.16.16.4.4.2.2.cmml">
                …
               </mi>
               <mo id="S2.E1.m1.16.16.4.4.2.1" lspace="0em" rspace="0em" xref="S2.E1.m1.16.16.4.4.2.1.cmml">
                ​
               </mo>
               <msubsup id="S2.E1.m1.16.16.4.4.2.3" xref="S2.E1.m1.16.16.4.4.2.3.cmml">
                <mi id="S2.E1.m1.16.16.4.4.2.3.2.2" xref="S2.E1.m1.16.16.4.4.2.3.2.2.cmml">
                 s
                </mi>
                <mtext id="S2.E1.m1.16.16.4.4.2.3.2.3" xref="S2.E1.m1.16.16.4.4.2.3.2.3a.cmml">
                 res
                </mtext>
                <mrow id="S2.E1.m1.14.14.2.2.1.3" xref="S2.E1.m1.16.16.4.4.2.3.cmml">
                 <mo id="S2.E1.m1.14.14.2.2.1.3.1" stretchy="false" xref="S2.E1.m1.16.16.4.4.2.3.cmml">
                  (
                 </mo>
                 <mi id="S2.E1.m1.14.14.2.2.1.1" xref="S2.E1.m1.14.14.2.2.1.1.cmml">
                  T
                 </mi>
                 <mo id="S2.E1.m1.14.14.2.2.1.3.2" stretchy="false" xref="S2.E1.m1.16.16.4.4.2.3.cmml">
                  )
                 </mo>
                </mrow>
               </msubsup>
              </mrow>
             </mrow>
             <mo id="S2.E1.m1.16.16.5" xref="S2.E1.m1.16.16.5.cmml">
              ⏟
             </mo>
            </munder>
            <mtext id="S2.E1.m1.17.17.1.1.6.2" xref="S2.E1.m1.17.17.1.1.6.2a.cmml">
             response
            </mtext>
           </munder>
          </mrow>
          <mo id="S2.E1.m1.17.17.1.2" lspace="0em" xref="S2.E1.m1.17.17.1.1.cmml">
           .
          </mo>
         </mrow>
         <annotation-xml encoding="MathML-Content" id="S2.E1.m1.17b">
          <apply id="S2.E1.m1.17.17.1.1.cmml" xref="S2.E1.m1.17.17.1">
           <times id="S2.E1.m1.17.17.1.1.1.cmml" xref="S2.E1.m1.17.17.1.1.1">
           </times>
           <apply id="S2.E1.m1.17.17.1.1.2.cmml" xref="S2.E1.m1.17.17.1.1.2">
            <csymbol cd="ambiguous" id="S2.E1.m1.17.17.1.1.2.1.cmml" xref="S2.E1.m1.17.17.1.1.2">
             subscript
            </csymbol>
            <apply id="S2.E1.m1.17.17.1.1.2.2.cmml" xref="S2.E1.m1.17.17.1.1.2.2">
             <ci id="S2.E1.m1.17.17.1.1.2.2.1.cmml" xref="S2.E1.m1.17.17.1.1.2.2.1">
              ⏟
             </ci>
             <ci id="S2.E1.m1.17.17.1.1.2.2.2a.cmml" xref="S2.E1.m1.17.17.1.1.2.2.2">
              <mtext class="ltx_mathvariant_monospace" id="S2.E1.m1.17.17.1.1.2.2.2.cmml" xref="S2.E1.m1.17.17.1.1.2.2.2">
               You are...
              </mtext>
             </ci>
            </apply>
            <ci id="S2.E1.m1.17.17.1.1.2.3a.cmml" xref="S2.E1.m1.17.17.1.1.2.3">
             <mtext id="S2.E1.m1.17.17.1.1.2.3.cmml" mathsize="70%" xref="S2.E1.m1.17.17.1.1.2.3">
              system message
             </mtext>
            </ci>
           </apply>
           <apply id="S2.E1.m1.17.17.1.1.3.cmml" xref="S2.E1.m1.17.17.1.1.3">
            <csymbol cd="ambiguous" id="S2.E1.m1.17.17.1.1.3.1.cmml" xref="S2.E1.m1.17.17.1.1.3">
             subscript
            </csymbol>
            <apply id="S2.E1.m1.7.7.cmml" xref="S2.E1.m1.7.7">
             <ci id="S2.E1.m1.7.7.6.cmml" xref="S2.E1.m1.7.7.6">
              ⏟
             </ci>
             <list id="S2.E1.m1.7.7.5.6.cmml" xref="S2.E1.m1.7.7.5.5">
              <apply id="S2.E1.m1.6.6.4.4.1.cmml" xref="S2.E1.m1.6.6.4.4.1">
               <csymbol cd="ambiguous" id="S2.E1.m1.6.6.4.4.1.1.cmml" xref="S2.E1.m1.6.6.4.4.1">
                superscript
               </csymbol>
               <apply id="S2.E1.m1.6.6.4.4.1.2.cmml" xref="S2.E1.m1.6.6.4.4.1">
                <csymbol cd="ambiguous" id="S2.E1.m1.6.6.4.4.1.2.1.cmml" xref="S2.E1.m1.6.6.4.4.1">
                 subscript
                </csymbol>
                <ci id="S2.E1.m1.6.6.4.4.1.2.2.cmml" xref="S2.E1.m1.6.6.4.4.1.2.2">
                 𝑠
                </ci>
                <ci id="S2.E1.m1.6.6.4.4.1.2.3a.cmml" xref="S2.E1.m1.6.6.4.4.1.2.3">
                 <mtext id="S2.E1.m1.6.6.4.4.1.2.3.cmml" mathsize="70%" xref="S2.E1.m1.6.6.4.4.1.2.3">
                  2D
                 </mtext>
                </ci>
               </apply>
               <cn id="S2.E1.m1.3.3.1.1.1.1.cmml" type="integer" xref="S2.E1.m1.3.3.1.1.1.1">
                1
               </cn>
              </apply>
              <ci id="S2.E1.m1.5.5.3.3.cmml" xref="S2.E1.m1.5.5.3.3">
               …
              </ci>
              <apply id="S2.E1.m1.7.7.5.5.2.cmml" xref="S2.E1.m1.7.7.5.5.2">
               <csymbol cd="ambiguous" id="S2.E1.m1.7.7.5.5.2.1.cmml" xref="S2.E1.m1.7.7.5.5.2">
                superscript
               </csymbol>
               <apply id="S2.E1.m1.7.7.5.5.2.2.cmml" xref="S2.E1.m1.7.7.5.5.2">
                <csymbol cd="ambiguous" id="S2.E1.m1.7.7.5.5.2.2.1.cmml" xref="S2.E1.m1.7.7.5.5.2">
                 subscript
                </csymbol>
                <ci id="S2.E1.m1.7.7.5.5.2.2.2.cmml" xref="S2.E1.m1.7.7.5.5.2.2.2">
                 𝑠
                </ci>
                <ci id="S2.E1.m1.7.7.5.5.2.2.3a.cmml" xref="S2.E1.m1.7.7.5.5.2.2.3">
                 <mtext id="S2.E1.m1.7.7.5.5.2.2.3.cmml" mathsize="70%" xref="S2.E1.m1.7.7.5.5.2.2.3">
                  2D
                 </mtext>
                </ci>
               </apply>
               <ci id="S2.E1.m1.4.4.2.2.1.1.cmml" xref="S2.E1.m1.4.4.2.2.1.1">
                𝑀
               </ci>
              </apply>
             </list>
            </apply>
            <list id="S2.E1.m1.1.1.1a.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1">
             <matrix id="S2.E1.m1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1">
              <matrixrow id="S2.E1.m1.1.1.1.1.1.1a.cmml" xref="S2.E1.m1.1.1.1.1.1.1">
               <ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1a.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1">
                <mtext id="S2.E1.m1.1.1.1.1.1.1.1.1.1.cmml" mathsize="70%" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1">
                 2D image tokens
                </mtext>
               </ci>
              </matrixrow>
              <matrixrow id="S2.E1.m1.1.1.1.1.1.1b.cmml" xref="S2.E1.m1.1.1.1.1.1.1">
               <ci id="S2.E1.m1.1.1.1.1.1.1.2.1.1a.cmml" xref="S2.E1.m1.1.1.1.1.1.1.2.1.1">
                <mtext id="S2.E1.m1.1.1.1.1.1.1.2.1.1.cmml" mathsize="70%" xref="S2.E1.m1.1.1.1.1.1.1.2.1.1">
                 (optional)
                </mtext>
               </ci>
              </matrixrow>
             </matrix>
            </list>
           </apply>
           <apply id="S2.E1.m1.17.17.1.1.4.cmml" xref="S2.E1.m1.17.17.1.1.4">
            <csymbol cd="ambiguous" id="S2.E1.m1.17.17.1.1.4.1.cmml" xref="S2.E1.m1.17.17.1.1.4">
             subscript
            </csymbol>
            <apply id="S2.E1.m1.12.12.cmml" xref="S2.E1.m1.12.12">
             <ci id="S2.E1.m1.12.12.6.cmml" xref="S2.E1.m1.12.12.6">
              ⏟
             </ci>
             <list id="S2.E1.m1.12.12.5.6.cmml" xref="S2.E1.m1.12.12.5.5">
              <apply id="S2.E1.m1.11.11.4.4.1.cmml" xref="S2.E1.m1.11.11.4.4.1">
               <csymbol cd="ambiguous" id="S2.E1.m1.11.11.4.4.1.1.cmml" xref="S2.E1.m1.11.11.4.4.1">
                superscript
               </csymbol>
               <apply id="S2.E1.m1.11.11.4.4.1.2.cmml" xref="S2.E1.m1.11.11.4.4.1">
                <csymbol cd="ambiguous" id="S2.E1.m1.11.11.4.4.1.2.1.cmml" xref="S2.E1.m1.11.11.4.4.1">
                 subscript
                </csymbol>
                <ci id="S2.E1.m1.11.11.4.4.1.2.2.cmml" xref="S2.E1.m1.11.11.4.4.1.2.2">
                 𝑠
                </ci>
                <ci id="S2.E1.m1.11.11.4.4.1.2.3a.cmml" xref="S2.E1.m1.11.11.4.4.1.2.3">
                 <mtext id="S2.E1.m1.11.11.4.4.1.2.3.cmml" mathsize="70%" xref="S2.E1.m1.11.11.4.4.1.2.3">
                  3D
                 </mtext>
                </ci>
               </apply>
               <cn id="S2.E1.m1.8.8.1.1.1.1.cmml" type="integer" xref="S2.E1.m1.8.8.1.1.1.1">
                1
               </cn>
              </apply>
              <ci id="S2.E1.m1.10.10.3.3.cmml" xref="S2.E1.m1.10.10.3.3">
               …
              </ci>
              <apply id="S2.E1.m1.12.12.5.5.2.cmml" xref="S2.E1.m1.12.12.5.5.2">
               <csymbol cd="ambiguous" id="S2.E1.m1.12.12.5.5.2.1.cmml" xref="S2.E1.m1.12.12.5.5.2">
                superscript
               </csymbol>
               <apply id="S2.E1.m1.12.12.5.5.2.2.cmml" xref="S2.E1.m1.12.12.5.5.2">
                <csymbol cd="ambiguous" id="S2.E1.m1.12.12.5.5.2.2.1.cmml" xref="S2.E1.m1.12.12.5.5.2">
                 subscript
                </csymbol>
                <ci id="S2.E1.m1.12.12.5.5.2.2.2.cmml" xref="S2.E1.m1.12.12.5.5.2.2.2">
                 𝑠
                </ci>
                <ci id="S2.E1.m1.12.12.5.5.2.2.3a.cmml" xref="S2.E1.m1.12.12.5.5.2.2.3">
                 <mtext id="S2.E1.m1.12.12.5.5.2.2.3.cmml" mathsize="70%" xref="S2.E1.m1.12.12.5.5.2.2.3">
                  3D
                 </mtext>
                </ci>
               </apply>
               <ci id="S2.E1.m1.9.9.2.2.1.1.cmml" xref="S2.E1.m1.9.9.2.2.1.1">
                𝑁
               </ci>
              </apply>
             </list>
            </apply>
            <list id="S2.E1.m1.2.2.1a.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1">
             <matrix id="S2.E1.m1.2.2.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1">
              <matrixrow id="S2.E1.m1.2.2.1.1.1.1a.cmml" xref="S2.E1.m1.2.2.1.1.1.1">
               <ci id="S2.E1.m1.2.2.1.1.1.1.1.1.1a.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1">
                <mtext id="S2.E1.m1.2.2.1.1.1.1.1.1.1.cmml" mathsize="70%" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1">
                 object-centric
                </mtext>
               </ci>
              </matrixrow>
              <matrixrow id="S2.E1.m1.2.2.1.1.1.1b.cmml" xref="S2.E1.m1.2.2.1.1.1.1">
               <ci id="S2.E1.m1.2.2.1.1.1.1.2.1.1a.cmml" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1">
                <mtext id="S2.E1.m1.2.2.1.1.1.1.2.1.1.cmml" mathsize="70%" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1">
                 3D tokens
                </mtext>
               </ci>
              </matrixrow>
             </matrix>
            </list>
           </apply>
           <apply id="S2.E1.m1.17.17.1.1.5.cmml" xref="S2.E1.m1.17.17.1.1.5">
            <csymbol cd="ambiguous" id="S2.E1.m1.17.17.1.1.5.1.cmml" xref="S2.E1.m1.17.17.1.1.5">
             subscript
            </csymbol>
            <apply id="S2.E1.m1.17.17.1.1.5.2.cmml" xref="S2.E1.m1.17.17.1.1.5.2">
             <ci id="S2.E1.m1.17.17.1.1.5.2.1.cmml" xref="S2.E1.m1.17.17.1.1.5.2.1">
              ⏟
             </ci>
             <ci id="S2.E1.m1.17.17.1.1.5.2.2a.cmml" xref="S2.E1.m1.17.17.1.1.5.2.2">
              <mtext class="ltx_mathvariant_monospace" id="S2.E1.m1.17.17.1.1.5.2.2.cmml" xref="S2.E1.m1.17.17.1.1.5.2.2">
               USER:... ASSISTANT:
              </mtext>
             </ci>
            </apply>
            <ci id="S2.E1.m1.17.17.1.1.5.3a.cmml" xref="S2.E1.m1.17.17.1.1.5.3">
             <mtext id="S2.E1.m1.17.17.1.1.5.3.cmml" mathsize="70%" xref="S2.E1.m1.17.17.1.1.5.3">
              instruction
             </mtext>
            </ci>
           </apply>
           <apply id="S2.E1.m1.17.17.1.1.6.cmml" xref="S2.E1.m1.17.17.1.1.6">
            <csymbol cd="ambiguous" id="S2.E1.m1.17.17.1.1.6.1.cmml" xref="S2.E1.m1.17.17.1.1.6">
             subscript
            </csymbol>
            <apply id="S2.E1.m1.16.16.cmml" xref="S2.E1.m1.16.16">
             <ci id="S2.E1.m1.16.16.5.cmml" xref="S2.E1.m1.16.16.5">
              ⏟
             </ci>
             <list id="S2.E1.m1.16.16.4.5.cmml" xref="S2.E1.m1.16.16.4.4">
              <apply id="S2.E1.m1.15.15.3.3.1.cmml" xref="S2.E1.m1.15.15.3.3.1">
               <csymbol cd="ambiguous" id="S2.E1.m1.15.15.3.3.1.1.cmml" xref="S2.E1.m1.15.15.3.3.1">
                superscript
               </csymbol>
               <apply id="S2.E1.m1.15.15.3.3.1.2.cmml" xref="S2.E1.m1.15.15.3.3.1">
                <csymbol cd="ambiguous" id="S2.E1.m1.15.15.3.3.1.2.1.cmml" xref="S2.E1.m1.15.15.3.3.1">
                 subscript
                </csymbol>
                <ci id="S2.E1.m1.15.15.3.3.1.2.2.cmml" xref="S2.E1.m1.15.15.3.3.1.2.2">
                 𝑠
                </ci>
                <ci id="S2.E1.m1.15.15.3.3.1.2.3a.cmml" xref="S2.E1.m1.15.15.3.3.1.2.3">
                 <mtext id="S2.E1.m1.15.15.3.3.1.2.3.cmml" mathsize="70%" xref="S2.E1.m1.15.15.3.3.1.2.3">
                  res
                 </mtext>
                </ci>
               </apply>
               <cn id="S2.E1.m1.13.13.1.1.1.1.cmml" type="integer" xref="S2.E1.m1.13.13.1.1.1.1">
                1
               </cn>
              </apply>
              <apply id="S2.E1.m1.16.16.4.4.2.cmml" xref="S2.E1.m1.16.16.4.4.2">
               <times id="S2.E1.m1.16.16.4.4.2.1.cmml" xref="S2.E1.m1.16.16.4.4.2.1">
               </times>
               <ci id="S2.E1.m1.16.16.4.4.2.2.cmml" xref="S2.E1.m1.16.16.4.4.2.2">
                …
               </ci>
               <apply id="S2.E1.m1.16.16.4.4.2.3.cmml" xref="S2.E1.m1.16.16.4.4.2.3">
                <csymbol cd="ambiguous" id="S2.E1.m1.16.16.4.4.2.3.1.cmml" xref="S2.E1.m1.16.16.4.4.2.3">
                 superscript
                </csymbol>
                <apply id="S2.E1.m1.16.16.4.4.2.3.2.cmml" xref="S2.E1.m1.16.16.4.4.2.3">
                 <csymbol cd="ambiguous" id="S2.E1.m1.16.16.4.4.2.3.2.1.cmml" xref="S2.E1.m1.16.16.4.4.2.3">
                  subscript
                 </csymbol>
                 <ci id="S2.E1.m1.16.16.4.4.2.3.2.2.cmml" xref="S2.E1.m1.16.16.4.4.2.3.2.2">
                  𝑠
                 </ci>
                 <ci id="S2.E1.m1.16.16.4.4.2.3.2.3a.cmml" xref="S2.E1.m1.16.16.4.4.2.3.2.3">
                  <mtext id="S2.E1.m1.16.16.4.4.2.3.2.3.cmml" mathsize="70%" xref="S2.E1.m1.16.16.4.4.2.3.2.3">
                   res
                  </mtext>
                 </ci>
                </apply>
                <ci id="S2.E1.m1.14.14.2.2.1.1.cmml" xref="S2.E1.m1.14.14.2.2.1.1">
                 𝑇
                </ci>
               </apply>
              </apply>
             </list>
            </apply>
            <ci id="S2.E1.m1.17.17.1.1.6.2a.cmml" xref="S2.E1.m1.17.17.1.1.6.2">
             <mtext id="S2.E1.m1.17.17.1.1.6.2.cmml" mathsize="70%" xref="S2.E1.m1.17.17.1.1.6.2">
              response
             </mtext>
            </ci>
           </apply>
          </apply>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="S2.E1.m1.17c">
          \displaystyle\underbrace{\text{{You are...}}}_{\text{system message}}~{}\underbrace{s_{\text{2D}}^{(1)},...,s_{\text{2D}}^{(M)}}_{\begin{subarray}{c}\text{2D image tokens}\\
\text{(optional)}\end{subarray}}\underbrace{s_{\text{3D}}^{(1)},...,s_{\text{3D}}^{(N)}}_{\begin{subarray}{c}\text{object-centric}\\
\text{3D tokens}\end{subarray}}~{}\underbrace{\text{{USER:... ASSISTANT:}}}_{\text{instruction}}~{}\underbrace{s_{\text{res}}^{(1)},...s_{\text{res}}^{(T)}}_{\text{response}}.
         </annotation>
        </semantics>
       </math>
      </td>
      <td class="ltx_eqn_cell ltx_eqn_center_padright">
      </td>
      <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1">
       <span class="ltx_tag ltx_tag_equation ltx_align_right">
        (1)
       </span>
      </td>
     </tr>
    </tbody>
   </table>
   <p class="ltx_p" id="S2.p1.2">
    With this representation, we formulate the learning of
    <span class="ltx_text ltx_font_smallcaps" id="S2.p1.2.1">
     LEO
    </span>
    as GPT-style autoregressive language modeling
    <cite class="ltx_cite ltx_citemacro_citep">
     (Brown et al.,
     <a class="ltx_ref" href="#bib.bib10" title="">
      2020
     </a>
     )
    </cite>
    given the
    <span class="ltx_text ltx_font_italic" id="S2.p1.2.2">
     prefix
    </span>
    (from
    <span class="ltx_text ltx_font_italic" id="S2.p1.2.3">
     system message
    </span>
    to
    <span class="ltx_text ltx_font_italic" id="S2.p1.2.4">
     instruction
    </span>
    ),
    <em class="ltx_emph ltx_font_italic" id="S2.p1.2.5">
     i.e
    </em>
    .
    <span class="ltx_text" id="S2.p1.2.6">
    </span>
    prefix language modeling
    <cite class="ltx_cite ltx_citemacro_citep">
     (Raffel et al.,
     <a class="ltx_ref" href="#bib.bib62" title="">
      2020
     </a>
     )
    </cite>
    . Therefore, a pretrained LLM can be used to process such sequences. In the following, we will detail the tokenization of multi-modal data, model architecture, training loss, and inference settings. An overview of our model can be found in
    <a class="ltx_ref" href="#S1.F1" title="In 1 Introduction ‣ An Embodied Generalist Agent in 3D World">
     <span class="ltx_text ltx_ref_tag">
      Fig.
     </span>
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    .
   </p>
  </div>
  <section class="ltx_subsection" id="S2.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.1
    </span>
    Tokenization
   </h3>
   <div class="ltx_para ltx_noindent" id="S2.SS1.p1">
    <p class="ltx_p" id="S2.SS1.p1.1">
     We follow prior practices in 2D VLM
     <cite class="ltx_cite ltx_citemacro_citep">
      (Liu et al.,
      <a class="ltx_ref" href="#bib.bib47" title="">
       2023b
      </a>
      ; Alayrac et al.,
      <a class="ltx_ref" href="#bib.bib3" title="">
       2022
      </a>
      )
     </cite>
     and 3D VLM
     <cite class="ltx_cite ltx_citemacro_citep">
      (Zhu et al.,
      <a class="ltx_ref" href="#bib.bib94" title="">
       2023c
      </a>
      )
     </cite>
     to tokenize the multi-modal data in
     <span class="ltx_text ltx_font_smallcaps" id="S2.SS1.p1.1.1">
      LEO
     </span>
     .
We use SentencePiece tokenizer
     <cite class="ltx_cite ltx_citemacro_citep">
      (Kudo &amp; Richardson,
      <a class="ltx_ref" href="#bib.bib38" title="">
       2018
      </a>
      )
     </cite>
     to encode text with 32k subwords; 2D image tokens for egocentric 2D images; and object-centric 3D tokens extracted over Mask3D-based
     <cite class="ltx_cite ltx_citemacro_citep">
      (Schult et al.,
      <a class="ltx_ref" href="#bib.bib71" title="">
       2022
      </a>
      )
     </cite>
     object proposals for 3D point cloud inputs.
For embodied action commands, continuous actions (
     <em class="ltx_emph ltx_font_italic" id="S2.SS1.p1.1.2">
      e.g
     </em>
     .
     <span class="ltx_text" id="S2.SS1.p1.1.3">
     </span>
     in manipulation) are discretized (details in
     <a class="ltx_ref" href="#A2" title="Appendix B Action Tokenization ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Appendix
      </span>
      <span class="ltx_text ltx_ref_tag">
       B
      </span>
     </a>
     ) to join the discrete actions (
     <em class="ltx_emph ltx_font_italic" id="S2.SS1.p1.1.4">
      e.g
     </em>
     .
     <span class="ltx_text" id="S2.SS1.p1.1.5">
     </span>
     navigation) and form a unified discrete action space. We follow
     <cite class="ltx_cite ltx_citemacro_cite">
      Brohan et al. (
      <a class="ltx_ref" href="#bib.bib9" title="">
       2023
      </a>
      )
     </cite>
     to map these discrete actions to the least used tokens in SentencePiece.
After tokenization, all tokens are ordered into the format in (
     <a class="ltx_ref" href="#S2.E1" title="Equation 1 ‣ 2 Model ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     ).
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="S2.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.2
    </span>
    Token embedding &amp; LLM
   </h3>
   <div class="ltx_para ltx_noindent" id="S2.SS2.p1">
    <p class="ltx_p" id="S2.SS2.p1.1">
     We apply several token embedding functions to process the tokens in the sequence before sending them to the LLM. The LLM will then align these tokens of different modalities, and produce the response. Most of the responses are text and can be decoded directly. For responses that include embodied actions, we will map the reserved SentencePiece text tokens back to action commands.
    </p>
   </div>
   <section class="ltx_paragraph" id="S2.SS2.SSS0.Px1">
    <h5 class="ltx_title ltx_title_paragraph">
     Text &amp; 2D token embedding.
    </h5>
    <div class="ltx_para ltx_noindent" id="S2.SS2.SSS0.Px1.p1">
     <p class="ltx_p" id="S2.SS2.SSS0.Px1.p1.1">
      For text tokens (including embodied actions that have been mapped to the reserved text tokens), an embedding look-up table is used to map them into vectors. While the egocentric 2D image is encoded by a pretrained OpenCLIP ConvNext
      <cite class="ltx_cite ltx_citemacro_citep">
       (Liu et al.,
       <a class="ltx_ref" href="#bib.bib48" title="">
        2022
       </a>
       )
      </cite>
      for obtaining image token embeddings.
We apply MLP adapters to match the dimensions of all token embeddings.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S2.SS2.SSS0.Px2">
    <h5 class="ltx_title ltx_title_paragraph">
     Object-centric 3D token embedding.
    </h5>
    <div class="ltx_para ltx_noindent" id="S2.SS2.SSS0.Px2.p1">
     <p class="ltx_p" id="S2.SS2.SSS0.Px2.p1.1">
      Each 3D object token (
      <em class="ltx_emph ltx_font_italic" id="S2.SS2.SSS0.Px2.p1.1.1">
       i.e
      </em>
      .
      <span class="ltx_text" id="S2.SS2.SSS0.Px2.p1.1.2">
      </span>
      , the point cloud of a 3D object) is first encoded by a pretrained point cloud encoder (
      <em class="ltx_emph ltx_font_italic" id="S2.SS2.SSS0.Px2.p1.1.3">
       e.g
      </em>
      .
      <span class="ltx_text" id="S2.SS2.SSS0.Px2.p1.1.4">
      </span>
      , PointNet++
      <cite class="ltx_cite ltx_citemacro_citep">
       (Qi et al.,
       <a class="ltx_ref" href="#bib.bib60" title="">
        2017
       </a>
       )
      </cite>
      ). We then adopt the Spatial Transformer introduced in
      <cite class="ltx_cite ltx_citemacro_cite">
       Chen et al. (
       <a class="ltx_ref" href="#bib.bib15" title="">
        2022
       </a>
       )
      </cite>
      to further process the point cloud embedding of all objects into object-centric 3D token embeddings.
In a nutshell, Spatial Transformer biases the standard attention score with relative position and size for capturing 3D relations between objects.
Due to space limit, the readers are referred to
      <cite class="ltx_cite ltx_citemacro_cite">
       Chen et al. (
       <a class="ltx_ref" href="#bib.bib15" title="">
        2022
       </a>
       )
      </cite>
      and
      <a class="ltx_ref" href="#A4.SS2" title="D.2 Feature Encoding ‣ Appendix D Model Details ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Sec.
       </span>
       <span class="ltx_text ltx_ref_tag">
        D.2
       </span>
      </a>
      for more details.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S2.SS2.SSS0.Px3">
    <h5 class="ltx_title ltx_title_paragraph">
     Pretrained LLM.
    </h5>
    <div class="ltx_para ltx_noindent" id="S2.SS2.SSS0.Px3.p1">
     <p class="ltx_p" id="S2.SS2.SSS0.Px3.p1.1">
      We choose Vicuna-7B
      <cite class="ltx_cite ltx_citemacro_citep">
       (Chiang et al.,
       <a class="ltx_ref" href="#bib.bib18" title="">
        2023
       </a>
       )
      </cite>
      to process the token sequence. In order to tackle the challenging alignment and grounding problem of multi-modal tokens (2D, 3D, text, embodied action) while preserving the LLM pretrained knowledge, we employ LoRA
      <cite class="ltx_cite ltx_citemacro_citep">
       (Hu et al.,
       <a class="ltx_ref" href="#bib.bib31" title="">
        2022
       </a>
       )
      </cite>
      to introduce additional tunable parameters to the frozen pretrained LLM.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S2.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     2.3
    </span>
    Training &amp; Inference
   </h3>
   <div class="ltx_para ltx_noindent" id="S2.SS3.p1">
    <p class="ltx_p" id="S2.SS3.p1.2">
     We formulate the learning objective of
     <span class="ltx_text ltx_font_smallcaps" id="S2.SS3.p1.2.1">
      LEO
     </span>
     following
     <cite class="ltx_cite ltx_citemacro_citep">
      (Brown et al.,
      <a class="ltx_ref" href="#bib.bib10" title="">
       2020
      </a>
      ; Raffel et al.,
      <a class="ltx_ref" href="#bib.bib62" title="">
       2020
      </a>
      )
     </cite>
     in a prefix language modeling fashion. For a batch
     <math alttext="\mathcal{B}" class="ltx_Math" display="inline" id="S2.SS3.p1.1.m1.1">
      <semantics id="S2.SS3.p1.1.m1.1a">
       <mi class="ltx_font_mathcaligraphic" id="S2.SS3.p1.1.m1.1.1" xref="S2.SS3.p1.1.m1.1.1.cmml">
        ℬ
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.1b">
        <ci id="S2.SS3.p1.1.m1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1">
         ℬ
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.1c">
        \mathcal{B}
       </annotation>
      </semantics>
     </math>
     of token sequence
     <math alttext="s" class="ltx_Math" display="inline" id="S2.SS3.p1.2.m2.1">
      <semantics id="S2.SS3.p1.2.m2.1a">
       <mi id="S2.SS3.p1.2.m2.1.1" xref="S2.SS3.p1.2.m2.1.1.cmml">
        s
       </mi>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p1.2.m2.1b">
        <ci id="S2.SS3.p1.2.m2.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1">
         𝑠
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p1.2.m2.1c">
        s
       </annotation>
      </semantics>
     </math>
     , we optimize
     <span class="ltx_text ltx_font_smallcaps" id="S2.SS3.p1.2.2">
      LEO
     </span>
     via:
    </p>
    <table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="A9.EGx2">
     <tbody id="S2.E2">
      <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
       <td class="ltx_eqn_cell ltx_eqn_center_padleft">
       </td>
       <td class="ltx_td ltx_align_right ltx_eqn_cell">
        <math alttext="\displaystyle\mathcal{L}(\theta,\mathcal{B})=-\sum^{|\mathcal{B}|}_{b=1}\sum^{T}_{t=1}\log p_{\theta}(s_{\text{res}}^{(b,t)}|s_{\text{res}}^{(b,&lt;t)},s_{\text{prefix}}^{(b,1)},...,s_{\text{prefix}}^{(b,L)})," class="ltx_math_unparsed" display="inline" id="S2.E2.m1.11">
         <semantics id="S2.E2.m1.11a">
          <mrow id="S2.E2.m1.11.11.1">
           <mrow id="S2.E2.m1.11.11.1.1">
            <mrow id="S2.E2.m1.11.11.1.1.3">
             <mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.11.11.1.1.3.2">
              ℒ
             </mi>
             <mo id="S2.E2.m1.11.11.1.1.3.1" lspace="0em" rspace="0em">
              ​
             </mo>
             <mrow id="S2.E2.m1.11.11.1.1.3.3.2">
              <mo id="S2.E2.m1.11.11.1.1.3.3.2.1" stretchy="false">
               (
              </mo>
              <mi id="S2.E2.m1.8.8">
               θ
              </mi>
              <mo id="S2.E2.m1.11.11.1.1.3.3.2.2">
               ,
              </mo>
              <mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.9.9">
               ℬ
              </mi>
              <mo id="S2.E2.m1.11.11.1.1.3.3.2.3" stretchy="false">
               )
              </mo>
             </mrow>
            </mrow>
            <mo id="S2.E2.m1.11.11.1.1.2">
             =
            </mo>
            <mrow id="S2.E2.m1.11.11.1.1.1">
             <mo id="S2.E2.m1.11.11.1.1.1a">
              −
             </mo>
             <mrow id="S2.E2.m1.11.11.1.1.1.1">
              <mstyle displaystyle="true" id="S2.E2.m1.11.11.1.1.1.1.2">
               <munderover id="S2.E2.m1.11.11.1.1.1.1.2a">
                <mo id="S2.E2.m1.11.11.1.1.1.1.2.2.2" movablelimits="false">
                 ∑
                </mo>
                <mrow id="S2.E2.m1.11.11.1.1.1.1.2.3">
                 <mi id="S2.E2.m1.11.11.1.1.1.1.2.3.2">
                  b
                 </mi>
                 <mo id="S2.E2.m1.11.11.1.1.1.1.2.3.1">
                  =
                 </mo>
                 <mn id="S2.E2.m1.11.11.1.1.1.1.2.3.3">
                  1
                 </mn>
                </mrow>
                <mrow id="S2.E2.m1.1.1.1.3">
                 <mo id="S2.E2.m1.1.1.1.3.1" stretchy="false">
                  |
                 </mo>
                 <mi class="ltx_font_mathcaligraphic" id="S2.E2.m1.1.1.1.1">
                  ℬ
                 </mi>
                 <mo id="S2.E2.m1.1.1.1.3.2" stretchy="false">
                  |
                 </mo>
                </mrow>
               </munderover>
              </mstyle>
              <mrow id="S2.E2.m1.11.11.1.1.1.1.1">
               <mstyle displaystyle="true" id="S2.E2.m1.11.11.1.1.1.1.1.2">
                <munderover id="S2.E2.m1.11.11.1.1.1.1.1.2a">
                 <mo id="S2.E2.m1.11.11.1.1.1.1.1.2.2.2" movablelimits="false">
                  ∑
                 </mo>
                 <mrow id="S2.E2.m1.11.11.1.1.1.1.1.2.3">
                  <mi id="S2.E2.m1.11.11.1.1.1.1.1.2.3.2">
                   t
                  </mi>
                  <mo id="S2.E2.m1.11.11.1.1.1.1.1.2.3.1">
                   =
                  </mo>
                  <mn id="S2.E2.m1.11.11.1.1.1.1.1.2.3.3">
                   1
                  </mn>
                 </mrow>
                 <mi id="S2.E2.m1.11.11.1.1.1.1.1.2.2.3">
                  T
                 </mi>
                </munderover>
               </mstyle>
               <mrow id="S2.E2.m1.11.11.1.1.1.1.1.1">
                <mrow id="S2.E2.m1.11.11.1.1.1.1.1.1.3">
                 <mi id="S2.E2.m1.11.11.1.1.1.1.1.1.3.1">
                  log
                 </mi>
                 <mo id="S2.E2.m1.11.11.1.1.1.1.1.1.3a" lspace="0.167em">
                  ⁡
                 </mo>
                 <msub id="S2.E2.m1.11.11.1.1.1.1.1.1.3.2">
                  <mi id="S2.E2.m1.11.11.1.1.1.1.1.1.3.2.2">
                   p
                  </mi>
                  <mi id="S2.E2.m1.11.11.1.1.1.1.1.1.3.2.3">
                   θ
                  </mi>
                 </msub>
                </mrow>
                <mo id="S2.E2.m1.11.11.1.1.1.1.1.1.2" lspace="0em" rspace="0em">
                 ​
                </mo>
                <mrow id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1">
                 <mo id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.2" stretchy="false">
                  (
                 </mo>
                 <mrow id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1">
                  <msubsup id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.5">
                   <mi id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.5.2.2">
                    s
                   </mi>
                   <mtext id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.5.2.3">
                    res
                   </mtext>
                   <mrow id="S2.E2.m1.3.3.2.4">
                    <mo id="S2.E2.m1.3.3.2.4.1" stretchy="false">
                     (
                    </mo>
                    <mi id="S2.E2.m1.2.2.1.1">
                     b
                    </mi>
                    <mo id="S2.E2.m1.3.3.2.4.2">
                     ,
                    </mo>
                    <mi id="S2.E2.m1.3.3.2.2">
                     t
                    </mi>
                    <mo id="S2.E2.m1.3.3.2.4.3" stretchy="false">
                     )
                    </mo>
                   </mrow>
                  </msubsup>
                  <mo fence="false" id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.4">
                   |
                  </mo>
                  <mrow id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.3.3">
                   <msubsup id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1">
                    <mi id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.2.2">
                     s
                    </mi>
                    <mtext id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.2.3">
                     res
                    </mtext>
                    <mrow id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.3">
                     <mo id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.3.1" stretchy="false">
                      (
                     </mo>
                     <mi id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.3.2">
                      b
                     </mi>
                     <mo id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.3.3">
                      ,
                     </mo>
                     <mo id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.3.4" lspace="0em">
                      &lt;
                     </mo>
                     <mi id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.3.5">
                      t
                     </mi>
                     <mo id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.1.1.1.3.6" stretchy="false">
                      )
                     </mo>
                    </mrow>
                   </msubsup>
                   <mo id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.3.3.4">
                    ,
                   </mo>
                   <msubsup id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.2.2.2">
                    <mi id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.2.2.2.2.2">
                     s
                    </mi>
                    <mtext id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.2.2.2.2.3">
                     prefix
                    </mtext>
                    <mrow id="S2.E2.m1.5.5.2.4">
                     <mo id="S2.E2.m1.5.5.2.4.1" stretchy="false">
                      (
                     </mo>
                     <mi id="S2.E2.m1.4.4.1.1">
                      b
                     </mi>
                     <mo id="S2.E2.m1.5.5.2.4.2">
                      ,
                     </mo>
                     <mn id="S2.E2.m1.5.5.2.2">
                      1
                     </mn>
                     <mo id="S2.E2.m1.5.5.2.4.3" stretchy="false">
                      )
                     </mo>
                    </mrow>
                   </msubsup>
                   <mo id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.3.3.5">
                    ,
                   </mo>
                   <mi id="S2.E2.m1.10.10" mathvariant="normal">
                    …
                   </mi>
                   <mo id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.3.3.6">
                    ,
                   </mo>
                   <msubsup id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.3.3.3">
                    <mi id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.3.3.3.2.2">
                     s
                    </mi>
                    <mtext id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.1.3.3.3.2.3">
                     prefix
                    </mtext>
                    <mrow id="S2.E2.m1.7.7.2.4">
                     <mo id="S2.E2.m1.7.7.2.4.1" stretchy="false">
                      (
                     </mo>
                     <mi id="S2.E2.m1.6.6.1.1">
                      b
                     </mi>
                     <mo id="S2.E2.m1.7.7.2.4.2">
                      ,
                     </mo>
                     <mi id="S2.E2.m1.7.7.2.2">
                      L
                     </mi>
                     <mo id="S2.E2.m1.7.7.2.4.3" stretchy="false">
                      )
                     </mo>
                    </mrow>
                   </msubsup>
                  </mrow>
                 </mrow>
                 <mo id="S2.E2.m1.11.11.1.1.1.1.1.1.1.1.3" stretchy="false">
                  )
                 </mo>
                </mrow>
               </mrow>
              </mrow>
             </mrow>
            </mrow>
           </mrow>
           <mo id="S2.E2.m1.11.11.1.2">
            ,
           </mo>
          </mrow>
          <annotation encoding="application/x-tex" id="S2.E2.m1.11b">
           \displaystyle\mathcal{L}(\theta,\mathcal{B})=-\sum^{|\mathcal{B}|}_{b=1}\sum^{T}_{t=1}\log p_{\theta}(s_{\text{res}}^{(b,t)}|s_{\text{res}}^{(b,&lt;t)},s_{\text{prefix}}^{(b,1)},...,s_{\text{prefix}}^{(b,L)}),
          </annotation>
         </semantics>
        </math>
       </td>
       <td class="ltx_eqn_cell ltx_eqn_center_padright">
       </td>
       <td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1">
        <span class="ltx_tag ltx_tag_equation ltx_align_right">
         (2)
        </span>
       </td>
      </tr>
     </tbody>
    </table>
    <p class="ltx_p" id="S2.SS3.p1.3">
     where
     <math alttext="s_{\text{prefix}}" class="ltx_Math" display="inline" id="S2.SS3.p1.3.m1.1">
      <semantics id="S2.SS3.p1.3.m1.1a">
       <msub id="S2.SS3.p1.3.m1.1.1" xref="S2.SS3.p1.3.m1.1.1.cmml">
        <mi id="S2.SS3.p1.3.m1.1.1.2" xref="S2.SS3.p1.3.m1.1.1.2.cmml">
         s
        </mi>
        <mtext id="S2.SS3.p1.3.m1.1.1.3" xref="S2.SS3.p1.3.m1.1.1.3a.cmml">
         prefix
        </mtext>
       </msub>
       <annotation-xml encoding="MathML-Content" id="S2.SS3.p1.3.m1.1b">
        <apply id="S2.SS3.p1.3.m1.1.1.cmml" xref="S2.SS3.p1.3.m1.1.1">
         <csymbol cd="ambiguous" id="S2.SS3.p1.3.m1.1.1.1.cmml" xref="S2.SS3.p1.3.m1.1.1">
          subscript
         </csymbol>
         <ci id="S2.SS3.p1.3.m1.1.1.2.cmml" xref="S2.SS3.p1.3.m1.1.1.2">
          𝑠
         </ci>
         <ci id="S2.SS3.p1.3.m1.1.1.3a.cmml" xref="S2.SS3.p1.3.m1.1.1.3">
          <mtext id="S2.SS3.p1.3.m1.1.1.3.cmml" mathsize="70%" xref="S2.SS3.p1.3.m1.1.1.3">
           prefix
          </mtext>
         </ci>
        </apply>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="S2.SS3.p1.3.m1.1c">
        s_{\text{prefix}}
       </annotation>
      </semantics>
     </math>
     denotes the prefix token (from
     <span class="ltx_text ltx_font_italic" id="S2.SS3.p1.3.1">
      system message
     </span>
     to
     <span class="ltx_text ltx_font_italic" id="S2.SS3.p1.3.2">
      instruction
     </span>
     ) in (
     <a class="ltx_ref" href="#S2.E1" title="Equation 1 ‣ 2 Model ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       1
      </span>
     </a>
     ).
During training, we freeze the pretrained 3D point cloud encoder and the LLM and finetune the 2D image encoder, the Spatial Transformer and the LoRA parameters.
In total,
     <span class="ltx_text ltx_font_smallcaps" id="S2.SS3.p1.3.3">
      LEO
     </span>
     has ~7B parameters and ~142M of them will be tuned.
During inference, we use beam search to generate textual responses. For tasks that require action commands, we map the textual outputs to action commands as discussed in
     <a class="ltx_ref" href="#S2.SS1" title="2.1 Tokenization ‣ 2 Model ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Sec.
      </span>
      <span class="ltx_text ltx_ref_tag">
       2.1
      </span>
     </a>
     . More details on the model and training can be found in
     <a class="ltx_ref" href="#A4" title="Appendix D Model Details ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Appendix
      </span>
      <span class="ltx_text ltx_ref_tag">
       D
      </span>
     </a>
     .
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S3">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    3
   </span>
   Datasets
  </h2>
  <div class="ltx_para ltx_noindent" id="S3.p1">
   <p class="ltx_p" id="S3.p1.1">
    Since
    <span class="ltx_text ltx_font_smallcaps" id="S3.p1.1.1">
     LEO
    </span>
    is a generalist agent that receives multi-modal inputs and follows instructions, we adopt the two-stage training proposed in
    <cite class="ltx_cite ltx_citemacro_cite">
     Liu et al. (
     <a class="ltx_ref" href="#bib.bib47" title="">
      2023b
     </a>
     )
    </cite>
    and categorize the data into two sets: (i)
    <span class="ltx_text ltx_font_smallcaps" id="S3.p1.1.2">
     LEO
    </span>
    -align that focuses on
    <span class="ltx_text ltx_font_bold" id="S3.p1.1.3">
     3D vision-language alignment
    </span>
    at object-level and scene-level, to bridge the gap between 3D scene representations and natural language; and (ii)
    <span class="ltx_text ltx_font_smallcaps" id="S3.p1.1.4">
     LEO
    </span>
    -instruct that targets at
    <span class="ltx_text ltx_font_bold" id="S3.p1.1.5">
     3D VLA instruction tuning
    </span>
    for endowing
    <span class="ltx_text ltx_font_smallcaps" id="S3.p1.1.6">
     LEO
    </span>
    with the generalist capability of accomplishing myriad tasks in the 3D world including perceiving, reasoning, and acting. We provide the statistics of the two separate splits of data in
    <a class="ltx_ref" href="#S3.T1" title="In 3 Datasets ‣ An Embodied Generalist Agent in 3D World">
     <span class="ltx_text ltx_ref_tag">
      Tab.
     </span>
     <span class="ltx_text ltx_ref_tag">
      1
     </span>
    </a>
    . Examples of both datasets can be found in
    <a class="ltx_ref" href="#A3" title="Appendix C Data Examples ‣ An Embodied Generalist Agent in 3D World">
     <span class="ltx_text ltx_ref_tag">
      Appendix
     </span>
     <span class="ltx_text ltx_ref_tag">
      C
     </span>
    </a>
    .
   </p>
  </div>
  <figure class="ltx_table" id="S3.T1">
   <figcaption class="ltx_caption">
    <span class="ltx_tag ltx_tag_table">
     Table 1:
    </span>
    <span class="ltx_text ltx_font_bold" id="S3.T1.9.1">
     Datasets statistics
    </span>
    . Top: Datasets for 3D-language alignment; Bottom: Datasets for 3D VLA instruction tuning.
    <span class="ltx_text ltx_font_italic" id="S3.T1.10.2">
     res.
    </span>
    denotes tokens to be predicted in training (response), while
    <span class="ltx_text ltx_font_italic" id="S3.T1.11.3">
     prefix
    </span>
    denotes those in the context.
* stands for the tabletop scene setting in CLIPort
    <cite class="ltx_cite ltx_citemacro_citep">
     (Shridhar et al.,
     <a class="ltx_ref" href="#bib.bib72" title="">
      2021
     </a>
     )
    </cite>
    .
    <sup class="ltx_sup" id="S3.T1.12.4">
     †
    </sup>
    stands for approximate count.
   </figcaption>
   <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S3.T1.4" style="width:377.2pt;height:162.9pt;vertical-align:-0.8pt;">
    <span class="ltx_transformed_inner" style="transform:translate(-48.0pt,20.6pt) scale(0.797065389192646,0.797065389192646) ;">
     <table class="ltx_tabular ltx_align_middle" id="S3.T1.4.2">
      <tr class="ltx_tr" id="S3.T1.4.2.2">
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.4.2.2.3" style="padding-left:3.0pt;padding-right:3.0pt;">
        Dataset
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.4.2.2.4" style="padding-left:3.0pt;padding-right:3.0pt;">
        Task
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.4.2.2.5" style="padding-left:3.0pt;padding-right:3.0pt;">
        2D requried?
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.4.2.2.6" style="padding-left:3.0pt;padding-right:3.0pt;">
        3D dataset
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.4.2.2.7" style="padding-left:3.0pt;padding-right:3.0pt;">
        #instance
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.3.1.1.1" style="padding-left:3.0pt;padding-right:3.0pt;">
        <span class="ltx_text" id="S3.T1.3.1.1.1.2">
        </span>
        <span class="ltx_text" id="S3.T1.3.1.1.1.1">
         <span class="ltx_tabular ltx_align_middle" id="S3.T1.3.1.1.1.1.1">
          <span class="ltx_tr" id="S3.T1.3.1.1.1.1.1.1">
           <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.3.1.1.1.1.1.1.1" style="padding-left:3.0pt;padding-right:3.0pt;">
            <sup class="ltx_sup" id="S3.T1.3.1.1.1.1.1.1.1.1">
             †
            </sup>
            #token
           </span>
          </span>
          <span class="ltx_tr" id="S3.T1.3.1.1.1.1.1.2">
           <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.3.1.1.1.1.1.2.1" style="padding-left:3.0pt;padding-right:3.0pt;">
            (
            <span class="ltx_text ltx_font_italic" id="S3.T1.3.1.1.1.1.1.2.1.1">
             res.
            </span>
            )
           </span>
          </span>
         </span>
        </span>
        <span class="ltx_text" id="S3.T1.3.1.1.1.3">
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_tt" id="S3.T1.4.2.2.2" style="padding-left:3.0pt;padding-right:3.0pt;">
        <span class="ltx_text" id="S3.T1.4.2.2.2.2">
        </span>
        <span class="ltx_text" id="S3.T1.4.2.2.2.1">
         <span class="ltx_tabular ltx_align_middle" id="S3.T1.4.2.2.2.1.1">
          <span class="ltx_tr" id="S3.T1.4.2.2.2.1.1.1">
           <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.4.2.2.2.1.1.1.1" style="padding-left:3.0pt;padding-right:3.0pt;">
            <sup class="ltx_sup" id="S3.T1.4.2.2.2.1.1.1.1.1">
             †
            </sup>
            #token
           </span>
          </span>
          <span class="ltx_tr" id="S3.T1.4.2.2.2.1.1.2">
           <span class="ltx_td ltx_nopad_r ltx_align_center" id="S3.T1.4.2.2.2.1.1.2.1" style="padding-left:3.0pt;padding-right:3.0pt;">
            (
            <span class="ltx_text ltx_font_italic" id="S3.T1.4.2.2.2.1.1.2.1.1">
             prefix
            </span>
            +
            <span class="ltx_text ltx_font_italic" id="S3.T1.4.2.2.2.1.1.2.1.2">
             res.
            </span>
            )
           </span>
          </span>
         </span>
        </span>
        <span class="ltx_text" id="S3.T1.4.2.2.2.3">
        </span>
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.4.2.3">
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.2.3.1" rowspan="3" style="padding-left:3.0pt;padding-right:3.0pt;">
        <span class="ltx_text" id="S3.T1.4.2.3.1.1">
         <span class="ltx_text ltx_font_smallcaps" id="S3.T1.4.2.3.1.1.1">
          LEO
         </span>
         -align
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.2.3.2" style="padding-left:3.0pt;padding-right:3.0pt;">
        object captioning
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.2.3.3" style="padding-left:3.0pt;padding-right:3.0pt;">
        ✗
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.2.3.4" style="padding-left:3.0pt;padding-right:3.0pt;">
        Objaverse
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.2.3.5" style="padding-left:3.0pt;padding-right:3.0pt;">
        660K
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.2.3.6" style="padding-left:3.0pt;padding-right:3.0pt;">
        10M
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.2.3.7" style="padding-left:3.0pt;padding-right:3.0pt;">
        27M
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.4.2.4">
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.4.1" style="padding-left:3.0pt;padding-right:3.0pt;">
        object referring
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.4.2" style="padding-left:3.0pt;padding-right:3.0pt;">
        ✗
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.4.3" style="padding-left:3.0pt;padding-right:3.0pt;">
        ScanNet + 3RScan
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.4.4" style="padding-left:3.0pt;padding-right:3.0pt;">
        354K
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.4.5" style="padding-left:3.0pt;padding-right:3.0pt;">
        15M
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.4.6" style="padding-left:3.0pt;padding-right:3.0pt;">
        39M
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.4.2.5">
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.5.1" style="padding-left:3.0pt;padding-right:3.0pt;">
        scene captioning
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.5.2" style="padding-left:3.0pt;padding-right:3.0pt;">
        ✗
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.5.3" style="padding-left:3.0pt;padding-right:3.0pt;">
        3RScan
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.5.4" style="padding-left:3.0pt;padding-right:3.0pt;">
        20K
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.5.5" style="padding-left:3.0pt;padding-right:3.0pt;">
        3.3M
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.5.6" style="padding-left:3.0pt;padding-right:3.0pt;">
        4.4M
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.4.2.6">
       <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S3.T1.4.2.6.1" rowspan="6" style="padding-left:3.0pt;padding-right:3.0pt;">
        <span class="ltx_text" id="S3.T1.4.2.6.1.1">
         <span class="ltx_text ltx_font_smallcaps" id="S3.T1.4.2.6.1.1.1">
          LEO
         </span>
         -instruct
        </span>
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.2.6.2" style="padding-left:3.0pt;padding-right:3.0pt;">
        3D captioning
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.2.6.3" style="padding-left:3.0pt;padding-right:3.0pt;">
        ✗
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.2.6.4" style="padding-left:3.0pt;padding-right:3.0pt;">
        ScanNet
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.2.6.5" style="padding-left:3.0pt;padding-right:3.0pt;">
        37K
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.2.6.6" style="padding-left:3.0pt;padding-right:3.0pt;">
        821K
       </td>
       <td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.2.6.7" style="padding-left:3.0pt;padding-right:3.0pt;">
        3M
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.4.2.7">
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.7.1" style="padding-left:3.0pt;padding-right:3.0pt;">
        3D QA
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.7.2" style="padding-left:3.0pt;padding-right:3.0pt;">
        ✗
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.7.3" style="padding-left:3.0pt;padding-right:3.0pt;">
        ScanNet + 3RScan
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.7.4" style="padding-left:3.0pt;padding-right:3.0pt;">
        83K
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.7.5" style="padding-left:3.0pt;padding-right:3.0pt;">
        177K
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.7.6" style="padding-left:3.0pt;padding-right:3.0pt;">
        4M
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.4.2.8">
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.8.1" style="padding-left:3.0pt;padding-right:3.0pt;">
        3D dialogue
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.8.2" style="padding-left:3.0pt;padding-right:3.0pt;">
        ✗
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.8.3" style="padding-left:3.0pt;padding-right:3.0pt;">
        3RScan
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.8.4" style="padding-left:3.0pt;padding-right:3.0pt;">
        11K
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.8.5" style="padding-left:3.0pt;padding-right:3.0pt;">
        1.1M
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.8.6" style="padding-left:3.0pt;padding-right:3.0pt;">
        8.3M
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.4.2.9">
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.9.1" style="padding-left:3.0pt;padding-right:3.0pt;">
        task planning
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.9.2" style="padding-left:3.0pt;padding-right:3.0pt;">
        ✗
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.9.3" style="padding-left:3.0pt;padding-right:3.0pt;">
        3RScan
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.9.4" style="padding-left:3.0pt;padding-right:3.0pt;">
        14K
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.9.5" style="padding-left:3.0pt;padding-right:3.0pt;">
        1.9M
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.9.6" style="padding-left:3.0pt;padding-right:3.0pt;">
        2.7M
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.4.2.10">
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.10.1" style="padding-left:3.0pt;padding-right:3.0pt;">
        navigation
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.10.2" style="padding-left:3.0pt;padding-right:3.0pt;">
        ✓
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.10.3" style="padding-left:3.0pt;padding-right:3.0pt;">
        MP3D
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.10.4" style="padding-left:3.0pt;padding-right:3.0pt;">
        60K
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.10.5" style="padding-left:3.0pt;padding-right:3.0pt;">
        11.4M
       </td>
       <td class="ltx_td ltx_align_center" id="S3.T1.4.2.10.6" style="padding-left:3.0pt;padding-right:3.0pt;">
        272M
       </td>
      </tr>
      <tr class="ltx_tr" id="S3.T1.4.2.11">
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.2.11.1" style="padding-left:3.0pt;padding-right:3.0pt;">
        manipulation
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.2.11.2" style="padding-left:3.0pt;padding-right:3.0pt;">
        ✓
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.2.11.3" style="padding-left:3.0pt;padding-right:3.0pt;">
        *CLIPort
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.2.11.4" style="padding-left:3.0pt;padding-right:3.0pt;">
        300K
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.2.11.5" style="padding-left:3.0pt;padding-right:3.0pt;">
        7.2M
       </td>
       <td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.2.11.6" style="padding-left:3.0pt;padding-right:3.0pt;">
        734M
       </td>
      </tr>
     </table>
    </span>
   </div>
  </figure>
  <section class="ltx_subsection" id="S3.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.1
    </span>
    <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.1.1">
     LEO
    </span>
    -align: 3D Vision-Language Alignment
   </h3>
   <div class="ltx_para ltx_noindent" id="S3.SS1.p1">
    <p class="ltx_p" id="S3.SS1.p1.1">
     In
     <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.p1.1.1">
      LEO
     </span>
     -align, we focus on 3D vision-language alignment. We follow the alignment method proposed by BLIP-2
     <cite class="ltx_cite ltx_citemacro_citep">
      (Li et al.,
      <a class="ltx_ref" href="#bib.bib45" title="">
       2023d
      </a>
      )
     </cite>
     and train the model to follow the instructions for captioning given 3D input. As a result, we consider collecting the following types of 3D caption data:
    </p>
   </div>
   <section class="ltx_paragraph" id="S3.SS1.SSS0.Px1">
    <h5 class="ltx_title ltx_title_paragraph">
     Object-level caption.
    </h5>
    <div class="ltx_para ltx_noindent" id="S3.SS1.SSS0.Px1.p1">
     <p class="ltx_p" id="S3.SS1.SSS0.Px1.p1.1">
      To facilitate object-level grounding of detailed object attributes, we leverage Cap3D
      <cite class="ltx_cite ltx_citemacro_citep">
       (Luo et al.,
       <a class="ltx_ref" href="#bib.bib50" title="">
        2023
       </a>
       )
      </cite>
      , which contains language descriptions for objects in Objaverse
      <cite class="ltx_cite ltx_citemacro_citep">
       (Deitke et al.,
       <a class="ltx_ref" href="#bib.bib22" title="">
        2023
       </a>
       )
      </cite>
      . Given a single 3D object as input,
      <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.SSS0.Px1.p1.1.1">
       LEO
      </span>
      will be asked to predict its caption.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S3.SS1.SSS0.Px2">
    <h5 class="ltx_title ltx_title_paragraph">
     Object-in-the-scene caption.
    </h5>
    <div class="ltx_para ltx_noindent" id="S3.SS1.SSS0.Px2.p1">
     <p class="ltx_p" id="S3.SS1.SSS0.Px2.p1.1">
      For a better understanding of how an object can be related to others (spatial relations,
      <em class="ltx_emph ltx_font_italic" id="S3.SS1.SSS0.Px2.p1.1.1">
       etc
      </em>
      .
      <span class="ltx_text" id="S3.SS1.SSS0.Px2.p1.1.2">
      </span>
      ) when situated in a 3D scene, we collect referring expressions of objects in scenes from existing datasets, including ScanScribe
      <cite class="ltx_cite ltx_citemacro_citep">
       (Zhu et al.,
       <a class="ltx_ref" href="#bib.bib94" title="">
        2023c
       </a>
       )
      </cite>
      and ReferIt3D
      <cite class="ltx_cite ltx_citemacro_citep">
       (Achlioptas et al.,
       <a class="ltx_ref" href="#bib.bib1" title="">
        2020
       </a>
       )
      </cite>
      . Further, we generate additional object-referring expressions on 3RScan
      <cite class="ltx_cite ltx_citemacro_citep">
       (Wald et al.,
       <a class="ltx_ref" href="#bib.bib77" title="">
        2019
       </a>
       )
      </cite>
      scenes by prompting
      <abbr class="ltx_glossaryref" title="large language models">
       <span class="ltx_text ltx_glossary_short">
        LLMs
       </span>
      </abbr>
      (details in
      <a class="ltx_ref" href="#A1.SS1" title="A.1 Prompts for LLM-assisted 3D Data Generation ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Sec.
       </span>
       <span class="ltx_text ltx_ref_tag">
        A.1
       </span>
      </a>
      ).
During alignment,
      <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.SSS0.Px2.p1.1.3">
       LEO
      </span>
      needs to predict these referring expressions given the object-centric 3D input of the scene and the referred object.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S3.SS1.SSS0.Px3">
    <h5 class="ltx_title ltx_title_paragraph">
     Scene-level caption.
    </h5>
    <div class="ltx_para ltx_noindent" id="S3.SS1.SSS0.Px3.p1">
     <p class="ltx_p" id="S3.SS1.SSS0.Px3.p1.1">
      Finally, we encourage
      <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.SSS0.Px3.p1.1.1">
       LEO
      </span>
      to capture scene-level descriptions of a 3D scene. These scene-level captions focus on global information depicting key objects in the scene as well as their attributes and functionalities, relations among multiple objects, and room types and styles. We leverage scene graph annotations
      <cite class="ltx_cite ltx_citemacro_citep">
       (Wald et al.,
       <a class="ltx_ref" href="#bib.bib77" title="">
        2019
       </a>
       )
      </cite>
      and prompt
      <abbr class="ltx_glossaryref" title="large language models">
       <span class="ltx_text ltx_glossary_short">
        LLMs
       </span>
      </abbr>
      to produce a total of ~20K captions.
To further increase caption diversity, we propose a subgraph sampling strategy to prevent LLMs from always attending to certain notable facets of the scene (details in
      <a class="ltx_ref" href="#A1.SS5" title="A.5 Subgraph Sampling ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Sec.
       </span>
       <span class="ltx_text ltx_ref_tag">
        A.5
       </span>
      </a>
      ). Similar to previous settings,
      <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.SSS0.Px3.p1.1.2">
       LEO
      </span>
      needs to predict these captions given the corresponding 3D input.
     </p>
    </div>
    <figure class="ltx_figure" id="S3.F2">
     <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="253" id="S3.F2.g1" src="/html/2311.12871/assets/x2.png" width="422"/>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_figure">
       Figure 2:
      </span>
      <span class="ltx_text ltx_font_bold" id="S3.F2.5.1">
       An overview of our proposed LLM-assisted 3D-language data generation and examples of
       <span class="ltx_text ltx_font_smallcaps" id="S3.F2.5.1.1">
        LEO
       </span>
       datasets
      </span>
      . (Top-left) Messages with 3D scene graphs,
including object attributes and relations in a phrasal form,
used for providing scene context when prompting LLM.
(Top-right) The human-defined refinement procedures conducted over raw LLM responses to improve data quality.
(Bottom) Examples of LLM-assisted generation in
      <span class="ltx_text ltx_font_smallcaps" id="S3.F2.6.2">
       LEO
      </span>
      -align and
      <span class="ltx_text ltx_font_smallcaps" id="S3.F2.7.3">
       LEO
      </span>
      -instruct.
      <span class="ltx_text" id="S3.F2.8.4" style="color:#808080;">
       Thoughts, colored in gray, will be removed after refinements
      </span>
      .
     </figcaption>
    </figure>
   </section>
  </section>
  <section class="ltx_subsection" id="S3.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.2
    </span>
    <span class="ltx_text ltx_font_smallcaps" id="S3.SS2.1.1">
     LEO
    </span>
    -instruct: Instruction Tuning for Tasks in the 3D world
   </h3>
   <div class="ltx_para ltx_noindent" id="S3.SS2.p1">
    <p class="ltx_p" id="S3.SS2.p1.1">
     After alignment,
     <span class="ltx_text ltx_font_smallcaps" id="S3.SS2.p1.1.1">
      LEO
     </span>
     will be tuned to follow instructions and accomplish various 3D
     <abbr class="ltx_glossaryref" title="vision-language-action">
      <span class="ltx_text ltx_glossary_short">
       VLA
      </span>
     </abbr>
     tasks.
Below, we provide a comprehensive illustration of the data preparation process for these tasks and an overview of generated data in
     <a class="ltx_ref" href="#S3.F2" title="In Scene-level caption. ‣ 3.1 LEO-align: 3D Vision-Language Alignment ‣ 3 Datasets ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Fig.
      </span>
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     . We list the corresponding instructions in
     <a class="ltx_ref" href="#A3" title="Appendix C Data Examples ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Appendix
      </span>
      <span class="ltx_text ltx_ref_tag">
       C
      </span>
     </a>
     .
    </p>
   </div>
   <section class="ltx_paragraph" id="S3.SS2.SSS0.Px1">
    <h5 class="ltx_title ltx_title_paragraph">
     3D captioning.
    </h5>
    <div class="ltx_para ltx_noindent" id="S3.SS2.SSS0.Px1.p1">
     <p class="ltx_p" id="S3.SS2.SSS0.Px1.p1.1">
      The task is to produce a generic caption given 3D input. We adopt the Scan2Cap dataset
      <cite class="ltx_cite ltx_citemacro_citep">
       (Chen et al.,
       <a class="ltx_ref" href="#bib.bib17" title="">
        2021
       </a>
       )
      </cite>
      , which is based on the ScanNet
      <cite class="ltx_cite ltx_citemacro_citep">
       (Dai et al.,
       <a class="ltx_ref" href="#bib.bib20" title="">
        2017
       </a>
       )
      </cite>
      3D scenes and covers various levels (object-level and scene-level) and aspects (attributes, relations,
      <em class="ltx_emph ltx_font_italic" id="S3.SS2.SSS0.Px1.p1.1.1">
       etc
      </em>
      .
      <span class="ltx_text" id="S3.SS2.SSS0.Px1.p1.1.2">
      </span>
      ) of scene details.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S3.SS2.SSS0.Px2">
    <h5 class="ltx_title ltx_title_paragraph">
     3D question answering.
    </h5>
    <div class="ltx_para ltx_noindent" id="S3.SS2.SSS0.Px2.p1">
     <p class="ltx_p" id="S3.SS2.SSS0.Px2.p1.1">
      The 3D-QA task is an extension of VQA
      <cite class="ltx_cite ltx_citemacro_citep">
       (Antol et al.,
       <a class="ltx_ref" href="#bib.bib4" title="">
        2015
       </a>
       )
      </cite>
      to 3D scenes with a focus on 3D knowledge, ranging from spatial relations to functionalities of objects. For this task, we first aggregate two existing 3D-QA datasets: ScanQA
      <cite class="ltx_cite ltx_citemacro_citep">
       (Azuma et al.,
       <a class="ltx_ref" href="#bib.bib5" title="">
        2022
       </a>
       )
      </cite>
      and SQA3D
      <cite class="ltx_cite ltx_citemacro_citep">
       (Ma et al.,
       <a class="ltx_ref" href="#bib.bib51" title="">
        2023
       </a>
       )
      </cite>
      . To further generate questions concerning rich 3D knowledge, we prompt LLMs to generate ~35K QA pairs on 3RScanQA with our quality refinement techniques discussed in
      <a class="ltx_ref" href="#S3.SS3" title="3.3 LLM-assisted 3D-language Data Generation ‣ 3 Datasets ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Sec.
       </span>
       <span class="ltx_text ltx_ref_tag">
        3.3
       </span>
      </a>
      .
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S3.SS2.SSS0.Px3">
    <h5 class="ltx_title ltx_title_paragraph">
     3D dialogue.
    </h5>
    <div class="ltx_para ltx_noindent" id="S3.SS2.SSS0.Px3.p1">
     <p class="ltx_p" id="S3.SS2.SSS0.Px3.p1.1">
      The goal of this task is to support natural conversations between
      <span class="ltx_text ltx_font_smallcaps" id="S3.SS2.SSS0.Px3.p1.1.1">
       LEO
      </span>
      and users about a given 3D scene.
This task necessitates coherence and continuity across multiple rounds of conversational interactions.
We build such dialogues on 3RScan scenes by prompting LLMs with a variant of the Chain-of-Thought prompting method discussed in
      <a class="ltx_ref" href="#S3.SS3" title="3.3 LLM-assisted 3D-language Data Generation ‣ 3 Datasets ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Sec.
       </span>
       <span class="ltx_text ltx_ref_tag">
        3.3
       </span>
      </a>
      to facilitate diverse dialogues about relevant and accurate details about the 3D scene.
In total, ~11K dialogues are collected.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S3.SS2.SSS0.Px4">
    <h5 class="ltx_title ltx_title_paragraph">
     Scene-aware task planning.
    </h5>
    <div class="ltx_para ltx_noindent" id="S3.SS2.SSS0.Px4.p1">
     <p class="ltx_p" id="S3.SS2.SSS0.Px4.p1.1">
      In this task,
      <span class="ltx_text ltx_font_smallcaps" id="S3.SS2.SSS0.Px4.p1.1.1">
       LEO
      </span>
      is required to decompose high-level tasks into step-by-step low-level plans given 3D scenes.
We expect
      <span class="ltx_text ltx_font_smallcaps" id="S3.SS2.SSS0.Px4.p1.1.2">
       LEO
      </span>
      to generate feasible plans based on the current 3D scene and ground its inherent common sense knowledge about procedures to the scene configurations, including, objects, their attributes, relations, and functional characteristics,
      <em class="ltx_emph ltx_font_italic" id="S3.SS2.SSS0.Px4.p1.1.3">
       etc
      </em>
      . By prompting LLMs, we end up collecting ~14K task-plan pairs on 3RScan scenes.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S3.SS2.SSS0.Px5">
    <h5 class="ltx_title ltx_title_paragraph">
     Embodied navigation.
    </h5>
    <div class="ltx_para ltx_noindent" id="S3.SS2.SSS0.Px5.p1">
     <p class="ltx_p" id="S3.SS2.SSS0.Px5.p1.1">
      We follow imitation learning setting in Habitat-web
      <cite class="ltx_cite ltx_citemacro_citep">
       (Ramrakhya et al.,
       <a class="ltx_ref" href="#bib.bib64" title="">
        2022
       </a>
       )
      </cite>
      for the embodied navigation task. We choose
      <span class="ltx_text ltx_font_typewriter" id="S3.SS2.SSS0.Px5.p1.1.1">
       ObjNav
      </span>
      , where
      <span class="ltx_text ltx_font_smallcaps" id="S3.SS2.SSS0.Px5.p1.1.2">
       LEO
      </span>
      needs to map navigation instructions (
      <em class="ltx_emph ltx_font_italic" id="S3.SS2.SSS0.Px5.p1.1.3">
       e.g
      </em>
      .
      <span class="ltx_text" id="S3.SS2.SSS0.Px5.p1.1.4">
      </span>
      “find bed”), object-centric 3D input, and an egocentric 2D input into discrete habitat motor commands. For simplicity, we use shortest path navigation trials rather than human demonstrations for learning as they are less noisy and therefore easier to learn when provided with the 3D scene. In total, we generate ~60K navigation episodes out of the MP3D
      <span class="ltx_text ltx_font_typewriter" id="S3.SS2.SSS0.Px5.p1.1.5">
       ObjNav
      </span>
      training scenes
      <cite class="ltx_cite ltx_citemacro_citep">
       (Savva et al.,
       <a class="ltx_ref" href="#bib.bib68" title="">
        2019
       </a>
       )
      </cite>
      for this task.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S3.SS2.SSS0.Px6">
    <h5 class="ltx_title ltx_title_paragraph">
     Robotic manipulation.
    </h5>
    <div class="ltx_para ltx_noindent" id="S3.SS2.SSS0.Px6.p1">
     <p class="ltx_p" id="S3.SS2.SSS0.Px6.p1.1">
      We employ a subset of the manipulation tasks introduced in CLIPort
      <cite class="ltx_cite ltx_citemacro_citep">
       (Shridhar et al.,
       <a class="ltx_ref" href="#bib.bib72" title="">
        2021
       </a>
       )
      </cite>
      . The input of this task includes instructions, egocentric 2D observations, and object-centric 3D information. As discussed in
      <a class="ltx_ref" href="#S2.SS1" title="2.1 Tokenization ‣ 2 Model ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Sec.
       </span>
       <span class="ltx_text ltx_ref_tag">
        2.1
       </span>
      </a>
      , we discretize the continuous action space of CLIPort into bins to unify the action decoding of navigation and manipulation (more details in
      <a class="ltx_ref" href="#A2" title="Appendix B Action Tokenization ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Appendix
       </span>
       <span class="ltx_text ltx_ref_tag">
        B
       </span>
      </a>
      ). We generate 100K demonstrations for each selected manipulation task.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S3.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     3.3
    </span>
    LLM-assisted 3D-language Data Generation
   </h3>
   <div class="ltx_para ltx_noindent" id="S3.SS3.p1">
    <p class="ltx_p" id="S3.SS3.p1.1">
     As mentioned above, at the core of producing a large proportion of
     <span class="ltx_text ltx_font_smallcaps" id="S3.SS3.p1.1.1">
      LEO
     </span>
     -align and
     <span class="ltx_text ltx_font_smallcaps" id="S3.SS3.p1.1.2">
      LEO
     </span>
     -instruct is the assistance of LLMs. We now detail the key techniques of prompting LLMs (more specifically, ChatGPT) to generate 3D-text data. An overview can be found in
     <a class="ltx_ref" href="#S3.F2" title="In Scene-level caption. ‣ 3.1 LEO-align: 3D Vision-Language Alignment ‣ 3 Datasets ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Fig.
      </span>
      <span class="ltx_text ltx_ref_tag">
       2
      </span>
     </a>
     .
    </p>
   </div>
   <section class="ltx_paragraph" id="S3.SS3.SSS0.Px1">
    <h5 class="ltx_title ltx_title_paragraph">
     Scene-graph-based prompting.
    </h5>
    <div class="ltx_para ltx_noindent" id="S3.SS3.SSS0.Px1.p1">
     <p class="ltx_p" id="S3.SS3.SSS0.Px1.p1.1">
      We use 3D scene graph from 3DSSG
      <cite class="ltx_cite ltx_citemacro_citep">
       (Wu et al.,
       <a class="ltx_ref" href="#bib.bib84" title="">
        2021
       </a>
       )
      </cite>
      to provide scene contexts in prompts.
Compared to recent efforts that utilize object boxes
      <cite class="ltx_cite ltx_citemacro_citep">
       (Yin et al.,
       <a class="ltx_ref" href="#bib.bib87" title="">
        2023
       </a>
       ; Hong et al.,
       <a class="ltx_ref" href="#bib.bib30" title="">
        2023
       </a>
       ; Wang et al.,
       <a class="ltx_ref" href="#bib.bib81" title="">
        2023d
       </a>
       )
      </cite>
      , we observed that our method provides high-quality object attributes and spatial relation information among objects, allowing
      <abbr class="ltx_glossaryref" title="large language models">
       <span class="ltx_text ltx_glossary_short">
        LLMs
       </span>
      </abbr>
      to capture and generate more accurate and relevant 3D details (see comparisons in
      <a class="ltx_ref" href="#A1.SS6" title="A.6 Scene-graph-based Prompting vs. Box-based Prompting ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Sec.
       </span>
       <span class="ltx_text ltx_ref_tag">
        A.6
       </span>
      </a>
      ). To further improve data quality in open-ended generation and reduce the hallucination of
      <abbr class="ltx_glossaryref" title="large language models">
       <span class="ltx_text ltx_glossary_short">
        LLMs
       </span>
      </abbr>
      <cite class="ltx_cite ltx_citemacro_citep">
       (Bang et al.,
       <a class="ltx_ref" href="#bib.bib6" title="">
        2023
       </a>
       )
      </cite>
      , we propose the Object-centric chain of thought (
      <abbr class="ltx_glossaryref" title="Object-centric Chain-of-Thought">
       <span class="ltx_text ltx_glossary_short">
        O-CoT
       </span>
      </abbr>
      ) prompting that requires the LLM to explicitly provide the label and ID of object candidates as
      <span class="ltx_text" id="S3.SS3.SSS0.Px1.p1.1.1" style="color:#808080;">
       thoughts
      </span>
      during question and dialogue generation. We provide examples of
      <abbr class="ltx_glossaryref" title="Object-centric Chain-of-Thought">
       <span class="ltx_text ltx_glossary_short">
        O-CoT
       </span>
      </abbr>
      in
      <a class="ltx_ref" href="#S3.F2" title="In Scene-level caption. ‣ 3.1 LEO-align: 3D Vision-Language Alignment ‣ 3 Datasets ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Fig.
       </span>
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      and comparative experiments to verify the effectiveness of
      <abbr class="ltx_glossaryref" title="Object-centric Chain-of-Thought">
       <span class="ltx_text ltx_glossary_short">
        O-CoT
       </span>
      </abbr>
      on improving answer reliability in
      <a class="ltx_ref" href="#A1.SS2" title="A.2 Analysis of the Object-Centric Chain-of-Thought ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Sec.
       </span>
       <span class="ltx_text ltx_ref_tag">
        A.2
       </span>
      </a>
      . We also utilize subgraph sampling to further enhance the diversity of 3D scene graph (see details in
      <a class="ltx_ref" href="#A1.SS5" title="A.5 Subgraph Sampling ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Sec.
       </span>
       <span class="ltx_text ltx_ref_tag">
        A.5
       </span>
      </a>
      ).
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S3.SS3.SSS0.Px2">
    <h5 class="ltx_title ltx_title_paragraph">
     Refinement procedures.
    </h5>
    <div class="ltx_para ltx_noindent" id="S3.SS3.SSS0.Px2.p1">
     <p class="ltx_p" id="S3.SS3.SSS0.Px2.p1.1">
      We pass raw LLM-generated responses into several human-defined filtering procedures based on the 3D scene graph. Notably, negative responses (
      <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS0.Px2.p1.1.1">
       e.g
      </em>
      .
      <span class="ltx_text" id="S3.SS3.SSS0.Px2.p1.1.2">
      </span>
      , lacking necessary information to answer) will be removed; unnatural narratives will be rewritten. For generated text that involves logical reasoning (
      <em class="ltx_emph ltx_font_italic" id="S3.SS3.SSS0.Px2.p1.1.3">
       e.g
      </em>
      .
      <span class="ltx_text" id="S3.SS3.SSS0.Px2.p1.1.4">
      </span>
      , counting) or hallucination, we manually fix the wrong responses based on the information provided by the 3D scene graph. We provide details about these procedures in
      <a class="ltx_ref" href="#A1.SS3" title="A.3 Refinement Details ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Sec.
       </span>
       <span class="ltx_text ltx_ref_tag">
        A.3
       </span>
      </a>
      and statistics in
      <a class="ltx_ref" href="#A1.SS4" title="A.4 Statistics of Raw Responses ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Sec.
       </span>
       <span class="ltx_text ltx_ref_tag">
        A.4
       </span>
      </a>
      .
     </p>
    </div>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S4">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    4
   </span>
   Capabilities and Analyses
  </h2>
  <div class="ltx_para ltx_noindent" id="S4.p1">
   <p class="ltx_p" id="S4.p1.1">
    We present a comprehensive demonstration of
    <span class="ltx_text ltx_font_smallcaps" id="S4.p1.1.1">
     LEO
    </span>
    ’s capabilities by evaluating it on the full spectrum of embodied 3D tasks encompassing perceiving, grounding, reasoning, planning, and acting. We provide both quantitative comparisons between
    <span class="ltx_text ltx_font_smallcaps" id="S4.p1.1.2">
     LEO
    </span>
    and competitive task-specific baselines and qualitative visualizations (see in
    <a class="ltx_ref" href="#S4.F3" title="In Results &amp; analysis. ‣ 4.1 3D Vision-Language Understanding and Embodied Reasoning ‣ 4 Capabilities and Analyses ‣ An Embodied Generalist Agent in 3D World">
     <span class="ltx_text ltx_ref_tag">
      Fig.
     </span>
     <span class="ltx_text ltx_ref_tag">
      3
     </span>
    </a>
    ) to showcase the power of
    <span class="ltx_text ltx_font_smallcaps" id="S4.p1.1.3">
     LEO
    </span>
    as an embodied generalist agent. We provide additional experimental details about the model and implementation in
    <a class="ltx_ref" href="#A4" title="Appendix D Model Details ‣ An Embodied Generalist Agent in 3D World">
     <span class="ltx_text ltx_ref_tag">
      Appendix
     </span>
     <span class="ltx_text ltx_ref_tag">
      D
     </span>
    </a>
    . We further ablate
    <span class="ltx_text ltx_font_smallcaps" id="S4.p1.1.4">
     LEO
    </span>
    with various data configurations and analyze the scaling law.
   </p>
  </div>
  <section class="ltx_subsection" id="S4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.1
    </span>
    3D Vision-Language Understanding and Embodied Reasoning
   </h3>
   <section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
    <h5 class="ltx_title ltx_title_paragraph">
     Overview.
    </h5>
    <div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px1.p1">
     <p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">
      Understanding and reasoning about object attributes, object relations, and other facets of 3D scenes from an agent’s egocentric perspective is a fundamental capability of an embodied generalist agent in the 3D world. We investigate how well can
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.SSS0.Px1.p1.1.1">
       LEO
      </span>
      perform 3D VL understanding and embodied reasoning tasks, especially when being compared against task-specific models and existing generalist agents. Specifically, we consider three renowned 3D tasks: 3D captioning on Scan2Cap
      <cite class="ltx_cite ltx_citemacro_citep">
       (Chen et al.,
       <a class="ltx_ref" href="#bib.bib17" title="">
        2021
       </a>
       )
      </cite>
      , 3D QA on ScanQA
      <cite class="ltx_cite ltx_citemacro_citep">
       (Azuma et al.,
       <a class="ltx_ref" href="#bib.bib5" title="">
        2022
       </a>
       )
      </cite>
      , and 3D embodied reasoning on SQA3D
      <cite class="ltx_cite ltx_citemacro_citep">
       (Ma et al.,
       <a class="ltx_ref" href="#bib.bib51" title="">
        2023
       </a>
       )
      </cite>
      .
By prompting
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.SSS0.Px1.p1.1.2">
       LEO
      </span>
      to follow instructions for these tasks, we follow the standard evaluation metric to report conventional captioning scores (CIDEr, BLEU, METEOR, and ROUGE) and SentenceSim
      <cite class="ltx_cite ltx_citemacro_citep">
       (Reimers &amp; Gurevych,
       <a class="ltx_ref" href="#bib.bib66" title="">
        2019
       </a>
       )
      </cite>
      for open-ended VL generation, as well as exact-match accuracies for QA tasks.
Following 3D-VisTA
      <cite class="ltx_cite ltx_citemacro_citep">
       (Zhu et al.,
       <a class="ltx_ref" href="#bib.bib94" title="">
        2023c
       </a>
       )
      </cite>
      , we use object proposals from Mask3D
      <cite class="ltx_cite ltx_citemacro_citep">
       (Schult et al.,
       <a class="ltx_ref" href="#bib.bib71" title="">
        2022
       </a>
       )
      </cite>
      in our object-centric 3D encoder.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
    <h5 class="ltx_title ltx_title_paragraph">
     Baselines.
    </h5>
    <div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px2.p1">
     <p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">
      For quantitative comparisons, we include both task-specific approaches and generalist models: 1) state-of-the-art specialists in 3D dense captioning
      <cite class="ltx_cite ltx_citemacro_citep">
       (Chen et al.,
       <a class="ltx_ref" href="#bib.bib17" title="">
        2021
       </a>
       ; Cai et al.,
       <a class="ltx_ref" href="#bib.bib11" title="">
        2022
       </a>
       ; Chen et al.,
       <a class="ltx_ref" href="#bib.bib16" title="">
        2023
       </a>
       )
      </cite>
      ; 2) state-of-the-art specialists in 3D QA
      <cite class="ltx_cite ltx_citemacro_citep">
       (Azuma et al.,
       <a class="ltx_ref" href="#bib.bib5" title="">
        2022
       </a>
       ; Ma et al.,
       <a class="ltx_ref" href="#bib.bib51" title="">
        2023
       </a>
       )
      </cite>
      ; 3) task-specific fine-tuned generalist models like 3D-VisTA
      <cite class="ltx_cite ltx_citemacro_citep">
       (Zhu et al.,
       <a class="ltx_ref" href="#bib.bib94" title="">
        2023c
       </a>
       )
      </cite>
      and 3D-LLM
      <cite class="ltx_cite ltx_citemacro_citep">
       (Hong et al.,
       <a class="ltx_ref" href="#bib.bib30" title="">
        2023
       </a>
       )
      </cite>
      . To the best of our knowledge,
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.SSS0.Px2.p1.1.1">
       LEO
      </span>
      is the first model that, in stark contrast to prior models, can handle the aforementioned VL tasks in a unified architecture without additional fine-tuning. This lends greater credence to
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.SSS0.Px2.p1.1.2">
       LEO
      </span>
      ’s comparative superiority.
     </p>
    </div>
    <figure class="ltx_table" id="S4.T2">
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_table">
       Table 2:
      </span>
      <span class="ltx_text ltx_font_bold" id="S4.T2.6.1">
       Quantitative comparison with state-of-the-art models on 3D VL understanding and embodied reasoning tasks
      </span>
      . “C” stands for “CIDEr”, “B-4” for “BLEU-4”, “M” for “METEOR”, “R” for “ROUGE”, “Sim” for sentence similarity, and “EM@1” for top-1 exact match. The n-gram metrics for Scan2Cap are governed by IoU@0.5.
      <sup class="ltx_sup" id="S4.T2.7.2">
       †
      </sup>
      indicates answering questions via prompting GPT-3 with the generated scene caption.
     </figcaption>
     <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="S4.T2.3" style="width:433.6pt;height:153.4pt;vertical-align:-0.7pt;">
      <span class="ltx_transformed_inner" style="transform:translate(-115.5pt,40.7pt) scale(0.652457503172204,0.652457503172204) ;">
       <table class="ltx_tabular ltx_align_middle" id="S4.T2.3.1">
        <tr class="ltx_tr" id="S4.T2.3.1.2">
         <td class="ltx_td ltx_border_tt" id="S4.T2.3.1.2.1">
         </td>
         <td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="S4.T2.3.1.2.2">
          Scan2Cap (val)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="S4.T2.3.1.2.3">
          ScanQA (val)
         </td>
         <td class="ltx_td ltx_align_center ltx_border_tt" id="S4.T2.3.1.2.4">
          SQA3D
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.3.1.3">
         <td class="ltx_td" id="S4.T2.3.1.3.1">
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.3.2">
          C
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.3.3">
          B-4
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.3.4">
          M
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.3.5">
          R
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.3.6">
          Sim
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.3.7">
          C
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.3.8">
          B-4
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.3.9">
          M
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.3.10">
          R
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.3.11">
          EM@1
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="S4.T2.3.1.3.12">
          EM@1
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.3.1.4">
         <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.3.1.4.1">
          <span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.T2.3.1.4.1.1">
           Task-specific models
          </span>
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.4.2">
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.4.3">
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.4.4">
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.4.5">
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.4.6">
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.4.7">
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.4.8">
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.4.9">
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.4.10">
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.4.11">
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.4.12">
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.3.1.1">
         <td class="ltx_td ltx_align_left" id="S4.T2.3.1.1.2">
          Scan2Cap (GPT-3)
          <cite class="ltx_cite ltx_citemacro_citep">
           (Chen et al.,
           <a class="ltx_ref" href="#bib.bib17" title="">
            2021
           </a>
           )
          </cite>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.1.3">
          35.2
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.1.4">
          22.4
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.1.5">
          21.4
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.1.6">
          43.5
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.1.7">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.1.8">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.1.9">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.1.10">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.1.11">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.1.12">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.1.1">
          41.0
          <sup class="ltx_sup" id="S4.T2.3.1.1.1.1">
           †
          </sup>
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.3.1.5">
         <td class="ltx_td ltx_align_left" id="S4.T2.3.1.5.1">
          3DJCG
          <cite class="ltx_cite ltx_citemacro_citep">
           (Cai et al.,
           <a class="ltx_ref" href="#bib.bib11" title="">
            2022
           </a>
           )
          </cite>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.2">
          47.7
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.3">
          31.5
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.4">
          24.3
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.5">
          51.8
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.6">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.7">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.8">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.9">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.10">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.11">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.5.12">
          -
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.3.1.6">
         <td class="ltx_td ltx_align_left" id="S4.T2.3.1.6.1">
          Vote2Cap-DETR
          <cite class="ltx_cite ltx_citemacro_citep">
           (Chen et al.,
           <a class="ltx_ref" href="#bib.bib16" title="">
            2023
           </a>
           )
          </cite>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.2">
          61.8
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.3">
          34.5
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.4">
          26.2
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.5">
          54.4
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.6">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.7">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.8">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.9">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.10">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.11">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.6.12">
          -
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.3.1.7">
         <td class="ltx_td ltx_align_left" id="S4.T2.3.1.7.1">
          ScanRefer+MCAN
          <cite class="ltx_cite ltx_citemacro_citep">
           (Chen et al.,
           <a class="ltx_ref" href="#bib.bib14" title="">
            2020
           </a>
           )
          </cite>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.2">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.3">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.4">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.5">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.6">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.7">
          55.4
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.8">
          7.9
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.9">
          11.5
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.10">
          30.0
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.11">
          18.6
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.7.12">
          -
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.3.1.8">
         <td class="ltx_td ltx_align_left" id="S4.T2.3.1.8.1">
          ClipBERT
          <cite class="ltx_cite ltx_citemacro_citep">
           (Lei et al.,
           <a class="ltx_ref" href="#bib.bib41" title="">
            2021
           </a>
           )
          </cite>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.2">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.3">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.4">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.5">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.6">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.7">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.8">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.9">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.10">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.11">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.8.12">
          43.3
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.3.1.9">
         <td class="ltx_td ltx_align_left" id="S4.T2.3.1.9.1">
          ScanQA
          <cite class="ltx_cite ltx_citemacro_citep">
           (Azuma et al.,
           <a class="ltx_ref" href="#bib.bib5" title="">
            2022
           </a>
           )
          </cite>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.2">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.3">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.4">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.5">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.6">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.7">
          64.9
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.8">
          10.1
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.9">
          13.1
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.10">
          33.3
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.11">
          21.1
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.9.12">
          47.2
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.3.1.10">
         <td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.3.1.10.1">
          <span class="ltx_text ltx_font_bold ltx_font_italic" id="S4.T2.3.1.10.1.1">
           Task-specific fine-tuned
          </span>
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.10.2">
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.10.3">
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.10.4">
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.10.5">
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.10.6">
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.10.7">
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.10.8">
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.10.9">
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.10.10">
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.10.11">
         </td>
         <td class="ltx_td ltx_border_t" id="S4.T2.3.1.10.12">
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.3.1.11">
         <td class="ltx_td ltx_align_left" id="S4.T2.3.1.11.1">
          3D-VisTA
          <cite class="ltx_cite ltx_citemacro_citep">
           (Zhu et al.,
           <a class="ltx_ref" href="#bib.bib94" title="">
            2023c
           </a>
           )
          </cite>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.2">
          66.9
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.3">
          34.0
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.4">
          27.1
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.5">
          54.3
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.6">
          53.8
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.7">
          69.6
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.8">
          10.4
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.9">
          13.9
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.10">
          35.7
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.11">
          22.4
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.11.12">
          48.5
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.3.1.12">
         <td class="ltx_td ltx_align_left" id="S4.T2.3.1.12.1">
          3D-LLM (FlanT5)
          <cite class="ltx_cite ltx_citemacro_citep">
           (Hong et al.,
           <a class="ltx_ref" href="#bib.bib30" title="">
            2023
           </a>
           )
          </cite>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.2">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.3">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.4">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.5">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.6">
          -
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.7">
          69.4
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.8">
          <span class="ltx_text ltx_font_bold" id="S4.T2.3.1.12.8.1">
           12.0
          </span>
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.9">
          14.5
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.10">
          35.7
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.11">
          20.5
         </td>
         <td class="ltx_td ltx_align_center" id="S4.T2.3.1.12.12">
          -
         </td>
        </tr>
        <tr class="ltx_tr" id="S4.T2.3.1.13">
         <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.T2.3.1.13.1">
          <span class="ltx_text ltx_font_smallcaps" id="S4.T2.3.1.13.1.1">
           LEO
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.3.1.13.2">
          <span class="ltx_text ltx_font_bold" id="S4.T2.3.1.13.2.1">
           68.4
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.3.1.13.3">
          <span class="ltx_text ltx_font_bold" id="S4.T2.3.1.13.3.1">
           36.9
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.3.1.13.4">
          <span class="ltx_text ltx_font_bold" id="S4.T2.3.1.13.4.1">
           27.7
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.3.1.13.5">
          <span class="ltx_text ltx_font_bold" id="S4.T2.3.1.13.5.1">
           57.8
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.3.1.13.6">
          <span class="ltx_text ltx_font_bold" id="S4.T2.3.1.13.6.1">
           54.7
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.3.1.13.7">
          <span class="ltx_text ltx_font_bold" id="S4.T2.3.1.13.7.1">
           80.0
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.3.1.13.8">
          11.5
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.3.1.13.9">
          <span class="ltx_text ltx_font_bold" id="S4.T2.3.1.13.9.1">
           16.2
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.3.1.13.10">
          <span class="ltx_text ltx_font_bold" id="S4.T2.3.1.13.10.1">
           39.3
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.3.1.13.11">
          <span class="ltx_text ltx_font_bold" id="S4.T2.3.1.13.11.1">
           36.6
          </span>
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.T2.3.1.13.12">
          <span class="ltx_text ltx_font_bold" id="S4.T2.3.1.13.12.1">
           53.7
          </span>
         </td>
        </tr>
       </table>
      </span>
     </div>
    </figure>
    <figure class="ltx_table" id="S4.SS1.SSS0.Px2.7">
     <div class="ltx_flex_figure ltx_flex_table">
      <div class="ltx_flex_cell ltx_flex_size_2">
       <figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_middle" id="S4.SS1.SSS0.Px2.1.fig1" style="width:230.5pt;">
        <div class="ltx_flex_figure">
         <div class="ltx_flex_cell ltx_flex_size_1">
          <figure class="ltx_table ltx_figure_panel" id="S4.T3">
           <figcaption class="ltx_caption">
            <span class="ltx_tag ltx_tag_table">
             Table 3:
            </span>
            <span class="ltx_text ltx_font_bold" id="S4.T3.4.1">
             Results on CLIPort robot manipulation
            </span>
            . We compare with results from
            <cite class="ltx_cite ltx_citemacro_cite">
             Shridhar et al. (
             <a class="ltx_ref" href="#bib.bib72" title="">
              2021
             </a>
             )
            </cite>
            .
            <span class="ltx_text" id="S4.T3.5.2" style="color:#008000;">
             seen
            </span>
            indicates in-domain tasks.
            <span class="ltx_text" id="S4.T3.6.3" style="color:#CC4054;">
             unseen
            </span>
            marks OOD tasks with novel colors or objects.
           </figcaption>
          </figure>
         </div>
         <div class="ltx_flex_break">
         </div>
         <div class="ltx_flex_cell ltx_flex_size_1">
          <div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" id="S4.SS1.SSS0.Px2.1.fig1.1" style="width:433.6pt;height:265.2pt;vertical-align:-0.0pt;">
           <span class="ltx_transformed_inner" style="transform:translate(80.0pt,-48.9pt) scale(1.5843200168413,1.5843200168413) ;">
            <table class="ltx_tabular ltx_align_middle" id="S4.SS1.SSS0.Px2.1.fig1.1.1">
             <tr class="ltx_tr" id="S4.SS1.SSS0.Px2.1.fig1.1.1.1">
              <td class="ltx_td ltx_border_tt" id="S4.SS1.SSS0.Px2.1.fig1.1.1.1.1" style="padding-left:2.0pt;padding-right:2.0pt;">
              </td>
              <td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.SS1.SSS0.Px2.1.fig1.1.1.1.2" style="padding-left:2.0pt;padding-right:2.0pt;">
               separating-piles
              </td>
              <td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.SS1.SSS0.Px2.1.fig1.1.1.1.3" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text" id="S4.SS1.SSS0.Px2.1.fig1.1.1.1.3.1">
               </span>
               <span class="ltx_text" id="S4.SS1.SSS0.Px2.1.fig1.1.1.1.3.2">
                <span class="ltx_tabular ltx_align_middle" id="S4.SS1.SSS0.Px2.1.fig1.1.1.1.3.2.1">
                 <span class="ltx_tr" id="S4.SS1.SSS0.Px2.1.fig1.1.1.1.3.2.1.1">
                  <span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.1.3.2.1.1.1" style="padding-left:2.0pt;padding-right:2.0pt;">
                   packing-google
                  </span>
                 </span>
                 <span class="ltx_tr" id="S4.SS1.SSS0.Px2.1.fig1.1.1.1.3.2.1.2">
                  <span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.1.3.2.1.2.1" style="padding-left:2.0pt;padding-right:2.0pt;">
                   -objects-seq
                  </span>
                 </span>
                </span>
               </span>
               <span class="ltx_text" id="S4.SS1.SSS0.Px2.1.fig1.1.1.1.3.3">
               </span>
              </td>
              <td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.SS1.SSS0.Px2.1.fig1.1.1.1.4" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text" id="S4.SS1.SSS0.Px2.1.fig1.1.1.1.4.1">
               </span>
               <span class="ltx_text" id="S4.SS1.SSS0.Px2.1.fig1.1.1.1.4.2">
                <span class="ltx_tabular ltx_align_middle" id="S4.SS1.SSS0.Px2.1.fig1.1.1.1.4.2.1">
                 <span class="ltx_tr" id="S4.SS1.SSS0.Px2.1.fig1.1.1.1.4.2.1.1">
                  <span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.1.4.2.1.1.1" style="padding-left:2.0pt;padding-right:2.0pt;">
                   put-blocks-in
                  </span>
                 </span>
                 <span class="ltx_tr" id="S4.SS1.SSS0.Px2.1.fig1.1.1.1.4.2.1.2">
                  <span class="ltx_td ltx_nopad_r ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.1.4.2.1.2.1" style="padding-left:2.0pt;padding-right:2.0pt;">
                   -bowls
                  </span>
                 </span>
                </span>
               </span>
               <span class="ltx_text" id="S4.SS1.SSS0.Px2.1.fig1.1.1.1.4.3">
               </span>
              </td>
             </tr>
             <tr class="ltx_tr" id="S4.SS1.SSS0.Px2.1.fig1.1.1.2">
              <td class="ltx_td" id="S4.SS1.SSS0.Px2.1.fig1.1.1.2.1" style="padding-left:2.0pt;padding-right:2.0pt;">
              </td>
              <td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS0.Px2.1.fig1.1.1.2.2" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text" id="S4.SS1.SSS0.Px2.1.fig1.1.1.2.2.1" style="color:#008000;">
                seen
               </span>
              </td>
              <td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS0.Px2.1.fig1.1.1.2.3" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text" id="S4.SS1.SSS0.Px2.1.fig1.1.1.2.3.1" style="color:#CC4054;">
                unseen
               </span>
              </td>
              <td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS0.Px2.1.fig1.1.1.2.4" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text" id="S4.SS1.SSS0.Px2.1.fig1.1.1.2.4.1" style="color:#008000;">
                seen
               </span>
              </td>
              <td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS0.Px2.1.fig1.1.1.2.5" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text" id="S4.SS1.SSS0.Px2.1.fig1.1.1.2.5.1" style="color:#CC4054;">
                unseen
               </span>
              </td>
              <td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS0.Px2.1.fig1.1.1.2.6" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text" id="S4.SS1.SSS0.Px2.1.fig1.1.1.2.6.1" style="color:#008000;">
                seen
               </span>
              </td>
              <td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS0.Px2.1.fig1.1.1.2.7" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text" id="S4.SS1.SSS0.Px2.1.fig1.1.1.2.7.1" style="color:#CC4054;">
                unseen
               </span>
              </td>
             </tr>
             <tr class="ltx_tr" id="S4.SS1.SSS0.Px2.1.fig1.1.1.3">
              <td class="ltx_td ltx_align_left ltx_border_t" id="S4.SS1.SSS0.Px2.1.fig1.1.1.3.1" style="padding-left:2.0pt;padding-right:2.0pt;">
               Transporter
              </td>
              <td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS0.Px2.1.fig1.1.1.3.2" style="padding-left:2.0pt;padding-right:2.0pt;">
               48.4
              </td>
              <td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS0.Px2.1.fig1.1.1.3.3" style="padding-left:2.0pt;padding-right:2.0pt;">
               52.3
              </td>
              <td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS0.Px2.1.fig1.1.1.3.4" style="padding-left:2.0pt;padding-right:2.0pt;">
               46.3
              </td>
              <td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS0.Px2.1.fig1.1.1.3.5" style="padding-left:2.0pt;padding-right:2.0pt;">
               37.3
              </td>
              <td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS0.Px2.1.fig1.1.1.3.6" style="padding-left:2.0pt;padding-right:2.0pt;">
               64.7
              </td>
              <td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS0.Px2.1.fig1.1.1.3.7" style="padding-left:2.0pt;padding-right:2.0pt;">
               18.7
              </td>
             </tr>
             <tr class="ltx_tr" id="S4.SS1.SSS0.Px2.1.fig1.1.1.4">
              <td class="ltx_td ltx_align_left" id="S4.SS1.SSS0.Px2.1.fig1.1.1.4.1" style="padding-left:2.0pt;padding-right:2.0pt;">
               CLIP-only
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.4.2" style="padding-left:2.0pt;padding-right:2.0pt;">
               90.2
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.4.3" style="padding-left:2.0pt;padding-right:2.0pt;">
               71.0
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.4.4" style="padding-left:2.0pt;padding-right:2.0pt;">
               95.8
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.4.5" style="padding-left:2.0pt;padding-right:2.0pt;">
               57.8
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.4.6" style="padding-left:2.0pt;padding-right:2.0pt;">
               97.7
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.4.7" style="padding-left:2.0pt;padding-right:2.0pt;">
               44.5
              </td>
             </tr>
             <tr class="ltx_tr" id="S4.SS1.SSS0.Px2.1.fig1.1.1.5">
              <td class="ltx_td ltx_align_left" id="S4.SS1.SSS0.Px2.1.fig1.1.1.5.1" style="padding-left:2.0pt;padding-right:2.0pt;">
               RN50-BERT
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.5.2" style="padding-left:2.0pt;padding-right:2.0pt;">
               46.5
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.5.3" style="padding-left:2.0pt;padding-right:2.0pt;">
               44.9
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.5.4" style="padding-left:2.0pt;padding-right:2.0pt;">
               94.0
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.5.5" style="padding-left:2.0pt;padding-right:2.0pt;">
               56.1
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.5.6" style="padding-left:2.0pt;padding-right:2.0pt;">
               91.8
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.5.7" style="padding-left:2.0pt;padding-right:2.0pt;">
               23.8
              </td>
             </tr>
             <tr class="ltx_tr" id="S4.SS1.SSS0.Px2.1.fig1.1.1.6">
              <td class="ltx_td ltx_align_left" id="S4.SS1.SSS0.Px2.1.fig1.1.1.6.1" style="padding-left:2.0pt;padding-right:2.0pt;">
               CLIPort (single)
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.6.2" style="padding-left:2.0pt;padding-right:2.0pt;">
               98.0
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.6.3" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS0.Px2.1.fig1.1.1.6.3.1">
                75.2
               </span>
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.6.4" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS0.Px2.1.fig1.1.1.6.4.1">
                96.2
               </span>
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.6.5" style="padding-left:2.0pt;padding-right:2.0pt;">
               71.9
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.6.6" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS0.Px2.1.fig1.1.1.6.6.1">
                100
               </span>
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.6.7" style="padding-left:2.0pt;padding-right:2.0pt;">
               25.0
              </td>
             </tr>
             <tr class="ltx_tr" id="S4.SS1.SSS0.Px2.1.fig1.1.1.7">
              <td class="ltx_td ltx_align_left" id="S4.SS1.SSS0.Px2.1.fig1.1.1.7.1" style="padding-left:2.0pt;padding-right:2.0pt;">
               CLIPort (multi)
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.7.2" style="padding-left:2.0pt;padding-right:2.0pt;">
               89.0
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.7.3" style="padding-left:2.0pt;padding-right:2.0pt;">
               62.8
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.7.4" style="padding-left:2.0pt;padding-right:2.0pt;">
               84.4
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.7.5" style="padding-left:2.0pt;padding-right:2.0pt;">
               70.3
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.7.6" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS0.Px2.1.fig1.1.1.7.6.1">
                100
               </span>
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.1.fig1.1.1.7.7" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS0.Px2.1.fig1.1.1.7.7.1">
                45.8
               </span>
              </td>
             </tr>
             <tr class="ltx_tr" id="S4.SS1.SSS0.Px2.1.fig1.1.1.8">
              <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" id="S4.SS1.SSS0.Px2.1.fig1.1.1.8.1" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.SSS0.Px2.1.fig1.1.1.8.1.1">
                LEO
               </span>
              </td>
              <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.SSS0.Px2.1.fig1.1.1.8.2" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS0.Px2.1.fig1.1.1.8.2.1">
                98.8
               </span>
              </td>
              <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.SSS0.Px2.1.fig1.1.1.8.3" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS0.Px2.1.fig1.1.1.8.3.1">
                75.2
               </span>
              </td>
              <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.SSS0.Px2.1.fig1.1.1.8.4" style="padding-left:2.0pt;padding-right:2.0pt;">
               76.6
              </td>
              <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.SSS0.Px2.1.fig1.1.1.8.5" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS0.Px2.1.fig1.1.1.8.5.1">
                79.8
               </span>
              </td>
              <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.SSS0.Px2.1.fig1.1.1.8.6" style="padding-left:2.0pt;padding-right:2.0pt;">
               86.2
              </td>
              <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.SSS0.Px2.1.fig1.1.1.8.7" style="padding-left:2.0pt;padding-right:2.0pt;">
               35.2
              </td>
             </tr>
            </table>
           </span>
          </div>
         </div>
        </div>
       </figure>
      </div>
      <div class="ltx_flex_cell ltx_flex_size_2">
       <figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" id="S4.SS1.SSS0.Px2.7.6" style="width:159.0pt;">
        <div class="ltx_flex_figure">
         <div class="ltx_flex_cell ltx_flex_size_1">
          <figure class="ltx_table ltx_figure_panel" id="S4.T4">
           <figcaption class="ltx_caption">
            <span class="ltx_tag ltx_tag_table">
             Table 4:
            </span>
            <span class="ltx_text ltx_font_bold" id="S4.T4.7.1">
             Results on object navigation.
            </span>
            We compare
            <span class="ltx_text ltx_font_smallcaps" id="S4.T4.8.2">
             LEO
            </span>
            with similar imitation learning agents in Habitat-web (H.w.)
            <cite class="ltx_cite ltx_citemacro_citep">
             (Ramrakhya et al.,
             <a class="ltx_ref" href="#bib.bib64" title="">
              2022
             </a>
             )
            </cite>
            and CortexBench (VC-1)
            <cite class="ltx_cite ltx_citemacro_citep">
             (Majumdar et al.,
             <a class="ltx_ref" href="#bib.bib52" title="">
              2023
             </a>
             )
            </cite>
            . S: success rate; L: SPL.
            <sup class="ltx_sup" id="S4.T4.9.3">
             †
            </sup>
            <span class="ltx_text ltx_font_smallcaps" id="S4.T4.10.4">
             LEO
            </span>
            is not trained on HM3D scenes.
           </figcaption>
          </figure>
         </div>
         <div class="ltx_flex_break">
         </div>
         <div class="ltx_flex_cell ltx_flex_size_1">
          <div class="ltx_inline-block ltx_figure_panel ltx_align_center ltx_transformed_outer" id="S4.SS1.SSS0.Px2.7.6.6" style="width:411.9pt;height:240.2pt;vertical-align:-0.0pt;">
           <span class="ltx_transformed_inner" style="transform:translate(113.4pt,-66.1pt) scale(2.2239474353643,2.2239474353643) ;">
            <table class="ltx_tabular ltx_align_middle" id="S4.SS1.SSS0.Px2.7.6.6.6">
             <tr class="ltx_tr" id="S4.SS1.SSS0.Px2.7.6.6.6.7">
              <td class="ltx_td ltx_border_tt" id="S4.SS1.SSS0.Px2.7.6.6.6.7.1" rowspan="2" style="padding-left:2.0pt;padding-right:2.0pt;">
              </td>
              <td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.SS1.SSS0.Px2.7.6.6.6.7.2" style="padding-left:2.0pt;padding-right:2.0pt;">
               MP3D-val
              </td>
              <td class="ltx_td ltx_border_tt" id="S4.SS1.SSS0.Px2.7.6.6.6.7.3" style="padding-left:2.0pt;padding-right:2.0pt;">
              </td>
              <td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.SS1.SSS0.Px2.7.6.6.6.7.4" style="padding-left:2.0pt;padding-right:2.0pt;">
               HM3D-val
              </td>
             </tr>
             <tr class="ltx_tr" id="S4.SS1.SSS0.Px2.5.4.4.4.4">
              <td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS0.Px2.2.1.1.1.1.1" style="padding-left:2.0pt;padding-right:2.0pt;">
               S
               <math alttext="(\uparrow)" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px2.2.1.1.1.1.1.m1.1">
                <semantics id="S4.SS1.SSS0.Px2.2.1.1.1.1.1.m1.1a">
                 <mrow id="S4.SS1.SSS0.Px2.2.1.1.1.1.1.m1.1.2.2">
                  <mo id="S4.SS1.SSS0.Px2.2.1.1.1.1.1.m1.1.2.2.1" stretchy="false">
                   (
                  </mo>
                  <mo id="S4.SS1.SSS0.Px2.2.1.1.1.1.1.m1.1.1" lspace="0em" rspace="0em" stretchy="false" xref="S4.SS1.SSS0.Px2.2.1.1.1.1.1.m1.1.1.cmml">
                   ↑
                  </mo>
                  <mo id="S4.SS1.SSS0.Px2.2.1.1.1.1.1.m1.1.2.2.2" stretchy="false">
                   )
                  </mo>
                 </mrow>
                 <annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px2.2.1.1.1.1.1.m1.1b">
                  <ci id="S4.SS1.SSS0.Px2.2.1.1.1.1.1.m1.1.1.cmml" xref="S4.SS1.SSS0.Px2.2.1.1.1.1.1.m1.1.1">
                   ↑
                  </ci>
                 </annotation-xml>
                 <annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px2.2.1.1.1.1.1.m1.1c">
                  (\uparrow)
                 </annotation>
                </semantics>
               </math>
              </td>
              <td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS0.Px2.3.2.2.2.2.2" style="padding-left:2.0pt;padding-right:2.0pt;">
               L
               <math alttext="(\uparrow)" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px2.3.2.2.2.2.2.m1.1">
                <semantics id="S4.SS1.SSS0.Px2.3.2.2.2.2.2.m1.1a">
                 <mrow id="S4.SS1.SSS0.Px2.3.2.2.2.2.2.m1.1.2.2">
                  <mo id="S4.SS1.SSS0.Px2.3.2.2.2.2.2.m1.1.2.2.1" stretchy="false">
                   (
                  </mo>
                  <mo id="S4.SS1.SSS0.Px2.3.2.2.2.2.2.m1.1.1" lspace="0em" rspace="0em" stretchy="false" xref="S4.SS1.SSS0.Px2.3.2.2.2.2.2.m1.1.1.cmml">
                   ↑
                  </mo>
                  <mo id="S4.SS1.SSS0.Px2.3.2.2.2.2.2.m1.1.2.2.2" stretchy="false">
                   )
                  </mo>
                 </mrow>
                 <annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px2.3.2.2.2.2.2.m1.1b">
                  <ci id="S4.SS1.SSS0.Px2.3.2.2.2.2.2.m1.1.1.cmml" xref="S4.SS1.SSS0.Px2.3.2.2.2.2.2.m1.1.1">
                   ↑
                  </ci>
                 </annotation-xml>
                 <annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px2.3.2.2.2.2.2.m1.1c">
                  (\uparrow)
                 </annotation>
                </semantics>
               </math>
              </td>
              <td class="ltx_td" id="S4.SS1.SSS0.Px2.5.4.4.4.4.5" style="padding-left:2.0pt;padding-right:2.0pt;">
              </td>
              <td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS0.Px2.4.3.3.3.3.3" style="padding-left:2.0pt;padding-right:2.0pt;">
               S
               <math alttext="(\uparrow)" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px2.4.3.3.3.3.3.m1.1">
                <semantics id="S4.SS1.SSS0.Px2.4.3.3.3.3.3.m1.1a">
                 <mrow id="S4.SS1.SSS0.Px2.4.3.3.3.3.3.m1.1.2.2">
                  <mo id="S4.SS1.SSS0.Px2.4.3.3.3.3.3.m1.1.2.2.1" stretchy="false">
                   (
                  </mo>
                  <mo id="S4.SS1.SSS0.Px2.4.3.3.3.3.3.m1.1.1" lspace="0em" rspace="0em" stretchy="false" xref="S4.SS1.SSS0.Px2.4.3.3.3.3.3.m1.1.1.cmml">
                   ↑
                  </mo>
                  <mo id="S4.SS1.SSS0.Px2.4.3.3.3.3.3.m1.1.2.2.2" stretchy="false">
                   )
                  </mo>
                 </mrow>
                 <annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px2.4.3.3.3.3.3.m1.1b">
                  <ci id="S4.SS1.SSS0.Px2.4.3.3.3.3.3.m1.1.1.cmml" xref="S4.SS1.SSS0.Px2.4.3.3.3.3.3.m1.1.1">
                   ↑
                  </ci>
                 </annotation-xml>
                 <annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px2.4.3.3.3.3.3.m1.1c">
                  (\uparrow)
                 </annotation>
                </semantics>
               </math>
              </td>
              <td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS0.Px2.5.4.4.4.4.4" style="padding-left:2.0pt;padding-right:2.0pt;">
               L
               <math alttext="(\uparrow)" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px2.5.4.4.4.4.4.m1.1">
                <semantics id="S4.SS1.SSS0.Px2.5.4.4.4.4.4.m1.1a">
                 <mrow id="S4.SS1.SSS0.Px2.5.4.4.4.4.4.m1.1.2.2">
                  <mo id="S4.SS1.SSS0.Px2.5.4.4.4.4.4.m1.1.2.2.1" stretchy="false">
                   (
                  </mo>
                  <mo id="S4.SS1.SSS0.Px2.5.4.4.4.4.4.m1.1.1" lspace="0em" rspace="0em" stretchy="false" xref="S4.SS1.SSS0.Px2.5.4.4.4.4.4.m1.1.1.cmml">
                   ↑
                  </mo>
                  <mo id="S4.SS1.SSS0.Px2.5.4.4.4.4.4.m1.1.2.2.2" stretchy="false">
                   )
                  </mo>
                 </mrow>
                 <annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px2.5.4.4.4.4.4.m1.1b">
                  <ci id="S4.SS1.SSS0.Px2.5.4.4.4.4.4.m1.1.1.cmml" xref="S4.SS1.SSS0.Px2.5.4.4.4.4.4.m1.1.1">
                   ↑
                  </ci>
                 </annotation-xml>
                 <annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px2.5.4.4.4.4.4.m1.1c">
                  (\uparrow)
                 </annotation>
                </semantics>
               </math>
              </td>
             </tr>
             <tr class="ltx_tr" id="S4.SS1.SSS0.Px2.7.6.6.6.8">
              <td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS0.Px2.7.6.6.6.8.1" style="padding-left:2.0pt;padding-right:2.0pt;">
               H.w. (shortest)
              </td>
              <td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS0.Px2.7.6.6.6.8.2" style="padding-left:2.0pt;padding-right:2.0pt;">
               4.4
              </td>
              <td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS0.Px2.7.6.6.6.8.3" style="padding-left:2.0pt;padding-right:2.0pt;">
               2.2
              </td>
              <td class="ltx_td ltx_border_t" id="S4.SS1.SSS0.Px2.7.6.6.6.8.4" style="padding-left:2.0pt;padding-right:2.0pt;">
              </td>
              <td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS0.Px2.7.6.6.6.8.5" style="padding-left:2.0pt;padding-right:2.0pt;">
               -
              </td>
              <td class="ltx_td ltx_align_center ltx_border_t" id="S4.SS1.SSS0.Px2.7.6.6.6.8.6" style="padding-left:2.0pt;padding-right:2.0pt;">
               -
              </td>
             </tr>
             <tr class="ltx_tr" id="S4.SS1.SSS0.Px2.7.6.6.6.9">
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.7.6.6.6.9.1" style="padding-left:2.0pt;padding-right:2.0pt;">
               H.w. (70k demo)
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.7.6.6.6.9.2" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS0.Px2.7.6.6.6.9.2.1">
                35.4
               </span>
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.7.6.6.6.9.3" style="padding-left:2.0pt;padding-right:2.0pt;">
               10.2
              </td>
              <td class="ltx_td" id="S4.SS1.SSS0.Px2.7.6.6.6.9.4" style="padding-left:2.0pt;padding-right:2.0pt;">
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.7.6.6.6.9.5" style="padding-left:2.0pt;padding-right:2.0pt;">
               -
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.7.6.6.6.9.6" style="padding-left:2.0pt;padding-right:2.0pt;">
               -
              </td>
             </tr>
             <tr class="ltx_tr" id="S4.SS1.SSS0.Px2.7.6.6.6.10">
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.7.6.6.6.10.1" style="padding-left:2.0pt;padding-right:2.0pt;">
               VC-1 (ViT-B)
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.7.6.6.6.10.2" style="padding-left:2.0pt;padding-right:2.0pt;">
               -
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.7.6.6.6.10.3" style="padding-left:2.0pt;padding-right:2.0pt;">
               -
              </td>
              <td class="ltx_td" id="S4.SS1.SSS0.Px2.7.6.6.6.10.4" style="padding-left:2.0pt;padding-right:2.0pt;">
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.7.6.6.6.10.5" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS0.Px2.7.6.6.6.10.5.1">
                57.1
               </span>
              </td>
              <td class="ltx_td ltx_align_center" id="S4.SS1.SSS0.Px2.7.6.6.6.10.6" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS0.Px2.7.6.6.6.10.6.1">
                31.4
               </span>
              </td>
             </tr>
             <tr class="ltx_tr" id="S4.SS1.SSS0.Px2.7.6.6.6.6">
              <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.SSS0.Px2.7.6.6.6.6.3" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.SSS0.Px2.7.6.6.6.6.3.1">
                LEO
               </span>
              </td>
              <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.SSS0.Px2.7.6.6.6.6.4" style="padding-left:2.0pt;padding-right:2.0pt;">
               23.1
              </td>
              <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.SSS0.Px2.7.6.6.6.6.5" style="padding-left:2.0pt;padding-right:2.0pt;">
               <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS0.Px2.7.6.6.6.6.5.1">
                15.2
               </span>
              </td>
              <td class="ltx_td ltx_border_bb ltx_border_t" id="S4.SS1.SSS0.Px2.7.6.6.6.6.6" style="padding-left:2.0pt;padding-right:2.0pt;">
              </td>
              <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.SSS0.Px2.6.5.5.5.5.1" style="padding-left:2.0pt;padding-right:2.0pt;">
               23.1
               <sup class="ltx_sup" id="S4.SS1.SSS0.Px2.6.5.5.5.5.1.1">
                †
               </sup>
              </td>
              <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="S4.SS1.SSS0.Px2.7.6.6.6.6.2" style="padding-left:2.0pt;padding-right:2.0pt;">
               19.1
               <sup class="ltx_sup" id="S4.SS1.SSS0.Px2.7.6.6.6.6.2.1">
                †
               </sup>
              </td>
             </tr>
            </table>
           </span>
          </div>
         </div>
        </div>
       </figure>
      </div>
     </div>
    </figure>
   </section>
   <section class="ltx_paragraph" id="S4.SS1.SSS0.Px3">
    <h5 class="ltx_title ltx_title_paragraph">
     Results &amp; analysis.
    </h5>
    <div class="ltx_para ltx_noindent" id="S4.SS1.SSS0.Px3.p1">
     <p class="ltx_p" id="S4.SS1.SSS0.Px3.p1.1">
      As shown in
      <a class="ltx_ref" href="#S4.T2" title="In Baselines. ‣ 4.1 3D Vision-Language Understanding and Embodied Reasoning ‣ 4 Capabilities and Analyses ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Tab.
       </span>
       <span class="ltx_text ltx_ref_tag">
        2
       </span>
      </a>
      ,
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.SSS0.Px3.p1.1.1">
       LEO
      </span>
      surpasses state-of-the-art task-specific and task-specific fine-tuned models significantly on both 3D dense captioning and 3D QA tasks. In contrast to the specialist models that utilize task-specific heads, we demonstrate our LLM-based approach
      <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS0.Px3.p1.1.2">
       not only affords the flexibility of generating open-ended responses but also can achieve excellent scores in terms of standard metrics
      </span>
      . Notably, considering the difference between close-set classification (
      <em class="ltx_emph ltx_font_italic" id="S4.SS1.SSS0.Px3.p1.1.3">
       e.g
      </em>
      .
      <span class="ltx_text" id="S4.SS1.SSS0.Px3.p1.1.4">
      </span>
      , 3D-VisTA) and open-ended text generation, we refine the protocol of exact match (see details in
      <a class="ltx_ref" href="#A8.SS1" title="H.1 3D Question Answering ‣ Appendix H Evaluation Details ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Sec.
       </span>
       <span class="ltx_text ltx_ref_tag">
        H.1
       </span>
      </a>
      ). On the other hand, compared with the complicated 3D feature aggregation in 3D-LLM, we suggest that
      <span class="ltx_text ltx_font_bold" id="S4.SS1.SSS0.Px3.p1.1.5">
       object-centric 3D representation is a simple yet effective option to connect 3D scenes with LLM while harnessing the inherent knowledge of LLM
      </span>
      .
     </p>
    </div>
    <figure class="ltx_figure" id="S4.F3">
     <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="420" id="S4.F3.g1" src="/html/2311.12871/assets/x3.png" width="423"/>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_figure">
       Figure 3:
      </span>
      <span class="ltx_text ltx_font_bold" id="S4.F3.4.1">
       Qualitative results of interacting with
       <span class="ltx_text ltx_font_smallcaps" id="S4.F3.4.1.1">
        LEO
       </span>
      </span>
      on unseen scenarios from a held-out test set of
      <span class="ltx_text ltx_font_smallcaps" id="S4.F3.5.2">
       LEO
      </span>
      -instruct.
      <span class="ltx_text ltx_font_smallcaps" id="S4.F3.6.3">
       LEO
      </span>
      ’s responses and actions can be grounded in novel scenes.
     </figcaption>
    </figure>
   </section>
  </section>
  <section class="ltx_subsection" id="S4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.2
    </span>
    Chatting and planning about a 3D scene
   </h3>
   <section class="ltx_paragraph" id="S4.SS2.SSS0.Px1">
    <h5 class="ltx_title ltx_title_paragraph">
     Overview.
    </h5>
    <div class="ltx_para ltx_noindent" id="S4.SS2.SSS0.Px1.p1">
     <p class="ltx_p" id="S4.SS2.SSS0.Px1.p1.1">
      Upon the 3D VL understanding and reasoning, we anticipate
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px1.p1.1.1">
       LEO
      </span>
      to support more sophisticated and grounded interaction with human users,
      <em class="ltx_emph ltx_font_italic" id="S4.SS2.SSS0.Px1.p1.1.2">
       i.e
      </em>
      .
      <span class="ltx_text" id="S4.SS2.SSS0.Px1.p1.1.3">
      </span>
      , responding to complex multi-round user instructions in the 3D world. To verify these capabilities, we choose two tasks: 3D dialogue and scene-aware task planning. We provide qualitative examples of unseen scenarios from the held-out test sets of
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px1.p1.1.4">
       LEO
      </span>
      -instruct, highlighting
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px1.p1.1.5">
       LEO
      </span>
      ’s merits of instruction following and scene-grounded responses. We defer the quantitative results of dialogue and planning to our ablation study in
      <a class="ltx_ref" href="#S4.SS4" title="4.4 Ablative Study ‣ 4 Capabilities and Analyses ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Sec.
       </span>
       <span class="ltx_text ltx_ref_tag">
        4.4
       </span>
      </a>
      . Quantitative comparison with other approaches is infeasible due to the lack of a common benchmark.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S4.SS2.SSS0.Px2">
    <h5 class="ltx_title ltx_title_paragraph">
     Results &amp; analysis.
    </h5>
    <div class="ltx_para ltx_noindent" id="S4.SS2.SSS0.Px2.p1">
     <p class="ltx_p" id="S4.SS2.SSS0.Px2.p1.1">
      As shown in
      <a class="ltx_ref" href="#S4.F3" title="In Results &amp; analysis. ‣ 4.1 3D Vision-Language Understanding and Embodied Reasoning ‣ 4 Capabilities and Analyses ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Fig.
       </span>
       <span class="ltx_text ltx_ref_tag">
        3
       </span>
      </a>
      ,
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px2.p1.1.1">
       LEO
      </span>
      is capable of generating high-quality responses to complete the tasks of dialogue and planning. We highlight two features:
      <span class="ltx_text ltx_font_bold" id="S4.SS2.SSS0.Px2.p1.1.2">
       1) The responses of
       <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px2.p1.1.2.1">
        LEO
       </span>
       are precisely grounded to the 3D scenes.
      </span>
      In particular, the proposed plan by
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px2.p1.1.3">
       LEO
      </span>
      contains concrete objects that are present in the scenes, as well as concrete actions regarding these objects.
      <span class="ltx_text ltx_font_bold" id="S4.SS2.SSS0.Px2.p1.1.4">
       2) The responses of
       <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.SSS0.Px2.p1.1.4.1">
        LEO
       </span>
       incorporates rich informative spatial relations.
      </span>
      Such information is necessary to refer to specific objects in complex 3D scenes and affords considerable assistance for humans.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S4.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.3
    </span>
    Embodied Action in 3D World
   </h3>
   <section class="ltx_paragraph" id="S4.SS3.SSS0.Px1">
    <h5 class="ltx_title ltx_title_paragraph">
     Overview.
    </h5>
    <div class="ltx_para ltx_noindent" id="S4.SS3.SSS0.Px1.p1">
     <p class="ltx_p" id="S4.SS3.SSS0.Px1.p1.1">
      Finally, we hope to directly probe the embodied acting and interacting capacity of
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p1.1.1">
       LEO
      </span>
      in the 3D World. We select two canonical embodied AI tasks: embodied navigation with
      <span class="ltx_text ltx_font_typewriter" id="S4.SS3.SSS0.Px1.p1.1.2">
       ObjNav
      </span>
      on AI Habitat
      <cite class="ltx_cite ltx_citemacro_citep">
       (Ramrakhya et al.,
       <a class="ltx_ref" href="#bib.bib64" title="">
        2022
       </a>
       )
      </cite>
      and robotic manipulation on CLIPort
      <cite class="ltx_cite ltx_citemacro_citep">
       (Shridhar et al.,
       <a class="ltx_ref" href="#bib.bib72" title="">
        2021
       </a>
       )
      </cite>
      .
Specifically, for
      <span class="ltx_text ltx_font_typewriter" id="S4.SS3.SSS0.Px1.p1.1.3">
       ObjNav
      </span>
      , although
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p1.1.4">
       LEO
      </span>
      is trained on a customized dataset (see
      <a class="ltx_ref" href="#S3.SS2" title="3.2 LEO-instruct: Instruction Tuning for Tasks in the 3D world ‣ 3 Datasets ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Sec.
       </span>
       <span class="ltx_text ltx_ref_tag">
        3.2
       </span>
      </a>
      ), the scenes are all included in the original MP3D
      <span class="ltx_text ltx_font_typewriter" id="S4.SS3.SSS0.Px1.p1.1.5">
       ObjNav
      </span>
      training split
      <cite class="ltx_cite ltx_citemacro_citep">
       (Savva et al.,
       <a class="ltx_ref" href="#bib.bib68" title="">
        2019
       </a>
       )
      </cite>
      . Therefore, we still evaluate
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p1.1.6">
       LEO
      </span>
      on the original MP3D
      <span class="ltx_text ltx_font_typewriter" id="S4.SS3.SSS0.Px1.p1.1.7">
       ObjNav
      </span>
      validation split against baselines. Additionally, we test
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p1.1.8">
       LEO
      </span>
      on the validation split of the newly introduced HM3D
      <span class="ltx_text ltx_font_typewriter" id="S4.SS3.SSS0.Px1.p1.1.9">
       ObjNav
      </span>
      task
      <cite class="ltx_cite ltx_citemacro_citep">
       (Ramakrishnan et al.,
       <a class="ltx_ref" href="#bib.bib63" title="">
        2021
       </a>
       )
      </cite>
      . We report the success rate and SPL metrics following
      <cite class="ltx_cite ltx_citemacro_cite">
       Ramrakhya et al. (
       <a class="ltx_ref" href="#bib.bib64" title="">
        2022
       </a>
       )
      </cite>
      . For CLIPort robotic manipulation, we evaluate
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px1.p1.1.10">
       LEO
      </span>
      on the three training tasks listed in
      <a class="ltx_ref" href="#S4.T3" title="In Baselines. ‣ 4.1 3D Vision-Language Understanding and Embodied Reasoning ‣ 4 Capabilities and Analyses ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Tab.
       </span>
       <span class="ltx_text ltx_ref_tag">
        3
       </span>
      </a>
      and their corresponding unseen tasks and report the average reward across the evaluation episodes.
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S4.SS3.SSS0.Px2">
    <h5 class="ltx_title ltx_title_paragraph">
     Results &amp; analysis.
    </h5>
    <div class="ltx_para ltx_noindent" id="S4.SS3.SSS0.Px2.p1">
     <p class="ltx_p" id="S4.SS3.SSS0.Px2.p1.1">
      We present the results of CLIPort manipulation and object navigation in
      <a class="ltx_ref" href="#S4.T3" title="In Baselines. ‣ 4.1 3D Vision-Language Understanding and Embodied Reasoning ‣ 4 Capabilities and Analyses ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Tabs.
       </span>
       <span class="ltx_text ltx_ref_tag">
        3
       </span>
      </a>
      and
      <a class="ltx_ref" href="#S4.T4" title="Table 4 ‣ Baselines. ‣ 4.1 3D Vision-Language Understanding and Embodied Reasoning ‣ 4 Capabilities and Analyses ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        4
       </span>
      </a>
      . Our findings are as follows: 1) In robotic manipulation,
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px2.p1.1.1">
       LEO
      </span>
      exhibits comparable performances to many strong baselines and even achieves significantly better results on some challenging
      <span class="ltx_text" id="S4.SS3.SSS0.Px2.p1.1.2" style="color:#CC4054;">
       unseen
      </span>
      tasks. Note that compared to baselines that rely on heatmap output,
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px2.p1.1.3">
       LEO
      </span>
      produces motor commands directly. 2) On
      <span class="ltx_text ltx_font_typewriter" id="S4.SS3.SSS0.Px2.p1.1.4">
       ObjNav
      </span>
      ,
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px2.p1.1.5">
       LEO
      </span>
      attains a reasonable success rate and better SPL on MP3D-val compared with baselines, suggesting that
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px2.p1.1.6">
       LEO
      </span>
      can learn to leverage the object-centric 3D scene input (potentially offering a coarse global map) and take a shorter path to the target. Further, results on HM3D-val confirm
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px2.p1.1.7">
       LEO
      </span>
      ’s zero-shot generalization to novel scenes. Please note that all baselines use an RNN policy while
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px2.p1.1.8">
       LEO
      </span>
      can be viewed as a transformer-based feed-forward policy similar to RT-2
      <cite class="ltx_cite ltx_citemacro_citep">
       (Brohan et al.,
       <a class="ltx_ref" href="#bib.bib9" title="">
        2023
       </a>
       )
      </cite>
      considering the training efficiency, which could lead to a lower success rate. More discussions on this can be found in
      <a class="ltx_ref" href="#A8.SS2" title="H.2 Embodied Navigation ‣ Appendix H Evaluation Details ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Sec.
       </span>
       <span class="ltx_text ltx_ref_tag">
        H.2
       </span>
      </a>
      . 3) Overall, the align-then-instruct tuning scheme endows
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS3.SSS0.Px2.p1.1.9">
       LEO
      </span>
      with semantic-level generalization (novel objects,
      <em class="ltx_emph ltx_font_italic" id="S4.SS3.SSS0.Px2.p1.1.10">
       etc
      </em>
      .
      <span class="ltx_text" id="S4.SS3.SSS0.Px2.p1.1.11">
      </span>
      ) in both manipulation and navigation tasks (we provide results on
      <span class="ltx_text ltx_font_typewriter" id="S4.SS3.SSS0.Px2.p1.1.12">
       ObjNav
      </span>
      with
      <span class="ltx_text" id="S4.SS3.SSS0.Px2.p1.1.13" style="color:#CC4054;">
       unseen
      </span>
      objects in
      <a class="ltx_ref" href="#A9.SS1" title="I.1 Embodied Acting ‣ Appendix I Additional Results ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Sec.
       </span>
       <span class="ltx_text ltx_ref_tag">
        I.1
       </span>
      </a>
      ).
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S4.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.4
    </span>
    Ablative Study
   </h3>
   <section class="ltx_paragraph" id="S4.SS4.SSS0.Px1">
    <h5 class="ltx_title ltx_title_paragraph">
     Settings.
    </h5>
    <div class="ltx_para ltx_noindent" id="S4.SS4.SSS0.Px1.p1">
     <p class="ltx_p" id="S4.SS4.SSS0.Px1.p1.1">
      We ablate
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px1.p1.1.1">
       LEO
      </span>
      on different data configurations. Specifically, we compare
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px1.p1.1.2">
       LEO
      </span>
      ’s performance under the following settings: (1)
      <span class="ltx_text ltx_font_italic" id="S4.SS4.SSS0.Px1.p1.1.3">
       NoAlign
      </span>
      : tuning
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px1.p1.1.4">
       LEO
      </span>
      from scratch on
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px1.p1.1.5">
       LEO
      </span>
      -instruct, skipping pre-training on
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px1.p1.1.6">
       LEO
      </span>
      -align; (2)
      <span class="ltx_text ltx_font_italic" id="S4.SS4.SSS0.Px1.p1.1.7">
       PartialData
      </span>
      : uniformly sampling 10% of data in
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px1.p1.1.8">
       LEO
      </span>
      -instruct during instruction-tuning; (3)
      <span class="ltx_text ltx_font_italic" id="S4.SS4.SSS0.Px1.p1.1.9">
       ScanNetOnly
      </span>
      : excluding data generated by LLM and embodied tasks (
      <em class="ltx_emph ltx_font_italic" id="S4.SS4.SSS0.Px1.p1.1.10">
       i.e
      </em>
      .
      <span class="ltx_text" id="S4.SS4.SSS0.Px1.p1.1.11">
      </span>
      , navigation and manipulation) during instruction tuning; (4)
      <span class="ltx_text ltx_font_italic" id="S4.SS4.SSS0.Px1.p1.1.12">
       NoAct (VL)
      </span>
      : excluding embodied task data during instruction tuning. We provide additional results and findings in
      <a class="ltx_ref" href="#A7" title="Appendix G Ablation Details ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Appendix
       </span>
       <span class="ltx_text ltx_ref_tag">
        G
       </span>
      </a>
      .
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S4.SS4.SSS0.Px2">
    <h5 class="ltx_title ltx_title_paragraph">
     Evaluation.
    </h5>
    <div class="ltx_para ltx_noindent" id="S4.SS4.SSS0.Px2.p1">
     <p class="ltx_p" id="S4.SS4.SSS0.Px2.p1.1">
      We provide a more comprehensive quantitative evaluation of
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px2.p1.1.1">
       LEO
      </span>
      on all 3D VL tasks, including 3D object/scene captioning, 3D QA, scene-grounded dialogue and task planning.
Following prior works
      <cite class="ltx_cite ltx_citemacro_citep">
       (Achlioptas et al.,
       <a class="ltx_ref" href="#bib.bib1" title="">
        2020
       </a>
       )
      </cite>
      , we use ground-truth object proposals in our ablation to pinpoint the reasoning and planning capabilities of
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px2.p1.1.2">
       LEO
      </span>
      . We report exact match scores for QA tasks and SentenceSim for all other tasks.
      <a class="ltx_ref" href="#S4.F4" title="In Evaluation. ‣ 4.4 Ablative Study ‣ 4 Capabilities and Analyses ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Fig.
       </span>
       <span class="ltx_text ltx_ref_tag">
        4
       </span>
      </a>
      shows a holistic view of the results.
     </p>
    </div>
    <figure class="ltx_figure" id="S4.F4">
     <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="122" id="S4.F4.g1" src="/html/2311.12871/assets/x4.png" width="422"/>
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_figure">
       Figure 4:
      </span>
      (a) Comparison of
      <span class="ltx_text ltx_font_smallcaps" id="S4.F4.4.1">
       LEO
      </span>
      trained under different data configurations. We test models on the validation set of Scan2Cap and ScanQA, and the held-out test sets of other datasets. * indicates datasets that belong to
      <span class="ltx_text ltx_font_smallcaps" id="S4.F4.5.2">
       LEO
      </span>
      -align. The color-gradient bar of
      <span class="ltx_text ltx_font_italic" id="S4.F4.6.3">
       ScanNetOnly
      </span>
      on 3RQA, 3RPlan and 3RDialog indicates zero-shot transfer. Refer to
      <a class="ltx_ref" href="#A7" title="Appendix G Ablation Details ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Appendix
       </span>
       <span class="ltx_text ltx_ref_tag">
        G
       </span>
      </a>
      for numerical results. (b) Instruction-tuning losses on the test set, with the growth of data and model scale. These results echo the scaling law introduced in
      <cite class="ltx_cite ltx_citemacro_cite">
       Kaplan et al. (
       <a class="ltx_ref" href="#bib.bib35" title="">
        2020
       </a>
       ); Reed et al. (
       <a class="ltx_ref" href="#bib.bib65" title="">
        2022
       </a>
       )
      </cite>
      .
     </figcaption>
    </figure>
   </section>
   <section class="ltx_paragraph" id="S4.SS4.SSS0.Px3">
    <h5 class="ltx_title ltx_title_paragraph">
     Results &amp; analysis.
    </h5>
    <div class="ltx_para ltx_noindent" id="S4.SS4.SSS0.Px3.p1">
     <p class="ltx_p" id="S4.SS4.SSS0.Px3.p1.1">
      <span class="ltx_text ltx_font_bold" id="S4.SS4.SSS0.Px3.p1.1.1">
       1) The two-stage align-then-instruct pipeline is critical for
       <span class="ltx_text ltx_font_smallcaps" id="S4.SS4.SSS0.Px3.p1.1.1.1">
        LEO
       </span>
       learning.
      </span>
      The lack of alignment harms detailed understanding of scenes, while the decrease in instruction-tuning data affects reasoning and planning.
      <span class="ltx_text ltx_font_bold" id="S4.SS4.SSS0.Px3.p1.1.2">
       2) Compositional generalization poses considerable challenges.
      </span>
      <span class="ltx_text ltx_font_italic" id="S4.SS4.SSS0.Px3.p1.1.3">
       ScanNetOnly
      </span>
      , having been exposed to 3RScan scenes or QA skills during the two stages respectively, still struggles to handle the QA task in 3RScan scenes (3RQA).
      <span class="ltx_text ltx_font_bold" id="S4.SS4.SSS0.Px3.p1.1.4">
       3) General vs. specific.
      </span>
      We observe model performance drops on in-domain tasks (
      <em class="ltx_emph ltx_font_italic" id="S4.SS4.SSS0.Px3.p1.1.5">
       e.g
      </em>
      .
      <span class="ltx_text" id="S4.SS4.SSS0.Px3.p1.1.6">
      </span>
      , Scan2Cap) when adding data from other domains or new tasks (
      <span class="ltx_text ltx_font_italic" id="S4.SS4.SSS0.Px3.p1.1.7">
       ScanNetOnly
      </span>
      <em class="ltx_emph ltx_font_italic" id="S4.SS4.SSS0.Px3.p1.1.8">
       vs
      </em>
      .
      <span class="ltx_text" id="S4.SS4.SSS0.Px3.p1.1.9">
      </span>
      <span class="ltx_text ltx_font_italic" id="S4.SS4.SSS0.Px3.p1.1.10">
       NoAct (VL)
      </span>
      ). Scaling up the instruction-tuning data brings significant improvements, though the embodied acting data counteracts such effects due to the domain gap (
      <span class="ltx_text ltx_font_italic" id="S4.SS4.SSS0.Px3.p1.1.11">
       PartialData
      </span>
      <em class="ltx_emph ltx_font_italic" id="S4.SS4.SSS0.Px3.p1.1.12">
       vs
      </em>
      .
      <span class="ltx_text" id="S4.SS4.SSS0.Px3.p1.1.13">
      </span>
      <span class="ltx_text ltx_font_italic" id="S4.SS4.SSS0.Px3.p1.1.14">
       Full (VLA)
      </span>
      <em class="ltx_emph ltx_font_italic" id="S4.SS4.SSS0.Px3.p1.1.15">
       vs
      </em>
      .
      <span class="ltx_text" id="S4.SS4.SSS0.Px3.p1.1.16">
      </span>
      <span class="ltx_text ltx_font_italic" id="S4.SS4.SSS0.Px3.p1.1.17">
       NoAct (VL)
      </span>
      ).
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="S4.SS5">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     4.5
    </span>
    Scaling Law Analysis
   </h3>
   <section class="ltx_paragraph" id="S4.SS5.SSS0.Px1">
    <h5 class="ltx_title ltx_title_paragraph">
     Settings.
    </h5>
    <div class="ltx_para ltx_noindent" id="S4.SS5.SSS0.Px1.p1">
     <p class="ltx_p" id="S4.SS5.SSS0.Px1.p1.1">
      Following the analysis in
      <a class="ltx_ref" href="#S4.SS4" title="4.4 Ablative Study ‣ 4 Capabilities and Analyses ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Sec.
       </span>
       <span class="ltx_text ltx_ref_tag">
        4.4
       </span>
      </a>
      , we study the scaling effect
      <cite class="ltx_cite ltx_citemacro_citep">
       (Kaplan et al.,
       <a class="ltx_ref" href="#bib.bib35" title="">
        2020
       </a>
       ; Reed et al.,
       <a class="ltx_ref" href="#bib.bib65" title="">
        2022
       </a>
       )
      </cite>
      of data and model in
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS5.SSS0.Px1.p1.1.1">
       LEO
      </span>
      . We use the instruction-tuning loss (on the test set) of
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS5.SSS0.Px1.p1.1.2">
       LEO
      </span>
      with the growth of data and model scale as an indicator. Based on
      <span class="ltx_text ltx_font_italic" id="S4.SS5.SSS0.Px1.p1.1.3">
       NoAct (VL)
      </span>
      with Vicuna-7B (referred to as
      <span class="ltx_text ltx_font_italic" id="S4.SS5.SSS0.Px1.p1.1.4">
       Vicuna-7B Aligned
      </span>
      ), we add two variants: (1)
      <span class="ltx_text ltx_font_italic" id="S4.SS5.SSS0.Px1.p1.1.5">
       Vicuna-7B Scratch
      </span>
      , trained without the alignment stage; and (2)
      <span class="ltx_text ltx_font_italic" id="S4.SS5.SSS0.Px1.p1.1.6">
       Vicuna-13B Scratch
      </span>
      , trained without the alignment stage and scaling up the LLM to 13B. The curves of test loss are visualized in
      <a class="ltx_ref" href="#S4.F4" title="In Evaluation. ‣ 4.4 Ablative Study ‣ 4 Capabilities and Analyses ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Fig.
       </span>
       <span class="ltx_text ltx_ref_tag">
        4
       </span>
      </a>
      (b).
     </p>
    </div>
   </section>
   <section class="ltx_paragraph" id="S4.SS5.SSS0.Px2">
    <h5 class="ltx_title ltx_title_paragraph">
     Results &amp; analysis.
    </h5>
    <div class="ltx_para ltx_noindent" id="S4.SS5.SSS0.Px2.p1">
     <p class="ltx_p" id="S4.SS5.SSS0.Px2.p1.1">
      <span class="ltx_text ltx_font_bold" id="S4.SS5.SSS0.Px2.p1.1.1">
       1) The instruction tuning of
       <span class="ltx_text ltx_font_smallcaps" id="S4.SS5.SSS0.Px2.p1.1.1.1">
        LEO
       </span>
       conforms to the scaling law
      </span>
      <cite class="ltx_cite ltx_citemacro_citep">
       (Kaplan et al.,
       <a class="ltx_ref" href="#bib.bib35" title="">
        2020
       </a>
       ; Reed et al.,
       <a class="ltx_ref" href="#bib.bib65" title="">
        2022
       </a>
       )
      </cite>
      . For all three settings, we find the test loss of
      <span class="ltx_text ltx_font_smallcaps" id="S4.SS5.SSS0.Px2.p1.1.2">
       LEO
      </span>
      decreases log-linearly as it is fed with more data.
      <span class="ltx_text ltx_font_bold" id="S4.SS5.SSS0.Px2.p1.1.3">
       2) The lack of alignment causes significantly higher loss.
      </span>
      <span class="ltx_text ltx_font_italic" id="S4.SS5.SSS0.Px2.p1.1.4">
       Vicuna-7B Scratch
      </span>
      shows consistently higher loss than
      <span class="ltx_text ltx_font_italic" id="S4.SS5.SSS0.Px2.p1.1.5">
       Vicuna-7B Aligned
      </span>
      . This corresponds to the inferior performances of
      <span class="ltx_text ltx_font_italic" id="S4.SS5.SSS0.Px2.p1.1.6">
       NoAlign
      </span>
      in
      <a class="ltx_ref" href="#S4.SS4" title="4.4 Ablative Study ‣ 4 Capabilities and Analyses ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Sec.
       </span>
       <span class="ltx_text ltx_ref_tag">
        4.4
       </span>
      </a>
      and emphasizes the importance of alignment.
      <span class="ltx_text ltx_font_bold" id="S4.SS5.SSS0.Px2.p1.1.7">
       3) Scaling up LLM leads to degradation.
      </span>
      <span class="ltx_text ltx_font_italic" id="S4.SS5.SSS0.Px2.p1.1.8">
       Vicuna-13B Scratch
      </span>
      shows consistently higher loss than
      <span class="ltx_text ltx_font_italic" id="S4.SS5.SSS0.Px2.p1.1.9">
       Vicuna-7B Scratch
      </span>
      , which echos previous findings
      <cite class="ltx_cite ltx_citemacro_citep">
       (Dai et al.,
       <a class="ltx_ref" href="#bib.bib21" title="">
        2023
       </a>
       ; Xu et al.,
       <a class="ltx_ref" href="#bib.bib85" title="">
        2023
       </a>
       )
      </cite>
      . We conjecture there are two possible reasons: multi-modal instruction tuning data is insufficient to reveal the benefit of scaling up LLMs, or a small-scale LLM (
      <em class="ltx_emph ltx_font_italic" id="S4.SS5.SSS0.Px2.p1.1.10">
       e.g
      </em>
      .
      <span class="ltx_text" id="S4.SS5.SSS0.Px2.p1.1.11">
      </span>
      , Vicuna-7B) already suffices for connecting the visual modality.
     </p>
    </div>
   </section>
  </section>
 </section>
 <section class="ltx_section" id="S5">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    5
   </span>
   Related Work
  </h2>
  <section class="ltx_paragraph" id="S5.SS0.SSS0.Px1">
   <h5 class="ltx_title ltx_title_paragraph">
    Generalist agents.
   </h5>
   <div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px1.p1">
    <p class="ltx_p" id="S5.SS0.SSS0.Px1.p1.1">
     The AI community has witnessed the rising generalist models in both vision
     <cite class="ltx_cite ltx_citemacro_citep">
      (Lu et al.,
      <a class="ltx_ref" href="#bib.bib49" title="">
       2023
      </a>
      ; Wang et al.,
      <a class="ltx_ref" href="#bib.bib79" title="">
       2023b
      </a>
      ; Kirillov et al.,
      <a class="ltx_ref" href="#bib.bib37" title="">
       2023
      </a>
      )
     </cite>
     and language
     <cite class="ltx_cite ltx_citemacro_citep">
      (OpenAI,
      <a class="ltx_ref" href="#bib.bib55" title="">
       2022
      </a>
      ;
      <a class="ltx_ref" href="#bib.bib56" title="">
       2023
      </a>
      )
     </cite>
     domains. A generalist agent requires additional embodiment knowledge to interact with the environment and complete embodied acting tasks. Existing efforts towards generalist agents include: grounded reasoning and task planning in the real world
     <cite class="ltx_cite ltx_citemacro_citep">
      (Ahn et al.,
      <a class="ltx_ref" href="#bib.bib2" title="">
       2022
      </a>
      ; Huang et al.,
      <a class="ltx_ref" href="#bib.bib33" title="">
       2022b
      </a>
      )
     </cite>
     , skill generalization in open-world environment
     <cite class="ltx_cite ltx_citemacro_citep">
      (Fan et al.,
      <a class="ltx_ref" href="#bib.bib24" title="">
       2022
      </a>
      ; Cai et al.,
      <a class="ltx_ref" href="#bib.bib12" title="">
       2023a
      </a>
      ; Wang et al.,
      <a class="ltx_ref" href="#bib.bib82" title="">
       2023e
      </a>
      ;
      <a class="ltx_ref" href="#bib.bib78" title="">
       a
      </a>
      ; Cai et al.,
      <a class="ltx_ref" href="#bib.bib13" title="">
       2023b
      </a>
      ; Gong et al.,
      <a class="ltx_ref" href="#bib.bib27" title="">
       2023b
      </a>
      )
     </cite>
     , general robotic manipulation
     <cite class="ltx_cite ltx_citemacro_citep">
      (Brohan et al.,
      <a class="ltx_ref" href="#bib.bib8" title="">
       2022
      </a>
      ; Jiang et al.,
      <a class="ltx_ref" href="#bib.bib34" title="">
       2023
      </a>
      ; Gong et al.,
      <a class="ltx_ref" href="#bib.bib26" title="">
       2023a
      </a>
      )
     </cite>
     , and unified vision-language-action (VLA) models such as Gato
     <cite class="ltx_cite ltx_citemacro_citep">
      (Reed et al.,
      <a class="ltx_ref" href="#bib.bib65" title="">
       2022
      </a>
      )
     </cite>
     , PaLM-E
     <cite class="ltx_cite ltx_citemacro_citep">
      (Driess et al.,
      <a class="ltx_ref" href="#bib.bib23" title="">
       2023
      </a>
      )
     </cite>
     , EmbodiedGPT
     <cite class="ltx_cite ltx_citemacro_citep">
      (Mu et al.,
      <a class="ltx_ref" href="#bib.bib54" title="">
       2023
      </a>
      )
     </cite>
     , and RT-2
     <cite class="ltx_cite ltx_citemacro_citep">
      (Brohan et al.,
      <a class="ltx_ref" href="#bib.bib9" title="">
       2023
      </a>
      )
     </cite>
     .
     <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px1.p1.1.1">
      LEO
     </span>
     belongs to the
     <abbr class="ltx_glossaryref" title="vision-language-action">
      <span class="ltx_text ltx_glossary_short">
       VLA
      </span>
     </abbr>
     model, however, its goal is to build a generalist agent that can understand the real 3D world beyond 2D images, which is absent in existing works.
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S5.SS0.SSS0.Px2">
   <h5 class="ltx_title ltx_title_paragraph">
    Multi-modal instruction tuning.
   </h5>
   <div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px2.p1">
    <p class="ltx_p" id="S5.SS0.SSS0.Px2.p1.1">
     Pre-trained LLMs demonstrated practical for solving vision-language tasks
     <cite class="ltx_cite ltx_citemacro_citep">
      (Tsimpoukelli et al.,
      <a class="ltx_ref" href="#bib.bib75" title="">
       2021
      </a>
      ; Alayrac et al.,
      <a class="ltx_ref" href="#bib.bib3" title="">
       2022
      </a>
      ; Guo et al.,
      <a class="ltx_ref" href="#bib.bib29" title="">
       2023
      </a>
      ; Li et al.,
      <a class="ltx_ref" href="#bib.bib45" title="">
       2023d
      </a>
      ; Zhao et al.,
      <a class="ltx_ref" href="#bib.bib89" title="">
       2023
      </a>
      )
     </cite>
     . Meanwhile, the instruction-tuning paradigm exhibited strong zero-shot generalization in NLP tasks
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wei et al.,
      <a class="ltx_ref" href="#bib.bib83" title="">
       2022
      </a>
      ; Sanh et al.,
      <a class="ltx_ref" href="#bib.bib67" title="">
       2022
      </a>
      ; Ouyang et al.,
      <a class="ltx_ref" href="#bib.bib57" title="">
       2022
      </a>
      ; Chung et al.,
      <a class="ltx_ref" href="#bib.bib19" title="">
       2022
      </a>
      )
     </cite>
     . The two streams merged into instruction-tuned LVLMs
     <cite class="ltx_cite ltx_citemacro_citep">
      (Liu et al.,
      <a class="ltx_ref" href="#bib.bib47" title="">
       2023b
      </a>
      ; Zhu et al.,
      <a class="ltx_ref" href="#bib.bib92" title="">
       2023b
      </a>
      ; Ye et al.,
      <a class="ltx_ref" href="#bib.bib86" title="">
       2023
      </a>
      ; Gao et al.,
      <a class="ltx_ref" href="#bib.bib25" title="">
       2023
      </a>
      ; Li et al.,
      <a class="ltx_ref" href="#bib.bib43" title="">
       2023b
      </a>
      ; Gong et al.,
      <a class="ltx_ref" href="#bib.bib28" title="">
       2023c
      </a>
      ; Dai et al.,
      <a class="ltx_ref" href="#bib.bib21" title="">
       2023
      </a>
      )
     </cite>
     . Despite the burst, these models are confined to 2D visual modalities,
     <em class="ltx_emph ltx_font_italic" id="S5.SS0.SSS0.Px2.p1.1.1">
      e.g
     </em>
     .
     <span class="ltx_text" id="S5.SS0.SSS0.Px2.p1.1.2">
     </span>
     , image or video. Concurrent works
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yin et al.,
      <a class="ltx_ref" href="#bib.bib87" title="">
       2023
      </a>
      ; Hong et al.,
      <a class="ltx_ref" href="#bib.bib30" title="">
       2023
      </a>
      ; Wang et al.,
      <a class="ltx_ref" href="#bib.bib81" title="">
       2023d
      </a>
      ; Xu et al.,
      <a class="ltx_ref" href="#bib.bib85" title="">
       2023
      </a>
      )
     </cite>
     extend to 3D vision tasks, but these models either lack the acting capability or unified efficient architecture.
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S5.SS0.SSS0.Px3">
   <h5 class="ltx_title ltx_title_paragraph">
    Grounded 3D scene understanding.
   </h5>
   <div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px3.p1">
    <p class="ltx_p" id="S5.SS0.SSS0.Px3.p1.1">
     One key obstacle to building
     <span class="ltx_text ltx_font_smallcaps" id="S5.SS0.SSS0.Px3.p1.1.1">
      LEO
     </span>
     is grounding the 3D world with natural languages. There exist diverse methods of grounded scene understanding,
     <em class="ltx_emph ltx_font_italic" id="S5.SS0.SSS0.Px3.p1.1.2">
      e.g
     </em>
     .
     <span class="ltx_text" id="S5.SS0.SSS0.Px3.p1.1.3">
     </span>
     , spatial relation modeling
     <cite class="ltx_cite ltx_citemacro_citep">
      (Zhao et al.,
      <a class="ltx_ref" href="#bib.bib90" title="">
       2021
      </a>
      ; Chen et al.,
      <a class="ltx_ref" href="#bib.bib15" title="">
       2022
      </a>
      ; Zhu et al.,
      <a class="ltx_ref" href="#bib.bib94" title="">
       2023c
      </a>
      )
     </cite>
     and fine-grained open-scene understanding
     <cite class="ltx_cite ltx_citemacro_citep">
      (Peng et al.,
      <a class="ltx_ref" href="#bib.bib59" title="">
       2023b
      </a>
      ; Kerr et al.,
      <a class="ltx_ref" href="#bib.bib36" title="">
       2023
      </a>
      )
     </cite>
     . However, due to data scarcity, how to utilize
     <abbr class="ltx_glossaryref" title="large language models">
      <span class="ltx_text ltx_glossary_short">
       LLMs
      </span>
     </abbr>
     to ground the 3D scene is rarely explored. Recently, 3D-LLM
     <cite class="ltx_cite ltx_citemacro_citep">
      (Hong et al.,
      <a class="ltx_ref" href="#bib.bib30" title="">
       2023
      </a>
      )
     </cite>
     leverages multi-view images and Chat-3D
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wang et al.,
      <a class="ltx_ref" href="#bib.bib81" title="">
       2023d
      </a>
      )
     </cite>
     uses object-centric point clouds to enable the
     <abbr class="ltx_glossaryref" title="large language models">
      <span class="ltx_text ltx_glossary_short">
       LLMs
      </span>
     </abbr>
     with 3D grounding. In this work, we devise both 2D and 3D encoders for grounding various visual representations and employ LoRA
     <cite class="ltx_cite ltx_citemacro_citep">
      (Hu et al.,
      <a class="ltx_ref" href="#bib.bib31" title="">
       2022
      </a>
      )
     </cite>
     to efficiently fine-tune the
     <abbr class="ltx_glossaryref" title="large language models">
      <span class="ltx_text ltx_glossary_short">
       LLMs
      </span>
     </abbr>
     .
    </p>
   </div>
  </section>
  <section class="ltx_paragraph" id="S5.SS0.SSS0.Px4">
   <h5 class="ltx_title ltx_title_paragraph">
    3D data prompting from LLMs.
   </h5>
   <div class="ltx_para ltx_noindent" id="S5.SS0.SSS0.Px4.p1">
    <p class="ltx_p" id="S5.SS0.SSS0.Px4.p1.1">
     LLMs exhibit extraordinary capabilities of text generation and serve as a source for collecting diverse instruction-following data
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wang et al.,
      <a class="ltx_ref" href="#bib.bib80" title="">
       2023c
      </a>
      ; Taori et al.,
      <a class="ltx_ref" href="#bib.bib74" title="">
       2023
      </a>
      ; Peng et al.,
      <a class="ltx_ref" href="#bib.bib58" title="">
       2023a
      </a>
      )
     </cite>
     . However, the lack of access to visual modalities makes it troublesome to collect visual instruction-tuning data. To address this issue, existing methods provide bounding boxes
     <cite class="ltx_cite ltx_citemacro_citep">
      (Liu et al.,
      <a class="ltx_ref" href="#bib.bib47" title="">
       2023b
      </a>
      )
     </cite>
     and add dense captions
     <cite class="ltx_cite ltx_citemacro_citep">
      (Li et al.,
      <a class="ltx_ref" href="#bib.bib42" title="">
       2023a
      </a>
      ; Liu et al.,
      <a class="ltx_ref" href="#bib.bib46" title="">
       2023a
      </a>
      )
     </cite>
     as image descriptions or directly use off-the-shelf
     <span class="ltx_glossaryref" title="large vision-language models">
      <span class="ltx_text ltx_glossary_long">
       large vision-language models
      </span>
     </span>
     (
     <abbr class="ltx_glossaryref" title="large vision-language models">
      <span class="ltx_text ltx_glossary_short">
       LVLM
      </span>
     </abbr>
     )
     <cite class="ltx_cite ltx_citemacro_citep">
      (Zhu et al.,
      <a class="ltx_ref" href="#bib.bib91" title="">
       2023a
      </a>
      ; Luo et al.,
      <a class="ltx_ref" href="#bib.bib50" title="">
       2023
      </a>
      )
     </cite>
     to help collect such data. Unlike concurrent attempts
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yin et al.,
      <a class="ltx_ref" href="#bib.bib87" title="">
       2023
      </a>
      ; Hong et al.,
      <a class="ltx_ref" href="#bib.bib30" title="">
       2023
      </a>
      ; Wang et al.,
      <a class="ltx_ref" href="#bib.bib81" title="">
       2023d
      </a>
      )
     </cite>
     in collecting 3D instruction-tuning data, our approach features a scene-graph-based prompting and refinement method to prompt and correct the data.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_section" id="S6">
  <h2 class="ltx_title ltx_title_section">
   <span class="ltx_tag ltx_tag_section">
    6
   </span>
   Conclusions
  </h2>
  <div class="ltx_para ltx_noindent" id="S6.p1">
   <p class="ltx_p" id="S6.p1.1">
    The proposed agent
    <span class="ltx_text ltx_font_smallcaps" id="S6.p1.1.1">
     LEO
    </span>
    extends the current generalist ability of
    <abbr class="ltx_glossaryref" title="large language models">
     <span class="ltx_text ltx_glossary_short">
      LLMs
     </span>
    </abbr>
    from text towards the 3D world and embodied tasks. It is a crucial initial step toward building embodied generalist agents. In light of this work, we identify several promising directions that hold the potential for substantial advancement: (1) enhancing the 3D vision-language grounding capability by leveraging larger-scale paired data from richer real-world 3D domains; (2) continually bridging the gap between 3D vision-language and embodied action, as our experiments reveal the feasibility of their joint learning; (3) investigating the issues of safety and alignment in the context of embodied generalist agents, particularly given that our scaling law analysis suggests that such agents can experience significant enhancements through data scaling in the near future.
   </p>
  </div>
  <div class="ltx_pagination ltx_role_newpage">
  </div>
 </section>
 <section class="ltx_bibliography" id="bib">
  <h2 class="ltx_title ltx_title_bibliography">
   References
  </h2>
  <ul class="ltx_biblist">
   <li class="ltx_bibitem" id="bib.bib1">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Achlioptas et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Panos Achlioptas, Ahmed Abdelreheem, Fei Xia, Mohamed Elhoseiny, and Leonidas
Guibas.
    </span>
    <span class="ltx_bibblock">
     Referit3d: Neural listeners for fine-grained 3d object identification
in real-world scenes.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">
      European Conference on Computer Vision (ECCV)
     </em>
     , 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib2">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ahn et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Michael Ahn, Anthony Brohan, Noah Brown, Yevgen Chebotar, Omar Cortes, Byron
David, Chelsea Finn, Chuyuan Fu, Keerthana Gopalakrishnan, Karol Hausman,
et al.
    </span>
    <span class="ltx_bibblock">
     Do as i can, not as i say: Grounding language in robotic affordances.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">
      arXiv preprint arXiv:2204.01691
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib3">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Alayrac et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Jean-Baptiste Alayrac, Jeff Donahue, Pauline Luc, Antoine Miech, Iain Barr,
Yana Hasson, Karel Lenc, Arthur Mensch, Katherine Millican, Malcolm Reynolds,
et al.
    </span>
    <span class="ltx_bibblock">
     Flamingo: a visual language model for few-shot learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">
      Advances in Neural Information Processing Systems (NeurIPS)
     </em>
     ,
2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib4">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Antol et al. (2015)
    </span>
    <span class="ltx_bibblock">
     Stanislaw Antol, Aishwarya Agrawal, Jiasen Lu, Margaret Mitchell, Dhruv Batra,
C Lawrence Zitnick, and Devi Parikh.
    </span>
    <span class="ltx_bibblock">
     Vqa: Visual question answering.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">
      International Conference on Computer Vision (ICCV)
     </em>
     , 2015.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib5">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Azuma et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Daichi Azuma, Taiki Miyanishi, Shuhei Kurita, and Motoaki Kawanabe.
    </span>
    <span class="ltx_bibblock">
     Scanqa: 3d question answering for spatial scene understanding.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">
      Conference on Computer Vision and Pattern Recognition
(CVPR)
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib6">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Yejin Bang, Samuel Cahyawijaya, Nayeon Lee, Wenliang Dai, Dan Su, Bryan Wilie,
Holy Lovenia, Ziwei Ji, Tiezheng Yu, Willy Chung, et al.
    </span>
    <span class="ltx_bibblock">
     A multitask, multilingual, multimodal evaluation of chatgpt on
reasoning, hallucination, and interactivity.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">
      arXiv preprint arXiv:2302.04023
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib7">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Bommasani et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney
von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma
Brunskill, et al.
    </span>
    <span class="ltx_bibblock">
     On the opportunities and risks of foundation models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">
      arXiv preprint arXiv:2108.07258
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib8">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Brohan et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Joseph Dabis,
Chelsea Finn, Keerthana Gopalakrishnan, Karol Hausman, Alex Herzog, Jasmine
Hsu, et al.
    </span>
    <span class="ltx_bibblock">
     Rt-1: Robotics transformer for real-world control at scale.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">
      arXiv preprint arXiv:2212.06817
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib9">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Brohan et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Anthony Brohan, Noah Brown, Justice Carbajal, Yevgen Chebotar, Xi Chen,
Krzysztof Choromanski, Tianli Ding, Danny Driess, Avinava Dubey, Chelsea
Finn, et al.
    </span>
    <span class="ltx_bibblock">
     Rt-2: Vision-language-action models transfer web knowledge to robotic
control.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">
      arXiv preprint arXiv:2307.15818
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib10">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Brown et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla
Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell,
et al.
    </span>
    <span class="ltx_bibblock">
     Language models are few-shot learners.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">
      Advances in Neural Information Processing Systems
(NeurIPS)
     </em>
     , 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib11">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Cai et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Daigang Cai, Lichen Zhao, Jing Zhang, Lu Sheng, and Dong Xu.
    </span>
    <span class="ltx_bibblock">
     3djcg: A unified framework for joint dense captioning and visual
grounding on 3d point clouds.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">
      Conference on Computer Vision and Pattern Recognition
(CVPR)
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib12">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Cai et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Shaofei Cai, Zihao Wang, Xiaojian Ma, Anji Liu, and Yitao Liang.
    </span>
    <span class="ltx_bibblock">
     Open-world multi-task control through goal-aware representation
learning and adaptive horizon prediction.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">
      Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition
     </em>
     , pp.  13734–13744, 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib13">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Cai et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Shaofei Cai, Bowei Zhang, Zihao Wang, Xiaojian Ma, Anji Liu, and Yitao Liang.
    </span>
    <span class="ltx_bibblock">
     Groot: Learning to follow instructions by watching gameplay videos.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">
      arXiv preprint arXiv:2310.08235
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib14">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Dave Zhenyu Chen, Angel X Chang, and Matthias Nießner.
    </span>
    <span class="ltx_bibblock">
     Scanrefer: 3d object localization in rgb-d scans using natural
language.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">
      European Conference on Computer Vision (ECCV)
     </em>
     , 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib15">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Shizhe Chen, Pierre-Louis Guhur, Makarand Tapaswi, Cordelia Schmid, and Ivan
Laptev.
    </span>
    <span class="ltx_bibblock">
     Language conditioned spatial relation reasoning for 3d object
grounding.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">
      Advances in Neural Information Processing Systems (NeurIPS)
     </em>
     ,
2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib16">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Sijin Chen, Hongyuan Zhu, Xin Chen, Yinjie Lei, Gang Yu, and Tao Chen.
    </span>
    <span class="ltx_bibblock">
     End-to-end 3d dense captioning with vote2cap-detr.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">
      Conference on Computer Vision and Pattern Recognition
(CVPR)
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib17">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chen et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Zhenyu Chen, Ali Gholami, Matthias Nießner, and Angel X Chang.
    </span>
    <span class="ltx_bibblock">
     Scan2cap: Context-aware dense captioning in rgb-d scans.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">
      Conference on Computer Vision and Pattern Recognition
(CVPR)
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib18">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chiang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Wei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin
Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E. Gonzalez, Ion Stoica, and
Eric P. Xing.
    </span>
    <span class="ltx_bibblock">
     Vicuna: An open-source chatbot impressing gpt-4 with 90%* chatgpt
quality, 2023.
    </span>
    <span class="ltx_bibblock">
     URL
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://lmsys.org/blog/2023-03-30-vicuna/" target="_blank" title="">
      https://lmsys.org/blog/2023-03-30-vicuna/
     </a>
     .
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib19">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Chung et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus,
Eric Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al.
    </span>
    <span class="ltx_bibblock">
     Scaling instruction-finetuned language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">
      arXiv preprint arXiv:2210.11416
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib20">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dai et al. (2017)
    </span>
    <span class="ltx_bibblock">
     Angela Dai, Angel X Chang, Manolis Savva, Maciej Halber, Thomas Funkhouser, and
Matthias Nießner.
    </span>
    <span class="ltx_bibblock">
     Scannet: Richly-annotated 3d reconstructions of indoor scenes.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">
      Conference on Computer Vision and Pattern Recognition
(CVPR)
     </em>
     , 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib21">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Dai et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Wenliang Dai, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Junqi Zhao,
Weisheng Wang, Boyang Li, Pascale Fung, and Steven Hoi.
    </span>
    <span class="ltx_bibblock">
     Instructblip: Towards general-purpose vision-language models with
instruction tuning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">
      arXiv preprint arXiv:2305.06500
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib22">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Deitke et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Matt Deitke, Dustin Schwenk, Jordi Salvador, Luca Weihs, Oscar Michel, Eli
VanderBilt, Ludwig Schmidt, Kiana Ehsani, Aniruddha Kembhavi, and Ali
Farhadi.
    </span>
    <span class="ltx_bibblock">
     Objaverse: A universe of annotated 3d objects.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">
      Conference on Computer Vision and Pattern Recognition
(CVPR)
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib23">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Driess et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Danny Driess, Fei Xia, Mehdi SM Sajjadi, Corey Lynch, Aakanksha Chowdhery,
Brian Ichter, Ayzaan Wahid, Jonathan Tompson, Quan Vuong, Tianhe Yu, et al.
    </span>
    <span class="ltx_bibblock">
     Palm-e: An embodied multimodal language model.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">
      International Conference on Machine Learning (ICML)
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib24">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Fan et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Linxi Fan, Guanzhi Wang, Yunfan Jiang, Ajay Mandlekar, Yuncong Yang, Haoyi Zhu,
Andrew Tang, De-An Huang, Yuke Zhu, and Anima Anandkumar.
    </span>
    <span class="ltx_bibblock">
     Minedojo: Building open-ended embodied agents with internet-scale
knowledge.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">
      Advances in Neural Information Processing Systems (NeurIPS)
     </em>
     ,
2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib25">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gao et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Peng Gao, Jiaming Han, Renrui Zhang, Ziyi Lin, Shijie Geng, Aojun Zhou, Wei
Zhang, Pan Lu, Conghui He, Xiangyu Yue, et al.
    </span>
    <span class="ltx_bibblock">
     Llama-adapter v2: Parameter-efficient visual instruction model.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">
      arXiv preprint arXiv:2304.15010
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib26">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gong et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Ran Gong, Jiangyong Huang, Yizhou Zhao, Haoran Geng, Xiaofeng Gao, Qingyang Wu,
Wensi Ai, Ziheng Zhou, Demetri Terzopoulos, Song-Chun Zhu, et al.
    </span>
    <span class="ltx_bibblock">
     Arnold: A benchmark for language-grounded task learning with
continuous states in realistic 3d scenes.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">
      International Conference on Computer Vision (ICCV)
     </em>
     ,
2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib27">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gong et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Ran Gong, Qiuyuan Huang, Xiaojian Ma, Hoi Vo, Zane Durante, Yusuke Noda, Zilong
Zheng, Song-Chun Zhu, Demetri Terzopoulos, Li Fei-Fei, et al.
    </span>
    <span class="ltx_bibblock">
     Mindagent: Emergent gaming interaction.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">
      arXiv preprint arXiv:2309.09971
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib28">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Gong et al. (2023c)
    </span>
    <span class="ltx_bibblock">
     Tao Gong, Chengqi Lyu, Shilong Zhang, Yudong Wang, Miao Zheng, Qian Zhao,
Kuikun Liu, Wenwei Zhang, Ping Luo, and Kai Chen.
    </span>
    <span class="ltx_bibblock">
     Multimodal-gpt: A vision and language model for dialogue with humans.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">
      arXiv preprint arXiv:2305.04790
     </em>
     , 2023c.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib29">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Guo et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Jiaxian Guo, Junnan Li, Dongxu Li, Anthony Meng Huat Tiong, Boyang Li, Dacheng
Tao, and Steven CH Hoi.
    </span>
    <span class="ltx_bibblock">
     From images to textual prompts: Zero-shot vqa with frozen large
language models.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">
      Conference on Computer Vision and Pattern Recognition
(CVPR)
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib30">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hong et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Yining Hong, Haoyu Zhen, Peihao Chen, Shuhong Zheng, Yilun Du, Zhenfang Chen,
and Chuang Gan.
    </span>
    <span class="ltx_bibblock">
     3d-llm: Injecting the 3d world into large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">
      arXiv preprint arXiv:2307.12981
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib31">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Hu et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean
Wang, Lu Wang, and Weizhu Chen.
    </span>
    <span class="ltx_bibblock">
     Lora: Low-rank adaptation of large language models.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">
      International Conference on Learning Representations
(ICLR)
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib32">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Huang et al. (2022a)
    </span>
    <span class="ltx_bibblock">
     Jiangyong Huang, William Yicheng Zhu, Baoxiong Jia, Zan Wang, Xiaojian Ma, Qing
Li, and Siyuan Huang.
    </span>
    <span class="ltx_bibblock">
     Perceive, ground, reason, and act: A benchmark for general-purpose
visual representation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">
      arXiv preprint arXiv:2211.15402
     </em>
     , 2022a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib33">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Huang et al. (2022b)
    </span>
    <span class="ltx_bibblock">
     Wenlong Huang, Fei Xia, Ted Xiao, Harris Chan, Jacky Liang, Pete Florence, Andy
Zeng, Jonathan Tompson, Igor Mordatch, Yevgen Chebotar, et al.
    </span>
    <span class="ltx_bibblock">
     Inner monologue: Embodied reasoning through planning with language
models.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">
      Conference on Robot Learning (CoRL)
     </em>
     , 2022b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib34">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Jiang et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Yunfan Jiang, Agrim Gupta, Zichen Zhang, Guanzhi Wang, Yongqiang Dou, Yanjun
Chen, Li Fei-Fei, Anima Anandkumar, Yuke Zhu, and Linxi Fan.
    </span>
    <span class="ltx_bibblock">
     Vima: General robot manipulation with multimodal prompts.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">
      International Conference on Machine Learning (ICML)
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib35">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kaplan et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Jared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon
Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei.
    </span>
    <span class="ltx_bibblock">
     Scaling laws for neural language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib35.1.1">
      arXiv preprint arXiv:2001.08361
     </em>
     , 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib36">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kerr et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Justin Kerr, Chung Min Kim, Ken Goldberg, Angjoo Kanazawa, and Matthew Tancik.
    </span>
    <span class="ltx_bibblock">
     Lerf: Language embedded radiance fields.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">
      International Conference on Computer Vision (ICCV)
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib37">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kirillov et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Alexander Kirillov, Eric Mintun, Nikhila Ravi, Hanzi Mao, Chloe Rolland, Laura
Gustafson, Tete Xiao, Spencer Whitehead, Alexander C Berg, Wan-Yen Lo, et al.
    </span>
    <span class="ltx_bibblock">
     Segment anything.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">
      arXiv preprint arXiv:2304.02643
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib38">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Kudo &amp; Richardson (2018)
    </span>
    <span class="ltx_bibblock">
     Taku Kudo and John Richardson.
    </span>
    <span class="ltx_bibblock">
     Sentencepiece: A simple and language independent subword tokenizer
and detokenizer for neural text processing.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">
      arXiv preprint arXiv:1808.06226
     </em>
     , 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib39">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lake et al. (2015)
    </span>
    <span class="ltx_bibblock">
     Brenden M Lake, Ruslan Salakhutdinov, and Joshua B Tenenbaum.
    </span>
    <span class="ltx_bibblock">
     Human-level concept learning through probabilistic program induction.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">
      Science
     </em>
     , 2015.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib40">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lake et al. (2017)
    </span>
    <span class="ltx_bibblock">
     Brenden M Lake, Tomer D Ullman, Joshua B Tenenbaum, and Samuel J Gershman.
    </span>
    <span class="ltx_bibblock">
     Building machines that learn and think like people.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">
      Behavioral and Brain Sciences
     </em>
     , 2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib41">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lei et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Jie Lei, Linjie Li, Luowei Zhou, Zhe Gan, Tamara L. Berg, Mohit Bansal, and
Jingjing Liu.
    </span>
    <span class="ltx_bibblock">
     Less is more: Clipbert for video-and-language learningvia sparse
sampling.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">
      Conference on Computer Vision and Pattern Recognition
(CVPR)
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib42">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Bo Li, Yuanhan Zhang, Liangyu Chen, Jinghao Wang, Fanyi Pu, Jingkang Yang,
Chunyuan Li, and Ziwei Liu.
    </span>
    <span class="ltx_bibblock">
     Mimic-it: Multi-modal in-context instruction tuning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">
      arXiv preprint arXiv:2306.05425
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib43">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Bo Li, Yuanhan Zhang, Liangyu Chen, Jinghao Wang, Jingkang Yang, and Ziwei Liu.
    </span>
    <span class="ltx_bibblock">
     Otter: A multi-modal model with in-context instruction tuning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">
      arXiv preprint arXiv:2305.03726
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib44">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. (2023c)
    </span>
    <span class="ltx_bibblock">
     Chunyuan Li, Zhe Gan, Zhengyuan Yang, Jianwei Yang, Linjie Li, Lijuan Wang, and
Jianfeng Gao.
    </span>
    <span class="ltx_bibblock">
     Multimodal foundation models: From specialists to general-purpose
assistants, 2023c.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib45">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Li et al. (2023d)
    </span>
    <span class="ltx_bibblock">
     Junnan Li, Dongxu Li, Silvio Savarese, and Steven Hoi.
    </span>
    <span class="ltx_bibblock">
     Blip-2: Bootstrapping language-image pre-training with frozen image
encoders and large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">
      arXiv preprint arXiv:2301.12597
     </em>
     , 2023d.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib46">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Fuxiao Liu, Kevin Lin, Linjie Li, Jianfeng Wang, Yaser Yacoob, and Lijuan Wang.
    </span>
    <span class="ltx_bibblock">
     Aligning large multi-modal model with robust instruction tuning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">
      arXiv preprint arXiv:2306.14565
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib47">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Haotian Liu, Chunyuan Li, Qingyang Wu, and Yong Jae Lee.
    </span>
    <span class="ltx_bibblock">
     Visual instruction tuning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">
      arXiv preprint arXiv:2304.08485
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib48">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Liu et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Zhuang Liu, Hanzi Mao, Chao-Yuan Wu, Christoph Feichtenhofer, Trevor Darrell,
and Saining Xie.
    </span>
    <span class="ltx_bibblock">
     A convnet for the 2020s.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">
      Conference on Computer Vision and Pattern Recognition
(CVPR)
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib49">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Lu et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Jiasen Lu, Christopher Clark, Rowan Zellers, Roozbeh Mottaghi, and Aniruddha
Kembhavi.
    </span>
    <span class="ltx_bibblock">
     Unified-io: A unified model for vision, language, and multi-modal
tasks.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">
      International Conference on Learning Representations
(ICLR)
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib50">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Luo et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Tiange Luo, Chris Rockwell, Honglak Lee, and Justin Johnson.
    </span>
    <span class="ltx_bibblock">
     Scalable 3d captioning with pretrained models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">
      arXiv preprint arXiv:2306.07279
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib51">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ma et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Xiaojian Ma, Silong Yong, Zilong Zheng, Qing Li, Yitao Liang, Song-Chun Zhu,
and Siyuan Huang.
    </span>
    <span class="ltx_bibblock">
     Sqa3d: Situated question answering in 3d scenes.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">
      International Conference on Learning Representations
(ICLR)
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib52">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Majumdar et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Arjun Majumdar, Karmesh Yadav, Sergio Arnaud, Yecheng Jason Ma, Claire Chen,
Sneha Silwal, Aryan Jain, Vincent-Pierre Berges, Pieter Abbeel, Jitendra
Malik, et al.
    </span>
    <span class="ltx_bibblock">
     Where are we in the search for an artificial visual cortex for
embodied intelligence?
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">
      arXiv preprint arXiv:2303.18240
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib53">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Mountcastle (1979)
    </span>
    <span class="ltx_bibblock">
     Vernon B Mountcastle.
    </span>
    <span class="ltx_bibblock">
     An organizing principle for cerebral function: the unit module and
the distributed system.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">
      The neurosciences. Fourth study program
     </em>
     , 1979.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib54">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Mu et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Yao Mu, Qinglong Zhang, Mengkang Hu, Wenhai Wang, Mingyu Ding, Jun Jin, Bin
Wang, Jifeng Dai, Yu Qiao, and Ping Luo.
    </span>
    <span class="ltx_bibblock">
     Embodiedgpt: Vision-language pre-training via embodied chain of
thought.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">
      arXiv preprint arXiv:2305.15021
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib55">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     OpenAI (2022)
    </span>
    <span class="ltx_bibblock">
     OpenAI.
    </span>
    <span class="ltx_bibblock">
     Chatgpt.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/blog/chatgpt/" target="_blank" title="">
      https://openai.com/blog/chatgpt/
     </a>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib56">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     OpenAI (2023)
    </span>
    <span class="ltx_bibblock">
     OpenAI.
    </span>
    <span class="ltx_bibblock">
     Gpt-4 technical report.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib56.1.1">
      arXiv preprint arXiv:2303.08774
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib57">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ouyang et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela
Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al.
    </span>
    <span class="ltx_bibblock">
     Training language models to follow instructions with human feedback.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">
      Advances in Neural Information Processing Systems (NeurIPS)
     </em>
     ,
2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib58">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Peng et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao.
    </span>
    <span class="ltx_bibblock">
     Instruction tuning with gpt-4.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">
      arXiv preprint arXiv:2304.03277
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib59">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Peng et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Songyou Peng, Kyle Genova, Chiyu Jiang, Andrea Tagliasacchi, Marc Pollefeys,
Thomas Funkhouser, et al.
    </span>
    <span class="ltx_bibblock">
     Openscene: 3d scene understanding with open vocabularies.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">
      Conference on Computer Vision and Pattern Recognition
(CVPR)
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib60">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Qi et al. (2017)
    </span>
    <span class="ltx_bibblock">
     Charles Ruizhongtai Qi, Li Yi, Hao Su, and Leonidas J Guibas.
    </span>
    <span class="ltx_bibblock">
     Pointnet++: Deep hierarchical feature learning on point sets in a
metric space.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">
      Advances in Neural Information Processing Systems (NeurIPS)
     </em>
     ,
2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib61">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Radford et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh,
Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark,
et al.
    </span>
    <span class="ltx_bibblock">
     Learning transferable visual models from natural language
supervision.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">
      International Conference on Machine Learning (ICML)
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib62">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Raffel et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael
Matena, Yanqi Zhou, Wei Li, and Peter J Liu.
    </span>
    <span class="ltx_bibblock">
     Exploring the limits of transfer learning with a unified text-to-text
transformer.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">
      Journal of Machine Learning Research (JMLR)
     </em>
     , 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib63">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ramakrishnan et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Santhosh K Ramakrishnan, Aaron Gokaslan, Erik Wijmans, Oleksandr Maksymets,
Alex Clegg, John Turner, Eric Undersander, Wojciech Galuba, Andrew Westbury,
Angel X Chang, et al.
    </span>
    <span class="ltx_bibblock">
     Habitat-matterport 3d dataset (hm3d): 1000 large-scale 3d
environments for embodied ai.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">
      arXiv preprint arXiv:2109.08238
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib64">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ramrakhya et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Ram Ramrakhya, Eric Undersander, Dhruv Batra, and Abhishek Das.
    </span>
    <span class="ltx_bibblock">
     Habitat-web: Learning embodied object-search strategies from human
demonstrations at scale.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib64.1.1">
      Conference on Computer Vision and Pattern Recognition
(CVPR)
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib65">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Reed et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Scott Reed, Konrad Zolna, Emilio Parisotto, Sergio Gomez Colmenarejo, Alexander
Novikov, Gabriel Barth-Maron, Mai Gimenez, Yury Sulsky, Jackie Kay,
Jost Tobias Springenberg, et al.
    </span>
    <span class="ltx_bibblock">
     A generalist agent.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">
      Transactions on Machine Learning Research (TMLR)
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib66">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Reimers &amp; Gurevych (2019)
    </span>
    <span class="ltx_bibblock">
     Nils Reimers and Iryna Gurevych.
    </span>
    <span class="ltx_bibblock">
     Sentence-bert: Sentence embeddings using siamese bert-networks.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">
      Annual Conference on Empirical Methods in Natural Language
Processing (EMNLP)
     </em>
     , 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib67">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Sanh et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Victor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid
Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, et al.
    </span>
    <span class="ltx_bibblock">
     Multitask prompted training enables zero-shot task generalization.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">
      International Conference on Learning Representations
(ICLR)
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib68">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Savva et al. (2019)
    </span>
    <span class="ltx_bibblock">
     Manolis Savva, Abhishek Kadian, Oleksandr Maksymets, Yili Zhao, Erik Wijmans,
Bhavana Jain, Julian Straub, Jia Liu, Vladlen Koltun, Jitendra Malik, et al.
    </span>
    <span class="ltx_bibblock">
     Habitat: A platform for embodied ai research.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib68.1.1">
      International Conference on Computer Vision (ICCV)
     </em>
     , 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib69">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Schmidhuber (2018)
    </span>
    <span class="ltx_bibblock">
     Juergen Schmidhuber.
    </span>
    <span class="ltx_bibblock">
     One big net for everything.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib69.1.1">
      arXiv preprint arXiv:1802.08864
     </em>
     , 2018.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib70">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Schuhmann et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Christoph Schuhmann, Romain Beaumont, Richard Vencu, Cade Gordon, Ross
Wightman, Mehdi Cherti, Theo Coombes, Aarush Katta, Clayton Mullis, Mitchell
Wortsman, et al.
    </span>
    <span class="ltx_bibblock">
     Laion-5b: An open large-scale dataset for training next generation
image-text models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">
      Advances in Neural Information Processing Systems (NeurIPS)
     </em>
     ,
2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib71">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Schult et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Jonas Schult, Francis Engelmann, Alexander Hermans, Or Litany, Siyu Tang, and
Bastian Leibe.
    </span>
    <span class="ltx_bibblock">
     Mask3d for 3d semantic instance segmentation.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib71.1.1">
      arXiv preprint arXiv:2210.03105
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib72">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Shridhar et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Mohit Shridhar, Lucas Manuelli, and Dieter Fox.
    </span>
    <span class="ltx_bibblock">
     Cliport: What and where pathways for robotic manipulation.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib72.1.1">
      Conference on Robot Learning (CoRL)
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib73">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Suglia et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Alessandro Suglia, Qiaozi Gao, Jesse Thomason, Govind Thattai, and Gaurav
Sukhatme.
    </span>
    <span class="ltx_bibblock">
     Embodied bert: A transformer model for embodied, language-guided
visual task completion.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib73.1.1">
      arXiv preprint arXiv:2108.04927
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib74">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Taori et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos
Guestrin, Percy Liang, and Tatsunori B. Hashimoto.
    </span>
    <span class="ltx_bibblock">
     Stanford alpaca: An instruction-following llama model.
    </span>
    <span class="ltx_bibblock">
     <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/tatsu-lab/stanford_alpaca" target="_blank" title="">
      https://github.com/tatsu-lab/stanford_alpaca
     </a>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib75">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Tsimpoukelli et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Maria Tsimpoukelli, Jacob L Menick, Serkan Cabi, SM Eslami, Oriol Vinyals, and
Felix Hill.
    </span>
    <span class="ltx_bibblock">
     Multimodal few-shot learning with frozen language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib75.1.1">
      Advances in Neural Information Processing Systems (NeurIPS)
     </em>
     ,
2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib76">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Vaswani et al. (2017)
    </span>
    <span class="ltx_bibblock">
     Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones,
Aidan N Gomez, Łukasz Kaiser, and Illia Polosukhin.
    </span>
    <span class="ltx_bibblock">
     Attention is all you need.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib76.1.1">
      Advances in Neural Information Processing Systems (NeurIPS)
     </em>
     ,
2017.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib77">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wald et al. (2019)
    </span>
    <span class="ltx_bibblock">
     Johanna Wald, Armen Avetisyan, Nassir Navab, Federico Tombari, and Matthias
Nießner.
    </span>
    <span class="ltx_bibblock">
     Rio: 3d object instance re-localization in changing indoor
environments.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib77.1.1">
      International Conference on Computer Vision (ICCV)
     </em>
     , 2019.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib78">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Guanzhi Wang, Yuqi Xie, Yunfan Jiang, Ajay Mandlekar, Chaowei Xiao, Yuke Zhu,
Linxi Fan, and Anima Anandkumar.
    </span>
    <span class="ltx_bibblock">
     Voyager: An open-ended embodied agent with large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib78.1.1">
      arXiv preprint arXiv:2305.16291
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib79">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Xinlong Wang, Wen Wang, Yue Cao, Chunhua Shen, and Tiejun Huang.
    </span>
    <span class="ltx_bibblock">
     Images speak in images: A generalist painter for in-context visual
learning.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib79.1.1">
      Conference on Computer Vision and Pattern Recognition
(CVPR)
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib80">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023c)
    </span>
    <span class="ltx_bibblock">
     Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel
Khashabi, and Hannaneh Hajishirzi.
    </span>
    <span class="ltx_bibblock">
     Self-instruct: Aligning language model with self generated
instructions.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib80.1.1">
      Annual Meeting of the Association for Computational
Linguistics (ACL)
     </em>
     , 2023c.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib81">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023d)
    </span>
    <span class="ltx_bibblock">
     Zehan Wang, Haifeng Huang, Yang Zhao, Ziang Zhang, and Zhou Zhao.
    </span>
    <span class="ltx_bibblock">
     Chat-3d: Data-efficiently tuning large language model for universal
dialogue of 3d scenes.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib81.1.1">
      arXiv preprint arXiv:2308.08769
     </em>
     , 2023d.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib82">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wang et al. (2023e)
    </span>
    <span class="ltx_bibblock">
     Zihao Wang, Shaofei Cai, Anji Liu, Xiaojian Ma, and Yitao Liang.
    </span>
    <span class="ltx_bibblock">
     Describe, explain, plan and select: Interactive planning with large
language models enables open-world multi-task agents.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib82.1.1">
      arXiv preprint arXiv:2302.01560
     </em>
     , 2023e.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib83">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wei et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester,
Nan Du, Andrew M Dai, and Quoc V Le.
    </span>
    <span class="ltx_bibblock">
     Finetuned language models are zero-shot learners.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib83.1.1">
      International Conference on Learning Representations
(ICLR)
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib84">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Wu et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Shun-Cheng Wu, Johanna Wald, Keisuke Tateno, Nassir Navab, and Federico
Tombari.
    </span>
    <span class="ltx_bibblock">
     Scenegraphfusion: Incremental 3d scene graph prediction from rgb-d
sequences.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib84.1.1">
      Conference on Computer Vision and Pattern Recognition
(CVPR)
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib85">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Xu et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Runsen Xu, Xiaolong Wang, Tai Wang, Yilun Chen, Jiangmiao Pang, and Dahua Lin.
    </span>
    <span class="ltx_bibblock">
     Pointllm: Empowering large language models to understand point
clouds.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib85.1.1">
      arXiv preprint arXiv:2308.16911
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib86">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Ye et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Qinghao Ye, Haiyang Xu, Guohai Xu, Jiabo Ye, Ming Yan, Yiyang Zhou, Junyang
Wang, Anwen Hu, Pengcheng Shi, Yaya Shi, et al.
    </span>
    <span class="ltx_bibblock">
     mplug-owl: Modularization empowers large language models with
multimodality.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib86.1.1">
      arXiv preprint arXiv:2304.14178
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib87">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yin et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Zhenfei Yin, Jiong Wang, Jianjian Cao, Zhelun Shi, Dingning Liu, Mukai Li,
Lu Sheng, Lei Bai, Xiaoshui Huang, Zhiyong Wang, et al.
    </span>
    <span class="ltx_bibblock">
     Lamm: Language-assisted multi-modal instruction-tuning dataset,
framework, and benchmark.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib87.1.1">
      arXiv preprint arXiv:2306.06687
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib88">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Yu et al. (2022)
    </span>
    <span class="ltx_bibblock">
     Xumin Yu, Lulu Tang, Yongming Rao, Tiejun Huang, Jie Zhou, and Jiwen Lu.
    </span>
    <span class="ltx_bibblock">
     Point-bert: Pre-training 3d point cloud transformers with masked
point modeling.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib88.1.1">
      Conference on Computer Vision and Pattern Recognition
(CVPR)
     </em>
     , 2022.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib89">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhao et al. (2023)
    </span>
    <span class="ltx_bibblock">
     Haozhe Zhao, Zefan Cai, Shuzheng Si, Xiaojian Ma, Kaikai An, Liang Chen, Zixuan
Liu, Sheng Wang, Wenjuan Han, and Baobao Chang.
    </span>
    <span class="ltx_bibblock">
     Mmicl: Empowering vision-language model with multi-modal in-context
learning.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib89.1.1">
      arXiv preprint arXiv:2309.07915
     </em>
     , 2023.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib90">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhao et al. (2021)
    </span>
    <span class="ltx_bibblock">
     Lichen Zhao, Daigang Cai, Lu Sheng, and Dong Xu.
    </span>
    <span class="ltx_bibblock">
     3dvg-transformer: Relation modeling for visual grounding on point
clouds.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib90.1.1">
      International Conference on Computer Vision (ICCV)
     </em>
     , 2021.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib91">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhu et al. (2023a)
    </span>
    <span class="ltx_bibblock">
     Deyao Zhu, Jun Chen, Kilichbek Haydarov, Xiaoqian Shen, Wenxuan Zhang, and
Mohamed Elhoseiny.
    </span>
    <span class="ltx_bibblock">
     Chatgpt asks, blip-2 answers: Automatic questioning towards enriched
visual descriptions.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib91.1.1">
      arXiv preprint arXiv:2303.06594
     </em>
     , 2023a.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib92">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhu et al. (2023b)
    </span>
    <span class="ltx_bibblock">
     Deyao Zhu, Jun Chen, Xiaoqian Shen, Xiang Li, and Mohamed Elhoseiny.
    </span>
    <span class="ltx_bibblock">
     Minigpt-4: Enhancing vision-language understanding with advanced
large language models.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib92.1.1">
      arXiv preprint arXiv:2304.10592
     </em>
     , 2023b.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib93">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhu et al. (2020)
    </span>
    <span class="ltx_bibblock">
     Yixin Zhu, Tao Gao, Lifeng Fan, Siyuan Huang, Mark Edmonds, Hangxin Liu, Feng
Gao, Chi Zhang, Siyuan Qi, Ying Nian Wu, et al.
    </span>
    <span class="ltx_bibblock">
     Dark, beyond deep: A paradigm shift to cognitive ai with humanlike
common sense.
    </span>
    <span class="ltx_bibblock">
     <em class="ltx_emph ltx_font_italic" id="bib.bib93.1.1">
      Engineering
     </em>
     , 2020.
    </span>
   </li>
   <li class="ltx_bibitem" id="bib.bib94">
    <span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">
     Zhu et al. (2023c)
    </span>
    <span class="ltx_bibblock">
     Ziyu Zhu, Xiaojian Ma, Yixin Chen, Zhidong Deng, Siyuan Huang, and Qing Li.
    </span>
    <span class="ltx_bibblock">
     3d-vista: Pre-trained transformer for 3d vision and text alignment.
    </span>
    <span class="ltx_bibblock">
     In
     <em class="ltx_emph ltx_font_italic" id="bib.bib94.1.1">
      International Conference on Computer Vision (ICCV)
     </em>
     ,
2023c.
    </span>
   </li>
  </ul>
 </section>
 <div class="ltx_pagination ltx_role_newpage">
 </div>
 <section class="ltx_appendix" id="A1">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix A
   </span>
   Data
  </h2>
  <section class="ltx_subsection" id="A1.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     A.1
    </span>
    Prompts for LLM-assisted 3D Data Generation
   </h3>
   <div class="ltx_para ltx_noindent" id="A1.SS1.p1">
    <p class="ltx_p" id="A1.SS1.p1.1">
     In
     <a class="ltx_ref" href="#A1.F5" title="In A.1 Prompts for LLM-assisted 3D Data Generation ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Fig.
      </span>
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     –
     <a class="ltx_ref" href="#A1.F9" title="Figure 9 ‣ A.1 Prompts for LLM-assisted 3D Data Generation ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       9
      </span>
     </a>
     , we show the prompts for five types of LLM-assisted 3D-language data generation. We provide few-shot examples as the context. In each example, the “content” contains a scene graph, and the “response” refers to a human-labeled response. The query is a new scene graph, based on which ChatGPT
     <cite class="ltx_cite ltx_citemacro_citep">
      (OpenAI,
      <a class="ltx_ref" href="#bib.bib55" title="">
       2022
      </a>
      )
     </cite>
     generates responses.
    </p>
   </div>
   <figure class="ltx_figure" id="A1.F5">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="275" id="A1.F5.g1" src="/html/2311.12871/assets/x5.png" width="422"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 5:
     </span>
     The prompt for generating 3D Dialogue.
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="A1.F6">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="245" id="A1.F6.g1" src="/html/2311.12871/assets/x6.png" width="422"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 6:
     </span>
     The prompt for generating 3D QA.
    </figcaption>
   </figure>
   <div class="ltx_para ltx_noindent" id="A1.SS1.p2">
    <p class="ltx_p" id="A1.SS1.p2.1">
     <a class="ltx_ref" href="#A1.F5" title="In A.1 Prompts for LLM-assisted 3D Data Generation ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Fig.
      </span>
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     shows the prompt for generating 3D dialogue data.
     <span class="ltx_text" id="A1.SS1.p2.1.1" style="color:#FF0000;">
      Red fonts
     </span>
     outline our requirements of the dialogue content, including object attributes, spatial relations, and commonsense topics.
     <span class="ltx_text" id="A1.SS1.p2.1.2" style="color:#8C24FF;">
      Purple fonts
     </span>
     formulate the template of the response. We require the response generated by the ChatGPT should include the dialogue context as well; the “thought” contains the involved objects in the question, which is used to enhance the reliability of the answer. These two components will be removed after the refinement procedures.
    </p>
   </div>
   <figure class="ltx_figure" id="A1.F7">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="213" id="A1.F7.g1" src="/html/2311.12871/assets/x7.png" width="422"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 7:
     </span>
     The prompt for generating 3D planning.
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="A1.F8">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="243" id="A1.F8.g1" src="/html/2311.12871/assets/x8.png" width="422"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 8:
     </span>
     The prompt for generating 3D scene caption.
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="A1.F9">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="106" id="A1.F9.g1" src="/html/2311.12871/assets/x9.png" width="422"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 9:
     </span>
     The prompt for generating 3D object-in-the-scene caption.
    </figcaption>
   </figure>
  </section>
  <section class="ltx_subsection" id="A1.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     A.2
    </span>
    Analysis of the Object-Centric Chain-of-Thought
   </h3>
   <figure class="ltx_table" id="A1.T5">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 5:
     </span>
     The effect of
     <abbr class="ltx_glossaryref" title="Object-centric Chain-of-Thought">
      <span class="ltx_text ltx_glossary_short">
       O-CoT
      </span>
     </abbr>
     on the answer accuracy for Object Counting questions.
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T5.1">
     <tr class="ltx_tr" id="A1.T5.1.1">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A1.T5.1.1.1">
       <span class="ltx_text ltx_font_bold" id="A1.T5.1.1.1.1">
        Settings
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T5.1.1.2">
       <span class="ltx_text ltx_font_bold" id="A1.T5.1.1.2.1">
        Seed 1
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T5.1.1.3">
       <span class="ltx_text ltx_font_bold" id="A1.T5.1.1.3.1">
        Seed 2
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T5.1.1.4">
       <span class="ltx_text ltx_font_bold" id="A1.T5.1.1.4.1">
        Seed 3
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T5.1.1.5">
       <span class="ltx_text ltx_font_bold" id="A1.T5.1.1.5.1">
        Seed 4
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T5.1.1.6">
       <span class="ltx_text ltx_font_bold" id="A1.T5.1.1.6.1">
        Average
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T5.1.1.7">
       <span class="ltx_text ltx_font_bold" id="A1.T5.1.1.7.1">
        Avg. Gain
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T5.1.2">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T5.1.2.1">
       w/o
       <abbr class="ltx_glossaryref" title="Object-centric Chain-of-Thought">
        <span class="ltx_text ltx_glossary_short">
         O-CoT
        </span>
       </abbr>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.1.2.2">
       0.5838
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.1.2.3">
       0.5349
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.1.2.4">
       0.5962
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.1.2.5">
       0.5816
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.1.2.6">
       0.5741
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T5.1.2.7" rowspan="2">
       <span class="ltx_text" id="A1.T5.1.2.7.1">
        0.2061
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T5.1.3">
      <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="A1.T5.1.3.1">
       O-CoT
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T5.1.3.2">
       0.7647
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T5.1.3.3">
       0.8117
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T5.1.3.4">
       0.7778
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T5.1.3.5">
       0.7667
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T5.1.3.6">
       0.7802
      </td>
     </tr>
    </table>
   </figure>
   <div class="ltx_para ltx_noindent" id="A1.SS2.p1">
    <p class="ltx_p" id="A1.SS2.p1.1">
     To further investigate the impact of Object-centric Chain-of-Thought (
     <abbr class="ltx_glossaryref" title="Object-centric Chain-of-Thought">
      <span class="ltx_text ltx_glossary_short">
       O-CoT
      </span>
     </abbr>
     ) on data quality, we analyze the answer accuracy for Object Counting questions. Specifically, we collect several demonstrations, and for each run, we select two of them as the prompt seed. With these seeds, we generate dialogues across all scenes in 3DSSG
     <cite class="ltx_cite ltx_citemacro_citep">
      (Wu et al.,
      <a class="ltx_ref" href="#bib.bib84" title="">
       2021
      </a>
      )
     </cite>
     and then assess the answer accuracy for Object Counting questions. The results are presented in
     <a class="ltx_ref" href="#A1.T5" title="In A.2 Analysis of the Object-Centric Chain-of-Thought ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Tab.
      </span>
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A1.SS2.p2">
    <p class="ltx_p" id="A1.SS2.p2.1">
     The results in
     <a class="ltx_ref" href="#A1.T5" title="In A.2 Analysis of the Object-Centric Chain-of-Thought ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Tab.
      </span>
      <span class="ltx_text ltx_ref_tag">
       5
      </span>
     </a>
     indicate that
     <abbr class="ltx_glossaryref" title="Object-centric Chain-of-Thought">
      <span class="ltx_text ltx_glossary_short">
       O-CoT
      </span>
     </abbr>
     consistently improves the answer accuracy for Object Counting questions. Though there remain errors after applying
     <abbr class="ltx_glossaryref" title="Object-centric Chain-of-Thought">
      <span class="ltx_text ltx_glossary_short">
       O-CoT
      </span>
     </abbr>
     , we will conduct refinement to fix them. Examples of Object Counting questions are provided in
     <a class="ltx_ref" href="#A1.SS3" title="A.3 Refinement Details ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Sec.
      </span>
      <span class="ltx_text ltx_ref_tag">
       A.3
      </span>
     </a>
     .
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="A1.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     A.3
    </span>
    Refinement Details
   </h3>
   <div class="ltx_para ltx_noindent" id="A1.SS3.p1">
    <p class="ltx_p" id="A1.SS3.p1.1">
     We conduct refinement by passing raw LLM-generated responses into several human-defined filtering procedures based on the 3D scene graph. The refinement considers five raw response categories:
    </p>
    <ul class="ltx_itemize" id="A1.I1">
     <li class="ltx_item" id="A1.I1.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="A1.I1.i1.p1">
       <p class="ltx_p" id="A1.I1.i1.p1.1">
        Object Counting. The question concerns counting the target object.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A1.I1.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="A1.I1.i2.p1">
       <p class="ltx_p" id="A1.I1.i2.p1.1">
        Object Existence. The response claims the existence of objects, which can be actually either existent or non-existent.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A1.I1.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="A1.I1.i3.p1">
       <p class="ltx_p" id="A1.I1.i3.p1.1">
        Object Non-existence. The response claims the non-existence of objects, which can be actually either existent or non-existent.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A1.I1.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="A1.I1.i4.p1">
       <p class="ltx_p" id="A1.I1.i4.p1.1">
        Negative Response. The scene graph cannot provide a solid response to the question, which means the question cannot be answered and will be discarded.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A1.I1.i5" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para ltx_noindent" id="A1.I1.i5.p1">
       <p class="ltx_p" id="A1.I1.i5.p1.1">
        Response with ID. The response contains unexpected object IDs.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <div class="ltx_para" id="A1.SS3.p2">
    <p class="ltx_p" id="A1.SS3.p2.1">
     Specifically, we employ regular expression matching to detect errors in these five categories. And we also employ this method to correct the responses except for Response with ID, which will be rewritten by ChatGPT instead. The QA pair will be eliminated if multiple rounds of rewriting fail to remove the IDs.
     <a class="ltx_ref" href="#A1.T6" title="In A.3 Refinement Details ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Tab.
      </span>
      <span class="ltx_text ltx_ref_tag">
       6
      </span>
     </a>
     and
     <a class="ltx_ref" href="#A1.T7" title="In A.3 Refinement Details ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Tab.
      </span>
      <span class="ltx_text ltx_ref_tag">
       7
      </span>
     </a>
     show some examples of the responses subject to the above five categories as well as the effect of our refinement.
    </p>
   </div>
   <figure class="ltx_table" id="A1.T6">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 6:
     </span>
     <span class="ltx_text ltx_font_bold" id="A1.T6.2.1">
      Examples of dialogue refinement
     </span>
     .
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T6.3">
     <tr class="ltx_tr" id="A1.T6.3.1">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A1.T6.3.1.1">
       <span class="ltx_text ltx_font_bold" id="A1.T6.3.1.1.1">
        Types
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" id="A1.T6.3.1.2">
       <span class="ltx_inline-block ltx_align_top" id="A1.T6.3.1.2.1">
        <span class="ltx_p" id="A1.T6.3.1.2.1.1" style="width:128.0pt;">
         <span class="ltx_text ltx_font_bold" id="A1.T6.3.1.2.1.1.1">
          Raw Responses
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A1.T6.3.1.3">
       <span class="ltx_inline-block ltx_align_top" id="A1.T6.3.1.3.1">
        <span class="ltx_p" id="A1.T6.3.1.3.1.1" style="width:128.0pt;">
         <span class="ltx_text ltx_font_bold" id="A1.T6.3.1.3.1.1.1">
          Refined Responses
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T6.3.2">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T6.3.2.1">
       <span class="ltx_text ltx_font_bold" id="A1.T6.3.2.1.1">
        Object Counting
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A1.T6.3.2.2">
       <span class="ltx_inline-block ltx_align_top" id="A1.T6.3.2.2.1">
        <span class="ltx_p" id="A1.T6.3.2.2.1.1" style="width:128.0pt;">
         There are 3 chairs in the room.
        </span>
        <span class="ltx_p" id="A1.T6.3.2.2.1.2">
         I see there are two washing machines in the bathroom.
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T6.3.2.3">
       <span class="ltx_inline-block ltx_align_top" id="A1.T6.3.2.3.1">
        <span class="ltx_p" id="A1.T6.3.2.3.1.1" style="width:128.0pt;">
         There are 4 chairs in the room.
        </span>
        <span class="ltx_p" id="A1.T6.3.2.3.1.2">
         I see there are 4 washing machines in the bathroom.
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T6.3.3">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T6.3.3.1">
       <span class="ltx_text ltx_font_bold" id="A1.T6.3.3.1.1">
        Object Existence
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A1.T6.3.3.2">
       <span class="ltx_inline-block ltx_align_top" id="A1.T6.3.3.2.1">
        <span class="ltx_p" id="A1.T6.3.3.2.1.1" style="width:128.0pt;">
         Yes, there is a cutting board in the kitchen.
        </span>
        <span class="ltx_p" id="A1.T6.3.3.2.1.2">
         Yes, there is a computer and a monitor on the desk. However, the monitor is currently off.
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T6.3.3.3">
       <span class="ltx_inline-block ltx_align_top" id="A1.T6.3.3.3.1">
        <span class="ltx_p" id="A1.T6.3.3.3.1.1" style="width:128.0pt;">
         No, there is no cutting board in the room.
        </span>
        <span class="ltx_p" id="A1.T6.3.3.3.1.2">
         No, there is no computer in the room.
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T6.3.4">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T6.3.4.1">
       <span class="ltx_text ltx_font_bold" id="A1.T6.3.4.1.1">
        Object Non-existence
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A1.T6.3.4.2">
       <span class="ltx_inline-block ltx_align_top" id="A1.T6.3.4.2.1">
        <span class="ltx_p" id="A1.T6.3.4.2.1.1" style="width:128.0pt;">
         No, there is no stereo equipment in the room.
        </span>
        <span class="ltx_p" id="A1.T6.3.4.2.1.2">
         I’m sorry, but I couldn’t find a hair dryer in the bathroom.
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T6.3.4.3">
       <span class="ltx_inline-block ltx_align_top" id="A1.T6.3.4.3.1">
        <span class="ltx_p" id="A1.T6.3.4.3.1.1" style="width:128.0pt;">
         Yes, there is a stereo equipment in the room.
        </span>
        <span class="ltx_p" id="A1.T6.3.4.3.1.2">
         Yes, I found a hair dryer in the room.
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T6.3.5">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T6.3.5.1">
       <span class="ltx_text ltx_font_bold" id="A1.T6.3.5.1.1">
        Negative Response
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A1.T6.3.5.2">
       <span class="ltx_inline-block ltx_align_top" id="A1.T6.3.5.2.1">
        <span class="ltx_p" id="A1.T6.3.5.2.1.1" style="width:128.0pt;">
         No, there is nothing else mentioned in the scene graph.
        </span>
        <span class="ltx_p" id="A1.T6.3.5.2.1.2">
         I’m sorry, but there is no mention of a mirror in the scene graph for the bathroom.
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T6.3.5.3">
       <span class="ltx_inline-block ltx_align_top" id="A1.T6.3.5.3.1">
        <span class="ltx_p" id="A1.T6.3.5.3.1.1" style="width:128.0pt;">
         <span class="ltx_text ltx_font_italic" id="A1.T6.3.5.3.1.1.1">
          The negative responses will be removed.
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T6.3.6">
      <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="A1.T6.3.6.1">
       <span class="ltx_text ltx_font_bold" id="A1.T6.3.6.1.1">
        Response with ID
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A1.T6.3.6.2">
       <span class="ltx_inline-block ltx_align_top" id="A1.T6.3.6.2.1">
        <span class="ltx_p" id="A1.T6.3.6.2.1.1" style="width:128.0pt;">
         You can place your backpack on the floor, to the left of the dining table-33. As for your bag, you can place it on the floor, to the left of the bed-10.
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A1.T6.3.6.3">
       <span class="ltx_inline-block ltx_align_top" id="A1.T6.3.6.3.1">
        <span class="ltx_p" id="A1.T6.3.6.3.1.1" style="width:128.0pt;">
         You can place your backpack on the floor, to the left of the dining table. As for your bag, you can place it on the floor, to the left of the bed.
        </span>
       </span>
      </td>
     </tr>
    </table>
   </figure>
   <figure class="ltx_table" id="A1.T7">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 7:
     </span>
     <span class="ltx_text ltx_font_bold" id="A1.T7.2.1">
      Examples of QA refinement
     </span>
     .
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T7.3">
     <tr class="ltx_tr" id="A1.T7.3.1">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A1.T7.3.1.1">
       <span class="ltx_text ltx_font_bold" id="A1.T7.3.1.1.1">
        Types
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" id="A1.T7.3.1.2">
       <span class="ltx_inline-block ltx_align_top" id="A1.T7.3.1.2.1">
        <span class="ltx_p" id="A1.T7.3.1.2.1.1" style="width:128.0pt;">
         <span class="ltx_text ltx_font_bold" id="A1.T7.3.1.2.1.1.1">
          Raw Responses
         </span>
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A1.T7.3.1.3">
       <span class="ltx_inline-block ltx_align_top" id="A1.T7.3.1.3.1">
        <span class="ltx_p" id="A1.T7.3.1.3.1.1" style="width:128.0pt;">
         <span class="ltx_text ltx_font_bold" id="A1.T7.3.1.3.1.1.1">
          Refined Responses
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T7.3.2">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T7.3.2.1">
       <span class="ltx_text ltx_font_bold" id="A1.T7.3.2.1.1">
        Object Counting
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A1.T7.3.2.2">
       <span class="ltx_inline-block ltx_align_top" id="A1.T7.3.2.2.1">
        <span class="ltx_p" id="A1.T7.3.2.2.1.1" style="width:128.0pt;">
         Q: How many chairs are in the room?
        </span>
        <span class="ltx_p" id="A1.T7.3.2.2.1.2">
         A: 3
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T7.3.2.3">
       <span class="ltx_inline-block ltx_align_top" id="A1.T7.3.2.3.1">
        <span class="ltx_p" id="A1.T7.3.2.3.1.1" style="width:128.0pt;">
         Q: How many chairs are in the room?
        </span>
        <span class="ltx_p" id="A1.T7.3.2.3.1.2">
         A: four
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T7.3.3">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T7.3.3.1">
       <span class="ltx_text ltx_font_bold" id="A1.T7.3.3.1.1">
        Object Existence
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A1.T7.3.3.2">
       <span class="ltx_inline-block ltx_align_top" id="A1.T7.3.3.2.1">
        <span class="ltx_p" id="A1.T7.3.3.2.1.1" style="width:128.0pt;">
         Q: Is there a mirror in the room?
        </span>
        <span class="ltx_p" id="A1.T7.3.3.2.1.2">
         A: yes
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T7.3.3.3">
       <span class="ltx_inline-block ltx_align_top" id="A1.T7.3.3.3.1">
        <span class="ltx_p" id="A1.T7.3.3.3.1.1" style="width:128.0pt;">
         Q: Is there a mirror in the room?
        </span>
        <span class="ltx_p" id="A1.T7.3.3.3.1.2">
         A: no
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T7.3.4">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T7.3.4.1">
       <span class="ltx_text ltx_font_bold" id="A1.T7.3.4.1.1">
        Object Non-existence
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A1.T7.3.4.2">
       <span class="ltx_inline-block ltx_align_top" id="A1.T7.3.4.2.1">
        <span class="ltx_p" id="A1.T7.3.4.2.1.1" style="width:128.0pt;">
         Q: Is there an ironing board in the room?
        </span>
        <span class="ltx_p" id="A1.T7.3.4.2.1.2">
         A: no
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T7.3.4.3">
       <span class="ltx_inline-block ltx_align_top" id="A1.T7.3.4.3.1">
        <span class="ltx_p" id="A1.T7.3.4.3.1.1" style="width:128.0pt;">
         Q: Is there an ironing board in the room?
        </span>
        <span class="ltx_p" id="A1.T7.3.4.3.1.2">
         A: yes
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T7.3.5">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T7.3.5.1">
       <span class="ltx_text ltx_font_bold" id="A1.T7.3.5.1.1">
        Negative Response
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A1.T7.3.5.2">
       <span class="ltx_inline-block ltx_align_top" id="A1.T7.3.5.2.1">
        <span class="ltx_p" id="A1.T7.3.5.2.1.1" style="width:128.0pt;">
         Q: What is the material of the bathtub?
A: unknown
        </span>
        <span class="ltx_p" id="A1.T7.3.5.2.1.2">
         Q: Where is the shampoo dispenser?
A: unknown
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T7.3.5.3">
       <span class="ltx_inline-block ltx_align_top" id="A1.T7.3.5.3.1">
        <span class="ltx_p" id="A1.T7.3.5.3.1.1" style="width:128.0pt;">
         <span class="ltx_text ltx_font_italic" id="A1.T7.3.5.3.1.1.1">
          The negative responses will be removed.
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T7.3.6">
      <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="A1.T7.3.6.1">
       <span class="ltx_text ltx_font_bold" id="A1.T7.3.6.1.1">
        Response with ID
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A1.T7.3.6.2">
       <span class="ltx_inline-block ltx_align_top" id="A1.T7.3.6.2.1">
        <span class="ltx_p" id="A1.T7.3.6.2.1.1" style="width:128.0pt;">
         Q: Where is the mirror located?
        </span>
        <span class="ltx_p" id="A1.T7.3.6.2.1.2">
         A: attached to wall-3, behind heater-18, to the left of shelf-19
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A1.T7.3.6.3">
       <span class="ltx_inline-block ltx_align_top" id="A1.T7.3.6.3.1">
        <span class="ltx_p" id="A1.T7.3.6.3.1.1" style="width:128.0pt;">
         Q: Where is the mirror located?
        </span>
        <span class="ltx_p" id="A1.T7.3.6.3.1.2">
         A: attached to a wall, behind a heater, to the left of a shelf
        </span>
       </span>
      </td>
     </tr>
    </table>
   </figure>
  </section>
  <section class="ltx_subsection" id="A1.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     A.4
    </span>
    Statistics of Raw Responses
   </h3>
   <div class="ltx_para" id="A1.SS4.p1">
    <p class="ltx_p" id="A1.SS4.p1.1">
     Based on the aforementioned five raw response categories, we assess their quality by statistics and clarify the refinement effect accordingly. In
     <a class="ltx_ref" href="#A1.T8" title="In A.4 Statistics of Raw Responses ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Tab.
      </span>
      <span class="ltx_text ltx_ref_tag">
       8
      </span>
     </a>
     , we quantify the answer accuracy for Object Counting, Object Existence, and Object Non-existence in dialogue and QA tasks. Results of the two tasks are averaged over all 3DSSG scenes across 6 prompt seeds and 3 prompt seeds, respectively. For these three categories of responses, we can fix almost all the detected errors by referring to the scene graph. In
     <a class="ltx_ref" href="#A1.T9" title="In A.4 Statistics of Raw Responses ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Tab.
      </span>
      <span class="ltx_text ltx_ref_tag">
       9
      </span>
     </a>
     , we present the proportion of Negative Response and Response with ID in the total set of responses. Negative responses will be removed, as well as the responses with remaining IDs after multiple rounds of rewriting. All results are based on the
     <abbr class="ltx_glossaryref" title="Object-centric Chain-of-Thought">
      <span class="ltx_text ltx_glossary_short">
       O-CoT
      </span>
     </abbr>
     method.
    </p>
   </div>
   <figure class="ltx_table" id="A1.T8">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 8:
     </span>
     The accuracy of three types of raw responses from ChatGPT.
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T8.1">
     <tr class="ltx_tr" id="A1.T8.1.1">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A1.T8.1.1.1">
       <span class="ltx_text ltx_font_bold" id="A1.T8.1.1.1.1">
        Tasks
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T8.1.1.2">
       <span class="ltx_text ltx_font_bold" id="A1.T8.1.1.2.1">
        Object Counting
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T8.1.1.3">
       <span class="ltx_text ltx_font_bold" id="A1.T8.1.1.3.1">
        Object Existence
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T8.1.1.4">
       <span class="ltx_text ltx_font_bold" id="A1.T8.1.1.4.1">
        Object Non-existence
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T8.1.2">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T8.1.2.1">
       Dialogue
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A1.T8.1.2.2">
       0.7824
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A1.T8.1.2.3">
       0.9314
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A1.T8.1.2.4">
       0.2986
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T8.1.3">
      <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="A1.T8.1.3.1">
       QA
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T8.1.3.2">
       0.7691
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T8.1.3.3">
       0.8999
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T8.1.3.4">
       0.2848
      </td>
     </tr>
    </table>
   </figure>
   <figure class="ltx_table" id="A1.T9">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 9:
     </span>
     The proportion of Negative Response and Response with ID in the total set of responses.
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T9.1">
     <tr class="ltx_tr" id="A1.T9.1.1">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A1.T9.1.1.1">
       <span class="ltx_text ltx_font_bold" id="A1.T9.1.1.1.1">
        Tasks
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T9.1.1.2">
       <span class="ltx_text ltx_font_bold" id="A1.T9.1.1.2.1">
        Negative Response
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T9.1.1.3">
       <span class="ltx_text ltx_font_bold" id="A1.T9.1.1.3.1">
        Response with ID
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T9.1.2">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T9.1.2.1">
       Dialogue
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A1.T9.1.2.2">
       0.0080
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A1.T9.1.2.3">
       0.0360
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T9.1.3">
      <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="A1.T9.1.3.1">
       QA
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T9.1.3.2">
       0.1045
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T9.1.3.3">
       0.0221
      </td>
     </tr>
    </table>
   </figure>
  </section>
  <section class="ltx_subsection" id="A1.SS5">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     A.5
    </span>
    Subgraph Sampling
   </h3>
   <div class="ltx_para" id="A1.SS5.p1">
    <p class="ltx_p" id="A1.SS5.p1.1">
     To enhance the diversity of the 3D scene graphs used for prompting, we perform subgraph sampling on the 3DSSG according to a sampling rate, which denotes the ratio of preserved nodes. The sampled subgraphs are used for generating scene captions and planning data. We analyze the distribution of node numbers across the 3DSSG dataset in
     <a class="ltx_ref" href="#A1.F10" title="In A.5 Subgraph Sampling ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Fig.
      </span>
      <span class="ltx_text ltx_ref_tag">
       10
      </span>
     </a>
     and set different sampling rates for scenes with different numbers of nodes in
     <a class="ltx_ref" href="#A1.T10" title="In A.5 Subgraph Sampling ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Tab.
      </span>
      <span class="ltx_text ltx_ref_tag">
       10
      </span>
     </a>
     . For each sampling rate, we set 4 random prompt seeds to further enhance the diversity of prompted data.
    </p>
   </div>
   <figure class="ltx_figure" id="A1.F10">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="216" id="A1.F10.g1" src="/html/2311.12871/assets/figs/node_histogram.png" width="494"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 10:
     </span>
     <span class="ltx_text ltx_font_bold" id="A1.F10.2.1">
      The distribution of node numbers for 3DSSG scenes.
     </span>
     The node number represents the number of objects in a scene.
    </figcaption>
   </figure>
   <figure class="ltx_table" id="A1.T10">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 10:
     </span>
     <span class="ltx_text ltx_font_bold" id="A1.T10.4.1">
      Sampling rates for scenes with different node numbers.
     </span>
     The hyphen denotes a sweep of sampling rates,
     <em class="ltx_emph ltx_font_italic" id="A1.T10.5.2">
      e.g
     </em>
     .
     <span class="ltx_text" id="A1.T10.6.3">
     </span>
     , “0.7-0.9” means “0.7,0.8,0.9”.
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T10.7">
     <tr class="ltx_tr" id="A1.T10.7.1">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A1.T10.7.1.1">
       <span class="ltx_text ltx_font_bold" id="A1.T10.7.1.1.1">
        Node Number
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T10.7.1.2">
       <span class="ltx_text ltx_font_bold" id="A1.T10.7.1.2.1">
        10-20
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T10.7.1.3">
       <span class="ltx_text ltx_font_bold" id="A1.T10.7.1.3.1">
        20-30
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T10.7.1.4">
       <span class="ltx_text ltx_font_bold" id="A1.T10.7.1.4.1">
        30-40
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T10.7.1.5">
       <span class="ltx_text ltx_font_bold" id="A1.T10.7.1.5.1">
        40-50
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T10.7.1.6">
       <span class="ltx_text ltx_font_bold" id="A1.T10.7.1.6.1">
        50-60
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T10.7.1.7">
       <span class="ltx_text ltx_font_bold" id="A1.T10.7.1.7.1">
        60-70
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T10.7.1.8">
       <span class="ltx_text ltx_font_bold" id="A1.T10.7.1.8.1">
        &gt;70
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T10.7.2">
      <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="A1.T10.7.2.1">
       Sampling Rate
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T10.7.2.2">
       0.8,0.9
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T10.7.2.3">
       0.7-0.9
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T10.7.2.4">
       0.6-0.9
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T10.7.2.5">
       0.6-0.9
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T10.7.2.6">
       0.5-0.9
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T10.7.2.7">
       0.5-0.9
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A1.T10.7.2.8">
       0.4-0.9
      </td>
     </tr>
    </table>
   </figure>
   <div class="ltx_para ltx_noindent" id="A1.SS5.p2">
    <p class="ltx_p" id="A1.SS5.p2.1">
     To verify whether the subgraph sampling strategy can maintain the consistency and diversity of scene captions, we generate scene captions for the same scene using both the full graph and subgraph. We then employ GPT-4
     <cite class="ltx_cite ltx_citemacro_citep">
      (OpenAI,
      <a class="ltx_ref" href="#bib.bib56" title="">
       2023
      </a>
      )
     </cite>
     to evaluate the similarities and differences between the two captions.
The results in
     <a class="ltx_ref" href="#A1.T11" title="In A.5 Subgraph Sampling ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Tab.
      </span>
      <span class="ltx_text ltx_ref_tag">
       11
      </span>
     </a>
     indicate that our subgraph sampling strategy can maintain both consistency and diversity.
    </p>
   </div>
   <figure class="ltx_table" id="A1.T11">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 11:
     </span>
     <span class="ltx_text ltx_font_bold" id="A1.T11.2.1">
      The comparative analysis of full graph prompting and subgraph prompting.
     </span>
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="A1.T11.3">
     <tr class="ltx_tr" id="A1.T11.3.1">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_tt" id="A1.T11.3.1.1">
       <span class="ltx_text ltx_font_bold" id="A1.T11.3.1.1.1">
        Settings
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A1.T11.3.1.2">
       <span class="ltx_inline-block ltx_align_top" id="A1.T11.3.1.2.1">
        <span class="ltx_p" id="A1.T11.3.1.2.1.1" style="width:284.5pt;">
         <span class="ltx_text ltx_font_bold" id="A1.T11.3.1.2.1.1.1">
          Generated Scene Captions
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T11.3.2">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T11.3.2.1">
       <span class="ltx_text ltx_font_bold" id="A1.T11.3.2.1.1">
        Full Graph
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T11.3.2.2">
       <span class="ltx_inline-block ltx_align_top" id="A1.T11.3.2.2.1">
        <span class="ltx_p" id="A1.T11.3.2.2.1.1" style="width:284.5pt;">
         In this scene, there is a colorful and flat white wall. A small TV stand is positioned in front of a low upholstered couch, to the left of a brown lamp, and to the right of a wooden table. The couch is covered with a pink padded square pillow and a patterned blanket. A light hangs on the wall and another light is supported by the table. There is a rectangular glass window attached to the wall, behind which is a yellow curtain. The room has a comfortable and cozy atmosphere, suitable for relaxation and entertainment.
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T11.3.3">
      <td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="A1.T11.3.3.1">
       <span class="ltx_text ltx_font_bold" id="A1.T11.3.3.1.1">
        Sampling Rate 0.6
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A1.T11.3.3.2">
       <span class="ltx_inline-block ltx_align_top" id="A1.T11.3.3.2.1">
        <span class="ltx_p" id="A1.T11.3.3.2.1.1" style="width:284.5pt;">
         In this scene, there is a colorful white wall attached to a brown wooden floor. The couch is upholstered and low in size, located to the right of a small TV stand and a table. A red blanket covers the couch, and there are patterned, padded square pillows on the couch. A black glass window is attached to the wall, and there are artificial lamps standing on the floor and close to the couch. The lamps are also near a table and to the right of the TV stand. The scene suggests a comfortable living room with a cozy couch, pillows, and a blanket, suitable for relaxation and entertainment.
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A1.T11.3.4">
      <td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r ltx_border_t" id="A1.T11.3.4.1">
       <span class="ltx_text ltx_font_bold" id="A1.T11.3.4.1.1">
        GPT-4 Evalutaion
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A1.T11.3.4.2">
       <span class="ltx_inline-block ltx_align_top" id="A1.T11.3.4.2.1">
        <span class="ltx_p" id="A1.T11.3.4.2.1.1" style="width:284.5pt;">
         <span class="ltx_text ltx_font_bold" id="A1.T11.3.4.2.1.1.1">
          Similarities:
         </span>
         1. Both scenes describe a living room setting, emphasizing comfort and coziness suitable for relaxation and entertainment.
2. Both rooms have a white wall.
3. Each scene features a couch and a TV stand.
4. Both scenes describe a blanket and a padded square pillow on the couch.
        </span>
        <span class="ltx_p" id="A1.T11.3.4.2.1.2">
         <span class="ltx_text ltx_font_bold" id="A1.T11.3.4.2.1.2.1">
          Differences:
         </span>
         1. The first scene has a brown wooden floor, while the floor is not mentioned in the second scene.
2. The first scene has a red blanket on the couch; the second has a patterned blanket but doesn’t specify the color.
3. The first scene describes the lamps as “standing on the floor”, while the second mentions one light hanging on the wall and another supported by the table.
4. The second scene includes a yellow curtain behind the window, which the first scene does not mention.
        </span>
        <span class="ltx_p" id="A1.T11.3.4.2.1.3">
         <span class="ltx_text ltx_font_bold" id="A1.T11.3.4.2.1.3.1">
          Summary:
         </span>
         Overall, both summaries provide a similar thematic view of a comfortable living room but differ in the specific arrangement and color details of the items within the room.
        </span>
       </span>
      </td>
     </tr>
    </table>
   </figure>
  </section>
  <section class="ltx_subsection" id="A1.SS6">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     A.6
    </span>
    Scene-graph-based Prompting
    <em class="ltx_emph ltx_font_italic" id="A1.SS6.1.1">
     vs
    </em>
    .
    <span class="ltx_text" id="A1.SS6.2.2">
    </span>
    Box-based Prompting
   </h3>
   <figure class="ltx_figure" id="A1.F11">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="186" id="A1.F11.g1" src="/html/2311.12871/assets/x10.png" width="422"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 11:
     </span>
     Comparison of the content between box-based and scene-graph-based prompting.
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="A1.F12">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="218" id="A1.F12.g1" src="/html/2311.12871/assets/x11.png" width="422"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 12:
     </span>
     The demonstrations for prompting, which are designed to be similar for a fair comparison.
    </figcaption>
   </figure>
   <figure class="ltx_figure" id="A1.F13">
    <img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="114" id="A1.F13.g1" src="/html/2311.12871/assets/x12.png" width="422"/>
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_figure">
      Figure 13:
     </span>
     The responses of two prompting methods. Descriptions highlighted in
     <span class="ltx_text" id="A1.F13.2.1" style="color:#FF0000;">
      red
     </span>
     show our method leads to more flexible and reliable spatial relations.
    </figcaption>
   </figure>
   <div class="ltx_para ltx_noindent" id="A1.SS6.p1">
    <p class="ltx_p" id="A1.SS6.p1.1">
     In this section, we provide a comparative analysis of scene-graph-based prompting and box-based prompting
     <cite class="ltx_cite ltx_citemacro_citep">
      (Hong et al.,
      <a class="ltx_ref" href="#bib.bib30" title="">
       2023
      </a>
      )
     </cite>
     . We refer the readers to Figure 6 in 3D-LLM
     <cite class="ltx_cite ltx_citemacro_citep">
      (Hong et al.,
      <a class="ltx_ref" href="#bib.bib30" title="">
       2023
      </a>
      )
     </cite>
     for details of the box-based prompting method.
     <a class="ltx_ref" href="#A1.F11" title="In A.6 Scene-graph-based Prompting vs. Box-based Prompting ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Fig.
      </span>
      <span class="ltx_text ltx_ref_tag">
       11
      </span>
     </a>
     shows the contents of two methods. To present a fair comparison between the two methods, we prompt with 1) demonstrations that have similar content under the same scene (see
     <a class="ltx_ref" href="#A1.F12" title="In A.6 Scene-graph-based Prompting vs. Box-based Prompting ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Fig.
      </span>
      <span class="ltx_text ltx_ref_tag">
       12
      </span>
     </a>
     ) and 2) identical new scene queries. Since 3D-LLM does not elaborate on attribute-related prompts, we mainly compare the spatial relations in the responses. As shown in
     <a class="ltx_ref" href="#A1.F13" title="In A.6 Scene-graph-based Prompting vs. Box-based Prompting ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Fig.
      </span>
      <span class="ltx_text ltx_ref_tag">
       13
      </span>
     </a>
     , we highlight some spatial relations in
     <span class="ltx_text" id="A1.SS6.p1.1.1" style="color:#FF0000;">
      red
     </span>
     . The comparison shows that our method provides more diverse and reliable spatial relations, which are important for 3D scene understanding.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="A1.SS7">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     A.7
    </span>
    Dataset Statistics
   </h3>
   <figure class="ltx_figure" id="A1.F15">
    <div class="ltx_flex_figure">
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="A1.F15.1" style="width:178.9pt;">
       <img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="517" id="A1.F15.1.g1" src="/html/2311.12871/assets/figs/Rscan_qa_question_stat.png" width="548"/>
       <figcaption class="ltx_caption">
        <span class="ltx_tag ltx_tag_figure">
         Figure 14:
        </span>
        Question types: 3RQA.
       </figcaption>
      </figure>
     </div>
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="A1.F15.2" style="width:178.9pt;">
       <img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="493" id="A1.F15.2.g1" src="/html/2311.12871/assets/figs/Rscan_dialogue_question_stat.png" width="548"/>
       <figcaption class="ltx_caption">
        <span class="ltx_tag ltx_tag_figure">
         Figure 15:
        </span>
        Question types: 3RDialog.
       </figcaption>
      </figure>
     </div>
    </div>
   </figure>
   <figure class="ltx_figure" id="A1.F17">
    <div class="ltx_flex_figure">
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="A1.F17.1" style="width:178.9pt;">
       <img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="540" id="A1.F17.1.g1" src="/html/2311.12871/assets/figs/Rscan_dialogue_noun_verb_instruction_stat.png" width="548"/>
       <figcaption class="ltx_caption">
        <span class="ltx_tag ltx_tag_figure">
         Figure 16:
        </span>
        Noun-verb pairs: 3RDialog instruction.
       </figcaption>
      </figure>
     </div>
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="A1.F17.2" style="width:178.9pt;">
       <img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="528" id="A1.F17.2.g1" src="/html/2311.12871/assets/figs/Rscan_plan_noun_verb_instruction_stat.png" width="548"/>
       <figcaption class="ltx_caption">
        <span class="ltx_tag ltx_tag_figure">
         Figure 17:
        </span>
        Noun-verb pairs: 3RPlan instruction.
       </figcaption>
      </figure>
     </div>
    </div>
   </figure>
   <figure class="ltx_figure" id="A1.F19">
    <div class="ltx_flex_figure">
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="A1.F19.1" style="width:178.9pt;">
       <img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="516" id="A1.F19.1.g1" src="/html/2311.12871/assets/figs/Rscan_dialogue_noun_verb_response_stat.png" width="548"/>
       <figcaption class="ltx_caption">
        <span class="ltx_tag ltx_tag_figure">
         Figure 18:
        </span>
        Noun-verb pairs: 3RDialog response.
       </figcaption>
      </figure>
     </div>
     <div class="ltx_flex_cell ltx_flex_size_2">
      <figure class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_bottom" id="A1.F19.2" style="width:178.9pt;">
       <img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="539" id="A1.F19.2.g1" src="/html/2311.12871/assets/figs/Rscan_plan_noun_verb_response_stat.png" width="548"/>
       <figcaption class="ltx_caption">
        <span class="ltx_tag ltx_tag_figure">
         Figure 19:
        </span>
        Noun-verb pairs: 3RPlan response.
       </figcaption>
      </figure>
     </div>
    </div>
   </figure>
   <div class="ltx_para ltx_noindent" id="A1.SS7.p1">
    <p class="ltx_p" id="A1.SS7.p1.1">
     We provide statistics on the instruction-tuning datasets. We visualize the distribution of the question types in 3RQA (
     <a class="ltx_ref" href="#A1.F15" title="In A.7 Dataset Statistics ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Fig.
      </span>
      <span class="ltx_text ltx_ref_tag">
       15
      </span>
     </a>
     ) and 3RDialog (
     <a class="ltx_ref" href="#A1.F15" title="In A.7 Dataset Statistics ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Fig.
      </span>
      <span class="ltx_text ltx_ref_tag">
       15
      </span>
     </a>
     ). The pie chart’s inner circle represents the first word of the questions, while the outer circle accounts for the second or third word in the corresponding questions. The results show that the questions cover the attributes and spatial relations of the objects, as well as high-level topics such as room types and functionalities.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A1.SS7.p2">
    <p class="ltx_p" id="A1.SS7.p2.1">
     We also provide statistics of the root noun-verb pairs for instructions and responses in 3RDialog and 3RPlan, as shown in
     <a class="ltx_ref" href="#A1.F17" title="In A.7 Dataset Statistics ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Fig.
      </span>
      <span class="ltx_text ltx_ref_tag">
       17
      </span>
     </a>
     –
     <a class="ltx_ref" href="#A1.F19" title="Figure 19 ‣ A.7 Dataset Statistics ‣ Appendix A Data ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       19
      </span>
     </a>
     .
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_appendix" id="A2">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix B
   </span>
   Action Tokenization
  </h2>
  <div class="ltx_para ltx_noindent" id="A2.p1">
   <p class="ltx_p" id="A2.p1.1">
    To empower
    <span class="ltx_text ltx_font_smallcaps" id="A2.p1.1.1">
     LEO
    </span>
    to exert control over an embodiment or a robot, we encode all actions within the context of Object Navigation
    <cite class="ltx_cite ltx_citemacro_citep">
     (Ramrakhya et al.,
     <a class="ltx_ref" href="#bib.bib64" title="">
      2022
     </a>
     )
    </cite>
    and CLIPort
    <cite class="ltx_cite ltx_citemacro_citep">
     (Shridhar et al.,
     <a class="ltx_ref" href="#bib.bib72" title="">
      2021
     </a>
     )
    </cite>
    tasks using the least frequently employed language tokens. Specifically, for the Object Navigation task, we allocate 4 tokens to represent actions of
    <span class="ltx_text ltx_font_italic" id="A2.p1.1.2">
     move forward
    </span>
    ,
    <span class="ltx_text ltx_font_italic" id="A2.p1.1.3">
     turn right
    </span>
    ,
    <span class="ltx_text ltx_font_italic" id="A2.p1.1.4">
     turn left
    </span>
    , and
    <span class="ltx_text ltx_font_italic" id="A2.p1.1.5">
     stop
    </span>
    . For the CLIPort task, we use a total of 516 tokens to discretize action poses, with 320 tokens dedicated to the x-axis pose bins, 160 tokens for the y-axis pose bins, and 36 tokens for the z-rotation bins.
   </p>
  </div>
 </section>
 <section class="ltx_appendix" id="A3">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix C
   </span>
   Data Examples
  </h2>
  <div class="ltx_para ltx_noindent" id="A3.p1">
   <p class="ltx_p" id="A3.p1.1">
    Please refer to
    <a class="ltx_ref" href="#A9.T24" title="In I.4 SQA3D ‣ Appendix I Additional Results ‣ An Embodied Generalist Agent in 3D World">
     <span class="ltx_text ltx_ref_tag">
      Tabs.
     </span>
     <span class="ltx_text ltx_ref_tag">
      24
     </span>
    </a>
    –
    <a class="ltx_ref" href="#A9.T26" title="Table 26 ‣ I.4 SQA3D ‣ Appendix I Additional Results ‣ An Embodied Generalist Agent in 3D World">
     <span class="ltx_text ltx_ref_tag">
      26
     </span>
    </a>
    for examples of our dataset.
   </p>
  </div>
 </section>
 <section class="ltx_appendix" id="A4">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix D
   </span>
   Model Details
  </h2>
  <section class="ltx_subsection" id="A4.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     D.1
    </span>
    Prompts
   </h3>
   <div class="ltx_para ltx_noindent" id="A4.SS1.p1">
    <p class="ltx_p" id="A4.SS1.p1.1">
     The first portion of prompts sent into the LLM is a
     <span class="ltx_text ltx_font_bold" id="A4.SS1.p1.1.1">
      system message
     </span>
     . It consists of two parts: a role prompt and a situation prompt. The role prompt is the same for all tasks:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A4.SS1.p2">
    <svg class="ltx_picture" height="74.45" id="A4.SS1.p2.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,74.45) matrix(1 0 0 -1 0 0)">
      <g fill="#404040" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 68.55 C 0 71.81 2.64 74.45 5.91 74.45 L 594.09 74.45 C 597.36 74.45 600 71.81 600 68.55 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#F2F2F2" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 68.55 C 1.97 70.72 3.73 72.48 5.91 72.48 L 594.09 72.48 C 596.27 72.48 598.03 70.72 598.03 68.55 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject color="#000000" height="46.89" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
        <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A4.SS1.p2.pic1.1.1.1.1.1" style="width:402.3pt;">
         <span class="ltx_p ltx_minipage ltx_align_middle" id="A4.SS1.p2.pic1.1.1.1.1.1.1" style="width:433.6pt;">
          You are an AI visual assistant situated in a 3D scene. You can perceive (1) an ego-view image (accessible when necessary) and (2) the objects (including yourself) in the scene (always accessible). You should properly respond to the USER’s instructions according to the given visual information.
         </span>
        </span>
       </foreignobject>
      </g>
     </g>
    </svg>
   </div>
   <div class="ltx_para ltx_noindent" id="A4.SS1.p3">
    <p class="ltx_p" id="A4.SS1.p3.1">
     The situation prompt begins with a common sentence:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A4.SS1.p4">
    <svg class="ltx_picture" height="44.16" id="A4.SS1.p4.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,44.16) matrix(1 0 0 -1 0 0)">
      <g fill="#404040" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 38.26 C 0 41.52 2.64 44.16 5.91 44.16 L 594.09 44.16 C 597.36 44.16 600 41.52 600 38.26 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#F2F2F2" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 38.26 C 1.97 40.43 3.73 42.19 5.91 42.19 L 594.09 42.19 C 596.27 42.19 598.03 40.43 598.03 38.26 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject color="#000000" height="16.6" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
        <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A4.SS1.p4.pic1.1.1.1.1.1" style="width:402.3pt;">
         <span class="ltx_p ltx_minipage ltx_align_middle" id="A4.SS1.p4.pic1.1.1.1.1.1.1" style="width:433.6pt;">
          You are at a selected location in the 3D scene.
         </span>
        </span>
       </foreignobject>
      </g>
     </g>
    </svg>
   </div>
   <div class="ltx_para ltx_noindent" id="A4.SS1.p5">
    <p class="ltx_p" id="A4.SS1.p5.1">
     For SQA3D
     <cite class="ltx_cite ltx_citemacro_citep">
      (Ma et al.,
      <a class="ltx_ref" href="#bib.bib51" title="">
       2023
      </a>
      )
     </cite>
     , the situation prompt is further extended with the situation description in the dataset. The situation prompt is only used jointly with the embodiment token to support tasks that require information about the embodiment. Details can be found in
     <a class="ltx_ref" href="#A4.SS2.SSS1" title="D.2.1 Embodiment Encoding ‣ D.2 Feature Encoding ‣ Appendix D Model Details ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Sec.
      </span>
      <span class="ltx_text ltx_ref_tag">
       D.2.1
      </span>
     </a>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A4.SS1.p6">
    <p class="ltx_p" id="A4.SS1.p6.1">
     Next are the
     <span class="ltx_text ltx_font_bold" id="A4.SS1.p6.1.1">
      visual tokens
     </span>
     , including
     <span class="ltx_text ltx_font_bold" id="A4.SS1.p6.1.2">
      2D image tokens
     </span>
     and
     <span class="ltx_text ltx_font_bold" id="A4.SS1.p6.1.3">
      object-centric 3D tokens
     </span>
     . Each token sequence is interleaved within text tokens and starts with a text prefix.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A4.SS1.p7">
    <svg class="ltx_picture" height="59.38" id="A4.SS1.p7.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,59.38) matrix(1 0 0 -1 0 0)">
      <g fill="#404040" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 53.48 C 0 56.74 2.64 59.38 5.91 59.38 L 594.09 59.38 C 597.36 59.38 600 56.74 600 53.48 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#F2F2F2" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 53.48 C 1.97 55.65 3.73 57.42 5.91 57.42 L 594.09 57.42 C 596.27 57.42 598.03 55.65 598.03 53.48 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject color="#000000" height="31.83" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
        <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A4.SS1.p7.pic1.1.1.1.1.1" style="width:402.3pt;">
         <span class="ltx_block ltx_minipage ltx_align_middle" id="A4.SS1.p7.pic1.1.1.1.1.1.1" style="width:433.6pt;">
          <span class="ltx_p" id="A4.SS1.p7.pic1.1.1.1.1.1.1.1">
           Ego-view image: {
           <span class="ltx_text ltx_font_typewriter" id="A4.SS1.p7.pic1.1.1.1.1.1.1.1.1">
            IMAGE_TOKENS
           </span>
           }
          </span>
          <span class="ltx_p" id="A4.SS1.p7.pic1.1.1.1.1.1.1.2">
           Objects (including you) in the scene: {
           <span class="ltx_text ltx_font_typewriter" id="A4.SS1.p7.pic1.1.1.1.1.1.1.2.1">
            OBJECT_TOKENS
           </span>
           }
          </span>
         </span>
        </span>
       </foreignobject>
      </g>
     </g>
    </svg>
   </div>
   <div class="ltx_para ltx_noindent" id="A4.SS1.p8">
    <p class="ltx_p" id="A4.SS1.p8.1">
     The last portion of prompts is a
     <span class="ltx_text ltx_font_bold" id="A4.SS1.p8.1.1">
      task-specific instruction
     </span>
     . For
     <span class="ltx_text ltx_font_bold" id="A4.SS1.p8.1.2">
      object-level caption
     </span>
     and
     <span class="ltx_text ltx_font_bold" id="A4.SS1.p8.1.3">
      object-in-the-scene caption
     </span>
     , we randomly chose one sentence from 151 sentences to be the instruction. Some examples can be found in
     <a class="ltx_ref" href="#A4.T12" title="In D.1 Prompts ‣ Appendix D Model Details ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Tab.
      </span>
      <span class="ltx_text ltx_ref_tag">
       12
      </span>
     </a>
     . For
     <span class="ltx_text ltx_font_bold" id="A4.SS1.p8.1.4">
      scene-level caption
     </span>
     , we randomly choose one from 183 instructions. Examples can be found in
     <a class="ltx_ref" href="#A4.T13" title="In D.1 Prompts ‣ Appendix D Model Details ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Tab.
      </span>
      <span class="ltx_text ltx_ref_tag">
       13
      </span>
     </a>
     . For
     <span class="ltx_text ltx_font_bold" id="A4.SS1.p8.1.5">
      3D question answering
     </span>
     task, we simply use the question as the instruction. The dialog history is used as the instruction for
     <span class="ltx_text ltx_font_bold" id="A4.SS1.p8.1.6">
      3D dialogue
     </span>
     to provide continuity across multiple rounds of interactions. A planning instruction pool consisting of 202 instructions is introduced for
     <span class="ltx_text ltx_font_bold" id="A4.SS1.p8.1.7">
      scene-aware task planning
     </span>
     and we randomly choose one from it as done in the caption tasks. Examples from the pool can be found in
     <a class="ltx_ref" href="#A4.T14" title="In D.1 Prompts ‣ Appendix D Model Details ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Tab.
      </span>
      <span class="ltx_text ltx_ref_tag">
       14
      </span>
     </a>
     . The chosen instruction is further followed by an instruction that specifies the task,
     <em class="ltx_emph ltx_font_italic" id="A4.SS1.p8.1.8">
      e.g
     </em>
     .
     <span class="ltx_text" id="A4.SS1.p8.1.9">
     </span>
     ,
     <span class="ltx_text ltx_font_italic" id="A4.SS1.p8.1.10">
      set up a home office
     </span>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A4.SS1.p9">
    <p class="ltx_p" id="A4.SS1.p9.1">
     With past action tokens {
     <span class="ltx_text ltx_font_typewriter" id="A4.SS1.p9.1.1">
      PAST_ACTIONS
     </span>
     } appended at the end, the instruction for
     <span class="ltx_text ltx_font_bold" id="A4.SS1.p9.1.2">
      embodied navigation
     </span>
     is as follows, where {
     <span class="ltx_text ltx_font_typewriter" id="A4.SS1.p9.1.3">
      GOAL
     </span>
     } stands for the goal specified by the target object name:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A4.SS1.p10">
    <svg class="ltx_picture" height="59.38" id="A4.SS1.p10.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,59.38) matrix(1 0 0 -1 0 0)">
      <g fill="#404040" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 53.48 C 0 56.74 2.64 59.38 5.91 59.38 L 594.09 59.38 C 597.36 59.38 600 56.74 600 53.48 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#F2F2F2" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 53.48 C 1.97 55.65 3.73 57.42 5.91 57.42 L 594.09 57.42 C 596.27 57.42 598.03 55.65 598.03 53.48 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject color="#000000" height="31.83" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
        <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A4.SS1.p10.pic1.1.1.1.1.1" style="width:402.3pt;">
         <span class="ltx_p ltx_minipage ltx_align_middle" id="A4.SS1.p10.pic1.1.1.1.1.1.1" style="width:433.6pt;">
          The task is navigation. Your goal is to find {
          <span class="ltx_text ltx_font_typewriter" id="A4.SS1.p10.pic1.1.1.1.1.1.1.1">
           GOAL
          </span>
          } by moving around in the scene. Past actions: {
          <span class="ltx_text ltx_font_typewriter" id="A4.SS1.p10.pic1.1.1.1.1.1.1.2">
           PAST_ACTIONS
          </span>
          }.
         </span>
        </span>
       </foreignobject>
      </g>
     </g>
    </svg>
   </div>
   <div class="ltx_para ltx_noindent" id="A4.SS1.p11">
    <p class="ltx_p" id="A4.SS1.p11.1">
     The instruction for
     <span class="ltx_text ltx_font_bold" id="A4.SS1.p11.1.1">
      robotic manipulation
     </span>
     is similar to the one in
     <span class="ltx_text ltx_font_bold" id="A4.SS1.p11.1.2">
      embodied navigation
     </span>
     . Here {
     <span class="ltx_text ltx_font_typewriter" id="A4.SS1.p11.1.3">
      GOAL
     </span>
     } is the task description in CLIPort:
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A4.SS1.p12">
    <svg class="ltx_picture" height="44.16" id="A4.SS1.p12.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,44.16) matrix(1 0 0 -1 0 0)">
      <g fill="#404040" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 38.26 C 0 41.52 2.64 44.16 5.91 44.16 L 594.09 44.16 C 597.36 44.16 600 41.52 600 38.26 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#F2F2F2" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 38.26 C 1.97 40.43 3.73 42.19 5.91 42.19 L 594.09 42.19 C 596.27 42.19 598.03 40.43 598.03 38.26 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject color="#000000" height="16.6" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
        <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A4.SS1.p12.pic1.1.1.1.1.1" style="width:402.3pt;">
         <span class="ltx_p ltx_minipage ltx_align_middle" id="A4.SS1.p12.pic1.1.1.1.1.1.1" style="width:433.6pt;">
          The task is manipulation. Your goal is to {
          <span class="ltx_text ltx_font_typewriter" id="A4.SS1.p12.pic1.1.1.1.1.1.1.1">
           GOAL
          </span>
          }. Past actions: {
          <span class="ltx_text ltx_font_typewriter" id="A4.SS1.p12.pic1.1.1.1.1.1.1.2">
           PAST_ACTIONS
          </span>
          }.
         </span>
        </span>
       </foreignobject>
      </g>
     </g>
    </svg>
   </div>
   <figure class="ltx_table" id="A4.T12">
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_table">
      Table 12:
     </span>
     <span class="ltx_text ltx_font_bold" id="A4.T12.2.1">
      Examples from our object-level caption instruction set.
     </span>
    </figcaption>
    <svg class="ltx_picture" height="307.07" id="A4.T12.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,307.07) matrix(1 0 0 -1 0 0)">
      <g fill="#404040" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 301.16 C 0 304.42 2.64 307.07 5.91 307.07 L 594.09 307.07 C 597.36 307.07 600 304.42 600 301.16 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#F2F2F2" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 301.16 C 1.97 303.34 3.73 305.1 5.91 305.1 L 594.09 305.1 C 596.27 305.1 598.03 303.34 598.03 301.16 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject color="#000000" height="279.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
        <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A4.T12.pic1.1.1.1.1.1" style="width:402.3pt;">
         <span class="ltx_block ltx_minipage ltx_align_middle" id="A4.T12.pic1.1.1.1.1.1.1" style="width:433.6pt;">
          <span class="ltx_p" id="A4.T12.pic1.1.1.1.1.1.1.1">
           "Produce a description for the object at the chosen spot in the 3D scene.",
          </span>
          <span class="ltx_p" id="A4.T12.pic1.1.1.1.1.1.1.2">
           "How would you depict the object located at the selected point in the 3D environment?",
          </span>
          <span class="ltx_p" id="A4.T12.pic1.1.1.1.1.1.1.3">
           "Formulate a description of the item at the picked position within the 3D scene.",
          </span>
          <span class="ltx_p" id="A4.T12.pic1.1.1.1.1.1.1.4">
           "How would you describe the entity at the designated location in the 3D backdrop?",
          </span>
          <span class="ltx_p" id="A4.T12.pic1.1.1.1.1.1.1.5">
           "Can you detail the object situated at the selected point in the 3D setting?",
          </span>
          <span class="ltx_p" id="A4.T12.pic1.1.1.1.1.1.1.6">
           "Compose a narrative for the object at the chosen locale within the 3D environment.",
          </span>
          <span class="ltx_p" id="A4.T12.pic1.1.1.1.1.1.1.7">
           "What does the object at the specified position in the 3D visualization look like?",
          </span>
          <span class="ltx_p" id="A4.T12.pic1.1.1.1.1.1.1.8">
           "Provide a description for the item located at the marked site in the 3D world.",
          </span>
          <span class="ltx_p" id="A4.T12.pic1.1.1.1.1.1.1.9">
           "How would you illustrate the object placed at the selected spot in the 3D landscape?",
          </span>
          <span class="ltx_p" id="A4.T12.pic1.1.1.1.1.1.1.10">
           "Craft a depiction of the object at the pinpointed location within the 3D territory.",
          </span>
          <span class="ltx_p" id="A4.T12.pic1.1.1.1.1.1.1.11">
           "What kind of object is illustrated at the identified site in the 3D tableau?",
          </span>
          <span class="ltx_p" id="A4.T12.pic1.1.1.1.1.1.1.12">
           "Develop a description of the object at the specified position in the 3D backdrop.",
          </span>
          <span class="ltx_p" id="A4.T12.pic1.1.1.1.1.1.1.13">
           "What is the entity’s detail at the highlighted site in the 3D view?",
          </span>
          <span class="ltx_p" id="A4.T12.pic1.1.1.1.1.1.1.14">
           "Write up a description of the entity at the selected spot in the 3D realm.",
          </span>
          <span class="ltx_p" id="A4.T12.pic1.1.1.1.1.1.1.15">
           "What does the object look like at the pinpointed location in the 3D space?",
          </span>
          <span class="ltx_p" id="A4.T12.pic1.1.1.1.1.1.1.16">
           "Detail the entity located at the chosen position within the 3D scene.",
          </span>
          <span class="ltx_p" id="A4.T12.pic1.1.1.1.1.1.1.17">
           "Can you explain the essence of the object at the selected spot in the 3D zone?",
          </span>
         </span>
        </span>
       </foreignobject>
      </g>
     </g>
    </svg>
   </figure>
   <figure class="ltx_table" id="A4.T13">
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_table">
      Table 13:
     </span>
     <span class="ltx_text ltx_font_bold" id="A4.T13.2.1">
      Examples from our scene-level caption instruction set.
     </span>
    </figcaption>
    <svg class="ltx_picture" height="307.07" id="A4.T13.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,307.07) matrix(1 0 0 -1 0 0)">
      <g fill="#404040" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 301.16 C 0 304.42 2.64 307.07 5.91 307.07 L 594.09 307.07 C 597.36 307.07 600 304.42 600 301.16 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#F2F2F2" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 301.16 C 1.97 303.34 3.73 305.1 5.91 305.1 L 594.09 305.1 C 596.27 305.1 598.03 303.34 598.03 301.16 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject color="#000000" height="279.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
        <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A4.T13.pic1.1.1.1.1.1" style="width:402.3pt;">
         <span class="ltx_block ltx_minipage ltx_align_middle" id="A4.T13.pic1.1.1.1.1.1.1" style="width:433.6pt;">
          <span class="ltx_p" id="A4.T13.pic1.1.1.1.1.1.1.1">
           "Describe this scene.",
          </span>
          <span class="ltx_p" id="A4.T13.pic1.1.1.1.1.1.1.2">
           "Generate a description of this scene.",
          </span>
          <span class="ltx_p" id="A4.T13.pic1.1.1.1.1.1.1.3">
           "Generate a caption of this scene.",
          </span>
          <span class="ltx_p" id="A4.T13.pic1.1.1.1.1.1.1.4">
           "Can you describe the scene?",
          </span>
          <span class="ltx_p" id="A4.T13.pic1.1.1.1.1.1.1.5">
           "Can you generate a description of the scene?",
          </span>
          <span class="ltx_p" id="A4.T13.pic1.1.1.1.1.1.1.6">
           "Can you generate a caption of the scene?",
          </span>
          <span class="ltx_p" id="A4.T13.pic1.1.1.1.1.1.1.7">
           "Summarize this scene.",
          </span>
          <span class="ltx_p" id="A4.T13.pic1.1.1.1.1.1.1.8">
           "Provide an outline of this 3D scene’s characteristics.",
          </span>
          <span class="ltx_p" id="A4.T13.pic1.1.1.1.1.1.1.9">
           "How would you describe the 3D scene?",
          </span>
          <span class="ltx_p" id="A4.T13.pic1.1.1.1.1.1.1.10">
           "How would you summarize this scene?",
          </span>
          <span class="ltx_p" id="A4.T13.pic1.1.1.1.1.1.1.11">
           "Convey a summary of the 3D structure of this scene.",
          </span>
          <span class="ltx_p" id="A4.T13.pic1.1.1.1.1.1.1.12">
           "How would you interpret this 3D scene?",
          </span>
          <span class="ltx_p" id="A4.T13.pic1.1.1.1.1.1.1.13">
           "Offer a summary of the 3D scene.",
          </span>
          <span class="ltx_p" id="A4.T13.pic1.1.1.1.1.1.1.14">
           "Can you describe this scene in detail?",
          </span>
          <span class="ltx_p" id="A4.T13.pic1.1.1.1.1.1.1.15">
           "I’m interested in this scene, can you explain?",
          </span>
          <span class="ltx_p" id="A4.T13.pic1.1.1.1.1.1.1.16">
           "What is this scene made of?",
          </span>
          <span class="ltx_p" id="A4.T13.pic1.1.1.1.1.1.1.17">
           "Could you provide more info about this scene?",
          </span>
         </span>
        </span>
       </foreignobject>
      </g>
     </g>
    </svg>
   </figure>
   <figure class="ltx_table" id="A4.T14">
    <figcaption class="ltx_caption">
     <span class="ltx_tag ltx_tag_table">
      Table 14:
     </span>
     <span class="ltx_text ltx_font_bold" id="A4.T14.2.1">
      Examples from our planning instruction pool.
     </span>
    </figcaption>
    <svg class="ltx_picture" height="307.07" id="A4.T14.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,307.07) matrix(1 0 0 -1 0 0)">
      <g fill="#404040" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 301.16 C 0 304.42 2.64 307.07 5.91 307.07 L 594.09 307.07 C 597.36 307.07 600 304.42 600 301.16 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#F2F2F2" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 301.16 C 1.97 303.34 3.73 305.1 5.91 305.1 L 594.09 305.1 C 596.27 305.1 598.03 303.34 598.03 301.16 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject color="#000000" height="279.51" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
        <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A4.T14.pic1.1.1.1.1.1" style="width:402.3pt;">
         <span class="ltx_block ltx_minipage ltx_align_middle" id="A4.T14.pic1.1.1.1.1.1.1" style="width:433.6pt;">
          <span class="ltx_p" id="A4.T14.pic1.1.1.1.1.1.1.1">
           "Plan for the task",
          </span>
          <span class="ltx_p" id="A4.T14.pic1.1.1.1.1.1.1.2">
           "Can you come up with a plan for this task",
          </span>
          <span class="ltx_p" id="A4.T14.pic1.1.1.1.1.1.1.3">
           "How can we do this task, provide a step-by-step plan",
          </span>
          <span class="ltx_p" id="A4.T14.pic1.1.1.1.1.1.1.4">
           "Draft a plan for completing this task",
          </span>
          <span class="ltx_p" id="A4.T14.pic1.1.1.1.1.1.1.5">
           "Detail a strategy for the task",
          </span>
          <span class="ltx_p" id="A4.T14.pic1.1.1.1.1.1.1.6">
           "What’s the best plan for this task",
          </span>
          <span class="ltx_p" id="A4.T14.pic1.1.1.1.1.1.1.7">
           "Draw out a procedure for the task",
          </span>
          <span class="ltx_p" id="A4.T14.pic1.1.1.1.1.1.1.8">
           "Lay out the steps for this task",
          </span>
          <span class="ltx_p" id="A4.T14.pic1.1.1.1.1.1.1.9">
           "Could you devise a plan for the task",
          </span>
          <span class="ltx_p" id="A4.T14.pic1.1.1.1.1.1.1.10">
           "Show me a plan for this task",
          </span>
          <span class="ltx_p" id="A4.T14.pic1.1.1.1.1.1.1.11">
           "I need a plan for the task",
          </span>
          <span class="ltx_p" id="A4.T14.pic1.1.1.1.1.1.1.12">
           "Sketch a plan for the task at hand",
          </span>
          <span class="ltx_p" id="A4.T14.pic1.1.1.1.1.1.1.13">
           "Set up a plan for this",
          </span>
          <span class="ltx_p" id="A4.T14.pic1.1.1.1.1.1.1.14">
           "Recommend a plan for this task",
          </span>
          <span class="ltx_p" id="A4.T14.pic1.1.1.1.1.1.1.15">
           "Offer a strategy for this task",
          </span>
          <span class="ltx_p" id="A4.T14.pic1.1.1.1.1.1.1.16">
           "Design a blueprint for the task",
          </span>
          <span class="ltx_p" id="A4.T14.pic1.1.1.1.1.1.1.17">
           "Outline the approach for this task",
          </span>
         </span>
        </span>
       </foreignobject>
      </g>
     </g>
    </svg>
   </figure>
  </section>
  <section class="ltx_subsection" id="A4.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     D.2
    </span>
    Feature Encoding
   </h3>
   <div class="ltx_para ltx_noindent" id="A4.SS2.p1">
    <p class="ltx_p" id="A4.SS2.p1.1">
     We have several modules to encode the multi-modal features.
    </p>
    <ul class="ltx_itemize" id="A4.I1">
     <li class="ltx_item" id="A4.I1.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para ltx_noindent" id="A4.I1.i1.p1">
       <p class="ltx_p" id="A4.I1.i1.p1.1">
        <span class="ltx_text ltx_font_bold" id="A4.I1.i1.p1.1.1">
         Object-centric 3D token embedding.
        </span>
        The encoder for 3D object-centric point clouds is a PointNet++
        <cite class="ltx_cite ltx_citemacro_citep">
         (Qi et al.,
         <a class="ltx_ref" href="#bib.bib60" title="">
          2017
         </a>
         )
        </cite>
        pre-trained on ScanNet
        <cite class="ltx_cite ltx_citemacro_citep">
         (Dai et al.,
         <a class="ltx_ref" href="#bib.bib20" title="">
          2017
         </a>
         )
        </cite>
        with object-classfication task. We sample 1024 points for every object as in
        <cite class="ltx_cite ltx_citemacro_cite">
         Chen et al. (
         <a class="ltx_ref" href="#bib.bib15" title="">
          2022
         </a>
         )
        </cite>
        . The architecture parameters all remain the same with
        <cite class="ltx_cite ltx_citemacro_cite">
         Chen et al. (
         <a class="ltx_ref" href="#bib.bib15" title="">
          2022
         </a>
         )
        </cite>
        . We freeze the PointNet++ for empirically better results.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A4.I1.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para ltx_noindent" id="A4.I1.i2.p1">
       <p class="ltx_p" id="A4.I1.i2.p1.11">
        <span class="ltx_text ltx_font_bold" id="A4.I1.i2.p1.11.1">
         Spatial Transformer
         <cite class="ltx_cite ltx_citemacro_citep">
          (Chen et al.,
          <a class="ltx_ref" href="#bib.bib15" title="">
           2022
          </a>
          )
         </cite>
         .
        </span>
        Spatial Transformer is a modified transformer architecture that explicitly encodes spatial relations between object pairs. Specifically, consider the vanilla self-attention
        <cite class="ltx_cite ltx_citemacro_citep">
         (Vaswani et al.,
         <a class="ltx_ref" href="#bib.bib76" title="">
          2017
         </a>
         )
        </cite>
        mechanism which takes as input a feature matrix
        <math alttext="X\in\mathbf{R}^{N\times d}" class="ltx_Math" display="inline" id="A4.I1.i2.p1.1.m1.1">
         <semantics id="A4.I1.i2.p1.1.m1.1a">
          <mrow id="A4.I1.i2.p1.1.m1.1.1" xref="A4.I1.i2.p1.1.m1.1.1.cmml">
           <mi id="A4.I1.i2.p1.1.m1.1.1.2" xref="A4.I1.i2.p1.1.m1.1.1.2.cmml">
            X
           </mi>
           <mo id="A4.I1.i2.p1.1.m1.1.1.1" xref="A4.I1.i2.p1.1.m1.1.1.1.cmml">
            ∈
           </mo>
           <msup id="A4.I1.i2.p1.1.m1.1.1.3" xref="A4.I1.i2.p1.1.m1.1.1.3.cmml">
            <mi id="A4.I1.i2.p1.1.m1.1.1.3.2" xref="A4.I1.i2.p1.1.m1.1.1.3.2.cmml">
             𝐑
            </mi>
            <mrow id="A4.I1.i2.p1.1.m1.1.1.3.3" xref="A4.I1.i2.p1.1.m1.1.1.3.3.cmml">
             <mi id="A4.I1.i2.p1.1.m1.1.1.3.3.2" xref="A4.I1.i2.p1.1.m1.1.1.3.3.2.cmml">
              N
             </mi>
             <mo id="A4.I1.i2.p1.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="A4.I1.i2.p1.1.m1.1.1.3.3.1.cmml">
              ×
             </mo>
             <mi id="A4.I1.i2.p1.1.m1.1.1.3.3.3" xref="A4.I1.i2.p1.1.m1.1.1.3.3.3.cmml">
              d
             </mi>
            </mrow>
           </msup>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p1.1.m1.1b">
           <apply id="A4.I1.i2.p1.1.m1.1.1.cmml" xref="A4.I1.i2.p1.1.m1.1.1">
            <in id="A4.I1.i2.p1.1.m1.1.1.1.cmml" xref="A4.I1.i2.p1.1.m1.1.1.1">
            </in>
            <ci id="A4.I1.i2.p1.1.m1.1.1.2.cmml" xref="A4.I1.i2.p1.1.m1.1.1.2">
             𝑋
            </ci>
            <apply id="A4.I1.i2.p1.1.m1.1.1.3.cmml" xref="A4.I1.i2.p1.1.m1.1.1.3">
             <csymbol cd="ambiguous" id="A4.I1.i2.p1.1.m1.1.1.3.1.cmml" xref="A4.I1.i2.p1.1.m1.1.1.3">
              superscript
             </csymbol>
             <ci id="A4.I1.i2.p1.1.m1.1.1.3.2.cmml" xref="A4.I1.i2.p1.1.m1.1.1.3.2">
              𝐑
             </ci>
             <apply id="A4.I1.i2.p1.1.m1.1.1.3.3.cmml" xref="A4.I1.i2.p1.1.m1.1.1.3.3">
              <times id="A4.I1.i2.p1.1.m1.1.1.3.3.1.cmml" xref="A4.I1.i2.p1.1.m1.1.1.3.3.1">
              </times>
              <ci id="A4.I1.i2.p1.1.m1.1.1.3.3.2.cmml" xref="A4.I1.i2.p1.1.m1.1.1.3.3.2">
               𝑁
              </ci>
              <ci id="A4.I1.i2.p1.1.m1.1.1.3.3.3.cmml" xref="A4.I1.i2.p1.1.m1.1.1.3.3.3">
               𝑑
              </ci>
             </apply>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p1.1.m1.1c">
           X\in\mathbf{R}^{N\times d}
          </annotation>
         </semantics>
        </math>
        , where
        <math alttext="N" class="ltx_Math" display="inline" id="A4.I1.i2.p1.2.m2.1">
         <semantics id="A4.I1.i2.p1.2.m2.1a">
          <mi id="A4.I1.i2.p1.2.m2.1.1" xref="A4.I1.i2.p1.2.m2.1.1.cmml">
           N
          </mi>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p1.2.m2.1b">
           <ci id="A4.I1.i2.p1.2.m2.1.1.cmml" xref="A4.I1.i2.p1.2.m2.1.1">
            𝑁
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p1.2.m2.1c">
           N
          </annotation>
         </semantics>
        </math>
        stands for the number of tokens and
        <math alttext="d" class="ltx_Math" display="inline" id="A4.I1.i2.p1.3.m3.1">
         <semantics id="A4.I1.i2.p1.3.m3.1a">
          <mi id="A4.I1.i2.p1.3.m3.1.1" xref="A4.I1.i2.p1.3.m3.1.1.cmml">
           d
          </mi>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p1.3.m3.1b">
           <ci id="A4.I1.i2.p1.3.m3.1.1.cmml" xref="A4.I1.i2.p1.3.m3.1.1">
            𝑑
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p1.3.m3.1c">
           d
          </annotation>
         </semantics>
        </math>
        is the feature dimension. Vanilla self-attention first compute
        <math alttext="Q=XW_{Q},K=XW_{K},V=XW_{V}" class="ltx_Math" display="inline" id="A4.I1.i2.p1.4.m4.2">
         <semantics id="A4.I1.i2.p1.4.m4.2a">
          <mrow id="A4.I1.i2.p1.4.m4.2.2.2" xref="A4.I1.i2.p1.4.m4.2.2.3.cmml">
           <mrow id="A4.I1.i2.p1.4.m4.1.1.1.1" xref="A4.I1.i2.p1.4.m4.1.1.1.1.cmml">
            <mi id="A4.I1.i2.p1.4.m4.1.1.1.1.2" xref="A4.I1.i2.p1.4.m4.1.1.1.1.2.cmml">
             Q
            </mi>
            <mo id="A4.I1.i2.p1.4.m4.1.1.1.1.1" xref="A4.I1.i2.p1.4.m4.1.1.1.1.1.cmml">
             =
            </mo>
            <mrow id="A4.I1.i2.p1.4.m4.1.1.1.1.3" xref="A4.I1.i2.p1.4.m4.1.1.1.1.3.cmml">
             <mi id="A4.I1.i2.p1.4.m4.1.1.1.1.3.2" xref="A4.I1.i2.p1.4.m4.1.1.1.1.3.2.cmml">
              X
             </mi>
             <mo id="A4.I1.i2.p1.4.m4.1.1.1.1.3.1" lspace="0em" rspace="0em" xref="A4.I1.i2.p1.4.m4.1.1.1.1.3.1.cmml">
              ​
             </mo>
             <msub id="A4.I1.i2.p1.4.m4.1.1.1.1.3.3" xref="A4.I1.i2.p1.4.m4.1.1.1.1.3.3.cmml">
              <mi id="A4.I1.i2.p1.4.m4.1.1.1.1.3.3.2" xref="A4.I1.i2.p1.4.m4.1.1.1.1.3.3.2.cmml">
               W
              </mi>
              <mi id="A4.I1.i2.p1.4.m4.1.1.1.1.3.3.3" xref="A4.I1.i2.p1.4.m4.1.1.1.1.3.3.3.cmml">
               Q
              </mi>
             </msub>
            </mrow>
           </mrow>
           <mo id="A4.I1.i2.p1.4.m4.2.2.2.3" xref="A4.I1.i2.p1.4.m4.2.2.3a.cmml">
            ,
           </mo>
           <mrow id="A4.I1.i2.p1.4.m4.2.2.2.2.2" xref="A4.I1.i2.p1.4.m4.2.2.2.2.3.cmml">
            <mrow id="A4.I1.i2.p1.4.m4.2.2.2.2.1.1" xref="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.cmml">
             <mi id="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.2" xref="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.2.cmml">
              K
             </mi>
             <mo id="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.1" xref="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.1.cmml">
              =
             </mo>
             <mrow id="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3" xref="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.cmml">
              <mi id="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.2" xref="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.2.cmml">
               X
              </mi>
              <mo id="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.1" lspace="0em" rspace="0em" xref="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.1.cmml">
               ​
              </mo>
              <msub id="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.3" xref="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.3.cmml">
               <mi id="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.3.2" xref="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.3.2.cmml">
                W
               </mi>
               <mi id="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.3.3" xref="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.3.3.cmml">
                K
               </mi>
              </msub>
             </mrow>
            </mrow>
            <mo id="A4.I1.i2.p1.4.m4.2.2.2.2.2.3" xref="A4.I1.i2.p1.4.m4.2.2.2.2.3a.cmml">
             ,
            </mo>
            <mrow id="A4.I1.i2.p1.4.m4.2.2.2.2.2.2" xref="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.cmml">
             <mi id="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.2" xref="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.2.cmml">
              V
             </mi>
             <mo id="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.1" xref="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.1.cmml">
              =
             </mo>
             <mrow id="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3" xref="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.cmml">
              <mi id="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.2" xref="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.2.cmml">
               X
              </mi>
              <mo id="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.1" lspace="0em" rspace="0em" xref="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.1.cmml">
               ​
              </mo>
              <msub id="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.3" xref="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.3.cmml">
               <mi id="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.3.2" xref="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.3.2.cmml">
                W
               </mi>
               <mi id="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.3.3" xref="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.3.3.cmml">
                V
               </mi>
              </msub>
             </mrow>
            </mrow>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p1.4.m4.2b">
           <apply id="A4.I1.i2.p1.4.m4.2.2.3.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2">
            <csymbol cd="ambiguous" id="A4.I1.i2.p1.4.m4.2.2.3a.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.3">
             formulae-sequence
            </csymbol>
            <apply id="A4.I1.i2.p1.4.m4.1.1.1.1.cmml" xref="A4.I1.i2.p1.4.m4.1.1.1.1">
             <eq id="A4.I1.i2.p1.4.m4.1.1.1.1.1.cmml" xref="A4.I1.i2.p1.4.m4.1.1.1.1.1">
             </eq>
             <ci id="A4.I1.i2.p1.4.m4.1.1.1.1.2.cmml" xref="A4.I1.i2.p1.4.m4.1.1.1.1.2">
              𝑄
             </ci>
             <apply id="A4.I1.i2.p1.4.m4.1.1.1.1.3.cmml" xref="A4.I1.i2.p1.4.m4.1.1.1.1.3">
              <times id="A4.I1.i2.p1.4.m4.1.1.1.1.3.1.cmml" xref="A4.I1.i2.p1.4.m4.1.1.1.1.3.1">
              </times>
              <ci id="A4.I1.i2.p1.4.m4.1.1.1.1.3.2.cmml" xref="A4.I1.i2.p1.4.m4.1.1.1.1.3.2">
               𝑋
              </ci>
              <apply id="A4.I1.i2.p1.4.m4.1.1.1.1.3.3.cmml" xref="A4.I1.i2.p1.4.m4.1.1.1.1.3.3">
               <csymbol cd="ambiguous" id="A4.I1.i2.p1.4.m4.1.1.1.1.3.3.1.cmml" xref="A4.I1.i2.p1.4.m4.1.1.1.1.3.3">
                subscript
               </csymbol>
               <ci id="A4.I1.i2.p1.4.m4.1.1.1.1.3.3.2.cmml" xref="A4.I1.i2.p1.4.m4.1.1.1.1.3.3.2">
                𝑊
               </ci>
               <ci id="A4.I1.i2.p1.4.m4.1.1.1.1.3.3.3.cmml" xref="A4.I1.i2.p1.4.m4.1.1.1.1.3.3.3">
                𝑄
               </ci>
              </apply>
             </apply>
            </apply>
            <apply id="A4.I1.i2.p1.4.m4.2.2.2.2.3.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.2">
             <csymbol cd="ambiguous" id="A4.I1.i2.p1.4.m4.2.2.2.2.3a.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.2.3">
              formulae-sequence
             </csymbol>
             <apply id="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.1.1">
              <eq id="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.1.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.1">
              </eq>
              <ci id="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.2.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.2">
               𝐾
              </ci>
              <apply id="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3">
               <times id="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.1.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.1">
               </times>
               <ci id="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.2.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.2">
                𝑋
               </ci>
               <apply id="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.3.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.3">
                <csymbol cd="ambiguous" id="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.3.1.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.3">
                 subscript
                </csymbol>
                <ci id="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.3.2.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.3.2">
                 𝑊
                </ci>
                <ci id="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.3.3.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.1.1.3.3.3">
                 𝐾
                </ci>
               </apply>
              </apply>
             </apply>
             <apply id="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.2.2">
              <eq id="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.1.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.1">
              </eq>
              <ci id="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.2.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.2">
               𝑉
              </ci>
              <apply id="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3">
               <times id="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.1.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.1">
               </times>
               <ci id="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.2.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.2">
                𝑋
               </ci>
               <apply id="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.3.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.3">
                <csymbol cd="ambiguous" id="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.3.1.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.3">
                 subscript
                </csymbol>
                <ci id="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.3.2.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.3.2">
                 𝑊
                </ci>
                <ci id="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.3.3.cmml" xref="A4.I1.i2.p1.4.m4.2.2.2.2.2.2.3.3.3">
                 𝑉
                </ci>
               </apply>
              </apply>
             </apply>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p1.4.m4.2c">
           Q=XW_{Q},K=XW_{K},V=XW_{V}
          </annotation>
         </semantics>
        </math>
        from
        <math alttext="X" class="ltx_Math" display="inline" id="A4.I1.i2.p1.5.m5.1">
         <semantics id="A4.I1.i2.p1.5.m5.1a">
          <mi id="A4.I1.i2.p1.5.m5.1.1" xref="A4.I1.i2.p1.5.m5.1.1.cmml">
           X
          </mi>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p1.5.m5.1b">
           <ci id="A4.I1.i2.p1.5.m5.1.1.cmml" xref="A4.I1.i2.p1.5.m5.1.1">
            𝑋
           </ci>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p1.5.m5.1c">
           X
          </annotation>
         </semantics>
        </math>
        using learnable projection matrices
        <math alttext="W_{Q},W_{K},W_{V}\in\mathbf{R}^{d\times d_{h}}" class="ltx_Math" display="inline" id="A4.I1.i2.p1.6.m6.3">
         <semantics id="A4.I1.i2.p1.6.m6.3a">
          <mrow id="A4.I1.i2.p1.6.m6.3.3" xref="A4.I1.i2.p1.6.m6.3.3.cmml">
           <mrow id="A4.I1.i2.p1.6.m6.3.3.3.3" xref="A4.I1.i2.p1.6.m6.3.3.3.4.cmml">
            <msub id="A4.I1.i2.p1.6.m6.1.1.1.1.1" xref="A4.I1.i2.p1.6.m6.1.1.1.1.1.cmml">
             <mi id="A4.I1.i2.p1.6.m6.1.1.1.1.1.2" xref="A4.I1.i2.p1.6.m6.1.1.1.1.1.2.cmml">
              W
             </mi>
             <mi id="A4.I1.i2.p1.6.m6.1.1.1.1.1.3" xref="A4.I1.i2.p1.6.m6.1.1.1.1.1.3.cmml">
              Q
             </mi>
            </msub>
            <mo id="A4.I1.i2.p1.6.m6.3.3.3.3.4" xref="A4.I1.i2.p1.6.m6.3.3.3.4.cmml">
             ,
            </mo>
            <msub id="A4.I1.i2.p1.6.m6.2.2.2.2.2" xref="A4.I1.i2.p1.6.m6.2.2.2.2.2.cmml">
             <mi id="A4.I1.i2.p1.6.m6.2.2.2.2.2.2" xref="A4.I1.i2.p1.6.m6.2.2.2.2.2.2.cmml">
              W
             </mi>
             <mi id="A4.I1.i2.p1.6.m6.2.2.2.2.2.3" xref="A4.I1.i2.p1.6.m6.2.2.2.2.2.3.cmml">
              K
             </mi>
            </msub>
            <mo id="A4.I1.i2.p1.6.m6.3.3.3.3.5" xref="A4.I1.i2.p1.6.m6.3.3.3.4.cmml">
             ,
            </mo>
            <msub id="A4.I1.i2.p1.6.m6.3.3.3.3.3" xref="A4.I1.i2.p1.6.m6.3.3.3.3.3.cmml">
             <mi id="A4.I1.i2.p1.6.m6.3.3.3.3.3.2" xref="A4.I1.i2.p1.6.m6.3.3.3.3.3.2.cmml">
              W
             </mi>
             <mi id="A4.I1.i2.p1.6.m6.3.3.3.3.3.3" xref="A4.I1.i2.p1.6.m6.3.3.3.3.3.3.cmml">
              V
             </mi>
            </msub>
           </mrow>
           <mo id="A4.I1.i2.p1.6.m6.3.3.4" xref="A4.I1.i2.p1.6.m6.3.3.4.cmml">
            ∈
           </mo>
           <msup id="A4.I1.i2.p1.6.m6.3.3.5" xref="A4.I1.i2.p1.6.m6.3.3.5.cmml">
            <mi id="A4.I1.i2.p1.6.m6.3.3.5.2" xref="A4.I1.i2.p1.6.m6.3.3.5.2.cmml">
             𝐑
            </mi>
            <mrow id="A4.I1.i2.p1.6.m6.3.3.5.3" xref="A4.I1.i2.p1.6.m6.3.3.5.3.cmml">
             <mi id="A4.I1.i2.p1.6.m6.3.3.5.3.2" xref="A4.I1.i2.p1.6.m6.3.3.5.3.2.cmml">
              d
             </mi>
             <mo id="A4.I1.i2.p1.6.m6.3.3.5.3.1" lspace="0.222em" rspace="0.222em" xref="A4.I1.i2.p1.6.m6.3.3.5.3.1.cmml">
              ×
             </mo>
             <msub id="A4.I1.i2.p1.6.m6.3.3.5.3.3" xref="A4.I1.i2.p1.6.m6.3.3.5.3.3.cmml">
              <mi id="A4.I1.i2.p1.6.m6.3.3.5.3.3.2" xref="A4.I1.i2.p1.6.m6.3.3.5.3.3.2.cmml">
               d
              </mi>
              <mi id="A4.I1.i2.p1.6.m6.3.3.5.3.3.3" xref="A4.I1.i2.p1.6.m6.3.3.5.3.3.3.cmml">
               h
              </mi>
             </msub>
            </mrow>
           </msup>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p1.6.m6.3b">
           <apply id="A4.I1.i2.p1.6.m6.3.3.cmml" xref="A4.I1.i2.p1.6.m6.3.3">
            <in id="A4.I1.i2.p1.6.m6.3.3.4.cmml" xref="A4.I1.i2.p1.6.m6.3.3.4">
            </in>
            <list id="A4.I1.i2.p1.6.m6.3.3.3.4.cmml" xref="A4.I1.i2.p1.6.m6.3.3.3.3">
             <apply id="A4.I1.i2.p1.6.m6.1.1.1.1.1.cmml" xref="A4.I1.i2.p1.6.m6.1.1.1.1.1">
              <csymbol cd="ambiguous" id="A4.I1.i2.p1.6.m6.1.1.1.1.1.1.cmml" xref="A4.I1.i2.p1.6.m6.1.1.1.1.1">
               subscript
              </csymbol>
              <ci id="A4.I1.i2.p1.6.m6.1.1.1.1.1.2.cmml" xref="A4.I1.i2.p1.6.m6.1.1.1.1.1.2">
               𝑊
              </ci>
              <ci id="A4.I1.i2.p1.6.m6.1.1.1.1.1.3.cmml" xref="A4.I1.i2.p1.6.m6.1.1.1.1.1.3">
               𝑄
              </ci>
             </apply>
             <apply id="A4.I1.i2.p1.6.m6.2.2.2.2.2.cmml" xref="A4.I1.i2.p1.6.m6.2.2.2.2.2">
              <csymbol cd="ambiguous" id="A4.I1.i2.p1.6.m6.2.2.2.2.2.1.cmml" xref="A4.I1.i2.p1.6.m6.2.2.2.2.2">
               subscript
              </csymbol>
              <ci id="A4.I1.i2.p1.6.m6.2.2.2.2.2.2.cmml" xref="A4.I1.i2.p1.6.m6.2.2.2.2.2.2">
               𝑊
              </ci>
              <ci id="A4.I1.i2.p1.6.m6.2.2.2.2.2.3.cmml" xref="A4.I1.i2.p1.6.m6.2.2.2.2.2.3">
               𝐾
              </ci>
             </apply>
             <apply id="A4.I1.i2.p1.6.m6.3.3.3.3.3.cmml" xref="A4.I1.i2.p1.6.m6.3.3.3.3.3">
              <csymbol cd="ambiguous" id="A4.I1.i2.p1.6.m6.3.3.3.3.3.1.cmml" xref="A4.I1.i2.p1.6.m6.3.3.3.3.3">
               subscript
              </csymbol>
              <ci id="A4.I1.i2.p1.6.m6.3.3.3.3.3.2.cmml" xref="A4.I1.i2.p1.6.m6.3.3.3.3.3.2">
               𝑊
              </ci>
              <ci id="A4.I1.i2.p1.6.m6.3.3.3.3.3.3.cmml" xref="A4.I1.i2.p1.6.m6.3.3.3.3.3.3">
               𝑉
              </ci>
             </apply>
            </list>
            <apply id="A4.I1.i2.p1.6.m6.3.3.5.cmml" xref="A4.I1.i2.p1.6.m6.3.3.5">
             <csymbol cd="ambiguous" id="A4.I1.i2.p1.6.m6.3.3.5.1.cmml" xref="A4.I1.i2.p1.6.m6.3.3.5">
              superscript
             </csymbol>
             <ci id="A4.I1.i2.p1.6.m6.3.3.5.2.cmml" xref="A4.I1.i2.p1.6.m6.3.3.5.2">
              𝐑
             </ci>
             <apply id="A4.I1.i2.p1.6.m6.3.3.5.3.cmml" xref="A4.I1.i2.p1.6.m6.3.3.5.3">
              <times id="A4.I1.i2.p1.6.m6.3.3.5.3.1.cmml" xref="A4.I1.i2.p1.6.m6.3.3.5.3.1">
              </times>
              <ci id="A4.I1.i2.p1.6.m6.3.3.5.3.2.cmml" xref="A4.I1.i2.p1.6.m6.3.3.5.3.2">
               𝑑
              </ci>
              <apply id="A4.I1.i2.p1.6.m6.3.3.5.3.3.cmml" xref="A4.I1.i2.p1.6.m6.3.3.5.3.3">
               <csymbol cd="ambiguous" id="A4.I1.i2.p1.6.m6.3.3.5.3.3.1.cmml" xref="A4.I1.i2.p1.6.m6.3.3.5.3.3">
                subscript
               </csymbol>
               <ci id="A4.I1.i2.p1.6.m6.3.3.5.3.3.2.cmml" xref="A4.I1.i2.p1.6.m6.3.3.5.3.3.2">
                𝑑
               </ci>
               <ci id="A4.I1.i2.p1.6.m6.3.3.5.3.3.3.cmml" xref="A4.I1.i2.p1.6.m6.3.3.5.3.3.3">
                ℎ
               </ci>
              </apply>
             </apply>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p1.6.m6.3c">
           W_{Q},W_{K},W_{V}\in\mathbf{R}^{d\times d_{h}}
          </annotation>
         </semantics>
        </math>
        where
        <math alttext="d_{h}" class="ltx_Math" display="inline" id="A4.I1.i2.p1.7.m7.1">
         <semantics id="A4.I1.i2.p1.7.m7.1a">
          <msub id="A4.I1.i2.p1.7.m7.1.1" xref="A4.I1.i2.p1.7.m7.1.1.cmml">
           <mi id="A4.I1.i2.p1.7.m7.1.1.2" xref="A4.I1.i2.p1.7.m7.1.1.2.cmml">
            d
           </mi>
           <mi id="A4.I1.i2.p1.7.m7.1.1.3" xref="A4.I1.i2.p1.7.m7.1.1.3.cmml">
            h
           </mi>
          </msub>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p1.7.m7.1b">
           <apply id="A4.I1.i2.p1.7.m7.1.1.cmml" xref="A4.I1.i2.p1.7.m7.1.1">
            <csymbol cd="ambiguous" id="A4.I1.i2.p1.7.m7.1.1.1.cmml" xref="A4.I1.i2.p1.7.m7.1.1">
             subscript
            </csymbol>
            <ci id="A4.I1.i2.p1.7.m7.1.1.2.cmml" xref="A4.I1.i2.p1.7.m7.1.1.2">
             𝑑
            </ci>
            <ci id="A4.I1.i2.p1.7.m7.1.1.3.cmml" xref="A4.I1.i2.p1.7.m7.1.1.3">
             ℎ
            </ci>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p1.7.m7.1c">
           d_{h}
          </annotation>
         </semantics>
        </math>
        stands for the output feature dimension. Then the attention weight matrix is computed by
        <math alttext="(\omega^{o}_{ij})_{N\times N}=\Omega^{o}=softmax(\frac{QK^{T}}{\sqrt{d_{h}}})" class="ltx_Math" display="inline" id="A4.I1.i2.p1.8.m8.2">
         <semantics id="A4.I1.i2.p1.8.m8.2a">
          <mrow id="A4.I1.i2.p1.8.m8.2.2" xref="A4.I1.i2.p1.8.m8.2.2.cmml">
           <msub id="A4.I1.i2.p1.8.m8.2.2.1" xref="A4.I1.i2.p1.8.m8.2.2.1.cmml">
            <mrow id="A4.I1.i2.p1.8.m8.2.2.1.1.1" xref="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.cmml">
             <mo id="A4.I1.i2.p1.8.m8.2.2.1.1.1.2" stretchy="false" xref="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.cmml">
              (
             </mo>
             <msubsup id="A4.I1.i2.p1.8.m8.2.2.1.1.1.1" xref="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.cmml">
              <mi id="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.2.2" xref="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.2.2.cmml">
               ω
              </mi>
              <mrow id="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.3" xref="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.3.cmml">
               <mi id="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.3.2" xref="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.3.2.cmml">
                i
               </mi>
               <mo id="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.3.1" lspace="0em" rspace="0em" xref="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.3.1.cmml">
                ​
               </mo>
               <mi id="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.3.3" xref="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.3.3.cmml">
                j
               </mi>
              </mrow>
              <mi id="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.2.3" xref="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.2.3.cmml">
               o
              </mi>
             </msubsup>
             <mo id="A4.I1.i2.p1.8.m8.2.2.1.1.1.3" stretchy="false" xref="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.cmml">
              )
             </mo>
            </mrow>
            <mrow id="A4.I1.i2.p1.8.m8.2.2.1.3" xref="A4.I1.i2.p1.8.m8.2.2.1.3.cmml">
             <mi id="A4.I1.i2.p1.8.m8.2.2.1.3.2" xref="A4.I1.i2.p1.8.m8.2.2.1.3.2.cmml">
              N
             </mi>
             <mo id="A4.I1.i2.p1.8.m8.2.2.1.3.1" lspace="0.222em" rspace="0.222em" xref="A4.I1.i2.p1.8.m8.2.2.1.3.1.cmml">
              ×
             </mo>
             <mi id="A4.I1.i2.p1.8.m8.2.2.1.3.3" xref="A4.I1.i2.p1.8.m8.2.2.1.3.3.cmml">
              N
             </mi>
            </mrow>
           </msub>
           <mo id="A4.I1.i2.p1.8.m8.2.2.3" xref="A4.I1.i2.p1.8.m8.2.2.3.cmml">
            =
           </mo>
           <msup id="A4.I1.i2.p1.8.m8.2.2.4" xref="A4.I1.i2.p1.8.m8.2.2.4.cmml">
            <mi id="A4.I1.i2.p1.8.m8.2.2.4.2" mathvariant="normal" xref="A4.I1.i2.p1.8.m8.2.2.4.2.cmml">
             Ω
            </mi>
            <mi id="A4.I1.i2.p1.8.m8.2.2.4.3" xref="A4.I1.i2.p1.8.m8.2.2.4.3.cmml">
             o
            </mi>
           </msup>
           <mo id="A4.I1.i2.p1.8.m8.2.2.5" xref="A4.I1.i2.p1.8.m8.2.2.5.cmml">
            =
           </mo>
           <mrow id="A4.I1.i2.p1.8.m8.2.2.6" xref="A4.I1.i2.p1.8.m8.2.2.6.cmml">
            <mi id="A4.I1.i2.p1.8.m8.2.2.6.2" xref="A4.I1.i2.p1.8.m8.2.2.6.2.cmml">
             s
            </mi>
            <mo id="A4.I1.i2.p1.8.m8.2.2.6.1" lspace="0em" rspace="0em" xref="A4.I1.i2.p1.8.m8.2.2.6.1.cmml">
             ​
            </mo>
            <mi id="A4.I1.i2.p1.8.m8.2.2.6.3" xref="A4.I1.i2.p1.8.m8.2.2.6.3.cmml">
             o
            </mi>
            <mo id="A4.I1.i2.p1.8.m8.2.2.6.1a" lspace="0em" rspace="0em" xref="A4.I1.i2.p1.8.m8.2.2.6.1.cmml">
             ​
            </mo>
            <mi id="A4.I1.i2.p1.8.m8.2.2.6.4" xref="A4.I1.i2.p1.8.m8.2.2.6.4.cmml">
             f
            </mi>
            <mo id="A4.I1.i2.p1.8.m8.2.2.6.1b" lspace="0em" rspace="0em" xref="A4.I1.i2.p1.8.m8.2.2.6.1.cmml">
             ​
            </mo>
            <mi id="A4.I1.i2.p1.8.m8.2.2.6.5" xref="A4.I1.i2.p1.8.m8.2.2.6.5.cmml">
             t
            </mi>
            <mo id="A4.I1.i2.p1.8.m8.2.2.6.1c" lspace="0em" rspace="0em" xref="A4.I1.i2.p1.8.m8.2.2.6.1.cmml">
             ​
            </mo>
            <mi id="A4.I1.i2.p1.8.m8.2.2.6.6" xref="A4.I1.i2.p1.8.m8.2.2.6.6.cmml">
             m
            </mi>
            <mo id="A4.I1.i2.p1.8.m8.2.2.6.1d" lspace="0em" rspace="0em" xref="A4.I1.i2.p1.8.m8.2.2.6.1.cmml">
             ​
            </mo>
            <mi id="A4.I1.i2.p1.8.m8.2.2.6.7" xref="A4.I1.i2.p1.8.m8.2.2.6.7.cmml">
             a
            </mi>
            <mo id="A4.I1.i2.p1.8.m8.2.2.6.1e" lspace="0em" rspace="0em" xref="A4.I1.i2.p1.8.m8.2.2.6.1.cmml">
             ​
            </mo>
            <mi id="A4.I1.i2.p1.8.m8.2.2.6.8" xref="A4.I1.i2.p1.8.m8.2.2.6.8.cmml">
             x
            </mi>
            <mo id="A4.I1.i2.p1.8.m8.2.2.6.1f" lspace="0em" rspace="0em" xref="A4.I1.i2.p1.8.m8.2.2.6.1.cmml">
             ​
            </mo>
            <mrow id="A4.I1.i2.p1.8.m8.2.2.6.9.2" xref="A4.I1.i2.p1.8.m8.1.1.cmml">
             <mo id="A4.I1.i2.p1.8.m8.2.2.6.9.2.1" stretchy="false" xref="A4.I1.i2.p1.8.m8.1.1.cmml">
              (
             </mo>
             <mfrac id="A4.I1.i2.p1.8.m8.1.1" xref="A4.I1.i2.p1.8.m8.1.1.cmml">
              <mrow id="A4.I1.i2.p1.8.m8.1.1.2" xref="A4.I1.i2.p1.8.m8.1.1.2.cmml">
               <mi id="A4.I1.i2.p1.8.m8.1.1.2.2" xref="A4.I1.i2.p1.8.m8.1.1.2.2.cmml">
                Q
               </mi>
               <mo id="A4.I1.i2.p1.8.m8.1.1.2.1" lspace="0em" rspace="0em" xref="A4.I1.i2.p1.8.m8.1.1.2.1.cmml">
                ​
               </mo>
               <msup id="A4.I1.i2.p1.8.m8.1.1.2.3" xref="A4.I1.i2.p1.8.m8.1.1.2.3.cmml">
                <mi id="A4.I1.i2.p1.8.m8.1.1.2.3.2" xref="A4.I1.i2.p1.8.m8.1.1.2.3.2.cmml">
                 K
                </mi>
                <mi id="A4.I1.i2.p1.8.m8.1.1.2.3.3" xref="A4.I1.i2.p1.8.m8.1.1.2.3.3.cmml">
                 T
                </mi>
               </msup>
              </mrow>
              <msqrt id="A4.I1.i2.p1.8.m8.1.1.3" xref="A4.I1.i2.p1.8.m8.1.1.3.cmml">
               <msub id="A4.I1.i2.p1.8.m8.1.1.3.2" xref="A4.I1.i2.p1.8.m8.1.1.3.2.cmml">
                <mi id="A4.I1.i2.p1.8.m8.1.1.3.2.2" xref="A4.I1.i2.p1.8.m8.1.1.3.2.2.cmml">
                 d
                </mi>
                <mi id="A4.I1.i2.p1.8.m8.1.1.3.2.3" xref="A4.I1.i2.p1.8.m8.1.1.3.2.3.cmml">
                 h
                </mi>
               </msub>
              </msqrt>
             </mfrac>
             <mo id="A4.I1.i2.p1.8.m8.2.2.6.9.2.2" stretchy="false" xref="A4.I1.i2.p1.8.m8.1.1.cmml">
              )
             </mo>
            </mrow>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p1.8.m8.2b">
           <apply id="A4.I1.i2.p1.8.m8.2.2.cmml" xref="A4.I1.i2.p1.8.m8.2.2">
            <and id="A4.I1.i2.p1.8.m8.2.2a.cmml" xref="A4.I1.i2.p1.8.m8.2.2">
            </and>
            <apply id="A4.I1.i2.p1.8.m8.2.2b.cmml" xref="A4.I1.i2.p1.8.m8.2.2">
             <eq id="A4.I1.i2.p1.8.m8.2.2.3.cmml" xref="A4.I1.i2.p1.8.m8.2.2.3">
             </eq>
             <apply id="A4.I1.i2.p1.8.m8.2.2.1.cmml" xref="A4.I1.i2.p1.8.m8.2.2.1">
              <csymbol cd="ambiguous" id="A4.I1.i2.p1.8.m8.2.2.1.2.cmml" xref="A4.I1.i2.p1.8.m8.2.2.1">
               subscript
              </csymbol>
              <apply id="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.cmml" xref="A4.I1.i2.p1.8.m8.2.2.1.1.1">
               <csymbol cd="ambiguous" id="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.1.cmml" xref="A4.I1.i2.p1.8.m8.2.2.1.1.1">
                subscript
               </csymbol>
               <apply id="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.2.cmml" xref="A4.I1.i2.p1.8.m8.2.2.1.1.1">
                <csymbol cd="ambiguous" id="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.2.1.cmml" xref="A4.I1.i2.p1.8.m8.2.2.1.1.1">
                 superscript
                </csymbol>
                <ci id="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.2.2.cmml" xref="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.2.2">
                 𝜔
                </ci>
                <ci id="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.2.3.cmml" xref="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.2.3">
                 𝑜
                </ci>
               </apply>
               <apply id="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.3.cmml" xref="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.3">
                <times id="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.3.1.cmml" xref="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.3.1">
                </times>
                <ci id="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.3.2.cmml" xref="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.3.2">
                 𝑖
                </ci>
                <ci id="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.3.3.cmml" xref="A4.I1.i2.p1.8.m8.2.2.1.1.1.1.3.3">
                 𝑗
                </ci>
               </apply>
              </apply>
              <apply id="A4.I1.i2.p1.8.m8.2.2.1.3.cmml" xref="A4.I1.i2.p1.8.m8.2.2.1.3">
               <times id="A4.I1.i2.p1.8.m8.2.2.1.3.1.cmml" xref="A4.I1.i2.p1.8.m8.2.2.1.3.1">
               </times>
               <ci id="A4.I1.i2.p1.8.m8.2.2.1.3.2.cmml" xref="A4.I1.i2.p1.8.m8.2.2.1.3.2">
                𝑁
               </ci>
               <ci id="A4.I1.i2.p1.8.m8.2.2.1.3.3.cmml" xref="A4.I1.i2.p1.8.m8.2.2.1.3.3">
                𝑁
               </ci>
              </apply>
             </apply>
             <apply id="A4.I1.i2.p1.8.m8.2.2.4.cmml" xref="A4.I1.i2.p1.8.m8.2.2.4">
              <csymbol cd="ambiguous" id="A4.I1.i2.p1.8.m8.2.2.4.1.cmml" xref="A4.I1.i2.p1.8.m8.2.2.4">
               superscript
              </csymbol>
              <ci id="A4.I1.i2.p1.8.m8.2.2.4.2.cmml" xref="A4.I1.i2.p1.8.m8.2.2.4.2">
               Ω
              </ci>
              <ci id="A4.I1.i2.p1.8.m8.2.2.4.3.cmml" xref="A4.I1.i2.p1.8.m8.2.2.4.3">
               𝑜
              </ci>
             </apply>
            </apply>
            <apply id="A4.I1.i2.p1.8.m8.2.2c.cmml" xref="A4.I1.i2.p1.8.m8.2.2">
             <eq id="A4.I1.i2.p1.8.m8.2.2.5.cmml" xref="A4.I1.i2.p1.8.m8.2.2.5">
             </eq>
             <share href="#A4.I1.i2.p1.8.m8.2.2.4.cmml" id="A4.I1.i2.p1.8.m8.2.2d.cmml" xref="A4.I1.i2.p1.8.m8.2.2">
             </share>
             <apply id="A4.I1.i2.p1.8.m8.2.2.6.cmml" xref="A4.I1.i2.p1.8.m8.2.2.6">
              <times id="A4.I1.i2.p1.8.m8.2.2.6.1.cmml" xref="A4.I1.i2.p1.8.m8.2.2.6.1">
              </times>
              <ci id="A4.I1.i2.p1.8.m8.2.2.6.2.cmml" xref="A4.I1.i2.p1.8.m8.2.2.6.2">
               𝑠
              </ci>
              <ci id="A4.I1.i2.p1.8.m8.2.2.6.3.cmml" xref="A4.I1.i2.p1.8.m8.2.2.6.3">
               𝑜
              </ci>
              <ci id="A4.I1.i2.p1.8.m8.2.2.6.4.cmml" xref="A4.I1.i2.p1.8.m8.2.2.6.4">
               𝑓
              </ci>
              <ci id="A4.I1.i2.p1.8.m8.2.2.6.5.cmml" xref="A4.I1.i2.p1.8.m8.2.2.6.5">
               𝑡
              </ci>
              <ci id="A4.I1.i2.p1.8.m8.2.2.6.6.cmml" xref="A4.I1.i2.p1.8.m8.2.2.6.6">
               𝑚
              </ci>
              <ci id="A4.I1.i2.p1.8.m8.2.2.6.7.cmml" xref="A4.I1.i2.p1.8.m8.2.2.6.7">
               𝑎
              </ci>
              <ci id="A4.I1.i2.p1.8.m8.2.2.6.8.cmml" xref="A4.I1.i2.p1.8.m8.2.2.6.8">
               𝑥
              </ci>
              <apply id="A4.I1.i2.p1.8.m8.1.1.cmml" xref="A4.I1.i2.p1.8.m8.2.2.6.9.2">
               <divide id="A4.I1.i2.p1.8.m8.1.1.1.cmml" xref="A4.I1.i2.p1.8.m8.2.2.6.9.2">
               </divide>
               <apply id="A4.I1.i2.p1.8.m8.1.1.2.cmml" xref="A4.I1.i2.p1.8.m8.1.1.2">
                <times id="A4.I1.i2.p1.8.m8.1.1.2.1.cmml" xref="A4.I1.i2.p1.8.m8.1.1.2.1">
                </times>
                <ci id="A4.I1.i2.p1.8.m8.1.1.2.2.cmml" xref="A4.I1.i2.p1.8.m8.1.1.2.2">
                 𝑄
                </ci>
                <apply id="A4.I1.i2.p1.8.m8.1.1.2.3.cmml" xref="A4.I1.i2.p1.8.m8.1.1.2.3">
                 <csymbol cd="ambiguous" id="A4.I1.i2.p1.8.m8.1.1.2.3.1.cmml" xref="A4.I1.i2.p1.8.m8.1.1.2.3">
                  superscript
                 </csymbol>
                 <ci id="A4.I1.i2.p1.8.m8.1.1.2.3.2.cmml" xref="A4.I1.i2.p1.8.m8.1.1.2.3.2">
                  𝐾
                 </ci>
                 <ci id="A4.I1.i2.p1.8.m8.1.1.2.3.3.cmml" xref="A4.I1.i2.p1.8.m8.1.1.2.3.3">
                  𝑇
                 </ci>
                </apply>
               </apply>
               <apply id="A4.I1.i2.p1.8.m8.1.1.3.cmml" xref="A4.I1.i2.p1.8.m8.1.1.3">
                <root id="A4.I1.i2.p1.8.m8.1.1.3a.cmml" xref="A4.I1.i2.p1.8.m8.1.1.3">
                </root>
                <apply id="A4.I1.i2.p1.8.m8.1.1.3.2.cmml" xref="A4.I1.i2.p1.8.m8.1.1.3.2">
                 <csymbol cd="ambiguous" id="A4.I1.i2.p1.8.m8.1.1.3.2.1.cmml" xref="A4.I1.i2.p1.8.m8.1.1.3.2">
                  subscript
                 </csymbol>
                 <ci id="A4.I1.i2.p1.8.m8.1.1.3.2.2.cmml" xref="A4.I1.i2.p1.8.m8.1.1.3.2.2">
                  𝑑
                 </ci>
                 <ci id="A4.I1.i2.p1.8.m8.1.1.3.2.3.cmml" xref="A4.I1.i2.p1.8.m8.1.1.3.2.3">
                  ℎ
                 </ci>
                </apply>
               </apply>
              </apply>
             </apply>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p1.8.m8.2c">
           (\omega^{o}_{ij})_{N\times N}=\Omega^{o}=softmax(\frac{QK^{T}}{\sqrt{d_{h}}})
          </annotation>
         </semantics>
        </math>
        and finally used for re-weighting
        <math alttext="\Omega^{o}V" class="ltx_Math" display="inline" id="A4.I1.i2.p1.9.m9.1">
         <semantics id="A4.I1.i2.p1.9.m9.1a">
          <mrow id="A4.I1.i2.p1.9.m9.1.1" xref="A4.I1.i2.p1.9.m9.1.1.cmml">
           <msup id="A4.I1.i2.p1.9.m9.1.1.2" xref="A4.I1.i2.p1.9.m9.1.1.2.cmml">
            <mi id="A4.I1.i2.p1.9.m9.1.1.2.2" mathvariant="normal" xref="A4.I1.i2.p1.9.m9.1.1.2.2.cmml">
             Ω
            </mi>
            <mi id="A4.I1.i2.p1.9.m9.1.1.2.3" xref="A4.I1.i2.p1.9.m9.1.1.2.3.cmml">
             o
            </mi>
           </msup>
           <mo id="A4.I1.i2.p1.9.m9.1.1.1" lspace="0em" rspace="0em" xref="A4.I1.i2.p1.9.m9.1.1.1.cmml">
            ​
           </mo>
           <mi id="A4.I1.i2.p1.9.m9.1.1.3" xref="A4.I1.i2.p1.9.m9.1.1.3.cmml">
            V
           </mi>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p1.9.m9.1b">
           <apply id="A4.I1.i2.p1.9.m9.1.1.cmml" xref="A4.I1.i2.p1.9.m9.1.1">
            <times id="A4.I1.i2.p1.9.m9.1.1.1.cmml" xref="A4.I1.i2.p1.9.m9.1.1.1">
            </times>
            <apply id="A4.I1.i2.p1.9.m9.1.1.2.cmml" xref="A4.I1.i2.p1.9.m9.1.1.2">
             <csymbol cd="ambiguous" id="A4.I1.i2.p1.9.m9.1.1.2.1.cmml" xref="A4.I1.i2.p1.9.m9.1.1.2">
              superscript
             </csymbol>
             <ci id="A4.I1.i2.p1.9.m9.1.1.2.2.cmml" xref="A4.I1.i2.p1.9.m9.1.1.2.2">
              Ω
             </ci>
             <ci id="A4.I1.i2.p1.9.m9.1.1.2.3.cmml" xref="A4.I1.i2.p1.9.m9.1.1.2.3">
              𝑜
             </ci>
            </apply>
            <ci id="A4.I1.i2.p1.9.m9.1.1.3.cmml" xref="A4.I1.i2.p1.9.m9.1.1.3">
             𝑉
            </ci>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p1.9.m9.1c">
           \Omega^{o}V
          </annotation>
         </semantics>
        </math>
        . The intuition of Spatial Transformer is that we can re-scale the elements
        <math alttext="\omega_{ij}^{o}" class="ltx_Math" display="inline" id="A4.I1.i2.p1.10.m10.1">
         <semantics id="A4.I1.i2.p1.10.m10.1a">
          <msubsup id="A4.I1.i2.p1.10.m10.1.1" xref="A4.I1.i2.p1.10.m10.1.1.cmml">
           <mi id="A4.I1.i2.p1.10.m10.1.1.2.2" xref="A4.I1.i2.p1.10.m10.1.1.2.2.cmml">
            ω
           </mi>
           <mrow id="A4.I1.i2.p1.10.m10.1.1.2.3" xref="A4.I1.i2.p1.10.m10.1.1.2.3.cmml">
            <mi id="A4.I1.i2.p1.10.m10.1.1.2.3.2" xref="A4.I1.i2.p1.10.m10.1.1.2.3.2.cmml">
             i
            </mi>
            <mo id="A4.I1.i2.p1.10.m10.1.1.2.3.1" lspace="0em" rspace="0em" xref="A4.I1.i2.p1.10.m10.1.1.2.3.1.cmml">
             ​
            </mo>
            <mi id="A4.I1.i2.p1.10.m10.1.1.2.3.3" xref="A4.I1.i2.p1.10.m10.1.1.2.3.3.cmml">
             j
            </mi>
           </mrow>
           <mi id="A4.I1.i2.p1.10.m10.1.1.3" xref="A4.I1.i2.p1.10.m10.1.1.3.cmml">
            o
           </mi>
          </msubsup>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p1.10.m10.1b">
           <apply id="A4.I1.i2.p1.10.m10.1.1.cmml" xref="A4.I1.i2.p1.10.m10.1.1">
            <csymbol cd="ambiguous" id="A4.I1.i2.p1.10.m10.1.1.1.cmml" xref="A4.I1.i2.p1.10.m10.1.1">
             superscript
            </csymbol>
            <apply id="A4.I1.i2.p1.10.m10.1.1.2.cmml" xref="A4.I1.i2.p1.10.m10.1.1">
             <csymbol cd="ambiguous" id="A4.I1.i2.p1.10.m10.1.1.2.1.cmml" xref="A4.I1.i2.p1.10.m10.1.1">
              subscript
             </csymbol>
             <ci id="A4.I1.i2.p1.10.m10.1.1.2.2.cmml" xref="A4.I1.i2.p1.10.m10.1.1.2.2">
              𝜔
             </ci>
             <apply id="A4.I1.i2.p1.10.m10.1.1.2.3.cmml" xref="A4.I1.i2.p1.10.m10.1.1.2.3">
              <times id="A4.I1.i2.p1.10.m10.1.1.2.3.1.cmml" xref="A4.I1.i2.p1.10.m10.1.1.2.3.1">
              </times>
              <ci id="A4.I1.i2.p1.10.m10.1.1.2.3.2.cmml" xref="A4.I1.i2.p1.10.m10.1.1.2.3.2">
               𝑖
              </ci>
              <ci id="A4.I1.i2.p1.10.m10.1.1.2.3.3.cmml" xref="A4.I1.i2.p1.10.m10.1.1.2.3.3">
               𝑗
              </ci>
             </apply>
            </apply>
            <ci id="A4.I1.i2.p1.10.m10.1.1.3.cmml" xref="A4.I1.i2.p1.10.m10.1.1.3">
             𝑜
            </ci>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p1.10.m10.1c">
           \omega_{ij}^{o}
          </annotation>
         </semantics>
        </math>
        in the weight matrix
        <math alttext="\Omega^{o}" class="ltx_Math" display="inline" id="A4.I1.i2.p1.11.m11.1">
         <semantics id="A4.I1.i2.p1.11.m11.1a">
          <msup id="A4.I1.i2.p1.11.m11.1.1" xref="A4.I1.i2.p1.11.m11.1.1.cmml">
           <mi id="A4.I1.i2.p1.11.m11.1.1.2" mathvariant="normal" xref="A4.I1.i2.p1.11.m11.1.1.2.cmml">
            Ω
           </mi>
           <mi id="A4.I1.i2.p1.11.m11.1.1.3" xref="A4.I1.i2.p1.11.m11.1.1.3.cmml">
            o
           </mi>
          </msup>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p1.11.m11.1b">
           <apply id="A4.I1.i2.p1.11.m11.1.1.cmml" xref="A4.I1.i2.p1.11.m11.1.1">
            <csymbol cd="ambiguous" id="A4.I1.i2.p1.11.m11.1.1.1.cmml" xref="A4.I1.i2.p1.11.m11.1.1">
             superscript
            </csymbol>
            <ci id="A4.I1.i2.p1.11.m11.1.1.2.cmml" xref="A4.I1.i2.p1.11.m11.1.1.2">
             Ω
            </ci>
            <ci id="A4.I1.i2.p1.11.m11.1.1.3.cmml" xref="A4.I1.i2.p1.11.m11.1.1.3">
             𝑜
            </ci>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p1.11.m11.1c">
           \Omega^{o}
          </annotation>
         </semantics>
        </math>
        .
       </p>
      </div>
      <div class="ltx_para ltx_noindent" id="A4.I1.i2.p2">
       <p class="ltx_p" id="A4.I1.i2.p2.11">
        In the object-centric reasoning setting, the input feature matrix is
        <math alttext="O\in\mathbf{R}^{N\times d}" class="ltx_Math" display="inline" id="A4.I1.i2.p2.1.m1.1">
         <semantics id="A4.I1.i2.p2.1.m1.1a">
          <mrow id="A4.I1.i2.p2.1.m1.1.1" xref="A4.I1.i2.p2.1.m1.1.1.cmml">
           <mi id="A4.I1.i2.p2.1.m1.1.1.2" xref="A4.I1.i2.p2.1.m1.1.1.2.cmml">
            O
           </mi>
           <mo id="A4.I1.i2.p2.1.m1.1.1.1" xref="A4.I1.i2.p2.1.m1.1.1.1.cmml">
            ∈
           </mo>
           <msup id="A4.I1.i2.p2.1.m1.1.1.3" xref="A4.I1.i2.p2.1.m1.1.1.3.cmml">
            <mi id="A4.I1.i2.p2.1.m1.1.1.3.2" xref="A4.I1.i2.p2.1.m1.1.1.3.2.cmml">
             𝐑
            </mi>
            <mrow id="A4.I1.i2.p2.1.m1.1.1.3.3" xref="A4.I1.i2.p2.1.m1.1.1.3.3.cmml">
             <mi id="A4.I1.i2.p2.1.m1.1.1.3.3.2" xref="A4.I1.i2.p2.1.m1.1.1.3.3.2.cmml">
              N
             </mi>
             <mo id="A4.I1.i2.p2.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="A4.I1.i2.p2.1.m1.1.1.3.3.1.cmml">
              ×
             </mo>
             <mi id="A4.I1.i2.p2.1.m1.1.1.3.3.3" xref="A4.I1.i2.p2.1.m1.1.1.3.3.3.cmml">
              d
             </mi>
            </mrow>
           </msup>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p2.1.m1.1b">
           <apply id="A4.I1.i2.p2.1.m1.1.1.cmml" xref="A4.I1.i2.p2.1.m1.1.1">
            <in id="A4.I1.i2.p2.1.m1.1.1.1.cmml" xref="A4.I1.i2.p2.1.m1.1.1.1">
            </in>
            <ci id="A4.I1.i2.p2.1.m1.1.1.2.cmml" xref="A4.I1.i2.p2.1.m1.1.1.2">
             𝑂
            </ci>
            <apply id="A4.I1.i2.p2.1.m1.1.1.3.cmml" xref="A4.I1.i2.p2.1.m1.1.1.3">
             <csymbol cd="ambiguous" id="A4.I1.i2.p2.1.m1.1.1.3.1.cmml" xref="A4.I1.i2.p2.1.m1.1.1.3">
              superscript
             </csymbol>
             <ci id="A4.I1.i2.p2.1.m1.1.1.3.2.cmml" xref="A4.I1.i2.p2.1.m1.1.1.3.2">
              𝐑
             </ci>
             <apply id="A4.I1.i2.p2.1.m1.1.1.3.3.cmml" xref="A4.I1.i2.p2.1.m1.1.1.3.3">
              <times id="A4.I1.i2.p2.1.m1.1.1.3.3.1.cmml" xref="A4.I1.i2.p2.1.m1.1.1.3.3.1">
              </times>
              <ci id="A4.I1.i2.p2.1.m1.1.1.3.3.2.cmml" xref="A4.I1.i2.p2.1.m1.1.1.3.3.2">
               𝑁
              </ci>
              <ci id="A4.I1.i2.p2.1.m1.1.1.3.3.3.cmml" xref="A4.I1.i2.p2.1.m1.1.1.3.3.3">
               𝑑
              </ci>
             </apply>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p2.1.m1.1c">
           O\in\mathbf{R}^{N\times d}
          </annotation>
         </semantics>
        </math>
        . Consider an object pair
        <math alttext="(O_{i},O_{j})" class="ltx_Math" display="inline" id="A4.I1.i2.p2.2.m2.2">
         <semantics id="A4.I1.i2.p2.2.m2.2a">
          <mrow id="A4.I1.i2.p2.2.m2.2.2.2" xref="A4.I1.i2.p2.2.m2.2.2.3.cmml">
           <mo id="A4.I1.i2.p2.2.m2.2.2.2.3" stretchy="false" xref="A4.I1.i2.p2.2.m2.2.2.3.cmml">
            (
           </mo>
           <msub id="A4.I1.i2.p2.2.m2.1.1.1.1" xref="A4.I1.i2.p2.2.m2.1.1.1.1.cmml">
            <mi id="A4.I1.i2.p2.2.m2.1.1.1.1.2" xref="A4.I1.i2.p2.2.m2.1.1.1.1.2.cmml">
             O
            </mi>
            <mi id="A4.I1.i2.p2.2.m2.1.1.1.1.3" xref="A4.I1.i2.p2.2.m2.1.1.1.1.3.cmml">
             i
            </mi>
           </msub>
           <mo id="A4.I1.i2.p2.2.m2.2.2.2.4" xref="A4.I1.i2.p2.2.m2.2.2.3.cmml">
            ,
           </mo>
           <msub id="A4.I1.i2.p2.2.m2.2.2.2.2" xref="A4.I1.i2.p2.2.m2.2.2.2.2.cmml">
            <mi id="A4.I1.i2.p2.2.m2.2.2.2.2.2" xref="A4.I1.i2.p2.2.m2.2.2.2.2.2.cmml">
             O
            </mi>
            <mi id="A4.I1.i2.p2.2.m2.2.2.2.2.3" xref="A4.I1.i2.p2.2.m2.2.2.2.2.3.cmml">
             j
            </mi>
           </msub>
           <mo id="A4.I1.i2.p2.2.m2.2.2.2.5" stretchy="false" xref="A4.I1.i2.p2.2.m2.2.2.3.cmml">
            )
           </mo>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p2.2.m2.2b">
           <interval closure="open" id="A4.I1.i2.p2.2.m2.2.2.3.cmml" xref="A4.I1.i2.p2.2.m2.2.2.2">
            <apply id="A4.I1.i2.p2.2.m2.1.1.1.1.cmml" xref="A4.I1.i2.p2.2.m2.1.1.1.1">
             <csymbol cd="ambiguous" id="A4.I1.i2.p2.2.m2.1.1.1.1.1.cmml" xref="A4.I1.i2.p2.2.m2.1.1.1.1">
              subscript
             </csymbol>
             <ci id="A4.I1.i2.p2.2.m2.1.1.1.1.2.cmml" xref="A4.I1.i2.p2.2.m2.1.1.1.1.2">
              𝑂
             </ci>
             <ci id="A4.I1.i2.p2.2.m2.1.1.1.1.3.cmml" xref="A4.I1.i2.p2.2.m2.1.1.1.1.3">
              𝑖
             </ci>
            </apply>
            <apply id="A4.I1.i2.p2.2.m2.2.2.2.2.cmml" xref="A4.I1.i2.p2.2.m2.2.2.2.2">
             <csymbol cd="ambiguous" id="A4.I1.i2.p2.2.m2.2.2.2.2.1.cmml" xref="A4.I1.i2.p2.2.m2.2.2.2.2">
              subscript
             </csymbol>
             <ci id="A4.I1.i2.p2.2.m2.2.2.2.2.2.cmml" xref="A4.I1.i2.p2.2.m2.2.2.2.2.2">
              𝑂
             </ci>
             <ci id="A4.I1.i2.p2.2.m2.2.2.2.2.3.cmml" xref="A4.I1.i2.p2.2.m2.2.2.2.2.3">
              𝑗
             </ci>
            </apply>
           </interval>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p2.2.m2.2c">
           (O_{i},O_{j})
          </annotation>
         </semantics>
        </math>
        with their geometric centers
        <math alttext="c_{i},c_{j}" class="ltx_Math" display="inline" id="A4.I1.i2.p2.3.m3.2">
         <semantics id="A4.I1.i2.p2.3.m3.2a">
          <mrow id="A4.I1.i2.p2.3.m3.2.2.2" xref="A4.I1.i2.p2.3.m3.2.2.3.cmml">
           <msub id="A4.I1.i2.p2.3.m3.1.1.1.1" xref="A4.I1.i2.p2.3.m3.1.1.1.1.cmml">
            <mi id="A4.I1.i2.p2.3.m3.1.1.1.1.2" xref="A4.I1.i2.p2.3.m3.1.1.1.1.2.cmml">
             c
            </mi>
            <mi id="A4.I1.i2.p2.3.m3.1.1.1.1.3" xref="A4.I1.i2.p2.3.m3.1.1.1.1.3.cmml">
             i
            </mi>
           </msub>
           <mo id="A4.I1.i2.p2.3.m3.2.2.2.3" xref="A4.I1.i2.p2.3.m3.2.2.3.cmml">
            ,
           </mo>
           <msub id="A4.I1.i2.p2.3.m3.2.2.2.2" xref="A4.I1.i2.p2.3.m3.2.2.2.2.cmml">
            <mi id="A4.I1.i2.p2.3.m3.2.2.2.2.2" xref="A4.I1.i2.p2.3.m3.2.2.2.2.2.cmml">
             c
            </mi>
            <mi id="A4.I1.i2.p2.3.m3.2.2.2.2.3" xref="A4.I1.i2.p2.3.m3.2.2.2.2.3.cmml">
             j
            </mi>
           </msub>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p2.3.m3.2b">
           <list id="A4.I1.i2.p2.3.m3.2.2.3.cmml" xref="A4.I1.i2.p2.3.m3.2.2.2">
            <apply id="A4.I1.i2.p2.3.m3.1.1.1.1.cmml" xref="A4.I1.i2.p2.3.m3.1.1.1.1">
             <csymbol cd="ambiguous" id="A4.I1.i2.p2.3.m3.1.1.1.1.1.cmml" xref="A4.I1.i2.p2.3.m3.1.1.1.1">
              subscript
             </csymbol>
             <ci id="A4.I1.i2.p2.3.m3.1.1.1.1.2.cmml" xref="A4.I1.i2.p2.3.m3.1.1.1.1.2">
              𝑐
             </ci>
             <ci id="A4.I1.i2.p2.3.m3.1.1.1.1.3.cmml" xref="A4.I1.i2.p2.3.m3.1.1.1.1.3">
              𝑖
             </ci>
            </apply>
            <apply id="A4.I1.i2.p2.3.m3.2.2.2.2.cmml" xref="A4.I1.i2.p2.3.m3.2.2.2.2">
             <csymbol cd="ambiguous" id="A4.I1.i2.p2.3.m3.2.2.2.2.1.cmml" xref="A4.I1.i2.p2.3.m3.2.2.2.2">
              subscript
             </csymbol>
             <ci id="A4.I1.i2.p2.3.m3.2.2.2.2.2.cmml" xref="A4.I1.i2.p2.3.m3.2.2.2.2.2">
              𝑐
             </ci>
             <ci id="A4.I1.i2.p2.3.m3.2.2.2.2.3.cmml" xref="A4.I1.i2.p2.3.m3.2.2.2.2.3">
              𝑗
             </ci>
            </apply>
           </list>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p2.3.m3.2c">
           c_{i},c_{j}
          </annotation>
         </semantics>
        </math>
        . Spatial Transformer
        <cite class="ltx_cite ltx_citemacro_citep">
         (Chen et al.,
         <a class="ltx_ref" href="#bib.bib15" title="">
          2022
         </a>
         )
        </cite>
        computes the Euclidean distance
        <math alttext="d_{ij}=||c_{i}-c_{j}||_{2}" class="ltx_Math" display="inline" id="A4.I1.i2.p2.4.m4.1">
         <semantics id="A4.I1.i2.p2.4.m4.1a">
          <mrow id="A4.I1.i2.p2.4.m4.1.1" xref="A4.I1.i2.p2.4.m4.1.1.cmml">
           <msub id="A4.I1.i2.p2.4.m4.1.1.3" xref="A4.I1.i2.p2.4.m4.1.1.3.cmml">
            <mi id="A4.I1.i2.p2.4.m4.1.1.3.2" xref="A4.I1.i2.p2.4.m4.1.1.3.2.cmml">
             d
            </mi>
            <mrow id="A4.I1.i2.p2.4.m4.1.1.3.3" xref="A4.I1.i2.p2.4.m4.1.1.3.3.cmml">
             <mi id="A4.I1.i2.p2.4.m4.1.1.3.3.2" xref="A4.I1.i2.p2.4.m4.1.1.3.3.2.cmml">
              i
             </mi>
             <mo id="A4.I1.i2.p2.4.m4.1.1.3.3.1" lspace="0em" rspace="0em" xref="A4.I1.i2.p2.4.m4.1.1.3.3.1.cmml">
              ​
             </mo>
             <mi id="A4.I1.i2.p2.4.m4.1.1.3.3.3" xref="A4.I1.i2.p2.4.m4.1.1.3.3.3.cmml">
              j
             </mi>
            </mrow>
           </msub>
           <mo id="A4.I1.i2.p2.4.m4.1.1.2" xref="A4.I1.i2.p2.4.m4.1.1.2.cmml">
            =
           </mo>
           <msub id="A4.I1.i2.p2.4.m4.1.1.1" xref="A4.I1.i2.p2.4.m4.1.1.1.cmml">
            <mrow id="A4.I1.i2.p2.4.m4.1.1.1.1.1" xref="A4.I1.i2.p2.4.m4.1.1.1.1.2.cmml">
             <mo id="A4.I1.i2.p2.4.m4.1.1.1.1.1.2" stretchy="false" xref="A4.I1.i2.p2.4.m4.1.1.1.1.2.1.cmml">
              ‖
             </mo>
             <mrow id="A4.I1.i2.p2.4.m4.1.1.1.1.1.1" xref="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.cmml">
              <msub id="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.2" xref="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.2.cmml">
               <mi id="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.2.2" xref="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.2.2.cmml">
                c
               </mi>
               <mi id="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.2.3" xref="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.2.3.cmml">
                i
               </mi>
              </msub>
              <mo id="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.1" xref="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.1.cmml">
               −
              </mo>
              <msub id="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.3" xref="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.3.cmml">
               <mi id="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.3.2" xref="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.3.2.cmml">
                c
               </mi>
               <mi id="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.3.3" xref="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.3.3.cmml">
                j
               </mi>
              </msub>
             </mrow>
             <mo id="A4.I1.i2.p2.4.m4.1.1.1.1.1.3" stretchy="false" xref="A4.I1.i2.p2.4.m4.1.1.1.1.2.1.cmml">
              ‖
             </mo>
            </mrow>
            <mn id="A4.I1.i2.p2.4.m4.1.1.1.3" xref="A4.I1.i2.p2.4.m4.1.1.1.3.cmml">
             2
            </mn>
           </msub>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p2.4.m4.1b">
           <apply id="A4.I1.i2.p2.4.m4.1.1.cmml" xref="A4.I1.i2.p2.4.m4.1.1">
            <eq id="A4.I1.i2.p2.4.m4.1.1.2.cmml" xref="A4.I1.i2.p2.4.m4.1.1.2">
            </eq>
            <apply id="A4.I1.i2.p2.4.m4.1.1.3.cmml" xref="A4.I1.i2.p2.4.m4.1.1.3">
             <csymbol cd="ambiguous" id="A4.I1.i2.p2.4.m4.1.1.3.1.cmml" xref="A4.I1.i2.p2.4.m4.1.1.3">
              subscript
             </csymbol>
             <ci id="A4.I1.i2.p2.4.m4.1.1.3.2.cmml" xref="A4.I1.i2.p2.4.m4.1.1.3.2">
              𝑑
             </ci>
             <apply id="A4.I1.i2.p2.4.m4.1.1.3.3.cmml" xref="A4.I1.i2.p2.4.m4.1.1.3.3">
              <times id="A4.I1.i2.p2.4.m4.1.1.3.3.1.cmml" xref="A4.I1.i2.p2.4.m4.1.1.3.3.1">
              </times>
              <ci id="A4.I1.i2.p2.4.m4.1.1.3.3.2.cmml" xref="A4.I1.i2.p2.4.m4.1.1.3.3.2">
               𝑖
              </ci>
              <ci id="A4.I1.i2.p2.4.m4.1.1.3.3.3.cmml" xref="A4.I1.i2.p2.4.m4.1.1.3.3.3">
               𝑗
              </ci>
             </apply>
            </apply>
            <apply id="A4.I1.i2.p2.4.m4.1.1.1.cmml" xref="A4.I1.i2.p2.4.m4.1.1.1">
             <csymbol cd="ambiguous" id="A4.I1.i2.p2.4.m4.1.1.1.2.cmml" xref="A4.I1.i2.p2.4.m4.1.1.1">
              subscript
             </csymbol>
             <apply id="A4.I1.i2.p2.4.m4.1.1.1.1.2.cmml" xref="A4.I1.i2.p2.4.m4.1.1.1.1.1">
              <csymbol cd="latexml" id="A4.I1.i2.p2.4.m4.1.1.1.1.2.1.cmml" xref="A4.I1.i2.p2.4.m4.1.1.1.1.1.2">
               norm
              </csymbol>
              <apply id="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.cmml" xref="A4.I1.i2.p2.4.m4.1.1.1.1.1.1">
               <minus id="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.1.cmml" xref="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.1">
               </minus>
               <apply id="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.2.cmml" xref="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.2">
                <csymbol cd="ambiguous" id="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.2.1.cmml" xref="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.2">
                 subscript
                </csymbol>
                <ci id="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.2.2.cmml" xref="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.2.2">
                 𝑐
                </ci>
                <ci id="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.2.3.cmml" xref="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.2.3">
                 𝑖
                </ci>
               </apply>
               <apply id="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.3.cmml" xref="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.3">
                <csymbol cd="ambiguous" id="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.3.1.cmml" xref="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.3">
                 subscript
                </csymbol>
                <ci id="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.3.2.cmml" xref="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.3.2">
                 𝑐
                </ci>
                <ci id="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.3.3.cmml" xref="A4.I1.i2.p2.4.m4.1.1.1.1.1.1.3.3">
                 𝑗
                </ci>
               </apply>
              </apply>
             </apply>
             <cn id="A4.I1.i2.p2.4.m4.1.1.1.3.cmml" type="integer" xref="A4.I1.i2.p2.4.m4.1.1.1.3">
              2
             </cn>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p2.4.m4.1c">
           d_{ij}=||c_{i}-c_{j}||_{2}
          </annotation>
         </semantics>
        </math>
        and the horizontal and vertical angles
        <math alttext="\theta_{h},\theta_{v}" class="ltx_Math" display="inline" id="A4.I1.i2.p2.5.m5.2">
         <semantics id="A4.I1.i2.p2.5.m5.2a">
          <mrow id="A4.I1.i2.p2.5.m5.2.2.2" xref="A4.I1.i2.p2.5.m5.2.2.3.cmml">
           <msub id="A4.I1.i2.p2.5.m5.1.1.1.1" xref="A4.I1.i2.p2.5.m5.1.1.1.1.cmml">
            <mi id="A4.I1.i2.p2.5.m5.1.1.1.1.2" xref="A4.I1.i2.p2.5.m5.1.1.1.1.2.cmml">
             θ
            </mi>
            <mi id="A4.I1.i2.p2.5.m5.1.1.1.1.3" xref="A4.I1.i2.p2.5.m5.1.1.1.1.3.cmml">
             h
            </mi>
           </msub>
           <mo id="A4.I1.i2.p2.5.m5.2.2.2.3" xref="A4.I1.i2.p2.5.m5.2.2.3.cmml">
            ,
           </mo>
           <msub id="A4.I1.i2.p2.5.m5.2.2.2.2" xref="A4.I1.i2.p2.5.m5.2.2.2.2.cmml">
            <mi id="A4.I1.i2.p2.5.m5.2.2.2.2.2" xref="A4.I1.i2.p2.5.m5.2.2.2.2.2.cmml">
             θ
            </mi>
            <mi id="A4.I1.i2.p2.5.m5.2.2.2.2.3" xref="A4.I1.i2.p2.5.m5.2.2.2.2.3.cmml">
             v
            </mi>
           </msub>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p2.5.m5.2b">
           <list id="A4.I1.i2.p2.5.m5.2.2.3.cmml" xref="A4.I1.i2.p2.5.m5.2.2.2">
            <apply id="A4.I1.i2.p2.5.m5.1.1.1.1.cmml" xref="A4.I1.i2.p2.5.m5.1.1.1.1">
             <csymbol cd="ambiguous" id="A4.I1.i2.p2.5.m5.1.1.1.1.1.cmml" xref="A4.I1.i2.p2.5.m5.1.1.1.1">
              subscript
             </csymbol>
             <ci id="A4.I1.i2.p2.5.m5.1.1.1.1.2.cmml" xref="A4.I1.i2.p2.5.m5.1.1.1.1.2">
              𝜃
             </ci>
             <ci id="A4.I1.i2.p2.5.m5.1.1.1.1.3.cmml" xref="A4.I1.i2.p2.5.m5.1.1.1.1.3">
              ℎ
             </ci>
            </apply>
            <apply id="A4.I1.i2.p2.5.m5.2.2.2.2.cmml" xref="A4.I1.i2.p2.5.m5.2.2.2.2">
             <csymbol cd="ambiguous" id="A4.I1.i2.p2.5.m5.2.2.2.2.1.cmml" xref="A4.I1.i2.p2.5.m5.2.2.2.2">
              subscript
             </csymbol>
             <ci id="A4.I1.i2.p2.5.m5.2.2.2.2.2.cmml" xref="A4.I1.i2.p2.5.m5.2.2.2.2.2">
              𝜃
             </ci>
             <ci id="A4.I1.i2.p2.5.m5.2.2.2.2.3.cmml" xref="A4.I1.i2.p2.5.m5.2.2.2.2.3">
              𝑣
             </ci>
            </apply>
           </list>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p2.5.m5.2c">
           \theta_{h},\theta_{v}
          </annotation>
         </semantics>
        </math>
        of the line connecting
        <math alttext="c_{i}" class="ltx_Math" display="inline" id="A4.I1.i2.p2.6.m6.1">
         <semantics id="A4.I1.i2.p2.6.m6.1a">
          <msub id="A4.I1.i2.p2.6.m6.1.1" xref="A4.I1.i2.p2.6.m6.1.1.cmml">
           <mi id="A4.I1.i2.p2.6.m6.1.1.2" xref="A4.I1.i2.p2.6.m6.1.1.2.cmml">
            c
           </mi>
           <mi id="A4.I1.i2.p2.6.m6.1.1.3" xref="A4.I1.i2.p2.6.m6.1.1.3.cmml">
            i
           </mi>
          </msub>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p2.6.m6.1b">
           <apply id="A4.I1.i2.p2.6.m6.1.1.cmml" xref="A4.I1.i2.p2.6.m6.1.1">
            <csymbol cd="ambiguous" id="A4.I1.i2.p2.6.m6.1.1.1.cmml" xref="A4.I1.i2.p2.6.m6.1.1">
             subscript
            </csymbol>
            <ci id="A4.I1.i2.p2.6.m6.1.1.2.cmml" xref="A4.I1.i2.p2.6.m6.1.1.2">
             𝑐
            </ci>
            <ci id="A4.I1.i2.p2.6.m6.1.1.3.cmml" xref="A4.I1.i2.p2.6.m6.1.1.3">
             𝑖
            </ci>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p2.6.m6.1c">
           c_{i}
          </annotation>
         </semantics>
        </math>
        and
        <math alttext="c_{j}" class="ltx_Math" display="inline" id="A4.I1.i2.p2.7.m7.1">
         <semantics id="A4.I1.i2.p2.7.m7.1a">
          <msub id="A4.I1.i2.p2.7.m7.1.1" xref="A4.I1.i2.p2.7.m7.1.1.cmml">
           <mi id="A4.I1.i2.p2.7.m7.1.1.2" xref="A4.I1.i2.p2.7.m7.1.1.2.cmml">
            c
           </mi>
           <mi id="A4.I1.i2.p2.7.m7.1.1.3" xref="A4.I1.i2.p2.7.m7.1.1.3.cmml">
            j
           </mi>
          </msub>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p2.7.m7.1b">
           <apply id="A4.I1.i2.p2.7.m7.1.1.cmml" xref="A4.I1.i2.p2.7.m7.1.1">
            <csymbol cd="ambiguous" id="A4.I1.i2.p2.7.m7.1.1.1.cmml" xref="A4.I1.i2.p2.7.m7.1.1">
             subscript
            </csymbol>
            <ci id="A4.I1.i2.p2.7.m7.1.1.2.cmml" xref="A4.I1.i2.p2.7.m7.1.1.2">
             𝑐
            </ci>
            <ci id="A4.I1.i2.p2.7.m7.1.1.3.cmml" xref="A4.I1.i2.p2.7.m7.1.1.3">
             𝑗
            </ci>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p2.7.m7.1c">
           c_{j}
          </annotation>
         </semantics>
        </math>
        . The spatial feature between the two objects
        <math alttext="(O_{i},O_{j})" class="ltx_Math" display="inline" id="A4.I1.i2.p2.8.m8.2">
         <semantics id="A4.I1.i2.p2.8.m8.2a">
          <mrow id="A4.I1.i2.p2.8.m8.2.2.2" xref="A4.I1.i2.p2.8.m8.2.2.3.cmml">
           <mo id="A4.I1.i2.p2.8.m8.2.2.2.3" stretchy="false" xref="A4.I1.i2.p2.8.m8.2.2.3.cmml">
            (
           </mo>
           <msub id="A4.I1.i2.p2.8.m8.1.1.1.1" xref="A4.I1.i2.p2.8.m8.1.1.1.1.cmml">
            <mi id="A4.I1.i2.p2.8.m8.1.1.1.1.2" xref="A4.I1.i2.p2.8.m8.1.1.1.1.2.cmml">
             O
            </mi>
            <mi id="A4.I1.i2.p2.8.m8.1.1.1.1.3" xref="A4.I1.i2.p2.8.m8.1.1.1.1.3.cmml">
             i
            </mi>
           </msub>
           <mo id="A4.I1.i2.p2.8.m8.2.2.2.4" xref="A4.I1.i2.p2.8.m8.2.2.3.cmml">
            ,
           </mo>
           <msub id="A4.I1.i2.p2.8.m8.2.2.2.2" xref="A4.I1.i2.p2.8.m8.2.2.2.2.cmml">
            <mi id="A4.I1.i2.p2.8.m8.2.2.2.2.2" xref="A4.I1.i2.p2.8.m8.2.2.2.2.2.cmml">
             O
            </mi>
            <mi id="A4.I1.i2.p2.8.m8.2.2.2.2.3" xref="A4.I1.i2.p2.8.m8.2.2.2.2.3.cmml">
             j
            </mi>
           </msub>
           <mo id="A4.I1.i2.p2.8.m8.2.2.2.5" stretchy="false" xref="A4.I1.i2.p2.8.m8.2.2.3.cmml">
            )
           </mo>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p2.8.m8.2b">
           <interval closure="open" id="A4.I1.i2.p2.8.m8.2.2.3.cmml" xref="A4.I1.i2.p2.8.m8.2.2.2">
            <apply id="A4.I1.i2.p2.8.m8.1.1.1.1.cmml" xref="A4.I1.i2.p2.8.m8.1.1.1.1">
             <csymbol cd="ambiguous" id="A4.I1.i2.p2.8.m8.1.1.1.1.1.cmml" xref="A4.I1.i2.p2.8.m8.1.1.1.1">
              subscript
             </csymbol>
             <ci id="A4.I1.i2.p2.8.m8.1.1.1.1.2.cmml" xref="A4.I1.i2.p2.8.m8.1.1.1.1.2">
              𝑂
             </ci>
             <ci id="A4.I1.i2.p2.8.m8.1.1.1.1.3.cmml" xref="A4.I1.i2.p2.8.m8.1.1.1.1.3">
              𝑖
             </ci>
            </apply>
            <apply id="A4.I1.i2.p2.8.m8.2.2.2.2.cmml" xref="A4.I1.i2.p2.8.m8.2.2.2.2">
             <csymbol cd="ambiguous" id="A4.I1.i2.p2.8.m8.2.2.2.2.1.cmml" xref="A4.I1.i2.p2.8.m8.2.2.2.2">
              subscript
             </csymbol>
             <ci id="A4.I1.i2.p2.8.m8.2.2.2.2.2.cmml" xref="A4.I1.i2.p2.8.m8.2.2.2.2.2">
              𝑂
             </ci>
             <ci id="A4.I1.i2.p2.8.m8.2.2.2.2.3.cmml" xref="A4.I1.i2.p2.8.m8.2.2.2.2.3">
              𝑗
             </ci>
            </apply>
           </interval>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p2.8.m8.2c">
           (O_{i},O_{j})
          </annotation>
         </semantics>
        </math>
        is a 5-dimensional vector
        <math alttext="f_{ij}=[d_{ij},\sin{(\theta_{h})},\cos{(\theta_{h})},\sin{(\theta_{v})},\cos{(\theta_{v})}]" class="ltx_Math" display="inline" id="A4.I1.i2.p2.9.m9.9">
         <semantics id="A4.I1.i2.p2.9.m9.9a">
          <mrow id="A4.I1.i2.p2.9.m9.9.9" xref="A4.I1.i2.p2.9.m9.9.9.cmml">
           <msub id="A4.I1.i2.p2.9.m9.9.9.7" xref="A4.I1.i2.p2.9.m9.9.9.7.cmml">
            <mi id="A4.I1.i2.p2.9.m9.9.9.7.2" xref="A4.I1.i2.p2.9.m9.9.9.7.2.cmml">
             f
            </mi>
            <mrow id="A4.I1.i2.p2.9.m9.9.9.7.3" xref="A4.I1.i2.p2.9.m9.9.9.7.3.cmml">
             <mi id="A4.I1.i2.p2.9.m9.9.9.7.3.2" xref="A4.I1.i2.p2.9.m9.9.9.7.3.2.cmml">
              i
             </mi>
             <mo id="A4.I1.i2.p2.9.m9.9.9.7.3.1" lspace="0em" rspace="0em" xref="A4.I1.i2.p2.9.m9.9.9.7.3.1.cmml">
              ​
             </mo>
             <mi id="A4.I1.i2.p2.9.m9.9.9.7.3.3" xref="A4.I1.i2.p2.9.m9.9.9.7.3.3.cmml">
              j
             </mi>
            </mrow>
           </msub>
           <mo id="A4.I1.i2.p2.9.m9.9.9.6" xref="A4.I1.i2.p2.9.m9.9.9.6.cmml">
            =
           </mo>
           <mrow id="A4.I1.i2.p2.9.m9.9.9.5.5" xref="A4.I1.i2.p2.9.m9.9.9.5.6.cmml">
            <mo id="A4.I1.i2.p2.9.m9.9.9.5.5.6" stretchy="false" xref="A4.I1.i2.p2.9.m9.9.9.5.6.cmml">
             [
            </mo>
            <msub id="A4.I1.i2.p2.9.m9.5.5.1.1.1" xref="A4.I1.i2.p2.9.m9.5.5.1.1.1.cmml">
             <mi id="A4.I1.i2.p2.9.m9.5.5.1.1.1.2" xref="A4.I1.i2.p2.9.m9.5.5.1.1.1.2.cmml">
              d
             </mi>
             <mrow id="A4.I1.i2.p2.9.m9.5.5.1.1.1.3" xref="A4.I1.i2.p2.9.m9.5.5.1.1.1.3.cmml">
              <mi id="A4.I1.i2.p2.9.m9.5.5.1.1.1.3.2" xref="A4.I1.i2.p2.9.m9.5.5.1.1.1.3.2.cmml">
               i
              </mi>
              <mo id="A4.I1.i2.p2.9.m9.5.5.1.1.1.3.1" lspace="0em" rspace="0em" xref="A4.I1.i2.p2.9.m9.5.5.1.1.1.3.1.cmml">
               ​
              </mo>
              <mi id="A4.I1.i2.p2.9.m9.5.5.1.1.1.3.3" xref="A4.I1.i2.p2.9.m9.5.5.1.1.1.3.3.cmml">
               j
              </mi>
             </mrow>
            </msub>
            <mo id="A4.I1.i2.p2.9.m9.9.9.5.5.7" xref="A4.I1.i2.p2.9.m9.9.9.5.6.cmml">
             ,
            </mo>
            <mrow id="A4.I1.i2.p2.9.m9.6.6.2.2.2.1" xref="A4.I1.i2.p2.9.m9.6.6.2.2.2.2.cmml">
             <mi id="A4.I1.i2.p2.9.m9.1.1" xref="A4.I1.i2.p2.9.m9.1.1.cmml">
              sin
             </mi>
             <mo id="A4.I1.i2.p2.9.m9.6.6.2.2.2.1a" xref="A4.I1.i2.p2.9.m9.6.6.2.2.2.2.cmml">
              ⁡
             </mo>
             <mrow id="A4.I1.i2.p2.9.m9.6.6.2.2.2.1.1" xref="A4.I1.i2.p2.9.m9.6.6.2.2.2.2.cmml">
              <mo id="A4.I1.i2.p2.9.m9.6.6.2.2.2.1.1.2" stretchy="false" xref="A4.I1.i2.p2.9.m9.6.6.2.2.2.2.cmml">
               (
              </mo>
              <msub id="A4.I1.i2.p2.9.m9.6.6.2.2.2.1.1.1" xref="A4.I1.i2.p2.9.m9.6.6.2.2.2.1.1.1.cmml">
               <mi id="A4.I1.i2.p2.9.m9.6.6.2.2.2.1.1.1.2" xref="A4.I1.i2.p2.9.m9.6.6.2.2.2.1.1.1.2.cmml">
                θ
               </mi>
               <mi id="A4.I1.i2.p2.9.m9.6.6.2.2.2.1.1.1.3" xref="A4.I1.i2.p2.9.m9.6.6.2.2.2.1.1.1.3.cmml">
                h
               </mi>
              </msub>
              <mo id="A4.I1.i2.p2.9.m9.6.6.2.2.2.1.1.3" stretchy="false" xref="A4.I1.i2.p2.9.m9.6.6.2.2.2.2.cmml">
               )
              </mo>
             </mrow>
            </mrow>
            <mo id="A4.I1.i2.p2.9.m9.9.9.5.5.8" xref="A4.I1.i2.p2.9.m9.9.9.5.6.cmml">
             ,
            </mo>
            <mrow id="A4.I1.i2.p2.9.m9.7.7.3.3.3.1" xref="A4.I1.i2.p2.9.m9.7.7.3.3.3.2.cmml">
             <mi id="A4.I1.i2.p2.9.m9.2.2" xref="A4.I1.i2.p2.9.m9.2.2.cmml">
              cos
             </mi>
             <mo id="A4.I1.i2.p2.9.m9.7.7.3.3.3.1a" xref="A4.I1.i2.p2.9.m9.7.7.3.3.3.2.cmml">
              ⁡
             </mo>
             <mrow id="A4.I1.i2.p2.9.m9.7.7.3.3.3.1.1" xref="A4.I1.i2.p2.9.m9.7.7.3.3.3.2.cmml">
              <mo id="A4.I1.i2.p2.9.m9.7.7.3.3.3.1.1.2" stretchy="false" xref="A4.I1.i2.p2.9.m9.7.7.3.3.3.2.cmml">
               (
              </mo>
              <msub id="A4.I1.i2.p2.9.m9.7.7.3.3.3.1.1.1" xref="A4.I1.i2.p2.9.m9.7.7.3.3.3.1.1.1.cmml">
               <mi id="A4.I1.i2.p2.9.m9.7.7.3.3.3.1.1.1.2" xref="A4.I1.i2.p2.9.m9.7.7.3.3.3.1.1.1.2.cmml">
                θ
               </mi>
               <mi id="A4.I1.i2.p2.9.m9.7.7.3.3.3.1.1.1.3" xref="A4.I1.i2.p2.9.m9.7.7.3.3.3.1.1.1.3.cmml">
                h
               </mi>
              </msub>
              <mo id="A4.I1.i2.p2.9.m9.7.7.3.3.3.1.1.3" stretchy="false" xref="A4.I1.i2.p2.9.m9.7.7.3.3.3.2.cmml">
               )
              </mo>
             </mrow>
            </mrow>
            <mo id="A4.I1.i2.p2.9.m9.9.9.5.5.9" xref="A4.I1.i2.p2.9.m9.9.9.5.6.cmml">
             ,
            </mo>
            <mrow id="A4.I1.i2.p2.9.m9.8.8.4.4.4.1" xref="A4.I1.i2.p2.9.m9.8.8.4.4.4.2.cmml">
             <mi id="A4.I1.i2.p2.9.m9.3.3" xref="A4.I1.i2.p2.9.m9.3.3.cmml">
              sin
             </mi>
             <mo id="A4.I1.i2.p2.9.m9.8.8.4.4.4.1a" xref="A4.I1.i2.p2.9.m9.8.8.4.4.4.2.cmml">
              ⁡
             </mo>
             <mrow id="A4.I1.i2.p2.9.m9.8.8.4.4.4.1.1" xref="A4.I1.i2.p2.9.m9.8.8.4.4.4.2.cmml">
              <mo id="A4.I1.i2.p2.9.m9.8.8.4.4.4.1.1.2" stretchy="false" xref="A4.I1.i2.p2.9.m9.8.8.4.4.4.2.cmml">
               (
              </mo>
              <msub id="A4.I1.i2.p2.9.m9.8.8.4.4.4.1.1.1" xref="A4.I1.i2.p2.9.m9.8.8.4.4.4.1.1.1.cmml">
               <mi id="A4.I1.i2.p2.9.m9.8.8.4.4.4.1.1.1.2" xref="A4.I1.i2.p2.9.m9.8.8.4.4.4.1.1.1.2.cmml">
                θ
               </mi>
               <mi id="A4.I1.i2.p2.9.m9.8.8.4.4.4.1.1.1.3" xref="A4.I1.i2.p2.9.m9.8.8.4.4.4.1.1.1.3.cmml">
                v
               </mi>
              </msub>
              <mo id="A4.I1.i2.p2.9.m9.8.8.4.4.4.1.1.3" stretchy="false" xref="A4.I1.i2.p2.9.m9.8.8.4.4.4.2.cmml">
               )
              </mo>
             </mrow>
            </mrow>
            <mo id="A4.I1.i2.p2.9.m9.9.9.5.5.10" xref="A4.I1.i2.p2.9.m9.9.9.5.6.cmml">
             ,
            </mo>
            <mrow id="A4.I1.i2.p2.9.m9.9.9.5.5.5.1" xref="A4.I1.i2.p2.9.m9.9.9.5.5.5.2.cmml">
             <mi id="A4.I1.i2.p2.9.m9.4.4" xref="A4.I1.i2.p2.9.m9.4.4.cmml">
              cos
             </mi>
             <mo id="A4.I1.i2.p2.9.m9.9.9.5.5.5.1a" xref="A4.I1.i2.p2.9.m9.9.9.5.5.5.2.cmml">
              ⁡
             </mo>
             <mrow id="A4.I1.i2.p2.9.m9.9.9.5.5.5.1.1" xref="A4.I1.i2.p2.9.m9.9.9.5.5.5.2.cmml">
              <mo id="A4.I1.i2.p2.9.m9.9.9.5.5.5.1.1.2" stretchy="false" xref="A4.I1.i2.p2.9.m9.9.9.5.5.5.2.cmml">
               (
              </mo>
              <msub id="A4.I1.i2.p2.9.m9.9.9.5.5.5.1.1.1" xref="A4.I1.i2.p2.9.m9.9.9.5.5.5.1.1.1.cmml">
               <mi id="A4.I1.i2.p2.9.m9.9.9.5.5.5.1.1.1.2" xref="A4.I1.i2.p2.9.m9.9.9.5.5.5.1.1.1.2.cmml">
                θ
               </mi>
               <mi id="A4.I1.i2.p2.9.m9.9.9.5.5.5.1.1.1.3" xref="A4.I1.i2.p2.9.m9.9.9.5.5.5.1.1.1.3.cmml">
                v
               </mi>
              </msub>
              <mo id="A4.I1.i2.p2.9.m9.9.9.5.5.5.1.1.3" stretchy="false" xref="A4.I1.i2.p2.9.m9.9.9.5.5.5.2.cmml">
               )
              </mo>
             </mrow>
            </mrow>
            <mo id="A4.I1.i2.p2.9.m9.9.9.5.5.11" stretchy="false" xref="A4.I1.i2.p2.9.m9.9.9.5.6.cmml">
             ]
            </mo>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p2.9.m9.9b">
           <apply id="A4.I1.i2.p2.9.m9.9.9.cmml" xref="A4.I1.i2.p2.9.m9.9.9">
            <eq id="A4.I1.i2.p2.9.m9.9.9.6.cmml" xref="A4.I1.i2.p2.9.m9.9.9.6">
            </eq>
            <apply id="A4.I1.i2.p2.9.m9.9.9.7.cmml" xref="A4.I1.i2.p2.9.m9.9.9.7">
             <csymbol cd="ambiguous" id="A4.I1.i2.p2.9.m9.9.9.7.1.cmml" xref="A4.I1.i2.p2.9.m9.9.9.7">
              subscript
             </csymbol>
             <ci id="A4.I1.i2.p2.9.m9.9.9.7.2.cmml" xref="A4.I1.i2.p2.9.m9.9.9.7.2">
              𝑓
             </ci>
             <apply id="A4.I1.i2.p2.9.m9.9.9.7.3.cmml" xref="A4.I1.i2.p2.9.m9.9.9.7.3">
              <times id="A4.I1.i2.p2.9.m9.9.9.7.3.1.cmml" xref="A4.I1.i2.p2.9.m9.9.9.7.3.1">
              </times>
              <ci id="A4.I1.i2.p2.9.m9.9.9.7.3.2.cmml" xref="A4.I1.i2.p2.9.m9.9.9.7.3.2">
               𝑖
              </ci>
              <ci id="A4.I1.i2.p2.9.m9.9.9.7.3.3.cmml" xref="A4.I1.i2.p2.9.m9.9.9.7.3.3">
               𝑗
              </ci>
             </apply>
            </apply>
            <list id="A4.I1.i2.p2.9.m9.9.9.5.6.cmml" xref="A4.I1.i2.p2.9.m9.9.9.5.5">
             <apply id="A4.I1.i2.p2.9.m9.5.5.1.1.1.cmml" xref="A4.I1.i2.p2.9.m9.5.5.1.1.1">
              <csymbol cd="ambiguous" id="A4.I1.i2.p2.9.m9.5.5.1.1.1.1.cmml" xref="A4.I1.i2.p2.9.m9.5.5.1.1.1">
               subscript
              </csymbol>
              <ci id="A4.I1.i2.p2.9.m9.5.5.1.1.1.2.cmml" xref="A4.I1.i2.p2.9.m9.5.5.1.1.1.2">
               𝑑
              </ci>
              <apply id="A4.I1.i2.p2.9.m9.5.5.1.1.1.3.cmml" xref="A4.I1.i2.p2.9.m9.5.5.1.1.1.3">
               <times id="A4.I1.i2.p2.9.m9.5.5.1.1.1.3.1.cmml" xref="A4.I1.i2.p2.9.m9.5.5.1.1.1.3.1">
               </times>
               <ci id="A4.I1.i2.p2.9.m9.5.5.1.1.1.3.2.cmml" xref="A4.I1.i2.p2.9.m9.5.5.1.1.1.3.2">
                𝑖
               </ci>
               <ci id="A4.I1.i2.p2.9.m9.5.5.1.1.1.3.3.cmml" xref="A4.I1.i2.p2.9.m9.5.5.1.1.1.3.3">
                𝑗
               </ci>
              </apply>
             </apply>
             <apply id="A4.I1.i2.p2.9.m9.6.6.2.2.2.2.cmml" xref="A4.I1.i2.p2.9.m9.6.6.2.2.2.1">
              <sin id="A4.I1.i2.p2.9.m9.1.1.cmml" xref="A4.I1.i2.p2.9.m9.1.1">
              </sin>
              <apply id="A4.I1.i2.p2.9.m9.6.6.2.2.2.1.1.1.cmml" xref="A4.I1.i2.p2.9.m9.6.6.2.2.2.1.1.1">
               <csymbol cd="ambiguous" id="A4.I1.i2.p2.9.m9.6.6.2.2.2.1.1.1.1.cmml" xref="A4.I1.i2.p2.9.m9.6.6.2.2.2.1.1.1">
                subscript
               </csymbol>
               <ci id="A4.I1.i2.p2.9.m9.6.6.2.2.2.1.1.1.2.cmml" xref="A4.I1.i2.p2.9.m9.6.6.2.2.2.1.1.1.2">
                𝜃
               </ci>
               <ci id="A4.I1.i2.p2.9.m9.6.6.2.2.2.1.1.1.3.cmml" xref="A4.I1.i2.p2.9.m9.6.6.2.2.2.1.1.1.3">
                ℎ
               </ci>
              </apply>
             </apply>
             <apply id="A4.I1.i2.p2.9.m9.7.7.3.3.3.2.cmml" xref="A4.I1.i2.p2.9.m9.7.7.3.3.3.1">
              <cos id="A4.I1.i2.p2.9.m9.2.2.cmml" xref="A4.I1.i2.p2.9.m9.2.2">
              </cos>
              <apply id="A4.I1.i2.p2.9.m9.7.7.3.3.3.1.1.1.cmml" xref="A4.I1.i2.p2.9.m9.7.7.3.3.3.1.1.1">
               <csymbol cd="ambiguous" id="A4.I1.i2.p2.9.m9.7.7.3.3.3.1.1.1.1.cmml" xref="A4.I1.i2.p2.9.m9.7.7.3.3.3.1.1.1">
                subscript
               </csymbol>
               <ci id="A4.I1.i2.p2.9.m9.7.7.3.3.3.1.1.1.2.cmml" xref="A4.I1.i2.p2.9.m9.7.7.3.3.3.1.1.1.2">
                𝜃
               </ci>
               <ci id="A4.I1.i2.p2.9.m9.7.7.3.3.3.1.1.1.3.cmml" xref="A4.I1.i2.p2.9.m9.7.7.3.3.3.1.1.1.3">
                ℎ
               </ci>
              </apply>
             </apply>
             <apply id="A4.I1.i2.p2.9.m9.8.8.4.4.4.2.cmml" xref="A4.I1.i2.p2.9.m9.8.8.4.4.4.1">
              <sin id="A4.I1.i2.p2.9.m9.3.3.cmml" xref="A4.I1.i2.p2.9.m9.3.3">
              </sin>
              <apply id="A4.I1.i2.p2.9.m9.8.8.4.4.4.1.1.1.cmml" xref="A4.I1.i2.p2.9.m9.8.8.4.4.4.1.1.1">
               <csymbol cd="ambiguous" id="A4.I1.i2.p2.9.m9.8.8.4.4.4.1.1.1.1.cmml" xref="A4.I1.i2.p2.9.m9.8.8.4.4.4.1.1.1">
                subscript
               </csymbol>
               <ci id="A4.I1.i2.p2.9.m9.8.8.4.4.4.1.1.1.2.cmml" xref="A4.I1.i2.p2.9.m9.8.8.4.4.4.1.1.1.2">
                𝜃
               </ci>
               <ci id="A4.I1.i2.p2.9.m9.8.8.4.4.4.1.1.1.3.cmml" xref="A4.I1.i2.p2.9.m9.8.8.4.4.4.1.1.1.3">
                𝑣
               </ci>
              </apply>
             </apply>
             <apply id="A4.I1.i2.p2.9.m9.9.9.5.5.5.2.cmml" xref="A4.I1.i2.p2.9.m9.9.9.5.5.5.1">
              <cos id="A4.I1.i2.p2.9.m9.4.4.cmml" xref="A4.I1.i2.p2.9.m9.4.4">
              </cos>
              <apply id="A4.I1.i2.p2.9.m9.9.9.5.5.5.1.1.1.cmml" xref="A4.I1.i2.p2.9.m9.9.9.5.5.5.1.1.1">
               <csymbol cd="ambiguous" id="A4.I1.i2.p2.9.m9.9.9.5.5.5.1.1.1.1.cmml" xref="A4.I1.i2.p2.9.m9.9.9.5.5.5.1.1.1">
                subscript
               </csymbol>
               <ci id="A4.I1.i2.p2.9.m9.9.9.5.5.5.1.1.1.2.cmml" xref="A4.I1.i2.p2.9.m9.9.9.5.5.5.1.1.1.2">
                𝜃
               </ci>
               <ci id="A4.I1.i2.p2.9.m9.9.9.5.5.5.1.1.1.3.cmml" xref="A4.I1.i2.p2.9.m9.9.9.5.5.5.1.1.1.3">
                𝑣
               </ci>
              </apply>
             </apply>
            </list>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p2.9.m9.9c">
           f_{ij}=[d_{ij},\sin{(\theta_{h})},\cos{(\theta_{h})},\sin{(\theta_{v})},\cos{(\theta_{v})}]
          </annotation>
         </semantics>
        </math>
        . To combine this feature with objects, the spatial attention computes
        <math alttext="\omega^{s}_{ij}=g_{i}f_{ij}" class="ltx_Math" display="inline" id="A4.I1.i2.p2.10.m10.1">
         <semantics id="A4.I1.i2.p2.10.m10.1a">
          <mrow id="A4.I1.i2.p2.10.m10.1.1" xref="A4.I1.i2.p2.10.m10.1.1.cmml">
           <msubsup id="A4.I1.i2.p2.10.m10.1.1.2" xref="A4.I1.i2.p2.10.m10.1.1.2.cmml">
            <mi id="A4.I1.i2.p2.10.m10.1.1.2.2.2" xref="A4.I1.i2.p2.10.m10.1.1.2.2.2.cmml">
             ω
            </mi>
            <mrow id="A4.I1.i2.p2.10.m10.1.1.2.3" xref="A4.I1.i2.p2.10.m10.1.1.2.3.cmml">
             <mi id="A4.I1.i2.p2.10.m10.1.1.2.3.2" xref="A4.I1.i2.p2.10.m10.1.1.2.3.2.cmml">
              i
             </mi>
             <mo id="A4.I1.i2.p2.10.m10.1.1.2.3.1" lspace="0em" rspace="0em" xref="A4.I1.i2.p2.10.m10.1.1.2.3.1.cmml">
              ​
             </mo>
             <mi id="A4.I1.i2.p2.10.m10.1.1.2.3.3" xref="A4.I1.i2.p2.10.m10.1.1.2.3.3.cmml">
              j
             </mi>
            </mrow>
            <mi id="A4.I1.i2.p2.10.m10.1.1.2.2.3" xref="A4.I1.i2.p2.10.m10.1.1.2.2.3.cmml">
             s
            </mi>
           </msubsup>
           <mo id="A4.I1.i2.p2.10.m10.1.1.1" xref="A4.I1.i2.p2.10.m10.1.1.1.cmml">
            =
           </mo>
           <mrow id="A4.I1.i2.p2.10.m10.1.1.3" xref="A4.I1.i2.p2.10.m10.1.1.3.cmml">
            <msub id="A4.I1.i2.p2.10.m10.1.1.3.2" xref="A4.I1.i2.p2.10.m10.1.1.3.2.cmml">
             <mi id="A4.I1.i2.p2.10.m10.1.1.3.2.2" xref="A4.I1.i2.p2.10.m10.1.1.3.2.2.cmml">
              g
             </mi>
             <mi id="A4.I1.i2.p2.10.m10.1.1.3.2.3" xref="A4.I1.i2.p2.10.m10.1.1.3.2.3.cmml">
              i
             </mi>
            </msub>
            <mo id="A4.I1.i2.p2.10.m10.1.1.3.1" lspace="0em" rspace="0em" xref="A4.I1.i2.p2.10.m10.1.1.3.1.cmml">
             ​
            </mo>
            <msub id="A4.I1.i2.p2.10.m10.1.1.3.3" xref="A4.I1.i2.p2.10.m10.1.1.3.3.cmml">
             <mi id="A4.I1.i2.p2.10.m10.1.1.3.3.2" xref="A4.I1.i2.p2.10.m10.1.1.3.3.2.cmml">
              f
             </mi>
             <mrow id="A4.I1.i2.p2.10.m10.1.1.3.3.3" xref="A4.I1.i2.p2.10.m10.1.1.3.3.3.cmml">
              <mi id="A4.I1.i2.p2.10.m10.1.1.3.3.3.2" xref="A4.I1.i2.p2.10.m10.1.1.3.3.3.2.cmml">
               i
              </mi>
              <mo id="A4.I1.i2.p2.10.m10.1.1.3.3.3.1" lspace="0em" rspace="0em" xref="A4.I1.i2.p2.10.m10.1.1.3.3.3.1.cmml">
               ​
              </mo>
              <mi id="A4.I1.i2.p2.10.m10.1.1.3.3.3.3" xref="A4.I1.i2.p2.10.m10.1.1.3.3.3.3.cmml">
               j
              </mi>
             </mrow>
            </msub>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p2.10.m10.1b">
           <apply id="A4.I1.i2.p2.10.m10.1.1.cmml" xref="A4.I1.i2.p2.10.m10.1.1">
            <eq id="A4.I1.i2.p2.10.m10.1.1.1.cmml" xref="A4.I1.i2.p2.10.m10.1.1.1">
            </eq>
            <apply id="A4.I1.i2.p2.10.m10.1.1.2.cmml" xref="A4.I1.i2.p2.10.m10.1.1.2">
             <csymbol cd="ambiguous" id="A4.I1.i2.p2.10.m10.1.1.2.1.cmml" xref="A4.I1.i2.p2.10.m10.1.1.2">
              subscript
             </csymbol>
             <apply id="A4.I1.i2.p2.10.m10.1.1.2.2.cmml" xref="A4.I1.i2.p2.10.m10.1.1.2">
              <csymbol cd="ambiguous" id="A4.I1.i2.p2.10.m10.1.1.2.2.1.cmml" xref="A4.I1.i2.p2.10.m10.1.1.2">
               superscript
              </csymbol>
              <ci id="A4.I1.i2.p2.10.m10.1.1.2.2.2.cmml" xref="A4.I1.i2.p2.10.m10.1.1.2.2.2">
               𝜔
              </ci>
              <ci id="A4.I1.i2.p2.10.m10.1.1.2.2.3.cmml" xref="A4.I1.i2.p2.10.m10.1.1.2.2.3">
               𝑠
              </ci>
             </apply>
             <apply id="A4.I1.i2.p2.10.m10.1.1.2.3.cmml" xref="A4.I1.i2.p2.10.m10.1.1.2.3">
              <times id="A4.I1.i2.p2.10.m10.1.1.2.3.1.cmml" xref="A4.I1.i2.p2.10.m10.1.1.2.3.1">
              </times>
              <ci id="A4.I1.i2.p2.10.m10.1.1.2.3.2.cmml" xref="A4.I1.i2.p2.10.m10.1.1.2.3.2">
               𝑖
              </ci>
              <ci id="A4.I1.i2.p2.10.m10.1.1.2.3.3.cmml" xref="A4.I1.i2.p2.10.m10.1.1.2.3.3">
               𝑗
              </ci>
             </apply>
            </apply>
            <apply id="A4.I1.i2.p2.10.m10.1.1.3.cmml" xref="A4.I1.i2.p2.10.m10.1.1.3">
             <times id="A4.I1.i2.p2.10.m10.1.1.3.1.cmml" xref="A4.I1.i2.p2.10.m10.1.1.3.1">
             </times>
             <apply id="A4.I1.i2.p2.10.m10.1.1.3.2.cmml" xref="A4.I1.i2.p2.10.m10.1.1.3.2">
              <csymbol cd="ambiguous" id="A4.I1.i2.p2.10.m10.1.1.3.2.1.cmml" xref="A4.I1.i2.p2.10.m10.1.1.3.2">
               subscript
              </csymbol>
              <ci id="A4.I1.i2.p2.10.m10.1.1.3.2.2.cmml" xref="A4.I1.i2.p2.10.m10.1.1.3.2.2">
               𝑔
              </ci>
              <ci id="A4.I1.i2.p2.10.m10.1.1.3.2.3.cmml" xref="A4.I1.i2.p2.10.m10.1.1.3.2.3">
               𝑖
              </ci>
             </apply>
             <apply id="A4.I1.i2.p2.10.m10.1.1.3.3.cmml" xref="A4.I1.i2.p2.10.m10.1.1.3.3">
              <csymbol cd="ambiguous" id="A4.I1.i2.p2.10.m10.1.1.3.3.1.cmml" xref="A4.I1.i2.p2.10.m10.1.1.3.3">
               subscript
              </csymbol>
              <ci id="A4.I1.i2.p2.10.m10.1.1.3.3.2.cmml" xref="A4.I1.i2.p2.10.m10.1.1.3.3.2">
               𝑓
              </ci>
              <apply id="A4.I1.i2.p2.10.m10.1.1.3.3.3.cmml" xref="A4.I1.i2.p2.10.m10.1.1.3.3.3">
               <times id="A4.I1.i2.p2.10.m10.1.1.3.3.3.1.cmml" xref="A4.I1.i2.p2.10.m10.1.1.3.3.3.1">
               </times>
               <ci id="A4.I1.i2.p2.10.m10.1.1.3.3.3.2.cmml" xref="A4.I1.i2.p2.10.m10.1.1.3.3.3.2">
                𝑖
               </ci>
               <ci id="A4.I1.i2.p2.10.m10.1.1.3.3.3.3.cmml" xref="A4.I1.i2.p2.10.m10.1.1.3.3.3.3">
                𝑗
               </ci>
              </apply>
             </apply>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p2.10.m10.1c">
           \omega^{s}_{ij}=g_{i}f_{ij}
          </annotation>
         </semantics>
        </math>
        where
        <math alttext="g_{i}=W_{S}^{T}o_{i}" class="ltx_Math" display="inline" id="A4.I1.i2.p2.11.m11.1">
         <semantics id="A4.I1.i2.p2.11.m11.1a">
          <mrow id="A4.I1.i2.p2.11.m11.1.1" xref="A4.I1.i2.p2.11.m11.1.1.cmml">
           <msub id="A4.I1.i2.p2.11.m11.1.1.2" xref="A4.I1.i2.p2.11.m11.1.1.2.cmml">
            <mi id="A4.I1.i2.p2.11.m11.1.1.2.2" xref="A4.I1.i2.p2.11.m11.1.1.2.2.cmml">
             g
            </mi>
            <mi id="A4.I1.i2.p2.11.m11.1.1.2.3" xref="A4.I1.i2.p2.11.m11.1.1.2.3.cmml">
             i
            </mi>
           </msub>
           <mo id="A4.I1.i2.p2.11.m11.1.1.1" xref="A4.I1.i2.p2.11.m11.1.1.1.cmml">
            =
           </mo>
           <mrow id="A4.I1.i2.p2.11.m11.1.1.3" xref="A4.I1.i2.p2.11.m11.1.1.3.cmml">
            <msubsup id="A4.I1.i2.p2.11.m11.1.1.3.2" xref="A4.I1.i2.p2.11.m11.1.1.3.2.cmml">
             <mi id="A4.I1.i2.p2.11.m11.1.1.3.2.2.2" xref="A4.I1.i2.p2.11.m11.1.1.3.2.2.2.cmml">
              W
             </mi>
             <mi id="A4.I1.i2.p2.11.m11.1.1.3.2.2.3" xref="A4.I1.i2.p2.11.m11.1.1.3.2.2.3.cmml">
              S
             </mi>
             <mi id="A4.I1.i2.p2.11.m11.1.1.3.2.3" xref="A4.I1.i2.p2.11.m11.1.1.3.2.3.cmml">
              T
             </mi>
            </msubsup>
            <mo id="A4.I1.i2.p2.11.m11.1.1.3.1" lspace="0em" rspace="0em" xref="A4.I1.i2.p2.11.m11.1.1.3.1.cmml">
             ​
            </mo>
            <msub id="A4.I1.i2.p2.11.m11.1.1.3.3" xref="A4.I1.i2.p2.11.m11.1.1.3.3.cmml">
             <mi id="A4.I1.i2.p2.11.m11.1.1.3.3.2" xref="A4.I1.i2.p2.11.m11.1.1.3.3.2.cmml">
              o
             </mi>
             <mi id="A4.I1.i2.p2.11.m11.1.1.3.3.3" xref="A4.I1.i2.p2.11.m11.1.1.3.3.3.cmml">
              i
             </mi>
            </msub>
           </mrow>
          </mrow>
          <annotation-xml encoding="MathML-Content" id="A4.I1.i2.p2.11.m11.1b">
           <apply id="A4.I1.i2.p2.11.m11.1.1.cmml" xref="A4.I1.i2.p2.11.m11.1.1">
            <eq id="A4.I1.i2.p2.11.m11.1.1.1.cmml" xref="A4.I1.i2.p2.11.m11.1.1.1">
            </eq>
            <apply id="A4.I1.i2.p2.11.m11.1.1.2.cmml" xref="A4.I1.i2.p2.11.m11.1.1.2">
             <csymbol cd="ambiguous" id="A4.I1.i2.p2.11.m11.1.1.2.1.cmml" xref="A4.I1.i2.p2.11.m11.1.1.2">
              subscript
             </csymbol>
             <ci id="A4.I1.i2.p2.11.m11.1.1.2.2.cmml" xref="A4.I1.i2.p2.11.m11.1.1.2.2">
              𝑔
             </ci>
             <ci id="A4.I1.i2.p2.11.m11.1.1.2.3.cmml" xref="A4.I1.i2.p2.11.m11.1.1.2.3">
              𝑖
             </ci>
            </apply>
            <apply id="A4.I1.i2.p2.11.m11.1.1.3.cmml" xref="A4.I1.i2.p2.11.m11.1.1.3">
             <times id="A4.I1.i2.p2.11.m11.1.1.3.1.cmml" xref="A4.I1.i2.p2.11.m11.1.1.3.1">
             </times>
             <apply id="A4.I1.i2.p2.11.m11.1.1.3.2.cmml" xref="A4.I1.i2.p2.11.m11.1.1.3.2">
              <csymbol cd="ambiguous" id="A4.I1.i2.p2.11.m11.1.1.3.2.1.cmml" xref="A4.I1.i2.p2.11.m11.1.1.3.2">
               superscript
              </csymbol>
              <apply id="A4.I1.i2.p2.11.m11.1.1.3.2.2.cmml" xref="A4.I1.i2.p2.11.m11.1.1.3.2">
               <csymbol cd="ambiguous" id="A4.I1.i2.p2.11.m11.1.1.3.2.2.1.cmml" xref="A4.I1.i2.p2.11.m11.1.1.3.2">
                subscript
               </csymbol>
               <ci id="A4.I1.i2.p2.11.m11.1.1.3.2.2.2.cmml" xref="A4.I1.i2.p2.11.m11.1.1.3.2.2.2">
                𝑊
               </ci>
               <ci id="A4.I1.i2.p2.11.m11.1.1.3.2.2.3.cmml" xref="A4.I1.i2.p2.11.m11.1.1.3.2.2.3">
                𝑆
               </ci>
              </apply>
              <ci id="A4.I1.i2.p2.11.m11.1.1.3.2.3.cmml" xref="A4.I1.i2.p2.11.m11.1.1.3.2.3">
               𝑇
              </ci>
             </apply>
             <apply id="A4.I1.i2.p2.11.m11.1.1.3.3.cmml" xref="A4.I1.i2.p2.11.m11.1.1.3.3">
              <csymbol cd="ambiguous" id="A4.I1.i2.p2.11.m11.1.1.3.3.1.cmml" xref="A4.I1.i2.p2.11.m11.1.1.3.3">
               subscript
              </csymbol>
              <ci id="A4.I1.i2.p2.11.m11.1.1.3.3.2.cmml" xref="A4.I1.i2.p2.11.m11.1.1.3.3.2">
               𝑜
              </ci>
              <ci id="A4.I1.i2.p2.11.m11.1.1.3.3.3.cmml" xref="A4.I1.i2.p2.11.m11.1.1.3.3.3">
               𝑖
              </ci>
             </apply>
            </apply>
           </apply>
          </annotation-xml>
          <annotation encoding="application/x-tex" id="A4.I1.i2.p2.11.m11.1c">
           g_{i}=W_{S}^{T}o_{i}
          </annotation>
         </semantics>
        </math>
        is a 5-dimensional vector. The spatial attention further reweights the original self-attention weight matrix as
       </p>
       <table class="ltx_equation ltx_eqn_table" id="A4.Ex1">
        <tbody>
         <tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
          <td class="ltx_eqn_cell ltx_eqn_center_padleft">
          </td>
          <td class="ltx_eqn_cell ltx_align_center">
           <math alttext="\omega_{ij}=\frac{\sigma(\omega^{s}_{ij})exp(\omega^{o}_{ij})}{\sum_{l=1}^{N}\sigma(\omega^{s}_{il})exp(\omega^{o}_{il})}." class="ltx_Math" display="block" id="A4.Ex1.m1.5">
            <semantics id="A4.Ex1.m1.5a">
             <mrow id="A4.Ex1.m1.5.5.1" xref="A4.Ex1.m1.5.5.1.1.cmml">
              <mrow id="A4.Ex1.m1.5.5.1.1" xref="A4.Ex1.m1.5.5.1.1.cmml">
               <msub id="A4.Ex1.m1.5.5.1.1.2" xref="A4.Ex1.m1.5.5.1.1.2.cmml">
                <mi id="A4.Ex1.m1.5.5.1.1.2.2" xref="A4.Ex1.m1.5.5.1.1.2.2.cmml">
                 ω
                </mi>
                <mrow id="A4.Ex1.m1.5.5.1.1.2.3" xref="A4.Ex1.m1.5.5.1.1.2.3.cmml">
                 <mi id="A4.Ex1.m1.5.5.1.1.2.3.2" xref="A4.Ex1.m1.5.5.1.1.2.3.2.cmml">
                  i
                 </mi>
                 <mo id="A4.Ex1.m1.5.5.1.1.2.3.1" lspace="0em" rspace="0em" xref="A4.Ex1.m1.5.5.1.1.2.3.1.cmml">
                  ​
                 </mo>
                 <mi id="A4.Ex1.m1.5.5.1.1.2.3.3" xref="A4.Ex1.m1.5.5.1.1.2.3.3.cmml">
                  j
                 </mi>
                </mrow>
               </msub>
               <mo id="A4.Ex1.m1.5.5.1.1.1" xref="A4.Ex1.m1.5.5.1.1.1.cmml">
                =
               </mo>
               <mfrac id="A4.Ex1.m1.4.4" xref="A4.Ex1.m1.4.4.cmml">
                <mrow id="A4.Ex1.m1.2.2.2" xref="A4.Ex1.m1.2.2.2.cmml">
                 <mi id="A4.Ex1.m1.2.2.2.4" xref="A4.Ex1.m1.2.2.2.4.cmml">
                  σ
                 </mi>
                 <mo id="A4.Ex1.m1.2.2.2.3" lspace="0em" rspace="0em" xref="A4.Ex1.m1.2.2.2.3.cmml">
                  ​
                 </mo>
                 <mrow id="A4.Ex1.m1.1.1.1.1.1" xref="A4.Ex1.m1.1.1.1.1.1.1.cmml">
                  <mo id="A4.Ex1.m1.1.1.1.1.1.2" stretchy="false" xref="A4.Ex1.m1.1.1.1.1.1.1.cmml">
                   (
                  </mo>
                  <msubsup id="A4.Ex1.m1.1.1.1.1.1.1" xref="A4.Ex1.m1.1.1.1.1.1.1.cmml">
                   <mi id="A4.Ex1.m1.1.1.1.1.1.1.2.2" xref="A4.Ex1.m1.1.1.1.1.1.1.2.2.cmml">
                    ω
                   </mi>
                   <mrow id="A4.Ex1.m1.1.1.1.1.1.1.3" xref="A4.Ex1.m1.1.1.1.1.1.1.3.cmml">
                    <mi id="A4.Ex1.m1.1.1.1.1.1.1.3.2" xref="A4.Ex1.m1.1.1.1.1.1.1.3.2.cmml">
                     i
                    </mi>
                    <mo id="A4.Ex1.m1.1.1.1.1.1.1.3.1" lspace="0em" rspace="0em" xref="A4.Ex1.m1.1.1.1.1.1.1.3.1.cmml">
                     ​
                    </mo>
                    <mi id="A4.Ex1.m1.1.1.1.1.1.1.3.3" xref="A4.Ex1.m1.1.1.1.1.1.1.3.3.cmml">
                     j
                    </mi>
                   </mrow>
                   <mi id="A4.Ex1.m1.1.1.1.1.1.1.2.3" xref="A4.Ex1.m1.1.1.1.1.1.1.2.3.cmml">
                    s
                   </mi>
                  </msubsup>
                  <mo id="A4.Ex1.m1.1.1.1.1.1.3" stretchy="false" xref="A4.Ex1.m1.1.1.1.1.1.1.cmml">
                   )
                  </mo>
                 </mrow>
                 <mo id="A4.Ex1.m1.2.2.2.3a" lspace="0em" rspace="0em" xref="A4.Ex1.m1.2.2.2.3.cmml">
                  ​
                 </mo>
                 <mi id="A4.Ex1.m1.2.2.2.5" xref="A4.Ex1.m1.2.2.2.5.cmml">
                  e
                 </mi>
                 <mo id="A4.Ex1.m1.2.2.2.3b" lspace="0em" rspace="0em" xref="A4.Ex1.m1.2.2.2.3.cmml">
                  ​
                 </mo>
                 <mi id="A4.Ex1.m1.2.2.2.6" xref="A4.Ex1.m1.2.2.2.6.cmml">
                  x
                 </mi>
                 <mo id="A4.Ex1.m1.2.2.2.3c" lspace="0em" rspace="0em" xref="A4.Ex1.m1.2.2.2.3.cmml">
                  ​
                 </mo>
                 <mi id="A4.Ex1.m1.2.2.2.7" xref="A4.Ex1.m1.2.2.2.7.cmml">
                  p
                 </mi>
                 <mo id="A4.Ex1.m1.2.2.2.3d" lspace="0em" rspace="0em" xref="A4.Ex1.m1.2.2.2.3.cmml">
                  ​
                 </mo>
                 <mrow id="A4.Ex1.m1.2.2.2.2.1" xref="A4.Ex1.m1.2.2.2.2.1.1.cmml">
                  <mo id="A4.Ex1.m1.2.2.2.2.1.2" stretchy="false" xref="A4.Ex1.m1.2.2.2.2.1.1.cmml">
                   (
                  </mo>
                  <msubsup id="A4.Ex1.m1.2.2.2.2.1.1" xref="A4.Ex1.m1.2.2.2.2.1.1.cmml">
                   <mi id="A4.Ex1.m1.2.2.2.2.1.1.2.2" xref="A4.Ex1.m1.2.2.2.2.1.1.2.2.cmml">
                    ω
                   </mi>
                   <mrow id="A4.Ex1.m1.2.2.2.2.1.1.3" xref="A4.Ex1.m1.2.2.2.2.1.1.3.cmml">
                    <mi id="A4.Ex1.m1.2.2.2.2.1.1.3.2" xref="A4.Ex1.m1.2.2.2.2.1.1.3.2.cmml">
                     i
                    </mi>
                    <mo id="A4.Ex1.m1.2.2.2.2.1.1.3.1" lspace="0em" rspace="0em" xref="A4.Ex1.m1.2.2.2.2.1.1.3.1.cmml">
                     ​
                    </mo>
                    <mi id="A4.Ex1.m1.2.2.2.2.1.1.3.3" xref="A4.Ex1.m1.2.2.2.2.1.1.3.3.cmml">
                     j
                    </mi>
                   </mrow>
                   <mi id="A4.Ex1.m1.2.2.2.2.1.1.2.3" xref="A4.Ex1.m1.2.2.2.2.1.1.2.3.cmml">
                    o
                   </mi>
                  </msubsup>
                  <mo id="A4.Ex1.m1.2.2.2.2.1.3" stretchy="false" xref="A4.Ex1.m1.2.2.2.2.1.1.cmml">
                   )
                  </mo>
                 </mrow>
                </mrow>
                <mrow id="A4.Ex1.m1.4.4.4" xref="A4.Ex1.m1.4.4.4.cmml">
                 <msubsup id="A4.Ex1.m1.4.4.4.3" xref="A4.Ex1.m1.4.4.4.3.cmml">
                  <mo id="A4.Ex1.m1.4.4.4.3.2.2" xref="A4.Ex1.m1.4.4.4.3.2.2.cmml">
                   ∑
                  </mo>
                  <mrow id="A4.Ex1.m1.4.4.4.3.2.3" xref="A4.Ex1.m1.4.4.4.3.2.3.cmml">
                   <mi id="A4.Ex1.m1.4.4.4.3.2.3.2" xref="A4.Ex1.m1.4.4.4.3.2.3.2.cmml">
                    l
                   </mi>
                   <mo id="A4.Ex1.m1.4.4.4.3.2.3.1" xref="A4.Ex1.m1.4.4.4.3.2.3.1.cmml">
                    =
                   </mo>
                   <mn id="A4.Ex1.m1.4.4.4.3.2.3.3" xref="A4.Ex1.m1.4.4.4.3.2.3.3.cmml">
                    1
                   </mn>
                  </mrow>
                  <mi id="A4.Ex1.m1.4.4.4.3.3" xref="A4.Ex1.m1.4.4.4.3.3.cmml">
                   N
                  </mi>
                 </msubsup>
                 <mrow id="A4.Ex1.m1.4.4.4.2" xref="A4.Ex1.m1.4.4.4.2.cmml">
                  <mi id="A4.Ex1.m1.4.4.4.2.4" xref="A4.Ex1.m1.4.4.4.2.4.cmml">
                   σ
                  </mi>
                  <mo id="A4.Ex1.m1.4.4.4.2.3" lspace="0em" rspace="0em" xref="A4.Ex1.m1.4.4.4.2.3.cmml">
                   ​
                  </mo>
                  <mrow id="A4.Ex1.m1.3.3.3.1.1.1" xref="A4.Ex1.m1.3.3.3.1.1.1.1.cmml">
                   <mo id="A4.Ex1.m1.3.3.3.1.1.1.2" stretchy="false" xref="A4.Ex1.m1.3.3.3.1.1.1.1.cmml">
                    (
                   </mo>
                   <msubsup id="A4.Ex1.m1.3.3.3.1.1.1.1" xref="A4.Ex1.m1.3.3.3.1.1.1.1.cmml">
                    <mi id="A4.Ex1.m1.3.3.3.1.1.1.1.2.2" xref="A4.Ex1.m1.3.3.3.1.1.1.1.2.2.cmml">
                     ω
                    </mi>
                    <mrow id="A4.Ex1.m1.3.3.3.1.1.1.1.3" xref="A4.Ex1.m1.3.3.3.1.1.1.1.3.cmml">
                     <mi id="A4.Ex1.m1.3.3.3.1.1.1.1.3.2" xref="A4.Ex1.m1.3.3.3.1.1.1.1.3.2.cmml">
                      i
                     </mi>
                     <mo id="A4.Ex1.m1.3.3.3.1.1.1.1.3.1" lspace="0em" rspace="0em" xref="A4.Ex1.m1.3.3.3.1.1.1.1.3.1.cmml">
                      ​
                     </mo>
                     <mi id="A4.Ex1.m1.3.3.3.1.1.1.1.3.3" xref="A4.Ex1.m1.3.3.3.1.1.1.1.3.3.cmml">
                      l
                     </mi>
                    </mrow>
                    <mi id="A4.Ex1.m1.3.3.3.1.1.1.1.2.3" xref="A4.Ex1.m1.3.3.3.1.1.1.1.2.3.cmml">
                     s
                    </mi>
                   </msubsup>
                   <mo id="A4.Ex1.m1.3.3.3.1.1.1.3" stretchy="false" xref="A4.Ex1.m1.3.3.3.1.1.1.1.cmml">
                    )
                   </mo>
                  </mrow>
                  <mo id="A4.Ex1.m1.4.4.4.2.3a" lspace="0em" rspace="0em" xref="A4.Ex1.m1.4.4.4.2.3.cmml">
                   ​
                  </mo>
                  <mi id="A4.Ex1.m1.4.4.4.2.5" xref="A4.Ex1.m1.4.4.4.2.5.cmml">
                   e
                  </mi>
                  <mo id="A4.Ex1.m1.4.4.4.2.3b" lspace="0em" rspace="0em" xref="A4.Ex1.m1.4.4.4.2.3.cmml">
                   ​
                  </mo>
                  <mi id="A4.Ex1.m1.4.4.4.2.6" xref="A4.Ex1.m1.4.4.4.2.6.cmml">
                   x
                  </mi>
                  <mo id="A4.Ex1.m1.4.4.4.2.3c" lspace="0em" rspace="0em" xref="A4.Ex1.m1.4.4.4.2.3.cmml">
                   ​
                  </mo>
                  <mi id="A4.Ex1.m1.4.4.4.2.7" xref="A4.Ex1.m1.4.4.4.2.7.cmml">
                   p
                  </mi>
                  <mo id="A4.Ex1.m1.4.4.4.2.3d" lspace="0em" rspace="0em" xref="A4.Ex1.m1.4.4.4.2.3.cmml">
                   ​
                  </mo>
                  <mrow id="A4.Ex1.m1.4.4.4.2.2.1" xref="A4.Ex1.m1.4.4.4.2.2.1.1.cmml">
                   <mo id="A4.Ex1.m1.4.4.4.2.2.1.2" stretchy="false" xref="A4.Ex1.m1.4.4.4.2.2.1.1.cmml">
                    (
                   </mo>
                   <msubsup id="A4.Ex1.m1.4.4.4.2.2.1.1" xref="A4.Ex1.m1.4.4.4.2.2.1.1.cmml">
                    <mi id="A4.Ex1.m1.4.4.4.2.2.1.1.2.2" xref="A4.Ex1.m1.4.4.4.2.2.1.1.2.2.cmml">
                     ω
                    </mi>
                    <mrow id="A4.Ex1.m1.4.4.4.2.2.1.1.3" xref="A4.Ex1.m1.4.4.4.2.2.1.1.3.cmml">
                     <mi id="A4.Ex1.m1.4.4.4.2.2.1.1.3.2" xref="A4.Ex1.m1.4.4.4.2.2.1.1.3.2.cmml">
                      i
                     </mi>
                     <mo id="A4.Ex1.m1.4.4.4.2.2.1.1.3.1" lspace="0em" rspace="0em" xref="A4.Ex1.m1.4.4.4.2.2.1.1.3.1.cmml">
                      ​
                     </mo>
                     <mi id="A4.Ex1.m1.4.4.4.2.2.1.1.3.3" xref="A4.Ex1.m1.4.4.4.2.2.1.1.3.3.cmml">
                      l
                     </mi>
                    </mrow>
                    <mi id="A4.Ex1.m1.4.4.4.2.2.1.1.2.3" xref="A4.Ex1.m1.4.4.4.2.2.1.1.2.3.cmml">
                     o
                    </mi>
                   </msubsup>
                   <mo id="A4.Ex1.m1.4.4.4.2.2.1.3" stretchy="false" xref="A4.Ex1.m1.4.4.4.2.2.1.1.cmml">
                    )
                   </mo>
                  </mrow>
                 </mrow>
                </mrow>
               </mfrac>
              </mrow>
              <mo id="A4.Ex1.m1.5.5.1.2" lspace="0em" xref="A4.Ex1.m1.5.5.1.1.cmml">
               .
              </mo>
             </mrow>
             <annotation-xml encoding="MathML-Content" id="A4.Ex1.m1.5b">
              <apply id="A4.Ex1.m1.5.5.1.1.cmml" xref="A4.Ex1.m1.5.5.1">
               <eq id="A4.Ex1.m1.5.5.1.1.1.cmml" xref="A4.Ex1.m1.5.5.1.1.1">
               </eq>
               <apply id="A4.Ex1.m1.5.5.1.1.2.cmml" xref="A4.Ex1.m1.5.5.1.1.2">
                <csymbol cd="ambiguous" id="A4.Ex1.m1.5.5.1.1.2.1.cmml" xref="A4.Ex1.m1.5.5.1.1.2">
                 subscript
                </csymbol>
                <ci id="A4.Ex1.m1.5.5.1.1.2.2.cmml" xref="A4.Ex1.m1.5.5.1.1.2.2">
                 𝜔
                </ci>
                <apply id="A4.Ex1.m1.5.5.1.1.2.3.cmml" xref="A4.Ex1.m1.5.5.1.1.2.3">
                 <times id="A4.Ex1.m1.5.5.1.1.2.3.1.cmml" xref="A4.Ex1.m1.5.5.1.1.2.3.1">
                 </times>
                 <ci id="A4.Ex1.m1.5.5.1.1.2.3.2.cmml" xref="A4.Ex1.m1.5.5.1.1.2.3.2">
                  𝑖
                 </ci>
                 <ci id="A4.Ex1.m1.5.5.1.1.2.3.3.cmml" xref="A4.Ex1.m1.5.5.1.1.2.3.3">
                  𝑗
                 </ci>
                </apply>
               </apply>
               <apply id="A4.Ex1.m1.4.4.cmml" xref="A4.Ex1.m1.4.4">
                <divide id="A4.Ex1.m1.4.4.5.cmml" xref="A4.Ex1.m1.4.4">
                </divide>
                <apply id="A4.Ex1.m1.2.2.2.cmml" xref="A4.Ex1.m1.2.2.2">
                 <times id="A4.Ex1.m1.2.2.2.3.cmml" xref="A4.Ex1.m1.2.2.2.3">
                 </times>
                 <ci id="A4.Ex1.m1.2.2.2.4.cmml" xref="A4.Ex1.m1.2.2.2.4">
                  𝜎
                 </ci>
                 <apply id="A4.Ex1.m1.1.1.1.1.1.1.cmml" xref="A4.Ex1.m1.1.1.1.1.1">
                  <csymbol cd="ambiguous" id="A4.Ex1.m1.1.1.1.1.1.1.1.cmml" xref="A4.Ex1.m1.1.1.1.1.1">
                   subscript
                  </csymbol>
                  <apply id="A4.Ex1.m1.1.1.1.1.1.1.2.cmml" xref="A4.Ex1.m1.1.1.1.1.1">
                   <csymbol cd="ambiguous" id="A4.Ex1.m1.1.1.1.1.1.1.2.1.cmml" xref="A4.Ex1.m1.1.1.1.1.1">
                    superscript
                   </csymbol>
                   <ci id="A4.Ex1.m1.1.1.1.1.1.1.2.2.cmml" xref="A4.Ex1.m1.1.1.1.1.1.1.2.2">
                    𝜔
                   </ci>
                   <ci id="A4.Ex1.m1.1.1.1.1.1.1.2.3.cmml" xref="A4.Ex1.m1.1.1.1.1.1.1.2.3">
                    𝑠
                   </ci>
                  </apply>
                  <apply id="A4.Ex1.m1.1.1.1.1.1.1.3.cmml" xref="A4.Ex1.m1.1.1.1.1.1.1.3">
                   <times id="A4.Ex1.m1.1.1.1.1.1.1.3.1.cmml" xref="A4.Ex1.m1.1.1.1.1.1.1.3.1">
                   </times>
                   <ci id="A4.Ex1.m1.1.1.1.1.1.1.3.2.cmml" xref="A4.Ex1.m1.1.1.1.1.1.1.3.2">
                    𝑖
                   </ci>
                   <ci id="A4.Ex1.m1.1.1.1.1.1.1.3.3.cmml" xref="A4.Ex1.m1.1.1.1.1.1.1.3.3">
                    𝑗
                   </ci>
                  </apply>
                 </apply>
                 <ci id="A4.Ex1.m1.2.2.2.5.cmml" xref="A4.Ex1.m1.2.2.2.5">
                  𝑒
                 </ci>
                 <ci id="A4.Ex1.m1.2.2.2.6.cmml" xref="A4.Ex1.m1.2.2.2.6">
                  𝑥
                 </ci>
                 <ci id="A4.Ex1.m1.2.2.2.7.cmml" xref="A4.Ex1.m1.2.2.2.7">
                  𝑝
                 </ci>
                 <apply id="A4.Ex1.m1.2.2.2.2.1.1.cmml" xref="A4.Ex1.m1.2.2.2.2.1">
                  <csymbol cd="ambiguous" id="A4.Ex1.m1.2.2.2.2.1.1.1.cmml" xref="A4.Ex1.m1.2.2.2.2.1">
                   subscript
                  </csymbol>
                  <apply id="A4.Ex1.m1.2.2.2.2.1.1.2.cmml" xref="A4.Ex1.m1.2.2.2.2.1">
                   <csymbol cd="ambiguous" id="A4.Ex1.m1.2.2.2.2.1.1.2.1.cmml" xref="A4.Ex1.m1.2.2.2.2.1">
                    superscript
                   </csymbol>
                   <ci id="A4.Ex1.m1.2.2.2.2.1.1.2.2.cmml" xref="A4.Ex1.m1.2.2.2.2.1.1.2.2">
                    𝜔
                   </ci>
                   <ci id="A4.Ex1.m1.2.2.2.2.1.1.2.3.cmml" xref="A4.Ex1.m1.2.2.2.2.1.1.2.3">
                    𝑜
                   </ci>
                  </apply>
                  <apply id="A4.Ex1.m1.2.2.2.2.1.1.3.cmml" xref="A4.Ex1.m1.2.2.2.2.1.1.3">
                   <times id="A4.Ex1.m1.2.2.2.2.1.1.3.1.cmml" xref="A4.Ex1.m1.2.2.2.2.1.1.3.1">
                   </times>
                   <ci id="A4.Ex1.m1.2.2.2.2.1.1.3.2.cmml" xref="A4.Ex1.m1.2.2.2.2.1.1.3.2">
                    𝑖
                   </ci>
                   <ci id="A4.Ex1.m1.2.2.2.2.1.1.3.3.cmml" xref="A4.Ex1.m1.2.2.2.2.1.1.3.3">
                    𝑗
                   </ci>
                  </apply>
                 </apply>
                </apply>
                <apply id="A4.Ex1.m1.4.4.4.cmml" xref="A4.Ex1.m1.4.4.4">
                 <apply id="A4.Ex1.m1.4.4.4.3.cmml" xref="A4.Ex1.m1.4.4.4.3">
                  <csymbol cd="ambiguous" id="A4.Ex1.m1.4.4.4.3.1.cmml" xref="A4.Ex1.m1.4.4.4.3">
                   superscript
                  </csymbol>
                  <apply id="A4.Ex1.m1.4.4.4.3.2.cmml" xref="A4.Ex1.m1.4.4.4.3">
                   <csymbol cd="ambiguous" id="A4.Ex1.m1.4.4.4.3.2.1.cmml" xref="A4.Ex1.m1.4.4.4.3">
                    subscript
                   </csymbol>
                   <sum id="A4.Ex1.m1.4.4.4.3.2.2.cmml" xref="A4.Ex1.m1.4.4.4.3.2.2">
                   </sum>
                   <apply id="A4.Ex1.m1.4.4.4.3.2.3.cmml" xref="A4.Ex1.m1.4.4.4.3.2.3">
                    <eq id="A4.Ex1.m1.4.4.4.3.2.3.1.cmml" xref="A4.Ex1.m1.4.4.4.3.2.3.1">
                    </eq>
                    <ci id="A4.Ex1.m1.4.4.4.3.2.3.2.cmml" xref="A4.Ex1.m1.4.4.4.3.2.3.2">
                     𝑙
                    </ci>
                    <cn id="A4.Ex1.m1.4.4.4.3.2.3.3.cmml" type="integer" xref="A4.Ex1.m1.4.4.4.3.2.3.3">
                     1
                    </cn>
                   </apply>
                  </apply>
                  <ci id="A4.Ex1.m1.4.4.4.3.3.cmml" xref="A4.Ex1.m1.4.4.4.3.3">
                   𝑁
                  </ci>
                 </apply>
                 <apply id="A4.Ex1.m1.4.4.4.2.cmml" xref="A4.Ex1.m1.4.4.4.2">
                  <times id="A4.Ex1.m1.4.4.4.2.3.cmml" xref="A4.Ex1.m1.4.4.4.2.3">
                  </times>
                  <ci id="A4.Ex1.m1.4.4.4.2.4.cmml" xref="A4.Ex1.m1.4.4.4.2.4">
                   𝜎
                  </ci>
                  <apply id="A4.Ex1.m1.3.3.3.1.1.1.1.cmml" xref="A4.Ex1.m1.3.3.3.1.1.1">
                   <csymbol cd="ambiguous" id="A4.Ex1.m1.3.3.3.1.1.1.1.1.cmml" xref="A4.Ex1.m1.3.3.3.1.1.1">
                    subscript
                   </csymbol>
                   <apply id="A4.Ex1.m1.3.3.3.1.1.1.1.2.cmml" xref="A4.Ex1.m1.3.3.3.1.1.1">
                    <csymbol cd="ambiguous" id="A4.Ex1.m1.3.3.3.1.1.1.1.2.1.cmml" xref="A4.Ex1.m1.3.3.3.1.1.1">
                     superscript
                    </csymbol>
                    <ci id="A4.Ex1.m1.3.3.3.1.1.1.1.2.2.cmml" xref="A4.Ex1.m1.3.3.3.1.1.1.1.2.2">
                     𝜔
                    </ci>
                    <ci id="A4.Ex1.m1.3.3.3.1.1.1.1.2.3.cmml" xref="A4.Ex1.m1.3.3.3.1.1.1.1.2.3">
                     𝑠
                    </ci>
                   </apply>
                   <apply id="A4.Ex1.m1.3.3.3.1.1.1.1.3.cmml" xref="A4.Ex1.m1.3.3.3.1.1.1.1.3">
                    <times id="A4.Ex1.m1.3.3.3.1.1.1.1.3.1.cmml" xref="A4.Ex1.m1.3.3.3.1.1.1.1.3.1">
                    </times>
                    <ci id="A4.Ex1.m1.3.3.3.1.1.1.1.3.2.cmml" xref="A4.Ex1.m1.3.3.3.1.1.1.1.3.2">
                     𝑖
                    </ci>
                    <ci id="A4.Ex1.m1.3.3.3.1.1.1.1.3.3.cmml" xref="A4.Ex1.m1.3.3.3.1.1.1.1.3.3">
                     𝑙
                    </ci>
                   </apply>
                  </apply>
                  <ci id="A4.Ex1.m1.4.4.4.2.5.cmml" xref="A4.Ex1.m1.4.4.4.2.5">
                   𝑒
                  </ci>
                  <ci id="A4.Ex1.m1.4.4.4.2.6.cmml" xref="A4.Ex1.m1.4.4.4.2.6">
                   𝑥
                  </ci>
                  <ci id="A4.Ex1.m1.4.4.4.2.7.cmml" xref="A4.Ex1.m1.4.4.4.2.7">
                   𝑝
                  </ci>
                  <apply id="A4.Ex1.m1.4.4.4.2.2.1.1.cmml" xref="A4.Ex1.m1.4.4.4.2.2.1">
                   <csymbol cd="ambiguous" id="A4.Ex1.m1.4.4.4.2.2.1.1.1.cmml" xref="A4.Ex1.m1.4.4.4.2.2.1">
                    subscript
                   </csymbol>
                   <apply id="A4.Ex1.m1.4.4.4.2.2.1.1.2.cmml" xref="A4.Ex1.m1.4.4.4.2.2.1">
                    <csymbol cd="ambiguous" id="A4.Ex1.m1.4.4.4.2.2.1.1.2.1.cmml" xref="A4.Ex1.m1.4.4.4.2.2.1">
                     superscript
                    </csymbol>
                    <ci id="A4.Ex1.m1.4.4.4.2.2.1.1.2.2.cmml" xref="A4.Ex1.m1.4.4.4.2.2.1.1.2.2">
                     𝜔
                    </ci>
                    <ci id="A4.Ex1.m1.4.4.4.2.2.1.1.2.3.cmml" xref="A4.Ex1.m1.4.4.4.2.2.1.1.2.3">
                     𝑜
                    </ci>
                   </apply>
                   <apply id="A4.Ex1.m1.4.4.4.2.2.1.1.3.cmml" xref="A4.Ex1.m1.4.4.4.2.2.1.1.3">
                    <times id="A4.Ex1.m1.4.4.4.2.2.1.1.3.1.cmml" xref="A4.Ex1.m1.4.4.4.2.2.1.1.3.1">
                    </times>
                    <ci id="A4.Ex1.m1.4.4.4.2.2.1.1.3.2.cmml" xref="A4.Ex1.m1.4.4.4.2.2.1.1.3.2">
                     𝑖
                    </ci>
                    <ci id="A4.Ex1.m1.4.4.4.2.2.1.1.3.3.cmml" xref="A4.Ex1.m1.4.4.4.2.2.1.1.3.3">
                     𝑙
                    </ci>
                   </apply>
                  </apply>
                 </apply>
                </apply>
               </apply>
              </apply>
             </annotation-xml>
             <annotation encoding="application/x-tex" id="A4.Ex1.m1.5c">
              \omega_{ij}=\frac{\sigma(\omega^{s}_{ij})exp(\omega^{o}_{ij})}{\sum_{l=1}^{N}\sigma(\omega^{s}_{il})exp(\omega^{o}_{il})}.
             </annotation>
            </semantics>
           </math>
          </td>
          <td class="ltx_eqn_cell ltx_eqn_center_padright">
          </td>
         </tr>
        </tbody>
       </table>
       <p class="ltx_p" id="A4.I1.i2.p2.12">
        Readers are referred to
        <cite class="ltx_cite ltx_citemacro_cite">
         Chen et al. (
         <a class="ltx_ref" href="#bib.bib15" title="">
          2022
         </a>
         )
        </cite>
        for more details. In summary, Spatial Transformer explicitly computes pairwise spatial relations and fuses them with vanilla self-attention to provide better spatial reasoning ability. We use a three-layer Spatial Transformer with 8 heads to process the object-centric features produced by PointNet++ and output object tokens for LLM. For other settings, We follow all the default hyperparameters in
        <cite class="ltx_cite ltx_citemacro_cite">
         Chen et al. (
         <a class="ltx_ref" href="#bib.bib15" title="">
          2022
         </a>
         )
        </cite>
        .
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A4.I1.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="A4.I1.i3.p1">
       <p class="ltx_p" id="A4.I1.i3.p1.1">
        <span class="ltx_text ltx_font_bold" id="A4.I1.i3.p1.1.1">
         2D token embedding.
        </span>
        We use OpenCLIP ConvNext-base model
        <cite class="ltx_cite ltx_citemacro_citep">
         (Liu et al.,
         <a class="ltx_ref" href="#bib.bib48" title="">
          2022
         </a>
         )
        </cite>
        pre-trained on LAION2B
        <cite class="ltx_cite ltx_citemacro_citep">
         (Schuhmann et al.,
         <a class="ltx_ref" href="#bib.bib70" title="">
          2022
         </a>
         )
        </cite>
        to process the egocentric 2D image.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A4.I1.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para ltx_noindent" id="A4.I1.i4.p1">
       <p class="ltx_p" id="A4.I1.i4.p1.1">
        <span class="ltx_text ltx_font_bold" id="A4.I1.i4.p1.1.1">
         CLIP fusion.
        </span>
        To enhance the alignment between visual tokens and instruction tokens, we use the text encoder from CLIP
        <cite class="ltx_cite ltx_citemacro_citep">
         (Radford et al.,
         <a class="ltx_ref" href="#bib.bib61" title="">
          2021
         </a>
         )
        </cite>
        to process the instruction tokens to obtain a global feature of the instruction. Next, we update the visual tokens with the element-wise product between the CLIP instruction feature and each image &amp; object token embedding.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <section class="ltx_subsubsection" id="A4.SS2.SSS1">
    <h4 class="ltx_title ltx_title_subsubsection">
     <span class="ltx_tag ltx_tag_subsubsection">
      D.2.1
     </span>
     Embodiment Encoding
    </h4>
    <div class="ltx_para ltx_noindent" id="A4.SS2.SSS1.p1">
     <p class="ltx_p" id="A4.SS2.SSS1.p1.2">
      In addition to the egocentric 2D input, we introduce an embodiment token to help
      <span class="ltx_text ltx_font_smallcaps" id="A4.SS2.SSS1.p1.2.1">
       LEO
      </span>
      reason in an embodiment-aware fashion. We find it useful to use it together with the situation prompt and 2D egocentric input. Specifically, an embodiment token
      <math alttext="e" class="ltx_Math" display="inline" id="A4.SS2.SSS1.p1.1.m1.1">
       <semantics id="A4.SS2.SSS1.p1.1.m1.1a">
        <mi id="A4.SS2.SSS1.p1.1.m1.1.1" xref="A4.SS2.SSS1.p1.1.m1.1.1.cmml">
         e
        </mi>
        <annotation-xml encoding="MathML-Content" id="A4.SS2.SSS1.p1.1.m1.1b">
         <ci id="A4.SS2.SSS1.p1.1.m1.1.1.cmml" xref="A4.SS2.SSS1.p1.1.m1.1.1">
          𝑒
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A4.SS2.SSS1.p1.1.m1.1c">
         e
        </annotation>
       </semantics>
      </math>
      is introduced in
      <span class="ltx_text ltx_font_bold" id="A4.SS2.SSS1.p1.2.2">
       embodied navigation
      </span>
      ,
      <span class="ltx_text ltx_font_bold" id="A4.SS2.SSS1.p1.2.3">
       embodied reasoning
      </span>
      , and
      <span class="ltx_text ltx_font_bold" id="A4.SS2.SSS1.p1.2.4">
       object-in-the-scene caption
      </span>
      tasks. Specifically,
      <math alttext="e" class="ltx_Math" display="inline" id="A4.SS2.SSS1.p1.2.m2.1">
       <semantics id="A4.SS2.SSS1.p1.2.m2.1a">
        <mi id="A4.SS2.SSS1.p1.2.m2.1.1" xref="A4.SS2.SSS1.p1.2.m2.1.1.cmml">
         e
        </mi>
        <annotation-xml encoding="MathML-Content" id="A4.SS2.SSS1.p1.2.m2.1b">
         <ci id="A4.SS2.SSS1.p1.2.m2.1.1.cmml" xref="A4.SS2.SSS1.p1.2.m2.1.1">
          𝑒
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A4.SS2.SSS1.p1.2.m2.1c">
         e
        </annotation>
       </semantics>
      </math>
      is a learnable embedding that will be inserted into the 3D object list.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="A4.SS2.SSS1.p2">
     <p class="ltx_p" id="A4.SS2.SSS1.p2.1">
      So what does embodiment information mean in these tasks? In
      <span class="ltx_text ltx_font_bold" id="A4.SS2.SSS1.p2.1.1">
       embodied navigation
      </span>
      , it means the agent’s position and orientation in the scene, which can be derived from a GPS and a compass sensor. The orientation of the agent is further represented by a rotation which is Fourier-embedded and mapped to a feature vector
      <math alttext="r" class="ltx_Math" display="inline" id="A4.SS2.SSS1.p2.1.m1.1">
       <semantics id="A4.SS2.SSS1.p2.1.m1.1a">
        <mi id="A4.SS2.SSS1.p2.1.m1.1.1" xref="A4.SS2.SSS1.p2.1.m1.1.1.cmml">
         r
        </mi>
        <annotation-xml encoding="MathML-Content" id="A4.SS2.SSS1.p2.1.m1.1b">
         <ci id="A4.SS2.SSS1.p2.1.m1.1.1.cmml" xref="A4.SS2.SSS1.p2.1.m1.1.1">
          𝑟
         </ci>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A4.SS2.SSS1.p2.1.m1.1c">
         r
        </annotation>
       </semantics>
      </math>
      by a linear layer. It is the same in
      <span class="ltx_text ltx_font_bold" id="A4.SS2.SSS1.p2.1.2">
       embodied reasoning
      </span>
      task.
In the
      <span class="ltx_text ltx_font_bold" id="A4.SS2.SSS1.p2.1.3">
       object-in-the-scene caption
      </span>
      task, we assume the agent is situated at the location of the object that is being referred to. Therefore, embodiment information also means the location of the referred object. We obtain this location by randomly choosing a spot inside the referred object bounding box. To sum up, we could simply treat the embodiment token as a special
      <span class="ltx_text ltx_font_italic" id="A4.SS2.SSS1.p2.1.4">
       self object
      </span>
      , where its object embedding is learnable, and its location/orientation corresponds to the actual or assumed “agent”.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="A4.SS2.SSS1.p3">
     <p class="ltx_p" id="A4.SS2.SSS1.p3.3">
      After inserting the embodiment token, we obtain a new 3D object token list:
      <math alttext="e,s_{\text{3D}}^{(1)},s_{\text{3D}}^{(2)},\dots,s_{\text{3D}}^{(N)}" class="ltx_Math" display="inline" id="A4.SS2.SSS1.p3.1.m1.8">
       <semantics id="A4.SS2.SSS1.p3.1.m1.8a">
        <mrow id="A4.SS2.SSS1.p3.1.m1.8.8.3" xref="A4.SS2.SSS1.p3.1.m1.8.8.4.cmml">
         <mi id="A4.SS2.SSS1.p3.1.m1.4.4" xref="A4.SS2.SSS1.p3.1.m1.4.4.cmml">
          e
         </mi>
         <mo id="A4.SS2.SSS1.p3.1.m1.8.8.3.4" xref="A4.SS2.SSS1.p3.1.m1.8.8.4.cmml">
          ,
         </mo>
         <msubsup id="A4.SS2.SSS1.p3.1.m1.6.6.1.1" xref="A4.SS2.SSS1.p3.1.m1.6.6.1.1.cmml">
          <mi id="A4.SS2.SSS1.p3.1.m1.6.6.1.1.2.2" xref="A4.SS2.SSS1.p3.1.m1.6.6.1.1.2.2.cmml">
           s
          </mi>
          <mtext id="A4.SS2.SSS1.p3.1.m1.6.6.1.1.2.3" xref="A4.SS2.SSS1.p3.1.m1.6.6.1.1.2.3a.cmml">
           3D
          </mtext>
          <mrow id="A4.SS2.SSS1.p3.1.m1.1.1.1.3" xref="A4.SS2.SSS1.p3.1.m1.6.6.1.1.cmml">
           <mo id="A4.SS2.SSS1.p3.1.m1.1.1.1.3.1" stretchy="false" xref="A4.SS2.SSS1.p3.1.m1.6.6.1.1.cmml">
            (
           </mo>
           <mn id="A4.SS2.SSS1.p3.1.m1.1.1.1.1" xref="A4.SS2.SSS1.p3.1.m1.1.1.1.1.cmml">
            1
           </mn>
           <mo id="A4.SS2.SSS1.p3.1.m1.1.1.1.3.2" stretchy="false" xref="A4.SS2.SSS1.p3.1.m1.6.6.1.1.cmml">
            )
           </mo>
          </mrow>
         </msubsup>
         <mo id="A4.SS2.SSS1.p3.1.m1.8.8.3.5" xref="A4.SS2.SSS1.p3.1.m1.8.8.4.cmml">
          ,
         </mo>
         <msubsup id="A4.SS2.SSS1.p3.1.m1.7.7.2.2" xref="A4.SS2.SSS1.p3.1.m1.7.7.2.2.cmml">
          <mi id="A4.SS2.SSS1.p3.1.m1.7.7.2.2.2.2" xref="A4.SS2.SSS1.p3.1.m1.7.7.2.2.2.2.cmml">
           s
          </mi>
          <mtext id="A4.SS2.SSS1.p3.1.m1.7.7.2.2.2.3" xref="A4.SS2.SSS1.p3.1.m1.7.7.2.2.2.3a.cmml">
           3D
          </mtext>
          <mrow id="A4.SS2.SSS1.p3.1.m1.2.2.1.3" xref="A4.SS2.SSS1.p3.1.m1.7.7.2.2.cmml">
           <mo id="A4.SS2.SSS1.p3.1.m1.2.2.1.3.1" stretchy="false" xref="A4.SS2.SSS1.p3.1.m1.7.7.2.2.cmml">
            (
           </mo>
           <mn id="A4.SS2.SSS1.p3.1.m1.2.2.1.1" xref="A4.SS2.SSS1.p3.1.m1.2.2.1.1.cmml">
            2
           </mn>
           <mo id="A4.SS2.SSS1.p3.1.m1.2.2.1.3.2" stretchy="false" xref="A4.SS2.SSS1.p3.1.m1.7.7.2.2.cmml">
            )
           </mo>
          </mrow>
         </msubsup>
         <mo id="A4.SS2.SSS1.p3.1.m1.8.8.3.6" xref="A4.SS2.SSS1.p3.1.m1.8.8.4.cmml">
          ,
         </mo>
         <mi id="A4.SS2.SSS1.p3.1.m1.5.5" mathvariant="normal" xref="A4.SS2.SSS1.p3.1.m1.5.5.cmml">
          …
         </mi>
         <mo id="A4.SS2.SSS1.p3.1.m1.8.8.3.7" xref="A4.SS2.SSS1.p3.1.m1.8.8.4.cmml">
          ,
         </mo>
         <msubsup id="A4.SS2.SSS1.p3.1.m1.8.8.3.3" xref="A4.SS2.SSS1.p3.1.m1.8.8.3.3.cmml">
          <mi id="A4.SS2.SSS1.p3.1.m1.8.8.3.3.2.2" xref="A4.SS2.SSS1.p3.1.m1.8.8.3.3.2.2.cmml">
           s
          </mi>
          <mtext id="A4.SS2.SSS1.p3.1.m1.8.8.3.3.2.3" xref="A4.SS2.SSS1.p3.1.m1.8.8.3.3.2.3a.cmml">
           3D
          </mtext>
          <mrow id="A4.SS2.SSS1.p3.1.m1.3.3.1.3" xref="A4.SS2.SSS1.p3.1.m1.8.8.3.3.cmml">
           <mo id="A4.SS2.SSS1.p3.1.m1.3.3.1.3.1" stretchy="false" xref="A4.SS2.SSS1.p3.1.m1.8.8.3.3.cmml">
            (
           </mo>
           <mi id="A4.SS2.SSS1.p3.1.m1.3.3.1.1" xref="A4.SS2.SSS1.p3.1.m1.3.3.1.1.cmml">
            N
           </mi>
           <mo id="A4.SS2.SSS1.p3.1.m1.3.3.1.3.2" stretchy="false" xref="A4.SS2.SSS1.p3.1.m1.8.8.3.3.cmml">
            )
           </mo>
          </mrow>
         </msubsup>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="A4.SS2.SSS1.p3.1.m1.8b">
         <list id="A4.SS2.SSS1.p3.1.m1.8.8.4.cmml" xref="A4.SS2.SSS1.p3.1.m1.8.8.3">
          <ci id="A4.SS2.SSS1.p3.1.m1.4.4.cmml" xref="A4.SS2.SSS1.p3.1.m1.4.4">
           𝑒
          </ci>
          <apply id="A4.SS2.SSS1.p3.1.m1.6.6.1.1.cmml" xref="A4.SS2.SSS1.p3.1.m1.6.6.1.1">
           <csymbol cd="ambiguous" id="A4.SS2.SSS1.p3.1.m1.6.6.1.1.1.cmml" xref="A4.SS2.SSS1.p3.1.m1.6.6.1.1">
            superscript
           </csymbol>
           <apply id="A4.SS2.SSS1.p3.1.m1.6.6.1.1.2.cmml" xref="A4.SS2.SSS1.p3.1.m1.6.6.1.1">
            <csymbol cd="ambiguous" id="A4.SS2.SSS1.p3.1.m1.6.6.1.1.2.1.cmml" xref="A4.SS2.SSS1.p3.1.m1.6.6.1.1">
             subscript
            </csymbol>
            <ci id="A4.SS2.SSS1.p3.1.m1.6.6.1.1.2.2.cmml" xref="A4.SS2.SSS1.p3.1.m1.6.6.1.1.2.2">
             𝑠
            </ci>
            <ci id="A4.SS2.SSS1.p3.1.m1.6.6.1.1.2.3a.cmml" xref="A4.SS2.SSS1.p3.1.m1.6.6.1.1.2.3">
             <mtext id="A4.SS2.SSS1.p3.1.m1.6.6.1.1.2.3.cmml" mathsize="70%" xref="A4.SS2.SSS1.p3.1.m1.6.6.1.1.2.3">
              3D
             </mtext>
            </ci>
           </apply>
           <cn id="A4.SS2.SSS1.p3.1.m1.1.1.1.1.cmml" type="integer" xref="A4.SS2.SSS1.p3.1.m1.1.1.1.1">
            1
           </cn>
          </apply>
          <apply id="A4.SS2.SSS1.p3.1.m1.7.7.2.2.cmml" xref="A4.SS2.SSS1.p3.1.m1.7.7.2.2">
           <csymbol cd="ambiguous" id="A4.SS2.SSS1.p3.1.m1.7.7.2.2.1.cmml" xref="A4.SS2.SSS1.p3.1.m1.7.7.2.2">
            superscript
           </csymbol>
           <apply id="A4.SS2.SSS1.p3.1.m1.7.7.2.2.2.cmml" xref="A4.SS2.SSS1.p3.1.m1.7.7.2.2">
            <csymbol cd="ambiguous" id="A4.SS2.SSS1.p3.1.m1.7.7.2.2.2.1.cmml" xref="A4.SS2.SSS1.p3.1.m1.7.7.2.2">
             subscript
            </csymbol>
            <ci id="A4.SS2.SSS1.p3.1.m1.7.7.2.2.2.2.cmml" xref="A4.SS2.SSS1.p3.1.m1.7.7.2.2.2.2">
             𝑠
            </ci>
            <ci id="A4.SS2.SSS1.p3.1.m1.7.7.2.2.2.3a.cmml" xref="A4.SS2.SSS1.p3.1.m1.7.7.2.2.2.3">
             <mtext id="A4.SS2.SSS1.p3.1.m1.7.7.2.2.2.3.cmml" mathsize="70%" xref="A4.SS2.SSS1.p3.1.m1.7.7.2.2.2.3">
              3D
             </mtext>
            </ci>
           </apply>
           <cn id="A4.SS2.SSS1.p3.1.m1.2.2.1.1.cmml" type="integer" xref="A4.SS2.SSS1.p3.1.m1.2.2.1.1">
            2
           </cn>
          </apply>
          <ci id="A4.SS2.SSS1.p3.1.m1.5.5.cmml" xref="A4.SS2.SSS1.p3.1.m1.5.5">
           …
          </ci>
          <apply id="A4.SS2.SSS1.p3.1.m1.8.8.3.3.cmml" xref="A4.SS2.SSS1.p3.1.m1.8.8.3.3">
           <csymbol cd="ambiguous" id="A4.SS2.SSS1.p3.1.m1.8.8.3.3.1.cmml" xref="A4.SS2.SSS1.p3.1.m1.8.8.3.3">
            superscript
           </csymbol>
           <apply id="A4.SS2.SSS1.p3.1.m1.8.8.3.3.2.cmml" xref="A4.SS2.SSS1.p3.1.m1.8.8.3.3">
            <csymbol cd="ambiguous" id="A4.SS2.SSS1.p3.1.m1.8.8.3.3.2.1.cmml" xref="A4.SS2.SSS1.p3.1.m1.8.8.3.3">
             subscript
            </csymbol>
            <ci id="A4.SS2.SSS1.p3.1.m1.8.8.3.3.2.2.cmml" xref="A4.SS2.SSS1.p3.1.m1.8.8.3.3.2.2">
             𝑠
            </ci>
            <ci id="A4.SS2.SSS1.p3.1.m1.8.8.3.3.2.3a.cmml" xref="A4.SS2.SSS1.p3.1.m1.8.8.3.3.2.3">
             <mtext id="A4.SS2.SSS1.p3.1.m1.8.8.3.3.2.3.cmml" mathsize="70%" xref="A4.SS2.SSS1.p3.1.m1.8.8.3.3.2.3">
              3D
             </mtext>
            </ci>
           </apply>
           <ci id="A4.SS2.SSS1.p3.1.m1.3.3.1.1.cmml" xref="A4.SS2.SSS1.p3.1.m1.3.3.1.1">
            𝑁
           </ci>
          </apply>
         </list>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A4.SS2.SSS1.p3.1.m1.8c">
         e,s_{\text{3D}}^{(1)},s_{\text{3D}}^{(2)},\dots,s_{\text{3D}}^{(N)}
        </annotation>
       </semantics>
      </math>
      , where
      <math alttext="s_{\text{3D}}^{(i)},i\in\{1,2,\dots,N\}" class="ltx_Math" display="inline" id="A4.SS2.SSS1.p3.2.m2.7">
       <semantics id="A4.SS2.SSS1.p3.2.m2.7a">
        <mrow id="A4.SS2.SSS1.p3.2.m2.7.7" xref="A4.SS2.SSS1.p3.2.m2.7.7.cmml">
         <mrow id="A4.SS2.SSS1.p3.2.m2.7.7.1.1" xref="A4.SS2.SSS1.p3.2.m2.7.7.1.2.cmml">
          <msubsup id="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1" xref="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1.cmml">
           <mi id="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1.2.2" xref="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1.2.2.cmml">
            s
           </mi>
           <mtext id="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1.2.3" xref="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1.2.3a.cmml">
            3D
           </mtext>
           <mrow id="A4.SS2.SSS1.p3.2.m2.1.1.1.3" xref="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1.cmml">
            <mo id="A4.SS2.SSS1.p3.2.m2.1.1.1.3.1" stretchy="false" xref="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1.cmml">
             (
            </mo>
            <mi id="A4.SS2.SSS1.p3.2.m2.1.1.1.1" xref="A4.SS2.SSS1.p3.2.m2.1.1.1.1.cmml">
             i
            </mi>
            <mo id="A4.SS2.SSS1.p3.2.m2.1.1.1.3.2" stretchy="false" xref="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1.cmml">
             )
            </mo>
           </mrow>
          </msubsup>
          <mo id="A4.SS2.SSS1.p3.2.m2.7.7.1.1.2" xref="A4.SS2.SSS1.p3.2.m2.7.7.1.2.cmml">
           ,
          </mo>
          <mi id="A4.SS2.SSS1.p3.2.m2.6.6" xref="A4.SS2.SSS1.p3.2.m2.6.6.cmml">
           i
          </mi>
         </mrow>
         <mo id="A4.SS2.SSS1.p3.2.m2.7.7.2" xref="A4.SS2.SSS1.p3.2.m2.7.7.2.cmml">
          ∈
         </mo>
         <mrow id="A4.SS2.SSS1.p3.2.m2.7.7.3.2" xref="A4.SS2.SSS1.p3.2.m2.7.7.3.1.cmml">
          <mo id="A4.SS2.SSS1.p3.2.m2.7.7.3.2.1" stretchy="false" xref="A4.SS2.SSS1.p3.2.m2.7.7.3.1.cmml">
           {
          </mo>
          <mn id="A4.SS2.SSS1.p3.2.m2.2.2" xref="A4.SS2.SSS1.p3.2.m2.2.2.cmml">
           1
          </mn>
          <mo id="A4.SS2.SSS1.p3.2.m2.7.7.3.2.2" xref="A4.SS2.SSS1.p3.2.m2.7.7.3.1.cmml">
           ,
          </mo>
          <mn id="A4.SS2.SSS1.p3.2.m2.3.3" xref="A4.SS2.SSS1.p3.2.m2.3.3.cmml">
           2
          </mn>
          <mo id="A4.SS2.SSS1.p3.2.m2.7.7.3.2.3" xref="A4.SS2.SSS1.p3.2.m2.7.7.3.1.cmml">
           ,
          </mo>
          <mi id="A4.SS2.SSS1.p3.2.m2.4.4" mathvariant="normal" xref="A4.SS2.SSS1.p3.2.m2.4.4.cmml">
           …
          </mi>
          <mo id="A4.SS2.SSS1.p3.2.m2.7.7.3.2.4" xref="A4.SS2.SSS1.p3.2.m2.7.7.3.1.cmml">
           ,
          </mo>
          <mi id="A4.SS2.SSS1.p3.2.m2.5.5" xref="A4.SS2.SSS1.p3.2.m2.5.5.cmml">
           N
          </mi>
          <mo id="A4.SS2.SSS1.p3.2.m2.7.7.3.2.5" stretchy="false" xref="A4.SS2.SSS1.p3.2.m2.7.7.3.1.cmml">
           }
          </mo>
         </mrow>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="A4.SS2.SSS1.p3.2.m2.7b">
         <apply id="A4.SS2.SSS1.p3.2.m2.7.7.cmml" xref="A4.SS2.SSS1.p3.2.m2.7.7">
          <in id="A4.SS2.SSS1.p3.2.m2.7.7.2.cmml" xref="A4.SS2.SSS1.p3.2.m2.7.7.2">
          </in>
          <list id="A4.SS2.SSS1.p3.2.m2.7.7.1.2.cmml" xref="A4.SS2.SSS1.p3.2.m2.7.7.1.1">
           <apply id="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1.cmml" xref="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1">
            <csymbol cd="ambiguous" id="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1.1.cmml" xref="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1">
             superscript
            </csymbol>
            <apply id="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1.2.cmml" xref="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1">
             <csymbol cd="ambiguous" id="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1.2.1.cmml" xref="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1">
              subscript
             </csymbol>
             <ci id="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1.2.2.cmml" xref="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1.2.2">
              𝑠
             </ci>
             <ci id="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1.2.3a.cmml" xref="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1.2.3">
              <mtext id="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1.2.3.cmml" mathsize="70%" xref="A4.SS2.SSS1.p3.2.m2.7.7.1.1.1.2.3">
               3D
              </mtext>
             </ci>
            </apply>
            <ci id="A4.SS2.SSS1.p3.2.m2.1.1.1.1.cmml" xref="A4.SS2.SSS1.p3.2.m2.1.1.1.1">
             𝑖
            </ci>
           </apply>
           <ci id="A4.SS2.SSS1.p3.2.m2.6.6.cmml" xref="A4.SS2.SSS1.p3.2.m2.6.6">
            𝑖
           </ci>
          </list>
          <set id="A4.SS2.SSS1.p3.2.m2.7.7.3.1.cmml" xref="A4.SS2.SSS1.p3.2.m2.7.7.3.2">
           <cn id="A4.SS2.SSS1.p3.2.m2.2.2.cmml" type="integer" xref="A4.SS2.SSS1.p3.2.m2.2.2">
            1
           </cn>
           <cn id="A4.SS2.SSS1.p3.2.m2.3.3.cmml" type="integer" xref="A4.SS2.SSS1.p3.2.m2.3.3">
            2
           </cn>
           <ci id="A4.SS2.SSS1.p3.2.m2.4.4.cmml" xref="A4.SS2.SSS1.p3.2.m2.4.4">
            …
           </ci>
           <ci id="A4.SS2.SSS1.p3.2.m2.5.5.cmml" xref="A4.SS2.SSS1.p3.2.m2.5.5">
            𝑁
           </ci>
          </set>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A4.SS2.SSS1.p3.2.m2.7c">
         s_{\text{3D}}^{(i)},i\in\{1,2,\dots,N\}
        </annotation>
       </semantics>
      </math>
      are 3D object token embeddings produced by PointNet++, along with location specified for each object (including the
      <span class="ltx_text ltx_font_italic" id="A4.SS2.SSS1.p3.3.1">
       self-object
      </span>
      ). We can concatenate them together to get a feature matrix
      <math alttext="O\in\mathbf{R}^{(N+1)\times d}" class="ltx_Math" display="inline" id="A4.SS2.SSS1.p3.3.m3.1">
       <semantics id="A4.SS2.SSS1.p3.3.m3.1a">
        <mrow id="A4.SS2.SSS1.p3.3.m3.1.2" xref="A4.SS2.SSS1.p3.3.m3.1.2.cmml">
         <mi id="A4.SS2.SSS1.p3.3.m3.1.2.2" xref="A4.SS2.SSS1.p3.3.m3.1.2.2.cmml">
          O
         </mi>
         <mo id="A4.SS2.SSS1.p3.3.m3.1.2.1" xref="A4.SS2.SSS1.p3.3.m3.1.2.1.cmml">
          ∈
         </mo>
         <msup id="A4.SS2.SSS1.p3.3.m3.1.2.3" xref="A4.SS2.SSS1.p3.3.m3.1.2.3.cmml">
          <mi id="A4.SS2.SSS1.p3.3.m3.1.2.3.2" xref="A4.SS2.SSS1.p3.3.m3.1.2.3.2.cmml">
           𝐑
          </mi>
          <mrow id="A4.SS2.SSS1.p3.3.m3.1.1.1" xref="A4.SS2.SSS1.p3.3.m3.1.1.1.cmml">
           <mrow id="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1" xref="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1.1.cmml">
            <mo id="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1.2" stretchy="false" xref="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1.1.cmml">
             (
            </mo>
            <mrow id="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1.1" xref="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1.1.cmml">
             <mi id="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1.1.2" xref="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1.1.2.cmml">
              N
             </mi>
             <mo id="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1.1.1" xref="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1.1.1.cmml">
              +
             </mo>
             <mn id="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1.1.3" xref="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1.1.3.cmml">
              1
             </mn>
            </mrow>
            <mo id="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1.3" rspace="0.055em" stretchy="false" xref="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1.1.cmml">
             )
            </mo>
           </mrow>
           <mo id="A4.SS2.SSS1.p3.3.m3.1.1.1.2" rspace="0.222em" xref="A4.SS2.SSS1.p3.3.m3.1.1.1.2.cmml">
            ×
           </mo>
           <mi id="A4.SS2.SSS1.p3.3.m3.1.1.1.3" xref="A4.SS2.SSS1.p3.3.m3.1.1.1.3.cmml">
            d
           </mi>
          </mrow>
         </msup>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="A4.SS2.SSS1.p3.3.m3.1b">
         <apply id="A4.SS2.SSS1.p3.3.m3.1.2.cmml" xref="A4.SS2.SSS1.p3.3.m3.1.2">
          <in id="A4.SS2.SSS1.p3.3.m3.1.2.1.cmml" xref="A4.SS2.SSS1.p3.3.m3.1.2.1">
          </in>
          <ci id="A4.SS2.SSS1.p3.3.m3.1.2.2.cmml" xref="A4.SS2.SSS1.p3.3.m3.1.2.2">
           𝑂
          </ci>
          <apply id="A4.SS2.SSS1.p3.3.m3.1.2.3.cmml" xref="A4.SS2.SSS1.p3.3.m3.1.2.3">
           <csymbol cd="ambiguous" id="A4.SS2.SSS1.p3.3.m3.1.2.3.1.cmml" xref="A4.SS2.SSS1.p3.3.m3.1.2.3">
            superscript
           </csymbol>
           <ci id="A4.SS2.SSS1.p3.3.m3.1.2.3.2.cmml" xref="A4.SS2.SSS1.p3.3.m3.1.2.3.2">
            𝐑
           </ci>
           <apply id="A4.SS2.SSS1.p3.3.m3.1.1.1.cmml" xref="A4.SS2.SSS1.p3.3.m3.1.1.1">
            <times id="A4.SS2.SSS1.p3.3.m3.1.1.1.2.cmml" xref="A4.SS2.SSS1.p3.3.m3.1.1.1.2">
            </times>
            <apply id="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1.1.cmml" xref="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1">
             <plus id="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1.1.1.cmml" xref="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1.1.1">
             </plus>
             <ci id="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1.1.2.cmml" xref="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1.1.2">
              𝑁
             </ci>
             <cn id="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1.1.3.cmml" type="integer" xref="A4.SS2.SSS1.p3.3.m3.1.1.1.1.1.1.3">
              1
             </cn>
            </apply>
            <ci id="A4.SS2.SSS1.p3.3.m3.1.1.1.3.cmml" xref="A4.SS2.SSS1.p3.3.m3.1.1.1.3">
             𝑑
            </ci>
           </apply>
          </apply>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A4.SS2.SSS1.p3.3.m3.1c">
         O\in\mathbf{R}^{(N+1)\times d}
        </annotation>
       </semantics>
      </math>
      and send them to the Spatial Transformer to explicitly fuse the spatial information of all the 3D objects and the self-object.
     </p>
    </div>
   </section>
  </section>
  <section class="ltx_subsection" id="A4.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     D.3
    </span>
    LLM Hyperparameters
   </h3>
   <div class="ltx_para ltx_noindent" id="A4.SS3.p1">
    <p class="ltx_p" id="A4.SS3.p1.3">
     We set the maximum output length of our Vicuna-7B to be 256. The maximum context length is also set to 256 and if the length of the input is greater than 256, we truncate it to 256 by deleting tokens from the left (
     <em class="ltx_emph ltx_font_italic" id="A4.SS3.p1.3.1">
      i.e
     </em>
     .
     <span class="ltx_text" id="A4.SS3.p1.3.2">
     </span>
     , only the rightmost 256 tokens are preserved). We set rank and
     <math alttext="\alpha" class="ltx_Math" display="inline" id="A4.SS3.p1.1.m1.1">
      <semantics id="A4.SS3.p1.1.m1.1a">
       <mi id="A4.SS3.p1.1.m1.1.1" xref="A4.SS3.p1.1.m1.1.1.cmml">
        α
       </mi>
       <annotation-xml encoding="MathML-Content" id="A4.SS3.p1.1.m1.1b">
        <ci id="A4.SS3.p1.1.m1.1.1.cmml" xref="A4.SS3.p1.1.m1.1.1">
         𝛼
        </ci>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="A4.SS3.p1.1.m1.1c">
        \alpha
       </annotation>
      </semantics>
     </math>
     in LoRA
     <cite class="ltx_cite ltx_citemacro_citep">
      (Hu et al.,
      <a class="ltx_ref" href="#bib.bib31" title="">
       2022
      </a>
      )
     </cite>
     to be 16 and the dropout rate to be 0. LoRA is implemented for all the projection matrices in the LLM,
     <em class="ltx_emph ltx_font_italic" id="A4.SS3.p1.3.3">
      i.e
     </em>
     .
     <span class="ltx_text" id="A4.SS3.p1.3.4">
     </span>
     ,
     <math alttext="(W_{q},W_{k},W_{v},W_{o})" class="ltx_Math" display="inline" id="A4.SS3.p1.2.m2.4">
      <semantics id="A4.SS3.p1.2.m2.4a">
       <mrow id="A4.SS3.p1.2.m2.4.4.4" xref="A4.SS3.p1.2.m2.4.4.5.cmml">
        <mo id="A4.SS3.p1.2.m2.4.4.4.5" stretchy="false" xref="A4.SS3.p1.2.m2.4.4.5.cmml">
         (
        </mo>
        <msub id="A4.SS3.p1.2.m2.1.1.1.1" xref="A4.SS3.p1.2.m2.1.1.1.1.cmml">
         <mi id="A4.SS3.p1.2.m2.1.1.1.1.2" xref="A4.SS3.p1.2.m2.1.1.1.1.2.cmml">
          W
         </mi>
         <mi id="A4.SS3.p1.2.m2.1.1.1.1.3" xref="A4.SS3.p1.2.m2.1.1.1.1.3.cmml">
          q
         </mi>
        </msub>
        <mo id="A4.SS3.p1.2.m2.4.4.4.6" xref="A4.SS3.p1.2.m2.4.4.5.cmml">
         ,
        </mo>
        <msub id="A4.SS3.p1.2.m2.2.2.2.2" xref="A4.SS3.p1.2.m2.2.2.2.2.cmml">
         <mi id="A4.SS3.p1.2.m2.2.2.2.2.2" xref="A4.SS3.p1.2.m2.2.2.2.2.2.cmml">
          W
         </mi>
         <mi id="A4.SS3.p1.2.m2.2.2.2.2.3" xref="A4.SS3.p1.2.m2.2.2.2.2.3.cmml">
          k
         </mi>
        </msub>
        <mo id="A4.SS3.p1.2.m2.4.4.4.7" xref="A4.SS3.p1.2.m2.4.4.5.cmml">
         ,
        </mo>
        <msub id="A4.SS3.p1.2.m2.3.3.3.3" xref="A4.SS3.p1.2.m2.3.3.3.3.cmml">
         <mi id="A4.SS3.p1.2.m2.3.3.3.3.2" xref="A4.SS3.p1.2.m2.3.3.3.3.2.cmml">
          W
         </mi>
         <mi id="A4.SS3.p1.2.m2.3.3.3.3.3" xref="A4.SS3.p1.2.m2.3.3.3.3.3.cmml">
          v
         </mi>
        </msub>
        <mo id="A4.SS3.p1.2.m2.4.4.4.8" xref="A4.SS3.p1.2.m2.4.4.5.cmml">
         ,
        </mo>
        <msub id="A4.SS3.p1.2.m2.4.4.4.4" xref="A4.SS3.p1.2.m2.4.4.4.4.cmml">
         <mi id="A4.SS3.p1.2.m2.4.4.4.4.2" xref="A4.SS3.p1.2.m2.4.4.4.4.2.cmml">
          W
         </mi>
         <mi id="A4.SS3.p1.2.m2.4.4.4.4.3" xref="A4.SS3.p1.2.m2.4.4.4.4.3.cmml">
          o
         </mi>
        </msub>
        <mo id="A4.SS3.p1.2.m2.4.4.4.9" stretchy="false" xref="A4.SS3.p1.2.m2.4.4.5.cmml">
         )
        </mo>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="A4.SS3.p1.2.m2.4b">
        <vector id="A4.SS3.p1.2.m2.4.4.5.cmml" xref="A4.SS3.p1.2.m2.4.4.4">
         <apply id="A4.SS3.p1.2.m2.1.1.1.1.cmml" xref="A4.SS3.p1.2.m2.1.1.1.1">
          <csymbol cd="ambiguous" id="A4.SS3.p1.2.m2.1.1.1.1.1.cmml" xref="A4.SS3.p1.2.m2.1.1.1.1">
           subscript
          </csymbol>
          <ci id="A4.SS3.p1.2.m2.1.1.1.1.2.cmml" xref="A4.SS3.p1.2.m2.1.1.1.1.2">
           𝑊
          </ci>
          <ci id="A4.SS3.p1.2.m2.1.1.1.1.3.cmml" xref="A4.SS3.p1.2.m2.1.1.1.1.3">
           𝑞
          </ci>
         </apply>
         <apply id="A4.SS3.p1.2.m2.2.2.2.2.cmml" xref="A4.SS3.p1.2.m2.2.2.2.2">
          <csymbol cd="ambiguous" id="A4.SS3.p1.2.m2.2.2.2.2.1.cmml" xref="A4.SS3.p1.2.m2.2.2.2.2">
           subscript
          </csymbol>
          <ci id="A4.SS3.p1.2.m2.2.2.2.2.2.cmml" xref="A4.SS3.p1.2.m2.2.2.2.2.2">
           𝑊
          </ci>
          <ci id="A4.SS3.p1.2.m2.2.2.2.2.3.cmml" xref="A4.SS3.p1.2.m2.2.2.2.2.3">
           𝑘
          </ci>
         </apply>
         <apply id="A4.SS3.p1.2.m2.3.3.3.3.cmml" xref="A4.SS3.p1.2.m2.3.3.3.3">
          <csymbol cd="ambiguous" id="A4.SS3.p1.2.m2.3.3.3.3.1.cmml" xref="A4.SS3.p1.2.m2.3.3.3.3">
           subscript
          </csymbol>
          <ci id="A4.SS3.p1.2.m2.3.3.3.3.2.cmml" xref="A4.SS3.p1.2.m2.3.3.3.3.2">
           𝑊
          </ci>
          <ci id="A4.SS3.p1.2.m2.3.3.3.3.3.cmml" xref="A4.SS3.p1.2.m2.3.3.3.3.3">
           𝑣
          </ci>
         </apply>
         <apply id="A4.SS3.p1.2.m2.4.4.4.4.cmml" xref="A4.SS3.p1.2.m2.4.4.4.4">
          <csymbol cd="ambiguous" id="A4.SS3.p1.2.m2.4.4.4.4.1.cmml" xref="A4.SS3.p1.2.m2.4.4.4.4">
           subscript
          </csymbol>
          <ci id="A4.SS3.p1.2.m2.4.4.4.4.2.cmml" xref="A4.SS3.p1.2.m2.4.4.4.4.2">
           𝑊
          </ci>
          <ci id="A4.SS3.p1.2.m2.4.4.4.4.3.cmml" xref="A4.SS3.p1.2.m2.4.4.4.4.3">
           𝑜
          </ci>
         </apply>
        </vector>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="A4.SS3.p1.2.m2.4c">
        (W_{q},W_{k},W_{v},W_{o})
       </annotation>
      </semantics>
     </math>
     in attention modules and
     <math alttext="(W_{gate},W_{up},W_{down})" class="ltx_Math" display="inline" id="A4.SS3.p1.3.m3.3">
      <semantics id="A4.SS3.p1.3.m3.3a">
       <mrow id="A4.SS3.p1.3.m3.3.3.3" xref="A4.SS3.p1.3.m3.3.3.4.cmml">
        <mo id="A4.SS3.p1.3.m3.3.3.3.4" stretchy="false" xref="A4.SS3.p1.3.m3.3.3.4.cmml">
         (
        </mo>
        <msub id="A4.SS3.p1.3.m3.1.1.1.1" xref="A4.SS3.p1.3.m3.1.1.1.1.cmml">
         <mi id="A4.SS3.p1.3.m3.1.1.1.1.2" xref="A4.SS3.p1.3.m3.1.1.1.1.2.cmml">
          W
         </mi>
         <mrow id="A4.SS3.p1.3.m3.1.1.1.1.3" xref="A4.SS3.p1.3.m3.1.1.1.1.3.cmml">
          <mi id="A4.SS3.p1.3.m3.1.1.1.1.3.2" xref="A4.SS3.p1.3.m3.1.1.1.1.3.2.cmml">
           g
          </mi>
          <mo id="A4.SS3.p1.3.m3.1.1.1.1.3.1" lspace="0em" rspace="0em" xref="A4.SS3.p1.3.m3.1.1.1.1.3.1.cmml">
           ​
          </mo>
          <mi id="A4.SS3.p1.3.m3.1.1.1.1.3.3" xref="A4.SS3.p1.3.m3.1.1.1.1.3.3.cmml">
           a
          </mi>
          <mo id="A4.SS3.p1.3.m3.1.1.1.1.3.1a" lspace="0em" rspace="0em" xref="A4.SS3.p1.3.m3.1.1.1.1.3.1.cmml">
           ​
          </mo>
          <mi id="A4.SS3.p1.3.m3.1.1.1.1.3.4" xref="A4.SS3.p1.3.m3.1.1.1.1.3.4.cmml">
           t
          </mi>
          <mo id="A4.SS3.p1.3.m3.1.1.1.1.3.1b" lspace="0em" rspace="0em" xref="A4.SS3.p1.3.m3.1.1.1.1.3.1.cmml">
           ​
          </mo>
          <mi id="A4.SS3.p1.3.m3.1.1.1.1.3.5" xref="A4.SS3.p1.3.m3.1.1.1.1.3.5.cmml">
           e
          </mi>
         </mrow>
        </msub>
        <mo id="A4.SS3.p1.3.m3.3.3.3.5" xref="A4.SS3.p1.3.m3.3.3.4.cmml">
         ,
        </mo>
        <msub id="A4.SS3.p1.3.m3.2.2.2.2" xref="A4.SS3.p1.3.m3.2.2.2.2.cmml">
         <mi id="A4.SS3.p1.3.m3.2.2.2.2.2" xref="A4.SS3.p1.3.m3.2.2.2.2.2.cmml">
          W
         </mi>
         <mrow id="A4.SS3.p1.3.m3.2.2.2.2.3" xref="A4.SS3.p1.3.m3.2.2.2.2.3.cmml">
          <mi id="A4.SS3.p1.3.m3.2.2.2.2.3.2" xref="A4.SS3.p1.3.m3.2.2.2.2.3.2.cmml">
           u
          </mi>
          <mo id="A4.SS3.p1.3.m3.2.2.2.2.3.1" lspace="0em" rspace="0em" xref="A4.SS3.p1.3.m3.2.2.2.2.3.1.cmml">
           ​
          </mo>
          <mi id="A4.SS3.p1.3.m3.2.2.2.2.3.3" xref="A4.SS3.p1.3.m3.2.2.2.2.3.3.cmml">
           p
          </mi>
         </mrow>
        </msub>
        <mo id="A4.SS3.p1.3.m3.3.3.3.6" xref="A4.SS3.p1.3.m3.3.3.4.cmml">
         ,
        </mo>
        <msub id="A4.SS3.p1.3.m3.3.3.3.3" xref="A4.SS3.p1.3.m3.3.3.3.3.cmml">
         <mi id="A4.SS3.p1.3.m3.3.3.3.3.2" xref="A4.SS3.p1.3.m3.3.3.3.3.2.cmml">
          W
         </mi>
         <mrow id="A4.SS3.p1.3.m3.3.3.3.3.3" xref="A4.SS3.p1.3.m3.3.3.3.3.3.cmml">
          <mi id="A4.SS3.p1.3.m3.3.3.3.3.3.2" xref="A4.SS3.p1.3.m3.3.3.3.3.3.2.cmml">
           d
          </mi>
          <mo id="A4.SS3.p1.3.m3.3.3.3.3.3.1" lspace="0em" rspace="0em" xref="A4.SS3.p1.3.m3.3.3.3.3.3.1.cmml">
           ​
          </mo>
          <mi id="A4.SS3.p1.3.m3.3.3.3.3.3.3" xref="A4.SS3.p1.3.m3.3.3.3.3.3.3.cmml">
           o
          </mi>
          <mo id="A4.SS3.p1.3.m3.3.3.3.3.3.1a" lspace="0em" rspace="0em" xref="A4.SS3.p1.3.m3.3.3.3.3.3.1.cmml">
           ​
          </mo>
          <mi id="A4.SS3.p1.3.m3.3.3.3.3.3.4" xref="A4.SS3.p1.3.m3.3.3.3.3.3.4.cmml">
           w
          </mi>
          <mo id="A4.SS3.p1.3.m3.3.3.3.3.3.1b" lspace="0em" rspace="0em" xref="A4.SS3.p1.3.m3.3.3.3.3.3.1.cmml">
           ​
          </mo>
          <mi id="A4.SS3.p1.3.m3.3.3.3.3.3.5" xref="A4.SS3.p1.3.m3.3.3.3.3.3.5.cmml">
           n
          </mi>
         </mrow>
        </msub>
        <mo id="A4.SS3.p1.3.m3.3.3.3.7" stretchy="false" xref="A4.SS3.p1.3.m3.3.3.4.cmml">
         )
        </mo>
       </mrow>
       <annotation-xml encoding="MathML-Content" id="A4.SS3.p1.3.m3.3b">
        <vector id="A4.SS3.p1.3.m3.3.3.4.cmml" xref="A4.SS3.p1.3.m3.3.3.3">
         <apply id="A4.SS3.p1.3.m3.1.1.1.1.cmml" xref="A4.SS3.p1.3.m3.1.1.1.1">
          <csymbol cd="ambiguous" id="A4.SS3.p1.3.m3.1.1.1.1.1.cmml" xref="A4.SS3.p1.3.m3.1.1.1.1">
           subscript
          </csymbol>
          <ci id="A4.SS3.p1.3.m3.1.1.1.1.2.cmml" xref="A4.SS3.p1.3.m3.1.1.1.1.2">
           𝑊
          </ci>
          <apply id="A4.SS3.p1.3.m3.1.1.1.1.3.cmml" xref="A4.SS3.p1.3.m3.1.1.1.1.3">
           <times id="A4.SS3.p1.3.m3.1.1.1.1.3.1.cmml" xref="A4.SS3.p1.3.m3.1.1.1.1.3.1">
           </times>
           <ci id="A4.SS3.p1.3.m3.1.1.1.1.3.2.cmml" xref="A4.SS3.p1.3.m3.1.1.1.1.3.2">
            𝑔
           </ci>
           <ci id="A4.SS3.p1.3.m3.1.1.1.1.3.3.cmml" xref="A4.SS3.p1.3.m3.1.1.1.1.3.3">
            𝑎
           </ci>
           <ci id="A4.SS3.p1.3.m3.1.1.1.1.3.4.cmml" xref="A4.SS3.p1.3.m3.1.1.1.1.3.4">
            𝑡
           </ci>
           <ci id="A4.SS3.p1.3.m3.1.1.1.1.3.5.cmml" xref="A4.SS3.p1.3.m3.1.1.1.1.3.5">
            𝑒
           </ci>
          </apply>
         </apply>
         <apply id="A4.SS3.p1.3.m3.2.2.2.2.cmml" xref="A4.SS3.p1.3.m3.2.2.2.2">
          <csymbol cd="ambiguous" id="A4.SS3.p1.3.m3.2.2.2.2.1.cmml" xref="A4.SS3.p1.3.m3.2.2.2.2">
           subscript
          </csymbol>
          <ci id="A4.SS3.p1.3.m3.2.2.2.2.2.cmml" xref="A4.SS3.p1.3.m3.2.2.2.2.2">
           𝑊
          </ci>
          <apply id="A4.SS3.p1.3.m3.2.2.2.2.3.cmml" xref="A4.SS3.p1.3.m3.2.2.2.2.3">
           <times id="A4.SS3.p1.3.m3.2.2.2.2.3.1.cmml" xref="A4.SS3.p1.3.m3.2.2.2.2.3.1">
           </times>
           <ci id="A4.SS3.p1.3.m3.2.2.2.2.3.2.cmml" xref="A4.SS3.p1.3.m3.2.2.2.2.3.2">
            𝑢
           </ci>
           <ci id="A4.SS3.p1.3.m3.2.2.2.2.3.3.cmml" xref="A4.SS3.p1.3.m3.2.2.2.2.3.3">
            𝑝
           </ci>
          </apply>
         </apply>
         <apply id="A4.SS3.p1.3.m3.3.3.3.3.cmml" xref="A4.SS3.p1.3.m3.3.3.3.3">
          <csymbol cd="ambiguous" id="A4.SS3.p1.3.m3.3.3.3.3.1.cmml" xref="A4.SS3.p1.3.m3.3.3.3.3">
           subscript
          </csymbol>
          <ci id="A4.SS3.p1.3.m3.3.3.3.3.2.cmml" xref="A4.SS3.p1.3.m3.3.3.3.3.2">
           𝑊
          </ci>
          <apply id="A4.SS3.p1.3.m3.3.3.3.3.3.cmml" xref="A4.SS3.p1.3.m3.3.3.3.3.3">
           <times id="A4.SS3.p1.3.m3.3.3.3.3.3.1.cmml" xref="A4.SS3.p1.3.m3.3.3.3.3.3.1">
           </times>
           <ci id="A4.SS3.p1.3.m3.3.3.3.3.3.2.cmml" xref="A4.SS3.p1.3.m3.3.3.3.3.3.2">
            𝑑
           </ci>
           <ci id="A4.SS3.p1.3.m3.3.3.3.3.3.3.cmml" xref="A4.SS3.p1.3.m3.3.3.3.3.3.3">
            𝑜
           </ci>
           <ci id="A4.SS3.p1.3.m3.3.3.3.3.3.4.cmml" xref="A4.SS3.p1.3.m3.3.3.3.3.3.4">
            𝑤
           </ci>
           <ci id="A4.SS3.p1.3.m3.3.3.3.3.3.5.cmml" xref="A4.SS3.p1.3.m3.3.3.3.3.3.5">
            𝑛
           </ci>
          </apply>
         </apply>
        </vector>
       </annotation-xml>
       <annotation encoding="application/x-tex" id="A4.SS3.p1.3.m3.3c">
        (W_{gate},W_{up},W_{down})
       </annotation>
      </semantics>
     </math>
     in MLPs.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A4.SS3.p2">
    <p class="ltx_p" id="A4.SS3.p2.1">
     The hyperparameters for beam search during inference are as follows:
    </p>
   </div>
   <figure class="ltx_table" id="A4.T15">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 15:
     </span>
     Hyperparameters for
     <span class="ltx_text ltx_font_smallcaps" id="A4.T15.2.1">
      LEO
     </span>
     inference.
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="A4.T15.3">
     <tr class="ltx_tr" id="A4.T15.3.1">
      <td class="ltx_td ltx_align_center ltx_border_tt" id="A4.T15.3.1.1">
       <span class="ltx_text ltx_font_bold" id="A4.T15.3.1.1.1">
        Beam search hyperparameter
       </span>
      </td>
      <td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="A4.T15.3.1.2">
       <span class="ltx_text ltx_font_bold" id="A4.T15.3.1.2.1">
        Value
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A4.T15.3.2">
      <td class="ltx_td ltx_align_center ltx_border_t" id="A4.T15.3.2.1">
       Number of beams
      </td>
      <td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="A4.T15.3.2.2">
       5
      </td>
     </tr>
     <tr class="ltx_tr" id="A4.T15.3.3">
      <td class="ltx_td ltx_align_center" id="A4.T15.3.3.1">
       maximum output length
      </td>
      <td class="ltx_td ltx_nopad_r ltx_align_center" id="A4.T15.3.3.2">
       256
      </td>
     </tr>
     <tr class="ltx_tr" id="A4.T15.3.4">
      <td class="ltx_td ltx_align_center" id="A4.T15.3.4.1">
       minimum output length
      </td>
      <td class="ltx_td ltx_nopad_r ltx_align_center" id="A4.T15.3.4.2">
       1
      </td>
     </tr>
     <tr class="ltx_tr" id="A4.T15.3.5">
      <td class="ltx_td ltx_align_center" id="A4.T15.3.5.1">
       top p
      </td>
      <td class="ltx_td ltx_nopad_r ltx_align_center" id="A4.T15.3.5.2">
       0.9
      </td>
     </tr>
     <tr class="ltx_tr" id="A4.T15.3.6">
      <td class="ltx_td ltx_align_center" id="A4.T15.3.6.1">
       repetition penalty
      </td>
      <td class="ltx_td ltx_nopad_r ltx_align_center" id="A4.T15.3.6.2">
       3.0
      </td>
     </tr>
     <tr class="ltx_tr" id="A4.T15.3.7">
      <td class="ltx_td ltx_align_center" id="A4.T15.3.7.1">
       length penalty
      </td>
      <td class="ltx_td ltx_nopad_r ltx_align_center" id="A4.T15.3.7.2">
       1
      </td>
     </tr>
     <tr class="ltx_tr" id="A4.T15.3.8">
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A4.T15.3.8.1">
       temperature
      </td>
      <td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="A4.T15.3.8.2">
       1
      </td>
     </tr>
    </table>
   </figure>
  </section>
 </section>
 <section class="ltx_appendix" id="A5">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix E
   </span>
   Alignment Setup
  </h2>
  <div class="ltx_para" id="A5.p1">
   <p class="ltx_p" id="A5.p1.1">
    The hyperparameters for the first-stage 3D vision-language alignment are presented in
    <a class="ltx_ref" href="#A5.T16" title="In Appendix E Alignment Setup ‣ An Embodied Generalist Agent in 3D World">
     <span class="ltx_text ltx_ref_tag">
      Tab.
     </span>
     <span class="ltx_text ltx_ref_tag">
      16
     </span>
    </a>
   </p>
  </div>
  <figure class="ltx_table" id="A5.T16">
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     Table 16:
    </span>
    Hyperparameters for the alignment stage.
   </figcaption>
   <table class="ltx_tabular ltx_centering ltx_align_middle" id="A5.T16.1">
    <tr class="ltx_tr" id="A5.T16.1.2">
     <td class="ltx_td ltx_align_center ltx_border_tt" id="A5.T16.1.2.1">
      <span class="ltx_text ltx_font_bold" id="A5.T16.1.2.1.1">
       Hyperparameter
      </span>
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="A5.T16.1.2.2">
      <span class="ltx_text ltx_font_bold" id="A5.T16.1.2.2.1">
       Value
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A5.T16.1.3">
     <td class="ltx_td ltx_align_center ltx_border_t" id="A5.T16.1.3.1">
      Optimizer
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="A5.T16.1.3.2">
      AdamW
     </td>
    </tr>
    <tr class="ltx_tr" id="A5.T16.1.4">
     <td class="ltx_td ltx_align_center" id="A5.T16.1.4.1">
      Weight Decay
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A5.T16.1.4.2">
      0.05
     </td>
    </tr>
    <tr class="ltx_tr" id="A5.T16.1.5">
     <td class="ltx_td ltx_align_center" id="A5.T16.1.5.1">
      betas
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A5.T16.1.5.2">
      [0.9, 0.999]
     </td>
    </tr>
    <tr class="ltx_tr" id="A5.T16.1.1">
     <td class="ltx_td ltx_align_center" id="A5.T16.1.1.2">
      Learning Rate
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A5.T16.1.1.1">
      <math alttext="3\times 10^{-4}" class="ltx_Math" display="inline" id="A5.T16.1.1.1.m1.1">
       <semantics id="A5.T16.1.1.1.m1.1a">
        <mrow id="A5.T16.1.1.1.m1.1.1" xref="A5.T16.1.1.1.m1.1.1.cmml">
         <mn id="A5.T16.1.1.1.m1.1.1.2" xref="A5.T16.1.1.1.m1.1.1.2.cmml">
          3
         </mn>
         <mo id="A5.T16.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A5.T16.1.1.1.m1.1.1.1.cmml">
          ×
         </mo>
         <msup id="A5.T16.1.1.1.m1.1.1.3" xref="A5.T16.1.1.1.m1.1.1.3.cmml">
          <mn id="A5.T16.1.1.1.m1.1.1.3.2" xref="A5.T16.1.1.1.m1.1.1.3.2.cmml">
           10
          </mn>
          <mrow id="A5.T16.1.1.1.m1.1.1.3.3" xref="A5.T16.1.1.1.m1.1.1.3.3.cmml">
           <mo id="A5.T16.1.1.1.m1.1.1.3.3a" xref="A5.T16.1.1.1.m1.1.1.3.3.cmml">
            −
           </mo>
           <mn id="A5.T16.1.1.1.m1.1.1.3.3.2" xref="A5.T16.1.1.1.m1.1.1.3.3.2.cmml">
            4
           </mn>
          </mrow>
         </msup>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="A5.T16.1.1.1.m1.1b">
         <apply id="A5.T16.1.1.1.m1.1.1.cmml" xref="A5.T16.1.1.1.m1.1.1">
          <times id="A5.T16.1.1.1.m1.1.1.1.cmml" xref="A5.T16.1.1.1.m1.1.1.1">
          </times>
          <cn id="A5.T16.1.1.1.m1.1.1.2.cmml" type="integer" xref="A5.T16.1.1.1.m1.1.1.2">
           3
          </cn>
          <apply id="A5.T16.1.1.1.m1.1.1.3.cmml" xref="A5.T16.1.1.1.m1.1.1.3">
           <csymbol cd="ambiguous" id="A5.T16.1.1.1.m1.1.1.3.1.cmml" xref="A5.T16.1.1.1.m1.1.1.3">
            superscript
           </csymbol>
           <cn id="A5.T16.1.1.1.m1.1.1.3.2.cmml" type="integer" xref="A5.T16.1.1.1.m1.1.1.3.2">
            10
           </cn>
           <apply id="A5.T16.1.1.1.m1.1.1.3.3.cmml" xref="A5.T16.1.1.1.m1.1.1.3.3">
            <minus id="A5.T16.1.1.1.m1.1.1.3.3.1.cmml" xref="A5.T16.1.1.1.m1.1.1.3.3">
            </minus>
            <cn id="A5.T16.1.1.1.m1.1.1.3.3.2.cmml" type="integer" xref="A5.T16.1.1.1.m1.1.1.3.3.2">
             4
            </cn>
           </apply>
          </apply>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A5.T16.1.1.1.m1.1c">
         3\times 10^{-4}
        </annotation>
       </semantics>
      </math>
     </td>
    </tr>
    <tr class="ltx_tr" id="A5.T16.1.6">
     <td class="ltx_td ltx_align_center" id="A5.T16.1.6.1">
      Warmup Steps
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A5.T16.1.6.2">
      400
     </td>
    </tr>
    <tr class="ltx_tr" id="A5.T16.1.7">
     <td class="ltx_td ltx_align_center" id="A5.T16.1.7.1">
      Number of Workers
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A5.T16.1.7.2">
      4
     </td>
    </tr>
    <tr class="ltx_tr" id="A5.T16.1.8">
     <td class="ltx_td ltx_align_center" id="A5.T16.1.8.1">
      Parallel Strategy
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A5.T16.1.8.2">
      DDP
     </td>
    </tr>
    <tr class="ltx_tr" id="A5.T16.1.9">
     <td class="ltx_td ltx_align_center" id="A5.T16.1.9.1">
      Type of GPUs
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A5.T16.1.9.2">
      NVIDIA A100
     </td>
    </tr>
    <tr class="ltx_tr" id="A5.T16.1.10">
     <td class="ltx_td ltx_align_center" id="A5.T16.1.10.1">
      Number of GPUs
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A5.T16.1.10.2">
      4
     </td>
    </tr>
    <tr class="ltx_tr" id="A5.T16.1.11">
     <td class="ltx_td ltx_align_center" id="A5.T16.1.11.1">
      Accumulate Gradient Batches
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A5.T16.1.11.2">
      5
     </td>
    </tr>
    <tr class="ltx_tr" id="A5.T16.1.12">
     <td class="ltx_td ltx_align_center" id="A5.T16.1.12.1">
      Batch Size/GPU (total)
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A5.T16.1.12.2">
      4 (80)
     </td>
    </tr>
    <tr class="ltx_tr" id="A5.T16.1.13">
     <td class="ltx_td ltx_align_center" id="A5.T16.1.13.1">
      Training Precision
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A5.T16.1.13.2">
      bfloat16
     </td>
    </tr>
    <tr class="ltx_tr" id="A5.T16.1.14">
     <td class="ltx_td ltx_align_center" id="A5.T16.1.14.1">
      gradient norm
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A5.T16.1.14.2">
      5.0
     </td>
    </tr>
    <tr class="ltx_tr" id="A5.T16.1.15">
     <td class="ltx_td ltx_align_center ltx_border_bb" id="A5.T16.1.15.1">
      epochs
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="A5.T16.1.15.2">
      10
     </td>
    </tr>
   </table>
  </figure>
 </section>
 <section class="ltx_appendix" id="A6">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix F
   </span>
   Instruction-tuning Setup
  </h2>
  <div class="ltx_para" id="A6.p1">
   <p class="ltx_p" id="A6.p1.1">
    The hyperparameters for 3D VLA instruction tuning are presented in
    <a class="ltx_ref" href="#A6.T17" title="In Appendix F Instruction-tuning Setup ‣ An Embodied Generalist Agent in 3D World">
     <span class="ltx_text ltx_ref_tag">
      Tab.
     </span>
     <span class="ltx_text ltx_ref_tag">
      17
     </span>
    </a>
   </p>
  </div>
  <figure class="ltx_table" id="A6.T17">
   <figcaption class="ltx_caption ltx_centering">
    <span class="ltx_tag ltx_tag_table">
     Table 17:
    </span>
    Hyperparameters for the instruction-tuning stage.
   </figcaption>
   <table class="ltx_tabular ltx_centering ltx_align_middle" id="A6.T17.1">
    <tr class="ltx_tr" id="A6.T17.1.2">
     <td class="ltx_td ltx_align_center ltx_border_tt" id="A6.T17.1.2.1">
      <span class="ltx_text ltx_font_bold" id="A6.T17.1.2.1.1">
       Hyperparameter
      </span>
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_tt" id="A6.T17.1.2.2">
      <span class="ltx_text ltx_font_bold" id="A6.T17.1.2.2.1">
       Value
      </span>
     </td>
    </tr>
    <tr class="ltx_tr" id="A6.T17.1.3">
     <td class="ltx_td ltx_align_center ltx_border_t" id="A6.T17.1.3.1">
      Optimizer
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_t" id="A6.T17.1.3.2">
      AdamW
     </td>
    </tr>
    <tr class="ltx_tr" id="A6.T17.1.4">
     <td class="ltx_td ltx_align_center" id="A6.T17.1.4.1">
      Weight Decay
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T17.1.4.2">
      0.05
     </td>
    </tr>
    <tr class="ltx_tr" id="A6.T17.1.5">
     <td class="ltx_td ltx_align_center" id="A6.T17.1.5.1">
      betas
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T17.1.5.2">
      [0.9, 0.999]
     </td>
    </tr>
    <tr class="ltx_tr" id="A6.T17.1.1">
     <td class="ltx_td ltx_align_center" id="A6.T17.1.1.2">
      Learning Rate
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T17.1.1.1">
      <math alttext="3\times 10^{-5}" class="ltx_Math" display="inline" id="A6.T17.1.1.1.m1.1">
       <semantics id="A6.T17.1.1.1.m1.1a">
        <mrow id="A6.T17.1.1.1.m1.1.1" xref="A6.T17.1.1.1.m1.1.1.cmml">
         <mn id="A6.T17.1.1.1.m1.1.1.2" xref="A6.T17.1.1.1.m1.1.1.2.cmml">
          3
         </mn>
         <mo id="A6.T17.1.1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="A6.T17.1.1.1.m1.1.1.1.cmml">
          ×
         </mo>
         <msup id="A6.T17.1.1.1.m1.1.1.3" xref="A6.T17.1.1.1.m1.1.1.3.cmml">
          <mn id="A6.T17.1.1.1.m1.1.1.3.2" xref="A6.T17.1.1.1.m1.1.1.3.2.cmml">
           10
          </mn>
          <mrow id="A6.T17.1.1.1.m1.1.1.3.3" xref="A6.T17.1.1.1.m1.1.1.3.3.cmml">
           <mo id="A6.T17.1.1.1.m1.1.1.3.3a" xref="A6.T17.1.1.1.m1.1.1.3.3.cmml">
            −
           </mo>
           <mn id="A6.T17.1.1.1.m1.1.1.3.3.2" xref="A6.T17.1.1.1.m1.1.1.3.3.2.cmml">
            5
           </mn>
          </mrow>
         </msup>
        </mrow>
        <annotation-xml encoding="MathML-Content" id="A6.T17.1.1.1.m1.1b">
         <apply id="A6.T17.1.1.1.m1.1.1.cmml" xref="A6.T17.1.1.1.m1.1.1">
          <times id="A6.T17.1.1.1.m1.1.1.1.cmml" xref="A6.T17.1.1.1.m1.1.1.1">
          </times>
          <cn id="A6.T17.1.1.1.m1.1.1.2.cmml" type="integer" xref="A6.T17.1.1.1.m1.1.1.2">
           3
          </cn>
          <apply id="A6.T17.1.1.1.m1.1.1.3.cmml" xref="A6.T17.1.1.1.m1.1.1.3">
           <csymbol cd="ambiguous" id="A6.T17.1.1.1.m1.1.1.3.1.cmml" xref="A6.T17.1.1.1.m1.1.1.3">
            superscript
           </csymbol>
           <cn id="A6.T17.1.1.1.m1.1.1.3.2.cmml" type="integer" xref="A6.T17.1.1.1.m1.1.1.3.2">
            10
           </cn>
           <apply id="A6.T17.1.1.1.m1.1.1.3.3.cmml" xref="A6.T17.1.1.1.m1.1.1.3.3">
            <minus id="A6.T17.1.1.1.m1.1.1.3.3.1.cmml" xref="A6.T17.1.1.1.m1.1.1.3.3">
            </minus>
            <cn id="A6.T17.1.1.1.m1.1.1.3.3.2.cmml" type="integer" xref="A6.T17.1.1.1.m1.1.1.3.3.2">
             5
            </cn>
           </apply>
          </apply>
         </apply>
        </annotation-xml>
        <annotation encoding="application/x-tex" id="A6.T17.1.1.1.m1.1c">
         3\times 10^{-5}
        </annotation>
       </semantics>
      </math>
     </td>
    </tr>
    <tr class="ltx_tr" id="A6.T17.1.6">
     <td class="ltx_td ltx_align_center" id="A6.T17.1.6.1">
      Warmup Steps
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T17.1.6.2">
      400
     </td>
    </tr>
    <tr class="ltx_tr" id="A6.T17.1.7">
     <td class="ltx_td ltx_align_center" id="A6.T17.1.7.1">
      Number of Workers
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T17.1.7.2">
      4
     </td>
    </tr>
    <tr class="ltx_tr" id="A6.T17.1.8">
     <td class="ltx_td ltx_align_center" id="A6.T17.1.8.1">
      Parallel Strategy
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T17.1.8.2">
      DDP
     </td>
    </tr>
    <tr class="ltx_tr" id="A6.T17.1.9">
     <td class="ltx_td ltx_align_center" id="A6.T17.1.9.1">
      Type of GPUs
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T17.1.9.2">
      NVIDIA A100
     </td>
    </tr>
    <tr class="ltx_tr" id="A6.T17.1.10">
     <td class="ltx_td ltx_align_center" id="A6.T17.1.10.1">
      Number of GPUs
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T17.1.10.2">
      4
     </td>
    </tr>
    <tr class="ltx_tr" id="A6.T17.1.11">
     <td class="ltx_td ltx_align_center" id="A6.T17.1.11.1">
      Accumulate Gradient Batches
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T17.1.11.2">
      5
     </td>
    </tr>
    <tr class="ltx_tr" id="A6.T17.1.12">
     <td class="ltx_td ltx_align_center" id="A6.T17.1.12.1">
      Batch Size/GPU (total)
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T17.1.12.2">
      4 (80)
     </td>
    </tr>
    <tr class="ltx_tr" id="A6.T17.1.13">
     <td class="ltx_td ltx_align_center" id="A6.T17.1.13.1">
      Training Precision
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T17.1.13.2">
      bfloat16
     </td>
    </tr>
    <tr class="ltx_tr" id="A6.T17.1.14">
     <td class="ltx_td ltx_align_center" id="A6.T17.1.14.1">
      gradient norm
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center" id="A6.T17.1.14.2">
      5.0
     </td>
    </tr>
    <tr class="ltx_tr" id="A6.T17.1.15">
     <td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T17.1.15.1">
      epochs
     </td>
     <td class="ltx_td ltx_nopad_r ltx_align_center ltx_border_bb" id="A6.T17.1.15.2">
      10
     </td>
    </tr>
   </table>
  </figure>
 </section>
 <section class="ltx_appendix" id="A7">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix G
   </span>
   Ablation Details
  </h2>
  <section class="ltx_paragraph" id="A7.SS0.SSS0.Px1">
   <h5 class="ltx_title ltx_title_paragraph">
    Data ablation.
   </h5>
   <div class="ltx_para ltx_noindent" id="A7.SS0.SSS0.Px1.p1">
    <p class="ltx_p" id="A7.SS0.SSS0.Px1.p1.1">
     We present the numerical results in
     <a class="ltx_ref" href="#A7.T18" title="In Data ablation. ‣ Appendix G Ablation Details ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Tab.
      </span>
      <span class="ltx_text ltx_ref_tag">
       18
      </span>
     </a>
     as complements to
     <a class="ltx_ref" href="#S4.F4" title="In Evaluation. ‣ 4.4 Ablative Study ‣ 4 Capabilities and Analyses ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Fig.
      </span>
      <span class="ltx_text ltx_ref_tag">
       4
      </span>
     </a>
     (a).
    </p>
   </div>
   <figure class="ltx_table" id="A7.T18">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 18:
     </span>
     Evaluation results of
     <span class="ltx_text ltx_font_smallcaps" id="A7.T18.4.1">
      LEO
     </span>
     with different data configurations for training. We test models on the validation set of Scan2Cap and ScanQA, and the held-out test sets of other datasets. We report exact match scores for QA tasks and SentenceSim for all other tasks. * indicates datasets that belong to
     <span class="ltx_text ltx_font_smallcaps" id="A7.T18.5.2">
      LEO
     </span>
     -align.
     <span class="ltx_text" id="A7.T18.6.3" style="color:#808080;">
      Figures in gray
     </span>
     indicate zero-shot transfer.
    </figcaption>
    <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A7.T18.7" style="width:433.6pt;height:101.7pt;vertical-align:-0.9pt;">
     <span class="ltx_transformed_inner" style="transform:translate(-15.6pt,3.6pt) scale(0.932904626747642,0.932904626747642) ;">
      <table class="ltx_tabular ltx_align_middle" id="A7.T18.7.1">
       <tr class="ltx_tr" id="A7.T18.7.1.1">
        <td class="ltx_td ltx_border_tt" id="A7.T18.7.1.1.1">
        </td>
        <td class="ltx_td ltx_align_center ltx_border_tt" id="A7.T18.7.1.1.2">
         Cap3D*
        </td>
        <td class="ltx_td ltx_align_center ltx_border_tt" id="A7.T18.7.1.1.3">
         SceneCap*
        </td>
        <td class="ltx_td ltx_align_center ltx_border_tt" id="A7.T18.7.1.1.4">
         Scan2Cap
        </td>
        <td class="ltx_td ltx_align_center ltx_border_tt" id="A7.T18.7.1.1.5">
         ScanQA
        </td>
        <td class="ltx_td ltx_align_center ltx_border_tt" id="A7.T18.7.1.1.6">
         SQA3D
        </td>
        <td class="ltx_td ltx_align_center ltx_border_tt" id="A7.T18.7.1.1.7">
         3RQA
        </td>
        <td class="ltx_td ltx_align_center ltx_border_tt" id="A7.T18.7.1.1.8">
         3RPlan
        </td>
        <td class="ltx_td ltx_align_center ltx_border_tt" id="A7.T18.7.1.1.9">
         3RDialog
        </td>
       </tr>
       <tr class="ltx_tr" id="A7.T18.7.1.2">
        <td class="ltx_td ltx_align_left ltx_border_t" id="A7.T18.7.1.2.1">
         <span class="ltx_text ltx_font_italic" id="A7.T18.7.1.2.1.1">
          NoAlign
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A7.T18.7.1.2.2">
         20.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A7.T18.7.1.2.3">
         23.6
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A7.T18.7.1.2.4">
         52.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A7.T18.7.1.2.5">
         35.3
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A7.T18.7.1.2.6">
         50.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A7.T18.7.1.2.7">
         46.8
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A7.T18.7.1.2.8">
         69.2
        </td>
        <td class="ltx_td ltx_align_center ltx_border_t" id="A7.T18.7.1.2.9">
         76.4
        </td>
       </tr>
       <tr class="ltx_tr" id="A7.T18.7.1.3">
        <td class="ltx_td ltx_align_left" id="A7.T18.7.1.3.1">
         <span class="ltx_text ltx_font_italic" id="A7.T18.7.1.3.1.1">
          PartialData
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.3.2">
         23.0
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.3.3">
         61.5
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.3.4">
         62.2
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.3.5">
         30.2
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.3.6">
         45.4
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.3.7">
         47.3
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.3.8">
         69.3
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.3.9">
         76.4
        </td>
       </tr>
       <tr class="ltx_tr" id="A7.T18.7.1.4">
        <td class="ltx_td ltx_align_left" id="A7.T18.7.1.4.1">
         <span class="ltx_text ltx_font_italic" id="A7.T18.7.1.4.1.1">
          ScanNetOnly
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.4.2">
         34.5
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.4.3">
         <span class="ltx_text ltx_font_bold" id="A7.T18.7.1.4.3.1">
          67.0
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.4.4">
         <span class="ltx_text ltx_font_bold" id="A7.T18.7.1.4.4.1">
          65.2
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.4.5">
         <span class="ltx_text ltx_font_bold" id="A7.T18.7.1.4.5.1">
          37.8
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.4.6">
         <span class="ltx_text ltx_font_bold" id="A7.T18.7.1.4.6.1">
          54.4
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.4.7">
         <span class="ltx_text" id="A7.T18.7.1.4.7.1" style="color:#808080;">
          32.5
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.4.8">
         <span class="ltx_text" id="A7.T18.7.1.4.8.1" style="color:#808080;">
          33.2
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.4.9">
         <span class="ltx_text" id="A7.T18.7.1.4.9.1" style="color:#808080;">
          63.2
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A7.T18.7.1.5">
        <td class="ltx_td ltx_align_left" id="A7.T18.7.1.5.1">
         <span class="ltx_text ltx_font_italic" id="A7.T18.7.1.5.1.1">
          NoAct (VL)
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.5.2">
         <span class="ltx_text ltx_font_bold" id="A7.T18.7.1.5.2.1">
          35.9
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.5.3">
         65.5
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.5.4">
         64.9
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.5.5">
         36.8
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.5.6">
         54.1
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.5.7">
         <span class="ltx_text ltx_font_bold" id="A7.T18.7.1.5.7.1">
          61.3
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.5.8">
         <span class="ltx_text ltx_font_bold" id="A7.T18.7.1.5.8.1">
          74.1
         </span>
        </td>
        <td class="ltx_td ltx_align_center" id="A7.T18.7.1.5.9">
         <span class="ltx_text ltx_font_bold" id="A7.T18.7.1.5.9.1">
          79.6
         </span>
        </td>
       </tr>
       <tr class="ltx_tr" id="A7.T18.7.1.6">
        <td class="ltx_td ltx_align_left ltx_border_bb" id="A7.T18.7.1.6.1">
         <span class="ltx_text ltx_font_italic" id="A7.T18.7.1.6.1.1">
          Full (VLA)
         </span>
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T18.7.1.6.2">
         12.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T18.7.1.6.3">
         64.7
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T18.7.1.6.4">
         62.1
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T18.7.1.6.5">
         37.0
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T18.7.1.6.6">
         51.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T18.7.1.6.7">
         55.9
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T18.7.1.6.8">
         73.5
        </td>
        <td class="ltx_td ltx_align_center ltx_border_bb" id="A7.T18.7.1.6.9">
         78.4
        </td>
       </tr>
      </table>
     </span>
    </div>
   </figure>
  </section>
  <section class="ltx_paragraph" id="A7.SS0.SSS0.Px2">
   <h5 class="ltx_title ltx_title_paragraph">
    Model ablation.
   </h5>
   <div class="ltx_para ltx_noindent" id="A7.SS0.SSS0.Px2.p1">
    <p class="ltx_p" id="A7.SS0.SSS0.Px2.p1.1">
     We also make some explorations in model ablation and simply present qualitative findings here. For the point cloud encoder, we choose Point-BERT
     <cite class="ltx_cite ltx_citemacro_citep">
      (Yu et al.,
      <a class="ltx_ref" href="#bib.bib88" title="">
       2022
      </a>
      )
     </cite>
     as an alternative to the default PointNet++
     <cite class="ltx_cite ltx_citemacro_citep">
      (Qi et al.,
      <a class="ltx_ref" href="#bib.bib60" title="">
       2017
      </a>
      )
     </cite>
     . We utilize the checkpoint from PointLLM
     <cite class="ltx_cite ltx_citemacro_citep">
      (Xu et al.,
      <a class="ltx_ref" href="#bib.bib85" title="">
       2023
      </a>
      )
     </cite>
     , which has adapted Point-BERT to 6-channel (XYZRGB) input and learned a language-aligned representation for 3D objects. Despite larger capacity, Point-BERT shows significantly worse performances than PointNet++ as the point cloud encoder. Similarly, for the Spatial Transformer and LLM, we ablate with different model scales but find no improvement. The influence of different modules remains an interesting question that deserves further exploration.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_appendix" id="A8">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix H
   </span>
   Evaluation Details
  </h2>
  <section class="ltx_subsection" id="A8.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     H.1
    </span>
    3D Question Answering
   </h3>
   <section class="ltx_paragraph" id="A8.SS1.SSS0.Px1">
    <h5 class="ltx_title ltx_title_paragraph">
     Rationality of QA evaluation protocol.
    </h5>
    <div class="ltx_para ltx_noindent" id="A8.SS1.SSS0.Px1.p1">
     <p class="ltx_p" id="A8.SS1.SSS0.Px1.p1.1">
      We argue that exact match (EM), as a conventional metric for 3D QA, is unsuitable for evaluating the open-ended answer generated by LLMs. For example, given the question “
      <span class="ltx_text ltx_font_italic" id="A8.SS1.SSS0.Px1.p1.1.1">
       On what side of the towel is a bathroom curtain
      </span>
      ?” with ground-truth answer “
      <span class="ltx_text ltx_font_italic" id="A8.SS1.SSS0.Px1.p1.1.2">
       left side of towel
      </span>
      ”, it is never wrong to answer “left”. However, this will be deemed incorrect if we adopt the strict exact match protocol. Such a misjudgment is quite likely to occur when evaluating the answers from LLMs. By contrast, the classifier heads for QA (
      <em class="ltx_emph ltx_font_italic" id="A8.SS1.SSS0.Px1.p1.1.3">
       e.g
      </em>
      .
      <span class="ltx_text" id="A8.SS1.SSS0.Px1.p1.1.4">
      </span>
      , MCAN) are less affected because they collect all possible answers in advance to formulate the QA as a close-set classification problem. Hence, we refine the strict exact match protocol as follows.
     </p>
    </div>
    <div class="ltx_para ltx_noindent" id="A8.SS1.SSS0.Px1.p2">
     <div class="ltx_listing ltx_lst_language_Python ltx_lst_numbers_left ltx_lstlisting ltx_listing" id="A8.SS1.SSS0.Px1.p2.1" style="background-color:#F2F2EB;">
      <div class="ltx_listing_data">
       <a download="" href="data:text/plain;base64,IiIiCmNvZGUgZm9yIFFBIHByb3RvY29scwpwcmVkOiBzdHIKZ3RzOiBMaXN0W3N0cl0KIiIiCgpkZWYgc3RyaWN0X2VtKHByZWQsIGd0cyk6CiAgICBmb3IgZ3QgaW4gZ3RzOgogICAgICAgIGlmIHByZWQgPT0gZ3Q6CiAgICAgICAgICAgICMgY2FzZSAxCiAgICAgICAgICAgIHJldHVybiBUcnVlCgoKZGVmIHJlZmluZWRfZW0ocHJlZCwgZ3RzKToKICAgIGZvciBndCBpbiBndHM6CiAgICAgICAgaWYgcHJlZCA9PSBndDoKICAgICAgICAgICAgIyBjYXNlIDEKICAgICAgICAgICAgcmV0dXJuIFRydWUKICAgICAgICBlbGlmICcnLmpvaW4ocHJlZC5zcGxpdCgpKSBpbiAnJy5qb2luKGd0LnNwbGl0KCkpOgogICAgICAgICAgICAjIGNhc2UgMgogICAgICAgICAgICByZXR1cm4gVHJ1ZQogICAgICAgIGVsaWYgJycuam9pbihndC5zcGxpdCgpKSBpbiAnJy5qb2luKHByZWQuc3BsaXQoKSk6CiAgICAgICAgICAgICMgY2FzZSAzCiAgICAgICAgICAgIHJldHVybiBUcnVlCiAgICByZXR1cm4gRmFsc2U=">
        ⬇
       </a>
      </div>
      <div class="ltx_listingline" id="lstnumberx1">
       <span class="ltx_tag ltx_tag_listingline">
        1
       </span>
       <span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx1.1" style="color:#9400D1;">
        ""
       </span>
       <span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx1.2" style="color:#9400D1;">
        "
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx2">
       <span class="ltx_tag ltx_tag_listingline">
        2
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx2.1" style="color:#9400D1;">
        code
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx2.2" style="color:#9400D1;">
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx2.3" style="color:#9400D1;">
        for
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx2.4" style="color:#9400D1;">
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx2.5" style="color:#9400D1;">
        QA
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx2.6" style="color:#9400D1;">
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx2.7" style="color:#9400D1;">
        protocols
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx3">
       <span class="ltx_tag ltx_tag_listingline">
        3
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx3.1" style="color:#9400D1;">
        pred:
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx3.2" style="color:#9400D1;">
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx3.3" style="color:#9400D1;">
        str
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx4">
       <span class="ltx_tag ltx_tag_listingline">
        4
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx4.1" style="color:#9400D1;">
        gts:
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx4.2" style="color:#9400D1;">
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx4.3" style="color:#9400D1;">
        List[str]
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx5">
       <span class="ltx_tag ltx_tag_listingline">
        5
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx5.1" style="color:#9400D1;">
        "
       </span>
       <span class="ltx_text ltx_lst_string" id="lstnumberx5.2">
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx5.3" style="color:#9400D1;">
        ""
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx6">
       <span class="ltx_tag ltx_tag_listingline">
        6
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx7">
       <span class="ltx_tag ltx_tag_listingline">
        7
       </span>
       <span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx7.1" style="color:#FF00FF;">
        def
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.2">
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx7.3">
        strict_em
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx7.4">
        (
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx7.5">
        pred
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx7.6">
        ,
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx7.7">
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx7.8">
        gts
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx7.9">
        ):
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx8">
       <span class="ltx_tag ltx_tag_listingline">
        8
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.1">
       </span>
       <span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx8.2" style="color:#FF00FF;">
        for
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.3">
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.4">
        gt
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.5">
       </span>
       <span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx8.6" style="color:#FF00FF;">
        in
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx8.7">
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx8.8">
        gts
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx8.9">
        :
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx9">
       <span class="ltx_tag ltx_tag_listingline">
        9
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.1">
       </span>
       <span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx9.2" style="color:#FF00FF;">
        if
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.3">
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx9.4">
        pred
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.5">
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx9.6">
        ==
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx9.7">
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx9.8">
        gt
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx9.9">
        :
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx10">
       <span class="ltx_tag ltx_tag_listingline">
        10
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx10.1">
       </span>
       <span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx10.2" style="color:#009900;">
        #
        <span class="ltx_text ltx_lst_space" id="lstnumberx10.2.1">
        </span>
        case
        <span class="ltx_text ltx_lst_space" id="lstnumberx10.2.2">
        </span>
        1
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx11">
       <span class="ltx_tag ltx_tag_listingline">
        11
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.1">
       </span>
       <span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx11.2" style="color:#FF00FF;">
        return
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx11.3">
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx11.4">
        True
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx12">
       <span class="ltx_tag ltx_tag_listingline">
        12
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx13">
       <span class="ltx_tag ltx_tag_listingline">
        13
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx14">
       <span class="ltx_tag ltx_tag_listingline">
        14
       </span>
       <span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx14.1" style="color:#FF00FF;">
        def
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.2">
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.3">
        refined_em
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx14.4">
        (
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.5">
        pred
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx14.6">
        ,
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx14.7">
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx14.8">
        gts
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx14.9">
        ):
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx15">
       <span class="ltx_tag ltx_tag_listingline">
        15
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.1">
       </span>
       <span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx15.2" style="color:#FF00FF;">
        for
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.3">
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.4">
        gt
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.5">
       </span>
       <span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx15.6" style="color:#FF00FF;">
        in
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx15.7">
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx15.8">
        gts
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx15.9">
        :
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx16">
       <span class="ltx_tag ltx_tag_listingline">
        16
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.1">
       </span>
       <span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx16.2" style="color:#FF00FF;">
        if
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.3">
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.4">
        pred
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.5">
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx16.6">
        ==
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx16.7">
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx16.8">
        gt
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx16.9">
        :
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx17">
       <span class="ltx_tag ltx_tag_listingline">
        17
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx17.1">
       </span>
       <span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx17.2" style="color:#009900;">
        #
        <span class="ltx_text ltx_lst_space" id="lstnumberx17.2.1">
        </span>
        case
        <span class="ltx_text ltx_lst_space" id="lstnumberx17.2.2">
        </span>
        1
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx18">
       <span class="ltx_tag ltx_tag_listingline">
        18
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.1">
       </span>
       <span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx18.2" style="color:#FF00FF;">
        return
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx18.3">
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx18.4">
        True
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx19">
       <span class="ltx_tag ltx_tag_listingline">
        19
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.1">
       </span>
       <span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx19.2" style="color:#FF00FF;">
        elif
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.3">
       </span>
       <span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx19.4" style="color:#9400D1;">
        ’’
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx19.5">
        .
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.6">
        join
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx19.7">
        (
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.8">
        pred
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx19.9">
        .
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.10">
        split
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx19.11">
        ())
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.12">
       </span>
       <span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx19.13" style="color:#FF00FF;">
        in
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx19.14">
       </span>
       <span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx19.15" style="color:#9400D1;">
        ’’
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx19.16">
        .
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.17">
        join
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx19.18">
        (
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.19">
        gt
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx19.20">
        .
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx19.21">
        split
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx19.22">
        ()):
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx20">
       <span class="ltx_tag ltx_tag_listingline">
        20
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx20.1">
       </span>
       <span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx20.2" style="color:#009900;">
        #
        <span class="ltx_text ltx_lst_space" id="lstnumberx20.2.1">
        </span>
        case
        <span class="ltx_text ltx_lst_space" id="lstnumberx20.2.2">
        </span>
        2
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx21">
       <span class="ltx_tag ltx_tag_listingline">
        21
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.1">
       </span>
       <span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx21.2" style="color:#FF00FF;">
        return
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx21.3">
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx21.4">
        True
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx22">
       <span class="ltx_tag ltx_tag_listingline">
        22
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.1">
       </span>
       <span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx22.2" style="color:#FF00FF;">
        elif
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.3">
       </span>
       <span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx22.4" style="color:#9400D1;">
        ’’
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx22.5">
        .
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.6">
        join
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx22.7">
        (
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.8">
        gt
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx22.9">
        .
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.10">
        split
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx22.11">
        ())
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.12">
       </span>
       <span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx22.13" style="color:#FF00FF;">
        in
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx22.14">
       </span>
       <span class="ltx_text ltx_lst_string ltx_font_typewriter" id="lstnumberx22.15" style="color:#9400D1;">
        ’’
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx22.16">
        .
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.17">
        join
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx22.18">
        (
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.19">
        pred
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx22.20">
        .
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx22.21">
        split
       </span>
       <span class="ltx_text ltx_font_typewriter" id="lstnumberx22.22">
        ()):
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx23">
       <span class="ltx_tag ltx_tag_listingline">
        23
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx23.1">
       </span>
       <span class="ltx_text ltx_lst_comment ltx_font_typewriter" id="lstnumberx23.2" style="color:#009900;">
        #
        <span class="ltx_text ltx_lst_space" id="lstnumberx23.2.1">
        </span>
        case
        <span class="ltx_text ltx_lst_space" id="lstnumberx23.2.2">
        </span>
        3
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx24">
       <span class="ltx_tag ltx_tag_listingline">
        24
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.1">
       </span>
       <span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx24.2" style="color:#FF00FF;">
        return
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx24.3">
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx24.4">
        True
       </span>
      </div>
      <div class="ltx_listingline" id="lstnumberx25">
       <span class="ltx_tag ltx_tag_listingline">
        25
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.1">
       </span>
       <span class="ltx_text ltx_lst_keyword ltx_font_typewriter" id="lstnumberx25.2" style="color:#FF00FF;">
        return
       </span>
       <span class="ltx_text ltx_lst_space ltx_font_typewriter" id="lstnumberx25.3">
       </span>
       <span class="ltx_text ltx_lst_identifier ltx_font_typewriter" id="lstnumberx25.4">
        False
       </span>
      </div>
     </div>
    </div>
    <div class="ltx_para" id="A8.SS1.SSS0.Px1.p3">
     <p class="ltx_p" id="A8.SS1.SSS0.Px1.p3.1">
      In a nutshell, we squeeze the
      <span class="ltx_text ltx_font_typewriter" id="A8.SS1.SSS0.Px1.p3.1.1">
       pred
      </span>
      and
      <span class="ltx_text ltx_font_typewriter" id="A8.SS1.SSS0.Px1.p3.1.2">
       gt
      </span>
      , and then check whether one is a subset of the other. To justify our refined exact match protocol, in
      <a class="ltx_ref" href="#A8.T19" title="In Rationality of QA evaluation protocol. ‣ H.1 3D Question Answering ‣ Appendix H Evaluation Details ‣ An Embodied Generalist Agent in 3D World">
       <span class="ltx_text ltx_ref_tag">
        Tab.
       </span>
       <span class="ltx_text ltx_ref_tag">
        19
       </span>
      </a>
      we provide some representative examples in the ScanQA validation set. Despite the improvements, we speculate such a simple refinement is still insufficient for a sound evaluation metric considering the flexibility of human language.
     </p>
    </div>
    <figure class="ltx_table" id="A8.T19">
     <figcaption class="ltx_caption ltx_centering">
      <span class="ltx_tag ltx_tag_table">
       Table 19:
      </span>
      Examples from ScanQA validation set, showing the rationality of our refined exact match protocol.
     </figcaption>
     <div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A8.T19.1" style="width:433.6pt;height:157.4pt;vertical-align:-0.6pt;">
      <span class="ltx_transformed_inner" style="transform:translate(-131.7pt,47.6pt) scale(0.622147200497197,0.622147200497197) ;">
       <table class="ltx_tabular ltx_align_middle" id="A8.T19.1.1">
        <tr class="ltx_tr" id="A8.T19.1.1.1">
         <td class="ltx_td ltx_align_left ltx_border_tt" id="A8.T19.1.1.1.1">
          Question
         </td>
         <td class="ltx_td ltx_align_left ltx_border_tt" id="A8.T19.1.1.1.2">
          Ground-truth answer
         </td>
         <td class="ltx_td ltx_align_left ltx_border_tt" id="A8.T19.1.1.1.3">
          Generated answer
         </td>
         <td class="ltx_td ltx_align_center ltx_border_tt" id="A8.T19.1.1.1.4">
          Strict EM
         </td>
         <td class="ltx_td ltx_align_center ltx_border_tt" id="A8.T19.1.1.1.5">
          Refined EM
         </td>
        </tr>
        <tr class="ltx_tr" id="A8.T19.1.1.2">
         <td class="ltx_td ltx_align_left ltx_border_t" id="A8.T19.1.1.2.1">
          What color is the chair in the kitchen?
         </td>
         <td class="ltx_td ltx_align_left ltx_border_t" id="A8.T19.1.1.2.2">
          dark brown
         </td>
         <td class="ltx_td ltx_align_left ltx_border_t" id="A8.T19.1.1.2.3">
          brown
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="A8.T19.1.1.2.4">
          ✗
         </td>
         <td class="ltx_td ltx_align_center ltx_border_t" id="A8.T19.1.1.2.5">
          ✓(case 2)
         </td>
        </tr>
        <tr class="ltx_tr" id="A8.T19.1.1.3">
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.3.1">
          What is under the long kitchen counter?
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.3.2">
          kitchen cabinets
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.3.3">
          brown rectangular kitchen cabinets
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.3.4">
          ✗
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.3.5">
          ✓(case 2)
         </td>
        </tr>
        <tr class="ltx_tr" id="A8.T19.1.1.4">
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.4.1">
          What type of refrigerator is on the right of a kitchen counter?
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.4.2">
          stainless steel refrigerator
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.4.3">
          stainless steel
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.4.4">
          ✗
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.4.5">
          ✓(case 2)
         </td>
        </tr>
        <tr class="ltx_tr" id="A8.T19.1.1.5">
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.5.1">
          Where is the beige wooden desk placed?
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.5.2">
          up against wall
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.5.3">
          against wall
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.5.4">
          ✗
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.5.5">
          ✓(case 2)
         </td>
        </tr>
        <tr class="ltx_tr" id="A8.T19.1.1.6">
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.6.1">
          What color does the sofa look?
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.6.2">
          it looks black
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.6.3">
          black
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.6.4">
          ✗
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.6.5">
          ✓(case 2)
         </td>
        </tr>
        <tr class="ltx_tr" id="A8.T19.1.1.7">
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.7.1">
          Where is the black office chair located?
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.7.2">
          in front of desks
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.7.3">
          in front of desk
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.7.4">
          ✗
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.7.5">
          ✓(case 2)
         </td>
        </tr>
        <tr class="ltx_tr" id="A8.T19.1.1.8">
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.8.1">
          What is in the corner by windows?
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.8.2">
          book shelf
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.8.3">
          bookshelf
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.8.4">
          ✗
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.8.5">
          ✓(case 2)
         </td>
        </tr>
        <tr class="ltx_tr" id="A8.T19.1.1.9">
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.9.1">
          Where is the chair pulled into?
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.9.2">
          table
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.9.3">
          under table
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.9.4">
          ✗
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.9.5">
          ✓(case 3)
         </td>
        </tr>
        <tr class="ltx_tr" id="A8.T19.1.1.10">
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.10.1">
          How many chairs are to the left of the table?
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.10.2">
          4
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.10.3">
          4 chairs
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.10.4">
          ✗
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.10.5">
          ✓(case 3)
         </td>
        </tr>
        <tr class="ltx_tr" id="A8.T19.1.1.11">
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.11.1">
          What objects are sitting on the black couch?
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.11.2">
          pillow
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.11.3">
          pillows
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.11.4">
          ✗
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.11.5">
          ✓(case 3)
         </td>
        </tr>
        <tr class="ltx_tr" id="A8.T19.1.1.12">
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.12.1">
          Where are the two different size tables located in room?
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.12.2">
          in center
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.12.3">
          in center of room
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.12.4">
          ✗
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.12.5">
          ✓(case 3)
         </td>
        </tr>
        <tr class="ltx_tr" id="A8.T19.1.1.13">
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.13.1">
          Where is the laptop located?
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.13.2">
          desk
         </td>
         <td class="ltx_td ltx_align_left" id="A8.T19.1.1.13.3">
          on desk
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.13.4">
          ✗
         </td>
         <td class="ltx_td ltx_align_center" id="A8.T19.1.1.13.5">
          ✓(case 3)
         </td>
        </tr>
        <tr class="ltx_tr" id="A8.T19.1.1.14">
         <td class="ltx_td ltx_align_left ltx_border_bb" id="A8.T19.1.1.14.1">
          Where is the soap dispenser mounted
         </td>
         <td class="ltx_td ltx_align_left ltx_border_bb" id="A8.T19.1.1.14.2">
          above sink
         </td>
         <td class="ltx_td ltx_align_left ltx_border_bb" id="A8.T19.1.1.14.3">
          on wall above sink
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T19.1.1.14.4">
          ✗
         </td>
         <td class="ltx_td ltx_align_center ltx_border_bb" id="A8.T19.1.1.14.5">
          ✓(case 3)
         </td>
        </tr>
       </table>
      </span>
     </div>
    </figure>
   </section>
  </section>
  <section class="ltx_subsection" id="A8.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     H.2
    </span>
    Embodied Navigation
   </h3>
   <div class="ltx_para ltx_noindent" id="A8.SS2.p1">
    <p class="ltx_p" id="A8.SS2.p1.1">
     To construct our training set, we adopt all 57 scenes in the MP3D
     <span class="ltx_text ltx_font_typewriter" id="A8.SS2.p1.1.1">
      ObjNav
     </span>
     training split
     <cite class="ltx_cite ltx_citemacro_citep">
      (Savva et al.,
      <a class="ltx_ref" href="#bib.bib68" title="">
       2019
      </a>
      ; Ramrakhya et al.,
      <a class="ltx_ref" href="#bib.bib64" title="">
       2022
      </a>
      )
     </cite>
     and generate ~60K shortest-path navigation episodes. The evaluation is conducted on the original validation split of the MP3D
     <span class="ltx_text ltx_font_typewriter" id="A8.SS2.p1.1.2">
      ObjNav
     </span>
     task and the newly introduced HM3D
     <span class="ltx_text ltx_font_typewriter" id="A8.SS2.p1.1.3">
      ObjNav
     </span>
     task
     <cite class="ltx_cite ltx_citemacro_citep">
      (Ramakrishnan et al.,
      <a class="ltx_ref" href="#bib.bib63" title="">
       2021
      </a>
      )
     </cite>
     .
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A8.SS2.p2">
    <p class="ltx_p" id="A8.SS2.p2.1">
     In contrast to most
     <span class="ltx_text ltx_font_typewriter" id="A8.SS2.p2.1.1">
      ObjNav
     </span>
     agents that utilize recurrence through either RNN
     <cite class="ltx_cite ltx_citemacro_citep">
      (Ramrakhya et al.,
      <a class="ltx_ref" href="#bib.bib64" title="">
       2022
      </a>
      )
     </cite>
     or DT-style Transformer
     <cite class="ltx_cite ltx_citemacro_citep">
      (Suglia et al.,
      <a class="ltx_ref" href="#bib.bib73" title="">
       2021
      </a>
      )
     </cite>
     ,
     <span class="ltx_text ltx_font_smallcaps" id="A8.SS2.p2.1.2">
      LEO
     </span>
     only employs a simplistic feed-forward policy,
     <em class="ltx_emph ltx_font_italic" id="A8.SS2.p2.1.3">
      i.e
     </em>
     .
     <span class="ltx_text" id="A8.SS2.p2.1.4">
     </span>
     , the Transformer in
     <span class="ltx_text ltx_font_smallcaps" id="A8.SS2.p2.1.5">
      LEO
     </span>
     only takes in the instruction, current state (2D and 3D observation), and past 4 actions, and predicts the next action, similar to RT-2
     <cite class="ltx_cite ltx_citemacro_citep">
      (Brohan et al.,
      <a class="ltx_ref" href="#bib.bib9" title="">
       2023
      </a>
      )
     </cite>
     . Therefore, the only information relayed from the past is about past actions. The absence of recurrence in
     <span class="ltx_text ltx_font_smallcaps" id="A8.SS2.p2.1.6">
      LEO
     </span>
     ’s acting policy is indeed the result of a trade-off between better performances and training efficiency. We will commit to exploring the possibility of looping in more sophisticated policy architectures (
     <em class="ltx_emph ltx_font_italic" id="A8.SS2.p2.1.7">
      e.g
     </em>
     .
     <span class="ltx_text" id="A8.SS2.p2.1.8">
     </span>
     , recurrence) in future work.
    </p>
   </div>
  </section>
 </section>
 <section class="ltx_appendix" id="A9">
  <h2 class="ltx_title ltx_title_appendix">
   <span class="ltx_tag ltx_tag_appendix">
    Appendix I
   </span>
   Additional Results
  </h2>
  <section class="ltx_subsection" id="A9.SS1">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     I.1
    </span>
    Embodied Acting
   </h3>
   <div class="ltx_para ltx_noindent" id="A9.SS1.p1">
    <p class="ltx_p" id="A9.SS1.p1.1">
     <span class="ltx_text ltx_font_bold" id="A9.SS1.p1.1.1">
      Quantitative results of
      <span class="ltx_text ltx_font_typewriter" id="A9.SS1.p1.1.1.1">
       ObjNav
      </span>
      .
     </span>
     We provide additional results of
     <span class="ltx_text ltx_font_smallcaps" id="A9.SS1.p1.1.2">
      LEO
     </span>
     1) generalizing to unseen objects on MP3D, and 2) learning with 70K human demonstrations provided by Habitat-web
     <cite class="ltx_cite ltx_citemacro_citep">
      (Ramrakhya et al.,
      <a class="ltx_ref" href="#bib.bib64" title="">
       2022
      </a>
      )
     </cite>
     instead of shortest path. Below is a list of the objects used during training (
     <span class="ltx_text" id="A9.SS1.p1.1.3" style="color:#008000;">
      seen
     </span>
     ) and for OOD evaluation (
     <span class="ltx_text" id="A9.SS1.p1.1.4" style="color:#CC4054;">
      unseen
     </span>
     ). Evaluation results are shown in
     <a class="ltx_ref" href="#A9.T20" title="In I.1 Embodied Acting ‣ Appendix I Additional Results ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Tab.
      </span>
      <span class="ltx_text ltx_ref_tag">
       20
      </span>
     </a>
     . Note that the baseline Habitat-web is unable to generalize to novel objects as it uses categorical embedding rather than natural language to represent object goals.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A9.SS1.p2">
    <svg class="ltx_picture" height="140.87" id="A9.SS1.p2.pic1" overflow="visible" version="1.1" width="600">
     <g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,140.87) matrix(1 0 0 -1 0 0)">
      <g fill="#404040" fill-opacity="1.0">
       <path d="M 0 5.91 L 0 134.96 C 0 138.22 2.64 140.87 5.91 140.87 L 594.09 140.87 C 597.36 140.87 600 138.22 600 134.96 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill="#F2F2F2" fill-opacity="1.0">
       <path d="M 1.97 5.91 L 1.97 134.96 C 1.97 137.14 3.73 138.9 5.91 138.9 L 594.09 138.9 C 596.27 138.9 598.03 137.14 598.03 134.96 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none">
       </path>
      </g>
      <g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)">
       <foreignobject color="#000000" height="113.31" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="556.69">
        <span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A9.SS1.p2.pic1.1.1.1.1.1" style="width:402.3pt;">
         <span class="ltx_block ltx_minipage ltx_align_middle" id="A9.SS1.p2.pic1.1.1.1.1.1.1" style="width:433.6pt;">
          <span class="ltx_p" id="A9.SS1.p2.pic1.1.1.1.1.1.1.1">
           #
           <span class="ltx_text ltx_font_typewriter" id="A9.SS1.p2.pic1.1.1.1.1.1.1.1.1">
            Objects (seen)
            <br class="ltx_break"/>
            ‘‘gym_equipment’’, ‘‘tv_monitor’’, ‘‘picture’’, ‘‘counter’’, ‘‘chair’’, ‘‘cabinet’’, ‘‘table’’, ‘‘stool’’, ‘‘plant’’, ‘‘towel’’, ‘‘sofa’’, ‘‘cushion’’, ‘‘sink’’, ‘‘fireplace’’, ‘‘toilet’’, ‘‘seating’’, ‘‘chest_of_drawers’’, ‘‘bed’’, ‘‘shower’’, ‘‘bathtub’’, ‘‘clothes’’
           </span>
          </span>
          <span class="ltx_p" id="A9.SS1.p2.pic1.1.1.1.1.1.1.2">
           #
           <span class="ltx_text ltx_font_typewriter" id="A9.SS1.p2.pic1.1.1.1.1.1.1.2.1">
            Objects (unseen)
            <br class="ltx_break"/>
            ‘‘shelf’’, ‘‘pillow’’, ‘‘lamp’’, ‘‘box’’, ‘‘desk’’, ‘‘refrigerator’’, ‘‘vase’’, ‘‘armchair’’
           </span>
          </span>
         </span>
        </span>
       </foreignobject>
      </g>
     </g>
    </svg>
   </div>
   <figure class="ltx_table" id="A9.T20">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 20:
     </span>
     <span class="ltx_text ltx_font_bold" id="A9.T20.7.1">
      Results on object navigation with OOD objects and human demonstrations.
     </span>
     Note that the baseline Habitat-web is unable to generalize to MP3D-
     <span class="ltx_text" id="A9.T20.8.2" style="color:#CC4054;">
      unseen
     </span>
     as it uses categorical embedding rather than natural language to represent object goals.
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="A9.T20.4">
     <tr class="ltx_tr" id="A9.T20.4.5">
      <td class="ltx_td ltx_border_tt" id="A9.T20.4.5.1" rowspan="2" style="padding-left:2.0pt;padding-right:2.0pt;">
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A9.T20.4.5.2" style="padding-left:2.0pt;padding-right:2.0pt;">
       MP3D-
       <span class="ltx_text" id="A9.T20.4.5.2.1" style="color:#008000;">
        seen
       </span>
      </td>
      <td class="ltx_td ltx_border_tt" id="A9.T20.4.5.3" style="padding-left:2.0pt;padding-right:2.0pt;">
      </td>
      <td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="A9.T20.4.5.4" style="padding-left:2.0pt;padding-right:2.0pt;">
       MP3D-
       <span class="ltx_text" id="A9.T20.4.5.4.1" style="color:#CC4054;">
        unseen
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T20.4.4">
      <td class="ltx_td ltx_align_center ltx_border_t" id="A9.T20.1.1.1" style="padding-left:2.0pt;padding-right:2.0pt;">
       Success
       <math alttext="(\uparrow)" class="ltx_Math" display="inline" id="A9.T20.1.1.1.m1.1">
        <semantics id="A9.T20.1.1.1.m1.1a">
         <mrow id="A9.T20.1.1.1.m1.1.2.2">
          <mo id="A9.T20.1.1.1.m1.1.2.2.1" stretchy="false">
           (
          </mo>
          <mo id="A9.T20.1.1.1.m1.1.1" lspace="0em" rspace="0em" stretchy="false" xref="A9.T20.1.1.1.m1.1.1.cmml">
           ↑
          </mo>
          <mo id="A9.T20.1.1.1.m1.1.2.2.2" stretchy="false">
           )
          </mo>
         </mrow>
         <annotation-xml encoding="MathML-Content" id="A9.T20.1.1.1.m1.1b">
          <ci id="A9.T20.1.1.1.m1.1.1.cmml" xref="A9.T20.1.1.1.m1.1.1">
           ↑
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A9.T20.1.1.1.m1.1c">
          (\uparrow)
         </annotation>
        </semantics>
       </math>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A9.T20.2.2.2" style="padding-left:2.0pt;padding-right:2.0pt;">
       SPL
       <math alttext="(\uparrow)" class="ltx_Math" display="inline" id="A9.T20.2.2.2.m1.1">
        <semantics id="A9.T20.2.2.2.m1.1a">
         <mrow id="A9.T20.2.2.2.m1.1.2.2">
          <mo id="A9.T20.2.2.2.m1.1.2.2.1" stretchy="false">
           (
          </mo>
          <mo id="A9.T20.2.2.2.m1.1.1" lspace="0em" rspace="0em" stretchy="false" xref="A9.T20.2.2.2.m1.1.1.cmml">
           ↑
          </mo>
          <mo id="A9.T20.2.2.2.m1.1.2.2.2" stretchy="false">
           )
          </mo>
         </mrow>
         <annotation-xml encoding="MathML-Content" id="A9.T20.2.2.2.m1.1b">
          <ci id="A9.T20.2.2.2.m1.1.1.cmml" xref="A9.T20.2.2.2.m1.1.1">
           ↑
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A9.T20.2.2.2.m1.1c">
          (\uparrow)
         </annotation>
        </semantics>
       </math>
      </td>
      <td class="ltx_td" id="A9.T20.4.4.5" style="padding-left:2.0pt;padding-right:2.0pt;">
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A9.T20.3.3.3" style="padding-left:2.0pt;padding-right:2.0pt;">
       Success
       <math alttext="(\uparrow)" class="ltx_Math" display="inline" id="A9.T20.3.3.3.m1.1">
        <semantics id="A9.T20.3.3.3.m1.1a">
         <mrow id="A9.T20.3.3.3.m1.1.2.2">
          <mo id="A9.T20.3.3.3.m1.1.2.2.1" stretchy="false">
           (
          </mo>
          <mo id="A9.T20.3.3.3.m1.1.1" lspace="0em" rspace="0em" stretchy="false" xref="A9.T20.3.3.3.m1.1.1.cmml">
           ↑
          </mo>
          <mo id="A9.T20.3.3.3.m1.1.2.2.2" stretchy="false">
           )
          </mo>
         </mrow>
         <annotation-xml encoding="MathML-Content" id="A9.T20.3.3.3.m1.1b">
          <ci id="A9.T20.3.3.3.m1.1.1.cmml" xref="A9.T20.3.3.3.m1.1.1">
           ↑
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A9.T20.3.3.3.m1.1c">
          (\uparrow)
         </annotation>
        </semantics>
       </math>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A9.T20.4.4.4" style="padding-left:2.0pt;padding-right:2.0pt;">
       SPL
       <math alttext="(\uparrow)" class="ltx_Math" display="inline" id="A9.T20.4.4.4.m1.1">
        <semantics id="A9.T20.4.4.4.m1.1a">
         <mrow id="A9.T20.4.4.4.m1.1.2.2">
          <mo id="A9.T20.4.4.4.m1.1.2.2.1" stretchy="false">
           (
          </mo>
          <mo id="A9.T20.4.4.4.m1.1.1" lspace="0em" rspace="0em" stretchy="false" xref="A9.T20.4.4.4.m1.1.1.cmml">
           ↑
          </mo>
          <mo id="A9.T20.4.4.4.m1.1.2.2.2" stretchy="false">
           )
          </mo>
         </mrow>
         <annotation-xml encoding="MathML-Content" id="A9.T20.4.4.4.m1.1b">
          <ci id="A9.T20.4.4.4.m1.1.1.cmml" xref="A9.T20.4.4.4.m1.1.1">
           ↑
          </ci>
         </annotation-xml>
         <annotation encoding="application/x-tex" id="A9.T20.4.4.4.m1.1c">
          (\uparrow)
         </annotation>
        </semantics>
       </math>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T20.4.6">
      <td class="ltx_td ltx_align_center ltx_border_t" id="A9.T20.4.6.1" style="padding-left:2.0pt;padding-right:2.0pt;">
       Habitat-web (shortest)
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A9.T20.4.6.2" style="padding-left:2.0pt;padding-right:2.0pt;">
       4.4
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A9.T20.4.6.3" style="padding-left:2.0pt;padding-right:2.0pt;">
       2.2
      </td>
      <td class="ltx_td ltx_border_t" id="A9.T20.4.6.4" style="padding-left:2.0pt;padding-right:2.0pt;">
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A9.T20.4.6.5" style="padding-left:2.0pt;padding-right:2.0pt;">
       -
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A9.T20.4.6.6" style="padding-left:2.0pt;padding-right:2.0pt;">
       -
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T20.4.7">
      <td class="ltx_td ltx_align_center" id="A9.T20.4.7.1" style="padding-left:2.0pt;padding-right:2.0pt;">
       Habitat-web (70k demo)
      </td>
      <td class="ltx_td ltx_align_center" id="A9.T20.4.7.2" style="padding-left:2.0pt;padding-right:2.0pt;">
       <span class="ltx_text ltx_font_bold" id="A9.T20.4.7.2.1">
        35.4
       </span>
      </td>
      <td class="ltx_td ltx_align_center" id="A9.T20.4.7.3" style="padding-left:2.0pt;padding-right:2.0pt;">
       10.2
      </td>
      <td class="ltx_td" id="A9.T20.4.7.4" style="padding-left:2.0pt;padding-right:2.0pt;">
      </td>
      <td class="ltx_td ltx_align_center" id="A9.T20.4.7.5" style="padding-left:2.0pt;padding-right:2.0pt;">
       -
      </td>
      <td class="ltx_td ltx_align_center" id="A9.T20.4.7.6" style="padding-left:2.0pt;padding-right:2.0pt;">
       -
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T20.4.8">
      <td class="ltx_td ltx_align_center ltx_border_t" id="A9.T20.4.8.1" style="padding-left:2.0pt;padding-right:2.0pt;">
       <span class="ltx_text ltx_font_smallcaps" id="A9.T20.4.8.1.1">
        LEO
       </span>
       (shortest)
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A9.T20.4.8.2" style="padding-left:2.0pt;padding-right:2.0pt;">
       23.1
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A9.T20.4.8.3" style="padding-left:2.0pt;padding-right:2.0pt;">
       <span class="ltx_text ltx_font_bold" id="A9.T20.4.8.3.1">
        15.2
       </span>
      </td>
      <td class="ltx_td ltx_border_t" id="A9.T20.4.8.4" style="padding-left:2.0pt;padding-right:2.0pt;">
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A9.T20.4.8.5" style="padding-left:2.0pt;padding-right:2.0pt;">
       <span class="ltx_text ltx_font_bold" id="A9.T20.4.8.5.1">
        11.1
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_t" id="A9.T20.4.8.6" style="padding-left:2.0pt;padding-right:2.0pt;">
       <span class="ltx_text ltx_font_bold" id="A9.T20.4.8.6.1">
        9.6
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T20.4.9">
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A9.T20.4.9.1" style="padding-left:2.0pt;padding-right:2.0pt;">
       <span class="ltx_text ltx_font_smallcaps" id="A9.T20.4.9.1.1">
        LEO
       </span>
       (70k demo)
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A9.T20.4.9.2" style="padding-left:2.0pt;padding-right:2.0pt;">
       7.1
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A9.T20.4.9.3" style="padding-left:2.0pt;padding-right:2.0pt;">
       5.3
      </td>
      <td class="ltx_td ltx_border_bb" id="A9.T20.4.9.4" style="padding-left:2.0pt;padding-right:2.0pt;">
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A9.T20.4.9.5" style="padding-left:2.0pt;padding-right:2.0pt;">
       8.9
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb" id="A9.T20.4.9.6" style="padding-left:2.0pt;padding-right:2.0pt;">
       8.6
      </td>
     </tr>
    </table>
   </figure>
   <div class="ltx_para ltx_noindent" id="A9.SS1.p3">
    <p class="ltx_p" id="A9.SS1.p3.1">
     The results show that
     <span class="ltx_text ltx_font_smallcaps" id="A9.SS1.p3.1.1">
      LEO
     </span>
     can generalize to novel objects. On the other hand, human demonstrations include more explorations, compared with shortest-path data. Therefore, it will be much harder for agents without a recurrent module (
     <em class="ltx_emph ltx_font_italic" id="A9.SS1.p3.1.2">
      e.g
     </em>
     .
     <span class="ltx_text" id="A9.SS1.p3.1.3">
     </span>
     ,
     <span class="ltx_text ltx_font_smallcaps" id="A9.SS1.p3.1.4">
      LEO
     </span>
     ) to learn from human demonstrations (see
     <a class="ltx_ref" href="#A8.SS2" title="H.2 Embodied Navigation ‣ Appendix H Evaluation Details ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Sec.
      </span>
      <span class="ltx_text ltx_ref_tag">
       H.2
      </span>
     </a>
     ), leading to significantly weaker performances.
    </p>
   </div>
   <div class="ltx_para ltx_noindent" id="A9.SS1.p4">
    <p class="ltx_p" id="A9.SS1.p4.1">
     <span class="ltx_text ltx_font_bold" id="A9.SS1.p4.1.1">
      Qualitative results
     </span>
     .  We provide more qualitative results of robotic manipulation and embodied navigation in the supplementary video.
    </p>
   </div>
  </section>
  <section class="ltx_subsection" id="A9.SS2">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     I.2
    </span>
    Scan2Cap
   </h3>
   <div class="ltx_para ltx_noindent" id="A9.SS2.p1">
    <p class="ltx_p" id="A9.SS2.p1.1">
     We provide additional qualitative results on Scan2Cap validation set in
     <a class="ltx_ref" href="#A9.T21" title="In I.2 Scan2Cap ‣ Appendix I Additional Results ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Tab.
      </span>
      <span class="ltx_text ltx_ref_tag">
       21
      </span>
     </a>
     . The results show that
     <span class="ltx_text ltx_font_smallcaps" id="A9.SS2.p1.1.1">
      LEO
     </span>
     can correctly refer to the queried object and provide accurate descriptions, including spatial relationships with other objects. However,
     <span class="ltx_text ltx_font_smallcaps" id="A9.SS2.p1.1.2">
      LEO
     </span>
     ’s responses are confined to simple formats that lack diversity. How to unlock more flexible responses while maintaining accuracy can be a direction for future research.
    </p>
   </div>
   <figure class="ltx_table" id="A9.T21">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 21:
     </span>
     <span class="ltx_text ltx_font_bold" id="A9.T21.6.1">
      Additional qualitative results on Scan2Cap validation set
     </span>
     .
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="A9.T21.4">
     <tr class="ltx_tr" id="A9.T21.4.5">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A9.T21.4.5.1">
       Scene
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" id="A9.T21.4.5.2">
       <span class="ltx_inline-block ltx_align_top" id="A9.T21.4.5.2.1">
        <span class="ltx_p" id="A9.T21.4.5.2.1.1" style="width:80.0pt;">
         Instruction
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" id="A9.T21.4.5.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T21.4.5.3.1">
        <span class="ltx_p" id="A9.T21.4.5.3.1.1" style="width:80.0pt;">
         Response
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A9.T21.4.5.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T21.4.5.4.1">
        <span class="ltx_p" id="A9.T21.4.5.4.1.1" style="width:100.0pt;">
         Ground Truth
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T21.1.1">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A9.T21.1.1.1">
       <span class="ltx_text" id="A9.T21.1.1.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="110" id="A9.T21.1.1.1.1.g1" src="/html/2311.12871/assets/figs/scan2cap_keyboard.jpg" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T21.1.1.2">
       <span class="ltx_inline-block ltx_align_top" id="A9.T21.1.1.2.1">
        <span class="ltx_p" id="A9.T21.1.1.2.1.1" style="width:80.0pt;">
         Develop a description of the object at the specified position in the 3D backdrop.
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T21.1.1.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T21.1.1.3.1">
        <span class="ltx_p" id="A9.T21.1.1.3.1.1" style="width:80.0pt;">
         This is a black keyboard. It is in front of two monitors.
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.T21.1.1.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T21.1.1.4.1">
        <span class="ltx_p" id="A9.T21.1.1.4.1.1" style="width:100.0pt;">
         The keyboard sits atop the workstation desk. It is located in front of the left-side monitor.
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T21.2.2">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A9.T21.2.2.1">
       <span class="ltx_text" id="A9.T21.2.2.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="97" id="A9.T21.2.2.1.1.g1" src="/html/2311.12871/assets/figs/scan2cap_pillow.jpg" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T21.2.2.2">
       <span class="ltx_inline-block ltx_align_top" id="A9.T21.2.2.2.1">
        <span class="ltx_p" id="A9.T21.2.2.2.1.1" style="width:80.0pt;">
         Focus on the object at the given 3D location and describe it.
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T21.2.2.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T21.2.2.3.1">
        <span class="ltx_p" id="A9.T21.2.2.3.1.1" style="width:80.0pt;">
         This is a white pillow. It is on the couch.
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.T21.2.2.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T21.2.2.4.1">
        <span class="ltx_p" id="A9.T21.2.2.4.1.1" style="width:100.0pt;">
         It is a small pillow located on the couch. You can notice it directly on your left when walking through the door into the room.
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T21.3.3">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A9.T21.3.3.1">
       <span class="ltx_text" id="A9.T21.3.3.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="110" id="A9.T21.3.3.1.1.g1" src="/html/2311.12871/assets/figs/scan2cap_cabinet.jpg" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T21.3.3.2">
       <span class="ltx_inline-block ltx_align_top" id="A9.T21.3.3.2.1">
        <span class="ltx_p" id="A9.T21.3.3.2.1.1" style="width:80.0pt;">
         Provide a clearer description of the object at that specific 3D spot.
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T21.3.3.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T21.3.3.3.1">
        <span class="ltx_p" id="A9.T21.3.3.3.1.1" style="width:80.0pt;">
         This is a white cabinet. It is to the right of a couch.
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.T21.3.3.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T21.3.3.4.1">
        <span class="ltx_p" id="A9.T21.3.3.4.1.1" style="width:100.0pt;">
         This is a white ottoman. It is located to the right of the black couch.
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T21.4.4">
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A9.T21.4.4.1">
       <span class="ltx_text" id="A9.T21.4.4.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="110" id="A9.T21.4.4.1.1.g1" src="/html/2311.12871/assets/figs/scan2cap_door.jpg" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A9.T21.4.4.2">
       <span class="ltx_inline-block ltx_align_top" id="A9.T21.4.4.2.1">
        <span class="ltx_p" id="A9.T21.4.4.2.1.1" style="width:80.0pt;">
         What does the object at the specified position in the 3D visualization look like?
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A9.T21.4.4.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T21.4.4.3.1">
        <span class="ltx_p" id="A9.T21.4.4.3.1.1" style="width:80.0pt;">
         There is a rectangular brown door. It is next to a couch.
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A9.T21.4.4.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T21.4.4.4.1">
        <span class="ltx_p" id="A9.T21.4.4.4.1.1" style="width:100.0pt;">
         There is a door in the middle of the northern wall next to a metal cabinet. The door is shaped like a brown rectangle and as a dark yellow colored doorknob.
        </span>
       </span>
      </td>
     </tr>
    </table>
   </figure>
  </section>
  <section class="ltx_subsection" id="A9.SS3">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     I.3
    </span>
    ScanQA
   </h3>
   <div class="ltx_para ltx_noindent" id="A9.SS3.p1">
    <p class="ltx_p" id="A9.SS3.p1.1">
     We provide additional qualitative results on ScanQA validation set in
     <a class="ltx_ref" href="#A9.T22" title="In I.3 ScanQA ‣ Appendix I Additional Results ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Tab.
      </span>
      <span class="ltx_text ltx_ref_tag">
       22
      </span>
     </a>
     and categorize the responses into several types:
    </p>
    <ul class="ltx_itemize" id="A9.I1">
     <li class="ltx_item" id="A9.I1.i1" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="A9.I1.i1.p1">
       <p class="ltx_p" id="A9.I1.i1.p1.1">
        <span class="ltx_text ltx_font_italic" id="A9.I1.i1.p1.1.1">
         Wrong
        </span>
        . The response is inaccurate and deemed wrong.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i2" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="A9.I1.i2.p1">
       <p class="ltx_p" id="A9.I1.i2.p1.1">
        <span class="ltx_text ltx_font_italic" id="A9.I1.i2.p1.1.1">
         Wrong but reasonable
        </span>
        . The response is deemed wrong but is reasonable to some extent, probably due to ambiguities in the scene. Consider the second case in
        <a class="ltx_ref" href="#A9.T22" title="In I.3 ScanQA ‣ Appendix I Additional Results ‣ An Embodied Generalist Agent in 3D World">
         <span class="ltx_text ltx_ref_tag">
          Tab.
         </span>
         <span class="ltx_text ltx_ref_tag">
          22
         </span>
        </a>
        . There are many objects such as a coat rack, a coat, and a mini fridge-shaped cabinet on the right side of the organizer. Though
        <span class="ltx_text ltx_font_smallcaps" id="A9.I1.i2.p1.1.2">
         LEO
        </span>
        ’s response “mini fridge” does not match the ground truth “coat rack”, it is consistent with the 3D scene layout.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i3" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="A9.I1.i3.p1">
       <p class="ltx_p" id="A9.I1.i3.p1.1">
        <span class="ltx_text ltx_font_italic" id="A9.I1.i3.p1.1.1">
         Wrong but accurate
        </span>
        . The response is accurate according to the scene but is deemed wrong due to imperfect ground truth annotations.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i4" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para" id="A9.I1.i4.p1">
       <p class="ltx_p" id="A9.I1.i4.p1.1">
        <span class="ltx_text ltx_font_italic" id="A9.I1.i4.p1.1.1">
         Correct
        </span>
        . The response is accurate and deemed correct.
       </p>
      </div>
     </li>
     <li class="ltx_item" id="A9.I1.i5" style="list-style-type:none;">
      <span class="ltx_tag ltx_tag_item">
       •
      </span>
      <div class="ltx_para ltx_noindent" id="A9.I1.i5.p1">
       <p class="ltx_p" id="A9.I1.i5.p1.1">
        <span class="ltx_text ltx_font_italic" id="A9.I1.i5.p1.1.1">
         Correct and more accurate
        </span>
        . The response is more accurate than the ground truth annotations.
       </p>
      </div>
     </li>
    </ul>
   </div>
   <figure class="ltx_table" id="A9.T22">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 22:
     </span>
     <span class="ltx_text ltx_font_bold" id="A9.T22.8.1">
      Additional qualitative results on ScanQA validation set
     </span>
     .
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="A9.T22.6">
     <tr class="ltx_tr" id="A9.T22.6.7">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A9.T22.6.7.1">
       Scene
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" id="A9.T22.6.7.2">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.6.7.2.1">
        <span class="ltx_p" id="A9.T22.6.7.2.1.1" style="width:60.0pt;">
         Question
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" id="A9.T22.6.7.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.6.7.3.1">
        <span class="ltx_p" id="A9.T22.6.7.3.1.1" style="width:60.0pt;">
         Response
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" id="A9.T22.6.7.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.6.7.4.1">
        <span class="ltx_p" id="A9.T22.6.7.4.1.1" style="width:80.0pt;">
         Ground Truth
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A9.T22.6.7.5">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.6.7.5.1">
        <span class="ltx_p" id="A9.T22.6.7.5.1.1" style="width:60.0pt;">
         Response Type
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T22.1.1">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A9.T22.1.1.1">
       <span class="ltx_text" id="A9.T22.1.1.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="81" id="A9.T22.1.1.1.1.g1" src="/html/2311.12871/assets/figs/vis_scanqa_2.jpg" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T22.1.1.2">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.1.1.2.1">
        <span class="ltx_p" id="A9.T22.1.1.2.1.1" style="width:60.0pt;">
         What is placed on the black chair out of the three chairs present in the room?
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T22.1.1.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.1.1.3.1">
        <span class="ltx_p" id="A9.T22.1.1.3.1.1" style="width:60.0pt;">
         pillow
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T22.1.1.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.1.1.4.1">
        <span class="ltx_p" id="A9.T22.1.1.4.1.1" style="width:80.0pt;">
         tan jacket, guitar box like object
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.T22.1.1.5">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.1.1.5.1">
        <span class="ltx_p" id="A9.T22.1.1.5.1.1" style="width:60.0pt;">
         <span class="ltx_text ltx_font_italic" id="A9.T22.1.1.5.1.1.1">
          Wrong
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T22.2.2">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A9.T22.2.2.1">
       <span class="ltx_text" id="A9.T22.2.2.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="134" id="A9.T22.2.2.1.1.g1" src="/html/2311.12871/assets/figs/vis_scanqa_1.jpg" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T22.2.2.2">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.2.2.2.1">
        <span class="ltx_p" id="A9.T22.2.2.2.1.1" style="width:60.0pt;">
         What is next to the organizer shelf?
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T22.2.2.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.2.2.3.1">
        <span class="ltx_p" id="A9.T22.2.2.3.1.1" style="width:60.0pt;">
         mini fridge
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T22.2.2.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.2.2.4.1">
        <span class="ltx_p" id="A9.T22.2.2.4.1.1" style="width:80.0pt;">
         coat rack
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.T22.2.2.5">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.2.2.5.1">
        <span class="ltx_p" id="A9.T22.2.2.5.1.1" style="width:60.0pt;">
         <span class="ltx_text ltx_font_italic" id="A9.T22.2.2.5.1.1.1">
          Wrong but reasonable
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T22.3.3">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A9.T22.3.3.1">
       <span class="ltx_text" id="A9.T22.3.3.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="74" id="A9.T22.3.3.1.1.g1" src="/html/2311.12871/assets/figs/vis_scanqa_3.jpg" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T22.3.3.2">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.3.3.2.1">
        <span class="ltx_p" id="A9.T22.3.3.2.1.1" style="width:60.0pt;">
         Where is the dresser located?
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T22.3.3.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.3.3.3.1">
        <span class="ltx_p" id="A9.T22.3.3.3.1.1" style="width:60.0pt;">
         to right of door
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T22.3.3.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.3.3.4.1">
        <span class="ltx_p" id="A9.T22.3.3.4.1.1" style="width:80.0pt;">
         underneath television next to black guitar case and green guitar case, under tv set next to guitar cases
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.T22.3.3.5">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.3.3.5.1">
        <span class="ltx_p" id="A9.T22.3.3.5.1.1" style="width:60.0pt;">
         <span class="ltx_text ltx_font_italic" id="A9.T22.3.3.5.1.1.1">
          Wrong but accurate
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T22.4.4">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A9.T22.4.4.1">
       <span class="ltx_text" id="A9.T22.4.4.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="66" id="A9.T22.4.4.1.1.g1" src="/html/2311.12871/assets/figs/vis_scanqa_4.jpg" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T22.4.4.2">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.4.4.2.1">
        <span class="ltx_p" id="A9.T22.4.4.2.1.1" style="width:60.0pt;">
         What kind of desk is the electric piano on?
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T22.4.4.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.4.4.3.1">
        <span class="ltx_p" id="A9.T22.4.4.3.1.1" style="width:60.0pt;">
         wooden desk
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T22.4.4.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.4.4.4.1">
        <span class="ltx_p" id="A9.T22.4.4.4.1.1" style="width:80.0pt;">
         wooden desk
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.T22.4.4.5">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.4.4.5.1">
        <span class="ltx_p" id="A9.T22.4.4.5.1.1" style="width:60.0pt;">
         <span class="ltx_text ltx_font_italic" id="A9.T22.4.4.5.1.1.1">
          Correct
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T22.5.5">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A9.T22.5.5.1">
       <span class="ltx_text" id="A9.T22.5.5.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="66" id="A9.T22.5.5.1.1.g1" src="/html/2311.12871/assets/figs/vis_scanqa_4.jpg" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T22.5.5.2">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.5.5.2.1">
        <span class="ltx_p" id="A9.T22.5.5.2.1.1" style="width:60.0pt;">
         How many monitor sits on top of the desk?
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T22.5.5.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.5.5.3.1">
        <span class="ltx_p" id="A9.T22.5.5.3.1.1" style="width:60.0pt;">
         2
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T22.5.5.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.5.5.4.1">
        <span class="ltx_p" id="A9.T22.5.5.4.1.1" style="width:80.0pt;">
         2
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.T22.5.5.5">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.5.5.5.1">
        <span class="ltx_p" id="A9.T22.5.5.5.1.1" style="width:60.0pt;">
         <span class="ltx_text ltx_font_italic" id="A9.T22.5.5.5.1.1.1">
          Correct
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T22.6.6">
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A9.T22.6.6.1">
       <span class="ltx_text" id="A9.T22.6.6.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="95" id="A9.T22.6.6.1.1.g1" src="/html/2311.12871/assets/figs/vis_scanqa_6.jpg" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A9.T22.6.6.2">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.6.6.2.1">
        <span class="ltx_p" id="A9.T22.6.6.2.1.1" style="width:60.0pt;">
         What is on the left side of the brown desk?
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A9.T22.6.6.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.6.6.3.1">
        <span class="ltx_p" id="A9.T22.6.6.3.1.1" style="width:60.0pt;">
         black computer monitor
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A9.T22.6.6.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.6.6.4.1">
        <span class="ltx_p" id="A9.T22.6.6.4.1.1" style="width:80.0pt;">
         monitor / computer monitor
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A9.T22.6.6.5">
       <span class="ltx_inline-block ltx_align_top" id="A9.T22.6.6.5.1">
        <span class="ltx_p" id="A9.T22.6.6.5.1.1" style="width:60.0pt;">
         <span class="ltx_text ltx_font_italic" id="A9.T22.6.6.5.1.1.1">
          Correct and more accurate
         </span>
        </span>
       </span>
      </td>
     </tr>
    </table>
   </figure>
  </section>
  <section class="ltx_subsection" id="A9.SS4">
   <h3 class="ltx_title ltx_title_subsection">
    <span class="ltx_tag ltx_tag_subsection">
     I.4
    </span>
    SQA3D
   </h3>
   <div class="ltx_para ltx_noindent" id="A9.SS4.p1">
    <p class="ltx_p" id="A9.SS4.p1.1">
     We provide additional qualitative results on SQA3D test set in
     <a class="ltx_ref" href="#A9.T23" title="In I.4 SQA3D ‣ Appendix I Additional Results ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Tab.
      </span>
      <span class="ltx_text ltx_ref_tag">
       23
      </span>
     </a>
     and follow the aforementioned response types. The embodied reasoning in SQA3D requires the understanding of not only the scene but also the situation of embodiment. In
     <a class="ltx_ref" href="#A9.T23" title="In I.4 SQA3D ‣ Appendix I Additional Results ‣ An Embodied Generalist Agent in 3D World">
      <span class="ltx_text ltx_ref_tag">
       Tab.
      </span>
      <span class="ltx_text ltx_ref_tag">
       23
      </span>
     </a>
     , answering “What am I sitting at?” necessitates that
     <span class="ltx_text ltx_font_smallcaps" id="A9.SS4.p1.1.1">
      LEO
     </span>
     accurately identifies the objects at its current location. And the response to “How many beds are in front of me?” indicates that
     <span class="ltx_text ltx_font_smallcaps" id="A9.SS4.p1.1.2">
      LEO
     </span>
     can reason based on the understanding of its orientation.
    </p>
   </div>
   <figure class="ltx_table" id="A9.T23">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 23:
     </span>
     <span class="ltx_text ltx_font_bold" id="A9.T23.7.1">
      Additional qualitative results on SQA3D test set
     </span>
     .
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="A9.T23.5">
     <tr class="ltx_tr" id="A9.T23.5.6">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A9.T23.5.6.1">
       Scene
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" id="A9.T23.5.6.2">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.5.6.2.1">
        <span class="ltx_p" id="A9.T23.5.6.2.1.1" style="width:60.0pt;">
         Question
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" id="A9.T23.5.6.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.5.6.3.1">
        <span class="ltx_p" id="A9.T23.5.6.3.1.1" style="width:60.0pt;">
         Response
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" id="A9.T23.5.6.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.5.6.4.1">
        <span class="ltx_p" id="A9.T23.5.6.4.1.1" style="width:80.0pt;">
         Ground Truth
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A9.T23.5.6.5">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.5.6.5.1">
        <span class="ltx_p" id="A9.T23.5.6.5.1.1" style="width:60.0pt;">
         Response Type
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T23.1.1">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A9.T23.1.1.1">
       <span class="ltx_text" id="A9.T23.1.1.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="69" id="A9.T23.1.1.1.1.g1" src="/html/2311.12871/assets/figs/vis_sqa_2.jpg" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T23.1.1.2">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.1.1.2.1">
        <span class="ltx_p" id="A9.T23.1.1.2.1.1" style="width:60.0pt;">
         What is the only orange object on my left side?
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T23.1.1.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.1.1.3.1">
        <span class="ltx_p" id="A9.T23.1.1.3.1.1" style="width:60.0pt;">
         backpack
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T23.1.1.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.1.1.4.1">
        <span class="ltx_p" id="A9.T23.1.1.4.1.1" style="width:80.0pt;">
         jacket
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.T23.1.1.5">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.1.1.5.1">
        <span class="ltx_p" id="A9.T23.1.1.5.1.1" style="width:60.0pt;">
         <span class="ltx_text ltx_font_italic" id="A9.T23.1.1.5.1.1.1">
          Wrong
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T23.2.2">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A9.T23.2.2.1">
       <span class="ltx_text" id="A9.T23.2.2.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="71" id="A9.T23.2.2.1.1.g1" src="/html/2311.12871/assets/figs/vis_sqa_4.jpg" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T23.2.2.2">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.2.2.2.1">
        <span class="ltx_p" id="A9.T23.2.2.2.1.1" style="width:60.0pt;">
         Is there anything on the desk?
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T23.2.2.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.2.2.3.1">
        <span class="ltx_p" id="A9.T23.2.2.3.1.1" style="width:60.0pt;">
         yes
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T23.2.2.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.2.2.4.1">
        <span class="ltx_p" id="A9.T23.2.2.4.1.1" style="width:80.0pt;">
         laptop
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.T23.2.2.5">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.2.2.5.1">
        <span class="ltx_p" id="A9.T23.2.2.5.1.1" style="width:60.0pt;">
         <span class="ltx_text ltx_font_italic" id="A9.T23.2.2.5.1.1.1">
          Wrong but accurate
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T23.3.3">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A9.T23.3.3.1">
       <span class="ltx_text" id="A9.T23.3.3.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="88" id="A9.T23.3.3.1.1.g1" src="/html/2311.12871/assets/figs/vis_sqa_1.jpg" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T23.3.3.2">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.3.3.2.1">
        <span class="ltx_p" id="A9.T23.3.3.2.1.1" style="width:60.0pt;">
         What type of bed is the one on the right?
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T23.3.3.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.3.3.3.1">
        <span class="ltx_p" id="A9.T23.3.3.3.1.1" style="width:60.0pt;">
         loft bed
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T23.3.3.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.3.3.4.1">
        <span class="ltx_p" id="A9.T23.3.3.4.1.1" style="width:80.0pt;">
         loft bed
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.T23.3.3.5">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.3.3.5.1">
        <span class="ltx_p" id="A9.T23.3.3.5.1.1" style="width:60.0pt;">
         <span class="ltx_text ltx_font_italic" id="A9.T23.3.3.5.1.1.1">
          Correct
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T23.4.4">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A9.T23.4.4.1">
       <span class="ltx_text" id="A9.T23.4.4.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="71" id="A9.T23.4.4.1.1.g1" src="/html/2311.12871/assets/figs/vis_sqa_4.jpg" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T23.4.4.2">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.4.4.2.1">
        <span class="ltx_p" id="A9.T23.4.4.2.1.1" style="width:60.0pt;">
         What am I sitting at?
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T23.4.4.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.4.4.3.1">
        <span class="ltx_p" id="A9.T23.4.4.3.1.1" style="width:60.0pt;">
         desk
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T23.4.4.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.4.4.4.1">
        <span class="ltx_p" id="A9.T23.4.4.4.1.1" style="width:80.0pt;">
         desk
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.T23.4.4.5">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.4.4.5.1">
        <span class="ltx_p" id="A9.T23.4.4.5.1.1" style="width:60.0pt;">
         <span class="ltx_text ltx_font_italic" id="A9.T23.4.4.5.1.1.1">
          Correct
         </span>
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T23.5.5">
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A9.T23.5.5.1">
       <span class="ltx_text" id="A9.T23.5.5.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="74" id="A9.T23.5.5.1.1.g1" src="/html/2311.12871/assets/figs/vis_sqa_5.jpg" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A9.T23.5.5.2">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.5.5.2.1">
        <span class="ltx_p" id="A9.T23.5.5.2.1.1" style="width:60.0pt;">
         How many beds are in front of me?
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A9.T23.5.5.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.5.5.3.1">
        <span class="ltx_p" id="A9.T23.5.5.3.1.1" style="width:60.0pt;">
         one
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A9.T23.5.5.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.5.5.4.1">
        <span class="ltx_p" id="A9.T23.5.5.4.1.1" style="width:80.0pt;">
         one
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A9.T23.5.5.5">
       <span class="ltx_inline-block ltx_align_top" id="A9.T23.5.5.5.1">
        <span class="ltx_p" id="A9.T23.5.5.5.1.1" style="width:60.0pt;">
         <span class="ltx_text ltx_font_italic" id="A9.T23.5.5.5.1.1.1">
          Correct
         </span>
        </span>
       </span>
      </td>
     </tr>
    </table>
   </figure>
   <figure class="ltx_table" id="A9.T24">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 24:
     </span>
     <span class="ltx_text ltx_font_bold" id="A9.T24.7.1">
      Examples from our datasets
     </span>
     . We provide the tasks, 2D images (optional), 3D point clouds, and instructions as the input of
     <span class="ltx_text ltx_font_smallcaps" id="A9.T24.8.2">
      LEO
     </span>
     , as well as the expected responses of
     <span class="ltx_text ltx_font_smallcaps" id="A9.T24.9.3">
      LEO
     </span>
     .
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="A9.T24.3">
     <tr class="ltx_tr" id="A9.T24.3.4">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A9.T24.3.4.1">
       Dataset &amp; Task
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A9.T24.3.4.2">
       2D &amp; 3D input
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" id="A9.T24.3.4.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T24.3.4.3.1">
        <span class="ltx_p" id="A9.T24.3.4.3.1.1" style="width:60.0pt;">
         Instruction
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A9.T24.3.4.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T24.3.4.4.1">
        <span class="ltx_p" id="A9.T24.3.4.4.1.1" style="width:120.0pt;">
         Response
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T24.1.1">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A9.T24.1.1.2">
       <span class="ltx_text" id="A9.T24.1.1.2.1">
       </span>
       <span class="ltx_text" id="A9.T24.1.1.2.2">
        <span class="ltx_tabular ltx_align_middle" id="A9.T24.1.1.2.2.1">
         <span class="ltx_tr" id="A9.T24.1.1.2.2.1.1">
          <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T24.1.1.2.2.1.1.1">
           <span class="ltx_text ltx_font_smallcaps" id="A9.T24.1.1.2.2.1.1.1.1">
            LEO
           </span>
           -align
          </span>
         </span>
         <span class="ltx_tr" id="A9.T24.1.1.2.2.1.2">
          <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T24.1.1.2.2.1.2.1">
           object captioning
          </span>
         </span>
        </span>
       </span>
       <span class="ltx_text" id="A9.T24.1.1.2.3">
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A9.T24.1.1.1">
       <span class="ltx_text" id="A9.T24.1.1.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="74" id="A9.T24.1.1.1.1.g1" src="/html/2311.12871/assets/figs/cap3d_data.jpg" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T24.1.1.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T24.1.1.3.1">
        <span class="ltx_p" id="A9.T24.1.1.3.1.1" style="width:60.0pt;">
         USER: Explain the object at the pinpointed location in the 3D setting. ASSISTANT:
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.T24.1.1.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T24.1.1.4.1">
        <span class="ltx_p" id="A9.T24.1.1.4.1.1" style="width:120.0pt;">
         a yellow metal cage with a fence around it.
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T24.2.2">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A9.T24.2.2.2">
       <span class="ltx_text" id="A9.T24.2.2.2.1">
       </span>
       <span class="ltx_text" id="A9.T24.2.2.2.2">
        <span class="ltx_tabular ltx_align_middle" id="A9.T24.2.2.2.2.1">
         <span class="ltx_tr" id="A9.T24.2.2.2.2.1.1">
          <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T24.2.2.2.2.1.1.1">
           <span class="ltx_text ltx_font_smallcaps" id="A9.T24.2.2.2.2.1.1.1.1">
            LEO
           </span>
           -align
          </span>
         </span>
         <span class="ltx_tr" id="A9.T24.2.2.2.2.1.2">
          <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T24.2.2.2.2.1.2.1">
           object referring
          </span>
         </span>
        </span>
       </span>
       <span class="ltx_text" id="A9.T24.2.2.2.3">
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A9.T24.2.2.1">
       <span class="ltx_text" id="A9.T24.2.2.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="103" id="A9.T24.2.2.1.1.g1" src="/html/2311.12871/assets/figs/obj_refer_3d.jpg" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T24.2.2.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T24.2.2.3.1">
        <span class="ltx_p" id="A9.T24.2.2.3.1.1" style="width:60.0pt;">
         USER: Give me a snapshot of the object at the chosen 3D location. ASSISTANT:
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.T24.2.2.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T24.2.2.4.1">
        <span class="ltx_p" id="A9.T24.2.2.4.1.1" style="width:120.0pt;">
         find the office chair that is near the copier
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T24.3.3">
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A9.T24.3.3.2">
       <span class="ltx_text" id="A9.T24.3.3.2.1">
       </span>
       <span class="ltx_text" id="A9.T24.3.3.2.2">
        <span class="ltx_tabular ltx_align_middle" id="A9.T24.3.3.2.2.1">
         <span class="ltx_tr" id="A9.T24.3.3.2.2.1.1">
          <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T24.3.3.2.2.1.1.1">
           <span class="ltx_text ltx_font_smallcaps" id="A9.T24.3.3.2.2.1.1.1.1">
            LEO
           </span>
           -align
          </span>
         </span>
         <span class="ltx_tr" id="A9.T24.3.3.2.2.1.2">
          <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T24.3.3.2.2.1.2.1">
           scene captioning
          </span>
         </span>
        </span>
       </span>
       <span class="ltx_text" id="A9.T24.3.3.2.3">
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A9.T24.3.3.1">
       <span class="ltx_text" id="A9.T24.3.3.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="87" id="A9.T24.3.3.1.1.g1" src="/html/2311.12871/assets/figs/scene_cap_data.png" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A9.T24.3.3.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T24.3.3.3.1">
        <span class="ltx_p" id="A9.T24.3.3.3.1.1" style="width:60.0pt;">
         USER: Relay a brief summary of this scene’s elements. ASSISTANT:
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A9.T24.3.3.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T24.3.3.4.1">
        <span class="ltx_p" id="A9.T24.3.3.4.1.1" style="width:120.0pt;">
         In this scene, there is a gray flat picture hanging on the wall, standing in front of a windowsill. There is also a rectangular white padded pillow lying on the bed, close to a big rectangular white padded pillow. The room has a white architectural wall and a flat overhead ceiling. The bed is tidy and white, located in front of a narrow tall commode. The curtains are hanging on the wall. The room has a calm and comfortable atmosphere, suitable for relaxation and sleep.
        </span>
       </span>
      </td>
     </tr>
    </table>
   </figure>
   <figure class="ltx_table" id="A9.T25">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 25:
     </span>
     <span class="ltx_text ltx_font_bold" id="A9.T25.6.1">
      Examples from our datasets
     </span>
     . Continued.
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="A9.T25.4">
     <tr class="ltx_tr" id="A9.T25.1.1">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A9.T25.1.1.2">
       <span class="ltx_text" id="A9.T25.1.1.2.1">
       </span>
       <span class="ltx_text" id="A9.T25.1.1.2.2">
        <span class="ltx_tabular ltx_align_middle" id="A9.T25.1.1.2.2.1">
         <span class="ltx_tr" id="A9.T25.1.1.2.2.1.1">
          <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T25.1.1.2.2.1.1.1">
           <span class="ltx_text ltx_font_smallcaps" id="A9.T25.1.1.2.2.1.1.1.1">
            LEO
           </span>
           -instruct
          </span>
         </span>
         <span class="ltx_tr" id="A9.T25.1.1.2.2.1.2">
          <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T25.1.1.2.2.1.2.1">
           3D captioning
          </span>
         </span>
        </span>
       </span>
       <span class="ltx_text" id="A9.T25.1.1.2.3">
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A9.T25.1.1.1">
       <span class="ltx_text" id="A9.T25.1.1.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="110" id="A9.T25.1.1.1.1.g1" src="/html/2311.12871/assets/figs/scan2cap_door.jpg" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" id="A9.T25.1.1.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T25.1.1.3.1">
        <span class="ltx_p" id="A9.T25.1.1.3.1.1" style="width:80.0pt;">
         USER: What does the object at the specified position in the 3D visualization look like? ASSISTANT:
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A9.T25.1.1.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T25.1.1.4.1">
        <span class="ltx_p" id="A9.T25.1.1.4.1.1" style="width:100.0pt;">
         there is a door in the middle of the northern wall next to a metal cabinet. the door is shaped like a brown rectangle and as a dark yellow colored doorknob.
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T25.2.2">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A9.T25.2.2.2">
       <span class="ltx_text" id="A9.T25.2.2.2.1">
       </span>
       <span class="ltx_text" id="A9.T25.2.2.2.2">
        <span class="ltx_tabular ltx_align_middle" id="A9.T25.2.2.2.2.1">
         <span class="ltx_tr" id="A9.T25.2.2.2.2.1.1">
          <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T25.2.2.2.2.1.1.1">
           <span class="ltx_text ltx_font_smallcaps" id="A9.T25.2.2.2.2.1.1.1.1">
            LEO
           </span>
           -instruct
          </span>
         </span>
         <span class="ltx_tr" id="A9.T25.2.2.2.2.1.2">
          <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T25.2.2.2.2.1.2.1">
           3D QA
          </span>
         </span>
        </span>
       </span>
       <span class="ltx_text" id="A9.T25.2.2.2.3">
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A9.T25.2.2.1">
       <span class="ltx_text" id="A9.T25.2.2.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="99" id="A9.T25.2.2.1.1.g1" src="/html/2311.12871/assets/figs/qa_caption_3d.jpg" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T25.2.2.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T25.2.2.3.1">
        <span class="ltx_p" id="A9.T25.2.2.3.1.1" style="width:80.0pt;">
         USER: What is in the right corner of room by curtains? ASSISTANT:
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.T25.2.2.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T25.2.2.4.1">
        <span class="ltx_p" id="A9.T25.2.2.4.1.1" style="width:100.0pt;">
         brown cabinet with tv sitting in it
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T25.3.3">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A9.T25.3.3.2">
       <span class="ltx_text" id="A9.T25.3.3.2.1">
       </span>
       <span class="ltx_text" id="A9.T25.3.3.2.2">
        <span class="ltx_tabular ltx_align_middle" id="A9.T25.3.3.2.2.1">
         <span class="ltx_tr" id="A9.T25.3.3.2.2.1.1">
          <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T25.3.3.2.2.1.1.1">
           <span class="ltx_text ltx_font_smallcaps" id="A9.T25.3.3.2.2.1.1.1.1">
            LEO
           </span>
           -instruct
          </span>
         </span>
         <span class="ltx_tr" id="A9.T25.3.3.2.2.1.2">
          <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T25.3.3.2.2.1.2.1">
           3D dialogue
          </span>
         </span>
        </span>
       </span>
       <span class="ltx_text" id="A9.T25.3.3.2.3">
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="A9.T25.3.3.1">
       <span class="ltx_text" id="A9.T25.3.3.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="69" id="A9.T25.3.3.1.1.g1" src="/html/2311.12871/assets/figs/3rdialog_data.jpg" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t" id="A9.T25.3.3.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T25.3.3.3.1">
        <span class="ltx_p" id="A9.T25.3.3.3.1.1" style="width:80.0pt;">
         USER: I’m redecorating my living room. Can you give me some suggestions on how to arrange the furniture?
        </span>
        <span class="ltx_p" id="A9.T25.3.3.3.1.2">
         ASSISTANT: Of course! I’d be happy to help. What furniture do you have in your living room?
        </span>
        <span class="ltx_p" id="A9.T25.3.3.3.1.3">
         USER: I have a sofa, a table, a chair, and a couch table. ASSISTANT:
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A9.T25.3.3.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T25.3.3.4.1">
        <span class="ltx_p" id="A9.T25.3.3.4.1.1" style="width:100.0pt;">
         Great! Here’s a suggestion: you can place the sofa against the wall, with the table in front of it. The chair can be placed to the right of the table, and the couch table can be placed to the right of the chair. This arrangement creates a cozy seating area.
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T25.4.4">
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A9.T25.4.4.2">
       <span class="ltx_text" id="A9.T25.4.4.2.1">
       </span>
       <span class="ltx_text" id="A9.T25.4.4.2.2">
        <span class="ltx_tabular ltx_align_middle" id="A9.T25.4.4.2.2.1">
         <span class="ltx_tr" id="A9.T25.4.4.2.2.1.1">
          <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T25.4.4.2.2.1.1.1">
           <span class="ltx_text ltx_font_smallcaps" id="A9.T25.4.4.2.2.1.1.1.1">
            LEO
           </span>
           -instruct
          </span>
         </span>
         <span class="ltx_tr" id="A9.T25.4.4.2.2.1.2">
          <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T25.4.4.2.2.1.2.1">
           task planning
          </span>
         </span>
        </span>
       </span>
       <span class="ltx_text" id="A9.T25.4.4.2.3">
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A9.T25.4.4.1">
       <span class="ltx_text" id="A9.T25.4.4.1.1" style="position:relative; bottom:-10.0pt;">
        <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="97" id="A9.T25.4.4.1.1.g1" src="/html/2311.12871/assets/figs/3rplan_data.jpg" width="110"/>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A9.T25.4.4.3">
       <span class="ltx_inline-block ltx_align_top" id="A9.T25.4.4.3.1">
        <span class="ltx_p" id="A9.T25.4.4.3.1.1" style="width:80.0pt;">
         USER: Develop a plan for this: Arrange and embellish the family room. ASSISTANT:
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A9.T25.4.4.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T25.4.4.4.1">
        <span class="ltx_p" id="A9.T25.4.4.4.1.1" style="width:100.0pt;">
         1. Arrange and fluff the cushions and pillows on the armchair.
        </span>
        <span class="ltx_p" id="A9.T25.4.4.4.1.2">
         2. Place decorations, such as figurines or vases, on the cabinet or shelf.
        </span>
        <span class="ltx_p" id="A9.T25.4.4.4.1.3">
         3. Place hygiene products, such as wipes or lotions, on the commode.
        </span>
        <span class="ltx_p" id="A9.T25.4.4.4.1.4">
         4. Turn on the lights and adjust their brightness if needed.
        </span>
        <span class="ltx_p" id="A9.T25.4.4.4.1.5">
         5. Arrange diapers in a designated storage area.
        </span>
        <span class="ltx_p" id="A9.T25.4.4.4.1.6">
         6. Place a blanket or pillow on the armchair for added comfort.
        </span>
        <span class="ltx_p" id="A9.T25.4.4.4.1.7">
         7. Adjust the festoon or other decorative elements if desired.
        </span>
       </span>
      </td>
     </tr>
    </table>
   </figure>
   <figure class="ltx_table" id="A9.T26">
    <figcaption class="ltx_caption ltx_centering">
     <span class="ltx_tag ltx_tag_table">
      Table 26:
     </span>
     <span class="ltx_text ltx_font_bold" id="A9.T26.6.1">
      Examples from our datasets
     </span>
     . Continued.
    </figcaption>
    <table class="ltx_tabular ltx_centering ltx_align_middle" id="A9.T26.4">
     <tr class="ltx_tr" id="A9.T26.2.2">
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A9.T26.2.2.3">
       <span class="ltx_text" id="A9.T26.2.2.3.1">
       </span>
       <span class="ltx_text" id="A9.T26.2.2.3.2">
        <span class="ltx_tabular ltx_align_middle" id="A9.T26.2.2.3.2.1">
         <span class="ltx_tr" id="A9.T26.2.2.3.2.1.1">
          <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T26.2.2.3.2.1.1.1">
           <span class="ltx_text ltx_font_smallcaps" id="A9.T26.2.2.3.2.1.1.1.1">
            LEO
           </span>
           -instruct
          </span>
         </span>
         <span class="ltx_tr" id="A9.T26.2.2.3.2.1.2">
          <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T26.2.2.3.2.1.2.1">
           embodied navigation
          </span>
         </span>
        </span>
       </span>
       <span class="ltx_text" id="A9.T26.2.2.3.3">
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" id="A9.T26.2.2.2">
       <span class="ltx_text" id="A9.T26.2.2.2.2" style="position:relative; bottom:-10.0pt;">
        <span class="ltx_text" id="A9.T26.2.2.2.2.3">
        </span>
        <span class="ltx_text" id="A9.T26.2.2.2.2.2">
         <span class="ltx_tabular ltx_align_middle" id="A9.T26.2.2.2.2.2.2">
          <span class="ltx_tr" id="A9.T26.1.1.1.1.1.1.1">
           <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T26.1.1.1.1.1.1.1.1">
            <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="110" id="A9.T26.1.1.1.1.1.1.1.1.g1" src="/html/2311.12871/assets/figs/mp3d_objnav_2d.png" width="110"/>
           </span>
          </span>
          <span class="ltx_tr" id="A9.T26.2.2.2.2.2.2.2">
           <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T26.2.2.2.2.2.2.2.1">
            <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="71" id="A9.T26.2.2.2.2.2.2.2.1.g1" src="/html/2311.12871/assets/figs/mp3d_objnav_3d.jpg" width="110"/>
           </span>
          </span>
         </span>
        </span>
        <span class="ltx_text" id="A9.T26.2.2.2.2.4">
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_tt" id="A9.T26.2.2.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T26.2.2.4.1">
        <span class="ltx_p" id="A9.T26.2.2.4.1.1" style="width:80.0pt;">
         USER: The task is navigation. Your goal is to find counter by moving around in the scene. Past actions: &lt;31999&gt; &lt;31999&gt; &lt;31999&gt; &lt;31999&gt;. ASSISTANT:
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" id="A9.T26.2.2.5">
       <span class="ltx_inline-block ltx_align_top" id="A9.T26.2.2.5.1">
        <span class="ltx_p" id="A9.T26.2.2.5.1.1" style="width:120.0pt;">
         &lt;31996&gt;
        </span>
       </span>
      </td>
     </tr>
     <tr class="ltx_tr" id="A9.T26.4.4">
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A9.T26.4.4.3">
       <span class="ltx_text" id="A9.T26.4.4.3.1">
       </span>
       <span class="ltx_text" id="A9.T26.4.4.3.2">
        <span class="ltx_tabular ltx_align_middle" id="A9.T26.4.4.3.2.1">
         <span class="ltx_tr" id="A9.T26.4.4.3.2.1.1">
          <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T26.4.4.3.2.1.1.1">
           <span class="ltx_text ltx_font_smallcaps" id="A9.T26.4.4.3.2.1.1.1.1">
            LEO
           </span>
           -instruct
          </span>
         </span>
         <span class="ltx_tr" id="A9.T26.4.4.3.2.1.2">
          <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T26.4.4.3.2.1.2.1">
           robotic manipulation
          </span>
         </span>
        </span>
       </span>
       <span class="ltx_text" id="A9.T26.4.4.3.3">
       </span>
      </td>
      <td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r ltx_border_t" id="A9.T26.4.4.2">
       <span class="ltx_text" id="A9.T26.4.4.2.2" style="position:relative; bottom:-10.0pt;">
        <span class="ltx_text" id="A9.T26.4.4.2.2.3">
        </span>
        <span class="ltx_text" id="A9.T26.4.4.2.2.2">
         <span class="ltx_tabular ltx_align_middle" id="A9.T26.4.4.2.2.2.2">
          <span class="ltx_tr" id="A9.T26.3.3.1.1.1.1.1">
           <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T26.3.3.1.1.1.1.1.1">
            <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_square" height="110" id="A9.T26.3.3.1.1.1.1.1.1.g1" src="/html/2311.12871/assets/figs/cliport_2d.png" width="110"/>
           </span>
          </span>
          <span class="ltx_tr" id="A9.T26.4.4.2.2.2.2.2">
           <span class="ltx_td ltx_nopad_r ltx_align_center" id="A9.T26.4.4.2.2.2.2.2.1">
            <img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="86" id="A9.T26.4.4.2.2.2.2.2.1.g1" src="/html/2311.12871/assets/figs/cliport_3d.jpg" width="110"/>
           </span>
          </span>
         </span>
        </span>
        <span class="ltx_text" id="A9.T26.4.4.2.2.4">
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_r ltx_border_t" id="A9.T26.4.4.4">
       <span class="ltx_inline-block ltx_align_top" id="A9.T26.4.4.4.1">
        <span class="ltx_p" id="A9.T26.4.4.4.1.1" style="width:80.0pt;">
         USER: The task is manipulation. Your goal is to put the blue blocks in a green bowl. Past actions: &lt;31991&gt; &lt;31671&gt; &lt;31511&gt; &lt;31991&gt; &lt;31671&gt; &lt;31511&gt; &lt;31991&gt; &lt;31671&gt; &lt;31511&gt; &lt;31991&gt; &lt;31671&gt; &lt;31511&gt; &lt;31991&gt; &lt;31671&gt; &lt;31511&gt; &lt;31991&gt; &lt;31671&gt; &lt;31511&gt; &lt;31991&gt; &lt;31671&gt; &lt;31511&gt; &lt;31991&gt; &lt;31671&gt; &lt;31511&gt;. ASSISTANT:
        </span>
       </span>
      </td>
      <td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb ltx_border_t" id="A9.T26.4.4.5">
       <span class="ltx_inline-block ltx_align_top" id="A9.T26.4.4.5.1">
        <span class="ltx_p" id="A9.T26.4.4.5.1.1" style="width:120.0pt;">
         &lt;31748&gt; &lt;31644&gt; &lt;31511&gt; &lt;31736&gt; &lt;31595&gt; &lt;31500&gt;
        </span>
       </span>
      </td>
     </tr>
    </table>
   </figure>
   <div class="ltx_pagination ltx_role_newpage">
   </div>
  </section>
 </section>
</article>
