<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2308.09948] Bamboo: Boosting Training Efficiency for Real-Time Video Streaming via Online Grouped Federated Transfer Learning</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Bamboo: Boosting Training Efficiency for Real-Time Video Streaming via Online Grouped Federated Transfer Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Bamboo: Boosting Training Efficiency for Real-Time Video Streaming via Online Grouped Federated Transfer Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2308.09948">

<!--Generated on Wed Feb 28 12:40:09 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Bamboo: Boosting Training Efficiency for Real-Time Video Streaming via Online Grouped Federated Transfer Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Qianyuan Zheng
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">Nanjing University</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_city">Nanjing</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_country">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:qianyuanzheng@smail.nju.edu.cn">qianyuanzheng@smail.nju.edu.cn</a>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hao Chen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id4.1.id1" class="ltx_text ltx_affiliation_institution">Nanjing University</span><span id="id5.2.id2" class="ltx_text ltx_affiliation_city">Nanjing</span><span id="id6.3.id3" class="ltx_text ltx_affiliation_country">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:chenhao1210@nju.edu.cn">chenhao1210@nju.edu.cn</a>
</span></span></span>
<span class="ltx_author_before">Â andÂ </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zhan Ma
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id7.1.id1" class="ltx_text ltx_affiliation_institution">Nanjing University</span><span id="id8.2.id2" class="ltx_text ltx_affiliation_city">Nanjing</span><span id="id9.3.id3" class="ltx_text ltx_affiliation_country">China</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:mazhan@nju.edu.cn">mazhan@nju.edu.cn</a>
</span></span></span>
</div>
<div class="ltx_dates">(2023)</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">journalyear: </span>2023</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_copyright"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">copyright: </span>acmlicensed</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">conference: </span>7th Asia-Pacific Workshop on Networking; June 29â€“30, 2023; Hong Kong, China</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_booktitle"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">booktitle: </span>7th Asia-Pacific Workshop on Networking (APNET 2023), June 29â€“30, 2023, Hong Kong, China</span></span></span><span id="id5" class="ltx_note ltx_note_frontmatter ltx_role_price"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">price: </span>15.00</span></span></span><span id="id6" class="ltx_note ltx_note_frontmatter ltx_role_doi"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">doi: </span>10.1145/3600061.3600069</span></span></span><span id="id7" class="ltx_note ltx_note_frontmatter ltx_role_isbn"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">isbn: </span>979-8-4007-0782-7/23/06</span></span></span><span id="id8" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Information systemsÂ Multimedia streaming</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Recently, learning-based bitrate adaptation algorithms have emerged, eliminating the reliance on handcrafted rules. For example, they utilize deep reinforcement learning (RL) to train their learning agents for the generation of proper bitrate adaptation policies in a simple simulation environment.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Existing works primarily involve offline and online learning methods. Most of them are limited to the offline mode, applying the â€œlearning offline, running onlineâ€ strategyÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite>, which inevitably suffers from the simulation-to-reality gap.
Compared with offline learning, online learning supports the training along with video streaming service, continuously refining RL models in response to new environments instead of relying on pre-trained models. Although online learning can better adapt to dynamic scenes, it faces the slow training convergence challenge. On the one hand, acquiring the training data is relatively slow as environmental observations are not available for collection until the completion of a video streaming session. In this case, only one actual learning agent can be used for online learning at a time. On the other hand, it is impractical to wait for the online model to be fully trained before making decisions, considering that a real-time video streaming session enforces the prompt responseÂ <cite class="ltx_cite ltx_citemacro_citep">(rep, <a href="#bib.bib2" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To this end, this paper proposes <span id="S1.p3.1.1" class="ltx_text ltx_font_sansserif">Bamboo</span>, a novel online grouped federated transfer learning framework for real-time video streaming to boost training efficiency. <span id="S1.p3.1.2" class="ltx_text ltx_font_sansserif">Bamboo</span> utilizes user grouping for intra-group federated learning and mitigates RLâ€™s trial-and-error impacts through online transfer. As a result, <span id="S1.p3.1.3" class="ltx_text ltx_font_sansserif">Bamboo</span> can complete the online training within a userâ€™s real-time video session.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">We implement <span id="S1.p4.1.1" class="ltx_text ltx_font_sansserif">Bamboo</span> on a WebRTC-based real-time video conferencing testbed<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We develop the testbed based on an open-source WebRTC framework which is available at https://github.com/yuanrongxi/razor.</span></span></span> which uses the Linux traffic control (TC) tool to control the network condition. Our experimental results show that <span id="S1.p4.1.2" class="ltx_text ltx_font_sansserif">Bamboo</span> remarkably improves online training efficiency by up to 302% compared to other reinforcement learning algorithms across various network conditions while ensuring the quality of experience (QoE) of real-time video streaming.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Bamboo Design</h2>

<figure id="S2.F1" class="ltx_figure"><img src="/html/2308.09948/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="438" height="326" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span><span id="S2.F1.2.1" class="ltx_text ltx_font_sansserif">Bamboo</span> utilizes the discriminator to group users and then performs grouped federated learning within each group. Users conduct online transfer learning.</figcaption>
</figure>
<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">FigureÂ <a href="#S2.F1" title="Figure 1 â€£ 2. Bamboo Design â€£ Bamboo: Boosting Training Efficiency for Real-Time Video Streaming via Online Grouped Federated Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> gives an overview of <span id="S2.p1.1.1" class="ltx_text ltx_font_sansserif">Bamboo</span>. We first design a dynamic network condition discriminator to identify each userâ€™s network type and transportation mode. Especially, the network type (e.g., 3G, 4G, and WiFi) can be directly obtained from internet service providers (ISP)Â <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>)</cite>, and the transportation mode (e.g., car, bus, ferry, and train) can be detected using mobile sensors (e.g., GPS, accelerometers or microphones)Â <cite class="ltx_cite ltx_citemacro_citep">(Wang and Jiang, <a href="#bib.bib8" title="" class="ltx_ref">2022</a>)</cite>. Users are classified into 12 groups (labeled as <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S2.p1.1.m1.1a"><mi id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><ci id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">G</annotation></semantics></math>, which can be extended to the more general group classification) as depicted in TableÂ <a href="#S2.T1" title="Table 1 â€£ 2. Bamboo Design â€£ Bamboo: Boosting Training Efficiency for Real-Time Video Streaming via Online Grouped Federated Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Users within the same group engage in intra-group federated learning.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Intra-Group Federated Learning.</span> Without loss of generality, we assume two users and one central server are in one group, which can be extended to more general cases. The framework primarily comprises four procedures. Firstly, offline training involves training a well-generalized fixed neural network model using extensive datasets in a simulator, which is then deployed on the central server. Secondly, the pre-trained offline model is distributed to users, enabling them to train their own models using local network conditions. Thirdly, each user locally updates the model parameters and periodically shares them with the central server. The central server aggregates these parameters to construct an aggregated global model of the group. Finally, users can train personalized models by incorporating the central server model with their own previous models. The aggregated global model undergoes iterative updates through interactive exchanges with the users in a cyclic iterative process. This accelerates batch writing of user data and facilitates RL model training within the same group.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1. </span><span id="S2.T1.14.1" class="ltx_text ltx_font_sansserif">Bamboo</span> classifies network conditions into 12 groups.</figcaption>
<table id="S2.T1.12" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.3.3" class="ltx_tr">
<th id="S2.T1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t">
<math id="S2.T1.1.1.1.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S2.T1.1.1.1.m1.1a"><mi id="S2.T1.1.1.1.m1.1.1" xref="S2.T1.1.1.1.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S2.T1.1.1.1.m1.1b"><ci id="S2.T1.1.1.1.m1.1.1.cmml" xref="S2.T1.1.1.1.m1.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.1.1.1.m1.1c">G</annotation></semantics></math>-1:</th>
<th id="S2.T1.3.3.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">3G &amp; foot</th>
<th id="S2.T1.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t">
<math id="S2.T1.2.2.2.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S2.T1.2.2.2.m1.1a"><mi id="S2.T1.2.2.2.m1.1.1" xref="S2.T1.2.2.2.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S2.T1.2.2.2.m1.1b"><ci id="S2.T1.2.2.2.m1.1.1.cmml" xref="S2.T1.2.2.2.m1.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.2.2.2.m1.1c">G</annotation></semantics></math>-5:</th>
<th id="S2.T1.3.3.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t">4G &amp; foot</th>
<th id="S2.T1.3.3.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_t">
<math id="S2.T1.3.3.3.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S2.T1.3.3.3.m1.1a"><mi id="S2.T1.3.3.3.m1.1.1" xref="S2.T1.3.3.3.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S2.T1.3.3.3.m1.1b"><ci id="S2.T1.3.3.3.m1.1.1.cmml" xref="S2.T1.3.3.3.m1.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.3.3.3.m1.1c">G</annotation></semantics></math>-9:</th>
<th id="S2.T1.3.3.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">WIFI &amp; foot</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.6.6" class="ltx_tr">
<th id="S2.T1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">
<math id="S2.T1.4.4.1.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S2.T1.4.4.1.m1.1a"><mi id="S2.T1.4.4.1.m1.1.1" xref="S2.T1.4.4.1.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S2.T1.4.4.1.m1.1b"><ci id="S2.T1.4.4.1.m1.1.1.cmml" xref="S2.T1.4.4.1.m1.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.4.4.1.m1.1c">G</annotation></semantics></math>-2:</th>
<td id="S2.T1.6.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">3G &amp; car</td>
<th id="S2.T1.5.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">
<math id="S2.T1.5.5.2.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S2.T1.5.5.2.m1.1a"><mi id="S2.T1.5.5.2.m1.1.1" xref="S2.T1.5.5.2.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S2.T1.5.5.2.m1.1b"><ci id="S2.T1.5.5.2.m1.1.1.cmml" xref="S2.T1.5.5.2.m1.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.5.5.2.m1.1c">G</annotation></semantics></math>-6:</th>
<td id="S2.T1.6.6.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">4G &amp; car</td>
<th id="S2.T1.6.6.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">
<math id="S2.T1.6.6.3.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S2.T1.6.6.3.m1.1a"><mi id="S2.T1.6.6.3.m1.1.1" xref="S2.T1.6.6.3.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S2.T1.6.6.3.m1.1b"><ci id="S2.T1.6.6.3.m1.1.1.cmml" xref="S2.T1.6.6.3.m1.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.6.6.3.m1.1c">G</annotation></semantics></math>-10:</th>
<td id="S2.T1.6.6.6" class="ltx_td ltx_align_left ltx_border_t">WIFI &amp; car</td>
</tr>
<tr id="S2.T1.9.9" class="ltx_tr">
<th id="S2.T1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">
<math id="S2.T1.7.7.1.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S2.T1.7.7.1.m1.1a"><mi id="S2.T1.7.7.1.m1.1.1" xref="S2.T1.7.7.1.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S2.T1.7.7.1.m1.1b"><ci id="S2.T1.7.7.1.m1.1.1.cmml" xref="S2.T1.7.7.1.m1.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.7.7.1.m1.1c">G</annotation></semantics></math>-3:</th>
<td id="S2.T1.9.9.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">3G &amp; ferry</td>
<th id="S2.T1.8.8.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">
<math id="S2.T1.8.8.2.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S2.T1.8.8.2.m1.1a"><mi id="S2.T1.8.8.2.m1.1.1" xref="S2.T1.8.8.2.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S2.T1.8.8.2.m1.1b"><ci id="S2.T1.8.8.2.m1.1.1.cmml" xref="S2.T1.8.8.2.m1.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.8.8.2.m1.1c">G</annotation></semantics></math>-7:</th>
<td id="S2.T1.9.9.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">4G &amp; ferry</td>
<th id="S2.T1.9.9.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">
<math id="S2.T1.9.9.3.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S2.T1.9.9.3.m1.1a"><mi id="S2.T1.9.9.3.m1.1.1" xref="S2.T1.9.9.3.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S2.T1.9.9.3.m1.1b"><ci id="S2.T1.9.9.3.m1.1.1.cmml" xref="S2.T1.9.9.3.m1.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.9.9.3.m1.1c">G</annotation></semantics></math>-11:</th>
<td id="S2.T1.9.9.6" class="ltx_td ltx_align_left ltx_border_t">WIFI &amp; ferry</td>
</tr>
<tr id="S2.T1.12.12" class="ltx_tr">
<th id="S2.T1.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t">
<math id="S2.T1.10.10.1.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S2.T1.10.10.1.m1.1a"><mi id="S2.T1.10.10.1.m1.1.1" xref="S2.T1.10.10.1.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S2.T1.10.10.1.m1.1b"><ci id="S2.T1.10.10.1.m1.1.1.cmml" xref="S2.T1.10.10.1.m1.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.10.10.1.m1.1c">G</annotation></semantics></math>-4:</th>
<td id="S2.T1.12.12.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">3G &amp; train</td>
<th id="S2.T1.11.11.2" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t">
<math id="S2.T1.11.11.2.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S2.T1.11.11.2.m1.1a"><mi id="S2.T1.11.11.2.m1.1.1" xref="S2.T1.11.11.2.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S2.T1.11.11.2.m1.1b"><ci id="S2.T1.11.11.2.m1.1.1.cmml" xref="S2.T1.11.11.2.m1.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.11.11.2.m1.1c">G</annotation></semantics></math>-8:</th>
<td id="S2.T1.12.12.5" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">4G &amp; train</td>
<th id="S2.T1.12.12.3" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_t">
<math id="S2.T1.12.12.3.m1.1" class="ltx_Math" alttext="G" display="inline"><semantics id="S2.T1.12.12.3.m1.1a"><mi id="S2.T1.12.12.3.m1.1.1" xref="S2.T1.12.12.3.m1.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S2.T1.12.12.3.m1.1b"><ci id="S2.T1.12.12.3.m1.1.1.cmml" xref="S2.T1.12.12.3.m1.1.1">ğº</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.T1.12.12.3.m1.1c">G</annotation></semantics></math>-12:</th>
<td id="S2.T1.12.12.6" class="ltx_td ltx_align_left ltx_border_b ltx_border_t">WIFI &amp; train</td>
</tr>
</tbody>
</table>
</figure>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Specifically, the federal learning method we adopt enhances the A3CÂ <cite class="ltx_cite ltx_citemacro_citep">(Mnih etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">[n.â€‰d.]</a>)</cite> algorithm to synchronously optimize the neural network of each user by averaging the optimization of neural network gradients within the same group. Users dynamically interact with the real-time video streaming environment, undergo training, and make decisions. The integration of federated learning techniques not only mitigates communication overhead resulting from data transmission but also simultaneously enhances model accuracy and generalization performance.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p"><span id="S2.p4.1.1" class="ltx_text ltx_font_bold">Efficient Online Transfer.</span> In the final step, to mitigate the discrepancy between the offline pre-trained model and the userâ€™s online model caused by the simulation-to-reality gap, we use online transfer training to fine-tune the pre-trained model to better adapt to the real network conditions and video content characteristics. In model transfer, the low-level layers for common feature extraction are frozen. In contrast, the parameters of high-level task-specific layers are updated to adapt to the new network environment.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">Through efficient offline pre-training, the basic knowledge of the real-time video streaming environment is learned and the scarcity of real samples is alleviated. In the following online training, transfer learning is leveraged to fully utilize past experiences for mitigating early-stage â€œtrial-and-errorâ€ and expediting the training process for new network environments, which significantly benefits computational resource savings without degrading model generalization.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">Overall, the dynamic network condition discriminator periodically identifies the group to which a user belongs, and the user continuously interacts with the central server within the same group to exchange the model parameters. Such flexible grouping and iterative training endow <span id="S2.p6.1.1" class="ltx_text ltx_font_sansserif">Bamboo</span> to handle instantaneous changes in network conditions and enhance its generalization performance.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>EVALUATION &amp; FUTURE WORK</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We built a WebRTC-based real-time video conferencing testbed to evaluate <span id="S3.p1.1.1" class="ltx_text ltx_font_sansserif">Bamboo</span>. We created a network trace corpus from HSDPAÂ <cite class="ltx_cite ltx_citemacro_citep">(Riiser etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2013</a>)</cite>, NYUÂ <cite class="ltx_cite ltx_citemacro_citep">(Mei etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2020</a>)</cite>, FCCÂ <cite class="ltx_cite ltx_citemacro_citep">(Commission, <a href="#bib.bib4" title="" class="ltx_ref">2016</a>)</cite>, and used the Linux TC tool to reproduce the real-world network dynamics recorded in these traces. The corpus was randomly divided into training and testing datasets, with 80% of the data used for training <span id="S3.p1.1.2" class="ltx_text ltx_font_sansserif">Bamboo</span> and 20% for testing all algorithms by default. Within the training set, 80% of data were used to train pre-trained offline models, while the remaining 20% were used to train online fine-tuning models. We compare <span id="S3.p1.1.3" class="ltx_text ltx_font_sansserif">Bamboo</span> to the following schemes, which represent the state-of-the-art in bitrate adaptation: (a) ARSÂ <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2019</a>)</cite>, a learning-based bitrate adaptation algorithm with its model trained offline; (b) OnRLÂ <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite>, which employs online training from scratch to improve its model performance; (c) <span id="S3.p1.1.4" class="ltx_text ltx_font_sansserif">Bamboo</span>-transfer, a variant of <span id="S3.p1.1.5" class="ltx_text ltx_font_sansserif">Bamboo</span> with transfer learning enabled but intra-group federated learning disabled. Note that we use the same neural network architecture for these baselines as <span id="S3.p1.1.6" class="ltx_text ltx_font_sansserif">Bamboo</span> for a fair comparison.</p>
</div>
<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.1" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" style="width:199.5pt;"><img src="/html/2308.09948/assets/x2.png" id="S3.F3.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="327" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Rewards gained over epochs in the training.</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.2" class="ltx_figure ltx_figure_panel ltx_minipage ltx_align_center ltx_align_middle" style="width:208.1pt;"><img src="/html/2308.09948/assets/x3.png" id="S3.F3.2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="331" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>Performance evaluation on each QoE metric.</figcaption>
</figure>
</div>
</div>
</figure>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2. </span>Average convergence time in hours to train an online model using different schemes on various networks.</figcaption>
<table id="S3.T2.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T2.1.1.1" class="ltx_tr">
<td id="S3.T2.1.1.1.1" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S3.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3G</td>
<td id="S3.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">4G</td>
<td id="S3.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t">WIFI</td>
</tr>
<tr id="S3.T2.1.2.2" class="ltx_tr">
<td id="S3.T2.1.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">OnRL</td>
<td id="S3.T2.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2.54</td>
<td id="S3.T2.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">2.65</td>
<td id="S3.T2.1.2.2.4" class="ltx_td ltx_align_center ltx_border_t">2.57</td>
</tr>
<tr id="S3.T2.1.3.3" class="ltx_tr">
<td id="S3.T2.1.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span id="S3.T2.1.3.3.1.1" class="ltx_text ltx_font_sansserif">Bamboo</span>-transfer</td>
<td id="S3.T2.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.56</td>
<td id="S3.T2.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.28</td>
<td id="S3.T2.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t">1.51</td>
</tr>
<tr id="S3.T2.1.4.4" class="ltx_tr">
<td id="S3.T2.1.4.4.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S3.T2.1.4.4.1.1" class="ltx_text ltx_font_sansserif">Bamboo</span></td>
<td id="S3.T2.1.4.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S3.T2.1.4.4.2.1" class="ltx_text ltx_font_bold">0.80</span></td>
<td id="S3.T2.1.4.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S3.T2.1.4.4.3.1" class="ltx_text ltx_font_bold">0.53</span></td>
<td id="S3.T2.1.4.4.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t"><span id="S3.T2.1.4.4.4.1" class="ltx_text ltx_font_bold">0.60</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">TableÂ <a href="#S3.T2" title="Table 2 â€£ 3. EVALUATION &amp; FUTURE WORK â€£ Bamboo: Boosting Training Efficiency for Real-Time Video Streaming via Online Grouped Federated Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> and FigureÂ <a href="#S3.F3" title="Figure 3 â€£ 3. EVALUATION &amp; FUTURE WORK â€£ Bamboo: Boosting Training Efficiency for Real-Time Video Streaming via Online Grouped Federated Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> illustrate the training efficiency of <span id="S3.p2.1.1" class="ltx_text ltx_font_sansserif">Bamboo</span>. We evaluate the performance of <span id="S3.p2.1.2" class="ltx_text ltx_font_sansserif">Bamboo</span> and other methods under the same test trace lasting for 300s and plot the normalized average value of QoE metrics (e.g., bitrate, stalling rate, and delay) in FigureÂ <a href="#S3.F3" title="Figure 3 â€£ 3. EVALUATION &amp; FUTURE WORK â€£ Bamboo: Boosting Training Efficiency for Real-Time Video Streaming via Online Grouped Federated Transfer Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. We observe that <span id="S3.p2.1.3" class="ltx_text ltx_font_sansserif">Bamboo</span>â€™s online transfer and grouped federated training improve the online model training efficiency by 43.9% and 55.6%, respectively. Furthermore, when compared to the ARS anchor across all trace sets, these mechanisms increase the bitrate by 0.7%-3.7% and reduce the stalling rate by 2.3%-2.9% as well as delay by 2.3%-4.7%. These findings demonstrate <span id="S3.p2.1.4" class="ltx_text ltx_font_sansserif">Bamboo</span>â€™s proficiency in knowledge transfer and its generalization ability by mitigating RLâ€™s trial-and-error impacts and expediting training data acquisition. Consequently, <span id="S3.p2.1.5" class="ltx_text ltx_font_sansserif">Bamboo</span> outperforms existing approaches by 302% in terms of average convergence time and ensures a satisfactory QoE in real-time video streaming.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">In the future, we will consider more practical issues (e.g., robust hybrid learning mechanism, determining whether the online training can be terminated) and conduct more testbed experiments.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">rep (2023)</span>
<span class="ltx_bibblock">
2023.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">The state of video conferencing 2022</em>.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.dialpad.com/blog/video-conferencing-report/." title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.dialpad.com/blog/video-conferencing-report/.</a>

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Hao Chen, Xu Zhang,
etÂ al<span id="bib.bib3.3.1" class="ltx_text">.</span> 2019.

</span>
<span class="ltx_bibblock">T-Gaming: A Cost-Efficient Cloud Gaming System at
Scale.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.4.1" class="ltx_emph ltx_font_italic">IEEE Trans. Parallel Distrib. Syst.</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Commission (2016)</span>
<span class="ltx_bibblock">
FederalÂ Communications Commission.
2016.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Raw Data-Measuring Broadband America
2016</em>.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://www.fcc.gov/reports-research/reports/measuring-broadband-america/raw-data-measuring-broadband-america-2016" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.fcc.gov/reports-research/reports/measuring-broadband-america/raw-data-measuring-broadband-america-2016</a>

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mei etÂ al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Lifan Mei, Runchen Hu,
etÂ al<span id="bib.bib5.3.1" class="ltx_text">.</span> 2020.

</span>
<span class="ltx_bibblock">Realtime mobile bandwidth prediction using LSTM
neural network and Bayesian fusion.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.4.1" class="ltx_emph ltx_font_italic">Comput. Netw.</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mnih etÂ al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> ([n.â€‰d.])</span>
<span class="ltx_bibblock">
Volodymyr Mnih,
AdriaÂ Puigdomenech Badia, etÂ al<span id="bib.bib6.3.1" class="ltx_text">.</span>
[n.â€‰d.].

</span>
<span class="ltx_bibblock">Asynchronous Methods for Deep Reinforcement
Learning. In <em id="bib.bib6.4.1" class="ltx_emph ltx_font_italic">Proc. ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Riiser etÂ al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2013)</span>
<span class="ltx_bibblock">
Haakon Riiser, Paul
Vigmostad, etÂ al<span id="bib.bib7.3.1" class="ltx_text">.</span> 2013.

</span>
<span class="ltx_bibblock">Commute Path Bandwidth Traces from 3G Networks:
Analysis and Applications. In <em id="bib.bib7.4.1" class="ltx_emph ltx_font_italic">Proc. ACM MMSys</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang and Jiang (2022)</span>
<span class="ltx_bibblock">
Pu Wang and Yongguo
Jiang. 2022.

</span>
<span class="ltx_bibblock">Transportation Mode Detection Using Temporal
Convolutional Networks Based on Sensors Integrated into Smartphones.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Sensors</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Huanhuan Zhang, Anfu
Zhou, etÂ al<span id="bib.bib9.3.1" class="ltx_text">.</span> 2020.

</span>
<span class="ltx_bibblock">OnRL: Improving Mobile Video Telephony via Online
Reinforcement Learning. In <em id="bib.bib9.4.1" class="ltx_emph ltx_font_italic">Proc. ACM MobiCom</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Huanhuan Zhang, Anfu
Zhou, etÂ al<span id="bib.bib10.3.1" class="ltx_text">.</span> 2022.

</span>
<span class="ltx_bibblock">Improving Mobile Interactive Video QoE Via
Two-level Online Cooperative Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.4.1" class="ltx_emph ltx_font_italic">IEEE. Trans. Mob. Comput.</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2308.09946" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2308.09948" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2308.09948">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2308.09948" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2308.09949" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 12:40:09 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
