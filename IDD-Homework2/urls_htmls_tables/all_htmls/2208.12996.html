<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2208.12996] A Federated Learning-enabled Smart Street Light Monitoring Application: Benefits and Future Challenges</title><meta property="og:description" content="Data-enabled cities are recently accelerated and enhanced with automated learning for improved Smart Cities applications. In the context of an Internet of Things (IoT) ecosystem, the data communication is frequently co…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="A Federated Learning-enabled Smart Street Light Monitoring Application: Benefits and Future Challenges">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="A Federated Learning-enabled Smart Street Light Monitoring Application: Benefits and Future Challenges">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2208.12996">

<!--Generated on Wed Mar 13 20:11:04 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Smart Cities,  IoT,  Infrastructure,  Monitoring,  Lamppost,  Neural Networks,  Federated Learning">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">A Federated Learning-enabled Smart Street Light Monitoring Application: Benefits and Future Challenges</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Diya Anand
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">Electrical and Electronic Engineering
<br class="ltx_break">University of Bristol</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_city">Bristol</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_country">UK</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:ul18753@bristol.ac.uk">ul18753@bristol.ac.uk</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ioannis Mavromatis
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a target="_blank" href="https://orcid.org/0000-0002-3309-132X" title="ORCID identifier" class="ltx_ref">0000-0002-3309-132X</a></span>

<span class="ltx_contact ltx_role_affiliation"><span id="id4.1.id1" class="ltx_text ltx_affiliation_institution">Bristol Research and Innovation Laboratory (BRIL), Toshiba Europe Ltd.</span><span id="id5.2.id2" class="ltx_text ltx_affiliation_city">Bristol</span><span id="id6.3.id3" class="ltx_text ltx_affiliation_country">UK</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:Ioannis.Mavromatis@toshiba-bril.com">Ioannis.Mavromatis@toshiba-bril.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Pietro Carnelli
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a target="_blank" href="https://orcid.org/0000-0002-4993-5873" title="ORCID identifier" class="ltx_ref">0000-0002-4993-5873</a></span>

<span class="ltx_contact ltx_role_affiliation"><span id="id7.1.id1" class="ltx_text ltx_affiliation_institution">BRIL, Toshiba Europe Ltd.</span><span id="id8.2.id2" class="ltx_text ltx_affiliation_city">Bristol</span><span id="id9.3.id3" class="ltx_text ltx_affiliation_country">UK</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:Pietro.Carnelli@toshiba-bril.com">Pietro.Carnelli@toshiba-bril.com</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Aftab Khan
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_orcid"><a target="_blank" href="https://orcid.org/0000-0002-3573-6240" title="ORCID identifier" class="ltx_ref">0000-0002-3573-6240</a></span>

<span class="ltx_contact ltx_role_affiliation"><span id="id10.1.id1" class="ltx_text ltx_affiliation_institution">BRIL, Toshiba Europe Ltd.</span><span id="id11.2.id2" class="ltx_text ltx_affiliation_city">Bristol</span><span id="id12.3.id3" class="ltx_text ltx_affiliation_country">UK</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:Aftab.Khan@toshiba-bril.com">Aftab.Khan@toshiba-bril.com</a>
</span></span></span>
</div>
<div class="ltx_dates">(2022)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id13.id1" class="ltx_p">Data-enabled cities are recently accelerated and enhanced with automated learning for improved Smart Cities applications. In the context of an Internet of Things (IoT) ecosystem, the data communication is frequently costly, inefficient, not scalable and lacks security. Federated Learning (FL) plays a pivotal role in providing privacy-preserving and communication efficient Machine Learning (ML) frameworks. In this paper we evaluate the feasibility of FL in the context of a Smart Cities Street Light Monitoring application. FL is evaluated against benchmarks of centralised and (fully) personalised machine learning techniques for the classification task of the lampposts operation. Incorporating FL in such a scenario shows minimal performance reduction in terms of the classification task, but huge improvements in the communication cost and the privacy preserving. These outcomes strengthen FL’s viability and potential for IoT applications.</p>
</div>
<div class="ltx_keywords">Smart Cities, IoT, Infrastructure, Monitoring, Lamppost, Neural Networks, Federated Learning
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">journalyear: </span>2022</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_conference"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">conference: </span>1st ACM Workshop on AI Empowered Mobile and Wireless Sensing; October 21, 2022; Sydney, NSW, Australia</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_booktitle"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">booktitle: </span>1st ACM Workshop on AI Empowered Mobile and Wireless Sensing (MORSE ’22), October 21, 2022, Sydney, NSW, Australia</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_price"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">price: </span>15.00</span></span></span><span id="id5" class="ltx_note ltx_note_frontmatter ltx_role_doi"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">doi: </span>10.1145/3556558.3558580</span></span></span><span id="id6" class="ltx_note ltx_note_frontmatter ltx_role_isbn"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">isbn: </span>978-1-4503-9522-9/22/10</span></span></span><span id="id7" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computer systems organization Client-server architectures</span></span></span><span id="id8" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Supervised learning by classification</span></span></span><span id="id9" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Information systems Data analytics</span></span></span><span id="id10" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computer systems organization Sensor networks</span></span></span><span id="id11" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">ccs: </span>Computing methodologies Neural networks</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">A Smart City is described in <cite class="ltx_cite ltx_citemacro_citep">(Marsal-Llacuna et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2015</a>)</cite> as an urban medium using Information and Communication Technologies (ICT) to promote more efficient ordinary city operations and improve the Quality of Services (QoS) received by the citizens. The objective of a Smart City is to enhance the Quality of Life (QoL) of the citizens and improve sustainability. This is achieved by promoting the digitisation of services, automation, and the use of data for intelligent responses and decisions, while autonomously adapting to different needs <cite class="ltx_cite ltx_citemacro_citep">(Silva
et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The realm of Smart Cities covers multiple areas and applications, such as Smart Transportation, Smart Urban Management, Smart Tourism, Green Cities, Smart Healthcare, etc. <cite class="ltx_cite ltx_citemacro_citep">(Su et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2011</a>)</cite>. The technologies required for these applications are numerous but can be commonly grouped under three categories, i.e., sensing and data collection, intelligent decision support, and exchange of data and decisions between different system entities <cite class="ltx_cite ltx_citemacro_citep">(Umamaheswari
et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite>. All these technologies are part of an Internet of Things (IoT) framework <cite class="ltx_cite ltx_citemacro_citep">(Zanella et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2014</a>)</cite> that provides the underlying infrastructure and services for their operation.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Our work focuses on improving resource utilisation within an IoT ecosystem by moving intelligent decision-making closer to the sensors and the “edge”. More specifically, we evaluate the feasibility of using Federated Learning (FL) within a Smart Street Light Monitoring application context. This application is a good representation of Smart Cities as it generates a large amount of data, requires increased communication bandwidth for their exchange, and is resource-intensive when classifying whether a lamppost is operational or not.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">FL <cite class="ltx_cite ltx_citemacro_citep">(Zheng
et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2022</a>)</cite> is a branch of Machine Learning (ML) that relies on multiple “clients”, e.g., edge devices, to collect and process local data for training an ML model. In turn, the client’s ML model parameters are shared with a central FL server for global model aggregation. Once enough updates from clients (sample fraction per round of FL) within the network have been received, a new global model is generated and broadcast to all clients. Such methods of training local models have certain benefits important to IoT and “smart city”-centric networks <cite class="ltx_cite ltx_citemacro_citep">(Zheng
et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">IoT networks often build upon Low-power Wide-Area Network (LPWAN) wireless protocols such as LoRaWAN, Zigbee and Bluetooth <cite class="ltx_cite ltx_citemacro_citep">(Ding
et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2020</a>)</cite>. For example, a Smart Street Light Monitoring application can easily generate hundreds of gigabytes of data if central training and processing are required <cite class="ltx_cite ltx_citemacro_citep">(Yang
et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2020</a>)</cite>. However, this amount of data is almost impossible to be exchanged via the low-power, low data rate IoT wireless links. In such a scenario, FL can play a pivotal role by replacing the exchange of data with the exchange of the more lightweight prediction models.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Furthermore, FL provides a variety of privacy advantages required for real-world Smart Cities applications <cite class="ltx_cite ltx_citemacro_citep">(Lin et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2021</a>)</cite>. Data minimisation is achieved as the raw data stay on the edge device, and data leakage can be avoided in transit. For external users interacting with the system, having access to only aggregated models and data can enhance privacy. Traditional end-to-end encryption mechanisms can secure the models exchanged in transit. Finally, even when an edge device is tampered with, and the model is altered, the nature of FL and the model aggregation on the server limits individual malicious models’ influence on the global output. Of course, extensions and algorithms can provide more formal guarantees such as differential privacy <cite class="ltx_cite ltx_citemacro_citep">(Ouadrhiri and
Abdelhadi, <a href="#bib.bib17" title="" class="ltx_ref">2022</a>)</cite>, or algorithms for concept drift detection can identify such drifts <cite class="ltx_cite ltx_citemacro_citep">(Khan et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">The rest of the paper is structured as follows; Section 2 summarises the related work to optimising FL clients to their local datasets/environments. Section 3 discusses our methodology, experiments and introduces our evaluation dataset. Our experimental evaluation and results are discussed in Section 4, supported by a detailed discussion on the lessons learned from this activity. Finally, Section 5 summarises our findings, and provides suggestions for future research activities.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">ML is currently being used in various intelligent fault diagnosis methods. For example, <cite class="ltx_cite ltx_citemacro_citep">(Tang
et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2021</a>; Lee
et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2019</a>)</cite> present two ML-based fault detection mechanisms for street light applications. Sending the collected data to a central server, the real-time illuminance of the lamppost is evaluated, and faults are reported to the maintenance staff. The results show up to <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="90\%" display="inline"><semantics id="S2.p1.1.m1.1a"><mrow id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml"><mn id="S2.p1.1.m1.1.1.2" xref="S2.p1.1.m1.1.1.2.cmml">90</mn><mo id="S2.p1.1.m1.1.1.1" xref="S2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><apply id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1"><csymbol cd="latexml" id="S2.p1.1.m1.1.1.1.cmml" xref="S2.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S2.p1.1.m1.1.1.2.cmml" xref="S2.p1.1.m1.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">90\%</annotation></semantics></math> of fault detection accuracy for such scenarios. Such an approach increased the communication cost in the IoT system while introducing many challenges in securing the data in transit.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Personalisation in ML can enhance detection by targeting particular entities and optimising the trained models accordingly. Authors in <cite class="ltx_cite ltx_citemacro_citep">(Schneider and
Vlachos, <a href="#bib.bib18" title="" class="ltx_ref">2021</a>)</cite> present three ways of personalisation utilising the MNIST dataset. Their results show increased performance compared to traditional ML strategies. However, personalised models trained on a server require again increased communication overhead. Personalised models trained at the edge, even though they minimise the communication overhead, require a large dataset available for each model trained. The intermittent nature of an IoT system, where data may be scarce, can create obstacles to collecting such vast amounts of data.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.2" class="ltx_p">FL can bridge the gap between the personalised and centralised approach. Training models locally decrease communication costs while preserving data privacy. Moreover, for edge nodes with an abundance of data, aggregating the existing models on the server side and sharing them with all edge nodes can ensure that a highly accurate model is always available for inference. However, FL can suffer from highly skewed, non-Independent, Identically Distributed (IID) data. Knowing the data types and ways of clustering them can enhance FL’s accuracy. Work carried out by <cite class="ltx_cite ltx_citemacro_citep">(Zhao
et al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2018</a>)</cite> shows an improvement of circa <math id="S2.p3.1.m1.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S2.p3.1.m1.1a"><mn id="S2.p3.1.m1.1.1" xref="S2.p3.1.m1.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S2.p3.1.m1.1b"><cn type="integer" id="S2.p3.1.m1.1.1.cmml" xref="S2.p3.1.m1.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.1.m1.1c">30</annotation></semantics></math>% on the CIFAR-10 dataset compared to classical FedAvg using their proposed data-sharing strategy between participating clients. The authors show that sharing <math id="S2.p3.2.m2.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S2.p3.2.m2.1a"><mn id="S2.p3.2.m2.1.1" xref="S2.p3.2.m2.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S2.p3.2.m2.1b"><cn type="integer" id="S2.p3.2.m2.1.1.cmml" xref="S2.p3.2.m2.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p3.2.m2.1c">5</annotation></semantics></math>% of a separate global dataset across clients and initialising a model at the server on the dataset mentioned above leads to a classification performance increase. Federated Meta-Learning or FedMeta framework <cite class="ltx_cite ltx_citemacro_citep">(Chen
et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2018</a>)</cite> uses parameterised algorithms such as MAML and Meta-SGD to train on the client’s local data and communicate the updates to the server instead of updated models in traditional FL. In FedAMP <cite class="ltx_cite ltx_citemacro_citep">(Y. Huang et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2021</a>)</cite>, copies of local models are kept on the cloud server with attentive message passing between clients and server leading to aggregated client models of messages passed. Both methods can again enhance FL’s performance.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">Whilst such techniques show general performance improvement, the practical challenges are numerous. For example, creating a separate dataset of similar distribution would require prior knowledge of client data and sharing this data with the server. This method is not aligned with FL principles of maintaining local datasets for the participating clients. Furthermore, such data-sharing techniques might not be feasible amongst thousands of sensors/edge devices in an IoT network. Similarly, sharing and storing multiple copies of clients’ models requires more robust, scalable and resource-rich infrastructure and storage capabilities. This approach does not scale well in networks of hundreds of thousands of participating devices.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Methodology And Experiments</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this paper we investigate the feasibility of FL for a lamppost fault detection use-case and compare it against a centralised and a “fully” personalised approach. An FL benchmark method, using a typical averaging technique to establish a global model (inspired by <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al<span class="ltx_text">.</span>, <a href="#bib.bib16" title="" class="ltx_ref">2016</a>)</cite>), was compared to a centralised method (i.e., classical ML) and an extreme version of or a “hyper-personalised” FL method, whereby each lamppost uses a model trained on <span id="S3.p1.1.1" class="ltx_text ltx_font_bold">only</span> it’s dataset and was never aggregated centrally. Such “extreme” methods provide a good overview of their potential for accurate detection using very different training data splits.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Convolutional Neural Network Model Selection</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">For most FL IoT applications, the model should be lightweight enough to train on the edge device. Moreover, FL involves broadcasting the model between clients and the server. Hence a bigger model would not meet the bandwidth limitations of FL and increase communication costs significantly.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">A Convolutional Neural Network (CNN) based on the Residual Networks (ResNet) architecture was considered “lightweight” enough for training and inference on IoT devices and capable of classifying incoming images. In particular, ResNets <cite class="ltx_cite ltx_citemacro_citep">(He
et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2015</a>)</cite> were designed to combat deep neural networks which suffer from vanishing gradients (a common problem encountered in neural network training procedures). Furthermore, such a model allowed for fair comparison amongst the three different ML strategies being investigated.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>The Dataset</h3>

<figure id="S3.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.12996/assets/images/node0.jpg" id="S3.F1.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F1.sf1.3.2" class="ltx_text" style="font-size:90%;">Node Type 0</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.12996/assets/images/node1.jpg" id="S3.F1.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F1.sf2.3.2" class="ltx_text" style="font-size:90%;">Node Type 1</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F1.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2208.12996/assets/images/node2.jpg" id="S3.F1.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="449" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S3.F1.sf3.3.2" class="ltx_text" style="font-size:90%;">Node Type 2</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>. </span><span id="S3.F1.3.2" class="ltx_text" style="font-size:90%;">(a) Node 0: Ideal Lamppost. The light is clearly visible and this becomes easy detection of whether the light is on or off (b) Node 1: Normal Lamppost. The light is not directly visible; for detection (c) Node 2: Edge Case Lamppost. the light is completely covered by vegetation or the camera has slipped making for complicated detection.</span></figcaption>
</figure>
<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.7" class="ltx_p">Our investigation is based on a large volume dataset of street light images. Since our focus is the evaluation of FL under Smart Street Light Monitoring environments, we selected the ”Dataset of Images of Public Streetlights” <cite class="ltx_cite ltx_citemacro_citep">(Mavromatis et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2022a</a>)</cite>, generated as part of the UMBRELLA project <cite class="ltx_cite ltx_citemacro_citep">(Farnham et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2021</a>)</cite>. The dataset is publicly available from Zenodo Open Repository <cite class="ltx_cite ltx_citemacro_citep">(Mavromatis et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2022b</a>)</cite>. The dataset consists of over <math id="S3.SS2.p1.1.m1.2" class="ltx_Math" alttext="350,000" display="inline"><semantics id="S3.SS2.p1.1.m1.2a"><mrow id="S3.SS2.p1.1.m1.2.3.2" xref="S3.SS2.p1.1.m1.2.3.1.cmml"><mn id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">350</mn><mo id="S3.SS2.p1.1.m1.2.3.2.1" xref="S3.SS2.p1.1.m1.2.3.1.cmml">,</mo><mn id="S3.SS2.p1.1.m1.2.2" xref="S3.SS2.p1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.2b"><list id="S3.SS2.p1.1.m1.2.3.1.cmml" xref="S3.SS2.p1.1.m1.2.3.2"><cn type="integer" id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">350</cn><cn type="integer" id="S3.SS2.p1.1.m1.2.2.cmml" xref="S3.SS2.p1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.2c">350,000</annotation></semantics></math> images of streetlights, collected hourly and over a period of six months. The images come from <math id="S3.SS2.p1.2.m2.1" class="ltx_Math" alttext="140" display="inline"><semantics id="S3.SS2.p1.2.m2.1a"><mn id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">140</mn><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><cn type="integer" id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">140</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">140</annotation></semantics></math> UMBRELLA IoT nodes deployed across multiple locations in the South Gloucestershire region of the UK. The UMBRELLA nodes are currently installed at a public stretch of <math id="S3.SS2.p1.3.m3.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S3.SS2.p1.3.m3.1a"><mo id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><csymbol cd="latexml" id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">\sim</annotation></semantics></math><math id="S3.SS2.p1.4.m4.3" class="ltx_Math" alttext="7.2\text{\,}\mathrm{km}" display="inline"><semantics id="S3.SS2.p1.4.m4.3a"><mrow id="S3.SS2.p1.4.m4.3.3" xref="S3.SS2.p1.4.m4.3.3.cmml"><mn id="S3.SS2.p1.4.m4.1.1.1.1.1.1" xref="S3.SS2.p1.4.m4.1.1.1.1.1.1.cmml">7.2</mn><mtext id="S3.SS2.p1.4.m4.2.2.2.2.2.2" xref="S3.SS2.p1.4.m4.2.2.2.2.2.2.cmml"> </mtext><mi class="ltx_unit" id="S3.SS2.p1.4.m4.3.3.3.3.3.3" xref="S3.SS2.p1.4.m4.3.3.3.3.3.3.cmml">km</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.3b"><apply id="S3.SS2.p1.4.m4.3.3.cmml" xref="S3.SS2.p1.4.m4.3.3"><csymbol cd="latexml" id="S3.SS2.p1.4.m4.2.2.2.2.2.2.cmml" xref="S3.SS2.p1.4.m4.2.2.2.2.2.2">times</csymbol><cn type="float" id="S3.SS2.p1.4.m4.1.1.1.1.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1.1.1.1.1">7.2</cn><csymbol cd="latexml" id="S3.SS2.p1.4.m4.3.3.3.3.3.3.cmml" xref="S3.SS2.p1.4.m4.3.3.3.3.3.3">kilometer</csymbol></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.3c">7.2\text{\,}\mathrm{km}</annotation></semantics></math> road (about <math id="S3.SS2.p1.5.m5.1" class="ltx_Math" alttext="\sim 80\%" display="inline"><semantics id="S3.SS2.p1.5.m5.1a"><mrow id="S3.SS2.p1.5.m5.1.1" xref="S3.SS2.p1.5.m5.1.1.cmml"><mi id="S3.SS2.p1.5.m5.1.1.2" xref="S3.SS2.p1.5.m5.1.1.2.cmml"></mi><mo id="S3.SS2.p1.5.m5.1.1.1" xref="S3.SS2.p1.5.m5.1.1.1.cmml">∼</mo><mrow id="S3.SS2.p1.5.m5.1.1.3" xref="S3.SS2.p1.5.m5.1.1.3.cmml"><mn id="S3.SS2.p1.5.m5.1.1.3.2" xref="S3.SS2.p1.5.m5.1.1.3.2.cmml">80</mn><mo id="S3.SS2.p1.5.m5.1.1.3.1" xref="S3.SS2.p1.5.m5.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.5.m5.1b"><apply id="S3.SS2.p1.5.m5.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1"><csymbol cd="latexml" id="S3.SS2.p1.5.m5.1.1.1.cmml" xref="S3.SS2.p1.5.m5.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S3.SS2.p1.5.m5.1.1.2.cmml" xref="S3.SS2.p1.5.m5.1.1.2">absent</csymbol><apply id="S3.SS2.p1.5.m5.1.1.3.cmml" xref="S3.SS2.p1.5.m5.1.1.3"><csymbol cd="latexml" id="S3.SS2.p1.5.m5.1.1.3.1.cmml" xref="S3.SS2.p1.5.m5.1.1.3.1">percent</csymbol><cn type="integer" id="S3.SS2.p1.5.m5.1.1.3.2.cmml" xref="S3.SS2.p1.5.m5.1.1.3.2">80</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.5.m5.1c">\sim 80\%</annotation></semantics></math> of the nodes) and around the University of the West of England (UWE) Frenchay Campus (about <math id="S3.SS2.p1.6.m6.1" class="ltx_Math" alttext="\sim 20\%" display="inline"><semantics id="S3.SS2.p1.6.m6.1a"><mrow id="S3.SS2.p1.6.m6.1.1" xref="S3.SS2.p1.6.m6.1.1.cmml"><mi id="S3.SS2.p1.6.m6.1.1.2" xref="S3.SS2.p1.6.m6.1.1.2.cmml"></mi><mo id="S3.SS2.p1.6.m6.1.1.1" xref="S3.SS2.p1.6.m6.1.1.1.cmml">∼</mo><mrow id="S3.SS2.p1.6.m6.1.1.3" xref="S3.SS2.p1.6.m6.1.1.3.cmml"><mn id="S3.SS2.p1.6.m6.1.1.3.2" xref="S3.SS2.p1.6.m6.1.1.3.2.cmml">20</mn><mo id="S3.SS2.p1.6.m6.1.1.3.1" xref="S3.SS2.p1.6.m6.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.6.m6.1b"><apply id="S3.SS2.p1.6.m6.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1"><csymbol cd="latexml" id="S3.SS2.p1.6.m6.1.1.1.cmml" xref="S3.SS2.p1.6.m6.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S3.SS2.p1.6.m6.1.1.2.cmml" xref="S3.SS2.p1.6.m6.1.1.2">absent</csymbol><apply id="S3.SS2.p1.6.m6.1.1.3.cmml" xref="S3.SS2.p1.6.m6.1.1.3"><csymbol cd="latexml" id="S3.SS2.p1.6.m6.1.1.3.1.cmml" xref="S3.SS2.p1.6.m6.1.1.3.1">percent</csymbol><cn type="integer" id="S3.SS2.p1.6.m6.1.1.3.2.cmml" xref="S3.SS2.p1.6.m6.1.1.3.2">20</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.6.m6.1c">\sim 20\%</annotation></semantics></math> of the nodes). Since each lamppost had between <math id="S3.SS2.p1.7.m7.3" class="ltx_Math" alttext="1,000-4,000" display="inline"><semantics id="S3.SS2.p1.7.m7.3a"><mrow id="S3.SS2.p1.7.m7.3.3.1" xref="S3.SS2.p1.7.m7.3.3.2.cmml"><mn id="S3.SS2.p1.7.m7.1.1" xref="S3.SS2.p1.7.m7.1.1.cmml">1</mn><mo id="S3.SS2.p1.7.m7.3.3.1.2" xref="S3.SS2.p1.7.m7.3.3.2.cmml">,</mo><mrow id="S3.SS2.p1.7.m7.3.3.1.1" xref="S3.SS2.p1.7.m7.3.3.1.1.cmml"><mn id="S3.SS2.p1.7.m7.3.3.1.1.2" xref="S3.SS2.p1.7.m7.3.3.1.1.2.cmml">000</mn><mo id="S3.SS2.p1.7.m7.3.3.1.1.1" xref="S3.SS2.p1.7.m7.3.3.1.1.1.cmml">−</mo><mn id="S3.SS2.p1.7.m7.3.3.1.1.3" xref="S3.SS2.p1.7.m7.3.3.1.1.3.cmml">4</mn></mrow><mo id="S3.SS2.p1.7.m7.3.3.1.3" xref="S3.SS2.p1.7.m7.3.3.2.cmml">,</mo><mn id="S3.SS2.p1.7.m7.2.2" xref="S3.SS2.p1.7.m7.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.7.m7.3b"><list id="S3.SS2.p1.7.m7.3.3.2.cmml" xref="S3.SS2.p1.7.m7.3.3.1"><cn type="integer" id="S3.SS2.p1.7.m7.1.1.cmml" xref="S3.SS2.p1.7.m7.1.1">1</cn><apply id="S3.SS2.p1.7.m7.3.3.1.1.cmml" xref="S3.SS2.p1.7.m7.3.3.1.1"><minus id="S3.SS2.p1.7.m7.3.3.1.1.1.cmml" xref="S3.SS2.p1.7.m7.3.3.1.1.1"></minus><cn type="integer" id="S3.SS2.p1.7.m7.3.3.1.1.2.cmml" xref="S3.SS2.p1.7.m7.3.3.1.1.2">000</cn><cn type="integer" id="S3.SS2.p1.7.m7.3.3.1.1.3.cmml" xref="S3.SS2.p1.7.m7.3.3.1.1.3">4</cn></apply><cn type="integer" id="S3.SS2.p1.7.m7.2.2.cmml" xref="S3.SS2.p1.7.m7.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.7.m7.3c">1,000-4,000</annotation></semantics></math> images, personalised models per lamppost were possible to train and optimise for our comparison, achieving very high accuracy on each model independently.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">The images in the dataset were used to determine whether the lamppost is operational or not, i.e., whether the lamppost is switched ON or OFF. The lamppost functionality is monitored during different times (once per hour), with the light expected to be ON at night and OFF during the day, as part of a partnership with the local government to ensure road safety. As “night” is considered the time period from “15-minutes before sunset” until “15-minutes after sunrise” and calculated independently for each day.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">The images are in JPEG format with a resolution of <math id="S3.SS2.p3.1.m1.1" class="ltx_Math" alttext="1024\times 768" display="inline"><semantics id="S3.SS2.p3.1.m1.1a"><mrow id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mn id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">1024</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS2.p3.1.m1.1.1.1" xref="S3.SS2.p3.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml">768</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><times id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1.1"></times><cn type="integer" id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">1024</cn><cn type="integer" id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3">768</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">1024\times 768</annotation></semantics></math> pixels. The entries in the dataset are already pre-labelled. What is more, the dataset spans a large geographical area and various different lamppost designs, heights and operational modes. Several streetlights are partially obstructed by vegetation or are outside the Field of View (FoV) of the camera. Finally, the cameras facing the sky are susceptible to weather conditions (e.g., rain, snow, direct sunlight, etc.) that can partially or entirely alter the quality of the images taken. All the above generate “interesting” and unique edge-cases when evaluating FL within the context of a Smart Street Light Monitoring application.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Node Categorisation</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Figure <a href="#S3.F1" title="Figure 1 ‣ 3.2. The Dataset ‣ 3. Methodology And Experiments ‣ A Federated Learning-enabled Smart Street Light Monitoring Application: Benefits and Future Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows some example images of the dataset used. Our evaluation and discussion are based on further grouping the nodes in the three categories seen in Figure <a href="#S3.F1" title="Figure 1 ‣ 3.2. The Dataset ‣ 3. Methodology And Experiments ‣ A Federated Learning-enabled Smart Street Light Monitoring Application: Benefits and Future Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. As discussed in Section <a href="#S4" title="4. Experimental Evaluation ‣ A Federated Learning-enabled Smart Street Light Monitoring Application: Benefits and Future Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, we grouped the nodes into three categories with respect to the Line-of-Sight (LoS) to the lamppost (being inside the camera’s FoV or not) and whether there is any obstruction by vegetation.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">More specifically, Figure <a href="#S3.F1.sf1" title="In Figure 1 ‣ 3.2. The Dataset ‣ 3. Methodology And Experiments ‣ A Federated Learning-enabled Smart Street Light Monitoring Application: Benefits and Future Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(a)</span></a> is labelled as “node type 0”, modelling an ideal lamppost image; it possesses a clear view of the lamppost light, making the binary classification task of whether the light is on or off relatively simple. Figure <a href="#S3.F1.sf2" title="In Figure 1 ‣ 3.2. The Dataset ‣ 3. Methodology And Experiments ‣ A Federated Learning-enabled Smart Street Light Monitoring Application: Benefits and Future Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(b)</span></a> is an intermediate case labelled as “node type 1”; due to the positioning of the UMBRELLA node, only the pole of the lamppost is visible. For this node type, the “turned-off” and “turned-on” lampposts can be classified by a human looking at the luminance of an image. However, depending on the camera’s position inside the node and the weather conditions, the classification is not always easy with bare eyes. Finally, Figure <a href="#S3.F1.sf3" title="In Figure 1 ‣ 3.2. The Dataset ‣ 3. Methodology And Experiments ‣ A Federated Learning-enabled Smart Street Light Monitoring Application: Benefits and Future Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(c)</span></a>, referred to as “node type 2”, represents the most challenging type captured; this subclass consists of images with no view of the lamppost due to vegetation or the camera being mispositioned. The labelling of each node was done manually before the evaluation. For that, we considered the unique characteristics of each node. The labelling is later used during our evaluation process (fed as a CSV file in our algorithm)<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>A copy of this file can be found in the following link:
<br class="ltx_break"><a target="_blank" href="https://www.dropbox.com/s/ydxioouluet3gwf/nodetypes.csv?dl=0" title="" class="ltx_ref ltx_href">https://www.dropbox.com/s/ydxioouluet3gwf/nodetypes.csv?dl=0</a></span></span></span>.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4. </span>Data Pre-Processing</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.2" class="ltx_p">The original, ‘raw’ lamppost dataset consists of images of <math id="S3.SS4.p1.1.m1.1" class="ltx_Math" alttext="1024\times 768" display="inline"><semantics id="S3.SS4.p1.1.m1.1a"><mrow id="S3.SS4.p1.1.m1.1.1" xref="S3.SS4.p1.1.m1.1.1.cmml"><mn id="S3.SS4.p1.1.m1.1.1.2" xref="S3.SS4.p1.1.m1.1.1.2.cmml">1024</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS4.p1.1.m1.1.1.1" xref="S3.SS4.p1.1.m1.1.1.1.cmml">×</mo><mn id="S3.SS4.p1.1.m1.1.1.3" xref="S3.SS4.p1.1.m1.1.1.3.cmml">768</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.1.m1.1b"><apply id="S3.SS4.p1.1.m1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1"><times id="S3.SS4.p1.1.m1.1.1.1.cmml" xref="S3.SS4.p1.1.m1.1.1.1"></times><cn type="integer" id="S3.SS4.p1.1.m1.1.1.2.cmml" xref="S3.SS4.p1.1.m1.1.1.2">1024</cn><cn type="integer" id="S3.SS4.p1.1.m1.1.1.3.cmml" xref="S3.SS4.p1.1.m1.1.1.3">768</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.1.m1.1c">1024\times 768</annotation></semantics></math> Red, Green, Blue (RGB) pixels which are far too big for most CNNs trained on edge devices (such as the Nvidia Jetson Nano). To reduce the computational and memory footprint during training and deployment we reduced the images to <math id="S3.SS4.p1.2.m2.1" class="ltx_Math" alttext="32\times 32" display="inline"><semantics id="S3.SS4.p1.2.m2.1a"><mrow id="S3.SS4.p1.2.m2.1.1" xref="S3.SS4.p1.2.m2.1.1.cmml"><mn id="S3.SS4.p1.2.m2.1.1.2" xref="S3.SS4.p1.2.m2.1.1.2.cmml">32</mn><mo lspace="0.222em" rspace="0.222em" id="S3.SS4.p1.2.m2.1.1.1" xref="S3.SS4.p1.2.m2.1.1.1.cmml">×</mo><mn id="S3.SS4.p1.2.m2.1.1.3" xref="S3.SS4.p1.2.m2.1.1.3.cmml">32</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p1.2.m2.1b"><apply id="S3.SS4.p1.2.m2.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1"><times id="S3.SS4.p1.2.m2.1.1.1.cmml" xref="S3.SS4.p1.2.m2.1.1.1"></times><cn type="integer" id="S3.SS4.p1.2.m2.1.1.2.cmml" xref="S3.SS4.p1.2.m2.1.1.2">32</cn><cn type="integer" id="S3.SS4.p1.2.m2.1.1.3.cmml" xref="S3.SS4.p1.2.m2.1.1.3">32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p1.2.m2.1c">32\times 32</annotation></semantics></math> pixels with three channels (RGB representation) as shown in Figure <a href="#S3.F2" title="Figure 2 ‣ 3.4. Data Pre-Processing ‣ 3. Methodology And Experiments ‣ A Federated Learning-enabled Smart Street Light Monitoring Application: Benefits and Future Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> by resizing, cropping and down-sampling the image using a bilinear interpolation method. Finally we normalised the reduced RGB images by subtracting the mean from each pixel and dividing it by the standard deviation (Figure <a href="#S3.F2" title="Figure 2 ‣ 3.4. Data Pre-Processing ‣ 3. Methodology And Experiments ‣ A Federated Learning-enabled Smart Street Light Monitoring Application: Benefits and Future Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2208.12996/assets/x1.png" id="S3.F2.g1" class="ltx_graphics ltx_img_landscape" width="460" height="313" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>. </span><span id="S3.F2.3.2" class="ltx_text" style="font-size:90%;">Flowchart of Data Pre-Processing Pipeline</span></figcaption>
</figure>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.2.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>. </span><span id="S3.T1.3.2" class="ltx_text" style="font-size:90%;">Overview of Experiments</span></figcaption>
<table id="S3.T1.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.4.1.1" class="ltx_tr">
<th id="S3.T1.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;">Method</th>
<th id="S3.T1.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;">Trained on</th>
<th id="S3.T1.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;">#Training Devices</th>
<th id="S3.T1.4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;">Evaluated on</th>
<th id="S3.T1.4.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;">#Testing Devices</th>
<th id="S3.T1.4.1.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;">#Models</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.4.2.1" class="ltx_tr">
<td id="S3.T1.4.2.1.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="3"><span id="S3.T1.4.2.1.1.1" class="ltx_text">Personalised</span></td>
<td id="S3.T1.4.2.1.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">Normal Nodes</td>
<td id="S3.T1.4.2.1.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">133</td>
<td id="S3.T1.4.2.1.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">Normal Nodes</td>
<td id="S3.T1.4.2.1.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">133</td>
<td id="S3.T1.4.2.1.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">133</td>
</tr>
<tr id="S3.T1.4.3.2" class="ltx_tr">
<td id="S3.T1.4.3.2.1" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">Edge-Case Nodes</td>
<td id="S3.T1.4.3.2.2" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">7</td>
<td id="S3.T1.4.3.2.3" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">Edge-Case Nodes</td>
<td id="S3.T1.4.3.2.4" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">7</td>
<td id="S3.T1.4.3.2.5" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">7</td>
</tr>
<tr id="S3.T1.4.4.3" class="ltx_tr">
<td id="S3.T1.4.4.3.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">All nodes or devices</td>
<td id="S3.T1.4.4.3.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">140</td>
<td id="S3.T1.4.4.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">All nodes or devices</td>
<td id="S3.T1.4.4.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">140</td>
<td id="S3.T1.4.4.3.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">140</td>
</tr>
<tr id="S3.T1.4.5.4" class="ltx_tr">
<td id="S3.T1.4.5.4.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="3"><span id="S3.T1.4.5.4.1.1" class="ltx_text">Centralised</span></td>
<td id="S3.T1.4.5.4.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">All nodes or devices</td>
<td id="S3.T1.4.5.4.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">140</td>
<td id="S3.T1.4.5.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">Normal Nodes</td>
<td id="S3.T1.4.5.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">133</td>
<td id="S3.T1.4.5.4.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">1</td>
</tr>
<tr id="S3.T1.4.6.5" class="ltx_tr">
<td id="S3.T1.4.6.5.1" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">All nodes or devices</td>
<td id="S3.T1.4.6.5.2" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">140</td>
<td id="S3.T1.4.6.5.3" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">Edge-Case Nodes</td>
<td id="S3.T1.4.6.5.4" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">7</td>
<td id="S3.T1.4.6.5.5" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">1</td>
</tr>
<tr id="S3.T1.4.7.6" class="ltx_tr">
<td id="S3.T1.4.7.6.1" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">All nodes or devices</td>
<td id="S3.T1.4.7.6.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">140</td>
<td id="S3.T1.4.7.6.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">All nodes or devices</td>
<td id="S3.T1.4.7.6.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">140</td>
<td id="S3.T1.4.7.6.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">1</td>
</tr>
<tr id="S3.T1.4.8.7" class="ltx_tr">
<td id="S3.T1.4.8.7.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="3"><span id="S3.T1.4.8.7.1.1" class="ltx_text">FL benchmark</span></td>
<td id="S3.T1.4.8.7.2" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">All nodes or devices</td>
<td id="S3.T1.4.8.7.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">140</td>
<td id="S3.T1.4.8.7.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">Normal Nodes</td>
<td id="S3.T1.4.8.7.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">133</td>
<td id="S3.T1.4.8.7.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">1</td>
</tr>
<tr id="S3.T1.4.9.8" class="ltx_tr">
<td id="S3.T1.4.9.8.1" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">All nodes or devices</td>
<td id="S3.T1.4.9.8.2" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">140</td>
<td id="S3.T1.4.9.8.3" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">Edge-Case Nodes</td>
<td id="S3.T1.4.9.8.4" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">7</td>
<td id="S3.T1.4.9.8.5" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">1</td>
</tr>
<tr id="S3.T1.4.10.9" class="ltx_tr">
<td id="S3.T1.4.10.9.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">All nodes or devices</td>
<td id="S3.T1.4.10.9.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">140</td>
<td id="S3.T1.4.10.9.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">All nodes or devices</td>
<td id="S3.T1.4.10.9.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">140</td>
<td id="S3.T1.4.10.9.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">1</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Experimental Evaluation</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">As discussed in Section <a href="#S3" title="3. Methodology And Experiments ‣ A Federated Learning-enabled Smart Street Light Monitoring Application: Benefits and Future Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> our evaluation compares a centralised, a “fully” personalised, and an FL approach. The dataset was split into a training and testing dataset; the test set consisted of 20% of images from every lamppost node/device, and the remaining 80% constituted the training dataset. This was consistent throughout all experiments. For our performance investigation, we also considered the type of nodes. We combined grouped the nodes of types 0 and 1 while we separately evaluated the nodes of type 2 to observe how the performance can degrade when facing such edge cases.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">The developed centralised model and method generates a single model for the entire lamppost dataset for training. The “fully” personalised method is demonstrated by treating each lamppost as a separate entity. A model is trained solely on its own dataset (i.e., with no FL aggregation). Finally, the FL approach is based on 140 clients (i.e., one per lamppost), aggregating their models using the FedAvg algorithm. All experiments are summarised in Table <a href="#S3.T1" title="Table 1 ‣ 3.4. Data Pre-Processing ‣ 3. Methodology And Experiments ‣ A Federated Learning-enabled Smart Street Light Monitoring Application: Benefits and Future Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Results for all Training/Testing Methods</h3>

<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.9.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>. </span><span id="S4.T2.10.2" class="ltx_text" style="font-size:90%;">Experimental Results for all Three Implemented Methods of Training and Testing.</span></figcaption>
<table id="S4.T2.7" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.7.8.1" class="ltx_tr">
<td id="S4.T2.7.8.1.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;">Method</td>
<td id="S4.T2.7.8.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.7.8.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.7.8.1.2.1.1" class="ltx_p" style="width:45.5pt;">#training lampposts</span>
</span>
</td>
<td id="S4.T2.7.8.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.7.8.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.7.8.1.3.1.1" class="ltx_p" style="width:45.5pt;">#test lampposts</span>
</span>
</td>
<td id="S4.T2.7.8.1.4" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;">#FL clients</td>
<td id="S4.T2.7.8.1.5" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;">#Models</td>
<td id="S4.T2.7.8.1.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.7.8.1.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.7.8.1.6.1.1" class="ltx_p" style="width:51.2pt;">#Training samples</span>
</span>
</td>
<td id="S4.T2.7.8.1.7" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;">#Test samples</td>
<td id="S4.T2.7.8.1.8" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;">Accuracy (%)</td>
<td id="S4.T2.7.8.1.9" class="ltx_td ltx_align_center ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;">F1-Score</td>
</tr>
<tr id="S4.T2.7.9.2" class="ltx_tr">
<td id="S4.T2.7.9.2.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="3"><span id="S4.T2.7.9.2.1.1" class="ltx_text">Personalised</span></td>
<td id="S4.T2.7.9.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.7.9.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.7.9.2.2.1.1" class="ltx_p" style="width:45.5pt;">133<sup id="S4.T2.7.9.2.2.1.1.1" class="ltx_sup ltx_centering">†</sup></span>
</span>
</td>
<td id="S4.T2.7.9.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.7.9.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.7.9.2.3.1.1" class="ltx_p" style="width:45.5pt;">133<sup id="S4.T2.7.9.2.3.1.1.1" class="ltx_sup ltx_centering">†</sup></span>
</span>
</td>
<td id="S4.T2.7.9.2.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">–</td>
<td id="S4.T2.7.9.2.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">133</td>
<td id="S4.T2.7.9.2.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.7.9.2.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.7.9.2.6.1.1" class="ltx_p" style="width:51.2pt;">281804</span>
</span>
</td>
<td id="S4.T2.7.9.2.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">70549</td>
<td id="S4.T2.7.9.2.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">98.57</td>
<td id="S4.T2.7.9.2.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.990</td>
</tr>
<tr id="S4.T2.2.2" class="ltx_tr">
<td id="S4.T2.1.1.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.1.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.1.1.1.1.1" class="ltx_p" style="width:45.5pt;">7<sup id="S4.T2.1.1.1.1.1.1" class="ltx_sup ltx_centering"><math id="S4.T2.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\ddagger" display="inline"><semantics id="S4.T2.1.1.1.1.1.1.m1.1a"><mo id="S4.T2.1.1.1.1.1.1.m1.1.1" xref="S4.T2.1.1.1.1.1.1.m1.1.1.cmml">‡</mo><annotation-xml encoding="MathML-Content" id="S4.T2.1.1.1.1.1.1.m1.1b"><ci id="S4.T2.1.1.1.1.1.1.m1.1.1.cmml" xref="S4.T2.1.1.1.1.1.1.m1.1.1">‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.1.1.1.1.1.1.m1.1c">\ddagger</annotation></semantics></math></sup></span>
</span>
</td>
<td id="S4.T2.2.2.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.2.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.2.2.2.1.1" class="ltx_p" style="width:45.5pt;">7<sup id="S4.T2.2.2.2.1.1.1" class="ltx_sup ltx_centering"><math id="S4.T2.2.2.2.1.1.1.m1.1" class="ltx_Math" alttext="\ddagger" display="inline"><semantics id="S4.T2.2.2.2.1.1.1.m1.1a"><mo id="S4.T2.2.2.2.1.1.1.m1.1.1" xref="S4.T2.2.2.2.1.1.1.m1.1.1.cmml">‡</mo><annotation-xml encoding="MathML-Content" id="S4.T2.2.2.2.1.1.1.m1.1b"><ci id="S4.T2.2.2.2.1.1.1.m1.1.1.cmml" xref="S4.T2.2.2.2.1.1.1.m1.1.1">‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.2.2.2.1.1.1.m1.1c">\ddagger</annotation></semantics></math></sup></span>
</span>
</td>
<td id="S4.T2.2.2.3" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">–</td>
<td id="S4.T2.2.2.4" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">7</td>
<td id="S4.T2.2.2.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.2.2.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.2.2.5.1.1" class="ltx_p" style="width:51.2pt;">5891</span>
</span>
</td>
<td id="S4.T2.2.2.6" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">1476</td>
<td id="S4.T2.2.2.7" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">94.82</td>
<td id="S4.T2.2.2.8" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.945</td>
</tr>
<tr id="S4.T2.7.10.3" class="ltx_tr">
<td id="S4.T2.7.10.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.7.10.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.7.10.3.1.1.1" class="ltx_p" style="width:45.5pt;">140</span>
</span>
</td>
<td id="S4.T2.7.10.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.7.10.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.7.10.3.2.1.1" class="ltx_p" style="width:45.5pt;">140</span>
</span>
</td>
<td id="S4.T2.7.10.3.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">–</td>
<td id="S4.T2.7.10.3.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">140</td>
<td id="S4.T2.7.10.3.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.7.10.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.7.10.3.5.1.1" class="ltx_p" style="width:51.2pt;">287695</span>
</span>
</td>
<td id="S4.T2.7.10.3.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">72025</td>
<td id="S4.T2.7.10.3.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">98.25</td>
<td id="S4.T2.7.10.3.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.984</td>
</tr>
<tr id="S4.T2.7.11.4" class="ltx_tr">
<td id="S4.T2.7.11.4.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="3"><span id="S4.T2.7.11.4.1.1" class="ltx_text">Centralised</span></td>
<td id="S4.T2.7.11.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.7.11.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.7.11.4.2.1.1" class="ltx_p" style="width:45.5pt;">140</span>
</span>
</td>
<td id="S4.T2.7.11.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.7.11.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.7.11.4.3.1.1" class="ltx_p" style="width:45.5pt;">133<sup id="S4.T2.7.11.4.3.1.1.1" class="ltx_sup ltx_centering">†</sup></span>
</span>
</td>
<td id="S4.T2.7.11.4.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">–</td>
<td id="S4.T2.7.11.4.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">1</td>
<td id="S4.T2.7.11.4.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.7.11.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.7.11.4.6.1.1" class="ltx_p" style="width:51.2pt;">287695</span>
</span>
</td>
<td id="S4.T2.7.11.4.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">70549</td>
<td id="S4.T2.7.11.4.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">98.41</td>
<td id="S4.T2.7.11.4.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.988</td>
</tr>
<tr id="S4.T2.3.3" class="ltx_tr">
<td id="S4.T2.3.3.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.3.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.3.2.1.1" class="ltx_p" style="width:45.5pt;">140</span>
</span>
</td>
<td id="S4.T2.3.3.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.3.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.3.1.1.1" class="ltx_p" style="width:45.5pt;">7<sup id="S4.T2.3.3.1.1.1.1" class="ltx_sup ltx_centering"><math id="S4.T2.3.3.1.1.1.1.m1.1" class="ltx_Math" alttext="\ddagger" display="inline"><semantics id="S4.T2.3.3.1.1.1.1.m1.1a"><mo id="S4.T2.3.3.1.1.1.1.m1.1.1" xref="S4.T2.3.3.1.1.1.1.m1.1.1.cmml">‡</mo><annotation-xml encoding="MathML-Content" id="S4.T2.3.3.1.1.1.1.m1.1b"><ci id="S4.T2.3.3.1.1.1.1.m1.1.1.cmml" xref="S4.T2.3.3.1.1.1.1.m1.1.1">‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.3.3.1.1.1.1.m1.1c">\ddagger</annotation></semantics></math></sup></span>
</span>
</td>
<td id="S4.T2.3.3.3" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">–</td>
<td id="S4.T2.3.3.4" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">1</td>
<td id="S4.T2.3.3.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.3.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.3.3.5.1.1" class="ltx_p" style="width:51.2pt;">287695</span>
</span>
</td>
<td id="S4.T2.3.3.6" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">1476</td>
<td id="S4.T2.3.3.7" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">93.39</td>
<td id="S4.T2.3.3.8" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.943</td>
</tr>
<tr id="S4.T2.7.12.5" class="ltx_tr">
<td id="S4.T2.7.12.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.7.12.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.7.12.5.1.1.1" class="ltx_p" style="width:45.5pt;">140</span>
</span>
</td>
<td id="S4.T2.7.12.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.7.12.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.7.12.5.2.1.1" class="ltx_p" style="width:45.5pt;">140</span>
</span>
</td>
<td id="S4.T2.7.12.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">–</td>
<td id="S4.T2.7.12.5.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">1</td>
<td id="S4.T2.7.12.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.7.12.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.7.12.5.5.1.1" class="ltx_p" style="width:51.2pt;">287695</span>
</span>
</td>
<td id="S4.T2.7.12.5.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">72025</td>
<td id="S4.T2.7.12.5.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">98.01</td>
<td id="S4.T2.7.12.5.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.983</td>
</tr>
<tr id="S4.T2.7.13.6" class="ltx_tr">
<td id="S4.T2.7.13.6.1" class="ltx_td ltx_align_left ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;" rowspan="3"><span id="S4.T2.7.13.6.1.1" class="ltx_text">FL benchmark</span></td>
<td id="S4.T2.7.13.6.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.7.13.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.7.13.6.2.1.1" class="ltx_p" style="width:45.5pt;">140</span>
</span>
</td>
<td id="S4.T2.7.13.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.7.13.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.7.13.6.3.1.1" class="ltx_p" style="width:45.5pt;">133<sup id="S4.T2.7.13.6.3.1.1.1" class="ltx_sup ltx_centering">†</sup></span>
</span>
</td>
<td id="S4.T2.7.13.6.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">140</td>
<td id="S4.T2.7.13.6.5" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">1</td>
<td id="S4.T2.7.13.6.6" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.7.13.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.7.13.6.6.1.1" class="ltx_p" style="width:51.2pt;">287695</span>
</span>
</td>
<td id="S4.T2.7.13.6.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">70549</td>
<td id="S4.T2.7.13.6.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">95.89</td>
<td id="S4.T2.7.13.6.9" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.967</td>
</tr>
<tr id="S4.T2.4.4" class="ltx_tr">
<td id="S4.T2.4.4.2" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.4.4.2.1.1" class="ltx_p" style="width:45.5pt;">140</span>
</span>
</td>
<td id="S4.T2.4.4.1" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.4.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.4.4.1.1.1" class="ltx_p" style="width:45.5pt;">7<sup id="S4.T2.4.4.1.1.1.1" class="ltx_sup ltx_centering"><math id="S4.T2.4.4.1.1.1.1.m1.1" class="ltx_Math" alttext="\ddagger" display="inline"><semantics id="S4.T2.4.4.1.1.1.1.m1.1a"><mo id="S4.T2.4.4.1.1.1.1.m1.1.1" xref="S4.T2.4.4.1.1.1.1.m1.1.1.cmml">‡</mo><annotation-xml encoding="MathML-Content" id="S4.T2.4.4.1.1.1.1.m1.1b"><ci id="S4.T2.4.4.1.1.1.1.m1.1.1.cmml" xref="S4.T2.4.4.1.1.1.1.m1.1.1">‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.4.4.1.1.1.1.m1.1c">\ddagger</annotation></semantics></math></sup></span>
</span>
</td>
<td id="S4.T2.4.4.3" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">140</td>
<td id="S4.T2.4.4.4" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">1</td>
<td id="S4.T2.4.4.5" class="ltx_td ltx_align_justify ltx_align_top" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.4.4.5.1.1" class="ltx_p" style="width:51.2pt;">287695</span>
</span>
</td>
<td id="S4.T2.4.4.6" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">1476</td>
<td id="S4.T2.4.4.7" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">92.15</td>
<td id="S4.T2.4.4.8" class="ltx_td ltx_align_center" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.932</td>
</tr>
<tr id="S4.T2.5.5" class="ltx_tr">
<td id="S4.T2.5.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.5.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.5.5.1.1.1" class="ltx_p" style="width:45.5pt;"><math id="S4.T2.5.5.1.1.1.m1.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="S4.T2.5.5.1.1.1.m1.1a"><mi id="S4.T2.5.5.1.1.1.m1.1.1" xref="S4.T2.5.5.1.1.1.m1.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="S4.T2.5.5.1.1.1.m1.1b"><ci id="S4.T2.5.5.1.1.1.m1.1.1.cmml" xref="S4.T2.5.5.1.1.1.m1.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.5.5.1.1.1.m1.1c">\mu</annotation></semantics></math></span>
</span>
</td>
<td id="S4.T2.5.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.5.5.2.1.1" class="ltx_p" style="width:45.5pt;">140</span>
</span>
</td>
<td id="S4.T2.5.5.3" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">–</td>
<td id="S4.T2.5.5.4" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">–</td>
<td id="S4.T2.5.5.5" class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">
<span id="S4.T2.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S4.T2.5.5.5.1.1" class="ltx_p" style="width:51.2pt;">287695</span>
</span>
</td>
<td id="S4.T2.5.5.6" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">72025</td>
<td id="S4.T2.5.5.7" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">94.02</td>
<td id="S4.T2.5.5.8" class="ltx_td ltx_align_center ltx_border_t" style="padding-top:0.5pt;padding-bottom:0.5pt;">0.949</td>
</tr>
<tr id="S4.T2.7.14.7" class="ltx_tr">
<td id="S4.T2.7.14.7.1" class="ltx_td ltx_align_left ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;" colspan="8">
<sup id="S4.T2.7.14.7.1.1" class="ltx_sup">†</sup>actual normal case</td>
<td id="S4.T2.7.14.7.2" class="ltx_td ltx_border_tt" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
</tr>
<tr id="S4.T2.6.6" class="ltx_tr">
<td id="S4.T2.6.6.1" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;" colspan="8">
<sup id="S4.T2.6.6.1.1" class="ltx_sup"><math id="S4.T2.6.6.1.1.m1.1" class="ltx_Math" alttext="\ddagger" display="inline"><semantics id="S4.T2.6.6.1.1.m1.1a"><mo id="S4.T2.6.6.1.1.m1.1.1" xref="S4.T2.6.6.1.1.m1.1.1.cmml">‡</mo><annotation-xml encoding="MathML-Content" id="S4.T2.6.6.1.1.m1.1b"><ci id="S4.T2.6.6.1.1.m1.1.1.cmml" xref="S4.T2.6.6.1.1.m1.1.1">‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.6.6.1.1.m1.1c">\ddagger</annotation></semantics></math></sup>actual edge case</td>
<td id="S4.T2.6.6.2" class="ltx_td" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
</tr>
<tr id="S4.T2.7.7" class="ltx_tr">
<td id="S4.T2.7.7.1" class="ltx_td ltx_align_left" style="padding-top:0.5pt;padding-bottom:0.5pt;" colspan="8">
<math id="S4.T2.7.7.1.m1.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="S4.T2.7.7.1.m1.1a"><mi id="S4.T2.7.7.1.m1.1.1" xref="S4.T2.7.7.1.m1.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="S4.T2.7.7.1.m1.1b"><ci id="S4.T2.7.7.1.m1.1.1.cmml" xref="S4.T2.7.7.1.m1.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.7.7.1.m1.1c">\mu</annotation></semantics></math> average of models</td>
<td id="S4.T2.7.7.2" class="ltx_td" style="padding-top:0.5pt;padding-bottom:0.5pt;"></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.F3" class="ltx_figure"><img src="/html/2208.12996/assets/x2.png" id="S4.F3.g1" class="ltx_graphics ltx_img_landscape" width="368" height="185" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>. </span><span id="S4.F3.3.2" class="ltx_text" style="font-size:90%;">Flowchart of Proposed Approach for Personalised Federated Learning</span></figcaption>
</figure>
<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.6" class="ltx_p">Our results are summarised in Table <a href="#S4.T2" title="Table 2 ‣ 4.1. Results for all Training/Testing Methods ‣ 4. Experimental Evaluation ‣ A Federated Learning-enabled Smart Street Light Monitoring Application: Benefits and Future Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Considering the “normal” nodes, as expected, the fully personalised and centralised methods generated higher accuracy (<math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="98.57\%" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mrow id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mn id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">98.57</mn><mo id="S4.SS1.p1.1.m1.1.1.1" xref="S4.SS1.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS1.p1.1.m1.1.1.2.cmml" xref="S4.SS1.p1.1.m1.1.1.2">98.57</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">98.57\%</annotation></semantics></math> and <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="98.41\%" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><mrow id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mn id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml">98.41</mn><mo id="S4.SS1.p1.2.m2.1.1.1" xref="S4.SS1.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><csymbol cd="latexml" id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1.1">percent</csymbol><cn type="float" id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2">98.41</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">98.41\%</annotation></semantics></math> respectively) and F1-scores (<math id="S4.SS1.p1.3.m3.1" class="ltx_Math" alttext="0.99" display="inline"><semantics id="S4.SS1.p1.3.m3.1a"><mn id="S4.SS1.p1.3.m3.1.1" xref="S4.SS1.p1.3.m3.1.1.cmml">0.99</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.3.m3.1b"><cn type="float" id="S4.SS1.p1.3.m3.1.1.cmml" xref="S4.SS1.p1.3.m3.1.1">0.99</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.3.m3.1c">0.99</annotation></semantics></math> and <math id="S4.SS1.p1.4.m4.1" class="ltx_Math" alttext="0.988" display="inline"><semantics id="S4.SS1.p1.4.m4.1a"><mn id="S4.SS1.p1.4.m4.1.1" xref="S4.SS1.p1.4.m4.1.1.cmml">0.988</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.4.m4.1b"><cn type="float" id="S4.SS1.p1.4.m4.1.1.cmml" xref="S4.SS1.p1.4.m4.1.1">0.988</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.4.m4.1c">0.988</annotation></semantics></math> respectively) than the benchmark FL method (accuracy of <math id="S4.SS1.p1.5.m5.1" class="ltx_Math" alttext="96.7\%" display="inline"><semantics id="S4.SS1.p1.5.m5.1a"><mrow id="S4.SS1.p1.5.m5.1.1" xref="S4.SS1.p1.5.m5.1.1.cmml"><mn id="S4.SS1.p1.5.m5.1.1.2" xref="S4.SS1.p1.5.m5.1.1.2.cmml">96.7</mn><mo id="S4.SS1.p1.5.m5.1.1.1" xref="S4.SS1.p1.5.m5.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.5.m5.1b"><apply id="S4.SS1.p1.5.m5.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1"><csymbol cd="latexml" id="S4.SS1.p1.5.m5.1.1.1.cmml" xref="S4.SS1.p1.5.m5.1.1.1">percent</csymbol><cn type="float" id="S4.SS1.p1.5.m5.1.1.2.cmml" xref="S4.SS1.p1.5.m5.1.1.2">96.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.5.m5.1c">96.7\%</annotation></semantics></math> and F1-score of <math id="S4.SS1.p1.6.m6.1" class="ltx_Math" alttext="0.967" display="inline"><semantics id="S4.SS1.p1.6.m6.1a"><mn id="S4.SS1.p1.6.m6.1.1" xref="S4.SS1.p1.6.m6.1.1.cmml">0.967</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.6.m6.1b"><cn type="float" id="S4.SS1.p1.6.m6.1.1.cmml" xref="S4.SS1.p1.6.m6.1.1">0.967</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.6.m6.1c">0.967</annotation></semantics></math>). Both methods were allowed to train until fully converged (with minimal overfitting).</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">The difference is less prominent when the “edge” nodes (node type 2) are considered. Again, personalised and centralised methods slightly outperform FL, but only by a couple of percentage points. The above results are due to having either access to the entire dataset with a single model to train (centralised) or having each client train on a single lamppost’s datasets (fully personalised method).</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Discussion and Observations</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Whilst the personalised method fractionally outperformed the centralised and FL training methods, it still achieved a lower accuracy and F1-score than required for immediate deployment. Considering a city-scale deployment, such a system will still produce false positives/negatives at a rate not easily monitored by local government officials. Even at the fairly limited coverage provided within our dataset (140 nodes and lampposts), an error rate of <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="1.75\%" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mn id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">1.75</mn><mo id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><csymbol cd="latexml" id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">1.75</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">1.75\%</annotation></semantics></math> will result in tens if not more daily alerts. Given the diversity of the node types and camera locations, more sophisticated classification algorithms are required for better accuracy. For example, taking into account multiple concurrent decisions can reduce the error rate as falsely classified results will be the minority of the reported values.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">The “fully” personalised method relies on having a large enough amount of data stored locally on the lamppost edge device for individual training. This constitutes a significant problem when considering the resource-constrained nature of the current IoT devices or when “new” lampposts join the network (as there is no available global model).</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">Considering the centralised classification, as seen, it performs almost as well as the fully personalised method. However, it relies on having all the lamppost data transferred to a central server for processing and training. Currently, the entire compressed lamppost dataset is circa <math id="S4.SS2.p3.1.m1.1" class="ltx_Math" alttext="150" display="inline"><semantics id="S4.SS2.p3.1.m1.1a"><mn id="S4.SS2.p3.1.m1.1.1" xref="S4.SS2.p3.1.m1.1.1.cmml">150</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p3.1.m1.1b"><cn type="integer" id="S4.SS2.p3.1.m1.1.1.cmml" xref="S4.SS2.p3.1.m1.1.1">150</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p3.1.m1.1c">150</annotation></semantics></math>GB in volume. Admittedly, this is without any of our pre-processing and dimensionality reduction techniques applied to the images. However, this is still a good indication of the costly nature of exchanging such a large volume of data. Furthermore, this will also result in privacy and confidentiality issues that may arise with the data being in transit.</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p">The benchmark FL performed the worst out of the three evaluated. This is likely due to the combination and equal weighting during aggregation of the edge case nodes (i.e., type 2). The FL method was several percentage points lower in accuracy and F1-score than the personalised and centralised methods. However, such a method provides not only increased data privacy but also a global model too, ready to be used for initialising training or inference on a new lamppost/edge device joining the network. Therefore, gaining some scalability advantage and drastically reducing the overall data communication volume during training.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Conclusions and Future Research</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we evaluated three different methods of detecting lamppost operability in a smart city environment. As seen, a “fully” personalised method provides a strong performance but does not scale well. On the other hand, a centralised approach is very demanding on the communication overhead introduced. FL can provide benefits of both worlds but still lacks in terms of accuracy. We suggest the following for future FL and personalised FL research challenges:</p>
</div>
<div id="S5.p2" class="ltx_para">
<ol id="S5.I1" class="ltx_enumerate">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(i)</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p">We are currently experimenting with a “tuned” personalised method, whereby certain model layers are trained and optimised solely on each device and dataset. In contrast, the remaining model layers are used for aggregation when receiving updates from the global FL parameter server. Work is still ongoing, with promising results regarding accuracy observed and the reduction of communication costs.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(ii)</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p">Clustered personalised FL based on client model parameters received at the FL parameter server (proposed method shown in Figure <a href="#S4.F3" title="Figure 3 ‣ 4.1. Results for all Training/Testing Methods ‣ 4. Experimental Evaluation ‣ A Federated Learning-enabled Smart Street Light Monitoring Application: Benefits and Future Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>). Ideally, this would allow for early detection of the lamppost node types, which could then be separately aggregated into multiple (but concurrent) FL global models. Any new connected lamppost joining the network could receive a copy of each FL global model and run local tests to evaluate performance on its local dataset before conducting local training/tuning optimisation. Early experiments suggest it is possible to detect and classify extreme edge case nodes (i.e., node type 2) fairly accurately, but we fail to detect the other node types. Whilst having only two global models for FL would work, ideally, we want to personalise the clusters to the extent that we achieve even higher accuracies, again to drastically reduce notifications/alerts received by the government officials monitoring the system and prioritising lampposts for maintenance.</p>
</div>
</li>
<li id="S5.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(iii)</span> 
<div id="S5.I1.i3.p1" class="ltx_para">
<p id="S5.I1.i3.p1.1" class="ltx_p">Given the hypothesised upper bound of performance (currently, the personalised method achieved an averaged F1-score of 0.98), it may suggest that further FL personalisation strategies may struggle to gain significant improvements. As such, in particular with ML, often the dataset might be limiting in terms of achieving such a high performance; for example details/nuances might be missed or averaged out when the images are drastically reduced in size during our pre-processing step (see Figure <a href="#S3.F2" title="Figure 2 ‣ 3.4. Data Pre-Processing ‣ 3. Methodology And Experiments ‣ A Federated Learning-enabled Smart Street Light Monitoring Application: Benefits and Future Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). Consequently, we have been experimenting with image metadata and other image statistics, particularly the mean and median green pixel values. Our intuition is that in extreme edge cases, where the lighting element is not visible to the monitoring sensor camera, small amounts of reflected light (or remnants of refracted light through vegetation) might be detectable. Our preliminary experiments using such metadata to improve detection accuracy have proven relatively successful but need careful calibration and integration into a robust and scalable personalised FL method.</p>
</div>
</li>
<li id="S5.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(iv)</span> 
<div id="S5.I1.i4.p1" class="ltx_para">
<p id="S5.I1.i4.p1.1" class="ltx_p">Communication overhead in FL can be further improved by introducing selective update strategies, such as dynamic sampling or selective masking on the models exchanged <cite class="ltx_cite ltx_citemacro_citep">(Anwar
et al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2022a</a>; Ji
et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2022</a>)</cite>. Such methods can enhance the system’s scalability, mainly when introducing thousands of clients. Furthermore, adaptive compression on the generated models <cite class="ltx_cite ltx_citemacro_citep">(Anwar
et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2022b</a>; Hardy
et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2017</a>)</cite> can bring even more benefits by reducing the communication overhead and enabling the exchange of data over low data rate IoT technologies and longer distances.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
This work is funded in part by Toshiba Europe Ltd. UMBRELLA project is funded in conjunction with South Gloucestershire Council by the West of England Local Enterprise Partnership through the Local Growth Fund, administered by the West of England Combined Authority.

</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anwar
et al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Saif Anwar, Pietro E
Carnelli, and Aftab Khan.
2022a.

</span>
<span class="ltx_bibblock">Methods and Systems for Remote Training of a Machine
Learning Model.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">US Patent App. 16/952,308.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anwar
et al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Saif Anwar, Pietro E
Carnelli, and Aftab Khan.
2022b.

</span>
<span class="ltx_bibblock">System and Method for Adaptive Compression in
Federated Learning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">US Patent App. 16/952,705.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen
et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
F. Chen, M. Luo,
Z. Dong, Z. Li, and X.
He. 2018.

</span>
<span class="ltx_bibblock">Federated meta-learning with fast convergence and
efficient communication.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">arXiv preprint</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ding
et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Jie Ding, Mahyar Nemati,
Chathurika Ranaweera, and Jinho Choi.
2020.

</span>
<span class="ltx_bibblock">IoT Connectivity Technologies and Applications: A
Survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.3.1" class="ltx_emph ltx_font_italic">IEEE Access</em> 8
(2020), 67646–67673.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/ACCESS.2020.2985932" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ACCESS.2020.2985932</a>

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Farnham et al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Tim Farnham, Simon Jones,
Adnan Aijaz, Yichao Jin,
Ioannis Mavromatis, Usman Raza,
Anthony Portelli, Aleksandar Stanoev,
and Mahesh Sooriyabandara.
2021.

</span>
<span class="ltx_bibblock">UMBRELLA Collaborative Robotics Testbed and IoT
Platform. In <em id="bib.bib6.3.1" class="ltx_emph ltx_font_italic">2021 IEEE 18th Annual Consumer
Communications and Networking Conference (CCNC)</em>. IEEE,
1–7.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/CCNC49032.2021.9369615" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/CCNC49032.2021.9369615</a>

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hardy
et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
C. Hardy, E. Le Merrer,
and B. Sericola. 2017.

</span>
<span class="ltx_bibblock">Distributed Deep Learning on Edge-Devices:
Feasibility via Adaptive Compression. In <em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">2017
IEEE 16th International Symposium on Network Computing and Applications
(NCA)</em>. IEEE Computer Society, Los
Alamitos, CA, USA, 1–8.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/NCA.2017.8171350" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/NCA.2017.8171350</a>

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He
et al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Kaiming He, Xiangyu
Zhang, Shaoqing Ren, and Jian Sun.
2015.

</span>
<span class="ltx_bibblock">Deep Residual Learning for Image Recognition.

</span>
<span class="ltx_bibblock">(12 2015).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji
et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
S. Ji, W. Jiang,
A. Walid, and X. Li.
2022.

</span>
<span class="ltx_bibblock">Dynamic Sampling and Selective Masking for
Communication-Efficient Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Systems</em>
37, 02 (mar
2022), 27–34.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/MIS.2021.3114610" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/MIS.2021.3114610</a>

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khan et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Aftab Khan, Pietro E
Carnelli, Timothy David Farnham, Ioannis
Mavromatis, and Anthony Portelli.
2022.

</span>
<span class="ltx_bibblock">System and Method for Detecting and Rectifying
Concept Drift in Federated Learning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">US Patent App. 17/018,923.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee
et al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Yanming Lee, Hongyi
Zhang, and Jimmi Rosa. 2019.

</span>
<span class="ltx_bibblock">Street Lamp Fault Diagnosis System Based on Extreme
Learning Machine.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.3.1" class="ltx_emph ltx_font_italic">IOP Conference Series: Materials Science
and Engineering</em> 490 (apr
2019), 042053.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1088/1757-899x/490/4/042053" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1088/1757-899x/490/4/042053</a>

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Hui Lin, Wenxin Liu,
and Xiaoding Wang. 2021.

</span>
<span class="ltx_bibblock">A Secure Federated Learning Mechanism for Data
Privacy Protection. In <em id="bib.bib12.3.1" class="ltx_emph ltx_font_italic">2021 20th International
Conference on Ubiquitous Computing and Communications
(IUCC/CIT/DSCI/SmartCNS)</em>. 25–31.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/IUCC-CIT-DSCI-SmartCNS55181.2021.00019" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/IUCC-CIT-DSCI-SmartCNS55181.2021.00019</a>

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marsal-Llacuna et al<span id="bib.bib13.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
M-Lluïsa Marsal-Llacuna,
J. Colomer-Llinàs, and J.
Meléndez-Frigola. 2015.

</span>
<span class="ltx_bibblock">Lessons in urban monitoring taken from sustainable
and livable cities to better address the Smart Cities initiative.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.3.1" class="ltx_emph ltx_font_italic">Technological Forecasting and Social Change</em>
90 (2015), 611–622.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mavromatis et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Ioannis Mavromatis,
Aleksandar Stanoev, Pietro Carnelli,
Yichao Jin, Mahesh Sooriyabandara, and
Aftab Khan. 2022a.

</span>
<span class="ltx_bibblock">A Dataset of Images of Public Streetlights with
Operational Monitoring using Computer Vision Techniques.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/ARXIV.2203.16915" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/ARXIV.2203.16915</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mavromatis et al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Ioannis Mavromatis,
Aleksandar Stanoev, Pietro Carnelli,
Yichao Jin, Mahesh Sooriyabandara, and
Aftab Khan. 2022b.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.3.1" class="ltx_emph ltx_font_italic">Images of Public Streetlights with
Operational Monitoring using Computer Vision Techniques</em>.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.5281/zenodo.6046759" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.5281/zenodo.6046759</a>

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al<span id="bib.bib16.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
H. Brendan McMahan, Eider
Moore, Daniel Ramage, Seth Hampson,
and Blaise Agüera y Arcas.
2016.

</span>
<span class="ltx_bibblock">Communication-Efficient Learning of Deep Networks
from Decentralized Data.

</span>
<span class="ltx_bibblock">(2 2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouadrhiri and
Abdelhadi (2022)</span>
<span class="ltx_bibblock">
Ahmed El Ouadrhiri and
Ahmed Abdelhadi. 2022.

</span>
<span class="ltx_bibblock">Differential Privacy for Deep and Federated
Learning: A Survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">IEEE Access</em> 10
(2022), 22359–22380.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/ACCESS.2022.3151670" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ACCESS.2022.3151670</a>

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schneider and
Vlachos (2021)</span>
<span class="ltx_bibblock">
Johannes Schneider and
Michalis Vlachos. 2021.

</span>
<span class="ltx_bibblock">Personalization of Deep Learning. In
<em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">Data Science – Analytics and Applications</em>,
Peter Haber, Thomas
Lampoltshammer, Manfred Mayr, and
Kathrin Plankensteiner (Eds.).
Springer Fachmedien Wiesbaden,
Wiesbaden, 89–96.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Silva
et al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Bhagya Nathali Silva,
Murad Khan, and Kijun Han.
2018.

</span>
<span class="ltx_bibblock">Towards Sustainable Smart Cities: A Review of
Trends, Architectures, Components, and Open Challenges in Smart Cities.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.3.1" class="ltx_emph ltx_font_italic">Sustainable Cities and Society</em>
38 (2018), 697–713.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/j.scs.2018.01.053" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.scs.2018.01.053</a>

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su et al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2011)</span>
<span class="ltx_bibblock">
Kehua Su, Jie Li, and
Hongbo Fu. 2011.

</span>
<span class="ltx_bibblock">Smart City and The Applications. In
<em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">2011 International Conference on Electronics,
Communications and Control (ICECC)</em>. 1028–1031.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/ICECC.2011.6066743" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICECC.2011.6066743</a>

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang
et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Dongjun Tang, Fulai Ding,
Boya Deng, Pingkang Zhang,
Qingming Wang, and Hui Lv.
2021.

</span>
<span class="ltx_bibblock">An Intelligent Fault Diagnosis Method for Street
Lamps. In <em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">2021 International Conference on
Internet, Education and Information Technology (IEIT)</em>.
300–303.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/IEIT53597.2021.00073" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/IEIT53597.2021.00073</a>

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Umamaheswari
et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
S. Umamaheswari, K.Hari
Priya, and S.Arun Kumar.
2021.

</span>
<span class="ltx_bibblock">Technologies Used in Smart City Applications –
An Overview. In <em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">2021 International Conference on
Advancements in Electrical, Electronics, Communication, Computing and
Automation (ICAECA)</em>. 1–6.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/ICAECA52838.2021.9675707" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICAECA52838.2021.9675707</a>

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Y. Huang et al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Y. Huang, L. Chu,
Z. Zhou, L. Wang,
J. Liu, J. Pei, and
Y. Zhang. 2021.

</span>
<span class="ltx_bibblock">Personalized cross-silo federated learning on
non-iid data.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">Association for the Advancement of Artificial
Intelligence (AAAI)</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang
et al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yu-Sheng Yang, Shih-Hsiung
Lee, Guan-Sheng Chen, Chu-Sing Yang,
Yueh-Min Huang, and Ting-Wei Hou.
2020.

</span>
<span class="ltx_bibblock">An Implementation of High Efficient Smart Street
Light Management System for Smart City.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.3.1" class="ltx_emph ltx_font_italic">IEEE Access</em> 8
(2020), 38568–38585.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/ACCESS.2020.2975708" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ACCESS.2020.2975708</a>

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zanella et al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Andrea Zanella, Nicola
Bui, Angelo Castellani, Lorenzo
Vangelista, and Michele Zorzi.
2014.

</span>
<span class="ltx_bibblock">Internet of Things for Smart Cities.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.3.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>
1, 1 (2014),
22–32.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1109/JIOT.2014.2306328" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/JIOT.2014.2306328</a>

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao
et al<span id="bib.bib26.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Yue Zhao, Meng Li,
Liangzhen Lai, Naveen Suda,
Damon Civin, and Vikas Chandra.
2018.

</span>
<span class="ltx_bibblock">Federated Learning with Non-IID Data.

</span>
<span class="ltx_bibblock">(6 2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng
et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Zhaohua Zheng, Yize Zhou,
Yilong Sun, Zhang Wang,
Boyi Liu, and Keqiu Li.
2022.

</span>
<span class="ltx_bibblock">Applications of Federated Learning in Smart
Cities: Recent Advances, Taxonomy, and Open Challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.3.1" class="ltx_emph ltx_font_italic">Connection Science</em> 34,
1 (2022), 1–28.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1080/09540091.2021.1936455" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1080/09540091.2021.1936455</a>

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2208.12995" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2208.12996" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2208.12996">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2208.12996" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2208.12997" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Mar 13 20:11:04 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
