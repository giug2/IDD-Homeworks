<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2204.09715] Scaling Language Model Size in Cross-Device Federated Learning</title><meta property="og:description" content="Most studies in cross-device federated learning focus on small models, due to the server-client communication and on-device computation bottlenecks. In this work, we leverage various techniques for mitigating these bot…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Scaling Language Model Size in Cross-Device Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Scaling Language Model Size in Cross-Device Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2204.09715">

<!--Generated on Wed Feb 28 06:18:15 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on  Google .-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Scaling Language Model Size in Cross-Device Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jae Hun Ro<sup id="id7.2.id1" class="ltx_sup">∗</sup>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Theresa Breiner
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Lara McConnaughey
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mingqing Chen
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ananda Theertha Suresh
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Shankar Kumar
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Rajiv Mathews
</span></span>
</div>
<div class="ltx_dates">( Google 
<br class="ltx_break">
<sup id="id8.id1" class="ltx_sup">∗</sup><span id="id9.id2" class="ltx_text ltx_font_typewriter">jaero@google.com</span>
)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id6.4" class="ltx_p">Most studies in cross-device federated learning focus on small models, due to the server-client communication and on-device computation bottlenecks. In this work, we leverage various techniques for mitigating these bottlenecks to train larger language models in cross-device federated learning. With systematic applications of partial model training, quantization, efficient transfer learning, and communication-efficient optimizers, we are able to train a <math id="id3.1.m1.1" class="ltx_Math" alttext="21" display="inline"><semantics id="id3.1.m1.1a"><mn id="id3.1.m1.1.1" xref="id3.1.m1.1.1.cmml">21</mn><annotation-xml encoding="MathML-Content" id="id3.1.m1.1b"><cn type="integer" id="id3.1.m1.1.1.cmml" xref="id3.1.m1.1.1">21</cn></annotation-xml><annotation encoding="application/x-tex" id="id3.1.m1.1c">21</annotation></semantics></math>M parameter Transformer and <math id="id4.2.m2.1" class="ltx_Math" alttext="20.2" display="inline"><semantics id="id4.2.m2.1a"><mn id="id4.2.m2.1.1" xref="id4.2.m2.1.1.cmml">20.2</mn><annotation-xml encoding="MathML-Content" id="id4.2.m2.1b"><cn type="float" id="id4.2.m2.1.1.cmml" xref="id4.2.m2.1.1">20.2</cn></annotation-xml><annotation encoding="application/x-tex" id="id4.2.m2.1c">20.2</annotation></semantics></math>M parameter Conformer that achieve the same or better perplexity as that of a similarly sized LSTM with <math id="id5.3.m3.1" class="ltx_math_unparsed" alttext="\sim 10\times" display="inline"><semantics id="id5.3.m3.1a"><mrow id="id5.3.m3.1b"><mo id="id5.3.m3.1.1">∼</mo><mn id="id5.3.m3.1.2">10</mn><mo lspace="0.222em" id="id5.3.m3.1.3">×</mo></mrow><annotation encoding="application/x-tex" id="id5.3.m3.1c">\sim 10\times</annotation></semantics></math> smaller client-to-server communication cost and <math id="id6.4.m4.1" class="ltx_Math" alttext="11\%" display="inline"><semantics id="id6.4.m4.1a"><mrow id="id6.4.m4.1.1" xref="id6.4.m4.1.1.cmml"><mn id="id6.4.m4.1.1.2" xref="id6.4.m4.1.1.2.cmml">11</mn><mo id="id6.4.m4.1.1.1" xref="id6.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="id6.4.m4.1b"><apply id="id6.4.m4.1.1.cmml" xref="id6.4.m4.1.1"><csymbol cd="latexml" id="id6.4.m4.1.1.1.cmml" xref="id6.4.m4.1.1.1">percent</csymbol><cn type="integer" id="id6.4.m4.1.1.2.cmml" xref="id6.4.m4.1.1.2">11</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id6.4.m4.1c">11\%</annotation></semantics></math> lower perplexity than smaller LSTMs commonly studied in literature.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Federated learning is a distributed training technique, where a model is trained on data distributed across clients or edge devices without user-generated data ever leaving the device, providing an additional layer of privacy and security <cite class="ltx_cite ltx_citemacro_citep">(Konečnỳ et al., <a href="#bib.bib30" title="" class="ltx_ref">2016b</a>, <a href="#bib.bib29" title="" class="ltx_ref">a</a>; McMahan et al., <a href="#bib.bib38" title="" class="ltx_ref">2017</a>)</cite>.
We refer readers to <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a href="#bib.bib35" title="" class="ltx_ref">2020</a>); Kairouz et al. (<a href="#bib.bib24" title="" class="ltx_ref">2021</a>)</cite> for a detailed literature survey on federated learning.
Federated learning has been used in several applications including virtual keyboard applications <cite class="ltx_cite ltx_citemacro_citep">(Hard et al., <a href="#bib.bib18" title="" class="ltx_ref">2018</a>)</cite>, keyword spotting <cite class="ltx_cite ltx_citemacro_citep">(Hard et al., <a href="#bib.bib19" title="" class="ltx_ref">2020</a>)</cite>, and healthcare <cite class="ltx_cite ltx_citemacro_citep">(Brisimi et al., <a href="#bib.bib4" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Language models (LM) have many uses in language-based applications including virtual keyboard <cite class="ltx_cite ltx_citemacro_citep">(Chen et al., <a href="#bib.bib9" title="" class="ltx_ref">2019</a>; Zhang et al., <a href="#bib.bib57" title="" class="ltx_ref">2021</a>)</cite> and automatic speech recognition <cite class="ltx_cite ltx_citemacro_citep">(Kannan et al., <a href="#bib.bib25" title="" class="ltx_ref">2018</a>; Variani et al., <a href="#bib.bib52" title="" class="ltx_ref">2020</a>; Gruenstein et al., <a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite>.
Recently, there has been increased interest in training progressively larger and deeper LMs with impressive quality improvements in downstream tasks, including question answering, text classification, and text summarization <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al., <a href="#bib.bib12" title="" class="ltx_ref">2019</a>; Dai et al., <a href="#bib.bib11" title="" class="ltx_ref">2019</a>; Yang et al., <a href="#bib.bib56" title="" class="ltx_ref">2019</a>; Irie et al., <a href="#bib.bib23" title="" class="ltx_ref">2019</a>; Kaplan et al., <a href="#bib.bib26" title="" class="ltx_ref">2020</a>)</cite>.
These models tend to be variants of the Transformer <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a href="#bib.bib53" title="" class="ltx_ref">2017</a>)</cite>. Recently, Conformer models, which employ convolution layers in Transformer-based architectures, have also been proposed <cite class="ltx_cite ltx_citemacro_citep">(Gulati et al., <a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Federated learning is typically studied in two scenarios: <em id="S1.p3.1.1" class="ltx_emph ltx_font_italic">cross-silo</em>, where the number of clients is small, and <em id="S1.p3.1.2" class="ltx_emph ltx_font_italic">cross-device</em>, where the number of clients can be in the order of millions <cite class="ltx_cite ltx_citemacro_citep">(Hard et al., <a href="#bib.bib18" title="" class="ltx_ref">2018</a>)</cite>.
In this work we focus on cross-device, where devices are typically edge devices such as cell phones, with limited computation and communication capabilities.
Hence, the major benchmark LMs tend to be very limited in size <cite class="ltx_cite ltx_citemacro_citep">(McMahan et al., <a href="#bib.bib38" title="" class="ltx_ref">2017</a>, <a href="#bib.bib39" title="" class="ltx_ref">2018</a>; Caldas et al., <a href="#bib.bib6" title="" class="ltx_ref">2019a</a>; Reddi et al., <a href="#bib.bib41" title="" class="ltx_ref">2020</a>; Sim et al., <a href="#bib.bib44" title="" class="ltx_ref">2021</a>)</cite> because memory, computation, and communication are critical bottlenecks <cite class="ltx_cite ltx_citemacro_citep">(Kairouz et al., <a href="#bib.bib24" title="" class="ltx_ref">2021</a>)</cite>.
In particular, previous works that train federated LMs in production settings have used coupled input forget gate (CIFG) long short-term memory (LSTM) models with fewer than 4 million parameters <cite class="ltx_cite ltx_citemacro_citep">(Hard et al., <a href="#bib.bib18" title="" class="ltx_ref">2018</a>; Chen et al., <a href="#bib.bib9" title="" class="ltx_ref">2019</a>; Ramaswamy et al., <a href="#bib.bib40" title="" class="ltx_ref">2020</a>)</cite>.
These resource constraints have motivated research into various efficient algorithms for training larger models with federated learning <cite class="ltx_cite ltx_citemacro_citep">(Konečnỳ et al., <a href="#bib.bib30" title="" class="ltx_ref">2016b</a>; Hamer et al., <a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite>.
However, most of these techniques are still evaluated on relatively small models compared to their server-based counterparts.
In this work, we systematically evaluate multiple strategies for mitigating communication and computation costs of training larger LMs to determine if the impressive quality gains from larger models can also be achieved in cross-device federated learning.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">While there are previous works on <em id="S1.p4.1.1" class="ltx_emph ltx_font_italic">efficient</em> Transformers <cite class="ltx_cite ltx_citemacro_citep">(Tay et al., <a href="#bib.bib48" title="" class="ltx_ref">2020</a>, <a href="#bib.bib49" title="" class="ltx_ref">2021</a>)</cite>, we forgo these efficient variants as they may actually be more inefficient when sequences are short <cite class="ltx_cite ltx_citemacro_citep">(Katharopoulos et al., <a href="#bib.bib28" title="" class="ltx_ref">2020</a>; Choromanski et al., <a href="#bib.bib10" title="" class="ltx_ref">2021</a>)</cite>.
Additionally, <cite class="ltx_cite ltx_citemacro_citet">Lin et al. (<a href="#bib.bib36" title="" class="ltx_ref">2020</a>); Liu and Miller (<a href="#bib.bib37" title="" class="ltx_ref">2020</a>); Hilmkil et al. (<a href="#bib.bib20" title="" class="ltx_ref">2021</a>)</cite> trained large Transformer models in the cross-silo setting, where devices have more resources, whereas we focus on the resource-constrained cross-device setting.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Recent large LMs, such as GPT-3 <cite class="ltx_cite ltx_citemacro_cite">Brown et al. (<a href="#bib.bib5" title="" class="ltx_ref">2020</a>)</cite>, contain hundreds of billions of parameters, which is substantially bigger than the memory limits of edge devices.
Therefore in this work, we consider <em id="S1.p5.1.1" class="ltx_emph ltx_font_italic">large</em> models to be at most <math id="S1.p5.1.m1.1" class="ltx_Math" alttext="25" display="inline"><semantics id="S1.p5.1.m1.1a"><mn id="S1.p5.1.m1.1.1" xref="S1.p5.1.m1.1.1.cmml">25</mn><annotation-xml encoding="MathML-Content" id="S1.p5.1.m1.1b"><cn type="integer" id="S1.p5.1.m1.1.1.cmml" xref="S1.p5.1.m1.1.1">25</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.1.m1.1c">25</annotation></semantics></math> million parameters, which is still considerably larger than existing models trained on-device.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">The rest of the paper is organized as follows. In Section <a href="#S2" title="2 Our contributions ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we overview our contributions.
In Section <a href="#S3" title="3 Dataset and models ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we detail the dataset and models.
We then analyze techniques to reduce the per-round cost in Section <a href="#S4" title="4 Cost per round ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, and the number of communication rounds in Section <a href="#S5" title="5 Number of communication rounds ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.
Finally in Section <a href="#S6" title="6 Combination of techniques ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, we combine techniques and demonstrate that large Transformers can be trained using many fewer rounds and significantly lower communication and computation cost.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Our contributions</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.2" class="ltx_p">We explore two regimes: small models typically studied in cross-device federated learning with fewer than <math id="S2.p1.1.m1.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S2.p1.1.m1.1a"><mn id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><cn type="integer" id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">5</annotation></semantics></math>M parameters and new larger models with at most <math id="S2.p1.2.m2.1" class="ltx_Math" alttext="25" display="inline"><semantics id="S2.p1.2.m2.1a"><mn id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml">25</mn><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><cn type="integer" id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1">25</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">25</annotation></semantics></math>M parameters. We study three architectures: CIFG-LSTM <cite class="ltx_cite ltx_citemacro_citep">(Hochreiter and Schmidhuber, <a href="#bib.bib21" title="" class="ltx_ref">1997</a>)</cite>, or LSTM for simplicity, <cite class="ltx_cite ltx_citemacro_citep">(Hard et al., <a href="#bib.bib18" title="" class="ltx_ref">2018</a>)</cite>, Transformer <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al., <a href="#bib.bib53" title="" class="ltx_ref">2017</a>)</cite>, and Conformer <cite class="ltx_cite ltx_citemacro_citep">(Gulati et al., <a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite>. We refer to both the Transformer and Conformer as Transformer-based models. Our contributions are the following:</p>
</div>
<div id="S2.p2" class="ltx_para">
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p">We are the first to investigate Transformer-based LMs with 25M parameters for cross-device federated learning, which we find outperform LSTMs of similar size.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p">We demonstrate that large models substantially outperform small models on standard tasks but at much higher communication and computation costs, requiring <math id="S2.I1.i2.p1.1.m1.1" class="ltx_math_unparsed" alttext="4\times" display="inline"><semantics id="S2.I1.i2.p1.1.m1.1a"><mrow id="S2.I1.i2.p1.1.m1.1b"><mn id="S2.I1.i2.p1.1.m1.1.1">4</mn><mo lspace="0.222em" id="S2.I1.i2.p1.1.m1.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S2.I1.i2.p1.1.m1.1c">4\times</annotation></semantics></math> the communication cost per round.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.2" class="ltx_p">We investigate quantization and partial model training to address the per round communication and computation cost. With quantization, we achieve similar perplexity with half the download cost and one quarter of the upload cost, reducing total communication cost by <math id="S2.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="62.5\%" display="inline"><semantics id="S2.I1.i3.p1.1.m1.1a"><mrow id="S2.I1.i3.p1.1.m1.1.1" xref="S2.I1.i3.p1.1.m1.1.1.cmml"><mn id="S2.I1.i3.p1.1.m1.1.1.2" xref="S2.I1.i3.p1.1.m1.1.1.2.cmml">62.5</mn><mo id="S2.I1.i3.p1.1.m1.1.1.1" xref="S2.I1.i3.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.1.m1.1b"><apply id="S2.I1.i3.p1.1.m1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1"><csymbol cd="latexml" id="S2.I1.i3.p1.1.m1.1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1.1">percent</csymbol><cn type="float" id="S2.I1.i3.p1.1.m1.1.1.2.cmml" xref="S2.I1.i3.p1.1.m1.1.1.2">62.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.1.m1.1c">62.5\%</annotation></semantics></math>. Partial model training can further reduce the upload cost by <math id="S2.I1.i3.p1.2.m2.1" class="ltx_Math" alttext="70\%" display="inline"><semantics id="S2.I1.i3.p1.2.m2.1a"><mrow id="S2.I1.i3.p1.2.m2.1.1" xref="S2.I1.i3.p1.2.m2.1.1.cmml"><mn id="S2.I1.i3.p1.2.m2.1.1.2" xref="S2.I1.i3.p1.2.m2.1.1.2.cmml">70</mn><mo id="S2.I1.i3.p1.2.m2.1.1.1" xref="S2.I1.i3.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.2.m2.1b"><apply id="S2.I1.i3.p1.2.m2.1.1.cmml" xref="S2.I1.i3.p1.2.m2.1.1"><csymbol cd="latexml" id="S2.I1.i3.p1.2.m2.1.1.1.cmml" xref="S2.I1.i3.p1.2.m2.1.1.1">percent</csymbol><cn type="integer" id="S2.I1.i3.p1.2.m2.1.1.2.cmml" xref="S2.I1.i3.p1.2.m2.1.1.2">70</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.2.m2.1c">70\%</annotation></semantics></math>.</p>
</div>
</li>
<li id="S2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i4.p1" class="ltx_para">
<p id="S2.I1.i4.p1.1" class="ltx_p">We study transfer learning as a method of reducing the number of communication rounds and show that centralized pretraining on a suitable alternate corpus reduces the total communication rounds by <math id="S2.I1.i4.p1.1.m1.1" class="ltx_math_unparsed" alttext="3\times" display="inline"><semantics id="S2.I1.i4.p1.1.m1.1a"><mrow id="S2.I1.i4.p1.1.m1.1b"><mn id="S2.I1.i4.p1.1.m1.1.1">3</mn><mo lspace="0.222em" id="S2.I1.i4.p1.1.m1.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S2.I1.i4.p1.1.m1.1c">3\times</annotation></semantics></math>.</p>
</div>
</li>
<li id="S2.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i5.p1" class="ltx_para">
<p id="S2.I1.i5.p1.1" class="ltx_p">We show that the combination of above techniques can be used to train a Large Transformer and Conformer with the same perplexity as that of a similarly sized LSTM with <math id="S2.I1.i5.p1.1.m1.1" class="ltx_math_unparsed" alttext="\sim 10\times" display="inline"><semantics id="S2.I1.i5.p1.1.m1.1a"><mrow id="S2.I1.i5.p1.1.m1.1b"><mo id="S2.I1.i5.p1.1.m1.1.1">∼</mo><mn id="S2.I1.i5.p1.1.m1.1.2">10</mn><mo lspace="0.222em" id="S2.I1.i5.p1.1.m1.1.3">×</mo></mrow><annotation encoding="application/x-tex" id="S2.I1.i5.p1.1.m1.1c">\sim 10\times</annotation></semantics></math> the smaller client-to-server communication cost.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Dataset and models</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">In this section, we describe the models and dataset used in the rest of the paper.
We train on the Stack Overflow federated dataset from <cite class="ltx_cite ltx_citemacro_citet">TFF (<a href="#bib.bib50" title="" class="ltx_ref">2018</a>)</cite>, which contains posts from the public forum grouped by username.
Following trends in training Transformers, we use sentence-piece <cite class="ltx_cite ltx_citemacro_citep">(Kudo and Richardson, <a href="#bib.bib32" title="" class="ltx_ref">2018</a>)</cite> for sub-word tokenization with a vocabulary size of <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S3.p1.1.m1.1a"><mn id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><cn type="integer" id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">4</annotation></semantics></math>K.
The sentence-piece model is computed based on the entire Stack Overflow training corpus in an offline process on server.
During federated learning, this fixed sentence-piece model is transmitted to each client to encode the local text data.
Doing so provides greater coverage for cross-dataset applications as well as potential downstream speech applications such as ASR <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a href="#bib.bib33" title="" class="ltx_ref">2021</a>); Sim et al. (<a href="#bib.bib44" title="" class="ltx_ref">2021</a>)</cite>.
We measure performance on next-subword prediction using test perplexity.
See Appendix <a href="#A1" title="Appendix A Dataset and models ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a> for descriptive dataset statistics.
All experiments were implemented using JAX <cite class="ltx_cite ltx_citemacro_citep">(Bradbury et al., <a href="#bib.bib3" title="" class="ltx_ref">2018</a>)</cite> and FedJAX <cite class="ltx_cite ltx_citemacro_citep">(Ro et al., <a href="#bib.bib43" title="" class="ltx_ref">2021</a>)</cite> federated simulation libraries.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.10" class="ltx_p">We first did a hyperparameter search for each model and size (<math id="S3.p2.1.m1.1" class="ltx_Math" alttext="\leq 5" display="inline"><semantics id="S3.p2.1.m1.1a"><mrow id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml"><mi id="S3.p2.1.m1.1.1.2" xref="S3.p2.1.m1.1.1.2.cmml"></mi><mo id="S3.p2.1.m1.1.1.1" xref="S3.p2.1.m1.1.1.1.cmml">≤</mo><mn id="S3.p2.1.m1.1.1.3" xref="S3.p2.1.m1.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><apply id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1"><leq id="S3.p2.1.m1.1.1.1.cmml" xref="S3.p2.1.m1.1.1.1"></leq><csymbol cd="latexml" id="S3.p2.1.m1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.2">absent</csymbol><cn type="integer" id="S3.p2.1.m1.1.1.3.cmml" xref="S3.p2.1.m1.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">\leq 5</annotation></semantics></math>M and <math id="S3.p2.2.m2.1" class="ltx_Math" alttext="\leq 25" display="inline"><semantics id="S3.p2.2.m2.1a"><mrow id="S3.p2.2.m2.1.1" xref="S3.p2.2.m2.1.1.cmml"><mi id="S3.p2.2.m2.1.1.2" xref="S3.p2.2.m2.1.1.2.cmml"></mi><mo id="S3.p2.2.m2.1.1.1" xref="S3.p2.2.m2.1.1.1.cmml">≤</mo><mn id="S3.p2.2.m2.1.1.3" xref="S3.p2.2.m2.1.1.3.cmml">25</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.2.m2.1b"><apply id="S3.p2.2.m2.1.1.cmml" xref="S3.p2.2.m2.1.1"><leq id="S3.p2.2.m2.1.1.1.cmml" xref="S3.p2.2.m2.1.1.1"></leq><csymbol cd="latexml" id="S3.p2.2.m2.1.1.2.cmml" xref="S3.p2.2.m2.1.1.2">absent</csymbol><cn type="integer" id="S3.p2.2.m2.1.1.3.cmml" xref="S3.p2.2.m2.1.1.3">25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m2.1c">\leq 25</annotation></semantics></math>M), with FedAdam <cite class="ltx_cite ltx_citemacro_citep">(Reddi et al., <a href="#bib.bib41" title="" class="ltx_ref">2020</a>)</cite>, or FedAvg for simplicity,
with <math id="S3.p2.3.m3.1" class="ltx_Math" alttext="200" display="inline"><semantics id="S3.p2.3.m3.1a"><mn id="S3.p2.3.m3.1.1" xref="S3.p2.3.m3.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="S3.p2.3.m3.1b"><cn type="integer" id="S3.p2.3.m3.1.1.cmml" xref="S3.p2.3.m3.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m3.1c">200</annotation></semantics></math> clients per round for <math id="S3.p2.4.m4.1" class="ltx_Math" alttext="3" display="inline"><semantics id="S3.p2.4.m4.1a"><mn id="S3.p2.4.m4.1.1" xref="S3.p2.4.m4.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="S3.p2.4.m4.1b"><cn type="integer" id="S3.p2.4.m4.1.1.cmml" xref="S3.p2.4.m4.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.4.m4.1c">3</annotation></semantics></math>K rounds, resulting in six models: <em id="S3.p2.10.1" class="ltx_emph ltx_font_italic">Small LSTM</em> (<math id="S3.p2.5.m5.1" class="ltx_Math" alttext="4.7" display="inline"><semantics id="S3.p2.5.m5.1a"><mn id="S3.p2.5.m5.1.1" xref="S3.p2.5.m5.1.1.cmml">4.7</mn><annotation-xml encoding="MathML-Content" id="S3.p2.5.m5.1b"><cn type="float" id="S3.p2.5.m5.1.1.cmml" xref="S3.p2.5.m5.1.1">4.7</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.5.m5.1c">4.7</annotation></semantics></math>M), <em id="S3.p2.10.2" class="ltx_emph ltx_font_italic">Large LSTM</em> (<math id="S3.p2.6.m6.1" class="ltx_Math" alttext="18.8" display="inline"><semantics id="S3.p2.6.m6.1a"><mn id="S3.p2.6.m6.1.1" xref="S3.p2.6.m6.1.1.cmml">18.8</mn><annotation-xml encoding="MathML-Content" id="S3.p2.6.m6.1b"><cn type="float" id="S3.p2.6.m6.1.1.cmml" xref="S3.p2.6.m6.1.1">18.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.6.m6.1c">18.8</annotation></semantics></math>M), <em id="S3.p2.10.3" class="ltx_emph ltx_font_italic">Small Transformer</em> (<math id="S3.p2.7.m7.1" class="ltx_Math" alttext="4.1" display="inline"><semantics id="S3.p2.7.m7.1a"><mn id="S3.p2.7.m7.1.1" xref="S3.p2.7.m7.1.1.cmml">4.1</mn><annotation-xml encoding="MathML-Content" id="S3.p2.7.m7.1b"><cn type="float" id="S3.p2.7.m7.1.1.cmml" xref="S3.p2.7.m7.1.1">4.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.7.m7.1c">4.1</annotation></semantics></math>M), <em id="S3.p2.10.4" class="ltx_emph ltx_font_italic">Large Transformer</em> (<math id="S3.p2.8.m8.1" class="ltx_Math" alttext="21" display="inline"><semantics id="S3.p2.8.m8.1a"><mn id="S3.p2.8.m8.1.1" xref="S3.p2.8.m8.1.1.cmml">21</mn><annotation-xml encoding="MathML-Content" id="S3.p2.8.m8.1b"><cn type="integer" id="S3.p2.8.m8.1.1.cmml" xref="S3.p2.8.m8.1.1">21</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.8.m8.1c">21</annotation></semantics></math>M), <em id="S3.p2.10.5" class="ltx_emph ltx_font_italic">Small Conformer</em> (<math id="S3.p2.9.m9.1" class="ltx_Math" alttext="4.1" display="inline"><semantics id="S3.p2.9.m9.1a"><mn id="S3.p2.9.m9.1.1" xref="S3.p2.9.m9.1.1.cmml">4.1</mn><annotation-xml encoding="MathML-Content" id="S3.p2.9.m9.1b"><cn type="float" id="S3.p2.9.m9.1.1.cmml" xref="S3.p2.9.m9.1.1">4.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.9.m9.1c">4.1</annotation></semantics></math>M), and <em id="S3.p2.10.6" class="ltx_emph ltx_font_italic">Large Conformer</em> (<math id="S3.p2.10.m10.1" class="ltx_Math" alttext="20.2" display="inline"><semantics id="S3.p2.10.m10.1a"><mn id="S3.p2.10.m10.1.1" xref="S3.p2.10.m10.1.1.cmml">20.2</mn><annotation-xml encoding="MathML-Content" id="S3.p2.10.m10.1b"><cn type="float" id="S3.p2.10.m10.1.1.cmml" xref="S3.p2.10.m10.1.1">20.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.10.m10.1c">20.2</annotation></semantics></math>M).</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2204.09715/assets/so_fedavg.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="250" height="115" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Test perplexity over communication rounds for each class and size of model.</figcaption>
</figure>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.3" class="ltx_p">We then trained the chosen architectures with <math id="S3.p3.1.m1.1" class="ltx_Math" alttext="800" display="inline"><semantics id="S3.p3.1.m1.1a"><mn id="S3.p3.1.m1.1.1" xref="S3.p3.1.m1.1.1.cmml">800</mn><annotation-xml encoding="MathML-Content" id="S3.p3.1.m1.1b"><cn type="integer" id="S3.p3.1.m1.1.1.cmml" xref="S3.p3.1.m1.1.1">800</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.1.m1.1c">800</annotation></semantics></math> clients per round for <math id="S3.p3.2.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S3.p3.2.m2.1a"><mn id="S3.p3.2.m2.1.1" xref="S3.p3.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S3.p3.2.m2.1b"><cn type="integer" id="S3.p3.2.m2.1.1.cmml" xref="S3.p3.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.2.m2.1c">10</annotation></semantics></math>K rounds in Figure <a href="#S3.F1" title="Figure 1 ‣ 3 Dataset and models ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
As expected, the larger variants significantly outperform their smaller counterparts with the Large Conformer achieving the best perplexity.
However, the larger models are more expensive to train per round and although the Large Conformer achieves the best perplexity, it only surpasses the Large LSTM after <math id="S3.p3.3.m3.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S3.p3.3.m3.1a"><mn id="S3.p3.3.m3.1.1" xref="S3.p3.3.m3.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S3.p3.3.m3.1b"><cn type="integer" id="S3.p3.3.m3.1.1.cmml" xref="S3.p3.3.m3.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.p3.3.m3.1c">4</annotation></semantics></math>K rounds.
Next, we focus on techniques to reduce this cost per round and number of rounds.
For more details about the architecture search, the selected models, and their performance, see Appendix <a href="#A1" title="Appendix A Dataset and models ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Cost per round</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.7" class="ltx_p">The larger models have <math id="S4.p1.1.m1.1" class="ltx_Math" alttext="18.8" display="inline"><semantics id="S4.p1.1.m1.1a"><mn id="S4.p1.1.m1.1.1" xref="S4.p1.1.m1.1.1.cmml">18.8</mn><annotation-xml encoding="MathML-Content" id="S4.p1.1.m1.1b"><cn type="float" id="S4.p1.1.m1.1.1.cmml" xref="S4.p1.1.m1.1.1">18.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.1.m1.1c">18.8</annotation></semantics></math>M, <math id="S4.p1.2.m2.1" class="ltx_Math" alttext="21" display="inline"><semantics id="S4.p1.2.m2.1a"><mn id="S4.p1.2.m2.1.1" xref="S4.p1.2.m2.1.1.cmml">21</mn><annotation-xml encoding="MathML-Content" id="S4.p1.2.m2.1b"><cn type="integer" id="S4.p1.2.m2.1.1.cmml" xref="S4.p1.2.m2.1.1">21</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.2.m2.1c">21</annotation></semantics></math>M, and <math id="S4.p1.3.m3.1" class="ltx_Math" alttext="20.2" display="inline"><semantics id="S4.p1.3.m3.1a"><mn id="S4.p1.3.m3.1.1" xref="S4.p1.3.m3.1.1.cmml">20.2</mn><annotation-xml encoding="MathML-Content" id="S4.p1.3.m3.1b"><cn type="float" id="S4.p1.3.m3.1.1.cmml" xref="S4.p1.3.m3.1.1">20.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.3.m3.1c">20.2</annotation></semantics></math>M parameters (<math id="S4.p1.4.m4.1" class="ltx_Math" alttext="150" display="inline"><semantics id="S4.p1.4.m4.1a"><mn id="S4.p1.4.m4.1.1" xref="S4.p1.4.m4.1.1.cmml">150</mn><annotation-xml encoding="MathML-Content" id="S4.p1.4.m4.1b"><cn type="integer" id="S4.p1.4.m4.1.1.cmml" xref="S4.p1.4.m4.1.1">150</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.4.m4.1c">150</annotation></semantics></math>MB, <math id="S4.p1.5.m5.1" class="ltx_Math" alttext="168" display="inline"><semantics id="S4.p1.5.m5.1a"><mn id="S4.p1.5.m5.1.1" xref="S4.p1.5.m5.1.1.cmml">168</mn><annotation-xml encoding="MathML-Content" id="S4.p1.5.m5.1b"><cn type="integer" id="S4.p1.5.m5.1.1.cmml" xref="S4.p1.5.m5.1.1">168</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.5.m5.1c">168</annotation></semantics></math>MB, and <math id="S4.p1.6.m6.1" class="ltx_Math" alttext="162" display="inline"><semantics id="S4.p1.6.m6.1a"><mn id="S4.p1.6.m6.1.1" xref="S4.p1.6.m6.1.1.cmml">162</mn><annotation-xml encoding="MathML-Content" id="S4.p1.6.m6.1b"><cn type="integer" id="S4.p1.6.m6.1.1.cmml" xref="S4.p1.6.m6.1.1">162</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.6.m6.1c">162</annotation></semantics></math>MB at <math id="S4.p1.7.m7.1" class="ltx_Math" alttext="32" display="inline"><semantics id="S4.p1.7.m7.1a"><mn id="S4.p1.7.m7.1.1" xref="S4.p1.7.m7.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="S4.p1.7.m7.1b"><cn type="integer" id="S4.p1.7.m7.1.1.cmml" xref="S4.p1.7.m7.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p1.7.m7.1c">32</annotation></semantics></math> bits per parameter) which need to be downloaded, trained, and uploaded at each round, a strain on both communication and computation on device. There are often strict time or transfer byte limits for each round of training, which can prohibit some devices from training these models due to slower transfer/processing speeds <cite class="ltx_cite ltx_citemacro_citep">(Kairouz et al., <a href="#bib.bib24" title="" class="ltx_ref">2021</a>)</cite>.
We show that we can significantly reduce these costs by partial model training and quantization techniques.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p"><span id="S4.p2.1.1" class="ltx_text ltx_font_bold">Partial model training</span>:
Training only a subset of the model can reduce the computational cost of training and has been examined in both federated <cite class="ltx_cite ltx_citemacro_citep">(Caldas et al., <a href="#bib.bib7" title="" class="ltx_ref">2019b</a>; Yang et al., <a href="#bib.bib55" title="" class="ltx_ref">2021</a>)</cite> and non-federated <cite class="ltx_cite ltx_citemacro_citep">(Kovaleva et al., <a href="#bib.bib31" title="" class="ltx_ref">2019</a>)</cite> settings.
Additionally, reducing the number of trainable parameters can also decrease communication cost since only the trainable parameters need to be uploaded.</p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2204.09715/assets/so_pvt_trainable.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="173" height="115" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Test perplexity as a function of number of trainable variables.</figcaption>
</figure>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.3" class="ltx_p">We follow the Partial Variable Training (PVT) per client per round strategy <cite class="ltx_cite ltx_citemacro_citep">(Yang et al., <a href="#bib.bib55" title="" class="ltx_ref">2021</a>)</cite> as it only freezes a subset of the original model and can be applied generally to multiple model architecture types. For more experiment details, see Appendix <a href="#A2" title="Appendix B Partial model training ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>.
We report test perplexity as a function of number of trainable variables in Figure <a href="#S4.F2" title="Figure 2 ‣ 4 Cost per round ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.
Large LSTM and Conformer seem to be able to handle more aggressive parameter freezing compared to Large Transformer in terms of quality regression.
Additionally, training only <math id="S4.p3.1.m1.1" class="ltx_Math" alttext="30\%" display="inline"><semantics id="S4.p3.1.m1.1a"><mrow id="S4.p3.1.m1.1.1" xref="S4.p3.1.m1.1.1.cmml"><mn id="S4.p3.1.m1.1.1.2" xref="S4.p3.1.m1.1.1.2.cmml">30</mn><mo id="S4.p3.1.m1.1.1.1" xref="S4.p3.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.1b"><apply id="S4.p3.1.m1.1.1.cmml" xref="S4.p3.1.m1.1.1"><csymbol cd="latexml" id="S4.p3.1.m1.1.1.1.cmml" xref="S4.p3.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S4.p3.1.m1.1.1.2.cmml" xref="S4.p3.1.m1.1.1.2">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.1c">30\%</annotation></semantics></math> of variables for the Large Conformer (<math id="S4.p3.2.m2.1" class="ltx_Math" alttext="6.1" display="inline"><semantics id="S4.p3.2.m2.1a"><mn id="S4.p3.2.m2.1.1" xref="S4.p3.2.m2.1.1.cmml">6.1</mn><annotation-xml encoding="MathML-Content" id="S4.p3.2.m2.1b"><cn type="float" id="S4.p3.2.m2.1.1.cmml" xref="S4.p3.2.m2.1.1">6.1</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.2.m2.1c">6.1</annotation></semantics></math>M) achieves better performance than the full Large LSTM (<math id="S4.p3.3.m3.1" class="ltx_Math" alttext="18.8" display="inline"><semantics id="S4.p3.3.m3.1a"><mn id="S4.p3.3.m3.1.1" xref="S4.p3.3.m3.1.1.cmml">18.8</mn><annotation-xml encoding="MathML-Content" id="S4.p3.3.m3.1b"><cn type="float" id="S4.p3.3.m3.1.1.cmml" xref="S4.p3.3.m3.1.1">18.8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.3.m3.1c">18.8</annotation></semantics></math>M).</p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p"><span id="S4.p4.1.1" class="ltx_text ltx_font_bold">Quantization</span>:
To reduce communication costs, various quantization strategies can decrease the number of bits required to represent model parameters <cite class="ltx_cite ltx_citemacro_citep">(Bernstein et al., <a href="#bib.bib2" title="" class="ltx_ref">2018</a>; Reisizadeh et al., <a href="#bib.bib42" title="" class="ltx_ref">2020</a>; Gandikota et al., <a href="#bib.bib14" title="" class="ltx_ref">2021</a>; Vargaftik et al., <a href="#bib.bib51" title="" class="ltx_ref">2021</a>)</cite>. We examine stochastic k-level uniform quantization <cite class="ltx_cite ltx_citemacro_citep">(Alistarh et al., <a href="#bib.bib1" title="" class="ltx_ref">2017</a>; Suresh et al., <a href="#bib.bib47" title="" class="ltx_ref">2017</a>)</cite> as it can be applied to model parameters on download (server-to-client) and model updates on upload (client-to-server) communication with adjustable levels of compression, and compare with TernGrad, an upload technique <cite class="ltx_cite ltx_citemacro_citep">(Wen et al., <a href="#bib.bib54" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<figure id="S4.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2204.09715/assets/rnn_quant_download.png" id="S4.F3.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="143" height="105" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2204.09715/assets/large_trans_download_quant_left_leg.png" id="S4.F3.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="143" height="105" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2204.09715/assets/conf_quant_download.png" id="S4.F3.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="143" height="105" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Test perplexity over communication rounds for varying download quantization levels, with upload quantization fixed to <math id="S4.F3.2.m1.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S4.F3.2.m1.1b"><mn id="S4.F3.2.m1.1.1" xref="S4.F3.2.m1.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S4.F3.2.m1.1c"><cn type="integer" id="S4.F3.2.m1.1.1.cmml" xref="S4.F3.2.m1.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.F3.2.m1.1d">8</annotation></semantics></math> bits. Dashed line shows the baseline without quantization.</figcaption>
</figure>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.2" class="ltx_p">We focus analysis on larger models which are more affected by quantization. The LSTM appears more "quantizable" during download than the Transformer and Conformer, with less regression in Figure <a href="#S4.F3" title="Figure 3 ‣ 4 Cost per round ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
The perplexities of the Transformer and Conformer with <math id="S4.p5.1.m1.1" class="ltx_Math" alttext="16" display="inline"><semantics id="S4.p5.1.m1.1a"><mn id="S4.p5.1.m1.1.1" xref="S4.p5.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S4.p5.1.m1.1b"><cn type="integer" id="S4.p5.1.m1.1.1.cmml" xref="S4.p5.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.1.m1.1c">16</annotation></semantics></math> download bits match that of their corresponding baselines and with <math id="S4.p5.2.m2.1" class="ltx_Math" alttext="12" display="inline"><semantics id="S4.p5.2.m2.1a"><mn id="S4.p5.2.m2.1.1" xref="S4.p5.2.m2.1.1.cmml">12</mn><annotation-xml encoding="MathML-Content" id="S4.p5.2.m2.1b"><cn type="integer" id="S4.p5.2.m2.1.1.cmml" xref="S4.p5.2.m2.1.1">12</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.2.m2.1c">12</annotation></semantics></math> bits are close to that of the LSTM.</p>
</div>
<figure id="S4.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2204.09715/assets/rnn_upload_quant.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="143" height="105" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2204.09715/assets/trans_quant_upload.png" id="S4.F4.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="143" height="105" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2204.09715/assets/conf_quant_upload.png" id="S4.F4.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="143" height="105" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Test perplexity over communication rounds for varying upload quantization levels, with download quantization fixed to <math id="S4.F4.3.m1.1" class="ltx_Math" alttext="16" display="inline"><semantics id="S4.F4.3.m1.1b"><mn id="S4.F4.3.m1.1.1" xref="S4.F4.3.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S4.F4.3.m1.1c"><cn type="integer" id="S4.F4.3.m1.1.1.cmml" xref="S4.F4.3.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.3.m1.1d">16</annotation></semantics></math> bits. TernGrad is comparable to uniform with about <math id="S4.F4.4.m2.1" class="ltx_Math" alttext="1.6" display="inline"><semantics id="S4.F4.4.m2.1b"><mn id="S4.F4.4.m2.1.1" xref="S4.F4.4.m2.1.1.cmml">1.6</mn><annotation-xml encoding="MathML-Content" id="S4.F4.4.m2.1c"><cn type="float" id="S4.F4.4.m2.1.1.cmml" xref="S4.F4.4.m2.1.1">1.6</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.F4.4.m2.1d">1.6</annotation></semantics></math> bits. Dashed line shows the baseline without quantization.</figcaption>
</figure>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2204.09715/assets/comm_costs_plus_conf.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="165" height="121" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Test set perplexity versus total communication cost (download <math id="S4.F5.2.m1.1" class="ltx_Math" alttext="+" display="inline"><semantics id="S4.F5.2.m1.1b"><mo id="S4.F5.2.m1.1.1" xref="S4.F5.2.m1.1.1.cmml">+</mo><annotation-xml encoding="MathML-Content" id="S4.F5.2.m1.1c"><plus id="S4.F5.2.m1.1.1.cmml" xref="S4.F5.2.m1.1.1"></plus></annotation-xml><annotation encoding="application/x-tex" id="S4.F5.2.m1.1d">+</annotation></semantics></math> upload) in a single round of training, for each quantization algorithm. Uniform settings include points for varying quantization bits.</figcaption>
</figure>
<div id="S4.p6" class="ltx_para">
<p id="S4.p6.4" class="ltx_p">For all models, <math id="S4.p6.1.m1.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S4.p6.1.m1.1a"><mn id="S4.p6.1.m1.1.1" xref="S4.p6.1.m1.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S4.p6.1.m1.1b"><cn type="integer" id="S4.p6.1.m1.1.1.cmml" xref="S4.p6.1.m1.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.1.m1.1c">8</annotation></semantics></math> bit upload matches the corresponding baselines, or even <math id="S4.p6.2.m2.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S4.p6.2.m2.1a"><mn id="S4.p6.2.m2.1.1" xref="S4.p6.2.m2.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S4.p6.2.m2.1b"><cn type="integer" id="S4.p6.2.m2.1.1.cmml" xref="S4.p6.2.m2.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.2.m2.1c">6</annotation></semantics></math> bits for the LSTM in Figure <a href="#S4.F4" title="Figure 4 ‣ 4 Cost per round ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. TernGrad, requiring <math id="S4.p6.3.m3.2" class="ltx_Math" alttext="\log_{2}(3)" display="inline"><semantics id="S4.p6.3.m3.2a"><mrow id="S4.p6.3.m3.2.2.1" xref="S4.p6.3.m3.2.2.2.cmml"><msub id="S4.p6.3.m3.2.2.1.1" xref="S4.p6.3.m3.2.2.1.1.cmml"><mi id="S4.p6.3.m3.2.2.1.1.2" xref="S4.p6.3.m3.2.2.1.1.2.cmml">log</mi><mn id="S4.p6.3.m3.2.2.1.1.3" xref="S4.p6.3.m3.2.2.1.1.3.cmml">2</mn></msub><mo id="S4.p6.3.m3.2.2.1a" xref="S4.p6.3.m3.2.2.2.cmml">⁡</mo><mrow id="S4.p6.3.m3.2.2.1.2" xref="S4.p6.3.m3.2.2.2.cmml"><mo stretchy="false" id="S4.p6.3.m3.2.2.1.2.1" xref="S4.p6.3.m3.2.2.2.cmml">(</mo><mn id="S4.p6.3.m3.1.1" xref="S4.p6.3.m3.1.1.cmml">3</mn><mo stretchy="false" id="S4.p6.3.m3.2.2.1.2.2" xref="S4.p6.3.m3.2.2.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.p6.3.m3.2b"><apply id="S4.p6.3.m3.2.2.2.cmml" xref="S4.p6.3.m3.2.2.1"><apply id="S4.p6.3.m3.2.2.1.1.cmml" xref="S4.p6.3.m3.2.2.1.1"><csymbol cd="ambiguous" id="S4.p6.3.m3.2.2.1.1.1.cmml" xref="S4.p6.3.m3.2.2.1.1">subscript</csymbol><log id="S4.p6.3.m3.2.2.1.1.2.cmml" xref="S4.p6.3.m3.2.2.1.1.2"></log><cn type="integer" id="S4.p6.3.m3.2.2.1.1.3.cmml" xref="S4.p6.3.m3.2.2.1.1.3">2</cn></apply><cn type="integer" id="S4.p6.3.m3.1.1.cmml" xref="S4.p6.3.m3.1.1">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.3.m3.2c">\log_{2}(3)</annotation></semantics></math> bits, outperforms the <math id="S4.p6.4.m4.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S4.p6.4.m4.1a"><mn id="S4.p6.4.m4.1.1" xref="S4.p6.4.m4.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S4.p6.4.m4.1b"><cn type="integer" id="S4.p6.4.m4.1.1.cmml" xref="S4.p6.4.m4.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.p6.4.m4.1c">4</annotation></semantics></math> bit in the Transformer and Conformer but not for the LSTM. It provides the best cost-performance tradeoff in Figure <a href="#S4.F5" title="Figure 5 ‣ 4 Cost per round ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.
More details are in Appendix <a href="#A3" title="Appendix C Quantization ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Number of communication rounds</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p"><span id="S5.p1.1.1" class="ltx_text ltx_font_bold">Transfer learning</span>: Transfer learning leverages pretrained models to improve model quality <cite class="ltx_cite ltx_citemacro_citep">(Houlsby et al., <a href="#bib.bib22" title="" class="ltx_ref">2019</a>)</cite>.
By pretraining, the number of communication rounds required for model convergence can be significantly reduced <cite class="ltx_cite ltx_citemacro_citep">(Stremmel and Singh, <a href="#bib.bib46" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<figure id="S5.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2204.09715/assets/large_lstm_pretrain.png" id="S5.F6.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="145" height="108" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2204.09715/assets/large_trans_pretrain.png" id="S5.F6.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="145" height="108" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2204.09715/assets/large_conf_pretrain.png" id="S5.F6.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="145" height="108" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Test perplexity over communication rounds comparing pretraining corpora. Dashed line is the final perplexity reached by the randomly initialized model.</figcaption>
</figure>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">We use two datasets for pretraining: a large corpus of digitized books <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a href="#bib.bib57" title="" class="ltx_ref">2021</a>)</cite> and the One Billion Word Benchmark (LM1B) <cite class="ltx_cite ltx_citemacro_citep">(Chelba et al., <a href="#bib.bib8" title="" class="ltx_ref">2014</a>)</cite>.
After pretraining using synchronous SGD for <math id="S5.p2.1.m1.1" class="ltx_Math" alttext="30" display="inline"><semantics id="S5.p2.1.m1.1a"><mn id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.1b"><cn type="integer" id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.1c">30</annotation></semantics></math>M steps, we finetune on Stack Overflow using FedAvg.
For additional details, see Appendix <a href="#A4" title="Appendix D Transfer learning ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">D</span></a>.
We report results for each of the pretraining datasets and random initialization in Figure <a href="#S5.F6" title="Figure 6 ‣ 5 Number of communication rounds ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.3" class="ltx_p">Books consistently outperforms LM1B for all models.
Pretraining greatly benefits the Large Transformer and Conformer compared to the Large LSTM, reducing the number of rounds needed to reach the final <math id="S5.p3.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="S5.p3.1.m1.1a"><mn id="S5.p3.1.m1.1.1" xref="S5.p3.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S5.p3.1.m1.1b"><cn type="integer" id="S5.p3.1.m1.1.1.cmml" xref="S5.p3.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.1.m1.1c">10</annotation></semantics></math>K without pretraining by <math id="S5.p3.2.m2.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S5.p3.2.m2.1a"><mn id="S5.p3.2.m2.1.1" xref="S5.p3.2.m2.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S5.p3.2.m2.1b"><cn type="integer" id="S5.p3.2.m2.1.1.cmml" xref="S5.p3.2.m2.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.2.m2.1c">4</annotation></semantics></math>K rounds.
Furthermore, at round <math id="S5.p3.3.m3.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S5.p3.3.m3.1a"><mn id="S5.p3.3.m3.1.1" xref="S5.p3.3.m3.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S5.p3.3.m3.1b"><cn type="integer" id="S5.p3.3.m3.1.1.cmml" xref="S5.p3.3.m3.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.p3.3.m3.1c">2</annotation></semantics></math>K, the Large Transformer and Conformer already outperform the Large LSTM, making the number of rounds needed for training similar to that of smaller models used in mobile keyboard prediction <cite class="ltx_cite ltx_citemacro_citep">(Hard et al., <a href="#bib.bib18" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<figure id="S5.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2204.09715/assets/so_lstm_opt.png" id="S5.F7.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="145" height="108" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2204.09715/assets/so_trans_opt.png" id="S5.F7.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="145" height="108" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2204.09715/assets/so_conf_opt.png" id="S5.F7.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="145" height="108" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Test perplexity over communication rounds for each model and algorithm.</figcaption>
</figure>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p"><span id="S5.p4.1.1" class="ltx_text ltx_font_bold">Different optimizers</span>:
Since the introduction of FedAvg, several variations continue to be developed <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib34" title="" class="ltx_ref">2018</a>; Hamer et al., <a href="#bib.bib17" title="" class="ltx_ref">2020</a>; Reddi et al., <a href="#bib.bib41" title="" class="ltx_ref">2020</a>)</cite>.
Specifically, we examine MimeLite <cite class="ltx_cite ltx_citemacro_citep">(Karimireddy et al., <a href="#bib.bib27" title="" class="ltx_ref">2020</a>)</cite> and FedProx <cite class="ltx_cite ltx_citemacro_citep">(Li et al., <a href="#bib.bib34" title="" class="ltx_ref">2018</a>)</cite> as they have been shown to reduce the total amount of rounds required for provable convergence.
However, in Figure <a href="#S5.F7" title="Figure 7 ‣ 5 Number of communication rounds ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, FedProx and MimeLite do not improve convergence speed over FedAvg.
More details can be found in Appendix <a href="#A5" title="Appendix E Different optimizers ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">E</span></a>.</p>
</div>
<figure id="S5.F8" class="ltx_figure"><img src="/html/2204.09715/assets/so_combo.png" id="S5.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="255" height="114" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Test perplexity over total uploaded gigabytes per client for each class of model.</figcaption>
</figure>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Combination of techniques</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.4" class="ltx_p">We experiment with combining partial model training, quantization, and transfer learning to train <em id="S6.p1.4.1" class="ltx_emph ltx_font_italic">efficient</em> larger models.
For these experiments, we train on just <math id="S6.p1.1.m1.1" class="ltx_Math" alttext="40\%" display="inline"><semantics id="S6.p1.1.m1.1a"><mrow id="S6.p1.1.m1.1.1" xref="S6.p1.1.m1.1.1.cmml"><mn id="S6.p1.1.m1.1.1.2" xref="S6.p1.1.m1.1.1.2.cmml">40</mn><mo id="S6.p1.1.m1.1.1.1" xref="S6.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.p1.1.m1.1b"><apply id="S6.p1.1.m1.1.1.cmml" xref="S6.p1.1.m1.1.1"><csymbol cd="latexml" id="S6.p1.1.m1.1.1.1.cmml" xref="S6.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S6.p1.1.m1.1.1.2.cmml" xref="S6.p1.1.m1.1.1.2">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.m1.1c">40\%</annotation></semantics></math> of trainable parameters with PVT
and warm start after pretraining on the Books corpus.
Combining download quantization with these techniques did not perform as well, so we only apply <math id="S6.p1.2.m2.1" class="ltx_Math" alttext="8" display="inline"><semantics id="S6.p1.2.m2.1a"><mn id="S6.p1.2.m2.1.1" xref="S6.p1.2.m2.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="S6.p1.2.m2.1b"><cn type="integer" id="S6.p1.2.m2.1.1.cmml" xref="S6.p1.2.m2.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.2.m2.1c">8</annotation></semantics></math> bit uniform quantization on upload, which is the tightest communication bottleneck (<cite class="ltx_cite ltx_citemacro_citet">Statista.com (<a href="#bib.bib45" title="" class="ltx_ref">2021</a>)</cite> reports that mobile upload speeds worldwide are over <math id="S6.p1.3.m3.1" class="ltx_math_unparsed" alttext="4\times" display="inline"><semantics id="S6.p1.3.m3.1a"><mrow id="S6.p1.3.m3.1b"><mn id="S6.p1.3.m3.1.1">4</mn><mo lspace="0.222em" id="S6.p1.3.m3.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="S6.p1.3.m3.1c">4\times</annotation></semantics></math> slower than download as of May 2021).
For the full experiment details, refer to Appendix <a href="#A6" title="Appendix F Combination of techniques ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">F</span></a>.
We report the test perplexity in terms of total upload communication cost in Figure <a href="#S5.F8" title="Figure 8 ‣ 5 Number of communication rounds ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>.
Restricting for small upload costs (<math id="S6.p1.4.m4.1" class="ltx_Math" alttext="&lt;200" display="inline"><semantics id="S6.p1.4.m4.1a"><mrow id="S6.p1.4.m4.1.1" xref="S6.p1.4.m4.1.1.cmml"><mi id="S6.p1.4.m4.1.1.2" xref="S6.p1.4.m4.1.1.2.cmml"></mi><mo id="S6.p1.4.m4.1.1.1" xref="S6.p1.4.m4.1.1.1.cmml">&lt;</mo><mn id="S6.p1.4.m4.1.1.3" xref="S6.p1.4.m4.1.1.3.cmml">200</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.p1.4.m4.1b"><apply id="S6.p1.4.m4.1.1.cmml" xref="S6.p1.4.m4.1.1"><lt id="S6.p1.4.m4.1.1.1.cmml" xref="S6.p1.4.m4.1.1.1"></lt><csymbol cd="latexml" id="S6.p1.4.m4.1.1.2.cmml" xref="S6.p1.4.m4.1.1.2">absent</csymbol><cn type="integer" id="S6.p1.4.m4.1.1.3.cmml" xref="S6.p1.4.m4.1.1.3">200</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.4.m4.1c">&lt;200</annotation></semantics></math>GB), the efficient models outperform all others with the efficient Large Conformer yielding the best perplexity.
Furthermore, the efficient Large Transformer and efficient Large Conformer achieve the same or better perplexity as the Large LSTM with no efficient techniques.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">We systematically studied several techniques for addressing the communication and computation bottlenecks of federated learning.
We further demonstrated that these techniques, individually or in combination, can scale to larger models in cross-device federated learning.
Extending this study to other architectures and efficient strategies remains an interesting open question.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alistarh et al. [2017]</span>
<span class="ltx_bibblock">
D. Alistarh, D. Grubic, J. Li, R. Tomioka, and M. Vojnovic.

</span>
<span class="ltx_bibblock">Qsgd: Communication-efficient sgd via gradient quantization and
encoding.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 30, 2017.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bernstein et al. [2018]</span>
<span class="ltx_bibblock">
J. Bernstein, Y.-X. Wang, K. Azizzadenesheli, and A. Anandkumar.

</span>
<span class="ltx_bibblock">signsgd: Compressed optimisation for non-convex problems.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
560–569. PMLR, 2018.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bradbury et al. [2018]</span>
<span class="ltx_bibblock">
J. Bradbury, R. Frostig, P. Hawkins, M. J. Johnson, C. Leary, D. Maclaurin,
G. Necula, A. Paszke, J. VanderPlas, S. Wanderman-Milne, and Q. Zhang.

</span>
<span class="ltx_bibblock">JAX: composable transformations of Python+NumPy programs,
2018.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://github.com/google/jax" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://github.com/google/jax</a>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brisimi et al. [2018]</span>
<span class="ltx_bibblock">
T. S. Brisimi, R. Chen, T. Mela, A. Olshevsky, I. C. Paschalidis, and W. Shi.

</span>
<span class="ltx_bibblock">Federated learning of predictive models from federated electronic
health records.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">International journal of medical informatics</em>, 112:59–67, 2018.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. [2020]</span>
<span class="ltx_bibblock">
T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal,
A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss,
G. Krueger, T. Henighan, R. Child, A. Ramesh, D. M. Ziegler, J. Wu,
C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess,
J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever, and D. Amodei.

</span>
<span class="ltx_bibblock">Language models are few-shot learners, 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caldas et al. [2019a]</span>
<span class="ltx_bibblock">
S. Caldas, S. M. K. Duddu, P. Wu, T. Li, J. Konečný, H. B. McMahan, V. Smith,
and A. Talwalkar.

</span>
<span class="ltx_bibblock">Leaf: A benchmark for federated settings, 2019a.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caldas et al. [2019b]</span>
<span class="ltx_bibblock">
S. Caldas, J. Konečny, H. B. McMahan, and A. Talwalkar.

</span>
<span class="ltx_bibblock">Expanding the reach of federated learning by reducing client resource
requirements, 2019b.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chelba et al. [2014]</span>
<span class="ltx_bibblock">
C. Chelba, T. Mikolov, M. Schuster, Q. Ge, T. Brants, P. T. Koehn, and
T. Robinson.

</span>
<span class="ltx_bibblock">One billion word benchmark for measuring progress in statistical
language modeling.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/1312.3005, 2014.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. [2019]</span>
<span class="ltx_bibblock">
M. Chen, A. T. Suresh, R. Mathews, A. Wong, C. Allauzen, F. Beaufays, and
M. Riley.

</span>
<span class="ltx_bibblock">Federated learning of n-gram language models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 23rd Conference on Computational Natural
Language Learning (CoNLL)</em>, pages 121–130, Hong Kong, China, Nov. 2019.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/K19-1012</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.aclweb.org/anthology/K19-1012" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.aclweb.org/anthology/K19-1012</a>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Choromanski et al. [2021]</span>
<span class="ltx_bibblock">
K. M. Choromanski, V. Likhosherstov, D. Dohan, X. Song, A. Gane, T. Sarlos,
P. Hawkins, J. Q. Davis, A. Mohiuddin, L. Kaiser, D. B. Belanger, L. J.
Colwell, and A. Weller.

</span>
<span class="ltx_bibblock">Rethinking attention with performers.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=Ua6zuk0WRH" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=Ua6zuk0WRH</a>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai et al. [2019]</span>
<span class="ltx_bibblock">
Z. Dai, Z. Yang, Y. Yang, J. Carbonell, Q. Le, and R. Salakhutdinov.

</span>
<span class="ltx_bibblock">Transformer-XL: Attentive language models beyond a fixed-length
context.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 2978–2988, Florence, Italy, July 2019.
Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/P19-1285</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/P19-1285" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/P19-1285</a>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al. [2019]</span>
<span class="ltx_bibblock">
J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova.

</span>
<span class="ltx_bibblock">BERT: Pre-training of deep bidirectional transformers for language
understanding.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Language
Technologies, Volume 1 (Long and Short Papers)</em>, pages 4171–4186,
Minneapolis, Minnesota, June 2019. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/N19-1423</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/N19-1423" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/N19-1423</a>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Duchi et al. [2011]</span>
<span class="ltx_bibblock">
J. Duchi, E. Hazan, and Y. Singer.

</span>
<span class="ltx_bibblock">Adaptive subgradient methods for online learning and stochastic
optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Journal of Machine Learning Research</em>, 12(61):2121–2159, 2011.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://jmlr.org/papers/v12/duchi11a.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://jmlr.org/papers/v12/duchi11a.html</a>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gandikota et al. [2021]</span>
<span class="ltx_bibblock">
V. Gandikota, D. Kane, R. K. Maity, and A. Mazumdar.

</span>
<span class="ltx_bibblock">vqsgd: Vector quantized stochastic gradient descent.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">International Conference on Artificial Intelligence and
Statistics</em>, pages 2197–2205. PMLR, 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gruenstein et al. [2021]</span>
<span class="ltx_bibblock">
A. Gruenstein, A. Gulati, A. Narayanan, B. Li, C. Peyser, C.-C. Chiu,
C. Allauzen, D. J. Rybach, D. A. Caseiro, E. Variani, E. Guzman, I. C.
McGraw, J. Qin, J. Yu, M. D. Riley, P. Rondon, Q. Liang, Q.-N. Le-The,
R. Botros, R. Pang, S. Mavandadi, S. yiin Chang, T. N. Sainath, T. D.
Strohman, W. R. Huang, W. Li, Y. R. He, Y. Wu, and Y. Zhang.

</span>
<span class="ltx_bibblock">An efficient streaming non-recurrent on-device end-to-end model with
improvements to rare-word modeling.

</span>
<span class="ltx_bibblock">2021.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gulati et al. [2020]</span>
<span class="ltx_bibblock">
A. Gulati, J. Qin, C.-C. Chiu, N. Parmar, Y. Zhang, J. Yu, W. Han, S. Wang,
Z. Zhang, Y. Wu, and R. Pang.

</span>
<span class="ltx_bibblock">Conformer: Convolution-augmented Transformer for Speech
Recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2020</em>, pages 5036–5040, 2020.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.21437/Interspeech.2020-3015</span>.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hamer et al. [2020]</span>
<span class="ltx_bibblock">
J. Hamer, M. Mohri, and A. T. Suresh.

</span>
<span class="ltx_bibblock">Fedboost: A communication-efficient algorithm for federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
3973–3983. PMLR, 2020.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hard et al. [2018]</span>
<span class="ltx_bibblock">
A. Hard, K. Rao, R. Mathews, F. Beaufays, S. Augenstein, H. Eichner, C. Kiddon,
and D. Ramage.

</span>
<span class="ltx_bibblock">Federated learning for mobile keyboard prediction.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.03604</em>, 2018.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hard et al. [2020]</span>
<span class="ltx_bibblock">
A. Hard, K. Partridge, C. Nguyen, N. Subrahmanya, A. Shah, P. Zhu, I. L.
Moreno, and R. Mathews.

</span>
<span class="ltx_bibblock">Training keyword spotting models on non-iid data with federated
learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Interspeech</em>, 2020.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hilmkil et al. [2021]</span>
<span class="ltx_bibblock">
A. Hilmkil, S. Callh, M. Barbieri, L. R. Sütfeld, E. L. Zec, and O. Mogren.

</span>
<span class="ltx_bibblock">Scaling federated learning for fine-tuning of large language models.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">International Conference on Applications of Natural Language
to Information Systems</em>, pages 15–23. Springer, 2021.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hochreiter and Schmidhuber [1997]</span>
<span class="ltx_bibblock">
S. Hochreiter and J. Schmidhuber.

</span>
<span class="ltx_bibblock">Long short-term memory.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Neural computation</em>, 9(8):1735–1780, 1997.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Houlsby et al. [2019]</span>
<span class="ltx_bibblock">
N. Houlsby, A. Giurgiu, S. Jastrzebski, B. Morrone, Q. De Laroussilhe,
A. Gesmundo, M. Attariyan, and S. Gelly.

</span>
<span class="ltx_bibblock">Parameter-efficient transfer learning for NLP.

</span>
<span class="ltx_bibblock">In K. Chaudhuri and R. Salakhutdinov, editors, <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">Proceedings of
the 36th International Conference on Machine Learning</em>, volume 97 of
<em id="bib.bib22.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>, pages 2790–2799. PMLR,
09–15 Jun 2019.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://proceedings.mlr.press/v97/houlsby19a.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.mlr.press/v97/houlsby19a.html</a>.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Irie et al. [2019]</span>
<span class="ltx_bibblock">
K. Irie, A. Zeyer, R. Schlüter, and H. Ney.

</span>
<span class="ltx_bibblock">Language modeling with deep transformers.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Interspeech 2019</em>, Sep 2019.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.21437/interspeech.2019-2225</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://dx.doi.org/10.21437/Interspeech.2019-2225" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dx.doi.org/10.21437/Interspeech.2019-2225</a>.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kairouz et al. [2021]</span>
<span class="ltx_bibblock">
P. Kairouz et al.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Foundations and Trends® in Machine Learning</em>,
14(1), 2021.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kannan et al. [2018]</span>
<span class="ltx_bibblock">
A. Kannan, Y. Wu, P. Nguyen, T. N. Sainath, Z. Chen, and R. Prabhavalkar.

</span>
<span class="ltx_bibblock">An analysis of incorporating an external language model into a
sequence-to-sequence model.

</span>
<span class="ltx_bibblock">In <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">2018 IEEE International Conference on Acoustics, Speech and
Signal Processing (ICASSP)</em>, pages 1–5828, 2018.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/ICASSP.2018.8462682</span>.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kaplan et al. [2020]</span>
<span class="ltx_bibblock">
J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child,
S. Gray, A. Radford, J. Wu, and D. Amodei.

</span>
<span class="ltx_bibblock">Scaling laws for neural language models, 2020.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karimireddy et al. [2020]</span>
<span class="ltx_bibblock">
S. P. Karimireddy, M. Jaggi, S. Kale, M. Mohri, S. J. Reddi, S. U. Stich, and
A. T. Suresh.

</span>
<span class="ltx_bibblock">Mime: Mimicking centralized stochastic algorithms in federated
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2008.03606</em>, 2020.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Katharopoulos et al. [2020]</span>
<span class="ltx_bibblock">
A. Katharopoulos, A. Vyas, N. Pappas, and F. Fleuret.

</span>
<span class="ltx_bibblock">Transformers are rnns: Fast autoregressive transformers with linear
attention.

</span>
<span class="ltx_bibblock">In <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">ICML 2020: 37th International Conference on Machine
Learning</em>, volume 1, pages 5156–5165, 2020.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Konečnỳ et al. [2016a]</span>
<span class="ltx_bibblock">
J. Konečnỳ, H. B. McMahan, D. Ramage, and P. Richtárik.

</span>
<span class="ltx_bibblock">Federated optimization: Distributed machine learning for on-device
intelligence.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.02527</em>, 2016a.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Konečnỳ et al. [2016b]</span>
<span class="ltx_bibblock">
J. Konečnỳ, H. B. McMahan, F. X. Yu, P. Richtárik, A. T. Suresh,
and D. Bacon.

</span>
<span class="ltx_bibblock">Federated learning: Strategies for improving communication
efficiency.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.05492</em>, 2016b.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kovaleva et al. [2019]</span>
<span class="ltx_bibblock">
O. Kovaleva, A. Romanov, A. Rogers, and A. Rumshisky.

</span>
<span class="ltx_bibblock">Revealing the dark secrets of BERT.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference on Empirical Methods in
Natural Language Processing and the 9th International Joint Conference on
Natural Language Processing (EMNLP-IJCNLP)</em>, pages 4365–4374, Hong Kong,
China, Nov. 2019. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D19-1445</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/D19-1445" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/D19-1445</a>.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kudo and Richardson [2018]</span>
<span class="ltx_bibblock">
T. Kudo and J. Richardson.

</span>
<span class="ltx_bibblock">SentencePiece: A simple and language independent subword
tokenizer and detokenizer for neural text processing.

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2018 Conference on Empirical Methods in
Natural Language Processing: System Demonstrations</em>, pages 66–71, Brussels,
Belgium, Nov. 2018. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/D18-2012</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://aclanthology.org/D18-2012" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/D18-2012</a>.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2021]</span>
<span class="ltx_bibblock">
B. Li, A. Gulati, J. Yu, T. N. Sainath, C. Chiu, A. Narayanan, S. Chang,
R. Pang, Y. He, J. Qin, W. Han, Q. Liang, Y. Zhang, T. Strohman, and Y. Wu.

</span>
<span class="ltx_bibblock">A better and faster end-to-end model for streaming ASR.

</span>
<span class="ltx_bibblock">In <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">IEEE International Conference on Acoustics, Speech and
Signal Processing, ICASSP 2021, Toronto, ON, Canada, June 6-11, 2021</em>,
pages 5634–5638. IEEE, 2021.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1109/ICASSP39728.2021.9413899</span>.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://doi.org/10.1109/ICASSP39728.2021.9413899" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/ICASSP39728.2021.9413899</a>.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2018]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith.

</span>
<span class="ltx_bibblock">Federated optimization in heterogeneous networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.06127</em>, 2018.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2020]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, A. Talwalkar, and V. Smith.

</span>
<span class="ltx_bibblock">Federated learning: Challenges, methods, and future directions.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">IEEE Signal Processing Magazine</em>, 37(3):50–60, 2020.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. [2020]</span>
<span class="ltx_bibblock">
T. Lin, L. Kong, S. U. Stich, and M. Jaggi.

</span>
<span class="ltx_bibblock">Ensemble distillation for robust model fusion in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
33:2351–2363, 2020.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu and Miller [2020]</span>
<span class="ltx_bibblock">
D. Liu and T. Miller.

</span>
<span class="ltx_bibblock">Federated pretraining and fine tuning of bert using clinical notes
from multiple silos.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.08562</em>, 2020.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. [2017]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized
data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence and Statistics</em>, pages 1273–1282.
PMLR, 2017.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. [2018]</span>
<span class="ltx_bibblock">
H. B. McMahan, D. Ramage, K. Talwar, and L. Zhang.

</span>
<span class="ltx_bibblock">Learning differentially private recurrent language models, 2018.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramaswamy et al. [2020]</span>
<span class="ltx_bibblock">
S. Ramaswamy, O. Thakkar, R. Mathews, G. Andrew, H. B. McMahan, and
F. Beaufays.

</span>
<span class="ltx_bibblock">Training production language models without memorizing user data,
2020.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reddi et al. [2020]</span>
<span class="ltx_bibblock">
S. Reddi, Z. Charles, M. Zaheer, Z. Garrett, K. Rush, J. Konečný, S. Kumar,
and H. B. McMahan.

</span>
<span class="ltx_bibblock">Adaptive federated optimization, 2020.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reisizadeh et al. [2020]</span>
<span class="ltx_bibblock">
A. Reisizadeh, A. Mokhtari, H. Hassani, A. Jadbabaie, and R. Pedarsani.

</span>
<span class="ltx_bibblock">Fedpaq: A communication-efficient federated learning method with
periodic averaging and quantization.

</span>
<span class="ltx_bibblock">In S. Chiappa and R. Calandra, editors, <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
Twenty Third International Conference on Artificial Intelligence and
Statistics</em>, volume 108 of <em id="bib.bib42.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning Research</em>,
pages 2021–2031. PMLR, 26–28 Aug 2020.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://proceedings.mlr.press/v108/reisizadeh20a.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.mlr.press/v108/reisizadeh20a.html</a>.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ro et al. [2021]</span>
<span class="ltx_bibblock">
J. H. Ro, A. T. Suresh, and K. Wu.

</span>
<span class="ltx_bibblock">Fedjax: Federated learning simulation with jax.

</span>
<span class="ltx_bibblock"><em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2108.02117</em>, 2021.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sim et al. [2021]</span>
<span class="ltx_bibblock">
K. C. Sim, A. Chandorkar, F. Gao, M. Chua, T. Munkhdalai, and F. Beaufays.

</span>
<span class="ltx_bibblock">Robust Continuous On-Device Personalization for Automatic Speech
Recognition.

</span>
<span class="ltx_bibblock">In <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">Proc. Interspeech 2021</em>, pages 1284–1288, 2021.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.21437/Interspeech.2021-318</span>.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Statista.com [2021]</span>
<span class="ltx_bibblock">
Statista.com.

</span>
<span class="ltx_bibblock">Average mobile and fixed broadband download and upload speeds
worldwide as of May 2021, 2021.

</span>
<span class="ltx_bibblock">accessed September 26, 2021.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stremmel and Singh [2020]</span>
<span class="ltx_bibblock">
J. Stremmel and A. Singh.

</span>
<span class="ltx_bibblock">Pretraining federated text models for next word prediction.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2005.04828, 2020.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://arxiv.org/abs/2005.04828" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2005.04828</a>.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Suresh et al. [2017]</span>
<span class="ltx_bibblock">
A. T. Suresh, F. X. Yu, S. Kumar, and H. B. McMahan.

</span>
<span class="ltx_bibblock">Distributed mean estimation with limited communication.

</span>
<span class="ltx_bibblock">In <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 34th International Conference on Machine
Learning-Volume 70</em>, pages 3329–3337. JMLR. org, 2017.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tay et al. [2020]</span>
<span class="ltx_bibblock">
Y. Tay, M. Dehghani, D. Bahri, and D. Metzler.

</span>
<span class="ltx_bibblock">Efficient transformers: A survey, 2020.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tay et al. [2021]</span>
<span class="ltx_bibblock">
Y. Tay, M. Dehghani, S. Abnar, Y. Shen, D. Bahri, P. Pham, J. Rao, L. Yang,
S. Ruder, and D. Metzler.

</span>
<span class="ltx_bibblock">Long range arena : A benchmark for efficient transformers.

</span>
<span class="ltx_bibblock">In <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=qVyeW-grC2k" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=qVyeW-grC2k</a>.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">TFF [2018]</span>
<span class="ltx_bibblock">
TFF.

</span>
<span class="ltx_bibblock">Tensorflow federated, 2018.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.tensorflow.org/federated" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.tensorflow.org/federated</a>.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vargaftik et al. [2021]</span>
<span class="ltx_bibblock">
S. Vargaftik, R. Ben-Basat, A. Portnoy, G. Mendelson, Y. Ben-Itzhak, and
M. Mitzenmacher.

</span>
<span class="ltx_bibblock">DRIVE: One-bit distributed mean estimation.

</span>
<span class="ltx_bibblock">In A. Beygelzimer, Y. Dauphin, P. Liang, and J. W. Vaughan, editors,
<em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>, 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://openreview.net/forum?id=KXRTmcv3dQ8" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=KXRTmcv3dQ8</a>.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Variani et al. [2020]</span>
<span class="ltx_bibblock">
E. Variani, D. Rybach, C. Allauzen, and M. Riley.

</span>
<span class="ltx_bibblock">Hybrid autoregressive transducer (hat), 2020.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al. [2017]</span>
<span class="ltx_bibblock">
A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. u.
Kaiser, and I. Polosukhin.

</span>
<span class="ltx_bibblock">Attention is all you need.

</span>
<span class="ltx_bibblock">In I. Guyon, U. V. Luxburg, S. Bengio, H. Wallach, R. Fergus,
S. Vishwanathan, and R. Garnett, editors, <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">Advances in Neural
Information Processing Systems</em>, volume 30. Curran Associates, Inc., 2017.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wen et al. [2017]</span>
<span class="ltx_bibblock">
W. Wen, C. Xu, F. Yan, C. Wu, Y. Wang, Y. Chen, and H. Li.

</span>
<span class="ltx_bibblock">Terngrad: Ternary gradients to reduce communication in distributed
deep learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/1705.07878, 2017.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="http://arxiv.org/abs/1705.07878" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://arxiv.org/abs/1705.07878</a>.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. [2021]</span>
<span class="ltx_bibblock">
T.-J. Yang, D. Guliani, F. Beaufays, and G. Motta.

</span>
<span class="ltx_bibblock">Partial variable training for efficient on-device federated learning,
2021.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. [2019]</span>
<span class="ltx_bibblock">
Z. Yang, Z. Dai, Y. Yang, J. Carbonell, R. R. Salakhutdinov, and Q. V. Le.

</span>
<span class="ltx_bibblock">Xlnet: Generalized autoregressive pretraining for language
understanding.

</span>
<span class="ltx_bibblock">In H. Wallach, H. Larochelle, A. Beygelzimer, F. d Alché-Buc,
E. Fox, and R. Garnett, editors, <em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information
Processing Systems</em>, volume 32. Curran Associates, Inc., 2019.

</span>
<span class="ltx_bibblock">URL
<a target="_blank" href="https://proceedings.neurips.cc/paper/2019/file/dc6a7e655d7e5840e66733e9ee67cc69-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2019/file/dc6a7e655d7e5840e66733e9ee67cc69-Paper.pdf</a>.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. [2021]</span>
<span class="ltx_bibblock">
H. Zhang, Y.-C. Cheng, S. Kumar, M. Chen, and R. Mathews.

</span>
<span class="ltx_bibblock">Position-invariant truecasing with a word-and-character hierarchical
recurrent neural network.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2108.11943, 2021.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zoph et al. [2020]</span>
<span class="ltx_bibblock">
B. Zoph, G. Ghiasi, T.-Y. Lin, Y. Cui, H. Liu, E. D. Cubuk, and Q. Le.

</span>
<span class="ltx_bibblock">Rethinking pre-training and self-training.

</span>
<span class="ltx_bibblock">In <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">NeurIPS</em>, 2020.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p ltx_align_center"><span id="p1.1.1" class="ltx_text" style="font-size:144%;">Appendix</span></p>
</div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Dataset and models</h2>

<figure id="A1.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2204.09715/assets/so_train_num_sent.png" id="A1.F9.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="183" height="130" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2204.09715/assets/so_train_num_wp.png" id="A1.F9.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="180" height="130" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2204.09715/assets/so_train_wp_length.png" id="A1.F9.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="178" height="130" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Stack Overflow train split sub-word statistics.</figcaption>
</figure>
<figure id="A1.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Selected architectures for each model and size range. The values in <math id="A1.T1.2.m1.1" class="ltx_Math" alttext="[\ ]" display="inline"><semantics id="A1.T1.2.m1.1b"><mrow id="A1.T1.2.m1.1.1.2"><mo rspace="0.500em" stretchy="false" id="A1.T1.2.m1.1.1.2.1" xref="A1.T1.2.m1.1.1.1.cmml">[</mo><mo stretchy="false" id="A1.T1.2.m1.1.1.2.2" xref="A1.T1.2.m1.1.1.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.T1.2.m1.1c"><list id="A1.T1.2.m1.1.1.1.cmml" xref="A1.T1.2.m1.1.1.2.1"></list></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.2.m1.1d">[\ ]</annotation></semantics></math> are the possible hyperparameter values searched over.
Layer Size refers to the LSTM layer dimension and MLP layer dimension for Transformer and # Layers refers to number of LSTM layers and number of Transformer and Conformer blocks. Note that for the Conformer, the Layer Size is directly tied to the Embedding Size.</figcaption>
<table id="A1.T1.28" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T1.28.27.1" class="ltx_tr">
<th id="A1.T1.28.27.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column">Model</th>
<th id="A1.T1.28.27.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"># Parameters</th>
<th id="A1.T1.28.27.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">Embedding Size</th>
<th id="A1.T1.28.27.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">Layer Size</th>
<th id="A1.T1.28.27.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column"># Layers</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T1.5.3" class="ltx_tr">
<td id="A1.T1.5.3.4" class="ltx_td"></td>
<th id="A1.T1.5.3.5" class="ltx_td ltx_th ltx_th_column"></th>
<th id="A1.T1.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column"><math id="A1.T1.3.1.1.m1.4" class="ltx_Math" alttext="[128,256,512,1024]" display="inline"><semantics id="A1.T1.3.1.1.m1.4a"><mrow id="A1.T1.3.1.1.m1.4.5.2" xref="A1.T1.3.1.1.m1.4.5.1.cmml"><mo stretchy="false" id="A1.T1.3.1.1.m1.4.5.2.1" xref="A1.T1.3.1.1.m1.4.5.1.cmml">[</mo><mn id="A1.T1.3.1.1.m1.1.1" xref="A1.T1.3.1.1.m1.1.1.cmml">128</mn><mo id="A1.T1.3.1.1.m1.4.5.2.2" xref="A1.T1.3.1.1.m1.4.5.1.cmml">,</mo><mn id="A1.T1.3.1.1.m1.2.2" xref="A1.T1.3.1.1.m1.2.2.cmml">256</mn><mo id="A1.T1.3.1.1.m1.4.5.2.3" xref="A1.T1.3.1.1.m1.4.5.1.cmml">,</mo><mn id="A1.T1.3.1.1.m1.3.3" xref="A1.T1.3.1.1.m1.3.3.cmml">512</mn><mo id="A1.T1.3.1.1.m1.4.5.2.4" xref="A1.T1.3.1.1.m1.4.5.1.cmml">,</mo><mn id="A1.T1.3.1.1.m1.4.4" xref="A1.T1.3.1.1.m1.4.4.cmml">1024</mn><mo stretchy="false" id="A1.T1.3.1.1.m1.4.5.2.5" xref="A1.T1.3.1.1.m1.4.5.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.T1.3.1.1.m1.4b"><list id="A1.T1.3.1.1.m1.4.5.1.cmml" xref="A1.T1.3.1.1.m1.4.5.2"><cn type="integer" id="A1.T1.3.1.1.m1.1.1.cmml" xref="A1.T1.3.1.1.m1.1.1">128</cn><cn type="integer" id="A1.T1.3.1.1.m1.2.2.cmml" xref="A1.T1.3.1.1.m1.2.2">256</cn><cn type="integer" id="A1.T1.3.1.1.m1.3.3.cmml" xref="A1.T1.3.1.1.m1.3.3">512</cn><cn type="integer" id="A1.T1.3.1.1.m1.4.4.cmml" xref="A1.T1.3.1.1.m1.4.4">1024</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.3.1.1.m1.4c">[128,256,512,1024]</annotation></semantics></math></th>
<th id="A1.T1.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"><math id="A1.T1.4.2.2.m1.3" class="ltx_Math" alttext="[512,1024,2048]" display="inline"><semantics id="A1.T1.4.2.2.m1.3a"><mrow id="A1.T1.4.2.2.m1.3.4.2" xref="A1.T1.4.2.2.m1.3.4.1.cmml"><mo stretchy="false" id="A1.T1.4.2.2.m1.3.4.2.1" xref="A1.T1.4.2.2.m1.3.4.1.cmml">[</mo><mn id="A1.T1.4.2.2.m1.1.1" xref="A1.T1.4.2.2.m1.1.1.cmml">512</mn><mo id="A1.T1.4.2.2.m1.3.4.2.2" xref="A1.T1.4.2.2.m1.3.4.1.cmml">,</mo><mn id="A1.T1.4.2.2.m1.2.2" xref="A1.T1.4.2.2.m1.2.2.cmml">1024</mn><mo id="A1.T1.4.2.2.m1.3.4.2.3" xref="A1.T1.4.2.2.m1.3.4.1.cmml">,</mo><mn id="A1.T1.4.2.2.m1.3.3" xref="A1.T1.4.2.2.m1.3.3.cmml">2048</mn><mo stretchy="false" id="A1.T1.4.2.2.m1.3.4.2.4" xref="A1.T1.4.2.2.m1.3.4.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.T1.4.2.2.m1.3b"><list id="A1.T1.4.2.2.m1.3.4.1.cmml" xref="A1.T1.4.2.2.m1.3.4.2"><cn type="integer" id="A1.T1.4.2.2.m1.1.1.cmml" xref="A1.T1.4.2.2.m1.1.1">512</cn><cn type="integer" id="A1.T1.4.2.2.m1.2.2.cmml" xref="A1.T1.4.2.2.m1.2.2">1024</cn><cn type="integer" id="A1.T1.4.2.2.m1.3.3.cmml" xref="A1.T1.4.2.2.m1.3.3">2048</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.4.2.2.m1.3c">[512,1024,2048]</annotation></semantics></math></th>
<th id="A1.T1.5.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column"><math id="A1.T1.5.3.3.m1.6" class="ltx_Math" alttext="[1,2,3,4,6,8]" display="inline"><semantics id="A1.T1.5.3.3.m1.6a"><mrow id="A1.T1.5.3.3.m1.6.7.2" xref="A1.T1.5.3.3.m1.6.7.1.cmml"><mo stretchy="false" id="A1.T1.5.3.3.m1.6.7.2.1" xref="A1.T1.5.3.3.m1.6.7.1.cmml">[</mo><mn id="A1.T1.5.3.3.m1.1.1" xref="A1.T1.5.3.3.m1.1.1.cmml">1</mn><mo id="A1.T1.5.3.3.m1.6.7.2.2" xref="A1.T1.5.3.3.m1.6.7.1.cmml">,</mo><mn id="A1.T1.5.3.3.m1.2.2" xref="A1.T1.5.3.3.m1.2.2.cmml">2</mn><mo id="A1.T1.5.3.3.m1.6.7.2.3" xref="A1.T1.5.3.3.m1.6.7.1.cmml">,</mo><mn id="A1.T1.5.3.3.m1.3.3" xref="A1.T1.5.3.3.m1.3.3.cmml">3</mn><mo id="A1.T1.5.3.3.m1.6.7.2.4" xref="A1.T1.5.3.3.m1.6.7.1.cmml">,</mo><mn id="A1.T1.5.3.3.m1.4.4" xref="A1.T1.5.3.3.m1.4.4.cmml">4</mn><mo id="A1.T1.5.3.3.m1.6.7.2.5" xref="A1.T1.5.3.3.m1.6.7.1.cmml">,</mo><mn id="A1.T1.5.3.3.m1.5.5" xref="A1.T1.5.3.3.m1.5.5.cmml">6</mn><mo id="A1.T1.5.3.3.m1.6.7.2.6" xref="A1.T1.5.3.3.m1.6.7.1.cmml">,</mo><mn id="A1.T1.5.3.3.m1.6.6" xref="A1.T1.5.3.3.m1.6.6.cmml">8</mn><mo stretchy="false" id="A1.T1.5.3.3.m1.6.7.2.7" xref="A1.T1.5.3.3.m1.6.7.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.T1.5.3.3.m1.6b"><list id="A1.T1.5.3.3.m1.6.7.1.cmml" xref="A1.T1.5.3.3.m1.6.7.2"><cn type="integer" id="A1.T1.5.3.3.m1.1.1.cmml" xref="A1.T1.5.3.3.m1.1.1">1</cn><cn type="integer" id="A1.T1.5.3.3.m1.2.2.cmml" xref="A1.T1.5.3.3.m1.2.2">2</cn><cn type="integer" id="A1.T1.5.3.3.m1.3.3.cmml" xref="A1.T1.5.3.3.m1.3.3">3</cn><cn type="integer" id="A1.T1.5.3.3.m1.4.4.cmml" xref="A1.T1.5.3.3.m1.4.4">4</cn><cn type="integer" id="A1.T1.5.3.3.m1.5.5.cmml" xref="A1.T1.5.3.3.m1.5.5">6</cn><cn type="integer" id="A1.T1.5.3.3.m1.6.6.cmml" xref="A1.T1.5.3.3.m1.6.6">8</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.5.3.3.m1.6c">[1,2,3,4,6,8]</annotation></semantics></math></th>
</tr>
<tr id="A1.T1.9.7" class="ltx_tr">
<td id="A1.T1.9.7.5" class="ltx_td ltx_align_center ltx_border_t">Small LSTM</td>
<td id="A1.T1.6.4.1" class="ltx_td ltx_align_center ltx_border_t">
<math id="A1.T1.6.4.1.m1.1" class="ltx_Math" alttext="4.7" display="inline"><semantics id="A1.T1.6.4.1.m1.1a"><mn id="A1.T1.6.4.1.m1.1.1" xref="A1.T1.6.4.1.m1.1.1.cmml">4.7</mn><annotation-xml encoding="MathML-Content" id="A1.T1.6.4.1.m1.1b"><cn type="float" id="A1.T1.6.4.1.m1.1.1.cmml" xref="A1.T1.6.4.1.m1.1.1">4.7</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.6.4.1.m1.1c">4.7</annotation></semantics></math>M</td>
<td id="A1.T1.7.5.2" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T1.7.5.2.m1.1" class="ltx_Math" alttext="256" display="inline"><semantics id="A1.T1.7.5.2.m1.1a"><mn id="A1.T1.7.5.2.m1.1.1" xref="A1.T1.7.5.2.m1.1.1.cmml">256</mn><annotation-xml encoding="MathML-Content" id="A1.T1.7.5.2.m1.1b"><cn type="integer" id="A1.T1.7.5.2.m1.1.1.cmml" xref="A1.T1.7.5.2.m1.1.1">256</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.7.5.2.m1.1c">256</annotation></semantics></math></td>
<td id="A1.T1.8.6.3" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T1.8.6.3.m1.1" class="ltx_Math" alttext="2048" display="inline"><semantics id="A1.T1.8.6.3.m1.1a"><mn id="A1.T1.8.6.3.m1.1.1" xref="A1.T1.8.6.3.m1.1.1.cmml">2048</mn><annotation-xml encoding="MathML-Content" id="A1.T1.8.6.3.m1.1b"><cn type="integer" id="A1.T1.8.6.3.m1.1.1.cmml" xref="A1.T1.8.6.3.m1.1.1">2048</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.8.6.3.m1.1c">2048</annotation></semantics></math></td>
<td id="A1.T1.9.7.4" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T1.9.7.4.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="A1.T1.9.7.4.m1.1a"><mn id="A1.T1.9.7.4.m1.1.1" xref="A1.T1.9.7.4.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A1.T1.9.7.4.m1.1b"><cn type="integer" id="A1.T1.9.7.4.m1.1.1.cmml" xref="A1.T1.9.7.4.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.9.7.4.m1.1c">1</annotation></semantics></math></td>
</tr>
<tr id="A1.T1.13.11" class="ltx_tr">
<td id="A1.T1.13.11.5" class="ltx_td ltx_align_center">Small Transformer</td>
<td id="A1.T1.10.8.1" class="ltx_td ltx_align_center">
<math id="A1.T1.10.8.1.m1.1" class="ltx_Math" alttext="4.1" display="inline"><semantics id="A1.T1.10.8.1.m1.1a"><mn id="A1.T1.10.8.1.m1.1.1" xref="A1.T1.10.8.1.m1.1.1.cmml">4.1</mn><annotation-xml encoding="MathML-Content" id="A1.T1.10.8.1.m1.1b"><cn type="float" id="A1.T1.10.8.1.m1.1.1.cmml" xref="A1.T1.10.8.1.m1.1.1">4.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.10.8.1.m1.1c">4.1</annotation></semantics></math>M</td>
<td id="A1.T1.11.9.2" class="ltx_td ltx_align_center"><math id="A1.T1.11.9.2.m1.1" class="ltx_Math" alttext="128" display="inline"><semantics id="A1.T1.11.9.2.m1.1a"><mn id="A1.T1.11.9.2.m1.1.1" xref="A1.T1.11.9.2.m1.1.1.cmml">128</mn><annotation-xml encoding="MathML-Content" id="A1.T1.11.9.2.m1.1b"><cn type="integer" id="A1.T1.11.9.2.m1.1.1.cmml" xref="A1.T1.11.9.2.m1.1.1">128</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.11.9.2.m1.1c">128</annotation></semantics></math></td>
<td id="A1.T1.12.10.3" class="ltx_td ltx_align_center"><math id="A1.T1.12.10.3.m1.1" class="ltx_Math" alttext="2048" display="inline"><semantics id="A1.T1.12.10.3.m1.1a"><mn id="A1.T1.12.10.3.m1.1.1" xref="A1.T1.12.10.3.m1.1.1.cmml">2048</mn><annotation-xml encoding="MathML-Content" id="A1.T1.12.10.3.m1.1b"><cn type="integer" id="A1.T1.12.10.3.m1.1.1.cmml" xref="A1.T1.12.10.3.m1.1.1">2048</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.12.10.3.m1.1c">2048</annotation></semantics></math></td>
<td id="A1.T1.13.11.4" class="ltx_td ltx_align_center"><math id="A1.T1.13.11.4.m1.1" class="ltx_Math" alttext="6" display="inline"><semantics id="A1.T1.13.11.4.m1.1a"><mn id="A1.T1.13.11.4.m1.1.1" xref="A1.T1.13.11.4.m1.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="A1.T1.13.11.4.m1.1b"><cn type="integer" id="A1.T1.13.11.4.m1.1.1.cmml" xref="A1.T1.13.11.4.m1.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.13.11.4.m1.1c">6</annotation></semantics></math></td>
</tr>
<tr id="A1.T1.16.14" class="ltx_tr">
<td id="A1.T1.16.14.4" class="ltx_td ltx_align_center">Small Conformer</td>
<td id="A1.T1.14.12.1" class="ltx_td ltx_align_center">
<math id="A1.T1.14.12.1.m1.1" class="ltx_Math" alttext="4.1" display="inline"><semantics id="A1.T1.14.12.1.m1.1a"><mn id="A1.T1.14.12.1.m1.1.1" xref="A1.T1.14.12.1.m1.1.1.cmml">4.1</mn><annotation-xml encoding="MathML-Content" id="A1.T1.14.12.1.m1.1b"><cn type="float" id="A1.T1.14.12.1.m1.1.1.cmml" xref="A1.T1.14.12.1.m1.1.1">4.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.14.12.1.m1.1c">4.1</annotation></semantics></math>M</td>
<td id="A1.T1.16.14.5" class="ltx_td ltx_align_center">256</td>
<td id="A1.T1.15.13.2" class="ltx_td ltx_align_center"><math id="A1.T1.15.13.2.m1.1" class="ltx_Math" alttext="-" display="inline"><semantics id="A1.T1.15.13.2.m1.1a"><mo id="A1.T1.15.13.2.m1.1.1" xref="A1.T1.15.13.2.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="A1.T1.15.13.2.m1.1b"><minus id="A1.T1.15.13.2.m1.1.1.cmml" xref="A1.T1.15.13.2.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.15.13.2.m1.1c">-</annotation></semantics></math></td>
<td id="A1.T1.16.14.3" class="ltx_td ltx_align_center"><math id="A1.T1.16.14.3.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="A1.T1.16.14.3.m1.1a"><mn id="A1.T1.16.14.3.m1.1.1" xref="A1.T1.16.14.3.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A1.T1.16.14.3.m1.1b"><cn type="integer" id="A1.T1.16.14.3.m1.1.1.cmml" xref="A1.T1.16.14.3.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.16.14.3.m1.1c">2</annotation></semantics></math></td>
</tr>
<tr id="A1.T1.20.18" class="ltx_tr">
<td id="A1.T1.20.18.5" class="ltx_td ltx_align_center ltx_border_t">Large LSTM</td>
<td id="A1.T1.17.15.1" class="ltx_td ltx_align_center ltx_border_t">
<math id="A1.T1.17.15.1.m1.1" class="ltx_Math" alttext="18.8" display="inline"><semantics id="A1.T1.17.15.1.m1.1a"><mn id="A1.T1.17.15.1.m1.1.1" xref="A1.T1.17.15.1.m1.1.1.cmml">18.8</mn><annotation-xml encoding="MathML-Content" id="A1.T1.17.15.1.m1.1b"><cn type="float" id="A1.T1.17.15.1.m1.1.1.cmml" xref="A1.T1.17.15.1.m1.1.1">18.8</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.17.15.1.m1.1c">18.8</annotation></semantics></math>M</td>
<td id="A1.T1.18.16.2" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T1.18.16.2.m1.1" class="ltx_Math" alttext="1024" display="inline"><semantics id="A1.T1.18.16.2.m1.1a"><mn id="A1.T1.18.16.2.m1.1.1" xref="A1.T1.18.16.2.m1.1.1.cmml">1024</mn><annotation-xml encoding="MathML-Content" id="A1.T1.18.16.2.m1.1b"><cn type="integer" id="A1.T1.18.16.2.m1.1.1.cmml" xref="A1.T1.18.16.2.m1.1.1">1024</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.18.16.2.m1.1c">1024</annotation></semantics></math></td>
<td id="A1.T1.19.17.3" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T1.19.17.3.m1.1" class="ltx_Math" alttext="2048" display="inline"><semantics id="A1.T1.19.17.3.m1.1a"><mn id="A1.T1.19.17.3.m1.1.1" xref="A1.T1.19.17.3.m1.1.1.cmml">2048</mn><annotation-xml encoding="MathML-Content" id="A1.T1.19.17.3.m1.1b"><cn type="integer" id="A1.T1.19.17.3.m1.1.1.cmml" xref="A1.T1.19.17.3.m1.1.1">2048</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.19.17.3.m1.1c">2048</annotation></semantics></math></td>
<td id="A1.T1.20.18.4" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T1.20.18.4.m1.1" class="ltx_Math" alttext="1" display="inline"><semantics id="A1.T1.20.18.4.m1.1a"><mn id="A1.T1.20.18.4.m1.1.1" xref="A1.T1.20.18.4.m1.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A1.T1.20.18.4.m1.1b"><cn type="integer" id="A1.T1.20.18.4.m1.1.1.cmml" xref="A1.T1.20.18.4.m1.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.20.18.4.m1.1c">1</annotation></semantics></math></td>
</tr>
<tr id="A1.T1.24.22" class="ltx_tr">
<td id="A1.T1.24.22.5" class="ltx_td ltx_align_center">Large Transformer</td>
<td id="A1.T1.21.19.1" class="ltx_td ltx_align_center">
<math id="A1.T1.21.19.1.m1.1" class="ltx_Math" alttext="21.0" display="inline"><semantics id="A1.T1.21.19.1.m1.1a"><mn id="A1.T1.21.19.1.m1.1.1" xref="A1.T1.21.19.1.m1.1.1.cmml">21.0</mn><annotation-xml encoding="MathML-Content" id="A1.T1.21.19.1.m1.1b"><cn type="float" id="A1.T1.21.19.1.m1.1.1.cmml" xref="A1.T1.21.19.1.m1.1.1">21.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.21.19.1.m1.1c">21.0</annotation></semantics></math>M</td>
<td id="A1.T1.22.20.2" class="ltx_td ltx_align_center"><math id="A1.T1.22.20.2.m1.1" class="ltx_Math" alttext="512" display="inline"><semantics id="A1.T1.22.20.2.m1.1a"><mn id="A1.T1.22.20.2.m1.1.1" xref="A1.T1.22.20.2.m1.1.1.cmml">512</mn><annotation-xml encoding="MathML-Content" id="A1.T1.22.20.2.m1.1b"><cn type="integer" id="A1.T1.22.20.2.m1.1.1.cmml" xref="A1.T1.22.20.2.m1.1.1">512</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.22.20.2.m1.1c">512</annotation></semantics></math></td>
<td id="A1.T1.23.21.3" class="ltx_td ltx_align_center"><math id="A1.T1.23.21.3.m1.1" class="ltx_Math" alttext="2048" display="inline"><semantics id="A1.T1.23.21.3.m1.1a"><mn id="A1.T1.23.21.3.m1.1.1" xref="A1.T1.23.21.3.m1.1.1.cmml">2048</mn><annotation-xml encoding="MathML-Content" id="A1.T1.23.21.3.m1.1b"><cn type="integer" id="A1.T1.23.21.3.m1.1.1.cmml" xref="A1.T1.23.21.3.m1.1.1">2048</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.23.21.3.m1.1c">2048</annotation></semantics></math></td>
<td id="A1.T1.24.22.4" class="ltx_td ltx_align_center"><math id="A1.T1.24.22.4.m1.1" class="ltx_Math" alttext="6" display="inline"><semantics id="A1.T1.24.22.4.m1.1a"><mn id="A1.T1.24.22.4.m1.1.1" xref="A1.T1.24.22.4.m1.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="A1.T1.24.22.4.m1.1b"><cn type="integer" id="A1.T1.24.22.4.m1.1.1.cmml" xref="A1.T1.24.22.4.m1.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.24.22.4.m1.1c">6</annotation></semantics></math></td>
</tr>
<tr id="A1.T1.28.26" class="ltx_tr">
<td id="A1.T1.28.26.5" class="ltx_td ltx_align_center">Large Conformer</td>
<td id="A1.T1.25.23.1" class="ltx_td ltx_align_center">
<math id="A1.T1.25.23.1.m1.1" class="ltx_Math" alttext="20.2" display="inline"><semantics id="A1.T1.25.23.1.m1.1a"><mn id="A1.T1.25.23.1.m1.1.1" xref="A1.T1.25.23.1.m1.1.1.cmml">20.2</mn><annotation-xml encoding="MathML-Content" id="A1.T1.25.23.1.m1.1b"><cn type="float" id="A1.T1.25.23.1.m1.1.1.cmml" xref="A1.T1.25.23.1.m1.1.1">20.2</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.25.23.1.m1.1c">20.2</annotation></semantics></math>M</td>
<td id="A1.T1.26.24.2" class="ltx_td ltx_align_center"><math id="A1.T1.26.24.2.m1.1" class="ltx_Math" alttext="512" display="inline"><semantics id="A1.T1.26.24.2.m1.1a"><mn id="A1.T1.26.24.2.m1.1.1" xref="A1.T1.26.24.2.m1.1.1.cmml">512</mn><annotation-xml encoding="MathML-Content" id="A1.T1.26.24.2.m1.1b"><cn type="integer" id="A1.T1.26.24.2.m1.1.1.cmml" xref="A1.T1.26.24.2.m1.1.1">512</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.26.24.2.m1.1c">512</annotation></semantics></math></td>
<td id="A1.T1.27.25.3" class="ltx_td ltx_align_center"><math id="A1.T1.27.25.3.m1.1" class="ltx_Math" alttext="-" display="inline"><semantics id="A1.T1.27.25.3.m1.1a"><mo id="A1.T1.27.25.3.m1.1.1" xref="A1.T1.27.25.3.m1.1.1.cmml">−</mo><annotation-xml encoding="MathML-Content" id="A1.T1.27.25.3.m1.1b"><minus id="A1.T1.27.25.3.m1.1.1.cmml" xref="A1.T1.27.25.3.m1.1.1"></minus></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.27.25.3.m1.1c">-</annotation></semantics></math></td>
<td id="A1.T1.28.26.4" class="ltx_td ltx_align_center"><math id="A1.T1.28.26.4.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="A1.T1.28.26.4.m1.1a"><mn id="A1.T1.28.26.4.m1.1.1" xref="A1.T1.28.26.4.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="A1.T1.28.26.4.m1.1b"><cn type="integer" id="A1.T1.28.26.4.m1.1.1.cmml" xref="A1.T1.28.26.4.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T1.28.26.4.m1.1c">3</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
<figure id="A1.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Test metrics after <math id="A1.T2.2.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.T2.2.m1.1b"><mn id="A1.T2.2.m1.1.1" xref="A1.T2.2.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.T2.2.m1.1c"><cn type="integer" id="A1.T2.2.m1.1.1.cmml" xref="A1.T2.2.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.2.m1.1d">10</annotation></semantics></math>K rounds of training for each class of model and number of clients per round. The results in <span id="A1.T2.40.1" class="ltx_text ltx_font_bold">bold</span> indicate the best for each size range.</figcaption>
<table id="A1.T2.38" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T2.38.37.1" class="ltx_tr">
<th id="A1.T2.38.37.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row">Model</th>
<th id="A1.T2.38.37.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"># Clients</th>
<th id="A1.T2.38.37.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">Perplexity</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T2.4.2" class="ltx_tr">
<th id="A1.T2.4.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Small LSTM</th>
<td id="A1.T2.3.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T2.3.1.1.m1.1" class="ltx_Math" alttext="200" display="inline"><semantics id="A1.T2.3.1.1.m1.1a"><mn id="A1.T2.3.1.1.m1.1.1" xref="A1.T2.3.1.1.m1.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="A1.T2.3.1.1.m1.1b"><cn type="integer" id="A1.T2.3.1.1.m1.1.1.cmml" xref="A1.T2.3.1.1.m1.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.3.1.1.m1.1c">200</annotation></semantics></math></td>
<td id="A1.T2.4.2.2" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T2.4.2.2.m1.1" class="ltx_Math" alttext="35.31" display="inline"><semantics id="A1.T2.4.2.2.m1.1a"><mn id="A1.T2.4.2.2.m1.1.1" xref="A1.T2.4.2.2.m1.1.1.cmml">35.31</mn><annotation-xml encoding="MathML-Content" id="A1.T2.4.2.2.m1.1b"><cn type="float" id="A1.T2.4.2.2.m1.1.1.cmml" xref="A1.T2.4.2.2.m1.1.1">35.31</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.4.2.2.m1.1c">35.31</annotation></semantics></math></td>
</tr>
<tr id="A1.T2.6.4" class="ltx_tr">
<th id="A1.T2.6.4.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Small LSTM</th>
<td id="A1.T2.5.3.1" class="ltx_td ltx_align_center"><math id="A1.T2.5.3.1.m1.1" class="ltx_Math" alttext="400" display="inline"><semantics id="A1.T2.5.3.1.m1.1a"><mn id="A1.T2.5.3.1.m1.1.1" xref="A1.T2.5.3.1.m1.1.1.cmml">400</mn><annotation-xml encoding="MathML-Content" id="A1.T2.5.3.1.m1.1b"><cn type="integer" id="A1.T2.5.3.1.m1.1.1.cmml" xref="A1.T2.5.3.1.m1.1.1">400</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.5.3.1.m1.1c">400</annotation></semantics></math></td>
<td id="A1.T2.6.4.2" class="ltx_td ltx_align_center"><math id="A1.T2.6.4.2.m1.1" class="ltx_Math" alttext="34.93" display="inline"><semantics id="A1.T2.6.4.2.m1.1a"><mn id="A1.T2.6.4.2.m1.1.1" xref="A1.T2.6.4.2.m1.1.1.cmml">34.93</mn><annotation-xml encoding="MathML-Content" id="A1.T2.6.4.2.m1.1b"><cn type="float" id="A1.T2.6.4.2.m1.1.1.cmml" xref="A1.T2.6.4.2.m1.1.1">34.93</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.6.4.2.m1.1c">34.93</annotation></semantics></math></td>
</tr>
<tr id="A1.T2.8.6" class="ltx_tr">
<th id="A1.T2.8.6.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Small LSTM</th>
<td id="A1.T2.7.5.1" class="ltx_td ltx_align_center"><math id="A1.T2.7.5.1.m1.1" class="ltx_Math" alttext="800" display="inline"><semantics id="A1.T2.7.5.1.m1.1a"><mn id="A1.T2.7.5.1.m1.1.1" xref="A1.T2.7.5.1.m1.1.1.cmml">800</mn><annotation-xml encoding="MathML-Content" id="A1.T2.7.5.1.m1.1b"><cn type="integer" id="A1.T2.7.5.1.m1.1.1.cmml" xref="A1.T2.7.5.1.m1.1.1">800</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.7.5.1.m1.1c">800</annotation></semantics></math></td>
<td id="A1.T2.8.6.2" class="ltx_td ltx_align_center"><math id="A1.T2.8.6.2.m1.1" class="ltx_Math" alttext="\mathbf{34.80}" display="inline"><semantics id="A1.T2.8.6.2.m1.1a"><mn class="ltx_mathvariant_bold" mathvariant="bold" id="A1.T2.8.6.2.m1.1.1" xref="A1.T2.8.6.2.m1.1.1.cmml">34.80</mn><annotation-xml encoding="MathML-Content" id="A1.T2.8.6.2.m1.1b"><cn type="float" id="A1.T2.8.6.2.m1.1.1.cmml" xref="A1.T2.8.6.2.m1.1.1">34.80</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.8.6.2.m1.1c">\mathbf{34.80}</annotation></semantics></math></td>
</tr>
<tr id="A1.T2.10.8" class="ltx_tr">
<th id="A1.T2.10.8.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Small Transformer</th>
<td id="A1.T2.9.7.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T2.9.7.1.m1.1" class="ltx_Math" alttext="200" display="inline"><semantics id="A1.T2.9.7.1.m1.1a"><mn id="A1.T2.9.7.1.m1.1.1" xref="A1.T2.9.7.1.m1.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="A1.T2.9.7.1.m1.1b"><cn type="integer" id="A1.T2.9.7.1.m1.1.1.cmml" xref="A1.T2.9.7.1.m1.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.9.7.1.m1.1c">200</annotation></semantics></math></td>
<td id="A1.T2.10.8.2" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T2.10.8.2.m1.1" class="ltx_Math" alttext="40.18" display="inline"><semantics id="A1.T2.10.8.2.m1.1a"><mn id="A1.T2.10.8.2.m1.1.1" xref="A1.T2.10.8.2.m1.1.1.cmml">40.18</mn><annotation-xml encoding="MathML-Content" id="A1.T2.10.8.2.m1.1b"><cn type="float" id="A1.T2.10.8.2.m1.1.1.cmml" xref="A1.T2.10.8.2.m1.1.1">40.18</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.10.8.2.m1.1c">40.18</annotation></semantics></math></td>
</tr>
<tr id="A1.T2.12.10" class="ltx_tr">
<th id="A1.T2.12.10.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Small Transformer</th>
<td id="A1.T2.11.9.1" class="ltx_td ltx_align_center"><math id="A1.T2.11.9.1.m1.1" class="ltx_Math" alttext="400" display="inline"><semantics id="A1.T2.11.9.1.m1.1a"><mn id="A1.T2.11.9.1.m1.1.1" xref="A1.T2.11.9.1.m1.1.1.cmml">400</mn><annotation-xml encoding="MathML-Content" id="A1.T2.11.9.1.m1.1b"><cn type="integer" id="A1.T2.11.9.1.m1.1.1.cmml" xref="A1.T2.11.9.1.m1.1.1">400</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.11.9.1.m1.1c">400</annotation></semantics></math></td>
<td id="A1.T2.12.10.2" class="ltx_td ltx_align_center"><math id="A1.T2.12.10.2.m1.1" class="ltx_Math" alttext="39.38" display="inline"><semantics id="A1.T2.12.10.2.m1.1a"><mn id="A1.T2.12.10.2.m1.1.1" xref="A1.T2.12.10.2.m1.1.1.cmml">39.38</mn><annotation-xml encoding="MathML-Content" id="A1.T2.12.10.2.m1.1b"><cn type="float" id="A1.T2.12.10.2.m1.1.1.cmml" xref="A1.T2.12.10.2.m1.1.1">39.38</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.12.10.2.m1.1c">39.38</annotation></semantics></math></td>
</tr>
<tr id="A1.T2.14.12" class="ltx_tr">
<th id="A1.T2.14.12.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Small Transformer</th>
<td id="A1.T2.13.11.1" class="ltx_td ltx_align_center"><math id="A1.T2.13.11.1.m1.1" class="ltx_Math" alttext="800" display="inline"><semantics id="A1.T2.13.11.1.m1.1a"><mn id="A1.T2.13.11.1.m1.1.1" xref="A1.T2.13.11.1.m1.1.1.cmml">800</mn><annotation-xml encoding="MathML-Content" id="A1.T2.13.11.1.m1.1b"><cn type="integer" id="A1.T2.13.11.1.m1.1.1.cmml" xref="A1.T2.13.11.1.m1.1.1">800</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.13.11.1.m1.1c">800</annotation></semantics></math></td>
<td id="A1.T2.14.12.2" class="ltx_td ltx_align_center"><math id="A1.T2.14.12.2.m1.1" class="ltx_Math" alttext="38.66" display="inline"><semantics id="A1.T2.14.12.2.m1.1a"><mn id="A1.T2.14.12.2.m1.1.1" xref="A1.T2.14.12.2.m1.1.1.cmml">38.66</mn><annotation-xml encoding="MathML-Content" id="A1.T2.14.12.2.m1.1b"><cn type="float" id="A1.T2.14.12.2.m1.1.1.cmml" xref="A1.T2.14.12.2.m1.1.1">38.66</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.14.12.2.m1.1c">38.66</annotation></semantics></math></td>
</tr>
<tr id="A1.T2.16.14" class="ltx_tr">
<th id="A1.T2.16.14.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Small Conformer</th>
<td id="A1.T2.15.13.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T2.15.13.1.m1.1" class="ltx_Math" alttext="200" display="inline"><semantics id="A1.T2.15.13.1.m1.1a"><mn id="A1.T2.15.13.1.m1.1.1" xref="A1.T2.15.13.1.m1.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="A1.T2.15.13.1.m1.1b"><cn type="integer" id="A1.T2.15.13.1.m1.1.1.cmml" xref="A1.T2.15.13.1.m1.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.15.13.1.m1.1c">200</annotation></semantics></math></td>
<td id="A1.T2.16.14.2" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T2.16.14.2.m1.1" class="ltx_Math" alttext="38.22" display="inline"><semantics id="A1.T2.16.14.2.m1.1a"><mn id="A1.T2.16.14.2.m1.1.1" xref="A1.T2.16.14.2.m1.1.1.cmml">38.22</mn><annotation-xml encoding="MathML-Content" id="A1.T2.16.14.2.m1.1b"><cn type="float" id="A1.T2.16.14.2.m1.1.1.cmml" xref="A1.T2.16.14.2.m1.1.1">38.22</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.16.14.2.m1.1c">38.22</annotation></semantics></math></td>
</tr>
<tr id="A1.T2.18.16" class="ltx_tr">
<th id="A1.T2.18.16.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Small Conformer</th>
<td id="A1.T2.17.15.1" class="ltx_td ltx_align_center"><math id="A1.T2.17.15.1.m1.1" class="ltx_Math" alttext="400" display="inline"><semantics id="A1.T2.17.15.1.m1.1a"><mn id="A1.T2.17.15.1.m1.1.1" xref="A1.T2.17.15.1.m1.1.1.cmml">400</mn><annotation-xml encoding="MathML-Content" id="A1.T2.17.15.1.m1.1b"><cn type="integer" id="A1.T2.17.15.1.m1.1.1.cmml" xref="A1.T2.17.15.1.m1.1.1">400</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.17.15.1.m1.1c">400</annotation></semantics></math></td>
<td id="A1.T2.18.16.2" class="ltx_td ltx_align_center"><math id="A1.T2.18.16.2.m1.1" class="ltx_Math" alttext="37.53" display="inline"><semantics id="A1.T2.18.16.2.m1.1a"><mn id="A1.T2.18.16.2.m1.1.1" xref="A1.T2.18.16.2.m1.1.1.cmml">37.53</mn><annotation-xml encoding="MathML-Content" id="A1.T2.18.16.2.m1.1b"><cn type="float" id="A1.T2.18.16.2.m1.1.1.cmml" xref="A1.T2.18.16.2.m1.1.1">37.53</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.18.16.2.m1.1c">37.53</annotation></semantics></math></td>
</tr>
<tr id="A1.T2.20.18" class="ltx_tr">
<th id="A1.T2.20.18.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Small Conformer</th>
<td id="A1.T2.19.17.1" class="ltx_td ltx_align_center"><math id="A1.T2.19.17.1.m1.1" class="ltx_Math" alttext="800" display="inline"><semantics id="A1.T2.19.17.1.m1.1a"><mn id="A1.T2.19.17.1.m1.1.1" xref="A1.T2.19.17.1.m1.1.1.cmml">800</mn><annotation-xml encoding="MathML-Content" id="A1.T2.19.17.1.m1.1b"><cn type="integer" id="A1.T2.19.17.1.m1.1.1.cmml" xref="A1.T2.19.17.1.m1.1.1">800</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.19.17.1.m1.1c">800</annotation></semantics></math></td>
<td id="A1.T2.20.18.2" class="ltx_td ltx_align_center"><math id="A1.T2.20.18.2.m1.1" class="ltx_Math" alttext="36.80" display="inline"><semantics id="A1.T2.20.18.2.m1.1a"><mn id="A1.T2.20.18.2.m1.1.1" xref="A1.T2.20.18.2.m1.1.1.cmml">36.80</mn><annotation-xml encoding="MathML-Content" id="A1.T2.20.18.2.m1.1b"><cn type="float" id="A1.T2.20.18.2.m1.1.1.cmml" xref="A1.T2.20.18.2.m1.1.1">36.80</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.20.18.2.m1.1c">36.80</annotation></semantics></math></td>
</tr>
<tr id="A1.T2.22.20" class="ltx_tr">
<th id="A1.T2.22.20.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_tt">Large LSTM</th>
<td id="A1.T2.21.19.1" class="ltx_td ltx_align_center ltx_border_tt"><math id="A1.T2.21.19.1.m1.1" class="ltx_Math" alttext="200" display="inline"><semantics id="A1.T2.21.19.1.m1.1a"><mn id="A1.T2.21.19.1.m1.1.1" xref="A1.T2.21.19.1.m1.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="A1.T2.21.19.1.m1.1b"><cn type="integer" id="A1.T2.21.19.1.m1.1.1.cmml" xref="A1.T2.21.19.1.m1.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.21.19.1.m1.1c">200</annotation></semantics></math></td>
<td id="A1.T2.22.20.2" class="ltx_td ltx_align_center ltx_border_tt"><math id="A1.T2.22.20.2.m1.1" class="ltx_Math" alttext="30.97" display="inline"><semantics id="A1.T2.22.20.2.m1.1a"><mn id="A1.T2.22.20.2.m1.1.1" xref="A1.T2.22.20.2.m1.1.1.cmml">30.97</mn><annotation-xml encoding="MathML-Content" id="A1.T2.22.20.2.m1.1b"><cn type="float" id="A1.T2.22.20.2.m1.1.1.cmml" xref="A1.T2.22.20.2.m1.1.1">30.97</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.22.20.2.m1.1c">30.97</annotation></semantics></math></td>
</tr>
<tr id="A1.T2.24.22" class="ltx_tr">
<th id="A1.T2.24.22.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Large LSTM</th>
<td id="A1.T2.23.21.1" class="ltx_td ltx_align_center"><math id="A1.T2.23.21.1.m1.1" class="ltx_Math" alttext="400" display="inline"><semantics id="A1.T2.23.21.1.m1.1a"><mn id="A1.T2.23.21.1.m1.1.1" xref="A1.T2.23.21.1.m1.1.1.cmml">400</mn><annotation-xml encoding="MathML-Content" id="A1.T2.23.21.1.m1.1b"><cn type="integer" id="A1.T2.23.21.1.m1.1.1.cmml" xref="A1.T2.23.21.1.m1.1.1">400</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.23.21.1.m1.1c">400</annotation></semantics></math></td>
<td id="A1.T2.24.22.2" class="ltx_td ltx_align_center"><math id="A1.T2.24.22.2.m1.1" class="ltx_Math" alttext="30.79" display="inline"><semantics id="A1.T2.24.22.2.m1.1a"><mn id="A1.T2.24.22.2.m1.1.1" xref="A1.T2.24.22.2.m1.1.1.cmml">30.79</mn><annotation-xml encoding="MathML-Content" id="A1.T2.24.22.2.m1.1b"><cn type="float" id="A1.T2.24.22.2.m1.1.1.cmml" xref="A1.T2.24.22.2.m1.1.1">30.79</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.24.22.2.m1.1c">30.79</annotation></semantics></math></td>
</tr>
<tr id="A1.T2.26.24" class="ltx_tr">
<th id="A1.T2.26.24.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Large LSTM</th>
<td id="A1.T2.25.23.1" class="ltx_td ltx_align_center"><math id="A1.T2.25.23.1.m1.1" class="ltx_Math" alttext="800" display="inline"><semantics id="A1.T2.25.23.1.m1.1a"><mn id="A1.T2.25.23.1.m1.1.1" xref="A1.T2.25.23.1.m1.1.1.cmml">800</mn><annotation-xml encoding="MathML-Content" id="A1.T2.25.23.1.m1.1b"><cn type="integer" id="A1.T2.25.23.1.m1.1.1.cmml" xref="A1.T2.25.23.1.m1.1.1">800</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.25.23.1.m1.1c">800</annotation></semantics></math></td>
<td id="A1.T2.26.24.2" class="ltx_td ltx_align_center"><math id="A1.T2.26.24.2.m1.1" class="ltx_Math" alttext="30.83" display="inline"><semantics id="A1.T2.26.24.2.m1.1a"><mn id="A1.T2.26.24.2.m1.1.1" xref="A1.T2.26.24.2.m1.1.1.cmml">30.83</mn><annotation-xml encoding="MathML-Content" id="A1.T2.26.24.2.m1.1b"><cn type="float" id="A1.T2.26.24.2.m1.1.1.cmml" xref="A1.T2.26.24.2.m1.1.1">30.83</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.26.24.2.m1.1c">30.83</annotation></semantics></math></td>
</tr>
<tr id="A1.T2.28.26" class="ltx_tr">
<th id="A1.T2.28.26.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Large Transformer</th>
<td id="A1.T2.27.25.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T2.27.25.1.m1.1" class="ltx_Math" alttext="200" display="inline"><semantics id="A1.T2.27.25.1.m1.1a"><mn id="A1.T2.27.25.1.m1.1.1" xref="A1.T2.27.25.1.m1.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="A1.T2.27.25.1.m1.1b"><cn type="integer" id="A1.T2.27.25.1.m1.1.1.cmml" xref="A1.T2.27.25.1.m1.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.27.25.1.m1.1c">200</annotation></semantics></math></td>
<td id="A1.T2.28.26.2" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T2.28.26.2.m1.1" class="ltx_Math" alttext="30.64" display="inline"><semantics id="A1.T2.28.26.2.m1.1a"><mn id="A1.T2.28.26.2.m1.1.1" xref="A1.T2.28.26.2.m1.1.1.cmml">30.64</mn><annotation-xml encoding="MathML-Content" id="A1.T2.28.26.2.m1.1b"><cn type="float" id="A1.T2.28.26.2.m1.1.1.cmml" xref="A1.T2.28.26.2.m1.1.1">30.64</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.28.26.2.m1.1c">30.64</annotation></semantics></math></td>
</tr>
<tr id="A1.T2.30.28" class="ltx_tr">
<th id="A1.T2.30.28.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Large Transformer</th>
<td id="A1.T2.29.27.1" class="ltx_td ltx_align_center"><math id="A1.T2.29.27.1.m1.1" class="ltx_Math" alttext="400" display="inline"><semantics id="A1.T2.29.27.1.m1.1a"><mn id="A1.T2.29.27.1.m1.1.1" xref="A1.T2.29.27.1.m1.1.1.cmml">400</mn><annotation-xml encoding="MathML-Content" id="A1.T2.29.27.1.m1.1b"><cn type="integer" id="A1.T2.29.27.1.m1.1.1.cmml" xref="A1.T2.29.27.1.m1.1.1">400</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.29.27.1.m1.1c">400</annotation></semantics></math></td>
<td id="A1.T2.30.28.2" class="ltx_td ltx_align_center"><math id="A1.T2.30.28.2.m1.1" class="ltx_Math" alttext="29.81" display="inline"><semantics id="A1.T2.30.28.2.m1.1a"><mn id="A1.T2.30.28.2.m1.1.1" xref="A1.T2.30.28.2.m1.1.1.cmml">29.81</mn><annotation-xml encoding="MathML-Content" id="A1.T2.30.28.2.m1.1b"><cn type="float" id="A1.T2.30.28.2.m1.1.1.cmml" xref="A1.T2.30.28.2.m1.1.1">29.81</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.30.28.2.m1.1c">29.81</annotation></semantics></math></td>
</tr>
<tr id="A1.T2.32.30" class="ltx_tr">
<th id="A1.T2.32.30.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Large Transformer</th>
<td id="A1.T2.31.29.1" class="ltx_td ltx_align_center"><math id="A1.T2.31.29.1.m1.1" class="ltx_Math" alttext="800" display="inline"><semantics id="A1.T2.31.29.1.m1.1a"><mn id="A1.T2.31.29.1.m1.1.1" xref="A1.T2.31.29.1.m1.1.1.cmml">800</mn><annotation-xml encoding="MathML-Content" id="A1.T2.31.29.1.m1.1b"><cn type="integer" id="A1.T2.31.29.1.m1.1.1.cmml" xref="A1.T2.31.29.1.m1.1.1">800</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.31.29.1.m1.1c">800</annotation></semantics></math></td>
<td id="A1.T2.32.30.2" class="ltx_td ltx_align_center"><math id="A1.T2.32.30.2.m1.1" class="ltx_Math" alttext="29.15" display="inline"><semantics id="A1.T2.32.30.2.m1.1a"><mn id="A1.T2.32.30.2.m1.1.1" xref="A1.T2.32.30.2.m1.1.1.cmml">29.15</mn><annotation-xml encoding="MathML-Content" id="A1.T2.32.30.2.m1.1b"><cn type="float" id="A1.T2.32.30.2.m1.1.1.cmml" xref="A1.T2.32.30.2.m1.1.1">29.15</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.32.30.2.m1.1c">29.15</annotation></semantics></math></td>
</tr>
<tr id="A1.T2.34.32" class="ltx_tr">
<th id="A1.T2.34.32.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Large Conformer</th>
<td id="A1.T2.33.31.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T2.33.31.1.m1.1" class="ltx_Math" alttext="200" display="inline"><semantics id="A1.T2.33.31.1.m1.1a"><mn id="A1.T2.33.31.1.m1.1.1" xref="A1.T2.33.31.1.m1.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="A1.T2.33.31.1.m1.1b"><cn type="integer" id="A1.T2.33.31.1.m1.1.1.cmml" xref="A1.T2.33.31.1.m1.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.33.31.1.m1.1c">200</annotation></semantics></math></td>
<td id="A1.T2.34.32.2" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T2.34.32.2.m1.1" class="ltx_Math" alttext="30.44" display="inline"><semantics id="A1.T2.34.32.2.m1.1a"><mn id="A1.T2.34.32.2.m1.1.1" xref="A1.T2.34.32.2.m1.1.1.cmml">30.44</mn><annotation-xml encoding="MathML-Content" id="A1.T2.34.32.2.m1.1b"><cn type="float" id="A1.T2.34.32.2.m1.1.1.cmml" xref="A1.T2.34.32.2.m1.1.1">30.44</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.34.32.2.m1.1c">30.44</annotation></semantics></math></td>
</tr>
<tr id="A1.T2.36.34" class="ltx_tr">
<th id="A1.T2.36.34.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Large Conformer</th>
<td id="A1.T2.35.33.1" class="ltx_td ltx_align_center"><math id="A1.T2.35.33.1.m1.1" class="ltx_Math" alttext="400" display="inline"><semantics id="A1.T2.35.33.1.m1.1a"><mn id="A1.T2.35.33.1.m1.1.1" xref="A1.T2.35.33.1.m1.1.1.cmml">400</mn><annotation-xml encoding="MathML-Content" id="A1.T2.35.33.1.m1.1b"><cn type="integer" id="A1.T2.35.33.1.m1.1.1.cmml" xref="A1.T2.35.33.1.m1.1.1">400</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.35.33.1.m1.1c">400</annotation></semantics></math></td>
<td id="A1.T2.36.34.2" class="ltx_td ltx_align_center"><math id="A1.T2.36.34.2.m1.1" class="ltx_Math" alttext="29.66" display="inline"><semantics id="A1.T2.36.34.2.m1.1a"><mn id="A1.T2.36.34.2.m1.1.1" xref="A1.T2.36.34.2.m1.1.1.cmml">29.66</mn><annotation-xml encoding="MathML-Content" id="A1.T2.36.34.2.m1.1b"><cn type="float" id="A1.T2.36.34.2.m1.1.1.cmml" xref="A1.T2.36.34.2.m1.1.1">29.66</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.36.34.2.m1.1c">29.66</annotation></semantics></math></td>
</tr>
<tr id="A1.T2.38.36" class="ltx_tr">
<th id="A1.T2.38.36.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Large Conformer</th>
<td id="A1.T2.37.35.1" class="ltx_td ltx_align_center"><math id="A1.T2.37.35.1.m1.1" class="ltx_Math" alttext="800" display="inline"><semantics id="A1.T2.37.35.1.m1.1a"><mn id="A1.T2.37.35.1.m1.1.1" xref="A1.T2.37.35.1.m1.1.1.cmml">800</mn><annotation-xml encoding="MathML-Content" id="A1.T2.37.35.1.m1.1b"><cn type="integer" id="A1.T2.37.35.1.m1.1.1.cmml" xref="A1.T2.37.35.1.m1.1.1">800</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.37.35.1.m1.1c">800</annotation></semantics></math></td>
<td id="A1.T2.38.36.2" class="ltx_td ltx_align_center"><math id="A1.T2.38.36.2.m1.1" class="ltx_Math" alttext="\mathbf{29.06}" display="inline"><semantics id="A1.T2.38.36.2.m1.1a"><mn class="ltx_mathvariant_bold" mathvariant="bold" id="A1.T2.38.36.2.m1.1.1" xref="A1.T2.38.36.2.m1.1.1.cmml">29.06</mn><annotation-xml encoding="MathML-Content" id="A1.T2.38.36.2.m1.1b"><cn type="float" id="A1.T2.38.36.2.m1.1.1.cmml" xref="A1.T2.38.36.2.m1.1.1">29.06</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T2.38.36.2.m1.1c">\mathbf{29.06}</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
<figure id="A1.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Selected hyperparameters for each model and size range.
The values in <math id="A1.T3.2.m1.1" class="ltx_Math" alttext="[\ ]" display="inline"><semantics id="A1.T3.2.m1.1b"><mrow id="A1.T3.2.m1.1.1.2"><mo rspace="0.500em" stretchy="false" id="A1.T3.2.m1.1.1.2.1" xref="A1.T3.2.m1.1.1.1.cmml">[</mo><mo stretchy="false" id="A1.T3.2.m1.1.1.2.2" xref="A1.T3.2.m1.1.1.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.T3.2.m1.1c"><list id="A1.T3.2.m1.1.1.1.cmml" xref="A1.T3.2.m1.1.1.2.1"></list></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.2.m1.1d">[\ ]</annotation></semantics></math> are the possible hyperparameter values searched over.
Batch Size, # Examples, and Clipnorm here apply to the client local SGD steps. LR is learning rate.</figcaption>
<table id="A1.T3.37" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T3.37.36.1" class="ltx_tr">
<th id="A1.T3.37.36.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row">Model</th>
<th id="A1.T3.37.36.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">Batch Size</th>
<th id="A1.T3.37.36.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column"># Examples</th>
<th id="A1.T3.37.36.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">Clipnorm</th>
<th id="A1.T3.37.36.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column">Client LR</th>
<th id="A1.T3.37.36.1.6" class="ltx_td ltx_align_center ltx_th ltx_th_column">Server LR</th>
</tr>
<tr id="A1.T3.7.5" class="ltx_tr">
<th id="A1.T3.7.5.6" class="ltx_td ltx_th ltx_th_row"></th>
<th id="A1.T3.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column"><math id="A1.T3.3.1.1.m1.2" class="ltx_Math" alttext="[8,16]" display="inline"><semantics id="A1.T3.3.1.1.m1.2a"><mrow id="A1.T3.3.1.1.m1.2.3.2" xref="A1.T3.3.1.1.m1.2.3.1.cmml"><mo stretchy="false" id="A1.T3.3.1.1.m1.2.3.2.1" xref="A1.T3.3.1.1.m1.2.3.1.cmml">[</mo><mn id="A1.T3.3.1.1.m1.1.1" xref="A1.T3.3.1.1.m1.1.1.cmml">8</mn><mo id="A1.T3.3.1.1.m1.2.3.2.2" xref="A1.T3.3.1.1.m1.2.3.1.cmml">,</mo><mn id="A1.T3.3.1.1.m1.2.2" xref="A1.T3.3.1.1.m1.2.2.cmml">16</mn><mo stretchy="false" id="A1.T3.3.1.1.m1.2.3.2.3" xref="A1.T3.3.1.1.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.T3.3.1.1.m1.2b"><interval closure="closed" id="A1.T3.3.1.1.m1.2.3.1.cmml" xref="A1.T3.3.1.1.m1.2.3.2"><cn type="integer" id="A1.T3.3.1.1.m1.1.1.cmml" xref="A1.T3.3.1.1.m1.1.1">8</cn><cn type="integer" id="A1.T3.3.1.1.m1.2.2.cmml" xref="A1.T3.3.1.1.m1.2.2">16</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.3.1.1.m1.2c">[8,16]</annotation></semantics></math></th>
<th id="A1.T3.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column"><math id="A1.T3.4.2.2.m1.2" class="ltx_Math" alttext="[1200,1600]" display="inline"><semantics id="A1.T3.4.2.2.m1.2a"><mrow id="A1.T3.4.2.2.m1.2.3.2" xref="A1.T3.4.2.2.m1.2.3.1.cmml"><mo stretchy="false" id="A1.T3.4.2.2.m1.2.3.2.1" xref="A1.T3.4.2.2.m1.2.3.1.cmml">[</mo><mn id="A1.T3.4.2.2.m1.1.1" xref="A1.T3.4.2.2.m1.1.1.cmml">1200</mn><mo id="A1.T3.4.2.2.m1.2.3.2.2" xref="A1.T3.4.2.2.m1.2.3.1.cmml">,</mo><mn id="A1.T3.4.2.2.m1.2.2" xref="A1.T3.4.2.2.m1.2.2.cmml">1600</mn><mo stretchy="false" id="A1.T3.4.2.2.m1.2.3.2.3" xref="A1.T3.4.2.2.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.T3.4.2.2.m1.2b"><interval closure="closed" id="A1.T3.4.2.2.m1.2.3.1.cmml" xref="A1.T3.4.2.2.m1.2.3.2"><cn type="integer" id="A1.T3.4.2.2.m1.1.1.cmml" xref="A1.T3.4.2.2.m1.1.1">1200</cn><cn type="integer" id="A1.T3.4.2.2.m1.2.2.cmml" xref="A1.T3.4.2.2.m1.2.2">1600</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.4.2.2.m1.2c">[1200,1600]</annotation></semantics></math></th>
<th id="A1.T3.5.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_column"><math id="A1.T3.5.3.3.m1.2" class="ltx_Math" alttext="[0.0,16.0]" display="inline"><semantics id="A1.T3.5.3.3.m1.2a"><mrow id="A1.T3.5.3.3.m1.2.3.2" xref="A1.T3.5.3.3.m1.2.3.1.cmml"><mo stretchy="false" id="A1.T3.5.3.3.m1.2.3.2.1" xref="A1.T3.5.3.3.m1.2.3.1.cmml">[</mo><mn id="A1.T3.5.3.3.m1.1.1" xref="A1.T3.5.3.3.m1.1.1.cmml">0.0</mn><mo id="A1.T3.5.3.3.m1.2.3.2.2" xref="A1.T3.5.3.3.m1.2.3.1.cmml">,</mo><mn id="A1.T3.5.3.3.m1.2.2" xref="A1.T3.5.3.3.m1.2.2.cmml">16.0</mn><mo stretchy="false" id="A1.T3.5.3.3.m1.2.3.2.3" xref="A1.T3.5.3.3.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.T3.5.3.3.m1.2b"><interval closure="closed" id="A1.T3.5.3.3.m1.2.3.1.cmml" xref="A1.T3.5.3.3.m1.2.3.2"><cn type="float" id="A1.T3.5.3.3.m1.1.1.cmml" xref="A1.T3.5.3.3.m1.1.1">0.0</cn><cn type="float" id="A1.T3.5.3.3.m1.2.2.cmml" xref="A1.T3.5.3.3.m1.2.2">16.0</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.5.3.3.m1.2c">[0.0,16.0]</annotation></semantics></math></th>
<th id="A1.T3.6.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_column"><math id="A1.T3.6.4.4.m1.5" class="ltx_Math" alttext="[0.01,0.1,0.5,1.0,2.0]" display="inline"><semantics id="A1.T3.6.4.4.m1.5a"><mrow id="A1.T3.6.4.4.m1.5.6.2" xref="A1.T3.6.4.4.m1.5.6.1.cmml"><mo stretchy="false" id="A1.T3.6.4.4.m1.5.6.2.1" xref="A1.T3.6.4.4.m1.5.6.1.cmml">[</mo><mn id="A1.T3.6.4.4.m1.1.1" xref="A1.T3.6.4.4.m1.1.1.cmml">0.01</mn><mo id="A1.T3.6.4.4.m1.5.6.2.2" xref="A1.T3.6.4.4.m1.5.6.1.cmml">,</mo><mn id="A1.T3.6.4.4.m1.2.2" xref="A1.T3.6.4.4.m1.2.2.cmml">0.1</mn><mo id="A1.T3.6.4.4.m1.5.6.2.3" xref="A1.T3.6.4.4.m1.5.6.1.cmml">,</mo><mn id="A1.T3.6.4.4.m1.3.3" xref="A1.T3.6.4.4.m1.3.3.cmml">0.5</mn><mo id="A1.T3.6.4.4.m1.5.6.2.4" xref="A1.T3.6.4.4.m1.5.6.1.cmml">,</mo><mn id="A1.T3.6.4.4.m1.4.4" xref="A1.T3.6.4.4.m1.4.4.cmml">1.0</mn><mo id="A1.T3.6.4.4.m1.5.6.2.5" xref="A1.T3.6.4.4.m1.5.6.1.cmml">,</mo><mn id="A1.T3.6.4.4.m1.5.5" xref="A1.T3.6.4.4.m1.5.5.cmml">2.0</mn><mo stretchy="false" id="A1.T3.6.4.4.m1.5.6.2.6" xref="A1.T3.6.4.4.m1.5.6.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.T3.6.4.4.m1.5b"><list id="A1.T3.6.4.4.m1.5.6.1.cmml" xref="A1.T3.6.4.4.m1.5.6.2"><cn type="float" id="A1.T3.6.4.4.m1.1.1.cmml" xref="A1.T3.6.4.4.m1.1.1">0.01</cn><cn type="float" id="A1.T3.6.4.4.m1.2.2.cmml" xref="A1.T3.6.4.4.m1.2.2">0.1</cn><cn type="float" id="A1.T3.6.4.4.m1.3.3.cmml" xref="A1.T3.6.4.4.m1.3.3">0.5</cn><cn type="float" id="A1.T3.6.4.4.m1.4.4.cmml" xref="A1.T3.6.4.4.m1.4.4">1.0</cn><cn type="float" id="A1.T3.6.4.4.m1.5.5.cmml" xref="A1.T3.6.4.4.m1.5.5">2.0</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.6.4.4.m1.5c">[0.01,0.1,0.5,1.0,2.0]</annotation></semantics></math></th>
<th id="A1.T3.7.5.5" class="ltx_td ltx_align_center ltx_th ltx_th_column"><math id="A1.T3.7.5.5.m1.2" class="ltx_Math" alttext="[0.001,0.01]" display="inline"><semantics id="A1.T3.7.5.5.m1.2a"><mrow id="A1.T3.7.5.5.m1.2.3.2" xref="A1.T3.7.5.5.m1.2.3.1.cmml"><mo stretchy="false" id="A1.T3.7.5.5.m1.2.3.2.1" xref="A1.T3.7.5.5.m1.2.3.1.cmml">[</mo><mn id="A1.T3.7.5.5.m1.1.1" xref="A1.T3.7.5.5.m1.1.1.cmml">0.001</mn><mo id="A1.T3.7.5.5.m1.2.3.2.2" xref="A1.T3.7.5.5.m1.2.3.1.cmml">,</mo><mn id="A1.T3.7.5.5.m1.2.2" xref="A1.T3.7.5.5.m1.2.2.cmml">0.01</mn><mo stretchy="false" id="A1.T3.7.5.5.m1.2.3.2.3" xref="A1.T3.7.5.5.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.T3.7.5.5.m1.2b"><interval closure="closed" id="A1.T3.7.5.5.m1.2.3.1.cmml" xref="A1.T3.7.5.5.m1.2.3.2"><cn type="float" id="A1.T3.7.5.5.m1.1.1.cmml" xref="A1.T3.7.5.5.m1.1.1">0.001</cn><cn type="float" id="A1.T3.7.5.5.m1.2.2.cmml" xref="A1.T3.7.5.5.m1.2.2">0.01</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.7.5.5.m1.2c">[0.001,0.01]</annotation></semantics></math></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T3.12.10" class="ltx_tr">
<th id="A1.T3.12.10.6" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Small LSTM</th>
<td id="A1.T3.8.6.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T3.8.6.1.m1.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A1.T3.8.6.1.m1.1a"><mn id="A1.T3.8.6.1.m1.1.1" xref="A1.T3.8.6.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A1.T3.8.6.1.m1.1b"><cn type="integer" id="A1.T3.8.6.1.m1.1.1.cmml" xref="A1.T3.8.6.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.8.6.1.m1.1c">16</annotation></semantics></math></td>
<td id="A1.T3.9.7.2" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T3.9.7.2.m1.1" class="ltx_Math" alttext="1200" display="inline"><semantics id="A1.T3.9.7.2.m1.1a"><mn id="A1.T3.9.7.2.m1.1.1" xref="A1.T3.9.7.2.m1.1.1.cmml">1200</mn><annotation-xml encoding="MathML-Content" id="A1.T3.9.7.2.m1.1b"><cn type="integer" id="A1.T3.9.7.2.m1.1.1.cmml" xref="A1.T3.9.7.2.m1.1.1">1200</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.9.7.2.m1.1c">1200</annotation></semantics></math></td>
<td id="A1.T3.10.8.3" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T3.10.8.3.m1.1" class="ltx_Math" alttext="16.0" display="inline"><semantics id="A1.T3.10.8.3.m1.1a"><mn id="A1.T3.10.8.3.m1.1.1" xref="A1.T3.10.8.3.m1.1.1.cmml">16.0</mn><annotation-xml encoding="MathML-Content" id="A1.T3.10.8.3.m1.1b"><cn type="float" id="A1.T3.10.8.3.m1.1.1.cmml" xref="A1.T3.10.8.3.m1.1.1">16.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.10.8.3.m1.1c">16.0</annotation></semantics></math></td>
<td id="A1.T3.11.9.4" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T3.11.9.4.m1.1" class="ltx_Math" alttext="1.0" display="inline"><semantics id="A1.T3.11.9.4.m1.1a"><mn id="A1.T3.11.9.4.m1.1.1" xref="A1.T3.11.9.4.m1.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="A1.T3.11.9.4.m1.1b"><cn type="float" id="A1.T3.11.9.4.m1.1.1.cmml" xref="A1.T3.11.9.4.m1.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.11.9.4.m1.1c">1.0</annotation></semantics></math></td>
<td id="A1.T3.12.10.5" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T3.12.10.5.m1.1" class="ltx_Math" alttext="0.001" display="inline"><semantics id="A1.T3.12.10.5.m1.1a"><mn id="A1.T3.12.10.5.m1.1.1" xref="A1.T3.12.10.5.m1.1.1.cmml">0.001</mn><annotation-xml encoding="MathML-Content" id="A1.T3.12.10.5.m1.1b"><cn type="float" id="A1.T3.12.10.5.m1.1.1.cmml" xref="A1.T3.12.10.5.m1.1.1">0.001</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.12.10.5.m1.1c">0.001</annotation></semantics></math></td>
</tr>
<tr id="A1.T3.17.15" class="ltx_tr">
<th id="A1.T3.17.15.6" class="ltx_td ltx_align_center ltx_th ltx_th_row">Small Transformer</th>
<td id="A1.T3.13.11.1" class="ltx_td ltx_align_center"><math id="A1.T3.13.11.1.m1.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A1.T3.13.11.1.m1.1a"><mn id="A1.T3.13.11.1.m1.1.1" xref="A1.T3.13.11.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A1.T3.13.11.1.m1.1b"><cn type="integer" id="A1.T3.13.11.1.m1.1.1.cmml" xref="A1.T3.13.11.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.13.11.1.m1.1c">16</annotation></semantics></math></td>
<td id="A1.T3.14.12.2" class="ltx_td ltx_align_center"><math id="A1.T3.14.12.2.m1.1" class="ltx_Math" alttext="1200" display="inline"><semantics id="A1.T3.14.12.2.m1.1a"><mn id="A1.T3.14.12.2.m1.1.1" xref="A1.T3.14.12.2.m1.1.1.cmml">1200</mn><annotation-xml encoding="MathML-Content" id="A1.T3.14.12.2.m1.1b"><cn type="integer" id="A1.T3.14.12.2.m1.1.1.cmml" xref="A1.T3.14.12.2.m1.1.1">1200</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.14.12.2.m1.1c">1200</annotation></semantics></math></td>
<td id="A1.T3.15.13.3" class="ltx_td ltx_align_center"><math id="A1.T3.15.13.3.m1.1" class="ltx_Math" alttext="0.0" display="inline"><semantics id="A1.T3.15.13.3.m1.1a"><mn id="A1.T3.15.13.3.m1.1.1" xref="A1.T3.15.13.3.m1.1.1.cmml">0.0</mn><annotation-xml encoding="MathML-Content" id="A1.T3.15.13.3.m1.1b"><cn type="float" id="A1.T3.15.13.3.m1.1.1.cmml" xref="A1.T3.15.13.3.m1.1.1">0.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.15.13.3.m1.1c">0.0</annotation></semantics></math></td>
<td id="A1.T3.16.14.4" class="ltx_td ltx_align_center"><math id="A1.T3.16.14.4.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="A1.T3.16.14.4.m1.1a"><mn id="A1.T3.16.14.4.m1.1.1" xref="A1.T3.16.14.4.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A1.T3.16.14.4.m1.1b"><cn type="float" id="A1.T3.16.14.4.m1.1.1.cmml" xref="A1.T3.16.14.4.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.16.14.4.m1.1c">0.1</annotation></semantics></math></td>
<td id="A1.T3.17.15.5" class="ltx_td ltx_align_center"><math id="A1.T3.17.15.5.m1.1" class="ltx_Math" alttext="0.001" display="inline"><semantics id="A1.T3.17.15.5.m1.1a"><mn id="A1.T3.17.15.5.m1.1.1" xref="A1.T3.17.15.5.m1.1.1.cmml">0.001</mn><annotation-xml encoding="MathML-Content" id="A1.T3.17.15.5.m1.1b"><cn type="float" id="A1.T3.17.15.5.m1.1.1.cmml" xref="A1.T3.17.15.5.m1.1.1">0.001</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.17.15.5.m1.1c">0.001</annotation></semantics></math></td>
</tr>
<tr id="A1.T3.22.20" class="ltx_tr">
<th id="A1.T3.22.20.6" class="ltx_td ltx_align_center ltx_th ltx_th_row">Small Conformer</th>
<td id="A1.T3.18.16.1" class="ltx_td ltx_align_center"><math id="A1.T3.18.16.1.m1.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A1.T3.18.16.1.m1.1a"><mn id="A1.T3.18.16.1.m1.1.1" xref="A1.T3.18.16.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A1.T3.18.16.1.m1.1b"><cn type="integer" id="A1.T3.18.16.1.m1.1.1.cmml" xref="A1.T3.18.16.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.18.16.1.m1.1c">16</annotation></semantics></math></td>
<td id="A1.T3.19.17.2" class="ltx_td ltx_align_center"><math id="A1.T3.19.17.2.m1.1" class="ltx_Math" alttext="1200" display="inline"><semantics id="A1.T3.19.17.2.m1.1a"><mn id="A1.T3.19.17.2.m1.1.1" xref="A1.T3.19.17.2.m1.1.1.cmml">1200</mn><annotation-xml encoding="MathML-Content" id="A1.T3.19.17.2.m1.1b"><cn type="integer" id="A1.T3.19.17.2.m1.1.1.cmml" xref="A1.T3.19.17.2.m1.1.1">1200</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.19.17.2.m1.1c">1200</annotation></semantics></math></td>
<td id="A1.T3.20.18.3" class="ltx_td ltx_align_center"><math id="A1.T3.20.18.3.m1.1" class="ltx_Math" alttext="0.0" display="inline"><semantics id="A1.T3.20.18.3.m1.1a"><mn id="A1.T3.20.18.3.m1.1.1" xref="A1.T3.20.18.3.m1.1.1.cmml">0.0</mn><annotation-xml encoding="MathML-Content" id="A1.T3.20.18.3.m1.1b"><cn type="float" id="A1.T3.20.18.3.m1.1.1.cmml" xref="A1.T3.20.18.3.m1.1.1">0.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.20.18.3.m1.1c">0.0</annotation></semantics></math></td>
<td id="A1.T3.21.19.4" class="ltx_td ltx_align_center"><math id="A1.T3.21.19.4.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="A1.T3.21.19.4.m1.1a"><mn id="A1.T3.21.19.4.m1.1.1" xref="A1.T3.21.19.4.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A1.T3.21.19.4.m1.1b"><cn type="float" id="A1.T3.21.19.4.m1.1.1.cmml" xref="A1.T3.21.19.4.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.21.19.4.m1.1c">0.1</annotation></semantics></math></td>
<td id="A1.T3.22.20.5" class="ltx_td ltx_align_center"><math id="A1.T3.22.20.5.m1.1" class="ltx_Math" alttext="0.001" display="inline"><semantics id="A1.T3.22.20.5.m1.1a"><mn id="A1.T3.22.20.5.m1.1.1" xref="A1.T3.22.20.5.m1.1.1.cmml">0.001</mn><annotation-xml encoding="MathML-Content" id="A1.T3.22.20.5.m1.1b"><cn type="float" id="A1.T3.22.20.5.m1.1.1.cmml" xref="A1.T3.22.20.5.m1.1.1">0.001</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.22.20.5.m1.1c">0.001</annotation></semantics></math></td>
</tr>
<tr id="A1.T3.27.25" class="ltx_tr">
<th id="A1.T3.27.25.6" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Large LSTM</th>
<td id="A1.T3.23.21.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T3.23.21.1.m1.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A1.T3.23.21.1.m1.1a"><mn id="A1.T3.23.21.1.m1.1.1" xref="A1.T3.23.21.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A1.T3.23.21.1.m1.1b"><cn type="integer" id="A1.T3.23.21.1.m1.1.1.cmml" xref="A1.T3.23.21.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.23.21.1.m1.1c">16</annotation></semantics></math></td>
<td id="A1.T3.24.22.2" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T3.24.22.2.m1.1" class="ltx_Math" alttext="1200" display="inline"><semantics id="A1.T3.24.22.2.m1.1a"><mn id="A1.T3.24.22.2.m1.1.1" xref="A1.T3.24.22.2.m1.1.1.cmml">1200</mn><annotation-xml encoding="MathML-Content" id="A1.T3.24.22.2.m1.1b"><cn type="integer" id="A1.T3.24.22.2.m1.1.1.cmml" xref="A1.T3.24.22.2.m1.1.1">1200</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.24.22.2.m1.1c">1200</annotation></semantics></math></td>
<td id="A1.T3.25.23.3" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T3.25.23.3.m1.1" class="ltx_Math" alttext="16.0" display="inline"><semantics id="A1.T3.25.23.3.m1.1a"><mn id="A1.T3.25.23.3.m1.1.1" xref="A1.T3.25.23.3.m1.1.1.cmml">16.0</mn><annotation-xml encoding="MathML-Content" id="A1.T3.25.23.3.m1.1b"><cn type="float" id="A1.T3.25.23.3.m1.1.1.cmml" xref="A1.T3.25.23.3.m1.1.1">16.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.25.23.3.m1.1c">16.0</annotation></semantics></math></td>
<td id="A1.T3.26.24.4" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T3.26.24.4.m1.1" class="ltx_Math" alttext="1.0" display="inline"><semantics id="A1.T3.26.24.4.m1.1a"><mn id="A1.T3.26.24.4.m1.1.1" xref="A1.T3.26.24.4.m1.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="A1.T3.26.24.4.m1.1b"><cn type="float" id="A1.T3.26.24.4.m1.1.1.cmml" xref="A1.T3.26.24.4.m1.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.26.24.4.m1.1c">1.0</annotation></semantics></math></td>
<td id="A1.T3.27.25.5" class="ltx_td ltx_align_center ltx_border_t"><math id="A1.T3.27.25.5.m1.1" class="ltx_Math" alttext="0.001" display="inline"><semantics id="A1.T3.27.25.5.m1.1a"><mn id="A1.T3.27.25.5.m1.1.1" xref="A1.T3.27.25.5.m1.1.1.cmml">0.001</mn><annotation-xml encoding="MathML-Content" id="A1.T3.27.25.5.m1.1b"><cn type="float" id="A1.T3.27.25.5.m1.1.1.cmml" xref="A1.T3.27.25.5.m1.1.1">0.001</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.27.25.5.m1.1c">0.001</annotation></semantics></math></td>
</tr>
<tr id="A1.T3.32.30" class="ltx_tr">
<th id="A1.T3.32.30.6" class="ltx_td ltx_align_center ltx_th ltx_th_row">Large Transformer</th>
<td id="A1.T3.28.26.1" class="ltx_td ltx_align_center"><math id="A1.T3.28.26.1.m1.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A1.T3.28.26.1.m1.1a"><mn id="A1.T3.28.26.1.m1.1.1" xref="A1.T3.28.26.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A1.T3.28.26.1.m1.1b"><cn type="integer" id="A1.T3.28.26.1.m1.1.1.cmml" xref="A1.T3.28.26.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.28.26.1.m1.1c">16</annotation></semantics></math></td>
<td id="A1.T3.29.27.2" class="ltx_td ltx_align_center"><math id="A1.T3.29.27.2.m1.1" class="ltx_Math" alttext="1200" display="inline"><semantics id="A1.T3.29.27.2.m1.1a"><mn id="A1.T3.29.27.2.m1.1.1" xref="A1.T3.29.27.2.m1.1.1.cmml">1200</mn><annotation-xml encoding="MathML-Content" id="A1.T3.29.27.2.m1.1b"><cn type="integer" id="A1.T3.29.27.2.m1.1.1.cmml" xref="A1.T3.29.27.2.m1.1.1">1200</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.29.27.2.m1.1c">1200</annotation></semantics></math></td>
<td id="A1.T3.30.28.3" class="ltx_td ltx_align_center"><math id="A1.T3.30.28.3.m1.1" class="ltx_Math" alttext="0.0" display="inline"><semantics id="A1.T3.30.28.3.m1.1a"><mn id="A1.T3.30.28.3.m1.1.1" xref="A1.T3.30.28.3.m1.1.1.cmml">0.0</mn><annotation-xml encoding="MathML-Content" id="A1.T3.30.28.3.m1.1b"><cn type="float" id="A1.T3.30.28.3.m1.1.1.cmml" xref="A1.T3.30.28.3.m1.1.1">0.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.30.28.3.m1.1c">0.0</annotation></semantics></math></td>
<td id="A1.T3.31.29.4" class="ltx_td ltx_align_center"><math id="A1.T3.31.29.4.m1.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="A1.T3.31.29.4.m1.1a"><mn id="A1.T3.31.29.4.m1.1.1" xref="A1.T3.31.29.4.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="A1.T3.31.29.4.m1.1b"><cn type="float" id="A1.T3.31.29.4.m1.1.1.cmml" xref="A1.T3.31.29.4.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.31.29.4.m1.1c">0.5</annotation></semantics></math></td>
<td id="A1.T3.32.30.5" class="ltx_td ltx_align_center"><math id="A1.T3.32.30.5.m1.1" class="ltx_Math" alttext="0.001" display="inline"><semantics id="A1.T3.32.30.5.m1.1a"><mn id="A1.T3.32.30.5.m1.1.1" xref="A1.T3.32.30.5.m1.1.1.cmml">0.001</mn><annotation-xml encoding="MathML-Content" id="A1.T3.32.30.5.m1.1b"><cn type="float" id="A1.T3.32.30.5.m1.1.1.cmml" xref="A1.T3.32.30.5.m1.1.1">0.001</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.32.30.5.m1.1c">0.001</annotation></semantics></math></td>
</tr>
<tr id="A1.T3.37.35" class="ltx_tr">
<th id="A1.T3.37.35.6" class="ltx_td ltx_align_center ltx_th ltx_th_row">Large Conformer</th>
<td id="A1.T3.33.31.1" class="ltx_td ltx_align_center"><math id="A1.T3.33.31.1.m1.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A1.T3.33.31.1.m1.1a"><mn id="A1.T3.33.31.1.m1.1.1" xref="A1.T3.33.31.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A1.T3.33.31.1.m1.1b"><cn type="integer" id="A1.T3.33.31.1.m1.1.1.cmml" xref="A1.T3.33.31.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.33.31.1.m1.1c">16</annotation></semantics></math></td>
<td id="A1.T3.34.32.2" class="ltx_td ltx_align_center"><math id="A1.T3.34.32.2.m1.1" class="ltx_Math" alttext="1200" display="inline"><semantics id="A1.T3.34.32.2.m1.1a"><mn id="A1.T3.34.32.2.m1.1.1" xref="A1.T3.34.32.2.m1.1.1.cmml">1200</mn><annotation-xml encoding="MathML-Content" id="A1.T3.34.32.2.m1.1b"><cn type="integer" id="A1.T3.34.32.2.m1.1.1.cmml" xref="A1.T3.34.32.2.m1.1.1">1200</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.34.32.2.m1.1c">1200</annotation></semantics></math></td>
<td id="A1.T3.35.33.3" class="ltx_td ltx_align_center"><math id="A1.T3.35.33.3.m1.1" class="ltx_Math" alttext="0.0" display="inline"><semantics id="A1.T3.35.33.3.m1.1a"><mn id="A1.T3.35.33.3.m1.1.1" xref="A1.T3.35.33.3.m1.1.1.cmml">0.0</mn><annotation-xml encoding="MathML-Content" id="A1.T3.35.33.3.m1.1b"><cn type="float" id="A1.T3.35.33.3.m1.1.1.cmml" xref="A1.T3.35.33.3.m1.1.1">0.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.35.33.3.m1.1c">0.0</annotation></semantics></math></td>
<td id="A1.T3.36.34.4" class="ltx_td ltx_align_center"><math id="A1.T3.36.34.4.m1.1" class="ltx_Math" alttext="1.0" display="inline"><semantics id="A1.T3.36.34.4.m1.1a"><mn id="A1.T3.36.34.4.m1.1.1" xref="A1.T3.36.34.4.m1.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="A1.T3.36.34.4.m1.1b"><cn type="float" id="A1.T3.36.34.4.m1.1.1.cmml" xref="A1.T3.36.34.4.m1.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.36.34.4.m1.1c">1.0</annotation></semantics></math></td>
<td id="A1.T3.37.35.5" class="ltx_td ltx_align_center"><math id="A1.T3.37.35.5.m1.1" class="ltx_Math" alttext="0.001" display="inline"><semantics id="A1.T3.37.35.5.m1.1a"><mn id="A1.T3.37.35.5.m1.1.1" xref="A1.T3.37.35.5.m1.1.1.cmml">0.001</mn><annotation-xml encoding="MathML-Content" id="A1.T3.37.35.5.m1.1b"><cn type="float" id="A1.T3.37.35.5.m1.1.1.cmml" xref="A1.T3.37.35.5.m1.1.1">0.001</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.37.35.5.m1.1c">0.001</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
<figure id="A1.F10" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2204.09715/assets/so_small_central.png" id="A1.F10.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="294" height="131" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2204.09715/assets/so_large_central.png" id="A1.F10.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="295" height="131" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Test set perplexity as a function of number of gradient computations for comparing the centralized and federated averaging baselines.</figcaption>
</figure>
<div id="A1.p1" class="ltx_para">
<p id="A1.p1.8" class="ltx_p">For the baseline architecture search, Table <a href="#A1.T1" title="Table 1 ‣ Appendix A Dataset and models ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> details the selected architectures as well as the search ranges for each dimension.
The final hyperparameters were selected based on the test perplexity after <math id="A1.p1.1.m1.1" class="ltx_Math" alttext="3" display="inline"><semantics id="A1.p1.1.m1.1a"><mn id="A1.p1.1.m1.1.1" xref="A1.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="A1.p1.1.m1.1b"><cn type="integer" id="A1.p1.1.m1.1.1.cmml" xref="A1.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.1.m1.1c">3</annotation></semantics></math>K rounds of training using FedAvg with <math id="A1.p1.2.m2.1" class="ltx_Math" alttext="200" display="inline"><semantics id="A1.p1.2.m2.1a"><mn id="A1.p1.2.m2.1.1" xref="A1.p1.2.m2.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="A1.p1.2.m2.1b"><cn type="integer" id="A1.p1.2.m2.1.1.cmml" xref="A1.p1.2.m2.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.2.m2.1c">200</annotation></semantics></math> clients per round.
From here on, we fix the Adam optimizer with <math id="A1.p1.3.m3.1" class="ltx_Math" alttext="\beta_{1}" display="inline"><semantics id="A1.p1.3.m3.1a"><msub id="A1.p1.3.m3.1.1" xref="A1.p1.3.m3.1.1.cmml"><mi id="A1.p1.3.m3.1.1.2" xref="A1.p1.3.m3.1.1.2.cmml">β</mi><mn id="A1.p1.3.m3.1.1.3" xref="A1.p1.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A1.p1.3.m3.1b"><apply id="A1.p1.3.m3.1.1.cmml" xref="A1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="A1.p1.3.m3.1.1.1.cmml" xref="A1.p1.3.m3.1.1">subscript</csymbol><ci id="A1.p1.3.m3.1.1.2.cmml" xref="A1.p1.3.m3.1.1.2">𝛽</ci><cn type="integer" id="A1.p1.3.m3.1.1.3.cmml" xref="A1.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.3.m3.1c">\beta_{1}</annotation></semantics></math> at <math id="A1.p1.4.m4.1" class="ltx_Math" alttext="0.9" display="inline"><semantics id="A1.p1.4.m4.1a"><mn id="A1.p1.4.m4.1.1" xref="A1.p1.4.m4.1.1.cmml">0.9</mn><annotation-xml encoding="MathML-Content" id="A1.p1.4.m4.1b"><cn type="float" id="A1.p1.4.m4.1.1.cmml" xref="A1.p1.4.m4.1.1">0.9</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.4.m4.1c">0.9</annotation></semantics></math>, <math id="A1.p1.5.m5.1" class="ltx_Math" alttext="\beta_{2}" display="inline"><semantics id="A1.p1.5.m5.1a"><msub id="A1.p1.5.m5.1.1" xref="A1.p1.5.m5.1.1.cmml"><mi id="A1.p1.5.m5.1.1.2" xref="A1.p1.5.m5.1.1.2.cmml">β</mi><mn id="A1.p1.5.m5.1.1.3" xref="A1.p1.5.m5.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A1.p1.5.m5.1b"><apply id="A1.p1.5.m5.1.1.cmml" xref="A1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="A1.p1.5.m5.1.1.1.cmml" xref="A1.p1.5.m5.1.1">subscript</csymbol><ci id="A1.p1.5.m5.1.1.2.cmml" xref="A1.p1.5.m5.1.1.2">𝛽</ci><cn type="integer" id="A1.p1.5.m5.1.1.3.cmml" xref="A1.p1.5.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.5.m5.1c">\beta_{2}</annotation></semantics></math> at <math id="A1.p1.6.m6.1" class="ltx_Math" alttext="0.999" display="inline"><semantics id="A1.p1.6.m6.1a"><mn id="A1.p1.6.m6.1.1" xref="A1.p1.6.m6.1.1.cmml">0.999</mn><annotation-xml encoding="MathML-Content" id="A1.p1.6.m6.1b"><cn type="float" id="A1.p1.6.m6.1.1.cmml" xref="A1.p1.6.m6.1.1">0.999</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.6.m6.1c">0.999</annotation></semantics></math>, and epsilon at <math id="A1.p1.7.m7.1" class="ltx_Math" alttext="1e^{-8}" display="inline"><semantics id="A1.p1.7.m7.1a"><mrow id="A1.p1.7.m7.1.1" xref="A1.p1.7.m7.1.1.cmml"><mn id="A1.p1.7.m7.1.1.2" xref="A1.p1.7.m7.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="A1.p1.7.m7.1.1.1" xref="A1.p1.7.m7.1.1.1.cmml">​</mo><msup id="A1.p1.7.m7.1.1.3" xref="A1.p1.7.m7.1.1.3.cmml"><mi id="A1.p1.7.m7.1.1.3.2" xref="A1.p1.7.m7.1.1.3.2.cmml">e</mi><mrow id="A1.p1.7.m7.1.1.3.3" xref="A1.p1.7.m7.1.1.3.3.cmml"><mo id="A1.p1.7.m7.1.1.3.3a" xref="A1.p1.7.m7.1.1.3.3.cmml">−</mo><mn id="A1.p1.7.m7.1.1.3.3.2" xref="A1.p1.7.m7.1.1.3.3.2.cmml">8</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.p1.7.m7.1b"><apply id="A1.p1.7.m7.1.1.cmml" xref="A1.p1.7.m7.1.1"><times id="A1.p1.7.m7.1.1.1.cmml" xref="A1.p1.7.m7.1.1.1"></times><cn type="integer" id="A1.p1.7.m7.1.1.2.cmml" xref="A1.p1.7.m7.1.1.2">1</cn><apply id="A1.p1.7.m7.1.1.3.cmml" xref="A1.p1.7.m7.1.1.3"><csymbol cd="ambiguous" id="A1.p1.7.m7.1.1.3.1.cmml" xref="A1.p1.7.m7.1.1.3">superscript</csymbol><ci id="A1.p1.7.m7.1.1.3.2.cmml" xref="A1.p1.7.m7.1.1.3.2">𝑒</ci><apply id="A1.p1.7.m7.1.1.3.3.cmml" xref="A1.p1.7.m7.1.1.3.3"><minus id="A1.p1.7.m7.1.1.3.3.1.cmml" xref="A1.p1.7.m7.1.1.3.3"></minus><cn type="integer" id="A1.p1.7.m7.1.1.3.3.2.cmml" xref="A1.p1.7.m7.1.1.3.3.2">8</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.7.m7.1c">1e^{-8}</annotation></semantics></math>.
Additionally, based on the distribution of average sequence lengths across Stack Overflow clients in Figure <a href="#A1.F9" title="Figure 9 ‣ Appendix A Dataset and models ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, we fix the max sequence length for training and evaluation to <math id="A1.p1.8.m8.1" class="ltx_Math" alttext="30" display="inline"><semantics id="A1.p1.8.m8.1a"><mn id="A1.p1.8.m8.1.1" xref="A1.p1.8.m8.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="A1.p1.8.m8.1b"><cn type="integer" id="A1.p1.8.m8.1.1.cmml" xref="A1.p1.8.m8.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.8.m8.1c">30</annotation></semantics></math>.</p>
</div>
<div id="A1.p2" class="ltx_para">
<p id="A1.p2.12" class="ltx_p">Table <a href="#A1.T2" title="Table 2 ‣ Appendix A Dataset and models ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> contains the results for each selected model after <math id="A1.p2.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.p2.1.m1.1a"><mn id="A1.p2.1.m1.1.1" xref="A1.p2.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.p2.1.m1.1b"><cn type="integer" id="A1.p2.1.m1.1.1.cmml" xref="A1.p2.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.1.m1.1c">10</annotation></semantics></math>K rounds of training using FedAvg with <math id="A1.p2.2.m2.1" class="ltx_Math" alttext="200" display="inline"><semantics id="A1.p2.2.m2.1a"><mn id="A1.p2.2.m2.1.1" xref="A1.p2.2.m2.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="A1.p2.2.m2.1b"><cn type="integer" id="A1.p2.2.m2.1.1.cmml" xref="A1.p2.2.m2.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.2.m2.1c">200</annotation></semantics></math>, <math id="A1.p2.3.m3.1" class="ltx_Math" alttext="400" display="inline"><semantics id="A1.p2.3.m3.1a"><mn id="A1.p2.3.m3.1.1" xref="A1.p2.3.m3.1.1.cmml">400</mn><annotation-xml encoding="MathML-Content" id="A1.p2.3.m3.1b"><cn type="integer" id="A1.p2.3.m3.1.1.cmml" xref="A1.p2.3.m3.1.1">400</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.3.m3.1c">400</annotation></semantics></math>, and <math id="A1.p2.4.m4.1" class="ltx_Math" alttext="800" display="inline"><semantics id="A1.p2.4.m4.1a"><mn id="A1.p2.4.m4.1.1" xref="A1.p2.4.m4.1.1.cmml">800</mn><annotation-xml encoding="MathML-Content" id="A1.p2.4.m4.1b"><cn type="integer" id="A1.p2.4.m4.1.1.cmml" xref="A1.p2.4.m4.1.1">800</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.4.m4.1c">800</annotation></semantics></math> clients per round.
As expected, the best results are achieved by using <math id="A1.p2.5.m5.1" class="ltx_Math" alttext="800" display="inline"><semantics id="A1.p2.5.m5.1a"><mn id="A1.p2.5.m5.1.1" xref="A1.p2.5.m5.1.1.cmml">800</mn><annotation-xml encoding="MathML-Content" id="A1.p2.5.m5.1b"><cn type="integer" id="A1.p2.5.m5.1.1.cmml" xref="A1.p2.5.m5.1.1">800</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.5.m5.1c">800</annotation></semantics></math> clients per round.
Thus, from here on, we report results for <math id="A1.p2.6.m6.1" class="ltx_Math" alttext="800" display="inline"><semantics id="A1.p2.6.m6.1a"><mn id="A1.p2.6.m6.1.1" xref="A1.p2.6.m6.1.1.cmml">800</mn><annotation-xml encoding="MathML-Content" id="A1.p2.6.m6.1b"><cn type="integer" id="A1.p2.6.m6.1.1.cmml" xref="A1.p2.6.m6.1.1">800</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.6.m6.1c">800</annotation></semantics></math> clients per round only.
For these experiments, we also search over client learning rate, client batch size, client max number of examples (with client number of epochs fixed to <math id="A1.p2.7.m7.1" class="ltx_Math" alttext="1" display="inline"><semantics id="A1.p2.7.m7.1a"><mn id="A1.p2.7.m7.1.1" xref="A1.p2.7.m7.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A1.p2.7.m7.1b"><cn type="integer" id="A1.p2.7.m7.1.1.cmml" xref="A1.p2.7.m7.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.7.m7.1c">1</annotation></semantics></math>), client <math id="A1.p2.8.m8.1" class="ltx_Math" alttext="\ell_{2}" display="inline"><semantics id="A1.p2.8.m8.1a"><msub id="A1.p2.8.m8.1.1" xref="A1.p2.8.m8.1.1.cmml"><mi mathvariant="normal" id="A1.p2.8.m8.1.1.2" xref="A1.p2.8.m8.1.1.2.cmml">ℓ</mi><mn id="A1.p2.8.m8.1.1.3" xref="A1.p2.8.m8.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A1.p2.8.m8.1b"><apply id="A1.p2.8.m8.1.1.cmml" xref="A1.p2.8.m8.1.1"><csymbol cd="ambiguous" id="A1.p2.8.m8.1.1.1.cmml" xref="A1.p2.8.m8.1.1">subscript</csymbol><ci id="A1.p2.8.m8.1.1.2.cmml" xref="A1.p2.8.m8.1.1.2">ℓ</ci><cn type="integer" id="A1.p2.8.m8.1.1.3.cmml" xref="A1.p2.8.m8.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.8.m8.1c">\ell_{2}</annotation></semantics></math> norm for clipping, and server learning rate.
The search ranges as well as selected values for each model are detailed in Table <a href="#A1.T3" title="Table 3 ‣ Appendix A Dataset and models ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.
For all following experiments, we fix client batch size to <math id="A1.p2.9.m9.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A1.p2.9.m9.1a"><mn id="A1.p2.9.m9.1.1" xref="A1.p2.9.m9.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A1.p2.9.m9.1b"><cn type="integer" id="A1.p2.9.m9.1.1.cmml" xref="A1.p2.9.m9.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.9.m9.1c">16</annotation></semantics></math> and client max number of examples to <math id="A1.p2.10.m10.1" class="ltx_Math" alttext="1200" display="inline"><semantics id="A1.p2.10.m10.1a"><mn id="A1.p2.10.m10.1.1" xref="A1.p2.10.m10.1.1.cmml">1200</mn><annotation-xml encoding="MathML-Content" id="A1.p2.10.m10.1b"><cn type="integer" id="A1.p2.10.m10.1.1.cmml" xref="A1.p2.10.m10.1.1">1200</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.10.m10.1c">1200</annotation></semantics></math> since the larger batch size consistently performed the best and Figure <a href="#A1.F9" title="Figure 9 ‣ Appendix A Dataset and models ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> shows that <math id="A1.p2.11.m11.1" class="ltx_Math" alttext="1200" display="inline"><semantics id="A1.p2.11.m11.1a"><mn id="A1.p2.11.m11.1.1" xref="A1.p2.11.m11.1.1.cmml">1200</mn><annotation-xml encoding="MathML-Content" id="A1.p2.11.m11.1b"><cn type="integer" id="A1.p2.11.m11.1.1.cmml" xref="A1.p2.11.m11.1.1">1200</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.11.m11.1c">1200</annotation></semantics></math> sequences is more than enough to cover the vast majority of clients with the number of epochs fixed at <math id="A1.p2.12.m12.1" class="ltx_Math" alttext="1" display="inline"><semantics id="A1.p2.12.m12.1a"><mn id="A1.p2.12.m12.1.1" xref="A1.p2.12.m12.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A1.p2.12.m12.1b"><cn type="integer" id="A1.p2.12.m12.1.1.cmml" xref="A1.p2.12.m12.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p2.12.m12.1c">1</annotation></semantics></math>.
We also search over the same ranges for all following experiments where applicable for consistency.</p>
</div>
<div id="A1.p3" class="ltx_para">
<p id="A1.p3.3" class="ltx_p">As an additional baseline comparison, we also train each model using synchronous SGD to observe model quality in terms of number of gradient computations.
These centralized baselines provide a rough estimate of an upper bound on model quality for federated learning.
To produce a reasonable comparison between the federated and centralized experiments, we compare by number of gradient computations.
We approximate the number of gradient steps taken for federated learning with <math id="A1.p3.1.m1.1" class="ltx_Math" alttext="200" display="inline"><semantics id="A1.p3.1.m1.1a"><mn id="A1.p3.1.m1.1.1" xref="A1.p3.1.m1.1.1.cmml">200</mn><annotation-xml encoding="MathML-Content" id="A1.p3.1.m1.1b"><cn type="integer" id="A1.p3.1.m1.1.1.cmml" xref="A1.p3.1.m1.1.1">200</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p3.1.m1.1c">200</annotation></semantics></math> clients per round for <math id="A1.p3.2.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.p3.2.m2.1a"><mn id="A1.p3.2.m2.1.1" xref="A1.p3.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.p3.2.m2.1b"><cn type="integer" id="A1.p3.2.m2.1.1.cmml" xref="A1.p3.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p3.2.m2.1c">10</annotation></semantics></math>K communication rounds.
We train the centralized models using the Adam optimizer and run periodic evaluation on the test set at the same frequency as the federated experiments.
We compare final metrics between centralized and federated training on the test set in Figure <a href="#A1.F10" title="Figure 10 ‣ Appendix A Dataset and models ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>.
Observing the test perplexity over gradient steps, it is evident that the relative rankings of the models remain consistent between centralized and federated baselines.
Additionally, by <math id="A1.p3.3.m3.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A1.p3.3.m3.1a"><mn id="A1.p3.3.m3.1.1" xref="A1.p3.3.m3.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A1.p3.3.m3.1b"><cn type="integer" id="A1.p3.3.m3.1.1.cmml" xref="A1.p3.3.m3.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p3.3.m3.1c">10</annotation></semantics></math>K rounds, the large federated models approach similar perplexity as centralized.</p>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Partial model training</h2>

<figure id="A2.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Test perplexity after <math id="A2.T4.2.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A2.T4.2.m1.1b"><mn id="A2.T4.2.m1.1.1" xref="A2.T4.2.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A2.T4.2.m1.1c"><cn type="integer" id="A2.T4.2.m1.1.1.cmml" xref="A2.T4.2.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.2.m1.1d">10</annotation></semantics></math>K communication rounds of training for each class of model and PVT % of trainable variables.</figcaption>
<table id="A2.T4.38" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A2.T4.38.37.1" class="ltx_tr">
<th id="A2.T4.38.37.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row">Model</th>
<th id="A2.T4.38.37.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">Trainable %</th>
<th id="A2.T4.38.37.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column"># Parameters</th>
<th id="A2.T4.38.37.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">Perplexity</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A2.T4.5.3" class="ltx_tr">
<th id="A2.T4.5.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Small LSTM</th>
<td id="A2.T4.3.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A2.T4.3.1.1.m1.1" class="ltx_Math" alttext="100\%" display="inline"><semantics id="A2.T4.3.1.1.m1.1a"><mrow id="A2.T4.3.1.1.m1.1.1" xref="A2.T4.3.1.1.m1.1.1.cmml"><mn id="A2.T4.3.1.1.m1.1.1.2" xref="A2.T4.3.1.1.m1.1.1.2.cmml">100</mn><mo id="A2.T4.3.1.1.m1.1.1.1" xref="A2.T4.3.1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.3.1.1.m1.1b"><apply id="A2.T4.3.1.1.m1.1.1.cmml" xref="A2.T4.3.1.1.m1.1.1"><csymbol cd="latexml" id="A2.T4.3.1.1.m1.1.1.1.cmml" xref="A2.T4.3.1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="A2.T4.3.1.1.m1.1.1.2.cmml" xref="A2.T4.3.1.1.m1.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.3.1.1.m1.1c">100\%</annotation></semantics></math></td>
<td id="A2.T4.4.2.2" class="ltx_td ltx_align_center ltx_border_t">
<math id="A2.T4.4.2.2.m1.1" class="ltx_Math" alttext="4.7" display="inline"><semantics id="A2.T4.4.2.2.m1.1a"><mn id="A2.T4.4.2.2.m1.1.1" xref="A2.T4.4.2.2.m1.1.1.cmml">4.7</mn><annotation-xml encoding="MathML-Content" id="A2.T4.4.2.2.m1.1b"><cn type="float" id="A2.T4.4.2.2.m1.1.1.cmml" xref="A2.T4.4.2.2.m1.1.1">4.7</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.4.2.2.m1.1c">4.7</annotation></semantics></math>M</td>
<td id="A2.T4.5.3.3" class="ltx_td ltx_align_center ltx_border_t"><math id="A2.T4.5.3.3.m1.1" class="ltx_Math" alttext="34.80" display="inline"><semantics id="A2.T4.5.3.3.m1.1a"><mn id="A2.T4.5.3.3.m1.1.1" xref="A2.T4.5.3.3.m1.1.1.cmml">34.80</mn><annotation-xml encoding="MathML-Content" id="A2.T4.5.3.3.m1.1b"><cn type="float" id="A2.T4.5.3.3.m1.1.1.cmml" xref="A2.T4.5.3.3.m1.1.1">34.80</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.5.3.3.m1.1c">34.80</annotation></semantics></math></td>
</tr>
<tr id="A2.T4.8.6" class="ltx_tr">
<th id="A2.T4.8.6.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">Small Transformer</th>
<td id="A2.T4.6.4.1" class="ltx_td ltx_align_center"><math id="A2.T4.6.4.1.m1.1" class="ltx_Math" alttext="100\%" display="inline"><semantics id="A2.T4.6.4.1.m1.1a"><mrow id="A2.T4.6.4.1.m1.1.1" xref="A2.T4.6.4.1.m1.1.1.cmml"><mn id="A2.T4.6.4.1.m1.1.1.2" xref="A2.T4.6.4.1.m1.1.1.2.cmml">100</mn><mo id="A2.T4.6.4.1.m1.1.1.1" xref="A2.T4.6.4.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.6.4.1.m1.1b"><apply id="A2.T4.6.4.1.m1.1.1.cmml" xref="A2.T4.6.4.1.m1.1.1"><csymbol cd="latexml" id="A2.T4.6.4.1.m1.1.1.1.cmml" xref="A2.T4.6.4.1.m1.1.1.1">percent</csymbol><cn type="integer" id="A2.T4.6.4.1.m1.1.1.2.cmml" xref="A2.T4.6.4.1.m1.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.6.4.1.m1.1c">100\%</annotation></semantics></math></td>
<td id="A2.T4.7.5.2" class="ltx_td ltx_align_center">
<math id="A2.T4.7.5.2.m1.1" class="ltx_Math" alttext="4.1" display="inline"><semantics id="A2.T4.7.5.2.m1.1a"><mn id="A2.T4.7.5.2.m1.1.1" xref="A2.T4.7.5.2.m1.1.1.cmml">4.1</mn><annotation-xml encoding="MathML-Content" id="A2.T4.7.5.2.m1.1b"><cn type="float" id="A2.T4.7.5.2.m1.1.1.cmml" xref="A2.T4.7.5.2.m1.1.1">4.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.7.5.2.m1.1c">4.1</annotation></semantics></math>M</td>
<td id="A2.T4.8.6.3" class="ltx_td ltx_align_center"><math id="A2.T4.8.6.3.m1.1" class="ltx_Math" alttext="38.66" display="inline"><semantics id="A2.T4.8.6.3.m1.1a"><mn id="A2.T4.8.6.3.m1.1.1" xref="A2.T4.8.6.3.m1.1.1.cmml">38.66</mn><annotation-xml encoding="MathML-Content" id="A2.T4.8.6.3.m1.1b"><cn type="float" id="A2.T4.8.6.3.m1.1.1.cmml" xref="A2.T4.8.6.3.m1.1.1">38.66</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.8.6.3.m1.1c">38.66</annotation></semantics></math></td>
</tr>
<tr id="A2.T4.11.9" class="ltx_tr">
<th id="A2.T4.11.9.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">Small Conformer</th>
<td id="A2.T4.9.7.1" class="ltx_td ltx_align_center"><math id="A2.T4.9.7.1.m1.1" class="ltx_Math" alttext="100\%" display="inline"><semantics id="A2.T4.9.7.1.m1.1a"><mrow id="A2.T4.9.7.1.m1.1.1" xref="A2.T4.9.7.1.m1.1.1.cmml"><mn id="A2.T4.9.7.1.m1.1.1.2" xref="A2.T4.9.7.1.m1.1.1.2.cmml">100</mn><mo id="A2.T4.9.7.1.m1.1.1.1" xref="A2.T4.9.7.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.9.7.1.m1.1b"><apply id="A2.T4.9.7.1.m1.1.1.cmml" xref="A2.T4.9.7.1.m1.1.1"><csymbol cd="latexml" id="A2.T4.9.7.1.m1.1.1.1.cmml" xref="A2.T4.9.7.1.m1.1.1.1">percent</csymbol><cn type="integer" id="A2.T4.9.7.1.m1.1.1.2.cmml" xref="A2.T4.9.7.1.m1.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.9.7.1.m1.1c">100\%</annotation></semantics></math></td>
<td id="A2.T4.10.8.2" class="ltx_td ltx_align_center">
<math id="A2.T4.10.8.2.m1.1" class="ltx_Math" alttext="4.1" display="inline"><semantics id="A2.T4.10.8.2.m1.1a"><mn id="A2.T4.10.8.2.m1.1.1" xref="A2.T4.10.8.2.m1.1.1.cmml">4.1</mn><annotation-xml encoding="MathML-Content" id="A2.T4.10.8.2.m1.1b"><cn type="float" id="A2.T4.10.8.2.m1.1.1.cmml" xref="A2.T4.10.8.2.m1.1.1">4.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.10.8.2.m1.1c">4.1</annotation></semantics></math>M</td>
<td id="A2.T4.11.9.3" class="ltx_td ltx_align_center"><math id="A2.T4.11.9.3.m1.1" class="ltx_Math" alttext="36.80" display="inline"><semantics id="A2.T4.11.9.3.m1.1a"><mn id="A2.T4.11.9.3.m1.1.1" xref="A2.T4.11.9.3.m1.1.1.cmml">36.80</mn><annotation-xml encoding="MathML-Content" id="A2.T4.11.9.3.m1.1b"><cn type="float" id="A2.T4.11.9.3.m1.1.1.cmml" xref="A2.T4.11.9.3.m1.1.1">36.80</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.11.9.3.m1.1c">36.80</annotation></semantics></math></td>
</tr>
<tr id="A2.T4.14.12" class="ltx_tr">
<th id="A2.T4.14.12.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Large LSTM</th>
<td id="A2.T4.12.10.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A2.T4.12.10.1.m1.1" class="ltx_Math" alttext="100\%" display="inline"><semantics id="A2.T4.12.10.1.m1.1a"><mrow id="A2.T4.12.10.1.m1.1.1" xref="A2.T4.12.10.1.m1.1.1.cmml"><mn id="A2.T4.12.10.1.m1.1.1.2" xref="A2.T4.12.10.1.m1.1.1.2.cmml">100</mn><mo id="A2.T4.12.10.1.m1.1.1.1" xref="A2.T4.12.10.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.12.10.1.m1.1b"><apply id="A2.T4.12.10.1.m1.1.1.cmml" xref="A2.T4.12.10.1.m1.1.1"><csymbol cd="latexml" id="A2.T4.12.10.1.m1.1.1.1.cmml" xref="A2.T4.12.10.1.m1.1.1.1">percent</csymbol><cn type="integer" id="A2.T4.12.10.1.m1.1.1.2.cmml" xref="A2.T4.12.10.1.m1.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.12.10.1.m1.1c">100\%</annotation></semantics></math></td>
<td id="A2.T4.13.11.2" class="ltx_td ltx_align_center ltx_border_t">
<math id="A2.T4.13.11.2.m1.1" class="ltx_Math" alttext="18.8" display="inline"><semantics id="A2.T4.13.11.2.m1.1a"><mn id="A2.T4.13.11.2.m1.1.1" xref="A2.T4.13.11.2.m1.1.1.cmml">18.8</mn><annotation-xml encoding="MathML-Content" id="A2.T4.13.11.2.m1.1b"><cn type="float" id="A2.T4.13.11.2.m1.1.1.cmml" xref="A2.T4.13.11.2.m1.1.1">18.8</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.13.11.2.m1.1c">18.8</annotation></semantics></math>M</td>
<td id="A2.T4.14.12.3" class="ltx_td ltx_align_center ltx_border_t"><math id="A2.T4.14.12.3.m1.1" class="ltx_Math" alttext="30.83" display="inline"><semantics id="A2.T4.14.12.3.m1.1a"><mn id="A2.T4.14.12.3.m1.1.1" xref="A2.T4.14.12.3.m1.1.1.cmml">30.83</mn><annotation-xml encoding="MathML-Content" id="A2.T4.14.12.3.m1.1b"><cn type="float" id="A2.T4.14.12.3.m1.1.1.cmml" xref="A2.T4.14.12.3.m1.1.1">30.83</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.14.12.3.m1.1c">30.83</annotation></semantics></math></td>
</tr>
<tr id="A2.T4.17.15" class="ltx_tr">
<th id="A2.T4.17.15.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">Large LSTM</th>
<td id="A2.T4.15.13.1" class="ltx_td ltx_align_center"><math id="A2.T4.15.13.1.m1.1" class="ltx_Math" alttext="40\%" display="inline"><semantics id="A2.T4.15.13.1.m1.1a"><mrow id="A2.T4.15.13.1.m1.1.1" xref="A2.T4.15.13.1.m1.1.1.cmml"><mn id="A2.T4.15.13.1.m1.1.1.2" xref="A2.T4.15.13.1.m1.1.1.2.cmml">40</mn><mo id="A2.T4.15.13.1.m1.1.1.1" xref="A2.T4.15.13.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.15.13.1.m1.1b"><apply id="A2.T4.15.13.1.m1.1.1.cmml" xref="A2.T4.15.13.1.m1.1.1"><csymbol cd="latexml" id="A2.T4.15.13.1.m1.1.1.1.cmml" xref="A2.T4.15.13.1.m1.1.1.1">percent</csymbol><cn type="integer" id="A2.T4.15.13.1.m1.1.1.2.cmml" xref="A2.T4.15.13.1.m1.1.1.2">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.15.13.1.m1.1c">40\%</annotation></semantics></math></td>
<td id="A2.T4.16.14.2" class="ltx_td ltx_align_center">
<math id="A2.T4.16.14.2.m1.1" class="ltx_Math" alttext="7.5" display="inline"><semantics id="A2.T4.16.14.2.m1.1a"><mn id="A2.T4.16.14.2.m1.1.1" xref="A2.T4.16.14.2.m1.1.1.cmml">7.5</mn><annotation-xml encoding="MathML-Content" id="A2.T4.16.14.2.m1.1b"><cn type="float" id="A2.T4.16.14.2.m1.1.1.cmml" xref="A2.T4.16.14.2.m1.1.1">7.5</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.16.14.2.m1.1c">7.5</annotation></semantics></math>M</td>
<td id="A2.T4.17.15.3" class="ltx_td ltx_align_center"><math id="A2.T4.17.15.3.m1.1" class="ltx_Math" alttext="31.53" display="inline"><semantics id="A2.T4.17.15.3.m1.1a"><mn id="A2.T4.17.15.3.m1.1.1" xref="A2.T4.17.15.3.m1.1.1.cmml">31.53</mn><annotation-xml encoding="MathML-Content" id="A2.T4.17.15.3.m1.1b"><cn type="float" id="A2.T4.17.15.3.m1.1.1.cmml" xref="A2.T4.17.15.3.m1.1.1">31.53</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.17.15.3.m1.1c">31.53</annotation></semantics></math></td>
</tr>
<tr id="A2.T4.20.18" class="ltx_tr">
<th id="A2.T4.20.18.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">Large LSTM</th>
<td id="A2.T4.18.16.1" class="ltx_td ltx_align_center"><math id="A2.T4.18.16.1.m1.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="A2.T4.18.16.1.m1.1a"><mrow id="A2.T4.18.16.1.m1.1.1" xref="A2.T4.18.16.1.m1.1.1.cmml"><mn id="A2.T4.18.16.1.m1.1.1.2" xref="A2.T4.18.16.1.m1.1.1.2.cmml">20</mn><mo id="A2.T4.18.16.1.m1.1.1.1" xref="A2.T4.18.16.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.18.16.1.m1.1b"><apply id="A2.T4.18.16.1.m1.1.1.cmml" xref="A2.T4.18.16.1.m1.1.1"><csymbol cd="latexml" id="A2.T4.18.16.1.m1.1.1.1.cmml" xref="A2.T4.18.16.1.m1.1.1.1">percent</csymbol><cn type="integer" id="A2.T4.18.16.1.m1.1.1.2.cmml" xref="A2.T4.18.16.1.m1.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.18.16.1.m1.1c">20\%</annotation></semantics></math></td>
<td id="A2.T4.19.17.2" class="ltx_td ltx_align_center">
<math id="A2.T4.19.17.2.m1.1" class="ltx_Math" alttext="3.8" display="inline"><semantics id="A2.T4.19.17.2.m1.1a"><mn id="A2.T4.19.17.2.m1.1.1" xref="A2.T4.19.17.2.m1.1.1.cmml">3.8</mn><annotation-xml encoding="MathML-Content" id="A2.T4.19.17.2.m1.1b"><cn type="float" id="A2.T4.19.17.2.m1.1.1.cmml" xref="A2.T4.19.17.2.m1.1.1">3.8</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.19.17.2.m1.1c">3.8</annotation></semantics></math>M</td>
<td id="A2.T4.20.18.3" class="ltx_td ltx_align_center"><math id="A2.T4.20.18.3.m1.1" class="ltx_Math" alttext="32.93" display="inline"><semantics id="A2.T4.20.18.3.m1.1a"><mn id="A2.T4.20.18.3.m1.1.1" xref="A2.T4.20.18.3.m1.1.1.cmml">32.93</mn><annotation-xml encoding="MathML-Content" id="A2.T4.20.18.3.m1.1b"><cn type="float" id="A2.T4.20.18.3.m1.1.1.cmml" xref="A2.T4.20.18.3.m1.1.1">32.93</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.20.18.3.m1.1c">32.93</annotation></semantics></math></td>
</tr>
<tr id="A2.T4.23.21" class="ltx_tr">
<th id="A2.T4.23.21.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Large Transformer</th>
<td id="A2.T4.21.19.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A2.T4.21.19.1.m1.1" class="ltx_Math" alttext="100\%" display="inline"><semantics id="A2.T4.21.19.1.m1.1a"><mrow id="A2.T4.21.19.1.m1.1.1" xref="A2.T4.21.19.1.m1.1.1.cmml"><mn id="A2.T4.21.19.1.m1.1.1.2" xref="A2.T4.21.19.1.m1.1.1.2.cmml">100</mn><mo id="A2.T4.21.19.1.m1.1.1.1" xref="A2.T4.21.19.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.21.19.1.m1.1b"><apply id="A2.T4.21.19.1.m1.1.1.cmml" xref="A2.T4.21.19.1.m1.1.1"><csymbol cd="latexml" id="A2.T4.21.19.1.m1.1.1.1.cmml" xref="A2.T4.21.19.1.m1.1.1.1">percent</csymbol><cn type="integer" id="A2.T4.21.19.1.m1.1.1.2.cmml" xref="A2.T4.21.19.1.m1.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.21.19.1.m1.1c">100\%</annotation></semantics></math></td>
<td id="A2.T4.22.20.2" class="ltx_td ltx_align_center ltx_border_t">
<math id="A2.T4.22.20.2.m1.1" class="ltx_Math" alttext="21.0" display="inline"><semantics id="A2.T4.22.20.2.m1.1a"><mn id="A2.T4.22.20.2.m1.1.1" xref="A2.T4.22.20.2.m1.1.1.cmml">21.0</mn><annotation-xml encoding="MathML-Content" id="A2.T4.22.20.2.m1.1b"><cn type="float" id="A2.T4.22.20.2.m1.1.1.cmml" xref="A2.T4.22.20.2.m1.1.1">21.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.22.20.2.m1.1c">21.0</annotation></semantics></math>M</td>
<td id="A2.T4.23.21.3" class="ltx_td ltx_align_center ltx_border_t"><math id="A2.T4.23.21.3.m1.1" class="ltx_Math" alttext="29.15" display="inline"><semantics id="A2.T4.23.21.3.m1.1a"><mn id="A2.T4.23.21.3.m1.1.1" xref="A2.T4.23.21.3.m1.1.1.cmml">29.15</mn><annotation-xml encoding="MathML-Content" id="A2.T4.23.21.3.m1.1b"><cn type="float" id="A2.T4.23.21.3.m1.1.1.cmml" xref="A2.T4.23.21.3.m1.1.1">29.15</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.23.21.3.m1.1c">29.15</annotation></semantics></math></td>
</tr>
<tr id="A2.T4.26.24" class="ltx_tr">
<th id="A2.T4.26.24.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">Large Transformer</th>
<td id="A2.T4.24.22.1" class="ltx_td ltx_align_center"><math id="A2.T4.24.22.1.m1.1" class="ltx_Math" alttext="40\%" display="inline"><semantics id="A2.T4.24.22.1.m1.1a"><mrow id="A2.T4.24.22.1.m1.1.1" xref="A2.T4.24.22.1.m1.1.1.cmml"><mn id="A2.T4.24.22.1.m1.1.1.2" xref="A2.T4.24.22.1.m1.1.1.2.cmml">40</mn><mo id="A2.T4.24.22.1.m1.1.1.1" xref="A2.T4.24.22.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.24.22.1.m1.1b"><apply id="A2.T4.24.22.1.m1.1.1.cmml" xref="A2.T4.24.22.1.m1.1.1"><csymbol cd="latexml" id="A2.T4.24.22.1.m1.1.1.1.cmml" xref="A2.T4.24.22.1.m1.1.1.1">percent</csymbol><cn type="integer" id="A2.T4.24.22.1.m1.1.1.2.cmml" xref="A2.T4.24.22.1.m1.1.1.2">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.24.22.1.m1.1c">40\%</annotation></semantics></math></td>
<td id="A2.T4.25.23.2" class="ltx_td ltx_align_center">
<math id="A2.T4.25.23.2.m1.1" class="ltx_Math" alttext="8.4" display="inline"><semantics id="A2.T4.25.23.2.m1.1a"><mn id="A2.T4.25.23.2.m1.1.1" xref="A2.T4.25.23.2.m1.1.1.cmml">8.4</mn><annotation-xml encoding="MathML-Content" id="A2.T4.25.23.2.m1.1b"><cn type="float" id="A2.T4.25.23.2.m1.1.1.cmml" xref="A2.T4.25.23.2.m1.1.1">8.4</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.25.23.2.m1.1c">8.4</annotation></semantics></math>M</td>
<td id="A2.T4.26.24.3" class="ltx_td ltx_align_center"><math id="A2.T4.26.24.3.m1.1" class="ltx_Math" alttext="30.45" display="inline"><semantics id="A2.T4.26.24.3.m1.1a"><mn id="A2.T4.26.24.3.m1.1.1" xref="A2.T4.26.24.3.m1.1.1.cmml">30.45</mn><annotation-xml encoding="MathML-Content" id="A2.T4.26.24.3.m1.1b"><cn type="float" id="A2.T4.26.24.3.m1.1.1.cmml" xref="A2.T4.26.24.3.m1.1.1">30.45</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.26.24.3.m1.1c">30.45</annotation></semantics></math></td>
</tr>
<tr id="A2.T4.29.27" class="ltx_tr">
<th id="A2.T4.29.27.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">Large Transformer</th>
<td id="A2.T4.27.25.1" class="ltx_td ltx_align_center"><math id="A2.T4.27.25.1.m1.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="A2.T4.27.25.1.m1.1a"><mrow id="A2.T4.27.25.1.m1.1.1" xref="A2.T4.27.25.1.m1.1.1.cmml"><mn id="A2.T4.27.25.1.m1.1.1.2" xref="A2.T4.27.25.1.m1.1.1.2.cmml">20</mn><mo id="A2.T4.27.25.1.m1.1.1.1" xref="A2.T4.27.25.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.27.25.1.m1.1b"><apply id="A2.T4.27.25.1.m1.1.1.cmml" xref="A2.T4.27.25.1.m1.1.1"><csymbol cd="latexml" id="A2.T4.27.25.1.m1.1.1.1.cmml" xref="A2.T4.27.25.1.m1.1.1.1">percent</csymbol><cn type="integer" id="A2.T4.27.25.1.m1.1.1.2.cmml" xref="A2.T4.27.25.1.m1.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.27.25.1.m1.1c">20\%</annotation></semantics></math></td>
<td id="A2.T4.28.26.2" class="ltx_td ltx_align_center">
<math id="A2.T4.28.26.2.m1.1" class="ltx_Math" alttext="4.2" display="inline"><semantics id="A2.T4.28.26.2.m1.1a"><mn id="A2.T4.28.26.2.m1.1.1" xref="A2.T4.28.26.2.m1.1.1.cmml">4.2</mn><annotation-xml encoding="MathML-Content" id="A2.T4.28.26.2.m1.1b"><cn type="float" id="A2.T4.28.26.2.m1.1.1.cmml" xref="A2.T4.28.26.2.m1.1.1">4.2</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.28.26.2.m1.1c">4.2</annotation></semantics></math>M</td>
<td id="A2.T4.29.27.3" class="ltx_td ltx_align_center"><math id="A2.T4.29.27.3.m1.1" class="ltx_Math" alttext="32.61" display="inline"><semantics id="A2.T4.29.27.3.m1.1a"><mn id="A2.T4.29.27.3.m1.1.1" xref="A2.T4.29.27.3.m1.1.1.cmml">32.61</mn><annotation-xml encoding="MathML-Content" id="A2.T4.29.27.3.m1.1b"><cn type="float" id="A2.T4.29.27.3.m1.1.1.cmml" xref="A2.T4.29.27.3.m1.1.1">32.61</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.29.27.3.m1.1c">32.61</annotation></semantics></math></td>
</tr>
<tr id="A2.T4.32.30" class="ltx_tr">
<th id="A2.T4.32.30.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Large Conformer</th>
<td id="A2.T4.30.28.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A2.T4.30.28.1.m1.1" class="ltx_Math" alttext="100\%" display="inline"><semantics id="A2.T4.30.28.1.m1.1a"><mrow id="A2.T4.30.28.1.m1.1.1" xref="A2.T4.30.28.1.m1.1.1.cmml"><mn id="A2.T4.30.28.1.m1.1.1.2" xref="A2.T4.30.28.1.m1.1.1.2.cmml">100</mn><mo id="A2.T4.30.28.1.m1.1.1.1" xref="A2.T4.30.28.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.30.28.1.m1.1b"><apply id="A2.T4.30.28.1.m1.1.1.cmml" xref="A2.T4.30.28.1.m1.1.1"><csymbol cd="latexml" id="A2.T4.30.28.1.m1.1.1.1.cmml" xref="A2.T4.30.28.1.m1.1.1.1">percent</csymbol><cn type="integer" id="A2.T4.30.28.1.m1.1.1.2.cmml" xref="A2.T4.30.28.1.m1.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.30.28.1.m1.1c">100\%</annotation></semantics></math></td>
<td id="A2.T4.31.29.2" class="ltx_td ltx_align_center ltx_border_t">
<math id="A2.T4.31.29.2.m1.1" class="ltx_Math" alttext="20.2" display="inline"><semantics id="A2.T4.31.29.2.m1.1a"><mn id="A2.T4.31.29.2.m1.1.1" xref="A2.T4.31.29.2.m1.1.1.cmml">20.2</mn><annotation-xml encoding="MathML-Content" id="A2.T4.31.29.2.m1.1b"><cn type="float" id="A2.T4.31.29.2.m1.1.1.cmml" xref="A2.T4.31.29.2.m1.1.1">20.2</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.31.29.2.m1.1c">20.2</annotation></semantics></math>M</td>
<td id="A2.T4.32.30.3" class="ltx_td ltx_align_center ltx_border_t"><math id="A2.T4.32.30.3.m1.1" class="ltx_Math" alttext="29.06" display="inline"><semantics id="A2.T4.32.30.3.m1.1a"><mn id="A2.T4.32.30.3.m1.1.1" xref="A2.T4.32.30.3.m1.1.1.cmml">29.06</mn><annotation-xml encoding="MathML-Content" id="A2.T4.32.30.3.m1.1b"><cn type="float" id="A2.T4.32.30.3.m1.1.1.cmml" xref="A2.T4.32.30.3.m1.1.1">29.06</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.32.30.3.m1.1c">29.06</annotation></semantics></math></td>
</tr>
<tr id="A2.T4.35.33" class="ltx_tr">
<th id="A2.T4.35.33.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">Large Conformer</th>
<td id="A2.T4.33.31.1" class="ltx_td ltx_align_center"><math id="A2.T4.33.31.1.m1.1" class="ltx_Math" alttext="40\%" display="inline"><semantics id="A2.T4.33.31.1.m1.1a"><mrow id="A2.T4.33.31.1.m1.1.1" xref="A2.T4.33.31.1.m1.1.1.cmml"><mn id="A2.T4.33.31.1.m1.1.1.2" xref="A2.T4.33.31.1.m1.1.1.2.cmml">40</mn><mo id="A2.T4.33.31.1.m1.1.1.1" xref="A2.T4.33.31.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.33.31.1.m1.1b"><apply id="A2.T4.33.31.1.m1.1.1.cmml" xref="A2.T4.33.31.1.m1.1.1"><csymbol cd="latexml" id="A2.T4.33.31.1.m1.1.1.1.cmml" xref="A2.T4.33.31.1.m1.1.1.1">percent</csymbol><cn type="integer" id="A2.T4.33.31.1.m1.1.1.2.cmml" xref="A2.T4.33.31.1.m1.1.1.2">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.33.31.1.m1.1c">40\%</annotation></semantics></math></td>
<td id="A2.T4.34.32.2" class="ltx_td ltx_align_center">
<math id="A2.T4.34.32.2.m1.1" class="ltx_Math" alttext="8.1" display="inline"><semantics id="A2.T4.34.32.2.m1.1a"><mn id="A2.T4.34.32.2.m1.1.1" xref="A2.T4.34.32.2.m1.1.1.cmml">8.1</mn><annotation-xml encoding="MathML-Content" id="A2.T4.34.32.2.m1.1b"><cn type="float" id="A2.T4.34.32.2.m1.1.1.cmml" xref="A2.T4.34.32.2.m1.1.1">8.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.34.32.2.m1.1c">8.1</annotation></semantics></math>M</td>
<td id="A2.T4.35.33.3" class="ltx_td ltx_align_center"><math id="A2.T4.35.33.3.m1.1" class="ltx_Math" alttext="30.06" display="inline"><semantics id="A2.T4.35.33.3.m1.1a"><mn id="A2.T4.35.33.3.m1.1.1" xref="A2.T4.35.33.3.m1.1.1.cmml">30.06</mn><annotation-xml encoding="MathML-Content" id="A2.T4.35.33.3.m1.1b"><cn type="float" id="A2.T4.35.33.3.m1.1.1.cmml" xref="A2.T4.35.33.3.m1.1.1">30.06</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.35.33.3.m1.1c">30.06</annotation></semantics></math></td>
</tr>
<tr id="A2.T4.38.36" class="ltx_tr">
<th id="A2.T4.38.36.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">Large Conformer</th>
<td id="A2.T4.36.34.1" class="ltx_td ltx_align_center"><math id="A2.T4.36.34.1.m1.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="A2.T4.36.34.1.m1.1a"><mrow id="A2.T4.36.34.1.m1.1.1" xref="A2.T4.36.34.1.m1.1.1.cmml"><mn id="A2.T4.36.34.1.m1.1.1.2" xref="A2.T4.36.34.1.m1.1.1.2.cmml">20</mn><mo id="A2.T4.36.34.1.m1.1.1.1" xref="A2.T4.36.34.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.T4.36.34.1.m1.1b"><apply id="A2.T4.36.34.1.m1.1.1.cmml" xref="A2.T4.36.34.1.m1.1.1"><csymbol cd="latexml" id="A2.T4.36.34.1.m1.1.1.1.cmml" xref="A2.T4.36.34.1.m1.1.1.1">percent</csymbol><cn type="integer" id="A2.T4.36.34.1.m1.1.1.2.cmml" xref="A2.T4.36.34.1.m1.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.36.34.1.m1.1c">20\%</annotation></semantics></math></td>
<td id="A2.T4.37.35.2" class="ltx_td ltx_align_center">
<math id="A2.T4.37.35.2.m1.1" class="ltx_Math" alttext="4.0" display="inline"><semantics id="A2.T4.37.35.2.m1.1a"><mn id="A2.T4.37.35.2.m1.1.1" xref="A2.T4.37.35.2.m1.1.1.cmml">4.0</mn><annotation-xml encoding="MathML-Content" id="A2.T4.37.35.2.m1.1b"><cn type="float" id="A2.T4.37.35.2.m1.1.1.cmml" xref="A2.T4.37.35.2.m1.1.1">4.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.37.35.2.m1.1c">4.0</annotation></semantics></math>M</td>
<td id="A2.T4.38.36.3" class="ltx_td ltx_align_center"><math id="A2.T4.38.36.3.m1.1" class="ltx_Math" alttext="31.51" display="inline"><semantics id="A2.T4.38.36.3.m1.1a"><mn id="A2.T4.38.36.3.m1.1.1" xref="A2.T4.38.36.3.m1.1.1.cmml">31.51</mn><annotation-xml encoding="MathML-Content" id="A2.T4.38.36.3.m1.1b"><cn type="float" id="A2.T4.38.36.3.m1.1.1.cmml" xref="A2.T4.38.36.3.m1.1.1">31.51</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.T4.38.36.3.m1.1c">31.51</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
<figure id="A2.F11" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2204.09715/assets/pvt_lstm.png" id="A2.F11.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="176" height="130" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2204.09715/assets/pvt_trans.png" id="A2.F11.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="176" height="130" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_3"><img src="/html/2204.09715/assets/pvt_conf.png" id="A2.F11.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="176" height="130" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Test perplexity over communication rounds for the large models with select percentages of trainable variables denoted by <math id="A2.F11.3.m1.1" class="ltx_Math" alttext="X\%" display="inline"><semantics id="A2.F11.3.m1.1b"><mrow id="A2.F11.3.m1.1.1" xref="A2.F11.3.m1.1.1.cmml"><mi id="A2.F11.3.m1.1.1.2" xref="A2.F11.3.m1.1.1.2.cmml">X</mi><mo id="A2.F11.3.m1.1.1.1" xref="A2.F11.3.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.F11.3.m1.1c"><apply id="A2.F11.3.m1.1.1.cmml" xref="A2.F11.3.m1.1.1"><csymbol cd="latexml" id="A2.F11.3.m1.1.1.1.cmml" xref="A2.F11.3.m1.1.1.1">percent</csymbol><ci id="A2.F11.3.m1.1.1.2.cmml" xref="A2.F11.3.m1.1.1.2">𝑋</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.F11.3.m1.1d">X\%</annotation></semantics></math> with <math id="A2.F11.4.m2.1" class="ltx_Math" alttext="100\%" display="inline"><semantics id="A2.F11.4.m2.1b"><mrow id="A2.F11.4.m2.1.1" xref="A2.F11.4.m2.1.1.cmml"><mn id="A2.F11.4.m2.1.1.2" xref="A2.F11.4.m2.1.1.2.cmml">100</mn><mo id="A2.F11.4.m2.1.1.1" xref="A2.F11.4.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.F11.4.m2.1c"><apply id="A2.F11.4.m2.1.1.cmml" xref="A2.F11.4.m2.1.1"><csymbol cd="latexml" id="A2.F11.4.m2.1.1.1.cmml" xref="A2.F11.4.m2.1.1.1">percent</csymbol><cn type="integer" id="A2.F11.4.m2.1.1.2.cmml" xref="A2.F11.4.m2.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.F11.4.m2.1d">100\%</annotation></semantics></math> indicating all trainable variables are trained (i.e. baseline).</figcaption>
</figure>
<div id="A2.p1" class="ltx_para">
<p id="A2.p1.4" class="ltx_p">In our experiments with PVT, we vary the percentage of trainable variables from <math id="A2.p1.1.m1.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="A2.p1.1.m1.1a"><mrow id="A2.p1.1.m1.1.1" xref="A2.p1.1.m1.1.1.cmml"><mn id="A2.p1.1.m1.1.1.2" xref="A2.p1.1.m1.1.1.2.cmml">10</mn><mo id="A2.p1.1.m1.1.1.1" xref="A2.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.1.m1.1b"><apply id="A2.p1.1.m1.1.1.cmml" xref="A2.p1.1.m1.1.1"><csymbol cd="latexml" id="A2.p1.1.m1.1.1.1.cmml" xref="A2.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="A2.p1.1.m1.1.1.2.cmml" xref="A2.p1.1.m1.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.1.m1.1c">10\%</annotation></semantics></math> to <math id="A2.p1.2.m2.1" class="ltx_Math" alttext="90\%" display="inline"><semantics id="A2.p1.2.m2.1a"><mrow id="A2.p1.2.m2.1.1" xref="A2.p1.2.m2.1.1.cmml"><mn id="A2.p1.2.m2.1.1.2" xref="A2.p1.2.m2.1.1.2.cmml">90</mn><mo id="A2.p1.2.m2.1.1.1" xref="A2.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.2.m2.1b"><apply id="A2.p1.2.m2.1.1.cmml" xref="A2.p1.2.m2.1.1"><csymbol cd="latexml" id="A2.p1.2.m2.1.1.1.cmml" xref="A2.p1.2.m2.1.1.1">percent</csymbol><cn type="integer" id="A2.p1.2.m2.1.1.2.cmml" xref="A2.p1.2.m2.1.1.2">90</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.2.m2.1c">90\%</annotation></semantics></math> in increments of <math id="A2.p1.3.m3.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A2.p1.3.m3.1a"><mn id="A2.p1.3.m3.1.1" xref="A2.p1.3.m3.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A2.p1.3.m3.1b"><cn type="integer" id="A2.p1.3.m3.1.1.cmml" xref="A2.p1.3.m3.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.3.m3.1c">10</annotation></semantics></math>.
As before, we search over the hyperparameters in Table <a href="#A1.T3" title="Table 3 ‣ Appendix A Dataset and models ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and find them to be mostly consistent with baseline other than client learning rate.
Following <cite class="ltx_cite ltx_citemacro_citet">Yang et al. [<a href="#bib.bib55" title="" class="ltx_ref">2021</a>]</cite>, we use the per client per round (PCPR) configuration, where the frozen variables vary from round to round and from client to client, as this was shown to achieve the highest accuracy.
Specifically, we only freeze subsets of the multiplicative vectors and matrices of the original model.
This corresponds to the embedding and weights of the LSTM, and for the Transformer and Conformer, the weights of the MLP layer, attention matrices, layer normalization in each block, embedding, and weights for Conformer convolution.
We also note though that although overall the number of trainable variables might average to the desired percentage (e.g. <math id="A2.p1.4.m4.1" class="ltx_Math" alttext="10\%" display="inline"><semantics id="A2.p1.4.m4.1a"><mrow id="A2.p1.4.m4.1.1" xref="A2.p1.4.m4.1.1.cmml"><mn id="A2.p1.4.m4.1.1.2" xref="A2.p1.4.m4.1.1.2.cmml">10</mn><mo id="A2.p1.4.m4.1.1.1" xref="A2.p1.4.m4.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.4.m4.1b"><apply id="A2.p1.4.m4.1.1.cmml" xref="A2.p1.4.m4.1.1"><csymbol cd="latexml" id="A2.p1.4.m4.1.1.1.cmml" xref="A2.p1.4.m4.1.1.1">percent</csymbol><cn type="integer" id="A2.p1.4.m4.1.1.2.cmml" xref="A2.p1.4.m4.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.4.m4.1c">10\%</annotation></semantics></math>), for certain architectures, like LSTM, that don’t have that many <em id="A2.p1.4.1" class="ltx_emph ltx_font_italic">freezable variables</em> (only one layer’s weight matrix and embedding matrix), the number of trained variables will be much more variable from round to round.
On the other hand, for architectures, like Transformer and Conformer, that have more freezable variables (each blocks’ weight matrices and attention matrices and embeddings), the number of trained is much more consistent between rounds.</p>
</div>
<div id="A2.p2" class="ltx_para">
<p id="A2.p2.5" class="ltx_p">We report test set perplexity over communication rounds for the large architectures and varying degrees of PVT in Figure <a href="#A2.F11" title="Figure 11 ‣ Appendix B Partial model training ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> with the number of clients per round set to <math id="A2.p2.1.m1.1" class="ltx_Math" alttext="800" display="inline"><semantics id="A2.p2.1.m1.1a"><mn id="A2.p2.1.m1.1.1" xref="A2.p2.1.m1.1.1.cmml">800</mn><annotation-xml encoding="MathML-Content" id="A2.p2.1.m1.1b"><cn type="integer" id="A2.p2.1.m1.1.1.cmml" xref="A2.p2.1.m1.1.1">800</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.1.m1.1c">800</annotation></semantics></math>.
Looking at Table <a href="#A2.T4" title="Table 4 ‣ Appendix B Partial model training ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, it is evident that both large models can handle some percentage of partial freezing up until a certain point and that the Large Conformer with only <math id="A2.p2.2.m2.1" class="ltx_Math" alttext="30\%" display="inline"><semantics id="A2.p2.2.m2.1a"><mrow id="A2.p2.2.m2.1.1" xref="A2.p2.2.m2.1.1.cmml"><mn id="A2.p2.2.m2.1.1.2" xref="A2.p2.2.m2.1.1.2.cmml">30</mn><mo id="A2.p2.2.m2.1.1.1" xref="A2.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.p2.2.m2.1b"><apply id="A2.p2.2.m2.1.1.cmml" xref="A2.p2.2.m2.1.1"><csymbol cd="latexml" id="A2.p2.2.m2.1.1.1.cmml" xref="A2.p2.2.m2.1.1.1">percent</csymbol><cn type="integer" id="A2.p2.2.m2.1.1.2.cmml" xref="A2.p2.2.m2.1.1.2">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.2.m2.1c">30\%</annotation></semantics></math> of trainable variables can reach a better perplexity than the Large LSTM with <math id="A2.p2.3.m3.1" class="ltx_Math" alttext="100\%" display="inline"><semantics id="A2.p2.3.m3.1a"><mrow id="A2.p2.3.m3.1.1" xref="A2.p2.3.m3.1.1.cmml"><mn id="A2.p2.3.m3.1.1.2" xref="A2.p2.3.m3.1.1.2.cmml">100</mn><mo id="A2.p2.3.m3.1.1.1" xref="A2.p2.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.p2.3.m3.1b"><apply id="A2.p2.3.m3.1.1.cmml" xref="A2.p2.3.m3.1.1"><csymbol cd="latexml" id="A2.p2.3.m3.1.1.1.cmml" xref="A2.p2.3.m3.1.1.1">percent</csymbol><cn type="integer" id="A2.p2.3.m3.1.1.2.cmml" xref="A2.p2.3.m3.1.1.2">100</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.3.m3.1c">100\%</annotation></semantics></math> trainable variables by <math id="A2.p2.4.m4.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A2.p2.4.m4.1a"><mn id="A2.p2.4.m4.1.1" xref="A2.p2.4.m4.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A2.p2.4.m4.1b"><cn type="integer" id="A2.p2.4.m4.1.1.cmml" xref="A2.p2.4.m4.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.4.m4.1c">10</annotation></semantics></math>K rounds or so.
However, training for the full <math id="A2.p2.5.m5.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A2.p2.5.m5.1a"><mn id="A2.p2.5.m5.1.1" xref="A2.p2.5.m5.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A2.p2.5.m5.1b"><cn type="integer" id="A2.p2.5.m5.1.1.cmml" xref="A2.p2.5.m5.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A2.p2.5.m5.1c">10</annotation></semantics></math>K rounds can be a communication bottleneck so PVT would need to be combined with another technique to reduce the number of rounds needed.</p>
</div>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Quantization</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.16" class="ltx_p">In stochastic <math id="A3.p1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A3.p1.1.m1.1a"><mi id="A3.p1.1.m1.1.1" xref="A3.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A3.p1.1.m1.1b"><ci id="A3.p1.1.m1.1.1.cmml" xref="A3.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.1.m1.1c">k</annotation></semantics></math>-level uniform quantization <cite class="ltx_cite ltx_citemacro_cite">Suresh et al. [<a href="#bib.bib47" title="" class="ltx_ref">2017</a>]</cite>, values in each layer are converted into one of <math id="A3.p1.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A3.p1.2.m2.1a"><mi id="A3.p1.2.m2.1.1" xref="A3.p1.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A3.p1.2.m2.1b"><ci id="A3.p1.2.m2.1.1.cmml" xref="A3.p1.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.2.m2.1c">k</annotation></semantics></math> evenly distributed values between the layer min and max, stochastically assigned to the closest target value either above or below the real value. The lower the <math id="A3.p1.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A3.p1.3.m3.1a"><mi id="A3.p1.3.m3.1.1" xref="A3.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A3.p1.3.m3.1b"><ci id="A3.p1.3.m3.1.1.cmml" xref="A3.p1.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.3.m3.1c">k</annotation></semantics></math> value, the more the data is being compressed, as the number of bits used to store the value equals <math id="A3.p1.4.m4.2" class="ltx_Math" alttext="\log_{2}(k)" display="inline"><semantics id="A3.p1.4.m4.2a"><mrow id="A3.p1.4.m4.2.2.1" xref="A3.p1.4.m4.2.2.2.cmml"><msub id="A3.p1.4.m4.2.2.1.1" xref="A3.p1.4.m4.2.2.1.1.cmml"><mi id="A3.p1.4.m4.2.2.1.1.2" xref="A3.p1.4.m4.2.2.1.1.2.cmml">log</mi><mn id="A3.p1.4.m4.2.2.1.1.3" xref="A3.p1.4.m4.2.2.1.1.3.cmml">2</mn></msub><mo id="A3.p1.4.m4.2.2.1a" xref="A3.p1.4.m4.2.2.2.cmml">⁡</mo><mrow id="A3.p1.4.m4.2.2.1.2" xref="A3.p1.4.m4.2.2.2.cmml"><mo stretchy="false" id="A3.p1.4.m4.2.2.1.2.1" xref="A3.p1.4.m4.2.2.2.cmml">(</mo><mi id="A3.p1.4.m4.1.1" xref="A3.p1.4.m4.1.1.cmml">k</mi><mo stretchy="false" id="A3.p1.4.m4.2.2.1.2.2" xref="A3.p1.4.m4.2.2.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.p1.4.m4.2b"><apply id="A3.p1.4.m4.2.2.2.cmml" xref="A3.p1.4.m4.2.2.1"><apply id="A3.p1.4.m4.2.2.1.1.cmml" xref="A3.p1.4.m4.2.2.1.1"><csymbol cd="ambiguous" id="A3.p1.4.m4.2.2.1.1.1.cmml" xref="A3.p1.4.m4.2.2.1.1">subscript</csymbol><log id="A3.p1.4.m4.2.2.1.1.2.cmml" xref="A3.p1.4.m4.2.2.1.1.2"></log><cn type="integer" id="A3.p1.4.m4.2.2.1.1.3.cmml" xref="A3.p1.4.m4.2.2.1.1.3">2</cn></apply><ci id="A3.p1.4.m4.1.1.cmml" xref="A3.p1.4.m4.1.1">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.4.m4.2c">\log_{2}(k)</annotation></semantics></math>. For download quantization, we explore <math id="A3.p1.5.m5.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A3.p1.5.m5.1a"><mi id="A3.p1.5.m5.1.1" xref="A3.p1.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A3.p1.5.m5.1b"><ci id="A3.p1.5.m5.1.1.cmml" xref="A3.p1.5.m5.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.5.m5.1c">k</annotation></semantics></math> values corresponding to between <math id="A3.p1.6.m6.1" class="ltx_Math" alttext="8" display="inline"><semantics id="A3.p1.6.m6.1a"><mn id="A3.p1.6.m6.1.1" xref="A3.p1.6.m6.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A3.p1.6.m6.1b"><cn type="integer" id="A3.p1.6.m6.1.1.cmml" xref="A3.p1.6.m6.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.6.m6.1c">8</annotation></semantics></math> and <math id="A3.p1.7.m7.1" class="ltx_Math" alttext="28" display="inline"><semantics id="A3.p1.7.m7.1a"><mn id="A3.p1.7.m7.1.1" xref="A3.p1.7.m7.1.1.cmml">28</mn><annotation-xml encoding="MathML-Content" id="A3.p1.7.m7.1b"><cn type="integer" id="A3.p1.7.m7.1.1.cmml" xref="A3.p1.7.m7.1.1">28</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.7.m7.1c">28</annotation></semantics></math> bits. For upload quantization, which can be a larger bottleneck in edge devices <cite class="ltx_cite ltx_citemacro_citep">[Statista.com, <a href="#bib.bib45" title="" class="ltx_ref">2021</a>]</cite>, we explore <math id="A3.p1.8.m8.1" class="ltx_Math" alttext="k" display="inline"><semantics id="A3.p1.8.m8.1a"><mi id="A3.p1.8.m8.1.1" xref="A3.p1.8.m8.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="A3.p1.8.m8.1b"><ci id="A3.p1.8.m8.1.1.cmml" xref="A3.p1.8.m8.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.8.m8.1c">k</annotation></semantics></math> values corresponding to between <math id="A3.p1.9.m9.1" class="ltx_Math" alttext="1" display="inline"><semantics id="A3.p1.9.m9.1a"><mn id="A3.p1.9.m9.1.1" xref="A3.p1.9.m9.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="A3.p1.9.m9.1b"><cn type="integer" id="A3.p1.9.m9.1.1.cmml" xref="A3.p1.9.m9.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.9.m9.1c">1</annotation></semantics></math> and <math id="A3.p1.10.m10.1" class="ltx_Math" alttext="28" display="inline"><semantics id="A3.p1.10.m10.1a"><mn id="A3.p1.10.m10.1.1" xref="A3.p1.10.m10.1.1.cmml">28</mn><annotation-xml encoding="MathML-Content" id="A3.p1.10.m10.1b"><cn type="integer" id="A3.p1.10.m10.1.1.cmml" xref="A3.p1.10.m10.1.1">28</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.10.m10.1c">28</annotation></semantics></math> bits. On upload, we also try applying zero-centering during uniform quantization as well as trying the TernGrad <cite class="ltx_cite ltx_citemacro_citep">[Wen et al., <a href="#bib.bib54" title="" class="ltx_ref">2017</a>]</cite> algorithm, which quantizes values in each vector <math id="A3.p1.11.m11.1" class="ltx_Math" alttext="v" display="inline"><semantics id="A3.p1.11.m11.1a"><mi id="A3.p1.11.m11.1.1" xref="A3.p1.11.m11.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="A3.p1.11.m11.1b"><ci id="A3.p1.11.m11.1.1.cmml" xref="A3.p1.11.m11.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.11.m11.1c">v</annotation></semantics></math> into only one of three values, <math id="A3.p1.12.m12.1" class="ltx_Math" alttext="0" display="inline"><semantics id="A3.p1.12.m12.1a"><mn id="A3.p1.12.m12.1.1" xref="A3.p1.12.m12.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="A3.p1.12.m12.1b"><cn type="integer" id="A3.p1.12.m12.1.1.cmml" xref="A3.p1.12.m12.1.1">0</cn></annotation-xml></semantics></math> and <math id="A3.p1.13.m13.3" class="ltx_Math" alttext="\pm\max(|v|)" display="inline"><semantics id="A3.p1.13.m13.3a"><mrow id="A3.p1.13.m13.3.3" xref="A3.p1.13.m13.3.3.cmml"><mo rspace="0.167em" id="A3.p1.13.m13.3.3a" xref="A3.p1.13.m13.3.3.cmml">±</mo><mrow id="A3.p1.13.m13.3.3.1.1" xref="A3.p1.13.m13.3.3.1.2.cmml"><mi id="A3.p1.13.m13.2.2" xref="A3.p1.13.m13.2.2.cmml">max</mi><mo id="A3.p1.13.m13.3.3.1.1a" xref="A3.p1.13.m13.3.3.1.2.cmml">⁡</mo><mrow id="A3.p1.13.m13.3.3.1.1.1" xref="A3.p1.13.m13.3.3.1.2.cmml"><mo stretchy="false" id="A3.p1.13.m13.3.3.1.1.1.2" xref="A3.p1.13.m13.3.3.1.2.cmml">(</mo><mrow id="A3.p1.13.m13.3.3.1.1.1.1.2" xref="A3.p1.13.m13.3.3.1.1.1.1.1.cmml"><mo stretchy="false" id="A3.p1.13.m13.3.3.1.1.1.1.2.1" xref="A3.p1.13.m13.3.3.1.1.1.1.1.1.cmml">|</mo><mi id="A3.p1.13.m13.1.1" xref="A3.p1.13.m13.1.1.cmml">v</mi><mo stretchy="false" id="A3.p1.13.m13.3.3.1.1.1.1.2.2" xref="A3.p1.13.m13.3.3.1.1.1.1.1.1.cmml">|</mo></mrow><mo stretchy="false" id="A3.p1.13.m13.3.3.1.1.1.3" xref="A3.p1.13.m13.3.3.1.2.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.p1.13.m13.3b"><apply id="A3.p1.13.m13.3.3.cmml" xref="A3.p1.13.m13.3.3"><csymbol cd="latexml" id="A3.p1.13.m13.3.3.2.cmml" xref="A3.p1.13.m13.3.3">plus-or-minus</csymbol><apply id="A3.p1.13.m13.3.3.1.2.cmml" xref="A3.p1.13.m13.3.3.1.1"><max id="A3.p1.13.m13.2.2.cmml" xref="A3.p1.13.m13.2.2"></max><apply id="A3.p1.13.m13.3.3.1.1.1.1.1.cmml" xref="A3.p1.13.m13.3.3.1.1.1.1.2"><abs id="A3.p1.13.m13.3.3.1.1.1.1.1.1.cmml" xref="A3.p1.13.m13.3.3.1.1.1.1.2.1"></abs><ci id="A3.p1.13.m13.1.1.cmml" xref="A3.p1.13.m13.1.1">𝑣</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.13.m13.3c">\pm\max(|v|)</annotation></semantics></math>, corresponding to <math id="A3.p1.14.m14.2" class="ltx_Math" alttext="\log_{2}(3)" display="inline"><semantics id="A3.p1.14.m14.2a"><mrow id="A3.p1.14.m14.2.2.1" xref="A3.p1.14.m14.2.2.2.cmml"><msub id="A3.p1.14.m14.2.2.1.1" xref="A3.p1.14.m14.2.2.1.1.cmml"><mi id="A3.p1.14.m14.2.2.1.1.2" xref="A3.p1.14.m14.2.2.1.1.2.cmml">log</mi><mn id="A3.p1.14.m14.2.2.1.1.3" xref="A3.p1.14.m14.2.2.1.1.3.cmml">2</mn></msub><mo id="A3.p1.14.m14.2.2.1a" xref="A3.p1.14.m14.2.2.2.cmml">⁡</mo><mrow id="A3.p1.14.m14.2.2.1.2" xref="A3.p1.14.m14.2.2.2.cmml"><mo stretchy="false" id="A3.p1.14.m14.2.2.1.2.1" xref="A3.p1.14.m14.2.2.2.cmml">(</mo><mn id="A3.p1.14.m14.1.1" xref="A3.p1.14.m14.1.1.cmml">3</mn><mo stretchy="false" id="A3.p1.14.m14.2.2.1.2.2" xref="A3.p1.14.m14.2.2.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.p1.14.m14.2b"><apply id="A3.p1.14.m14.2.2.2.cmml" xref="A3.p1.14.m14.2.2.1"><apply id="A3.p1.14.m14.2.2.1.1.cmml" xref="A3.p1.14.m14.2.2.1.1"><csymbol cd="ambiguous" id="A3.p1.14.m14.2.2.1.1.1.cmml" xref="A3.p1.14.m14.2.2.1.1">subscript</csymbol><log id="A3.p1.14.m14.2.2.1.1.2.cmml" xref="A3.p1.14.m14.2.2.1.1.2"></log><cn type="integer" id="A3.p1.14.m14.2.2.1.1.3.cmml" xref="A3.p1.14.m14.2.2.1.1.3">2</cn></apply><cn type="integer" id="A3.p1.14.m14.1.1.cmml" xref="A3.p1.14.m14.1.1">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.14.m14.2c">\log_{2}(3)</annotation></semantics></math> (<math id="A3.p1.15.m15.1" class="ltx_Math" alttext="\sim 1.585" display="inline"><semantics id="A3.p1.15.m15.1a"><mrow id="A3.p1.15.m15.1.1" xref="A3.p1.15.m15.1.1.cmml"><mi id="A3.p1.15.m15.1.1.2" xref="A3.p1.15.m15.1.1.2.cmml"></mi><mo id="A3.p1.15.m15.1.1.1" xref="A3.p1.15.m15.1.1.1.cmml">∼</mo><mn id="A3.p1.15.m15.1.1.3" xref="A3.p1.15.m15.1.1.3.cmml">1.585</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.p1.15.m15.1b"><apply id="A3.p1.15.m15.1.1.cmml" xref="A3.p1.15.m15.1.1"><csymbol cd="latexml" id="A3.p1.15.m15.1.1.1.cmml" xref="A3.p1.15.m15.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="A3.p1.15.m15.1.1.2.cmml" xref="A3.p1.15.m15.1.1.2">absent</csymbol><cn type="float" id="A3.p1.15.m15.1.1.3.cmml" xref="A3.p1.15.m15.1.1.3">1.585</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.15.m15.1c">\sim 1.585</annotation></semantics></math>) bits per parameter. While TernGrad is designed to use L infinity clipping (<math id="A3.p1.16.m16.1" class="ltx_Math" alttext="\ell_{\infty}" display="inline"><semantics id="A3.p1.16.m16.1a"><msub id="A3.p1.16.m16.1.1" xref="A3.p1.16.m16.1.1.cmml"><mi mathvariant="normal" id="A3.p1.16.m16.1.1.2" xref="A3.p1.16.m16.1.1.2.cmml">ℓ</mi><mi mathvariant="normal" id="A3.p1.16.m16.1.1.3" xref="A3.p1.16.m16.1.1.3.cmml">∞</mi></msub><annotation-xml encoding="MathML-Content" id="A3.p1.16.m16.1b"><apply id="A3.p1.16.m16.1.1.cmml" xref="A3.p1.16.m16.1.1"><csymbol cd="ambiguous" id="A3.p1.16.m16.1.1.1.cmml" xref="A3.p1.16.m16.1.1">subscript</csymbol><ci id="A3.p1.16.m16.1.1.2.cmml" xref="A3.p1.16.m16.1.1.2">ℓ</ci><infinity id="A3.p1.16.m16.1.1.3.cmml" xref="A3.p1.16.m16.1.1.3"></infinity></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p1.16.m16.1c">\ell_{\infty}</annotation></semantics></math>), we experiment with and without this for completeness.</p>
</div>
<figure id="A3.F12" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2204.09715/assets/rnn_quant_upload_detailed.png" id="A3.F12.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="310" height="131" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2204.09715/assets/trans_quant_upload_detailed.png" id="A3.F12.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="310" height="131" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2204.09715/assets/conf_quant_upload_detailed.png" id="A3.F12.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="310" height="131" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Test set perplexity over communication rounds for varying upload quantization levels, with download quantization fixed to <math id="A3.F12.3.m1.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A3.F12.3.m1.1b"><mn id="A3.F12.3.m1.1.1" xref="A3.F12.3.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A3.F12.3.m1.1c"><cn type="integer" id="A3.F12.3.m1.1.1.cmml" xref="A3.F12.3.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.F12.3.m1.1d">16</annotation></semantics></math> bits. The dotted line shows baseline perplexity achieved after <math id="A3.F12.4.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A3.F12.4.m2.1b"><mn id="A3.F12.4.m2.1.1" xref="A3.F12.4.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A3.F12.4.m2.1c"><cn type="integer" id="A3.F12.4.m2.1.1.cmml" xref="A3.F12.4.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.F12.4.m2.1d">10</annotation></semantics></math>K rounds without any quantization.</figcaption>
</figure>
<div id="A3.p2" class="ltx_para">
<p id="A3.p2.8" class="ltx_p">While <math id="A3.p2.1.m1.1" class="ltx_Math" alttext="\ell_{\infty}" display="inline"><semantics id="A3.p2.1.m1.1a"><msub id="A3.p2.1.m1.1.1" xref="A3.p2.1.m1.1.1.cmml"><mi mathvariant="normal" id="A3.p2.1.m1.1.1.2" xref="A3.p2.1.m1.1.1.2.cmml">ℓ</mi><mi mathvariant="normal" id="A3.p2.1.m1.1.1.3" xref="A3.p2.1.m1.1.1.3.cmml">∞</mi></msub><annotation-xml encoding="MathML-Content" id="A3.p2.1.m1.1b"><apply id="A3.p2.1.m1.1.1.cmml" xref="A3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="A3.p2.1.m1.1.1.1.cmml" xref="A3.p2.1.m1.1.1">subscript</csymbol><ci id="A3.p2.1.m1.1.1.2.cmml" xref="A3.p2.1.m1.1.1.2">ℓ</ci><infinity id="A3.p2.1.m1.1.1.3.cmml" xref="A3.p2.1.m1.1.1.3"></infinity></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p2.1.m1.1c">\ell_{\infty}</annotation></semantics></math> clipping did make a significant difference in the TernGrad experiment for Transformers and Conformers, performing much better with it than without, it did not have a large effect on the TernGrad performance in the LSTM in Figure <a href="#A3.F12" title="Figure 12 ‣ Appendix C Quantization ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>. TernGrad and its counterpart uniform quantization to <math id="A3.p2.2.m2.1" class="ltx_Math" alttext="\sim 1.585" display="inline"><semantics id="A3.p2.2.m2.1a"><mrow id="A3.p2.2.m2.1.1" xref="A3.p2.2.m2.1.1.cmml"><mi id="A3.p2.2.m2.1.1.2" xref="A3.p2.2.m2.1.1.2.cmml"></mi><mo id="A3.p2.2.m2.1.1.1" xref="A3.p2.2.m2.1.1.1.cmml">∼</mo><mn id="A3.p2.2.m2.1.1.3" xref="A3.p2.2.m2.1.1.3.cmml">1.585</mn></mrow><annotation-xml encoding="MathML-Content" id="A3.p2.2.m2.1b"><apply id="A3.p2.2.m2.1.1.cmml" xref="A3.p2.2.m2.1.1"><csymbol cd="latexml" id="A3.p2.2.m2.1.1.1.cmml" xref="A3.p2.2.m2.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="A3.p2.2.m2.1.1.2.cmml" xref="A3.p2.2.m2.1.1.2">absent</csymbol><cn type="float" id="A3.p2.2.m2.1.1.3.cmml" xref="A3.p2.2.m2.1.1.3">1.585</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p2.2.m2.1c">\sim 1.585</annotation></semantics></math> bits performed the same, as long as <math id="A3.p2.3.m3.1" class="ltx_Math" alttext="\ell_{\infty}" display="inline"><semantics id="A3.p2.3.m3.1a"><msub id="A3.p2.3.m3.1.1" xref="A3.p2.3.m3.1.1.cmml"><mi mathvariant="normal" id="A3.p2.3.m3.1.1.2" xref="A3.p2.3.m3.1.1.2.cmml">ℓ</mi><mi mathvariant="normal" id="A3.p2.3.m3.1.1.3" xref="A3.p2.3.m3.1.1.3.cmml">∞</mi></msub><annotation-xml encoding="MathML-Content" id="A3.p2.3.m3.1b"><apply id="A3.p2.3.m3.1.1.cmml" xref="A3.p2.3.m3.1.1"><csymbol cd="ambiguous" id="A3.p2.3.m3.1.1.1.cmml" xref="A3.p2.3.m3.1.1">subscript</csymbol><ci id="A3.p2.3.m3.1.1.2.cmml" xref="A3.p2.3.m3.1.1.2">ℓ</ci><infinity id="A3.p2.3.m3.1.1.3.cmml" xref="A3.p2.3.m3.1.1.3"></infinity></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p2.3.m3.1c">\ell_{\infty}</annotation></semantics></math> clipping was applied. It is clear from the uniform <math id="A3.p2.4.m4.1" class="ltx_Math" alttext="2" display="inline"><semantics id="A3.p2.4.m4.1a"><mn id="A3.p2.4.m4.1.1" xref="A3.p2.4.m4.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A3.p2.4.m4.1b"><cn type="integer" id="A3.p2.4.m4.1.1.cmml" xref="A3.p2.4.m4.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.p2.4.m4.1c">2</annotation></semantics></math>-bit experiments as well that <math id="A3.p2.5.m5.1" class="ltx_Math" alttext="\ell_{\infty}" display="inline"><semantics id="A3.p2.5.m5.1a"><msub id="A3.p2.5.m5.1.1" xref="A3.p2.5.m5.1.1.cmml"><mi mathvariant="normal" id="A3.p2.5.m5.1.1.2" xref="A3.p2.5.m5.1.1.2.cmml">ℓ</mi><mi mathvariant="normal" id="A3.p2.5.m5.1.1.3" xref="A3.p2.5.m5.1.1.3.cmml">∞</mi></msub><annotation-xml encoding="MathML-Content" id="A3.p2.5.m5.1b"><apply id="A3.p2.5.m5.1.1.cmml" xref="A3.p2.5.m5.1.1"><csymbol cd="ambiguous" id="A3.p2.5.m5.1.1.1.cmml" xref="A3.p2.5.m5.1.1">subscript</csymbol><ci id="A3.p2.5.m5.1.1.2.cmml" xref="A3.p2.5.m5.1.1.2">ℓ</ci><infinity id="A3.p2.5.m5.1.1.3.cmml" xref="A3.p2.5.m5.1.1.3"></infinity></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p2.5.m5.1c">\ell_{\infty}</annotation></semantics></math> clipping is important when quantizing into these lower number of bits; the <math id="A3.p2.6.m6.1" class="ltx_Math" alttext="2" display="inline"><semantics id="A3.p2.6.m6.1a"><mn id="A3.p2.6.m6.1.1" xref="A3.p2.6.m6.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A3.p2.6.m6.1b"><cn type="integer" id="A3.p2.6.m6.1.1.cmml" xref="A3.p2.6.m6.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.p2.6.m6.1c">2</annotation></semantics></math>-bit experiment without clipping performs much worse than the Terngrad without clipping, although enabling clipping allows <math id="A3.p2.7.m7.1" class="ltx_Math" alttext="2" display="inline"><semantics id="A3.p2.7.m7.1a"><mn id="A3.p2.7.m7.1.1" xref="A3.p2.7.m7.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="A3.p2.7.m7.1b"><cn type="integer" id="A3.p2.7.m7.1.1.cmml" xref="A3.p2.7.m7.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.p2.7.m7.1c">2</annotation></semantics></math>-bit to perform slightly better than Terngrad’s <math id="A3.p2.8.m8.2" class="ltx_Math" alttext="\log_{2}(3)" display="inline"><semantics id="A3.p2.8.m8.2a"><mrow id="A3.p2.8.m8.2.2.1" xref="A3.p2.8.m8.2.2.2.cmml"><msub id="A3.p2.8.m8.2.2.1.1" xref="A3.p2.8.m8.2.2.1.1.cmml"><mi id="A3.p2.8.m8.2.2.1.1.2" xref="A3.p2.8.m8.2.2.1.1.2.cmml">log</mi><mn id="A3.p2.8.m8.2.2.1.1.3" xref="A3.p2.8.m8.2.2.1.1.3.cmml">2</mn></msub><mo id="A3.p2.8.m8.2.2.1a" xref="A3.p2.8.m8.2.2.2.cmml">⁡</mo><mrow id="A3.p2.8.m8.2.2.1.2" xref="A3.p2.8.m8.2.2.2.cmml"><mo stretchy="false" id="A3.p2.8.m8.2.2.1.2.1" xref="A3.p2.8.m8.2.2.2.cmml">(</mo><mn id="A3.p2.8.m8.1.1" xref="A3.p2.8.m8.1.1.cmml">3</mn><mo stretchy="false" id="A3.p2.8.m8.2.2.1.2.2" xref="A3.p2.8.m8.2.2.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A3.p2.8.m8.2b"><apply id="A3.p2.8.m8.2.2.2.cmml" xref="A3.p2.8.m8.2.2.1"><apply id="A3.p2.8.m8.2.2.1.1.cmml" xref="A3.p2.8.m8.2.2.1.1"><csymbol cd="ambiguous" id="A3.p2.8.m8.2.2.1.1.1.cmml" xref="A3.p2.8.m8.2.2.1.1">subscript</csymbol><log id="A3.p2.8.m8.2.2.1.1.2.cmml" xref="A3.p2.8.m8.2.2.1.1.2"></log><cn type="integer" id="A3.p2.8.m8.2.2.1.1.3.cmml" xref="A3.p2.8.m8.2.2.1.1.3">2</cn></apply><cn type="integer" id="A3.p2.8.m8.1.1.cmml" xref="A3.p2.8.m8.1.1">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.p2.8.m8.2c">\log_{2}(3)</annotation></semantics></math> bits with clipping. Zero-centering did not seem to affect upload behavior much for either model, marginally improving the LSTM and marginally degrading the Transformer.</p>
</div>
<div id="A3.p3" class="ltx_para">
<p id="A3.p3.1" class="ltx_p">We explore the patterns of communication cost for each experiment setting in Figure <a href="#S4.F5" title="Figure 5 ‣ 4 Cost per round ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. We calculate the approximate download and upload MB for each experiment by multiplying the model’s number of parameters by the number of download or upload bits to get total bits transported.</p>
</div>
<div id="A3.p4" class="ltx_para">
<p id="A3.p4.6" class="ltx_p">Examining Figure <a href="#S4.F5" title="Figure 5 ‣ 4 Cost per round ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we note the baseline points for each set of experiments as the lowest and rightmost, getting the best perplexity but also highest communication cost. Starting from there, we see trends of no perplexity degradation as we apply conservative quantization to the Large LSTM and Transformer and Conformer settings and move left in the plot. We then reach an elbow in the points for each setting right around where the Terngrad point is, from which point perplexity degrades drastically without much communication cost savings as the points head up in two lines as upload quantization is reduced, with one line corresponding to experiments with download <math id="A3.p4.1.m1.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A3.p4.1.m1.1a"><mn id="A3.p4.1.m1.1.1" xref="A3.p4.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A3.p4.1.m1.1b"><cn type="integer" id="A3.p4.1.m1.1.1.cmml" xref="A3.p4.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.p4.1.m1.1c">16</annotation></semantics></math> bits and the other to download <math id="A3.p4.2.m2.1" class="ltx_Math" alttext="12" display="inline"><semantics id="A3.p4.2.m2.1a"><mn id="A3.p4.2.m2.1.1" xref="A3.p4.2.m2.1.1.cmml">12</mn><annotation-xml encoding="MathML-Content" id="A3.p4.2.m2.1b"><cn type="integer" id="A3.p4.2.m2.1.1.cmml" xref="A3.p4.2.m2.1.1">12</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.p4.2.m2.1c">12</annotation></semantics></math> bits. While the Terngrad point for the Large Transformer falls at the outermost point in the "elbow" and therefore gives the best tradeoff for cost versus perplexity, there is one uniform quantization point that does better than the Large LSTM Terngrad, which is download <math id="A3.p4.3.m3.1" class="ltx_Math" alttext="12" display="inline"><semantics id="A3.p4.3.m3.1a"><mn id="A3.p4.3.m3.1.1" xref="A3.p4.3.m3.1.1.cmml">12</mn><annotation-xml encoding="MathML-Content" id="A3.p4.3.m3.1b"><cn type="integer" id="A3.p4.3.m3.1.1.cmml" xref="A3.p4.3.m3.1.1">12</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.p4.3.m3.1c">12</annotation></semantics></math> bits and upload <math id="A3.p4.4.m4.1" class="ltx_Math" alttext="6" display="inline"><semantics id="A3.p4.4.m4.1a"><mn id="A3.p4.4.m4.1.1" xref="A3.p4.4.m4.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="A3.p4.4.m4.1b"><cn type="integer" id="A3.p4.4.m4.1.1.cmml" xref="A3.p4.4.m4.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.p4.4.m4.1c">6</annotation></semantics></math> bits. It makes sense that this does well as we saw that the LSTM was able to use these settings without much regression from the baseline performance, while the Transformer and Conformer could only quantize to <math id="A3.p4.5.m5.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A3.p4.5.m5.1a"><mn id="A3.p4.5.m5.1.1" xref="A3.p4.5.m5.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A3.p4.5.m5.1b"><cn type="integer" id="A3.p4.5.m5.1.1.cmml" xref="A3.p4.5.m5.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.p4.5.m5.1c">16</annotation></semantics></math> download bits and <math id="A3.p4.6.m6.1" class="ltx_Math" alttext="8" display="inline"><semantics id="A3.p4.6.m6.1a"><mn id="A3.p4.6.m6.1.1" xref="A3.p4.6.m6.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A3.p4.6.m6.1b"><cn type="integer" id="A3.p4.6.m6.1.1.cmml" xref="A3.p4.6.m6.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.p4.6.m6.1c">8</annotation></semantics></math> upload bits without regressions.</p>
</div>
</section>
<section id="A4" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Transfer learning</h2>

<figure id="A4.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Selected hyperparameters for each centrally trained model and dataset.
The values in <math id="A4.T5.2.m1.1" class="ltx_Math" alttext="[\ ]" display="inline"><semantics id="A4.T5.2.m1.1b"><mrow id="A4.T5.2.m1.1.1.2"><mo rspace="0.500em" stretchy="false" id="A4.T5.2.m1.1.1.2.1" xref="A4.T5.2.m1.1.1.1.cmml">[</mo><mo stretchy="false" id="A4.T5.2.m1.1.1.2.2" xref="A4.T5.2.m1.1.1.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A4.T5.2.m1.1c"><list id="A4.T5.2.m1.1.1.1.cmml" xref="A4.T5.2.m1.1.1.2.1"></list></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.2.m1.1d">[\ ]</annotation></semantics></math> are the possible hyperparameter values searched over.</figcaption>
<table id="A4.T5.17" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A4.T5.17.16.1" class="ltx_tr">
<th id="A4.T5.17.16.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row">Model</th>
<th id="A4.T5.17.16.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_row">Dataset</th>
<td id="A4.T5.17.16.1.3" class="ltx_td ltx_align_center">Clipnorm</td>
<td id="A4.T5.17.16.1.4" class="ltx_td ltx_align_center">Learning Rate</td>
</tr>
<tr id="A4.T5.4.2" class="ltx_tr">
<th id="A4.T5.4.2.3" class="ltx_td ltx_th ltx_th_row"></th>
<th id="A4.T5.4.2.4" class="ltx_td ltx_th ltx_th_row"></th>
<td id="A4.T5.3.1.1" class="ltx_td ltx_align_center"><math id="A4.T5.3.1.1.m1.2" class="ltx_Math" alttext="[0,16]" display="inline"><semantics id="A4.T5.3.1.1.m1.2a"><mrow id="A4.T5.3.1.1.m1.2.3.2" xref="A4.T5.3.1.1.m1.2.3.1.cmml"><mo stretchy="false" id="A4.T5.3.1.1.m1.2.3.2.1" xref="A4.T5.3.1.1.m1.2.3.1.cmml">[</mo><mn id="A4.T5.3.1.1.m1.1.1" xref="A4.T5.3.1.1.m1.1.1.cmml">0</mn><mo id="A4.T5.3.1.1.m1.2.3.2.2" xref="A4.T5.3.1.1.m1.2.3.1.cmml">,</mo><mn id="A4.T5.3.1.1.m1.2.2" xref="A4.T5.3.1.1.m1.2.2.cmml">16</mn><mo stretchy="false" id="A4.T5.3.1.1.m1.2.3.2.3" xref="A4.T5.3.1.1.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A4.T5.3.1.1.m1.2b"><interval closure="closed" id="A4.T5.3.1.1.m1.2.3.1.cmml" xref="A4.T5.3.1.1.m1.2.3.2"><cn type="integer" id="A4.T5.3.1.1.m1.1.1.cmml" xref="A4.T5.3.1.1.m1.1.1">0</cn><cn type="integer" id="A4.T5.3.1.1.m1.2.2.cmml" xref="A4.T5.3.1.1.m1.2.2">16</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.3.1.1.m1.2c">[0,16]</annotation></semantics></math></td>
<td id="A4.T5.4.2.2" class="ltx_td ltx_align_center"><math id="A4.T5.4.2.2.m1.1" class="ltx_math_unparsed" alttext="[1e^{-5},5e^{-5},1e^{-4}," display="inline"><semantics id="A4.T5.4.2.2.m1.1a"><mrow id="A4.T5.4.2.2.m1.1b"><mo stretchy="false" id="A4.T5.4.2.2.m1.1.1">[</mo><mn id="A4.T5.4.2.2.m1.1.2">1</mn><msup id="A4.T5.4.2.2.m1.1.3"><mi id="A4.T5.4.2.2.m1.1.3.2">e</mi><mrow id="A4.T5.4.2.2.m1.1.3.3"><mo id="A4.T5.4.2.2.m1.1.3.3a">−</mo><mn id="A4.T5.4.2.2.m1.1.3.3.2">5</mn></mrow></msup><mo id="A4.T5.4.2.2.m1.1.4">,</mo><mn id="A4.T5.4.2.2.m1.1.5">5</mn><msup id="A4.T5.4.2.2.m1.1.6"><mi id="A4.T5.4.2.2.m1.1.6.2">e</mi><mrow id="A4.T5.4.2.2.m1.1.6.3"><mo id="A4.T5.4.2.2.m1.1.6.3a">−</mo><mn id="A4.T5.4.2.2.m1.1.6.3.2">5</mn></mrow></msup><mo id="A4.T5.4.2.2.m1.1.7">,</mo><mn id="A4.T5.4.2.2.m1.1.8">1</mn><msup id="A4.T5.4.2.2.m1.1.9"><mi id="A4.T5.4.2.2.m1.1.9.2">e</mi><mrow id="A4.T5.4.2.2.m1.1.9.3"><mo id="A4.T5.4.2.2.m1.1.9.3a">−</mo><mn id="A4.T5.4.2.2.m1.1.9.3.2">4</mn></mrow></msup><mo id="A4.T5.4.2.2.m1.1.10">,</mo></mrow><annotation encoding="application/x-tex" id="A4.T5.4.2.2.m1.1c">[1e^{-5},5e^{-5},1e^{-4},</annotation></semantics></math></td>
</tr>
<tr id="A4.T5.5.3" class="ltx_tr">
<th id="A4.T5.5.3.2" class="ltx_td ltx_th ltx_th_row"></th>
<th id="A4.T5.5.3.3" class="ltx_td ltx_th ltx_th_row"></th>
<td id="A4.T5.5.3.4" class="ltx_td"></td>
<td id="A4.T5.5.3.1" class="ltx_td ltx_align_center"><math id="A4.T5.5.3.1.m1.1" class="ltx_math_unparsed" alttext="5e^{-4},1e^{-3},5e^{-3},1e^{-2}]" display="inline"><semantics id="A4.T5.5.3.1.m1.1a"><mrow id="A4.T5.5.3.1.m1.1b"><mn id="A4.T5.5.3.1.m1.1.1">5</mn><msup id="A4.T5.5.3.1.m1.1.2"><mi id="A4.T5.5.3.1.m1.1.2.2">e</mi><mrow id="A4.T5.5.3.1.m1.1.2.3"><mo id="A4.T5.5.3.1.m1.1.2.3a">−</mo><mn id="A4.T5.5.3.1.m1.1.2.3.2">4</mn></mrow></msup><mo id="A4.T5.5.3.1.m1.1.3">,</mo><mn id="A4.T5.5.3.1.m1.1.4">1</mn><msup id="A4.T5.5.3.1.m1.1.5"><mi id="A4.T5.5.3.1.m1.1.5.2">e</mi><mrow id="A4.T5.5.3.1.m1.1.5.3"><mo id="A4.T5.5.3.1.m1.1.5.3a">−</mo><mn id="A4.T5.5.3.1.m1.1.5.3.2">3</mn></mrow></msup><mo id="A4.T5.5.3.1.m1.1.6">,</mo><mn id="A4.T5.5.3.1.m1.1.7">5</mn><msup id="A4.T5.5.3.1.m1.1.8"><mi id="A4.T5.5.3.1.m1.1.8.2">e</mi><mrow id="A4.T5.5.3.1.m1.1.8.3"><mo id="A4.T5.5.3.1.m1.1.8.3a">−</mo><mn id="A4.T5.5.3.1.m1.1.8.3.2">3</mn></mrow></msup><mo id="A4.T5.5.3.1.m1.1.9">,</mo><mn id="A4.T5.5.3.1.m1.1.10">1</mn><msup id="A4.T5.5.3.1.m1.1.11"><mi id="A4.T5.5.3.1.m1.1.11.2">e</mi><mrow id="A4.T5.5.3.1.m1.1.11.3"><mo id="A4.T5.5.3.1.m1.1.11.3a">−</mo><mn id="A4.T5.5.3.1.m1.1.11.3.2">2</mn></mrow></msup><mo stretchy="false" id="A4.T5.5.3.1.m1.1.12">]</mo></mrow><annotation encoding="application/x-tex" id="A4.T5.5.3.1.m1.1c">5e^{-4},1e^{-3},5e^{-3},1e^{-2}]</annotation></semantics></math></td>
</tr>
<tr id="A4.T5.7.5" class="ltx_tr">
<th id="A4.T5.7.5.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Large LSTM</th>
<th id="A4.T5.7.5.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Book</th>
<td id="A4.T5.6.4.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A4.T5.6.4.1.m1.1" class="ltx_Math" alttext="0.0" display="inline"><semantics id="A4.T5.6.4.1.m1.1a"><mn id="A4.T5.6.4.1.m1.1.1" xref="A4.T5.6.4.1.m1.1.1.cmml">0.0</mn><annotation-xml encoding="MathML-Content" id="A4.T5.6.4.1.m1.1b"><cn type="float" id="A4.T5.6.4.1.m1.1.1.cmml" xref="A4.T5.6.4.1.m1.1.1">0.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.6.4.1.m1.1c">0.0</annotation></semantics></math></td>
<td id="A4.T5.7.5.2" class="ltx_td ltx_align_center ltx_border_t"><math id="A4.T5.7.5.2.m1.1" class="ltx_Math" alttext="5e^{-5}" display="inline"><semantics id="A4.T5.7.5.2.m1.1a"><mrow id="A4.T5.7.5.2.m1.1.1" xref="A4.T5.7.5.2.m1.1.1.cmml"><mn id="A4.T5.7.5.2.m1.1.1.2" xref="A4.T5.7.5.2.m1.1.1.2.cmml">5</mn><mo lspace="0em" rspace="0em" id="A4.T5.7.5.2.m1.1.1.1" xref="A4.T5.7.5.2.m1.1.1.1.cmml">​</mo><msup id="A4.T5.7.5.2.m1.1.1.3" xref="A4.T5.7.5.2.m1.1.1.3.cmml"><mi id="A4.T5.7.5.2.m1.1.1.3.2" xref="A4.T5.7.5.2.m1.1.1.3.2.cmml">e</mi><mrow id="A4.T5.7.5.2.m1.1.1.3.3" xref="A4.T5.7.5.2.m1.1.1.3.3.cmml"><mo id="A4.T5.7.5.2.m1.1.1.3.3a" xref="A4.T5.7.5.2.m1.1.1.3.3.cmml">−</mo><mn id="A4.T5.7.5.2.m1.1.1.3.3.2" xref="A4.T5.7.5.2.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A4.T5.7.5.2.m1.1b"><apply id="A4.T5.7.5.2.m1.1.1.cmml" xref="A4.T5.7.5.2.m1.1.1"><times id="A4.T5.7.5.2.m1.1.1.1.cmml" xref="A4.T5.7.5.2.m1.1.1.1"></times><cn type="integer" id="A4.T5.7.5.2.m1.1.1.2.cmml" xref="A4.T5.7.5.2.m1.1.1.2">5</cn><apply id="A4.T5.7.5.2.m1.1.1.3.cmml" xref="A4.T5.7.5.2.m1.1.1.3"><csymbol cd="ambiguous" id="A4.T5.7.5.2.m1.1.1.3.1.cmml" xref="A4.T5.7.5.2.m1.1.1.3">superscript</csymbol><ci id="A4.T5.7.5.2.m1.1.1.3.2.cmml" xref="A4.T5.7.5.2.m1.1.1.3.2">𝑒</ci><apply id="A4.T5.7.5.2.m1.1.1.3.3.cmml" xref="A4.T5.7.5.2.m1.1.1.3.3"><minus id="A4.T5.7.5.2.m1.1.1.3.3.1.cmml" xref="A4.T5.7.5.2.m1.1.1.3.3"></minus><cn type="integer" id="A4.T5.7.5.2.m1.1.1.3.3.2.cmml" xref="A4.T5.7.5.2.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.7.5.2.m1.1c">5e^{-5}</annotation></semantics></math></td>
</tr>
<tr id="A4.T5.9.7" class="ltx_tr">
<th id="A4.T5.9.7.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Large LSTM</th>
<th id="A4.T5.9.7.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">LM1B</th>
<td id="A4.T5.8.6.1" class="ltx_td ltx_align_center"><math id="A4.T5.8.6.1.m1.1" class="ltx_Math" alttext="0.0" display="inline"><semantics id="A4.T5.8.6.1.m1.1a"><mn id="A4.T5.8.6.1.m1.1.1" xref="A4.T5.8.6.1.m1.1.1.cmml">0.0</mn><annotation-xml encoding="MathML-Content" id="A4.T5.8.6.1.m1.1b"><cn type="float" id="A4.T5.8.6.1.m1.1.1.cmml" xref="A4.T5.8.6.1.m1.1.1">0.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.8.6.1.m1.1c">0.0</annotation></semantics></math></td>
<td id="A4.T5.9.7.2" class="ltx_td ltx_align_center"><math id="A4.T5.9.7.2.m1.1" class="ltx_Math" alttext="5e^{-5}" display="inline"><semantics id="A4.T5.9.7.2.m1.1a"><mrow id="A4.T5.9.7.2.m1.1.1" xref="A4.T5.9.7.2.m1.1.1.cmml"><mn id="A4.T5.9.7.2.m1.1.1.2" xref="A4.T5.9.7.2.m1.1.1.2.cmml">5</mn><mo lspace="0em" rspace="0em" id="A4.T5.9.7.2.m1.1.1.1" xref="A4.T5.9.7.2.m1.1.1.1.cmml">​</mo><msup id="A4.T5.9.7.2.m1.1.1.3" xref="A4.T5.9.7.2.m1.1.1.3.cmml"><mi id="A4.T5.9.7.2.m1.1.1.3.2" xref="A4.T5.9.7.2.m1.1.1.3.2.cmml">e</mi><mrow id="A4.T5.9.7.2.m1.1.1.3.3" xref="A4.T5.9.7.2.m1.1.1.3.3.cmml"><mo id="A4.T5.9.7.2.m1.1.1.3.3a" xref="A4.T5.9.7.2.m1.1.1.3.3.cmml">−</mo><mn id="A4.T5.9.7.2.m1.1.1.3.3.2" xref="A4.T5.9.7.2.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A4.T5.9.7.2.m1.1b"><apply id="A4.T5.9.7.2.m1.1.1.cmml" xref="A4.T5.9.7.2.m1.1.1"><times id="A4.T5.9.7.2.m1.1.1.1.cmml" xref="A4.T5.9.7.2.m1.1.1.1"></times><cn type="integer" id="A4.T5.9.7.2.m1.1.1.2.cmml" xref="A4.T5.9.7.2.m1.1.1.2">5</cn><apply id="A4.T5.9.7.2.m1.1.1.3.cmml" xref="A4.T5.9.7.2.m1.1.1.3"><csymbol cd="ambiguous" id="A4.T5.9.7.2.m1.1.1.3.1.cmml" xref="A4.T5.9.7.2.m1.1.1.3">superscript</csymbol><ci id="A4.T5.9.7.2.m1.1.1.3.2.cmml" xref="A4.T5.9.7.2.m1.1.1.3.2">𝑒</ci><apply id="A4.T5.9.7.2.m1.1.1.3.3.cmml" xref="A4.T5.9.7.2.m1.1.1.3.3"><minus id="A4.T5.9.7.2.m1.1.1.3.3.1.cmml" xref="A4.T5.9.7.2.m1.1.1.3.3"></minus><cn type="integer" id="A4.T5.9.7.2.m1.1.1.3.3.2.cmml" xref="A4.T5.9.7.2.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.9.7.2.m1.1c">5e^{-5}</annotation></semantics></math></td>
</tr>
<tr id="A4.T5.11.9" class="ltx_tr">
<th id="A4.T5.11.9.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Large Transformer</th>
<th id="A4.T5.11.9.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Book</th>
<td id="A4.T5.10.8.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A4.T5.10.8.1.m1.1" class="ltx_Math" alttext="16.0" display="inline"><semantics id="A4.T5.10.8.1.m1.1a"><mn id="A4.T5.10.8.1.m1.1.1" xref="A4.T5.10.8.1.m1.1.1.cmml">16.0</mn><annotation-xml encoding="MathML-Content" id="A4.T5.10.8.1.m1.1b"><cn type="float" id="A4.T5.10.8.1.m1.1.1.cmml" xref="A4.T5.10.8.1.m1.1.1">16.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.10.8.1.m1.1c">16.0</annotation></semantics></math></td>
<td id="A4.T5.11.9.2" class="ltx_td ltx_align_center ltx_border_t"><math id="A4.T5.11.9.2.m1.1" class="ltx_Math" alttext="5e^{-5}" display="inline"><semantics id="A4.T5.11.9.2.m1.1a"><mrow id="A4.T5.11.9.2.m1.1.1" xref="A4.T5.11.9.2.m1.1.1.cmml"><mn id="A4.T5.11.9.2.m1.1.1.2" xref="A4.T5.11.9.2.m1.1.1.2.cmml">5</mn><mo lspace="0em" rspace="0em" id="A4.T5.11.9.2.m1.1.1.1" xref="A4.T5.11.9.2.m1.1.1.1.cmml">​</mo><msup id="A4.T5.11.9.2.m1.1.1.3" xref="A4.T5.11.9.2.m1.1.1.3.cmml"><mi id="A4.T5.11.9.2.m1.1.1.3.2" xref="A4.T5.11.9.2.m1.1.1.3.2.cmml">e</mi><mrow id="A4.T5.11.9.2.m1.1.1.3.3" xref="A4.T5.11.9.2.m1.1.1.3.3.cmml"><mo id="A4.T5.11.9.2.m1.1.1.3.3a" xref="A4.T5.11.9.2.m1.1.1.3.3.cmml">−</mo><mn id="A4.T5.11.9.2.m1.1.1.3.3.2" xref="A4.T5.11.9.2.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A4.T5.11.9.2.m1.1b"><apply id="A4.T5.11.9.2.m1.1.1.cmml" xref="A4.T5.11.9.2.m1.1.1"><times id="A4.T5.11.9.2.m1.1.1.1.cmml" xref="A4.T5.11.9.2.m1.1.1.1"></times><cn type="integer" id="A4.T5.11.9.2.m1.1.1.2.cmml" xref="A4.T5.11.9.2.m1.1.1.2">5</cn><apply id="A4.T5.11.9.2.m1.1.1.3.cmml" xref="A4.T5.11.9.2.m1.1.1.3"><csymbol cd="ambiguous" id="A4.T5.11.9.2.m1.1.1.3.1.cmml" xref="A4.T5.11.9.2.m1.1.1.3">superscript</csymbol><ci id="A4.T5.11.9.2.m1.1.1.3.2.cmml" xref="A4.T5.11.9.2.m1.1.1.3.2">𝑒</ci><apply id="A4.T5.11.9.2.m1.1.1.3.3.cmml" xref="A4.T5.11.9.2.m1.1.1.3.3"><minus id="A4.T5.11.9.2.m1.1.1.3.3.1.cmml" xref="A4.T5.11.9.2.m1.1.1.3.3"></minus><cn type="integer" id="A4.T5.11.9.2.m1.1.1.3.3.2.cmml" xref="A4.T5.11.9.2.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.11.9.2.m1.1c">5e^{-5}</annotation></semantics></math></td>
</tr>
<tr id="A4.T5.13.11" class="ltx_tr">
<th id="A4.T5.13.11.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Large Transformer</th>
<th id="A4.T5.13.11.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">LM1B</th>
<td id="A4.T5.12.10.1" class="ltx_td ltx_align_center"><math id="A4.T5.12.10.1.m1.1" class="ltx_Math" alttext="16.0" display="inline"><semantics id="A4.T5.12.10.1.m1.1a"><mn id="A4.T5.12.10.1.m1.1.1" xref="A4.T5.12.10.1.m1.1.1.cmml">16.0</mn><annotation-xml encoding="MathML-Content" id="A4.T5.12.10.1.m1.1b"><cn type="float" id="A4.T5.12.10.1.m1.1.1.cmml" xref="A4.T5.12.10.1.m1.1.1">16.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.12.10.1.m1.1c">16.0</annotation></semantics></math></td>
<td id="A4.T5.13.11.2" class="ltx_td ltx_align_center"><math id="A4.T5.13.11.2.m1.1" class="ltx_Math" alttext="5e^{-5}" display="inline"><semantics id="A4.T5.13.11.2.m1.1a"><mrow id="A4.T5.13.11.2.m1.1.1" xref="A4.T5.13.11.2.m1.1.1.cmml"><mn id="A4.T5.13.11.2.m1.1.1.2" xref="A4.T5.13.11.2.m1.1.1.2.cmml">5</mn><mo lspace="0em" rspace="0em" id="A4.T5.13.11.2.m1.1.1.1" xref="A4.T5.13.11.2.m1.1.1.1.cmml">​</mo><msup id="A4.T5.13.11.2.m1.1.1.3" xref="A4.T5.13.11.2.m1.1.1.3.cmml"><mi id="A4.T5.13.11.2.m1.1.1.3.2" xref="A4.T5.13.11.2.m1.1.1.3.2.cmml">e</mi><mrow id="A4.T5.13.11.2.m1.1.1.3.3" xref="A4.T5.13.11.2.m1.1.1.3.3.cmml"><mo id="A4.T5.13.11.2.m1.1.1.3.3a" xref="A4.T5.13.11.2.m1.1.1.3.3.cmml">−</mo><mn id="A4.T5.13.11.2.m1.1.1.3.3.2" xref="A4.T5.13.11.2.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A4.T5.13.11.2.m1.1b"><apply id="A4.T5.13.11.2.m1.1.1.cmml" xref="A4.T5.13.11.2.m1.1.1"><times id="A4.T5.13.11.2.m1.1.1.1.cmml" xref="A4.T5.13.11.2.m1.1.1.1"></times><cn type="integer" id="A4.T5.13.11.2.m1.1.1.2.cmml" xref="A4.T5.13.11.2.m1.1.1.2">5</cn><apply id="A4.T5.13.11.2.m1.1.1.3.cmml" xref="A4.T5.13.11.2.m1.1.1.3"><csymbol cd="ambiguous" id="A4.T5.13.11.2.m1.1.1.3.1.cmml" xref="A4.T5.13.11.2.m1.1.1.3">superscript</csymbol><ci id="A4.T5.13.11.2.m1.1.1.3.2.cmml" xref="A4.T5.13.11.2.m1.1.1.3.2">𝑒</ci><apply id="A4.T5.13.11.2.m1.1.1.3.3.cmml" xref="A4.T5.13.11.2.m1.1.1.3.3"><minus id="A4.T5.13.11.2.m1.1.1.3.3.1.cmml" xref="A4.T5.13.11.2.m1.1.1.3.3"></minus><cn type="integer" id="A4.T5.13.11.2.m1.1.1.3.3.2.cmml" xref="A4.T5.13.11.2.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.13.11.2.m1.1c">5e^{-5}</annotation></semantics></math></td>
</tr>
<tr id="A4.T5.15.13" class="ltx_tr">
<th id="A4.T5.15.13.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Large Conformer</th>
<th id="A4.T5.15.13.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Book</th>
<td id="A4.T5.14.12.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A4.T5.14.12.1.m1.1" class="ltx_Math" alttext="0.0" display="inline"><semantics id="A4.T5.14.12.1.m1.1a"><mn id="A4.T5.14.12.1.m1.1.1" xref="A4.T5.14.12.1.m1.1.1.cmml">0.0</mn><annotation-xml encoding="MathML-Content" id="A4.T5.14.12.1.m1.1b"><cn type="float" id="A4.T5.14.12.1.m1.1.1.cmml" xref="A4.T5.14.12.1.m1.1.1">0.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.14.12.1.m1.1c">0.0</annotation></semantics></math></td>
<td id="A4.T5.15.13.2" class="ltx_td ltx_align_center ltx_border_t"><math id="A4.T5.15.13.2.m1.1" class="ltx_Math" alttext="5e^{-5}" display="inline"><semantics id="A4.T5.15.13.2.m1.1a"><mrow id="A4.T5.15.13.2.m1.1.1" xref="A4.T5.15.13.2.m1.1.1.cmml"><mn id="A4.T5.15.13.2.m1.1.1.2" xref="A4.T5.15.13.2.m1.1.1.2.cmml">5</mn><mo lspace="0em" rspace="0em" id="A4.T5.15.13.2.m1.1.1.1" xref="A4.T5.15.13.2.m1.1.1.1.cmml">​</mo><msup id="A4.T5.15.13.2.m1.1.1.3" xref="A4.T5.15.13.2.m1.1.1.3.cmml"><mi id="A4.T5.15.13.2.m1.1.1.3.2" xref="A4.T5.15.13.2.m1.1.1.3.2.cmml">e</mi><mrow id="A4.T5.15.13.2.m1.1.1.3.3" xref="A4.T5.15.13.2.m1.1.1.3.3.cmml"><mo id="A4.T5.15.13.2.m1.1.1.3.3a" xref="A4.T5.15.13.2.m1.1.1.3.3.cmml">−</mo><mn id="A4.T5.15.13.2.m1.1.1.3.3.2" xref="A4.T5.15.13.2.m1.1.1.3.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A4.T5.15.13.2.m1.1b"><apply id="A4.T5.15.13.2.m1.1.1.cmml" xref="A4.T5.15.13.2.m1.1.1"><times id="A4.T5.15.13.2.m1.1.1.1.cmml" xref="A4.T5.15.13.2.m1.1.1.1"></times><cn type="integer" id="A4.T5.15.13.2.m1.1.1.2.cmml" xref="A4.T5.15.13.2.m1.1.1.2">5</cn><apply id="A4.T5.15.13.2.m1.1.1.3.cmml" xref="A4.T5.15.13.2.m1.1.1.3"><csymbol cd="ambiguous" id="A4.T5.15.13.2.m1.1.1.3.1.cmml" xref="A4.T5.15.13.2.m1.1.1.3">superscript</csymbol><ci id="A4.T5.15.13.2.m1.1.1.3.2.cmml" xref="A4.T5.15.13.2.m1.1.1.3.2">𝑒</ci><apply id="A4.T5.15.13.2.m1.1.1.3.3.cmml" xref="A4.T5.15.13.2.m1.1.1.3.3"><minus id="A4.T5.15.13.2.m1.1.1.3.3.1.cmml" xref="A4.T5.15.13.2.m1.1.1.3.3"></minus><cn type="integer" id="A4.T5.15.13.2.m1.1.1.3.3.2.cmml" xref="A4.T5.15.13.2.m1.1.1.3.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.15.13.2.m1.1c">5e^{-5}</annotation></semantics></math></td>
</tr>
<tr id="A4.T5.17.15" class="ltx_tr">
<th id="A4.T5.17.15.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Large Conformer</th>
<th id="A4.T5.17.15.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">LM1B</th>
<td id="A4.T5.16.14.1" class="ltx_td ltx_align_center"><math id="A4.T5.16.14.1.m1.1" class="ltx_Math" alttext="0.0" display="inline"><semantics id="A4.T5.16.14.1.m1.1a"><mn id="A4.T5.16.14.1.m1.1.1" xref="A4.T5.16.14.1.m1.1.1.cmml">0.0</mn><annotation-xml encoding="MathML-Content" id="A4.T5.16.14.1.m1.1b"><cn type="float" id="A4.T5.16.14.1.m1.1.1.cmml" xref="A4.T5.16.14.1.m1.1.1">0.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.16.14.1.m1.1c">0.0</annotation></semantics></math></td>
<td id="A4.T5.17.15.2" class="ltx_td ltx_align_center"><math id="A4.T5.17.15.2.m1.1" class="ltx_Math" alttext="1e^{-4}" display="inline"><semantics id="A4.T5.17.15.2.m1.1a"><mrow id="A4.T5.17.15.2.m1.1.1" xref="A4.T5.17.15.2.m1.1.1.cmml"><mn id="A4.T5.17.15.2.m1.1.1.2" xref="A4.T5.17.15.2.m1.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="A4.T5.17.15.2.m1.1.1.1" xref="A4.T5.17.15.2.m1.1.1.1.cmml">​</mo><msup id="A4.T5.17.15.2.m1.1.1.3" xref="A4.T5.17.15.2.m1.1.1.3.cmml"><mi id="A4.T5.17.15.2.m1.1.1.3.2" xref="A4.T5.17.15.2.m1.1.1.3.2.cmml">e</mi><mrow id="A4.T5.17.15.2.m1.1.1.3.3" xref="A4.T5.17.15.2.m1.1.1.3.3.cmml"><mo id="A4.T5.17.15.2.m1.1.1.3.3a" xref="A4.T5.17.15.2.m1.1.1.3.3.cmml">−</mo><mn id="A4.T5.17.15.2.m1.1.1.3.3.2" xref="A4.T5.17.15.2.m1.1.1.3.3.2.cmml">4</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A4.T5.17.15.2.m1.1b"><apply id="A4.T5.17.15.2.m1.1.1.cmml" xref="A4.T5.17.15.2.m1.1.1"><times id="A4.T5.17.15.2.m1.1.1.1.cmml" xref="A4.T5.17.15.2.m1.1.1.1"></times><cn type="integer" id="A4.T5.17.15.2.m1.1.1.2.cmml" xref="A4.T5.17.15.2.m1.1.1.2">1</cn><apply id="A4.T5.17.15.2.m1.1.1.3.cmml" xref="A4.T5.17.15.2.m1.1.1.3"><csymbol cd="ambiguous" id="A4.T5.17.15.2.m1.1.1.3.1.cmml" xref="A4.T5.17.15.2.m1.1.1.3">superscript</csymbol><ci id="A4.T5.17.15.2.m1.1.1.3.2.cmml" xref="A4.T5.17.15.2.m1.1.1.3.2">𝑒</ci><apply id="A4.T5.17.15.2.m1.1.1.3.3.cmml" xref="A4.T5.17.15.2.m1.1.1.3.3"><minus id="A4.T5.17.15.2.m1.1.1.3.3.1.cmml" xref="A4.T5.17.15.2.m1.1.1.3.3"></minus><cn type="integer" id="A4.T5.17.15.2.m1.1.1.3.3.2.cmml" xref="A4.T5.17.15.2.m1.1.1.3.3.2">4</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T5.17.15.2.m1.1c">1e^{-4}</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
<div id="A4.p1" class="ltx_para">
<p id="A4.p1.7" class="ltx_p">To find the best models pretrained on the Books and LM1B datasets, we train for <math id="A4.p1.1.m1.1" class="ltx_Math" alttext="30" display="inline"><semantics id="A4.p1.1.m1.1a"><mn id="A4.p1.1.m1.1.1" xref="A4.p1.1.m1.1.1.cmml">30</mn><annotation-xml encoding="MathML-Content" id="A4.p1.1.m1.1b"><cn type="integer" id="A4.p1.1.m1.1.1.cmml" xref="A4.p1.1.m1.1.1">30</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.1.m1.1c">30</annotation></semantics></math>M steps of synchronous SGD searching over learning rate and clip norm.
Like our other centrally trained models, the batch size is fixed to <math id="A4.p1.2.m2.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A4.p1.2.m2.1a"><mn id="A4.p1.2.m2.1.1" xref="A4.p1.2.m2.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A4.p1.2.m2.1b"><cn type="integer" id="A4.p1.2.m2.1.1.cmml" xref="A4.p1.2.m2.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.2.m2.1c">16</annotation></semantics></math> and Adam is used with <math id="A4.p1.3.m3.1" class="ltx_Math" alttext="\beta_{1}" display="inline"><semantics id="A4.p1.3.m3.1a"><msub id="A4.p1.3.m3.1.1" xref="A4.p1.3.m3.1.1.cmml"><mi id="A4.p1.3.m3.1.1.2" xref="A4.p1.3.m3.1.1.2.cmml">β</mi><mn id="A4.p1.3.m3.1.1.3" xref="A4.p1.3.m3.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="A4.p1.3.m3.1b"><apply id="A4.p1.3.m3.1.1.cmml" xref="A4.p1.3.m3.1.1"><csymbol cd="ambiguous" id="A4.p1.3.m3.1.1.1.cmml" xref="A4.p1.3.m3.1.1">subscript</csymbol><ci id="A4.p1.3.m3.1.1.2.cmml" xref="A4.p1.3.m3.1.1.2">𝛽</ci><cn type="integer" id="A4.p1.3.m3.1.1.3.cmml" xref="A4.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.3.m3.1c">\beta_{1}</annotation></semantics></math> at <math id="A4.p1.4.m4.1" class="ltx_Math" alttext="0.9" display="inline"><semantics id="A4.p1.4.m4.1a"><mn id="A4.p1.4.m4.1.1" xref="A4.p1.4.m4.1.1.cmml">0.9</mn><annotation-xml encoding="MathML-Content" id="A4.p1.4.m4.1b"><cn type="float" id="A4.p1.4.m4.1.1.cmml" xref="A4.p1.4.m4.1.1">0.9</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.4.m4.1c">0.9</annotation></semantics></math>, <math id="A4.p1.5.m5.1" class="ltx_Math" alttext="\beta_{2}" display="inline"><semantics id="A4.p1.5.m5.1a"><msub id="A4.p1.5.m5.1.1" xref="A4.p1.5.m5.1.1.cmml"><mi id="A4.p1.5.m5.1.1.2" xref="A4.p1.5.m5.1.1.2.cmml">β</mi><mn id="A4.p1.5.m5.1.1.3" xref="A4.p1.5.m5.1.1.3.cmml">2</mn></msub><annotation-xml encoding="MathML-Content" id="A4.p1.5.m5.1b"><apply id="A4.p1.5.m5.1.1.cmml" xref="A4.p1.5.m5.1.1"><csymbol cd="ambiguous" id="A4.p1.5.m5.1.1.1.cmml" xref="A4.p1.5.m5.1.1">subscript</csymbol><ci id="A4.p1.5.m5.1.1.2.cmml" xref="A4.p1.5.m5.1.1.2">𝛽</ci><cn type="integer" id="A4.p1.5.m5.1.1.3.cmml" xref="A4.p1.5.m5.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.5.m5.1c">\beta_{2}</annotation></semantics></math> at <math id="A4.p1.6.m6.1" class="ltx_Math" alttext="0.999" display="inline"><semantics id="A4.p1.6.m6.1a"><mn id="A4.p1.6.m6.1.1" xref="A4.p1.6.m6.1.1.cmml">0.999</mn><annotation-xml encoding="MathML-Content" id="A4.p1.6.m6.1b"><cn type="float" id="A4.p1.6.m6.1.1.cmml" xref="A4.p1.6.m6.1.1">0.999</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.6.m6.1c">0.999</annotation></semantics></math>, and epsilon at <math id="A4.p1.7.m7.1" class="ltx_Math" alttext="1e^{-8}" display="inline"><semantics id="A4.p1.7.m7.1a"><mrow id="A4.p1.7.m7.1.1" xref="A4.p1.7.m7.1.1.cmml"><mn id="A4.p1.7.m7.1.1.2" xref="A4.p1.7.m7.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="A4.p1.7.m7.1.1.1" xref="A4.p1.7.m7.1.1.1.cmml">​</mo><msup id="A4.p1.7.m7.1.1.3" xref="A4.p1.7.m7.1.1.3.cmml"><mi id="A4.p1.7.m7.1.1.3.2" xref="A4.p1.7.m7.1.1.3.2.cmml">e</mi><mrow id="A4.p1.7.m7.1.1.3.3" xref="A4.p1.7.m7.1.1.3.3.cmml"><mo id="A4.p1.7.m7.1.1.3.3a" xref="A4.p1.7.m7.1.1.3.3.cmml">−</mo><mn id="A4.p1.7.m7.1.1.3.3.2" xref="A4.p1.7.m7.1.1.3.3.2.cmml">8</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="A4.p1.7.m7.1b"><apply id="A4.p1.7.m7.1.1.cmml" xref="A4.p1.7.m7.1.1"><times id="A4.p1.7.m7.1.1.1.cmml" xref="A4.p1.7.m7.1.1.1"></times><cn type="integer" id="A4.p1.7.m7.1.1.2.cmml" xref="A4.p1.7.m7.1.1.2">1</cn><apply id="A4.p1.7.m7.1.1.3.cmml" xref="A4.p1.7.m7.1.1.3"><csymbol cd="ambiguous" id="A4.p1.7.m7.1.1.3.1.cmml" xref="A4.p1.7.m7.1.1.3">superscript</csymbol><ci id="A4.p1.7.m7.1.1.3.2.cmml" xref="A4.p1.7.m7.1.1.3.2">𝑒</ci><apply id="A4.p1.7.m7.1.1.3.3.cmml" xref="A4.p1.7.m7.1.1.3.3"><minus id="A4.p1.7.m7.1.1.3.3.1.cmml" xref="A4.p1.7.m7.1.1.3.3"></minus><cn type="integer" id="A4.p1.7.m7.1.1.3.3.2.cmml" xref="A4.p1.7.m7.1.1.3.3.2">8</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.p1.7.m7.1c">1e^{-8}</annotation></semantics></math>.
See Table <a href="#A4.T5" title="Table 5 ‣ Appendix D Transfer learning ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> for the selected hyperparameters.</p>
</div>
<div id="A4.p2" class="ltx_para">
<p id="A4.p2.2" class="ltx_p">Next we warmstart each models with the parameters from the best corresponding pretrained centralized model and train using FedAvg for <math id="A4.p2.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A4.p2.1.m1.1a"><mn id="A4.p2.1.m1.1.1" xref="A4.p2.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A4.p2.1.m1.1b"><cn type="integer" id="A4.p2.1.m1.1.1.cmml" xref="A4.p2.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.p2.1.m1.1c">10</annotation></semantics></math>K rounds.
We sweep over clip norm and client learning rate.
See Table <a href="#A4.T6" title="Table 6 ‣ Appendix D Transfer learning ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> for the selected hyperparameters.
Clip norm is omitted in Table <a href="#A4.T6" title="Table 6 ‣ Appendix D Transfer learning ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, since for all hyperparameter sweeps <math id="A4.p2.2.m2.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A4.p2.2.m2.1a"><mn id="A4.p2.2.m2.1.1" xref="A4.p2.2.m2.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A4.p2.2.m2.1b"><cn type="integer" id="A4.p2.2.m2.1.1.cmml" xref="A4.p2.2.m2.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.p2.2.m2.1c">16</annotation></semantics></math> was the best value. The Book dataset outperforms the LM1B dataset in all model architectures across LSTM, Transformer, and Conformer. Investigating the difference between the two datasets and their similarities to the Stackoverflow dataset to determine why Books always outperformed LM1B remains an interesting open question.</p>
</div>
<figure id="A4.T6" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Test set metrics after <math id="A4.T6.4.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A4.T6.4.m1.1b"><mn id="A4.T6.4.m1.1.1" xref="A4.T6.4.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A4.T6.4.m1.1c"><cn type="integer" id="A4.T6.4.m1.1.1.cmml" xref="A4.T6.4.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.4.m1.1d">10</annotation></semantics></math>K communication rounds of training with <math id="A4.T6.5.m2.1" class="ltx_Math" alttext="800" display="inline"><semantics id="A4.T6.5.m2.1b"><mn id="A4.T6.5.m2.1.1" xref="A4.T6.5.m2.1.1.cmml">800</mn><annotation-xml encoding="MathML-Content" id="A4.T6.5.m2.1c"><cn type="integer" id="A4.T6.5.m2.1.1.cmml" xref="A4.T6.5.m2.1.1">800</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.5.m2.1d">800</annotation></semantics></math> clients per round for each class of model and pretrain dataset. The client learning rate listed is the best performing learning rate found from a hyperparameter sweep. Reported <math id="A4.T6.6.m3.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="A4.T6.6.m3.1b"><mi mathvariant="normal" id="A4.T6.6.m3.1.1" xref="A4.T6.6.m3.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A4.T6.6.m3.1c"><ci id="A4.T6.6.m3.1.1.cmml" xref="A4.T6.6.m3.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.6.m3.1d">\Delta</annotation></semantics></math> metrics are the change in quality relative to Table <a href="#A1.T2" title="Table 2 ‣ Appendix A Dataset and models ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</figcaption>
<table id="A4.T6.19" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A4.T6.7.1" class="ltx_tr">
<th id="A4.T6.7.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row">Model</th>
<th id="A4.T6.7.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row">Dataset</th>
<th id="A4.T6.7.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column"> Client Learning Rate</th>
<th id="A4.T6.7.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column">
<math id="A4.T6.7.1.1.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="A4.T6.7.1.1.m1.1a"><mi mathvariant="normal" id="A4.T6.7.1.1.m1.1.1" xref="A4.T6.7.1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A4.T6.7.1.1.m1.1b"><ci id="A4.T6.7.1.1.m1.1.1.cmml" xref="A4.T6.7.1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.7.1.1.m1.1c">\Delta</annotation></semantics></math> Perplexity</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A4.T6.19.14.1" class="ltx_tr">
<th id="A4.T6.19.14.1.1" class="ltx_td ltx_th ltx_th_row"></th>
<th id="A4.T6.19.14.1.2" class="ltx_td ltx_th ltx_th_column ltx_th_row"></th>
<th id="A4.T6.19.14.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">[0.01, 0.1, 0.5, 1.0, 2.0]</th>
<td id="A4.T6.19.14.1.4" class="ltx_td"></td>
</tr>
<tr id="A4.T6.9.3" class="ltx_tr">
<th id="A4.T6.9.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Large LSTM</th>
<th id="A4.T6.9.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Book</th>
<td id="A4.T6.8.2.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A4.T6.8.2.1.m1.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="A4.T6.8.2.1.m1.1a"><mn id="A4.T6.8.2.1.m1.1.1" xref="A4.T6.8.2.1.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="A4.T6.8.2.1.m1.1b"><cn type="float" id="A4.T6.8.2.1.m1.1.1.cmml" xref="A4.T6.8.2.1.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.8.2.1.m1.1c">0.5</annotation></semantics></math></td>
<td id="A4.T6.9.3.2" class="ltx_td ltx_align_center ltx_border_t"><math id="A4.T6.9.3.2.m1.1" class="ltx_Math" alttext="0.76" display="inline"><semantics id="A4.T6.9.3.2.m1.1a"><mn id="A4.T6.9.3.2.m1.1.1" xref="A4.T6.9.3.2.m1.1.1.cmml">0.76</mn><annotation-xml encoding="MathML-Content" id="A4.T6.9.3.2.m1.1b"><cn type="float" id="A4.T6.9.3.2.m1.1.1.cmml" xref="A4.T6.9.3.2.m1.1.1">0.76</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.9.3.2.m1.1c">0.76</annotation></semantics></math></td>
</tr>
<tr id="A4.T6.11.5" class="ltx_tr">
<th id="A4.T6.11.5.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Large LSTM</th>
<th id="A4.T6.11.5.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">LM1B</th>
<td id="A4.T6.10.4.1" class="ltx_td ltx_align_center"><math id="A4.T6.10.4.1.m1.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="A4.T6.10.4.1.m1.1a"><mn id="A4.T6.10.4.1.m1.1.1" xref="A4.T6.10.4.1.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="A4.T6.10.4.1.m1.1b"><cn type="float" id="A4.T6.10.4.1.m1.1.1.cmml" xref="A4.T6.10.4.1.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.10.4.1.m1.1c">0.5</annotation></semantics></math></td>
<td id="A4.T6.11.5.2" class="ltx_td ltx_align_center"><math id="A4.T6.11.5.2.m1.1" class="ltx_Math" alttext="1.05" display="inline"><semantics id="A4.T6.11.5.2.m1.1a"><mn id="A4.T6.11.5.2.m1.1.1" xref="A4.T6.11.5.2.m1.1.1.cmml">1.05</mn><annotation-xml encoding="MathML-Content" id="A4.T6.11.5.2.m1.1b"><cn type="float" id="A4.T6.11.5.2.m1.1.1.cmml" xref="A4.T6.11.5.2.m1.1.1">1.05</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.11.5.2.m1.1c">1.05</annotation></semantics></math></td>
</tr>
<tr id="A4.T6.13.7" class="ltx_tr">
<th id="A4.T6.13.7.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Large Transformer</th>
<th id="A4.T6.13.7.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Book</th>
<td id="A4.T6.12.6.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A4.T6.12.6.1.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="A4.T6.12.6.1.m1.1a"><mn id="A4.T6.12.6.1.m1.1.1" xref="A4.T6.12.6.1.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A4.T6.12.6.1.m1.1b"><cn type="float" id="A4.T6.12.6.1.m1.1.1.cmml" xref="A4.T6.12.6.1.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.12.6.1.m1.1c">0.1</annotation></semantics></math></td>
<td id="A4.T6.13.7.2" class="ltx_td ltx_align_center ltx_border_t"><math id="A4.T6.13.7.2.m1.1" class="ltx_Math" alttext="\mathbf{-0.43}" display="inline"><semantics id="A4.T6.13.7.2.m1.1a"><mrow id="A4.T6.13.7.2.m1.1.1" xref="A4.T6.13.7.2.m1.1.1.cmml"><mo id="A4.T6.13.7.2.m1.1.1a" xref="A4.T6.13.7.2.m1.1.1.cmml">−</mo><mn class="ltx_mathvariant_bold" mathvariant="bold" id="A4.T6.13.7.2.m1.1.1.2" xref="A4.T6.13.7.2.m1.1.1.2.cmml">0.43</mn></mrow><annotation-xml encoding="MathML-Content" id="A4.T6.13.7.2.m1.1b"><apply id="A4.T6.13.7.2.m1.1.1.cmml" xref="A4.T6.13.7.2.m1.1.1"><minus id="A4.T6.13.7.2.m1.1.1.1.cmml" xref="A4.T6.13.7.2.m1.1.1"></minus><cn type="float" id="A4.T6.13.7.2.m1.1.1.2.cmml" xref="A4.T6.13.7.2.m1.1.1.2">0.43</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.13.7.2.m1.1c">\mathbf{-0.43}</annotation></semantics></math></td>
</tr>
<tr id="A4.T6.15.9" class="ltx_tr">
<th id="A4.T6.15.9.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Large Transformer</th>
<th id="A4.T6.15.9.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">LM1B</th>
<td id="A4.T6.14.8.1" class="ltx_td ltx_align_center"><math id="A4.T6.14.8.1.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="A4.T6.14.8.1.m1.1a"><mn id="A4.T6.14.8.1.m1.1.1" xref="A4.T6.14.8.1.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A4.T6.14.8.1.m1.1b"><cn type="float" id="A4.T6.14.8.1.m1.1.1.cmml" xref="A4.T6.14.8.1.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.14.8.1.m1.1c">0.1</annotation></semantics></math></td>
<td id="A4.T6.15.9.2" class="ltx_td ltx_align_center"><math id="A4.T6.15.9.2.m1.1" class="ltx_Math" alttext="\mathbf{-0.32}" display="inline"><semantics id="A4.T6.15.9.2.m1.1a"><mrow id="A4.T6.15.9.2.m1.1.1" xref="A4.T6.15.9.2.m1.1.1.cmml"><mo id="A4.T6.15.9.2.m1.1.1a" xref="A4.T6.15.9.2.m1.1.1.cmml">−</mo><mn class="ltx_mathvariant_bold" mathvariant="bold" id="A4.T6.15.9.2.m1.1.1.2" xref="A4.T6.15.9.2.m1.1.1.2.cmml">0.32</mn></mrow><annotation-xml encoding="MathML-Content" id="A4.T6.15.9.2.m1.1b"><apply id="A4.T6.15.9.2.m1.1.1.cmml" xref="A4.T6.15.9.2.m1.1.1"><minus id="A4.T6.15.9.2.m1.1.1.1.cmml" xref="A4.T6.15.9.2.m1.1.1"></minus><cn type="float" id="A4.T6.15.9.2.m1.1.1.2.cmml" xref="A4.T6.15.9.2.m1.1.1.2">0.32</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.15.9.2.m1.1c">\mathbf{-0.32}</annotation></semantics></math></td>
</tr>
<tr id="A4.T6.17.11" class="ltx_tr">
<th id="A4.T6.17.11.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Large Conformer</th>
<th id="A4.T6.17.11.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_t">Book</th>
<td id="A4.T6.16.10.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A4.T6.16.10.1.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="A4.T6.16.10.1.m1.1a"><mn id="A4.T6.16.10.1.m1.1.1" xref="A4.T6.16.10.1.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A4.T6.16.10.1.m1.1b"><cn type="float" id="A4.T6.16.10.1.m1.1.1.cmml" xref="A4.T6.16.10.1.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.16.10.1.m1.1c">0.1</annotation></semantics></math></td>
<td id="A4.T6.17.11.2" class="ltx_td ltx_align_center ltx_border_t"><math id="A4.T6.17.11.2.m1.1" class="ltx_Math" alttext="\mathbf{-0.38}" display="inline"><semantics id="A4.T6.17.11.2.m1.1a"><mrow id="A4.T6.17.11.2.m1.1.1" xref="A4.T6.17.11.2.m1.1.1.cmml"><mo id="A4.T6.17.11.2.m1.1.1a" xref="A4.T6.17.11.2.m1.1.1.cmml">−</mo><mn class="ltx_mathvariant_bold" mathvariant="bold" id="A4.T6.17.11.2.m1.1.1.2" xref="A4.T6.17.11.2.m1.1.1.2.cmml">0.38</mn></mrow><annotation-xml encoding="MathML-Content" id="A4.T6.17.11.2.m1.1b"><apply id="A4.T6.17.11.2.m1.1.1.cmml" xref="A4.T6.17.11.2.m1.1.1"><minus id="A4.T6.17.11.2.m1.1.1.1.cmml" xref="A4.T6.17.11.2.m1.1.1"></minus><cn type="float" id="A4.T6.17.11.2.m1.1.1.2.cmml" xref="A4.T6.17.11.2.m1.1.1.2">0.38</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.17.11.2.m1.1c">\mathbf{-0.38}</annotation></semantics></math></td>
</tr>
<tr id="A4.T6.19.13" class="ltx_tr">
<th id="A4.T6.19.13.3" class="ltx_td ltx_align_center ltx_th ltx_th_row">Large Conformer</th>
<th id="A4.T6.19.13.4" class="ltx_td ltx_align_center ltx_th ltx_th_row">LM1B</th>
<td id="A4.T6.18.12.1" class="ltx_td ltx_align_center"><math id="A4.T6.18.12.1.m1.1" class="ltx_Math" alttext="0.1" display="inline"><semantics id="A4.T6.18.12.1.m1.1a"><mn id="A4.T6.18.12.1.m1.1.1" xref="A4.T6.18.12.1.m1.1.1.cmml">0.1</mn><annotation-xml encoding="MathML-Content" id="A4.T6.18.12.1.m1.1b"><cn type="float" id="A4.T6.18.12.1.m1.1.1.cmml" xref="A4.T6.18.12.1.m1.1.1">0.1</cn></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.18.12.1.m1.1c">0.1</annotation></semantics></math></td>
<td id="A4.T6.19.13.2" class="ltx_td ltx_align_center"><math id="A4.T6.19.13.2.m1.1" class="ltx_Math" alttext="\mathbf{-0.23}" display="inline"><semantics id="A4.T6.19.13.2.m1.1a"><mrow id="A4.T6.19.13.2.m1.1.1" xref="A4.T6.19.13.2.m1.1.1.cmml"><mo id="A4.T6.19.13.2.m1.1.1a" xref="A4.T6.19.13.2.m1.1.1.cmml">−</mo><mn class="ltx_mathvariant_bold" mathvariant="bold" id="A4.T6.19.13.2.m1.1.1.2" xref="A4.T6.19.13.2.m1.1.1.2.cmml">0.23</mn></mrow><annotation-xml encoding="MathML-Content" id="A4.T6.19.13.2.m1.1b"><apply id="A4.T6.19.13.2.m1.1.1.cmml" xref="A4.T6.19.13.2.m1.1.1"><minus id="A4.T6.19.13.2.m1.1.1.1.cmml" xref="A4.T6.19.13.2.m1.1.1"></minus><cn type="float" id="A4.T6.19.13.2.m1.1.1.2.cmml" xref="A4.T6.19.13.2.m1.1.1.2">0.23</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A4.T6.19.13.2.m1.1c">\mathbf{-0.23}</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="A5" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Different optimizers</h2>

<figure id="A5.T7" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Test perplexity after <math id="A5.T7.2.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A5.T7.2.m1.1b"><mn id="A5.T7.2.m1.1.1" xref="A5.T7.2.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A5.T7.2.m1.1c"><cn type="integer" id="A5.T7.2.m1.1.1.cmml" xref="A5.T7.2.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.2.m1.1d">10</annotation></semantics></math>K communication rounds of training for each class of model and federated algorithm.</figcaption>
<table id="A5.T7.11" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A5.T7.11.10.1" class="ltx_tr">
<th id="A5.T7.11.10.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column">Model</th>
<th id="A5.T7.11.10.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">Algorithm</th>
<th id="A5.T7.11.10.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">Perplexity</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A5.T7.3.1" class="ltx_tr">
<td id="A5.T7.3.1.2" class="ltx_td ltx_align_center ltx_border_t">Large LSTM</td>
<td id="A5.T7.3.1.3" class="ltx_td ltx_align_center ltx_border_t">FedAvg</td>
<td id="A5.T7.3.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A5.T7.3.1.1.m1.1" class="ltx_Math" alttext="30.83" display="inline"><semantics id="A5.T7.3.1.1.m1.1a"><mn id="A5.T7.3.1.1.m1.1.1" xref="A5.T7.3.1.1.m1.1.1.cmml">30.83</mn><annotation-xml encoding="MathML-Content" id="A5.T7.3.1.1.m1.1b"><cn type="float" id="A5.T7.3.1.1.m1.1.1.cmml" xref="A5.T7.3.1.1.m1.1.1">30.83</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.3.1.1.m1.1c">30.83</annotation></semantics></math></td>
</tr>
<tr id="A5.T7.4.2" class="ltx_tr">
<td id="A5.T7.4.2.2" class="ltx_td ltx_align_center">Large LSTM</td>
<td id="A5.T7.4.2.3" class="ltx_td ltx_align_center">MimeLite</td>
<td id="A5.T7.4.2.1" class="ltx_td ltx_align_center"><math id="A5.T7.4.2.1.m1.1" class="ltx_Math" alttext="31.00" display="inline"><semantics id="A5.T7.4.2.1.m1.1a"><mn id="A5.T7.4.2.1.m1.1.1" xref="A5.T7.4.2.1.m1.1.1.cmml">31.00</mn><annotation-xml encoding="MathML-Content" id="A5.T7.4.2.1.m1.1b"><cn type="float" id="A5.T7.4.2.1.m1.1.1.cmml" xref="A5.T7.4.2.1.m1.1.1">31.00</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.4.2.1.m1.1c">31.00</annotation></semantics></math></td>
</tr>
<tr id="A5.T7.5.3" class="ltx_tr">
<td id="A5.T7.5.3.2" class="ltx_td ltx_align_center">Large LSTM</td>
<td id="A5.T7.5.3.3" class="ltx_td ltx_align_center">FedProx</td>
<td id="A5.T7.5.3.1" class="ltx_td ltx_align_center"><math id="A5.T7.5.3.1.m1.1" class="ltx_Math" alttext="30.76" display="inline"><semantics id="A5.T7.5.3.1.m1.1a"><mn id="A5.T7.5.3.1.m1.1.1" xref="A5.T7.5.3.1.m1.1.1.cmml">30.76</mn><annotation-xml encoding="MathML-Content" id="A5.T7.5.3.1.m1.1b"><cn type="float" id="A5.T7.5.3.1.m1.1.1.cmml" xref="A5.T7.5.3.1.m1.1.1">30.76</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.5.3.1.m1.1c">30.76</annotation></semantics></math></td>
</tr>
<tr id="A5.T7.6.4" class="ltx_tr">
<td id="A5.T7.6.4.2" class="ltx_td ltx_align_center ltx_border_t">Large Transformer</td>
<td id="A5.T7.6.4.3" class="ltx_td ltx_align_center ltx_border_t">FedAvg</td>
<td id="A5.T7.6.4.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A5.T7.6.4.1.m1.1" class="ltx_Math" alttext="29.15" display="inline"><semantics id="A5.T7.6.4.1.m1.1a"><mn id="A5.T7.6.4.1.m1.1.1" xref="A5.T7.6.4.1.m1.1.1.cmml">29.15</mn><annotation-xml encoding="MathML-Content" id="A5.T7.6.4.1.m1.1b"><cn type="float" id="A5.T7.6.4.1.m1.1.1.cmml" xref="A5.T7.6.4.1.m1.1.1">29.15</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.6.4.1.m1.1c">29.15</annotation></semantics></math></td>
</tr>
<tr id="A5.T7.7.5" class="ltx_tr">
<td id="A5.T7.7.5.2" class="ltx_td ltx_align_center">Large Transformer</td>
<td id="A5.T7.7.5.3" class="ltx_td ltx_align_center">MimeLite</td>
<td id="A5.T7.7.5.1" class="ltx_td ltx_align_center"><math id="A5.T7.7.5.1.m1.1" class="ltx_Math" alttext="30.39" display="inline"><semantics id="A5.T7.7.5.1.m1.1a"><mn id="A5.T7.7.5.1.m1.1.1" xref="A5.T7.7.5.1.m1.1.1.cmml">30.39</mn><annotation-xml encoding="MathML-Content" id="A5.T7.7.5.1.m1.1b"><cn type="float" id="A5.T7.7.5.1.m1.1.1.cmml" xref="A5.T7.7.5.1.m1.1.1">30.39</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.7.5.1.m1.1c">30.39</annotation></semantics></math></td>
</tr>
<tr id="A5.T7.8.6" class="ltx_tr">
<td id="A5.T7.8.6.2" class="ltx_td ltx_align_center">Large Transformer</td>
<td id="A5.T7.8.6.3" class="ltx_td ltx_align_center">FedProx</td>
<td id="A5.T7.8.6.1" class="ltx_td ltx_align_center"><math id="A5.T7.8.6.1.m1.1" class="ltx_Math" alttext="29.04" display="inline"><semantics id="A5.T7.8.6.1.m1.1a"><mn id="A5.T7.8.6.1.m1.1.1" xref="A5.T7.8.6.1.m1.1.1.cmml">29.04</mn><annotation-xml encoding="MathML-Content" id="A5.T7.8.6.1.m1.1b"><cn type="float" id="A5.T7.8.6.1.m1.1.1.cmml" xref="A5.T7.8.6.1.m1.1.1">29.04</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.8.6.1.m1.1c">29.04</annotation></semantics></math></td>
</tr>
<tr id="A5.T7.9.7" class="ltx_tr">
<td id="A5.T7.9.7.2" class="ltx_td ltx_align_center ltx_border_t">Large Conformer</td>
<td id="A5.T7.9.7.3" class="ltx_td ltx_align_center ltx_border_t">FedAvg</td>
<td id="A5.T7.9.7.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A5.T7.9.7.1.m1.1" class="ltx_Math" alttext="29.03" display="inline"><semantics id="A5.T7.9.7.1.m1.1a"><mn id="A5.T7.9.7.1.m1.1.1" xref="A5.T7.9.7.1.m1.1.1.cmml">29.03</mn><annotation-xml encoding="MathML-Content" id="A5.T7.9.7.1.m1.1b"><cn type="float" id="A5.T7.9.7.1.m1.1.1.cmml" xref="A5.T7.9.7.1.m1.1.1">29.03</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.9.7.1.m1.1c">29.03</annotation></semantics></math></td>
</tr>
<tr id="A5.T7.10.8" class="ltx_tr">
<td id="A5.T7.10.8.2" class="ltx_td ltx_align_center">Large Conformer</td>
<td id="A5.T7.10.8.3" class="ltx_td ltx_align_center">MimeLite</td>
<td id="A5.T7.10.8.1" class="ltx_td ltx_align_center"><math id="A5.T7.10.8.1.m1.1" class="ltx_Math" alttext="30.41" display="inline"><semantics id="A5.T7.10.8.1.m1.1a"><mn id="A5.T7.10.8.1.m1.1.1" xref="A5.T7.10.8.1.m1.1.1.cmml">30.41</mn><annotation-xml encoding="MathML-Content" id="A5.T7.10.8.1.m1.1b"><cn type="float" id="A5.T7.10.8.1.m1.1.1.cmml" xref="A5.T7.10.8.1.m1.1.1">30.41</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.10.8.1.m1.1c">30.41</annotation></semantics></math></td>
</tr>
<tr id="A5.T7.11.9" class="ltx_tr">
<td id="A5.T7.11.9.2" class="ltx_td ltx_align_center">Large Conformer</td>
<td id="A5.T7.11.9.3" class="ltx_td ltx_align_center">FedProx</td>
<td id="A5.T7.11.9.1" class="ltx_td ltx_align_center"><math id="A5.T7.11.9.1.m1.1" class="ltx_Math" alttext="28.93" display="inline"><semantics id="A5.T7.11.9.1.m1.1a"><mn id="A5.T7.11.9.1.m1.1.1" xref="A5.T7.11.9.1.m1.1.1.cmml">28.93</mn><annotation-xml encoding="MathML-Content" id="A5.T7.11.9.1.m1.1b"><cn type="float" id="A5.T7.11.9.1.m1.1.1.cmml" xref="A5.T7.11.9.1.m1.1.1">28.93</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.T7.11.9.1.m1.1c">28.93</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
<div id="A5.p1" class="ltx_para">
<p id="A5.p1.5" class="ltx_p">In an effort to improve communication efficiency of the larger language models, we examine two communication-efficient federated algorithms: MimeLite and FedProx.
By comparing the speed and point of convergence of these algorithms in number of rounds, we can determine if the overall communication cost of training can be decreased.
As before, we fix the model architectures for each class of model and conduct a basic search over learning hyperparameters using the same common search space as Table <a href="#A1.T3" title="Table 3 ‣ Appendix A Dataset and models ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> with the addition of the following algorithm specific hyperparameter sweeps.
For MimeLite, we use Adagrad <cite class="ltx_cite ltx_citemacro_citep">[Duchi et al., <a href="#bib.bib13" title="" class="ltx_ref">2011</a>]</cite> for the base optimizer as this setup was shown to perform the best by <cite class="ltx_cite ltx_citemacro_citet">Karimireddy et al. [<a href="#bib.bib27" title="" class="ltx_ref">2020</a>]</cite> for Stack Overflow.
For the MimeLite Adagrad base optimizer, we sweep over base learning rates of <math id="A5.p1.1.m1.5" class="ltx_Math" alttext="[0.01,0.03,0.1,0.3,1.0]" display="inline"><semantics id="A5.p1.1.m1.5a"><mrow id="A5.p1.1.m1.5.6.2" xref="A5.p1.1.m1.5.6.1.cmml"><mo stretchy="false" id="A5.p1.1.m1.5.6.2.1" xref="A5.p1.1.m1.5.6.1.cmml">[</mo><mn id="A5.p1.1.m1.1.1" xref="A5.p1.1.m1.1.1.cmml">0.01</mn><mo id="A5.p1.1.m1.5.6.2.2" xref="A5.p1.1.m1.5.6.1.cmml">,</mo><mn id="A5.p1.1.m1.2.2" xref="A5.p1.1.m1.2.2.cmml">0.03</mn><mo id="A5.p1.1.m1.5.6.2.3" xref="A5.p1.1.m1.5.6.1.cmml">,</mo><mn id="A5.p1.1.m1.3.3" xref="A5.p1.1.m1.3.3.cmml">0.1</mn><mo id="A5.p1.1.m1.5.6.2.4" xref="A5.p1.1.m1.5.6.1.cmml">,</mo><mn id="A5.p1.1.m1.4.4" xref="A5.p1.1.m1.4.4.cmml">0.3</mn><mo id="A5.p1.1.m1.5.6.2.5" xref="A5.p1.1.m1.5.6.1.cmml">,</mo><mn id="A5.p1.1.m1.5.5" xref="A5.p1.1.m1.5.5.cmml">1.0</mn><mo stretchy="false" id="A5.p1.1.m1.5.6.2.6" xref="A5.p1.1.m1.5.6.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A5.p1.1.m1.5b"><list id="A5.p1.1.m1.5.6.1.cmml" xref="A5.p1.1.m1.5.6.2"><cn type="float" id="A5.p1.1.m1.1.1.cmml" xref="A5.p1.1.m1.1.1">0.01</cn><cn type="float" id="A5.p1.1.m1.2.2.cmml" xref="A5.p1.1.m1.2.2">0.03</cn><cn type="float" id="A5.p1.1.m1.3.3.cmml" xref="A5.p1.1.m1.3.3">0.1</cn><cn type="float" id="A5.p1.1.m1.4.4.cmml" xref="A5.p1.1.m1.4.4">0.3</cn><cn type="float" id="A5.p1.1.m1.5.5.cmml" xref="A5.p1.1.m1.5.5">1.0</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A5.p1.1.m1.5c">[0.01,0.03,0.1,0.3,1.0]</annotation></semantics></math> and epsilons of <math id="A5.p1.2.m2.4" class="ltx_Math" alttext="[1e^{-1},1e^{-3},1e^{-5},1e^{-7}]" display="inline"><semantics id="A5.p1.2.m2.4a"><mrow id="A5.p1.2.m2.4.4.4" xref="A5.p1.2.m2.4.4.5.cmml"><mo stretchy="false" id="A5.p1.2.m2.4.4.4.5" xref="A5.p1.2.m2.4.4.5.cmml">[</mo><mrow id="A5.p1.2.m2.1.1.1.1" xref="A5.p1.2.m2.1.1.1.1.cmml"><mn id="A5.p1.2.m2.1.1.1.1.2" xref="A5.p1.2.m2.1.1.1.1.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="A5.p1.2.m2.1.1.1.1.1" xref="A5.p1.2.m2.1.1.1.1.1.cmml">​</mo><msup id="A5.p1.2.m2.1.1.1.1.3" xref="A5.p1.2.m2.1.1.1.1.3.cmml"><mi id="A5.p1.2.m2.1.1.1.1.3.2" xref="A5.p1.2.m2.1.1.1.1.3.2.cmml">e</mi><mrow id="A5.p1.2.m2.1.1.1.1.3.3" xref="A5.p1.2.m2.1.1.1.1.3.3.cmml"><mo id="A5.p1.2.m2.1.1.1.1.3.3a" xref="A5.p1.2.m2.1.1.1.1.3.3.cmml">−</mo><mn id="A5.p1.2.m2.1.1.1.1.3.3.2" xref="A5.p1.2.m2.1.1.1.1.3.3.2.cmml">1</mn></mrow></msup></mrow><mo id="A5.p1.2.m2.4.4.4.6" xref="A5.p1.2.m2.4.4.5.cmml">,</mo><mrow id="A5.p1.2.m2.2.2.2.2" xref="A5.p1.2.m2.2.2.2.2.cmml"><mn id="A5.p1.2.m2.2.2.2.2.2" xref="A5.p1.2.m2.2.2.2.2.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="A5.p1.2.m2.2.2.2.2.1" xref="A5.p1.2.m2.2.2.2.2.1.cmml">​</mo><msup id="A5.p1.2.m2.2.2.2.2.3" xref="A5.p1.2.m2.2.2.2.2.3.cmml"><mi id="A5.p1.2.m2.2.2.2.2.3.2" xref="A5.p1.2.m2.2.2.2.2.3.2.cmml">e</mi><mrow id="A5.p1.2.m2.2.2.2.2.3.3" xref="A5.p1.2.m2.2.2.2.2.3.3.cmml"><mo id="A5.p1.2.m2.2.2.2.2.3.3a" xref="A5.p1.2.m2.2.2.2.2.3.3.cmml">−</mo><mn id="A5.p1.2.m2.2.2.2.2.3.3.2" xref="A5.p1.2.m2.2.2.2.2.3.3.2.cmml">3</mn></mrow></msup></mrow><mo id="A5.p1.2.m2.4.4.4.7" xref="A5.p1.2.m2.4.4.5.cmml">,</mo><mrow id="A5.p1.2.m2.3.3.3.3" xref="A5.p1.2.m2.3.3.3.3.cmml"><mn id="A5.p1.2.m2.3.3.3.3.2" xref="A5.p1.2.m2.3.3.3.3.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="A5.p1.2.m2.3.3.3.3.1" xref="A5.p1.2.m2.3.3.3.3.1.cmml">​</mo><msup id="A5.p1.2.m2.3.3.3.3.3" xref="A5.p1.2.m2.3.3.3.3.3.cmml"><mi id="A5.p1.2.m2.3.3.3.3.3.2" xref="A5.p1.2.m2.3.3.3.3.3.2.cmml">e</mi><mrow id="A5.p1.2.m2.3.3.3.3.3.3" xref="A5.p1.2.m2.3.3.3.3.3.3.cmml"><mo id="A5.p1.2.m2.3.3.3.3.3.3a" xref="A5.p1.2.m2.3.3.3.3.3.3.cmml">−</mo><mn id="A5.p1.2.m2.3.3.3.3.3.3.2" xref="A5.p1.2.m2.3.3.3.3.3.3.2.cmml">5</mn></mrow></msup></mrow><mo id="A5.p1.2.m2.4.4.4.8" xref="A5.p1.2.m2.4.4.5.cmml">,</mo><mrow id="A5.p1.2.m2.4.4.4.4" xref="A5.p1.2.m2.4.4.4.4.cmml"><mn id="A5.p1.2.m2.4.4.4.4.2" xref="A5.p1.2.m2.4.4.4.4.2.cmml">1</mn><mo lspace="0em" rspace="0em" id="A5.p1.2.m2.4.4.4.4.1" xref="A5.p1.2.m2.4.4.4.4.1.cmml">​</mo><msup id="A5.p1.2.m2.4.4.4.4.3" xref="A5.p1.2.m2.4.4.4.4.3.cmml"><mi id="A5.p1.2.m2.4.4.4.4.3.2" xref="A5.p1.2.m2.4.4.4.4.3.2.cmml">e</mi><mrow id="A5.p1.2.m2.4.4.4.4.3.3" xref="A5.p1.2.m2.4.4.4.4.3.3.cmml"><mo id="A5.p1.2.m2.4.4.4.4.3.3a" xref="A5.p1.2.m2.4.4.4.4.3.3.cmml">−</mo><mn id="A5.p1.2.m2.4.4.4.4.3.3.2" xref="A5.p1.2.m2.4.4.4.4.3.3.2.cmml">7</mn></mrow></msup></mrow><mo stretchy="false" id="A5.p1.2.m2.4.4.4.9" xref="A5.p1.2.m2.4.4.5.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A5.p1.2.m2.4b"><list id="A5.p1.2.m2.4.4.5.cmml" xref="A5.p1.2.m2.4.4.4"><apply id="A5.p1.2.m2.1.1.1.1.cmml" xref="A5.p1.2.m2.1.1.1.1"><times id="A5.p1.2.m2.1.1.1.1.1.cmml" xref="A5.p1.2.m2.1.1.1.1.1"></times><cn type="integer" id="A5.p1.2.m2.1.1.1.1.2.cmml" xref="A5.p1.2.m2.1.1.1.1.2">1</cn><apply id="A5.p1.2.m2.1.1.1.1.3.cmml" xref="A5.p1.2.m2.1.1.1.1.3"><csymbol cd="ambiguous" id="A5.p1.2.m2.1.1.1.1.3.1.cmml" xref="A5.p1.2.m2.1.1.1.1.3">superscript</csymbol><ci id="A5.p1.2.m2.1.1.1.1.3.2.cmml" xref="A5.p1.2.m2.1.1.1.1.3.2">𝑒</ci><apply id="A5.p1.2.m2.1.1.1.1.3.3.cmml" xref="A5.p1.2.m2.1.1.1.1.3.3"><minus id="A5.p1.2.m2.1.1.1.1.3.3.1.cmml" xref="A5.p1.2.m2.1.1.1.1.3.3"></minus><cn type="integer" id="A5.p1.2.m2.1.1.1.1.3.3.2.cmml" xref="A5.p1.2.m2.1.1.1.1.3.3.2">1</cn></apply></apply></apply><apply id="A5.p1.2.m2.2.2.2.2.cmml" xref="A5.p1.2.m2.2.2.2.2"><times id="A5.p1.2.m2.2.2.2.2.1.cmml" xref="A5.p1.2.m2.2.2.2.2.1"></times><cn type="integer" id="A5.p1.2.m2.2.2.2.2.2.cmml" xref="A5.p1.2.m2.2.2.2.2.2">1</cn><apply id="A5.p1.2.m2.2.2.2.2.3.cmml" xref="A5.p1.2.m2.2.2.2.2.3"><csymbol cd="ambiguous" id="A5.p1.2.m2.2.2.2.2.3.1.cmml" xref="A5.p1.2.m2.2.2.2.2.3">superscript</csymbol><ci id="A5.p1.2.m2.2.2.2.2.3.2.cmml" xref="A5.p1.2.m2.2.2.2.2.3.2">𝑒</ci><apply id="A5.p1.2.m2.2.2.2.2.3.3.cmml" xref="A5.p1.2.m2.2.2.2.2.3.3"><minus id="A5.p1.2.m2.2.2.2.2.3.3.1.cmml" xref="A5.p1.2.m2.2.2.2.2.3.3"></minus><cn type="integer" id="A5.p1.2.m2.2.2.2.2.3.3.2.cmml" xref="A5.p1.2.m2.2.2.2.2.3.3.2">3</cn></apply></apply></apply><apply id="A5.p1.2.m2.3.3.3.3.cmml" xref="A5.p1.2.m2.3.3.3.3"><times id="A5.p1.2.m2.3.3.3.3.1.cmml" xref="A5.p1.2.m2.3.3.3.3.1"></times><cn type="integer" id="A5.p1.2.m2.3.3.3.3.2.cmml" xref="A5.p1.2.m2.3.3.3.3.2">1</cn><apply id="A5.p1.2.m2.3.3.3.3.3.cmml" xref="A5.p1.2.m2.3.3.3.3.3"><csymbol cd="ambiguous" id="A5.p1.2.m2.3.3.3.3.3.1.cmml" xref="A5.p1.2.m2.3.3.3.3.3">superscript</csymbol><ci id="A5.p1.2.m2.3.3.3.3.3.2.cmml" xref="A5.p1.2.m2.3.3.3.3.3.2">𝑒</ci><apply id="A5.p1.2.m2.3.3.3.3.3.3.cmml" xref="A5.p1.2.m2.3.3.3.3.3.3"><minus id="A5.p1.2.m2.3.3.3.3.3.3.1.cmml" xref="A5.p1.2.m2.3.3.3.3.3.3"></minus><cn type="integer" id="A5.p1.2.m2.3.3.3.3.3.3.2.cmml" xref="A5.p1.2.m2.3.3.3.3.3.3.2">5</cn></apply></apply></apply><apply id="A5.p1.2.m2.4.4.4.4.cmml" xref="A5.p1.2.m2.4.4.4.4"><times id="A5.p1.2.m2.4.4.4.4.1.cmml" xref="A5.p1.2.m2.4.4.4.4.1"></times><cn type="integer" id="A5.p1.2.m2.4.4.4.4.2.cmml" xref="A5.p1.2.m2.4.4.4.4.2">1</cn><apply id="A5.p1.2.m2.4.4.4.4.3.cmml" xref="A5.p1.2.m2.4.4.4.4.3"><csymbol cd="ambiguous" id="A5.p1.2.m2.4.4.4.4.3.1.cmml" xref="A5.p1.2.m2.4.4.4.4.3">superscript</csymbol><ci id="A5.p1.2.m2.4.4.4.4.3.2.cmml" xref="A5.p1.2.m2.4.4.4.4.3.2">𝑒</ci><apply id="A5.p1.2.m2.4.4.4.4.3.3.cmml" xref="A5.p1.2.m2.4.4.4.4.3.3"><minus id="A5.p1.2.m2.4.4.4.4.3.3.1.cmml" xref="A5.p1.2.m2.4.4.4.4.3.3"></minus><cn type="integer" id="A5.p1.2.m2.4.4.4.4.3.3.2.cmml" xref="A5.p1.2.m2.4.4.4.4.3.3.2">7</cn></apply></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="A5.p1.2.m2.4c">[1e^{-1},1e^{-3},1e^{-5},1e^{-7}]</annotation></semantics></math> and fix the server learning rate to <math id="A5.p1.3.m3.1" class="ltx_Math" alttext="1.0" display="inline"><semantics id="A5.p1.3.m3.1a"><mn id="A5.p1.3.m3.1.1" xref="A5.p1.3.m3.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="A5.p1.3.m3.1b"><cn type="float" id="A5.p1.3.m3.1.1.cmml" xref="A5.p1.3.m3.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.p1.3.m3.1c">1.0</annotation></semantics></math>.
For FedProx, we sweep over <math id="A5.p1.4.m4.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="A5.p1.4.m4.1a"><mi id="A5.p1.4.m4.1.1" xref="A5.p1.4.m4.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="A5.p1.4.m4.1b"><ci id="A5.p1.4.m4.1.1.cmml" xref="A5.p1.4.m4.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="A5.p1.4.m4.1c">\mu</annotation></semantics></math> values of <math id="A5.p1.5.m5.5" class="ltx_Math" alttext="[0,0.1,0.01,0.001,0.0001]" display="inline"><semantics id="A5.p1.5.m5.5a"><mrow id="A5.p1.5.m5.5.6.2" xref="A5.p1.5.m5.5.6.1.cmml"><mo stretchy="false" id="A5.p1.5.m5.5.6.2.1" xref="A5.p1.5.m5.5.6.1.cmml">[</mo><mn id="A5.p1.5.m5.1.1" xref="A5.p1.5.m5.1.1.cmml">0</mn><mo id="A5.p1.5.m5.5.6.2.2" xref="A5.p1.5.m5.5.6.1.cmml">,</mo><mn id="A5.p1.5.m5.2.2" xref="A5.p1.5.m5.2.2.cmml">0.1</mn><mo id="A5.p1.5.m5.5.6.2.3" xref="A5.p1.5.m5.5.6.1.cmml">,</mo><mn id="A5.p1.5.m5.3.3" xref="A5.p1.5.m5.3.3.cmml">0.01</mn><mo id="A5.p1.5.m5.5.6.2.4" xref="A5.p1.5.m5.5.6.1.cmml">,</mo><mn id="A5.p1.5.m5.4.4" xref="A5.p1.5.m5.4.4.cmml">0.001</mn><mo id="A5.p1.5.m5.5.6.2.5" xref="A5.p1.5.m5.5.6.1.cmml">,</mo><mn id="A5.p1.5.m5.5.5" xref="A5.p1.5.m5.5.5.cmml">0.0001</mn><mo stretchy="false" id="A5.p1.5.m5.5.6.2.6" xref="A5.p1.5.m5.5.6.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A5.p1.5.m5.5b"><list id="A5.p1.5.m5.5.6.1.cmml" xref="A5.p1.5.m5.5.6.2"><cn type="integer" id="A5.p1.5.m5.1.1.cmml" xref="A5.p1.5.m5.1.1">0</cn><cn type="float" id="A5.p1.5.m5.2.2.cmml" xref="A5.p1.5.m5.2.2">0.1</cn><cn type="float" id="A5.p1.5.m5.3.3.cmml" xref="A5.p1.5.m5.3.3">0.01</cn><cn type="float" id="A5.p1.5.m5.4.4.cmml" xref="A5.p1.5.m5.4.4">0.001</cn><cn type="float" id="A5.p1.5.m5.5.5.cmml" xref="A5.p1.5.m5.5.5">0.0001</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A5.p1.5.m5.5c">[0,0.1,0.01,0.001,0.0001]</annotation></semantics></math> which controls the weight of the L2 squared norm.</p>
</div>
<div id="A5.p2" class="ltx_para">
<p id="A5.p2.2" class="ltx_p">We report test perplexity over <math id="A5.p2.1.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A5.p2.1.m1.1a"><mn id="A5.p2.1.m1.1.1" xref="A5.p2.1.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A5.p2.1.m1.1b"><cn type="integer" id="A5.p2.1.m1.1.1.cmml" xref="A5.p2.1.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.p2.1.m1.1c">10</annotation></semantics></math>K federated training rounds with <math id="A5.p2.2.m2.1" class="ltx_Math" alttext="800" display="inline"><semantics id="A5.p2.2.m2.1a"><mn id="A5.p2.2.m2.1.1" xref="A5.p2.2.m2.1.1.cmml">800</mn><annotation-xml encoding="MathML-Content" id="A5.p2.2.m2.1b"><cn type="integer" id="A5.p2.2.m2.1.1.cmml" xref="A5.p2.2.m2.1.1">800</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.p2.2.m2.1c">800</annotation></semantics></math> clients per round in Figure <a href="#S5.F7" title="Figure 7 ‣ 5 Number of communication rounds ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> and Table <a href="#A5.T7" title="Table 7 ‣ Appendix E Different optimizers ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.
While FedProx does slightly outperform FedAvg, it does not significantly alter the speed of training in terms of number of communication rounds.
Thus, we chose to continue using FedAvg in the combination experiments for consistency across experiments and more accurate comparisons.</p>
</div>
</section>
<section id="A6" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Combination of techniques</h2>

<figure id="A6.T8" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Test perplexity and total communication costs in gigabytes after <math id="A6.T8.3.m1.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A6.T8.3.m1.1b"><mn id="A6.T8.3.m1.1.1" xref="A6.T8.3.m1.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A6.T8.3.m1.1c"><cn type="integer" id="A6.T8.3.m1.1.1.cmml" xref="A6.T8.3.m1.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.3.m1.1d">10</annotation></semantics></math>K communication rounds of training for each class of model and setup. If the number of download bits is unspecified, the standard <math id="A6.T8.4.m2.1" class="ltx_Math" alttext="32" display="inline"><semantics id="A6.T8.4.m2.1b"><mn id="A6.T8.4.m2.1.1" xref="A6.T8.4.m2.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="A6.T8.4.m2.1c"><cn type="integer" id="A6.T8.4.m2.1.1.cmml" xref="A6.T8.4.m2.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.4.m2.1d">32</annotation></semantics></math> bits was used.</figcaption>
<table id="A6.T8.47" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A6.T8.47.44.1" class="ltx_tr">
<th id="A6.T8.47.44.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column">Model</th>
<th id="A6.T8.47.44.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column">Download Cost (GB)</th>
<th id="A6.T8.47.44.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column">Upload Cost (GB)</th>
<th id="A6.T8.47.44.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column">Perplexity</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A6.T8.7.3" class="ltx_tr">
<td id="A6.T8.7.3.4" class="ltx_td ltx_align_center ltx_border_t">Small LSTM</td>
<td id="A6.T8.5.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A6.T8.5.1.1.m1.1" class="ltx_Math" alttext="188" display="inline"><semantics id="A6.T8.5.1.1.m1.1a"><mn id="A6.T8.5.1.1.m1.1.1" xref="A6.T8.5.1.1.m1.1.1.cmml">188</mn><annotation-xml encoding="MathML-Content" id="A6.T8.5.1.1.m1.1b"><cn type="integer" id="A6.T8.5.1.1.m1.1.1.cmml" xref="A6.T8.5.1.1.m1.1.1">188</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.5.1.1.m1.1c">188</annotation></semantics></math></td>
<td id="A6.T8.6.2.2" class="ltx_td ltx_align_center ltx_border_t"><math id="A6.T8.6.2.2.m1.1" class="ltx_Math" alttext="188" display="inline"><semantics id="A6.T8.6.2.2.m1.1a"><mn id="A6.T8.6.2.2.m1.1.1" xref="A6.T8.6.2.2.m1.1.1.cmml">188</mn><annotation-xml encoding="MathML-Content" id="A6.T8.6.2.2.m1.1b"><cn type="integer" id="A6.T8.6.2.2.m1.1.1.cmml" xref="A6.T8.6.2.2.m1.1.1">188</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.6.2.2.m1.1c">188</annotation></semantics></math></td>
<td id="A6.T8.7.3.3" class="ltx_td ltx_align_center ltx_border_t"><math id="A6.T8.7.3.3.m1.1" class="ltx_Math" alttext="34.80" display="inline"><semantics id="A6.T8.7.3.3.m1.1a"><mn id="A6.T8.7.3.3.m1.1.1" xref="A6.T8.7.3.3.m1.1.1.cmml">34.80</mn><annotation-xml encoding="MathML-Content" id="A6.T8.7.3.3.m1.1b"><cn type="float" id="A6.T8.7.3.3.m1.1.1.cmml" xref="A6.T8.7.3.3.m1.1.1">34.80</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.7.3.3.m1.1c">34.80</annotation></semantics></math></td>
</tr>
<tr id="A6.T8.10.6" class="ltx_tr">
<td id="A6.T8.10.6.4" class="ltx_td ltx_align_center">Small Transformer</td>
<td id="A6.T8.8.4.1" class="ltx_td ltx_align_center"><math id="A6.T8.8.4.1.m1.1" class="ltx_Math" alttext="164" display="inline"><semantics id="A6.T8.8.4.1.m1.1a"><mn id="A6.T8.8.4.1.m1.1.1" xref="A6.T8.8.4.1.m1.1.1.cmml">164</mn><annotation-xml encoding="MathML-Content" id="A6.T8.8.4.1.m1.1b"><cn type="integer" id="A6.T8.8.4.1.m1.1.1.cmml" xref="A6.T8.8.4.1.m1.1.1">164</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.8.4.1.m1.1c">164</annotation></semantics></math></td>
<td id="A6.T8.9.5.2" class="ltx_td ltx_align_center"><math id="A6.T8.9.5.2.m1.1" class="ltx_Math" alttext="164" display="inline"><semantics id="A6.T8.9.5.2.m1.1a"><mn id="A6.T8.9.5.2.m1.1.1" xref="A6.T8.9.5.2.m1.1.1.cmml">164</mn><annotation-xml encoding="MathML-Content" id="A6.T8.9.5.2.m1.1b"><cn type="integer" id="A6.T8.9.5.2.m1.1.1.cmml" xref="A6.T8.9.5.2.m1.1.1">164</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.9.5.2.m1.1c">164</annotation></semantics></math></td>
<td id="A6.T8.10.6.3" class="ltx_td ltx_align_center"><math id="A6.T8.10.6.3.m1.1" class="ltx_Math" alttext="38.66" display="inline"><semantics id="A6.T8.10.6.3.m1.1a"><mn id="A6.T8.10.6.3.m1.1.1" xref="A6.T8.10.6.3.m1.1.1.cmml">38.66</mn><annotation-xml encoding="MathML-Content" id="A6.T8.10.6.3.m1.1b"><cn type="float" id="A6.T8.10.6.3.m1.1.1.cmml" xref="A6.T8.10.6.3.m1.1.1">38.66</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.10.6.3.m1.1c">38.66</annotation></semantics></math></td>
</tr>
<tr id="A6.T8.13.9" class="ltx_tr">
<td id="A6.T8.13.9.4" class="ltx_td ltx_align_center">Small Conformer</td>
<td id="A6.T8.11.7.1" class="ltx_td ltx_align_center"><math id="A6.T8.11.7.1.m1.1" class="ltx_Math" alttext="162" display="inline"><semantics id="A6.T8.11.7.1.m1.1a"><mn id="A6.T8.11.7.1.m1.1.1" xref="A6.T8.11.7.1.m1.1.1.cmml">162</mn><annotation-xml encoding="MathML-Content" id="A6.T8.11.7.1.m1.1b"><cn type="integer" id="A6.T8.11.7.1.m1.1.1.cmml" xref="A6.T8.11.7.1.m1.1.1">162</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.11.7.1.m1.1c">162</annotation></semantics></math></td>
<td id="A6.T8.12.8.2" class="ltx_td ltx_align_center"><math id="A6.T8.12.8.2.m1.1" class="ltx_Math" alttext="162" display="inline"><semantics id="A6.T8.12.8.2.m1.1a"><mn id="A6.T8.12.8.2.m1.1.1" xref="A6.T8.12.8.2.m1.1.1.cmml">162</mn><annotation-xml encoding="MathML-Content" id="A6.T8.12.8.2.m1.1b"><cn type="integer" id="A6.T8.12.8.2.m1.1.1.cmml" xref="A6.T8.12.8.2.m1.1.1">162</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.12.8.2.m1.1c">162</annotation></semantics></math></td>
<td id="A6.T8.13.9.3" class="ltx_td ltx_align_center"><math id="A6.T8.13.9.3.m1.1" class="ltx_Math" alttext="36.80" display="inline"><semantics id="A6.T8.13.9.3.m1.1a"><mn id="A6.T8.13.9.3.m1.1.1" xref="A6.T8.13.9.3.m1.1.1.cmml">36.80</mn><annotation-xml encoding="MathML-Content" id="A6.T8.13.9.3.m1.1b"><cn type="float" id="A6.T8.13.9.3.m1.1.1.cmml" xref="A6.T8.13.9.3.m1.1.1">36.80</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.13.9.3.m1.1c">36.80</annotation></semantics></math></td>
</tr>
<tr id="A6.T8.16.12" class="ltx_tr">
<td id="A6.T8.16.12.4" class="ltx_td ltx_align_center ltx_border_t">Large LSTM</td>
<td id="A6.T8.14.10.1" class="ltx_td ltx_align_center ltx_border_t"><math id="A6.T8.14.10.1.m1.1" class="ltx_Math" alttext="752" display="inline"><semantics id="A6.T8.14.10.1.m1.1a"><mn id="A6.T8.14.10.1.m1.1.1" xref="A6.T8.14.10.1.m1.1.1.cmml">752</mn><annotation-xml encoding="MathML-Content" id="A6.T8.14.10.1.m1.1b"><cn type="integer" id="A6.T8.14.10.1.m1.1.1.cmml" xref="A6.T8.14.10.1.m1.1.1">752</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.14.10.1.m1.1c">752</annotation></semantics></math></td>
<td id="A6.T8.15.11.2" class="ltx_td ltx_align_center ltx_border_t"><math id="A6.T8.15.11.2.m1.1" class="ltx_Math" alttext="752" display="inline"><semantics id="A6.T8.15.11.2.m1.1a"><mn id="A6.T8.15.11.2.m1.1.1" xref="A6.T8.15.11.2.m1.1.1.cmml">752</mn><annotation-xml encoding="MathML-Content" id="A6.T8.15.11.2.m1.1b"><cn type="integer" id="A6.T8.15.11.2.m1.1.1.cmml" xref="A6.T8.15.11.2.m1.1.1">752</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.15.11.2.m1.1c">752</annotation></semantics></math></td>
<td id="A6.T8.16.12.3" class="ltx_td ltx_align_center ltx_border_t"><math id="A6.T8.16.12.3.m1.1" class="ltx_Math" alttext="30.83" display="inline"><semantics id="A6.T8.16.12.3.m1.1a"><mn id="A6.T8.16.12.3.m1.1.1" xref="A6.T8.16.12.3.m1.1.1.cmml">30.83</mn><annotation-xml encoding="MathML-Content" id="A6.T8.16.12.3.m1.1b"><cn type="float" id="A6.T8.16.12.3.m1.1.1.cmml" xref="A6.T8.16.12.3.m1.1.1">30.83</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.16.12.3.m1.1c">30.83</annotation></semantics></math></td>
</tr>
<tr id="A6.T8.19.15" class="ltx_tr">
<td id="A6.T8.19.15.4" class="ltx_td ltx_align_center">Large Transformer</td>
<td id="A6.T8.17.13.1" class="ltx_td ltx_align_center"><math id="A6.T8.17.13.1.m1.1" class="ltx_Math" alttext="840" display="inline"><semantics id="A6.T8.17.13.1.m1.1a"><mn id="A6.T8.17.13.1.m1.1.1" xref="A6.T8.17.13.1.m1.1.1.cmml">840</mn><annotation-xml encoding="MathML-Content" id="A6.T8.17.13.1.m1.1b"><cn type="integer" id="A6.T8.17.13.1.m1.1.1.cmml" xref="A6.T8.17.13.1.m1.1.1">840</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.17.13.1.m1.1c">840</annotation></semantics></math></td>
<td id="A6.T8.18.14.2" class="ltx_td ltx_align_center"><math id="A6.T8.18.14.2.m1.1" class="ltx_Math" alttext="840" display="inline"><semantics id="A6.T8.18.14.2.m1.1a"><mn id="A6.T8.18.14.2.m1.1.1" xref="A6.T8.18.14.2.m1.1.1.cmml">840</mn><annotation-xml encoding="MathML-Content" id="A6.T8.18.14.2.m1.1b"><cn type="integer" id="A6.T8.18.14.2.m1.1.1.cmml" xref="A6.T8.18.14.2.m1.1.1">840</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.18.14.2.m1.1c">840</annotation></semantics></math></td>
<td id="A6.T8.19.15.3" class="ltx_td ltx_align_center"><math id="A6.T8.19.15.3.m1.1" class="ltx_Math" alttext="29.15" display="inline"><semantics id="A6.T8.19.15.3.m1.1a"><mn id="A6.T8.19.15.3.m1.1.1" xref="A6.T8.19.15.3.m1.1.1.cmml">29.15</mn><annotation-xml encoding="MathML-Content" id="A6.T8.19.15.3.m1.1b"><cn type="float" id="A6.T8.19.15.3.m1.1.1.cmml" xref="A6.T8.19.15.3.m1.1.1">29.15</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.19.15.3.m1.1c">29.15</annotation></semantics></math></td>
</tr>
<tr id="A6.T8.22.18" class="ltx_tr">
<td id="A6.T8.22.18.4" class="ltx_td ltx_align_center">Large Conformer</td>
<td id="A6.T8.20.16.1" class="ltx_td ltx_align_center"><math id="A6.T8.20.16.1.m1.1" class="ltx_Math" alttext="808" display="inline"><semantics id="A6.T8.20.16.1.m1.1a"><mn id="A6.T8.20.16.1.m1.1.1" xref="A6.T8.20.16.1.m1.1.1.cmml">808</mn><annotation-xml encoding="MathML-Content" id="A6.T8.20.16.1.m1.1b"><cn type="integer" id="A6.T8.20.16.1.m1.1.1.cmml" xref="A6.T8.20.16.1.m1.1.1">808</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.20.16.1.m1.1c">808</annotation></semantics></math></td>
<td id="A6.T8.21.17.2" class="ltx_td ltx_align_center"><math id="A6.T8.21.17.2.m1.1" class="ltx_Math" alttext="808" display="inline"><semantics id="A6.T8.21.17.2.m1.1a"><mn id="A6.T8.21.17.2.m1.1.1" xref="A6.T8.21.17.2.m1.1.1.cmml">808</mn><annotation-xml encoding="MathML-Content" id="A6.T8.21.17.2.m1.1b"><cn type="integer" id="A6.T8.21.17.2.m1.1.1.cmml" xref="A6.T8.21.17.2.m1.1.1">808</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.21.17.2.m1.1c">808</annotation></semantics></math></td>
<td id="A6.T8.22.18.3" class="ltx_td ltx_align_center"><math id="A6.T8.22.18.3.m1.1" class="ltx_Math" alttext="29.06" display="inline"><semantics id="A6.T8.22.18.3.m1.1a"><mn id="A6.T8.22.18.3.m1.1.1" xref="A6.T8.22.18.3.m1.1.1.cmml">29.06</mn><annotation-xml encoding="MathML-Content" id="A6.T8.22.18.3.m1.1b"><cn type="float" id="A6.T8.22.18.3.m1.1.1.cmml" xref="A6.T8.22.18.3.m1.1.1">29.06</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.22.18.3.m1.1c">29.06</annotation></semantics></math></td>
</tr>
<tr id="A6.T8.27.23" class="ltx_tr">
<td id="A6.T8.23.19.1" class="ltx_td ltx_align_center ltx_border_t">Efficient Large LSTM (download <math id="A6.T8.23.19.1.m1.1" class="ltx_Math" alttext="32" display="inline"><semantics id="A6.T8.23.19.1.m1.1a"><mn id="A6.T8.23.19.1.m1.1.1" xref="A6.T8.23.19.1.m1.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="A6.T8.23.19.1.m1.1b"><cn type="integer" id="A6.T8.23.19.1.m1.1.1.cmml" xref="A6.T8.23.19.1.m1.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.23.19.1.m1.1c">32</annotation></semantics></math> bits)</td>
<td id="A6.T8.25.21.3" class="ltx_td ltx_align_center ltx_border_t">752</td>
<td id="A6.T8.26.22.4" class="ltx_td ltx_align_center ltx_border_t"><math id="A6.T8.26.22.4.m1.1" class="ltx_Math" alttext="75" display="inline"><semantics id="A6.T8.26.22.4.m1.1a"><mn id="A6.T8.26.22.4.m1.1.1" xref="A6.T8.26.22.4.m1.1.1.cmml">75</mn><annotation-xml encoding="MathML-Content" id="A6.T8.26.22.4.m1.1b"><cn type="integer" id="A6.T8.26.22.4.m1.1.1.cmml" xref="A6.T8.26.22.4.m1.1.1">75</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.26.22.4.m1.1c">75</annotation></semantics></math></td>
<td id="A6.T8.27.23.5" class="ltx_td ltx_align_center ltx_border_t"><math id="A6.T8.27.23.5.m1.1" class="ltx_Math" alttext="32.57" display="inline"><semantics id="A6.T8.27.23.5.m1.1a"><mn id="A6.T8.27.23.5.m1.1.1" xref="A6.T8.27.23.5.m1.1.1.cmml">32.57</mn><annotation-xml encoding="MathML-Content" id="A6.T8.27.23.5.m1.1b"><cn type="float" id="A6.T8.27.23.5.m1.1.1.cmml" xref="A6.T8.27.23.5.m1.1.1">32.57</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.27.23.5.m1.1c">32.57</annotation></semantics></math></td>
</tr>
<tr id="A6.T8.31.27" class="ltx_tr">
<td id="A6.T8.28.24.1" class="ltx_td ltx_align_center">Efficient Large Transformer (download <math id="A6.T8.28.24.1.m1.1" class="ltx_Math" alttext="32" display="inline"><semantics id="A6.T8.28.24.1.m1.1a"><mn id="A6.T8.28.24.1.m1.1.1" xref="A6.T8.28.24.1.m1.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="A6.T8.28.24.1.m1.1b"><cn type="integer" id="A6.T8.28.24.1.m1.1.1.cmml" xref="A6.T8.28.24.1.m1.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.28.24.1.m1.1c">32</annotation></semantics></math> bits)</td>
<td id="A6.T8.29.25.2" class="ltx_td ltx_align_center"><math id="A6.T8.29.25.2.m1.1" class="ltx_Math" alttext="840" display="inline"><semantics id="A6.T8.29.25.2.m1.1a"><mn id="A6.T8.29.25.2.m1.1.1" xref="A6.T8.29.25.2.m1.1.1.cmml">840</mn><annotation-xml encoding="MathML-Content" id="A6.T8.29.25.2.m1.1b"><cn type="integer" id="A6.T8.29.25.2.m1.1.1.cmml" xref="A6.T8.29.25.2.m1.1.1">840</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.29.25.2.m1.1c">840</annotation></semantics></math></td>
<td id="A6.T8.30.26.3" class="ltx_td ltx_align_center"><math id="A6.T8.30.26.3.m1.1" class="ltx_Math" alttext="84" display="inline"><semantics id="A6.T8.30.26.3.m1.1a"><mn id="A6.T8.30.26.3.m1.1.1" xref="A6.T8.30.26.3.m1.1.1.cmml">84</mn><annotation-xml encoding="MathML-Content" id="A6.T8.30.26.3.m1.1b"><cn type="integer" id="A6.T8.30.26.3.m1.1.1.cmml" xref="A6.T8.30.26.3.m1.1.1">84</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.30.26.3.m1.1c">84</annotation></semantics></math></td>
<td id="A6.T8.31.27.4" class="ltx_td ltx_align_center"><math id="A6.T8.31.27.4.m1.1" class="ltx_Math" alttext="30.83" display="inline"><semantics id="A6.T8.31.27.4.m1.1a"><mn id="A6.T8.31.27.4.m1.1.1" xref="A6.T8.31.27.4.m1.1.1.cmml">30.83</mn><annotation-xml encoding="MathML-Content" id="A6.T8.31.27.4.m1.1b"><cn type="float" id="A6.T8.31.27.4.m1.1.1.cmml" xref="A6.T8.31.27.4.m1.1.1">30.83</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.31.27.4.m1.1c">30.83</annotation></semantics></math></td>
</tr>
<tr id="A6.T8.35.31" class="ltx_tr">
<td id="A6.T8.32.28.1" class="ltx_td ltx_align_center">Efficient Large Conformer (download <math id="A6.T8.32.28.1.m1.1" class="ltx_Math" alttext="32" display="inline"><semantics id="A6.T8.32.28.1.m1.1a"><mn id="A6.T8.32.28.1.m1.1.1" xref="A6.T8.32.28.1.m1.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="A6.T8.32.28.1.m1.1b"><cn type="integer" id="A6.T8.32.28.1.m1.1.1.cmml" xref="A6.T8.32.28.1.m1.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.32.28.1.m1.1c">32</annotation></semantics></math> bits)</td>
<td id="A6.T8.33.29.2" class="ltx_td ltx_align_center"><math id="A6.T8.33.29.2.m1.1" class="ltx_Math" alttext="808" display="inline"><semantics id="A6.T8.33.29.2.m1.1a"><mn id="A6.T8.33.29.2.m1.1.1" xref="A6.T8.33.29.2.m1.1.1.cmml">808</mn><annotation-xml encoding="MathML-Content" id="A6.T8.33.29.2.m1.1b"><cn type="integer" id="A6.T8.33.29.2.m1.1.1.cmml" xref="A6.T8.33.29.2.m1.1.1">808</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.33.29.2.m1.1c">808</annotation></semantics></math></td>
<td id="A6.T8.34.30.3" class="ltx_td ltx_align_center"><math id="A6.T8.34.30.3.m1.1" class="ltx_Math" alttext="81" display="inline"><semantics id="A6.T8.34.30.3.m1.1a"><mn id="A6.T8.34.30.3.m1.1.1" xref="A6.T8.34.30.3.m1.1.1.cmml">81</mn><annotation-xml encoding="MathML-Content" id="A6.T8.34.30.3.m1.1b"><cn type="integer" id="A6.T8.34.30.3.m1.1.1.cmml" xref="A6.T8.34.30.3.m1.1.1">81</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.34.30.3.m1.1c">81</annotation></semantics></math></td>
<td id="A6.T8.35.31.4" class="ltx_td ltx_align_center"><math id="A6.T8.35.31.4.m1.1" class="ltx_Math" alttext="30.37" display="inline"><semantics id="A6.T8.35.31.4.m1.1a"><mn id="A6.T8.35.31.4.m1.1.1" xref="A6.T8.35.31.4.m1.1.1.cmml">30.37</mn><annotation-xml encoding="MathML-Content" id="A6.T8.35.31.4.m1.1b"><cn type="float" id="A6.T8.35.31.4.m1.1.1.cmml" xref="A6.T8.35.31.4.m1.1.1">30.37</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.35.31.4.m1.1c">30.37</annotation></semantics></math></td>
</tr>
<tr id="A6.T8.39.35" class="ltx_tr">
<td id="A6.T8.36.32.1" class="ltx_td ltx_align_center ltx_border_t">Efficient Large LSTM (download <math id="A6.T8.36.32.1.m1.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A6.T8.36.32.1.m1.1a"><mn id="A6.T8.36.32.1.m1.1.1" xref="A6.T8.36.32.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A6.T8.36.32.1.m1.1b"><cn type="integer" id="A6.T8.36.32.1.m1.1.1.cmml" xref="A6.T8.36.32.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.36.32.1.m1.1c">16</annotation></semantics></math> bits)</td>
<td id="A6.T8.37.33.2" class="ltx_td ltx_align_center ltx_border_t"><math id="A6.T8.37.33.2.m1.1" class="ltx_Math" alttext="376" display="inline"><semantics id="A6.T8.37.33.2.m1.1a"><mn id="A6.T8.37.33.2.m1.1.1" xref="A6.T8.37.33.2.m1.1.1.cmml">376</mn><annotation-xml encoding="MathML-Content" id="A6.T8.37.33.2.m1.1b"><cn type="integer" id="A6.T8.37.33.2.m1.1.1.cmml" xref="A6.T8.37.33.2.m1.1.1">376</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.37.33.2.m1.1c">376</annotation></semantics></math></td>
<td id="A6.T8.38.34.3" class="ltx_td ltx_align_center ltx_border_t"><math id="A6.T8.38.34.3.m1.1" class="ltx_Math" alttext="75" display="inline"><semantics id="A6.T8.38.34.3.m1.1a"><mn id="A6.T8.38.34.3.m1.1.1" xref="A6.T8.38.34.3.m1.1.1.cmml">75</mn><annotation-xml encoding="MathML-Content" id="A6.T8.38.34.3.m1.1b"><cn type="integer" id="A6.T8.38.34.3.m1.1.1.cmml" xref="A6.T8.38.34.3.m1.1.1">75</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.38.34.3.m1.1c">75</annotation></semantics></math></td>
<td id="A6.T8.39.35.4" class="ltx_td ltx_align_center ltx_border_t"><math id="A6.T8.39.35.4.m1.1" class="ltx_Math" alttext="32.76" display="inline"><semantics id="A6.T8.39.35.4.m1.1a"><mn id="A6.T8.39.35.4.m1.1.1" xref="A6.T8.39.35.4.m1.1.1.cmml">32.76</mn><annotation-xml encoding="MathML-Content" id="A6.T8.39.35.4.m1.1b"><cn type="float" id="A6.T8.39.35.4.m1.1.1.cmml" xref="A6.T8.39.35.4.m1.1.1">32.76</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.39.35.4.m1.1c">32.76</annotation></semantics></math></td>
</tr>
<tr id="A6.T8.43.39" class="ltx_tr">
<td id="A6.T8.40.36.1" class="ltx_td ltx_align_center">Efficient Large Transformer (download <math id="A6.T8.40.36.1.m1.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A6.T8.40.36.1.m1.1a"><mn id="A6.T8.40.36.1.m1.1.1" xref="A6.T8.40.36.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A6.T8.40.36.1.m1.1b"><cn type="integer" id="A6.T8.40.36.1.m1.1.1.cmml" xref="A6.T8.40.36.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.40.36.1.m1.1c">16</annotation></semantics></math> bits)</td>
<td id="A6.T8.41.37.2" class="ltx_td ltx_align_center"><math id="A6.T8.41.37.2.m1.1" class="ltx_Math" alttext="420" display="inline"><semantics id="A6.T8.41.37.2.m1.1a"><mn id="A6.T8.41.37.2.m1.1.1" xref="A6.T8.41.37.2.m1.1.1.cmml">420</mn><annotation-xml encoding="MathML-Content" id="A6.T8.41.37.2.m1.1b"><cn type="integer" id="A6.T8.41.37.2.m1.1.1.cmml" xref="A6.T8.41.37.2.m1.1.1">420</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.41.37.2.m1.1c">420</annotation></semantics></math></td>
<td id="A6.T8.42.38.3" class="ltx_td ltx_align_center"><math id="A6.T8.42.38.3.m1.1" class="ltx_Math" alttext="84" display="inline"><semantics id="A6.T8.42.38.3.m1.1a"><mn id="A6.T8.42.38.3.m1.1.1" xref="A6.T8.42.38.3.m1.1.1.cmml">84</mn><annotation-xml encoding="MathML-Content" id="A6.T8.42.38.3.m1.1b"><cn type="integer" id="A6.T8.42.38.3.m1.1.1.cmml" xref="A6.T8.42.38.3.m1.1.1">84</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.42.38.3.m1.1c">84</annotation></semantics></math></td>
<td id="A6.T8.43.39.4" class="ltx_td ltx_align_center"><math id="A6.T8.43.39.4.m1.1" class="ltx_Math" alttext="32.32" display="inline"><semantics id="A6.T8.43.39.4.m1.1a"><mn id="A6.T8.43.39.4.m1.1.1" xref="A6.T8.43.39.4.m1.1.1.cmml">32.32</mn><annotation-xml encoding="MathML-Content" id="A6.T8.43.39.4.m1.1b"><cn type="float" id="A6.T8.43.39.4.m1.1.1.cmml" xref="A6.T8.43.39.4.m1.1.1">32.32</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.43.39.4.m1.1c">32.32</annotation></semantics></math></td>
</tr>
<tr id="A6.T8.47.43" class="ltx_tr">
<td id="A6.T8.44.40.1" class="ltx_td ltx_align_center">Efficient Large Conformer (download <math id="A6.T8.44.40.1.m1.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A6.T8.44.40.1.m1.1a"><mn id="A6.T8.44.40.1.m1.1.1" xref="A6.T8.44.40.1.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A6.T8.44.40.1.m1.1b"><cn type="integer" id="A6.T8.44.40.1.m1.1.1.cmml" xref="A6.T8.44.40.1.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.44.40.1.m1.1c">16</annotation></semantics></math> bits)</td>
<td id="A6.T8.45.41.2" class="ltx_td ltx_align_center"><math id="A6.T8.45.41.2.m1.1" class="ltx_Math" alttext="404" display="inline"><semantics id="A6.T8.45.41.2.m1.1a"><mn id="A6.T8.45.41.2.m1.1.1" xref="A6.T8.45.41.2.m1.1.1.cmml">404</mn><annotation-xml encoding="MathML-Content" id="A6.T8.45.41.2.m1.1b"><cn type="integer" id="A6.T8.45.41.2.m1.1.1.cmml" xref="A6.T8.45.41.2.m1.1.1">404</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.45.41.2.m1.1c">404</annotation></semantics></math></td>
<td id="A6.T8.46.42.3" class="ltx_td ltx_align_center"><math id="A6.T8.46.42.3.m1.1" class="ltx_Math" alttext="81" display="inline"><semantics id="A6.T8.46.42.3.m1.1a"><mn id="A6.T8.46.42.3.m1.1.1" xref="A6.T8.46.42.3.m1.1.1.cmml">81</mn><annotation-xml encoding="MathML-Content" id="A6.T8.46.42.3.m1.1b"><cn type="integer" id="A6.T8.46.42.3.m1.1.1.cmml" xref="A6.T8.46.42.3.m1.1.1">81</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.46.42.3.m1.1c">81</annotation></semantics></math></td>
<td id="A6.T8.47.43.4" class="ltx_td ltx_align_center"><math id="A6.T8.47.43.4.m1.1" class="ltx_Math" alttext="31.71" display="inline"><semantics id="A6.T8.47.43.4.m1.1a"><mn id="A6.T8.47.43.4.m1.1.1" xref="A6.T8.47.43.4.m1.1.1.cmml">31.71</mn><annotation-xml encoding="MathML-Content" id="A6.T8.47.43.4.m1.1b"><cn type="float" id="A6.T8.47.43.4.m1.1.1.cmml" xref="A6.T8.47.43.4.m1.1.1">31.71</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.T8.47.43.4.m1.1c">31.71</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</figure>
<figure id="A6.F13" class="ltx_figure"><img src="/html/2204.09715/assets/so_combo_rounds.png" id="A6.F13.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="387" height="135" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>Test perplexity over communication rounds for the large models with and without efficient techniques applied.</figcaption>
</figure>
<div id="A6.p1" class="ltx_para">
<p id="A6.p1.7" class="ltx_p">For the combination experiments, we conducted a joint search over a smaller range of hyperparameters for each technique to keep the total search space reasonable.
For PVT, we restricted the possible percentages to <math id="A6.p1.1.m1.1" class="ltx_Math" alttext="20\%" display="inline"><semantics id="A6.p1.1.m1.1a"><mrow id="A6.p1.1.m1.1.1" xref="A6.p1.1.m1.1.1.cmml"><mn id="A6.p1.1.m1.1.1.2" xref="A6.p1.1.m1.1.1.2.cmml">20</mn><mo id="A6.p1.1.m1.1.1.1" xref="A6.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A6.p1.1.m1.1b"><apply id="A6.p1.1.m1.1.1.cmml" xref="A6.p1.1.m1.1.1"><csymbol cd="latexml" id="A6.p1.1.m1.1.1.1.cmml" xref="A6.p1.1.m1.1.1.1">percent</csymbol><cn type="integer" id="A6.p1.1.m1.1.1.2.cmml" xref="A6.p1.1.m1.1.1.2">20</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p1.1.m1.1c">20\%</annotation></semantics></math>, <math id="A6.p1.2.m2.1" class="ltx_Math" alttext="30\%" display="inline"><semantics id="A6.p1.2.m2.1a"><mrow id="A6.p1.2.m2.1.1" xref="A6.p1.2.m2.1.1.cmml"><mn id="A6.p1.2.m2.1.1.2" xref="A6.p1.2.m2.1.1.2.cmml">30</mn><mo id="A6.p1.2.m2.1.1.1" xref="A6.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A6.p1.2.m2.1b"><apply id="A6.p1.2.m2.1.1.cmml" xref="A6.p1.2.m2.1.1"><csymbol cd="latexml" id="A6.p1.2.m2.1.1.1.cmml" xref="A6.p1.2.m2.1.1.1">percent</csymbol><cn type="integer" id="A6.p1.2.m2.1.1.2.cmml" xref="A6.p1.2.m2.1.1.2">30</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p1.2.m2.1c">30\%</annotation></semantics></math>, and <math id="A6.p1.3.m3.1" class="ltx_Math" alttext="40\%" display="inline"><semantics id="A6.p1.3.m3.1a"><mrow id="A6.p1.3.m3.1.1" xref="A6.p1.3.m3.1.1.cmml"><mn id="A6.p1.3.m3.1.1.2" xref="A6.p1.3.m3.1.1.2.cmml">40</mn><mo id="A6.p1.3.m3.1.1.1" xref="A6.p1.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="A6.p1.3.m3.1b"><apply id="A6.p1.3.m3.1.1.cmml" xref="A6.p1.3.m3.1.1"><csymbol cd="latexml" id="A6.p1.3.m3.1.1.1.cmml" xref="A6.p1.3.m3.1.1.1">percent</csymbol><cn type="integer" id="A6.p1.3.m3.1.1.2.cmml" xref="A6.p1.3.m3.1.1.2">40</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.p1.3.m3.1c">40\%</annotation></semantics></math> of trainable variables as those were shown to yield good performance while cutting model size to less than half the original size.
For uniform quantization, we restricted the search of upload to <math id="A6.p1.4.m4.1" class="ltx_Math" alttext="6" display="inline"><semantics id="A6.p1.4.m4.1a"><mn id="A6.p1.4.m4.1.1" xref="A6.p1.4.m4.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="A6.p1.4.m4.1b"><cn type="integer" id="A6.p1.4.m4.1.1.cmml" xref="A6.p1.4.m4.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.p1.4.m4.1c">6</annotation></semantics></math> or <math id="A6.p1.5.m5.1" class="ltx_Math" alttext="8" display="inline"><semantics id="A6.p1.5.m5.1a"><mn id="A6.p1.5.m5.1.1" xref="A6.p1.5.m5.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A6.p1.5.m5.1b"><cn type="integer" id="A6.p1.5.m5.1.1.cmml" xref="A6.p1.5.m5.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.p1.5.m5.1c">8</annotation></semantics></math> bits and download to <math id="A6.p1.6.m6.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A6.p1.6.m6.1a"><mn id="A6.p1.6.m6.1.1" xref="A6.p1.6.m6.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A6.p1.6.m6.1b"><cn type="integer" id="A6.p1.6.m6.1.1.cmml" xref="A6.p1.6.m6.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.p1.6.m6.1c">16</annotation></semantics></math> or <math id="A6.p1.7.m7.1" class="ltx_Math" alttext="32" display="inline"><semantics id="A6.p1.7.m7.1a"><mn id="A6.p1.7.m7.1.1" xref="A6.p1.7.m7.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="A6.p1.7.m7.1b"><cn type="integer" id="A6.p1.7.m7.1.1.cmml" xref="A6.p1.7.m7.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.p1.7.m7.1c">32</annotation></semantics></math> bits since the Transformer was shown to be able to handle aggressive upload quantization but required more care on download quantization.
Finally, for transfer learning, we warmstarted after pretraining on the Books corpus.
As in previous experiments, we also search over the common hyperparameter space defined in Table <a href="#A1.T3" title="Table 3 ‣ Appendix A Dataset and models ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, where applicable.</p>
</div>
<div id="A6.p2" class="ltx_para">
<p id="A6.p2.8" class="ltx_p">Similar to previous experiments, we use <math id="A6.p2.1.m1.1" class="ltx_Math" alttext="800" display="inline"><semantics id="A6.p2.1.m1.1a"><mn id="A6.p2.1.m1.1.1" xref="A6.p2.1.m1.1.1.cmml">800</mn><annotation-xml encoding="MathML-Content" id="A6.p2.1.m1.1b"><cn type="integer" id="A6.p2.1.m1.1.1.cmml" xref="A6.p2.1.m1.1.1">800</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.p2.1.m1.1c">800</annotation></semantics></math> clients per round and train for <math id="A6.p2.2.m2.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A6.p2.2.m2.1a"><mn id="A6.p2.2.m2.1.1" xref="A6.p2.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A6.p2.2.m2.1b"><cn type="integer" id="A6.p2.2.m2.1.1.cmml" xref="A6.p2.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.p2.2.m2.1c">10</annotation></semantics></math>K rounds with FedAvg.
Figure <a href="#A6.F13" title="Figure 13 ‣ Appendix F Combination of techniques ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a> and Table <a href="#A6.T8" title="Table 8 ‣ Appendix F Combination of techniques ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> contain the results for the large models with and without the efficient techniques applied.
We apply two levels of quantization on download, <math id="A6.p2.3.m3.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A6.p2.3.m3.1a"><mn id="A6.p2.3.m3.1.1" xref="A6.p2.3.m3.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A6.p2.3.m3.1b"><cn type="integer" id="A6.p2.3.m3.1.1.cmml" xref="A6.p2.3.m3.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.p2.3.m3.1c">16</annotation></semantics></math> and <math id="A6.p2.4.m4.1" class="ltx_Math" alttext="32" display="inline"><semantics id="A6.p2.4.m4.1a"><mn id="A6.p2.4.m4.1.1" xref="A6.p2.4.m4.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="A6.p2.4.m4.1b"><cn type="integer" id="A6.p2.4.m4.1.1.cmml" xref="A6.p2.4.m4.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.p2.4.m4.1c">32</annotation></semantics></math> bits, and observe that the Large LSTM is more amenable to download quantization compared to the Large Transformer and Conformer as the regression between the two levels is much smaller for the LSTM than the Transformer and Conformer.
However, the Transformer and Conformer with <math id="A6.p2.5.m5.1" class="ltx_Math" alttext="16" display="inline"><semantics id="A6.p2.5.m5.1a"><mn id="A6.p2.5.m5.1.1" xref="A6.p2.5.m5.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="A6.p2.5.m5.1b"><cn type="integer" id="A6.p2.5.m5.1.1.cmml" xref="A6.p2.5.m5.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.p2.5.m5.1c">16</annotation></semantics></math> bit download quantization still outperforms all efficient LSTMs though it requires more communication rounds to do so than the efficient Transformer and Conformer with <math id="A6.p2.6.m6.1" class="ltx_Math" alttext="32" display="inline"><semantics id="A6.p2.6.m6.1a"><mn id="A6.p2.6.m6.1.1" xref="A6.p2.6.m6.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="A6.p2.6.m6.1b"><cn type="integer" id="A6.p2.6.m6.1.1.cmml" xref="A6.p2.6.m6.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.p2.6.m6.1c">32</annotation></semantics></math> bits for download.
For the remaining analysis, we focus on the efficient Transformer and Conformer using <math id="A6.p2.7.m7.1" class="ltx_Math" alttext="32" display="inline"><semantics id="A6.p2.7.m7.1a"><mn id="A6.p2.7.m7.1.1" xref="A6.p2.7.m7.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="A6.p2.7.m7.1b"><cn type="integer" id="A6.p2.7.m7.1.1.cmml" xref="A6.p2.7.m7.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.p2.7.m7.1c">32</annotation></semantics></math> bits for download.
It is clear that for the Large Transformer and Conformer, applying efficient techniques yields better quality in earlier communication rounds.
Although there are regressions in the final model quality after <math id="A6.p2.8.m8.1" class="ltx_Math" alttext="10" display="inline"><semantics id="A6.p2.8.m8.1a"><mn id="A6.p2.8.m8.1.1" xref="A6.p2.8.m8.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A6.p2.8.m8.1b"><cn type="integer" id="A6.p2.8.m8.1.1.cmml" xref="A6.p2.8.m8.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.p2.8.m8.1c">10</annotation></semantics></math>K rounds of training, this could be attributed to previously observed issues with increased amounts of labeled data diminishing the value pretraining <cite class="ltx_cite ltx_citemacro_citep">[Zoph et al., <a href="#bib.bib58" title="" class="ltx_ref">2020</a>]</cite>.
However, the Efficient Large Transformer and Efficient Large Conformer still reach the same or better final perplexity as the Large LSTM which had no efficient techniques applied.
Furthermore, when considered in terms of actual communication cost, as is done in Figure <a href="#S5.F8" title="Figure 8 ‣ 5 Number of communication rounds ‣ Scaling Language Model Size in Cross-Device Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, the efficient models yield much better performance at smaller total communication costs.</p>
</div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2204.09714" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2204.09715" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2204.09715">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2204.09715" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2204.09716" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 06:18:15 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
