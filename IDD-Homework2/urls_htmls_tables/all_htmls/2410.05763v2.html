<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Information Discovery in e-Commerce</title>
<!--Generated on Sat Oct 12 13:44:39 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.05763v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_chapter">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch1" title="In Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a>
<ol class="ltx_toclist ltx_toclist_chapter">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch1.S1" title="In Chapter 1 Introduction ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.1 </span>Motivation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch1.S2" title="In Chapter 1 Introduction ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.2 </span>Aims of this survey</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch1.S3" title="In Chapter 1 Introduction ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.3 </span>Outline</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch1.S3.SS1" title="In 1.3 Outline ‣ Chapter 1 Introduction ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.3.1 </span>Topics covered</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch1.S3.SS2" title="In 1.3 Outline ‣ Chapter 1 Introduction ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.3.2 </span>Topics not covered</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch1.S3.SS3" title="In 1.3 Outline ‣ Chapter 1 Introduction ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.3.3 </span>Structure of the survey</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch1.S4" title="In Chapter 1 Introduction ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1.4 </span>Our readers</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_chapter">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch2" title="In Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Definitions and background</span></a>
<ol class="ltx_toclist ltx_toclist_chapter">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch2.S1" title="In Chapter 2 Definitions and background ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Background</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch2.S2" title="In Chapter 2 Definitions and background ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>User modeling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch2.S3" title="In Chapter 2 Definitions and background ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Information retrieval in e-commerce</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch2.S4" title="In Chapter 2 Definitions and background ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Conversational AI</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_chapter">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3" title="In Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>E-commerce presentations and users</span></a>
<ol class="ltx_toclist ltx_toclist_chapter">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S1" title="In Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>E-commerce presentations</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S1.SS1" title="In 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Basic concepts</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S1.SS2" title="In 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Analyzing information components</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S1.SS2.SSS1" title="In 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2.1 </span>Search results in e-commerce</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S1.SS2.SSS2" title="In 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2.2 </span>Recommendation results in e-commerce platforms</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S1.SS2.SSS3" title="In 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2.3 </span>Product titles in e-commerce platforms</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S1.SS2.SSS4" title="In 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2.4 </span>Product descriptions in e-commerce platforms</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S1.SS2.SSS5" title="In 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2.5 </span>Question answering in e-commerce</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S1.SS2.SSS6" title="In 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2.6 </span>User reviews in e-commerce</span></a>
<ol class="ltx_toclist ltx_toclist_subsubsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S1.SS2.SSS6.Px1" title="In 3.1.2.6 User reviews in e-commerce ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title">(i) Sentiment classification in reviews.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S1.SS2.SSS6.Px2" title="In 3.1.2.6 User reviews in e-commerce ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title">(ii) Helpfulness prediction.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S1.SS2.SSS6.Px3" title="In 3.1.2.6 User reviews in e-commerce ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title">(iii) Review summarization.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S1.SS2.SSS6.Px4" title="In 3.1.2.6 User reviews in e-commerce ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title">(iv) Review generation.</span></a></li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S2" title="In Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>E-commerce users</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S2.SS1" title="In 3.2 E-commerce users ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.1 </span>From clicks to purchases</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S2.SS2" title="In 3.2 E-commerce users ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2.2 </span>User engagement and post-clicks</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S3" title="In Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Discussion</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_chapter">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4" title="In Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>E-commerce user modeling</span></a>
<ol class="ltx_toclist ltx_toclist_chapter">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S1" title="In Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>User behavior modeling in e-commerce</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S1.SS1" title="In 4.1 User behavior modeling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.1 </span>Click behavior modeling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S1.SS2" title="In 4.1 User behavior modeling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.2 </span>Post-click behavior tracking</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S1.SS3" title="In 4.1 User behavior modeling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1.3 </span>Purchase-intent modeling</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S2" title="In Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>User profiling in e-commerce</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S2.SS1" title="In 4.2 User profiling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.1 </span>Types of user profiling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S2.SS2" title="In 4.2 User profiling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.2 </span>User profiling with social media</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S2.SS3" title="In 4.2 User profiling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2.3 </span>Graph-based user profiling</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S3" title="In Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Emerging directions</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S3.SS1" title="In 4.3 Emerging directions ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.1 </span>Graph learning for user behavior modeling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S3.SS2" title="In 4.3 Emerging directions ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.2 </span>Dynamic user behavior modeling and profiling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S3.SS3" title="In 4.3 Emerging directions ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3.3 </span>User modeling with insufficient data</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_chapter">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5" title="In Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>E-commerce search</span></a>
<ol class="ltx_toclist ltx_toclist_chapter">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S1" title="In Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Characteristics of e-commerce search</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S1.SS1" title="In 5.1 Characteristics of e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.1 </span>Overview of e-commerce search</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S1.SS2" title="In 5.1 Characteristics of e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1.2 </span>Challenges in e-commerce search</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S2" title="In Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Evaluation metrics</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S2.SS1" title="In 5.2 Evaluation metrics ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.1 </span>Relevance-based metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S2.SS2" title="In 5.2 Evaluation metrics ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.2 </span>Revenue-aware metrics</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S2.SS3" title="In 5.2 Evaluation metrics ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2.3 </span>User engagement metrics</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S3" title="In Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Matching strategies in e-commerce search</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S3.SS1" title="In 5.3 Matching strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.1 </span>Vocabulary gap</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S3.SS2" title="In 5.3 Matching strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.2 </span>Representation-based matching</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S3.SS3" title="In 5.3 Matching strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.3 </span>Interaction-based matching</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S3.SS4" title="In 5.3 Matching strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.4 </span>Hybrid matching</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S3.SS5" title="In 5.3 Matching strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3.5 </span>Matching in personalized search</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S4" title="In Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Ranking strategies in e-commerce search</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S5" title="In Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5 </span>Emerging directions</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S5.SS1" title="In 5.5 Emerging directions ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5.1 </span>Multi-modal e-commerce search</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S5.SS2" title="In 5.5 Emerging directions ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5.2 </span>Conversational e-commerce search</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S5.SS3" title="In 5.5 Emerging directions ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.5.3 </span>Generative retrieval in e-commerce</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_chapter">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6" title="In Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>E-commerce recommendation</span></a>
<ol class="ltx_toclist ltx_toclist_chapter">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S1" title="In Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Characteristics of e-commerce recommendation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S2" title="In Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Candidate retrieval models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S2.SS1" title="In 6.2 Candidate retrieval models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2.1 </span>Heuristic methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S2.SS2" title="In 6.2 Candidate retrieval models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2.2 </span>Embedding-based methods</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S2.SS3" title="In 6.2 Candidate retrieval models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2.3 </span>Session-based recommendation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S2.SS4" title="In 6.2 Candidate retrieval models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2.4 </span>Next-basket recommendation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S3" title="In Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Candidate ranking models</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S3.SS1" title="In 6.3 Candidate ranking models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3.1 </span>Linear models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S3.SS2" title="In 6.3 Candidate ranking models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3.2 </span>Polynomial models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S3.SS3" title="In 6.3 Candidate ranking models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3.3 </span>Neural network models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S3.SS4" title="In 6.3 Candidate ranking models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3.4 </span>Retraining strategies</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S4" title="In Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.4 </span>Re-ranking strategies</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S5" title="In Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.5 </span>Emerging directions</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S5.SS1" title="In 6.5 Emerging directions ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.5.1 </span>Structured recommendations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S5.SS2" title="In 6.5 Emerging directions ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.5.2 </span>Conversational recommendation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S5.SS3" title="In 6.5 Emerging directions ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.5.3 </span>Explainable e-commerce recommendation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S5.SS4" title="In 6.5 Emerging directions ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.5.4 </span>Biases and debiasing in recommendations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S5.SS5" title="In 6.5 Emerging directions ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.5.5 </span>Unifying recommendation and search</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S5.SS6" title="In 6.5 Emerging directions ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.5.6 </span>LLMs in recommendation</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_chapter">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7" title="In Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>E-commerce QA and conversations</span></a>
<ol class="ltx_toclist ltx_toclist_chapter">
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S1" title="In Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1 </span>Question answering in e-commerce</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S1.SS1" title="In 7.1 Question answering in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1.1 </span>Introduction to question answering</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S1.SS2" title="In 7.1 Question answering in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1.2 </span>Characteristics of e-commerce question answering</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S1.SS3" title="In 7.1 Question answering in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1.3 </span>Extractive product-aware QA</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S1.SS4" title="In 7.1 Question answering in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.1.4 </span>Generative product-aware QA</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S2" title="In Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2 </span>Dialogue systems in e-commerce</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S2.SS1" title="In 7.2 Dialogue systems in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2.1 </span>Introduction to dialogue systems</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S2.SS2" title="In 7.2 Dialogue systems in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2.2 </span>Task-oriented dialogue systems</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S2.SS3" title="In 7.2 Dialogue systems in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2.3 </span>Knowledge-grounded dialogue systems</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S2.SS4" title="In 7.2 Dialogue systems in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.2.4 </span>Empathetic dialogue generation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S3" title="In Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7.3 </span>Emerging directions</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_chapter">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch8" title="In Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8 </span>Conclusion and outlook</span></a>
<ol class="ltx_toclist ltx_toclist_chapter">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch8.S1" title="In Chapter 8 Conclusion and outlook ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.1 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch8.S2" title="In Chapter 8 Conclusion and outlook ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.2 </span>Outlook</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch8.S2.SS1" title="In 8.2 Outlook ‣ Chapter 8 Conclusion and outlook ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.2.1 </span>Four directions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch8.S2.SS2" title="In 8.2 Outlook ‣ Chapter 8 Conclusion and outlook ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">8.2.2 </span>Beyond accuracy</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#A1" title="In Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Datasets</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#A1.S1" title="In Appendix A Datasets ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Datasets for e-commerce infrastructures</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#A1.S2" title="In Appendix A Datasets ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Datasets for e-commerce user modeling</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#A1.S3" title="In Appendix A Datasets ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Datasets for e-commerce search</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#A1.S4" title="In Appendix A Datasets ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.4 </span>Datasets for e-commerce recommendations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#A1.S5" title="In Appendix A Datasets ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.5 </span>Datasets for e-commerce QA and dialogues</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Information Discovery in e-Commerce</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ren
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Zhaochun
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">He
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Xiangnan
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yin
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Dawei
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">de Rijke
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Maarten
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span>
<span class="ltx_contact ltx_role_affiliation">[
</span></span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1"><span class="ltx_text" id="id1.id1.1" lang="en">Electronic commerce, or e-commerce, is the buying and selling of goods and services, or the transmitting of funds or data online.
E-commerce platforms come in many kinds, with global players such as Amazon, Airbnb, Alibaba, Booking.com, eBay, JD.com and platforms targeting specific geographic regions such as Bol.com and Flipkart.com.
Information retrieval has a natural role to play in e-commerce, especially in connecting people to goods and services.
Information discovery in e-commerce concerns different types of search (e.g., exploratory search vs. lookup tasks), recommender systems, and natural language processing in e-commerce portals.
The rise in popularity of e-commerce sites has made research on information discovery in e-commerce an increasingly active research area.
This is witnessed by an increase in publications and dedicated workshops in this space.
Methods for information discovery in e-commerce largely focus on improving the effectiveness of e-commerce search and recommender systems, on enriching and using knowledge graphs to support e-commerce, and on developing innovative question answering and bot-based solutions that help to connect people to goods and services.
In this survey, an overview is given of the fundamental infrastructure, algorithms, and technical solutions for information discovery in e-commerce.
The topics covered include user behavior and profiling, search, recommendation, and language technology in e-commerce.</span></p>
</div>
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\PassOptionsToClass</span>
<p class="ltx_p" id="p1.2">book,bibernowfnt




























<span class="ltx_ERROR undefined" id="p1.2.1">\maintitleauthorlist</span>
Zhaochun Ren 
<br class="ltx_break"/>Leiden University 
<br class="ltx_break"/>z.ren@liacs.leidenuniv.nl
 and Xiangnan He 
<br class="ltx_break"/>University of Science and Technology of China 
<br class="ltx_break"/>xiangnanhe@gmail.com
 and Dawei Yin 
<br class="ltx_break"/>Baidu Inc. 
<br class="ltx_break"/>yindawei@acm.com
 and Maarten de Rijke 
<br class="ltx_break"/>University of Amsterdam 
<br class="ltx_break"/>m.derijke@uva.nl





1]Leiden University; z.ren@liacs.leidenuniv.nl
2]University of Science and Technology of China; xiangnanhe@gmail.com
3]Baidu Inc.; yindawei@acm.com
4]University of Amsterdam; m.derijke@uva.nl
<span class="ltx_ERROR undefined" id="p1.2.2">\issuesetup</span>copyrightowner=Z. Ren, X. He, D. Yin, and M. de Rijke,
volume = xx,
issue = xx,
pubyear = 2023,
isbn = xxx-x-xxxxx-xxx-x,
eisbn = xxx-x-xxxxx-xxx-x,
doi = 10.1561/XXXXXXXXX,
firstpage = 1, lastpage = 999


<span class="ltx_ERROR undefined" id="p1.2.3">\addbibresource</span>references.bib
<span class="ltx_ERROR undefined" id="p1.2.4">\articledatabox</span><span class="ltx_ERROR undefined" id="p1.2.5">\nowfntstandardcitation</span>
<span class="ltx_text" id="p1.2.6" lang="en"></span></p>
</div>
<div class="ltx_para" id="p2">
<span class="ltx_ERROR undefined" id="p2.1" lang="en">\makeabstracttitle</span>
</div>
<section class="ltx_chapter" id="Ch1" lang="en">
<h2 class="ltx_title ltx_title_chapter">
<span class="ltx_tag ltx_tag_chapter">Chapter 1 </span>Introduction</h2>
<section class="ltx_section" id="Ch1.S1">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1.1 </span>Motivation</h3>
<div class="ltx_para" id="Ch1.S1.p1">
<p class="ltx_p" id="Ch1.S1.p1.1">Over the past 20 years, we have seen the explosive growth of e-commerce portals, such as Alibaba, Amazon, eBay, and JD.com. These developments have reshaped people’s’ shopping habits.
Accordingly, an increasing number of customers now prefer to spend more time shopping online, generating billions of user requests per day.
As part of the process of serving customer requests, large volumes of multi-modal data, including user search logs, clicks, orders, reviews, images, and chat logs, etc., are being generated.
From an information retrieval point of view, discovering and employing pertinent information from the sheer volume of e-commerce data so as to enhance the performance of e-commerce services presents interesting challenges, both for academic and industrial researchers.
In this survey we describe those challenges and the solutions that the community has so far proposed.</p>
</div>
<div class="ltx_para" id="Ch1.S1.p2">
<p class="ltx_p" id="Ch1.S1.p2.1">The topics of information discovery in e-commerce can be divided into several main directions:</p>
<ul class="ltx_itemize" id="Ch1.S1.I1">
<li class="ltx_item" id="Ch1.S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch1.S1.I1.i1.p1">
<p class="ltx_p" id="Ch1.S1.I1.i1.p1.1">e-commerce presentations and users;</p>
</div>
</li>
<li class="ltx_item" id="Ch1.S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch1.S1.I1.i2.p1">
<p class="ltx_p" id="Ch1.S1.I1.i2.p1.1">user behavior and profiling;</p>
</div>
</li>
<li class="ltx_item" id="Ch1.S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch1.S1.I1.i3.p1">
<p class="ltx_p" id="Ch1.S1.I1.i3.p1.1">search in e-commerce;</p>
</div>
</li>
<li class="ltx_item" id="Ch1.S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch1.S1.I1.i4.p1">
<p class="ltx_p" id="Ch1.S1.I1.i4.p1.1">recommender systems in e-commerce; and</p>
</div>
</li>
<li class="ltx_item" id="Ch1.S1.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch1.S1.I1.i5.p1">
<p class="ltx_p" id="Ch1.S1.I1.i5.p1.1">question answering and dialogue systems in e-commerce.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="Ch1.S1.p3">
<p class="ltx_p" id="Ch1.S1.p3.1">Each of these areas comes with its own set of research challenges.
For example, in e-commerce search there may be no hypertext links between products, thus excluding an important type of ranking signal that is often used in the setting of web search.
But with click streams and order streams we have two parallel sources of ranking signal, a characteristic e-commerce feature that is absent from more traditional search scenarios.</p>
</div>
<div class="ltx_para" id="Ch1.S1.p4">
<p class="ltx_p" id="Ch1.S1.p4.1">E-commerce information discovery problems are wide in scope as the underlying discovery tasks concern a broad range of interaction modalities.
There is a growing body of established methods in the area, aimed at developing algorithms for analyzing user behavior, for product search in e-commerce, for recommender systems, and for question answering and dialogue systems.
These areas, and the methods developed, form the core around which most ongoing research efforts concerning information discovery for e-commerce are organized.
The time is right to organize this material and to present it to a broad audience of interested information retrieval researchers, whether junior or senior, whether academic or industrial <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">tsagkias-2020-challenges</span>]</cite>.</p>
</div>
</section>
<section class="ltx_section" id="Ch1.S2">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1.2 </span>Aims of this survey</h3>
<div class="ltx_para" id="Ch1.S2.p1">
<p class="ltx_p" id="Ch1.S2.p1.1">A key aim of this survey is to bring together, and offer a unified perspective on, the large number of methods for e-commerce information discovery available today.
To achieve this, we describe the basic architecture used for information discovery in e-commerce, algorithms for e-commerce information discovery, and evaluation principles.
We supplement this with an account of available datasets and software based on these.
We also introduce e-commerce applications accompanied by examples.</p>
</div>
<div class="ltx_para" id="Ch1.S2.p2">
<p class="ltx_p" id="Ch1.S2.p2.1">The survey targets practitioners and researchers from academia and industry and aims to present them with the challenges, state-of-the-art approaches, and the most urgent open questions in information discovery for e-commerce.
Specifically, in terms of content, the objectives of the survey are as follows:</p>
</div>
<div class="ltx_para" id="Ch1.S2.p3">
<ul class="ltx_itemize" id="Ch1.S2.I1">
<li class="ltx_item" id="Ch1.S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch1.S2.I1.i1.p1">
<p class="ltx_p" id="Ch1.S2.I1.i1.p1.1">To introduce tasks that constitute the information discovery problem in e-commerce, and to explain the difference between e-commerce information discovery and related work in other domains;</p>
</div>
</li>
<li class="ltx_item" id="Ch1.S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch1.S2.I1.i2.p1">
<p class="ltx_p" id="Ch1.S2.I1.i2.p1.1">To describe e-commerce information discovery algorithms in a unified way, i.e., using common notation and terminology, so that different models can easily be related to each other;</p>
</div>
</li>
<li class="ltx_item" id="Ch1.S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch1.S2.I1.i3.p1">
<p class="ltx_p" id="Ch1.S2.I1.i3.p1.1">To explain how to analyze the performance of e-commerce information discovery algorithms and why it is worth the effort;</p>
</div>
</li>
<li class="ltx_item" id="Ch1.S2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch1.S2.I1.i4.p1">
<p class="ltx_p" id="Ch1.S2.I1.i4.p1.1">To present appropriate experimental and evaluation methodologies for e-commerce information discovery in both synthetic and real world settings; and</p>
</div>
</li>
<li class="ltx_item" id="Ch1.S2.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch1.S2.I1.i5.p1">
<p class="ltx_p" id="Ch1.S2.I1.i5.p1.1">To discuss future directions of research in e-commerce information discovery.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="Ch1.S3">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1.3 </span>Outline</h3>
<div class="ltx_para" id="Ch1.S3.p1">
<p class="ltx_p" id="Ch1.S3.p1.1">Information discovery aims to distill pertinent information from datasets with various modalities; it plays a role in many areas, ranging from web search to academic search and medical search.
What is different about the e-commerce setting is that many traditional ranking features are either not present or present in a different form <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">degenhardt-ecom-2017</span>]</cite>.
Instead, discovery processes need to be supported based on structured information, semi-structured information, or information that might have facets such as price, ratings, title, description, seller location, etc.</p>
</div>
<section class="ltx_subsection" id="Ch1.S3.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.3.1 </span>Topics covered</h4>
<div class="ltx_para" id="Ch1.S3.SS1.p1">
<p class="ltx_p" id="Ch1.S3.SS1.p1.1">In this survey, we break the e-commerce information discovery problem down into five research directions:

<span class="ltx_inline-enumerate" id="Ch1.S3.I1">
<span class="ltx_inline-item" id="Ch1.S3.I1.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch1.S3.I1.i1.1">e-commerce information presentation and users,
</span></span>
<span class="ltx_inline-item" id="Ch1.S3.I1.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch1.S3.I1.i2.1">user behavior and profiling in e-commerce,
</span></span>
<span class="ltx_inline-item" id="Ch1.S3.I1.i3"><span class="ltx_tag ltx_tag_inline-item">(iii)</span> <span class="ltx_text" id="Ch1.S3.I1.i3.1">search in e-commerce,
</span></span>
<span class="ltx_inline-item" id="Ch1.S3.I1.i4"><span class="ltx_tag ltx_tag_inline-item">(iv)</span> <span class="ltx_text" id="Ch1.S3.I1.i4.1">recommendation in e-commerce, and
</span></span>
<span class="ltx_inline-item" id="Ch1.S3.I1.i5"><span class="ltx_tag ltx_tag_inline-item">(v)</span> <span class="ltx_text" id="Ch1.S3.I1.i5.1">question answering and dialogue systems in e-commerce.
</span></span>
</span>
Below, we briefly describe each of these five directions, respectively.</p>
</div>
<div class="ltx_para" id="Ch1.S3.SS1.p2">
<p class="ltx_p" id="Ch1.S3.SS1.p2.1">The first direction concerns preliminaries about e-commerce information presentation and users. E-commerce portals provide various modalities of information to users, e.g., rankings of products, product titles, descriptions, tips, and user reviews, etc.
Multiple genres and types of text analysis can be employed to enhance e-commerce services, e.g., review filtering, review analysis, and normalization of production descriptions. User characteristics in e-commerce, e.g., browsing modules, clicks, purchases, and dwell time, generate multiple patterns for e-commerce scenarios. These two factors play fundamental roles in e-commerce information discovery.
In this survey, we summarize recent work on both e-commerce information presentation and user characteristics.</p>
</div>
<div class="ltx_para" id="Ch1.S3.SS1.p3">
<p class="ltx_p" id="Ch1.S3.SS1.p3.1">The second direction concerns user behavior modeling and user profiling.
Tracking and profiling users’ behavior on e-commerce portals are important prerequisites for many e-commerce services, such as recommender systems, search, and online advertising.
In this survey, we summarize recent work on user behavior modeling in e-commerce and introduce solutions to profiling users of e-commerce services.</p>
</div>
<div class="ltx_para" id="Ch1.S3.SS1.p4">
<p class="ltx_p" id="Ch1.S3.SS1.p4.1">The third direction of this survey concerns search in e-commerce, which examines approaches for product search scenarios on e-commerce portals.
Just like, e.g., traditional web search, the target of this task is to satisfy users’ needs.
However, product search in e-commerce sites should be realized with different types of features than, e.g., web search, with the availability of a large number of product, query attributes, and engagement features.
Moreover, calculating of relevance in product search confronts more challenges about gaps between users and products. Additionally, the target corpora can be structured, semi-structured, or unstructured, or a mixture of these; semantic search against such diverse sources raises interesting research challenges.
</p>
</div>
<div class="ltx_para" id="Ch1.S3.SS1.p5">
<p class="ltx_p" id="Ch1.S3.SS1.p5.1">The fourth direction concerns recommendations in e-commerce.
In contrast to traditional research on recommender systems that focuses on rating prediction, e-commerce recommender systems aim to tackle three challenges: the huge volume of products, sparsity, and data richness.
Due to the existence of a very large number of candidate items in e-commerce portals, of which only a small fraction will attract a user’s attention, e-commerce recommendation methods usually follow a two-stage recommendation framework that contains two phases:

<span class="ltx_inline-enumerate" id="Ch1.S3.I2">
<span class="ltx_inline-item" id="Ch1.S3.I2.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch1.S3.I2.i1.1">candidate retrieval, and
</span></span>
<span class="ltx_inline-item" id="Ch1.S3.I2.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch1.S3.I2.i2.1">candidate ranking.
</span></span>
</span>
The first phase of candidate retrieval goes through the whole product catalog, and selects a small set of products that might match the information need.
The second phase of candidate ranking ranks the candidates to present the final top-<math alttext="K" class="ltx_Math" display="inline" id="Ch1.S3.SS1.p5.1.m1.1"><semantics id="Ch1.S3.SS1.p5.1.m1.1a"><mi id="Ch1.S3.SS1.p5.1.m1.1.1" xref="Ch1.S3.SS1.p5.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="Ch1.S3.SS1.p5.1.m1.1b"><ci id="Ch1.S3.SS1.p5.1.m1.1.1.cmml" xref="Ch1.S3.SS1.p5.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch1.S3.SS1.p5.1.m1.1c">K</annotation><annotation encoding="application/x-llamapun" id="Ch1.S3.SS1.p5.1.m1.1d">italic_K</annotation></semantics></math> products to the user.
Given structured user behavior logs and semi-structured data about product features, e-commerce knowledge bases can be created to assist the candidate generation step.
And the candidate ranking procedure ranks the retrieved candidate items for a better conversion rate or click-through rate, based on various machine learning models.</p>
</div>
<div class="ltx_para" id="Ch1.S3.SS1.p6">
<p class="ltx_p" id="Ch1.S3.SS1.p6.1">The fifth and final direction of this survey concerns question answering and dialogue systems in e-commerce.
We survey recent work on e-commerce question answering and dialogue systems that have attracted increased attention.
For dialogue systems, we describe both task-oriented dialogue systems, aimed at helping users complete a task in an e-commerce setting, and non-task-oriented dialogue systems aimed at generating fluent and engaging responses.</p>
</div>
<div class="ltx_para" id="Ch1.S3.SS1.p7">
<p class="ltx_p" id="Ch1.S3.SS1.p7.1">For the directions listed above, our ambition has been to cover related work up to the spring of 2023.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch1.S3.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.3.2 </span>Topics not covered</h4>
<div class="ltx_para" id="Ch1.S3.SS2.p1">
<p class="ltx_p" id="Ch1.S3.SS2.p1.1">E-commerce impacts large parts of our economy and society, including markets and retailers, supply chain management, and employment.
With the development of data science, business intelligence studies on e-commerce marketing, e.g., sales volume forecast and time series analysis, are receiving an increasing amount of attention.
All of these areas are important, scientifically challenging, and deserving of attention from the information retrieval community.
However, our focus will be limited to information discovery within the context of e-commerce. Specifically, we will not address topics such as computational advertising approaches that are irrelevant to search and recommendation, marketing strategies, forecasting, or information management in e-commerce.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch1.S3.SS3">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.3.3 </span>Structure of the survey</h4>
<div class="ltx_para" id="Ch1.S3.SS3.p1">
<p class="ltx_p" id="Ch1.S3.SS3.p1.1">The rest of this survey is organized as follows.
Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch2" title="Chapter 2 Definitions and background ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">2</span></a> provides key definitions and background related to e-commerce information discovery, drawing from user modeling, search, recommender systems, question-answering, and dialogue systems.
Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3" title="Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3</span></a> describes preliminaries of e-commerce presentations as well as e-commerce users, including user behavior characteristics, and relevant language technologies and their use in e-commerce applications;
Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4" title="Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4</span></a> details user behavior modeling and user profiling approaches in e-commerce, including click behavior tracking, post-click tracking, purchase behavior modeling, and user profiling in e-commerce.
Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5" title="Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5</span></a> describes recent approaches proposed for e-commerce search, which we organize along two lines: research about the matching problem in e-commerce search, and about ranking strategies for e-commerce search.
Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6" title="Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6</span></a> presents algorithms and solutions for recommender systems in e-commerce. After introducing the two-stage recommendation framework in e-commerce portals, we organize the e-commerce recommendation studies into two groups: candidate retrieval models and candidate ranking models.
We survey e-commerce question answering and dialogue systems in Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7" title="Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7</span></a>, where we introduce recent studies on e-commerce question answering and dialogue systems, respectively.
In Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch8" title="Chapter 8 Conclusion and outlook ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">8</span></a> we conclude this survey and identify emerging research directions and issues for future work.</p>
</div>
</section>
</section>
<section class="ltx_section" id="Ch1.S4">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1.4 </span>Our readers</h3>
<div class="ltx_para" id="Ch1.S4.p1">
<p class="ltx_p" id="Ch1.S4.p1.1">We expect this survey to be useful for both academic and industrial researchers who either want to develop e-commerce information discovery methods, use them in their own research, or apply the methods described in the survey to improve product performance in e-commerce services.
The intention is to help our audience acquire domain knowledge and to promote information discovery research activities in e-commerce.</p>
</div>
<div class="ltx_para" id="Ch1.S4.p2">
<p class="ltx_p" id="Ch1.S4.p2.1">To be able to benefit from this survey, we expect the reader to have a background in information retrieval, natural language processing, or machine learning.
We recommend that readers read the material that we offer from start to finish, in the order that we offer it. However, readers who have a specific interest in search, or in recommender systems, or in conversational technology in e-commerce should read Chapters <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3" title="Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4" title="Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4</span></a> first before skipping ahead to Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5" title="Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6" title="Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6</span></a>, or <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7" title="Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7</span></a>, respectively.</p>
</div>
</section>
</section>
<section class="ltx_chapter" id="Ch2" lang="en">
<h2 class="ltx_title ltx_title_chapter">
<span class="ltx_tag ltx_tag_chapter">Chapter 2 </span>Definitions and background</h2>
<div class="ltx_para" id="Ch2.p1">
<p class="ltx_p" id="Ch2.p1.1">The chapter presents definitions and background applied to e-commerce information discovery studies from the perspectives of research communities on user modeling, search, recommender systems, quesiton-answering, and dialogue systems.
Specifically, we first introduce background-relevant concepts about user modeling, information retrieval, recommender systems, and conversational AI.
Thereafter, we introduce definitions and notations associated with e-commerce information discovery. Next, we explore fundamental concepts in e-commerce information discovery, including e-commerce information presentation, e-commerce search, e-commerce recommendation, and e-commerce conversational AI systems. The glossary and notations attached to this concept are introduced in the last part of this chapter.</p>
</div>
<section class="ltx_section" id="Ch2.S1">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2.1 </span>Background</h3>
<div class="ltx_para" id="Ch2.S1.p1">
<p class="ltx_p" id="Ch2.S1.p1.1">E-commerce has revolutionized how consumers interact with products and services, fundamentally altering the landscape of information discovery. There are plenty of relevant research perspectives on information discovery in e-commerce. Unlike traditional retailing settings, where physical exploration and interaction drive decision-making, e-commerce relies on digital mechanisms to guide users through vast and often overwhelming amounts of information. As a result, the effectiveness of e-commerce platforms hinges on their ability to deliver personalized, relevant, and timely information to users.</p>
</div>
<div class="ltx_para" id="Ch2.S1.p2">
<p class="ltx_p" id="Ch2.S1.p2.1">Various research disciplines—such as user modeling, information retrieval, recommender systems, question-answering, and conversational AI—contribute significantly to enhancing the e-commerce experience. Each of these fields offers unique insights and methodologies for addressing key challenges in e-commerce, such as understanding user intent, predicting user preferences, addressing user concerns, satisfying user needs, and facilitating seamless product discovery. Targeting on guiding the following chapters, we list the fundamental concepts and research perspectives behind these areas, laying the groundwork for understanding how e-commerce platforms enable efficient and effective information discovery for users.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch2.S1.p3">
<p class="ltx_p" id="Ch2.S1.p3.1"><span class="ltx_text ltx_font_bold" id="Ch2.S1.p3.1.1">Information discovery in e-commerce.</span>
In the context of e-commerce, information discovery refers to the process by which users engage with relevant products or services based on their specific needs, regardless of the format or presentation of that information. This process encompasses a variety of functions, including search, recommendation, and personalized content delivery and presentation. At its core, information discovery in e-commerce involves not only retrieving relevant products but also understanding user intent and preferences to provide the most suitable results. It relies on sophisticated algorithms to identify, search, recommend, and display information that aligns with user requirements. Whether through search queries, personalized recommendations, or curated content, information discovery systems enable users to efficiently navigate large product catalogs and find what they need in a seamless, engaging manner.</p>
</div>
</section>
<section class="ltx_section" id="Ch2.S2">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2.2 </span>User modeling</h3>
<div class="ltx_para" id="Ch2.S2.p1">
<p class="ltx_p" id="Ch2.S2.p1.1">User modeling refers to the process of creating a representation of a user’s characteristics, behaviors, preferences, and goals in order to personalize user-system interactions or appropriate content for that user. It is widely used in various fields like information retrieval, recommender systems, conversational AI, etc. User modeling is a critical component of personalizing e-commerce experiences. It involves the construction of user profiles based on behavioral data, preferences, demographics, and interactions within the system. These profiles help systems adapt content, recommendations, and interactions to suit individual needs.
Meanwhile, e-commerce platforms present information in various formats, such as lists, grids, or interactive elements, which can significantly affect user engagement and conversion rates. Understanding user behavior and preferences by optimizing these presentations is also important for enhancing user experience and satisfaction.</p>
</div>
<div class="ltx_para" id="Ch2.S2.p2">
<p class="ltx_p" id="Ch2.S2.p2.1">In e-commerce, user modeling can leverage implicit feedback (e.g., clicks, purchases, carting, and user engagement) and explicit feedback (e.g., ratings and reviews) to predict the user future behaviors, preferences, and profiling. Techniques like collaborative filtering, content-based filtering, and hybrid models are frequently employed in user modeling during early studies on this topic. In recent years, deep neural networks and pre-trained language models have been successfully applied to user modeling in e-commerce portals.From a broader research perspective, user modeling spans across domains such as cognitive science, machine learning, and human-computer interaction, contributing to the development of systems that continuously refine the understanding of users as they interact with the platform.</p>
</div>
</section>
<section class="ltx_section" id="Ch2.S3">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2.3 </span>Information retrieval in e-commerce</h3>
<div class="ltx_para" id="Ch2.S3.p1">
<p class="ltx_p" id="Ch2.S3.p1.1">Information retrieval (IR) has been playing a critical role in e-commerce services. Search and recommendation functionalities have been applied to e-commerce portals almost since the beginning of e-commerce.
Beyond traditional search functionalities, IR techniques have evolved to support a wide range of features, including search and recommendation, making them essential for delivering a seamless user engagement. In e-commerce platforms, IR techniques are responsible for retrieving relevant items from a vast product catalog based on a user’s query or search intent. This process involves not only matching query terms to product descriptions but also understanding the broader context behind the query, such as user preferences, purchase history, and real-time behaviors.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch2.S3.p2">
<p class="ltx_p" id="Ch2.S3.p2.1"><span class="ltx_text ltx_font_bold" id="Ch2.S3.p2.1.1">E-commerce search.</span>
E-commerce search involves techniques and algorithms used to allow users to efficiently find products or services within an online store. This includes the use of keywords, filters, and advanced semantic search technologies. The e-commerce search differs from traditional information retrieval because it often focuses on product features, pricing, availability, and user preferences. Research in this area spans areas like query understanding, ranking algorithms, and the integration of multimodal data (e.g., images and reviews).</p>
</div>
<div class="ltx_para" id="Ch2.S3.p3">
<p class="ltx_p" id="Ch2.S3.p3.1">The effectiveness of an e-commerce search engine depends heavily on how well it can interpret user queries and match them with appropriate products or services. With natural language processing methods, query understanding and expansion techniques are playing an important role to bridge the semantic gap between queries and product information during this procedure, allowing the system to understand complex, ambiguous, or conversational queries from users. For example, users might search for “affordable running shoes for winter,” which requires the platform to parse the query, infer user intent (i.e., shoes for running in cold weather), and prioritize products based on pricing and seasonal relevance. Semantic search in e-commerce techniques go beyond keyword matching by understanding the user query and correlations between key entities, enabling more context-aware results.
Search engines in e-commerce also rely on machine learning models that take into account user intent, contextual data, and preferences to deliver highly relevant search results.
Additionally, search engines in e-commerce must address unique challenges like scalability and diversity. With product catalogs growing rapidly, search engines must efficiently process and rank millions of items in real-time. Advanced ranking algorithms, often powered by machine learning, play a vital role in this process, optimizing for both relevance and user engagement metrics such as click-through rates or conversion rates.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch2.S3.p4">
<p class="ltx_p" id="Ch2.S3.p4.1"><span class="ltx_text ltx_font_bold" id="Ch2.S3.p4.1.1">E-commerce recommendations.</span>
Moreover, IR in e-commerce is increasingly intertwined with recommender systems.
Recommender systems are a cornerstone of e-commerce platforms, helping users discover products they might not have explicitly searched for but are likely to find appealing. These systems predict user preferences using collaborative filtering, content-based filtering, or hybrid methods that combine both approaches.
While search engines retrieve items explicitly requested by the user (i.e., with queries), recommendations anticipate user needs by suggesting products the user may not have thought to search for.
These systems analyze user data, such as browsing history, purchase patterns, and interactions, to suggest relevant items. They typically use a combination of techniques, including collaborative filtering, which recommends products based on the behaviors of similar users, and content-based filtering, which suggests items with attributes similar to those the user has shown interest in. Many modern systems employ hybrid models that integrate both methods, sometimes enhanced with advanced techniques like deep learning, to improve accuracy and diversity.
By delivering personalized recommendations, these systems not only enhance user experience but also drive business goals by increasing engagement, conversion rates, and customer satisfaction, all while introducing users to new products that may surprise or delight them.</p>
</div>
<div class="ltx_para" id="Ch2.S3.p5">
<p class="ltx_p" id="Ch2.S3.p5.1">Recommendation systems in e-commerce analyze user data and behavioral patterns to suggest products or services that users are likely to be interested in. These systems utilize various algorithms, including collaborative filtering, content-based filtering, and hybrid approaches.
In the context of e-commerce, recommender systems must balance relevance, diversity, novelty, and serendipity to enhance user engagement and satisfaction. By dividing into candidate retrieval and reranking stages, these systems often operate in two modes: personalized recommendations (based on individual profiles and history) and non-personalized recommendations (based on overall product popularity or trends). Research in recommender systems for e-commerce involves improving recommendation algorithms, addressing challenges like cold-start users, and optimizing recommendations for business goals such as conversion rates and customer retention.</p>
</div>
<div class="ltx_para" id="Ch2.S3.p6">
<p class="ltx_p" id="Ch2.S3.p6.1">In summary, information retrieval is foundational to the search and recommendation functions within e-commerce platforms.
This convergence between search and recommendation highlights the importance of IR techniques that can balance precision (retrieving highly relevant products) with recall (offering a broader set of options that might interest the user). Hybrid models that combine collaborative filtering, content-based filtering, and neural IR approaches are commonly employed to address this dual need.
The integration of advanced IR techniques, such as search and recommendation models, allows e-commerce platforms to deliver highly personalized, efficient, and contextually relevant user experiences, ensuring that users find the products they want—and even those they didn’t know they wanted.</p>
</div>
</section>
<section class="ltx_section" id="Ch2.S4">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2.4 </span>Conversational AI</h3>
<div class="ltx_para" id="Ch2.S4.p1">
<p class="ltx_p" id="Ch2.S4.p1.1">Conversational artificial intelligence (AI) techniques refer to technologies that enable natural, human-like interactions between users and machines through conversational communication. These interactions can be categorized into single-turn and multi-turn scenarios, corresponding to question-answering systems and dialogue systems, respectively.
During the interactions, conversational AI aims to understand user input, process context, and generate meaningful, human-like responses. Conversational AI is used in various applications, such as virtual assistants, customer support, and personal productivity tools. These systems can handle simple queries as well as complex, multi-turn conversations, adapting to user needs and improving over time through continuous learning. By mimicking human conversation patterns, conversational AI allows for more intuitive and accessible interactions, making it a valuable tool for enhancing communication between users and machines.</p>
</div>
<div class="ltx_para" id="Ch2.S4.p2">
<p class="ltx_p" id="Ch2.S4.p2.1">In e-commerce, chatbots and QA services powered by conversational AI can help users find relevant products, provide recommendations, and even complete transactions seamlessly. By offering a more engaging and interactive way for customers to interact with e-commerce platforms, conversational AI improves user satisfaction, increases engagement, and reduces the friction often associated with traditional search and navigation methods.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch2.S4.p3">
<p class="ltx_p" id="Ch2.S4.p3.1"><span class="ltx_text ltx_font_bold" id="Ch2.S4.p3.1.1">E-commerce question-answering.</span>
Question-answering (QA) systems are designed to deliver direct and precise responses to user questions, improving both user satisfaction and decision-making efficiency.
Recently, more and more e-commerce platforms start to provide question-answering services. E-commerce QA systems help to enhance user experiences by enabling customers to obtain relevant, concise, and accurate answers to their product-related queries. These systems typically understand user intent and either retrieve answers from existing product descriptions, reviews, and FAQs or generate responses dynamically using advanced models.

E-commerce question-answering refers to the process in which users ask product-related questions on an e-commerce platform, and the system provides answers either from existing knowledge bases, reviews, or user-generated content. E-commerce QA systems leverage both retrieval-based and generative models to match or generate appropriate answers. This helps users make informed decisions based on product descriptions, user reviews, and frequently asked questions (FAQs). The goal is to reduce information overload and improve the user experience by providing relevant and concise answers.</p>
</div>
<div class="ltx_para" id="Ch2.S4.p4">
<p class="ltx_p" id="Ch2.S4.p4.1">E-commerce QA systems must handle a wide variety of queries ranging from simple fact-based questions (e.g., "What is the price of this product?") to more complex inquiries about product specifications, reviews, or usage (e.g., "Is this laptop suitable for gaming?"). To address this diversity, QA systems often incorporate a mix of retrieval-based approaches, which search for relevant information in structured data or knowledge bases, and generative approaches, which generate answers when information is sparse or not directly available. Additionally, many e-commerce platforms enable community-based QA, where previous buyers or users of a product can contribute answers, further enriching the system’s knowledge base.
The integration of QA systems into e-commerce portals helps reduce the friction often associated with product discovery and decision-making. By offering immediate answers to user queries, these systems improve the overall shopping experience, increase user engagement, and can positively impact conversion rates.
E-commerce QA is a rapidly evolving field with ongoing research aimed at improving the accuracy, efficiency, and personalization of responses.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch2.S4.p5">
<p class="ltx_p" id="Ch2.S4.p5.1"><span class="ltx_text ltx_font_bold" id="Ch2.S4.p5.1.1">E-commerce automatic dialogue systems.</span>
Automatic dialogue systems aim to engage in natural, human-like conversations with users and are widely used in applications such as customer support, virtual assistants, and e-commerce. They provide personalized, efficient, and engaging interactions, enhancing the overall user experience. In e-commerce, automatic dialogue systems, often in the form of chatbots or voice assistants, enable natural language interactions between users and platforms.
They can support multi-turn interactions, where users ask follow-up questions, refine their preferences, or seek assistance, creating a more engaging and personalized shopping experience.
These systems assist users in discovering information, finding products, completing purchases, and sharing their opinions, all through conversational interfaces.
Systematically, automatic dialogue systems in e-commerce refers to the use of chatbots and virtual assistants that can simulate a human conversation to assist users in finding products, answering inquiries, and facilitating transactions. These systems leverage natural language processing and machine learning to provide timely and relevant assistance.</p>
</div>
<div class="ltx_para" id="Ch2.S4.p6">
<p class="ltx_p" id="Ch2.S4.p6.1">Towards both single-turn and multi-turn interactions between users and systems, research in conversational AI for e-commerce focuses on improving dialogue understanding, response generation, context retention across sessions, and user satisfaction. Additionally, conversational AI systems must adapt to diverse user needs and accommodate various languages and cultural contexts, making this an evolving area of study.</p>
</div>
</section>
</section>
<section class="ltx_chapter" id="Ch3" lang="en">
<h2 class="ltx_title ltx_title_chapter">
<span class="ltx_tag ltx_tag_chapter">Chapter 3 </span>E-commerce presentations and users</h2>
<div class="ltx_para" id="Ch3.p1">
<p class="ltx_p" id="Ch3.p1.1">E-commerce presentations are composed of a series of user-facing components in e-commerce portals, e.g., various pages about items and categories, titles of items, user comments on item pages, search bars, and recommendation list.
Such functions provided by e-commerce portals are meant to enable interactions with users on e-commerce platforms.
E-commerce users possess unique characteristics.
There are multiple types of user behavior and feedback on an e-commerce platform, e.g., search, clicks, add-to-carts, purchases, returns, comments, and discussions with retailers. These unique characteristics of e-commerce users provide a rich source of information about the successes and failures of e-commerce platforms in helping users discover the items they need.</p>
</div>
<div class="ltx_para" id="Ch3.p2">
<p class="ltx_p" id="Ch3.p2.1">We divide this chapter into two sections: e-commerce presentations (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S1" title="3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.1</span></a>) and e-commerce users (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S2" title="3.2 E-commerce users ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.2</span></a>). In Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S1" title="3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.1</span></a>, we first introduce basic concepts of e-commerce interfaces; then we detail studies that analyze different aspects of e-commerce presentations, i.e., title analysis, item information analysis, and review analysis.
In Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S2" title="3.2 E-commerce users ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.2</span></a>, we list characteristics of e-commerce users, and examine user behavior on e-commerce portals, i.e., macro behavior, micro behavior and cross-platform behavior.</p>
</div>
<section class="ltx_section" id="Ch3.S1">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3.1 </span>E-commerce presentations</h3>
<div class="ltx_para" id="Ch3.S1.p1">
<p class="ltx_p" id="Ch3.S1.p1.1">In this section, we cover two aspects of e-commerce presenations:

<span class="ltx_inline-enumerate" id="Ch3.S1.I1">
<span class="ltx_inline-item" id="Ch3.S1.I1.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch3.S1.I1.i1.1">basic concepts and types of e-commerce interface (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S1.SS1" title="3.1.1 Basic concepts ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.1.1</span></a>), and
</span></span>
<span class="ltx_inline-item" id="Ch3.S1.I1.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch3.S1.I1.i2.1">e-commerce presentation analysis (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S1.SS2" title="3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.1.2</span></a>).
</span></span>
</span></p>
</div>
<section class="ltx_subsection" id="Ch3.S1.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1.1 </span>Basic concepts</h4>
<div class="ltx_para" id="Ch3.S1.SS1.p1">
<p class="ltx_p" id="Ch3.S1.SS1.p1.1">An <em class="ltx_emph ltx_font_italic" id="Ch3.S1.SS1.p1.1.1">interface</em> refers to an interactive component of a webpage or an application <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">hearst-2009-search</span>]</cite>.
Referring to all interactive components on e-commerce portals (e.g., search bars, navigation panels, lists of recommended items, item titles, and user reviews), e-commerce interfaces are playing invaluable role for the e-commerce user experience.
Therefore, e-commerce interfaces dramatically impact the performance of an e-commerce platform.
Depending on the nature of the stakeholders involved, most e-commerce sites can be divided into four types of business: <em class="ltx_emph ltx_font_italic" id="Ch3.S1.SS1.p1.1.2">business-to-business</em>, <em class="ltx_emph ltx_font_italic" id="Ch3.S1.SS1.p1.1.3">business-to-consumer</em>, <em class="ltx_emph ltx_font_italic" id="Ch3.S1.SS1.p1.1.4">consumer-to-consumer</em>, and <em class="ltx_emph ltx_font_italic" id="Ch3.S1.SS1.p1.1.5">consumer-to-business</em> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">nemat2011taking</span>]</cite>:</p>
</div>
<div class="ltx_para" id="Ch3.S1.SS1.p2">
<dl class="ltx_description" id="Ch3.S1.I2">
<dt class="ltx_item" id="Ch3.S1.I2.ix1"><span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="Ch3.S1.I2.ix1.1.1.1">B2B: Business to Business</span></span></dt>
<dd class="ltx_item">
<div class="ltx_para" id="Ch3.S1.I2.ix1.p1">
<p class="ltx_p" id="Ch3.S1.I2.ix1.p1.1">This type of e-commerce business focuses on electronic transactions of goods or services between two corporations, i.e., one company uses the e-commerce site to sell items to another company. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F1" title="Figure 3.1 ‣ 3.1.1 Basic concepts ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.1</span></a>(1) shows an example of the interface used in a B2B setting.</p>
</div>
</dd>
<dt class="ltx_item" id="Ch3.S1.I2.ix2"><span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="Ch3.S1.I2.ix2.1.1.1">B2C: Business to Consumer</span></span></dt>
<dd class="ltx_item">
<div class="ltx_para" id="Ch3.S1.I2.ix2.p1">
<p class="ltx_p" id="Ch3.S1.I2.ix2.p1.1">B2C indicates scenarios where businesses directly sell items to consumers. Most online shopping platforms, such as Amazon, Booking.com, and JD.com belong to this type of business. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F1" title="Figure 3.1 ‣ 3.1.1 Basic concepts ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.1</span></a>(2) shows an item page from Amazon as an example of the interface used by B2C businesses.</p>
</div>
</dd>
<dt class="ltx_item" id="Ch3.S1.I2.ix3"><span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="Ch3.S1.I2.ix3.1.1.1">C2B: Consumer to Business</span></span></dt>
<dd class="ltx_item">
<div class="ltx_para" id="Ch3.S1.I2.ix3.p1">
<p class="ltx_p" id="Ch3.S1.I2.ix3.p1.1">Instead of a business retailing items to consumers, C2B sites such as UpWork<span class="ltx_note ltx_role_footnote" id="Ch3.footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.upwork.com" title="">https://www.upwork.com</a></span></span></span> cater for a scenario where consumers provide services to businesses. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F1" title="Figure 3.1 ‣ 3.1.1 Basic concepts ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.1</span></a>(3) provides a screenshot from Upwork as an example of a C2B interface.</p>
</div>
</dd>
<dt class="ltx_item" id="Ch3.S1.I2.ix4"><span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="Ch3.S1.I2.ix4.1.1.1">C2C: Consumer to Consumer</span></span></dt>
<dd class="ltx_item">
<div class="ltx_para" id="Ch3.S1.I2.ix4.p1">
<p class="ltx_p" id="Ch3.S1.I2.ix4.p1.1">C2C refers to a type of e-commerce business where both retailers and buyers are consumers, while the C2C site itself benefits from commission fees that are normally paid by the seller. eBay is a well-known example of C2C business. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F1" title="Figure 3.1 ‣ 3.1.1 Basic concepts ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.1</span></a>(4) lists a screenshot from eBay as an example of a C2C business interface.</p>
</div>
</dd>
</dl>
</div>
<figure class="ltx_figure" id="Ch3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="168" id="Ch3.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.1: </span>Four types of e-commerce businesses examples. Image sources: Alibaba.com, Amazon.com, UpWork.com, and EBay.com.</figcaption>
</figure>
<div class="ltx_para" id="Ch3.S1.SS1.p3">
<p class="ltx_p" id="Ch3.S1.SS1.p3.1">Like other web interfaces, e-commerce interfaces are evaluated in terms of user satisfaction <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">vergo2002commerce</span>]</cite>. Thus, different communities of users are usually catered for with different interfaces that are designed to accommodate for their tastes and shopping interests.
Three ingredients are shared by virtually all e-commerce interface designs:</p>
<ul class="ltx_itemize" id="Ch3.S1.I3">
<li class="ltx_item" id="Ch3.S1.I3.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch3.S1.I3.i1.p1">
<p class="ltx_p" id="Ch3.S1.I3.i1.p1.1"><span class="ltx_text ltx_font_bold" id="Ch3.S1.I3.i1.p1.1.1">navigation options</span>, which refer to elements that help users reach a certain part of the e-commerce platform, e.g., search bars, paginations, and universal menus;</p>
</div>
</li>
<li class="ltx_item" id="Ch3.S1.I3.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch3.S1.I3.i2.p1">
<p class="ltx_p" id="Ch3.S1.I3.i2.p1.1"><span class="ltx_text ltx_font_bold" id="Ch3.S1.I3.i2.p1.1.1">input options</span>, which are elements of an e-commerce platform for which the user provides input from their end, e.g., search bars, checkboxes, dropdown lists, dropdown buttons, toggles, and other text fields; and</p>
</div>
</li>
<li class="ltx_item" id="Ch3.S1.I3.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch3.S1.I3.i3.p1">
<p class="ltx_p" id="Ch3.S1.I3.i3.p1.1"><span class="ltx_text ltx_font_bold" id="Ch3.S1.I3.i3.p1.1.1">information components</span>, which are composed of various types of information about the products or services listed on e-commerce platforms, such as search results, recommendation results, item titles, images, item information, question answer pairs, user reviews, and tooltips.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="Ch3.S1.SS1.p4">
<p class="ltx_p" id="Ch3.S1.SS1.p4.1">As we dive into the problem of information discovery in e-commerce, information components are our main focus in this section.
We find that almost every e-commerce site provides six information components: <em class="ltx_emph ltx_font_italic" id="Ch3.S1.SS1.p4.1.1">search results</em>, <em class="ltx_emph ltx_font_italic" id="Ch3.S1.SS1.p4.1.2">recommendation results</em>, <em class="ltx_emph ltx_font_italic" id="Ch3.S1.SS1.p4.1.3">item titles</em>, <em class="ltx_emph ltx_font_italic" id="Ch3.S1.SS1.p4.1.4">item features and descriptions</em>, <em class="ltx_emph ltx_font_italic" id="Ch3.S1.SS1.p4.1.5">question answer pairs</em>, and <em class="ltx_emph ltx_font_italic" id="Ch3.S1.SS1.p4.1.6">user reviews of the item</em>.
In Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S1.SS2" title="3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.1.2</span></a>, we describe studies on information interface analysis of these six components.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch3.S1.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1.2 </span>Analyzing information components</h4>
<div class="ltx_para" id="Ch3.S1.SS2.p1">
<p class="ltx_p" id="Ch3.S1.SS2.p1.1">Many studies have been devoted to analyzing the effect of different information components. In this section, we summarize studies that focus on search results, recommendation results, titles, item descriptions, question answering, and reviews, respectively.</p>
</div>
<section class="ltx_subsubsection" id="Ch3.S1.SS2.SSS1">
<h5 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2.1 </span>Search results in e-commerce</h5>
<div class="ltx_para" id="Ch3.S1.SS2.SSS1.p1">
<p class="ltx_p" id="Ch3.S1.SS2.SSS1.p1.1">For all e-commerce information components, search and recommendation are the two main tasks in most of e-commerce platforms.
E-commerce search engines are often the starting points for many online consumers <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span>]</cite>.
E-commerce sites typically feature two-stage search interfaces.
As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F2" title="Figure 3.2 ‣ 3.1.2.1 Search results in e-commerce ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.2</span></a>, in an e-commerce search session,<span class="ltx_note ltx_role_footnote" id="Ch3.footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>As defined in web-based search engines, a search session refers to all queries made by a user in a particular time period with a consistent underlying user need <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">eickhoff2014lessons</span>]</cite>.</span></span></span> a consumer first searches using a query, leading to a result page, and then selects an item to click on the result page; after that, the user decides whether or not to purchase the item by examining its detailed description on the so-called item page.</p>
</div>
<figure class="ltx_figure" id="Ch3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="501" id="Ch3.F2.g1" src="x2.png" width="788"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.2: </span>Illustration of a sample search session in an e-commerce platform. The query is “rosy wedding dress,” and the search result page is shown on the left and a portion of the item page for two items is shown on the right. This search session consists of two stages:
(i) selecting an item to click from a ranked list, and
(ii) deciding whether to purchase the item by reading its detailed description.
Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span>]</cite>. </figcaption>
</figure>
<div class="ltx_para" id="Ch3.S1.SS2.SSS1.p2">
<p class="ltx_p" id="Ch3.S1.SS2.SSS1.p2.1">E-commerce search engines provide category options with the search bar.
During the early development of e-commerce search, interfaces of different types have been considered, e.g., devoted type, divided type, co-existing type, and multi-page type <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lu2006clustering</span>]</cite>.
But with the development of e-commerce search, these types of interfaces have been blended by e-commerce platforms.
Currently, a typical e-commerce search system includes three main components: query processing, candidate retrieval and ranking <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2020towards</span>]</cite>.
In query processing, the search engine rewrites a query from the user into a term-based representation that can be processed by downstream components.
In the candidate retrieval stage, the system uses the inverted index to retrieve candidate products to match queries.
Finally, the ranking component orders the retrieved candidates based on factors such as relevance, and predicted conversion ratio.
We will discuss research about principles and strategies of all these three components in Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5" title="Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5</span></a> with more details.</p>
</div>
</section>
<section class="ltx_subsubsection" id="Ch3.S1.SS2.SSS2">
<h5 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2.2 </span>Recommendation results in e-commerce platforms</h5>
<div class="ltx_para" id="Ch3.S1.SS2.SSS2.p1">
<p class="ltx_p" id="Ch3.S1.SS2.SSS2.p1.1">For many e-commerce platforms, recommendation is becoming the most important service to help users find their needed items.
E.g., recommendations have been reported to contribute to the majority of both revenue and traffic in Taobao <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2018billion</span>]</cite>, where one billion users can be connected to two billion items.
To this end, the homepage on the mobile Taobao app is generated based on consumers’ past behavior via recommendation algorithms, as illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F3" title="Figure 3.3 ‣ 3.1.2.2 Recommendation results in e-commerce platforms ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.3</span></a>.</p>
</div>
<figure class="ltx_figure" id="Ch3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="503" id="Ch3.F3.g1" src="x3.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.3: </span>E-commerce recommendation scenarios in Taobao. The areas highlighted with dashed rectangles are personalized for users. Images and textual descriptions are also generated for better user experience. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2018billion</span>]</cite>. </figcaption>
</figure>
<div class="ltx_para" id="Ch3.S1.SS2.SSS2.p2">
<p class="ltx_p" id="Ch3.S1.SS2.SSS2.p2.1">Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F3" title="Figure 3.3 ‣ 3.1.2.2 Recommendation results in e-commerce platforms ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.3</span></a> shows three recommendation areas displayed on the home page: a list of recommendation interfaces, a “popular products” list, and a promotion list, respectively.
Each recommendation area is provided based on users’ past behaviors with recommendation strategies.
As user behavior varies between scenarios, the recommendation strategy also needs to consider specific patterns and user preferences specific for each recommendation scenario.
For example, on the item page, the recommendation strategy needs to provide either relevant or similar items to the item that the user is focusing on, whereas the recommendation list on the home page shows the recommendation results considering the user’s personalized preferences <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhouwsdm2018</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch3.S1.SS2.SSS2.p3">
<p class="ltx_p" id="Ch3.S1.SS2.SSS2.p3.1">Different types of recommendation results may be shown at different stages of a customer’s.
Examples include “substitutes” (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F4.sf1" title="In Figure 3.4 ‣ 3.1.2.3 Product titles in e-commerce platforms ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.4(a)</span></a> and “complementary items” before and after the user adds a product to their cart (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F4.sf2" title="In Figure 3.4 ‣ 3.1.2.3 Product titles in e-commerce platforms ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.4(b)</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F4.sf3" title="In Figure 3.4 ‣ 3.1.2.3 Product titles in e-commerce platforms ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.4(c)</span></a>, respectively).
Once the consumer clicks a recommended product, the system will automatically jump to the product detail page, which includes product titles, product descriptions, categories, ratings, and reviews.
We will discuss more details about strategies and technologies of e-commerce recommendation in Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6" title="Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="Ch3.S1.SS2.SSS3">
<h5 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2.3 </span>Product titles in e-commerce platforms</h5>
<figure class="ltx_figure" id="Ch3.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="Ch3.F4.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="376" id="Ch3.F4.sf1.g1" src="x4.png" width="266"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Ch3.F4.sf1.2.1.1" style="font-size:80%;">(a)</span> </span><span class="ltx_text" id="Ch3.F4.sf1.3.2" style="font-size:80%;">JD.com</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="Ch3.F4.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="376" id="Ch3.F4.sf2.g1" src="x5.png" width="266"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Ch3.F4.sf2.2.1.1" style="font-size:80%;">(b)</span> </span><span class="ltx_text" id="Ch3.F4.sf2.3.2" style="font-size:80%;">Amazon</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="Ch3.F4.sf3"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="376" id="Ch3.F4.sf3.g1" src="x6.png" width="266"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Ch3.F4.sf3.2.1.1" style="font-size:80%;">(c)</span> </span><span class="ltx_text" id="Ch3.F4.sf3.3.2" style="font-size:80%;">Tmall.com</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.4: </span>Recommendation results exposed to users in three e-commerce platforms. Image sources: <a class="ltx_ref ltx_url ltx_font_typewriter" href="JD.com" title="">JD.com</a>, <a class="ltx_ref ltx_url ltx_font_typewriter" href="Amazon.com" title="">Amazon.com</a>, and <a class="ltx_ref ltx_url ltx_font_typewriter" href="Tmall.com" title="">Tmall.com</a>.</figcaption>
</figure>
<div class="ltx_para" id="Ch3.S1.SS2.SSS3.p1">
<p class="ltx_p" id="Ch3.S1.SS2.SSS3.p1.1">Product titles and their images are uploaded by suppliers to showcase their items.
As most e-commerce platforms at least provide search and recommendation services based on information in the titles, retailers have applied many search engine optimization strategies to titles <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ledford2015search</span>]</cite>.
As a result, lots of item titles are lengthy, over-informative, and sometimes incorrect.
Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F5" title="Figure 3.5 ‣ 3.1.2.3 Product titles in e-commerce platforms ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.5</span></a>(b) provides an example from Tmall, the largest B2C online shopping platform in China, where the item title is composed of more than 30 Chinese words.
But when a customer browses an item on Tmall Apps, fewer than 10 Chinese words can be displayed due to screen size limitations (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F5" title="Figure 3.5 ‣ 3.1.2.3 Product titles in e-commerce platforms ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.5</span></a>(a)).
Thus, lengthy and verbose titles are inconvenient for mobile e-commerce users to search items on e-commerce platforms.
Similarly, it has been reported that item titles with less than 80 characters improve the shopping experience on Amazon, because these shorter titles make it easier for customers to find products.<span class="ltx_note ltx_role_footnote" id="Ch3.footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://sellercentral.amazon.com/forums/message.jspa?messageID=2921001" title="">https://sellercentral.amazon.com/forums/message.jspa?messageID=2921001</a></span></span></span>
Accordingly, research on e-commerce title analysis mainly focuses on obtaining effective compression or summaries of lengthy item titles for e-commerce search.</p>
</div>
<figure class="ltx_figure" id="Ch3.F5">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="Ch3.F5.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="340" id="Ch3.F5.sf1.g1" src="extracted/5921744/figs/SRP2.png" width="287"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Ch3.F5.sf1.2.1.1" style="font-size:80%;">(a)</span> </span><span class="ltx_text" id="Ch3.F5.sf1.3.2" style="font-size:80%;">Search result page</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="Ch3.F5.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="352" id="Ch3.F5.sf2.g1" src="extracted/5921744/figs/detail_page2.png" width="287"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Ch3.F5.sf2.2.1.1" style="font-size:80%;">(b)</span> </span><span class="ltx_text" id="Ch3.F5.sf2.3.2" style="font-size:80%;">Item detail page</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.5: </span>Given a query “floral-dress long sleeve women” on Tmall, the complete title cannot be displayed in the search result page unless the user proceeds to the detail page further. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2018multi</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch3.S1.SS2.SSS3.p2">
<p class="ltx_p" id="Ch3.S1.SS2.SSS3.p2.1">Item title compression, also called short title extraction <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gong2019automatic</span>]</cite>, is meant to extract sufficient words from lengthy and verbose titles to produce a succinct new title to improve the user experience on mobile devices <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2018multi</span>]</cite>.
Inspired by neural extractive document summarization methods <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ren2017leveraging</span>]</cite>, item title compression methods apply neural networks to weight the importance of each word in the item title.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">gong2019automatic</span></cite> proposed a feature-enriched neural extractive model to extract short titles.
Specifically, the authors apply a recurrent neural network as a sequential classifier with three types of features: content, attention, and semantics respectively.
By using user search logs as external knowledge, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2018multi</span></cite> proposed a multi-task learning approach for improving item title compression. The proposed method is composed of two seq2seq components which share an identical encoder.
The authors combine these two components with an overall pointer neural networks <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">vinyals2015pointer</span>]</cite> to automatically select the most informative words from the given item title.</p>
</div>
<div class="ltx_para" id="Ch3.S1.SS2.SSS3.p3">
<p class="ltx_p" id="Ch3.S1.SS2.SSS3.p3.1">Pointer neural networks easily omit key information.
To tackle this problem, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2018multi</span></cite> proposed a multi-source pointer network model, named the multi-source pointer network (MS-Pointer), by considering two extra constraints:

<span class="ltx_inline-enumerate" id="Ch3.S1.I4">
<span class="ltx_inline-item" id="Ch3.S1.I4.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch3.S1.I4.i1.1">irrelevant information reduction; and
</span></span>
<span class="ltx_inline-item" id="Ch3.S1.I4.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch3.S1.I4.i2.1">the key information retainment.
</span></span>
</span>
Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F6" title="Figure 3.6 ‣ 3.1.2.3 Product titles in e-commerce platforms ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.6</span></a> provides an overview of MS-Pointer, with two encoders.
In MS-Pointer, in addition to the encoder for the source title, the authors add another knowledge encoder that uses an LSTM to embed the brand name and the commodity name.
As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F6" title="Figure 3.6 ‣ 3.1.2.3 Product titles in e-commerce platforms ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.6</span></a>, MS-Pointer combines the original title “Nintendo switch console…” and background knowledge “brand name: Nintendo”, and then it generates the short title about the item “Nintendo switch”.
Recently, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/emnlp/FetahuCRM23</span></cite> proposed a instruction fine-tuning strategy to summarize product titles according to various criteria such as number of words in a summary or inclusion of specific phrases.</p>
</div>
<figure class="ltx_figure" id="Ch3.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="521" id="Ch3.F6.g1" src="x7.png" width="788"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.6: </span>Multi-source pointer network (MS-Pointer) with two encoders for item title compression. MS-Pointer copies words from two encoders. At each decoding time step, a soft gating weight <math alttext="\lambda\in[0,1]" class="ltx_Math" display="inline" id="Ch3.F6.4.m1.2"><semantics id="Ch3.F6.4.m1.2b"><mrow id="Ch3.F6.4.m1.2.3" xref="Ch3.F6.4.m1.2.3.cmml"><mi id="Ch3.F6.4.m1.2.3.2" xref="Ch3.F6.4.m1.2.3.2.cmml">λ</mi><mo id="Ch3.F6.4.m1.2.3.1" xref="Ch3.F6.4.m1.2.3.1.cmml">∈</mo><mrow id="Ch3.F6.4.m1.2.3.3.2" xref="Ch3.F6.4.m1.2.3.3.1.cmml"><mo id="Ch3.F6.4.m1.2.3.3.2.1" stretchy="false" xref="Ch3.F6.4.m1.2.3.3.1.cmml">[</mo><mn id="Ch3.F6.4.m1.1.1" xref="Ch3.F6.4.m1.1.1.cmml">0</mn><mo id="Ch3.F6.4.m1.2.3.3.2.2" xref="Ch3.F6.4.m1.2.3.3.1.cmml">,</mo><mn id="Ch3.F6.4.m1.2.2" xref="Ch3.F6.4.m1.2.2.cmml">1</mn><mo id="Ch3.F6.4.m1.2.3.3.2.3" stretchy="false" xref="Ch3.F6.4.m1.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch3.F6.4.m1.2c"><apply id="Ch3.F6.4.m1.2.3.cmml" xref="Ch3.F6.4.m1.2.3"><in id="Ch3.F6.4.m1.2.3.1.cmml" xref="Ch3.F6.4.m1.2.3.1"></in><ci id="Ch3.F6.4.m1.2.3.2.cmml" xref="Ch3.F6.4.m1.2.3.2">𝜆</ci><interval closure="closed" id="Ch3.F6.4.m1.2.3.3.1.cmml" xref="Ch3.F6.4.m1.2.3.3.2"><cn id="Ch3.F6.4.m1.1.1.cmml" type="integer" xref="Ch3.F6.4.m1.1.1">0</cn><cn id="Ch3.F6.4.m1.2.2.cmml" type="integer" xref="Ch3.F6.4.m1.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch3.F6.4.m1.2d">\lambda\in[0,1]</annotation><annotation encoding="application/x-llamapun" id="Ch3.F6.4.m1.2e">italic_λ ∈ [ 0 , 1 ]</annotation></semantics></math> is calculated to weight the probability of words from the source title, versus words from the background knowledge. The final output distribution is the weighted sum of attention distributions <math alttext="a_{t}" class="ltx_Math" display="inline" id="Ch3.F6.5.m2.1"><semantics id="Ch3.F6.5.m2.1b"><msub id="Ch3.F6.5.m2.1.1" xref="Ch3.F6.5.m2.1.1.cmml"><mi id="Ch3.F6.5.m2.1.1.2" xref="Ch3.F6.5.m2.1.1.2.cmml">a</mi><mi id="Ch3.F6.5.m2.1.1.3" xref="Ch3.F6.5.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="Ch3.F6.5.m2.1c"><apply id="Ch3.F6.5.m2.1.1.cmml" xref="Ch3.F6.5.m2.1.1"><csymbol cd="ambiguous" id="Ch3.F6.5.m2.1.1.1.cmml" xref="Ch3.F6.5.m2.1.1">subscript</csymbol><ci id="Ch3.F6.5.m2.1.1.2.cmml" xref="Ch3.F6.5.m2.1.1.2">𝑎</ci><ci id="Ch3.F6.5.m2.1.1.3.cmml" xref="Ch3.F6.5.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch3.F6.5.m2.1d">a_{t}</annotation><annotation encoding="application/x-llamapun" id="Ch3.F6.5.m2.1e">italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and <math alttext="a^{\prime}_{t}" class="ltx_Math" display="inline" id="Ch3.F6.6.m3.1"><semantics id="Ch3.F6.6.m3.1b"><msubsup id="Ch3.F6.6.m3.1.1" xref="Ch3.F6.6.m3.1.1.cmml"><mi id="Ch3.F6.6.m3.1.1.2.2" xref="Ch3.F6.6.m3.1.1.2.2.cmml">a</mi><mi id="Ch3.F6.6.m3.1.1.3" xref="Ch3.F6.6.m3.1.1.3.cmml">t</mi><mo id="Ch3.F6.6.m3.1.1.2.3" xref="Ch3.F6.6.m3.1.1.2.3.cmml">′</mo></msubsup><annotation-xml encoding="MathML-Content" id="Ch3.F6.6.m3.1c"><apply id="Ch3.F6.6.m3.1.1.cmml" xref="Ch3.F6.6.m3.1.1"><csymbol cd="ambiguous" id="Ch3.F6.6.m3.1.1.1.cmml" xref="Ch3.F6.6.m3.1.1">subscript</csymbol><apply id="Ch3.F6.6.m3.1.1.2.cmml" xref="Ch3.F6.6.m3.1.1"><csymbol cd="ambiguous" id="Ch3.F6.6.m3.1.1.2.1.cmml" xref="Ch3.F6.6.m3.1.1">superscript</csymbol><ci id="Ch3.F6.6.m3.1.1.2.2.cmml" xref="Ch3.F6.6.m3.1.1.2.2">𝑎</ci><ci id="Ch3.F6.6.m3.1.1.2.3.cmml" xref="Ch3.F6.6.m3.1.1.2.3">′</ci></apply><ci id="Ch3.F6.6.m3.1.1.3.cmml" xref="Ch3.F6.6.m3.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch3.F6.6.m3.1d">a^{\prime}_{t}</annotation><annotation encoding="application/x-llamapun" id="Ch3.F6.6.m3.1e">italic_a start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2018multi</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch3.S1.SS2.SSS3.p4">
<p class="ltx_p" id="Ch3.S1.SS2.SSS3.p4.1">The task of title generation has been proposed to extend the task of title compression into a text generation problem.
Unlike title compression, which only extracts words from item titles, the task of title generation is to <em class="ltx_emph ltx_font_italic" id="Ch3.S1.SS2.SSS3.p4.1.1">generate</em> a short item title so as to address the problem of inaccurate item titles in e-commerce <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2019multi</span>]</cite>.
To generate a succinct and accurate short title from a long source title, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2019multi</span></cite> proposed a multi-modal generative adversarial network, named MM-GAN, which addresses the title generation task as a reinforcement learning problem.
MM-GAN is composed of two main components, a title generator and a discriminator (Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F7" title="Figure 3.7 ‣ 3.1.2.3 Product titles in e-commerce platforms ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.7</span></a>).
Given the source title and its corresponding tags or features, the generator applies an LSTM-based network to generate a short item title.
The discriminator, i.e., a binary classifier, distinguishes whether the generated short titles are human-generated or machine-generated.
Thus, an adversarial learning procedure is constructed, in which the quality of the short title depends on its ability to fool the discriminator into believing it is a human-generated one, and the output of the discriminator is a reward for the generator to improve the generation performance.
Recently, scene marketing has become a new marketing mode for product promotion where scene scenarios are created to demonstrate product functions <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2020data</span>]</cite>.
To help the e-commerce system find scene topics, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">lin2022automatic</span></cite> proposed a topic generation method to generate scene-based titles in e-commerce.</p>
</div>
<figure class="ltx_figure" id="Ch3.F7"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="333" id="Ch3.F7.g1" src="extracted/5921744/figs/jianguo_fig2.jpg" width="509"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.7: </span>Overall framework of the MM-GAN model for short item title generation. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2019multi</span>]</cite>.</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="Ch3.S1.SS2.SSS4">
<h5 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2.4 </span>Product descriptions in e-commerce platforms</h5>
<div class="ltx_para" id="Ch3.S1.SS2.SSS4.p1">
<p class="ltx_p" id="Ch3.S1.SS2.SSS4.p1.1">As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F8" title="Figure 3.8 ‣ 3.1.2.4 Product descriptions in e-commerce platforms ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.8</span></a>, many e-commerce platforms provide a short description for each item so as to showcase the features of the item.
As an important factor in content marketing, the item description is key for increasing consumer engagement.
During the early years of e-commerce, item descriptions were usually written or edited by human copywriters.
However, the availability of an increasing number of items in e-commerce makes this manual process too costly.
Moreover, with the development of virtual assistants in e-commerce, such as Alexa and Tmall Genie, there is a growing demand for automatically generating a short description given item attributes.
To address this demand, the task of item description generation has been proposed.
Item description generation needs to generate an item’s description from a series of complicated attributes. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2017statistical</span></cite> proposed a statistical framework to weight the relative importance of the attributes of an item and to maintain accuracy at the same time.
In Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F9" title="Figure 3.9 ‣ 3.1.2.4 Product descriptions in e-commerce platforms ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.9</span></a> we specify the framework of the proposed item description model.
By combining sentence-level templates extracted from the input data with knowledge from a pre-trained dataset, the authors generate and rank candidate item descriptions through an online <em class="ltx_emph ltx_font_italic" id="Ch3.S1.SS2.SSS4.p1.1.1">document planning</em> stage.</p>
</div>
<figure class="ltx_figure" id="Ch3.F8">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="Ch3.F8.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="564" id="Ch3.F8.sf1.g1" src="x8.png" width="399"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Ch3.F8.sf1.2.1.1" style="font-size:80%;">(a)</span> </span><span class="ltx_text" id="Ch3.F8.sf1.3.2" style="font-size:80%;">Recommendation page on Taobao</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="Ch3.F8.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="563" id="Ch3.F8.sf2.g1" src="x9.png" width="398"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Ch3.F8.sf2.2.1.1" style="font-size:80%;">(b)</span> </span><span class="ltx_text" id="Ch3.F8.sf2.3.2" style="font-size:80%;">Item detail page on Amazon</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.8: </span>Item descriptions are widely used in e-commerce platforms, e.g., (a) Taobao and (b) Amazon. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2019automatic</span>]</cite>.</figcaption>
</figure>
<figure class="ltx_figure" id="Ch3.F9"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="265" id="Ch3.F9.g1" src="x10.png" width="706"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.9: </span>Overall framework for item description generation with pretrained writing knowledge. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2017statistical</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch3.S1.SS2.SSS4.p2">
<p class="ltx_p" id="Ch3.S1.SS2.SSS4.p2.1">Unlike early studies that focused on generating item descriptions purely from the item’s attributes, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2019automatic</span></cite> generated a pattern-controlled item description from multiple features, e.g., titles and item categories.
Based on the copy mechanism <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gu2016incorporating</span>]</cite>, the authors propose a pattern-controlled pointer-generator network (PGPCN) to generate the description.
In PGPCN, a transformer is applied in the encoder component, whereas the decoder is used to control the pattern (e.g., the category, the length, and the style of the description) of the item.</p>
</div>
<div class="ltx_para" id="Ch3.S1.SS2.SSS4.p3">
<p class="ltx_p" id="Ch3.S1.SS2.SSS4.p3.1">It is important that the descriptions generated for item description are grounded in facts.
To generate a fact-based description, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chanstick2019</span></cite> proposed an encoder-decoder framework, called the fidelity-oriented product description generator (FPDG), by searching key information from keyword labels. The authors established semantic connections between item keywords and the generated product description.
As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F10" title="Figure 3.10 ‣ 3.1.2.4 Product descriptions in e-commerce platforms ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.10</span></a>, FPDG has two main components:

<span class="ltx_inline-enumerate" id="Ch3.S1.I5">
<span class="ltx_inline-item" id="Ch3.S1.I5.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch3.S1.I5.i1.1">a keyword encoder that stores the word and its entity label in the token memory and self-attention modules, and
</span></span>
<span class="ltx_inline-item" id="Ch3.S1.I5.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch3.S1.I5.i2.1">an entity-based generator that generates an item description based on the memory and self-attention modules.
</span></span>
</span></p>
</div>
<figure class="ltx_figure" id="Ch3.F10"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="187" id="Ch3.F10.g1" src="x11.png" width="789"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.10: </span>Overview of the fidelity-oriented item description generator. The whole model is divided into two components: (i) a keyword encoder, and (ii) an entity-based generator. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chanstick2019</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch3.S1.SS2.SSS4.p4">
<p class="ltx_p" id="Ch3.S1.SS2.SSS4.p4.1">Personal interest is neglected by all of the above approaches that generate descriptions given attributes or keywords.
To address this shortcoming, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019towards</span></cite> proposed a knowledge-based personalized item description generation strategy.
The authors extended the encoder-decoder framework <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sutskever2014sequence</span>]</cite> to a sequence modeling formulation using a self-attention mechanism.
A large variety of item attributes, including the target user’s personalized preference features, are combined in an attribute fusion component through multi-layer attention mechanisms; retrieved external knowledge is incorporated in a <em class="ltx_emph ltx_font_italic" id="Ch3.S1.SS2.SSS4.p4.1.1">knowledge incorporation</em> component. In Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F11" title="Figure 3.11 ‣ 3.1.2.4 Product descriptions in e-commerce platforms ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.11</span></a>, we provide an example of the knowledge-based personalized item description generation.</p>
</div>
<figure class="ltx_figure" id="Ch3.F11"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="349" id="Ch3.F11.g1" src="x12.png" width="789"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.11: </span>An example of knowledge-based personalized item description generation. The example is divided into three parts: (a) a user clicks an on item; (b) knowledge-based personalized item description generation; and (c) results generated by <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019towards</span></cite>’s proposed method and a baseline. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019towards</span>]</cite>.</figcaption>
</figure>
</section>
<section class="ltx_subsubsection" id="Ch3.S1.SS2.SSS5">
<h5 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2.5 </span>Question answering in e-commerce</h5>
<div class="ltx_para" id="Ch3.S1.SS2.SSS5.p1">
<p class="ltx_p" id="Ch3.S1.SS2.SSS5.p1.1">Question-answering (QA) systems are designed to provide direct and concise answers to user queries by understanding the intent behind a question and retrieving or generating the most relevant information. QA systems aim to deliver specific answers from structured or unstructured data sources, such as web documents or knowledge bases. QA systems are essential across a variety of domains, including web search, customer support, where users seek quick, accurate, and contextually relevant information <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">radev2002evaluating</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">tapeh2008knowledge</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yin2015neural</span>]</cite>.
To increase the number of sales, most e-commerce portals provide a QA service to facilitate the customers’ shopping procedure by answering their questions about products <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gao2019product</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">feng2021multi</span>]</cite>.
Currently, on many e-commerce sites, a user can ask a question about a product, and the QA system allows some users (e.g., customers who bought this product) to provide answers <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gao2019product</span>]</cite>.
In Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F12" title="Figure 3.12 ‣ 3.1.2.6 User reviews in e-commerce ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.12</span></a>, we show examples of question-answering services at Amazon and JD.com.
More detailed discussions of e-commerce QA is provided in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S1" title="7.1 Question answering in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.1</span></a>.</p>
</div>
</section>
<section class="ltx_subsubsection" id="Ch3.S1.SS2.SSS6">
<h5 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2.6 </span>User reviews in e-commerce</h5>
<div class="ltx_para" id="Ch3.S1.SS2.SSS6.p1">
<p class="ltx_p" id="Ch3.S1.SS2.SSS6.p1.1">User reviews serve as a type of reliable information about the quality of items on e-commerce platforms.
User reviews have been shown to play an essential role in determining user preference <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liang2015consumer</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">huebner2018people</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2018document</span>]</cite>.
In this section, we introduce methods for review analysis in e-commerce.
Research on review analysis can be organized into four key components:

<span class="ltx_inline-enumerate" id="Ch3.S1.I6">
<span class="ltx_inline-item" id="Ch3.S1.I6.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch3.S1.I6.i1.1">sentiment classification,
</span></span>
<span class="ltx_inline-item" id="Ch3.S1.I6.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch3.S1.I6.i2.1">helpfulness prediction,
</span></span>
<span class="ltx_inline-item" id="Ch3.S1.I6.i3"><span class="ltx_tag ltx_tag_inline-item">(iii)</span> <span class="ltx_text" id="Ch3.S1.I6.i3.1">review summarization, and
</span></span>
<span class="ltx_inline-item" id="Ch3.S1.I6.i4"><span class="ltx_tag ltx_tag_inline-item">(iv)</span> <span class="ltx_text" id="Ch3.S1.I6.i4.1">review generation.
</span></span>
</span></p>
</div>
<figure class="ltx_figure" id="Ch3.F12">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="Ch3.F12.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="218" id="Ch3.F12.sf1.g1" src="x13.png" width="278"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Ch3.F12.sf1.2.1.1" style="font-size:80%;">(a)</span> </span><span class="ltx_text" id="Ch3.F12.sf1.3.2" style="font-size:80%;">Question answering service on Amazon</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="Ch3.F12.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="218" id="Ch3.F12.sf2.g1" src="x14.png" width="291"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Ch3.F12.sf2.2.1.1" style="font-size:80%;">(b)</span> </span><span class="ltx_text" id="Ch3.F12.sf2.3.2" style="font-size:80%;">Question answering service on JD.com</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.12: </span>Question answering services are widely applied in e-commerce platforms, (a) Amazon and (b) JD.com. Image sources: <a class="ltx_ref ltx_url ltx_font_typewriter" href="Amazon.com" title="">Amazon.com</a> and <a class="ltx_ref ltx_url ltx_font_typewriter" href="JD.com" title="">JD.com</a>.</figcaption>
</figure>
<section class="ltx_paragraph" id="Ch3.S1.SS2.SSS6.Px1">
<h6 class="ltx_title ltx_title_paragraph">(i) Sentiment classification in reviews.</h6>
<div class="ltx_para" id="Ch3.S1.SS2.SSS6.Px1.p1">
<p class="ltx_p" id="Ch3.S1.SS2.SSS6.Px1.p1.1">The <em class="ltx_emph ltx_font_italic" id="Ch3.S1.SS2.SSS6.Px1.p1.1.1">sentiment classification</em> task is to label a given text with a specific opinion label.
It has received lots of attention during the past two decades <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">pang2002thumbs</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">go2009twitter</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">pan2010cross</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kamal2012mining</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">tang2014learning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">pontiki2015semeval</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">tsytsarau2016managing</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2017review</span>]</cite>.
Work on sentiment classification in an e-commerce context has attempted to capture a user’s opinion about a specific item from reviews on an e-commerce platform <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2017review</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">tang2015learning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">xia2015dual</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">tripathy2016classification</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2018effect</span>]</cite>.
Traditional approaches to sentiment classification focus on the classification problem given textual attributes of an item <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">pang2002thumbs</span>]</cite>, while largely ignoring the relation between users and the item.
To address this problem, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">tang2015learning</span></cite> proposed a neural network, the user-product neural network (UPNN), to incorporate user and item information into a document-level sentiment classification procedure.
In particular, the authors jointly embedded the user preference information, i.e., ratings and reviews, and item attributes.
Then, a convolutional neural network is used to predict the sentiment label of the target review.</p>
</div>
<div class="ltx_para" id="Ch3.S1.SS2.SSS6.Px1.p2">
<p class="ltx_p" id="Ch3.S1.SS2.SSS6.Px1.p2.1">Sentiment classification using the relation between users and products or services faces two important challenges:

<span class="ltx_inline-enumerate" id="Ch3.S1.I7">
<span class="ltx_inline-item" id="Ch3.S1.I7.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch3.S1.I7.i1.1">the sparseness of user-item interactions, and
</span></span>
<span class="ltx_inline-item" id="Ch3.S1.I7.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch3.S1.I7.i2.1">the information in user embedding methods.
</span></span>
</span>
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2016neural</span></cite> proposed a fine-grained hierarchical neural network model to incorporate global user and item information into sentiment classification. Unlike many sentiment classifiers which use convolutional neural networks, the authors applied a hierarchical LSTM <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gers1999learning</span>]</cite> to jointly generate sentence-level representations and document-level representations. Then, user-item interaction information is applied as attention over various regions of a document to enhance the sentiment classification.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018improving</span></cite> distinguished between different roles of words and sentences in user reviews: to describe the user’s preferences or to describe an item’s characteristics. To distinguish between these roles, the authors proposed an attention-based hierarchical neural network model to embed user and item information to generate two text representations with user attention or item attention, respectively.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">Hao2021wwwsentiment</span></cite> leveraged fine-grained latent opinion knowledge into the sentiment classification process by using a variational reasoning method.</p>
</div>
</section>
<section class="ltx_paragraph" id="Ch3.S1.SS2.SSS6.Px2">
<h6 class="ltx_title ltx_title_paragraph">(ii) Helpfulness prediction.</h6>
<div class="ltx_para" id="Ch3.S1.SS2.SSS6.Px2.p1">
<p class="ltx_p" id="Ch3.S1.SS2.SSS6.Px2.p1.1">Given the fact that an item can be commented on by hundreds of thousands of consumers, the quality of reviews in e-commerce varies considerably and not all reviews are helpful.
To gain insights from helpful reviews, the task of review helpfulness prediction has attracted attention from both academia and industry <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mcauley2016addressing</span>]</cite>.
Early studies on review helpfulness prediction employed feature-aware methods, where multiple types of features, such as structural features <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">kim2006automatically</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">susan2010makes</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">xiong2011automatically</span>]</cite>, emotional features <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">martin2014prediction</span>]</cite>, semantic features 
<cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2015semantic</span>]</cite>, argument features <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2017using</span>]</cite>, and lexical features <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">xiong2014empirical</span>]</cite>, were successfully applied.</p>
</div>
<div class="ltx_para" id="Ch3.S1.SS2.SSS6.Px2.p2">
<p class="ltx_p" id="Ch3.S1.SS2.SSS6.Px2.p2.1">Motivated by the progress of deep neural networks, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">fan2018multi</span></cite> introduced a multi-task neural learning (MTNL) architecture for identifying helpful reviews. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2018cross</span></cite> proposed a CNN-based neural network with multi-granularity (i.e., character-level, word-level, and topic-level) features for helpfulness prediction.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">fan2019product</span></cite> proposed an end-to-end deep neural architecture to capture the intrinsic relationship between the meta-data of an item and its numerous comments that could be beneficial to discover the helpful reviews.
Multi-modal data has become increasingly popular in online reviews. To analyze multi-modal reviews, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">liumulti2021</span></cite> proposed a multi-modal review helpfulness prediction task that is aimed at exploring multi-modal clues for review helpfulness prediction. The authors proposed an item-review coherent reasoning module to capture the intra- and inter-modal coherence between the target item and the review.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">han2022sancl</span></cite> proposed a selective attention approach, including probe mask generation and mask-based attention computation, for the multi-modal review helpfulness prediction problem.
To mine the mutual information of cross-modal relations in the input, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">nguyen2022adaptive</span></cite> proposed an adaptive cross-modal contrastive learning mechanism, with a multi-modal interaction module to correlate modalities’ features.</p>
</div>
</section>
<section class="ltx_paragraph" id="Ch3.S1.SS2.SSS6.Px3">
<h6 class="ltx_title ltx_title_paragraph">(iii) Review summarization.</h6>
<div class="ltx_para" id="Ch3.S1.SS2.SSS6.Px3.p1">
<p class="ltx_p" id="Ch3.S1.SS2.SSS6.Px3.p1.1">Given a set of user reviews, the task of <em class="ltx_emph ltx_font_italic" id="Ch3.S1.SS2.SSS6.Px3.p1.1.1">review summarization</em> is to extract the main information from the reviews.
Similar to multi-document summarization, review summarization summarizes a set of item reviews for a single item.
Approaches to review summarization can be divided into two: feature-aware methods and aspect-aware methods.</p>
</div>
<div class="ltx_para" id="Ch3.S1.SS2.SSS6.Px3.p2">
<p class="ltx_p" id="Ch3.S1.SS2.SSS6.Px3.p2.1">Feature-aware methods are inspired by previous document summarization methods: <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2010feature</span></cite> proposed a feature-based item review summarization method to satisfy the detailed information needs of customers.
To jointly summarize reviews and predict ratings in a mobile environment, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2012movie</span></cite> proposed a latent semantic indexing based approach to extract features and attributes from user reviews and ratings.
For new items without reviews, a probabilistic retrieval method is proposed to extract relevant opinion features from other items to describe the item information <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">park2015retrieval</span>]</cite>.
Another important part of review summarization concerns aspect extraction from user reviews <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2014aspect</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">angelidis2018summarizing</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">bravzinskas2020few</span>]</cite>, where target entities and aspects need to be extracted from opinionated text.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2014aspect</span></cite> extracted prior knowledge automatically from user reviews and propose a fault-tolerant model to extract aspects guided by the knowledge.
Category hierarchy information is combined with a topic model to improve the performance of aspect extraction <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2017aspect</span>]</cite>.
By jointly considering fine-grained aspect-topic-sentiment connections, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">tan2017sentence</span></cite> propose a generative topic aspect sentiment model.</p>
</div>
<div class="ltx_para" id="Ch3.S1.SS2.SSS6.Px3.p3">
<p class="ltx_p" id="Ch3.S1.SS2.SSS6.Px3.p3.1">With the development of deep learning, item review summarization has been tackled from a range of perspectives <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ly2011product</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2016aspect</span>]</cite>.
For instance, to tackle the weakness of the “bag of words” assumption, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">he2017unsupervised</span></cite> proposed an unsupervised neural network model. Considering dependencies between adjacent words, the authors used an embedding method with attention mechanism to de-emphasize saliency and extract aspects.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">angelidis2018summarizing</span></cite> proposed a weakly supervised neural framework for the identification and extraction of salient customer opinions that combines aspect and sentiment information.
Using a small number of annotated instances with a large-scale unlabeled corpus, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">bravzinskas2020few</span></cite> proposed a few-shot learning framework for generating an abstractive summary.
In recent years, pre-trained language models <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">vaswani2017attention</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kenton2019bert</span>]</cite> have been shown to be effective in document summarization <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2019hierarchical</span>]</cite>.
A domain-specific generative pre-training method, PEGASUS, was proposed to address the e-commerce review summarization problem <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">3404835zhang3463037</span>]</cite>.
Inspired by Vector-Quantized Variational Auto-encoders (VQ-VAE) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">van2017neural</span>]</cite>, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">angelidis2021extractive</span></cite> proposed an unsupervised neural model, Quantized Transformer (QT), that uses a clustering interpretation of the quantized space to discover popular opinions among hundreds of reviews.
To tackle challenges such as a lack of cross item diversity and consistency, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ovedpass21</span></cite> proposed a method that leverages strong pre-trained language models.</p>
</div>
</section>
<section class="ltx_paragraph" id="Ch3.S1.SS2.SSS6.Px4">
<h6 class="ltx_title ltx_title_paragraph">(iv) Review generation.</h6>
<div class="ltx_para" id="Ch3.S1.SS2.SSS6.Px4.p1">
<p class="ltx_p" id="Ch3.S1.SS2.SSS6.Px4.p1.1">The task of <em class="ltx_emph ltx_font_italic" id="Ch3.S1.SS2.SSS6.Px4.p1.1.1">review generation</em> has been proposed to understand how a specific user provides comments on items <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">dong2017learning</span>]</cite>.
Unlike review summarization, where one extracts salient sentences or generates abstractive summaries, the task of <em class="ltx_emph ltx_font_italic" id="Ch3.S1.SS2.SSS6.Px4.p1.1.2">review generation</em> is to generate sentences as user reviews to represent users’ intention.
Sequence-to-sequence (seq2seq) neural networks have been applied to automatically generate text <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sutskever2014sequence</span>]</cite>.
However, it is difficult to directly use traditional seq2seq models to generate reviews because of the following challenges:

<span class="ltx_inline-enumerate" id="Ch3.S1.I8">
<span class="ltx_inline-item" id="Ch3.S1.I8.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch3.S1.I8.i1.1">the presence of unknown factors renders the generation process non-deterministic, and
</span></span>
<span class="ltx_inline-item" id="Ch3.S1.I8.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch3.S1.I8.i2.1">both implicit and explicit information need to be handled, which makes it difficult to decode reviews.
</span></span>
</span></p>
</div>
<div class="ltx_para" id="Ch3.S1.SS2.SSS6.Px4.p2">
<p class="ltx_p" id="Ch3.S1.SS2.SSS6.Px4.p2.1">To address these problems, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">dong2017learning</span></cite> proposed an attention-enhanced attribute-to-sequence model to generate item reviews for given attribute information.
The authors proposed an attention-enhanced attribute-to-sequence model that learns to encode attributes into vectors and then uses a recurrent neural networks based on LSTM units to generate reviews by conditioning on the encoding vectors; see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F13" title="Figure 3.13 ‣ (iv) Review generation. ‣ 3.1.2.6 User reviews in e-commerce ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.13</span></a>. The model can be divided into three components: an attribute encoder, a sequence decoder, and an attention mechanism. The authors use a dataset collected from Amazon to verify the effectiveness of the proposed method, especially the attention mechanism in the review generation procedure.</p>
</div>
<figure class="ltx_figure" id="Ch3.F13"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="200" id="Ch3.F13.g1" src="x15.png" width="539"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.13: </span>Overview of the attention-enhanced attribute-to-sequence model for review generation. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">dong2017learning</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch3.S1.SS2.SSS6.Px4.p3">
<p class="ltx_p" id="Ch3.S1.SS2.SSS6.Px4.p3.1">There is increasing attention for combining preference prediction with review generation.
As sentiment classification plays an important role in e-commerce review analysis, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">radford2017learning</span></cite> proposed a representation learning strategy to detect opinions while generating reviews, where a generic sentiment tree bank was applied to represent the sentiment label in user reviews <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">socher2013recursive</span>]</cite>.
Many e-commerce sites provide structured information, such as aspect-sentiment scores, i.e., each review text contains sentences describing a number of aspects of the item.
Focusing on generating long Chinese reviews from aspect-sentiment scores, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zang2017towards</span></cite> proposed end-to-end sequential review generation models (SRGMs). Unlike traditional seq2seq models, SRGMs encode inputs of aspect-sentiment scores using multi-layer perceptrons.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">sharma2018cyclegen</span></cite> proposed an LSTM-based neural network to generate personalized reviews from multi-faceted factors, i.e., user profiles and item attributes, where an additional loss term is used to ensure consistency of the sentiment rating in the generated review.</p>
</div>
<div class="ltx_para" id="Ch3.S1.SS2.SSS6.Px4.p4">
<p class="ltx_p" id="Ch3.S1.SS2.SSS6.Px4.p4.1"><cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ni2017estimating</span></cite> proposed a collaborative-filtering generative concatenative network to jointly optimize item recommendation and generate personalized reviews.
To generate personalized high-fidelity reviews, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ni2018personalized</span></cite> proposed an encoder-decoder model to leverage both user and item information as well as auxiliary, textual input and aspect-aware knowledge, where an attention fusion layer is introduced to control the influence of various encoders.</p>
</div>
<figure class="ltx_figure" id="Ch3.F14"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="528" id="Ch3.F14.g1" src="x16.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.14: </span>Examples of reviews and tips selected from the restaurant “Gary Danko” on Yelp. Users will get conclusions about this restaurant immediately after scanning the tips with their mobile phones. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Li2017</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch3.S1.SS2.SSS6.Px4.p5">
<p class="ltx_p" id="Ch3.S1.SS2.SSS6.Px4.p5.1">Some e-commerce sites have launched an interaction box called <em class="ltx_emph ltx_font_italic" id="Ch3.S1.SS2.SSS6.Px4.p5.1.1">tips</em> on their mobile platforms.
Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F14" title="Figure 3.14 ‣ (iv) Review generation. ‣ 3.1.2.6 User reviews in e-commerce ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.14</span></a> shows examples of reviews and tips on Yelp. The left column is the review from the user “Monica H.”, and tips from several other users are shown in the right column.
Tips are more concise than reviews and can reveal user experience, feelings, and suggestions with only a few words. To generate concise tips from reviews, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">Li2017</span></cite> proposed a multi-task learning framework for tip generation and rating prediction.
For abstractive tip generation, gated recurrent neural networks are employed to decode user and item latent factors, whereas for rating regression, a multilayer perceptron network is employed to project user latent factors and item latent factors into ratings.
A persona-aware tip generation framework has been proposed for <em class="ltx_emph ltx_font_italic" id="Ch3.S1.SS2.SSS6.Px4.p5.1.2">personalized</em> tip generation through adversarial variational auto-encoders (aVAE) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2019persona</span>]</cite>.</p>
</div>
<figure class="ltx_figure" id="Ch3.F15"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="522" id="Ch3.F15.g1" src="x17.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.15: </span>An example of a set of reviews and their corresponding opinion tags. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2021abstractive</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch3.S1.SS2.SSS6.Px4.p6">
<p class="ltx_p" id="Ch3.S1.SS2.SSS6.Px4.p6.1"><em class="ltx_emph ltx_font_italic" id="Ch3.S1.SS2.SSS6.Px4.p6.1.1">Opinion tags</em> refer to a ranked list of tags provided by the e-commerce platform that reflect the characteristics of reviews of an item; see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F15" title="Figure 3.15 ‣ (iv) Review generation. ‣ 3.1.2.6 User reviews in e-commerce ‣ 3.1.2 Analyzing information components ‣ 3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.15</span></a>.
To assist consumers to quickly grasp a large number of reviews about an item, opinion tags are increasingly being applied by e-commerce platforms.
Current mechanisms for generating opinion tags rely on either manual labelling or heuristic methods, which is time-consuming and ineffective.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">li2021abstractive</span></cite> proposed the abstractive opinion tagging task, where systems have to automatically generate a ranked list of opinion tags that are based on, but need not occur in, a given set of user-generated reviews.</p>
</div>
<div class="ltx_para" id="Ch3.S1.SS2.SSS6.Px4.p7">
<p class="ltx_p" id="Ch3.S1.SS2.SSS6.Px4.p7.1">The abstractive opinion tagging task comes with three main challenges:

<span class="ltx_inline-enumerate" id="Ch3.S1.I9">
<span class="ltx_inline-item" id="Ch3.S1.I9.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch3.S1.I9.i1.1">the noisy nature of reviews;
</span></span>
<span class="ltx_inline-item" id="Ch3.S1.I9.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch3.S1.I9.i2.1">the formal nature of opinion tags vs. the colloquial language usage in reviews; and
</span></span>
<span class="ltx_inline-item" id="Ch3.S1.I9.i3"><span class="ltx_tag ltx_tag_inline-item">(iii)</span> <span class="ltx_text" id="Ch3.S1.I9.i3.1">the need to distinguish between different items with very similar aspects.
</span></span>
</span>
To address these challenges, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">li2021abstractive</span></cite> proposed an abstractive opinion tagging framework, named AOT-Net, that first predicts a salience score for each review, and given the salience scores, it groups all reviews into opinion clusters and ranks opinion clusters by cluster size. With the designed alignment feature and alignment loss, AOT-Net sequentially reads ranked opinion clusters and generates opinion tags with ranks.
To generate opinion tags in a personalized way, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2022personaot</span></cite> selected the information that users are interested in from reviews and then generated a ranked list of aspect and opinion tag pairs. The authors tracked user preferences not only using explicit feedback, i.e., reviews, but also using implicit feedback such as clicks and purchases in a heterogeneous graph neural network model.</p>
</div>
</section>
</section>
</section>
</section>
<section class="ltx_section" id="Ch3.S2">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3.2 </span>E-commerce users</h3>
<div class="ltx_para" id="Ch3.S2.p1">
<p class="ltx_p" id="Ch3.S2.p1.1">Over 55% of online customers start to search on an e-commerce website as opposed to a generic web search engine <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhouwsdm2018</span>]</cite>.
Besides desktop clients, there are multiple e-commerce environments, e.g., mobile apps, smart watches, and interactive systems.
These devices provide new means of interaction for users with e-commerce interfaces.
User behavior on e-commerce platforms can be divided into two types: implicit feedback and explicit feedback <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">brown2003buying</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">su2018detecting</span>]</cite>. Implicit feedback is captured in transaction logs and includes clicks, purchases, browses, and engagements, etc.; explicit feedback of online shopping is captured in user comments, chat logs, and questions.
Following <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">lo2016understanding</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhouwsdm2018</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gao2019product</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2020jddc</span></cite>, we list eight types of user behavior information from e-commerce platforms:</p>
</div>
<div class="ltx_para" id="Ch3.S2.p2">
<ul class="ltx_itemize" id="Ch3.S2.I1">
<li class="ltx_item" id="Ch3.S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch3.S2.I1.i1.p1">
<p class="ltx_p" id="Ch3.S2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="Ch3.S2.I1.i1.p1.1.1">Clicks.</span> As the entrance to an item page, a click on an item hints that the user is interested in the item. Click sources include the home page, shopping cart page, sale page, and the search result page, etc.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zou2018drlunderreview</span></cite> find that the more clicks, the bigger the interest from the user.</p>
</div>
</li>
<li class="ltx_item" id="Ch3.S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch3.S2.I1.i2.p1">
<p class="ltx_p" id="Ch3.S2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="Ch3.S2.I1.i2.p1.1.1">Purchases.</span> In e-commerce systems, purchases are very strong signals for recommendation. Most e-commerce platforms employ the <em class="ltx_emph ltx_font_italic" id="Ch3.S2.I1.i2.p1.1.2">Gross Merchandise Volume</em> (GMV) as a gold standard for measuring success. GMV indicates the total amount of purchases from merchandise sales as the target of optimization of e-commerce <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">anderson2002new</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lee2001visualization</span>]</cite>.
More and more recent studies utilize binary purchase information as the learning objective to characterize different levels of clicks <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhouwsdm2018</span>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="Ch3.S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch3.S2.I1.i3.p1">
<p class="ltx_p" id="Ch3.S2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="Ch3.S2.I1.i3.p1.1.1">Browses.</span> On an item detail page, there are three browsable components: the main page (including basic information, title, price, pictures, etc.), the specification page (including more parameters and details), and comment page. The browsable components are helpful to understand users’ interests, e.g., if a user browses the comments and specifications instead of only browsing the brief information, they have a higher probability of buying this item.</p>
</div>
</li>
<li class="ltx_item" id="Ch3.S2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch3.S2.I1.i4.p1">
<p class="ltx_p" id="Ch3.S2.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="Ch3.S2.I1.i4.p1.1.1">Add-to-carts.</span> Adding to cart and ordering actions offer strong signals for e-commerce search and recommendation <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">su2018detecting</span>]</cite>. Adding to cart usually reflects a strong sign of buying an item, whereas it may also reflect an interest shift phenomenon or high potential for re-purchase <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhouwsdm2018</span>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="Ch3.S2.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch3.S2.I1.i5.p1">
<p class="ltx_p" id="Ch3.S2.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="Ch3.S2.I1.i5.p1.1.1">Dwell time.</span> Dwell time is an effective signal to measure user engagement <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yi2014beyond</span>]</cite>. It denotes the length of time that a user spends on a web page before navigating to another page. Typically, the longer the dwell time, the more appealing the page. Dwell time is widely captured on e-commerce sites.</p>
</div>
</li>
<li class="ltx_item" id="Ch3.S2.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch3.S2.I1.i6.p1">
<p class="ltx_p" id="Ch3.S2.I1.i6.p1.1"><span class="ltx_text ltx_font_bold" id="Ch3.S2.I1.i6.p1.1.1">Product-aware question answering.</span> As explained above e-commerce platforms allow consumers to ask product-aware questions to those whom bought the same product. Correspondingly, consumers can also answer these questions asked by other users on the platform. These questions and answers provide explicit feedback and opinions of the user <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gao2019product</span>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="Ch3.S2.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch3.S2.I1.i7.p1">
<p class="ltx_p" id="Ch3.S2.I1.i7.p1.1"><span class="ltx_text ltx_font_bold" id="Ch3.S2.I1.i7.p1.1.1">Interactions with customer services.</span> Provided to customers before, during, and after a purchase, customer services give direct one-on-one interactions between a consumer and the e-commerce service provider via multiple channels, e.g., dialogues, emails, and messages.
Most user feedback from customer service is textual information. However, recently more and more multi-modal information, e.g., images, videos and audio messages is also included <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2021jddc</span>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="Ch3.S2.I1.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch3.S2.I1.i8.p1">
<p class="ltx_p" id="Ch3.S2.I1.i8.p1.1"><span class="ltx_text ltx_font_bold" id="Ch3.S2.I1.i8.p1.1.1">Reviews and comments.</span> As explained above, reviews and comments are prevalent in e-commerce platforms. Reviews and comments, written by consumers, explicitly reflect their opinions about specific products and services on the e-commerce platform.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="Ch3.S2.p3">
<p class="ltx_p" id="Ch3.S2.p3.1">Given these types of user behavior, recent research on analyzing user behavior on e-commerce platforms focuses on answering the following questions:</p>
<ul class="ltx_itemize" id="Ch3.S2.I2">
<li class="ltx_item" id="Ch3.S2.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch3.S2.I2.i1.p1">
<p class="ltx_p" id="Ch3.S2.I2.i1.p1.1">How do people make their shopping decisions? What is the process from a user’s click to their purchase in e-commerce?</p>
</div>
</li>
<li class="ltx_item" id="Ch3.S2.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch3.S2.I2.i2.p1">
<p class="ltx_p" id="Ch3.S2.I2.i2.p1.1">What is the post-click behavior in e-commerce? What is the difference between macro-behavior and micro-behavior?
</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para ltx_noindent" id="Ch3.S2.p4">
<p class="ltx_p" id="Ch3.S2.p4.1">In this section, we analyze recent work on user behavior analysis in e-commerce:

<span class="ltx_inline-enumerate" id="Ch3.S2.I3">
<span class="ltx_inline-item" id="Ch3.S2.I3.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch3.S2.I3.i1.1">click behavior analysis (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S2.SS1" title="3.2.1 From clicks to purchases ‣ 3.2 E-commerce users ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.2.1</span></a>); and
</span></span>
<span class="ltx_inline-item" id="Ch3.S2.I3.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch3.S2.I3.i2.1">user engagement and post-click behavior (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S2.SS2" title="3.2.2 User engagement and post-clicks ‣ 3.2 E-commerce users ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.2.2</span></a>).
</span></span>
</span></p>
</div>
<section class="ltx_subsection" id="Ch3.S2.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2.1 </span>From clicks to purchases</h4>
<div class="ltx_para" id="Ch3.S2.SS1.p1">
<p class="ltx_p" id="Ch3.S2.SS1.p1.1">As an e-commerce user interacts with an item, they express a certain degree of interest in the item.
When users browse an e-commerce platform, they may examine a specific item that is sufficiently relevant or intriguing. User clicks are an important signal for tracking a user’s interest <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chuklin-click-2015</span>]</cite>.
A user’s online shopping behavior can be divided into two consecutive stages: item selection/clicks, and the decision to purchase the clicked item.
Users may have different intentions while shopping online, e.g., some wish to make a purchase as soon as possible while others are just looking around so as to get inspired.
Therefore, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span></cite> argued that clicks, as a kind of implicit feedback, should be integrated with other kinds of feedback to evaluate the “relevance” of items given a query on e-commerce portals.</p>
</div>
<div class="ltx_para" id="Ch3.S2.SS1.p2">
<p class="ltx_p" id="Ch3.S2.SS1.p2.1">During online shopping, users can add items to shopping carts and purchase them, but many platforms also facilitate additional types of activity. For instance, “adding to favorites” is a function to help users save some potentially interesting items for future purchase activities.
To some extent, the degree of “adding to favorites” reflects the popularity of an item that can be exploited as a facet for item ranking for e-commerce search and recommendation <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2011towards</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch3.S2.SS1.p3">
<p class="ltx_p" id="Ch3.S2.SS1.p3.1">To boost sales, some online retailers modify the ranking of their items’ popularity with the usage of crowdsourcing platforms. For example, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">su2018detecting</span></cite> investigated and detected such kind of activities in e-commerce, e.g., crowd workers need to follow some particularly designed guidelines to disguise themselves as normal users. An example of this crowdsouring “add to favorites” task is shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F16" title="Figure 3.16 ‣ 3.2.1 From clicks to purchases ‣ 3.2 E-commerce users ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.16</span></a>.
By simultaneously manipulating a number of crowdsourcing tasks and collecting user behavior, the authors compare behavioral attributes between normal activities and spamming activities. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F17" title="Figure 3.17 ‣ 3.2.1 From clicks to purchases ‣ 3.2 E-commerce users ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.17</span></a> shows these comparisons in terms of four behavioral attributes: query length, page number, browse time (time period between search and click), and dwell time (on detailed item pages).</p>
</div>
<figure class="ltx_figure" id="Ch3.F16"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="856" id="Ch3.F16.g1" src="x18.png" width="789"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.16: </span>An example of crowdsourcing “add to favorites” task. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">su2018detecting</span>]</cite>.</figcaption>
</figure>
<figure class="ltx_figure" id="Ch3.F17">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="Ch3.F17.1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="151" id="Ch3.F17.1.g1" src="x19.png" width="269"/>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="Ch3.F17.2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="151" id="Ch3.F17.2.g1" src="x20.png" width="269"/>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="Ch3.F17.3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="151" id="Ch3.F17.3.g1" src="x21.png" width="269"/>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="Ch3.F17.4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="151" id="Ch3.F17.4.g1" src="x22.png" width="269"/>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.17: </span>Comparisons of behavior attribute distributions between normal and spamming “add to favorites” activities. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">su2018detecting</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="Ch3.S2.SS1.p4">
<p class="ltx_p" id="Ch3.S2.SS1.p4.1">Different recommendation scenarios on an e-commerce platforms may yield different types of user click and purchase behavior. E.g., clicks on the follow-up recommendation results after adding an item to the shopping cart, and clicks on the recommended results listed on an item’s detailed page <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhouwsdm2018</span>]</cite>.
The diversity in scenarios may make it harder to interpret clicks and their relation to purchase behavior.
In e-commerce search and recommendation, a purchase action is a natural ground-truth label for a click.
If a user ends up purchasing an item after clicking on it, such a click indicates the user’s strong interest in and satisfaction with the item. Accordingly, the conversion rate has been proposed as a important signal <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhouwsdm2018</span>]</cite>:</p>
<table class="ltx_equation ltx_eqn_table" id="Ch3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\begin{split}\text{Conversion rate}=\frac{\text{Number of clicks that ended %
with an order}}{\text{Number of clicks}}.\end{split}" class="ltx_Math" display="block" id="Ch3.E1.m1.6"><semantics id="Ch3.E1.m1.6a"><mtable displaystyle="true" id="Ch3.E1.m1.6.6.2"><mtr id="Ch3.E1.m1.6.6.2a"><mtd class="ltx_align_right" columnalign="right" id="Ch3.E1.m1.6.6.2b"><mrow id="Ch3.E1.m1.6.6.2.5.5.5.5"><mrow id="Ch3.E1.m1.6.6.2.5.5.5.5.1"><mtext id="Ch3.E1.m1.1.1.1.1.1.1" xref="Ch3.E1.m1.1.1.1.1.1.1a.cmml">Conversion rate</mtext><mo id="Ch3.E1.m1.2.2.2.2.2.2" xref="Ch3.E1.m1.2.2.2.2.2.2.cmml">=</mo><mfrac id="Ch3.E1.m1.3.3.3.3.3.3" xref="Ch3.E1.m1.3.3.3.3.3.3.cmml"><mtext id="Ch3.E1.m1.3.3.3.3.3.3.2" xref="Ch3.E1.m1.3.3.3.3.3.3.2a.cmml">Number of clicks that ended with an order</mtext><mtext id="Ch3.E1.m1.3.3.3.3.3.3.3" xref="Ch3.E1.m1.3.3.3.3.3.3.3a.cmml">Number of clicks</mtext></mfrac></mrow><mo id="Ch3.E1.m1.4.4.4.4.4.4" lspace="0em" xref="Ch3.E1.m1.5.5.1.1.1.cmml">.</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="Ch3.E1.m1.6b"><apply id="Ch3.E1.m1.5.5.1.1.1.cmml" xref="Ch3.E1.m1.4.4.4.4.4.4"><eq id="Ch3.E1.m1.2.2.2.2.2.2.cmml" xref="Ch3.E1.m1.2.2.2.2.2.2"></eq><ci id="Ch3.E1.m1.1.1.1.1.1.1a.cmml" xref="Ch3.E1.m1.1.1.1.1.1.1"><mtext id="Ch3.E1.m1.1.1.1.1.1.1.cmml" xref="Ch3.E1.m1.1.1.1.1.1.1">Conversion rate</mtext></ci><apply id="Ch3.E1.m1.3.3.3.3.3.3.cmml" xref="Ch3.E1.m1.3.3.3.3.3.3"><divide id="Ch3.E1.m1.3.3.3.3.3.3.1.cmml" xref="Ch3.E1.m1.3.3.3.3.3.3"></divide><ci id="Ch3.E1.m1.3.3.3.3.3.3.2a.cmml" xref="Ch3.E1.m1.3.3.3.3.3.3.2"><mtext id="Ch3.E1.m1.3.3.3.3.3.3.2.cmml" xref="Ch3.E1.m1.3.3.3.3.3.3.2">Number of clicks that ended with an order</mtext></ci><ci id="Ch3.E1.m1.3.3.3.3.3.3.3a.cmml" xref="Ch3.E1.m1.3.3.3.3.3.3.3"><mtext id="Ch3.E1.m1.3.3.3.3.3.3.3.cmml" xref="Ch3.E1.m1.3.3.3.3.3.3.3">Number of clicks</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch3.E1.m1.6c">\begin{split}\text{Conversion rate}=\frac{\text{Number of clicks that ended %
with an order}}{\text{Number of clicks}}.\end{split}</annotation><annotation encoding="application/x-llamapun" id="Ch3.E1.m1.6d">start_ROW start_CELL Conversion rate = divide start_ARG Number of clicks that ended with an order end_ARG start_ARG Number of clicks end_ARG . end_CELL end_ROW</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3.1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch3.S2.SS1.p4.2"><em class="ltx_emph ltx_font_italic" id="Ch3.S2.SS1.p4.2.1">Purchase intent</em> represents a predictive measure of subsequent purchasing behavior.
Understanding purchase intent and how it is built up over time is important for personalized and contextualized e-commerce services.
In recent years, many studies have explored the conversion from clicks to purchases <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2018multi</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">guoziyi2018</span>]</cite>.
Moreover, to understand how user activities lead to purchase intent, both long and short-term purchase intent have been investigated <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lo2016understanding</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">brown2003buying</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kim2003combination</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sismeiro2004modeling</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">swinyard2004activities</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">suh2004prediction</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">van2005predicting</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">young2004predicting</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch3.S2.SS1.p5">
<p class="ltx_p" id="Ch3.S2.SS1.p5.1">Studies focusing on short-term purchase intent analysis have investigated user demographics <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">young2004predicting</span>]</cite>, purchase patterns <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">kim2003combination</span>]</cite>, item attributes <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">brown2003buying</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">van2005predicting</span>]</cite>, and click streams <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sismeiro2004modeling</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">young2004predicting</span></cite> find that the transaction, cost, and incentive programs are important predictors for determining the short-term intention to purchase clothing, jewelry, and accessories on e-commerce portals.
Furthermore, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">mcduff2015predicting</span></cite> presented a large-scale analysis of the connection between facial responses and purchases.</p>
</div>
<div class="ltx_para" id="Ch3.S2.SS1.p6">
<p class="ltx_p" id="Ch3.S2.SS1.p6.1"><cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">lo2016understanding</span></cite> focused on long-term purchase intent analysis.
The authors perform a large-scale long-term cross-platform study of user purchase intent and how it varies over time.
They focus on four kinds of signals of user actions to detect purchase intent: closing-up on a piece of content, clicking through a link to an external website, searching for content, and saving content for later retrieval.
The authors find that signals for purchase intent tend to slowly build up over time, and sharply increase about three to five days before a purchase.
Moreover, users with a long-term purchase intent tend to save and click-through more content; these signals may be present for weeks before a purchase is made and they are amplified in the last three days before purchase.</p>
</div>
<div class="ltx_para" id="Ch3.S2.SS1.p7">
<p class="ltx_p" id="Ch3.S2.SS1.p7.1">Social interactions can also be used to improve understanding of consumer behavior <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2011role</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gunawan2015viral</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hajli2017social</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">testa2018social</span>]</cite>.
Users may consult their social network when they need to purchase something they are unfamiliar with.
Thus, although social relations only provide implicit signals, they have been found to be useful to understand purchase decisions <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2011role</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">bhatt2010predicting</span></cite> find that purchase intent from highly connected individuals is correlated with adoption by users in their social circle.
However, there is little evidence of social influence by these high degree individuals. The spread of purchase intent remains mostly local to first-adopters and their immediate friends.
In a 2011 study of information passing in Taobao, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2011role</span></cite> verified that implicit information passing is present in the network, and that communication between buyers is a fundamental driver of purchasing activity.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2013predicting</span></cite> presented a system to understand the relation between users’ Facebook profiles and purchase behaviors in eBay.
Extensive analysis have been done on a benchmark dataset collected from Facebook and eBay; the authors find that there are significant correlations between social network information and online purchases.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch3.S2.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2.2 </span>User engagement and post-clicks</h4>
<div class="ltx_para" id="Ch3.S2.SS2.p1">
<p class="ltx_p" id="Ch3.S2.SS2.p1.1">User engagement is usually described as a combination of cognitive processes such as focused attention, affection, and
interest <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mathur2016engagement</span>]</cite>.
In e-commerce, there is a long line of research that analyses user engagement <cite class="ltx_cite ltx_citemacro_citep">[e.g.,  <span class="ltx_ref ltx_missing_citation ltx_ref_self">o2010development</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">vanderveld2016engagement</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2017returning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zou2018drlunderreview</span>]</cite>.
User engagement in e-commerce can be divided into two categories: short-term engagement and long-term engagement <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zou2018drlunderreview</span>]</cite>.
Short-term engagement refers to the instant response (e.g., clicks and dwell time on an item page), which reflects the users’ real-time preferences.
However,
the systems may not only want to optimize for more clicks or purchases, but also to keep users in active interaction with the system (i.e., user stickiness), which is typically measured by <em class="ltx_emph ltx_font_italic" id="Ch3.S2.SS2.p1.1.1">delayed metrics</em> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lehmann2012models</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch3.S2.SS2.p2">
<p class="ltx_p" id="Ch3.S2.SS2.p2.1">Long-term user engagement is more complicated than short-term user engagement; it includes, e.g., dwell time on applications, depth of the page-viewing, and the internal time between two visits <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2017returning</span>]</cite>.
Long-term user engagement reflects the user’s desire to stay on the e-commerce portal longer and use the service repeatedly <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zou2018drlunderreview</span>]</cite>, i.e., the “stickiness.”</p>
</div>
<div class="ltx_para" id="Ch3.S2.SS2.p3">
<p class="ltx_p" id="Ch3.S2.SS2.p3.1">After clicking an item via search results or recommendation results, the user enters the item page.
A user’s post-click refers to the user’s actions within the item page after the user clicks, including inner-item clicks (i.e., clicks within the item page), purchases, service contact, and thumbnail picture views <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">rosales2012post</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yi2014beyond</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">mao2014estimating</span>]</cite>.
Recent studies aim to characterize such post-click behavior on item pages as different post-click behavior has sharply different conversion rates <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhouwsdm2018</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">guoziyi2018</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lalmas2018tutorial</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span>]</cite>.</p>
</div>
<figure class="ltx_figure" id="Ch3.F18"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="162" id="Ch3.F18.g1" src="x23.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.18: </span>An illustrative example of post-click behavior from JD.com. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhouwsdm2018</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch3.S2.SS2.p4">
<p class="ltx_p" id="Ch3.S2.SS2.p4.1">To illustrates post-click behavior on an e-commerce platform, Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F18" title="Figure 3.18 ‣ 3.2.2 User engagement and post-clicks ‣ 3.2 E-commerce users ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.18</span></a> provides an example of observed data of a user during a short period.
We see that the user first enters a product page for the iPhone 7 from a search result page.
After reading the detailed description and comments, this user adds the item to their shopping cart.
Then the user shifts to a page for the iPhone 6 from the search result page and reads the comments.
After that, they browse a page devoted to iPhone 7 cases from the sales page and order the case.
Finally, they jump to a page about Samsung Galaxy from the home page of the e-commerce site.
During this period, two kinds of post-click behavior can be found:

<span class="ltx_inline-enumerate" id="Ch3.S2.I4">
<span class="ltx_inline-item" id="Ch3.S2.I4.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch3.S2.I4.i1.1">from a coarse-grained perspective, the user interacted with the iPhone 7, the iPhone 6, iPhone 7 cases, and the Samsung Galaxy; and
</span></span>
<span class="ltx_inline-item" id="Ch3.S2.I4.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch3.S2.I4.i2.1">from a fine-grained perspective, each coarse-grained interaction includes a sequence of behavior that can indicate how the user locates the item page, whether the user clicks detailed information, whether a user adds-to-cart or orders an item, and how long the user dwells on an item <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhouwsdm2018</span>]</cite>.
</span></span>
</span></p>
</div>
<figure class="ltx_figure" id="Ch3.F19"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="430" id="Ch3.F19.g1" src="x24.png" width="777"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.19: </span>The relation between clicks and browsing modules. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhouwsdm2018</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch3.S2.SS2.p5">
<p class="ltx_p" id="Ch3.S2.SS2.p5.1">As mentioned in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S2" title="3.2 E-commerce users ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.2</span></a>, typically, there are three browsing modules on e-commerce sites: the main page (including basic information, title, price, and pictures), the specification page (including more parameters and details), and the comment page.
Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F19" title="Figure 3.19 ‣ 3.2.2 User engagement and post-clicks ‣ 3.2 E-commerce users ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.19</span></a> illustrates the relations between clicks and these browsable components <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhouwsdm2018</span>]</cite>.
We see that a user is more likely to buy an item if they makes more clicks on its different browsable components, i.e., a user may gather basic information from the main item page, review feedback from the comment page, and click images to check if the item satisfies their requirements.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">guoziyi2018</span></cite> showed how dwell time is related to clicks and browsable components; see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F20" title="Figure 3.20 ‣ 3.2.2 User engagement and post-clicks ‣ 3.2 E-commerce users ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.20</span></a>.
The dwell time on an item is related to how a user locates the item.
As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.F20.sf2" title="In Figure 3.20 ‣ 3.2.2 User engagement and post-clicks ‣ 3.2 E-commerce users ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.20(b)</span></a>, the longer the dwell time, the more likely a user would visit detailed components, including reading comments and specifications.</p>
</div>
<figure class="ltx_figure" id="Ch3.F20">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="Ch3.F20.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="170" id="Ch3.F20.sf1.g1" src="extracted/5921744/figs/mi-box.png" width="240"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Ch3.F20.sf1.2.1.1" style="font-size:80%;">(a)</span> </span><span class="ltx_text" id="Ch3.F20.sf1.3.2" style="font-size:80%;">Dwell time vs. clicks</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="Ch3.F20.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="170" id="Ch3.F20.sf2.g1" src="extracted/5921744/figs/mi-dwell-behavior.png" width="240"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Ch3.F20.sf2.2.1.1" style="font-size:80%;">(b)</span> </span><span class="ltx_text" id="Ch3.F20.sf2.3.2" style="font-size:80%;">Dwell time vs. browsing module</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3.20: </span>Performance of dwell time, clicks, and browsable components. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhouwsdm2018</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch3.S2.SS2.p6">
<p class="ltx_p" id="Ch3.S2.SS2.p6.1"><cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhouwsdm2018</span></cite> investigated the relation between certain types of post-click behavior and the  <span class="ltx_glossaryref" title="conversion rate"><span class="ltx_text ltx_glossary_long">conversion rate</span></span> (<abbr class="ltx_glossaryref" title="conversion rate"><span class="ltx_text ltx_glossary_short">CVR</span></abbr>). They find that the post-click behavior “Cart” has the highest conversion rate, which means if a user adds an item to the cart, they are more likely to order it in the end. Similarly, if a user enters an item page from the list of items in the cart, they are also very likely to order it.
When the dwell time is outside a certain range, the conversion rate drops.
If the user stays much longer than they need to finish the page, they might have transferred their attention offline.
It is observed that users’ interactions often exhibit a monotonic structure, i.e., the presence of a more explicit interaction (such as reviews) necessarily implies the presence of a more implicit signal (such as clicks) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wan2018item</span>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="Ch3.S3">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3.3 </span>Discussion</h3>
<div class="ltx_para" id="Ch3.S3.p1">
<p class="ltx_p" id="Ch3.S3.p1.1">In this chapter, we have surveyed the infrastructure of e-commerce platforms, i.e., presentations and users. Specifically, we have introduced six information components that are widely applied in e-commerce platforms: search results, recommendation results, titles, product descriptions, question answering, and reviews.
We have highlighted studies about user behavior in e-commerce, including user clicks, purchases, engagement, and post-click behavior.</p>
</div>
<div class="ltx_para" id="Ch3.S3.p2">
<p class="ltx_p" id="Ch3.S3.p2.1">For e-commerce presentations, we have introduced basic concepts and identified key components of e-commerce interfaces. We have found that almost every e-commerce site provides six information components: search results, recommendation results, item titles, item features and descriptions, question answer pairs, and user reviews of the item.
Furthermore, we have summarized recent studies that focus on analyzing the effect of these information components. Empirical studies on these information components have revealed remarkably high correlations between user behavior and information displayed in e-commerce presentations.</p>
</div>
<div class="ltx_para" id="Ch3.S3.p3">
<p class="ltx_p" id="Ch3.S3.p3.1">For e-commerce users, we have observed complex user behavior from clicks to purchases.
According to empirical studies on e-commerce users, signals for purchase intent tend to slowly build up over time and sharply increase before a purchase.
Studies also find that users are more likely to buy an item if they produce more clicks on its different browsable components.
If a user adds an item to a cart, they are more likely to purchase it in the end. Similarly, if a user enters an item detail page from the list of items in the cart, they are also very likely to purchase it.</p>
</div>
<div class="ltx_para" id="Ch3.S3.p4">
<p class="ltx_p" id="Ch3.S3.p4.1">To gain a deeper understanding of information discovery on e-commerce platforms, we list three research questions to guide the following three chapters:</p>
<ul class="ltx_itemize" id="Ch3.S3.I1">
<li class="ltx_item" id="Ch3.S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch3.S3.I1.i1.p1">
<p class="ltx_p" id="Ch3.S3.I1.i1.p1.1">Can we model user behavior and profile users by using multiple types of user behavior, e.g., clicks, post-clicks, and purchases?</p>
</div>
</li>
<li class="ltx_item" id="Ch3.S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch3.S3.I1.i2.p1">
<p class="ltx_p" id="Ch3.S3.I1.i2.p1.1">How can we understand frameworks and components of e-commerce search through interactions between users and search engines?</p>
</div>
</li>
<li class="ltx_item" id="Ch3.S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch3.S3.I1.i3.p1">
<p class="ltx_p" id="Ch3.S3.I1.i3.p1.1">What are the principles and characteristics of e-commerce recommendations?</p>
</div>
</li>
</ul>
<p class="ltx_p" id="Ch3.S3.p4.2">We will address these questions through discussions in Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4" title="Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4</span></a>, Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5" title="Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5</span></a>, and Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6" title="Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6</span></a>, respectively.
A considerable amount of relevant work about information components will be discussed in Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7" title="Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7</span></a> as they have a clear connection to question answering and dialogue generation in e-commerce.</p>
</div>
</section>
</section>
<section class="ltx_chapter" id="Ch4" lang="en">
<h2 class="ltx_title ltx_title_chapter">
<span class="ltx_tag ltx_tag_chapter">Chapter 4 </span>E-commerce user modeling</h2>
<div class="ltx_para" id="Ch4.p1">
<p class="ltx_p" id="Ch4.p1.1">In Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3" title="Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3</span></a>, we discussed work on e-commerce information infrastructures, focusing on e-commerce presentations, and on e-commerce users.
The unique characteristics of e-commerce users make modeling for e-commerce users essential when attempting to understand and support information discovery <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lo2016understanding</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Huangwww2018</span>]</cite>.
E-commerce user modeling can be separated into two types: <em class="ltx_emph ltx_font_italic" id="Ch4.p1.1.1">user behavior modeling</em> and <em class="ltx_emph ltx_font_italic" id="Ch4.p1.1.2">user profiling</em>.
Given specific user behavior in various scenarios, e.g., click behavior, purchasing behavior, and post-click behavior, user behavior modeling focuses on learning a model of user behavior to predict the user’s next preference.
In contrast, user profiling aims to predict a user’s profile (e.g., age, gender, and occupation) given the user’s behavior records.
In this chapter, we survey research on user behavior modeling and user profiling in e-commerce.
First, we detail user behavior modeling approaches in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S1" title="4.1 User behavior modeling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4.1</span></a>.
Next, we discuss studies on user profiling in e-commerce in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S2" title="4.2 User profiling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4.2</span></a>.
Lastly, Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S3" title="4.3 Emerging directions ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4.3</span></a> discusses emerging directions in e-commerce user modeling.</p>
</div>
<section class="ltx_section" id="Ch4.S1">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4.1 </span>User behavior modeling in e-commerce</h3>
<div class="ltx_para" id="Ch4.S1.p1">
<p class="ltx_p" id="Ch4.S1.p1.1">In this section, we describe research on e-commerce user behavior modeling, including click behavior modeling (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S1.SS1" title="4.1.1 Click behavior modeling ‣ 4.1 User behavior modeling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4.1.1</span></a>), post-click behavior tracking (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S1.SS2" title="4.1.2 Post-click behavior tracking ‣ 4.1 User behavior modeling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4.1.2</span></a>), and purchase intent modeling (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S1.SS3" title="4.1.3 Purchase-intent modeling ‣ 4.1 User behavior modeling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4.1.3</span></a>).</p>
</div>
<section class="ltx_subsection" id="Ch4.S1.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1.1 </span>Click behavior modeling</h4>
<div class="ltx_para" id="Ch4.S1.SS1.p1">
<p class="ltx_p" id="Ch4.S1.SS1.p1.1">Click actions recorded in query logs have successfully been applied to extract important features in the context of ranking scenarios <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">agichtein2006improving</span>]</cite>.
Regarding web search, click models have been proposed to help the search engine to accurately understand interactive user behavior <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2009efficient</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yilmaz2010expected</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2011user</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chuklin-click-2015</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">borisov2016neural</span>]</cite>.
Early research on the topic aimed to track a user’s behavior by using probabilistic graphical models.
More recently, neural networks have been applied to improve the performance of click models by representing user behavior to capture the user’s information needs <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">borisov2016neural</span>]</cite>.
Focusing on improving the effectiveness by exploiting information from user-system interactions, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ferro2017including</span></cite> decided to explore embedding dynamic interactions into learning to rank frameworks.
Thereafter, curriculum learning and continuation methods have been successfully applied to exploit user interactions and facilitate rank learning <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ferro2019boosting</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch4.S1.SS1.p2">
<p class="ltx_p" id="Ch4.S1.SS1.p2.1">Given the work mentioned above, click behavior modeling has received an increasing amount of attention in e-commerce scenarios <cite class="ltx_cite ltx_citemacro_citep">[see, e.g., <span class="ltx_ref ltx_missing_citation ltx_ref_self">he2014practical</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chapelle2015simple</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2016deep</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">he2017neural</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">LiRCRLM17</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhouwsdm2018</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">huang2019ecompred</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gong2020edgerec</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">bian2021contra</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2021hierarchy</span>]</cite>.
Viewing click prediction as a binary classification problem, the researchers who conducted those early studies employed logistic regression to predict whether an item will be clicked <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">richardson2007predicting</span>]</cite>, where handcrafted features are extracted from raw data to optimize a log-likelihood objective function for training.
Latent factor optimization approaches, e.g., factorization machines <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">FM</span>]</cite>, have also been applied to utilize importance-aware and hierarchical structures purposed to manage dynamic user behavior <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">oentaryo2014predicting</span>]</cite>. In Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S3.SS2" title="6.3.2 Polynomial models ‣ 6.3 Candidate ranking models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6.3.2</span></a>, we detail studies about factorization machines in e-commerce recommendation.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch4.S1.SS1.p3">
<p class="ltx_p" id="Ch4.S1.SS1.p3.7"><span class="ltx_text ltx_font_bold" id="Ch4.S1.SS1.p3.7.1">CTR prediction metric.</span>
The <em class="ltx_emph ltx_font_italic" id="Ch4.S1.SS1.p3.7.2">click-through rate</em> (CTR) is a widely applied evaluation metric for click prediction that reflects the probability of a click in a trial impression.
Following <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">regelson2006predicting</span></cite>, we established <math alttext="p" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p3.1.m1.1"><semantics id="Ch4.S1.SS1.p3.1.m1.1a"><mi id="Ch4.S1.SS1.p3.1.m1.1.1" xref="Ch4.S1.SS1.p3.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p3.1.m1.1b"><ci id="Ch4.S1.SS1.p3.1.m1.1.1.cmml" xref="Ch4.S1.SS1.p3.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p3.1.m1.1c">p</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p3.1.m1.1d">italic_p</annotation></semantics></math> as the probability of a click, <math alttext="P=\{p_{1},p_{2},\ldots,p_{N}\}" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p3.2.m2.4"><semantics id="Ch4.S1.SS1.p3.2.m2.4a"><mrow id="Ch4.S1.SS1.p3.2.m2.4.4" xref="Ch4.S1.SS1.p3.2.m2.4.4.cmml"><mi id="Ch4.S1.SS1.p3.2.m2.4.4.5" xref="Ch4.S1.SS1.p3.2.m2.4.4.5.cmml">P</mi><mo id="Ch4.S1.SS1.p3.2.m2.4.4.4" xref="Ch4.S1.SS1.p3.2.m2.4.4.4.cmml">=</mo><mrow id="Ch4.S1.SS1.p3.2.m2.4.4.3.3" xref="Ch4.S1.SS1.p3.2.m2.4.4.3.4.cmml"><mo id="Ch4.S1.SS1.p3.2.m2.4.4.3.3.4" stretchy="false" xref="Ch4.S1.SS1.p3.2.m2.4.4.3.4.cmml">{</mo><msub id="Ch4.S1.SS1.p3.2.m2.2.2.1.1.1" xref="Ch4.S1.SS1.p3.2.m2.2.2.1.1.1.cmml"><mi id="Ch4.S1.SS1.p3.2.m2.2.2.1.1.1.2" xref="Ch4.S1.SS1.p3.2.m2.2.2.1.1.1.2.cmml">p</mi><mn id="Ch4.S1.SS1.p3.2.m2.2.2.1.1.1.3" xref="Ch4.S1.SS1.p3.2.m2.2.2.1.1.1.3.cmml">1</mn></msub><mo id="Ch4.S1.SS1.p3.2.m2.4.4.3.3.5" xref="Ch4.S1.SS1.p3.2.m2.4.4.3.4.cmml">,</mo><msub id="Ch4.S1.SS1.p3.2.m2.3.3.2.2.2" xref="Ch4.S1.SS1.p3.2.m2.3.3.2.2.2.cmml"><mi id="Ch4.S1.SS1.p3.2.m2.3.3.2.2.2.2" xref="Ch4.S1.SS1.p3.2.m2.3.3.2.2.2.2.cmml">p</mi><mn id="Ch4.S1.SS1.p3.2.m2.3.3.2.2.2.3" xref="Ch4.S1.SS1.p3.2.m2.3.3.2.2.2.3.cmml">2</mn></msub><mo id="Ch4.S1.SS1.p3.2.m2.4.4.3.3.6" xref="Ch4.S1.SS1.p3.2.m2.4.4.3.4.cmml">,</mo><mi id="Ch4.S1.SS1.p3.2.m2.1.1" mathvariant="normal" xref="Ch4.S1.SS1.p3.2.m2.1.1.cmml">…</mi><mo id="Ch4.S1.SS1.p3.2.m2.4.4.3.3.7" xref="Ch4.S1.SS1.p3.2.m2.4.4.3.4.cmml">,</mo><msub id="Ch4.S1.SS1.p3.2.m2.4.4.3.3.3" xref="Ch4.S1.SS1.p3.2.m2.4.4.3.3.3.cmml"><mi id="Ch4.S1.SS1.p3.2.m2.4.4.3.3.3.2" xref="Ch4.S1.SS1.p3.2.m2.4.4.3.3.3.2.cmml">p</mi><mi id="Ch4.S1.SS1.p3.2.m2.4.4.3.3.3.3" xref="Ch4.S1.SS1.p3.2.m2.4.4.3.3.3.3.cmml">N</mi></msub><mo id="Ch4.S1.SS1.p3.2.m2.4.4.3.3.8" stretchy="false" xref="Ch4.S1.SS1.p3.2.m2.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p3.2.m2.4b"><apply id="Ch4.S1.SS1.p3.2.m2.4.4.cmml" xref="Ch4.S1.SS1.p3.2.m2.4.4"><eq id="Ch4.S1.SS1.p3.2.m2.4.4.4.cmml" xref="Ch4.S1.SS1.p3.2.m2.4.4.4"></eq><ci id="Ch4.S1.SS1.p3.2.m2.4.4.5.cmml" xref="Ch4.S1.SS1.p3.2.m2.4.4.5">𝑃</ci><set id="Ch4.S1.SS1.p3.2.m2.4.4.3.4.cmml" xref="Ch4.S1.SS1.p3.2.m2.4.4.3.3"><apply id="Ch4.S1.SS1.p3.2.m2.2.2.1.1.1.cmml" xref="Ch4.S1.SS1.p3.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p3.2.m2.2.2.1.1.1.1.cmml" xref="Ch4.S1.SS1.p3.2.m2.2.2.1.1.1">subscript</csymbol><ci id="Ch4.S1.SS1.p3.2.m2.2.2.1.1.1.2.cmml" xref="Ch4.S1.SS1.p3.2.m2.2.2.1.1.1.2">𝑝</ci><cn id="Ch4.S1.SS1.p3.2.m2.2.2.1.1.1.3.cmml" type="integer" xref="Ch4.S1.SS1.p3.2.m2.2.2.1.1.1.3">1</cn></apply><apply id="Ch4.S1.SS1.p3.2.m2.3.3.2.2.2.cmml" xref="Ch4.S1.SS1.p3.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p3.2.m2.3.3.2.2.2.1.cmml" xref="Ch4.S1.SS1.p3.2.m2.3.3.2.2.2">subscript</csymbol><ci id="Ch4.S1.SS1.p3.2.m2.3.3.2.2.2.2.cmml" xref="Ch4.S1.SS1.p3.2.m2.3.3.2.2.2.2">𝑝</ci><cn id="Ch4.S1.SS1.p3.2.m2.3.3.2.2.2.3.cmml" type="integer" xref="Ch4.S1.SS1.p3.2.m2.3.3.2.2.2.3">2</cn></apply><ci id="Ch4.S1.SS1.p3.2.m2.1.1.cmml" xref="Ch4.S1.SS1.p3.2.m2.1.1">…</ci><apply id="Ch4.S1.SS1.p3.2.m2.4.4.3.3.3.cmml" xref="Ch4.S1.SS1.p3.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p3.2.m2.4.4.3.3.3.1.cmml" xref="Ch4.S1.SS1.p3.2.m2.4.4.3.3.3">subscript</csymbol><ci id="Ch4.S1.SS1.p3.2.m2.4.4.3.3.3.2.cmml" xref="Ch4.S1.SS1.p3.2.m2.4.4.3.3.3.2">𝑝</ci><ci id="Ch4.S1.SS1.p3.2.m2.4.4.3.3.3.3.cmml" xref="Ch4.S1.SS1.p3.2.m2.4.4.3.3.3.3">𝑁</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p3.2.m2.4c">P=\{p_{1},p_{2},\ldots,p_{N}\}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p3.2.m2.4d">italic_P = { italic_p start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_p start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_p start_POSTSUBSCRIPT italic_N end_POSTSUBSCRIPT }</annotation></semantics></math> as the set of product items, and <math alttext="U=\{u_{1},u_{2},\ldots,u_{M}\}" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p3.3.m3.4"><semantics id="Ch4.S1.SS1.p3.3.m3.4a"><mrow id="Ch4.S1.SS1.p3.3.m3.4.4" xref="Ch4.S1.SS1.p3.3.m3.4.4.cmml"><mi id="Ch4.S1.SS1.p3.3.m3.4.4.5" xref="Ch4.S1.SS1.p3.3.m3.4.4.5.cmml">U</mi><mo id="Ch4.S1.SS1.p3.3.m3.4.4.4" xref="Ch4.S1.SS1.p3.3.m3.4.4.4.cmml">=</mo><mrow id="Ch4.S1.SS1.p3.3.m3.4.4.3.3" xref="Ch4.S1.SS1.p3.3.m3.4.4.3.4.cmml"><mo id="Ch4.S1.SS1.p3.3.m3.4.4.3.3.4" stretchy="false" xref="Ch4.S1.SS1.p3.3.m3.4.4.3.4.cmml">{</mo><msub id="Ch4.S1.SS1.p3.3.m3.2.2.1.1.1" xref="Ch4.S1.SS1.p3.3.m3.2.2.1.1.1.cmml"><mi id="Ch4.S1.SS1.p3.3.m3.2.2.1.1.1.2" xref="Ch4.S1.SS1.p3.3.m3.2.2.1.1.1.2.cmml">u</mi><mn id="Ch4.S1.SS1.p3.3.m3.2.2.1.1.1.3" xref="Ch4.S1.SS1.p3.3.m3.2.2.1.1.1.3.cmml">1</mn></msub><mo id="Ch4.S1.SS1.p3.3.m3.4.4.3.3.5" xref="Ch4.S1.SS1.p3.3.m3.4.4.3.4.cmml">,</mo><msub id="Ch4.S1.SS1.p3.3.m3.3.3.2.2.2" xref="Ch4.S1.SS1.p3.3.m3.3.3.2.2.2.cmml"><mi id="Ch4.S1.SS1.p3.3.m3.3.3.2.2.2.2" xref="Ch4.S1.SS1.p3.3.m3.3.3.2.2.2.2.cmml">u</mi><mn id="Ch4.S1.SS1.p3.3.m3.3.3.2.2.2.3" xref="Ch4.S1.SS1.p3.3.m3.3.3.2.2.2.3.cmml">2</mn></msub><mo id="Ch4.S1.SS1.p3.3.m3.4.4.3.3.6" xref="Ch4.S1.SS1.p3.3.m3.4.4.3.4.cmml">,</mo><mi id="Ch4.S1.SS1.p3.3.m3.1.1" mathvariant="normal" xref="Ch4.S1.SS1.p3.3.m3.1.1.cmml">…</mi><mo id="Ch4.S1.SS1.p3.3.m3.4.4.3.3.7" xref="Ch4.S1.SS1.p3.3.m3.4.4.3.4.cmml">,</mo><msub id="Ch4.S1.SS1.p3.3.m3.4.4.3.3.3" xref="Ch4.S1.SS1.p3.3.m3.4.4.3.3.3.cmml"><mi id="Ch4.S1.SS1.p3.3.m3.4.4.3.3.3.2" xref="Ch4.S1.SS1.p3.3.m3.4.4.3.3.3.2.cmml">u</mi><mi id="Ch4.S1.SS1.p3.3.m3.4.4.3.3.3.3" xref="Ch4.S1.SS1.p3.3.m3.4.4.3.3.3.3.cmml">M</mi></msub><mo id="Ch4.S1.SS1.p3.3.m3.4.4.3.3.8" stretchy="false" xref="Ch4.S1.SS1.p3.3.m3.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p3.3.m3.4b"><apply id="Ch4.S1.SS1.p3.3.m3.4.4.cmml" xref="Ch4.S1.SS1.p3.3.m3.4.4"><eq id="Ch4.S1.SS1.p3.3.m3.4.4.4.cmml" xref="Ch4.S1.SS1.p3.3.m3.4.4.4"></eq><ci id="Ch4.S1.SS1.p3.3.m3.4.4.5.cmml" xref="Ch4.S1.SS1.p3.3.m3.4.4.5">𝑈</ci><set id="Ch4.S1.SS1.p3.3.m3.4.4.3.4.cmml" xref="Ch4.S1.SS1.p3.3.m3.4.4.3.3"><apply id="Ch4.S1.SS1.p3.3.m3.2.2.1.1.1.cmml" xref="Ch4.S1.SS1.p3.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p3.3.m3.2.2.1.1.1.1.cmml" xref="Ch4.S1.SS1.p3.3.m3.2.2.1.1.1">subscript</csymbol><ci id="Ch4.S1.SS1.p3.3.m3.2.2.1.1.1.2.cmml" xref="Ch4.S1.SS1.p3.3.m3.2.2.1.1.1.2">𝑢</ci><cn id="Ch4.S1.SS1.p3.3.m3.2.2.1.1.1.3.cmml" type="integer" xref="Ch4.S1.SS1.p3.3.m3.2.2.1.1.1.3">1</cn></apply><apply id="Ch4.S1.SS1.p3.3.m3.3.3.2.2.2.cmml" xref="Ch4.S1.SS1.p3.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p3.3.m3.3.3.2.2.2.1.cmml" xref="Ch4.S1.SS1.p3.3.m3.3.3.2.2.2">subscript</csymbol><ci id="Ch4.S1.SS1.p3.3.m3.3.3.2.2.2.2.cmml" xref="Ch4.S1.SS1.p3.3.m3.3.3.2.2.2.2">𝑢</ci><cn id="Ch4.S1.SS1.p3.3.m3.3.3.2.2.2.3.cmml" type="integer" xref="Ch4.S1.SS1.p3.3.m3.3.3.2.2.2.3">2</cn></apply><ci id="Ch4.S1.SS1.p3.3.m3.1.1.cmml" xref="Ch4.S1.SS1.p3.3.m3.1.1">…</ci><apply id="Ch4.S1.SS1.p3.3.m3.4.4.3.3.3.cmml" xref="Ch4.S1.SS1.p3.3.m3.4.4.3.3.3"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p3.3.m3.4.4.3.3.3.1.cmml" xref="Ch4.S1.SS1.p3.3.m3.4.4.3.3.3">subscript</csymbol><ci id="Ch4.S1.SS1.p3.3.m3.4.4.3.3.3.2.cmml" xref="Ch4.S1.SS1.p3.3.m3.4.4.3.3.3.2">𝑢</ci><ci id="Ch4.S1.SS1.p3.3.m3.4.4.3.3.3.3.cmml" xref="Ch4.S1.SS1.p3.3.m3.4.4.3.3.3.3">𝑀</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p3.3.m3.4c">U=\{u_{1},u_{2},\ldots,u_{M}\}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p3.3.m3.4d">italic_U = { italic_u start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_u start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_u start_POSTSUBSCRIPT italic_M end_POSTSUBSCRIPT }</annotation></semantics></math> to represent the set of users.

The maximum-likelihood estimate of <math alttext="p" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p3.4.m4.1"><semantics id="Ch4.S1.SS1.p3.4.m4.1a"><mi id="Ch4.S1.SS1.p3.4.m4.1.1" xref="Ch4.S1.SS1.p3.4.m4.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p3.4.m4.1b"><ci id="Ch4.S1.SS1.p3.4.m4.1.1.cmml" xref="Ch4.S1.SS1.p3.4.m4.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p3.4.m4.1c">p</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p3.4.m4.1d">italic_p</annotation></semantics></math> refers to the number of observed successes divided by the number of trials, i.e., clicks/impressions.
Given a set of search or recommendation sessions <math alttext="S" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p3.5.m5.1"><semantics id="Ch4.S1.SS1.p3.5.m5.1a"><mi id="Ch4.S1.SS1.p3.5.m5.1.1" xref="Ch4.S1.SS1.p3.5.m5.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p3.5.m5.1b"><ci id="Ch4.S1.SS1.p3.5.m5.1.1.cmml" xref="Ch4.S1.SS1.p3.5.m5.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p3.5.m5.1c">S</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p3.5.m5.1d">italic_S</annotation></semantics></math> and a query <math alttext="q" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p3.6.m6.1"><semantics id="Ch4.S1.SS1.p3.6.m6.1a"><mi id="Ch4.S1.SS1.p3.6.m6.1.1" xref="Ch4.S1.SS1.p3.6.m6.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p3.6.m6.1b"><ci id="Ch4.S1.SS1.p3.6.m6.1.1.cmml" xref="Ch4.S1.SS1.p3.6.m6.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p3.6.m6.1c">q</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p3.6.m6.1d">italic_q</annotation></semantics></math>, the probability of a product <math alttext="\operatorname{CTR}(p{\mid}q)" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p3.7.m7.2"><semantics id="Ch4.S1.SS1.p3.7.m7.2a"><mrow id="Ch4.S1.SS1.p3.7.m7.2.2.1" xref="Ch4.S1.SS1.p3.7.m7.2.2.2.cmml"><mi id="Ch4.S1.SS1.p3.7.m7.1.1" xref="Ch4.S1.SS1.p3.7.m7.1.1.cmml">CTR</mi><mo id="Ch4.S1.SS1.p3.7.m7.2.2.1a" xref="Ch4.S1.SS1.p3.7.m7.2.2.2.cmml">⁡</mo><mrow id="Ch4.S1.SS1.p3.7.m7.2.2.1.1" xref="Ch4.S1.SS1.p3.7.m7.2.2.2.cmml"><mo id="Ch4.S1.SS1.p3.7.m7.2.2.1.1.2" stretchy="false" xref="Ch4.S1.SS1.p3.7.m7.2.2.2.cmml">(</mo><mrow id="Ch4.S1.SS1.p3.7.m7.2.2.1.1.1" xref="Ch4.S1.SS1.p3.7.m7.2.2.1.1.1.cmml"><mi id="Ch4.S1.SS1.p3.7.m7.2.2.1.1.1.2" xref="Ch4.S1.SS1.p3.7.m7.2.2.1.1.1.2.cmml">p</mi><mo id="Ch4.S1.SS1.p3.7.m7.2.2.1.1.1.1" xref="Ch4.S1.SS1.p3.7.m7.2.2.1.1.1.1.cmml">∣</mo><mi id="Ch4.S1.SS1.p3.7.m7.2.2.1.1.1.3" xref="Ch4.S1.SS1.p3.7.m7.2.2.1.1.1.3.cmml">q</mi></mrow><mo id="Ch4.S1.SS1.p3.7.m7.2.2.1.1.3" stretchy="false" xref="Ch4.S1.SS1.p3.7.m7.2.2.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p3.7.m7.2b"><apply id="Ch4.S1.SS1.p3.7.m7.2.2.2.cmml" xref="Ch4.S1.SS1.p3.7.m7.2.2.1"><ci id="Ch4.S1.SS1.p3.7.m7.1.1.cmml" xref="Ch4.S1.SS1.p3.7.m7.1.1">CTR</ci><apply id="Ch4.S1.SS1.p3.7.m7.2.2.1.1.1.cmml" xref="Ch4.S1.SS1.p3.7.m7.2.2.1.1.1"><csymbol cd="latexml" id="Ch4.S1.SS1.p3.7.m7.2.2.1.1.1.1.cmml" xref="Ch4.S1.SS1.p3.7.m7.2.2.1.1.1.1">conditional</csymbol><ci id="Ch4.S1.SS1.p3.7.m7.2.2.1.1.1.2.cmml" xref="Ch4.S1.SS1.p3.7.m7.2.2.1.1.1.2">𝑝</ci><ci id="Ch4.S1.SS1.p3.7.m7.2.2.1.1.1.3.cmml" xref="Ch4.S1.SS1.p3.7.m7.2.2.1.1.1.3">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p3.7.m7.2c">\operatorname{CTR}(p{\mid}q)</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p3.7.m7.2d">roman_CTR ( italic_p ∣ italic_q )</annotation></semantics></math> can be formulated as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="Ch4.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\operatorname{CTR}(p{\mid}q)=\sum\limits_{{s^{q}}\in S}{{{{\Psi^{{s^{q}}}}(p)}%
\over{{\mid}{s^{q}}\in S{\mid}}}}," class="ltx_math_unparsed" display="block" id="Ch4.E1.m1.3"><semantics id="Ch4.E1.m1.3a"><mrow id="Ch4.E1.m1.3.3.1"><mrow id="Ch4.E1.m1.3.3.1.1"><mrow id="Ch4.E1.m1.3.3.1.1.1.1"><mi id="Ch4.E1.m1.2.2">CTR</mi><mo id="Ch4.E1.m1.3.3.1.1.1.1a">⁡</mo><mrow id="Ch4.E1.m1.3.3.1.1.1.1.1"><mo id="Ch4.E1.m1.3.3.1.1.1.1.1.2" stretchy="false">(</mo><mrow id="Ch4.E1.m1.3.3.1.1.1.1.1.1"><mi id="Ch4.E1.m1.3.3.1.1.1.1.1.1.2">p</mi><mo id="Ch4.E1.m1.3.3.1.1.1.1.1.1.1">∣</mo><mi id="Ch4.E1.m1.3.3.1.1.1.1.1.1.3">q</mi></mrow><mo id="Ch4.E1.m1.3.3.1.1.1.1.1.3" stretchy="false">)</mo></mrow></mrow><mo id="Ch4.E1.m1.3.3.1.1.2" rspace="0.111em">=</mo><mrow id="Ch4.E1.m1.3.3.1.1.3"><munder id="Ch4.E1.m1.3.3.1.1.3.1"><mo id="Ch4.E1.m1.3.3.1.1.3.1.2" movablelimits="false">∑</mo><mrow id="Ch4.E1.m1.3.3.1.1.3.1.3"><msup id="Ch4.E1.m1.3.3.1.1.3.1.3.2"><mi id="Ch4.E1.m1.3.3.1.1.3.1.3.2.2">s</mi><mi id="Ch4.E1.m1.3.3.1.1.3.1.3.2.3">q</mi></msup><mo id="Ch4.E1.m1.3.3.1.1.3.1.3.1">∈</mo><mi id="Ch4.E1.m1.3.3.1.1.3.1.3.3">S</mi></mrow></munder><mfrac id="Ch4.E1.m1.1.1"><mrow id="Ch4.E1.m1.1.1.1"><msup id="Ch4.E1.m1.1.1.1.3"><mi id="Ch4.E1.m1.1.1.1.3.2" mathvariant="normal">Ψ</mi><msup id="Ch4.E1.m1.1.1.1.3.3"><mi id="Ch4.E1.m1.1.1.1.3.3.2">s</mi><mi id="Ch4.E1.m1.1.1.1.3.3.3">q</mi></msup></msup><mo id="Ch4.E1.m1.1.1.1.2">⁢</mo><mrow id="Ch4.E1.m1.1.1.1.4.2"><mo id="Ch4.E1.m1.1.1.1.4.2.1" stretchy="false">(</mo><mi id="Ch4.E1.m1.1.1.1.1">p</mi><mo id="Ch4.E1.m1.1.1.1.4.2.2" stretchy="false">)</mo></mrow></mrow><mrow id="Ch4.E1.m1.1.1.3"><mo id="Ch4.E1.m1.1.1.3.1" rspace="0.167em">∣</mo><msup id="Ch4.E1.m1.1.1.3.2"><mi id="Ch4.E1.m1.1.1.3.2.2">s</mi><mi id="Ch4.E1.m1.1.1.3.2.3">q</mi></msup><mo id="Ch4.E1.m1.1.1.3.3">∈</mo><mi id="Ch4.E1.m1.1.1.3.4">S</mi><mo id="Ch4.E1.m1.1.1.3.5" lspace="0em">∣</mo></mrow></mfrac></mrow></mrow><mo id="Ch4.E1.m1.3.3.1.2">,</mo></mrow><annotation encoding="application/x-tex" id="Ch4.E1.m1.3b">\operatorname{CTR}(p{\mid}q)=\sum\limits_{{s^{q}}\in S}{{{{\Psi^{{s^{q}}}}(p)}%
\over{{\mid}{s^{q}}\in S{\mid}}}},</annotation><annotation encoding="application/x-llamapun" id="Ch4.E1.m1.3c">roman_CTR ( italic_p ∣ italic_q ) = ∑ start_POSTSUBSCRIPT italic_s start_POSTSUPERSCRIPT italic_q end_POSTSUPERSCRIPT ∈ italic_S end_POSTSUBSCRIPT divide start_ARG roman_Ψ start_POSTSUPERSCRIPT italic_s start_POSTSUPERSCRIPT italic_q end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT ( italic_p ) end_ARG start_ARG ∣ italic_s start_POSTSUPERSCRIPT italic_q end_POSTSUPERSCRIPT ∈ italic_S ∣ end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4.1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch4.S1.SS1.p3.11">where <math alttext="s^{q}" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p3.8.m1.1"><semantics id="Ch4.S1.SS1.p3.8.m1.1a"><msup id="Ch4.S1.SS1.p3.8.m1.1.1" xref="Ch4.S1.SS1.p3.8.m1.1.1.cmml"><mi id="Ch4.S1.SS1.p3.8.m1.1.1.2" xref="Ch4.S1.SS1.p3.8.m1.1.1.2.cmml">s</mi><mi id="Ch4.S1.SS1.p3.8.m1.1.1.3" xref="Ch4.S1.SS1.p3.8.m1.1.1.3.cmml">q</mi></msup><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p3.8.m1.1b"><apply id="Ch4.S1.SS1.p3.8.m1.1.1.cmml" xref="Ch4.S1.SS1.p3.8.m1.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p3.8.m1.1.1.1.cmml" xref="Ch4.S1.SS1.p3.8.m1.1.1">superscript</csymbol><ci id="Ch4.S1.SS1.p3.8.m1.1.1.2.cmml" xref="Ch4.S1.SS1.p3.8.m1.1.1.2">𝑠</ci><ci id="Ch4.S1.SS1.p3.8.m1.1.1.3.cmml" xref="Ch4.S1.SS1.p3.8.m1.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p3.8.m1.1c">s^{q}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p3.8.m1.1d">italic_s start_POSTSUPERSCRIPT italic_q end_POSTSUPERSCRIPT</annotation></semantics></math> denotes a session with <math alttext="q" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p3.9.m2.1"><semantics id="Ch4.S1.SS1.p3.9.m2.1a"><mi id="Ch4.S1.SS1.p3.9.m2.1.1" xref="Ch4.S1.SS1.p3.9.m2.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p3.9.m2.1b"><ci id="Ch4.S1.SS1.p3.9.m2.1.1.cmml" xref="Ch4.S1.SS1.p3.9.m2.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p3.9.m2.1c">q</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p3.9.m2.1d">italic_q</annotation></semantics></math>, and <math alttext="\Psi^{{s^{q}}}" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p3.10.m3.1"><semantics id="Ch4.S1.SS1.p3.10.m3.1a"><msup id="Ch4.S1.SS1.p3.10.m3.1.1" xref="Ch4.S1.SS1.p3.10.m3.1.1.cmml"><mi id="Ch4.S1.SS1.p3.10.m3.1.1.2" mathvariant="normal" xref="Ch4.S1.SS1.p3.10.m3.1.1.2.cmml">Ψ</mi><msup id="Ch4.S1.SS1.p3.10.m3.1.1.3" xref="Ch4.S1.SS1.p3.10.m3.1.1.3.cmml"><mi id="Ch4.S1.SS1.p3.10.m3.1.1.3.2" xref="Ch4.S1.SS1.p3.10.m3.1.1.3.2.cmml">s</mi><mi id="Ch4.S1.SS1.p3.10.m3.1.1.3.3" xref="Ch4.S1.SS1.p3.10.m3.1.1.3.3.cmml">q</mi></msup></msup><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p3.10.m3.1b"><apply id="Ch4.S1.SS1.p3.10.m3.1.1.cmml" xref="Ch4.S1.SS1.p3.10.m3.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p3.10.m3.1.1.1.cmml" xref="Ch4.S1.SS1.p3.10.m3.1.1">superscript</csymbol><ci id="Ch4.S1.SS1.p3.10.m3.1.1.2.cmml" xref="Ch4.S1.SS1.p3.10.m3.1.1.2">Ψ</ci><apply id="Ch4.S1.SS1.p3.10.m3.1.1.3.cmml" xref="Ch4.S1.SS1.p3.10.m3.1.1.3"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p3.10.m3.1.1.3.1.cmml" xref="Ch4.S1.SS1.p3.10.m3.1.1.3">superscript</csymbol><ci id="Ch4.S1.SS1.p3.10.m3.1.1.3.2.cmml" xref="Ch4.S1.SS1.p3.10.m3.1.1.3.2">𝑠</ci><ci id="Ch4.S1.SS1.p3.10.m3.1.1.3.3.cmml" xref="Ch4.S1.SS1.p3.10.m3.1.1.3.3">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p3.10.m3.1c">\Psi^{{s^{q}}}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p3.10.m3.1d">roman_Ψ start_POSTSUPERSCRIPT italic_s start_POSTSUPERSCRIPT italic_q end_POSTSUPERSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math> denotes an event of a click within <math alttext="s^{q}" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p3.11.m4.1"><semantics id="Ch4.S1.SS1.p3.11.m4.1a"><msup id="Ch4.S1.SS1.p3.11.m4.1.1" xref="Ch4.S1.SS1.p3.11.m4.1.1.cmml"><mi id="Ch4.S1.SS1.p3.11.m4.1.1.2" xref="Ch4.S1.SS1.p3.11.m4.1.1.2.cmml">s</mi><mi id="Ch4.S1.SS1.p3.11.m4.1.1.3" xref="Ch4.S1.SS1.p3.11.m4.1.1.3.cmml">q</mi></msup><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p3.11.m4.1b"><apply id="Ch4.S1.SS1.p3.11.m4.1.1.cmml" xref="Ch4.S1.SS1.p3.11.m4.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p3.11.m4.1.1.1.cmml" xref="Ch4.S1.SS1.p3.11.m4.1.1">superscript</csymbol><ci id="Ch4.S1.SS1.p3.11.m4.1.1.2.cmml" xref="Ch4.S1.SS1.p3.11.m4.1.1.2">𝑠</ci><ci id="Ch4.S1.SS1.p3.11.m4.1.1.3.cmml" xref="Ch4.S1.SS1.p3.11.m4.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p3.11.m4.1c">s^{q}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p3.11.m4.1d">italic_s start_POSTSUPERSCRIPT italic_q end_POSTSUPERSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch4.S1.SS1.p4">
<p class="ltx_p" id="Ch4.S1.SS1.p4.1"><span class="ltx_text ltx_font_bold" id="Ch4.S1.SS1.p4.1.1">From shallow to deep models.</span>
CTR has been widely applied as an evaluation metric for click modeling in e-commerce portals.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">rendle2010pairwise</span></cite> proposed a tensor-based method for CTR prediction; Bayesian approaches have also been used effectively for CTR prediction <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">graepel2010web</span>]</cite>.
Starting in 2015, deep learning significantly improved CTR estimation by transferring traditional architectures and developing new ones. Deep neural networks effectively capture high-order feature interactions, resulting in better CTR prediction performance.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2016deep</span></cite> proposed a deep neural network to learn patterns from categorical feature interactions. Similarly, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2016deep</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhu2017optimized</span></cite> employed neural network models with multiple fully-connected layers to predict user clicks.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">aryafar2017ensemble</span></cite> investigated CTR prediction in promoted listings by using an ensemble learning approach to leverage different signals of listings.
Generally, these logistic regression models can effectively achieve memorization by applying cross-product transformations over sparse features.
Recent work involves representing sparse features as dense vectors, which are concatenated to form an instance vector. This vector is then passed through a multi-layer perceptron, with a sigmoid output layer, to predict the click probability. These advancements have greatly enhanced model accuracy in CTR tasks <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2021deep</span>]</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch4.S1.SS1.p5">
<p class="ltx_p" id="Ch4.S1.SS1.p5.5"><span class="ltx_text ltx_font_bold" id="Ch4.S1.SS1.p5.5.1">Wide &amp; Deep model.</span>
Modeling the interactions between features, especially the interactions between low-order and high-order features, is essential for click prediction. The Wide &amp; Deep model <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">cheng2016wide</span>]</cite> considers low- and high-order feature interactions simultaneously.
Wide &amp; Deep pursues the balance between memorization and generalization.
Owing to its simple structure, the “strong” features (i.e., feature combinations) of Wide &amp; Deep allow for the assignment of larger weights during training, thus endowing the model with stronger memory.
Besides the deep component based on MLP, Wide &amp; Deep consists of another components, the wide component.

It is a generalized linear model with an input feature set that includes raw features and a feature that has been transformed by the cross-product transformation and is defined as</p>
<table class="ltx_equationgroup ltx_eqn_gather ltx_eqn_table" id="A1.S5.EGx1">
<tbody id="Ch4.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\displaystyle\phi_{k}(x)=\prod_{i=1}^{d}x_{i}^{c_{ki}},\quad c_{ki}\in\{0,1\}" class="ltx_Math" display="block" id="Ch4.E2.m1.5"><semantics id="Ch4.E2.m1.5a"><mrow id="Ch4.E2.m1.5.5.2" xref="Ch4.E2.m1.5.5.3.cmml"><mrow id="Ch4.E2.m1.4.4.1.1" xref="Ch4.E2.m1.4.4.1.1.cmml"><mrow id="Ch4.E2.m1.4.4.1.1.2" xref="Ch4.E2.m1.4.4.1.1.2.cmml"><msub id="Ch4.E2.m1.4.4.1.1.2.2" xref="Ch4.E2.m1.4.4.1.1.2.2.cmml"><mi id="Ch4.E2.m1.4.4.1.1.2.2.2" xref="Ch4.E2.m1.4.4.1.1.2.2.2.cmml">ϕ</mi><mi id="Ch4.E2.m1.4.4.1.1.2.2.3" xref="Ch4.E2.m1.4.4.1.1.2.2.3.cmml">k</mi></msub><mo id="Ch4.E2.m1.4.4.1.1.2.1" xref="Ch4.E2.m1.4.4.1.1.2.1.cmml">⁢</mo><mrow id="Ch4.E2.m1.4.4.1.1.2.3.2" xref="Ch4.E2.m1.4.4.1.1.2.cmml"><mo id="Ch4.E2.m1.4.4.1.1.2.3.2.1" stretchy="false" xref="Ch4.E2.m1.4.4.1.1.2.cmml">(</mo><mi id="Ch4.E2.m1.1.1" xref="Ch4.E2.m1.1.1.cmml">x</mi><mo id="Ch4.E2.m1.4.4.1.1.2.3.2.2" stretchy="false" xref="Ch4.E2.m1.4.4.1.1.2.cmml">)</mo></mrow></mrow><mo id="Ch4.E2.m1.4.4.1.1.1" rspace="0.111em" xref="Ch4.E2.m1.4.4.1.1.1.cmml">=</mo><mrow id="Ch4.E2.m1.4.4.1.1.3" xref="Ch4.E2.m1.4.4.1.1.3.cmml"><munderover id="Ch4.E2.m1.4.4.1.1.3.1" xref="Ch4.E2.m1.4.4.1.1.3.1.cmml"><mo id="Ch4.E2.m1.4.4.1.1.3.1.2.2" movablelimits="false" xref="Ch4.E2.m1.4.4.1.1.3.1.2.2.cmml">∏</mo><mrow id="Ch4.E2.m1.4.4.1.1.3.1.2.3" xref="Ch4.E2.m1.4.4.1.1.3.1.2.3.cmml"><mi id="Ch4.E2.m1.4.4.1.1.3.1.2.3.2" xref="Ch4.E2.m1.4.4.1.1.3.1.2.3.2.cmml">i</mi><mo id="Ch4.E2.m1.4.4.1.1.3.1.2.3.1" xref="Ch4.E2.m1.4.4.1.1.3.1.2.3.1.cmml">=</mo><mn id="Ch4.E2.m1.4.4.1.1.3.1.2.3.3" xref="Ch4.E2.m1.4.4.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="Ch4.E2.m1.4.4.1.1.3.1.3" xref="Ch4.E2.m1.4.4.1.1.3.1.3.cmml">d</mi></munderover><msubsup id="Ch4.E2.m1.4.4.1.1.3.2" xref="Ch4.E2.m1.4.4.1.1.3.2.cmml"><mi id="Ch4.E2.m1.4.4.1.1.3.2.2.2" xref="Ch4.E2.m1.4.4.1.1.3.2.2.2.cmml">x</mi><mi id="Ch4.E2.m1.4.4.1.1.3.2.2.3" xref="Ch4.E2.m1.4.4.1.1.3.2.2.3.cmml">i</mi><msub id="Ch4.E2.m1.4.4.1.1.3.2.3" xref="Ch4.E2.m1.4.4.1.1.3.2.3.cmml"><mi id="Ch4.E2.m1.4.4.1.1.3.2.3.2" xref="Ch4.E2.m1.4.4.1.1.3.2.3.2.cmml">c</mi><mrow id="Ch4.E2.m1.4.4.1.1.3.2.3.3" xref="Ch4.E2.m1.4.4.1.1.3.2.3.3.cmml"><mi id="Ch4.E2.m1.4.4.1.1.3.2.3.3.2" xref="Ch4.E2.m1.4.4.1.1.3.2.3.3.2.cmml">k</mi><mo id="Ch4.E2.m1.4.4.1.1.3.2.3.3.1" xref="Ch4.E2.m1.4.4.1.1.3.2.3.3.1.cmml">⁢</mo><mi id="Ch4.E2.m1.4.4.1.1.3.2.3.3.3" xref="Ch4.E2.m1.4.4.1.1.3.2.3.3.3.cmml">i</mi></mrow></msub></msubsup></mrow></mrow><mo id="Ch4.E2.m1.5.5.2.3" rspace="1.167em" xref="Ch4.E2.m1.5.5.3a.cmml">,</mo><mrow id="Ch4.E2.m1.5.5.2.2" xref="Ch4.E2.m1.5.5.2.2.cmml"><msub id="Ch4.E2.m1.5.5.2.2.2" xref="Ch4.E2.m1.5.5.2.2.2.cmml"><mi id="Ch4.E2.m1.5.5.2.2.2.2" xref="Ch4.E2.m1.5.5.2.2.2.2.cmml">c</mi><mrow id="Ch4.E2.m1.5.5.2.2.2.3" xref="Ch4.E2.m1.5.5.2.2.2.3.cmml"><mi id="Ch4.E2.m1.5.5.2.2.2.3.2" xref="Ch4.E2.m1.5.5.2.2.2.3.2.cmml">k</mi><mo id="Ch4.E2.m1.5.5.2.2.2.3.1" xref="Ch4.E2.m1.5.5.2.2.2.3.1.cmml">⁢</mo><mi id="Ch4.E2.m1.5.5.2.2.2.3.3" xref="Ch4.E2.m1.5.5.2.2.2.3.3.cmml">i</mi></mrow></msub><mo id="Ch4.E2.m1.5.5.2.2.1" xref="Ch4.E2.m1.5.5.2.2.1.cmml">∈</mo><mrow id="Ch4.E2.m1.5.5.2.2.3.2" xref="Ch4.E2.m1.5.5.2.2.3.1.cmml"><mo id="Ch4.E2.m1.5.5.2.2.3.2.1" stretchy="false" xref="Ch4.E2.m1.5.5.2.2.3.1.cmml">{</mo><mn id="Ch4.E2.m1.2.2" xref="Ch4.E2.m1.2.2.cmml">0</mn><mo id="Ch4.E2.m1.5.5.2.2.3.2.2" xref="Ch4.E2.m1.5.5.2.2.3.1.cmml">,</mo><mn id="Ch4.E2.m1.3.3" xref="Ch4.E2.m1.3.3.cmml">1</mn><mo id="Ch4.E2.m1.5.5.2.2.3.2.3" stretchy="false" xref="Ch4.E2.m1.5.5.2.2.3.1.cmml">}</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch4.E2.m1.5b"><apply id="Ch4.E2.m1.5.5.3.cmml" xref="Ch4.E2.m1.5.5.2"><csymbol cd="ambiguous" id="Ch4.E2.m1.5.5.3a.cmml" xref="Ch4.E2.m1.5.5.2.3">formulae-sequence</csymbol><apply id="Ch4.E2.m1.4.4.1.1.cmml" xref="Ch4.E2.m1.4.4.1.1"><eq id="Ch4.E2.m1.4.4.1.1.1.cmml" xref="Ch4.E2.m1.4.4.1.1.1"></eq><apply id="Ch4.E2.m1.4.4.1.1.2.cmml" xref="Ch4.E2.m1.4.4.1.1.2"><times id="Ch4.E2.m1.4.4.1.1.2.1.cmml" xref="Ch4.E2.m1.4.4.1.1.2.1"></times><apply id="Ch4.E2.m1.4.4.1.1.2.2.cmml" xref="Ch4.E2.m1.4.4.1.1.2.2"><csymbol cd="ambiguous" id="Ch4.E2.m1.4.4.1.1.2.2.1.cmml" xref="Ch4.E2.m1.4.4.1.1.2.2">subscript</csymbol><ci id="Ch4.E2.m1.4.4.1.1.2.2.2.cmml" xref="Ch4.E2.m1.4.4.1.1.2.2.2">italic-ϕ</ci><ci id="Ch4.E2.m1.4.4.1.1.2.2.3.cmml" xref="Ch4.E2.m1.4.4.1.1.2.2.3">𝑘</ci></apply><ci id="Ch4.E2.m1.1.1.cmml" xref="Ch4.E2.m1.1.1">𝑥</ci></apply><apply id="Ch4.E2.m1.4.4.1.1.3.cmml" xref="Ch4.E2.m1.4.4.1.1.3"><apply id="Ch4.E2.m1.4.4.1.1.3.1.cmml" xref="Ch4.E2.m1.4.4.1.1.3.1"><csymbol cd="ambiguous" id="Ch4.E2.m1.4.4.1.1.3.1.1.cmml" xref="Ch4.E2.m1.4.4.1.1.3.1">superscript</csymbol><apply id="Ch4.E2.m1.4.4.1.1.3.1.2.cmml" xref="Ch4.E2.m1.4.4.1.1.3.1"><csymbol cd="ambiguous" id="Ch4.E2.m1.4.4.1.1.3.1.2.1.cmml" xref="Ch4.E2.m1.4.4.1.1.3.1">subscript</csymbol><csymbol cd="latexml" id="Ch4.E2.m1.4.4.1.1.3.1.2.2.cmml" xref="Ch4.E2.m1.4.4.1.1.3.1.2.2">product</csymbol><apply id="Ch4.E2.m1.4.4.1.1.3.1.2.3.cmml" xref="Ch4.E2.m1.4.4.1.1.3.1.2.3"><eq id="Ch4.E2.m1.4.4.1.1.3.1.2.3.1.cmml" xref="Ch4.E2.m1.4.4.1.1.3.1.2.3.1"></eq><ci id="Ch4.E2.m1.4.4.1.1.3.1.2.3.2.cmml" xref="Ch4.E2.m1.4.4.1.1.3.1.2.3.2">𝑖</ci><cn id="Ch4.E2.m1.4.4.1.1.3.1.2.3.3.cmml" type="integer" xref="Ch4.E2.m1.4.4.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="Ch4.E2.m1.4.4.1.1.3.1.3.cmml" xref="Ch4.E2.m1.4.4.1.1.3.1.3">𝑑</ci></apply><apply id="Ch4.E2.m1.4.4.1.1.3.2.cmml" xref="Ch4.E2.m1.4.4.1.1.3.2"><csymbol cd="ambiguous" id="Ch4.E2.m1.4.4.1.1.3.2.1.cmml" xref="Ch4.E2.m1.4.4.1.1.3.2">superscript</csymbol><apply id="Ch4.E2.m1.4.4.1.1.3.2.2.cmml" xref="Ch4.E2.m1.4.4.1.1.3.2"><csymbol cd="ambiguous" id="Ch4.E2.m1.4.4.1.1.3.2.2.1.cmml" xref="Ch4.E2.m1.4.4.1.1.3.2">subscript</csymbol><ci id="Ch4.E2.m1.4.4.1.1.3.2.2.2.cmml" xref="Ch4.E2.m1.4.4.1.1.3.2.2.2">𝑥</ci><ci id="Ch4.E2.m1.4.4.1.1.3.2.2.3.cmml" xref="Ch4.E2.m1.4.4.1.1.3.2.2.3">𝑖</ci></apply><apply id="Ch4.E2.m1.4.4.1.1.3.2.3.cmml" xref="Ch4.E2.m1.4.4.1.1.3.2.3"><csymbol cd="ambiguous" id="Ch4.E2.m1.4.4.1.1.3.2.3.1.cmml" xref="Ch4.E2.m1.4.4.1.1.3.2.3">subscript</csymbol><ci id="Ch4.E2.m1.4.4.1.1.3.2.3.2.cmml" xref="Ch4.E2.m1.4.4.1.1.3.2.3.2">𝑐</ci><apply id="Ch4.E2.m1.4.4.1.1.3.2.3.3.cmml" xref="Ch4.E2.m1.4.4.1.1.3.2.3.3"><times id="Ch4.E2.m1.4.4.1.1.3.2.3.3.1.cmml" xref="Ch4.E2.m1.4.4.1.1.3.2.3.3.1"></times><ci id="Ch4.E2.m1.4.4.1.1.3.2.3.3.2.cmml" xref="Ch4.E2.m1.4.4.1.1.3.2.3.3.2">𝑘</ci><ci id="Ch4.E2.m1.4.4.1.1.3.2.3.3.3.cmml" xref="Ch4.E2.m1.4.4.1.1.3.2.3.3.3">𝑖</ci></apply></apply></apply></apply></apply><apply id="Ch4.E2.m1.5.5.2.2.cmml" xref="Ch4.E2.m1.5.5.2.2"><in id="Ch4.E2.m1.5.5.2.2.1.cmml" xref="Ch4.E2.m1.5.5.2.2.1"></in><apply id="Ch4.E2.m1.5.5.2.2.2.cmml" xref="Ch4.E2.m1.5.5.2.2.2"><csymbol cd="ambiguous" id="Ch4.E2.m1.5.5.2.2.2.1.cmml" xref="Ch4.E2.m1.5.5.2.2.2">subscript</csymbol><ci id="Ch4.E2.m1.5.5.2.2.2.2.cmml" xref="Ch4.E2.m1.5.5.2.2.2.2">𝑐</ci><apply id="Ch4.E2.m1.5.5.2.2.2.3.cmml" xref="Ch4.E2.m1.5.5.2.2.2.3"><times id="Ch4.E2.m1.5.5.2.2.2.3.1.cmml" xref="Ch4.E2.m1.5.5.2.2.2.3.1"></times><ci id="Ch4.E2.m1.5.5.2.2.2.3.2.cmml" xref="Ch4.E2.m1.5.5.2.2.2.3.2">𝑘</ci><ci id="Ch4.E2.m1.5.5.2.2.2.3.3.cmml" xref="Ch4.E2.m1.5.5.2.2.2.3.3">𝑖</ci></apply></apply><set id="Ch4.E2.m1.5.5.2.2.3.1.cmml" xref="Ch4.E2.m1.5.5.2.2.3.2"><cn id="Ch4.E2.m1.2.2.cmml" type="integer" xref="Ch4.E2.m1.2.2">0</cn><cn id="Ch4.E2.m1.3.3.cmml" type="integer" xref="Ch4.E2.m1.3.3">1</cn></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.E2.m1.5c">\displaystyle\phi_{k}(x)=\prod_{i=1}^{d}x_{i}^{c_{ki}},\quad c_{ki}\in\{0,1\}</annotation><annotation encoding="application/x-llamapun" id="Ch4.E2.m1.5d">italic_ϕ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ( italic_x ) = ∏ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_d end_POSTSUPERSCRIPT italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_c start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT end_POSTSUPERSCRIPT , italic_c start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT ∈ { 0 , 1 }</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4.2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch4.S1.SS1.p5.4">where <math alttext="c_{ki}" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p5.1.m1.1"><semantics id="Ch4.S1.SS1.p5.1.m1.1a"><msub id="Ch4.S1.SS1.p5.1.m1.1.1" xref="Ch4.S1.SS1.p5.1.m1.1.1.cmml"><mi id="Ch4.S1.SS1.p5.1.m1.1.1.2" xref="Ch4.S1.SS1.p5.1.m1.1.1.2.cmml">c</mi><mrow id="Ch4.S1.SS1.p5.1.m1.1.1.3" xref="Ch4.S1.SS1.p5.1.m1.1.1.3.cmml"><mi id="Ch4.S1.SS1.p5.1.m1.1.1.3.2" xref="Ch4.S1.SS1.p5.1.m1.1.1.3.2.cmml">k</mi><mo id="Ch4.S1.SS1.p5.1.m1.1.1.3.1" xref="Ch4.S1.SS1.p5.1.m1.1.1.3.1.cmml">⁢</mo><mi id="Ch4.S1.SS1.p5.1.m1.1.1.3.3" xref="Ch4.S1.SS1.p5.1.m1.1.1.3.3.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p5.1.m1.1b"><apply id="Ch4.S1.SS1.p5.1.m1.1.1.cmml" xref="Ch4.S1.SS1.p5.1.m1.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p5.1.m1.1.1.1.cmml" xref="Ch4.S1.SS1.p5.1.m1.1.1">subscript</csymbol><ci id="Ch4.S1.SS1.p5.1.m1.1.1.2.cmml" xref="Ch4.S1.SS1.p5.1.m1.1.1.2">𝑐</ci><apply id="Ch4.S1.SS1.p5.1.m1.1.1.3.cmml" xref="Ch4.S1.SS1.p5.1.m1.1.1.3"><times id="Ch4.S1.SS1.p5.1.m1.1.1.3.1.cmml" xref="Ch4.S1.SS1.p5.1.m1.1.1.3.1"></times><ci id="Ch4.S1.SS1.p5.1.m1.1.1.3.2.cmml" xref="Ch4.S1.SS1.p5.1.m1.1.1.3.2">𝑘</ci><ci id="Ch4.S1.SS1.p5.1.m1.1.1.3.3.cmml" xref="Ch4.S1.SS1.p5.1.m1.1.1.3.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p5.1.m1.1c">c_{ki}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p5.1.m1.1d">italic_c start_POSTSUBSCRIPT italic_k italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is a Boolean variable that is 1 if the <math alttext="i" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p5.2.m2.1"><semantics id="Ch4.S1.SS1.p5.2.m2.1a"><mi id="Ch4.S1.SS1.p5.2.m2.1.1" xref="Ch4.S1.SS1.p5.2.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p5.2.m2.1b"><ci id="Ch4.S1.SS1.p5.2.m2.1.1.cmml" xref="Ch4.S1.SS1.p5.2.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p5.2.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p5.2.m2.1d">italic_i</annotation></semantics></math>-th feature is part of the <math alttext="k" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p5.3.m3.1"><semantics id="Ch4.S1.SS1.p5.3.m3.1a"><mi id="Ch4.S1.SS1.p5.3.m3.1.1" xref="Ch4.S1.SS1.p5.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p5.3.m3.1b"><ci id="Ch4.S1.SS1.p5.3.m3.1.1.cmml" xref="Ch4.S1.SS1.p5.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p5.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p5.3.m3.1d">italic_k</annotation></semantics></math>-th transformation <math alttext="\phi_{k}" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p5.4.m4.1"><semantics id="Ch4.S1.SS1.p5.4.m4.1a"><msub id="Ch4.S1.SS1.p5.4.m4.1.1" xref="Ch4.S1.SS1.p5.4.m4.1.1.cmml"><mi id="Ch4.S1.SS1.p5.4.m4.1.1.2" xref="Ch4.S1.SS1.p5.4.m4.1.1.2.cmml">ϕ</mi><mi id="Ch4.S1.SS1.p5.4.m4.1.1.3" xref="Ch4.S1.SS1.p5.4.m4.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p5.4.m4.1b"><apply id="Ch4.S1.SS1.p5.4.m4.1.1.cmml" xref="Ch4.S1.SS1.p5.4.m4.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p5.4.m4.1.1.1.cmml" xref="Ch4.S1.SS1.p5.4.m4.1.1">subscript</csymbol><ci id="Ch4.S1.SS1.p5.4.m4.1.1.2.cmml" xref="Ch4.S1.SS1.p5.4.m4.1.1.2">italic-ϕ</ci><ci id="Ch4.S1.SS1.p5.4.m4.1.1.3.cmml" xref="Ch4.S1.SS1.p5.4.m4.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p5.4.m4.1c">\phi_{k}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p5.4.m4.1d">italic_ϕ start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math>, and 0 otherwise. Such a transformation allows the model to capture the interactions between the binary features, and adds nonlinearity to the wide component.
The overall model architecture of Wide &amp; Deep is shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.F1" title="Figure 4.1 ‣ 4.1.1 Click behavior modeling ‣ 4.1 User behavior modeling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4.1</span></a>.
Wide &amp; Deep has been verified as effective in e-commerce recommendation scenarios; more details are provided in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S3.SS3" title="6.3.3 Neural network models ‣ 6.3 Candidate ranking models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6.3.3</span></a>.</p>
</div>
<figure class="ltx_figure" id="Ch4.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="202" id="Ch4.F1.g1" src="extracted/5921744/figs/ch53_wide_and_deep.png" width="538"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4.1: </span>Wide &amp; Deep model architecture. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">cheng2016wide</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch4.S1.SS1.p6">
<p class="ltx_p" id="Ch4.S1.SS1.p6.1">The Wide&amp; Deep model is a representative of dual tower models for user behavior modeling. Similarly, DeepFM <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2017deepfm</span>]</cite>, DCN <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2017deep</span>]</cite>, xDeepFM <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lian2018xdeepfm</span>]</cite> and Autoint <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">song2020towards</span>]</cite> are also proposed for CTR prediction.
The deep neural network part in these dual tower models can always be regarded as a supplementary to
learn the residual signal of the feature interaction layer to approach the label, which yields stable training and the improved
performance.
In contrast, Single-tower models like NFM <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">he2017neural</span>]</cite> and Product-based Neural Network <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Qu2018Product</span>]</cite> have enhanced modeling capacity due to their more sophisticated network structures, which allow them to capture complex feature interactions. However, they often struggle with issues such as getting stuck in poor local minima and exhibit a heavy reliance on careful parameter initialization. This sensitivity to initialization can affect their training stability and convergence, making optimization more challenging compared to simpler models.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch4.S1.SS1.p7">
<p class="ltx_p" id="Ch4.S1.SS1.p7.1"><span class="ltx_text ltx_font_bold" id="Ch4.S1.SS1.p7.1.1">Attention models for CTR.</span>
Attention neural networks have been proposed to enhance the performance of CTR prediction. The Deep Interest Network (DIN) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2018deep</span>]</cite> was the first model to introduce the attention network mechanism for user behavior modeling with CTR prediction. It assigns different weights to past behaviors based on their relevance to the target item. To capture dynamic interest evolution, the Deep Interest Evolution Network (DIEN) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2019deep</span>]</cite> was proposed, utilizing a two-layer GRU with an attentional update gate to model evolving user interests. Further advancements, like the Behavior Sequence Transformer and Deep Session Interest Network <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">feng2019deep</span>]</cite>, leverage self-attention to model behavior dependencies and session-based representations, showing the importance of attention mechanisms in CTR prediction <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">xiao2020deep</span>]</cite>.
Recent advances on user click model with attention models have focused on leveraging deep neural networks to capture complex interactions given user profiles, item attributes, and contextual features <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">hou2023deep</span>]</cite>. These models have shown great potential in improving the accuracy and scalability.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch4.S1.SS1.p8">
<p class="ltx_p" id="Ch4.S1.SS1.p8.1"><span class="ltx_text ltx_font_bold" id="Ch4.S1.SS1.p8.1.1">Memory-based models.</span>
With the accumulation of vast user behavior data on large e-commerce platforms, effectively handling long behavior sequences is increasingly important. However, many models such as DIN <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2018deep</span>]</cite> still struggle with time complexity when processing such sequences. To address this, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ren2019lifelong</span></cite> proposed the Hierarchical Periodic Memory Network, which uses a lifelong memory mechanism with multi-layer GRUs updating at different frequencies, capturing long-term and multi-scale temporal patterns. Similarly, the User Interest Center and Multi-channel User Interest Memory Network were designed to handle long-term user interest modeling, providing a more systematic, industrial-level approach <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">pi2019practice</span>]</cite>.
Recently, multi-interest networks have been studied to improve the robustness and consistency in user click modeling <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">cen2020controllable</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chang2023twin</span>]</cite>.
To mitigate noisy correlations and user intent vanishing during this procedure, attribute transition graphs and matching among various patterns need to be constructed. To get this, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2023enhancing</span></cite> characterized user intents with attribute patterns, where the frequent and compact attribute patterns are served as memory to augment session representations.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch4.S1.SS1.p9">
<p class="ltx_p" id="Ch4.S1.SS1.p9.1"><span class="ltx_text ltx_font_bold" id="Ch4.S1.SS1.p9.1.1">Hybrid models combining multiple factors.</span>
To address the complexity of feature interactions, various hybrid models have been proposed. For example, the gradient boosting decision tree model <cite class="ltx_cite ltx_citemacro_citep">[GBDT; <span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2016xgboost</span>]</cite> has been applied successfully to predict user clicks <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">he2014practical</span>]</cite>.
Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.F2" title="Figure 4.2 ‣ 4.1.1 Click behavior modeling ‣ 4.1 User behavior modeling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4.2</span></a> illustrates the structure of a hybrid model with GBDT and logistic regression. The model concatenates the boosted decision trees, which transforms features and the sparse logistic regression classifier.</p>
</div>
<div class="ltx_para" id="Ch4.S1.SS1.p10">
<p class="ltx_p" id="Ch4.S1.SS1.p10.8">The input is a structured embedding <math alttext="x=(e_{i_{1}},e_{i_{2}},\ldots,e_{i_{n}})" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p10.1.m1.4"><semantics id="Ch4.S1.SS1.p10.1.m1.4a"><mrow id="Ch4.S1.SS1.p10.1.m1.4.4" xref="Ch4.S1.SS1.p10.1.m1.4.4.cmml"><mi id="Ch4.S1.SS1.p10.1.m1.4.4.5" xref="Ch4.S1.SS1.p10.1.m1.4.4.5.cmml">x</mi><mo id="Ch4.S1.SS1.p10.1.m1.4.4.4" xref="Ch4.S1.SS1.p10.1.m1.4.4.4.cmml">=</mo><mrow id="Ch4.S1.SS1.p10.1.m1.4.4.3.3" xref="Ch4.S1.SS1.p10.1.m1.4.4.3.4.cmml"><mo id="Ch4.S1.SS1.p10.1.m1.4.4.3.3.4" stretchy="false" xref="Ch4.S1.SS1.p10.1.m1.4.4.3.4.cmml">(</mo><msub id="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1" xref="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1.cmml"><mi id="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1.2" xref="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1.2.cmml">e</mi><msub id="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1.3" xref="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1.3.cmml"><mi id="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1.3.2" xref="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1.3.2.cmml">i</mi><mn id="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1.3.3" xref="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1.3.3.cmml">1</mn></msub></msub><mo id="Ch4.S1.SS1.p10.1.m1.4.4.3.3.5" xref="Ch4.S1.SS1.p10.1.m1.4.4.3.4.cmml">,</mo><msub id="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2" xref="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2.cmml"><mi id="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2.2" xref="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2.2.cmml">e</mi><msub id="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2.3" xref="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2.3.cmml"><mi id="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2.3.2" xref="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2.3.2.cmml">i</mi><mn id="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2.3.3" xref="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2.3.3.cmml">2</mn></msub></msub><mo id="Ch4.S1.SS1.p10.1.m1.4.4.3.3.6" xref="Ch4.S1.SS1.p10.1.m1.4.4.3.4.cmml">,</mo><mi id="Ch4.S1.SS1.p10.1.m1.1.1" mathvariant="normal" xref="Ch4.S1.SS1.p10.1.m1.1.1.cmml">…</mi><mo id="Ch4.S1.SS1.p10.1.m1.4.4.3.3.7" xref="Ch4.S1.SS1.p10.1.m1.4.4.3.4.cmml">,</mo><msub id="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3" xref="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3.cmml"><mi id="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3.2" xref="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3.2.cmml">e</mi><msub id="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3.3" xref="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3.3.cmml"><mi id="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3.3.2" xref="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3.3.2.cmml">i</mi><mi id="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3.3.3" xref="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3.3.3.cmml">n</mi></msub></msub><mo id="Ch4.S1.SS1.p10.1.m1.4.4.3.3.8" stretchy="false" xref="Ch4.S1.SS1.p10.1.m1.4.4.3.4.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p10.1.m1.4b"><apply id="Ch4.S1.SS1.p10.1.m1.4.4.cmml" xref="Ch4.S1.SS1.p10.1.m1.4.4"><eq id="Ch4.S1.SS1.p10.1.m1.4.4.4.cmml" xref="Ch4.S1.SS1.p10.1.m1.4.4.4"></eq><ci id="Ch4.S1.SS1.p10.1.m1.4.4.5.cmml" xref="Ch4.S1.SS1.p10.1.m1.4.4.5">𝑥</ci><vector id="Ch4.S1.SS1.p10.1.m1.4.4.3.4.cmml" xref="Ch4.S1.SS1.p10.1.m1.4.4.3.3"><apply id="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1.cmml" xref="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1.1.cmml" xref="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1">subscript</csymbol><ci id="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1.2.cmml" xref="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1.2">𝑒</ci><apply id="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1.3.cmml" xref="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1.3"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1.3.1.cmml" xref="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1.3">subscript</csymbol><ci id="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1.3.2.cmml" xref="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1.3.2">𝑖</ci><cn id="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1.3.3.cmml" type="integer" xref="Ch4.S1.SS1.p10.1.m1.2.2.1.1.1.3.3">1</cn></apply></apply><apply id="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2.cmml" xref="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2.1.cmml" xref="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2">subscript</csymbol><ci id="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2.2.cmml" xref="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2.2">𝑒</ci><apply id="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2.3.cmml" xref="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2.3"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2.3.1.cmml" xref="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2.3">subscript</csymbol><ci id="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2.3.2.cmml" xref="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2.3.2">𝑖</ci><cn id="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2.3.3.cmml" type="integer" xref="Ch4.S1.SS1.p10.1.m1.3.3.2.2.2.3.3">2</cn></apply></apply><ci id="Ch4.S1.SS1.p10.1.m1.1.1.cmml" xref="Ch4.S1.SS1.p10.1.m1.1.1">…</ci><apply id="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3.cmml" xref="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3.1.cmml" xref="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3">subscript</csymbol><ci id="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3.2.cmml" xref="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3.2">𝑒</ci><apply id="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3.3.cmml" xref="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3.3"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3.3.1.cmml" xref="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3.3">subscript</csymbol><ci id="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3.3.2.cmml" xref="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3.3.2">𝑖</ci><ci id="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3.3.3.cmml" xref="Ch4.S1.SS1.p10.1.m1.4.4.3.3.3.3.3">𝑛</ci></apply></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p10.1.m1.4c">x=(e_{i_{1}},e_{i_{2}},\ldots,e_{i_{n}})</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p10.1.m1.4d">italic_x = ( italic_e start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_e start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , … , italic_e start_POSTSUBSCRIPT italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT end_POSTSUBSCRIPT )</annotation></semantics></math> for each item <math alttext="x" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p10.2.m2.1"><semantics id="Ch4.S1.SS1.p10.2.m2.1a"><mi id="Ch4.S1.SS1.p10.2.m2.1.1" xref="Ch4.S1.SS1.p10.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p10.2.m2.1b"><ci id="Ch4.S1.SS1.p10.2.m2.1.1.cmml" xref="Ch4.S1.SS1.p10.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p10.2.m2.1c">x</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p10.2.m2.1d">italic_x</annotation></semantics></math>, where <math alttext="e_{i}" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p10.3.m3.1"><semantics id="Ch4.S1.SS1.p10.3.m3.1a"><msub id="Ch4.S1.SS1.p10.3.m3.1.1" xref="Ch4.S1.SS1.p10.3.m3.1.1.cmml"><mi id="Ch4.S1.SS1.p10.3.m3.1.1.2" xref="Ch4.S1.SS1.p10.3.m3.1.1.2.cmml">e</mi><mi id="Ch4.S1.SS1.p10.3.m3.1.1.3" xref="Ch4.S1.SS1.p10.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p10.3.m3.1b"><apply id="Ch4.S1.SS1.p10.3.m3.1.1.cmml" xref="Ch4.S1.SS1.p10.3.m3.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p10.3.m3.1.1.1.cmml" xref="Ch4.S1.SS1.p10.3.m3.1.1">subscript</csymbol><ci id="Ch4.S1.SS1.p10.3.m3.1.1.2.cmml" xref="Ch4.S1.SS1.p10.3.m3.1.1.2">𝑒</ci><ci id="Ch4.S1.SS1.p10.3.m3.1.1.3.cmml" xref="Ch4.S1.SS1.p10.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p10.3.m3.1c">e_{i}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p10.3.m3.1d">italic_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> refers to the <math alttext="i" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p10.4.m4.1"><semantics id="Ch4.S1.SS1.p10.4.m4.1a"><mi id="Ch4.S1.SS1.p10.4.m4.1.1" xref="Ch4.S1.SS1.p10.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p10.4.m4.1b"><ci id="Ch4.S1.SS1.p10.4.m4.1.1.cmml" xref="Ch4.S1.SS1.p10.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p10.4.m4.1c">i</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p10.4.m4.1d">italic_i</annotation></semantics></math>-th unit vector, and <math alttext="i_{n}" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p10.5.m5.1"><semantics id="Ch4.S1.SS1.p10.5.m5.1a"><msub id="Ch4.S1.SS1.p10.5.m5.1.1" xref="Ch4.S1.SS1.p10.5.m5.1.1.cmml"><mi id="Ch4.S1.SS1.p10.5.m5.1.1.2" xref="Ch4.S1.SS1.p10.5.m5.1.1.2.cmml">i</mi><mi id="Ch4.S1.SS1.p10.5.m5.1.1.3" xref="Ch4.S1.SS1.p10.5.m5.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p10.5.m5.1b"><apply id="Ch4.S1.SS1.p10.5.m5.1.1.cmml" xref="Ch4.S1.SS1.p10.5.m5.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p10.5.m5.1.1.1.cmml" xref="Ch4.S1.SS1.p10.5.m5.1.1">subscript</csymbol><ci id="Ch4.S1.SS1.p10.5.m5.1.1.2.cmml" xref="Ch4.S1.SS1.p10.5.m5.1.1.2">𝑖</ci><ci id="Ch4.S1.SS1.p10.5.m5.1.1.3.cmml" xref="Ch4.S1.SS1.p10.5.m5.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p10.5.m5.1c">i_{n}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p10.5.m5.1d">italic_i start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT</annotation></semantics></math> is the index of the categorical features. The output of the model is a binary label <math alttext="y\in\{+1,-1\}" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p10.6.m6.2"><semantics id="Ch4.S1.SS1.p10.6.m6.2a"><mrow id="Ch4.S1.SS1.p10.6.m6.2.2" xref="Ch4.S1.SS1.p10.6.m6.2.2.cmml"><mi id="Ch4.S1.SS1.p10.6.m6.2.2.4" xref="Ch4.S1.SS1.p10.6.m6.2.2.4.cmml">y</mi><mo id="Ch4.S1.SS1.p10.6.m6.2.2.3" xref="Ch4.S1.SS1.p10.6.m6.2.2.3.cmml">∈</mo><mrow id="Ch4.S1.SS1.p10.6.m6.2.2.2.2" xref="Ch4.S1.SS1.p10.6.m6.2.2.2.3.cmml"><mo id="Ch4.S1.SS1.p10.6.m6.2.2.2.2.3" stretchy="false" xref="Ch4.S1.SS1.p10.6.m6.2.2.2.3.cmml">{</mo><mrow id="Ch4.S1.SS1.p10.6.m6.1.1.1.1.1" xref="Ch4.S1.SS1.p10.6.m6.1.1.1.1.1.cmml"><mo id="Ch4.S1.SS1.p10.6.m6.1.1.1.1.1a" xref="Ch4.S1.SS1.p10.6.m6.1.1.1.1.1.cmml">+</mo><mn id="Ch4.S1.SS1.p10.6.m6.1.1.1.1.1.2" xref="Ch4.S1.SS1.p10.6.m6.1.1.1.1.1.2.cmml">1</mn></mrow><mo id="Ch4.S1.SS1.p10.6.m6.2.2.2.2.4" xref="Ch4.S1.SS1.p10.6.m6.2.2.2.3.cmml">,</mo><mrow id="Ch4.S1.SS1.p10.6.m6.2.2.2.2.2" xref="Ch4.S1.SS1.p10.6.m6.2.2.2.2.2.cmml"><mo id="Ch4.S1.SS1.p10.6.m6.2.2.2.2.2a" xref="Ch4.S1.SS1.p10.6.m6.2.2.2.2.2.cmml">−</mo><mn id="Ch4.S1.SS1.p10.6.m6.2.2.2.2.2.2" xref="Ch4.S1.SS1.p10.6.m6.2.2.2.2.2.2.cmml">1</mn></mrow><mo id="Ch4.S1.SS1.p10.6.m6.2.2.2.2.5" stretchy="false" xref="Ch4.S1.SS1.p10.6.m6.2.2.2.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p10.6.m6.2b"><apply id="Ch4.S1.SS1.p10.6.m6.2.2.cmml" xref="Ch4.S1.SS1.p10.6.m6.2.2"><in id="Ch4.S1.SS1.p10.6.m6.2.2.3.cmml" xref="Ch4.S1.SS1.p10.6.m6.2.2.3"></in><ci id="Ch4.S1.SS1.p10.6.m6.2.2.4.cmml" xref="Ch4.S1.SS1.p10.6.m6.2.2.4">𝑦</ci><set id="Ch4.S1.SS1.p10.6.m6.2.2.2.3.cmml" xref="Ch4.S1.SS1.p10.6.m6.2.2.2.2"><apply id="Ch4.S1.SS1.p10.6.m6.1.1.1.1.1.cmml" xref="Ch4.S1.SS1.p10.6.m6.1.1.1.1.1"><plus id="Ch4.S1.SS1.p10.6.m6.1.1.1.1.1.1.cmml" xref="Ch4.S1.SS1.p10.6.m6.1.1.1.1.1"></plus><cn id="Ch4.S1.SS1.p10.6.m6.1.1.1.1.1.2.cmml" type="integer" xref="Ch4.S1.SS1.p10.6.m6.1.1.1.1.1.2">1</cn></apply><apply id="Ch4.S1.SS1.p10.6.m6.2.2.2.2.2.cmml" xref="Ch4.S1.SS1.p10.6.m6.2.2.2.2.2"><minus id="Ch4.S1.SS1.p10.6.m6.2.2.2.2.2.1.cmml" xref="Ch4.S1.SS1.p10.6.m6.2.2.2.2.2"></minus><cn id="Ch4.S1.SS1.p10.6.m6.2.2.2.2.2.2.cmml" type="integer" xref="Ch4.S1.SS1.p10.6.m6.2.2.2.2.2.2">1</cn></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p10.6.m6.2c">y\in\{+1,-1\}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p10.6.m6.2d">italic_y ∈ { + 1 , - 1 }</annotation></semantics></math>, which indicates a click or no click. Given a labeled pair <math alttext="(x,y)" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p10.7.m7.2"><semantics id="Ch4.S1.SS1.p10.7.m7.2a"><mrow id="Ch4.S1.SS1.p10.7.m7.2.3.2" xref="Ch4.S1.SS1.p10.7.m7.2.3.1.cmml"><mo id="Ch4.S1.SS1.p10.7.m7.2.3.2.1" stretchy="false" xref="Ch4.S1.SS1.p10.7.m7.2.3.1.cmml">(</mo><mi id="Ch4.S1.SS1.p10.7.m7.1.1" xref="Ch4.S1.SS1.p10.7.m7.1.1.cmml">x</mi><mo id="Ch4.S1.SS1.p10.7.m7.2.3.2.2" xref="Ch4.S1.SS1.p10.7.m7.2.3.1.cmml">,</mo><mi id="Ch4.S1.SS1.p10.7.m7.2.2" xref="Ch4.S1.SS1.p10.7.m7.2.2.cmml">y</mi><mo id="Ch4.S1.SS1.p10.7.m7.2.3.2.3" stretchy="false" xref="Ch4.S1.SS1.p10.7.m7.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p10.7.m7.2b"><interval closure="open" id="Ch4.S1.SS1.p10.7.m7.2.3.1.cmml" xref="Ch4.S1.SS1.p10.7.m7.2.3.2"><ci id="Ch4.S1.SS1.p10.7.m7.1.1.cmml" xref="Ch4.S1.SS1.p10.7.m7.1.1">𝑥</ci><ci id="Ch4.S1.SS1.p10.7.m7.2.2.cmml" xref="Ch4.S1.SS1.p10.7.m7.2.2">𝑦</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p10.7.m7.2c">(x,y)</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p10.7.m7.2d">( italic_x , italic_y )</annotation></semantics></math>, the authors have denoted the linear combination of active weights as <math alttext="s(y,x,w)" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p10.8.m8.3"><semantics id="Ch4.S1.SS1.p10.8.m8.3a"><mrow id="Ch4.S1.SS1.p10.8.m8.3.4" xref="Ch4.S1.SS1.p10.8.m8.3.4.cmml"><mi id="Ch4.S1.SS1.p10.8.m8.3.4.2" xref="Ch4.S1.SS1.p10.8.m8.3.4.2.cmml">s</mi><mo id="Ch4.S1.SS1.p10.8.m8.3.4.1" xref="Ch4.S1.SS1.p10.8.m8.3.4.1.cmml">⁢</mo><mrow id="Ch4.S1.SS1.p10.8.m8.3.4.3.2" xref="Ch4.S1.SS1.p10.8.m8.3.4.3.1.cmml"><mo id="Ch4.S1.SS1.p10.8.m8.3.4.3.2.1" stretchy="false" xref="Ch4.S1.SS1.p10.8.m8.3.4.3.1.cmml">(</mo><mi id="Ch4.S1.SS1.p10.8.m8.1.1" xref="Ch4.S1.SS1.p10.8.m8.1.1.cmml">y</mi><mo id="Ch4.S1.SS1.p10.8.m8.3.4.3.2.2" xref="Ch4.S1.SS1.p10.8.m8.3.4.3.1.cmml">,</mo><mi id="Ch4.S1.SS1.p10.8.m8.2.2" xref="Ch4.S1.SS1.p10.8.m8.2.2.cmml">x</mi><mo id="Ch4.S1.SS1.p10.8.m8.3.4.3.2.3" xref="Ch4.S1.SS1.p10.8.m8.3.4.3.1.cmml">,</mo><mi id="Ch4.S1.SS1.p10.8.m8.3.3" xref="Ch4.S1.SS1.p10.8.m8.3.3.cmml">w</mi><mo id="Ch4.S1.SS1.p10.8.m8.3.4.3.2.4" stretchy="false" xref="Ch4.S1.SS1.p10.8.m8.3.4.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p10.8.m8.3b"><apply id="Ch4.S1.SS1.p10.8.m8.3.4.cmml" xref="Ch4.S1.SS1.p10.8.m8.3.4"><times id="Ch4.S1.SS1.p10.8.m8.3.4.1.cmml" xref="Ch4.S1.SS1.p10.8.m8.3.4.1"></times><ci id="Ch4.S1.SS1.p10.8.m8.3.4.2.cmml" xref="Ch4.S1.SS1.p10.8.m8.3.4.2">𝑠</ci><vector id="Ch4.S1.SS1.p10.8.m8.3.4.3.1.cmml" xref="Ch4.S1.SS1.p10.8.m8.3.4.3.2"><ci id="Ch4.S1.SS1.p10.8.m8.1.1.cmml" xref="Ch4.S1.SS1.p10.8.m8.1.1">𝑦</ci><ci id="Ch4.S1.SS1.p10.8.m8.2.2.cmml" xref="Ch4.S1.SS1.p10.8.m8.2.2">𝑥</ci><ci id="Ch4.S1.SS1.p10.8.m8.3.3.cmml" xref="Ch4.S1.SS1.p10.8.m8.3.3">𝑤</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p10.8.m8.3c">s(y,x,w)</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p10.8.m8.3d">italic_s ( italic_y , italic_x , italic_w )</annotation></semantics></math>, which can be calculated as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="Ch4.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="s(y,x,w)=y\cdot w^{T}\cdot x=y\sum\limits_{j=1}^{n}{w_{j,i_{j}}}," class="ltx_Math" display="block" id="Ch4.E3.m1.6"><semantics id="Ch4.E3.m1.6a"><mrow id="Ch4.E3.m1.6.6.1" xref="Ch4.E3.m1.6.6.1.1.cmml"><mrow id="Ch4.E3.m1.6.6.1.1" xref="Ch4.E3.m1.6.6.1.1.cmml"><mrow id="Ch4.E3.m1.6.6.1.1.2" xref="Ch4.E3.m1.6.6.1.1.2.cmml"><mi id="Ch4.E3.m1.6.6.1.1.2.2" xref="Ch4.E3.m1.6.6.1.1.2.2.cmml">s</mi><mo id="Ch4.E3.m1.6.6.1.1.2.1" xref="Ch4.E3.m1.6.6.1.1.2.1.cmml">⁢</mo><mrow id="Ch4.E3.m1.6.6.1.1.2.3.2" xref="Ch4.E3.m1.6.6.1.1.2.3.1.cmml"><mo id="Ch4.E3.m1.6.6.1.1.2.3.2.1" stretchy="false" xref="Ch4.E3.m1.6.6.1.1.2.3.1.cmml">(</mo><mi id="Ch4.E3.m1.3.3" xref="Ch4.E3.m1.3.3.cmml">y</mi><mo id="Ch4.E3.m1.6.6.1.1.2.3.2.2" xref="Ch4.E3.m1.6.6.1.1.2.3.1.cmml">,</mo><mi id="Ch4.E3.m1.4.4" xref="Ch4.E3.m1.4.4.cmml">x</mi><mo id="Ch4.E3.m1.6.6.1.1.2.3.2.3" xref="Ch4.E3.m1.6.6.1.1.2.3.1.cmml">,</mo><mi id="Ch4.E3.m1.5.5" xref="Ch4.E3.m1.5.5.cmml">w</mi><mo id="Ch4.E3.m1.6.6.1.1.2.3.2.4" stretchy="false" xref="Ch4.E3.m1.6.6.1.1.2.3.1.cmml">)</mo></mrow></mrow><mo id="Ch4.E3.m1.6.6.1.1.3" xref="Ch4.E3.m1.6.6.1.1.3.cmml">=</mo><mrow id="Ch4.E3.m1.6.6.1.1.4" xref="Ch4.E3.m1.6.6.1.1.4.cmml"><mi id="Ch4.E3.m1.6.6.1.1.4.2" xref="Ch4.E3.m1.6.6.1.1.4.2.cmml">y</mi><mo id="Ch4.E3.m1.6.6.1.1.4.1" lspace="0.222em" rspace="0.222em" xref="Ch4.E3.m1.6.6.1.1.4.1.cmml">⋅</mo><msup id="Ch4.E3.m1.6.6.1.1.4.3" xref="Ch4.E3.m1.6.6.1.1.4.3.cmml"><mi id="Ch4.E3.m1.6.6.1.1.4.3.2" xref="Ch4.E3.m1.6.6.1.1.4.3.2.cmml">w</mi><mi id="Ch4.E3.m1.6.6.1.1.4.3.3" xref="Ch4.E3.m1.6.6.1.1.4.3.3.cmml">T</mi></msup><mo id="Ch4.E3.m1.6.6.1.1.4.1a" lspace="0.222em" rspace="0.222em" xref="Ch4.E3.m1.6.6.1.1.4.1.cmml">⋅</mo><mi id="Ch4.E3.m1.6.6.1.1.4.4" xref="Ch4.E3.m1.6.6.1.1.4.4.cmml">x</mi></mrow><mo id="Ch4.E3.m1.6.6.1.1.5" xref="Ch4.E3.m1.6.6.1.1.5.cmml">=</mo><mrow id="Ch4.E3.m1.6.6.1.1.6" xref="Ch4.E3.m1.6.6.1.1.6.cmml"><mi id="Ch4.E3.m1.6.6.1.1.6.2" xref="Ch4.E3.m1.6.6.1.1.6.2.cmml">y</mi><mo id="Ch4.E3.m1.6.6.1.1.6.1" xref="Ch4.E3.m1.6.6.1.1.6.1.cmml">⁢</mo><mrow id="Ch4.E3.m1.6.6.1.1.6.3" xref="Ch4.E3.m1.6.6.1.1.6.3.cmml"><munderover id="Ch4.E3.m1.6.6.1.1.6.3.1" xref="Ch4.E3.m1.6.6.1.1.6.3.1.cmml"><mo id="Ch4.E3.m1.6.6.1.1.6.3.1.2.2" movablelimits="false" xref="Ch4.E3.m1.6.6.1.1.6.3.1.2.2.cmml">∑</mo><mrow id="Ch4.E3.m1.6.6.1.1.6.3.1.2.3" xref="Ch4.E3.m1.6.6.1.1.6.3.1.2.3.cmml"><mi id="Ch4.E3.m1.6.6.1.1.6.3.1.2.3.2" xref="Ch4.E3.m1.6.6.1.1.6.3.1.2.3.2.cmml">j</mi><mo id="Ch4.E3.m1.6.6.1.1.6.3.1.2.3.1" xref="Ch4.E3.m1.6.6.1.1.6.3.1.2.3.1.cmml">=</mo><mn id="Ch4.E3.m1.6.6.1.1.6.3.1.2.3.3" xref="Ch4.E3.m1.6.6.1.1.6.3.1.2.3.3.cmml">1</mn></mrow><mi id="Ch4.E3.m1.6.6.1.1.6.3.1.3" xref="Ch4.E3.m1.6.6.1.1.6.3.1.3.cmml">n</mi></munderover><msub id="Ch4.E3.m1.6.6.1.1.6.3.2" xref="Ch4.E3.m1.6.6.1.1.6.3.2.cmml"><mi id="Ch4.E3.m1.6.6.1.1.6.3.2.2" xref="Ch4.E3.m1.6.6.1.1.6.3.2.2.cmml">w</mi><mrow id="Ch4.E3.m1.2.2.2.2" xref="Ch4.E3.m1.2.2.2.3.cmml"><mi id="Ch4.E3.m1.1.1.1.1" xref="Ch4.E3.m1.1.1.1.1.cmml">j</mi><mo id="Ch4.E3.m1.2.2.2.2.2" xref="Ch4.E3.m1.2.2.2.3.cmml">,</mo><msub id="Ch4.E3.m1.2.2.2.2.1" xref="Ch4.E3.m1.2.2.2.2.1.cmml"><mi id="Ch4.E3.m1.2.2.2.2.1.2" xref="Ch4.E3.m1.2.2.2.2.1.2.cmml">i</mi><mi id="Ch4.E3.m1.2.2.2.2.1.3" xref="Ch4.E3.m1.2.2.2.2.1.3.cmml">j</mi></msub></mrow></msub></mrow></mrow></mrow><mo id="Ch4.E3.m1.6.6.1.2" xref="Ch4.E3.m1.6.6.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch4.E3.m1.6b"><apply id="Ch4.E3.m1.6.6.1.1.cmml" xref="Ch4.E3.m1.6.6.1"><and id="Ch4.E3.m1.6.6.1.1a.cmml" xref="Ch4.E3.m1.6.6.1"></and><apply id="Ch4.E3.m1.6.6.1.1b.cmml" xref="Ch4.E3.m1.6.6.1"><eq id="Ch4.E3.m1.6.6.1.1.3.cmml" xref="Ch4.E3.m1.6.6.1.1.3"></eq><apply id="Ch4.E3.m1.6.6.1.1.2.cmml" xref="Ch4.E3.m1.6.6.1.1.2"><times id="Ch4.E3.m1.6.6.1.1.2.1.cmml" xref="Ch4.E3.m1.6.6.1.1.2.1"></times><ci id="Ch4.E3.m1.6.6.1.1.2.2.cmml" xref="Ch4.E3.m1.6.6.1.1.2.2">𝑠</ci><vector id="Ch4.E3.m1.6.6.1.1.2.3.1.cmml" xref="Ch4.E3.m1.6.6.1.1.2.3.2"><ci id="Ch4.E3.m1.3.3.cmml" xref="Ch4.E3.m1.3.3">𝑦</ci><ci id="Ch4.E3.m1.4.4.cmml" xref="Ch4.E3.m1.4.4">𝑥</ci><ci id="Ch4.E3.m1.5.5.cmml" xref="Ch4.E3.m1.5.5">𝑤</ci></vector></apply><apply id="Ch4.E3.m1.6.6.1.1.4.cmml" xref="Ch4.E3.m1.6.6.1.1.4"><ci id="Ch4.E3.m1.6.6.1.1.4.1.cmml" xref="Ch4.E3.m1.6.6.1.1.4.1">⋅</ci><ci id="Ch4.E3.m1.6.6.1.1.4.2.cmml" xref="Ch4.E3.m1.6.6.1.1.4.2">𝑦</ci><apply id="Ch4.E3.m1.6.6.1.1.4.3.cmml" xref="Ch4.E3.m1.6.6.1.1.4.3"><csymbol cd="ambiguous" id="Ch4.E3.m1.6.6.1.1.4.3.1.cmml" xref="Ch4.E3.m1.6.6.1.1.4.3">superscript</csymbol><ci id="Ch4.E3.m1.6.6.1.1.4.3.2.cmml" xref="Ch4.E3.m1.6.6.1.1.4.3.2">𝑤</ci><ci id="Ch4.E3.m1.6.6.1.1.4.3.3.cmml" xref="Ch4.E3.m1.6.6.1.1.4.3.3">𝑇</ci></apply><ci id="Ch4.E3.m1.6.6.1.1.4.4.cmml" xref="Ch4.E3.m1.6.6.1.1.4.4">𝑥</ci></apply></apply><apply id="Ch4.E3.m1.6.6.1.1c.cmml" xref="Ch4.E3.m1.6.6.1"><eq id="Ch4.E3.m1.6.6.1.1.5.cmml" xref="Ch4.E3.m1.6.6.1.1.5"></eq><share href="https://arxiv.org/html/2410.05763v2#Ch4.E3.m1.6.6.1.1.4.cmml" id="Ch4.E3.m1.6.6.1.1d.cmml" xref="Ch4.E3.m1.6.6.1"></share><apply id="Ch4.E3.m1.6.6.1.1.6.cmml" xref="Ch4.E3.m1.6.6.1.1.6"><times id="Ch4.E3.m1.6.6.1.1.6.1.cmml" xref="Ch4.E3.m1.6.6.1.1.6.1"></times><ci id="Ch4.E3.m1.6.6.1.1.6.2.cmml" xref="Ch4.E3.m1.6.6.1.1.6.2">𝑦</ci><apply id="Ch4.E3.m1.6.6.1.1.6.3.cmml" xref="Ch4.E3.m1.6.6.1.1.6.3"><apply id="Ch4.E3.m1.6.6.1.1.6.3.1.cmml" xref="Ch4.E3.m1.6.6.1.1.6.3.1"><csymbol cd="ambiguous" id="Ch4.E3.m1.6.6.1.1.6.3.1.1.cmml" xref="Ch4.E3.m1.6.6.1.1.6.3.1">superscript</csymbol><apply id="Ch4.E3.m1.6.6.1.1.6.3.1.2.cmml" xref="Ch4.E3.m1.6.6.1.1.6.3.1"><csymbol cd="ambiguous" id="Ch4.E3.m1.6.6.1.1.6.3.1.2.1.cmml" xref="Ch4.E3.m1.6.6.1.1.6.3.1">subscript</csymbol><sum id="Ch4.E3.m1.6.6.1.1.6.3.1.2.2.cmml" xref="Ch4.E3.m1.6.6.1.1.6.3.1.2.2"></sum><apply id="Ch4.E3.m1.6.6.1.1.6.3.1.2.3.cmml" xref="Ch4.E3.m1.6.6.1.1.6.3.1.2.3"><eq id="Ch4.E3.m1.6.6.1.1.6.3.1.2.3.1.cmml" xref="Ch4.E3.m1.6.6.1.1.6.3.1.2.3.1"></eq><ci id="Ch4.E3.m1.6.6.1.1.6.3.1.2.3.2.cmml" xref="Ch4.E3.m1.6.6.1.1.6.3.1.2.3.2">𝑗</ci><cn id="Ch4.E3.m1.6.6.1.1.6.3.1.2.3.3.cmml" type="integer" xref="Ch4.E3.m1.6.6.1.1.6.3.1.2.3.3">1</cn></apply></apply><ci id="Ch4.E3.m1.6.6.1.1.6.3.1.3.cmml" xref="Ch4.E3.m1.6.6.1.1.6.3.1.3">𝑛</ci></apply><apply id="Ch4.E3.m1.6.6.1.1.6.3.2.cmml" xref="Ch4.E3.m1.6.6.1.1.6.3.2"><csymbol cd="ambiguous" id="Ch4.E3.m1.6.6.1.1.6.3.2.1.cmml" xref="Ch4.E3.m1.6.6.1.1.6.3.2">subscript</csymbol><ci id="Ch4.E3.m1.6.6.1.1.6.3.2.2.cmml" xref="Ch4.E3.m1.6.6.1.1.6.3.2.2">𝑤</ci><list id="Ch4.E3.m1.2.2.2.3.cmml" xref="Ch4.E3.m1.2.2.2.2"><ci id="Ch4.E3.m1.1.1.1.1.cmml" xref="Ch4.E3.m1.1.1.1.1">𝑗</ci><apply id="Ch4.E3.m1.2.2.2.2.1.cmml" xref="Ch4.E3.m1.2.2.2.2.1"><csymbol cd="ambiguous" id="Ch4.E3.m1.2.2.2.2.1.1.cmml" xref="Ch4.E3.m1.2.2.2.2.1">subscript</csymbol><ci id="Ch4.E3.m1.2.2.2.2.1.2.cmml" xref="Ch4.E3.m1.2.2.2.2.1.2">𝑖</ci><ci id="Ch4.E3.m1.2.2.2.2.1.3.cmml" xref="Ch4.E3.m1.2.2.2.2.1.3">𝑗</ci></apply></list></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.E3.m1.6c">s(y,x,w)=y\cdot w^{T}\cdot x=y\sum\limits_{j=1}^{n}{w_{j,i_{j}}},</annotation><annotation encoding="application/x-llamapun" id="Ch4.E3.m1.6d">italic_s ( italic_y , italic_x , italic_w ) = italic_y ⋅ italic_w start_POSTSUPERSCRIPT italic_T end_POSTSUPERSCRIPT ⋅ italic_x = italic_y ∑ start_POSTSUBSCRIPT italic_j = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_w start_POSTSUBSCRIPT italic_j , italic_i start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4.3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch4.S1.SS1.p10.11">where <math alttext="w" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p10.9.m1.1"><semantics id="Ch4.S1.SS1.p10.9.m1.1a"><mi id="Ch4.S1.SS1.p10.9.m1.1.1" xref="Ch4.S1.SS1.p10.9.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p10.9.m1.1b"><ci id="Ch4.S1.SS1.p10.9.m1.1.1.cmml" xref="Ch4.S1.SS1.p10.9.m1.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p10.9.m1.1c">w</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p10.9.m1.1d">italic_w</annotation></semantics></math> is the weight vector of the click score. Using stochastic gradient descent <cite class="ltx_cite ltx_citemacro_citep">[SGD;  <span class="ltx_ref ltx_missing_citation ltx_ref_self">saad1998online</span>]</cite>, the authors inferred the likelihood function <math alttext="p(y{\mid}x,w)" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p10.10.m2.3"><semantics id="Ch4.S1.SS1.p10.10.m2.3a"><mrow id="Ch4.S1.SS1.p10.10.m2.3.3" xref="Ch4.S1.SS1.p10.10.m2.3.3.cmml"><mi id="Ch4.S1.SS1.p10.10.m2.3.3.3" xref="Ch4.S1.SS1.p10.10.m2.3.3.3.cmml">p</mi><mo id="Ch4.S1.SS1.p10.10.m2.3.3.2" xref="Ch4.S1.SS1.p10.10.m2.3.3.2.cmml">⁢</mo><mrow id="Ch4.S1.SS1.p10.10.m2.3.3.1.1" xref="Ch4.S1.SS1.p10.10.m2.3.3.1.1.1.cmml"><mo id="Ch4.S1.SS1.p10.10.m2.3.3.1.1.2" stretchy="false" xref="Ch4.S1.SS1.p10.10.m2.3.3.1.1.1.cmml">(</mo><mrow id="Ch4.S1.SS1.p10.10.m2.3.3.1.1.1" xref="Ch4.S1.SS1.p10.10.m2.3.3.1.1.1.cmml"><mi id="Ch4.S1.SS1.p10.10.m2.3.3.1.1.1.2" xref="Ch4.S1.SS1.p10.10.m2.3.3.1.1.1.2.cmml">y</mi><mo id="Ch4.S1.SS1.p10.10.m2.3.3.1.1.1.1" xref="Ch4.S1.SS1.p10.10.m2.3.3.1.1.1.1.cmml">∣</mo><mrow id="Ch4.S1.SS1.p10.10.m2.3.3.1.1.1.3.2" xref="Ch4.S1.SS1.p10.10.m2.3.3.1.1.1.3.1.cmml"><mi id="Ch4.S1.SS1.p10.10.m2.1.1" xref="Ch4.S1.SS1.p10.10.m2.1.1.cmml">x</mi><mo id="Ch4.S1.SS1.p10.10.m2.3.3.1.1.1.3.2.1" xref="Ch4.S1.SS1.p10.10.m2.3.3.1.1.1.3.1.cmml">,</mo><mi id="Ch4.S1.SS1.p10.10.m2.2.2" xref="Ch4.S1.SS1.p10.10.m2.2.2.cmml">w</mi></mrow></mrow><mo id="Ch4.S1.SS1.p10.10.m2.3.3.1.1.3" stretchy="false" xref="Ch4.S1.SS1.p10.10.m2.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p10.10.m2.3b"><apply id="Ch4.S1.SS1.p10.10.m2.3.3.cmml" xref="Ch4.S1.SS1.p10.10.m2.3.3"><times id="Ch4.S1.SS1.p10.10.m2.3.3.2.cmml" xref="Ch4.S1.SS1.p10.10.m2.3.3.2"></times><ci id="Ch4.S1.SS1.p10.10.m2.3.3.3.cmml" xref="Ch4.S1.SS1.p10.10.m2.3.3.3">𝑝</ci><apply id="Ch4.S1.SS1.p10.10.m2.3.3.1.1.1.cmml" xref="Ch4.S1.SS1.p10.10.m2.3.3.1.1"><csymbol cd="latexml" id="Ch4.S1.SS1.p10.10.m2.3.3.1.1.1.1.cmml" xref="Ch4.S1.SS1.p10.10.m2.3.3.1.1.1.1">conditional</csymbol><ci id="Ch4.S1.SS1.p10.10.m2.3.3.1.1.1.2.cmml" xref="Ch4.S1.SS1.p10.10.m2.3.3.1.1.1.2">𝑦</ci><list id="Ch4.S1.SS1.p10.10.m2.3.3.1.1.1.3.1.cmml" xref="Ch4.S1.SS1.p10.10.m2.3.3.1.1.1.3.2"><ci id="Ch4.S1.SS1.p10.10.m2.1.1.cmml" xref="Ch4.S1.SS1.p10.10.m2.1.1">𝑥</ci><ci id="Ch4.S1.SS1.p10.10.m2.2.2.cmml" xref="Ch4.S1.SS1.p10.10.m2.2.2">𝑤</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p10.10.m2.3c">p(y{\mid}x,w)</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p10.10.m2.3d">italic_p ( italic_y ∣ italic_x , italic_w )</annotation></semantics></math> by applying a sigmoid function over <math alttext="s(y,x,w)" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p10.11.m3.3"><semantics id="Ch4.S1.SS1.p10.11.m3.3a"><mrow id="Ch4.S1.SS1.p10.11.m3.3.4" xref="Ch4.S1.SS1.p10.11.m3.3.4.cmml"><mi id="Ch4.S1.SS1.p10.11.m3.3.4.2" xref="Ch4.S1.SS1.p10.11.m3.3.4.2.cmml">s</mi><mo id="Ch4.S1.SS1.p10.11.m3.3.4.1" xref="Ch4.S1.SS1.p10.11.m3.3.4.1.cmml">⁢</mo><mrow id="Ch4.S1.SS1.p10.11.m3.3.4.3.2" xref="Ch4.S1.SS1.p10.11.m3.3.4.3.1.cmml"><mo id="Ch4.S1.SS1.p10.11.m3.3.4.3.2.1" stretchy="false" xref="Ch4.S1.SS1.p10.11.m3.3.4.3.1.cmml">(</mo><mi id="Ch4.S1.SS1.p10.11.m3.1.1" xref="Ch4.S1.SS1.p10.11.m3.1.1.cmml">y</mi><mo id="Ch4.S1.SS1.p10.11.m3.3.4.3.2.2" xref="Ch4.S1.SS1.p10.11.m3.3.4.3.1.cmml">,</mo><mi id="Ch4.S1.SS1.p10.11.m3.2.2" xref="Ch4.S1.SS1.p10.11.m3.2.2.cmml">x</mi><mo id="Ch4.S1.SS1.p10.11.m3.3.4.3.2.3" xref="Ch4.S1.SS1.p10.11.m3.3.4.3.1.cmml">,</mo><mi id="Ch4.S1.SS1.p10.11.m3.3.3" xref="Ch4.S1.SS1.p10.11.m3.3.3.cmml">w</mi><mo id="Ch4.S1.SS1.p10.11.m3.3.4.3.2.4" stretchy="false" xref="Ch4.S1.SS1.p10.11.m3.3.4.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p10.11.m3.3b"><apply id="Ch4.S1.SS1.p10.11.m3.3.4.cmml" xref="Ch4.S1.SS1.p10.11.m3.3.4"><times id="Ch4.S1.SS1.p10.11.m3.3.4.1.cmml" xref="Ch4.S1.SS1.p10.11.m3.3.4.1"></times><ci id="Ch4.S1.SS1.p10.11.m3.3.4.2.cmml" xref="Ch4.S1.SS1.p10.11.m3.3.4.2">𝑠</ci><vector id="Ch4.S1.SS1.p10.11.m3.3.4.3.1.cmml" xref="Ch4.S1.SS1.p10.11.m3.3.4.3.2"><ci id="Ch4.S1.SS1.p10.11.m3.1.1.cmml" xref="Ch4.S1.SS1.p10.11.m3.1.1">𝑦</ci><ci id="Ch4.S1.SS1.p10.11.m3.2.2.cmml" xref="Ch4.S1.SS1.p10.11.m3.2.2">𝑥</ci><ci id="Ch4.S1.SS1.p10.11.m3.3.3.cmml" xref="Ch4.S1.SS1.p10.11.m3.3.3">𝑤</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p10.11.m3.3c">s(y,x,w)</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p10.11.m3.3d">italic_s ( italic_y , italic_x , italic_w )</annotation></semantics></math>.
Based on these transformed features extracted from gradient boosting decision trees, the authors applied logistic regression as a linear classifier to predict click or no click.
Boosted decision trees are able to aggressively reduce the number of active features with only moderate prediction accuracy degradation. The hybrid click model has been widely applied in e-commerce recommendations for candidate ranking (See Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S3.SS2" title="6.3.2 Polynomial models ‣ 6.3 Candidate ranking models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6.3.2</span></a> for more details.).</p>
</div>
<figure class="ltx_figure" id="Ch4.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="399" id="Ch4.F2.g1" src="x25.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4.2: </span>Overview of the hybrid click prediction model that uses GBDT and logistic regression. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">he2014practical</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch4.S1.SS1.p11">
<p class="ltx_p" id="Ch4.S1.SS1.p11.4">To explore the feature interactions hidden in data collections, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2017deepfm</span></cite> proposed a neural network method, i.e., DeepFM, that combines the architectures of factorization machines and deep neural networks.
As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.F3" title="Figure 4.3 ‣ 4.1.1 Click behavior modeling ‣ 4.1 User behavior modeling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4.3</span></a>, DeepFM utilizes a wide and deep component to share the same raw input feature vector; this allows the model to learn low- and high-order feature interactions simultaneously. The authors divided DeepFM into the following two components: an FM component and a deep component.
These components share the same input features. All parameters are jointly trained for the combined prediction model, as described by Eq. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.E4" title="In 4.1.1 Click behavior modeling ‣ 4.1 User behavior modeling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4.4</span></a>:</p>
<table class="ltx_equation ltx_eqn_table" id="Ch4.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\widehat{y}=\operatorname{sigmod}({y_{FM}}+{y_{DNN}})," class="ltx_Math" display="block" id="Ch4.E4.m1.2"><semantics id="Ch4.E4.m1.2a"><mrow id="Ch4.E4.m1.2.2.1" xref="Ch4.E4.m1.2.2.1.1.cmml"><mrow id="Ch4.E4.m1.2.2.1.1" xref="Ch4.E4.m1.2.2.1.1.cmml"><mover accent="true" id="Ch4.E4.m1.2.2.1.1.3" xref="Ch4.E4.m1.2.2.1.1.3.cmml"><mi id="Ch4.E4.m1.2.2.1.1.3.2" xref="Ch4.E4.m1.2.2.1.1.3.2.cmml">y</mi><mo id="Ch4.E4.m1.2.2.1.1.3.1" xref="Ch4.E4.m1.2.2.1.1.3.1.cmml">^</mo></mover><mo id="Ch4.E4.m1.2.2.1.1.2" xref="Ch4.E4.m1.2.2.1.1.2.cmml">=</mo><mrow id="Ch4.E4.m1.2.2.1.1.1.1" xref="Ch4.E4.m1.2.2.1.1.1.2.cmml"><mi id="Ch4.E4.m1.1.1" xref="Ch4.E4.m1.1.1.cmml">sigmod</mi><mo id="Ch4.E4.m1.2.2.1.1.1.1a" xref="Ch4.E4.m1.2.2.1.1.1.2.cmml">⁡</mo><mrow id="Ch4.E4.m1.2.2.1.1.1.1.1" xref="Ch4.E4.m1.2.2.1.1.1.2.cmml"><mo id="Ch4.E4.m1.2.2.1.1.1.1.1.2" stretchy="false" xref="Ch4.E4.m1.2.2.1.1.1.2.cmml">(</mo><mrow id="Ch4.E4.m1.2.2.1.1.1.1.1.1" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.cmml"><msub id="Ch4.E4.m1.2.2.1.1.1.1.1.1.2" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.cmml"><mi id="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.2" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.2.cmml">y</mi><mrow id="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.3" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.3.cmml"><mi id="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.3.2" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.3.2.cmml">F</mi><mo id="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.3.1" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.3.3" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.3.3.cmml">M</mi></mrow></msub><mo id="Ch4.E4.m1.2.2.1.1.1.1.1.1.1" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.1.cmml">+</mo><msub id="Ch4.E4.m1.2.2.1.1.1.1.1.1.3" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.cmml"><mi id="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.2" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.2.cmml">y</mi><mrow id="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3.cmml"><mi id="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3.2" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3.2.cmml">D</mi><mo id="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3.1" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3.3" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3.3.cmml">N</mi><mo id="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3.1a" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3.4" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3.4.cmml">N</mi></mrow></msub></mrow><mo id="Ch4.E4.m1.2.2.1.1.1.1.1.3" stretchy="false" xref="Ch4.E4.m1.2.2.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mo id="Ch4.E4.m1.2.2.1.2" xref="Ch4.E4.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch4.E4.m1.2b"><apply id="Ch4.E4.m1.2.2.1.1.cmml" xref="Ch4.E4.m1.2.2.1"><eq id="Ch4.E4.m1.2.2.1.1.2.cmml" xref="Ch4.E4.m1.2.2.1.1.2"></eq><apply id="Ch4.E4.m1.2.2.1.1.3.cmml" xref="Ch4.E4.m1.2.2.1.1.3"><ci id="Ch4.E4.m1.2.2.1.1.3.1.cmml" xref="Ch4.E4.m1.2.2.1.1.3.1">^</ci><ci id="Ch4.E4.m1.2.2.1.1.3.2.cmml" xref="Ch4.E4.m1.2.2.1.1.3.2">𝑦</ci></apply><apply id="Ch4.E4.m1.2.2.1.1.1.2.cmml" xref="Ch4.E4.m1.2.2.1.1.1.1"><ci id="Ch4.E4.m1.1.1.cmml" xref="Ch4.E4.m1.1.1">sigmod</ci><apply id="Ch4.E4.m1.2.2.1.1.1.1.1.1.cmml" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1"><plus id="Ch4.E4.m1.2.2.1.1.1.1.1.1.1.cmml" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.1"></plus><apply id="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.cmml" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.2">subscript</csymbol><ci id="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.2.cmml" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.2">𝑦</ci><apply id="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.3.cmml" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.3"><times id="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.3.1.cmml" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.3.1"></times><ci id="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.3.2.cmml" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.3.2">𝐹</ci><ci id="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.3.3.cmml" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.2.3.3">𝑀</ci></apply></apply><apply id="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.cmml" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.1.cmml" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.3">subscript</csymbol><ci id="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.2.cmml" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.2">𝑦</ci><apply id="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3.cmml" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3"><times id="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3.1.cmml" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3.1"></times><ci id="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3.2.cmml" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3.2">𝐷</ci><ci id="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3.3.cmml" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3.3">𝑁</ci><ci id="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3.4.cmml" xref="Ch4.E4.m1.2.2.1.1.1.1.1.1.3.3.4">𝑁</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.E4.m1.2c">\widehat{y}=\operatorname{sigmod}({y_{FM}}+{y_{DNN}}),</annotation><annotation encoding="application/x-llamapun" id="Ch4.E4.m1.2d">over^ start_ARG italic_y end_ARG = roman_sigmod ( italic_y start_POSTSUBSCRIPT italic_F italic_M end_POSTSUBSCRIPT + italic_y start_POSTSUBSCRIPT italic_D italic_N italic_N end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4.4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch4.S1.SS1.p11.3">where <math alttext="\widehat{y}\in(0,1)" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p11.1.m1.2"><semantics id="Ch4.S1.SS1.p11.1.m1.2a"><mrow id="Ch4.S1.SS1.p11.1.m1.2.3" xref="Ch4.S1.SS1.p11.1.m1.2.3.cmml"><mover accent="true" id="Ch4.S1.SS1.p11.1.m1.2.3.2" xref="Ch4.S1.SS1.p11.1.m1.2.3.2.cmml"><mi id="Ch4.S1.SS1.p11.1.m1.2.3.2.2" xref="Ch4.S1.SS1.p11.1.m1.2.3.2.2.cmml">y</mi><mo id="Ch4.S1.SS1.p11.1.m1.2.3.2.1" xref="Ch4.S1.SS1.p11.1.m1.2.3.2.1.cmml">^</mo></mover><mo id="Ch4.S1.SS1.p11.1.m1.2.3.1" xref="Ch4.S1.SS1.p11.1.m1.2.3.1.cmml">∈</mo><mrow id="Ch4.S1.SS1.p11.1.m1.2.3.3.2" xref="Ch4.S1.SS1.p11.1.m1.2.3.3.1.cmml"><mo id="Ch4.S1.SS1.p11.1.m1.2.3.3.2.1" stretchy="false" xref="Ch4.S1.SS1.p11.1.m1.2.3.3.1.cmml">(</mo><mn id="Ch4.S1.SS1.p11.1.m1.1.1" xref="Ch4.S1.SS1.p11.1.m1.1.1.cmml">0</mn><mo id="Ch4.S1.SS1.p11.1.m1.2.3.3.2.2" xref="Ch4.S1.SS1.p11.1.m1.2.3.3.1.cmml">,</mo><mn id="Ch4.S1.SS1.p11.1.m1.2.2" xref="Ch4.S1.SS1.p11.1.m1.2.2.cmml">1</mn><mo id="Ch4.S1.SS1.p11.1.m1.2.3.3.2.3" stretchy="false" xref="Ch4.S1.SS1.p11.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p11.1.m1.2b"><apply id="Ch4.S1.SS1.p11.1.m1.2.3.cmml" xref="Ch4.S1.SS1.p11.1.m1.2.3"><in id="Ch4.S1.SS1.p11.1.m1.2.3.1.cmml" xref="Ch4.S1.SS1.p11.1.m1.2.3.1"></in><apply id="Ch4.S1.SS1.p11.1.m1.2.3.2.cmml" xref="Ch4.S1.SS1.p11.1.m1.2.3.2"><ci id="Ch4.S1.SS1.p11.1.m1.2.3.2.1.cmml" xref="Ch4.S1.SS1.p11.1.m1.2.3.2.1">^</ci><ci id="Ch4.S1.SS1.p11.1.m1.2.3.2.2.cmml" xref="Ch4.S1.SS1.p11.1.m1.2.3.2.2">𝑦</ci></apply><interval closure="open" id="Ch4.S1.SS1.p11.1.m1.2.3.3.1.cmml" xref="Ch4.S1.SS1.p11.1.m1.2.3.3.2"><cn id="Ch4.S1.SS1.p11.1.m1.1.1.cmml" type="integer" xref="Ch4.S1.SS1.p11.1.m1.1.1">0</cn><cn id="Ch4.S1.SS1.p11.1.m1.2.2.cmml" type="integer" xref="Ch4.S1.SS1.p11.1.m1.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p11.1.m1.2c">\widehat{y}\in(0,1)</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p11.1.m1.2d">over^ start_ARG italic_y end_ARG ∈ ( 0 , 1 )</annotation></semantics></math> refers to the predicted CTR, <math alttext="y_{FM}" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p11.2.m2.1"><semantics id="Ch4.S1.SS1.p11.2.m2.1a"><msub id="Ch4.S1.SS1.p11.2.m2.1.1" xref="Ch4.S1.SS1.p11.2.m2.1.1.cmml"><mi id="Ch4.S1.SS1.p11.2.m2.1.1.2" xref="Ch4.S1.SS1.p11.2.m2.1.1.2.cmml">y</mi><mrow id="Ch4.S1.SS1.p11.2.m2.1.1.3" xref="Ch4.S1.SS1.p11.2.m2.1.1.3.cmml"><mi id="Ch4.S1.SS1.p11.2.m2.1.1.3.2" xref="Ch4.S1.SS1.p11.2.m2.1.1.3.2.cmml">F</mi><mo id="Ch4.S1.SS1.p11.2.m2.1.1.3.1" xref="Ch4.S1.SS1.p11.2.m2.1.1.3.1.cmml">⁢</mo><mi id="Ch4.S1.SS1.p11.2.m2.1.1.3.3" xref="Ch4.S1.SS1.p11.2.m2.1.1.3.3.cmml">M</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p11.2.m2.1b"><apply id="Ch4.S1.SS1.p11.2.m2.1.1.cmml" xref="Ch4.S1.SS1.p11.2.m2.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p11.2.m2.1.1.1.cmml" xref="Ch4.S1.SS1.p11.2.m2.1.1">subscript</csymbol><ci id="Ch4.S1.SS1.p11.2.m2.1.1.2.cmml" xref="Ch4.S1.SS1.p11.2.m2.1.1.2">𝑦</ci><apply id="Ch4.S1.SS1.p11.2.m2.1.1.3.cmml" xref="Ch4.S1.SS1.p11.2.m2.1.1.3"><times id="Ch4.S1.SS1.p11.2.m2.1.1.3.1.cmml" xref="Ch4.S1.SS1.p11.2.m2.1.1.3.1"></times><ci id="Ch4.S1.SS1.p11.2.m2.1.1.3.2.cmml" xref="Ch4.S1.SS1.p11.2.m2.1.1.3.2">𝐹</ci><ci id="Ch4.S1.SS1.p11.2.m2.1.1.3.3.cmml" xref="Ch4.S1.SS1.p11.2.m2.1.1.3.3">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p11.2.m2.1c">y_{FM}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p11.2.m2.1d">italic_y start_POSTSUBSCRIPT italic_F italic_M end_POSTSUBSCRIPT</annotation></semantics></math> is the output of the FM component, and <math alttext="y_{DNN}" class="ltx_Math" display="inline" id="Ch4.S1.SS1.p11.3.m3.1"><semantics id="Ch4.S1.SS1.p11.3.m3.1a"><msub id="Ch4.S1.SS1.p11.3.m3.1.1" xref="Ch4.S1.SS1.p11.3.m3.1.1.cmml"><mi id="Ch4.S1.SS1.p11.3.m3.1.1.2" xref="Ch4.S1.SS1.p11.3.m3.1.1.2.cmml">y</mi><mrow id="Ch4.S1.SS1.p11.3.m3.1.1.3" xref="Ch4.S1.SS1.p11.3.m3.1.1.3.cmml"><mi id="Ch4.S1.SS1.p11.3.m3.1.1.3.2" xref="Ch4.S1.SS1.p11.3.m3.1.1.3.2.cmml">D</mi><mo id="Ch4.S1.SS1.p11.3.m3.1.1.3.1" xref="Ch4.S1.SS1.p11.3.m3.1.1.3.1.cmml">⁢</mo><mi id="Ch4.S1.SS1.p11.3.m3.1.1.3.3" xref="Ch4.S1.SS1.p11.3.m3.1.1.3.3.cmml">N</mi><mo id="Ch4.S1.SS1.p11.3.m3.1.1.3.1a" xref="Ch4.S1.SS1.p11.3.m3.1.1.3.1.cmml">⁢</mo><mi id="Ch4.S1.SS1.p11.3.m3.1.1.3.4" xref="Ch4.S1.SS1.p11.3.m3.1.1.3.4.cmml">N</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS1.p11.3.m3.1b"><apply id="Ch4.S1.SS1.p11.3.m3.1.1.cmml" xref="Ch4.S1.SS1.p11.3.m3.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS1.p11.3.m3.1.1.1.cmml" xref="Ch4.S1.SS1.p11.3.m3.1.1">subscript</csymbol><ci id="Ch4.S1.SS1.p11.3.m3.1.1.2.cmml" xref="Ch4.S1.SS1.p11.3.m3.1.1.2">𝑦</ci><apply id="Ch4.S1.SS1.p11.3.m3.1.1.3.cmml" xref="Ch4.S1.SS1.p11.3.m3.1.1.3"><times id="Ch4.S1.SS1.p11.3.m3.1.1.3.1.cmml" xref="Ch4.S1.SS1.p11.3.m3.1.1.3.1"></times><ci id="Ch4.S1.SS1.p11.3.m3.1.1.3.2.cmml" xref="Ch4.S1.SS1.p11.3.m3.1.1.3.2">𝐷</ci><ci id="Ch4.S1.SS1.p11.3.m3.1.1.3.3.cmml" xref="Ch4.S1.SS1.p11.3.m3.1.1.3.3">𝑁</ci><ci id="Ch4.S1.SS1.p11.3.m3.1.1.3.4.cmml" xref="Ch4.S1.SS1.p11.3.m3.1.1.3.4">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS1.p11.3.m3.1c">y_{DNN}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS1.p11.3.m3.1d">italic_y start_POSTSUBSCRIPT italic_D italic_N italic_N end_POSTSUBSCRIPT</annotation></semantics></math> is the output of the deep component.
The authors applied a feed-forward network in the deep component to learn higher-order feature interactions.
More DeepFM model-based deep learning methods have been proposed to address the CTR prediction problem, including deep convolutional neural networks (CNNs) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chan2018convolutional</span>]</cite> and deep interest neural networks <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2018deep</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">feng2019deep</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2019multi</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2019deep</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2021deepctr</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhu2022tkdectr</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2022icdectr</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">cheng2022dynamic</span>]</cite>.
All of the above-mentioned deep neural networks have significantly contributed to the optimization of item ranking in e-commerce searches and recommendations; this will be further discussed in Sections <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S4" title="5.4 Ranking strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.4</span></a> and  <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S3.SS3" title="6.3.3 Neural network models ‣ 6.3 Candidate ranking models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6.3.3</span></a>, respectively.</p>
</div>
<figure class="ltx_figure" id="Ch4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="412" id="Ch4.F3.g1" src="x26.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4.3: </span>Architecture of the DeepFM model for CTR prediction. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2017deepfm</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch4.S1.SS1.p12">
<p class="ltx_p" id="Ch4.S1.SS1.p12.1">Additionally, to ensure consistent evaluation and comparison of CTR prediction models, benchmark frameworks such as the open benchmarking for CTR <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhu2021open</span>]</cite> and BARS-CTR <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhu2022bars</span>]</cite> have been introduced. These frameworks provide a standardized way to evaluate model performance across different datasets, improving reproducibility and promoting further advancements in CTR research.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch4.S1.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1.2 </span>Post-click behavior tracking</h4>
<div class="ltx_para" id="Ch4.S1.SS2.p1">
<p class="ltx_p" id="Ch4.S1.SS2.p1.1">As we have discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S2.SS2" title="3.2.2 User engagement and post-clicks ‣ 3.2 E-commerce users ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.2.2</span></a>, post-click behavior plays an important role in modeling for e-commerce users in search (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5" title="Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5</span></a>) and recommendation scenarios (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6" title="Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6</span></a>).
In the literature, multiple studies have focused on applying various types of interaction signals to model post-click behaviors in search and recommendation scenarios.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">sculley2009predicting</span></cite> measured users’ post-click experience by evaluating the corresponding bounce rate.
The model proposed by <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhong2010incorporating</span></cite> leverages both user clicks on the search page and post-clicks beyond the search page to provide an unbiased estimation of document relevance.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">lalmas2015promoting</span></cite> investigated how viewport time can be used to measure user attention level as an engagement metric.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">o2016leveraging</span></cite> leveraged user interactions as signals within the clicked items to enhance the search results.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wan2018item</span></cite> determined the monotonic dependency between explicit user signals and more implicit signals to improve recommender systems.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">lu2018between</span></cite> proposed a preference prediction model to predict user actual preferences for the clicked items by taking into account multiple post-click interactions.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch4.S1.SS2.p2">
<p class="ltx_p" id="Ch4.S1.SS2.p2.1"><span class="ltx_text ltx_font_bold" id="Ch4.S1.SS2.p2.1.1">Dwell time.</span>
As we have discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S2.SS2" title="3.2.2 User engagement and post-clicks ‣ 3.2 E-commerce users ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.2.2</span></a>, dwell time is the most common evaluation metric for the analysis of post-click user behavior <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yin2013silence</span>]</cite>.
Accordingly, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">yin2013silence</span></cite> built a graphical model that focuses on utilizing explicit user feedback and dwell time to predict user preferences in e-commerce recommendations.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">yi2014beyond</span></cite> showed that integrating dwell time into the learning objective or learning weight results in better recommendation performance than pure predictions of the CTR.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">rosales2012post</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chapelle2015simple</span></cite> utilized dwell time as a proxy of post-click experience in online advertising to improve the ranking performance.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">bogina2017incorporating</span></cite> explored the value of incorporating dwell time for session-based recommendations by boosting items above the preassigned dwell time threshold.
Modeling user behavior by taking into account dwell time has been demonstrated to facilitate e-commerce recommendation performance.
In Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S2.SS3" title="6.2.3 Session-based recommendation ‣ 6.2 Candidate retrieval models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6.2.3</span></a>, we will discuss more studies that focused on modeling sequential user dynamics by using dwell time.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch4.S1.SS2.p3">
<p class="ltx_p" id="Ch4.S1.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="Ch4.S1.SS2.p3.1.1">User return modeling.</span>
There is a limited amount of work on modeling user returns in e-commerce, especially when user returns depend heavily on the quality of the provided service <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lo2016understanding</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhouwsdm2018</span>]</cite>.
The model developed by <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhouwsdm2018</span></cite> provides rich user interfaces after a user clicks an item. For instance, it encourages users to visit different item modules or sub-pages, i.e., to read comments or click on pictures embedded within the item page; this generates a large amount of heterogeneous post-click behavior.
Three problems pose a challenge for attempts to model micro-behavior on e-commerce platforms:

<span class="ltx_inline-enumerate" id="Ch4.S1.I1">
<span class="ltx_inline-item" id="Ch4.S1.I1.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch4.S1.I1.i1.1">Sparseness and high dimensionality of the user representation;
</span></span>
<span class="ltx_inline-item" id="Ch4.S1.I1.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch4.S1.I1.i2.1">Sequential information of micro-behavior; and
</span></span>
<span class="ltx_inline-item" id="Ch4.S1.I1.i3"><span class="ltx_tag ltx_tag_inline-item">(iii)</span> <span class="ltx_text" id="Ch4.S1.I1.i3.1">Diverse effects of micro-behavior.
</span></span>
</span>
To address these three challenges, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhouwsdm2018</span></cite> proposed the framework shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.F4" title="Figure 4.4 ‣ 4.1.2 Post-click behavior tracking ‣ 4.1 User behavior modeling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4.4</span></a>, which consists of five layers: an input layer, an embedding layer to solve the problems of sparseness and high dimensionality, an RNN layer to model sequential information, an attention layer to capture the diverse effects of micro-behavior, and an output layer.</p>
</div>
<figure class="ltx_figure" id="Ch4.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="283" id="Ch4.F4.g1" src="x27.png" width="789"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4.4: </span>Micro-behavior modeling framework. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhouwsdm2018</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="Ch4.S1.SS2.p4">
<p class="ltx_p" id="Ch4.S1.SS2.p4.3">The input of the model comprises the data of a user, <math alttext="u" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.1.m1.1"><semantics id="Ch4.S1.SS2.p4.1.m1.1a"><mi id="Ch4.S1.SS2.p4.1.m1.1.1" xref="Ch4.S1.SS2.p4.1.m1.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.1.m1.1b"><ci id="Ch4.S1.SS2.p4.1.m1.1.1.cmml" xref="Ch4.S1.SS2.p4.1.m1.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.1.m1.1c">u</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.1.m1.1d">italic_u</annotation></semantics></math>, with a sequence of micro-behavior.
Formally, the authors define it as the sequence <math alttext="S_{u}=\{x_{1},x_{2},\ldots,x_{n}\}" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.2.m2.4"><semantics id="Ch4.S1.SS2.p4.2.m2.4a"><mrow id="Ch4.S1.SS2.p4.2.m2.4.4" xref="Ch4.S1.SS2.p4.2.m2.4.4.cmml"><msub id="Ch4.S1.SS2.p4.2.m2.4.4.5" xref="Ch4.S1.SS2.p4.2.m2.4.4.5.cmml"><mi id="Ch4.S1.SS2.p4.2.m2.4.4.5.2" xref="Ch4.S1.SS2.p4.2.m2.4.4.5.2.cmml">S</mi><mi id="Ch4.S1.SS2.p4.2.m2.4.4.5.3" xref="Ch4.S1.SS2.p4.2.m2.4.4.5.3.cmml">u</mi></msub><mo id="Ch4.S1.SS2.p4.2.m2.4.4.4" xref="Ch4.S1.SS2.p4.2.m2.4.4.4.cmml">=</mo><mrow id="Ch4.S1.SS2.p4.2.m2.4.4.3.3" xref="Ch4.S1.SS2.p4.2.m2.4.4.3.4.cmml"><mo id="Ch4.S1.SS2.p4.2.m2.4.4.3.3.4" stretchy="false" xref="Ch4.S1.SS2.p4.2.m2.4.4.3.4.cmml">{</mo><msub id="Ch4.S1.SS2.p4.2.m2.2.2.1.1.1" xref="Ch4.S1.SS2.p4.2.m2.2.2.1.1.1.cmml"><mi id="Ch4.S1.SS2.p4.2.m2.2.2.1.1.1.2" xref="Ch4.S1.SS2.p4.2.m2.2.2.1.1.1.2.cmml">x</mi><mn id="Ch4.S1.SS2.p4.2.m2.2.2.1.1.1.3" xref="Ch4.S1.SS2.p4.2.m2.2.2.1.1.1.3.cmml">1</mn></msub><mo id="Ch4.S1.SS2.p4.2.m2.4.4.3.3.5" xref="Ch4.S1.SS2.p4.2.m2.4.4.3.4.cmml">,</mo><msub id="Ch4.S1.SS2.p4.2.m2.3.3.2.2.2" xref="Ch4.S1.SS2.p4.2.m2.3.3.2.2.2.cmml"><mi id="Ch4.S1.SS2.p4.2.m2.3.3.2.2.2.2" xref="Ch4.S1.SS2.p4.2.m2.3.3.2.2.2.2.cmml">x</mi><mn id="Ch4.S1.SS2.p4.2.m2.3.3.2.2.2.3" xref="Ch4.S1.SS2.p4.2.m2.3.3.2.2.2.3.cmml">2</mn></msub><mo id="Ch4.S1.SS2.p4.2.m2.4.4.3.3.6" xref="Ch4.S1.SS2.p4.2.m2.4.4.3.4.cmml">,</mo><mi id="Ch4.S1.SS2.p4.2.m2.1.1" mathvariant="normal" xref="Ch4.S1.SS2.p4.2.m2.1.1.cmml">…</mi><mo id="Ch4.S1.SS2.p4.2.m2.4.4.3.3.7" xref="Ch4.S1.SS2.p4.2.m2.4.4.3.4.cmml">,</mo><msub id="Ch4.S1.SS2.p4.2.m2.4.4.3.3.3" xref="Ch4.S1.SS2.p4.2.m2.4.4.3.3.3.cmml"><mi id="Ch4.S1.SS2.p4.2.m2.4.4.3.3.3.2" xref="Ch4.S1.SS2.p4.2.m2.4.4.3.3.3.2.cmml">x</mi><mi id="Ch4.S1.SS2.p4.2.m2.4.4.3.3.3.3" xref="Ch4.S1.SS2.p4.2.m2.4.4.3.3.3.3.cmml">n</mi></msub><mo id="Ch4.S1.SS2.p4.2.m2.4.4.3.3.8" stretchy="false" xref="Ch4.S1.SS2.p4.2.m2.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.2.m2.4b"><apply id="Ch4.S1.SS2.p4.2.m2.4.4.cmml" xref="Ch4.S1.SS2.p4.2.m2.4.4"><eq id="Ch4.S1.SS2.p4.2.m2.4.4.4.cmml" xref="Ch4.S1.SS2.p4.2.m2.4.4.4"></eq><apply id="Ch4.S1.SS2.p4.2.m2.4.4.5.cmml" xref="Ch4.S1.SS2.p4.2.m2.4.4.5"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.2.m2.4.4.5.1.cmml" xref="Ch4.S1.SS2.p4.2.m2.4.4.5">subscript</csymbol><ci id="Ch4.S1.SS2.p4.2.m2.4.4.5.2.cmml" xref="Ch4.S1.SS2.p4.2.m2.4.4.5.2">𝑆</ci><ci id="Ch4.S1.SS2.p4.2.m2.4.4.5.3.cmml" xref="Ch4.S1.SS2.p4.2.m2.4.4.5.3">𝑢</ci></apply><set id="Ch4.S1.SS2.p4.2.m2.4.4.3.4.cmml" xref="Ch4.S1.SS2.p4.2.m2.4.4.3.3"><apply id="Ch4.S1.SS2.p4.2.m2.2.2.1.1.1.cmml" xref="Ch4.S1.SS2.p4.2.m2.2.2.1.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.2.m2.2.2.1.1.1.1.cmml" xref="Ch4.S1.SS2.p4.2.m2.2.2.1.1.1">subscript</csymbol><ci id="Ch4.S1.SS2.p4.2.m2.2.2.1.1.1.2.cmml" xref="Ch4.S1.SS2.p4.2.m2.2.2.1.1.1.2">𝑥</ci><cn id="Ch4.S1.SS2.p4.2.m2.2.2.1.1.1.3.cmml" type="integer" xref="Ch4.S1.SS2.p4.2.m2.2.2.1.1.1.3">1</cn></apply><apply id="Ch4.S1.SS2.p4.2.m2.3.3.2.2.2.cmml" xref="Ch4.S1.SS2.p4.2.m2.3.3.2.2.2"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.2.m2.3.3.2.2.2.1.cmml" xref="Ch4.S1.SS2.p4.2.m2.3.3.2.2.2">subscript</csymbol><ci id="Ch4.S1.SS2.p4.2.m2.3.3.2.2.2.2.cmml" xref="Ch4.S1.SS2.p4.2.m2.3.3.2.2.2.2">𝑥</ci><cn id="Ch4.S1.SS2.p4.2.m2.3.3.2.2.2.3.cmml" type="integer" xref="Ch4.S1.SS2.p4.2.m2.3.3.2.2.2.3">2</cn></apply><ci id="Ch4.S1.SS2.p4.2.m2.1.1.cmml" xref="Ch4.S1.SS2.p4.2.m2.1.1">…</ci><apply id="Ch4.S1.SS2.p4.2.m2.4.4.3.3.3.cmml" xref="Ch4.S1.SS2.p4.2.m2.4.4.3.3.3"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.2.m2.4.4.3.3.3.1.cmml" xref="Ch4.S1.SS2.p4.2.m2.4.4.3.3.3">subscript</csymbol><ci id="Ch4.S1.SS2.p4.2.m2.4.4.3.3.3.2.cmml" xref="Ch4.S1.SS2.p4.2.m2.4.4.3.3.3.2">𝑥</ci><ci id="Ch4.S1.SS2.p4.2.m2.4.4.3.3.3.3.cmml" xref="Ch4.S1.SS2.p4.2.m2.4.4.3.3.3.3">𝑛</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.2.m2.4c">S_{u}=\{x_{1},x_{2},\ldots,x_{n}\}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.2.m2.4d">italic_S start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT = { italic_x start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_x start_POSTSUBSCRIPT italic_n end_POSTSUBSCRIPT }</annotation></semantics></math>, where each <math alttext="x_{i}" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.3.m3.1"><semantics id="Ch4.S1.SS2.p4.3.m3.1a"><msub id="Ch4.S1.SS2.p4.3.m3.1.1" xref="Ch4.S1.SS2.p4.3.m3.1.1.cmml"><mi id="Ch4.S1.SS2.p4.3.m3.1.1.2" xref="Ch4.S1.SS2.p4.3.m3.1.1.2.cmml">x</mi><mi id="Ch4.S1.SS2.p4.3.m3.1.1.3" xref="Ch4.S1.SS2.p4.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.3.m3.1b"><apply id="Ch4.S1.SS2.p4.3.m3.1.1.cmml" xref="Ch4.S1.SS2.p4.3.m3.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.3.m3.1.1.1.cmml" xref="Ch4.S1.SS2.p4.3.m3.1.1">subscript</csymbol><ci id="Ch4.S1.SS2.p4.3.m3.1.1.2.cmml" xref="Ch4.S1.SS2.p4.3.m3.1.1.2">𝑥</ci><ci id="Ch4.S1.SS2.p4.3.m3.1.1.3.cmml" xref="Ch4.S1.SS2.p4.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.3.m3.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.3.m3.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is a tuple, i.e.,</p>
<table class="ltx_equation ltx_eqn_table" id="Ch4.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="x_{t}=(p_{v},a_{m},d_{k})," class="ltx_Math" display="block" id="Ch4.E5.m1.1"><semantics id="Ch4.E5.m1.1a"><mrow id="Ch4.E5.m1.1.1.1" xref="Ch4.E5.m1.1.1.1.1.cmml"><mrow id="Ch4.E5.m1.1.1.1.1" xref="Ch4.E5.m1.1.1.1.1.cmml"><msub id="Ch4.E5.m1.1.1.1.1.5" xref="Ch4.E5.m1.1.1.1.1.5.cmml"><mi id="Ch4.E5.m1.1.1.1.1.5.2" xref="Ch4.E5.m1.1.1.1.1.5.2.cmml">x</mi><mi id="Ch4.E5.m1.1.1.1.1.5.3" xref="Ch4.E5.m1.1.1.1.1.5.3.cmml">t</mi></msub><mo id="Ch4.E5.m1.1.1.1.1.4" xref="Ch4.E5.m1.1.1.1.1.4.cmml">=</mo><mrow id="Ch4.E5.m1.1.1.1.1.3.3" xref="Ch4.E5.m1.1.1.1.1.3.4.cmml"><mo id="Ch4.E5.m1.1.1.1.1.3.3.4" stretchy="false" xref="Ch4.E5.m1.1.1.1.1.3.4.cmml">(</mo><msub id="Ch4.E5.m1.1.1.1.1.1.1.1" xref="Ch4.E5.m1.1.1.1.1.1.1.1.cmml"><mi id="Ch4.E5.m1.1.1.1.1.1.1.1.2" xref="Ch4.E5.m1.1.1.1.1.1.1.1.2.cmml">p</mi><mi id="Ch4.E5.m1.1.1.1.1.1.1.1.3" xref="Ch4.E5.m1.1.1.1.1.1.1.1.3.cmml">v</mi></msub><mo id="Ch4.E5.m1.1.1.1.1.3.3.5" xref="Ch4.E5.m1.1.1.1.1.3.4.cmml">,</mo><msub id="Ch4.E5.m1.1.1.1.1.2.2.2" xref="Ch4.E5.m1.1.1.1.1.2.2.2.cmml"><mi id="Ch4.E5.m1.1.1.1.1.2.2.2.2" xref="Ch4.E5.m1.1.1.1.1.2.2.2.2.cmml">a</mi><mi id="Ch4.E5.m1.1.1.1.1.2.2.2.3" xref="Ch4.E5.m1.1.1.1.1.2.2.2.3.cmml">m</mi></msub><mo id="Ch4.E5.m1.1.1.1.1.3.3.6" xref="Ch4.E5.m1.1.1.1.1.3.4.cmml">,</mo><msub id="Ch4.E5.m1.1.1.1.1.3.3.3" xref="Ch4.E5.m1.1.1.1.1.3.3.3.cmml"><mi id="Ch4.E5.m1.1.1.1.1.3.3.3.2" xref="Ch4.E5.m1.1.1.1.1.3.3.3.2.cmml">d</mi><mi id="Ch4.E5.m1.1.1.1.1.3.3.3.3" xref="Ch4.E5.m1.1.1.1.1.3.3.3.3.cmml">k</mi></msub><mo id="Ch4.E5.m1.1.1.1.1.3.3.7" stretchy="false" xref="Ch4.E5.m1.1.1.1.1.3.4.cmml">)</mo></mrow></mrow><mo id="Ch4.E5.m1.1.1.1.2" xref="Ch4.E5.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch4.E5.m1.1b"><apply id="Ch4.E5.m1.1.1.1.1.cmml" xref="Ch4.E5.m1.1.1.1"><eq id="Ch4.E5.m1.1.1.1.1.4.cmml" xref="Ch4.E5.m1.1.1.1.1.4"></eq><apply id="Ch4.E5.m1.1.1.1.1.5.cmml" xref="Ch4.E5.m1.1.1.1.1.5"><csymbol cd="ambiguous" id="Ch4.E5.m1.1.1.1.1.5.1.cmml" xref="Ch4.E5.m1.1.1.1.1.5">subscript</csymbol><ci id="Ch4.E5.m1.1.1.1.1.5.2.cmml" xref="Ch4.E5.m1.1.1.1.1.5.2">𝑥</ci><ci id="Ch4.E5.m1.1.1.1.1.5.3.cmml" xref="Ch4.E5.m1.1.1.1.1.5.3">𝑡</ci></apply><vector id="Ch4.E5.m1.1.1.1.1.3.4.cmml" xref="Ch4.E5.m1.1.1.1.1.3.3"><apply id="Ch4.E5.m1.1.1.1.1.1.1.1.cmml" xref="Ch4.E5.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="Ch4.E5.m1.1.1.1.1.1.1.1.1.cmml" xref="Ch4.E5.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="Ch4.E5.m1.1.1.1.1.1.1.1.2.cmml" xref="Ch4.E5.m1.1.1.1.1.1.1.1.2">𝑝</ci><ci id="Ch4.E5.m1.1.1.1.1.1.1.1.3.cmml" xref="Ch4.E5.m1.1.1.1.1.1.1.1.3">𝑣</ci></apply><apply id="Ch4.E5.m1.1.1.1.1.2.2.2.cmml" xref="Ch4.E5.m1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="Ch4.E5.m1.1.1.1.1.2.2.2.1.cmml" xref="Ch4.E5.m1.1.1.1.1.2.2.2">subscript</csymbol><ci id="Ch4.E5.m1.1.1.1.1.2.2.2.2.cmml" xref="Ch4.E5.m1.1.1.1.1.2.2.2.2">𝑎</ci><ci id="Ch4.E5.m1.1.1.1.1.2.2.2.3.cmml" xref="Ch4.E5.m1.1.1.1.1.2.2.2.3">𝑚</ci></apply><apply id="Ch4.E5.m1.1.1.1.1.3.3.3.cmml" xref="Ch4.E5.m1.1.1.1.1.3.3.3"><csymbol cd="ambiguous" id="Ch4.E5.m1.1.1.1.1.3.3.3.1.cmml" xref="Ch4.E5.m1.1.1.1.1.3.3.3">subscript</csymbol><ci id="Ch4.E5.m1.1.1.1.1.3.3.3.2.cmml" xref="Ch4.E5.m1.1.1.1.1.3.3.3.2">𝑑</ci><ci id="Ch4.E5.m1.1.1.1.1.3.3.3.3.cmml" xref="Ch4.E5.m1.1.1.1.1.3.3.3.3">𝑘</ci></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.E5.m1.1c">x_{t}=(p_{v},a_{m},d_{k}),</annotation><annotation encoding="application/x-llamapun" id="Ch4.E5.m1.1d">italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = ( italic_p start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4.5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch4.S1.SS2.p4.21">where <math alttext="p_{v}\in\mathbb{R}^{V}" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.4.m1.1"><semantics id="Ch4.S1.SS2.p4.4.m1.1a"><mrow id="Ch4.S1.SS2.p4.4.m1.1.1" xref="Ch4.S1.SS2.p4.4.m1.1.1.cmml"><msub id="Ch4.S1.SS2.p4.4.m1.1.1.2" xref="Ch4.S1.SS2.p4.4.m1.1.1.2.cmml"><mi id="Ch4.S1.SS2.p4.4.m1.1.1.2.2" xref="Ch4.S1.SS2.p4.4.m1.1.1.2.2.cmml">p</mi><mi id="Ch4.S1.SS2.p4.4.m1.1.1.2.3" xref="Ch4.S1.SS2.p4.4.m1.1.1.2.3.cmml">v</mi></msub><mo id="Ch4.S1.SS2.p4.4.m1.1.1.1" xref="Ch4.S1.SS2.p4.4.m1.1.1.1.cmml">∈</mo><msup id="Ch4.S1.SS2.p4.4.m1.1.1.3" xref="Ch4.S1.SS2.p4.4.m1.1.1.3.cmml"><mi id="Ch4.S1.SS2.p4.4.m1.1.1.3.2" xref="Ch4.S1.SS2.p4.4.m1.1.1.3.2.cmml">ℝ</mi><mi id="Ch4.S1.SS2.p4.4.m1.1.1.3.3" xref="Ch4.S1.SS2.p4.4.m1.1.1.3.3.cmml">V</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.4.m1.1b"><apply id="Ch4.S1.SS2.p4.4.m1.1.1.cmml" xref="Ch4.S1.SS2.p4.4.m1.1.1"><in id="Ch4.S1.SS2.p4.4.m1.1.1.1.cmml" xref="Ch4.S1.SS2.p4.4.m1.1.1.1"></in><apply id="Ch4.S1.SS2.p4.4.m1.1.1.2.cmml" xref="Ch4.S1.SS2.p4.4.m1.1.1.2"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.4.m1.1.1.2.1.cmml" xref="Ch4.S1.SS2.p4.4.m1.1.1.2">subscript</csymbol><ci id="Ch4.S1.SS2.p4.4.m1.1.1.2.2.cmml" xref="Ch4.S1.SS2.p4.4.m1.1.1.2.2">𝑝</ci><ci id="Ch4.S1.SS2.p4.4.m1.1.1.2.3.cmml" xref="Ch4.S1.SS2.p4.4.m1.1.1.2.3">𝑣</ci></apply><apply id="Ch4.S1.SS2.p4.4.m1.1.1.3.cmml" xref="Ch4.S1.SS2.p4.4.m1.1.1.3"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.4.m1.1.1.3.1.cmml" xref="Ch4.S1.SS2.p4.4.m1.1.1.3">superscript</csymbol><ci id="Ch4.S1.SS2.p4.4.m1.1.1.3.2.cmml" xref="Ch4.S1.SS2.p4.4.m1.1.1.3.2">ℝ</ci><ci id="Ch4.S1.SS2.p4.4.m1.1.1.3.3.cmml" xref="Ch4.S1.SS2.p4.4.m1.1.1.3.3">𝑉</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.4.m1.1c">p_{v}\in\mathbb{R}^{V}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.4.m1.1d">italic_p start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_V end_POSTSUPERSCRIPT</annotation></semantics></math> is a one-hot indicator vector where <math alttext="p_{v}(i)=1" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.5.m2.1"><semantics id="Ch4.S1.SS2.p4.5.m2.1a"><mrow id="Ch4.S1.SS2.p4.5.m2.1.2" xref="Ch4.S1.SS2.p4.5.m2.1.2.cmml"><mrow id="Ch4.S1.SS2.p4.5.m2.1.2.2" xref="Ch4.S1.SS2.p4.5.m2.1.2.2.cmml"><msub id="Ch4.S1.SS2.p4.5.m2.1.2.2.2" xref="Ch4.S1.SS2.p4.5.m2.1.2.2.2.cmml"><mi id="Ch4.S1.SS2.p4.5.m2.1.2.2.2.2" xref="Ch4.S1.SS2.p4.5.m2.1.2.2.2.2.cmml">p</mi><mi id="Ch4.S1.SS2.p4.5.m2.1.2.2.2.3" xref="Ch4.S1.SS2.p4.5.m2.1.2.2.2.3.cmml">v</mi></msub><mo id="Ch4.S1.SS2.p4.5.m2.1.2.2.1" xref="Ch4.S1.SS2.p4.5.m2.1.2.2.1.cmml">⁢</mo><mrow id="Ch4.S1.SS2.p4.5.m2.1.2.2.3.2" xref="Ch4.S1.SS2.p4.5.m2.1.2.2.cmml"><mo id="Ch4.S1.SS2.p4.5.m2.1.2.2.3.2.1" stretchy="false" xref="Ch4.S1.SS2.p4.5.m2.1.2.2.cmml">(</mo><mi id="Ch4.S1.SS2.p4.5.m2.1.1" xref="Ch4.S1.SS2.p4.5.m2.1.1.cmml">i</mi><mo id="Ch4.S1.SS2.p4.5.m2.1.2.2.3.2.2" stretchy="false" xref="Ch4.S1.SS2.p4.5.m2.1.2.2.cmml">)</mo></mrow></mrow><mo id="Ch4.S1.SS2.p4.5.m2.1.2.1" xref="Ch4.S1.SS2.p4.5.m2.1.2.1.cmml">=</mo><mn id="Ch4.S1.SS2.p4.5.m2.1.2.3" xref="Ch4.S1.SS2.p4.5.m2.1.2.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.5.m2.1b"><apply id="Ch4.S1.SS2.p4.5.m2.1.2.cmml" xref="Ch4.S1.SS2.p4.5.m2.1.2"><eq id="Ch4.S1.SS2.p4.5.m2.1.2.1.cmml" xref="Ch4.S1.SS2.p4.5.m2.1.2.1"></eq><apply id="Ch4.S1.SS2.p4.5.m2.1.2.2.cmml" xref="Ch4.S1.SS2.p4.5.m2.1.2.2"><times id="Ch4.S1.SS2.p4.5.m2.1.2.2.1.cmml" xref="Ch4.S1.SS2.p4.5.m2.1.2.2.1"></times><apply id="Ch4.S1.SS2.p4.5.m2.1.2.2.2.cmml" xref="Ch4.S1.SS2.p4.5.m2.1.2.2.2"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.5.m2.1.2.2.2.1.cmml" xref="Ch4.S1.SS2.p4.5.m2.1.2.2.2">subscript</csymbol><ci id="Ch4.S1.SS2.p4.5.m2.1.2.2.2.2.cmml" xref="Ch4.S1.SS2.p4.5.m2.1.2.2.2.2">𝑝</ci><ci id="Ch4.S1.SS2.p4.5.m2.1.2.2.2.3.cmml" xref="Ch4.S1.SS2.p4.5.m2.1.2.2.2.3">𝑣</ci></apply><ci id="Ch4.S1.SS2.p4.5.m2.1.1.cmml" xref="Ch4.S1.SS2.p4.5.m2.1.1">𝑖</ci></apply><cn id="Ch4.S1.SS2.p4.5.m2.1.2.3.cmml" type="integer" xref="Ch4.S1.SS2.p4.5.m2.1.2.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.5.m2.1c">p_{v}(i)=1</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.5.m2.1d">italic_p start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ( italic_i ) = 1</annotation></semantics></math> if <math alttext="x_{i}" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.6.m3.1"><semantics id="Ch4.S1.SS2.p4.6.m3.1a"><msub id="Ch4.S1.SS2.p4.6.m3.1.1" xref="Ch4.S1.SS2.p4.6.m3.1.1.cmml"><mi id="Ch4.S1.SS2.p4.6.m3.1.1.2" xref="Ch4.S1.SS2.p4.6.m3.1.1.2.cmml">x</mi><mi id="Ch4.S1.SS2.p4.6.m3.1.1.3" xref="Ch4.S1.SS2.p4.6.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.6.m3.1b"><apply id="Ch4.S1.SS2.p4.6.m3.1.1.cmml" xref="Ch4.S1.SS2.p4.6.m3.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.6.m3.1.1.1.cmml" xref="Ch4.S1.SS2.p4.6.m3.1.1">subscript</csymbol><ci id="Ch4.S1.SS2.p4.6.m3.1.1.2.cmml" xref="Ch4.S1.SS2.p4.6.m3.1.1.2">𝑥</ci><ci id="Ch4.S1.SS2.p4.6.m3.1.1.3.cmml" xref="Ch4.S1.SS2.p4.6.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.6.m3.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.6.m3.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is about the <math alttext="i" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.7.m4.1"><semantics id="Ch4.S1.SS2.p4.7.m4.1a"><mi id="Ch4.S1.SS2.p4.7.m4.1.1" xref="Ch4.S1.SS2.p4.7.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.7.m4.1b"><ci id="Ch4.S1.SS2.p4.7.m4.1.1.cmml" xref="Ch4.S1.SS2.p4.7.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.7.m4.1c">i</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.7.m4.1d">italic_i</annotation></semantics></math>-th product and other entities are zero.
Similarly, <math alttext="a_{m}\in\mathbb{R}^{M}" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.8.m5.1"><semantics id="Ch4.S1.SS2.p4.8.m5.1a"><mrow id="Ch4.S1.SS2.p4.8.m5.1.1" xref="Ch4.S1.SS2.p4.8.m5.1.1.cmml"><msub id="Ch4.S1.SS2.p4.8.m5.1.1.2" xref="Ch4.S1.SS2.p4.8.m5.1.1.2.cmml"><mi id="Ch4.S1.SS2.p4.8.m5.1.1.2.2" xref="Ch4.S1.SS2.p4.8.m5.1.1.2.2.cmml">a</mi><mi id="Ch4.S1.SS2.p4.8.m5.1.1.2.3" xref="Ch4.S1.SS2.p4.8.m5.1.1.2.3.cmml">m</mi></msub><mo id="Ch4.S1.SS2.p4.8.m5.1.1.1" xref="Ch4.S1.SS2.p4.8.m5.1.1.1.cmml">∈</mo><msup id="Ch4.S1.SS2.p4.8.m5.1.1.3" xref="Ch4.S1.SS2.p4.8.m5.1.1.3.cmml"><mi id="Ch4.S1.SS2.p4.8.m5.1.1.3.2" xref="Ch4.S1.SS2.p4.8.m5.1.1.3.2.cmml">ℝ</mi><mi id="Ch4.S1.SS2.p4.8.m5.1.1.3.3" xref="Ch4.S1.SS2.p4.8.m5.1.1.3.3.cmml">M</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.8.m5.1b"><apply id="Ch4.S1.SS2.p4.8.m5.1.1.cmml" xref="Ch4.S1.SS2.p4.8.m5.1.1"><in id="Ch4.S1.SS2.p4.8.m5.1.1.1.cmml" xref="Ch4.S1.SS2.p4.8.m5.1.1.1"></in><apply id="Ch4.S1.SS2.p4.8.m5.1.1.2.cmml" xref="Ch4.S1.SS2.p4.8.m5.1.1.2"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.8.m5.1.1.2.1.cmml" xref="Ch4.S1.SS2.p4.8.m5.1.1.2">subscript</csymbol><ci id="Ch4.S1.SS2.p4.8.m5.1.1.2.2.cmml" xref="Ch4.S1.SS2.p4.8.m5.1.1.2.2">𝑎</ci><ci id="Ch4.S1.SS2.p4.8.m5.1.1.2.3.cmml" xref="Ch4.S1.SS2.p4.8.m5.1.1.2.3">𝑚</ci></apply><apply id="Ch4.S1.SS2.p4.8.m5.1.1.3.cmml" xref="Ch4.S1.SS2.p4.8.m5.1.1.3"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.8.m5.1.1.3.1.cmml" xref="Ch4.S1.SS2.p4.8.m5.1.1.3">superscript</csymbol><ci id="Ch4.S1.SS2.p4.8.m5.1.1.3.2.cmml" xref="Ch4.S1.SS2.p4.8.m5.1.1.3.2">ℝ</ci><ci id="Ch4.S1.SS2.p4.8.m5.1.1.3.3.cmml" xref="Ch4.S1.SS2.p4.8.m5.1.1.3.3">𝑀</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.8.m5.1c">a_{m}\in\mathbb{R}^{M}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.8.m5.1d">italic_a start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_M end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="d_{k}\in\mathbb{R}^{K}" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.9.m6.1"><semantics id="Ch4.S1.SS2.p4.9.m6.1a"><mrow id="Ch4.S1.SS2.p4.9.m6.1.1" xref="Ch4.S1.SS2.p4.9.m6.1.1.cmml"><msub id="Ch4.S1.SS2.p4.9.m6.1.1.2" xref="Ch4.S1.SS2.p4.9.m6.1.1.2.cmml"><mi id="Ch4.S1.SS2.p4.9.m6.1.1.2.2" xref="Ch4.S1.SS2.p4.9.m6.1.1.2.2.cmml">d</mi><mi id="Ch4.S1.SS2.p4.9.m6.1.1.2.3" xref="Ch4.S1.SS2.p4.9.m6.1.1.2.3.cmml">k</mi></msub><mo id="Ch4.S1.SS2.p4.9.m6.1.1.1" xref="Ch4.S1.SS2.p4.9.m6.1.1.1.cmml">∈</mo><msup id="Ch4.S1.SS2.p4.9.m6.1.1.3" xref="Ch4.S1.SS2.p4.9.m6.1.1.3.cmml"><mi id="Ch4.S1.SS2.p4.9.m6.1.1.3.2" xref="Ch4.S1.SS2.p4.9.m6.1.1.3.2.cmml">ℝ</mi><mi id="Ch4.S1.SS2.p4.9.m6.1.1.3.3" xref="Ch4.S1.SS2.p4.9.m6.1.1.3.3.cmml">K</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.9.m6.1b"><apply id="Ch4.S1.SS2.p4.9.m6.1.1.cmml" xref="Ch4.S1.SS2.p4.9.m6.1.1"><in id="Ch4.S1.SS2.p4.9.m6.1.1.1.cmml" xref="Ch4.S1.SS2.p4.9.m6.1.1.1"></in><apply id="Ch4.S1.SS2.p4.9.m6.1.1.2.cmml" xref="Ch4.S1.SS2.p4.9.m6.1.1.2"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.9.m6.1.1.2.1.cmml" xref="Ch4.S1.SS2.p4.9.m6.1.1.2">subscript</csymbol><ci id="Ch4.S1.SS2.p4.9.m6.1.1.2.2.cmml" xref="Ch4.S1.SS2.p4.9.m6.1.1.2.2">𝑑</ci><ci id="Ch4.S1.SS2.p4.9.m6.1.1.2.3.cmml" xref="Ch4.S1.SS2.p4.9.m6.1.1.2.3">𝑘</ci></apply><apply id="Ch4.S1.SS2.p4.9.m6.1.1.3.cmml" xref="Ch4.S1.SS2.p4.9.m6.1.1.3"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.9.m6.1.1.3.1.cmml" xref="Ch4.S1.SS2.p4.9.m6.1.1.3">superscript</csymbol><ci id="Ch4.S1.SS2.p4.9.m6.1.1.3.2.cmml" xref="Ch4.S1.SS2.p4.9.m6.1.1.3.2">ℝ</ci><ci id="Ch4.S1.SS2.p4.9.m6.1.1.3.3.cmml" xref="Ch4.S1.SS2.p4.9.m6.1.1.3.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.9.m6.1c">d_{k}\in\mathbb{R}^{K}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.9.m6.1d">italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ∈ blackboard_R start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT</annotation></semantics></math> are indicator vectors for activities and dwell time, respectively.
Each indicates a unique element in the product set <math alttext="P" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.10.m7.1"><semantics id="Ch4.S1.SS2.p4.10.m7.1a"><mi id="Ch4.S1.SS2.p4.10.m7.1.1" xref="Ch4.S1.SS2.p4.10.m7.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.10.m7.1b"><ci id="Ch4.S1.SS2.p4.10.m7.1.1.cmml" xref="Ch4.S1.SS2.p4.10.m7.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.10.m7.1c">P</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.10.m7.1d">italic_P</annotation></semantics></math>, activity set <math alttext="A" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.11.m8.1"><semantics id="Ch4.S1.SS2.p4.11.m8.1a"><mi id="Ch4.S1.SS2.p4.11.m8.1.1" xref="Ch4.S1.SS2.p4.11.m8.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.11.m8.1b"><ci id="Ch4.S1.SS2.p4.11.m8.1.1.cmml" xref="Ch4.S1.SS2.p4.11.m8.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.11.m8.1c">A</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.11.m8.1d">italic_A</annotation></semantics></math>, and dwell time set <math alttext="D" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.12.m9.1"><semantics id="Ch4.S1.SS2.p4.12.m9.1a"><mi id="Ch4.S1.SS2.p4.12.m9.1.1" xref="Ch4.S1.SS2.p4.12.m9.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.12.m9.1b"><ci id="Ch4.S1.SS2.p4.12.m9.1.1.cmml" xref="Ch4.S1.SS2.p4.12.m9.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.12.m9.1c">D</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.12.m9.1d">italic_D</annotation></semantics></math>, respectively.
Here, the vocabulary sizes of <math alttext="P" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.13.m10.1"><semantics id="Ch4.S1.SS2.p4.13.m10.1a"><mi id="Ch4.S1.SS2.p4.13.m10.1.1" xref="Ch4.S1.SS2.p4.13.m10.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.13.m10.1b"><ci id="Ch4.S1.SS2.p4.13.m10.1.1.cmml" xref="Ch4.S1.SS2.p4.13.m10.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.13.m10.1c">P</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.13.m10.1d">italic_P</annotation></semantics></math>, <math alttext="A" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.14.m11.1"><semantics id="Ch4.S1.SS2.p4.14.m11.1a"><mi id="Ch4.S1.SS2.p4.14.m11.1.1" xref="Ch4.S1.SS2.p4.14.m11.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.14.m11.1b"><ci id="Ch4.S1.SS2.p4.14.m11.1.1.cmml" xref="Ch4.S1.SS2.p4.14.m11.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.14.m11.1c">A</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.14.m11.1d">italic_A</annotation></semantics></math>, and <math alttext="D" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.15.m12.1"><semantics id="Ch4.S1.SS2.p4.15.m12.1a"><mi id="Ch4.S1.SS2.p4.15.m12.1.1" xref="Ch4.S1.SS2.p4.15.m12.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.15.m12.1b"><ci id="Ch4.S1.SS2.p4.15.m12.1.1.cmml" xref="Ch4.S1.SS2.p4.15.m12.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.15.m12.1c">D</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.15.m12.1d">italic_D</annotation></semantics></math> are <math alttext="V" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.16.m13.1"><semantics id="Ch4.S1.SS2.p4.16.m13.1a"><mi id="Ch4.S1.SS2.p4.16.m13.1.1" xref="Ch4.S1.SS2.p4.16.m13.1.1.cmml">V</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.16.m13.1b"><ci id="Ch4.S1.SS2.p4.16.m13.1.1.cmml" xref="Ch4.S1.SS2.p4.16.m13.1.1">𝑉</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.16.m13.1c">V</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.16.m13.1d">italic_V</annotation></semantics></math>, <math alttext="M" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.17.m14.1"><semantics id="Ch4.S1.SS2.p4.17.m14.1a"><mi id="Ch4.S1.SS2.p4.17.m14.1.1" xref="Ch4.S1.SS2.p4.17.m14.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.17.m14.1b"><ci id="Ch4.S1.SS2.p4.17.m14.1.1.cmml" xref="Ch4.S1.SS2.p4.17.m14.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.17.m14.1c">M</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.17.m14.1d">italic_M</annotation></semantics></math>, and <math alttext="K" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.18.m15.1"><semantics id="Ch4.S1.SS2.p4.18.m15.1a"><mi id="Ch4.S1.SS2.p4.18.m15.1.1" xref="Ch4.S1.SS2.p4.18.m15.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.18.m15.1b"><ci id="Ch4.S1.SS2.p4.18.m15.1.1.cmml" xref="Ch4.S1.SS2.p4.18.m15.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.18.m15.1c">K</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.18.m15.1d">italic_K</annotation></semantics></math>, respectively, and there are <math alttext="V\times M\times K" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.19.m16.1"><semantics id="Ch4.S1.SS2.p4.19.m16.1a"><mrow id="Ch4.S1.SS2.p4.19.m16.1.1" xref="Ch4.S1.SS2.p4.19.m16.1.1.cmml"><mi id="Ch4.S1.SS2.p4.19.m16.1.1.2" xref="Ch4.S1.SS2.p4.19.m16.1.1.2.cmml">V</mi><mo id="Ch4.S1.SS2.p4.19.m16.1.1.1" lspace="0.222em" rspace="0.222em" xref="Ch4.S1.SS2.p4.19.m16.1.1.1.cmml">×</mo><mi id="Ch4.S1.SS2.p4.19.m16.1.1.3" xref="Ch4.S1.SS2.p4.19.m16.1.1.3.cmml">M</mi><mo id="Ch4.S1.SS2.p4.19.m16.1.1.1a" lspace="0.222em" rspace="0.222em" xref="Ch4.S1.SS2.p4.19.m16.1.1.1.cmml">×</mo><mi id="Ch4.S1.SS2.p4.19.m16.1.1.4" xref="Ch4.S1.SS2.p4.19.m16.1.1.4.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.19.m16.1b"><apply id="Ch4.S1.SS2.p4.19.m16.1.1.cmml" xref="Ch4.S1.SS2.p4.19.m16.1.1"><times id="Ch4.S1.SS2.p4.19.m16.1.1.1.cmml" xref="Ch4.S1.SS2.p4.19.m16.1.1.1"></times><ci id="Ch4.S1.SS2.p4.19.m16.1.1.2.cmml" xref="Ch4.S1.SS2.p4.19.m16.1.1.2">𝑉</ci><ci id="Ch4.S1.SS2.p4.19.m16.1.1.3.cmml" xref="Ch4.S1.SS2.p4.19.m16.1.1.3">𝑀</ci><ci id="Ch4.S1.SS2.p4.19.m16.1.1.4.cmml" xref="Ch4.S1.SS2.p4.19.m16.1.1.4">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.19.m16.1c">V\times M\times K</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.19.m16.1d">italic_V × italic_M × italic_K</annotation></semantics></math> tuples in total.
To address sparseness and high-dimensionality problems, the authors designed an embedding layer to transform the input <math alttext="x_{t}" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.20.m17.1"><semantics id="Ch4.S1.SS2.p4.20.m17.1a"><msub id="Ch4.S1.SS2.p4.20.m17.1.1" xref="Ch4.S1.SS2.p4.20.m17.1.1.cmml"><mi id="Ch4.S1.SS2.p4.20.m17.1.1.2" xref="Ch4.S1.SS2.p4.20.m17.1.1.2.cmml">x</mi><mi id="Ch4.S1.SS2.p4.20.m17.1.1.3" xref="Ch4.S1.SS2.p4.20.m17.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.20.m17.1b"><apply id="Ch4.S1.SS2.p4.20.m17.1.1.cmml" xref="Ch4.S1.SS2.p4.20.m17.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.20.m17.1.1.1.cmml" xref="Ch4.S1.SS2.p4.20.m17.1.1">subscript</csymbol><ci id="Ch4.S1.SS2.p4.20.m17.1.1.2.cmml" xref="Ch4.S1.SS2.p4.20.m17.1.1.2">𝑥</ci><ci id="Ch4.S1.SS2.p4.20.m17.1.1.3.cmml" xref="Ch4.S1.SS2.p4.20.m17.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.20.m17.1c">x_{t}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.20.m17.1d">italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> into a low-dimensional dense vector <math alttext="e_{t}" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.21.m18.1"><semantics id="Ch4.S1.SS2.p4.21.m18.1a"><msub id="Ch4.S1.SS2.p4.21.m18.1.1" xref="Ch4.S1.SS2.p4.21.m18.1.1.cmml"><mi id="Ch4.S1.SS2.p4.21.m18.1.1.2" xref="Ch4.S1.SS2.p4.21.m18.1.1.2.cmml">e</mi><mi id="Ch4.S1.SS2.p4.21.m18.1.1.3" xref="Ch4.S1.SS2.p4.21.m18.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.21.m18.1b"><apply id="Ch4.S1.SS2.p4.21.m18.1.1.cmml" xref="Ch4.S1.SS2.p4.21.m18.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.21.m18.1.1.1.cmml" xref="Ch4.S1.SS2.p4.21.m18.1.1">subscript</csymbol><ci id="Ch4.S1.SS2.p4.21.m18.1.1.2.cmml" xref="Ch4.S1.SS2.p4.21.m18.1.1.2">𝑒</ci><ci id="Ch4.S1.SS2.p4.21.m18.1.1.3.cmml" xref="Ch4.S1.SS2.p4.21.m18.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.21.m18.1c">e_{t}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.21.m18.1d">italic_e start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>, which is formally defined as</p>
<table class="ltx_equation ltx_eqn_table" id="Ch4.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="e_{t}=\operatorname{concatenate}(W_{P}p_{v},W_{A}a_{m},W_{D}d_{k})," class="ltx_Math" display="block" id="Ch4.E6.m1.2"><semantics id="Ch4.E6.m1.2a"><mrow id="Ch4.E6.m1.2.2.1" xref="Ch4.E6.m1.2.2.1.1.cmml"><mrow id="Ch4.E6.m1.2.2.1.1" xref="Ch4.E6.m1.2.2.1.1.cmml"><msub id="Ch4.E6.m1.2.2.1.1.5" xref="Ch4.E6.m1.2.2.1.1.5.cmml"><mi id="Ch4.E6.m1.2.2.1.1.5.2" xref="Ch4.E6.m1.2.2.1.1.5.2.cmml">e</mi><mi id="Ch4.E6.m1.2.2.1.1.5.3" xref="Ch4.E6.m1.2.2.1.1.5.3.cmml">t</mi></msub><mo id="Ch4.E6.m1.2.2.1.1.4" xref="Ch4.E6.m1.2.2.1.1.4.cmml">=</mo><mrow id="Ch4.E6.m1.2.2.1.1.3.3" xref="Ch4.E6.m1.2.2.1.1.3.4.cmml"><mi id="Ch4.E6.m1.1.1" xref="Ch4.E6.m1.1.1.cmml">concatenate</mi><mo id="Ch4.E6.m1.2.2.1.1.3.3a" xref="Ch4.E6.m1.2.2.1.1.3.4.cmml">⁡</mo><mrow id="Ch4.E6.m1.2.2.1.1.3.3.3" xref="Ch4.E6.m1.2.2.1.1.3.4.cmml"><mo id="Ch4.E6.m1.2.2.1.1.3.3.3.4" stretchy="false" xref="Ch4.E6.m1.2.2.1.1.3.4.cmml">(</mo><mrow id="Ch4.E6.m1.2.2.1.1.1.1.1.1" xref="Ch4.E6.m1.2.2.1.1.1.1.1.1.cmml"><msub id="Ch4.E6.m1.2.2.1.1.1.1.1.1.2" xref="Ch4.E6.m1.2.2.1.1.1.1.1.1.2.cmml"><mi id="Ch4.E6.m1.2.2.1.1.1.1.1.1.2.2" xref="Ch4.E6.m1.2.2.1.1.1.1.1.1.2.2.cmml">W</mi><mi id="Ch4.E6.m1.2.2.1.1.1.1.1.1.2.3" xref="Ch4.E6.m1.2.2.1.1.1.1.1.1.2.3.cmml">P</mi></msub><mo id="Ch4.E6.m1.2.2.1.1.1.1.1.1.1" xref="Ch4.E6.m1.2.2.1.1.1.1.1.1.1.cmml">⁢</mo><msub id="Ch4.E6.m1.2.2.1.1.1.1.1.1.3" xref="Ch4.E6.m1.2.2.1.1.1.1.1.1.3.cmml"><mi id="Ch4.E6.m1.2.2.1.1.1.1.1.1.3.2" xref="Ch4.E6.m1.2.2.1.1.1.1.1.1.3.2.cmml">p</mi><mi id="Ch4.E6.m1.2.2.1.1.1.1.1.1.3.3" xref="Ch4.E6.m1.2.2.1.1.1.1.1.1.3.3.cmml">v</mi></msub></mrow><mo id="Ch4.E6.m1.2.2.1.1.3.3.3.5" xref="Ch4.E6.m1.2.2.1.1.3.4.cmml">,</mo><mrow id="Ch4.E6.m1.2.2.1.1.2.2.2.2" xref="Ch4.E6.m1.2.2.1.1.2.2.2.2.cmml"><msub id="Ch4.E6.m1.2.2.1.1.2.2.2.2.2" xref="Ch4.E6.m1.2.2.1.1.2.2.2.2.2.cmml"><mi id="Ch4.E6.m1.2.2.1.1.2.2.2.2.2.2" xref="Ch4.E6.m1.2.2.1.1.2.2.2.2.2.2.cmml">W</mi><mi id="Ch4.E6.m1.2.2.1.1.2.2.2.2.2.3" xref="Ch4.E6.m1.2.2.1.1.2.2.2.2.2.3.cmml">A</mi></msub><mo id="Ch4.E6.m1.2.2.1.1.2.2.2.2.1" xref="Ch4.E6.m1.2.2.1.1.2.2.2.2.1.cmml">⁢</mo><msub id="Ch4.E6.m1.2.2.1.1.2.2.2.2.3" xref="Ch4.E6.m1.2.2.1.1.2.2.2.2.3.cmml"><mi id="Ch4.E6.m1.2.2.1.1.2.2.2.2.3.2" xref="Ch4.E6.m1.2.2.1.1.2.2.2.2.3.2.cmml">a</mi><mi id="Ch4.E6.m1.2.2.1.1.2.2.2.2.3.3" xref="Ch4.E6.m1.2.2.1.1.2.2.2.2.3.3.cmml">m</mi></msub></mrow><mo id="Ch4.E6.m1.2.2.1.1.3.3.3.6" xref="Ch4.E6.m1.2.2.1.1.3.4.cmml">,</mo><mrow id="Ch4.E6.m1.2.2.1.1.3.3.3.3" xref="Ch4.E6.m1.2.2.1.1.3.3.3.3.cmml"><msub id="Ch4.E6.m1.2.2.1.1.3.3.3.3.2" xref="Ch4.E6.m1.2.2.1.1.3.3.3.3.2.cmml"><mi id="Ch4.E6.m1.2.2.1.1.3.3.3.3.2.2" xref="Ch4.E6.m1.2.2.1.1.3.3.3.3.2.2.cmml">W</mi><mi id="Ch4.E6.m1.2.2.1.1.3.3.3.3.2.3" xref="Ch4.E6.m1.2.2.1.1.3.3.3.3.2.3.cmml">D</mi></msub><mo id="Ch4.E6.m1.2.2.1.1.3.3.3.3.1" xref="Ch4.E6.m1.2.2.1.1.3.3.3.3.1.cmml">⁢</mo><msub id="Ch4.E6.m1.2.2.1.1.3.3.3.3.3" xref="Ch4.E6.m1.2.2.1.1.3.3.3.3.3.cmml"><mi id="Ch4.E6.m1.2.2.1.1.3.3.3.3.3.2" xref="Ch4.E6.m1.2.2.1.1.3.3.3.3.3.2.cmml">d</mi><mi id="Ch4.E6.m1.2.2.1.1.3.3.3.3.3.3" xref="Ch4.E6.m1.2.2.1.1.3.3.3.3.3.3.cmml">k</mi></msub></mrow><mo id="Ch4.E6.m1.2.2.1.1.3.3.3.7" stretchy="false" xref="Ch4.E6.m1.2.2.1.1.3.4.cmml">)</mo></mrow></mrow></mrow><mo id="Ch4.E6.m1.2.2.1.2" xref="Ch4.E6.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch4.E6.m1.2b"><apply id="Ch4.E6.m1.2.2.1.1.cmml" xref="Ch4.E6.m1.2.2.1"><eq id="Ch4.E6.m1.2.2.1.1.4.cmml" xref="Ch4.E6.m1.2.2.1.1.4"></eq><apply id="Ch4.E6.m1.2.2.1.1.5.cmml" xref="Ch4.E6.m1.2.2.1.1.5"><csymbol cd="ambiguous" id="Ch4.E6.m1.2.2.1.1.5.1.cmml" xref="Ch4.E6.m1.2.2.1.1.5">subscript</csymbol><ci id="Ch4.E6.m1.2.2.1.1.5.2.cmml" xref="Ch4.E6.m1.2.2.1.1.5.2">𝑒</ci><ci id="Ch4.E6.m1.2.2.1.1.5.3.cmml" xref="Ch4.E6.m1.2.2.1.1.5.3">𝑡</ci></apply><apply id="Ch4.E6.m1.2.2.1.1.3.4.cmml" xref="Ch4.E6.m1.2.2.1.1.3.3"><ci id="Ch4.E6.m1.1.1.cmml" xref="Ch4.E6.m1.1.1">concatenate</ci><apply id="Ch4.E6.m1.2.2.1.1.1.1.1.1.cmml" xref="Ch4.E6.m1.2.2.1.1.1.1.1.1"><times id="Ch4.E6.m1.2.2.1.1.1.1.1.1.1.cmml" xref="Ch4.E6.m1.2.2.1.1.1.1.1.1.1"></times><apply id="Ch4.E6.m1.2.2.1.1.1.1.1.1.2.cmml" xref="Ch4.E6.m1.2.2.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="Ch4.E6.m1.2.2.1.1.1.1.1.1.2.1.cmml" xref="Ch4.E6.m1.2.2.1.1.1.1.1.1.2">subscript</csymbol><ci id="Ch4.E6.m1.2.2.1.1.1.1.1.1.2.2.cmml" xref="Ch4.E6.m1.2.2.1.1.1.1.1.1.2.2">𝑊</ci><ci id="Ch4.E6.m1.2.2.1.1.1.1.1.1.2.3.cmml" xref="Ch4.E6.m1.2.2.1.1.1.1.1.1.2.3">𝑃</ci></apply><apply id="Ch4.E6.m1.2.2.1.1.1.1.1.1.3.cmml" xref="Ch4.E6.m1.2.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="Ch4.E6.m1.2.2.1.1.1.1.1.1.3.1.cmml" xref="Ch4.E6.m1.2.2.1.1.1.1.1.1.3">subscript</csymbol><ci id="Ch4.E6.m1.2.2.1.1.1.1.1.1.3.2.cmml" xref="Ch4.E6.m1.2.2.1.1.1.1.1.1.3.2">𝑝</ci><ci id="Ch4.E6.m1.2.2.1.1.1.1.1.1.3.3.cmml" xref="Ch4.E6.m1.2.2.1.1.1.1.1.1.3.3">𝑣</ci></apply></apply><apply id="Ch4.E6.m1.2.2.1.1.2.2.2.2.cmml" xref="Ch4.E6.m1.2.2.1.1.2.2.2.2"><times id="Ch4.E6.m1.2.2.1.1.2.2.2.2.1.cmml" xref="Ch4.E6.m1.2.2.1.1.2.2.2.2.1"></times><apply id="Ch4.E6.m1.2.2.1.1.2.2.2.2.2.cmml" xref="Ch4.E6.m1.2.2.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="Ch4.E6.m1.2.2.1.1.2.2.2.2.2.1.cmml" xref="Ch4.E6.m1.2.2.1.1.2.2.2.2.2">subscript</csymbol><ci id="Ch4.E6.m1.2.2.1.1.2.2.2.2.2.2.cmml" xref="Ch4.E6.m1.2.2.1.1.2.2.2.2.2.2">𝑊</ci><ci id="Ch4.E6.m1.2.2.1.1.2.2.2.2.2.3.cmml" xref="Ch4.E6.m1.2.2.1.1.2.2.2.2.2.3">𝐴</ci></apply><apply id="Ch4.E6.m1.2.2.1.1.2.2.2.2.3.cmml" xref="Ch4.E6.m1.2.2.1.1.2.2.2.2.3"><csymbol cd="ambiguous" id="Ch4.E6.m1.2.2.1.1.2.2.2.2.3.1.cmml" xref="Ch4.E6.m1.2.2.1.1.2.2.2.2.3">subscript</csymbol><ci id="Ch4.E6.m1.2.2.1.1.2.2.2.2.3.2.cmml" xref="Ch4.E6.m1.2.2.1.1.2.2.2.2.3.2">𝑎</ci><ci id="Ch4.E6.m1.2.2.1.1.2.2.2.2.3.3.cmml" xref="Ch4.E6.m1.2.2.1.1.2.2.2.2.3.3">𝑚</ci></apply></apply><apply id="Ch4.E6.m1.2.2.1.1.3.3.3.3.cmml" xref="Ch4.E6.m1.2.2.1.1.3.3.3.3"><times id="Ch4.E6.m1.2.2.1.1.3.3.3.3.1.cmml" xref="Ch4.E6.m1.2.2.1.1.3.3.3.3.1"></times><apply id="Ch4.E6.m1.2.2.1.1.3.3.3.3.2.cmml" xref="Ch4.E6.m1.2.2.1.1.3.3.3.3.2"><csymbol cd="ambiguous" id="Ch4.E6.m1.2.2.1.1.3.3.3.3.2.1.cmml" xref="Ch4.E6.m1.2.2.1.1.3.3.3.3.2">subscript</csymbol><ci id="Ch4.E6.m1.2.2.1.1.3.3.3.3.2.2.cmml" xref="Ch4.E6.m1.2.2.1.1.3.3.3.3.2.2">𝑊</ci><ci id="Ch4.E6.m1.2.2.1.1.3.3.3.3.2.3.cmml" xref="Ch4.E6.m1.2.2.1.1.3.3.3.3.2.3">𝐷</ci></apply><apply id="Ch4.E6.m1.2.2.1.1.3.3.3.3.3.cmml" xref="Ch4.E6.m1.2.2.1.1.3.3.3.3.3"><csymbol cd="ambiguous" id="Ch4.E6.m1.2.2.1.1.3.3.3.3.3.1.cmml" xref="Ch4.E6.m1.2.2.1.1.3.3.3.3.3">subscript</csymbol><ci id="Ch4.E6.m1.2.2.1.1.3.3.3.3.3.2.cmml" xref="Ch4.E6.m1.2.2.1.1.3.3.3.3.3.2">𝑑</ci><ci id="Ch4.E6.m1.2.2.1.1.3.3.3.3.3.3.cmml" xref="Ch4.E6.m1.2.2.1.1.3.3.3.3.3.3">𝑘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.E6.m1.2c">e_{t}=\operatorname{concatenate}(W_{P}p_{v},W_{A}a_{m},W_{D}d_{k}),</annotation><annotation encoding="application/x-llamapun" id="Ch4.E6.m1.2d">italic_e start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = roman_concatenate ( italic_W start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT italic_p start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT , italic_W start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT italic_a start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT , italic_W start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT italic_d start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4.6)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch4.S1.SS2.p4.33">where <math alttext="W_{P}\in R^{d_{P}\times V}" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.22.m1.1"><semantics id="Ch4.S1.SS2.p4.22.m1.1a"><mrow id="Ch4.S1.SS2.p4.22.m1.1.1" xref="Ch4.S1.SS2.p4.22.m1.1.1.cmml"><msub id="Ch4.S1.SS2.p4.22.m1.1.1.2" xref="Ch4.S1.SS2.p4.22.m1.1.1.2.cmml"><mi id="Ch4.S1.SS2.p4.22.m1.1.1.2.2" xref="Ch4.S1.SS2.p4.22.m1.1.1.2.2.cmml">W</mi><mi id="Ch4.S1.SS2.p4.22.m1.1.1.2.3" xref="Ch4.S1.SS2.p4.22.m1.1.1.2.3.cmml">P</mi></msub><mo id="Ch4.S1.SS2.p4.22.m1.1.1.1" xref="Ch4.S1.SS2.p4.22.m1.1.1.1.cmml">∈</mo><msup id="Ch4.S1.SS2.p4.22.m1.1.1.3" xref="Ch4.S1.SS2.p4.22.m1.1.1.3.cmml"><mi id="Ch4.S1.SS2.p4.22.m1.1.1.3.2" xref="Ch4.S1.SS2.p4.22.m1.1.1.3.2.cmml">R</mi><mrow id="Ch4.S1.SS2.p4.22.m1.1.1.3.3" xref="Ch4.S1.SS2.p4.22.m1.1.1.3.3.cmml"><msub id="Ch4.S1.SS2.p4.22.m1.1.1.3.3.2" xref="Ch4.S1.SS2.p4.22.m1.1.1.3.3.2.cmml"><mi id="Ch4.S1.SS2.p4.22.m1.1.1.3.3.2.2" xref="Ch4.S1.SS2.p4.22.m1.1.1.3.3.2.2.cmml">d</mi><mi id="Ch4.S1.SS2.p4.22.m1.1.1.3.3.2.3" xref="Ch4.S1.SS2.p4.22.m1.1.1.3.3.2.3.cmml">P</mi></msub><mo id="Ch4.S1.SS2.p4.22.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="Ch4.S1.SS2.p4.22.m1.1.1.3.3.1.cmml">×</mo><mi id="Ch4.S1.SS2.p4.22.m1.1.1.3.3.3" xref="Ch4.S1.SS2.p4.22.m1.1.1.3.3.3.cmml">V</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.22.m1.1b"><apply id="Ch4.S1.SS2.p4.22.m1.1.1.cmml" xref="Ch4.S1.SS2.p4.22.m1.1.1"><in id="Ch4.S1.SS2.p4.22.m1.1.1.1.cmml" xref="Ch4.S1.SS2.p4.22.m1.1.1.1"></in><apply id="Ch4.S1.SS2.p4.22.m1.1.1.2.cmml" xref="Ch4.S1.SS2.p4.22.m1.1.1.2"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.22.m1.1.1.2.1.cmml" xref="Ch4.S1.SS2.p4.22.m1.1.1.2">subscript</csymbol><ci id="Ch4.S1.SS2.p4.22.m1.1.1.2.2.cmml" xref="Ch4.S1.SS2.p4.22.m1.1.1.2.2">𝑊</ci><ci id="Ch4.S1.SS2.p4.22.m1.1.1.2.3.cmml" xref="Ch4.S1.SS2.p4.22.m1.1.1.2.3">𝑃</ci></apply><apply id="Ch4.S1.SS2.p4.22.m1.1.1.3.cmml" xref="Ch4.S1.SS2.p4.22.m1.1.1.3"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.22.m1.1.1.3.1.cmml" xref="Ch4.S1.SS2.p4.22.m1.1.1.3">superscript</csymbol><ci id="Ch4.S1.SS2.p4.22.m1.1.1.3.2.cmml" xref="Ch4.S1.SS2.p4.22.m1.1.1.3.2">𝑅</ci><apply id="Ch4.S1.SS2.p4.22.m1.1.1.3.3.cmml" xref="Ch4.S1.SS2.p4.22.m1.1.1.3.3"><times id="Ch4.S1.SS2.p4.22.m1.1.1.3.3.1.cmml" xref="Ch4.S1.SS2.p4.22.m1.1.1.3.3.1"></times><apply id="Ch4.S1.SS2.p4.22.m1.1.1.3.3.2.cmml" xref="Ch4.S1.SS2.p4.22.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.22.m1.1.1.3.3.2.1.cmml" xref="Ch4.S1.SS2.p4.22.m1.1.1.3.3.2">subscript</csymbol><ci id="Ch4.S1.SS2.p4.22.m1.1.1.3.3.2.2.cmml" xref="Ch4.S1.SS2.p4.22.m1.1.1.3.3.2.2">𝑑</ci><ci id="Ch4.S1.SS2.p4.22.m1.1.1.3.3.2.3.cmml" xref="Ch4.S1.SS2.p4.22.m1.1.1.3.3.2.3">𝑃</ci></apply><ci id="Ch4.S1.SS2.p4.22.m1.1.1.3.3.3.cmml" xref="Ch4.S1.SS2.p4.22.m1.1.1.3.3.3">𝑉</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.22.m1.1c">W_{P}\in R^{d_{P}\times V}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.22.m1.1d">italic_W start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ∈ italic_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT × italic_V end_POSTSUPERSCRIPT</annotation></semantics></math>, <math alttext="W_{A}\in R^{d_{A}\times M}" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.23.m2.1"><semantics id="Ch4.S1.SS2.p4.23.m2.1a"><mrow id="Ch4.S1.SS2.p4.23.m2.1.1" xref="Ch4.S1.SS2.p4.23.m2.1.1.cmml"><msub id="Ch4.S1.SS2.p4.23.m2.1.1.2" xref="Ch4.S1.SS2.p4.23.m2.1.1.2.cmml"><mi id="Ch4.S1.SS2.p4.23.m2.1.1.2.2" xref="Ch4.S1.SS2.p4.23.m2.1.1.2.2.cmml">W</mi><mi id="Ch4.S1.SS2.p4.23.m2.1.1.2.3" xref="Ch4.S1.SS2.p4.23.m2.1.1.2.3.cmml">A</mi></msub><mo id="Ch4.S1.SS2.p4.23.m2.1.1.1" xref="Ch4.S1.SS2.p4.23.m2.1.1.1.cmml">∈</mo><msup id="Ch4.S1.SS2.p4.23.m2.1.1.3" xref="Ch4.S1.SS2.p4.23.m2.1.1.3.cmml"><mi id="Ch4.S1.SS2.p4.23.m2.1.1.3.2" xref="Ch4.S1.SS2.p4.23.m2.1.1.3.2.cmml">R</mi><mrow id="Ch4.S1.SS2.p4.23.m2.1.1.3.3" xref="Ch4.S1.SS2.p4.23.m2.1.1.3.3.cmml"><msub id="Ch4.S1.SS2.p4.23.m2.1.1.3.3.2" xref="Ch4.S1.SS2.p4.23.m2.1.1.3.3.2.cmml"><mi id="Ch4.S1.SS2.p4.23.m2.1.1.3.3.2.2" xref="Ch4.S1.SS2.p4.23.m2.1.1.3.3.2.2.cmml">d</mi><mi id="Ch4.S1.SS2.p4.23.m2.1.1.3.3.2.3" xref="Ch4.S1.SS2.p4.23.m2.1.1.3.3.2.3.cmml">A</mi></msub><mo id="Ch4.S1.SS2.p4.23.m2.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="Ch4.S1.SS2.p4.23.m2.1.1.3.3.1.cmml">×</mo><mi id="Ch4.S1.SS2.p4.23.m2.1.1.3.3.3" xref="Ch4.S1.SS2.p4.23.m2.1.1.3.3.3.cmml">M</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.23.m2.1b"><apply id="Ch4.S1.SS2.p4.23.m2.1.1.cmml" xref="Ch4.S1.SS2.p4.23.m2.1.1"><in id="Ch4.S1.SS2.p4.23.m2.1.1.1.cmml" xref="Ch4.S1.SS2.p4.23.m2.1.1.1"></in><apply id="Ch4.S1.SS2.p4.23.m2.1.1.2.cmml" xref="Ch4.S1.SS2.p4.23.m2.1.1.2"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.23.m2.1.1.2.1.cmml" xref="Ch4.S1.SS2.p4.23.m2.1.1.2">subscript</csymbol><ci id="Ch4.S1.SS2.p4.23.m2.1.1.2.2.cmml" xref="Ch4.S1.SS2.p4.23.m2.1.1.2.2">𝑊</ci><ci id="Ch4.S1.SS2.p4.23.m2.1.1.2.3.cmml" xref="Ch4.S1.SS2.p4.23.m2.1.1.2.3">𝐴</ci></apply><apply id="Ch4.S1.SS2.p4.23.m2.1.1.3.cmml" xref="Ch4.S1.SS2.p4.23.m2.1.1.3"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.23.m2.1.1.3.1.cmml" xref="Ch4.S1.SS2.p4.23.m2.1.1.3">superscript</csymbol><ci id="Ch4.S1.SS2.p4.23.m2.1.1.3.2.cmml" xref="Ch4.S1.SS2.p4.23.m2.1.1.3.2">𝑅</ci><apply id="Ch4.S1.SS2.p4.23.m2.1.1.3.3.cmml" xref="Ch4.S1.SS2.p4.23.m2.1.1.3.3"><times id="Ch4.S1.SS2.p4.23.m2.1.1.3.3.1.cmml" xref="Ch4.S1.SS2.p4.23.m2.1.1.3.3.1"></times><apply id="Ch4.S1.SS2.p4.23.m2.1.1.3.3.2.cmml" xref="Ch4.S1.SS2.p4.23.m2.1.1.3.3.2"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.23.m2.1.1.3.3.2.1.cmml" xref="Ch4.S1.SS2.p4.23.m2.1.1.3.3.2">subscript</csymbol><ci id="Ch4.S1.SS2.p4.23.m2.1.1.3.3.2.2.cmml" xref="Ch4.S1.SS2.p4.23.m2.1.1.3.3.2.2">𝑑</ci><ci id="Ch4.S1.SS2.p4.23.m2.1.1.3.3.2.3.cmml" xref="Ch4.S1.SS2.p4.23.m2.1.1.3.3.2.3">𝐴</ci></apply><ci id="Ch4.S1.SS2.p4.23.m2.1.1.3.3.3.cmml" xref="Ch4.S1.SS2.p4.23.m2.1.1.3.3.3">𝑀</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.23.m2.1c">W_{A}\in R^{d_{A}\times M}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.23.m2.1d">italic_W start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ∈ italic_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT × italic_M end_POSTSUPERSCRIPT</annotation></semantics></math>, and <math alttext="W_{D}\in R^{d_{D}\times K}" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.24.m3.1"><semantics id="Ch4.S1.SS2.p4.24.m3.1a"><mrow id="Ch4.S1.SS2.p4.24.m3.1.1" xref="Ch4.S1.SS2.p4.24.m3.1.1.cmml"><msub id="Ch4.S1.SS2.p4.24.m3.1.1.2" xref="Ch4.S1.SS2.p4.24.m3.1.1.2.cmml"><mi id="Ch4.S1.SS2.p4.24.m3.1.1.2.2" xref="Ch4.S1.SS2.p4.24.m3.1.1.2.2.cmml">W</mi><mi id="Ch4.S1.SS2.p4.24.m3.1.1.2.3" xref="Ch4.S1.SS2.p4.24.m3.1.1.2.3.cmml">D</mi></msub><mo id="Ch4.S1.SS2.p4.24.m3.1.1.1" xref="Ch4.S1.SS2.p4.24.m3.1.1.1.cmml">∈</mo><msup id="Ch4.S1.SS2.p4.24.m3.1.1.3" xref="Ch4.S1.SS2.p4.24.m3.1.1.3.cmml"><mi id="Ch4.S1.SS2.p4.24.m3.1.1.3.2" xref="Ch4.S1.SS2.p4.24.m3.1.1.3.2.cmml">R</mi><mrow id="Ch4.S1.SS2.p4.24.m3.1.1.3.3" xref="Ch4.S1.SS2.p4.24.m3.1.1.3.3.cmml"><msub id="Ch4.S1.SS2.p4.24.m3.1.1.3.3.2" xref="Ch4.S1.SS2.p4.24.m3.1.1.3.3.2.cmml"><mi id="Ch4.S1.SS2.p4.24.m3.1.1.3.3.2.2" xref="Ch4.S1.SS2.p4.24.m3.1.1.3.3.2.2.cmml">d</mi><mi id="Ch4.S1.SS2.p4.24.m3.1.1.3.3.2.3" xref="Ch4.S1.SS2.p4.24.m3.1.1.3.3.2.3.cmml">D</mi></msub><mo id="Ch4.S1.SS2.p4.24.m3.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="Ch4.S1.SS2.p4.24.m3.1.1.3.3.1.cmml">×</mo><mi id="Ch4.S1.SS2.p4.24.m3.1.1.3.3.3" xref="Ch4.S1.SS2.p4.24.m3.1.1.3.3.3.cmml">K</mi></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.24.m3.1b"><apply id="Ch4.S1.SS2.p4.24.m3.1.1.cmml" xref="Ch4.S1.SS2.p4.24.m3.1.1"><in id="Ch4.S1.SS2.p4.24.m3.1.1.1.cmml" xref="Ch4.S1.SS2.p4.24.m3.1.1.1"></in><apply id="Ch4.S1.SS2.p4.24.m3.1.1.2.cmml" xref="Ch4.S1.SS2.p4.24.m3.1.1.2"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.24.m3.1.1.2.1.cmml" xref="Ch4.S1.SS2.p4.24.m3.1.1.2">subscript</csymbol><ci id="Ch4.S1.SS2.p4.24.m3.1.1.2.2.cmml" xref="Ch4.S1.SS2.p4.24.m3.1.1.2.2">𝑊</ci><ci id="Ch4.S1.SS2.p4.24.m3.1.1.2.3.cmml" xref="Ch4.S1.SS2.p4.24.m3.1.1.2.3">𝐷</ci></apply><apply id="Ch4.S1.SS2.p4.24.m3.1.1.3.cmml" xref="Ch4.S1.SS2.p4.24.m3.1.1.3"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.24.m3.1.1.3.1.cmml" xref="Ch4.S1.SS2.p4.24.m3.1.1.3">superscript</csymbol><ci id="Ch4.S1.SS2.p4.24.m3.1.1.3.2.cmml" xref="Ch4.S1.SS2.p4.24.m3.1.1.3.2">𝑅</ci><apply id="Ch4.S1.SS2.p4.24.m3.1.1.3.3.cmml" xref="Ch4.S1.SS2.p4.24.m3.1.1.3.3"><times id="Ch4.S1.SS2.p4.24.m3.1.1.3.3.1.cmml" xref="Ch4.S1.SS2.p4.24.m3.1.1.3.3.1"></times><apply id="Ch4.S1.SS2.p4.24.m3.1.1.3.3.2.cmml" xref="Ch4.S1.SS2.p4.24.m3.1.1.3.3.2"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.24.m3.1.1.3.3.2.1.cmml" xref="Ch4.S1.SS2.p4.24.m3.1.1.3.3.2">subscript</csymbol><ci id="Ch4.S1.SS2.p4.24.m3.1.1.3.3.2.2.cmml" xref="Ch4.S1.SS2.p4.24.m3.1.1.3.3.2.2">𝑑</ci><ci id="Ch4.S1.SS2.p4.24.m3.1.1.3.3.2.3.cmml" xref="Ch4.S1.SS2.p4.24.m3.1.1.3.3.2.3">𝐷</ci></apply><ci id="Ch4.S1.SS2.p4.24.m3.1.1.3.3.3.cmml" xref="Ch4.S1.SS2.p4.24.m3.1.1.3.3.3">𝐾</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.24.m3.1c">W_{D}\in R^{d_{D}\times K}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.24.m3.1d">italic_W start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ∈ italic_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT × italic_K end_POSTSUPERSCRIPT</annotation></semantics></math>, where <math alttext="d_{P}\ll N" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.25.m4.1"><semantics id="Ch4.S1.SS2.p4.25.m4.1a"><mrow id="Ch4.S1.SS2.p4.25.m4.1.1" xref="Ch4.S1.SS2.p4.25.m4.1.1.cmml"><msub id="Ch4.S1.SS2.p4.25.m4.1.1.2" xref="Ch4.S1.SS2.p4.25.m4.1.1.2.cmml"><mi id="Ch4.S1.SS2.p4.25.m4.1.1.2.2" xref="Ch4.S1.SS2.p4.25.m4.1.1.2.2.cmml">d</mi><mi id="Ch4.S1.SS2.p4.25.m4.1.1.2.3" xref="Ch4.S1.SS2.p4.25.m4.1.1.2.3.cmml">P</mi></msub><mo id="Ch4.S1.SS2.p4.25.m4.1.1.1" xref="Ch4.S1.SS2.p4.25.m4.1.1.1.cmml">≪</mo><mi id="Ch4.S1.SS2.p4.25.m4.1.1.3" xref="Ch4.S1.SS2.p4.25.m4.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.25.m4.1b"><apply id="Ch4.S1.SS2.p4.25.m4.1.1.cmml" xref="Ch4.S1.SS2.p4.25.m4.1.1"><csymbol cd="latexml" id="Ch4.S1.SS2.p4.25.m4.1.1.1.cmml" xref="Ch4.S1.SS2.p4.25.m4.1.1.1">much-less-than</csymbol><apply id="Ch4.S1.SS2.p4.25.m4.1.1.2.cmml" xref="Ch4.S1.SS2.p4.25.m4.1.1.2"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.25.m4.1.1.2.1.cmml" xref="Ch4.S1.SS2.p4.25.m4.1.1.2">subscript</csymbol><ci id="Ch4.S1.SS2.p4.25.m4.1.1.2.2.cmml" xref="Ch4.S1.SS2.p4.25.m4.1.1.2.2">𝑑</ci><ci id="Ch4.S1.SS2.p4.25.m4.1.1.2.3.cmml" xref="Ch4.S1.SS2.p4.25.m4.1.1.2.3">𝑃</ci></apply><ci id="Ch4.S1.SS2.p4.25.m4.1.1.3.cmml" xref="Ch4.S1.SS2.p4.25.m4.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.25.m4.1c">d_{P}\ll N</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.25.m4.1d">italic_d start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT ≪ italic_N</annotation></semantics></math>, <math alttext="d_{A}\ll M" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.26.m5.1"><semantics id="Ch4.S1.SS2.p4.26.m5.1a"><mrow id="Ch4.S1.SS2.p4.26.m5.1.1" xref="Ch4.S1.SS2.p4.26.m5.1.1.cmml"><msub id="Ch4.S1.SS2.p4.26.m5.1.1.2" xref="Ch4.S1.SS2.p4.26.m5.1.1.2.cmml"><mi id="Ch4.S1.SS2.p4.26.m5.1.1.2.2" xref="Ch4.S1.SS2.p4.26.m5.1.1.2.2.cmml">d</mi><mi id="Ch4.S1.SS2.p4.26.m5.1.1.2.3" xref="Ch4.S1.SS2.p4.26.m5.1.1.2.3.cmml">A</mi></msub><mo id="Ch4.S1.SS2.p4.26.m5.1.1.1" xref="Ch4.S1.SS2.p4.26.m5.1.1.1.cmml">≪</mo><mi id="Ch4.S1.SS2.p4.26.m5.1.1.3" xref="Ch4.S1.SS2.p4.26.m5.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.26.m5.1b"><apply id="Ch4.S1.SS2.p4.26.m5.1.1.cmml" xref="Ch4.S1.SS2.p4.26.m5.1.1"><csymbol cd="latexml" id="Ch4.S1.SS2.p4.26.m5.1.1.1.cmml" xref="Ch4.S1.SS2.p4.26.m5.1.1.1">much-less-than</csymbol><apply id="Ch4.S1.SS2.p4.26.m5.1.1.2.cmml" xref="Ch4.S1.SS2.p4.26.m5.1.1.2"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.26.m5.1.1.2.1.cmml" xref="Ch4.S1.SS2.p4.26.m5.1.1.2">subscript</csymbol><ci id="Ch4.S1.SS2.p4.26.m5.1.1.2.2.cmml" xref="Ch4.S1.SS2.p4.26.m5.1.1.2.2">𝑑</ci><ci id="Ch4.S1.SS2.p4.26.m5.1.1.2.3.cmml" xref="Ch4.S1.SS2.p4.26.m5.1.1.2.3">𝐴</ci></apply><ci id="Ch4.S1.SS2.p4.26.m5.1.1.3.cmml" xref="Ch4.S1.SS2.p4.26.m5.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.26.m5.1c">d_{A}\ll M</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.26.m5.1d">italic_d start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT ≪ italic_M</annotation></semantics></math>, and <math alttext="d_{D}\ll K" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.27.m6.1"><semantics id="Ch4.S1.SS2.p4.27.m6.1a"><mrow id="Ch4.S1.SS2.p4.27.m6.1.1" xref="Ch4.S1.SS2.p4.27.m6.1.1.cmml"><msub id="Ch4.S1.SS2.p4.27.m6.1.1.2" xref="Ch4.S1.SS2.p4.27.m6.1.1.2.cmml"><mi id="Ch4.S1.SS2.p4.27.m6.1.1.2.2" xref="Ch4.S1.SS2.p4.27.m6.1.1.2.2.cmml">d</mi><mi id="Ch4.S1.SS2.p4.27.m6.1.1.2.3" xref="Ch4.S1.SS2.p4.27.m6.1.1.2.3.cmml">D</mi></msub><mo id="Ch4.S1.SS2.p4.27.m6.1.1.1" xref="Ch4.S1.SS2.p4.27.m6.1.1.1.cmml">≪</mo><mi id="Ch4.S1.SS2.p4.27.m6.1.1.3" xref="Ch4.S1.SS2.p4.27.m6.1.1.3.cmml">K</mi></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.27.m6.1b"><apply id="Ch4.S1.SS2.p4.27.m6.1.1.cmml" xref="Ch4.S1.SS2.p4.27.m6.1.1"><csymbol cd="latexml" id="Ch4.S1.SS2.p4.27.m6.1.1.1.cmml" xref="Ch4.S1.SS2.p4.27.m6.1.1.1">much-less-than</csymbol><apply id="Ch4.S1.SS2.p4.27.m6.1.1.2.cmml" xref="Ch4.S1.SS2.p4.27.m6.1.1.2"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.27.m6.1.1.2.1.cmml" xref="Ch4.S1.SS2.p4.27.m6.1.1.2">subscript</csymbol><ci id="Ch4.S1.SS2.p4.27.m6.1.1.2.2.cmml" xref="Ch4.S1.SS2.p4.27.m6.1.1.2.2">𝑑</ci><ci id="Ch4.S1.SS2.p4.27.m6.1.1.2.3.cmml" xref="Ch4.S1.SS2.p4.27.m6.1.1.2.3">𝐷</ci></apply><ci id="Ch4.S1.SS2.p4.27.m6.1.1.3.cmml" xref="Ch4.S1.SS2.p4.27.m6.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.27.m6.1c">d_{D}\ll K</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.27.m6.1d">italic_d start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT ≪ italic_K</annotation></semantics></math> are the number of latent dimensions for products, activities, and dwell time, respectively.
The initial weights of <math alttext="W_{P}" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.28.m7.1"><semantics id="Ch4.S1.SS2.p4.28.m7.1a"><msub id="Ch4.S1.SS2.p4.28.m7.1.1" xref="Ch4.S1.SS2.p4.28.m7.1.1.cmml"><mi id="Ch4.S1.SS2.p4.28.m7.1.1.2" xref="Ch4.S1.SS2.p4.28.m7.1.1.2.cmml">W</mi><mi id="Ch4.S1.SS2.p4.28.m7.1.1.3" xref="Ch4.S1.SS2.p4.28.m7.1.1.3.cmml">P</mi></msub><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.28.m7.1b"><apply id="Ch4.S1.SS2.p4.28.m7.1.1.cmml" xref="Ch4.S1.SS2.p4.28.m7.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.28.m7.1.1.1.cmml" xref="Ch4.S1.SS2.p4.28.m7.1.1">subscript</csymbol><ci id="Ch4.S1.SS2.p4.28.m7.1.1.2.cmml" xref="Ch4.S1.SS2.p4.28.m7.1.1.2">𝑊</ci><ci id="Ch4.S1.SS2.p4.28.m7.1.1.3.cmml" xref="Ch4.S1.SS2.p4.28.m7.1.1.3">𝑃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.28.m7.1c">W_{P}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.28.m7.1d">italic_W start_POSTSUBSCRIPT italic_P end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="W_{A}" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.29.m8.1"><semantics id="Ch4.S1.SS2.p4.29.m8.1a"><msub id="Ch4.S1.SS2.p4.29.m8.1.1" xref="Ch4.S1.SS2.p4.29.m8.1.1.cmml"><mi id="Ch4.S1.SS2.p4.29.m8.1.1.2" xref="Ch4.S1.SS2.p4.29.m8.1.1.2.cmml">W</mi><mi id="Ch4.S1.SS2.p4.29.m8.1.1.3" xref="Ch4.S1.SS2.p4.29.m8.1.1.3.cmml">A</mi></msub><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.29.m8.1b"><apply id="Ch4.S1.SS2.p4.29.m8.1.1.cmml" xref="Ch4.S1.SS2.p4.29.m8.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.29.m8.1.1.1.cmml" xref="Ch4.S1.SS2.p4.29.m8.1.1">subscript</csymbol><ci id="Ch4.S1.SS2.p4.29.m8.1.1.2.cmml" xref="Ch4.S1.SS2.p4.29.m8.1.1.2">𝑊</ci><ci id="Ch4.S1.SS2.p4.29.m8.1.1.3.cmml" xref="Ch4.S1.SS2.p4.29.m8.1.1.3">𝐴</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.29.m8.1c">W_{A}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.29.m8.1d">italic_W start_POSTSUBSCRIPT italic_A end_POSTSUBSCRIPT</annotation></semantics></math>, and <math alttext="W_{D}" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.30.m9.1"><semantics id="Ch4.S1.SS2.p4.30.m9.1a"><msub id="Ch4.S1.SS2.p4.30.m9.1.1" xref="Ch4.S1.SS2.p4.30.m9.1.1.cmml"><mi id="Ch4.S1.SS2.p4.30.m9.1.1.2" xref="Ch4.S1.SS2.p4.30.m9.1.1.2.cmml">W</mi><mi id="Ch4.S1.SS2.p4.30.m9.1.1.3" xref="Ch4.S1.SS2.p4.30.m9.1.1.3.cmml">D</mi></msub><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.30.m9.1b"><apply id="Ch4.S1.SS2.p4.30.m9.1.1.cmml" xref="Ch4.S1.SS2.p4.30.m9.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.30.m9.1.1.1.cmml" xref="Ch4.S1.SS2.p4.30.m9.1.1">subscript</csymbol><ci id="Ch4.S1.SS2.p4.30.m9.1.1.2.cmml" xref="Ch4.S1.SS2.p4.30.m9.1.1.2">𝑊</ci><ci id="Ch4.S1.SS2.p4.30.m9.1.1.3.cmml" xref="Ch4.S1.SS2.p4.30.m9.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.30.m9.1c">W_{D}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.30.m9.1d">italic_W start_POSTSUBSCRIPT italic_D end_POSTSUBSCRIPT</annotation></semantics></math> are trained by applying word2vec <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mikolov2013efficient</span>]</cite>. Additionally, the final embedding of <math alttext="x_{t}" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.31.m10.1"><semantics id="Ch4.S1.SS2.p4.31.m10.1a"><msub id="Ch4.S1.SS2.p4.31.m10.1.1" xref="Ch4.S1.SS2.p4.31.m10.1.1.cmml"><mi id="Ch4.S1.SS2.p4.31.m10.1.1.2" xref="Ch4.S1.SS2.p4.31.m10.1.1.2.cmml">x</mi><mi id="Ch4.S1.SS2.p4.31.m10.1.1.3" xref="Ch4.S1.SS2.p4.31.m10.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.31.m10.1b"><apply id="Ch4.S1.SS2.p4.31.m10.1.1.cmml" xref="Ch4.S1.SS2.p4.31.m10.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.31.m10.1.1.1.cmml" xref="Ch4.S1.SS2.p4.31.m10.1.1">subscript</csymbol><ci id="Ch4.S1.SS2.p4.31.m10.1.1.2.cmml" xref="Ch4.S1.SS2.p4.31.m10.1.1.2">𝑥</ci><ci id="Ch4.S1.SS2.p4.31.m10.1.1.3.cmml" xref="Ch4.S1.SS2.p4.31.m10.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.31.m10.1c">x_{t}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.31.m10.1d">italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> is the concatenation of three embeddings. To capture the sequential information of micro-behavior, the authors built an RNN layer. The output of the embedding layer <math alttext="e_{t}" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.32.m11.1"><semantics id="Ch4.S1.SS2.p4.32.m11.1a"><msub id="Ch4.S1.SS2.p4.32.m11.1.1" xref="Ch4.S1.SS2.p4.32.m11.1.1.cmml"><mi id="Ch4.S1.SS2.p4.32.m11.1.1.2" xref="Ch4.S1.SS2.p4.32.m11.1.1.2.cmml">e</mi><mi id="Ch4.S1.SS2.p4.32.m11.1.1.3" xref="Ch4.S1.SS2.p4.32.m11.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.32.m11.1b"><apply id="Ch4.S1.SS2.p4.32.m11.1.1.cmml" xref="Ch4.S1.SS2.p4.32.m11.1.1"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.32.m11.1.1.1.cmml" xref="Ch4.S1.SS2.p4.32.m11.1.1">subscript</csymbol><ci id="Ch4.S1.SS2.p4.32.m11.1.1.2.cmml" xref="Ch4.S1.SS2.p4.32.m11.1.1.2">𝑒</ci><ci id="Ch4.S1.SS2.p4.32.m11.1.1.3.cmml" xref="Ch4.S1.SS2.p4.32.m11.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.32.m11.1c">e_{t}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.32.m11.1d">italic_e start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> is the input of the RNN layer. The <math alttext="t" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.33.m12.1"><semantics id="Ch4.S1.SS2.p4.33.m12.1a"><mi id="Ch4.S1.SS2.p4.33.m12.1.1" xref="Ch4.S1.SS2.p4.33.m12.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.33.m12.1b"><ci id="Ch4.S1.SS2.p4.33.m12.1.1.cmml" xref="Ch4.S1.SS2.p4.33.m12.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.33.m12.1c">t</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.33.m12.1d">italic_t</annotation></semantics></math>-th hidden state unit output is calculated as</p>
<table class="ltx_equation ltx_eqn_table" id="Ch4.E7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="h_{t}=\sigma(W_{eh}e_{t}+W_{hh}h_{t-1}+b_{t})," class="ltx_Math" display="block" id="Ch4.E7.m1.1"><semantics id="Ch4.E7.m1.1a"><mrow id="Ch4.E7.m1.1.1.1" xref="Ch4.E7.m1.1.1.1.1.cmml"><mrow id="Ch4.E7.m1.1.1.1.1" xref="Ch4.E7.m1.1.1.1.1.cmml"><msub id="Ch4.E7.m1.1.1.1.1.3" xref="Ch4.E7.m1.1.1.1.1.3.cmml"><mi id="Ch4.E7.m1.1.1.1.1.3.2" xref="Ch4.E7.m1.1.1.1.1.3.2.cmml">h</mi><mi id="Ch4.E7.m1.1.1.1.1.3.3" xref="Ch4.E7.m1.1.1.1.1.3.3.cmml">t</mi></msub><mo id="Ch4.E7.m1.1.1.1.1.2" xref="Ch4.E7.m1.1.1.1.1.2.cmml">=</mo><mrow id="Ch4.E7.m1.1.1.1.1.1" xref="Ch4.E7.m1.1.1.1.1.1.cmml"><mi id="Ch4.E7.m1.1.1.1.1.1.3" xref="Ch4.E7.m1.1.1.1.1.1.3.cmml">σ</mi><mo id="Ch4.E7.m1.1.1.1.1.1.2" xref="Ch4.E7.m1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="Ch4.E7.m1.1.1.1.1.1.1.1" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.cmml"><mo id="Ch4.E7.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="Ch4.E7.m1.1.1.1.1.1.1.1.1" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.cmml"><mrow id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.cmml"><msub id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.cmml"><mi id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.2" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.2.cmml">W</mi><mrow id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.3" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.3.cmml"><mi id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.3.2" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.3.2.cmml">e</mi><mo id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.3.1" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.3.1.cmml">⁢</mo><mi id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.3.3" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.3.3.cmml">h</mi></mrow></msub><mo id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.1" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.1.cmml">⁢</mo><msub id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.3" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.3.cmml"><mi id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.3.2" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.3.2.cmml">e</mi><mi id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.3.3" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.3.3.cmml">t</mi></msub></mrow><mo id="Ch4.E7.m1.1.1.1.1.1.1.1.1.1" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mrow id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.cmml"><msub id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.cmml"><mi id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.2" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.2.cmml">W</mi><mrow id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.3" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.3.cmml"><mi id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.3.2" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.3.2.cmml">h</mi><mo id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.3.1" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.3.1.cmml">⁢</mo><mi id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.3.3" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.3.3.cmml">h</mi></mrow></msub><mo id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.1" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><msub id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.cmml"><mi id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.2" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.2.cmml">h</mi><mrow id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.3" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.3.cmml"><mi id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.3.2" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.3.2.cmml">t</mi><mo id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.3.1" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.3.1.cmml">−</mo><mn id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.3.3" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.3.3.cmml">1</mn></mrow></msub></mrow><mo id="Ch4.E7.m1.1.1.1.1.1.1.1.1.1a" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.1.cmml">+</mo><msub id="Ch4.E7.m1.1.1.1.1.1.1.1.1.4" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.4.cmml"><mi id="Ch4.E7.m1.1.1.1.1.1.1.1.1.4.2" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.4.2.cmml">b</mi><mi id="Ch4.E7.m1.1.1.1.1.1.1.1.1.4.3" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.4.3.cmml">t</mi></msub></mrow><mo id="Ch4.E7.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="Ch4.E7.m1.1.1.1.2" xref="Ch4.E7.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch4.E7.m1.1b"><apply id="Ch4.E7.m1.1.1.1.1.cmml" xref="Ch4.E7.m1.1.1.1"><eq id="Ch4.E7.m1.1.1.1.1.2.cmml" xref="Ch4.E7.m1.1.1.1.1.2"></eq><apply id="Ch4.E7.m1.1.1.1.1.3.cmml" xref="Ch4.E7.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="Ch4.E7.m1.1.1.1.1.3.1.cmml" xref="Ch4.E7.m1.1.1.1.1.3">subscript</csymbol><ci id="Ch4.E7.m1.1.1.1.1.3.2.cmml" xref="Ch4.E7.m1.1.1.1.1.3.2">ℎ</ci><ci id="Ch4.E7.m1.1.1.1.1.3.3.cmml" xref="Ch4.E7.m1.1.1.1.1.3.3">𝑡</ci></apply><apply id="Ch4.E7.m1.1.1.1.1.1.cmml" xref="Ch4.E7.m1.1.1.1.1.1"><times id="Ch4.E7.m1.1.1.1.1.1.2.cmml" xref="Ch4.E7.m1.1.1.1.1.1.2"></times><ci id="Ch4.E7.m1.1.1.1.1.1.3.cmml" xref="Ch4.E7.m1.1.1.1.1.1.3">𝜎</ci><apply id="Ch4.E7.m1.1.1.1.1.1.1.1.1.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1"><plus id="Ch4.E7.m1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.1"></plus><apply id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2"><times id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.1"></times><apply id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.2">𝑊</ci><apply id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.3"><times id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.3.1.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.3.1"></times><ci id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.3.2.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.3.2">𝑒</ci><ci id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.3.3.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.2.3.3">ℎ</ci></apply></apply><apply id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.3">subscript</csymbol><ci id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.3.2.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.3.2">𝑒</ci><ci id="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.3.3.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.2.3.3">𝑡</ci></apply></apply><apply id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3"><times id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.1.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.1"></times><apply id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.2.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.2">𝑊</ci><apply id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.3.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.3"><times id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.3.1.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.3.1"></times><ci id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.3.2.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.3.2">ℎ</ci><ci id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.3.3.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.2.3.3">ℎ</ci></apply></apply><apply id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.1.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3">subscript</csymbol><ci id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.2.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.2">ℎ</ci><apply id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.3.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.3"><minus id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.3.1.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.3.1"></minus><ci id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.3.2.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.3.2">𝑡</ci><cn id="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.3.3.cmml" type="integer" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.3.3.3.3">1</cn></apply></apply></apply><apply id="Ch4.E7.m1.1.1.1.1.1.1.1.1.4.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.4"><csymbol cd="ambiguous" id="Ch4.E7.m1.1.1.1.1.1.1.1.1.4.1.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.4">subscript</csymbol><ci id="Ch4.E7.m1.1.1.1.1.1.1.1.1.4.2.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.4.2">𝑏</ci><ci id="Ch4.E7.m1.1.1.1.1.1.1.1.1.4.3.cmml" xref="Ch4.E7.m1.1.1.1.1.1.1.1.1.4.3">𝑡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.E7.m1.1c">h_{t}=\sigma(W_{eh}e_{t}+W_{hh}h_{t-1}+b_{t}),</annotation><annotation encoding="application/x-llamapun" id="Ch4.E7.m1.1d">italic_h start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_σ ( italic_W start_POSTSUBSCRIPT italic_e italic_h end_POSTSUBSCRIPT italic_e start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT + italic_W start_POSTSUBSCRIPT italic_h italic_h end_POSTSUBSCRIPT italic_h start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT + italic_b start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4.7)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch4.S1.SS2.p4.39">where <math alttext="\sigma(\cdot)" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.34.m1.1"><semantics id="Ch4.S1.SS2.p4.34.m1.1a"><mrow id="Ch4.S1.SS2.p4.34.m1.1.2" xref="Ch4.S1.SS2.p4.34.m1.1.2.cmml"><mi id="Ch4.S1.SS2.p4.34.m1.1.2.2" xref="Ch4.S1.SS2.p4.34.m1.1.2.2.cmml">σ</mi><mo id="Ch4.S1.SS2.p4.34.m1.1.2.1" xref="Ch4.S1.SS2.p4.34.m1.1.2.1.cmml">⁢</mo><mrow id="Ch4.S1.SS2.p4.34.m1.1.2.3.2" xref="Ch4.S1.SS2.p4.34.m1.1.2.cmml"><mo id="Ch4.S1.SS2.p4.34.m1.1.2.3.2.1" stretchy="false" xref="Ch4.S1.SS2.p4.34.m1.1.2.cmml">(</mo><mo id="Ch4.S1.SS2.p4.34.m1.1.1" lspace="0em" rspace="0em" xref="Ch4.S1.SS2.p4.34.m1.1.1.cmml">⋅</mo><mo id="Ch4.S1.SS2.p4.34.m1.1.2.3.2.2" stretchy="false" xref="Ch4.S1.SS2.p4.34.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.34.m1.1b"><apply id="Ch4.S1.SS2.p4.34.m1.1.2.cmml" xref="Ch4.S1.SS2.p4.34.m1.1.2"><times id="Ch4.S1.SS2.p4.34.m1.1.2.1.cmml" xref="Ch4.S1.SS2.p4.34.m1.1.2.1"></times><ci id="Ch4.S1.SS2.p4.34.m1.1.2.2.cmml" xref="Ch4.S1.SS2.p4.34.m1.1.2.2">𝜎</ci><ci id="Ch4.S1.SS2.p4.34.m1.1.1.cmml" xref="Ch4.S1.SS2.p4.34.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.34.m1.1c">\sigma(\cdot)</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.34.m1.1d">italic_σ ( ⋅ )</annotation></semantics></math> is a non-linear activation function, e.g., ReLU, sigmoid, or tanh; <math alttext="W_{eh}\in R^{d_{h}\times d_{e}}" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.35.m2.1"><semantics id="Ch4.S1.SS2.p4.35.m2.1a"><mrow id="Ch4.S1.SS2.p4.35.m2.1.1" xref="Ch4.S1.SS2.p4.35.m2.1.1.cmml"><msub id="Ch4.S1.SS2.p4.35.m2.1.1.2" xref="Ch4.S1.SS2.p4.35.m2.1.1.2.cmml"><mi id="Ch4.S1.SS2.p4.35.m2.1.1.2.2" xref="Ch4.S1.SS2.p4.35.m2.1.1.2.2.cmml">W</mi><mrow id="Ch4.S1.SS2.p4.35.m2.1.1.2.3" xref="Ch4.S1.SS2.p4.35.m2.1.1.2.3.cmml"><mi id="Ch4.S1.SS2.p4.35.m2.1.1.2.3.2" xref="Ch4.S1.SS2.p4.35.m2.1.1.2.3.2.cmml">e</mi><mo id="Ch4.S1.SS2.p4.35.m2.1.1.2.3.1" xref="Ch4.S1.SS2.p4.35.m2.1.1.2.3.1.cmml">⁢</mo><mi id="Ch4.S1.SS2.p4.35.m2.1.1.2.3.3" xref="Ch4.S1.SS2.p4.35.m2.1.1.2.3.3.cmml">h</mi></mrow></msub><mo id="Ch4.S1.SS2.p4.35.m2.1.1.1" xref="Ch4.S1.SS2.p4.35.m2.1.1.1.cmml">∈</mo><msup id="Ch4.S1.SS2.p4.35.m2.1.1.3" xref="Ch4.S1.SS2.p4.35.m2.1.1.3.cmml"><mi id="Ch4.S1.SS2.p4.35.m2.1.1.3.2" xref="Ch4.S1.SS2.p4.35.m2.1.1.3.2.cmml">R</mi><mrow id="Ch4.S1.SS2.p4.35.m2.1.1.3.3" xref="Ch4.S1.SS2.p4.35.m2.1.1.3.3.cmml"><msub id="Ch4.S1.SS2.p4.35.m2.1.1.3.3.2" xref="Ch4.S1.SS2.p4.35.m2.1.1.3.3.2.cmml"><mi id="Ch4.S1.SS2.p4.35.m2.1.1.3.3.2.2" xref="Ch4.S1.SS2.p4.35.m2.1.1.3.3.2.2.cmml">d</mi><mi id="Ch4.S1.SS2.p4.35.m2.1.1.3.3.2.3" xref="Ch4.S1.SS2.p4.35.m2.1.1.3.3.2.3.cmml">h</mi></msub><mo id="Ch4.S1.SS2.p4.35.m2.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="Ch4.S1.SS2.p4.35.m2.1.1.3.3.1.cmml">×</mo><msub id="Ch4.S1.SS2.p4.35.m2.1.1.3.3.3" xref="Ch4.S1.SS2.p4.35.m2.1.1.3.3.3.cmml"><mi id="Ch4.S1.SS2.p4.35.m2.1.1.3.3.3.2" xref="Ch4.S1.SS2.p4.35.m2.1.1.3.3.3.2.cmml">d</mi><mi id="Ch4.S1.SS2.p4.35.m2.1.1.3.3.3.3" xref="Ch4.S1.SS2.p4.35.m2.1.1.3.3.3.3.cmml">e</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.35.m2.1b"><apply id="Ch4.S1.SS2.p4.35.m2.1.1.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1"><in id="Ch4.S1.SS2.p4.35.m2.1.1.1.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1.1"></in><apply id="Ch4.S1.SS2.p4.35.m2.1.1.2.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1.2"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.35.m2.1.1.2.1.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1.2">subscript</csymbol><ci id="Ch4.S1.SS2.p4.35.m2.1.1.2.2.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1.2.2">𝑊</ci><apply id="Ch4.S1.SS2.p4.35.m2.1.1.2.3.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1.2.3"><times id="Ch4.S1.SS2.p4.35.m2.1.1.2.3.1.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1.2.3.1"></times><ci id="Ch4.S1.SS2.p4.35.m2.1.1.2.3.2.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1.2.3.2">𝑒</ci><ci id="Ch4.S1.SS2.p4.35.m2.1.1.2.3.3.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1.2.3.3">ℎ</ci></apply></apply><apply id="Ch4.S1.SS2.p4.35.m2.1.1.3.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1.3"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.35.m2.1.1.3.1.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1.3">superscript</csymbol><ci id="Ch4.S1.SS2.p4.35.m2.1.1.3.2.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1.3.2">𝑅</ci><apply id="Ch4.S1.SS2.p4.35.m2.1.1.3.3.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1.3.3"><times id="Ch4.S1.SS2.p4.35.m2.1.1.3.3.1.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1.3.3.1"></times><apply id="Ch4.S1.SS2.p4.35.m2.1.1.3.3.2.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1.3.3.2"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.35.m2.1.1.3.3.2.1.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1.3.3.2">subscript</csymbol><ci id="Ch4.S1.SS2.p4.35.m2.1.1.3.3.2.2.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1.3.3.2.2">𝑑</ci><ci id="Ch4.S1.SS2.p4.35.m2.1.1.3.3.2.3.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1.3.3.2.3">ℎ</ci></apply><apply id="Ch4.S1.SS2.p4.35.m2.1.1.3.3.3.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1.3.3.3"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.35.m2.1.1.3.3.3.1.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1.3.3.3">subscript</csymbol><ci id="Ch4.S1.SS2.p4.35.m2.1.1.3.3.3.2.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1.3.3.3.2">𝑑</ci><ci id="Ch4.S1.SS2.p4.35.m2.1.1.3.3.3.3.cmml" xref="Ch4.S1.SS2.p4.35.m2.1.1.3.3.3.3">𝑒</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.35.m2.1c">W_{eh}\in R^{d_{h}\times d_{e}}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.35.m2.1d">italic_W start_POSTSUBSCRIPT italic_e italic_h end_POSTSUBSCRIPT ∈ italic_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT × italic_d start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math>, <math alttext="W_{hh}\in R^{d_{h}\times d_{h}}" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.36.m3.1"><semantics id="Ch4.S1.SS2.p4.36.m3.1a"><mrow id="Ch4.S1.SS2.p4.36.m3.1.1" xref="Ch4.S1.SS2.p4.36.m3.1.1.cmml"><msub id="Ch4.S1.SS2.p4.36.m3.1.1.2" xref="Ch4.S1.SS2.p4.36.m3.1.1.2.cmml"><mi id="Ch4.S1.SS2.p4.36.m3.1.1.2.2" xref="Ch4.S1.SS2.p4.36.m3.1.1.2.2.cmml">W</mi><mrow id="Ch4.S1.SS2.p4.36.m3.1.1.2.3" xref="Ch4.S1.SS2.p4.36.m3.1.1.2.3.cmml"><mi id="Ch4.S1.SS2.p4.36.m3.1.1.2.3.2" xref="Ch4.S1.SS2.p4.36.m3.1.1.2.3.2.cmml">h</mi><mo id="Ch4.S1.SS2.p4.36.m3.1.1.2.3.1" xref="Ch4.S1.SS2.p4.36.m3.1.1.2.3.1.cmml">⁢</mo><mi id="Ch4.S1.SS2.p4.36.m3.1.1.2.3.3" xref="Ch4.S1.SS2.p4.36.m3.1.1.2.3.3.cmml">h</mi></mrow></msub><mo id="Ch4.S1.SS2.p4.36.m3.1.1.1" xref="Ch4.S1.SS2.p4.36.m3.1.1.1.cmml">∈</mo><msup id="Ch4.S1.SS2.p4.36.m3.1.1.3" xref="Ch4.S1.SS2.p4.36.m3.1.1.3.cmml"><mi id="Ch4.S1.SS2.p4.36.m3.1.1.3.2" xref="Ch4.S1.SS2.p4.36.m3.1.1.3.2.cmml">R</mi><mrow id="Ch4.S1.SS2.p4.36.m3.1.1.3.3" xref="Ch4.S1.SS2.p4.36.m3.1.1.3.3.cmml"><msub id="Ch4.S1.SS2.p4.36.m3.1.1.3.3.2" xref="Ch4.S1.SS2.p4.36.m3.1.1.3.3.2.cmml"><mi id="Ch4.S1.SS2.p4.36.m3.1.1.3.3.2.2" xref="Ch4.S1.SS2.p4.36.m3.1.1.3.3.2.2.cmml">d</mi><mi id="Ch4.S1.SS2.p4.36.m3.1.1.3.3.2.3" xref="Ch4.S1.SS2.p4.36.m3.1.1.3.3.2.3.cmml">h</mi></msub><mo id="Ch4.S1.SS2.p4.36.m3.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="Ch4.S1.SS2.p4.36.m3.1.1.3.3.1.cmml">×</mo><msub id="Ch4.S1.SS2.p4.36.m3.1.1.3.3.3" xref="Ch4.S1.SS2.p4.36.m3.1.1.3.3.3.cmml"><mi id="Ch4.S1.SS2.p4.36.m3.1.1.3.3.3.2" xref="Ch4.S1.SS2.p4.36.m3.1.1.3.3.3.2.cmml">d</mi><mi id="Ch4.S1.SS2.p4.36.m3.1.1.3.3.3.3" xref="Ch4.S1.SS2.p4.36.m3.1.1.3.3.3.3.cmml">h</mi></msub></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.36.m3.1b"><apply id="Ch4.S1.SS2.p4.36.m3.1.1.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1"><in id="Ch4.S1.SS2.p4.36.m3.1.1.1.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1.1"></in><apply id="Ch4.S1.SS2.p4.36.m3.1.1.2.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1.2"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.36.m3.1.1.2.1.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1.2">subscript</csymbol><ci id="Ch4.S1.SS2.p4.36.m3.1.1.2.2.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1.2.2">𝑊</ci><apply id="Ch4.S1.SS2.p4.36.m3.1.1.2.3.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1.2.3"><times id="Ch4.S1.SS2.p4.36.m3.1.1.2.3.1.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1.2.3.1"></times><ci id="Ch4.S1.SS2.p4.36.m3.1.1.2.3.2.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1.2.3.2">ℎ</ci><ci id="Ch4.S1.SS2.p4.36.m3.1.1.2.3.3.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1.2.3.3">ℎ</ci></apply></apply><apply id="Ch4.S1.SS2.p4.36.m3.1.1.3.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1.3"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.36.m3.1.1.3.1.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1.3">superscript</csymbol><ci id="Ch4.S1.SS2.p4.36.m3.1.1.3.2.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1.3.2">𝑅</ci><apply id="Ch4.S1.SS2.p4.36.m3.1.1.3.3.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1.3.3"><times id="Ch4.S1.SS2.p4.36.m3.1.1.3.3.1.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1.3.3.1"></times><apply id="Ch4.S1.SS2.p4.36.m3.1.1.3.3.2.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1.3.3.2"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.36.m3.1.1.3.3.2.1.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1.3.3.2">subscript</csymbol><ci id="Ch4.S1.SS2.p4.36.m3.1.1.3.3.2.2.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1.3.3.2.2">𝑑</ci><ci id="Ch4.S1.SS2.p4.36.m3.1.1.3.3.2.3.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1.3.3.2.3">ℎ</ci></apply><apply id="Ch4.S1.SS2.p4.36.m3.1.1.3.3.3.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1.3.3.3"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.36.m3.1.1.3.3.3.1.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1.3.3.3">subscript</csymbol><ci id="Ch4.S1.SS2.p4.36.m3.1.1.3.3.3.2.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1.3.3.3.2">𝑑</ci><ci id="Ch4.S1.SS2.p4.36.m3.1.1.3.3.3.3.cmml" xref="Ch4.S1.SS2.p4.36.m3.1.1.3.3.3.3">ℎ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.36.m3.1c">W_{hh}\in R^{d_{h}\times d_{h}}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.36.m3.1d">italic_W start_POSTSUBSCRIPT italic_h italic_h end_POSTSUBSCRIPT ∈ italic_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT × italic_d start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math>, and <math alttext="b_{i}\in R^{d_{h}}" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.37.m4.1"><semantics id="Ch4.S1.SS2.p4.37.m4.1a"><mrow id="Ch4.S1.SS2.p4.37.m4.1.1" xref="Ch4.S1.SS2.p4.37.m4.1.1.cmml"><msub id="Ch4.S1.SS2.p4.37.m4.1.1.2" xref="Ch4.S1.SS2.p4.37.m4.1.1.2.cmml"><mi id="Ch4.S1.SS2.p4.37.m4.1.1.2.2" xref="Ch4.S1.SS2.p4.37.m4.1.1.2.2.cmml">b</mi><mi id="Ch4.S1.SS2.p4.37.m4.1.1.2.3" xref="Ch4.S1.SS2.p4.37.m4.1.1.2.3.cmml">i</mi></msub><mo id="Ch4.S1.SS2.p4.37.m4.1.1.1" xref="Ch4.S1.SS2.p4.37.m4.1.1.1.cmml">∈</mo><msup id="Ch4.S1.SS2.p4.37.m4.1.1.3" xref="Ch4.S1.SS2.p4.37.m4.1.1.3.cmml"><mi id="Ch4.S1.SS2.p4.37.m4.1.1.3.2" xref="Ch4.S1.SS2.p4.37.m4.1.1.3.2.cmml">R</mi><msub id="Ch4.S1.SS2.p4.37.m4.1.1.3.3" xref="Ch4.S1.SS2.p4.37.m4.1.1.3.3.cmml"><mi id="Ch4.S1.SS2.p4.37.m4.1.1.3.3.2" xref="Ch4.S1.SS2.p4.37.m4.1.1.3.3.2.cmml">d</mi><mi id="Ch4.S1.SS2.p4.37.m4.1.1.3.3.3" xref="Ch4.S1.SS2.p4.37.m4.1.1.3.3.3.cmml">h</mi></msub></msup></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.37.m4.1b"><apply id="Ch4.S1.SS2.p4.37.m4.1.1.cmml" xref="Ch4.S1.SS2.p4.37.m4.1.1"><in id="Ch4.S1.SS2.p4.37.m4.1.1.1.cmml" xref="Ch4.S1.SS2.p4.37.m4.1.1.1"></in><apply id="Ch4.S1.SS2.p4.37.m4.1.1.2.cmml" xref="Ch4.S1.SS2.p4.37.m4.1.1.2"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.37.m4.1.1.2.1.cmml" xref="Ch4.S1.SS2.p4.37.m4.1.1.2">subscript</csymbol><ci id="Ch4.S1.SS2.p4.37.m4.1.1.2.2.cmml" xref="Ch4.S1.SS2.p4.37.m4.1.1.2.2">𝑏</ci><ci id="Ch4.S1.SS2.p4.37.m4.1.1.2.3.cmml" xref="Ch4.S1.SS2.p4.37.m4.1.1.2.3">𝑖</ci></apply><apply id="Ch4.S1.SS2.p4.37.m4.1.1.3.cmml" xref="Ch4.S1.SS2.p4.37.m4.1.1.3"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.37.m4.1.1.3.1.cmml" xref="Ch4.S1.SS2.p4.37.m4.1.1.3">superscript</csymbol><ci id="Ch4.S1.SS2.p4.37.m4.1.1.3.2.cmml" xref="Ch4.S1.SS2.p4.37.m4.1.1.3.2">𝑅</ci><apply id="Ch4.S1.SS2.p4.37.m4.1.1.3.3.cmml" xref="Ch4.S1.SS2.p4.37.m4.1.1.3.3"><csymbol cd="ambiguous" id="Ch4.S1.SS2.p4.37.m4.1.1.3.3.1.cmml" xref="Ch4.S1.SS2.p4.37.m4.1.1.3.3">subscript</csymbol><ci id="Ch4.S1.SS2.p4.37.m4.1.1.3.3.2.cmml" xref="Ch4.S1.SS2.p4.37.m4.1.1.3.3.2">𝑑</ci><ci id="Ch4.S1.SS2.p4.37.m4.1.1.3.3.3.cmml" xref="Ch4.S1.SS2.p4.37.m4.1.1.3.3.3">ℎ</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.37.m4.1c">b_{i}\in R^{d_{h}}</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.37.m4.1d">italic_b start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ italic_R start_POSTSUPERSCRIPT italic_d start_POSTSUBSCRIPT italic_h end_POSTSUBSCRIPT end_POSTSUPERSCRIPT</annotation></semantics></math>.
To capture the effects of micro-behavior, the authors decided to introduce an attention layer <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">attention1</span>]</cite> that assigns proper weights to each hidden unit; this helps to obtain a more balanced output.
The attention weight is mapped from the hidden layer vector to a real valued score by the function <math alttext="\sigma(\cdot)" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.38.m5.1"><semantics id="Ch4.S1.SS2.p4.38.m5.1a"><mrow id="Ch4.S1.SS2.p4.38.m5.1.2" xref="Ch4.S1.SS2.p4.38.m5.1.2.cmml"><mi id="Ch4.S1.SS2.p4.38.m5.1.2.2" xref="Ch4.S1.SS2.p4.38.m5.1.2.2.cmml">σ</mi><mo id="Ch4.S1.SS2.p4.38.m5.1.2.1" xref="Ch4.S1.SS2.p4.38.m5.1.2.1.cmml">⁢</mo><mrow id="Ch4.S1.SS2.p4.38.m5.1.2.3.2" xref="Ch4.S1.SS2.p4.38.m5.1.2.cmml"><mo id="Ch4.S1.SS2.p4.38.m5.1.2.3.2.1" stretchy="false" xref="Ch4.S1.SS2.p4.38.m5.1.2.cmml">(</mo><mo id="Ch4.S1.SS2.p4.38.m5.1.1" lspace="0em" rspace="0em" xref="Ch4.S1.SS2.p4.38.m5.1.1.cmml">⋅</mo><mo id="Ch4.S1.SS2.p4.38.m5.1.2.3.2.2" stretchy="false" xref="Ch4.S1.SS2.p4.38.m5.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.38.m5.1b"><apply id="Ch4.S1.SS2.p4.38.m5.1.2.cmml" xref="Ch4.S1.SS2.p4.38.m5.1.2"><times id="Ch4.S1.SS2.p4.38.m5.1.2.1.cmml" xref="Ch4.S1.SS2.p4.38.m5.1.2.1"></times><ci id="Ch4.S1.SS2.p4.38.m5.1.2.2.cmml" xref="Ch4.S1.SS2.p4.38.m5.1.2.2">𝜎</ci><ci id="Ch4.S1.SS2.p4.38.m5.1.1.cmml" xref="Ch4.S1.SS2.p4.38.m5.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.38.m5.1c">\sigma(\cdot)</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.38.m5.1d">italic_σ ( ⋅ )</annotation></semantics></math>. To achieve sufficient expressive ability, the function <math alttext="\sigma(\cdot)" class="ltx_Math" display="inline" id="Ch4.S1.SS2.p4.39.m6.1"><semantics id="Ch4.S1.SS2.p4.39.m6.1a"><mrow id="Ch4.S1.SS2.p4.39.m6.1.2" xref="Ch4.S1.SS2.p4.39.m6.1.2.cmml"><mi id="Ch4.S1.SS2.p4.39.m6.1.2.2" xref="Ch4.S1.SS2.p4.39.m6.1.2.2.cmml">σ</mi><mo id="Ch4.S1.SS2.p4.39.m6.1.2.1" xref="Ch4.S1.SS2.p4.39.m6.1.2.1.cmml">⁢</mo><mrow id="Ch4.S1.SS2.p4.39.m6.1.2.3.2" xref="Ch4.S1.SS2.p4.39.m6.1.2.cmml"><mo id="Ch4.S1.SS2.p4.39.m6.1.2.3.2.1" stretchy="false" xref="Ch4.S1.SS2.p4.39.m6.1.2.cmml">(</mo><mo id="Ch4.S1.SS2.p4.39.m6.1.1" lspace="0em" rspace="0em" xref="Ch4.S1.SS2.p4.39.m6.1.1.cmml">⋅</mo><mo id="Ch4.S1.SS2.p4.39.m6.1.2.3.2.2" stretchy="false" xref="Ch4.S1.SS2.p4.39.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS2.p4.39.m6.1b"><apply id="Ch4.S1.SS2.p4.39.m6.1.2.cmml" xref="Ch4.S1.SS2.p4.39.m6.1.2"><times id="Ch4.S1.SS2.p4.39.m6.1.2.1.cmml" xref="Ch4.S1.SS2.p4.39.m6.1.2.1"></times><ci id="Ch4.S1.SS2.p4.39.m6.1.2.2.cmml" xref="Ch4.S1.SS2.p4.39.m6.1.2.2">𝜎</ci><ci id="Ch4.S1.SS2.p4.39.m6.1.1.cmml" xref="Ch4.S1.SS2.p4.39.m6.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS2.p4.39.m6.1c">\sigma(\cdot)</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS2.p4.39.m6.1d">italic_σ ( ⋅ )</annotation></semantics></math> is typically implemented by a neural network layer.
Then, the final output is an attention weighted pooling of the RNN layer.
To exploit the different transition patterns between items and operations in micro-behavior modeling, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">meng2020sigirclick</span></cite> incorporated the item knowledge into a joint user modeling framework including a recurrent neural network and a graph neural network.
To incorporate the micro-behavior information in the iterative process of user behavior modeling, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">jianhao2022session</span></cite> modeled a user session as a fine-grained sequence of micro-behaviors and proposed a self-attention mechanism to encode the dyadic relations of micro-behaviors.</p>
</div>
<div class="ltx_para" id="Ch4.S1.SS2.p5">
<p class="ltx_p" id="Ch4.S1.SS2.p5.1">Experimental results have confirmed that post-click user modeling can provide deeper insight into user behavior, which is utilized to advance e-commerce search and recommender systems by successfully modeling the sequential dynamics in the candidate retrieval stage <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhouwsdm2018</span>]</cite>.
However, post-click behaviors are often sparse in real-world scenarios, making it challenging to supplement large-scale implicit feedback. To address this, recent studies have integrated post-clicks with other user behaviors.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2019leveraging</span></cite> proposed a generic probabilistic framework to fuse click and post-click feedback in recommender systems.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2021clicks</span></cite> revealed the importance of mitigating the clickbait issue
from click behaviors, and applied causal inference to establish a causal graph to reformulate the process.
In Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S2.SS3" title="6.2.3 Session-based recommendation ‣ 6.2 Candidate retrieval models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6.2.3</span></a>, we discuss further studies that have focused on integrating post-click tracking into e-commerce recommendation.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch4.S1.SS3">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1.3 </span>Purchase-intent modeling</h4>
<div class="ltx_para" id="Ch4.S1.SS3.p1">
<p class="ltx_p" id="Ch4.S1.SS3.p1.1">As it is widely applied in search and recommendation approaches, <em class="ltx_emph ltx_font_italic" id="Ch4.S1.SS3.p1.1.1">purchase-intent prediction</em> is another important task in e-commerce modeling <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">qiu2015predicting</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kooti2016portrait</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lo2016understanding</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wan2017modeling</span>]</cite>.
According to <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">bellman1999predictors</span></cite>, the volume of the online activity of a customer proves useful when predicting the occurrence of a future purchase.
Statistical models of customer purchase behavior have been studied for decades.
Early research on purchase behavior modeling was based on statistical approaches, e.g., negative binomial distribution models <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bearden1999handbook</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kooti2016portrait</span>]</cite>.
Features related to information gathering and the purchase potential (e.g., monetary resources and product values) also help to predict the purchase intention <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bearden1999handbook</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hansen2004predicting</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">pavlou2006understanding</span>]</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch4.S1.SS3.p2">
<p class="ltx_p" id="Ch4.S1.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="Ch4.S1.SS3.p2.1.1">Feature-based methods.</span>
User-aware features have been successfully applied to predict purchase intent in e-commerce scenarios.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">qiu2015predicting</span></cite> proposed a pipeline-based purchase-prediction approach that includes three main components.
First, the authors utilized associations between products to predict the needs of customers; then, they combined collaborative filtering and a hierarchical Bayesian discrete choice model enable customer preference learning; lastly, they constructed a support vector regression-based model to calculate the popularity of products.
After analyzing user behavior on Pinterest, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">lo2016understanding</span></cite> proposed a predictor to detect a user’s purchase intent.
The authors applied five kinds of features: demographics, activity, action-type, content, and temporal features.

<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wan2017modeling</span></cite> also proposed a three-stage model to predict the purchase behavior on a real-world e-commerce portal.
To identify who can be converted to regular loyal buyers and then targeted to reduce promotion cost, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2016repeat</span></cite> proposed a solution for repeat buyer prediction; they collected a large number of features to capture the preferences and behavior of users, characteristics of merchants, brands, categories, and items, and the interactions among them.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">hendriksen-2020-analyzing</span></cite> analyzed the potential of long-term historical records (from logged-in users) to more accurately and reliably predict purchase intent.
Additionally, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ariannezhad-2021-understanding</span></cite> showed that data that provides information on customer behavior in one channel (e.g., online) can help to predict purchase intent in other channels (e.g., offline).
Social media has become another important source of information to help explore consumer purchase intentions <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mishne-2006-deriving</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2013predicting</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ding2015mining</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2013predicting</span></cite> explored whether users’ social media information is correlated with their e-commerce profiling categories.
Accordingly, the authors leveraged correlations to build machine learning algorithms to predict user purchase behavior.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch4.S1.SS3.p3">
<p class="ltx_p" id="Ch4.S1.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="Ch4.S1.SS3.p3.1.1">CVR prediction methods.</span>
<em class="ltx_emph ltx_font_italic" id="Ch4.S1.SS3.p3.1.2">Conversion rate</em> (CVR) prediction is another way to predict the user purchase intention on e-commerce platforms.
CVR calculates the proportion of users who will eventually convert after clicking <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lee2012estimating</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2016large</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lu2017practical</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2019multi</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">su2020attention</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2020entire</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yasui2020feedback</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2021capturing</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hou2021conversion</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2021conversionpred</span>]</cite>.
Because conversions are extremely rare, CVR modeling is very challenging.
CVR can be split into the following two categories: post-view conversion and post-click conversion, i.e., conversion after viewing an item without having clicked it, and conversion after having clicked the item, respectively.
Most approaches focus on the task of post-click conversion.

<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2019multi</span></cite> proposed a decision tree ensemble model, i.e., <em class="ltx_emph ltx_font_italic" id="Ch4.S1.SS3.p3.1.3">ldcTree</em>, that exploits deep cascade structures and applies cross-entropy based feature representations.
Nonetheless, there are still <math alttext="3" class="ltx_Math" display="inline" id="Ch4.S1.SS3.p3.1.m1.1"><semantics id="Ch4.S1.SS3.p3.1.m1.1a"><mn id="Ch4.S1.SS3.p3.1.m1.1.1" xref="Ch4.S1.SS3.p3.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="Ch4.S1.SS3.p3.1.m1.1b"><cn id="Ch4.S1.SS3.p3.1.m1.1.1.cmml" type="integer" xref="Ch4.S1.SS3.p3.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S1.SS3.p3.1.m1.1c">3</annotation><annotation encoding="application/x-llamapun" id="Ch4.S1.SS3.p3.1.m1.1d">3</annotation></semantics></math> challenges in CVR estimation: <em class="ltx_emph ltx_font_italic" id="Ch4.S1.SS3.p3.1.4">data sparsity</em>, <em class="ltx_emph ltx_font_italic" id="Ch4.S1.SS3.p3.1.5">sample selection bias</em>, and <em class="ltx_emph ltx_font_italic" id="Ch4.S1.SS3.p3.1.6">delayed feedback</em>.
The data sparsity problem reflects the insufficiency of click samples in training data.
Sample selection bias refers to the systematic difference in the data distribution between the training space and inference space <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2020entire</span>]</cite>.
Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.F5" title="Figure 4.5 ‣ 4.1.3 Purchase-intent modeling ‣ 4.1 User behavior modeling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4.5</span></a> illustrates the sample selection bias problem related to the development of an efficient industrial-level recommender system.</p>
</div>
<figure class="ltx_figure" id="Ch4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="304" id="Ch4.F5.g1" src="x28.png" width="539"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4.5: </span>Illustration of the sample selection bias problem in conventional CVR prediction, where the training space only consists of clicked samples, whereas the inference space is the entire space of all items. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2020entire</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch4.S1.SS3.p4">
<p class="ltx_p" id="Ch4.S1.SS3.p4.1">The delayed feedback problem indicates that the e-commerce platform can receive feedback with a delay after an item is impressed or clicked by a user <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chapelle2014modeling</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">su2020attention</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch4.S1.SS3.p5">
<p class="ltx_p" id="Ch4.S1.SS3.p5.1">To address the data sparsity problem, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ma2018entire</span></cite> proposed the entire space multi-task model, which aims to apply multi-task learning to accomplish two subtasks of predicting the post-view click-through rate and post-view conversion rate.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2020entire</span></cite> observed that users always engaged in abundant purchase-related actions after clicking.
Thus, they proposed a deep neural network method within a multi-task learning framework to decompose post-click behavior to predict CVR.
The authors were able to distinguish between purchase-related actions and other actions, which, taken together, can be used to form a probabilistic sequential user behavior graph.</p>
</div>
<div class="ltx_para" id="Ch4.S1.SS3.p6">
<p class="ltx_p" id="Ch4.S1.SS3.p6.1">All the above multi-task strategies are also helpful in alleviating the selection bias problem.
Furthermore, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2020large</span></cite> proposed a doubly robust estimation method to debias CVR prediction.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">yasui2020feedback</span></cite> proposed a dual learning method to simultaneously address the delayed feedback problem and the selection bias problem.
To reduce the variance of doubly robust loss to enhance model robustness, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2021enhanced</span></cite> enhanced a more robust doubly robust approach for debiasing post-click conversion rate estimation.
But the authors didn’t directly control the bias and the variance in an effective way.
To address this problem, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">dai2022kddcvr</span></cite> proposed a generalized framework of doubly robust learning, which unifies the existing doubly robust methods. Based on this framework, two new doubly robust methods were proposed to control the bias and mean squared error.</p>
</div>
<div class="ltx_para" id="Ch4.S1.SS3.p7">
<p class="ltx_p" id="Ch4.S1.SS3.p7.1">Starting to address the delayed feedback problem, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chapelle2014modeling</span></cite> proposed the delayed feedback model to optimize CVR as a joint probability over the predicted CVR and the delayed time distribution.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">yoshikawa2018nonparametric</span></cite> extended the delayed feedback model to a non-parametric model.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">su2020attention</span></cite> focused on post-click calibration in CVR modeling. The authors extracted pre-trained embeddings from impressions/clicks to enhance the conversion models; they proposed an inner/self-attention mechanism to capture the fine-grained personalized product purchase interests.
To estimate unbiased CVR in the online settings, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2021capturing</span></cite> proposed the elapsed-time sampling delayed feedback model to track relations between the observed conversion distribution and the true conversion distribution.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">li2021conversionpred</span></cite> utilized an idealized dataset for training a prophet model that can use the data properly, and then learned the actual model by imitating the prophet.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2022kddasymptotically</span></cite> confirmed the importance of dividing observed samples in a more granular manner, and hence proposed an unbiased importance sampling method with two-step optimization to address the delayed feedback issue.</p>
</div>
<div class="ltx_para" id="Ch4.S1.SS3.p8">
<p class="ltx_p" id="Ch4.S1.SS3.p8.1">These purchase-intent modeling strategies have been applied in e-commerce searches and recommendations; we will discuss these strategies in more detail in Sections <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.T1" title="Table 5.1 ‣ 5.4 Ranking strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.1</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S2" title="6.2 Candidate retrieval models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6.2</span></a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch4.S1.SS3.p9">
<p class="ltx_p" id="Ch4.S1.SS3.p9.1"><span class="ltx_text ltx_font_bold" id="Ch4.S1.SS3.p9.1.1">CLTV prediction methods.</span>
Lastly, <em class="ltx_emph ltx_font_italic" id="Ch4.S1.SS3.p9.1.2">customer lifetime value</em> (CLTV) prediction has also received attention in recent years.
CLTV is an important task in e-commerce search and recommendation models.
CLTV is defined as the sales, net of returns, of a customer over a 1-year period.
The objective of CLTV prediction is to improve three key business metrics:

<span class="ltx_inline-enumerate" id="Ch4.S1.I2">
<span class="ltx_inline-item" id="Ch4.S1.I2.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch4.S1.I2.i1.1">the average customer shopping frequency,
</span></span>
<span class="ltx_inline-item" id="Ch4.S1.I2.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch4.S1.I2.i2.1">the average order size, and
</span></span>
<span class="ltx_inline-item" id="Ch4.S1.I2.i3"><span class="ltx_tag ltx_tag_inline-item">(iii)</span> <span class="ltx_text" id="Ch4.S1.I2.i3.1">the customer churn rate.
</span></span>
</span>
With CLTV prediction, e-commerce retailers can rapidly identify and nurture high-value customers <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">vanderveld2016engagement</span>]</cite>.
Classic work on CLTV prediction applies handcrafted features and ensemble classifiers <cite class="ltx_cite ltx_citemacro_citep">[e.g., GBDT, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2016xgboost</span>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="Ch4.S2">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4.2 </span>User profiling in e-commerce</h3>
<div class="ltx_para" id="Ch4.S2.p1">
<p class="ltx_p" id="Ch4.S2.p1.1">A <em class="ltx_emph ltx_font_italic" id="Ch4.S2.p1.1.1">user profile</em> refers to personal information about a specific user.
Personalization plays an important role in web search and recommender systems.
In e-commerce portals, user profiling is a critical module for e-commerce information discovery tasks, as it provides personalized content in search or recommendation results.
User profiling can be defined as the process of exploring information about a user’s interest domain <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">dong2014inferring</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kanoje2015user</span>]</cite>.
Information about a user can be used by e-commerce search and recommender systems to enhance the system effectiveness because it enables better user understanding (see Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S3.SS5" title="5.3.5 Matching in personalized search ‣ 5.3 Matching strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.3.5</span></a> and  <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S4" title="6.4 Re-ranking strategies ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6.4</span></a>).
Given that it originated from work on the prediction of user purchase intention, research into user profiling in e-commerce has continuously garnered attention over the years <cite class="ltx_cite ltx_citemacro_citep">[see, e.g.,  <span class="ltx_ref ltx_missing_citation ltx_ref_self">solomon1994buying</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">braynov2003personalization</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hollerit2013towards</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2013predicting</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gupta2014identifying</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">rahdari2017analysis</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Huangwww2018</span>]</cite>.
Early work on user profiling for e-commerce mainly focused on information filtering, social media analysis, web searches, and fraud detection <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">solomon1994buying</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">fawcett1996combining</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">adomavicius1999user</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kuflik2000generation</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">braynov2003personalization</span>]</cite>.
Most of these are rule-based strategies.
For example, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">fawcett1996combining</span></cite> employed a rule-based user-profiling method to uncover indicators of fraudulent behavior.
These indicators were used to create user profiles that were then applied as features of their proposed system, which combines evidence from multiple profilers to generate high-confidence alarms.</p>
</div>
<section class="ltx_subsection" id="Ch4.S2.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2.1 </span>Types of user profiling</h4>
<div class="ltx_para" id="Ch4.S2.SS1.p1">
<p class="ltx_p" id="Ch4.S2.SS1.p1.1">User profiling can be classified as either <em class="ltx_emph ltx_font_italic" id="Ch4.S2.SS1.p1.1.1">profile extraction</em> and <em class="ltx_emph ltx_font_italic" id="Ch4.S2.SS1.p1.1.2">profile learning</em> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">tang2010combination</span>]</cite>.
Profile extraction focuses on extracting information about a user, such as demographic data (e.g., age, gender, location) or basic behavior patterns. However, in the environment of e-commerce, profile extraction is often less critical because it provides only a fixed snapshot of the user, lacking the adaptability needed to capture evolving preferences and real-time behavioral changes.
In contrast, profile learning is more significant as an e-commerce modeling tool <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">kuflik2000generation</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">cufoglu2014user</span>]</cite>.
Profile learning methods can be grouped into three categories:

<span class="ltx_inline-enumerate" id="Ch4.S2.I1">
<span class="ltx_inline-item" id="Ch4.S2.I1.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch4.S2.I1.i1.1">content-based methods,
</span></span>
<span class="ltx_inline-item" id="Ch4.S2.I1.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch4.S2.I1.i2.1">collaborative methods, and
</span></span>
<span class="ltx_inline-item" id="Ch4.S2.I1.i3"><span class="ltx_tag ltx_tag_inline-item">(iii)</span> <span class="ltx_text" id="Ch4.S2.I1.i3.1">hybrid methods <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">cufoglu2014user</span>]</cite>.
</span></span>
</span>
Content-based methods infer user profiles based solely on the users’ own previous behavior <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">kuflik2000generation</span>]</cite>.
Collaborative methods in user profiling focus on applying collaborative filtering approaches to infer profile information based on the behavior of users in a suitably defined neighborhood of similar users. Collaborative filtering methods can be classified as either <em class="ltx_emph ltx_font_italic" id="Ch4.S2.SS1.p1.1.3">memory-based methods</em> or <em class="ltx_emph ltx_font_italic" id="Ch4.S2.SS1.p1.1.4">model-based methods</em> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">godoy2005user</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">cufoglu2014user</span>]</cite>.
Memory-based solutions estimate ratings for a user based on the entire collection of previous ratings of similar users <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">adomavicius2005toward</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">su2009survey</span>]</cite>.
In contrast to memory-based collaborative filtering methods for user profiling, model-based methods use the collection of ratings to learn a model to estimate user profiles <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">su2009survey</span>]</cite>.
Hybrid methods have garnered attention because they combine content-based methods and collaborative methods <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">godoy2005user</span>]</cite>.
Regarding research on personalized recommendations, to capture users’ information and interest, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2010iui</span></cite> proposed a dynamic collaborative filtering method for news recommendation where the recommender constructs user profiles based on their past click behavior.
The authors initially conducted a log analysis of the changes in user interest in news topics over time.
By classifying users’ news interests as either <em class="ltx_emph ltx_font_italic" id="Ch4.S2.SS1.p1.1.5">genuine interests</em> or the <em class="ltx_emph ltx_font_italic" id="Ch4.S2.SS1.p1.1.6">influence of local news trends</em>, the authors were able to

<span class="ltx_inline-enumerate" id="Ch4.S2.I2">
<span class="ltx_inline-item" id="Ch4.S2.I2.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch4.S2.I2.i1.1">construct a Bayesian framework to model a user’s genuine interests based on their past click behavior, and
</span></span>
<span class="ltx_inline-item" id="Ch4.S2.I2.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch4.S2.I2.i2.1">predict current interests by jointly analyzing the genuine interest and the local news trends.
</span></span>
</span></p>
</div>
</section>
<section class="ltx_subsection" id="Ch4.S2.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2.2 </span>User profiling with social media</h4>
<div class="ltx_para" id="Ch4.S2.SS2.p1">
<p class="ltx_p" id="Ch4.S2.SS2.p1.1">Social media is playing an important role in e-commerce user profiling.
On the one hand, social media provides a source for generating user profiles, especially when addressing the <em class="ltx_emph ltx_font_italic" id="Ch4.S2.SS2.p1.1.1">cold start</em> problem.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">mishne-deriving-2006</span></cite> provided an early example of this idea, using a combination of text analysis and external knowledge sources to estimate the commercial tastes of bloggers from their posts.
On the other hand, profiling information learned from social media data can be applied to explore the user’s purchase intentions on e-commerce platforms.
Targeting users with no history on an e-commerce site, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2013predicting</span></cite> focused on predicting the purchase behavior by proposing a feature-selection method to predict the product categories from which a user will buy.
Representing user purchase intent as textual information that indicates a desire to purchase a product or service in the future, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">gupta2014identifying</span></cite> proposed a binary classification approach to identify the user purchase intention based on their social media posts.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ding2015mining</span></cite> explored relationships between a user’s consumption habits and their social media data. They proposed a consumption intention mining model (CIMM) based on CNNs.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">lo2016understanding</span></cite> analyzed user activities in social media to build a time-varying model to predict user purchase intent. The authors analyzed Pinterest<span class="ltx_note ltx_role_footnote" id="Ch4.footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://www.pinterest.com</span></span></span> data to understand how the usage of an e-commerce platform relates to future user shopping behavior. They found that indicators of purchase intent tended to gradually build up over time and sharply increase 3 to 5 days before purchase.
Multi-modal information has also been applied to infer user profiles.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">gelli2017personality</span></cite> focused on automatically discovering actionable images for users according to their personality.
By applying their model to a large-scale dataset, the authors found a significant correlation between personality
traits and affective visual concepts in the image content.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch4.S2.SS3">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2.3 </span>Graph-based user profiling</h4>
<div class="ltx_para" id="Ch4.S2.SS3.p1">
<p class="ltx_p" id="Ch4.S2.SS3.p1.1">Most approaches to user profiling only use a single type of information.
In e-commerce modeling, heterogeneous graphs are also being used to work with user profiles.
Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.F6" title="Figure 4.6 ‣ 4.2.3 Graph-based user profiling ‣ 4.2 User profiling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4.6</span></a> shows an example of a graph with heterogeneous information; particularly, three kinds of nodes were applied to represent three types of data, i.e., users, items, and attributes, respectively.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019semi</span></cite> focused on applying rich interactions among data instances, i.e., co-click and co-purchase behavior on e-commerce platforms, to enhance user-profiling performance in e-commerce models.
Neighborhood features were found to provide useful information that helps to infer user profiles, e.g., users that have similar co-purchase behavior on e-commerce platforms are likely to be of a similar age.
The authors proposed a heterogeneous graph attention network to infer user profiles within a multi-type data environment; the network was able to model the rich unsupervised information in a heterogeneous graph by encoding the graph structure and node features.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">gu2020hierarchical</span></cite> constructed a hierarchical profiling framework to model users’ real-time interests at different granularities.
A pyramid recurrent neural network model for hierarchical user profiling was constructed based on users’ micro-behavior; it was subsequently applied to model the types and dwell times of behavior to enable an effective formulation of users’ real-time interests.
These graph-based user-profiling methods have been applied to enhance the re-ranking results in e-commerce recommendation systems. More details are discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S4" title="6.4 Re-ranking strategies ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6.4</span></a>.</p>
</div>
<figure class="ltx_figure" id="Ch4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="407" id="Ch4.F6.g1" src="x29.png" width="705"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4.6: </span>User profiling results in the form of a heterogeneous graph. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019semi</span>]</cite>.</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="Ch4.S3">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4.3 </span>Emerging directions</h3>
<section class="ltx_subsection" id="Ch4.S3.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3.1 </span>Graph learning for user behavior modeling</h4>
<div class="ltx_para" id="Ch4.S3.SS1.p1">
<p class="ltx_p" id="Ch4.S3.SS1.p1.1">Graph neural networks use neural networks to represent graph information <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">scarselli2009graph</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">bruna2013spectral</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">battaglia2016interaction</span>]</cite>.
Graph convolutional networks extend CNNs to graph structured data; they have been shown to be effective on a range of graph classification tasks <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bruna2013spectral</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">defferrard2016convolutional</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2021sigirwgcn</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2022sigirgraph</span>]</cite>, and when applied for semi-supervised classification <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">hamilton2017inductive</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kipf2016semi</span>]</cite> and link prediction <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ma2018dynamic</span>]</cite>.
Most of these models have been designed for static graphs. However, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ma2018dynamic</span></cite> proposed a dynamic graph neural network model that can model dynamic information.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">xu2021transformer</span></cite> enhanced the capacity for learning complicated temporal dependency in the graph, by proposing a transformer-style relational reasoning network with a dynamic memory updating mechanism.
Graph neural networks that have been successfully applied to recommender systems were proven to be able to learn item embeddings within a large-scale item relationship graph <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ying2018graph</span>]</cite> that describes users, items, and pairwise relations in e-commerce scenarios <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ma2018dynamic</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gaowsdm2022rec</span>]</cite>.
Graph learning can also be applied for post-click modeling and user purchase-intent modeling.
To predict fine-grained post-click CVR, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">bao2020gmcm</span></cite> designed a model to represent user micro-behavior as a purchase-related micro-behavior graph.
The authors applied a multi-task learning framework to construct a graph-based micro-behavior conversion model that can capture the correlation between different types of micro-behavior.
The proposed multi-task learning and inverse propensity weighting modules mitigate the data sparsity- and sample selection bias-related problems.
To prediction efficient and accurate CVR, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2021hierarchy</span></cite> proposed a graph neural network to hierarchically model both micro- and macro-behaviors in a unified framework.
It seems likely that graph neural networks will continue to facilitate new ways of modeling, gaining insights into, and predicting, e-commerce user behavior in search (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S3.SS3" title="5.3.3 Interaction-based matching ‣ 5.3 Matching strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.3.3</span></a>) and recommendation scenarios (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S2.SS2" title="6.2.2 Embedding-based methods ‣ 6.2 Candidate retrieval models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6.2.2</span></a>).</p>
</div>
</section>
<section class="ltx_subsection" id="Ch4.S3.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3.2 </span>Dynamic user behavior modeling and profiling</h4>
<div class="ltx_para" id="Ch4.S3.SS2.p1">
<p class="ltx_p" id="Ch4.S3.SS2.p1.1">Most previous studies on e-commerce user behavior modeling and user profiling were conducted under the assumption that a snapshot of user behavior is recorded on e-commerce portals. However, a user’s personal interests and behavior may change over time <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">koren2009collaborative</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gao2013modeling</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yin2014temporal</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">huang2015tencentrec</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yin2015dynamic</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">jagerman2019people</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2021clicks</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">huang2022clickrec</span>]</cite>. Thus, modeling e-commerce users’ temporal behavior is important for e-commerce search and recommendation system development.
Social networks and social media provide a rich source of information for temporal models of user behavior <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mislove2010you</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gao2013modeling</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yin2014temporal</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yin2015dynamic</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">yin2014temporal</span></cite> designed a latent mixture model, which they named a temporal context-aware mixture model, to account for the intentions and preferences that drive user behavior.
It models the topics related to users’ intrinsic interests, and the topics related to temporal context’ it then jointly analyzes the influences of the two factors to model user behavior in a unified way.
To enable the dynamic learning of user profiles, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">cao2017you</span></cite> developed a model that considers multiple information sources and their relations.
Similarly, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">liang2018dynamic-kdd</span></cite> proposed a streaming profiling algorithm that initially applies a user-expertise tracking model to track the changes in the dynamic expertise of users; it then utilizes a keyword diversification algorithm to produce top-<math alttext="k" class="ltx_Math" display="inline" id="Ch4.S3.SS2.p1.1.m1.1"><semantics id="Ch4.S3.SS2.p1.1.m1.1a"><mi id="Ch4.S3.SS2.p1.1.m1.1.1" xref="Ch4.S3.SS2.p1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="Ch4.S3.SS2.p1.1.m1.1b"><ci id="Ch4.S3.SS2.p1.1.m1.1.1.cmml" xref="Ch4.S3.SS2.p1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S3.SS2.p1.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="Ch4.S3.SS2.p1.1.m1.1d">italic_k</annotation></semantics></math> diversified keywords that allow the users’ dynamic expertise to be profiled at a specific timestamp.</p>
</div>
<div class="ltx_para" id="Ch4.S3.SS2.p2">
<p class="ltx_p" id="Ch4.S3.SS2.p2.1">Time and temporal phenomena are valuable sources of information that can facilitate the understanding and prediction of user behavior; this area of research is likely to continue to garner much attention in the near future.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch4.S3.SS3">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3.3 </span>User modeling with insufficient data</h4>
<div class="ltx_para" id="Ch4.S3.SS3.p1">
<p class="ltx_p" id="Ch4.S3.SS3.p1.1">As we have discussed in this chapter, a wide range of click models and ranking methods can be applied to model user click behavior <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chuklin-click-2015</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">borisov2016neural</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ferro2017including</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">he2017neural</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ferro2019boosting</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2022sigirgraph</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">vardasbi-2022-probabilistic</span>]</cite>.
However, the models developed to date tend to require fully labeled data to train the ranking models, although, in realistic e-commerce scenarios, not all of a user’s behavior can be recorded.
Similarly, regarding post-click modeling, purchase-intent prediction, and user-profiling tasks, the reality that there is a limited amount of behavioral data makes it difficult to work with existing click modeling and ranking solutions.
For example, in the case of CVR tasks, the data sparsity problem arises when the number of training samples for the sequential behavior of the form “click <math alttext="\to" class="ltx_Math" display="inline" id="Ch4.S3.SS3.p1.1.m1.1"><semantics id="Ch4.S3.SS3.p1.1.m1.1a"><mo id="Ch4.S3.SS3.p1.1.m1.1.1" stretchy="false" xref="Ch4.S3.SS3.p1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="Ch4.S3.SS3.p1.1.m1.1b"><ci id="Ch4.S3.SS3.p1.1.m1.1.1.cmml" xref="Ch4.S3.SS3.p1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch4.S3.SS3.p1.1.m1.1c">\to</annotation><annotation encoding="application/x-llamapun" id="Ch4.S3.SS3.p1.1.m1.1d">→</annotation></semantics></math> purchase” is insufficient to fit the large parameter space of the CVR task <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2020entire</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2021enhanced</span>]</cite>.
How to enhance user modeling performance under the conditions of a limited amount of imperfectly labeled data remains an important open problem in e-commerce.</p>
</div>
</section>
</section>
</section>
<section class="ltx_chapter" id="Ch5" lang="en">
<h2 class="ltx_title ltx_title_chapter">
<span class="ltx_tag ltx_tag_chapter">Chapter 5 </span>E-commerce search</h2>
<div class="ltx_para" id="Ch5.p1">
<p class="ltx_p" id="Ch5.p1.1">E-commerce search, or simply “product search,” represents a special retrieval scenario where users submit queries to retrieve products from a search engine <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ai2017learning</span>]</cite>.
E-commerce search portals are gaining in popularity as many consumers choose e-commerce search on an e-commerce platform rather than generic web search <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2011towards</span>]</cite>.
Unlike in web search, in e-commerce search there can be millions of results to surface for a given search query <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span>]</cite>.
We have discussed user behavior modeling and user profiling in Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4" title="Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4</span></a> to understand how to explore and exploit information from user behavior.
In this chapter, we focus on the other side of the coin, on search technologies that are based on users’ interactive behavior.
To learn about e-commerce search solutions, we discuss research on query understanding and ranking technologies for e-commerce search.
In Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S1" title="5.1 Characteristics of e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.1</span></a> we summarize characteristics of e-commerce search.
In Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S2" title="5.2 Evaluation metrics ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.2</span></a> we recall key metrics being used for evaluating e-commerce search.
In Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S3" title="5.3 Matching strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.3</span></a> we present studies on representing e-commerce search queries.
Then, we detail e-commerce ranking approaches in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S4" title="5.4 Ranking strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.4</span></a>.
Finally, we discuss emerging research directions in e-commerce search in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S5" title="5.5 Emerging directions ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.5</span></a>.</p>
</div>
<section class="ltx_section" id="Ch5.S1">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5.1 </span>Characteristics of e-commerce search</h3>
<div class="ltx_para" id="Ch5.S1.p1">
<p class="ltx_p" id="Ch5.S1.p1.1">Before detailing related work, we highlight characteristics of e-commerce search. We divide this section into two parts: an overview of e-commerce search, and challenges in e-commerce search.</p>
</div>
<section class="ltx_subsection" id="Ch5.S1.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1.1 </span>Overview of e-commerce search</h4>
<div class="ltx_para" id="Ch5.S1.SS1.p1">
<p class="ltx_p" id="Ch5.S1.SS1.p1.1">Early e-commerce search approaches are based on traditional information retrieval theory and faceted search models <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yee2003faceted</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">jansen2006effectiveness</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">jansen2006effectiveness</span></cite> explored the difference between ad-hoc search and e-commerce search.
A grocery retrieval system was developed by considering a discrepancy between consumers’ shopping lists and retailers’ stock information <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">nurmi2008product</span>]</cite>.
Early on, e-commerce search systems relied on information that retailers make available: either semantic markup on unstructured HTML documents or a data feed provided in some predefined structured format.
Product resolution <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">balog2011investigation</span>]</cite> focuses on recognizing webpages that represent the same product.
Based on the task of product resolution, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">duan2013probabilistic</span></cite> proposed a probabilistic mixture model for mining and analyzing product search logs.
Similar setups can be also found in a product-aware keyword search system <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">duan2013supporting</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch5.S1.SS1.p2">
<p class="ltx_p" id="Ch5.S1.SS1.p2.1">Unlike traditional ad-hoc retrieval, e-commerce search relies on a decision mechanism about consumers’ purchase behavior in e-commerce portals <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2011towards</span>]</cite>.
There are two main stakeholders in e-commerce search, consumers and business owners, whose interests align but also conflict to a certain extent <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">tsagkias-2020-challenges</span>]</cite>.
In e-commerce search, customers do not just browse relevant items, but also try to locate an item that satisfies their specific purchase intent <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2011towards</span>]</cite>.
While consumers aim to find the best quality at the lowest price, businesses want to maximize profit, which translates into higher prices for customers or lower costs for businesses.
E-commerce search typically requires more structured information (e.g., brands, categories, shops, etc.) than web search and more diversified personal definitions of “relevance” during search sessions.
On the one hand, as we have discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S2" title="3.2 E-commerce users ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.2</span></a>, users come to e-commerce websites with a wide spectrum of intents.
Hence, multiple user behavior discussed in Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3" title="Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3</span></a> and Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4" title="Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4</span></a>, e.g., clicks, post-clicks, and purchases, etc., should be integrated to model the “relevance” in e-commerce search.
On the other hand, only a few products are actually purchased by the consumers and different individuals have different opinions even about the same product <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ai2017learning</span>]</cite>.
Thus, e-commerce search should consider users’ differences to satisfy the needs of all consumers.
In general, there are four unique characteristics in e-commerce search:</p>
</div>
<div class="ltx_para" id="Ch5.S1.SS1.p3">
<ul class="ltx_itemize" id="Ch5.S1.I1">
<li class="ltx_item" id="Ch5.S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch5.S1.I1.i1.p1">
<p class="ltx_p" id="Ch5.S1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="Ch5.S1.I1.i1.p1.1.1">Consumer query intent.</span> Similar to web search, queries in e-commerce search can be divided into three classes: navigational, informational and transactional <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2011towards</span>]</cite>. However, e-commerce search queries take a different form. Specifically, navigational queries are product serial numbers and inquiries for customer support; informational queries include leaves in the product taxonomy and product attributes; and transactional queries are a mix of navigational and informational queries. Unlike traditional web search, there are three query intents for e-commerce search: <em class="ltx_emph ltx_font_italic" id="Ch5.S1.I1.i1.p1.1.2">target finding, decision making, and exploration</em> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">su2018user</span>]</cite>. Following the well-known web-search taxonomy due to <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">broder2002taxonomy</span></cite>, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">su2018user</span></cite> proposed a hierarchical e-commerce search taxonomy to explore consumers’ shopping intents, with <em class="ltx_emph ltx_font_italic" id="Ch5.S1.I1.i1.p1.1.3">shallow exploration</em>, <em class="ltx_emph ltx_font_italic" id="Ch5.S1.I1.i1.p1.1.4">targeted purchase</em>, <em class="ltx_emph ltx_font_italic" id="Ch5.S1.I1.i1.p1.1.5">major-item shopping</em>, <em class="ltx_emph ltx_font_italic" id="Ch5.S1.I1.i1.p1.1.6">minor-item shopping</em>, and <em class="ltx_emph ltx_font_italic" id="Ch5.S1.I1.i1.p1.1.7">hard-choice shopping</em>.
The authors found that consumers tend to conduct more focused searches in target finding sessions compared to those in the decision making and exploration sessions.
In target finding sessions, consumers tend to issue a few specific queries and browse only top ranked results; in decision making sessions, consumers tend to issue short queries, browse deep, and click more results; and in exploration sessions consumers issue many diverse queries but do not click often.
Given all these search intents, customized search approaches for each type of search queries can be developed to improve the utility of e-commerce search.</p>
</div>
</li>
<li class="ltx_item" id="Ch5.S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch5.S1.I1.i2.p1">
<p class="ltx_p" id="Ch5.S1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="Ch5.S1.I1.i2.p1.1.1">Heterogeneous consumer behavior.</span> As we have described in Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3" title="Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3</span></a>, multiple types of user behavior can be observed in e-commerce platforms. During an online shopping journey, a consumer may have multiple targets at different stages. During a journey, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">blake2016returns</span></cite> found that e-commerce search proceeds as a kind of “funnel” where, initially, search is along broad categories, and then it becomes more refined to obtain an item at the lowest cost given a consumer’s cost of search. Hence, e-commerce search approaches should be aware of the
stages in each consumer’s journey. Meanwhile, the overall impact of heterogeneous consumer behavior also makes e-commerce search different from traditional web search. Users’ micro behavior, post-click behavior, and engagement make the search intent dynamic and complicated during search sessions <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhouwsdm2018</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="Ch5.S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch5.S1.I1.i3.p1">
<p class="ltx_p" id="Ch5.S1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="Ch5.S1.I1.i3.p1.1.1">Online and offline ranking.</span> Traditional learning to rank methods sort documents according to their relevance to the query.
E-commerce search has an intrinsic difference in the relevance in rankings: the notion of “relevance” is blurred <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span>]</cite>.
Users come to e-commerce platforms with a wide spectrum of intents. Some users wish to make a purchase as soon as possible while others are just wandering around the platform to get inspired. Hence, various kinds of signals, including clicks, favorites, adding carts, purchases, etc., should be integrated to model the relevance in e-commerce search.
E-commerce businesses having both online and physical presence bring a unique blend of infrastructure challenges <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ariannezhad-2021-understanding</span>]</cite>.
Thus, users’ shopping experiences lie in smooth transitions from offline to online and vice versa <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">tsagkias-2020-challenges</span>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="Ch5.S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch5.S1.I1.i4.p1">
<p class="ltx_p" id="Ch5.S1.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="Ch5.S1.I1.i4.p1.1.1">Business criteria and metrics.</span> Most e-commerce platforms apply <em class="ltx_emph ltx_font_italic" id="Ch5.S1.I1.i4.p1.1.2">Gross Merchandise Volume</em> (GMV) as the gold standard for measuring success, which indicates the total amount of sales during e-commerce activities.
Thus, one of the main targets of an e-commerce search algorithm should be to maximize the value of purchases per search session <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span>]</cite>.
Many e-commerce search engines apply a two-stage framework to resolve the whole process into two successive subtasks: a ranking problem and a classification problem <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span>]</cite>.
This two-stage search process on e-commerce platforms makes the optimization more complicated in contrast to web search. In e-commerce, regulatory and business constraints decide which products can be shown to which consumers, whereas competing brands can have agreements with an online retailer to restrict showing their products with those of their competitors. Therefore, it is important to understand consumers’ inventory gaps and provide alternatives in e-commerce search <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">tsagkias-2020-challenges</span>]</cite>.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_subsection" id="Ch5.S1.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1.2 </span>Challenges in e-commerce search</h4>
<div class="ltx_para" id="Ch5.S1.SS2.p1">
<p class="ltx_p" id="Ch5.S1.SS2.p1.1">Based on the above criteria, we see two main challenges in e-commerce search <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">rowley2000product</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">jansen2006effectiveness</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2011towards</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">duan2013probabilistic</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ai2017learning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">trotman2017architecture</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span>]</cite>.
First, there exists a mismatch between users’ queries and product representations where both use different terms to describe the same concepts <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2011towards</span>]</cite>.
This mismatch problem is even more severe in personalized search when more personalized information needs to be considered during retrieval.
Second, the ranking problem in e-commerce search is challenging: multiple types of information sources make ranking products in e-commerce search more complicated than in web search.
Diverse relevance factors make it difficult to use traditional static-ranking evaluation metrics, e.g., NDCG and MAP, to measure the quality of rankings in e-commerce search.</p>
</div>
<div class="ltx_para" id="Ch5.S1.SS2.p2">
<p class="ltx_p" id="Ch5.S1.SS2.p2.1">Recent studies on e-commerce search that aim to tackle the above challenges, focus on one of two aspects <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">trotman2017architecture</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span>]</cite>:

<span class="ltx_inline-enumerate" id="Ch5.S1.I2">
<span class="ltx_inline-item" id="Ch5.S1.I2.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch5.S1.I2.i1.1">matching optimization in e-commerce search, i.e., the vocabulary gap problem, representation-based matching, interaction-based matching, and matching in personalized search; and
</span></span>
<span class="ltx_inline-item" id="Ch5.S1.I2.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch5.S1.I2.i2.1">ranking optimization in e-commerce search, i.e., learning to rank methods and evaluation metrics.
</span></span>
</span>
For real-world e-commerce search, a joint online and offline search framework with both semantic matching and ranking optimization modules is able to outperform traditional search systems at both semantic retrieval and personalized ranking scenarios <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2019semantic</span>]</cite>.
In Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S3" title="5.3 Matching strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S4" title="5.4 Ranking strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.4</span></a>, we summarize recent work on e-commerce search that is aimed at tackling the two research challenge listed above. Prior to that, we introduce the evaluation metrics used to assess e-commerce search in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S2" title="5.2 Evaluation metrics ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.2</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="Ch5.S2">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5.2 </span>Evaluation metrics</h3>
<div class="ltx_para" id="Ch5.S2.p1">
<p class="ltx_p" id="Ch5.S2.p1.1">Evaluation in web search focuses on the relevance to a given query of documents.
E-commerce search provides multiple signals to judge the saliency of items.
Besides for relevance of an item to a given query, revenue-aware features are also considered in e-commerce search evaluation <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span>]</cite>.</p>
</div>
<section class="ltx_subsection" id="Ch5.S2.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2.1 </span>Relevance-based metrics</h4>
<div class="ltx_para" id="Ch5.S2.SS1.p1">
<p class="ltx_p" id="Ch5.S2.SS1.p1.10">Relevance-aware evaluation metrics are in various information retrieval domains <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">schutze2008introduction</span>]</cite>, including in e-commerce search.
It is common to see studies compute evaluation metrics based on the top 100 items retrieved by each e-commerce search model <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ai2017learning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">van2016learning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">van2018mix</span>]</cite>.
Mean average precision (MAP), hit ratio (HR), mean reciprocal rank (MRR), and normalized discounted cumulative gain (NDCG) are four widely-used relevance-aware metrics <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">van2018mix</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span>]</cite>. All these metrics are also widely applied in various information retrieval domains <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">schutze2008introduction</span>]</cite>.
Average precision (AP) computes the average value of Precision over the interval from <math alttext="0" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.1.m1.1"><semantics id="Ch5.S2.SS1.p1.1.m1.1a"><mn id="Ch5.S2.SS1.p1.1.m1.1.1" xref="Ch5.S2.SS1.p1.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.1.m1.1b"><cn id="Ch5.S2.SS1.p1.1.m1.1.1.cmml" type="integer" xref="Ch5.S2.SS1.p1.1.m1.1.1">0</cn></annotation-xml></semantics></math> to <math alttext="1" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.2.m2.1"><semantics id="Ch5.S2.SS1.p1.2.m2.1a"><mn id="Ch5.S2.SS1.p1.2.m2.1.1" xref="Ch5.S2.SS1.p1.2.m2.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.2.m2.1b"><cn id="Ch5.S2.SS1.p1.2.m2.1.1.cmml" type="integer" xref="Ch5.S2.SS1.p1.2.m2.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS1.p1.2.m2.1c">1</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS1.p1.2.m2.1d">1</annotation></semantics></math>. Given <math alttext="k" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.3.m3.1"><semantics id="Ch5.S2.SS1.p1.3.m3.1a"><mi id="Ch5.S2.SS1.p1.3.m3.1.1" xref="Ch5.S2.SS1.p1.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.3.m3.1b"><ci id="Ch5.S2.SS1.p1.3.m3.1.1.cmml" xref="Ch5.S2.SS1.p1.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS1.p1.3.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS1.p1.3.m3.1d">italic_k</annotation></semantics></math> candidate items, <math alttext="AP@k=\sum_{k=1}^{n}{P@k\cdot rel(k)}" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.4.m4.1"><semantics id="Ch5.S2.SS1.p1.4.m4.1a"><mrow id="Ch5.S2.SS1.p1.4.m4.1.2" xref="Ch5.S2.SS1.p1.4.m4.1.2.cmml"><mrow id="Ch5.S2.SS1.p1.4.m4.1.2.2" xref="Ch5.S2.SS1.p1.4.m4.1.2.2.cmml"><mi id="Ch5.S2.SS1.p1.4.m4.1.2.2.2" xref="Ch5.S2.SS1.p1.4.m4.1.2.2.2.cmml">A</mi><mo id="Ch5.S2.SS1.p1.4.m4.1.2.2.1" xref="Ch5.S2.SS1.p1.4.m4.1.2.2.1.cmml">⁢</mo><mi id="Ch5.S2.SS1.p1.4.m4.1.2.2.3" xref="Ch5.S2.SS1.p1.4.m4.1.2.2.3.cmml">P</mi><mo id="Ch5.S2.SS1.p1.4.m4.1.2.2.1a" xref="Ch5.S2.SS1.p1.4.m4.1.2.2.1.cmml">⁢</mo><mi id="Ch5.S2.SS1.p1.4.m4.1.2.2.4" mathvariant="normal" xref="Ch5.S2.SS1.p1.4.m4.1.2.2.4.cmml">@</mi><mo id="Ch5.S2.SS1.p1.4.m4.1.2.2.1b" xref="Ch5.S2.SS1.p1.4.m4.1.2.2.1.cmml">⁢</mo><mi id="Ch5.S2.SS1.p1.4.m4.1.2.2.5" xref="Ch5.S2.SS1.p1.4.m4.1.2.2.5.cmml">k</mi></mrow><mo id="Ch5.S2.SS1.p1.4.m4.1.2.1" rspace="0.111em" xref="Ch5.S2.SS1.p1.4.m4.1.2.1.cmml">=</mo><mrow id="Ch5.S2.SS1.p1.4.m4.1.2.3" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.cmml"><msubsup id="Ch5.S2.SS1.p1.4.m4.1.2.3.1" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.1.cmml"><mo id="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.2" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.2.cmml">∑</mo><mrow id="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.3" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.3.cmml"><mi id="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.3.2" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.3.2.cmml">k</mi><mo id="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.3.1" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.3.1.cmml">=</mo><mn id="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.3.3" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.3.3.cmml">1</mn></mrow><mi id="Ch5.S2.SS1.p1.4.m4.1.2.3.1.3" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.1.3.cmml">n</mi></msubsup><mrow id="Ch5.S2.SS1.p1.4.m4.1.2.3.2" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.cmml"><mrow id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.cmml"><mrow id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2.cmml"><mi id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2.2" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2.2.cmml">P</mi><mo id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2.1" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2.1.cmml">⁢</mo><mi id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2.3" mathvariant="normal" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2.3.cmml">@</mi><mo id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2.1a" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2.1.cmml">⁢</mo><mi id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2.4" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2.4.cmml">k</mi></mrow><mo id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.1" lspace="0.222em" rspace="0.222em" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.1.cmml">⋅</mo><mi id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.3" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.3.cmml">r</mi></mrow><mo id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.1" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.1.cmml">⁢</mo><mi id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.3" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.3.cmml">e</mi><mo id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.1a" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.1.cmml">⁢</mo><mi id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.4" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.4.cmml">l</mi><mo id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.1b" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.1.cmml">⁢</mo><mrow id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.5.2" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.cmml"><mo id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.5.2.1" stretchy="false" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.cmml">(</mo><mi id="Ch5.S2.SS1.p1.4.m4.1.1" xref="Ch5.S2.SS1.p1.4.m4.1.1.cmml">k</mi><mo id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.5.2.2" stretchy="false" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.4.m4.1b"><apply id="Ch5.S2.SS1.p1.4.m4.1.2.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2"><eq id="Ch5.S2.SS1.p1.4.m4.1.2.1.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.1"></eq><apply id="Ch5.S2.SS1.p1.4.m4.1.2.2.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.2"><times id="Ch5.S2.SS1.p1.4.m4.1.2.2.1.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.2.1"></times><ci id="Ch5.S2.SS1.p1.4.m4.1.2.2.2.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.2.2">𝐴</ci><ci id="Ch5.S2.SS1.p1.4.m4.1.2.2.3.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.2.3">𝑃</ci><ci id="Ch5.S2.SS1.p1.4.m4.1.2.2.4.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.2.4">@</ci><ci id="Ch5.S2.SS1.p1.4.m4.1.2.2.5.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.2.5">𝑘</ci></apply><apply id="Ch5.S2.SS1.p1.4.m4.1.2.3.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3"><apply id="Ch5.S2.SS1.p1.4.m4.1.2.3.1.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.1"><csymbol cd="ambiguous" id="Ch5.S2.SS1.p1.4.m4.1.2.3.1.1.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.1">superscript</csymbol><apply id="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.1"><csymbol cd="ambiguous" id="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.1.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.1">subscript</csymbol><sum id="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.2.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.2"></sum><apply id="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.3.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.3"><eq id="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.3.1.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.3.1"></eq><ci id="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.3.2.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.3.2">𝑘</ci><cn id="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.3.3.cmml" type="integer" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.1.2.3.3">1</cn></apply></apply><ci id="Ch5.S2.SS1.p1.4.m4.1.2.3.1.3.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.1.3">𝑛</ci></apply><apply id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2"><times id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.1.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.1"></times><apply id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2"><ci id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.1.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.1">⋅</ci><apply id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2"><times id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2.1.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2.1"></times><ci id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2.2.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2.2">𝑃</ci><ci id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2.3.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2.3">@</ci><ci id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2.4.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.2.4">𝑘</ci></apply><ci id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.3.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.2.3">𝑟</ci></apply><ci id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.3.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.3">𝑒</ci><ci id="Ch5.S2.SS1.p1.4.m4.1.2.3.2.4.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.2.3.2.4">𝑙</ci><ci id="Ch5.S2.SS1.p1.4.m4.1.1.cmml" xref="Ch5.S2.SS1.p1.4.m4.1.1">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS1.p1.4.m4.1c">AP@k=\sum_{k=1}^{n}{P@k\cdot rel(k)}</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS1.p1.4.m4.1d">italic_A italic_P @ italic_k = ∑ start_POSTSUBSCRIPT italic_k = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT italic_P @ italic_k ⋅ italic_r italic_e italic_l ( italic_k )</annotation></semantics></math>, where <math alttext="P@k" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.5.m5.1"><semantics id="Ch5.S2.SS1.p1.5.m5.1a"><mrow id="Ch5.S2.SS1.p1.5.m5.1.1" xref="Ch5.S2.SS1.p1.5.m5.1.1.cmml"><mi id="Ch5.S2.SS1.p1.5.m5.1.1.2" xref="Ch5.S2.SS1.p1.5.m5.1.1.2.cmml">P</mi><mo id="Ch5.S2.SS1.p1.5.m5.1.1.1" xref="Ch5.S2.SS1.p1.5.m5.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS1.p1.5.m5.1.1.3" mathvariant="normal" xref="Ch5.S2.SS1.p1.5.m5.1.1.3.cmml">@</mi><mo id="Ch5.S2.SS1.p1.5.m5.1.1.1a" xref="Ch5.S2.SS1.p1.5.m5.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS1.p1.5.m5.1.1.4" xref="Ch5.S2.SS1.p1.5.m5.1.1.4.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.5.m5.1b"><apply id="Ch5.S2.SS1.p1.5.m5.1.1.cmml" xref="Ch5.S2.SS1.p1.5.m5.1.1"><times id="Ch5.S2.SS1.p1.5.m5.1.1.1.cmml" xref="Ch5.S2.SS1.p1.5.m5.1.1.1"></times><ci id="Ch5.S2.SS1.p1.5.m5.1.1.2.cmml" xref="Ch5.S2.SS1.p1.5.m5.1.1.2">𝑃</ci><ci id="Ch5.S2.SS1.p1.5.m5.1.1.3.cmml" xref="Ch5.S2.SS1.p1.5.m5.1.1.3">@</ci><ci id="Ch5.S2.SS1.p1.5.m5.1.1.4.cmml" xref="Ch5.S2.SS1.p1.5.m5.1.1.4">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS1.p1.5.m5.1c">P@k</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS1.p1.5.m5.1d">italic_P @ italic_k</annotation></semantics></math> refers to Precision@k; <math alttext="rel(k)" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.6.m6.1"><semantics id="Ch5.S2.SS1.p1.6.m6.1a"><mrow id="Ch5.S2.SS1.p1.6.m6.1.2" xref="Ch5.S2.SS1.p1.6.m6.1.2.cmml"><mi id="Ch5.S2.SS1.p1.6.m6.1.2.2" xref="Ch5.S2.SS1.p1.6.m6.1.2.2.cmml">r</mi><mo id="Ch5.S2.SS1.p1.6.m6.1.2.1" xref="Ch5.S2.SS1.p1.6.m6.1.2.1.cmml">⁢</mo><mi id="Ch5.S2.SS1.p1.6.m6.1.2.3" xref="Ch5.S2.SS1.p1.6.m6.1.2.3.cmml">e</mi><mo id="Ch5.S2.SS1.p1.6.m6.1.2.1a" xref="Ch5.S2.SS1.p1.6.m6.1.2.1.cmml">⁢</mo><mi id="Ch5.S2.SS1.p1.6.m6.1.2.4" xref="Ch5.S2.SS1.p1.6.m6.1.2.4.cmml">l</mi><mo id="Ch5.S2.SS1.p1.6.m6.1.2.1b" xref="Ch5.S2.SS1.p1.6.m6.1.2.1.cmml">⁢</mo><mrow id="Ch5.S2.SS1.p1.6.m6.1.2.5.2" xref="Ch5.S2.SS1.p1.6.m6.1.2.cmml"><mo id="Ch5.S2.SS1.p1.6.m6.1.2.5.2.1" stretchy="false" xref="Ch5.S2.SS1.p1.6.m6.1.2.cmml">(</mo><mi id="Ch5.S2.SS1.p1.6.m6.1.1" xref="Ch5.S2.SS1.p1.6.m6.1.1.cmml">k</mi><mo id="Ch5.S2.SS1.p1.6.m6.1.2.5.2.2" stretchy="false" xref="Ch5.S2.SS1.p1.6.m6.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.6.m6.1b"><apply id="Ch5.S2.SS1.p1.6.m6.1.2.cmml" xref="Ch5.S2.SS1.p1.6.m6.1.2"><times id="Ch5.S2.SS1.p1.6.m6.1.2.1.cmml" xref="Ch5.S2.SS1.p1.6.m6.1.2.1"></times><ci id="Ch5.S2.SS1.p1.6.m6.1.2.2.cmml" xref="Ch5.S2.SS1.p1.6.m6.1.2.2">𝑟</ci><ci id="Ch5.S2.SS1.p1.6.m6.1.2.3.cmml" xref="Ch5.S2.SS1.p1.6.m6.1.2.3">𝑒</ci><ci id="Ch5.S2.SS1.p1.6.m6.1.2.4.cmml" xref="Ch5.S2.SS1.p1.6.m6.1.2.4">𝑙</ci><ci id="Ch5.S2.SS1.p1.6.m6.1.1.cmml" xref="Ch5.S2.SS1.p1.6.m6.1.1">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS1.p1.6.m6.1c">rel(k)</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS1.p1.6.m6.1d">italic_r italic_e italic_l ( italic_k )</annotation></semantics></math> indicates <math alttext="1" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.7.m7.1"><semantics id="Ch5.S2.SS1.p1.7.m7.1a"><mn id="Ch5.S2.SS1.p1.7.m7.1.1" xref="Ch5.S2.SS1.p1.7.m7.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.7.m7.1b"><cn id="Ch5.S2.SS1.p1.7.m7.1.1.cmml" type="integer" xref="Ch5.S2.SS1.p1.7.m7.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS1.p1.7.m7.1c">1</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS1.p1.7.m7.1d">1</annotation></semantics></math> if the <math alttext="k" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.8.m8.1"><semantics id="Ch5.S2.SS1.p1.8.m8.1a"><mi id="Ch5.S2.SS1.p1.8.m8.1.1" xref="Ch5.S2.SS1.p1.8.m8.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.8.m8.1b"><ci id="Ch5.S2.SS1.p1.8.m8.1.1.cmml" xref="Ch5.S2.SS1.p1.8.m8.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS1.p1.8.m8.1c">k</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS1.p1.8.m8.1d">italic_k</annotation></semantics></math>-th item is relevant and <math alttext="0" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.9.m9.1"><semantics id="Ch5.S2.SS1.p1.9.m9.1a"><mn id="Ch5.S2.SS1.p1.9.m9.1.1" xref="Ch5.S2.SS1.p1.9.m9.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.9.m9.1b"><cn id="Ch5.S2.SS1.p1.9.m9.1.1.cmml" type="integer" xref="Ch5.S2.SS1.p1.9.m9.1.1">0</cn></annotation-xml></semantics></math> otherwise <math alttext="rel(k)=0" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.10.m10.1"><semantics id="Ch5.S2.SS1.p1.10.m10.1a"><mrow id="Ch5.S2.SS1.p1.10.m10.1.2" xref="Ch5.S2.SS1.p1.10.m10.1.2.cmml"><mrow id="Ch5.S2.SS1.p1.10.m10.1.2.2" xref="Ch5.S2.SS1.p1.10.m10.1.2.2.cmml"><mi id="Ch5.S2.SS1.p1.10.m10.1.2.2.2" xref="Ch5.S2.SS1.p1.10.m10.1.2.2.2.cmml">r</mi><mo id="Ch5.S2.SS1.p1.10.m10.1.2.2.1" xref="Ch5.S2.SS1.p1.10.m10.1.2.2.1.cmml">⁢</mo><mi id="Ch5.S2.SS1.p1.10.m10.1.2.2.3" xref="Ch5.S2.SS1.p1.10.m10.1.2.2.3.cmml">e</mi><mo id="Ch5.S2.SS1.p1.10.m10.1.2.2.1a" xref="Ch5.S2.SS1.p1.10.m10.1.2.2.1.cmml">⁢</mo><mi id="Ch5.S2.SS1.p1.10.m10.1.2.2.4" xref="Ch5.S2.SS1.p1.10.m10.1.2.2.4.cmml">l</mi><mo id="Ch5.S2.SS1.p1.10.m10.1.2.2.1b" xref="Ch5.S2.SS1.p1.10.m10.1.2.2.1.cmml">⁢</mo><mrow id="Ch5.S2.SS1.p1.10.m10.1.2.2.5.2" xref="Ch5.S2.SS1.p1.10.m10.1.2.2.cmml"><mo id="Ch5.S2.SS1.p1.10.m10.1.2.2.5.2.1" stretchy="false" xref="Ch5.S2.SS1.p1.10.m10.1.2.2.cmml">(</mo><mi id="Ch5.S2.SS1.p1.10.m10.1.1" xref="Ch5.S2.SS1.p1.10.m10.1.1.cmml">k</mi><mo id="Ch5.S2.SS1.p1.10.m10.1.2.2.5.2.2" stretchy="false" xref="Ch5.S2.SS1.p1.10.m10.1.2.2.cmml">)</mo></mrow></mrow><mo id="Ch5.S2.SS1.p1.10.m10.1.2.1" xref="Ch5.S2.SS1.p1.10.m10.1.2.1.cmml">=</mo><mn id="Ch5.S2.SS1.p1.10.m10.1.2.3" xref="Ch5.S2.SS1.p1.10.m10.1.2.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.10.m10.1b"><apply id="Ch5.S2.SS1.p1.10.m10.1.2.cmml" xref="Ch5.S2.SS1.p1.10.m10.1.2"><eq id="Ch5.S2.SS1.p1.10.m10.1.2.1.cmml" xref="Ch5.S2.SS1.p1.10.m10.1.2.1"></eq><apply id="Ch5.S2.SS1.p1.10.m10.1.2.2.cmml" xref="Ch5.S2.SS1.p1.10.m10.1.2.2"><times id="Ch5.S2.SS1.p1.10.m10.1.2.2.1.cmml" xref="Ch5.S2.SS1.p1.10.m10.1.2.2.1"></times><ci id="Ch5.S2.SS1.p1.10.m10.1.2.2.2.cmml" xref="Ch5.S2.SS1.p1.10.m10.1.2.2.2">𝑟</ci><ci id="Ch5.S2.SS1.p1.10.m10.1.2.2.3.cmml" xref="Ch5.S2.SS1.p1.10.m10.1.2.2.3">𝑒</ci><ci id="Ch5.S2.SS1.p1.10.m10.1.2.2.4.cmml" xref="Ch5.S2.SS1.p1.10.m10.1.2.2.4">𝑙</ci><ci id="Ch5.S2.SS1.p1.10.m10.1.1.cmml" xref="Ch5.S2.SS1.p1.10.m10.1.1">𝑘</ci></apply><cn id="Ch5.S2.SS1.p1.10.m10.1.2.3.cmml" type="integer" xref="Ch5.S2.SS1.p1.10.m10.1.2.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS1.p1.10.m10.1c">rel(k)=0</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS1.p1.10.m10.1d">italic_r italic_e italic_l ( italic_k ) = 0</annotation></semantics></math>.
Based on that, MAP calculates the mean of AP for all queries:</p>
<table class="ltx_equation ltx_eqn_table" id="Ch5.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathit{MAP}={1\over Q}\sum\limits_{q=1}^{Q}\mathit{AP}_{q}," class="ltx_Math" display="block" id="Ch5.E1.m1.1"><semantics id="Ch5.E1.m1.1a"><mrow id="Ch5.E1.m1.1.1.1" xref="Ch5.E1.m1.1.1.1.1.cmml"><mrow id="Ch5.E1.m1.1.1.1.1" xref="Ch5.E1.m1.1.1.1.1.cmml"><mi id="Ch5.E1.m1.1.1.1.1.2" xref="Ch5.E1.m1.1.1.1.1.2.cmml">𝑀𝐴𝑃</mi><mo id="Ch5.E1.m1.1.1.1.1.1" xref="Ch5.E1.m1.1.1.1.1.1.cmml">=</mo><mrow id="Ch5.E1.m1.1.1.1.1.3" xref="Ch5.E1.m1.1.1.1.1.3.cmml"><mfrac id="Ch5.E1.m1.1.1.1.1.3.2" xref="Ch5.E1.m1.1.1.1.1.3.2.cmml"><mn id="Ch5.E1.m1.1.1.1.1.3.2.2" xref="Ch5.E1.m1.1.1.1.1.3.2.2.cmml">1</mn><mi id="Ch5.E1.m1.1.1.1.1.3.2.3" xref="Ch5.E1.m1.1.1.1.1.3.2.3.cmml">Q</mi></mfrac><mo id="Ch5.E1.m1.1.1.1.1.3.1" xref="Ch5.E1.m1.1.1.1.1.3.1.cmml">⁢</mo><mrow id="Ch5.E1.m1.1.1.1.1.3.3" xref="Ch5.E1.m1.1.1.1.1.3.3.cmml"><munderover id="Ch5.E1.m1.1.1.1.1.3.3.1" xref="Ch5.E1.m1.1.1.1.1.3.3.1.cmml"><mo id="Ch5.E1.m1.1.1.1.1.3.3.1.2.2" movablelimits="false" xref="Ch5.E1.m1.1.1.1.1.3.3.1.2.2.cmml">∑</mo><mrow id="Ch5.E1.m1.1.1.1.1.3.3.1.2.3" xref="Ch5.E1.m1.1.1.1.1.3.3.1.2.3.cmml"><mi id="Ch5.E1.m1.1.1.1.1.3.3.1.2.3.2" xref="Ch5.E1.m1.1.1.1.1.3.3.1.2.3.2.cmml">q</mi><mo id="Ch5.E1.m1.1.1.1.1.3.3.1.2.3.1" xref="Ch5.E1.m1.1.1.1.1.3.3.1.2.3.1.cmml">=</mo><mn id="Ch5.E1.m1.1.1.1.1.3.3.1.2.3.3" xref="Ch5.E1.m1.1.1.1.1.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="Ch5.E1.m1.1.1.1.1.3.3.1.3" xref="Ch5.E1.m1.1.1.1.1.3.3.1.3.cmml">Q</mi></munderover><msub id="Ch5.E1.m1.1.1.1.1.3.3.2" xref="Ch5.E1.m1.1.1.1.1.3.3.2.cmml"><mi id="Ch5.E1.m1.1.1.1.1.3.3.2.2" xref="Ch5.E1.m1.1.1.1.1.3.3.2.2.cmml">𝐴𝑃</mi><mi id="Ch5.E1.m1.1.1.1.1.3.3.2.3" xref="Ch5.E1.m1.1.1.1.1.3.3.2.3.cmml">q</mi></msub></mrow></mrow></mrow><mo id="Ch5.E1.m1.1.1.1.2" xref="Ch5.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch5.E1.m1.1b"><apply id="Ch5.E1.m1.1.1.1.1.cmml" xref="Ch5.E1.m1.1.1.1"><eq id="Ch5.E1.m1.1.1.1.1.1.cmml" xref="Ch5.E1.m1.1.1.1.1.1"></eq><ci id="Ch5.E1.m1.1.1.1.1.2.cmml" xref="Ch5.E1.m1.1.1.1.1.2">𝑀𝐴𝑃</ci><apply id="Ch5.E1.m1.1.1.1.1.3.cmml" xref="Ch5.E1.m1.1.1.1.1.3"><times id="Ch5.E1.m1.1.1.1.1.3.1.cmml" xref="Ch5.E1.m1.1.1.1.1.3.1"></times><apply id="Ch5.E1.m1.1.1.1.1.3.2.cmml" xref="Ch5.E1.m1.1.1.1.1.3.2"><divide id="Ch5.E1.m1.1.1.1.1.3.2.1.cmml" xref="Ch5.E1.m1.1.1.1.1.3.2"></divide><cn id="Ch5.E1.m1.1.1.1.1.3.2.2.cmml" type="integer" xref="Ch5.E1.m1.1.1.1.1.3.2.2">1</cn><ci id="Ch5.E1.m1.1.1.1.1.3.2.3.cmml" xref="Ch5.E1.m1.1.1.1.1.3.2.3">𝑄</ci></apply><apply id="Ch5.E1.m1.1.1.1.1.3.3.cmml" xref="Ch5.E1.m1.1.1.1.1.3.3"><apply id="Ch5.E1.m1.1.1.1.1.3.3.1.cmml" xref="Ch5.E1.m1.1.1.1.1.3.3.1"><csymbol cd="ambiguous" id="Ch5.E1.m1.1.1.1.1.3.3.1.1.cmml" xref="Ch5.E1.m1.1.1.1.1.3.3.1">superscript</csymbol><apply id="Ch5.E1.m1.1.1.1.1.3.3.1.2.cmml" xref="Ch5.E1.m1.1.1.1.1.3.3.1"><csymbol cd="ambiguous" id="Ch5.E1.m1.1.1.1.1.3.3.1.2.1.cmml" xref="Ch5.E1.m1.1.1.1.1.3.3.1">subscript</csymbol><sum id="Ch5.E1.m1.1.1.1.1.3.3.1.2.2.cmml" xref="Ch5.E1.m1.1.1.1.1.3.3.1.2.2"></sum><apply id="Ch5.E1.m1.1.1.1.1.3.3.1.2.3.cmml" xref="Ch5.E1.m1.1.1.1.1.3.3.1.2.3"><eq id="Ch5.E1.m1.1.1.1.1.3.3.1.2.3.1.cmml" xref="Ch5.E1.m1.1.1.1.1.3.3.1.2.3.1"></eq><ci id="Ch5.E1.m1.1.1.1.1.3.3.1.2.3.2.cmml" xref="Ch5.E1.m1.1.1.1.1.3.3.1.2.3.2">𝑞</ci><cn id="Ch5.E1.m1.1.1.1.1.3.3.1.2.3.3.cmml" type="integer" xref="Ch5.E1.m1.1.1.1.1.3.3.1.2.3.3">1</cn></apply></apply><ci id="Ch5.E1.m1.1.1.1.1.3.3.1.3.cmml" xref="Ch5.E1.m1.1.1.1.1.3.3.1.3">𝑄</ci></apply><apply id="Ch5.E1.m1.1.1.1.1.3.3.2.cmml" xref="Ch5.E1.m1.1.1.1.1.3.3.2"><csymbol cd="ambiguous" id="Ch5.E1.m1.1.1.1.1.3.3.2.1.cmml" xref="Ch5.E1.m1.1.1.1.1.3.3.2">subscript</csymbol><ci id="Ch5.E1.m1.1.1.1.1.3.3.2.2.cmml" xref="Ch5.E1.m1.1.1.1.1.3.3.2.2">𝐴𝑃</ci><ci id="Ch5.E1.m1.1.1.1.1.3.3.2.3.cmml" xref="Ch5.E1.m1.1.1.1.1.3.3.2.3">𝑞</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.E1.m1.1c">\mathit{MAP}={1\over Q}\sum\limits_{q=1}^{Q}\mathit{AP}_{q},</annotation><annotation encoding="application/x-llamapun" id="Ch5.E1.m1.1d">italic_MAP = divide start_ARG 1 end_ARG start_ARG italic_Q end_ARG ∑ start_POSTSUBSCRIPT italic_q = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT italic_AP start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5.1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch5.S2.SS1.p1.13">where <math alttext="Q" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.11.m1.1"><semantics id="Ch5.S2.SS1.p1.11.m1.1a"><mi id="Ch5.S2.SS1.p1.11.m1.1.1" xref="Ch5.S2.SS1.p1.11.m1.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.11.m1.1b"><ci id="Ch5.S2.SS1.p1.11.m1.1.1.cmml" xref="Ch5.S2.SS1.p1.11.m1.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS1.p1.11.m1.1c">Q</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS1.p1.11.m1.1d">italic_Q</annotation></semantics></math> denotes the number of queries. HR@<math alttext="k" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.12.m2.1"><semantics id="Ch5.S2.SS1.p1.12.m2.1a"><mi id="Ch5.S2.SS1.p1.12.m2.1.1" xref="Ch5.S2.SS1.p1.12.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.12.m2.1b"><ci id="Ch5.S2.SS1.p1.12.m2.1.1.cmml" xref="Ch5.S2.SS1.p1.12.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS1.p1.12.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS1.p1.12.m2.1d">italic_k</annotation></semantics></math> refers to the fraction of queries for which the relevant item is included in the top-<math alttext="k" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.13.m3.1"><semantics id="Ch5.S2.SS1.p1.13.m3.1a"><mi id="Ch5.S2.SS1.p1.13.m3.1.1" xref="Ch5.S2.SS1.p1.13.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.13.m3.1b"><ci id="Ch5.S2.SS1.p1.13.m3.1.1.cmml" xref="Ch5.S2.SS1.p1.13.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS1.p1.13.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS1.p1.13.m3.1d">italic_k</annotation></semantics></math> results, so we have:</p>
<table class="ltx_equation ltx_eqn_table" id="Ch5.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathit{HR}@k={{|Q_{rel}^{k}|}\over Q}," class="ltx_Math" display="block" id="Ch5.E2.m1.2"><semantics id="Ch5.E2.m1.2a"><mrow id="Ch5.E2.m1.2.2.1" xref="Ch5.E2.m1.2.2.1.1.cmml"><mrow id="Ch5.E2.m1.2.2.1.1" xref="Ch5.E2.m1.2.2.1.1.cmml"><mrow id="Ch5.E2.m1.2.2.1.1.2" xref="Ch5.E2.m1.2.2.1.1.2.cmml"><mi id="Ch5.E2.m1.2.2.1.1.2.2" xref="Ch5.E2.m1.2.2.1.1.2.2.cmml">𝐻𝑅</mi><mo id="Ch5.E2.m1.2.2.1.1.2.1" xref="Ch5.E2.m1.2.2.1.1.2.1.cmml">⁢</mo><mi id="Ch5.E2.m1.2.2.1.1.2.3" mathvariant="normal" xref="Ch5.E2.m1.2.2.1.1.2.3.cmml">@</mi><mo id="Ch5.E2.m1.2.2.1.1.2.1a" xref="Ch5.E2.m1.2.2.1.1.2.1.cmml">⁢</mo><mi id="Ch5.E2.m1.2.2.1.1.2.4" xref="Ch5.E2.m1.2.2.1.1.2.4.cmml">k</mi></mrow><mo id="Ch5.E2.m1.2.2.1.1.1" xref="Ch5.E2.m1.2.2.1.1.1.cmml">=</mo><mfrac id="Ch5.E2.m1.1.1" xref="Ch5.E2.m1.1.1.cmml"><mrow id="Ch5.E2.m1.1.1.1.1" xref="Ch5.E2.m1.1.1.1.2.cmml"><mo id="Ch5.E2.m1.1.1.1.1.2" stretchy="false" xref="Ch5.E2.m1.1.1.1.2.1.cmml">|</mo><msubsup id="Ch5.E2.m1.1.1.1.1.1" xref="Ch5.E2.m1.1.1.1.1.1.cmml"><mi id="Ch5.E2.m1.1.1.1.1.1.2.2" xref="Ch5.E2.m1.1.1.1.1.1.2.2.cmml">Q</mi><mrow id="Ch5.E2.m1.1.1.1.1.1.2.3" xref="Ch5.E2.m1.1.1.1.1.1.2.3.cmml"><mi id="Ch5.E2.m1.1.1.1.1.1.2.3.2" xref="Ch5.E2.m1.1.1.1.1.1.2.3.2.cmml">r</mi><mo id="Ch5.E2.m1.1.1.1.1.1.2.3.1" xref="Ch5.E2.m1.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="Ch5.E2.m1.1.1.1.1.1.2.3.3" xref="Ch5.E2.m1.1.1.1.1.1.2.3.3.cmml">e</mi><mo id="Ch5.E2.m1.1.1.1.1.1.2.3.1a" xref="Ch5.E2.m1.1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="Ch5.E2.m1.1.1.1.1.1.2.3.4" xref="Ch5.E2.m1.1.1.1.1.1.2.3.4.cmml">l</mi></mrow><mi id="Ch5.E2.m1.1.1.1.1.1.3" xref="Ch5.E2.m1.1.1.1.1.1.3.cmml">k</mi></msubsup><mo id="Ch5.E2.m1.1.1.1.1.3" stretchy="false" xref="Ch5.E2.m1.1.1.1.2.1.cmml">|</mo></mrow><mi id="Ch5.E2.m1.1.1.3" xref="Ch5.E2.m1.1.1.3.cmml">Q</mi></mfrac></mrow><mo id="Ch5.E2.m1.2.2.1.2" xref="Ch5.E2.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch5.E2.m1.2b"><apply id="Ch5.E2.m1.2.2.1.1.cmml" xref="Ch5.E2.m1.2.2.1"><eq id="Ch5.E2.m1.2.2.1.1.1.cmml" xref="Ch5.E2.m1.2.2.1.1.1"></eq><apply id="Ch5.E2.m1.2.2.1.1.2.cmml" xref="Ch5.E2.m1.2.2.1.1.2"><times id="Ch5.E2.m1.2.2.1.1.2.1.cmml" xref="Ch5.E2.m1.2.2.1.1.2.1"></times><ci id="Ch5.E2.m1.2.2.1.1.2.2.cmml" xref="Ch5.E2.m1.2.2.1.1.2.2">𝐻𝑅</ci><ci id="Ch5.E2.m1.2.2.1.1.2.3.cmml" xref="Ch5.E2.m1.2.2.1.1.2.3">@</ci><ci id="Ch5.E2.m1.2.2.1.1.2.4.cmml" xref="Ch5.E2.m1.2.2.1.1.2.4">𝑘</ci></apply><apply id="Ch5.E2.m1.1.1.cmml" xref="Ch5.E2.m1.1.1"><divide id="Ch5.E2.m1.1.1.2.cmml" xref="Ch5.E2.m1.1.1"></divide><apply id="Ch5.E2.m1.1.1.1.2.cmml" xref="Ch5.E2.m1.1.1.1.1"><abs id="Ch5.E2.m1.1.1.1.2.1.cmml" xref="Ch5.E2.m1.1.1.1.1.2"></abs><apply id="Ch5.E2.m1.1.1.1.1.1.cmml" xref="Ch5.E2.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="Ch5.E2.m1.1.1.1.1.1.1.cmml" xref="Ch5.E2.m1.1.1.1.1.1">superscript</csymbol><apply id="Ch5.E2.m1.1.1.1.1.1.2.cmml" xref="Ch5.E2.m1.1.1.1.1.1"><csymbol cd="ambiguous" id="Ch5.E2.m1.1.1.1.1.1.2.1.cmml" xref="Ch5.E2.m1.1.1.1.1.1">subscript</csymbol><ci id="Ch5.E2.m1.1.1.1.1.1.2.2.cmml" xref="Ch5.E2.m1.1.1.1.1.1.2.2">𝑄</ci><apply id="Ch5.E2.m1.1.1.1.1.1.2.3.cmml" xref="Ch5.E2.m1.1.1.1.1.1.2.3"><times id="Ch5.E2.m1.1.1.1.1.1.2.3.1.cmml" xref="Ch5.E2.m1.1.1.1.1.1.2.3.1"></times><ci id="Ch5.E2.m1.1.1.1.1.1.2.3.2.cmml" xref="Ch5.E2.m1.1.1.1.1.1.2.3.2">𝑟</ci><ci id="Ch5.E2.m1.1.1.1.1.1.2.3.3.cmml" xref="Ch5.E2.m1.1.1.1.1.1.2.3.3">𝑒</ci><ci id="Ch5.E2.m1.1.1.1.1.1.2.3.4.cmml" xref="Ch5.E2.m1.1.1.1.1.1.2.3.4">𝑙</ci></apply></apply><ci id="Ch5.E2.m1.1.1.1.1.1.3.cmml" xref="Ch5.E2.m1.1.1.1.1.1.3">𝑘</ci></apply></apply><ci id="Ch5.E2.m1.1.1.3.cmml" xref="Ch5.E2.m1.1.1.3">𝑄</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.E2.m1.2c">\mathit{HR}@k={{|Q_{rel}^{k}|}\over Q},</annotation><annotation encoding="application/x-llamapun" id="Ch5.E2.m1.2d">italic_HR @ italic_k = divide start_ARG | italic_Q start_POSTSUBSCRIPT italic_r italic_e italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT | end_ARG start_ARG italic_Q end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5.2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch5.S2.SS1.p1.15">where <math alttext="{|Q_{rel}^{k}|}" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.14.m1.1"><semantics id="Ch5.S2.SS1.p1.14.m1.1a"><mrow id="Ch5.S2.SS1.p1.14.m1.1.1.1" xref="Ch5.S2.SS1.p1.14.m1.1.1.2.cmml"><mo id="Ch5.S2.SS1.p1.14.m1.1.1.1.2" stretchy="false" xref="Ch5.S2.SS1.p1.14.m1.1.1.2.1.cmml">|</mo><msubsup id="Ch5.S2.SS1.p1.14.m1.1.1.1.1" xref="Ch5.S2.SS1.p1.14.m1.1.1.1.1.cmml"><mi id="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.2" xref="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.2.cmml">Q</mi><mrow id="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3" xref="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3.cmml"><mi id="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3.2" xref="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3.2.cmml">r</mi><mo id="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3.1" xref="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3.3" xref="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3.3.cmml">e</mi><mo id="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3.1a" xref="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3.4" xref="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3.4.cmml">l</mi></mrow><mi id="Ch5.S2.SS1.p1.14.m1.1.1.1.1.3" xref="Ch5.S2.SS1.p1.14.m1.1.1.1.1.3.cmml">k</mi></msubsup><mo id="Ch5.S2.SS1.p1.14.m1.1.1.1.3" stretchy="false" xref="Ch5.S2.SS1.p1.14.m1.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.14.m1.1b"><apply id="Ch5.S2.SS1.p1.14.m1.1.1.2.cmml" xref="Ch5.S2.SS1.p1.14.m1.1.1.1"><abs id="Ch5.S2.SS1.p1.14.m1.1.1.2.1.cmml" xref="Ch5.S2.SS1.p1.14.m1.1.1.1.2"></abs><apply id="Ch5.S2.SS1.p1.14.m1.1.1.1.1.cmml" xref="Ch5.S2.SS1.p1.14.m1.1.1.1.1"><csymbol cd="ambiguous" id="Ch5.S2.SS1.p1.14.m1.1.1.1.1.1.cmml" xref="Ch5.S2.SS1.p1.14.m1.1.1.1.1">superscript</csymbol><apply id="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.cmml" xref="Ch5.S2.SS1.p1.14.m1.1.1.1.1"><csymbol cd="ambiguous" id="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.1.cmml" xref="Ch5.S2.SS1.p1.14.m1.1.1.1.1">subscript</csymbol><ci id="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.2.cmml" xref="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.2">𝑄</ci><apply id="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3.cmml" xref="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3"><times id="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3.1.cmml" xref="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3.1"></times><ci id="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3.2.cmml" xref="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3.2">𝑟</ci><ci id="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3.3.cmml" xref="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3.3">𝑒</ci><ci id="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3.4.cmml" xref="Ch5.S2.SS1.p1.14.m1.1.1.1.1.2.3.4">𝑙</ci></apply></apply><ci id="Ch5.S2.SS1.p1.14.m1.1.1.1.1.3.cmml" xref="Ch5.S2.SS1.p1.14.m1.1.1.1.1.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS1.p1.14.m1.1c">{|Q_{rel}^{k}|}</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS1.p1.14.m1.1d">| italic_Q start_POSTSUBSCRIPT italic_r italic_e italic_l end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT |</annotation></semantics></math> denotes the number of queries for which the relevant item is included in the top-<math alttext="k" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.15.m2.1"><semantics id="Ch5.S2.SS1.p1.15.m2.1a"><mi id="Ch5.S2.SS1.p1.15.m2.1.1" xref="Ch5.S2.SS1.p1.15.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.15.m2.1b"><ci id="Ch5.S2.SS1.p1.15.m2.1.1.cmml" xref="Ch5.S2.SS1.p1.15.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS1.p1.15.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS1.p1.15.m2.1d">italic_k</annotation></semantics></math> results. MRR, also known as average reciprocal hit ratio <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">radev2002evaluating</span>]</cite>, evaluates processes where a list of possible responses to a sample of queries ordered by probability of correctness:</p>
<table class="ltx_equation ltx_eqn_table" id="Ch5.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathit{MRR}={1\over Q}\sum_{i=1}^{Q}{1/\mathit{rank}_{i}}," class="ltx_Math" display="block" id="Ch5.E3.m1.1"><semantics id="Ch5.E3.m1.1a"><mrow id="Ch5.E3.m1.1.1.1" xref="Ch5.E3.m1.1.1.1.1.cmml"><mrow id="Ch5.E3.m1.1.1.1.1" xref="Ch5.E3.m1.1.1.1.1.cmml"><mi id="Ch5.E3.m1.1.1.1.1.2" xref="Ch5.E3.m1.1.1.1.1.2.cmml">𝑀𝑅𝑅</mi><mo id="Ch5.E3.m1.1.1.1.1.1" xref="Ch5.E3.m1.1.1.1.1.1.cmml">=</mo><mrow id="Ch5.E3.m1.1.1.1.1.3" xref="Ch5.E3.m1.1.1.1.1.3.cmml"><mfrac id="Ch5.E3.m1.1.1.1.1.3.2" xref="Ch5.E3.m1.1.1.1.1.3.2.cmml"><mn id="Ch5.E3.m1.1.1.1.1.3.2.2" xref="Ch5.E3.m1.1.1.1.1.3.2.2.cmml">1</mn><mi id="Ch5.E3.m1.1.1.1.1.3.2.3" xref="Ch5.E3.m1.1.1.1.1.3.2.3.cmml">Q</mi></mfrac><mo id="Ch5.E3.m1.1.1.1.1.3.1" xref="Ch5.E3.m1.1.1.1.1.3.1.cmml">⁢</mo><mrow id="Ch5.E3.m1.1.1.1.1.3.3" xref="Ch5.E3.m1.1.1.1.1.3.3.cmml"><munderover id="Ch5.E3.m1.1.1.1.1.3.3.1" xref="Ch5.E3.m1.1.1.1.1.3.3.1.cmml"><mo id="Ch5.E3.m1.1.1.1.1.3.3.1.2.2" movablelimits="false" xref="Ch5.E3.m1.1.1.1.1.3.3.1.2.2.cmml">∑</mo><mrow id="Ch5.E3.m1.1.1.1.1.3.3.1.2.3" xref="Ch5.E3.m1.1.1.1.1.3.3.1.2.3.cmml"><mi id="Ch5.E3.m1.1.1.1.1.3.3.1.2.3.2" xref="Ch5.E3.m1.1.1.1.1.3.3.1.2.3.2.cmml">i</mi><mo id="Ch5.E3.m1.1.1.1.1.3.3.1.2.3.1" xref="Ch5.E3.m1.1.1.1.1.3.3.1.2.3.1.cmml">=</mo><mn id="Ch5.E3.m1.1.1.1.1.3.3.1.2.3.3" xref="Ch5.E3.m1.1.1.1.1.3.3.1.2.3.3.cmml">1</mn></mrow><mi id="Ch5.E3.m1.1.1.1.1.3.3.1.3" xref="Ch5.E3.m1.1.1.1.1.3.3.1.3.cmml">Q</mi></munderover><mrow id="Ch5.E3.m1.1.1.1.1.3.3.2" xref="Ch5.E3.m1.1.1.1.1.3.3.2.cmml"><mn id="Ch5.E3.m1.1.1.1.1.3.3.2.2" xref="Ch5.E3.m1.1.1.1.1.3.3.2.2.cmml">1</mn><mo id="Ch5.E3.m1.1.1.1.1.3.3.2.1" xref="Ch5.E3.m1.1.1.1.1.3.3.2.1.cmml">/</mo><msub id="Ch5.E3.m1.1.1.1.1.3.3.2.3" xref="Ch5.E3.m1.1.1.1.1.3.3.2.3.cmml"><mi id="Ch5.E3.m1.1.1.1.1.3.3.2.3.2" xref="Ch5.E3.m1.1.1.1.1.3.3.2.3.2.cmml">𝑟𝑎𝑛𝑘</mi><mi id="Ch5.E3.m1.1.1.1.1.3.3.2.3.3" xref="Ch5.E3.m1.1.1.1.1.3.3.2.3.3.cmml">i</mi></msub></mrow></mrow></mrow></mrow><mo id="Ch5.E3.m1.1.1.1.2" xref="Ch5.E3.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch5.E3.m1.1b"><apply id="Ch5.E3.m1.1.1.1.1.cmml" xref="Ch5.E3.m1.1.1.1"><eq id="Ch5.E3.m1.1.1.1.1.1.cmml" xref="Ch5.E3.m1.1.1.1.1.1"></eq><ci id="Ch5.E3.m1.1.1.1.1.2.cmml" xref="Ch5.E3.m1.1.1.1.1.2">𝑀𝑅𝑅</ci><apply id="Ch5.E3.m1.1.1.1.1.3.cmml" xref="Ch5.E3.m1.1.1.1.1.3"><times id="Ch5.E3.m1.1.1.1.1.3.1.cmml" xref="Ch5.E3.m1.1.1.1.1.3.1"></times><apply id="Ch5.E3.m1.1.1.1.1.3.2.cmml" xref="Ch5.E3.m1.1.1.1.1.3.2"><divide id="Ch5.E3.m1.1.1.1.1.3.2.1.cmml" xref="Ch5.E3.m1.1.1.1.1.3.2"></divide><cn id="Ch5.E3.m1.1.1.1.1.3.2.2.cmml" type="integer" xref="Ch5.E3.m1.1.1.1.1.3.2.2">1</cn><ci id="Ch5.E3.m1.1.1.1.1.3.2.3.cmml" xref="Ch5.E3.m1.1.1.1.1.3.2.3">𝑄</ci></apply><apply id="Ch5.E3.m1.1.1.1.1.3.3.cmml" xref="Ch5.E3.m1.1.1.1.1.3.3"><apply id="Ch5.E3.m1.1.1.1.1.3.3.1.cmml" xref="Ch5.E3.m1.1.1.1.1.3.3.1"><csymbol cd="ambiguous" id="Ch5.E3.m1.1.1.1.1.3.3.1.1.cmml" xref="Ch5.E3.m1.1.1.1.1.3.3.1">superscript</csymbol><apply id="Ch5.E3.m1.1.1.1.1.3.3.1.2.cmml" xref="Ch5.E3.m1.1.1.1.1.3.3.1"><csymbol cd="ambiguous" id="Ch5.E3.m1.1.1.1.1.3.3.1.2.1.cmml" xref="Ch5.E3.m1.1.1.1.1.3.3.1">subscript</csymbol><sum id="Ch5.E3.m1.1.1.1.1.3.3.1.2.2.cmml" xref="Ch5.E3.m1.1.1.1.1.3.3.1.2.2"></sum><apply id="Ch5.E3.m1.1.1.1.1.3.3.1.2.3.cmml" xref="Ch5.E3.m1.1.1.1.1.3.3.1.2.3"><eq id="Ch5.E3.m1.1.1.1.1.3.3.1.2.3.1.cmml" xref="Ch5.E3.m1.1.1.1.1.3.3.1.2.3.1"></eq><ci id="Ch5.E3.m1.1.1.1.1.3.3.1.2.3.2.cmml" xref="Ch5.E3.m1.1.1.1.1.3.3.1.2.3.2">𝑖</ci><cn id="Ch5.E3.m1.1.1.1.1.3.3.1.2.3.3.cmml" type="integer" xref="Ch5.E3.m1.1.1.1.1.3.3.1.2.3.3">1</cn></apply></apply><ci id="Ch5.E3.m1.1.1.1.1.3.3.1.3.cmml" xref="Ch5.E3.m1.1.1.1.1.3.3.1.3">𝑄</ci></apply><apply id="Ch5.E3.m1.1.1.1.1.3.3.2.cmml" xref="Ch5.E3.m1.1.1.1.1.3.3.2"><divide id="Ch5.E3.m1.1.1.1.1.3.3.2.1.cmml" xref="Ch5.E3.m1.1.1.1.1.3.3.2.1"></divide><cn id="Ch5.E3.m1.1.1.1.1.3.3.2.2.cmml" type="integer" xref="Ch5.E3.m1.1.1.1.1.3.3.2.2">1</cn><apply id="Ch5.E3.m1.1.1.1.1.3.3.2.3.cmml" xref="Ch5.E3.m1.1.1.1.1.3.3.2.3"><csymbol cd="ambiguous" id="Ch5.E3.m1.1.1.1.1.3.3.2.3.1.cmml" xref="Ch5.E3.m1.1.1.1.1.3.3.2.3">subscript</csymbol><ci id="Ch5.E3.m1.1.1.1.1.3.3.2.3.2.cmml" xref="Ch5.E3.m1.1.1.1.1.3.3.2.3.2">𝑟𝑎𝑛𝑘</ci><ci id="Ch5.E3.m1.1.1.1.1.3.3.2.3.3.cmml" xref="Ch5.E3.m1.1.1.1.1.3.3.2.3.3">𝑖</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.E3.m1.1c">\mathit{MRR}={1\over Q}\sum_{i=1}^{Q}{1/\mathit{rank}_{i}},</annotation><annotation encoding="application/x-llamapun" id="Ch5.E3.m1.1d">italic_MRR = divide start_ARG 1 end_ARG start_ARG italic_Q end_ARG ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_Q end_POSTSUPERSCRIPT 1 / italic_rank start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5.3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch5.S2.SS1.p1.19">where <math alttext="rank_{i}" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.16.m1.1"><semantics id="Ch5.S2.SS1.p1.16.m1.1a"><mrow id="Ch5.S2.SS1.p1.16.m1.1.1" xref="Ch5.S2.SS1.p1.16.m1.1.1.cmml"><mi id="Ch5.S2.SS1.p1.16.m1.1.1.2" xref="Ch5.S2.SS1.p1.16.m1.1.1.2.cmml">r</mi><mo id="Ch5.S2.SS1.p1.16.m1.1.1.1" xref="Ch5.S2.SS1.p1.16.m1.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS1.p1.16.m1.1.1.3" xref="Ch5.S2.SS1.p1.16.m1.1.1.3.cmml">a</mi><mo id="Ch5.S2.SS1.p1.16.m1.1.1.1a" xref="Ch5.S2.SS1.p1.16.m1.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS1.p1.16.m1.1.1.4" xref="Ch5.S2.SS1.p1.16.m1.1.1.4.cmml">n</mi><mo id="Ch5.S2.SS1.p1.16.m1.1.1.1b" xref="Ch5.S2.SS1.p1.16.m1.1.1.1.cmml">⁢</mo><msub id="Ch5.S2.SS1.p1.16.m1.1.1.5" xref="Ch5.S2.SS1.p1.16.m1.1.1.5.cmml"><mi id="Ch5.S2.SS1.p1.16.m1.1.1.5.2" xref="Ch5.S2.SS1.p1.16.m1.1.1.5.2.cmml">k</mi><mi id="Ch5.S2.SS1.p1.16.m1.1.1.5.3" xref="Ch5.S2.SS1.p1.16.m1.1.1.5.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.16.m1.1b"><apply id="Ch5.S2.SS1.p1.16.m1.1.1.cmml" xref="Ch5.S2.SS1.p1.16.m1.1.1"><times id="Ch5.S2.SS1.p1.16.m1.1.1.1.cmml" xref="Ch5.S2.SS1.p1.16.m1.1.1.1"></times><ci id="Ch5.S2.SS1.p1.16.m1.1.1.2.cmml" xref="Ch5.S2.SS1.p1.16.m1.1.1.2">𝑟</ci><ci id="Ch5.S2.SS1.p1.16.m1.1.1.3.cmml" xref="Ch5.S2.SS1.p1.16.m1.1.1.3">𝑎</ci><ci id="Ch5.S2.SS1.p1.16.m1.1.1.4.cmml" xref="Ch5.S2.SS1.p1.16.m1.1.1.4">𝑛</ci><apply id="Ch5.S2.SS1.p1.16.m1.1.1.5.cmml" xref="Ch5.S2.SS1.p1.16.m1.1.1.5"><csymbol cd="ambiguous" id="Ch5.S2.SS1.p1.16.m1.1.1.5.1.cmml" xref="Ch5.S2.SS1.p1.16.m1.1.1.5">subscript</csymbol><ci id="Ch5.S2.SS1.p1.16.m1.1.1.5.2.cmml" xref="Ch5.S2.SS1.p1.16.m1.1.1.5.2">𝑘</ci><ci id="Ch5.S2.SS1.p1.16.m1.1.1.5.3.cmml" xref="Ch5.S2.SS1.p1.16.m1.1.1.5.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS1.p1.16.m1.1c">rank_{i}</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS1.p1.16.m1.1d">italic_r italic_a italic_n italic_k start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> refers to the rank position of the first relevant document for the <math alttext="i" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.17.m2.1"><semantics id="Ch5.S2.SS1.p1.17.m2.1a"><mi id="Ch5.S2.SS1.p1.17.m2.1.1" xref="Ch5.S2.SS1.p1.17.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.17.m2.1b"><ci id="Ch5.S2.SS1.p1.17.m2.1.1.cmml" xref="Ch5.S2.SS1.p1.17.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS1.p1.17.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS1.p1.17.m2.1d">italic_i</annotation></semantics></math>-th query.
DCG@<math alttext="k" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.18.m3.1"><semantics id="Ch5.S2.SS1.p1.18.m3.1a"><mi id="Ch5.S2.SS1.p1.18.m3.1.1" xref="Ch5.S2.SS1.p1.18.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.18.m3.1b"><ci id="Ch5.S2.SS1.p1.18.m3.1.1.cmml" xref="Ch5.S2.SS1.p1.18.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS1.p1.18.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS1.p1.18.m3.1d">italic_k</annotation></semantics></math> evaluates the relevance of a document based on its position in the top-<math alttext="k" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.19.m4.1"><semantics id="Ch5.S2.SS1.p1.19.m4.1a"><mi id="Ch5.S2.SS1.p1.19.m4.1.1" xref="Ch5.S2.SS1.p1.19.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.19.m4.1b"><ci id="Ch5.S2.SS1.p1.19.m4.1.1.cmml" xref="Ch5.S2.SS1.p1.19.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS1.p1.19.m4.1c">k</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS1.p1.19.m4.1d">italic_k</annotation></semantics></math> results:</p>
<table class="ltx_equation ltx_eqn_table" id="Ch5.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathit{DCG}_{k}=\sum\limits_{i=1}^{k}{{{re{l_{i}}}\over{\log(i+1)}}}," class="ltx_Math" display="block" id="Ch5.E4.m1.3"><semantics id="Ch5.E4.m1.3a"><mrow id="Ch5.E4.m1.3.3.1" xref="Ch5.E4.m1.3.3.1.1.cmml"><mrow id="Ch5.E4.m1.3.3.1.1" xref="Ch5.E4.m1.3.3.1.1.cmml"><msub id="Ch5.E4.m1.3.3.1.1.2" xref="Ch5.E4.m1.3.3.1.1.2.cmml"><mi id="Ch5.E4.m1.3.3.1.1.2.2" xref="Ch5.E4.m1.3.3.1.1.2.2.cmml">𝐷𝐶𝐺</mi><mi id="Ch5.E4.m1.3.3.1.1.2.3" xref="Ch5.E4.m1.3.3.1.1.2.3.cmml">k</mi></msub><mo id="Ch5.E4.m1.3.3.1.1.1" rspace="0.111em" xref="Ch5.E4.m1.3.3.1.1.1.cmml">=</mo><mrow id="Ch5.E4.m1.3.3.1.1.3" xref="Ch5.E4.m1.3.3.1.1.3.cmml"><munderover id="Ch5.E4.m1.3.3.1.1.3.1" xref="Ch5.E4.m1.3.3.1.1.3.1.cmml"><mo id="Ch5.E4.m1.3.3.1.1.3.1.2.2" movablelimits="false" xref="Ch5.E4.m1.3.3.1.1.3.1.2.2.cmml">∑</mo><mrow id="Ch5.E4.m1.3.3.1.1.3.1.2.3" xref="Ch5.E4.m1.3.3.1.1.3.1.2.3.cmml"><mi id="Ch5.E4.m1.3.3.1.1.3.1.2.3.2" xref="Ch5.E4.m1.3.3.1.1.3.1.2.3.2.cmml">i</mi><mo id="Ch5.E4.m1.3.3.1.1.3.1.2.3.1" xref="Ch5.E4.m1.3.3.1.1.3.1.2.3.1.cmml">=</mo><mn id="Ch5.E4.m1.3.3.1.1.3.1.2.3.3" xref="Ch5.E4.m1.3.3.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="Ch5.E4.m1.3.3.1.1.3.1.3" xref="Ch5.E4.m1.3.3.1.1.3.1.3.cmml">k</mi></munderover><mfrac id="Ch5.E4.m1.2.2" xref="Ch5.E4.m1.2.2.cmml"><mrow id="Ch5.E4.m1.2.2.4" xref="Ch5.E4.m1.2.2.4.cmml"><mi id="Ch5.E4.m1.2.2.4.2" xref="Ch5.E4.m1.2.2.4.2.cmml">r</mi><mo id="Ch5.E4.m1.2.2.4.1" xref="Ch5.E4.m1.2.2.4.1.cmml">⁢</mo><mi id="Ch5.E4.m1.2.2.4.3" xref="Ch5.E4.m1.2.2.4.3.cmml">e</mi><mo id="Ch5.E4.m1.2.2.4.1a" xref="Ch5.E4.m1.2.2.4.1.cmml">⁢</mo><msub id="Ch5.E4.m1.2.2.4.4" xref="Ch5.E4.m1.2.2.4.4.cmml"><mi id="Ch5.E4.m1.2.2.4.4.2" xref="Ch5.E4.m1.2.2.4.4.2.cmml">l</mi><mi id="Ch5.E4.m1.2.2.4.4.3" xref="Ch5.E4.m1.2.2.4.4.3.cmml">i</mi></msub></mrow><mrow id="Ch5.E4.m1.2.2.2.2" xref="Ch5.E4.m1.2.2.2.3.cmml"><mi id="Ch5.E4.m1.1.1.1.1" xref="Ch5.E4.m1.1.1.1.1.cmml">log</mi><mo id="Ch5.E4.m1.2.2.2.2a" xref="Ch5.E4.m1.2.2.2.3.cmml">⁡</mo><mrow id="Ch5.E4.m1.2.2.2.2.1" xref="Ch5.E4.m1.2.2.2.3.cmml"><mo id="Ch5.E4.m1.2.2.2.2.1.2" stretchy="false" xref="Ch5.E4.m1.2.2.2.3.cmml">(</mo><mrow id="Ch5.E4.m1.2.2.2.2.1.1" xref="Ch5.E4.m1.2.2.2.2.1.1.cmml"><mi id="Ch5.E4.m1.2.2.2.2.1.1.2" xref="Ch5.E4.m1.2.2.2.2.1.1.2.cmml">i</mi><mo id="Ch5.E4.m1.2.2.2.2.1.1.1" xref="Ch5.E4.m1.2.2.2.2.1.1.1.cmml">+</mo><mn id="Ch5.E4.m1.2.2.2.2.1.1.3" xref="Ch5.E4.m1.2.2.2.2.1.1.3.cmml">1</mn></mrow><mo id="Ch5.E4.m1.2.2.2.2.1.3" stretchy="false" xref="Ch5.E4.m1.2.2.2.3.cmml">)</mo></mrow></mrow></mfrac></mrow></mrow><mo id="Ch5.E4.m1.3.3.1.2" xref="Ch5.E4.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch5.E4.m1.3b"><apply id="Ch5.E4.m1.3.3.1.1.cmml" xref="Ch5.E4.m1.3.3.1"><eq id="Ch5.E4.m1.3.3.1.1.1.cmml" xref="Ch5.E4.m1.3.3.1.1.1"></eq><apply id="Ch5.E4.m1.3.3.1.1.2.cmml" xref="Ch5.E4.m1.3.3.1.1.2"><csymbol cd="ambiguous" id="Ch5.E4.m1.3.3.1.1.2.1.cmml" xref="Ch5.E4.m1.3.3.1.1.2">subscript</csymbol><ci id="Ch5.E4.m1.3.3.1.1.2.2.cmml" xref="Ch5.E4.m1.3.3.1.1.2.2">𝐷𝐶𝐺</ci><ci id="Ch5.E4.m1.3.3.1.1.2.3.cmml" xref="Ch5.E4.m1.3.3.1.1.2.3">𝑘</ci></apply><apply id="Ch5.E4.m1.3.3.1.1.3.cmml" xref="Ch5.E4.m1.3.3.1.1.3"><apply id="Ch5.E4.m1.3.3.1.1.3.1.cmml" xref="Ch5.E4.m1.3.3.1.1.3.1"><csymbol cd="ambiguous" id="Ch5.E4.m1.3.3.1.1.3.1.1.cmml" xref="Ch5.E4.m1.3.3.1.1.3.1">superscript</csymbol><apply id="Ch5.E4.m1.3.3.1.1.3.1.2.cmml" xref="Ch5.E4.m1.3.3.1.1.3.1"><csymbol cd="ambiguous" id="Ch5.E4.m1.3.3.1.1.3.1.2.1.cmml" xref="Ch5.E4.m1.3.3.1.1.3.1">subscript</csymbol><sum id="Ch5.E4.m1.3.3.1.1.3.1.2.2.cmml" xref="Ch5.E4.m1.3.3.1.1.3.1.2.2"></sum><apply id="Ch5.E4.m1.3.3.1.1.3.1.2.3.cmml" xref="Ch5.E4.m1.3.3.1.1.3.1.2.3"><eq id="Ch5.E4.m1.3.3.1.1.3.1.2.3.1.cmml" xref="Ch5.E4.m1.3.3.1.1.3.1.2.3.1"></eq><ci id="Ch5.E4.m1.3.3.1.1.3.1.2.3.2.cmml" xref="Ch5.E4.m1.3.3.1.1.3.1.2.3.2">𝑖</ci><cn id="Ch5.E4.m1.3.3.1.1.3.1.2.3.3.cmml" type="integer" xref="Ch5.E4.m1.3.3.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="Ch5.E4.m1.3.3.1.1.3.1.3.cmml" xref="Ch5.E4.m1.3.3.1.1.3.1.3">𝑘</ci></apply><apply id="Ch5.E4.m1.2.2.cmml" xref="Ch5.E4.m1.2.2"><divide id="Ch5.E4.m1.2.2.3.cmml" xref="Ch5.E4.m1.2.2"></divide><apply id="Ch5.E4.m1.2.2.4.cmml" xref="Ch5.E4.m1.2.2.4"><times id="Ch5.E4.m1.2.2.4.1.cmml" xref="Ch5.E4.m1.2.2.4.1"></times><ci id="Ch5.E4.m1.2.2.4.2.cmml" xref="Ch5.E4.m1.2.2.4.2">𝑟</ci><ci id="Ch5.E4.m1.2.2.4.3.cmml" xref="Ch5.E4.m1.2.2.4.3">𝑒</ci><apply id="Ch5.E4.m1.2.2.4.4.cmml" xref="Ch5.E4.m1.2.2.4.4"><csymbol cd="ambiguous" id="Ch5.E4.m1.2.2.4.4.1.cmml" xref="Ch5.E4.m1.2.2.4.4">subscript</csymbol><ci id="Ch5.E4.m1.2.2.4.4.2.cmml" xref="Ch5.E4.m1.2.2.4.4.2">𝑙</ci><ci id="Ch5.E4.m1.2.2.4.4.3.cmml" xref="Ch5.E4.m1.2.2.4.4.3">𝑖</ci></apply></apply><apply id="Ch5.E4.m1.2.2.2.3.cmml" xref="Ch5.E4.m1.2.2.2.2"><log id="Ch5.E4.m1.1.1.1.1.cmml" xref="Ch5.E4.m1.1.1.1.1"></log><apply id="Ch5.E4.m1.2.2.2.2.1.1.cmml" xref="Ch5.E4.m1.2.2.2.2.1.1"><plus id="Ch5.E4.m1.2.2.2.2.1.1.1.cmml" xref="Ch5.E4.m1.2.2.2.2.1.1.1"></plus><ci id="Ch5.E4.m1.2.2.2.2.1.1.2.cmml" xref="Ch5.E4.m1.2.2.2.2.1.1.2">𝑖</ci><cn id="Ch5.E4.m1.2.2.2.2.1.1.3.cmml" type="integer" xref="Ch5.E4.m1.2.2.2.2.1.1.3">1</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.E4.m1.3c">\mathit{DCG}_{k}=\sum\limits_{i=1}^{k}{{{re{l_{i}}}\over{\log(i+1)}}},</annotation><annotation encoding="application/x-llamapun" id="Ch5.E4.m1.3d">italic_DCG start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT = ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT divide start_ARG italic_r italic_e italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_ARG start_ARG roman_log ( italic_i + 1 ) end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5.4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch5.S2.SS1.p1.22">where <math alttext="rel_{i}" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.20.m1.1"><semantics id="Ch5.S2.SS1.p1.20.m1.1a"><mrow id="Ch5.S2.SS1.p1.20.m1.1.1" xref="Ch5.S2.SS1.p1.20.m1.1.1.cmml"><mi id="Ch5.S2.SS1.p1.20.m1.1.1.2" xref="Ch5.S2.SS1.p1.20.m1.1.1.2.cmml">r</mi><mo id="Ch5.S2.SS1.p1.20.m1.1.1.1" xref="Ch5.S2.SS1.p1.20.m1.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS1.p1.20.m1.1.1.3" xref="Ch5.S2.SS1.p1.20.m1.1.1.3.cmml">e</mi><mo id="Ch5.S2.SS1.p1.20.m1.1.1.1a" xref="Ch5.S2.SS1.p1.20.m1.1.1.1.cmml">⁢</mo><msub id="Ch5.S2.SS1.p1.20.m1.1.1.4" xref="Ch5.S2.SS1.p1.20.m1.1.1.4.cmml"><mi id="Ch5.S2.SS1.p1.20.m1.1.1.4.2" xref="Ch5.S2.SS1.p1.20.m1.1.1.4.2.cmml">l</mi><mi id="Ch5.S2.SS1.p1.20.m1.1.1.4.3" xref="Ch5.S2.SS1.p1.20.m1.1.1.4.3.cmml">i</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.20.m1.1b"><apply id="Ch5.S2.SS1.p1.20.m1.1.1.cmml" xref="Ch5.S2.SS1.p1.20.m1.1.1"><times id="Ch5.S2.SS1.p1.20.m1.1.1.1.cmml" xref="Ch5.S2.SS1.p1.20.m1.1.1.1"></times><ci id="Ch5.S2.SS1.p1.20.m1.1.1.2.cmml" xref="Ch5.S2.SS1.p1.20.m1.1.1.2">𝑟</ci><ci id="Ch5.S2.SS1.p1.20.m1.1.1.3.cmml" xref="Ch5.S2.SS1.p1.20.m1.1.1.3">𝑒</ci><apply id="Ch5.S2.SS1.p1.20.m1.1.1.4.cmml" xref="Ch5.S2.SS1.p1.20.m1.1.1.4"><csymbol cd="ambiguous" id="Ch5.S2.SS1.p1.20.m1.1.1.4.1.cmml" xref="Ch5.S2.SS1.p1.20.m1.1.1.4">subscript</csymbol><ci id="Ch5.S2.SS1.p1.20.m1.1.1.4.2.cmml" xref="Ch5.S2.SS1.p1.20.m1.1.1.4.2">𝑙</ci><ci id="Ch5.S2.SS1.p1.20.m1.1.1.4.3.cmml" xref="Ch5.S2.SS1.p1.20.m1.1.1.4.3">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS1.p1.20.m1.1c">rel_{i}</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS1.p1.20.m1.1d">italic_r italic_e italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> indicates the relevance of the document at position <math alttext="i" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.21.m2.1"><semantics id="Ch5.S2.SS1.p1.21.m2.1a"><mi id="Ch5.S2.SS1.p1.21.m2.1.1" xref="Ch5.S2.SS1.p1.21.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.21.m2.1b"><ci id="Ch5.S2.SS1.p1.21.m2.1.1.cmml" xref="Ch5.S2.SS1.p1.21.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS1.p1.21.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS1.p1.21.m2.1d">italic_i</annotation></semantics></math>. Ideal DCG (IDCG) is the DCG score for the ideal ranking, which is ranking the items top down according their relevance up to position <math alttext="k" class="ltx_Math" display="inline" id="Ch5.S2.SS1.p1.22.m3.1"><semantics id="Ch5.S2.SS1.p1.22.m3.1a"><mi id="Ch5.S2.SS1.p1.22.m3.1.1" xref="Ch5.S2.SS1.p1.22.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS1.p1.22.m3.1b"><ci id="Ch5.S2.SS1.p1.22.m3.1.1.cmml" xref="Ch5.S2.SS1.p1.22.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS1.p1.22.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS1.p1.22.m3.1d">italic_k</annotation></semantics></math>. NDCG allows one to compare the performance across different queries, using normalization of DCG by IDCG:</p>
<table class="ltx_equation ltx_eqn_table" id="Ch5.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathit{NDCG}@k={\mathit{DCG}_{k}\over\mathit{IDCG}_{k}}," class="ltx_Math" display="block" id="Ch5.E5.m1.1"><semantics id="Ch5.E5.m1.1a"><mrow id="Ch5.E5.m1.1.1.1" xref="Ch5.E5.m1.1.1.1.1.cmml"><mrow id="Ch5.E5.m1.1.1.1.1" xref="Ch5.E5.m1.1.1.1.1.cmml"><mrow id="Ch5.E5.m1.1.1.1.1.2" xref="Ch5.E5.m1.1.1.1.1.2.cmml"><mi id="Ch5.E5.m1.1.1.1.1.2.2" xref="Ch5.E5.m1.1.1.1.1.2.2.cmml">𝑁𝐷𝐶𝐺</mi><mo id="Ch5.E5.m1.1.1.1.1.2.1" xref="Ch5.E5.m1.1.1.1.1.2.1.cmml">⁢</mo><mi id="Ch5.E5.m1.1.1.1.1.2.3" mathvariant="normal" xref="Ch5.E5.m1.1.1.1.1.2.3.cmml">@</mi><mo id="Ch5.E5.m1.1.1.1.1.2.1a" xref="Ch5.E5.m1.1.1.1.1.2.1.cmml">⁢</mo><mi id="Ch5.E5.m1.1.1.1.1.2.4" xref="Ch5.E5.m1.1.1.1.1.2.4.cmml">k</mi></mrow><mo id="Ch5.E5.m1.1.1.1.1.1" xref="Ch5.E5.m1.1.1.1.1.1.cmml">=</mo><mfrac id="Ch5.E5.m1.1.1.1.1.3" xref="Ch5.E5.m1.1.1.1.1.3.cmml"><msub id="Ch5.E5.m1.1.1.1.1.3.2" xref="Ch5.E5.m1.1.1.1.1.3.2.cmml"><mi id="Ch5.E5.m1.1.1.1.1.3.2.2" xref="Ch5.E5.m1.1.1.1.1.3.2.2.cmml">𝐷𝐶𝐺</mi><mi id="Ch5.E5.m1.1.1.1.1.3.2.3" xref="Ch5.E5.m1.1.1.1.1.3.2.3.cmml">k</mi></msub><msub id="Ch5.E5.m1.1.1.1.1.3.3" xref="Ch5.E5.m1.1.1.1.1.3.3.cmml"><mi id="Ch5.E5.m1.1.1.1.1.3.3.2" xref="Ch5.E5.m1.1.1.1.1.3.3.2.cmml">𝐼𝐷𝐶𝐺</mi><mi id="Ch5.E5.m1.1.1.1.1.3.3.3" xref="Ch5.E5.m1.1.1.1.1.3.3.3.cmml">k</mi></msub></mfrac></mrow><mo id="Ch5.E5.m1.1.1.1.2" xref="Ch5.E5.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch5.E5.m1.1b"><apply id="Ch5.E5.m1.1.1.1.1.cmml" xref="Ch5.E5.m1.1.1.1"><eq id="Ch5.E5.m1.1.1.1.1.1.cmml" xref="Ch5.E5.m1.1.1.1.1.1"></eq><apply id="Ch5.E5.m1.1.1.1.1.2.cmml" xref="Ch5.E5.m1.1.1.1.1.2"><times id="Ch5.E5.m1.1.1.1.1.2.1.cmml" xref="Ch5.E5.m1.1.1.1.1.2.1"></times><ci id="Ch5.E5.m1.1.1.1.1.2.2.cmml" xref="Ch5.E5.m1.1.1.1.1.2.2">𝑁𝐷𝐶𝐺</ci><ci id="Ch5.E5.m1.1.1.1.1.2.3.cmml" xref="Ch5.E5.m1.1.1.1.1.2.3">@</ci><ci id="Ch5.E5.m1.1.1.1.1.2.4.cmml" xref="Ch5.E5.m1.1.1.1.1.2.4">𝑘</ci></apply><apply id="Ch5.E5.m1.1.1.1.1.3.cmml" xref="Ch5.E5.m1.1.1.1.1.3"><divide id="Ch5.E5.m1.1.1.1.1.3.1.cmml" xref="Ch5.E5.m1.1.1.1.1.3"></divide><apply id="Ch5.E5.m1.1.1.1.1.3.2.cmml" xref="Ch5.E5.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="Ch5.E5.m1.1.1.1.1.3.2.1.cmml" xref="Ch5.E5.m1.1.1.1.1.3.2">subscript</csymbol><ci id="Ch5.E5.m1.1.1.1.1.3.2.2.cmml" xref="Ch5.E5.m1.1.1.1.1.3.2.2">𝐷𝐶𝐺</ci><ci id="Ch5.E5.m1.1.1.1.1.3.2.3.cmml" xref="Ch5.E5.m1.1.1.1.1.3.2.3">𝑘</ci></apply><apply id="Ch5.E5.m1.1.1.1.1.3.3.cmml" xref="Ch5.E5.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="Ch5.E5.m1.1.1.1.1.3.3.1.cmml" xref="Ch5.E5.m1.1.1.1.1.3.3">subscript</csymbol><ci id="Ch5.E5.m1.1.1.1.1.3.3.2.cmml" xref="Ch5.E5.m1.1.1.1.1.3.3.2">𝐼𝐷𝐶𝐺</ci><ci id="Ch5.E5.m1.1.1.1.1.3.3.3.cmml" xref="Ch5.E5.m1.1.1.1.1.3.3.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.E5.m1.1c">\mathit{NDCG}@k={\mathit{DCG}_{k}\over\mathit{IDCG}_{k}},</annotation><annotation encoding="application/x-llamapun" id="Ch5.E5.m1.1d">italic_NDCG @ italic_k = divide start_ARG italic_DCG start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_ARG start_ARG italic_IDCG start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5.5)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section class="ltx_subsection" id="Ch5.S2.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2.2 </span>Revenue-aware metrics</h4>
<div class="ltx_para" id="Ch5.S2.SS2.p1">
<p class="ltx_p" id="Ch5.S2.SS2.p1.3">GMV indicates the total income amount transacted from merchandise sales, whereas the overall revenue generated for the e-commerce site is proportional to the GMV <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span>]</cite>.
Revenue-aware metrics are applied to e-commerce search evaluation to evaluate how the methods can improve the actual revenue of search sessions.
To calculate the average revenue for every impression in each e-commerce search session, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span></cite> proposed the average revenue metric, <math alttext="Avg.Rev" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p1.1.m1.2"><semantics id="Ch5.S2.SS2.p1.1.m1.2a"><mrow id="Ch5.S2.SS2.p1.1.m1.2.2.2" xref="Ch5.S2.SS2.p1.1.m1.2.2.3.cmml"><mrow id="Ch5.S2.SS2.p1.1.m1.1.1.1.1" xref="Ch5.S2.SS2.p1.1.m1.1.1.1.1.cmml"><mi id="Ch5.S2.SS2.p1.1.m1.1.1.1.1.2" xref="Ch5.S2.SS2.p1.1.m1.1.1.1.1.2.cmml">A</mi><mo id="Ch5.S2.SS2.p1.1.m1.1.1.1.1.1" xref="Ch5.S2.SS2.p1.1.m1.1.1.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p1.1.m1.1.1.1.1.3" xref="Ch5.S2.SS2.p1.1.m1.1.1.1.1.3.cmml">v</mi><mo id="Ch5.S2.SS2.p1.1.m1.1.1.1.1.1a" xref="Ch5.S2.SS2.p1.1.m1.1.1.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p1.1.m1.1.1.1.1.4" xref="Ch5.S2.SS2.p1.1.m1.1.1.1.1.4.cmml">g</mi></mrow><mo id="Ch5.S2.SS2.p1.1.m1.2.2.2.3" lspace="0em" rspace="0.167em" xref="Ch5.S2.SS2.p1.1.m1.2.2.3a.cmml">.</mo><mrow id="Ch5.S2.SS2.p1.1.m1.2.2.2.2" xref="Ch5.S2.SS2.p1.1.m1.2.2.2.2.cmml"><mi id="Ch5.S2.SS2.p1.1.m1.2.2.2.2.2" xref="Ch5.S2.SS2.p1.1.m1.2.2.2.2.2.cmml">R</mi><mo id="Ch5.S2.SS2.p1.1.m1.2.2.2.2.1" xref="Ch5.S2.SS2.p1.1.m1.2.2.2.2.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p1.1.m1.2.2.2.2.3" xref="Ch5.S2.SS2.p1.1.m1.2.2.2.2.3.cmml">e</mi><mo id="Ch5.S2.SS2.p1.1.m1.2.2.2.2.1a" xref="Ch5.S2.SS2.p1.1.m1.2.2.2.2.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p1.1.m1.2.2.2.2.4" xref="Ch5.S2.SS2.p1.1.m1.2.2.2.2.4.cmml">v</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p1.1.m1.2b"><apply id="Ch5.S2.SS2.p1.1.m1.2.2.3.cmml" xref="Ch5.S2.SS2.p1.1.m1.2.2.2"><csymbol cd="ambiguous" id="Ch5.S2.SS2.p1.1.m1.2.2.3a.cmml" xref="Ch5.S2.SS2.p1.1.m1.2.2.2.3">formulae-sequence</csymbol><apply id="Ch5.S2.SS2.p1.1.m1.1.1.1.1.cmml" xref="Ch5.S2.SS2.p1.1.m1.1.1.1.1"><times id="Ch5.S2.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="Ch5.S2.SS2.p1.1.m1.1.1.1.1.1"></times><ci id="Ch5.S2.SS2.p1.1.m1.1.1.1.1.2.cmml" xref="Ch5.S2.SS2.p1.1.m1.1.1.1.1.2">𝐴</ci><ci id="Ch5.S2.SS2.p1.1.m1.1.1.1.1.3.cmml" xref="Ch5.S2.SS2.p1.1.m1.1.1.1.1.3">𝑣</ci><ci id="Ch5.S2.SS2.p1.1.m1.1.1.1.1.4.cmml" xref="Ch5.S2.SS2.p1.1.m1.1.1.1.1.4">𝑔</ci></apply><apply id="Ch5.S2.SS2.p1.1.m1.2.2.2.2.cmml" xref="Ch5.S2.SS2.p1.1.m1.2.2.2.2"><times id="Ch5.S2.SS2.p1.1.m1.2.2.2.2.1.cmml" xref="Ch5.S2.SS2.p1.1.m1.2.2.2.2.1"></times><ci id="Ch5.S2.SS2.p1.1.m1.2.2.2.2.2.cmml" xref="Ch5.S2.SS2.p1.1.m1.2.2.2.2.2">𝑅</ci><ci id="Ch5.S2.SS2.p1.1.m1.2.2.2.2.3.cmml" xref="Ch5.S2.SS2.p1.1.m1.2.2.2.2.3">𝑒</ci><ci id="Ch5.S2.SS2.p1.1.m1.2.2.2.2.4.cmml" xref="Ch5.S2.SS2.p1.1.m1.2.2.2.2.4">𝑣</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p1.1.m1.2c">Avg.Rev</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p1.1.m1.2d">italic_A italic_v italic_g . italic_R italic_e italic_v</annotation></semantics></math> <math alttext="(i,q)" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p1.2.m2.2"><semantics id="Ch5.S2.SS2.p1.2.m2.2a"><mrow id="Ch5.S2.SS2.p1.2.m2.2.3.2" xref="Ch5.S2.SS2.p1.2.m2.2.3.1.cmml"><mo id="Ch5.S2.SS2.p1.2.m2.2.3.2.1" stretchy="false" xref="Ch5.S2.SS2.p1.2.m2.2.3.1.cmml">(</mo><mi id="Ch5.S2.SS2.p1.2.m2.1.1" xref="Ch5.S2.SS2.p1.2.m2.1.1.cmml">i</mi><mo id="Ch5.S2.SS2.p1.2.m2.2.3.2.2" xref="Ch5.S2.SS2.p1.2.m2.2.3.1.cmml">,</mo><mi id="Ch5.S2.SS2.p1.2.m2.2.2" xref="Ch5.S2.SS2.p1.2.m2.2.2.cmml">q</mi><mo id="Ch5.S2.SS2.p1.2.m2.2.3.2.3" stretchy="false" xref="Ch5.S2.SS2.p1.2.m2.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p1.2.m2.2b"><interval closure="open" id="Ch5.S2.SS2.p1.2.m2.2.3.1.cmml" xref="Ch5.S2.SS2.p1.2.m2.2.3.2"><ci id="Ch5.S2.SS2.p1.2.m2.1.1.cmml" xref="Ch5.S2.SS2.p1.2.m2.1.1">𝑖</ci><ci id="Ch5.S2.SS2.p1.2.m2.2.2.cmml" xref="Ch5.S2.SS2.p1.2.m2.2.2">𝑞</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p1.2.m2.2c">(i,q)</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p1.2.m2.2d">( italic_i , italic_q )</annotation></semantics></math>, for a query-item pair <math alttext="(i,q)" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p1.3.m3.2"><semantics id="Ch5.S2.SS2.p1.3.m3.2a"><mrow id="Ch5.S2.SS2.p1.3.m3.2.3.2" xref="Ch5.S2.SS2.p1.3.m3.2.3.1.cmml"><mo id="Ch5.S2.SS2.p1.3.m3.2.3.2.1" stretchy="false" xref="Ch5.S2.SS2.p1.3.m3.2.3.1.cmml">(</mo><mi id="Ch5.S2.SS2.p1.3.m3.1.1" xref="Ch5.S2.SS2.p1.3.m3.1.1.cmml">i</mi><mo id="Ch5.S2.SS2.p1.3.m3.2.3.2.2" xref="Ch5.S2.SS2.p1.3.m3.2.3.1.cmml">,</mo><mi id="Ch5.S2.SS2.p1.3.m3.2.2" xref="Ch5.S2.SS2.p1.3.m3.2.2.cmml">q</mi><mo id="Ch5.S2.SS2.p1.3.m3.2.3.2.3" stretchy="false" xref="Ch5.S2.SS2.p1.3.m3.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p1.3.m3.2b"><interval closure="open" id="Ch5.S2.SS2.p1.3.m3.2.3.1.cmml" xref="Ch5.S2.SS2.p1.3.m3.2.3.2"><ci id="Ch5.S2.SS2.p1.3.m3.1.1.cmml" xref="Ch5.S2.SS2.p1.3.m3.1.1">𝑖</ci><ci id="Ch5.S2.SS2.p1.3.m3.2.2.cmml" xref="Ch5.S2.SS2.p1.3.m3.2.2">𝑞</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p1.3.m3.2c">(i,q)</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p1.3.m3.2d">( italic_i , italic_q )</annotation></semantics></math> as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="Ch5.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="Avg.Rev\left(i,q\right)=\frac{price\left(i\right)\times purchase\left(i,q%
\right)}{\left|S_{q}|i\in S_{q}\right|}," class="ltx_math_unparsed" display="block" id="Ch5.E6.m1.6"><semantics id="Ch5.E6.m1.6a"><mrow id="Ch5.E6.m1.6.6.1"><mrow id="Ch5.E6.m1.6.6.1.1.2"><mrow id="Ch5.E6.m1.6.6.1.1.1.1"><mi id="Ch5.E6.m1.6.6.1.1.1.1.2">A</mi><mo id="Ch5.E6.m1.6.6.1.1.1.1.1">⁢</mo><mi id="Ch5.E6.m1.6.6.1.1.1.1.3">v</mi><mo id="Ch5.E6.m1.6.6.1.1.1.1.1a">⁢</mo><mi id="Ch5.E6.m1.6.6.1.1.1.1.4">g</mi></mrow><mo id="Ch5.E6.m1.6.6.1.1.2.3" lspace="0em" rspace="0.167em">.</mo><mrow id="Ch5.E6.m1.6.6.1.1.2.2"><mrow id="Ch5.E6.m1.6.6.1.1.2.2.2"><mi id="Ch5.E6.m1.6.6.1.1.2.2.2.2">R</mi><mo id="Ch5.E6.m1.6.6.1.1.2.2.2.1">⁢</mo><mi id="Ch5.E6.m1.6.6.1.1.2.2.2.3">e</mi><mo id="Ch5.E6.m1.6.6.1.1.2.2.2.1a">⁢</mo><mi id="Ch5.E6.m1.6.6.1.1.2.2.2.4">v</mi><mo id="Ch5.E6.m1.6.6.1.1.2.2.2.1b">⁢</mo><mrow id="Ch5.E6.m1.6.6.1.1.2.2.2.5.2"><mo id="Ch5.E6.m1.6.6.1.1.2.2.2.5.2.1">(</mo><mi id="Ch5.E6.m1.4.4">i</mi><mo id="Ch5.E6.m1.6.6.1.1.2.2.2.5.2.2">,</mo><mi id="Ch5.E6.m1.5.5">q</mi><mo id="Ch5.E6.m1.6.6.1.1.2.2.2.5.2.3">)</mo></mrow></mrow><mo id="Ch5.E6.m1.6.6.1.1.2.2.1">=</mo><mfrac id="Ch5.E6.m1.3.3"><mrow id="Ch5.E6.m1.3.3.3"><mrow id="Ch5.E6.m1.3.3.3.5"><mrow id="Ch5.E6.m1.3.3.3.5.2"><mi id="Ch5.E6.m1.3.3.3.5.2.2">p</mi><mo id="Ch5.E6.m1.3.3.3.5.2.1">⁢</mo><mi id="Ch5.E6.m1.3.3.3.5.2.3">r</mi><mo id="Ch5.E6.m1.3.3.3.5.2.1a">⁢</mo><mi id="Ch5.E6.m1.3.3.3.5.2.4">i</mi><mo id="Ch5.E6.m1.3.3.3.5.2.1b">⁢</mo><mi id="Ch5.E6.m1.3.3.3.5.2.5">c</mi><mo id="Ch5.E6.m1.3.3.3.5.2.1c">⁢</mo><mi id="Ch5.E6.m1.3.3.3.5.2.6">e</mi><mo id="Ch5.E6.m1.3.3.3.5.2.1d">⁢</mo><mrow id="Ch5.E6.m1.3.3.3.5.2.7.2"><mo id="Ch5.E6.m1.3.3.3.5.2.7.2.1">(</mo><mi id="Ch5.E6.m1.1.1.1.1">i</mi><mo id="Ch5.E6.m1.3.3.3.5.2.7.2.2" rspace="0.055em">)</mo></mrow></mrow><mo id="Ch5.E6.m1.3.3.3.5.1" rspace="0.222em">×</mo><mi id="Ch5.E6.m1.3.3.3.5.3">p</mi></mrow><mo id="Ch5.E6.m1.3.3.3.4">⁢</mo><mi id="Ch5.E6.m1.3.3.3.6">u</mi><mo id="Ch5.E6.m1.3.3.3.4a">⁢</mo><mi id="Ch5.E6.m1.3.3.3.7">r</mi><mo id="Ch5.E6.m1.3.3.3.4b">⁢</mo><mi id="Ch5.E6.m1.3.3.3.8">c</mi><mo id="Ch5.E6.m1.3.3.3.4c">⁢</mo><mi id="Ch5.E6.m1.3.3.3.9">h</mi><mo id="Ch5.E6.m1.3.3.3.4d">⁢</mo><mi id="Ch5.E6.m1.3.3.3.10">a</mi><mo id="Ch5.E6.m1.3.3.3.4e">⁢</mo><mi id="Ch5.E6.m1.3.3.3.11">s</mi><mo id="Ch5.E6.m1.3.3.3.4f">⁢</mo><mi id="Ch5.E6.m1.3.3.3.12">e</mi><mo id="Ch5.E6.m1.3.3.3.4g">⁢</mo><mrow id="Ch5.E6.m1.3.3.3.13.2"><mo id="Ch5.E6.m1.3.3.3.13.2.1">(</mo><mi id="Ch5.E6.m1.2.2.2.2">i</mi><mo id="Ch5.E6.m1.3.3.3.13.2.2">,</mo><mi id="Ch5.E6.m1.3.3.3.3">q</mi><mo id="Ch5.E6.m1.3.3.3.13.2.3">)</mo></mrow></mrow><mrow id="Ch5.E6.m1.3.3.5"><mo fence="false" id="Ch5.E6.m1.3.3.5.1" rspace="0.167em">|</mo><msub id="Ch5.E6.m1.3.3.5.2"><mi id="Ch5.E6.m1.3.3.5.2.2">S</mi><mi id="Ch5.E6.m1.3.3.5.2.3">q</mi></msub><mo fence="false" id="Ch5.E6.m1.3.3.5.3" rspace="0.167em" stretchy="false">|</mo><mi id="Ch5.E6.m1.3.3.5.4">i</mi><mo id="Ch5.E6.m1.3.3.5.5">∈</mo><msub id="Ch5.E6.m1.3.3.5.6"><mi id="Ch5.E6.m1.3.3.5.6.2">S</mi><mi id="Ch5.E6.m1.3.3.5.6.3">q</mi></msub><mo fence="false" id="Ch5.E6.m1.3.3.5.7">|</mo></mrow></mfrac></mrow></mrow><mo id="Ch5.E6.m1.6.6.1.2">,</mo></mrow><annotation encoding="application/x-tex" id="Ch5.E6.m1.6b">Avg.Rev\left(i,q\right)=\frac{price\left(i\right)\times purchase\left(i,q%
\right)}{\left|S_{q}|i\in S_{q}\right|},</annotation><annotation encoding="application/x-llamapun" id="Ch5.E6.m1.6c">italic_A italic_v italic_g . italic_R italic_e italic_v ( italic_i , italic_q ) = divide start_ARG italic_p italic_r italic_i italic_c italic_e ( italic_i ) × italic_p italic_u italic_r italic_c italic_h italic_a italic_s italic_e ( italic_i , italic_q ) end_ARG start_ARG | italic_S start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT | italic_i ∈ italic_S start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT | end_ARG ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5.6)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch5.S2.SS2.p1.9">where <math alttext="purchase\left(i,q\right)" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p1.4.m1.2"><semantics id="Ch5.S2.SS2.p1.4.m1.2a"><mrow id="Ch5.S2.SS2.p1.4.m1.2.3" xref="Ch5.S2.SS2.p1.4.m1.2.3.cmml"><mi id="Ch5.S2.SS2.p1.4.m1.2.3.2" xref="Ch5.S2.SS2.p1.4.m1.2.3.2.cmml">p</mi><mo id="Ch5.S2.SS2.p1.4.m1.2.3.1" xref="Ch5.S2.SS2.p1.4.m1.2.3.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p1.4.m1.2.3.3" xref="Ch5.S2.SS2.p1.4.m1.2.3.3.cmml">u</mi><mo id="Ch5.S2.SS2.p1.4.m1.2.3.1a" xref="Ch5.S2.SS2.p1.4.m1.2.3.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p1.4.m1.2.3.4" xref="Ch5.S2.SS2.p1.4.m1.2.3.4.cmml">r</mi><mo id="Ch5.S2.SS2.p1.4.m1.2.3.1b" xref="Ch5.S2.SS2.p1.4.m1.2.3.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p1.4.m1.2.3.5" xref="Ch5.S2.SS2.p1.4.m1.2.3.5.cmml">c</mi><mo id="Ch5.S2.SS2.p1.4.m1.2.3.1c" xref="Ch5.S2.SS2.p1.4.m1.2.3.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p1.4.m1.2.3.6" xref="Ch5.S2.SS2.p1.4.m1.2.3.6.cmml">h</mi><mo id="Ch5.S2.SS2.p1.4.m1.2.3.1d" xref="Ch5.S2.SS2.p1.4.m1.2.3.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p1.4.m1.2.3.7" xref="Ch5.S2.SS2.p1.4.m1.2.3.7.cmml">a</mi><mo id="Ch5.S2.SS2.p1.4.m1.2.3.1e" xref="Ch5.S2.SS2.p1.4.m1.2.3.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p1.4.m1.2.3.8" xref="Ch5.S2.SS2.p1.4.m1.2.3.8.cmml">s</mi><mo id="Ch5.S2.SS2.p1.4.m1.2.3.1f" xref="Ch5.S2.SS2.p1.4.m1.2.3.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p1.4.m1.2.3.9" xref="Ch5.S2.SS2.p1.4.m1.2.3.9.cmml">e</mi><mo id="Ch5.S2.SS2.p1.4.m1.2.3.1g" xref="Ch5.S2.SS2.p1.4.m1.2.3.1.cmml">⁢</mo><mrow id="Ch5.S2.SS2.p1.4.m1.2.3.10.2" xref="Ch5.S2.SS2.p1.4.m1.2.3.10.1.cmml"><mo id="Ch5.S2.SS2.p1.4.m1.2.3.10.2.1" xref="Ch5.S2.SS2.p1.4.m1.2.3.10.1.cmml">(</mo><mi id="Ch5.S2.SS2.p1.4.m1.1.1" xref="Ch5.S2.SS2.p1.4.m1.1.1.cmml">i</mi><mo id="Ch5.S2.SS2.p1.4.m1.2.3.10.2.2" xref="Ch5.S2.SS2.p1.4.m1.2.3.10.1.cmml">,</mo><mi id="Ch5.S2.SS2.p1.4.m1.2.2" xref="Ch5.S2.SS2.p1.4.m1.2.2.cmml">q</mi><mo id="Ch5.S2.SS2.p1.4.m1.2.3.10.2.3" xref="Ch5.S2.SS2.p1.4.m1.2.3.10.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p1.4.m1.2b"><apply id="Ch5.S2.SS2.p1.4.m1.2.3.cmml" xref="Ch5.S2.SS2.p1.4.m1.2.3"><times id="Ch5.S2.SS2.p1.4.m1.2.3.1.cmml" xref="Ch5.S2.SS2.p1.4.m1.2.3.1"></times><ci id="Ch5.S2.SS2.p1.4.m1.2.3.2.cmml" xref="Ch5.S2.SS2.p1.4.m1.2.3.2">𝑝</ci><ci id="Ch5.S2.SS2.p1.4.m1.2.3.3.cmml" xref="Ch5.S2.SS2.p1.4.m1.2.3.3">𝑢</ci><ci id="Ch5.S2.SS2.p1.4.m1.2.3.4.cmml" xref="Ch5.S2.SS2.p1.4.m1.2.3.4">𝑟</ci><ci id="Ch5.S2.SS2.p1.4.m1.2.3.5.cmml" xref="Ch5.S2.SS2.p1.4.m1.2.3.5">𝑐</ci><ci id="Ch5.S2.SS2.p1.4.m1.2.3.6.cmml" xref="Ch5.S2.SS2.p1.4.m1.2.3.6">ℎ</ci><ci id="Ch5.S2.SS2.p1.4.m1.2.3.7.cmml" xref="Ch5.S2.SS2.p1.4.m1.2.3.7">𝑎</ci><ci id="Ch5.S2.SS2.p1.4.m1.2.3.8.cmml" xref="Ch5.S2.SS2.p1.4.m1.2.3.8">𝑠</ci><ci id="Ch5.S2.SS2.p1.4.m1.2.3.9.cmml" xref="Ch5.S2.SS2.p1.4.m1.2.3.9">𝑒</ci><interval closure="open" id="Ch5.S2.SS2.p1.4.m1.2.3.10.1.cmml" xref="Ch5.S2.SS2.p1.4.m1.2.3.10.2"><ci id="Ch5.S2.SS2.p1.4.m1.1.1.cmml" xref="Ch5.S2.SS2.p1.4.m1.1.1">𝑖</ci><ci id="Ch5.S2.SS2.p1.4.m1.2.2.cmml" xref="Ch5.S2.SS2.p1.4.m1.2.2">𝑞</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p1.4.m1.2c">purchase\left(i,q\right)</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p1.4.m1.2d">italic_p italic_u italic_r italic_c italic_h italic_a italic_s italic_e ( italic_i , italic_q )</annotation></semantics></math> denotes the number of times that the item <math alttext="i" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p1.5.m2.1"><semantics id="Ch5.S2.SS2.p1.5.m2.1a"><mi id="Ch5.S2.SS2.p1.5.m2.1.1" xref="Ch5.S2.SS2.p1.5.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p1.5.m2.1b"><ci id="Ch5.S2.SS2.p1.5.m2.1.1.cmml" xref="Ch5.S2.SS2.p1.5.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p1.5.m2.1c">i</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p1.5.m2.1d">italic_i</annotation></semantics></math> has been purchased in a search session for a query <math alttext="q" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p1.6.m3.1"><semantics id="Ch5.S2.SS2.p1.6.m3.1a"><mi id="Ch5.S2.SS2.p1.6.m3.1.1" xref="Ch5.S2.SS2.p1.6.m3.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p1.6.m3.1b"><ci id="Ch5.S2.SS2.p1.6.m3.1.1.cmml" xref="Ch5.S2.SS2.p1.6.m3.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p1.6.m3.1c">q</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p1.6.m3.1d">italic_q</annotation></semantics></math>; and <math alttext="\left|S_{q}\right|" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p1.7.m4.1"><semantics id="Ch5.S2.SS2.p1.7.m4.1a"><mrow id="Ch5.S2.SS2.p1.7.m4.1.1.1" xref="Ch5.S2.SS2.p1.7.m4.1.1.2.cmml"><mo id="Ch5.S2.SS2.p1.7.m4.1.1.1.2" xref="Ch5.S2.SS2.p1.7.m4.1.1.2.1.cmml">|</mo><msub id="Ch5.S2.SS2.p1.7.m4.1.1.1.1" xref="Ch5.S2.SS2.p1.7.m4.1.1.1.1.cmml"><mi id="Ch5.S2.SS2.p1.7.m4.1.1.1.1.2" xref="Ch5.S2.SS2.p1.7.m4.1.1.1.1.2.cmml">S</mi><mi id="Ch5.S2.SS2.p1.7.m4.1.1.1.1.3" xref="Ch5.S2.SS2.p1.7.m4.1.1.1.1.3.cmml">q</mi></msub><mo id="Ch5.S2.SS2.p1.7.m4.1.1.1.3" xref="Ch5.S2.SS2.p1.7.m4.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p1.7.m4.1b"><apply id="Ch5.S2.SS2.p1.7.m4.1.1.2.cmml" xref="Ch5.S2.SS2.p1.7.m4.1.1.1"><abs id="Ch5.S2.SS2.p1.7.m4.1.1.2.1.cmml" xref="Ch5.S2.SS2.p1.7.m4.1.1.1.2"></abs><apply id="Ch5.S2.SS2.p1.7.m4.1.1.1.1.cmml" xref="Ch5.S2.SS2.p1.7.m4.1.1.1.1"><csymbol cd="ambiguous" id="Ch5.S2.SS2.p1.7.m4.1.1.1.1.1.cmml" xref="Ch5.S2.SS2.p1.7.m4.1.1.1.1">subscript</csymbol><ci id="Ch5.S2.SS2.p1.7.m4.1.1.1.1.2.cmml" xref="Ch5.S2.SS2.p1.7.m4.1.1.1.1.2">𝑆</ci><ci id="Ch5.S2.SS2.p1.7.m4.1.1.1.1.3.cmml" xref="Ch5.S2.SS2.p1.7.m4.1.1.1.1.3">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p1.7.m4.1c">\left|S_{q}\right|</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p1.7.m4.1d">| italic_S start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT |</annotation></semantics></math> is the set of search sessions for query <math alttext="q" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p1.8.m5.1"><semantics id="Ch5.S2.SS2.p1.8.m5.1a"><mi id="Ch5.S2.SS2.p1.8.m5.1.1" xref="Ch5.S2.SS2.p1.8.m5.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p1.8.m5.1b"><ci id="Ch5.S2.SS2.p1.8.m5.1.1.cmml" xref="Ch5.S2.SS2.p1.8.m5.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p1.8.m5.1c">q</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p1.8.m5.1d">italic_q</annotation></semantics></math> where the item <math alttext="i" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p1.9.m6.1"><semantics id="Ch5.S2.SS2.p1.9.m6.1a"><mi id="Ch5.S2.SS2.p1.9.m6.1.1" xref="Ch5.S2.SS2.p1.9.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p1.9.m6.1b"><ci id="Ch5.S2.SS2.p1.9.m6.1.1.cmml" xref="Ch5.S2.SS2.p1.9.m6.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p1.9.m6.1c">i</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p1.9.m6.1d">italic_i</annotation></semantics></math> is impressed.</p>
</div>
<div class="ltx_para" id="Ch5.S2.SS2.p2">
<p class="ltx_p" id="Ch5.S2.SS2.p2.3"><cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span></cite> proposed a metric named <math alttext="Rev@k" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p2.1.m1.1"><semantics id="Ch5.S2.SS2.p2.1.m1.1a"><mrow id="Ch5.S2.SS2.p2.1.m1.1.1" xref="Ch5.S2.SS2.p2.1.m1.1.1.cmml"><mi id="Ch5.S2.SS2.p2.1.m1.1.1.2" xref="Ch5.S2.SS2.p2.1.m1.1.1.2.cmml">R</mi><mo id="Ch5.S2.SS2.p2.1.m1.1.1.1" xref="Ch5.S2.SS2.p2.1.m1.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p2.1.m1.1.1.3" xref="Ch5.S2.SS2.p2.1.m1.1.1.3.cmml">e</mi><mo id="Ch5.S2.SS2.p2.1.m1.1.1.1a" xref="Ch5.S2.SS2.p2.1.m1.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p2.1.m1.1.1.4" xref="Ch5.S2.SS2.p2.1.m1.1.1.4.cmml">v</mi><mo id="Ch5.S2.SS2.p2.1.m1.1.1.1b" xref="Ch5.S2.SS2.p2.1.m1.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p2.1.m1.1.1.5" mathvariant="normal" xref="Ch5.S2.SS2.p2.1.m1.1.1.5.cmml">@</mi><mo id="Ch5.S2.SS2.p2.1.m1.1.1.1c" xref="Ch5.S2.SS2.p2.1.m1.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p2.1.m1.1.1.6" xref="Ch5.S2.SS2.p2.1.m1.1.1.6.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p2.1.m1.1b"><apply id="Ch5.S2.SS2.p2.1.m1.1.1.cmml" xref="Ch5.S2.SS2.p2.1.m1.1.1"><times id="Ch5.S2.SS2.p2.1.m1.1.1.1.cmml" xref="Ch5.S2.SS2.p2.1.m1.1.1.1"></times><ci id="Ch5.S2.SS2.p2.1.m1.1.1.2.cmml" xref="Ch5.S2.SS2.p2.1.m1.1.1.2">𝑅</ci><ci id="Ch5.S2.SS2.p2.1.m1.1.1.3.cmml" xref="Ch5.S2.SS2.p2.1.m1.1.1.3">𝑒</ci><ci id="Ch5.S2.SS2.p2.1.m1.1.1.4.cmml" xref="Ch5.S2.SS2.p2.1.m1.1.1.4">𝑣</ci><ci id="Ch5.S2.SS2.p2.1.m1.1.1.5.cmml" xref="Ch5.S2.SS2.p2.1.m1.1.1.5">@</ci><ci id="Ch5.S2.SS2.p2.1.m1.1.1.6.cmml" xref="Ch5.S2.SS2.p2.1.m1.1.1.6">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p2.1.m1.1c">Rev@k</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p2.1.m1.1d">italic_R italic_e italic_v @ italic_k</annotation></semantics></math> to evaluate the revenue in e-commerce rankers. <math alttext="Rev@k" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p2.2.m2.1"><semantics id="Ch5.S2.SS2.p2.2.m2.1a"><mrow id="Ch5.S2.SS2.p2.2.m2.1.1" xref="Ch5.S2.SS2.p2.2.m2.1.1.cmml"><mi id="Ch5.S2.SS2.p2.2.m2.1.1.2" xref="Ch5.S2.SS2.p2.2.m2.1.1.2.cmml">R</mi><mo id="Ch5.S2.SS2.p2.2.m2.1.1.1" xref="Ch5.S2.SS2.p2.2.m2.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p2.2.m2.1.1.3" xref="Ch5.S2.SS2.p2.2.m2.1.1.3.cmml">e</mi><mo id="Ch5.S2.SS2.p2.2.m2.1.1.1a" xref="Ch5.S2.SS2.p2.2.m2.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p2.2.m2.1.1.4" xref="Ch5.S2.SS2.p2.2.m2.1.1.4.cmml">v</mi><mo id="Ch5.S2.SS2.p2.2.m2.1.1.1b" xref="Ch5.S2.SS2.p2.2.m2.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p2.2.m2.1.1.5" mathvariant="normal" xref="Ch5.S2.SS2.p2.2.m2.1.1.5.cmml">@</mi><mo id="Ch5.S2.SS2.p2.2.m2.1.1.1c" xref="Ch5.S2.SS2.p2.2.m2.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p2.2.m2.1.1.6" xref="Ch5.S2.SS2.p2.2.m2.1.1.6.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p2.2.m2.1b"><apply id="Ch5.S2.SS2.p2.2.m2.1.1.cmml" xref="Ch5.S2.SS2.p2.2.m2.1.1"><times id="Ch5.S2.SS2.p2.2.m2.1.1.1.cmml" xref="Ch5.S2.SS2.p2.2.m2.1.1.1"></times><ci id="Ch5.S2.SS2.p2.2.m2.1.1.2.cmml" xref="Ch5.S2.SS2.p2.2.m2.1.1.2">𝑅</ci><ci id="Ch5.S2.SS2.p2.2.m2.1.1.3.cmml" xref="Ch5.S2.SS2.p2.2.m2.1.1.3">𝑒</ci><ci id="Ch5.S2.SS2.p2.2.m2.1.1.4.cmml" xref="Ch5.S2.SS2.p2.2.m2.1.1.4">𝑣</ci><ci id="Ch5.S2.SS2.p2.2.m2.1.1.5.cmml" xref="Ch5.S2.SS2.p2.2.m2.1.1.5">@</ci><ci id="Ch5.S2.SS2.p2.2.m2.1.1.6.cmml" xref="Ch5.S2.SS2.p2.2.m2.1.1.6">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p2.2.m2.1c">Rev@k</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p2.2.m2.1d">italic_R italic_e italic_v @ italic_k</annotation></semantics></math> calculates the average revenues that a prediction algorithm would generate for each session. Specifically, <math alttext="Rev@k" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p2.3.m3.1"><semantics id="Ch5.S2.SS2.p2.3.m3.1a"><mrow id="Ch5.S2.SS2.p2.3.m3.1.1" xref="Ch5.S2.SS2.p2.3.m3.1.1.cmml"><mi id="Ch5.S2.SS2.p2.3.m3.1.1.2" xref="Ch5.S2.SS2.p2.3.m3.1.1.2.cmml">R</mi><mo id="Ch5.S2.SS2.p2.3.m3.1.1.1" xref="Ch5.S2.SS2.p2.3.m3.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p2.3.m3.1.1.3" xref="Ch5.S2.SS2.p2.3.m3.1.1.3.cmml">e</mi><mo id="Ch5.S2.SS2.p2.3.m3.1.1.1a" xref="Ch5.S2.SS2.p2.3.m3.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p2.3.m3.1.1.4" xref="Ch5.S2.SS2.p2.3.m3.1.1.4.cmml">v</mi><mo id="Ch5.S2.SS2.p2.3.m3.1.1.1b" xref="Ch5.S2.SS2.p2.3.m3.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p2.3.m3.1.1.5" mathvariant="normal" xref="Ch5.S2.SS2.p2.3.m3.1.1.5.cmml">@</mi><mo id="Ch5.S2.SS2.p2.3.m3.1.1.1c" xref="Ch5.S2.SS2.p2.3.m3.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p2.3.m3.1.1.6" xref="Ch5.S2.SS2.p2.3.m3.1.1.6.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p2.3.m3.1b"><apply id="Ch5.S2.SS2.p2.3.m3.1.1.cmml" xref="Ch5.S2.SS2.p2.3.m3.1.1"><times id="Ch5.S2.SS2.p2.3.m3.1.1.1.cmml" xref="Ch5.S2.SS2.p2.3.m3.1.1.1"></times><ci id="Ch5.S2.SS2.p2.3.m3.1.1.2.cmml" xref="Ch5.S2.SS2.p2.3.m3.1.1.2">𝑅</ci><ci id="Ch5.S2.SS2.p2.3.m3.1.1.3.cmml" xref="Ch5.S2.SS2.p2.3.m3.1.1.3">𝑒</ci><ci id="Ch5.S2.SS2.p2.3.m3.1.1.4.cmml" xref="Ch5.S2.SS2.p2.3.m3.1.1.4">𝑣</ci><ci id="Ch5.S2.SS2.p2.3.m3.1.1.5.cmml" xref="Ch5.S2.SS2.p2.3.m3.1.1.5">@</ci><ci id="Ch5.S2.SS2.p2.3.m3.1.1.6.cmml" xref="Ch5.S2.SS2.p2.3.m3.1.1.6">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p2.3.m3.1c">Rev@k</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p2.3.m3.1d">italic_R italic_e italic_v @ italic_k</annotation></semantics></math> is calculated as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="Ch5.E7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="Rev@k(\rho)=\sum_{s\in S}{\sum_{{r_{s}}\leq k}{price({r_{s}}^{-1})}}\Phi({r_{s%
}}^{-1})," class="ltx_Math" display="block" id="Ch5.E7.m1.2"><semantics id="Ch5.E7.m1.2a"><mrow id="Ch5.E7.m1.2.2.1" xref="Ch5.E7.m1.2.2.1.1.cmml"><mrow id="Ch5.E7.m1.2.2.1.1" xref="Ch5.E7.m1.2.2.1.1.cmml"><mrow id="Ch5.E7.m1.2.2.1.1.4" xref="Ch5.E7.m1.2.2.1.1.4.cmml"><mi id="Ch5.E7.m1.2.2.1.1.4.2" xref="Ch5.E7.m1.2.2.1.1.4.2.cmml">R</mi><mo id="Ch5.E7.m1.2.2.1.1.4.1" xref="Ch5.E7.m1.2.2.1.1.4.1.cmml">⁢</mo><mi id="Ch5.E7.m1.2.2.1.1.4.3" xref="Ch5.E7.m1.2.2.1.1.4.3.cmml">e</mi><mo id="Ch5.E7.m1.2.2.1.1.4.1a" xref="Ch5.E7.m1.2.2.1.1.4.1.cmml">⁢</mo><mi id="Ch5.E7.m1.2.2.1.1.4.4" xref="Ch5.E7.m1.2.2.1.1.4.4.cmml">v</mi><mo id="Ch5.E7.m1.2.2.1.1.4.1b" xref="Ch5.E7.m1.2.2.1.1.4.1.cmml">⁢</mo><mi id="Ch5.E7.m1.2.2.1.1.4.5" mathvariant="normal" xref="Ch5.E7.m1.2.2.1.1.4.5.cmml">@</mi><mo id="Ch5.E7.m1.2.2.1.1.4.1c" xref="Ch5.E7.m1.2.2.1.1.4.1.cmml">⁢</mo><mi id="Ch5.E7.m1.2.2.1.1.4.6" xref="Ch5.E7.m1.2.2.1.1.4.6.cmml">k</mi><mo id="Ch5.E7.m1.2.2.1.1.4.1d" xref="Ch5.E7.m1.2.2.1.1.4.1.cmml">⁢</mo><mrow id="Ch5.E7.m1.2.2.1.1.4.7.2" xref="Ch5.E7.m1.2.2.1.1.4.cmml"><mo id="Ch5.E7.m1.2.2.1.1.4.7.2.1" stretchy="false" xref="Ch5.E7.m1.2.2.1.1.4.cmml">(</mo><mi id="Ch5.E7.m1.1.1" xref="Ch5.E7.m1.1.1.cmml">ρ</mi><mo id="Ch5.E7.m1.2.2.1.1.4.7.2.2" stretchy="false" xref="Ch5.E7.m1.2.2.1.1.4.cmml">)</mo></mrow></mrow><mo id="Ch5.E7.m1.2.2.1.1.3" rspace="0.111em" xref="Ch5.E7.m1.2.2.1.1.3.cmml">=</mo><mrow id="Ch5.E7.m1.2.2.1.1.2" xref="Ch5.E7.m1.2.2.1.1.2.cmml"><munder id="Ch5.E7.m1.2.2.1.1.2.3" xref="Ch5.E7.m1.2.2.1.1.2.3.cmml"><mo id="Ch5.E7.m1.2.2.1.1.2.3.2" movablelimits="false" rspace="0em" xref="Ch5.E7.m1.2.2.1.1.2.3.2.cmml">∑</mo><mrow id="Ch5.E7.m1.2.2.1.1.2.3.3" xref="Ch5.E7.m1.2.2.1.1.2.3.3.cmml"><mi id="Ch5.E7.m1.2.2.1.1.2.3.3.2" xref="Ch5.E7.m1.2.2.1.1.2.3.3.2.cmml">s</mi><mo id="Ch5.E7.m1.2.2.1.1.2.3.3.1" xref="Ch5.E7.m1.2.2.1.1.2.3.3.1.cmml">∈</mo><mi id="Ch5.E7.m1.2.2.1.1.2.3.3.3" xref="Ch5.E7.m1.2.2.1.1.2.3.3.3.cmml">S</mi></mrow></munder><mrow id="Ch5.E7.m1.2.2.1.1.2.2" xref="Ch5.E7.m1.2.2.1.1.2.2.cmml"><munder id="Ch5.E7.m1.2.2.1.1.2.2.3" xref="Ch5.E7.m1.2.2.1.1.2.2.3.cmml"><mo id="Ch5.E7.m1.2.2.1.1.2.2.3.2" movablelimits="false" xref="Ch5.E7.m1.2.2.1.1.2.2.3.2.cmml">∑</mo><mrow id="Ch5.E7.m1.2.2.1.1.2.2.3.3" xref="Ch5.E7.m1.2.2.1.1.2.2.3.3.cmml"><msub id="Ch5.E7.m1.2.2.1.1.2.2.3.3.2" xref="Ch5.E7.m1.2.2.1.1.2.2.3.3.2.cmml"><mi id="Ch5.E7.m1.2.2.1.1.2.2.3.3.2.2" xref="Ch5.E7.m1.2.2.1.1.2.2.3.3.2.2.cmml">r</mi><mi id="Ch5.E7.m1.2.2.1.1.2.2.3.3.2.3" xref="Ch5.E7.m1.2.2.1.1.2.2.3.3.2.3.cmml">s</mi></msub><mo id="Ch5.E7.m1.2.2.1.1.2.2.3.3.1" xref="Ch5.E7.m1.2.2.1.1.2.2.3.3.1.cmml">≤</mo><mi id="Ch5.E7.m1.2.2.1.1.2.2.3.3.3" xref="Ch5.E7.m1.2.2.1.1.2.2.3.3.3.cmml">k</mi></mrow></munder><mrow id="Ch5.E7.m1.2.2.1.1.2.2.2" xref="Ch5.E7.m1.2.2.1.1.2.2.2.cmml"><mi id="Ch5.E7.m1.2.2.1.1.2.2.2.4" xref="Ch5.E7.m1.2.2.1.1.2.2.2.4.cmml">p</mi><mo id="Ch5.E7.m1.2.2.1.1.2.2.2.3" xref="Ch5.E7.m1.2.2.1.1.2.2.2.3.cmml">⁢</mo><mi id="Ch5.E7.m1.2.2.1.1.2.2.2.5" xref="Ch5.E7.m1.2.2.1.1.2.2.2.5.cmml">r</mi><mo id="Ch5.E7.m1.2.2.1.1.2.2.2.3a" xref="Ch5.E7.m1.2.2.1.1.2.2.2.3.cmml">⁢</mo><mi id="Ch5.E7.m1.2.2.1.1.2.2.2.6" xref="Ch5.E7.m1.2.2.1.1.2.2.2.6.cmml">i</mi><mo id="Ch5.E7.m1.2.2.1.1.2.2.2.3b" xref="Ch5.E7.m1.2.2.1.1.2.2.2.3.cmml">⁢</mo><mi id="Ch5.E7.m1.2.2.1.1.2.2.2.7" xref="Ch5.E7.m1.2.2.1.1.2.2.2.7.cmml">c</mi><mo id="Ch5.E7.m1.2.2.1.1.2.2.2.3c" xref="Ch5.E7.m1.2.2.1.1.2.2.2.3.cmml">⁢</mo><mi id="Ch5.E7.m1.2.2.1.1.2.2.2.8" xref="Ch5.E7.m1.2.2.1.1.2.2.2.8.cmml">e</mi><mo id="Ch5.E7.m1.2.2.1.1.2.2.2.3d" xref="Ch5.E7.m1.2.2.1.1.2.2.2.3.cmml">⁢</mo><mrow id="Ch5.E7.m1.2.2.1.1.1.1.1.1.1" xref="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mo id="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.2" stretchy="false" xref="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.cmml">(</mo><mmultiscripts id="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1" xref="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mi id="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.2.2" xref="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.2.2.cmml">r</mi><mi id="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.2.3" xref="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.2.3.cmml">s</mi><mrow id="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1a" xref="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.cmml"></mrow><mrow id="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1b" xref="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.cmml"></mrow><mrow id="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.3" xref="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.3.cmml"><mo id="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.3a" xref="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.3.cmml">−</mo><mn id="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2" xref="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.cmml">1</mn></mrow></mmultiscripts><mo id="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.3" stretchy="false" xref="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="Ch5.E7.m1.2.2.1.1.2.2.2.3e" xref="Ch5.E7.m1.2.2.1.1.2.2.2.3.cmml">⁢</mo><mi id="Ch5.E7.m1.2.2.1.1.2.2.2.9" mathvariant="normal" xref="Ch5.E7.m1.2.2.1.1.2.2.2.9.cmml">Φ</mi><mo id="Ch5.E7.m1.2.2.1.1.2.2.2.3f" xref="Ch5.E7.m1.2.2.1.1.2.2.2.3.cmml">⁢</mo><mrow id="Ch5.E7.m1.2.2.1.1.2.2.2.2.1" xref="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.cmml"><mo id="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.2" stretchy="false" xref="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.cmml">(</mo><mmultiscripts id="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1" xref="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.cmml"><mi id="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.2.2" xref="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.2.2.cmml">r</mi><mi id="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.2.3" xref="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.2.3.cmml">s</mi><mrow id="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1a" xref="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.cmml"></mrow><mrow id="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1b" xref="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.cmml"></mrow><mrow id="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.3" xref="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.3.cmml"><mo id="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.3a" xref="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.3.cmml">−</mo><mn id="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.3.2" xref="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.3.2.cmml">1</mn></mrow></mmultiscripts><mo id="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.3" stretchy="false" xref="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo id="Ch5.E7.m1.2.2.1.2" xref="Ch5.E7.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch5.E7.m1.2b"><apply id="Ch5.E7.m1.2.2.1.1.cmml" xref="Ch5.E7.m1.2.2.1"><eq id="Ch5.E7.m1.2.2.1.1.3.cmml" xref="Ch5.E7.m1.2.2.1.1.3"></eq><apply id="Ch5.E7.m1.2.2.1.1.4.cmml" xref="Ch5.E7.m1.2.2.1.1.4"><times id="Ch5.E7.m1.2.2.1.1.4.1.cmml" xref="Ch5.E7.m1.2.2.1.1.4.1"></times><ci id="Ch5.E7.m1.2.2.1.1.4.2.cmml" xref="Ch5.E7.m1.2.2.1.1.4.2">𝑅</ci><ci id="Ch5.E7.m1.2.2.1.1.4.3.cmml" xref="Ch5.E7.m1.2.2.1.1.4.3">𝑒</ci><ci id="Ch5.E7.m1.2.2.1.1.4.4.cmml" xref="Ch5.E7.m1.2.2.1.1.4.4">𝑣</ci><ci id="Ch5.E7.m1.2.2.1.1.4.5.cmml" xref="Ch5.E7.m1.2.2.1.1.4.5">@</ci><ci id="Ch5.E7.m1.2.2.1.1.4.6.cmml" xref="Ch5.E7.m1.2.2.1.1.4.6">𝑘</ci><ci id="Ch5.E7.m1.1.1.cmml" xref="Ch5.E7.m1.1.1">𝜌</ci></apply><apply id="Ch5.E7.m1.2.2.1.1.2.cmml" xref="Ch5.E7.m1.2.2.1.1.2"><apply id="Ch5.E7.m1.2.2.1.1.2.3.cmml" xref="Ch5.E7.m1.2.2.1.1.2.3"><csymbol cd="ambiguous" id="Ch5.E7.m1.2.2.1.1.2.3.1.cmml" xref="Ch5.E7.m1.2.2.1.1.2.3">subscript</csymbol><sum id="Ch5.E7.m1.2.2.1.1.2.3.2.cmml" xref="Ch5.E7.m1.2.2.1.1.2.3.2"></sum><apply id="Ch5.E7.m1.2.2.1.1.2.3.3.cmml" xref="Ch5.E7.m1.2.2.1.1.2.3.3"><in id="Ch5.E7.m1.2.2.1.1.2.3.3.1.cmml" xref="Ch5.E7.m1.2.2.1.1.2.3.3.1"></in><ci id="Ch5.E7.m1.2.2.1.1.2.3.3.2.cmml" xref="Ch5.E7.m1.2.2.1.1.2.3.3.2">𝑠</ci><ci id="Ch5.E7.m1.2.2.1.1.2.3.3.3.cmml" xref="Ch5.E7.m1.2.2.1.1.2.3.3.3">𝑆</ci></apply></apply><apply id="Ch5.E7.m1.2.2.1.1.2.2.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2"><apply id="Ch5.E7.m1.2.2.1.1.2.2.3.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.3"><csymbol cd="ambiguous" id="Ch5.E7.m1.2.2.1.1.2.2.3.1.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.3">subscript</csymbol><sum id="Ch5.E7.m1.2.2.1.1.2.2.3.2.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.3.2"></sum><apply id="Ch5.E7.m1.2.2.1.1.2.2.3.3.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.3.3"><leq id="Ch5.E7.m1.2.2.1.1.2.2.3.3.1.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.3.3.1"></leq><apply id="Ch5.E7.m1.2.2.1.1.2.2.3.3.2.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.3.3.2"><csymbol cd="ambiguous" id="Ch5.E7.m1.2.2.1.1.2.2.3.3.2.1.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.3.3.2">subscript</csymbol><ci id="Ch5.E7.m1.2.2.1.1.2.2.3.3.2.2.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.3.3.2.2">𝑟</ci><ci id="Ch5.E7.m1.2.2.1.1.2.2.3.3.2.3.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.3.3.2.3">𝑠</ci></apply><ci id="Ch5.E7.m1.2.2.1.1.2.2.3.3.3.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.3.3.3">𝑘</ci></apply></apply><apply id="Ch5.E7.m1.2.2.1.1.2.2.2.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.2"><times id="Ch5.E7.m1.2.2.1.1.2.2.2.3.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.2.3"></times><ci id="Ch5.E7.m1.2.2.1.1.2.2.2.4.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.2.4">𝑝</ci><ci id="Ch5.E7.m1.2.2.1.1.2.2.2.5.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.2.5">𝑟</ci><ci id="Ch5.E7.m1.2.2.1.1.2.2.2.6.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.2.6">𝑖</ci><ci id="Ch5.E7.m1.2.2.1.1.2.2.2.7.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.2.7">𝑐</ci><ci id="Ch5.E7.m1.2.2.1.1.2.2.2.8.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.2.8">𝑒</ci><apply id="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="Ch5.E7.m1.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="Ch5.E7.m1.2.2.1.1.1.1.1.1.1">superscript</csymbol><apply id="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="Ch5.E7.m1.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.2.1.cmml" xref="Ch5.E7.m1.2.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.2.2.cmml" xref="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.2.2">𝑟</ci><ci id="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.2.3.cmml" xref="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.2.3">𝑠</ci></apply><apply id="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.3"><minus id="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.3.1.cmml" xref="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.3"></minus><cn id="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2.cmml" type="integer" xref="Ch5.E7.m1.2.2.1.1.1.1.1.1.1.1.3.2">1</cn></apply></apply><ci id="Ch5.E7.m1.2.2.1.1.2.2.2.9.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.2.9">Φ</ci><apply id="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.2.2.1"><csymbol cd="ambiguous" id="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.1.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.2.2.1">superscript</csymbol><apply id="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.2.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.2.2.1"><csymbol cd="ambiguous" id="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.2.1.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.2.2.1">subscript</csymbol><ci id="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.2.2.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.2.2">𝑟</ci><ci id="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.2.3.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.2.3">𝑠</ci></apply><apply id="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.3.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.3"><minus id="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.3.1.cmml" xref="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.3"></minus><cn id="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.3.2.cmml" type="integer" xref="Ch5.E7.m1.2.2.1.1.2.2.2.2.1.1.3.2">1</cn></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.E7.m1.2c">Rev@k(\rho)=\sum_{s\in S}{\sum_{{r_{s}}\leq k}{price({r_{s}}^{-1})}}\Phi({r_{s%
}}^{-1}),</annotation><annotation encoding="application/x-llamapun" id="Ch5.E7.m1.2d">italic_R italic_e italic_v @ italic_k ( italic_ρ ) = ∑ start_POSTSUBSCRIPT italic_s ∈ italic_S end_POSTSUBSCRIPT ∑ start_POSTSUBSCRIPT italic_r start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ≤ italic_k end_POSTSUBSCRIPT italic_p italic_r italic_i italic_c italic_e ( italic_r start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) roman_Φ ( italic_r start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5.7)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch5.S2.SS2.p2.13">where <math alttext="\rho" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p2.4.m1.1"><semantics id="Ch5.S2.SS2.p2.4.m1.1a"><mi id="Ch5.S2.SS2.p2.4.m1.1.1" xref="Ch5.S2.SS2.p2.4.m1.1.1.cmml">ρ</mi><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p2.4.m1.1b"><ci id="Ch5.S2.SS2.p2.4.m1.1.1.cmml" xref="Ch5.S2.SS2.p2.4.m1.1.1">𝜌</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p2.4.m1.1c">\rho</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p2.4.m1.1d">italic_ρ</annotation></semantics></math> is the ranking order and <math alttext="r_{s}\leq k" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p2.5.m2.1"><semantics id="Ch5.S2.SS2.p2.5.m2.1a"><mrow id="Ch5.S2.SS2.p2.5.m2.1.1" xref="Ch5.S2.SS2.p2.5.m2.1.1.cmml"><msub id="Ch5.S2.SS2.p2.5.m2.1.1.2" xref="Ch5.S2.SS2.p2.5.m2.1.1.2.cmml"><mi id="Ch5.S2.SS2.p2.5.m2.1.1.2.2" xref="Ch5.S2.SS2.p2.5.m2.1.1.2.2.cmml">r</mi><mi id="Ch5.S2.SS2.p2.5.m2.1.1.2.3" xref="Ch5.S2.SS2.p2.5.m2.1.1.2.3.cmml">s</mi></msub><mo id="Ch5.S2.SS2.p2.5.m2.1.1.1" xref="Ch5.S2.SS2.p2.5.m2.1.1.1.cmml">≤</mo><mi id="Ch5.S2.SS2.p2.5.m2.1.1.3" xref="Ch5.S2.SS2.p2.5.m2.1.1.3.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p2.5.m2.1b"><apply id="Ch5.S2.SS2.p2.5.m2.1.1.cmml" xref="Ch5.S2.SS2.p2.5.m2.1.1"><leq id="Ch5.S2.SS2.p2.5.m2.1.1.1.cmml" xref="Ch5.S2.SS2.p2.5.m2.1.1.1"></leq><apply id="Ch5.S2.SS2.p2.5.m2.1.1.2.cmml" xref="Ch5.S2.SS2.p2.5.m2.1.1.2"><csymbol cd="ambiguous" id="Ch5.S2.SS2.p2.5.m2.1.1.2.1.cmml" xref="Ch5.S2.SS2.p2.5.m2.1.1.2">subscript</csymbol><ci id="Ch5.S2.SS2.p2.5.m2.1.1.2.2.cmml" xref="Ch5.S2.SS2.p2.5.m2.1.1.2.2">𝑟</ci><ci id="Ch5.S2.SS2.p2.5.m2.1.1.2.3.cmml" xref="Ch5.S2.SS2.p2.5.m2.1.1.2.3">𝑠</ci></apply><ci id="Ch5.S2.SS2.p2.5.m2.1.1.3.cmml" xref="Ch5.S2.SS2.p2.5.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p2.5.m2.1c">r_{s}\leq k</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p2.5.m2.1d">italic_r start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT ≤ italic_k</annotation></semantics></math> denotes the top-<math alttext="k" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p2.6.m3.1"><semantics id="Ch5.S2.SS2.p2.6.m3.1a"><mi id="Ch5.S2.SS2.p2.6.m3.1.1" xref="Ch5.S2.SS2.p2.6.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p2.6.m3.1b"><ci id="Ch5.S2.SS2.p2.6.m3.1.1.cmml" xref="Ch5.S2.SS2.p2.6.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p2.6.m3.1c">k</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p2.6.m3.1d">italic_k</annotation></semantics></math> ranked positions in the session <math alttext="s" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p2.7.m4.1"><semantics id="Ch5.S2.SS2.p2.7.m4.1a"><mi id="Ch5.S2.SS2.p2.7.m4.1.1" xref="Ch5.S2.SS2.p2.7.m4.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p2.7.m4.1b"><ci id="Ch5.S2.SS2.p2.7.m4.1.1.cmml" xref="Ch5.S2.SS2.p2.7.m4.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p2.7.m4.1c">s</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p2.7.m4.1d">italic_s</annotation></semantics></math>. <math alttext="r_{s}^{-1}" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p2.8.m5.1"><semantics id="Ch5.S2.SS2.p2.8.m5.1a"><msubsup id="Ch5.S2.SS2.p2.8.m5.1.1" xref="Ch5.S2.SS2.p2.8.m5.1.1.cmml"><mi id="Ch5.S2.SS2.p2.8.m5.1.1.2.2" xref="Ch5.S2.SS2.p2.8.m5.1.1.2.2.cmml">r</mi><mi id="Ch5.S2.SS2.p2.8.m5.1.1.2.3" xref="Ch5.S2.SS2.p2.8.m5.1.1.2.3.cmml">s</mi><mrow id="Ch5.S2.SS2.p2.8.m5.1.1.3" xref="Ch5.S2.SS2.p2.8.m5.1.1.3.cmml"><mo id="Ch5.S2.SS2.p2.8.m5.1.1.3a" xref="Ch5.S2.SS2.p2.8.m5.1.1.3.cmml">−</mo><mn id="Ch5.S2.SS2.p2.8.m5.1.1.3.2" xref="Ch5.S2.SS2.p2.8.m5.1.1.3.2.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p2.8.m5.1b"><apply id="Ch5.S2.SS2.p2.8.m5.1.1.cmml" xref="Ch5.S2.SS2.p2.8.m5.1.1"><csymbol cd="ambiguous" id="Ch5.S2.SS2.p2.8.m5.1.1.1.cmml" xref="Ch5.S2.SS2.p2.8.m5.1.1">superscript</csymbol><apply id="Ch5.S2.SS2.p2.8.m5.1.1.2.cmml" xref="Ch5.S2.SS2.p2.8.m5.1.1"><csymbol cd="ambiguous" id="Ch5.S2.SS2.p2.8.m5.1.1.2.1.cmml" xref="Ch5.S2.SS2.p2.8.m5.1.1">subscript</csymbol><ci id="Ch5.S2.SS2.p2.8.m5.1.1.2.2.cmml" xref="Ch5.S2.SS2.p2.8.m5.1.1.2.2">𝑟</ci><ci id="Ch5.S2.SS2.p2.8.m5.1.1.2.3.cmml" xref="Ch5.S2.SS2.p2.8.m5.1.1.2.3">𝑠</ci></apply><apply id="Ch5.S2.SS2.p2.8.m5.1.1.3.cmml" xref="Ch5.S2.SS2.p2.8.m5.1.1.3"><minus id="Ch5.S2.SS2.p2.8.m5.1.1.3.1.cmml" xref="Ch5.S2.SS2.p2.8.m5.1.1.3"></minus><cn id="Ch5.S2.SS2.p2.8.m5.1.1.3.2.cmml" type="integer" xref="Ch5.S2.SS2.p2.8.m5.1.1.3.2">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p2.8.m5.1c">r_{s}^{-1}</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p2.8.m5.1d">italic_r start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT - 1 end_POSTSUPERSCRIPT</annotation></semantics></math> denotes the corresponding item at the position <math alttext="r_{s}" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p2.9.m6.1"><semantics id="Ch5.S2.SS2.p2.9.m6.1a"><msub id="Ch5.S2.SS2.p2.9.m6.1.1" xref="Ch5.S2.SS2.p2.9.m6.1.1.cmml"><mi id="Ch5.S2.SS2.p2.9.m6.1.1.2" xref="Ch5.S2.SS2.p2.9.m6.1.1.2.cmml">r</mi><mi id="Ch5.S2.SS2.p2.9.m6.1.1.3" xref="Ch5.S2.SS2.p2.9.m6.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p2.9.m6.1b"><apply id="Ch5.S2.SS2.p2.9.m6.1.1.cmml" xref="Ch5.S2.SS2.p2.9.m6.1.1"><csymbol cd="ambiguous" id="Ch5.S2.SS2.p2.9.m6.1.1.1.cmml" xref="Ch5.S2.SS2.p2.9.m6.1.1">subscript</csymbol><ci id="Ch5.S2.SS2.p2.9.m6.1.1.2.cmml" xref="Ch5.S2.SS2.p2.9.m6.1.1.2">𝑟</ci><ci id="Ch5.S2.SS2.p2.9.m6.1.1.3.cmml" xref="Ch5.S2.SS2.p2.9.m6.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p2.9.m6.1c">r_{s}</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p2.9.m6.1d">italic_r start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT</annotation></semantics></math>, <math alttext="price(i)" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p2.10.m7.1"><semantics id="Ch5.S2.SS2.p2.10.m7.1a"><mrow id="Ch5.S2.SS2.p2.10.m7.1.2" xref="Ch5.S2.SS2.p2.10.m7.1.2.cmml"><mi id="Ch5.S2.SS2.p2.10.m7.1.2.2" xref="Ch5.S2.SS2.p2.10.m7.1.2.2.cmml">p</mi><mo id="Ch5.S2.SS2.p2.10.m7.1.2.1" xref="Ch5.S2.SS2.p2.10.m7.1.2.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p2.10.m7.1.2.3" xref="Ch5.S2.SS2.p2.10.m7.1.2.3.cmml">r</mi><mo id="Ch5.S2.SS2.p2.10.m7.1.2.1a" xref="Ch5.S2.SS2.p2.10.m7.1.2.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p2.10.m7.1.2.4" xref="Ch5.S2.SS2.p2.10.m7.1.2.4.cmml">i</mi><mo id="Ch5.S2.SS2.p2.10.m7.1.2.1b" xref="Ch5.S2.SS2.p2.10.m7.1.2.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p2.10.m7.1.2.5" xref="Ch5.S2.SS2.p2.10.m7.1.2.5.cmml">c</mi><mo id="Ch5.S2.SS2.p2.10.m7.1.2.1c" xref="Ch5.S2.SS2.p2.10.m7.1.2.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p2.10.m7.1.2.6" xref="Ch5.S2.SS2.p2.10.m7.1.2.6.cmml">e</mi><mo id="Ch5.S2.SS2.p2.10.m7.1.2.1d" xref="Ch5.S2.SS2.p2.10.m7.1.2.1.cmml">⁢</mo><mrow id="Ch5.S2.SS2.p2.10.m7.1.2.7.2" xref="Ch5.S2.SS2.p2.10.m7.1.2.cmml"><mo id="Ch5.S2.SS2.p2.10.m7.1.2.7.2.1" stretchy="false" xref="Ch5.S2.SS2.p2.10.m7.1.2.cmml">(</mo><mi id="Ch5.S2.SS2.p2.10.m7.1.1" xref="Ch5.S2.SS2.p2.10.m7.1.1.cmml">i</mi><mo id="Ch5.S2.SS2.p2.10.m7.1.2.7.2.2" stretchy="false" xref="Ch5.S2.SS2.p2.10.m7.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p2.10.m7.1b"><apply id="Ch5.S2.SS2.p2.10.m7.1.2.cmml" xref="Ch5.S2.SS2.p2.10.m7.1.2"><times id="Ch5.S2.SS2.p2.10.m7.1.2.1.cmml" xref="Ch5.S2.SS2.p2.10.m7.1.2.1"></times><ci id="Ch5.S2.SS2.p2.10.m7.1.2.2.cmml" xref="Ch5.S2.SS2.p2.10.m7.1.2.2">𝑝</ci><ci id="Ch5.S2.SS2.p2.10.m7.1.2.3.cmml" xref="Ch5.S2.SS2.p2.10.m7.1.2.3">𝑟</ci><ci id="Ch5.S2.SS2.p2.10.m7.1.2.4.cmml" xref="Ch5.S2.SS2.p2.10.m7.1.2.4">𝑖</ci><ci id="Ch5.S2.SS2.p2.10.m7.1.2.5.cmml" xref="Ch5.S2.SS2.p2.10.m7.1.2.5">𝑐</ci><ci id="Ch5.S2.SS2.p2.10.m7.1.2.6.cmml" xref="Ch5.S2.SS2.p2.10.m7.1.2.6">𝑒</ci><ci id="Ch5.S2.SS2.p2.10.m7.1.1.cmml" xref="Ch5.S2.SS2.p2.10.m7.1.1">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p2.10.m7.1c">price(i)</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p2.10.m7.1d">italic_p italic_r italic_i italic_c italic_e ( italic_i )</annotation></semantics></math> indicates the price of item <math alttext="i" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p2.11.m8.1"><semantics id="Ch5.S2.SS2.p2.11.m8.1a"><mi id="Ch5.S2.SS2.p2.11.m8.1.1" xref="Ch5.S2.SS2.p2.11.m8.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p2.11.m8.1b"><ci id="Ch5.S2.SS2.p2.11.m8.1.1.cmml" xref="Ch5.S2.SS2.p2.11.m8.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p2.11.m8.1c">i</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p2.11.m8.1d">italic_i</annotation></semantics></math>, while <math alttext="\Phi" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p2.12.m9.1"><semantics id="Ch5.S2.SS2.p2.12.m9.1a"><mi id="Ch5.S2.SS2.p2.12.m9.1.1" mathvariant="normal" xref="Ch5.S2.SS2.p2.12.m9.1.1.cmml">Φ</mi><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p2.12.m9.1b"><ci id="Ch5.S2.SS2.p2.12.m9.1.1.cmml" xref="Ch5.S2.SS2.p2.12.m9.1.1">Φ</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p2.12.m9.1c">\Phi</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p2.12.m9.1d">roman_Φ</annotation></semantics></math> denotes an event of purchase. Based on <math alttext="Rev@k" class="ltx_Math" display="inline" id="Ch5.S2.SS2.p2.13.m10.1"><semantics id="Ch5.S2.SS2.p2.13.m10.1a"><mrow id="Ch5.S2.SS2.p2.13.m10.1.1" xref="Ch5.S2.SS2.p2.13.m10.1.1.cmml"><mi id="Ch5.S2.SS2.p2.13.m10.1.1.2" xref="Ch5.S2.SS2.p2.13.m10.1.1.2.cmml">R</mi><mo id="Ch5.S2.SS2.p2.13.m10.1.1.1" xref="Ch5.S2.SS2.p2.13.m10.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p2.13.m10.1.1.3" xref="Ch5.S2.SS2.p2.13.m10.1.1.3.cmml">e</mi><mo id="Ch5.S2.SS2.p2.13.m10.1.1.1a" xref="Ch5.S2.SS2.p2.13.m10.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p2.13.m10.1.1.4" xref="Ch5.S2.SS2.p2.13.m10.1.1.4.cmml">v</mi><mo id="Ch5.S2.SS2.p2.13.m10.1.1.1b" xref="Ch5.S2.SS2.p2.13.m10.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p2.13.m10.1.1.5" mathvariant="normal" xref="Ch5.S2.SS2.p2.13.m10.1.1.5.cmml">@</mi><mo id="Ch5.S2.SS2.p2.13.m10.1.1.1c" xref="Ch5.S2.SS2.p2.13.m10.1.1.1.cmml">⁢</mo><mi id="Ch5.S2.SS2.p2.13.m10.1.1.6" xref="Ch5.S2.SS2.p2.13.m10.1.1.6.cmml">k</mi></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS2.p2.13.m10.1b"><apply id="Ch5.S2.SS2.p2.13.m10.1.1.cmml" xref="Ch5.S2.SS2.p2.13.m10.1.1"><times id="Ch5.S2.SS2.p2.13.m10.1.1.1.cmml" xref="Ch5.S2.SS2.p2.13.m10.1.1.1"></times><ci id="Ch5.S2.SS2.p2.13.m10.1.1.2.cmml" xref="Ch5.S2.SS2.p2.13.m10.1.1.2">𝑅</ci><ci id="Ch5.S2.SS2.p2.13.m10.1.1.3.cmml" xref="Ch5.S2.SS2.p2.13.m10.1.1.3">𝑒</ci><ci id="Ch5.S2.SS2.p2.13.m10.1.1.4.cmml" xref="Ch5.S2.SS2.p2.13.m10.1.1.4">𝑣</ci><ci id="Ch5.S2.SS2.p2.13.m10.1.1.5.cmml" xref="Ch5.S2.SS2.p2.13.m10.1.1.5">@</ci><ci id="Ch5.S2.SS2.p2.13.m10.1.1.6.cmml" xref="Ch5.S2.SS2.p2.13.m10.1.1.6">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS2.p2.13.m10.1c">Rev@k</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS2.p2.13.m10.1d">italic_R italic_e italic_v @ italic_k</annotation></semantics></math>, it is able to evaluate the revenue influence of the candidate rankers.</p>
</div>
<div class="ltx_para" id="Ch5.S2.SS2.p3">
<p class="ltx_p" id="Ch5.S2.SS2.p3.1">Empirical studies have been performed in benchmark e-commerce search datasets to find differences between relevance-based metrics and revenue-aware metrics <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span>]</cite>. Relevance-based metrics primarily measure the success of retrieving relevant data from user logs, while revenue-aware metrics provide a clearer understanding of how ranking methods influence actual revenue in e-commerce scenarios. This difference shows that, although relevance is important, incorporating revenue-aware metrics offers more practical insights into the financial impact of search ranking methods within e-commerce settings.
The lack of annotated real-world benchmarks poses a challenge for conducting large-scale empirical studies in e-commerce scenarios. To address this issue, recent studies have started using both synthetic and semi-synthetic datasets in their experiments, allowing for more controlled analysis while approximating real-world conditions <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">xu2022product</span>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch5.S2.SS3">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2.3 </span>User engagement metrics</h4>
<div class="ltx_para" id="Ch5.S2.SS3.p1">
<p class="ltx_p" id="Ch5.S2.SS3.p1.1">As we discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S2.SS2" title="3.2.2 User engagement and post-clicks ‣ 3.2 E-commerce users ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.2.2</span></a>, user engagement is defined as the quality of user experience in interaction with a system, characterized by various attributes, e.g., positive affect, aesthetic and sensory appeal, attention, novelty, and perceived user control <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mathur2016engagement</span>]</cite>.
In recent years, engagement metrics have been applied to evaluate the quality of interaction between the user and e-commerce search engines <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">vanderveld2016engagement</span>]</cite>.
User engagement metrics in e-commerce can be divided into two categories: short-term engagement metrics and long-term engagement metrics <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zou2018drlunderreview</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch5.S2.SS3.p2">
<p class="ltx_p" id="Ch5.S2.SS3.p2.1">To evaluate the quality of short-term user-system interactions, short-term engagement metrics about instant clicks, purchases, and dwell time are used in e-commerce search evaluation.
As we discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S1" title="4.1 User behavior modeling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4.1</span></a> and Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S1.SS3" title="4.1.3 Purchase-intent modeling ‣ 4.1 User behavior modeling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4.1.3</span></a>, the <em class="ltx_emph ltx_font_italic" id="Ch5.S2.SS3.p2.1.1">click-through rate</em> (CTR) and <em class="ltx_emph ltx_font_italic" id="Ch5.S2.SS3.p2.1.2">conversion rate</em> (CVR) are the two most widely applied metrics to evaluate instant click and purchase prediction.
Meanwhile, dwell time and bounce rate are the two main metrics used in short-term post-click evaluations <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lalmas2015promoting</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch5.S2.SS3.p3">
<p class="ltx_p" id="Ch5.S2.SS3.p3.1">As we discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S2.SS2" title="3.2.2 User engagement and post-clicks ‣ 3.2 E-commerce users ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.2.2</span></a>, long-term user engagement reflects the user’s desire to stay on the e-commerce portal longer and use the service repeatedly <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zou2018drlunderreview</span>]</cite>, i.e., the “stickiness.”
Long-term user engagements measure versatile user behaviors based on a very large number of environmental interactions.
Multiple long-term engagement metrics have been applied in previous studies.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2017returning</span></cite> employ cumulative clicks over time to estimate the long-term interactions between the user and the system.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zou2018drlunderreview</span></cite> applied <math alttext="3" class="ltx_Math" display="inline" id="Ch5.S2.SS3.p3.1.m1.1"><semantics id="Ch5.S2.SS3.p3.1.m1.1a"><mn id="Ch5.S2.SS3.p3.1.m1.1.1" xref="Ch5.S2.SS3.p3.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="Ch5.S2.SS3.p3.1.m1.1b"><cn id="Ch5.S2.SS3.p3.1.m1.1.1.cmml" type="integer" xref="Ch5.S2.SS3.p3.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S2.SS3.p3.1.m1.1c">3</annotation><annotation encoding="application/x-llamapun" id="Ch5.S2.SS3.p3.1.m1.1d">3</annotation></semantics></math> evaluation metrics to evaluate the long-term user interaction behaviors: (1) average clicks per session: the average cumulative number of clicks over a user visit; (2) average depth per session: the average browsing depth that the users interact with the recommender agent; and (3) average return time: the average revisiting days between.
In multilingual scenarios, a transformed query converts a secondary language query into a semantically equivalent query in the primary language, allowing it to fully utilize the existing search engines’ abilities.
To evaluate transformed queries in multilingual e-commerce search, a set of behavior metrics based on user engagement specific to the existing search system was developed. Using these metrics, a query transformation system was built and tested both offline and through online A/B tests on the Amazon platform, showing improvements in the multilingual search experience for customers <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">hu2020query</span>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="Ch5.S3">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5.3 </span>Matching strategies in e-commerce search</h3>
<div class="ltx_para" id="Ch5.S3.p1">
<p class="ltx_p" id="Ch5.S3.p1.1">In this section, we showcase recent research on matching in e-commerce search, especially concerning e-commerce query understanding and processing.
We divide this section into five parts:

<span class="ltx_inline-enumerate" id="Ch5.S3.I1">
<span class="ltx_inline-item" id="Ch5.S3.I1.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch5.S3.I1.i1.1">we recall the vocabulary gap problem in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S3.SS1" title="5.3.1 Vocabulary gap ‣ 5.3 Matching strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.3.1</span></a>;
</span></span>
<span class="ltx_inline-item" id="Ch5.S3.I1.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch5.S3.I1.i2.1">we detail representation-based matching approaches in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S3.SS2" title="5.3.2 Representation-based matching ‣ 5.3 Matching strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.3.2</span></a>;
</span></span>
<span class="ltx_inline-item" id="Ch5.S3.I1.i3"><span class="ltx_tag ltx_tag_inline-item">(iii)</span> <span class="ltx_text" id="Ch5.S3.I1.i3.1">we detail interaction-based matching approaches in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S3.SS3" title="5.3.3 Interaction-based matching ‣ 5.3 Matching strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.3.3</span></a>;
</span></span>
<span class="ltx_inline-item" id="Ch5.S3.I1.i4"><span class="ltx_tag ltx_tag_inline-item">(iv)</span> <span class="ltx_text" id="Ch5.S3.I1.i4.1">we detail hybrid matching approaches in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S3.SS4" title="5.3.4 Hybrid matching ‣ 5.3 Matching strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.3.4</span></a>; and
</span></span>
<span class="ltx_inline-item" id="Ch5.S3.I1.i5"><span class="ltx_tag ltx_tag_inline-item">(v)</span> <span class="ltx_text" id="Ch5.S3.I1.i5.1">Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S3.SS5" title="5.3.5 Matching in personalized search ‣ 5.3 Matching strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.3.5</span></a> describes studies on query processing in personalized e-commerce search.
</span></span>
</span></p>
</div>
<section class="ltx_subsection" id="Ch5.S3.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3.1 </span>Vocabulary gap</h4>
<div class="ltx_para" id="Ch5.S3.SS1.p1">
<p class="ltx_p" id="Ch5.S3.SS1.p1.1">Users’ shopping lists often differ from the product information maintained by retailers <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">nurmi2008product</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">duan2013probabilistic</span></cite> found that while query languages such as SQL can be successfully applied to search in these product databases, their usage is difficult for non-experienced end users.
In direct search scenarios in e-commerce platforms, most consumers formulate queries using characteristics of the product they are interested in (e.g., terms that describe the product’s categories, brands, and shops, etc.).
Hence, it is common to see a mismatch in e-commerce search between queries and product representations, where different tokens are used to describe the same product, i.e., the <em class="ltx_emph ltx_font_italic" id="Ch5.S3.SS1.p1.1.1">vocabulary gap problem</em> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">van2016learning</span>]</cite>.
To address this problem, early studies focus on rewriting verbose queries in e-commerce search <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bendersky2009analysis</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">xue2010improving</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">singh2012rewriting</span>]</cite>.
Selecting a subset of the original query (i.e., “sub-query”) has been shown to be effective for improving these queries.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">xue2010improving</span></cite> proposed to formally model the distribution of sub-queries, where the sub-query selection procedure is modeled as a sequential labeling problem. A conditional random field model was applied to track the local and global dependencies between query words.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">singh2012rewriting</span></cite> presented techniques to reduce long queries to effective shorter ones that lack superfluous terms.
Specifically, the authors proposed a system that provides high quality product recommendations for null queries, where time-based relevance feedback is used to improve the fidelity of rewrites.
However, these approaches focus only on the query space and overlook critical information from the product space and the connection between the two spaces <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">van2016learning</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch5.S3.SS1.p2">
<p class="ltx_p" id="Ch5.S3.SS1.p2.1">To address the vocabulary gap problem, a series of studies have been proposed to match queries and product information in e-commerce search.
Following <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">sarvi-2020-comparison</span></cite>, matching solutions can be divided into <em class="ltx_emph ltx_font_italic" id="Ch5.S3.SS1.p2.1.1">representation-based</em>, <em class="ltx_emph ltx_font_italic" id="Ch5.S3.SS1.p2.1.2">interaction-based</em>, and <em class="ltx_emph ltx_font_italic" id="Ch5.S3.SS1.p2.1.3">hybrid</em> approaches.
All of them have been shown to be effective for matching consumers’ queries and product information <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2019semantic</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yao2022reprbert</span>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch5.S3.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3.2 </span>Representation-based matching</h4>
<div class="ltx_para" id="Ch5.S3.SS2.p1">
<p class="ltx_p" id="Ch5.S3.SS2.p1.1">In early work, approaches to the task of <em class="ltx_emph ltx_font_italic" id="Ch5.S3.SS2.p1.1.1">entity finding</em> have been applied to address the vocabulary gap problem between queries and products, where products are viewed as retrievable entities <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">balog2010entity</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gade2016overview</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">van2016learning</span>]</cite>.
However, there are two problems in entity finding for e-commerce search <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">de2007overview</span>]</cite>:
First, entity finding retrieves entities of a particular type from multi-domain knowledge bases, whereas e-commerce search systems operate within a single but dynamic domain. Second, queries in e-commerce search contain a lot of free-form text <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">rowley2000product</span>]</cite>, whereas in entity finding most queries are semi-structured with relational constraints <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">balog2010entity</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch5.S3.SS2.p2">
<p class="ltx_p" id="Ch5.S3.SS2.p2.1">To address the above two problems of matching optimization, representation learning methods have been applied to obtain better representations for each text associated with products by encoding both the query and the product title into single embedding vectors. Representation learning helps by flexibly adapting to the dynamic nature of e-commerce domains. It also effectively encodes the free-form text of queries and product descriptions into a common semantic space. Many numerous neural text matching methods have been developed <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">onal-neural-2018</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">mitra2017introduction</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lin-2021-pretrained</span>]</cite>.
DSSM is one of the earliest deep learning-based models in text matching, in which each text is vectorized separately by a five-layer network <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">huang2013learning</span>]</cite>;
CDSSM replaces the full connection layer with a convolution layer and a pooling layer to generate text vectors <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">shen2014learning</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">hu2014convolutional</span></cite> proposed ARC-I, where convolution operations represent two concatenated texts for matching using a linear transformation.
CNTN also adopts convolution neural network to represent two texts, and it proposes the neural tensor network to model the similarities between two texts <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">qiu2015convolutional</span>]</cite>.
MVLSTM obtains representations for each text and adopts an interactive method to measure similarities between two texts using 3 similarity operations, i.e., cosine, bilinear, and tensor layer <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wan2016deep</span>]</cite>.
As there are important differences between web search and e-commerce search, learning query and product representations is not a solved problem.
Hence, to discriminate products based on textual descriptions, the importance of learning semantic representations of products was soon realized <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">demartini2009vector</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">van2016unsupervised</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch5.S3.SS2.p3">
<p class="ltx_p" id="Ch5.S3.SS2.p3.1"><cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">van2016learning</span></cite> proposed an unsupervised distributed representation learning approach, namely latent semantic entities (LSE), to learn a unidirectional mapping between words and entities, as well as distributed representations of both words and entities.
Given a set of entities, the authors assume that each entity has a set of associated documents. LSE then learns a function that maps a sequence of words in the query from the vocabulary to an entity vector space. Thereafter, cosine similarity is applied to calculate a relevance score between candidate entities and the query.
In Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.F1" title="Figure 5.1 ‣ 5.3.2 Representation-based matching ‣ 5.3 Matching strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.1</span></a>, we see how entities are then ranked according to the projected query.</p>
</div>
<figure class="ltx_figure" id="Ch5.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="96" id="Ch5.F1.g1" src="x30.png" width="290"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5.1: </span>Illustrative example of how entities are ranked in vector space models w.r.t. a projected query. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">van2016learning</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch5.S3.SS2.p4">
<p class="ltx_p" id="Ch5.S3.SS2.p4.1">Specifically, the authors take the representation of a string of words to be the average of the representations of the words it contains. Then, a projection matrix is employed to map the average one-hot representations to a distributed representation. Similarly, distributed representations of entities are mapped to the same space.
Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.F2" title="Figure 5.2 ‣ 5.3.2 Representation-based matching ‣ 5.3 Matching strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.2</span></a> provides a schematic overview of the LSE model.
All the parameters are learned by using gradient descent.</p>
</div>
<figure class="ltx_figure" id="Ch5.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="183" id="Ch5.F2.g1" src="x31.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5.2: </span>Schematic representation of the Latent Semantic Entities model for a single word <math alttext="w" class="ltx_Math" display="inline" id="Ch5.F2.2.m1.1"><semantics id="Ch5.F2.2.m1.1b"><mi id="Ch5.F2.2.m1.1.1" xref="Ch5.F2.2.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="Ch5.F2.2.m1.1c"><ci id="Ch5.F2.2.m1.1.1.cmml" xref="Ch5.F2.2.m1.1.1">𝑤</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.F2.2.m1.1d">w</annotation><annotation encoding="application/x-llamapun" id="Ch5.F2.2.m1.1e">italic_w</annotation></semantics></math>. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">van2016learning</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch5.S3.SS2.p5">
<p class="ltx_p" id="Ch5.S3.SS2.p5.1">Based on the LSE model, an increasing number of representation learning approaches have been proposed to address the vocabulary gap problem in e-commerce search <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">xu2018deep</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">van2018mix</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2019neural</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch5.S3.SS2.p6">
<p class="ltx_p" id="Ch5.S3.SS2.p6.1">In addition to learning the semantic representation of products, e-commerce search, due to its specific task nature, also has multiple methods for optimizing matching results.
<em class="ltx_emph ltx_font_italic" id="Ch5.S3.SS2.p6.1.1">Substitutable</em> products are those that are interchangeable in e-commerce platforms <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Wang2018Improving</span>]</cite>.
The substitutability relation among products can be determined in multiple ways.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">van2018mix</span></cite> found that product substitutability relations can facilitate the retrieval of relevant products impacted by the vocabulary gap problem, i.e., product substitutability can be integrated into product search either extrinsically or intrinsically.
The authors proposed a two stage framework to combine textual matching method (i.e., the LSE model) and substitutability to infer representations of queries and products. Unlike previous work on entity representation learning, the authors integrated relations among entities within the latent semantic space inference.</p>
</div>
<div class="ltx_para" id="Ch5.S3.SS2.p7">
<p class="ltx_p" id="Ch5.S3.SS2.p7.1">Users often browse multiple search results pages and make comparisons before purchase.
Relevance feedback (RF) approaches were proposed to extract the relevant topic <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">jin2013interactive</span>]</cite>. However, the mismatch problem between queries and products still existed in the task of multi-page e-commerce search.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">bi2019study</span></cite> analyzed different context dependency assumptions in multiple search result pages, and proposed a context-aware embedding model to capture different types of dependency.
The authors introduced three different types of context dependencies:

<span class="ltx_inline-enumerate" id="Ch5.S3.I2">
<span class="ltx_inline-item" id="Ch5.S3.I2.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch5.S3.I2.i1.1">long-term context dependency,
</span></span>
<span class="ltx_inline-item" id="Ch5.S3.I2.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch5.S3.I2.i2.1">short-term context dependency, and
</span></span>
<span class="ltx_inline-item" id="Ch5.S3.I2.i3"><span class="ltx_tag ltx_tag_inline-item">(iii)</span> <span class="ltx_text" id="Ch5.S3.I2.i3.1">long-short-term context dependency.
</span></span>
</span>
Given these three types of context dependencies, a context-aware embedding model was proposed.
By assuming that the users’ preferences are associated with their implicit feedback, the embedding model, namely CEM, captures user preferences from their clicked items, which are implicit positive signals.</p>
</div>
<div class="ltx_para" id="Ch5.S3.SS2.p8">
<p class="ltx_p" id="Ch5.S3.SS2.p8.1">Another important aspect of e-commerce search is query reformulations by users. Based on query logs of eBay’s search engine, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">hirsch2020query</span></cite> proposed the first large-scale and in-depth study of users’ query reformulations in e-commerce search. The authors analyzed many aspects of search sessions composed of query reformulations, e.g., the number of reformulations and the distribution of their types, changes of search results pages as a result of the reformulations, clicks and purchases. An approach was proposed to predict if a query will be reformulated in an e-commerce search session.
The authors find that post-retrieval features and query performance predictors contribute the most to the prediction of reformulation.
By incorporating these features, the accuracy in predicting whether users will reformulate their queries can be significantly enhanced.
Based on the attention mechanism, the MMAN model was proposed to enhance query representation by extending category information and includes three main modules: self-matching, char-level matching, and semantic-level matching <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Yuan_2023</span>]</cite>. Experiments have shown that these modules improve query representation, effectively handle long-tail queries, and achieve better semantic disambiguation.</p>
</div>
<div class="ltx_para" id="Ch5.S3.SS2.p9">
<p class="ltx_p" id="Ch5.S3.SS2.p9.1">In recent years, graph neural networks (GNNs) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">scarselli2008graph</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kipf2016semi</span>]</cite> have been applied to e-commerce search to help infer query and product embeddings.
GNNs derive node representations by aggregating features appearing in the neighborhood.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">niu2020dual</span></cite> proposed a GNN-based method to learn representations of users and shops in e-commerce search.
Specifically, the authors proposed a dual hierarchical graph attention network for e-commerce search. A heterogeneous graph was constructed to perform graph-based representation learning for both shops and queries, which includes both first-order and second-order proximities from various user interactions in e-commerce.
The authors verified that their proposed method can help to relieve the semantic gap between user queries and shop names by borrowing item neighbor title text. Furthermore, the proposed neighbor proximity loss provides strong additional guidance for learning graph topological structure.
The results of large-scale offline evaluations and online A/B tests demonstrate the significant superiority of this approach.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chang2021extreme</span></cite> transferred the matching problem as an extreme multi-label classification problem <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yu2022pecos</span>]</cite>, aiming to tag input instances (i.e., queries) with the most relevant output labels of products. The authors proposed a tree-based sparse linear model with n-gram TF-IDF features to augment the diversity of the matching results.
For multi-lingual search scenarios in e-commerce, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">lu2021graph</span></cite> proposed a graph-based model with a graph convolution layer to fill the vocabulary gap.</p>
</div>
<div class="ltx_para" id="Ch5.S3.SS2.p10">
<p class="ltx_p" id="Ch5.S3.SS2.p10.1">Transformer-based pre-trained models like BERT <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">kenton2019bert</span>]</cite> utilize stacked encoder layers that rely on a self-attention mechanism.
This mechanism allows each word in a sequence to attend to all other words, facilitating capturing richer semantic relations throughout the sequence. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chang2020pre</span></cite> conducted a comprehensive study applying a pre-trained dual-tower matching model across multiple retrieval tasks, demonstrating the effectiveness of such models in enhancing retrieval performance.
BERT and BERT-like pre-trained models has been applied in product search <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">peeters2020intermediate</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2022towards</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">qiu2022pre</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2023learning</span>]</cite>. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">qiu2022pre</span></cite> applied dual-tower pre-training strategies to optimize both user intent detection and embedding retrieval in e-commerce search.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2022towards</span></cite> examined the performance of multiple pre-training embedding methods and observed that query representation learning remains a bottleneck compared to product representation learning when using these semantic search training objectives.
Recently, large-scale pre-trained language models, such as GPT-3 <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">brown2020language</span>]</cite>, also demonstrate promising performance across several benchmarks <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">kim2022ask</span>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch5.S3.SS3">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3.3 </span>Interaction-based matching</h4>
<div class="ltx_para" id="Ch5.S3.SS3.p1">
<p class="ltx_p" id="Ch5.S3.SS3.p1.1">However, encoding queries and products in representation-based matching methods are independent of each other.
These individual queries and products into
the fixed-dimensional vectors may lose the fine-grained matching information.
To tackle this challenge, interaction-based matching was proposed.
This kind of method first matches different parts of the query with different parts of the document and then aggregates the partial evidence of relevance.
In contrast to representation-based matching methods, interaction-based approaches usually build an interaction matrix between two documents and optimize it for matching <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">hu2014convolutional</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">pang2016text</span>]</cite>.
This interaction-based matching approach was applied in web-based retrieval at first.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">hu2014convolutional</span></cite> built an interaction matrix to conduct several convolution and pooling operations to extract matching features.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2016deep</span></cite> mentioned three factors in relevance matching: exact matching signals, query term importance, and diverse matching requirements, and designed the architecture of their deep matching model.
Similarly, the model of MatchPyramid constructs an interaction matrix to capture matching patterns <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">pang2016text</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">mitra2017learning</span></cite> employed both distributed representations and local representations to obtain the final matching score.
Subsequently, researchers proposed a series of matching approaches specifically for e-commerce built upon existing interaction-based approaches.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2019matchzoo</span></cite> proposed a model based on the MatchZoo. It is meant for short-text matching and replaces the matching histogram with a top-k max pooling layer.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">li2020deep</span></cite> proposed a product matching model, namely PMM, to make use of the information contained in titles and attributes of products, respectively. PMM consists of two modules, a product title matching module, and a product attributes matching module. The former computes similarities between product titles, whereas the latter measures similarities between product attribute set.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">bi2019leverage</span></cite> proposed an end-to-end context-aware embedding model that can incorporate both long-term and short-term contexts to predict purchased items, unlike most approaches that focus on relevance feedback.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch5.S3.SS4">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3.4 </span>Hybrid matching</h4>
<div class="ltx_para" id="Ch5.S3.SS4.p1">
<p class="ltx_p" id="Ch5.S3.SS4.p1.1">Recently, more and more hybrid matching models have been proposed to combine the strengths of representation- and interaction-based models.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">mitra2017learning</span></cite> proposed a matching model, namely DUET, which integrates both local (interaction-based) and distributed (representation-based) features to calculate query-document relevance.
Pre-trained language models, such as BERT <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">kenton2019bert</span>]</cite>, have further advanced hybrid approaches by capturing both contextualized token-level interactions and global semantic representations, achieving promising performance in tasks like search and recommendation <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2019bert4rec</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">nogueira2019multi</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lin2021pretrained</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">tracz2020bert</span></cite> proposed a BERT-based model to leverage both types of matching in a similarity learning framework for product matching in e-commerce.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">yao2022reprbert</span></cite> explored the deployment of BERT in online retrieval systems by distilling it into a representation-based architecture, while still maintaining the advantages of interaction-based processing for more precise matching.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch5.S3.SS5">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3.5 </span>Matching in personalized search</h4>
<div class="ltx_para" id="Ch5.S3.SS5.p1">
<p class="ltx_p" id="Ch5.S3.SS5.p1.1">One of the primary characteristics of e-commerce search is its highly personal variance in queries.
First, multiple items could be topic-related with a consumer’s query, but only a few are actually purchased, i.e., different individuals have different opinions even on the same
product. Hence e-commerce search without personalization cannot satisfy consumers.
Second, personalization has explicit benefits for e-commerce platforms by exhibiting the products that consumers would like to purchase. As we have demonstrated in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S1" title="5.1 Characteristics of e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.1</span></a>, the definition of “relevance” for e-commerce search is not the same as for web-based search as most of e-commerce platforms apply gross merchandise volume (GMV) as the gold standard for measuring success.
To the best of our knowledge, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">jannach2017investigating</span></cite> were the first to attempt to personalize product search by using personalized recommendation approaches.
However, the matching problem in personalized e-commerce search is more challenging as most platforms have approaches to matching products to queries that are far from perfect.
To address this problem, an increasing number of matching studies have been proposed.
Matching approaches in personalized product search can be classified into query-independent and query-dependent ones <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2022category</span>]</cite>.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch5.S3.SS5.p2">
<p class="ltx_p" id="Ch5.S3.SS5.p2.8"><span class="ltx_text ltx_font_bold" id="Ch5.S3.SS5.p2.8.1">Query-independent matching.</span>
The query-independent matching methods embedded users into a general profiling vector in the offline training stage <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ai2017learning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ai2019explainable</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2020structural</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ai2017learning</span></cite> proposed a deep neural network and jointly learn latent representations for queries, products, and users. Specifically, a hierarchical embedding model is proposed for personalized e-commerce search.
As illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.F3" title="Figure 5.3 ‣ 5.3.5 Matching in personalized search ‣ 5.3 Matching strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.3</span></a>, the authors projected both queries and consumers into a single latent space and explicitly control their weights in a personalized product search model.
Following <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">van2016learning</span></cite>, the authors designed the latent representations of queries and users to have good compositionality so that the personalized search model can be directly computed as a linear combination of query models and user models. Specifically, both queries and users are projected into a single latent space. Given a query <math alttext="q" class="ltx_Math" display="inline" id="Ch5.S3.SS5.p2.1.m1.1"><semantics id="Ch5.S3.SS5.p2.1.m1.1a"><mi id="Ch5.S3.SS5.p2.1.m1.1.1" xref="Ch5.S3.SS5.p2.1.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="Ch5.S3.SS5.p2.1.m1.1b"><ci id="Ch5.S3.SS5.p2.1.m1.1.1.cmml" xref="Ch5.S3.SS5.p2.1.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S3.SS5.p2.1.m1.1c">q</annotation><annotation encoding="application/x-llamapun" id="Ch5.S3.SS5.p2.1.m1.1d">italic_q</annotation></semantics></math>, the corresponding query intent is represented in <math alttext="R^{\alpha}" class="ltx_Math" display="inline" id="Ch5.S3.SS5.p2.2.m2.1"><semantics id="Ch5.S3.SS5.p2.2.m2.1a"><msup id="Ch5.S3.SS5.p2.2.m2.1.1" xref="Ch5.S3.SS5.p2.2.m2.1.1.cmml"><mi id="Ch5.S3.SS5.p2.2.m2.1.1.2" xref="Ch5.S3.SS5.p2.2.m2.1.1.2.cmml">R</mi><mi id="Ch5.S3.SS5.p2.2.m2.1.1.3" xref="Ch5.S3.SS5.p2.2.m2.1.1.3.cmml">α</mi></msup><annotation-xml encoding="MathML-Content" id="Ch5.S3.SS5.p2.2.m2.1b"><apply id="Ch5.S3.SS5.p2.2.m2.1.1.cmml" xref="Ch5.S3.SS5.p2.2.m2.1.1"><csymbol cd="ambiguous" id="Ch5.S3.SS5.p2.2.m2.1.1.1.cmml" xref="Ch5.S3.SS5.p2.2.m2.1.1">superscript</csymbol><ci id="Ch5.S3.SS5.p2.2.m2.1.1.2.cmml" xref="Ch5.S3.SS5.p2.2.m2.1.1.2">𝑅</ci><ci id="Ch5.S3.SS5.p2.2.m2.1.1.3.cmml" xref="Ch5.S3.SS5.p2.2.m2.1.1.3">𝛼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S3.SS5.p2.2.m2.1c">R^{\alpha}</annotation><annotation encoding="application/x-llamapun" id="Ch5.S3.SS5.p2.2.m2.1d">italic_R start_POSTSUPERSCRIPT italic_α end_POSTSUPERSCRIPT</annotation></semantics></math>; similarly, the user preference is represented in <math alttext="R^{\alpha}" class="ltx_Math" display="inline" id="Ch5.S3.SS5.p2.3.m3.1"><semantics id="Ch5.S3.SS5.p2.3.m3.1a"><msup id="Ch5.S3.SS5.p2.3.m3.1.1" xref="Ch5.S3.SS5.p2.3.m3.1.1.cmml"><mi id="Ch5.S3.SS5.p2.3.m3.1.1.2" xref="Ch5.S3.SS5.p2.3.m3.1.1.2.cmml">R</mi><mi id="Ch5.S3.SS5.p2.3.m3.1.1.3" xref="Ch5.S3.SS5.p2.3.m3.1.1.3.cmml">α</mi></msup><annotation-xml encoding="MathML-Content" id="Ch5.S3.SS5.p2.3.m3.1b"><apply id="Ch5.S3.SS5.p2.3.m3.1.1.cmml" xref="Ch5.S3.SS5.p2.3.m3.1.1"><csymbol cd="ambiguous" id="Ch5.S3.SS5.p2.3.m3.1.1.1.cmml" xref="Ch5.S3.SS5.p2.3.m3.1.1">superscript</csymbol><ci id="Ch5.S3.SS5.p2.3.m3.1.1.2.cmml" xref="Ch5.S3.SS5.p2.3.m3.1.1.2">𝑅</ci><ci id="Ch5.S3.SS5.p2.3.m3.1.1.3.cmml" xref="Ch5.S3.SS5.p2.3.m3.1.1.3">𝛼</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S3.SS5.p2.3.m3.1c">R^{\alpha}</annotation><annotation encoding="application/x-llamapun" id="Ch5.S3.SS5.p2.3.m3.1d">italic_R start_POSTSUPERSCRIPT italic_α end_POSTSUPERSCRIPT</annotation></semantics></math> given a user <math alttext="u" class="ltx_Math" display="inline" id="Ch5.S3.SS5.p2.4.m4.1"><semantics id="Ch5.S3.SS5.p2.4.m4.1a"><mi id="Ch5.S3.SS5.p2.4.m4.1.1" xref="Ch5.S3.SS5.p2.4.m4.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="Ch5.S3.SS5.p2.4.m4.1b"><ci id="Ch5.S3.SS5.p2.4.m4.1.1.cmml" xref="Ch5.S3.SS5.p2.4.m4.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S3.SS5.p2.4.m4.1c">u</annotation><annotation encoding="application/x-llamapun" id="Ch5.S3.SS5.p2.4.m4.1d">italic_u</annotation></semantics></math>.
As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.F3" title="Figure 5.3 ‣ 5.3.5 Matching in personalized search ‣ 5.3 Matching strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.3</span></a>, the personalized product retrieval model is defined as <math alttext="{M_{uq}}=\lambda q+(1-\lambda)u" class="ltx_Math" display="inline" id="Ch5.S3.SS5.p2.5.m5.1"><semantics id="Ch5.S3.SS5.p2.5.m5.1a"><mrow id="Ch5.S3.SS5.p2.5.m5.1.1" xref="Ch5.S3.SS5.p2.5.m5.1.1.cmml"><msub id="Ch5.S3.SS5.p2.5.m5.1.1.3" xref="Ch5.S3.SS5.p2.5.m5.1.1.3.cmml"><mi id="Ch5.S3.SS5.p2.5.m5.1.1.3.2" xref="Ch5.S3.SS5.p2.5.m5.1.1.3.2.cmml">M</mi><mrow id="Ch5.S3.SS5.p2.5.m5.1.1.3.3" xref="Ch5.S3.SS5.p2.5.m5.1.1.3.3.cmml"><mi id="Ch5.S3.SS5.p2.5.m5.1.1.3.3.2" xref="Ch5.S3.SS5.p2.5.m5.1.1.3.3.2.cmml">u</mi><mo id="Ch5.S3.SS5.p2.5.m5.1.1.3.3.1" xref="Ch5.S3.SS5.p2.5.m5.1.1.3.3.1.cmml">⁢</mo><mi id="Ch5.S3.SS5.p2.5.m5.1.1.3.3.3" xref="Ch5.S3.SS5.p2.5.m5.1.1.3.3.3.cmml">q</mi></mrow></msub><mo id="Ch5.S3.SS5.p2.5.m5.1.1.2" xref="Ch5.S3.SS5.p2.5.m5.1.1.2.cmml">=</mo><mrow id="Ch5.S3.SS5.p2.5.m5.1.1.1" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.cmml"><mrow id="Ch5.S3.SS5.p2.5.m5.1.1.1.3" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.3.cmml"><mi id="Ch5.S3.SS5.p2.5.m5.1.1.1.3.2" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.3.2.cmml">λ</mi><mo id="Ch5.S3.SS5.p2.5.m5.1.1.1.3.1" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.3.1.cmml">⁢</mo><mi id="Ch5.S3.SS5.p2.5.m5.1.1.1.3.3" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.3.3.cmml">q</mi></mrow><mo id="Ch5.S3.SS5.p2.5.m5.1.1.1.2" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.2.cmml">+</mo><mrow id="Ch5.S3.SS5.p2.5.m5.1.1.1.1" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.1.cmml"><mrow id="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1.1.cmml"><mo id="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1.2" stretchy="false" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1.1.cmml">(</mo><mrow id="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1.1" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1.1.cmml"><mn id="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1.1.2" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1.1.2.cmml">1</mn><mo id="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1.1.1" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1.1.1.cmml">−</mo><mi id="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1.1.3" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1.1.3.cmml">λ</mi></mrow><mo id="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1.3" stretchy="false" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="Ch5.S3.SS5.p2.5.m5.1.1.1.1.2" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.1.2.cmml">⁢</mo><mi id="Ch5.S3.SS5.p2.5.m5.1.1.1.1.3" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.1.3.cmml">u</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S3.SS5.p2.5.m5.1b"><apply id="Ch5.S3.SS5.p2.5.m5.1.1.cmml" xref="Ch5.S3.SS5.p2.5.m5.1.1"><eq id="Ch5.S3.SS5.p2.5.m5.1.1.2.cmml" xref="Ch5.S3.SS5.p2.5.m5.1.1.2"></eq><apply id="Ch5.S3.SS5.p2.5.m5.1.1.3.cmml" xref="Ch5.S3.SS5.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="Ch5.S3.SS5.p2.5.m5.1.1.3.1.cmml" xref="Ch5.S3.SS5.p2.5.m5.1.1.3">subscript</csymbol><ci id="Ch5.S3.SS5.p2.5.m5.1.1.3.2.cmml" xref="Ch5.S3.SS5.p2.5.m5.1.1.3.2">𝑀</ci><apply id="Ch5.S3.SS5.p2.5.m5.1.1.3.3.cmml" xref="Ch5.S3.SS5.p2.5.m5.1.1.3.3"><times id="Ch5.S3.SS5.p2.5.m5.1.1.3.3.1.cmml" xref="Ch5.S3.SS5.p2.5.m5.1.1.3.3.1"></times><ci id="Ch5.S3.SS5.p2.5.m5.1.1.3.3.2.cmml" xref="Ch5.S3.SS5.p2.5.m5.1.1.3.3.2">𝑢</ci><ci id="Ch5.S3.SS5.p2.5.m5.1.1.3.3.3.cmml" xref="Ch5.S3.SS5.p2.5.m5.1.1.3.3.3">𝑞</ci></apply></apply><apply id="Ch5.S3.SS5.p2.5.m5.1.1.1.cmml" xref="Ch5.S3.SS5.p2.5.m5.1.1.1"><plus id="Ch5.S3.SS5.p2.5.m5.1.1.1.2.cmml" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.2"></plus><apply id="Ch5.S3.SS5.p2.5.m5.1.1.1.3.cmml" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.3"><times id="Ch5.S3.SS5.p2.5.m5.1.1.1.3.1.cmml" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.3.1"></times><ci id="Ch5.S3.SS5.p2.5.m5.1.1.1.3.2.cmml" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.3.2">𝜆</ci><ci id="Ch5.S3.SS5.p2.5.m5.1.1.1.3.3.cmml" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.3.3">𝑞</ci></apply><apply id="Ch5.S3.SS5.p2.5.m5.1.1.1.1.cmml" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.1"><times id="Ch5.S3.SS5.p2.5.m5.1.1.1.1.2.cmml" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.1.2"></times><apply id="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1.1.cmml" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1"><minus id="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1.1.1.cmml" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1.1.1"></minus><cn id="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1.1.2.cmml" type="integer" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1.1.2">1</cn><ci id="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1.1.3.cmml" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.1.1.1.1.3">𝜆</ci></apply><ci id="Ch5.S3.SS5.p2.5.m5.1.1.1.1.3.cmml" xref="Ch5.S3.SS5.p2.5.m5.1.1.1.1.3">𝑢</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S3.SS5.p2.5.m5.1c">{M_{uq}}=\lambda q+(1-\lambda)u</annotation><annotation encoding="application/x-llamapun" id="Ch5.S3.SS5.p2.5.m5.1d">italic_M start_POSTSUBSCRIPT italic_u italic_q end_POSTSUBSCRIPT = italic_λ italic_q + ( 1 - italic_λ ) italic_u</annotation></semantics></math>, where <math alttext="\lambda" class="ltx_Math" display="inline" id="Ch5.S3.SS5.p2.6.m6.1"><semantics id="Ch5.S3.SS5.p2.6.m6.1a"><mi id="Ch5.S3.SS5.p2.6.m6.1.1" xref="Ch5.S3.SS5.p2.6.m6.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="Ch5.S3.SS5.p2.6.m6.1b"><ci id="Ch5.S3.SS5.p2.6.m6.1.1.cmml" xref="Ch5.S3.SS5.p2.6.m6.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S3.SS5.p2.6.m6.1c">\lambda</annotation><annotation encoding="application/x-llamapun" id="Ch5.S3.SS5.p2.6.m6.1d">italic_λ</annotation></semantics></math> is a hyper-parameter that controls the weight of the query model <math alttext="q" class="ltx_Math" display="inline" id="Ch5.S3.SS5.p2.7.m7.1"><semantics id="Ch5.S3.SS5.p2.7.m7.1a"><mi id="Ch5.S3.SS5.p2.7.m7.1.1" xref="Ch5.S3.SS5.p2.7.m7.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="Ch5.S3.SS5.p2.7.m7.1b"><ci id="Ch5.S3.SS5.p2.7.m7.1.1.cmml" xref="Ch5.S3.SS5.p2.7.m7.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S3.SS5.p2.7.m7.1c">q</annotation><annotation encoding="application/x-llamapun" id="Ch5.S3.SS5.p2.7.m7.1d">italic_q</annotation></semantics></math> and the user model <math alttext="u" class="ltx_Math" display="inline" id="Ch5.S3.SS5.p2.8.m8.1"><semantics id="Ch5.S3.SS5.p2.8.m8.1a"><mi id="Ch5.S3.SS5.p2.8.m8.1.1" xref="Ch5.S3.SS5.p2.8.m8.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="Ch5.S3.SS5.p2.8.m8.1b"><ci id="Ch5.S3.SS5.p2.8.m8.1.1.cmml" xref="Ch5.S3.SS5.p2.8.m8.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S3.SS5.p2.8.m8.1c">u</annotation><annotation encoding="application/x-llamapun" id="Ch5.S3.SS5.p2.8.m8.1d">italic_u</annotation></semantics></math>. To alleviate the mismatch problem during personalized product search, the authors proposed a hierarchical embedding approach to reflect the distributed representations of users, items, and queries. The experiments are conducted with synthetic queries generated from product category information.</p>
</div>
<figure class="ltx_figure" id="Ch5.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="195" id="Ch5.F3.g1" src="x32.png" width="290"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5.3: </span>Personalized product search in a latent space with query <math alttext="q" class="ltx_Math" display="inline" id="Ch5.F3.5.m1.1"><semantics id="Ch5.F3.5.m1.1b"><mi id="Ch5.F3.5.m1.1.1" xref="Ch5.F3.5.m1.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="Ch5.F3.5.m1.1c"><ci id="Ch5.F3.5.m1.1.1.cmml" xref="Ch5.F3.5.m1.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.F3.5.m1.1d">q</annotation><annotation encoding="application/x-llamapun" id="Ch5.F3.5.m1.1e">italic_q</annotation></semantics></math>, user <math alttext="u" class="ltx_Math" display="inline" id="Ch5.F3.6.m2.1"><semantics id="Ch5.F3.6.m2.1b"><mi id="Ch5.F3.6.m2.1.1" xref="Ch5.F3.6.m2.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="Ch5.F3.6.m2.1c"><ci id="Ch5.F3.6.m2.1.1.cmml" xref="Ch5.F3.6.m2.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.F3.6.m2.1d">u</annotation><annotation encoding="application/x-llamapun" id="Ch5.F3.6.m2.1e">italic_u</annotation></semantics></math>, personalized search model <math alttext="M_{uq}" class="ltx_Math" display="inline" id="Ch5.F3.7.m3.1"><semantics id="Ch5.F3.7.m3.1b"><msub id="Ch5.F3.7.m3.1.1" xref="Ch5.F3.7.m3.1.1.cmml"><mi id="Ch5.F3.7.m3.1.1.2" xref="Ch5.F3.7.m3.1.1.2.cmml">M</mi><mrow id="Ch5.F3.7.m3.1.1.3" xref="Ch5.F3.7.m3.1.1.3.cmml"><mi id="Ch5.F3.7.m3.1.1.3.2" xref="Ch5.F3.7.m3.1.1.3.2.cmml">u</mi><mo id="Ch5.F3.7.m3.1.1.3.1" xref="Ch5.F3.7.m3.1.1.3.1.cmml">⁢</mo><mi id="Ch5.F3.7.m3.1.1.3.3" xref="Ch5.F3.7.m3.1.1.3.3.cmml">q</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="Ch5.F3.7.m3.1c"><apply id="Ch5.F3.7.m3.1.1.cmml" xref="Ch5.F3.7.m3.1.1"><csymbol cd="ambiguous" id="Ch5.F3.7.m3.1.1.1.cmml" xref="Ch5.F3.7.m3.1.1">subscript</csymbol><ci id="Ch5.F3.7.m3.1.1.2.cmml" xref="Ch5.F3.7.m3.1.1.2">𝑀</ci><apply id="Ch5.F3.7.m3.1.1.3.cmml" xref="Ch5.F3.7.m3.1.1.3"><times id="Ch5.F3.7.m3.1.1.3.1.cmml" xref="Ch5.F3.7.m3.1.1.3.1"></times><ci id="Ch5.F3.7.m3.1.1.3.2.cmml" xref="Ch5.F3.7.m3.1.1.3.2">𝑢</ci><ci id="Ch5.F3.7.m3.1.1.3.3.cmml" xref="Ch5.F3.7.m3.1.1.3.3">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.F3.7.m3.1d">M_{uq}</annotation><annotation encoding="application/x-llamapun" id="Ch5.F3.7.m3.1e">italic_M start_POSTSUBSCRIPT italic_u italic_q end_POSTSUBSCRIPT</annotation></semantics></math> and item <math alttext="i" class="ltx_Math" display="inline" id="Ch5.F3.8.m4.1"><semantics id="Ch5.F3.8.m4.1b"><mi id="Ch5.F3.8.m4.1.1" xref="Ch5.F3.8.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="Ch5.F3.8.m4.1c"><ci id="Ch5.F3.8.m4.1.1.cmml" xref="Ch5.F3.8.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.F3.8.m4.1d">i</annotation><annotation encoding="application/x-llamapun" id="Ch5.F3.8.m4.1e">italic_i</annotation></semantics></math>. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ai2017learning</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch5.S3.SS5.p3">
<p class="ltx_p" id="Ch5.S3.SS5.p3.1">External structured knowledge graphs have been applied to enhance the personalized matching procedure.
Structured relationship among users, products, and queries has been jointly considered in a novel graph neural network approach <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ai2019explainable</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2020structural</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ai2019explainable</span></cite> proposed a unified knowledge graph on multiple types of product data, and conducted retrieval with it: a dynamic relation embedding module was proposed to construct a session-based knowledge graph; a soft matching algorithm was able to efficiently extract explainable paths with knowledge embeddings.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2020structural</span></cite> exploited the structured representation learning scheme from user-query-product interactions with conjunctive graph patterns. Geometric operations, such as projections and intersections, are applied in the proposed graph neural networks.
Derived from the knowledge graph embedding, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2022category</span></cite> used multiple vectors to encode the diverse preferences of users.
The authors leveraged the category information to aggregate the multiple interests of users with category indications as references.
To sufficiently exploit collaborative signals among products, users, and queries, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">cheng2022ihgnn</span></cite> proposed a hypergraph-based method from the ternary user-product-query interactions, by considering high-order features of neighbors.
Query-independent matching models can calculate user embeddings and store them in advance, which makes it convenient and efficient to apply in real-world search engines.
To tackle inconsistent user behavior in multi-stage e-commerce search systems, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2023learning</span></cite> employed external information to refine query-item matching. By mining various user interactions (ordered, clicked, unclicked items) within a post-fusion strategy, they generated more accurate semantic representations. This approach not only enhances retrieval efficiency, but also improves both offline recall and online conversion rates.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch5.S3.SS5.p4">
<p class="ltx_p" id="Ch5.S3.SS5.p4.13"><span class="ltx_text ltx_font_bold" id="Ch5.S3.SS5.p4.13.1">Query-dependent matching.</span>
To capture users’ dynamic interests given the current query, query-dependent matching approaches were proposed to establish user profiles in the running time <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ai2019zero</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2018attentive</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">xiao2019dynamic</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">bi2020transformer</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">bi2020learning</span>]</cite>.
To address the problem of when and how to conduct search personalization in product retrieval, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ai2019zero</span></cite> conducted an empirical analysis of the potential of personalization in product search with large-scale search logs sampled from a real-world e-commerce search engine.
To analyze query specificity, the authors computed the purchase entropy of each query in the sampled e-commerce search logs as <math alttext="\mathit{Entropy}(q)=-\sum_{i\in{I_{q}}}{P(i|q)\log P(i|q)}" class="ltx_Math" display="inline" id="Ch5.S3.SS5.p4.1.m1.3"><semantics id="Ch5.S3.SS5.p4.1.m1.3a"><mrow id="Ch5.S3.SS5.p4.1.m1.3.3" xref="Ch5.S3.SS5.p4.1.m1.3.3.cmml"><mrow id="Ch5.S3.SS5.p4.1.m1.3.3.4" xref="Ch5.S3.SS5.p4.1.m1.3.3.4.cmml"><mi id="Ch5.S3.SS5.p4.1.m1.3.3.4.2" xref="Ch5.S3.SS5.p4.1.m1.3.3.4.2.cmml">𝐸𝑛𝑡𝑟𝑜𝑝𝑦</mi><mo id="Ch5.S3.SS5.p4.1.m1.3.3.4.1" xref="Ch5.S3.SS5.p4.1.m1.3.3.4.1.cmml">⁢</mo><mrow id="Ch5.S3.SS5.p4.1.m1.3.3.4.3.2" xref="Ch5.S3.SS5.p4.1.m1.3.3.4.cmml"><mo id="Ch5.S3.SS5.p4.1.m1.3.3.4.3.2.1" stretchy="false" xref="Ch5.S3.SS5.p4.1.m1.3.3.4.cmml">(</mo><mi id="Ch5.S3.SS5.p4.1.m1.1.1" xref="Ch5.S3.SS5.p4.1.m1.1.1.cmml">q</mi><mo id="Ch5.S3.SS5.p4.1.m1.3.3.4.3.2.2" stretchy="false" xref="Ch5.S3.SS5.p4.1.m1.3.3.4.cmml">)</mo></mrow></mrow><mo id="Ch5.S3.SS5.p4.1.m1.3.3.3" xref="Ch5.S3.SS5.p4.1.m1.3.3.3.cmml">=</mo><mrow id="Ch5.S3.SS5.p4.1.m1.3.3.2" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.cmml"><mo id="Ch5.S3.SS5.p4.1.m1.3.3.2a" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.cmml">−</mo><mrow id="Ch5.S3.SS5.p4.1.m1.3.3.2.2" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.cmml"><msub id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.cmml"><mo id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.2" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.2.cmml">∑</mo><mrow id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.cmml"><mi id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.2" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.2.cmml">i</mi><mo id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.1" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.1.cmml">∈</mo><msub id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.3" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.3.cmml"><mi id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.3.2" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.3.2.cmml">I</mi><mi id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.3.3" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.3.3.cmml">q</mi></msub></mrow></msub><mrow id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.cmml"><mi id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.4" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.4.cmml">P</mi><mo id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.3" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.3.cmml">⁢</mo><mrow id="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1" xref="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1.1.cmml"><mo id="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1.2" stretchy="false" xref="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1.1" xref="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1.1.cmml"><mi id="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1.1.2" xref="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1.1.2.cmml">i</mi><mo fence="false" id="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1.1.1" xref="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1.1.1.cmml">|</mo><mi id="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1.1.3" xref="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1.1.3.cmml">q</mi></mrow><mo id="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1.3" stretchy="false" xref="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1.1.cmml">)</mo></mrow><mo id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.3a" lspace="0.167em" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.3.cmml">⁢</mo><mrow id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.5" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.5.cmml"><mi id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.5.1" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.5.1.cmml">log</mi><mo id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.5a" lspace="0.167em" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.5.cmml">⁡</mo><mi id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.5.2" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.5.2.cmml">P</mi></mrow><mo id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.3b" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.3.cmml">⁢</mo><mrow id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1.1.cmml"><mo id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1.2" stretchy="false" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1.1.cmml">(</mo><mrow id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1.1" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1.1.cmml"><mi id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1.1.2" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1.1.2.cmml">i</mi><mo fence="false" id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1.1.1" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1.1.1.cmml">|</mo><mi id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1.1.3" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1.1.3.cmml">q</mi></mrow><mo id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1.3" stretchy="false" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S3.SS5.p4.1.m1.3b"><apply id="Ch5.S3.SS5.p4.1.m1.3.3.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3"><eq id="Ch5.S3.SS5.p4.1.m1.3.3.3.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.3"></eq><apply id="Ch5.S3.SS5.p4.1.m1.3.3.4.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.4"><times id="Ch5.S3.SS5.p4.1.m1.3.3.4.1.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.4.1"></times><ci id="Ch5.S3.SS5.p4.1.m1.3.3.4.2.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.4.2">𝐸𝑛𝑡𝑟𝑜𝑝𝑦</ci><ci id="Ch5.S3.SS5.p4.1.m1.1.1.cmml" xref="Ch5.S3.SS5.p4.1.m1.1.1">𝑞</ci></apply><apply id="Ch5.S3.SS5.p4.1.m1.3.3.2.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2"><minus id="Ch5.S3.SS5.p4.1.m1.3.3.2.3.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2"></minus><apply id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2"><apply id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3"><csymbol cd="ambiguous" id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.1.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3">subscript</csymbol><sum id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.2.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.2"></sum><apply id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3"><in id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.1.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.1"></in><ci id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.2.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.2">𝑖</ci><apply id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.3.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.3"><csymbol cd="ambiguous" id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.3.1.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.3">subscript</csymbol><ci id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.3.2.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.3.2">𝐼</ci><ci id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.3.3.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.3.3.3.3">𝑞</ci></apply></apply></apply><apply id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2"><times id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.3.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.3"></times><ci id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.4.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.4">𝑃</ci><apply id="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1.1.cmml" xref="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1"><csymbol cd="latexml" id="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1.1.1">conditional</csymbol><ci id="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1.1.2.cmml" xref="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1.1.2">𝑖</ci><ci id="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1.1.3.cmml" xref="Ch5.S3.SS5.p4.1.m1.2.2.1.1.1.1.1.1.3">𝑞</ci></apply><apply id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.5.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.5"><log id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.5.1.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.5.1"></log><ci id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.5.2.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.5.2">𝑃</ci></apply><apply id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1.1.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1"><csymbol cd="latexml" id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1.1.1.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1.1.1">conditional</csymbol><ci id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1.1.2.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1.1.2">𝑖</ci><ci id="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1.1.3.cmml" xref="Ch5.S3.SS5.p4.1.m1.3.3.2.2.2.2.1.1.3">𝑞</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S3.SS5.p4.1.m1.3c">\mathit{Entropy}(q)=-\sum_{i\in{I_{q}}}{P(i|q)\log P(i|q)}</annotation><annotation encoding="application/x-llamapun" id="Ch5.S3.SS5.p4.1.m1.3d">italic_Entropy ( italic_q ) = - ∑ start_POSTSUBSCRIPT italic_i ∈ italic_I start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT end_POSTSUBSCRIPT italic_P ( italic_i | italic_q ) roman_log italic_P ( italic_i | italic_q )</annotation></semantics></math>, where <math alttext="I_{q}" class="ltx_Math" display="inline" id="Ch5.S3.SS5.p4.2.m2.1"><semantics id="Ch5.S3.SS5.p4.2.m2.1a"><msub id="Ch5.S3.SS5.p4.2.m2.1.1" xref="Ch5.S3.SS5.p4.2.m2.1.1.cmml"><mi id="Ch5.S3.SS5.p4.2.m2.1.1.2" xref="Ch5.S3.SS5.p4.2.m2.1.1.2.cmml">I</mi><mi id="Ch5.S3.SS5.p4.2.m2.1.1.3" xref="Ch5.S3.SS5.p4.2.m2.1.1.3.cmml">q</mi></msub><annotation-xml encoding="MathML-Content" id="Ch5.S3.SS5.p4.2.m2.1b"><apply id="Ch5.S3.SS5.p4.2.m2.1.1.cmml" xref="Ch5.S3.SS5.p4.2.m2.1.1"><csymbol cd="ambiguous" id="Ch5.S3.SS5.p4.2.m2.1.1.1.cmml" xref="Ch5.S3.SS5.p4.2.m2.1.1">subscript</csymbol><ci id="Ch5.S3.SS5.p4.2.m2.1.1.2.cmml" xref="Ch5.S3.SS5.p4.2.m2.1.1.2">𝐼</ci><ci id="Ch5.S3.SS5.p4.2.m2.1.1.3.cmml" xref="Ch5.S3.SS5.p4.2.m2.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S3.SS5.p4.2.m2.1c">I_{q}</annotation><annotation encoding="application/x-llamapun" id="Ch5.S3.SS5.p4.2.m2.1d">italic_I start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT</annotation></semantics></math> refers to the candidate item set for a query <math alttext="q" class="ltx_Math" display="inline" id="Ch5.S3.SS5.p4.3.m3.1"><semantics id="Ch5.S3.SS5.p4.3.m3.1a"><mi id="Ch5.S3.SS5.p4.3.m3.1.1" xref="Ch5.S3.SS5.p4.3.m3.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="Ch5.S3.SS5.p4.3.m3.1b"><ci id="Ch5.S3.SS5.p4.3.m3.1.1.cmml" xref="Ch5.S3.SS5.p4.3.m3.1.1">𝑞</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S3.SS5.p4.3.m3.1c">q</annotation><annotation encoding="application/x-llamapun" id="Ch5.S3.SS5.p4.3.m3.1d">italic_q</annotation></semantics></math>.
As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.F4.sf1" title="In Figure 5.4 ‣ 5.3.5 Matching in personalized search ‣ 5.3 Matching strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.4(a)</span></a>, the authors provided the purchase entropy of queries on <em class="ltx_emph ltx_font_italic" id="Ch5.S3.SS5.p4.13.2">Beauty</em> products (e.g., facial cleanser) in the sampled search logs. They ranked queries according to their frequencies on a logarithmic scale and split them into three groups: the queries with low frequency (LowFreq), with medium frequency (MedFreq), and with high frequency (HighFreq).
The authors found queries with high frequencies have more potential for personalization, as more purchases on different items can be observed when the number of sessions increases.
The authors evaluate the differences between <math alttext="P(i|q,u)" class="ltx_Math" display="inline" id="Ch5.S3.SS5.p4.4.m4.3"><semantics id="Ch5.S3.SS5.p4.4.m4.3a"><mrow id="Ch5.S3.SS5.p4.4.m4.3.3" xref="Ch5.S3.SS5.p4.4.m4.3.3.cmml"><mi id="Ch5.S3.SS5.p4.4.m4.3.3.3" xref="Ch5.S3.SS5.p4.4.m4.3.3.3.cmml">P</mi><mo id="Ch5.S3.SS5.p4.4.m4.3.3.2" xref="Ch5.S3.SS5.p4.4.m4.3.3.2.cmml">⁢</mo><mrow id="Ch5.S3.SS5.p4.4.m4.3.3.1.1" xref="Ch5.S3.SS5.p4.4.m4.3.3.1.1.1.cmml"><mo id="Ch5.S3.SS5.p4.4.m4.3.3.1.1.2" stretchy="false" xref="Ch5.S3.SS5.p4.4.m4.3.3.1.1.1.cmml">(</mo><mrow id="Ch5.S3.SS5.p4.4.m4.3.3.1.1.1" xref="Ch5.S3.SS5.p4.4.m4.3.3.1.1.1.cmml"><mi id="Ch5.S3.SS5.p4.4.m4.3.3.1.1.1.2" xref="Ch5.S3.SS5.p4.4.m4.3.3.1.1.1.2.cmml">i</mi><mo fence="false" id="Ch5.S3.SS5.p4.4.m4.3.3.1.1.1.1" xref="Ch5.S3.SS5.p4.4.m4.3.3.1.1.1.1.cmml">|</mo><mrow id="Ch5.S3.SS5.p4.4.m4.3.3.1.1.1.3.2" xref="Ch5.S3.SS5.p4.4.m4.3.3.1.1.1.3.1.cmml"><mi id="Ch5.S3.SS5.p4.4.m4.1.1" xref="Ch5.S3.SS5.p4.4.m4.1.1.cmml">q</mi><mo id="Ch5.S3.SS5.p4.4.m4.3.3.1.1.1.3.2.1" xref="Ch5.S3.SS5.p4.4.m4.3.3.1.1.1.3.1.cmml">,</mo><mi id="Ch5.S3.SS5.p4.4.m4.2.2" xref="Ch5.S3.SS5.p4.4.m4.2.2.cmml">u</mi></mrow></mrow><mo id="Ch5.S3.SS5.p4.4.m4.3.3.1.1.3" stretchy="false" xref="Ch5.S3.SS5.p4.4.m4.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S3.SS5.p4.4.m4.3b"><apply id="Ch5.S3.SS5.p4.4.m4.3.3.cmml" xref="Ch5.S3.SS5.p4.4.m4.3.3"><times id="Ch5.S3.SS5.p4.4.m4.3.3.2.cmml" xref="Ch5.S3.SS5.p4.4.m4.3.3.2"></times><ci id="Ch5.S3.SS5.p4.4.m4.3.3.3.cmml" xref="Ch5.S3.SS5.p4.4.m4.3.3.3">𝑃</ci><apply id="Ch5.S3.SS5.p4.4.m4.3.3.1.1.1.cmml" xref="Ch5.S3.SS5.p4.4.m4.3.3.1.1"><csymbol cd="latexml" id="Ch5.S3.SS5.p4.4.m4.3.3.1.1.1.1.cmml" xref="Ch5.S3.SS5.p4.4.m4.3.3.1.1.1.1">conditional</csymbol><ci id="Ch5.S3.SS5.p4.4.m4.3.3.1.1.1.2.cmml" xref="Ch5.S3.SS5.p4.4.m4.3.3.1.1.1.2">𝑖</ci><list id="Ch5.S3.SS5.p4.4.m4.3.3.1.1.1.3.1.cmml" xref="Ch5.S3.SS5.p4.4.m4.3.3.1.1.1.3.2"><ci id="Ch5.S3.SS5.p4.4.m4.1.1.cmml" xref="Ch5.S3.SS5.p4.4.m4.1.1">𝑞</ci><ci id="Ch5.S3.SS5.p4.4.m4.2.2.cmml" xref="Ch5.S3.SS5.p4.4.m4.2.2">𝑢</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S3.SS5.p4.4.m4.3c">P(i|q,u)</annotation><annotation encoding="application/x-llamapun" id="Ch5.S3.SS5.p4.4.m4.3d">italic_P ( italic_i | italic_q , italic_u )</annotation></semantics></math> and <math alttext="{P(i|q)}" class="ltx_Math" display="inline" id="Ch5.S3.SS5.p4.5.m5.1"><semantics id="Ch5.S3.SS5.p4.5.m5.1a"><mrow id="Ch5.S3.SS5.p4.5.m5.1.1" xref="Ch5.S3.SS5.p4.5.m5.1.1.cmml"><mi id="Ch5.S3.SS5.p4.5.m5.1.1.3" xref="Ch5.S3.SS5.p4.5.m5.1.1.3.cmml">P</mi><mo id="Ch5.S3.SS5.p4.5.m5.1.1.2" xref="Ch5.S3.SS5.p4.5.m5.1.1.2.cmml">⁢</mo><mrow id="Ch5.S3.SS5.p4.5.m5.1.1.1.1" xref="Ch5.S3.SS5.p4.5.m5.1.1.1.1.1.cmml"><mo id="Ch5.S3.SS5.p4.5.m5.1.1.1.1.2" stretchy="false" xref="Ch5.S3.SS5.p4.5.m5.1.1.1.1.1.cmml">(</mo><mrow id="Ch5.S3.SS5.p4.5.m5.1.1.1.1.1" xref="Ch5.S3.SS5.p4.5.m5.1.1.1.1.1.cmml"><mi id="Ch5.S3.SS5.p4.5.m5.1.1.1.1.1.2" xref="Ch5.S3.SS5.p4.5.m5.1.1.1.1.1.2.cmml">i</mi><mo fence="false" id="Ch5.S3.SS5.p4.5.m5.1.1.1.1.1.1" xref="Ch5.S3.SS5.p4.5.m5.1.1.1.1.1.1.cmml">|</mo><mi id="Ch5.S3.SS5.p4.5.m5.1.1.1.1.1.3" xref="Ch5.S3.SS5.p4.5.m5.1.1.1.1.1.3.cmml">q</mi></mrow><mo id="Ch5.S3.SS5.p4.5.m5.1.1.1.1.3" stretchy="false" xref="Ch5.S3.SS5.p4.5.m5.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S3.SS5.p4.5.m5.1b"><apply id="Ch5.S3.SS5.p4.5.m5.1.1.cmml" xref="Ch5.S3.SS5.p4.5.m5.1.1"><times id="Ch5.S3.SS5.p4.5.m5.1.1.2.cmml" xref="Ch5.S3.SS5.p4.5.m5.1.1.2"></times><ci id="Ch5.S3.SS5.p4.5.m5.1.1.3.cmml" xref="Ch5.S3.SS5.p4.5.m5.1.1.3">𝑃</ci><apply id="Ch5.S3.SS5.p4.5.m5.1.1.1.1.1.cmml" xref="Ch5.S3.SS5.p4.5.m5.1.1.1.1"><csymbol cd="latexml" id="Ch5.S3.SS5.p4.5.m5.1.1.1.1.1.1.cmml" xref="Ch5.S3.SS5.p4.5.m5.1.1.1.1.1.1">conditional</csymbol><ci id="Ch5.S3.SS5.p4.5.m5.1.1.1.1.1.2.cmml" xref="Ch5.S3.SS5.p4.5.m5.1.1.1.1.1.2">𝑖</ci><ci id="Ch5.S3.SS5.p4.5.m5.1.1.1.1.1.3.cmml" xref="Ch5.S3.SS5.p4.5.m5.1.1.1.1.1.3">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S3.SS5.p4.5.m5.1c">{P(i|q)}</annotation><annotation encoding="application/x-llamapun" id="Ch5.S3.SS5.p4.5.m5.1d">italic_P ( italic_i | italic_q )</annotation></semantics></math> by using the familiar <math alttext="\mathit{MRR}" class="ltx_Math" display="inline" id="Ch5.S3.SS5.p4.6.m6.1"><semantics id="Ch5.S3.SS5.p4.6.m6.1a"><mi id="Ch5.S3.SS5.p4.6.m6.1.1" xref="Ch5.S3.SS5.p4.6.m6.1.1.cmml">𝑀𝑅𝑅</mi><annotation-xml encoding="MathML-Content" id="Ch5.S3.SS5.p4.6.m6.1b"><ci id="Ch5.S3.SS5.p4.6.m6.1.1.cmml" xref="Ch5.S3.SS5.p4.6.m6.1.1">𝑀𝑅𝑅</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S3.SS5.p4.6.m6.1c">\mathit{MRR}</annotation><annotation encoding="application/x-llamapun" id="Ch5.S3.SS5.p4.6.m6.1d">italic_MRR</annotation></semantics></math> metric, i.e., <math alttext="\mathit{MRR}(q)=\sum_{u\in u}{\mathit{RR}(P(i|q),P(i|q,u))\cdot P(u)}" class="ltx_Math" display="inline" id="Ch5.S3.SS5.p4.7.m7.6"><semantics id="Ch5.S3.SS5.p4.7.m7.6a"><mrow id="Ch5.S3.SS5.p4.7.m7.6.6" xref="Ch5.S3.SS5.p4.7.m7.6.6.cmml"><mrow id="Ch5.S3.SS5.p4.7.m7.6.6.4" xref="Ch5.S3.SS5.p4.7.m7.6.6.4.cmml"><mi id="Ch5.S3.SS5.p4.7.m7.6.6.4.2" xref="Ch5.S3.SS5.p4.7.m7.6.6.4.2.cmml">𝑀𝑅𝑅</mi><mo id="Ch5.S3.SS5.p4.7.m7.6.6.4.1" xref="Ch5.S3.SS5.p4.7.m7.6.6.4.1.cmml">⁢</mo><mrow id="Ch5.S3.SS5.p4.7.m7.6.6.4.3.2" xref="Ch5.S3.SS5.p4.7.m7.6.6.4.cmml"><mo id="Ch5.S3.SS5.p4.7.m7.6.6.4.3.2.1" stretchy="false" xref="Ch5.S3.SS5.p4.7.m7.6.6.4.cmml">(</mo><mi id="Ch5.S3.SS5.p4.7.m7.1.1" xref="Ch5.S3.SS5.p4.7.m7.1.1.cmml">q</mi><mo id="Ch5.S3.SS5.p4.7.m7.6.6.4.3.2.2" stretchy="false" xref="Ch5.S3.SS5.p4.7.m7.6.6.4.cmml">)</mo></mrow></mrow><mo id="Ch5.S3.SS5.p4.7.m7.6.6.3" rspace="0.111em" xref="Ch5.S3.SS5.p4.7.m7.6.6.3.cmml">=</mo><mrow id="Ch5.S3.SS5.p4.7.m7.6.6.2" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.cmml"><msub id="Ch5.S3.SS5.p4.7.m7.6.6.2.3" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.3.cmml"><mo id="Ch5.S3.SS5.p4.7.m7.6.6.2.3.2" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.3.2.cmml">∑</mo><mrow id="Ch5.S3.SS5.p4.7.m7.6.6.2.3.3" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.3.3.cmml"><mi id="Ch5.S3.SS5.p4.7.m7.6.6.2.3.3.2" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.3.3.2.cmml">u</mi><mo id="Ch5.S3.SS5.p4.7.m7.6.6.2.3.3.1" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.3.3.1.cmml">∈</mo><mi id="Ch5.S3.SS5.p4.7.m7.6.6.2.3.3.3" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.3.3.3.cmml">u</mi></mrow></msub><mrow id="Ch5.S3.SS5.p4.7.m7.6.6.2.2" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.cmml"><mrow id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.cmml"><mrow id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.cmml"><mi id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.4" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.4.cmml">𝑅𝑅</mi><mo id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.3" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.3.cmml">⁢</mo><mrow id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.3.cmml"><mo id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.3" stretchy="false" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.3.cmml">(</mo><mrow id="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1" xref="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.cmml"><mi id="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.3" xref="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.3.cmml">P</mi><mo id="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.2" xref="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1" xref="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1.1" xref="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1.1.2" xref="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1.1.2.cmml">i</mi><mo fence="false" id="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1.1.1" xref="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml">|</mo><mi id="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1.1.3" xref="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1.1.3.cmml">q</mi></mrow><mo id="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.4" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.3.cmml">,</mo><mrow id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.cmml"><mi id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.3" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.3.cmml">P</mi><mo id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.2" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.2.cmml">⁢</mo><mrow id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.1.cmml"><mo id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.2" stretchy="false" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.1.cmml">(</mo><mrow id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.1" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.1.cmml"><mi id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.1.2" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.1.2.cmml">i</mi><mo fence="false" id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.1.1" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.1.1.cmml">|</mo><mrow id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.1.3.2" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.1.3.1.cmml"><mi id="Ch5.S3.SS5.p4.7.m7.2.2" xref="Ch5.S3.SS5.p4.7.m7.2.2.cmml">q</mi><mo id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.1.3.2.1" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.1.3.1.cmml">,</mo><mi id="Ch5.S3.SS5.p4.7.m7.3.3" xref="Ch5.S3.SS5.p4.7.m7.3.3.cmml">u</mi></mrow></mrow><mo id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.3" stretchy="false" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.5" rspace="0.055em" stretchy="false" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.3.cmml">)</mo></mrow></mrow><mo id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.3" rspace="0.222em" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.3.cmml">⋅</mo><mi id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.4" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.4.cmml">P</mi></mrow><mo id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.3" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.3.cmml">⁢</mo><mrow id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.4.2" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.cmml"><mo id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.4.2.1" stretchy="false" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.cmml">(</mo><mi id="Ch5.S3.SS5.p4.7.m7.4.4" xref="Ch5.S3.SS5.p4.7.m7.4.4.cmml">u</mi><mo id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.4.2.2" stretchy="false" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S3.SS5.p4.7.m7.6b"><apply id="Ch5.S3.SS5.p4.7.m7.6.6.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6"><eq id="Ch5.S3.SS5.p4.7.m7.6.6.3.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.3"></eq><apply id="Ch5.S3.SS5.p4.7.m7.6.6.4.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.4"><times id="Ch5.S3.SS5.p4.7.m7.6.6.4.1.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.4.1"></times><ci id="Ch5.S3.SS5.p4.7.m7.6.6.4.2.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.4.2">𝑀𝑅𝑅</ci><ci id="Ch5.S3.SS5.p4.7.m7.1.1.cmml" xref="Ch5.S3.SS5.p4.7.m7.1.1">𝑞</ci></apply><apply id="Ch5.S3.SS5.p4.7.m7.6.6.2.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2"><apply id="Ch5.S3.SS5.p4.7.m7.6.6.2.3.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.3"><csymbol cd="ambiguous" id="Ch5.S3.SS5.p4.7.m7.6.6.2.3.1.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.3">subscript</csymbol><sum id="Ch5.S3.SS5.p4.7.m7.6.6.2.3.2.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.3.2"></sum><apply id="Ch5.S3.SS5.p4.7.m7.6.6.2.3.3.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.3.3"><in id="Ch5.S3.SS5.p4.7.m7.6.6.2.3.3.1.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.3.3.1"></in><ci id="Ch5.S3.SS5.p4.7.m7.6.6.2.3.3.2.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.3.3.2">𝑢</ci><ci id="Ch5.S3.SS5.p4.7.m7.6.6.2.3.3.3.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.3.3.3">𝑢</ci></apply></apply><apply id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2"><times id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.3.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.3"></times><apply id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2"><ci id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.3.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.3">⋅</ci><apply id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2"><times id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.3.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.3"></times><ci id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.4.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.4">𝑅𝑅</ci><interval closure="open" id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.3.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2"><apply id="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.cmml" xref="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1"><times id="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.2.cmml" xref="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.2"></times><ci id="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.3.cmml" xref="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.3">𝑃</ci><apply id="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1.1.1">conditional</csymbol><ci id="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1.1.2">𝑖</ci><ci id="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="Ch5.S3.SS5.p4.7.m7.5.5.1.1.1.1.1.1.1.1.1.1.3">𝑞</ci></apply></apply><apply id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2"><times id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.2.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.2"></times><ci id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.3.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.3">𝑃</ci><apply id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.1.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1"><csymbol cd="latexml" id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.1.1.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.1.1">conditional</csymbol><ci id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.1.2.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.1.2">𝑖</ci><list id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.1.3.1.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.2.2.2.2.1.1.1.3.2"><ci id="Ch5.S3.SS5.p4.7.m7.2.2.cmml" xref="Ch5.S3.SS5.p4.7.m7.2.2">𝑞</ci><ci id="Ch5.S3.SS5.p4.7.m7.3.3.cmml" xref="Ch5.S3.SS5.p4.7.m7.3.3">𝑢</ci></list></apply></apply></interval></apply><ci id="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.4.cmml" xref="Ch5.S3.SS5.p4.7.m7.6.6.2.2.2.4">𝑃</ci></apply><ci id="Ch5.S3.SS5.p4.7.m7.4.4.cmml" xref="Ch5.S3.SS5.p4.7.m7.4.4">𝑢</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S3.SS5.p4.7.m7.6c">\mathit{MRR}(q)=\sum_{u\in u}{\mathit{RR}(P(i|q),P(i|q,u))\cdot P(u)}</annotation><annotation encoding="application/x-llamapun" id="Ch5.S3.SS5.p4.7.m7.6d">italic_MRR ( italic_q ) = ∑ start_POSTSUBSCRIPT italic_u ∈ italic_u end_POSTSUBSCRIPT italic_RR ( italic_P ( italic_i | italic_q ) , italic_P ( italic_i | italic_q , italic_u ) ) ⋅ italic_P ( italic_u )</annotation></semantics></math>, where <math alttext="{\mathit{RR}(P(i|q),P(i|q,u))}" class="ltx_Math" display="inline" id="Ch5.S3.SS5.p4.8.m8.4"><semantics id="Ch5.S3.SS5.p4.8.m8.4a"><mrow id="Ch5.S3.SS5.p4.8.m8.4.4" xref="Ch5.S3.SS5.p4.8.m8.4.4.cmml"><mi id="Ch5.S3.SS5.p4.8.m8.4.4.4" xref="Ch5.S3.SS5.p4.8.m8.4.4.4.cmml">𝑅𝑅</mi><mo id="Ch5.S3.SS5.p4.8.m8.4.4.3" xref="Ch5.S3.SS5.p4.8.m8.4.4.3.cmml">⁢</mo><mrow id="Ch5.S3.SS5.p4.8.m8.4.4.2.2" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.3.cmml"><mo id="Ch5.S3.SS5.p4.8.m8.4.4.2.2.3" stretchy="false" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.3.cmml">(</mo><mrow id="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1" xref="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.cmml"><mi id="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.3" xref="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.3.cmml">P</mi><mo id="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.2" xref="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.2.cmml">⁢</mo><mrow id="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1" xref="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1.1.cmml"><mo id="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1.2" stretchy="false" xref="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1.1.cmml">(</mo><mrow id="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1.1" xref="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1.1.cmml"><mi id="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1.1.2" xref="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1.1.2.cmml">i</mi><mo fence="false" id="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1.1.1" xref="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1.1.1.cmml">|</mo><mi id="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1.1.3" xref="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1.1.3.cmml">q</mi></mrow><mo id="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1.3" stretchy="false" xref="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="Ch5.S3.SS5.p4.8.m8.4.4.2.2.4" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.3.cmml">,</mo><mrow id="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.cmml"><mi id="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.3" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.3.cmml">P</mi><mo id="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.2" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.2.cmml">⁢</mo><mrow id="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.1.cmml"><mo id="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.2" stretchy="false" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.1.cmml">(</mo><mrow id="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.1" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.1.cmml"><mi id="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.1.2" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.1.2.cmml">i</mi><mo fence="false" id="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.1.1" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.1.1.cmml">|</mo><mrow id="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.1.3.2" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.1.3.1.cmml"><mi id="Ch5.S3.SS5.p4.8.m8.1.1" xref="Ch5.S3.SS5.p4.8.m8.1.1.cmml">q</mi><mo id="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.1.3.2.1" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.1.3.1.cmml">,</mo><mi id="Ch5.S3.SS5.p4.8.m8.2.2" xref="Ch5.S3.SS5.p4.8.m8.2.2.cmml">u</mi></mrow></mrow><mo id="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.3" stretchy="false" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.1.cmml">)</mo></mrow></mrow><mo id="Ch5.S3.SS5.p4.8.m8.4.4.2.2.5" stretchy="false" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S3.SS5.p4.8.m8.4b"><apply id="Ch5.S3.SS5.p4.8.m8.4.4.cmml" xref="Ch5.S3.SS5.p4.8.m8.4.4"><times id="Ch5.S3.SS5.p4.8.m8.4.4.3.cmml" xref="Ch5.S3.SS5.p4.8.m8.4.4.3"></times><ci id="Ch5.S3.SS5.p4.8.m8.4.4.4.cmml" xref="Ch5.S3.SS5.p4.8.m8.4.4.4">𝑅𝑅</ci><interval closure="open" id="Ch5.S3.SS5.p4.8.m8.4.4.2.3.cmml" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.2"><apply id="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.cmml" xref="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1"><times id="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.2.cmml" xref="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.2"></times><ci id="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.3.cmml" xref="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.3">𝑃</ci><apply id="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1.1.cmml" xref="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1"><csymbol cd="latexml" id="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1.1.1.cmml" xref="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1.1.1">conditional</csymbol><ci id="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1.1.2.cmml" xref="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1.1.2">𝑖</ci><ci id="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1.1.3.cmml" xref="Ch5.S3.SS5.p4.8.m8.3.3.1.1.1.1.1.1.3">𝑞</ci></apply></apply><apply id="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.cmml" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2"><times id="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.2.cmml" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.2"></times><ci id="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.3.cmml" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.3">𝑃</ci><apply id="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.1.cmml" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1"><csymbol cd="latexml" id="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.1.1.cmml" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.1.1">conditional</csymbol><ci id="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.1.2.cmml" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.1.2">𝑖</ci><list id="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.1.3.1.cmml" xref="Ch5.S3.SS5.p4.8.m8.4.4.2.2.2.1.1.1.3.2"><ci id="Ch5.S3.SS5.p4.8.m8.1.1.cmml" xref="Ch5.S3.SS5.p4.8.m8.1.1">𝑞</ci><ci id="Ch5.S3.SS5.p4.8.m8.2.2.cmml" xref="Ch5.S3.SS5.p4.8.m8.2.2">𝑢</ci></list></apply></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S3.SS5.p4.8.m8.4c">{\mathit{RR}(P(i|q),P(i|q,u))}</annotation><annotation encoding="application/x-llamapun" id="Ch5.S3.SS5.p4.8.m8.4d">italic_RR ( italic_P ( italic_i | italic_q ) , italic_P ( italic_i | italic_q , italic_u ) )</annotation></semantics></math> reflects the the reciprocal rank of a ranked list produced by ranking with <math alttext="{P(i|q)}" class="ltx_Math" display="inline" id="Ch5.S3.SS5.p4.9.m9.1"><semantics id="Ch5.S3.SS5.p4.9.m9.1a"><mrow id="Ch5.S3.SS5.p4.9.m9.1.1" xref="Ch5.S3.SS5.p4.9.m9.1.1.cmml"><mi id="Ch5.S3.SS5.p4.9.m9.1.1.3" xref="Ch5.S3.SS5.p4.9.m9.1.1.3.cmml">P</mi><mo id="Ch5.S3.SS5.p4.9.m9.1.1.2" xref="Ch5.S3.SS5.p4.9.m9.1.1.2.cmml">⁢</mo><mrow id="Ch5.S3.SS5.p4.9.m9.1.1.1.1" xref="Ch5.S3.SS5.p4.9.m9.1.1.1.1.1.cmml"><mo id="Ch5.S3.SS5.p4.9.m9.1.1.1.1.2" stretchy="false" xref="Ch5.S3.SS5.p4.9.m9.1.1.1.1.1.cmml">(</mo><mrow id="Ch5.S3.SS5.p4.9.m9.1.1.1.1.1" xref="Ch5.S3.SS5.p4.9.m9.1.1.1.1.1.cmml"><mi id="Ch5.S3.SS5.p4.9.m9.1.1.1.1.1.2" xref="Ch5.S3.SS5.p4.9.m9.1.1.1.1.1.2.cmml">i</mi><mo fence="false" id="Ch5.S3.SS5.p4.9.m9.1.1.1.1.1.1" xref="Ch5.S3.SS5.p4.9.m9.1.1.1.1.1.1.cmml">|</mo><mi id="Ch5.S3.SS5.p4.9.m9.1.1.1.1.1.3" xref="Ch5.S3.SS5.p4.9.m9.1.1.1.1.1.3.cmml">q</mi></mrow><mo id="Ch5.S3.SS5.p4.9.m9.1.1.1.1.3" stretchy="false" xref="Ch5.S3.SS5.p4.9.m9.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S3.SS5.p4.9.m9.1b"><apply id="Ch5.S3.SS5.p4.9.m9.1.1.cmml" xref="Ch5.S3.SS5.p4.9.m9.1.1"><times id="Ch5.S3.SS5.p4.9.m9.1.1.2.cmml" xref="Ch5.S3.SS5.p4.9.m9.1.1.2"></times><ci id="Ch5.S3.SS5.p4.9.m9.1.1.3.cmml" xref="Ch5.S3.SS5.p4.9.m9.1.1.3">𝑃</ci><apply id="Ch5.S3.SS5.p4.9.m9.1.1.1.1.1.cmml" xref="Ch5.S3.SS5.p4.9.m9.1.1.1.1"><csymbol cd="latexml" id="Ch5.S3.SS5.p4.9.m9.1.1.1.1.1.1.cmml" xref="Ch5.S3.SS5.p4.9.m9.1.1.1.1.1.1">conditional</csymbol><ci id="Ch5.S3.SS5.p4.9.m9.1.1.1.1.1.2.cmml" xref="Ch5.S3.SS5.p4.9.m9.1.1.1.1.1.2">𝑖</ci><ci id="Ch5.S3.SS5.p4.9.m9.1.1.1.1.1.3.cmml" xref="Ch5.S3.SS5.p4.9.m9.1.1.1.1.1.3">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S3.SS5.p4.9.m9.1c">{P(i|q)}</annotation><annotation encoding="application/x-llamapun" id="Ch5.S3.SS5.p4.9.m9.1d">italic_P ( italic_i | italic_q )</annotation></semantics></math>, using <math alttext="{P(i|q,u)}" class="ltx_Math" display="inline" id="Ch5.S3.SS5.p4.10.m10.3"><semantics id="Ch5.S3.SS5.p4.10.m10.3a"><mrow id="Ch5.S3.SS5.p4.10.m10.3.3" xref="Ch5.S3.SS5.p4.10.m10.3.3.cmml"><mi id="Ch5.S3.SS5.p4.10.m10.3.3.3" xref="Ch5.S3.SS5.p4.10.m10.3.3.3.cmml">P</mi><mo id="Ch5.S3.SS5.p4.10.m10.3.3.2" xref="Ch5.S3.SS5.p4.10.m10.3.3.2.cmml">⁢</mo><mrow id="Ch5.S3.SS5.p4.10.m10.3.3.1.1" xref="Ch5.S3.SS5.p4.10.m10.3.3.1.1.1.cmml"><mo id="Ch5.S3.SS5.p4.10.m10.3.3.1.1.2" stretchy="false" xref="Ch5.S3.SS5.p4.10.m10.3.3.1.1.1.cmml">(</mo><mrow id="Ch5.S3.SS5.p4.10.m10.3.3.1.1.1" xref="Ch5.S3.SS5.p4.10.m10.3.3.1.1.1.cmml"><mi id="Ch5.S3.SS5.p4.10.m10.3.3.1.1.1.2" xref="Ch5.S3.SS5.p4.10.m10.3.3.1.1.1.2.cmml">i</mi><mo fence="false" id="Ch5.S3.SS5.p4.10.m10.3.3.1.1.1.1" xref="Ch5.S3.SS5.p4.10.m10.3.3.1.1.1.1.cmml">|</mo><mrow id="Ch5.S3.SS5.p4.10.m10.3.3.1.1.1.3.2" xref="Ch5.S3.SS5.p4.10.m10.3.3.1.1.1.3.1.cmml"><mi id="Ch5.S3.SS5.p4.10.m10.1.1" xref="Ch5.S3.SS5.p4.10.m10.1.1.cmml">q</mi><mo id="Ch5.S3.SS5.p4.10.m10.3.3.1.1.1.3.2.1" xref="Ch5.S3.SS5.p4.10.m10.3.3.1.1.1.3.1.cmml">,</mo><mi id="Ch5.S3.SS5.p4.10.m10.2.2" xref="Ch5.S3.SS5.p4.10.m10.2.2.cmml">u</mi></mrow></mrow><mo id="Ch5.S3.SS5.p4.10.m10.3.3.1.1.3" stretchy="false" xref="Ch5.S3.SS5.p4.10.m10.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S3.SS5.p4.10.m10.3b"><apply id="Ch5.S3.SS5.p4.10.m10.3.3.cmml" xref="Ch5.S3.SS5.p4.10.m10.3.3"><times id="Ch5.S3.SS5.p4.10.m10.3.3.2.cmml" xref="Ch5.S3.SS5.p4.10.m10.3.3.2"></times><ci id="Ch5.S3.SS5.p4.10.m10.3.3.3.cmml" xref="Ch5.S3.SS5.p4.10.m10.3.3.3">𝑃</ci><apply id="Ch5.S3.SS5.p4.10.m10.3.3.1.1.1.cmml" xref="Ch5.S3.SS5.p4.10.m10.3.3.1.1"><csymbol cd="latexml" id="Ch5.S3.SS5.p4.10.m10.3.3.1.1.1.1.cmml" xref="Ch5.S3.SS5.p4.10.m10.3.3.1.1.1.1">conditional</csymbol><ci id="Ch5.S3.SS5.p4.10.m10.3.3.1.1.1.2.cmml" xref="Ch5.S3.SS5.p4.10.m10.3.3.1.1.1.2">𝑖</ci><list id="Ch5.S3.SS5.p4.10.m10.3.3.1.1.1.3.1.cmml" xref="Ch5.S3.SS5.p4.10.m10.3.3.1.1.1.3.2"><ci id="Ch5.S3.SS5.p4.10.m10.1.1.cmml" xref="Ch5.S3.SS5.p4.10.m10.1.1">𝑞</ci><ci id="Ch5.S3.SS5.p4.10.m10.2.2.cmml" xref="Ch5.S3.SS5.p4.10.m10.2.2">𝑢</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S3.SS5.p4.10.m10.3c">{P(i|q,u)}</annotation><annotation encoding="application/x-llamapun" id="Ch5.S3.SS5.p4.10.m10.3d">italic_P ( italic_i | italic_q , italic_u )</annotation></semantics></math> as the ground truth.
As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.F4.sf2" title="In Figure 5.4 ‣ 5.3.5 Matching in personalized search ‣ 5.3 Matching strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.4(b)</span></a>, the authors show the <math alttext="\mathit{MRR}(q)" class="ltx_Math" display="inline" id="Ch5.S3.SS5.p4.11.m11.1"><semantics id="Ch5.S3.SS5.p4.11.m11.1a"><mrow id="Ch5.S3.SS5.p4.11.m11.1.2" xref="Ch5.S3.SS5.p4.11.m11.1.2.cmml"><mi id="Ch5.S3.SS5.p4.11.m11.1.2.2" xref="Ch5.S3.SS5.p4.11.m11.1.2.2.cmml">𝑀𝑅𝑅</mi><mo id="Ch5.S3.SS5.p4.11.m11.1.2.1" xref="Ch5.S3.SS5.p4.11.m11.1.2.1.cmml">⁢</mo><mrow id="Ch5.S3.SS5.p4.11.m11.1.2.3.2" xref="Ch5.S3.SS5.p4.11.m11.1.2.cmml"><mo id="Ch5.S3.SS5.p4.11.m11.1.2.3.2.1" stretchy="false" xref="Ch5.S3.SS5.p4.11.m11.1.2.cmml">(</mo><mi id="Ch5.S3.SS5.p4.11.m11.1.1" xref="Ch5.S3.SS5.p4.11.m11.1.1.cmml">q</mi><mo id="Ch5.S3.SS5.p4.11.m11.1.2.3.2.2" stretchy="false" xref="Ch5.S3.SS5.p4.11.m11.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S3.SS5.p4.11.m11.1b"><apply id="Ch5.S3.SS5.p4.11.m11.1.2.cmml" xref="Ch5.S3.SS5.p4.11.m11.1.2"><times id="Ch5.S3.SS5.p4.11.m11.1.2.1.cmml" xref="Ch5.S3.SS5.p4.11.m11.1.2.1"></times><ci id="Ch5.S3.SS5.p4.11.m11.1.2.2.cmml" xref="Ch5.S3.SS5.p4.11.m11.1.2.2">𝑀𝑅𝑅</ci><ci id="Ch5.S3.SS5.p4.11.m11.1.1.cmml" xref="Ch5.S3.SS5.p4.11.m11.1.1">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S3.SS5.p4.11.m11.1c">\mathit{MRR}(q)</annotation><annotation encoding="application/x-llamapun" id="Ch5.S3.SS5.p4.11.m11.1d">italic_MRR ( italic_q )</annotation></semantics></math> of queries on Beauty products. They found the similarity between <math alttext="P(i|q,u)" class="ltx_Math" display="inline" id="Ch5.S3.SS5.p4.12.m12.3"><semantics id="Ch5.S3.SS5.p4.12.m12.3a"><mrow id="Ch5.S3.SS5.p4.12.m12.3.3" xref="Ch5.S3.SS5.p4.12.m12.3.3.cmml"><mi id="Ch5.S3.SS5.p4.12.m12.3.3.3" xref="Ch5.S3.SS5.p4.12.m12.3.3.3.cmml">P</mi><mo id="Ch5.S3.SS5.p4.12.m12.3.3.2" xref="Ch5.S3.SS5.p4.12.m12.3.3.2.cmml">⁢</mo><mrow id="Ch5.S3.SS5.p4.12.m12.3.3.1.1" xref="Ch5.S3.SS5.p4.12.m12.3.3.1.1.1.cmml"><mo id="Ch5.S3.SS5.p4.12.m12.3.3.1.1.2" stretchy="false" xref="Ch5.S3.SS5.p4.12.m12.3.3.1.1.1.cmml">(</mo><mrow id="Ch5.S3.SS5.p4.12.m12.3.3.1.1.1" xref="Ch5.S3.SS5.p4.12.m12.3.3.1.1.1.cmml"><mi id="Ch5.S3.SS5.p4.12.m12.3.3.1.1.1.2" xref="Ch5.S3.SS5.p4.12.m12.3.3.1.1.1.2.cmml">i</mi><mo fence="false" id="Ch5.S3.SS5.p4.12.m12.3.3.1.1.1.1" xref="Ch5.S3.SS5.p4.12.m12.3.3.1.1.1.1.cmml">|</mo><mrow id="Ch5.S3.SS5.p4.12.m12.3.3.1.1.1.3.2" xref="Ch5.S3.SS5.p4.12.m12.3.3.1.1.1.3.1.cmml"><mi id="Ch5.S3.SS5.p4.12.m12.1.1" xref="Ch5.S3.SS5.p4.12.m12.1.1.cmml">q</mi><mo id="Ch5.S3.SS5.p4.12.m12.3.3.1.1.1.3.2.1" xref="Ch5.S3.SS5.p4.12.m12.3.3.1.1.1.3.1.cmml">,</mo><mi id="Ch5.S3.SS5.p4.12.m12.2.2" xref="Ch5.S3.SS5.p4.12.m12.2.2.cmml">u</mi></mrow></mrow><mo id="Ch5.S3.SS5.p4.12.m12.3.3.1.1.3" stretchy="false" xref="Ch5.S3.SS5.p4.12.m12.3.3.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S3.SS5.p4.12.m12.3b"><apply id="Ch5.S3.SS5.p4.12.m12.3.3.cmml" xref="Ch5.S3.SS5.p4.12.m12.3.3"><times id="Ch5.S3.SS5.p4.12.m12.3.3.2.cmml" xref="Ch5.S3.SS5.p4.12.m12.3.3.2"></times><ci id="Ch5.S3.SS5.p4.12.m12.3.3.3.cmml" xref="Ch5.S3.SS5.p4.12.m12.3.3.3">𝑃</ci><apply id="Ch5.S3.SS5.p4.12.m12.3.3.1.1.1.cmml" xref="Ch5.S3.SS5.p4.12.m12.3.3.1.1"><csymbol cd="latexml" id="Ch5.S3.SS5.p4.12.m12.3.3.1.1.1.1.cmml" xref="Ch5.S3.SS5.p4.12.m12.3.3.1.1.1.1">conditional</csymbol><ci id="Ch5.S3.SS5.p4.12.m12.3.3.1.1.1.2.cmml" xref="Ch5.S3.SS5.p4.12.m12.3.3.1.1.1.2">𝑖</ci><list id="Ch5.S3.SS5.p4.12.m12.3.3.1.1.1.3.1.cmml" xref="Ch5.S3.SS5.p4.12.m12.3.3.1.1.1.3.2"><ci id="Ch5.S3.SS5.p4.12.m12.1.1.cmml" xref="Ch5.S3.SS5.p4.12.m12.1.1">𝑞</ci><ci id="Ch5.S3.SS5.p4.12.m12.2.2.cmml" xref="Ch5.S3.SS5.p4.12.m12.2.2">𝑢</ci></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S3.SS5.p4.12.m12.3c">P(i|q,u)</annotation><annotation encoding="application/x-llamapun" id="Ch5.S3.SS5.p4.12.m12.3d">italic_P ( italic_i | italic_q , italic_u )</annotation></semantics></math> and <math alttext="P(i|q)" class="ltx_Math" display="inline" id="Ch5.S3.SS5.p4.13.m13.1"><semantics id="Ch5.S3.SS5.p4.13.m13.1a"><mrow id="Ch5.S3.SS5.p4.13.m13.1.1" xref="Ch5.S3.SS5.p4.13.m13.1.1.cmml"><mi id="Ch5.S3.SS5.p4.13.m13.1.1.3" xref="Ch5.S3.SS5.p4.13.m13.1.1.3.cmml">P</mi><mo id="Ch5.S3.SS5.p4.13.m13.1.1.2" xref="Ch5.S3.SS5.p4.13.m13.1.1.2.cmml">⁢</mo><mrow id="Ch5.S3.SS5.p4.13.m13.1.1.1.1" xref="Ch5.S3.SS5.p4.13.m13.1.1.1.1.1.cmml"><mo id="Ch5.S3.SS5.p4.13.m13.1.1.1.1.2" stretchy="false" xref="Ch5.S3.SS5.p4.13.m13.1.1.1.1.1.cmml">(</mo><mrow id="Ch5.S3.SS5.p4.13.m13.1.1.1.1.1" xref="Ch5.S3.SS5.p4.13.m13.1.1.1.1.1.cmml"><mi id="Ch5.S3.SS5.p4.13.m13.1.1.1.1.1.2" xref="Ch5.S3.SS5.p4.13.m13.1.1.1.1.1.2.cmml">i</mi><mo fence="false" id="Ch5.S3.SS5.p4.13.m13.1.1.1.1.1.1" xref="Ch5.S3.SS5.p4.13.m13.1.1.1.1.1.1.cmml">|</mo><mi id="Ch5.S3.SS5.p4.13.m13.1.1.1.1.1.3" xref="Ch5.S3.SS5.p4.13.m13.1.1.1.1.1.3.cmml">q</mi></mrow><mo id="Ch5.S3.SS5.p4.13.m13.1.1.1.1.3" stretchy="false" xref="Ch5.S3.SS5.p4.13.m13.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch5.S3.SS5.p4.13.m13.1b"><apply id="Ch5.S3.SS5.p4.13.m13.1.1.cmml" xref="Ch5.S3.SS5.p4.13.m13.1.1"><times id="Ch5.S3.SS5.p4.13.m13.1.1.2.cmml" xref="Ch5.S3.SS5.p4.13.m13.1.1.2"></times><ci id="Ch5.S3.SS5.p4.13.m13.1.1.3.cmml" xref="Ch5.S3.SS5.p4.13.m13.1.1.3">𝑃</ci><apply id="Ch5.S3.SS5.p4.13.m13.1.1.1.1.1.cmml" xref="Ch5.S3.SS5.p4.13.m13.1.1.1.1"><csymbol cd="latexml" id="Ch5.S3.SS5.p4.13.m13.1.1.1.1.1.1.cmml" xref="Ch5.S3.SS5.p4.13.m13.1.1.1.1.1.1">conditional</csymbol><ci id="Ch5.S3.SS5.p4.13.m13.1.1.1.1.1.2.cmml" xref="Ch5.S3.SS5.p4.13.m13.1.1.1.1.1.2">𝑖</ci><ci id="Ch5.S3.SS5.p4.13.m13.1.1.1.1.1.3.cmml" xref="Ch5.S3.SS5.p4.13.m13.1.1.1.1.1.3">𝑞</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S3.SS5.p4.13.m13.1c">P(i|q)</annotation><annotation encoding="application/x-llamapun" id="Ch5.S3.SS5.p4.13.m13.1d">italic_P ( italic_i | italic_q )</annotation></semantics></math> is not monotonically correlated with query frequency. Accordingly, the potential of personalization varies significantly in different queries, which requires a more sophisticated model for personalization in product search.</p>
</div>
<figure class="ltx_figure" id="Ch5.F4">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="Ch5.F4.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="193" id="Ch5.F4.sf1.g1" src="x33.png" width="348"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Ch5.F4.sf1.2.1.1" style="font-size:80%;">(a)</span> </span><span class="ltx_text" id="Ch5.F4.sf1.3.2" style="font-size:80%;">Purchase entropy</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="Ch5.F4.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="193" id="Ch5.F4.sf2.g1" src="x34.png" width="348"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="Ch5.F4.sf2.2.1.1" style="font-size:80%;">(b)</span> </span><span class="ltx_text" id="Ch5.F4.sf2.3.2" style="font-size:80%;">Popularity model performance</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5.4: </span>The purchase entropy <math alttext="\emph{Entropy}(q)" class="ltx_Math" display="inline" id="Ch5.F4.3.m1.1"><semantics id="Ch5.F4.3.m1.1b"><mrow id="Ch5.F4.3.m1.1.2" xref="Ch5.F4.3.m1.1.2.cmml"><mtext class="ltx_mathvariant_italic" id="Ch5.F4.3.m1.1.2.2" xref="Ch5.F4.3.m1.1.2.2b.cmml"><em class="ltx_emph ltx_font_italic" id="Ch5.F4.3.m1.1.2.2.1nest">Entropy</em></mtext><mo id="Ch5.F4.3.m1.1.2.1" xref="Ch5.F4.3.m1.1.2.1.cmml">⁢</mo><mrow id="Ch5.F4.3.m1.1.2.3.2" xref="Ch5.F4.3.m1.1.2.cmml"><mo id="Ch5.F4.3.m1.1.2.3.2.1" stretchy="false" xref="Ch5.F4.3.m1.1.2.cmml">(</mo><mi id="Ch5.F4.3.m1.1.1" xref="Ch5.F4.3.m1.1.1.cmml">q</mi><mo id="Ch5.F4.3.m1.1.2.3.2.2" stretchy="false" xref="Ch5.F4.3.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch5.F4.3.m1.1c"><apply id="Ch5.F4.3.m1.1.2.cmml" xref="Ch5.F4.3.m1.1.2"><times id="Ch5.F4.3.m1.1.2.1.cmml" xref="Ch5.F4.3.m1.1.2.1"></times><ci id="Ch5.F4.3.m1.1.2.2b.cmml" xref="Ch5.F4.3.m1.1.2.2"><mtext class="ltx_mathvariant_italic" id="Ch5.F4.3.m1.1.2.2.cmml" xref="Ch5.F4.3.m1.1.2.2"><em class="ltx_emph ltx_font_italic" id="Ch5.F4.3.m1.1.2.2.1anest">Entropy</em></mtext></ci><ci id="Ch5.F4.3.m1.1.1.cmml" xref="Ch5.F4.3.m1.1.1">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.F4.3.m1.1d">\emph{Entropy}(q)</annotation><annotation encoding="application/x-llamapun" id="Ch5.F4.3.m1.1e">Entropy ( italic_q )</annotation></semantics></math> and popularity model performance in <math alttext="\emph{MRR}(q)" class="ltx_Math" display="inline" id="Ch5.F4.4.m2.1"><semantics id="Ch5.F4.4.m2.1b"><mrow id="Ch5.F4.4.m2.1.2" xref="Ch5.F4.4.m2.1.2.cmml"><mtext class="ltx_mathvariant_italic" id="Ch5.F4.4.m2.1.2.2" xref="Ch5.F4.4.m2.1.2.2b.cmml"><em class="ltx_emph ltx_font_italic" id="Ch5.F4.4.m2.1.2.2.1nest">MRR</em></mtext><mo id="Ch5.F4.4.m2.1.2.1" xref="Ch5.F4.4.m2.1.2.1.cmml">⁢</mo><mrow id="Ch5.F4.4.m2.1.2.3.2" xref="Ch5.F4.4.m2.1.2.cmml"><mo id="Ch5.F4.4.m2.1.2.3.2.1" stretchy="false" xref="Ch5.F4.4.m2.1.2.cmml">(</mo><mi id="Ch5.F4.4.m2.1.1" xref="Ch5.F4.4.m2.1.1.cmml">q</mi><mo id="Ch5.F4.4.m2.1.2.3.2.2" stretchy="false" xref="Ch5.F4.4.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch5.F4.4.m2.1c"><apply id="Ch5.F4.4.m2.1.2.cmml" xref="Ch5.F4.4.m2.1.2"><times id="Ch5.F4.4.m2.1.2.1.cmml" xref="Ch5.F4.4.m2.1.2.1"></times><ci id="Ch5.F4.4.m2.1.2.2b.cmml" xref="Ch5.F4.4.m2.1.2.2"><mtext class="ltx_mathvariant_italic" id="Ch5.F4.4.m2.1.2.2.cmml" xref="Ch5.F4.4.m2.1.2.2"><em class="ltx_emph ltx_font_italic" id="Ch5.F4.4.m2.1.2.2.1anest">MRR</em></mtext></ci><ci id="Ch5.F4.4.m2.1.1.cmml" xref="Ch5.F4.4.m2.1.1">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch5.F4.4.m2.1d">\emph{MRR}(q)</annotation><annotation encoding="application/x-llamapun" id="Ch5.F4.4.m2.1e">MRR ( italic_q )</annotation></semantics></math> for queries with different frequencies. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ai2019zero</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch5.S3.SS5.p5">
<p class="ltx_p" id="Ch5.S3.SS5.p5.1">To tackle this challenge, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ai2019zero</span></cite> proposed a zero-attention neural network model (ZAM) for personalized product search by conducting differentiated personalization for different query-user pairs.
This neural network is designed based on an embedding-based generative framework.
In detail, the authors conduct query-dependent personalization by constructing user profiles with a zero attention strategy that enables it to automatically decide when and how to attend in different search scenarios.
Likewise, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2018attentive</span></cite> designed a dual attention-based network to capture users’ current search intentions and their long-term preferences.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">bi2019study</span></cite> studied relevance feedback based on both long-term and short-term
context dependencies in multi-page product search with an end-to-end personalized product search model.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">xiao2019dynamic</span></cite> proposed a streaming Bayesian method to explicitly and collaboratively learn representations of different categories of entities in a joint metric space over time.</p>
</div>
<div class="ltx_para" id="Ch5.S3.SS5.p6">
<p class="ltx_p" id="Ch5.S3.SS5.p6.1">Spareness is another critical challenge in tracking users’ sequential behaviors in product search. Graph-based methods were proposed to tackle this challenge.
By utilizing short-term user behaviors, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">fan2022modeling</span></cite> extended the structural relationship representation learning scheme <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2020structural</span>]</cite> to explore both local and global user behavior patterns on a user successive behavior graph.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhu2022cross</span></cite> integrated cross-domain transfer learning with a knowledge graph to establish the underlying interest correlation. Their proposed method performs interest alignment across domains by explicitly modeling the long-term and short-term interactions between users and items, which capture the dynamics of product properties and user interests.</p>
</div>
<div class="ltx_para" id="Ch5.S3.SS5.p7">
<p class="ltx_p" id="Ch5.S3.SS5.p7.1">Pre-trained language models have also been applied to query-dependent matching in personalized product search.
To conduct differential personalization adaptively under different contexts, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">bi2020transformer</span></cite> proposed a transformer-based embedding model (TEM) that is more flexible; in TEM, personalization can vary from no to full effect. In contrast with ZAM, TEM takes into consideration the interactions between purchased items so that it learns better dynamic representations of queries and items, which leads to better attention weights in personalized product search.
Based on TEM, the review-based transformer model, abbreviated as RTM, is proposed to match user intents and items at the level of finer-grained information (e.g., their associated reviews) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bi2020learning</span>]</cite>.
The authors conducted user-item matching at the review level so that the reason an item is ranked at the top can be explained; also, the importance of each user and item review during matching is dynamically adapted. RTM represents users and items based only on their reviews without the need for their identifiers, which improves the generalization ability during product search.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">dai2023contrastive</span></cite> proposed a contrastive learning framework, namely CoPPS, to enhance user representations for personalized product search. By pre-training a sequence encoder with contrastive sampling and fine-tuning, CoPPS employs multiple data augmentation strategies to improve user modeling.</p>
</div>
<div class="ltx_para" id="Ch5.S3.SS5.p8">
<p class="ltx_p" id="Ch5.S3.SS5.p8.1">For real-world applications, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2020towards</span></cite> jointly considered semantic matching and personalized matching at JD.com.
The authors propose the deep personalized and semantic retrieval (abbreviated as DPSR) model with a two-tower architecture: a multi-head design of a query tower and an attention-based loss function.
Similarly, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">magnani2022semantic</span></cite> proposed a semantic retrieval model with a two-tower architecture in e-commerce search production at Walmart.com.
The authors proposed to select negative examples for training a large semantic retrieval model and an approximate metric to evaluate the performance.</p>
</div>
</section>
</section>
<section class="ltx_section" id="Ch5.S4">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5.4 </span>Ranking strategies in e-commerce search</h3>
<div class="ltx_para" id="Ch5.S4.p1">
<p class="ltx_p" id="Ch5.S4.p1.1">Ranking optimization is another core task in e-commerce search. In this section, we introduce ranking strategies in e-commerce search.</p>
</div>
<div class="ltx_table ltx_transformed_outer" id="Ch5.T1" style="width:241.9pt;height:567.7pt;vertical-align:-0.0pt;"><div class="ltx_transformed_inner" style="width:567.7pt;transform:translate(-162.87pt,-158.89pt) rotate(-90deg) ;"><figure>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5.1: </span>Comparison of ranking algorithms in terms of NDCG@10 for target variable “Click Rate”, “Cart Add Rate”, “Order Rate”, and “Revenue.” Regu. is an abbreviation for Regulation, whereas lo. is an abbreviation for loss. Table source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">karmaker2017application</span>]</cite></figcaption>
<table class="ltx_tabular ltx_centering ltx_align_middle" id="Ch5.T1.1">
<tr class="ltx_tr" id="Ch5.T1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="Ch5.T1.1.1.1" rowspan="2"><span class="ltx_text ltx_font_bold" id="Ch5.T1.1.1.1.1">Algorithm</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="Ch5.T1.1.1.2"><span class="ltx_text ltx_font_bold" id="Ch5.T1.1.1.2.1">Click Rate</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="Ch5.T1.1.1.3"><span class="ltx_text ltx_font_bold" id="Ch5.T1.1.1.3.1">Cart Add Rate</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="Ch5.T1.1.1.4"><span class="ltx_text ltx_font_bold" id="Ch5.T1.1.1.4.1">Order Rate</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="Ch5.T1.1.1.5"><span class="ltx_text ltx_font_bold" id="Ch5.T1.1.1.5.1">Revenue</span></td>
</tr>
<tr class="ltx_tr" id="Ch5.T1.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch5.T1.1.2.1"><span class="ltx_text ltx_font_bold" id="Ch5.T1.1.2.1.1">Train</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch5.T1.1.2.2"><span class="ltx_text ltx_font_bold" id="Ch5.T1.1.2.2.1">Test</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch5.T1.1.2.3"><span class="ltx_text ltx_font_bold" id="Ch5.T1.1.2.3.1">Train</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch5.T1.1.2.4"><span class="ltx_text ltx_font_bold" id="Ch5.T1.1.2.4.1">Test</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch5.T1.1.2.5"><span class="ltx_text ltx_font_bold" id="Ch5.T1.1.2.5.1">Train</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch5.T1.1.2.6"><span class="ltx_text ltx_font_bold" id="Ch5.T1.1.2.6.1">Test</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch5.T1.1.2.7"><span class="ltx_text ltx_font_bold" id="Ch5.T1.1.2.7.1">Train</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch5.T1.1.2.8"><span class="ltx_text ltx_font_bold" id="Ch5.T1.1.2.8.1">Test</span></td>
</tr>
<tr class="ltx_tr" id="Ch5.T1.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="Ch5.T1.1.3.1">RankNet <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">burges2005learning</span>]</cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch5.T1.1.3.2">0.6857</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch5.T1.1.3.3">0.6855</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch5.T1.1.3.4">0.4399</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch5.T1.1.3.5">0.4402</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch5.T1.1.3.6">0.7158</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch5.T1.1.3.7">0.7142</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch5.T1.1.3.8">0.7577</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch5.T1.1.3.9">0.7578</td>
</tr>
<tr class="ltx_tr" id="Ch5.T1.1.4">
<td class="ltx_td ltx_align_left" id="Ch5.T1.1.4.1">RankBoost <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">freund2003efficient</span>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.4.2">0.5899</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.4.3">0.5904</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.4.4">0.4073</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.4.5">0.4043</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.4.6">0.5007</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.4.7">0.4994</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.4.8">0.5663</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.4.9">0.5639</td>
</tr>
<tr class="ltx_tr" id="Ch5.T1.1.5">
<td class="ltx_td ltx_align_left" id="Ch5.T1.1.5.1">AdaRank <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">xu2007adarank</span>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.5.2">0.6877</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.5.3">0.6857</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.5.4">0.4464</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.5.5">0.4401</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.5.6">0.7334</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.5.7">0.7349</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.5.8">0.757</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.5.9">0.7566</td>
</tr>
<tr class="ltx_tr" id="Ch5.T1.1.6">
<td class="ltx_td ltx_align_left" id="Ch5.T1.1.6.1">Random Forest <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">breiman2001random</span>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.6.2">0.6378</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.6.3">0.6125</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.6.4">0.4588</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.6.5">0.4296</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.6.6">0.5707</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.6.7">0.5288</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.6.8">0.6463</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.6.9">0.5959</td>
</tr>
<tr class="ltx_tr" id="Ch5.T1.1.7">
<td class="ltx_td ltx_align_left" id="Ch5.T1.1.7.1">LambdaMART <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">burges2010ranknet</span>]</cite>
</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.7.2">0.8426</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.7.3"><span class="ltx_text ltx_font_bold" id="Ch5.T1.1.7.3.1">0.8291</span></td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.7.4">0.7664</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.7.5"><span class="ltx_text ltx_font_bold" id="Ch5.T1.1.7.5.1">0.7324</span></td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.7.6">0.7728</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.7.7"><span class="ltx_text ltx_font_bold" id="Ch5.T1.1.7.7.1">0.7687</span></td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.7.8">0.8183</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.7.9"><span class="ltx_text ltx_font_bold" id="Ch5.T1.1.7.9.1">0.7998</span></td>
</tr>
<tr class="ltx_tr" id="Ch5.T1.1.8">
<td class="ltx_td ltx_align_left" id="Ch5.T1.1.8.1"><span class="ltx_text" id="Ch5.T1.1.8.1.1" style="font-size:90%;">Logistic Regression <span class="ltx_text" id="Ch5.T1.1.8.1.1.1" style="font-size:56%;">(L1 regu.) <cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="Ch5.T1.1.8.1.1.1.1.1" style="font-size:200%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">fan2008liblinear</span><span class="ltx_text" id="Ch5.T1.1.8.1.1.1.2.2" style="font-size:200%;">]</span></cite></span></span></td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.8.2">0.6284</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.8.3">0.6272</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.8.4">0.4274</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.8.5">0.4252</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.8.6">0.6677</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.8.7">0.6632</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.8.8">0.6873</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.8.9">0.6822</td>
</tr>
<tr class="ltx_tr" id="Ch5.T1.1.9">
<td class="ltx_td ltx_align_left" id="Ch5.T1.1.9.1"><span class="ltx_text" id="Ch5.T1.1.9.1.1" style="font-size:90%;">Logistic Regression <span class="ltx_text" id="Ch5.T1.1.9.1.1.1" style="font-size:56%;">(L2 regu.) <cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="Ch5.T1.1.9.1.1.1.1.1" style="font-size:200%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">fan2008liblinear</span><span class="ltx_text" id="Ch5.T1.1.9.1.1.1.2.2" style="font-size:200%;">]</span></cite></span></span></td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.9.2">0.5889</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.9.3">0.5866</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.9.4">0.4066</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.9.5">0.4025</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.9.6">0.5045</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.9.7">0.4983</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.9.8">0.5751</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.9.9">0.5675</td>
</tr>
<tr class="ltx_tr" id="Ch5.T1.1.10">
<td class="ltx_td ltx_align_left" id="Ch5.T1.1.10.1"><span class="ltx_text" id="Ch5.T1.1.10.1.1" style="font-size:90%;">SVM Classifier <span class="ltx_text" id="Ch5.T1.1.10.1.1.1" style="font-size:56%;">(L1 regu.+L2 lo.) <cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="Ch5.T1.1.10.1.1.1.1.1" style="font-size:140%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">fan2008liblinear</span><span class="ltx_text" id="Ch5.T1.1.10.1.1.1.2.2" style="font-size:140%;">]</span></cite></span></span></td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.10.2">0.6366</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.10.3">0.6317</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.10.4">0.4348</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.10.5">0.4331</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.10.6">0.6870</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.10.7">0.6794</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.10.8">0.7105</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.10.9">0.7059</td>
</tr>
<tr class="ltx_tr" id="Ch5.T1.1.11">
<td class="ltx_td ltx_align_left" id="Ch5.T1.1.11.1"><span class="ltx_text" id="Ch5.T1.1.11.1.1" style="font-size:90%;">SVM Classifier <span class="ltx_text" id="Ch5.T1.1.11.1.1.1" style="font-size:56%;">(L2 regu.+L1 lo.) <cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="Ch5.T1.1.11.1.1.1.1.1" style="font-size:140%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">fan2008liblinear</span><span class="ltx_text" id="Ch5.T1.1.11.1.1.1.2.2" style="font-size:140%;">]</span></cite></span></span></td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.11.2">0.4596</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.11.3">0.4594</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.11.4">0.3274</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.11.5">0.3219</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.11.6">0.4281</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.11.7">0.4289</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.11.8">0.4503</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.11.9">0.4462</td>
</tr>
<tr class="ltx_tr" id="Ch5.T1.1.12">
<td class="ltx_td ltx_align_left" id="Ch5.T1.1.12.1"><span class="ltx_text" id="Ch5.T1.1.12.1.1" style="font-size:90%;">SVM Regressor <span class="ltx_text" id="Ch5.T1.1.12.1.1.1" style="font-size:56%;">(L2 regu.+L2 lo.) <cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="Ch5.T1.1.12.1.1.1.1.1" style="font-size:140%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">smola1997support</span><span class="ltx_text" id="Ch5.T1.1.12.1.1.1.2.2" style="font-size:140%;">]</span></cite></span></span></td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.12.2">0.2358</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.12.3">0.2341</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.12.4">0.1909</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.12.5">0.1914</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.12.6">0.2100</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.12.7">0.2087</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.12.8">0.2030</td>
<td class="ltx_td ltx_align_center" id="Ch5.T1.1.12.9">0.2027</td>
</tr>
<tr class="ltx_tr" id="Ch5.T1.1.13">
<td class="ltx_td ltx_align_left ltx_border_bb" id="Ch5.T1.1.13.1"><span class="ltx_text" id="Ch5.T1.1.13.1.1" style="font-size:90%;">SVM Regressor <span class="ltx_text" id="Ch5.T1.1.13.1.1.1" style="font-size:56%;">(L2 regu.+L1 lo.) <cite class="ltx_cite ltx_citemacro_citep"><span class="ltx_text" id="Ch5.T1.1.13.1.1.1.1.1" style="font-size:140%;">[</span><span class="ltx_ref ltx_missing_citation ltx_ref_self">smola1997support</span><span class="ltx_text" id="Ch5.T1.1.13.1.1.1.2.2" style="font-size:140%;">]</span></cite></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Ch5.T1.1.13.2">0.2876</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Ch5.T1.1.13.3">0.2865</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Ch5.T1.1.13.4">0.2110</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Ch5.T1.1.13.5">0.2096</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Ch5.T1.1.13.6">0.2078</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Ch5.T1.1.13.7">0.2038</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Ch5.T1.1.13.8">0.2093</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="Ch5.T1.1.13.9">0.2121</td>
</tr>
</table>
</figure></div></div>
<div class="ltx_para" id="Ch5.S4.p2">
<p class="ltx_p" id="Ch5.S4.p2.1">As we have discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S1.SS1" title="5.1.1 Overview of e-commerce search ‣ 5.1 Characteristics of e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.1.1</span></a>, learning to rank approaches have been applied to e-commerce search.
Unlike web search scenarios based on relevance judgments, e-commerce search has multiple implicit and explicit signals that need to be integrated during the ranking process.
In e-commerce search, learning to rank methods need to tackle a series of challenges <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">karmaker2017application</span>]</cite>.
Learning to rank methods assume that the scoring of items to be ranked is a parameterized function of multiple features computed based on the given query and the items, whereas parameters are used to control the weights of features.
A large number of product and query features, such as brands, rating, categories, etc., are important to present useful representations in e-commerce learning to rank models.
Also, product popularity related features have been verified effective in optimizing ranking results of e-commerce search.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">karmaker2017application</span></cite> studied performances of multiple learning to rank strategies in e-commerce search, and found that LambdaMART <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">burges2010ranknet</span>]</cite> is able to learn a balance between these two kinds of features.
Detailed comparisons are listed in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.T1" title="Table 5.1 ‣ 5.4 Ranking strategies in e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.1</span></a>.
In addition, user engagement behavior, such as clicks and orders, also play an important role in optimizing ranking results <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">karmaker2017application</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span>]</cite>.
In contrast with web search which only has clicks to judge the relevance, e-commerce search contains <math alttext="4" class="ltx_Math" display="inline" id="Ch5.S4.p2.1.m1.1"><semantics id="Ch5.S4.p2.1.m1.1a"><mn id="Ch5.S4.p2.1.m1.1.1" xref="Ch5.S4.p2.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="Ch5.S4.p2.1.m1.1b"><cn id="Ch5.S4.p2.1.m1.1.1.cmml" type="integer" xref="Ch5.S4.p2.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="Ch5.S4.p2.1.m1.1c">4</annotation><annotation encoding="application/x-llamapun" id="Ch5.S4.p2.1.m1.1d">4</annotation></semantics></math> prominent relevance feedback behavior: clicks, cart-adds, orders and revenue.
Thus, various training objectives can be considered in optimizing e-commerce ranking results.</p>
</div>
<div class="ltx_para" id="Ch5.S4.p3">
<p class="ltx_p" id="Ch5.S4.p3.1">Another main challenge for e-commerce learning to rank methods is the lack of labeled information.
In web search, high-quality labeled information obtained by eliciting relevance ratings from human experts or crowdsourcing, makes learning to rank methods effective.
However, in the context of e-commerce search it is infeasible to found a standard method to obtain ground-truth information.
Intuitively, crowd sourcing annotations seem to provide labels for e-commerce learning to rank methods.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">karmaker2017application</span></cite> and <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">alonso2009relevance</span></cite> studied the reliability of the relevance judgements provided by the crowd workers for e-commerce queries.
However, the authors found that crowdsourcing fails to provide reliable relevance judgements for e-commerce queries.
Thus implicit feedback from e-commerce users is an important source of information that helps reveal the saliency of products for a given query.</p>
</div>
<div class="ltx_para" id="Ch5.S4.p4">
<p class="ltx_p" id="Ch5.S4.p4.1"><cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span></cite> divided the ranking optimization problem into two successive stages: click optimization and purchase optimization.
We have discussed previous studies on click modeling and purchase modeling in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S1.SS1" title="4.1.1 Click behavior modeling ‣ 4.1 User behavior modeling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4.1.1</span></a> and Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S1.SS3" title="4.1.3 Purchase-intent modeling ‣ 4.1 User behavior modeling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4.1.3</span></a>, respectively.
Inspired by these approaches, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span></cite> applied a list-wise learning to rank model <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">cao2007learning</span>]</cite> to optimize clicks by jointly considering item positions and query-level structures; a binary classification approach was applied to predict the purchase behavior.</p>
</div>
<div class="ltx_para" id="Ch5.S4.p5">
<p class="ltx_p" id="Ch5.S4.p5.1">Online learning to rank approaches have been applied to optimize ranking results in e-commerce search <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">hu2018reinforcement</span>]</cite>.
Unlike traditional static learning to rank models, online learning to rank methods optimize the production ranker interactively by exploiting user implicit feedbacks <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zoghi-copeland-2015</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">oosterhuis-balancing-2017</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">schuth-multileave-2016</span>]</cite>.
Online learning to rank approaches can be divided into two groups: the first is to learn the best ranking function from a function space <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">hofmann2016online</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hofmann2013balancing</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yue2009interactively</span>]</cite>; the second group directly learns the best list under some model of user interactions <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">radlinski2008learning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">schuth-multileave-2016</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">oosterhuis-balancing-2017</span>]</cite>.
As part of the first group of online learning to rank methods, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">hu2018reinforcement</span></cite> proposed a reinforcement learning method for ranking optimization in e-commerce searching scenarios. The authors formulated the multi-step ranking procedure in e-commerce search as a search session Markov decision process (SSMDP).
An algorithm, named deterministic policy gradient with full backup estimation (DPG-FBE), was then proposed for the problem of high reward variance and unbalanced reward distribution of SSMDP.
To integrate search results from heterogeneous sources, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">takanobu2019aggregating</span></cite> proposed a search result aggregation method that formulates a semi-Markov decision process, where a low-level policy is applied to represent items and a high-level policy is used to select rankers.
Based on a large-scale real-world dataset, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">pkddAnwaarRK20</span></cite> employed a counterfactual risk minimization (CRM) approach to directly optimize the ranking list from the log data.</p>
</div>
<div class="ltx_para" id="Ch5.S4.p6">
<p class="ltx_p" id="Ch5.S4.p6.1">In recent years, deep neural-based retrieval models <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mitra2017introduction</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kenter-neural-2017</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">onal-neural-2018</span>]</cite> were used in the ranking step of the e-commerce search <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">magnani2019neural</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2019neural</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2022multi</span>]</cite>. Specifically, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">magnani2019neural</span></cite> enhanced the deep neural network model using different types of text representation and loss function at Warmart.com.
Whereas <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2019neural</span></cite> proposed an e-commerce ranking model with interaction features between the query and a graph of products maintaining product interactions.
Pre-trained foundation models have been verified effective in real-world web search scenarios <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zou2021pre</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lin2021pretrained</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chu2022h</span>]</cite>.
In e-commerce search, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2022multi</span></cite> applied BERT for product ranking within a multi-task learning framework.
The authors used the probability transfer method in the framework to model multiple sequential engagement behaviors.
By integrating semantic matching features output by the domain-specific BERT, the authors confirmed the effectiveness of their proposed approach on real-world e-commerce search data.</p>
</div>
</section>
<section class="ltx_section" id="Ch5.S5">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5.5 </span>Emerging directions</h3>
<section class="ltx_subsection" id="Ch5.S5.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5.1 </span>Multi-modal e-commerce search</h4>
<div class="ltx_para" id="Ch5.S5.SS1.p1">
<p class="ltx_p" id="Ch5.S5.SS1.p1.1">Along with the rise of deep neural networks, recently multi-modal search has received an increasing number of attention <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2013attribute</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">mao2014deep</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2017visual</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2018attentive</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">balaneshin2018deep</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2018multi</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2018visual</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">qu2021dynamic</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wei2021universal</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">tan2022bit</span>]</cite>.
The key of multi-modal search is to find an effective mapping mechanism to project data from different modalities into a common latent space.
Multi-modal search approaches can be classified into hashing-aware models and semantic-aware models.
The former type of methods map various modalities in the original space to a Hamming space using hash functions <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">cao2017transitive</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">luo2018scalable</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhu2020deep</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">tan2022bit</span>]</cite>; whereas the latter ones project the multi-modal data into a low-dimensional space by learning a mapping function <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2016effective</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">laenen2018web</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">qu2021dynamic</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2022siamese</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch5.S5.SS1.p2">
<p class="ltx_p" id="Ch5.S5.SS1.p2.1">As we discussed in previous sections, most approaches to e-commerce search focus on the textual matching problem.
However, multi-modal search in e-commerce is becoming more and more important along with the rise in online photos and openly available image datasets <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2017visual</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2018visual</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2018design</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2020metasearch</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sigir21DaganGN21</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2022pretraining</span>]</cite>.
Real-world scenarios have received a lot of attention:
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2017visual</span></cite> proposed a novel end-to-end approach for scalable visual search infrastructure at Ebay.
Similar platforms can be found at Alibaba <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2018visual</span>]</cite> and JD.com <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2018design</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2020metasearch</span>]</cite>.
Early studies on multi-modal e-commerce search has mostly focused on the fashion category <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2017visual</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2018visual</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2018design</span>]</cite>.
However, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2020metasearch</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sigir21DaganGN21</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2022pretraining</span></cite> confirmed that multi-modal search is widespread across many e-commerce categories, especially categories that involve aspects that are harder to express verbally, but can naturally be captured visually, such as style, type, and pattern.</p>
</div>
<div class="ltx_para" id="Ch5.S5.SS1.p3">
<p class="ltx_p" id="Ch5.S5.SS1.p3.1">In multi-modal search, multiple modalities, such as text and images, can be found in both queries and products. Most of existing multi-modal search solutions optimize a function to project the multi-modal data into a low-dimensional space after unified representation learning.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">laenen2018web</span></cite> presented a multi-modal search paradigm for e-commerce search that results in an improved shopping experience. The authors reason with both images and languages through a common embedding space.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2018multi</span></cite> formulated the e-commerce personalized search problem based on the relevance between images and text with respect to the query and the user preferences from both textual and visual modalities.
The authors modeled the relevance of a product with respect to the query and the user’s multi-modal preferences.
A transition-based product search method was proposed, where the multi-modal feature space is initialized based on the textual and visual features of products.
An interpretable multi-modal e-commerce retrieval framework has been proposed for fashion products <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liao2018interpretable</span>]</cite>.
The authors bridged the gap between deep features and meaningful fashion concepts. They proposed a hierarchical similarity function to accurately characterize the semantic affinities among fashion items.</p>
</div>
<div class="ltx_para" id="Ch5.S5.SS1.p4">
<p class="ltx_p" id="Ch5.S5.SS1.p4.1"><cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">sigir21DaganGN21</span></cite> highlight various differences between visual and textual search, which can be summarized in the following main challenges in multi-modal e-commerce search:</p>
<ul class="ltx_itemize" id="Ch5.S5.I1">
<li class="ltx_item" id="Ch5.S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch5.S5.I1.i1.p1">
<p class="ltx_p" id="Ch5.S5.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="Ch5.S5.I1.i1.p1.1.1">Heterogeneous resources.</span> User queries submitted on e-commerce platforms can be real-world images shot while the user is engaging with the platform.</p>
</div>
</li>
<li class="ltx_item" id="Ch5.S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch5.S5.I1.i2.p1">
<p class="ltx_p" id="Ch5.S5.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="Ch5.S5.I1.i2.p1.1.1">Large-scale sparse data.</span> Large multimedia corpora make scalability and efficiency key requirements for e-commerce search.
Visual queries are more specific than text queries, which results in a lower number of retrieved results and sparse coverages of categories.</p>
</div>
</li>
<li class="ltx_item" id="Ch5.S5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch5.S5.I1.i3.p1">
<p class="ltx_p" id="Ch5.S5.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="Ch5.S5.I1.i3.p1.1.1">Limited user engagement.</span> In multi-modal e-commerce search, user engagement behaviors, e.g., clicks, dwell time, purchases, etc., is substantially sparser than in textual search.</p>
</div>
</li>
<li class="ltx_item" id="Ch5.S5.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch5.S5.I1.i4.p1">
<p class="ltx_p" id="Ch5.S5.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="Ch5.S5.I1.i4.p1.1.1">Ambiguous user intents.</span> Two different main use cases exist in multi-modal e-commerce search: target finding and decision making <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sigir21DaganGN21</span>]</cite>. The two use cases reflect the navigational intent and informational intent respectively.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="Ch5.S5.SS1.p5">
<p class="ltx_p" id="Ch5.S5.SS1.p5.1">Additionally, annotating new product images and retraining a new feature representation model on large-scale data is expensive.
To address this problem, few-shot multi-modal product search was proposed to update the feature representation and index model with few-shot data and employ a fast learning strategy for new categories.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2020metasearch</span></cite> proposed a framework for few-shot incremental search via meta-learning, with a multi-pooling feature extractor to extract discriminative multi-modal features.
Recently, based on pre-trained language models, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2022pretraining</span></cite> proposed an effective contrastive learning framework to learn representations of multi-modal search sessions based on multi-view heterogeneous graph networks.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2023multimodal</span></cite> employed BERT with self-distillation framework for product understanding by integrating visual and textual information.</p>
</div>
<div class="ltx_para" id="Ch5.S5.SS1.p6">
<p class="ltx_p" id="Ch5.S5.SS1.p6.1">Cross-modal search is receiving more and more attention <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">qu2021dynamic</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2022siamese</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">tan2022bit</span>]</cite>.
Unlike multi-modal search, cross-modal search aims to solve the discrepancy problem between different modalities in search sessions <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2022siamese</span>]</cite>.
Although much progress has been made in bridging multiple modalities, it still remains challenging because of the difficult intra-modal reasoning and cross-modal alignment <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">qu2021dynamic</span>]</cite>.
As complicated relations exist among products in e-commerce, it is more difficult to explore these multi-hop interactions in cross-modal product search scenarios.
Moreover, the extremely high computation cost brought by multi-modal input limits its usefulness in large-scale cross-modal retrieval in e-commerce applications.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch5.S5.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5.2 </span>Conversational e-commerce search</h4>
<div class="ltx_para" id="Ch5.S5.SS2.p1">
<p class="ltx_p" id="Ch5.S5.SS2.p1.1">Originating from early studies on interactive information retrieval <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">croft1987i3r</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">belkin1995cases</span>]</cite>, conversational search refers to the process of interacting with a dialogue system to search for information.
Conversational search allows users to express their information needs by directly conducting conversations with search engines.
Unlike traditional query-based search engines, conversational search systems capture users’ intent by taking advantage of the flexibility of mixed-initiative interactions and by providing useful information more directly using human-like responses <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">10.1145/3020165.3020183</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Vtyurina:2017:ECS:3027063.3053175</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ren2021wizard</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">vakulenko2021large</span>]</cite>.
User studies have been conducted to study whether conversational search is needed and what it should look like.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">Trippas:2018:IDS:3176349.3176387</span></cite> conducted a laboratory-based observational study, where pairs of people perform search tasks communicating verbally.
The authors found that conversation search paradigms are more complex and interactive than traditional search scenarios. Moreover, it is difficult to simulate human-human interactions in a conversational search session.
To address this problem, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ren2021wizard</span></cite> collected a dataset of human-human dialogues about conversational search in a wizard-of-oz fashion, namely wizard of search engine (WISE), where two workers play the role of seeker and intermediary, respectively.</p>
</div>
<div class="ltx_para" id="Ch5.S5.SS2.p2">
<p class="ltx_p" id="Ch5.S5.SS2.p2.1">In a conversational search session, the user first initializes the conversation with a request, then the conversational agent iteratively asks the user about their preferences and estimates user interest based on their feedback.
At last, the agent retrieves the information and generates the response.
Many studies focus on the second stage, including generating clarifying queries <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Hamedwww2020</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2021learning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ghanem2022question</span>]</cite> and understanding users’ intent <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wu-yan-2018-deep</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gao2021advances</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">TRIPPAS2020102162</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">radlinski-2017-theoretical</span></cite> considered the question of what properties would be desirable for a system so that the system enables users to answer a variety of information needs in a natural and efficient manner.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">azzopardi2018conceptualizing</span></cite> outlined the actions and intents of users and systems and explain how these actions enable users to explore the search space and resolve their information needs.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ghanem2022question</span></cite> proposed a method to generate user queries for story-based reading comprehension skills.
Recently, the response generation problem in conversational search has been addressed.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ren2021wizard</span></cite> proposed a modular end-to-end neural architecture to transfer the output from the intent understanding to improve the response generation.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ye2022structured</span></cite> designed an interconnected network to co-generate structured and natural responses that allow for bidirectional semantic associations to generate responses.</p>
</div>
<div class="ltx_para" id="Ch5.S5.SS2.p3">
<p class="ltx_p" id="Ch5.S5.SS2.p3.1">In e-commerce, conversational search systems can help consumers access products through instant conversational interactions on mobile phones or other smart devices. Also, conversational e-commerce search alleviates the burden of reformulating queries and browsing through dozens of products in e-commerce search <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zou2022learning</span>]</cite>. Moreover, conversational e-commerce search provides a more natural way to collect explicit feedback from users to understand their preferences <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zamani2022conversational</span>]</cite>.
As an early attempt, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2018towards</span></cite> proposed a paradigm for conversational product search to ask users about their preferred values of an aspect and adopted a memory network to retrieve search results.
Based on that, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">bi2019conversational</span></cite> focused on product-seeking conversations and proposed an aspect-value likelihood model for negative feedback, with a multivariate Bernoulli distribution to generate explainable e-commerce aspects.
To improve the quality of representation in conversational product search, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zou2022learning</span></cite> integrated the representation learning of user, query, item, and conversation into a unified generative framework.</p>
</div>
<div class="ltx_para" id="Ch5.S5.SS2.p4">
<p class="ltx_p" id="Ch5.S5.SS2.p4.1">There are several open questions and research directions for future work in conversational e-commerce search.
First, obtaining data in real-world scenarios is still a challenging problem. Several studies, including, e.g., ConvPS <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zou2022learning</span>]</cite>, have applied simulated data in the experiments. It would be useful to extend the observational experiment into a wizard-of-oz setting by establishing a real-world dataset in the future. We also observe that the ongoing trend in simulating users in task-oriented dialogues could provide more useful insights <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sunzhang2021simulator</span>]</cite>.
Second, modeling user-system interactions is a crucial aspect of conversational e-commerce search.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">vakulenko2021large</span></cite> revealed the complicated situation for large-scale dialogue analysis specifically focusing on the patterns of mixed-initiative.
In contrast with traditional web search scenarios, e-commerce search needs to analyze more complicated user engagement behaviors (See Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S1.SS2" title="5.1.2 Challenges in e-commerce search ‣ 5.1 Characteristics of e-commerce search ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.1.2</span></a> and Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S2" title="3.2 E-commerce users ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.2</span></a>).
Hence in future work, both short-term and long-term user engagement interactions may need specialized attention in conversational e-commerce search.
Third, how to evaluate the performance of conversational e-commerce search is still an open question.
We have demonstrated a wide-range class of evaluation metrics applied in e-commerce search, e.g., engagement-based metrics and revenue-based metrics (See Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5.S2" title="5.2 Evaluation metrics ‣ Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5.2</span></a>).
Therefore, it is even more challenging to measure the success of conversational e-commerce search in terms of all these various kinds of metrics.
Measuring interactivity is critical in conversational information seeking <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zamani2022conversational</span>]</cite>.
Keeping track of how well a user understands the system and vice versa can be another important research direction.
Fourth, personalization conversational e-commerce search needs more attention in future work.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch5.S5.SS3">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5.3 </span>Generative retrieval in e-commerce</h4>
<div class="ltx_para" id="Ch5.S5.SS3.p1">
<p class="ltx_p" id="Ch5.S5.SS3.p1.1">Generative retrieval (GR) has emerged as a novel retrieval paradigm in recent years. During the training phase, documents and their corresponding document identifiers (DocIDs) are encoded into the model’s parameters. Given a query, the model can directly generate the relevant DocIDs <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">tay2022transformer</span>]</cite>.
This approach leverages the model’s ability to memorize and utilize document representations, enhancing retrieval efficiency and accuracy by bypassing traditional retrieval pipelines.</p>
</div>
<div class="ltx_para" id="Ch5.S5.SS3.p2">
<p class="ltx_p" id="Ch5.S5.SS3.p2.1">For indexing strategies, the approach typically involves using the sequence-to-sequence (seq2seq) model to learn the mapping from queries to DocIDs.
In addition, a range of tasks have been introduced to enhance the indexing performance, including learning the mapping from documents to DocIDs <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">tay2022transformer</span>]</cite>, constructing pseudo-queries for documents and mapping them to DocIDs <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2022neural</span>]</cite>, as well as training the model to rank different documents corresponding to the same query <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2024learning</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch5.S5.SS3.p3">
<p class="ltx_p" id="Ch5.S5.SS3.p3.1">Document representations are another key component of the GR model. Since DocIDs are the direct output of model, the quality of these representations directly determines the prediction accuracy of the GR model.
Existing DocIDs can generally be categorized into two types: numeric-based and text-based.
 <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">tay2022transformer</span></cite> introduced three types of numeric DocIDs: (1) unstructured atomic DocIDs, where each document is assigned a random and unique integer identifier, without any structural or semantic information; (2) naively structured string DocIDs, where each document is assigned a random and unique numeric string; and (3) semantically structured DocIDs, which use a hierarchical k-means method, allowing relevant documents to share the same prefix, thereby introducing semantic structure.
 <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2022neural</span></cite> proposed that the meaning of a DodID depends on both the position and the prefix context.
Therefore, they propose a prefix-aware weight-adaptive decoder to adapt to different DocIDs.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2024learning</span></cite> proposed learnable document representations by using a discrete autoencoder to encode documents into short, discrete DocIDs. It optimizes these DocIDs by converting documents into DocIDs through an encoder, then training the model to minimize the reconstruction loss of converting DocIDs back to the original documents.
Text-based DocIDs are another popular approach, as they can inherit the language model’s text generation ability and do not require learning a new DocIDs vocabulary.
The title can be regarded as an intuitive abstract text that represents the content of a document.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">de2020autoregressive</span></cite> proposed using the title as the DocID and achieved good retrieval performance.
However, an arbitrary document may not have an informative and structured title like those in Wikipedia, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2022ultron</span></cite> combined keywords from both the URL and the title to form the DocID.
Additionally, some works have attempted to incorporate more content into text-based DocIDs, including titles, URLs, document substrings, pseudo-queries, and more <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2023multiview</span>]</cite>.
The substrings in the document can also represent the information stored in the document.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">bevilacqua2022autoregressive</span></cite> used arbitrary n-grams in documents as DocID, and retrieves documents under the constrain of a pre-built FM-indexer.</p>
</div>
</section>
</section>
</section>
<section class="ltx_chapter" id="Ch6" lang="en">
<h2 class="ltx_title ltx_title_chapter">
<span class="ltx_tag ltx_tag_chapter">Chapter 6 </span>E-commerce recommendation</h2>
<div class="ltx_para" id="Ch6.p1">
<p class="ltx_p" id="Ch6.p1.1">Recommendation methods refer to information filtering techniques, which can be traced back to the 1980s <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">malone-1987-intelligent</span>]</cite>, i.e., even before the web was developed.
Significant research efforts have been devoted to recommendation in various domains, such as email, movies, books, and music.
E-commerce has its unique properties; recommendation methods developed for other domains may not be suitable for e-commerce scenarios.</p>
</div>
<div class="ltx_para" id="Ch6.p2">
<p class="ltx_p" id="Ch6.p2.1">In this chapter, we focus on recommendation techniques for e-commerce.
First, we summarize the key characteristics of e-commerce recommendation, for which a two-stage framework is developed.
This forms the mainstream solution for e-commerce recommender systems.
We then review models developed for the two stages.
We discuss evaluation methodologies of for e-commerce recommendation and conclude with a description of future research directions to help build better e-commerce recommendation solutions.</p>
</div>
<section class="ltx_section" id="Ch6.S1">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6.1 </span>Characteristics of e-commerce recommendation</h3>
<div class="ltx_para" id="Ch6.S1.p1">
<p class="ltx_p" id="Ch6.S1.p1.1">Recommendation techniques have been applied extensively in e-commerce, in many different scenarios.
They play a crucial role in e-commerce by facilitating users to find desired products and to help boost revenue.
E-commerce has three key characteristics that affect recommendation techniques:</p>
<dl class="ltx_description" id="Ch6.S1.I1">
<dt class="ltx_item" id="Ch6.S1.I1.ix1"><span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="Ch6.S1.I1.ix1.1.1.1">Large volume of products</span></span></dt>
<dd class="ltx_item">
<div class="ltx_para" id="Ch6.S1.I1.ix1.p1">
<p class="ltx_p" id="Ch6.S1.I1.ix1.p1.1">The first key characteristic of e-commerce is the large volume of products, which brings challenges to algorithm scalability, as recommendation algorithms need to quickly scan products and select the ones that are of interest to a user.</p>
</div>
<div class="ltx_para" id="Ch6.S1.I1.ix1.p2">
<p class="ltx_p" id="Ch6.S1.I1.ix1.p2.1">It is common that an e-commerce platform contains millions of products <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">kersbergen-2021-learnings</span>]</cite>. This sheer number of items inevitably poses a computational challenge to recommender systems. The training of models needs to be efficient to be able to quickly (e.g., hourly or at least daily) refresh the model given new user behavior data and latency needs to be sufficiently low in order to be able expose the large catalog to a large number of users.</p>
</div>
</dd>
<dt class="ltx_item" id="Ch6.S1.I1.ix2"><span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="Ch6.S1.I1.ix2.1.1.1">Sparsity</span></span></dt>
<dd class="ltx_item">
<div class="ltx_para" id="Ch6.S1.I1.ix2.p1">
<p class="ltx_p" id="Ch6.S1.I1.ix2.p1.1">The second characteristic is the sparsity of behavior, since a user can only consume (e.g., purchase or click) a few products.</p>
</div>
<div class="ltx_para" id="Ch6.S1.I1.ix2.p2">
<p class="ltx_p" id="Ch6.S1.I1.ix2.p2.1">The main aim of e-commerce recommendation is to satisfy the information needs of users in viewing or purchasing products and services. Behavioral data (e.g., browsing, purchases, and clicks) is an important and useful data source for learning the personalized tastes of users. Given the huge volume of products, it is impossible for a user to interact with most items.
The products with which a user actually interacts are typically just a small fraction of the entire catalog <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li-2021-next-arxiv</span>]</cite>. This results in a significant sparsity issue that forces recommendation methods to learn from user behavior on a limited set of products and to generalize their predictions to all other products.</p>
</div>
</dd>
<dt class="ltx_item" id="Ch6.S1.I1.ix3"><span class="ltx_tag ltx_tag_item"><span class="ltx_text ltx_font_bold" id="Ch6.S1.I1.ix3.1.1.1">Data richness</span></span></dt>
<dd class="ltx_item">
<div class="ltx_para" id="Ch6.S1.I1.ix3.p1">
<p class="ltx_p" id="Ch6.S1.I1.ix3.p1.1">The third characteristic is the richness of product and user data (see Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3" title="Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3</span></a>).</p>
</div>
<div class="ltx_para" id="Ch6.S1.I1.ix3.p2">
<p class="ltx_p" id="Ch6.S1.I1.ix3.p2.1">In addition to user behavior data that directly reflects user preferences, rich information about products (e.g., product name, description, categories, images, etc.) and users (e.g., age, gender, occupation, income level, etc.) is available in e-commerce scenarios.
Moreover, there is much contextual information associated with user behavior, such as time, location, last purchase, and submitted query in the session etc. <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen-top-n-2017</span>]</cite>. This auxiliary information is useful for inferring why a user chooses an item, and is particularly beneficial for cold-start scenarios, where a user (or an item) has very few interactions.</p>
</div>
</dd>
</dl>
</div>
<div class="ltx_para ltx_noindent" id="Ch6.S1.p2">
<p class="ltx_p" id="Ch6.S1.p2.1">As we will see below, many developments in e-commerce recommendation have addressed the three characteristics listed above, resulting in a large number of technical achievements that can be directly put to practical use.</p>
</div>
<figure class="ltx_figure" id="Ch6.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="355" id="Ch6.F1.g1" src="x35.png" width="664"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6.1: </span>Illustration of a two-stage recommendation solution that contains two phases: candidate retrieval and candidate ranking. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ren2018information</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch6.S1.p3">
<p class="ltx_p" id="Ch6.S1.p3.1">We present a two-stage solution that has been commonly used in industrial recommender systems <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">cheng2016wide</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Wang2018Improving</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Covington:2016</span>]</cite>.
Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.F1" title="Figure 6.1 ‣ 6.1 Characteristics of e-commerce recommendation ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6.1</span></a> illustrates a two-stage recommendation framework with two main phases: <em class="ltx_emph ltx_font_italic" id="Ch6.S1.p3.1.1">candidate retrieval</em> and <em class="ltx_emph ltx_font_italic" id="Ch6.S1.p3.1.2">candidate ranking</em>.
Given an information need (either expressed explicitly, e.g., by a user expressing interest in a product category, or implicitly, e.g., through the event of a user visiting a recommender system), the first phase of candidate retrieval goes through the entire product catalog, which may contain millions of products, and selects a small set of products that best match the information need.
Then the selected candidates (usually in the magnitude of hundreds) are passed to the second phase of candidate ranking, which ranks the candidates to produce the final top-<math alttext="k" class="ltx_Math" display="inline" id="Ch6.S1.p3.1.m1.1"><semantics id="Ch6.S1.p3.1.m1.1a"><mi id="Ch6.S1.p3.1.m1.1.1" xref="Ch6.S1.p3.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="Ch6.S1.p3.1.m1.1b"><ci id="Ch6.S1.p3.1.m1.1.1.cmml" xref="Ch6.S1.p3.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S1.p3.1.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="Ch6.S1.p3.1.m1.1d">italic_k</annotation></semantics></math> products to the user.
Such a two-stage architecture can strike a balance between efficiency and effectiveness — it not only supports fast retrieval from a large-scale catalog by using an efficient and light-weight candidate retrieval model, but also maintains good recommendation performance as the final ranking is determined using a potentially fine-grained ranking model.
We survey studies into each stage in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S2" title="6.2 Candidate retrieval models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6.2</span></a> and Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S3" title="6.3 Candidate ranking models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6.3</span></a>, respectively.</p>
</div>
<div class="ltx_para" id="Ch6.S1.p4">
<p class="ltx_p" id="Ch6.S1.p4.1">It is worth mentioning that the pipeline sketched in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.F1" title="Figure 6.1 ‣ 6.1 Characteristics of e-commerce recommendation ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6.1</span></a> may involve third stage, re-ranking, to refine the list produced by the ranking model to meet additional criteria or constraints, such as diversity, novelty, or fairness <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">abdollahpouri2019popularity</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Wilhelm2018Practical</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Gogna2017Balancing</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Pei2019Personalized</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ai2018learning</span>]</cite>.
We briefly introduce recent progress in re-ranking models in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S4" title="6.4 Re-ranking strategies ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6.4</span></a>.</p>
</div>
</section>
<section class="ltx_section" id="Ch6.S2">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6.2 </span>Candidate retrieval models</h3>
<div class="ltx_para" id="Ch6.S2.p1">
<p class="ltx_p" id="Ch6.S2.p1.1">In this section, we survey candidate retrieval models ranging from traditional heuristic methods (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S2.SS1" title="6.2.1 Heuristic methods ‣ 6.2 Candidate retrieval models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6.2.1</span></a>) to recent advanced embedding-based methods (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.S2.SS2" title="6.2.2 Embedding-based methods ‣ 6.2 Candidate retrieval models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6.2.2</span></a>).</p>
</div>
<section class="ltx_subsection" id="Ch6.S2.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2.1 </span>Heuristic methods</h4>
<div class="ltx_para" id="Ch6.S2.SS1.p1">
<p class="ltx_p" id="Ch6.S2.SS1.p1.1">Heuristic-based methods are commonly used for candidate retrieval because they are simple and easy to implement. These methods are based on a manually heuristic rather than on optimization with an objective function.
Early studies have presented various retrieval strategies to search candidate products.
For example, selecting high sale or promotion items has been widely adopted in practical recommender systems, whereas several researchers leveraged principles from economics to perform item selection for candidate retrieval <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2017multi</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2016economic</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch6.S2.SS1.p2">
<p class="ltx_p" id="Ch6.S2.SS1.p2.1">There are many heuristic methods that aim at mining item or user relations for candidate retrieval. We detail approaches to these methods from three perspectives:

<span class="ltx_inline-enumerate" id="Ch6.S2.I1">
<span class="ltx_inline-item" id="Ch6.S2.I1.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch6.S2.I1.i1.1">neighborhood-based methods,
</span></span>
<span class="ltx_inline-item" id="Ch6.S2.I1.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch6.S2.I1.i2.1">graph-based method
and
</span></span>
<span class="ltx_inline-item" id="Ch6.S2.I1.i3"><span class="ltx_tag ltx_tag_inline-item">(iii)</span> <span class="ltx_text" id="Ch6.S2.I1.i3.1">methods based on complementary and substitutable items.
</span></span>
</span></p>
</div>
<div class="ltx_para ltx_noindent" id="Ch6.S2.SS1.p3">
<p class="ltx_p" id="Ch6.S2.SS1.p3.11"><span class="ltx_text ltx_font_bold" id="Ch6.S2.SS1.p3.11.1">Neighborhood-based methods.</span>
Neighborhood-based methods first compute similarity between items or users, and then make recommendations by aggregating information from similar users or items. Neighborhood-based methods can be classified into two types: <em class="ltx_emph ltx_font_italic" id="Ch6.S2.SS1.p3.11.2">user-oriented</em> and <em class="ltx_emph ltx_font_italic" id="Ch6.S2.SS1.p3.11.3">item-oriented</em>.
The paradigm of user-oriented methods <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">grouplens1994</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">grouplens1997</span>]</cite> can be summarized as follows <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">adomavicius2005toward</span>]</cite>:</p>
<table class="ltx_equation ltx_eqn_table" id="Ch6.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\begin{split}\hat{r}_{u,i}=Agg(\{r_{u^{\prime},i}\}_{u^{\prime}\in S_{u}}).%
\end{split}" class="ltx_Math" display="block" id="Ch6.E1.m1.16"><semantics id="Ch6.E1.m1.16a"><mtable displaystyle="true" id="Ch6.E1.m1.16.16.2"><mtr id="Ch6.E1.m1.16.16.2a"><mtd class="ltx_align_right" columnalign="right" id="Ch6.E1.m1.16.16.2b"><mrow id="Ch6.E1.m1.16.16.2.15.15.15.15"><mrow id="Ch6.E1.m1.16.16.2.15.15.15.15.1"><msub id="Ch6.E1.m1.16.16.2.15.15.15.15.1.2"><mover accent="true" id="Ch6.E1.m1.1.1.1.1.1.1" xref="Ch6.E1.m1.1.1.1.1.1.1.cmml"><mi id="Ch6.E1.m1.1.1.1.1.1.1.2" xref="Ch6.E1.m1.1.1.1.1.1.1.2.cmml">r</mi><mo id="Ch6.E1.m1.1.1.1.1.1.1.1" xref="Ch6.E1.m1.1.1.1.1.1.1.1.cmml">^</mo></mover><mrow id="Ch6.E1.m1.2.2.2.2.2.2.1.4" xref="Ch6.E1.m1.2.2.2.2.2.2.1.3.cmml"><mi id="Ch6.E1.m1.2.2.2.2.2.2.1.1" xref="Ch6.E1.m1.2.2.2.2.2.2.1.1.cmml">u</mi><mo id="Ch6.E1.m1.2.2.2.2.2.2.1.4.1" xref="Ch6.E1.m1.2.2.2.2.2.2.1.3.cmml">,</mo><mi id="Ch6.E1.m1.2.2.2.2.2.2.1.2" xref="Ch6.E1.m1.2.2.2.2.2.2.1.2.cmml">i</mi></mrow></msub><mo id="Ch6.E1.m1.3.3.3.3.3.3" xref="Ch6.E1.m1.3.3.3.3.3.3.cmml">=</mo><mrow id="Ch6.E1.m1.16.16.2.15.15.15.15.1.1"><mi id="Ch6.E1.m1.4.4.4.4.4.4" xref="Ch6.E1.m1.4.4.4.4.4.4.cmml">A</mi><mo id="Ch6.E1.m1.16.16.2.15.15.15.15.1.1.2" xref="Ch6.E1.m1.15.15.1.1.1.cmml">⁢</mo><mi id="Ch6.E1.m1.5.5.5.5.5.5" xref="Ch6.E1.m1.5.5.5.5.5.5.cmml">g</mi><mo id="Ch6.E1.m1.16.16.2.15.15.15.15.1.1.2a" xref="Ch6.E1.m1.15.15.1.1.1.cmml">⁢</mo><mi id="Ch6.E1.m1.6.6.6.6.6.6" xref="Ch6.E1.m1.6.6.6.6.6.6.cmml">g</mi><mo id="Ch6.E1.m1.16.16.2.15.15.15.15.1.1.2b" xref="Ch6.E1.m1.15.15.1.1.1.cmml">⁢</mo><mrow id="Ch6.E1.m1.16.16.2.15.15.15.15.1.1.1.1"><mo id="Ch6.E1.m1.7.7.7.7.7.7" stretchy="false" xref="Ch6.E1.m1.15.15.1.1.1.cmml">(</mo><msub id="Ch6.E1.m1.16.16.2.15.15.15.15.1.1.1.1.1"><mrow id="Ch6.E1.m1.16.16.2.15.15.15.15.1.1.1.1.1.1.1"><mo id="Ch6.E1.m1.8.8.8.8.8.8" stretchy="false" xref="Ch6.E1.m1.15.15.1.1.1.cmml">{</mo><msub id="Ch6.E1.m1.16.16.2.15.15.15.15.1.1.1.1.1.1.1.1"><mi id="Ch6.E1.m1.9.9.9.9.9.9" xref="Ch6.E1.m1.9.9.9.9.9.9.cmml">r</mi><mrow id="Ch6.E1.m1.10.10.10.10.10.10.1.2" xref="Ch6.E1.m1.10.10.10.10.10.10.1.3.cmml"><msup id="Ch6.E1.m1.10.10.10.10.10.10.1.2.1" xref="Ch6.E1.m1.10.10.10.10.10.10.1.2.1.cmml"><mi id="Ch6.E1.m1.10.10.10.10.10.10.1.2.1.2" xref="Ch6.E1.m1.10.10.10.10.10.10.1.2.1.2.cmml">u</mi><mo id="Ch6.E1.m1.10.10.10.10.10.10.1.2.1.3" xref="Ch6.E1.m1.10.10.10.10.10.10.1.2.1.3.cmml">′</mo></msup><mo id="Ch6.E1.m1.10.10.10.10.10.10.1.2.2" xref="Ch6.E1.m1.10.10.10.10.10.10.1.3.cmml">,</mo><mi id="Ch6.E1.m1.10.10.10.10.10.10.1.1" xref="Ch6.E1.m1.10.10.10.10.10.10.1.1.cmml">i</mi></mrow></msub><mo id="Ch6.E1.m1.11.11.11.11.11.11" stretchy="false" xref="Ch6.E1.m1.15.15.1.1.1.cmml">}</mo></mrow><mrow id="Ch6.E1.m1.12.12.12.12.12.12.1" xref="Ch6.E1.m1.12.12.12.12.12.12.1.cmml"><msup id="Ch6.E1.m1.12.12.12.12.12.12.1.2" xref="Ch6.E1.m1.12.12.12.12.12.12.1.2.cmml"><mi id="Ch6.E1.m1.12.12.12.12.12.12.1.2.2" xref="Ch6.E1.m1.12.12.12.12.12.12.1.2.2.cmml">u</mi><mo id="Ch6.E1.m1.12.12.12.12.12.12.1.2.3" xref="Ch6.E1.m1.12.12.12.12.12.12.1.2.3.cmml">′</mo></msup><mo id="Ch6.E1.m1.12.12.12.12.12.12.1.1" xref="Ch6.E1.m1.12.12.12.12.12.12.1.1.cmml">∈</mo><msub id="Ch6.E1.m1.12.12.12.12.12.12.1.3" xref="Ch6.E1.m1.12.12.12.12.12.12.1.3.cmml"><mi id="Ch6.E1.m1.12.12.12.12.12.12.1.3.2" xref="Ch6.E1.m1.12.12.12.12.12.12.1.3.2.cmml">S</mi><mi id="Ch6.E1.m1.12.12.12.12.12.12.1.3.3" xref="Ch6.E1.m1.12.12.12.12.12.12.1.3.3.cmml">u</mi></msub></mrow></msub><mo id="Ch6.E1.m1.13.13.13.13.13.13" stretchy="false" xref="Ch6.E1.m1.15.15.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="Ch6.E1.m1.14.14.14.14.14.14" lspace="0em" xref="Ch6.E1.m1.15.15.1.1.1.cmml">.</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="Ch6.E1.m1.16b"><apply id="Ch6.E1.m1.15.15.1.1.1.cmml" xref="Ch6.E1.m1.16.16.2.15.15.15.15.1.1.2"><eq id="Ch6.E1.m1.3.3.3.3.3.3.cmml" xref="Ch6.E1.m1.3.3.3.3.3.3"></eq><apply id="Ch6.E1.m1.15.15.1.1.1.3.cmml" xref="Ch6.E1.m1.16.16.2.15.15.15.15.1.1.2"><csymbol cd="ambiguous" id="Ch6.E1.m1.15.15.1.1.1.3.1.cmml" xref="Ch6.E1.m1.16.16.2.15.15.15.15.1.1.2">subscript</csymbol><apply id="Ch6.E1.m1.1.1.1.1.1.1.cmml" xref="Ch6.E1.m1.1.1.1.1.1.1"><ci id="Ch6.E1.m1.1.1.1.1.1.1.1.cmml" xref="Ch6.E1.m1.1.1.1.1.1.1.1">^</ci><ci id="Ch6.E1.m1.1.1.1.1.1.1.2.cmml" xref="Ch6.E1.m1.1.1.1.1.1.1.2">𝑟</ci></apply><list id="Ch6.E1.m1.2.2.2.2.2.2.1.3.cmml" xref="Ch6.E1.m1.2.2.2.2.2.2.1.4"><ci id="Ch6.E1.m1.2.2.2.2.2.2.1.1.cmml" xref="Ch6.E1.m1.2.2.2.2.2.2.1.1">𝑢</ci><ci id="Ch6.E1.m1.2.2.2.2.2.2.1.2.cmml" xref="Ch6.E1.m1.2.2.2.2.2.2.1.2">𝑖</ci></list></apply><apply id="Ch6.E1.m1.15.15.1.1.1.1.cmml" xref="Ch6.E1.m1.16.16.2.15.15.15.15.1.1.2"><times id="Ch6.E1.m1.15.15.1.1.1.1.2.cmml" xref="Ch6.E1.m1.16.16.2.15.15.15.15.1.1.2"></times><ci id="Ch6.E1.m1.4.4.4.4.4.4.cmml" xref="Ch6.E1.m1.4.4.4.4.4.4">𝐴</ci><ci id="Ch6.E1.m1.5.5.5.5.5.5.cmml" xref="Ch6.E1.m1.5.5.5.5.5.5">𝑔</ci><ci id="Ch6.E1.m1.6.6.6.6.6.6.cmml" xref="Ch6.E1.m1.6.6.6.6.6.6">𝑔</ci><apply id="Ch6.E1.m1.15.15.1.1.1.1.1.1.1.cmml" xref="Ch6.E1.m1.16.16.2.15.15.15.15.1.1.2"><csymbol cd="ambiguous" id="Ch6.E1.m1.15.15.1.1.1.1.1.1.1.2.cmml" xref="Ch6.E1.m1.16.16.2.15.15.15.15.1.1.2">subscript</csymbol><set id="Ch6.E1.m1.15.15.1.1.1.1.1.1.1.1.2.cmml" xref="Ch6.E1.m1.16.16.2.15.15.15.15.1.1.2"><apply id="Ch6.E1.m1.15.15.1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch6.E1.m1.16.16.2.15.15.15.15.1.1.2"><csymbol cd="ambiguous" id="Ch6.E1.m1.15.15.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch6.E1.m1.16.16.2.15.15.15.15.1.1.2">subscript</csymbol><ci id="Ch6.E1.m1.9.9.9.9.9.9.cmml" xref="Ch6.E1.m1.9.9.9.9.9.9">𝑟</ci><list id="Ch6.E1.m1.10.10.10.10.10.10.1.3.cmml" xref="Ch6.E1.m1.10.10.10.10.10.10.1.2"><apply id="Ch6.E1.m1.10.10.10.10.10.10.1.2.1.cmml" xref="Ch6.E1.m1.10.10.10.10.10.10.1.2.1"><csymbol cd="ambiguous" id="Ch6.E1.m1.10.10.10.10.10.10.1.2.1.1.cmml" xref="Ch6.E1.m1.10.10.10.10.10.10.1.2.1">superscript</csymbol><ci id="Ch6.E1.m1.10.10.10.10.10.10.1.2.1.2.cmml" xref="Ch6.E1.m1.10.10.10.10.10.10.1.2.1.2">𝑢</ci><ci id="Ch6.E1.m1.10.10.10.10.10.10.1.2.1.3.cmml" xref="Ch6.E1.m1.10.10.10.10.10.10.1.2.1.3">′</ci></apply><ci id="Ch6.E1.m1.10.10.10.10.10.10.1.1.cmml" xref="Ch6.E1.m1.10.10.10.10.10.10.1.1">𝑖</ci></list></apply></set><apply id="Ch6.E1.m1.12.12.12.12.12.12.1.cmml" xref="Ch6.E1.m1.12.12.12.12.12.12.1"><in id="Ch6.E1.m1.12.12.12.12.12.12.1.1.cmml" xref="Ch6.E1.m1.12.12.12.12.12.12.1.1"></in><apply id="Ch6.E1.m1.12.12.12.12.12.12.1.2.cmml" xref="Ch6.E1.m1.12.12.12.12.12.12.1.2"><csymbol cd="ambiguous" id="Ch6.E1.m1.12.12.12.12.12.12.1.2.1.cmml" xref="Ch6.E1.m1.12.12.12.12.12.12.1.2">superscript</csymbol><ci id="Ch6.E1.m1.12.12.12.12.12.12.1.2.2.cmml" xref="Ch6.E1.m1.12.12.12.12.12.12.1.2.2">𝑢</ci><ci id="Ch6.E1.m1.12.12.12.12.12.12.1.2.3.cmml" xref="Ch6.E1.m1.12.12.12.12.12.12.1.2.3">′</ci></apply><apply id="Ch6.E1.m1.12.12.12.12.12.12.1.3.cmml" xref="Ch6.E1.m1.12.12.12.12.12.12.1.3"><csymbol cd="ambiguous" id="Ch6.E1.m1.12.12.12.12.12.12.1.3.1.cmml" xref="Ch6.E1.m1.12.12.12.12.12.12.1.3">subscript</csymbol><ci id="Ch6.E1.m1.12.12.12.12.12.12.1.3.2.cmml" xref="Ch6.E1.m1.12.12.12.12.12.12.1.3.2">𝑆</ci><ci id="Ch6.E1.m1.12.12.12.12.12.12.1.3.3.cmml" xref="Ch6.E1.m1.12.12.12.12.12.12.1.3.3">𝑢</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.E1.m1.16c">\begin{split}\hat{r}_{u,i}=Agg(\{r_{u^{\prime},i}\}_{u^{\prime}\in S_{u}}).%
\end{split}</annotation><annotation encoding="application/x-llamapun" id="Ch6.E1.m1.16d">start_ROW start_CELL over^ start_ARG italic_r end_ARG start_POSTSUBSCRIPT italic_u , italic_i end_POSTSUBSCRIPT = italic_A italic_g italic_g ( { italic_r start_POSTSUBSCRIPT italic_u start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , italic_i end_POSTSUBSCRIPT } start_POSTSUBSCRIPT italic_u start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ∈ italic_S start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) . end_CELL end_ROW</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6.1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch6.S2.SS1.p3.10">where <math alttext="\hat{r}_{u,i}" class="ltx_Math" display="inline" id="Ch6.S2.SS1.p3.1.m1.2"><semantics id="Ch6.S2.SS1.p3.1.m1.2a"><msub id="Ch6.S2.SS1.p3.1.m1.2.3" xref="Ch6.S2.SS1.p3.1.m1.2.3.cmml"><mover accent="true" id="Ch6.S2.SS1.p3.1.m1.2.3.2" xref="Ch6.S2.SS1.p3.1.m1.2.3.2.cmml"><mi id="Ch6.S2.SS1.p3.1.m1.2.3.2.2" xref="Ch6.S2.SS1.p3.1.m1.2.3.2.2.cmml">r</mi><mo id="Ch6.S2.SS1.p3.1.m1.2.3.2.1" xref="Ch6.S2.SS1.p3.1.m1.2.3.2.1.cmml">^</mo></mover><mrow id="Ch6.S2.SS1.p3.1.m1.2.2.2.4" xref="Ch6.S2.SS1.p3.1.m1.2.2.2.3.cmml"><mi id="Ch6.S2.SS1.p3.1.m1.1.1.1.1" xref="Ch6.S2.SS1.p3.1.m1.1.1.1.1.cmml">u</mi><mo id="Ch6.S2.SS1.p3.1.m1.2.2.2.4.1" xref="Ch6.S2.SS1.p3.1.m1.2.2.2.3.cmml">,</mo><mi id="Ch6.S2.SS1.p3.1.m1.2.2.2.2" xref="Ch6.S2.SS1.p3.1.m1.2.2.2.2.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS1.p3.1.m1.2b"><apply id="Ch6.S2.SS1.p3.1.m1.2.3.cmml" xref="Ch6.S2.SS1.p3.1.m1.2.3"><csymbol cd="ambiguous" id="Ch6.S2.SS1.p3.1.m1.2.3.1.cmml" xref="Ch6.S2.SS1.p3.1.m1.2.3">subscript</csymbol><apply id="Ch6.S2.SS1.p3.1.m1.2.3.2.cmml" xref="Ch6.S2.SS1.p3.1.m1.2.3.2"><ci id="Ch6.S2.SS1.p3.1.m1.2.3.2.1.cmml" xref="Ch6.S2.SS1.p3.1.m1.2.3.2.1">^</ci><ci id="Ch6.S2.SS1.p3.1.m1.2.3.2.2.cmml" xref="Ch6.S2.SS1.p3.1.m1.2.3.2.2">𝑟</ci></apply><list id="Ch6.S2.SS1.p3.1.m1.2.2.2.3.cmml" xref="Ch6.S2.SS1.p3.1.m1.2.2.2.4"><ci id="Ch6.S2.SS1.p3.1.m1.1.1.1.1.cmml" xref="Ch6.S2.SS1.p3.1.m1.1.1.1.1">𝑢</ci><ci id="Ch6.S2.SS1.p3.1.m1.2.2.2.2.cmml" xref="Ch6.S2.SS1.p3.1.m1.2.2.2.2">𝑖</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS1.p3.1.m1.2c">\hat{r}_{u,i}</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS1.p3.1.m1.2d">over^ start_ARG italic_r end_ARG start_POSTSUBSCRIPT italic_u , italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is the rating of user <math alttext="u" class="ltx_Math" display="inline" id="Ch6.S2.SS1.p3.2.m2.1"><semantics id="Ch6.S2.SS1.p3.2.m2.1a"><mi id="Ch6.S2.SS1.p3.2.m2.1.1" xref="Ch6.S2.SS1.p3.2.m2.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS1.p3.2.m2.1b"><ci id="Ch6.S2.SS1.p3.2.m2.1.1.cmml" xref="Ch6.S2.SS1.p3.2.m2.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS1.p3.2.m2.1c">u</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS1.p3.2.m2.1d">italic_u</annotation></semantics></math> for the target unrated item <math alttext="i" class="ltx_Math" display="inline" id="Ch6.S2.SS1.p3.3.m3.1"><semantics id="Ch6.S2.SS1.p3.3.m3.1a"><mi id="Ch6.S2.SS1.p3.3.m3.1.1" xref="Ch6.S2.SS1.p3.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS1.p3.3.m3.1b"><ci id="Ch6.S2.SS1.p3.3.m3.1.1.cmml" xref="Ch6.S2.SS1.p3.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS1.p3.3.m3.1c">i</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS1.p3.3.m3.1d">italic_i</annotation></semantics></math> that we seek to estimate, <math alttext="S_{u}" class="ltx_Math" display="inline" id="Ch6.S2.SS1.p3.4.m4.1"><semantics id="Ch6.S2.SS1.p3.4.m4.1a"><msub id="Ch6.S2.SS1.p3.4.m4.1.1" xref="Ch6.S2.SS1.p3.4.m4.1.1.cmml"><mi id="Ch6.S2.SS1.p3.4.m4.1.1.2" xref="Ch6.S2.SS1.p3.4.m4.1.1.2.cmml">S</mi><mi id="Ch6.S2.SS1.p3.4.m4.1.1.3" xref="Ch6.S2.SS1.p3.4.m4.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS1.p3.4.m4.1b"><apply id="Ch6.S2.SS1.p3.4.m4.1.1.cmml" xref="Ch6.S2.SS1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="Ch6.S2.SS1.p3.4.m4.1.1.1.cmml" xref="Ch6.S2.SS1.p3.4.m4.1.1">subscript</csymbol><ci id="Ch6.S2.SS1.p3.4.m4.1.1.2.cmml" xref="Ch6.S2.SS1.p3.4.m4.1.1.2">𝑆</ci><ci id="Ch6.S2.SS1.p3.4.m4.1.1.3.cmml" xref="Ch6.S2.SS1.p3.4.m4.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS1.p3.4.m4.1c">S_{u}</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS1.p3.4.m4.1d">italic_S start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math> is the set of similar users of <math alttext="u" class="ltx_Math" display="inline" id="Ch6.S2.SS1.p3.5.m5.1"><semantics id="Ch6.S2.SS1.p3.5.m5.1a"><mi id="Ch6.S2.SS1.p3.5.m5.1.1" xref="Ch6.S2.SS1.p3.5.m5.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS1.p3.5.m5.1b"><ci id="Ch6.S2.SS1.p3.5.m5.1.1.cmml" xref="Ch6.S2.SS1.p3.5.m5.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS1.p3.5.m5.1c">u</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS1.p3.5.m5.1d">italic_u</annotation></semantics></math>, and <math alttext="r_{u^{\prime},i}" class="ltx_Math" display="inline" id="Ch6.S2.SS1.p3.6.m6.2"><semantics id="Ch6.S2.SS1.p3.6.m6.2a"><msub id="Ch6.S2.SS1.p3.6.m6.2.3" xref="Ch6.S2.SS1.p3.6.m6.2.3.cmml"><mi id="Ch6.S2.SS1.p3.6.m6.2.3.2" xref="Ch6.S2.SS1.p3.6.m6.2.3.2.cmml">r</mi><mrow id="Ch6.S2.SS1.p3.6.m6.2.2.2.2" xref="Ch6.S2.SS1.p3.6.m6.2.2.2.3.cmml"><msup id="Ch6.S2.SS1.p3.6.m6.2.2.2.2.1" xref="Ch6.S2.SS1.p3.6.m6.2.2.2.2.1.cmml"><mi id="Ch6.S2.SS1.p3.6.m6.2.2.2.2.1.2" xref="Ch6.S2.SS1.p3.6.m6.2.2.2.2.1.2.cmml">u</mi><mo id="Ch6.S2.SS1.p3.6.m6.2.2.2.2.1.3" xref="Ch6.S2.SS1.p3.6.m6.2.2.2.2.1.3.cmml">′</mo></msup><mo id="Ch6.S2.SS1.p3.6.m6.2.2.2.2.2" xref="Ch6.S2.SS1.p3.6.m6.2.2.2.3.cmml">,</mo><mi id="Ch6.S2.SS1.p3.6.m6.1.1.1.1" xref="Ch6.S2.SS1.p3.6.m6.1.1.1.1.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS1.p3.6.m6.2b"><apply id="Ch6.S2.SS1.p3.6.m6.2.3.cmml" xref="Ch6.S2.SS1.p3.6.m6.2.3"><csymbol cd="ambiguous" id="Ch6.S2.SS1.p3.6.m6.2.3.1.cmml" xref="Ch6.S2.SS1.p3.6.m6.2.3">subscript</csymbol><ci id="Ch6.S2.SS1.p3.6.m6.2.3.2.cmml" xref="Ch6.S2.SS1.p3.6.m6.2.3.2">𝑟</ci><list id="Ch6.S2.SS1.p3.6.m6.2.2.2.3.cmml" xref="Ch6.S2.SS1.p3.6.m6.2.2.2.2"><apply id="Ch6.S2.SS1.p3.6.m6.2.2.2.2.1.cmml" xref="Ch6.S2.SS1.p3.6.m6.2.2.2.2.1"><csymbol cd="ambiguous" id="Ch6.S2.SS1.p3.6.m6.2.2.2.2.1.1.cmml" xref="Ch6.S2.SS1.p3.6.m6.2.2.2.2.1">superscript</csymbol><ci id="Ch6.S2.SS1.p3.6.m6.2.2.2.2.1.2.cmml" xref="Ch6.S2.SS1.p3.6.m6.2.2.2.2.1.2">𝑢</ci><ci id="Ch6.S2.SS1.p3.6.m6.2.2.2.2.1.3.cmml" xref="Ch6.S2.SS1.p3.6.m6.2.2.2.2.1.3">′</ci></apply><ci id="Ch6.S2.SS1.p3.6.m6.1.1.1.1.cmml" xref="Ch6.S2.SS1.p3.6.m6.1.1.1.1">𝑖</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS1.p3.6.m6.2c">r_{u^{\prime},i}</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS1.p3.6.m6.2d">italic_r start_POSTSUBSCRIPT italic_u start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT , italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is the rating of similar user <math alttext="u^{\prime}" class="ltx_Math" display="inline" id="Ch6.S2.SS1.p3.7.m7.1"><semantics id="Ch6.S2.SS1.p3.7.m7.1a"><msup id="Ch6.S2.SS1.p3.7.m7.1.1" xref="Ch6.S2.SS1.p3.7.m7.1.1.cmml"><mi id="Ch6.S2.SS1.p3.7.m7.1.1.2" xref="Ch6.S2.SS1.p3.7.m7.1.1.2.cmml">u</mi><mo id="Ch6.S2.SS1.p3.7.m7.1.1.3" xref="Ch6.S2.SS1.p3.7.m7.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS1.p3.7.m7.1b"><apply id="Ch6.S2.SS1.p3.7.m7.1.1.cmml" xref="Ch6.S2.SS1.p3.7.m7.1.1"><csymbol cd="ambiguous" id="Ch6.S2.SS1.p3.7.m7.1.1.1.cmml" xref="Ch6.S2.SS1.p3.7.m7.1.1">superscript</csymbol><ci id="Ch6.S2.SS1.p3.7.m7.1.1.2.cmml" xref="Ch6.S2.SS1.p3.7.m7.1.1.2">𝑢</ci><ci id="Ch6.S2.SS1.p3.7.m7.1.1.3.cmml" xref="Ch6.S2.SS1.p3.7.m7.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS1.p3.7.m7.1c">u^{\prime}</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS1.p3.7.m7.1d">italic_u start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math> on the target item <math alttext="i" class="ltx_Math" display="inline" id="Ch6.S2.SS1.p3.8.m8.1"><semantics id="Ch6.S2.SS1.p3.8.m8.1a"><mi id="Ch6.S2.SS1.p3.8.m8.1.1" xref="Ch6.S2.SS1.p3.8.m8.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS1.p3.8.m8.1b"><ci id="Ch6.S2.SS1.p3.8.m8.1.1.cmml" xref="Ch6.S2.SS1.p3.8.m8.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS1.p3.8.m8.1c">i</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS1.p3.8.m8.1d">italic_i</annotation></semantics></math>. <math alttext="Agg(\cdot)" class="ltx_Math" display="inline" id="Ch6.S2.SS1.p3.9.m9.1"><semantics id="Ch6.S2.SS1.p3.9.m9.1a"><mrow id="Ch6.S2.SS1.p3.9.m9.1.2" xref="Ch6.S2.SS1.p3.9.m9.1.2.cmml"><mi id="Ch6.S2.SS1.p3.9.m9.1.2.2" xref="Ch6.S2.SS1.p3.9.m9.1.2.2.cmml">A</mi><mo id="Ch6.S2.SS1.p3.9.m9.1.2.1" xref="Ch6.S2.SS1.p3.9.m9.1.2.1.cmml">⁢</mo><mi id="Ch6.S2.SS1.p3.9.m9.1.2.3" xref="Ch6.S2.SS1.p3.9.m9.1.2.3.cmml">g</mi><mo id="Ch6.S2.SS1.p3.9.m9.1.2.1a" xref="Ch6.S2.SS1.p3.9.m9.1.2.1.cmml">⁢</mo><mi id="Ch6.S2.SS1.p3.9.m9.1.2.4" xref="Ch6.S2.SS1.p3.9.m9.1.2.4.cmml">g</mi><mo id="Ch6.S2.SS1.p3.9.m9.1.2.1b" xref="Ch6.S2.SS1.p3.9.m9.1.2.1.cmml">⁢</mo><mrow id="Ch6.S2.SS1.p3.9.m9.1.2.5.2" xref="Ch6.S2.SS1.p3.9.m9.1.2.cmml"><mo id="Ch6.S2.SS1.p3.9.m9.1.2.5.2.1" stretchy="false" xref="Ch6.S2.SS1.p3.9.m9.1.2.cmml">(</mo><mo id="Ch6.S2.SS1.p3.9.m9.1.1" lspace="0em" rspace="0em" xref="Ch6.S2.SS1.p3.9.m9.1.1.cmml">⋅</mo><mo id="Ch6.S2.SS1.p3.9.m9.1.2.5.2.2" stretchy="false" xref="Ch6.S2.SS1.p3.9.m9.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS1.p3.9.m9.1b"><apply id="Ch6.S2.SS1.p3.9.m9.1.2.cmml" xref="Ch6.S2.SS1.p3.9.m9.1.2"><times id="Ch6.S2.SS1.p3.9.m9.1.2.1.cmml" xref="Ch6.S2.SS1.p3.9.m9.1.2.1"></times><ci id="Ch6.S2.SS1.p3.9.m9.1.2.2.cmml" xref="Ch6.S2.SS1.p3.9.m9.1.2.2">𝐴</ci><ci id="Ch6.S2.SS1.p3.9.m9.1.2.3.cmml" xref="Ch6.S2.SS1.p3.9.m9.1.2.3">𝑔</ci><ci id="Ch6.S2.SS1.p3.9.m9.1.2.4.cmml" xref="Ch6.S2.SS1.p3.9.m9.1.2.4">𝑔</ci><ci id="Ch6.S2.SS1.p3.9.m9.1.1.cmml" xref="Ch6.S2.SS1.p3.9.m9.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS1.p3.9.m9.1c">Agg(\cdot)</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS1.p3.9.m9.1d">italic_A italic_g italic_g ( ⋅ )</annotation></semantics></math> is a function that aggregates information from similar users. The process consists of two steps:

<span class="ltx_inline-enumerate" id="Ch6.S2.I2">
<span class="ltx_inline-item" id="Ch6.S2.I2.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch6.S2.I2.i1.1">finding similar users, and
</span></span>
<span class="ltx_inline-item" id="Ch6.S2.I2.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch6.S2.I2.i2.1">aggregating the information of similar users.
</span></span>
</span>
Recent work has explored various approaches for similarity computation, including but not limited to Pearson correlation coefficients, information entropy, and mean squared difference <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">shardanand1995social</span>]</cite> between the ratings given by two users <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">grouplens1994</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">shardanand1995social</span>]</cite>. Spearman rank correlation has been leveraged to measure item rank similarity rather than value similarity <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">herlocker1999algorithmic</span>]</cite>.
For the aggregation function <math alttext="Agg(\cdot)" class="ltx_Math" display="inline" id="Ch6.S2.SS1.p3.10.m10.1"><semantics id="Ch6.S2.SS1.p3.10.m10.1a"><mrow id="Ch6.S2.SS1.p3.10.m10.1.2" xref="Ch6.S2.SS1.p3.10.m10.1.2.cmml"><mi id="Ch6.S2.SS1.p3.10.m10.1.2.2" xref="Ch6.S2.SS1.p3.10.m10.1.2.2.cmml">A</mi><mo id="Ch6.S2.SS1.p3.10.m10.1.2.1" xref="Ch6.S2.SS1.p3.10.m10.1.2.1.cmml">⁢</mo><mi id="Ch6.S2.SS1.p3.10.m10.1.2.3" xref="Ch6.S2.SS1.p3.10.m10.1.2.3.cmml">g</mi><mo id="Ch6.S2.SS1.p3.10.m10.1.2.1a" xref="Ch6.S2.SS1.p3.10.m10.1.2.1.cmml">⁢</mo><mi id="Ch6.S2.SS1.p3.10.m10.1.2.4" xref="Ch6.S2.SS1.p3.10.m10.1.2.4.cmml">g</mi><mo id="Ch6.S2.SS1.p3.10.m10.1.2.1b" xref="Ch6.S2.SS1.p3.10.m10.1.2.1.cmml">⁢</mo><mrow id="Ch6.S2.SS1.p3.10.m10.1.2.5.2" xref="Ch6.S2.SS1.p3.10.m10.1.2.cmml"><mo id="Ch6.S2.SS1.p3.10.m10.1.2.5.2.1" stretchy="false" xref="Ch6.S2.SS1.p3.10.m10.1.2.cmml">(</mo><mo id="Ch6.S2.SS1.p3.10.m10.1.1" lspace="0em" rspace="0em" xref="Ch6.S2.SS1.p3.10.m10.1.1.cmml">⋅</mo><mo id="Ch6.S2.SS1.p3.10.m10.1.2.5.2.2" stretchy="false" xref="Ch6.S2.SS1.p3.10.m10.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS1.p3.10.m10.1b"><apply id="Ch6.S2.SS1.p3.10.m10.1.2.cmml" xref="Ch6.S2.SS1.p3.10.m10.1.2"><times id="Ch6.S2.SS1.p3.10.m10.1.2.1.cmml" xref="Ch6.S2.SS1.p3.10.m10.1.2.1"></times><ci id="Ch6.S2.SS1.p3.10.m10.1.2.2.cmml" xref="Ch6.S2.SS1.p3.10.m10.1.2.2">𝐴</ci><ci id="Ch6.S2.SS1.p3.10.m10.1.2.3.cmml" xref="Ch6.S2.SS1.p3.10.m10.1.2.3">𝑔</ci><ci id="Ch6.S2.SS1.p3.10.m10.1.2.4.cmml" xref="Ch6.S2.SS1.p3.10.m10.1.2.4">𝑔</ci><ci id="Ch6.S2.SS1.p3.10.m10.1.1.cmml" xref="Ch6.S2.SS1.p3.10.m10.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS1.p3.10.m10.1c">Agg(\cdot)</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS1.p3.10.m10.1d">italic_A italic_g italic_g ( ⋅ )</annotation></semantics></math>, a linear weighted combination is a commonly used strategy <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">grouplens1994</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">shardanand1995social</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">herlocker1999algorithmic</span>]</cite>. The similarity score is usually leveraged for setting combination weights, as similar users naturally deserve a larger contribution to a prediction.</p>
</div>
<div class="ltx_para" id="Ch6.S2.SS1.p4">
<p class="ltx_p" id="Ch6.S2.SS1.p4.1">Inspired by the success of user-oriented methods, item-oriented methods have also been explored <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sarwar2001itemCF</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">karypis2001itemCF</span>]</cite>. Item-oriented methods have a quite similar process compared as user-oriented methods except that they aim at mining item similarity rather than user similarity. Recent studies empirically show that item-oriented methods achieve better performance than user-oriented methods <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mclaughlin2004useranditemcf</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sarwar2001itemCF</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">karypis2001itemCF</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch6.S2.SS1.p5">
<p class="ltx_p" id="Ch6.S2.SS1.p5.1">In summary, neighborhood-based methods have shown several advantages: they are simple, efficient, highly explainable, and easily deployed.
However, their disadvantages are also obvious: they have a heavy reliance on human expertise, lack of flexibility, and they suffer from data sparsity.
Although they may not perform as well as recent, more advanced methods, they usually serve as a benchmark for candidates generation in real-world recommender systems.</p>
</div>
<figure class="ltx_figure" id="Ch6.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="464" id="Ch6.F2.g1" src="x36.png" width="498"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6.2: </span>An item graph. Each node represents an item and each edge indicates the existence of a co-occurrence relation between the two items. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">leem2014impact</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="Ch6.S2.SS1.p6">
<p class="ltx_p" id="Ch6.S2.SS1.p6.1"><span class="ltx_text ltx_font_bold" id="Ch6.S2.SS1.p6.1.1">Graph-based methods.</span>
Another type of heuristic strategy is to explore similar items through an item graph.
As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.F2" title="Figure 6.2 ‣ 6.2.1 Heuristic methods ‣ 6.2 Candidate retrieval models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6.2</span></a>, the graph can be constructed from item-item co-occurrence or user-item interaction information, where each node represents a user or an item while each edge indicates a certain relation between these objects.
Based on the graph, it is easier and more effective to evaluate the similarity between items via the closeness of two items in the graph.
This has inspired a number of recent publications on graph-based retrieval.
For example, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">leem2014impact</span></cite> conduct information propagation on the graph to calculate item similarity, whereas <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">eksombatchai2018pixie</span></cite> directly perform random walks from seed nodes to select relevant items.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch6.S2.SS1.p7">
<p class="ltx_p" id="Ch6.S2.SS1.p7.1"><span class="ltx_text ltx_font_bold" id="Ch6.S2.SS1.p7.1.1">Complementary and substitutable items.</span>
Beyond item similarity, more complicated item relations concerning complementarity of items and substitutability of one item for another have also been considered <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Wang2018Improving</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2018quality</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2020try</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">guoziyi2018</span>]</cite>.
Complements indicate items that might be purchased together, while substitutes indicate items that are interchangeable.
Mining complements and substitutes is beneficial to satisfy the true need of users, and further increases the click-through rate and user stickiness <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Wang2018Improving</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">guoziyi2018</span>]</cite>. However, it is challenging as we often lack ground-truth labels of such relations. To deal with this problem, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">Wang2018Improving</span></cite> leverage co-view and co-purchase statistics, as weak relation signals to supervise the learning of the complements and substitutes. They further integrate the learned relations into a vanilla recommendation model and observe improvements in recommendation performance.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">guoziyi2018</span></cite> propose a graph convolutional neural network that decouples item semantics for inferring complementary and substitutable items.
The decoupled graph neural network contains a two-step knowledge integration scheme.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2020try</span></cite> propose attribute-aware collaborative filtering to perform substitute recommendation by addressing issues from both personalization and interpretability perspectives.</p>
</div>
<figure class="ltx_figure" id="Ch6.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="209" id="Ch6.F3.g1" src="x37.png" width="498"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6.3: </span>Illustration of the workflow of embedding-based methods: They first map users and items into a common embedding space; then they leverage the KNN algorithm to search the candidate items having the smallest embedding distance with the target user.
Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">andoni2006near</span>]</cite>.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="Ch6.S2.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2.2 </span>Embedding-based methods</h4>
<div class="ltx_para" id="Ch6.S2.SS2.p1">
<p class="ltx_p" id="Ch6.S2.SS2.p1.1">Embedding-based methods are another type of candidate retrieval methods.
As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.F3" title="Figure 6.3 ‣ 6.2.1 Heuristic methods ‣ 6.2 Candidate retrieval models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6.3</span></a>, this kind of method first maps users and items into a common embedding space, and then leverages approximate the K-Nearest Neighbor (KNN) algorithm <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">andoni2006near</span>]</cite> to search for candidate items with the smallest embedding distance to the target user.
The key of these methods lies in learning high-quality embeddings for each user and item. In what follows, we introduce techniques for learning embeddings.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch6.S2.SS2.p2">
<p class="ltx_p" id="Ch6.S2.SS2.p2.5"><span class="ltx_text ltx_font_bold" id="Ch6.S2.SS2.p2.5.1">Matrix factorization.</span>
Matrix factorization (MF) is a classic embedding-based method.
The basic assumption behind MF is that the user-item interaction matrix has a low-rank structure.
As such, MF delineates each user and item as an embedding vector and then predicts the preference between each user-item pair as the inner product of their embedding vectors.
Let <math alttext="p_{u}\in\mathcal{R}^{k}" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p2.1.m1.1"><semantics id="Ch6.S2.SS2.p2.1.m1.1a"><mrow id="Ch6.S2.SS2.p2.1.m1.1.1" xref="Ch6.S2.SS2.p2.1.m1.1.1.cmml"><msub id="Ch6.S2.SS2.p2.1.m1.1.1.2" xref="Ch6.S2.SS2.p2.1.m1.1.1.2.cmml"><mi id="Ch6.S2.SS2.p2.1.m1.1.1.2.2" xref="Ch6.S2.SS2.p2.1.m1.1.1.2.2.cmml">p</mi><mi id="Ch6.S2.SS2.p2.1.m1.1.1.2.3" xref="Ch6.S2.SS2.p2.1.m1.1.1.2.3.cmml">u</mi></msub><mo id="Ch6.S2.SS2.p2.1.m1.1.1.1" xref="Ch6.S2.SS2.p2.1.m1.1.1.1.cmml">∈</mo><msup id="Ch6.S2.SS2.p2.1.m1.1.1.3" xref="Ch6.S2.SS2.p2.1.m1.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="Ch6.S2.SS2.p2.1.m1.1.1.3.2" xref="Ch6.S2.SS2.p2.1.m1.1.1.3.2.cmml">ℛ</mi><mi id="Ch6.S2.SS2.p2.1.m1.1.1.3.3" xref="Ch6.S2.SS2.p2.1.m1.1.1.3.3.cmml">k</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p2.1.m1.1b"><apply id="Ch6.S2.SS2.p2.1.m1.1.1.cmml" xref="Ch6.S2.SS2.p2.1.m1.1.1"><in id="Ch6.S2.SS2.p2.1.m1.1.1.1.cmml" xref="Ch6.S2.SS2.p2.1.m1.1.1.1"></in><apply id="Ch6.S2.SS2.p2.1.m1.1.1.2.cmml" xref="Ch6.S2.SS2.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="Ch6.S2.SS2.p2.1.m1.1.1.2.1.cmml" xref="Ch6.S2.SS2.p2.1.m1.1.1.2">subscript</csymbol><ci id="Ch6.S2.SS2.p2.1.m1.1.1.2.2.cmml" xref="Ch6.S2.SS2.p2.1.m1.1.1.2.2">𝑝</ci><ci id="Ch6.S2.SS2.p2.1.m1.1.1.2.3.cmml" xref="Ch6.S2.SS2.p2.1.m1.1.1.2.3">𝑢</ci></apply><apply id="Ch6.S2.SS2.p2.1.m1.1.1.3.cmml" xref="Ch6.S2.SS2.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="Ch6.S2.SS2.p2.1.m1.1.1.3.1.cmml" xref="Ch6.S2.SS2.p2.1.m1.1.1.3">superscript</csymbol><ci id="Ch6.S2.SS2.p2.1.m1.1.1.3.2.cmml" xref="Ch6.S2.SS2.p2.1.m1.1.1.3.2">ℛ</ci><ci id="Ch6.S2.SS2.p2.1.m1.1.1.3.3.cmml" xref="Ch6.S2.SS2.p2.1.m1.1.1.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p2.1.m1.1c">p_{u}\in\mathcal{R}^{k}</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p2.1.m1.1d">italic_p start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ∈ caligraphic_R start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT</annotation></semantics></math>, <math alttext="q_{i}\in\mathcal{R}^{k}" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p2.2.m2.1"><semantics id="Ch6.S2.SS2.p2.2.m2.1a"><mrow id="Ch6.S2.SS2.p2.2.m2.1.1" xref="Ch6.S2.SS2.p2.2.m2.1.1.cmml"><msub id="Ch6.S2.SS2.p2.2.m2.1.1.2" xref="Ch6.S2.SS2.p2.2.m2.1.1.2.cmml"><mi id="Ch6.S2.SS2.p2.2.m2.1.1.2.2" xref="Ch6.S2.SS2.p2.2.m2.1.1.2.2.cmml">q</mi><mi id="Ch6.S2.SS2.p2.2.m2.1.1.2.3" xref="Ch6.S2.SS2.p2.2.m2.1.1.2.3.cmml">i</mi></msub><mo id="Ch6.S2.SS2.p2.2.m2.1.1.1" xref="Ch6.S2.SS2.p2.2.m2.1.1.1.cmml">∈</mo><msup id="Ch6.S2.SS2.p2.2.m2.1.1.3" xref="Ch6.S2.SS2.p2.2.m2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="Ch6.S2.SS2.p2.2.m2.1.1.3.2" xref="Ch6.S2.SS2.p2.2.m2.1.1.3.2.cmml">ℛ</mi><mi id="Ch6.S2.SS2.p2.2.m2.1.1.3.3" xref="Ch6.S2.SS2.p2.2.m2.1.1.3.3.cmml">k</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p2.2.m2.1b"><apply id="Ch6.S2.SS2.p2.2.m2.1.1.cmml" xref="Ch6.S2.SS2.p2.2.m2.1.1"><in id="Ch6.S2.SS2.p2.2.m2.1.1.1.cmml" xref="Ch6.S2.SS2.p2.2.m2.1.1.1"></in><apply id="Ch6.S2.SS2.p2.2.m2.1.1.2.cmml" xref="Ch6.S2.SS2.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="Ch6.S2.SS2.p2.2.m2.1.1.2.1.cmml" xref="Ch6.S2.SS2.p2.2.m2.1.1.2">subscript</csymbol><ci id="Ch6.S2.SS2.p2.2.m2.1.1.2.2.cmml" xref="Ch6.S2.SS2.p2.2.m2.1.1.2.2">𝑞</ci><ci id="Ch6.S2.SS2.p2.2.m2.1.1.2.3.cmml" xref="Ch6.S2.SS2.p2.2.m2.1.1.2.3">𝑖</ci></apply><apply id="Ch6.S2.SS2.p2.2.m2.1.1.3.cmml" xref="Ch6.S2.SS2.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="Ch6.S2.SS2.p2.2.m2.1.1.3.1.cmml" xref="Ch6.S2.SS2.p2.2.m2.1.1.3">superscript</csymbol><ci id="Ch6.S2.SS2.p2.2.m2.1.1.3.2.cmml" xref="Ch6.S2.SS2.p2.2.m2.1.1.3.2">ℛ</ci><ci id="Ch6.S2.SS2.p2.2.m2.1.1.3.3.cmml" xref="Ch6.S2.SS2.p2.2.m2.1.1.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p2.2.m2.1c">q_{i}\in\mathcal{R}^{k}</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p2.2.m2.1d">italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ caligraphic_R start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT</annotation></semantics></math> denote the embedding vector of user <math alttext="u" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p2.3.m3.1"><semantics id="Ch6.S2.SS2.p2.3.m3.1a"><mi id="Ch6.S2.SS2.p2.3.m3.1.1" xref="Ch6.S2.SS2.p2.3.m3.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p2.3.m3.1b"><ci id="Ch6.S2.SS2.p2.3.m3.1.1.cmml" xref="Ch6.S2.SS2.p2.3.m3.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p2.3.m3.1c">u</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p2.3.m3.1d">italic_u</annotation></semantics></math> and item <math alttext="i" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p2.4.m4.1"><semantics id="Ch6.S2.SS2.p2.4.m4.1a"><mi id="Ch6.S2.SS2.p2.4.m4.1.1" xref="Ch6.S2.SS2.p2.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p2.4.m4.1b"><ci id="Ch6.S2.SS2.p2.4.m4.1.1.cmml" xref="Ch6.S2.SS2.p2.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p2.4.m4.1c">i</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p2.4.m4.1d">italic_i</annotation></semantics></math>, respectively.
MF makes a prediction for the user-item pair <math alttext="(u,i)" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p2.5.m5.2"><semantics id="Ch6.S2.SS2.p2.5.m5.2a"><mrow id="Ch6.S2.SS2.p2.5.m5.2.3.2" xref="Ch6.S2.SS2.p2.5.m5.2.3.1.cmml"><mo id="Ch6.S2.SS2.p2.5.m5.2.3.2.1" stretchy="false" xref="Ch6.S2.SS2.p2.5.m5.2.3.1.cmml">(</mo><mi id="Ch6.S2.SS2.p2.5.m5.1.1" xref="Ch6.S2.SS2.p2.5.m5.1.1.cmml">u</mi><mo id="Ch6.S2.SS2.p2.5.m5.2.3.2.2" xref="Ch6.S2.SS2.p2.5.m5.2.3.1.cmml">,</mo><mi id="Ch6.S2.SS2.p2.5.m5.2.2" xref="Ch6.S2.SS2.p2.5.m5.2.2.cmml">i</mi><mo id="Ch6.S2.SS2.p2.5.m5.2.3.2.3" stretchy="false" xref="Ch6.S2.SS2.p2.5.m5.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p2.5.m5.2b"><interval closure="open" id="Ch6.S2.SS2.p2.5.m5.2.3.1.cmml" xref="Ch6.S2.SS2.p2.5.m5.2.3.2"><ci id="Ch6.S2.SS2.p2.5.m5.1.1.cmml" xref="Ch6.S2.SS2.p2.5.m5.1.1">𝑢</ci><ci id="Ch6.S2.SS2.p2.5.m5.2.2.cmml" xref="Ch6.S2.SS2.p2.5.m5.2.2">𝑖</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p2.5.m5.2c">(u,i)</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p2.5.m5.2d">( italic_u , italic_i )</annotation></semantics></math> as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="Ch6.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\hat{r}_{ui}=p_{u}^{\top}q_{i}." class="ltx_Math" display="block" id="Ch6.E2.m1.1"><semantics id="Ch6.E2.m1.1a"><mrow id="Ch6.E2.m1.1.1.1" xref="Ch6.E2.m1.1.1.1.1.cmml"><mrow id="Ch6.E2.m1.1.1.1.1" xref="Ch6.E2.m1.1.1.1.1.cmml"><msub id="Ch6.E2.m1.1.1.1.1.2" xref="Ch6.E2.m1.1.1.1.1.2.cmml"><mover accent="true" id="Ch6.E2.m1.1.1.1.1.2.2" xref="Ch6.E2.m1.1.1.1.1.2.2.cmml"><mi id="Ch6.E2.m1.1.1.1.1.2.2.2" xref="Ch6.E2.m1.1.1.1.1.2.2.2.cmml">r</mi><mo id="Ch6.E2.m1.1.1.1.1.2.2.1" xref="Ch6.E2.m1.1.1.1.1.2.2.1.cmml">^</mo></mover><mrow id="Ch6.E2.m1.1.1.1.1.2.3" xref="Ch6.E2.m1.1.1.1.1.2.3.cmml"><mi id="Ch6.E2.m1.1.1.1.1.2.3.2" xref="Ch6.E2.m1.1.1.1.1.2.3.2.cmml">u</mi><mo id="Ch6.E2.m1.1.1.1.1.2.3.1" xref="Ch6.E2.m1.1.1.1.1.2.3.1.cmml">⁢</mo><mi id="Ch6.E2.m1.1.1.1.1.2.3.3" xref="Ch6.E2.m1.1.1.1.1.2.3.3.cmml">i</mi></mrow></msub><mo id="Ch6.E2.m1.1.1.1.1.1" xref="Ch6.E2.m1.1.1.1.1.1.cmml">=</mo><mrow id="Ch6.E2.m1.1.1.1.1.3" xref="Ch6.E2.m1.1.1.1.1.3.cmml"><msubsup id="Ch6.E2.m1.1.1.1.1.3.2" xref="Ch6.E2.m1.1.1.1.1.3.2.cmml"><mi id="Ch6.E2.m1.1.1.1.1.3.2.2.2" xref="Ch6.E2.m1.1.1.1.1.3.2.2.2.cmml">p</mi><mi id="Ch6.E2.m1.1.1.1.1.3.2.2.3" xref="Ch6.E2.m1.1.1.1.1.3.2.2.3.cmml">u</mi><mo id="Ch6.E2.m1.1.1.1.1.3.2.3" xref="Ch6.E2.m1.1.1.1.1.3.2.3.cmml">⊤</mo></msubsup><mo id="Ch6.E2.m1.1.1.1.1.3.1" xref="Ch6.E2.m1.1.1.1.1.3.1.cmml">⁢</mo><msub id="Ch6.E2.m1.1.1.1.1.3.3" xref="Ch6.E2.m1.1.1.1.1.3.3.cmml"><mi id="Ch6.E2.m1.1.1.1.1.3.3.2" xref="Ch6.E2.m1.1.1.1.1.3.3.2.cmml">q</mi><mi id="Ch6.E2.m1.1.1.1.1.3.3.3" xref="Ch6.E2.m1.1.1.1.1.3.3.3.cmml">i</mi></msub></mrow></mrow><mo id="Ch6.E2.m1.1.1.1.2" lspace="0em" xref="Ch6.E2.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch6.E2.m1.1b"><apply id="Ch6.E2.m1.1.1.1.1.cmml" xref="Ch6.E2.m1.1.1.1"><eq id="Ch6.E2.m1.1.1.1.1.1.cmml" xref="Ch6.E2.m1.1.1.1.1.1"></eq><apply id="Ch6.E2.m1.1.1.1.1.2.cmml" xref="Ch6.E2.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="Ch6.E2.m1.1.1.1.1.2.1.cmml" xref="Ch6.E2.m1.1.1.1.1.2">subscript</csymbol><apply id="Ch6.E2.m1.1.1.1.1.2.2.cmml" xref="Ch6.E2.m1.1.1.1.1.2.2"><ci id="Ch6.E2.m1.1.1.1.1.2.2.1.cmml" xref="Ch6.E2.m1.1.1.1.1.2.2.1">^</ci><ci id="Ch6.E2.m1.1.1.1.1.2.2.2.cmml" xref="Ch6.E2.m1.1.1.1.1.2.2.2">𝑟</ci></apply><apply id="Ch6.E2.m1.1.1.1.1.2.3.cmml" xref="Ch6.E2.m1.1.1.1.1.2.3"><times id="Ch6.E2.m1.1.1.1.1.2.3.1.cmml" xref="Ch6.E2.m1.1.1.1.1.2.3.1"></times><ci id="Ch6.E2.m1.1.1.1.1.2.3.2.cmml" xref="Ch6.E2.m1.1.1.1.1.2.3.2">𝑢</ci><ci id="Ch6.E2.m1.1.1.1.1.2.3.3.cmml" xref="Ch6.E2.m1.1.1.1.1.2.3.3">𝑖</ci></apply></apply><apply id="Ch6.E2.m1.1.1.1.1.3.cmml" xref="Ch6.E2.m1.1.1.1.1.3"><times id="Ch6.E2.m1.1.1.1.1.3.1.cmml" xref="Ch6.E2.m1.1.1.1.1.3.1"></times><apply id="Ch6.E2.m1.1.1.1.1.3.2.cmml" xref="Ch6.E2.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="Ch6.E2.m1.1.1.1.1.3.2.1.cmml" xref="Ch6.E2.m1.1.1.1.1.3.2">superscript</csymbol><apply id="Ch6.E2.m1.1.1.1.1.3.2.2.cmml" xref="Ch6.E2.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="Ch6.E2.m1.1.1.1.1.3.2.2.1.cmml" xref="Ch6.E2.m1.1.1.1.1.3.2">subscript</csymbol><ci id="Ch6.E2.m1.1.1.1.1.3.2.2.2.cmml" xref="Ch6.E2.m1.1.1.1.1.3.2.2.2">𝑝</ci><ci id="Ch6.E2.m1.1.1.1.1.3.2.2.3.cmml" xref="Ch6.E2.m1.1.1.1.1.3.2.2.3">𝑢</ci></apply><csymbol cd="latexml" id="Ch6.E2.m1.1.1.1.1.3.2.3.cmml" xref="Ch6.E2.m1.1.1.1.1.3.2.3">top</csymbol></apply><apply id="Ch6.E2.m1.1.1.1.1.3.3.cmml" xref="Ch6.E2.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="Ch6.E2.m1.1.1.1.1.3.3.1.cmml" xref="Ch6.E2.m1.1.1.1.1.3.3">subscript</csymbol><ci id="Ch6.E2.m1.1.1.1.1.3.3.2.cmml" xref="Ch6.E2.m1.1.1.1.1.3.3.2">𝑞</ci><ci id="Ch6.E2.m1.1.1.1.1.3.3.3.cmml" xref="Ch6.E2.m1.1.1.1.1.3.3.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.E2.m1.1c">\hat{r}_{ui}=p_{u}^{\top}q_{i}.</annotation><annotation encoding="application/x-llamapun" id="Ch6.E2.m1.1d">over^ start_ARG italic_r end_ARG start_POSTSUBSCRIPT italic_u italic_i end_POSTSUBSCRIPT = italic_p start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6.2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch6.S2.SS2.p2.13">MF can be optimized by minimizing the deviation between the predictions and the user-item interactions.
Formally, we have the following objective function:</p>
<table class="ltx_equation ltx_eqn_table" id="Ch6.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="{\min_{P,Q}}\sum\limits_{(u,i)}l({r_{ui}},{\hat{r}_{ui}})+\lambda{L_{reg}}(P,Q)," class="ltx_Math" display="block" id="Ch6.E3.m1.7"><semantics id="Ch6.E3.m1.7a"><mrow id="Ch6.E3.m1.7.7.1" xref="Ch6.E3.m1.7.7.1.1.cmml"><mrow id="Ch6.E3.m1.7.7.1.1" xref="Ch6.E3.m1.7.7.1.1.cmml"><mrow id="Ch6.E3.m1.7.7.1.1.2" xref="Ch6.E3.m1.7.7.1.1.2.cmml"><munder id="Ch6.E3.m1.7.7.1.1.2.4" xref="Ch6.E3.m1.7.7.1.1.2.4.cmml"><mi id="Ch6.E3.m1.7.7.1.1.2.4.2" xref="Ch6.E3.m1.7.7.1.1.2.4.2.cmml">min</mi><mrow id="Ch6.E3.m1.2.2.2.4" xref="Ch6.E3.m1.2.2.2.3.cmml"><mi id="Ch6.E3.m1.1.1.1.1" xref="Ch6.E3.m1.1.1.1.1.cmml">P</mi><mo id="Ch6.E3.m1.2.2.2.4.1" xref="Ch6.E3.m1.2.2.2.3.cmml">,</mo><mi id="Ch6.E3.m1.2.2.2.2" xref="Ch6.E3.m1.2.2.2.2.cmml">Q</mi></mrow></munder><mo id="Ch6.E3.m1.7.7.1.1.2.3" xref="Ch6.E3.m1.7.7.1.1.2.3.cmml">⁢</mo><mrow id="Ch6.E3.m1.7.7.1.1.2.2" xref="Ch6.E3.m1.7.7.1.1.2.2.cmml"><munder id="Ch6.E3.m1.7.7.1.1.2.2.3" xref="Ch6.E3.m1.7.7.1.1.2.2.3.cmml"><mo id="Ch6.E3.m1.7.7.1.1.2.2.3.2" movablelimits="false" xref="Ch6.E3.m1.7.7.1.1.2.2.3.2.cmml">∑</mo><mrow id="Ch6.E3.m1.4.4.2.4" xref="Ch6.E3.m1.4.4.2.3.cmml"><mo id="Ch6.E3.m1.4.4.2.4.1" stretchy="false" xref="Ch6.E3.m1.4.4.2.3.cmml">(</mo><mi id="Ch6.E3.m1.3.3.1.1" xref="Ch6.E3.m1.3.3.1.1.cmml">u</mi><mo id="Ch6.E3.m1.4.4.2.4.2" xref="Ch6.E3.m1.4.4.2.3.cmml">,</mo><mi id="Ch6.E3.m1.4.4.2.2" xref="Ch6.E3.m1.4.4.2.2.cmml">i</mi><mo id="Ch6.E3.m1.4.4.2.4.3" stretchy="false" xref="Ch6.E3.m1.4.4.2.3.cmml">)</mo></mrow></munder><mrow id="Ch6.E3.m1.7.7.1.1.2.2.2" xref="Ch6.E3.m1.7.7.1.1.2.2.2.cmml"><mi id="Ch6.E3.m1.7.7.1.1.2.2.2.4" xref="Ch6.E3.m1.7.7.1.1.2.2.2.4.cmml">l</mi><mo id="Ch6.E3.m1.7.7.1.1.2.2.2.3" xref="Ch6.E3.m1.7.7.1.1.2.2.2.3.cmml">⁢</mo><mrow id="Ch6.E3.m1.7.7.1.1.2.2.2.2.2" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.3.cmml"><mo id="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.3" stretchy="false" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.3.cmml">(</mo><msub id="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1" xref="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.cmml"><mi id="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.2" xref="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.2.cmml">r</mi><mrow id="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.3" xref="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.3.cmml"><mi id="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.3.2" xref="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.3.2.cmml">u</mi><mo id="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.3.1" xref="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.3.3" xref="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.3.3.cmml">i</mi></mrow></msub><mo id="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.4" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.3.cmml">,</mo><msub id="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.cmml"><mover accent="true" id="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.2" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.2.cmml"><mi id="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.2.2" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.2.2.cmml">r</mi><mo id="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.2.1" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.2.1.cmml">^</mo></mover><mrow id="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.3" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.3.cmml"><mi id="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.3.2" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.3.2.cmml">u</mi><mo id="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.3.1" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.3.1.cmml">⁢</mo><mi id="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.3.3" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.3.3.cmml">i</mi></mrow></msub><mo id="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.5" stretchy="false" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="Ch6.E3.m1.7.7.1.1.3" xref="Ch6.E3.m1.7.7.1.1.3.cmml">+</mo><mrow id="Ch6.E3.m1.7.7.1.1.4" xref="Ch6.E3.m1.7.7.1.1.4.cmml"><mi id="Ch6.E3.m1.7.7.1.1.4.2" xref="Ch6.E3.m1.7.7.1.1.4.2.cmml">λ</mi><mo id="Ch6.E3.m1.7.7.1.1.4.1" xref="Ch6.E3.m1.7.7.1.1.4.1.cmml">⁢</mo><msub id="Ch6.E3.m1.7.7.1.1.4.3" xref="Ch6.E3.m1.7.7.1.1.4.3.cmml"><mi id="Ch6.E3.m1.7.7.1.1.4.3.2" xref="Ch6.E3.m1.7.7.1.1.4.3.2.cmml">L</mi><mrow id="Ch6.E3.m1.7.7.1.1.4.3.3" xref="Ch6.E3.m1.7.7.1.1.4.3.3.cmml"><mi id="Ch6.E3.m1.7.7.1.1.4.3.3.2" xref="Ch6.E3.m1.7.7.1.1.4.3.3.2.cmml">r</mi><mo id="Ch6.E3.m1.7.7.1.1.4.3.3.1" xref="Ch6.E3.m1.7.7.1.1.4.3.3.1.cmml">⁢</mo><mi id="Ch6.E3.m1.7.7.1.1.4.3.3.3" xref="Ch6.E3.m1.7.7.1.1.4.3.3.3.cmml">e</mi><mo id="Ch6.E3.m1.7.7.1.1.4.3.3.1a" xref="Ch6.E3.m1.7.7.1.1.4.3.3.1.cmml">⁢</mo><mi id="Ch6.E3.m1.7.7.1.1.4.3.3.4" xref="Ch6.E3.m1.7.7.1.1.4.3.3.4.cmml">g</mi></mrow></msub><mo id="Ch6.E3.m1.7.7.1.1.4.1a" xref="Ch6.E3.m1.7.7.1.1.4.1.cmml">⁢</mo><mrow id="Ch6.E3.m1.7.7.1.1.4.4.2" xref="Ch6.E3.m1.7.7.1.1.4.4.1.cmml"><mo id="Ch6.E3.m1.7.7.1.1.4.4.2.1" stretchy="false" xref="Ch6.E3.m1.7.7.1.1.4.4.1.cmml">(</mo><mi id="Ch6.E3.m1.5.5" xref="Ch6.E3.m1.5.5.cmml">P</mi><mo id="Ch6.E3.m1.7.7.1.1.4.4.2.2" xref="Ch6.E3.m1.7.7.1.1.4.4.1.cmml">,</mo><mi id="Ch6.E3.m1.6.6" xref="Ch6.E3.m1.6.6.cmml">Q</mi><mo id="Ch6.E3.m1.7.7.1.1.4.4.2.3" stretchy="false" xref="Ch6.E3.m1.7.7.1.1.4.4.1.cmml">)</mo></mrow></mrow></mrow><mo id="Ch6.E3.m1.7.7.1.2" xref="Ch6.E3.m1.7.7.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch6.E3.m1.7b"><apply id="Ch6.E3.m1.7.7.1.1.cmml" xref="Ch6.E3.m1.7.7.1"><plus id="Ch6.E3.m1.7.7.1.1.3.cmml" xref="Ch6.E3.m1.7.7.1.1.3"></plus><apply id="Ch6.E3.m1.7.7.1.1.2.cmml" xref="Ch6.E3.m1.7.7.1.1.2"><times id="Ch6.E3.m1.7.7.1.1.2.3.cmml" xref="Ch6.E3.m1.7.7.1.1.2.3"></times><apply id="Ch6.E3.m1.7.7.1.1.2.4.cmml" xref="Ch6.E3.m1.7.7.1.1.2.4"><csymbol cd="ambiguous" id="Ch6.E3.m1.7.7.1.1.2.4.1.cmml" xref="Ch6.E3.m1.7.7.1.1.2.4">subscript</csymbol><min id="Ch6.E3.m1.7.7.1.1.2.4.2.cmml" xref="Ch6.E3.m1.7.7.1.1.2.4.2"></min><list id="Ch6.E3.m1.2.2.2.3.cmml" xref="Ch6.E3.m1.2.2.2.4"><ci id="Ch6.E3.m1.1.1.1.1.cmml" xref="Ch6.E3.m1.1.1.1.1">𝑃</ci><ci id="Ch6.E3.m1.2.2.2.2.cmml" xref="Ch6.E3.m1.2.2.2.2">𝑄</ci></list></apply><apply id="Ch6.E3.m1.7.7.1.1.2.2.cmml" xref="Ch6.E3.m1.7.7.1.1.2.2"><apply id="Ch6.E3.m1.7.7.1.1.2.2.3.cmml" xref="Ch6.E3.m1.7.7.1.1.2.2.3"><csymbol cd="ambiguous" id="Ch6.E3.m1.7.7.1.1.2.2.3.1.cmml" xref="Ch6.E3.m1.7.7.1.1.2.2.3">subscript</csymbol><sum id="Ch6.E3.m1.7.7.1.1.2.2.3.2.cmml" xref="Ch6.E3.m1.7.7.1.1.2.2.3.2"></sum><interval closure="open" id="Ch6.E3.m1.4.4.2.3.cmml" xref="Ch6.E3.m1.4.4.2.4"><ci id="Ch6.E3.m1.3.3.1.1.cmml" xref="Ch6.E3.m1.3.3.1.1">𝑢</ci><ci id="Ch6.E3.m1.4.4.2.2.cmml" xref="Ch6.E3.m1.4.4.2.2">𝑖</ci></interval></apply><apply id="Ch6.E3.m1.7.7.1.1.2.2.2.cmml" xref="Ch6.E3.m1.7.7.1.1.2.2.2"><times id="Ch6.E3.m1.7.7.1.1.2.2.2.3.cmml" xref="Ch6.E3.m1.7.7.1.1.2.2.2.3"></times><ci id="Ch6.E3.m1.7.7.1.1.2.2.2.4.cmml" xref="Ch6.E3.m1.7.7.1.1.2.2.2.4">𝑙</ci><interval closure="open" id="Ch6.E3.m1.7.7.1.1.2.2.2.2.3.cmml" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.2"><apply id="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.cmml" xref="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.1.cmml" xref="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.2.cmml" xref="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.2">𝑟</ci><apply id="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.3.cmml" xref="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.3"><times id="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.3.1.cmml" xref="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.3.1"></times><ci id="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.3.2.cmml" xref="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.3.2">𝑢</ci><ci id="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.3.3.cmml" xref="Ch6.E3.m1.7.7.1.1.1.1.1.1.1.1.3.3">𝑖</ci></apply></apply><apply id="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.cmml" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.1.cmml" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2">subscript</csymbol><apply id="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.2.cmml" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.2"><ci id="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.2.1.cmml" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.2.1">^</ci><ci id="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.2.2.cmml" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.2.2">𝑟</ci></apply><apply id="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.3.cmml" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.3"><times id="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.3.1.cmml" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.3.1"></times><ci id="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.3.2.cmml" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.3.2">𝑢</ci><ci id="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.3.3.cmml" xref="Ch6.E3.m1.7.7.1.1.2.2.2.2.2.2.3.3">𝑖</ci></apply></apply></interval></apply></apply></apply><apply id="Ch6.E3.m1.7.7.1.1.4.cmml" xref="Ch6.E3.m1.7.7.1.1.4"><times id="Ch6.E3.m1.7.7.1.1.4.1.cmml" xref="Ch6.E3.m1.7.7.1.1.4.1"></times><ci id="Ch6.E3.m1.7.7.1.1.4.2.cmml" xref="Ch6.E3.m1.7.7.1.1.4.2">𝜆</ci><apply id="Ch6.E3.m1.7.7.1.1.4.3.cmml" xref="Ch6.E3.m1.7.7.1.1.4.3"><csymbol cd="ambiguous" id="Ch6.E3.m1.7.7.1.1.4.3.1.cmml" xref="Ch6.E3.m1.7.7.1.1.4.3">subscript</csymbol><ci id="Ch6.E3.m1.7.7.1.1.4.3.2.cmml" xref="Ch6.E3.m1.7.7.1.1.4.3.2">𝐿</ci><apply id="Ch6.E3.m1.7.7.1.1.4.3.3.cmml" xref="Ch6.E3.m1.7.7.1.1.4.3.3"><times id="Ch6.E3.m1.7.7.1.1.4.3.3.1.cmml" xref="Ch6.E3.m1.7.7.1.1.4.3.3.1"></times><ci id="Ch6.E3.m1.7.7.1.1.4.3.3.2.cmml" xref="Ch6.E3.m1.7.7.1.1.4.3.3.2">𝑟</ci><ci id="Ch6.E3.m1.7.7.1.1.4.3.3.3.cmml" xref="Ch6.E3.m1.7.7.1.1.4.3.3.3">𝑒</ci><ci id="Ch6.E3.m1.7.7.1.1.4.3.3.4.cmml" xref="Ch6.E3.m1.7.7.1.1.4.3.3.4">𝑔</ci></apply></apply><interval closure="open" id="Ch6.E3.m1.7.7.1.1.4.4.1.cmml" xref="Ch6.E3.m1.7.7.1.1.4.4.2"><ci id="Ch6.E3.m1.5.5.cmml" xref="Ch6.E3.m1.5.5">𝑃</ci><ci id="Ch6.E3.m1.6.6.cmml" xref="Ch6.E3.m1.6.6">𝑄</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.E3.m1.7c">{\min_{P,Q}}\sum\limits_{(u,i)}l({r_{ui}},{\hat{r}_{ui}})+\lambda{L_{reg}}(P,Q),</annotation><annotation encoding="application/x-llamapun" id="Ch6.E3.m1.7d">roman_min start_POSTSUBSCRIPT italic_P , italic_Q end_POSTSUBSCRIPT ∑ start_POSTSUBSCRIPT ( italic_u , italic_i ) end_POSTSUBSCRIPT italic_l ( italic_r start_POSTSUBSCRIPT italic_u italic_i end_POSTSUBSCRIPT , over^ start_ARG italic_r end_ARG start_POSTSUBSCRIPT italic_u italic_i end_POSTSUBSCRIPT ) + italic_λ italic_L start_POSTSUBSCRIPT italic_r italic_e italic_g end_POSTSUBSCRIPT ( italic_P , italic_Q ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6.3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch6.S2.SS2.p2.12">where <math alttext="r_{u,i}" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p2.6.m1.2"><semantics id="Ch6.S2.SS2.p2.6.m1.2a"><msub id="Ch6.S2.SS2.p2.6.m1.2.3" xref="Ch6.S2.SS2.p2.6.m1.2.3.cmml"><mi id="Ch6.S2.SS2.p2.6.m1.2.3.2" xref="Ch6.S2.SS2.p2.6.m1.2.3.2.cmml">r</mi><mrow id="Ch6.S2.SS2.p2.6.m1.2.2.2.4" xref="Ch6.S2.SS2.p2.6.m1.2.2.2.3.cmml"><mi id="Ch6.S2.SS2.p2.6.m1.1.1.1.1" xref="Ch6.S2.SS2.p2.6.m1.1.1.1.1.cmml">u</mi><mo id="Ch6.S2.SS2.p2.6.m1.2.2.2.4.1" xref="Ch6.S2.SS2.p2.6.m1.2.2.2.3.cmml">,</mo><mi id="Ch6.S2.SS2.p2.6.m1.2.2.2.2" xref="Ch6.S2.SS2.p2.6.m1.2.2.2.2.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p2.6.m1.2b"><apply id="Ch6.S2.SS2.p2.6.m1.2.3.cmml" xref="Ch6.S2.SS2.p2.6.m1.2.3"><csymbol cd="ambiguous" id="Ch6.S2.SS2.p2.6.m1.2.3.1.cmml" xref="Ch6.S2.SS2.p2.6.m1.2.3">subscript</csymbol><ci id="Ch6.S2.SS2.p2.6.m1.2.3.2.cmml" xref="Ch6.S2.SS2.p2.6.m1.2.3.2">𝑟</ci><list id="Ch6.S2.SS2.p2.6.m1.2.2.2.3.cmml" xref="Ch6.S2.SS2.p2.6.m1.2.2.2.4"><ci id="Ch6.S2.SS2.p2.6.m1.1.1.1.1.cmml" xref="Ch6.S2.SS2.p2.6.m1.1.1.1.1">𝑢</ci><ci id="Ch6.S2.SS2.p2.6.m1.2.2.2.2.cmml" xref="Ch6.S2.SS2.p2.6.m1.2.2.2.2">𝑖</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p2.6.m1.2c">r_{u,i}</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p2.6.m1.2d">italic_r start_POSTSUBSCRIPT italic_u , italic_i end_POSTSUBSCRIPT</annotation></semantics></math> denotes a user-item interaction.
This can be explicit feedback (e.g., user ratings), which directly reflects the user preference, or implicit feedback (e.g., purchases and clicks), which indicates whether the user interacts with the item.
<math alttext="l(\cdot,\cdot)" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p2.7.m2.2"><semantics id="Ch6.S2.SS2.p2.7.m2.2a"><mrow id="Ch6.S2.SS2.p2.7.m2.2.3" xref="Ch6.S2.SS2.p2.7.m2.2.3.cmml"><mi id="Ch6.S2.SS2.p2.7.m2.2.3.2" xref="Ch6.S2.SS2.p2.7.m2.2.3.2.cmml">l</mi><mo id="Ch6.S2.SS2.p2.7.m2.2.3.1" xref="Ch6.S2.SS2.p2.7.m2.2.3.1.cmml">⁢</mo><mrow id="Ch6.S2.SS2.p2.7.m2.2.3.3.2" xref="Ch6.S2.SS2.p2.7.m2.2.3.3.1.cmml"><mo id="Ch6.S2.SS2.p2.7.m2.2.3.3.2.1" stretchy="false" xref="Ch6.S2.SS2.p2.7.m2.2.3.3.1.cmml">(</mo><mo id="Ch6.S2.SS2.p2.7.m2.1.1" lspace="0em" rspace="0em" xref="Ch6.S2.SS2.p2.7.m2.1.1.cmml">⋅</mo><mo id="Ch6.S2.SS2.p2.7.m2.2.3.3.2.2" rspace="0em" xref="Ch6.S2.SS2.p2.7.m2.2.3.3.1.cmml">,</mo><mo id="Ch6.S2.SS2.p2.7.m2.2.2" lspace="0em" rspace="0em" xref="Ch6.S2.SS2.p2.7.m2.2.2.cmml">⋅</mo><mo id="Ch6.S2.SS2.p2.7.m2.2.3.3.2.3" stretchy="false" xref="Ch6.S2.SS2.p2.7.m2.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p2.7.m2.2b"><apply id="Ch6.S2.SS2.p2.7.m2.2.3.cmml" xref="Ch6.S2.SS2.p2.7.m2.2.3"><times id="Ch6.S2.SS2.p2.7.m2.2.3.1.cmml" xref="Ch6.S2.SS2.p2.7.m2.2.3.1"></times><ci id="Ch6.S2.SS2.p2.7.m2.2.3.2.cmml" xref="Ch6.S2.SS2.p2.7.m2.2.3.2">𝑙</ci><interval closure="open" id="Ch6.S2.SS2.p2.7.m2.2.3.3.1.cmml" xref="Ch6.S2.SS2.p2.7.m2.2.3.3.2"><ci id="Ch6.S2.SS2.p2.7.m2.1.1.cmml" xref="Ch6.S2.SS2.p2.7.m2.1.1">⋅</ci><ci id="Ch6.S2.SS2.p2.7.m2.2.2.cmml" xref="Ch6.S2.SS2.p2.7.m2.2.2">⋅</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p2.7.m2.2c">l(\cdot,\cdot)</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p2.7.m2.2d">italic_l ( ⋅ , ⋅ )</annotation></semantics></math> denotes the selected error function between the prediction and the ground truth label.
It can be selected from mean squared error (MSE) loss <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Koren2009Matrix</span>]</cite>, binary cross-entropy loss <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">He2017NCF</span>]</cite>, hinge loss <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2016collaborative</span>]</cite>, and Poisson likelihood <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">PoissionMF</span>]</cite>. <math alttext="L_{reg}(\cdot,\cdot)" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p2.8.m3.2"><semantics id="Ch6.S2.SS2.p2.8.m3.2a"><mrow id="Ch6.S2.SS2.p2.8.m3.2.3" xref="Ch6.S2.SS2.p2.8.m3.2.3.cmml"><msub id="Ch6.S2.SS2.p2.8.m3.2.3.2" xref="Ch6.S2.SS2.p2.8.m3.2.3.2.cmml"><mi id="Ch6.S2.SS2.p2.8.m3.2.3.2.2" xref="Ch6.S2.SS2.p2.8.m3.2.3.2.2.cmml">L</mi><mrow id="Ch6.S2.SS2.p2.8.m3.2.3.2.3" xref="Ch6.S2.SS2.p2.8.m3.2.3.2.3.cmml"><mi id="Ch6.S2.SS2.p2.8.m3.2.3.2.3.2" xref="Ch6.S2.SS2.p2.8.m3.2.3.2.3.2.cmml">r</mi><mo id="Ch6.S2.SS2.p2.8.m3.2.3.2.3.1" xref="Ch6.S2.SS2.p2.8.m3.2.3.2.3.1.cmml">⁢</mo><mi id="Ch6.S2.SS2.p2.8.m3.2.3.2.3.3" xref="Ch6.S2.SS2.p2.8.m3.2.3.2.3.3.cmml">e</mi><mo id="Ch6.S2.SS2.p2.8.m3.2.3.2.3.1a" xref="Ch6.S2.SS2.p2.8.m3.2.3.2.3.1.cmml">⁢</mo><mi id="Ch6.S2.SS2.p2.8.m3.2.3.2.3.4" xref="Ch6.S2.SS2.p2.8.m3.2.3.2.3.4.cmml">g</mi></mrow></msub><mo id="Ch6.S2.SS2.p2.8.m3.2.3.1" xref="Ch6.S2.SS2.p2.8.m3.2.3.1.cmml">⁢</mo><mrow id="Ch6.S2.SS2.p2.8.m3.2.3.3.2" xref="Ch6.S2.SS2.p2.8.m3.2.3.3.1.cmml"><mo id="Ch6.S2.SS2.p2.8.m3.2.3.3.2.1" stretchy="false" xref="Ch6.S2.SS2.p2.8.m3.2.3.3.1.cmml">(</mo><mo id="Ch6.S2.SS2.p2.8.m3.1.1" lspace="0em" rspace="0em" xref="Ch6.S2.SS2.p2.8.m3.1.1.cmml">⋅</mo><mo id="Ch6.S2.SS2.p2.8.m3.2.3.3.2.2" rspace="0em" xref="Ch6.S2.SS2.p2.8.m3.2.3.3.1.cmml">,</mo><mo id="Ch6.S2.SS2.p2.8.m3.2.2" lspace="0em" rspace="0em" xref="Ch6.S2.SS2.p2.8.m3.2.2.cmml">⋅</mo><mo id="Ch6.S2.SS2.p2.8.m3.2.3.3.2.3" stretchy="false" xref="Ch6.S2.SS2.p2.8.m3.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p2.8.m3.2b"><apply id="Ch6.S2.SS2.p2.8.m3.2.3.cmml" xref="Ch6.S2.SS2.p2.8.m3.2.3"><times id="Ch6.S2.SS2.p2.8.m3.2.3.1.cmml" xref="Ch6.S2.SS2.p2.8.m3.2.3.1"></times><apply id="Ch6.S2.SS2.p2.8.m3.2.3.2.cmml" xref="Ch6.S2.SS2.p2.8.m3.2.3.2"><csymbol cd="ambiguous" id="Ch6.S2.SS2.p2.8.m3.2.3.2.1.cmml" xref="Ch6.S2.SS2.p2.8.m3.2.3.2">subscript</csymbol><ci id="Ch6.S2.SS2.p2.8.m3.2.3.2.2.cmml" xref="Ch6.S2.SS2.p2.8.m3.2.3.2.2">𝐿</ci><apply id="Ch6.S2.SS2.p2.8.m3.2.3.2.3.cmml" xref="Ch6.S2.SS2.p2.8.m3.2.3.2.3"><times id="Ch6.S2.SS2.p2.8.m3.2.3.2.3.1.cmml" xref="Ch6.S2.SS2.p2.8.m3.2.3.2.3.1"></times><ci id="Ch6.S2.SS2.p2.8.m3.2.3.2.3.2.cmml" xref="Ch6.S2.SS2.p2.8.m3.2.3.2.3.2">𝑟</ci><ci id="Ch6.S2.SS2.p2.8.m3.2.3.2.3.3.cmml" xref="Ch6.S2.SS2.p2.8.m3.2.3.2.3.3">𝑒</ci><ci id="Ch6.S2.SS2.p2.8.m3.2.3.2.3.4.cmml" xref="Ch6.S2.SS2.p2.8.m3.2.3.2.3.4">𝑔</ci></apply></apply><interval closure="open" id="Ch6.S2.SS2.p2.8.m3.2.3.3.1.cmml" xref="Ch6.S2.SS2.p2.8.m3.2.3.3.2"><ci id="Ch6.S2.SS2.p2.8.m3.1.1.cmml" xref="Ch6.S2.SS2.p2.8.m3.1.1">⋅</ci><ci id="Ch6.S2.SS2.p2.8.m3.2.2.cmml" xref="Ch6.S2.SS2.p2.8.m3.2.2">⋅</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p2.8.m3.2c">L_{reg}(\cdot,\cdot)</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p2.8.m3.2d">italic_L start_POSTSUBSCRIPT italic_r italic_e italic_g end_POSTSUBSCRIPT ( ⋅ , ⋅ )</annotation></semantics></math> denotes a regularizer for the embeddings to avoid over-fitting.
Here we collect <math alttext="p_{u}" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p2.9.m4.1"><semantics id="Ch6.S2.SS2.p2.9.m4.1a"><msub id="Ch6.S2.SS2.p2.9.m4.1.1" xref="Ch6.S2.SS2.p2.9.m4.1.1.cmml"><mi id="Ch6.S2.SS2.p2.9.m4.1.1.2" xref="Ch6.S2.SS2.p2.9.m4.1.1.2.cmml">p</mi><mi id="Ch6.S2.SS2.p2.9.m4.1.1.3" xref="Ch6.S2.SS2.p2.9.m4.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p2.9.m4.1b"><apply id="Ch6.S2.SS2.p2.9.m4.1.1.cmml" xref="Ch6.S2.SS2.p2.9.m4.1.1"><csymbol cd="ambiguous" id="Ch6.S2.SS2.p2.9.m4.1.1.1.cmml" xref="Ch6.S2.SS2.p2.9.m4.1.1">subscript</csymbol><ci id="Ch6.S2.SS2.p2.9.m4.1.1.2.cmml" xref="Ch6.S2.SS2.p2.9.m4.1.1.2">𝑝</ci><ci id="Ch6.S2.SS2.p2.9.m4.1.1.3.cmml" xref="Ch6.S2.SS2.p2.9.m4.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p2.9.m4.1c">p_{u}</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p2.9.m4.1d">italic_p start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math> (and <math alttext="q_{i}" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p2.10.m5.1"><semantics id="Ch6.S2.SS2.p2.10.m5.1a"><msub id="Ch6.S2.SS2.p2.10.m5.1.1" xref="Ch6.S2.SS2.p2.10.m5.1.1.cmml"><mi id="Ch6.S2.SS2.p2.10.m5.1.1.2" xref="Ch6.S2.SS2.p2.10.m5.1.1.2.cmml">q</mi><mi id="Ch6.S2.SS2.p2.10.m5.1.1.3" xref="Ch6.S2.SS2.p2.10.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p2.10.m5.1b"><apply id="Ch6.S2.SS2.p2.10.m5.1.1.cmml" xref="Ch6.S2.SS2.p2.10.m5.1.1"><csymbol cd="ambiguous" id="Ch6.S2.SS2.p2.10.m5.1.1.1.cmml" xref="Ch6.S2.SS2.p2.10.m5.1.1">subscript</csymbol><ci id="Ch6.S2.SS2.p2.10.m5.1.1.2.cmml" xref="Ch6.S2.SS2.p2.10.m5.1.1.2">𝑞</ci><ci id="Ch6.S2.SS2.p2.10.m5.1.1.3.cmml" xref="Ch6.S2.SS2.p2.10.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p2.10.m5.1c">q_{i}</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p2.10.m5.1d">italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>) for each user (and item) as a matrix <math alttext="P" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p2.11.m6.1"><semantics id="Ch6.S2.SS2.p2.11.m6.1a"><mi id="Ch6.S2.SS2.p2.11.m6.1.1" xref="Ch6.S2.SS2.p2.11.m6.1.1.cmml">P</mi><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p2.11.m6.1b"><ci id="Ch6.S2.SS2.p2.11.m6.1.1.cmml" xref="Ch6.S2.SS2.p2.11.m6.1.1">𝑃</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p2.11.m6.1c">P</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p2.11.m6.1d">italic_P</annotation></semantics></math> (and <math alttext="Q" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p2.12.m7.1"><semantics id="Ch6.S2.SS2.p2.12.m7.1a"><mi id="Ch6.S2.SS2.p2.12.m7.1.1" xref="Ch6.S2.SS2.p2.12.m7.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p2.12.m7.1b"><ci id="Ch6.S2.SS2.p2.12.m7.1.1.cmml" xref="Ch6.S2.SS2.p2.12.m7.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p2.12.m7.1c">Q</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p2.12.m7.1d">italic_Q</annotation></semantics></math>).</p>
</div>
<div class="ltx_para" id="Ch6.S2.SS2.p3">
<p class="ltx_p" id="Ch6.S2.SS2.p3.1">Compared with heuristic-based methods, MF is a more generic method that can adaptively learn user preferences from their history behaviors and require no manually crafted heuristic design.
The use of MF has brought a revolution, drawing research attention from previous heuristic-based methods towards recent embedding-based methods.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch6.S2.SS2.p4">
<p class="ltx_p" id="Ch6.S2.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="Ch6.S2.SS2.p4.1.1">Information-enhanced embedding models.</span>
Despite the prevalence of MF, it is still insufficient to yield accurate embeddings. The reason is that MF directly projects user/item IDs to an embedding space, making MF reliant on the behavioral signal from the objective function.
Hence, MF models do not perform well for inactive users or items with very few interactions.
To deal with this problem, several methods have been proposed to enrich the representation with supplementary information.
We can divide them into three groups:


<span class="ltx_inline-enumerate" id="Ch6.S2.I3">
<span class="ltx_inline-item" id="Ch6.S2.I3.i1"><span class="ltx_tag ltx_tag_inline-item">(1)</span> <span class="ltx_text" id="Ch6.S2.I3.i1.1">neighborhood-enriched embedding methods
</span></span>
<span class="ltx_inline-item" id="Ch6.S2.I3.i2"><span class="ltx_tag ltx_tag_inline-item">(2)</span> <span class="ltx_text" id="Ch6.S2.I3.i2.1">feature-enriched embedding methods
and
</span></span>
<span class="ltx_inline-item" id="Ch6.S2.I3.i3"><span class="ltx_tag ltx_tag_inline-item">(3)</span> <span class="ltx_text" id="Ch6.S2.I3.i3.1">graph-enriched embedding methods.
</span></span>
</span>
We discuss each of these groups in detail as follows:</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch6.S2.SS2.p5">
<p class="ltx_p" id="Ch6.S2.SS2.p5.5"><span class="ltx_text ltx_font_bold" id="Ch6.S2.SS2.p5.5.1">(1) Neighborhood-enriched embedding.</span>
Beyond user ID, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">bell2007lessons</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">koren2008svd++</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kabbur2013fism</span></cite> enrich a user’s representation with their rating history.
This kind of method generates user-item preference scores as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="Ch6.E4">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\hat{r}_{ui}=q_{i}^{\top}\left(p_{u}+|\mathcal{N}(u)|^{-\alpha}\sum_{j\in%
\mathcal{N}(u)}y_{j}\right)," class="ltx_Math" display="block" id="Ch6.E4.m1.3"><semantics id="Ch6.E4.m1.3a"><mrow id="Ch6.E4.m1.3.3.1" xref="Ch6.E4.m1.3.3.1.1.cmml"><mrow id="Ch6.E4.m1.3.3.1.1" xref="Ch6.E4.m1.3.3.1.1.cmml"><msub id="Ch6.E4.m1.3.3.1.1.3" xref="Ch6.E4.m1.3.3.1.1.3.cmml"><mover accent="true" id="Ch6.E4.m1.3.3.1.1.3.2" xref="Ch6.E4.m1.3.3.1.1.3.2.cmml"><mi id="Ch6.E4.m1.3.3.1.1.3.2.2" xref="Ch6.E4.m1.3.3.1.1.3.2.2.cmml">r</mi><mo id="Ch6.E4.m1.3.3.1.1.3.2.1" xref="Ch6.E4.m1.3.3.1.1.3.2.1.cmml">^</mo></mover><mrow id="Ch6.E4.m1.3.3.1.1.3.3" xref="Ch6.E4.m1.3.3.1.1.3.3.cmml"><mi id="Ch6.E4.m1.3.3.1.1.3.3.2" xref="Ch6.E4.m1.3.3.1.1.3.3.2.cmml">u</mi><mo id="Ch6.E4.m1.3.3.1.1.3.3.1" xref="Ch6.E4.m1.3.3.1.1.3.3.1.cmml">⁢</mo><mi id="Ch6.E4.m1.3.3.1.1.3.3.3" xref="Ch6.E4.m1.3.3.1.1.3.3.3.cmml">i</mi></mrow></msub><mo id="Ch6.E4.m1.3.3.1.1.2" xref="Ch6.E4.m1.3.3.1.1.2.cmml">=</mo><mrow id="Ch6.E4.m1.3.3.1.1.1" xref="Ch6.E4.m1.3.3.1.1.1.cmml"><msubsup id="Ch6.E4.m1.3.3.1.1.1.3" xref="Ch6.E4.m1.3.3.1.1.1.3.cmml"><mi id="Ch6.E4.m1.3.3.1.1.1.3.2.2" xref="Ch6.E4.m1.3.3.1.1.1.3.2.2.cmml">q</mi><mi id="Ch6.E4.m1.3.3.1.1.1.3.2.3" xref="Ch6.E4.m1.3.3.1.1.1.3.2.3.cmml">i</mi><mo id="Ch6.E4.m1.3.3.1.1.1.3.3" xref="Ch6.E4.m1.3.3.1.1.1.3.3.cmml">⊤</mo></msubsup><mo id="Ch6.E4.m1.3.3.1.1.1.2" xref="Ch6.E4.m1.3.3.1.1.1.2.cmml">⁢</mo><mrow id="Ch6.E4.m1.3.3.1.1.1.1.1" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.cmml"><mo id="Ch6.E4.m1.3.3.1.1.1.1.1.2" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.cmml">(</mo><mrow id="Ch6.E4.m1.3.3.1.1.1.1.1.1" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.cmml"><msub id="Ch6.E4.m1.3.3.1.1.1.1.1.1.3" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.3.cmml"><mi id="Ch6.E4.m1.3.3.1.1.1.1.1.1.3.2" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.3.2.cmml">p</mi><mi id="Ch6.E4.m1.3.3.1.1.1.1.1.1.3.3" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.3.3.cmml">u</mi></msub><mo id="Ch6.E4.m1.3.3.1.1.1.1.1.1.2" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.2.cmml">+</mo><mrow id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.cmml"><msup id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.cmml"><mrow id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml"><mo id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.1.cmml">|</mo><mrow id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.cmml">𝒩</mi><mo id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml">⁢</mo><mrow id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.2" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.2.1" stretchy="false" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><mi id="Ch6.E4.m1.2.2" xref="Ch6.E4.m1.2.2.cmml">u</mi><mo id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.3.2.2" stretchy="false" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.1.cmml">|</mo></mrow><mrow id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.3" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.3.cmml"><mo id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.3a" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.3.cmml">−</mo><mi id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.3.2" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.3.2.cmml">α</mi></mrow></msup><mo id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.2" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.cmml"><munder id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.1" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.1.cmml"><mo id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.1.2" movablelimits="false" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.1.2.cmml">∑</mo><mrow id="Ch6.E4.m1.1.1.1" xref="Ch6.E4.m1.1.1.1.cmml"><mi id="Ch6.E4.m1.1.1.1.3" xref="Ch6.E4.m1.1.1.1.3.cmml">j</mi><mo id="Ch6.E4.m1.1.1.1.2" xref="Ch6.E4.m1.1.1.1.2.cmml">∈</mo><mrow id="Ch6.E4.m1.1.1.1.4" xref="Ch6.E4.m1.1.1.1.4.cmml"><mi class="ltx_font_mathcaligraphic" id="Ch6.E4.m1.1.1.1.4.2" xref="Ch6.E4.m1.1.1.1.4.2.cmml">𝒩</mi><mo id="Ch6.E4.m1.1.1.1.4.1" xref="Ch6.E4.m1.1.1.1.4.1.cmml">⁢</mo><mrow id="Ch6.E4.m1.1.1.1.4.3.2" xref="Ch6.E4.m1.1.1.1.4.cmml"><mo id="Ch6.E4.m1.1.1.1.4.3.2.1" stretchy="false" xref="Ch6.E4.m1.1.1.1.4.cmml">(</mo><mi id="Ch6.E4.m1.1.1.1.1" xref="Ch6.E4.m1.1.1.1.1.cmml">u</mi><mo id="Ch6.E4.m1.1.1.1.4.3.2.2" stretchy="false" xref="Ch6.E4.m1.1.1.1.4.cmml">)</mo></mrow></mrow></mrow></munder><msub id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.2" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.2.cmml"><mi id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.2.2" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.2.2.cmml">y</mi><mi id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.2.3" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.2.3.cmml">j</mi></msub></mrow></mrow></mrow><mo id="Ch6.E4.m1.3.3.1.1.1.1.1.3" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="Ch6.E4.m1.3.3.1.2" xref="Ch6.E4.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch6.E4.m1.3b"><apply id="Ch6.E4.m1.3.3.1.1.cmml" xref="Ch6.E4.m1.3.3.1"><eq id="Ch6.E4.m1.3.3.1.1.2.cmml" xref="Ch6.E4.m1.3.3.1.1.2"></eq><apply id="Ch6.E4.m1.3.3.1.1.3.cmml" xref="Ch6.E4.m1.3.3.1.1.3"><csymbol cd="ambiguous" id="Ch6.E4.m1.3.3.1.1.3.1.cmml" xref="Ch6.E4.m1.3.3.1.1.3">subscript</csymbol><apply id="Ch6.E4.m1.3.3.1.1.3.2.cmml" xref="Ch6.E4.m1.3.3.1.1.3.2"><ci id="Ch6.E4.m1.3.3.1.1.3.2.1.cmml" xref="Ch6.E4.m1.3.3.1.1.3.2.1">^</ci><ci id="Ch6.E4.m1.3.3.1.1.3.2.2.cmml" xref="Ch6.E4.m1.3.3.1.1.3.2.2">𝑟</ci></apply><apply id="Ch6.E4.m1.3.3.1.1.3.3.cmml" xref="Ch6.E4.m1.3.3.1.1.3.3"><times id="Ch6.E4.m1.3.3.1.1.3.3.1.cmml" xref="Ch6.E4.m1.3.3.1.1.3.3.1"></times><ci id="Ch6.E4.m1.3.3.1.1.3.3.2.cmml" xref="Ch6.E4.m1.3.3.1.1.3.3.2">𝑢</ci><ci id="Ch6.E4.m1.3.3.1.1.3.3.3.cmml" xref="Ch6.E4.m1.3.3.1.1.3.3.3">𝑖</ci></apply></apply><apply id="Ch6.E4.m1.3.3.1.1.1.cmml" xref="Ch6.E4.m1.3.3.1.1.1"><times id="Ch6.E4.m1.3.3.1.1.1.2.cmml" xref="Ch6.E4.m1.3.3.1.1.1.2"></times><apply id="Ch6.E4.m1.3.3.1.1.1.3.cmml" xref="Ch6.E4.m1.3.3.1.1.1.3"><csymbol cd="ambiguous" id="Ch6.E4.m1.3.3.1.1.1.3.1.cmml" xref="Ch6.E4.m1.3.3.1.1.1.3">superscript</csymbol><apply id="Ch6.E4.m1.3.3.1.1.1.3.2.cmml" xref="Ch6.E4.m1.3.3.1.1.1.3"><csymbol cd="ambiguous" id="Ch6.E4.m1.3.3.1.1.1.3.2.1.cmml" xref="Ch6.E4.m1.3.3.1.1.1.3">subscript</csymbol><ci id="Ch6.E4.m1.3.3.1.1.1.3.2.2.cmml" xref="Ch6.E4.m1.3.3.1.1.1.3.2.2">𝑞</ci><ci id="Ch6.E4.m1.3.3.1.1.1.3.2.3.cmml" xref="Ch6.E4.m1.3.3.1.1.1.3.2.3">𝑖</ci></apply><csymbol cd="latexml" id="Ch6.E4.m1.3.3.1.1.1.3.3.cmml" xref="Ch6.E4.m1.3.3.1.1.1.3.3">top</csymbol></apply><apply id="Ch6.E4.m1.3.3.1.1.1.1.1.1.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1"><plus id="Ch6.E4.m1.3.3.1.1.1.1.1.1.2.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.2"></plus><apply id="Ch6.E4.m1.3.3.1.1.1.1.1.1.3.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="Ch6.E4.m1.3.3.1.1.1.1.1.1.3.1.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.3">subscript</csymbol><ci id="Ch6.E4.m1.3.3.1.1.1.1.1.1.3.2.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.3.2">𝑝</ci><ci id="Ch6.E4.m1.3.3.1.1.1.1.1.1.3.3.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.3.3">𝑢</ci></apply><apply id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1"><times id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.2"></times><apply id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.2.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1"><abs id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.2"></abs><apply id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1"><times id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.1"></times><ci id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.1.1.1.2">𝒩</ci><ci id="Ch6.E4.m1.2.2.cmml" xref="Ch6.E4.m1.2.2">𝑢</ci></apply></apply><apply id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.3.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.3"><minus id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.3.1.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.3"></minus><ci id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.3.2.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.1.3.2">𝛼</ci></apply></apply><apply id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3"><apply id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.1.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.1.1.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.1">subscript</csymbol><sum id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.1.2.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.1.2"></sum><apply id="Ch6.E4.m1.1.1.1.cmml" xref="Ch6.E4.m1.1.1.1"><in id="Ch6.E4.m1.1.1.1.2.cmml" xref="Ch6.E4.m1.1.1.1.2"></in><ci id="Ch6.E4.m1.1.1.1.3.cmml" xref="Ch6.E4.m1.1.1.1.3">𝑗</ci><apply id="Ch6.E4.m1.1.1.1.4.cmml" xref="Ch6.E4.m1.1.1.1.4"><times id="Ch6.E4.m1.1.1.1.4.1.cmml" xref="Ch6.E4.m1.1.1.1.4.1"></times><ci id="Ch6.E4.m1.1.1.1.4.2.cmml" xref="Ch6.E4.m1.1.1.1.4.2">𝒩</ci><ci id="Ch6.E4.m1.1.1.1.1.cmml" xref="Ch6.E4.m1.1.1.1.1">𝑢</ci></apply></apply></apply><apply id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.2.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.2.1.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.2.2.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.2.2">𝑦</ci><ci id="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.2.3.cmml" xref="Ch6.E4.m1.3.3.1.1.1.1.1.1.1.3.2.3">𝑗</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.E4.m1.3c">\hat{r}_{ui}=q_{i}^{\top}\left(p_{u}+|\mathcal{N}(u)|^{-\alpha}\sum_{j\in%
\mathcal{N}(u)}y_{j}\right),</annotation><annotation encoding="application/x-llamapun" id="Ch6.E4.m1.3d">over^ start_ARG italic_r end_ARG start_POSTSUBSCRIPT italic_u italic_i end_POSTSUBSCRIPT = italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT ( italic_p start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT + | caligraphic_N ( italic_u ) | start_POSTSUPERSCRIPT - italic_α end_POSTSUPERSCRIPT ∑ start_POSTSUBSCRIPT italic_j ∈ caligraphic_N ( italic_u ) end_POSTSUBSCRIPT italic_y start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6.4)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch6.S2.SS2.p5.4">where <math alttext="\mathcal{N}(u)" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p5.1.m1.1"><semantics id="Ch6.S2.SS2.p5.1.m1.1a"><mrow id="Ch6.S2.SS2.p5.1.m1.1.2" xref="Ch6.S2.SS2.p5.1.m1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="Ch6.S2.SS2.p5.1.m1.1.2.2" xref="Ch6.S2.SS2.p5.1.m1.1.2.2.cmml">𝒩</mi><mo id="Ch6.S2.SS2.p5.1.m1.1.2.1" xref="Ch6.S2.SS2.p5.1.m1.1.2.1.cmml">⁢</mo><mrow id="Ch6.S2.SS2.p5.1.m1.1.2.3.2" xref="Ch6.S2.SS2.p5.1.m1.1.2.cmml"><mo id="Ch6.S2.SS2.p5.1.m1.1.2.3.2.1" stretchy="false" xref="Ch6.S2.SS2.p5.1.m1.1.2.cmml">(</mo><mi id="Ch6.S2.SS2.p5.1.m1.1.1" xref="Ch6.S2.SS2.p5.1.m1.1.1.cmml">u</mi><mo id="Ch6.S2.SS2.p5.1.m1.1.2.3.2.2" stretchy="false" xref="Ch6.S2.SS2.p5.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p5.1.m1.1b"><apply id="Ch6.S2.SS2.p5.1.m1.1.2.cmml" xref="Ch6.S2.SS2.p5.1.m1.1.2"><times id="Ch6.S2.SS2.p5.1.m1.1.2.1.cmml" xref="Ch6.S2.SS2.p5.1.m1.1.2.1"></times><ci id="Ch6.S2.SS2.p5.1.m1.1.2.2.cmml" xref="Ch6.S2.SS2.p5.1.m1.1.2.2">𝒩</ci><ci id="Ch6.S2.SS2.p5.1.m1.1.1.cmml" xref="Ch6.S2.SS2.p5.1.m1.1.1">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p5.1.m1.1c">\mathcal{N}(u)</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p5.1.m1.1d">caligraphic_N ( italic_u )</annotation></semantics></math> denotes a set of items with which the user <math alttext="u" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p5.2.m2.1"><semantics id="Ch6.S2.SS2.p5.2.m2.1a"><mi id="Ch6.S2.SS2.p5.2.m2.1.1" xref="Ch6.S2.SS2.p5.2.m2.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p5.2.m2.1b"><ci id="Ch6.S2.SS2.p5.2.m2.1.1.cmml" xref="Ch6.S2.SS2.p5.2.m2.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p5.2.m2.1c">u</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p5.2.m2.1d">italic_u</annotation></semantics></math> has interacted.
Each item <math alttext="j\in\mathcal{N}(u)" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p5.3.m3.1"><semantics id="Ch6.S2.SS2.p5.3.m3.1a"><mrow id="Ch6.S2.SS2.p5.3.m3.1.2" xref="Ch6.S2.SS2.p5.3.m3.1.2.cmml"><mi id="Ch6.S2.SS2.p5.3.m3.1.2.2" xref="Ch6.S2.SS2.p5.3.m3.1.2.2.cmml">j</mi><mo id="Ch6.S2.SS2.p5.3.m3.1.2.1" xref="Ch6.S2.SS2.p5.3.m3.1.2.1.cmml">∈</mo><mrow id="Ch6.S2.SS2.p5.3.m3.1.2.3" xref="Ch6.S2.SS2.p5.3.m3.1.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="Ch6.S2.SS2.p5.3.m3.1.2.3.2" xref="Ch6.S2.SS2.p5.3.m3.1.2.3.2.cmml">𝒩</mi><mo id="Ch6.S2.SS2.p5.3.m3.1.2.3.1" xref="Ch6.S2.SS2.p5.3.m3.1.2.3.1.cmml">⁢</mo><mrow id="Ch6.S2.SS2.p5.3.m3.1.2.3.3.2" xref="Ch6.S2.SS2.p5.3.m3.1.2.3.cmml"><mo id="Ch6.S2.SS2.p5.3.m3.1.2.3.3.2.1" stretchy="false" xref="Ch6.S2.SS2.p5.3.m3.1.2.3.cmml">(</mo><mi id="Ch6.S2.SS2.p5.3.m3.1.1" xref="Ch6.S2.SS2.p5.3.m3.1.1.cmml">u</mi><mo id="Ch6.S2.SS2.p5.3.m3.1.2.3.3.2.2" stretchy="false" xref="Ch6.S2.SS2.p5.3.m3.1.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p5.3.m3.1b"><apply id="Ch6.S2.SS2.p5.3.m3.1.2.cmml" xref="Ch6.S2.SS2.p5.3.m3.1.2"><in id="Ch6.S2.SS2.p5.3.m3.1.2.1.cmml" xref="Ch6.S2.SS2.p5.3.m3.1.2.1"></in><ci id="Ch6.S2.SS2.p5.3.m3.1.2.2.cmml" xref="Ch6.S2.SS2.p5.3.m3.1.2.2">𝑗</ci><apply id="Ch6.S2.SS2.p5.3.m3.1.2.3.cmml" xref="Ch6.S2.SS2.p5.3.m3.1.2.3"><times id="Ch6.S2.SS2.p5.3.m3.1.2.3.1.cmml" xref="Ch6.S2.SS2.p5.3.m3.1.2.3.1"></times><ci id="Ch6.S2.SS2.p5.3.m3.1.2.3.2.cmml" xref="Ch6.S2.SS2.p5.3.m3.1.2.3.2">𝒩</ci><ci id="Ch6.S2.SS2.p5.3.m3.1.1.cmml" xref="Ch6.S2.SS2.p5.3.m3.1.1">𝑢</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p5.3.m3.1c">j\in\mathcal{N}(u)</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p5.3.m3.1d">italic_j ∈ caligraphic_N ( italic_u )</annotation></semantics></math> is mapped into a common embedding space to get a vector representation <math alttext="q_{j}" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p5.4.m4.1"><semantics id="Ch6.S2.SS2.p5.4.m4.1a"><msub id="Ch6.S2.SS2.p5.4.m4.1.1" xref="Ch6.S2.SS2.p5.4.m4.1.1.cmml"><mi id="Ch6.S2.SS2.p5.4.m4.1.1.2" xref="Ch6.S2.SS2.p5.4.m4.1.1.2.cmml">q</mi><mi id="Ch6.S2.SS2.p5.4.m4.1.1.3" xref="Ch6.S2.SS2.p5.4.m4.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p5.4.m4.1b"><apply id="Ch6.S2.SS2.p5.4.m4.1.1.cmml" xref="Ch6.S2.SS2.p5.4.m4.1.1"><csymbol cd="ambiguous" id="Ch6.S2.SS2.p5.4.m4.1.1.1.cmml" xref="Ch6.S2.SS2.p5.4.m4.1.1">subscript</csymbol><ci id="Ch6.S2.SS2.p5.4.m4.1.1.2.cmml" xref="Ch6.S2.SS2.p5.4.m4.1.1.2">𝑞</ci><ci id="Ch6.S2.SS2.p5.4.m4.1.1.3.cmml" xref="Ch6.S2.SS2.p5.4.m4.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p5.4.m4.1c">q_{j}</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p5.4.m4.1d">italic_q start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math>.
Neighborhood-enriched embedding methods can be considered as a combination of MF-based methods and neighborhood embedding methods.
MF-based and neighborhood methods make predictions from different perspectives, which results in different strengths and weaknesses.
Neighborhood methods struggle to detect all associations captured by interactions, whereas MF-based methods are poor at detecting associations among sparse neighborhoods.
Hence, endowing MF with neighborhood methods fosters its merits and circumvents its weaknesses.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch6.S2.SS2.p6">
<p class="ltx_p" id="Ch6.S2.SS2.p6.4"><span class="ltx_text ltx_font_bold" id="Ch6.S2.SS2.p6.4.1">(2) Feature-enriched embedding.</span>
Another way to improve MF is to leverage rich user and item features, e.g., a user’s age, gender, education, revenue, product tags, category, and price.
These features are valuable in enriching the representations of users and items, which further boosts the recommendation performance.
Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.F4" title="Figure 6.4 ‣ 6.2.2 Embedding-based methods ‣ 6.2 Candidate retrieval models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6.4</span></a> summarizes the architecture of feature-enriched candidate retrieval methods as a two-tower structure <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yi2019youtube-2tower</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">fan2019mobius</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">xu2016tag-dssm</span>]</cite>.
The left tower is the user tower that translates a user’s features into the user’s embedding representation; the right tower is the item tower generating the item representation.
Let <math alttext="x_{u}" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p6.1.m1.1"><semantics id="Ch6.S2.SS2.p6.1.m1.1a"><msub id="Ch6.S2.SS2.p6.1.m1.1.1" xref="Ch6.S2.SS2.p6.1.m1.1.1.cmml"><mi id="Ch6.S2.SS2.p6.1.m1.1.1.2" xref="Ch6.S2.SS2.p6.1.m1.1.1.2.cmml">x</mi><mi id="Ch6.S2.SS2.p6.1.m1.1.1.3" xref="Ch6.S2.SS2.p6.1.m1.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p6.1.m1.1b"><apply id="Ch6.S2.SS2.p6.1.m1.1.1.cmml" xref="Ch6.S2.SS2.p6.1.m1.1.1"><csymbol cd="ambiguous" id="Ch6.S2.SS2.p6.1.m1.1.1.1.cmml" xref="Ch6.S2.SS2.p6.1.m1.1.1">subscript</csymbol><ci id="Ch6.S2.SS2.p6.1.m1.1.1.2.cmml" xref="Ch6.S2.SS2.p6.1.m1.1.1.2">𝑥</ci><ci id="Ch6.S2.SS2.p6.1.m1.1.1.3.cmml" xref="Ch6.S2.SS2.p6.1.m1.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p6.1.m1.1c">x_{u}</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p6.1.m1.1d">italic_x start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math> denote the features of user <math alttext="u" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p6.2.m2.1"><semantics id="Ch6.S2.SS2.p6.2.m2.1a"><mi id="Ch6.S2.SS2.p6.2.m2.1.1" xref="Ch6.S2.SS2.p6.2.m2.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p6.2.m2.1b"><ci id="Ch6.S2.SS2.p6.2.m2.1.1.cmml" xref="Ch6.S2.SS2.p6.2.m2.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p6.2.m2.1c">u</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p6.2.m2.1d">italic_u</annotation></semantics></math>, while <math alttext="x_{i}" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p6.3.m3.1"><semantics id="Ch6.S2.SS2.p6.3.m3.1a"><msub id="Ch6.S2.SS2.p6.3.m3.1.1" xref="Ch6.S2.SS2.p6.3.m3.1.1.cmml"><mi id="Ch6.S2.SS2.p6.3.m3.1.1.2" xref="Ch6.S2.SS2.p6.3.m3.1.1.2.cmml">x</mi><mi id="Ch6.S2.SS2.p6.3.m3.1.1.3" xref="Ch6.S2.SS2.p6.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p6.3.m3.1b"><apply id="Ch6.S2.SS2.p6.3.m3.1.1.cmml" xref="Ch6.S2.SS2.p6.3.m3.1.1"><csymbol cd="ambiguous" id="Ch6.S2.SS2.p6.3.m3.1.1.1.cmml" xref="Ch6.S2.SS2.p6.3.m3.1.1">subscript</csymbol><ci id="Ch6.S2.SS2.p6.3.m3.1.1.2.cmml" xref="Ch6.S2.SS2.p6.3.m3.1.1.2">𝑥</ci><ci id="Ch6.S2.SS2.p6.3.m3.1.1.3.cmml" xref="Ch6.S2.SS2.p6.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p6.3.m3.1c">x_{i}</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p6.3.m3.1d">italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> denotes the features of item <math alttext="i" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p6.4.m4.1"><semantics id="Ch6.S2.SS2.p6.4.m4.1a"><mi id="Ch6.S2.SS2.p6.4.m4.1.1" xref="Ch6.S2.SS2.p6.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p6.4.m4.1b"><ci id="Ch6.S2.SS2.p6.4.m4.1.1.cmml" xref="Ch6.S2.SS2.p6.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p6.4.m4.1c">i</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p6.4.m4.1d">italic_i</annotation></semantics></math>. The function of the two towers can be depicted as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="Ch6.E5">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="p_{u}=f_{U}(x_{u}),\,q_{i}=f_{I}(x_{i})," class="ltx_Math" display="block" id="Ch6.E5.m1.1"><semantics id="Ch6.E5.m1.1a"><mrow id="Ch6.E5.m1.1.1.1"><mrow id="Ch6.E5.m1.1.1.1.1.2" xref="Ch6.E5.m1.1.1.1.1.3.cmml"><mrow id="Ch6.E5.m1.1.1.1.1.1.1" xref="Ch6.E5.m1.1.1.1.1.1.1.cmml"><msub id="Ch6.E5.m1.1.1.1.1.1.1.3" xref="Ch6.E5.m1.1.1.1.1.1.1.3.cmml"><mi id="Ch6.E5.m1.1.1.1.1.1.1.3.2" xref="Ch6.E5.m1.1.1.1.1.1.1.3.2.cmml">p</mi><mi id="Ch6.E5.m1.1.1.1.1.1.1.3.3" xref="Ch6.E5.m1.1.1.1.1.1.1.3.3.cmml">u</mi></msub><mo id="Ch6.E5.m1.1.1.1.1.1.1.2" xref="Ch6.E5.m1.1.1.1.1.1.1.2.cmml">=</mo><mrow id="Ch6.E5.m1.1.1.1.1.1.1.1" xref="Ch6.E5.m1.1.1.1.1.1.1.1.cmml"><msub id="Ch6.E5.m1.1.1.1.1.1.1.1.3" xref="Ch6.E5.m1.1.1.1.1.1.1.1.3.cmml"><mi id="Ch6.E5.m1.1.1.1.1.1.1.1.3.2" xref="Ch6.E5.m1.1.1.1.1.1.1.1.3.2.cmml">f</mi><mi id="Ch6.E5.m1.1.1.1.1.1.1.1.3.3" xref="Ch6.E5.m1.1.1.1.1.1.1.1.3.3.cmml">U</mi></msub><mo id="Ch6.E5.m1.1.1.1.1.1.1.1.2" xref="Ch6.E5.m1.1.1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="Ch6.E5.m1.1.1.1.1.1.1.1.1.1" xref="Ch6.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mo id="Ch6.E5.m1.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="Ch6.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="Ch6.E5.m1.1.1.1.1.1.1.1.1.1.1" xref="Ch6.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="Ch6.E5.m1.1.1.1.1.1.1.1.1.1.1.2" xref="Ch6.E5.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="Ch6.E5.m1.1.1.1.1.1.1.1.1.1.1.3" xref="Ch6.E5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">u</mi></msub><mo id="Ch6.E5.m1.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="Ch6.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="Ch6.E5.m1.1.1.1.1.2.3" rspace="0.337em" xref="Ch6.E5.m1.1.1.1.1.3a.cmml">,</mo><mrow id="Ch6.E5.m1.1.1.1.1.2.2" xref="Ch6.E5.m1.1.1.1.1.2.2.cmml"><msub id="Ch6.E5.m1.1.1.1.1.2.2.3" xref="Ch6.E5.m1.1.1.1.1.2.2.3.cmml"><mi id="Ch6.E5.m1.1.1.1.1.2.2.3.2" xref="Ch6.E5.m1.1.1.1.1.2.2.3.2.cmml">q</mi><mi id="Ch6.E5.m1.1.1.1.1.2.2.3.3" xref="Ch6.E5.m1.1.1.1.1.2.2.3.3.cmml">i</mi></msub><mo id="Ch6.E5.m1.1.1.1.1.2.2.2" xref="Ch6.E5.m1.1.1.1.1.2.2.2.cmml">=</mo><mrow id="Ch6.E5.m1.1.1.1.1.2.2.1" xref="Ch6.E5.m1.1.1.1.1.2.2.1.cmml"><msub id="Ch6.E5.m1.1.1.1.1.2.2.1.3" xref="Ch6.E5.m1.1.1.1.1.2.2.1.3.cmml"><mi id="Ch6.E5.m1.1.1.1.1.2.2.1.3.2" xref="Ch6.E5.m1.1.1.1.1.2.2.1.3.2.cmml">f</mi><mi id="Ch6.E5.m1.1.1.1.1.2.2.1.3.3" xref="Ch6.E5.m1.1.1.1.1.2.2.1.3.3.cmml">I</mi></msub><mo id="Ch6.E5.m1.1.1.1.1.2.2.1.2" xref="Ch6.E5.m1.1.1.1.1.2.2.1.2.cmml">⁢</mo><mrow id="Ch6.E5.m1.1.1.1.1.2.2.1.1.1" xref="Ch6.E5.m1.1.1.1.1.2.2.1.1.1.1.cmml"><mo id="Ch6.E5.m1.1.1.1.1.2.2.1.1.1.2" stretchy="false" xref="Ch6.E5.m1.1.1.1.1.2.2.1.1.1.1.cmml">(</mo><msub id="Ch6.E5.m1.1.1.1.1.2.2.1.1.1.1" xref="Ch6.E5.m1.1.1.1.1.2.2.1.1.1.1.cmml"><mi id="Ch6.E5.m1.1.1.1.1.2.2.1.1.1.1.2" xref="Ch6.E5.m1.1.1.1.1.2.2.1.1.1.1.2.cmml">x</mi><mi id="Ch6.E5.m1.1.1.1.1.2.2.1.1.1.1.3" xref="Ch6.E5.m1.1.1.1.1.2.2.1.1.1.1.3.cmml">i</mi></msub><mo id="Ch6.E5.m1.1.1.1.1.2.2.1.1.1.3" stretchy="false" xref="Ch6.E5.m1.1.1.1.1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="Ch6.E5.m1.1.1.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch6.E5.m1.1b"><apply id="Ch6.E5.m1.1.1.1.1.3.cmml" xref="Ch6.E5.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="Ch6.E5.m1.1.1.1.1.3a.cmml" xref="Ch6.E5.m1.1.1.1.1.2.3">formulae-sequence</csymbol><apply id="Ch6.E5.m1.1.1.1.1.1.1.cmml" xref="Ch6.E5.m1.1.1.1.1.1.1"><eq id="Ch6.E5.m1.1.1.1.1.1.1.2.cmml" xref="Ch6.E5.m1.1.1.1.1.1.1.2"></eq><apply id="Ch6.E5.m1.1.1.1.1.1.1.3.cmml" xref="Ch6.E5.m1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="Ch6.E5.m1.1.1.1.1.1.1.3.1.cmml" xref="Ch6.E5.m1.1.1.1.1.1.1.3">subscript</csymbol><ci id="Ch6.E5.m1.1.1.1.1.1.1.3.2.cmml" xref="Ch6.E5.m1.1.1.1.1.1.1.3.2">𝑝</ci><ci id="Ch6.E5.m1.1.1.1.1.1.1.3.3.cmml" xref="Ch6.E5.m1.1.1.1.1.1.1.3.3">𝑢</ci></apply><apply id="Ch6.E5.m1.1.1.1.1.1.1.1.cmml" xref="Ch6.E5.m1.1.1.1.1.1.1.1"><times id="Ch6.E5.m1.1.1.1.1.1.1.1.2.cmml" xref="Ch6.E5.m1.1.1.1.1.1.1.1.2"></times><apply id="Ch6.E5.m1.1.1.1.1.1.1.1.3.cmml" xref="Ch6.E5.m1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="Ch6.E5.m1.1.1.1.1.1.1.1.3.1.cmml" xref="Ch6.E5.m1.1.1.1.1.1.1.1.3">subscript</csymbol><ci id="Ch6.E5.m1.1.1.1.1.1.1.1.3.2.cmml" xref="Ch6.E5.m1.1.1.1.1.1.1.1.3.2">𝑓</ci><ci id="Ch6.E5.m1.1.1.1.1.1.1.1.3.3.cmml" xref="Ch6.E5.m1.1.1.1.1.1.1.1.3.3">𝑈</ci></apply><apply id="Ch6.E5.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch6.E5.m1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="Ch6.E5.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch6.E5.m1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="Ch6.E5.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="Ch6.E5.m1.1.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="Ch6.E5.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="Ch6.E5.m1.1.1.1.1.1.1.1.1.1.1.3">𝑢</ci></apply></apply></apply><apply id="Ch6.E5.m1.1.1.1.1.2.2.cmml" xref="Ch6.E5.m1.1.1.1.1.2.2"><eq id="Ch6.E5.m1.1.1.1.1.2.2.2.cmml" xref="Ch6.E5.m1.1.1.1.1.2.2.2"></eq><apply id="Ch6.E5.m1.1.1.1.1.2.2.3.cmml" xref="Ch6.E5.m1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="Ch6.E5.m1.1.1.1.1.2.2.3.1.cmml" xref="Ch6.E5.m1.1.1.1.1.2.2.3">subscript</csymbol><ci id="Ch6.E5.m1.1.1.1.1.2.2.3.2.cmml" xref="Ch6.E5.m1.1.1.1.1.2.2.3.2">𝑞</ci><ci id="Ch6.E5.m1.1.1.1.1.2.2.3.3.cmml" xref="Ch6.E5.m1.1.1.1.1.2.2.3.3">𝑖</ci></apply><apply id="Ch6.E5.m1.1.1.1.1.2.2.1.cmml" xref="Ch6.E5.m1.1.1.1.1.2.2.1"><times id="Ch6.E5.m1.1.1.1.1.2.2.1.2.cmml" xref="Ch6.E5.m1.1.1.1.1.2.2.1.2"></times><apply id="Ch6.E5.m1.1.1.1.1.2.2.1.3.cmml" xref="Ch6.E5.m1.1.1.1.1.2.2.1.3"><csymbol cd="ambiguous" id="Ch6.E5.m1.1.1.1.1.2.2.1.3.1.cmml" xref="Ch6.E5.m1.1.1.1.1.2.2.1.3">subscript</csymbol><ci id="Ch6.E5.m1.1.1.1.1.2.2.1.3.2.cmml" xref="Ch6.E5.m1.1.1.1.1.2.2.1.3.2">𝑓</ci><ci id="Ch6.E5.m1.1.1.1.1.2.2.1.3.3.cmml" xref="Ch6.E5.m1.1.1.1.1.2.2.1.3.3">𝐼</ci></apply><apply id="Ch6.E5.m1.1.1.1.1.2.2.1.1.1.1.cmml" xref="Ch6.E5.m1.1.1.1.1.2.2.1.1.1"><csymbol cd="ambiguous" id="Ch6.E5.m1.1.1.1.1.2.2.1.1.1.1.1.cmml" xref="Ch6.E5.m1.1.1.1.1.2.2.1.1.1">subscript</csymbol><ci id="Ch6.E5.m1.1.1.1.1.2.2.1.1.1.1.2.cmml" xref="Ch6.E5.m1.1.1.1.1.2.2.1.1.1.1.2">𝑥</ci><ci id="Ch6.E5.m1.1.1.1.1.2.2.1.1.1.1.3.cmml" xref="Ch6.E5.m1.1.1.1.1.2.2.1.1.1.1.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.E5.m1.1c">p_{u}=f_{U}(x_{u}),\,q_{i}=f_{I}(x_{i}),</annotation><annotation encoding="application/x-llamapun" id="Ch6.E5.m1.1d">italic_p start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT = italic_f start_POSTSUBSCRIPT italic_U end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ) , italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = italic_f start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6.5)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch6.S2.SS2.p6.6">where <math alttext="f_{U}(\cdot)" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p6.5.m1.1"><semantics id="Ch6.S2.SS2.p6.5.m1.1a"><mrow id="Ch6.S2.SS2.p6.5.m1.1.2" xref="Ch6.S2.SS2.p6.5.m1.1.2.cmml"><msub id="Ch6.S2.SS2.p6.5.m1.1.2.2" xref="Ch6.S2.SS2.p6.5.m1.1.2.2.cmml"><mi id="Ch6.S2.SS2.p6.5.m1.1.2.2.2" xref="Ch6.S2.SS2.p6.5.m1.1.2.2.2.cmml">f</mi><mi id="Ch6.S2.SS2.p6.5.m1.1.2.2.3" xref="Ch6.S2.SS2.p6.5.m1.1.2.2.3.cmml">U</mi></msub><mo id="Ch6.S2.SS2.p6.5.m1.1.2.1" xref="Ch6.S2.SS2.p6.5.m1.1.2.1.cmml">⁢</mo><mrow id="Ch6.S2.SS2.p6.5.m1.1.2.3.2" xref="Ch6.S2.SS2.p6.5.m1.1.2.cmml"><mo id="Ch6.S2.SS2.p6.5.m1.1.2.3.2.1" stretchy="false" xref="Ch6.S2.SS2.p6.5.m1.1.2.cmml">(</mo><mo id="Ch6.S2.SS2.p6.5.m1.1.1" lspace="0em" rspace="0em" xref="Ch6.S2.SS2.p6.5.m1.1.1.cmml">⋅</mo><mo id="Ch6.S2.SS2.p6.5.m1.1.2.3.2.2" stretchy="false" xref="Ch6.S2.SS2.p6.5.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p6.5.m1.1b"><apply id="Ch6.S2.SS2.p6.5.m1.1.2.cmml" xref="Ch6.S2.SS2.p6.5.m1.1.2"><times id="Ch6.S2.SS2.p6.5.m1.1.2.1.cmml" xref="Ch6.S2.SS2.p6.5.m1.1.2.1"></times><apply id="Ch6.S2.SS2.p6.5.m1.1.2.2.cmml" xref="Ch6.S2.SS2.p6.5.m1.1.2.2"><csymbol cd="ambiguous" id="Ch6.S2.SS2.p6.5.m1.1.2.2.1.cmml" xref="Ch6.S2.SS2.p6.5.m1.1.2.2">subscript</csymbol><ci id="Ch6.S2.SS2.p6.5.m1.1.2.2.2.cmml" xref="Ch6.S2.SS2.p6.5.m1.1.2.2.2">𝑓</ci><ci id="Ch6.S2.SS2.p6.5.m1.1.2.2.3.cmml" xref="Ch6.S2.SS2.p6.5.m1.1.2.2.3">𝑈</ci></apply><ci id="Ch6.S2.SS2.p6.5.m1.1.1.cmml" xref="Ch6.S2.SS2.p6.5.m1.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p6.5.m1.1c">f_{U}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p6.5.m1.1d">italic_f start_POSTSUBSCRIPT italic_U end_POSTSUBSCRIPT ( ⋅ )</annotation></semantics></math> and <math alttext="f_{I}(\cdot)" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p6.6.m2.1"><semantics id="Ch6.S2.SS2.p6.6.m2.1a"><mrow id="Ch6.S2.SS2.p6.6.m2.1.2" xref="Ch6.S2.SS2.p6.6.m2.1.2.cmml"><msub id="Ch6.S2.SS2.p6.6.m2.1.2.2" xref="Ch6.S2.SS2.p6.6.m2.1.2.2.cmml"><mi id="Ch6.S2.SS2.p6.6.m2.1.2.2.2" xref="Ch6.S2.SS2.p6.6.m2.1.2.2.2.cmml">f</mi><mi id="Ch6.S2.SS2.p6.6.m2.1.2.2.3" xref="Ch6.S2.SS2.p6.6.m2.1.2.2.3.cmml">I</mi></msub><mo id="Ch6.S2.SS2.p6.6.m2.1.2.1" xref="Ch6.S2.SS2.p6.6.m2.1.2.1.cmml">⁢</mo><mrow id="Ch6.S2.SS2.p6.6.m2.1.2.3.2" xref="Ch6.S2.SS2.p6.6.m2.1.2.cmml"><mo id="Ch6.S2.SS2.p6.6.m2.1.2.3.2.1" stretchy="false" xref="Ch6.S2.SS2.p6.6.m2.1.2.cmml">(</mo><mo id="Ch6.S2.SS2.p6.6.m2.1.1" lspace="0em" rspace="0em" xref="Ch6.S2.SS2.p6.6.m2.1.1.cmml">⋅</mo><mo id="Ch6.S2.SS2.p6.6.m2.1.2.3.2.2" stretchy="false" xref="Ch6.S2.SS2.p6.6.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p6.6.m2.1b"><apply id="Ch6.S2.SS2.p6.6.m2.1.2.cmml" xref="Ch6.S2.SS2.p6.6.m2.1.2"><times id="Ch6.S2.SS2.p6.6.m2.1.2.1.cmml" xref="Ch6.S2.SS2.p6.6.m2.1.2.1"></times><apply id="Ch6.S2.SS2.p6.6.m2.1.2.2.cmml" xref="Ch6.S2.SS2.p6.6.m2.1.2.2"><csymbol cd="ambiguous" id="Ch6.S2.SS2.p6.6.m2.1.2.2.1.cmml" xref="Ch6.S2.SS2.p6.6.m2.1.2.2">subscript</csymbol><ci id="Ch6.S2.SS2.p6.6.m2.1.2.2.2.cmml" xref="Ch6.S2.SS2.p6.6.m2.1.2.2.2">𝑓</ci><ci id="Ch6.S2.SS2.p6.6.m2.1.2.2.3.cmml" xref="Ch6.S2.SS2.p6.6.m2.1.2.2.3">𝐼</ci></apply><ci id="Ch6.S2.SS2.p6.6.m2.1.1.cmml" xref="Ch6.S2.SS2.p6.6.m2.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p6.6.m2.1c">f_{I}(\cdot)</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p6.6.m2.1d">italic_f start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT ( ⋅ )</annotation></semantics></math> denote the translation function with regard to the implementation of the two towers.
Linear models and neural networks (e.g., MLP <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">huang2013dssm</span>]</cite>, LSTM <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">song2016TDDSSM</span>]</cite>, CNN <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">shen2014CDSSM</span>]</cite> and auto-encoders <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">CDAE</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liang2018variational</span>]</cite>) can be used as the translation function.
Given user and item embeddings, the two-tower model makes a prediction for each user-item pair. Cosine similarity and inner product are usually adopted to measure the embedding distance, so we have:</p>
<table class="ltx_equation ltx_eqn_table" id="Ch6.E6">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\begin{split}\text{Cosine: }&amp;\hat{r}_{ui}=\frac{q_{i}^{\top}p_{u}}{\|p_{u}\|%
\cdot\|q_{i}\|},\\
\text{Inner product: }&amp;\hat{r}_{ui}=q_{i}^{\top}p_{u}.\end{split}" class="ltx_Math" display="block" id="Ch6.E6.m1.19"><semantics id="Ch6.E6.m1.19a"><mtable columnspacing="0pt" displaystyle="true" id="Ch6.E6.m1.19.19.3" rowspacing="0pt"><mtr id="Ch6.E6.m1.19.19.3a"><mtd class="ltx_align_right" columnalign="right" id="Ch6.E6.m1.19.19.3b"><mtext id="Ch6.E6.m1.1.1.1.1.1.1" xref="Ch6.E6.m1.1.1.1.1.1.1a.cmml">Cosine: </mtext></mtd><mtd class="ltx_align_left" columnalign="left" id="Ch6.E6.m1.19.19.3c"><mrow id="Ch6.E6.m1.18.18.2.17.7.6.6"><mrow id="Ch6.E6.m1.18.18.2.17.7.6.6.1"><msub id="Ch6.E6.m1.18.18.2.17.7.6.6.1.1"><mover accent="true" id="Ch6.E6.m1.2.2.2.2.1.1" xref="Ch6.E6.m1.2.2.2.2.1.1.cmml"><mi id="Ch6.E6.m1.2.2.2.2.1.1.2" xref="Ch6.E6.m1.2.2.2.2.1.1.2.cmml">r</mi><mo id="Ch6.E6.m1.2.2.2.2.1.1.1" xref="Ch6.E6.m1.2.2.2.2.1.1.1.cmml">^</mo></mover><mrow id="Ch6.E6.m1.3.3.3.3.2.2.1" xref="Ch6.E6.m1.3.3.3.3.2.2.1.cmml"><mi id="Ch6.E6.m1.3.3.3.3.2.2.1.2" xref="Ch6.E6.m1.3.3.3.3.2.2.1.2.cmml">u</mi><mo id="Ch6.E6.m1.3.3.3.3.2.2.1.1" xref="Ch6.E6.m1.3.3.3.3.2.2.1.1.cmml">⁢</mo><mi id="Ch6.E6.m1.3.3.3.3.2.2.1.3" xref="Ch6.E6.m1.3.3.3.3.2.2.1.3.cmml">i</mi></mrow></msub><mo id="Ch6.E6.m1.4.4.4.4.3.3" xref="Ch6.E6.m1.4.4.4.4.3.3.cmml">=</mo><mfrac id="Ch6.E6.m1.5.5.5.5.4.4" xref="Ch6.E6.m1.5.5.5.5.4.4.cmml"><mrow id="Ch6.E6.m1.5.5.5.5.4.4.4" xref="Ch6.E6.m1.5.5.5.5.4.4.4.cmml"><msubsup id="Ch6.E6.m1.5.5.5.5.4.4.4.2" xref="Ch6.E6.m1.5.5.5.5.4.4.4.2.cmml"><mi id="Ch6.E6.m1.5.5.5.5.4.4.4.2.2.2" xref="Ch6.E6.m1.5.5.5.5.4.4.4.2.2.2.cmml">q</mi><mi id="Ch6.E6.m1.5.5.5.5.4.4.4.2.2.3" xref="Ch6.E6.m1.5.5.5.5.4.4.4.2.2.3.cmml">i</mi><mo id="Ch6.E6.m1.5.5.5.5.4.4.4.2.3" xref="Ch6.E6.m1.5.5.5.5.4.4.4.2.3.cmml">⊤</mo></msubsup><mo id="Ch6.E6.m1.5.5.5.5.4.4.4.1" xref="Ch6.E6.m1.5.5.5.5.4.4.4.1.cmml">⁢</mo><msub id="Ch6.E6.m1.5.5.5.5.4.4.4.3" xref="Ch6.E6.m1.5.5.5.5.4.4.4.3.cmml"><mi id="Ch6.E6.m1.5.5.5.5.4.4.4.3.2" xref="Ch6.E6.m1.5.5.5.5.4.4.4.3.2.cmml">p</mi><mi id="Ch6.E6.m1.5.5.5.5.4.4.4.3.3" xref="Ch6.E6.m1.5.5.5.5.4.4.4.3.3.cmml">u</mi></msub></mrow><mrow id="Ch6.E6.m1.5.5.5.5.4.4.2" xref="Ch6.E6.m1.5.5.5.5.4.4.2.cmml"><mrow id="Ch6.E6.m1.5.5.5.5.4.4.1.1.1" xref="Ch6.E6.m1.5.5.5.5.4.4.1.1.2.cmml"><mo id="Ch6.E6.m1.5.5.5.5.4.4.1.1.1.2" stretchy="false" xref="Ch6.E6.m1.5.5.5.5.4.4.1.1.2.1.cmml">‖</mo><msub id="Ch6.E6.m1.5.5.5.5.4.4.1.1.1.1" xref="Ch6.E6.m1.5.5.5.5.4.4.1.1.1.1.cmml"><mi id="Ch6.E6.m1.5.5.5.5.4.4.1.1.1.1.2" xref="Ch6.E6.m1.5.5.5.5.4.4.1.1.1.1.2.cmml">p</mi><mi id="Ch6.E6.m1.5.5.5.5.4.4.1.1.1.1.3" xref="Ch6.E6.m1.5.5.5.5.4.4.1.1.1.1.3.cmml">u</mi></msub><mo id="Ch6.E6.m1.5.5.5.5.4.4.1.1.1.3" rspace="0.055em" stretchy="false" xref="Ch6.E6.m1.5.5.5.5.4.4.1.1.2.1.cmml">‖</mo></mrow><mo id="Ch6.E6.m1.5.5.5.5.4.4.2.3" rspace="0.222em" xref="Ch6.E6.m1.5.5.5.5.4.4.2.3.cmml">⋅</mo><mrow id="Ch6.E6.m1.5.5.5.5.4.4.2.2.1" xref="Ch6.E6.m1.5.5.5.5.4.4.2.2.2.cmml"><mo id="Ch6.E6.m1.5.5.5.5.4.4.2.2.1.2" stretchy="false" xref="Ch6.E6.m1.5.5.5.5.4.4.2.2.2.1.cmml">‖</mo><msub id="Ch6.E6.m1.5.5.5.5.4.4.2.2.1.1" xref="Ch6.E6.m1.5.5.5.5.4.4.2.2.1.1.cmml"><mi id="Ch6.E6.m1.5.5.5.5.4.4.2.2.1.1.2" xref="Ch6.E6.m1.5.5.5.5.4.4.2.2.1.1.2.cmml">q</mi><mi id="Ch6.E6.m1.5.5.5.5.4.4.2.2.1.1.3" xref="Ch6.E6.m1.5.5.5.5.4.4.2.2.1.1.3.cmml">i</mi></msub><mo id="Ch6.E6.m1.5.5.5.5.4.4.2.2.1.3" stretchy="false" xref="Ch6.E6.m1.5.5.5.5.4.4.2.2.2.1.cmml">‖</mo></mrow></mrow></mfrac></mrow><mo id="Ch6.E6.m1.6.6.6.6.5.5">,</mo></mrow></mtd></mtr><mtr id="Ch6.E6.m1.19.19.3d"><mtd class="ltx_align_right" columnalign="right" id="Ch6.E6.m1.19.19.3e"><mtext id="Ch6.E6.m1.7.7.7.1.1.1" xref="Ch6.E6.m1.7.7.7.1.1.1a.cmml">Inner product: </mtext></mtd><mtd class="ltx_align_left" columnalign="left" id="Ch6.E6.m1.19.19.3f"><mrow id="Ch6.E6.m1.19.19.3.18.11.10.10"><mrow id="Ch6.E6.m1.19.19.3.18.11.10.10.1"><msub id="Ch6.E6.m1.19.19.3.18.11.10.10.1.1"><mover accent="true" id="Ch6.E6.m1.8.8.8.2.1.1" xref="Ch6.E6.m1.8.8.8.2.1.1.cmml"><mi id="Ch6.E6.m1.8.8.8.2.1.1.2" xref="Ch6.E6.m1.8.8.8.2.1.1.2.cmml">r</mi><mo id="Ch6.E6.m1.8.8.8.2.1.1.1" xref="Ch6.E6.m1.8.8.8.2.1.1.1.cmml">^</mo></mover><mrow id="Ch6.E6.m1.9.9.9.3.2.2.1" xref="Ch6.E6.m1.9.9.9.3.2.2.1.cmml"><mi id="Ch6.E6.m1.9.9.9.3.2.2.1.2" xref="Ch6.E6.m1.9.9.9.3.2.2.1.2.cmml">u</mi><mo id="Ch6.E6.m1.9.9.9.3.2.2.1.1" xref="Ch6.E6.m1.9.9.9.3.2.2.1.1.cmml">⁢</mo><mi id="Ch6.E6.m1.9.9.9.3.2.2.1.3" xref="Ch6.E6.m1.9.9.9.3.2.2.1.3.cmml">i</mi></mrow></msub><mo id="Ch6.E6.m1.10.10.10.4.3.3" xref="Ch6.E6.m1.10.10.10.4.3.3.cmml">=</mo><mrow id="Ch6.E6.m1.19.19.3.18.11.10.10.1.2"><msubsup id="Ch6.E6.m1.19.19.3.18.11.10.10.1.2.2"><mi id="Ch6.E6.m1.11.11.11.5.4.4" xref="Ch6.E6.m1.11.11.11.5.4.4.cmml">q</mi><mi id="Ch6.E6.m1.12.12.12.6.5.5.1" xref="Ch6.E6.m1.12.12.12.6.5.5.1.cmml">i</mi><mo id="Ch6.E6.m1.13.13.13.7.6.6.1" xref="Ch6.E6.m1.13.13.13.7.6.6.1.cmml">⊤</mo></msubsup><mo id="Ch6.E6.m1.19.19.3.18.11.10.10.1.2.1">⁢</mo><msub id="Ch6.E6.m1.19.19.3.18.11.10.10.1.2.3"><mi id="Ch6.E6.m1.14.14.14.8.7.7" xref="Ch6.E6.m1.14.14.14.8.7.7.cmml">p</mi><mi id="Ch6.E6.m1.15.15.15.9.8.8.1" xref="Ch6.E6.m1.15.15.15.9.8.8.1.cmml">u</mi></msub></mrow></mrow><mo id="Ch6.E6.m1.16.16.16.10.9.9" lspace="0em">.</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="Ch6.E6.m1.19b"><apply id="Ch6.E6.m1.17.17.1.1.1.3.cmml"><csymbol cd="ambiguous" id="Ch6.E6.m1.17.17.1.1.1.3a.cmml">formulae-sequence</csymbol><apply id="Ch6.E6.m1.17.17.1.1.1.1.1.cmml"><eq id="Ch6.E6.m1.4.4.4.4.3.3.cmml" xref="Ch6.E6.m1.4.4.4.4.3.3"></eq><apply id="Ch6.E6.m1.17.17.1.1.1.1.1.2.cmml"><times id="Ch6.E6.m1.17.17.1.1.1.1.1.2.1.cmml"></times><ci id="Ch6.E6.m1.1.1.1.1.1.1a.cmml" xref="Ch6.E6.m1.1.1.1.1.1.1"><mtext id="Ch6.E6.m1.1.1.1.1.1.1.cmml" xref="Ch6.E6.m1.1.1.1.1.1.1">Cosine: </mtext></ci><apply id="Ch6.E6.m1.17.17.1.1.1.1.1.2.3.cmml"><csymbol cd="ambiguous" id="Ch6.E6.m1.17.17.1.1.1.1.1.2.3.1.cmml">subscript</csymbol><apply id="Ch6.E6.m1.2.2.2.2.1.1.cmml" xref="Ch6.E6.m1.2.2.2.2.1.1"><ci id="Ch6.E6.m1.2.2.2.2.1.1.1.cmml" xref="Ch6.E6.m1.2.2.2.2.1.1.1">^</ci><ci id="Ch6.E6.m1.2.2.2.2.1.1.2.cmml" xref="Ch6.E6.m1.2.2.2.2.1.1.2">𝑟</ci></apply><apply id="Ch6.E6.m1.3.3.3.3.2.2.1.cmml" xref="Ch6.E6.m1.3.3.3.3.2.2.1"><times id="Ch6.E6.m1.3.3.3.3.2.2.1.1.cmml" xref="Ch6.E6.m1.3.3.3.3.2.2.1.1"></times><ci id="Ch6.E6.m1.3.3.3.3.2.2.1.2.cmml" xref="Ch6.E6.m1.3.3.3.3.2.2.1.2">𝑢</ci><ci id="Ch6.E6.m1.3.3.3.3.2.2.1.3.cmml" xref="Ch6.E6.m1.3.3.3.3.2.2.1.3">𝑖</ci></apply></apply></apply><apply id="Ch6.E6.m1.5.5.5.5.4.4.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4"><divide id="Ch6.E6.m1.5.5.5.5.4.4.3.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4"></divide><apply id="Ch6.E6.m1.5.5.5.5.4.4.4.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.4"><times id="Ch6.E6.m1.5.5.5.5.4.4.4.1.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.4.1"></times><apply id="Ch6.E6.m1.5.5.5.5.4.4.4.2.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.4.2"><csymbol cd="ambiguous" id="Ch6.E6.m1.5.5.5.5.4.4.4.2.1.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.4.2">superscript</csymbol><apply id="Ch6.E6.m1.5.5.5.5.4.4.4.2.2.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.4.2"><csymbol cd="ambiguous" id="Ch6.E6.m1.5.5.5.5.4.4.4.2.2.1.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.4.2">subscript</csymbol><ci id="Ch6.E6.m1.5.5.5.5.4.4.4.2.2.2.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.4.2.2.2">𝑞</ci><ci id="Ch6.E6.m1.5.5.5.5.4.4.4.2.2.3.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.4.2.2.3">𝑖</ci></apply><csymbol cd="latexml" id="Ch6.E6.m1.5.5.5.5.4.4.4.2.3.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.4.2.3">top</csymbol></apply><apply id="Ch6.E6.m1.5.5.5.5.4.4.4.3.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.4.3"><csymbol cd="ambiguous" id="Ch6.E6.m1.5.5.5.5.4.4.4.3.1.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.4.3">subscript</csymbol><ci id="Ch6.E6.m1.5.5.5.5.4.4.4.3.2.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.4.3.2">𝑝</ci><ci id="Ch6.E6.m1.5.5.5.5.4.4.4.3.3.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.4.3.3">𝑢</ci></apply></apply><apply id="Ch6.E6.m1.5.5.5.5.4.4.2.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.2"><ci id="Ch6.E6.m1.5.5.5.5.4.4.2.3.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.2.3">⋅</ci><apply id="Ch6.E6.m1.5.5.5.5.4.4.1.1.2.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.1.1.1"><csymbol cd="latexml" id="Ch6.E6.m1.5.5.5.5.4.4.1.1.2.1.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.1.1.1.2">norm</csymbol><apply id="Ch6.E6.m1.5.5.5.5.4.4.1.1.1.1.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.1.1.1.1"><csymbol cd="ambiguous" id="Ch6.E6.m1.5.5.5.5.4.4.1.1.1.1.1.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.1.1.1.1">subscript</csymbol><ci id="Ch6.E6.m1.5.5.5.5.4.4.1.1.1.1.2.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.1.1.1.1.2">𝑝</ci><ci id="Ch6.E6.m1.5.5.5.5.4.4.1.1.1.1.3.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.1.1.1.1.3">𝑢</ci></apply></apply><apply id="Ch6.E6.m1.5.5.5.5.4.4.2.2.2.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.2.2.1"><csymbol cd="latexml" id="Ch6.E6.m1.5.5.5.5.4.4.2.2.2.1.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.2.2.1.2">norm</csymbol><apply id="Ch6.E6.m1.5.5.5.5.4.4.2.2.1.1.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.2.2.1.1"><csymbol cd="ambiguous" id="Ch6.E6.m1.5.5.5.5.4.4.2.2.1.1.1.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.2.2.1.1">subscript</csymbol><ci id="Ch6.E6.m1.5.5.5.5.4.4.2.2.1.1.2.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.2.2.1.1.2">𝑞</ci><ci id="Ch6.E6.m1.5.5.5.5.4.4.2.2.1.1.3.cmml" xref="Ch6.E6.m1.5.5.5.5.4.4.2.2.1.1.3">𝑖</ci></apply></apply></apply></apply></apply><apply id="Ch6.E6.m1.17.17.1.1.1.2.2.cmml"><eq id="Ch6.E6.m1.10.10.10.4.3.3.cmml" xref="Ch6.E6.m1.10.10.10.4.3.3"></eq><apply id="Ch6.E6.m1.17.17.1.1.1.2.2.2.cmml"><times id="Ch6.E6.m1.17.17.1.1.1.2.2.2.1.cmml"></times><ci id="Ch6.E6.m1.7.7.7.1.1.1a.cmml" xref="Ch6.E6.m1.7.7.7.1.1.1"><mtext id="Ch6.E6.m1.7.7.7.1.1.1.cmml" xref="Ch6.E6.m1.7.7.7.1.1.1">Inner product: </mtext></ci><apply id="Ch6.E6.m1.17.17.1.1.1.2.2.2.3.cmml"><csymbol cd="ambiguous" id="Ch6.E6.m1.17.17.1.1.1.2.2.2.3.1.cmml">subscript</csymbol><apply id="Ch6.E6.m1.8.8.8.2.1.1.cmml" xref="Ch6.E6.m1.8.8.8.2.1.1"><ci id="Ch6.E6.m1.8.8.8.2.1.1.1.cmml" xref="Ch6.E6.m1.8.8.8.2.1.1.1">^</ci><ci id="Ch6.E6.m1.8.8.8.2.1.1.2.cmml" xref="Ch6.E6.m1.8.8.8.2.1.1.2">𝑟</ci></apply><apply id="Ch6.E6.m1.9.9.9.3.2.2.1.cmml" xref="Ch6.E6.m1.9.9.9.3.2.2.1"><times id="Ch6.E6.m1.9.9.9.3.2.2.1.1.cmml" xref="Ch6.E6.m1.9.9.9.3.2.2.1.1"></times><ci id="Ch6.E6.m1.9.9.9.3.2.2.1.2.cmml" xref="Ch6.E6.m1.9.9.9.3.2.2.1.2">𝑢</ci><ci id="Ch6.E6.m1.9.9.9.3.2.2.1.3.cmml" xref="Ch6.E6.m1.9.9.9.3.2.2.1.3">𝑖</ci></apply></apply></apply><apply id="Ch6.E6.m1.17.17.1.1.1.2.2.3.cmml"><times id="Ch6.E6.m1.17.17.1.1.1.2.2.3.1.cmml"></times><apply id="Ch6.E6.m1.17.17.1.1.1.2.2.3.2.cmml"><csymbol cd="ambiguous" id="Ch6.E6.m1.17.17.1.1.1.2.2.3.2.1.cmml">superscript</csymbol><apply id="Ch6.E6.m1.17.17.1.1.1.2.2.3.2.2.cmml"><csymbol cd="ambiguous" id="Ch6.E6.m1.17.17.1.1.1.2.2.3.2.2.1.cmml">subscript</csymbol><ci id="Ch6.E6.m1.11.11.11.5.4.4.cmml" xref="Ch6.E6.m1.11.11.11.5.4.4">𝑞</ci><ci id="Ch6.E6.m1.12.12.12.6.5.5.1.cmml" xref="Ch6.E6.m1.12.12.12.6.5.5.1">𝑖</ci></apply><csymbol cd="latexml" id="Ch6.E6.m1.13.13.13.7.6.6.1.cmml" xref="Ch6.E6.m1.13.13.13.7.6.6.1">top</csymbol></apply><apply id="Ch6.E6.m1.17.17.1.1.1.2.2.3.3.cmml"><csymbol cd="ambiguous" id="Ch6.E6.m1.17.17.1.1.1.2.2.3.3.1.cmml">subscript</csymbol><ci id="Ch6.E6.m1.14.14.14.8.7.7.cmml" xref="Ch6.E6.m1.14.14.14.8.7.7">𝑝</ci><ci id="Ch6.E6.m1.15.15.15.9.8.8.1.cmml" xref="Ch6.E6.m1.15.15.15.9.8.8.1">𝑢</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.E6.m1.19c">\begin{split}\text{Cosine: }&amp;\hat{r}_{ui}=\frac{q_{i}^{\top}p_{u}}{\|p_{u}\|%
\cdot\|q_{i}\|},\\
\text{Inner product: }&amp;\hat{r}_{ui}=q_{i}^{\top}p_{u}.\end{split}</annotation><annotation encoding="application/x-llamapun" id="Ch6.E6.m1.19d">start_ROW start_CELL Cosine: end_CELL start_CELL over^ start_ARG italic_r end_ARG start_POSTSUBSCRIPT italic_u italic_i end_POSTSUBSCRIPT = divide start_ARG italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT end_ARG start_ARG ∥ italic_p start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT ∥ ⋅ ∥ italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∥ end_ARG , end_CELL end_ROW start_ROW start_CELL Inner product: end_CELL start_CELL over^ start_ARG italic_r end_ARG start_POSTSUBSCRIPT italic_u italic_i end_POSTSUBSCRIPT = italic_q start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT ⊤ end_POSTSUPERSCRIPT italic_p start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT . end_CELL end_ROW</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6.6)</span></td>
</tr></tbody>
</table>
</div>
<figure class="ltx_figure" id="Ch6.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="344" id="Ch6.F4.g1" src="x38.png" width="498"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6.4: </span>Illustration of the two-tower architecture for learning users’ and items’ representations. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">xu2016tag-dssm</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para ltx_noindent" id="Ch6.S2.SS2.p7">
<p class="ltx_p" id="Ch6.S2.SS2.p7.1"><span class="ltx_text ltx_font_bold" id="Ch6.S2.SS2.p7.1.1">(3) Graph-enriched embedding.</span>
A drawback of the aforementioned methods is that they regard each user or item as an “island” and fail to explicitly encode their relations into representations.
In fact, these relations, e.g., item-item occurrences or user-item interactions, are important in revealing correlations between users and items, which provide valuable signals for recommendation.
To address this problem, several studies have established specific graphs between users and items, and then conduct graph representation learning to generate user and item embeddings.
One representative method is EGES <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">EGES</span>]</cite>.
EGES constructs an item-item graph based on user behavior sequences, where two items are connected if they consecutively occur in one sequence. EGES then applies DeepWalk <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">perozzi2014deepwalk</span>]</cite> on the item graph to generate item representations.
Similarly, other related methods perform graph convolutional networks to enrich the representation learning of both users and items <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2019NGCF</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">pingsage</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">LightGCN</span>]</cite>.
The knowledge graph with informative relations between items has been exploited to learn better embeddings <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2019kgat</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2020ckan</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch6.S2.SS2.p8">
<p class="ltx_p" id="Ch6.S2.SS2.p8.4">LightGCN <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">LightGCN</span>]</cite> is a light graph neural network (GNN) model for recommendation, in which only the item and user embedding need to be learned, whereas non-linear operations are not considered.
The basic concept of LightGCN is to learn the user or item representation by aggregating the information from multi-order neighbors in the user-item interaction graph.
Assuming that the user and item embedding are <math alttext="\mathbf{e}_{u}^{0}" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p8.1.m1.1"><semantics id="Ch6.S2.SS2.p8.1.m1.1a"><msubsup id="Ch6.S2.SS2.p8.1.m1.1.1" xref="Ch6.S2.SS2.p8.1.m1.1.1.cmml"><mi id="Ch6.S2.SS2.p8.1.m1.1.1.2.2" xref="Ch6.S2.SS2.p8.1.m1.1.1.2.2.cmml">𝐞</mi><mi id="Ch6.S2.SS2.p8.1.m1.1.1.2.3" xref="Ch6.S2.SS2.p8.1.m1.1.1.2.3.cmml">u</mi><mn id="Ch6.S2.SS2.p8.1.m1.1.1.3" xref="Ch6.S2.SS2.p8.1.m1.1.1.3.cmml">0</mn></msubsup><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p8.1.m1.1b"><apply id="Ch6.S2.SS2.p8.1.m1.1.1.cmml" xref="Ch6.S2.SS2.p8.1.m1.1.1"><csymbol cd="ambiguous" id="Ch6.S2.SS2.p8.1.m1.1.1.1.cmml" xref="Ch6.S2.SS2.p8.1.m1.1.1">superscript</csymbol><apply id="Ch6.S2.SS2.p8.1.m1.1.1.2.cmml" xref="Ch6.S2.SS2.p8.1.m1.1.1"><csymbol cd="ambiguous" id="Ch6.S2.SS2.p8.1.m1.1.1.2.1.cmml" xref="Ch6.S2.SS2.p8.1.m1.1.1">subscript</csymbol><ci id="Ch6.S2.SS2.p8.1.m1.1.1.2.2.cmml" xref="Ch6.S2.SS2.p8.1.m1.1.1.2.2">𝐞</ci><ci id="Ch6.S2.SS2.p8.1.m1.1.1.2.3.cmml" xref="Ch6.S2.SS2.p8.1.m1.1.1.2.3">𝑢</ci></apply><cn id="Ch6.S2.SS2.p8.1.m1.1.1.3.cmml" type="integer" xref="Ch6.S2.SS2.p8.1.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p8.1.m1.1c">\mathbf{e}_{u}^{0}</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p8.1.m1.1d">bold_e start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT</annotation></semantics></math> and <math alttext="\mathbf{e}_{i}^{0}" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p8.2.m2.1"><semantics id="Ch6.S2.SS2.p8.2.m2.1a"><msubsup id="Ch6.S2.SS2.p8.2.m2.1.1" xref="Ch6.S2.SS2.p8.2.m2.1.1.cmml"><mi id="Ch6.S2.SS2.p8.2.m2.1.1.2.2" xref="Ch6.S2.SS2.p8.2.m2.1.1.2.2.cmml">𝐞</mi><mi id="Ch6.S2.SS2.p8.2.m2.1.1.2.3" xref="Ch6.S2.SS2.p8.2.m2.1.1.2.3.cmml">i</mi><mn id="Ch6.S2.SS2.p8.2.m2.1.1.3" xref="Ch6.S2.SS2.p8.2.m2.1.1.3.cmml">0</mn></msubsup><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p8.2.m2.1b"><apply id="Ch6.S2.SS2.p8.2.m2.1.1.cmml" xref="Ch6.S2.SS2.p8.2.m2.1.1"><csymbol cd="ambiguous" id="Ch6.S2.SS2.p8.2.m2.1.1.1.cmml" xref="Ch6.S2.SS2.p8.2.m2.1.1">superscript</csymbol><apply id="Ch6.S2.SS2.p8.2.m2.1.1.2.cmml" xref="Ch6.S2.SS2.p8.2.m2.1.1"><csymbol cd="ambiguous" id="Ch6.S2.SS2.p8.2.m2.1.1.2.1.cmml" xref="Ch6.S2.SS2.p8.2.m2.1.1">subscript</csymbol><ci id="Ch6.S2.SS2.p8.2.m2.1.1.2.2.cmml" xref="Ch6.S2.SS2.p8.2.m2.1.1.2.2">𝐞</ci><ci id="Ch6.S2.SS2.p8.2.m2.1.1.2.3.cmml" xref="Ch6.S2.SS2.p8.2.m2.1.1.2.3">𝑖</ci></apply><cn id="Ch6.S2.SS2.p8.2.m2.1.1.3.cmml" type="integer" xref="Ch6.S2.SS2.p8.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p8.2.m2.1c">\mathbf{e}_{i}^{0}</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p8.2.m2.1d">bold_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 0 end_POSTSUPERSCRIPT</annotation></semantics></math> for user <math alttext="u" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p8.3.m3.1"><semantics id="Ch6.S2.SS2.p8.3.m3.1a"><mi id="Ch6.S2.SS2.p8.3.m3.1.1" xref="Ch6.S2.SS2.p8.3.m3.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p8.3.m3.1b"><ci id="Ch6.S2.SS2.p8.3.m3.1.1.cmml" xref="Ch6.S2.SS2.p8.3.m3.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p8.3.m3.1c">u</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p8.3.m3.1d">italic_u</annotation></semantics></math> and item <math alttext="i" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p8.4.m4.1"><semantics id="Ch6.S2.SS2.p8.4.m4.1a"><mi id="Ch6.S2.SS2.p8.4.m4.1.1" xref="Ch6.S2.SS2.p8.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p8.4.m4.1b"><ci id="Ch6.S2.SS2.p8.4.m4.1.1.cmml" xref="Ch6.S2.SS2.p8.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p8.4.m4.1c">i</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p8.4.m4.1d">italic_i</annotation></semantics></math> respectively, LightGCN takes the following aggregation to get the representations of different layers:</p>
<table class="ltx_equation ltx_eqn_table" id="Ch6.E7">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathbf{e}^{k+1}_{u}=\sum_{i\in\mathcal{N}_{u}}\mathbf{e}_{i}^{k},\,\mathbf{e}%
^{k+1}_{i}=\sum_{u\in\mathcal{N}_{i}}\mathbf{e}_{u}^{k}," class="ltx_Math" display="block" id="Ch6.E7.m1.1"><semantics id="Ch6.E7.m1.1a"><mrow id="Ch6.E7.m1.1.1.1"><mrow id="Ch6.E7.m1.1.1.1.1.2" xref="Ch6.E7.m1.1.1.1.1.3.cmml"><mrow id="Ch6.E7.m1.1.1.1.1.1.1" xref="Ch6.E7.m1.1.1.1.1.1.1.cmml"><msubsup id="Ch6.E7.m1.1.1.1.1.1.1.2" xref="Ch6.E7.m1.1.1.1.1.1.1.2.cmml"><mi id="Ch6.E7.m1.1.1.1.1.1.1.2.2.2" xref="Ch6.E7.m1.1.1.1.1.1.1.2.2.2.cmml">𝐞</mi><mi id="Ch6.E7.m1.1.1.1.1.1.1.2.3" xref="Ch6.E7.m1.1.1.1.1.1.1.2.3.cmml">u</mi><mrow id="Ch6.E7.m1.1.1.1.1.1.1.2.2.3" xref="Ch6.E7.m1.1.1.1.1.1.1.2.2.3.cmml"><mi id="Ch6.E7.m1.1.1.1.1.1.1.2.2.3.2" xref="Ch6.E7.m1.1.1.1.1.1.1.2.2.3.2.cmml">k</mi><mo id="Ch6.E7.m1.1.1.1.1.1.1.2.2.3.1" xref="Ch6.E7.m1.1.1.1.1.1.1.2.2.3.1.cmml">+</mo><mn id="Ch6.E7.m1.1.1.1.1.1.1.2.2.3.3" xref="Ch6.E7.m1.1.1.1.1.1.1.2.2.3.3.cmml">1</mn></mrow></msubsup><mo id="Ch6.E7.m1.1.1.1.1.1.1.1" rspace="0.111em" xref="Ch6.E7.m1.1.1.1.1.1.1.1.cmml">=</mo><mrow id="Ch6.E7.m1.1.1.1.1.1.1.3" xref="Ch6.E7.m1.1.1.1.1.1.1.3.cmml"><munder id="Ch6.E7.m1.1.1.1.1.1.1.3.1" xref="Ch6.E7.m1.1.1.1.1.1.1.3.1.cmml"><mo id="Ch6.E7.m1.1.1.1.1.1.1.3.1.2" movablelimits="false" xref="Ch6.E7.m1.1.1.1.1.1.1.3.1.2.cmml">∑</mo><mrow id="Ch6.E7.m1.1.1.1.1.1.1.3.1.3" xref="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.cmml"><mi id="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.2" xref="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.2.cmml">i</mi><mo id="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.1" xref="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.1.cmml">∈</mo><msub id="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.3" xref="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.3.2" xref="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.3.2.cmml">𝒩</mi><mi id="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.3.3" xref="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.3.3.cmml">u</mi></msub></mrow></munder><msubsup id="Ch6.E7.m1.1.1.1.1.1.1.3.2" xref="Ch6.E7.m1.1.1.1.1.1.1.3.2.cmml"><mi id="Ch6.E7.m1.1.1.1.1.1.1.3.2.2.2" xref="Ch6.E7.m1.1.1.1.1.1.1.3.2.2.2.cmml">𝐞</mi><mi id="Ch6.E7.m1.1.1.1.1.1.1.3.2.2.3" xref="Ch6.E7.m1.1.1.1.1.1.1.3.2.2.3.cmml">i</mi><mi id="Ch6.E7.m1.1.1.1.1.1.1.3.2.3" xref="Ch6.E7.m1.1.1.1.1.1.1.3.2.3.cmml">k</mi></msubsup></mrow></mrow><mo id="Ch6.E7.m1.1.1.1.1.2.3" rspace="0.337em" xref="Ch6.E7.m1.1.1.1.1.3a.cmml">,</mo><mrow id="Ch6.E7.m1.1.1.1.1.2.2" xref="Ch6.E7.m1.1.1.1.1.2.2.cmml"><msubsup id="Ch6.E7.m1.1.1.1.1.2.2.2" xref="Ch6.E7.m1.1.1.1.1.2.2.2.cmml"><mi id="Ch6.E7.m1.1.1.1.1.2.2.2.2.2" xref="Ch6.E7.m1.1.1.1.1.2.2.2.2.2.cmml">𝐞</mi><mi id="Ch6.E7.m1.1.1.1.1.2.2.2.3" xref="Ch6.E7.m1.1.1.1.1.2.2.2.3.cmml">i</mi><mrow id="Ch6.E7.m1.1.1.1.1.2.2.2.2.3" xref="Ch6.E7.m1.1.1.1.1.2.2.2.2.3.cmml"><mi id="Ch6.E7.m1.1.1.1.1.2.2.2.2.3.2" xref="Ch6.E7.m1.1.1.1.1.2.2.2.2.3.2.cmml">k</mi><mo id="Ch6.E7.m1.1.1.1.1.2.2.2.2.3.1" xref="Ch6.E7.m1.1.1.1.1.2.2.2.2.3.1.cmml">+</mo><mn id="Ch6.E7.m1.1.1.1.1.2.2.2.2.3.3" xref="Ch6.E7.m1.1.1.1.1.2.2.2.2.3.3.cmml">1</mn></mrow></msubsup><mo id="Ch6.E7.m1.1.1.1.1.2.2.1" rspace="0.111em" xref="Ch6.E7.m1.1.1.1.1.2.2.1.cmml">=</mo><mrow id="Ch6.E7.m1.1.1.1.1.2.2.3" xref="Ch6.E7.m1.1.1.1.1.2.2.3.cmml"><munder id="Ch6.E7.m1.1.1.1.1.2.2.3.1" xref="Ch6.E7.m1.1.1.1.1.2.2.3.1.cmml"><mo id="Ch6.E7.m1.1.1.1.1.2.2.3.1.2" movablelimits="false" xref="Ch6.E7.m1.1.1.1.1.2.2.3.1.2.cmml">∑</mo><mrow id="Ch6.E7.m1.1.1.1.1.2.2.3.1.3" xref="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.cmml"><mi id="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.2" xref="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.2.cmml">u</mi><mo id="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.1" xref="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.1.cmml">∈</mo><msub id="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.3" xref="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.3.2" xref="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.3.2.cmml">𝒩</mi><mi id="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.3.3" xref="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.3.3.cmml">i</mi></msub></mrow></munder><msubsup id="Ch6.E7.m1.1.1.1.1.2.2.3.2" xref="Ch6.E7.m1.1.1.1.1.2.2.3.2.cmml"><mi id="Ch6.E7.m1.1.1.1.1.2.2.3.2.2.2" xref="Ch6.E7.m1.1.1.1.1.2.2.3.2.2.2.cmml">𝐞</mi><mi id="Ch6.E7.m1.1.1.1.1.2.2.3.2.2.3" xref="Ch6.E7.m1.1.1.1.1.2.2.3.2.2.3.cmml">u</mi><mi id="Ch6.E7.m1.1.1.1.1.2.2.3.2.3" xref="Ch6.E7.m1.1.1.1.1.2.2.3.2.3.cmml">k</mi></msubsup></mrow></mrow></mrow><mo id="Ch6.E7.m1.1.1.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch6.E7.m1.1b"><apply id="Ch6.E7.m1.1.1.1.1.3.cmml" xref="Ch6.E7.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="Ch6.E7.m1.1.1.1.1.3a.cmml" xref="Ch6.E7.m1.1.1.1.1.2.3">formulae-sequence</csymbol><apply id="Ch6.E7.m1.1.1.1.1.1.1.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1"><eq id="Ch6.E7.m1.1.1.1.1.1.1.1.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.1"></eq><apply id="Ch6.E7.m1.1.1.1.1.1.1.2.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="Ch6.E7.m1.1.1.1.1.1.1.2.1.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.2">subscript</csymbol><apply id="Ch6.E7.m1.1.1.1.1.1.1.2.2.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="Ch6.E7.m1.1.1.1.1.1.1.2.2.1.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.2">superscript</csymbol><ci id="Ch6.E7.m1.1.1.1.1.1.1.2.2.2.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.2.2.2">𝐞</ci><apply id="Ch6.E7.m1.1.1.1.1.1.1.2.2.3.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.2.2.3"><plus id="Ch6.E7.m1.1.1.1.1.1.1.2.2.3.1.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.2.2.3.1"></plus><ci id="Ch6.E7.m1.1.1.1.1.1.1.2.2.3.2.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.2.2.3.2">𝑘</ci><cn id="Ch6.E7.m1.1.1.1.1.1.1.2.2.3.3.cmml" type="integer" xref="Ch6.E7.m1.1.1.1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="Ch6.E7.m1.1.1.1.1.1.1.2.3.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.2.3">𝑢</ci></apply><apply id="Ch6.E7.m1.1.1.1.1.1.1.3.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.3"><apply id="Ch6.E7.m1.1.1.1.1.1.1.3.1.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="Ch6.E7.m1.1.1.1.1.1.1.3.1.1.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.3.1">subscript</csymbol><sum id="Ch6.E7.m1.1.1.1.1.1.1.3.1.2.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.3.1.2"></sum><apply id="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.3.1.3"><in id="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.1.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.1"></in><ci id="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.2.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.2">𝑖</ci><apply id="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.3.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.3"><csymbol cd="ambiguous" id="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.3.1.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.3">subscript</csymbol><ci id="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.3.2.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.3.2">𝒩</ci><ci id="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.3.3.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.3.1.3.3.3">𝑢</ci></apply></apply></apply><apply id="Ch6.E7.m1.1.1.1.1.1.1.3.2.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="Ch6.E7.m1.1.1.1.1.1.1.3.2.1.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.3.2">superscript</csymbol><apply id="Ch6.E7.m1.1.1.1.1.1.1.3.2.2.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="Ch6.E7.m1.1.1.1.1.1.1.3.2.2.1.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.3.2">subscript</csymbol><ci id="Ch6.E7.m1.1.1.1.1.1.1.3.2.2.2.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.3.2.2.2">𝐞</ci><ci id="Ch6.E7.m1.1.1.1.1.1.1.3.2.2.3.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.3.2.2.3">𝑖</ci></apply><ci id="Ch6.E7.m1.1.1.1.1.1.1.3.2.3.cmml" xref="Ch6.E7.m1.1.1.1.1.1.1.3.2.3">𝑘</ci></apply></apply></apply><apply id="Ch6.E7.m1.1.1.1.1.2.2.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2"><eq id="Ch6.E7.m1.1.1.1.1.2.2.1.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.1"></eq><apply id="Ch6.E7.m1.1.1.1.1.2.2.2.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="Ch6.E7.m1.1.1.1.1.2.2.2.1.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.2">subscript</csymbol><apply id="Ch6.E7.m1.1.1.1.1.2.2.2.2.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="Ch6.E7.m1.1.1.1.1.2.2.2.2.1.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.2">superscript</csymbol><ci id="Ch6.E7.m1.1.1.1.1.2.2.2.2.2.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.2.2.2">𝐞</ci><apply id="Ch6.E7.m1.1.1.1.1.2.2.2.2.3.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.2.2.3"><plus id="Ch6.E7.m1.1.1.1.1.2.2.2.2.3.1.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.2.2.3.1"></plus><ci id="Ch6.E7.m1.1.1.1.1.2.2.2.2.3.2.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.2.2.3.2">𝑘</ci><cn id="Ch6.E7.m1.1.1.1.1.2.2.2.2.3.3.cmml" type="integer" xref="Ch6.E7.m1.1.1.1.1.2.2.2.2.3.3">1</cn></apply></apply><ci id="Ch6.E7.m1.1.1.1.1.2.2.2.3.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.2.3">𝑖</ci></apply><apply id="Ch6.E7.m1.1.1.1.1.2.2.3.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.3"><apply id="Ch6.E7.m1.1.1.1.1.2.2.3.1.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.3.1"><csymbol cd="ambiguous" id="Ch6.E7.m1.1.1.1.1.2.2.3.1.1.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.3.1">subscript</csymbol><sum id="Ch6.E7.m1.1.1.1.1.2.2.3.1.2.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.3.1.2"></sum><apply id="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.3.1.3"><in id="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.1.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.1"></in><ci id="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.2.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.2">𝑢</ci><apply id="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.3.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.3"><csymbol cd="ambiguous" id="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.3.1.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.3">subscript</csymbol><ci id="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.3.2.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.3.2">𝒩</ci><ci id="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.3.3.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.3.1.3.3.3">𝑖</ci></apply></apply></apply><apply id="Ch6.E7.m1.1.1.1.1.2.2.3.2.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.3.2"><csymbol cd="ambiguous" id="Ch6.E7.m1.1.1.1.1.2.2.3.2.1.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.3.2">superscript</csymbol><apply id="Ch6.E7.m1.1.1.1.1.2.2.3.2.2.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.3.2"><csymbol cd="ambiguous" id="Ch6.E7.m1.1.1.1.1.2.2.3.2.2.1.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.3.2">subscript</csymbol><ci id="Ch6.E7.m1.1.1.1.1.2.2.3.2.2.2.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.3.2.2.2">𝐞</ci><ci id="Ch6.E7.m1.1.1.1.1.2.2.3.2.2.3.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.3.2.2.3">𝑢</ci></apply><ci id="Ch6.E7.m1.1.1.1.1.2.2.3.2.3.cmml" xref="Ch6.E7.m1.1.1.1.1.2.2.3.2.3">𝑘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.E7.m1.1c">\mathbf{e}^{k+1}_{u}=\sum_{i\in\mathcal{N}_{u}}\mathbf{e}_{i}^{k},\,\mathbf{e}%
^{k+1}_{i}=\sum_{u\in\mathcal{N}_{i}}\mathbf{e}_{u}^{k},</annotation><annotation encoding="application/x-llamapun" id="Ch6.E7.m1.1d">bold_e start_POSTSUPERSCRIPT italic_k + 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT = ∑ start_POSTSUBSCRIPT italic_i ∈ caligraphic_N start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT end_POSTSUBSCRIPT bold_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT , bold_e start_POSTSUPERSCRIPT italic_k + 1 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = ∑ start_POSTSUBSCRIPT italic_u ∈ caligraphic_N start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT end_POSTSUBSCRIPT bold_e start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6.7)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch6.S2.SS2.p8.10">where <math alttext="k" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p8.5.m1.1"><semantics id="Ch6.S2.SS2.p8.5.m1.1a"><mi id="Ch6.S2.SS2.p8.5.m1.1.1" xref="Ch6.S2.SS2.p8.5.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p8.5.m1.1b"><ci id="Ch6.S2.SS2.p8.5.m1.1.1.cmml" xref="Ch6.S2.SS2.p8.5.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p8.5.m1.1c">k</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p8.5.m1.1d">italic_k</annotation></semantics></math> represents the <math alttext="k" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p8.6.m2.1"><semantics id="Ch6.S2.SS2.p8.6.m2.1a"><mi id="Ch6.S2.SS2.p8.6.m2.1.1" xref="Ch6.S2.SS2.p8.6.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p8.6.m2.1b"><ci id="Ch6.S2.SS2.p8.6.m2.1.1.cmml" xref="Ch6.S2.SS2.p8.6.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p8.6.m2.1c">k</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p8.6.m2.1d">italic_k</annotation></semantics></math>-th layer, <math alttext="\mathcal{N}_{u}" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p8.7.m3.1"><semantics id="Ch6.S2.SS2.p8.7.m3.1a"><msub id="Ch6.S2.SS2.p8.7.m3.1.1" xref="Ch6.S2.SS2.p8.7.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Ch6.S2.SS2.p8.7.m3.1.1.2" xref="Ch6.S2.SS2.p8.7.m3.1.1.2.cmml">𝒩</mi><mi id="Ch6.S2.SS2.p8.7.m3.1.1.3" xref="Ch6.S2.SS2.p8.7.m3.1.1.3.cmml">u</mi></msub><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p8.7.m3.1b"><apply id="Ch6.S2.SS2.p8.7.m3.1.1.cmml" xref="Ch6.S2.SS2.p8.7.m3.1.1"><csymbol cd="ambiguous" id="Ch6.S2.SS2.p8.7.m3.1.1.1.cmml" xref="Ch6.S2.SS2.p8.7.m3.1.1">subscript</csymbol><ci id="Ch6.S2.SS2.p8.7.m3.1.1.2.cmml" xref="Ch6.S2.SS2.p8.7.m3.1.1.2">𝒩</ci><ci id="Ch6.S2.SS2.p8.7.m3.1.1.3.cmml" xref="Ch6.S2.SS2.p8.7.m3.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p8.7.m3.1c">\mathcal{N}_{u}</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p8.7.m3.1d">caligraphic_N start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT</annotation></semantics></math> represents the neighbors of user <math alttext="u" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p8.8.m4.1"><semantics id="Ch6.S2.SS2.p8.8.m4.1a"><mi id="Ch6.S2.SS2.p8.8.m4.1.1" xref="Ch6.S2.SS2.p8.8.m4.1.1.cmml">u</mi><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p8.8.m4.1b"><ci id="Ch6.S2.SS2.p8.8.m4.1.1.cmml" xref="Ch6.S2.SS2.p8.8.m4.1.1">𝑢</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p8.8.m4.1c">u</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p8.8.m4.1d">italic_u</annotation></semantics></math>, and <math alttext="\mathcal{N}_{i}" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p8.9.m5.1"><semantics id="Ch6.S2.SS2.p8.9.m5.1a"><msub id="Ch6.S2.SS2.p8.9.m5.1.1" xref="Ch6.S2.SS2.p8.9.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Ch6.S2.SS2.p8.9.m5.1.1.2" xref="Ch6.S2.SS2.p8.9.m5.1.1.2.cmml">𝒩</mi><mi id="Ch6.S2.SS2.p8.9.m5.1.1.3" xref="Ch6.S2.SS2.p8.9.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p8.9.m5.1b"><apply id="Ch6.S2.SS2.p8.9.m5.1.1.cmml" xref="Ch6.S2.SS2.p8.9.m5.1.1"><csymbol cd="ambiguous" id="Ch6.S2.SS2.p8.9.m5.1.1.1.cmml" xref="Ch6.S2.SS2.p8.9.m5.1.1">subscript</csymbol><ci id="Ch6.S2.SS2.p8.9.m5.1.1.2.cmml" xref="Ch6.S2.SS2.p8.9.m5.1.1.2">𝒩</ci><ci id="Ch6.S2.SS2.p8.9.m5.1.1.3.cmml" xref="Ch6.S2.SS2.p8.9.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p8.9.m5.1c">\mathcal{N}_{i}</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p8.9.m5.1d">caligraphic_N start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> represents the neighbors of item <math alttext="i" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p8.10.m6.1"><semantics id="Ch6.S2.SS2.p8.10.m6.1a"><mi id="Ch6.S2.SS2.p8.10.m6.1.1" xref="Ch6.S2.SS2.p8.10.m6.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p8.10.m6.1b"><ci id="Ch6.S2.SS2.p8.10.m6.1.1.cmml" xref="Ch6.S2.SS2.p8.10.m6.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p8.10.m6.1c">i</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p8.10.m6.1d">italic_i</annotation></semantics></math>.
Then, the final representation of users and items are computed as follows:</p>
<table class="ltx_equation ltx_eqn_table" id="Ch6.E8">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathbf{e}_{u}=\sum_{k=0}^{K}\alpha_{k}\mathbf{e}_{u}^{k},\,\mathbf{e}_{i}=%
\sum_{k=0}^{K}\alpha_{k}\mathbf{e}_{i}^{k}," class="ltx_Math" display="block" id="Ch6.E8.m1.1"><semantics id="Ch6.E8.m1.1a"><mrow id="Ch6.E8.m1.1.1.1"><mrow id="Ch6.E8.m1.1.1.1.1.2" xref="Ch6.E8.m1.1.1.1.1.3.cmml"><mrow id="Ch6.E8.m1.1.1.1.1.1.1" xref="Ch6.E8.m1.1.1.1.1.1.1.cmml"><msub id="Ch6.E8.m1.1.1.1.1.1.1.2" xref="Ch6.E8.m1.1.1.1.1.1.1.2.cmml"><mi id="Ch6.E8.m1.1.1.1.1.1.1.2.2" xref="Ch6.E8.m1.1.1.1.1.1.1.2.2.cmml">𝐞</mi><mi id="Ch6.E8.m1.1.1.1.1.1.1.2.3" xref="Ch6.E8.m1.1.1.1.1.1.1.2.3.cmml">u</mi></msub><mo id="Ch6.E8.m1.1.1.1.1.1.1.1" rspace="0.111em" xref="Ch6.E8.m1.1.1.1.1.1.1.1.cmml">=</mo><mrow id="Ch6.E8.m1.1.1.1.1.1.1.3" xref="Ch6.E8.m1.1.1.1.1.1.1.3.cmml"><munderover id="Ch6.E8.m1.1.1.1.1.1.1.3.1" xref="Ch6.E8.m1.1.1.1.1.1.1.3.1.cmml"><mo id="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.2" movablelimits="false" xref="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.2.cmml">∑</mo><mrow id="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.3" xref="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.3.cmml"><mi id="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.3.2" xref="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.3.2.cmml">k</mi><mo id="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.3.1" xref="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.3.1.cmml">=</mo><mn id="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.3.3" xref="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.3.3.cmml">0</mn></mrow><mi id="Ch6.E8.m1.1.1.1.1.1.1.3.1.3" xref="Ch6.E8.m1.1.1.1.1.1.1.3.1.3.cmml">K</mi></munderover><mrow id="Ch6.E8.m1.1.1.1.1.1.1.3.2" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2.cmml"><msub id="Ch6.E8.m1.1.1.1.1.1.1.3.2.2" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2.2.cmml"><mi id="Ch6.E8.m1.1.1.1.1.1.1.3.2.2.2" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2.2.2.cmml">α</mi><mi id="Ch6.E8.m1.1.1.1.1.1.1.3.2.2.3" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2.2.3.cmml">k</mi></msub><mo id="Ch6.E8.m1.1.1.1.1.1.1.3.2.1" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2.1.cmml">⁢</mo><msubsup id="Ch6.E8.m1.1.1.1.1.1.1.3.2.3" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2.3.cmml"><mi id="Ch6.E8.m1.1.1.1.1.1.1.3.2.3.2.2" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2.3.2.2.cmml">𝐞</mi><mi id="Ch6.E8.m1.1.1.1.1.1.1.3.2.3.2.3" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2.3.2.3.cmml">u</mi><mi id="Ch6.E8.m1.1.1.1.1.1.1.3.2.3.3" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2.3.3.cmml">k</mi></msubsup></mrow></mrow></mrow><mo id="Ch6.E8.m1.1.1.1.1.2.3" rspace="0.337em" xref="Ch6.E8.m1.1.1.1.1.3a.cmml">,</mo><mrow id="Ch6.E8.m1.1.1.1.1.2.2" xref="Ch6.E8.m1.1.1.1.1.2.2.cmml"><msub id="Ch6.E8.m1.1.1.1.1.2.2.2" xref="Ch6.E8.m1.1.1.1.1.2.2.2.cmml"><mi id="Ch6.E8.m1.1.1.1.1.2.2.2.2" xref="Ch6.E8.m1.1.1.1.1.2.2.2.2.cmml">𝐞</mi><mi id="Ch6.E8.m1.1.1.1.1.2.2.2.3" xref="Ch6.E8.m1.1.1.1.1.2.2.2.3.cmml">i</mi></msub><mo id="Ch6.E8.m1.1.1.1.1.2.2.1" rspace="0.111em" xref="Ch6.E8.m1.1.1.1.1.2.2.1.cmml">=</mo><mrow id="Ch6.E8.m1.1.1.1.1.2.2.3" xref="Ch6.E8.m1.1.1.1.1.2.2.3.cmml"><munderover id="Ch6.E8.m1.1.1.1.1.2.2.3.1" xref="Ch6.E8.m1.1.1.1.1.2.2.3.1.cmml"><mo id="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.2" movablelimits="false" xref="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.2.cmml">∑</mo><mrow id="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.3" xref="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.3.cmml"><mi id="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.3.2" xref="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.3.2.cmml">k</mi><mo id="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.3.1" xref="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.3.1.cmml">=</mo><mn id="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.3.3" xref="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.3.3.cmml">0</mn></mrow><mi id="Ch6.E8.m1.1.1.1.1.2.2.3.1.3" xref="Ch6.E8.m1.1.1.1.1.2.2.3.1.3.cmml">K</mi></munderover><mrow id="Ch6.E8.m1.1.1.1.1.2.2.3.2" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2.cmml"><msub id="Ch6.E8.m1.1.1.1.1.2.2.3.2.2" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2.2.cmml"><mi id="Ch6.E8.m1.1.1.1.1.2.2.3.2.2.2" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2.2.2.cmml">α</mi><mi id="Ch6.E8.m1.1.1.1.1.2.2.3.2.2.3" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2.2.3.cmml">k</mi></msub><mo id="Ch6.E8.m1.1.1.1.1.2.2.3.2.1" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2.1.cmml">⁢</mo><msubsup id="Ch6.E8.m1.1.1.1.1.2.2.3.2.3" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2.3.cmml"><mi id="Ch6.E8.m1.1.1.1.1.2.2.3.2.3.2.2" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2.3.2.2.cmml">𝐞</mi><mi id="Ch6.E8.m1.1.1.1.1.2.2.3.2.3.2.3" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2.3.2.3.cmml">i</mi><mi id="Ch6.E8.m1.1.1.1.1.2.2.3.2.3.3" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2.3.3.cmml">k</mi></msubsup></mrow></mrow></mrow></mrow><mo id="Ch6.E8.m1.1.1.1.2">,</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch6.E8.m1.1b"><apply id="Ch6.E8.m1.1.1.1.1.3.cmml" xref="Ch6.E8.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="Ch6.E8.m1.1.1.1.1.3a.cmml" xref="Ch6.E8.m1.1.1.1.1.2.3">formulae-sequence</csymbol><apply id="Ch6.E8.m1.1.1.1.1.1.1.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1"><eq id="Ch6.E8.m1.1.1.1.1.1.1.1.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.1"></eq><apply id="Ch6.E8.m1.1.1.1.1.1.1.2.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="Ch6.E8.m1.1.1.1.1.1.1.2.1.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.2">subscript</csymbol><ci id="Ch6.E8.m1.1.1.1.1.1.1.2.2.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.2.2">𝐞</ci><ci id="Ch6.E8.m1.1.1.1.1.1.1.2.3.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.2.3">𝑢</ci></apply><apply id="Ch6.E8.m1.1.1.1.1.1.1.3.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3"><apply id="Ch6.E8.m1.1.1.1.1.1.1.3.1.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="Ch6.E8.m1.1.1.1.1.1.1.3.1.1.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.1">superscript</csymbol><apply id="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.1.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.1">subscript</csymbol><sum id="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.2.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.2"></sum><apply id="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.3.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.3"><eq id="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.3.1.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.3.1"></eq><ci id="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.3.2.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.3.2">𝑘</ci><cn id="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.3.3.cmml" type="integer" xref="Ch6.E8.m1.1.1.1.1.1.1.3.1.2.3.3">0</cn></apply></apply><ci id="Ch6.E8.m1.1.1.1.1.1.1.3.1.3.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.1.3">𝐾</ci></apply><apply id="Ch6.E8.m1.1.1.1.1.1.1.3.2.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2"><times id="Ch6.E8.m1.1.1.1.1.1.1.3.2.1.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2.1"></times><apply id="Ch6.E8.m1.1.1.1.1.1.1.3.2.2.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2.2"><csymbol cd="ambiguous" id="Ch6.E8.m1.1.1.1.1.1.1.3.2.2.1.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2.2">subscript</csymbol><ci id="Ch6.E8.m1.1.1.1.1.1.1.3.2.2.2.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2.2.2">𝛼</ci><ci id="Ch6.E8.m1.1.1.1.1.1.1.3.2.2.3.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2.2.3">𝑘</ci></apply><apply id="Ch6.E8.m1.1.1.1.1.1.1.3.2.3.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="Ch6.E8.m1.1.1.1.1.1.1.3.2.3.1.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2.3">superscript</csymbol><apply id="Ch6.E8.m1.1.1.1.1.1.1.3.2.3.2.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="Ch6.E8.m1.1.1.1.1.1.1.3.2.3.2.1.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2.3">subscript</csymbol><ci id="Ch6.E8.m1.1.1.1.1.1.1.3.2.3.2.2.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2.3.2.2">𝐞</ci><ci id="Ch6.E8.m1.1.1.1.1.1.1.3.2.3.2.3.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2.3.2.3">𝑢</ci></apply><ci id="Ch6.E8.m1.1.1.1.1.1.1.3.2.3.3.cmml" xref="Ch6.E8.m1.1.1.1.1.1.1.3.2.3.3">𝑘</ci></apply></apply></apply></apply><apply id="Ch6.E8.m1.1.1.1.1.2.2.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2"><eq id="Ch6.E8.m1.1.1.1.1.2.2.1.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.1"></eq><apply id="Ch6.E8.m1.1.1.1.1.2.2.2.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="Ch6.E8.m1.1.1.1.1.2.2.2.1.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.2">subscript</csymbol><ci id="Ch6.E8.m1.1.1.1.1.2.2.2.2.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.2.2">𝐞</ci><ci id="Ch6.E8.m1.1.1.1.1.2.2.2.3.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.2.3">𝑖</ci></apply><apply id="Ch6.E8.m1.1.1.1.1.2.2.3.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3"><apply id="Ch6.E8.m1.1.1.1.1.2.2.3.1.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.1"><csymbol cd="ambiguous" id="Ch6.E8.m1.1.1.1.1.2.2.3.1.1.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.1">superscript</csymbol><apply id="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.1"><csymbol cd="ambiguous" id="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.1.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.1">subscript</csymbol><sum id="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.2.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.2"></sum><apply id="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.3.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.3"><eq id="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.3.1.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.3.1"></eq><ci id="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.3.2.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.3.2">𝑘</ci><cn id="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.3.3.cmml" type="integer" xref="Ch6.E8.m1.1.1.1.1.2.2.3.1.2.3.3">0</cn></apply></apply><ci id="Ch6.E8.m1.1.1.1.1.2.2.3.1.3.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.1.3">𝐾</ci></apply><apply id="Ch6.E8.m1.1.1.1.1.2.2.3.2.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2"><times id="Ch6.E8.m1.1.1.1.1.2.2.3.2.1.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2.1"></times><apply id="Ch6.E8.m1.1.1.1.1.2.2.3.2.2.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2.2"><csymbol cd="ambiguous" id="Ch6.E8.m1.1.1.1.1.2.2.3.2.2.1.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2.2">subscript</csymbol><ci id="Ch6.E8.m1.1.1.1.1.2.2.3.2.2.2.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2.2.2">𝛼</ci><ci id="Ch6.E8.m1.1.1.1.1.2.2.3.2.2.3.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2.2.3">𝑘</ci></apply><apply id="Ch6.E8.m1.1.1.1.1.2.2.3.2.3.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2.3"><csymbol cd="ambiguous" id="Ch6.E8.m1.1.1.1.1.2.2.3.2.3.1.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2.3">superscript</csymbol><apply id="Ch6.E8.m1.1.1.1.1.2.2.3.2.3.2.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2.3"><csymbol cd="ambiguous" id="Ch6.E8.m1.1.1.1.1.2.2.3.2.3.2.1.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2.3">subscript</csymbol><ci id="Ch6.E8.m1.1.1.1.1.2.2.3.2.3.2.2.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2.3.2.2">𝐞</ci><ci id="Ch6.E8.m1.1.1.1.1.2.2.3.2.3.2.3.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2.3.2.3">𝑖</ci></apply><ci id="Ch6.E8.m1.1.1.1.1.2.2.3.2.3.3.cmml" xref="Ch6.E8.m1.1.1.1.1.2.2.3.2.3.3">𝑘</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.E8.m1.1c">\mathbf{e}_{u}=\sum_{k=0}^{K}\alpha_{k}\mathbf{e}_{u}^{k},\,\mathbf{e}_{i}=%
\sum_{k=0}^{K}\alpha_{k}\mathbf{e}_{i}^{k},</annotation><annotation encoding="application/x-llamapun" id="Ch6.E8.m1.1d">bold_e start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT = ∑ start_POSTSUBSCRIPT italic_k = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT italic_α start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT bold_e start_POSTSUBSCRIPT italic_u end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT , bold_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT = ∑ start_POSTSUBSCRIPT italic_k = 0 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_K end_POSTSUPERSCRIPT italic_α start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT bold_e start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6.8)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch6.S2.SS2.p8.11">where <math alttext="a_{k}" class="ltx_Math" display="inline" id="Ch6.S2.SS2.p8.11.m1.1"><semantics id="Ch6.S2.SS2.p8.11.m1.1a"><msub id="Ch6.S2.SS2.p8.11.m1.1.1" xref="Ch6.S2.SS2.p8.11.m1.1.1.cmml"><mi id="Ch6.S2.SS2.p8.11.m1.1.1.2" xref="Ch6.S2.SS2.p8.11.m1.1.1.2.cmml">a</mi><mi id="Ch6.S2.SS2.p8.11.m1.1.1.3" xref="Ch6.S2.SS2.p8.11.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="Ch6.S2.SS2.p8.11.m1.1b"><apply id="Ch6.S2.SS2.p8.11.m1.1.1.cmml" xref="Ch6.S2.SS2.p8.11.m1.1.1"><csymbol cd="ambiguous" id="Ch6.S2.SS2.p8.11.m1.1.1.1.cmml" xref="Ch6.S2.SS2.p8.11.m1.1.1">subscript</csymbol><ci id="Ch6.S2.SS2.p8.11.m1.1.1.2.cmml" xref="Ch6.S2.SS2.p8.11.m1.1.1.2">𝑎</ci><ci id="Ch6.S2.SS2.p8.11.m1.1.1.3.cmml" xref="Ch6.S2.SS2.p8.11.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S2.SS2.p8.11.m1.1c">a_{k}</annotation><annotation encoding="application/x-llamapun" id="Ch6.S2.SS2.p8.11.m1.1d">italic_a start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math> is a hyper-parameter to control the contributions of different layers.
Eventually, it takes the dot product of the two representations as the prediction score.</p>
</div>
<div class="ltx_para" id="Ch6.S2.SS2.p9">
<p class="ltx_p" id="Ch6.S2.SS2.p9.1">The quality of data affects the upper bound of the performance of the learning-based models. However, user behavior data in e-commerce recommendation is usually very sparse.
To address this problem, data augmentation is a common strategy to increase the diversity of data.
SGL <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wu202SGL</span>]</cite> designs three types of methods to augment the training data for graph-based methods. The augmented data is used for an additional unsupervised task which maximizes the agreement of positive pairs.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch6.S2.SS3">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2.3 </span>Session-based recommendation</h4>
<div class="ltx_para" id="Ch6.S2.SS3.p1">
<p class="ltx_p" id="Ch6.S2.SS3.p1.1">Modeling sequential dynamics is important for candidate retrieval in e-commerce recommendation. Sequential (or session-based) recommendation takes behavior sequences as the input, and then predicts the user’s next click or purchase behavior.
Sequential methods can be grouped into two classes: Markov chain-based and neural network-based sequential recommendation methods.
</p>
</div>
<div class="ltx_para" id="Ch6.S2.SS3.p2">
<p class="ltx_p" id="Ch6.S2.SS3.p2.1">Early studies on sequential recommendation methods often use Markov chains by assuming that the user’s next action only depends on the previous one.
As a representative method, the factorizing personalized Markov chains model (FPMC) extends MF by modeling the effects of sequential-consecutive actions <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">FPMC</span>]</cite>.
Since the previous action is indeed a critical factor affecting the user’s next decision, FPMC achieves a significant gain over MF-based models.
Following FPMC, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">he2016fusing</span></cite> leverage a higher-order Markov chain to capture the sequential dependence among non-consecutive behavior.
it is hard to use Markov chain-based methods for capturing complicated and long-term dependencies in sequential data, and this limits their performance in e-commerce recommendation.</p>
</div>
<div class="ltx_para" id="Ch6.S2.SS3.p3">
<p class="ltx_p" id="Ch6.S2.SS3.p3.1">More recently, deep neural networks have been leveraged in sequential recommendation due to its powerful expressive ability on capturing behavior dependences (discussed in Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4" title="Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4</span></a>).
Generally speaking, neural networks for sequential recommendation can be divided into three types:

<span class="ltx_inline-enumerate" id="Ch6.S2.I4">
<span class="ltx_inline-item" id="Ch6.S2.I4.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch6.S2.I4.i1.1">RNN-based methods that model sequential dependence with RNN (or improved versions such as LSTM and GRU) to capture both long-term and short-term dependencies <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">quadrana2017personalizing</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">jannach2017recurrent</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hidasi2016parallel</span>]</cite>;
</span></span>
<span class="ltx_inline-item" id="Ch6.S2.I4.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch6.S2.I4.i2.1">CNN-based methods that concatenates the embedding of previous item in a sequence as to a matrix <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">tang2018personalized</span>]</cite>; and
</span></span>
<span class="ltx_inline-item" id="Ch6.S2.I4.i3"><span class="ltx_tag ltx_tag_inline-item">(iii)</span> <span class="ltx_text" id="Ch6.S2.I4.i3.1">attention-based methods that introduce attention mechanism into sequential recommendation by considering various types of user behaviors with different influences <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">kang2018self</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2019bert4rec</span>]</cite>.
</span></span>
</span></p>
</div>
</section>
<section class="ltx_subsection" id="Ch6.S2.SS4">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2.4 </span>Next-basket recommendation</h4>
<div class="ltx_para" id="Ch6.S2.SS4.p1">
<p class="ltx_p" id="Ch6.S2.SS4.p1.1">The  <span class="ltx_glossaryref" title="next basket recommendation"><span class="ltx_text ltx_glossary_long">next basket recommendation</span></span> (<abbr class="ltx_glossaryref" title="next basket recommendation"><span class="ltx_text ltx_glossary_short">NBR</span></abbr>) task uses information from previous sessions.
It is defined as recommending a group of items to a user based on their shopping history, where the history is a time-ordered sequence of baskets that they have purchased in the past <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li-2023-next</span>]</cite>.
Each basket is a set of items with no particular order.
This formulation fits the grocery shopping setting well, where a user’s purchase history occurs naturally in the form of such baskets.
Variations of the <abbr class="ltx_glossaryref" title="next basket recommendation"><span class="ltx_text ltx_glossary_short">NBR</span></abbr> task where the order of items in a basket may be relevant, can, e.g., be found in music (playlist recommendation), in travel (recommending holiday packages), and in research and education (recommending reading lists).
Two main characteristics of the grocery shopping scenario make the <abbr class="ltx_glossaryref" title="next basket recommendation"><span class="ltx_text ltx_glossary_short">NBR</span></abbr> in this domain distinct from other retail domains:

<span class="ltx_inline-enumerate" id="Ch6.S2.I5">
<span class="ltx_inline-item" id="Ch6.S2.I5.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch6.S2.I5.i1.1">users shop for grocery items repeatedly and on a regular basis, and
</span></span>
<span class="ltx_inline-item" id="Ch6.S2.I5.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch6.S2.I5.i2.1">grocery items have a short life time and are repurchased frequently by the same user <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liu-2019-characterizing</span>]</cite>.
</span></span>
</span></p>
</div>
<div class="ltx_para" id="Ch6.S2.SS4.p2">
<p class="ltx_p" id="Ch6.S2.SS4.p2.1">In the grocery shopping domain, it has been found to be useful to distinguish between <em class="ltx_emph ltx_font_italic" id="Ch6.S2.SS4.p2.1.1">repeat items</em>, i.e., items that a user has consumed before, and <em class="ltx_emph ltx_font_italic" id="Ch6.S2.SS4.p2.1.2">explore items</em>, i.e., items that a user has not consumed before <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ariannezhad-2022-recanet</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li-2023-next</span>]</cite>.
In particular, for repeat items, the set of candidate items that needs to be considered for an individual user is usually in the low hundreds <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ariannezhad-2021-understanding</span>]</cite> as opposed to the full item catalog that needs to be considered for explore items, whose size may exceed 50,000 items in grocery shopping <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ariannezhad-2020-demand</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sprangers-2023-parameter</span>]</cite>.
This fact makes the task of retrieving repeat items to be included in the next basket to be recommended to a user considerably easier than the task of retrieving explore items.
Frequency-based, nearest neighbor-based, and deep learning-based methods have all been used for the <abbr class="ltx_glossaryref" title="next basket recommendation"><span class="ltx_text ltx_glossary_short">NBR</span></abbr> task, and for the candidate retrieval phase in particular <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li-2023-next</span>]</cite>.
As a rule of thumb, being biased towards the easier repetition task is an important strategy that helps to boost the overall NBR performance.
Deep learning-based methods do not effectively exploit the repetition behavior.
Indeed, they achieve a relatively good exploration performance, but they are not able to outperform the simple frequency-based
baselines in several cases.
Some recent state-of-the-art <abbr class="ltx_glossaryref" title="next basket recommendation"><span class="ltx_text ltx_glossary_short">NBR</span></abbr> methods are skewed towards the repetition task and outperform frequency-based baselines. However, the improvements they achieve are limited, especially considering the complexity and computational costs, e.g., for the training process <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yu-2020-predicting</span>]</cite> and for hyper-parameter search <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">faggioli-2020-recency</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hu-2020-modeling</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch6.S2.SS4.p3">
<p class="ltx_p" id="Ch6.S2.SS4.p3.1">A number of variations of the <abbr class="ltx_glossaryref" title="next basket recommendation"><span class="ltx_text ltx_glossary_short">NBR</span></abbr> task have recently been considered, each with their own challenges for retrieving candidate items.
The <em class="ltx_emph ltx_font_italic" id="Ch6.S2.SS4.p3.1.1">within-basket recommendation</em> task uses information from previous sessions as well as information from an incomplete basket to which additional items could potentially be added <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ariannezhad-2023-personalized</span>]</cite>.
Another variation concerns an <em class="ltx_emph ltx_font_italic" id="Ch6.S2.SS4.p3.1.2">item-centered</em> scenario (as opposed to the familiar user-centered scenario), where the input is an item and the task is to identify users who might be interested in consuming the item <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li-2023-who</span>]</cite>.</p>
</div>
</section>
</section>
<section class="ltx_section" id="Ch6.S3">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6.3 </span>Candidate ranking models</h3>
<div class="ltx_para" id="Ch6.S3.p1">
<p class="ltx_p" id="Ch6.S3.p1.1">Given generic feature vectors as input, work on candidate ranking strategies has mainly focused on modeling interactions between features.
According to the types of interaction function they adopt, existing methods can be divided into linear models, polynomial models, and neural network models.</p>
</div>
<section class="ltx_subsection" id="Ch6.S3.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3.1 </span>Linear models</h4>
<div class="ltx_para" id="Ch6.S3.SS1.p1">
<p class="ltx_p" id="Ch6.S3.SS1.p1.1">Early studies on candidate ranking usually apply linear models, such as <em class="ltx_emph ltx_font_italic" id="Ch6.S3.SS1.p1.1.1">logistic regression</em> (LR) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">kleinbaum2002logistic</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hosmer2013applied</span>]</cite> and naive Bayesian methods <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">hastie2009elements</span>]</cite>.
In contrast to other complicated models, linear models are straightforward, efficient, and explainable. Although linear models may not perform as well as deep neural networks, they indeed lay the foundation for recent advances in e-commerce recommendation <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">peng2002introduction</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kiseleva2016beyond</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">bernardi2015continuous</span>]</cite>.
In e-commerce recommendation, logistic regression (LR) is one of the most popular methods that formulate the task as a classification task to rank through predicting the probability of an item to be interacted.
LR first collects features of users (e.g., age and gender) and items (e.g., price and categories) into a number of feature vectors, and then apply a linear combination function to map the feature vector into the final predicted score.
Similarly, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">kiseleva2016beyond</span></cite> employed a naive Bayesian ranking strategy in e-commerce recommendation by considering contextual user profiling.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch6.S3.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3.2 </span>Polynomial models</h4>
<div class="ltx_para" id="Ch6.S3.SS2.p1">
<p class="ltx_p" id="Ch6.S3.SS2.p1.4">Performances of linear models are limited because of high space complexity and inability of high-level feature modeling.
To address these two problems, factorization machines (FM) have been proposed <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">FM</span>]</cite>. Factorization machines factorize parameters <math alttext="w_{i,j}" class="ltx_Math" display="inline" id="Ch6.S3.SS2.p1.1.m1.2"><semantics id="Ch6.S3.SS2.p1.1.m1.2a"><msub id="Ch6.S3.SS2.p1.1.m1.2.3" xref="Ch6.S3.SS2.p1.1.m1.2.3.cmml"><mi id="Ch6.S3.SS2.p1.1.m1.2.3.2" xref="Ch6.S3.SS2.p1.1.m1.2.3.2.cmml">w</mi><mrow id="Ch6.S3.SS2.p1.1.m1.2.2.2.4" xref="Ch6.S3.SS2.p1.1.m1.2.2.2.3.cmml"><mi id="Ch6.S3.SS2.p1.1.m1.1.1.1.1" xref="Ch6.S3.SS2.p1.1.m1.1.1.1.1.cmml">i</mi><mo id="Ch6.S3.SS2.p1.1.m1.2.2.2.4.1" xref="Ch6.S3.SS2.p1.1.m1.2.2.2.3.cmml">,</mo><mi id="Ch6.S3.SS2.p1.1.m1.2.2.2.2" xref="Ch6.S3.SS2.p1.1.m1.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="Ch6.S3.SS2.p1.1.m1.2b"><apply id="Ch6.S3.SS2.p1.1.m1.2.3.cmml" xref="Ch6.S3.SS2.p1.1.m1.2.3"><csymbol cd="ambiguous" id="Ch6.S3.SS2.p1.1.m1.2.3.1.cmml" xref="Ch6.S3.SS2.p1.1.m1.2.3">subscript</csymbol><ci id="Ch6.S3.SS2.p1.1.m1.2.3.2.cmml" xref="Ch6.S3.SS2.p1.1.m1.2.3.2">𝑤</ci><list id="Ch6.S3.SS2.p1.1.m1.2.2.2.3.cmml" xref="Ch6.S3.SS2.p1.1.m1.2.2.2.4"><ci id="Ch6.S3.SS2.p1.1.m1.1.1.1.1.cmml" xref="Ch6.S3.SS2.p1.1.m1.1.1.1.1">𝑖</ci><ci id="Ch6.S3.SS2.p1.1.m1.2.2.2.2.cmml" xref="Ch6.S3.SS2.p1.1.m1.2.2.2.2">𝑗</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S3.SS2.p1.1.m1.2c">w_{i,j}</annotation><annotation encoding="application/x-llamapun" id="Ch6.S3.SS2.p1.1.m1.2d">italic_w start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT</annotation></semantics></math> into an inner product of two latent vectors, i.e., <math alttext="w_{i,j}\equiv\left&lt;v_{i},v_{j}\right&gt;" class="ltx_Math" display="inline" id="Ch6.S3.SS2.p1.2.m2.4"><semantics id="Ch6.S3.SS2.p1.2.m2.4a"><mrow id="Ch6.S3.SS2.p1.2.m2.4.4" xref="Ch6.S3.SS2.p1.2.m2.4.4.cmml"><msub id="Ch6.S3.SS2.p1.2.m2.4.4.4" xref="Ch6.S3.SS2.p1.2.m2.4.4.4.cmml"><mi id="Ch6.S3.SS2.p1.2.m2.4.4.4.2" xref="Ch6.S3.SS2.p1.2.m2.4.4.4.2.cmml">w</mi><mrow id="Ch6.S3.SS2.p1.2.m2.2.2.2.4" xref="Ch6.S3.SS2.p1.2.m2.2.2.2.3.cmml"><mi id="Ch6.S3.SS2.p1.2.m2.1.1.1.1" xref="Ch6.S3.SS2.p1.2.m2.1.1.1.1.cmml">i</mi><mo id="Ch6.S3.SS2.p1.2.m2.2.2.2.4.1" xref="Ch6.S3.SS2.p1.2.m2.2.2.2.3.cmml">,</mo><mi id="Ch6.S3.SS2.p1.2.m2.2.2.2.2" xref="Ch6.S3.SS2.p1.2.m2.2.2.2.2.cmml">j</mi></mrow></msub><mo id="Ch6.S3.SS2.p1.2.m2.4.4.3" xref="Ch6.S3.SS2.p1.2.m2.4.4.3.cmml">≡</mo><mrow id="Ch6.S3.SS2.p1.2.m2.4.4.2.2" xref="Ch6.S3.SS2.p1.2.m2.4.4.2.3.cmml"><mo id="Ch6.S3.SS2.p1.2.m2.4.4.2.2.3" xref="Ch6.S3.SS2.p1.2.m2.4.4.2.3.cmml">⟨</mo><msub id="Ch6.S3.SS2.p1.2.m2.3.3.1.1.1" xref="Ch6.S3.SS2.p1.2.m2.3.3.1.1.1.cmml"><mi id="Ch6.S3.SS2.p1.2.m2.3.3.1.1.1.2" xref="Ch6.S3.SS2.p1.2.m2.3.3.1.1.1.2.cmml">v</mi><mi id="Ch6.S3.SS2.p1.2.m2.3.3.1.1.1.3" xref="Ch6.S3.SS2.p1.2.m2.3.3.1.1.1.3.cmml">i</mi></msub><mo id="Ch6.S3.SS2.p1.2.m2.4.4.2.2.4" xref="Ch6.S3.SS2.p1.2.m2.4.4.2.3.cmml">,</mo><msub id="Ch6.S3.SS2.p1.2.m2.4.4.2.2.2" xref="Ch6.S3.SS2.p1.2.m2.4.4.2.2.2.cmml"><mi id="Ch6.S3.SS2.p1.2.m2.4.4.2.2.2.2" xref="Ch6.S3.SS2.p1.2.m2.4.4.2.2.2.2.cmml">v</mi><mi id="Ch6.S3.SS2.p1.2.m2.4.4.2.2.2.3" xref="Ch6.S3.SS2.p1.2.m2.4.4.2.2.2.3.cmml">j</mi></msub><mo id="Ch6.S3.SS2.p1.2.m2.4.4.2.2.5" xref="Ch6.S3.SS2.p1.2.m2.4.4.2.3.cmml">⟩</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch6.S3.SS2.p1.2.m2.4b"><apply id="Ch6.S3.SS2.p1.2.m2.4.4.cmml" xref="Ch6.S3.SS2.p1.2.m2.4.4"><equivalent id="Ch6.S3.SS2.p1.2.m2.4.4.3.cmml" xref="Ch6.S3.SS2.p1.2.m2.4.4.3"></equivalent><apply id="Ch6.S3.SS2.p1.2.m2.4.4.4.cmml" xref="Ch6.S3.SS2.p1.2.m2.4.4.4"><csymbol cd="ambiguous" id="Ch6.S3.SS2.p1.2.m2.4.4.4.1.cmml" xref="Ch6.S3.SS2.p1.2.m2.4.4.4">subscript</csymbol><ci id="Ch6.S3.SS2.p1.2.m2.4.4.4.2.cmml" xref="Ch6.S3.SS2.p1.2.m2.4.4.4.2">𝑤</ci><list id="Ch6.S3.SS2.p1.2.m2.2.2.2.3.cmml" xref="Ch6.S3.SS2.p1.2.m2.2.2.2.4"><ci id="Ch6.S3.SS2.p1.2.m2.1.1.1.1.cmml" xref="Ch6.S3.SS2.p1.2.m2.1.1.1.1">𝑖</ci><ci id="Ch6.S3.SS2.p1.2.m2.2.2.2.2.cmml" xref="Ch6.S3.SS2.p1.2.m2.2.2.2.2">𝑗</ci></list></apply><list id="Ch6.S3.SS2.p1.2.m2.4.4.2.3.cmml" xref="Ch6.S3.SS2.p1.2.m2.4.4.2.2"><apply id="Ch6.S3.SS2.p1.2.m2.3.3.1.1.1.cmml" xref="Ch6.S3.SS2.p1.2.m2.3.3.1.1.1"><csymbol cd="ambiguous" id="Ch6.S3.SS2.p1.2.m2.3.3.1.1.1.1.cmml" xref="Ch6.S3.SS2.p1.2.m2.3.3.1.1.1">subscript</csymbol><ci id="Ch6.S3.SS2.p1.2.m2.3.3.1.1.1.2.cmml" xref="Ch6.S3.SS2.p1.2.m2.3.3.1.1.1.2">𝑣</ci><ci id="Ch6.S3.SS2.p1.2.m2.3.3.1.1.1.3.cmml" xref="Ch6.S3.SS2.p1.2.m2.3.3.1.1.1.3">𝑖</ci></apply><apply id="Ch6.S3.SS2.p1.2.m2.4.4.2.2.2.cmml" xref="Ch6.S3.SS2.p1.2.m2.4.4.2.2.2"><csymbol cd="ambiguous" id="Ch6.S3.SS2.p1.2.m2.4.4.2.2.2.1.cmml" xref="Ch6.S3.SS2.p1.2.m2.4.4.2.2.2">subscript</csymbol><ci id="Ch6.S3.SS2.p1.2.m2.4.4.2.2.2.2.cmml" xref="Ch6.S3.SS2.p1.2.m2.4.4.2.2.2.2">𝑣</ci><ci id="Ch6.S3.SS2.p1.2.m2.4.4.2.2.2.3.cmml" xref="Ch6.S3.SS2.p1.2.m2.4.4.2.2.2.3">𝑗</ci></apply></list></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S3.SS2.p1.2.m2.4c">w_{i,j}\equiv\left&lt;v_{i},v_{j}\right&gt;</annotation><annotation encoding="application/x-llamapun" id="Ch6.S3.SS2.p1.2.m2.4d">italic_w start_POSTSUBSCRIPT italic_i , italic_j end_POSTSUBSCRIPT ≡ ⟨ italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT , italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ⟩</annotation></semantics></math>, where <math alttext="v_{i}" class="ltx_Math" display="inline" id="Ch6.S3.SS2.p1.3.m3.1"><semantics id="Ch6.S3.SS2.p1.3.m3.1a"><msub id="Ch6.S3.SS2.p1.3.m3.1.1" xref="Ch6.S3.SS2.p1.3.m3.1.1.cmml"><mi id="Ch6.S3.SS2.p1.3.m3.1.1.2" xref="Ch6.S3.SS2.p1.3.m3.1.1.2.cmml">v</mi><mi id="Ch6.S3.SS2.p1.3.m3.1.1.3" xref="Ch6.S3.SS2.p1.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="Ch6.S3.SS2.p1.3.m3.1b"><apply id="Ch6.S3.SS2.p1.3.m3.1.1.cmml" xref="Ch6.S3.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="Ch6.S3.SS2.p1.3.m3.1.1.1.cmml" xref="Ch6.S3.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="Ch6.S3.SS2.p1.3.m3.1.1.2.cmml" xref="Ch6.S3.SS2.p1.3.m3.1.1.2">𝑣</ci><ci id="Ch6.S3.SS2.p1.3.m3.1.1.3.cmml" xref="Ch6.S3.SS2.p1.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S3.SS2.p1.3.m3.1c">v_{i}</annotation><annotation encoding="application/x-llamapun" id="Ch6.S3.SS2.p1.3.m3.1d">italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> denotes a latent vector of the <math alttext="i" class="ltx_Math" display="inline" id="Ch6.S3.SS2.p1.4.m4.1"><semantics id="Ch6.S3.SS2.p1.4.m4.1a"><mi id="Ch6.S3.SS2.p1.4.m4.1.1" xref="Ch6.S3.SS2.p1.4.m4.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="Ch6.S3.SS2.p1.4.m4.1b"><ci id="Ch6.S3.SS2.p1.4.m4.1.1.cmml" xref="Ch6.S3.SS2.p1.4.m4.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S3.SS2.p1.4.m4.1c">i</annotation><annotation encoding="application/x-llamapun" id="Ch6.S3.SS2.p1.4.m4.1d">italic_i</annotation></semantics></math>-th feature.
With different types of knowledge, the feature interactions across multiple fields should have different weights in recommendation.
To tackle this challenge, field-aware factorization machines (FFM) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">FFM</span>]</cite> was proposed to capture field-aware weights and distribute a single latent vector to multiple fields.</p>
</div>
<div class="ltx_para" id="Ch6.S3.SS2.p2">
<p class="ltx_p" id="Ch6.S3.SS2.p2.1">A drawback of FM or FFM is that they just capture 2-order feature interactions but neglect higher order interactions, which are widely observed in e-commerce scenarios.
As described in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S1.SS1" title="4.1.1 Click behavior modeling ‣ 4.1 User behavior modeling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4.1.1</span></a>, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">he2014practical</span></cite> proposed a hybrid model by combining GBDT and logistic regression for click-behavior modeling.
The hybrid model is able to leverage the boosted decision trees (i.e., GBDT) to conduct feature interactions into logistic regression for e-commerce recommendation.
In this hybrid model, GBDT adaptively conducts feature selection and higher-order feature interactions.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch6.S3.SS3">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3.3 </span>Neural network models</h4>
<div class="ltx_para" id="Ch6.S3.SS3.p1">
<p class="ltx_p" id="Ch6.S3.SS3.p1.1">Deep neural networks have been leveraged in e-commerce recommendation because of their powerful expression ability of capturing complicated feature interactions.
Up to now, research on neural network models can be categorized into the following three research directions:</p>
<ul class="ltx_itemize" id="Ch6.S3.I1">
<li class="ltx_item" id="Ch6.S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch6.S3.I1.i1.p1">
<p class="ltx_p" id="Ch6.S3.I1.i1.p1.1">The first direction aims at developing feature interaction modules based on neural networks, e.g., adding more neural network layers or combining the superiority of different neural networks.</p>
</div>
</li>
<li class="ltx_item" id="Ch6.S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch6.S3.I1.i2.p1">
<p class="ltx_p" id="Ch6.S3.I1.i2.p1.1">The second direction aims at enhancing the expression by leveraging deep neural networks using FMs.</p>
</div>
</li>
<li class="ltx_item" id="Ch6.S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch6.S3.I1.i3.p1">
<p class="ltx_p" id="Ch6.S3.I1.i3.p1.1">The third direction aims at leveraging the attention mechanism in capturing diverge and dynamic contributions of feature interactions.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="Ch6.S3.SS3.p1.2">In the upcoming sections, we will detail the recent advances along these research directions.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch6.S3.SS3.p2">
<p class="ltx_p" id="Ch6.S3.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="Ch6.S3.SS3.p2.1.1">Neural feature interactions.</span>
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DeepCross</span></cite> proposed <span class="ltx_text ltx_font_italic" id="Ch6.S3.SS3.p2.1.2">Deep Crossing</span> model, which can be considered as the first end-to-end deep learning framework for recommender systems.
Deep Crossing enjoys the merits of deep learning in coping with various features and capturing complex feature interactions, consisting of the following four components: the embedding layer, stacking layer, multiple residual units layer, and scoring layer.
The goal of the embedding layer is to transform per individual sparse features into dense vectors in latent space via neural networks, whereas the stacking layer concatenates different embedding features from the embedding layer and generates a new vector for all features.
The scoring layer servers as an output layer with logistic regression to generate the final predicted score.</p>
</div>
<div class="ltx_para" id="Ch6.S3.SS3.p3">
<p class="ltx_p" id="Ch6.S3.SS3.p3.1">Collaborative filtering can be reconsidered from the perspective of deep learning.
Traditional collaborative filtering methods employ the inner product of a user’s latent vector and an item’s latent vector for rating prediction.
However, the simple model structure of MF makes it insufficient to fit the objective, which limits the expressiveness of the model. Motivated by this, neural collaborative filtering (NCF) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">He2017NCF</span>]</cite> was proposed to replace the inner product operation with a neural network.</p>
</div>
<div class="ltx_para" id="Ch6.S3.SS3.p4">
<p class="ltx_p" id="Ch6.S3.SS3.p4.1">By learning frequent co-occurrences of features, deep neural networks may have poor memorization, i.e., these models easily over-generalize and recommend less relevant items when user-item interactions are sparse.
To address this problem, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">cheng2016wide</span></cite> proposed the Wide&amp;Deep model for recommendation.
The detailed model architecture of Wide&amp;Deep is presented in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.S1.SS1" title="4.1.1 Click behavior modeling ‣ 4.1 User behavior modeling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4.1.1</span></a>.
Wide&amp;Deep can keep a balance between memorization and generalization: its wide component can effectively memorize sparse feature interactions, while the deep neural networks can generalize the previously unseen feature interactions through low-dimensional embeddings.</p>
</div>
<div class="ltx_para" id="Ch6.S3.SS3.p5">
<p class="ltx_p" id="Ch6.S3.SS3.p5.1">There are lots of follow-up studies that improve either the wide component or the deep component in the Wide&amp;Deep model. Deep&amp;Cross Network (DCN) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2017deep</span>]</cite> replaces the wide component with a well-designed Cross network.
DCN applies an explicit feature crossing mechanism with multiple cross layers.
Recent studies seek to apply automating machine learning (AutoML) to model the selection of feature interactions <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Su2021Detecting</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Ze2021A</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ZhaO2021AutoLoss</span>]</cite>.
SIF <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Yao2020Efficient</span>]</cite> utilizes one-shot architecture search methods to search proper interaction functions (e.g., inner product, plus/minor, max/min pooling, outer product, and concatenation) for collaborative filtering models.
AutoFIS <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Liu2020AutoFIS</span>]</cite> continuously searches the effective feature interactions by incorporating architecture parameters to identify important feature interactions.
AutoGroup <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Liu2020AutoGroup</span>]</cite> groups useful features into sets using AutoML and then generates interactions from each set.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch6.S3.SS3.p6">
<p class="ltx_p" id="Ch6.S3.SS3.p6.2"><span class="ltx_text ltx_font_bold" id="Ch6.S3.SS3.p6.2.1">Endowing factorization machines with neural networks.</span>
Many models have been proposed to integrate <span class="ltx_glossaryref" title="factorization machine"><span class="ltx_text ltx_glossary_long-plural">factorization machines</span></span> with deep neural networks to make full use of their advantages in feature combination.
Neural factorization machines <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">he2017neural</span>]</cite> enhances <abbr class="ltx_glossaryref" title="factorization machine"><span class="ltx_text ltx_glossary_short-plural">FMs</span></abbr> by modeling higher-order and non-linear feature interactions.
NFM introduced the bi-interaction pooling operation in neural network modeling, and presented a new neural network perspective for <abbr class="ltx_glossaryref" title="factorization machine"><span class="ltx_text ltx_glossary_short-plural">FMs</span></abbr>.
Given the embedding set of all features <math alttext="\mathcal{V}_{x}" class="ltx_Math" display="inline" id="Ch6.S3.SS3.p6.1.m1.1"><semantics id="Ch6.S3.SS3.p6.1.m1.1a"><msub id="Ch6.S3.SS3.p6.1.m1.1.1" xref="Ch6.S3.SS3.p6.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Ch6.S3.SS3.p6.1.m1.1.1.2" xref="Ch6.S3.SS3.p6.1.m1.1.1.2.cmml">𝒱</mi><mi id="Ch6.S3.SS3.p6.1.m1.1.1.3" xref="Ch6.S3.SS3.p6.1.m1.1.1.3.cmml">x</mi></msub><annotation-xml encoding="MathML-Content" id="Ch6.S3.SS3.p6.1.m1.1b"><apply id="Ch6.S3.SS3.p6.1.m1.1.1.cmml" xref="Ch6.S3.SS3.p6.1.m1.1.1"><csymbol cd="ambiguous" id="Ch6.S3.SS3.p6.1.m1.1.1.1.cmml" xref="Ch6.S3.SS3.p6.1.m1.1.1">subscript</csymbol><ci id="Ch6.S3.SS3.p6.1.m1.1.1.2.cmml" xref="Ch6.S3.SS3.p6.1.m1.1.1.2">𝒱</ci><ci id="Ch6.S3.SS3.p6.1.m1.1.1.3.cmml" xref="Ch6.S3.SS3.p6.1.m1.1.1.3">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S3.SS3.p6.1.m1.1c">\mathcal{V}_{x}</annotation><annotation encoding="application/x-llamapun" id="Ch6.S3.SS3.p6.1.m1.1d">caligraphic_V start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT</annotation></semantics></math>, the bi-interaction layer in NFM converts <math alttext="\mathcal{V}_{x}" class="ltx_Math" display="inline" id="Ch6.S3.SS3.p6.2.m2.1"><semantics id="Ch6.S3.SS3.p6.2.m2.1a"><msub id="Ch6.S3.SS3.p6.2.m2.1.1" xref="Ch6.S3.SS3.p6.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Ch6.S3.SS3.p6.2.m2.1.1.2" xref="Ch6.S3.SS3.p6.2.m2.1.1.2.cmml">𝒱</mi><mi id="Ch6.S3.SS3.p6.2.m2.1.1.3" xref="Ch6.S3.SS3.p6.2.m2.1.1.3.cmml">x</mi></msub><annotation-xml encoding="MathML-Content" id="Ch6.S3.SS3.p6.2.m2.1b"><apply id="Ch6.S3.SS3.p6.2.m2.1.1.cmml" xref="Ch6.S3.SS3.p6.2.m2.1.1"><csymbol cd="ambiguous" id="Ch6.S3.SS3.p6.2.m2.1.1.1.cmml" xref="Ch6.S3.SS3.p6.2.m2.1.1">subscript</csymbol><ci id="Ch6.S3.SS3.p6.2.m2.1.1.2.cmml" xref="Ch6.S3.SS3.p6.2.m2.1.1.2">𝒱</ci><ci id="Ch6.S3.SS3.p6.2.m2.1.1.3.cmml" xref="Ch6.S3.SS3.p6.2.m2.1.1.3">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S3.SS3.p6.2.m2.1c">\mathcal{V}_{x}</annotation><annotation encoding="application/x-llamapun" id="Ch6.S3.SS3.p6.2.m2.1d">caligraphic_V start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT</annotation></semantics></math> to one vector:</p>
<table class="ltx_equationgroup ltx_eqn_gather ltx_eqn_table" id="A1.S5.EGx2">
<tbody id="Ch6.E9"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\displaystyle f_{BI}(\mathcal{V}_{x})=\sum_{i=1}^{n-1}\sum_{j=i+1}^{n}(x_{i}v_%
{i})\odot(x_{j}v_{j})," class="ltx_Math" display="block" id="Ch6.E9.m1.1"><semantics id="Ch6.E9.m1.1a"><mrow id="Ch6.E9.m1.1.1.1" xref="Ch6.E9.m1.1.1.1.1.cmml"><mrow id="Ch6.E9.m1.1.1.1.1" xref="Ch6.E9.m1.1.1.1.1.cmml"><mrow id="Ch6.E9.m1.1.1.1.1.1" xref="Ch6.E9.m1.1.1.1.1.1.cmml"><msub id="Ch6.E9.m1.1.1.1.1.1.3" xref="Ch6.E9.m1.1.1.1.1.1.3.cmml"><mi id="Ch6.E9.m1.1.1.1.1.1.3.2" xref="Ch6.E9.m1.1.1.1.1.1.3.2.cmml">f</mi><mrow id="Ch6.E9.m1.1.1.1.1.1.3.3" xref="Ch6.E9.m1.1.1.1.1.1.3.3.cmml"><mi id="Ch6.E9.m1.1.1.1.1.1.3.3.2" xref="Ch6.E9.m1.1.1.1.1.1.3.3.2.cmml">B</mi><mo id="Ch6.E9.m1.1.1.1.1.1.3.3.1" xref="Ch6.E9.m1.1.1.1.1.1.3.3.1.cmml">⁢</mo><mi id="Ch6.E9.m1.1.1.1.1.1.3.3.3" xref="Ch6.E9.m1.1.1.1.1.1.3.3.3.cmml">I</mi></mrow></msub><mo id="Ch6.E9.m1.1.1.1.1.1.2" xref="Ch6.E9.m1.1.1.1.1.1.2.cmml">⁢</mo><mrow id="Ch6.E9.m1.1.1.1.1.1.1.1" xref="Ch6.E9.m1.1.1.1.1.1.1.1.1.cmml"><mo id="Ch6.E9.m1.1.1.1.1.1.1.1.2" stretchy="false" xref="Ch6.E9.m1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="Ch6.E9.m1.1.1.1.1.1.1.1.1" xref="Ch6.E9.m1.1.1.1.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="Ch6.E9.m1.1.1.1.1.1.1.1.1.2" xref="Ch6.E9.m1.1.1.1.1.1.1.1.1.2.cmml">𝒱</mi><mi id="Ch6.E9.m1.1.1.1.1.1.1.1.1.3" xref="Ch6.E9.m1.1.1.1.1.1.1.1.1.3.cmml">x</mi></msub><mo id="Ch6.E9.m1.1.1.1.1.1.1.1.3" stretchy="false" xref="Ch6.E9.m1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="Ch6.E9.m1.1.1.1.1.4" rspace="0.111em" xref="Ch6.E9.m1.1.1.1.1.4.cmml">=</mo><mrow id="Ch6.E9.m1.1.1.1.1.3" xref="Ch6.E9.m1.1.1.1.1.3.cmml"><munderover id="Ch6.E9.m1.1.1.1.1.3.3" xref="Ch6.E9.m1.1.1.1.1.3.3.cmml"><mo id="Ch6.E9.m1.1.1.1.1.3.3.2.2" movablelimits="false" rspace="0em" xref="Ch6.E9.m1.1.1.1.1.3.3.2.2.cmml">∑</mo><mrow id="Ch6.E9.m1.1.1.1.1.3.3.2.3" xref="Ch6.E9.m1.1.1.1.1.3.3.2.3.cmml"><mi id="Ch6.E9.m1.1.1.1.1.3.3.2.3.2" xref="Ch6.E9.m1.1.1.1.1.3.3.2.3.2.cmml">i</mi><mo id="Ch6.E9.m1.1.1.1.1.3.3.2.3.1" xref="Ch6.E9.m1.1.1.1.1.3.3.2.3.1.cmml">=</mo><mn id="Ch6.E9.m1.1.1.1.1.3.3.2.3.3" xref="Ch6.E9.m1.1.1.1.1.3.3.2.3.3.cmml">1</mn></mrow><mrow id="Ch6.E9.m1.1.1.1.1.3.3.3" xref="Ch6.E9.m1.1.1.1.1.3.3.3.cmml"><mi id="Ch6.E9.m1.1.1.1.1.3.3.3.2" xref="Ch6.E9.m1.1.1.1.1.3.3.3.2.cmml">n</mi><mo id="Ch6.E9.m1.1.1.1.1.3.3.3.1" xref="Ch6.E9.m1.1.1.1.1.3.3.3.1.cmml">−</mo><mn id="Ch6.E9.m1.1.1.1.1.3.3.3.3" xref="Ch6.E9.m1.1.1.1.1.3.3.3.3.cmml">1</mn></mrow></munderover><mrow id="Ch6.E9.m1.1.1.1.1.3.2" xref="Ch6.E9.m1.1.1.1.1.3.2.cmml"><munderover id="Ch6.E9.m1.1.1.1.1.3.2.3" xref="Ch6.E9.m1.1.1.1.1.3.2.3.cmml"><mo id="Ch6.E9.m1.1.1.1.1.3.2.3.2.2" movablelimits="false" rspace="0em" xref="Ch6.E9.m1.1.1.1.1.3.2.3.2.2.cmml">∑</mo><mrow id="Ch6.E9.m1.1.1.1.1.3.2.3.2.3" xref="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.cmml"><mi id="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.2" xref="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.2.cmml">j</mi><mo id="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.1" xref="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.1.cmml">=</mo><mrow id="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.3" xref="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.3.cmml"><mi id="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.3.2" xref="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.3.2.cmml">i</mi><mo id="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.3.1" xref="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.3.1.cmml">+</mo><mn id="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.3.3" xref="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.3.3.cmml">1</mn></mrow></mrow><mi id="Ch6.E9.m1.1.1.1.1.3.2.3.3" xref="Ch6.E9.m1.1.1.1.1.3.2.3.3.cmml">n</mi></munderover><mrow id="Ch6.E9.m1.1.1.1.1.3.2.2" xref="Ch6.E9.m1.1.1.1.1.3.2.2.cmml"><mrow id="Ch6.E9.m1.1.1.1.1.2.1.1.1.1" xref="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.cmml"><mo id="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.2" stretchy="false" xref="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.cmml">(</mo><mrow id="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1" xref="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.cmml"><msub id="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.2" xref="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.2.cmml"><mi id="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.2.2" xref="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.2.2.cmml">x</mi><mi id="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.2.3" xref="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.1" xref="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.1.cmml">⁢</mo><msub id="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.3" xref="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.3.cmml"><mi id="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.3.2" xref="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.3.2.cmml">v</mi><mi id="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.3.3" xref="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.3.3.cmml">i</mi></msub></mrow><mo id="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.3" rspace="0.055em" stretchy="false" xref="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.cmml">)</mo></mrow><mo id="Ch6.E9.m1.1.1.1.1.3.2.2.3" rspace="0.222em" xref="Ch6.E9.m1.1.1.1.1.3.2.2.3.cmml">⊙</mo><mrow id="Ch6.E9.m1.1.1.1.1.3.2.2.2.1" xref="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.cmml"><mo id="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.2" stretchy="false" xref="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.cmml">(</mo><mrow id="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1" xref="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.cmml"><msub id="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.2" xref="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.2.cmml"><mi id="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.2.2" xref="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.2.2.cmml">x</mi><mi id="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.2.3" xref="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.2.3.cmml">j</mi></msub><mo id="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.1" xref="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.1.cmml">⁢</mo><msub id="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.3" xref="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.3.cmml"><mi id="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.3.2" xref="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.3.2.cmml">v</mi><mi id="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.3.3" xref="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.3.3.cmml">j</mi></msub></mrow><mo id="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.3" stretchy="false" xref="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo id="Ch6.E9.m1.1.1.1.2" xref="Ch6.E9.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="Ch6.E9.m1.1b"><apply id="Ch6.E9.m1.1.1.1.1.cmml" xref="Ch6.E9.m1.1.1.1"><eq id="Ch6.E9.m1.1.1.1.1.4.cmml" xref="Ch6.E9.m1.1.1.1.1.4"></eq><apply id="Ch6.E9.m1.1.1.1.1.1.cmml" xref="Ch6.E9.m1.1.1.1.1.1"><times id="Ch6.E9.m1.1.1.1.1.1.2.cmml" xref="Ch6.E9.m1.1.1.1.1.1.2"></times><apply id="Ch6.E9.m1.1.1.1.1.1.3.cmml" xref="Ch6.E9.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="Ch6.E9.m1.1.1.1.1.1.3.1.cmml" xref="Ch6.E9.m1.1.1.1.1.1.3">subscript</csymbol><ci id="Ch6.E9.m1.1.1.1.1.1.3.2.cmml" xref="Ch6.E9.m1.1.1.1.1.1.3.2">𝑓</ci><apply id="Ch6.E9.m1.1.1.1.1.1.3.3.cmml" xref="Ch6.E9.m1.1.1.1.1.1.3.3"><times id="Ch6.E9.m1.1.1.1.1.1.3.3.1.cmml" xref="Ch6.E9.m1.1.1.1.1.1.3.3.1"></times><ci id="Ch6.E9.m1.1.1.1.1.1.3.3.2.cmml" xref="Ch6.E9.m1.1.1.1.1.1.3.3.2">𝐵</ci><ci id="Ch6.E9.m1.1.1.1.1.1.3.3.3.cmml" xref="Ch6.E9.m1.1.1.1.1.1.3.3.3">𝐼</ci></apply></apply><apply id="Ch6.E9.m1.1.1.1.1.1.1.1.1.cmml" xref="Ch6.E9.m1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="Ch6.E9.m1.1.1.1.1.1.1.1.1.1.cmml" xref="Ch6.E9.m1.1.1.1.1.1.1.1">subscript</csymbol><ci id="Ch6.E9.m1.1.1.1.1.1.1.1.1.2.cmml" xref="Ch6.E9.m1.1.1.1.1.1.1.1.1.2">𝒱</ci><ci id="Ch6.E9.m1.1.1.1.1.1.1.1.1.3.cmml" xref="Ch6.E9.m1.1.1.1.1.1.1.1.1.3">𝑥</ci></apply></apply><apply id="Ch6.E9.m1.1.1.1.1.3.cmml" xref="Ch6.E9.m1.1.1.1.1.3"><apply id="Ch6.E9.m1.1.1.1.1.3.3.cmml" xref="Ch6.E9.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="Ch6.E9.m1.1.1.1.1.3.3.1.cmml" xref="Ch6.E9.m1.1.1.1.1.3.3">superscript</csymbol><apply id="Ch6.E9.m1.1.1.1.1.3.3.2.cmml" xref="Ch6.E9.m1.1.1.1.1.3.3"><csymbol cd="ambiguous" id="Ch6.E9.m1.1.1.1.1.3.3.2.1.cmml" xref="Ch6.E9.m1.1.1.1.1.3.3">subscript</csymbol><sum id="Ch6.E9.m1.1.1.1.1.3.3.2.2.cmml" xref="Ch6.E9.m1.1.1.1.1.3.3.2.2"></sum><apply id="Ch6.E9.m1.1.1.1.1.3.3.2.3.cmml" xref="Ch6.E9.m1.1.1.1.1.3.3.2.3"><eq id="Ch6.E9.m1.1.1.1.1.3.3.2.3.1.cmml" xref="Ch6.E9.m1.1.1.1.1.3.3.2.3.1"></eq><ci id="Ch6.E9.m1.1.1.1.1.3.3.2.3.2.cmml" xref="Ch6.E9.m1.1.1.1.1.3.3.2.3.2">𝑖</ci><cn id="Ch6.E9.m1.1.1.1.1.3.3.2.3.3.cmml" type="integer" xref="Ch6.E9.m1.1.1.1.1.3.3.2.3.3">1</cn></apply></apply><apply id="Ch6.E9.m1.1.1.1.1.3.3.3.cmml" xref="Ch6.E9.m1.1.1.1.1.3.3.3"><minus id="Ch6.E9.m1.1.1.1.1.3.3.3.1.cmml" xref="Ch6.E9.m1.1.1.1.1.3.3.3.1"></minus><ci id="Ch6.E9.m1.1.1.1.1.3.3.3.2.cmml" xref="Ch6.E9.m1.1.1.1.1.3.3.3.2">𝑛</ci><cn id="Ch6.E9.m1.1.1.1.1.3.3.3.3.cmml" type="integer" xref="Ch6.E9.m1.1.1.1.1.3.3.3.3">1</cn></apply></apply><apply id="Ch6.E9.m1.1.1.1.1.3.2.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2"><apply id="Ch6.E9.m1.1.1.1.1.3.2.3.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="Ch6.E9.m1.1.1.1.1.3.2.3.1.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.3">superscript</csymbol><apply id="Ch6.E9.m1.1.1.1.1.3.2.3.2.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="Ch6.E9.m1.1.1.1.1.3.2.3.2.1.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.3">subscript</csymbol><sum id="Ch6.E9.m1.1.1.1.1.3.2.3.2.2.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.3.2.2"></sum><apply id="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.3.2.3"><eq id="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.1.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.1"></eq><ci id="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.2.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.2">𝑗</ci><apply id="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.3.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.3"><plus id="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.3.1.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.3.1"></plus><ci id="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.3.2.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.3.2">𝑖</ci><cn id="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.3.3.cmml" type="integer" xref="Ch6.E9.m1.1.1.1.1.3.2.3.2.3.3.3">1</cn></apply></apply></apply><ci id="Ch6.E9.m1.1.1.1.1.3.2.3.3.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.3.3">𝑛</ci></apply><apply id="Ch6.E9.m1.1.1.1.1.3.2.2.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.2"><csymbol cd="latexml" id="Ch6.E9.m1.1.1.1.1.3.2.2.3.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.2.3">direct-product</csymbol><apply id="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.cmml" xref="Ch6.E9.m1.1.1.1.1.2.1.1.1.1"><times id="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.1.cmml" xref="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.1"></times><apply id="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.2.cmml" xref="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.2"><csymbol cd="ambiguous" id="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.2.1.cmml" xref="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.2">subscript</csymbol><ci id="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.2.2.cmml" xref="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.2.2">𝑥</ci><ci id="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.2.3.cmml" xref="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.2.3">𝑖</ci></apply><apply id="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.3.cmml" xref="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.3"><csymbol cd="ambiguous" id="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.3.1.cmml" xref="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.3">subscript</csymbol><ci id="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.3.2.cmml" xref="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.3.2">𝑣</ci><ci id="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.3.3.cmml" xref="Ch6.E9.m1.1.1.1.1.2.1.1.1.1.1.3.3">𝑖</ci></apply></apply><apply id="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.2.2.1"><times id="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.1.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.1"></times><apply id="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.2.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.2"><csymbol cd="ambiguous" id="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.2.1.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.2">subscript</csymbol><ci id="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.2.2.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.2.2">𝑥</ci><ci id="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.2.3.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.2.3">𝑗</ci></apply><apply id="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.3.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.3"><csymbol cd="ambiguous" id="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.3.1.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.3">subscript</csymbol><ci id="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.3.2.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.3.2">𝑣</ci><ci id="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.3.3.cmml" xref="Ch6.E9.m1.1.1.1.1.3.2.2.2.1.1.3.3">𝑗</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch6.E9.m1.1c">\displaystyle f_{BI}(\mathcal{V}_{x})=\sum_{i=1}^{n-1}\sum_{j=i+1}^{n}(x_{i}v_%
{i})\odot(x_{j}v_{j}),</annotation><annotation encoding="application/x-llamapun" id="Ch6.E9.m1.1d">italic_f start_POSTSUBSCRIPT italic_B italic_I end_POSTSUBSCRIPT ( caligraphic_V start_POSTSUBSCRIPT italic_x end_POSTSUBSCRIPT ) = ∑ start_POSTSUBSCRIPT italic_i = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n - 1 end_POSTSUPERSCRIPT ∑ start_POSTSUBSCRIPT italic_j = italic_i + 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_n end_POSTSUPERSCRIPT ( italic_x start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) ⊙ ( italic_x start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT italic_v start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6.9)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="Ch6.S3.SS3.p6.4">where <math alttext="\odot" class="ltx_Math" display="inline" id="Ch6.S3.SS3.p6.3.m1.1"><semantics id="Ch6.S3.SS3.p6.3.m1.1a"><mo id="Ch6.S3.SS3.p6.3.m1.1.1" xref="Ch6.S3.SS3.p6.3.m1.1.1.cmml">⊙</mo><annotation-xml encoding="MathML-Content" id="Ch6.S3.SS3.p6.3.m1.1b"><csymbol cd="latexml" id="Ch6.S3.SS3.p6.3.m1.1.1.cmml" xref="Ch6.S3.SS3.p6.3.m1.1.1">direct-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S3.SS3.p6.3.m1.1c">\odot</annotation><annotation encoding="application/x-llamapun" id="Ch6.S3.SS3.p6.3.m1.1d">⊙</annotation></semantics></math> denotes an element-wise product of two vectors.
The output of bi-interaction pooling is a <math alttext="d" class="ltx_Math" display="inline" id="Ch6.S3.SS3.p6.4.m2.1"><semantics id="Ch6.S3.SS3.p6.4.m2.1a"><mi id="Ch6.S3.SS3.p6.4.m2.1.1" xref="Ch6.S3.SS3.p6.4.m2.1.1.cmml">d</mi><annotation-xml encoding="MathML-Content" id="Ch6.S3.SS3.p6.4.m2.1b"><ci id="Ch6.S3.SS3.p6.4.m2.1.1.cmml" xref="Ch6.S3.SS3.p6.4.m2.1.1">𝑑</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch6.S3.SS3.p6.4.m2.1c">d</annotation><annotation encoding="application/x-llamapun" id="Ch6.S3.SS3.p6.4.m2.1d">italic_d</annotation></semantics></math>-dimension vector that encodes the second-order interactions between features in the embedding space.
Through stacking non-linear layers above the bi-interaction layer, NFM can effectively model higher-order and nonlinear feature interactions. In contrast to traditional deep learning methods that simply concatenate or average embedding vectors in the low level, the use of bi-interaction pooling encodes more informative feature interactions. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6.F5" title="Figure 6.5 ‣ 6.3.3 Neural network models ‣ 6.3 Candidate ranking models ‣ Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6.5</span></a> illustrates the architecture of NFM.</p>
</div>
<figure class="ltx_figure" id="Ch6.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="432" id="Ch6.F5.g1" src="x39.png" width="664"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6.5: </span>Overview of neural factorization machines. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">he2017neural</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch6.S3.SS3.p7">
<p class="ltx_p" id="Ch6.S3.SS3.p7.1">As demonstrated in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4.E1" title="In 4.1.1 Click behavior modeling ‣ 4.1 User behavior modeling in e-commerce ‣ Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4.1</span></a>, DeepFM <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2017deepfm</span>]</cite> aims at learning both low and high-order feature interactions, and consists of two components: the FM component and the deep component.
Compared with Wide&amp;Deep, DeepFM replaces its wide component with FM to remedy its shortcoming in automatic feature combination. Another difference is that DeepFM shares the feature embedding between the FM and deep component.
Besides NFM and DeepFM, many other neural networks also have been proposed based on <abbr class="ltx_glossaryref" title="factorization machine"><span class="ltx_text ltx_glossary_short-plural">FMs</span></abbr>: FNN <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2016deep</span>]</cite> directly stacks <abbr class="ltx_glossaryref" title="factorization machine"><span class="ltx_text ltx_glossary_short-plural">FMs</span></abbr> with neural networks; PNN <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">qu2016product</span>]</cite> models both bit-wise interactions and vector-wise feature interactions; and xDeepFM <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lian2018xdeepfm</span>]</cite> extends deepFM with explicit high-order feature interactions.</p>
</div>
<div class="ltx_para ltx_noindent" id="Ch6.S3.SS3.p8">
<p class="ltx_p" id="Ch6.S3.SS3.p8.1"><span class="ltx_text ltx_font_bold" id="Ch6.S3.SS3.p8.1.1">Attention mechanisms.</span>
Attention mechanisms have been applied in recommender systems and achieved a great success <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">AFM</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">LiRCRLM17</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2019deep</span>]</cite>.
As far as we know, AFM <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">AFM</span>]</cite> is an early attempt to introduce the attention mechanism to recommendation. It can be regarded as an extension of NFM.
The sum pooling operation in NFM treats all pairwise feature interactions equally, which may produce suboptimal results.
To address this problem, AFM uses the attention mechanism on feature interactions by performing a weighted sum on the interacted vectors.
The output of the attention-based pooling layer is projected into the prediction score.
In session-based or sequential recommendation scenarios,
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">LiRCRLM17</span></cite> proposed an encoder-decoder model, namely neural attentive recommendation machine (NARM), to emphasize a user’s main purpose in the current session.
The authors adopted a hybrid encoder structure with a global component for modeling long-term purposes and a local component for modeling short-term purposes.
Based on the combined session representation, a bi-linear matching scheme was then applied to compute the recommendation scores for each candidate item.
Following NARM, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ren2018repeatnet</span></cite> proposed the RepeatNet model to deal with the phenomenon of repeat consumption behaviors.
The authors incorporated a repeat-explore mechanism into neural networks, which can select items from a user’s history and suggests them at the appropriate moment.
In standard embedding paradigms, user features are compressed into fixed-length representation vectors. However, the fixed-length vectors restrict the capture of the diverse interests of the user from historical behaviors.
<cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2018deep</span>]</cite> proposed the deep interest network (DIN) to tackle this challenge by designing a local attention unit. The local attention unit in DIN adaptively learns the representation of user interests from historical behaviors by taking account of the relevance of historical behaviors.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">Yuan2021Looking</span></cite> unified existing CTR prediction models using a discrete choice model based on the self-attention mechanism. The authors regarded feature interaction as the individual’s comprehensive measurement of the influence of different factors on the decision-making process.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch6.S3.SS4">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3.4 </span>Retraining strategies</h4>
<div class="ltx_para" id="Ch6.S3.SS4.p1">
<p class="ltx_p" id="Ch6.S3.SS4.p1.1">E-commerce recommender systems rely on knowledge gleaned from historical interactions. As the collected interactions grows, recommendation models must be regularly retrained to reflect users’ dynamic preferences.
There are two intuitive heuristic retraining methods:</p>
<ul class="ltx_itemize" id="Ch6.S3.I2">
<li class="ltx_item" id="Ch6.S3.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch6.S3.I2.i1.p1">
<p class="ltx_p" id="Ch6.S3.I2.i1.p1.1"><span class="ltx_text ltx_font_bold" id="Ch6.S3.I2.i1.p1.1.1">Full retraining</span> simply merges the old data and new data to perform a full model training. The method is designed to capture both short-term and long-term features of the recommender system based on all the data it has accumulated.</p>
</div>
</li>
<li class="ltx_item" id="Ch6.S3.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="Ch6.S3.I2.i2.p1">
<p class="ltx_p" id="Ch6.S3.I2.i2.p1.1"><span class="ltx_text ltx_font_bold" id="Ch6.S3.I2.i2.p1.1.1">Fine-tune retraining</span> refers to using the parameters of the old model that were optimized by the old data to initialize the new model and train it with the new data. It reduces the time and storage overhead of retraining, making life-long updating feasible.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="Ch6.S3.SS4.p1.2">Numerous deep learning-based retraining methods have been proposed.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">SML</span></cite> proposed a sequential meta learning model (SML), including a meta-learning retraining framework for vanilla matrix factorization models. SML model captures the trend of changes between two distinct retraining phases at adjacent times.
Recently, graph convolutional neural network (GCN) has become the cutting-edge technique for recommendation <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">LightGCN</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">pinsage</span>]</cite>.
However, GCN-based recommender models encounter challenges regarding model retraining as GCN-based models take more time to converge.
CIGC <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">CIGC</span>]</cite> has been proposed with two novel operators: incremental graph convolution and colliding effect distillation.
The incremental graph convolution estimates the output of fully retraining the graph convolution using only new data; whereas the colliding effect distillation uses causal inference to retrain the representations of users (or items) that have no new data.</p>
</div>
</section>
</section>
<section class="ltx_section" id="Ch6.S4">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6.4 </span>Re-ranking strategies</h3>
<div class="ltx_para" id="Ch6.S4.p1">
<p class="ltx_p" id="Ch6.S4.p1.1">The two-stage framework still faces several problems in e-commerce recommendation:

<span class="ltx_inline-enumerate" id="Ch6.S4.I1">
<span class="ltx_inline-item" id="Ch6.S4.I1.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch6.S4.I1.i1.1">The point-wise objective functions (e.g., log-loss) at the ranking stage often become sub-optimal because of the neglect of mutual influences between items.
</span></span>
<span class="ltx_inline-item" id="Ch6.S4.I1.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch6.S4.I1.i2.1">Users with different preferences may exhibit different behavior patterns.
</span></span>
<span class="ltx_inline-item" id="Ch6.S4.I1.i3"><span class="ltx_tag ltx_tag_inline-item">(iii)</span> <span class="ltx_text" id="Ch6.S4.I1.i3.1">Recommendation result diversification has not yet been well addressed during the ranking stage.
</span></span>
</span>
Therefore, before exposing the recommendation items to users, most of e-commerce recommender systems usually refine the recommendation results through an additional re-ranking stages.
Generally, the goal of re-ranking is to enhance the recommendation results through
additional criteria or constraints <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Chen2017Improving</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zehlike2017fa</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">abdollahpouri2019popularity</span>]</cite>.
Existing methods on re-ranking can be categorized into two types: heuristic strategies and list-wise objective functions.
The former type of methods are based on determinantal point processes <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Wilhelm2018Practical</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Chen2017Improving</span>]</cite> and maximal marginal relevance <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Carbonell1998The</span>]</cite>. These methods have been widely applied in e-commerce to avoid the items with the same category being presented consecutively for greater diversity. While for list-wise objective functions, DLCM <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ai2018learning</span>]</cite> and PRM <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Pei2019Personalized</span>]</cite> were proposed with specific list-wise optimization objectives.</p>
</div>
</section>
<section class="ltx_section" id="Ch6.S5">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6.5 </span>Emerging directions</h3>
<div class="ltx_para" id="Ch6.S5.p1">
<p class="ltx_p" id="Ch6.S5.p1.1">We discuss five emerging research directions on e-commerce recommendation:

<span class="ltx_inline-enumerate" id="Ch6.S5.I1">
<span class="ltx_inline-item" id="Ch6.S5.I1.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch6.S5.I1.i1.1">structured recommendations,
</span></span>
<span class="ltx_inline-item" id="Ch6.S5.I1.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch6.S5.I1.i2.1">conversational recommendation,
</span></span>
<span class="ltx_inline-item" id="Ch6.S5.I1.i3"><span class="ltx_tag ltx_tag_inline-item">(iii)</span> <span class="ltx_text" id="Ch6.S5.I1.i3.1">reasoning recommendations and explanations,
</span></span>
<span class="ltx_inline-item" id="Ch6.S5.I1.i4"><span class="ltx_tag ltx_tag_inline-item">(iv)</span> <span class="ltx_text" id="Ch6.S5.I1.i4.1">biases and debiasing in recommendation, and
</span></span>
<span class="ltx_inline-item" id="Ch6.S5.I1.i5"><span class="ltx_tag ltx_tag_inline-item">(v)</span> <span class="ltx_text" id="Ch6.S5.I1.i5.1">unifying recommendation and search.
</span></span>
</span></p>
</div>
<section class="ltx_subsection" id="Ch6.S5.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.5.1 </span>Structured recommendations</h4>
<div class="ltx_para" id="Ch6.S5.SS1.p1">
<p class="ltx_p" id="Ch6.S5.SS1.p1.1">The task of structured recommendations is to predict the next structured item sets instead of the next item. we discuss three categories of structured recommendations: slate recommendation, playlist recommendation, and next-basket recommendation.</p>
</div>
<div class="ltx_para" id="Ch6.S5.SS1.p2">
<p class="ltx_p" id="Ch6.S5.SS1.p2.1">In applications like music or bundle recommendations, the objective is to provide users with a ’slate’—a combination of items—to maximize their engagement with the recommended content. This task raises critical questions, including the consideration of metrics such as diversity and the computational challenges posed by the combinatorial nature of slates. Reinforcement learning (RL) is extensively applied in slate recommendation<cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Ie2019ReinforcementLF</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Sunehag2015DeepRL</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/kdd/TomasiCKCRD23</span>]</cite>. However, due to the combinatorial complexity of actions, RL typically necessitates simplifying assumptions, such as the user selecting the optimal item <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Ie2019ReinforcementLF</span>]</cite>. An alternative approach involves integrating a separate user preference model to optimize slate assembly and subsequently training the RL model <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/kdd/TomasiCKCRD23</span>]</cite>. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/nips/SwaminathanKADL17</span></cite> investigated off-policy evaluation and optimization via inverse propensity scores for slate interactions. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/www/MehrotraLKLH19</span></cite> constructed a hierarchical model to assess user satisfaction in slate recommendation systems.</p>
</div>
<div class="ltx_para" id="Ch6.S5.SS1.p3">
<p class="ltx_p" id="Ch6.S5.SS1.p3.1">The music playlist recommendation can be considered as a special case of music recommendation, focusing on delivering a curated list of songs to users. The order and characteristics of music tracks significantly influence the playlist’s overall quality. An earlier study employed time-series-based machine learning to address the challenge of recommending music playlists<cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Choi2016TowardsPG</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Irene2019AutomaticPG</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Monti2018AnEA</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Vall2018TheIO</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Kim2018TowardsSM</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/dasfaa/YangZXYZZ19</span>]</cite>. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">Choi2016TowardsPG</span></cite> utilized a recurrent neural network (RNN) for music playlist generation, emphasizing track transition qualities. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">Monti2018AnEA</span></cite> implemented an ensemble of RNNs, leveraging pre-trained embeddings for album and title representation. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">Irene2019AutomaticPG</span></cite> predicted user preferences by analyzing manually created playlists, employing both RNN and convolutional neural network (CNN) models. Recent studies have employed reinforcement learning (RL)-based methods to capture users’ long-term preferences<cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Hu2017PlaylistRB</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/ismir/ShihC18</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/gcce/SakuraiTOH20</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/lifetech/SakuraiTOH21</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:journals/sensors/SakuraiTOH22</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/kdd/TomasiCKCRD23</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/atal/LiebmanSS15</span>]</cite>. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/atal/LiebmanSS15</span></cite> attempted to utilize a novel reinforcement-learning-based music recommendation system that generates playlists by considering both song preferences and transitions. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">Hu2017PlaylistRB</span></cite> enhanced playlist generation performance by integrating user feedback into the recommendation reward function. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/ismir/ShihC18</span></cite> incorporated novelty and popularity indices into the reward function, resulting in playlists with a mix of new and well-known tracks. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:journals/sensors/SakuraiTOH22</span></cite> utilized informative knowledge graphs to enhance reinforcement learning optimization, and allowing users to customize flexible reward functions to discover new music genres. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/kdd/TomasiCKCRD23</span></cite> presented a reinforcement learning framework optimizing directly for user satisfaction via the use of a simulated playlist-generation environment.</p>
</div>
<div class="ltx_para" id="Ch6.S5.SS1.p4">
<p class="ltx_p" id="Ch6.S5.SS1.p4.1">Next-basket recommendation(NBR) is a task focused on predicting a user’s next shopping basket based on their past purchase history, aiming to enhance user experience and satisfaction.
There are mainly three families of NBR methods. First are conventional NBR methods, such as those employing pattern mining<cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/icdm/GuidottiRPGP17</span>]</cite>, KNN models<cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/sigir/Hu0GZ20</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/um/FaggioliPA20</span>]</cite>, and Markov chain
models<cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/www/RendleFS10</span>]</cite>. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/sigir/Hu0GZ20</span></cite> and <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/um/FaggioliPA20</span></cite> model temporal patterns across frequency data and integrate this with neighbor information or user-wise collaborative filtering. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/www/RendleFS10</span></cite> leverage matrix factorization and Markov chains to model users’ general interest and basket transition relations. Second are latent representation methods, which utilized representation learning techniques to capture implicit patterns in data. For instance, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/sigir/WangGLXWC15</span></cite> applied aggregation operations to learn a hierarchical representation of user’s last basket to predict the next basket. Third are deep learning-based method. Recurrent neural networks (RNNs) have been extensively applied in next-basket recommendation, demonstrating their efficacy in learning long-term trends by modeling the whole basket sequence. For instance, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/sigir/YuLWWT16</span></cite> utilized max/avg pooling to encode baskets and <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/kdd/HuH19</span></cite> adapted an attention mechanism and integrate frequency information to improve performance. Some methods<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/ijcai/LeLF19</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/aaai/WangH0SOC20</span></cite> utilized item relations to enhance representation. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/kdd/YuSDL0L20</span></cite> employed graph neural networks (GNNs) to model item-item relations between baskets and a self-attention mechanism to discern temporal dynamics. Some methods <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/sigir/BaiNZZDW18</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:journals/corr/abs-2109-11654</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/dasfaa/LengYXX20</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/sigir/SunBDL0L20</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:journals/jcst/WangZNG19</span>]</cite> leverage auxiliary information, including product categories, amounts, prices, and explicit timestamps.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch6.S5.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.5.2 </span>Conversational recommendation</h4>
<div class="ltx_para" id="Ch6.S5.SS2.p1">
<p class="ltx_p" id="Ch6.S5.SS2.p1.1">The task of a  <span class="ltx_glossaryref" title="conversational recommender system"><span class="ltx_text ltx_glossary_long">conversational recommender system</span></span> (<abbr class="ltx_glossaryref" title="conversational recommender system"><span class="ltx_text ltx_glossary_short">CRS</span></abbr>) is to provide recommendations to users through conversational interactions. Since recently, <abbr class="ltx_glossaryref" title="conversational recommender system"><span class="ltx_text ltx_glossary_short-plural">CRSs</span></abbr> are attracting increasing attention <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2013interactive</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ConversationRS-KDD16</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yu2019visual</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zou2020neural</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">mangili2020bayesian</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ConversationRS-SIGIR18</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lei20estimation</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lei2020interactive</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2020improving</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2020towards</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2020topicguided</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2020conversational</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2020seamlessly</span>]</cite>.
According to <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gao-2021-advances</span>]</cite>, the task of <abbr class="ltx_glossaryref" title="conversational recommender system"><span class="ltx_text ltx_glossary_short">CRS</span></abbr> is formally defined as follows:</p>
<blockquote class="ltx_quote" id="Ch6.S5.SS2.p1.2">
<p class="ltx_p" id="Ch6.S5.SS2.p1.2.1"><em class="ltx_emph ltx_font_italic" id="Ch6.S5.SS2.p1.2.1.1">A recommendation system that can elicit the dynamic preferences of users and take actions based on their current needs through real-time multi-turn interactions.</em></p>
</blockquote>
<p class="ltx_p" id="Ch6.S5.SS2.p1.3">Building on advances in interactive recommendation <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">christakopoulou2018q</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2017factorization</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2020diversified</span>]</cite>,
early studies on <abbr class="ltx_glossaryref" title="conversational recommender system"><span class="ltx_text ltx_glossary_short-plural">CRSs</span></abbr> formulated the task as a specific application of task-oriented multi-turn dialogue systems (TDS) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/ccks/LeLWWLJ18</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">dhingra-EtAl:2017:Long1</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2017network</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2019memory</span>]</cite>.
For existing studies on <abbr class="ltx_glossaryref" title="conversational recommender system"><span class="ltx_text ltx_glossary_short-plural">CRSs</span></abbr>, there are two main types of strategies: attribute-aware and topic-guided.</p>
</div>
<div class="ltx_para" id="Ch6.S5.SS2.p2">
<p class="ltx_p" id="Ch6.S5.SS2.p2.1">Attribute-aware <abbr class="ltx_glossaryref" title="conversational recommender system"><span class="ltx_text ltx_glossary_short-plural">CRSs</span></abbr> aim to answer three main research questions: “whether to ask or recommend”, “which attributes to ask” or “which items to recommend.”
Early work on attribute-aware <abbr class="ltx_glossaryref" title="conversational recommender system"><span class="ltx_text ltx_glossary_short-plural">CRSs</span></abbr> obtained user preferences based on asking about items directly <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2013interactive</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2018online</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ConversationRS-KDD16</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zou2020neural</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/aaai/VendrovLHB20</span>]</cite>, or asking attributes through a heuristic method <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">christakopoulou2018q</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2018towards</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/sigir/LuoYWS20</span>]</cite>.
There are two main kinds of attribute-aware <abbr class="ltx_glossaryref" title="conversational recommender system"><span class="ltx_text ltx_glossary_short-plural">CRSs</span></abbr> solutions. One kind asks a fixed number of questions and makes a recommendation at the last turn <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lei20estimation</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lei2020interactive</span>]</cite>; whereas the other predicts a specific turn to recommend items.
Reinforcement learning strategies have been successfully applied to attribute-aware <abbr class="ltx_glossaryref" title="conversational recommender system"><span class="ltx_text ltx_glossary_short-plural">CRSs</span></abbr>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2020towards</span></cite> and <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">li2020seamlessly</span></cite> focused on cold-start users in conversational recommendation and extended bandit-based algorithms to balance the trade-off between exploration and exploitation.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zou2022improving</span></cite> proposed TSCR, a Transformer-based sequential conversational recommendation method that captures the sequential dependencies in dialogues to enhance recommendation accuracy.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">deng2023unified</span></cite> propose a novel Unified MultI-goal conversational recommender system, namely UniMIND, which unifies these goals into a single sequence-to-sequence (Seq2Seq) paradigm and employs prompt-based learning strategies to facilitate multi-task learning.</p>
</div>
<div class="ltx_para" id="Ch6.S5.SS2.p3">
<p class="ltx_p" id="Ch6.S5.SS2.p3.1">Topic-guided <abbr class="ltx_glossaryref" title="conversational recommender system"><span class="ltx_text ltx_glossary_short-plural">CRSs</span></abbr> interact with users through natural language conversations with fluent responses and precise recommendations <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/nips/LiKSMCP18</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2020topicguided</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/emnlp/ChenLZDCYT19</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2020towards</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2020improving</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/emnlp/MaTH21</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/wsdm/ZhouZZWJ022</span>]</cite>.
Unlike attribute-aware <abbr class="ltx_glossaryref" title="conversational recommender system"><span class="ltx_text ltx_glossary_short-plural">CRSs</span></abbr>, topic-guided <abbr class="ltx_glossaryref" title="conversational recommender system"><span class="ltx_text ltx_glossary_short-plural">CRSs</span></abbr> focus on making recommendations using free text, which creates considerable flexibility to influence how a dialogue continues.
External knowledge has been applied in topic-guided <abbr class="ltx_glossaryref" title="conversational recommender system"><span class="ltx_text ltx_glossary_short-plural">CRSs</span></abbr> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/emnlp/MaTH21</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2020improving</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/emnlp/ChenLZDCYT19</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/emnlp/ChenLZDCYT19</span></cite> integrated a recommendation system and a dialogue system via an end-to-end framework to bridge the gap between the two systems.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/nips/LiKSMCP18</span></cite> used an auto-encoder for recommendation and a hierarchical RNN for response generation.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2020topicguided</span></cite> proposed a topic-guided <abbr class="ltx_glossaryref" title="conversational recommender system"><span class="ltx_text ltx_glossary_short-plural">CRSs</span></abbr> method that incorporates topic threads to enforce transitions actively toward a final recommendation.
Recently, external knowledge graphs have been shown to be effective in improving the performance of topic-guided conversational recommendation systems.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/emnlp/ChenLZDCYT19</span></cite> applied knowledge graphs to enhance the semantics of contextual items for recommendation.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2020improving</span></cite> incorporated both word-oriented and entity-oriented knowledge graphs.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/emnlp/MaTH21</span></cite> performed a tree-structured reasoning on a knowledge graph for recommendation.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2022analyzing</span></cite> focused on user reformulation behaviors to improve the robustness of conversational agents.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ren2022variational</span></cite> explored user preferences in conversational recommendation, proposed a variational reasoning mechanism to jointly track both short-term and long-term user behaviors.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2023variational</span></cite> made the first attempt to explicitly address the problem of dynamic reasoning over incomplete knowledge graphs. However, none of the existing studies are capable of fusing recommendation and response generation in an end-to-end manner, which limits the potential for mutual reinforcement between these two tasks. Additionally, a lack of interpretability in current conversational recommendation system (CRS) models further hinders their ability to fully align with user needs.
Existing models are typically trained on conversational recommendation datasets, but the assumption that the standard items and responses in these benchmark datasets are optimal leads to a tendency for CRSs to replicate the logic of the recommenders found in the data, rather than truly addressing the evolving needs of the users. This misalignment remains a significant challenge in advancing more user-centric and adaptable conversational recommendation systems.</p>
</div>
<div class="ltx_para" id="Ch6.S5.SS2.p4">
<p class="ltx_p" id="Ch6.S5.SS2.p4.1">Although <abbr class="ltx_glossaryref" title="conversational recommender system"><span class="ltx_text ltx_glossary_short-plural">CRSs</span></abbr> poses many merits, its evaluation is still a thorny issue.
Recent studies have evaluated <abbr class="ltx_glossaryref" title="conversational recommender system"><span class="ltx_text ltx_glossary_short-plural">CRSs</span></abbr> either through offline evaluation or human evaluation <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Lamel2000TheLA</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2015toward</span>]</cite>.
Offline evaluation evaluates a dialogue system based on test sets, whereas human evaluation reflects the overall performance of the agent through in-field experiments <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Black2011SpokenDC</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gilotte2018offline</span>]</cite> or crowd-sourcing <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2020topicguided</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/nips/LiKSMCP18</span>]</cite>.
However, offline evaluation is often limited to single turn assessments, while human evaluation is intrusive, time-intensive, and is not scalable <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2019toward</span>]</cite>.
As an alternative, user simulators that mimic user behavior are able to provide broad insights to generate human-like conversations for assessing <abbr class="ltx_glossaryref" title="conversational recommender system"><span class="ltx_text ltx_glossary_short-plural">CRSs</span></abbr> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">afzali2023usersimcrs</span>]</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch6.S5.SS3">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.5.3 </span>Explainable e-commerce recommendation</h4>
<div class="ltx_para" id="Ch6.S5.SS3.p1">
<p class="ltx_p" id="Ch6.S5.SS3.p1.1">Although recommendation models can generate relevant items for users in many e-commerce applications, it is often ambiguous to understand why an item is recommended to a user.
Hence it is necessary to develop explainable recommendation strategies to generate not only high-quality recommendations but also intuitive explanations.
Recent years have witnessed increasing publications on explainable recommendation. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2014explicit</span></cite> generated textual sentences as recommendation explanation to help users understand each recommendation result.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2018visually</span></cite> proposed visually explainable recommendations where particular regions of a recommended image are highlighted as the visual explanations for users. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">sharma2013social</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">quijano2017make</span></cite> generated a list of social friends who also liked the recommended product as social explanations for target user, whereas <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">gao2019bloma</span></cite> generated the recommendation described by a set of topics.</p>
</div>
<div class="ltx_para" id="Ch6.S5.SS3.p2">
<p class="ltx_p" id="Ch6.S5.SS3.p2.1">Several researchers have started to generate explanations for deep recommendation models. For example, several studies leverage knowledge graph for interpretation. They aim to construct multi-hop paths from users to items along the knowledge graph, which indicates a specific explainable user-item relation <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">hu2018leveraging</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2019explainable</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">xian2019reinforcement</span>]</cite>. Besides, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2021neural</span></cite> proposed a neural collaborative reasoning system integrating the power of representation learning and logical reasoning. However, research on explainable deep recommendation models is relatively new and deserve to be further explored in e-commerce.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch6.S5.SS4">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.5.4 </span>Biases and debiasing in recommendations</h4>
<div class="ltx_para" id="Ch6.S5.SS4.p1">
<p class="ltx_p" id="Ch6.S5.SS4.p1.1">Many recommendation solutions about fitting user behaviors may deteriorate owing to biases in behavior inherent in e-commerce recommendation  <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">LightGCN</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2019bert4rec</span>]</cite>.
In e-commerce scenarios, user behaviors are observational rather than experimental, which is often affected by many factors, e.g., self-selection of the user (selection bias) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">marlin2007collaborative</span>]</cite>, systematic exposure mechanisms (exposure bias) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ovaisi2020correcting</span>]</cite>, public opinions (conformity bias) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">krishnan2014methodology</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liang2016modeling</span>]</cite> and the display position (position bias) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">joachims2007evaluating</span>]</cite>.
These biases make the data deviate from reflecting true preferences of users in recommender systems.
Efforts to debias recommendation can be divided into three major categories:

<span class="ltx_inline-enumerate" id="Ch6.S5.I2">
<span class="ltx_inline-item" id="Ch6.S5.I2.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch6.S5.I2.i1.1">data imputation, which assigns pseudo-labels to missing data to reduce variance <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">steck2013evaluation</span>]</cite>,
</span></span>
<span class="ltx_inline-item" id="Ch6.S5.I2.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch6.S5.I2.i2.1">inverse propensity scoring (IPS), which reweighs the collected data for an expectation-unbiased learning <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2019debiasing</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2016learning</span>]</cite>, and </span></span>
<span class="ltx_inline-item" id="Ch6.S5.I2.i3"><span class="ltx_tag ltx_tag_inline-item">(iii)</span> <span class="ltx_text" id="Ch6.S5.I2.i3.1">generative modeling, which assumes the generation process of data and reduces biases <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liang2016modeling</span>]</cite>.
</span></span>
</span>
Most approaches lack the universal capacity to account for mixed or even unknown biases.
To bridge the gap, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2021autodebias</span></cite> proposed a universal debiasing framework that not only account for multiple biases and their combinations, but also
frees human efforts to identify biases.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">10.1145/3488560.3498375</span></cite> introduced DANCER, a debiasing method that accounts for dynamic selection bias and user preferences, demonstrating its improved rating prediction performance over static bias methods.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">10.1145/3583780.3615011</span></cite> explored the use of uncertainty estimates in ranking scores to reduce societal biases in retrieved documents while minimizing utility loss. They proposed an uncertainty-aware, post hoc bias mitigation method that outperforms existing baselines in terms of utility-fairness trade-offs, controllability, and computational costs, without requiring additional training.
Although recent years have seen a surge in research effort on recommendation biases, biases are still a huge problem in e-commerce recommender systems. Sophisticated meta models to capture complex patterns and exploration of dynamic biases in recommendation should provide helpful insights.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch6.S5.SS5">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.5.5 </span>Unifying recommendation and search</h4>
<div class="ltx_para" id="Ch6.S5.SS5.p1">
<p class="ltx_p" id="Ch6.S5.SS5.p1.1">Search and recommendation in e-commerce have similar characteristics, except for the different representation of “contexts” — search aims at retrieving relevant items for matching “query” while recommendation aims at finding items for matching user preference. However, researchers usually conduct separate studies on them and use different techniques and training data for the two tasks. Thus, building a unified model for search and recommendation has the potential to improve both tasks as more comprehensive user behavior data can be used. One practical way to unify the two tasks is aforementioned conversational recommendation, and the other is personalized search, which we detail next.</p>
</div>
<div class="ltx_para" id="Ch6.S5.SS5.p2">
<p class="ltx_p" id="Ch6.S5.SS5.p2.1">Early search engines, like Google and AltaVista, retrieved personalized results based on keywords.
Personalized search, as pioneered by Google, has become far more complex with the goal to “understand exactly what you mean and give you exactly what you want.” Concretely, a personalized search engine not only focuses on retrieving items that satisfy the user’s current information needs, which is usually related to the query topic, but also considers user personality and aims at retrieving items that meet user preference. To achieve both goals, it is critical to model the interactions between users, items and queries.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ai2017learning</span></cite> leveraged hierarchical embedding model to linearly combine the item-query matching scores with item-user preference scores;
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2019attentive</span></cite> explored long and short term user preference learning model for personalized search;
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">10.1145/3459637.3482489</span></cite> integrated user behaviors in search and recommendation into a heterogeneous behavior sequence and used a joint model to handle both tasks based on this unified sequence;
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">si2023search</span></cite> leveraged users’ search interests for recommendations. It separately learns similar and dissimilar representations from search and recommendation behaviors using transformer encoders;
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2020structural</span></cite> constructed a specific user-item-query graph and conducts node representation learning on the graph.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">10.1145/3488560.3498414</span></cite> proposed a method that jointly predict user clicks for both search and recommendation scenarios by constructing a unified graph to share user and item representations uniformly. Such kind of graph embedding techniques open the potential to integrate both node information and topological structure information, which can capture high-order user-item-query interactions.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch6.S5.SS6">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.5.6 </span>LLMs in recommendation</h4>
<div class="ltx_para" id="Ch6.S5.SS6.p1">
<p class="ltx_p" id="Ch6.S5.SS6.p1.1">Large language models (LLMs) have exhibited strong capabilities in understanding and processing text and researchers hope to apply LLMs to recommendation systems.
The main benefit of using LLMs in recommendation systems is their ability to produce high-quality representations of text features and make use of the wide range of knowledge they hold <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2023pre</span>]</cite>. LLM-based models can capture context more accurately, allowing them to understand better user questions, product descriptions, and other textual information.
Existing studies to apply LLMs to recommendation systems can be divided into two categories: discriminative strategies and generative strategies.</p>
</div>
<div class="ltx_para" id="Ch6.S5.SS6.p2">
<p class="ltx_p" id="Ch6.S5.SS6.p2.1">For studies about discriminative strategies, to improve the quality of vector representations for queries and products, and fully utilize the external knowledge stored in LLMs, a common approach is to fine-tune the original models, adapting them to recommendation tasks in order to obtain high-quality representations.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">qiu2021u</span></cite> proposed a novel U-BERT approach that utilizes a pre-training and fine-tuning framework to learn user representations. By leveraging content-rich domains, U-BERT compensates for users’ features in domains where behavior data is insufficient, improving recommendation performance.
Similarly,  <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2021userbert</span></cite> utilized unlabeled user behavior data and incorporates two self-supervised tasks: masked behavior prediction and behavior sequence matching for user model training.</p>
</div>
<div class="ltx_para" id="Ch6.S5.SS6.p3">
<p class="ltx_p" id="Ch6.S5.SS6.p3.1">Compared to discriminative models, generative models have better natural language generation capabilities. Therefore, most generative models typically translate recommendation tasks into natural language tasks, allowing the model to directly output recommendation results through fine-tuning or in-context learning.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2023chatgpt</span></cite> introduced a sliding window prompt strategy for ranking candidates. This strategy ranks items within a window at each step, sliding the window from back to front multiple times to generate the final ranking results. This approach helps improve ranking performance by iteratively refining the candidate list.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">kang2023llms</span></cite> investigated the ability of LLMs to predict user ratings based on past behavior, comparing them with traditional Collaborative Filtering (CF) methods.</p>
</div>
<div class="ltx_para" id="Ch6.S5.SS6.p4">
<p class="ltx_p" id="Ch6.S5.SS6.p4.1">Given existing advances for such area, there is still challenges which guide the future research for LLMs in e-commerce recommender systems</p>
</div>
</section>
</section>
</section>
<section class="ltx_chapter" id="Ch7" lang="en">
<h2 class="ltx_title ltx_title_chapter">
<span class="ltx_tag ltx_tag_chapter">Chapter 7 </span>E-commerce QA and conversations</h2>
<div class="ltx_para" id="Ch7.p1">
<p class="ltx_p" id="Ch7.p1.1">Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3" title="Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3</span></a> provides insights on how natural language processing technologies have been widely applied in e-commerce platform interfaces to help consumers better communicate with e-commerce portals.
This chapter demonstrates question answering (QA) services and dialogue systems in e-commerce portals.
We divide this chapter into three sections: e-commerce question answering, e-commerce dialogue systems, and emerging directions.
Specifically, we first detail characteristics and existing approaches to e-commerce question answering (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S1" title="7.1 Question answering in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.1</span></a>).
Then, we demonstrate recent studies on dialogue systems applicable in e-commerce customer services (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S2" title="7.2 Dialogue systems in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.2</span></a>).
Lastly, we briefly describe emerging directions in e-commerce question answering and dialogue systems (Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S3" title="7.3 Emerging directions ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.3</span></a>).</p>
</div>
<section class="ltx_section" id="Ch7.S1">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7.1 </span>Question answering in e-commerce</h3>
<div class="ltx_para" id="Ch7.S1.p1">
<p class="ltx_p" id="Ch7.S1.p1.1">In this section, we describe related work on e-commerce question answering. We divide this section into <math alttext="3" class="ltx_Math" display="inline" id="Ch7.S1.p1.1.m1.1"><semantics id="Ch7.S1.p1.1.m1.1a"><mn id="Ch7.S1.p1.1.m1.1.1" xref="Ch7.S1.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="Ch7.S1.p1.1.m1.1b"><cn id="Ch7.S1.p1.1.m1.1.1.cmml" type="integer" xref="Ch7.S1.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S1.p1.1.m1.1c">3</annotation><annotation encoding="application/x-llamapun" id="Ch7.S1.p1.1.m1.1d">3</annotation></semantics></math> parts: we first briefly introduce existing studies on question answering in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S1.SS1" title="7.1.1 Introduction to question answering ‣ 7.1 Question answering in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.1.1</span></a>, then in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S1.SS2" title="7.1.2 Characteristics of e-commerce question answering ‣ 7.1 Question answering in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.1.2</span></a> we formulate characteristics of product-aware question answering; eventually, we detail existing approaches on e-commerce question answering in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S1.SS3" title="7.1.3 Extractive product-aware QA ‣ 7.1 Question answering in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.1.3</span></a> and Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S1.SS4" title="7.1.4 Generative product-aware QA ‣ 7.1 Question answering in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.1.4</span></a>.</p>
</div>
<section class="ltx_subsection" id="Ch7.S1.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1.1 </span>Introduction to question answering</h4>
<div class="ltx_para" id="Ch7.S1.SS1.p1">
<p class="ltx_p" id="Ch7.S1.SS1.p1.1">We first provide a brief introduction to question answering (QA) research.
QA systems <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">simmons1965answering</span>]</cite> greatly facilitate users’ access to information for many web-based applications, where QA services provide a proper answer to a given question from the user <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">heilman2010tree</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2002learning</span>]</cite>.
Question answering research has received much attention in the past decades, including approaches to question classification, answer selection, answer generation, and answer summarization <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2002learning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">heilman2010tree</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2016retrieving</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">geigle2016scaling</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">song2017summarizing</span>]</cite>.
QA systems have various classifications.
According to the dimensionality of questions, existing QA systems can be divided into open-domain and specific-domain QA systems <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2020open</span>]</cite>.
Open-domain QA focuses on answering questions relying on knowledge and ontologies <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ferrucci2010building</span>]</cite>, whereas specific-domain QA focuses on providing proper answers in a specific scenario, e.g., customer service, hotel booking, etc.
Existing QA systems can be divided into retrieval-based and generation-based QA systems according to how they generate answers <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2015wikiqa</span>]</cite>.
The former searches and extracts potential answers via search engines, whereas the latter applies generation-based methods to give proper answers to the questions.
According to the answers, QA systems can be divided into factoid QA and non-factoid QA <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">song2017summarizing</span>]</cite>.
Factoid QA systems return a concise answer to the given question, whereas
non-factoid QA systems provide more subjective answers to the given questions.</p>
</div>
<div class="ltx_para" id="Ch7.S1.SS1.p2">
<p class="ltx_p" id="Ch7.S1.SS1.p2.2">During the early stage of QA studies, there are <math alttext="4" class="ltx_Math" display="inline" id="Ch7.S1.SS1.p2.1.m1.1"><semantics id="Ch7.S1.SS1.p2.1.m1.1a"><mn id="Ch7.S1.SS1.p2.1.m1.1.1" xref="Ch7.S1.SS1.p2.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="Ch7.S1.SS1.p2.1.m1.1b"><cn id="Ch7.S1.SS1.p2.1.m1.1.1.cmml" type="integer" xref="Ch7.S1.SS1.p2.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S1.SS1.p2.1.m1.1c">4</annotation><annotation encoding="application/x-llamapun" id="Ch7.S1.SS1.p2.1.m1.1d">4</annotation></semantics></math> categories of QA systems: list-structured database systems, graphical database systems, text-based systems, and logical inference systems forms <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">simmons1965answering</span>]</cite>. All these systems focus on the limited scope with rule-based strategies.
Search engines remain integral components of QA systems.
With the development of information retrieval, researchers find that QA systems can be a new research direction <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">jurafsky2000speech</span>]</cite>.
In 1999, TREC-QA tracks were proposed to provide benchmarks for researchers <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">srihari1999information</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">voorhees1999trec</span>]</cite>.
There are <math alttext="3" class="ltx_Math" display="inline" id="Ch7.S1.SS1.p2.2.m2.1"><semantics id="Ch7.S1.SS1.p2.2.m2.1a"><mn id="Ch7.S1.SS1.p2.2.m2.1.1" xref="Ch7.S1.SS1.p2.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="Ch7.S1.SS1.p2.2.m2.1b"><cn id="Ch7.S1.SS1.p2.2.m2.1.1.cmml" type="integer" xref="Ch7.S1.SS1.p2.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S1.SS1.p2.2.m2.1c">3</annotation><annotation encoding="application/x-llamapun" id="Ch7.S1.SS1.p2.2.m2.1d">3</annotation></semantics></math> main components in a retrieval-based TREC-QA system: question processing, passage retrieval, and answer processing <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">jurafsky2000speech</span>]</cite>.
For each step, sub-tasks must be considered, e.g., query formulation or answer type detection. Based on such a framework, several approaches have been proposed to address research tasks in each component <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">brill2001data</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2002learning</span>]</cite>.
Early studies on QA focus on factoid QA systems that generate concise answers <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">srihari1999information</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">jurafsky2000speech</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">brill2001data</span>]</cite>.
Retrieval-based methods effectively answer these concise and simple questions <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">jurafsky2000speech</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ahn2004using</span>]</cite>.
However, complicated questions are found difficult to be addressed by pure retrieval-based methods <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lin2006role</span>]</cite>.
Therefore, integrating natural language understanding and knowledge reasoning techniques is essential for retrieval-based QA strategies in answering complicated questions.</p>
</div>
<div class="ltx_para" id="Ch7.S1.SS1.p3">
<p class="ltx_p" id="Ch7.S1.SS1.p3.1">In TREC-QA 2004, questions are grouped into topics, which motivates research on fact identification from reference knowledge resources, e.g., Wikipedia <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ahn2004using</span>]</cite>.
Wikipedia can be considered a generic collection of articles with real-world facts for open-domain QA systems.
With the development of knowledge bases (KBs), innovations have occurred in the context of QA from KBs with the creation of resources like web questions and short questions <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">berant2013semantic</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">bordes2015large</span>]</cite>.
However, inherent limitations such as incompleteness and fixed schemas still exist in traditional KB-based QA systems.
Thus increasing QA studies generate answers from raw text explored on Wikipedia <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ryu2014open</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ahn2004using</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">buscaldi2006mining</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ferrucci2010building</span>]</cite>.
As far as we know, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ahn2004using</span></cite> first combined Wikipedia as a text resource with another.
Similarly, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ryu2014open</span></cite> performed a QA system using a Wikipedia-based knowledge model by combining articles with other answer-matching components.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ferrucci2010building</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">baudivs2015yodaqa</span></cite> integrated web-based and Wikipedia-based articles as knowledge resources into highly developed full-pipeline QA platforms.</p>
</div>
<div class="ltx_para" id="Ch7.S1.SS1.p4">
<p class="ltx_p" id="Ch7.S1.SS1.p4.1">In recent years, increasing QA models have been proposed by applying deep neural networks to understand the questions and generate answers.
<cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yin2015neural</span>]</cite> presented an end-to-end neural network model, namely neural generative question answering (GENQA), that can generate answers to simple factoid questions.
A bi-directional attention flow mechanism was then proposed to obtain a query-aware passage representation <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">seo2016bidirectional</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2017reading</span></cite> developed a system for question answering from Wikipedia, namely DrQA, composed of a two-stage retrieval-reader QA framework.
DrQA includes a document retriever module via bigram hashing and TF-IDF matching.
It also contains a document reader module where a multi-layer recurrent neural network is trained to detect answer spans in those few returned documents.</p>
</div>
<div class="ltx_para" id="Ch7.S1.SS1.p5">
<p class="ltx_p" id="Ch7.S1.SS1.p5.1">Following <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2017reading</span></cite>, most existing open-domain QA systems apply a two-stage retrieval-reader framework in their QA mechanisms <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2018r</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2018open</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lin2018denoising</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">pang2019has</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lee2019latent</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">guu2020retrieval</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">karpukhin2020dense</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">izacard2021leveraging</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">mao2020generation</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sachan2021end</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">NEURIPS2021_da3fde15</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yu-etal-2022-kg</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/emnlp/KediaZL22</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/emnlp/Ju00Z022</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/acl/WangY023</span>]</cite>.
These studies employed a determinate retrieval function and treated each passage independently in the retrieval stage:
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2018r</span></cite> proposed a reinforcement learning-based ranking strategy in the retrieval stage.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2018open</span></cite> offered a graph convolution-based neural network by operating over heterogeneous graphs of KB facts and text sentences.
In contrast with previous KB-based open-domain QA systems, the authors propose heterogeneous update rules that handle KB nodes differently from the text nodes.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">lin2018denoising</span></cite> proposed a coarse-to-fine denoising model to extract correct answers from multiple paragraphs in the noisy data.
Their model employed a paragraph selector to filter out those noisy paragraphs and keep those informative paragraphs.
Similarly, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">pang2019has</span></cite> proposed a three-level probabilistic formulation model for open-domain QA.
Word-level matching strategies are usually applied in the retrieval stage to match keywords represented in high-dimensional and sparse vectors.
Dense passage retrieval has been successfully applied to open-domain QA to improve the matching performance as it is complementary to sparse representations in the retrieval stage.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">karpukhin2020dense</span></cite> aimed to train a dense embedding model using only pairs of questions and passages.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">izacard2021leveraging</span></cite> proposed an effective two-step dense passage retrieval method. First, the authors retrieved supporting passages using either sparse or dense embeddings, then employed a sequence-to-sequence model to generate the answer.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhu2021adaptive</span></cite> used the partially observed Markov decision process (POMDP) to formulate the QA research problem to address the mismatch problem through the determinate retrieval function.
The authors applied a reinforcement learning method to reflect the interactive characteristics between the QA model (i.e., agent), including a belief module with a set of evidence for state performance, and the intractable large-scale corpus.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">yu-etal-2022-kg</span></cite> leveraged a knowledge graph to establish relational dependencies among retrieved passages and employed a graph neural network to re-rank retrieved passages for each query.
Recently, several studies have been proposed to improve reader performance and thereby improve QA performance. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/emnlp/KediaZL22</span></cite> proposed a method fusing information across multiple passages within a transformer encoder using global representation tokens. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/emnlp/Ju00Z022</span></cite> proposed a knowledge graph enhanced passage reader which fuses graph and contextual representations into the hidden states of the reader model. <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/acl/WangY023</span></cite> enhanced the Fusion-in-Decoder (FiD) framework by incorporating a rationale identification process to distinguish between relevant and spurious passages, thereby improving the model’s reasoning and performance in open-domain QA.</p>
</div>
<div class="ltx_para" id="Ch7.S1.SS1.p6">
<p class="ltx_p" id="Ch7.S1.SS1.p6.1">Relevant studies have also been proposed to enhance QA performance through reading comprehension.
A model that matches the question with a passage using gated attention-based recurrent networks has been verified effective in QA benchmark datasets <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2017gated</span>]</cite>.
QANet was proposed to combine local convolution with global self-attention for reading comprehension, which improved the reading comprehension performances <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yu2018qanet</span>]</cite>.
Recent studies also verified that pre-trained language models effectively understand questions and answers in QA systems <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">guu2020retrieval</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">mao2020generation</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sachan2021end</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">NEURIPS2021_da3fde15</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">mao2020generation</span></cite> augmented a query in open-domain QA using text generation of a pre-trained language model.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">sachan2021end</span></cite> proposed a QA method with an unsupervised pre-training of the retriever with a supervised fine-tune procedure.</p>
</div>
<div class="ltx_para" id="Ch7.S1.SS1.p7">
<p class="ltx_p" id="Ch7.S1.SS1.p7.1">During past decades, many benchmark QA datasets have been proposed.
Several QA benchmark datasets, such as SQuAD <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">rajpurkar2016squad</span>]</cite>, TriviaQA <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">joshi2017triviaqa</span>]</cite>, and SearchQA <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">dunn2017searchqa</span>]</cite>, only evaluate the reasoning ability within a single paragraph, whereas the other relevant documents or paragraphs are neglected.
Moreover, these datasets employ existing knowledge bases for multi-hop reasoning, constrained by the schema of existing knowledge bases.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2018hotpotqa</span></cite> proposed an open-domain QA benchmark dataset, namely HotpotQA, which requires reasoning over multiple documents without constraining itself to an existing knowledge base.
To understand how the questions and answers are distributed in open-domain QA, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">lewis2020question</span></cite> performed large-scale analysis on open-domain QA benchmark datasets, and provided annotated subsets of test sets indicating whether test-time questions are duplicates of training time questions.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch7.S1.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1.2 </span>Characteristics of e-commerce question answering</h4>
<div class="ltx_para" id="Ch7.S1.SS2.p1">
<p class="ltx_p" id="Ch7.S1.SS2.p1.1">E-commerce QA services focus on answering product-aware questions asked by e-commerce users.
Early studies on e-commerce QA focused on providing answers automatically from reviews by heuristic methods <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2009answering</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">moghaddam2011aqa</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yu2012answering</span>]</cite>.
With the development of both QA techniques and e-commerce services, e-commerce QA has received increasing attention in recent years <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mcauley2016addressing</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yu2017modelling</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yu2018aware</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">fan2019reading</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2020answer</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gao2019product</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gaoshen2021tois</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">feng2021multi</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">deng2022toward</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch7.S1.SS2.p2">
<p class="ltx_p" id="Ch7.S1.SS2.p2.1">In contrast with open-domain QA, distinct characteristics of e-commerce QA exist:

<span class="ltx_inline-enumerate" id="Ch7.S1.I1">
<span class="ltx_inline-item" id="Ch7.S1.I1.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch7.S1.I1.i1.1">Domain-specific aspects are the first e-commerce QA characteristic.
E-commerce QA systems rely on exploiting more domain-specific information from product descriptions.
Different products make product-aware aspects popular in e-commerce QA studies <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mcauley2016addressing</span>]</cite>. These product-aware aspects can help distinguish products and questions.
</span></span>
<span class="ltx_inline-item" id="Ch7.S1.I1.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch7.S1.I1.i2.1">The second characteristic of e-commerce QA is the large number of consumer reviews, which can be used as a data source to help people form opinions and decisions <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2016retrieving</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">mcauley2016addressing</span>]</cite>.
With the growth of those opinionated reviews, e-commerce users rely on advice from reviews before making purchase decisions.
Reviews have been used as supporting data and candidate answers to supervise QA prediction models <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yu2018aware</span>]</cite>.
</span></span>
<span class="ltx_inline-item" id="Ch7.S1.I1.i3"><span class="ltx_tag ltx_tag_inline-item">(iii)</span> <span class="ltx_text" id="Ch7.S1.I1.i3.1">The third characteristic of e-commerce QA is various sources of answers.
Most e-commerce QA services focus on extracting answers from reviews <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mcauley2016addressing</span>]</cite>, and many e-commerce sites provide question answer pairs as knowledge bases for QA.
</span></span>
</span></p>
</div>
<div class="ltx_para" id="Ch7.S1.SS2.p3">
<p class="ltx_p" id="Ch7.S1.SS2.p3.1">Text generation approaches have been studied to generate answers to given questions and reviews.
Besides given question answers in many e-commerce QA platforms, question reranking and answer reranking also have been studied <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yu2017modelling</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2020answer</span>]</cite>.
Existing e-commerce QA research can be divided into two directions: extractive product-aware QA and generative product-aware QA. The former focuses on extracting sentences or passages from reviews to answer questions, whereas the latter applies textual generation approaches to generate answers.
We detail each type of e-commerce QA study in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S1.SS3" title="7.1.3 Extractive product-aware QA ‣ 7.1 Question answering in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.1.3</span></a> and Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S1.SS4" title="7.1.4 Generative product-aware QA ‣ 7.1 Question answering in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.1.4</span></a> respectively.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch7.S1.SS3">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1.3 </span>Extractive product-aware QA</h4>
<div class="ltx_para" id="Ch7.S1.SS3.p1">
<p class="ltx_p" id="Ch7.S1.SS3.p1.1">Most existing e-commerce QA systems aim at extracting relevant sentences or fragments from the input text to answer the question given by the consumer.
Early studies automatically extracted answers from reviews by heuristic unsupervised methods <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2009answering</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">moghaddam2011aqa</span>]</cite>, whereas the follow-ups mainly focused on the matching between questions and reviews or candidate answers <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mcauley2016addressing</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yu2018aware</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">yu2012answering</span></cite> proposed a framework for opinionated QA, which organizes reviews into a hierarchy structure and retrieves review sentences as the answer.
The authors then used such a hierarchy structure to help retrieve question analysis and relevant review fragments.
A joint optimization approach was proposed by simultaneously considering review salience, coherence, and diversity to rank fragments.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2016retrieving</span></cite> aimed to find a concise set of questions addressed by a given review and cover its main points to help the user quickly comprehend the reviews.
The authors proposed a two-stage framework, where a probabilistic retrieval model was used to retrieve candidate questions first.
Subsequently, a matching procedure between answers and questions was used to bridge the vocabulary gap between reviews and questions.
Then, increasing extractive QA strategies were proposed to tackle challenges in e-commerce QA.</p>
</div>
<div class="ltx_para" id="Ch7.S1.SS3.p2">
<p class="ltx_p" id="Ch7.S1.SS3.p2.1">Unlike open-domain QA in other scenarios that require utilizing entity knowledge graphs, any two products in e-commerce sites are distinct even though they belong to the same category.
Some products such as clothes and paintings do not even have proper names.
Hence aspects have been considered to replace the external knowledge of e-commerce to address this problem.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">mcauley2016addressing</span></cite> proposed an answer prediction model by incorporating an aspect analytic model to learn latent aspect-specific review representation for predicting the answer.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wan2016modeling</span></cite> aimed to address ambiguity, subjectivity, and diversity problems in consumer reviews.
By leveraging multiple answers in a supervised framework, the authors aim to provide more accurate answers to those objective and subjective questions.
The authors also released a large-scale e-commerce QA dataset consisting of 135 thousand products from Amazon, 808 thousand questions, 3 million answers, and 11 million reviews.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">carmel2018product</span></cite> focused on subjective questions from Amazon customers, which can relate to various intent types such as product usage, recommendations, and opinions.
The authors applied automatic QA methods, enhanced with community QA approaches to retrieve the most relevant answer found in reviews and QAs to address this problem.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">yu2018aware</span></cite> proposed an answer prediction model by incorporating an aspect analytic model to learn latent aspect-specific review representation for predicting the answer.
The authors have verified its advantage of generating aspect-specific representations for new questions, which they used to develop the predictive answer model to capture intricate relationships among question texts and review texts jointly.
The proposed model uses reviews as knowledge to predict the answer by classifying answers into two types, binary (i.e. “yes” or “no”) and open-ended responses.
As the amount of labeling data is limited in customer reviews, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">das2019learning</span></cite> proposed an adversarial review-based approach to answer subjective and specific product-aware questions in a weakly supervised setting.
Reading comprehension has recently been verified as useful to help extract relevant answers from e-commerce reviews <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">fan2019reading</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">xu2019review</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2020answering</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019answer</span>]</cite>.
Fed by the raw text of product-aware questions and customer reviews, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">fan2019reading</span></cite> proposed an end-to-end neural network model to synthesize multiple review representations.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019answer</span></cite> proposed a multi-task attentive model, namely QAR-Net, to identify plausible answers from product reviews for user questions.
QAR-Net can leverage generated question answer pairs to help question-review matching.</p>
</div>
<div class="ltx_para" id="Ch7.S1.SS3.p3">
<p class="ltx_p" id="Ch7.S1.SS3.p3.1">Pre-trained language models help understand the content of questions and reviews.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">xu2019review</span></cite> applied a BERT-based fine-tuning approach to extract answers from reviews.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">mittal2021distantly</span></cite> utilized a pre-trained language model to learn a vital relevance function by jointly learning unified syntactic and semantic representations of questions and reviews.
A QA dataset for review comprehension with subjectivity labels for questions and answers has also been exploited <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bjerva2020subjqa</span>]</cite>.
Besides user reviews, another kind of information, namely product details provided by the manufacturer, has been considered an auxiliary information source for addressing product-related questions <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2020answering</span>]</cite>.
In order to alleviate the unavailability of labeled data, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">DBLP:conf/emnlp/JainRA23</span></cite> proposed a distant supervision based NLI model to prepare training data without any manual effort. The end-to-end manner and an auxiliary contrastive loss for evidence extraction are introduced in the training stage.</p>
</div>
<div class="ltx_para" id="Ch7.S1.SS3.p4">
<p class="ltx_p" id="Ch7.S1.SS3.p4.1">Review-based QA approaches extract answers from customer reviews, which can partially address these questions.
However, there are many products with few or no reviews available.
By collecting question answer pairs from real users, many e-commerce platforms develop retrieval-based QA systems for automatically answering frequently asked questions (FAQs) in the e-commerce industry <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yu2017modelling</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">song2020tcnn</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">song2021online</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2020answer</span>]</cite>.
As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.F1" title="Figure 7.1 ‣ 7.1.3 Extractive product-aware QA ‣ 7.1 Question answering in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.1</span></a>, we see the retrieval-based QA framework applied in Alibaba, the largest e-commerce platform in China <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yu2017modelling</span>]</cite>.
Given a large scale of question answer pairs (i.e., the knowledge base in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.F1" title="Figure 7.1 ‣ 7.1.3 Extractive product-aware QA ‣ 7.1 Question answering in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.1</span></a>), a key component is the question rerank module, which reranks candidate questions in a question answering knowledge base to find the best match given a question from a user.
Based on such a framework, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">yu2017modelling</span></cite> formulated e-commerce QA as a paraphrase identification problem, where the target is to identify semantic relations of the given sentence pairs.
The authors proposed a transfer learning QA strategy to adapt the shared knowledge learned from a resource-rich source domain to a resource-poor target domain.
Amazon presented a large review-based QA dataset, namely AmazonQA, based on their real-world community QA platform <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gupta2019amazonqa</span>]</cite>.
AmaonQA uses consumer reviews as the data resource and extracts snippets to answer questions.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">song2020tcnn</span></cite> improved the matching performance in retrieval-based e-commerce QA by introducing a multi-layer triple convolutional neural network model.
Also, a sub-graph searching mechanism is verified to improve the efficiency of retrieval-based e-commerce QA <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">song2021online</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2020answer</span></cite> focused on answer selection in retrieval-based e-commerce QA.
Using graph neural networks, the authors proposed a new framework to jointly model multiple semantic relations, including the semantic relevance between the question and answers, the textual similarity among answers, and the textual entailment between answers and reviews.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">rozen2021answering</span></cite> proposed an answer prediction approach that leverages similar questions about other products.
The authors calculated the contextual product similarity to determine whether two products are similar in the context of a specific question.
Two large-scale datasets, including a question-to-question similarity dataset from Amazon and a corpus of question answer pairs from Amazon, are released with the publication.</p>
</div>
<figure class="ltx_figure" id="Ch7.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="447" id="Ch7.F1.g1" src="x40.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7.1: </span>An overview of the retrieval-based QA system in Alibaba. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yu2017modelling</span>]</cite>.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="Ch7.S1.SS4">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1.4 </span>Generative product-aware QA</h4>
<div class="ltx_para" id="Ch7.S1.SS4.p1">
<p class="ltx_p" id="Ch7.S1.SS4.p1.1">Many e-commerce portals have provided question answering services that assist users in posing product-aware questions to other consumers who have purchased the same product before.
Under the e-commerce QA circumstances, users must read the product’s reviews to find the answer themselves.
Given product attributes and reviews, following a cascading procedure, an answer is manually generated.

<span class="ltx_inline-enumerate" id="Ch7.S1.I2">
<span class="ltx_inline-item" id="Ch7.S1.I2.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch7.S1.I2.i1.1">A user skims reviews and finds relevant sentences;
</span></span>
<span class="ltx_inline-item" id="Ch7.S1.I2.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch7.S1.I2.i2.1">they extract functional semantic units; and
</span></span>
<span class="ltx_inline-item" id="Ch7.S1.I2.i3"><span class="ltx_tag ltx_tag_inline-item">(iii)</span> <span class="ltx_text" id="Ch7.S1.I2.i3.1">and the user jointly combines these semantic units with attributes and writes an appropriate answer.
</span></span>
</span>
However, the information overload phenomenon makes this procedure an energy-draining process to pursue an answer from a rapidly increasing number of reviews <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gao2019product</span>]</cite>.
Several strategies have been proposed to automatically generate answers using the product’s reviews to alleviate the burdens of customers <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gao2019product</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019driven</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">deng2020opinion</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lu2020chime</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">feng2021multi</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">deng2022toward</span>]</cite>.
The task on which these approaches focus is the <em class="ltx_emph ltx_font_italic" id="Ch7.S1.SS4.p1.1.1">generative product-aware QA</em> given reviews and product attributes.</p>
</div>
<div class="ltx_para" id="Ch7.S1.SS4.p2">
<p class="ltx_p" id="Ch7.S1.SS4.p2.15">In their first attempt, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">gao2019product</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019driven</span></cite> proposed the task of <span class="ltx_text ltx_font_italic" id="Ch7.S1.SS4.p2.15.1">product-aware answer generation</span>, where a product-related question answering model is applied to incorporate customer reviews with product attributes.
The authors formulated the research problem in generative e-commerce QA: for a product, there is a question <math alttext="X^{q}=\{x^{q}_{1},x^{q}_{2},\dots,x^{q}_{T_{q}}\}" class="ltx_Math" display="inline" id="Ch7.S1.SS4.p2.1.m1.4"><semantics id="Ch7.S1.SS4.p2.1.m1.4a"><mrow id="Ch7.S1.SS4.p2.1.m1.4.4" xref="Ch7.S1.SS4.p2.1.m1.4.4.cmml"><msup id="Ch7.S1.SS4.p2.1.m1.4.4.5" xref="Ch7.S1.SS4.p2.1.m1.4.4.5.cmml"><mi id="Ch7.S1.SS4.p2.1.m1.4.4.5.2" xref="Ch7.S1.SS4.p2.1.m1.4.4.5.2.cmml">X</mi><mi id="Ch7.S1.SS4.p2.1.m1.4.4.5.3" xref="Ch7.S1.SS4.p2.1.m1.4.4.5.3.cmml">q</mi></msup><mo id="Ch7.S1.SS4.p2.1.m1.4.4.4" xref="Ch7.S1.SS4.p2.1.m1.4.4.4.cmml">=</mo><mrow id="Ch7.S1.SS4.p2.1.m1.4.4.3.3" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.4.cmml"><mo id="Ch7.S1.SS4.p2.1.m1.4.4.3.3.4" stretchy="false" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.4.cmml">{</mo><msubsup id="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1" xref="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1.cmml"><mi id="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1.2.2" xref="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1.2.2.cmml">x</mi><mn id="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1.3" xref="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1.3.cmml">1</mn><mi id="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1.2.3" xref="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1.2.3.cmml">q</mi></msubsup><mo id="Ch7.S1.SS4.p2.1.m1.4.4.3.3.5" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.4.cmml">,</mo><msubsup id="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2" xref="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2.cmml"><mi id="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2.2.2" xref="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2.2.2.cmml">x</mi><mn id="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2.3" xref="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2.3.cmml">2</mn><mi id="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2.2.3" xref="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2.2.3.cmml">q</mi></msubsup><mo id="Ch7.S1.SS4.p2.1.m1.4.4.3.3.6" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.4.cmml">,</mo><mi id="Ch7.S1.SS4.p2.1.m1.1.1" mathvariant="normal" xref="Ch7.S1.SS4.p2.1.m1.1.1.cmml">…</mi><mo id="Ch7.S1.SS4.p2.1.m1.4.4.3.3.7" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.4.cmml">,</mo><msubsup id="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.cmml"><mi id="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.2.2" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.2.2.cmml">x</mi><msub id="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.3" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.3.cmml"><mi id="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.3.2" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.3.2.cmml">T</mi><mi id="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.3.3" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.3.3.cmml">q</mi></msub><mi id="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.2.3" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.2.3.cmml">q</mi></msubsup><mo id="Ch7.S1.SS4.p2.1.m1.4.4.3.3.8" stretchy="false" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch7.S1.SS4.p2.1.m1.4b"><apply id="Ch7.S1.SS4.p2.1.m1.4.4.cmml" xref="Ch7.S1.SS4.p2.1.m1.4.4"><eq id="Ch7.S1.SS4.p2.1.m1.4.4.4.cmml" xref="Ch7.S1.SS4.p2.1.m1.4.4.4"></eq><apply id="Ch7.S1.SS4.p2.1.m1.4.4.5.cmml" xref="Ch7.S1.SS4.p2.1.m1.4.4.5"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.1.m1.4.4.5.1.cmml" xref="Ch7.S1.SS4.p2.1.m1.4.4.5">superscript</csymbol><ci id="Ch7.S1.SS4.p2.1.m1.4.4.5.2.cmml" xref="Ch7.S1.SS4.p2.1.m1.4.4.5.2">𝑋</ci><ci id="Ch7.S1.SS4.p2.1.m1.4.4.5.3.cmml" xref="Ch7.S1.SS4.p2.1.m1.4.4.5.3">𝑞</ci></apply><set id="Ch7.S1.SS4.p2.1.m1.4.4.3.4.cmml" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.3"><apply id="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1.cmml" xref="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1.1.cmml" xref="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1">subscript</csymbol><apply id="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1.2.cmml" xref="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1.2.1.cmml" xref="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1">superscript</csymbol><ci id="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1.2.2.cmml" xref="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1.2.2">𝑥</ci><ci id="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1.2.3.cmml" xref="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1.2.3">𝑞</ci></apply><cn id="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1.3.cmml" type="integer" xref="Ch7.S1.SS4.p2.1.m1.2.2.1.1.1.3">1</cn></apply><apply id="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2.cmml" xref="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2.1.cmml" xref="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2">subscript</csymbol><apply id="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2.2.cmml" xref="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2.2.1.cmml" xref="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2">superscript</csymbol><ci id="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2.2.2.cmml" xref="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2.2.2">𝑥</ci><ci id="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2.2.3.cmml" xref="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2.2.3">𝑞</ci></apply><cn id="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2.3.cmml" type="integer" xref="Ch7.S1.SS4.p2.1.m1.3.3.2.2.2.3">2</cn></apply><ci id="Ch7.S1.SS4.p2.1.m1.1.1.cmml" xref="Ch7.S1.SS4.p2.1.m1.1.1">…</ci><apply id="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.cmml" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.1.cmml" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3">subscript</csymbol><apply id="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.2.cmml" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.2.1.cmml" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3">superscript</csymbol><ci id="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.2.2.cmml" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.2.2">𝑥</ci><ci id="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.2.3.cmml" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.2.3">𝑞</ci></apply><apply id="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.3.cmml" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.3"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.3.1.cmml" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.3">subscript</csymbol><ci id="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.3.2.cmml" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.3.2">𝑇</ci><ci id="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.3.3.cmml" xref="Ch7.S1.SS4.p2.1.m1.4.4.3.3.3.3.3">𝑞</ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S1.SS4.p2.1.m1.4c">X^{q}=\{x^{q}_{1},x^{q}_{2},\dots,x^{q}_{T_{q}}\}</annotation><annotation encoding="application/x-llamapun" id="Ch7.S1.SS4.p2.1.m1.4d">italic_X start_POSTSUPERSCRIPT italic_q end_POSTSUPERSCRIPT = { italic_x start_POSTSUPERSCRIPT italic_q end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUPERSCRIPT italic_q end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_x start_POSTSUPERSCRIPT italic_q end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_T start_POSTSUBSCRIPT italic_q end_POSTSUBSCRIPT end_POSTSUBSCRIPT }</annotation></semantics></math>, <math alttext="T_{r}" class="ltx_Math" display="inline" id="Ch7.S1.SS4.p2.2.m2.1"><semantics id="Ch7.S1.SS4.p2.2.m2.1a"><msub id="Ch7.S1.SS4.p2.2.m2.1.1" xref="Ch7.S1.SS4.p2.2.m2.1.1.cmml"><mi id="Ch7.S1.SS4.p2.2.m2.1.1.2" xref="Ch7.S1.SS4.p2.2.m2.1.1.2.cmml">T</mi><mi id="Ch7.S1.SS4.p2.2.m2.1.1.3" xref="Ch7.S1.SS4.p2.2.m2.1.1.3.cmml">r</mi></msub><annotation-xml encoding="MathML-Content" id="Ch7.S1.SS4.p2.2.m2.1b"><apply id="Ch7.S1.SS4.p2.2.m2.1.1.cmml" xref="Ch7.S1.SS4.p2.2.m2.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.2.m2.1.1.1.cmml" xref="Ch7.S1.SS4.p2.2.m2.1.1">subscript</csymbol><ci id="Ch7.S1.SS4.p2.2.m2.1.1.2.cmml" xref="Ch7.S1.SS4.p2.2.m2.1.1.2">𝑇</ci><ci id="Ch7.S1.SS4.p2.2.m2.1.1.3.cmml" xref="Ch7.S1.SS4.p2.2.m2.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S1.SS4.p2.2.m2.1c">T_{r}</annotation><annotation encoding="application/x-llamapun" id="Ch7.S1.SS4.p2.2.m2.1d">italic_T start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT</annotation></semantics></math> reviews <math alttext="X^{r}=\{x^{r}_{1},x^{r}_{2},\dots,x^{r}_{T_{r}}\}" class="ltx_Math" display="inline" id="Ch7.S1.SS4.p2.3.m3.4"><semantics id="Ch7.S1.SS4.p2.3.m3.4a"><mrow id="Ch7.S1.SS4.p2.3.m3.4.4" xref="Ch7.S1.SS4.p2.3.m3.4.4.cmml"><msup id="Ch7.S1.SS4.p2.3.m3.4.4.5" xref="Ch7.S1.SS4.p2.3.m3.4.4.5.cmml"><mi id="Ch7.S1.SS4.p2.3.m3.4.4.5.2" xref="Ch7.S1.SS4.p2.3.m3.4.4.5.2.cmml">X</mi><mi id="Ch7.S1.SS4.p2.3.m3.4.4.5.3" xref="Ch7.S1.SS4.p2.3.m3.4.4.5.3.cmml">r</mi></msup><mo id="Ch7.S1.SS4.p2.3.m3.4.4.4" xref="Ch7.S1.SS4.p2.3.m3.4.4.4.cmml">=</mo><mrow id="Ch7.S1.SS4.p2.3.m3.4.4.3.3" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.4.cmml"><mo id="Ch7.S1.SS4.p2.3.m3.4.4.3.3.4" stretchy="false" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.4.cmml">{</mo><msubsup id="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1" xref="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1.cmml"><mi id="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1.2.2" xref="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1.2.2.cmml">x</mi><mn id="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1.3" xref="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1.3.cmml">1</mn><mi id="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1.2.3" xref="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1.2.3.cmml">r</mi></msubsup><mo id="Ch7.S1.SS4.p2.3.m3.4.4.3.3.5" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.4.cmml">,</mo><msubsup id="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2" xref="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2.cmml"><mi id="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2.2.2" xref="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2.2.2.cmml">x</mi><mn id="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2.3" xref="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2.3.cmml">2</mn><mi id="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2.2.3" xref="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2.2.3.cmml">r</mi></msubsup><mo id="Ch7.S1.SS4.p2.3.m3.4.4.3.3.6" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.4.cmml">,</mo><mi id="Ch7.S1.SS4.p2.3.m3.1.1" mathvariant="normal" xref="Ch7.S1.SS4.p2.3.m3.1.1.cmml">…</mi><mo id="Ch7.S1.SS4.p2.3.m3.4.4.3.3.7" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.4.cmml">,</mo><msubsup id="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.cmml"><mi id="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.2.2" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.2.2.cmml">x</mi><msub id="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.3" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.3.cmml"><mi id="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.3.2" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.3.2.cmml">T</mi><mi id="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.3.3" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.3.3.cmml">r</mi></msub><mi id="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.2.3" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.2.3.cmml">r</mi></msubsup><mo id="Ch7.S1.SS4.p2.3.m3.4.4.3.3.8" stretchy="false" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch7.S1.SS4.p2.3.m3.4b"><apply id="Ch7.S1.SS4.p2.3.m3.4.4.cmml" xref="Ch7.S1.SS4.p2.3.m3.4.4"><eq id="Ch7.S1.SS4.p2.3.m3.4.4.4.cmml" xref="Ch7.S1.SS4.p2.3.m3.4.4.4"></eq><apply id="Ch7.S1.SS4.p2.3.m3.4.4.5.cmml" xref="Ch7.S1.SS4.p2.3.m3.4.4.5"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.3.m3.4.4.5.1.cmml" xref="Ch7.S1.SS4.p2.3.m3.4.4.5">superscript</csymbol><ci id="Ch7.S1.SS4.p2.3.m3.4.4.5.2.cmml" xref="Ch7.S1.SS4.p2.3.m3.4.4.5.2">𝑋</ci><ci id="Ch7.S1.SS4.p2.3.m3.4.4.5.3.cmml" xref="Ch7.S1.SS4.p2.3.m3.4.4.5.3">𝑟</ci></apply><set id="Ch7.S1.SS4.p2.3.m3.4.4.3.4.cmml" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.3"><apply id="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1.cmml" xref="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1.1.cmml" xref="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1">subscript</csymbol><apply id="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1.2.cmml" xref="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1.2.1.cmml" xref="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1">superscript</csymbol><ci id="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1.2.2.cmml" xref="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1.2.2">𝑥</ci><ci id="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1.2.3.cmml" xref="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1.2.3">𝑟</ci></apply><cn id="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1.3.cmml" type="integer" xref="Ch7.S1.SS4.p2.3.m3.2.2.1.1.1.3">1</cn></apply><apply id="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2.cmml" xref="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2.1.cmml" xref="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2">subscript</csymbol><apply id="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2.2.cmml" xref="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2.2.1.cmml" xref="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2">superscript</csymbol><ci id="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2.2.2.cmml" xref="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2.2.2">𝑥</ci><ci id="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2.2.3.cmml" xref="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2.2.3">𝑟</ci></apply><cn id="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2.3.cmml" type="integer" xref="Ch7.S1.SS4.p2.3.m3.3.3.2.2.2.3">2</cn></apply><ci id="Ch7.S1.SS4.p2.3.m3.1.1.cmml" xref="Ch7.S1.SS4.p2.3.m3.1.1">…</ci><apply id="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.cmml" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.1.cmml" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3">subscript</csymbol><apply id="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.2.cmml" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.2.1.cmml" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3">superscript</csymbol><ci id="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.2.2.cmml" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.2.2">𝑥</ci><ci id="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.2.3.cmml" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.2.3">𝑟</ci></apply><apply id="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.3.cmml" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.3"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.3.1.cmml" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.3">subscript</csymbol><ci id="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.3.2.cmml" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.3.2">𝑇</ci><ci id="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.3.3.cmml" xref="Ch7.S1.SS4.p2.3.m3.4.4.3.3.3.3.3">𝑟</ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S1.SS4.p2.3.m3.4c">X^{r}=\{x^{r}_{1},x^{r}_{2},\dots,x^{r}_{T_{r}}\}</annotation><annotation encoding="application/x-llamapun" id="Ch7.S1.SS4.p2.3.m3.4d">italic_X start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT = { italic_x start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_x start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , italic_x start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_T start_POSTSUBSCRIPT italic_r end_POSTSUBSCRIPT end_POSTSUBSCRIPT }</annotation></semantics></math> and <math alttext="T_{a}" class="ltx_Math" display="inline" id="Ch7.S1.SS4.p2.4.m4.1"><semantics id="Ch7.S1.SS4.p2.4.m4.1a"><msub id="Ch7.S1.SS4.p2.4.m4.1.1" xref="Ch7.S1.SS4.p2.4.m4.1.1.cmml"><mi id="Ch7.S1.SS4.p2.4.m4.1.1.2" xref="Ch7.S1.SS4.p2.4.m4.1.1.2.cmml">T</mi><mi id="Ch7.S1.SS4.p2.4.m4.1.1.3" xref="Ch7.S1.SS4.p2.4.m4.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="Ch7.S1.SS4.p2.4.m4.1b"><apply id="Ch7.S1.SS4.p2.4.m4.1.1.cmml" xref="Ch7.S1.SS4.p2.4.m4.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.4.m4.1.1.1.cmml" xref="Ch7.S1.SS4.p2.4.m4.1.1">subscript</csymbol><ci id="Ch7.S1.SS4.p2.4.m4.1.1.2.cmml" xref="Ch7.S1.SS4.p2.4.m4.1.1.2">𝑇</ci><ci id="Ch7.S1.SS4.p2.4.m4.1.1.3.cmml" xref="Ch7.S1.SS4.p2.4.m4.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S1.SS4.p2.4.m4.1c">T_{a}</annotation><annotation encoding="application/x-llamapun" id="Ch7.S1.SS4.p2.4.m4.1d">italic_T start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT</annotation></semantics></math> key-value pairs of attributes <math alttext="A=\{(a^{k}_{1},a^{v}_{1}),(a^{k}_{2},a^{v}_{2}),\dots,(a^{k}_{T_{a}},a^{v}_{T_%
{a}})\}" class="ltx_Math" display="inline" id="Ch7.S1.SS4.p2.5.m5.4"><semantics id="Ch7.S1.SS4.p2.5.m5.4a"><mrow id="Ch7.S1.SS4.p2.5.m5.4.4" xref="Ch7.S1.SS4.p2.5.m5.4.4.cmml"><mi id="Ch7.S1.SS4.p2.5.m5.4.4.5" xref="Ch7.S1.SS4.p2.5.m5.4.4.5.cmml">A</mi><mo id="Ch7.S1.SS4.p2.5.m5.4.4.4" xref="Ch7.S1.SS4.p2.5.m5.4.4.4.cmml">=</mo><mrow id="Ch7.S1.SS4.p2.5.m5.4.4.3.3" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.4.cmml"><mo id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.4" stretchy="false" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.4.cmml">{</mo><mrow id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.3.cmml"><mo id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.3" stretchy="false" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.3.cmml">(</mo><msubsup id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1.cmml"><mi id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1.2.2" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1.2.2.cmml">a</mi><mn id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1.3" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1.3.cmml">1</mn><mi id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1.2.3" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1.2.3.cmml">k</mi></msubsup><mo id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.4" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.3.cmml">,</mo><msubsup id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2.cmml"><mi id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2.2.2" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2.2.2.cmml">a</mi><mn id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2.3" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2.3.cmml">1</mn><mi id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2.2.3" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2.2.3.cmml">v</mi></msubsup><mo id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.5" stretchy="false" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.3.cmml">)</mo></mrow><mo id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.5" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.4.cmml">,</mo><mrow id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.3.cmml"><mo id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.3" stretchy="false" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.3.cmml">(</mo><msubsup id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1.cmml"><mi id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1.2.2" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1.2.2.cmml">a</mi><mn id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1.3" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1.3.cmml">2</mn><mi id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1.2.3" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1.2.3.cmml">k</mi></msubsup><mo id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.4" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.3.cmml">,</mo><msubsup id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2.cmml"><mi id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2.2.2" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2.2.2.cmml">a</mi><mn id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2.3" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2.3.cmml">2</mn><mi id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2.2.3" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2.2.3.cmml">v</mi></msubsup><mo id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.5" stretchy="false" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.3.cmml">)</mo></mrow><mo id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.6" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.4.cmml">,</mo><mi id="Ch7.S1.SS4.p2.5.m5.1.1" mathvariant="normal" xref="Ch7.S1.SS4.p2.5.m5.1.1.cmml">…</mi><mo id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.7" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.4.cmml">,</mo><mrow id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.3.cmml"><mo id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.3" stretchy="false" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.3.cmml">(</mo><msubsup id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.cmml"><mi id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.2.2" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.2.2.cmml">a</mi><msub id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.3" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.3.cmml"><mi id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.3.2" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.3.2.cmml">T</mi><mi id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.3.3" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.3.3.cmml">a</mi></msub><mi id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.2.3" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.2.3.cmml">k</mi></msubsup><mo id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.4" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.3.cmml">,</mo><msubsup id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.cmml"><mi id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.2.2" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.2.2.cmml">a</mi><msub id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.3" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.3.cmml"><mi id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.3.2" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.3.2.cmml">T</mi><mi id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.3.3" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.3.3.cmml">a</mi></msub><mi id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.2.3" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.2.3.cmml">v</mi></msubsup><mo id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.5" stretchy="false" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.3.cmml">)</mo></mrow><mo id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.8" stretchy="false" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch7.S1.SS4.p2.5.m5.4b"><apply id="Ch7.S1.SS4.p2.5.m5.4.4.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4"><eq id="Ch7.S1.SS4.p2.5.m5.4.4.4.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.4"></eq><ci id="Ch7.S1.SS4.p2.5.m5.4.4.5.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.5">𝐴</ci><set id="Ch7.S1.SS4.p2.5.m5.4.4.3.4.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3"><interval closure="open" id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.3.cmml" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2"><apply id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1.cmml" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1.1.cmml" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1">subscript</csymbol><apply id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1.2.cmml" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1.2.1.cmml" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1">superscript</csymbol><ci id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1.2.2.cmml" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1.2.2">𝑎</ci><ci id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1.2.3.cmml" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1.2.3">𝑘</ci></apply><cn id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1.3.cmml" type="integer" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.1.1.3">1</cn></apply><apply id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2.cmml" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2.1.cmml" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2">subscript</csymbol><apply id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2.2.cmml" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2.2.1.cmml" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2">superscript</csymbol><ci id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2.2.2.cmml" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2.2.2">𝑎</ci><ci id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2.2.3.cmml" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2.2.3">𝑣</ci></apply><cn id="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2.3.cmml" type="integer" xref="Ch7.S1.SS4.p2.5.m5.2.2.1.1.1.2.2.3">1</cn></apply></interval><interval closure="open" id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.3.cmml" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2"><apply id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1.cmml" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1.1.cmml" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1">subscript</csymbol><apply id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1.2.cmml" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1.2.1.cmml" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1">superscript</csymbol><ci id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1.2.2.cmml" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1.2.2">𝑎</ci><ci id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1.2.3.cmml" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1.2.3">𝑘</ci></apply><cn id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1.3.cmml" type="integer" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.1.1.3">2</cn></apply><apply id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2.cmml" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2.1.cmml" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2">subscript</csymbol><apply id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2.2.cmml" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2.2.1.cmml" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2">superscript</csymbol><ci id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2.2.2.cmml" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2.2.2">𝑎</ci><ci id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2.2.3.cmml" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2.2.3">𝑣</ci></apply><cn id="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2.3.cmml" type="integer" xref="Ch7.S1.SS4.p2.5.m5.3.3.2.2.2.2.2.3">2</cn></apply></interval><ci id="Ch7.S1.SS4.p2.5.m5.1.1.cmml" xref="Ch7.S1.SS4.p2.5.m5.1.1">…</ci><interval closure="open" id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.3.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2"><apply id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.1.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1">subscript</csymbol><apply id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.2.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.2.1.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1">superscript</csymbol><ci id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.2.2.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.2.2">𝑎</ci><ci id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.2.3.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.2.3">𝑘</ci></apply><apply id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.3.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.3"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.3.1.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.3">subscript</csymbol><ci id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.3.2.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.3.2">𝑇</ci><ci id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.3.3.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.1.1.3.3">𝑎</ci></apply></apply><apply id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.1.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2">subscript</csymbol><apply id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.2.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.2.1.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2">superscript</csymbol><ci id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.2.2.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.2.2">𝑎</ci><ci id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.2.3.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.2.3">𝑣</ci></apply><apply id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.3.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.3"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.3.1.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.3">subscript</csymbol><ci id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.3.2.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.3.2">𝑇</ci><ci id="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.3.3.cmml" xref="Ch7.S1.SS4.p2.5.m5.4.4.3.3.3.2.2.3.3">𝑎</ci></apply></apply></interval></set></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S1.SS4.p2.5.m5.4c">A=\{(a^{k}_{1},a^{v}_{1}),(a^{k}_{2},a^{v}_{2}),\dots,(a^{k}_{T_{a}},a^{v}_{T_%
{a}})\}</annotation><annotation encoding="application/x-llamapun" id="Ch7.S1.SS4.p2.5.m5.4d">italic_A = { ( italic_a start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_a start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT ) , ( italic_a start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_a start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ) , … , ( italic_a start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_T start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_a start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_T start_POSTSUBSCRIPT italic_a end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) }</annotation></semantics></math>, where <math alttext="a^{k}_{i}" class="ltx_Math" display="inline" id="Ch7.S1.SS4.p2.6.m6.1"><semantics id="Ch7.S1.SS4.p2.6.m6.1a"><msubsup id="Ch7.S1.SS4.p2.6.m6.1.1" xref="Ch7.S1.SS4.p2.6.m6.1.1.cmml"><mi id="Ch7.S1.SS4.p2.6.m6.1.1.2.2" xref="Ch7.S1.SS4.p2.6.m6.1.1.2.2.cmml">a</mi><mi id="Ch7.S1.SS4.p2.6.m6.1.1.3" xref="Ch7.S1.SS4.p2.6.m6.1.1.3.cmml">i</mi><mi id="Ch7.S1.SS4.p2.6.m6.1.1.2.3" xref="Ch7.S1.SS4.p2.6.m6.1.1.2.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="Ch7.S1.SS4.p2.6.m6.1b"><apply id="Ch7.S1.SS4.p2.6.m6.1.1.cmml" xref="Ch7.S1.SS4.p2.6.m6.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.6.m6.1.1.1.cmml" xref="Ch7.S1.SS4.p2.6.m6.1.1">subscript</csymbol><apply id="Ch7.S1.SS4.p2.6.m6.1.1.2.cmml" xref="Ch7.S1.SS4.p2.6.m6.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.6.m6.1.1.2.1.cmml" xref="Ch7.S1.SS4.p2.6.m6.1.1">superscript</csymbol><ci id="Ch7.S1.SS4.p2.6.m6.1.1.2.2.cmml" xref="Ch7.S1.SS4.p2.6.m6.1.1.2.2">𝑎</ci><ci id="Ch7.S1.SS4.p2.6.m6.1.1.2.3.cmml" xref="Ch7.S1.SS4.p2.6.m6.1.1.2.3">𝑘</ci></apply><ci id="Ch7.S1.SS4.p2.6.m6.1.1.3.cmml" xref="Ch7.S1.SS4.p2.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S1.SS4.p2.6.m6.1c">a^{k}_{i}</annotation><annotation encoding="application/x-llamapun" id="Ch7.S1.SS4.p2.6.m6.1d">italic_a start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is the name of <math alttext="i" class="ltx_Math" display="inline" id="Ch7.S1.SS4.p2.7.m7.1"><semantics id="Ch7.S1.SS4.p2.7.m7.1a"><mi id="Ch7.S1.SS4.p2.7.m7.1.1" xref="Ch7.S1.SS4.p2.7.m7.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="Ch7.S1.SS4.p2.7.m7.1b"><ci id="Ch7.S1.SS4.p2.7.m7.1.1.cmml" xref="Ch7.S1.SS4.p2.7.m7.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S1.SS4.p2.7.m7.1c">i</annotation><annotation encoding="application/x-llamapun" id="Ch7.S1.SS4.p2.7.m7.1d">italic_i</annotation></semantics></math>-th attribute and <math alttext="a^{v}_{i}" class="ltx_Math" display="inline" id="Ch7.S1.SS4.p2.8.m8.1"><semantics id="Ch7.S1.SS4.p2.8.m8.1a"><msubsup id="Ch7.S1.SS4.p2.8.m8.1.1" xref="Ch7.S1.SS4.p2.8.m8.1.1.cmml"><mi id="Ch7.S1.SS4.p2.8.m8.1.1.2.2" xref="Ch7.S1.SS4.p2.8.m8.1.1.2.2.cmml">a</mi><mi id="Ch7.S1.SS4.p2.8.m8.1.1.3" xref="Ch7.S1.SS4.p2.8.m8.1.1.3.cmml">i</mi><mi id="Ch7.S1.SS4.p2.8.m8.1.1.2.3" xref="Ch7.S1.SS4.p2.8.m8.1.1.2.3.cmml">v</mi></msubsup><annotation-xml encoding="MathML-Content" id="Ch7.S1.SS4.p2.8.m8.1b"><apply id="Ch7.S1.SS4.p2.8.m8.1.1.cmml" xref="Ch7.S1.SS4.p2.8.m8.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.8.m8.1.1.1.cmml" xref="Ch7.S1.SS4.p2.8.m8.1.1">subscript</csymbol><apply id="Ch7.S1.SS4.p2.8.m8.1.1.2.cmml" xref="Ch7.S1.SS4.p2.8.m8.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.8.m8.1.1.2.1.cmml" xref="Ch7.S1.SS4.p2.8.m8.1.1">superscript</csymbol><ci id="Ch7.S1.SS4.p2.8.m8.1.1.2.2.cmml" xref="Ch7.S1.SS4.p2.8.m8.1.1.2.2">𝑎</ci><ci id="Ch7.S1.SS4.p2.8.m8.1.1.2.3.cmml" xref="Ch7.S1.SS4.p2.8.m8.1.1.2.3">𝑣</ci></apply><ci id="Ch7.S1.SS4.p2.8.m8.1.1.3.cmml" xref="Ch7.S1.SS4.p2.8.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S1.SS4.p2.8.m8.1c">a^{v}_{i}</annotation><annotation encoding="application/x-llamapun" id="Ch7.S1.SS4.p2.8.m8.1d">italic_a start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is the attribute content.
Each attribute, including key <math alttext="a^{k}_{i}" class="ltx_Math" display="inline" id="Ch7.S1.SS4.p2.9.m9.1"><semantics id="Ch7.S1.SS4.p2.9.m9.1a"><msubsup id="Ch7.S1.SS4.p2.9.m9.1.1" xref="Ch7.S1.SS4.p2.9.m9.1.1.cmml"><mi id="Ch7.S1.SS4.p2.9.m9.1.1.2.2" xref="Ch7.S1.SS4.p2.9.m9.1.1.2.2.cmml">a</mi><mi id="Ch7.S1.SS4.p2.9.m9.1.1.3" xref="Ch7.S1.SS4.p2.9.m9.1.1.3.cmml">i</mi><mi id="Ch7.S1.SS4.p2.9.m9.1.1.2.3" xref="Ch7.S1.SS4.p2.9.m9.1.1.2.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="Ch7.S1.SS4.p2.9.m9.1b"><apply id="Ch7.S1.SS4.p2.9.m9.1.1.cmml" xref="Ch7.S1.SS4.p2.9.m9.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.9.m9.1.1.1.cmml" xref="Ch7.S1.SS4.p2.9.m9.1.1">subscript</csymbol><apply id="Ch7.S1.SS4.p2.9.m9.1.1.2.cmml" xref="Ch7.S1.SS4.p2.9.m9.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.9.m9.1.1.2.1.cmml" xref="Ch7.S1.SS4.p2.9.m9.1.1">superscript</csymbol><ci id="Ch7.S1.SS4.p2.9.m9.1.1.2.2.cmml" xref="Ch7.S1.SS4.p2.9.m9.1.1.2.2">𝑎</ci><ci id="Ch7.S1.SS4.p2.9.m9.1.1.2.3.cmml" xref="Ch7.S1.SS4.p2.9.m9.1.1.2.3">𝑘</ci></apply><ci id="Ch7.S1.SS4.p2.9.m9.1.1.3.cmml" xref="Ch7.S1.SS4.p2.9.m9.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S1.SS4.p2.9.m9.1c">a^{k}_{i}</annotation><annotation encoding="application/x-llamapun" id="Ch7.S1.SS4.p2.9.m9.1d">italic_a start_POSTSUPERSCRIPT italic_k end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> and value <math alttext="a^{v}_{i}" class="ltx_Math" display="inline" id="Ch7.S1.SS4.p2.10.m10.1"><semantics id="Ch7.S1.SS4.p2.10.m10.1a"><msubsup id="Ch7.S1.SS4.p2.10.m10.1.1" xref="Ch7.S1.SS4.p2.10.m10.1.1.cmml"><mi id="Ch7.S1.SS4.p2.10.m10.1.1.2.2" xref="Ch7.S1.SS4.p2.10.m10.1.1.2.2.cmml">a</mi><mi id="Ch7.S1.SS4.p2.10.m10.1.1.3" xref="Ch7.S1.SS4.p2.10.m10.1.1.3.cmml">i</mi><mi id="Ch7.S1.SS4.p2.10.m10.1.1.2.3" xref="Ch7.S1.SS4.p2.10.m10.1.1.2.3.cmml">v</mi></msubsup><annotation-xml encoding="MathML-Content" id="Ch7.S1.SS4.p2.10.m10.1b"><apply id="Ch7.S1.SS4.p2.10.m10.1.1.cmml" xref="Ch7.S1.SS4.p2.10.m10.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.10.m10.1.1.1.cmml" xref="Ch7.S1.SS4.p2.10.m10.1.1">subscript</csymbol><apply id="Ch7.S1.SS4.p2.10.m10.1.1.2.cmml" xref="Ch7.S1.SS4.p2.10.m10.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.10.m10.1.1.2.1.cmml" xref="Ch7.S1.SS4.p2.10.m10.1.1">superscript</csymbol><ci id="Ch7.S1.SS4.p2.10.m10.1.1.2.2.cmml" xref="Ch7.S1.SS4.p2.10.m10.1.1.2.2">𝑎</ci><ci id="Ch7.S1.SS4.p2.10.m10.1.1.2.3.cmml" xref="Ch7.S1.SS4.p2.10.m10.1.1.2.3">𝑣</ci></apply><ci id="Ch7.S1.SS4.p2.10.m10.1.1.3.cmml" xref="Ch7.S1.SS4.p2.10.m10.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S1.SS4.p2.10.m10.1c">a^{v}_{i}</annotation><annotation encoding="application/x-llamapun" id="Ch7.S1.SS4.p2.10.m10.1d">italic_a start_POSTSUPERSCRIPT italic_v end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, is represented as a single word in the generation task.
Given a question <math alttext="X^{q}" class="ltx_Math" display="inline" id="Ch7.S1.SS4.p2.11.m11.1"><semantics id="Ch7.S1.SS4.p2.11.m11.1a"><msup id="Ch7.S1.SS4.p2.11.m11.1.1" xref="Ch7.S1.SS4.p2.11.m11.1.1.cmml"><mi id="Ch7.S1.SS4.p2.11.m11.1.1.2" xref="Ch7.S1.SS4.p2.11.m11.1.1.2.cmml">X</mi><mi id="Ch7.S1.SS4.p2.11.m11.1.1.3" xref="Ch7.S1.SS4.p2.11.m11.1.1.3.cmml">q</mi></msup><annotation-xml encoding="MathML-Content" id="Ch7.S1.SS4.p2.11.m11.1b"><apply id="Ch7.S1.SS4.p2.11.m11.1.1.cmml" xref="Ch7.S1.SS4.p2.11.m11.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.11.m11.1.1.1.cmml" xref="Ch7.S1.SS4.p2.11.m11.1.1">superscript</csymbol><ci id="Ch7.S1.SS4.p2.11.m11.1.1.2.cmml" xref="Ch7.S1.SS4.p2.11.m11.1.1.2">𝑋</ci><ci id="Ch7.S1.SS4.p2.11.m11.1.1.3.cmml" xref="Ch7.S1.SS4.p2.11.m11.1.1.3">𝑞</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S1.SS4.p2.11.m11.1c">X^{q}</annotation><annotation encoding="application/x-llamapun" id="Ch7.S1.SS4.p2.11.m11.1d">italic_X start_POSTSUPERSCRIPT italic_q end_POSTSUPERSCRIPT</annotation></semantics></math>, an answer generator reads the reviews <math alttext="X^{r}" class="ltx_Math" display="inline" id="Ch7.S1.SS4.p2.12.m12.1"><semantics id="Ch7.S1.SS4.p2.12.m12.1a"><msup id="Ch7.S1.SS4.p2.12.m12.1.1" xref="Ch7.S1.SS4.p2.12.m12.1.1.cmml"><mi id="Ch7.S1.SS4.p2.12.m12.1.1.2" xref="Ch7.S1.SS4.p2.12.m12.1.1.2.cmml">X</mi><mi id="Ch7.S1.SS4.p2.12.m12.1.1.3" xref="Ch7.S1.SS4.p2.12.m12.1.1.3.cmml">r</mi></msup><annotation-xml encoding="MathML-Content" id="Ch7.S1.SS4.p2.12.m12.1b"><apply id="Ch7.S1.SS4.p2.12.m12.1.1.cmml" xref="Ch7.S1.SS4.p2.12.m12.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.12.m12.1.1.1.cmml" xref="Ch7.S1.SS4.p2.12.m12.1.1">superscript</csymbol><ci id="Ch7.S1.SS4.p2.12.m12.1.1.2.cmml" xref="Ch7.S1.SS4.p2.12.m12.1.1.2">𝑋</ci><ci id="Ch7.S1.SS4.p2.12.m12.1.1.3.cmml" xref="Ch7.S1.SS4.p2.12.m12.1.1.3">𝑟</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S1.SS4.p2.12.m12.1c">X^{r}</annotation><annotation encoding="application/x-llamapun" id="Ch7.S1.SS4.p2.12.m12.1d">italic_X start_POSTSUPERSCRIPT italic_r end_POSTSUPERSCRIPT</annotation></semantics></math> and attributes <math alttext="A" class="ltx_Math" display="inline" id="Ch7.S1.SS4.p2.13.m13.1"><semantics id="Ch7.S1.SS4.p2.13.m13.1a"><mi id="Ch7.S1.SS4.p2.13.m13.1.1" xref="Ch7.S1.SS4.p2.13.m13.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="Ch7.S1.SS4.p2.13.m13.1b"><ci id="Ch7.S1.SS4.p2.13.m13.1.1.cmml" xref="Ch7.S1.SS4.p2.13.m13.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S1.SS4.p2.13.m13.1c">A</annotation><annotation encoding="application/x-llamapun" id="Ch7.S1.SS4.p2.13.m13.1d">italic_A</annotation></semantics></math>, then generates an answer <math alttext="\hat{Y}=\{\hat{y}_{1},\hat{y}_{2},\dots,\hat{y}_{T_{y}}\}" class="ltx_Math" display="inline" id="Ch7.S1.SS4.p2.14.m14.4"><semantics id="Ch7.S1.SS4.p2.14.m14.4a"><mrow id="Ch7.S1.SS4.p2.14.m14.4.4" xref="Ch7.S1.SS4.p2.14.m14.4.4.cmml"><mover accent="true" id="Ch7.S1.SS4.p2.14.m14.4.4.5" xref="Ch7.S1.SS4.p2.14.m14.4.4.5.cmml"><mi id="Ch7.S1.SS4.p2.14.m14.4.4.5.2" xref="Ch7.S1.SS4.p2.14.m14.4.4.5.2.cmml">Y</mi><mo id="Ch7.S1.SS4.p2.14.m14.4.4.5.1" xref="Ch7.S1.SS4.p2.14.m14.4.4.5.1.cmml">^</mo></mover><mo id="Ch7.S1.SS4.p2.14.m14.4.4.4" xref="Ch7.S1.SS4.p2.14.m14.4.4.4.cmml">=</mo><mrow id="Ch7.S1.SS4.p2.14.m14.4.4.3.3" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.4.cmml"><mo id="Ch7.S1.SS4.p2.14.m14.4.4.3.3.4" stretchy="false" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.4.cmml">{</mo><msub id="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1" xref="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1.cmml"><mover accent="true" id="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1.2" xref="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1.2.cmml"><mi id="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1.2.2" xref="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1.2.2.cmml">y</mi><mo id="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1.2.1" xref="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1.2.1.cmml">^</mo></mover><mn id="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1.3" xref="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1.3.cmml">1</mn></msub><mo id="Ch7.S1.SS4.p2.14.m14.4.4.3.3.5" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.4.cmml">,</mo><msub id="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2" xref="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2.cmml"><mover accent="true" id="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2.2" xref="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2.2.cmml"><mi id="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2.2.2" xref="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2.2.2.cmml">y</mi><mo id="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2.2.1" xref="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2.2.1.cmml">^</mo></mover><mn id="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2.3" xref="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2.3.cmml">2</mn></msub><mo id="Ch7.S1.SS4.p2.14.m14.4.4.3.3.6" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.4.cmml">,</mo><mi id="Ch7.S1.SS4.p2.14.m14.1.1" mathvariant="normal" xref="Ch7.S1.SS4.p2.14.m14.1.1.cmml">…</mi><mo id="Ch7.S1.SS4.p2.14.m14.4.4.3.3.7" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.4.cmml">,</mo><msub id="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.cmml"><mover accent="true" id="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.2" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.2.cmml"><mi id="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.2.2" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.2.2.cmml">y</mi><mo id="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.2.1" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.2.1.cmml">^</mo></mover><msub id="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.3" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.3.cmml"><mi id="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.3.2" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.3.2.cmml">T</mi><mi id="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.3.3" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.3.3.cmml">y</mi></msub></msub><mo id="Ch7.S1.SS4.p2.14.m14.4.4.3.3.8" stretchy="false" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="Ch7.S1.SS4.p2.14.m14.4b"><apply id="Ch7.S1.SS4.p2.14.m14.4.4.cmml" xref="Ch7.S1.SS4.p2.14.m14.4.4"><eq id="Ch7.S1.SS4.p2.14.m14.4.4.4.cmml" xref="Ch7.S1.SS4.p2.14.m14.4.4.4"></eq><apply id="Ch7.S1.SS4.p2.14.m14.4.4.5.cmml" xref="Ch7.S1.SS4.p2.14.m14.4.4.5"><ci id="Ch7.S1.SS4.p2.14.m14.4.4.5.1.cmml" xref="Ch7.S1.SS4.p2.14.m14.4.4.5.1">^</ci><ci id="Ch7.S1.SS4.p2.14.m14.4.4.5.2.cmml" xref="Ch7.S1.SS4.p2.14.m14.4.4.5.2">𝑌</ci></apply><set id="Ch7.S1.SS4.p2.14.m14.4.4.3.4.cmml" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.3"><apply id="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1.cmml" xref="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1.1.cmml" xref="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1">subscript</csymbol><apply id="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1.2.cmml" xref="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1.2"><ci id="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1.2.1.cmml" xref="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1.2.1">^</ci><ci id="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1.2.2.cmml" xref="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1.2.2">𝑦</ci></apply><cn id="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1.3.cmml" type="integer" xref="Ch7.S1.SS4.p2.14.m14.2.2.1.1.1.3">1</cn></apply><apply id="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2.cmml" xref="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2.1.cmml" xref="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2">subscript</csymbol><apply id="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2.2.cmml" xref="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2.2"><ci id="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2.2.1.cmml" xref="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2.2.1">^</ci><ci id="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2.2.2.cmml" xref="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2.2.2">𝑦</ci></apply><cn id="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2.3.cmml" type="integer" xref="Ch7.S1.SS4.p2.14.m14.3.3.2.2.2.3">2</cn></apply><ci id="Ch7.S1.SS4.p2.14.m14.1.1.cmml" xref="Ch7.S1.SS4.p2.14.m14.1.1">…</ci><apply id="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.cmml" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.1.cmml" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3">subscript</csymbol><apply id="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.2.cmml" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.2"><ci id="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.2.1.cmml" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.2.1">^</ci><ci id="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.2.2.cmml" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.2.2">𝑦</ci></apply><apply id="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.3.cmml" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.3"><csymbol cd="ambiguous" id="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.3.1.cmml" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.3">subscript</csymbol><ci id="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.3.2.cmml" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.3.2">𝑇</ci><ci id="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.3.3.cmml" xref="Ch7.S1.SS4.p2.14.m14.4.4.3.3.3.3.3">𝑦</ci></apply></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S1.SS4.p2.14.m14.4c">\hat{Y}=\{\hat{y}_{1},\hat{y}_{2},\dots,\hat{y}_{T_{y}}\}</annotation><annotation encoding="application/x-llamapun" id="Ch7.S1.SS4.p2.14.m14.4d">over^ start_ARG italic_Y end_ARG = { over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , … , over^ start_ARG italic_y end_ARG start_POSTSUBSCRIPT italic_T start_POSTSUBSCRIPT italic_y end_POSTSUBSCRIPT end_POSTSUBSCRIPT }</annotation></semantics></math>.
The goal is to generate an answer <math alttext="\hat{Y}" class="ltx_Math" display="inline" id="Ch7.S1.SS4.p2.15.m15.1"><semantics id="Ch7.S1.SS4.p2.15.m15.1a"><mover accent="true" id="Ch7.S1.SS4.p2.15.m15.1.1" xref="Ch7.S1.SS4.p2.15.m15.1.1.cmml"><mi id="Ch7.S1.SS4.p2.15.m15.1.1.2" xref="Ch7.S1.SS4.p2.15.m15.1.1.2.cmml">Y</mi><mo id="Ch7.S1.SS4.p2.15.m15.1.1.1" xref="Ch7.S1.SS4.p2.15.m15.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="Ch7.S1.SS4.p2.15.m15.1b"><apply id="Ch7.S1.SS4.p2.15.m15.1.1.cmml" xref="Ch7.S1.SS4.p2.15.m15.1.1"><ci id="Ch7.S1.SS4.p2.15.m15.1.1.1.cmml" xref="Ch7.S1.SS4.p2.15.m15.1.1.1">^</ci><ci id="Ch7.S1.SS4.p2.15.m15.1.1.2.cmml" xref="Ch7.S1.SS4.p2.15.m15.1.1.2">𝑌</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S1.SS4.p2.15.m15.1c">\hat{Y}</annotation><annotation encoding="application/x-llamapun" id="Ch7.S1.SS4.p2.15.m15.1d">over^ start_ARG italic_Y end_ARG</annotation></semantics></math> that is grammatically correct and consistent with product attributes and opinions in the reviews.</p>
</div>
<div class="ltx_para" id="Ch7.S1.SS4.p3">
<p class="ltx_p" id="Ch7.S1.SS4.p3.1">As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.F2" title="Figure 7.2 ‣ 7.1.4 Generative product-aware QA ‣ 7.1 Question answering in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.2</span></a>, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">gao2019product</span></cite> provided an overview of their proposed product-aware answer generator, the PAAG model.
PAAG is divided into four parts:

<span class="ltx_inline-enumerate" id="Ch7.S1.I3">
<span class="ltx_inline-item" id="Ch7.S1.I3.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text ltx_font_italic" id="Ch7.S1.I3.i1.1">review reader</span><span class="ltx_text" id="Ch7.S1.I3.i1.2">reads the review to extract relevant semantic parts;
</span></span>
<span class="ltx_inline-item" id="Ch7.S1.I3.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text ltx_font_italic" id="Ch7.S1.I3.i2.1">attribute encoder</span><span class="ltx_text" id="Ch7.S1.I3.i2.2">encodes the attribute key-value pairs using a key-value memory network;
</span></span>
<span class="ltx_inline-item" id="Ch7.S1.I3.i3"><span class="ltx_tag ltx_tag_inline-item">(iii)</span> <span class="ltx_text ltx_font_italic" id="Ch7.S1.I3.i3.1">facts decoder</span><span class="ltx_text" id="Ch7.S1.I3.i3.2">generates the final answer according to the facts learned by the two modules introduced before; and
</span></span>
<span class="ltx_inline-item" id="Ch7.S1.I3.i4"><span class="ltx_tag ltx_tag_inline-item">(iv)</span> <span class="ltx_text ltx_font_italic" id="Ch7.S1.I3.i4.1">consistency discriminator</span><span class="ltx_text" id="Ch7.S1.I3.i4.2">distinguishes whether the generated answer matches the extracted facts, and we also use the result of the discriminator as another training signal.
</span></span>
</span>
A generative e-commerce QA dataset extracted from JD.com is released with the publication.
Similarly, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019driven</span></cite> proposed a noise-tolerant solution based on convolutional neural networks to generate natural answers.</p>
</div>
<figure class="ltx_figure" id="Ch7.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="392" id="Ch7.F2.g1" src="x41.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7.2: </span>Overview of the product-aware answer generator model. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gao2019product</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch7.S1.SS4.p4">
<p class="ltx_p" id="Ch7.S1.SS4.p4.1"><cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">deng2020opinion</span></cite> exploited opinion information reflected in the reviews. The authors generated opinion-aware natural answers using multi-task learning to integrate opinion detection and answer generation simultaneously.</p>
</div>
<div class="ltx_para" id="Ch7.S1.SS4.p5">
<p class="ltx_p" id="Ch7.S1.SS4.p5.1">It is necessary to consider the text information from different reviews and attributes to answer specific questions in the wild.
In Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.F3" title="Figure 7.3 ‣ 7.1.4 Generative product-aware QA ‣ 7.1 Question answering in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.3</span></a>, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">feng2021multi</span></cite> provided examples to demonstrate the multi-type text relation for product-aware question answering.
As an example, <span class="ltx_text ltx_font_italic" id="Ch7.S1.SS4.p5.1.1">Q1</span> asks <span class="ltx_text ltx_font_italic" id="Ch7.S1.SS4.p5.1.2">“Does the design of this top look baggy?”</span>. <span class="ltx_text ltx_font_italic" id="Ch7.S1.SS4.p5.1.3">R1</span> and <span class="ltx_text ltx_font_italic" id="Ch7.S1.SS4.p5.1.4">R2</span> do not answer this question directly. But they provide a common entity <span class="ltx_text ltx_font_italic" id="Ch7.S1.SS4.p5.1.5">“bat-like sleeve”</span>. If we transfer the information provided by <span class="ltx_text ltx_font_italic" id="Ch7.S1.SS4.p5.1.6">R1</span> and <span class="ltx_text ltx_font_italic" id="Ch7.S1.SS4.p5.1.7">R2</span> to answer <span class="ltx_text ltx_font_italic" id="Ch7.S1.SS4.p5.1.8">Q1</span> indirectly, it is easy to generate the answer that <span class="ltx_text ltx_font_italic" id="Ch7.S1.SS4.p5.1.9">“The design of this tops looks baggy.”</span>. The above example shows that we may generate more accurate and pleasing answers to complex questions by integrating, understanding, and reasoning over the information of reviews and product attributes.</p>
</div>
<figure class="ltx_figure" id="Ch7.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="615" id="Ch7.F3.g1" src="x42.png" width="705"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7.3: </span>Examples of the multi-type text relation for product-aware question answering. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">feng2021multi</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch7.S1.SS4.p6">
<p class="ltx_p" id="Ch7.S1.SS4.p6.1">One major limitation of most existing generative QA approaches is that they analyze each review and the corresponding attribute of the product individually, i.e., they neglect the relationship between different reviews/attributes of the product.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">feng2021multi</span></cite> proposed a review-attribute heterogeneous graph neural network, namely RAHGNN, for product-aware answer generation to sufficiently understand and reason the related information and its inner logic in multi-type texts.
Most generative product-aware QA methods neglect personalization as it is insufficient to provide the same “completely summarized” answer to all customers.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">deng2022toward</span></cite> proposed a personalized answer generation method, namely PAGE, to comprehensively model multi-perspective user preferences in personalized product question answering.</p>
</div>
</section>
</section>
<section class="ltx_section" id="Ch7.S2">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7.2 </span>Dialogue systems in e-commerce</h3>
<div class="ltx_para" id="Ch7.S2.p1">
<p class="ltx_p" id="Ch7.S2.p1.1">Dialogue systems have attracted more and more attention in e-commerce.
This section introduces studies on dialogue systems that can be applied to e-commerce platforms.
According to most previous work investigating this research problem <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">Chen2017A</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ziwwsdm1</span></cite>, we divide this section into three parts: we briefly introduce recent studies on dialogue systems in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S2.SS1" title="7.2.1 Introduction to dialogue systems ‣ 7.2 Dialogue systems in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.2.1</span></a>; then detail task-oriented dialogue systems in e-commerce in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S2.SS2" title="7.2.2 Task-oriented dialogue systems ‣ 7.2 Dialogue systems in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.2.2</span></a>; demonstrate knowledge-grounded conversational agents in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S2.SS3" title="7.2.3 Knowledge-grounded dialogue systems ‣ 7.2 Dialogue systems in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.2.3</span></a>.</p>
</div>
<section class="ltx_subsection" id="Ch7.S2.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2.1 </span>Introduction to dialogue systems</h4>
<div class="ltx_para" id="Ch7.S2.SS1.p1">
<p class="ltx_p" id="Ch7.S2.SS1.p1.1">In recent years, dialogue systems have received more and more attention in numerous applications, from e-commerce technical support to personal assistant tools <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">song2017summarizing</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Chen2017A</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ziwwsdm1</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2016conversational</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2018towards</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lei2018sequicity</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2018knowledge</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">meng2020dukenet</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2021conversations</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">shen2021vida</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2021jddc</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2021conversational</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ren2022variational</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2022knowledge</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yu2022xdai</span>]</cite>.
The goal of creating an automatic human-computer conversation system as our assistant or chat companion is no longer an illusion as two different aspects have been combined simultaneously.
First, many conversation logs are accessible, making it possible to learn how to respond to the input utterances.
Second, deep generative neural network models, such as sequence-to-sequence and generative adversarial networks, have been verified to capture complex patterns in big data <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Chen2017A</span>]</cite>.
Based on these two aspects, studies on dialogue systems aim to provide a natural and coherent response given an utterance from a user <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Young2013POMDP</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Ritter2011Data</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Banchs2013IRIS</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Ameixa2014Luke</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS1.p2">
<p class="ltx_p" id="Ch7.S2.SS1.p2.1">Dialogue systems can be divided into chitchat systems, task-oriented dialogue systems, and knowledge-grounded conversations <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Chen2017A</span>]</cite>.
Chitchat agents are applied widely in open-domain dialogue systems, where dialogue systems interact with humans to provide reasonable and natural responses for open-domain dialogues <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ziwwsdm1</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yan2017building</span>]</cite>.
Chitchat messages usually represent user experiences and preferences, playing an essential role in many real-world applications.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">yan2017building</span></cite> revealed most utterances in the online shopping scenario are chitchat messages.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS1.p3">
<p class="ltx_p" id="Ch7.S2.SS1.p3.1">Task-oriented dialogue systems aim to complete a specific task, e.g., restaurant reservation, along with a response generation process.
Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.F4" title="Figure 7.4 ‣ 7.2.1 Introduction to dialogue systems ‣ 7.2 Dialogue systems in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.4</span></a> shows traditional task-oriented dialogue systems based on four individual modules: natural language understanding, dialogue state tracking, policy learning, and natural language generation <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2017latent</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">mrkvsic2015multi</span>]</cite>.
Given an utterance from a user, the system will generate a proper response to address the user’s intention. In recent years, end-to-end task-oriented dialogue generation methods have been proposed to address the research problem more efficiently <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2017network</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lei2018sequicity</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2019transferable</span>]</cite>.</p>
</div>
<figure class="ltx_figure" id="Ch7.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="270" id="Ch7.F4.g1" src="x43.png" width="664"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7.4: </span>Traditional pipeline for task-oriented dialogue systems. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Chen2017A</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch7.S2.SS1.p4">
<p class="ltx_p" id="Ch7.S2.SS1.p4.1">Knowledge-grounded conversations focus on generating a response with the correct knowledge to address the user’s utterance <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">meng2020dukenet</span>]</cite>.
According to the knowledge modality, existing works for knowledge-grounded conversation can be mainly categorized into two groups.
The methods in the first group aim to leverage <span class="ltx_text ltx_font_italic" id="Ch7.S2.SS1.p4.1.1">structured knowledge</span> (given knowledge graphs)  <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2018commonsense</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2018knowledge</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">tuan2019dykgchat</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2019proactive</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">moon2019opendialkg</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2020diverse</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou-etal-2020-kdconv</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2020improving</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2020improving</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">xu2020knowledge</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">xu2020conversational</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">jung2020attnio</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">xu-etal-2021-discovering</span>]</cite>.
Those in the second group focus on leveraging <span class="ltx_text ltx_font_italic" id="Ch7.S2.SS1.p4.1.2">unstructured knowledge</span>, such as <span class="ltx_text ltx_font_italic" id="Ch7.S2.SS1.p4.1.3">document-based unstructured knowledge</span> (given a whole document, e.g., a Wikipedia article) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chuanmeng2020refnet</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ma2020survey</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ma2020compare</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">tian-etal-2020-response</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ren2019thinking</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gopalakrishnan2019topical</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zekangli2018incremental</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">qin-etal-2019-conversing</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">moghe2018towards</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2018dataset</span>]</cite> or <span class="ltx_text ltx_font_italic" id="Ch7.S2.SS1.p4.1.4">piece-based unstructured knowledge</span> (given some separate pieces of knowledge, e.g., Foursquare tips) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ghazvininejad2018knowledge</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">dinan2018wizard</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">meng2020dukenet</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kim2020sequential</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Lian2019Learning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zheng2019enhancing</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zheng2020difference</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2020bridging</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zheng2020approximation</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2020knowledge</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yu2022xdai</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS1.p5">
<p class="ltx_p" id="Ch7.S2.SS1.p5.1">According to the way of generating responses, dialogue systems can be divided into retrieval-based and generation-based dialogue systems.
The former retrieves several response candidates from a prebuilt index and then selects an appropriate one as a response. In contrast, the latter directly synthesizes a reply via natural language generation techniques <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">hvred</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">tao2021survey</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS1.p6">
<p class="ltx_p" id="Ch7.S2.SS1.p6.1">Retrieval-based dialogue systems retrieve several response candidates from a prebuilt index and then select an appropriate one as a response.
The flourishing of social networking services has accumulated a significant amount of conversation data among humans on the web, encouraging researchers to investigate data-driven approaches to re-use the existing human conversations and select a response for new input from candidates <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">tao2021survey</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">xu2021response</span>]</cite>.
Retrieval-based dialogue generation methods are superior to their generation-based counterparts in response fluency and informativeness, which powers a series of real-world applications, e.g., XiaoIce from Microsoft <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2020design</span>]</cite>.
Learning to rank and matching approaches have been widely applied in the retrieval process <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yan2016learning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2017sequential</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2018multi</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2018response</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yuan2019multi</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">su2020dialogue</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">tao2021survey</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lin2022task</span>]</cite>.
A core task in retrieval-based dialogue systems is response selection.
According to the way of matching candidate responses, existing studies on retrieval-based response selection can be divided into <math alttext="3" class="ltx_Math" display="inline" id="Ch7.S2.SS1.p6.1.m1.1"><semantics id="Ch7.S2.SS1.p6.1.m1.1a"><mn id="Ch7.S2.SS1.p6.1.m1.1.1" xref="Ch7.S2.SS1.p6.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="Ch7.S2.SS1.p6.1.m1.1b"><cn id="Ch7.S2.SS1.p6.1.m1.1.1.cmml" type="integer" xref="Ch7.S2.SS1.p6.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S2.SS1.p6.1.m1.1c">3</annotation><annotation encoding="application/x-llamapun" id="Ch7.S2.SS1.p6.1.m1.1d">3</annotation></semantics></math> types: representation-based, interaction-based, and pre-trained language model-based methods.
Representation-based methods are composed of a representation-matching paradigm and consist of a representation layer and a matching layer <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yan2016learning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018response</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2017deep</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2018dataset</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2018multi</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yan2018response</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">xu2021topic</span>]</cite>.
Interaction-based methods use context-response interactions to match potential responses <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">tao2021survey</span>]</cite>.
These methods followed a representation-matching-aggregation paradigm, formulating an interaction function to calculate the interaction between the two representation matrices of input utterances.
The interaction function has two main types of definitions for the interaction function: similarity-based and attention-based methods <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">tao2021survey</span>]</cite>.
Similarity-based methods calculate the similarity of each word pair between the context message and the response candidate <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2017sequential</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2018modeling</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2018multi</span>]</cite>.
Attention-based methods, however, use an attention mechanism to match the context message and the candidate’s response <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019sequential</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">humeau2019poly</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yuan2019multi</span>]</cite>.
In recent years, pre-trained language models have been applied in retrieval-based dialogue systems due to their strong ability for language representation and understanding.
These approaches employed an attention-based strategy to unify the representation, interaction, and aggregation operations by feeding the concatenation of context utterances and the candidate responses into a pre-trained multi-layer self-attention network <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">whang2020effective</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gu2020speaker</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">xu2021learning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">han2021fine</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">tao2021pre</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">feng2022reciprocal</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2022unsupervised</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS1.p7">
<p class="ltx_p" id="Ch7.S2.SS1.p7.1">Generation-based dialogue systems aim to generate natural-sounding replies automatically to exchange information (e.g., knowledge, sentiments, etc.) and complete a variety of specific tasks in a conversation interaction process <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Young2013POMDP</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">shawar2007</span>]</cite>.
End-to-end textual generation models <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">shang</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">vinyals2015neural</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sordoni2015</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2016a</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2016b</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">serban2016building</span>]</cite> have proved capable in multiple dialogue systems applications with promising performance.
Most end-to-end neural generation models apply an encoder-decoder architecture based on a recurrent neural network, which directly maps an input context to the output response.
Several approaches have been proposed to softly model language patterns, such as word alignment and repeating into sequence-to-sequence structure <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bahdanau2015neural</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gu2016incorporating</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">serban2017multiresolution</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">cao2017</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">gu2016incorporating</span></cite> proposed a copy mechanism to consider additional copying probabilities for contextual words in forum conversations.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">serban2017multiresolution</span></cite> decoded coarse tokens before generating the complete response.
Variational neural networks perform efficient inference and learning in models with directed probabilities on a large-scale dataset <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Kingma2014Auto</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Kingma2014Adam</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">cao2017</span></cite> tackled the boring output issue of deterministic dialogue models by introducing a latent variable model for a one-shot dialogue response.
<cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">hvred</span>]</cite> proposed HVRED to utilize the latent variable at the sub-sequence level in a hierarchical setting, whereas <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ziwwsdm1</span></cite> added a hierarchical structure and a variational memory module into a neural encoder-decoder network.</p>
</div>
<figure class="ltx_figure" id="Ch7.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="305" id="Ch7.F5.g1" src="x44.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7.5: </span>An example e-commerce dialogue in the JDDC 1.0 dataset. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019jddc</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch7.S2.SS1.p8">
<p class="ltx_p" id="Ch7.S2.SS1.p8.1">In e-commerce platforms, after-sale customer service is the main application scenario for dialogue systems.
In contrast with existing dialogue systems, e-commerce dialogues need to address three targets:

<span class="ltx_inline-enumerate" id="Ch7.S2.I1">
<span class="ltx_inline-item" id="Ch7.S2.I1.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch7.S2.I1.i1.1">task completion, such as changing the order address, providing the receipt, and returning the order;
</span></span>
<span class="ltx_inline-item" id="Ch7.S2.I1.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch7.S2.I1.i2.1">knowledge-based response selection and generation, such as checking the status of the delivery, answering the request about the refund period; and
</span></span>
<span class="ltx_inline-item" id="Ch7.S2.I1.i3"><span class="ltx_tag ltx_tag_inline-item">(iii)</span> <span class="ltx_text" id="Ch7.S2.I1.i3.1">empathetic response generation, such as satisfying the consumers’ request and replying to consumers’ complaints.
</span></span>
</span>
JDDC datasets are collected from JD.com. one of the largest e-commerce platforms in China.
Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.F5" title="Figure 7.5 ‣ 7.2.1 Introduction to dialogue systems ‣ 7.2 Dialogue systems in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.5</span></a> shows a typical example dialogue from JDDC 1.0 dataset.
We can see that the blue text shows the target completion task, the red text indicates the knowledge-based response generation task, and the purple text shows the empathetic response generation task.
Another characteristic of e-commerce dialogue systems is the phenomenon of multiple modalities.
It is observed that text and images are often used in customer service dialogues <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2021jddc</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yuan2022mcic</span>]</cite>.</p>
</div>
<figure class="ltx_figure" id="Ch7.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="527" id="Ch7.F6.g1" src="x45.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7.6: </span>Three segments of dialogue sampled from our JDDC 2.0 corpus. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2021jddc</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch7.S2.SS1.p9">
<p class="ltx_p" id="Ch7.S2.SS1.p9.3">Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.F6" title="Figure 7.6 ‣ 7.2.1 Introduction to dialogue systems ‣ 7.2 Dialogue systems in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.6</span></a> shows another example from the JDDC 2.0 dataset to demonstrate the multi-modality characteristic of e-commerce.
In this figure, <math alttext="3" class="ltx_Math" display="inline" id="Ch7.S2.SS1.p9.1.m1.1"><semantics id="Ch7.S2.SS1.p9.1.m1.1a"><mn id="Ch7.S2.SS1.p9.1.m1.1.1" xref="Ch7.S2.SS1.p9.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="Ch7.S2.SS1.p9.1.m1.1b"><cn id="Ch7.S2.SS1.p9.1.m1.1.1.cmml" type="integer" xref="Ch7.S2.SS1.p9.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S2.SS1.p9.1.m1.1c">3</annotation><annotation encoding="application/x-llamapun" id="Ch7.S2.SS1.p9.1.m1.1d">3</annotation></semantics></math> dialogue segments show images that are used to distinguish different product models for the same brand or used for identifying the location and cause of product failures.
According to the above <math alttext="3" class="ltx_Math" display="inline" id="Ch7.S2.SS1.p9.2.m2.1"><semantics id="Ch7.S2.SS1.p9.2.m2.1a"><mn id="Ch7.S2.SS1.p9.2.m2.1.1" xref="Ch7.S2.SS1.p9.2.m2.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="Ch7.S2.SS1.p9.2.m2.1b"><cn id="Ch7.S2.SS1.p9.2.m2.1.1.cmml" type="integer" xref="Ch7.S2.SS1.p9.2.m2.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S2.SS1.p9.2.m2.1c">3</annotation><annotation encoding="application/x-llamapun" id="Ch7.S2.SS1.p9.2.m2.1d">3</annotation></semantics></math> targets in e-commerce dialogues, we detail e-commerce dialogue systems through <math alttext="3" class="ltx_Math" display="inline" id="Ch7.S2.SS1.p9.3.m3.1"><semantics id="Ch7.S2.SS1.p9.3.m3.1a"><mn id="Ch7.S2.SS1.p9.3.m3.1.1" xref="Ch7.S2.SS1.p9.3.m3.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="Ch7.S2.SS1.p9.3.m3.1b"><cn id="Ch7.S2.SS1.p9.3.m3.1.1.cmml" type="integer" xref="Ch7.S2.SS1.p9.3.m3.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S2.SS1.p9.3.m3.1c">3</annotation><annotation encoding="application/x-llamapun" id="Ch7.S2.SS1.p9.3.m3.1d">3</annotation></semantics></math> angles: task-oriented dialogue systems, knowledge-grounded dialogue systems, and empathetic dialogue systems in Sections <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S2.SS2" title="7.2.2 Task-oriented dialogue systems ‣ 7.2 Dialogue systems in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.2.2</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S2.SS3" title="7.2.3 Knowledge-grounded dialogue systems ‣ 7.2 Dialogue systems in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.2.3</span></a>, and <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S2.SS4" title="7.2.4 Empathetic dialogue generation ‣ 7.2 Dialogue systems in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.2.4</span></a>, respectively.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch7.S2.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2.2 </span>Task-oriented dialogue systems</h4>
<div class="ltx_para" id="Ch7.S2.SS2.p1">
<p class="ltx_p" id="Ch7.S2.SS2.p1.1">The methods of task-oriented dialogue systems can be divided into pipeline methods and end-to-end methods.
As shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.F4" title="Figure 7.4 ‣ 7.2.1 Introduction to dialogue systems ‣ 7.2 Dialogue systems in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.4</span></a>, the pipeline of task-oriented dialogue systems can be divided into natural language understanding (NLU), dialogue state tracking (DST), and dialogue policy learning (DPL), and natural language generation (NLG) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Chen2017A</span>]</cite>.
For each stage, there are a bunch of pipeline-based approaches have been proposed.
Despite a lot of domain-specific handcrafting in traditional task-oriented dialogue systems, which are difficult to adapt to new domains <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bordes2016learning</span>]</cite>.
Recently, end-to-end neural network solutions have been widely applied to the task <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bordes2016learning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2016towards</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2017network</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">jin2018explicit</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gao2018neural</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">madotto2018mem2seq</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS2.p2">
<p class="ltx_p" id="Ch7.S2.SS2.p2.1">In NLU, the dialogue system maps the input utterance into semantic slots. These semantic slots are pre-defined in different application scenarios.
NLU includes two challenging problems: intent detection and slot filling.
Intent detection methods for language understanding are performed to detect the user’s intent <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">deng2012use</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">tur2012towards</span>]</cite>.
Deep neural networks have also been applied to detect the user’s intent.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">huang2013learning</span></cite> use convolutional neural networks (CNN) to detect the user’s intent. A similar CNN-based classification framework also resembled <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">shen2014learning</span>]</cite>.
Slot filling is usually set as a sequence labeling problem, where words are assigned with semantic labels <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Chen2017A</span>]</cite>.
Deep belief networks have been successfully applied to address the filling problem <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">deng2012use</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">deoras2013deep</span>]</cite>.
Subsequently, recurrent neural networks are verified as effective in slot filling <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mesnil2013investigation</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sarikaya2011deep</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yao2013recurrent</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yao2014spoken</span>]</cite>.
Unlike other NLU approaches, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">liang2020moss</span></cite> jointly formulated intent detection and slot filling as a sequence generation problem.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">rastogi2020towards</span></cite> provided a schema-guided paradigm for NLU.
Recently, pre-trained language models have been applied to enhance NLC in task-oriented dialogue systems.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2020tod</span></cite> proposed a self-supervised language model trained on multiple task-oriented dialogue system benchmarks. The authors verified that their proposed model achieved the best in-scope and out-of-scope performances in NLU.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2021effectiveness</span></cite> proposed a pre-trained model for few-shot NLU by fine-tuning BERT on a small set of labeled utterances.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">10.1145/3477495.3532069</span></cite> explored tree-induced semi-supervised contrastive pre-training for NLU in task-oriented dialogue systems. The authors improved the NLU performance by injecting structural-semantic information to enhance the representation of dialogues.
To explore more knowledge from long sequences in dialogue context, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhong2022dialoglm</span></cite> proposed a window-based pre-trained model for NLU based on the sequence-to-sequence model architecture.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS2.p3">
<p class="ltx_p" id="Ch7.S2.SS2.p3.2">In a conversation, a <em class="ltx_emph ltx_font_italic" id="Ch7.S2.SS2.p3.2.1">dialogue state</em> refers to a full and temporal representation of each participant’s intention <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">goddeau1996form</span>]</cite>.
In task-oriented dialogue generation, dynamically tracking dialogue states is the key to generating coherent and context-sensitive responses.
In DST, we use a dialogue state <math alttext="H_{t}" class="ltx_Math" display="inline" id="Ch7.S2.SS2.p3.1.m1.1"><semantics id="Ch7.S2.SS2.p3.1.m1.1a"><msub id="Ch7.S2.SS2.p3.1.m1.1.1" xref="Ch7.S2.SS2.p3.1.m1.1.1.cmml"><mi id="Ch7.S2.SS2.p3.1.m1.1.1.2" xref="Ch7.S2.SS2.p3.1.m1.1.1.2.cmml">H</mi><mi id="Ch7.S2.SS2.p3.1.m1.1.1.3" xref="Ch7.S2.SS2.p3.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="Ch7.S2.SS2.p3.1.m1.1b"><apply id="Ch7.S2.SS2.p3.1.m1.1.1.cmml" xref="Ch7.S2.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="Ch7.S2.SS2.p3.1.m1.1.1.1.cmml" xref="Ch7.S2.SS2.p3.1.m1.1.1">subscript</csymbol><ci id="Ch7.S2.SS2.p3.1.m1.1.1.2.cmml" xref="Ch7.S2.SS2.p3.1.m1.1.1.2">𝐻</ci><ci id="Ch7.S2.SS2.p3.1.m1.1.1.3.cmml" xref="Ch7.S2.SS2.p3.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S2.SS2.p3.1.m1.1c">H_{t}</annotation><annotation encoding="application/x-llamapun" id="Ch7.S2.SS2.p3.1.m1.1d">italic_H start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> to denote the representation of the dialogue till time <math alttext="t" class="ltx_Math" display="inline" id="Ch7.S2.SS2.p3.2.m2.1"><semantics id="Ch7.S2.SS2.p3.2.m2.1a"><mi id="Ch7.S2.SS2.p3.2.m2.1.1" xref="Ch7.S2.SS2.p3.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="Ch7.S2.SS2.p3.2.m2.1b"><ci id="Ch7.S2.SS2.p3.2.m2.1.1.cmml" xref="Ch7.S2.SS2.p3.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S2.SS2.p3.2.m2.1c">t</annotation><annotation encoding="application/x-llamapun" id="Ch7.S2.SS2.p3.2.m2.1d">italic_t</annotation></semantics></math>.
Traditional approaches to DST focus on searching hand-crafted rules to select the most likely results <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2013simple</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">young2010hidden</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">williams2012belief</span>]</cite>, where the dialogue state tracking is transferred to a slot filling problem.
Such a kind of slot filling problem was also addressed by approaches using conditional random fields <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lee2013structured</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lee2013recipe</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ren2013dialog</span>]</cite> and maximum entropy <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">williams2013multi</span>]</cite>.
However, relying on the most likely results from an NLU module <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Perez17</span>]</cite>, these rule-based systems hardly model uncertainty, which is prone to frequent errors <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">williams2014web</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Perez17</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS2.p4">
<p class="ltx_p" id="Ch7.S2.SS2.p4.1">Unlike rule-based state tracking methods, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">young2010hidden</span></cite> proposed a distributional dialogue state for statistical dialog systems and maintained a distribution over multiple hypotheses facing noisy conditions and ambiguity.
Neural networks have been successfully applied to dialogue state tracking <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">henderson2013deep</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">mrkvsic2015multi</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">mrkvsic2017neural</span>]</cite>.
In task-oriented dialogue systems, end-to-end neural networks are employed for tracking dialogue states via interacting with an external knowledge base <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2017network</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">eric2017key</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">bordes2016learning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">williamszweig2017Long</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2017network</span></cite> divided the training procedure into two phases: the dialogue state tracker training and the complete model training.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">mrkvsic2017neural</span></cite> proposed a dialogue state tracker based on word embedding similarities.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">eric2017key</span></cite> implicitly modeled a dialogue state through an attention-based retrieval mechanism to reason over a key-value representation of the underlying knowledge base.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">bordes2016learning</span></cite> tracked the dialogue context in a memory module and repeatedly searched this context to select an adequate system response.
Instead of employing symbolic knowledge queries, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">dhingra-EtAl:2017:Long1</span></cite> proposed an induced “soft” posterior distribution over the knowledge base to search for matching entities.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">williamszweig2017Long</span></cite> combined an RNN with domain-specific knowledge encoded as software and system action templates.
The copying mechanism is verified effective as generative dialogue state tracking.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">lei2018sequicity</span></cite> proposed an extendable framework to track dialogue states with a text span, including the constraints for a knowledge base query.
The limited amount of labeled data is a severe challenge for DST.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">jin2018explicit</span></cite> proposed a semi-supervised way to integrate a copy procedure with the dialogue state tracking.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS2.p5">
<p class="ltx_p" id="Ch7.S2.SS2.p5.1">While early studies on DST methods focused on a single-domain scenario, recent studies have turned their attention to multi-domain DST with the release of a multi-domain DST benchmark dataset, MultiWoZ <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">budzianowski2018multiwoz</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ramadan2018large</span></cite> jointly identified the domain and tracks the belief states corresponding to that domain to address the multi-domain DST problem.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2019multi</span></cite> formulated multi-domain DST as a question-answering task and used
reading comprehension techniques to generate the answers.
Similarly, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">gao2019dialog</span></cite> also formulated DST as a reading comprehension task and proposed an attention-based neural network to find the state answer as a span over tokens.
DSTC challenges have provided a series of popular experimentation frameworks and dialog datasets collected through human-machine interactions for benchmarking <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">henderson2014second</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">henderson2014third</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">williams2014dialog</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">williams2016dialog</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS2.p6">
<p class="ltx_p" id="Ch7.S2.SS2.p6.1">In real-world scenarios, it is often not practical to enumerate all possible slot value pairs and
perform scoring from a large, dynamically changing knowledge base <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">xu2018end</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2019transferable</span></cite> proposed a method to generate dialogue states from utterances using a copy mechanism, where tracking knowledge across domains is shared.
To alleviate the data sparsity in DST, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">yin2020dialog</span></cite> proposed a reinforced data augmentation framework to increase both the amount and diversity of the training data.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2020schema</span></cite> incorporated slot relations and model slot interactions in multi-domain dialogue state tracking to enhance the slot interrelation between disciplines.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">feng2022dynamic</span></cite> extended this method by dynamically updating slot relations in the schema graph.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">heck2020trippy</span></cite> maintained two memories in DST: one for system inform slots and one for the previously seen slots.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">li-etal-2021-generation</span></cite> proposed the generation and extraction combined method with hierarchical ontology integration for DST.
To tackle the understanding of enormous ellipsis and reference expressions in open vocabulary-based methods, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ouyang2020dialogue</span></cite> proposed a copy-augmented encoder-decoder model by connecting the target slot and its source slot explicitly.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">liao2021multi</span></cite> formulated multi-domain DST as a recursive inference mechanism to improve the generation performance.
Most existing DST models are usually trained offline, which requires a fixed dataset prepared in advance.
Given a new domain in multi-domain DST, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">campagna2020zero</span></cite> proposed a zero-shot transfer learning method to handle new domains without incurring the high cost of data acquisition.
Recently, the granularity of dialogue history has been proposed to mitigate the sparseness in DST <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yang2021comprehensive</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">guo2022beyond</span></cite> proposed a multi-perspective dialogue collaborative selector module to dynamically select the granularity of dialogue history in DST.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS2.p7">
<p class="ltx_p" id="Ch7.S2.SS2.p7.1">Pre-trained language models have been verified as effective in dialogue state tracking.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">lin2021zero</span></cite> applied a pre-trained model for DST to exploit external knowledge from reading comprehension data.
Similarly, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhong2022dialoglm</span></cite> verified document summarization can provide helpful signals to improve DST.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2021domain</span></cite> introduced domain-lifelong learning into DST. The authors proposed a knowledge preservation network that includes a multi-prototype enhanced retrospection component and a multi-strategy knowledge distillation component.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">lin2021leveraging</span></cite> successfully applied T5 to improve zero-shot cross-domain DST.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">lee2021dialogue</span></cite> proposed a solution for multi-domain DST by prompting knowledge from a large-scale pre-trained language model.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">lin2021knowledge</span></cite> proposed a hybrid method to integrate GPT-2 with graph attention networks to enhance the DST performance.
To mitigate the problem of incorrect in DST, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2022luna</span></cite> proposed a BERT-based method by explicitly aligning each slot with its most relevant utterance.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS2.p8">
<p class="ltx_p" id="Ch7.S2.SS2.p8.1">Scalability, robustness, and efficiency in DST have also been addressed recently.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">lei2018sequicity</span></cite> proposed a two-stage copy-aware network demonstrating good scalability.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ren2019scalable</span></cite> considered the DST task as a sequence generation problem and proposed a scalable hierarchical encoder-decoder neural network with constant inference time complexity.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">kumar2020ma</span></cite> extended to improve the encoding of dialog context and slot semantics for DST to robustly capture critical dependencies between slots and the conversation history.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">kim2020efficient</span></cite> focused on an open vocabulary-based setting and considered the dialogue state as a memory that can be selectively overwritten to improve the efficiency in multi-domain DST.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhu2020efficient</span></cite> proposed an efficient multi-domain dialogue state tracker by jointly encoding the previous dialogue state, the current turn dialogue, and the schema graph by
internal and external attention mechanisms.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS2.p9">
<p class="ltx_p" id="Ch7.S2.SS2.p9.1">The policy learning module in task-oriented dialogue systems is to generate the following available system action given the state generation result <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">cuayahuitl2015strategic</span>]</cite>.
Traditional rule-based methods are first applied in the policy learning procedure <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">cuayahuitl2015strategic</span>]</cite>.
Supervised and reinforcement learning are also proven effective in policy learning <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">su2016continuously</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">yan2017building</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">su2016continuously</span></cite> proposed a two-stage framework for policy learning, i.e., a supervised learning stage and a reinforcement learning stage.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019agentgraph</span></cite> proposed a structured deep reinforcement learning approach for policy learning based on graph neural networks.
The dialogue policy can be further trained in an end-to-end way with reinforcement learning to lead the system in making policies toward the final performance <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yan2017building</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019agentgraph</span>]</cite>.
In an e-commerce scenario, the policy learning component needs to trigger the “recommendation” or a concrete service provided by the customer service <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2016conversational</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2018conversational</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2021jddc</span>]</cite>.
Most existing task-oriented dialogue datasets, including WoZ and MultiWoZ, focus mainly on language understanding and dialogue state tracking.
However, selecting actions in real life requires obeying user requests and following practical policy limitations.
Accordingly, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2021action</span></cite> presented the action-based conversations dataset consisting of <math alttext="10042" class="ltx_Math" display="inline" id="Ch7.S2.SS2.p9.1.m1.1"><semantics id="Ch7.S2.SS2.p9.1.m1.1a"><mn id="Ch7.S2.SS2.p9.1.m1.1.1" xref="Ch7.S2.SS2.p9.1.m1.1.1.cmml">10042</mn><annotation-xml encoding="MathML-Content" id="Ch7.S2.SS2.p9.1.m1.1b"><cn id="Ch7.S2.SS2.p9.1.m1.1.1.cmml" type="integer" xref="Ch7.S2.SS2.p9.1.m1.1.1">10042</cn></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S2.SS2.p9.1.m1.1c">10042</annotation><annotation encoding="application/x-llamapun" id="Ch7.S2.SS2.p9.1.m1.1d">10042</annotation></semantics></math> conversations containing numerous actions with precise procedural requirements.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">he2022galaxy</span></cite> utilized semi-supervised pre-training to model explicit dialog policy in task-oriented dialogue systems.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS2.p10">
<p class="ltx_p" id="Ch7.S2.SS2.p10.1">The natural language generation (NLG) component transfers a dialogue action into a natural language response <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Chen2017A</span>]</cite>.
Neural network-based NLG approaches have been proposed for task-oriented dialogues <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2015stochastic</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2015semantically</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">tran2017semantic</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2016context</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2015stochastic</span></cite> applied an RNN-based generator module and a CNN-based module to rerank candidate utterances.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2015semantically</span></cite> used an additional control cell to gate the dialogue act to address the slot information omitting and duplicating problems in surface realization.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">tran2017semantic</span></cite> extended this approach by gating the input token vector of LSTM with the dialogue act.
A sequence-to-sequence approach was applied to produce natural language output and deep syntax dependency trees from input dialogue acts <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">duvsek2016sequence</span>]</cite>.
Then, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2016context</span></cite> proposed an encoder-decoder LSTM-based method to jointly incorporate the request information, semantic slot values, and dialogue act type to generate correct answers.
Note that the copy mechanism <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">vinyals2015pointer</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gu2016incorporating</span>]</cite> has been successfully applied to the task-oriented dialogue systems to enhance the performance of NLG <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">eric2017copy</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lei2018sequicity</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">jin2018explicit</span>]</cite>.
Aiming to augment existing dialog data sets through paraphrase, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">gao2020paraphrase</span></cite> jointly optimized dialog paraphrase and dialog response generation via a paraphrase augmented response generation approach.
Pre-trained language models have shown supreme performances in text generation tasks <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2021pretrained</span>]</cite>.
In recent years, more and more studies have applied pre-trained language models to enhance the performances of NLG in task-oriented dialogue systems <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2019dialogpt</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">peng-etal-2020-shot</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2020tod</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">NEURIPS2020e9462095</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhong2022dialoglm</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS2.p11">
<p class="ltx_p" id="Ch7.S2.SS2.p11.1">End-to-end methods have been proposed for task-oriented dialogue systems.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2017network</span></cite> proposed an end-to-end trainable goal-oriented dialogue system with a new way of collecting dialogue data based on a pipeline framework toward end-to-end learning for DST and policy learning <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2016towards</span>]</cite>.
The pipeline-aware method can also be implemented and trained end-to-end using the copy mechanism <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lei2018sequicity</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">jin2018explicit</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liao2021multi</span>]</cite>.
A copy-augmented sequence-to-sequence architecture was proposed to provide better performance in task-oriented dialogues <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">eric2017copy</span>]</cite>, while <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">eric2017key</span></cite> proposed a key-value retrieval network for task-oriented dialogue response generation.
Using the copy mechanism, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">lei2018sequicity</span></cite> proposed a theoretically and aesthetically framework that is end-to-end trainable using only one seq-to-seq
model.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">jin2018explicit</span></cite> proposed a semi-supervised copy flow neural network to train the end-to-end dialogue generation model.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">madotto2018mem2seq</span></cite> proposed a memory-to-sequence neural network that combines the multi-hop attention over memories with the idea of a pointer network.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">xu2018end</span></cite> also applied a pointer network to handle unknown slot values in the absence of a predefined ontology.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">NEURIPS2020e9462095</span></cite> enabled modeling of the inherent dependencies between the sub-tasks of task-oriented dialogue by optimizing for all tasks in an end-to-end manner, recasting task-oriented dialogue as a simple and casual language modeling task.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">liao2021multi</span></cite> proposed a recursive inference mechanism to resolve multi-domain DST in an end-to-end way.
Recently, pre-trained language models have also been applied to end-to-end solutions for task-oriented dialogue systems <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2020tod</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lin2021knowledge</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">10.1145/3477495.3532069</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS2.p12">
<p class="ltx_p" id="Ch7.S2.SS2.p12.1">In contrast with other types of dialogue systems, evaluation metrics in task-oriented dialogue systems need to consider specific metrics in the experiments:
<em class="ltx_emph ltx_font_italic" id="Ch7.S2.SS2.p12.1.1">Entity match rate</em> evaluates task completion. According to <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2017network</span></cite>, it determines if a system can generate all correct constraints to search the indicated user entities of the user. This metric is either 0 or 1 for each dialogue.
The original <em class="ltx_emph ltx_font_italic" id="Ch7.S2.SS2.p12.1.2">success rate</em> metric measures if the system answered all the requested
information (e.g., address, phone number) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wen2015stochastic</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">mrkvsic2015multi</span>]</cite>. However, this metric only evaluates recall.
As a variant, <em class="ltx_emph ltx_font_italic" id="Ch7.S2.SS2.p12.1.3">Success F1</em> evaluates task completion and is modified from the success rate by balancing both recall and precision <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lei2018sequicity</span>]</cite>.
Automatic user satisfaction received attention in task-oriented dialogues.
User simulation is a promising approach to evaluating dialogue systems at scale in task-oriented dialogue scenarios <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2020evaluating</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">sunzhang2021simulator</span></cite> formulate the task of simulating user satisfaction for evaluating task-oriented dialogue systems to enhance the evaluation of dialogue systems. The authors also shared a dataset about user satisfaction simulation.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">kim2022mismatch</span></cite> proposed the relative slot accuracy metric in DST evaluation, which is not affected by unseen slots in the current dialogue turn.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch7.S2.SS3">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2.3 </span>Knowledge-grounded dialogue systems</h4>
<div class="ltx_para" id="Ch7.S2.SS3.p1">
<p class="ltx_p" id="Ch7.S2.SS3.p1.1">Although answering inquiries is essential for dialogue systems, especially for task-oriented dialogue systems, it is still far behind a natural knowledge-grounded dialogue system, which should be able to understand the facts involved in the current dialogue session (so-called facts matching) and diffuse them to other similar entities for knowledge-based dialogues (i.e., entity diffusion):</p>
<ol class="ltx_enumerate" id="Ch7.S2.I2">
<li class="ltx_item" id="Ch7.S2.I2.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(1)</span>
<div class="ltx_para" id="Ch7.S2.I2.i1.p1">
<p class="ltx_p" id="Ch7.S2.I2.i1.p1.1"><span class="ltx_text ltx_font_italic" id="Ch7.S2.I2.i1.p1.1.1">Facts matching</span>: In dialogue systems, matching utterances to exact facts is much harder than explicit factoid inquiries answering.
Though some utterances, whose subjects and relations can be easily recognized, are fact-related inquiries for some utterances, the subjects and relations are elusive, leading to trouble matching exact facts.
Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.T1" title="Table 7.1 ‣ 7.2.3 Knowledge-grounded dialogue systems ‣ 7.2 Dialogue systems in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.1</span></a> shows an example of Items 1 and 2 talking about the film “Titanic”. Unlike item 1, which is a typical question-answering conversation, item 2 is a knowledge-related chit-chat without any explicit relation. It is difficult to define the exact fact match for item 2.</p>
</div>
</li>
<li class="ltx_item" id="Ch7.S2.I2.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">(2)</span>
<div class="ltx_para" id="Ch7.S2.I2.i2.p1">
<p class="ltx_p" id="Ch7.S2.I2.i2.p1.1"><span class="ltx_text ltx_font_italic" id="Ch7.S2.I2.i2.p1.1.1">Entity diffusion</span>: Another noticeable phenomenon is that the conversation usually drifts from one entity to another.
In Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.T1" title="Table 7.1 ‣ 7.2.3 Knowledge-grounded dialogue systems ‣ 7.2 Dialogue systems in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.1</span></a>, utterances in items 3 and 4 are about the entity “Titanic.” However, the entity of responses is other similar films.
The current knowledge triplets rarely capture such entity diffusion relations.
The response in item 3 shows that the two entities, “Titanic” and “Waterloo Bridge”, are relevant through “love stories”. Item 4 suggests another similar shipwreck film “Titanic”.</p>
</div>
</li>
</ol>
</div>
<div class="ltx_para ltx_noindent" id="Ch7.S2.SS3.p2">
<p class="ltx_p" id="Ch7.S2.SS3.p2.1">Knowledge-grounded dialogue (KGD) systems are proposed to address the aforementioned challenges.
According to the knowledge modality, existing works for knowledge-grounded dialogue systems can be mainly categorized into two groups.
The methods in the first group aims to leverage <span class="ltx_text ltx_font_italic" id="Ch7.S2.SS3.p2.1.1">structured knowledge</span> (given knowledge graphs) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2020diverse</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou-etal-2020-kdconv</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2020improving</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2020improving</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">xu2020knowledge</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">xu2020conversational</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">jung2020attnio</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">tuan2019dykgchat</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2019proactive</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">moon2019opendialkg</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2018commonsense</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2018knowledge</span>]</cite>; while the ones in the second group focus on leveraging <span class="ltx_text ltx_font_italic" id="Ch7.S2.SS3.p2.1.2">unstructured knowledge</span>, such as <span class="ltx_text ltx_font_italic" id="Ch7.S2.SS3.p2.1.3">document-based unstructured knowledge</span> (given a whole document, e.g. Wikipedia article) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chuanmeng2020refnet</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ma2020survey</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ma2020compare</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">tian-etal-2020-response</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">ren2019thinking</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">gopalakrishnan2019topical</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zekangli2018incremental</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">qin-etal-2019-conversing</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">moghe2018towards</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2018dataset</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">parthasarathi2018extending</span>]</cite> or <span class="ltx_text ltx_font_italic" id="Ch7.S2.SS3.p2.1.4">piece-based unstructured knowledge</span> (given some separate pieces of knowledge, e.g. Foursquare tips) <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ghazvininejad2018knowledge</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">dinan2018wizard</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">meng2020dukenet</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kim2020sequential</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Lian2019Learning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zheng2020difference</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2020bridging</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zheng2020approximation</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2020knowledge</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zheng2019enhancing</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lin-etal-2020-generating</span>]</cite>.
There are key research directions for both groups:

<span class="ltx_inline-enumerate" id="Ch7.S2.I3">
<span class="ltx_inline-item" id="Ch7.S2.I3.i1"><span class="ltx_tag ltx_tag_inline-item">1.</span> <span class="ltx_text" id="Ch7.S2.I3.i1.1">improving knowledge selection <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">kim2020sequential</span>]</cite>;
</span></span>
<span class="ltx_inline-item" id="Ch7.S2.I3.i2"><span class="ltx_tag ltx_tag_inline-item">2.</span> <span class="ltx_text" id="Ch7.S2.I3.i2.1">improving knowledge-aware response generation <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2020knowledge</span>]</cite> or response selection <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">young2018augmenting</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2019document</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hua2020learning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2020history</span>]</cite>;
that is, given the chosen knowledge, how to better generate a response token by token or select a response from pre-defined response candidates;
</span></span>
<span class="ltx_inline-item" id="Ch7.S2.I3.i3"><span class="ltx_tag ltx_tag_inline-item">3.</span> <span class="ltx_text" id="Ch7.S2.I3.i3.1">leveraging multiple knowledge modalities <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2019knowledge</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2020multiple</span>]</cite>;
that is, how to utilize structured, unstructured, and even other types of knowledge simultaneously;
</span></span>
<span class="ltx_inline-item" id="Ch7.S2.I3.i4"><span class="ltx_tag ltx_tag_inline-item">4.</span> <span class="ltx_text" id="Ch7.S2.I3.i4.1">overcoming data scarcity <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2019low</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2020zero</span>]</cite>.
</span></span>
</span></p>
</div>
<figure class="ltx_table" id="Ch7.T1">
<table class="ltx_tabular ltx_centering ltx_align_middle" id="Ch7.T1.1">
<tr class="ltx_tr" id="Ch7.T1.1.1">
<td class="ltx_td ltx_align_center ltx_border_tt" id="Ch7.T1.1.1.1"><span class="ltx_text ltx_font_bold" id="Ch7.T1.1.1.1.1" style="font-size:90%;">ID</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="Ch7.T1.1.1.2"><span class="ltx_text ltx_font_bold" id="Ch7.T1.1.1.2.1" style="font-size:90%;">Dialogue</span></td>
</tr>
<tr class="ltx_tr" id="Ch7.T1.1.2">
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch7.T1.1.2.1" rowspan="4"><span class="ltx_text" id="Ch7.T1.1.2.1.1" style="font-size:90%;">1</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch7.T1.1.2.2">
<span class="ltx_text" id="Ch7.T1.1.2.2.1" style="font-size:90%;">A: Who is the director of the </span><span class="ltx_text ltx_framed ltx_framed_underline" id="Ch7.T1.1.2.2.2" style="font-size:90%;">Titanic</span><span class="ltx_text" id="Ch7.T1.1.2.2.3" style="font-size:90%;">?</span>
</td>
</tr>
<tr class="ltx_tr" id="Ch7.T1.1.3">
<td class="ltx_td ltx_align_center" id="Ch7.T1.1.3.1">
<span class="ltx_ERROR undefined" id="Ch7.T1.1.3.1.1">{CJK}</span><span class="ltx_text" id="Ch7.T1.1.3.1.2" style="font-size:90%;">UTF8gkai</span><span class="ltx_text ltx_framed ltx_framed_underline" id="Ch7.T1.1.3.1.3" style="font-size:90%;">泰坦尼克号</span><span class="ltx_text" id="Ch7.T1.1.3.1.4" style="font-size:90%;">的导演是谁？</span>
</td>
</tr>
<tr class="ltx_tr" id="Ch7.T1.1.4">
<td class="ltx_td ltx_align_center" id="Ch7.T1.1.4.1">
<span class="ltx_text" id="Ch7.T1.1.4.1.1" style="font-size:90%;">B: </span><span class="ltx_text ltx_framed ltx_framed_underline" id="Ch7.T1.1.4.1.2" style="font-size:90%;">James Cameron</span><span class="ltx_text" id="Ch7.T1.1.4.1.3" style="font-size:90%;">.</span>
</td>
</tr>
<tr class="ltx_tr" id="Ch7.T1.1.5">
<td class="ltx_td ltx_align_center" id="Ch7.T1.1.5.1">
<span class="ltx_ERROR undefined" id="Ch7.T1.1.5.1.1">{CJK}</span><span class="ltx_text" id="Ch7.T1.1.5.1.2" style="font-size:90%;">UTF8gkai</span><span class="ltx_text ltx_framed ltx_framed_underline" id="Ch7.T1.1.5.1.3" style="font-size:90%;">詹姆斯卡梅隆</span><span class="ltx_text" id="Ch7.T1.1.5.1.4" style="font-size:90%;">。</span>
</td>
</tr>
<tr class="ltx_tr" id="Ch7.T1.1.6">
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch7.T1.1.6.1" rowspan="4"><span class="ltx_text" id="Ch7.T1.1.6.1.1" style="font-size:90%;">2</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch7.T1.1.6.2">
<span class="ltx_text" id="Ch7.T1.1.6.2.1" style="font-size:90%;">A: </span><span class="ltx_text ltx_framed ltx_framed_underline" id="Ch7.T1.1.6.2.2" style="font-size:90%;">Titanic</span><span class="ltx_text" id="Ch7.T1.1.6.2.3" style="font-size:90%;"> is my favorite film!</span>
</td>
</tr>
<tr class="ltx_tr" id="Ch7.T1.1.7">
<td class="ltx_td ltx_align_center" id="Ch7.T1.1.7.1">
<span class="ltx_ERROR undefined" id="Ch7.T1.1.7.1.1">{CJK}</span><span class="ltx_text" id="Ch7.T1.1.7.1.2" style="font-size:90%;">UTF8gkai</span><span class="ltx_text ltx_framed ltx_framed_underline" id="Ch7.T1.1.7.1.3" style="font-size:90%;">泰坦尼克号</span><span class="ltx_text" id="Ch7.T1.1.7.1.4" style="font-size:90%;">是我最爱的电影！</span>
</td>
</tr>
<tr class="ltx_tr" id="Ch7.T1.1.8">
<td class="ltx_td ltx_align_center" id="Ch7.T1.1.8.1"><span class="ltx_text" id="Ch7.T1.1.8.1.1" style="font-size:90%;">B: The love inside it is so touching.</span></td>
</tr>
<tr class="ltx_tr" id="Ch7.T1.1.9">
<td class="ltx_td ltx_align_center" id="Ch7.T1.1.9.1">
<span class="ltx_ERROR undefined" id="Ch7.T1.1.9.1.1">{CJK}</span><span class="ltx_text" id="Ch7.T1.1.9.1.2" style="font-size:90%;">UTF8gkai里面的爱情太感人了。</span>
</td>
</tr>
<tr class="ltx_tr" id="Ch7.T1.1.10">
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch7.T1.1.10.1" rowspan="5"><span class="ltx_text" id="Ch7.T1.1.10.1.1" style="font-size:90%;">3</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch7.T1.1.10.2">
<span class="ltx_text" id="Ch7.T1.1.10.2.1" style="font-size:90%;">A: Is there anything like the </span><span class="ltx_text ltx_framed ltx_framed_underline" id="Ch7.T1.1.10.2.2" style="font-size:90%;">Titanic</span><span class="ltx_text" id="Ch7.T1.1.10.2.3" style="font-size:90%;">?</span>
</td>
</tr>
<tr class="ltx_tr" id="Ch7.T1.1.11">
<td class="ltx_td ltx_align_center" id="Ch7.T1.1.11.1">
<span class="ltx_ERROR undefined" id="Ch7.T1.1.11.1.1">{CJK}</span><span class="ltx_text" id="Ch7.T1.1.11.1.2" style="font-size:90%;">UTF8gkai有什么像</span><span class="ltx_text ltx_framed ltx_framed_underline" id="Ch7.T1.1.11.1.3" style="font-size:90%;">泰坦尼克号</span><span class="ltx_text" id="Ch7.T1.1.11.1.4" style="font-size:90%;">一样的电影吗？</span>
</td>
</tr>
<tr class="ltx_tr" id="Ch7.T1.1.12">
<td class="ltx_td ltx_align_center" id="Ch7.T1.1.12.1">
<span class="ltx_text" id="Ch7.T1.1.12.1.1" style="font-size:90%;">B: I think the love story in film </span><span class="ltx_text ltx_framed ltx_framed_underline" id="Ch7.T1.1.12.1.2" style="font-size:90%;">Waterloo</span>
</td>
</tr>
<tr class="ltx_tr" id="Ch7.T1.1.13">
<td class="ltx_td ltx_align_center" id="Ch7.T1.1.13.1">
<span class="ltx_text ltx_framed ltx_framed_underline" id="Ch7.T1.1.13.1.1" style="font-size:90%;">Bridge</span><span class="ltx_text" id="Ch7.T1.1.13.1.2" style="font-size:90%;"> is beautiful, too.</span>
</td>
</tr>
<tr class="ltx_tr" id="Ch7.T1.1.14">
<td class="ltx_td ltx_align_center" id="Ch7.T1.1.14.1">
<span class="ltx_ERROR undefined" id="Ch7.T1.1.14.1.1">{CJK}</span><span class="ltx_text" id="Ch7.T1.1.14.1.2" style="font-size:90%;">UTF8gkai我觉得</span><span class="ltx_text ltx_framed ltx_framed_underline" id="Ch7.T1.1.14.1.3" style="font-size:90%;">魂断蓝桥</span><span class="ltx_text" id="Ch7.T1.1.14.1.4" style="font-size:90%;">中的爱情故事也很美。</span>
</td>
</tr>
<tr class="ltx_tr" id="Ch7.T1.1.15">
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="Ch7.T1.1.15.1" rowspan="4"><span class="ltx_text" id="Ch7.T1.1.15.1.1" style="font-size:90%;">4</span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="Ch7.T1.1.15.2">
<span class="ltx_text" id="Ch7.T1.1.15.2.1" style="font-size:90%;">A: Is there anything like the </span><span class="ltx_text ltx_framed ltx_framed_underline" id="Ch7.T1.1.15.2.2" style="font-size:90%;">Titanic</span><span class="ltx_text" id="Ch7.T1.1.15.2.3" style="font-size:90%;">?</span>
</td>
</tr>
<tr class="ltx_tr" id="Ch7.T1.1.16">
<td class="ltx_td ltx_align_center" id="Ch7.T1.1.16.1">
<span class="ltx_ERROR undefined" id="Ch7.T1.1.16.1.1">{CJK}</span><span class="ltx_text" id="Ch7.T1.1.16.1.2" style="font-size:90%;">UTF8gkai有什么像</span><span class="ltx_text ltx_framed ltx_framed_underline" id="Ch7.T1.1.16.1.3" style="font-size:90%;">泰坦尼克号</span><span class="ltx_text" id="Ch7.T1.1.16.1.4" style="font-size:90%;">一样的电影吗？</span>
</td>
</tr>
<tr class="ltx_tr" id="Ch7.T1.1.17">
<td class="ltx_td ltx_align_center" id="Ch7.T1.1.17.1">
<span class="ltx_text" id="Ch7.T1.1.17.1.1" style="font-size:90%;">B: </span><span class="ltx_text ltx_framed ltx_framed_underline" id="Ch7.T1.1.17.1.2" style="font-size:90%;">Poseidon</span><span class="ltx_text" id="Ch7.T1.1.17.1.3" style="font-size:90%;"> is also a classic marine film.</span>
</td>
</tr>
<tr class="ltx_tr" id="Ch7.T1.1.18">
<td class="ltx_td ltx_align_center ltx_border_bb" id="Ch7.T1.1.18.1">
<span class="ltx_ERROR undefined" id="Ch7.T1.1.18.1.1">{CJK}</span><span class="ltx_text" id="Ch7.T1.1.18.1.2" style="font-size:90%;">UTF8gkai</span><span class="ltx_text ltx_framed ltx_framed_underline" id="Ch7.T1.1.18.1.3" style="font-size:90%;">海神号</span><span class="ltx_text" id="Ch7.T1.1.18.1.4" style="font-size:90%;">也是一部经典的海难电影。</span>
</td>
</tr>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7.1: </span> Examples of knowledge grounded conversations. Knowledge entities are underlined. Image source: <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2018knowledge</span>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="Ch7.S2.SS3.p3">
<p class="ltx_p" id="Ch7.S2.SS3.p3.1">The neural knowledge diffusion (NKD) model introduces knowledge into the dialogue generation. This method can match the relevant facts for the input utterance and diffuse them to similar entities <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2018knowledge</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS3.p4">
<p class="ltx_p" id="Ch7.S2.SS3.p4.1">Early studies on knowledge selection in KGD calculated the weight of each piece of knowledge and got the weighted sum of their representations <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ghazvininejad2018knowledge</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zheng2019enhancing</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lin-etal-2020-generating</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zheng2020approximation</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">bordes2016learning</span></cite> employed memory networks to handle restaurant reservations, using a small number of keywords to handle entity types in a knowledge base (cuisine type, location, price range, party size, rating, phone number, and address).
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ghazvininejad2017knowledge</span></cite> adapt it to memorize the relevant, grounded facts for a neural conversation model.
The hierarchical variational memory network (HVMN) adds the hierarchical structure and the variational memory network into a neural encoder-decoder network for non-task-oriented dialogue generation <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ziwwsdm1</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS3.p5">
<p class="ltx_p" id="Ch7.S2.SS3.p5.1">Several recent studies on knowledge selection focused on calculating a weight on each piece of knowledge and then directly sampling the amount of knowledge with the highest weight.
Specifically, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">dinan2018wizard</span></cite> proposed the TMemNet model that uses context to predict a distribution over pieces of knowledge and then only sample one of them into a decoder.
They also introduced a knowledge selection loss to supervise knowledge selection during training.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">Lian2019Learning</span></cite> proposed PostKS, which uses a context to predict a prior distribution over pieces of knowledge.
During training, the prior distribution is supervised by a posterior distribution predicted by the context and the corresponding response.
Similar to PostKS, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zheng2020approximation</span></cite> proposed to use a context and a piece of knowledge retrieved by the context to predict a distribution over fragments of knowledge, where the probability of the amount of knowledge retrieved by the corresponding response is maximized during training.
The former distills a context containing multiple utterances at different turns into a vector that is used to match with the representation of a piece of knowledge to get a score, while the latter matches every utterance in a context with a piece of knowledge to get matching features that are aggregated to get a score.
A piece of knowledge is chosen based on the score list for all pieces of knowledge.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">kim2020sequential</span></cite> proposed a sequential knowledge transformer (SKT), which jointly uses previously selected knowledge and context to facilitate knowledge selection.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2020bridging</span></cite> upgraded SKT by adding the knowledge distillation-based training strategy to improve knowledge selection.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zheng2020difference</span></cite> proposed a method that introduces the difference information between the previously selected knowledge and the current pieces of candidate knowledge to facilitate knowledge selection.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">meng2020dukenet</span></cite> proposed DukeNet, which regards tracking the previously selected knowledge and selecting the current knowledge as dual tasks within a dual learning paradigm <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">qin2020dual</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2020knowledge</span></cite> proposed an RLKS method, where the selected knowledge is sent to a decoder to generate a response that would be compared with the ground truth response to give feedback to further supervised knowledge selection.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">meng2021initiative</span></cite> proposed a mixed-initiative knowledge selection method for KGC, which explicitly distinguishes between user-initiative and system-initiative knowledge selection at each conversation turn to improve the performance of knowledge selection.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2021conversations</span></cite> find that the amount of knowledge available in different languages is highly imbalanced. Hence the authors proposed the cross-lingual knowledge grounded conversation with a self-distillation knowledge selection and curriculum learning.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS3.p6">
<p class="ltx_p" id="Ch7.S2.SS3.p6.1">Recent years have witnessed a rapid development of pre-trained language models in open-domain dialogue systems.
Large pre-trained language models can store knowledge into their parameters during pre-training and can generate informative responses in conversations <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Zhao2020ArePL</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">Petroni2019LanguageMA</span></cite> have shown that pre-trained language models can serve as knowledge bases for downstream tasks (e.g., question-answering <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Roberts2020HowMK</span>]</cite>).
On this basis, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">Zhao2020ArePL</span></cite> have shown that pre-trained language models can ground open-domain dialogues using their implicit knowledge.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">madotto2020learning</span></cite> embeded knowledge bases into model’s parameters for end-to-end task-oriented dialogues.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">Roller2021RecipesFB</span></cite> fine-tuned pre-trained language models on KGD data.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">Cui2021KnowledgeEF</span></cite> proposed knowledge-enhanced fine-tuning methods to handle unseen entities.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">Xu2021RetrievalFreeKD</span></cite> proposed a topic-aware adapter to adapt pre-trained language models in KGDs.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">Liu2022MultiStagePF</span></cite> proposed a multi-stage prompting approach for triggering knowledge in pre-trained language models.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">Wu2022LexicalKI</span></cite> proposed lexical knowledge internalization to integrate token-level knowledge into the model’s parameters.
The problem of hallucination is becoming more and more challenging.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2023contrastive</span></cite> optimized the implicit knowledge eliciting process, i.e., reduce hallucination of pre-trained language models in KGD, via a contrastive learning framework.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch7.S2.SS4">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2.4 </span>Empathetic dialogue generation</h4>
<div class="ltx_para" id="Ch7.S2.SS4.p1">
<p class="ltx_p" id="Ch7.S2.SS4.p1.1">With the rise of data-driven learning approaches <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">SutskeverVL14</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">vaswani2017attention</span>]</cite>, open-domain dialogue generation models have seen increasing interest in recent years <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">vinyals2015neural</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">shang</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">SerbanLCP16</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">limrjgg16</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2018commonsense</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">dinan2018wizard</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS4.p2">
<p class="ltx_p" id="Ch7.S2.SS4.p2.1">Recent approaches generate emotional responses conditioning based on a manually specified label to control the dynamic content of the target output <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2018emotional</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lis18</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2018mojitalk</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">huang2018automatic</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wei2019emotion</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">colombo2019affect</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">shenf20</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS4.p3">
<p class="ltx_p" id="Ch7.S2.SS4.p3.1">To control the emotional content of the target output, recent approaches generate emotional responses conditioning on a manually specified label <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2018emotional</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lis18</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2018mojitalk</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">huang2018automatic</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">wei2019emotion</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">colombo2019affect</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">shenf20</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS4.p4">
<p class="ltx_p" id="Ch7.S2.SS4.p4.1">Unlike emotional dialogue generation, the study of empathetic dialogue generation avoids an additional step of determining which emotion type to respond to explicitly <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">skowron2013affect</span>]</cite>.
Several studies <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Rashkin18</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhong2019affect</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Shin19</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">rashkin2019towards</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">santhanam19</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">linmsxf19</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">lin2020caire</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhong2020</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">MajumderHPLGGMP20</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">li2020empdg</span>]</cite> have attempted to make dialogue models more empathetic.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">rashkin2019towards</span></cite> combined existing models in different ways to produce empathetic responses.
While <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">linmsxf19</span></cite> softly combined the possible emotional responses from several separate experts.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">MajumderHPLGGMP20</span></cite> considered of this polarity-based emotion clusters and emotional mimicry.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">li2020empdg</span></cite> proposed a multi-resolution adversarial framework that considers multi-granularity emotion factors and users’ feedback.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">li2020empathetic</span></cite> investigated how to leverage external knowledge to explicitly improve the emotional understanding and expression in the task of empathetic dialogue generation.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">sabour2022cem</span></cite> focused on two aspects in empathetic dialogue generation: affection and cognition. The authors proposed a method with various
commonsense reasoning to improve understanding of interlocutors’ situations and feelings.</p>
</div>
<div class="ltx_para" id="Ch7.S2.SS4.p5">
<p class="ltx_p" id="Ch7.S2.SS4.p5.1">Besides the advancements in empathetic dialogue models, the emergence of new emotion-labeled dialogue corpora has also contributed to this research field <cite class="ltx_cite ltx_citemacro_cite">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2017dailydialog</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">hsuckhk18</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">rashkin2019towards</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citeauthor"><span class="ltx_ref ltx_missing_citation ltx_ref_self">rashkin2019towards</span></cite> considered a more prosperous and evenly distributed set of emotions and released a dataset <span class="ltx_text ltx_font_smallcaps" id="Ch7.S2.SS4.p5.1.1">EmpatheticDialogues</span>, where a listener responds to a speaker in an emotional situation in an empathetic way.</p>
</div>
</section>
</section>
<section class="ltx_section" id="Ch7.S3">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7.3 </span>Emerging directions</h3>
<div class="ltx_para" id="Ch7.S3.p1">
<p class="ltx_p" id="Ch7.S3.p1.1">This section describes recent emerging directions on question-answering and dialogue systems in e-commerce. These emerging directions on QA and dialogue systems can be divided into <math alttext="5" class="ltx_Math" display="inline" id="Ch7.S3.p1.1.m1.1"><semantics id="Ch7.S3.p1.1.m1.1a"><mn id="Ch7.S3.p1.1.m1.1.1" xref="Ch7.S3.p1.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="Ch7.S3.p1.1.m1.1b"><cn id="Ch7.S3.p1.1.m1.1.1.cmml" type="integer" xref="Ch7.S3.p1.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="Ch7.S3.p1.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="Ch7.S3.p1.1.m1.1d">5</annotation></semantics></math> perspectives: safety, ethics, interpretability, privacy, and evaluation.</p>
</div>
<div class="ltx_para" id="Ch7.S3.p2">
<p class="ltx_p" id="Ch7.S3.p2.1">As discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S1" title="7.1 Question answering in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.1</span></a>, e-commerce QA agents aim to answer these questions through massive reviews.
However, reviews may not answer these questions as they may not contain any relevant answers for the question, or a query may be poorly phrased and therefore requires additional clarification.
Moreover, untruthful comments and spams are also widely observed in e-commerce reviews.
These answers or reviews may attribute to multiple factors such as misunderstandings of the question, improper expressions during writing, and even malicious attacks from the competitors <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">carmel2018product</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">mihaylova2019semeval</span></cite> investigated the fact-checking problem in a QA scenario with a system to classify the veracity of answers.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2020answerfact</span></cite> released a large-scale fact-checking dataset called AnswerFact for investigating the answer veracity in e-commerce QA.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">estes2022fact</span></cite> developed a high-speed fact-verification system that has a very high false statement recall and very high true statement precision to product question-answering.
However, the authors still applied a rule-based method in their system, and found that pre-trained language models are still unable to perform fact-checking well on the e-commerce structured catalog data.
As limitations such as poor generalization exist in rule-based methods, how to optimize pre-trained language models in fact-checking for product question-answering still needs more attention in future research.
</p>
</div>
<div class="ltx_para" id="Ch7.S3.p3">
<p class="ltx_p" id="Ch7.S3.p3.1">In dialogue systems, ethical challenges have been becoming more and more severe in recent years. Currently, most dialogue systems are developed from scratch with large corpora or fine-tuned through pre-trained language models. Large-scale datasets collected from the open Internet have been applied during model training. However, offensive and malevolent content can be observed in the data <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">si2022so</span>]</cite>.
To avoid being unintentionally offensive or harming the user, research studies have been performed to detect toxic speech around religion, race, and violence <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">tripathi2019detecting</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">dinan2020queens</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2021human</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">kann2022open</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">si2022so</span>]</cite>.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2021human</span></cite> proposed a human-machine collaborative evaluation framework for reliable toxic speech detection in dialogue systems.
Note that <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">si2022so</span></cite> studied toxic speech in open-domain dialogue systems to reveal that specific kinds of “non-toxic” queries are able to trigger an open-domain conversation artificial intelligence to output toxic responses.
However, how to respond when these malevolence topics are being identified is still an open question for conversational artificial intelligence <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">kann2022open</span>]</cite>.
As more and more e-commerce dialogue systems have also been trained based on pre-trained language models, ethical challenges will still need to be tackled in future research.</p>
</div>
<div class="ltx_para" id="Ch7.S3.p4">
<p class="ltx_p" id="Ch7.S3.p4.1">Poor explainability is a challenging problem for most e-commerce QA approaches.
Most existing e-commerce QA approaches apply end-to-end semantic matching methodologies, which tend to be black-box and directly output a matching score for each question answer pair.
<cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2019riker</span></cite> address the explainable QA problem through a hybrid retrieval-based framework.
The authors employ a bidirectional recurrent neural network in the internal word representation stage and apply a keyword-aware retrieval method during the second stage. In contrast, the tf-idf ranking function naturally exhibits much better interpretability owing to its transparency and intuitiveness.
The conversational recommendation is another typical application of e-commerce dialogue systems <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2016conversational</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">mangili2020bayesian</span>]</cite>.
Most approaches neglect explainability during the recommendation action learning procedure. As the first attempt, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2020towards</span></cite> propose an incremental multi-task learning framework using user feedback for the task of explainable conversational recommendation.
By considering user preferences as latent variables in a variational Bayesian manner, <cite class="ltx_cite ltx_citemacro_citet"><span class="ltx_ref ltx_missing_citation ltx_ref_self">ren2022variational</span></cite> employed a variational reasoning method to estimate explicit user preferences during the dialogue.</p>
</div>
<div class="ltx_para" id="Ch7.S3.p5">
<p class="ltx_p" id="Ch7.S3.p5.1">Privacy protection has received more and more attention in dialogue systems <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">papernot2016semi</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">henderson2018ethical</span>]</cite>.
For many task-oriented dialogue systems, it is necessary to notice that we are using the same dialogue assistant.
Recent studies on membership inference attacks have confirmed that privacy information in training data for sequence-to-sequence generative models and pre-trained language models can be attacked <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">hisamoto2020membership</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2021encodermi</span>]</cite>.
As we discussed in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S2" title="7.2 Dialogue systems in e-commerce ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.2</span></a>, most existing e-commerce dialogue system models are designed based on sequence-to-sequence generative neural networks and pre-trained language models.
By learning through interactions and communications, a dialogue assistant can inadvertently and implicitly store some sensitive information.
Hence consumers’ privacy information may get obtained by attackers through membership inference attacks.
To address this problem, developing privacy-aware dialogue systems will attract increasing attention in the future.</p>
</div>
<div class="ltx_para" id="Ch7.S3.p6">
<p class="ltx_p" id="Ch7.S3.p6.1">The evaluation of e-commerce dialogue systems is a crucial part of the development process.
Recent studies on evaluating dialogue systems are either through offline evaluation or human evaluation <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Lamel2000TheLA</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">Jurccek2011RealUE</span>]</cite>.
Offline evaluation is often limited to single-turn assessments, while human evaluation is intrusive, time-intensive, and does not scale <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Deriu2020SurveyOE</span>]</cite>.
User simulators have been applied to exhaustively enumerate user goals to generate human-like conversations for simulated evaluation <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Zhang2020RecentAA</span>]</cite>.
However, user simulators as evaluation methods for e-commerce dialogue systems are still under-explored.
Employing existing simulators suffers from limited realism and evaluation capability, whereas there is a lack of automatic methods to assess user simulators’ realism and evaluation capabilities <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">Balog2021Sim4IRTS</span>]</cite>.
Moreover, evaluation metrics of e-commerce aspects are still unexploited in existing e-commerce dialogue agents.
Evaluation metrics in e-commerce search and recommendation scenarios can provide more insights for future work.</p>
</div>
</section>
</section>
<section class="ltx_chapter" id="Ch8" lang="en">
<h2 class="ltx_title ltx_title_chapter">
<span class="ltx_tag ltx_tag_chapter">Chapter 8 </span>Conclusion and outlook</h2>
<div class="ltx_para" id="Ch8.p1">
<p class="ltx_p" id="Ch8.p1.1">We briefly summarize the main topics presented in this survey in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch8.S1" title="8.1 Conclusion ‣ Chapter 8 Conclusion and outlook ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">8.1</span></a>.
In Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch8.S2" title="8.2 Outlook ‣ Chapter 8 Conclusion and outlook ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">8.2</span></a>, we describe our outlook on future developments.</p>
</div>
<section class="ltx_section" id="Ch8.S1">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8.1 </span>Conclusion</h3>
<div class="ltx_para" id="Ch8.S1.p1">
<p class="ltx_p" id="Ch8.S1.p1.1">From the large number of user engagements on e-commerce platforms a large amount of information can be inferred.
Information discovery has increasingly been attracting attention from information retrieval community.
The aim of this survey has been to give a broad overview of information discovery in e-commerce portals.
Our overview has included methods about user behavior modeling, search, recommendation, question answering, and dialogue systems in e-commerce.</p>
</div>
<div class="ltx_para" id="Ch8.S1.p2">
<p class="ltx_p" id="Ch8.S1.p2.1">Our strategy with this survey has been to provide a broad coverage of research directions about information discovery in e-commerce.
Although we have tried our best to provide all key approaches in each direction as much as possible, the amount of technical details is limited.
For areas that are broad enough to have their own survey, we only focus on key publications and provide structure and pipelines for each direction.
Additionally, we only focus on areas that are relevant to information retrieval research; studies in other areas relevant to e-commerce, such as supply chains and computational advertising, are ignored in this survey.</p>
</div>
<div class="ltx_para" id="Ch8.S1.p3">
<p class="ltx_p" id="Ch8.S1.p3.1">We have briefly presented information discovery research in e-commerce scenarios.
In the introduction, we summarized the outline and topics covered in this survey, followed by a chapter with basic concepts and key definitions in Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch2" title="Chapter 2 Definitions and background ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">2</span></a>.
Then we introduced preliminaries about e-commerce interfaces and users in Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3" title="Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3</span></a>. We formulated concepts of e-commerce infrastructures and summarized studies about information seeking via e-commerce interfaces in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch3.S1" title="3.1 E-commerce presentations ‣ Chapter 3 E-commerce presentations and users ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">3.1</span></a>.
We investigated e-commerce information components, i.e., titles, product descriptions, and reviews, and detailed characteristics of consumer behaviors in e-commerce portals.
We introduced studies into e-commerce user analyses concerning multiple behaviors, including clicks, purchases, engagements, and post-clicks, on e-commerce platforms.</p>
</div>
<div class="ltx_para" id="Ch8.S1.p4">
<p class="ltx_p" id="Ch8.S1.p4.1">The core of this survey is organized around five directions: e-commerce user modeling, e-commerce search, e-commerce recommendation, e-commerce QA, and e-commerce dialogue systems. We have detailed each of these in four chapters (i.e., Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4" title="Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5" title="Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5</span></a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6" title="Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6</span></a>, and <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7" title="Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7</span></a>).
Each chapter starts with an overview of the main direction discussed in the chapter, with characteristics and subtasks.
After that, key research studies of each subtasks were demonstrated with some level of detail.
We discussed emerging research directions at the end of each key component.</p>
</div>
<div class="ltx_para" id="Ch8.S1.p5">
<p class="ltx_p" id="Ch8.S1.p5.1">In particular, in Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch4" title="Chapter 4 E-commerce user modeling ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">4</span></a>, we introduced approaches to user modeling and profiling for e-commerce applications.
We divided this chapter into two main components: user behavior modeling and user profiling.
We provided a summary of studies on modeling these e-commerce user behavior, analyzed research on user profiling in e-commerce, and discussed emerging directions on user modeling in e-commerce.</p>
</div>
<div class="ltx_para" id="Ch8.S1.p6">
<p class="ltx_p" id="Ch8.S1.p6.1">In Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5" title="Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5</span></a>, we focused on search technologies in e-commerce platforms.
We provided the characteristics of e-commerce search and divided research studies based on matching strategies and ranking technologies for e-commerce search scenarios, respectively.
We presented approaches aiming for studying matching strategies for e-commerce search.
And we studied research approaches on ranking technologies for e-commerce search.
Emerging research directions were discussed at the end of the chapter.</p>
</div>
<div class="ltx_para" id="Ch8.S1.p7">
<p class="ltx_p" id="Ch8.S1.p7.1">In Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6" title="Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6</span></a>, we introduced the most prominent approaches on e-commerce recommendation methods.
We summarized the key characteristics of e-commerce recommendation, towards which a two-stage framework was developed that contains candidate retrieval and candidate ranking, forming the mainstream solution for e-commerce recommender systems. We reviewed models developed for the two stages and detailed mainstream learning methods for optimizing model parameters to provide a complete view of e-commerce recommender systems.</p>
</div>
<div class="ltx_para" id="Ch8.S1.p8">
<p class="ltx_p" id="Ch8.S1.p8.1">Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7" title="Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7</span></a> detailed research methods for question answering and dialogue systems in e-commerce.
We merged question answering and dialogue systems into a single chapter as most research background and approaches are shared in these two directions.
We reviewed previous work on question answering and then demonstrated the characteristics of e-commerce QA.
For e-commerce question answering (QA), we described studies both on extractive QA and generative QA..
For e-commerce dialogue systems, we demonstrated the patterns of e-commerce dialogue systems, especially about task-oriented dialogue systems, knowledge-grounded conversations, and empathetic dialogue systems.
We discussed emerging research directions around QA and dialogue agents in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7.S3" title="7.3 Emerging directions ‣ Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7.3</span></a>.</p>
</div>
</section>
<section class="ltx_section" id="Ch8.S2">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8.2 </span>Outlook</h3>
<div class="ltx_para" id="Ch8.S2.p1">
<p class="ltx_p" id="Ch8.S2.p1.1">Information discovery is increasingly a mixed initiative scenario, where users and e-commerce platforms take turns.
As described in the previous chapters, the research presented on information discovery in e-commerce has been addressed from six angles: infrastructures, user modeling, search, recommendation, QA, and dialogue systems.
As we summarized at the end of each chapter, a broad variety of emerging research has also been motivated following each angle.
For user modeling, we consider three research topics as emerging directions on user modeling and profiling: graph learning for user behavior modeling, dynamic user behavior modeling and profiling, and multi-modal user profiling.
For emerging directions on e-commerce search, we focus on applications for multi-modal e-commerce search and ranking.
Online learning to rank technologies also provide insights. We also foresee the development of new learning theories that will improve e-commerce search and ranking performance in future.
We divide emerging directions on e-commerce recommendation into three directions:

<span class="ltx_inline-enumerate" id="Ch8.S2.I1">
<span class="ltx_inline-item" id="Ch8.S2.I1.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch8.S2.I1.i1.1">reasoning recommendation and explanations;
</span></span>
<span class="ltx_inline-item" id="Ch8.S2.I1.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch8.S2.I1.i2.1">conversational recommendation; and
</span></span>
<span class="ltx_inline-item" id="Ch8.S2.I1.i3"><span class="ltx_tag ltx_tag_inline-item">(iii)</span> <span class="ltx_text" id="Ch8.S2.I1.i3.1">unifying recommendation and search.
</span></span>
</span>
In our view, future work on e-commerce language processing should includes generating explainable reasons for search and recommendation, improving robustness e-commerce question answering, and improving conversational e-commerce search and recommendation.</p>
</div>
<section class="ltx_subsection" id="Ch8.S2.SS1">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.2.1 </span>Four directions</h4>
<div class="ltx_para" id="Ch8.S2.SS1.p1">
<p class="ltx_p" id="Ch8.S2.SS1.p1.1">Among these emerging research approaches, we have identified potential directions of future work that are encountered across multiple angles.
In particular, we list future research directions in four bigger themes: conversational search, conversational recommendation, multi-modal information discovery, and generative information discovery.</p>
</div>
<div class="ltx_para" id="Ch8.S2.SS1.p2">
<p class="ltx_p" id="Ch8.S2.SS1.p2.1"><em class="ltx_emph ltx_font_italic" id="Ch8.S2.SS1.p2.1.1">Conversational search</em> refers to a novel search paradigm using interactions between users and search engines. As we have discussed in Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch5" title="Chapter 5 E-commerce search ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">5</span></a>, conversational search is increasingly receiving more attention in the IR community.
Different from the traditional query-aware search paradigm, conversational search allows users to express their information need by directly conducting conversations with search engines.
Recent studies start to apply conversational search to online shopping scenarios as it is able to provide natural, adaptive and interactive shopping experience for consumers <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">xiao2021end</span>]</cite>. In e-commerce, conversational search faces two challenges: imperfect product attribute schemas and product
knowledge.
The former exists as product attributes link lengthy multi-turn utterances with products in conversational search systems, whereas the derives from the lack of manually labelling in benchmark datasets.
Core tasks in conversational search, e.g., search intent detection, action prediction, query selection, passage selection, and response generation <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ren2021wizard</span>]</cite>, also provide insights in future work about e-commerce conversational search systems.</p>
</div>
<div class="ltx_para" id="Ch8.S2.SS1.p3">
<p class="ltx_p" id="Ch8.S2.SS1.p3.1"><em class="ltx_emph ltx_font_italic" id="Ch8.S2.SS1.p3.1.1">Conversational recommendation</em> refers to a recommendation system that can elicit the dynamic preferences of users and take actions based on their current needs through real-time multi-turn interactions.
As we have discussed in Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch6" title="Chapter 6 E-commerce recommendation ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">6</span></a>, conversational recommendation is becoming an emerging research direction for e-commerce recommendation.
Integrating more accurate domain-specific knowledge to promote the recommendation and conversation is still a challenging problem in conversational recommendation <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2020towards</span>]</cite>.
Moreover, as with conversational search, current studies on conversational recommendation suffer from the lack of manually labelled data in benchmark datasets.
Recent studies on empathetic dialogue systems reveal that there exist some kind of dependency between commonsense knowledge and emotional preference <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">li2020empathetic</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">siro-2022-understanding</span>]</cite>.
Hence, a conversational recommender system jointly combining emotion detection and knowledge exploration is worth studying in future.</p>
</div>
<div class="ltx_para" id="Ch8.S2.SS1.p4">
<p class="ltx_p" id="Ch8.S2.SS1.p4.1"><em class="ltx_emph ltx_font_italic" id="Ch8.S2.SS1.p4.1.1">Multi-modal information</em> can be widely observed in many e-commerce scenarios, e.g., user behaviors, search, recommendation, and dialogue systems.
Most previous e-commerce information discovery approaches are constructed only based on text understanding and retrieval; addressing multi-modal information, e.g., images and videos, still appears to be difficult.
In future work, it is more and more important to tackle challenges about multi-modality in e-commerce scenarios.
Multimedia technologies focusing on integrating various types of modalities are expected to help to understand those multi-modal information for various types of e-commerce applications.
Moreover, it is interesting to explore multi-modal generation through more powerful generative deep neural networks in e-commerce review generation, question answering, and dialogue systems.</p>
</div>
<div class="ltx_para" id="Ch8.S2.SS1.p5">
<p class="ltx_p" id="Ch8.S2.SS1.p5.1"><em class="ltx_emph ltx_font_italic" id="Ch8.S2.SS1.p5.1.1">Large scale generative models</em> have the potential to significantly enhance various e-commerce information discovery applications, such as search, recommendation, and conversational AI. Transformer-based pre-trained language models like BERT have already proven effective in both search and recommendation tasks in e-commerce. More recently, large language models (LLMs) based on auto-regressive mechanisms, such as T5 and GPT, have demonstrated promising capabilities in understanding and generating human-like information, making them valuable for e-commerce contexts.
Moreover, while traditional two-stage paradigms (i.e., retrieval followed by re-ranking) have been widely used in e-commerce search and recommendation scenarios. They face two limitations:

<span class="ltx_inline-enumerate" id="Ch8.S2.I2">
<span class="ltx_inline-item" id="Ch8.S2.I2.i1"><span class="ltx_tag ltx_tag_inline-item">(i)</span> <span class="ltx_text" id="Ch8.S2.I2.i1.1">heterogeneous modules with different optimization objectives may lead to sub-optimal performance; and
</span></span>
<span class="ltx_inline-item" id="Ch8.S2.I2.i2"><span class="ltx_tag ltx_tag_inline-item">(ii)</span> <span class="ltx_text" id="Ch8.S2.I2.i2.1">a large document index is needed which may come with substantial memory and computational requirements.
</span></span>
</span>
This has motivated research into end-to-end solutions using generative models. Recent studies on generative retrieval, such as DSI <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">tay2022transformer</span>]</cite>, have shown encouraging performance on several information retrieval benchmarks, suggesting that exploring generative models for end-to-end e-commerce search and recommendation could be a promising direction for future research.</p>
</div>
</section>
<section class="ltx_subsection" id="Ch8.S2.SS2">
<h4 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.2.2 </span>Beyond accuracy</h4>
<div class="ltx_para" id="Ch8.S2.SS2.p1">
<p class="ltx_p" id="Ch8.S2.SS2.p1.1">Besides the three directions for future work listed above, we also consider the following important issues when it comes to information discovery tasks in e-commerce: <em class="ltx_emph ltx_font_italic" id="Ch8.S2.SS2.p1.1.1">fairness</em>, <em class="ltx_emph ltx_font_italic" id="Ch8.S2.SS2.p1.1.2">trustworthiness</em>, and <em class="ltx_emph ltx_font_italic" id="Ch8.S2.SS2.p1.1.3">explainability</em> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">derijke-2023-beyond</span>]</cite>.</p>
</div>
<div class="ltx_para" id="Ch8.S2.SS2.p2">
<p class="ltx_p" id="Ch8.S2.SS2.p2.1">Recently, the problem of bias has attracted considerable attention in the IR community, in multiple contexts, e.g., for user behavior modeling, profiling, ranking, and recommendation.
To address the bias problem, <em class="ltx_emph ltx_font_italic" id="Ch8.S2.SS2.p2.1.1">fairness</em> is considered as a significant metric during the optimization procedure.
Early on, fairness was studied from the perspective of information exposure regarding sensitive attributes such as gender and race <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">singh2018fairness</span>]</cite>.
Fairness in IR also focuses on how to let different items receive equal exposure, or exposure proportional to their utility or impact, depending on which exposure distribution is considered to be fair by the system <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">morik2020controlling</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2020bias</span>]</cite>.
In e-commerce, ranking-based interfaces are quite common in various scenarios, which makes the fairness issue a growing influence role for information discovery.
Future work on interactive fairness-aware reranking can be helpful for debiasing user modeling, search, recommendation, and answer generation in e-commerce platforms.
Also, knowledge-based and dynamic fairness-aware methods are able to address more real-world challenges.
The trade-off between accuracy and fairness is of importance in e-commerce search and recommendation scenarios, where equally treating different groups has been shown to sacrifice the performance.
To address this problem, an important research direction is to understand the dimensions of causality and design fairness-aware algorithms.</p>
</div>
<div class="ltx_para" id="Ch8.S2.SS2.p3">
<p class="ltx_p" id="Ch8.S2.SS2.p3.1">Fake news and fake information are is increasingly widespread.
It is now viewed as one of the greatest threats on the web <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhou2020survey</span>]</cite>.
As we have discussed in Chapter <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#Ch7" title="Chapter 7 E-commerce QA and conversations ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">7</span></a>, spam and fake reviews and answers are widely observed in many e-commerce platforms.
Therefore, pursuing <em class="ltx_emph ltx_font_italic" id="Ch8.S2.SS2.p3.1.1">trustworthiness</em> has become an important issue in e-commerce question answering and dialogue systems.
Recent studies aim to distinguish spam or fake reviews in online review systems via graph neural networks <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">kaghazgaran2018combating</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">rao2020xfraud</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2020alleviating</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">dou2020enhancing</span>]</cite>.
Textual generation methods based on deep neural networks have been applied to fake reviews or spam generation by camouflaged fraudsters. Thus, distinguishing the authenticity of e-commerce information is a challenging task.
Other patterns in the reviews, e.g., sentiments and emotions, can be applied to improve the detection.
Also, investigating inconsistency problems under multiple domains provides new avenues of research.</p>
</div>
<div class="ltx_para" id="Ch8.S2.SS2.p4">
<p class="ltx_p" id="Ch8.S2.SS2.p4.1"><em class="ltx_emph ltx_font_italic" id="Ch8.S2.SS2.p4.1.1">Explainability</em> in e-commerce aims to answer the question about why we receive a specific ranking, recommendation, or answer results. The task of explainability can be divided into to types: the explainability of the learning models and the explainability of the results.
The former aims to provide more transparent learning details for the proposed methods, whereas the latter focuses on provide more explainable results to various application scenarios, e.g., search, recommendation, and question answering, etc.
Explainability methods have been shown to be effective for enhancing the e-commerce search and recommendation <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2018towards</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">liu2020keywords</span>]</cite>.
For future work, it is important to evaluate if and how users are satisfied with the explanations generated from an e-commerce system, especially as these are increasingly conversational in nature.
Generating coherent and naturally-sounded explanations based on a sequence of reasoning steps (including search or recommendation system output) is still difficult.</p>
</div>
<div class="ltx_para" id="Ch8.S2.SS2.p5">
<p class="ltx_p" id="Ch8.S2.SS2.p5.1">In a broad sense, researchers in the broader communities, e.g., AI and operational research, have also realized the importance of information discovery in e-commerce, which aims to address a wide range of information discovery problems in e-commerce applications.
This survey would be useful for both academic and industrial researchers who are working on either information retrieval or e-commerce.
As we have discussed in our survey, the number of emerging research studies is increasing in recent years.
We believe that this is only the beginning of the whole research task.
The recent launch of a dedicated product search track at TREC seems to confirm this.<span class="ltx_note ltx_role_footnote" id="Ch8.footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://trec-product-search.github.io" title="">https://trec-product-search.github.io</a></span></span></span>
The quantity of the work described in this survey and the steady pace of publications in the field together with the open research follow-ups indicate a promising future ahead.
There is a lot of future work to be done.</p>
</div>
<div class="ltx_acknowledgements">
<h6 class="ltx_title ltx_title_acknowledgements">Acknowledgements.</h6>
This survey grew out of a tutorial “Information Discovery in e-Commerce” taught at SIGIR 2018.
We thank the audience for their feedback and questions.
We also thank our colleagues
Mozhdeh Ariannezhad,
Hongshen Chen,
Jiawei Chen,
Zhumin Chen,
Zhuoye Ding,
Yue Feng,
Yulong Gu,
Shuyu Guo,
Ziyi Guo,
Maria Heuss,
Mariya Hendriksen,
Na Huang,
Sami Jullien,
Barrie Kersbergen,
Jiahuan Lei,
Dongdong Li,
Ming Li,
Xiang Li,
Xinyi Li,
Zhenyang Li,
Xiaozhong Liu,
Hengliang Luo,
Si Luo,
Yougang Lyu,
Jun Ma,
Yao Ma,
Pengjie Ren,
Fatemeh Sarvi,
Sebastian Schelter,
Xinlei Shi,
Clemencia Siro,
Hongye Song,
Olivier Sprangers,
Changlong Sun,
Fei Sun,
Weiwei Sun,
Jiliang Tang,
Jingang Wang,
Shuaiqiang Wang,
Xuepeng Wang,
Zihan Wang,
Long Xia,
Xin Xin,
Zhen Zhang,
Jiashu Zhao,
Xiangyu Zhao,
and Yihong Zhao
for help, feedback, and inspiration.
We thank our editors Yiqun Liu and Mark Sanderson for support and valuable feedback.
This research was supported by
Baidu.com,
JD.com,
Alibaba DAMO Academy,
Meituan,
and
by the Hybrid Intelligence Center, a 10-year program funded by the Dutch Ministry of Education, Culture and Science through the Netherlands Organisation for Scientific Research, <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://hybrid-intelligence-centre.nl" title="">https://hybrid-intelligence-centre.nl</a>.
All content represents the opinion of the authors, which is not necessarily shared or endorsed by their respective employers and/or sponsors.

</div>
</section>
</section>
</section>
<section class="ltx_appendix" id="A1" lang="en">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Datasets</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">In this appendix, we list benchmark datasets that are relevant for studying information discovery in e-commerce.
We follow the topical of our chapters, and divide the datasets into <math alttext="5" class="ltx_Math" display="inline" id="A1.p1.1.m1.1"><semantics id="A1.p1.1.m1.1a"><mn id="A1.p1.1.m1.1.1" xref="A1.p1.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A1.p1.1.m1.1b"><cn id="A1.p1.1.m1.1.1.cmml" type="integer" xref="A1.p1.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.p1.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="A1.p1.1.m1.1d">5</annotation></semantics></math> types: e-commerce infrastructures, e-commerce user modeling, e-commerce search, e-commerce recommendation, and e-commerce QA &amp; Dialogues.</p>
</div>
<section class="ltx_section" id="A1.S1">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">A.1 </span>Datasets for e-commerce infrastructures</h3>
<div class="ltx_para" id="A1.S1.p1">
<p class="ltx_p" id="A1.S1.p1.1">To begin, we list benchmark datasets about e-commerce interfaces and users:</p>
</div>
<div class="ltx_para" id="A1.S1.p2">
<ul class="ltx_itemize" id="A1.S1.I1">
<li class="ltx_item" id="A1.S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S1.I1.i1.p1">
<p class="ltx_p" id="A1.S1.I1.i1.p1.6"><span class="ltx_text ltx_font_bold" id="A1.S1.I1.i1.p1.6.1">Taobao short title dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2018multi</span>]</cite>:
This dataset contains <math alttext="411,246" class="ltx_Math" display="inline" id="A1.S1.I1.i1.p1.1.m1.2"><semantics id="A1.S1.I1.i1.p1.1.m1.2a"><mrow id="A1.S1.I1.i1.p1.1.m1.2.3.2" xref="A1.S1.I1.i1.p1.1.m1.2.3.1.cmml"><mn id="A1.S1.I1.i1.p1.1.m1.1.1" xref="A1.S1.I1.i1.p1.1.m1.1.1.cmml">411</mn><mo id="A1.S1.I1.i1.p1.1.m1.2.3.2.1" xref="A1.S1.I1.i1.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.S1.I1.i1.p1.1.m1.2.2" xref="A1.S1.I1.i1.p1.1.m1.2.2.cmml">246</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S1.I1.i1.p1.1.m1.2b"><list id="A1.S1.I1.i1.p1.1.m1.2.3.1.cmml" xref="A1.S1.I1.i1.p1.1.m1.2.3.2"><cn id="A1.S1.I1.i1.p1.1.m1.1.1.cmml" type="integer" xref="A1.S1.I1.i1.p1.1.m1.1.1">411</cn><cn id="A1.S1.I1.i1.p1.1.m1.2.2.cmml" type="integer" xref="A1.S1.I1.i1.p1.1.m1.2.2">246</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S1.I1.i1.p1.1.m1.2c">411,246</annotation><annotation encoding="application/x-llamapun" id="A1.S1.I1.i1.p1.1.m1.2d">411 , 246</annotation></semantics></math> title-product pairs in <math alttext="94" class="ltx_Math" display="inline" id="A1.S1.I1.i1.p1.2.m2.1"><semantics id="A1.S1.I1.i1.p1.2.m2.1a"><mn id="A1.S1.I1.i1.p1.2.m2.1.1" xref="A1.S1.I1.i1.p1.2.m2.1.1.cmml">94</mn><annotation-xml encoding="MathML-Content" id="A1.S1.I1.i1.p1.2.m2.1b"><cn id="A1.S1.I1.i1.p1.2.m2.1.1.cmml" type="integer" xref="A1.S1.I1.i1.p1.2.m2.1.1">94</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.S1.I1.i1.p1.2.m2.1c">94</annotation><annotation encoding="application/x-llamapun" id="A1.S1.I1.i1.p1.2.m2.1d">94</annotation></semantics></math> categories. Each item in the dataset is represented as <math alttext="\langle Q,K,S\rangle" class="ltx_Math" display="inline" id="A1.S1.I1.i1.p1.3.m3.3"><semantics id="A1.S1.I1.i1.p1.3.m3.3a"><mrow id="A1.S1.I1.i1.p1.3.m3.3.4.2" xref="A1.S1.I1.i1.p1.3.m3.3.4.1.cmml"><mo id="A1.S1.I1.i1.p1.3.m3.3.4.2.1" stretchy="false" xref="A1.S1.I1.i1.p1.3.m3.3.4.1.cmml">⟨</mo><mi id="A1.S1.I1.i1.p1.3.m3.1.1" xref="A1.S1.I1.i1.p1.3.m3.1.1.cmml">Q</mi><mo id="A1.S1.I1.i1.p1.3.m3.3.4.2.2" xref="A1.S1.I1.i1.p1.3.m3.3.4.1.cmml">,</mo><mi id="A1.S1.I1.i1.p1.3.m3.2.2" xref="A1.S1.I1.i1.p1.3.m3.2.2.cmml">K</mi><mo id="A1.S1.I1.i1.p1.3.m3.3.4.2.3" xref="A1.S1.I1.i1.p1.3.m3.3.4.1.cmml">,</mo><mi id="A1.S1.I1.i1.p1.3.m3.3.3" xref="A1.S1.I1.i1.p1.3.m3.3.3.cmml">S</mi><mo id="A1.S1.I1.i1.p1.3.m3.3.4.2.4" stretchy="false" xref="A1.S1.I1.i1.p1.3.m3.3.4.1.cmml">⟩</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.S1.I1.i1.p1.3.m3.3b"><list id="A1.S1.I1.i1.p1.3.m3.3.4.1.cmml" xref="A1.S1.I1.i1.p1.3.m3.3.4.2"><ci id="A1.S1.I1.i1.p1.3.m3.1.1.cmml" xref="A1.S1.I1.i1.p1.3.m3.1.1">𝑄</ci><ci id="A1.S1.I1.i1.p1.3.m3.2.2.cmml" xref="A1.S1.I1.i1.p1.3.m3.2.2">𝐾</ci><ci id="A1.S1.I1.i1.p1.3.m3.3.3.cmml" xref="A1.S1.I1.i1.p1.3.m3.3.3">𝑆</ci></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S1.I1.i1.p1.3.m3.3c">\langle Q,K,S\rangle</annotation><annotation encoding="application/x-llamapun" id="A1.S1.I1.i1.p1.3.m3.3d">⟨ italic_Q , italic_K , italic_S ⟩</annotation></semantics></math>, where <math alttext="Q" class="ltx_Math" display="inline" id="A1.S1.I1.i1.p1.4.m4.1"><semantics id="A1.S1.I1.i1.p1.4.m4.1a"><mi id="A1.S1.I1.i1.p1.4.m4.1.1" xref="A1.S1.I1.i1.p1.4.m4.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="A1.S1.I1.i1.p1.4.m4.1b"><ci id="A1.S1.I1.i1.p1.4.m4.1.1.cmml" xref="A1.S1.I1.i1.p1.4.m4.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.S1.I1.i1.p1.4.m4.1c">Q</annotation><annotation encoding="application/x-llamapun" id="A1.S1.I1.i1.p1.4.m4.1d">italic_Q</annotation></semantics></math> denotes the products’ original titles, <math alttext="K" class="ltx_Math" display="inline" id="A1.S1.I1.i1.p1.5.m5.1"><semantics id="A1.S1.I1.i1.p1.5.m5.1a"><mi id="A1.S1.I1.i1.p1.5.m5.1.1" xref="A1.S1.I1.i1.p1.5.m5.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A1.S1.I1.i1.p1.5.m5.1b"><ci id="A1.S1.I1.i1.p1.5.m5.1.1.cmml" xref="A1.S1.I1.i1.p1.5.m5.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.S1.I1.i1.p1.5.m5.1c">K</annotation><annotation encoding="application/x-llamapun" id="A1.S1.I1.i1.p1.5.m5.1d">italic_K</annotation></semantics></math> refers to the background knowledge about the products, and <math alttext="S" class="ltx_Math" display="inline" id="A1.S1.I1.i1.p1.6.m6.1"><semantics id="A1.S1.I1.i1.p1.6.m6.1a"><mi id="A1.S1.I1.i1.p1.6.m6.1.1" xref="A1.S1.I1.i1.p1.6.m6.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="A1.S1.I1.i1.p1.6.m6.1b"><ci id="A1.S1.I1.i1.p1.6.m6.1.1.cmml" xref="A1.S1.I1.i1.p1.6.m6.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.S1.I1.i1.p1.6.m6.1c">S</annotation><annotation encoding="application/x-llamapun" id="A1.S1.I1.i1.p1.6.m6.1d">italic_S</annotation></semantics></math> represents the human-written short titles.</p>
</div>
</li>
<li class="ltx_item" id="A1.S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S1.I1.i2.p1">
<p class="ltx_p" id="A1.S1.I1.i2.p1.5"><span class="ltx_text ltx_font_bold" id="A1.S1.I1.i2.p1.5.1">eCOM-C2C dataset</span> about product categories and titles <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2018multi</span>]</cite>:
This dataset takes advantage of realistic data from a well-known C2C website in China.
The dataset contains <math alttext="185,386" class="ltx_Math" display="inline" id="A1.S1.I1.i2.p1.1.m1.2"><semantics id="A1.S1.I1.i2.p1.1.m1.2a"><mrow id="A1.S1.I1.i2.p1.1.m1.2.3.2" xref="A1.S1.I1.i2.p1.1.m1.2.3.1.cmml"><mn id="A1.S1.I1.i2.p1.1.m1.1.1" xref="A1.S1.I1.i2.p1.1.m1.1.1.cmml">185</mn><mo id="A1.S1.I1.i2.p1.1.m1.2.3.2.1" xref="A1.S1.I1.i2.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.S1.I1.i2.p1.1.m1.2.2" xref="A1.S1.I1.i2.p1.1.m1.2.2.cmml">386</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S1.I1.i2.p1.1.m1.2b"><list id="A1.S1.I1.i2.p1.1.m1.2.3.1.cmml" xref="A1.S1.I1.i2.p1.1.m1.2.3.2"><cn id="A1.S1.I1.i2.p1.1.m1.1.1.cmml" type="integer" xref="A1.S1.I1.i2.p1.1.m1.1.1">185</cn><cn id="A1.S1.I1.i2.p1.1.m1.2.2.cmml" type="integer" xref="A1.S1.I1.i2.p1.1.m1.2.2">386</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S1.I1.i2.p1.1.m1.2c">185,386</annotation><annotation encoding="application/x-llamapun" id="A1.S1.I1.i2.p1.1.m1.2d">185 , 386</annotation></semantics></math> triplets in the Women’s Clothes category. Each item in the dataset is represented as a triple <math alttext="\langle S,T,Q\rangle" class="ltx_Math" display="inline" id="A1.S1.I1.i2.p1.2.m2.3"><semantics id="A1.S1.I1.i2.p1.2.m2.3a"><mrow id="A1.S1.I1.i2.p1.2.m2.3.4.2" xref="A1.S1.I1.i2.p1.2.m2.3.4.1.cmml"><mo id="A1.S1.I1.i2.p1.2.m2.3.4.2.1" stretchy="false" xref="A1.S1.I1.i2.p1.2.m2.3.4.1.cmml">⟨</mo><mi id="A1.S1.I1.i2.p1.2.m2.1.1" xref="A1.S1.I1.i2.p1.2.m2.1.1.cmml">S</mi><mo id="A1.S1.I1.i2.p1.2.m2.3.4.2.2" xref="A1.S1.I1.i2.p1.2.m2.3.4.1.cmml">,</mo><mi id="A1.S1.I1.i2.p1.2.m2.2.2" xref="A1.S1.I1.i2.p1.2.m2.2.2.cmml">T</mi><mo id="A1.S1.I1.i2.p1.2.m2.3.4.2.3" xref="A1.S1.I1.i2.p1.2.m2.3.4.1.cmml">,</mo><mi id="A1.S1.I1.i2.p1.2.m2.3.3" xref="A1.S1.I1.i2.p1.2.m2.3.3.cmml">Q</mi><mo id="A1.S1.I1.i2.p1.2.m2.3.4.2.4" stretchy="false" xref="A1.S1.I1.i2.p1.2.m2.3.4.1.cmml">⟩</mo></mrow><annotation-xml encoding="MathML-Content" id="A1.S1.I1.i2.p1.2.m2.3b"><list id="A1.S1.I1.i2.p1.2.m2.3.4.1.cmml" xref="A1.S1.I1.i2.p1.2.m2.3.4.2"><ci id="A1.S1.I1.i2.p1.2.m2.1.1.cmml" xref="A1.S1.I1.i2.p1.2.m2.1.1">𝑆</ci><ci id="A1.S1.I1.i2.p1.2.m2.2.2.cmml" xref="A1.S1.I1.i2.p1.2.m2.2.2">𝑇</ci><ci id="A1.S1.I1.i2.p1.2.m2.3.3.cmml" xref="A1.S1.I1.i2.p1.2.m2.3.3">𝑄</ci></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S1.I1.i2.p1.2.m2.3c">\langle S,T,Q\rangle</annotation><annotation encoding="application/x-llamapun" id="A1.S1.I1.i2.p1.2.m2.3d">⟨ italic_S , italic_T , italic_Q ⟩</annotation></semantics></math>, where <math alttext="S" class="ltx_Math" display="inline" id="A1.S1.I1.i2.p1.3.m3.1"><semantics id="A1.S1.I1.i2.p1.3.m3.1a"><mi id="A1.S1.I1.i2.p1.3.m3.1.1" xref="A1.S1.I1.i2.p1.3.m3.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="A1.S1.I1.i2.p1.3.m3.1b"><ci id="A1.S1.I1.i2.p1.3.m3.1.1.cmml" xref="A1.S1.I1.i2.p1.3.m3.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.S1.I1.i2.p1.3.m3.1c">S</annotation><annotation encoding="application/x-llamapun" id="A1.S1.I1.i2.p1.3.m3.1d">italic_S</annotation></semantics></math> refers to a product’s original title, <math alttext="T" class="ltx_Math" display="inline" id="A1.S1.I1.i2.p1.4.m4.1"><semantics id="A1.S1.I1.i2.p1.4.m4.1a"><mi id="A1.S1.I1.i2.p1.4.m4.1.1" xref="A1.S1.I1.i2.p1.4.m4.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="A1.S1.I1.i2.p1.4.m4.1b"><ci id="A1.S1.I1.i2.p1.4.m4.1.1.cmml" xref="A1.S1.I1.i2.p1.4.m4.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.S1.I1.i2.p1.4.m4.1c">T</annotation><annotation encoding="application/x-llamapun" id="A1.S1.I1.i2.p1.4.m4.1d">italic_T</annotation></semantics></math> denotes a handcrafted short title, and <math alttext="Q" class="ltx_Math" display="inline" id="A1.S1.I1.i2.p1.5.m5.1"><semantics id="A1.S1.I1.i2.p1.5.m5.1a"><mi id="A1.S1.I1.i2.p1.5.m5.1.1" xref="A1.S1.I1.i2.p1.5.m5.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="A1.S1.I1.i2.p1.5.m5.1b"><ci id="A1.S1.I1.i2.p1.5.m5.1.1.cmml" xref="A1.S1.I1.i2.p1.5.m5.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.S1.I1.i2.p1.5.m5.1c">Q</annotation><annotation encoding="application/x-llamapun" id="A1.S1.I1.i2.p1.5.m5.1d">italic_Q</annotation></semantics></math> is a successful transaction-leading search queries.</p>
</div>
</li>
<li class="ltx_item" id="A1.S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S1.I1.i3.p1">
<p class="ltx_p" id="A1.S1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S1.I1.i3.p1.1.1">Walmart product summarization dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mukherjee2020discriminative</span>]</cite>:
The dataset includes 40,445 top-selling Walmart grocery products during the calendar year 2018, together with their product titles and corresponding human-generated summaries. There are also descriptions, brand names, and category information of the products.</p>
</div>
</li>
<li class="ltx_item" id="A1.S1.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S1.I1.i4.p1">
<p class="ltx_p" id="A1.S1.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S1.I1.i4.p1.1.1">Taobao multi-modal title dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">miao2020multi</span>]</cite>:
The dataset contains <math alttext="114,278" class="ltx_Math" display="inline" id="A1.S1.I1.i4.p1.1.m1.2"><semantics id="A1.S1.I1.i4.p1.1.m1.2a"><mrow id="A1.S1.I1.i4.p1.1.m1.2.3.2" xref="A1.S1.I1.i4.p1.1.m1.2.3.1.cmml"><mn id="A1.S1.I1.i4.p1.1.m1.1.1" xref="A1.S1.I1.i4.p1.1.m1.1.1.cmml">114</mn><mo id="A1.S1.I1.i4.p1.1.m1.2.3.2.1" xref="A1.S1.I1.i4.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.S1.I1.i4.p1.1.m1.2.2" xref="A1.S1.I1.i4.p1.1.m1.2.2.cmml">278</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S1.I1.i4.p1.1.m1.2b"><list id="A1.S1.I1.i4.p1.1.m1.2.3.1.cmml" xref="A1.S1.I1.i4.p1.1.m1.2.3.2"><cn id="A1.S1.I1.i4.p1.1.m1.1.1.cmml" type="integer" xref="A1.S1.I1.i4.p1.1.m1.1.1">114</cn><cn id="A1.S1.I1.i4.p1.1.m1.2.2.cmml" type="integer" xref="A1.S1.I1.i4.p1.1.m1.2.2">278</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S1.I1.i4.p1.1.m1.2c">114,278</annotation><annotation encoding="application/x-llamapun" id="A1.S1.I1.i4.p1.1.m1.2d">114 , 278</annotation></semantics></math> original titles with corresponding short titles and product images. The short titles are manually written by professional editors, whereas the images are selected by the seller.</p>
</div>
</li>
<li class="ltx_item" id="A1.S1.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S1.I1.i5.p1">
<p class="ltx_p" id="A1.S1.I1.i5.p1.4"><span class="ltx_text ltx_font_bold" id="A1.S1.I1.i5.p1.4.1">Walmart e-commerce product dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mukherjee2021unsupervised</span>]</cite>:
The dataset contains 5 parts: D-search includes the top 12 million product search queries on Walmart.com and their frequencies over a 1 year period.
D-product includes <math alttext="250,000" class="ltx_Math" display="inline" id="A1.S1.I1.i5.p1.1.m1.2"><semantics id="A1.S1.I1.i5.p1.1.m1.2a"><mrow id="A1.S1.I1.i5.p1.1.m1.2.3.2" xref="A1.S1.I1.i5.p1.1.m1.2.3.1.cmml"><mn id="A1.S1.I1.i5.p1.1.m1.1.1" xref="A1.S1.I1.i5.p1.1.m1.1.1.cmml">250</mn><mo id="A1.S1.I1.i5.p1.1.m1.2.3.2.1" xref="A1.S1.I1.i5.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.S1.I1.i5.p1.1.m1.2.2" xref="A1.S1.I1.i5.p1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S1.I1.i5.p1.1.m1.2b"><list id="A1.S1.I1.i5.p1.1.m1.2.3.1.cmml" xref="A1.S1.I1.i5.p1.1.m1.2.3.2"><cn id="A1.S1.I1.i5.p1.1.m1.1.1.cmml" type="integer" xref="A1.S1.I1.i5.p1.1.m1.1.1">250</cn><cn id="A1.S1.I1.i5.p1.1.m1.2.2.cmml" type="integer" xref="A1.S1.I1.i5.p1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S1.I1.i5.p1.1.m1.2c">250,000</annotation><annotation encoding="application/x-llamapun" id="A1.S1.I1.i5.p1.1.m1.2d">250 , 000</annotation></semantics></math> top-selling Walmart products over a 6 month period.
D-com-human includes <math alttext="40,445" class="ltx_Math" display="inline" id="A1.S1.I1.i5.p1.2.m2.2"><semantics id="A1.S1.I1.i5.p1.2.m2.2a"><mrow id="A1.S1.I1.i5.p1.2.m2.2.3.2" xref="A1.S1.I1.i5.p1.2.m2.2.3.1.cmml"><mn id="A1.S1.I1.i5.p1.2.m2.1.1" xref="A1.S1.I1.i5.p1.2.m2.1.1.cmml">40</mn><mo id="A1.S1.I1.i5.p1.2.m2.2.3.2.1" xref="A1.S1.I1.i5.p1.2.m2.2.3.1.cmml">,</mo><mn id="A1.S1.I1.i5.p1.2.m2.2.2" xref="A1.S1.I1.i5.p1.2.m2.2.2.cmml">445</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S1.I1.i5.p1.2.m2.2b"><list id="A1.S1.I1.i5.p1.2.m2.2.3.1.cmml" xref="A1.S1.I1.i5.p1.2.m2.2.3.2"><cn id="A1.S1.I1.i5.p1.2.m2.1.1.cmml" type="integer" xref="A1.S1.I1.i5.p1.2.m2.1.1">40</cn><cn id="A1.S1.I1.i5.p1.2.m2.2.2.cmml" type="integer" xref="A1.S1.I1.i5.p1.2.m2.2.2">445</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S1.I1.i5.p1.2.m2.2c">40,445</annotation><annotation encoding="application/x-llamapun" id="A1.S1.I1.i5.p1.2.m2.2d">40 , 445</annotation></semantics></math> human-generated title compressions from the Walmart catalog across 8 different product categories.
D-meta-auto contains <math alttext="40,000" class="ltx_Math" display="inline" id="A1.S1.I1.i5.p1.3.m3.2"><semantics id="A1.S1.I1.i5.p1.3.m3.2a"><mrow id="A1.S1.I1.i5.p1.3.m3.2.3.2" xref="A1.S1.I1.i5.p1.3.m3.2.3.1.cmml"><mn id="A1.S1.I1.i5.p1.3.m3.1.1" xref="A1.S1.I1.i5.p1.3.m3.1.1.cmml">40</mn><mo id="A1.S1.I1.i5.p1.3.m3.2.3.2.1" xref="A1.S1.I1.i5.p1.3.m3.2.3.1.cmml">,</mo><mn id="A1.S1.I1.i5.p1.3.m3.2.2" xref="A1.S1.I1.i5.p1.3.m3.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S1.I1.i5.p1.3.m3.2b"><list id="A1.S1.I1.i5.p1.3.m3.2.3.1.cmml" xref="A1.S1.I1.i5.p1.3.m3.2.3.2"><cn id="A1.S1.I1.i5.p1.3.m3.1.1.cmml" type="integer" xref="A1.S1.I1.i5.p1.3.m3.1.1">40</cn><cn id="A1.S1.I1.i5.p1.3.m3.2.2.cmml" type="integer" xref="A1.S1.I1.i5.p1.3.m3.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S1.I1.i5.p1.3.m3.2c">40,000</annotation><annotation encoding="application/x-llamapun" id="A1.S1.I1.i5.p1.3.m3.2d">40 , 000</annotation></semantics></math> meta-training examples. And D-meta-human is a dataset consisting of <math alttext="16,000" class="ltx_Math" display="inline" id="A1.S1.I1.i5.p1.4.m4.2"><semantics id="A1.S1.I1.i5.p1.4.m4.2a"><mrow id="A1.S1.I1.i5.p1.4.m4.2.3.2" xref="A1.S1.I1.i5.p1.4.m4.2.3.1.cmml"><mn id="A1.S1.I1.i5.p1.4.m4.1.1" xref="A1.S1.I1.i5.p1.4.m4.1.1.cmml">16</mn><mo id="A1.S1.I1.i5.p1.4.m4.2.3.2.1" xref="A1.S1.I1.i5.p1.4.m4.2.3.1.cmml">,</mo><mn id="A1.S1.I1.i5.p1.4.m4.2.2" xref="A1.S1.I1.i5.p1.4.m4.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S1.I1.i5.p1.4.m4.2b"><list id="A1.S1.I1.i5.p1.4.m4.2.3.1.cmml" xref="A1.S1.I1.i5.p1.4.m4.2.3.2"><cn id="A1.S1.I1.i5.p1.4.m4.1.1.cmml" type="integer" xref="A1.S1.I1.i5.p1.4.m4.1.1">16</cn><cn id="A1.S1.I1.i5.p1.4.m4.2.2.cmml" type="integer" xref="A1.S1.I1.i5.p1.4.m4.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S1.I1.i5.p1.4.m4.2c">16,000</annotation><annotation encoding="application/x-llamapun" id="A1.S1.I1.i5.p1.4.m4.2d">16 , 000</annotation></semantics></math> human-generated 1-shot title compression examples.</p>
</div>
</li>
<li class="ltx_item" id="A1.S1.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S1.I1.i6.p1">
<p class="ltx_p" id="A1.S1.I1.i6.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S1.I1.i6.p1.1.1">LESD4EC dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gong2019automatic</span>]</cite>:
The dataset consists of <math alttext="6,481,623" class="ltx_Math" display="inline" id="A1.S1.I1.i6.p1.1.m1.3"><semantics id="A1.S1.I1.i6.p1.1.m1.3a"><mrow id="A1.S1.I1.i6.p1.1.m1.3.4.2" xref="A1.S1.I1.i6.p1.1.m1.3.4.1.cmml"><mn id="A1.S1.I1.i6.p1.1.m1.1.1" xref="A1.S1.I1.i6.p1.1.m1.1.1.cmml">6</mn><mo id="A1.S1.I1.i6.p1.1.m1.3.4.2.1" xref="A1.S1.I1.i6.p1.1.m1.3.4.1.cmml">,</mo><mn id="A1.S1.I1.i6.p1.1.m1.2.2" xref="A1.S1.I1.i6.p1.1.m1.2.2.cmml">481</mn><mo id="A1.S1.I1.i6.p1.1.m1.3.4.2.2" xref="A1.S1.I1.i6.p1.1.m1.3.4.1.cmml">,</mo><mn id="A1.S1.I1.i6.p1.1.m1.3.3" xref="A1.S1.I1.i6.p1.1.m1.3.3.cmml">623</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S1.I1.i6.p1.1.m1.3b"><list id="A1.S1.I1.i6.p1.1.m1.3.4.1.cmml" xref="A1.S1.I1.i6.p1.1.m1.3.4.2"><cn id="A1.S1.I1.i6.p1.1.m1.1.1.cmml" type="integer" xref="A1.S1.I1.i6.p1.1.m1.1.1">6</cn><cn id="A1.S1.I1.i6.p1.1.m1.2.2.cmml" type="integer" xref="A1.S1.I1.i6.p1.1.m1.2.2">481</cn><cn id="A1.S1.I1.i6.p1.1.m1.3.3.cmml" type="integer" xref="A1.S1.I1.i6.p1.1.m1.3.3">623</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S1.I1.i6.p1.1.m1.3c">6,481,623</annotation><annotation encoding="application/x-llamapun" id="A1.S1.I1.i6.p1.1.m1.3d">6 , 481 , 623</annotation></semantics></math> pairs of original and short product titles in a module in Taobao named “Youhuashuo.” Each product in this dataset includes a long product title and a short title summary written by professional writers, along with a high-quality image and attributes tags.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="A1.S1.p3">
<p class="ltx_p" id="A1.S1.p3.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#A1.T1" title="Table A.1 ‣ A.1 Datasets for e-commerce infrastructures ‣ Appendix A Datasets ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">A.1</span></a> summarizes the key statistics of the datasets listed above.</p>
</div>
<div class="ltx_table ltx_transformed_outer" id="A1.T1" style="width:110.8pt;height:515.5pt;vertical-align:-0.0pt;"><div class="ltx_transformed_inner" style="width:515.5pt;transform:translate(-202.34pt,-197.1pt) rotate(-90deg) ;"><figure>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table A.1: </span>Statistics of datasets about e-commerce infrastructures.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T1.1" style="width:512.1pt;height:100.9pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-171.3pt,33.5pt) scale(0.599198942129597,0.599198942129597) ;">
<table class="ltx_tabular ltx_align_middle" id="A1.T1.1.1">
<tr class="ltx_tr" id="A1.T1.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T1.1.1.1.1" rowspan="2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T1.1.1.1.1.1">Datasets</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="A1.T1.1.1.1.2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T1.1.1.1.2.1">Statistics</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T1.1.1.1.3" rowspan="2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T1.1.1.1.3.1">References</span></td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.1.2">
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T1.1.1.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Dataset size</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T1.1.1.2.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_text" id="A1.T1.1.1.2.2.1"></span> <span class="ltx_text" id="A1.T1.1.1.2.2.2">
<span class="ltx_tabular ltx_align_middle" id="A1.T1.1.1.2.2.2.1">
<span class="ltx_tr" id="A1.T1.1.1.2.2.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T1.1.1.2.2.2.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Number</span></span>
<span class="ltx_tr" id="A1.T1.1.1.2.2.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T1.1.1.2.2.2.1.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">of category</span></span>
</span></span><span class="ltx_text" id="A1.T1.1.1.2.2.3"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T1.1.1.2.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_text" id="A1.T1.1.1.2.3.1"></span> <span class="ltx_text" id="A1.T1.1.1.2.3.2">
<span class="ltx_tabular ltx_align_middle" id="A1.T1.1.1.2.3.2.1">
<span class="ltx_tr" id="A1.T1.1.1.2.3.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T1.1.1.2.3.2.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Avg.length</span></span>
<span class="ltx_tr" id="A1.T1.1.1.2.3.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T1.1.1.2.3.2.1.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">of original titles</span></span>
</span></span><span class="ltx_text" id="A1.T1.1.1.2.3.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T1.1.1.2.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_text" id="A1.T1.1.1.2.4.1"></span> <span class="ltx_text" id="A1.T1.1.1.2.4.2">
<span class="ltx_tabular ltx_align_middle" id="A1.T1.1.1.2.4.2.1">
<span class="ltx_tr" id="A1.T1.1.1.2.4.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T1.1.1.2.4.2.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Avg.length</span></span>
<span class="ltx_tr" id="A1.T1.1.1.2.4.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T1.1.1.2.4.2.1.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">of short titles</span></span>
</span></span><span class="ltx_text" id="A1.T1.1.1.2.4.3"></span></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T1.1.1.2.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_text" id="A1.T1.1.1.2.5.1"></span> <span class="ltx_text" id="A1.T1.1.1.2.5.2">
<span class="ltx_tabular ltx_align_middle" id="A1.T1.1.1.2.5.2.1">
<span class="ltx_tr" id="A1.T1.1.1.2.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T1.1.1.2.5.2.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Avg.length</span></span>
<span class="ltx_tr" id="A1.T1.1.1.2.5.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T1.1.1.2.5.2.1.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">of background knowledge</span></span>
</span></span><span class="ltx_text" id="A1.T1.1.1.2.5.3"></span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.1.3.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Taobao short title dataset</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T1.1.1.3.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">453,138</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T1.1.1.3.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">94</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T1.1.1.3.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">25.34</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T1.1.1.3.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">7.73</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T1.1.1.3.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">5.92</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.1.3.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sun2018multi</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.1.4">
<td class="ltx_td ltx_align_left" id="A1.T1.1.1.4.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">eCOM-C2C dataset</td>
<td class="ltx_td ltx_align_right" id="A1.T1.1.1.4.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">185,386</td>
<td class="ltx_td ltx_align_right" id="A1.T1.1.1.4.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">1</td>
<td class="ltx_td ltx_align_center" id="A1.T1.1.1.4.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">25.1</td>
<td class="ltx_td ltx_align_center" id="A1.T1.1.1.4.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">7.5</td>
<td class="ltx_td ltx_align_right" id="A1.T1.1.1.4.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">8.3</td>
<td class="ltx_td ltx_align_left" id="A1.T1.1.1.4.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wang2018multi</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.1.5">
<td class="ltx_td ltx_align_left" id="A1.T1.1.1.5.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Walmart product summarization dataset</td>
<td class="ltx_td ltx_align_right" id="A1.T1.1.1.5.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">40,445</td>
<td class="ltx_td" id="A1.T1.1.1.5.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_center" id="A1.T1.1.1.5.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">4/10/35</td>
<td class="ltx_td ltx_align_center" id="A1.T1.1.1.5.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">1/2/5</td>
<td class="ltx_td" id="A1.T1.1.1.5.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left" id="A1.T1.1.1.5.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mukherjee2020discriminative</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.1.6">
<td class="ltx_td ltx_align_left" id="A1.T1.1.1.6.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Taobao multi-modal title dataset</td>
<td class="ltx_td ltx_align_right" id="A1.T1.1.1.6.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">114,278</td>
<td class="ltx_td" id="A1.T1.1.1.6.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T1.1.1.6.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T1.1.1.6.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T1.1.1.6.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left" id="A1.T1.1.1.6.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">miao2020multi</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.1.7">
<td class="ltx_td ltx_align_left" id="A1.T1.1.1.7.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Walmart e-commerce product dataset</td>
<td class="ltx_td ltx_align_right" id="A1.T1.1.1.7.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">40,000 + 16,000</td>
<td class="ltx_td ltx_align_right" id="A1.T1.1.1.7.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">4</td>
<td class="ltx_td" id="A1.T1.1.1.7.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T1.1.1.7.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T1.1.1.7.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left" id="A1.T1.1.1.7.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mukherjee2021unsupervised</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.1.8">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T1.1.1.8.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">LESD4EC dataset</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T1.1.1.8.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">6,481,623</td>
<td class="ltx_td ltx_border_bb" id="A1.T1.1.1.8.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T1.1.1.8.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">12</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T1.1.1.8.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">5</td>
<td class="ltx_td ltx_border_bb" id="A1.T1.1.1.8.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T1.1.1.8.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gong2019automatic</span>]</cite></td>
</tr>
</table>
</span></div>
</figure></div></div>
</section>
<section class="ltx_section" id="A1.S2">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">A.2 </span>Datasets for e-commerce user modeling</h3>
<div class="ltx_para" id="A1.S2.p1">
<p class="ltx_p" id="A1.S2.p1.1">Next, we list benchmark datasets about e-commerce user modeling:</p>
</div>
<div class="ltx_para" id="A1.S2.p2">
<ul class="ltx_itemize" id="A1.S2.I1">
<li class="ltx_item" id="A1.S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S2.I1.i1.p1">
<p class="ltx_p" id="A1.S2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S2.I1.i1.p1.1.1">Taobao Tianchi consumer dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">kim2021deep</span>]</cite>:
The dataset includes responses of users to advertisements of inventory in the user profile and advertising information.
The time length of the data is 8 days, and the dataset is divided into four tables: advertisement features, user profiles, past shopping behavior that users engaged in, and who received the advertisement with responses.<span class="ltx_note ltx_role_footnote" id="A1.footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://tianchi.aliyun.com/dataset/dataDetail?dataId=56" title="">https://tianchi.aliyun.com/dataset/dataDetail?dataId=56</a></span></span></span></p>
</div>
</li>
<li class="ltx_item" id="A1.S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S2.I1.i2.p1">
<p class="ltx_p" id="A1.S2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S2.I1.i2.p1.1.1">Instacart.MB dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sheng2021htda</span>]</cite>:
The Instacart Market Basket (Instacart.MB) dataset is anonymized and contains a sample of over 3 million grocery orders from more than <math alttext="200,000" class="ltx_Math" display="inline" id="A1.S2.I1.i2.p1.1.m1.2"><semantics id="A1.S2.I1.i2.p1.1.m1.2a"><mrow id="A1.S2.I1.i2.p1.1.m1.2.3.2" xref="A1.S2.I1.i2.p1.1.m1.2.3.1.cmml"><mn id="A1.S2.I1.i2.p1.1.m1.1.1" xref="A1.S2.I1.i2.p1.1.m1.1.1.cmml">200</mn><mo id="A1.S2.I1.i2.p1.1.m1.2.3.2.1" xref="A1.S2.I1.i2.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.S2.I1.i2.p1.1.m1.2.2" xref="A1.S2.I1.i2.p1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S2.I1.i2.p1.1.m1.2b"><list id="A1.S2.I1.i2.p1.1.m1.2.3.1.cmml" xref="A1.S2.I1.i2.p1.1.m1.2.3.2"><cn id="A1.S2.I1.i2.p1.1.m1.1.1.cmml" type="integer" xref="A1.S2.I1.i2.p1.1.m1.1.1">200</cn><cn id="A1.S2.I1.i2.p1.1.m1.2.2.cmml" type="integer" xref="A1.S2.I1.i2.p1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S2.I1.i2.p1.1.m1.2c">200,000</annotation><annotation encoding="application/x-llamapun" id="A1.S2.I1.i2.p1.1.m1.2d">200 , 000</annotation></semantics></math> Instacart users.
For each user in the dataset, there are between 4 and 100 of their orders, with the sequence of products purchased in each order.<span class="ltx_note ltx_role_footnote" id="A1.footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.kaggle.com/c/instacart-market-basket-analysis/data" title="">https://www.kaggle.com/c/instacart-market-basket-analysis/data</a></span></span></span></p>
</div>
</li>
<li class="ltx_item" id="A1.S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S2.I1.i3.p1">
<p class="ltx_p" id="A1.S2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S2.I1.i3.p1.1.1">Bing advertising service dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lian2021multi</span>]</cite>:
The dataset contains user click logs within a two week period from the Bing Native Advertising service. It also includes users’ online behavior history before their corresponding clicks.
The user behavior sequences are truncated to 100 in the dataset.</p>
</div>
</li>
<li class="ltx_item" id="A1.S2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S2.I1.i4.p1">
<p class="ltx_p" id="A1.S2.I1.i4.p1.4"><span class="ltx_text ltx_font_bold" id="A1.S2.I1.i4.p1.4.1">Feeds user dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yi2021debiasedrec</span>]</cite>:
The feeds dataset is collected on Microsoft News App from August 1, 2020, to September 1, 2020. It contains <math alttext="643,177" class="ltx_Math" display="inline" id="A1.S2.I1.i4.p1.1.m1.2"><semantics id="A1.S2.I1.i4.p1.1.m1.2a"><mrow id="A1.S2.I1.i4.p1.1.m1.2.3.2" xref="A1.S2.I1.i4.p1.1.m1.2.3.1.cmml"><mn id="A1.S2.I1.i4.p1.1.m1.1.1" xref="A1.S2.I1.i4.p1.1.m1.1.1.cmml">643</mn><mo id="A1.S2.I1.i4.p1.1.m1.2.3.2.1" xref="A1.S2.I1.i4.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.S2.I1.i4.p1.1.m1.2.2" xref="A1.S2.I1.i4.p1.1.m1.2.2.cmml">177</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S2.I1.i4.p1.1.m1.2b"><list id="A1.S2.I1.i4.p1.1.m1.2.3.1.cmml" xref="A1.S2.I1.i4.p1.1.m1.2.3.2"><cn id="A1.S2.I1.i4.p1.1.m1.1.1.cmml" type="integer" xref="A1.S2.I1.i4.p1.1.m1.1.1">643</cn><cn id="A1.S2.I1.i4.p1.1.m1.2.2.cmml" type="integer" xref="A1.S2.I1.i4.p1.1.m1.2.2">177</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S2.I1.i4.p1.1.m1.2c">643,177</annotation><annotation encoding="application/x-llamapun" id="A1.S2.I1.i4.p1.1.m1.2d">643 , 177</annotation></semantics></math> news items, over <math alttext="10,000" class="ltx_Math" display="inline" id="A1.S2.I1.i4.p1.2.m2.2"><semantics id="A1.S2.I1.i4.p1.2.m2.2a"><mrow id="A1.S2.I1.i4.p1.2.m2.2.3.2" xref="A1.S2.I1.i4.p1.2.m2.2.3.1.cmml"><mn id="A1.S2.I1.i4.p1.2.m2.1.1" xref="A1.S2.I1.i4.p1.2.m2.1.1.cmml">10</mn><mo id="A1.S2.I1.i4.p1.2.m2.2.3.2.1" xref="A1.S2.I1.i4.p1.2.m2.2.3.1.cmml">,</mo><mn id="A1.S2.I1.i4.p1.2.m2.2.2" xref="A1.S2.I1.i4.p1.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S2.I1.i4.p1.2.m2.2b"><list id="A1.S2.I1.i4.p1.2.m2.2.3.1.cmml" xref="A1.S2.I1.i4.p1.2.m2.2.3.2"><cn id="A1.S2.I1.i4.p1.2.m2.1.1.cmml" type="integer" xref="A1.S2.I1.i4.p1.2.m2.1.1">10</cn><cn id="A1.S2.I1.i4.p1.2.m2.2.2.cmml" type="integer" xref="A1.S2.I1.i4.p1.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S2.I1.i4.p1.2.m2.2c">10,000</annotation><annotation encoding="application/x-llamapun" id="A1.S2.I1.i4.p1.2.m2.2d">10 , 000</annotation></semantics></math> users, <math alttext="320,925" class="ltx_Math" display="inline" id="A1.S2.I1.i4.p1.3.m3.2"><semantics id="A1.S2.I1.i4.p1.3.m3.2a"><mrow id="A1.S2.I1.i4.p1.3.m3.2.3.2" xref="A1.S2.I1.i4.p1.3.m3.2.3.1.cmml"><mn id="A1.S2.I1.i4.p1.3.m3.1.1" xref="A1.S2.I1.i4.p1.3.m3.1.1.cmml">320</mn><mo id="A1.S2.I1.i4.p1.3.m3.2.3.2.1" xref="A1.S2.I1.i4.p1.3.m3.2.3.1.cmml">,</mo><mn id="A1.S2.I1.i4.p1.3.m3.2.2" xref="A1.S2.I1.i4.p1.3.m3.2.2.cmml">925</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S2.I1.i4.p1.3.m3.2b"><list id="A1.S2.I1.i4.p1.3.m3.2.3.1.cmml" xref="A1.S2.I1.i4.p1.3.m3.2.3.2"><cn id="A1.S2.I1.i4.p1.3.m3.1.1.cmml" type="integer" xref="A1.S2.I1.i4.p1.3.m3.1.1">320</cn><cn id="A1.S2.I1.i4.p1.3.m3.2.2.cmml" type="integer" xref="A1.S2.I1.i4.p1.3.m3.2.2">925</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S2.I1.i4.p1.3.m3.2c">320,925</annotation><annotation encoding="application/x-llamapun" id="A1.S2.I1.i4.p1.3.m3.2d">320 , 925</annotation></semantics></math> impressions, and <math alttext="970,846" class="ltx_Math" display="inline" id="A1.S2.I1.i4.p1.4.m4.2"><semantics id="A1.S2.I1.i4.p1.4.m4.2a"><mrow id="A1.S2.I1.i4.p1.4.m4.2.3.2" xref="A1.S2.I1.i4.p1.4.m4.2.3.1.cmml"><mn id="A1.S2.I1.i4.p1.4.m4.1.1" xref="A1.S2.I1.i4.p1.4.m4.1.1.cmml">970</mn><mo id="A1.S2.I1.i4.p1.4.m4.2.3.2.1" xref="A1.S2.I1.i4.p1.4.m4.2.3.1.cmml">,</mo><mn id="A1.S2.I1.i4.p1.4.m4.2.2" xref="A1.S2.I1.i4.p1.4.m4.2.2.cmml">846</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S2.I1.i4.p1.4.m4.2b"><list id="A1.S2.I1.i4.p1.4.m4.2.3.1.cmml" xref="A1.S2.I1.i4.p1.4.m4.2.3.2"><cn id="A1.S2.I1.i4.p1.4.m4.1.1.cmml" type="integer" xref="A1.S2.I1.i4.p1.4.m4.1.1">970</cn><cn id="A1.S2.I1.i4.p1.4.m4.2.2.cmml" type="integer" xref="A1.S2.I1.i4.p1.4.m4.2.2">846</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S2.I1.i4.p1.4.m4.2c">970,846</annotation><annotation encoding="application/x-llamapun" id="A1.S2.I1.i4.p1.4.m4.2d">970 , 846</annotation></semantics></math> clicks.</p>
</div>
</li>
<li class="ltx_item" id="A1.S2.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S2.I1.i5.p1">
<p class="ltx_p" id="A1.S2.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S2.I1.i5.p1.1.1">JD user profiling dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019semi</span>]</cite>:
This dataset is collected from one of the largest e-commerce platforms in China.
In this dataset, users, items, and attributes reflect real-world e-commerce consumers, products, and words in the titles of the products respectively.
The profiles of users are the age and gender labels.</p>
</div>
</li>
<li class="ltx_item" id="A1.S2.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S2.I1.i6.p1">
<p class="ltx_p" id="A1.S2.I1.i6.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S2.I1.i6.p1.1.1">Twitter user behavior dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">al2012homophily</span>]</cite>:
Each attribute dataset consists of approximately 400 labeled Twitter users, 200 with one label (e.g., “female”) and 200 with a second label (e.g., “male”). In addition, all of the friends of these labeled users are identified; for each of these labeled and neighbor users, the most recent 1000 tweets generated by the user were collected.</p>
</div>
</li>
<li class="ltx_item" id="A1.S2.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S2.I1.i7.p1">
<p class="ltx_p" id="A1.S2.I1.i7.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S2.I1.i7.p1.1.1">UCL social media user profiling dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liang2017inferring</span>]</cite>:
This dataset was collected by UCL’s Big Data Institute.
The data set includes <math alttext="1,375" class="ltx_Math" display="inline" id="A1.S2.I1.i7.p1.1.m1.2"><semantics id="A1.S2.I1.i7.p1.1.m1.2a"><mrow id="A1.S2.I1.i7.p1.1.m1.2.3.2" xref="A1.S2.I1.i7.p1.1.m1.2.3.1.cmml"><mn id="A1.S2.I1.i7.p1.1.m1.1.1" xref="A1.S2.I1.i7.p1.1.m1.1.1.cmml">1</mn><mo id="A1.S2.I1.i7.p1.1.m1.2.3.2.1" xref="A1.S2.I1.i7.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.S2.I1.i7.p1.1.m1.2.2" xref="A1.S2.I1.i7.p1.1.m1.2.2.cmml">375</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S2.I1.i7.p1.1.m1.2b"><list id="A1.S2.I1.i7.p1.1.m1.2.3.1.cmml" xref="A1.S2.I1.i7.p1.1.m1.2.3.2"><cn id="A1.S2.I1.i7.p1.1.m1.1.1.cmml" type="integer" xref="A1.S2.I1.i7.p1.1.m1.1.1">1</cn><cn id="A1.S2.I1.i7.p1.1.m1.2.2.cmml" type="integer" xref="A1.S2.I1.i7.p1.1.m1.2.2">375</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S2.I1.i7.p1.1.m1.2c">1,375</annotation><annotation encoding="application/x-llamapun" id="A1.S2.I1.i7.p1.1.m1.2d">1 , 375</annotation></semantics></math> active Twitter users chosen randomly and their tweets from the time they registered until May 31, 2015. The dataset has 3.78 million tweets in total. The length of a tweet is 12 words on average.</p>
</div>
</li>
<li class="ltx_item" id="A1.S2.I1.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S2.I1.i8.p1">
<p class="ltx_p" id="A1.S2.I1.i8.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S2.I1.i8.p1.1.1">CALL dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">dong2014inferring</span>]</cite>:
The dataset is extracted from a collection of more than 1 billion (i.e., <math alttext="1,000,229,603" class="ltx_Math" display="inline" id="A1.S2.I1.i8.p1.1.m1.4"><semantics id="A1.S2.I1.i8.p1.1.m1.4a"><mrow id="A1.S2.I1.i8.p1.1.m1.4.5.2" xref="A1.S2.I1.i8.p1.1.m1.4.5.1.cmml"><mn id="A1.S2.I1.i8.p1.1.m1.1.1" xref="A1.S2.I1.i8.p1.1.m1.1.1.cmml">1</mn><mo id="A1.S2.I1.i8.p1.1.m1.4.5.2.1" xref="A1.S2.I1.i8.p1.1.m1.4.5.1.cmml">,</mo><mn id="A1.S2.I1.i8.p1.1.m1.2.2" xref="A1.S2.I1.i8.p1.1.m1.2.2.cmml">000</mn><mo id="A1.S2.I1.i8.p1.1.m1.4.5.2.2" xref="A1.S2.I1.i8.p1.1.m1.4.5.1.cmml">,</mo><mn id="A1.S2.I1.i8.p1.1.m1.3.3" xref="A1.S2.I1.i8.p1.1.m1.3.3.cmml">229</mn><mo id="A1.S2.I1.i8.p1.1.m1.4.5.2.3" xref="A1.S2.I1.i8.p1.1.m1.4.5.1.cmml">,</mo><mn id="A1.S2.I1.i8.p1.1.m1.4.4" xref="A1.S2.I1.i8.p1.1.m1.4.4.cmml">603</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S2.I1.i8.p1.1.m1.4b"><list id="A1.S2.I1.i8.p1.1.m1.4.5.1.cmml" xref="A1.S2.I1.i8.p1.1.m1.4.5.2"><cn id="A1.S2.I1.i8.p1.1.m1.1.1.cmml" type="integer" xref="A1.S2.I1.i8.p1.1.m1.1.1">1</cn><cn id="A1.S2.I1.i8.p1.1.m1.2.2.cmml" type="integer" xref="A1.S2.I1.i8.p1.1.m1.2.2">000</cn><cn id="A1.S2.I1.i8.p1.1.m1.3.3.cmml" type="integer" xref="A1.S2.I1.i8.p1.1.m1.3.3">229</cn><cn id="A1.S2.I1.i8.p1.1.m1.4.4.cmml" type="integer" xref="A1.S2.I1.i8.p1.1.m1.4.4">603</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S2.I1.i8.p1.1.m1.4c">1,000,229,603</annotation><annotation encoding="application/x-llamapun" id="A1.S2.I1.i8.p1.1.m1.4d">1 , 000 , 229 , 603</annotation></semantics></math>) call and text-message events from an anonymous country, which spans from August 2008 to September 2008. The data does not contain any communication content.</p>
</div>
</li>
<li class="ltx_item" id="A1.S2.I1.i9" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S2.I1.i9.p1">
<p class="ltx_p" id="A1.S2.I1.i9.p1.2"><span class="ltx_text ltx_font_bold" id="A1.S2.I1.i9.p1.2.1">W-NUT dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">han2016twitter</span>]</cite>:
This is a user-level dataset of the geolocation prediction shared task released at the W-NUT workshop in 2016.
The dataset consists of over 1 million training users, <math alttext="10,000" class="ltx_Math" display="inline" id="A1.S2.I1.i9.p1.1.m1.2"><semantics id="A1.S2.I1.i9.p1.1.m1.2a"><mrow id="A1.S2.I1.i9.p1.1.m1.2.3.2" xref="A1.S2.I1.i9.p1.1.m1.2.3.1.cmml"><mn id="A1.S2.I1.i9.p1.1.m1.1.1" xref="A1.S2.I1.i9.p1.1.m1.1.1.cmml">10</mn><mo id="A1.S2.I1.i9.p1.1.m1.2.3.2.1" xref="A1.S2.I1.i9.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.S2.I1.i9.p1.1.m1.2.2" xref="A1.S2.I1.i9.p1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S2.I1.i9.p1.1.m1.2b"><list id="A1.S2.I1.i9.p1.1.m1.2.3.1.cmml" xref="A1.S2.I1.i9.p1.1.m1.2.3.2"><cn id="A1.S2.I1.i9.p1.1.m1.1.1.cmml" type="integer" xref="A1.S2.I1.i9.p1.1.m1.1.1">10</cn><cn id="A1.S2.I1.i9.p1.1.m1.2.2.cmml" type="integer" xref="A1.S2.I1.i9.p1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S2.I1.i9.p1.1.m1.2c">10,000</annotation><annotation encoding="application/x-llamapun" id="A1.S2.I1.i9.p1.1.m1.2d">10 , 000</annotation></semantics></math> development users, and <math alttext="10,000" class="ltx_Math" display="inline" id="A1.S2.I1.i9.p1.2.m2.2"><semantics id="A1.S2.I1.i9.p1.2.m2.2a"><mrow id="A1.S2.I1.i9.p1.2.m2.2.3.2" xref="A1.S2.I1.i9.p1.2.m2.2.3.1.cmml"><mn id="A1.S2.I1.i9.p1.2.m2.1.1" xref="A1.S2.I1.i9.p1.2.m2.1.1.cmml">10</mn><mo id="A1.S2.I1.i9.p1.2.m2.2.3.2.1" xref="A1.S2.I1.i9.p1.2.m2.2.3.1.cmml">,</mo><mn id="A1.S2.I1.i9.p1.2.m2.2.2" xref="A1.S2.I1.i9.p1.2.m2.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S2.I1.i9.p1.2.m2.2b"><list id="A1.S2.I1.i9.p1.2.m2.2.3.1.cmml" xref="A1.S2.I1.i9.p1.2.m2.2.3.2"><cn id="A1.S2.I1.i9.p1.2.m2.1.1.cmml" type="integer" xref="A1.S2.I1.i9.p1.2.m2.1.1">10</cn><cn id="A1.S2.I1.i9.p1.2.m2.2.2.cmml" type="integer" xref="A1.S2.I1.i9.p1.2.m2.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S2.I1.i9.p1.2.m2.2c">10,000</annotation><annotation encoding="application/x-llamapun" id="A1.S2.I1.i9.p1.2.m2.2d">10 , 000</annotation></semantics></math> test users. The ground truth location of a user is decided by majority voting of the closest city center.</p>
</div>
</li>
<li class="ltx_item" id="A1.S2.I1.i10" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S2.I1.i10.p1">
<p class="ltx_p" id="A1.S2.I1.i10.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S2.I1.i10.p1.1.1">Facebook user profiling dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">farnadi2018user</span>]</cite>:
This is a re-collected dataset based on Facebook’s MyPersonality project dataset.<span class="ltx_note ltx_role_footnote" id="A1.footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="http://www.mypersonality.org" title="">http://www.mypersonality.org</a></span></span></span>
The dataset includes information about each user’s demographics, friendship links, Facebook activities (e.g., number of group affiliations, page likes, education, and work history), status updates, profile picture, and Big Five Personality scores (ranging from 1 to 5).</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="A1.S2.p3">
<p class="ltx_p" id="A1.S2.p3.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#A1.T2" title="Table A.2 ‣ A.2 Datasets for e-commerce user modeling ‣ Appendix A Datasets ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">A.2</span></a> summarizes the key statistics of the datasets listed above.</p>
</div>
<div class="ltx_table ltx_transformed_outer" id="A1.T2" style="width:161.4pt;height:515.5pt;vertical-align:-0.0pt;"><div class="ltx_transformed_inner" style="width:515.5pt;transform:translate(-177.02pt,-171.73pt) rotate(-90deg) ;"><figure>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table A.2: </span>Statistics of datasets about e-commerce user modeling.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T2.1" style="width:512.1pt;height:151.6pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-110.6pt,32.6pt) scale(0.698384467725705,0.698384467725705) ;">
<table class="ltx_tabular ltx_align_middle" id="A1.T2.1.1">
<tr class="ltx_tr" id="A1.T2.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T2.1.1.1.1" rowspan="2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T2.1.1.1.1.1">Datasets</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="A1.T2.1.1.1.2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T2.1.1.1.2.1">Statistics</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T2.1.1.1.3" rowspan="2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T2.1.1.1.3.1">References</span></td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.2">
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T2.1.1.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Users</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T2.1.1.2.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Items</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T2.1.1.2.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Interactions</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T2.1.1.2.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Avg.seq.len</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.1.1.2.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">TimeSpan</td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T2.1.1.3.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Taobao Tianchi consumer dataset</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T2.1.1.3.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">1,140,000</td>
<td class="ltx_td ltx_border_t" id="A1.T2.1.1.3.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_border_t" id="A1.T2.1.1.3.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T2.1.1.3.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">26,000,000</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T2.1.1.3.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">20170506-20170513</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T2.1.1.3.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">kim2021deep</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.4">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.4.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Instacart.MB dataset</td>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.4.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">11,464</td>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.4.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">42,207</td>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.4.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">7,764,043</td>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.4.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">677.25</td>
<td class="ltx_td" id="A1.T2.1.1.4.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.4.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">sheng2021htda</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.5">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.5.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Bing advertising service dataset</td>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.5.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">748,000</td>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.5.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">409,000</td>
<td class="ltx_td" id="A1.T2.1.1.5.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.5.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">74</td>
<td class="ltx_td" id="A1.T2.1.1.5.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.5.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">lian2021multi</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.6">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.6.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Feeds user dataset</td>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.6.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">10,000</td>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.6.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">643,177</td>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.6.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">970,846</td>
<td class="ltx_td" id="A1.T2.1.1.6.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T2.1.1.6.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.6.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yi2021debiasedrec</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.7">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.7.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">JD user profiling dataset</td>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.7.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">54,161</td>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.7.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">203,712</td>
<td class="ltx_td" id="A1.T2.1.1.7.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T2.1.1.7.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T2.1.1.7.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.7.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019semi</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.8">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.8.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Twitter user behavior dataset</td>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.8.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">400</td>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.8.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">400,000</td>
<td class="ltx_td" id="A1.T2.1.1.8.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.8.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">1,000</td>
<td class="ltx_td" id="A1.T2.1.1.8.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.8.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">al2012homophily</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.9">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.9.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">UCL social media user profiling dataset</td>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.9.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">1,375</td>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.9.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">3,780,000</td>
<td class="ltx_td" id="A1.T2.1.1.9.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.9.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">12</td>
<td class="ltx_td ltx_align_center" id="A1.T2.1.1.9.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">time of registration-20150531</td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.9.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">liang2017inferring</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.10">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.10.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">CALL dataset</td>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.10.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">1,090,000</td>
<td class="ltx_td" id="A1.T2.1.1.10.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T2.1.1.10.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T2.1.1.10.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_center" id="A1.T2.1.1.10.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">200808-200809</td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.10.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">dong2014inferring</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.11">
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.11.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">W-NUT dataset</td>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.11.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">1,020,000</td>
<td class="ltx_td ltx_align_right" id="A1.T2.1.1.11.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">13,000,000</td>
<td class="ltx_td" id="A1.T2.1.1.11.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T2.1.1.11.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T2.1.1.11.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left" id="A1.T2.1.1.11.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">han2016twitter</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T2.1.1.12">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T2.1.1.12.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Facebook user profiling dataset</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T2.1.1.12.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">5,670</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T2.1.1.12.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">49,372</td>
<td class="ltx_td ltx_border_bb" id="A1.T2.1.1.12.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_border_bb" id="A1.T2.1.1.12.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_border_bb" id="A1.T2.1.1.12.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T2.1.1.12.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">farnadi2018user</span>]</cite></td>
</tr>
</table>
</span></div>
</figure></div></div>
</section>
<section class="ltx_section" id="A1.S3">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">A.3 </span>Datasets for e-commerce search</h3>
<div class="ltx_para" id="A1.S3.p1">
<p class="ltx_p" id="A1.S3.p1.1">We list benchmark datasets about e-commerce search as follows:</p>
</div>
<div class="ltx_para" id="A1.S3.p2">
<ul class="ltx_itemize" id="A1.S3.I1">
<li class="ltx_item" id="A1.S3.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S3.I1.i1.p1">
<p class="ltx_p" id="A1.S3.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S3.I1.i1.p1.1.1">QUARTS e-commerce search dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">nguyen2020learning</span>]</cite>:
This is a human-labeled dataset of query-item pairs, obtained from an e-commerce search platform. There are in total 3.2 million pairs of which only a small fraction are mismatches. About <math alttext="100,000" class="ltx_Math" display="inline" id="A1.S3.I1.i1.p1.1.m1.2"><semantics id="A1.S3.I1.i1.p1.1.m1.2a"><mrow id="A1.S3.I1.i1.p1.1.m1.2.3.2" xref="A1.S3.I1.i1.p1.1.m1.2.3.1.cmml"><mn id="A1.S3.I1.i1.p1.1.m1.1.1" xref="A1.S3.I1.i1.p1.1.m1.1.1.cmml">100</mn><mo id="A1.S3.I1.i1.p1.1.m1.2.3.2.1" xref="A1.S3.I1.i1.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.S3.I1.i1.p1.1.m1.2.2" xref="A1.S3.I1.i1.p1.1.m1.2.2.cmml">000</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S3.I1.i1.p1.1.m1.2b"><list id="A1.S3.I1.i1.p1.1.m1.2.3.1.cmml" xref="A1.S3.I1.i1.p1.1.m1.2.3.2"><cn id="A1.S3.I1.i1.p1.1.m1.1.1.cmml" type="integer" xref="A1.S3.I1.i1.p1.1.m1.1.1">100</cn><cn id="A1.S3.I1.i1.p1.1.m1.2.2.cmml" type="integer" xref="A1.S3.I1.i1.p1.1.m1.2.2">000</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S3.I1.i1.p1.1.m1.2c">100,000</annotation><annotation encoding="application/x-llamapun" id="A1.S3.I1.i1.p1.1.m1.2d">100 , 000</annotation></semantics></math> labeled pairs are used as a separate test set. Another 3 million query-item pairs are deemed “matched” by considering items that are purchased frequently in response to those queries from the search logs.</p>
</div>
</li>
<li class="ltx_item" id="A1.S3.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S3.I1.i2.p1">
<p class="ltx_p" id="A1.S3.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S3.I1.i2.p1.1.1">SCEM product search dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bi2019leverage</span>]</cite>:
The dataset contains three category-specific datasets, namely, “Toys &amp; Games,” “Garden &amp; Outdoor,” and “Cell Phones &amp; Accessories,” from the logs of a commercial product search engine spanning ten months between years 2017 and 2018. The datasets include up to a few million query sessions containing several hundred thousand unique queries.</p>
</div>
</li>
<li class="ltx_item" id="A1.S3.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S3.I1.i3.p1">
<p class="ltx_p" id="A1.S3.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S3.I1.i3.p1.1.1">Walmart product search dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">karmaker2017application</span>]</cite>:
This is a subset obtained from Walmart’s online product catalog.
The dataset consists of more than <math alttext="2,800" class="ltx_Math" display="inline" id="A1.S3.I1.i3.p1.1.m1.2"><semantics id="A1.S3.I1.i3.p1.1.m1.2a"><mrow id="A1.S3.I1.i3.p1.1.m1.2.3.2" xref="A1.S3.I1.i3.p1.1.m1.2.3.1.cmml"><mn id="A1.S3.I1.i3.p1.1.m1.1.1" xref="A1.S3.I1.i3.p1.1.m1.1.1.cmml">2</mn><mo id="A1.S3.I1.i3.p1.1.m1.2.3.2.1" xref="A1.S3.I1.i3.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.S3.I1.i3.p1.1.m1.2.2" xref="A1.S3.I1.i3.p1.1.m1.2.2.cmml">800</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S3.I1.i3.p1.1.m1.2b"><list id="A1.S3.I1.i3.p1.1.m1.2.3.1.cmml" xref="A1.S3.I1.i3.p1.1.m1.2.3.2"><cn id="A1.S3.I1.i3.p1.1.m1.1.1.cmml" type="integer" xref="A1.S3.I1.i3.p1.1.m1.1.1">2</cn><cn id="A1.S3.I1.i3.p1.1.m1.2.2.cmml" type="integer" xref="A1.S3.I1.i3.p1.1.m1.2.2">800</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S3.I1.i3.p1.1.m1.2c">2,800</annotation><annotation encoding="application/x-llamapun" id="A1.S3.I1.i3.p1.1.m1.2d">2 , 800</annotation></semantics></math> randomly selected product search queries and a catalog of around 5 million products. For each query, the top 120 products are retrieved.</p>
</div>
</li>
<li class="ltx_item" id="A1.S3.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S3.I1.i4.p1">
<p class="ltx_p" id="A1.S3.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S3.I1.i4.p1.1.1">Walmart query log dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">magnani2019neural</span>]</cite>:
This is a large query log dataset on shoe segments during a six-month window from May 2018 to October 2018 on Walmart.com. Historical data of the extra features such as clicks and orders are collected from the query log six months before May 2018. The dataset is composed of more than 100 million query and product pairs, of which there are more than 1 million unique queries and more than 1 million unique item titles.</p>
</div>
</li>
<li class="ltx_item" id="A1.S3.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S3.I1.i5.p1">
<p class="ltx_p" id="A1.S3.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S3.I1.i5.p1.1.1">Bestbuy dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">duan2013supporting</span>]</cite>:
The dataset consists of a full crawl of the “Laptop &amp; Netbook Computers” category of Bestbuy.com. In total, there are 864 laptops in the database, each entity has 44 specifications on average. And 260 laptops have user reviews. The annotated datasets contain 40 queries, on average, there are 2.8 keywords per query and 3.8 keywords per query for the hard queries.</p>
</div>
</li>
<li class="ltx_item" id="A1.S3.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S3.I1.i6.p1">
<p class="ltx_p" id="A1.S3.I1.i6.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S3.I1.i6.p1.1.1">Amazon product dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bi2020learning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">mcauley2015image</span>]</cite>:
The Amazon product dataset is a well-known benchmark for product search and recommendation. It contains information for millions of customers, products and associated metadata, including descriptions, reviews, brands, and categories.<span class="ltx_note ltx_role_footnote" id="A1.footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="http://jmcauley.ucsd.edu/data/amazon" title="">http://jmcauley.ucsd.edu/data/amazon</a></span></span></span></p>
</div>
</li>
<li class="ltx_item" id="A1.S3.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S3.I1.i7.p1">
<p class="ltx_p" id="A1.S3.I1.i7.p1.6"><span class="ltx_text ltx_font_bold" id="A1.S3.I1.i7.p1.6.1">Etsy product search dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span>]</cite>:
The dataset contains 4 weeks worth of search log data with clicks and purchases from Etsy.<span class="ltx_note ltx_role_footnote" id="A1.footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.etsy.com" title="">https://www.etsy.com</a></span></span></span> In total, there are <math alttext="334,931" class="ltx_Math" display="inline" id="A1.S3.I1.i7.p1.1.m1.2"><semantics id="A1.S3.I1.i7.p1.1.m1.2a"><mrow id="A1.S3.I1.i7.p1.1.m1.2.3.2" xref="A1.S3.I1.i7.p1.1.m1.2.3.1.cmml"><mn id="A1.S3.I1.i7.p1.1.m1.1.1" xref="A1.S3.I1.i7.p1.1.m1.1.1.cmml">334</mn><mo id="A1.S3.I1.i7.p1.1.m1.2.3.2.1" xref="A1.S3.I1.i7.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.S3.I1.i7.p1.1.m1.2.2" xref="A1.S3.I1.i7.p1.1.m1.2.2.cmml">931</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S3.I1.i7.p1.1.m1.2b"><list id="A1.S3.I1.i7.p1.1.m1.2.3.1.cmml" xref="A1.S3.I1.i7.p1.1.m1.2.3.2"><cn id="A1.S3.I1.i7.p1.1.m1.1.1.cmml" type="integer" xref="A1.S3.I1.i7.p1.1.m1.1.1">334</cn><cn id="A1.S3.I1.i7.p1.1.m1.2.2.cmml" type="integer" xref="A1.S3.I1.i7.p1.1.m1.2.2">931</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S3.I1.i7.p1.1.m1.2c">334,931</annotation><annotation encoding="application/x-llamapun" id="A1.S3.I1.i7.p1.1.m1.2d">334 , 931</annotation></semantics></math> search sessions with <math alttext="239,928" class="ltx_Math" display="inline" id="A1.S3.I1.i7.p1.2.m2.2"><semantics id="A1.S3.I1.i7.p1.2.m2.2a"><mrow id="A1.S3.I1.i7.p1.2.m2.2.3.2" xref="A1.S3.I1.i7.p1.2.m2.2.3.1.cmml"><mn id="A1.S3.I1.i7.p1.2.m2.1.1" xref="A1.S3.I1.i7.p1.2.m2.1.1.cmml">239</mn><mo id="A1.S3.I1.i7.p1.2.m2.2.3.2.1" xref="A1.S3.I1.i7.p1.2.m2.2.3.1.cmml">,</mo><mn id="A1.S3.I1.i7.p1.2.m2.2.2" xref="A1.S3.I1.i7.p1.2.m2.2.2.cmml">928</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S3.I1.i7.p1.2.m2.2b"><list id="A1.S3.I1.i7.p1.2.m2.2.3.1.cmml" xref="A1.S3.I1.i7.p1.2.m2.2.3.2"><cn id="A1.S3.I1.i7.p1.2.m2.1.1.cmml" type="integer" xref="A1.S3.I1.i7.p1.2.m2.1.1">239</cn><cn id="A1.S3.I1.i7.p1.2.m2.2.2.cmml" type="integer" xref="A1.S3.I1.i7.p1.2.m2.2.2">928</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S3.I1.i7.p1.2.m2.2c">239,928</annotation><annotation encoding="application/x-llamapun" id="A1.S3.I1.i7.p1.2.m2.2d">239 , 928</annotation></semantics></math> queries and <math alttext="6,347,251" class="ltx_Math" display="inline" id="A1.S3.I1.i7.p1.3.m3.3"><semantics id="A1.S3.I1.i7.p1.3.m3.3a"><mrow id="A1.S3.I1.i7.p1.3.m3.3.4.2" xref="A1.S3.I1.i7.p1.3.m3.3.4.1.cmml"><mn id="A1.S3.I1.i7.p1.3.m3.1.1" xref="A1.S3.I1.i7.p1.3.m3.1.1.cmml">6</mn><mo id="A1.S3.I1.i7.p1.3.m3.3.4.2.1" xref="A1.S3.I1.i7.p1.3.m3.3.4.1.cmml">,</mo><mn id="A1.S3.I1.i7.p1.3.m3.2.2" xref="A1.S3.I1.i7.p1.3.m3.2.2.cmml">347</mn><mo id="A1.S3.I1.i7.p1.3.m3.3.4.2.2" xref="A1.S3.I1.i7.p1.3.m3.3.4.1.cmml">,</mo><mn id="A1.S3.I1.i7.p1.3.m3.3.3" xref="A1.S3.I1.i7.p1.3.m3.3.3.cmml">251</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S3.I1.i7.p1.3.m3.3b"><list id="A1.S3.I1.i7.p1.3.m3.3.4.1.cmml" xref="A1.S3.I1.i7.p1.3.m3.3.4.2"><cn id="A1.S3.I1.i7.p1.3.m3.1.1.cmml" type="integer" xref="A1.S3.I1.i7.p1.3.m3.1.1">6</cn><cn id="A1.S3.I1.i7.p1.3.m3.2.2.cmml" type="integer" xref="A1.S3.I1.i7.p1.3.m3.2.2">347</cn><cn id="A1.S3.I1.i7.p1.3.m3.3.3.cmml" type="integer" xref="A1.S3.I1.i7.p1.3.m3.3.3">251</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S3.I1.i7.p1.3.m3.3c">6,347,251</annotation><annotation encoding="application/x-llamapun" id="A1.S3.I1.i7.p1.3.m3.3d">6 , 347 , 251</annotation></semantics></math> items. In total, <math alttext="270,239" class="ltx_Math" display="inline" id="A1.S3.I1.i7.p1.4.m4.2"><semantics id="A1.S3.I1.i7.p1.4.m4.2a"><mrow id="A1.S3.I1.i7.p1.4.m4.2.3.2" xref="A1.S3.I1.i7.p1.4.m4.2.3.1.cmml"><mn id="A1.S3.I1.i7.p1.4.m4.1.1" xref="A1.S3.I1.i7.p1.4.m4.1.1.cmml">270</mn><mo id="A1.S3.I1.i7.p1.4.m4.2.3.2.1" xref="A1.S3.I1.i7.p1.4.m4.2.3.1.cmml">,</mo><mn id="A1.S3.I1.i7.p1.4.m4.2.2" xref="A1.S3.I1.i7.p1.4.m4.2.2.cmml">239</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S3.I1.i7.p1.4.m4.2b"><list id="A1.S3.I1.i7.p1.4.m4.2.3.1.cmml" xref="A1.S3.I1.i7.p1.4.m4.2.3.2"><cn id="A1.S3.I1.i7.p1.4.m4.1.1.cmml" type="integer" xref="A1.S3.I1.i7.p1.4.m4.1.1">270</cn><cn id="A1.S3.I1.i7.p1.4.m4.2.2.cmml" type="integer" xref="A1.S3.I1.i7.p1.4.m4.2.2">239</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S3.I1.i7.p1.4.m4.2c">270,239</annotation><annotation encoding="application/x-llamapun" id="A1.S3.I1.i7.p1.4.m4.2d">270 , 239</annotation></semantics></math> buyers and <math alttext="550,025" class="ltx_Math" display="inline" id="A1.S3.I1.i7.p1.5.m5.2"><semantics id="A1.S3.I1.i7.p1.5.m5.2a"><mrow id="A1.S3.I1.i7.p1.5.m5.2.3.2" xref="A1.S3.I1.i7.p1.5.m5.2.3.1.cmml"><mn id="A1.S3.I1.i7.p1.5.m5.1.1" xref="A1.S3.I1.i7.p1.5.m5.1.1.cmml">550</mn><mo id="A1.S3.I1.i7.p1.5.m5.2.3.2.1" xref="A1.S3.I1.i7.p1.5.m5.2.3.1.cmml">,</mo><mn id="A1.S3.I1.i7.p1.5.m5.2.2" xref="A1.S3.I1.i7.p1.5.m5.2.2.cmml">025</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S3.I1.i7.p1.5.m5.2b"><list id="A1.S3.I1.i7.p1.5.m5.2.3.1.cmml" xref="A1.S3.I1.i7.p1.5.m5.2.3.2"><cn id="A1.S3.I1.i7.p1.5.m5.1.1.cmml" type="integer" xref="A1.S3.I1.i7.p1.5.m5.1.1">550</cn><cn id="A1.S3.I1.i7.p1.5.m5.2.2.cmml" type="integer" xref="A1.S3.I1.i7.p1.5.m5.2.2">025</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S3.I1.i7.p1.5.m5.2c">550,025</annotation><annotation encoding="application/x-llamapun" id="A1.S3.I1.i7.p1.5.m5.2d">550 , 025</annotation></semantics></math> sellers are involved in the transactions, whereas <math alttext="631,778" class="ltx_Math" display="inline" id="A1.S3.I1.i7.p1.6.m6.2"><semantics id="A1.S3.I1.i7.p1.6.m6.2a"><mrow id="A1.S3.I1.i7.p1.6.m6.2.3.2" xref="A1.S3.I1.i7.p1.6.m6.2.3.1.cmml"><mn id="A1.S3.I1.i7.p1.6.m6.1.1" xref="A1.S3.I1.i7.p1.6.m6.1.1.cmml">631</mn><mo id="A1.S3.I1.i7.p1.6.m6.2.3.2.1" xref="A1.S3.I1.i7.p1.6.m6.2.3.1.cmml">,</mo><mn id="A1.S3.I1.i7.p1.6.m6.2.2" xref="A1.S3.I1.i7.p1.6.m6.2.2.cmml">778</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S3.I1.i7.p1.6.m6.2b"><list id="A1.S3.I1.i7.p1.6.m6.2.3.1.cmml" xref="A1.S3.I1.i7.p1.6.m6.2.3.2"><cn id="A1.S3.I1.i7.p1.6.m6.1.1.cmml" type="integer" xref="A1.S3.I1.i7.p1.6.m6.1.1">631</cn><cn id="A1.S3.I1.i7.p1.6.m6.2.2.cmml" type="integer" xref="A1.S3.I1.i7.p1.6.m6.2.2">778</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S3.I1.i7.p1.6.m6.2c">631,778</annotation><annotation encoding="application/x-llamapun" id="A1.S3.I1.i7.p1.6.m6.2d">631 , 778</annotation></semantics></math> keywords are used by sellers to describe their items.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="A1.S3.p3">
<p class="ltx_p" id="A1.S3.p3.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#A1.T3" title="Table A.3 ‣ A.3 Datasets for e-commerce search ‣ Appendix A Datasets ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">A.3</span></a> summarizes the key statistics of the datasets listed above.</p>
</div>
<div class="ltx_table ltx_transformed_outer" id="A1.T3" style="width:154.3pt;height:515.5pt;vertical-align:-0.0pt;"><div class="ltx_transformed_inner" style="width:515.5pt;transform:translate(-180.57pt,-175.29pt) rotate(-90deg) ;"><figure>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table A.3: </span>Statistics of datasets about e-commerce search.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T3.3" style="width:512.1pt;height:144.5pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-128.6pt,36.1pt) scale(0.665704412817294,0.665704412817294) ;">
<table class="ltx_tabular ltx_align_middle" id="A1.T3.3.3">
<tr class="ltx_tr" id="A1.T3.3.3.4">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T3.3.3.4.1" rowspan="2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T3.3.3.4.1.1">Datasets</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="A1.T3.3.3.4.2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T3.3.3.4.2.1">Statistics</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T3.3.3.4.3" rowspan="2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T3.3.3.4.3.1">References</span></td>
</tr>
<tr class="ltx_tr" id="A1.T3.3.3.5">
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T3.3.3.5.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Queries</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T3.3.3.5.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Products</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T3.3.3.5.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Pairs</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T3.3.3.5.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">Product title length</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T3.3.3.5.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">Vocabulary size</td>
</tr>
<tr class="ltx_tr" id="A1.T3.3.3.6">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T3.3.3.6.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">QUARTS e-commerce search dataset</td>
<td class="ltx_td ltx_border_t" id="A1.T3.3.3.6.2" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_border_t" id="A1.T3.3.3.6.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T3.3.3.6.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">3,200,000</td>
<td class="ltx_td ltx_border_t" id="A1.T3.3.3.6.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_border_t" id="A1.T3.3.3.6.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T3.3.3.6.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">nguyen2020learning</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T3.3.3.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T3.3.3.7.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">SCEM product search dataset</td>
<td class="ltx_td ltx_border_t" id="A1.T3.3.3.7.2" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_border_t" id="A1.T3.3.3.7.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_border_t" id="A1.T3.3.3.7.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_border_t" id="A1.T3.3.3.7.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_border_t" id="A1.T3.3.3.7.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T3.3.3.7.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bi2019leverage</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T3.1.1.1">
<td class="ltx_td ltx_align_left" id="A1.T3.1.1.1.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">SCEM-Toys&amp;Games</td>
<td class="ltx_td" id="A1.T3.1.1.1.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T3.1.1.1.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T3.1.1.1.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_right" id="A1.T3.1.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">13.14<math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.1.1.1.1.m1.1"><semantics id="A1.T3.1.1.1.1.m1.1a"><mo id="A1.T3.1.1.1.1.m1.1.1" xref="A1.T3.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.1.1.1.1.m1.1b"><csymbol cd="latexml" id="A1.T3.1.1.1.1.m1.1.1.cmml" xref="A1.T3.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.1.1.1.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.1.1.1.1.m1.1d">±</annotation></semantics></math>6.46</td>
<td class="ltx_td ltx_align_right" id="A1.T3.1.1.1.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">381,620</td>
<td class="ltx_td" id="A1.T3.1.1.1.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
</tr>
<tr class="ltx_tr" id="A1.T3.2.2.2">
<td class="ltx_td ltx_align_left" id="A1.T3.2.2.2.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">SCEM-Garden&amp;Outdoor</td>
<td class="ltx_td" id="A1.T3.2.2.2.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T3.2.2.2.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T3.2.2.2.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_right" id="A1.T3.2.2.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">16.39<math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.2.2.2.1.m1.1"><semantics id="A1.T3.2.2.2.1.m1.1a"><mo id="A1.T3.2.2.2.1.m1.1.1" xref="A1.T3.2.2.2.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.2.2.2.1.m1.1b"><csymbol cd="latexml" id="A1.T3.2.2.2.1.m1.1.1.cmml" xref="A1.T3.2.2.2.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.2.2.2.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.2.2.2.1.m1.1d">±</annotation></semantics></math>7.38</td>
<td class="ltx_td ltx_align_right" id="A1.T3.2.2.2.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">1,054,980</td>
<td class="ltx_td" id="A1.T3.2.2.2.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
</tr>
<tr class="ltx_tr" id="A1.T3.3.3.3">
<td class="ltx_td ltx_align_left" id="A1.T3.3.3.3.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">SCEM-CellPhones&amp;Accessories</td>
<td class="ltx_td" id="A1.T3.3.3.3.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T3.3.3.3.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T3.3.3.3.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_right" id="A1.T3.3.3.3.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">22.02<math alttext="\pm" class="ltx_Math" display="inline" id="A1.T3.3.3.3.1.m1.1"><semantics id="A1.T3.3.3.3.1.m1.1a"><mo id="A1.T3.3.3.3.1.m1.1.1" xref="A1.T3.3.3.3.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="A1.T3.3.3.3.1.m1.1b"><csymbol cd="latexml" id="A1.T3.3.3.3.1.m1.1.1.cmml" xref="A1.T3.3.3.3.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="A1.T3.3.3.3.1.m1.1c">\pm</annotation><annotation encoding="application/x-llamapun" id="A1.T3.3.3.3.1.m1.1d">±</annotation></semantics></math>7.34</td>
<td class="ltx_td ltx_align_right" id="A1.T3.3.3.3.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">194,022</td>
<td class="ltx_td" id="A1.T3.3.3.3.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
</tr>
<tr class="ltx_tr" id="A1.T3.3.3.8">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T3.3.3.8.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Walmart product search dataset</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T3.3.3.8.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">2,800</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T3.3.3.8.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">5,000,000</td>
<td class="ltx_td ltx_border_t" id="A1.T3.3.3.8.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_border_t" id="A1.T3.3.3.8.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_border_t" id="A1.T3.3.3.8.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T3.3.3.8.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">karmaker2017application</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T3.3.3.9">
<td class="ltx_td ltx_align_left" id="A1.T3.3.3.9.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Walmart query log dataset</td>
<td class="ltx_td ltx_align_right" id="A1.T3.3.3.9.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">1,000,000+</td>
<td class="ltx_td ltx_align_right" id="A1.T3.3.3.9.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">1,000,000+</td>
<td class="ltx_td ltx_align_right" id="A1.T3.3.3.9.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">100,000,000+</td>
<td class="ltx_td" id="A1.T3.3.3.9.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T3.3.3.9.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left" id="A1.T3.3.3.9.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">magnani2019neural</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T3.3.3.10">
<td class="ltx_td ltx_align_left" id="A1.T3.3.3.10.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Bestbuy dataset</td>
<td class="ltx_td ltx_align_right" id="A1.T3.3.3.10.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">40</td>
<td class="ltx_td ltx_align_right" id="A1.T3.3.3.10.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">864</td>
<td class="ltx_td" id="A1.T3.3.3.10.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T3.3.3.10.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T3.3.3.10.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left" id="A1.T3.3.3.10.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">duan2013supporting</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T3.3.3.11">
<td class="ltx_td ltx_align_left" id="A1.T3.3.3.11.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Amazon product dataset</td>
<td class="ltx_td" id="A1.T3.3.3.11.2" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T3.3.3.11.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T3.3.3.11.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T3.3.3.11.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T3.3.3.11.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left" id="A1.T3.3.3.11.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">bi2020learning</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">mcauley2015image</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T3.3.3.12">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T3.3.3.12.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Etsy product search dataset</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T3.3.3.12.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">239,928</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T3.3.3.12.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">6,347,251</td>
<td class="ltx_td ltx_border_bb" id="A1.T3.3.3.12.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T3.3.3.12.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">26.5</td>
<td class="ltx_td ltx_border_bb" id="A1.T3.3.3.12.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T3.3.3.12.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">wu2018turning</span>]</cite></td>
</tr>
</table>
</span></div>
</figure></div></div>
</section>
<section class="ltx_section" id="A1.S4">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">A.4 </span>Datasets for e-commerce recommendations</h3>
<div class="ltx_para" id="A1.S4.p1">
<p class="ltx_p" id="A1.S4.p1.1">Next, we list benchmark datasets about e-commerce recommender systems:</p>
</div>
<div class="ltx_para" id="A1.S4.p2">
<ul class="ltx_itemize" id="A1.S4.I1">
<li class="ltx_item" id="A1.S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S4.I1.i1.p1">
<p class="ltx_p" id="A1.S4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S4.I1.i1.p1.1.1">Amazon product dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">he2016ups</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">mcauley2015image</span>]</cite>:
For e-commerce recommendations, the Amazon product dataset is split by top-level product categories in amazon and is notable for its high sparsity and variability.
This dataset contains product reviews and metadata from Amazon, including 142.8 million reviews spanning May 1996 – July 2014. This dataset includes reviews (i.e., ratings, text, helpfulness votes), product metadata (i.e., descriptions, category information, price, brand, and image features), and links (i.e., substitutive/complementary relations).</p>
</div>
</li>
<li class="ltx_item" id="A1.S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S4.I1.i2.p1">
<p class="ltx_p" id="A1.S4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S4.I1.i2.p1.1.1">Amazon soc dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mcauley2015image</span>]</cite>:
A large-scale database of 230,000 users; each data sample includes a user’s profile, user feedback on a product, and social relationship among users. More specifically, the user’s profile includes gender, income, age, and hobby. User feedback includes the user’s comments and browsing history.</p>
</div>
</li>
<li class="ltx_item" id="A1.S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S4.I1.i3.p1">
<p class="ltx_p" id="A1.S4.I1.i3.p1.3"><span class="ltx_text ltx_font_bold" id="A1.S4.I1.i3.p1.3.1">AliExpress dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ahmed2021deep</span>]</cite>:
This dataset is collected from an online retailer service owned by the Alibaba group.
There are about <math alttext="2,260,923" class="ltx_Math" display="inline" id="A1.S4.I1.i3.p1.1.m1.3"><semantics id="A1.S4.I1.i3.p1.1.m1.3a"><mrow id="A1.S4.I1.i3.p1.1.m1.3.4.2" xref="A1.S4.I1.i3.p1.1.m1.3.4.1.cmml"><mn id="A1.S4.I1.i3.p1.1.m1.1.1" xref="A1.S4.I1.i3.p1.1.m1.1.1.cmml">2</mn><mo id="A1.S4.I1.i3.p1.1.m1.3.4.2.1" xref="A1.S4.I1.i3.p1.1.m1.3.4.1.cmml">,</mo><mn id="A1.S4.I1.i3.p1.1.m1.2.2" xref="A1.S4.I1.i3.p1.1.m1.2.2.cmml">260</mn><mo id="A1.S4.I1.i3.p1.1.m1.3.4.2.2" xref="A1.S4.I1.i3.p1.1.m1.3.4.1.cmml">,</mo><mn id="A1.S4.I1.i3.p1.1.m1.3.3" xref="A1.S4.I1.i3.p1.1.m1.3.3.cmml">923</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S4.I1.i3.p1.1.m1.3b"><list id="A1.S4.I1.i3.p1.1.m1.3.4.1.cmml" xref="A1.S4.I1.i3.p1.1.m1.3.4.2"><cn id="A1.S4.I1.i3.p1.1.m1.1.1.cmml" type="integer" xref="A1.S4.I1.i3.p1.1.m1.1.1">2</cn><cn id="A1.S4.I1.i3.p1.1.m1.2.2.cmml" type="integer" xref="A1.S4.I1.i3.p1.1.m1.2.2">260</cn><cn id="A1.S4.I1.i3.p1.1.m1.3.3.cmml" type="integer" xref="A1.S4.I1.i3.p1.1.m1.3.3">923</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S4.I1.i3.p1.1.m1.3c">2,260,923</annotation><annotation encoding="application/x-llamapun" id="A1.S4.I1.i3.p1.1.m1.3d">2 , 260 , 923</annotation></semantics></math> records from AliExpress, the data for about fourteen months from January 1, 2019 to February 23, 2020. The dataset contains <math alttext="1506,850" class="ltx_Math" display="inline" id="A1.S4.I1.i3.p1.2.m2.2"><semantics id="A1.S4.I1.i3.p1.2.m2.2a"><mrow id="A1.S4.I1.i3.p1.2.m2.2.3.2" xref="A1.S4.I1.i3.p1.2.m2.2.3.1.cmml"><mn id="A1.S4.I1.i3.p1.2.m2.1.1" xref="A1.S4.I1.i3.p1.2.m2.1.1.cmml">1506</mn><mo id="A1.S4.I1.i3.p1.2.m2.2.3.2.1" xref="A1.S4.I1.i3.p1.2.m2.2.3.1.cmml">,</mo><mn id="A1.S4.I1.i3.p1.2.m2.2.2" xref="A1.S4.I1.i3.p1.2.m2.2.2.cmml">850</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S4.I1.i3.p1.2.m2.2b"><list id="A1.S4.I1.i3.p1.2.m2.2.3.1.cmml" xref="A1.S4.I1.i3.p1.2.m2.2.3.2"><cn id="A1.S4.I1.i3.p1.2.m2.1.1.cmml" type="integer" xref="A1.S4.I1.i3.p1.2.m2.1.1">1506</cn><cn id="A1.S4.I1.i3.p1.2.m2.2.2.cmml" type="integer" xref="A1.S4.I1.i3.p1.2.m2.2.2">850</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S4.I1.i3.p1.2.m2.2c">1506,850</annotation><annotation encoding="application/x-llamapun" id="A1.S4.I1.i3.p1.2.m2.2d">1506 , 850</annotation></semantics></math> users that submitted the reviews against <math alttext="49,221" class="ltx_Math" display="inline" id="A1.S4.I1.i3.p1.3.m3.2"><semantics id="A1.S4.I1.i3.p1.3.m3.2a"><mrow id="A1.S4.I1.i3.p1.3.m3.2.3.2" xref="A1.S4.I1.i3.p1.3.m3.2.3.1.cmml"><mn id="A1.S4.I1.i3.p1.3.m3.1.1" xref="A1.S4.I1.i3.p1.3.m3.1.1.cmml">49</mn><mo id="A1.S4.I1.i3.p1.3.m3.2.3.2.1" xref="A1.S4.I1.i3.p1.3.m3.2.3.1.cmml">,</mo><mn id="A1.S4.I1.i3.p1.3.m3.2.2" xref="A1.S4.I1.i3.p1.3.m3.2.2.cmml">221</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S4.I1.i3.p1.3.m3.2b"><list id="A1.S4.I1.i3.p1.3.m3.2.3.1.cmml" xref="A1.S4.I1.i3.p1.3.m3.2.3.2"><cn id="A1.S4.I1.i3.p1.3.m3.1.1.cmml" type="integer" xref="A1.S4.I1.i3.p1.3.m3.1.1">49</cn><cn id="A1.S4.I1.i3.p1.3.m3.2.2.cmml" type="integer" xref="A1.S4.I1.i3.p1.3.m3.2.2">221</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S4.I1.i3.p1.3.m3.2c">49,221</annotation><annotation encoding="application/x-llamapun" id="A1.S4.I1.i3.p1.3.m3.2d">49 , 221</annotation></semantics></math> items in 205 different categories, such as electronic, entertainment, education, house, and garden, etc., and the items are rated from 1 to 5 scale.</p>
</div>
</li>
<li class="ltx_item" id="A1.S4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S4.I1.i4.p1">
<p class="ltx_p" id="A1.S4.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S4.I1.i4.p1.1.1">Instacart orders dataset</span>:
This is an anonymized dataset collected from the Instacart site.<span class="ltx_note ltx_role_footnote" id="A1.footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.instacart.com" title="">https://www.instacart.com</a></span></span></span> It contains a sample of over 3 million grocery orders from more than 200,000 Instacart users. For each user, 4 and 100 of his/her orders are provided, with the sequence of products purchased in each order. There are also the week and hour of the day the order was placed and a relative measure of time between orders.<span class="ltx_note ltx_role_footnote" id="A1.footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.instacart.com/datasets/grocery-shopping-2017" title="">https://www.instacart.com/datasets/grocery-shopping-2017</a></span></span></span></p>
</div>
</li>
<li class="ltx_item" id="A1.S4.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S4.I1.i5.p1">
<p class="ltx_p" id="A1.S4.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S4.I1.i5.p1.1.1">Movielens dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">harper2015movielens</span>]</cite>:
This is a widely used benchmark dataset collected from <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://movielens.org" title="">https://movielens.org</a>.
The dataset contains user ratings and timestamps for the movie. There is side-info of users and movies. According to the year and the size of the dataset, there are multiple specific versions.<span class="ltx_note ltx_role_footnote" id="A1.footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://grouplens.org/datasets/movielens/" title="">https://grouplens.org/datasets/movielens/</a></span></span></span></p>
</div>
</li>
<li class="ltx_item" id="A1.S4.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S4.I1.i6.p1">
<p class="ltx_p" id="A1.S4.I1.i6.p1.4"><span class="ltx_text ltx_font_bold" id="A1.S4.I1.i6.p1.4.1">Yoochoose dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ben2015recsys</span>]</cite>:
This dataset is collected from the 2015 recommender systems challenge (RecSys Challenge 2015).
The dataset includes six months of user activities for a large European e-commerce business that sells various consumer goods, including garden tools, toys, clothes, electronics, and more. There are <math alttext="33,040,175" class="ltx_Math" display="inline" id="A1.S4.I1.i6.p1.1.m1.3"><semantics id="A1.S4.I1.i6.p1.1.m1.3a"><mrow id="A1.S4.I1.i6.p1.1.m1.3.4.2" xref="A1.S4.I1.i6.p1.1.m1.3.4.1.cmml"><mn id="A1.S4.I1.i6.p1.1.m1.1.1" xref="A1.S4.I1.i6.p1.1.m1.1.1.cmml">33</mn><mo id="A1.S4.I1.i6.p1.1.m1.3.4.2.1" xref="A1.S4.I1.i6.p1.1.m1.3.4.1.cmml">,</mo><mn id="A1.S4.I1.i6.p1.1.m1.2.2" xref="A1.S4.I1.i6.p1.1.m1.2.2.cmml">040</mn><mo id="A1.S4.I1.i6.p1.1.m1.3.4.2.2" xref="A1.S4.I1.i6.p1.1.m1.3.4.1.cmml">,</mo><mn id="A1.S4.I1.i6.p1.1.m1.3.3" xref="A1.S4.I1.i6.p1.1.m1.3.3.cmml">175</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S4.I1.i6.p1.1.m1.3b"><list id="A1.S4.I1.i6.p1.1.m1.3.4.1.cmml" xref="A1.S4.I1.i6.p1.1.m1.3.4.2"><cn id="A1.S4.I1.i6.p1.1.m1.1.1.cmml" type="integer" xref="A1.S4.I1.i6.p1.1.m1.1.1">33</cn><cn id="A1.S4.I1.i6.p1.1.m1.2.2.cmml" type="integer" xref="A1.S4.I1.i6.p1.1.m1.2.2">040</cn><cn id="A1.S4.I1.i6.p1.1.m1.3.3.cmml" type="integer" xref="A1.S4.I1.i6.p1.1.m1.3.3">175</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S4.I1.i6.p1.1.m1.3c">33,040,175</annotation><annotation encoding="application/x-llamapun" id="A1.S4.I1.i6.p1.1.m1.3d">33 , 040 , 175</annotation></semantics></math> records in the click file and <math alttext="1,177,769" class="ltx_Math" display="inline" id="A1.S4.I1.i6.p1.2.m2.3"><semantics id="A1.S4.I1.i6.p1.2.m2.3a"><mrow id="A1.S4.I1.i6.p1.2.m2.3.4.2" xref="A1.S4.I1.i6.p1.2.m2.3.4.1.cmml"><mn id="A1.S4.I1.i6.p1.2.m2.1.1" xref="A1.S4.I1.i6.p1.2.m2.1.1.cmml">1</mn><mo id="A1.S4.I1.i6.p1.2.m2.3.4.2.1" xref="A1.S4.I1.i6.p1.2.m2.3.4.1.cmml">,</mo><mn id="A1.S4.I1.i6.p1.2.m2.2.2" xref="A1.S4.I1.i6.p1.2.m2.2.2.cmml">177</mn><mo id="A1.S4.I1.i6.p1.2.m2.3.4.2.2" xref="A1.S4.I1.i6.p1.2.m2.3.4.1.cmml">,</mo><mn id="A1.S4.I1.i6.p1.2.m2.3.3" xref="A1.S4.I1.i6.p1.2.m2.3.3.cmml">769</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S4.I1.i6.p1.2.m2.3b"><list id="A1.S4.I1.i6.p1.2.m2.3.4.1.cmml" xref="A1.S4.I1.i6.p1.2.m2.3.4.2"><cn id="A1.S4.I1.i6.p1.2.m2.1.1.cmml" type="integer" xref="A1.S4.I1.i6.p1.2.m2.1.1">1</cn><cn id="A1.S4.I1.i6.p1.2.m2.2.2.cmml" type="integer" xref="A1.S4.I1.i6.p1.2.m2.2.2">177</cn><cn id="A1.S4.I1.i6.p1.2.m2.3.3.cmml" type="integer" xref="A1.S4.I1.i6.p1.2.m2.3.3">769</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S4.I1.i6.p1.2.m2.3c">1,177,769</annotation><annotation encoding="application/x-llamapun" id="A1.S4.I1.i6.p1.2.m2.3d">1 , 177 , 769</annotation></semantics></math> records in the buys file.
The training set consists of <math alttext="9,512,786" class="ltx_Math" display="inline" id="A1.S4.I1.i6.p1.3.m3.3"><semantics id="A1.S4.I1.i6.p1.3.m3.3a"><mrow id="A1.S4.I1.i6.p1.3.m3.3.4.2" xref="A1.S4.I1.i6.p1.3.m3.3.4.1.cmml"><mn id="A1.S4.I1.i6.p1.3.m3.1.1" xref="A1.S4.I1.i6.p1.3.m3.1.1.cmml">9</mn><mo id="A1.S4.I1.i6.p1.3.m3.3.4.2.1" xref="A1.S4.I1.i6.p1.3.m3.3.4.1.cmml">,</mo><mn id="A1.S4.I1.i6.p1.3.m3.2.2" xref="A1.S4.I1.i6.p1.3.m3.2.2.cmml">512</mn><mo id="A1.S4.I1.i6.p1.3.m3.3.4.2.2" xref="A1.S4.I1.i6.p1.3.m3.3.4.1.cmml">,</mo><mn id="A1.S4.I1.i6.p1.3.m3.3.3" xref="A1.S4.I1.i6.p1.3.m3.3.3.cmml">786</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S4.I1.i6.p1.3.m3.3b"><list id="A1.S4.I1.i6.p1.3.m3.3.4.1.cmml" xref="A1.S4.I1.i6.p1.3.m3.3.4.2"><cn id="A1.S4.I1.i6.p1.3.m3.1.1.cmml" type="integer" xref="A1.S4.I1.i6.p1.3.m3.1.1">9</cn><cn id="A1.S4.I1.i6.p1.3.m3.2.2.cmml" type="integer" xref="A1.S4.I1.i6.p1.3.m3.2.2">512</cn><cn id="A1.S4.I1.i6.p1.3.m3.3.3.cmml" type="integer" xref="A1.S4.I1.i6.p1.3.m3.3.3">786</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S4.I1.i6.p1.3.m3.3c">9,512,786</annotation><annotation encoding="application/x-llamapun" id="A1.S4.I1.i6.p1.3.m3.3d">9 , 512 , 786</annotation></semantics></math> unique sessions, and the test file consists of <math alttext="2,312,432" class="ltx_Math" display="inline" id="A1.S4.I1.i6.p1.4.m4.3"><semantics id="A1.S4.I1.i6.p1.4.m4.3a"><mrow id="A1.S4.I1.i6.p1.4.m4.3.4.2" xref="A1.S4.I1.i6.p1.4.m4.3.4.1.cmml"><mn id="A1.S4.I1.i6.p1.4.m4.1.1" xref="A1.S4.I1.i6.p1.4.m4.1.1.cmml">2</mn><mo id="A1.S4.I1.i6.p1.4.m4.3.4.2.1" xref="A1.S4.I1.i6.p1.4.m4.3.4.1.cmml">,</mo><mn id="A1.S4.I1.i6.p1.4.m4.2.2" xref="A1.S4.I1.i6.p1.4.m4.2.2.cmml">312</mn><mo id="A1.S4.I1.i6.p1.4.m4.3.4.2.2" xref="A1.S4.I1.i6.p1.4.m4.3.4.1.cmml">,</mo><mn id="A1.S4.I1.i6.p1.4.m4.3.3" xref="A1.S4.I1.i6.p1.4.m4.3.3.cmml">432</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S4.I1.i6.p1.4.m4.3b"><list id="A1.S4.I1.i6.p1.4.m4.3.4.1.cmml" xref="A1.S4.I1.i6.p1.4.m4.3.4.2"><cn id="A1.S4.I1.i6.p1.4.m4.1.1.cmml" type="integer" xref="A1.S4.I1.i6.p1.4.m4.1.1">2</cn><cn id="A1.S4.I1.i6.p1.4.m4.2.2.cmml" type="integer" xref="A1.S4.I1.i6.p1.4.m4.2.2">312</cn><cn id="A1.S4.I1.i6.p1.4.m4.3.3.cmml" type="integer" xref="A1.S4.I1.i6.p1.4.m4.3.3">432</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S4.I1.i6.p1.4.m4.3c">2,312,432</annotation><annotation encoding="application/x-llamapun" id="A1.S4.I1.i6.p1.4.m4.3d">2 , 312 , 432</annotation></semantics></math> click sessions.</p>
</div>
</li>
<li class="ltx_item" id="A1.S4.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S4.I1.i7.p1">
<p class="ltx_p" id="A1.S4.I1.i7.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S4.I1.i7.p1.1.1">Alibaba Cloud/TIANCHI dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhu2018learning</span>]</cite>:
The dataset was randomly selected from Taobao; it contains about 1 million users with their behavior, which includes clicks, purchases, adding items to the shopping cart, and item favoring from November 25 to December 3, 2017. The dataset is organized in a very similar form to MovieLens-20M, i.e., each line represents a specific user-item interaction, which consists of user ID, item ID, item’s category ID, behavior type, and timestamp, separated by commas.<span class="ltx_note ltx_role_footnote" id="A1.footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://tianchi.aliyun.com/dataset/dataDetail?dataId=649&amp;userId=1&amp;lang=en-us" title="">https://tianchi.aliyun.com/dataset/dataDetail?dataId=649&amp;userId=1&amp;lang=en-us</a></span></span></span></p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="A1.S4.p3">
<p class="ltx_p" id="A1.S4.p3.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#A1.T4" title="Table A.4 ‣ A.4 Datasets for e-commerce recommendations ‣ Appendix A Datasets ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">A.4</span></a> summarizes the key statistics of the datasets listed above.</p>
</div>
<div class="ltx_table ltx_transformed_outer" id="A1.T4" style="width:168.6pt;height:515.5pt;vertical-align:-0.0pt;"><div class="ltx_transformed_inner" style="width:515.5pt;transform:translate(-173.45pt,-168.14pt) rotate(-90deg) ;"><figure>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table A.4: </span>Statistics of datasets about e-commerce recommendations.</figcaption>
<div class="ltx_inline-block ltx_transformed_outer" id="A1.T4.1" style="width:512.1pt;height:158.7pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-94.1pt,29.0pt) scale(0.731292474320407,0.731292474320407) ;">
<table class="ltx_tabular ltx_align_middle" id="A1.T4.1.1">
<tr class="ltx_tr" id="A1.T4.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T4.1.1.1.1" rowspan="2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T4.1.1.1.1.1">Datasets</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="A1.T4.1.1.1.2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T4.1.1.1.2.1">Statistics</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T4.1.1.1.3" rowspan="2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T4.1.1.1.3.1">References</span></td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.1.2">
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.1.1.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Users</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.1.1.2.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Items</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.1.1.2.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Records</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.1.1.2.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Categories</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T4.1.1.2.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">TimeSpan</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T4.1.1.3.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Amazon product dataset</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.1.1.3.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">20,980,320</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.1.1.3.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">5,933,184</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.1.1.3.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">143,663,229</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.1.1.3.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">11</td>
<td class="ltx_td ltx_border_t" id="A1.T4.1.1.3.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T4.1.1.3.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">he2016ups</span>, <span class="ltx_ref ltx_missing_citation ltx_ref_self">mcauley2015image</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.1.4">
<td class="ltx_td ltx_align_left" id="A1.T4.1.1.4.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Amazon soc dataset</td>
<td class="ltx_td ltx_align_right" id="A1.T4.1.1.4.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">230,000</td>
<td class="ltx_td" id="A1.T4.1.1.4.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T4.1.1.4.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T4.1.1.4.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T4.1.1.4.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left" id="A1.T4.1.1.4.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mcauley2015image</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.1.5">
<td class="ltx_td ltx_align_left" id="A1.T4.1.1.5.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">AliExpress dataset</td>
<td class="ltx_td ltx_align_right" id="A1.T4.1.1.5.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">1,506,850</td>
<td class="ltx_td ltx_align_right" id="A1.T4.1.1.5.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">49,221</td>
<td class="ltx_td ltx_align_right" id="A1.T4.1.1.5.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">2,260,923</td>
<td class="ltx_td ltx_align_right" id="A1.T4.1.1.5.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">205</td>
<td class="ltx_td ltx_align_center" id="A1.T4.1.1.5.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">20190101-20200223</td>
<td class="ltx_td ltx_align_left" id="A1.T4.1.1.5.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ahmed2021deep</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.1.6">
<td class="ltx_td ltx_align_left" id="A1.T4.1.1.6.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Instacart orders dataset</td>
<td class="ltx_td ltx_align_right" id="A1.T4.1.1.6.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">200,000+</td>
<td class="ltx_td ltx_align_right" id="A1.T4.1.1.6.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">3,000,000</td>
<td class="ltx_td" id="A1.T4.1.1.6.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T4.1.1.6.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T4.1.1.6.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left" id="A1.T4.1.1.6.7" style="padding-top:2.5pt;padding-bottom:2.5pt;">Instacart dataset<span class="ltx_note ltx_role_footnote" id="A1.footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.instacart.com/datasets/grocery-shopping-2017" title="">https://www.instacart.com/datasets/grocery-shopping-2017</a></span></span></span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.1.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T4.1.1.7.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Movielens-ML100K</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.1.1.7.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">943</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.1.1.7.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">1,682</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.1.1.7.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">100,000</td>
<td class="ltx_td ltx_border_t" id="A1.T4.1.1.7.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T4.1.1.7.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">199709-199804</td>
<td class="ltx_td ltx_border_t" id="A1.T4.1.1.7.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.1.8">
<td class="ltx_td ltx_align_left" id="A1.T4.1.1.8.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Movielens-ML1M</td>
<td class="ltx_td ltx_align_right" id="A1.T4.1.1.8.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">6,040</td>
<td class="ltx_td ltx_align_right" id="A1.T4.1.1.8.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">3,706</td>
<td class="ltx_td ltx_align_right" id="A1.T4.1.1.8.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">1,000,209</td>
<td class="ltx_td" id="A1.T4.1.1.8.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_center" id="A1.T4.1.1.8.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">200004-200302</td>
<td class="ltx_td ltx_align_left" id="A1.T4.1.1.8.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">harper2015movielens</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.1.9">
<td class="ltx_td ltx_align_left" id="A1.T4.1.1.9.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Movielens-ML10M</td>
<td class="ltx_td ltx_align_right" id="A1.T4.1.1.9.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">69,878</td>
<td class="ltx_td ltx_align_right" id="A1.T4.1.1.9.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">10,681</td>
<td class="ltx_td ltx_align_right" id="A1.T4.1.1.9.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">10,000,054</td>
<td class="ltx_td" id="A1.T4.1.1.9.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_center" id="A1.T4.1.1.9.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">199501-200901</td>
<td class="ltx_td" id="A1.T4.1.1.9.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.1.10">
<td class="ltx_td ltx_align_left" id="A1.T4.1.1.10.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Movielens-ML20M</td>
<td class="ltx_td ltx_align_right" id="A1.T4.1.1.10.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">138,493</td>
<td class="ltx_td ltx_align_right" id="A1.T4.1.1.10.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">27,278</td>
<td class="ltx_td ltx_align_right" id="A1.T4.1.1.10.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">20,000,263</td>
<td class="ltx_td" id="A1.T4.1.1.10.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_center" id="A1.T4.1.1.10.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">199501-201503</td>
<td class="ltx_td" id="A1.T4.1.1.10.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.1.11">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T4.1.1.11.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Yoochoose dataset</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.1.1.11.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">9,249,729</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.1.1.11.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">52,739</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T4.1.1.11.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">34,154,697</td>
<td class="ltx_td ltx_border_t" id="A1.T4.1.1.11.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_border_t" id="A1.T4.1.1.11.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T4.1.1.11.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">ben2015recsys</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T4.1.1.12">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T4.1.1.12.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Alibaba Cloud/TIANCHI dataset</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T4.1.1.12.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">1,000,000</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T4.1.1.12.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">4,023,451</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T4.1.1.12.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">100,934,102</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="A1.T4.1.1.12.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">9,378</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T4.1.1.12.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">20171125-20171203</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T4.1.1.12.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhu2018learning</span>]</cite></td>
</tr>
</table>
</span></div>
</figure></div></div>
</section>
<section class="ltx_section" id="A1.S5">
<h3 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">A.5 </span>Datasets for e-commerce QA and dialogues</h3>
<div class="ltx_para" id="A1.S5.p1">
<p class="ltx_p" id="A1.S5.p1.1">Next, we list benchmark datasets about e-commerce question answering and dialogue systems:</p>
</div>
<div class="ltx_para" id="A1.S5.p2">
<ul class="ltx_itemize" id="A1.S5.I1">
<li class="ltx_item" id="A1.S5.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S5.I1.i1.p1">
<p class="ltx_p" id="A1.S5.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S5.I1.i1.p1.1.1">JD product question answering</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gao2019product</span>]</cite>:
This dataset consists of online product-aware QA pairs.
Each QA pair is associated with the reviews and attributes of the corresponding product.
The corpus covers <math alttext="469,953" class="ltx_Math" display="inline" id="A1.S5.I1.i1.p1.1.m1.2"><semantics id="A1.S5.I1.i1.p1.1.m1.2a"><mrow id="A1.S5.I1.i1.p1.1.m1.2.3.2" xref="A1.S5.I1.i1.p1.1.m1.2.3.1.cmml"><mn id="A1.S5.I1.i1.p1.1.m1.1.1" xref="A1.S5.I1.i1.p1.1.m1.1.1.cmml">469</mn><mo id="A1.S5.I1.i1.p1.1.m1.2.3.2.1" xref="A1.S5.I1.i1.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.S5.I1.i1.p1.1.m1.2.2" xref="A1.S5.I1.i1.p1.1.m1.2.2.cmml">953</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S5.I1.i1.p1.1.m1.2b"><list id="A1.S5.I1.i1.p1.1.m1.2.3.1.cmml" xref="A1.S5.I1.i1.p1.1.m1.2.3.2"><cn id="A1.S5.I1.i1.p1.1.m1.1.1.cmml" type="integer" xref="A1.S5.I1.i1.p1.1.m1.1.1">469</cn><cn id="A1.S5.I1.i1.p1.1.m1.2.2.cmml" type="integer" xref="A1.S5.I1.i1.p1.1.m1.2.2">953</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S5.I1.i1.p1.1.m1.2c">469,953</annotation><annotation encoding="application/x-llamapun" id="A1.S5.I1.i1.p1.1.m1.2d">469 , 953</annotation></semantics></math> products and 38 product categories. The average length of the question is 9.03 words, and the ground truth answer is 10.3 words. The average number of attributes is 9.0 key-value pairs.</p>
</div>
</li>
<li class="ltx_item" id="A1.S5.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S5.I1.i2.p1">
<p class="ltx_p" id="A1.S5.I1.i2.p1.4"><span class="ltx_text ltx_font_bold" id="A1.S5.I1.i2.p1.4.1">Taobao question answering dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019driven</span>]</cite>:
This dataset is collected on Taobao. The dataset includes <math alttext="4,457" class="ltx_Math" display="inline" id="A1.S5.I1.i2.p1.1.m1.2"><semantics id="A1.S5.I1.i2.p1.1.m1.2a"><mrow id="A1.S5.I1.i2.p1.1.m1.2.3.2" xref="A1.S5.I1.i2.p1.1.m1.2.3.1.cmml"><mn id="A1.S5.I1.i2.p1.1.m1.1.1" xref="A1.S5.I1.i2.p1.1.m1.1.1.cmml">4</mn><mo id="A1.S5.I1.i2.p1.1.m1.2.3.2.1" xref="A1.S5.I1.i2.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.S5.I1.i2.p1.1.m1.2.2" xref="A1.S5.I1.i2.p1.1.m1.2.2.cmml">457</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S5.I1.i2.p1.1.m1.2b"><list id="A1.S5.I1.i2.p1.1.m1.2.3.1.cmml" xref="A1.S5.I1.i2.p1.1.m1.2.3.2"><cn id="A1.S5.I1.i2.p1.1.m1.1.1.cmml" type="integer" xref="A1.S5.I1.i2.p1.1.m1.1.1">4</cn><cn id="A1.S5.I1.i2.p1.1.m1.2.2.cmml" type="integer" xref="A1.S5.I1.i2.p1.1.m1.2.2">457</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S5.I1.i2.p1.1.m1.2c">4,457</annotation><annotation encoding="application/x-llamapun" id="A1.S5.I1.i2.p1.1.m1.2d">4 , 457</annotation></semantics></math> and <math alttext="47,979" class="ltx_Math" display="inline" id="A1.S5.I1.i2.p1.2.m2.2"><semantics id="A1.S5.I1.i2.p1.2.m2.2a"><mrow id="A1.S5.I1.i2.p1.2.m2.2.3.2" xref="A1.S5.I1.i2.p1.2.m2.2.3.1.cmml"><mn id="A1.S5.I1.i2.p1.2.m2.1.1" xref="A1.S5.I1.i2.p1.2.m2.1.1.cmml">47</mn><mo id="A1.S5.I1.i2.p1.2.m2.2.3.2.1" xref="A1.S5.I1.i2.p1.2.m2.2.3.1.cmml">,</mo><mn id="A1.S5.I1.i2.p1.2.m2.2.2" xref="A1.S5.I1.i2.p1.2.m2.2.2.cmml">979</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S5.I1.i2.p1.2.m2.2b"><list id="A1.S5.I1.i2.p1.2.m2.2.3.1.cmml" xref="A1.S5.I1.i2.p1.2.m2.2.3.2"><cn id="A1.S5.I1.i2.p1.2.m2.1.1.cmml" type="integer" xref="A1.S5.I1.i2.p1.2.m2.1.1">47</cn><cn id="A1.S5.I1.i2.p1.2.m2.2.2.cmml" type="integer" xref="A1.S5.I1.i2.p1.2.m2.2.2">979</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S5.I1.i2.p1.2.m2.2c">47,979</annotation><annotation encoding="application/x-llamapun" id="A1.S5.I1.i2.p1.2.m2.2d">47 , 979</annotation></semantics></math> products under the category Cellphone and Household Electrics, respectively.
For each product, the associated question-answering pairs and user reviews are included. After pre-processing, Cellphone/Household Electrics products have <math alttext="356,842" class="ltx_Math" display="inline" id="A1.S5.I1.i2.p1.3.m3.2"><semantics id="A1.S5.I1.i2.p1.3.m3.2a"><mrow id="A1.S5.I1.i2.p1.3.m3.2.3.2" xref="A1.S5.I1.i2.p1.3.m3.2.3.1.cmml"><mn id="A1.S5.I1.i2.p1.3.m3.1.1" xref="A1.S5.I1.i2.p1.3.m3.1.1.cmml">356</mn><mo id="A1.S5.I1.i2.p1.3.m3.2.3.2.1" xref="A1.S5.I1.i2.p1.3.m3.2.3.1.cmml">,</mo><mn id="A1.S5.I1.i2.p1.3.m3.2.2" xref="A1.S5.I1.i2.p1.3.m3.2.2.cmml">842</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S5.I1.i2.p1.3.m3.2b"><list id="A1.S5.I1.i2.p1.3.m3.2.3.1.cmml" xref="A1.S5.I1.i2.p1.3.m3.2.3.2"><cn id="A1.S5.I1.i2.p1.3.m3.1.1.cmml" type="integer" xref="A1.S5.I1.i2.p1.3.m3.1.1">356</cn><cn id="A1.S5.I1.i2.p1.3.m3.2.2.cmml" type="integer" xref="A1.S5.I1.i2.p1.3.m3.2.2">842</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S5.I1.i2.p1.3.m3.2c">356,842</annotation><annotation encoding="application/x-llamapun" id="A1.S5.I1.i2.p1.3.m3.2d">356 , 842</annotation></semantics></math> and <math alttext="798,688" class="ltx_Math" display="inline" id="A1.S5.I1.i2.p1.4.m4.2"><semantics id="A1.S5.I1.i2.p1.4.m4.2a"><mrow id="A1.S5.I1.i2.p1.4.m4.2.3.2" xref="A1.S5.I1.i2.p1.4.m4.2.3.1.cmml"><mn id="A1.S5.I1.i2.p1.4.m4.1.1" xref="A1.S5.I1.i2.p1.4.m4.1.1.cmml">798</mn><mo id="A1.S5.I1.i2.p1.4.m4.2.3.2.1" xref="A1.S5.I1.i2.p1.4.m4.2.3.1.cmml">,</mo><mn id="A1.S5.I1.i2.p1.4.m4.2.2" xref="A1.S5.I1.i2.p1.4.m4.2.2.cmml">688</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S5.I1.i2.p1.4.m4.2b"><list id="A1.S5.I1.i2.p1.4.m4.2.3.1.cmml" xref="A1.S5.I1.i2.p1.4.m4.2.3.2"><cn id="A1.S5.I1.i2.p1.4.m4.1.1.cmml" type="integer" xref="A1.S5.I1.i2.p1.4.m4.1.1">798</cn><cn id="A1.S5.I1.i2.p1.4.m4.2.2.cmml" type="integer" xref="A1.S5.I1.i2.p1.4.m4.2.2">688</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S5.I1.i2.p1.4.m4.2c">798,688</annotation><annotation encoding="application/x-llamapun" id="A1.S5.I1.i2.p1.4.m4.2d">798 , 688</annotation></semantics></math> QA-pairs in two subsets, respectively.</p>
</div>
</li>
<li class="ltx_item" id="A1.S5.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S5.I1.i3.p1">
<p class="ltx_p" id="A1.S5.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S5.I1.i3.p1.1.1">Amazon complex question/answer dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mcauley2016addressing</span>]</cite>:
This dataset was collected from Amazon, including reviews and descriptions of products and QA data.
This dataset contains 1.4 million answered questions on 191 thousand products and 13 million related reviews.</p>
</div>
</li>
<li class="ltx_item" id="A1.S5.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S5.I1.i4.p1">
<p class="ltx_p" id="A1.S5.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S5.I1.i4.p1.1.1">Hierarchical product review corpus</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yu2011domain</span>]</cite>:
This corpus contains consumer reviews on 11 popular products in four domains. These reviews were crawled from several prevalent forum websites, including cnet.com, viewpoints.com, reevoo.com, and gsmarena.com. All of the reviews were posted between June 2009 and September 2010. The aspects of the reviews, as well as the opinions on the aspects, were manually annotated.</p>
</div>
</li>
<li class="ltx_item" id="A1.S5.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S5.I1.i5.p1">
<p class="ltx_p" id="A1.S5.I1.i5.p1.3"><span class="ltx_text ltx_font_bold" id="A1.S5.I1.i5.p1.3.1">Amazon question answering dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">deng2020opinion</span>]</cite>:
This dataset is constructed by combining Amazon Question Answering Dataset <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mcauley2016addressing</span>]</cite> and Amazon Product Review Dataset <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">he2016ups</span>]</cite> by matching the product ID.
In this dataset, each QA sample contains a question, a reference answer, the answer opinion type label, and a set of relevant review snippets with corresponding ratings.
After collecting the final dataset, each QA sample contains a question, a reference answer, the answer opinion type label, and a set of relevant review snippets with corresponding ratings. There are three categories, namely Electronics, Home &amp; Kitchen, and Sports &amp; Outdoors, with <math alttext="193,960" class="ltx_Math" display="inline" id="A1.S5.I1.i5.p1.1.m1.2"><semantics id="A1.S5.I1.i5.p1.1.m1.2a"><mrow id="A1.S5.I1.i5.p1.1.m1.2.3.2" xref="A1.S5.I1.i5.p1.1.m1.2.3.1.cmml"><mn id="A1.S5.I1.i5.p1.1.m1.1.1" xref="A1.S5.I1.i5.p1.1.m1.1.1.cmml">193</mn><mo id="A1.S5.I1.i5.p1.1.m1.2.3.2.1" xref="A1.S5.I1.i5.p1.1.m1.2.3.1.cmml">,</mo><mn id="A1.S5.I1.i5.p1.1.m1.2.2" xref="A1.S5.I1.i5.p1.1.m1.2.2.cmml">960</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S5.I1.i5.p1.1.m1.2b"><list id="A1.S5.I1.i5.p1.1.m1.2.3.1.cmml" xref="A1.S5.I1.i5.p1.1.m1.2.3.2"><cn id="A1.S5.I1.i5.p1.1.m1.1.1.cmml" type="integer" xref="A1.S5.I1.i5.p1.1.m1.1.1">193</cn><cn id="A1.S5.I1.i5.p1.1.m1.2.2.cmml" type="integer" xref="A1.S5.I1.i5.p1.1.m1.2.2">960</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S5.I1.i5.p1.1.m1.2c">193,960</annotation><annotation encoding="application/x-llamapun" id="A1.S5.I1.i5.p1.1.m1.2d">193 , 960</annotation></semantics></math> (Electronics), <math alttext="90,269" class="ltx_Math" display="inline" id="A1.S5.I1.i5.p1.2.m2.2"><semantics id="A1.S5.I1.i5.p1.2.m2.2a"><mrow id="A1.S5.I1.i5.p1.2.m2.2.3.2" xref="A1.S5.I1.i5.p1.2.m2.2.3.1.cmml"><mn id="A1.S5.I1.i5.p1.2.m2.1.1" xref="A1.S5.I1.i5.p1.2.m2.1.1.cmml">90</mn><mo id="A1.S5.I1.i5.p1.2.m2.2.3.2.1" xref="A1.S5.I1.i5.p1.2.m2.2.3.1.cmml">,</mo><mn id="A1.S5.I1.i5.p1.2.m2.2.2" xref="A1.S5.I1.i5.p1.2.m2.2.2.cmml">269</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S5.I1.i5.p1.2.m2.2b"><list id="A1.S5.I1.i5.p1.2.m2.2.3.1.cmml" xref="A1.S5.I1.i5.p1.2.m2.2.3.2"><cn id="A1.S5.I1.i5.p1.2.m2.1.1.cmml" type="integer" xref="A1.S5.I1.i5.p1.2.m2.1.1">90</cn><cn id="A1.S5.I1.i5.p1.2.m2.2.2.cmml" type="integer" xref="A1.S5.I1.i5.p1.2.m2.2.2">269</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S5.I1.i5.p1.2.m2.2c">90,269</annotation><annotation encoding="application/x-llamapun" id="A1.S5.I1.i5.p1.2.m2.2d">90 , 269</annotation></semantics></math> (Home &amp; Kitchen), and <math alttext="50,020" class="ltx_Math" display="inline" id="A1.S5.I1.i5.p1.3.m3.2"><semantics id="A1.S5.I1.i5.p1.3.m3.2a"><mrow id="A1.S5.I1.i5.p1.3.m3.2.3.2" xref="A1.S5.I1.i5.p1.3.m3.2.3.1.cmml"><mn id="A1.S5.I1.i5.p1.3.m3.1.1" xref="A1.S5.I1.i5.p1.3.m3.1.1.cmml">50</mn><mo id="A1.S5.I1.i5.p1.3.m3.2.3.2.1" xref="A1.S5.I1.i5.p1.3.m3.2.3.1.cmml">,</mo><mn id="A1.S5.I1.i5.p1.3.m3.2.2" xref="A1.S5.I1.i5.p1.3.m3.2.2.cmml">020</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.S5.I1.i5.p1.3.m3.2b"><list id="A1.S5.I1.i5.p1.3.m3.2.3.1.cmml" xref="A1.S5.I1.i5.p1.3.m3.2.3.2"><cn id="A1.S5.I1.i5.p1.3.m3.1.1.cmml" type="integer" xref="A1.S5.I1.i5.p1.3.m3.1.1">50</cn><cn id="A1.S5.I1.i5.p1.3.m3.2.2.cmml" type="integer" xref="A1.S5.I1.i5.p1.3.m3.2.2">020</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.S5.I1.i5.p1.3.m3.2c">50,020</annotation><annotation encoding="application/x-llamapun" id="A1.S5.I1.i5.p1.3.m3.2d">50 , 020</annotation></semantics></math> pairs (Sports &amp; Outdoors).</p>
</div>
</li>
<li class="ltx_item" id="A1.S5.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S5.I1.i6.p1">
<p class="ltx_p" id="A1.S5.I1.i6.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S5.I1.i6.p1.1.1">JDDC e-commerce dialogue dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019jddc</span>]</cite>:
JDDC is a large-scale real scenario Chinese E-commerce conversation corpus, with more than 1 million multi-turn dialogues, 20 million utterances, and 150 million words, which contains conversations about after-sales topics between users and customer service staffs in an e-commerce scenario. JDDC was updated with multi-modal customer service information in 2021 <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhao2021jddc</span>]</cite>.</p>
</div>
</li>
<li class="ltx_item" id="A1.S5.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="A1.S5.I1.i7.p1">
<p class="ltx_p" id="A1.S5.I1.i7.p1.1"><span class="ltx_text ltx_font_bold" id="A1.S5.I1.i7.p1.1.1">E-commerce Dialogue Corpus dataset</span> <cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2018modeling</span>]</cite>:
The dataset is collected from the real-world conversations between customers and customer service staff on Taobao.
It contains over 5 types of conversations (i.e., commodity consultation, logistics express, recommendation, negotiation, and chitchat) based on over 20 commodities.<span class="ltx_note ltx_role_footnote" id="A1.footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://drive.google.com/file/d/154J-neBo20ABtSmJDvm7DK0eTuieAuvw/view?usp=sharing" title="">https://drive.google.com/file/d/154J-neBo20ABtSmJDvm7DK0eTuieAuvw/view?usp=sharing</a></span></span></span></p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="A1.S5.p3">
<p class="ltx_p" id="A1.S5.p3.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05763v2#A1.T5" title="Table A.5 ‣ A.5 Datasets for e-commerce QA and dialogues ‣ Appendix A Datasets ‣ Information Discovery in e-Commerce"><span class="ltx_text ltx_ref_tag">A.5</span></a> summarizes the key statistics for the datasets listed abvoe.</p>
</div>
<div class="ltx_table ltx_transformed_outer" id="A1.T5" style="width:183.5pt;height:515.5pt;vertical-align:-0.0pt;"><div class="ltx_transformed_inner" style="width:515.5pt;transform:translate(-165.98pt,-160.71pt) rotate(-90deg) ;"><figure>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table A.5: </span>Statistics of datasets about e-commerce question answering and dialogues.</figcaption>
<div class="ltx_inline-block ltx_align_center ltx_transformed_outer" id="A1.T5.1" style="width:512.1pt;height:173.6pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-140.9pt,47.6pt) scale(0.645023491573474,0.645023491573474) ;">
<table class="ltx_tabular ltx_align_middle" id="A1.T5.1.1">
<tr class="ltx_tr" id="A1.T5.1.1.1">
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T5.1.1.1.1" rowspan="2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T5.1.1.1.1.1">Datasets</span></td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="5" id="A1.T5.1.1.1.2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T5.1.1.1.2.1">Statistics</span></td>
<td class="ltx_td ltx_align_left ltx_border_tt" id="A1.T5.1.1.1.3" rowspan="2" style="padding-top:2.5pt;padding-bottom:2.5pt;"><span class="ltx_text ltx_font_bold" id="A1.T5.1.1.1.3.1">References</span></td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.1.2">
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T5.1.1.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Products</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T5.1.1.2.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Q-A pairs</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T5.1.1.2.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Categories</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.1.1.2.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_text" id="A1.T5.1.1.2.4.1"></span> <span class="ltx_text" id="A1.T5.1.1.2.4.2">
<span class="ltx_tabular ltx_align_middle" id="A1.T5.1.1.2.4.2.1">
<span class="ltx_tr" id="A1.T5.1.1.2.4.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T5.1.1.2.4.2.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Avg.length</span></span>
<span class="ltx_tr" id="A1.T5.1.1.2.4.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T5.1.1.2.4.2.1.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">of questions</span></span>
</span></span><span class="ltx_text" id="A1.T5.1.1.2.4.3"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T5.1.1.2.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_text" id="A1.T5.1.1.2.5.1"></span> <span class="ltx_text" id="A1.T5.1.1.2.5.2">
<span class="ltx_tabular ltx_align_middle" id="A1.T5.1.1.2.5.2.1">
<span class="ltx_tr" id="A1.T5.1.1.2.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T5.1.1.2.5.2.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Avg.length</span></span>
<span class="ltx_tr" id="A1.T5.1.1.2.5.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T5.1.1.2.5.2.1.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">of ground truth</span></span>
</span></span><span class="ltx_text" id="A1.T5.1.1.2.5.3"></span>
</td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.1.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T5.1.1.3.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">JD product question answering</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T5.1.1.3.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">469,953</td>
<td class="ltx_td ltx_border_t" id="A1.T5.1.1.3.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T5.1.1.3.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">38</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T5.1.1.3.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">9.03</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T5.1.1.3.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">10.3</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T5.1.1.3.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">gao2019product</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.1.4">
<td class="ltx_td ltx_align_left" id="A1.T5.1.1.4.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Taobao question answering dataset</td>
<td class="ltx_td ltx_align_right" id="A1.T5.1.1.4.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">4,457/47,979</td>
<td class="ltx_td ltx_align_right" id="A1.T5.1.1.4.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">356,842/798,688</td>
<td class="ltx_td ltx_align_right" id="A1.T5.1.1.4.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">2</td>
<td class="ltx_td ltx_align_right" id="A1.T5.1.1.4.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">9/8</td>
<td class="ltx_td ltx_align_right" id="A1.T5.1.1.4.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">13/13</td>
<td class="ltx_td ltx_align_left" id="A1.T5.1.1.4.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019driven</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.1.5">
<td class="ltx_td ltx_align_left" id="A1.T5.1.1.5.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Amazon complex question/answer dataset</td>
<td class="ltx_td ltx_align_right" id="A1.T5.1.1.5.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">191,185</td>
<td class="ltx_td ltx_align_right" id="A1.T5.1.1.5.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">1,447,173</td>
<td class="ltx_td ltx_align_right" id="A1.T5.1.1.5.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">8</td>
<td class="ltx_td" id="A1.T5.1.1.5.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T5.1.1.5.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left" id="A1.T5.1.1.5.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">mcauley2016addressing</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.1.6">
<td class="ltx_td ltx_align_left" id="A1.T5.1.1.6.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Hierarchical product review corpus</td>
<td class="ltx_td ltx_align_right" id="A1.T5.1.1.6.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">11</td>
<td class="ltx_td" id="A1.T5.1.1.6.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_right" id="A1.T5.1.1.6.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">4</td>
<td class="ltx_td" id="A1.T5.1.1.6.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T5.1.1.6.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left" id="A1.T5.1.1.6.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">yu2011domain</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.1.7">
<td class="ltx_td ltx_align_left" id="A1.T5.1.1.7.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">Amazon question answering dataset</td>
<td class="ltx_td" id="A1.T5.1.1.7.2" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_right" id="A1.T5.1.1.7.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">334,249</td>
<td class="ltx_td ltx_align_right" id="A1.T5.1.1.7.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">3</td>
<td class="ltx_td" id="A1.T5.1.1.7.5" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td" id="A1.T5.1.1.7.6" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_left" id="A1.T5.1.1.7.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">deng2020opinion</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.1.8">
<td class="ltx_td ltx_border_tt" id="A1.T5.1.1.8.1" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="A1.T5.1.1.8.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Dialogues</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="A1.T5.1.1.8.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Utterance</td>
<td class="ltx_td ltx_align_right ltx_border_tt" id="A1.T5.1.1.8.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Total words</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T5.1.1.8.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_text" id="A1.T5.1.1.8.5.1"></span> <span class="ltx_text" id="A1.T5.1.1.8.5.2">
<span class="ltx_tabular ltx_align_middle" id="A1.T5.1.1.8.5.2.1">
<span class="ltx_tr" id="A1.T5.1.1.8.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T5.1.1.8.5.2.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Avg.length</span></span>
<span class="ltx_tr" id="A1.T5.1.1.8.5.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T5.1.1.8.5.2.1.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">of utterances</span></span>
</span></span><span class="ltx_text" id="A1.T5.1.1.8.5.3"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A1.T5.1.1.8.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_text" id="A1.T5.1.1.8.6.1"></span> <span class="ltx_text" id="A1.T5.1.1.8.6.2">
<span class="ltx_tabular ltx_align_middle" id="A1.T5.1.1.8.6.2.1">
<span class="ltx_tr" id="A1.T5.1.1.8.6.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T5.1.1.8.6.2.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">#Avg.length</span></span>
<span class="ltx_tr" id="A1.T5.1.1.8.6.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T5.1.1.8.6.2.1.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">of dialogues</span></span>
</span></span><span class="ltx_text" id="A1.T5.1.1.8.6.3"></span>
</td>
<td class="ltx_td ltx_border_tt" id="A1.T5.1.1.8.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.1.9">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T5.1.1.9.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">JDDC e-commerce dialogue dataset</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T5.1.1.9.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">1,024,196</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T5.1.1.9.3" style="padding-top:2.5pt;padding-bottom:2.5pt;">20,451,337</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T5.1.1.9.4" style="padding-top:2.5pt;padding-bottom:2.5pt;">150,716,172</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T5.1.1.9.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">7.4</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="A1.T5.1.1.9.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">20</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T5.1.1.9.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">chen2019jddc</span>]</cite></td>
</tr>
<tr class="ltx_tr" id="A1.T5.1.1.10">
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T5.1.1.10.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">E-commerce Dialogue Corpus dataset</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T5.1.1.10.2" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_text" id="A1.T5.1.1.10.2.1"></span> <span class="ltx_text" id="A1.T5.1.1.10.2.2">
<span class="ltx_tabular ltx_align_middle" id="A1.T5.1.1.10.2.2.1">
<span class="ltx_tr" id="A1.T5.1.1.10.2.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T5.1.1.10.2.2.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">1,000,000 (Train)</span></span>
<span class="ltx_tr" id="A1.T5.1.1.10.2.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T5.1.1.10.2.2.1.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">10,000 (Valid)</span></span>
<span class="ltx_tr" id="A1.T5.1.1.10.2.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T5.1.1.10.2.2.1.3.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">10,000 (Test)</span></span>
</span></span><span class="ltx_text" id="A1.T5.1.1.10.2.3"></span>
</td>
<td class="ltx_td ltx_border_bb" id="A1.T5.1.1.10.3" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_border_bb" id="A1.T5.1.1.10.4" style="padding-top:2.5pt;padding-bottom:2.5pt;"></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T5.1.1.10.5" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_text" id="A1.T5.1.1.10.5.1"></span> <span class="ltx_text" id="A1.T5.1.1.10.5.2">
<span class="ltx_tabular ltx_align_middle" id="A1.T5.1.1.10.5.2.1">
<span class="ltx_tr" id="A1.T5.1.1.10.5.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T5.1.1.10.5.2.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">7.02 (Train)</span></span>
<span class="ltx_tr" id="A1.T5.1.1.10.5.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T5.1.1.10.5.2.1.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">6.99 (Valid)</span></span>
<span class="ltx_tr" id="A1.T5.1.1.10.5.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T5.1.1.10.5.2.1.3.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">7.11 (Test)</span></span>
</span></span><span class="ltx_text" id="A1.T5.1.1.10.5.3"></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T5.1.1.10.6" style="padding-top:2.5pt;padding-bottom:2.5pt;">
<span class="ltx_text" id="A1.T5.1.1.10.6.1"></span> <span class="ltx_text" id="A1.T5.1.1.10.6.2">
<span class="ltx_tabular ltx_align_middle" id="A1.T5.1.1.10.6.2.1">
<span class="ltx_tr" id="A1.T5.1.1.10.6.2.1.1">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T5.1.1.10.6.2.1.1.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">5.51 (Train)</span></span>
<span class="ltx_tr" id="A1.T5.1.1.10.6.2.1.2">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T5.1.1.10.6.2.1.2.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">5.48 (Valid)</span></span>
<span class="ltx_tr" id="A1.T5.1.1.10.6.2.1.3">
<span class="ltx_td ltx_nopad_r ltx_align_center" id="A1.T5.1.1.10.6.2.1.3.1" style="padding-top:2.5pt;padding-bottom:2.5pt;">5.64 (Test)</span></span>
</span></span><span class="ltx_text" id="A1.T5.1.1.10.6.3"></span>
</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="A1.T5.1.1.10.7" style="padding-top:2.5pt;padding-bottom:2.5pt;"><cite class="ltx_cite ltx_citemacro_citep">[<span class="ltx_ref ltx_missing_citation ltx_ref_self">zhang2018modeling</span>]</cite></td>
</tr>
</table>
</span></div>
</figure></div></div>
<div class="ltx_para" id="A1.S5.p4">
<span class="ltx_ERROR undefined" id="A1.S5.p4.1">\printbibliography</span>
<div class="ltx_pagination ltx_role_newpage"></div>
</div>
</section>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sat Oct 12 13:44:39 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
