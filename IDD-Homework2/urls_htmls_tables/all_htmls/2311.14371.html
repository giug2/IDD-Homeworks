<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2311.14371] Federated Transformed Learning for a Circular, Secure, and Tiny AI 1Alan Turing Institute, UK; 2Cranfield University, UK; 3Bin Li is with Beijing University of Posts and Telecommunications, China; 4Birkbeck, University of London, UK. ‚àóCorresponding Author: wguo@turing.ac.uk. The author wishes to acknowledge the Alan Turing Institute under the EPSRC grant EP/N510129/1, and Trustworthy Autonomous Systems (TAS) - Security Node under EPSRC grant EP/V026763/1.</title><meta property="og:description" content="Deep Learning (DL) is penetrating into a diverse range of mass mobility, smart living, and industrial applications, rapidly transforming the way we live and work. DL is at the heart of many AI implementations. A key se‚Ä¶">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Transformed Learning for a Circular, Secure, and Tiny AI 1Alan Turing Institute, UK; 2Cranfield University, UK; 3Bin Li is with Beijing University of Posts and Telecommunications, China; 4Birkbeck, University of London, UK. ‚àóCorresponding Author: wguo@turing.ac.uk. The author wishes to acknowledge the Alan Turing Institute under the EPSRC grant EP/N510129/1, and Trustworthy Autonomous Systems (TAS) - Security Node under EPSRC grant EP/V026763/1.">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Transformed Learning for a Circular, Secure, and Tiny AI 1Alan Turing Institute, UK; 2Cranfield University, UK; 3Bin Li is with Beijing University of Posts and Telecommunications, China; 4Birkbeck, University of London, UK. ‚àóCorresponding Author: wguo@turing.ac.uk. The author wishes to acknowledge the Alan Turing Institute under the EPSRC grant EP/N510129/1, and Trustworthy Autonomous Systems (TAS) - Security Node under EPSRC grant EP/V026763/1.">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2311.14371">

<!--Generated on Tue Feb 27 17:20:16 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
machine learning; deep learning; adversarial machine learning; compression; XAI; 5G; 6G;
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Federated Transformed Learning for a Circular, Secure, and Tiny AI
<span id="id5.5" class="ltx_note ltx_role_thanks"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">‚Ä†</sup><span class="ltx_note_type">thanks: </span><sup id="id5.5.1" class="ltx_sup"><span id="id5.5.1.1" class="ltx_text ltx_font_italic">1</span></sup>Alan Turing Institute, UK; <sup id="id5.5.2" class="ltx_sup"><span id="id5.5.2.1" class="ltx_text ltx_font_italic">2</span></sup>Cranfield University, UK; <sup id="id5.5.3" class="ltx_sup"><span id="id5.5.3.1" class="ltx_text ltx_font_italic">3</span></sup>Bin Li is with Beijing University of Posts and Telecommunications, China; <sup id="id5.5.4" class="ltx_sup"><span id="id5.5.4.1" class="ltx_text ltx_font_italic">4</span></sup>Birkbeck, University of London, UK.
<sup id="id5.5.5" class="ltx_sup">‚àó</sup>Corresponding Author: wguo@turing.ac.uk.
The author wishes to acknowledge the Alan Turing Institute under the EPSRC grant EP/N510129/1, and Trustworthy Autonomous Systems (TAS) - Security Node under EPSRC grant EP/V026763/1. </span></span></span>
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Weisi Guo<sup id="id12.5.id1" class="ltx_sup"><span id="id12.5.id1.1" class="ltx_text ltx_font_italic">1,2</span></sup>, Schyler Sun<sup id="id13.6.id2" class="ltx_sup"><span id="id13.6.id2.1" class="ltx_text ltx_font_italic">2</span></sup>, Bin Li<sup id="id14.7.id3" class="ltx_sup"><span id="id14.7.id3.1" class="ltx_text ltx_font_italic">3</span></sup>, Sam Blakeman<sup id="id15.8.id4" class="ltx_sup"><span id="id15.8.id4.1" class="ltx_text ltx_font_italic">1,4</span></sup>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id16.id1" class="ltx_p">Deep Learning (DL) is penetrating into a diverse range of mass mobility, smart living, and industrial applications, rapidly transforming the way we live and work. DL is at the heart of many AI implementations. A key set of challenges is to produce AI modules that are: (1) ‚Äùcircular‚Äù - can solve new tasks without forgetting how to solve previous ones, (2) ‚Äùsecure‚Äù - have immunity to adversarial data attacks, and (3) ‚Äùtiny‚Äù - implementable in low power low cost embedded hardware. Clearly it is difficult to achieve all three aspects on a single horizontal layer of platforms, as the techniques require <span id="id16.id1.1" class="ltx_text ltx_font_italic">transformed deep representations</span> that incur different computation and communication requirements.</p>
<p id="id17.id2" class="ltx_p">Here we set out the vision to achieve transformed DL representations across a 5G and Beyond networked architecture. We first detail the cross-sectoral motivations for each challenge area, before demonstrating recent advances in DL research that can achieve circular, secure, and tiny AI (CST-AI). Recognising the conflicting demand of each transformed deep representation, we federate their deep learning transformations and functionalities across the network to achieve connected run-time capabilities.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
machine learning; deep learning; adversarial machine learning; compression; XAI; 5G; 6G;

</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">As 5G networks roll out across the world, researchers are identifying the societal challenges for the next few decades in order to design the 6G networks that will serve as the digital backbone. Over 50 billion autonomous and IoT devices is set to be networked by end of the century, adding a hierarchy of distributed intelligence ranging from onboard embedded algorithms (e.g. dedicated purpose, sensitive to observations) to cloud intelligence orchestrating a range of services (e.g. episodic memory). As such, future 5G and 6G networks are likely to be increasingly integrated with the AI modules in a hyper-dense mass autonomous digital economy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, where intelligent agents (from autonomous vehicles to data analytic engines) are complementing and supplementing human labour across a diverse range of local industrial, commercial, agricultural, and mobility services. In particular, many autonomous and vehicular systems have stringent AI service performance demands that range form ultra low-latency decision-making to complex bio-inspired memory architectures to avoid catastrophic forgetting. These cannot co-exist on common hardware platforms and requires a federated approach.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS1.4.1.1" class="ltx_text">I-A</span> </span><span id="S1.SS1.5.2" class="ltx_text ltx_font_italic">Challenges &amp; Federated Learning</span>
</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">There are currently 3 key barriers to scalable mass autonomy across a wide range of applications: (1) AI catastrophically forgetting previous knowledge and re-learning at high computation and time costs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, (2) AI vulnerability to adversarial data attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, and (3) AI cannot be implemented on front-end machines due to limited or unsustainable processing power scaling laws <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.</p>
</div>
<div id="S1.SS1.p2" class="ltx_para">
<p id="S1.SS1.p2.1" class="ltx_p">It is widely recognised that these need to be addressed, but doing so on a single on-board or edge device incurs a high level of sophistication, compute energy requirement, and real-time data demand. In order to overcome these challenges, the community have made advances in the design of new AI algorithms and re-distributing its functionalities across the wireless network to leverage on various processing-communication capability trade-offs. One key advance is federated learning, where fragmented representations of the artificial neural network (ANN) is distributed across embedded and edge devices to enable scalable and decentralised or hybrid learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. Whilst this addresses some of the above challenges in security and scalability, federated learning fundamentally computes in the classic ANN domain. That means many of the challenges related to security and catastrophic forgetting cannot be solved. Yet, if we are to transform the ANN into more complex representations and develop computational twins for various purposes, then this requires re-distributing those <span id="S1.SS1.p2.1.1" class="ltx_text ltx_font_italic">transformed DL models</span> across the network for efficient computation. The diverse AI requirements differ significantly for the different ANN representations that serve different AI purposes via a wireless network - see Figure <a href="#S1.F1" title="Figure 1 ‚Ä£ I-A Challenges &amp; Federated Learning ‚Ä£ I Introduction ‚Ä£ Federated Transformed Learning for a Circular, Secure, and Tiny AI 1Alan Turing Institute, UK; 2Cranfield University, UK; 3Bin Li is with Beijing University of Posts and Telecommunications, China; 4Birkbeck, University of London, UK. ‚àóCorresponding Author: wguo@turing.ac.uk. The author wishes to acknowledge the Alan Turing Institute under the EPSRC grant EP/N510129/1, and Trustworthy Autonomous Systems (TAS) - Security Node under EPSRC grant EP/V026763/1." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2311.14371/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="233" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Digital ecosystem for Circular, Secure, and Tiny AI (CST-AI) with distributed functionalities across onboard-edge-cloud, and connected via wireless network: cloud based digital twins enable transformed representation of DL - which enables circular and robust AI; edge processing secure AI against adversarial attacks - implementing many of the transformed functionalities from cloud and aggregating data from diverse devices/machines; and onboard intelligence need real-time tiny AI for scalable capability.</figcaption>
</figure>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S1.SS2.4.1.1" class="ltx_text">I-B</span> </span><span id="S1.SS2.5.2" class="ltx_text ltx_font_italic">Novelty &amp; Contribution: Federating Transformed Deep Representations</span>
</h3>

<div id="S1.SS2.p1" class="ltx_para">
<p id="S1.SS2.p1.1" class="ltx_p">The opportunity here, is to develop wireless network enabled AI ecosystems that achieve CST-AI through federating the transformed representations. We will show how a wireless network with agile slicing is necessary:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">Section II: A networked ecosystem to achieve CST-AI via federating transformed DL functionalities across the wireless network with agile slicing. We review the key concepts and why a wireless network must federate these functionalities, before explaining the detailed methods below.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Section III: Circular DL aims at eliminating catastrophic forgetting through using parallel memory agents (unsupervised) or memory points (supervised) to enforce learning - significantly reducing computational costs and improving performance;</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Section IV: Secure DL through adversarial learning, statistical certificates, and manifold defence - offering either practical and theoretical benefits;</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">Section V: Computational scaling of deep learning implementation using novel compression and surrogate model techniques to overcome hardware scaling issues and enable practical embedded intelligence;</p>
</div>
</li>
<li id="S1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S1.I1.i5.p1" class="ltx_para">
<p id="S1.I1.i5.p1.1" class="ltx_p">Section VI: Summary and open challenges;</p>
</div>
</li>
</ol>
<p id="S1.SS2.p1.2" class="ltx_p">We hope this review enables readers to think about the joint challenges between AI for mass autonomy and wireless network design.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">TABLE I: </span>Federated Transformed Learning Functionalities distributed across onboard, edge, and cloud capabilities on a wireless network.</figcaption>
<table id="S1.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S1.T1.1.1.1" class="ltx_tr">
<th id="S1.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S1.T1.1.1.1.1.1" class="ltx_text ltx_font_bold">Deep Transforms</span></th>
<th id="S1.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S1.T1.1.1.1.2.1" class="ltx_text ltx_font_bold">Circular</span></th>
<th id="S1.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S1.T1.1.1.1.3.1" class="ltx_text ltx_font_bold">Secure</span></th>
<th id="S1.T1.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S1.T1.1.1.1.4.1" class="ltx_text ltx_font_bold">Tiny</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S1.T1.1.2.1" class="ltx_tr">
<td id="S1.T1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S1.T1.1.2.1.1.1" class="ltx_text ltx_font_bold">Cloud-side</span></td>
<td id="S1.T1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Memory Surrogates <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, Memory Points <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>
</td>
<td id="S1.T1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Statistical <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, Manifold Transform <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>
</td>
<td id="S1.T1.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">On-the-fly Decomposition</td>
</tr>
<tr id="S1.T1.1.3.2" class="ltx_tr">
<td id="S1.T1.1.3.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span id="S1.T1.1.3.2.1.1" class="ltx_text ltx_font_bold">Edge-side</span></td>
<td id="S1.T1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Temporal Difference <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, GP Kernel Update <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>
</td>
<td id="S1.T1.1.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Anomaly Detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>
</td>
<td id="S1.T1.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Federated Learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</td>
</tr>
<tr id="S1.T1.1.4.3" class="ltx_tr">
<td id="S1.T1.1.4.3.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t"><span id="S1.T1.1.4.3.1.1" class="ltx_text ltx_font_bold">Machine-side</span></td>
<td id="S1.T1.1.4.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">DL Model Update</td>
<td id="S1.T1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">N/A</td>
<td id="S1.T1.1.4.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Post-Training Decomposition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Wireless Network Ecosystem</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">We envisage that future AI modules that serve mass-automation (vehicles to factory) will distribute different services across the wireless network ecosystem in order to meet stringent AI-based Quality-of-Service (QoS) metrics: low AI model update latency, computational scalability <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>, adversarial AI security, AI explainability <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, and circular AI sustainability.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.4.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.5.2" class="ltx_text ltx_font_italic">On-board AI: Tiny</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.2" class="ltx_p">Starting at the bottom device level, there is urgent need to make DL algorithms achieve run-time performance on embedded platforms. Recent research <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> indicate a roughly ¬ø20<math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mo id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><times id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">\times</annotation></semantics></math> gap in storage size, and ¬ø10<math id="S2.SS1.p1.2.m2.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S2.SS1.p1.2.m2.1a"><mo id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">√ó</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><times id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">\times</annotation></semantics></math> gap in power consumption, between the DNN demands and the achievable computational capability on-board or at the edge. For example, a micro-controller DSP/FPGA sub-system typically has a power budget of 10mW and a storage size of 100kB on-chip memory, whist the corresponding DNN require 2MB of memory in weights and a significantly higher run-time energy demand. Whilst federated learning or cloud access critical, but both will incur latency and wireless access challenges. Therefore, the lightweight energy efficient DL paradigm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> becomes critical in attempting to meet the hardware gap that exists for the edge learning explained in detail in Section<a href="#S5" title="V Tiny AI ‚Ä£ Federated Transformed Learning for a Circular, Secure, and Tiny AI 1Alan Turing Institute, UK; 2Cranfield University, UK; 3Bin Li is with Beijing University of Posts and Telecommunications, China; 4Birkbeck, University of London, UK. ‚àóCorresponding Author: wguo@turing.ac.uk. The author wishes to acknowledge the Alan Turing Institute under the EPSRC grant EP/N510129/1, and Trustworthy Autonomous Systems (TAS) - Security Node under EPSRC grant EP/V026763/1." class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.4.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.5.2" class="ltx_text ltx_font_italic">Edge AI: Secure &amp; Robust</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Edge AI coordinates different aspects of the connected vehicles through data aggregation for federated learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. With over 50 billion devices set to be networked by end of the century, there is an unprecedented opportunity for malicious attacks. A particular danger is a false identity attack which injects poisonous data into the edge AI. The urgent need is to make the edge AI secure against spoofing and adversarial data attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> (see Section<a href="#S4" title="IV Security &amp; Trust ‚Ä£ Federated Transformed Learning for a Circular, Secure, and Tiny AI 1Alan Turing Institute, UK; 2Cranfield University, UK; 3Bin Li is with Beijing University of Posts and Telecommunications, China; 4Birkbeck, University of London, UK. ‚àóCorresponding Author: wguo@turing.ac.uk. The author wishes to acknowledge the Alan Turing Institute under the EPSRC grant EP/N510129/1, and Trustworthy Autonomous Systems (TAS) - Security Node under EPSRC grant EP/V026763/1." class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>). Other edge roles include aggregating not only training data in federated learning, but also the transformed representation data from cloud to inform security and robustness protocols. This leads us to the final upper layer of the ecosystem, where the transformed representations take place.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS3.4.1.1" class="ltx_text">II-C</span> </span><span id="S2.SS3.5.2" class="ltx_text ltx_font_italic">Cloud AI: Transformed Representation for Circular Economy</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">The transformed representations on cloud enable a circular digital economy, because by understanding DL‚Äôs reasoning in a transformed domain, we can dramatically reduce the likelihood of re-training/updating or re-purposing DL algorithms. As far as we are aware, this is the first time ‚Äùcircular AI‚Äù has been proposed, e.g. re-purposing the AI efficiently across a wide range of tasks and scenarios. Taking an example from NLP task training, the carbon footprint cost (CO<sub id="S2.SS3.p1.1.1" class="ltx_sub">2</sub> equivalent) of tuning a parsing pipeline is 35T and a large transformer is 284T <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. This is roughly equivalent to the equivalent carbon footprint generated by 40 and 313 passengers on a medium haul flight respectively, or 0.6 and 5 petrol cars in their typical life time. The research frontier (see Section<a href="#S3" title="III Circular AI ‚Ä£ Federated Transformed Learning for a Circular, Secure, and Tiny AI 1Alan Turing Institute, UK; 2Cranfield University, UK; 3Bin Li is with Beijing University of Posts and Telecommunications, China; 4Birkbeck, University of London, UK. ‚àóCorresponding Author: wguo@turing.ac.uk. The author wishes to acknowledge the Alan Turing Institute under the EPSRC grant EP/N510129/1, and Trustworthy Autonomous Systems (TAS) - Security Node under EPSRC grant EP/V026763/1." class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>) addresses this emerging energy efficient AI scalability challenge by creating methods that inject ‚Äùmemory‚Äù into the learning agent or identify deep feature space patterns that can be exploited for greater robustness. The application example is that this cloud-based digital twin responds to the diverse range of observations seen by robots and makes ecosystem level decisions in resource allocation, task assignment, and risk taking. These often require memory of previous lessons learnt to avoid catastrophic forgetting, and repeating lessons in the field.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS4.4.1.1" class="ltx_text">II-D</span> </span><span id="S2.SS4.5.2" class="ltx_text ltx_font_italic">Agile Network Slicing to Achieve CST-AI</span>
</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">As shown in Figure <a href="#S1.F1" title="Figure 1 ‚Ä£ I-A Challenges &amp; Federated Learning ‚Ä£ I Introduction ‚Ä£ Federated Transformed Learning for a Circular, Secure, and Tiny AI 1Alan Turing Institute, UK; 2Cranfield University, UK; 3Bin Li is with Beijing University of Posts and Telecommunications, China; 4Birkbeck, University of London, UK. ‚àóCorresponding Author: wguo@turing.ac.uk. The author wishes to acknowledge the Alan Turing Institute under the EPSRC grant EP/N510129/1, and Trustworthy Autonomous Systems (TAS) - Security Node under EPSRC grant EP/V026763/1." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, this CST-AI ecosystem creates stringent demands on the wireless network because it requires different AI transformed functionalities to be distributed, and to have their data streams and QoS demands streamed across the network. Network slicing is an integral part of the current 3GPP R16 and largely depends on explicit and timely knowledge on the demand and network environment condition. This enables a range of optimisation solutions ranging from classic optimisation to DL. However, many of the AI modules on-board and at edge are not known and change dynamically. The Radio Resource Management (RRM) need to allocate resources, reacting on the millisecond order in mass autonomy cases <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. This requires that a slicing is conducted in the absence of system state information while performance safeguards are kept across the run time trajectory. This leads to the need to create run-time slicing for AI demands. As shown in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, directly solving an off-line slicing solution is not feasible and a DL approach with stability guarantees can enable the system to learn a safe slicing solution from both historical records and run-time observations. To facilitate the imagination of the reader, a range of transformed DL functionalities and their QoS requirements are given in Table <a href="#S1.T1" title="TABLE I ‚Ä£ I-B Novelty &amp; Contribution: Federating Transformed Deep Representations ‚Ä£ I Introduction ‚Ä£ Federated Transformed Learning for a Circular, Secure, and Tiny AI 1Alan Turing Institute, UK; 2Cranfield University, UK; 3Bin Li is with Beijing University of Posts and Telecommunications, China; 4Birkbeck, University of London, UK. ‚àóCorresponding Author: wguo@turing.ac.uk. The author wishes to acknowledge the Alan Turing Institute under the EPSRC grant EP/N510129/1, and Trustworthy Autonomous Systems (TAS) - Security Node under EPSRC grant EP/V026763/1." class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>.</p>
</div>
<div id="S2.SS4.p2" class="ltx_para">
<p id="S2.SS4.p2.1" class="ltx_p">Having established the agile network slicing ecosystem to enable CST-AI, we now detail the specific innovations in different areas of the transformed representations and where they sit in the networked ecosystem.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Circular AI</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Overcoming catastrophic forgetting is the key to the continual learning in our proposed circular AI approach. This requires DNNs to not only hold its performance on previous datasets/tasks but also be capable of adapting to new datasets/tasks without significant repetitive training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2311.14371/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="438" height="381" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Circular Supervised AI using function regularization via memory points: embedded front-end DNNs are represented by GPs at the edge with cloud computing of complex memory points.</figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.4.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.5.2" class="ltx_text ltx_font_italic">Supervised Learning with Memory Points</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Regularization over the DNN <span id="S3.SS1.p1.1.1" class="ltx_text ltx_font_italic">weight space</span> or <span id="S3.SS1.p1.1.2" class="ltx_text ltx_font_italic">function space</span> are state-of-the-art approaches in avoiding catastrophic forgetting. Weight regularization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> fine-tunes the DNN parameters in further datasets/tasks training with parameter-regularisation so that the information learnt from previous datasets/tasks can be retained to some extent. However, due to the complex non-linear relationship between NN parameters and outputs, such direct approaches cannot theoretically guarantee its robustness to new arbitrary datasets.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_bold">Transformed Representation as GPs:</span> More recently, functional-regularisation (FR) directly regularises the equivalent function space of the DNN, by modeling the DNN as a Gaussian Processes (GP) - owing to the theoretical connections relating DNNs and GPs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. As shown in Figure <a href="#S3.F2" title="Figure 2 ‚Ä£ III Circular AI ‚Ä£ Federated Transformed Learning for a Circular, Secure, and Tiny AI 1Alan Turing Institute, UK; 2Cranfield University, UK; 3Bin Li is with Beijing University of Posts and Telecommunications, China; 4Birkbeck, University of London, UK. ‚àóCorresponding Author: wguo@turing.ac.uk. The author wishes to acknowledge the Alan Turing Institute under the EPSRC grant EP/N510129/1, and Trustworthy Autonomous Systems (TAS) - Security Node under EPSRC grant EP/V026763/1." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, the GP representation of the DNN weight space is the functional prior for the next new datasets/tasks training, which becomes approximately locally tunable. Hence, it is able to fit the new datasets/tasks with regularisation on its outputs based on previous memory points <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. Leveraging on the reverse mapping from GPs to DNN parameters, methods such as FROMP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> can translate functional prior regularisation into new DNN weights. An inevitable issue for state-of-the-arts methodologies is the infeasible computational complexity, whereupon, a number of approximations and assumptions are addressed in current applications. Therefore it becomes critical to develop a distributed computing system across the wireless network as shown in Figure <a href="#S3.F2" title="Figure 2 ‚Ä£ III Circular AI ‚Ä£ Federated Transformed Learning for a Circular, Secure, and Tiny AI 1Alan Turing Institute, UK; 2Cranfield University, UK; 3Bin Li is with Beijing University of Posts and Telecommunications, China; 4Birkbeck, University of London, UK. ‚àóCorresponding Author: wguo@turing.ac.uk. The author wishes to acknowledge the Alan Turing Institute under the EPSRC grant EP/N510129/1, and Trustworthy Autonomous Systems (TAS) - Security Node under EPSRC grant EP/V026763/1." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The front-end supervised learning is likely to be onboard machines/robots, whilst the complex GP representation and update process requires edge or cloud computational power. This highlights how the wireless network is essential in delivering circular AI.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.4.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.5.2" class="ltx_text ltx_font_italic">Reinforcement Learning with Surrogate Mind Map</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Deep Reinforcement Learning (DRL) has made it possible for AI systems to continuously interact with their environment. Many of the advances in DRL have been inspired by the human brain and its ability to transform high-dimensional sensory input into action. Importantly, the human brain appears highly adept at overcoming catastrophic forgetting as it continually learns new tasks without forgetting what it has previously learnt. It has been proposed that one of the reasons the brain is able to overcome catastrophic forgetting is due to its use of complementary learning systems. More specifically, it has been suggested that the brain uses episodic memory to rapidly store individual experiences and semantic memory to learn generalizations across many experiences. Crucially, this sampling procedure is done in an interleaved fashion so that new information is combined with old information and catastrophic forgetting is prevented.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p"><span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">Transformed Representation as Mind Map:</span> Seminal work in DRL, such as the Deep Q-Network, has taken inspiration from this brain architecture to successfully train DNNs to perform RL. In the case of DRL, the episodic memory system typically corresponds to a table of past experiences while the semantic memory system corresponds to a DNN. Experiences are constantly added to the table and the DNN is trained intermittently by sampling at random from the table. With respect to our recently proposed Continuous Temporal Difference Learning (CTDL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, the DNN can be used for function approximation at the edge while the table of past experiences can be stored in the cloud where more memory resources are available. If a copy of the DNN is also stored in the cloud then parameter updates can be calculated server-side and then passed to the edge using a wireless connection.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2311.14371/assets/x3.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="438" height="470" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Circular Reinforcement AI using CTDL: (top) edge-based pattern dependent DQN is wireless connected to a long-term pattern independent SOM memory, reducing catastrophic forgetting through temporal differences (TD), (bottom) CTDL achieves superior performance in a wide range of RL tasks against standard DQN and Advantage Actor Critic (A2C) algorithms.</figcaption>
</figure>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">CTDL utilizes the errors produced by the DNN to strategically decide which experiences to store in episodic memory, which in this case is represented as a Self-Organizing Map (SOM) (see Figure<a href="#S3.F3" title="Figure 3 ‚Ä£ III-B Reinforcement Learning with Surrogate Mind Map ‚Ä£ III Circular AI ‚Ä£ Federated Transformed Learning for a Circular, Secure, and Tiny AI 1Alan Turing Institute, UK; 2Cranfield University, UK; 3Bin Li is with Beijing University of Posts and Telecommunications, China; 4Birkbeck, University of London, UK. ‚àóCorresponding Author: wguo@turing.ac.uk. The author wishes to acknowledge the Alan Turing Institute under the EPSRC grant EP/N510129/1, and Trustworthy Autonomous Systems (TAS) - Security Node under EPSRC grant EP/V026763/1." class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>). This reduces the memory resources needed for the episodic memory system because the SOM only stores experiences in long-term memory that the DNN is poor at evaluating. The experiences in long-term memory therefore reflect problematic data points that are not amenable to function approximation. CTDL achieves superior performance in a wide range of RL tasks against standard DQN and Advantage Actor Critic (A2C) algorithms. An additional benefit of CTDL is that the experiences stored in long-term memory can be used for prediction using non-parametric approaches. These non-parametric predictions are immune to catastrophic forgetting for as long as the experiences are held in long-term memory. From the perspective of CST-AI, the edge can use the DNN for parametric function approximation, while the cloud can be used for non-parametric predictions when regions of the environment are visited that the DNN is poor at evaluating.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Security &amp; Trust</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Mass autonomy in cross-sectoral applications (e.g. mobility as a service, multi-infrastructure smart grid) often require consumer and industrial data sets that are heterogeneous and high-dimensional. This causes uncontrolled systematic noise resulting from high dimensional noise or adversarial data attacks - both of which are difficult to expose at the high dimensional levels of the DNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. The research is divided into developing both real-time data-driven defences, and statistically grounded certificate defences.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.4.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.5.2" class="ltx_text ltx_font_italic">Adversarial Training</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.2" class="ltx_p">The most practical method set is data-driven defences that provide a wide of training to the DNN to add a degree of adversarial immunity. In adversarial training, robust stochastic gradient descent (SGD) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> is one approach that tackles corrupted data or gradients during the training phase. Robust SGD with adversarial training at gradient <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="X" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mi id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">X</mi><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><ci id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">ùëã</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">X</annotation></semantics></math> is conducted by checking for adversarial examples <math id="S4.SS1.p1.2.m2.1" class="ltx_Math" alttext="X^{*}" display="inline"><semantics id="S4.SS1.p1.2.m2.1a"><msup id="S4.SS1.p1.2.m2.1.1" xref="S4.SS1.p1.2.m2.1.1.cmml"><mi id="S4.SS1.p1.2.m2.1.1.2" xref="S4.SS1.p1.2.m2.1.1.2.cmml">X</mi><mo id="S4.SS1.p1.2.m2.1.1.3" xref="S4.SS1.p1.2.m2.1.1.3.cmml">‚àó</mo></msup><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.2.m2.1b"><apply id="S4.SS1.p1.2.m2.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS1.p1.2.m2.1.1.1.cmml" xref="S4.SS1.p1.2.m2.1.1">superscript</csymbol><ci id="S4.SS1.p1.2.m2.1.1.2.cmml" xref="S4.SS1.p1.2.m2.1.1.2">ùëã</ci><times id="S4.SS1.p1.2.m2.1.1.3.cmml" xref="S4.SS1.p1.2.m2.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.2.m2.1c">X^{*}</annotation></semantics></math>. However, this does not effectively deal with real time backdoor access to training data that add both data artefacts and mislabels. Whilst this empirical approach do not offer guarantees or certificates, they present implementable and real-time solutions to real problems.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2311.14371/assets/x4.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="438" height="277" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Manifold defence using TDA to identify anomaly data features latent in the high-dimensional space with nonlinear inter-feature relations.</figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.4.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.5.2" class="ltx_text ltx_font_italic">Certificate Filters</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">Certified defences offer proofs to what attacks can be countered using statistical guarantees integrated into the DNN. Traditionally, in low dimensional data, we can identify corruption/noise through covariance checks via highest eigenvalue and remove the projection for real time cleaning. Filters can be implemented in the final representation layer of the DNN. This provides a statistical certificate against adversarial noise injections. This becomes more challenging at higher dimensions, especially with mixed data types and mixed adversarial statistics (e.g. higher moments). Other certified defences that might not operate in real time include: (1) randomised smoothing with soft classifiers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, and (2) manifold based defences to identify data topology anomalies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold">Transformed Representation as Feature Topology:</span> The latter method of manifold defences has gained significant attraction lately. By comparing the feature distribution difference between trusted data and full data in the DNN, one requires dimension reduction. Topological data analysis (TDA) can identify high-dimensional anomalies via persistent homology - see Figure <a href="#S4.F4" title="Figure 4 ‚Ä£ IV-A Adversarial Training ‚Ä£ IV Security &amp; Trust ‚Ä£ Federated Transformed Learning for a Circular, Secure, and Tiny AI 1Alan Turing Institute, UK; 2Cranfield University, UK; 3Bin Li is with Beijing University of Posts and Telecommunications, China; 4Birkbeck, University of London, UK. ‚àóCorresponding Author: wguo@turing.ac.uk. The author wishes to acknowledge the Alan Turing Institute under the EPSRC grant EP/N510129/1, and Trustworthy Autonomous Systems (TAS) - Security Node under EPSRC grant EP/V026763/1." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Through identifying simplicial complexes and multidimensional persistence, TDA can give a more comprehensive structure of the data feature distribution with intrinsic clusters by preserving local relationships of the high-dimensional feature space rather than conventional Principal component analysis (PCA) and Multidimensional scaling (MDS) methods - which do not capture any preserved data structure. The complexity of TDA implementation means it may very well be implemented on the cloud, but have the anomalies used to achieve security at the edge.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Tiny AI</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">As discussed previously in circular AI, the on-board training of DNNs at the edge is critical for low latency multi-task applications such as autonomous piloting, mission critical diagnostics, and agile manufacturing. In many such applications, the on-board or edge hardware has limited storage size, computational capability, energy budget, and communication capacity. It has to transition between different tasks, learning or updating its DNN on the fly or in run time.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S5.SS1.4.1.1" class="ltx_text">V-A</span> </span><span id="S5.SS1.5.2" class="ltx_text ltx_font_italic">Lightweight DNN Methods</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">The state-of-the-art methods combine joint hardware design (e.g. near-data processing, non-von Neumann architectures, systolic array architecture) and DNN compression. Parallel to the hardware innovations, the advances in lightweight algorithms have boosted the widespread use of DNN, which are designed to abstract a compressed DNN representation via <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>: (1) network pruning/compression, (2) weight quantization, and (3) network distillation, see Figure <a href="#S5.F5" title="Figure 5 ‚Ä£ V-A Lightweight DNN Methods ‚Ä£ V Tiny AI ‚Ä£ Federated Transformed Learning for a Circular, Secure, and Tiny AI 1Alan Turing Institute, UK; 2Cranfield University, UK; 3Bin Li is with Beijing University of Posts and Telecommunications, China; 4Birkbeck, University of London, UK. ‚àóCorresponding Author: wguo@turing.ac.uk. The author wishes to acknowledge the Alan Turing Institute under the EPSRC grant EP/N510129/1, and Trustworthy Autonomous Systems (TAS) - Security Node under EPSRC grant EP/V026763/1." class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p"><span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_bold">Transformed Representation via Compression:</span> The first method aims to compress a pre-trained network, by exploiting two dominant features of the learned weights, i.e. the sparsity and the low-rankness. The former reserves the network connections with large weights (see Figure <a href="#S5.F5" title="Figure 5 ‚Ä£ V-A Lightweight DNN Methods ‚Ä£ V Tiny AI ‚Ä£ Federated Transformed Learning for a Circular, Secure, and Tiny AI 1Alan Turing Institute, UK; 2Cranfield University, UK; 3Bin Li is with Beijing University of Posts and Telecommunications, China; 4Birkbeck, University of London, UK. ‚àóCorresponding Author: wguo@turing.ac.uk. The author wishes to acknowledge the Alan Turing Institute under the EPSRC grant EP/N510129/1, and Trustworthy Autonomous Systems (TAS) - Security Node under EPSRC grant EP/V026763/1." class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>top-left), without significantly degrading the prediction/classification accuracy; whilst the latter attempts to decompose a large pre-trained weight matrix into multiple small matrices (see Figure <a href="#S5.F5" title="Figure 5 ‚Ä£ V-A Lightweight DNN Methods ‚Ä£ V Tiny AI ‚Ä£ Federated Transformed Learning for a Circular, Secure, and Tiny AI 1Alan Turing Institute, UK; 2Cranfield University, UK; 3Bin Li is with Beijing University of Posts and Telecommunications, China; 4Birkbeck, University of London, UK. ‚àóCorresponding Author: wguo@turing.ac.uk. The author wishes to acknowledge the Alan Turing Institute under the EPSRC grant EP/N510129/1, and Trustworthy Autonomous Systems (TAS) - Security Node under EPSRC grant EP/V026763/1." class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>top-right), thereby reducing the storage and computation burden. According to some previous works, the pre-trained network may be reduced by 2-10 folds via such post-training compression methods.</p>
</div>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">The second method focuses on the machine precision adaptation of network weights (see Figure <a href="#S5.F5" title="Figure 5 ‚Ä£ V-A Lightweight DNN Methods ‚Ä£ V Tiny AI ‚Ä£ Federated Transformed Learning for a Circular, Secure, and Tiny AI 1Alan Turing Institute, UK; 2Cranfield University, UK; 3Bin Li is with Beijing University of Posts and Telecommunications, China; 4Birkbeck, University of London, UK. ‚àóCorresponding Author: wguo@turing.ac.uk. The author wishes to acknowledge the Alan Turing Institute under the EPSRC grant EP/N510129/1, and Trustworthy Autonomous Systems (TAS) - Security Node under EPSRC grant EP/V026763/1." class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>middle). By replacing the float-point weights (e.g. in 32 bits) with the low-resolution fixed-point weights (e.g. in 8 bits), the storage size can be effectively reduced. Similar to the aforementioned weight compression method, there also exists a compromise between the network accuracy and the weight reductions. In practice, one may assume the test accuracy would be slightly degraded by ¬°1%, and then exploits various quantization schemes, e.g. uniform, logarithm or other user-defined schemes.</p>
</div>
<div id="S5.SS1.p4" class="ltx_para">
<p id="S5.SS1.p4.1" class="ltx_p"><span id="S5.SS1.p4.1.1" class="ltx_text ltx_font_bold">Transformed Representation via Distillation:</span> The distillation network method tends to identify one smaller surrogate network to mimic the input-output mapping behaviors learned by an originally pre-trained DNN; such methods may include the local approximation for a small subset of input data, and the model translation for the entire dataset (see Figure <a href="#S5.F5" title="Figure 5 ‚Ä£ V-A Lightweight DNN Methods ‚Ä£ V Tiny AI ‚Ä£ Federated Transformed Learning for a Circular, Secure, and Tiny AI 1Alan Turing Institute, UK; 2Cranfield University, UK; 3Bin Li is with Beijing University of Posts and Telecommunications, China; 4Birkbeck, University of London, UK. ‚àóCorresponding Author: wguo@turing.ac.uk. The author wishes to acknowledge the Alan Turing Institute under the EPSRC grant EP/N510129/1, and Trustworthy Autonomous Systems (TAS) - Security Node under EPSRC grant EP/V026763/1." class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>bottom). A translated network may be implemented by decision tree, Bayesian graphs or even regressions. As demonstrated recently, such model translation techniques would achieve a largely reduced network, which is thus much easier to deploy in the edge scenarios and, more importantly, becomes even easily explainable <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
<figure id="S5.F5" class="ltx_figure"><img src="/html/2311.14371/assets/x5.png" id="S5.F5.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="375" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Tiny AI: Compression, Quantization, and Distillation network methods.</figcaption>
</figure>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusions and Open Challenges</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We know AI is going to change the way autonomous systems and wireless networks interface. What we don‚Äôt yet know is exactly what the frontier research challenges are in this space. Here, we propose that ‚Äùcircular‚Äù, ‚Äùsecure‚Äù, and ‚Äùtiny‚Äù are the 3 critical aspects of this challenge space. We detailed the cross-sectoral motivations for each area, before demonstrating recent advances in AI research that can achieve circular, secure, and tiny AI (CST-AI). Recognising the conflicting demand of each attribute, we distribute their functionalities across the network to achieve run-time capabilities using agile network slicing to achieve a future fit for mass autonomy.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">That being said, there is a long way to go before we connect connect diverse AI requirements and implementations seamlessly into a wireless network. We believe the key open challenges are:</p>
<ol id="S6.I1" class="ltx_enumerate">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p">Compress-on-the-Fly: building tiny AI modules that compress their architecture dynamically on the fly whilst training and operating, will be significantly better than post-training compression methods. This currently does not exist and requires new ways of integrating back-propagation with compression.</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p">Joint Communications and AI Defence: building secure edge intelligence that is jointly secure from a communication and AI perspective. Drawing inspiration from physical layer and public key security, we can develop methods to authenticate meaningful data via TDA manifold methods.</p>
</div>
</li>
<li id="S6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S6.I1.i3.p1" class="ltx_para">
<p id="S6.I1.i3.p1.1" class="ltx_p">Circular AI with Human Knowledge Integration and Explainability: building circular AI that can speak and interact with human experts so that catastrophic forgetting mitigation extends to a wider range of tasks and a deeper mutual understanding of the problem domain. This is done by translating human knowledge into memory points to regularize DNN functions, whilst explaining back the DNN‚Äôs reasoning to the human user via semantic or algebraic methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
</li>
</ol>
<p id="S6.p2.2" class="ltx_p">Achieving these objectives will enable the human society and machine world to be more integrated, facilitating cross learning and a smarter living.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
C.¬†Li, W.¬†Guo, S.¬†Sun, S.¬†Al-Rubaye, and A.¬†Tsourdos, ‚ÄúTrustworthy Deep
Learning in 6G Enabled Mass Autonomy: from Concept to Quality-of-Trust
KPIs,‚Äù <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">IEEE Vehicular Technology Magazine</em>, 2020.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
J.¬†Kirkpatrick <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">et¬†al.</em>, ‚ÄúOvercoming catastrophic forgetting in neural
networks,‚Äù <em id="bib.bib2.2.2" class="ltx_emph ltx_font_italic">Proceedings of the National Academy of Sciences (PNAS)</em>,
vol. 114, no.¬†13, pp. 3521‚Äì3526, 2017.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
I.¬†Goodfellow, P.¬†McDaniel, and N.¬†Papernot, ‚ÄúMaking machine learning robust
against adversarial inputs,‚Äù in <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">ACM Communications</em>, vol.¬†61, no.¬†7,
2018.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
X.¬†Xu, Y.¬†Ding, S.¬†X. Hu, M.¬†Niemier, J.¬†Cong, Y.¬†Hu, and Y.¬†Shi, ‚ÄúScaling for
edge inference of deep neural networks,‚Äù in <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Nature Electronics</em>, 2018.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Z.¬†Du, Y.¬†Deng, W.¬†Guo, A.¬†Nallanathan, and Q.¬†Wu, ‚ÄúGreen deep reinforcement
learning for radio resource management: Architecture, algorithm compression,
and challenges,‚Äù <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">IEEE Vehicular Technology Magazine</em>, 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
E.¬†Strubell, A.¬†Ganesh, and A.¬†McCallum, ‚ÄúEnergy and policy considerations for
modern deep learning research,‚Äù in <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">AAAI Conference on Artificial
Intelligence</em>, 2020, pp. 13‚Äâ693‚Äì13‚Äâ696.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
W.¬†Y.¬†B. Lim, N.¬†C. Luong, D.¬†T. Hoang, Y.¬†Jiao, Y.¬†C. Liang,
Q.¬†Yang, D.¬†Niyato, and C.¬†Miao, ‚ÄúFederated learning in mobile edge
networks: A comprehensive survey,‚Äù <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys
Tutorials</em>, vol.¬†22, no.¬†3, pp. 2031‚Äì2063, 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
S.¬†Blakeman and D.¬†Mareschal, ‚ÄúA complementary learning systems approach to
temporal difference learnings,‚Äù <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Neural Networks</em>, vol. 122, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
M.¬†K. Titsias, J.¬†Schwarz, A.¬†G. d.¬†G. Matthews, R.¬†Pascanu, and Y.¬†W. Teh,
‚ÄúFunctional regularisation for continual learning with gaussian processes,‚Äù
in <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations (ICLR)</em>, 2019.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Y.¬†Cheng, I.¬†Diakonikolas, R.¬†Ge, and M.¬†Soltanolkotabi, ‚ÄúHigh-dimensional
robust mean estimation via grad. descent,‚Äù in <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">International Conference
on Machine Learning (ICML)</em>, 2020.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
U.¬†Jang, S.¬†Jha, and S.¬†Jha, ‚ÄúOn the need for topology-aware generative models
for manifold-based defenses,‚Äù in <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning
Representations (ICLR)</em>, 2020.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
W.¬†Guo, ‚ÄúExplainable Artificial Intelligence (XAI) for 6G: Improving Trust
between Human and Machine,‚Äù <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Magazine</em>, vol.¬†58,
no.¬†6, 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
X.¬†Cheng, Y.¬†Wu, G.¬†Min, A.¬†Y. Zomaya, and X.¬†Fang, ‚ÄúSafeguard
Network Slicing in 5G: A Learning Augmented Optimization Approach,‚Äù
<em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">IEEE Journal on Selected Areas in Communications</em>, vol.¬†38, no.¬†7, pp.
1600‚Äì1613, 2020.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
M.¬†E.¬†E. Khan, A.¬†Immer, E.¬†Abedi, and M.¬†Korzepa, ‚ÄúApproximate inference
turns deep networks into gaussian processes,‚Äù in <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Advances in neural
information processing systems (NIPS)</em>, 2019, pp. 3094‚Äì3104.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
J.¬†Cohen, E.¬†Rosenfeld, and J.¬†Kolter, ‚ÄúCertified adversarial robustness via
randomised smoothing,‚Äù in <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning
(ICML)</em>, 2019.

</span>
</li>
</ul>
</section>
<figure id="id11" class="ltx_float biography">
<table id="id11.2" class="ltx_tabular">
<tr id="id11.2.2" class="ltx_tr">
<td id="id11.2.2.3" class="ltx_td"></td>
<td id="id11.2.2.2" class="ltx_td">
<span id="id11.2.2.2.2" class="ltx_inline-block">
<span id="id11.2.2.2.2.2" class="ltx_p"><span id="id11.2.2.2.2.2.1" class="ltx_text ltx_font_bold">Weisi Guo</span>  (S07, M11, SM17) received his MEng, MA, and Ph.D. degrees from the University of Cambridge, UK. He is Chair Professor of Human Machine Intelligence at Cranfield University. He has published over <math id="id10.1.1.1.1.1.m1.1" class="ltx_Math" alttext="170" display="inline"><semantics id="id10.1.1.1.1.1.m1.1a"><mn id="id10.1.1.1.1.1.m1.1.1" xref="id10.1.1.1.1.1.m1.1.1.cmml">170</mn><annotation-xml encoding="MathML-Content" id="id10.1.1.1.1.1.m1.1b"><cn type="integer" id="id10.1.1.1.1.1.m1.1.1.cmml" xref="id10.1.1.1.1.1.m1.1.1">170</cn></annotation-xml><annotation encoding="application/x-tex" id="id10.1.1.1.1.1.m1.1c">170</annotation></semantics></math> papers and is PI on over <math id="id11.2.2.2.2.2.m2.1" class="ltx_Math" alttext="\pounds 4" display="inline"><semantics id="id11.2.2.2.2.2.m2.1a"><mrow id="id11.2.2.2.2.2.m2.1.1" xref="id11.2.2.2.2.2.m2.1.1.cmml"><mi mathvariant="normal" id="id11.2.2.2.2.2.m2.1.1.2" xref="id11.2.2.2.2.2.m2.1.1.2.cmml">¬£</mi><mo lspace="0em" rspace="0em" id="id11.2.2.2.2.2.m2.1.1.1" xref="id11.2.2.2.2.2.m2.1.1.1.cmml">‚Äã</mo><mn id="id11.2.2.2.2.2.m2.1.1.3" xref="id11.2.2.2.2.2.m2.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="id11.2.2.2.2.2.m2.1b"><apply id="id11.2.2.2.2.2.m2.1.1.cmml" xref="id11.2.2.2.2.2.m2.1.1"><times id="id11.2.2.2.2.2.m2.1.1.1.cmml" xref="id11.2.2.2.2.2.m2.1.1.1"></times><ci id="id11.2.2.2.2.2.m2.1.1.2.cmml" xref="id11.2.2.2.2.2.m2.1.1.2">¬£</ci><cn type="integer" id="id11.2.2.2.2.2.m2.1.1.3.cmml" xref="id11.2.2.2.2.2.m2.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="id11.2.2.2.2.2.m2.1c">\pounds 4</annotation></semantics></math>m of research grants. His research has won him several international awards (IET Innovation 15, Bell Labs Prize Finalist 14 and Semi-Finalist 16 and 19). He was a Turing Fellow at the Alan Turing Institute and is a Fellow of Royal Statistical Society.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="tab1" class="ltx_float biography">
<table id="tab1.1" class="ltx_tabular">
<tr id="tab1.1.1" class="ltx_tr">
<td id="tab1.1.1.1" class="ltx_td"></td>
<td id="tab1.1.1.2" class="ltx_td">
<span id="tab1.1.1.2.1" class="ltx_inline-block">
<span id="tab1.1.1.2.1.1" class="ltx_p"><span id="tab1.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Schyler Sun</span>  (S07, M11, SM17) is a PhD student at Cranfield University, and works on mathematical proofs for explainable deep learning.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="tab2" class="ltx_float biography">
<table id="tab2.1" class="ltx_tabular">
<tr id="tab2.1.1" class="ltx_tr">
<td id="tab2.1.1.1" class="ltx_td"></td>
<td id="tab2.1.1.2" class="ltx_td">
<span id="tab2.1.1.2.1" class="ltx_inline-block">
<span id="tab2.1.1.2.1.1" class="ltx_p"><span id="tab2.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Bin Li</span>  (S07, M11, SM17) is an associate professor at BUPT and works in designing front end tiny AI implementations using novel signal processing decompositions.</span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="tab3" class="ltx_float biography">
<table id="tab3.1" class="ltx_tabular">
<tr id="tab3.1.1" class="ltx_tr">
<td id="tab3.1.1.1" class="ltx_td"></td>
<td id="tab3.1.1.2" class="ltx_td">
<span id="tab3.1.1.2.1" class="ltx_inline-block">
<span id="tab3.1.1.2.1.1" class="ltx_p"><span id="tab3.1.1.2.1.1.1" class="ltx_text ltx_font_bold">Sam Blakeman</span>  is a PhD student at Birbeck College London, and has worked on a wide range of human brain inspired reinforcement learning agent design.</span>
</span>
</td>
</tr>
</table>
</figure>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2311.14370" class="ar5iv-nav-button ar5iv-nav-button-prev">‚óÑ</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2311.14371" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2311.14371">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2311.14371" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2311.14372" class="ar5iv-nav-button ar5iv-nav-button-next">‚ñ∫</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Feb 27 17:20:16 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "√ó";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
