<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2403.04577] Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition</title><meta property="og:description" content="Web tables contain a large amount of valuable knowledge and have inspired tabular language models aimed at tackling table interpretation (TI) tasks. In this paper, we analyse a widely used benchmark dataset for evaluat…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2403.04577">

<!--Generated on Fri Apr  5 18:28:33 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Wiki-TabNER:Advancing Table Interpretation Through 
<br class="ltx_break">Named Entity Recognition</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Aneta Koleva
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id2.1.id1" class="ltx_text ltx_affiliation_institution">LMU, Siemens AG</span><span id="id3.2.id2" class="ltx_text ltx_affiliation_streetaddress">P.O. Box 1212</span><span id="id4.3.id3" class="ltx_text ltx_affiliation_city">Munich</span><span id="id5.4.id4" class="ltx_text ltx_affiliation_state">Germany</span><span id="id6.5.id5" class="ltx_text ltx_affiliation_postcode">43017-6221</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:firstname.lastname@siemens.com">firstname.lastname@siemens.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Martin Ringsquandl
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id7.1.id1" class="ltx_text ltx_affiliation_institution">Siemens AG</span><span id="id8.2.id2" class="ltx_text ltx_affiliation_streetaddress">1 Thørväld Circle</span><span id="id9.3.id3" class="ltx_text ltx_affiliation_city">Munich</span><span id="id10.4.id4" class="ltx_text ltx_affiliation_country">Germany</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:firstname.lastname@siemens.com">firstname.lastname@siemens.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ahmed Hatem
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id11.1.id1" class="ltx_text ltx_affiliation_institution">TUM</span><span id="id12.2.id2" class="ltx_text ltx_affiliation_city">Munich</span><span id="id13.3.id3" class="ltx_text ltx_affiliation_country">Germany</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:ahmed.hatem.m.g@gmail.com">ahmed.hatem.m.g@gmail.com</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Thomas Runkler
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id14.1.id1" class="ltx_text ltx_affiliation_institution">Siemens AG, TUM</span><span id="id15.2.id2" class="ltx_text ltx_affiliation_city">Munich</span><span id="id16.3.id3" class="ltx_text ltx_affiliation_country">Germany</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:firstname.lastname@siemens.com">firstname.lastname@siemens.com</a>
</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Volker Tresp
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id17.1.id1" class="ltx_text ltx_affiliation_institution">LMU</span><span id="id18.2.id2" class="ltx_text ltx_affiliation_city">Munich</span><span id="id19.3.id3" class="ltx_text ltx_affiliation_country">Germany</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:firstname.lastname@lmu.com">firstname.lastname@lmu.com</a>
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id20.id1" class="ltx_p">Web tables contain a large amount of valuable knowledge and have inspired tabular language models aimed at tackling table interpretation (TI) tasks. In this paper, we analyse a widely used benchmark dataset for evaluation of TI tasks, particularly focusing on the entity linking task. Our analysis reveals that this dataset is overly simplified, potentially reducing its effectiveness for thorough evaluation and failing to accurately represent tables as they appear in the real-world. To overcome this drawback, we construct and annotate a new more challenging dataset.
In addition to introducing the new dataset, we also introduce a novel problem aimed at addressing the entity linking task: named entity recognition within cells.
Finally, we propose a prompting framework for evaluating the newly developed large language models (LLMs) on this novel TI task. We conduct experiments on prompting LLMs under various settings, where we use both random and similarity-based selection to choose the examples presented to the models. Our ablation study helps us gain insights into the impact of the few-shot examples. Additionally, we perform qualitative analysis to gain insights into the challenges encountered by the models and to understand the limitations of the proposed dataset.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">PVLDB Reference Format:
<br class="ltx_break"></span><span id="p1.1.2" class="ltx_text" style="font-size:90%;">  PVLDB, 14(1): XXX-XXX, 2020.</span>
<br class="ltx_break"><a target="_blank" href="https://doi.org/XX.XX/XXX.XX" title="" class="ltx_ref ltx_href" style="font-size:90%;">doi:XX.XX/XXX.XX</a><span id="p1.1.3" class="ltx_text" style="font-size:90%;">
</span><span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup>This work is licensed under the Creative Commons BY-NC-ND 4.0 International License. Visit <a target="_blank" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://creativecommons.org/licenses/by-nc-nd/4.0/</a> to view a copy of this license. For any use beyond those covered by this license, obtain permission by emailing <a href="mailto:info@vldb.org" title="" class="ltx_ref ltx_href">info@vldb.org</a>. Copyright is held by the owner/author(s). Publication rights licensed to the VLDB Endowment. 
<br class="ltx_break">Proceedings of the VLDB Endowment, Vol. 14, No. 1 ISSN 2150-8097. 
<br class="ltx_break"><a target="_blank" href="https://doi.org/XX.XX/XXX.XX" title="" class="ltx_ref ltx_href">doi:XX.XX/XXX.XX</a> 
<br class="ltx_break"></span></span></span></p>
</div>
<div id="p2" class="ltx_para ltx_noindent">
<p id="p2.1" class="ltx_p"><span id="p2.1.1" class="ltx_text ltx_font_bold" style="font-size:90%;">PVLDB Artifact Availability:
<br class="ltx_break"></span><span id="p2.1.2" class="ltx_text" style="font-size:90%;">The source code, data, and/or other artifacts have been made available at </span><a target="_blank" href="https://github.com/table-interpretation/wiki_table_NER" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://github.com/table-interpretation/wiki_table_NER</a><span id="p2.1.3" class="ltx_text" style="font-size:90%;">.
</span><span id="p2.1.4" class="ltx_text"></span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Relational tables, consisting of multiple columns that represent entities and their attributes, effectively structure complex data. Representing complex data in such a structured manner enhances readability and facilitates improved data comprehension. The abundance of web tables <cite class="ltx_cite ltx_citemacro_citep">(Cafarella et al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2008</a>)</cite> and the recent advances in natural language processing (NLP) pioneered by the transformer model <cite class="ltx_cite ltx_citemacro_citep">(Vaswani et al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2017</a>)</cite>, have been the inspiration behind the numerous newly proposed tabular language models <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib43" title="" class="ltx_ref">2019</a>; Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2020</a>; Iida et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2021</a>; Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2020</a>; Herzig et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2020</a>; Eisenschlos et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2021</a>)</cite>. These models leverage a pre-trained large language model (LLM), such as BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2019</a>)</cite> as their backbone, which is then fine-tuned on tabular dataset for table specific downstream tasks such as: question answering, fact checking, semantic parsing, table population and table interpretation.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In this paper we focus on the problem of table interpretation (TI).
TI aims at discovering the semantics of the data captured in the tables and comprises of several sub-tasks. These include entity linking (EL), where the objective is to link entity mentions from the cells to reference entities; column type annotation (CTA), where columns are annotated with semantic types; and relation extraction (RE), where the semantic relations between the columns are identified.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2403.04577/assets/figures/complex_table.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="592" height="265" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>. </span><span id="S1.F1.3.2" class="ltx_text" style="font-size:90%;">Table retrieved from Wikipedia which illustrates what a complex relational table can look like. Representation of the original table in the Wiki-TabNER dataset and in the TURL dataset</span></figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The commonly used dataset for evaluation of TI is the TURL dataset <cite class="ltx_cite ltx_citemacro_citep">(Deng et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite> which has been extracted from the larger corpus of WikiTables <cite class="ltx_cite ltx_citemacro_citep">(Bhagavatula et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2015</a>)</cite>. This dataset consists of pre-processed tables, where numerical values have been removed and text within each cell is constrained to contain at most one entity mention. Through analysis of the tables in the WikiTables corpus, we illustrate that the assumption of one entity per cell is overly restrictive. Our investigation shows that there are tables with greater complexity than those typically used for evaluating TI. With our analysis of the corpus, we motivate why the table named entity recognition task (NER) is a task needed for improving table interpretation, particularly in addressing the EL task.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.2" class="ltx_p">The methods for solving EL have been evolving over time and the current state-of-the-art is a LLM with an accuracy of <math id="S1.p4.1.m1.1" class="ltx_Math" alttext="93.65" display="inline"><semantics id="S1.p4.1.m1.1a"><mn id="S1.p4.1.m1.1.1" xref="S1.p4.1.m1.1.1.cmml">93.65</mn><annotation-xml encoding="MathML-Content" id="S1.p4.1.m1.1b"><cn type="float" id="S1.p4.1.m1.1.1.cmml" xref="S1.p4.1.m1.1.1">93.65</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.1.m1.1c">93.65</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2023b</a>)</cite>, while the previous method was a table specific transformer model with an accuracy of <math id="S1.p4.2.m2.1" class="ltx_Math" alttext="84.9" display="inline"><semantics id="S1.p4.2.m2.1a"><mn id="S1.p4.2.m2.1.1" xref="S1.p4.2.m2.1.1.cmml">84.9</mn><annotation-xml encoding="MathML-Content" id="S1.p4.2.m2.1b"><cn type="float" id="S1.p4.2.m2.1.1.cmml" xref="S1.p4.2.m2.1.1">84.9</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p4.2.m2.1c">84.9</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_citep">(Deng et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite>. While these high scores may be partly attributed to the advancements in the models, they may also be due to the simplicity of tables that are commonly used for their evaluation. As shown in the table example from the TURL dataset <cite class="ltx_cite ltx_citemacro_citep">(Deng et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite> in Figure <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, the problem of EL is limited to a single entity mention per cell and the problem of NER is partly solved after solving the column type annotation problem. However, as illustrated in the original table in Figure <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, tables in reality are more complex. This highlights the need to first solve NER within the cells and only afterwards the EL problem.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">To address the shortcomings of the existing dataset, we introduce a novel dataset, Wiki-TabNER, which reflects the Wikipedia tables with their real structure. Moreover, we have annotated the entities within the cells with <math id="S1.p5.1.m1.1" class="ltx_Math" alttext="7" display="inline"><semantics id="S1.p5.1.m1.1a"><mn id="S1.p5.1.m1.1.1" xref="S1.p5.1.m1.1.1.cmml">7</mn><annotation-xml encoding="MathML-Content" id="S1.p5.1.m1.1b"><cn type="integer" id="S1.p5.1.m1.1.1.cmml" xref="S1.p5.1.m1.1.1">7</cn></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.1.m1.1c">7</annotation></semantics></math> Dbpedia entity types <cite class="ltx_cite ltx_citemacro_citep">(Bizer et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2009</a>)</cite> with the intention to utilize this dataset for evaluating the NER task within tables. In Figure <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> we show an example of how the original table from Wikipedia looks like, how the same table is presented in the novel Wiki-TabNER dataset and how this table is in the simplified TURL dataset <cite class="ltx_cite ltx_citemacro_citep">(Deng et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite>. Observing this example, we see the discrepancy between the original table and the simplified table that is used for evaluation of TI tasks. In the Wiki-TabNER dataset we annotate linked entities using both BIO-labels <cite class="ltx_cite ltx_citemacro_citep">(Ramshaw and Marcus, <a href="#bib.bib28" title="" class="ltx_ref">1995</a>)</cite> and span-based labels <cite class="ltx_cite ltx_citemacro_citep">(Joshi et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2020</a>)</cite>. This allows for an evaluation of both traditional sequence labeling models as well as transformer based models. In the example, we show that in the Wiki-TabNER dataset we preserve the original content of the table and we add the span-based labels for the entities, which in this case are entities of types <span id="S1.p5.1.1" class="ltx_text ltx_font_italic">Work</span>, <span id="S1.p5.1.2" class="ltx_text ltx_font_italic">Organization</span> and <span id="S1.p5.1.3" class="ltx_text ltx_font_italic">Person</span>.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Even though NER is a long-standing problem in the NLP community, this problem so far there is no common benchmark for evaluating NER in tables. Table NER can be defined as follows: Identify all entity mentions in a cell and classify each entity into a semantic type. In this paper we extend the idea of table NER to any relational table, not only industrial tables as in <cite class="ltx_cite ltx_citemacro_citep">(Koleva et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2022</a>)</cite>. We first show the limited applicability of the one entity per cell assumption, then we present the new benchmark dataset Wiki-TabNER, which addresses the task of NER in tables and EL. Following the trend of increasingly using LLMs for solving various tabular problems <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2023b</a>; Gong et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2020a</a>; Zha et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2023</a>)</cite>, we also propose an evaluation framework for in-context learning of LLMs on the Wiki-TabNER dataset. We explore the capabilities of these models for NER in tables, by conducting experiments in zero, one and few shot settings. To the best of our knowledge, this is the first work to propose a benchmark dataset with multi-entity cells which is closer to real-world use cases.
The contributions of this paper are:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We expose a limitation in the current dataset for evaluating the EL task and provide evidence to support the necessity to discard simplifications of the tables.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We construct a new benchmark dataset Wiki-TabNER for evaluating EL and NER in tables. This dataset serves as a basis for our evaluation and is proposed as a more challenging benchmark to the community.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Finally, we present an evaluation framework where we evaluate the performance of recent LLMs on this task. We make the proposed dataset and the evaluation framework publicly available.<span id="footnote1a" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>The dataset and the code will be available at <a target="_blank" href="https://github.com/table-interpretation/wiki_table_NER" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/table-interpretation/wiki_table_NER</a></span></span></span></p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Related Work</h2>

<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Existing Benchmark Datasets</h4>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p1.3" class="ltx_p">Several benchmarks have been proposed for the evaluation of the TI tasks. T2Dv2 <cite class="ltx_cite ltx_citemacro_citep">(Lehmberg et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2016a</a>)</cite> was published in <math id="S2.SS0.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="2016" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.1.m1.1a"><mn id="S2.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">2016</mn><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.1.m1.1b"><cn type="integer" id="S2.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.m1.1.1">2016</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.1.m1.1c">2016</annotation></semantics></math> and it consists of manually annotated row-to-instance, attribute-to-property, and table-to-class correspondences between <math id="S2.SS0.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="779" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.2.m2.1a"><mn id="S2.SS0.SSS0.Px1.p1.2.m2.1.1" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1.cmml">779</mn><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.2.m2.1b"><cn type="integer" id="S2.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m2.1.1">779</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.2.m2.1c">779</annotation></semantics></math> Web tables and the DBpedia Knowledge Base (KB) <cite class="ltx_cite ltx_citemacro_citep">(Bizer et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2009</a>)</cite>. However, only <math id="S2.SS0.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="237" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.3.m3.1a"><mn id="S2.SS0.SSS0.Px1.p1.3.m3.1.1" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.1.cmml">237</mn><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.3.m3.1b"><cn type="integer" id="S2.SS0.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m3.1.1">237</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.3.m3.1c">237</annotation></semantics></math> out of the 779 tables share at least one instance with DBpedia while the rest do not have any overlap with the KB. These tables were extracted from the English-language subset of the Web Data Commons Web Tables Corpus <cite class="ltx_cite ltx_citemacro_citep">(Lehmberg et al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2016b</a>)</cite>.
Another benchmark was proposed by Limaye et al. <cite class="ltx_cite ltx_citemacro_citep">(Limaye et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2010</a>)</cite> which contains 437 cell-level and column-level manually annotated tables using Wikipedia, DBpedia and YAGO <cite class="ltx_cite ltx_citemacro_citep">(Suchanek et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2007</a>)</cite>. This dataset is used for evaluation of the EL and the CTA tasks <cite class="ltx_cite ltx_citemacro_citep">(Efthymiou et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2017</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2019</a>)</cite>.
Efthymiou et al. <cite class="ltx_cite ltx_citemacro_citep">(Efthymiou et al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2017</a>)</cite> created a benchmark that consists of 485,096 tables from Wikipedia and is intended for the task of matching rows to Dbpedia entities. Similarly, the recent SemTab challenge <cite class="ltx_cite ltx_citemacro_citep">(Jimenez-Ruiz et al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2020</a>)</cite> aims at benchmarking systems that match tabular data to KBs, by using dataset with various level of difficuly, but in all datasets the tables are processed to have one entity per cell.</p>
</div>
<div id="S2.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p2.1" class="ltx_p">TableInstruct <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2023b</a>)</cite> was recently proposed for instruction tuning and evaluation of the TableLlama model. This dataset consists of prompts utilized for both fine-tuning and model evaluation, with the tables integrated as part of the prompts. A distinct dataset consisting of tables and the linked entities is lacking, and the tables are repeated multiple times within the dataset. Additionally, the EL problem in TableInstruct focuses on individual entities, there is a separate prompt for each entity in a table, which can be inefficient for large tables containing many entities, making evaluation expensive and inefficient for LLMs.</p>
</div>
<div id="S2.SS0.SSS0.Px1.p3" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p3.1" class="ltx_p">All of the mentioned datasets are unsuitable for table NER due to various reasons: the dataset is too small and the assumption is one entity per row <cite class="ltx_cite ltx_citemacro_citep">(Lehmberg et al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2016a</a>; Limaye et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2010</a>)</cite>, the annotation for EL is on cell-level with entity IDs <cite class="ltx_cite ltx_citemacro_citep">(Limaye et al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2010</a>)</cite>, there are no explicit tables with links to entities provided <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2023b</a>)</cite> or the dataset does not include instances of complex tables <cite class="ltx_cite ltx_citemacro_citep">(Deng et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite> as shown in Figure <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Tabular Language Models</h4>

<div id="S2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p1.1" class="ltx_p">The transformer architecture has been the most popular choice for TI in recent works. Models that have been pre-trained on large corpus of tabular data include Tabnet <cite class="ltx_cite ltx_citemacro_citep">(Arik and Pfister, <a href="#bib.bib2" title="" class="ltx_ref">2021</a>)</cite>, TURL <cite class="ltx_cite ltx_citemacro_citep">(Deng et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite>, TaPas <cite class="ltx_cite ltx_citemacro_citep">(Herzig et al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2020</a>)</cite>, TaBERT <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2020</a>)</cite>, TUTA <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2020</a>)</cite> and MATE <cite class="ltx_cite ltx_citemacro_citep">(Eisenschlos et al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2021</a>)</cite>. TURL is fine-tuned and evaluated on 6 different tasks for table understanding and augmentation (entity linking, column type annotation, relation extraction, row population, cell filling and schema augmentation), while TaBERT and TaPas were fine-tuned to solve a single task (table question answering). TabLLM is a LLM fine-tuned for table classification, exploring different methods of serialization of tables.
More recent works fine-tune LLMs directly without table-specific pre-training. UnifiedSKG <cite class="ltx_cite ltx_citemacro_citep">(Xie et al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2022</a>)</cite> fine-tunes the T5 model <cite class="ltx_cite ltx_citemacro_citep">(Raffel et al<span class="ltx_text">.</span>, <a href="#bib.bib27" title="" class="ltx_ref">2020</a>)</cite> on semantic parsing and question answering. Recently, more models based on the large generative models have been proposed. Models based on the GPT models include: <cite class="ltx_cite ltx_citemacro_citep">(Gong et al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2020a</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citep">(Gong et al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2020b</a>)</cite>, <cite class="ltx_cite ltx_citemacro_citep">(Zha et al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2023</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2023a</a>)</cite>. TableLlama model <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2023b</a>)</cite> is a fine-tuned Llama2 model <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2023</a>)</cite> proposed together with the TableInstruct dataset. These models address various tabular tasks and utilize different datasets for evaluation.
However, when evaluating on the entity linking task, all models use the existing benchmark datasets with simple tables and the assumption of one entity per cell.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">NER with LLMs</h4>

<div id="S2.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p1.1" class="ltx_p">NER methods focus on processing unstructured text, phrasing the NER problem as sequence labeling task. The solutions utilize different neural network models including Long Short-Term Memory networks (LSTMs) <cite class="ltx_cite ltx_citemacro_citep">(Hammerton, <a href="#bib.bib16" title="" class="ltx_ref">2003</a>)</cite>, Conditional Random Fields (CRFs) <cite class="ltx_cite ltx_citemacro_citep">(Lample et al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2016</a>)</cite> and Graph Neural Networks (GNNs) <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2023a</a>)</cite>. An interesting approach called DeepStruct <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2022a</a>)</cite> explores how LLMs can be used for structural understanding of text.
Span-based approaches for evaluation of NER include the SpanBERT method <cite class="ltx_cite ltx_citemacro_citep">(Joshi et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2020</a>)</cite> and ESD <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2022b</a>)</cite>. The latest developed LLMs are able to generalize and learn with few-shot prompting examples <cite class="ltx_cite ltx_citemacro_citep">(Brown et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2020</a>)</cite>. Therefore, the recent NER solution focus on utilizing few-shot prompting techniques for LLMs <cite class="ltx_cite ltx_citemacro_citep">(Vilar et al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2023</a>; Das et al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2022</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2023</a>; Wei et al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2022</a>)</cite>.
However, NER is a challenging task for LLMs because the problem is formulated as sequence labeling, while these models are often trained to do text generation tasks <cite class="ltx_cite ltx_citemacro_citep">(Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib36" title="" class="ltx_ref">2023b</a>)</cite>. In this paper we test the capabilities of LLMs on the NER task within tables.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Shortcomings of current benchmark</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Commonly used dataset for evaluation on TI tasks is the TURL dataset, which was proposed together with the TURL model <cite class="ltx_cite ltx_citemacro_citep">(Deng et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite>. This dataset was extracted from the larger corpus WikiTables <cite class="ltx_cite ltx_citemacro_citep">(Bhagavatula et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2015</a>)</cite> and was then pre-processed and transformed so that it simplifies the tables. Bhagavatula et al. <cite class="ltx_cite ltx_citemacro_citep">(Bhagavatula et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2015</a>)</cite> published the WikiTables corpus of 1.6 million Wikipedia tables in 2015. The corpus contains <math id="S3.p1.1.m1.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S3.p1.1.m1.1a"><mo id="S3.p1.1.m1.1.1" xref="S3.p1.1.m1.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S3.p1.1.m1.1b"><csymbol cd="latexml" id="S3.p1.1.m1.1.1.cmml" xref="S3.p1.1.m1.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.p1.1.m1.1c">\sim</annotation></semantics></math> 30 million hyperlinks to Wikipedia pages and can be used to build ground truth labels for the entity linking task. The tables store factual knowledge on various topics ranging from artistic works (e.g., Songs) to sporting events (e.g., Olympics). When we consider the WikiTables dataset before pre-processing, we find that 75.2% of the cells contain additional text that is removed during the pre-processing step. In real-world scenarios, tables have more complex structure and include several entities per cell, as shown in the industrial use-case presented in <cite class="ltx_cite ltx_citemacro_citep">(Koleva et al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Single Entity per Cell Assumption</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The objective of the EL task is to link every entity mention from a table to a corresponding entity in a knowledge base. When we consider complex tables such as the original table in Figure <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, it is necessary to first identify the tokens that represent an entity mention and only then it is possible to link the entity mentions to reference entities. However, in the existing benchmark dataset <cite class="ltx_cite ltx_citemacro_citep">(Deng et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite>, the tables always contain one entity per cell and the rest of the text is removed. The assumption is that every cell may contain up to one entity mention, simplifying the EL task. This assumption also overlooks the non-entity tokens in the cells. Non-entity tokens are text tokens that do not correspond to an entity. In real-world tables, one cell may contain non-entity tokens as well as multiple entity mentions. Consequently, the current formulation of one entity per cell faces a significant drawback, making it unsuitable for handling complex tables.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Dataset Analysis</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We first analyse the existing WikiTables corpus <cite class="ltx_cite ltx_citemacro_citep">(Bhagavatula et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2015</a>)</cite> which comprises tables extracted from Wikipedia pages. This dataset also includes links to reference entities for the entity mentions found within the tables. We consider three subsets of the corpus denoted by <em id="S3.SS2.p1.1.1" class="ltx_emph ltx_font_italic">random</em>, <em id="S3.SS2.p1.1.2" class="ltx_emph ltx_font_italic">90% linked</em> and <em id="S3.SS2.p1.1.3" class="ltx_emph ltx_font_italic">¿2avg linked</em>. They are each comprised of 3000 randomly sampled tables. We construct these subsets for the purpose of collecting statistics over the WikiTables. The <em id="S3.SS2.p1.1.4" class="ltx_emph ltx_font_italic">random</em> subset contains randomly selected Wikipedia tables, irrespective of the density of links in the tables. This subset is the same as the WIKI-LINKS-RANDOM in the original paper <cite class="ltx_cite ltx_citemacro_citep">(Bhagavatula et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2015</a>)</cite>. It contains around 50,000 entity mentions. The subset <em id="S3.SS2.p1.1.5" class="ltx_emph ltx_font_italic">90% linked</em> contains tables that have entity links in at least 90% of their cells. Finally, the <em id="S3.SS2.p1.1.6" class="ltx_emph ltx_font_italic">¿2avg linked</em> subset contains tables that have links in at least 90% of their cells and at least an average of 2 links per cell.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.4" class="ltx_p">These three subsets give us a glimpse of how the Wikipedia tables are structured. In Figure <a href="#S3.F2" title="Figure 2 ‣ 3.2. Dataset Analysis ‣ 3. Shortcomings of current benchmark ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, we show, for each subset, the percentages of the tables’ average numbers of links per cell. The <em id="S3.SS2.p2.4.1" class="ltx_emph ltx_font_italic">random</em> subset clearly shows that <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="\sim 85\%" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mrow id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml"></mi><mo id="S3.SS2.p2.1.m1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.cmml">∼</mo><mrow id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml"><mn id="S3.SS2.p2.1.m1.1.1.3.2" xref="S3.SS2.p2.1.m1.1.1.3.2.cmml">85</mn><mo id="S3.SS2.p2.1.m1.1.1.3.1" xref="S3.SS2.p2.1.m1.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><csymbol cd="latexml" id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">absent</csymbol><apply id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3"><csymbol cd="latexml" id="S3.SS2.p2.1.m1.1.1.3.1.cmml" xref="S3.SS2.p2.1.m1.1.1.3.1">percent</csymbol><cn type="integer" id="S3.SS2.p2.1.m1.1.1.3.2.cmml" xref="S3.SS2.p2.1.m1.1.1.3.2">85</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\sim 85\%</annotation></semantics></math> of the tables contain at most one linked entity per cell.
However, if we consider the tables from <em id="S3.SS2.p2.4.2" class="ltx_emph ltx_font_italic">90% linked</em> subset, we see that <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="\sim 80\%" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mrow id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mi id="S3.SS2.p2.2.m2.1.1.2" xref="S3.SS2.p2.2.m2.1.1.2.cmml"></mi><mo id="S3.SS2.p2.2.m2.1.1.1" xref="S3.SS2.p2.2.m2.1.1.1.cmml">∼</mo><mrow id="S3.SS2.p2.2.m2.1.1.3" xref="S3.SS2.p2.2.m2.1.1.3.cmml"><mn id="S3.SS2.p2.2.m2.1.1.3.2" xref="S3.SS2.p2.2.m2.1.1.3.2.cmml">80</mn><mo id="S3.SS2.p2.2.m2.1.1.3.1" xref="S3.SS2.p2.2.m2.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><csymbol cd="latexml" id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2">absent</csymbol><apply id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3"><csymbol cd="latexml" id="S3.SS2.p2.2.m2.1.1.3.1.cmml" xref="S3.SS2.p2.2.m2.1.1.3.1">percent</csymbol><cn type="integer" id="S3.SS2.p2.2.m2.1.1.3.2.cmml" xref="S3.SS2.p2.2.m2.1.1.3.2">80</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">\sim 80\%</annotation></semantics></math> of the tables have on average between 1 and 2 entities in their cells. Finally, if we consider the <em id="S3.SS2.p2.4.3" class="ltx_emph ltx_font_italic">¿2avg linked</em> subset, we observe that among very complex tables, there is diversity in the number of links per cell: <math id="S3.SS2.p2.3.m3.1" class="ltx_Math" alttext="\sim 70\%" display="inline"><semantics id="S3.SS2.p2.3.m3.1a"><mrow id="S3.SS2.p2.3.m3.1.1" xref="S3.SS2.p2.3.m3.1.1.cmml"><mi id="S3.SS2.p2.3.m3.1.1.2" xref="S3.SS2.p2.3.m3.1.1.2.cmml"></mi><mo id="S3.SS2.p2.3.m3.1.1.1" xref="S3.SS2.p2.3.m3.1.1.1.cmml">∼</mo><mrow id="S3.SS2.p2.3.m3.1.1.3" xref="S3.SS2.p2.3.m3.1.1.3.cmml"><mn id="S3.SS2.p2.3.m3.1.1.3.2" xref="S3.SS2.p2.3.m3.1.1.3.2.cmml">70</mn><mo id="S3.SS2.p2.3.m3.1.1.3.1" xref="S3.SS2.p2.3.m3.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.3.m3.1b"><apply id="S3.SS2.p2.3.m3.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1"><csymbol cd="latexml" id="S3.SS2.p2.3.m3.1.1.1.cmml" xref="S3.SS2.p2.3.m3.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S3.SS2.p2.3.m3.1.1.2.cmml" xref="S3.SS2.p2.3.m3.1.1.2">absent</csymbol><apply id="S3.SS2.p2.3.m3.1.1.3.cmml" xref="S3.SS2.p2.3.m3.1.1.3"><csymbol cd="latexml" id="S3.SS2.p2.3.m3.1.1.3.1.cmml" xref="S3.SS2.p2.3.m3.1.1.3.1">percent</csymbol><cn type="integer" id="S3.SS2.p2.3.m3.1.1.3.2.cmml" xref="S3.SS2.p2.3.m3.1.1.3.2">70</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.3.m3.1c">\sim 70\%</annotation></semantics></math> have between 2 and 3 linked entities per cell while <math id="S3.SS2.p2.4.m4.1" class="ltx_Math" alttext="\sim 14\%" display="inline"><semantics id="S3.SS2.p2.4.m4.1a"><mrow id="S3.SS2.p2.4.m4.1.1" xref="S3.SS2.p2.4.m4.1.1.cmml"><mi id="S3.SS2.p2.4.m4.1.1.2" xref="S3.SS2.p2.4.m4.1.1.2.cmml"></mi><mo id="S3.SS2.p2.4.m4.1.1.1" xref="S3.SS2.p2.4.m4.1.1.1.cmml">∼</mo><mrow id="S3.SS2.p2.4.m4.1.1.3" xref="S3.SS2.p2.4.m4.1.1.3.cmml"><mn id="S3.SS2.p2.4.m4.1.1.3.2" xref="S3.SS2.p2.4.m4.1.1.3.2.cmml">14</mn><mo id="S3.SS2.p2.4.m4.1.1.3.1" xref="S3.SS2.p2.4.m4.1.1.3.1.cmml">%</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.4.m4.1b"><apply id="S3.SS2.p2.4.m4.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1"><csymbol cd="latexml" id="S3.SS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.p2.4.m4.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S3.SS2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.p2.4.m4.1.1.2">absent</csymbol><apply id="S3.SS2.p2.4.m4.1.1.3.cmml" xref="S3.SS2.p2.4.m4.1.1.3"><csymbol cd="latexml" id="S3.SS2.p2.4.m4.1.1.3.1.cmml" xref="S3.SS2.p2.4.m4.1.1.3.1">percent</csymbol><cn type="integer" id="S3.SS2.p2.4.m4.1.1.3.2.cmml" xref="S3.SS2.p2.4.m4.1.1.3.2">14</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.4.m4.1c">\sim 14\%</annotation></semantics></math> have an average of at least 3 links per cell.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2403.04577/assets/figures/wikitables_avg_num_ents.jpeg" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="293" height="172" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>. </span><span id="S3.F2.3.2" class="ltx_text" style="font-size:90%;">Average number of links per cell for every table in each subset</span></figcaption>
</figure>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2403.04577/assets/figures/ser_entities_per_table.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="311" height="170" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>. </span><span id="S3.F3.3.2" class="ltx_text" style="font-size:90%;">Wiki-TabNER average number of labeled entities per table</span></figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>New Dataset Proposal</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">Motivated by the limitations of the existing benchmark dataset and the potential of complex tables from the WikiTables corpus, we now propose a new benchmark dataset for evaluation of EL and table NER.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Dataset Construction</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Following the creation of the TURL dataset <cite class="ltx_cite ltx_citemacro_citep">(Deng et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite>, we also extract a high quality subset of relational tables, by identifying tables that have a subject column. The subject column must be located in the first two columns of the table and contains unique entities which are treated as subject entities. Moreover, with the intention to create a dataset with complex tables we only retain tables that have: (1) between 2 and 20 columns; (2) at least 3 rows; (3) 90% linked cells and (4) an average of at least 2 links per cell. We further filter out the tables with empty or undesirable captions, such as ”External Links”, ”References” and ”Sources”. This results in a dataset of <math id="S4.SS1.p1.1.m1.1" class="ltx_Math" alttext="62063" display="inline"><semantics id="S4.SS1.p1.1.m1.1a"><mn id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml">62063</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><cn type="integer" id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1">62063</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">62063</annotation></semantics></math> tables. We refer to this dataset as <em id="S4.SS1.p1.1.1" class="ltx_emph ltx_font_italic">relational tables</em>.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">The subset <em id="S4.SS1.p2.1.1" class="ltx_emph ltx_font_italic">relational tables</em> already provides a high quality dataset of complex tables. However, in order to make this dataset suitable for the table NER and EL tasks, we further process it.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">To make our dataset practical and reusable across models, we clip the tables such that they contain at most 512 textual tokens. To convert strings of texts to lists of tokens, we use huggingface’s BertTokenizer <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertTokenizer</span></span></span>.
We go through every table in the <em id="S4.SS1.p3.1.1" class="ltx_emph ltx_font_italic">relational tables</em> dataset row-wise and count the number of tokens until we reach 512, then discard the rest of the table. The reason behind the clipping is that many language models such as BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2019</a>)</cite> and the transformer-based tabular models <cite class="ltx_cite ltx_citemacro_citep">(Yin et al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2020</a>; Iida et al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2021</a>; Deng et al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2020</a>; Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2020</a>)</cite> have a maximum input sequence of 512 tokens. Moreover, processing longer sequences requires more computational resources and it becomes expensive and time consuming when using the newer LLMs such as <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib26" title="" class="ltx_ref">2023</a>; Touvron et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2023</a>)</cite>. We also filter out tables, that after clipping, have less than 1 row left. This additional processing has not impacted the size of the tables in terms of number or rows or number of tokens. Figure <a href="#S4.F4" title="Figure 4 ‣ 4.1. Dataset Construction ‣ 4. New Dataset Proposal ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the number of tokens per table before clipping at 512 tokens. This plot indicates that the majority of tables already had less than 512 tokens meaning that only a small percentage of the tables (13%) were clipped.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2403.04577/assets/figures/num_tokens_before_clip.png" id="S4.F4.g1" class="ltx_graphics ltx_img_landscape" width="299" height="164" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>. </span><span id="S4.F4.3.2" class="ltx_text" style="font-size:90%;">Number of tokens per table before clipping to 512 tokens</span></figcaption>
</figure>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.2" class="ltx_p">The new dataset consists of 51271 tables, and we refer to it by <em id="S4.SS1.p4.2.1" class="ltx_emph ltx_font_italic">Wiki-TabNER dataset</em>. The average number of rows in the dataset is <math id="S4.SS1.p4.1.m1.1" class="ltx_Math" alttext="7.2" display="inline"><semantics id="S4.SS1.p4.1.m1.1a"><mn id="S4.SS1.p4.1.m1.1.1" xref="S4.SS1.p4.1.m1.1.1.cmml">7.2</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.1.m1.1b"><cn type="float" id="S4.SS1.p4.1.m1.1.1.cmml" xref="S4.SS1.p4.1.m1.1.1">7.2</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.1.m1.1c">7.2</annotation></semantics></math> and the average number of columns is <math id="S4.SS1.p4.2.m2.1" class="ltx_Math" alttext="4" display="inline"><semantics id="S4.SS1.p4.2.m2.1a"><mn id="S4.SS1.p4.2.m2.1.1" xref="S4.SS1.p4.2.m2.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p4.2.m2.1b"><cn type="integer" id="S4.SS1.p4.2.m2.1.1.cmml" xref="S4.SS1.p4.2.m2.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p4.2.m2.1c">4</annotation></semantics></math>. The <em id="S4.SS1.p4.2.2" class="ltx_emph ltx_font_italic">Wiki-TabNER dataset</em> is thus composed mainly of compact but complex tables.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2403.04577/assets/figures/num_entities_per_type_final.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="293" height="176" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.3.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>. </span><em id="S4.F5.4.2" class="ltx_emph ltx_font_italic" style="font-size:90%;">Wiki-TabNER dataset</em><span id="S4.F5.5.3" class="ltx_text" style="font-size:90%;">’s number of entities per type</span></figcaption>
</figure>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2403.04577/assets/figures/num_unique_labels_per_table.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="299" height="225" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>. </span><span id="S4.F6.3.2" class="ltx_text" style="font-size:90%;">Wiki-TabNER dataset’s number of distinct types per table</span></figcaption>
</figure>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Labeling Wiki-TabNER</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The first step towards solving the EL problem is to retrieve a list of candidates using a Wikidata Lookup service from where the correct entity should be chosen. Identifying all of the entity mentions within a cell and their types, can help retrieve a more concise list of candidates. Table <a href="#S4.T1" title="Table 1 ‣ 4.2. Labeling Wiki-TabNER ‣ 4. New Dataset Proposal ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows an example of a Wikipedia table where the entity <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_italic">Chocolat</span> from the first column in the highlighted row is the entity to be linked. Table <a href="#S4.T2" title="Table 2 ‣ 4.2. Labeling Wiki-TabNER ‣ 4. New Dataset Proposal ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the list of retrieved candidates for <span id="S4.SS2.p1.1.2" class="ltx_text ltx_font_italic">Chocolat</span>, and the highlighted row is the correct entity. We see that many entities with different types are listed as possible candidates. If we know that the entity <span id="S4.SS2.p1.1.3" class="ltx_text ltx_font_italic">Chocolat</span> in the table refers to an entity of type <span id="S4.SS2.p1.1.4" class="ltx_text ltx_font_italic">Work</span>, rather than an entity of type <span id="S4.SS2.p1.1.5" class="ltx_text ltx_font_italic">Organization</span> as the <span id="S4.SS2.p1.1.6" class="ltx_text ltx_font_italic">Chocolat - South Korean group</span>, we can narrow the search for entity candidates to instances of type <span id="S4.SS2.p1.1.7" class="ltx_text ltx_font_italic">Work</span> and with that reduce the list of candidates significantly.
Hence, we propose that identifying the entity type of the entities within the cells can help in addressing the EL task. In this direction, we label the entity mentions in the Wiki-TabNER dataset with entity types.</p>
</div>
<figure id="S4.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T1.2.1.1" class="ltx_text" style="font-size:90%;">Table 1</span>. </span><span id="S4.T1.3.2" class="ltx_text" style="font-size:90%;">Table used for evaluation</span></figcaption>
<table id="S4.T1.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.4.1.1" class="ltx_tr" style="background-color:#E9E9E9;">
<th id="S4.T1.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.4.1.1.1.1" class="ltx_text ltx_font_bold" style="background-color:#E9E9E9;">Title</span></th>
<th id="S4.T1.4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.4.1.1.2.1" class="ltx_text ltx_font_bold" style="background-color:#E9E9E9;">Director</span></th>
<th id="S4.T1.4.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S4.T1.4.1.1.3.1" class="ltx_text ltx_font_bold" style="background-color:#E9E9E9;">Cast</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.4.2.1" class="ltx_tr">
<td id="S4.T1.4.2.1.1" class="ltx_td ltx_align_left ltx_border_t">The Bear</td>
<td id="S4.T1.4.2.1.2" class="ltx_td ltx_align_left ltx_border_t">Jean-Jacques Annaud</td>
<td id="S4.T1.4.2.1.3" class="ltx_td ltx_align_left ltx_border_t">Tchéky Karyo</td>
</tr>
<tr id="S4.T1.4.3.2" class="ltx_tr">
<td id="S4.T1.4.3.2.1" class="ltx_td ltx_align_left">The Big Blue</td>
<td id="S4.T1.4.3.2.2" class="ltx_td ltx_align_left">Luc Besson</td>
<td id="S4.T1.4.3.2.3" class="ltx_td ltx_align_left">Rosanna Arquette</td>
</tr>
<tr id="S4.T1.4.4.3" class="ltx_tr">
<td id="S4.T1.4.4.3.1" class="ltx_td ltx_align_left">Camille Claudel</td>
<td id="S4.T1.4.4.3.2" class="ltx_td ltx_align_left">Bruno Nuytten</td>
<td id="S4.T1.4.4.3.3" class="ltx_td ltx_align_left">Isabelle Adjani</td>
</tr>
<tr id="S4.T1.4.5.4" class="ltx_tr" style="background-color:#FFFFA6;">
<td id="S4.T1.4.5.4.1" class="ltx_td ltx_align_left"><span id="S4.T1.4.5.4.1.1" class="ltx_text ltx_font_bold" style="background-color:#FFFFA6;">Chocolat</span></td>
<td id="S4.T1.4.5.4.2" class="ltx_td ltx_align_left"><span id="S4.T1.4.5.4.2.1" class="ltx_text" style="background-color:#FFFFA6;">Claire Denis</span></td>
<td id="S4.T1.4.5.4.3" class="ltx_td ltx_align_left"><span id="S4.T1.4.5.4.3.1" class="ltx_text" style="background-color:#FFFFA6;">François Cluzet</span></td>
</tr>
<tr id="S4.T1.4.6.5" class="ltx_tr">
<td id="S4.T1.4.6.5.1" class="ltx_td ltx_align_left ltx_border_bb">L’enfance de l’art</td>
<td id="S4.T1.4.6.5.2" class="ltx_td ltx_align_left ltx_border_bb">Francis Girod</td>
<td id="S4.T1.4.6.5.3" class="ltx_td ltx_border_bb"></td>
</tr>
</tbody>
</table>
</figure>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.2.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>. </span><span id="S4.T2.3.2" class="ltx_text" style="font-size:90%;">Retrieved candidates for solving the EL task</span></figcaption>
<table id="S4.T2.4" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.4.1.1" class="ltx_tr" style="background-color:#E9E9E9;">
<th id="S4.T2.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.4.1.1.1.1" class="ltx_text ltx_font_bold" style="background-color:#E9E9E9;">Wiki ID</span></th>
<th id="S4.T2.4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.4.1.1.2.1" class="ltx_text ltx_font_bold" style="background-color:#E9E9E9;">Label</span></th>
<th id="S4.T2.4.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt"><span id="S4.T2.4.1.1.3.1" class="ltx_text ltx_font_bold" style="background-color:#E9E9E9;">Description</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.4.2.1" class="ltx_tr">
<td id="S4.T2.4.2.1.1" class="ltx_td ltx_align_left ltx_border_t">Q220423</td>
<td id="S4.T2.4.2.1.2" class="ltx_td ltx_align_left ltx_border_t">Chocolat</td>
<td id="S4.T2.4.2.1.3" class="ltx_td ltx_align_left ltx_border_t">’2000 American-British film</td>
</tr>
<tr id="S4.T2.4.3.2" class="ltx_tr">
<td id="S4.T2.4.3.2.1" class="ltx_td ltx_align_left">Q492251</td>
<td id="S4.T2.4.3.2.2" class="ltx_td ltx_align_left">Chocolat</td>
<td id="S4.T2.4.3.2.3" class="ltx_td ltx_align_left">South Korean girl group</td>
</tr>
<tr id="S4.T2.4.4.3" class="ltx_tr">
<td id="S4.T2.4.4.3.1" class="ltx_td ltx_align_left">Q2964260</td>
<td id="S4.T2.4.4.3.2" class="ltx_td ltx_align_left">Chocolat</td>
<td id="S4.T2.4.4.3.3" class="ltx_td ltx_align_left">Clown of Afro-Cuban descent</td>
</tr>
<tr id="S4.T2.4.5.4" class="ltx_tr" style="background-color:#FFFFA6;">
<td id="S4.T2.4.5.4.1" class="ltx_td ltx_align_left"><span id="S4.T2.4.5.4.1.1" class="ltx_text" style="background-color:#FFFFA6;">Q591780</span></td>
<td id="S4.T2.4.5.4.2" class="ltx_td ltx_align_left"><span id="S4.T2.4.5.4.2.1" class="ltx_text" style="background-color:#FFFFA6;">Chocolat</span></td>
<td id="S4.T2.4.5.4.3" class="ltx_td ltx_align_left"><span id="S4.T2.4.5.4.3.1" class="ltx_text" style="background-color:#FFFFA6;">1988 French film by Claire D.</span></td>
</tr>
<tr id="S4.T2.4.6.5" class="ltx_tr">
<td id="S4.T2.4.6.5.1" class="ltx_td ltx_align_left">Q195</td>
<td id="S4.T2.4.6.5.2" class="ltx_td ltx_align_left">Chocolate</td>
<td id="S4.T2.4.6.5.3" class="ltx_td ltx_align_left">Food produced from cacao seed</td>
</tr>
<tr id="S4.T2.4.7.6" class="ltx_tr">
<td id="S4.T2.4.7.6.1" class="ltx_td ltx_align_left ltx_border_bb">Q977422</td>
<td id="S4.T2.4.7.6.2" class="ltx_td ltx_align_left ltx_border_bb">Chocolate Hills</td>
<td id="S4.T2.4.7.6.3" class="ltx_td ltx_align_left ltx_border_bb">Geological formation in Bohol</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">For this, we use the mapping from the linked Wikipedia pages to DBpedia <cite class="ltx_cite ltx_citemacro_citep">(Bizer et al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2009</a>)</cite> and to Yago <cite class="ltx_cite ltx_citemacro_citep">(Suchanek et al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2007</a>)</cite> semantic types.
The DBpedia classes are organized in a tree which is expansive. To simplify class extraction, we focus only on the first level of the tree, which contains the most general 30 classes. For instance, if the DBpedia mapping assigns the entity ”Finding Nemo” to the type <span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_italic">Movie</span> then we classify ”Finding Nemo” as type <span id="S4.SS2.p2.1.2" class="ltx_text ltx_font_italic">Work</span>, which represents the highest superclass encompassing the <span id="S4.SS2.p2.1.3" class="ltx_text ltx_font_italic">Movie</span> class. By propagating all entities to their most general superclass, we reduce the number of classes. The result is a set of unbalanced classes. To mitigate the unbalance in entity occurrences, we remove the small classes, which leave us with the classes: <span id="S4.SS2.p2.1.4" class="ltx_text ltx_font_italic">Activity, Agent, Architectural Structure, Event, Place, Species</span> and <span id="S4.SS2.p2.1.5" class="ltx_text ltx_font_italic">Work</span>. Since most of the entities labeled as <span id="S4.SS2.p2.1.6" class="ltx_text ltx_font_italic">Species</span> were actually of type <span id="S4.SS2.p2.1.7" class="ltx_text ltx_font_italic">Person</span> (subtype of Species), we classify them as type <span id="S4.SS2.p2.1.8" class="ltx_text ltx_font_italic">Person</span> instead. Similarly, we substitute the class <span id="S4.SS2.p2.1.9" class="ltx_text ltx_font_italic">Agent</span> with its subclass <span id="S4.SS2.p2.1.10" class="ltx_text ltx_font_italic">Organization</span>. Consequently, we have a set of <math id="S4.SS2.p2.1.m1.1" class="ltx_Math" alttext="7" display="inline"><semantics id="S4.SS2.p2.1.m1.1a"><mn id="S4.SS2.p2.1.m1.1.1" xref="S4.SS2.p2.1.m1.1.1.cmml">7</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p2.1.m1.1b"><cn type="integer" id="S4.SS2.p2.1.m1.1.1.cmml" xref="S4.SS2.p2.1.m1.1.1">7</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p2.1.m1.1c">7</annotation></semantics></math> distinct entity types with which we annotate the linked entities in the tables: <span id="S4.SS2.p2.1.11" class="ltx_text ltx_font_italic">Activity, Organization, Architectural Structure, Event, Place, Person</span> and <span id="S4.SS2.p2.1.12" class="ltx_text ltx_font_italic">Work</span>.</p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">An entity mention can consist of multiple words, like the entity ”Finding Nemo”. To ensure that the proposed dataset is compatible with both sequence labeling models and LLMS, we use both a BIO labeling scheme <cite class="ltx_cite ltx_citemacro_citep">(Ramshaw and Marcus, <a href="#bib.bib28" title="" class="ltx_ref">1995</a>)</cite> and a span-based labeling scheme <cite class="ltx_cite ltx_citemacro_citep">(Joshi et al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2020</a>)</cite>. We assign BIO labels such that the first token of a mention receives the B-prefix of its type name, while any subsequent token within the same mention receives the I-prefix. Tokens that are not associated with any entity mention are labeled as O. For example, the entity ”Finding Nemo” from Figure <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> is labels as [(Finding, B-Work), (Nemo, I-Work)].</p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.5" class="ltx_p">For the span-based labeling approach, we leverage the information provided in the original WikiTables dataset<cite class="ltx_cite ltx_citemacro_citep">(Bhagavatula et al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2015</a>)</cite>, where for every linked entity it is indicated the starting and ending positions of its span within the cell. The span label for an entity includes the cell position, the start and end of the span and the numerical value of the label. For example the entity ”Finding Nemo” has a span label <math id="S4.SS2.p4.1.m1.5" class="ltx_Math" alttext="[2,2,0,12,7]" display="inline"><semantics id="S4.SS2.p4.1.m1.5a"><mrow id="S4.SS2.p4.1.m1.5.6.2" xref="S4.SS2.p4.1.m1.5.6.1.cmml"><mo stretchy="false" id="S4.SS2.p4.1.m1.5.6.2.1" xref="S4.SS2.p4.1.m1.5.6.1.cmml">[</mo><mn id="S4.SS2.p4.1.m1.1.1" xref="S4.SS2.p4.1.m1.1.1.cmml">2</mn><mo id="S4.SS2.p4.1.m1.5.6.2.2" xref="S4.SS2.p4.1.m1.5.6.1.cmml">,</mo><mn id="S4.SS2.p4.1.m1.2.2" xref="S4.SS2.p4.1.m1.2.2.cmml">2</mn><mo id="S4.SS2.p4.1.m1.5.6.2.3" xref="S4.SS2.p4.1.m1.5.6.1.cmml">,</mo><mn id="S4.SS2.p4.1.m1.3.3" xref="S4.SS2.p4.1.m1.3.3.cmml">0</mn><mo id="S4.SS2.p4.1.m1.5.6.2.4" xref="S4.SS2.p4.1.m1.5.6.1.cmml">,</mo><mn id="S4.SS2.p4.1.m1.4.4" xref="S4.SS2.p4.1.m1.4.4.cmml">12</mn><mo id="S4.SS2.p4.1.m1.5.6.2.5" xref="S4.SS2.p4.1.m1.5.6.1.cmml">,</mo><mn id="S4.SS2.p4.1.m1.5.5" xref="S4.SS2.p4.1.m1.5.5.cmml">7</mn><mo stretchy="false" id="S4.SS2.p4.1.m1.5.6.2.6" xref="S4.SS2.p4.1.m1.5.6.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.1.m1.5b"><list id="S4.SS2.p4.1.m1.5.6.1.cmml" xref="S4.SS2.p4.1.m1.5.6.2"><cn type="integer" id="S4.SS2.p4.1.m1.1.1.cmml" xref="S4.SS2.p4.1.m1.1.1">2</cn><cn type="integer" id="S4.SS2.p4.1.m1.2.2.cmml" xref="S4.SS2.p4.1.m1.2.2">2</cn><cn type="integer" id="S4.SS2.p4.1.m1.3.3.cmml" xref="S4.SS2.p4.1.m1.3.3">0</cn><cn type="integer" id="S4.SS2.p4.1.m1.4.4.cmml" xref="S4.SS2.p4.1.m1.4.4">12</cn><cn type="integer" id="S4.SS2.p4.1.m1.5.5.cmml" xref="S4.SS2.p4.1.m1.5.5">7</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.1.m1.5c">[2,2,0,12,7]</annotation></semantics></math> where <math id="S4.SS2.p4.2.m2.2" class="ltx_Math" alttext="2,2" display="inline"><semantics id="S4.SS2.p4.2.m2.2a"><mrow id="S4.SS2.p4.2.m2.2.3.2" xref="S4.SS2.p4.2.m2.2.3.1.cmml"><mn id="S4.SS2.p4.2.m2.1.1" xref="S4.SS2.p4.2.m2.1.1.cmml">2</mn><mo id="S4.SS2.p4.2.m2.2.3.2.1" xref="S4.SS2.p4.2.m2.2.3.1.cmml">,</mo><mn id="S4.SS2.p4.2.m2.2.2" xref="S4.SS2.p4.2.m2.2.2.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.2.m2.2b"><list id="S4.SS2.p4.2.m2.2.3.1.cmml" xref="S4.SS2.p4.2.m2.2.3.2"><cn type="integer" id="S4.SS2.p4.2.m2.1.1.cmml" xref="S4.SS2.p4.2.m2.1.1">2</cn><cn type="integer" id="S4.SS2.p4.2.m2.2.2.cmml" xref="S4.SS2.p4.2.m2.2.2">2</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.2.m2.2c">2,2</annotation></semantics></math> indicates this entitiy is in the 2-nd row, 2-nd column in the table, the start of the span is at position <math id="S4.SS2.p4.3.m3.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S4.SS2.p4.3.m3.1a"><mn id="S4.SS2.p4.3.m3.1.1" xref="S4.SS2.p4.3.m3.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.3.m3.1b"><cn type="integer" id="S4.SS2.p4.3.m3.1.1.cmml" xref="S4.SS2.p4.3.m3.1.1">0</cn></annotation-xml></semantics></math> in the cell and it ends at <math id="S4.SS2.p4.4.m4.1" class="ltx_Math" alttext="12" display="inline"><semantics id="S4.SS2.p4.4.m4.1a"><mn id="S4.SS2.p4.4.m4.1.1" xref="S4.SS2.p4.4.m4.1.1.cmml">12</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.4.m4.1b"><cn type="integer" id="S4.SS2.p4.4.m4.1.1.cmml" xref="S4.SS2.p4.4.m4.1.1">12</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.4.m4.1c">12</annotation></semantics></math> and it has label <math id="S4.SS2.p4.5.m5.1" class="ltx_Math" alttext="7" display="inline"><semantics id="S4.SS2.p4.5.m5.1a"><mn id="S4.SS2.p4.5.m5.1.1" xref="S4.SS2.p4.5.m5.1.1.cmml">7</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.p4.5.m5.1b"><cn type="integer" id="S4.SS2.p4.5.m5.1.1.cmml" xref="S4.SS2.p4.5.m5.1.1">7</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p4.5.m5.1c">7</annotation></semantics></math> which corresponds to the entity type <span id="S4.SS2.p4.5.1" class="ltx_text ltx_font_italic">Work</span>. Every entity in the Wiki-TabNER dataset that is linked to Wikipedia page and it has a DBpedia or Yago type is labeled with both the BIO and span-based labeling schemes.</p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.1" class="ltx_p">However, there are entities which are linked to a Wikipedia page, but do lack a corresponding DBpedia entry, resulting in a missing an entity type. An example is the entity ”Astor Piazzolla” from the example table in Figure <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. Additionally, certain entities are not linked at all, so we cannot assign any entity type. These unlinked entities, such as ”Nostradamus” and ”Haketa Takefumi”, are disregarded when addressing the NER or EL task. We discuss more about the limitations of the dataset in section <a href="#S9.SS1" title="9.1. Data quality issues ‣ 9. Limitations ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9.1</span></a>.</p>
</div>
<div id="S4.SS2.p6" class="ltx_para">
<p id="S4.SS2.p6.2" class="ltx_p">The labeling of the dataset results in a richly annotated and reusable dataset where each table contains several unique labels. Figure <a href="#S4.F6" title="Figure 6 ‣ 4.1. Dataset Construction ‣ 4. New Dataset Proposal ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> illustrates the distribution of distinct labels per table within the dataset. In Figure <a href="#S4.F5" title="Figure 5 ‣ 4.1. Dataset Construction ‣ 4. New Dataset Proposal ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> we show the average number of entities per entity type.
Despite the imbalance in label distribution, with the smallest class, <span id="S4.SS2.p6.2.1" class="ltx_text ltx_font_italic">Activity</span>, containing <math id="S4.SS2.p6.1.m1.2" class="ltx_Math" alttext="15,094" display="inline"><semantics id="S4.SS2.p6.1.m1.2a"><mrow id="S4.SS2.p6.1.m1.2.3.2" xref="S4.SS2.p6.1.m1.2.3.1.cmml"><mn id="S4.SS2.p6.1.m1.1.1" xref="S4.SS2.p6.1.m1.1.1.cmml">15</mn><mo id="S4.SS2.p6.1.m1.2.3.2.1" xref="S4.SS2.p6.1.m1.2.3.1.cmml">,</mo><mn id="S4.SS2.p6.1.m1.2.2" xref="S4.SS2.p6.1.m1.2.2.cmml">094</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.1.m1.2b"><list id="S4.SS2.p6.1.m1.2.3.1.cmml" xref="S4.SS2.p6.1.m1.2.3.2"><cn type="integer" id="S4.SS2.p6.1.m1.1.1.cmml" xref="S4.SS2.p6.1.m1.1.1">15</cn><cn type="integer" id="S4.SS2.p6.1.m1.2.2.cmml" xref="S4.SS2.p6.1.m1.2.2">094</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.1.m1.2c">15,094</annotation></semantics></math> instances and the largest, <span id="S4.SS2.p6.2.2" class="ltx_text ltx_font_italic">Person</span>, containing <math id="S4.SS2.p6.2.m2.2" class="ltx_Math" alttext="571,686" display="inline"><semantics id="S4.SS2.p6.2.m2.2a"><mrow id="S4.SS2.p6.2.m2.2.3.2" xref="S4.SS2.p6.2.m2.2.3.1.cmml"><mn id="S4.SS2.p6.2.m2.1.1" xref="S4.SS2.p6.2.m2.1.1.cmml">571</mn><mo id="S4.SS2.p6.2.m2.2.3.2.1" xref="S4.SS2.p6.2.m2.2.3.1.cmml">,</mo><mn id="S4.SS2.p6.2.m2.2.2" xref="S4.SS2.p6.2.m2.2.2.cmml">686</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p6.2.m2.2b"><list id="S4.SS2.p6.2.m2.2.3.1.cmml" xref="S4.SS2.p6.2.m2.2.3.2"><cn type="integer" id="S4.SS2.p6.2.m2.1.1.cmml" xref="S4.SS2.p6.2.m2.1.1">571</cn><cn type="integer" id="S4.SS2.p6.2.m2.2.2.cmml" xref="S4.SS2.p6.2.m2.2.2">686</cn></list></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p6.2.m2.2c">571,686</annotation></semantics></math> instances, the dataset is suitable for evaluating various models.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Table NER with LLMs</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this paper, we present how the Wiki-TabNER dataset can be used to evaluate the performance of LLMs on the NER task, specifically on the subcell level within tables.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.10" class="ltx_p">A table defined by <math id="S5.p2.1.m1.2" class="ltx_Math" alttext="T=(C,H)" display="inline"><semantics id="S5.p2.1.m1.2a"><mrow id="S5.p2.1.m1.2.3" xref="S5.p2.1.m1.2.3.cmml"><mi id="S5.p2.1.m1.2.3.2" xref="S5.p2.1.m1.2.3.2.cmml">T</mi><mo id="S5.p2.1.m1.2.3.1" xref="S5.p2.1.m1.2.3.1.cmml">=</mo><mrow id="S5.p2.1.m1.2.3.3.2" xref="S5.p2.1.m1.2.3.3.1.cmml"><mo stretchy="false" id="S5.p2.1.m1.2.3.3.2.1" xref="S5.p2.1.m1.2.3.3.1.cmml">(</mo><mi id="S5.p2.1.m1.1.1" xref="S5.p2.1.m1.1.1.cmml">C</mi><mo id="S5.p2.1.m1.2.3.3.2.2" xref="S5.p2.1.m1.2.3.3.1.cmml">,</mo><mi id="S5.p2.1.m1.2.2" xref="S5.p2.1.m1.2.2.cmml">H</mi><mo stretchy="false" id="S5.p2.1.m1.2.3.3.2.3" xref="S5.p2.1.m1.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.1.m1.2b"><apply id="S5.p2.1.m1.2.3.cmml" xref="S5.p2.1.m1.2.3"><eq id="S5.p2.1.m1.2.3.1.cmml" xref="S5.p2.1.m1.2.3.1"></eq><ci id="S5.p2.1.m1.2.3.2.cmml" xref="S5.p2.1.m1.2.3.2">𝑇</ci><interval closure="open" id="S5.p2.1.m1.2.3.3.1.cmml" xref="S5.p2.1.m1.2.3.3.2"><ci id="S5.p2.1.m1.1.1.cmml" xref="S5.p2.1.m1.1.1">𝐶</ci><ci id="S5.p2.1.m1.2.2.cmml" xref="S5.p2.1.m1.2.2">𝐻</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.1.m1.2c">T=(C,H)</annotation></semantics></math> stores information in a 2 dimensional arrangement with <math id="S5.p2.2.m2.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S5.p2.2.m2.1a"><mi id="S5.p2.2.m2.1.1" xref="S5.p2.2.m2.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S5.p2.2.m2.1b"><ci id="S5.p2.2.m2.1.1.cmml" xref="S5.p2.2.m2.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.2.m2.1c">n</annotation></semantics></math> rows and <math id="S5.p2.3.m3.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S5.p2.3.m3.1a"><mi id="S5.p2.3.m3.1.1" xref="S5.p2.3.m3.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S5.p2.3.m3.1b"><ci id="S5.p2.3.m3.1.1.cmml" xref="S5.p2.3.m3.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.3.m3.1c">m</annotation></semantics></math> columns where <math id="S5.p2.4.m4.10" class="ltx_Math" alttext="C=\{c_{1,1},c_{1,2},...,c_{n,m}\}" display="inline"><semantics id="S5.p2.4.m4.10a"><mrow id="S5.p2.4.m4.10.10" xref="S5.p2.4.m4.10.10.cmml"><mi id="S5.p2.4.m4.10.10.5" xref="S5.p2.4.m4.10.10.5.cmml">C</mi><mo id="S5.p2.4.m4.10.10.4" xref="S5.p2.4.m4.10.10.4.cmml">=</mo><mrow id="S5.p2.4.m4.10.10.3.3" xref="S5.p2.4.m4.10.10.3.4.cmml"><mo stretchy="false" id="S5.p2.4.m4.10.10.3.3.4" xref="S5.p2.4.m4.10.10.3.4.cmml">{</mo><msub id="S5.p2.4.m4.8.8.1.1.1" xref="S5.p2.4.m4.8.8.1.1.1.cmml"><mi id="S5.p2.4.m4.8.8.1.1.1.2" xref="S5.p2.4.m4.8.8.1.1.1.2.cmml">c</mi><mrow id="S5.p2.4.m4.2.2.2.4" xref="S5.p2.4.m4.2.2.2.3.cmml"><mn id="S5.p2.4.m4.1.1.1.1" xref="S5.p2.4.m4.1.1.1.1.cmml">1</mn><mo id="S5.p2.4.m4.2.2.2.4.1" xref="S5.p2.4.m4.2.2.2.3.cmml">,</mo><mn id="S5.p2.4.m4.2.2.2.2" xref="S5.p2.4.m4.2.2.2.2.cmml">1</mn></mrow></msub><mo id="S5.p2.4.m4.10.10.3.3.5" xref="S5.p2.4.m4.10.10.3.4.cmml">,</mo><msub id="S5.p2.4.m4.9.9.2.2.2" xref="S5.p2.4.m4.9.9.2.2.2.cmml"><mi id="S5.p2.4.m4.9.9.2.2.2.2" xref="S5.p2.4.m4.9.9.2.2.2.2.cmml">c</mi><mrow id="S5.p2.4.m4.4.4.2.4" xref="S5.p2.4.m4.4.4.2.3.cmml"><mn id="S5.p2.4.m4.3.3.1.1" xref="S5.p2.4.m4.3.3.1.1.cmml">1</mn><mo id="S5.p2.4.m4.4.4.2.4.1" xref="S5.p2.4.m4.4.4.2.3.cmml">,</mo><mn id="S5.p2.4.m4.4.4.2.2" xref="S5.p2.4.m4.4.4.2.2.cmml">2</mn></mrow></msub><mo id="S5.p2.4.m4.10.10.3.3.6" xref="S5.p2.4.m4.10.10.3.4.cmml">,</mo><mi mathvariant="normal" id="S5.p2.4.m4.7.7" xref="S5.p2.4.m4.7.7.cmml">…</mi><mo id="S5.p2.4.m4.10.10.3.3.7" xref="S5.p2.4.m4.10.10.3.4.cmml">,</mo><msub id="S5.p2.4.m4.10.10.3.3.3" xref="S5.p2.4.m4.10.10.3.3.3.cmml"><mi id="S5.p2.4.m4.10.10.3.3.3.2" xref="S5.p2.4.m4.10.10.3.3.3.2.cmml">c</mi><mrow id="S5.p2.4.m4.6.6.2.4" xref="S5.p2.4.m4.6.6.2.3.cmml"><mi id="S5.p2.4.m4.5.5.1.1" xref="S5.p2.4.m4.5.5.1.1.cmml">n</mi><mo id="S5.p2.4.m4.6.6.2.4.1" xref="S5.p2.4.m4.6.6.2.3.cmml">,</mo><mi id="S5.p2.4.m4.6.6.2.2" xref="S5.p2.4.m4.6.6.2.2.cmml">m</mi></mrow></msub><mo stretchy="false" id="S5.p2.4.m4.10.10.3.3.8" xref="S5.p2.4.m4.10.10.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.4.m4.10b"><apply id="S5.p2.4.m4.10.10.cmml" xref="S5.p2.4.m4.10.10"><eq id="S5.p2.4.m4.10.10.4.cmml" xref="S5.p2.4.m4.10.10.4"></eq><ci id="S5.p2.4.m4.10.10.5.cmml" xref="S5.p2.4.m4.10.10.5">𝐶</ci><set id="S5.p2.4.m4.10.10.3.4.cmml" xref="S5.p2.4.m4.10.10.3.3"><apply id="S5.p2.4.m4.8.8.1.1.1.cmml" xref="S5.p2.4.m4.8.8.1.1.1"><csymbol cd="ambiguous" id="S5.p2.4.m4.8.8.1.1.1.1.cmml" xref="S5.p2.4.m4.8.8.1.1.1">subscript</csymbol><ci id="S5.p2.4.m4.8.8.1.1.1.2.cmml" xref="S5.p2.4.m4.8.8.1.1.1.2">𝑐</ci><list id="S5.p2.4.m4.2.2.2.3.cmml" xref="S5.p2.4.m4.2.2.2.4"><cn type="integer" id="S5.p2.4.m4.1.1.1.1.cmml" xref="S5.p2.4.m4.1.1.1.1">1</cn><cn type="integer" id="S5.p2.4.m4.2.2.2.2.cmml" xref="S5.p2.4.m4.2.2.2.2">1</cn></list></apply><apply id="S5.p2.4.m4.9.9.2.2.2.cmml" xref="S5.p2.4.m4.9.9.2.2.2"><csymbol cd="ambiguous" id="S5.p2.4.m4.9.9.2.2.2.1.cmml" xref="S5.p2.4.m4.9.9.2.2.2">subscript</csymbol><ci id="S5.p2.4.m4.9.9.2.2.2.2.cmml" xref="S5.p2.4.m4.9.9.2.2.2.2">𝑐</ci><list id="S5.p2.4.m4.4.4.2.3.cmml" xref="S5.p2.4.m4.4.4.2.4"><cn type="integer" id="S5.p2.4.m4.3.3.1.1.cmml" xref="S5.p2.4.m4.3.3.1.1">1</cn><cn type="integer" id="S5.p2.4.m4.4.4.2.2.cmml" xref="S5.p2.4.m4.4.4.2.2">2</cn></list></apply><ci id="S5.p2.4.m4.7.7.cmml" xref="S5.p2.4.m4.7.7">…</ci><apply id="S5.p2.4.m4.10.10.3.3.3.cmml" xref="S5.p2.4.m4.10.10.3.3.3"><csymbol cd="ambiguous" id="S5.p2.4.m4.10.10.3.3.3.1.cmml" xref="S5.p2.4.m4.10.10.3.3.3">subscript</csymbol><ci id="S5.p2.4.m4.10.10.3.3.3.2.cmml" xref="S5.p2.4.m4.10.10.3.3.3.2">𝑐</ci><list id="S5.p2.4.m4.6.6.2.3.cmml" xref="S5.p2.4.m4.6.6.2.4"><ci id="S5.p2.4.m4.5.5.1.1.cmml" xref="S5.p2.4.m4.5.5.1.1">𝑛</ci><ci id="S5.p2.4.m4.6.6.2.2.cmml" xref="S5.p2.4.m4.6.6.2.2">𝑚</ci></list></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.4.m4.10c">C=\{c_{1,1},c_{1,2},...,c_{n,m}\}</annotation></semantics></math> is the set of table body cells, and <math id="S5.p2.5.m5.4" class="ltx_Math" alttext="H=\{h_{1},h_{2},...,h_{m}\}" display="inline"><semantics id="S5.p2.5.m5.4a"><mrow id="S5.p2.5.m5.4.4" xref="S5.p2.5.m5.4.4.cmml"><mi id="S5.p2.5.m5.4.4.5" xref="S5.p2.5.m5.4.4.5.cmml">H</mi><mo id="S5.p2.5.m5.4.4.4" xref="S5.p2.5.m5.4.4.4.cmml">=</mo><mrow id="S5.p2.5.m5.4.4.3.3" xref="S5.p2.5.m5.4.4.3.4.cmml"><mo stretchy="false" id="S5.p2.5.m5.4.4.3.3.4" xref="S5.p2.5.m5.4.4.3.4.cmml">{</mo><msub id="S5.p2.5.m5.2.2.1.1.1" xref="S5.p2.5.m5.2.2.1.1.1.cmml"><mi id="S5.p2.5.m5.2.2.1.1.1.2" xref="S5.p2.5.m5.2.2.1.1.1.2.cmml">h</mi><mn id="S5.p2.5.m5.2.2.1.1.1.3" xref="S5.p2.5.m5.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S5.p2.5.m5.4.4.3.3.5" xref="S5.p2.5.m5.4.4.3.4.cmml">,</mo><msub id="S5.p2.5.m5.3.3.2.2.2" xref="S5.p2.5.m5.3.3.2.2.2.cmml"><mi id="S5.p2.5.m5.3.3.2.2.2.2" xref="S5.p2.5.m5.3.3.2.2.2.2.cmml">h</mi><mn id="S5.p2.5.m5.3.3.2.2.2.3" xref="S5.p2.5.m5.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S5.p2.5.m5.4.4.3.3.6" xref="S5.p2.5.m5.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S5.p2.5.m5.1.1" xref="S5.p2.5.m5.1.1.cmml">…</mi><mo id="S5.p2.5.m5.4.4.3.3.7" xref="S5.p2.5.m5.4.4.3.4.cmml">,</mo><msub id="S5.p2.5.m5.4.4.3.3.3" xref="S5.p2.5.m5.4.4.3.3.3.cmml"><mi id="S5.p2.5.m5.4.4.3.3.3.2" xref="S5.p2.5.m5.4.4.3.3.3.2.cmml">h</mi><mi id="S5.p2.5.m5.4.4.3.3.3.3" xref="S5.p2.5.m5.4.4.3.3.3.3.cmml">m</mi></msub><mo stretchy="false" id="S5.p2.5.m5.4.4.3.3.8" xref="S5.p2.5.m5.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.5.m5.4b"><apply id="S5.p2.5.m5.4.4.cmml" xref="S5.p2.5.m5.4.4"><eq id="S5.p2.5.m5.4.4.4.cmml" xref="S5.p2.5.m5.4.4.4"></eq><ci id="S5.p2.5.m5.4.4.5.cmml" xref="S5.p2.5.m5.4.4.5">𝐻</ci><set id="S5.p2.5.m5.4.4.3.4.cmml" xref="S5.p2.5.m5.4.4.3.3"><apply id="S5.p2.5.m5.2.2.1.1.1.cmml" xref="S5.p2.5.m5.2.2.1.1.1"><csymbol cd="ambiguous" id="S5.p2.5.m5.2.2.1.1.1.1.cmml" xref="S5.p2.5.m5.2.2.1.1.1">subscript</csymbol><ci id="S5.p2.5.m5.2.2.1.1.1.2.cmml" xref="S5.p2.5.m5.2.2.1.1.1.2">ℎ</ci><cn type="integer" id="S5.p2.5.m5.2.2.1.1.1.3.cmml" xref="S5.p2.5.m5.2.2.1.1.1.3">1</cn></apply><apply id="S5.p2.5.m5.3.3.2.2.2.cmml" xref="S5.p2.5.m5.3.3.2.2.2"><csymbol cd="ambiguous" id="S5.p2.5.m5.3.3.2.2.2.1.cmml" xref="S5.p2.5.m5.3.3.2.2.2">subscript</csymbol><ci id="S5.p2.5.m5.3.3.2.2.2.2.cmml" xref="S5.p2.5.m5.3.3.2.2.2.2">ℎ</ci><cn type="integer" id="S5.p2.5.m5.3.3.2.2.2.3.cmml" xref="S5.p2.5.m5.3.3.2.2.2.3">2</cn></apply><ci id="S5.p2.5.m5.1.1.cmml" xref="S5.p2.5.m5.1.1">…</ci><apply id="S5.p2.5.m5.4.4.3.3.3.cmml" xref="S5.p2.5.m5.4.4.3.3.3"><csymbol cd="ambiguous" id="S5.p2.5.m5.4.4.3.3.3.1.cmml" xref="S5.p2.5.m5.4.4.3.3.3">subscript</csymbol><ci id="S5.p2.5.m5.4.4.3.3.3.2.cmml" xref="S5.p2.5.m5.4.4.3.3.3.2">ℎ</ci><ci id="S5.p2.5.m5.4.4.3.3.3.3.cmml" xref="S5.p2.5.m5.4.4.3.3.3.3">𝑚</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.5.m5.4c">H=\{h_{1},h_{2},...,h_{m}\}</annotation></semantics></math> is the set of table headers. Each cell <math id="S5.p2.6.m6.2" class="ltx_Math" alttext="c_{i,j}" display="inline"><semantics id="S5.p2.6.m6.2a"><msub id="S5.p2.6.m6.2.3" xref="S5.p2.6.m6.2.3.cmml"><mi id="S5.p2.6.m6.2.3.2" xref="S5.p2.6.m6.2.3.2.cmml">c</mi><mrow id="S5.p2.6.m6.2.2.2.4" xref="S5.p2.6.m6.2.2.2.3.cmml"><mi id="S5.p2.6.m6.1.1.1.1" xref="S5.p2.6.m6.1.1.1.1.cmml">i</mi><mo id="S5.p2.6.m6.2.2.2.4.1" xref="S5.p2.6.m6.2.2.2.3.cmml">,</mo><mi id="S5.p2.6.m6.2.2.2.2" xref="S5.p2.6.m6.2.2.2.2.cmml">j</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.p2.6.m6.2b"><apply id="S5.p2.6.m6.2.3.cmml" xref="S5.p2.6.m6.2.3"><csymbol cd="ambiguous" id="S5.p2.6.m6.2.3.1.cmml" xref="S5.p2.6.m6.2.3">subscript</csymbol><ci id="S5.p2.6.m6.2.3.2.cmml" xref="S5.p2.6.m6.2.3.2">𝑐</ci><list id="S5.p2.6.m6.2.2.2.3.cmml" xref="S5.p2.6.m6.2.2.2.4"><ci id="S5.p2.6.m6.1.1.1.1.cmml" xref="S5.p2.6.m6.1.1.1.1">𝑖</ci><ci id="S5.p2.6.m6.2.2.2.2.cmml" xref="S5.p2.6.m6.2.2.2.2">𝑗</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.6.m6.2c">c_{i,j}</annotation></semantics></math> is composed of a list of <math id="S5.p2.7.m7.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S5.p2.7.m7.1a"><mi id="S5.p2.7.m7.1.1" xref="S5.p2.7.m7.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S5.p2.7.m7.1b"><ci id="S5.p2.7.m7.1.1.cmml" xref="S5.p2.7.m7.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.7.m7.1c">t</annotation></semantics></math> tokens: <math id="S5.p2.8.m8.18" class="ltx_Math" alttext="c_{i,j}=(w_{c_{i,j},1},w_{c_{i,j},2},...,w_{c_{i,j},t})" display="inline"><semantics id="S5.p2.8.m8.18a"><mrow id="S5.p2.8.m8.18.18" xref="S5.p2.8.m8.18.18.cmml"><msub id="S5.p2.8.m8.18.18.5" xref="S5.p2.8.m8.18.18.5.cmml"><mi id="S5.p2.8.m8.18.18.5.2" xref="S5.p2.8.m8.18.18.5.2.cmml">c</mi><mrow id="S5.p2.8.m8.2.2.2.4" xref="S5.p2.8.m8.2.2.2.3.cmml"><mi id="S5.p2.8.m8.1.1.1.1" xref="S5.p2.8.m8.1.1.1.1.cmml">i</mi><mo id="S5.p2.8.m8.2.2.2.4.1" xref="S5.p2.8.m8.2.2.2.3.cmml">,</mo><mi id="S5.p2.8.m8.2.2.2.2" xref="S5.p2.8.m8.2.2.2.2.cmml">j</mi></mrow></msub><mo id="S5.p2.8.m8.18.18.4" xref="S5.p2.8.m8.18.18.4.cmml">=</mo><mrow id="S5.p2.8.m8.18.18.3.3" xref="S5.p2.8.m8.18.18.3.4.cmml"><mo stretchy="false" id="S5.p2.8.m8.18.18.3.3.4" xref="S5.p2.8.m8.18.18.3.4.cmml">(</mo><msub id="S5.p2.8.m8.16.16.1.1.1" xref="S5.p2.8.m8.16.16.1.1.1.cmml"><mi id="S5.p2.8.m8.16.16.1.1.1.2" xref="S5.p2.8.m8.16.16.1.1.1.2.cmml">w</mi><mrow id="S5.p2.8.m8.6.6.4.4" xref="S5.p2.8.m8.6.6.4.5.cmml"><msub id="S5.p2.8.m8.6.6.4.4.1" xref="S5.p2.8.m8.6.6.4.4.1.cmml"><mi id="S5.p2.8.m8.6.6.4.4.1.2" xref="S5.p2.8.m8.6.6.4.4.1.2.cmml">c</mi><mrow id="S5.p2.8.m8.4.4.2.2.2.4" xref="S5.p2.8.m8.4.4.2.2.2.3.cmml"><mi id="S5.p2.8.m8.3.3.1.1.1.1" xref="S5.p2.8.m8.3.3.1.1.1.1.cmml">i</mi><mo id="S5.p2.8.m8.4.4.2.2.2.4.1" xref="S5.p2.8.m8.4.4.2.2.2.3.cmml">,</mo><mi id="S5.p2.8.m8.4.4.2.2.2.2" xref="S5.p2.8.m8.4.4.2.2.2.2.cmml">j</mi></mrow></msub><mo id="S5.p2.8.m8.6.6.4.4.2" xref="S5.p2.8.m8.6.6.4.5.cmml">,</mo><mn id="S5.p2.8.m8.5.5.3.3" xref="S5.p2.8.m8.5.5.3.3.cmml">1</mn></mrow></msub><mo id="S5.p2.8.m8.18.18.3.3.5" xref="S5.p2.8.m8.18.18.3.4.cmml">,</mo><msub id="S5.p2.8.m8.17.17.2.2.2" xref="S5.p2.8.m8.17.17.2.2.2.cmml"><mi id="S5.p2.8.m8.17.17.2.2.2.2" xref="S5.p2.8.m8.17.17.2.2.2.2.cmml">w</mi><mrow id="S5.p2.8.m8.10.10.4.4" xref="S5.p2.8.m8.10.10.4.5.cmml"><msub id="S5.p2.8.m8.10.10.4.4.1" xref="S5.p2.8.m8.10.10.4.4.1.cmml"><mi id="S5.p2.8.m8.10.10.4.4.1.2" xref="S5.p2.8.m8.10.10.4.4.1.2.cmml">c</mi><mrow id="S5.p2.8.m8.8.8.2.2.2.4" xref="S5.p2.8.m8.8.8.2.2.2.3.cmml"><mi id="S5.p2.8.m8.7.7.1.1.1.1" xref="S5.p2.8.m8.7.7.1.1.1.1.cmml">i</mi><mo id="S5.p2.8.m8.8.8.2.2.2.4.1" xref="S5.p2.8.m8.8.8.2.2.2.3.cmml">,</mo><mi id="S5.p2.8.m8.8.8.2.2.2.2" xref="S5.p2.8.m8.8.8.2.2.2.2.cmml">j</mi></mrow></msub><mo id="S5.p2.8.m8.10.10.4.4.2" xref="S5.p2.8.m8.10.10.4.5.cmml">,</mo><mn id="S5.p2.8.m8.9.9.3.3" xref="S5.p2.8.m8.9.9.3.3.cmml">2</mn></mrow></msub><mo id="S5.p2.8.m8.18.18.3.3.6" xref="S5.p2.8.m8.18.18.3.4.cmml">,</mo><mi mathvariant="normal" id="S5.p2.8.m8.15.15" xref="S5.p2.8.m8.15.15.cmml">…</mi><mo id="S5.p2.8.m8.18.18.3.3.7" xref="S5.p2.8.m8.18.18.3.4.cmml">,</mo><msub id="S5.p2.8.m8.18.18.3.3.3" xref="S5.p2.8.m8.18.18.3.3.3.cmml"><mi id="S5.p2.8.m8.18.18.3.3.3.2" xref="S5.p2.8.m8.18.18.3.3.3.2.cmml">w</mi><mrow id="S5.p2.8.m8.14.14.4.4" xref="S5.p2.8.m8.14.14.4.5.cmml"><msub id="S5.p2.8.m8.14.14.4.4.1" xref="S5.p2.8.m8.14.14.4.4.1.cmml"><mi id="S5.p2.8.m8.14.14.4.4.1.2" xref="S5.p2.8.m8.14.14.4.4.1.2.cmml">c</mi><mrow id="S5.p2.8.m8.12.12.2.2.2.4" xref="S5.p2.8.m8.12.12.2.2.2.3.cmml"><mi id="S5.p2.8.m8.11.11.1.1.1.1" xref="S5.p2.8.m8.11.11.1.1.1.1.cmml">i</mi><mo id="S5.p2.8.m8.12.12.2.2.2.4.1" xref="S5.p2.8.m8.12.12.2.2.2.3.cmml">,</mo><mi id="S5.p2.8.m8.12.12.2.2.2.2" xref="S5.p2.8.m8.12.12.2.2.2.2.cmml">j</mi></mrow></msub><mo id="S5.p2.8.m8.14.14.4.4.2" xref="S5.p2.8.m8.14.14.4.5.cmml">,</mo><mi id="S5.p2.8.m8.13.13.3.3" xref="S5.p2.8.m8.13.13.3.3.cmml">t</mi></mrow></msub><mo stretchy="false" id="S5.p2.8.m8.18.18.3.3.8" xref="S5.p2.8.m8.18.18.3.4.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.8.m8.18b"><apply id="S5.p2.8.m8.18.18.cmml" xref="S5.p2.8.m8.18.18"><eq id="S5.p2.8.m8.18.18.4.cmml" xref="S5.p2.8.m8.18.18.4"></eq><apply id="S5.p2.8.m8.18.18.5.cmml" xref="S5.p2.8.m8.18.18.5"><csymbol cd="ambiguous" id="S5.p2.8.m8.18.18.5.1.cmml" xref="S5.p2.8.m8.18.18.5">subscript</csymbol><ci id="S5.p2.8.m8.18.18.5.2.cmml" xref="S5.p2.8.m8.18.18.5.2">𝑐</ci><list id="S5.p2.8.m8.2.2.2.3.cmml" xref="S5.p2.8.m8.2.2.2.4"><ci id="S5.p2.8.m8.1.1.1.1.cmml" xref="S5.p2.8.m8.1.1.1.1">𝑖</ci><ci id="S5.p2.8.m8.2.2.2.2.cmml" xref="S5.p2.8.m8.2.2.2.2">𝑗</ci></list></apply><vector id="S5.p2.8.m8.18.18.3.4.cmml" xref="S5.p2.8.m8.18.18.3.3"><apply id="S5.p2.8.m8.16.16.1.1.1.cmml" xref="S5.p2.8.m8.16.16.1.1.1"><csymbol cd="ambiguous" id="S5.p2.8.m8.16.16.1.1.1.1.cmml" xref="S5.p2.8.m8.16.16.1.1.1">subscript</csymbol><ci id="S5.p2.8.m8.16.16.1.1.1.2.cmml" xref="S5.p2.8.m8.16.16.1.1.1.2">𝑤</ci><list id="S5.p2.8.m8.6.6.4.5.cmml" xref="S5.p2.8.m8.6.6.4.4"><apply id="S5.p2.8.m8.6.6.4.4.1.cmml" xref="S5.p2.8.m8.6.6.4.4.1"><csymbol cd="ambiguous" id="S5.p2.8.m8.6.6.4.4.1.1.cmml" xref="S5.p2.8.m8.6.6.4.4.1">subscript</csymbol><ci id="S5.p2.8.m8.6.6.4.4.1.2.cmml" xref="S5.p2.8.m8.6.6.4.4.1.2">𝑐</ci><list id="S5.p2.8.m8.4.4.2.2.2.3.cmml" xref="S5.p2.8.m8.4.4.2.2.2.4"><ci id="S5.p2.8.m8.3.3.1.1.1.1.cmml" xref="S5.p2.8.m8.3.3.1.1.1.1">𝑖</ci><ci id="S5.p2.8.m8.4.4.2.2.2.2.cmml" xref="S5.p2.8.m8.4.4.2.2.2.2">𝑗</ci></list></apply><cn type="integer" id="S5.p2.8.m8.5.5.3.3.cmml" xref="S5.p2.8.m8.5.5.3.3">1</cn></list></apply><apply id="S5.p2.8.m8.17.17.2.2.2.cmml" xref="S5.p2.8.m8.17.17.2.2.2"><csymbol cd="ambiguous" id="S5.p2.8.m8.17.17.2.2.2.1.cmml" xref="S5.p2.8.m8.17.17.2.2.2">subscript</csymbol><ci id="S5.p2.8.m8.17.17.2.2.2.2.cmml" xref="S5.p2.8.m8.17.17.2.2.2.2">𝑤</ci><list id="S5.p2.8.m8.10.10.4.5.cmml" xref="S5.p2.8.m8.10.10.4.4"><apply id="S5.p2.8.m8.10.10.4.4.1.cmml" xref="S5.p2.8.m8.10.10.4.4.1"><csymbol cd="ambiguous" id="S5.p2.8.m8.10.10.4.4.1.1.cmml" xref="S5.p2.8.m8.10.10.4.4.1">subscript</csymbol><ci id="S5.p2.8.m8.10.10.4.4.1.2.cmml" xref="S5.p2.8.m8.10.10.4.4.1.2">𝑐</ci><list id="S5.p2.8.m8.8.8.2.2.2.3.cmml" xref="S5.p2.8.m8.8.8.2.2.2.4"><ci id="S5.p2.8.m8.7.7.1.1.1.1.cmml" xref="S5.p2.8.m8.7.7.1.1.1.1">𝑖</ci><ci id="S5.p2.8.m8.8.8.2.2.2.2.cmml" xref="S5.p2.8.m8.8.8.2.2.2.2">𝑗</ci></list></apply><cn type="integer" id="S5.p2.8.m8.9.9.3.3.cmml" xref="S5.p2.8.m8.9.9.3.3">2</cn></list></apply><ci id="S5.p2.8.m8.15.15.cmml" xref="S5.p2.8.m8.15.15">…</ci><apply id="S5.p2.8.m8.18.18.3.3.3.cmml" xref="S5.p2.8.m8.18.18.3.3.3"><csymbol cd="ambiguous" id="S5.p2.8.m8.18.18.3.3.3.1.cmml" xref="S5.p2.8.m8.18.18.3.3.3">subscript</csymbol><ci id="S5.p2.8.m8.18.18.3.3.3.2.cmml" xref="S5.p2.8.m8.18.18.3.3.3.2">𝑤</ci><list id="S5.p2.8.m8.14.14.4.5.cmml" xref="S5.p2.8.m8.14.14.4.4"><apply id="S5.p2.8.m8.14.14.4.4.1.cmml" xref="S5.p2.8.m8.14.14.4.4.1"><csymbol cd="ambiguous" id="S5.p2.8.m8.14.14.4.4.1.1.cmml" xref="S5.p2.8.m8.14.14.4.4.1">subscript</csymbol><ci id="S5.p2.8.m8.14.14.4.4.1.2.cmml" xref="S5.p2.8.m8.14.14.4.4.1.2">𝑐</ci><list id="S5.p2.8.m8.12.12.2.2.2.3.cmml" xref="S5.p2.8.m8.12.12.2.2.2.4"><ci id="S5.p2.8.m8.11.11.1.1.1.1.cmml" xref="S5.p2.8.m8.11.11.1.1.1.1">𝑖</ci><ci id="S5.p2.8.m8.12.12.2.2.2.2.cmml" xref="S5.p2.8.m8.12.12.2.2.2.2">𝑗</ci></list></apply><ci id="S5.p2.8.m8.13.13.3.3.cmml" xref="S5.p2.8.m8.13.13.3.3">𝑡</ci></list></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.8.m8.18c">c_{i,j}=(w_{c_{i,j},1},w_{c_{i,j},2},...,w_{c_{i,j},t})</annotation></semantics></math>. The task is to accurately assign an entity type to all of the tokens within a cell. The sequence of entity types is denoted as <math id="S5.p2.9.m9.4" class="ltx_Math" alttext="Y=\{y_{1},y_{2},...,y_{n}\}" display="inline"><semantics id="S5.p2.9.m9.4a"><mrow id="S5.p2.9.m9.4.4" xref="S5.p2.9.m9.4.4.cmml"><mi id="S5.p2.9.m9.4.4.5" xref="S5.p2.9.m9.4.4.5.cmml">Y</mi><mo id="S5.p2.9.m9.4.4.4" xref="S5.p2.9.m9.4.4.4.cmml">=</mo><mrow id="S5.p2.9.m9.4.4.3.3" xref="S5.p2.9.m9.4.4.3.4.cmml"><mo stretchy="false" id="S5.p2.9.m9.4.4.3.3.4" xref="S5.p2.9.m9.4.4.3.4.cmml">{</mo><msub id="S5.p2.9.m9.2.2.1.1.1" xref="S5.p2.9.m9.2.2.1.1.1.cmml"><mi id="S5.p2.9.m9.2.2.1.1.1.2" xref="S5.p2.9.m9.2.2.1.1.1.2.cmml">y</mi><mn id="S5.p2.9.m9.2.2.1.1.1.3" xref="S5.p2.9.m9.2.2.1.1.1.3.cmml">1</mn></msub><mo id="S5.p2.9.m9.4.4.3.3.5" xref="S5.p2.9.m9.4.4.3.4.cmml">,</mo><msub id="S5.p2.9.m9.3.3.2.2.2" xref="S5.p2.9.m9.3.3.2.2.2.cmml"><mi id="S5.p2.9.m9.3.3.2.2.2.2" xref="S5.p2.9.m9.3.3.2.2.2.2.cmml">y</mi><mn id="S5.p2.9.m9.3.3.2.2.2.3" xref="S5.p2.9.m9.3.3.2.2.2.3.cmml">2</mn></msub><mo id="S5.p2.9.m9.4.4.3.3.6" xref="S5.p2.9.m9.4.4.3.4.cmml">,</mo><mi mathvariant="normal" id="S5.p2.9.m9.1.1" xref="S5.p2.9.m9.1.1.cmml">…</mi><mo id="S5.p2.9.m9.4.4.3.3.7" xref="S5.p2.9.m9.4.4.3.4.cmml">,</mo><msub id="S5.p2.9.m9.4.4.3.3.3" xref="S5.p2.9.m9.4.4.3.3.3.cmml"><mi id="S5.p2.9.m9.4.4.3.3.3.2" xref="S5.p2.9.m9.4.4.3.3.3.2.cmml">y</mi><mi id="S5.p2.9.m9.4.4.3.3.3.3" xref="S5.p2.9.m9.4.4.3.3.3.3.cmml">n</mi></msub><mo stretchy="false" id="S5.p2.9.m9.4.4.3.3.8" xref="S5.p2.9.m9.4.4.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.p2.9.m9.4b"><apply id="S5.p2.9.m9.4.4.cmml" xref="S5.p2.9.m9.4.4"><eq id="S5.p2.9.m9.4.4.4.cmml" xref="S5.p2.9.m9.4.4.4"></eq><ci id="S5.p2.9.m9.4.4.5.cmml" xref="S5.p2.9.m9.4.4.5">𝑌</ci><set id="S5.p2.9.m9.4.4.3.4.cmml" xref="S5.p2.9.m9.4.4.3.3"><apply id="S5.p2.9.m9.2.2.1.1.1.cmml" xref="S5.p2.9.m9.2.2.1.1.1"><csymbol cd="ambiguous" id="S5.p2.9.m9.2.2.1.1.1.1.cmml" xref="S5.p2.9.m9.2.2.1.1.1">subscript</csymbol><ci id="S5.p2.9.m9.2.2.1.1.1.2.cmml" xref="S5.p2.9.m9.2.2.1.1.1.2">𝑦</ci><cn type="integer" id="S5.p2.9.m9.2.2.1.1.1.3.cmml" xref="S5.p2.9.m9.2.2.1.1.1.3">1</cn></apply><apply id="S5.p2.9.m9.3.3.2.2.2.cmml" xref="S5.p2.9.m9.3.3.2.2.2"><csymbol cd="ambiguous" id="S5.p2.9.m9.3.3.2.2.2.1.cmml" xref="S5.p2.9.m9.3.3.2.2.2">subscript</csymbol><ci id="S5.p2.9.m9.3.3.2.2.2.2.cmml" xref="S5.p2.9.m9.3.3.2.2.2.2">𝑦</ci><cn type="integer" id="S5.p2.9.m9.3.3.2.2.2.3.cmml" xref="S5.p2.9.m9.3.3.2.2.2.3">2</cn></apply><ci id="S5.p2.9.m9.1.1.cmml" xref="S5.p2.9.m9.1.1">…</ci><apply id="S5.p2.9.m9.4.4.3.3.3.cmml" xref="S5.p2.9.m9.4.4.3.3.3"><csymbol cd="ambiguous" id="S5.p2.9.m9.4.4.3.3.3.1.cmml" xref="S5.p2.9.m9.4.4.3.3.3">subscript</csymbol><ci id="S5.p2.9.m9.4.4.3.3.3.2.cmml" xref="S5.p2.9.m9.4.4.3.3.3.2">𝑦</ci><ci id="S5.p2.9.m9.4.4.3.3.3.3.cmml" xref="S5.p2.9.m9.4.4.3.3.3.3">𝑛</ci></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.9.m9.4c">Y=\{y_{1},y_{2},...,y_{n}\}</annotation></semantics></math>, where each <math id="S5.p2.10.m10.1" class="ltx_Math" alttext="y_{i}" display="inline"><semantics id="S5.p2.10.m10.1a"><msub id="S5.p2.10.m10.1.1" xref="S5.p2.10.m10.1.1.cmml"><mi id="S5.p2.10.m10.1.1.2" xref="S5.p2.10.m10.1.1.2.cmml">y</mi><mi id="S5.p2.10.m10.1.1.3" xref="S5.p2.10.m10.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S5.p2.10.m10.1b"><apply id="S5.p2.10.m10.1.1.cmml" xref="S5.p2.10.m10.1.1"><csymbol cd="ambiguous" id="S5.p2.10.m10.1.1.1.cmml" xref="S5.p2.10.m10.1.1">subscript</csymbol><ci id="S5.p2.10.m10.1.1.2.cmml" xref="S5.p2.10.m10.1.1.2">𝑦</ci><ci id="S5.p2.10.m10.1.1.3.cmml" xref="S5.p2.10.m10.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p2.10.m10.1c">y_{i}</annotation></semantics></math> represents a specific entity type.
The annotation of subcell entities in a table using LLMs consists of several steps.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span>Input Prompt</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">The input to the LLMs is a prompt consisting of three parts. Figure <a href="#S5.F7" title="Figure 7 ‣ 5.1. Input Prompt ‣ 5. Table NER with LLMs ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows an example of an input prompt. The instruction part of the prompt describes the task and it instructs the model how the output should be formatted. It is always the same for all of the models and under the different settings. The example part of the prompt provides a <span id="S5.SS1.p1.1.1" class="ltx_text ltx_font_italic">k</span>-shot example to the model, where <math id="S5.SS1.p1.1.m1.3" class="ltx_Math" alttext="k\in\{0,1,3\}" display="inline"><semantics id="S5.SS1.p1.1.m1.3a"><mrow id="S5.SS1.p1.1.m1.3.4" xref="S5.SS1.p1.1.m1.3.4.cmml"><mi id="S5.SS1.p1.1.m1.3.4.2" xref="S5.SS1.p1.1.m1.3.4.2.cmml">k</mi><mo id="S5.SS1.p1.1.m1.3.4.1" xref="S5.SS1.p1.1.m1.3.4.1.cmml">∈</mo><mrow id="S5.SS1.p1.1.m1.3.4.3.2" xref="S5.SS1.p1.1.m1.3.4.3.1.cmml"><mo stretchy="false" id="S5.SS1.p1.1.m1.3.4.3.2.1" xref="S5.SS1.p1.1.m1.3.4.3.1.cmml">{</mo><mn id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml">0</mn><mo id="S5.SS1.p1.1.m1.3.4.3.2.2" xref="S5.SS1.p1.1.m1.3.4.3.1.cmml">,</mo><mn id="S5.SS1.p1.1.m1.2.2" xref="S5.SS1.p1.1.m1.2.2.cmml">1</mn><mo id="S5.SS1.p1.1.m1.3.4.3.2.3" xref="S5.SS1.p1.1.m1.3.4.3.1.cmml">,</mo><mn id="S5.SS1.p1.1.m1.3.3" xref="S5.SS1.p1.1.m1.3.3.cmml">3</mn><mo stretchy="false" id="S5.SS1.p1.1.m1.3.4.3.2.4" xref="S5.SS1.p1.1.m1.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.3b"><apply id="S5.SS1.p1.1.m1.3.4.cmml" xref="S5.SS1.p1.1.m1.3.4"><in id="S5.SS1.p1.1.m1.3.4.1.cmml" xref="S5.SS1.p1.1.m1.3.4.1"></in><ci id="S5.SS1.p1.1.m1.3.4.2.cmml" xref="S5.SS1.p1.1.m1.3.4.2">𝑘</ci><set id="S5.SS1.p1.1.m1.3.4.3.1.cmml" xref="S5.SS1.p1.1.m1.3.4.3.2"><cn type="integer" id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1">0</cn><cn type="integer" id="S5.SS1.p1.1.m1.2.2.cmml" xref="S5.SS1.p1.1.m1.2.2">1</cn><cn type="integer" id="S5.SS1.p1.1.m1.3.3.cmml" xref="S5.SS1.p1.1.m1.3.3">3</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.3c">k\in\{0,1,3\}</annotation></semantics></math>. Each example consists of a table and an output with the annotated entities from this table. However, in the case of 0-shot evaluation, instead of leaving this part empty, we show the model one row of a table and 2 annotated entities as an enhanced instruction. We found that without any example, the models give randomly structured output which is difficult to evaluate.
Finally, the last part of the prompt is the input table from which the model should extract the subcell entities and identify their entity types.</p>
</div>
<figure id="S5.F7" class="ltx_figure"><svg id="S5.F7.pic1" class="ltx_picture ltx_centering" height="440.73" overflow="visible" version="1.1" width="600"><g transform="translate(0,440.73) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#000000" fill-opacity="1.0"><path d="M 0 5.91 L 0 434.82 C 0 438.08 2.64 440.73 5.91 440.73 L 594.09 440.73 C 597.36 440.73 600 438.08 600 434.82 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 434.82 C 1.97 436.99 3.73 438.76 5.91 438.76 L 594.09 438.76 C 596.27 438.76 598.03 436.99 598.03 434.82 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignObject width="556.69" height="413.17" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:402.3pt;">
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.6" class="ltx_p"><span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.6.1" class="ltx_text ltx_font_italic">Instruction:</span></span>
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.7" class="ltx_p">You are an NER expert. Extract entities from the input table using the following types: Activity, <span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.7.1" class="ltx_text ltx_font_bold">Organisation</span>, ArchitecturalStructure, Event, <span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.7.2" class="ltx_text ltx_font_bold">Place</span>, <span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.7.3" class="ltx_text ltx_font_bold">Person</span>, <span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.7.4" class="ltx_text ltx_font_bold">Work</span>.
If the type of the entity is not one of the types above, please use type: MISC. The output is a list with dictionary for every entity in the following format:</span>
<span id="S5.Ex1" class="ltx_equation ltx_eqn_table">

<span><span class="ltx_equation ltx_eqn_row ltx_align_baseline">
<span class="ltx_eqn_cell ltx_eqn_center_padleft"></span>
<span class="ltx_eqn_cell ltx_align_center"><math id="S5.Ex1.m1.4" class="ltx_Math" alttext='\{"entity":Entity,"type":Type,"cell\_index":[x,y]\}' display="block"><semantics id="S5.Ex1.m1.4a"><mrow id="S5.Ex1.m1.4.4.2" xref="S5.Ex1.m1.4.4.3.cmml"><mo stretchy="false" id="S5.Ex1.m1.4.4.2.3" xref="S5.Ex1.m1.4.4.3.1.cmml">{</mo><mrow id="S5.Ex1.m1.3.3.1.1" xref="S5.Ex1.m1.3.3.1.1.cmml"><mi mathvariant="normal" id="S5.Ex1.m1.3.3.1.1.2" xref="S5.Ex1.m1.3.3.1.1.2.cmml">"</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.3.3.1.1.1" xref="S5.Ex1.m1.3.3.1.1.1.cmml">​</mo><mi id="S5.Ex1.m1.3.3.1.1.3" xref="S5.Ex1.m1.3.3.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.3.3.1.1.1a" xref="S5.Ex1.m1.3.3.1.1.1.cmml">​</mo><mi id="S5.Ex1.m1.3.3.1.1.4" xref="S5.Ex1.m1.3.3.1.1.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.3.3.1.1.1b" xref="S5.Ex1.m1.3.3.1.1.1.cmml">​</mo><mi id="S5.Ex1.m1.3.3.1.1.5" xref="S5.Ex1.m1.3.3.1.1.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.3.3.1.1.1c" xref="S5.Ex1.m1.3.3.1.1.1.cmml">​</mo><mi id="S5.Ex1.m1.3.3.1.1.6" xref="S5.Ex1.m1.3.3.1.1.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.3.3.1.1.1d" xref="S5.Ex1.m1.3.3.1.1.1.cmml">​</mo><mi id="S5.Ex1.m1.3.3.1.1.7" xref="S5.Ex1.m1.3.3.1.1.7.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.3.3.1.1.1e" xref="S5.Ex1.m1.3.3.1.1.1.cmml">​</mo><mi id="S5.Ex1.m1.3.3.1.1.8" xref="S5.Ex1.m1.3.3.1.1.8.cmml">y</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.3.3.1.1.1f" xref="S5.Ex1.m1.3.3.1.1.1.cmml">​</mo><mi mathvariant="normal" id="S5.Ex1.m1.3.3.1.1.9" xref="S5.Ex1.m1.3.3.1.1.9.cmml">"</mi></mrow><mo lspace="0.278em" rspace="0.278em" id="S5.Ex1.m1.4.4.2.4" xref="S5.Ex1.m1.4.4.3.1.cmml">:</mo><mrow id="S5.Ex1.m1.4.4.2.2" xref="S5.Ex1.m1.4.4.2.2.cmml"><mrow id="S5.Ex1.m1.4.4.2.2.2.2" xref="S5.Ex1.m1.4.4.2.2.2.3.cmml"><mrow id="S5.Ex1.m1.4.4.2.2.1.1.1" xref="S5.Ex1.m1.4.4.2.2.1.1.1.cmml"><mi id="S5.Ex1.m1.4.4.2.2.1.1.1.2" xref="S5.Ex1.m1.4.4.2.2.1.1.1.2.cmml">E</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.1.1.1.1" xref="S5.Ex1.m1.4.4.2.2.1.1.1.1.cmml">​</mo><mi id="S5.Ex1.m1.4.4.2.2.1.1.1.3" xref="S5.Ex1.m1.4.4.2.2.1.1.1.3.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.1.1.1.1a" xref="S5.Ex1.m1.4.4.2.2.1.1.1.1.cmml">​</mo><mi id="S5.Ex1.m1.4.4.2.2.1.1.1.4" xref="S5.Ex1.m1.4.4.2.2.1.1.1.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.1.1.1.1b" xref="S5.Ex1.m1.4.4.2.2.1.1.1.1.cmml">​</mo><mi id="S5.Ex1.m1.4.4.2.2.1.1.1.5" xref="S5.Ex1.m1.4.4.2.2.1.1.1.5.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.1.1.1.1c" xref="S5.Ex1.m1.4.4.2.2.1.1.1.1.cmml">​</mo><mi id="S5.Ex1.m1.4.4.2.2.1.1.1.6" xref="S5.Ex1.m1.4.4.2.2.1.1.1.6.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.1.1.1.1d" xref="S5.Ex1.m1.4.4.2.2.1.1.1.1.cmml">​</mo><mi id="S5.Ex1.m1.4.4.2.2.1.1.1.7" xref="S5.Ex1.m1.4.4.2.2.1.1.1.7.cmml">y</mi></mrow><mo id="S5.Ex1.m1.4.4.2.2.2.2.3" xref="S5.Ex1.m1.4.4.2.2.2.3.cmml">,</mo><mrow id="S5.Ex1.m1.4.4.2.2.2.2.2" xref="S5.Ex1.m1.4.4.2.2.2.2.2.cmml"><mi mathvariant="normal" id="S5.Ex1.m1.4.4.2.2.2.2.2.2" xref="S5.Ex1.m1.4.4.2.2.2.2.2.2.cmml">"</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.2.2.2.1" xref="S5.Ex1.m1.4.4.2.2.2.2.2.1.cmml">​</mo><mi id="S5.Ex1.m1.4.4.2.2.2.2.2.3" xref="S5.Ex1.m1.4.4.2.2.2.2.2.3.cmml">t</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.2.2.2.1a" xref="S5.Ex1.m1.4.4.2.2.2.2.2.1.cmml">​</mo><mi id="S5.Ex1.m1.4.4.2.2.2.2.2.4" xref="S5.Ex1.m1.4.4.2.2.2.2.2.4.cmml">y</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.2.2.2.1b" xref="S5.Ex1.m1.4.4.2.2.2.2.2.1.cmml">​</mo><mi id="S5.Ex1.m1.4.4.2.2.2.2.2.5" xref="S5.Ex1.m1.4.4.2.2.2.2.2.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.2.2.2.1c" xref="S5.Ex1.m1.4.4.2.2.2.2.2.1.cmml">​</mo><mi id="S5.Ex1.m1.4.4.2.2.2.2.2.6" xref="S5.Ex1.m1.4.4.2.2.2.2.2.6.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.2.2.2.1d" xref="S5.Ex1.m1.4.4.2.2.2.2.2.1.cmml">​</mo><mi mathvariant="normal" id="S5.Ex1.m1.4.4.2.2.2.2.2.7" xref="S5.Ex1.m1.4.4.2.2.2.2.2.7.cmml">"</mi></mrow></mrow><mo lspace="0.278em" rspace="0.278em" id="S5.Ex1.m1.4.4.2.2.6" xref="S5.Ex1.m1.4.4.2.2.6.cmml">:</mo><mrow id="S5.Ex1.m1.4.4.2.2.4.2" xref="S5.Ex1.m1.4.4.2.2.4.3.cmml"><mrow id="S5.Ex1.m1.4.4.2.2.3.1.1" xref="S5.Ex1.m1.4.4.2.2.3.1.1.cmml"><mi id="S5.Ex1.m1.4.4.2.2.3.1.1.2" xref="S5.Ex1.m1.4.4.2.2.3.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.3.1.1.1" xref="S5.Ex1.m1.4.4.2.2.3.1.1.1.cmml">​</mo><mi id="S5.Ex1.m1.4.4.2.2.3.1.1.3" xref="S5.Ex1.m1.4.4.2.2.3.1.1.3.cmml">y</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.3.1.1.1a" xref="S5.Ex1.m1.4.4.2.2.3.1.1.1.cmml">​</mo><mi id="S5.Ex1.m1.4.4.2.2.3.1.1.4" xref="S5.Ex1.m1.4.4.2.2.3.1.1.4.cmml">p</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.3.1.1.1b" xref="S5.Ex1.m1.4.4.2.2.3.1.1.1.cmml">​</mo><mi id="S5.Ex1.m1.4.4.2.2.3.1.1.5" xref="S5.Ex1.m1.4.4.2.2.3.1.1.5.cmml">e</mi></mrow><mo id="S5.Ex1.m1.4.4.2.2.4.2.3" xref="S5.Ex1.m1.4.4.2.2.4.3.cmml">,</mo><mrow id="S5.Ex1.m1.4.4.2.2.4.2.2" xref="S5.Ex1.m1.4.4.2.2.4.2.2.cmml"><mi mathvariant="normal" id="S5.Ex1.m1.4.4.2.2.4.2.2.2" xref="S5.Ex1.m1.4.4.2.2.4.2.2.2.cmml">"</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.4.2.2.1" xref="S5.Ex1.m1.4.4.2.2.4.2.2.1.cmml">​</mo><mi id="S5.Ex1.m1.4.4.2.2.4.2.2.3" xref="S5.Ex1.m1.4.4.2.2.4.2.2.3.cmml">c</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.4.2.2.1a" xref="S5.Ex1.m1.4.4.2.2.4.2.2.1.cmml">​</mo><mi id="S5.Ex1.m1.4.4.2.2.4.2.2.4" xref="S5.Ex1.m1.4.4.2.2.4.2.2.4.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.4.2.2.1b" xref="S5.Ex1.m1.4.4.2.2.4.2.2.1.cmml">​</mo><mi id="S5.Ex1.m1.4.4.2.2.4.2.2.5" xref="S5.Ex1.m1.4.4.2.2.4.2.2.5.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.4.2.2.1c" xref="S5.Ex1.m1.4.4.2.2.4.2.2.1.cmml">​</mo><mi id="S5.Ex1.m1.4.4.2.2.4.2.2.6" xref="S5.Ex1.m1.4.4.2.2.4.2.2.6.cmml">l</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.4.2.2.1d" xref="S5.Ex1.m1.4.4.2.2.4.2.2.1.cmml">​</mo><mi mathvariant="normal" id="S5.Ex1.m1.4.4.2.2.4.2.2.7" xref="S5.Ex1.m1.4.4.2.2.4.2.2.7.cmml">_</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.4.2.2.1e" xref="S5.Ex1.m1.4.4.2.2.4.2.2.1.cmml">​</mo><mi id="S5.Ex1.m1.4.4.2.2.4.2.2.8" xref="S5.Ex1.m1.4.4.2.2.4.2.2.8.cmml">i</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.4.2.2.1f" xref="S5.Ex1.m1.4.4.2.2.4.2.2.1.cmml">​</mo><mi id="S5.Ex1.m1.4.4.2.2.4.2.2.9" xref="S5.Ex1.m1.4.4.2.2.4.2.2.9.cmml">n</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.4.2.2.1g" xref="S5.Ex1.m1.4.4.2.2.4.2.2.1.cmml">​</mo><mi id="S5.Ex1.m1.4.4.2.2.4.2.2.10" xref="S5.Ex1.m1.4.4.2.2.4.2.2.10.cmml">d</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.4.2.2.1h" xref="S5.Ex1.m1.4.4.2.2.4.2.2.1.cmml">​</mo><mi id="S5.Ex1.m1.4.4.2.2.4.2.2.11" xref="S5.Ex1.m1.4.4.2.2.4.2.2.11.cmml">e</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.4.2.2.1i" xref="S5.Ex1.m1.4.4.2.2.4.2.2.1.cmml">​</mo><mi id="S5.Ex1.m1.4.4.2.2.4.2.2.12" xref="S5.Ex1.m1.4.4.2.2.4.2.2.12.cmml">x</mi><mo lspace="0em" rspace="0em" id="S5.Ex1.m1.4.4.2.2.4.2.2.1j" xref="S5.Ex1.m1.4.4.2.2.4.2.2.1.cmml">​</mo><mi mathvariant="normal" id="S5.Ex1.m1.4.4.2.2.4.2.2.13" xref="S5.Ex1.m1.4.4.2.2.4.2.2.13.cmml">"</mi></mrow></mrow><mo lspace="0.278em" rspace="0.278em" id="S5.Ex1.m1.4.4.2.2.7" xref="S5.Ex1.m1.4.4.2.2.7.cmml">:</mo><mrow id="S5.Ex1.m1.4.4.2.2.8.2" xref="S5.Ex1.m1.4.4.2.2.8.1.cmml"><mo stretchy="false" id="S5.Ex1.m1.4.4.2.2.8.2.1" xref="S5.Ex1.m1.4.4.2.2.8.1.cmml">[</mo><mi id="S5.Ex1.m1.1.1" xref="S5.Ex1.m1.1.1.cmml">x</mi><mo id="S5.Ex1.m1.4.4.2.2.8.2.2" xref="S5.Ex1.m1.4.4.2.2.8.1.cmml">,</mo><mi id="S5.Ex1.m1.2.2" xref="S5.Ex1.m1.2.2.cmml">y</mi><mo stretchy="false" id="S5.Ex1.m1.4.4.2.2.8.2.3" xref="S5.Ex1.m1.4.4.2.2.8.1.cmml">]</mo></mrow></mrow><mo stretchy="false" id="S5.Ex1.m1.4.4.2.5" xref="S5.Ex1.m1.4.4.3.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.Ex1.m1.4b"><apply id="S5.Ex1.m1.4.4.3.cmml" xref="S5.Ex1.m1.4.4.2"><csymbol cd="latexml" id="S5.Ex1.m1.4.4.3.1.cmml" xref="S5.Ex1.m1.4.4.2.3">conditional-set</csymbol><apply id="S5.Ex1.m1.3.3.1.1.cmml" xref="S5.Ex1.m1.3.3.1.1"><times id="S5.Ex1.m1.3.3.1.1.1.cmml" xref="S5.Ex1.m1.3.3.1.1.1"></times><ci id="S5.Ex1.m1.3.3.1.1.2.cmml" xref="S5.Ex1.m1.3.3.1.1.2">"</ci><ci id="S5.Ex1.m1.3.3.1.1.3.cmml" xref="S5.Ex1.m1.3.3.1.1.3">𝑒</ci><ci id="S5.Ex1.m1.3.3.1.1.4.cmml" xref="S5.Ex1.m1.3.3.1.1.4">𝑛</ci><ci id="S5.Ex1.m1.3.3.1.1.5.cmml" xref="S5.Ex1.m1.3.3.1.1.5">𝑡</ci><ci id="S5.Ex1.m1.3.3.1.1.6.cmml" xref="S5.Ex1.m1.3.3.1.1.6">𝑖</ci><ci id="S5.Ex1.m1.3.3.1.1.7.cmml" xref="S5.Ex1.m1.3.3.1.1.7">𝑡</ci><ci id="S5.Ex1.m1.3.3.1.1.8.cmml" xref="S5.Ex1.m1.3.3.1.1.8">𝑦</ci><ci id="S5.Ex1.m1.3.3.1.1.9.cmml" xref="S5.Ex1.m1.3.3.1.1.9">"</ci></apply><apply id="S5.Ex1.m1.4.4.2.2.cmml" xref="S5.Ex1.m1.4.4.2.2"><and id="S5.Ex1.m1.4.4.2.2a.cmml" xref="S5.Ex1.m1.4.4.2.2"></and><apply id="S5.Ex1.m1.4.4.2.2b.cmml" xref="S5.Ex1.m1.4.4.2.2"><ci id="S5.Ex1.m1.4.4.2.2.6.cmml" xref="S5.Ex1.m1.4.4.2.2.6">:</ci><list id="S5.Ex1.m1.4.4.2.2.2.3.cmml" xref="S5.Ex1.m1.4.4.2.2.2.2"><apply id="S5.Ex1.m1.4.4.2.2.1.1.1.cmml" xref="S5.Ex1.m1.4.4.2.2.1.1.1"><times id="S5.Ex1.m1.4.4.2.2.1.1.1.1.cmml" xref="S5.Ex1.m1.4.4.2.2.1.1.1.1"></times><ci id="S5.Ex1.m1.4.4.2.2.1.1.1.2.cmml" xref="S5.Ex1.m1.4.4.2.2.1.1.1.2">𝐸</ci><ci id="S5.Ex1.m1.4.4.2.2.1.1.1.3.cmml" xref="S5.Ex1.m1.4.4.2.2.1.1.1.3">𝑛</ci><ci id="S5.Ex1.m1.4.4.2.2.1.1.1.4.cmml" xref="S5.Ex1.m1.4.4.2.2.1.1.1.4">𝑡</ci><ci id="S5.Ex1.m1.4.4.2.2.1.1.1.5.cmml" xref="S5.Ex1.m1.4.4.2.2.1.1.1.5">𝑖</ci><ci id="S5.Ex1.m1.4.4.2.2.1.1.1.6.cmml" xref="S5.Ex1.m1.4.4.2.2.1.1.1.6">𝑡</ci><ci id="S5.Ex1.m1.4.4.2.2.1.1.1.7.cmml" xref="S5.Ex1.m1.4.4.2.2.1.1.1.7">𝑦</ci></apply><apply id="S5.Ex1.m1.4.4.2.2.2.2.2.cmml" xref="S5.Ex1.m1.4.4.2.2.2.2.2"><times id="S5.Ex1.m1.4.4.2.2.2.2.2.1.cmml" xref="S5.Ex1.m1.4.4.2.2.2.2.2.1"></times><ci id="S5.Ex1.m1.4.4.2.2.2.2.2.2.cmml" xref="S5.Ex1.m1.4.4.2.2.2.2.2.2">"</ci><ci id="S5.Ex1.m1.4.4.2.2.2.2.2.3.cmml" xref="S5.Ex1.m1.4.4.2.2.2.2.2.3">𝑡</ci><ci id="S5.Ex1.m1.4.4.2.2.2.2.2.4.cmml" xref="S5.Ex1.m1.4.4.2.2.2.2.2.4">𝑦</ci><ci id="S5.Ex1.m1.4.4.2.2.2.2.2.5.cmml" xref="S5.Ex1.m1.4.4.2.2.2.2.2.5">𝑝</ci><ci id="S5.Ex1.m1.4.4.2.2.2.2.2.6.cmml" xref="S5.Ex1.m1.4.4.2.2.2.2.2.6">𝑒</ci><ci id="S5.Ex1.m1.4.4.2.2.2.2.2.7.cmml" xref="S5.Ex1.m1.4.4.2.2.2.2.2.7">"</ci></apply></list><list id="S5.Ex1.m1.4.4.2.2.4.3.cmml" xref="S5.Ex1.m1.4.4.2.2.4.2"><apply id="S5.Ex1.m1.4.4.2.2.3.1.1.cmml" xref="S5.Ex1.m1.4.4.2.2.3.1.1"><times id="S5.Ex1.m1.4.4.2.2.3.1.1.1.cmml" xref="S5.Ex1.m1.4.4.2.2.3.1.1.1"></times><ci id="S5.Ex1.m1.4.4.2.2.3.1.1.2.cmml" xref="S5.Ex1.m1.4.4.2.2.3.1.1.2">𝑇</ci><ci id="S5.Ex1.m1.4.4.2.2.3.1.1.3.cmml" xref="S5.Ex1.m1.4.4.2.2.3.1.1.3">𝑦</ci><ci id="S5.Ex1.m1.4.4.2.2.3.1.1.4.cmml" xref="S5.Ex1.m1.4.4.2.2.3.1.1.4">𝑝</ci><ci id="S5.Ex1.m1.4.4.2.2.3.1.1.5.cmml" xref="S5.Ex1.m1.4.4.2.2.3.1.1.5">𝑒</ci></apply><apply id="S5.Ex1.m1.4.4.2.2.4.2.2.cmml" xref="S5.Ex1.m1.4.4.2.2.4.2.2"><times id="S5.Ex1.m1.4.4.2.2.4.2.2.1.cmml" xref="S5.Ex1.m1.4.4.2.2.4.2.2.1"></times><ci id="S5.Ex1.m1.4.4.2.2.4.2.2.2.cmml" xref="S5.Ex1.m1.4.4.2.2.4.2.2.2">"</ci><ci id="S5.Ex1.m1.4.4.2.2.4.2.2.3.cmml" xref="S5.Ex1.m1.4.4.2.2.4.2.2.3">𝑐</ci><ci id="S5.Ex1.m1.4.4.2.2.4.2.2.4.cmml" xref="S5.Ex1.m1.4.4.2.2.4.2.2.4">𝑒</ci><ci id="S5.Ex1.m1.4.4.2.2.4.2.2.5.cmml" xref="S5.Ex1.m1.4.4.2.2.4.2.2.5">𝑙</ci><ci id="S5.Ex1.m1.4.4.2.2.4.2.2.6.cmml" xref="S5.Ex1.m1.4.4.2.2.4.2.2.6">𝑙</ci><ci id="S5.Ex1.m1.4.4.2.2.4.2.2.7.cmml" xref="S5.Ex1.m1.4.4.2.2.4.2.2.7">_</ci><ci id="S5.Ex1.m1.4.4.2.2.4.2.2.8.cmml" xref="S5.Ex1.m1.4.4.2.2.4.2.2.8">𝑖</ci><ci id="S5.Ex1.m1.4.4.2.2.4.2.2.9.cmml" xref="S5.Ex1.m1.4.4.2.2.4.2.2.9">𝑛</ci><ci id="S5.Ex1.m1.4.4.2.2.4.2.2.10.cmml" xref="S5.Ex1.m1.4.4.2.2.4.2.2.10">𝑑</ci><ci id="S5.Ex1.m1.4.4.2.2.4.2.2.11.cmml" xref="S5.Ex1.m1.4.4.2.2.4.2.2.11">𝑒</ci><ci id="S5.Ex1.m1.4.4.2.2.4.2.2.12.cmml" xref="S5.Ex1.m1.4.4.2.2.4.2.2.12">𝑥</ci><ci id="S5.Ex1.m1.4.4.2.2.4.2.2.13.cmml" xref="S5.Ex1.m1.4.4.2.2.4.2.2.13">"</ci></apply></list></apply><apply id="S5.Ex1.m1.4.4.2.2c.cmml" xref="S5.Ex1.m1.4.4.2.2"><ci id="S5.Ex1.m1.4.4.2.2.7.cmml" xref="S5.Ex1.m1.4.4.2.2.7">:</ci><share href="#S5.Ex1.m1.4.4.2.2.4.cmml" id="S5.Ex1.m1.4.4.2.2d.cmml" xref="S5.Ex1.m1.4.4.2.2"></share><interval closure="closed" id="S5.Ex1.m1.4.4.2.2.8.1.cmml" xref="S5.Ex1.m1.4.4.2.2.8.2"><ci id="S5.Ex1.m1.1.1.cmml" xref="S5.Ex1.m1.1.1">𝑥</ci><ci id="S5.Ex1.m1.2.2.cmml" xref="S5.Ex1.m1.2.2">𝑦</ci></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.Ex1.m1.4c">\{"entity":Entity,"type":Type,"cell\_index":[x,y]\}</annotation></semantics></math></span>
<span class="ltx_eqn_cell ltx_eqn_center_padright"></span></span></span>
</span>
<span id="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4" class="ltx_p">Cell index should be one list <math id="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.2" class="ltx_Math" alttext="[x,y]" display="inline"><semantics id="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.2a"><mrow id="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.2.3.2" xref="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.2.3.1.cmml"><mo stretchy="false" id="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.2.3.2.1" xref="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.2.3.1.cmml">[</mo><mi id="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1" xref="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml">x</mi><mo id="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.2.3.2.2" xref="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.2.3.1.cmml">,</mo><mi id="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.2.2" xref="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.2.2.cmml">y</mi><mo stretchy="false" id="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.2.3.2.3" xref="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.2b"><interval closure="closed" id="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.2.3.1.cmml" xref="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.2.3.2"><ci id="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.1.1">𝑥</ci><ci id="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.2.2.cmml" xref="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.2.2">𝑦</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.pic1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.m1.2c">[x,y]</annotation></semantics></math> where <math id="S5.F7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S5.F7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1a"><mi id="S5.F7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1" xref="S5.F7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S5.F7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1b"><ci id="S5.F7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1.cmml" xref="S5.F7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.pic1.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.2.m2.1c">x</annotation></semantics></math> is the row number and <math id="S5.F7.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S5.F7.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1a"><mi id="S5.F7.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1" xref="S5.F7.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S5.F7.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1b"><ci id="S5.F7.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1.cmml" xref="S5.F7.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.pic1.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.3.m3.1c">y</annotation></semantics></math> is the column number.
The table header has index -1, the table content with entities start from index <math id="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.2" class="ltx_Math" alttext="[0,0]" display="inline"><semantics id="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.2a"><mrow id="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.2.3.2" xref="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.2.3.1.cmml"><mo stretchy="false" id="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.2.3.2.1" xref="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.2.3.1.cmml">[</mo><mn id="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1.1" xref="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1.1.cmml">0</mn><mo id="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.2.3.2.2" xref="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.2.3.1.cmml">,</mo><mn id="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.2.2" xref="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.2.2.cmml">0</mn><mo stretchy="false" id="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.2.3.2.3" xref="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.2b"><interval closure="closed" id="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.2.3.1.cmml" xref="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.2.3.2"><cn type="integer" id="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1.1.cmml" xref="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.1.1">0</cn><cn type="integer" id="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.2.2.cmml" xref="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.2.2">0</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.pic1.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.4.m4.2c">[0,0]</annotation></semantics></math>.</span>
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5" class="ltx_block ltx_minipage ltx_align_top" style="width:433.6pt;">
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.2" class="ltx_p"><span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.2.1" class="ltx_text ltx_font_italic">Example:</span></span>
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.3" class="ltx_block ltx_minipage ltx_align_top" style="width:216.8pt;">
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.3.1" class="ltx_p"><span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.3.1.1" class="ltx_text ltx_font_bold">Table:</span></span>
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.3.2" class="ltx_p">— Rider — Team — Time</span>
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.3.3" class="ltx_p">1 — Giorgia Bronzini ( ITA ) — Wiggle-Honda —</span>
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.3.4" class="ltx_p">2 — Emma Johansson ( SWE ) — Orica-AIS — s.t.</span>
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.3.5" class="ltx_p">3 — Pauline Ferrand-Prevot ( FRA ) — Rabobank-Liv/giant — s.t.</span>
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.3.6" class="ltx_p">4 — Pascale Jeuland ( FRA ) — Vienne Futuroscope — s.t.</span>
</span>
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1" class="ltx_block ltx_minipage ltx_align_top" style="width:238.5pt;">
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.2" class="ltx_p"><span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.2.1" class="ltx_text ltx_font_bold">Output:</span></span>
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1" class="ltx_p"><math id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8" class="ltx_Math" alttext='[\{\text{"entity": "Giorgia Bronzini", "type": "Person", "cell\_index": [0, 1]}\},\\
\{\text{"entity": "ITA", "type": "Place", "cell\_index": [0, 1]}\},\\
\{\text{"entity": "Emma Johansson", "type": "Person", "cell\_index": [1, 1]}\},\\
\{\text{"entity": "SWE", "type": "Place", "cell\_index": [1, 1]}\}]' display="inline"><semantics id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8a"><mrow id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.4" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.5.cmml"><mo stretchy="false" id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.4.5" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.5.cmml">[</mo><mrow id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.5.5.1.1.2" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.5.5.1.1.1.cmml"><mo stretchy="false" id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.5.5.1.1.2.1" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.5.5.1.1.1.cmml">{</mo><mtext id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.1.1" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.1.1a.cmml">”entity”: ”Giorgia Bronzini”, ”type”: ”Person”, ”cell_index”: [0, 1]</mtext><mo stretchy="false" id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.5.5.1.1.2.2" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.5.5.1.1.1.cmml">}</mo></mrow><mo id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.4.6" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.5.cmml">,</mo><mrow id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.6.6.2.2.2" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.6.6.2.2.1.cmml"><mo stretchy="false" id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.6.6.2.2.2.1" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.6.6.2.2.1.cmml">{</mo><mtext id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.2.2" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.2.2a.cmml">”entity”: ”ITA”, ”type”: ”Place”, ”cell_index”: [0, 1]</mtext><mo stretchy="false" id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.6.6.2.2.2.2" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.6.6.2.2.1.cmml">}</mo></mrow><mo id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.4.7" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.5.cmml">,</mo><mrow id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.7.7.3.3.2" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.7.7.3.3.1.cmml"><mo stretchy="false" id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.7.7.3.3.2.1" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.7.7.3.3.1.cmml">{</mo><mtext id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.3.3" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.3.3a.cmml">”entity”: ”Emma Johansson”, ”type”: ”Person”, ”cell_index”: [1, 1]</mtext><mo stretchy="false" id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.7.7.3.3.2.2" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.7.7.3.3.1.cmml">}</mo></mrow><mo id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.4.8" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.5.cmml">,</mo><mrow id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.4.4.2" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.4.4.1.cmml"><mo stretchy="false" id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.4.4.2.1" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.4.4.1.cmml">{</mo><mtext id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.4.4" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.4.4a.cmml">”entity”: ”SWE”, ”type”: ”Place”, ”cell_index”: [1, 1]</mtext><mo stretchy="false" id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.4.4.2.2" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.4.4.1.cmml">}</mo></mrow><mo stretchy="false" id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.4.9" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.5.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8b"><list id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.5.cmml" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.4"><set id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.5.5.1.1.1.cmml" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.5.5.1.1.2"><ci id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.1.1a.cmml" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.1.1"><mtext id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.1.1.cmml" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.1.1">”entity”: ”Giorgia Bronzini”, ”type”: ”Person”, ”cell_index”: [0, 1]</mtext></ci></set><set id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.6.6.2.2.1.cmml" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.6.6.2.2.2"><ci id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.2.2a.cmml" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.2.2"><mtext id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.2.2.cmml" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.2.2">”entity”: ”ITA”, ”type”: ”Place”, ”cell_index”: [0, 1]</mtext></ci></set><set id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.7.7.3.3.1.cmml" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.7.7.3.3.2"><ci id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.3.3a.cmml" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.3.3"><mtext id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.3.3.cmml" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.3.3">”entity”: ”Emma Johansson”, ”type”: ”Person”, ”cell_index”: [1, 1]</mtext></ci></set><set id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.4.4.1.cmml" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8.8.4.4.2"><ci id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.4.4a.cmml" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.4.4"><mtext id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.4.4.cmml" xref="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.4.4">”entity”: ”SWE”, ”type”: ”Place”, ”cell_index”: [1, 1]</mtext></ci></set></list></annotation-xml><annotation encoding="application/x-tex" id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.1.1.m1.8c">[\{\text{"entity": "Giorgia Bronzini", "type": "Person", "cell\_index": [0, 1]}\},\\
\{\text{"entity": "ITA", "type": "Place", "cell\_index": [0, 1]}\},\\
\{\text{"entity": "Emma Johansson", "type": "Person", "cell\_index": [1, 1]}\},\\
\{\text{"entity": "SWE", "type": "Place", "cell\_index": [1, 1]}\}]</annotation></semantics></math></span>
</span>
</span>
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.8" class="ltx_p"><span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.8.1" class="ltx_text ltx_font_italic">Input Table:</span></span>
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.9" class="ltx_p"><span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.9.1" class="ltx_text ltx_font_bold">Table:</span></span>
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.10" class="ltx_p">— Rider — Team — Time</span>
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.11" class="ltx_p">1 — Giorgia Bronzini ( ITA ) — Wiggle-Honda — 1h 57’ 41”</span>
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.12" class="ltx_p">2 — Joelle Numainville ( CAN ) — Team Optum p/b Kelly Benefit Strategies — s.t.</span>
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.13" class="ltx_p">3 — Rosella Ratto ( ITA ) — Hitec Products UCK — s.t.</span>
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.14" class="ltx_p">4 — Ashleigh Moolman ( RSA ) — Lotto Belisol Ladies — s.t.</span>
<span id="S5.F7.pic1.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.5.15" class="ltx_p">5 — Karol-ann Canuel ( CAN ) — Vienne Futuroscope — s.t.</span>
</span></foreignObject></g></g></svg>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>. </span><span id="S5.F7.3.2" class="ltx_text" style="font-size:90%;">Example of a prompt with one-shot example. The instructions part is in red. One example table and subcell NER is in blue. The input table for annotation is in violet</span></figcaption>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span>Completion of the prompt</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">The generated input prompt is forwarded to an LLM using the completion API.
In the second step, the LLM generates the completion to the input prompt by assigning entity types to the recognized entities in the table and structuring the output. The model should be able to follow the instruction part of the input prompt and generate the output in the specified format. In case the model’s output does not adhere to the specified format, we save the output to a log file for subsequent analysis.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3. </span>Extracting span-based predictions</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.5" class="ltx_p">The generated output of the model is assumed to be of the same format as the <span id="S5.SS3.p1.5.1" class="ltx_text ltx_font_italic">Output</span> from the example part in the prompt. In order to evaluate it, we process the output as follows: first, we serialize the generated output into JSON format, where every annotated entity is a separate JSON entry. Then, for every entity, we extract the entity text, the entity type and its cell position. To find the correct span of the entity in the table, we search in the input table, at the cell position if there is an exact match with the entity text. If yes, we extract the start and end of the entity text within the cell. As a final step, we map the predicted entity type to its corresponding numerical value and we represent the predicted annotation with a tuple consisting of <math id="S5.SS3.p1.1.m1.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S5.SS3.p1.1.m1.1a"><mn id="S5.SS3.p1.1.m1.1.1" xref="S5.SS3.p1.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.1.m1.1b"><cn type="integer" id="S5.SS3.p1.1.m1.1.1.cmml" xref="S5.SS3.p1.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.1.m1.1c">5</annotation></semantics></math> elements. A tuple <math id="S5.SS3.p1.2.m2.5" class="ltx_Math" alttext="(x,y,i,j,k)" display="inline"><semantics id="S5.SS3.p1.2.m2.5a"><mrow id="S5.SS3.p1.2.m2.5.6.2" xref="S5.SS3.p1.2.m2.5.6.1.cmml"><mo stretchy="false" id="S5.SS3.p1.2.m2.5.6.2.1" xref="S5.SS3.p1.2.m2.5.6.1.cmml">(</mo><mi id="S5.SS3.p1.2.m2.1.1" xref="S5.SS3.p1.2.m2.1.1.cmml">x</mi><mo id="S5.SS3.p1.2.m2.5.6.2.2" xref="S5.SS3.p1.2.m2.5.6.1.cmml">,</mo><mi id="S5.SS3.p1.2.m2.2.2" xref="S5.SS3.p1.2.m2.2.2.cmml">y</mi><mo id="S5.SS3.p1.2.m2.5.6.2.3" xref="S5.SS3.p1.2.m2.5.6.1.cmml">,</mo><mi id="S5.SS3.p1.2.m2.3.3" xref="S5.SS3.p1.2.m2.3.3.cmml">i</mi><mo id="S5.SS3.p1.2.m2.5.6.2.4" xref="S5.SS3.p1.2.m2.5.6.1.cmml">,</mo><mi id="S5.SS3.p1.2.m2.4.4" xref="S5.SS3.p1.2.m2.4.4.cmml">j</mi><mo id="S5.SS3.p1.2.m2.5.6.2.5" xref="S5.SS3.p1.2.m2.5.6.1.cmml">,</mo><mi id="S5.SS3.p1.2.m2.5.5" xref="S5.SS3.p1.2.m2.5.5.cmml">k</mi><mo stretchy="false" id="S5.SS3.p1.2.m2.5.6.2.6" xref="S5.SS3.p1.2.m2.5.6.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.2.m2.5b"><vector id="S5.SS3.p1.2.m2.5.6.1.cmml" xref="S5.SS3.p1.2.m2.5.6.2"><ci id="S5.SS3.p1.2.m2.1.1.cmml" xref="S5.SS3.p1.2.m2.1.1">𝑥</ci><ci id="S5.SS3.p1.2.m2.2.2.cmml" xref="S5.SS3.p1.2.m2.2.2">𝑦</ci><ci id="S5.SS3.p1.2.m2.3.3.cmml" xref="S5.SS3.p1.2.m2.3.3">𝑖</ci><ci id="S5.SS3.p1.2.m2.4.4.cmml" xref="S5.SS3.p1.2.m2.4.4">𝑗</ci><ci id="S5.SS3.p1.2.m2.5.5.cmml" xref="S5.SS3.p1.2.m2.5.5">𝑘</ci></vector></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.2.m2.5c">(x,y,i,j,k)</annotation></semantics></math> represents the cell position of the entity, the span and the entity type type. Namely, <math id="S5.SS3.p1.3.m3.2" class="ltx_Math" alttext="x,y" display="inline"><semantics id="S5.SS3.p1.3.m3.2a"><mrow id="S5.SS3.p1.3.m3.2.3.2" xref="S5.SS3.p1.3.m3.2.3.1.cmml"><mi id="S5.SS3.p1.3.m3.1.1" xref="S5.SS3.p1.3.m3.1.1.cmml">x</mi><mo id="S5.SS3.p1.3.m3.2.3.2.1" xref="S5.SS3.p1.3.m3.2.3.1.cmml">,</mo><mi id="S5.SS3.p1.3.m3.2.2" xref="S5.SS3.p1.3.m3.2.2.cmml">y</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.3.m3.2b"><list id="S5.SS3.p1.3.m3.2.3.1.cmml" xref="S5.SS3.p1.3.m3.2.3.2"><ci id="S5.SS3.p1.3.m3.1.1.cmml" xref="S5.SS3.p1.3.m3.1.1">𝑥</ci><ci id="S5.SS3.p1.3.m3.2.2.cmml" xref="S5.SS3.p1.3.m3.2.2">𝑦</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.3.m3.2c">x,y</annotation></semantics></math> represent the cell index, <math id="S5.SS3.p1.4.m4.2" class="ltx_Math" alttext="i,j" display="inline"><semantics id="S5.SS3.p1.4.m4.2a"><mrow id="S5.SS3.p1.4.m4.2.3.2" xref="S5.SS3.p1.4.m4.2.3.1.cmml"><mi id="S5.SS3.p1.4.m4.1.1" xref="S5.SS3.p1.4.m4.1.1.cmml">i</mi><mo id="S5.SS3.p1.4.m4.2.3.2.1" xref="S5.SS3.p1.4.m4.2.3.1.cmml">,</mo><mi id="S5.SS3.p1.4.m4.2.2" xref="S5.SS3.p1.4.m4.2.2.cmml">j</mi></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.4.m4.2b"><list id="S5.SS3.p1.4.m4.2.3.1.cmml" xref="S5.SS3.p1.4.m4.2.3.2"><ci id="S5.SS3.p1.4.m4.1.1.cmml" xref="S5.SS3.p1.4.m4.1.1">𝑖</ci><ci id="S5.SS3.p1.4.m4.2.2.cmml" xref="S5.SS3.p1.4.m4.2.2">𝑗</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.4.m4.2c">i,j</annotation></semantics></math> are the span position of the entity in the cell and <math id="S5.SS3.p1.5.m5.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S5.SS3.p1.5.m5.1a"><mi id="S5.SS3.p1.5.m5.1.1" xref="S5.SS3.p1.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S5.SS3.p1.5.m5.1b"><ci id="S5.SS3.p1.5.m5.1.1.cmml" xref="S5.SS3.p1.5.m5.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p1.5.m5.1c">k</annotation></semantics></math> is the type of the entity.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.10" class="ltx_p">For example, the parsed output for the first <math id="S5.SS3.p2.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S5.SS3.p2.1.m1.1a"><mn id="S5.SS3.p2.1.m1.1.1" xref="S5.SS3.p2.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.1.m1.1b"><cn type="integer" id="S5.SS3.p2.1.m1.1.1.cmml" xref="S5.SS3.p2.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.1.m1.1c">2</annotation></semantics></math> rows from the example table in Figure <a href="#S5.F7" title="Figure 7 ‣ 5.1. Input Prompt ‣ 5. Table NER with LLMs ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> are : 
<br class="ltx_break"><math id="S5.SS3.p2.2.m2.18" class="ltx_Math" alttext="[(0,1,0,16,6),(0,1,19,22,5),(1,1,21,24,5)]" display="inline"><semantics id="S5.SS3.p2.2.m2.18a"><mrow id="S5.SS3.p2.2.m2.18.18.3" xref="S5.SS3.p2.2.m2.18.18.4.cmml"><mo stretchy="false" id="S5.SS3.p2.2.m2.18.18.3.4" xref="S5.SS3.p2.2.m2.18.18.4.cmml">[</mo><mrow id="S5.SS3.p2.2.m2.16.16.1.1.2" xref="S5.SS3.p2.2.m2.16.16.1.1.1.cmml"><mo stretchy="false" id="S5.SS3.p2.2.m2.16.16.1.1.2.1" xref="S5.SS3.p2.2.m2.16.16.1.1.1.cmml">(</mo><mn id="S5.SS3.p2.2.m2.1.1" xref="S5.SS3.p2.2.m2.1.1.cmml">0</mn><mo id="S5.SS3.p2.2.m2.16.16.1.1.2.2" xref="S5.SS3.p2.2.m2.16.16.1.1.1.cmml">,</mo><mn id="S5.SS3.p2.2.m2.2.2" xref="S5.SS3.p2.2.m2.2.2.cmml">1</mn><mo id="S5.SS3.p2.2.m2.16.16.1.1.2.3" xref="S5.SS3.p2.2.m2.16.16.1.1.1.cmml">,</mo><mn id="S5.SS3.p2.2.m2.3.3" xref="S5.SS3.p2.2.m2.3.3.cmml">0</mn><mo id="S5.SS3.p2.2.m2.16.16.1.1.2.4" xref="S5.SS3.p2.2.m2.16.16.1.1.1.cmml">,</mo><mn id="S5.SS3.p2.2.m2.4.4" xref="S5.SS3.p2.2.m2.4.4.cmml">16</mn><mo id="S5.SS3.p2.2.m2.16.16.1.1.2.5" xref="S5.SS3.p2.2.m2.16.16.1.1.1.cmml">,</mo><mn id="S5.SS3.p2.2.m2.5.5" xref="S5.SS3.p2.2.m2.5.5.cmml">6</mn><mo stretchy="false" id="S5.SS3.p2.2.m2.16.16.1.1.2.6" xref="S5.SS3.p2.2.m2.16.16.1.1.1.cmml">)</mo></mrow><mo id="S5.SS3.p2.2.m2.18.18.3.5" xref="S5.SS3.p2.2.m2.18.18.4.cmml">,</mo><mrow id="S5.SS3.p2.2.m2.17.17.2.2.2" xref="S5.SS3.p2.2.m2.17.17.2.2.1.cmml"><mo stretchy="false" id="S5.SS3.p2.2.m2.17.17.2.2.2.1" xref="S5.SS3.p2.2.m2.17.17.2.2.1.cmml">(</mo><mn id="S5.SS3.p2.2.m2.6.6" xref="S5.SS3.p2.2.m2.6.6.cmml">0</mn><mo id="S5.SS3.p2.2.m2.17.17.2.2.2.2" xref="S5.SS3.p2.2.m2.17.17.2.2.1.cmml">,</mo><mn id="S5.SS3.p2.2.m2.7.7" xref="S5.SS3.p2.2.m2.7.7.cmml">1</mn><mo id="S5.SS3.p2.2.m2.17.17.2.2.2.3" xref="S5.SS3.p2.2.m2.17.17.2.2.1.cmml">,</mo><mn id="S5.SS3.p2.2.m2.8.8" xref="S5.SS3.p2.2.m2.8.8.cmml">19</mn><mo id="S5.SS3.p2.2.m2.17.17.2.2.2.4" xref="S5.SS3.p2.2.m2.17.17.2.2.1.cmml">,</mo><mn id="S5.SS3.p2.2.m2.9.9" xref="S5.SS3.p2.2.m2.9.9.cmml">22</mn><mo id="S5.SS3.p2.2.m2.17.17.2.2.2.5" xref="S5.SS3.p2.2.m2.17.17.2.2.1.cmml">,</mo><mn id="S5.SS3.p2.2.m2.10.10" xref="S5.SS3.p2.2.m2.10.10.cmml">5</mn><mo stretchy="false" id="S5.SS3.p2.2.m2.17.17.2.2.2.6" xref="S5.SS3.p2.2.m2.17.17.2.2.1.cmml">)</mo></mrow><mo id="S5.SS3.p2.2.m2.18.18.3.6" xref="S5.SS3.p2.2.m2.18.18.4.cmml">,</mo><mrow id="S5.SS3.p2.2.m2.18.18.3.3.2" xref="S5.SS3.p2.2.m2.18.18.3.3.1.cmml"><mo stretchy="false" id="S5.SS3.p2.2.m2.18.18.3.3.2.1" xref="S5.SS3.p2.2.m2.18.18.3.3.1.cmml">(</mo><mn id="S5.SS3.p2.2.m2.11.11" xref="S5.SS3.p2.2.m2.11.11.cmml">1</mn><mo id="S5.SS3.p2.2.m2.18.18.3.3.2.2" xref="S5.SS3.p2.2.m2.18.18.3.3.1.cmml">,</mo><mn id="S5.SS3.p2.2.m2.12.12" xref="S5.SS3.p2.2.m2.12.12.cmml">1</mn><mo id="S5.SS3.p2.2.m2.18.18.3.3.2.3" xref="S5.SS3.p2.2.m2.18.18.3.3.1.cmml">,</mo><mn id="S5.SS3.p2.2.m2.13.13" xref="S5.SS3.p2.2.m2.13.13.cmml">21</mn><mo id="S5.SS3.p2.2.m2.18.18.3.3.2.4" xref="S5.SS3.p2.2.m2.18.18.3.3.1.cmml">,</mo><mn id="S5.SS3.p2.2.m2.14.14" xref="S5.SS3.p2.2.m2.14.14.cmml">24</mn><mo id="S5.SS3.p2.2.m2.18.18.3.3.2.5" xref="S5.SS3.p2.2.m2.18.18.3.3.1.cmml">,</mo><mn id="S5.SS3.p2.2.m2.15.15" xref="S5.SS3.p2.2.m2.15.15.cmml">5</mn><mo stretchy="false" id="S5.SS3.p2.2.m2.18.18.3.3.2.6" xref="S5.SS3.p2.2.m2.18.18.3.3.1.cmml">)</mo></mrow><mo stretchy="false" id="S5.SS3.p2.2.m2.18.18.3.7" xref="S5.SS3.p2.2.m2.18.18.4.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.2.m2.18b"><list id="S5.SS3.p2.2.m2.18.18.4.cmml" xref="S5.SS3.p2.2.m2.18.18.3"><vector id="S5.SS3.p2.2.m2.16.16.1.1.1.cmml" xref="S5.SS3.p2.2.m2.16.16.1.1.2"><cn type="integer" id="S5.SS3.p2.2.m2.1.1.cmml" xref="S5.SS3.p2.2.m2.1.1">0</cn><cn type="integer" id="S5.SS3.p2.2.m2.2.2.cmml" xref="S5.SS3.p2.2.m2.2.2">1</cn><cn type="integer" id="S5.SS3.p2.2.m2.3.3.cmml" xref="S5.SS3.p2.2.m2.3.3">0</cn><cn type="integer" id="S5.SS3.p2.2.m2.4.4.cmml" xref="S5.SS3.p2.2.m2.4.4">16</cn><cn type="integer" id="S5.SS3.p2.2.m2.5.5.cmml" xref="S5.SS3.p2.2.m2.5.5">6</cn></vector><vector id="S5.SS3.p2.2.m2.17.17.2.2.1.cmml" xref="S5.SS3.p2.2.m2.17.17.2.2.2"><cn type="integer" id="S5.SS3.p2.2.m2.6.6.cmml" xref="S5.SS3.p2.2.m2.6.6">0</cn><cn type="integer" id="S5.SS3.p2.2.m2.7.7.cmml" xref="S5.SS3.p2.2.m2.7.7">1</cn><cn type="integer" id="S5.SS3.p2.2.m2.8.8.cmml" xref="S5.SS3.p2.2.m2.8.8">19</cn><cn type="integer" id="S5.SS3.p2.2.m2.9.9.cmml" xref="S5.SS3.p2.2.m2.9.9">22</cn><cn type="integer" id="S5.SS3.p2.2.m2.10.10.cmml" xref="S5.SS3.p2.2.m2.10.10">5</cn></vector><vector id="S5.SS3.p2.2.m2.18.18.3.3.1.cmml" xref="S5.SS3.p2.2.m2.18.18.3.3.2"><cn type="integer" id="S5.SS3.p2.2.m2.11.11.cmml" xref="S5.SS3.p2.2.m2.11.11">1</cn><cn type="integer" id="S5.SS3.p2.2.m2.12.12.cmml" xref="S5.SS3.p2.2.m2.12.12">1</cn><cn type="integer" id="S5.SS3.p2.2.m2.13.13.cmml" xref="S5.SS3.p2.2.m2.13.13">21</cn><cn type="integer" id="S5.SS3.p2.2.m2.14.14.cmml" xref="S5.SS3.p2.2.m2.14.14">24</cn><cn type="integer" id="S5.SS3.p2.2.m2.15.15.cmml" xref="S5.SS3.p2.2.m2.15.15">5</cn></vector></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.2.m2.18c">[(0,1,0,16,6),(0,1,19,22,5),(1,1,21,24,5)]</annotation></semantics></math>.
Indeed, the entity ”Giorgia Bronzini” is in the cell in the <math id="S5.SS3.p2.3.m3.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S5.SS3.p2.3.m3.1a"><mn id="S5.SS3.p2.3.m3.1.1" xref="S5.SS3.p2.3.m3.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.3.m3.1b"><cn type="integer" id="S5.SS3.p2.3.m3.1.1.cmml" xref="S5.SS3.p2.3.m3.1.1">0</cn></annotation-xml></semantics></math>-th row, column <math id="S5.SS3.p2.4.m4.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S5.SS3.p2.4.m4.1a"><mn id="S5.SS3.p2.4.m4.1.1" xref="S5.SS3.p2.4.m4.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.4.m4.1b"><cn type="integer" id="S5.SS3.p2.4.m4.1.1.cmml" xref="S5.SS3.p2.4.m4.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.4.m4.1c">1</annotation></semantics></math>, the span of the text is from <math id="S5.SS3.p2.5.m5.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S5.SS3.p2.5.m5.1a"><mn id="S5.SS3.p2.5.m5.1.1" xref="S5.SS3.p2.5.m5.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.5.m5.1b"><cn type="integer" id="S5.SS3.p2.5.m5.1.1.cmml" xref="S5.SS3.p2.5.m5.1.1">0</cn></annotation-xml></semantics></math> to <math id="S5.SS3.p2.6.m6.1" class="ltx_Math" alttext="16" display="inline"><semantics id="S5.SS3.p2.6.m6.1a"><mn id="S5.SS3.p2.6.m6.1.1" xref="S5.SS3.p2.6.m6.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.6.m6.1b"><cn type="integer" id="S5.SS3.p2.6.m6.1.1.cmml" xref="S5.SS3.p2.6.m6.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.6.m6.1c">16</annotation></semantics></math> and the type of the entity is <span id="S5.SS3.p2.10.1" class="ltx_text ltx_font_italic">Person</span> which has a corresponding numerical value <math id="S5.SS3.p2.7.m7.1" class="ltx_Math" alttext="6" display="inline"><semantics id="S5.SS3.p2.7.m7.1a"><mn id="S5.SS3.p2.7.m7.1.1" xref="S5.SS3.p2.7.m7.1.1.cmml">6</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.7.m7.1b"><cn type="integer" id="S5.SS3.p2.7.m7.1.1.cmml" xref="S5.SS3.p2.7.m7.1.1">6</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.7.m7.1c">6</annotation></semantics></math>. In the same cell with index <math id="S5.SS3.p2.8.m8.2" class="ltx_Math" alttext="(0,1)" display="inline"><semantics id="S5.SS3.p2.8.m8.2a"><mrow id="S5.SS3.p2.8.m8.2.3.2" xref="S5.SS3.p2.8.m8.2.3.1.cmml"><mo stretchy="false" id="S5.SS3.p2.8.m8.2.3.2.1" xref="S5.SS3.p2.8.m8.2.3.1.cmml">(</mo><mn id="S5.SS3.p2.8.m8.1.1" xref="S5.SS3.p2.8.m8.1.1.cmml">0</mn><mo id="S5.SS3.p2.8.m8.2.3.2.2" xref="S5.SS3.p2.8.m8.2.3.1.cmml">,</mo><mn id="S5.SS3.p2.8.m8.2.2" xref="S5.SS3.p2.8.m8.2.2.cmml">1</mn><mo stretchy="false" id="S5.SS3.p2.8.m8.2.3.2.3" xref="S5.SS3.p2.8.m8.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.8.m8.2b"><interval closure="open" id="S5.SS3.p2.8.m8.2.3.1.cmml" xref="S5.SS3.p2.8.m8.2.3.2"><cn type="integer" id="S5.SS3.p2.8.m8.1.1.cmml" xref="S5.SS3.p2.8.m8.1.1">0</cn><cn type="integer" id="S5.SS3.p2.8.m8.2.2.cmml" xref="S5.SS3.p2.8.m8.2.2">1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.8.m8.2c">(0,1)</annotation></semantics></math> is also the entity ”ITA” which has the span <math id="S5.SS3.p2.9.m9.2" class="ltx_Math" alttext="(19,22)" display="inline"><semantics id="S5.SS3.p2.9.m9.2a"><mrow id="S5.SS3.p2.9.m9.2.3.2" xref="S5.SS3.p2.9.m9.2.3.1.cmml"><mo stretchy="false" id="S5.SS3.p2.9.m9.2.3.2.1" xref="S5.SS3.p2.9.m9.2.3.1.cmml">(</mo><mn id="S5.SS3.p2.9.m9.1.1" xref="S5.SS3.p2.9.m9.1.1.cmml">19</mn><mo id="S5.SS3.p2.9.m9.2.3.2.2" xref="S5.SS3.p2.9.m9.2.3.1.cmml">,</mo><mn id="S5.SS3.p2.9.m9.2.2" xref="S5.SS3.p2.9.m9.2.2.cmml">22</mn><mo stretchy="false" id="S5.SS3.p2.9.m9.2.3.2.3" xref="S5.SS3.p2.9.m9.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.9.m9.2b"><interval closure="open" id="S5.SS3.p2.9.m9.2.3.1.cmml" xref="S5.SS3.p2.9.m9.2.3.2"><cn type="integer" id="S5.SS3.p2.9.m9.1.1.cmml" xref="S5.SS3.p2.9.m9.1.1">19</cn><cn type="integer" id="S5.SS3.p2.9.m9.2.2.cmml" xref="S5.SS3.p2.9.m9.2.2">22</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.9.m9.2c">(19,22)</annotation></semantics></math> and is of type ”Place”, represented with the numerical value <math id="S5.SS3.p2.10.m10.1" class="ltx_Math" alttext="5" display="inline"><semantics id="S5.SS3.p2.10.m10.1a"><mn id="S5.SS3.p2.10.m10.1.1" xref="S5.SS3.p2.10.m10.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S5.SS3.p2.10.m10.1b"><cn type="integer" id="S5.SS3.p2.10.m10.1.1.cmml" xref="S5.SS3.p2.10.m10.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S5.SS3.p2.10.m10.1c">5</annotation></semantics></math>.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4. </span>Evaluation</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">The last step is the evaluation of the extracted span-based predictions. In this direction, we compare the sequence of tuples representing annotated entities from the ground truth to the sequence of tuples generated by the LLMs. We evaluate how many exact matches are found between these two sequences. As evaluation metrics, we use precision, recall and the F1-score.</p>
</div>
<div id="S5.SS4.p2" class="ltx_para">
<p id="S5.SS4.p2.4" class="ltx_p">To be more specific, our evaluation focuses exclusively on entities which exist in the ground truth that are annotated with the given entity types. Even though in the ground truth there are entities annotated with <math id="S5.SS4.p2.1.m1.1" class="ltx_Math" alttext="0" display="inline"><semantics id="S5.SS4.p2.1.m1.1a"><mn id="S5.SS4.p2.1.m1.1.1" xref="S5.SS4.p2.1.m1.1.1.cmml">0</mn><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.1.m1.1b"><cn type="integer" id="S5.SS4.p2.1.m1.1.1.cmml" xref="S5.SS4.p2.1.m1.1.1">0</cn></annotation-xml></semantics></math> (unknown type), we exclude these entities during the evaluation process. Furthermore, since the Wiki-TabNER dataset is not complete, the LLM might accurately predict an entity type for an entity which does not exist in the ground truth.
For example, the ground truth for the first two rows of the input table in Figure <a href="#S5.F7" title="Figure 7 ‣ 5.1. Input Prompt ‣ 5. Table NER with LLMs ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> is <math id="S5.SS4.p2.2.m2.18" class="ltx_Math" alttext="[(0,1,0,16,6),(0,1,19,22,5),(1,1,21,24,5)]" display="inline"><semantics id="S5.SS4.p2.2.m2.18a"><mrow id="S5.SS4.p2.2.m2.18.18.3" xref="S5.SS4.p2.2.m2.18.18.4.cmml"><mo stretchy="false" id="S5.SS4.p2.2.m2.18.18.3.4" xref="S5.SS4.p2.2.m2.18.18.4.cmml">[</mo><mrow id="S5.SS4.p2.2.m2.16.16.1.1.2" xref="S5.SS4.p2.2.m2.16.16.1.1.1.cmml"><mo stretchy="false" id="S5.SS4.p2.2.m2.16.16.1.1.2.1" xref="S5.SS4.p2.2.m2.16.16.1.1.1.cmml">(</mo><mn id="S5.SS4.p2.2.m2.1.1" xref="S5.SS4.p2.2.m2.1.1.cmml">0</mn><mo id="S5.SS4.p2.2.m2.16.16.1.1.2.2" xref="S5.SS4.p2.2.m2.16.16.1.1.1.cmml">,</mo><mn id="S5.SS4.p2.2.m2.2.2" xref="S5.SS4.p2.2.m2.2.2.cmml">1</mn><mo id="S5.SS4.p2.2.m2.16.16.1.1.2.3" xref="S5.SS4.p2.2.m2.16.16.1.1.1.cmml">,</mo><mn id="S5.SS4.p2.2.m2.3.3" xref="S5.SS4.p2.2.m2.3.3.cmml">0</mn><mo id="S5.SS4.p2.2.m2.16.16.1.1.2.4" xref="S5.SS4.p2.2.m2.16.16.1.1.1.cmml">,</mo><mn id="S5.SS4.p2.2.m2.4.4" xref="S5.SS4.p2.2.m2.4.4.cmml">16</mn><mo id="S5.SS4.p2.2.m2.16.16.1.1.2.5" xref="S5.SS4.p2.2.m2.16.16.1.1.1.cmml">,</mo><mn id="S5.SS4.p2.2.m2.5.5" xref="S5.SS4.p2.2.m2.5.5.cmml">6</mn><mo stretchy="false" id="S5.SS4.p2.2.m2.16.16.1.1.2.6" xref="S5.SS4.p2.2.m2.16.16.1.1.1.cmml">)</mo></mrow><mo id="S5.SS4.p2.2.m2.18.18.3.5" xref="S5.SS4.p2.2.m2.18.18.4.cmml">,</mo><mrow id="S5.SS4.p2.2.m2.17.17.2.2.2" xref="S5.SS4.p2.2.m2.17.17.2.2.1.cmml"><mo stretchy="false" id="S5.SS4.p2.2.m2.17.17.2.2.2.1" xref="S5.SS4.p2.2.m2.17.17.2.2.1.cmml">(</mo><mn id="S5.SS4.p2.2.m2.6.6" xref="S5.SS4.p2.2.m2.6.6.cmml">0</mn><mo id="S5.SS4.p2.2.m2.17.17.2.2.2.2" xref="S5.SS4.p2.2.m2.17.17.2.2.1.cmml">,</mo><mn id="S5.SS4.p2.2.m2.7.7" xref="S5.SS4.p2.2.m2.7.7.cmml">1</mn><mo id="S5.SS4.p2.2.m2.17.17.2.2.2.3" xref="S5.SS4.p2.2.m2.17.17.2.2.1.cmml">,</mo><mn id="S5.SS4.p2.2.m2.8.8" xref="S5.SS4.p2.2.m2.8.8.cmml">19</mn><mo id="S5.SS4.p2.2.m2.17.17.2.2.2.4" xref="S5.SS4.p2.2.m2.17.17.2.2.1.cmml">,</mo><mn id="S5.SS4.p2.2.m2.9.9" xref="S5.SS4.p2.2.m2.9.9.cmml">22</mn><mo id="S5.SS4.p2.2.m2.17.17.2.2.2.5" xref="S5.SS4.p2.2.m2.17.17.2.2.1.cmml">,</mo><mn id="S5.SS4.p2.2.m2.10.10" xref="S5.SS4.p2.2.m2.10.10.cmml">5</mn><mo stretchy="false" id="S5.SS4.p2.2.m2.17.17.2.2.2.6" xref="S5.SS4.p2.2.m2.17.17.2.2.1.cmml">)</mo></mrow><mo id="S5.SS4.p2.2.m2.18.18.3.6" xref="S5.SS4.p2.2.m2.18.18.4.cmml">,</mo><mrow id="S5.SS4.p2.2.m2.18.18.3.3.2" xref="S5.SS4.p2.2.m2.18.18.3.3.1.cmml"><mo stretchy="false" id="S5.SS4.p2.2.m2.18.18.3.3.2.1" xref="S5.SS4.p2.2.m2.18.18.3.3.1.cmml">(</mo><mn id="S5.SS4.p2.2.m2.11.11" xref="S5.SS4.p2.2.m2.11.11.cmml">1</mn><mo id="S5.SS4.p2.2.m2.18.18.3.3.2.2" xref="S5.SS4.p2.2.m2.18.18.3.3.1.cmml">,</mo><mn id="S5.SS4.p2.2.m2.12.12" xref="S5.SS4.p2.2.m2.12.12.cmml">1</mn><mo id="S5.SS4.p2.2.m2.18.18.3.3.2.3" xref="S5.SS4.p2.2.m2.18.18.3.3.1.cmml">,</mo><mn id="S5.SS4.p2.2.m2.13.13" xref="S5.SS4.p2.2.m2.13.13.cmml">21</mn><mo id="S5.SS4.p2.2.m2.18.18.3.3.2.4" xref="S5.SS4.p2.2.m2.18.18.3.3.1.cmml">,</mo><mn id="S5.SS4.p2.2.m2.14.14" xref="S5.SS4.p2.2.m2.14.14.cmml">24</mn><mo id="S5.SS4.p2.2.m2.18.18.3.3.2.5" xref="S5.SS4.p2.2.m2.18.18.3.3.1.cmml">,</mo><mn id="S5.SS4.p2.2.m2.15.15" xref="S5.SS4.p2.2.m2.15.15.cmml">5</mn><mo stretchy="false" id="S5.SS4.p2.2.m2.18.18.3.3.2.6" xref="S5.SS4.p2.2.m2.18.18.3.3.1.cmml">)</mo></mrow><mo stretchy="false" id="S5.SS4.p2.2.m2.18.18.3.7" xref="S5.SS4.p2.2.m2.18.18.4.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.2.m2.18b"><list id="S5.SS4.p2.2.m2.18.18.4.cmml" xref="S5.SS4.p2.2.m2.18.18.3"><vector id="S5.SS4.p2.2.m2.16.16.1.1.1.cmml" xref="S5.SS4.p2.2.m2.16.16.1.1.2"><cn type="integer" id="S5.SS4.p2.2.m2.1.1.cmml" xref="S5.SS4.p2.2.m2.1.1">0</cn><cn type="integer" id="S5.SS4.p2.2.m2.2.2.cmml" xref="S5.SS4.p2.2.m2.2.2">1</cn><cn type="integer" id="S5.SS4.p2.2.m2.3.3.cmml" xref="S5.SS4.p2.2.m2.3.3">0</cn><cn type="integer" id="S5.SS4.p2.2.m2.4.4.cmml" xref="S5.SS4.p2.2.m2.4.4">16</cn><cn type="integer" id="S5.SS4.p2.2.m2.5.5.cmml" xref="S5.SS4.p2.2.m2.5.5">6</cn></vector><vector id="S5.SS4.p2.2.m2.17.17.2.2.1.cmml" xref="S5.SS4.p2.2.m2.17.17.2.2.2"><cn type="integer" id="S5.SS4.p2.2.m2.6.6.cmml" xref="S5.SS4.p2.2.m2.6.6">0</cn><cn type="integer" id="S5.SS4.p2.2.m2.7.7.cmml" xref="S5.SS4.p2.2.m2.7.7">1</cn><cn type="integer" id="S5.SS4.p2.2.m2.8.8.cmml" xref="S5.SS4.p2.2.m2.8.8">19</cn><cn type="integer" id="S5.SS4.p2.2.m2.9.9.cmml" xref="S5.SS4.p2.2.m2.9.9">22</cn><cn type="integer" id="S5.SS4.p2.2.m2.10.10.cmml" xref="S5.SS4.p2.2.m2.10.10">5</cn></vector><vector id="S5.SS4.p2.2.m2.18.18.3.3.1.cmml" xref="S5.SS4.p2.2.m2.18.18.3.3.2"><cn type="integer" id="S5.SS4.p2.2.m2.11.11.cmml" xref="S5.SS4.p2.2.m2.11.11">1</cn><cn type="integer" id="S5.SS4.p2.2.m2.12.12.cmml" xref="S5.SS4.p2.2.m2.12.12">1</cn><cn type="integer" id="S5.SS4.p2.2.m2.13.13.cmml" xref="S5.SS4.p2.2.m2.13.13">21</cn><cn type="integer" id="S5.SS4.p2.2.m2.14.14.cmml" xref="S5.SS4.p2.2.m2.14.14">24</cn><cn type="integer" id="S5.SS4.p2.2.m2.15.15.cmml" xref="S5.SS4.p2.2.m2.15.15">5</cn></vector></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.2.m2.18c">[(0,1,0,16,6),(0,1,19,22,5),(1,1,21,24,5)]</annotation></semantics></math>, while the predicted output from the LLM is <math id="S5.SS4.p2.3.m3.24" class="ltx_Math" alttext="[(0,1,0,16,6),(0,1,19,22,5),(1,1,0,18,6),\\
(1,1,21,24,5)]" display="inline"><semantics id="S5.SS4.p2.3.m3.24a"><mrow id="S5.SS4.p2.3.m3.24.24.4" xref="S5.SS4.p2.3.m3.24.24.5.cmml"><mo stretchy="false" id="S5.SS4.p2.3.m3.24.24.4.5" xref="S5.SS4.p2.3.m3.24.24.5.cmml">[</mo><mrow id="S5.SS4.p2.3.m3.21.21.1.1.2" xref="S5.SS4.p2.3.m3.21.21.1.1.1.cmml"><mo stretchy="false" id="S5.SS4.p2.3.m3.21.21.1.1.2.1" xref="S5.SS4.p2.3.m3.21.21.1.1.1.cmml">(</mo><mn id="S5.SS4.p2.3.m3.1.1" xref="S5.SS4.p2.3.m3.1.1.cmml">0</mn><mo id="S5.SS4.p2.3.m3.21.21.1.1.2.2" xref="S5.SS4.p2.3.m3.21.21.1.1.1.cmml">,</mo><mn id="S5.SS4.p2.3.m3.2.2" xref="S5.SS4.p2.3.m3.2.2.cmml">1</mn><mo id="S5.SS4.p2.3.m3.21.21.1.1.2.3" xref="S5.SS4.p2.3.m3.21.21.1.1.1.cmml">,</mo><mn id="S5.SS4.p2.3.m3.3.3" xref="S5.SS4.p2.3.m3.3.3.cmml">0</mn><mo id="S5.SS4.p2.3.m3.21.21.1.1.2.4" xref="S5.SS4.p2.3.m3.21.21.1.1.1.cmml">,</mo><mn id="S5.SS4.p2.3.m3.4.4" xref="S5.SS4.p2.3.m3.4.4.cmml">16</mn><mo id="S5.SS4.p2.3.m3.21.21.1.1.2.5" xref="S5.SS4.p2.3.m3.21.21.1.1.1.cmml">,</mo><mn id="S5.SS4.p2.3.m3.5.5" xref="S5.SS4.p2.3.m3.5.5.cmml">6</mn><mo stretchy="false" id="S5.SS4.p2.3.m3.21.21.1.1.2.6" xref="S5.SS4.p2.3.m3.21.21.1.1.1.cmml">)</mo></mrow><mo id="S5.SS4.p2.3.m3.24.24.4.6" xref="S5.SS4.p2.3.m3.24.24.5.cmml">,</mo><mrow id="S5.SS4.p2.3.m3.22.22.2.2.2" xref="S5.SS4.p2.3.m3.22.22.2.2.1.cmml"><mo stretchy="false" id="S5.SS4.p2.3.m3.22.22.2.2.2.1" xref="S5.SS4.p2.3.m3.22.22.2.2.1.cmml">(</mo><mn id="S5.SS4.p2.3.m3.6.6" xref="S5.SS4.p2.3.m3.6.6.cmml">0</mn><mo id="S5.SS4.p2.3.m3.22.22.2.2.2.2" xref="S5.SS4.p2.3.m3.22.22.2.2.1.cmml">,</mo><mn id="S5.SS4.p2.3.m3.7.7" xref="S5.SS4.p2.3.m3.7.7.cmml">1</mn><mo id="S5.SS4.p2.3.m3.22.22.2.2.2.3" xref="S5.SS4.p2.3.m3.22.22.2.2.1.cmml">,</mo><mn id="S5.SS4.p2.3.m3.8.8" xref="S5.SS4.p2.3.m3.8.8.cmml">19</mn><mo id="S5.SS4.p2.3.m3.22.22.2.2.2.4" xref="S5.SS4.p2.3.m3.22.22.2.2.1.cmml">,</mo><mn id="S5.SS4.p2.3.m3.9.9" xref="S5.SS4.p2.3.m3.9.9.cmml">22</mn><mo id="S5.SS4.p2.3.m3.22.22.2.2.2.5" xref="S5.SS4.p2.3.m3.22.22.2.2.1.cmml">,</mo><mn id="S5.SS4.p2.3.m3.10.10" xref="S5.SS4.p2.3.m3.10.10.cmml">5</mn><mo stretchy="false" id="S5.SS4.p2.3.m3.22.22.2.2.2.6" xref="S5.SS4.p2.3.m3.22.22.2.2.1.cmml">)</mo></mrow><mo id="S5.SS4.p2.3.m3.24.24.4.7" xref="S5.SS4.p2.3.m3.24.24.5.cmml">,</mo><mrow id="S5.SS4.p2.3.m3.23.23.3.3.2" xref="S5.SS4.p2.3.m3.23.23.3.3.1.cmml"><mo stretchy="false" id="S5.SS4.p2.3.m3.23.23.3.3.2.1" xref="S5.SS4.p2.3.m3.23.23.3.3.1.cmml">(</mo><mn id="S5.SS4.p2.3.m3.11.11" xref="S5.SS4.p2.3.m3.11.11.cmml">1</mn><mo id="S5.SS4.p2.3.m3.23.23.3.3.2.2" xref="S5.SS4.p2.3.m3.23.23.3.3.1.cmml">,</mo><mn id="S5.SS4.p2.3.m3.12.12" xref="S5.SS4.p2.3.m3.12.12.cmml">1</mn><mo id="S5.SS4.p2.3.m3.23.23.3.3.2.3" xref="S5.SS4.p2.3.m3.23.23.3.3.1.cmml">,</mo><mn id="S5.SS4.p2.3.m3.13.13" xref="S5.SS4.p2.3.m3.13.13.cmml">0</mn><mo id="S5.SS4.p2.3.m3.23.23.3.3.2.4" xref="S5.SS4.p2.3.m3.23.23.3.3.1.cmml">,</mo><mn id="S5.SS4.p2.3.m3.14.14" xref="S5.SS4.p2.3.m3.14.14.cmml">18</mn><mo id="S5.SS4.p2.3.m3.23.23.3.3.2.5" xref="S5.SS4.p2.3.m3.23.23.3.3.1.cmml">,</mo><mn id="S5.SS4.p2.3.m3.15.15" xref="S5.SS4.p2.3.m3.15.15.cmml">6</mn><mo stretchy="false" id="S5.SS4.p2.3.m3.23.23.3.3.2.6" xref="S5.SS4.p2.3.m3.23.23.3.3.1.cmml">)</mo></mrow><mo id="S5.SS4.p2.3.m3.24.24.4.8" xref="S5.SS4.p2.3.m3.24.24.5.cmml">,</mo><mrow id="S5.SS4.p2.3.m3.24.24.4.4.2" xref="S5.SS4.p2.3.m3.24.24.4.4.1.cmml"><mo stretchy="false" id="S5.SS4.p2.3.m3.24.24.4.4.2.1" xref="S5.SS4.p2.3.m3.24.24.4.4.1.cmml">(</mo><mn id="S5.SS4.p2.3.m3.16.16" xref="S5.SS4.p2.3.m3.16.16.cmml">1</mn><mo id="S5.SS4.p2.3.m3.24.24.4.4.2.2" xref="S5.SS4.p2.3.m3.24.24.4.4.1.cmml">,</mo><mn id="S5.SS4.p2.3.m3.17.17" xref="S5.SS4.p2.3.m3.17.17.cmml">1</mn><mo id="S5.SS4.p2.3.m3.24.24.4.4.2.3" xref="S5.SS4.p2.3.m3.24.24.4.4.1.cmml">,</mo><mn id="S5.SS4.p2.3.m3.18.18" xref="S5.SS4.p2.3.m3.18.18.cmml">21</mn><mo id="S5.SS4.p2.3.m3.24.24.4.4.2.4" xref="S5.SS4.p2.3.m3.24.24.4.4.1.cmml">,</mo><mn id="S5.SS4.p2.3.m3.19.19" xref="S5.SS4.p2.3.m3.19.19.cmml">24</mn><mo id="S5.SS4.p2.3.m3.24.24.4.4.2.5" xref="S5.SS4.p2.3.m3.24.24.4.4.1.cmml">,</mo><mn id="S5.SS4.p2.3.m3.20.20" xref="S5.SS4.p2.3.m3.20.20.cmml">5</mn><mo stretchy="false" id="S5.SS4.p2.3.m3.24.24.4.4.2.6" xref="S5.SS4.p2.3.m3.24.24.4.4.1.cmml">)</mo></mrow><mo stretchy="false" id="S5.SS4.p2.3.m3.24.24.4.9" xref="S5.SS4.p2.3.m3.24.24.5.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.3.m3.24b"><list id="S5.SS4.p2.3.m3.24.24.5.cmml" xref="S5.SS4.p2.3.m3.24.24.4"><vector id="S5.SS4.p2.3.m3.21.21.1.1.1.cmml" xref="S5.SS4.p2.3.m3.21.21.1.1.2"><cn type="integer" id="S5.SS4.p2.3.m3.1.1.cmml" xref="S5.SS4.p2.3.m3.1.1">0</cn><cn type="integer" id="S5.SS4.p2.3.m3.2.2.cmml" xref="S5.SS4.p2.3.m3.2.2">1</cn><cn type="integer" id="S5.SS4.p2.3.m3.3.3.cmml" xref="S5.SS4.p2.3.m3.3.3">0</cn><cn type="integer" id="S5.SS4.p2.3.m3.4.4.cmml" xref="S5.SS4.p2.3.m3.4.4">16</cn><cn type="integer" id="S5.SS4.p2.3.m3.5.5.cmml" xref="S5.SS4.p2.3.m3.5.5">6</cn></vector><vector id="S5.SS4.p2.3.m3.22.22.2.2.1.cmml" xref="S5.SS4.p2.3.m3.22.22.2.2.2"><cn type="integer" id="S5.SS4.p2.3.m3.6.6.cmml" xref="S5.SS4.p2.3.m3.6.6">0</cn><cn type="integer" id="S5.SS4.p2.3.m3.7.7.cmml" xref="S5.SS4.p2.3.m3.7.7">1</cn><cn type="integer" id="S5.SS4.p2.3.m3.8.8.cmml" xref="S5.SS4.p2.3.m3.8.8">19</cn><cn type="integer" id="S5.SS4.p2.3.m3.9.9.cmml" xref="S5.SS4.p2.3.m3.9.9">22</cn><cn type="integer" id="S5.SS4.p2.3.m3.10.10.cmml" xref="S5.SS4.p2.3.m3.10.10">5</cn></vector><vector id="S5.SS4.p2.3.m3.23.23.3.3.1.cmml" xref="S5.SS4.p2.3.m3.23.23.3.3.2"><cn type="integer" id="S5.SS4.p2.3.m3.11.11.cmml" xref="S5.SS4.p2.3.m3.11.11">1</cn><cn type="integer" id="S5.SS4.p2.3.m3.12.12.cmml" xref="S5.SS4.p2.3.m3.12.12">1</cn><cn type="integer" id="S5.SS4.p2.3.m3.13.13.cmml" xref="S5.SS4.p2.3.m3.13.13">0</cn><cn type="integer" id="S5.SS4.p2.3.m3.14.14.cmml" xref="S5.SS4.p2.3.m3.14.14">18</cn><cn type="integer" id="S5.SS4.p2.3.m3.15.15.cmml" xref="S5.SS4.p2.3.m3.15.15">6</cn></vector><vector id="S5.SS4.p2.3.m3.24.24.4.4.1.cmml" xref="S5.SS4.p2.3.m3.24.24.4.4.2"><cn type="integer" id="S5.SS4.p2.3.m3.16.16.cmml" xref="S5.SS4.p2.3.m3.16.16">1</cn><cn type="integer" id="S5.SS4.p2.3.m3.17.17.cmml" xref="S5.SS4.p2.3.m3.17.17">1</cn><cn type="integer" id="S5.SS4.p2.3.m3.18.18.cmml" xref="S5.SS4.p2.3.m3.18.18">21</cn><cn type="integer" id="S5.SS4.p2.3.m3.19.19.cmml" xref="S5.SS4.p2.3.m3.19.19">24</cn><cn type="integer" id="S5.SS4.p2.3.m3.20.20.cmml" xref="S5.SS4.p2.3.m3.20.20">5</cn></vector></list></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.3.m3.24c">[(0,1,0,16,6),(0,1,19,22,5),(1,1,0,18,6),\\
(1,1,21,24,5)]</annotation></semantics></math>. We notice that one of the entities which is recognized by the LLM, the entity ”Joelle Numainville” represented with the tuple <math id="S5.SS4.p2.4.m4.5" class="ltx_Math" alttext="(1,1,0,18,6)" display="inline"><semantics id="S5.SS4.p2.4.m4.5a"><mrow id="S5.SS4.p2.4.m4.5.6.2" xref="S5.SS4.p2.4.m4.5.6.1.cmml"><mo stretchy="false" id="S5.SS4.p2.4.m4.5.6.2.1" xref="S5.SS4.p2.4.m4.5.6.1.cmml">(</mo><mn id="S5.SS4.p2.4.m4.1.1" xref="S5.SS4.p2.4.m4.1.1.cmml">1</mn><mo id="S5.SS4.p2.4.m4.5.6.2.2" xref="S5.SS4.p2.4.m4.5.6.1.cmml">,</mo><mn id="S5.SS4.p2.4.m4.2.2" xref="S5.SS4.p2.4.m4.2.2.cmml">1</mn><mo id="S5.SS4.p2.4.m4.5.6.2.3" xref="S5.SS4.p2.4.m4.5.6.1.cmml">,</mo><mn id="S5.SS4.p2.4.m4.3.3" xref="S5.SS4.p2.4.m4.3.3.cmml">0</mn><mo id="S5.SS4.p2.4.m4.5.6.2.4" xref="S5.SS4.p2.4.m4.5.6.1.cmml">,</mo><mn id="S5.SS4.p2.4.m4.4.4" xref="S5.SS4.p2.4.m4.4.4.cmml">18</mn><mo id="S5.SS4.p2.4.m4.5.6.2.5" xref="S5.SS4.p2.4.m4.5.6.1.cmml">,</mo><mn id="S5.SS4.p2.4.m4.5.5" xref="S5.SS4.p2.4.m4.5.5.cmml">6</mn><mo stretchy="false" id="S5.SS4.p2.4.m4.5.6.2.6" xref="S5.SS4.p2.4.m4.5.6.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS4.p2.4.m4.5b"><vector id="S5.SS4.p2.4.m4.5.6.1.cmml" xref="S5.SS4.p2.4.m4.5.6.2"><cn type="integer" id="S5.SS4.p2.4.m4.1.1.cmml" xref="S5.SS4.p2.4.m4.1.1">1</cn><cn type="integer" id="S5.SS4.p2.4.m4.2.2.cmml" xref="S5.SS4.p2.4.m4.2.2">1</cn><cn type="integer" id="S5.SS4.p2.4.m4.3.3.cmml" xref="S5.SS4.p2.4.m4.3.3">0</cn><cn type="integer" id="S5.SS4.p2.4.m4.4.4.cmml" xref="S5.SS4.p2.4.m4.4.4">18</cn><cn type="integer" id="S5.SS4.p2.4.m4.5.5.cmml" xref="S5.SS4.p2.4.m4.5.5">6</cn></vector></annotation-xml><annotation encoding="application/x-tex" id="S5.SS4.p2.4.m4.5c">(1,1,0,18,6)</annotation></semantics></math>, is missing from the ground truth. Nevertheless, this entity will be included during the evaluation.</p>
</div>
<div id="S5.SS4.p3" class="ltx_para">
<p id="S5.SS4.p3.1" class="ltx_p">Moreover, there are cases when the LLMs assign too specific types to the entities.
Whenever the model correctly recognizes an entity, but wrongly assigns it an entity type <span id="S5.SS4.p3.1.1" class="ltx_text ltx_font_bold">not included</span> in the set of types specified in the instruction, this entity is categorized as ”MISC” and this annotation will be discarded.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span>Evaluation</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Although the Wiki-TabNER dataset includes BIO-labels, in this work we focus on evaluating pre-trained (LLMs) using a span-based evaluation approach.
Next, we outline the various experiments conducted to assess the performance of pre-trained LLMs on the table NER task.</p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1. </span>Dataset</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.3" class="ltx_p">For the evaluation we use the presented benchmark dataset Wiki-TabNER, described in section <a href="#S4" title="4. New Dataset Proposal ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Initially, we conducted experiments on a test set of randomly chosen <math id="S6.SS1.p1.1.m1.1" class="ltx_Math" alttext="2000" display="inline"><semantics id="S6.SS1.p1.1.m1.1a"><mn id="S6.SS1.p1.1.m1.1.1" xref="S6.SS1.p1.1.m1.1.1.cmml">2000</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.p1.1.m1.1b"><cn type="integer" id="S6.SS1.p1.1.m1.1.1.cmml" xref="S6.SS1.p1.1.m1.1.1">2000</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p1.1.m1.1c">2000</annotation></semantics></math> tables. However, these experiments took a considerable amount of time to complete and we noticed that there is no significant change in the metrics after the <math id="S6.SS1.p1.2.m2.1" class="ltx_Math" alttext="600" display="inline"><semantics id="S6.SS1.p1.2.m2.1a"><mn id="S6.SS1.p1.2.m2.1.1" xref="S6.SS1.p1.2.m2.1.1.cmml">600</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.p1.2.m2.1b"><cn type="integer" id="S6.SS1.p1.2.m2.1.1.cmml" xref="S6.SS1.p1.2.m2.1.1">600</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p1.2.m2.1c">600</annotation></semantics></math>-th table. Hence, we decided to evaluate on a smaller test set consisting of <math id="S6.SS1.p1.3.m3.1" class="ltx_Math" alttext="600" display="inline"><semantics id="S6.SS1.p1.3.m3.1a"><mn id="S6.SS1.p1.3.m3.1.1" xref="S6.SS1.p1.3.m3.1.1.cmml">600</mn><annotation-xml encoding="MathML-Content" id="S6.SS1.p1.3.m3.1b"><cn type="integer" id="S6.SS1.p1.3.m3.1.1.cmml" xref="S6.SS1.p1.3.m3.1.1">600</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS1.p1.3.m3.1c">600</annotation></semantics></math> tables. We show the comparison of the execution times with the initial experiments in Table <a href="#S6.T3" title="Table 3 ‣ 6.3. Results ‣ 6. Evaluation ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>.</p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2. </span>Models</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">We conducted the experiments with the Open-AI LLMs <span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://platform.openai.com/docs/models</span></span></span>: GPT-instruct which is the GPT 3 model <cite class="ltx_cite ltx_citemacro_citep">(Brown et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2020</a>)</cite> optimized for instruction following with maximum context length of 4096 tokens. GPT-3.5-turbo which is the same GPT 3 model but optimized for chat completion with context length of 16385 tokens. The more recent GPT-4 model <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a href="#bib.bib26" title="" class="ltx_ref">2023</a>)</cite> which has context window of 8192 tokens, and the open source model Llama2-7b <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2023</a>)</cite> with maximum context length of 4096 tokens. We also tried to evaluate the TableLlama <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2023b</a>)</cite> but the model was struggling with the defined task and only outputting the instruction part, so we were unable to get any meaningful output.</p>
</div>
</section>
<section id="S6.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3. </span>Results</h3>

<div id="S6.SS3.p1" class="ltx_para">
<p id="S6.SS3.p1.1" class="ltx_p">In Table <a href="#S6.T3" title="Table 3 ‣ 6.3. Results ‣ 6. Evaluation ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> we show the results from the initial experiments with the Open-AI LLMs, on the test set with 2000 tables compared to the test set with 600 tables. We show the achieved F1 score across the GPT models and the time of execution. We notice that there is no change in the achieved score, however the duration of the evaluation is reduced significantly.</p>
</div>
<figure id="S6.T3" class="ltx_table">
<table id="S6.T3.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T3.2.1.1" class="ltx_tr">
<th id="S6.T3.2.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_border_r"></th>
<th id="S6.T3.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r" colspan="2"><span id="S6.T3.2.1.1.2.1" class="ltx_text ltx_font_bold">2000 tables</span></th>
<th id="S6.T3.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r" colspan="2"><span id="S6.T3.2.1.1.3.1" class="ltx_text ltx_font_bold">600 tables</span></th>
</tr>
<tr id="S6.T3.2.2.2" class="ltx_tr">
<th id="S6.T3.2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Model</th>
<th id="S6.T3.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">F1 score</th>
<th id="S6.T3.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Time</th>
<th id="S6.T3.2.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">F1 score</th>
<th id="S6.T3.2.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">Time</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T3.2.3.1" class="ltx_tr">
<td id="S6.T3.2.3.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">GPT-instruct</td>
<td id="S6.T3.2.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.50</td>
<td id="S6.T3.2.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">04h50m</td>
<td id="S6.T3.2.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.51</td>
<td id="S6.T3.2.3.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">01h10m</td>
</tr>
<tr id="S6.T3.2.4.2" class="ltx_tr">
<td id="S6.T3.2.4.2.1" class="ltx_td ltx_align_center ltx_border_r">GPT-3.5-turbo</td>
<td id="S6.T3.2.4.2.2" class="ltx_td ltx_align_center ltx_border_r">0.40</td>
<td id="S6.T3.2.4.2.3" class="ltx_td ltx_align_center ltx_border_r">04h19m</td>
<td id="S6.T3.2.4.2.4" class="ltx_td ltx_align_center ltx_border_r">0.40</td>
<td id="S6.T3.2.4.2.5" class="ltx_td ltx_align_center ltx_border_r">01h30m</td>
</tr>
<tr id="S6.T3.2.5.3" class="ltx_tr">
<td id="S6.T3.2.5.3.1" class="ltx_td ltx_align_center ltx_border_r">GPT-4</td>
<td id="S6.T3.2.5.3.2" class="ltx_td ltx_align_center ltx_border_r">0.41</td>
<td id="S6.T3.2.5.3.3" class="ltx_td ltx_align_center ltx_border_r">28h34m</td>
<td id="S6.T3.2.5.3.4" class="ltx_td ltx_align_center ltx_border_r">0.41</td>
<td id="S6.T3.2.5.3.5" class="ltx_td ltx_align_center ltx_border_r">11h30m</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S6.T3.3.1.1" class="ltx_text" style="font-size:90%;">Table 3</span>. </span><span id="S6.T3.4.2" class="ltx_text" style="font-size:90%;">F1 Score and execution time of evaluation over 2000 tables and 600 tables</span></figcaption>
</figure>
<div id="S6.SS3.p2" class="ltx_para">
<p id="S6.SS3.p2.1" class="ltx_p">We now report the achieved precision, recall and F1 scores of the models, on the zero-shot predictions on the test set of 600 tables. Table <a href="#S6.T4" title="Table 4 ‣ 6.3. Results ‣ 6. Evaluation ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the performance achieved by the LLMs.
It is interesting to note that the GPT-instruct model has the highest F1 score among the models, even higher than the newer GPT-4 model. Another interesting result is the much higher precision than recall achieved by the Llama2 model. This suggests that while the model struggles to accurately identify many entities, it demonstrates a 53% precision rate in correctly predicting the entities that were recognized. Overall, without seeing any example of NER annotated entities, all of the models struggle with this task and achieve an F1 score of 0.5 or lower.</p>
</div>
<figure id="S6.T4" class="ltx_table">
<table id="S6.T4.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T4.2.1.1" class="ltx_tr">
<th id="S6.T4.2.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S6.T4.2.1.1.1.1" class="ltx_text ltx_font_bold">Model</span></th>
<th id="S6.T4.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S6.T4.2.1.1.2.1" class="ltx_text ltx_font_bold">P</span></th>
<th id="S6.T4.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r"><span id="S6.T4.2.1.1.3.1" class="ltx_text ltx_font_bold">R</span></th>
<th id="S6.T4.2.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column"><span id="S6.T4.2.1.1.4.1" class="ltx_text ltx_font_bold">F1</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T4.2.2.1" class="ltx_tr">
<td id="S6.T4.2.2.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">GPT-instruct</td>
<td id="S6.T4.2.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.57</td>
<td id="S6.T4.2.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.45</td>
<td id="S6.T4.2.2.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T4.2.2.1.4.1" class="ltx_text ltx_font_bold">0.51</span></td>
</tr>
<tr id="S6.T4.2.3.2" class="ltx_tr">
<td id="S6.T4.2.3.2.1" class="ltx_td ltx_align_center ltx_border_r">GPT-3.5-turbo</td>
<td id="S6.T4.2.3.2.2" class="ltx_td ltx_align_center ltx_border_r">0.53</td>
<td id="S6.T4.2.3.2.3" class="ltx_td ltx_align_center ltx_border_r">0.34</td>
<td id="S6.T4.2.3.2.4" class="ltx_td ltx_align_center">0.40</td>
</tr>
<tr id="S6.T4.2.4.3" class="ltx_tr">
<td id="S6.T4.2.4.3.1" class="ltx_td ltx_align_center ltx_border_r">GPT-4</td>
<td id="S6.T4.2.4.3.2" class="ltx_td ltx_align_center ltx_border_r">0.43</td>
<td id="S6.T4.2.4.3.3" class="ltx_td ltx_align_center ltx_border_r">0.39</td>
<td id="S6.T4.2.4.3.4" class="ltx_td ltx_align_center">0.41</td>
</tr>
<tr id="S6.T4.2.5.4" class="ltx_tr">
<td id="S6.T4.2.5.4.1" class="ltx_td ltx_align_center ltx_border_r">Llama2-7b</td>
<td id="S6.T4.2.5.4.2" class="ltx_td ltx_align_center ltx_border_r">0.53</td>
<td id="S6.T4.2.5.4.3" class="ltx_td ltx_align_center ltx_border_r">0.01</td>
<td id="S6.T4.2.5.4.4" class="ltx_td ltx_align_center">0.02</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S6.T4.3.1.1" class="ltx_text" style="font-size:90%;">Table 4</span>. </span><span id="S6.T4.4.2" class="ltx_text" style="font-size:90%;">LLMs performance on Wiki-TabNER task with zero-shot</span></figcaption>
</figure>
<figure id="S6.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F8.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.04577/assets/figures/GPT-35-turbo-instruct_both.png" id="S6.F8.1.g1" class="ltx_graphics ltx_img_square" width="598" height="591" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F8.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.04577/assets/figures/GPT-35-turbo_both.png" id="S6.F8.2.g1" class="ltx_graphics ltx_img_square" width="598" height="591" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F8.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.04577/assets/figures/GPT-4_both.png" id="S6.F8.3.g1" class="ltx_graphics ltx_img_square" width="598" height="591" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F8.4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.04577/assets/figures/Llama2_both.png" id="S6.F8.4.g1" class="ltx_graphics ltx_img_square" width="598" height="598" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F8.6.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>. </span><span id="S6.F8.7.2" class="ltx_text" style="font-size:90%;">Class-wise evaluation of the models 0 vs 3 shot examples sampled by similarity</span></figcaption>
</figure>
</section>
<section id="S6.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4. </span>Class-wise</h3>

<div id="S6.SS4.p1" class="ltx_para">
<p id="S6.SS4.p1.3" class="ltx_p">For a more detailed analysis, we calculate the class-wise F1 scores across the models. We show these results in Figure <a href="#S6.F8" title="Figure 8 ‣ 6.3. Results ‣ 6. Evaluation ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> alongside the class-wise results for the three-shot experiments.
For all the models, entities of type <span id="S6.SS4.p1.3.1" class="ltx_text ltx_font_italic">Activity</span> are the hardest to annotate, while <span id="S6.SS4.p1.3.2" class="ltx_text ltx_font_italic">Person</span> is the class where all the models have the highest F1 score when not shown any examples. The Llama2 model exhibited very low performance when not shown any examples, with the highest F1 score for the class <span id="S6.SS4.p1.3.3" class="ltx_text ltx_font_italic">Person</span> of just <math id="S6.SS4.p1.1.m1.1" class="ltx_Math" alttext="0.035" display="inline"><semantics id="S6.SS4.p1.1.m1.1a"><mn id="S6.SS4.p1.1.m1.1.1" xref="S6.SS4.p1.1.m1.1.1.cmml">0.035</mn><annotation-xml encoding="MathML-Content" id="S6.SS4.p1.1.m1.1b"><cn type="float" id="S6.SS4.p1.1.m1.1.1.cmml" xref="S6.SS4.p1.1.m1.1.1">0.035</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p1.1.m1.1c">0.035</annotation></semantics></math>. It is interesting to note, that in the case of 0-shot, the GPT-instruct is either on par or even better than the more powerful GPT-4 model.
In Figure <a href="#S6.F8" title="Figure 8 ‣ 6.3. Results ‣ 6. Evaluation ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> we also see the improvement across all classes in the case of the 3-shot experiment. We observe the most notable improvement in the class <span id="S6.SS4.p1.3.4" class="ltx_text ltx_font_italic">Architectural Structure</span>, where across all of the GPT models, has a significant increase in F1 score (from <math id="S6.SS4.p1.2.m2.1" class="ltx_Math" alttext="\sim 0.04" display="inline"><semantics id="S6.SS4.p1.2.m2.1a"><mrow id="S6.SS4.p1.2.m2.1.1" xref="S6.SS4.p1.2.m2.1.1.cmml"><mi id="S6.SS4.p1.2.m2.1.1.2" xref="S6.SS4.p1.2.m2.1.1.2.cmml"></mi><mo id="S6.SS4.p1.2.m2.1.1.1" xref="S6.SS4.p1.2.m2.1.1.1.cmml">∼</mo><mn id="S6.SS4.p1.2.m2.1.1.3" xref="S6.SS4.p1.2.m2.1.1.3.cmml">0.04</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS4.p1.2.m2.1b"><apply id="S6.SS4.p1.2.m2.1.1.cmml" xref="S6.SS4.p1.2.m2.1.1"><csymbol cd="latexml" id="S6.SS4.p1.2.m2.1.1.1.cmml" xref="S6.SS4.p1.2.m2.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S6.SS4.p1.2.m2.1.1.2.cmml" xref="S6.SS4.p1.2.m2.1.1.2">absent</csymbol><cn type="float" id="S6.SS4.p1.2.m2.1.1.3.cmml" xref="S6.SS4.p1.2.m2.1.1.3">0.04</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p1.2.m2.1c">\sim 0.04</annotation></semantics></math> to <math id="S6.SS4.p1.3.m3.1" class="ltx_Math" alttext="\sim 0.58" display="inline"><semantics id="S6.SS4.p1.3.m3.1a"><mrow id="S6.SS4.p1.3.m3.1.1" xref="S6.SS4.p1.3.m3.1.1.cmml"><mi id="S6.SS4.p1.3.m3.1.1.2" xref="S6.SS4.p1.3.m3.1.1.2.cmml"></mi><mo id="S6.SS4.p1.3.m3.1.1.1" xref="S6.SS4.p1.3.m3.1.1.1.cmml">∼</mo><mn id="S6.SS4.p1.3.m3.1.1.3" xref="S6.SS4.p1.3.m3.1.1.3.cmml">0.58</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.SS4.p1.3.m3.1b"><apply id="S6.SS4.p1.3.m3.1.1.cmml" xref="S6.SS4.p1.3.m3.1.1"><csymbol cd="latexml" id="S6.SS4.p1.3.m3.1.1.1.cmml" xref="S6.SS4.p1.3.m3.1.1.1">similar-to</csymbol><csymbol cd="latexml" id="S6.SS4.p1.3.m3.1.1.2.cmml" xref="S6.SS4.p1.3.m3.1.1.2">absent</csymbol><cn type="float" id="S6.SS4.p1.3.m3.1.1.3.cmml" xref="S6.SS4.p1.3.m3.1.1.3">0.58</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS4.p1.3.m3.1c">\sim 0.58</annotation></semantics></math> for the GPT-3.5-turbo and GPT-4 models).</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7. </span>Ablation Study</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">We now investigate the effects of the few-shot examples shown to the model. Additionally, we conduct a more refined evaluation where we use only 4 classes for annotation.</p>
</div>
<section id="S7.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.1. </span>Robustness to example tables</h3>

<div id="S7.SS1.p1" class="ltx_para">
<p id="S7.SS1.p1.1" class="ltx_p">To explore the impact of the few-shot examples, we evaluate two different strategies for sampling the examples: random selection and similarity-based selection. We experiment with 1 and three-shot examples for both strategies. We always choose the example tables from a training set, i.e., these are not tables that will appear in the evaluation. Since the number of input and output tokens of the models is limited, when adding the examples tables to the input prompt, we restrict their size to be at maximum to 4 rows.
During the experiments, the structure of the prompt is as presented in Section <a href="#S5.SS1" title="5.1. Input Prompt ‣ 5. Table NER with LLMs ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5.1</span></a>. We only increase the number of table examples shown to the model.</p>
</div>
<section id="S7.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Random</h4>

<div id="S7.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S7.SS1.SSS0.Px1.p1.1" class="ltx_p">For the random selection, we sampled at random 3 tables from the train set and we extracted their NER annotations. For the 1-shot experiment we use one of this tables as an example. To be consistent, we use the same example tables for all of the test tables and for all of the models.</p>
</div>
<figure id="S7.T5" class="ltx_table">
<table id="S7.T5.2" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S7.T5.2.1.1" class="ltx_tr">
<td id="S7.T5.2.1.1.1" class="ltx_td ltx_border_r"></td>
<td id="S7.T5.2.1.1.2" class="ltx_td ltx_align_center ltx_border_l ltx_border_r" colspan="2"><span id="S7.T5.2.1.1.2.1" class="ltx_text ltx_font_bold">Random</span></td>
<td id="S7.T5.2.1.1.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r" colspan="2"><span id="S7.T5.2.1.1.3.1" class="ltx_text ltx_font_bold">Similarity</span></td>
<td id="S7.T5.2.1.1.4" class="ltx_td"></td>
</tr>
<tr id="S7.T5.2.2.2" class="ltx_tr">
<td id="S7.T5.2.2.2.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S7.T5.2.2.2.1.1" class="ltx_text ltx_font_bold">Model</span></td>
<td id="S7.T5.2.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1-shot</td>
<td id="S7.T5.2.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3-shot</td>
<td id="S7.T5.2.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1-shot</td>
<td id="S7.T5.2.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">3-shot</td>
<td id="S7.T5.2.2.2.6" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S7.T5.2.3.3" class="ltx_tr">
<td id="S7.T5.2.3.3.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">GPT-instruct</td>
<td id="S7.T5.2.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.51</td>
<td id="S7.T5.2.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.54</td>
<td id="S7.T5.2.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.67</td>
<td id="S7.T5.2.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.69</td>
<td id="S7.T5.2.3.3.6" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S7.T5.2.4.4" class="ltx_tr">
<td id="S7.T5.2.4.4.1" class="ltx_td ltx_align_center ltx_border_r">GPT-3.5-turbo</td>
<td id="S7.T5.2.4.4.2" class="ltx_td ltx_align_center ltx_border_r">0.41</td>
<td id="S7.T5.2.4.4.3" class="ltx_td ltx_align_center ltx_border_r">0.48</td>
<td id="S7.T5.2.4.4.4" class="ltx_td ltx_align_center ltx_border_r">0.68</td>
<td id="S7.T5.2.4.4.5" class="ltx_td ltx_align_center ltx_border_r">0.73</td>
<td id="S7.T5.2.4.4.6" class="ltx_td"></td>
</tr>
<tr id="S7.T5.2.5.5" class="ltx_tr">
<td id="S7.T5.2.5.5.1" class="ltx_td ltx_align_center ltx_border_r">GPT-4</td>
<td id="S7.T5.2.5.5.2" class="ltx_td ltx_align_center ltx_border_r">0.43</td>
<td id="S7.T5.2.5.5.3" class="ltx_td ltx_align_center ltx_border_r">0.46</td>
<td id="S7.T5.2.5.5.4" class="ltx_td ltx_align_center ltx_border_r">0.68</td>
<td id="S7.T5.2.5.5.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T5.2.5.5.5.1" class="ltx_text ltx_font_bold">0.74</span></td>
<td id="S7.T5.2.5.5.6" class="ltx_td"></td>
</tr>
<tr id="S7.T5.2.6.6" class="ltx_tr">
<td id="S7.T5.2.6.6.1" class="ltx_td ltx_align_center ltx_border_r">Llama2-7b</td>
<td id="S7.T5.2.6.6.2" class="ltx_td ltx_align_center ltx_border_r">0.04</td>
<td id="S7.T5.2.6.6.3" class="ltx_td ltx_align_center ltx_border_r">0.08</td>
<td id="S7.T5.2.6.6.4" class="ltx_td ltx_align_center ltx_border_r">0.23</td>
<td id="S7.T5.2.6.6.5" class="ltx_td ltx_align_center ltx_border_r">0.29</td>
<td id="S7.T5.2.6.6.6" class="ltx_td"></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S7.T5.3.1.1" class="ltx_text" style="font-size:90%;">Table 5</span>. </span><span id="S7.T5.4.2" class="ltx_text" style="font-size:90%;">F1 Score with k-shot examples sampled at random and by similarity</span></figcaption>
</figure>
</section>
<section id="S7.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_font_bold ltx_title_paragraph">Similarity</h4>

<div id="S7.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S7.SS1.SSS0.Px2.p1.1" class="ltx_p">For the similarity-based selection of examples, we first compute the contextual vector for every table in the Wiki-TabNER dataset. We start by linearizing the table by concatenating the rows into one string. Then, we compute the BERT <cite class="ltx_cite ltx_citemacro_citep">(Devlin et al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2019</a>)</cite> contextual vector for every linearized table. To find similar tables, for every table in the test set, we compute the dot product with every table in the train set. Based on the similarity score, we select the three most similar tables for every table in the test set. We then extract the NER annotations for these tables. During the evaluation, for each test table, we sample either 1 or 3 most similar tables as k-shot examples. In Figure <a href="#S5.F7" title="Figure 7 ‣ 5.1. Input Prompt ‣ 5. Table NER with LLMs ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> the example table is chosen based on the high similarity to the input table.</p>
</div>
<div id="S7.SS1.SSS0.Px2.p2" class="ltx_para">
<p id="S7.SS1.SSS0.Px2.p2.1" class="ltx_p">We summarize the results in Table <a href="#S7.T5" title="Table 5 ‣ Random ‣ 7.1. Robustness to example tables ‣ 7. Ablation Study ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> where we show the achieved F1 score for all of the models. It is evident that all of the models improve with the addition of example to the input prompt. As expected, the similarity-based sampling strategy improves the results by a larger margin than the random-based strategy.</p>
</div>
<figure id="S7.T6" class="ltx_table">
<table id="S7.T6.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S7.T6.2.1.1" class="ltx_tr">
<th id="S7.T6.2.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_border_r"></th>
<th id="S7.T6.2.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r" colspan="2"><span id="S7.T6.2.1.1.2.1" class="ltx_text ltx_font_bold">Random</span></th>
<th id="S7.T6.2.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r" colspan="2"><span id="S7.T6.2.1.1.3.1" class="ltx_text ltx_font_bold">Similarity</span></th>
<th id="S7.T6.2.1.1.4" class="ltx_td ltx_th ltx_th_column"></th>
</tr>
<tr id="S7.T6.2.2.2" class="ltx_tr">
<th id="S7.T6.2.2.2.1" class="ltx_td ltx_th ltx_th_column ltx_border_r ltx_border_t"></th>
<th id="S7.T6.2.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">1-shot</th>
<th id="S7.T6.2.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">3-shot</th>
<th id="S7.T6.2.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">1-shot</th>
<th id="S7.T6.2.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">3-shot</th>
<th id="S7.T6.2.2.2.6" class="ltx_td ltx_th ltx_th_column ltx_border_t"></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S7.T6.2.3.1" class="ltx_tr">
<td id="S7.T6.2.3.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">GPT-instruct</td>
<td id="S7.T6.2.3.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.51</td>
<td id="S7.T6.2.3.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.52</td>
<td id="S7.T6.2.3.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.68</td>
<td id="S7.T6.2.3.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.71</td>
<td id="S7.T6.2.3.1.6" class="ltx_td ltx_border_t"></td>
</tr>
<tr id="S7.T6.2.4.2" class="ltx_tr">
<td id="S7.T6.2.4.2.1" class="ltx_td ltx_align_center ltx_border_r">GPT-3.5-turbo</td>
<td id="S7.T6.2.4.2.2" class="ltx_td ltx_align_center ltx_border_r">0.42</td>
<td id="S7.T6.2.4.2.3" class="ltx_td ltx_align_center ltx_border_r">0.47</td>
<td id="S7.T6.2.4.2.4" class="ltx_td ltx_align_center ltx_border_r">0.68</td>
<td id="S7.T6.2.4.2.5" class="ltx_td ltx_align_center ltx_border_r"><span id="S7.T6.2.4.2.5.1" class="ltx_text ltx_font_bold">0.73</span></td>
<td id="S7.T6.2.4.2.6" class="ltx_td"></td>
</tr>
<tr id="S7.T6.2.5.3" class="ltx_tr">
<td id="S7.T6.2.5.3.1" class="ltx_td ltx_align_center ltx_border_r">GPT-4</td>
<td id="S7.T6.2.5.3.2" class="ltx_td ltx_align_center ltx_border_r">0.43</td>
<td id="S7.T6.2.5.3.3" class="ltx_td ltx_align_center ltx_border_r">0.47</td>
<td id="S7.T6.2.5.3.4" class="ltx_td ltx_align_center ltx_border_r">0.69</td>
<td id="S7.T6.2.5.3.5" class="ltx_td ltx_align_center ltx_border_r">0.71</td>
<td id="S7.T6.2.5.3.6" class="ltx_td"></td>
</tr>
<tr id="S7.T6.2.6.4" class="ltx_tr">
<td id="S7.T6.2.6.4.1" class="ltx_td ltx_align_center ltx_border_r">Llama2-7b</td>
<td id="S7.T6.2.6.4.2" class="ltx_td ltx_align_center ltx_border_r">0.05</td>
<td id="S7.T6.2.6.4.3" class="ltx_td ltx_align_center ltx_border_r">0.09</td>
<td id="S7.T6.2.6.4.4" class="ltx_td ltx_align_center ltx_border_r">0.28</td>
<td id="S7.T6.2.6.4.5" class="ltx_td ltx_align_center ltx_border_r">0.38</td>
<td id="S7.T6.2.6.4.6" class="ltx_td"></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S7.T6.3.1.1" class="ltx_text" style="font-size:90%;">Table 6</span>. </span><span id="S7.T6.4.2" class="ltx_text" style="font-size:90%;">F1 Score with k-shot examples sampled at random and by similarity with reduced set of labels.</span></figcaption>
</figure>
</section>
</section>
<section id="S7.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">7.2. </span>Label specificity</h3>

<div id="S7.SS2.p1" class="ltx_para">
<p id="S7.SS2.p1.1" class="ltx_p">We observe that many of the errors are due to the possibility that one entity is of type Event or Activity. Therefore, we evaluate how much the models will improve if we keep only the 4 most distinct labels. We reduce the set of labels to : <math id="S7.SS2.p1.1.m1.4" class="ltx_Math" alttext="\{Organisation,Place,Person,Work\}" display="inline"><semantics id="S7.SS2.p1.1.m1.4a"><mrow id="S7.SS2.p1.1.m1.4.4.4" xref="S7.SS2.p1.1.m1.4.4.5.cmml"><mo stretchy="false" id="S7.SS2.p1.1.m1.4.4.4.5" xref="S7.SS2.p1.1.m1.4.4.5.cmml">{</mo><mrow id="S7.SS2.p1.1.m1.1.1.1.1" xref="S7.SS2.p1.1.m1.1.1.1.1.cmml"><mi id="S7.SS2.p1.1.m1.1.1.1.1.2" xref="S7.SS2.p1.1.m1.1.1.1.1.2.cmml">O</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.1.1.1.1.1" xref="S7.SS2.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.1.1.1.1.3" xref="S7.SS2.p1.1.m1.1.1.1.1.3.cmml">r</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.1.1.1.1.1a" xref="S7.SS2.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.1.1.1.1.4" xref="S7.SS2.p1.1.m1.1.1.1.1.4.cmml">g</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.1.1.1.1.1b" xref="S7.SS2.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.1.1.1.1.5" xref="S7.SS2.p1.1.m1.1.1.1.1.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.1.1.1.1.1c" xref="S7.SS2.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.1.1.1.1.6" xref="S7.SS2.p1.1.m1.1.1.1.1.6.cmml">n</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.1.1.1.1.1d" xref="S7.SS2.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.1.1.1.1.7" xref="S7.SS2.p1.1.m1.1.1.1.1.7.cmml">i</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.1.1.1.1.1e" xref="S7.SS2.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.1.1.1.1.8" xref="S7.SS2.p1.1.m1.1.1.1.1.8.cmml">s</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.1.1.1.1.1f" xref="S7.SS2.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.1.1.1.1.9" xref="S7.SS2.p1.1.m1.1.1.1.1.9.cmml">a</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.1.1.1.1.1g" xref="S7.SS2.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.1.1.1.1.10" xref="S7.SS2.p1.1.m1.1.1.1.1.10.cmml">t</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.1.1.1.1.1h" xref="S7.SS2.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.1.1.1.1.11" xref="S7.SS2.p1.1.m1.1.1.1.1.11.cmml">i</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.1.1.1.1.1i" xref="S7.SS2.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.1.1.1.1.12" xref="S7.SS2.p1.1.m1.1.1.1.1.12.cmml">o</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.1.1.1.1.1j" xref="S7.SS2.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.1.1.1.1.13" xref="S7.SS2.p1.1.m1.1.1.1.1.13.cmml">n</mi></mrow><mo id="S7.SS2.p1.1.m1.4.4.4.6" xref="S7.SS2.p1.1.m1.4.4.5.cmml">,</mo><mrow id="S7.SS2.p1.1.m1.2.2.2.2" xref="S7.SS2.p1.1.m1.2.2.2.2.cmml"><mi id="S7.SS2.p1.1.m1.2.2.2.2.2" xref="S7.SS2.p1.1.m1.2.2.2.2.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.2.2.2.2.1" xref="S7.SS2.p1.1.m1.2.2.2.2.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.2.2.2.2.3" xref="S7.SS2.p1.1.m1.2.2.2.2.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.2.2.2.2.1a" xref="S7.SS2.p1.1.m1.2.2.2.2.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.2.2.2.2.4" xref="S7.SS2.p1.1.m1.2.2.2.2.4.cmml">a</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.2.2.2.2.1b" xref="S7.SS2.p1.1.m1.2.2.2.2.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.2.2.2.2.5" xref="S7.SS2.p1.1.m1.2.2.2.2.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.2.2.2.2.1c" xref="S7.SS2.p1.1.m1.2.2.2.2.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.2.2.2.2.6" xref="S7.SS2.p1.1.m1.2.2.2.2.6.cmml">e</mi></mrow><mo id="S7.SS2.p1.1.m1.4.4.4.7" xref="S7.SS2.p1.1.m1.4.4.5.cmml">,</mo><mrow id="S7.SS2.p1.1.m1.3.3.3.3" xref="S7.SS2.p1.1.m1.3.3.3.3.cmml"><mi id="S7.SS2.p1.1.m1.3.3.3.3.2" xref="S7.SS2.p1.1.m1.3.3.3.3.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.3.3.3.3.1" xref="S7.SS2.p1.1.m1.3.3.3.3.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.3.3.3.3.3" xref="S7.SS2.p1.1.m1.3.3.3.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.3.3.3.3.1a" xref="S7.SS2.p1.1.m1.3.3.3.3.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.3.3.3.3.4" xref="S7.SS2.p1.1.m1.3.3.3.3.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.3.3.3.3.1b" xref="S7.SS2.p1.1.m1.3.3.3.3.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.3.3.3.3.5" xref="S7.SS2.p1.1.m1.3.3.3.3.5.cmml">s</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.3.3.3.3.1c" xref="S7.SS2.p1.1.m1.3.3.3.3.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.3.3.3.3.6" xref="S7.SS2.p1.1.m1.3.3.3.3.6.cmml">o</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.3.3.3.3.1d" xref="S7.SS2.p1.1.m1.3.3.3.3.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.3.3.3.3.7" xref="S7.SS2.p1.1.m1.3.3.3.3.7.cmml">n</mi></mrow><mo id="S7.SS2.p1.1.m1.4.4.4.8" xref="S7.SS2.p1.1.m1.4.4.5.cmml">,</mo><mrow id="S7.SS2.p1.1.m1.4.4.4.4" xref="S7.SS2.p1.1.m1.4.4.4.4.cmml"><mi id="S7.SS2.p1.1.m1.4.4.4.4.2" xref="S7.SS2.p1.1.m1.4.4.4.4.2.cmml">W</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.4.4.4.4.1" xref="S7.SS2.p1.1.m1.4.4.4.4.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.4.4.4.4.3" xref="S7.SS2.p1.1.m1.4.4.4.4.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.4.4.4.4.1a" xref="S7.SS2.p1.1.m1.4.4.4.4.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.4.4.4.4.4" xref="S7.SS2.p1.1.m1.4.4.4.4.4.cmml">r</mi><mo lspace="0em" rspace="0em" id="S7.SS2.p1.1.m1.4.4.4.4.1b" xref="S7.SS2.p1.1.m1.4.4.4.4.1.cmml">​</mo><mi id="S7.SS2.p1.1.m1.4.4.4.4.5" xref="S7.SS2.p1.1.m1.4.4.4.4.5.cmml">k</mi></mrow><mo stretchy="false" id="S7.SS2.p1.1.m1.4.4.4.9" xref="S7.SS2.p1.1.m1.4.4.5.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S7.SS2.p1.1.m1.4b"><set id="S7.SS2.p1.1.m1.4.4.5.cmml" xref="S7.SS2.p1.1.m1.4.4.4"><apply id="S7.SS2.p1.1.m1.1.1.1.1.cmml" xref="S7.SS2.p1.1.m1.1.1.1.1"><times id="S7.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="S7.SS2.p1.1.m1.1.1.1.1.1"></times><ci id="S7.SS2.p1.1.m1.1.1.1.1.2.cmml" xref="S7.SS2.p1.1.m1.1.1.1.1.2">𝑂</ci><ci id="S7.SS2.p1.1.m1.1.1.1.1.3.cmml" xref="S7.SS2.p1.1.m1.1.1.1.1.3">𝑟</ci><ci id="S7.SS2.p1.1.m1.1.1.1.1.4.cmml" xref="S7.SS2.p1.1.m1.1.1.1.1.4">𝑔</ci><ci id="S7.SS2.p1.1.m1.1.1.1.1.5.cmml" xref="S7.SS2.p1.1.m1.1.1.1.1.5">𝑎</ci><ci id="S7.SS2.p1.1.m1.1.1.1.1.6.cmml" xref="S7.SS2.p1.1.m1.1.1.1.1.6">𝑛</ci><ci id="S7.SS2.p1.1.m1.1.1.1.1.7.cmml" xref="S7.SS2.p1.1.m1.1.1.1.1.7">𝑖</ci><ci id="S7.SS2.p1.1.m1.1.1.1.1.8.cmml" xref="S7.SS2.p1.1.m1.1.1.1.1.8">𝑠</ci><ci id="S7.SS2.p1.1.m1.1.1.1.1.9.cmml" xref="S7.SS2.p1.1.m1.1.1.1.1.9">𝑎</ci><ci id="S7.SS2.p1.1.m1.1.1.1.1.10.cmml" xref="S7.SS2.p1.1.m1.1.1.1.1.10">𝑡</ci><ci id="S7.SS2.p1.1.m1.1.1.1.1.11.cmml" xref="S7.SS2.p1.1.m1.1.1.1.1.11">𝑖</ci><ci id="S7.SS2.p1.1.m1.1.1.1.1.12.cmml" xref="S7.SS2.p1.1.m1.1.1.1.1.12">𝑜</ci><ci id="S7.SS2.p1.1.m1.1.1.1.1.13.cmml" xref="S7.SS2.p1.1.m1.1.1.1.1.13">𝑛</ci></apply><apply id="S7.SS2.p1.1.m1.2.2.2.2.cmml" xref="S7.SS2.p1.1.m1.2.2.2.2"><times id="S7.SS2.p1.1.m1.2.2.2.2.1.cmml" xref="S7.SS2.p1.1.m1.2.2.2.2.1"></times><ci id="S7.SS2.p1.1.m1.2.2.2.2.2.cmml" xref="S7.SS2.p1.1.m1.2.2.2.2.2">𝑃</ci><ci id="S7.SS2.p1.1.m1.2.2.2.2.3.cmml" xref="S7.SS2.p1.1.m1.2.2.2.2.3">𝑙</ci><ci id="S7.SS2.p1.1.m1.2.2.2.2.4.cmml" xref="S7.SS2.p1.1.m1.2.2.2.2.4">𝑎</ci><ci id="S7.SS2.p1.1.m1.2.2.2.2.5.cmml" xref="S7.SS2.p1.1.m1.2.2.2.2.5">𝑐</ci><ci id="S7.SS2.p1.1.m1.2.2.2.2.6.cmml" xref="S7.SS2.p1.1.m1.2.2.2.2.6">𝑒</ci></apply><apply id="S7.SS2.p1.1.m1.3.3.3.3.cmml" xref="S7.SS2.p1.1.m1.3.3.3.3"><times id="S7.SS2.p1.1.m1.3.3.3.3.1.cmml" xref="S7.SS2.p1.1.m1.3.3.3.3.1"></times><ci id="S7.SS2.p1.1.m1.3.3.3.3.2.cmml" xref="S7.SS2.p1.1.m1.3.3.3.3.2">𝑃</ci><ci id="S7.SS2.p1.1.m1.3.3.3.3.3.cmml" xref="S7.SS2.p1.1.m1.3.3.3.3.3">𝑒</ci><ci id="S7.SS2.p1.1.m1.3.3.3.3.4.cmml" xref="S7.SS2.p1.1.m1.3.3.3.3.4">𝑟</ci><ci id="S7.SS2.p1.1.m1.3.3.3.3.5.cmml" xref="S7.SS2.p1.1.m1.3.3.3.3.5">𝑠</ci><ci id="S7.SS2.p1.1.m1.3.3.3.3.6.cmml" xref="S7.SS2.p1.1.m1.3.3.3.3.6">𝑜</ci><ci id="S7.SS2.p1.1.m1.3.3.3.3.7.cmml" xref="S7.SS2.p1.1.m1.3.3.3.3.7">𝑛</ci></apply><apply id="S7.SS2.p1.1.m1.4.4.4.4.cmml" xref="S7.SS2.p1.1.m1.4.4.4.4"><times id="S7.SS2.p1.1.m1.4.4.4.4.1.cmml" xref="S7.SS2.p1.1.m1.4.4.4.4.1"></times><ci id="S7.SS2.p1.1.m1.4.4.4.4.2.cmml" xref="S7.SS2.p1.1.m1.4.4.4.4.2">𝑊</ci><ci id="S7.SS2.p1.1.m1.4.4.4.4.3.cmml" xref="S7.SS2.p1.1.m1.4.4.4.4.3">𝑜</ci><ci id="S7.SS2.p1.1.m1.4.4.4.4.4.cmml" xref="S7.SS2.p1.1.m1.4.4.4.4.4">𝑟</ci><ci id="S7.SS2.p1.1.m1.4.4.4.4.5.cmml" xref="S7.SS2.p1.1.m1.4.4.4.4.5">𝑘</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S7.SS2.p1.1.m1.4c">\{Organisation,Place,Person,Work\}</annotation></semantics></math>. Table <a href="#S7.T6" title="Table 6 ‣ Similarity ‣ 7.1. Robustness to example tables ‣ 7. Ablation Study ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows the summarized results of the experiments with reduced label set. We observe that except for the Llama2 model, the overall performance of the rest of the models did not improve. Nevertheless, a comparison on a class level between the results on the reduced label dataset with and without any examples, demonstrates the increased ability of the model to correctly identify instances of the given classes. Even though the model still misclassifies instances of class <span id="S7.SS2.p1.1.1" class="ltx_text ltx_font_italic">Organization</span> as class <span id="S7.SS2.p1.1.2" class="ltx_text ltx_font_italic">Place</span>, the overall number of identified instances per class is doubled.</p>
</div>
<figure id="S7.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S7.F9.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.04577/assets/figures/cm_gpt-35-turbo-16k_0_bar_final.png" id="S7.F9.1.g1" class="ltx_graphics ltx_img_landscape" width="598" height="449" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S7.F9.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2403.04577/assets/figures/cm_gpt-35-turbo-16k_3_bar_False_final.png" id="S7.F9.2.g1" class="ltx_graphics ltx_img_landscape" width="598" height="449" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S7.F9.4.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>. </span><span id="S7.F9.5.2" class="ltx_text" style="font-size:90%;">GPT-3.5-turbo class-wise result on the reduced label set</span></figcaption>
</figure>
</section>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8. </span>Qualitative analysis</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">We do further analysis on the LLMs generated output to gain a better understanding of the model’s performance.</p>
</div>
<section id="S8.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.1. </span>Output Format Errors</h3>

<div id="S8.SS1.p1" class="ltx_para">
<p id="S8.SS1.p1.1" class="ltx_p">It is often the case that we could not correctly process the output from the model because of its size. Indeed, for tables with many entities, the output of the model exceeds the size limit of the generated text. We notice that for such tables, the completion of the prompt is stopped abruptly. We have identified a subset of <math id="S8.SS1.p1.1.m1.1" class="ltx_Math" alttext="15" display="inline"><semantics id="S8.SS1.p1.1.m1.1a"><mn id="S8.SS1.p1.1.m1.1.1" xref="S8.SS1.p1.1.m1.1.1.cmml">15</mn><annotation-xml encoding="MathML-Content" id="S8.SS1.p1.1.m1.1b"><cn type="integer" id="S8.SS1.p1.1.m1.1.1.cmml" xref="S8.SS1.p1.1.m1.1.1">15</cn></annotation-xml><annotation encoding="application/x-tex" id="S8.SS1.p1.1.m1.1c">15</annotation></semantics></math> tables for which we are unable to parse the output and they are not included in the evaluation.</p>
</div>
<div id="S8.SS1.p2" class="ltx_para">
<p id="S8.SS1.p2.1" class="ltx_p">The output from the Llama2 model was especially challenging to process. Firstly, because the output always included the full input prompt. Secondly, for some tables, the model abruptly stops generating the NERs and instead outputs ”\n” until it fills the context window, or it randomly repeats the last extracted NERs. Therefore, we had to process the output files in order to extract the annotated entities and evaluate the model’s performance. During the processing, we removed the input prompt and we removed the special characters as ”\n”.</p>
</div>
<div id="S8.SS1.p3" class="ltx_para">
<p id="S8.SS1.p3.1" class="ltx_p">Additionally, sometimes instead of following the instructions for the output, the model hallucinates and outputs not recognizable text or code that can be used for recognizing entities in the table. This kind of output is completely skipped and not considered in the evaluation.</p>
</div>
</section>
<section id="S8.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.2. </span>Errors in Cell and Span Position</h3>

<div id="S8.SS2.p1" class="ltx_para">
<p id="S8.SS2.p1.1" class="ltx_p">Initially, we conducted experiments with tables represented in csv format, comma delimited. This representation caused confusion for the LLMs, as it was difficult to estimate if entities separated by comma were in the same cell. Therefore, we changed the table representation to be bar delimited, as shown in the example in Figure <a href="#S5.F7" title="Figure 7 ‣ 5.1. Input Prompt ‣ 5. Table NER with LLMs ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, and with that we noticed that the models made fewer predictions with wrong cell positions.</p>
</div>
<div id="S8.SS2.p2" class="ltx_para">
<p id="S8.SS2.p2.1" class="ltx_p">To assess the errors in cell position, we count the instances where entities have the correct span and label but are located in different cells compared to the ground truth. Our analysis reveals that less than 20% of the erroneous predictions across the GPT models are from inaccuracies in cell positioning. For the LLama2 model, this figure rises to 36% of incorrect predictions. In contrast, errors in predicting span positions are considerably less. Specifically, in less than 1% of the incorrect predictions the model correctly identifies the cell position and label but misjudges either the beginning or end of the span.</p>
</div>
</section>
<section id="S8.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">8.3. </span>Errors in Type Prediction</h3>

<div id="S8.SS3.p1" class="ltx_para">
<p id="S8.SS3.p1.1" class="ltx_p">We observe that another common mistake of the LLMs is to assign a too specific type for an entity. For example, the GPT-instruct model recognizes the entity ”Football” as <span id="S8.SS3.p1.1.1" class="ltx_text ltx_font_italic">Sports</span>, instead of as <span id="S8.SS3.p1.1.2" class="ltx_text ltx_font_italic">Activity</span>. Even though this assignment is not wrong, the entity type <span id="S8.SS3.p1.1.3" class="ltx_text ltx_font_italic">Sports</span> is not included in the types given in the instruction part.
Table <a href="#S8.T7" title="Table 7 ‣ 8.3. Errors in Type Prediction ‣ 8. Qualitative analysis ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows an example of predicted entity types by the GPT-4 model and the GPT-instruct model in the case of zero-shot evaluation. The GPT-instruct model hallucinates more often and assigns more specific entity types then the types given in the instruction. However, it also invents entity types which are not specific types such as <span id="S8.SS3.p1.1.4" class="ltx_text ltx_font_italic">Edition, Founded</span> and <span id="S8.SS3.p1.1.5" class="ltx_text ltx_font_italic">Schools included</span>. On the other hand, the GPT-4 model mostly uses only the given types for annotation and invented only <math id="S8.SS3.p1.1.m1.1" class="ltx_Math" alttext="2" display="inline"><semantics id="S8.SS3.p1.1.m1.1a"><mn id="S8.SS3.p1.1.m1.1.1" xref="S8.SS3.p1.1.m1.1.1.cmml">2</mn><annotation-xml encoding="MathML-Content" id="S8.SS3.p1.1.m1.1b"><cn type="integer" id="S8.SS3.p1.1.m1.1.1.cmml" xref="S8.SS3.p1.1.m1.1.1">2</cn></annotation-xml><annotation encoding="application/x-tex" id="S8.SS3.p1.1.m1.1c">2</annotation></semantics></math> more specific type, <span id="S8.SS3.p1.1.6" class="ltx_text ltx_font_italic">Genre</span> and <span id="S8.SS3.p1.1.7" class="ltx_text ltx_font_italic">Job</span>.</p>
</div>
<div id="S8.SS3.p2" class="ltx_para">
<p id="S8.SS3.p2.2" class="ltx_p">Similarly, the Llama2 model often assigns very specific types. In the zero-shot setting, it had predicted <math id="S8.SS3.p2.1.m1.1" class="ltx_Math" alttext="123" display="inline"><semantics id="S8.SS3.p2.1.m1.1a"><mn id="S8.SS3.p2.1.m1.1.1" xref="S8.SS3.p2.1.m1.1.1.cmml">123</mn><annotation-xml encoding="MathML-Content" id="S8.SS3.p2.1.m1.1b"><cn type="integer" id="S8.SS3.p2.1.m1.1.1.cmml" xref="S8.SS3.p2.1.m1.1.1">123</cn></annotation-xml><annotation encoding="application/x-tex" id="S8.SS3.p2.1.m1.1c">123</annotation></semantics></math> different entity types. However, with the 3-shot examples, sampled by similarity, this number is reduced to <math id="S8.SS3.p2.2.m2.1" class="ltx_Math" alttext="54" display="inline"><semantics id="S8.SS3.p2.2.m2.1a"><mn id="S8.SS3.p2.2.m2.1.1" xref="S8.SS3.p2.2.m2.1.1.cmml">54</mn><annotation-xml encoding="MathML-Content" id="S8.SS3.p2.2.m2.1b"><cn type="integer" id="S8.SS3.p2.2.m2.1.1.cmml" xref="S8.SS3.p2.2.m2.1.1">54</cn></annotation-xml><annotation encoding="application/x-tex" id="S8.SS3.p2.2.m2.1c">54</annotation></semantics></math> entity types.</p>
</div>
<figure id="S8.T7" class="ltx_table">
<table id="S8.T7.2" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S8.T7.2.1.1" class="ltx_tr">
<th id="S8.T7.2.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S8.T7.2.1.1.1.1" class="ltx_text ltx_font_bold">Model</span></th>
<td id="S8.T7.2.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S8.T7.2.1.1.2.1" class="ltx_text ltx_font_bold">Predicted Types</span></td>
</tr>
<tr id="S8.T7.2.2.2" class="ltx_tr">
<th id="S8.T7.2.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S8.T7.2.2.2.1.1" class="ltx_text">GPT-4</span></th>
<td id="S8.T7.2.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Activity, Architectural Structure, Event, <span id="S8.T7.2.2.2.2.1" class="ltx_text" style="color:#FF3333;">Genre</span>
</td>
</tr>
<tr id="S8.T7.2.3.3" class="ltx_tr">
<th id="S8.T7.2.3.3.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<td id="S8.T7.2.3.3.2" class="ltx_td ltx_align_left ltx_border_r">
<span id="S8.T7.2.3.3.2.1" class="ltx_text" style="color:#FF3333;">Job</span>, MISC, Organization, Person, Place, Work</td>
</tr>
<tr id="S8.T7.2.4.4" class="ltx_tr">
<th id="S8.T7.2.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S8.T7.2.4.4.1.1" class="ltx_text">GPT-instruct</span></th>
<td id="S8.T7.2.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Activity, <span id="S8.T7.2.4.4.2.1" class="ltx_text" style="color:#FF3333;">Administration borough, Aircraft</span>,</td>
</tr>
<tr id="S8.T7.2.5.5" class="ltx_tr">
<th id="S8.T7.2.5.5.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<td id="S8.T7.2.5.5.2" class="ltx_td ltx_align_left ltx_border_r">Architectural Structure, <span id="S8.T7.2.5.5.2.1" class="ltx_text" style="color:#FF3333;">Album, Band, Capacity</span>
</td>
</tr>
<tr id="S8.T7.2.6.6" class="ltx_tr">
<th id="S8.T7.2.6.6.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<td id="S8.T7.2.6.6.2" class="ltx_td ltx_align_left ltx_border_r"><span id="S8.T7.2.6.6.2.1" class="ltx_text" style="color:#FF3333;">Centre of administration, Conference name,</span></td>
</tr>
<tr id="S8.T7.2.7.7" class="ltx_tr">
<th id="S8.T7.2.7.7.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<td id="S8.T7.2.7.7.2" class="ltx_td ltx_align_left ltx_border_r">
<span id="S8.T7.2.7.7.2.1" class="ltx_text" style="color:#FF3333;">Country, Date, Dates, Edition, Episode</span>, Event,</td>
</tr>
<tr id="S8.T7.2.8.8" class="ltx_tr">
<th id="S8.T7.2.8.8.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<td id="S8.T7.2.8.8.2" class="ltx_td ltx_align_left ltx_border_r">
<span id="S8.T7.2.8.8.2.1" class="ltx_text" style="color:#FF3333;">Genre, Home city</span>, Job, MISC, Organisation,</td>
</tr>
<tr id="S8.T7.2.9.9" class="ltx_tr">
<th id="S8.T7.2.9.9.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<td id="S8.T7.2.9.9.2" class="ltx_td ltx_align_left ltx_border_r">
<span id="S8.T7.2.9.9.2.1" class="ltx_text" style="color:#FF3333;">Other towns, villages and settlements</span>, Person,</td>
</tr>
<tr id="S8.T7.2.10.10" class="ltx_tr">
<th id="S8.T7.2.10.10.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<td id="S8.T7.2.10.10.2" class="ltx_td ltx_align_left ltx_border_r">Place, <span id="S8.T7.2.10.10.2.1" class="ltx_text" style="color:#FF3333;">Race team, Result, Schools included, Score</span>
</td>
</tr>
<tr id="S8.T7.2.11.11" class="ltx_tr">
<th id="S8.T7.2.11.11.1" class="ltx_td ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r"></th>
<td id="S8.T7.2.11.11.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r">
<span id="S8.T7.2.11.11.2.1" class="ltx_text" style="color:#FF3333;">Sports, Stadium, Team, Time, Tribe,</span> Work, <span id="S8.T7.2.11.11.2.2" class="ltx_text" style="color:#FF3333;">Year</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S8.T7.3.1.1" class="ltx_text" style="font-size:90%;">Table 7</span>. </span><span id="S8.T7.4.2" class="ltx_text" style="font-size:90%;">Predicted entity types</span></figcaption>
</figure>
<div id="S8.SS3.p3" class="ltx_para">
<p id="S8.SS3.p3.1" class="ltx_p">To better understand the misclassifications of the models, we also calculate the confusion matrix for the predictions. All the predicted types which are not part of the instruction, are represented as type <span id="S8.SS3.p3.1.1" class="ltx_text ltx_font_italic">MISC</span>. We show the confusion matrix of the GPT-instruct model with 0-shot examples in Figure <a href="#S8.F10" title="Figure 10 ‣ 8.3. Errors in Type Prediction ‣ 8. Qualitative analysis ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>. The last row of the matrix is with zeros because we do not include any entities without labels in the ground truth. The last column of the matrix represents the number of entities per class that were classified as an unknown type (<span id="S8.SS3.p3.1.2" class="ltx_text ltx_font_italic">MISC</span>). We observe that the highest number of miss classification is for the entities of type <span id="S8.SS3.p3.1.3" class="ltx_text ltx_font_italic">Organization</span>; these instances are either misclassified as type <span id="S8.SS3.p3.1.4" class="ltx_text ltx_font_italic">Place</span> or as some other, unspecified type <span id="S8.SS3.p3.1.5" class="ltx_text ltx_font_italic">MISC</span>.</p>
</div>
<figure id="S8.F10" class="ltx_figure"><img src="/html/2403.04577/assets/figures/cm_574_gpt-35-turbo-instruct_0_bar_True_fixed.png" id="S8.F10.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="502" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S8.F10.2.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>. </span><span id="S8.F10.3.2" class="ltx_text" style="font-size:90%;">Confusion Matrix - GPT-instruct zero-shot</span></figcaption>
</figure>
</section>
</section>
<section id="S9" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">9. </span>Limitations</h2>

<div id="S9.p1" class="ltx_para">
<p id="S9.p1.1" class="ltx_p">We now discuss certain limitations inherent in the proposed dataset, as well as the challenges we encounter when solving the task of NER in tables using LLMs.</p>
</div>
<section id="S9.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">9.1. </span>Data quality issues</h3>

<div id="S9.SS1.p1" class="ltx_para">
<p id="S9.SS1.p1.1" class="ltx_p">The qualitative analysis of the LLMs output helped us gain insights into the shortcomings of the proposed Wiki-TabNER dataset.</p>
</div>
<div id="S9.SS1.p2" class="ltx_para">
<p id="S9.SS1.p2.1" class="ltx_p">One issue identified is the datasets’ lack of annotations. As illustrated in Figure <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, there are certain entity mentions which have Wikipedia links, but we fail to find their entity type, so these are labeled as 0. Remarkably, we noticed that the LLMs consistently assign correct labels to such entities. For instance, entities like ”Astor Piazzola,” ”Antonio Carlos Jobim,” and ”John Powell” are accurately identified by all GPT models and labeled as <span id="S9.SS1.p2.1.1" class="ltx_text ltx_font_italic">Person</span>.</p>
</div>
<div id="S9.SS1.p3" class="ltx_para">
<p id="S9.SS1.p3.1" class="ltx_p">Another observed challenge is the existence of ambiguous entities, where multiple annotations are possible. This ambiguity often arises between entities categorized as <span id="S9.SS1.p3.1.1" class="ltx_text ltx_font_italic">Activity</span> and <span id="S9.SS1.p3.1.2" class="ltx_text ltx_font_italic">Event</span>. These are entities such as ”Winter Olympic Games 2010” or ”2011 Cannes Festival” which in different context can be an instance of both of the classes. On the one hand, since these involve various activities, such as sports competitions or film screenings, they can be viewed as an instance of the class <span id="S9.SS1.p3.1.3" class="ltx_text ltx_font_italic">Activity</span>. On the other hand, these are particular events with a particular duration. Thus, it can be difficult to define a label for such entities.</p>
</div>
<div id="S9.SS1.p4" class="ltx_para">
<p id="S9.SS1.p4.1" class="ltx_p">Lastly, the annotations in the Wiki-TabNER dataset represent the most general class. We made this decision to avoid numerous small classes that could hinder the fine-tuning of transformer models which require larger train and test sets. Nevertheless, the LLMs showed to be capable of detecting the more fine-grained entity types.</p>
</div>
<div id="S9.SS1.p5" class="ltx_para">
<p id="S9.SS1.p5.1" class="ltx_p">Regardless of these limitations, the Wiki-TabNER dataset is sufficiently challenging for the new LLMs and a good starting point for evaluating the NER task in tables.</p>
</div>
</section>
<section id="S9.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">9.2. </span>Limitations of LLMs</h3>

<div id="S9.SS2.p1" class="ltx_para">
<p id="S9.SS2.p1.1" class="ltx_p">Despite the fact that LLMs are capable of solving different NLP tasks <cite class="ltx_cite ltx_citemacro_citep">(Brown et al<span class="ltx_text">.</span>, <a href="#bib.bib5" title="" class="ltx_ref">2020</a>; Wang et al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2022a</a>, <a href="#bib.bib34" title="" class="ltx_ref">b</a>; Chen et al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2023</a>)</cite>, there are some challenges that we encounter when using them for solving the table NER problem.</p>
</div>
<div id="S9.SS2.p2" class="ltx_para">
<p id="S9.SS2.p2.1" class="ltx_p">Due to the limited information about the datasets used during the training of these models, we cannot be sure that the models have not already seen the test tables. Even though the task of table NER is novel to these models, we need to further investigate how much knowledge they have about the tables in the dataset.</p>
</div>
<div id="S9.SS2.p3" class="ltx_para">
<p id="S9.SS2.p3.1" class="ltx_p">Another challenge is the parsing of the generated text from the models. The output is not always structured as in the instruction part of the prompt and it may require heavy post-processing in order to extract the generated NERs.</p>
</div>
<div id="S9.SS2.p4" class="ltx_para">
<p id="S9.SS2.p4.1" class="ltx_p">Finally, we also encountered the known problem of hallucinations that these models exhibit. In the beginning, we had issues structuring the input prompt so that we minimize such hallucinations. It was often the case that the model would generate code on how to do programatically the extraction of NERs, or to generate more rows in the table than what we have in the input table.</p>
</div>
</section>
</section>
<section id="S10" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">10. </span>Discussion</h2>

<div id="S10.p1" class="ltx_para">
<p id="S10.p1.1" class="ltx_p">In this paper we presented a novel dataset for the evaluation of table NER and EL in tables. We motivated the need for a new dataset with the provided analysis on the existing benchmark dataset. The analysis showed that complex tables are overlooked and even simplified to facilitate easier evaluation of the EL task.</p>
</div>
<div id="S10.p2" class="ltx_para">
<p id="S10.p2.1" class="ltx_p">The proposed Wiki-TabNER dataset, comprises a set of complex tables annotated with named entity types.
We conducted an evaluation of LLMs using this new dataset to demonstrate the challenging nature of the table NER task.</p>
</div>
<div id="S10.p3" class="ltx_para">
<p id="S10.p3.1" class="ltx_p">Our results showed that in the zero-shot evaluation, all of the models performed poorly. A surprising result is the better performance of the GPT-instruct model compared to its successor, the GPT-4 model. The class-wise analysis shown in Figure <a href="#S6.F8" title="Figure 8 ‣ 6.3. Results ‣ 6. Evaluation ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> demonstrated that the GPT-instruct model is better at correctly predicting instances of types <span id="S10.p3.1.1" class="ltx_text ltx_font_italic">Organization, Architectural Structure, and Person</span> compared to its successor. This might be due to the fact that this model is optimized for instruction following, while the GPT-4 model is more tuned towards chat completion, which may lead to more hallucinations.</p>
</div>
<div id="S10.p4" class="ltx_para">
<p id="S10.p4.1" class="ltx_p">We demonstrated that adding few-shot examples to the input prompt helps improve the performance of the models. However, with the similarity-based sampling of examples, the models had showed significant improvement of F1 score (for GPT-4, improvement from 0.41 to 0.74). Interestingly, presenting randomly sampled tables in the input prompt did not bring any change in the score, which suggests that the models already can recognize the cell structure of the tables and the examples of other tables did not help them. This observation was also supported by the low percentage of errors due to incorrect cell positions. However, without seeing similar entities in the few-shot examples, the LLMs have trouble assigning the correct entity types to the identified entity mentions. Showing how similar entities are annotated in the examples helped the model’s performance improve.</p>
</div>
<div id="S10.p5" class="ltx_para">
<p id="S10.p5.1" class="ltx_p">The evaluation with the reduced label set did not bring significant improvement, which indicates that the instances of the smaller classes are not the issue for these models.</p>
</div>
<div id="S10.p6" class="ltx_para">
<p id="S10.p6.1" class="ltx_p">During the evaluation, we faced the challenge of limiting hallucinations and correctly parsing the output of the models. The comparison of the execution time between the models and the similar performance in terms of F1 scores between the GPT-instruct and GPT-4 models, suggest that using the more expensive GPT-4 model for solving table NER does not bring justifiable improvement.</p>
</div>
<div id="S10.p7" class="ltx_para">
<p id="S10.p7.1" class="ltx_p">As shown in Table <a href="#S6.T3" title="Table 3 ‣ 6.3. Results ‣ 6. Evaluation ‣ Wiki-TabNER:Advancing Table Interpretation Through Named Entity Recognition" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> the GPT-4 model has the drawback of a long execution time. It takes 10 times longer to finish the experiments compared to the GPT-3.5-turbo model and it also comes at a higher cost per generated token.</p>
</div>
<div id="S10.p8" class="ltx_para">
<p id="S10.p8.1" class="ltx_p">Our qualitative analysis of the evaluation emphasized the need for future improvement both on the dataset and the model side.</p>
</div>
</section>
<section id="S11" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">11. </span>Conclusion</h2>

<div id="S11.p1" class="ltx_para">
<p id="S11.p1.1" class="ltx_p">Recognizing the complexity of the tables in the real world and using more challenging dataset for solving TI tasks is essential. This is because employing a more complex dataset not only reflects real-world scenarios more accurately, but also ensures that models are robust and effective in handling complex table structures. We demonstrated that using a more complex dataset requires the accurate recognition of NER in tables before addressing the other tasks. Our evaluation showed that NER within tables is a challenging task even for the state-of-the-art LLMs. A solution to the NER in tables is the first step towards achieving a complete and correct information extraction from tables.</p>
</div>
<div id="S11.p2" class="ltx_para">
<p id="S11.p2.1" class="ltx_p">As future work, we aim to extend the evaluation to the entity linking task using the proposed dataset. Additional effort work on extending the Wiki-TabNER dataset and improving the NER annotations is also needed. Another interesting continuation is to evaluate if the LLMs have seen the tables during training.
We release the proposed dataset, alongside the evaluation framework for LLMs online. We hope we can stimulate interest in future research on the topic of table NER and facilitate these endeavors with the proposed dataset.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arik and Pfister (2021)</span>
<span class="ltx_bibblock">
Sercan Ö. Arik and Tomas Pfister. 2021.

</span>
<span class="ltx_bibblock">TabNet: Attentive Interpretable Tabular Learning. In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021, Thirty-Third Conference on Innovative Applications of Artificial Intelligence, IAAI 2021, The Eleventh Symposium on Educational Advances in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9, 2021</em>. AAAI Press, 6679–6687.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1609/AAAI.V35I8.16826" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1609/AAAI.V35I8.16826</a>

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhagavatula et al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Chandra Sekhar Bhagavatula, Thanapon Noraset, and Doug Downey. 2015.

</span>
<span class="ltx_bibblock">TabEL: Entity Linking in Web Tables. In <em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">The Semantic Web - ISWC 2015</em>, Marcelo Arenas, Oscar Corcho, Elena Simperl, Markus Strohmaier, Mathieu d’Aquin, Kavitha Srinivas, Paul Groth, Michel Dumontier, Jeff Heflin, Krishnaprasad Thirunarayan, Krishnaprasad Thirunarayan, and Steffen Staab (Eds.). Springer International Publishing, Cham, 425–441.

</span>
<span class="ltx_bibblock">

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bizer et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2009)</span>
<span class="ltx_bibblock">
Christian Bizer, Jens Lehmann, Georgi Kobilarov, Sören Auer, Christian Becker, Richard Cyganiak, and Sebastian Hellmann. 2009.

</span>
<span class="ltx_bibblock">DBpedia - A crystallization point for the Web of Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">Journal of Web Semantics</em> 7, 3 (2009), 154–165.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/j.websem.2009.07.002" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.websem.2009.07.002</a>

</span>
<span class="ltx_bibblock">The Web of Data.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,
and Dario Amodei. 2020.

</span>
<span class="ltx_bibblock">Language Models are Few-Shot Learners. In <em id="bib.bib5.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual</em>, Hugo Larochelle, Marc’Aurelio Ranzato, Raia Hadsell, Maria-Florina Balcan, and Hsuan-Tien Lin (Eds.).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2020/hash/1457c0d6bfcb4967418bfb8ac142f64a-Abstract.html</a>

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cafarella et al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2008)</span>
<span class="ltx_bibblock">
Michael J. Cafarella, Alon Y. Halevy, Daisy Zhe Wang, Eugene Wu, and Yang Zhang. 2008.

</span>
<span class="ltx_bibblock">WebTables: exploring the power of tables on the web.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.3.1" class="ltx_emph ltx_font_italic">Proc. VLDB Endow.</em> 1, 1 (2008), 538–549.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.14778/1453856.1453916" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.14778/1453856.1453916</a>

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Jiaoyan Chen, Ernesto Jimenez-Ruiz, Ian Horrocks, and Charles Sutton. 2019.

</span>
<span class="ltx_bibblock">Learning Semantic Annotations for Tabular Data.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1906.00781 [cs.DB]

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Yanru Chen, Yanan Zheng, and Zhilin Yang. 2023.

</span>
<span class="ltx_bibblock">Prompt-Based Metric Learning for Few-Shot NER. In <em id="bib.bib8.3.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023</em>, Anna Rogers, Jordan L. Boyd-Graber, and Naoaki Okazaki (Eds.). Association for Computational Linguistics, 7199–7212.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/V1/2023.FINDINGS-ACL.451" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/V1/2023.FINDINGS-ACL.451</a>

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Das et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Sarkar Snigdha Sarathi Das, Arzoo Katiyar, Rebecca J. Passonneau, and Rui Zhang. 2022.

</span>
<span class="ltx_bibblock">CONTaiNER: Few-Shot Named Entity Recognition via Contrastive Learning. In <em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27, 2022</em>, Smaranda Muresan, Preslav Nakov, and Aline Villavicencio (Eds.). Association for Computational Linguistics, 6338–6353.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/V1/2022.ACL-LONG.439" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/V1/2022.ACL-LONG.439</a>

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Xiang Deng, Huan Sun, Alyssa Lees, You Wu, and Cong Yu. 2020.

</span>
<span class="ltx_bibblock">TURL: Table Understanding through Representation Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">Proc. VLDB Endow.</em> 14, 3 (2020), 307–319.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.5555/3430915.3442430" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.5555/3430915.3442430</a>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin et al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019.

</span>
<span class="ltx_bibblock">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In <em id="bib.bib11.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers)</em>, Jill Burstein, Christy Doran, and Thamar Solorio (Eds.). Association for Computational Linguistics, 4171–4186.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/V1/N19-1423" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/V1/N19-1423</a>

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Efthymiou et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Vasilis Efthymiou, Oktie Hassanzadeh, Mariano Rodriguez-Muro, and Vassilis Christophides. 2017.

</span>
<span class="ltx_bibblock">Matching Web Tables with Knowledge Base Entities: From Entity Lookups to Entity Embeddings. In <em id="bib.bib12.3.1" class="ltx_emph ltx_font_italic">The Semantic Web – ISWC 2017: 16th International Semantic Web Conference, Vienna, Austria, October 21–25, 2017, Proceedings, Part I</em> (Vienna, Austria). Springer-Verlag, Berlin, Heidelberg, 260–277.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1007/978-3-319-68288-4_16" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/978-3-319-68288-4_16</a>

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eisenschlos et al<span id="bib.bib13.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Julian Martin Eisenschlos, Maharshi Gor, Thomas Müller, and William W. Cohen. 2021.

</span>
<span class="ltx_bibblock">MATE: Multi-view Attention for Table Transformer Efficiency. In <em id="bib.bib13.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021</em>, Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih (Eds.). Association for Computational Linguistics, 7606–7619.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/V1/2021.EMNLP-MAIN.600" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/V1/2021.EMNLP-MAIN.600</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gong et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Heng Gong, Yawei Sun, Xiaocheng Feng, Bing Qin, Wei Bi, Xiaojiang Liu, and Ting Liu. 2020a.

</span>
<span class="ltx_bibblock">TableGPT: Few-shot Table-to-Text Generation with Table Structure Reconstruction and Content Matching. In <em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th International Conference on Computational Linguistics</em>. International Committee on Computational Linguistics, Barcelona, Spain (Online), 1978–1988.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/2020.coling-main.179" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2020.coling-main.179</a>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gong et al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Heng Gong, Yawei Sun, Xiaocheng Feng, Bing Qin, Wei Bi, Xiaojiang Liu, and Ting Liu. 2020b.

</span>
<span class="ltx_bibblock">TableGPT: Few-shot Table-to-Text Generation with Table Structure Reconstruction and Content Matching. In <em id="bib.bib15.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 28th International Conference on Computational Linguistics, COLING 2020, Barcelona, Spain (Online), December 8-13, 2020</em>, Donia Scott, Núria Bel, and Chengqing Zong (Eds.). International Committee on Computational Linguistics, 1978–1988.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/V1/2020.COLING-MAIN.179" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/V1/2020.COLING-MAIN.179</a>

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hammerton (2003)</span>
<span class="ltx_bibblock">
James Alistair Hammerton. 2003.

</span>
<span class="ltx_bibblock">Named Entity Recognition with Long Short-Term Memory. In <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Seventh Conference on Natural Language Learning, CoNLL 2003, Held in cooperation with HLT-NAACL 2003, Edmonton, Canada, May 31 - June 1, 2003</em>, Walter Daelemans and Miles Osborne (Eds.). ACL, 172–175.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://aclanthology.org/W03-0426/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aclanthology.org/W03-0426/</a>

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Herzig et al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Jonathan Herzig, Pawel Krzysztof Nowak, Thomas Müller, Francesco Piccinno, and Julian Eisenschlos. 2020.

</span>
<span class="ltx_bibblock">TaPas: Weakly Supervised Table Parsing via Pre-training. In <em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.398" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/v1/2020.acl-main.398</a>

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Iida et al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Hiroshi Iida, Dung Thai, Varun Manjunatha, and Mohit Iyyer. 2021.

</span>
<span class="ltx_bibblock">TABBIE: Pretrained Representations of Tabular Data.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2105.02584 [cs.CL]

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jimenez-Ruiz et al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
E. Jimenez-Ruiz, O. Hassanzadeh, V. Efthymiou, J. Chen, and K. Srinivas. 2020.

</span>
<span class="ltx_bibblock">SemTab 2019: Resources to Benchmark Tabular Data to Knowledge Graph Matching Systems, In The Semantic Web. ESWC 2020.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.3.1" class="ltx_emph ltx_font_italic">The Semantic Web</em>, 514–530.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1007/978-3-030-49461-2_30" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/978-3-030-49461-2_30</a>

</span>
<span class="ltx_bibblock">The final authenticated version is available online at https://doi.org/10.1007/978-3-030-49461-2_30.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Joshi et al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Mandar Joshi, Danqi Chen, Yinhan Liu, Daniel S. Weld, Luke Zettlemoyer, and Omer Levy. 2020.

</span>
<span class="ltx_bibblock">SpanBERT: Improving Pre-training by Representing and Predicting Spans.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">Trans. Assoc. Comput. Linguistics</em> 8 (2020), 64–77.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1162/TACL_A_00300" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1162/TACL_A_00300</a>

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koleva et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Aneta Koleva, Martin Ringsquandl, Mark Buckley, Rakebul Hasan, and Volker Tresp. 2022.

</span>
<span class="ltx_bibblock">Named Entity Recognition in Industrial Tables using Tabular Language Models. In <em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing: EMNLP 2022 - Industry Track, Abu Dhabi, UAE, December 7 - 11, 2022</em>, Yunyao Li and Angeliki Lazaridou (Eds.). Association for Computational Linguistics, 348–356.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/V1/2022.EMNLP-INDUSTRY.35" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/V1/2022.EMNLP-INDUSTRY.35</a>

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lample et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Guillaume Lample, Miguel Ballesteros, Sandeep Subramanian, Kazuya Kawakami, and Chris Dyer. 2016.

</span>
<span class="ltx_bibblock">Neural Architectures for Named Entity Recognition. In <em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">NAACL HLT 2016, The 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, San Diego California, USA, June 12-17, 2016</em>, Kevin Knight, Ani Nenkova, and Owen Rambow (Eds.). The Association for Computational Linguistics, 260–270.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/V1/N16-1030" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/V1/N16-1030</a>

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lehmberg et al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2016a)</span>
<span class="ltx_bibblock">
Oliver Lehmberg, Dominique Ritze, Robert Meusel, and Christian Bizer. 2016a.

</span>
<span class="ltx_bibblock">A Large Public Corpus of Web Tables Containing Time and Context Metadata. In <em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 25th International Conference Companion on World Wide Web</em> (Montréal, Québec, Canada) <em id="bib.bib23.4.2" class="ltx_emph ltx_font_italic">(WWW ’16 Companion)</em>. International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, CHE, 75–76.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2872518.2889386" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2872518.2889386</a>

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lehmberg et al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2016b)</span>
<span class="ltx_bibblock">
Oliver Lehmberg, Dominique Ritze, Robert Meusel, and Christian Bizer. 2016b.

</span>
<span class="ltx_bibblock">A Large Public Corpus of Web Tables Containing Time and Context Metadata. In <em id="bib.bib24.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 25th International Conference Companion on World Wide Web</em> (Montréal, Québec, Canada) <em id="bib.bib24.4.2" class="ltx_emph ltx_font_italic">(WWW ’16 Companion)</em>. International World Wide Web Conferences Steering Committee, Republic and Canton of Geneva, CHE, 75–76.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/2872518.2889386" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/2872518.2889386</a>

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Limaye et al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2010)</span>
<span class="ltx_bibblock">
Girija Limaye, Sunita Sarawagi, and Soumen Chakrabarti. 2010.

</span>
<span class="ltx_bibblock">Annotating and Searching Web Tables Using Entities, Types and Relationships.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.3.1" class="ltx_emph ltx_font_italic">Proc. VLDB Endow.</em> 3, 1 (2010), 1338–1347.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="http://dblp.uni-trier.de/db/journals/pvldb/pvldb3.html#LimayeSC10" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://dblp.uni-trier.de/db/journals/pvldb/pvldb3.html#LimayeSC10</a>

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock">GPT-4 Technical Report.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/2303.08774 (2023).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/ARXIV.2303.08774" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/ARXIV.2303.08774</a>
arXiv:2303.08774

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Raffel et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020.

</span>
<span class="ltx_bibblock">Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.3.1" class="ltx_emph ltx_font_italic">J. Mach. Learn. Res.</em> 21 (2020), 140:1–140:67.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="http://jmlr.org/papers/v21/20-074.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">http://jmlr.org/papers/v21/20-074.html</a>

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ramshaw and Marcus (1995)</span>
<span class="ltx_bibblock">
Lance A. Ramshaw and Mitchell P. Marcus. 1995.

</span>
<span class="ltx_bibblock">Text Chunking using Transformation-Based Learning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:cmp-lg/9505040 [cmp-lg]

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Suchanek et al<span id="bib.bib29.2.2.1" class="ltx_text">.</span> (2007)</span>
<span class="ltx_bibblock">
Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007.

</span>
<span class="ltx_bibblock">Yago: A Core of Semantic Knowledge. In <em id="bib.bib29.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 16th International Conference on World Wide Web</em> (Banff, Alberta, Canada) <em id="bib.bib29.4.2" class="ltx_emph ltx_font_italic">(WWW ’07)</em>. Association for Computing Machinery, New York, NY, USA, 697–706.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/1242572.1242667" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/1242572.1242667</a>

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton-Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,
Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen
Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurélien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023.

</span>
<span class="ltx_bibblock">Llama 2: Open Foundation and Fine-Tuned Chat Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/2307.09288 (2023).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/ARXIV.2307.09288" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/ARXIV.2307.09288</a>
arXiv:2307.09288

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaswani et al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017.

</span>
<span class="ltx_bibblock">Attention Is All You Need.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">arXiv e-prints</em>, Article arXiv:1706.03762 (June 2017), arXiv:1706.03762 pages.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/arXiv.1706.03762" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/arXiv.1706.03762</a>
arXiv:1706.03762 [cs.CL]

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vilar et al<span id="bib.bib32.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
David Vilar, Markus Freitag, Colin Cherry, Jiaming Luo, Viresh Ratnakar, and George F. Foster. 2023.

</span>
<span class="ltx_bibblock">Prompting PaLM for Translation: Assessing Strategies and Performance. In <em id="bib.bib32.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023</em>, Anna Rogers, Jordan L. Boyd-Graber, and Naoaki Okazaki (Eds.). Association for Computational Linguistics, 15406–15427.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/V1/2023.ACL-LONG.859" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/V1/2023.ACL-LONG.859</a>

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Chenguang Wang, Xiao Liu, Zui Chen, Haoyun Hong, Jie Tang, and Dawn Song. 2022a.

</span>
<span class="ltx_bibblock">DeepStruct: Pretraining of Language Models for Structure Prediction. In <em id="bib.bib33.3.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: ACL 2022, Dublin, Ireland, May 22-27, 2022</em>, Smaranda Muresan, Preslav Nakov, and Aline Villavicencio (Eds.). Association for Computational Linguistics, 803–823.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/V1/2022.FINDINGS-ACL.67" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/V1/2022.FINDINGS-ACL.67</a>

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Peiyi Wang, Runxin Xu, Tianyu Liu, Qingyu Zhou, Yunbo Cao, Baobao Chang, and Zhifang Sui. 2022b.

</span>
<span class="ltx_bibblock">An Enhanced Span-based Decomposition Method for Few-Shot Sequence Labeling. In <em id="bib.bib34.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022, Seattle, WA, United States, July 10-15, 2022</em>, Marine Carpuat, Marie-Catherine de Marneffe, and Iván Vladimir Meza Ruíz (Eds.). Association for Computational Linguistics, 5012–5024.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/V1/2022.NAACL-MAIN.369" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/V1/2022.NAACL-MAIN.369</a>

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2023a)</span>
<span class="ltx_bibblock">
Shuhe Wang, Yuxian Meng, Rongbin Ouyang, Jiwei Li, Tianwei Zhang, Lingjuan Lyu, and Guoyin Wang. 2023a.

</span>
<span class="ltx_bibblock">GNN-SL: Sequence Labeling Based on Nearest Examples via GNN. In <em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">Findings of the Association for Computational Linguistics: ACL 2023, Toronto, Canada, July 9-14, 2023</em>, Anna Rogers, Jordan L. Boyd-Graber, and Naoaki Okazaki (Eds.). Association for Computational Linguistics, 12679–12692.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/V1/2023.FINDINGS-ACL.803" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/V1/2023.FINDINGS-ACL.803</a>

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib36.2.2.1" class="ltx_text">.</span> (2023b)</span>
<span class="ltx_bibblock">
Shuhe Wang, Xiaofei Sun, Xiaoya Li, Rongbin Ouyang, Fei Wu, Tianwei Zhang, Jiwei Li, and Guoyin Wang. 2023b.

</span>
<span class="ltx_bibblock">GPT-NER: Named Entity Recognition via Large Language Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.3.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/2304.10428 (2023).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/ARXIV.2304.10428" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/ARXIV.2304.10428</a>
arXiv:2304.10428

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Zhiruo Wang, Haoyu Dong, Ran Jia, Jia Li, Zhiyi Fu, Shi Han, and Dongmei Zhang. 2020.

</span>
<span class="ltx_bibblock">Structure-aware Pre-training for Table Understanding with Tree-based Transformers.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.3.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/2010.12537 (2020).

</span>
<span class="ltx_bibblock">arXiv:2010.12537

<a target="_blank" href="https://arxiv.org/abs/2010.12537" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2010.12537</a>

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al<span id="bib.bib38.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M. Dai, and Quoc V. Le. 2022.

</span>
<span class="ltx_bibblock">Finetuned Language Models are Zero-Shot Learners. In <em id="bib.bib38.3.1" class="ltx_emph ltx_font_italic">The Tenth International Conference on Learning Representations, ICLR 2022, Virtual Event, April 25-29, 2022</em>. OpenReview.net.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://openreview.net/forum?id=gEZrGCozdqR" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://openreview.net/forum?id=gEZrGCozdqR</a>

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al<span id="bib.bib39.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Tianbao Xie, Chen Henry Wu, Peng Shi, Ruiqi Zhong, Torsten Scholak, Michihiro Yasunaga, Chien-Sheng Wu, Ming Zhong, Pengcheng Yin, Sida I. Wang, Victor Zhong, Bailin Wang, Chengzu Li, Connor Boyle, Ansong Ni, Ziyu Yao, Dragomir Radev, Caiming Xiong, Lingpeng Kong, Rui Zhang, Noah A. Smith, Luke Zettlemoyer, and Tao Yu. 2022.

</span>
<span class="ltx_bibblock">UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2201.05966 [cs.CL]

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al<span id="bib.bib40.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Pengcheng Yin, Graham Neubig, Wen-tau Yih, and Sebastian Riedel. 2020.

</span>
<span class="ltx_bibblock">TaBERT: Pretraining for Joint Understanding of Textual and Tabular Data. In <em id="bib.bib40.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020</em>, Dan Jurafsky, Joyce Chai, Natalie Schluter, and Joel R. Tetreault (Eds.). Association for Computational Linguistics, 8413–8426.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.18653/V1/2020.ACL-MAIN.745" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.18653/V1/2020.ACL-MAIN.745</a>

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zha et al<span id="bib.bib41.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Liangyu Zha, Junlin Zhou, Liyao Li, Rui Wang, Qingyi Huang, Saisai Yang, Jing Yuan, Changbao Su, Xiang Li, Aofeng Su, Tao Zhang, Chen Zhou, Kaizhe Shou, Miao Wang, Wufang Zhu, Guoshan Lu, Chao Ye, Yali Ye, Wentao Ye, Yiming Zhang, Xinglong Deng, Jie Xu, Haobo Wang, Gang Chen, and Junbo Zhao. 2023.

</span>
<span class="ltx_bibblock">TableGPT: Towards Unifying Tables, Nature Language and Commands into One GPT.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.3.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/2307.08674 (2023).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/ARXIV.2307.08674" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/ARXIV.2307.08674</a>
arXiv:2307.08674

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib42.2.2.1" class="ltx_text">.</span> (2023a)</span>
<span class="ltx_bibblock">
Han Zhang, Xumeng Wen, Shun Zheng, Wei Xu, and Jiang Bian. 2023a.

</span>
<span class="ltx_bibblock">Towards Foundation Models for Learning on Tabular Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.3.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/2310.07338 (2023).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/ARXIV.2310.07338" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/ARXIV.2310.07338</a>
arXiv:2310.07338

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib43.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Li Zhang, Shuo Zhang, and Krisztian Balog. 2019.

</span>
<span class="ltx_bibblock">Table2Vec. In <em id="bib.bib43.3.1" class="ltx_emph ltx_font_italic">Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval</em>. ACM.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1145/3331184.3331333" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3331184.3331333</a>

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib44.2.2.1" class="ltx_text">.</span> (2023b)</span>
<span class="ltx_bibblock">
Tianshu Zhang, Xiang Yue, Yifei Li, and Huan Sun. 2023b.

</span>
<span class="ltx_bibblock">TableLlama: Towards Open Large Generalist Models for Tables.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.3.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/2311.09206 (2023).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.48550/ARXIV.2311.09206" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.48550/ARXIV.2311.09206</a>
arXiv:2311.09206

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2403.04576" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2403.04577" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2403.04577">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2403.04577" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2403.04578" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Apr  5 18:28:33 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
