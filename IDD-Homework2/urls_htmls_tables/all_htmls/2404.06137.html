<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2404.06137] SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for Hallucination Detection</title><meta property="og:description" content="In this paper, we present our novel systems developed for the SemEval-2024 hallucination detection task. Our investigation spans a range of strategies to compare model predictions with reference standards, encompassing…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for Hallucination Detection">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for Hallucination Detection">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2404.06137">

<!--Generated on Sun May  5 15:11:57 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for Hallucination Detection</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<span id="id1.1.id1" class="ltx_text ltx_font_bold">Elisei Rykov<sup id="id1.1.id1.1" class="ltx_sup">1,2</sup></span>,   <span id="id2.2.id2" class="ltx_text ltx_font_bold">Yana Shishkina<sup id="id2.2.id2.1" class="ltx_sup">2,3</sup></span>, <span id="id3.3.id3" class="ltx_text ltx_font_bold">Kseniia Petrushina<sup id="id3.3.id3.1" class="ltx_sup">1,4</sup></span> ,
<br class="ltx_break"><span id="id4.4.id4" class="ltx_text ltx_font_bold">Kseniia Titova<sup id="id4.4.id4.1" class="ltx_sup">1,5</sup></span>, <span id="id5.5.id5" class="ltx_text ltx_font_bold">Sergey Petrakov<sup id="id5.5.id5.1" class="ltx_sup">1</sup></span>, <span id="id6.6.id6" class="ltx_text ltx_font_bold">and</span>
<span id="id7.7.id7" class="ltx_text ltx_font_bold">Alexander Panchenko<sup id="id7.7.id7.1" class="ltx_sup">1,6</sup></span> 
<br class="ltx_break"><sup id="id8.8.id8" class="ltx_sup">1</sup>Skolkovo Institute of Science and Technology,
<sup id="id9.9.id9" class="ltx_sup">2</sup>Tinkoff,
<br class="ltx_break"><sup id="id10.10.id10" class="ltx_sup">3</sup>HSE University,
<sup id="id11.11.id11" class="ltx_sup">4</sup>Moscow Institute of Physics and Technology,
<sup id="id12.12.id12" class="ltx_sup">5</sup>MTS AI,
<sup id="id13.13.id13" class="ltx_sup">6</sup>AIRI
<br class="ltx_break"><a href="mailto:e.rykov@tinkoff.ai" title="" class="ltx_ref ltx_href ltx_font_sansserif">{e.rykov, y.a.shishkina}@tinkoff.ai</a>,
<a href="mailto:kseniia.petrushina@skol.tech" title="" class="ltx_ref ltx_href ltx_font_sansserif">{kseniia.petrushina, kseniia.titova, sergey.petrakov, a.panchenko}@skol.tech</a>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id14.id1" class="ltx_p">In this paper, we present our novel systems developed for the SemEval-2024 hallucination detection task. Our investigation spans a range of strategies to compare model predictions with reference standards, encompassing diverse baselines, the refinement of pre-trained encoders through supervised learning, and an ensemble approaches utilizing several high-performing models. Through these explorations, we introduce three distinct methods that exhibit strong performance metrics. To amplify our training data, we generate additional training samples from unlabelled training subset. Furthermore, we provide a detailed comparative analysis of our approaches. Notably, our premier method achieved a commendable 9th place in the competition’s model-agnostic track and 17th place in model-aware track, highlighting its effectiveness and potential.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<div id="p1.1" class="ltx_block ltx_align_bottom">
<p id="p1.1.1" class="ltx_p"><span id="p1.1.1.1" class="ltx_text ltx_font_bold">SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for Hallucination Detection</span></p>
<br class="ltx_break ltx_centering">
<p id="p1.1.2" class="ltx_p ltx_align_center" style="width:433.6pt;"><span id="p1.1.2.1" class="ltx_text ltx_inline-block" style="width:0.0pt;">
<span id="p1.1.2.1.1" class="ltx_tabular ltx_align_top">
<span id="p1.1.2.1.1.1" class="ltx_tr">
<span id="p1.1.2.1.1.1.1" class="ltx_td ltx_align_center"><span id="p1.1.2.1.1.1.1.1" class="ltx_text ltx_font_bold">
Elisei Rykov<sup id="p1.1.2.1.1.1.1.1.1" class="ltx_sup">1,2</sup>,   Yana Shishkina<sup id="p1.1.2.1.1.1.1.1.2" class="ltx_sup">2,3</sup>, Kseniia Petrushina<sup id="p1.1.2.1.1.1.1.1.3" class="ltx_sup">1,4</sup> ,</span></span></span>
<span id="p1.1.2.1.1.2" class="ltx_tr">
<span id="p1.1.2.1.1.2.1" class="ltx_td ltx_align_center"><span id="p1.1.2.1.1.2.1.1" class="ltx_text ltx_font_bold">Kseniia Titova<sup id="p1.1.2.1.1.2.1.1.1" class="ltx_sup">1,5</sup></span>, <span id="p1.1.2.1.1.2.1.2" class="ltx_text ltx_font_bold">Sergey Petrakov<sup id="p1.1.2.1.1.2.1.2.1" class="ltx_sup">1</sup></span>, <span id="p1.1.2.1.1.2.1.3" class="ltx_text ltx_font_bold">and</span>
<span id="p1.1.2.1.1.2.1.4" class="ltx_text ltx_font_bold">Alexander Panchenko<sup id="p1.1.2.1.1.2.1.4.1" class="ltx_sup">1,6</sup></span></span></span>
<span id="p1.1.2.1.1.3" class="ltx_tr">
<span id="p1.1.2.1.1.3.1" class="ltx_td ltx_align_center"><sup id="p1.1.2.1.1.3.1.1" class="ltx_sup">1</sup>Skolkovo Institute of Science and Technology,
<sup id="p1.1.2.1.1.3.1.2" class="ltx_sup">2</sup>Tinkoff,</span></span>
<span id="p1.1.2.1.1.4" class="ltx_tr">
<span id="p1.1.2.1.1.4.1" class="ltx_td ltx_align_center"><sup id="p1.1.2.1.1.4.1.1" class="ltx_sup">3</sup>HSE University,
<sup id="p1.1.2.1.1.4.1.2" class="ltx_sup">4</sup>Moscow Institute of Physics and Technology,
<sup id="p1.1.2.1.1.4.1.3" class="ltx_sup">5</sup>MTS AI,
<sup id="p1.1.2.1.1.4.1.4" class="ltx_sup">6</sup>AIRI</span></span>
<span id="p1.1.2.1.1.5" class="ltx_tr">
<span id="p1.1.2.1.1.5.1" class="ltx_td ltx_align_center"><a href="mailto:e.rykov@tinkoff.ai" title="" class="ltx_ref ltx_href ltx_font_sansserif">{e.rykov, y.a.shishkina}@tinkoff.ai</a>,
<a href="mailto:kseniia.petrushina@skol.tech" title="" class="ltx_ref ltx_href ltx_font_sansserif">{kseniia.petrushina, kseniia.titova, sergey.petrakov, a.panchenko}@skol.tech</a></span></span>
</span></span></p>
<br class="ltx_break ltx_centering">
</div>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Large language models are proficient in generating human-like text across various styles. However, even the most advanced models can produce hallucinations, leading users to question their reliability. There are two primary types of hallucinations: factuality hallucinations, which involve the generation of content that deviates from actual facts, and faithfulness hallucinations, when the model fails to solve tasks correctly following specific instructions <cite class="ltx_cite ltx_citemacro_cite">Huang et al. (<a href="#bib.bib7" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The SemEval 2024 Shared-task on Hallucinations and Related Observable Overgeneration Mistakes <cite class="ltx_cite ltx_citemacro_cite">Mickus et al. (<a href="#bib.bib9" title="" class="ltx_ref">2024</a>)</cite> has integrated both types into three tasks. The Definition Modeling task (DM) focused on fact-related hallucinations by challenging models to generate contextually relevant word definitions. Both the Machine Translation (MT) and Paraphrase Generation (PG) tasks included faithfulness hallucinations, with models asked to produce translations or paraphrases for given sentences. Evaluation labelled datasets for these tasks were provided and the training dataset consisted only of source sentences and model generations, without corresponding labels.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Motivated by the lack of annotated resources and the efficacy of other language models trained on synthetic data, we developed two synthetic datasets that replicate the targeted domain. First, we collected data through a proprietary GPT-4 model <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a href="#bib.bib12" title="" class="ltx_ref">2023</a>)</cite>, but our methods trained on the achieved data did not yield the desired results as prompt engineering made maintaining the domain challenging. As a second approach, we trained LLaMA2-7b <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a href="#bib.bib17" title="" class="ltx_ref">2023</a>)</cite> adapters using a small set of annotated examples and applied them to the unlabeled training data. This method proved to be a more effective form of in-domain data augmentation.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">While the competition was run on two tracks, we focus mainly on the model-agnostic track. In our methods we utilized the most effective models with varied sizes and architectures, which we had evaluated beforehand. Our experiments involved fine-tuning a pre-trained embedding model, repurposing it to function as a binary classifier across a number of open-source datasets, including our synthetic sets. We also experimented with a promising method for evaluating paraphrases by modifying its design and fine-tuning the model on different data. Finally, we tested different combinations of the highest-performing approaches in an ensemble setting. Generated synthetic data and code published on GitHub<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/s-nlp/shroom" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/s-nlp/shroom</a></span></span></span>.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In the field of text representation, the E5 <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a href="#bib.bib18" title="" class="ltx_ref">2022</a>)</cite> family represents a group of cutting-edge sentence embedding models trained through contrastive methods. The E5-Mistral<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://huggingface.co/intfloat/e5-mistral-7b-instruct" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/intfloat/e5-mistral-7b-instruct</a></span></span></span> model, a powerful embedding model that has been fine-tuned on a selection of annotated data, is currently recognized as the leading open-source model by the Multitask Text Embedding Benchmark <cite class="ltx_cite ltx_citemacro_cite">Muennighoff et al. (<a href="#bib.bib10" title="" class="ltx_ref">2023</a>)</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">Vectara’s <span id="S2.p2.1.1" class="ltx_text ltx_font_italic">hallucination_detection_model<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note"><span id="footnote3.1.1.1" class="ltx_text ltx_font_upright">3</span></span><a target="_blank" href="https://huggingface.co/vectara/hallucination_evaluation_model" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://huggingface.co/vectara/hallucination_evaluation_model</a></span></span></span></span> is a fine-tuned DeBERTa focused on summarization datasets that includes annotations for factual consistency. TrueTeacher <cite class="ltx_cite ltx_citemacro_cite">Gekhman et al. (<a href="#bib.bib5" title="" class="ltx_ref">2023</a>)</cite> is a family of models and an associated dataset designed for evaluating factual consistency. The dataset was created by first fine-tuning various-sized T5 models on summarization tasks. These models were then employed to generate hypotheses, which were subsequently automatically annotated using a 540B Large Language Model (LLM). This annotated dataset was then utilized to train multiple models to assess factual consistency.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">The Mutual Implication Score (MIS) <cite class="ltx_cite ltx_citemacro_cite">Babakov et al. (<a href="#bib.bib1" title="" class="ltx_ref">2022</a>)</cite> is a metric devised for evaluating the quality of text style transfer and paraphrasing systems, grounding its assessment on content similarity between the prediction and the reference text. It leverages a RoBERTa-NLI <cite class="ltx_cite ltx_citemacro_cite">Nie et al. (<a href="#bib.bib11" title="" class="ltx_ref">2020</a>)</cite> model that has been fine-tuned and incorporates it into an architecture that processes two input texts sequentially in both forward and reverse directions. The final hidden states from these two passes are merged and forwarded to a classification head to determine the MIS score. Initially, the MIS metric was trained using the Quora Question Pairs dataset (QQP) <cite class="ltx_cite ltx_citemacro_cite">Sharma et al. (<a href="#bib.bib16" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">SimCSE (Similarity-based Contrastive Self-supervised Learning) <cite class="ltx_cite ltx_citemacro_cite">Gao et al. (<a href="#bib.bib4" title="" class="ltx_ref">2021</a>)</cite> is a self-supervised learning method for text embeddings. It is used for creating embeddings of text data that are semantically meaningful and can be used in various downstream tasks. It involves training a neural network to maximize the similarity between embeddings of similar sentences and minimize the similarity between embeddings of dissimilar sentences. LaBSE (Language-agnostic BERT Sentence Embedding) <cite class="ltx_cite ltx_citemacro_cite">Feng et al. (<a href="#bib.bib3" title="" class="ltx_ref">2022</a>)</cite> is a method for generating multilingual sentence embeddings using the BERT architecture.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">Other metrics for evaluating content preservation, such as BLEU (Bilingual Evaluation Understudy) <cite class="ltx_cite ltx_citemacro_cite">Papineni et al. (<a href="#bib.bib13" title="" class="ltx_ref">2002</a>)</cite>, CHRF (Character n-gram F-score) <cite class="ltx_cite ltx_citemacro_cite">Popović (<a href="#bib.bib14" title="" class="ltx_ref">2015</a>)</cite>, METEOR (Metric for Evaluation of Translation with Explicit ORdering) <cite class="ltx_cite ltx_citemacro_cite">Banerjee and Lavie (<a href="#bib.bib2" title="" class="ltx_ref">2005</a>)</cite>, and BLEURT (Bilingual Evaluation Understudy for Ranking and Tuning) <cite class="ltx_cite ltx_citemacro_cite">Sellam et al. (<a href="#bib.bib15" title="" class="ltx_ref">2020</a>)</cite>, also stand out. BLEU utilizes a modified unigram precision score, CHRF evaluates the quality of machine translation by comparing character n-grams in candidate translations against reference translations to compute an F-score, METEOR calculates the harmonic mean of precision and recall at the single-word level, and BLEURT employs a fine-tuned BERT model in a cross-encoder setup, using synthetic data to assess semantic similarity.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2404.06137/assets/img/e5-mistral-instruct-classifier-architecture.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="627" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Classifier architecture when using synthetic data.</figcaption>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Data</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Existing datasets</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The QQP dataset consists of pairs of questions from the Quora forum. For each pair, it is indicated whether the questions are paraphrases, i.e. they ask about the same thing. PAWS <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a href="#bib.bib19" title="" class="ltx_ref">2019</a>)</cite> is a paraphrase detection dataset that contains complex cases with both paraphrase and non-paraphrase samples that have high lexical overlap.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">We postulated that other pre-existing datasets, such as QQP and PAWS, might exhibit particular biases due to their distinct task domains (for instance, QQP dataset includes only questions). To mitigate this potential issue, we generated synthetic data taking unlabeled training samples as starting points.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">Our experimentation with synthetic data creation was divided into two main approaches: the first involved training LoRA <cite class="ltx_cite ltx_citemacro_cite">Hu et al. (<a href="#bib.bib6" title="" class="ltx_ref">2022</a>)</cite> adapters for the LLaMA2-7b model using the annotated data derived from the validation set. The second approach involved the generation of both correct and incorrect hypotheses by employing GPT-4 and specific prompts.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p">All tasks were distilled down to the paraphrase evaluation task. Consequently, we only used targets (sources for paraphrase generation) and hypotheses as inputs for the models.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>LLaMA2-7b adapter</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">We trained 6 LoRA adapters, pairing them to specialize in either generating hallucinations or producing correct responses for each task. Due to the limited amount of labeled data, we made use of model’s ability of in-context learning by prepending samples with instructions: <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_italic">Paraphrase</span> for non-hallucinations and <span id="S3.SS2.p1.1.2" class="ltx_text ltx_font_italic">Provide an incorrect paraphrase</span> for hallucinations. The number of samples for each adapter is shown in Table <a href="#S3.T1" title="Table 1 ‣ 3.2 LLaMA2-7b adapter ‣ 3 Data ‣ SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for Hallucination Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<table id="S3.T1.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T1.1.1" class="ltx_tr">
<td id="S3.T1.1.1.1" class="ltx_td ltx_border_tt"></td>
<td id="S3.T1.1.1.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T1.1.1.2.1" class="ltx_text ltx_font_bold">DM</span></td>
<td id="S3.T1.1.1.3" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T1.1.1.3.1" class="ltx_text ltx_font_bold">MT</span></td>
<td id="S3.T1.1.1.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt"><span id="S3.T1.1.1.4.1" class="ltx_text ltx_font_bold">PG</span></td>
</tr>
<tr id="S3.T1.1.2" class="ltx_tr">
<td id="S3.T1.1.2.1" class="ltx_td ltx_align_left ltx_border_t">Not Hallucination</td>
<td id="S3.T1.1.2.2" class="ltx_td ltx_align_left ltx_border_t">188</td>
<td id="S3.T1.1.2.3" class="ltx_td ltx_align_left ltx_border_t">211</td>
<td id="S3.T1.1.2.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">132</td>
</tr>
<tr id="S3.T1.1.3" class="ltx_tr">
<td id="S3.T1.1.3.1" class="ltx_td ltx_align_left">Hallucination</td>
<td id="S3.T1.1.3.2" class="ltx_td ltx_align_left">175</td>
<td id="S3.T1.1.3.3" class="ltx_td ltx_align_left">179</td>
<td id="S3.T1.1.3.4" class="ltx_td ltx_nopad_r ltx_align_left">132</td>
</tr>
<tr id="S3.T1.1.4" class="ltx_tr">
<td id="S3.T1.1.4.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t"><span id="S3.T1.1.4.1.1" class="ltx_text ltx_font_bold">Total</span></td>
<td id="S3.T1.1.4.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">363</td>
<td id="S3.T1.1.4.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">390</td>
<td id="S3.T1.1.4.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_t">264</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Adapter train sample sizes.</figcaption>
</figure>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Training and generation hyperparameters are displayed in Table <a href="#S3.T2" title="Table 2 ‣ 3.2 LLaMA2-7b adapter ‣ 3 Data ‣ SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for Hallucination Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. For each task and label we manually selected the best epoch by analyzing a small set of generated samples. These checkpoints were further employed to synthesize hypotheses for their task’s training set. A small sample of the generated data using LLaMA2-7b adapter is provided in the Appendix <a href="#A3" title="Appendix C Synthetic data examples ‣ SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for Hallucination Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<table id="S3.T2.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T2.1.1" class="ltx_tr">
<td id="S3.T2.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T2.1.1.1.1" class="ltx_text ltx_font_bold">Stage</span></td>
<td id="S3.T2.1.1.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T2.1.1.2.1" class="ltx_text ltx_font_bold">Hyperparameter</span></td>
<td id="S3.T2.1.1.3" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt"><span id="S3.T2.1.1.3.1" class="ltx_text ltx_font_bold">Value</span></td>
</tr>
<tr id="S3.T2.1.2" class="ltx_tr">
<td id="S3.T2.1.2.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T2.1.2.1.1" class="ltx_text ltx_font_bold">Training</span></td>
<td id="S3.T2.1.2.2" class="ltx_td ltx_align_left ltx_border_t">lr</td>
<td id="S3.T2.1.2.3" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">4e-4</td>
</tr>
<tr id="S3.T2.1.3" class="ltx_tr">
<td id="S3.T2.1.3.1" class="ltx_td"></td>
<td id="S3.T2.1.3.2" class="ltx_td ltx_align_left">warmup_steps</td>
<td id="S3.T2.1.3.3" class="ltx_td ltx_nopad_r ltx_align_left">1</td>
</tr>
<tr id="S3.T2.1.4" class="ltx_tr">
<td id="S3.T2.1.4.1" class="ltx_td"></td>
<td id="S3.T2.1.4.2" class="ltx_td ltx_align_left">optimizer</td>
<td id="S3.T2.1.4.3" class="ltx_td ltx_nopad_r ltx_align_left">AdamW</td>
</tr>
<tr id="S3.T2.1.5" class="ltx_tr">
<td id="S3.T2.1.5.1" class="ltx_td"></td>
<td id="S3.T2.1.5.2" class="ltx_td ltx_align_left">scheduler</td>
<td id="S3.T2.1.5.3" class="ltx_td ltx_nopad_r ltx_align_left">linear</td>
</tr>
<tr id="S3.T2.1.6" class="ltx_tr">
<td id="S3.T2.1.6.1" class="ltx_td"></td>
<td id="S3.T2.1.6.2" class="ltx_td ltx_align_left">LoRA alpha</td>
<td id="S3.T2.1.6.3" class="ltx_td ltx_nopad_r ltx_align_left">16</td>
</tr>
<tr id="S3.T2.1.7" class="ltx_tr">
<td id="S3.T2.1.7.1" class="ltx_td"></td>
<td id="S3.T2.1.7.2" class="ltx_td ltx_align_left">LoRA dropout</td>
<td id="S3.T2.1.7.3" class="ltx_td ltx_nopad_r ltx_align_left">0.05</td>
</tr>
<tr id="S3.T2.1.8" class="ltx_tr">
<td id="S3.T2.1.8.1" class="ltx_td"></td>
<td id="S3.T2.1.8.2" class="ltx_td ltx_align_left">LoRA r</td>
<td id="S3.T2.1.8.3" class="ltx_td ltx_nopad_r ltx_align_left">16</td>
</tr>
<tr id="S3.T2.1.9" class="ltx_tr">
<td id="S3.T2.1.9.1" class="ltx_td"></td>
<td id="S3.T2.1.9.2" class="ltx_td ltx_align_left">batch size</td>
<td id="S3.T2.1.9.3" class="ltx_td ltx_nopad_r ltx_align_left">32</td>
</tr>
<tr id="S3.T2.1.10" class="ltx_tr">
<td id="S3.T2.1.10.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S3.T2.1.10.1.1" class="ltx_text ltx_font_bold">Inference</span></td>
<td id="S3.T2.1.10.2" class="ltx_td ltx_align_left ltx_border_t">num_beams</td>
<td id="S3.T2.1.10.3" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">3</td>
</tr>
<tr id="S3.T2.1.11" class="ltx_tr">
<td id="S3.T2.1.11.1" class="ltx_td"></td>
<td id="S3.T2.1.11.2" class="ltx_td ltx_align_left">do_sample</td>
<td id="S3.T2.1.11.3" class="ltx_td ltx_nopad_r ltx_align_left">true</td>
</tr>
<tr id="S3.T2.1.12" class="ltx_tr">
<td id="S3.T2.1.12.1" class="ltx_td"></td>
<td id="S3.T2.1.12.2" class="ltx_td ltx_align_left">repetition_penalty</td>
<td id="S3.T2.1.12.3" class="ltx_td ltx_nopad_r ltx_align_left">1.2</td>
</tr>
<tr id="S3.T2.1.13" class="ltx_tr">
<td id="S3.T2.1.13.1" class="ltx_td"></td>
<td id="S3.T2.1.13.2" class="ltx_td ltx_align_left">top_k</td>
<td id="S3.T2.1.13.3" class="ltx_td ltx_nopad_r ltx_align_left">50</td>
</tr>
<tr id="S3.T2.1.14" class="ltx_tr">
<td id="S3.T2.1.14.1" class="ltx_td ltx_border_bb"></td>
<td id="S3.T2.1.14.2" class="ltx_td ltx_align_left ltx_border_bb">max_new_tokens</td>
<td id="S3.T2.1.14.3" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb">512</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Training and inference hyperparameters for LoRA adapters.</figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>GPT-4 prompting</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">In addition, we created two distinct prompts for the PG task. In these prompts, we directed GPT-4 to generate a paraphrase of a source sentence extracted from an unlabeled training sample. The nature of the paraphrase, whether it should contain hallucinations and overgeneration errors or not, was determined by the specific prompt we used.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">We enriched the prompt structure for few-shot learning purposes, incorporating several illustrative examples drawn from both the validation and trial data splits. Alongside each <span id="S3.SS3.p2.1.1" class="ltx_text ltx_font_italic">incorrect</span> example, we included an explanation to clarify why the provided hypothesis did not meet the criteria.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">Moreover, we tasked GPT-4 to execute its reasoning step-by-step: to iterate through several examples with accompanying explanations, and, by leveraging those explanations, to discern and select the most suitable paraphrase.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para">
<p id="S3.SS3.p4.1" class="ltx_p">We utilized the <span id="S3.SS3.p4.1.1" class="ltx_text ltx_font_italic">gpt-4-1106-preview</span> model, adhering to the default generation parameters stipulated by the OpenAI API service.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Data filtration</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">In the process of evaluating the synthetic data we generated, we encountered multiple issues that necessitated an extra layer of filtering:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">A number of the samples produced by the LLaMA2-7B model were excessively lengthy, containing up to 1024 tokens.</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">The labeling of samples by the LLaMA2-7B as <span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_italic">Hallucination</span> was frequently incorrect. Samples designated as hallucinations were often devoid of any such content, and conversely, non-hallucination samples sometimes contained hallucinations.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p">A peculiar pattern was observed in the DM task generations from LLaMA2-7B, where more than 9,000 samples started with the word <span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">any</span> or <span id="S3.I1.i3.p1.1.2" class="ltx_text ltx_font_italic">anything</span> denoting a biased starting point which may impact the diversity and neutrality required for effective training.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p">In the subsets of synthetic data generated by GPT-4 and labeled as <span id="S3.I1.i4.p1.1.1" class="ltx_text ltx_font_italic">Not Hallucination</span> the resulting examples were deemed too straightforward, potentially leading to a training dataset that cannot robustly challenge and thereby improve the model’s discriminatory capabilities.</p>
</div>
</li>
</ul>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">To tackle the identified issues with the synthetic data, we adopted a systematic filtering methodology. We began by eliminating any hypothesis that exceeded a length of 200 tokens, ensuring the data remained succinct. For the samples that started with <span id="S3.SS4.p2.1.1" class="ltx_text ltx_font_italic">any</span> or <span id="S3.SS4.p2.1.2" class="ltx_text ltx_font_italic">anything</span>, we decided to limit the number to 500 to minimize bias.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<table id="S3.T3.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T3.1.1" class="ltx_tr">
<td id="S3.T3.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T3.1.1.1.1" class="ltx_text ltx_font_bold">Source method</span></td>
<td id="S3.T3.1.1.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T3.1.1.2.1" class="ltx_text ltx_font_bold">Task</span></td>
<td id="S3.T3.1.1.3" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T3.1.1.3.1" class="ltx_text ltx_font_bold">Label</span></td>
<td id="S3.T3.1.1.4" class="ltx_td ltx_align_left ltx_border_tt"><span id="S3.T3.1.1.4.1" class="ltx_text ltx_font_bold"># before filtering</span></td>
<td id="S3.T3.1.1.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt"><span id="S3.T3.1.1.5.1" class="ltx_text ltx_font_bold"># after filtering</span></td>
</tr>
<tr id="S3.T3.1.2" class="ltx_tr">
<td id="S3.T3.1.2.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="6"><span id="S3.T3.1.2.1.1" class="ltx_text">LLaMA2-7B</span></td>
<td id="S3.T3.1.2.2" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S3.T3.1.2.2.1" class="ltx_text">MT</span></td>
<td id="S3.T3.1.2.3" class="ltx_td ltx_align_left ltx_border_t">Hallucination</td>
<td id="S3.T3.1.2.4" class="ltx_td ltx_align_left ltx_border_t">18 093</td>
<td id="S3.T3.1.2.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">7 758</td>
</tr>
<tr id="S3.T3.1.3" class="ltx_tr">
<td id="S3.T3.1.3.1" class="ltx_td ltx_align_left">Not Hallucination</td>
<td id="S3.T3.1.3.2" class="ltx_td ltx_align_left">17 056</td>
<td id="S3.T3.1.3.3" class="ltx_td ltx_nopad_r ltx_align_left">3 572</td>
</tr>
<tr id="S3.T3.1.4" class="ltx_tr">
<td id="S3.T3.1.4.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S3.T3.1.4.1.1" class="ltx_text">PG</span></td>
<td id="S3.T3.1.4.2" class="ltx_td ltx_align_left ltx_border_t">Hallucination</td>
<td id="S3.T3.1.4.3" class="ltx_td ltx_align_left ltx_border_t">13 961</td>
<td id="S3.T3.1.4.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">2 839</td>
</tr>
<tr id="S3.T3.1.5" class="ltx_tr">
<td id="S3.T3.1.5.1" class="ltx_td ltx_align_left">Not Hallucination</td>
<td id="S3.T3.1.5.2" class="ltx_td ltx_align_left">14 928</td>
<td id="S3.T3.1.5.3" class="ltx_td ltx_nopad_r ltx_align_left">3 952</td>
</tr>
<tr id="S3.T3.1.6" class="ltx_tr">
<td id="S3.T3.1.6.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S3.T3.1.6.1.1" class="ltx_text">DM</span></td>
<td id="S3.T3.1.6.2" class="ltx_td ltx_align_left ltx_border_t">Hallucination</td>
<td id="S3.T3.1.6.3" class="ltx_td ltx_align_left ltx_border_t">19 224</td>
<td id="S3.T3.1.6.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">5 939</td>
</tr>
<tr id="S3.T3.1.7" class="ltx_tr">
<td id="S3.T3.1.7.1" class="ltx_td ltx_align_left">Not Hallucination</td>
<td id="S3.T3.1.7.2" class="ltx_td ltx_align_left">20 000</td>
<td id="S3.T3.1.7.3" class="ltx_td ltx_nopad_r ltx_align_left">12 032</td>
</tr>
<tr id="S3.T3.1.8" class="ltx_tr">
<td id="S3.T3.1.8.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" rowspan="2"><span id="S3.T3.1.8.1.1" class="ltx_text">GPT-4</span></td>
<td id="S3.T3.1.8.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" rowspan="2"><span id="S3.T3.1.8.2.1" class="ltx_text">PG</span></td>
<td id="S3.T3.1.8.3" class="ltx_td ltx_align_left ltx_border_t">Hallucination</td>
<td id="S3.T3.1.8.4" class="ltx_td ltx_align_left ltx_border_t">7 439</td>
<td id="S3.T3.1.8.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">-</td>
</tr>
<tr id="S3.T3.1.9" class="ltx_tr">
<td id="S3.T3.1.9.1" class="ltx_td ltx_align_left ltx_border_bb">Not Hallucination</td>
<td id="S3.T3.1.9.2" class="ltx_td ltx_align_left ltx_border_bb">6 279</td>
<td id="S3.T3.1.9.3" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb">-</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>The number of samples in the synthetic datasets. No filtering was performed for GPT-4.</figcaption>
</figure>
<div id="S3.SS4.p3" class="ltx_para">
<p id="S3.SS4.p3.1" class="ltx_p">With the aim of refining the data quality, we then annotated all the synthetic samples using MIS. We set specific thresholds for these MIS scores to filter the data further. In the subset containing hallucinations, we removed samples that had a score lower than 0.1 or higher than 0.5. For non-hallucinated samples, we only retained those with a score between 0.7 and 0.9. These score ranges were established empirically to ensure a balance between discernibility and ambiguity in both the hallucinated and non-hallucinated examples.</p>
</div>
<div id="S3.SS4.p4" class="ltx_para">
<p id="S3.SS4.p4.1" class="ltx_p">The number of samples generated using both synthetic methods, before and after the filtering stage, is given in Table <a href="#S3.T3" title="Table 3 ‣ 3.4 Data filtration ‣ 3 Data ‣ SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for Hallucination Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. After generating the synthetic data, we performed several experiments with different combinations of synthetic data.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Methods</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Black-box baselines</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">First, we started with an assessment of various baseline models that are detailed in Section <a href="#S2" title="2 Related work ‣ SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for Hallucination Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, including a new addition, GPT-4. These baseline models were utilized as-is, in a <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_italic">black-box</span> fashion, without any further fine-tuning specifically for our tasks.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">For all models other than GPT-4, we employed the inference code available on the official HuggingFace Hub pages. For GPT-4, we created specific prompts for each task. Within these prompts, we instructed GPT-4 to methodically process the information and ascertain the presence of hallucinations within the sample. We provided all pertinent data (source, hypothesis, and, when available, target) within the prompt. It is important to note that the collection and evaluation of predictions were conducted strictly within the model-aware track. The prompt is available in Appendix <a href="#A1" title="Appendix A GPT-4 prompt for PG task evaluation ‣ SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for Hallucination Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A</span></a>.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>SFT E5-Mistral</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The obtained synthetic data was used to fine-tune the E5-Mistral model on our domain. In our experiments, we adjusted the data inputs by adding or omitting certain subsets of synthetic data to create the final blend used for training. The choice of the E5-Mistral model as the foundation for our work was based on its superior performance compared to other models.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">The design of our classifier is depicted in Figure <a href="#S2.F1" title="Figure 1 ‣ 2 Related work ‣ SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for Hallucination Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. In simple terms, we prepare two sample sentences with a specific format and input them into an model with LoRA. Afterwards, we obtain the embedding of the last token and pass it to the classification head.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Mutual Implication Score</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">In this setup we experimented with some improvements to the original Mutual Implication Score model architecture. Even though MIS was already trained on a large amount of paraphrase detection data, QQP dataset biased to the questions. Therefore, we thought that we can fine-tune it to decrease this bias.</p>
</div>
<figure id="S4.T4" class="ltx_table">
<table id="S4.T4.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T4.1.1" class="ltx_tr">
<td id="S4.T4.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S4.T4.1.1.1.1" class="ltx_text ltx_font_bold">Hyperparameter</span></td>
<td id="S4.T4.1.1.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt"><span id="S4.T4.1.1.2.1" class="ltx_text ltx_font_bold">Value</span></td>
</tr>
<tr id="S4.T4.1.2" class="ltx_tr">
<td id="S4.T4.1.2.1" class="ltx_td ltx_align_left ltx_border_t">lr</td>
<td id="S4.T4.1.2.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">1e-4</td>
</tr>
<tr id="S4.T4.1.3" class="ltx_tr">
<td id="S4.T4.1.3.1" class="ltx_td ltx_align_left">lr scheduler</td>
<td id="S4.T4.1.3.2" class="ltx_td ltx_nopad_r ltx_align_left">constant</td>
</tr>
<tr id="S4.T4.1.4" class="ltx_tr">
<td id="S4.T4.1.4.1" class="ltx_td ltx_align_left">optimizer</td>
<td id="S4.T4.1.4.2" class="ltx_td ltx_nopad_r ltx_align_left">AdamW</td>
</tr>
<tr id="S4.T4.1.5" class="ltx_tr">
<td id="S4.T4.1.5.1" class="ltx_td ltx_align_left ltx_border_bb">batch size</td>
<td id="S4.T4.1.5.2" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb">32</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Training hyperparameters for MIS experiments.</figcaption>
</figure>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">In Table <a href="#S4.T4" title="Table 4 ‣ 4.3 Mutual Implication Score ‣ 4 Methods ‣ SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for Hallucination Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> we present default training hyperparameters used for experiments with MIS. Unless stated otherwise, we chose to train with the RoBERTa encoder, classifier and QQP dataset from original MIS study.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">We tried various experiment configurations, ranging from the use of new datasets to alterations in architecture and training methods. We will describe all the modifications presented:</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<ol id="S4.I1" class="ltx_enumerate">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">MIS</span>: Vanilla MIS from HuggingFace Hub without any fine-tuning.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><span id="S4.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">MIS trained with LoRA</span>: Add LoRA adapters instead of partially unfreezing layers.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p"><span id="S4.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">MIS with Vectara</span>: Replace the original RoBERTa encoder with Vectara’s model.</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p"><span id="S4.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">MIS with one encoder</span>: Change MIS two-folded architecture with a single one.</p>
</div>
</li>
<li id="S4.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S4.I1.i5.p1" class="ltx_para">
<p id="S4.I1.i5.p1.1" class="ltx_p"><span id="S4.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">MIS trained on the PAWS</span>: Add 108,463 human-labeled paraphrase adversaries from PAWS.</p>
</div>
</li>
<li id="S4.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">6.</span> 
<div id="S4.I1.i6.p1" class="ltx_para">
<p id="S4.I1.i6.p1.1" class="ltx_p"><span id="S4.I1.i6.p1.1.1" class="ltx_text ltx_font_bold">MIS trained on our synthetic data</span>: Add our synthetic data obtained previously.</p>
</div>
</li>
</ol>
</div>
<figure id="S4.T5" class="ltx_table">
<table id="S4.T5.3.3" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S4.T5.3.3.4" class="ltx_tr">
<td id="S4.T5.3.3.4.1" class="ltx_td ltx_align_center ltx_border_tt" rowspan="2"><span id="S4.T5.3.3.4.1.1" class="ltx_text ltx_font_bold">Method</span></td>
<td id="S4.T5.3.3.4.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S4.T5.3.3.4.2.1" class="ltx_text ltx_font_bold">val</span></td>
<td id="S4.T5.3.3.4.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S4.T5.3.3.4.3.1" class="ltx_text ltx_font_bold">test</span></td>
</tr>
<tr id="S4.T5.3.3.5" class="ltx_tr">
<td id="S4.T5.3.3.5.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T5.3.3.5.1.1" class="ltx_text ltx_font_bold">agnostic</span></td>
<td id="S4.T5.3.3.5.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T5.3.3.5.2.1" class="ltx_text ltx_font_bold">aware</span></td>
<td id="S4.T5.3.3.5.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T5.3.3.5.3.1" class="ltx_text ltx_font_bold">agnostic</span></td>
<td id="S4.T5.3.3.5.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t"><span id="S4.T5.3.3.5.4.1" class="ltx_text ltx_font_bold">aware</span></td>
</tr>
<tr id="S4.T5.1.1.1" class="ltx_tr">
<td id="S4.T5.1.1.1.1" class="ltx_td ltx_align_left ltx_border_t">ahoblitz<sup id="S4.T5.1.1.1.1.1" class="ltx_sup"><span id="S4.T5.1.1.1.1.1.1" class="ltx_text ltx_font_italic">∗</span></sup>
</td>
<td id="S4.T5.1.1.1.2" class="ltx_td ltx_align_left ltx_border_t">-</td>
<td id="S4.T5.1.1.1.3" class="ltx_td ltx_align_left ltx_border_t">-</td>
<td id="S4.T5.1.1.1.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T5.1.1.1.4.1" class="ltx_text ltx_font_bold">0.85</span></td>
<td id="S4.T5.1.1.1.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t"><span id="S4.T5.1.1.1.5.1" class="ltx_text ltx_font_bold">0.81</span></td>
</tr>
<tr id="S4.T5.2.2.2" class="ltx_tr">
<td id="S4.T5.2.2.2.1" class="ltx_td ltx_align_left">zackchen<sup id="S4.T5.2.2.2.1.1" class="ltx_sup"><span id="S4.T5.2.2.2.1.1.1" class="ltx_text ltx_font_italic">∗</span></sup>
</td>
<td id="S4.T5.2.2.2.2" class="ltx_td ltx_align_left">-</td>
<td id="S4.T5.2.2.2.3" class="ltx_td ltx_align_left">-</td>
<td id="S4.T5.2.2.2.4" class="ltx_td ltx_align_left">0.84</td>
<td id="S4.T5.2.2.2.5" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S4.T5.2.2.2.5.1" class="ltx_text ltx_font_bold">0.81</span></td>
</tr>
<tr id="S4.T5.3.3.3" class="ltx_tr">
<td id="S4.T5.3.3.3.1" class="ltx_td ltx_align_left">liuwei<sup id="S4.T5.3.3.3.1.1" class="ltx_sup"><span id="S4.T5.3.3.3.1.1.1" class="ltx_text ltx_font_italic">∗</span></sup>
</td>
<td id="S4.T5.3.3.3.2" class="ltx_td ltx_align_left">-</td>
<td id="S4.T5.3.3.3.3" class="ltx_td ltx_align_left">-</td>
<td id="S4.T5.3.3.3.4" class="ltx_td ltx_align_left">0.83</td>
<td id="S4.T5.3.3.3.5" class="ltx_td ltx_nopad_r ltx_align_left">0.80</td>
</tr>
<tr id="S4.T5.3.3.6" class="ltx_tr">
<td id="S4.T5.3.3.6.1" class="ltx_td ltx_align_left ltx_border_t">Voting</td>
<td id="S4.T5.3.3.6.2" class="ltx_td ltx_align_left ltx_border_t">0.85</td>
<td id="S4.T5.3.3.6.3" class="ltx_td ltx_align_left ltx_border_t">0.82</td>
<td id="S4.T5.3.3.6.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T5.3.3.6.4.1" class="ltx_text ltx_framed ltx_framed_underline">0.82</span></td>
<td id="S4.T5.3.3.6.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">0.78</td>
</tr>
<tr id="S4.T5.3.3.7" class="ltx_tr">
<td id="S4.T5.3.3.7.1" class="ltx_td ltx_align_left">Normalized averaging</td>
<td id="S4.T5.3.3.7.2" class="ltx_td ltx_align_left">0.81</td>
<td id="S4.T5.3.3.7.3" class="ltx_td ltx_align_left">0.81</td>
<td id="S4.T5.3.3.7.4" class="ltx_td ltx_align_left">0.81</td>
<td id="S4.T5.3.3.7.5" class="ltx_td ltx_nopad_r ltx_align_left">0.79</td>
</tr>
<tr id="S4.T5.3.3.8" class="ltx_tr">
<td id="S4.T5.3.3.8.1" class="ltx_td ltx_align_left">MIS + PAWS</td>
<td id="S4.T5.3.3.8.2" class="ltx_td ltx_align_left">0.82</td>
<td id="S4.T5.3.3.8.3" class="ltx_td ltx_align_left">0.82</td>
<td id="S4.T5.3.3.8.4" class="ltx_td ltx_align_left">0.81</td>
<td id="S4.T5.3.3.8.5" class="ltx_td ltx_nopad_r ltx_align_left">0.78</td>
</tr>
<tr id="S4.T5.3.3.9" class="ltx_tr">
<td id="S4.T5.3.3.9.1" class="ltx_td ltx_align_left">SFT E5 Mistral</td>
<td id="S4.T5.3.3.9.2" class="ltx_td ltx_align_left">0.83</td>
<td id="S4.T5.3.3.9.3" class="ltx_td ltx_align_left">0.77</td>
<td id="S4.T5.3.3.9.4" class="ltx_td ltx_align_left">0.80</td>
<td id="S4.T5.3.3.9.5" class="ltx_td ltx_nopad_r ltx_align_left">0.77</td>
</tr>
<tr id="S4.T5.3.3.10" class="ltx_tr">
<td id="S4.T5.3.3.10.1" class="ltx_td ltx_align_left ltx_border_t">MIS</td>
<td id="S4.T5.3.3.10.2" class="ltx_td ltx_align_left ltx_border_t">0.81</td>
<td id="S4.T5.3.3.10.3" class="ltx_td ltx_align_left ltx_border_t">0.78</td>
<td id="S4.T5.3.3.10.4" class="ltx_td ltx_align_left ltx_border_t">0.80</td>
<td id="S4.T5.3.3.10.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">0.77</td>
</tr>
<tr id="S4.T5.3.3.11" class="ltx_tr">
<td id="S4.T5.3.3.11.1" class="ltx_td ltx_align_left">E5 Mistral</td>
<td id="S4.T5.3.3.11.2" class="ltx_td ltx_align_left">0.81</td>
<td id="S4.T5.3.3.11.3" class="ltx_td ltx_align_left">0.80</td>
<td id="S4.T5.3.3.11.4" class="ltx_td ltx_align_left">0.76</td>
<td id="S4.T5.3.3.11.5" class="ltx_td ltx_nopad_r ltx_align_left">0.78</td>
</tr>
<tr id="S4.T5.3.3.12" class="ltx_tr">
<td id="S4.T5.3.3.12.1" class="ltx_td ltx_align_left">Vectara</td>
<td id="S4.T5.3.3.12.2" class="ltx_td ltx_align_left">0.76</td>
<td id="S4.T5.3.3.12.3" class="ltx_td ltx_align_left">0.76</td>
<td id="S4.T5.3.3.12.4" class="ltx_td ltx_align_left">0.75</td>
<td id="S4.T5.3.3.12.5" class="ltx_td ltx_nopad_r ltx_align_left">0.77</td>
</tr>
<tr id="S4.T5.3.3.13" class="ltx_tr">
<td id="S4.T5.3.3.13.1" class="ltx_td ltx_align_left">TrueTeacher</td>
<td id="S4.T5.3.3.13.2" class="ltx_td ltx_align_left">0.79</td>
<td id="S4.T5.3.3.13.3" class="ltx_td ltx_align_left">0.79</td>
<td id="S4.T5.3.3.13.4" class="ltx_td ltx_align_left">0.76</td>
<td id="S4.T5.3.3.13.5" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S4.T5.3.3.13.5.1" class="ltx_text ltx_framed ltx_framed_underline">0.80</span></td>
</tr>
<tr id="S4.T5.3.3.14" class="ltx_tr">
<td id="S4.T5.3.3.14.1" class="ltx_td ltx_align_left">GPT-4</td>
<td id="S4.T5.3.3.14.2" class="ltx_td ltx_align_left">-</td>
<td id="S4.T5.3.3.14.3" class="ltx_td ltx_align_left">0.74</td>
<td id="S4.T5.3.3.14.4" class="ltx_td ltx_align_left">-</td>
<td id="S4.T5.3.3.14.5" class="ltx_td ltx_nopad_r ltx_align_left">-</td>
</tr>
<tr id="S4.T5.3.3.15" class="ltx_tr">
<td id="S4.T5.3.3.15.1" class="ltx_td ltx_align_left ltx_border_t">SimCSE</td>
<td id="S4.T5.3.3.15.2" class="ltx_td ltx_align_left ltx_border_t">0.80</td>
<td id="S4.T5.3.3.15.3" class="ltx_td ltx_align_left ltx_border_t">0.80</td>
<td id="S4.T5.3.3.15.4" class="ltx_td ltx_align_left ltx_border_t">0.76</td>
<td id="S4.T5.3.3.15.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">0.76</td>
</tr>
<tr id="S4.T5.3.3.16" class="ltx_tr">
<td id="S4.T5.3.3.16.1" class="ltx_td ltx_align_left">BLEURT</td>
<td id="S4.T5.3.3.16.2" class="ltx_td ltx_align_left">0.77</td>
<td id="S4.T5.3.3.16.3" class="ltx_td ltx_align_left">0.77</td>
<td id="S4.T5.3.3.16.4" class="ltx_td ltx_align_left">0.74</td>
<td id="S4.T5.3.3.16.5" class="ltx_td ltx_nopad_r ltx_align_left">0.74</td>
</tr>
<tr id="S4.T5.3.3.17" class="ltx_tr">
<td id="S4.T5.3.3.17.1" class="ltx_td ltx_align_left">LaBSE</td>
<td id="S4.T5.3.3.17.2" class="ltx_td ltx_align_left">0.72</td>
<td id="S4.T5.3.3.17.3" class="ltx_td ltx_align_left">0.75</td>
<td id="S4.T5.3.3.17.4" class="ltx_td ltx_align_left">0.69</td>
<td id="S4.T5.3.3.17.5" class="ltx_td ltx_nopad_r ltx_align_left">0.73</td>
</tr>
<tr id="S4.T5.3.3.18" class="ltx_tr">
<td id="S4.T5.3.3.18.1" class="ltx_td ltx_align_left">METEOR</td>
<td id="S4.T5.3.3.18.2" class="ltx_td ltx_align_left">0.68</td>
<td id="S4.T5.3.3.18.3" class="ltx_td ltx_align_left">0.71</td>
<td id="S4.T5.3.3.18.4" class="ltx_td ltx_align_left">0.67</td>
<td id="S4.T5.3.3.18.5" class="ltx_td ltx_nopad_r ltx_align_left">0.69</td>
</tr>
<tr id="S4.T5.3.3.19" class="ltx_tr">
<td id="S4.T5.3.3.19.1" class="ltx_td ltx_align_left">chrF</td>
<td id="S4.T5.3.3.19.2" class="ltx_td ltx_align_left">0.63</td>
<td id="S4.T5.3.3.19.3" class="ltx_td ltx_align_left">0.72</td>
<td id="S4.T5.3.3.19.4" class="ltx_td ltx_align_left">0.65</td>
<td id="S4.T5.3.3.19.5" class="ltx_td ltx_nopad_r ltx_align_left">0.67</td>
</tr>
<tr id="S4.T5.3.3.20" class="ltx_tr">
<td id="S4.T5.3.3.20.1" class="ltx_td ltx_align_left">BLEU</td>
<td id="S4.T5.3.3.20.2" class="ltx_td ltx_align_left">0.67</td>
<td id="S4.T5.3.3.20.3" class="ltx_td ltx_align_left">0.70</td>
<td id="S4.T5.3.3.20.4" class="ltx_td ltx_align_left">0.64</td>
<td id="S4.T5.3.3.20.5" class="ltx_td ltx_nopad_r ltx_align_left">0.65</td>
</tr>
<tr id="S4.T5.3.3.21" class="ltx_tr">
<td id="S4.T5.3.3.21.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">Official baseline</td>
<td id="S4.T5.3.3.21.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">-</td>
<td id="S4.T5.3.3.21.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">-</td>
<td id="S4.T5.3.3.21.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">0.70</td>
<td id="S4.T5.3.3.21.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_t">0.74</td>
</tr>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Performance of described approaches. Accuracy is observed as evaluation score.                                                                                                                                   <sup id="S4.T5.7.1" class="ltx_sup"><span id="S4.T5.7.1.1" class="ltx_text ltx_font_italic">∗</span></sup>Top approaches from the official rankings.</figcaption>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Content Preservation Measures</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">We conducted a separate analysis on several NLP techniques as examined in the original MIS study. This exploration aimed to assess their suitability for the task of hallucination detection, considering the inherent connection between style transformation, paraphrase generation, and hallucination detection. A well-executed paraphrase should retain the essence of the original text without introducing extraneous elements, which is particularly crucial given that one of the competition’s subtasks involved paraphrasing. Specifically, our investigation involved LaBSE, SimCSE, and the metrics for evaluating content preservation described in Section <a href="#S2" title="2 Related work ‣ SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for Hallucination Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Ensembling</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">To enhance the performance of different pre-trained models, we combined them into an ensemble. The final decision on the presence of hallucinations is based on the predictions of multiple independent models.</p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.1" class="ltx_p">The predictions of separate models were normalized so that the decision boundary was the same for all models. Thus, differences in the scale of the threshold value did not introduce bias into the final decision.</p>
</div>
<div id="S4.SS5.p3" class="ltx_para">
<p id="S4.SS5.p3.1" class="ltx_p">We have chosen the best set of models for the ensemble from the possible options: E5-Mistral, fine-tuned E5-Mistral, Vectara, TrueTeacher, <span id="S4.SS5.p3.1.1" class="ltx_text ltx_font_italic">all-mpnet-base-v2<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">§</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">§</sup><span class="ltx_tag ltx_tag_note"><span id="footnote4.1.1.1" class="ltx_text ltx_font_upright">§</span></span><a target="_blank" href="https://huggingface.co/sentence-transformers/all-mpnet-base-v2" title="" class="ltx_ref ltx_url ltx_font_typewriter ltx_font_upright">https://huggingface.co/sentence-transformers/all-mpnet-base-v2</a></span></span></span></span> and also Mutual Implication Score. We calculated cosine between the encoded representations of the model’s hypothesis and the target sentence. To obtain a prediction, this score was compared with a descision boundary. For each model we select the optimal classification threshold on validation subset for each track and task. For Vectara we used a threshold of <math id="S4.SS5.p3.1.m1.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S4.SS5.p3.1.m1.1a"><mn id="S4.SS5.p3.1.m1.1.1" xref="S4.SS5.p3.1.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.p3.1.m1.1b"><cn type="float" id="S4.SS5.p3.1.m1.1.1.cmml" xref="S4.SS5.p3.1.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.p3.1.m1.1c">0.5</annotation></semantics></math>.</p>
</div>
<div id="S4.SS5.p4" class="ltx_para">
<p id="S4.SS5.p4.1" class="ltx_p">We employed different strategies on aggregating individual hallucination scores: Normalized averaging and Voting.</p>
</div>
<section id="S4.SS5.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.5.1 </span>Normalized averaging</h4>

<div id="S4.SS5.SSS1.p1" class="ltx_para">
<p id="S4.SS5.SSS1.p1.1" class="ltx_p">The predictions of separate models were normalized so that the decision boundary was the same for all models. Thus, differences in the scale of the threshold value did not introduce bias into the final decision.</p>
</div>
<div id="S4.SS5.SSS1.p2" class="ltx_para">
<p id="S4.SS5.SSS1.p2.3" class="ltx_p">Individual model scores are normalized as follows:</p>
<table id="S4.Ex1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.Ex1.m1.4" class="ltx_Math" alttext="\hat{p}=\begin{cases}kp+b,&amp;p\geq\text{thr}\\
\frac{p}{2\text{thr}},&amp;p&lt;\text{thr}\end{cases}" display="block"><semantics id="S4.Ex1.m1.4a"><mrow id="S4.Ex1.m1.4.5" xref="S4.Ex1.m1.4.5.cmml"><mover accent="true" id="S4.Ex1.m1.4.5.2" xref="S4.Ex1.m1.4.5.2.cmml"><mi id="S4.Ex1.m1.4.5.2.2" xref="S4.Ex1.m1.4.5.2.2.cmml">p</mi><mo id="S4.Ex1.m1.4.5.2.1" xref="S4.Ex1.m1.4.5.2.1.cmml">^</mo></mover><mo id="S4.Ex1.m1.4.5.1" xref="S4.Ex1.m1.4.5.1.cmml">=</mo><mrow id="S4.Ex1.m1.4.4" xref="S4.Ex1.m1.4.5.3.1.cmml"><mo id="S4.Ex1.m1.4.4.5" xref="S4.Ex1.m1.4.5.3.1.1.cmml">{</mo><mtable columnspacing="5pt" displaystyle="true" rowspacing="0pt" id="S4.Ex1.m1.4.4.4" xref="S4.Ex1.m1.4.5.3.1.cmml"><mtr id="S4.Ex1.m1.4.4.4a" xref="S4.Ex1.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S4.Ex1.m1.4.4.4b" xref="S4.Ex1.m1.4.5.3.1.cmml"><mrow id="S4.Ex1.m1.1.1.1.1.1.1.1" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.cmml"><mrow id="S4.Ex1.m1.1.1.1.1.1.1.1.1" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.cmml"><mrow id="S4.Ex1.m1.1.1.1.1.1.1.1.1.2" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.2.cmml"><mi id="S4.Ex1.m1.1.1.1.1.1.1.1.1.2.2" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.2.2.cmml">k</mi><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.1.1.1.1.1.1.1.1.2.1" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.2.1.cmml">​</mo><mi id="S4.Ex1.m1.1.1.1.1.1.1.1.1.2.3" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.2.3.cmml">p</mi></mrow><mo id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.cmml">+</mo><mi id="S4.Ex1.m1.1.1.1.1.1.1.1.1.3" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.3.cmml">b</mi></mrow><mo id="S4.Ex1.m1.1.1.1.1.1.1.1.2" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.cmml">,</mo></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S4.Ex1.m1.4.4.4c" xref="S4.Ex1.m1.4.5.3.1.cmml"><mrow id="S4.Ex1.m1.2.2.2.2.2.1" xref="S4.Ex1.m1.2.2.2.2.2.1.cmml"><mi id="S4.Ex1.m1.2.2.2.2.2.1.2" xref="S4.Ex1.m1.2.2.2.2.2.1.2.cmml">p</mi><mo id="S4.Ex1.m1.2.2.2.2.2.1.1" xref="S4.Ex1.m1.2.2.2.2.2.1.1.cmml">≥</mo><mtext id="S4.Ex1.m1.2.2.2.2.2.1.3" xref="S4.Ex1.m1.2.2.2.2.2.1.3a.cmml">thr</mtext></mrow></mtd></mtr><mtr id="S4.Ex1.m1.4.4.4d" xref="S4.Ex1.m1.4.5.3.1.cmml"><mtd class="ltx_align_left" columnalign="left" id="S4.Ex1.m1.4.4.4e" xref="S4.Ex1.m1.4.5.3.1.cmml"><mrow id="S4.Ex1.m1.3.3.3.3.1.1.3" xref="S4.Ex1.m1.3.3.3.3.1.1.1.cmml"><mstyle displaystyle="false" id="S4.Ex1.m1.3.3.3.3.1.1.1" xref="S4.Ex1.m1.3.3.3.3.1.1.1.cmml"><mfrac id="S4.Ex1.m1.3.3.3.3.1.1.1a" xref="S4.Ex1.m1.3.3.3.3.1.1.1.cmml"><mi id="S4.Ex1.m1.3.3.3.3.1.1.1.2" xref="S4.Ex1.m1.3.3.3.3.1.1.1.2.cmml">p</mi><mrow id="S4.Ex1.m1.3.3.3.3.1.1.1.3" xref="S4.Ex1.m1.3.3.3.3.1.1.1.3.cmml"><mn id="S4.Ex1.m1.3.3.3.3.1.1.1.3.2" xref="S4.Ex1.m1.3.3.3.3.1.1.1.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S4.Ex1.m1.3.3.3.3.1.1.1.3.1" xref="S4.Ex1.m1.3.3.3.3.1.1.1.3.1.cmml">​</mo><mtext id="S4.Ex1.m1.3.3.3.3.1.1.1.3.3" xref="S4.Ex1.m1.3.3.3.3.1.1.1.3.3a.cmml">thr</mtext></mrow></mfrac></mstyle><mo id="S4.Ex1.m1.3.3.3.3.1.1.3.1" xref="S4.Ex1.m1.3.3.3.3.1.1.1.cmml">,</mo></mrow></mtd><mtd class="ltx_align_left" columnalign="left" id="S4.Ex1.m1.4.4.4f" xref="S4.Ex1.m1.4.5.3.1.cmml"><mrow id="S4.Ex1.m1.4.4.4.4.2.1" xref="S4.Ex1.m1.4.4.4.4.2.1.cmml"><mi id="S4.Ex1.m1.4.4.4.4.2.1.2" xref="S4.Ex1.m1.4.4.4.4.2.1.2.cmml">p</mi><mo id="S4.Ex1.m1.4.4.4.4.2.1.1" xref="S4.Ex1.m1.4.4.4.4.2.1.1.cmml">&lt;</mo><mtext id="S4.Ex1.m1.4.4.4.4.2.1.3" xref="S4.Ex1.m1.4.4.4.4.2.1.3a.cmml">thr</mtext></mrow></mtd></mtr></mtable></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.Ex1.m1.4b"><apply id="S4.Ex1.m1.4.5.cmml" xref="S4.Ex1.m1.4.5"><eq id="S4.Ex1.m1.4.5.1.cmml" xref="S4.Ex1.m1.4.5.1"></eq><apply id="S4.Ex1.m1.4.5.2.cmml" xref="S4.Ex1.m1.4.5.2"><ci id="S4.Ex1.m1.4.5.2.1.cmml" xref="S4.Ex1.m1.4.5.2.1">^</ci><ci id="S4.Ex1.m1.4.5.2.2.cmml" xref="S4.Ex1.m1.4.5.2.2">𝑝</ci></apply><apply id="S4.Ex1.m1.4.5.3.1.cmml" xref="S4.Ex1.m1.4.4"><csymbol cd="latexml" id="S4.Ex1.m1.4.5.3.1.1.cmml" xref="S4.Ex1.m1.4.4.5">cases</csymbol><apply id="S4.Ex1.m1.1.1.1.1.1.1.1.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1"><plus id="S4.Ex1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.1"></plus><apply id="S4.Ex1.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.2"><times id="S4.Ex1.m1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.2.1"></times><ci id="S4.Ex1.m1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.2.2">𝑘</ci><ci id="S4.Ex1.m1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.2.3">𝑝</ci></apply><ci id="S4.Ex1.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S4.Ex1.m1.1.1.1.1.1.1.1.1.3">𝑏</ci></apply><apply id="S4.Ex1.m1.2.2.2.2.2.1.cmml" xref="S4.Ex1.m1.2.2.2.2.2.1"><geq id="S4.Ex1.m1.2.2.2.2.2.1.1.cmml" xref="S4.Ex1.m1.2.2.2.2.2.1.1"></geq><ci id="S4.Ex1.m1.2.2.2.2.2.1.2.cmml" xref="S4.Ex1.m1.2.2.2.2.2.1.2">𝑝</ci><ci id="S4.Ex1.m1.2.2.2.2.2.1.3a.cmml" xref="S4.Ex1.m1.2.2.2.2.2.1.3"><mtext id="S4.Ex1.m1.2.2.2.2.2.1.3.cmml" xref="S4.Ex1.m1.2.2.2.2.2.1.3">thr</mtext></ci></apply><apply id="S4.Ex1.m1.3.3.3.3.1.1.1.cmml" xref="S4.Ex1.m1.3.3.3.3.1.1.3"><divide id="S4.Ex1.m1.3.3.3.3.1.1.1.1.cmml" xref="S4.Ex1.m1.3.3.3.3.1.1.3"></divide><ci id="S4.Ex1.m1.3.3.3.3.1.1.1.2.cmml" xref="S4.Ex1.m1.3.3.3.3.1.1.1.2">𝑝</ci><apply id="S4.Ex1.m1.3.3.3.3.1.1.1.3.cmml" xref="S4.Ex1.m1.3.3.3.3.1.1.1.3"><times id="S4.Ex1.m1.3.3.3.3.1.1.1.3.1.cmml" xref="S4.Ex1.m1.3.3.3.3.1.1.1.3.1"></times><cn type="integer" id="S4.Ex1.m1.3.3.3.3.1.1.1.3.2.cmml" xref="S4.Ex1.m1.3.3.3.3.1.1.1.3.2">2</cn><ci id="S4.Ex1.m1.3.3.3.3.1.1.1.3.3a.cmml" xref="S4.Ex1.m1.3.3.3.3.1.1.1.3.3"><mtext mathsize="70%" id="S4.Ex1.m1.3.3.3.3.1.1.1.3.3.cmml" xref="S4.Ex1.m1.3.3.3.3.1.1.1.3.3">thr</mtext></ci></apply></apply><apply id="S4.Ex1.m1.4.4.4.4.2.1.cmml" xref="S4.Ex1.m1.4.4.4.4.2.1"><lt id="S4.Ex1.m1.4.4.4.4.2.1.1.cmml" xref="S4.Ex1.m1.4.4.4.4.2.1.1"></lt><ci id="S4.Ex1.m1.4.4.4.4.2.1.2.cmml" xref="S4.Ex1.m1.4.4.4.4.2.1.2">𝑝</ci><ci id="S4.Ex1.m1.4.4.4.4.2.1.3a.cmml" xref="S4.Ex1.m1.4.4.4.4.2.1.3"><mtext id="S4.Ex1.m1.4.4.4.4.2.1.3.cmml" xref="S4.Ex1.m1.4.4.4.4.2.1.3">thr</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.Ex1.m1.4c">\hat{p}=\begin{cases}kp+b,&amp;p\geq\text{thr}\\
\frac{p}{2\text{thr}},&amp;p&lt;\text{thr}\end{cases}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p id="S4.SS5.SSS1.p2.2" class="ltx_p">where <math id="S4.SS5.SSS1.p2.1.m1.3" class="ltx_Math" alttext="k=\frac{1}{2(1-\text{thr})},\;b=1-k" display="inline"><semantics id="S4.SS5.SSS1.p2.1.m1.3a"><mrow id="S4.SS5.SSS1.p2.1.m1.3.3.2" xref="S4.SS5.SSS1.p2.1.m1.3.3.3.cmml"><mrow id="S4.SS5.SSS1.p2.1.m1.2.2.1.1" xref="S4.SS5.SSS1.p2.1.m1.2.2.1.1.cmml"><mi id="S4.SS5.SSS1.p2.1.m1.2.2.1.1.2" xref="S4.SS5.SSS1.p2.1.m1.2.2.1.1.2.cmml">k</mi><mo id="S4.SS5.SSS1.p2.1.m1.2.2.1.1.1" xref="S4.SS5.SSS1.p2.1.m1.2.2.1.1.1.cmml">=</mo><mfrac id="S4.SS5.SSS1.p2.1.m1.1.1" xref="S4.SS5.SSS1.p2.1.m1.1.1.cmml"><mn id="S4.SS5.SSS1.p2.1.m1.1.1.3" xref="S4.SS5.SSS1.p2.1.m1.1.1.3.cmml">1</mn><mrow id="S4.SS5.SSS1.p2.1.m1.1.1.1" xref="S4.SS5.SSS1.p2.1.m1.1.1.1.cmml"><mn id="S4.SS5.SSS1.p2.1.m1.1.1.1.3" xref="S4.SS5.SSS1.p2.1.m1.1.1.1.3.cmml">2</mn><mo lspace="0em" rspace="0em" id="S4.SS5.SSS1.p2.1.m1.1.1.1.2" xref="S4.SS5.SSS1.p2.1.m1.1.1.1.2.cmml">​</mo><mrow id="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1" xref="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.2" xref="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.1" xref="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.1.cmml"><mn id="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.1.2" xref="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.1.2.cmml">1</mn><mo id="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.1.1" xref="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.1.1.cmml">−</mo><mtext id="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.1.3" xref="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.1.3a.cmml">thr</mtext></mrow><mo stretchy="false" id="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.3" xref="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mfrac></mrow><mo rspace="0.447em" id="S4.SS5.SSS1.p2.1.m1.3.3.2.3" xref="S4.SS5.SSS1.p2.1.m1.3.3.3a.cmml">,</mo><mrow id="S4.SS5.SSS1.p2.1.m1.3.3.2.2" xref="S4.SS5.SSS1.p2.1.m1.3.3.2.2.cmml"><mi id="S4.SS5.SSS1.p2.1.m1.3.3.2.2.2" xref="S4.SS5.SSS1.p2.1.m1.3.3.2.2.2.cmml">b</mi><mo id="S4.SS5.SSS1.p2.1.m1.3.3.2.2.1" xref="S4.SS5.SSS1.p2.1.m1.3.3.2.2.1.cmml">=</mo><mrow id="S4.SS5.SSS1.p2.1.m1.3.3.2.2.3" xref="S4.SS5.SSS1.p2.1.m1.3.3.2.2.3.cmml"><mn id="S4.SS5.SSS1.p2.1.m1.3.3.2.2.3.2" xref="S4.SS5.SSS1.p2.1.m1.3.3.2.2.3.2.cmml">1</mn><mo id="S4.SS5.SSS1.p2.1.m1.3.3.2.2.3.1" xref="S4.SS5.SSS1.p2.1.m1.3.3.2.2.3.1.cmml">−</mo><mi id="S4.SS5.SSS1.p2.1.m1.3.3.2.2.3.3" xref="S4.SS5.SSS1.p2.1.m1.3.3.2.2.3.3.cmml">k</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.SSS1.p2.1.m1.3b"><apply id="S4.SS5.SSS1.p2.1.m1.3.3.3.cmml" xref="S4.SS5.SSS1.p2.1.m1.3.3.2"><csymbol cd="ambiguous" id="S4.SS5.SSS1.p2.1.m1.3.3.3a.cmml" xref="S4.SS5.SSS1.p2.1.m1.3.3.2.3">formulae-sequence</csymbol><apply id="S4.SS5.SSS1.p2.1.m1.2.2.1.1.cmml" xref="S4.SS5.SSS1.p2.1.m1.2.2.1.1"><eq id="S4.SS5.SSS1.p2.1.m1.2.2.1.1.1.cmml" xref="S4.SS5.SSS1.p2.1.m1.2.2.1.1.1"></eq><ci id="S4.SS5.SSS1.p2.1.m1.2.2.1.1.2.cmml" xref="S4.SS5.SSS1.p2.1.m1.2.2.1.1.2">𝑘</ci><apply id="S4.SS5.SSS1.p2.1.m1.1.1.cmml" xref="S4.SS5.SSS1.p2.1.m1.1.1"><divide id="S4.SS5.SSS1.p2.1.m1.1.1.2.cmml" xref="S4.SS5.SSS1.p2.1.m1.1.1"></divide><cn type="integer" id="S4.SS5.SSS1.p2.1.m1.1.1.3.cmml" xref="S4.SS5.SSS1.p2.1.m1.1.1.3">1</cn><apply id="S4.SS5.SSS1.p2.1.m1.1.1.1.cmml" xref="S4.SS5.SSS1.p2.1.m1.1.1.1"><times id="S4.SS5.SSS1.p2.1.m1.1.1.1.2.cmml" xref="S4.SS5.SSS1.p2.1.m1.1.1.1.2"></times><cn type="integer" id="S4.SS5.SSS1.p2.1.m1.1.1.1.3.cmml" xref="S4.SS5.SSS1.p2.1.m1.1.1.1.3">2</cn><apply id="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.1.cmml" xref="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1"><minus id="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.1.1.cmml" xref="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.1.1"></minus><cn type="integer" id="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.1.2.cmml" xref="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.1.2">1</cn><ci id="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.1.3a.cmml" xref="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.1.3"><mtext mathsize="70%" id="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.1.3.cmml" xref="S4.SS5.SSS1.p2.1.m1.1.1.1.1.1.1.3">thr</mtext></ci></apply></apply></apply></apply><apply id="S4.SS5.SSS1.p2.1.m1.3.3.2.2.cmml" xref="S4.SS5.SSS1.p2.1.m1.3.3.2.2"><eq id="S4.SS5.SSS1.p2.1.m1.3.3.2.2.1.cmml" xref="S4.SS5.SSS1.p2.1.m1.3.3.2.2.1"></eq><ci id="S4.SS5.SSS1.p2.1.m1.3.3.2.2.2.cmml" xref="S4.SS5.SSS1.p2.1.m1.3.3.2.2.2">𝑏</ci><apply id="S4.SS5.SSS1.p2.1.m1.3.3.2.2.3.cmml" xref="S4.SS5.SSS1.p2.1.m1.3.3.2.2.3"><minus id="S4.SS5.SSS1.p2.1.m1.3.3.2.2.3.1.cmml" xref="S4.SS5.SSS1.p2.1.m1.3.3.2.2.3.1"></minus><cn type="integer" id="S4.SS5.SSS1.p2.1.m1.3.3.2.2.3.2.cmml" xref="S4.SS5.SSS1.p2.1.m1.3.3.2.2.3.2">1</cn><ci id="S4.SS5.SSS1.p2.1.m1.3.3.2.2.3.3.cmml" xref="S4.SS5.SSS1.p2.1.m1.3.3.2.2.3.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.SSS1.p2.1.m1.3c">k=\frac{1}{2(1-\text{thr})},\;b=1-k</annotation></semantics></math> and <span id="S4.SS5.SSS1.p2.2.1" class="ltx_text ltx_markedasmath">thr</span> is the optimal decision boundary on validation.</p>
</div>
<div id="S4.SS5.SSS1.p3" class="ltx_para">
<p id="S4.SS5.SSS1.p3.2" class="ltx_p">This transformation allows to keep the score within <math id="S4.SS5.SSS1.p3.1.m1.2" class="ltx_Math" alttext="[0,1]" display="inline"><semantics id="S4.SS5.SSS1.p3.1.m1.2a"><mrow id="S4.SS5.SSS1.p3.1.m1.2.3.2" xref="S4.SS5.SSS1.p3.1.m1.2.3.1.cmml"><mo stretchy="false" id="S4.SS5.SSS1.p3.1.m1.2.3.2.1" xref="S4.SS5.SSS1.p3.1.m1.2.3.1.cmml">[</mo><mn id="S4.SS5.SSS1.p3.1.m1.1.1" xref="S4.SS5.SSS1.p3.1.m1.1.1.cmml">0</mn><mo id="S4.SS5.SSS1.p3.1.m1.2.3.2.2" xref="S4.SS5.SSS1.p3.1.m1.2.3.1.cmml">,</mo><mn id="S4.SS5.SSS1.p3.1.m1.2.2" xref="S4.SS5.SSS1.p3.1.m1.2.2.cmml">1</mn><mo stretchy="false" id="S4.SS5.SSS1.p3.1.m1.2.3.2.3" xref="S4.SS5.SSS1.p3.1.m1.2.3.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.SS5.SSS1.p3.1.m1.2b"><interval closure="closed" id="S4.SS5.SSS1.p3.1.m1.2.3.1.cmml" xref="S4.SS5.SSS1.p3.1.m1.2.3.2"><cn type="integer" id="S4.SS5.SSS1.p3.1.m1.1.1.cmml" xref="S4.SS5.SSS1.p3.1.m1.1.1">0</cn><cn type="integer" id="S4.SS5.SSS1.p3.1.m1.2.2.cmml" xref="S4.SS5.SSS1.p3.1.m1.2.2">1</cn></interval></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.SSS1.p3.1.m1.2c">[0,1]</annotation></semantics></math>, at the same time, the decision boundary for all models becomes <math id="S4.SS5.SSS1.p3.2.m2.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="S4.SS5.SSS1.p3.2.m2.1a"><mn id="S4.SS5.SSS1.p3.2.m2.1.1" xref="S4.SS5.SSS1.p3.2.m2.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S4.SS5.SSS1.p3.2.m2.1b"><cn type="float" id="S4.SS5.SSS1.p3.2.m2.1.1.cmml" xref="S4.SS5.SSS1.p3.2.m2.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS5.SSS1.p3.2.m2.1c">0.5</annotation></semantics></math>.</p>
</div>
</section>
<section id="S4.SS5.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.5.2 </span>Voting</h4>

<div id="S4.SS5.SSS2.p1" class="ltx_para">
<p id="S4.SS5.SSS2.p1.1" class="ltx_p">Another strategy is to aggregate the binary predictions of the models in an ensemble. The presence of hallucinations was determined by voting models, depending on the number of votes in favor. At the verification stage, we determine the minimum number of model votes required to acknowledge the pair of sentences, model hypothesis and ground truth, as a paraphrase, for example, at least one, two or three models voted in favor. That is, we predicted a hallucination if an insufficient number of models compared to the optimal validation threshold classified the sample as a paraphrase.</p>
</div>
<figure id="S4.T6" class="ltx_table">
<div id="S4.T6.1" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:85.6pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-59.2pt,11.6pt) scale(0.785384138516618,0.785384138516618) ;">
<table id="S4.T6.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S4.T6.1.1.1" class="ltx_tr">
<td id="S4.T6.1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2"><span id="S4.T6.1.1.1.1.1" class="ltx_text ltx_font_bold">Method</span></td>
<td id="S4.T6.1.1.1.2" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2"><span id="S4.T6.1.1.1.2.1" class="ltx_text ltx_font_bold">Models</span></td>
<td id="S4.T6.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S4.T6.1.1.1.3.1" class="ltx_text ltx_font_bold">val</span></td>
<td id="S4.T6.1.1.1.4" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S4.T6.1.1.1.4.1" class="ltx_text ltx_font_bold">test</span></td>
</tr>
<tr id="S4.T6.1.1.2" class="ltx_tr">
<td id="S4.T6.1.1.2.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T6.1.1.2.1.1" class="ltx_text ltx_font_bold">agnostic</span></td>
<td id="S4.T6.1.1.2.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T6.1.1.2.2.1" class="ltx_text ltx_font_bold">aware</span></td>
<td id="S4.T6.1.1.2.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T6.1.1.2.3.1" class="ltx_text ltx_font_bold">agnostic</span></td>
<td id="S4.T6.1.1.2.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t"><span id="S4.T6.1.1.2.4.1" class="ltx_text ltx_font_bold">aware</span></td>
</tr>
<tr id="S4.T6.1.1.3" class="ltx_tr">
<td id="S4.T6.1.1.3.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="2"><span id="S4.T6.1.1.3.1.1" class="ltx_text">Voting</span></td>
<td id="S4.T6.1.1.3.2" class="ltx_td ltx_align_left ltx_border_t">MIS + E5-Mistral + SFT E5-Mistral + all-mpnet + Vectara</td>
<td id="S4.T6.1.1.3.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T6.1.1.3.3.1" class="ltx_text ltx_font_bold">0.85</span></td>
<td id="S4.T6.1.1.3.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T6.1.1.3.4.1" class="ltx_text ltx_font_bold">0.82</span></td>
<td id="S4.T6.1.1.3.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T6.1.1.3.5.1" class="ltx_text ltx_font_bold">0.82</span></td>
<td id="S4.T6.1.1.3.6" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">0.78</td>
</tr>
<tr id="S4.T6.1.1.4" class="ltx_tr">
<td id="S4.T6.1.1.4.1" class="ltx_td ltx_align_left ltx_border_t">MIS + E5-Mistral + SFT E5-Mistral + all-mpnet</td>
<td id="S4.T6.1.1.4.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T6.1.1.4.2.1" class="ltx_text ltx_font_bold">0.85</span></td>
<td id="S4.T6.1.1.4.3" class="ltx_td ltx_align_left ltx_border_t">0.80</td>
<td id="S4.T6.1.1.4.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T6.1.1.4.4.1" class="ltx_text ltx_font_bold">0.82</span></td>
<td id="S4.T6.1.1.4.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">0.77</td>
</tr>
<tr id="S4.T6.1.1.5" class="ltx_tr">
<td id="S4.T6.1.1.5.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" rowspan="2"><span id="S4.T6.1.1.5.1.1" class="ltx_text">Normalized averaging</span></td>
<td id="S4.T6.1.1.5.2" class="ltx_td ltx_align_left ltx_border_t">MIS + E5-Mistral + SFT E5-Mistral</td>
<td id="S4.T6.1.1.5.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S4.T6.1.1.5.3.1" class="ltx_text ltx_font_bold">0.85</span></td>
<td id="S4.T6.1.1.5.4" class="ltx_td ltx_align_left ltx_border_t">0.79</td>
<td id="S4.T6.1.1.5.5" class="ltx_td ltx_align_left ltx_border_t">0.81</td>
<td id="S4.T6.1.1.5.6" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">0.78</td>
</tr>
<tr id="S4.T6.1.1.6" class="ltx_tr">
<td id="S4.T6.1.1.6.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">MIS + all-mpnet + Vectara + TrueTeacher</td>
<td id="S4.T6.1.1.6.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">0.81</td>
<td id="S4.T6.1.1.6.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">0.81</td>
<td id="S4.T6.1.1.6.4" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">0.81</td>
<td id="S4.T6.1.1.6.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_t"><span id="S4.T6.1.1.6.5.1" class="ltx_text ltx_font_bold">0.79</span></td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Ensembling results. Accuracy is observed as evaluation score.</figcaption>
</figure>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">The comparative analysis of the performance across all baselines, our proposed methods, and the leading approaches derived from the official rankings is collated in Table <a href="#S4.T5" title="Table 5 ‣ 4.3 Mutual Implication Score ‣ 4 Methods ‣ SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for Hallucination Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Ensembling</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">According to the results, the Voting approach we developed surpasses all baselines as well as other methods we devised. Nevertheless, the performance narrowly trails the foremost methods from the model-agnostic track in the official rankings by a minimal margin of 0.01. In regards to the application of Ensembling methods, a detailed evaluation delineating the constituent models employed is documented in Table <a href="#S4.T6" title="Table 6 ‣ 4.5.2 Voting ‣ 4.5 Ensembling ‣ 4 Methods ‣ SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for Hallucination Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. It was discerned that the incorporation of our SFT E5-Mistral model enhances overall performance metrics.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>MIS</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Succeeding in performance ranking is the MIS model, refined through training on the PAWS dataset. As previously elucidated, an assortment of configurations was examined, the details of which are exhaustively represented in Table <a href="#S5.T7" title="Table 7 ‣ 5.2 MIS ‣ 5 Results ‣ SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for Hallucination Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>. It is observed that the original MIS model’s performance was not substantially uplifted; modifications yielded no marked increment in accuracy. Nonetheless, it is notable that the integration of the PAWS dataset into the training process marginally amplified accuracy for both tracks. Simultaneously, a minor enhancement on the aware track was observed upon the deployment of the Vectara encoder in place of the RoBERTa model.</p>
</div>
<figure id="S5.T7" class="ltx_table">
<div id="S5.T7.1" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:243pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(88.3pt,-49.5pt) scale(1.68759974903699,1.68759974903699) ;">
<table id="S5.T7.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S5.T7.1.1.1" class="ltx_tr">
<td id="S5.T7.1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt" rowspan="2"><span id="S5.T7.1.1.1.1.1" class="ltx_text ltx_font_bold">Method</span></td>
<td id="S5.T7.1.1.1.2" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S5.T7.1.1.1.2.1" class="ltx_text ltx_font_bold">val</span></td>
<td id="S5.T7.1.1.1.3" class="ltx_td ltx_align_center ltx_border_tt" colspan="2"><span id="S5.T7.1.1.1.3.1" class="ltx_text ltx_font_bold">test</span></td>
</tr>
<tr id="S5.T7.1.1.2" class="ltx_tr">
<td id="S5.T7.1.1.2.1" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T7.1.1.2.1.1" class="ltx_text ltx_font_bold">agnostic</span></td>
<td id="S5.T7.1.1.2.2" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T7.1.1.2.2.1" class="ltx_text ltx_font_bold">aware</span></td>
<td id="S5.T7.1.1.2.3" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T7.1.1.2.3.1" class="ltx_text ltx_font_bold">agnostic</span></td>
<td id="S5.T7.1.1.2.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t"><span id="S5.T7.1.1.2.4.1" class="ltx_text ltx_font_bold">aware</span></td>
</tr>
<tr id="S5.T7.1.1.3" class="ltx_tr">
<td id="S5.T7.1.1.3.1" class="ltx_td ltx_align_left ltx_border_t">MIS (original)</td>
<td id="S5.T7.1.1.3.2" class="ltx_td ltx_align_left ltx_border_t">0.80</td>
<td id="S5.T7.1.1.3.3" class="ltx_td ltx_align_left ltx_border_t">0.78</td>
<td id="S5.T7.1.1.3.4" class="ltx_td ltx_align_left ltx_border_t">0.77</td>
<td id="S5.T7.1.1.3.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t"><span id="S5.T7.1.1.3.5.1" class="ltx_text ltx_font_bold">0.80</span></td>
</tr>
<tr id="S5.T7.1.1.4" class="ltx_tr">
<td id="S5.T7.1.1.4.1" class="ltx_td ltx_align_left ltx_border_t">+ LoRA</td>
<td id="S5.T7.1.1.4.2" class="ltx_td ltx_align_left ltx_border_t">0.79</td>
<td id="S5.T7.1.1.4.3" class="ltx_td ltx_align_left ltx_border_t">0.79</td>
<td id="S5.T7.1.1.4.4" class="ltx_td ltx_align_left ltx_border_t">0.78</td>
<td id="S5.T7.1.1.4.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t"><span id="S5.T7.1.1.4.5.1" class="ltx_text ltx_font_bold">0.80</span></td>
</tr>
<tr id="S5.T7.1.1.5" class="ltx_tr">
<td id="S5.T7.1.1.5.1" class="ltx_td ltx_align_left">+ Vectara</td>
<td id="S5.T7.1.1.5.2" class="ltx_td ltx_align_left">0.79</td>
<td id="S5.T7.1.1.5.3" class="ltx_td ltx_align_left">0.81</td>
<td id="S5.T7.1.1.5.4" class="ltx_td ltx_align_left"><span id="S5.T7.1.1.5.4.1" class="ltx_text ltx_font_bold">0.81</span></td>
<td id="S5.T7.1.1.5.5" class="ltx_td ltx_nopad_r ltx_align_left">0.77</td>
</tr>
<tr id="S5.T7.1.1.6" class="ltx_tr">
<td id="S5.T7.1.1.6.1" class="ltx_td ltx_align_left">+ Single fold</td>
<td id="S5.T7.1.1.6.2" class="ltx_td ltx_align_left">0.78</td>
<td id="S5.T7.1.1.6.3" class="ltx_td ltx_align_left">0.77</td>
<td id="S5.T7.1.1.6.4" class="ltx_td ltx_align_left">0.75</td>
<td id="S5.T7.1.1.6.5" class="ltx_td ltx_nopad_r ltx_align_left">0.78</td>
</tr>
<tr id="S5.T7.1.1.7" class="ltx_tr">
<td id="S5.T7.1.1.7.1" class="ltx_td ltx_align_left">+ PAWS</td>
<td id="S5.T7.1.1.7.2" class="ltx_td ltx_align_left"><span id="S5.T7.1.1.7.2.1" class="ltx_text ltx_font_bold">0.82</span></td>
<td id="S5.T7.1.1.7.3" class="ltx_td ltx_align_left"><span id="S5.T7.1.1.7.3.1" class="ltx_text ltx_font_bold">0.82</span></td>
<td id="S5.T7.1.1.7.4" class="ltx_td ltx_align_left"><span id="S5.T7.1.1.7.4.1" class="ltx_text ltx_font_bold">0.81</span></td>
<td id="S5.T7.1.1.7.5" class="ltx_td ltx_nopad_r ltx_align_left">0.78</td>
</tr>
<tr id="S5.T7.1.1.8" class="ltx_tr">
<td id="S5.T7.1.1.8.1" class="ltx_td ltx_align_left ltx_border_bb">+ Synthetic data</td>
<td id="S5.T7.1.1.8.2" class="ltx_td ltx_align_left ltx_border_bb">0.79</td>
<td id="S5.T7.1.1.8.3" class="ltx_td ltx_align_left ltx_border_bb">0.77</td>
<td id="S5.T7.1.1.8.4" class="ltx_td ltx_align_left ltx_border_bb">0.77</td>
<td id="S5.T7.1.1.8.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb">0.74</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7: </span>MIS ablation study results. Accuracy is observed as evaluation score.</figcaption>
</figure>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>SFT E5-Mistral</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">The next approach by performance is our SFT E5-Mistral. The accuracy for different configurations in our synthetic data experiments can be found in Table <a href="#S5.T8" title="Table 8 ‣ 5.3 SFT E5-Mistral ‣ 5 Results ‣ SmurfCat at SemEval-2024 Task 6: Leveraging Synthetic Data for Hallucination Detection" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. The combination of PG and DM synthetic data achieves the best results. Unexpectedly, the use of synthetic data from GPT-4 does not yield as good outcomes. This suggests that GPT-4’s synthetic data may contain some inherent biases.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">We carried out a detailed evaluation of a particular subset and identified probable causes for bias:</p>
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p">For texts generated without hallucinations, they tend to be overly formal and intricate.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p">In cases with hallucinations, numerous instances are exceedingly convoluted, sometimes to the extent that the sentences convey the opposite meaning. Our investigation revealed that such hallucinations might not be readily detectable.</p>
</div>
</li>
</ul>
<p id="S5.SS3.p2.2" class="ltx_p">It is also clear that relying solely on DM synthetic data does not sufficiently address other tasks. By contrast, a model checkpoint trained with PG synthetic data shows promising performance. Just like the MIS approach, it appears that having PG data is sufficient to address hallucinations in other tasks, provided that the target is accessible.</p>
</div>
<figure id="S5.T8" class="ltx_table">
<table id="S5.T8.1" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S5.T8.1.1" class="ltx_tr">
<td id="S5.T8.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="S5.T8.1.1.1.1" class="ltx_text ltx_font_bold">Source</span></td>
<td id="S5.T8.1.1.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="S5.T8.1.1.2.1" class="ltx_text ltx_font_bold">Subset</span></td>
<td id="S5.T8.1.1.3" class="ltx_td ltx_align_left ltx_border_tt"><span id="S5.T8.1.1.3.1" class="ltx_text ltx_font_bold">agnostic</span></td>
<td id="S5.T8.1.1.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt"><span id="S5.T8.1.1.4.1" class="ltx_text ltx_font_bold">aware</span></td>
</tr>
<tr id="S5.T8.1.2" class="ltx_tr">
<td id="S5.T8.1.2.1" class="ltx_td ltx_align_left ltx_border_t">GPT</td>
<td id="S5.T8.1.2.2" class="ltx_td ltx_align_left ltx_border_t">PG</td>
<td id="S5.T8.1.2.3" class="ltx_td ltx_align_left ltx_border_t">0.76</td>
<td id="S5.T8.1.2.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">0.72</td>
</tr>
<tr id="S5.T8.1.3" class="ltx_tr">
<td id="S5.T8.1.3.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="7"><span id="S5.T8.1.3.1.1" class="ltx_text">LLaMA</span></td>
<td id="S5.T8.1.3.2" class="ltx_td ltx_align_left ltx_border_t">PG</td>
<td id="S5.T8.1.3.3" class="ltx_td ltx_align_left ltx_border_t">0.81</td>
<td id="S5.T8.1.3.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">0.75</td>
</tr>
<tr id="S5.T8.1.4" class="ltx_tr">
<td id="S5.T8.1.4.1" class="ltx_td ltx_align_left">DM</td>
<td id="S5.T8.1.4.2" class="ltx_td ltx_align_left">0.63</td>
<td id="S5.T8.1.4.3" class="ltx_td ltx_nopad_r ltx_align_left">0.51</td>
</tr>
<tr id="S5.T8.1.5" class="ltx_tr">
<td id="S5.T8.1.5.1" class="ltx_td ltx_align_left">MT</td>
<td id="S5.T8.1.5.2" class="ltx_td ltx_align_left">0.79</td>
<td id="S5.T8.1.5.3" class="ltx_td ltx_nopad_r ltx_align_left">0.71</td>
</tr>
<tr id="S5.T8.1.6" class="ltx_tr">
<td id="S5.T8.1.6.1" class="ltx_td ltx_align_left">PG + DM</td>
<td id="S5.T8.1.6.2" class="ltx_td ltx_align_left"><span id="S5.T8.1.6.2.1" class="ltx_text ltx_font_bold">0.83</span></td>
<td id="S5.T8.1.6.3" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S5.T8.1.6.3.1" class="ltx_text ltx_font_bold">0.77</span></td>
</tr>
<tr id="S5.T8.1.7" class="ltx_tr">
<td id="S5.T8.1.7.1" class="ltx_td ltx_align_left">PG + MT</td>
<td id="S5.T8.1.7.2" class="ltx_td ltx_align_left">0.81</td>
<td id="S5.T8.1.7.3" class="ltx_td ltx_nopad_r ltx_align_left">0.76</td>
</tr>
<tr id="S5.T8.1.8" class="ltx_tr">
<td id="S5.T8.1.8.1" class="ltx_td ltx_align_left">MT + DM</td>
<td id="S5.T8.1.8.2" class="ltx_td ltx_align_left">0.75</td>
<td id="S5.T8.1.8.3" class="ltx_td ltx_nopad_r ltx_align_left">0.71</td>
</tr>
<tr id="S5.T8.1.9" class="ltx_tr">
<td id="S5.T8.1.9.1" class="ltx_td ltx_align_left">All</td>
<td id="S5.T8.1.9.2" class="ltx_td ltx_align_left">0.77</td>
<td id="S5.T8.1.9.3" class="ltx_td ltx_nopad_r ltx_align_left">0.71</td>
</tr>
<tr id="S5.T8.1.10" class="ltx_tr">
<td id="S5.T8.1.10.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">GPT + LLaMA</td>
<td id="S5.T8.1.10.2" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">All</td>
<td id="S5.T8.1.10.3" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t">0.77</td>
<td id="S5.T8.1.10.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb ltx_border_t">0.73</td>
</tr>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 8: </span>Synthetic data ablation study on E5-Mistral. Accuracy is observed as evaluation score.</figcaption>
</figure>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Black-box baselines</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">All our advanced methods outperform black-box baselines on model-agnostic track. Even though, we observe that the E5-Mistral and MIS methods sets a solid baseline on model-agnostic track, maintaining a high level of performance even without any fine-tuning. Considering model-aware track, all baseline models except of GPT-4 show similar performance. The GPT-4 model does not do as well as the others in terms of the average score with our specific prompts. Finally, there is the official baseline that our approaches outperform.</p>
</div>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5 </span>Content Preservation Measures</h3>

<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.1" class="ltx_p">Across preservation measures, SimCSE demonstrates the most notable results. In the model-agnostic track, it performs at the same level as more sophisticated approaches such as TrueTeacher, Vectara, or E5 Mistral, without any fine-tuning. However, other preservation measures do not perform as well. Most of them, with the exception of BLEURT, perform even worse than the official baseline in the model-agnostic track.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We conducted a comparative analysis involving six baseline models (MIS, E5-Mistral, Vectara, TrueTeacher, GPT-4, and the official baseline from the participant kit) alongside four sophisticated approaches (Voting and Normalized Averaging in Ensembling, as well as the refined MIS and SFT E5-Mistral). Of all methods evaluated, Ensembling demonstrated the highest performance. Nonetheless, the refined MIS and the SFT E5-Mistral exhibited only a minor shortfall in performance when compared to these leading methodologies.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">Indeed, there appear to be several avenues for enhancing our synthetic data to potentially exceed the performance of other methods:</p>
</div>
<div id="S6.p3" class="ltx_para">
<ul id="S6.I1" class="ltx_itemize">
<li id="S6.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i1.p1" class="ltx_para">
<p id="S6.I1.i1.p1.1" class="ltx_p">Instead of training separate adapters for each task, centralized training with one adapter across multiple tasks could enrich the learning context and expand the size of the training dataset.</p>
</div>
</li>
<li id="S6.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i2.p1" class="ltx_para">
<p id="S6.I1.i2.p1.1" class="ltx_p">Exploring a range of other models, such as Mistral-7b <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a href="#bib.bib8" title="" class="ltx_ref">2023</a>)</cite>, Mixtral-8x7b<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">¶</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">¶</sup><span class="ltx_tag ltx_tag_note">¶</span><a target="_blank" href="https://huggingface.co/mistralai/Mixtral-8x7B-v0.1" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://huggingface.co/mistralai/Mixtral-8x7B-v0.1</a></span></span></span>, or LLaMA models of various larger sizes (LLaMA-13b, LLaMA-30b), could identify more efficient architectures or models that are better suited to handle the synthetic data effectively.</p>
</div>
</li>
<li id="S6.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S6.I1.i3.p1" class="ltx_para">
<p id="S6.I1.i3.p1.1" class="ltx_p">For improving the quality of GPT-generated synthetic data, incorporating a more extensive range of examples within few-shot prompts and providing detailed explanations for the <span id="S6.I1.i3.p1.1.1" class="ltx_text ltx_font_italic">correct</span> samples could help in mitigating bias and increasing the fidelity of the generated data.</p>
</div>
</li>
</ul>
</div>
<div id="S6.p4" class="ltx_para">
<p id="S6.p4.1" class="ltx_p">The potential use of our adapters to generate both positive and negative samples aimed at a specific target is indeed promising. By assembling datasets that offer these contrasting examples, we could refine the training process through contrastive fine-tuning. Such a method is hypothesized to yield superior performance by facilitating the model’s ability to discern and learn from the nuanced differences between correct and incorrect instances.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Babakov et al. (2022)</span>
<span class="ltx_bibblock">
Nikolay Babakov, David Dale, Varvara Logacheva, and Alexander Panchenko. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.acl-srw.23" title="" class="ltx_ref ltx_href">A large-scale computational study of content preservation measures for text style transfer and paraphrase generation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop</em>, pages 300–321, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Banerjee and Lavie (2005)</span>
<span class="ltx_bibblock">
Satanjeev Banerjee and Alon Lavie. 2005.

</span>
<span class="ltx_bibblock">Meteor: An automatic metric for mt evaluation with improved correlation with human judgments.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization</em>, pages 65–72.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al. (2022)</span>
<span class="ltx_bibblock">
Fangxiaoyu Feng, Yinfei Yang, Daniel Cer, Naveen Arivazhagan, and Wei Wang. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2022.acl-long.62" title="" class="ltx_ref ltx_href">Language-agnostic BERT sentence embedding</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 878–891, Dublin, Ireland. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al. (2021)</span>
<span class="ltx_bibblock">
Tianyu Gao, Xingcheng Yao, and Danqi Chen. 2021.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2021.emnlp-main.552" title="" class="ltx_ref ltx_href">SimCSE: Simple contrastive learning of sentence embeddings</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing</em>, pages 6894–6910, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gekhman et al. (2023)</span>
<span class="ltx_bibblock">
Zorik Gekhman, Jonathan Herzig, Roee Aharoni, Chen Elkind, and Idan Szpektor. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2023.emnlp-main.127" title="" class="ltx_ref ltx_href">TrueTeacher: Learning factual consistency evaluation with large language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing</em>, pages 2053–2070, Singapore. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2022)</span>
<span class="ltx_bibblock">
Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu Chen. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://openreview.net/forum?id=nZeVKeeFYf9" title="" class="ltx_ref ltx_href">LoRA: Low-rank adaptation of large language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al. (2023)</span>
<span class="ltx_bibblock">
Lei Huang, Weijiang Yu, Weitao Ma, Weihong Zhong, Zhangyin Feng, Haotian Wang, Qianglong Chen, Weihua Peng, Xiaocheng Feng, Bing Qin, and Ting Liu. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2311.05232" title="" class="ltx_ref ltx_href">A survey on hallucination in large language models: Principles, taxonomy, challenges, and open questions</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2311.05232.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2023)</span>
<span class="ltx_bibblock">
Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh Chaplot, Diego de Las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample, Lucile Saulnier, Lélio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao, Thibaut Lavril, Thomas Wang, Timothée Lacroix, and William El Sayed. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2310.06825" title="" class="ltx_ref ltx_href">Mistral 7b</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2310.06825.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mickus et al. (2024)</span>
<span class="ltx_bibblock">
Timothee Mickus, Elaine Zosa, Raúl Vázquez, Teemu Vahtola, Jörg Tiedemann, Vincent Segonne, Alessandro Raganato, and Marianna Apidianaki. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://aclanthology.org/2024.semeval2024-1.270" title="" class="ltx_ref ltx_href">Semeval-2024 shared task 6: Shroom, a shared-task on hallucinations and related observable overgeneration mistakes</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 18th International Workshop on Semantic Evaluation (SemEval-2024)</em>, pages 1980–1994, Mexico City, Mexico. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Muennighoff et al. (2023)</span>
<span class="ltx_bibblock">
Niklas Muennighoff, Nouamane Tazi, Loïc Magne, and Nils Reimers. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2023.EACL-MAIN.148" title="" class="ltx_ref ltx_href">MTEB: massive text embedding benchmark</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, EACL 2023, Dubrovnik, Croatia, May 2-6, 2023</em>, pages 2006–2029. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nie et al. (2020)</span>
<span class="ltx_bibblock">
Yixin Nie, Adina Williams, Emily Dinan, Mohit Bansal, Jason Weston, and Douwe Kiela. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/V1/2020.ACL-MAIN.441" title="" class="ltx_ref ltx_href">Adversarial NLI: A new benchmark for natural language understanding</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, ACL 2020, Online, July 5-10, 2020</em>, pages 4885–4901. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2303.08774" title="" class="ltx_ref ltx_href">GPT-4 technical report</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2303.08774.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et al. (2002)</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.3115/1073083.1073135" title="" class="ltx_ref ltx_href">Bleu: a method for automatic evaluation of machine translation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</em>, pages 311–318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Popović (2015)</span>
<span class="ltx_bibblock">
Maja Popović. 2015.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/W15-3049" title="" class="ltx_ref ltx_href">chrF: character n-gram F-score for automatic MT evaluation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Tenth Workshop on Statistical Machine Translation</em>, pages 392–395, Lisbon, Portugal. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sellam et al. (2020)</span>
<span class="ltx_bibblock">
Thibault Sellam, Dipanjan Das, and Ankur Parikh. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/2020.acl-main.704" title="" class="ltx_ref ltx_href">BLEURT: Learning robust metrics for text generation</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em>, pages 7881–7892, Online. Association for Computational Linguistics.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sharma et al. (2019)</span>
<span class="ltx_bibblock">
Lakshay Sharma, Laura Graesser, Nikita Nangia, and Utku Evci. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:195776066" title="" class="ltx_ref ltx_href">Natural language understanding with the quora question pairs dataset</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/1907.01041.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton-Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller, Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov, Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi, Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor, Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie Kambadur, Sharan Narang, Aurélien Rodriguez, Robert Stojnic, Sergey Edunov,
and Thomas Scialom. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2307.09288" title="" class="ltx_ref ltx_href">Llama 2: Open foundation and fine-tuned chat models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2307.09288.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022)</span>
<span class="ltx_bibblock">
Liang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder, and Furu Wei. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/ARXIV.2212.03533" title="" class="ltx_ref ltx_href">Text embeddings by weakly-supervised contrastive pre-training</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">CoRR</em>, abs/2212.03533.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2019)</span>
<span class="ltx_bibblock">
Yuan Zhang, Jason Baldridge, and Luheng He. 2019.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.18653/v1/N19-1131" title="" class="ltx_ref ltx_href">PAWS: Paraphrase adversaries from word scrambling</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</em>, pages 1298–1308, Minneapolis, Minnesota. Association for Computational Linguistics.

</span>
</li>
</ul>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>GPT-4 prompt for PG task evaluation</h2>

<figure id="A1.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="A1.F2.1" class="ltx_ERROR ltx_figure_panel undefined">{spverbatim}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="A1.F2.2" class="ltx_p ltx_figure_panel">Read the source sentence and the paraphrased hypothesis and answer whether there are any hallucinations or related observable overgeneration errors for the paraphrasing task.
Before answering, think step by step and write why you chose the answer you did.
Answer the last string with ’The hypothesis is correct’ if there are no hallucinations or misgenerations. Otherwise, answer with ’The hypothesis is false’.</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="A1.F2.3" class="ltx_p ltx_figure_panel">Example 1:
Source sentence: "The European Parliament does not approve the budget."
Paraphrased hypothesis: "The budget cannot be adopted against the will of the European Parliament."
The hypothesis is false</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="A1.F2.4" class="ltx_p ltx_figure_panel">Example 2:
Source sentence: "Everyone is capable of enjoying a good education in a society."
Paraphrased hypothesis: "We must create a society where everyone is able to enjoy a good education."
The hypothesis is correct</p>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Prompt for GPT-4 evaluation on PG task.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>GPT-4 prompt for synthetic paraphrased data generation with hallucinations</h2>

<figure id="A2.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="A2.F3.1" class="ltx_ERROR ltx_figure_panel undefined">{spverbatim}</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="A2.F3.2" class="ltx_p ltx_figure_panel">Your aim is to produce an incorrectly paraphrased sentence that contains a hallucination for the given source sentence. Hallucinations in a paraphrase can add new information that wasn’t present in the source sentence, or exclude some important information, or reverse the meaning of the source sentence. Remember that reversing source sentence has the lowest level of priority, so use it only if there is no other way to make a hallucination. Usually it’s much better to misrepresent some information, add new or exclude something important. If there is some quantitative information in the source, feel free to change them slightly. Complete the task using the examples below. The examples also show the correct paraphrase for the source sentences. Note that there are no hallucinations in the correct paraphrase, whereas your aim is to corrupt the source and produce a false paraphrase.</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="A2.F3.3" class="ltx_p ltx_figure_panel">Examples:
Source: "I have a permit."
The correct paraphrase: "Uh, I’m validated."
The incorrect paraphrase: "I have a permit to carry it."
Explanation: The incorrect paraphrase adds information that is not present in the source sentence ("to carry it")</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="A2.F3.4" class="ltx_p ltx_figure_panel">Source: "Easy, easy."
The correct paraphrase: "Watch it now."
The incorrect paraphrase: "The process is easy."
Explanation: The incorrect paraphrase introduces additional information ("The process is")</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="A2.F3.5" class="ltx_p ltx_figure_panel">Source: "A five, six, seven, eight."
The correct paraphrase: "And 5, 6, 7, 8."
The incorrect paraphrase: "A number between five and eight."
Explanation: While the source sentence is a rhythmic count or sequence of specific numbers, the incorrect paraphrase generalizes it to "a number between five and eight".</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="A2.F3.6" class="ltx_p ltx_figure_panel">Source: "A lot safer that way."
The correct paraphrase: "Because it’s safer."
The incorrect paraphrase: "That is a safer way to travel."
Explanation: The major hallucination lies in the addition of "That is," which wasn’t present in the original source sentence. This introduces a new element and changes the focus from the general concept of safety to a specific way of travel</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="A2.F3.7" class="ltx_p ltx_figure_panel">Source: "You’re a scam artist."
The correct paraphrase: "You are an imposter."
The incorrect paraphrase: "You’re not a good scam artist."
Explanation: While the source sentence simply states "You’re a scam artist," the incorrect paraphrase implies a judgment on the person’s skill as a scam artist</p>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="A2.F3.8" class="ltx_p ltx_figure_panel">Don’t answer now, read the source and think step by step how to make a false paraphrase for the source sentence. Before answering, provide several examples with explanations and choose the best one. Answer starting with ’The incorrect paraphrase:</p>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Prompt for PG data with hallucinations generation using GPT-4.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Synthetic data examples</h2>

<figure id="A3.T9" class="ltx_table">
<div id="A3.T9.1" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:312.7pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-58.5pt,42.1pt) scale(0.787563349270715,0.787563349270715) ;">
<table id="A3.T9.1.1" class="ltx_tabular ltx_align_middle">
<tr id="A3.T9.1.1.1" class="ltx_tr">
<td id="A3.T9.1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="A3.T9.1.1.1.1.1" class="ltx_text ltx_font_bold">Task</span></td>
<td id="A3.T9.1.1.1.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="A3.T9.1.1.1.2.1" class="ltx_text ltx_font_bold">Target</span></td>
<td id="A3.T9.1.1.1.3" class="ltx_td ltx_align_left ltx_border_tt"><span id="A3.T9.1.1.1.3.1" class="ltx_text ltx_font_bold">Hypothesis</span></td>
<td id="A3.T9.1.1.1.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt"><span id="A3.T9.1.1.1.4.1" class="ltx_text ltx_font_bold">Label</span></td>
</tr>
<tr id="A3.T9.1.1.2" class="ltx_tr">
<td id="A3.T9.1.1.2.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="7"><span id="A3.T9.1.1.2.1.1" class="ltx_text">MT</span></td>
<td id="A3.T9.1.1.2.2" class="ltx_td ltx_align_left ltx_border_t">I know you kissed Tom.</td>
<td id="A3.T9.1.1.2.3" class="ltx_td ltx_align_left ltx_border_t">I know you’re going to beat someone.</td>
<td id="A3.T9.1.1.2.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">Hallucination</td>
</tr>
<tr id="A3.T9.1.1.3" class="ltx_tr">
<td id="A3.T9.1.1.3.1" class="ltx_td ltx_align_left">I’ll talk to Tom today.</td>
<td id="A3.T9.1.1.3.2" class="ltx_td ltx_align_left">I’ll talk to John tomorrow.</td>
<td id="A3.T9.1.1.3.3" class="ltx_td ltx_nopad_r ltx_align_left">Hallucination</td>
</tr>
<tr id="A3.T9.1.1.4" class="ltx_tr">
<td id="A3.T9.1.1.4.1" class="ltx_td ltx_align_left">I should’ve waited.</td>
<td id="A3.T9.1.1.4.2" class="ltx_td ltx_align_left">I’ll be better tomorrow.</td>
<td id="A3.T9.1.1.4.3" class="ltx_td ltx_nopad_r ltx_align_left">Hallucination</td>
</tr>
<tr id="A3.T9.1.1.5" class="ltx_tr">
<td id="A3.T9.1.1.5.1" class="ltx_td ltx_align_left">He was mistaken for his younger brother</td>
<td id="A3.T9.1.1.5.2" class="ltx_td ltx_align_left">He was taken for his brother.</td>
<td id="A3.T9.1.1.5.3" class="ltx_td ltx_nopad_r ltx_align_left">Not Hallucination</td>
</tr>
<tr id="A3.T9.1.1.6" class="ltx_tr">
<td id="A3.T9.1.1.6.1" class="ltx_td ltx_align_left">She passed the examination.</td>
<td id="A3.T9.1.1.6.2" class="ltx_td ltx_align_left">She successfully completed the certification.</td>
<td id="A3.T9.1.1.6.3" class="ltx_td ltx_nopad_r ltx_align_left">Not Hallucination</td>
</tr>
<tr id="A3.T9.1.1.7" class="ltx_tr">
<td id="A3.T9.1.1.7.1" class="ltx_td ltx_align_left">A plane popped up out of nowhere.</td>
<td id="A3.T9.1.1.7.2" class="ltx_td ltx_align_left">A plane just came out of the blue.</td>
<td id="A3.T9.1.1.7.3" class="ltx_td ltx_nopad_r ltx_align_left">Not Hallucination</td>
</tr>
<tr id="A3.T9.1.1.8" class="ltx_tr">
<td id="A3.T9.1.1.8.1" class="ltx_td ltx_align_left">No one has seen Tom since.</td>
<td id="A3.T9.1.1.8.2" class="ltx_td ltx_align_left">No one has seen Tom for a long time.</td>
<td id="A3.T9.1.1.8.3" class="ltx_td ltx_nopad_r ltx_align_left">Not Hallucination</td>
</tr>
<tr id="A3.T9.1.1.9" class="ltx_tr">
<td id="A3.T9.1.1.9.1" class="ltx_td ltx_align_left ltx_border_t" rowspan="7"><span id="A3.T9.1.1.9.1.1" class="ltx_text">PG</span></td>
<td id="A3.T9.1.1.9.2" class="ltx_td ltx_align_left ltx_border_t">Wanna talk?</td>
<td id="A3.T9.1.1.9.3" class="ltx_td ltx_align_left ltx_border_t">Would you want to talk with me?</td>
<td id="A3.T9.1.1.9.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">Not Hallucination</td>
</tr>
<tr id="A3.T9.1.1.10" class="ltx_tr">
<td id="A3.T9.1.1.10.1" class="ltx_td ltx_align_left">We must not allow this to happen.</td>
<td id="A3.T9.1.1.10.2" class="ltx_td ltx_align_left">We must prevent this from happening.</td>
<td id="A3.T9.1.1.10.3" class="ltx_td ltx_nopad_r ltx_align_left">Not Hallucination</td>
</tr>
<tr id="A3.T9.1.1.11" class="ltx_tr">
<td id="A3.T9.1.1.11.1" class="ltx_td ltx_align_left">Have you found her?</td>
<td id="A3.T9.1.1.11.2" class="ltx_td ltx_align_left">Have you seen her?</td>
<td id="A3.T9.1.1.11.3" class="ltx_td ltx_nopad_r ltx_align_left">Hallucination</td>
</tr>
<tr id="A3.T9.1.1.12" class="ltx_tr">
<td id="A3.T9.1.1.12.1" class="ltx_td ltx_align_left">A word of advice.</td>
<td id="A3.T9.1.1.12.2" class="ltx_td ltx_align_left">Give me some advice.</td>
<td id="A3.T9.1.1.12.3" class="ltx_td ltx_nopad_r ltx_align_left">Not Hallucination</td>
</tr>
<tr id="A3.T9.1.1.13" class="ltx_tr">
<td id="A3.T9.1.1.13.1" class="ltx_td ltx_align_left">Hold your course.</td>
<td id="A3.T9.1.1.13.2" class="ltx_td ltx_align_left">You’re going the wrong way, man.</td>
<td id="A3.T9.1.1.13.3" class="ltx_td ltx_nopad_r ltx_align_left">Hallucination</td>
</tr>
<tr id="A3.T9.1.1.14" class="ltx_tr">
<td id="A3.T9.1.1.14.1" class="ltx_td ltx_align_left">Can I take a message?</td>
<td id="A3.T9.1.1.14.2" class="ltx_td ltx_align_left">Can I take a message for you,</td>
<td id="A3.T9.1.1.14.3" class="ltx_td ltx_nopad_r ltx_align_left">Not Hallucination</td>
</tr>
<tr id="A3.T9.1.1.15" class="ltx_tr">
<td id="A3.T9.1.1.15.1" class="ltx_td ltx_align_left">My job?</td>
<td id="A3.T9.1.1.15.2" class="ltx_td ltx_align_left">My job is to carry out the trash.</td>
<td id="A3.T9.1.1.15.3" class="ltx_td ltx_nopad_r ltx_align_left">Hallucination</td>
</tr>
<tr id="A3.T9.1.1.16" class="ltx_tr">
<td id="A3.T9.1.1.16.1" class="ltx_td ltx_align_left ltx_border_bb ltx_border_t" rowspan="7"><span id="A3.T9.1.1.16.1.1" class="ltx_text">DM</span></td>
<td id="A3.T9.1.1.16.2" class="ltx_td ltx_align_left ltx_border_t">Delicious .</td>
<td id="A3.T9.1.1.16.3" class="ltx_td ltx_align_left ltx_border_t">(scrambley) A scrambley dish.</td>
<td id="A3.T9.1.1.16.4" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">Hallucination</td>
</tr>
<tr id="A3.T9.1.1.17" class="ltx_tr">
<td id="A3.T9.1.1.17.1" class="ltx_td ltx_align_left">To increase the level or amount of .</td>
<td id="A3.T9.1.1.17.2" class="ltx_td ltx_align_left">To increase in volume.</td>
<td id="A3.T9.1.1.17.3" class="ltx_td ltx_nopad_r ltx_align_left">Not Hallucination</td>
</tr>
<tr id="A3.T9.1.1.18" class="ltx_tr">
<td id="A3.T9.1.1.18.1" class="ltx_td ltx_align_left">Causing the air to be hot .</td>
<td id="A3.T9.1.1.18.2" class="ltx_td ltx_align_left">Hot. Something that is hot.</td>
<td id="A3.T9.1.1.18.3" class="ltx_td ltx_nopad_r ltx_align_left">Not Hallucination</td>
</tr>
<tr id="A3.T9.1.1.19" class="ltx_tr">
<td id="A3.T9.1.1.19.1" class="ltx_td ltx_align_left">(slang, derogatory) schizoid, schizophrenic; crazy</td>
<td id="A3.T9.1.1.19.2" class="ltx_td ltx_align_left">(transitive) Crazy</td>
<td id="A3.T9.1.1.19.3" class="ltx_td ltx_nopad_r ltx_align_left">Not Hallucination</td>
</tr>
<tr id="A3.T9.1.1.20" class="ltx_tr">
<td id="A3.T9.1.1.20.1" class="ltx_td ltx_align_left">Covered with petals or petal-like objects.</td>
<td id="A3.T9.1.1.20.2" class="ltx_td ltx_align_left">planted.</td>
<td id="A3.T9.1.1.20.3" class="ltx_td ltx_nopad_r ltx_align_left">Hallucination</td>
</tr>
<tr id="A3.T9.1.1.21" class="ltx_tr">
<td id="A3.T9.1.1.21.1" class="ltx_td ltx_align_left">Alternative form of midstream</td>
<td id="A3.T9.1.1.21.2" class="ltx_td ltx_align_left">Middle stream</td>
<td id="A3.T9.1.1.21.3" class="ltx_td ltx_nopad_r ltx_align_left">Not Hallucination</td>
</tr>
<tr id="A3.T9.1.1.22" class="ltx_tr">
<td id="A3.T9.1.1.22.1" class="ltx_td ltx_align_left ltx_border_bb">To require</td>
<td id="A3.T9.1.1.22.2" class="ltx_td ltx_align_left ltx_border_bb">take time to finish something.</td>
<td id="A3.T9.1.1.22.3" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb">Hallucination</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 9: </span>Sample of synthetic data generated using LLaMA2-7B</figcaption>
</figure>
<figure id="A3.T10" class="ltx_table">
<div id="A3.T10.1" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:106.9pt;vertical-align:-0.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-113.9pt,27.9pt) scale(0.655674145243337,0.655674145243337) ;">
<table id="A3.T10.1.1" class="ltx_tabular ltx_align_middle">
<tr id="A3.T10.1.1.1" class="ltx_tr">
<td id="A3.T10.1.1.1.1" class="ltx_td ltx_align_left ltx_border_tt"><span id="A3.T10.1.1.1.1.1" class="ltx_text ltx_font_bold">Target</span></td>
<td id="A3.T10.1.1.1.2" class="ltx_td ltx_align_left ltx_border_tt"><span id="A3.T10.1.1.1.2.1" class="ltx_text ltx_font_bold">Hypothesis</span></td>
<td id="A3.T10.1.1.1.3" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_tt"><span id="A3.T10.1.1.1.3.1" class="ltx_text ltx_font_bold">Label</span></td>
</tr>
<tr id="A3.T10.1.1.2" class="ltx_tr">
<td id="A3.T10.1.1.2.1" class="ltx_td ltx_align_left ltx_border_t">That cannot be in our interest!</td>
<td id="A3.T10.1.1.2.2" class="ltx_td ltx_align_left ltx_border_t">It’s not beneficial for us!</td>
<td id="A3.T10.1.1.2.3" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">Not hallucination</td>
</tr>
<tr id="A3.T10.1.1.3" class="ltx_tr">
<td id="A3.T10.1.1.3.1" class="ltx_td ltx_align_left">The written language should be made more user-friendly.</td>
<td id="A3.T10.1.1.3.2" class="ltx_td ltx_align_left">The spoken language should be made more user-friendly.</td>
<td id="A3.T10.1.1.3.3" class="ltx_td ltx_nopad_r ltx_align_left">Hallucination</td>
</tr>
<tr id="A3.T10.1.1.4" class="ltx_tr">
<td id="A3.T10.1.1.4.1" class="ltx_td ltx_align_left">I do not think that is quite what the agreement is.</td>
<td id="A3.T10.1.1.4.2" class="ltx_td ltx_align_left">I do not think that’s the contract we signed.</td>
<td id="A3.T10.1.1.4.3" class="ltx_td ltx_nopad_r ltx_align_left">Hallucination</td>
</tr>
<tr id="A3.T10.1.1.5" class="ltx_tr">
<td id="A3.T10.1.1.5.1" class="ltx_td ltx_align_left">The vote will take place tomorrow at 11.30 a.m.</td>
<td id="A3.T10.1.1.5.2" class="ltx_td ltx_align_left">Tomorrow, the voting process is scheduled for 11.30 in the morning.</td>
<td id="A3.T10.1.1.5.3" class="ltx_td ltx_nopad_r ltx_align_left">Not hallucination</td>
</tr>
<tr id="A3.T10.1.1.6" class="ltx_tr">
<td id="A3.T10.1.1.6.1" class="ltx_td ltx_align_left">Mrs Green, you have the floor.</td>
<td id="A3.T10.1.1.6.2" class="ltx_td ltx_align_left">Mrs. Green, you own the flooring.</td>
<td id="A3.T10.1.1.6.3" class="ltx_td ltx_nopad_r ltx_align_left">Hallucination</td>
</tr>
<tr id="A3.T10.1.1.7" class="ltx_tr">
<td id="A3.T10.1.1.7.1" class="ltx_td ltx_align_left">I was also in a northern industrial suburb in Milan.</td>
<td id="A3.T10.1.1.7.2" class="ltx_td ltx_align_left">I too have been to one of Milan’s northern industrial neighborhoods.</td>
<td id="A3.T10.1.1.7.3" class="ltx_td ltx_nopad_r ltx_align_left">Not hallucination</td>
</tr>
<tr id="A3.T10.1.1.8" class="ltx_tr">
<td id="A3.T10.1.1.8.1" class="ltx_td ltx_align_left">Mr President, I should like to make a further remark.</td>
<td id="A3.T10.1.1.8.2" class="ltx_td ltx_align_left">Mr. President, I would like to add another comment.</td>
<td id="A3.T10.1.1.8.3" class="ltx_td ltx_nopad_r ltx_align_left">Not hallucination</td>
</tr>
<tr id="A3.T10.1.1.9" class="ltx_tr">
<td id="A3.T10.1.1.9.1" class="ltx_td ltx_align_left ltx_border_bb">Mrs Bonino tells me that no response is necessary.</td>
<td id="A3.T10.1.1.9.2" class="ltx_td ltx_align_left ltx_border_bb">Mrs. Bonino informed me a response isn’t required.</td>
<td id="A3.T10.1.1.9.3" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb">Not hallucination</td>
</tr>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 10: </span>Sample of synthetic data generated using GPT-4</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2404.06136" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2404.06137" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2404.06137">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2404.06137" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2404.06138" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sun May  5 15:11:57 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
