<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2407.01561] Synthetic Data in Radiological Imaging: Current State and Future Outlook</title><meta property="og:description" content="A key challenge for the development and deployment of artificial intelligence (AI) solutions in radiology is solving the associated data limitations. Obtaining sufficient and representative patient datasets with approp…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Synthetic Data in Radiological Imaging: Current State and Future Outlook">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Synthetic Data in Radiological Imaging: Current State and Future Outlook">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2407.01561">

<!--Generated on Mon Aug  5 13:43:35 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document" style="color:#000000;"> Synthetic Data in Radiological Imaging: 
<br class="ltx_break">Current State and Future Outlook</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname"><span id="id1.1.id1" class="ltx_text ltx_font_italic">E. Sizikova<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note"><span id="footnote1.1.1.1" class="ltx_text ltx_font_upright">1</span></span><span id="footnote1.5" class="ltx_text ltx_font_upright">Corresponding author email: elena.sizikova@fda.hhs.gov </span></span></span></span></span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> <span id="id2.1.id1" class="ltx_text ltx_font_italic">A. Badal</span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> <span id="id3.1.id1" class="ltx_text ltx_font_italic">J. G. Delfino</span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> <span id="id4.1.id1" class="ltx_text ltx_font_italic">M. Lago</span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> <span id="id5.1.id1" class="ltx_text ltx_font_italic">B. Nelson</span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> <span id="id6.1.id1" class="ltx_text ltx_font_italic">N. Saharkhiz</span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> 
<br class="ltx_break"><span id="id7.1.id1" class="ltx_text ltx_font_italic">B. Sahiner</span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> <span id="id8.1.id1" class="ltx_text ltx_font_italic">G. Zamzmi</span>
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> <span id="id9.1.id1" class="ltx_text ltx_font_italic">A. Badano</span> 
<br class="ltx_break">
<br class="ltx_break">Office of Science and Engineering Laboratories
<br class="ltx_break">Center for Devices and Radiological Health
<br class="ltx_break">U.S. Food and Drug Administration
<br class="ltx_break">Silver Spring
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> MD 20993 USA
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id10.id1" class="ltx_p">A key challenge for the development and deployment of artificial intelligence (AI) solutions in radiology is solving the associated data limitations. Obtaining sufficient and representative patient datasets with appropriate annotations may be burdensome due to high acquisition cost, safety limitations, patient privacy restrictions or low disease prevalence rates. In silico data offers a number of potential advantages to patient data, such as diminished patient harm, reduced cost, simplified data acquisition, scalability, improved quality assurance testing, and a mitigation approach to data imbalances. We summarize key research trends and practical uses for synthetically generated data for radiological applications of AI. Specifically, we discuss different types of techniques for generating synthetic examples, their main application areas, and related quality control assessment issues. We also discuss current approaches for evaluating synthetic imaging data. Overall, synthetic data holds great promise in addressing current data availability gaps, but additional work is needed before its full potential is realized.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>Radiology; In Silico Medicine; Synthetic Data; Simulations; Digital Twins
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Artificial Intelligence (AI) applications are becoming more and more prevalent in radiology and other types of medical imaging applications. AI techniques are used to aid clinical professionals in faster and more accurate detection of findings, <span id="S1.p1.1.1" class="ltx_text" style="color:#000000;"> optimize image quality</span> while reducing dose, and improve other facets of analyzing complex and multidimensional radiological data. A key feature of AI is its reliance on large-scale datasets for learning meaningful features. The goal of this paper is to review and discuss the emerging use of synthetic data for AI applications in radiology.</p>
</div>
<figure id="S1.T1" class="ltx_table">
<div id="S1.T1.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:115.6pt;vertical-align:-4.7pt;"><span class="ltx_transformed_inner" style="transform:translate(-205.5pt,52.6pt) scale(0.513371797877798,0.513371797877798) ;">
<table id="S1.T1.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S1.T1.1.1.1.1" class="ltx_tr">
<th id="S1.T1.1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S1.T1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Dataset</span></th>
<td id="S1.T1.1.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T1.1.1.1.1.2.1" class="ltx_text ltx_font_bold">Anatomy</span></td>
<td id="S1.T1.1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T1.1.1.1.1.3.1" class="ltx_text ltx_font_bold">Imaging Modality</span></td>
<td id="S1.T1.1.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T1.1.1.1.1.4.1" class="ltx_text ltx_font_bold">Data Generation Technique</span></td>
<td id="S1.T1.1.1.1.1.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S1.T1.1.1.1.1.5.1" class="ltx_text ltx_font_bold">Task</span></td>
</tr>
<tr id="S1.T1.1.1.2.2" class="ltx_tr">
<th id="S1.T1.1.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">pGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite><sup id="S1.T1.1.1.2.2.1.1" class="ltx_sup">a</sup>
</th>
<td id="S1.T1.1.1.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Vertebral units</td>
<td id="S1.T1.1.1.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">MRI</td>
<td id="S1.T1.1.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">GAN</td>
<td id="S1.T1.1.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Unit classification</td>
</tr>
<tr id="S1.T1.1.1.3.3" class="ltx_tr">
<th id="S1.T1.1.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">SinGAN-Seg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite><sup id="S1.T1.1.1.3.3.1.1" class="ltx_sup">a</sup>
</th>
<td id="S1.T1.1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Colon</td>
<td id="S1.T1.1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Endoscopy</td>
<td id="S1.T1.1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">GAN</td>
<td id="S1.T1.1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Polyp segmentation</td>
</tr>
<tr id="S1.T1.1.1.4.4" class="ltx_tr">
<th id="S1.T1.1.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">COVID-19 chest X-rays <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite><sup id="S1.T1.1.1.4.4.1.1" class="ltx_sup">a</sup>
</th>
<td id="S1.T1.1.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Chest</td>
<td id="S1.T1.1.1.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">X-ray</td>
<td id="S1.T1.1.1.4.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">GAN</td>
<td id="S1.T1.1.1.4.4.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Image classification</td>
</tr>
<tr id="S1.T1.1.1.5.5" class="ltx_tr">
<th id="S1.T1.1.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Med-DDPM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>
</th>
<td id="S1.T1.1.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Brain</td>
<td id="S1.T1.1.1.5.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">MRI</td>
<td id="S1.T1.1.1.5.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DDPM</td>
<td id="S1.T1.1.1.5.5.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Brain tumor segmentation</td>
</tr>
<tr id="S1.T1.1.1.6.6" class="ltx_tr">
<th id="S1.T1.1.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Echo from noise <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite><sup id="S1.T1.1.1.6.6.1.1" class="ltx_sup">a</sup>
</th>
<td id="S1.T1.1.1.6.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Heart</td>
<td id="S1.T1.1.1.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Ultrasound</td>
<td id="S1.T1.1.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DDPM</td>
<td id="S1.T1.1.1.6.6.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Cardiac segmentation</td>
</tr>
<tr id="S1.T1.1.1.7.7" class="ltx_tr">
<th id="S1.T1.1.1.7.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Awesome Lungs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite><sup id="S1.T1.1.1.7.7.1.1" class="ltx_sup">a</sup>
</th>
<td id="S1.T1.1.1.7.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Lung</td>
<td id="S1.T1.1.1.7.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">CT, X-Ray</td>
<td id="S1.T1.1.1.7.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DDPM</td>
<td id="S1.T1.1.1.7.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Lung disease diagnosis</td>
</tr>
<tr id="S1.T1.1.1.8.8" class="ltx_tr">
<th id="S1.T1.1.1.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">
<span id="S1.T1.1.1.8.8.1.1" class="ltx_text" style="color:#000000;"> Synthetic CSAW 100k Mammograms</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite><sup id="S1.T1.1.1.8.8.1.2" class="ltx_sup">a</sup>
</th>
<td id="S1.T1.1.1.8.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Breast</td>
<td id="S1.T1.1.1.8.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DM</td>
<td id="S1.T1.1.1.8.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DDPM</td>
<td id="S1.T1.1.1.8.8.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Classification masking of cancer</td>
</tr>
<tr id="S1.T1.1.1.9.9" class="ltx_tr">
<th id="S1.T1.1.1.9.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Sarno <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite><sup id="S1.T1.1.1.9.9.1.1" class="ltx_sup">a</sup>
</th>
<td id="S1.T1.1.1.9.9.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Breast</td>
<td id="S1.T1.1.1.9.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">CT, DM, DBT</td>
<td id="S1.T1.1.1.9.9.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Physical modeling</td>
<td id="S1.T1.1.1.9.9.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Development of a platform for virtual clinical trials</td>
</tr>
<tr id="S1.T1.1.1.10.10" class="ltx_tr">
<th id="S1.T1.1.1.10.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">VICTRE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite><sup id="S1.T1.1.1.10.10.1.1" class="ltx_sup">a</sup>
</th>
<td id="S1.T1.1.1.10.10.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Breast</td>
<td id="S1.T1.1.1.10.10.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DM, DBT</td>
<td id="S1.T1.1.1.10.10.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Physical modeling</td>
<td id="S1.T1.1.1.10.10.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Lesion detection</td>
</tr>
<tr id="S1.T1.1.1.11.11" class="ltx_tr">
<th id="S1.T1.1.1.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">M-SYNTH <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite><sup id="S1.T1.1.1.11.11.1.1" class="ltx_sup">a</sup>
</th>
<td id="S1.T1.1.1.11.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Breast</td>
<td id="S1.T1.1.1.11.11.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">DM</td>
<td id="S1.T1.1.1.11.11.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Physical modeling</td>
<td id="S1.T1.1.1.11.11.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Lesion detection</td>
</tr>
<tr id="S1.T1.1.1.12.12" class="ltx_tr">
<th id="S1.T1.1.1.12.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Synthetic renal ASL data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite><sup id="S1.T1.1.1.12.12.1.1" class="ltx_sup">a</sup>
</th>
<td id="S1.T1.1.1.12.12.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Kidney</td>
<td id="S1.T1.1.1.12.12.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">MRI</td>
<td id="S1.T1.1.1.12.12.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Physical modeling</td>
<td id="S1.T1.1.1.12.12.5" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">Registration, quantification, segmentation</td>
</tr>
</tbody>
</table>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.ix1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">a</span> 
<div id="S1.I1.ix1.p1" class="ltx_para">
<p id="S1.I1.ix1.p1.1" class="ltx_p"><span id="S1.I1.ix1.p1.1.1" class="ltx_text" style="font-size:80%;">Publicly available dataset, according to the publisher</span></p>
</div>
</li>
</ul>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>List of available synthetic radiologic datasets.</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">AI applications are often reliant on neural networks to perform predictions such as classification, segmentation or detection of objects of interest. Neural networks require large and diverse data collections to perform appropriate training and evaluation procedures. However, collecting sufficient examples from real patient sources comes with limitations due to patient privacy concerns, acquisition and annotation difficulties, high cost, and other challenges common to obtaining and sharing medical imaging datasets. Synthetically generated radiological data has been proposed to address some of these challenges and has become increasingly popular and realistic. Such data has been explored across different research domains, but the lack of consistent terminology has prevented a more unified and systematic study of synthetic data for radiology. For instance, the AI community has widely explored generative model techniques for the generation of synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, while the biomedical and clinical community have studied digital twin <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> and in silico medicine applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. A summary of existing synthetic radiological datasets can be found in Table <a href="#S1.T1" title="Table 1 ‣ 1 Introduction ‣ Synthetic Data in Radiological Imaging: Current State and Future Outlook" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. The potential benefits of the use of synthetic radiological data are:</p>
<ul id="S1.I2" class="ltx_itemize">
<li id="S1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i1.p1" class="ltx_para">
<p id="S1.I2.i1.p1.1" class="ltx_p"><span id="S1.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Reduced patient harm or risk.</span> Patient medical procedures (including imaging acquisition data collection) comes with inherent <span id="S1.I2.i1.p1.1.2" class="ltx_text" style="color:#000000;"> health risks</span> (e.g., radiation exposure) or privacy risks (e.g., leak of Personal Identifiable Information (PII)), while the use of synthetic data typically relieves these risks.</p>
</div>
</li>
<li id="S1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i2.p1" class="ltx_para">
<p id="S1.I2.i2.p1.1" class="ltx_p"><span id="S1.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Reduced time, lowered cost, and simplified acquisition. </span> Synthetic examples are often much easier and cost efficient to acquire, preprocess, store and maintain than patient data.</p>
</div>
</li>
<li id="S1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i3.p1" class="ltx_para">
<p id="S1.I2.i3.p1.1" class="ltx_p"><span id="S1.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">Scalability.</span> Large volumes of synthetic examples can be generated on demand when larger sample sizes are needed.</p>
</div>
</li>
<li id="S1.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i4.p1" class="ltx_para">
<p id="S1.I2.i4.p1.1" class="ltx_p"><span id="S1.I2.i4.p1.1.1" class="ltx_text ltx_font_bold">Quality assurance.</span> Synthetic examples can serve as a test-bed for evaluating AI algorithms to rapidly test comparative trends, or potentially support safety and effectiveness evaluations.</p>
</div>
</li>
<li id="S1.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I2.i5.p1" class="ltx_para">
<p id="S1.I2.i5.p1.1" class="ltx_p"><span id="S1.I2.i5.p1.1.1" class="ltx_text ltx_font_bold">Mitigation of data imbalances.</span> Synthetic examples can be conditionally generated according to manually specified distributions, addressing known class imbalances. The resulting process may address imbalances and minimize bias, increasing diversity and enriching patient datasets. Conditional generation allows creating rare cases or under-represented populations.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To date, synthetic data use has been explored in a variety of radiological AI uses. First, and most commonly, synthetic examples have been used as a source of rich and annotated training datasets, either on their own or combined with real patient examples to train an AI model, filling in gaps in data availability, particularly for underrepresented subgroups. Second, synthetic data can be used for generating standardized testing examples that would be otherwise too difficult to acquire from real patients. One notable emerging application is the use of synthetic data for in silico clinical trials. To accomplish these goals, synthetic data generators are becoming increasingly realistic and can be tuned to mimic properties of a radiologic device and the human anatomy (see Figure  <a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Synthetic Data in Radiological Imaging: Current State and Future Outlook" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> for an example).</p>
</div>
<figure id="S1.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S1.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2407.01561/assets/x1.png" id="S1.F1.sf1.g1" class="ltx_graphics ltx_img_portrait" width="60" height="113" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf1.4.1.1" class="ltx_text" style="font-size:80%;">(a)</span> </span><math id="S1.F1.sf1.2.m1.1" class="ltx_Math" alttext="4.44\times 10^{9}" display="inline"><semantics id="S1.F1.sf1.2.m1.1b"><mrow id="S1.F1.sf1.2.m1.1.1" xref="S1.F1.sf1.2.m1.1.1.cmml"><mn mathsize="70%" id="S1.F1.sf1.2.m1.1.1.2" xref="S1.F1.sf1.2.m1.1.1.2.cmml">4.44</mn><mo lspace="0.222em" mathsize="70%" rspace="0.222em" id="S1.F1.sf1.2.m1.1.1.1" xref="S1.F1.sf1.2.m1.1.1.1.cmml">×</mo><msup id="S1.F1.sf1.2.m1.1.1.3" xref="S1.F1.sf1.2.m1.1.1.3.cmml"><mn mathsize="70%" id="S1.F1.sf1.2.m1.1.1.3.2" xref="S1.F1.sf1.2.m1.1.1.3.2.cmml">10</mn><mn mathsize="70%" id="S1.F1.sf1.2.m1.1.1.3.3" xref="S1.F1.sf1.2.m1.1.1.3.3.cmml">9</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S1.F1.sf1.2.m1.1c"><apply id="S1.F1.sf1.2.m1.1.1.cmml" xref="S1.F1.sf1.2.m1.1.1"><times id="S1.F1.sf1.2.m1.1.1.1.cmml" xref="S1.F1.sf1.2.m1.1.1.1"></times><cn type="float" id="S1.F1.sf1.2.m1.1.1.2.cmml" xref="S1.F1.sf1.2.m1.1.1.2">4.44</cn><apply id="S1.F1.sf1.2.m1.1.1.3.cmml" xref="S1.F1.sf1.2.m1.1.1.3"><csymbol cd="ambiguous" id="S1.F1.sf1.2.m1.1.1.3.1.cmml" xref="S1.F1.sf1.2.m1.1.1.3">superscript</csymbol><cn type="integer" id="S1.F1.sf1.2.m1.1.1.3.2.cmml" xref="S1.F1.sf1.2.m1.1.1.3.2">10</cn><cn type="integer" id="S1.F1.sf1.2.m1.1.1.3.3.cmml" xref="S1.F1.sf1.2.m1.1.1.3.3">9</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.sf1.2.m1.1d">4.44\times 10^{9}</annotation></semantics></math></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S1.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2407.01561/assets/x2.png" id="S1.F1.sf2.g1" class="ltx_graphics ltx_img_portrait" width="60" height="113" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf2.4.1.1" class="ltx_text" style="font-size:80%;">(b)</span> </span><math id="S1.F1.sf2.2.m1.1" class="ltx_Math" alttext="8.88\times 10^{9}" display="inline"><semantics id="S1.F1.sf2.2.m1.1b"><mrow id="S1.F1.sf2.2.m1.1.1" xref="S1.F1.sf2.2.m1.1.1.cmml"><mn mathsize="70%" id="S1.F1.sf2.2.m1.1.1.2" xref="S1.F1.sf2.2.m1.1.1.2.cmml">8.88</mn><mo lspace="0.222em" mathsize="70%" rspace="0.222em" id="S1.F1.sf2.2.m1.1.1.1" xref="S1.F1.sf2.2.m1.1.1.1.cmml">×</mo><msup id="S1.F1.sf2.2.m1.1.1.3" xref="S1.F1.sf2.2.m1.1.1.3.cmml"><mn mathsize="70%" id="S1.F1.sf2.2.m1.1.1.3.2" xref="S1.F1.sf2.2.m1.1.1.3.2.cmml">10</mn><mn mathsize="70%" id="S1.F1.sf2.2.m1.1.1.3.3" xref="S1.F1.sf2.2.m1.1.1.3.3.cmml">9</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S1.F1.sf2.2.m1.1c"><apply id="S1.F1.sf2.2.m1.1.1.cmml" xref="S1.F1.sf2.2.m1.1.1"><times id="S1.F1.sf2.2.m1.1.1.1.cmml" xref="S1.F1.sf2.2.m1.1.1.1"></times><cn type="float" id="S1.F1.sf2.2.m1.1.1.2.cmml" xref="S1.F1.sf2.2.m1.1.1.2">8.88</cn><apply id="S1.F1.sf2.2.m1.1.1.3.cmml" xref="S1.F1.sf2.2.m1.1.1.3"><csymbol cd="ambiguous" id="S1.F1.sf2.2.m1.1.1.3.1.cmml" xref="S1.F1.sf2.2.m1.1.1.3">superscript</csymbol><cn type="integer" id="S1.F1.sf2.2.m1.1.1.3.2.cmml" xref="S1.F1.sf2.2.m1.1.1.3.2">10</cn><cn type="integer" id="S1.F1.sf2.2.m1.1.1.3.3.cmml" xref="S1.F1.sf2.2.m1.1.1.3.3">9</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.sf2.2.m1.1d">8.88\times 10^{9}</annotation></semantics></math></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S1.F1.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2407.01561/assets/x3.png" id="S1.F1.sf3.g1" class="ltx_graphics ltx_img_portrait" width="60" height="113" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf3.4.1.1" class="ltx_text" style="font-size:80%;">(c)</span> </span><math id="S1.F1.sf3.2.m1.1" class="ltx_Math" alttext="1.33\times 10^{10}" display="inline"><semantics id="S1.F1.sf3.2.m1.1b"><mrow id="S1.F1.sf3.2.m1.1.1" xref="S1.F1.sf3.2.m1.1.1.cmml"><mn mathsize="70%" id="S1.F1.sf3.2.m1.1.1.2" xref="S1.F1.sf3.2.m1.1.1.2.cmml">1.33</mn><mo lspace="0.222em" mathsize="70%" rspace="0.222em" id="S1.F1.sf3.2.m1.1.1.1" xref="S1.F1.sf3.2.m1.1.1.1.cmml">×</mo><msup id="S1.F1.sf3.2.m1.1.1.3" xref="S1.F1.sf3.2.m1.1.1.3.cmml"><mn mathsize="70%" id="S1.F1.sf3.2.m1.1.1.3.2" xref="S1.F1.sf3.2.m1.1.1.3.2.cmml">10</mn><mn mathsize="70%" id="S1.F1.sf3.2.m1.1.1.3.3" xref="S1.F1.sf3.2.m1.1.1.3.3.cmml">10</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S1.F1.sf3.2.m1.1c"><apply id="S1.F1.sf3.2.m1.1.1.cmml" xref="S1.F1.sf3.2.m1.1.1"><times id="S1.F1.sf3.2.m1.1.1.1.cmml" xref="S1.F1.sf3.2.m1.1.1.1"></times><cn type="float" id="S1.F1.sf3.2.m1.1.1.2.cmml" xref="S1.F1.sf3.2.m1.1.1.2">1.33</cn><apply id="S1.F1.sf3.2.m1.1.1.3.cmml" xref="S1.F1.sf3.2.m1.1.1.3"><csymbol cd="ambiguous" id="S1.F1.sf3.2.m1.1.1.3.1.cmml" xref="S1.F1.sf3.2.m1.1.1.3">superscript</csymbol><cn type="integer" id="S1.F1.sf3.2.m1.1.1.3.2.cmml" xref="S1.F1.sf3.2.m1.1.1.3.2">10</cn><cn type="integer" id="S1.F1.sf3.2.m1.1.1.3.3.cmml" xref="S1.F1.sf3.2.m1.1.1.3.3">10</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.sf3.2.m1.1d">1.33\times 10^{10}</annotation></semantics></math></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S1.F1.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2407.01561/assets/x4.png" id="S1.F1.sf4.g1" class="ltx_graphics ltx_img_portrait" width="60" height="113" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf4.4.1.1" class="ltx_text" style="font-size:80%;">(d)</span> </span><math id="S1.F1.sf4.2.m1.1" class="ltx_Math" alttext="1.78\times 10^{10}" display="inline"><semantics id="S1.F1.sf4.2.m1.1b"><mrow id="S1.F1.sf4.2.m1.1.1" xref="S1.F1.sf4.2.m1.1.1.cmml"><mn mathsize="70%" id="S1.F1.sf4.2.m1.1.1.2" xref="S1.F1.sf4.2.m1.1.1.2.cmml">1.78</mn><mo lspace="0.222em" mathsize="70%" rspace="0.222em" id="S1.F1.sf4.2.m1.1.1.1" xref="S1.F1.sf4.2.m1.1.1.1.cmml">×</mo><msup id="S1.F1.sf4.2.m1.1.1.3" xref="S1.F1.sf4.2.m1.1.1.3.cmml"><mn mathsize="70%" id="S1.F1.sf4.2.m1.1.1.3.2" xref="S1.F1.sf4.2.m1.1.1.3.2.cmml">10</mn><mn mathsize="70%" id="S1.F1.sf4.2.m1.1.1.3.3" xref="S1.F1.sf4.2.m1.1.1.3.3.cmml">10</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S1.F1.sf4.2.m1.1c"><apply id="S1.F1.sf4.2.m1.1.1.cmml" xref="S1.F1.sf4.2.m1.1.1"><times id="S1.F1.sf4.2.m1.1.1.1.cmml" xref="S1.F1.sf4.2.m1.1.1.1"></times><cn type="float" id="S1.F1.sf4.2.m1.1.1.2.cmml" xref="S1.F1.sf4.2.m1.1.1.2">1.78</cn><apply id="S1.F1.sf4.2.m1.1.1.3.cmml" xref="S1.F1.sf4.2.m1.1.1.3"><csymbol cd="ambiguous" id="S1.F1.sf4.2.m1.1.1.3.1.cmml" xref="S1.F1.sf4.2.m1.1.1.3">superscript</csymbol><cn type="integer" id="S1.F1.sf4.2.m1.1.1.3.2.cmml" xref="S1.F1.sf4.2.m1.1.1.3.2">10</cn><cn type="integer" id="S1.F1.sf4.2.m1.1.1.3.3.cmml" xref="S1.F1.sf4.2.m1.1.1.3.3">10</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.sf4.2.m1.1d">1.78\times 10^{10}</annotation></semantics></math></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_many">
<figure id="S1.F1.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2407.01561/assets/x5.png" id="S1.F1.sf5.g1" class="ltx_graphics ltx_img_portrait" width="60" height="113" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S1.F1.sf5.4.1.1" class="ltx_text" style="font-size:80%;">(e)</span> </span><math id="S1.F1.sf5.2.m1.1" class="ltx_Math" alttext="2.22\times 10^{10}" display="inline"><semantics id="S1.F1.sf5.2.m1.1b"><mrow id="S1.F1.sf5.2.m1.1.1" xref="S1.F1.sf5.2.m1.1.1.cmml"><mn mathsize="70%" id="S1.F1.sf5.2.m1.1.1.2" xref="S1.F1.sf5.2.m1.1.1.2.cmml">2.22</mn><mo lspace="0.222em" mathsize="70%" rspace="0.222em" id="S1.F1.sf5.2.m1.1.1.1" xref="S1.F1.sf5.2.m1.1.1.1.cmml">×</mo><msup id="S1.F1.sf5.2.m1.1.1.3" xref="S1.F1.sf5.2.m1.1.1.3.cmml"><mn mathsize="70%" id="S1.F1.sf5.2.m1.1.1.3.2" xref="S1.F1.sf5.2.m1.1.1.3.2.cmml">10</mn><mn mathsize="70%" id="S1.F1.sf5.2.m1.1.1.3.3" xref="S1.F1.sf5.2.m1.1.1.3.3.cmml">10</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S1.F1.sf5.2.m1.1c"><apply id="S1.F1.sf5.2.m1.1.1.cmml" xref="S1.F1.sf5.2.m1.1.1"><times id="S1.F1.sf5.2.m1.1.1.1.cmml" xref="S1.F1.sf5.2.m1.1.1.1"></times><cn type="float" id="S1.F1.sf5.2.m1.1.1.2.cmml" xref="S1.F1.sf5.2.m1.1.1.2">2.22</cn><apply id="S1.F1.sf5.2.m1.1.1.3.cmml" xref="S1.F1.sf5.2.m1.1.1.3"><csymbol cd="ambiguous" id="S1.F1.sf5.2.m1.1.1.3.1.cmml" xref="S1.F1.sf5.2.m1.1.1.3">superscript</csymbol><cn type="integer" id="S1.F1.sf5.2.m1.1.1.3.2.cmml" xref="S1.F1.sf5.2.m1.1.1.3.2">10</cn><cn type="integer" id="S1.F1.sf5.2.m1.1.1.3.3.cmml" xref="S1.F1.sf5.2.m1.1.1.3.3">10</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F1.sf5.2.m1.1d">2.22\times 10^{10}</annotation></semantics></math></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Properties of the digital object and acquisition system models can be controlled during synthetic data generation process. Shown is the variation in imaging dose (number of Monte Carlo histories) generated with the VICTRE pipeline for digital mammography simulation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> for a digital breast model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> with fatty breast density and mass model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> with 5 mm radius (adapted from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>).</figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The limitations of synthetic data depend on how synthetic examples were generated, how realistic they are, and whether their use has more benefits than shortcomings. We argue that this choice is application dependent. Synthetic data applications in radiology have been explored by the biomedical engineering, AI and clinical communities, but the differences in terminology and disconnect have prevented a more unified integration. To address existing gaps, we summarize the key uses of synthetic data for AI across radiological modalities to identify current and future trends in both ongoing research and current applications.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Terminology</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">A general definition of synthetic data in health care has been proposed as artificial data that mimic the properties and relationships seen in real <span id="S2.p1.1.1" class="ltx_text" style="color:#000000;"> patient data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite></span>. Synthetic examples are examples that have been partially or fully generated using computational techniques rather than acquired from a human subject by a physical system. The techniques used to generate synthetic examples (images and objects), described later in this article, vary in the fundamental origin of the information and are typically either knowledge-based or image-based approaches.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">The terms in silico imaging and in silico trials are closely related concepts which encompass computational approaches for generating data and evaluating imaging technology using computational models. <span id="S2.p2.1.1" class="ltx_text ltx_font_italic">In silico medicine</span> refers to the discipline that encompasses the use of patient-specific computer simulations involving all aspects of the prevention, diagnosis,
prognostic assessment, and treatment of disease <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. In turn, as defined in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>, <span id="S2.p2.1.2" class="ltx_text ltx_font_italic">in silico imaging trials</span> are “computational studies that seek to ascertain the performance of a medical device for the intended population, collecting this information entirely in the digital world via computer simulations”. Badano et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> discusses techniques for generating digital cohorts, referring to groups of digital stochastic human models that share common characteristics and are selected for participation within in silico trials.</p>
</div>
<figure id="S2.T2" class="ltx_table">
<div id="S2.T2.1" class="ltx_inline-block ltx_transformed_outer" style="width:433.6pt;height:736.6pt;vertical-align:-0.4pt;"><span class="ltx_transformed_inner" style="transform:translate(-284.2pt,482.6pt) scale(0.432713189746603,0.432713189746603) ;">
<table id="S2.T2.1.1" class="ltx_tabular ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S2.T2.1.1.1.1" class="ltx_tr">
<td id="S2.T2.1.1.1.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S2.T2.1.1.1.1.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">Manuscript</span></td>
<td id="S2.T2.1.1.1.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.1.1.2.1" class="ltx_text ltx_font_bold" style="color:#000000;">Model Type</span></td>
<td id="S2.T2.1.1.1.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S2.T2.1.1.1.1.3.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.1.1.1.1.3.1.1" class="ltx_tr">
<td id="S2.T2.1.1.1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S2.T2.1.1.1.1.3.1.1.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">Imaging</span></td>
</tr>
<tr id="S2.T2.1.1.1.1.3.1.2" class="ltx_tr">
<td id="S2.T2.1.1.1.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S2.T2.1.1.1.1.3.1.2.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">Modality</span></td>
</tr>
</table>
</td>
<td id="S2.T2.1.1.1.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S2.T2.1.1.1.1.4.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.1.1.1.1.4.1.1" class="ltx_tr">
<td id="S2.T2.1.1.1.1.4.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S2.T2.1.1.1.1.4.1.1.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">Anatomic</span></td>
</tr>
<tr id="S2.T2.1.1.1.1.4.1.2" class="ltx_tr">
<td id="S2.T2.1.1.1.1.4.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S2.T2.1.1.1.1.4.1.2.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">Site</span></td>
</tr>
</table>
</td>
<td id="S2.T2.1.1.1.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S2.T2.1.1.1.1.5.1" class="ltx_tabular ltx_align_middle">
<tr id="S2.T2.1.1.1.1.5.1.1" class="ltx_tr">
<td id="S2.T2.1.1.1.1.5.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left"><span id="S2.T2.1.1.1.1.5.1.1.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">Comments</span></td>
</tr>
</table>
</td>
</tr>
<tr id="S2.T2.1.1.2.2" class="ltx_tr">
<td id="S2.T2.1.1.2.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="5"><span id="S2.T2.1.1.2.2.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">Techniques for Synthetic Data Generation</span></td>
</tr>
<tr id="S2.T2.1.1.3.3" class="ltx_tr">
<td id="S2.T2.1.1.3.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.3.3.1.1" class="ltx_text" style="color:#000000;">Goodfellow </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.3.3.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib20" title="" class="ltx_ref">20</a><span id="S2.T2.1.1.3.3.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.3.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.3.3.2.1" class="ltx_text" style="color:#000000;">GAN</span></td>
<td id="S2.T2.1.1.3.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.3.3.3.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.3.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.3.3.4.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.3.3.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.3.3.5.1" class="ltx_text" style="color:#000000;">Original GAN implementation</span></td>
</tr>
<tr id="S2.T2.1.1.4.4" class="ltx_tr">
<td id="S2.T2.1.1.4.4.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.4.4.1.1" class="ltx_text" style="color:#000000;">Kossen </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.4.4.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib21" title="" class="ltx_ref">21</a><span id="S2.T2.1.1.4.4.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.4.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.4.4.2.1" class="ltx_text" style="color:#000000;">GAN</span></td>
<td id="S2.T2.1.1.4.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.4.4.3.1" class="ltx_text" style="color:#000000;">MRI</span></td>
<td id="S2.T2.1.1.4.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.4.4.4.1" class="ltx_text" style="color:#000000;">Brain</span></td>
<td id="S2.T2.1.1.4.4.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.4.4.5.1" class="ltx_text" style="color:#000000;">Differentially private generation of image patches for brain vessel segmentation</span></td>
</tr>
<tr id="S2.T2.1.1.5.5" class="ltx_tr">
<td id="S2.T2.1.1.5.5.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.5.5.1.1" class="ltx_text" style="color:#000000;">Jiang </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.5.5.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib22" title="" class="ltx_ref">22</a><span id="S2.T2.1.1.5.5.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.5.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.5.5.2.1" class="ltx_text" style="color:#000000;">GAN</span></td>
<td id="S2.T2.1.1.5.5.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.5.5.3.1" class="ltx_text" style="color:#000000;">CT</span></td>
<td id="S2.T2.1.1.5.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.5.5.4.1" class="ltx_text" style="color:#000000;">Lung</span></td>
<td id="S2.T2.1.1.5.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.5.5.5.1" class="ltx_text" style="color:#000000;">Adversarial domain adaptation (CT to MRI) for improved tumor segmentation</span></td>
</tr>
<tr id="S2.T2.1.1.6.6" class="ltx_tr">
<td id="S2.T2.1.1.6.6.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.6.6.1.1" class="ltx_text" style="color:#000000;">Xia </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.6.6.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib23" title="" class="ltx_ref">23</a><span id="S2.T2.1.1.6.6.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.6.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.6.6.2.1" class="ltx_text" style="color:#000000;">GAN</span></td>
<td id="S2.T2.1.1.6.6.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.6.6.3.1" class="ltx_text" style="color:#000000;">MRI</span></td>
<td id="S2.T2.1.1.6.6.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.6.6.4.1" class="ltx_text" style="color:#000000;">Brain</span></td>
<td id="S2.T2.1.1.6.6.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.6.6.5.1" class="ltx_text" style="color:#000000;">Creation of patient-specific healthy examples from given pathological ones</span></td>
</tr>
<tr id="S2.T2.1.1.7.7" class="ltx_tr">
<td id="S2.T2.1.1.7.7.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.7.7.1.1" class="ltx_text" style="color:#000000;">Zhu </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.7.7.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib24" title="" class="ltx_ref">24</a><span id="S2.T2.1.1.7.7.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.7.7.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.7.7.2.1" class="ltx_text" style="color:#000000;">GAN</span></td>
<td id="S2.T2.1.1.7.7.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.7.7.3.1" class="ltx_text" style="color:#000000;">Any</span></td>
<td id="S2.T2.1.1.7.7.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.7.7.4.1" class="ltx_text" style="color:#000000;">Any</span></td>
<td id="S2.T2.1.1.7.7.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.7.7.5.1" class="ltx_text" style="color:#000000;">CycleGAN: unpaired image-to-image translation</span></td>
</tr>
<tr id="S2.T2.1.1.8.8" class="ltx_tr">
<td id="S2.T2.1.1.8.8.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.8.8.1.1" class="ltx_text" style="color:#000000;">Bora </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.8.8.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib25" title="" class="ltx_ref">25</a><span id="S2.T2.1.1.8.8.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.8.8.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.8.8.2.1" class="ltx_text" style="color:#000000;">GAN</span></td>
<td id="S2.T2.1.1.8.8.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.8.8.3.1" class="ltx_text" style="color:#000000;">Any</span></td>
<td id="S2.T2.1.1.8.8.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.8.8.4.1" class="ltx_text" style="color:#000000;">Any</span></td>
<td id="S2.T2.1.1.8.8.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.8.8.5.1" class="ltx_text" style="color:#000000;">AmbientGAN: generative learning approach from noisy inputs</span></td>
</tr>
<tr id="S2.T2.1.1.9.9" class="ltx_tr">
<td id="S2.T2.1.1.9.9.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.9.9.1.1" class="ltx_text" style="color:#000000;">Zhou </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.9.9.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib26" title="" class="ltx_ref">26</a><span id="S2.T2.1.1.9.9.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.9.9.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.9.9.2.1" class="ltx_text" style="color:#000000;">GAN</span></td>
<td id="S2.T2.1.1.9.9.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.9.9.3.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.9.9.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.9.9.4.1" class="ltx_text" style="color:#000000;">MRI</span></td>
<td id="S2.T2.1.1.9.9.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.9.9.5.1" class="ltx_text" style="color:#000000;">Generative learning on noisy, multi-resolution inputs applied to brain and knee data</span></td>
</tr>
<tr id="S2.T2.1.1.10.10" class="ltx_tr">
<td id="S2.T2.1.1.10.10.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.10.10.1.1" class="ltx_text" style="color:#000000;">Liu </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.10.10.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib27" title="" class="ltx_ref">27</a><span id="S2.T2.1.1.10.10.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.10.10.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.10.10.2.1" class="ltx_text" style="color:#000000;">GAN</span></td>
<td id="S2.T2.1.1.10.10.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.10.10.3.1" class="ltx_text" style="color:#000000;">CT</span></td>
<td id="S2.T2.1.1.10.10.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.10.10.4.1" class="ltx_text" style="color:#000000;">Liver</span></td>
<td id="S2.T2.1.1.10.10.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.10.10.5.1" class="ltx_text" style="color:#000000;">Synthetic lesion synthesis for improved tumor segmentation</span></td>
</tr>
<tr id="S2.T2.1.1.11.11" class="ltx_tr">
<td id="S2.T2.1.1.11.11.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.11.11.1.1" class="ltx_text" style="color:#000000;">Jiang </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.11.11.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib28" title="" class="ltx_ref">28</a><span id="S2.T2.1.1.11.11.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.11.11.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.11.11.2.1" class="ltx_text" style="color:#000000;">GAN</span></td>
<td id="S2.T2.1.1.11.11.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.11.11.3.1" class="ltx_text" style="color:#000000;">CT</span></td>
<td id="S2.T2.1.1.11.11.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.11.11.4.1" class="ltx_text" style="color:#000000;">Chest and Torso</span></td>
<td id="S2.T2.1.1.11.11.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.11.11.5.1" class="ltx_text" style="color:#000000;">COVID-19 CT synthesis using conditional generative learning</span></td>
</tr>
<tr id="S2.T2.1.1.12.12" class="ltx_tr">
<td id="S2.T2.1.1.12.12.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.12.12.1.1" class="ltx_text" style="color:#000000;">Kobyzev </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.12.12.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib29" title="" class="ltx_ref">29</a><span id="S2.T2.1.1.12.12.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.12.12.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.12.12.2.1" class="ltx_text" style="color:#000000;">NF</span></td>
<td id="S2.T2.1.1.12.12.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.12.12.3.1" class="ltx_text" style="color:#000000;">Any</span></td>
<td id="S2.T2.1.1.12.12.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.12.12.4.1" class="ltx_text" style="color:#000000;">Any</span></td>
<td id="S2.T2.1.1.12.12.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.12.12.5.1" class="ltx_text" style="color:#000000;">Original Normalizing Flows (NF) implementation</span></td>
</tr>
<tr id="S2.T2.1.1.13.13" class="ltx_tr">
<td id="S2.T2.1.1.13.13.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.13.13.1.1" class="ltx_text" style="color:#000000;">Denker </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.13.13.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib30" title="" class="ltx_ref">30</a><span id="S2.T2.1.1.13.13.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.13.13.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.13.13.2.1" class="ltx_text" style="color:#000000;">NF</span></td>
<td id="S2.T2.1.1.13.13.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.13.13.3.1" class="ltx_text" style="color:#000000;">CT</span></td>
<td id="S2.T2.1.1.13.13.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.13.13.4.1" class="ltx_text" style="color:#000000;">Chest and Torso</span></td>
<td id="S2.T2.1.1.13.13.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.13.13.5.1" class="ltx_text" style="color:#000000;">Conditional NF for low-dose CT reconstruction</span></td>
</tr>
<tr id="S2.T2.1.1.14.14" class="ltx_tr">
<td id="S2.T2.1.1.14.14.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.14.14.1.1" class="ltx_text" style="color:#000000;">Hajij </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.14.14.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib31" title="" class="ltx_ref">31</a><span id="S2.T2.1.1.14.14.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.14.14.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.14.14.2.1" class="ltx_text" style="color:#000000;">NF</span></td>
<td id="S2.T2.1.1.14.14.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.14.14.3.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.14.14.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.14.14.4.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.14.14.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.14.14.5.1" class="ltx_text" style="color:#000000;">Comparison of NF to other generative models in medical image generation</span></td>
</tr>
<tr id="S2.T2.1.1.15.15" class="ltx_tr">
<td id="S2.T2.1.1.15.15.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.15.15.1.1" class="ltx_text" style="color:#000000;">Kingma </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.15.15.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib32" title="" class="ltx_ref">32</a><span id="S2.T2.1.1.15.15.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.15.15.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.15.15.2.1" class="ltx_text" style="color:#000000;">VAE</span></td>
<td id="S2.T2.1.1.15.15.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.15.15.3.1" class="ltx_text" style="color:#000000;">Any</span></td>
<td id="S2.T2.1.1.15.15.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.15.15.4.1" class="ltx_text" style="color:#000000;">Any</span></td>
<td id="S2.T2.1.1.15.15.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.15.15.5.1" class="ltx_text" style="color:#000000;">Original VAE (VAE) implementation</span></td>
</tr>
<tr id="S2.T2.1.1.16.16" class="ltx_tr">
<td id="S2.T2.1.1.16.16.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.16.16.1.1" class="ltx_text" style="color:#000000;">Ahmad </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.16.16.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib33" title="" class="ltx_ref">33</a><span id="S2.T2.1.1.16.16.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.16.16.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.16.16.2.1" class="ltx_text" style="color:#000000;">VAE and GAN</span></td>
<td id="S2.T2.1.1.16.16.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.16.16.3.1" class="ltx_text" style="color:#000000;">MRI</span></td>
<td id="S2.T2.1.1.16.16.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.16.16.4.1" class="ltx_text" style="color:#000000;">Brain</span></td>
<td id="S2.T2.1.1.16.16.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.16.16.5.1" class="ltx_text" style="color:#000000;">VAE-GAN implementation for brain tumor MRI generation to avoid mode collapse</span></td>
</tr>
<tr id="S2.T2.1.1.17.17" class="ltx_tr">
<td id="S2.T2.1.1.17.17.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.17.17.1.1" class="ltx_text" style="color:#000000;">Cui </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.17.17.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib34" title="" class="ltx_ref">34</a><span id="S2.T2.1.1.17.17.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.17.17.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.17.17.2.1" class="ltx_text" style="color:#000000;">VAE</span></td>
<td id="S2.T2.1.1.17.17.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.17.17.3.1" class="ltx_text" style="color:#000000;">PET</span></td>
<td id="S2.T2.1.1.17.17.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.17.17.4.1" class="ltx_text" style="color:#000000;">Chest and Torso</span></td>
<td id="S2.T2.1.1.17.17.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.17.17.5.1" class="ltx_text" style="color:#000000;">Denoising and uncertainty estimation for PET</span></td>
</tr>
<tr id="S2.T2.1.1.18.18" class="ltx_tr">
<td id="S2.T2.1.1.18.18.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.18.18.1.1" class="ltx_text" style="color:#000000;">Ho </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.18.18.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib35" title="" class="ltx_ref">35</a><span id="S2.T2.1.1.18.18.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.18.18.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.18.18.2.1" class="ltx_text" style="color:#000000;">DDPM</span></td>
<td id="S2.T2.1.1.18.18.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.18.18.3.1" class="ltx_text" style="color:#000000;">Any</span></td>
<td id="S2.T2.1.1.18.18.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.18.18.4.1" class="ltx_text" style="color:#000000;">Any</span></td>
<td id="S2.T2.1.1.18.18.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.18.18.5.1" class="ltx_text" style="color:#000000;">Original diffusion model implementation</span></td>
</tr>
<tr id="S2.T2.1.1.19.19" class="ltx_tr">
<td id="S2.T2.1.1.19.19.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.19.19.1.1" class="ltx_text" style="color:#000000;">Khosravi </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.19.19.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib36" title="" class="ltx_ref">36</a><span id="S2.T2.1.1.19.19.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.19.19.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.19.19.2.1" class="ltx_text" style="color:#000000;">DDPM</span></td>
<td id="S2.T2.1.1.19.19.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.19.19.3.1" class="ltx_text" style="color:#000000;">X-ray</span></td>
<td id="S2.T2.1.1.19.19.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.19.19.4.1" class="ltx_text" style="color:#000000;">Pelvis</span></td>
<td id="S2.T2.1.1.19.19.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.19.19.5.1" class="ltx_text" style="color:#000000;">Diffusion models for few-shot segmentation</span></td>
</tr>
<tr id="S2.T2.1.1.20.20" class="ltx_tr">
<td id="S2.T2.1.1.20.20.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.20.20.1.1" class="ltx_text" style="color:#000000;">Pinaya </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.20.20.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib7" title="" class="ltx_ref">7</a><span id="S2.T2.1.1.20.20.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.20.20.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.20.20.2.1" class="ltx_text" style="color:#000000;">Generative (multiple)</span></td>
<td id="S2.T2.1.1.20.20.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.20.20.3.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.20.20.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.20.20.4.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.20.20.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.20.20.5.1" class="ltx_text" style="color:#000000;">MONAI: generative AI library for medical imaging</span></td>
</tr>
<tr id="S2.T2.1.1.21.21" class="ltx_tr">
<td id="S2.T2.1.1.21.21.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.21.21.1.1" class="ltx_text" style="color:#000000;">Gosselin </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.21.21.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib37" title="" class="ltx_ref">37</a><span id="S2.T2.1.1.21.21.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.21.21.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.21.21.2.1" class="ltx_text" style="color:#000000;">Patient-Based Model</span></td>
<td id="S2.T2.1.1.21.21.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.21.21.3.1" class="ltx_text" style="color:#000000;">MRI</span></td>
<td id="S2.T2.1.1.21.21.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.21.21.4.1" class="ltx_text" style="color:#000000;">Whole Body</span></td>
<td id="S2.T2.1.1.21.21.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.21.21.5.1" class="ltx_text" style="color:#000000;">Virtual Population VIP3.0: High-resolution models created from patient MRI</span></td>
</tr>
<tr id="S2.T2.1.1.22.22" class="ltx_tr">
<td id="S2.T2.1.1.22.22.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.22.22.1.1" class="ltx_text" style="color:#000000;">Solomon </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.22.22.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib38" title="" class="ltx_ref">38</a><span id="S2.T2.1.1.22.22.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.22.22.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.22.22.2.1" class="ltx_text" style="color:#000000;">Patient-Based Model</span></td>
<td id="S2.T2.1.1.22.22.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.22.22.3.1" class="ltx_text" style="color:#000000;">CT</span></td>
<td id="S2.T2.1.1.22.22.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.22.22.4.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.22.22.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.22.22.5.1" class="ltx_text" style="color:#000000;">A simulation model for lung, liver and renal lesions</span></td>
</tr>
<tr id="S2.T2.1.1.23.23" class="ltx_tr">
<td id="S2.T2.1.1.23.23.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.23.23.1.1" class="ltx_text" style="color:#000000;">Tomic </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.23.23.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib39" title="" class="ltx_ref">39</a><span id="S2.T2.1.1.23.23.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.23.23.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.23.23.2.1" class="ltx_text" style="color:#000000;">Patient-Based Model</span></td>
<td id="S2.T2.1.1.23.23.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.23.23.3.1" class="ltx_text" style="color:#000000;">Any</span></td>
<td id="S2.T2.1.1.23.23.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.23.23.4.1" class="ltx_text" style="color:#000000;">Breast</span></td>
<td id="S2.T2.1.1.23.23.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.23.23.5.1" class="ltx_text" style="color:#000000;">A growing tumor model for breast cancer analysis</span></td>
</tr>
<tr id="S2.T2.1.1.24.24" class="ltx_tr">
<td id="S2.T2.1.1.24.24.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.24.24.1.1" class="ltx_text" style="color:#000000;">Al Khalil </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.24.24.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib40" title="" class="ltx_ref">40</a><span id="S2.T2.1.1.24.24.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.24.24.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.24.24.2.1" class="ltx_text" style="color:#000000;">Patient-Based Model</span></td>
<td id="S2.T2.1.1.24.24.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.24.24.3.1" class="ltx_text" style="color:#000000;">MRI</span></td>
<td id="S2.T2.1.1.24.24.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.24.24.4.1" class="ltx_text" style="color:#000000;">Cardiac</span></td>
<td id="S2.T2.1.1.24.24.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.24.24.5.1" class="ltx_text" style="color:#000000;">A set of simulated models for cardiac segmentation analysis</span></td>
</tr>
<tr id="S2.T2.1.1.25.25" class="ltx_tr">
<td id="S2.T2.1.1.25.25.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.25.25.1.1" class="ltx_text" style="color:#000000;">Segars </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.25.25.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib41" title="" class="ltx_ref">41</a><span id="S2.T2.1.1.25.25.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.25.25.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.25.25.2.1" class="ltx_text" style="color:#000000;">Patient-Based Model</span></td>
<td id="S2.T2.1.1.25.25.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.25.25.3.1" class="ltx_text" style="color:#000000;">PET-CT</span></td>
<td id="S2.T2.1.1.25.25.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.25.25.4.1" class="ltx_text" style="color:#000000;">Whole Body</span></td>
<td id="S2.T2.1.1.25.25.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.25.25.5.1" class="ltx_text" style="color:#000000;">Extended set of pediatric XCAT phantoms</span></td>
</tr>
<tr id="S2.T2.1.1.26.26" class="ltx_tr">
<td id="S2.T2.1.1.26.26.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.26.26.1.1" class="ltx_text" style="color:#000000;">Hoe </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.26.26.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib42" title="" class="ltx_ref">42</a><span id="S2.T2.1.1.26.26.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.26.26.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.26.26.2.1" class="ltx_text" style="color:#000000;">Patient-Based Model</span></td>
<td id="S2.T2.1.1.26.26.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.26.26.3.1" class="ltx_text" style="color:#000000;">Any</span></td>
<td id="S2.T2.1.1.26.26.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.26.26.4.1" class="ltx_text" style="color:#000000;">Liver</span></td>
<td id="S2.T2.1.1.26.26.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.26.26.5.1" class="ltx_text" style="color:#000000;">CT-derived pediatric liver lesion model</span></td>
</tr>
<tr id="S2.T2.1.1.27.27" class="ltx_tr">
<td id="S2.T2.1.1.27.27.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.27.27.1.1" class="ltx_text" style="color:#000000;">Shaheen </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.27.27.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib43" title="" class="ltx_ref">43</a><span id="S2.T2.1.1.27.27.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.27.27.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.27.27.2.1" class="ltx_text" style="color:#000000;">Patient-Based Model</span></td>
<td id="S2.T2.1.1.27.27.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.27.27.3.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.27.27.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.27.27.4.1" class="ltx_text" style="color:#000000;">Breast</span></td>
<td id="S2.T2.1.1.27.27.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.27.27.5.1" class="ltx_text" style="color:#000000;">An MRI-derived lesion model for DM and DBT analysis</span></td>
</tr>
<tr id="S2.T2.1.1.28.28" class="ltx_tr">
<td id="S2.T2.1.1.28.28.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.28.28.1.1" class="ltx_text" style="color:#000000;">Sarno </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.28.28.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib8" title="" class="ltx_ref">8</a><span id="S2.T2.1.1.28.28.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.28.28.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.28.28.2.1" class="ltx_text" style="color:#000000;">Patient-Based Model</span></td>
<td id="S2.T2.1.1.28.28.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.28.28.3.1" class="ltx_text" style="color:#000000;">CT</span></td>
<td id="S2.T2.1.1.28.28.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.28.28.4.1" class="ltx_text" style="color:#000000;">Breast</span></td>
<td id="S2.T2.1.1.28.28.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.28.28.5.1" class="ltx_text" style="color:#000000;">A set of digital CT breast phantoms designed for virtual clinical trials</span></td>
</tr>
<tr id="S2.T2.1.1.29.29" class="ltx_tr">
<td id="S2.T2.1.1.29.29.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.29.29.1.1" class="ltx_text" style="color:#000000;">Sauer </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.29.29.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib44" title="" class="ltx_ref">44</a><span id="S2.T2.1.1.29.29.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.29.29.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.29.29.2.1" class="ltx_text" style="color:#000000;">Patient-Based Model</span></td>
<td id="S2.T2.1.1.29.29.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.29.29.3.1" class="ltx_text" style="color:#000000;">CT</span></td>
<td id="S2.T2.1.1.29.29.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.29.29.4.1" class="ltx_text" style="color:#000000;">Lung</span></td>
<td id="S2.T2.1.1.29.29.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.29.29.5.1" class="ltx_text" style="color:#000000;">A growing lesion model for lung analysis applications</span></td>
</tr>
<tr id="S2.T2.1.1.30.30" class="ltx_tr">
<td id="S2.T2.1.1.30.30.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.30.30.1.1" class="ltx_text" style="color:#000000;">Graff </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.30.30.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib15" title="" class="ltx_ref">15</a><span id="S2.T2.1.1.30.30.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.30.30.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.30.30.2.1" class="ltx_text" style="color:#000000;">KB Model</span></td>
<td id="S2.T2.1.1.30.30.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.30.30.3.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.30.30.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.30.30.4.1" class="ltx_text" style="color:#000000;">Breast</span></td>
<td id="S2.T2.1.1.30.30.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.30.30.5.1" class="ltx_text" style="color:#000000;">A high-resolution breast phantom</span></td>
</tr>
<tr id="S2.T2.1.1.31.31" class="ltx_tr">
<td id="S2.T2.1.1.31.31.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.31.31.1.1" class="ltx_text" style="color:#000000;">de Sisternes </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.31.31.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib16" title="" class="ltx_ref">16</a><span id="S2.T2.1.1.31.31.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.31.31.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.31.31.2.1" class="ltx_text" style="color:#000000;">KB Model</span></td>
<td id="S2.T2.1.1.31.31.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.31.31.3.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.31.31.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.31.31.4.1" class="ltx_text" style="color:#000000;">Breast</span></td>
<td id="S2.T2.1.1.31.31.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.31.31.5.1" class="ltx_text" style="color:#000000;">A growing breast lesion model</span></td>
</tr>
<tr id="S2.T2.1.1.32.32" class="ltx_tr">
<td id="S2.T2.1.1.32.32.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.32.32.1.1" class="ltx_text" style="color:#000000;">Sengupta </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.32.32.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib45" title="" class="ltx_ref">45</a><span id="S2.T2.1.1.32.32.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.32.32.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.32.32.2.1" class="ltx_text" style="color:#000000;">KB Model</span></td>
<td id="S2.T2.1.1.32.32.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.32.32.3.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.32.32.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.32.32.4.1" class="ltx_text" style="color:#000000;">Breast</span></td>
<td id="S2.T2.1.1.32.32.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.32.32.5.1" class="ltx_text" style="color:#000000;">A growing breast lesion model</span></td>
</tr>
<tr id="S2.T2.1.1.33.33" class="ltx_tr">
<td id="S2.T2.1.1.33.33.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.33.33.1.1" class="ltx_text" style="color:#000000;">Sizikova </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.33.33.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib10" title="" class="ltx_ref">10</a><span id="S2.T2.1.1.33.33.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.33.33.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.33.33.2.1" class="ltx_text" style="color:#000000;">KB Model</span></td>
<td id="S2.T2.1.1.33.33.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.33.33.3.1" class="ltx_text" style="color:#000000;">DM</span></td>
<td id="S2.T2.1.1.33.33.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.33.33.4.1" class="ltx_text" style="color:#000000;">Breast</span></td>
<td id="S2.T2.1.1.33.33.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.33.33.5.1" class="ltx_text" style="color:#000000;">A simulated image dataset for comparative analysis of mammography AI</span></td>
</tr>
<tr id="S2.T2.1.1.34.34" class="ltx_tr">
<td id="S2.T2.1.1.34.34.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.34.34.1.1" class="ltx_text" style="color:#000000;">Abadi </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.34.34.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib46" title="" class="ltx_ref">46</a><span id="S2.T2.1.1.34.34.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.34.34.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.34.34.2.1" class="ltx_text" style="color:#000000;">Imaging Simulator</span></td>
<td id="S2.T2.1.1.34.34.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.34.34.3.1" class="ltx_text" style="color:#000000;">CT</span></td>
<td id="S2.T2.1.1.34.34.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.34.34.4.1" class="ltx_text" style="color:#000000;">Any</span></td>
<td id="S2.T2.1.1.34.34.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.34.34.5.1" class="ltx_text" style="color:#000000;">DukeSim: a scanner-specific CT simulation framework</span></td>
</tr>
<tr id="S2.T2.1.1.35.35" class="ltx_tr">
<td id="S2.T2.1.1.35.35.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.35.35.1.1" class="ltx_text" style="color:#000000;">Wu </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.35.35.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib47" title="" class="ltx_ref">47</a><span id="S2.T2.1.1.35.35.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.35.35.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.35.35.2.1" class="ltx_text" style="color:#000000;">Imaging Simulator</span></td>
<td id="S2.T2.1.1.35.35.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.35.35.3.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.35.35.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.35.35.4.1" class="ltx_text" style="color:#000000;">Any</span></td>
<td id="S2.T2.1.1.35.35.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.35.35.5.1" class="ltx_text" style="color:#000000;">XCIST: An X-ray/CT simulation framework</span></td>
</tr>
<tr id="S2.T2.1.1.36.36" class="ltx_tr">
<td id="S2.T2.1.1.36.36.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.36.36.1.1" class="ltx_text" style="color:#000000;">Badal </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.36.36.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib48" title="" class="ltx_ref">48</a><span id="S2.T2.1.1.36.36.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.36.36.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.36.36.2.1" class="ltx_text" style="color:#000000;">Imaging Simulator</span></td>
<td id="S2.T2.1.1.36.36.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.36.36.3.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.36.36.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.36.36.4.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.36.36.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.36.36.5.1" class="ltx_text" style="color:#000000;">Acceleration of Monte Carlo simulations in imaging using a GPU</span></td>
</tr>
<tr id="S2.T2.1.1.37.37" class="ltx_tr">
<td id="S2.T2.1.1.37.37.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.37.37.1.1" class="ltx_text" style="color:#000000;">Badal </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.37.37.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib49" title="" class="ltx_ref">49</a><span id="S2.T2.1.1.37.37.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.37.37.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.37.37.2.1" class="ltx_text" style="color:#000000;">Imaging Simulator</span></td>
<td id="S2.T2.1.1.37.37.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.37.37.3.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.37.37.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.37.37.4.1" class="ltx_text" style="color:#000000;">Breast</span></td>
<td id="S2.T2.1.1.37.37.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.37.37.5.1" class="ltx_text" style="color:#000000;">MC-GPU: DM and DBT breast imaging simulation framework</span></td>
</tr>
<tr id="S2.T2.1.1.38.38" class="ltx_tr">
<td id="S2.T2.1.1.38.38.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.38.38.1.1" class="ltx_text" style="color:#000000;">Sarrut </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.38.38.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib50" title="" class="ltx_ref">50</a><span id="S2.T2.1.1.38.38.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.38.38.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.38.38.2.1" class="ltx_text" style="color:#000000;">Imaging Simulator</span></td>
<td id="S2.T2.1.1.38.38.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.38.38.3.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.38.38.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.38.38.4.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.38.38.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.38.38.5.1" class="ltx_text" style="color:#000000;">OpenGATE: an open-source Monte Carlo toolkit for medical physics</span></td>
</tr>
<tr id="S2.T2.1.1.39.39" class="ltx_tr">
<td id="S2.T2.1.1.39.39.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.39.39.1.1" class="ltx_text" style="color:#000000;">Liu </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.39.39.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib51" title="" class="ltx_ref">51</a><span id="S2.T2.1.1.39.39.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.39.39.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.39.39.2.1" class="ltx_text" style="color:#000000;">Imaging Simulator</span></td>
<td id="S2.T2.1.1.39.39.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.39.39.3.1" class="ltx_text" style="color:#000000;">MRI</span></td>
<td id="S2.T2.1.1.39.39.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.39.39.4.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.39.39.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.39.39.5.1" class="ltx_text" style="color:#000000;">MRiLab: MRI simulation framework</span></td>
</tr>
<tr id="S2.T2.1.1.40.40" class="ltx_tr">
<td id="S2.T2.1.1.40.40.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.40.40.1.1" class="ltx_text" style="color:#000000;">Unberath </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.40.40.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib52" title="" class="ltx_ref">52</a><span id="S2.T2.1.1.40.40.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.40.40.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.40.40.2.1" class="ltx_text" style="color:#000000;">Imaging Simulator</span></td>
<td id="S2.T2.1.1.40.40.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.40.40.3.1" class="ltx_text" style="color:#000000;">X-ray</span></td>
<td id="S2.T2.1.1.40.40.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.40.40.4.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.40.40.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.40.40.5.1" class="ltx_text" style="color:#000000;">DeepDRR: simulation of X-ray from CT</span></td>
</tr>
<tr id="S2.T2.1.1.41.41" class="ltx_tr">
<td id="S2.T2.1.1.41.41.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.41.41.1.1" class="ltx_text" style="color:#000000;">Jensen </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.41.41.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib53" title="" class="ltx_ref">53</a><span id="S2.T2.1.1.41.41.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.41.41.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.41.41.2.1" class="ltx_text" style="color:#000000;">Imaging Simulator</span></td>
<td id="S2.T2.1.1.41.41.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.41.41.3.1" class="ltx_text" style="color:#000000;">Ultrasound</span></td>
<td id="S2.T2.1.1.41.41.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.41.41.4.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.41.41.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.41.41.5.1" class="ltx_text" style="color:#000000;">Field: ultrasound simulation framework</span></td>
</tr>
<tr id="S2.T2.1.1.42.42" class="ltx_tr">
<td id="S2.T2.1.1.42.42.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.42.42.1.1" class="ltx_text" style="color:#000000;">Maier </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.42.42.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib54" title="" class="ltx_ref">54</a><span id="S2.T2.1.1.42.42.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.42.42.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.42.42.2.1" class="ltx_text" style="color:#000000;">Hybrid, Physics-Informed</span></td>
<td id="S2.T2.1.1.42.42.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.42.42.3.1" class="ltx_text" style="color:#000000;">CT</span></td>
<td id="S2.T2.1.1.42.42.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.42.42.4.1" class="ltx_text" style="color:#000000;">Any</span></td>
<td id="S2.T2.1.1.42.42.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.42.42.5.1" class="ltx_text" style="color:#000000;">Deep scatter estimation (CT) for real time X-ray scatter in cone-beam CT</span></td>
</tr>
<tr id="S2.T2.1.1.43.43" class="ltx_tr">
<td id="S2.T2.1.1.43.43.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.43.43.1.1" class="ltx_text" style="color:#000000;">Horger </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.43.43.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib55" title="" class="ltx_ref">55</a><span id="S2.T2.1.1.43.43.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.43.43.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.43.43.2.1" class="ltx_text" style="color:#000000;">Hybrid, Physics-Informed</span></td>
<td id="S2.T2.1.1.43.43.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.43.43.3.1" class="ltx_text" style="color:#000000;">Any</span></td>
<td id="S2.T2.1.1.43.43.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.43.43.4.1" class="ltx_text" style="color:#000000;">Any</span></td>
<td id="S2.T2.1.1.43.43.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.43.43.5.1" class="ltx_text" style="color:#000000;">Efficient NN-based noise sampling for physics simulations</span></td>
</tr>
<tr id="S2.T2.1.1.44.44" class="ltx_tr">
<td id="S2.T2.1.1.44.44.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.44.44.1.1" class="ltx_text" style="color:#000000;">Maier </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.44.44.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib56" title="" class="ltx_ref">56</a><span id="S2.T2.1.1.44.44.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.44.44.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.44.44.2.1" class="ltx_text" style="color:#000000;">Hybrid, Physics-Informed</span></td>
<td id="S2.T2.1.1.44.44.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.44.44.3.1" class="ltx_text" style="color:#000000;">X-ray</span></td>
<td id="S2.T2.1.1.44.44.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.44.44.4.1" class="ltx_text" style="color:#000000;">Any</span></td>
<td id="S2.T2.1.1.44.44.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.44.44.5.1" class="ltx_text" style="color:#000000;">Precision learning: incorporating priors into data-driven material decomposition</span></td>
</tr>
<tr id="S2.T2.1.1.45.45" class="ltx_tr">
<td id="S2.T2.1.1.45.45.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_tt" colspan="5"><span id="S2.T2.1.1.45.45.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">Applications</span></td>
</tr>
<tr id="S2.T2.1.1.46.46" class="ltx_tr">
<td id="S2.T2.1.1.46.46.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.46.46.1.1" class="ltx_text" style="color:#000000;">Teixeira </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.46.46.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib57" title="" class="ltx_ref">57</a><span id="S2.T2.1.1.46.46.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.46.46.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.46.46.2.1" class="ltx_text" style="color:#000000;">GAN</span></td>
<td id="S2.T2.1.1.46.46.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.46.46.3.1" class="ltx_text" style="color:#000000;">X-ray</span></td>
<td id="S2.T2.1.1.46.46.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.46.46.4.1" class="ltx_text" style="color:#000000;">Chest and Torso</span></td>
<td id="S2.T2.1.1.46.46.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.46.46.5.1" class="ltx_text" style="color:#000000;">X-ray synthesis from surface geometry</span></td>
</tr>
<tr id="S2.T2.1.1.47.47" class="ltx_tr">
<td id="S2.T2.1.1.47.47.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.47.47.1.1" class="ltx_text" style="color:#000000;">Frid-Adar </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.47.47.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib58" title="" class="ltx_ref">58</a><span id="S2.T2.1.1.47.47.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.47.47.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.47.47.2.1" class="ltx_text" style="color:#000000;">GAN</span></td>
<td id="S2.T2.1.1.47.47.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.47.47.3.1" class="ltx_text" style="color:#000000;">CT</span></td>
<td id="S2.T2.1.1.47.47.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.47.47.4.1" class="ltx_text" style="color:#000000;">Liver</span></td>
<td id="S2.T2.1.1.47.47.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.47.47.5.1" class="ltx_text" style="color:#000000;">Generative lesion synthesis</span></td>
</tr>
<tr id="S2.T2.1.1.48.48" class="ltx_tr">
<td id="S2.T2.1.1.48.48.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.48.48.1.1" class="ltx_text" style="color:#000000;">Azizmohammadi </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.48.48.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib59" title="" class="ltx_ref">59</a><span id="S2.T2.1.1.48.48.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.48.48.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.48.48.2.1" class="ltx_text" style="color:#000000;">GAN</span></td>
<td id="S2.T2.1.1.48.48.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.48.48.3.1" class="ltx_text" style="color:#000000;">X-ray</span></td>
<td id="S2.T2.1.1.48.48.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.48.48.4.1" class="ltx_text" style="color:#000000;">Heart</span></td>
<td id="S2.T2.1.1.48.48.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.48.48.5.1" class="ltx_text" style="color:#000000;">Generative learning to predict angiography frames</span></td>
</tr>
<tr id="S2.T2.1.1.49.49" class="ltx_tr">
<td id="S2.T2.1.1.49.49.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.49.49.1.1" class="ltx_text" style="color:#000000;">Ben-Cohen </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.49.49.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib60" title="" class="ltx_ref">60</a><span id="S2.T2.1.1.49.49.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.49.49.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.49.49.2.1" class="ltx_text" style="color:#000000;">GAN</span></td>
<td id="S2.T2.1.1.49.49.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.49.49.3.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.49.49.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.49.49.4.1" class="ltx_text" style="color:#000000;">Liver</span></td>
<td id="S2.T2.1.1.49.49.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.49.49.5.1" class="ltx_text" style="color:#000000;">CT to PET cross-modal synthesis for improved lesion detection</span></td>
</tr>
<tr id="S2.T2.1.1.50.50" class="ltx_tr">
<td id="S2.T2.1.1.50.50.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.50.50.1.1" class="ltx_text" style="color:#000000;">Mahmood </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.50.50.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib61" title="" class="ltx_ref">61</a><span id="S2.T2.1.1.50.50.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.50.50.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.50.50.2.1" class="ltx_text" style="color:#000000;">GAN</span></td>
<td id="S2.T2.1.1.50.50.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.50.50.3.1" class="ltx_text" style="color:#000000;">Endoscopy</span></td>
<td id="S2.T2.1.1.50.50.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.50.50.4.1" class="ltx_text" style="color:#000000;">Chest and Torso</span></td>
<td id="S2.T2.1.1.50.50.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.50.50.5.1" class="ltx_text" style="color:#000000;">Reverse domain adaptation to match real and synthetic images</span></td>
</tr>
<tr id="S2.T2.1.1.51.51" class="ltx_tr">
<td id="S2.T2.1.1.51.51.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.51.51.1.1" class="ltx_text" style="color:#000000;">Shin </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.51.51.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib62" title="" class="ltx_ref">62</a><span id="S2.T2.1.1.51.51.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.51.51.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.51.51.2.1" class="ltx_text" style="color:#000000;">GAN</span></td>
<td id="S2.T2.1.1.51.51.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.51.51.3.1" class="ltx_text" style="color:#000000;">MRI</span></td>
<td id="S2.T2.1.1.51.51.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.51.51.4.1" class="ltx_text" style="color:#000000;">Brain</span></td>
<td id="S2.T2.1.1.51.51.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.51.51.5.1" class="ltx_text" style="color:#000000;">Synthesis of abnormal images for improved tumor segmentation</span></td>
</tr>
<tr id="S2.T2.1.1.52.52" class="ltx_tr">
<td id="S2.T2.1.1.52.52.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.52.52.1.1" class="ltx_text" style="color:#000000;">Lewis </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.52.52.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib63" title="" class="ltx_ref">63</a><span id="S2.T2.1.1.52.52.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.52.52.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.52.52.2.1" class="ltx_text" style="color:#000000;">GAN</span></td>
<td id="S2.T2.1.1.52.52.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.52.52.3.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.52.52.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.52.52.4.1" class="ltx_text" style="color:#000000;">Chest and Torso</span></td>
<td id="S2.T2.1.1.52.52.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.52.52.5.1" class="ltx_text" style="color:#000000;">CT generation from X-ray for low-resource environments</span></td>
</tr>
<tr id="S2.T2.1.1.53.53" class="ltx_tr">
<td id="S2.T2.1.1.53.53.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.53.53.1.1" class="ltx_text" style="color:#000000;">Korkinof </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.53.53.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib64" title="" class="ltx_ref">64</a><span id="S2.T2.1.1.53.53.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.53.53.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.53.53.2.1" class="ltx_text" style="color:#000000;">GAN</span></td>
<td id="S2.T2.1.1.53.53.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.53.53.3.1" class="ltx_text" style="color:#000000;">DM</span></td>
<td id="S2.T2.1.1.53.53.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.53.53.4.1" class="ltx_text" style="color:#000000;">Breast</span></td>
<td id="S2.T2.1.1.53.53.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.53.53.5.1" class="ltx_text" style="color:#000000;">MammoGAN: generative synthesis of mammograms</span></td>
</tr>
<tr id="S2.T2.1.1.54.54" class="ltx_tr">
<td id="S2.T2.1.1.54.54.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.54.54.1.1" class="ltx_text" style="color:#000000;">Sun </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.54.54.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib1" title="" class="ltx_ref">1</a><span id="S2.T2.1.1.54.54.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.54.54.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.54.54.2.1" class="ltx_text" style="color:#000000;">GAN</span></td>
<td id="S2.T2.1.1.54.54.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.54.54.3.1" class="ltx_text" style="color:#000000;">MRI</span></td>
<td id="S2.T2.1.1.54.54.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.54.54.4.1" class="ltx_text" style="color:#000000;">Vertebrae</span></td>
<td id="S2.T2.1.1.54.54.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.54.54.5.1" class="ltx_text" style="color:#000000;">Private data sharing of medical images</span></td>
</tr>
<tr id="S2.T2.1.1.55.55" class="ltx_tr">
<td id="S2.T2.1.1.55.55.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.55.55.1.1" class="ltx_text" style="color:#000000;">Thambawita </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.55.55.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib2" title="" class="ltx_ref">2</a><span id="S2.T2.1.1.55.55.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.55.55.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.55.55.2.1" class="ltx_text" style="color:#000000;">GAN</span></td>
<td id="S2.T2.1.1.55.55.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.55.55.3.1" class="ltx_text" style="color:#000000;">Endoscopy</span></td>
<td id="S2.T2.1.1.55.55.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.55.55.4.1" class="ltx_text" style="color:#000000;">Gastrointestinal (GI)</span></td>
<td id="S2.T2.1.1.55.55.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.55.55.5.1" class="ltx_text" style="color:#000000;">SinGAN-Seg: synthetic data generation for improving polyp segmentation</span></td>
</tr>
<tr id="S2.T2.1.1.56.56" class="ltx_tr">
<td id="S2.T2.1.1.56.56.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.56.56.1.1" class="ltx_text" style="color:#000000;">Zunair </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.56.56.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib3" title="" class="ltx_ref">3</a><span id="S2.T2.1.1.56.56.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.56.56.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.56.56.2.1" class="ltx_text" style="color:#000000;">GAN</span></td>
<td id="S2.T2.1.1.56.56.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.56.56.3.1" class="ltx_text" style="color:#000000;">X-ray</span></td>
<td id="S2.T2.1.1.56.56.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.56.56.4.1" class="ltx_text" style="color:#000000;">Chest and Torso</span></td>
<td id="S2.T2.1.1.56.56.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.56.56.5.1" class="ltx_text" style="color:#000000;">Synthetic COVID-19 chest X-ray dataset created using CycleGAN</span></td>
</tr>
<tr id="S2.T2.1.1.57.57" class="ltx_tr">
<td id="S2.T2.1.1.57.57.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.57.57.1.1" class="ltx_text" style="color:#000000;">Salem </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.57.57.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib65" title="" class="ltx_ref">65</a><span id="S2.T2.1.1.57.57.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.57.57.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.57.57.2.1" class="ltx_text" style="color:#000000;">Generative</span></td>
<td id="S2.T2.1.1.57.57.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.57.57.3.1" class="ltx_text" style="color:#000000;">MRI</span></td>
<td id="S2.T2.1.1.57.57.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.57.57.4.1" class="ltx_text" style="color:#000000;">Brain</span></td>
<td id="S2.T2.1.1.57.57.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.57.57.5.1" class="ltx_text" style="color:#000000;">Multiple Sclerosis (MS) lesion synthesis</span></td>
</tr>
<tr id="S2.T2.1.1.58.58" class="ltx_tr">
<td id="S2.T2.1.1.58.58.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.58.58.1.1" class="ltx_text" style="color:#000000;">Prados </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.58.58.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib66" title="" class="ltx_ref">66</a><span id="S2.T2.1.1.58.58.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.58.58.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.58.58.2.1" class="ltx_text" style="color:#000000;">Generative</span></td>
<td id="S2.T2.1.1.58.58.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.58.58.3.1" class="ltx_text" style="color:#000000;">MRI</span></td>
<td id="S2.T2.1.1.58.58.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.58.58.4.1" class="ltx_text" style="color:#000000;">Brain</span></td>
<td id="S2.T2.1.1.58.58.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.58.58.5.1" class="ltx_text" style="color:#000000;">Pathology inpainting in MRI for Multiple Sclerosis (MS) applications</span></td>
</tr>
<tr id="S2.T2.1.1.59.59" class="ltx_tr">
<td id="S2.T2.1.1.59.59.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.59.59.1.1" class="ltx_text" style="color:#000000;">Konukoglu </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.59.59.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib67" title="" class="ltx_ref">67</a><span id="S2.T2.1.1.59.59.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.59.59.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.59.59.2.1" class="ltx_text" style="color:#000000;">Generative</span></td>
<td id="S2.T2.1.1.59.59.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.59.59.3.1" class="ltx_text" style="color:#000000;">MRI</span></td>
<td id="S2.T2.1.1.59.59.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.59.59.4.1" class="ltx_text" style="color:#000000;">Any</span></td>
<td id="S2.T2.1.1.59.59.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.59.59.5.1" class="ltx_text" style="color:#000000;">MRI artifact reduction</span></td>
</tr>
<tr id="S2.T2.1.1.60.60" class="ltx_tr">
<td id="S2.T2.1.1.60.60.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.60.60.1.1" class="ltx_text" style="color:#000000;">Li </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.60.60.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib68" title="" class="ltx_ref">68</a><span id="S2.T2.1.1.60.60.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.60.60.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.60.60.2.1" class="ltx_text" style="color:#000000;">VAE</span></td>
<td id="S2.T2.1.1.60.60.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.60.60.3.1" class="ltx_text" style="color:#000000;">MRI</span></td>
<td id="S2.T2.1.1.60.60.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.60.60.4.1" class="ltx_text" style="color:#000000;">Lung</span></td>
<td id="S2.T2.1.1.60.60.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.60.60.5.1" class="ltx_text" style="color:#000000;">Cross-modality synthesis for improved tumor segmentation</span></td>
</tr>
<tr id="S2.T2.1.1.61.61" class="ltx_tr">
<td id="S2.T2.1.1.61.61.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.61.61.1.1" class="ltx_text" style="color:#000000;">Chambon </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.61.61.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib69" title="" class="ltx_ref">69</a><span id="S2.T2.1.1.61.61.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.61.61.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.61.61.2.1" class="ltx_text" style="color:#000000;">DDPM</span></td>
<td id="S2.T2.1.1.61.61.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.61.61.3.1" class="ltx_text" style="color:#000000;">X-ray</span></td>
<td id="S2.T2.1.1.61.61.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.61.61.4.1" class="ltx_text" style="color:#000000;">Chest and Torso</span></td>
<td id="S2.T2.1.1.61.61.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.61.61.5.1" class="ltx_text" style="color:#000000;">RoentGen: text-to-image synthesis of X-rays</span></td>
</tr>
<tr id="S2.T2.1.1.62.62" class="ltx_tr">
<td id="S2.T2.1.1.62.62.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.62.62.1.1" class="ltx_text" style="color:#000000;">Stojanovski </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.62.62.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib5" title="" class="ltx_ref">5</a><span id="S2.T2.1.1.62.62.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.62.62.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.62.62.2.1" class="ltx_text" style="color:#000000;">DDPM</span></td>
<td id="S2.T2.1.1.62.62.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.62.62.3.1" class="ltx_text" style="color:#000000;">Ultrasound</span></td>
<td id="S2.T2.1.1.62.62.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.62.62.4.1" class="ltx_text" style="color:#000000;">Cardiac</span></td>
<td id="S2.T2.1.1.62.62.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.62.62.5.1" class="ltx_text" style="color:#000000;">Generation of synthetic ultrasound images for improved segmentation</span></td>
</tr>
<tr id="S2.T2.1.1.63.63" class="ltx_tr">
<td id="S2.T2.1.1.63.63.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.63.63.1.1" class="ltx_text" style="color:#000000;">Ali </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.63.63.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib6" title="" class="ltx_ref">6</a><span id="S2.T2.1.1.63.63.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.63.63.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.63.63.2.1" class="ltx_text" style="color:#000000;">DDPM</span></td>
<td id="S2.T2.1.1.63.63.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.63.63.3.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.63.63.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.63.63.4.1" class="ltx_text" style="color:#000000;">Chest and Torso</span></td>
<td id="S2.T2.1.1.63.63.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.63.63.5.1" class="ltx_text" style="color:#000000;">Spot the fake lungs: generation of synthetic X-ray and CT lung images</span></td>
</tr>
<tr id="S2.T2.1.1.64.64" class="ltx_tr">
<td id="S2.T2.1.1.64.64.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.64.64.1.1" class="ltx_text" style="color:#000000;">Gao </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.64.64.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib70" title="" class="ltx_ref">70</a><span id="S2.T2.1.1.64.64.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.64.64.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.64.64.2.1" class="ltx_text" style="color:#000000;">Patient-Based Model</span></td>
<td id="S2.T2.1.1.64.64.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.64.64.3.1" class="ltx_text" style="color:#000000;">CT</span></td>
<td id="S2.T2.1.1.64.64.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.64.64.4.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.64.64.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.64.64.5.1" class="ltx_text" style="color:#000000;">SyntheX: CT to X-ray simulation using DeepDRR</span></td>
</tr>
<tr id="S2.T2.1.1.65.65" class="ltx_tr">
<td id="S2.T2.1.1.65.65.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.65.65.1.1" class="ltx_text" style="color:#000000;">Xanthis </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.65.65.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib71" title="" class="ltx_ref">71</a><span id="S2.T2.1.1.65.65.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.65.65.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.65.65.2.1" class="ltx_text" style="color:#000000;">Patient-Based Model</span></td>
<td id="S2.T2.1.1.65.65.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.65.65.3.1" class="ltx_text" style="color:#000000;">MRI</span></td>
<td id="S2.T2.1.1.65.65.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.65.65.4.1" class="ltx_text" style="color:#000000;">Heart</span></td>
<td id="S2.T2.1.1.65.65.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.65.65.5.1" class="ltx_text" style="color:#000000;">Simulation of synthetic images via XCAT for improved segmentation</span></td>
</tr>
<tr id="S2.T2.1.1.66.66" class="ltx_tr">
<td id="S2.T2.1.1.66.66.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.66.66.1.1" class="ltx_text" style="color:#000000;">de Dumast </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.66.66.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib72" title="" class="ltx_ref">72</a><span id="S2.T2.1.1.66.66.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.66.66.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.66.66.2.1" class="ltx_text" style="color:#000000;">Patient-Based Model</span></td>
<td id="S2.T2.1.1.66.66.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.66.66.3.1" class="ltx_text" style="color:#000000;">MRI</span></td>
<td id="S2.T2.1.1.66.66.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.66.66.4.1" class="ltx_text" style="color:#000000;">Fetal</span></td>
<td id="S2.T2.1.1.66.66.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.66.66.5.1" class="ltx_text" style="color:#000000;">Simulation of fetal brain MRI from a phantom for domain adaptation</span></td>
</tr>
<tr id="S2.T2.1.1.67.67" class="ltx_tr">
<td id="S2.T2.1.1.67.67.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.67.67.1.1" class="ltx_text" style="color:#000000;">Pezeshk </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.67.67.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib73" title="" class="ltx_ref">73</a><span id="S2.T2.1.1.67.67.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.67.67.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.67.67.2.1" class="ltx_text" style="color:#000000;">Patient-Based Model</span></td>
<td id="S2.T2.1.1.67.67.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.67.67.3.1" class="ltx_text" style="color:#000000;">CT</span></td>
<td id="S2.T2.1.1.67.67.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.67.67.4.1" class="ltx_text" style="color:#000000;">Lung</span></td>
<td id="S2.T2.1.1.67.67.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.67.67.5.1" class="ltx_text" style="color:#000000;">Synthetic data generation using lesion insertion</span></td>
</tr>
<tr id="S2.T2.1.1.68.68" class="ltx_tr">
<td id="S2.T2.1.1.68.68.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.68.68.1.1" class="ltx_text" style="color:#000000;">Brumer </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.68.68.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib11" title="" class="ltx_ref">11</a><span id="S2.T2.1.1.68.68.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.68.68.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.68.68.2.1" class="ltx_text" style="color:#000000;">Patient-Based Model</span></td>
<td id="S2.T2.1.1.68.68.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.68.68.3.1" class="ltx_text" style="color:#000000;">MRI</span></td>
<td id="S2.T2.1.1.68.68.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.68.68.4.1" class="ltx_text" style="color:#000000;">Kidney</span></td>
<td id="S2.T2.1.1.68.68.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.68.68.5.1" class="ltx_text" style="color:#000000;">Arterial spin labeling (ASL) analysis using synthetic data generated from XCAT</span></td>
</tr>
<tr id="S2.T2.1.1.69.69" class="ltx_tr">
<td id="S2.T2.1.1.69.69.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.69.69.1.1" class="ltx_text" style="color:#000000;">Badano </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.69.69.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib9" title="" class="ltx_ref">9</a><span id="S2.T2.1.1.69.69.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.69.69.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.69.69.2.1" class="ltx_text" style="color:#000000;">KB Model</span></td>
<td id="S2.T2.1.1.69.69.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.69.69.3.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.69.69.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.69.69.4.1" class="ltx_text" style="color:#000000;">Breast</span></td>
<td id="S2.T2.1.1.69.69.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.69.69.5.1" class="ltx_text" style="color:#000000;">VICTRE: virtual clinical trial for comparing DM and DBT</span></td>
</tr>
<tr id="S2.T2.1.1.70.70" class="ltx_tr">
<td id="S2.T2.1.1.70.70.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.70.70.1.1" class="ltx_text" style="color:#000000;">Kadia </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.70.70.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib74" title="" class="ltx_ref">74</a><span id="S2.T2.1.1.70.70.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.70.70.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.70.70.2.1" class="ltx_text" style="color:#000000;">KB Model</span></td>
<td id="S2.T2.1.1.70.70.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.70.70.3.1" class="ltx_text" style="color:#000000;">CT</span></td>
<td id="S2.T2.1.1.70.70.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.70.70.4.1" class="ltx_text" style="color:#000000;">Any</span></td>
<td id="S2.T2.1.1.70.70.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.70.70.5.1" class="ltx_text" style="color:#000000;">A lung lesion model for improvement of segmentation performance</span></td>
</tr>
<tr id="S2.T2.1.1.71.71" class="ltx_tr">
<td id="S2.T2.1.1.71.71.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.71.71.1.1" class="ltx_text" style="color:#000000;">Gong </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.71.71.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib75" title="" class="ltx_ref">75</a><span id="S2.T2.1.1.71.71.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.71.71.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.71.71.2.1" class="ltx_text" style="color:#000000;">KB Model</span></td>
<td id="S2.T2.1.1.71.71.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.71.71.3.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.71.71.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.71.71.4.1" class="ltx_text" style="color:#000000;">Breast</span></td>
<td id="S2.T2.1.1.71.71.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.71.71.5.1" class="ltx_text" style="color:#000000;">Simulations-based comparison of DM, DBT, and cone-beam CT imaging</span></td>
</tr>
<tr id="S2.T2.1.1.72.72" class="ltx_tr">
<td id="S2.T2.1.1.72.72.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.72.72.1.1" class="ltx_text" style="color:#000000;">Nelson </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.72.72.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib76" title="" class="ltx_ref">76</a><span id="S2.T2.1.1.72.72.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.72.72.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.72.72.2.1" class="ltx_text" style="color:#000000;">KB Model</span></td>
<td id="S2.T2.1.1.72.72.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.72.72.3.1" class="ltx_text" style="color:#000000;">CT</span></td>
<td id="S2.T2.1.1.72.72.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.72.72.4.1" class="ltx_text" style="color:#000000;">Multiple</span></td>
<td id="S2.T2.1.1.72.72.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.72.72.5.1" class="ltx_text" style="color:#000000;">Assessment of DL-based CT denoising using computer simulations</span></td>
</tr>
<tr id="S2.T2.1.1.73.73" class="ltx_tr">
<td id="S2.T2.1.1.73.73.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.73.73.1.1" class="ltx_text" style="color:#000000;">Li </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.73.73.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib77" title="" class="ltx_ref">77</a><span id="S2.T2.1.1.73.73.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.73.73.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.73.73.2.1" class="ltx_text" style="color:#000000;">KB Model</span></td>
<td id="S2.T2.1.1.73.73.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.73.73.3.1" class="ltx_text" style="color:#000000;">CT</span></td>
<td id="S2.T2.1.1.73.73.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.73.73.4.1" class="ltx_text" style="color:#000000;">Lung</span></td>
<td id="S2.T2.1.1.73.73.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.73.73.5.1" class="ltx_text" style="color:#000000;">A lung nodule model for pediatric CT</span></td>
</tr>
<tr id="S2.T2.1.1.74.74" class="ltx_tr">
<td id="S2.T2.1.1.74.74.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.74.74.1.1" class="ltx_text" style="color:#000000;">Cha </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.74.74.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib78" title="" class="ltx_ref">78</a><span id="S2.T2.1.1.74.74.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.74.74.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.74.74.2.1" class="ltx_text" style="color:#000000;">Any</span></td>
<td id="S2.T2.1.1.74.74.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.74.74.3.1" class="ltx_text" style="color:#000000;">DM</span></td>
<td id="S2.T2.1.1.74.74.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.74.74.4.1" class="ltx_text" style="color:#000000;">Breast</span></td>
<td id="S2.T2.1.1.74.74.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.74.74.5.1" class="ltx_text" style="color:#000000;">Analysis of data augmentation via synthetic data for breast mass detection</span></td>
</tr>
<tr id="S2.T2.1.1.75.75" class="ltx_tr">
<td id="S2.T2.1.1.75.75.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="5"><span id="S2.T2.1.1.75.75.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">Surveys and Overviews</span></td>
</tr>
<tr id="S2.T2.1.1.76.76" class="ltx_tr">
<td id="S2.T2.1.1.76.76.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.76.76.1.1" class="ltx_text" style="color:#000000;">Kazerouni </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.76.76.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib12" title="" class="ltx_ref">12</a><span id="S2.T2.1.1.76.76.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.76.76.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" colspan="3"><span id="S2.T2.1.1.76.76.2.1" class="ltx_text" style="color:#000000;">Survey/Overview</span></td>
<td id="S2.T2.1.1.76.76.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.76.76.3.1" class="ltx_text" style="color:#000000;">Survey of DDPM models in medical imaging</span></td>
</tr>
<tr id="S2.T2.1.1.77.77" class="ltx_tr">
<td id="S2.T2.1.1.77.77.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.77.77.1.1" class="ltx_text" style="color:#000000;">Singh </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.77.77.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib13" title="" class="ltx_ref">13</a><span id="S2.T2.1.1.77.77.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.77.77.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" colspan="3"><span id="S2.T2.1.1.77.77.2.1" class="ltx_text" style="color:#000000;">Survey/Overview</span></td>
<td id="S2.T2.1.1.77.77.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.77.77.3.1" class="ltx_text" style="color:#000000;">Survey of GAN models in medical imaging</span></td>
</tr>
<tr id="S2.T2.1.1.78.78" class="ltx_tr">
<td id="S2.T2.1.1.78.78.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.78.78.1.1" class="ltx_text" style="color:#000000;">Pesapane </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.78.78.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib14" title="" class="ltx_ref">14</a><span id="S2.T2.1.1.78.78.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.78.78.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" colspan="3"><span id="S2.T2.1.1.78.78.2.1" class="ltx_text" style="color:#000000;">Survey/Overview</span></td>
<td id="S2.T2.1.1.78.78.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.78.78.3.1" class="ltx_text" style="color:#000000;">Discussion of digital twins in radiology</span></td>
</tr>
<tr id="S2.T2.1.1.79.79" class="ltx_tr">
<td id="S2.T2.1.1.79.79.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.79.79.1.1" class="ltx_text" style="color:#000000;">Badano </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.79.79.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib19" title="" class="ltx_ref">19</a><span id="S2.T2.1.1.79.79.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.79.79.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" colspan="3"><span id="S2.T2.1.1.79.79.2.1" class="ltx_text" style="color:#000000;">Survey/Overview</span></td>
<td id="S2.T2.1.1.79.79.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.79.79.3.1" class="ltx_text" style="color:#000000;">Survey of techniques for generating synthetic data models</span></td>
</tr>
<tr id="S2.T2.1.1.80.80" class="ltx_tr">
<td id="S2.T2.1.1.80.80.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.80.80.1.1" class="ltx_text" style="color:#000000;">Xu </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.80.80.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib79" title="" class="ltx_ref">79</a><span id="S2.T2.1.1.80.80.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.80.80.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" colspan="3"><span id="S2.T2.1.1.80.80.2.1" class="ltx_text" style="color:#000000;">Survey/Overview</span></td>
<td id="S2.T2.1.1.80.80.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.80.80.3.1" class="ltx_text" style="color:#000000;">Survey of computational phantom use for radiation dose quantification</span></td>
</tr>
<tr id="S2.T2.1.1.81.81" class="ltx_tr">
<td id="S2.T2.1.1.81.81.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.81.81.1.1" class="ltx_text" style="color:#000000;">Segars </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.81.81.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib80" title="" class="ltx_ref">80</a><span id="S2.T2.1.1.81.81.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.81.81.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" colspan="3"><span id="S2.T2.1.1.81.81.2.1" class="ltx_text" style="color:#000000;">Survey/Overview</span></td>
<td id="S2.T2.1.1.81.81.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.81.81.3.1" class="ltx_text" style="color:#000000;">Survey of 4-D XCAT applications</span></td>
</tr>
<tr id="S2.T2.1.1.82.82" class="ltx_tr">
<td id="S2.T2.1.1.82.82.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.82.82.1.1" class="ltx_text" style="color:#000000;">Kainz </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.82.82.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib81" title="" class="ltx_ref">81</a><span id="S2.T2.1.1.82.82.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.82.82.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" colspan="3"><span id="S2.T2.1.1.82.82.2.1" class="ltx_text" style="color:#000000;">Survey/Overview</span></td>
<td id="S2.T2.1.1.82.82.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.82.82.3.1" class="ltx_text" style="color:#000000;">Survey of computational human phantoms</span></td>
</tr>
<tr id="S2.T2.1.1.83.83" class="ltx_tr">
<td id="S2.T2.1.1.83.83.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.83.83.1.1" class="ltx_text" style="color:#000000;">Killeen </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.83.83.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib82" title="" class="ltx_ref">82</a><span id="S2.T2.1.1.83.83.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.83.83.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" colspan="3"><span id="S2.T2.1.1.83.83.2.1" class="ltx_text" style="color:#000000;">Survey/Overview</span></td>
<td id="S2.T2.1.1.83.83.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.83.83.3.1" class="ltx_text" style="color:#000000;">Survey of in silico simulation for minimally invasive surgery applications</span></td>
</tr>
<tr id="S2.T2.1.1.84.84" class="ltx_tr">
<td id="S2.T2.1.1.84.84.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.84.84.1.1" class="ltx_text" style="color:#000000;">Rodero </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.84.84.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib83" title="" class="ltx_ref">83</a><span id="S2.T2.1.1.84.84.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.84.84.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" colspan="3"><span id="S2.T2.1.1.84.84.2.1" class="ltx_text" style="color:#000000;">Survey/Overview</span></td>
<td id="S2.T2.1.1.84.84.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.84.84.3.1" class="ltx_text" style="color:#000000;">Survey of in silico clinical trials for cardiac applications</span></td>
</tr>
<tr id="S2.T2.1.1.85.85" class="ltx_tr">
<td id="S2.T2.1.1.85.85.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.85.85.1.1" class="ltx_text" style="color:#000000;">Guan </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.85.85.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib84" title="" class="ltx_ref">84</a><span id="S2.T2.1.1.85.85.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.85.85.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" colspan="3"><span id="S2.T2.1.1.85.85.2.1" class="ltx_text" style="color:#000000;">Survey/Overview</span></td>
<td id="S2.T2.1.1.85.85.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.85.85.3.1" class="ltx_text" style="color:#000000;">Survey of domain adaptation for medical image analysis</span></td>
</tr>
<tr id="S2.T2.1.1.86.86" class="ltx_tr">
<td id="S2.T2.1.1.86.86.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.86.86.1.1" class="ltx_text" style="color:#000000;">Candemir </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.86.86.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib85" title="" class="ltx_ref">85</a><span id="S2.T2.1.1.86.86.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.86.86.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" colspan="3"><span id="S2.T2.1.1.86.86.2.1" class="ltx_text" style="color:#000000;">Survey/Overview</span></td>
<td id="S2.T2.1.1.86.86.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.86.86.3.1" class="ltx_text" style="color:#000000;">Survey of techniques for training radiologic deep learning models in data-limited scenarios</span></td>
</tr>
<tr id="S2.T2.1.1.87.87" class="ltx_tr">
<td id="S2.T2.1.1.87.87.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.87.87.1.1" class="ltx_text" style="color:#000000;">Boulanger </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.87.87.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib86" title="" class="ltx_ref">86</a><span id="S2.T2.1.1.87.87.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.87.87.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" colspan="3"><span id="S2.T2.1.1.87.87.2.1" class="ltx_text" style="color:#000000;">Survey/Overview</span></td>
<td id="S2.T2.1.1.87.87.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.87.87.3.1" class="ltx_text" style="color:#000000;">Survey of data-driven methods for CT synthesis from MRI</span></td>
</tr>
<tr id="S2.T2.1.1.88.88" class="ltx_tr">
<td id="S2.T2.1.1.88.88.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.88.88.1.1" class="ltx_text" style="color:#000000;">Edmund </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.88.88.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib87" title="" class="ltx_ref">87</a><span id="S2.T2.1.1.88.88.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.88.88.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" colspan="3"><span id="S2.T2.1.1.88.88.2.1" class="ltx_text" style="color:#000000;">Survey/Overview</span></td>
<td id="S2.T2.1.1.88.88.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.88.88.3.1" class="ltx_text" style="color:#000000;">Survey of CT substitution methods in MRI-only imaging</span></td>
</tr>
<tr id="S2.T2.1.1.89.89" class="ltx_tr">
<td id="S2.T2.1.1.89.89.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.89.89.1.1" class="ltx_text" style="color:#000000;">DuMont Schütte </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.89.89.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib88" title="" class="ltx_ref">88</a><span id="S2.T2.1.1.89.89.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.89.89.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" colspan="3"><span id="S2.T2.1.1.89.89.2.1" class="ltx_text" style="color:#000000;">Survey/Overview</span></td>
<td id="S2.T2.1.1.89.89.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.89.89.3.1" class="ltx_text" style="color:#000000;">Benchmark of GAN techniques on chest X-ray and brain CT with a study of data sharing applications</span></td>
</tr>
<tr id="S2.T2.1.1.90.90" class="ltx_tr">
<td id="S2.T2.1.1.90.90.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.90.90.1.1" class="ltx_text" style="color:#000000;">Castiglioni </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.90.90.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib89" title="" class="ltx_ref">89</a><span id="S2.T2.1.1.90.90.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.90.90.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" colspan="3"><span id="S2.T2.1.1.90.90.2.1" class="ltx_text" style="color:#000000;">Survey/Overview</span></td>
<td id="S2.T2.1.1.90.90.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.90.90.3.1" class="ltx_text" style="color:#000000;">Survey of medical imaging AI systems used as clinical decision support tools</span></td>
</tr>
<tr id="S2.T2.1.1.91.91" class="ltx_tr">
<td id="S2.T2.1.1.91.91.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.91.91.1.1" class="ltx_text" style="color:#000000;">Kelkar </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.91.91.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib90" title="" class="ltx_ref">90</a><span id="S2.T2.1.1.91.91.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.91.91.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" colspan="3"><span id="S2.T2.1.1.91.91.2.1" class="ltx_text" style="color:#000000;">Survey/Overview</span></td>
<td id="S2.T2.1.1.91.91.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.91.91.3.1" class="ltx_text" style="color:#000000;">Overview of GAN assessment in medical imaging</span></td>
</tr>
<tr id="S2.T2.1.1.92.92" class="ltx_tr">
<td id="S2.T2.1.1.92.92.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.92.92.1.1" class="ltx_text" style="color:#000000;">Dar </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.92.92.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib91" title="" class="ltx_ref">91</a><span id="S2.T2.1.1.92.92.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.92.92.2" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" colspan="3"><span id="S2.T2.1.1.92.92.2.1" class="ltx_text" style="color:#000000;">Survey/Overview</span></td>
<td id="S2.T2.1.1.92.92.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S2.T2.1.1.92.92.3.1" class="ltx_text" style="color:#000000;">Assessment of data memorization in medical DDPM models</span></td>
</tr>
<tr id="S2.T2.1.1.93.93" class="ltx_tr">
<td id="S2.T2.1.1.93.93.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<span id="S2.T2.1.1.93.93.1.1" class="ltx_text" style="color:#000000;">Shorten </span><cite class="ltx_cite ltx_citemacro_cite"><span id="S2.T2.1.1.93.93.1.2.1" class="ltx_text" style="color:#000000;">[</span><a href="#bib.bib92" title="" class="ltx_ref">92</a><span id="S2.T2.1.1.93.93.1.3.2" class="ltx_text" style="color:#000000;">]</span></cite>
</td>
<td id="S2.T2.1.1.93.93.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" colspan="3"><span id="S2.T2.1.1.93.93.2.1" class="ltx_text" style="color:#000000;">Survey/Overview</span></td>
<td id="S2.T2.1.1.93.93.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t"><span id="S2.T2.1.1.93.93.3.1" class="ltx_text" style="color:#000000;">Survey of image data augmentation in deep learning</span></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span><span id="S2.T2.3.1" class="ltx_text" style="font-size:90%;">Types of models, application modalities and anatomies analyzed using synthetic data.</span></figcaption>
</figure>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Techniques for Synthetic Data Generation</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Techniques for synthetic imaging data generation can be broadly grouped into three categories: statistical generative modeling, physics-based modeling, and hybrid, physics-informed modeling. A summary of popular models, applicable imaging modalities anatomies can be found in Table <a href="#S2.T2" title="Table 2 ‣ 2 Terminology ‣ Synthetic Data in Radiological Imaging: Current State and Future Outlook" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Statistical Generative Models</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Generative models learn to synthesize outputs (images) that capture patterns and structures observed from existing patient images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> by processing the distribution of pixel intensities. Most recent models are based on various neural network architectures developed in the ML community.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p"><span id="S3.SS1.p2.1.1" class="ltx_text ltx_font_bold">Generative Adversarial Networks (GANs).</span> The key idea behind GANs, a popular type of generative model, involves two competing networks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>: the first network (generator) aims to synthesize data that resembles the distribution of real data while the second network (discriminator) aims to differentiate the synthetic data from the real data. <span id="S3.SS1.p2.1.2" class="ltx_text" style="color:#000000;"> The GAN training process is adversarial and approximately solves a min-max optimization problem, with the objective of creating new data that matches the statistical distribution of training data.</span> GANs have been used for generating synthetic training images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, creating annotations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, cross-domain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> and pseudo-healthy synthesis <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. <span id="S3.SS1.p2.1.3" class="ltx_text" style="color:#000000;"> Extensions of GANs include CycleGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, which enables image domain transformation without the need for paired data, and AmbientGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, which learns implicit generative models from lossy measurements of the distribution of interest. Both variants have found numerous applications in medical imaging <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>.</span></p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p"><span id="S3.SS1.p3.1.1" class="ltx_text ltx_font_bold">Normalizing Flow (NF).</span> Normalizing flows are part of the generative model family that learn an invertible transformation, typically represented by a neural network, from a well-understood base distribution (e.g., multivariate Gaussian) to a complex data distribution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. This base distribution serves as the starting point (“prior”) from <span id="S3.SS1.p3.1.2" class="ltx_text" style="color:#000000;"> which data is generated</span>. NF learns a series of transformations to morph this base distribution to the target data distribution, enabling the generation of synthetic data that mimics the original. As compared to GANs, NFs offer an opportunity for a more profound interaction with the inherent data properties. While NFs do not inherently model physical properties of the data, their ability to provide exact likelihood evaluation allows them to better capture these properties if they significantly influence the data distribution. Nevertheless, incorporating domain-specific knowledge or physical laws directly into the flow structure is still an active area of research <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>.
In radiology, NFs have recently gained some attention in applications such as <span id="S3.SS1.p3.1.3" class="ltx_text" style="color:#000000;"> image reconstruction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite></span> and data augmentation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p"><span id="S3.SS1.p4.1.1" class="ltx_text ltx_font_bold">Variational Autoencoders (VAEs).</span> VAEs leverage the principles of autoencoding and variational inference <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, and consist of two components: an encoder network and a decoder network. The encoder transforms the input data into a specific distribution in the latent space. The decoder samples points from this latent distribution and attempts to reconstruct the original data. Through this process, VAEs can learn a stochastic, continuous <span id="S3.SS1.p4.1.2" class="ltx_text" style="color:#000000;"> bidirectional</span> mapping between the data and latent space. <span id="S3.SS1.p4.1.3" class="ltx_text" style="color:#000000;"> When only a limited number of training examples are available, combining variational inference with GANs may help avoid mode collapse, i.e., generation of uniform or blurry examples <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>.</span></p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p"><span id="S3.SS1.p5.1.1" class="ltx_text ltx_font_bold">Denoising Diffusion Probabilistic Models (DDPMs).</span> DDPMs are a type of generative model that <span id="S3.SS1.p5.1.2" class="ltx_text" style="color:#000000;"> represents image formation</span> as a diffusion process. This process starts with the actual data and gradually adds noise until a simple noise distribution is reached <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>. To generate new data, the procedure is reversed by taking a sample from the simple noise distribution and iteratively applying a learned denoising operation, until the original data distribution is recovered. Here, noise operations are typically parametrized by a deep neural network, allowing the model to learn complex transformations between the noise and data distributions. By using a noisy and stochastic transition process, DDPMs are able to model a wide variety of data distributions. Compared to GANs and VAEs, DDPMs may be easier to train and have a faster inference time <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Physical Modeling</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Synthetic data generation using physical modeling typically includes two components <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>: a digital model representing a patient or patient populations, and a digital model of an acquisition device (imaging system).</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Digital Human Models</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">Digital human models for computational simulations have been developed extensively over the past decades for different applications, particularly radiation dosimetry <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib79" title="" class="ltx_ref">79</a>]</cite>. Recent research has focused on the development of models with increased spatial resolution and anatomical realism. The level of detail and anatomic diversity in these models depend on the method of generation and the range of anatomy covered (whole body or specific regions).
The majority of digital human models are derived from detailed segmentations of tomographic images of patients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>. The voxelized organs resulting from the segmentation process can be converted to surface mesh models to allow modifications and repositioning.
Each organ is then assigned appropriate material properties depending on the intended use of the model. An early example is the Virtual Population VIP3.0 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>, a collection of digital human models developed for electromagnetic (EM) exposure evaluations.
<span id="S3.SS2.SSS1.p1.1.1" class="ltx_text" style="color:#000000;"> Another popular digital human model, </span>the Extended Cardiac Torso (XCAT) phantom <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib80" title="" class="ltx_ref">80</a>]</cite>, used a few reference surface phantoms and registered them to patient images to create large cohorts of digital models. The XCAT incorporates respiratory and cardiac motion, and has sufficient resolution to be used in imaging. Detailed digital human models have been used extensively in a range of applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib81" title="" class="ltx_ref">81</a>]</cite>, ranging from developing image processing and reconstruction methods to motion compensation.
Anatomic models of specific parts of the body are also commonly used, particularly for breast imaging applications. For example, a procedurally-generated stochastic breast model including a skin layer, blood vessels, glandular ducts, fat and other components was created by Graff et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, and used in the evaluation of full-field digital mammography and tomosynthesis in the Virtual Imaging Clinical Trial for Regulatory Evaluation (VICTRE) project <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Digital Acquisition Device Models</h4>

<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p">Radiological images can be reliably simulated in silico because the physical processes underlying the generation, propagation and detection of radiation (from optical light to gamma rays) are well understood. Physics-based digital replicas of radiation sources and detectors, coupled with realistic transport of radiation through digital phantoms, are used to create synthetic images that reproduce the features of images acquired with physical devices. The required accuracy of the image generation process depends on the context of use (COU) of the images. Typically, more realistic images can be generated by implementing more sophisticated physics models, at the expense of increasing the computational complexity. As an example, x-ray projections of digital phantoms can be efficiently simulated using Siddon’s ray-tracing algorithm, which models x-rays as straight lines from the source to the center of each pixel. However, if the pixel noise statistics or the contribution from scattered radiation are relevant to the context of use, more sophisticated Monte Carlo (MC) methods that track the interactions of individual x-rays might be necessary.</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p id="S3.SS2.SSS2.p2.1" class="ltx_p">Numerous software packages have been developed to simulate different imaging modalities. For example, DukeSim <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> and XCIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> simulate commercial computed tomography (CT) scanners using a combination of ray-tracing and MC methods. MC-GPU <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> implements a GPU-accelerated MC code for cone-beam computed tomography (CT), mammography and tomosynthesis (as shown in Fig. 1). Nuclear medicine applications can be simulated with the MC tools from the OpenGATE Collaboration <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>.
Simulation packages for imaging modalities not using ionizing radiation such as magnetic resonance imaging (MRI) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> and <span id="S3.SS2.SSS2.p2.1.1" class="ltx_text" style="color:#000000;"> ultrasound <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite></span> are also available. <span id="S3.SS2.SSS2.p2.1.2" class="ltx_text" style="color:#000000;">A comprehensive review of various simulation frameworks for visible light (endoscopic), ultrasound and x-ray imaging, as well as their applications in intelligent surgical systems is given by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib82" title="" class="ltx_ref">82</a>]</cite>.</span></p>
</div>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Hybrid, Physics-Informed Models</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Although recent advances in parallel computing, including graphical processing units (GPU), have allowed for complex physics-based simulations, such simulations may still often be prohibitive due to the computational <span id="S3.SS3.p1.1.1" class="ltx_text" style="color:#000000;"> overhead</span>. Hybrid, physics-informed models address this concern by accelerating select components of synthetic data generation with deep learning. Alternatively, physics-informed neural networks embed physical constraints to create more realistic outputs or reduce the amount of training samples needed to learn a task. For example, deepDRR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> speeds up generation of fluoroscopy and digital radiology from computed tomography (CT) scans by performing ML for scatter estimation and material decomposition, while retaining an analytic approach for other pipeline components. There are several other examples. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> proposed a deep scatter estimation (DSE) technique that is within 2% of traditional Monte Carlo simulations used for cone beam CT acquisition. In fact, a neural network (NN) can learn to sample from a given probability density function (PDF) with high sampling efficiency <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>, making it useful for noise modeling in physical simulations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib93" title="" class="ltx_ref">93</a>]</cite>. <span id="S3.SS3.p1.1.2" class="ltx_text" style="color:#000000;"> Finally, when known operators are combined together with NNs to inform the latter about known prior information during the training and inference, a NN may require less training data, training iterations, or achieve better performance levels <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>.</span></p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Synthesizing Disease Models</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">The lack of well-curated and labeled data is particularly acute for diseased cases. Synthetic examples generated using generative modelling have been explored for creating various types of lesions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib74" title="" class="ltx_ref">74</a>, <a href="#bib.bib65" title="" class="ltx_ref">65</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>. Alternatively, lesions could also be synthetically in-painted (i.e., removed) to reduce impact on image processing tasks such as registration or segmentation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite>. In silico, knowledge-based models of disease have been developed for various organs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite>. An important consideration for lesion models is their growth pattern <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>, since lesion presentation may be affected by properties of the surrounding tissue.</p>
</div>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Limitations of Data Generation Techniques</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">Statistical generative models are typically trained using images (e.g., collections of x-rays) and are able to rapidly generate examples from the learnt generative distributions. However, they may not learn appropriate physical constraints or causal links between attributes and physical findings, and thus often suffer from generating hallucinated findings or unrealistic anatomy. On the other hand, physics-based approaches are grounded in physiology naturally embedded in the digital human model, and are able to generate high-quality and fully-detailed outputs controlled by the input parametrization. These approaches, however, may require more time-consuming and computationally intensive simulations. In addition, physical modelling approaches are constrained by the variability of the parameter space of the digital human model and acquisition system, but the complexity of the model can be adjusted based on the task of interest. Hybrid, physics-informed models are typically designed to accelerate components of physics-based approaches using neural networks, which may result in loss of realism, limited variability or constrained generalization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>. <span id="S3.SS5.p1.1.1" class="ltx_text" style="color:#000000;"> The <span id="S3.SS5.p1.1.1.1" class="ltx_text ltx_font_italic">generative learning trilemma</span> states that current data generation approaches cannot generate high-quality, diverse samples fast enough  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib94" title="" class="ltx_ref">94</a>]</cite>.</span> On the other hand, generative models and mechanistic physical models may be complementary <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib95" title="" class="ltx_ref">95</a>]</cite>.</p>
</div>
<div id="S3.SS5.p2" class="ltx_para">
<p id="S3.SS5.p2.1" class="ltx_p"><span id="S3.SS5.p2.1.1" class="ltx_text ltx_font_bold">Patient-Derived Models.</span>
All models (whether generative or physics-based), that are created solely based on a fixed set of patients are limited to properties (e.g., presence of disease) observed during training, rather than full object properties that may characterize the population of interest. <span id="S3.SS5.p2.1.2" class="ltx_text" style="color:#000000;"> For example, patients with advanced breast cancer may be not captured by a patient-derived model that did not include such patients in the training set.</span> Such properties are better captured by knowledge-based models, derived from physical or biological measurements<span id="S3.SS5.p2.1.3" class="ltx_text" style="color:#000000;">, to the extent that the knowledge is representative of the patient population</span>. In addition, patient-derived models may be constrained by the quality <span id="S3.SS5.p2.1.4" class="ltx_text" style="color:#000000;"> and resolution</span> of the training data, including noise, artifacts, contrast constraints, and missing data.</p>
</div>
<div id="S3.SS5.p3" class="ltx_para">
<p id="S3.SS5.p3.1" class="ltx_p"><span id="S3.SS5.p3.1.1" class="ltx_text ltx_font_bold">Null Space.</span> Image-based methods, whether parametric or generative, are limited by the existence of a null space, which results from mapping a continuous object to a discrete image by an acquisition system, resulting in an unavoidable loss of information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib96" title="" class="ltx_ref">96</a>]</cite>. This limitation can be addressed by either learning from object models (typically via physics-based simulations) or by modifying the generative model training process to capture image degradation during training <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>.</p>
</div>
<div id="S3.SS5.p4" class="ltx_para">
<p id="S3.SS5.p4.1" class="ltx_p"><span id="S3.SS5.p4.1.1" class="ltx_text ltx_font_bold">Realism.</span> A key concern in the use of any synthetic data is its realism, i.e., the size of the distribution gap between real and synthetic examples, particularly in areas that affect device performance. <span id="S3.SS5.p4.1.2" class="ltx_text" style="color:#000000;"> Prior to integration of real and synthetic datasets, some pre-processing methods can be implemented to reduce the distribution gap, either using engineered features or learnt image transformations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib84" title="" class="ltx_ref">84</a>, <a href="#bib.bib70" title="" class="ltx_ref">70</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. However, the problem of mitigating the ‘synth2real’ gap still remains a hurdle. Also, one of the drawbacks of using statistical generative models for data augmentation is that the supplementary generated examples may not extend beyond the training distribution of the model.</span></p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Applications</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Algorithm Development and Training</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Synthetic examples have been widely used as a source of training data, either on their own or combined with real patient images. This approach has been well-explored across many types of radiological imaging <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>. For instance, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> showed that augmenting limited patient x-rays with synthetic images reduced marker localization error. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib78" title="" class="ltx_ref">78</a>]</cite> demonstrated that the addition of synthetic mammograms generated using in silico imaging improved performance according to breast mass detection free-response receiver operating characteristic (FROC) as compared to results from patient data alone. Several studies have used GANs for data augmentation and improved the performance of their algorithms, as seen in liver lesion classification on CT images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>, brain segmentation on CT and MRI images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib97" title="" class="ltx_ref">97</a>]</cite>. <span id="S4.SS1.p1.1.1" class="ltx_text" style="color:#000000;"> Synthetic images can address class imbalance concerns, but only if the synthetic images deviate sufficiently from the existing patient data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib85" title="" class="ltx_ref">85</a>]</cite>.</span></p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Image Reconstruction and Cross-modality Synthesis.</span> 
There has been a number of works that aim to predict one modality (e.g., CT) from another (e.g., x-ray) for improving image quality and decreasing number of artifacts <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite>, reducing radiation exposure <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>, and <span id="S4.SS1.p2.1.2" class="ltx_text" style="color:#000000;"> improving prediction accuracy (e.g., lesion detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite>)</span>. CT prediction from MRI has been particularly well-explored <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib86" title="" class="ltx_ref">86</a>]</cite>, as tissue electron density information from CT is needed for radiotherapy planning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib87" title="" class="ltx_ref">87</a>]</cite>.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">Source of Annotations.</span> <span id="S4.SS1.p3.1.2" class="ltx_text" style="color:#000000;">A significant advantage of synthetically generated examples is that they can be generated to include pixel-level annotations needed for training AI algorithms, thus reducing the annotation burden while retaining or even improving accuracy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite>, since pixel-level labels are particularly challenging to annotate. Segmentation supervision for images can be obtained either using deep conditional generation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> (i.e., generating images conditionally on an input segmentation mask) or using simulation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>, <a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> (where segmentation truth is obtained from a digital model).</span></p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Algorithm Testing</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p"><span id="S4.SS2.p1.1.1" class="ltx_text" style="color:#000000;">Synthetic data can be used for generating standardized testing examples that would be otherwise too difficult to acquire from patient images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib75" title="" class="ltx_ref">75</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>. When a synthetic dataset is used for testing, it is particularly important to ensure that this dataset is representative of the intended patient population in order for performance estimates to be accurate. Thus, compared to the scenario where synthetic data is used for training, the evaluation requirements for synthetic testing data are more stringent. </span></p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Sizikova et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> introduced the idea of using synthetic images for comparative performance testing in medical imaging, where AI is evaluated on known trends with respect to physical properties (e.g., mass size). For this application, physics-based synthetic simulations are particularly useful since they can be used to easily re-generate examples with modifications to physical properties (e.g., size or radiation dose), while obtaining similar patient examples may not be practically possible. An emerging application of synthetic data is within in silico clinical trials, where results from computer simulations are used in development or regulatory evaluation of a medicinal product, device, or intervention<span id="S4.SS2.p2.1.1" class="ltx_text" style="color:#000000;"> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib83" title="" class="ltx_ref">83</a>]</cite></span>. Here, synthetic data complements patient data for evaluation of novel treatment methodologies or medical devices. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> has shown that an in silico clinical trial comparing digital mammography (DM) and digital breast tomosynthesis (DBT) imaging modalities replicated the results of an in situ (non synthetic) clinical study involving hundreds of enrolled women. As discussed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib98" title="" class="ltx_ref">98</a>]</cite>, in silico trials are not identical to their in situ counterparts, and could provide evidence not found in traditional clinical trials <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib99" title="" class="ltx_ref">99</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Patient Privacy Preservation</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Synthetic data can act as an anonymization tool to protect patient characteristics while sharing data. For instance, a recent study <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib88" title="" class="ltx_ref">88</a>]</cite> has evaluated the quality of GAN-generated synthetic chest radiographs as an alternative to sharing patient chest radiographs and brain CT, and showed that NN performance matched closely when trained on either synthetic or real examples, but suffered when a larger number of classes (labels) was considered. <span id="S4.SS3.p1.1.1" class="ltx_text" style="color:#000000;"> However, the risk of generative models inadvertently memorizing specific data points, thereby compromising patient privacy, cannot be ignored <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib100" title="" class="ltx_ref">100</a>]</cite>. We refer the reader to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib101" title="" class="ltx_ref">101</a>]</cite> for a discussion of synthetic healthcare data privacy and associated risk mitigation measures. Finally, a recent set of recommendations for utilizing and evaluating differential privacy (AI) published by the National Institute of Standards and Technology (NIST) can be found in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib102" title="" class="ltx_ref">102</a>]</cite>.</span></p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Addressing Bias and Other Limitations of Patient Datasets</h3>

<section id="S4.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.1 </span>Class Imbalance and Modality Availability</h4>

<div id="S4.SS4.SSS1.p1" class="ltx_para">
<p id="S4.SS4.SSS1.p1.1" class="ltx_p">Many datasets are prone to data imbalance, i.e., an uneven data distribution across classes, due to, for instance, the secondary use of data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib103" title="" class="ltx_ref">103</a>]</cite>. <span id="S4.SS4.SSS1.p1.1.1" class="ltx_text" style="color:#000000;"> A popular technique to address this issue in imaging studies is the use of resampling techniques that synthetically resize training datasets to obtain more balanced distributions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib89" title="" class="ltx_ref">89</a>]</cite>. Algorithmic fairness approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib104" title="" class="ltx_ref">104</a>]</cite> may be used to balance out uneven distributions in available patient datasets. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib105" title="" class="ltx_ref">105</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> demonstrated the benefits of synthetic radiologic data created using generative models conditioned on various input attributes, such as examples with limited annotations or less frequent categories, to address class imbalances arising from existing data. As discussed in Section <a href="#S4.SS1" title="4.1 Algorithm Development and Training ‣ 4 Applications ‣ Synthetic Data in Radiological Imaging: Current State and Future Outlook" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4.1</span></a>, synthetic data can also be used to impute missing information. </span></p>
</div>
</section>
<section id="S4.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">4.4.2 </span>Enrichment of Underrepresented Populations</h4>

<div id="S4.SS4.SSS2.p1" class="ltx_para">
<p id="S4.SS4.SSS2.p1.1" class="ltx_p">An attractive feature of synthetic data is that it can be used to generate examples from known and underrepresented populations, such as patients with rare diseases and protected populations. For instance, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite> reported the creation of synthetic training data by inserting rare abnormal tumors into MRIs and demonstrated that this process improved model performance on patient examples. in another work, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite> investigated TB classification using synthetically generated CT over patient X-ray alone, and discussed the potential applications of synthetic data in supplementing costly imaging procedures for resource-poor communities.</p>
</div>
<div id="S4.SS4.SSS2.p2" class="ltx_para">
<p id="S4.SS4.SSS2.p2.1" class="ltx_p">Protected populations are also notoriously difficult to obtain data points from, and are a potential candidate for synthetic data use. For example, pediatric patients represent 20% of the US population, but make up only 5% of imaging studies  <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib106" title="" class="ltx_ref">106</a>]</cite>. Pediatric radiology datasets are particularly difficult to acquire due <span id="S4.SS4.SSS2.p2.1.1" class="ltx_text" style="color:#000000;"> to a</span> lack of domain specialist annotators, lower study numbers, added safety concerns and regulatory requirements, all of which contribute to a lack of AI applications for these patients <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib107" title="" class="ltx_ref">107</a>]</cite>. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib76" title="" class="ltx_ref">76</a>]</cite> simulated pediatric-size phantoms to evaluate AI denoising algorithms in newborn to adolescent sizes. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> demonstrated that synthetically generated pediatric liver CT images with in-painted lesions were indistinguishable to real counterparts when read by radiologists. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib77" title="" class="ltx_ref">77</a>]</cite> showed that CT images of synthetic and patient lung nodules in pediatric patients were perceptually indistinguishable. <span id="S4.SS4.SSS2.p2.1.2" class="ltx_text" style="color:#000000;"> Finally, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib72" title="" class="ltx_ref">72</a>]</cite> explored applications of synthetic data to AI-based segmentation of brain tissues in fetal MRI.</span></p>
</div>
<div id="S4.SS4.SSS2.p3" class="ltx_para">
<p id="S4.SS4.SSS2.p3.1" class="ltx_p"><span id="S4.SS4.SSS2.p3.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">Considerations.<span id="S4.SS4.SSS2.p3.1.1.1" class="ltx_text ltx_font_medium"> A key challenge in synthetic data use for underrepresented populations is that it is inherently hard to find samples to build a robust training dataset for the data generation model to ensure that it does not perpetuate existing biases <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib108" title="" class="ltx_ref">108</a>]</cite>. While approaches such as class-specific few-shot learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib109" title="" class="ltx_ref">109</a>, <a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite> may mitigate the issue, under such conditions, physical modeling, which typically requires fewer parameters, may be advantageous. In either case, attention must be given not to perpetuate existing biases present in the data or the knowledge model. </span></span></p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Data Assessment Metrics</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p"><span id="S5.p1.1.1" class="ltx_text ltx_font_bold">Fidelity and Utility.</span> Evaluating synthetic radiological data is important to ensure that the generated data can serve its intended purpose. Synthetic data is often assessed in terms of its <span id="S5.p1.1.2" class="ltx_text ltx_font_italic">fidelity</span>, i.e., whether it captures statistical inter-relationships of patient datasets, or its <span id="S5.p1.1.3" class="ltx_text ltx_font_italic">utility</span>, i.e., whether it achieves similar results (e.g., downstream task performance) as patient data. A high-fidelity dataset therefore should have high utility <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, however, high utility may not be necessary for applications such as an understanding of relative trends. <span id="S5.p1.1.4" class="ltx_text" style="color:#000000;">Fidelity metrics (e.g., Frechet Inception Distance (FID)) may capture summary statistics, single or pairwise distributional patterns, more complex interrelationships between variables in the synthetic and/or patient data points and or consistency with clinical domain expertise <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib90" title="" class="ltx_ref">90</a>]</cite>.</span> As the number of data dimensions increase, measuring fidelity becomes increasingly complex due to the exponentially increasing number of interrelationships <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib110" title="" class="ltx_ref">110</a>]</cite>.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p"><span id="S5.p2.1.1" class="ltx_text ltx_font_bold">Types of Utility Metrics.</span> As discussed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, utility metrics measure distance between patient and synthetic data and could be grouped into work-aware evaluations (metrics that compare real and synthetic data performance in tasks of interest), generic utility measures (metrics that compare general distance metrics between real and synthetic data), and subjective assessments (metrics that compare perceptual quality of synthetic and patient data based on domain expert assessment in a user study). How to evaluate synthetic radiological data is an on-going and open research problem. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> compared synthetic and real examples using distributions of top five moments. Work-aware evaluations (alternatively, task-based performance) is another popular method of evaluating synthetic data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>, particularly when the underlying real data distribution is unknown. Objective assessment of image quality in medical applications has been extensively studied <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib111" title="" class="ltx_ref">111</a>]</cite>. While current metrics provide some level of assessment for synthetic radiological data, they have limitations <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>, <a href="#bib.bib110" title="" class="ltx_ref">110</a>]</cite>, and may overlook issues such as hallucinations and memorization in synthetic radiological data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib113" title="" class="ltx_ref">113</a>]</cite>.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p"><span id="S5.p3.1.1" class="ltx_text ltx_font_bold">Subjective Assessment.</span> Subjective assessment metrics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib114" title="" class="ltx_ref">114</a>]</cite> typically include user studies or visual clinical assessments with reader studies. <span id="S5.p3.1.2" class="ltx_text" style="color:#000000;">
One well-known example is the visual Turing test (sometimes known as a “fool the human” study design), a commonplace approach to evaluate the realism of synthetic images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib73" title="" class="ltx_ref">73</a>]</cite> that derives from Turing’s work on machine intelligence <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib115" title="" class="ltx_ref">115</a>]</cite>. In a Turing test, radiologists are tasked with distinguishing between synthetic and real images. Several studies found that the performance of radiologists is at almost guessing levels <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib73" title="" class="ltx_ref">73</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, since a visual Turing test includes subjective and highly noisy nature of the interrogator <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib115" title="" class="ltx_ref">115</a>]</cite>. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> described a study where five radiologists were asked to evaluate mammography and breast tomosynthesis (DBT) images, comparing mass appearance in patient images and in images where MRI-derived, spiculated lesions were artificially inserted. Results showed that humans were only marginally capable of distinguishing synthetic from natural masses with an area-under-the-ROC curve averaged across observers of 0.54 (95% confidence interval [0.50, 0.66]) for the 2D study and 0.67 (95% confidence interval [0.55, 0.79]) for tomosynthesis. It is important to note that the result of the Turing test (whether human readers can correctly identify synthetic samples) may or may not be relevant for determining whether computational models and simulation tools are useful for evaluating new imaging systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib116" title="" class="ltx_ref">116</a>]</cite>.
</span></p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p"><span id="S5.p4.1.1" class="ltx_text ltx_font_bold">Future Directions</span>
A number of existing metrics for evaluating synthetic data already exist today <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib112" title="" class="ltx_ref">112</a>]</cite>. One future direction would involves establishing a standardized and comprehensive framework that can provide a holistic evaluation of synthetic data, ensuring that metrics are tailored to the application and offering a multifaceted view of performance, verifying that the synthetic data meets its intended purpose.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Challenges for the Use of Synthetic Data</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p"><span id="S6.p1.1.1" class="ltx_text" style="color:#000000;">As in other fields, applications of synthetic data in radiological imaging suffer from data complexity (multi-scale models spanning several scientific disciplines), disclosure limitations (no robust platform to develop and disseminate models), data privacy and data ownership concerns. Below, we discuss some existing challenges associated with practical use and evaluation of synthetic radiological data.</span></p>
</div>
<section id="S6.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection" style="color:#000000;">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Scientific Challenges</h3>

<div id="S6.SS1.p1" class="ltx_para">
<p id="S6.SS1.p1.1" class="ltx_p"><span id="S6.SS1.p1.1.1" class="ltx_text" style="color:#000000;">To ensure the safety and effectiveness of new biomedical technologies developed or evaluated with synthetic data, additional research is needed to better understand the uncertainty and bias of synthetic data generation approaches. An open area of research is the development of metrics for characterizing individual or population representation in a synthetic dataset and for evaluating the reliability of algorithm performance (e.g., does the algorithm performance reported on a synthetic dataset match the performance on a real patient dataset).</span><span id="S6.SS1.p1.1.2" class="ltx_text"> In addition, techniques to ensure unbiased outcomes from utilizing synthetic data need to be developed, in particular, to ensure that using synthetic data does not lead to shortcuts as compared to real examples. Moreover, statistical methods that optimize the incorporation of synthetic data into small patient test datasets need to be investigated. Finally, there is a need for methods and tools to quantify and improve the generalizability of the synthetic data when replicating different scenarios in terms of the clinical settings, population characteristics, and imaging device properties. In this context, methods and techniques to safely reuse synthetic data in the development and evaluation stages of new technology, as well as in post-market “in-the-wild” monitoring programs are needed including sound methods for data reuse and for practical and efficient data sequestration strategies.</span></p>
</div>
</section>
<section id="S6.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Evaluation Challenges</h3>

<div id="S6.SS2.p1" class="ltx_para">
<p id="S6.SS2.p1.1" class="ltx_p">The key challenge of using synthetic data in the context of medical device evaluation concerns validation requirements that should be sufficiently strict to support the data usage. Synthetic data may be used in multiple ways within the context of regulatory evaluations with different evidentiary requirements. Regardless of the specific application, evidence must exist to show that synthetic data within a regulatory submission can be sufficiently relied upon to support the claims made. Depending on how the synthetic data is used, this may include synthetic examples with patient data, cross-validation of synthetic data using different data generation techniques, or distribution gap analysis between patient and synthetic data. The greater the prominence of synthetic data in the submission, the higher the evidentiary requirements. As an example, a computer-aided diagnostic device may use a data augmentation strategy incorporating synthetic examples into its training data. Validation of such supplementary data may include demonstrating that the synthetic data distribution follows a similar distribution in specific features as with real data, and that its use improves performance of the studied algorithm in real data. Primary research supporting the safety and effectiveness of the device would continue to come from a robust test set of real patients.</p>
</div>
<div id="S6.SS2.p2" class="ltx_para">
<p id="S6.SS2.p2.1" class="ltx_p">As all models carry inherent assumptions, ensuring congruence between the use of the synthetic data in technology assessment and the original purpose of the data generation model is essential. The US Food and Drug Administration (FDA) applies the term <span id="S6.SS2.p2.1.1" class="ltx_text ltx_font_italic">“Context of Use (COU)”</span> to describe the way the synthetic data/algorithm/model is to be used. For a radiological device reliant on an AI algorithm, the context of use is the specific role and scope of the device, a detailed description of what will be modeled and how the device outputs will be used to answer specific questions of interest<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>See FDA guidance titled “<span id="footnote2.1" class="ltx_text ltx_font_italic">Assessing the Credibility of Computational Modeling and Simulation in Medical Device Submissions</span>” [<a target="_blank" href="https://www.fda.gov/media/154985/download" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.fda.gov/media/154985/download</a>].</span></span></span>. The context of use, the influence of the model in the regulatory decision, and the consequences of decision on patients, inform the validation and performance criteria necessary for the synthetic data to be relied upon for regulatory purposes.</p>
</div>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Summary</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">Synthetic data shows great promise in advancing radiological imaging, especially AI-based technologies. Developing or evaluating these technologies with synthetic data allows conserving resources and can help to ensure that device approvals consider the entire intended patient population. Looking forward, a recent study <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib117" title="" class="ltx_ref">117</a>]</cite> introduced the concept of a metaverse of “medical technology and AI” (MeTAI) that would augment regulatory evaluation of medical devices with virtual patient and scanner models, highlighting the interplay of synthetic data and healthcare applications. Badano et al. demonstrated this proof of concept for mammographic imaging with the VICTRE trial <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. Continued development and refinement of synthetic data generation techniques and applications in radiology are needed to make that future the next reality.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Hanxi Sun, Jason Plawinski, Sajanth Subramaniam, Amir Jamaludin, Timor Kadir,
Aimee Readie, Gregory Ligozio, David Ohlssen, Mark Baillie, and Thibaud
Coroller.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">A deep learning approach to private data sharing of medical images
using conditional GANs.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2106.13199</span><span id="bib.bib1.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Vajira Thambawita, Pegah Salehi, Sajad Amouei Sheshkal, Steven A Hicks, Hugo L
Hammer, Sravanthi Parasa, Thomas de Lange, Pål Halvorsen, and Michael A
Riegler.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">SinGAN-Seg: synthetic training data generation for medical image
segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">PLOS One</span><span id="bib.bib2.4.2" class="ltx_text" style="font-size:90%;">, 17(5):e0267976, 2022.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Hasib Zunair and A Ben Hamza.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">Synthesis of COVID-19 chest X-rays using unpaired image-to-image
translation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Social Network Analysis and Mining (SNAM)</span><span id="bib.bib3.4.2" class="ltx_text" style="font-size:90%;">, 11(1):1–12, 2021.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Zolnamar Dorjsembe, Hsing-Kuo Pao, Sodtavilan Odonchimed, and Furen Xiao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Conditional diffusion models for semantic 3D brain MRI synthesis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Journal of Biomedical and Health Informatics</span><span id="bib.bib4.4.2" class="ltx_text" style="font-size:90%;">, 2024.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
David Stojanovski, Uxio Hermida, Pablo Lamata, Arian Beqiri, and Alberto Gomez.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">Echo from noise: synthetic ultrasound image generation using
diffusion models for real image segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2305.05424</span><span id="bib.bib5.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Hazrat Ali, Shafaq Murad, and Zubair Shah.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Spot the fake lungs: Generating synthetic medical images using neural
diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Irish Conference on Artificial Intelligence and Cognitive
Science (AICS)</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, pages 32–39. Springer, 2022.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Walter HL Pinaya, Mark S Graham, Eric Kerfoot, Petru-Daniel Tudosiu, Jessica
Dafflon, Virginia Fernandez, Pedro Sanchez, Julia Wolleb, Pedro F da Costa,
Ashay Patel, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">Generative AI for medical imaging: extending the MONAI framework.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2307.15208</span><span id="bib.bib7.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
Antonio Sarno, Giovanni Mettivier, Francesca di Franco, Antonio Varallo,
Kristina Bliznakova, Andrew M. Hernandez, John M. Boone, and Paolo Russo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Dataset of patient-derived digital breast phantoms for in silico
studies in breast computed tomography, digital breast tomosynthesis, and
digital mammography.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Medical Physics</span><span id="bib.bib8.4.2" class="ltx_text" style="font-size:90%;">, 48(5):2682–2693, 2021.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Aldo Badano, Christian G Graff, Andreu Badal, Diksha Sharma, Rongping Zeng,
Frank W Samuelson, Stephen J Glick, and Kyle J Myers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Evaluation of digital breast tomosynthesis as replacement of
full-field digital mammography using an in silico imaging trial.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">JAMA Network Open</span><span id="bib.bib9.4.2" class="ltx_text" style="font-size:90%;">, 1(7):e185474–e185474, 2018.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
Elena Sizikova, Niloufar Saharkhiz, Diksha Sharma, Miguel Lago, Berkman
Sahiner, Jana Gut Delfino, and Aldo Badano.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Knowledge-based in silico models and dataset for the comparative
evaluation of mammography ai for a range of breast characteristics, lesion
conspicuities and doses.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib10.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems (NeurIPS)</span><span id="bib.bib10.5.3" class="ltx_text" style="font-size:90%;">,
2023.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Irène Brumer, Dominik F Bauer, Lothar R Schad, and Frank G Zöllner.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Synthetic arterial spin labeling MRI of the kidneys for evaluation
of data processing pipeline.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Diagnostics</span><span id="bib.bib11.4.2" class="ltx_text" style="font-size:90%;">, 12(8):1854, 2022.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Amirhossein Kazerouni, Ehsan Khodapanah Aghdam, Moein Heidari, Reza Azad,
Mohsen Fayyaz, Ilker Hacihaliloglu, and Dorit Merhof.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">Diffusion models in medical imaging: A comprehensive survey.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Medical Image Analysis</span><span id="bib.bib12.4.2" class="ltx_text" style="font-size:90%;">, page 102846, 2023.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
Nripendra Kumar Singh and Khalid Raza.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Medical image generation using generative adversarial networks: A
review.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Health Informatics: A Computational Perspective in Healthcare</span><span id="bib.bib13.4.2" class="ltx_text" style="font-size:90%;">,
pages 77–96, 2021.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Filippo Pesapane, Anna Rotili, Silvia Penco, Luca Nicosia, and Enrico Cassano.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">Digital twins in radiology.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Journal of Clinical Medicine (JCM)</span><span id="bib.bib14.4.2" class="ltx_text" style="font-size:90%;">, 11(21):6553, 2022.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Christian G Graff.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">A new, open-source, multi-modality digital breast phantom.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Medical Imaging 2016: Physics of Medical Imaging</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:90%;">, volume
9783, pages 72–81. SPIE, 2016.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Luis de Sisternes, Jovan G Brankov, Adam M Zysk, Robert A Schmidt, Robert M
Nishikawa, and Miles N Wernick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">A computational model to generate simulated three-dimensional breast
masses.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Medical Physics</span><span id="bib.bib16.4.2" class="ltx_text" style="font-size:90%;">, 42(2):1098–1118, 2015.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Puja Myles, Johan Ordish, and Allan Tucker.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">The potential synergies between synthetic data and in silico trials
in relation to generating representative virtual population cohorts.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Progress in Biomedical Engineering</span><span id="bib.bib17.4.2" class="ltx_text" style="font-size:90%;">, page 013001, 2023.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Marco Viceconti, Adriano Henney, and Edwin Morley-Fletcher.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">In silico clinical trials: how computer simulation will transform the
biomedical industry.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">International Journal of Clinical Trials (IJCT)</span><span id="bib.bib18.4.2" class="ltx_text" style="font-size:90%;">, 3(2):37–46,
2016.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
A Badano, M Lago, E Sizikova, JG Delfino, S Guan, MA Anastasio, and B Sahiner.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">The stochastic digital human is now enrolling for in silico imaging
trials–methods and tools for generating digital cohorts.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Progress in Biomedical Engineering</span><span id="bib.bib19.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley,
Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Generative adversarial networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Communications of the ACM</span><span id="bib.bib20.4.2" class="ltx_text" style="font-size:90%;">, 63(11):139–144, 2020.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Tabea Kossen, Manuel A Hirzel, Vince I Madai, Franziska Boenisch, Anja
Hennemuth, Kristian Hildebrand, Sebastian Pokutta, Kartikey Sharma, Adam
Hilbert, Jan Sobesky, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Toward sharing brain images: Differentially private TOF-MRA images
with segmentation labels using generative adversarial networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Frontiers in Artificial Intelligence</span><span id="bib.bib21.4.2" class="ltx_text" style="font-size:90%;">, 5:85, 2022.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Jue Jiang, Yu-Chi Hu, Neelam Tyagi, Pengpeng Zhang, Andreas Rimner, Gig S
Mageras, Joseph O Deasy, and Harini Veeraraghavan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Tumor-aware, adversarial domain adaptation from CT to MRI for
lung cancer segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib22.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the International Conference on Medical Image
Computing and Computer-Assisted Intervention (MICCAI)</span><span id="bib.bib22.5.3" class="ltx_text" style="font-size:90%;">, pages 777–785.
Springer, 2018.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Tian Xia, Agisilaos Chartsias, and Sotirios A Tsaftaris.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Pseudo-healthy synthesis with pathology disentanglement and
adversarial learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Medical Image Analysis</span><span id="bib.bib23.4.2" class="ltx_text" style="font-size:90%;">, 64:101719, 2020.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Jun-Yan Zhu, Taesung Park, Phillip Isola, and Alexei A Efros.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">Unpaired image-to-image translation using cycle-consistent
adversarial networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib24.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of IEEE International Conference on Computer
Vision (ICCV)</span><span id="bib.bib24.5.3" class="ltx_text" style="font-size:90%;">, pages 2223–2232, 2017.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
Ashish Bora, Eric Price, and Alexandros G Dimakis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">AmbientGAN: generative models from lossy measurements.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the International Conference on Learning
Representations (ICLR)</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Weimin Zhou, Sayantan Bhadra, Frank J Brooks, Hua Li, and Mark A Anastasio.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">Learning stochastic object models from medical imaging measurements
by use of advanced ambient generative adversarial networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Journal of Medical Imaging (JMI)</span><span id="bib.bib26.4.2" class="ltx_text" style="font-size:90%;">, 9(1):015503, 2022.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Yingao Liu, Fei Yang, and Yidong Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">Free-form lesion synthesis using a partial convolution generative
adversarial network for enhanced deep learning liver tumor segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2206.09065</span><span id="bib.bib27.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Yifan Jiang, Han Chen, Murray Loew, and Hanseok Ko.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Covid-19 ct image synthesis with a conditional generative adversarial
network.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Journal of Biomedical and Health Informatics (JBHI)</span><span id="bib.bib28.4.2" class="ltx_text" style="font-size:90%;">,
25(2):441–452, 2020.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
Ivan Kobyzev, Simon JD Prince, and Marcus A Brubaker.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Normalizing flows: An introduction and review of current methods.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Pattern Analysis and Machine Intelligence
(PAMI)</span><span id="bib.bib29.4.2" class="ltx_text" style="font-size:90%;">, 43(11):3964–3979, 2020.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Alexander Denker, Maximilian Schmidt, Johannes Leuschner, Peter Maass, and Jens
Behrmann.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Conditional normalizing flows for low-dose computed tomography image
reconstruction.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2006.06270</span><span id="bib.bib30.4.2" class="ltx_text" style="font-size:90%;">, 2020.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
Mustafa Hajij, Ghada Zamzmi, Rahul Paul, and Lokenda Thukar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Normalizing flow for synthetic medical images generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib31.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Healthcare Innovations and Point of Care Technologies
(HI-POCT)</span><span id="bib.bib31.5.3" class="ltx_text" style="font-size:90%;">, pages 46–49. IEEE, 2022.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
Diederik P Kingma and Max Welling.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">Auto-encoding variational bayes.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1312.6114</span><span id="bib.bib32.4.2" class="ltx_text" style="font-size:90%;">, 2013.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
Bilal Ahmad, Jun Sun, Qi You, Vasile Palade, and Zhongjie Mao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">Brain tumor classification using a combination of variational
autoencoders and generative adversarial networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Biomedicines</span><span id="bib.bib33.4.2" class="ltx_text" style="font-size:90%;">, 10(2):223, 2022.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
Jianan Cui, Yutong Xie, Anand A Joshi, Kuang Gong, Kyungsang Kim, Young-Don
Son, Jong-Hoon Kim, Richard Leahy, Huafeng Liu, and Quanzheng Li.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">PET denoising and uncertainty estimation based on NVAE model
using quantile regression loss.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib34.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the International Conference on Medical Image
Computing and Computer-Assisted Intervention (MICCAI)</span><span id="bib.bib34.5.3" class="ltx_text" style="font-size:90%;">, pages 173–183.
Springer, 2022.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
Jonathan Ho, Ajay Jain, and Pieter Abbeel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">Denoising diffusion probabilistic models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems (NeurIPS)</span><span id="bib.bib35.4.2" class="ltx_text" style="font-size:90%;">,
33:6840–6851, 2020.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
Bardia Khosravi, Pouria Rouzrokh, John P Mickley, Shahriar Faghani, Kellen
Mulford, Linjun Yang, A Noelle Larson, Benjamin M Howe, Bradley J Erickson,
Michael J Taunton, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">Few-shot biomedical image segmentation using diffusion models: beyond
image generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Methods and Programs in Biomedicine</span><span id="bib.bib36.4.2" class="ltx_text" style="font-size:90%;">, 242:107832, 2023.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
Marie-Christine Gosselin, Esra Neufeld, Heidi Moser, Eveline Huber, Silvia
Farcito, Livia Gerber, Maria Jedensjö, Isabel Hilber, Fabienne
Di Gennaro, Bryn Lloyd, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text" style="font-size:90%;">Development of a new generation of high-resolution anatomical models
for medical device evaluation: the Virtual Population 3.0.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Physics in Medicine &amp; Biology</span><span id="bib.bib37.4.2" class="ltx_text" style="font-size:90%;">, 59(18):5287, 2014.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
Justin Solomon and Ehsan Samei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">A generic framework to simulate realistic lung, liver and renal
pathologies in CT imaging.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Physics in Medicine &amp; Biology</span><span id="bib.bib38.4.2" class="ltx_text" style="font-size:90%;">, 59(21):6637, 2014.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
Hanna Tomic, Anna Bjerkén, Gustav Hellgren, Kristin Johnson, Daniel
Förnvik, Sophia Zackrisson, Anders Tingberg, Magnus Dustler, and
Predrag R Bakic.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">Development and evaluation of a method for tumor growth simulation in
virtual clinical trials of breast cancer screening.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Journal of Medical Imaging (JMI)</span><span id="bib.bib39.4.2" class="ltx_text" style="font-size:90%;">, 9(3):033503–033503, 2022.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
Yasmina Al Khalil, Sina Amirrajab, Cristian Lorenz, Jürgen Weese, and
Marcel Breeuwer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:90%;">Heterogeneous virtual population of simulated CMR images for
improving the generalization of cardiac segmentation algorithms.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib40.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">MICCAI Simulation and Synthesis in Medical Imaging
(SASHIMI)</span><span id="bib.bib40.5.3" class="ltx_text" style="font-size:90%;">, pages 68–79. Springer, 2020.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:90%;">
WP Segars, Hannah Norris, Gregory M Sturgeon, Yakun Zhang, Jason Bond, Anum
Minhas, Daniel J Tward, JT Ratnanather, MI Miller, D Frush, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.2.1" class="ltx_text" style="font-size:90%;">The development of a population of 4D pediatric XCAT phantoms for
imaging research and optimization.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Medical Physics</span><span id="bib.bib41.4.2" class="ltx_text" style="font-size:90%;">, 42(8):4719–4726, 2015.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text" style="font-size:90%;">
Chee L Hoe, Ehsan Samei, Donald P Frush, and David M Delong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.2.1" class="ltx_text" style="font-size:90%;">Simulation of liver lesions for pediatric CT.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Radiology</span><span id="bib.bib42.4.2" class="ltx_text" style="font-size:90%;">, 238(2):699–705, 2006.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text" style="font-size:90%;">
Eman Shaheen, Frederik De Keyzer, Hilde Bosmans, David R Dance, Kenneth C
Young, and Chantal Van Ongeval.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.2.1" class="ltx_text" style="font-size:90%;">The simulation of 3d mass models in 2d digital mammography and breast
tomosynthesis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Medical Physics</span><span id="bib.bib43.4.2" class="ltx_text" style="font-size:90%;">, 41:081913, 2014.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text" style="font-size:90%;">
Thomas J Sauer, Adrian Bejan, Paul Segars, and Ehsan Samei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.2.1" class="ltx_text" style="font-size:90%;">Development and CT image-domain validation of a computational lung
lesion model for use in virtual imaging trials.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Medical Physics</span><span id="bib.bib44.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text" style="font-size:90%;">
Aunnasha Sengupta, Diksha Sharma, and Aldo Badano.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.2.1" class="ltx_text" style="font-size:90%;">Computational model of tumor growth for in silico trials.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib45.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Medical Imaging 2021: Physics of Medical Imaging</span><span id="bib.bib45.5.3" class="ltx_text" style="font-size:90%;">, volume
11595, pages 1262–1270. SPIE, 2021.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text" style="font-size:90%;">
Ehsan Abadi, Brian Harrawood, Shobhit Sharma, Anuj Kapadia, William P Segars,
and Ehsan Samei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.2.1" class="ltx_text" style="font-size:90%;">DukeSim: a realistic, rapid, and scanner-specific simulation
framework in computed tomography.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Medical Imaging (TMI)</span><span id="bib.bib46.4.2" class="ltx_text" style="font-size:90%;">, 38(6):1457–1465,
2018.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text" style="font-size:90%;">
Mingye Wu, Paul FitzGerald, Jiayong Zhang, W Paul Segars, Hengyong Yu, Yongshun
Xu, and Bruno De Man.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.2.1" class="ltx_text" style="font-size:90%;">XCIST—an open access x-ray/ct simulation toolkit.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Physics in Medicine &amp; Biology</span><span id="bib.bib47.4.2" class="ltx_text" style="font-size:90%;">, 67(19):194002, 2022.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text" style="font-size:90%;">
Andreu Badal and Aldo Badano.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.2.1" class="ltx_text" style="font-size:90%;">Accelerating monte carlo simulations of photon transport in a
voxelized geometry using a massively parallel graphics processing unit.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Medical Physics</span><span id="bib.bib48.4.2" class="ltx_text" style="font-size:90%;">, 36(11):4878–4880, 2009.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text" style="font-size:90%;">
Andreu Badal, Diksha Sharma, Christian G Graff, Rongping Zeng, and Aldo Badano.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.2.1" class="ltx_text" style="font-size:90%;">Mammography and breast tomosynthesis simulator for virtual clinical
trials.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Physics Communications</span><span id="bib.bib49.4.2" class="ltx_text" style="font-size:90%;">, 261:107779, 2021.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock"><span id="bib.bib50.1.1" class="ltx_text" style="font-size:90%;">
David Sarrut, Thomas Baudier, Damian Borys, Ane Etxebeste, Hermann Fuchs, Jan
Gajewski, Loïc Grevillot, Sébastien Jan, George C Kagadis, Han Gyu
Kang, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.2.1" class="ltx_text" style="font-size:90%;">The OpenGATE ecosystem for monte carlo simulation in medical
physics.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Physics in Medicine &amp; Biology</span><span id="bib.bib50.4.2" class="ltx_text" style="font-size:90%;">, 67(18):184001, 2022.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text" style="font-size:90%;">
Fang Liu, Julia V Velikina, Walter F Block, Richard Kijowski, and Alexey A
Samsonov.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.2.1" class="ltx_text" style="font-size:90%;">Fast realistic MRI simulations based on generalized multi-pool
exchange tissue model.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Medical Imaging (TMI)</span><span id="bib.bib51.4.2" class="ltx_text" style="font-size:90%;">, 36(2):527–537,
2016.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text" style="font-size:90%;">
Mathias Unberath, Jan-Nico Zaech, Sing Chun Lee, Bastian Bier, Javad Fotouhi,
Mehran Armand, and Nassir Navab.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.2.1" class="ltx_text" style="font-size:90%;">DeepDRR–a catalyst for machine learning in fluoroscopy-guided
procedures.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib52.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the International Conference on Medical Image
Computing and Computer-Assisted Intervention (MICCAI)</span><span id="bib.bib52.5.3" class="ltx_text" style="font-size:90%;">. Springer, 2018.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text" style="font-size:90%;">
Jørgen Arendt Jensen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.2.1" class="ltx_text" style="font-size:90%;">Field: A program for simulating ultrasound systems.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Medical &amp; Biological Engineering &amp; Computing</span><span id="bib.bib53.4.2" class="ltx_text" style="font-size:90%;">, 34:351–353,
1997.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock"><span id="bib.bib54.1.1" class="ltx_text" style="font-size:90%;">
Joscha Maier, Yannick Berker, Stefan Sawall, and Marc Kachelrieß.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.2.1" class="ltx_text" style="font-size:90%;">Deep scatter estimation (dse): feasibility of using a deep
convolutional neural network for real-time x-ray scatter prediction in
cone-beam ct.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib54.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Medical Imaging 2018: Physics of Medical Imaging</span><span id="bib.bib54.5.3" class="ltx_text" style="font-size:90%;">, volume
10573, pages 393–398. SPIE, 2018.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock"><span id="bib.bib55.1.1" class="ltx_text" style="font-size:90%;">
Felix Horger, Tobias Würfl, Vincent Christlein, and Andreas Maier.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.2.1" class="ltx_text" style="font-size:90%;">Towards arbitrary noise augmentation—deep learning for sampling
from arbitrary probability distributions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib55.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">MICCAI Machine Learning for Medical Image Reconstruction
(MLMIR) Workshop</span><span id="bib.bib55.5.3" class="ltx_text" style="font-size:90%;">, pages 129–137. Springer, 2018.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock"><span id="bib.bib56.1.1" class="ltx_text" style="font-size:90%;">
Andreas Maier, Frank Schebesch, Christopher Syben, Tobias Würfl, Stefan
Steidl, Jang-Hwan Choi, and Rebecca Fahrig.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.2.1" class="ltx_text" style="font-size:90%;">Precision learning: towards use of known operators in neural
networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib56.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Conference on Pattern Recognition (ICPR)</span><span id="bib.bib56.5.3" class="ltx_text" style="font-size:90%;">,
pages 183–188. IEEE, 2018.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text" style="font-size:90%;">
Brian Teixeira, Vivek Singh, Terrence Chen, Kai Ma, Birgi Tamersoy, Yifan Wu,
Elena Balashova, and Dorin Comaniciu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.2.1" class="ltx_text" style="font-size:90%;">Generating synthetic x-ray images of a person from the surface
geometry.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib57.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE / CVF Computer Vision and Pattern
Recognition Conference (CVPR)</span><span id="bib.bib57.5.3" class="ltx_text" style="font-size:90%;">, pages 9059–9067, 2018.
</span>
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock"><span id="bib.bib58.1.1" class="ltx_text" style="font-size:90%;">
Maayan Frid-Adar, Idit Diamant, Eyal Klang, Michal Amitai, Jacob Goldberger,
and Hayit Greenspan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.2.1" class="ltx_text" style="font-size:90%;">GAN-based synthetic medical image augmentation for increased CNN
performance in liver lesion classification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Neurocomputing</span><span id="bib.bib58.4.2" class="ltx_text" style="font-size:90%;">, 321:321–331, 2018.
</span>
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock"><span id="bib.bib59.1.1" class="ltx_text" style="font-size:90%;">
Fariba Azizmohammadi, Iñaki Navarro Castellanos, Joaquim Miró, Paul
Segars, Ehsan Samei, and Luc Duong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.2.1" class="ltx_text" style="font-size:90%;">Generative learning approach for radiation dose reduction in x-ray
guided cardiac interventions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Medical Physics</span><span id="bib.bib59.4.2" class="ltx_text" style="font-size:90%;">, 49(6):4071–4081, 2022.
</span>
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock"><span id="bib.bib60.1.1" class="ltx_text" style="font-size:90%;">
Avi Ben-Cohen, Eyal Klang, Stephen P Raskin, Shelly Soffer, Simona Ben-Haim,
Eli Konen, Michal Marianne Amitai, and Hayit Greenspan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.2.1" class="ltx_text" style="font-size:90%;">Cross-modality synthesis from CT to PET using FCN and GAN
networks for improved automated lesion detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Engineering Applications of Artificial Intelligence</span><span id="bib.bib60.4.2" class="ltx_text" style="font-size:90%;">,
78:186–194, 2019.
</span>
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock"><span id="bib.bib61.1.1" class="ltx_text" style="font-size:90%;">
Faisal Mahmood, Richard Chen, and Nicholas J Durr.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.2.1" class="ltx_text" style="font-size:90%;">Unsupervised reverse domain adaptation for synthetic medical images
via adversarial training.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Medical Imaging (TMI)</span><span id="bib.bib61.4.2" class="ltx_text" style="font-size:90%;">, 37(12):2572–2581,
2018.
</span>
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock"><span id="bib.bib62.1.1" class="ltx_text" style="font-size:90%;">
Hoo-Chang Shin, Neil A Tenenholtz, Jameson K Rogers, Christopher G Schwarz,
Matthew L Senjem, Jeffrey L Gunter, Katherine P Andriole, and Mark Michalski.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.2.1" class="ltx_text" style="font-size:90%;">Medical image synthesis for data augmentation and anonymization using
generative adversarial networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib62.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">MICCAI Simulation and Synthesis in Medical Imaging (SASHIMI)
2018</span><span id="bib.bib62.5.3" class="ltx_text" style="font-size:90%;">, pages 1–11. Springer, 2018.
</span>
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock"><span id="bib.bib63.1.1" class="ltx_text" style="font-size:90%;">
Ashia Lewis, Evanjelin Mahmoodi, Yuyue Zhou, Megan Coffee, and Elena Sizikova.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.2.1" class="ltx_text" style="font-size:90%;">Improving tuberculosis (TB) prediction using synthetically
generated computed tomography (CT) images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib63.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of IEEE International Conference on Computer
Vision (ICCV)</span><span id="bib.bib63.5.3" class="ltx_text" style="font-size:90%;">, pages 3265–3273, 2021.
</span>
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock"><span id="bib.bib64.1.1" class="ltx_text" style="font-size:90%;">
Dimitrios Korkinof, Andreas Heindl, Tobias Rijken, Hugh Harvey, and Ben
Glocker.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.2.1" class="ltx_text" style="font-size:90%;">Mammogan: high-resolution synthesis of realistic mammograms.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Medical Imaging with Deep Learning (MIDL) Conference</span><span id="bib.bib64.4.2" class="ltx_text" style="font-size:90%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock"><span id="bib.bib65.1.1" class="ltx_text" style="font-size:90%;">
Mostafa Salem, Sergi Valverde, Mariano Cabezas, Deborah Pareto, Arnau Oliver,
Joaquim Salvi, Àlex Rovira, and Xavier Lladó.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib65.2.1" class="ltx_text" style="font-size:90%;">Multiple sclerosis lesion synthesis in MRI using an encoder-decoder
U-NET.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib65.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Access</span><span id="bib.bib65.4.2" class="ltx_text" style="font-size:90%;">, 7:25171–25184, 2019.
</span>
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock"><span id="bib.bib66.1.1" class="ltx_text" style="font-size:90%;">
Ferran Prados, M Jorge Cardoso, Niamh Cawley, Baris Kanber, Olga Ciccarelli,
Claudia AM Gandini Wheeler-Kingshott, and Sébastien Ourselin.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.2.1" class="ltx_text" style="font-size:90%;">Fully automated patch-based image restoration: application to
pathology inpainting.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib66.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">MICCAI Brainlesion: Glioma, Multiple Sclerosis, Stroke and
Traumatic Brain Injuries Workshop</span><span id="bib.bib66.5.3" class="ltx_text" style="font-size:90%;">, pages 3–15. Springer, 2016.
</span>
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock"><span id="bib.bib67.1.1" class="ltx_text" style="font-size:90%;">
Ender Konukoglu, Andre van der Kouwe, Mert Rory Sabuncu, and Bruce Fischl.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib67.2.1" class="ltx_text" style="font-size:90%;">Example-based restoration of high-resolution magnetic resonance image
acquisitions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib67.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib67.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the International Conference on Medical Image
Computing and Computer-Assisted Intervention (MICCAI)</span><span id="bib.bib67.5.3" class="ltx_text" style="font-size:90%;">, pages 131–138.
Springer, 2013.
</span>
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock"><span id="bib.bib68.1.1" class="ltx_text" style="font-size:90%;">
Jiaxin Li, Houjin Chen, Yanfeng Li, Yahui Peng, Jia Sun, and Pan Pan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib68.2.1" class="ltx_text" style="font-size:90%;">Cross-modality synthesis aiding lung tumor segmentation on
multi-modal MRI images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib68.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Biomedical Signal Processing and Control</span><span id="bib.bib68.4.2" class="ltx_text" style="font-size:90%;">, 76:103655, 2022.
</span>
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock"><span id="bib.bib69.1.1" class="ltx_text" style="font-size:90%;">
P Chambon, C Bluethgen, JB Delbrouck, R Van der Sluijs, M Połacin, JMZ
Chaves, TM Abraham, S Purohit, CP Langlotz, and A Chaudhari.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib69.2.1" class="ltx_text" style="font-size:90%;">Roentgen: vision-language foundation model for chest x-ray
generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib69.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2211.12737</span><span id="bib.bib69.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock"><span id="bib.bib70.1.1" class="ltx_text" style="font-size:90%;">
Cong Gao, Benjamin D Killeen, Yicheng Hu, Robert B Grupp, Russell H Taylor,
Mehran Armand, and Mathias Unberath.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib70.2.1" class="ltx_text" style="font-size:90%;">Synthex: scaling up learning-based x-ray image analysis through in
silico experiments.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib70.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2206.06127</span><span id="bib.bib70.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock"><span id="bib.bib71.1.1" class="ltx_text" style="font-size:90%;">
Christos G Xanthis, Dimitrios Filos, Kostas Haris, and Anthony H Aletras.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib71.2.1" class="ltx_text" style="font-size:90%;">Simulator-generated training datasets as an alternative to using
patient data for machine learning: an example in myocardial segmentation with
MRI.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib71.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Methods and Programs in Biomedicine</span><span id="bib.bib71.4.2" class="ltx_text" style="font-size:90%;">, 198:105817, 2021.
</span>
</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[72]</span>
<span class="ltx_bibblock"><span id="bib.bib72.1.1" class="ltx_text" style="font-size:90%;">
Priscille de Dumast, Hamza Kebiri, Kelly Payette, Andras Jakab, Hélène
Lajous, and Meritxell Bach Cuadra.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib72.2.1" class="ltx_text" style="font-size:90%;">Synthetic magnetic resonance images for domain adaptation:
Application to fetal brain tissue segmentation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib72.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib72.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">International Symposium on Biomedical Imaging (ISBI)</span><span id="bib.bib72.5.3" class="ltx_text" style="font-size:90%;">, pages
1–5. IEEE, 2022.
</span>
</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[73]</span>
<span class="ltx_bibblock"><span id="bib.bib73.1.1" class="ltx_text" style="font-size:90%;">
Aria Pezeshk, Berkman Sahiner, Rongping Zeng, Adam Wunderlich, Weijie Chen, and
Nicholas Petrick.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib73.2.1" class="ltx_text" style="font-size:90%;">Seamless insertion of pulmonary nodules in chest ct images.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib73.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Biomedical Engineering (TBME)</span><span id="bib.bib73.4.2" class="ltx_text" style="font-size:90%;">,
62(12):2812–2827, 2015.
</span>
</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[74]</span>
<span class="ltx_bibblock"><span id="bib.bib74.1.1" class="ltx_text" style="font-size:90%;">
Dhaval Kadia, Tam V. Nguyen, and Vijayan Asari.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib74.2.1" class="ltx_text" style="font-size:90%;">Lesion synthesis for robust segmentation of infected lung region on
small-scale data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib74.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Social Science Research Network (SSRN)</span><span id="bib.bib74.4.2" class="ltx_text" style="font-size:90%;">, 2022.
</span>
</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[75]</span>
<span class="ltx_bibblock"><span id="bib.bib75.1.1" class="ltx_text" style="font-size:90%;">
Xing Gong, Stephen J Glick, Bob Liu, Aruna A Vedula, and Samta Thacker.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib75.2.1" class="ltx_text" style="font-size:90%;">A computer simulation study comparing lesion detection accuracy with
digital mammography, breast tomosynthesis, and cone-beam CT breast imaging.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib75.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Medical Physics</span><span id="bib.bib75.4.2" class="ltx_text" style="font-size:90%;">, 33(4):1041–1052, 2006.
</span>
</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[76]</span>
<span class="ltx_bibblock"><span id="bib.bib76.1.1" class="ltx_text" style="font-size:90%;">
Brandon Nelson, Prabhat Kc, Andreu Badal-Soler, Lu Jiang, Shane Masters, and
Rongping Zeng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib76.2.1" class="ltx_text" style="font-size:90%;">Pediatric-specific evaluations for deep learning CT denoising.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib76.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Zenodo Preprint</span><span id="bib.bib76.4.2" class="ltx_text" style="font-size:90%;">, 2013.
</span>
</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[77]</span>
<span class="ltx_bibblock"><span id="bib.bib77.1.1" class="ltx_text" style="font-size:90%;">
X Li, Ehsan Samei, DM Delong, RP Jones, AM Gaca, CL Hollingsworth, CM Maxfield,
CWT Carrico, and DP Frush.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib77.2.1" class="ltx_text" style="font-size:90%;">Three-dimensional simulation of lung nodules for paediatric
multidetector array CT.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib77.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">The British Journal of Radiology (BJR)</span><span id="bib.bib77.4.2" class="ltx_text" style="font-size:90%;">, 82(977):401–411, 2009.
</span>
</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[78]</span>
<span class="ltx_bibblock"><span id="bib.bib78.1.1" class="ltx_text" style="font-size:90%;">
Kenny H Cha, Nicholas Petrick, Aria Pezeshk, Christian G Graff, Diksha Sharma,
Andreu Badal, and Berkman Sahiner.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib78.2.1" class="ltx_text" style="font-size:90%;">Evaluation of data augmentation via synthetic images for improved
breast mass detection on mammograms using deep learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib78.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Journal of Medical Imaging (JMI)</span><span id="bib.bib78.4.2" class="ltx_text" style="font-size:90%;">, 7(1):012703–012703, 2020.
</span>
</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[79]</span>
<span class="ltx_bibblock"><span id="bib.bib79.1.1" class="ltx_text" style="font-size:90%;">
X George Xu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib79.2.1" class="ltx_text" style="font-size:90%;">An exponential growth of computational phantom research in radiation
protection, imaging, and radiotherapy: a review of the fifty-year history.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib79.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Physics in Medicine &amp; Biology</span><span id="bib.bib79.4.2" class="ltx_text" style="font-size:90%;">, 59(18):R233, 2014.
</span>
</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[80]</span>
<span class="ltx_bibblock"><span id="bib.bib80.1.1" class="ltx_text" style="font-size:90%;">
W Paul Segars, Benjamin MW Tsui, Jing Cai, Fang-Fang Yin, George SK Fung, and
Ehsan Samei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib80.2.1" class="ltx_text" style="font-size:90%;">Application of the 4-D XCAT phantoms in biomedical imaging and
beyond.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib80.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Medical Imaging (TMI)</span><span id="bib.bib80.4.2" class="ltx_text" style="font-size:90%;">, 37(3):680–692,
2017.
</span>
</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[81]</span>
<span class="ltx_bibblock"><span id="bib.bib81.1.1" class="ltx_text" style="font-size:90%;">
Wolfgang Kainz, Esra Neufeld, Wesley E Bolch, Christian G Graff, Chan Hyeong
Kim, Niels Kuster, Bryn Lloyd, Tina Morrison, Paul Segars, Yeon Soo Yeom,
et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib81.2.1" class="ltx_text" style="font-size:90%;">Advances in computational human phantoms and their applications in
biomedical engineering—a topical review.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib81.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEE Transactions on Radiation and Plasma Medical Sciences
(TRPMS)</span><span id="bib.bib81.4.2" class="ltx_text" style="font-size:90%;">, 3(1):1–23, 2018.
</span>
</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[82]</span>
<span class="ltx_bibblock"><span id="bib.bib82.1.1" class="ltx_text" style="font-size:90%;">
Benjamin D Killeen, Sue Min Cho, Mehran Armand, Russell H Taylor, and Mathias
Unberath.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib82.2.1" class="ltx_text" style="font-size:90%;">In silico simulation: a key enabling technology for next-generation
intelligent surgical systems.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib82.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Progress in Biomedical Engineering</span><span id="bib.bib82.4.2" class="ltx_text" style="font-size:90%;">, 5(3):032001, 2023.
</span>
</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[83]</span>
<span class="ltx_bibblock"><span id="bib.bib83.1.1" class="ltx_text" style="font-size:90%;">
Cristobal Rodero, Tiffany MG Baptiste, Rosie K Barrows, Hamed Keramati,
Charles P Sillett, Marina Strocchi, Pablo Lamata, and Steven A Niederer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib83.2.1" class="ltx_text" style="font-size:90%;">A systematic review of cardiac in-silico clinical trials.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib83.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Progress in Biomedical Engineering</span><span id="bib.bib83.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[84]</span>
<span class="ltx_bibblock"><span id="bib.bib84.1.1" class="ltx_text" style="font-size:90%;">
Hao Guan and Mingxia Liu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib84.2.1" class="ltx_text" style="font-size:90%;">Domain adaptation for medical image analysis: a survey.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib84.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Biomedical Engineering (TBME)</span><span id="bib.bib84.4.2" class="ltx_text" style="font-size:90%;">,
69(3):1173–1185, 2021.
</span>
</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[85]</span>
<span class="ltx_bibblock"><span id="bib.bib85.1.1" class="ltx_text" style="font-size:90%;">
Sema Candemir, Xuan V Nguyen, Les R Folio, and Luciano M Prevedello.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib85.2.1" class="ltx_text" style="font-size:90%;">Training strategies for radiology deep learning models in
data-limited scenarios.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib85.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Radiology: Artificial Intelligence</span><span id="bib.bib85.4.2" class="ltx_text" style="font-size:90%;">, 3(6):e210014, 2021.
</span>
</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[86]</span>
<span class="ltx_bibblock"><span id="bib.bib86.1.1" class="ltx_text" style="font-size:90%;">
M Boulanger, Jean-Claude Nunes, H Chourak, A Largent, S Tahri, O Acosta,
R De Crevoisier, C Lafond, and A Barateau.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib86.2.1" class="ltx_text" style="font-size:90%;">Deep learning methods to generate synthetic CT from MRI in
radiotherapy: A literature review.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib86.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Physica Medica</span><span id="bib.bib86.4.2" class="ltx_text" style="font-size:90%;">, 89:265–281, 2021.
</span>
</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[87]</span>
<span class="ltx_bibblock"><span id="bib.bib87.1.1" class="ltx_text" style="font-size:90%;">
Jens M Edmund and Tufve Nyholm.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib87.2.1" class="ltx_text" style="font-size:90%;">A review of substitute CT generation for MRI-only radiation
therapy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib87.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Radiation Oncology</span><span id="bib.bib87.4.2" class="ltx_text" style="font-size:90%;">, 12:1–15, 2017.
</span>
</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[88]</span>
<span class="ltx_bibblock"><span id="bib.bib88.1.1" class="ltx_text" style="font-size:90%;">
August DuMont Schütte, Jürgen Hetzel, Sergios Gatidis, Tobias Hepp,
Benedikt Dietz, Stefan Bauer, and Patrick Schwab.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib88.2.1" class="ltx_text" style="font-size:90%;">Overcoming barriers to data sharing with medical image generation: a
comprehensive evaluation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib88.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">NPJ digital medicine</span><span id="bib.bib88.4.2" class="ltx_text" style="font-size:90%;">, 4(1):141, 2021.
</span>
</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[89]</span>
<span class="ltx_bibblock"><span id="bib.bib89.1.1" class="ltx_text" style="font-size:90%;">
Isabella Castiglioni, Leonardo Rundo, Marina Codari, Giovanni Di Leo, Christian
Salvatore, Matteo Interlenghi, Francesca Gallivanone, Andrea Cozzi,
Natascha Claudia D’Amico, and Francesco Sardanelli.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib89.2.1" class="ltx_text" style="font-size:90%;">AI applications to medical images: From machine learning to deep
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib89.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Physica Medica</span><span id="bib.bib89.4.2" class="ltx_text" style="font-size:90%;">, 83:9–24, 2021.
</span>
</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[90]</span>
<span class="ltx_bibblock"><span id="bib.bib90.1.1" class="ltx_text" style="font-size:90%;">
Varun A. Kelkar, Dimitrios S. Gotsis, Frank J. Brooks, Prabhat KC, Kyle J.
Myers, Rongping Zeng, and Mark A. Anastasio.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib90.2.1" class="ltx_text" style="font-size:90%;">Assessing the ability of generative adversarial networks to learn
canonical medical image statistics.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib90.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Medical Imaging</span><span id="bib.bib90.4.2" class="ltx_text" style="font-size:90%;">, 42(6):1799–1808, 2023.
</span>
</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[91]</span>
<span class="ltx_bibblock"><span id="bib.bib91.1.1" class="ltx_text" style="font-size:90%;">
Salman Ul Hassan Dar, Arman Ghanaat, Jannik Kahmann, Isabelle Ayx, Theano
Papavassiliou, Stefan O Schoenberg, and Sandy Engelhardt.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib91.2.1" class="ltx_text" style="font-size:90%;">Investigating data memorization in 3D latent diffusion models for
medical image synthesis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib91.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2307.01148</span><span id="bib.bib91.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[92]</span>
<span class="ltx_bibblock"><span id="bib.bib92.1.1" class="ltx_text" style="font-size:90%;">
Connor Shorten and Taghi M Khoshgoftaar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib92.2.1" class="ltx_text" style="font-size:90%;">A survey on image data augmentation for deep learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib92.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Journal of Big Data</span><span id="bib.bib92.4.2" class="ltx_text" style="font-size:90%;">, 6(1):1–48, 2019.
</span>
</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[93]</span>
<span class="ltx_bibblock"><span id="bib.bib93.1.1" class="ltx_text" style="font-size:90%;">
Andreas Maier, Christopher Syben, Tobias Lasser, and Christian Riess.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib93.2.1" class="ltx_text" style="font-size:90%;">A gentle introduction to deep learning in medical image processing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib93.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Zeitschrift für Medizinische Physik</span><span id="bib.bib93.4.2" class="ltx_text" style="font-size:90%;">, 29(2):86–101, 2019.
</span>
</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[94]</span>
<span class="ltx_bibblock"><span id="bib.bib94.1.1" class="ltx_text" style="font-size:90%;">
Zhisheng Xiao, Karsten Kreis, and Arash Vahdat.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib94.2.1" class="ltx_text" style="font-size:90%;">Tackling the generative learning trilemma with denoising diffusion
GANs.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib94.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib94.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the International Conference on Learning
Representations (ICLR)</span><span id="bib.bib94.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[95]</span>
<span class="ltx_bibblock"><span id="bib.bib95.1.1" class="ltx_text" style="font-size:90%;">
Gary An, Michael Döllinger, and Nicole YK Li-Jessen.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib95.2.1" class="ltx_text" style="font-size:90%;">Integration of machine learning and computer simulation in solving
complex physiological and medical questions.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib95.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Frontiers in Physiology</span><span id="bib.bib95.4.2" class="ltx_text" style="font-size:90%;">, 13:949771, 2022.
</span>
</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[96]</span>
<span class="ltx_bibblock"><span id="bib.bib96.1.1" class="ltx_text" style="font-size:90%;">
Leo K Tam, Jason P Stockmann, Gigi Galiana, and R Todd Constable.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib96.2.1" class="ltx_text" style="font-size:90%;">Null space imaging: nonlinear magnetic encoding fields designed
complementary to receiver coil sensitivities for improved acceleration in
parallel imaging.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib96.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Magnetic Resonance in Medicine</span><span id="bib.bib96.4.2" class="ltx_text" style="font-size:90%;">, 68(4):1166–1175, 2012.
</span>
</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[97]</span>
<span class="ltx_bibblock"><span id="bib.bib97.1.1" class="ltx_text" style="font-size:90%;">
Christopher Bowles, Liang Chen, Ricardo Guerrero, Paul Bentley, Roger Gunn,
Alexander Hammers, David Alexander Dickie, Maria Valdés Hernández,
Joanna Wardlaw, and Daniel Rueckert.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib97.2.1" class="ltx_text" style="font-size:90%;">GAN augmentation: Augmenting training data using generative
adversarial networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib97.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1810.10863</span><span id="bib.bib97.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[98]</span>
<span class="ltx_bibblock"><span id="bib.bib98.1.1" class="ltx_text" style="font-size:90%;">
Aldo Badano.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib98.2.1" class="ltx_text" style="font-size:90%;">In silico imaging clinical trials: cheaper, faster, better, safer,
and more scalable.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib98.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Trials</span><span id="bib.bib98.4.2" class="ltx_text" style="font-size:90%;">, 22(1):1–7, 2021.
</span>
</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[99]</span>
<span class="ltx_bibblock"><span id="bib.bib99.1.1" class="ltx_text" style="font-size:90%;">
Owen Faris and Jeffrey Shuren.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib99.2.1" class="ltx_text" style="font-size:90%;">An FDA viewpoint on unique considerations for medical-device
clinical trials.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib99.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">New England Journal of Medicine (NEJM)</span><span id="bib.bib99.4.2" class="ltx_text" style="font-size:90%;">, 376(14):1350–1357,
2017.
</span>
</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[100]</span>
<span class="ltx_bibblock"><span id="bib.bib100.1.1" class="ltx_text" style="font-size:90%;">
Nicolas Carlini, Jamie Hayes, Milad Nasr, Matthew Jagielski, Vikash Sehwag,
Florian Tramer, Borja Balle, Daphne Ippolito, and Eric Wallace.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib100.2.1" class="ltx_text" style="font-size:90%;">Extracting training data from diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib100.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib100.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">32nd USENIX Security Symposium (USENIX Security 23)</span><span id="bib.bib100.5.3" class="ltx_text" style="font-size:90%;">, pages
5253–5270, 2023.
</span>
</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[101]</span>
<span class="ltx_bibblock"><span id="bib.bib101.1.1" class="ltx_text" style="font-size:90%;">
Mauro Giuffrè and Dennis L Shung.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib101.2.1" class="ltx_text" style="font-size:90%;">Harnessing the power of synthetic data in healthcare: innovation,
application, and privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib101.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">NPJ Digital Medicine</span><span id="bib.bib101.4.2" class="ltx_text" style="font-size:90%;">, 6(1):186, 2023.
</span>
</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[102]</span>
<span class="ltx_bibblock"><span id="bib.bib102.1.1" class="ltx_text" style="font-size:90%;">
Joseph Near, David Darais, Naomi Lefkovitz, Gary Howarth, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib102.2.1" class="ltx_text" style="font-size:90%;">Guidelines for evaluating differential privacy guarantees.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib102.3.1" class="ltx_text" style="font-size:90%;">Technical report, National Institute of Standards and Technology
(NIST), 2023.
</span>
</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[103]</span>
<span class="ltx_bibblock"><span id="bib.bib103.1.1" class="ltx_text" style="font-size:90%;">
Allan Tucker, Zhenchen Wang, Ylenia Rotalinti, and Puja Myles.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib103.2.1" class="ltx_text" style="font-size:90%;">Generating high-fidelity synthetic patient data for assessing machine
learning healthcare software.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib103.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">NPJ Digital Medicine</span><span id="bib.bib103.4.2" class="ltx_text" style="font-size:90%;">, 3(1):1–13, 2020.
</span>
</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[104]</span>
<span class="ltx_bibblock"><span id="bib.bib104.1.1" class="ltx_text" style="font-size:90%;">
Moritz Hardt, Eric Price, and Nati Srebro.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib104.2.1" class="ltx_text" style="font-size:90%;">Equality of opportunity in supervised learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib104.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Advances in Neural Information Processing Systems (NeurIPS)</span><span id="bib.bib104.4.2" class="ltx_text" style="font-size:90%;">,
29, 2016.
</span>
</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[105]</span>
<span class="ltx_bibblock"><span id="bib.bib105.1.1" class="ltx_text" style="font-size:90%;">
Ira Ktena, Olivia Wiles, Isabela Albuquerque, Sylvestre-Alvise Rebuffi, Ryutaro
Tanno, Abhijit Guha Roy, Shekoofeh Azizi, Danielle Belgrave, Pushmeet Kohli,
Alan Karthikesalingam, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib105.2.1" class="ltx_text" style="font-size:90%;">Generative models improve fairness of medical classifiers under
distribution shifts.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib105.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2304.09218</span><span id="bib.bib105.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[106]</span>
<span class="ltx_bibblock"><span id="bib.bib106.1.1" class="ltx_text" style="font-size:90%;">
Rebecca Smith-Bindman, Marilyn L Kwan, Emily C Marlow, Mary Kay Theis, Wesley
Bolch, Stephanie Y Cheng, Erin JA Bowles, James R Duncan, Robert T Greenlee,
Lawrence H Kushi, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib106.2.1" class="ltx_text" style="font-size:90%;">Trends in use of medical imaging in us health care systems and in
ontario, canada, 2000-2016.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib106.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Jama</span><span id="bib.bib106.4.2" class="ltx_text" style="font-size:90%;">, 322(9):843–856, 2019.
</span>
</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[107]</span>
<span class="ltx_bibblock"><span id="bib.bib107.1.1" class="ltx_text" style="font-size:90%;">
Marla BK Sammer, Yasmin S Akbari, Richard A Barth, Steven L Blumer, Jonathan R
Dillman, Shannon G Farmakis, Don Frush, Ami Gokli, Safwan Halabi, Ramesh
Iyer, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib107.2.1" class="ltx_text" style="font-size:90%;">Use of artificial intelligence in radiology: impact on pediatric
patients, a white paper from the ACR pediatric AI workgroup.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib107.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Journal of the American College of Radiology (JACR)</span><span id="bib.bib107.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[108]</span>
<span class="ltx_bibblock"><span id="bib.bib108.1.1" class="ltx_text" style="font-size:90%;">
Alexandra Sasha Luccioni, Christopher Akiki, Margaret Mitchell, and Yacine
Jernite.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib108.2.1" class="ltx_text" style="font-size:90%;">Stable bias: analyzing societal representations in diffusion models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib108.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2303.11408</span><span id="bib.bib108.4.2" class="ltx_text" style="font-size:90%;">, 2023.
</span>
</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[109]</span>
<span class="ltx_bibblock"><span id="bib.bib109.1.1" class="ltx_text" style="font-size:90%;">
Nataniel Ruiz, Yuanzhen Li, Varun Jampani, Yael Pritch, Michael Rubinstein, and
Kfir Aberman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib109.2.1" class="ltx_text" style="font-size:90%;">Dreambooth: Fine tuning text-to-image diffusion models for
subject-driven generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib109.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib109.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE / CVF Computer Vision and Pattern
Recognition Conference (CVPR)</span><span id="bib.bib109.5.3" class="ltx_text" style="font-size:90%;">, pages 22500–22510, 2023.
</span>
</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[110]</span>
<span class="ltx_bibblock"><span id="bib.bib110.1.1" class="ltx_text" style="font-size:90%;">
Michael Platzer and Thomas Reutterer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib110.2.1" class="ltx_text" style="font-size:90%;">Holdout-based empirical assessment of mixed-type synthetic data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib110.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Frontiers in Big Data</span><span id="bib.bib110.4.2" class="ltx_text" style="font-size:90%;">, 4:679939, 2021.
</span>
</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[111]</span>
<span class="ltx_bibblock"><span id="bib.bib111.1.1" class="ltx_text" style="font-size:90%;">
Harrison H Barrett and Kyle J Myers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib111.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Foundations of image science</span><span id="bib.bib111.3.2" class="ltx_text" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib111.4.1" class="ltx_text" style="font-size:90%;">John Wiley &amp; Sons, 2013.
</span>
</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[112]</span>
<span class="ltx_bibblock"><span id="bib.bib112.1.1" class="ltx_text" style="font-size:90%;">
Ahmed Alaa, Boris Van Breugel, Evgeny S Saveliev, and Mihaela van der Schaar.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib112.2.1" class="ltx_text" style="font-size:90%;">How faithful is your synthetic data? sample-level metrics for
evaluating and auditing generative models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib112.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib112.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the International Conference on Machine
learning (ICML)</span><span id="bib.bib112.5.3" class="ltx_text" style="font-size:90%;">, pages 290–306. PMLR, 2022.
</span>
</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[113]</span>
<span class="ltx_bibblock"><span id="bib.bib113.1.1" class="ltx_text" style="font-size:90%;">
Sayantan Bhadra, Varun A Kelkar, Frank J Brooks, and Mark A Anastasio.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib113.2.1" class="ltx_text" style="font-size:90%;">On hallucinations in tomographic image reconstruction.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib113.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Medical Imaging (TMI)</span><span id="bib.bib113.4.2" class="ltx_text" style="font-size:90%;">, 40(11):3249–3260,
2021.
</span>
</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[114]</span>
<span class="ltx_bibblock"><span id="bib.bib114.1.1" class="ltx_text" style="font-size:90%;">
Li Sze Chow and Raveendran Paramesran.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib114.2.1" class="ltx_text" style="font-size:90%;">Review of medical image quality assessment.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib114.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Biomedical Signal Processing and Control</span><span id="bib.bib114.4.2" class="ltx_text" style="font-size:90%;">, 27:145–154, 2016.
</span>
</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[115]</span>
<span class="ltx_bibblock"><span id="bib.bib115.1.1" class="ltx_text" style="font-size:90%;">
Graham Oppy and David Dowe.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib115.2.1" class="ltx_text" style="font-size:90%;">The Turing test.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib115.3.1" class="ltx_text" style="font-size:90%;">In Edward N. Zalta, editor, </span><span id="bib.bib115.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">The Stanford Encyclopedia of
Philosophy</span><span id="bib.bib115.5.3" class="ltx_text" style="font-size:90%;">. Edward N. Zalta, spring 2016 edition, 2016.
</span>
</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[116]</span>
<span class="ltx_bibblock"><span id="bib.bib116.1.1" class="ltx_text" style="font-size:90%;">
Aldo Badano.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib116.2.1" class="ltx_text" style="font-size:90%;">“how much realism is needed?”—the wrong question in silico
imagers have been asking.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib116.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Medical Physics</span><span id="bib.bib116.4.2" class="ltx_text" style="font-size:90%;">, 44(5):1607–1609, 2017.
</span>
</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[117]</span>
<span class="ltx_bibblock"><span id="bib.bib117.1.1" class="ltx_text" style="font-size:90%;">
Ge Wang, Andreu Badal, Xun Jia, Jonathan S Maltz, Klaus Mueller, Kyle J Myers,
Chuang Niu, Michael Vannier, Pingkun Yan, Zhou Yu, et al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib117.2.1" class="ltx_text" style="font-size:90%;">Development of metaverse for intelligent healthcare.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib117.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Nature Machine Intelligence</span><span id="bib.bib117.4.2" class="ltx_text" style="font-size:90%;">, 4(11):922–929, 2022.
</span>
</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2407.01560" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2407.01561" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2407.01561">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2407.01561" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2407.01562" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Aug  5 13:43:35 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
