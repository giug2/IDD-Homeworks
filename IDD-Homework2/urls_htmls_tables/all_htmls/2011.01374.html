<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2011.01374] Synthetic Data Generation for Economists</title>
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Synthetic Data Generation for Economists">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Synthetic Data Generation for Economists">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2011.01374">

<!--Generated on Sat Mar  2 08:48:42 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<!--Document created on Presented at the American Economic Association (AEA) Annual Meeting .-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Synthetic Data Generation for Economists </h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Allison Koenecke
</span><span class="ltx_author_notes"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">koenecke@stanford.edu</span>, Stanford Institute for Computational &amp; Mathematical Engineering</span></span>
<span class="ltx_author_before">â€ƒâ€ƒ</span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Hal Varian
</span><span class="ltx_author_notes">Google Economics Team</span></span>
</div>
<div class="ltx_dates">(Presented at the American Economic Association (AEA) Annual Meeting 
<br class="ltx_break">January 2020 )</div>

<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Motivation</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">As more tech companies engage in rigorous economic analyses, we are confronted with a data problem: in-house papers cannot be replicated due to use of sensitive, proprietary, or private data. Readers are left to assume that the obscured true data (e.g., internal Google information) indeed produced the results given, or they must seek out comparable public-facing data (e.g., Google Trends) that yield similar results <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. One way to ameliorate this reproducibility issue is to have researchers release synthetic datasets based on their true data; this allows external parties to replicate an internal researcherâ€™s methodology. In this brief overview, we explore synthetic data generation at a high level for economic analyses.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">One analogy explaining synthetic data generation involves OpenAIâ€™s GPT-2 model for text generation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>. The model takes as input several starter lines of text, and outputs additional text based on the prompt; when the user gives the model just one sentence, she receives a full story back. In economic applications, we instead feed numerical data (such as time series values) into a generative model. The model then produces similar but new data that preserve certain aspects of the structure, such as covariances across attributes. In this way, we construct a plausible extension of the seed â€“ but not a true extension that would reveal private information.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The ideal outline for future publications using sensitive, proprietary, or private data looks roughly as follows:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">Describe the true data.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Describe a synthetic data generating model that produces a synthetic dataset.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Run the same analyses on both true and synthetic data.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">Confirm that results on both datasets are comparable.</p>
</div>
</li>
<li id="S1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S1.I1.i5.p1" class="ltx_para">
<p id="S1.I1.i5.p1.1" class="ltx_p">Publicly release the synthetic dataset.</p>
</div>
</li>
</ol>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The above framework both allows an external agent to reproduce the internal researcherâ€™s methodology, and allows a separate internal agent to reproduce the synthetic data via their access to the true data.
With this in mind, we turn to describing a variety of generative models that may be useful for economists.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Generative Models for Synthetic Data</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">We begin with the caveat that there is no single catch-all method to best generate synthetic data: one must consider the ensuing analyses before choosing the data generating method. For example, if only the first and second moments need to be captured, generating synthetic data will not be nearly as computationally intensive as an analysis requiring higher moments. Further, if the data must be scrubbed to enforce differential privacy when performing summary statistics, then additional precautions should be taken when generating synthetic data.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">A relatively basic but comprehensive method for data generation is the Synthetic Data Vault (SDV) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. This work uses the multivariate Gaussian Copula when calculating covariances across input columns. Then, the distributions and covariances are sampled to form synthetic data. As proof of concept, five relational datasets were synthetically generated and used by freelance data scientists to develop predictive models. The researchers found no significant difference between the results produced using the synthetic versus true data.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">While the SDV allows for a basic perturbation of model parameters to create noisy versions of the data, it does not explicitly address more concrete data privacy concerns. There is, however, a vast literature in the machine learning community regarding differential privacy<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>We provide the formal definition for <math id="footnote1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="footnote1.m1.1b"><mi id="footnote1.m1.1.1" xref="footnote1.m1.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="footnote1.m1.1c"><ci id="footnote1.m1.1.1.cmml" xref="footnote1.m1.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m1.1d">\epsilon</annotation></semantics></math>-differential privacy here. A randomized algorithm <math id="footnote1.m2.1" class="ltx_Math" alttext="\mathcal{A}:\mathcal{D}\rightarrow\mathcal{R}" display="inline"><semantics id="footnote1.m2.1b"><mrow id="footnote1.m2.1.1" xref="footnote1.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="footnote1.m2.1.1.2" xref="footnote1.m2.1.1.2.cmml">ğ’œ</mi><mo lspace="0.278em" rspace="0.278em" id="footnote1.m2.1.1.1" xref="footnote1.m2.1.1.1.cmml">:</mo><mrow id="footnote1.m2.1.1.3" xref="footnote1.m2.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="footnote1.m2.1.1.3.2" xref="footnote1.m2.1.1.3.2.cmml">ğ’Ÿ</mi><mo stretchy="false" id="footnote1.m2.1.1.3.1" xref="footnote1.m2.1.1.3.1.cmml">â†’</mo><mi class="ltx_font_mathcaligraphic" id="footnote1.m2.1.1.3.3" xref="footnote1.m2.1.1.3.3.cmml">â„›</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="footnote1.m2.1c"><apply id="footnote1.m2.1.1.cmml" xref="footnote1.m2.1.1"><ci id="footnote1.m2.1.1.1.cmml" xref="footnote1.m2.1.1.1">:</ci><ci id="footnote1.m2.1.1.2.cmml" xref="footnote1.m2.1.1.2">ğ’œ</ci><apply id="footnote1.m2.1.1.3.cmml" xref="footnote1.m2.1.1.3"><ci id="footnote1.m2.1.1.3.1.cmml" xref="footnote1.m2.1.1.3.1">â†’</ci><ci id="footnote1.m2.1.1.3.2.cmml" xref="footnote1.m2.1.1.3.2">ğ’Ÿ</ci><ci id="footnote1.m2.1.1.3.3.cmml" xref="footnote1.m2.1.1.3.3">â„›</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m2.1d">\mathcal{A}:\mathcal{D}\rightarrow\mathcal{R}</annotation></semantics></math> with domain <math id="footnote1.m3.1" class="ltx_Math" alttext="\mathcal{D}" display="inline"><semantics id="footnote1.m3.1b"><mi class="ltx_font_mathcaligraphic" id="footnote1.m3.1.1" xref="footnote1.m3.1.1.cmml">ğ’Ÿ</mi><annotation-xml encoding="MathML-Content" id="footnote1.m3.1c"><ci id="footnote1.m3.1.1.cmml" xref="footnote1.m3.1.1">ğ’Ÿ</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m3.1d">\mathcal{D}</annotation></semantics></math> and range <math id="footnote1.m4.1" class="ltx_Math" alttext="\mathcal{R}" display="inline"><semantics id="footnote1.m4.1b"><mi class="ltx_font_mathcaligraphic" id="footnote1.m4.1.1" xref="footnote1.m4.1.1.cmml">â„›</mi><annotation-xml encoding="MathML-Content" id="footnote1.m4.1c"><ci id="footnote1.m4.1.1.cmml" xref="footnote1.m4.1.1">â„›</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m4.1d">\mathcal{R}</annotation></semantics></math> is (<math id="footnote1.m5.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="footnote1.m5.1b"><mi id="footnote1.m5.1.1" xref="footnote1.m5.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="footnote1.m5.1c"><ci id="footnote1.m5.1.1.cmml" xref="footnote1.m5.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m5.1d">\epsilon</annotation></semantics></math>, <math id="footnote1.m6.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="footnote1.m6.1b"><mi id="footnote1.m6.1.1" xref="footnote1.m6.1.1.cmml">Î´</mi><annotation-xml encoding="MathML-Content" id="footnote1.m6.1c"><ci id="footnote1.m6.1.1.cmml" xref="footnote1.m6.1.1">ğ›¿</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m6.1d">\delta</annotation></semantics></math>)-differentially private if for any two adjacent training datasets d, dâ€™ <math id="footnote1.m7.1" class="ltx_Math" alttext="\subseteq" display="inline"><semantics id="footnote1.m7.1b"><mo id="footnote1.m7.1.1" xref="footnote1.m7.1.1.cmml">âŠ†</mo><annotation-xml encoding="MathML-Content" id="footnote1.m7.1c"><subset id="footnote1.m7.1.1.cmml" xref="footnote1.m7.1.1"></subset></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m7.1d">\subseteq</annotation></semantics></math> D, which differ by at most one training point, and any subset of outputs <math id="footnote1.m8.1" class="ltx_Math" alttext="\mathcal{S}\subseteq\mathcal{R}" display="inline"><semantics id="footnote1.m8.1b"><mrow id="footnote1.m8.1.1" xref="footnote1.m8.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="footnote1.m8.1.1.2" xref="footnote1.m8.1.1.2.cmml">ğ’®</mi><mo id="footnote1.m8.1.1.1" xref="footnote1.m8.1.1.1.cmml">âŠ†</mo><mi class="ltx_font_mathcaligraphic" id="footnote1.m8.1.1.3" xref="footnote1.m8.1.1.3.cmml">â„›</mi></mrow><annotation-xml encoding="MathML-Content" id="footnote1.m8.1c"><apply id="footnote1.m8.1.1.cmml" xref="footnote1.m8.1.1"><subset id="footnote1.m8.1.1.1.cmml" xref="footnote1.m8.1.1.1"></subset><ci id="footnote1.m8.1.1.2.cmml" xref="footnote1.m8.1.1.2">ğ’®</ci><ci id="footnote1.m8.1.1.3.cmml" xref="footnote1.m8.1.1.3">â„›</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m8.1d">\mathcal{S}\subseteq\mathcal{R}</annotation></semantics></math>, it satisfies that:
<math id="footnote1.m9.3" class="ltx_Math" alttext="\textrm{Pr}[\mathcal{A}(d)\in\mathcal{S}]\leq e^{\epsilon}\textrm{Pr}[\mathcal{A}(d^{\prime})\in\mathcal{S}]+\delta" display="inline"><semantics id="footnote1.m9.3b"><mrow id="footnote1.m9.3.3" xref="footnote1.m9.3.3.cmml"><mrow id="footnote1.m9.2.2.1" xref="footnote1.m9.2.2.1.cmml"><mtext id="footnote1.m9.2.2.1.3" xref="footnote1.m9.2.2.1.3a.cmml">Pr</mtext><mo lspace="0em" rspace="0em" id="footnote1.m9.2.2.1.2" xref="footnote1.m9.2.2.1.2.cmml">â€‹</mo><mrow id="footnote1.m9.2.2.1.1.1" xref="footnote1.m9.2.2.1.1.2.cmml"><mo stretchy="false" id="footnote1.m9.2.2.1.1.1.2" xref="footnote1.m9.2.2.1.1.2.1.cmml">[</mo><mrow id="footnote1.m9.2.2.1.1.1.1" xref="footnote1.m9.2.2.1.1.1.1.cmml"><mrow id="footnote1.m9.2.2.1.1.1.1.2" xref="footnote1.m9.2.2.1.1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="footnote1.m9.2.2.1.1.1.1.2.2" xref="footnote1.m9.2.2.1.1.1.1.2.2.cmml">ğ’œ</mi><mo lspace="0em" rspace="0em" id="footnote1.m9.2.2.1.1.1.1.2.1" xref="footnote1.m9.2.2.1.1.1.1.2.1.cmml">â€‹</mo><mrow id="footnote1.m9.2.2.1.1.1.1.2.3.2" xref="footnote1.m9.2.2.1.1.1.1.2.cmml"><mo stretchy="false" id="footnote1.m9.2.2.1.1.1.1.2.3.2.1" xref="footnote1.m9.2.2.1.1.1.1.2.cmml">(</mo><mi id="footnote1.m9.1.1" xref="footnote1.m9.1.1.cmml">d</mi><mo stretchy="false" id="footnote1.m9.2.2.1.1.1.1.2.3.2.2" xref="footnote1.m9.2.2.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="footnote1.m9.2.2.1.1.1.1.1" xref="footnote1.m9.2.2.1.1.1.1.1.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="footnote1.m9.2.2.1.1.1.1.3" xref="footnote1.m9.2.2.1.1.1.1.3.cmml">ğ’®</mi></mrow><mo stretchy="false" id="footnote1.m9.2.2.1.1.1.3" xref="footnote1.m9.2.2.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="footnote1.m9.3.3.3" xref="footnote1.m9.3.3.3.cmml">â‰¤</mo><mrow id="footnote1.m9.3.3.2" xref="footnote1.m9.3.3.2.cmml"><mrow id="footnote1.m9.3.3.2.1" xref="footnote1.m9.3.3.2.1.cmml"><msup id="footnote1.m9.3.3.2.1.3" xref="footnote1.m9.3.3.2.1.3.cmml"><mi id="footnote1.m9.3.3.2.1.3.2" xref="footnote1.m9.3.3.2.1.3.2.cmml">e</mi><mi id="footnote1.m9.3.3.2.1.3.3" xref="footnote1.m9.3.3.2.1.3.3.cmml">Ïµ</mi></msup><mo lspace="0em" rspace="0em" id="footnote1.m9.3.3.2.1.2" xref="footnote1.m9.3.3.2.1.2.cmml">â€‹</mo><mtext id="footnote1.m9.3.3.2.1.4" xref="footnote1.m9.3.3.2.1.4a.cmml">Pr</mtext><mo lspace="0em" rspace="0em" id="footnote1.m9.3.3.2.1.2b" xref="footnote1.m9.3.3.2.1.2.cmml">â€‹</mo><mrow id="footnote1.m9.3.3.2.1.1.1" xref="footnote1.m9.3.3.2.1.1.2.cmml"><mo stretchy="false" id="footnote1.m9.3.3.2.1.1.1.2" xref="footnote1.m9.3.3.2.1.1.2.1.cmml">[</mo><mrow id="footnote1.m9.3.3.2.1.1.1.1" xref="footnote1.m9.3.3.2.1.1.1.1.cmml"><mrow id="footnote1.m9.3.3.2.1.1.1.1.1" xref="footnote1.m9.3.3.2.1.1.1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="footnote1.m9.3.3.2.1.1.1.1.1.3" xref="footnote1.m9.3.3.2.1.1.1.1.1.3.cmml">ğ’œ</mi><mo lspace="0em" rspace="0em" id="footnote1.m9.3.3.2.1.1.1.1.1.2" xref="footnote1.m9.3.3.2.1.1.1.1.1.2.cmml">â€‹</mo><mrow id="footnote1.m9.3.3.2.1.1.1.1.1.1.1" xref="footnote1.m9.3.3.2.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="footnote1.m9.3.3.2.1.1.1.1.1.1.1.2" xref="footnote1.m9.3.3.2.1.1.1.1.1.1.1.1.cmml">(</mo><msup id="footnote1.m9.3.3.2.1.1.1.1.1.1.1.1" xref="footnote1.m9.3.3.2.1.1.1.1.1.1.1.1.cmml"><mi id="footnote1.m9.3.3.2.1.1.1.1.1.1.1.1.2" xref="footnote1.m9.3.3.2.1.1.1.1.1.1.1.1.2.cmml">d</mi><mo id="footnote1.m9.3.3.2.1.1.1.1.1.1.1.1.3" xref="footnote1.m9.3.3.2.1.1.1.1.1.1.1.1.3.cmml">â€²</mo></msup><mo stretchy="false" id="footnote1.m9.3.3.2.1.1.1.1.1.1.1.3" xref="footnote1.m9.3.3.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="footnote1.m9.3.3.2.1.1.1.1.2" xref="footnote1.m9.3.3.2.1.1.1.1.2.cmml">âˆˆ</mo><mi class="ltx_font_mathcaligraphic" id="footnote1.m9.3.3.2.1.1.1.1.3" xref="footnote1.m9.3.3.2.1.1.1.1.3.cmml">ğ’®</mi></mrow><mo stretchy="false" id="footnote1.m9.3.3.2.1.1.1.3" xref="footnote1.m9.3.3.2.1.1.2.1.cmml">]</mo></mrow></mrow><mo id="footnote1.m9.3.3.2.2" xref="footnote1.m9.3.3.2.2.cmml">+</mo><mi id="footnote1.m9.3.3.2.3" xref="footnote1.m9.3.3.2.3.cmml">Î´</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="footnote1.m9.3c"><apply id="footnote1.m9.3.3.cmml" xref="footnote1.m9.3.3"><leq id="footnote1.m9.3.3.3.cmml" xref="footnote1.m9.3.3.3"></leq><apply id="footnote1.m9.2.2.1.cmml" xref="footnote1.m9.2.2.1"><times id="footnote1.m9.2.2.1.2.cmml" xref="footnote1.m9.2.2.1.2"></times><ci id="footnote1.m9.2.2.1.3a.cmml" xref="footnote1.m9.2.2.1.3"><mtext id="footnote1.m9.2.2.1.3.cmml" xref="footnote1.m9.2.2.1.3">Pr</mtext></ci><apply id="footnote1.m9.2.2.1.1.2.cmml" xref="footnote1.m9.2.2.1.1.1"><csymbol cd="latexml" id="footnote1.m9.2.2.1.1.2.1.cmml" xref="footnote1.m9.2.2.1.1.1.2">delimited-[]</csymbol><apply id="footnote1.m9.2.2.1.1.1.1.cmml" xref="footnote1.m9.2.2.1.1.1.1"><in id="footnote1.m9.2.2.1.1.1.1.1.cmml" xref="footnote1.m9.2.2.1.1.1.1.1"></in><apply id="footnote1.m9.2.2.1.1.1.1.2.cmml" xref="footnote1.m9.2.2.1.1.1.1.2"><times id="footnote1.m9.2.2.1.1.1.1.2.1.cmml" xref="footnote1.m9.2.2.1.1.1.1.2.1"></times><ci id="footnote1.m9.2.2.1.1.1.1.2.2.cmml" xref="footnote1.m9.2.2.1.1.1.1.2.2">ğ’œ</ci><ci id="footnote1.m9.1.1.cmml" xref="footnote1.m9.1.1">ğ‘‘</ci></apply><ci id="footnote1.m9.2.2.1.1.1.1.3.cmml" xref="footnote1.m9.2.2.1.1.1.1.3">ğ’®</ci></apply></apply></apply><apply id="footnote1.m9.3.3.2.cmml" xref="footnote1.m9.3.3.2"><plus id="footnote1.m9.3.3.2.2.cmml" xref="footnote1.m9.3.3.2.2"></plus><apply id="footnote1.m9.3.3.2.1.cmml" xref="footnote1.m9.3.3.2.1"><times id="footnote1.m9.3.3.2.1.2.cmml" xref="footnote1.m9.3.3.2.1.2"></times><apply id="footnote1.m9.3.3.2.1.3.cmml" xref="footnote1.m9.3.3.2.1.3"><csymbol cd="ambiguous" id="footnote1.m9.3.3.2.1.3.1.cmml" xref="footnote1.m9.3.3.2.1.3">superscript</csymbol><ci id="footnote1.m9.3.3.2.1.3.2.cmml" xref="footnote1.m9.3.3.2.1.3.2">ğ‘’</ci><ci id="footnote1.m9.3.3.2.1.3.3.cmml" xref="footnote1.m9.3.3.2.1.3.3">italic-Ïµ</ci></apply><ci id="footnote1.m9.3.3.2.1.4a.cmml" xref="footnote1.m9.3.3.2.1.4"><mtext id="footnote1.m9.3.3.2.1.4.cmml" xref="footnote1.m9.3.3.2.1.4">Pr</mtext></ci><apply id="footnote1.m9.3.3.2.1.1.2.cmml" xref="footnote1.m9.3.3.2.1.1.1"><csymbol cd="latexml" id="footnote1.m9.3.3.2.1.1.2.1.cmml" xref="footnote1.m9.3.3.2.1.1.1.2">delimited-[]</csymbol><apply id="footnote1.m9.3.3.2.1.1.1.1.cmml" xref="footnote1.m9.3.3.2.1.1.1.1"><in id="footnote1.m9.3.3.2.1.1.1.1.2.cmml" xref="footnote1.m9.3.3.2.1.1.1.1.2"></in><apply id="footnote1.m9.3.3.2.1.1.1.1.1.cmml" xref="footnote1.m9.3.3.2.1.1.1.1.1"><times id="footnote1.m9.3.3.2.1.1.1.1.1.2.cmml" xref="footnote1.m9.3.3.2.1.1.1.1.1.2"></times><ci id="footnote1.m9.3.3.2.1.1.1.1.1.3.cmml" xref="footnote1.m9.3.3.2.1.1.1.1.1.3">ğ’œ</ci><apply id="footnote1.m9.3.3.2.1.1.1.1.1.1.1.1.cmml" xref="footnote1.m9.3.3.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="footnote1.m9.3.3.2.1.1.1.1.1.1.1.1.1.cmml" xref="footnote1.m9.3.3.2.1.1.1.1.1.1.1">superscript</csymbol><ci id="footnote1.m9.3.3.2.1.1.1.1.1.1.1.1.2.cmml" xref="footnote1.m9.3.3.2.1.1.1.1.1.1.1.1.2">ğ‘‘</ci><ci id="footnote1.m9.3.3.2.1.1.1.1.1.1.1.1.3.cmml" xref="footnote1.m9.3.3.2.1.1.1.1.1.1.1.1.3">â€²</ci></apply></apply><ci id="footnote1.m9.3.3.2.1.1.1.1.3.cmml" xref="footnote1.m9.3.3.2.1.1.1.1.3">ğ’®</ci></apply></apply></apply><ci id="footnote1.m9.3.3.2.3.cmml" xref="footnote1.m9.3.3.2.3">ğ›¿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m9.3d">\textrm{Pr}[\mathcal{A}(d)\in\mathcal{S}]\leq e^{\epsilon}\textrm{Pr}[\mathcal{A}(d^{\prime})\in\mathcal{S}]+\delta</annotation></semantics></math>, where <math id="footnote1.m10.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="footnote1.m10.1b"><mi id="footnote1.m10.1.1" xref="footnote1.m10.1.1.cmml">Ïµ</mi><annotation-xml encoding="MathML-Content" id="footnote1.m10.1c"><ci id="footnote1.m10.1.1.cmml" xref="footnote1.m10.1.1">italic-Ïµ</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m10.1d">\epsilon</annotation></semantics></math> is the privacy budget and <math id="footnote1.m11.1" class="ltx_Math" alttext="\delta" display="inline"><semantics id="footnote1.m11.1b"><mi id="footnote1.m11.1.1" xref="footnote1.m11.1.1.cmml">Î´</mi><annotation-xml encoding="MathML-Content" id="footnote1.m11.1c"><ci id="footnote1.m11.1.1.cmml" xref="footnote1.m11.1.1">ğ›¿</ci></annotation-xml><annotation encoding="application/x-tex" id="footnote1.m11.1d">\delta</annotation></semantics></math> is a failure rate <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. </span></span></span>
with generative models; a Gaussian mechanism is often used to perturb the input with noise sampled from a normal distribution based on the sensitivity <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. Within a machine learning framework, â€œprivacy lossâ€ can be quantified at each iteration of training, which ends when the loss reaches a pre-defined privacy budget. This training is often performed on auto-encoders<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>These are models used in unsupervised learning, which use dimensionality reduction to hone in on the most important data features, and are particularly useful for high-dimensional input data. The superficially similar Variational Auto-Encoder <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> encourages its latent variables to be distributed as a Gaussian distribution, enabling use as a generative model.</span></span></span>, which learn the latent structure of an input (using the â€œencoderâ€), and then reconstruct the input (using the â€œdecoderâ€); these two parts of the network are generally trained together to minimize reconstruction loss. In particular, the auto-encoder technique DP-SYN has been shown experimentally to out-perform other methods of privacy-preserving synthetic data generation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. Further, it is important for differential privacy to defend against model inversion and Generative Adversarial Network<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>We discuss GANs at length in the following section.</span></span></span> (GAN)-based attacks; these types of attacks are able to reconstruct training data despite the training process being differentially private <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, even when using federated learning (as popularized by Google <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>). The harm from these attacks can be mitigated by using auto-encoder-based generative model techniques such as DP-AuGM (which requires the user to include public data seeds to generate new data based on the private data training), and DP-VaeGM (which generates an infinite amount of data based on Gaussian noise, but is less stable) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. The examples cited here are applied to classification tasks; there additionally exist algorithms for differentially private regression <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> and association rule mining <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> that can be applied to synthetic data.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">Next, we discuss the current literature with regard to robustness. Economists are familiar with using torture tests to generate a worst-case model and finding the minimal perturbation necessary to break a result (e.g., reversing a sign in some variable of interest). Robustness checks on the data rather than the model can be done to confirm that perturbing the true data (when generating synthetic data) is not problematic. In the deep learning world, similar analyses are a cornerstone of adversarial machine learning research; much of it follows the canonical 2013 paper showing that data perturbations can result in misclassification of images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. More recent work has studied neural network robustness necessary for resistance against adversarial attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. Robustness research is not limited to deep learning; work has also been done using robust regressions with low-rank approximations to defend against what has been termed â€œtraining data poisoningâ€ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. In this vein, economists can further confirm the transferability of results obtained from their sensitive, proprietary, or private data.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Generative Adversarial Networks</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Further to the above generative methods described, there has been much excitement surrounding Generative Adversarial Networks (GANs) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> in generating synthetic data. While common applications include generation of images and text, there has recently been increasing interest in the economic space. We first explore what GANs are, and then briefly survey the current literature as it relates to generating synthetic data for economists.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">GANs generate data using two components: a generator (which creates candidates for data distributions) and a discriminator (which evaluates the candidates)<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Usually, the generator and discriminator are various kinds of neural networks. But, we can also imagine a simple GAN wherein both generator and discriminator are simply parametric models. The generator is trained to optimize for increasing the error rate of the discriminator.</span></span></span>.
If the discriminator is able to correctly classify the generatorâ€™s candidates as synthetic data (as opposed to true data), then the generator has failed. The generator will try to act adversarially to fool the discriminator into not being able to differentiate between the true and synthetic data (i.e., minimizing the maximum distance between these datasets). Wasserstein GANs, in particular, use the Wasserstein distance<span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>Intuitively, the Wasserstein metric can be thought of in relation to the optimal transport problem, wherein the goal is to transport one distribution of mass to a different distribution (of the same mass) on the same space. We can think of this as shifting a pile of sand from one distribution to another; which grains of sand should be moved so that the cost of transporting sand is minimized?</span></span></span>
between probability distributions on a given metric space <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">In the economic literature, GANs are a useful way to redesign standard Monte Carlo studies. As one example, Wasserstein GANs have been used to generate realistic synthetic data by Athey et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, which were then used to compare different estimators for average treatment effects. In addition to using a systematic simulation study design, a new estimator has been proposed based on GAN discriminators, and was found to be more efficient than a standard indirect inference estimator <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. This is broadly useful in structural estimation where researchers aim to learn about policy effects arising from economic models that often have intractable likelihoods. Lastly, it is of note that privacy-preserving methods can also be extended to GAN-generated synthetic data, in applications ranging from image generation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> to clinical studies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">While we only cover a few generative models in this overview, it is worth noting that there are many other types of deep generative models worth exploring, including: Variational Auto-Encoders <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, Autoregressive Models (MADE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, Pixel RNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, Pixel CNN++ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, WaveNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>), Normalizing Flow Models (RealNVP <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>, Glow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>), and Energy-Based Models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. Going forward, we hope to see more synthetic data generation methods in the economic literature.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:80%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:80%;">
NazmiyeÂ Ceren Abay, Yan Zhou, Murat Kantarcioglu, Bhavani Thuraisingham, and
Latanya Sweeney.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.2.1" class="ltx_text" style="font-size:80%;">Privacy preserving synthetic data release using deep learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text" style="font-size:80%;">In Michele Berlingerio, Francesco Bonchi, Thomas GÃ¤rtner, Neil
Hurley, and Georgiana Ifrim, editors, </span><span id="bib.bib1.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Machine Learning and Knowledge
Discovery in Databases</span><span id="bib.bib1.5.3" class="ltx_text" style="font-size:80%;">, pages 510â€“526, Cham, 2019. Springer International
Publishing.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:80%;">
Martin Arjovsky, Soumith Chintala, and LÃ©on Bottou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.2.1" class="ltx_text" style="font-size:80%;">Wasserstein gan, 2017.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:80%;">
Susan Athey, Guido Imbens, Jonas Metzger, and Evan Munro.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:80%;">Using wasserstein generative adversarial networks for the design of
monte carlo simulations, 2019.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:80%;">
BrettÂ K. Beaulieu-Jones, ZhiweiÂ Steven Wu, Chris Williams, Ran Lee, SanjeevÂ P.
Bhavnani, JamesÂ Brian Byrd, and CaseyÂ S. Greene.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:80%;">Privacy-preserving generative deep neural networks support clinical
data sharing.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">bioRxiv</span><span id="bib.bib4.4.2" class="ltx_text" style="font-size:80%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:80%;">
Kamalika Chaudhuri and Claire Monteleoni.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:80%;">Privacy-preserving logistic regression.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text" style="font-size:80%;">In D.Â Koller, D.Â Schuurmans, Y.Â Bengio, and L.Â Bottou, editors, </span><span id="bib.bib5.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Advances in Neural Information Processing Systems 21</span><span id="bib.bib5.5.3" class="ltx_text" style="font-size:80%;">, pages 289â€“296. Curran
Associates, Inc., 2009.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:80%;">
Qingrong Chen, Chong Xiang, Minhui Xue, BoÂ Li, Nikita Borisov, Dali Kaarfar,
and Haojin Zhu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:80%;">Differentially private data generative models, 2018.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:80%;">
Laurent Dinh, Jascha Sohl-Dickstein, and Samy Bengio.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:80%;">Density estimation using real nvp, 2016.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:80%;">
Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:80%;">Calibrating noise to sensitivity in private data analysis.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib8.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Theory of Cryptography</span><span id="bib.bib8.5.3" class="ltx_text" style="font-size:80%;">, volume Vol. 3876, pages 265â€“284, 01
2006.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:80%;">
Mathieu Germain, Karol Gregor, Iain Murray, and Hugo Larochelle.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:80%;">Made: Masked autoencoder for distribution estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the 32nd International Conference on Machine
Learning, JMLR W&amp;CP 37:881-889, 2015</span><span id="bib.bib9.4.2" class="ltx_text" style="font-size:80%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:80%;">
IanÂ J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David
Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:80%;">Generative adversarial networks, 2014.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:80%;">
Briland Hitaj, Giuseppe Ateniese, and Fernando Perez-Cruz.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:80%;">Deep models under the gan: Information leakage from collaborative
deep learning, 2017.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:80%;">
Tetsuya Kaji, Elena Manresa, and Guillaume Pouliot.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:80%;">Deep inference: Artificial intelligence for structural estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Barcelona GSE</span><span id="bib.bib12.4.2" class="ltx_text" style="font-size:80%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:80%;">
DiederikÂ P. Kingma and Prafulla Dhariwal.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:80%;">Glow: Generative flow with invertible 1x1 convolutions, 2018.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:80%;">
DiederikÂ P Kingma and Max Welling.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:80%;">Auto-encoding variational bayes, 2013.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:80%;">
Yann LeCun, Sumit Chopra, Raia Hadsell, FuÂ Jie Huang, and etÂ al.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:80%;">A tutorial on energy-based learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib15.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Predicting Structured Data</span><span id="bib.bib15.5.3" class="ltx_text" style="font-size:80%;">. MIT Press, 2006.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:80%;">
Ninghui Li, Wahbeh Qardaji, Dong Su, and Jianneng Cao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:80%;">Privbasis: Frequent itemset mining with differential privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
1340-1351 (2012)</span><span id="bib.bib16.4.2" class="ltx_text" style="font-size:80%;">, 2012.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:80%;">
Chang Liu, BoÂ Li, Yevgeniy Vorobeychik, and Alina Oprea.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:80%;">Robust linear regression against training data poisoning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the 10th ACM Workshop on Artificial
Intelligence and Security</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:80%;">, AISec â€™17, pages 91â€“102, New York, NY, USA,
2017. ACM.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:80%;">
Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and
Adrian Vladu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:80%;">Towards deep learning models resistant to adversarial attacks, 2017.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:80%;">
H.Â Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and
BlaiseÂ AgÃ¼era yÂ Arcas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:80%;">Communication-efficient learning of deep networks from decentralized
data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the 20 th International Conference on Artificial
Intelligence and Statistics (AISTATS) 2017. JMLR: W&amp;CP volume 54</span><span id="bib.bib19.4.2" class="ltx_text" style="font-size:80%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:80%;">
N.Â Patki, R.Â Wedge, and K.Â Veeramachaneni.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:80%;">The synthetic data vault.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:80%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:80%;">2016 IEEE International Conference on Data Science and
Advanced Analytics (DSAA)</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:80%;">, pages 399â€“410, Oct 2016.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:80%;">
Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya
Sutskever.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:80%;">Language models are unsupervised multitask learners.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">OpenAI blog</span><span id="bib.bib21.4.2" class="ltx_text" style="font-size:80%;">, 2019.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:80%;">
Tim Salimans, Andrej Karpathy, XiÂ Chen, and DiederikÂ P. Kingma.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:80%;">Pixelcnn++: Improving the pixelcnn with discretized logistic mixture
likelihood and other modifications, 2017.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:80%;">
Seth Stephens-Davidowitz, Hal Varian, and MichaelÂ D. Smith.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:80%;">Super returns to Super Bowl ads?
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Quantitative Marketing and Economics (QME)</span><span id="bib.bib23.4.2" class="ltx_text" style="font-size:80%;">, 15(1):1â€“28, March
2017.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:80%;">
Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan,
Ian Goodfellow, and Rob Fergus.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:80%;">Intriguing properties of neural networks, 2013.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:80%;">
Aaron vanÂ den Oord, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals,
Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:80%;">Wavenet: A generative model for raw audio, 2016.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:80%;">
Aaron vanÂ den Oord, Nal Kalchbrenner, and Koray Kavukcuoglu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:80%;">Pixel recurrent neural networks, 2016.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:80%;">
Liyang Xie, Kaixiang Lin, Shu Wang, Fei Wang, and Jiayu Zhou.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:80%;">Differentially private generative adversarial network, 2018.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:80%;">
C.Â Zeng, J.Â F. Naughton, and J.Â Y. Cai.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:80%;">On Differentially Private Frequent Itemset Mining.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">VLDB J</span><span id="bib.bib28.4.2" class="ltx_text" style="font-size:80%;">, 6(1):25â€“36, Nov 2012.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:80%;">
Jun Zhang, Zhenjie Zhang, Xiaokui Xiao, Yin Yang, and Marianne Winslett.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:80%;">Functional mechanism: Regression analysis under differential privacy.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text ltx_font_italic" style="font-size:80%;">Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 11, pp.
1364-1375 (2012)</span><span id="bib.bib29.4.2" class="ltx_text" style="font-size:80%;">, 2012.
</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2011.01373" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2011.01374" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2011.01374">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2011.01374" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2011.01375" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Sat Mar  2 08:48:42 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
