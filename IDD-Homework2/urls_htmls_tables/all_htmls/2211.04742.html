<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2211.04742] Knowledge Distillation for Federated Learning: a Practical Guide</title><meta property="og:description" content="Federated Learning (FL) enables the training of Deep Learning models without centrally collecting possibly sensitive raw data. This paves the way for stronger privacy guarantees when building predictive models. The mosâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Knowledge Distillation for Federated Learning: a Practical Guide">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Knowledge Distillation for Federated Learning: a Practical Guide">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2211.04742">

<!--Generated on Thu Mar 14 06:16:27 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Knowledge Distillation for Federated Learning: a Practical Guide</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
â€… Alessio Mora 
<br class="ltx_break">Department of Computer Science and Engineering
<br class="ltx_break">University of Bologna
<br class="ltx_break">Bologna, Italy 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">alessio.mora@unibo.it</span> 
<br class="ltx_break"><span id="id2.2.id2" class="ltx_ERROR undefined">\And</span>Irene Tenison
<br class="ltx_break">Mila, University of Montreal
<br class="ltx_break">Montreal, Canada
<br class="ltx_break"><span id="id3.3.id3" class="ltx_text ltx_font_typewriter">irene.tenison@umontreal.ca
<br class="ltx_break"><span id="id3.3.id3.1" class="ltx_ERROR undefined">\AND</span></span>Paolo Bellavista 
<br class="ltx_break">Department of Computer Science and Engineering 
<br class="ltx_break">University of Bologna
<br class="ltx_break">Bologna, Italy 
<br class="ltx_break"><span id="id4.4.id4" class="ltx_text ltx_font_typewriter">paolo.bellavista@unibo.it</span> 
<br class="ltx_break"><span id="id5.5.id5" class="ltx_ERROR undefined">\And</span>Irina Rish 
<br class="ltx_break">Mila, University of Montreal 
<br class="ltx_break">Montreal, Canada 
<br class="ltx_break"><span id="id6.6.id6" class="ltx_text ltx_font_typewriter">irina.rish@mila.quebec</span> 
<br class="ltx_break">
</span><span class="ltx_author_notes">Work performed while at Mila, University of Montreal.</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id7.id1" class="ltx_p">Federated Learning (FL) enables the training of Deep Learning models without centrally collecting possibly sensitive raw data. This paves the way for stronger privacy guarantees when building predictive models. The most used algorithms for FL are parameter-averaging based schemes (e.g., Federated Averaging) that, however, have well known limits: (i) Clients must implement the same model architecture; (ii) Transmitting model weights and model updates implies high communication cost, which scales up with the number of model parameters; (iii) In presence of non-IID data distributions, parameter-averaging aggregation schemes perform poorly due to client model drifts. Federated adaptations of regular Knowledge Distillation (KD) can solve and/or mitigate the weaknesses of parameter-averaging FL algorithms while possibly introducing other trade-offs. In this article, we provide a review of KD-based algorithms tailored for specific FL issues.</p>
</div>
<div id="p1" class="ltx_para ltx_noindent">
<p id="p1.4" class="ltx_p"><em id="p1.4.1" class="ltx_emph ltx_font_bold ltx_font_italic">K</em><span id="p1.4.2" class="ltx_text ltx_font_bold">eywords</span>â€‚Knowledge Distillation Â <math id="p1.1.m1.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.1.m1.1a"><mo id="p1.1.m1.1.1" xref="p1.1.m1.1.1.cmml">â‹…</mo><annotation-xml encoding="MathML-Content" id="p1.1.m1.1b"><ci id="p1.1.m1.1.1.cmml" xref="p1.1.m1.1.1">â‹…</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.1.m1.1c">\cdot</annotation></semantics></math>
Federated Learning Â <math id="p1.2.m2.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.2.m2.1a"><mo id="p1.2.m2.1.1" xref="p1.2.m2.1.1.cmml">â‹…</mo><annotation-xml encoding="MathML-Content" id="p1.2.m2.1b"><ci id="p1.2.m2.1.1.cmml" xref="p1.2.m2.1.1">â‹…</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.2.m2.1c">\cdot</annotation></semantics></math>
Device Heterogeneity Â <math id="p1.3.m3.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.3.m3.1a"><mo id="p1.3.m3.1.1" xref="p1.3.m3.1.1.cmml">â‹…</mo><annotation-xml encoding="MathML-Content" id="p1.3.m3.1b"><ci id="p1.3.m3.1.1.cmml" xref="p1.3.m3.1.1">â‹…</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.3.m3.1c">\cdot</annotation></semantics></math>
Model Heterogeneity Â <math id="p1.4.m4.1" class="ltx_Math" alttext="\cdot" display="inline"><semantics id="p1.4.m4.1a"><mo id="p1.4.m4.1.1" xref="p1.4.m4.1.1.cmml">â‹…</mo><annotation-xml encoding="MathML-Content" id="p1.4.m4.1b"><ci id="p1.4.m4.1.1.cmml" xref="p1.4.m4.1.1">â‹…</ci></annotation-xml><annotation encoding="application/x-tex" id="p1.4.m4.1c">\cdot</annotation></semantics></math>
Data Heterogeneity</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para ltx_noindent">
<p id="S1.p1.1" class="ltx_p">Federated Learning (FL) has been proposed as an alternative to cloud-based Deep Learning (DL). This paradigm decouples the ability to train DL models from the need of harvesting raw data, alternating on-device computation and periodic communication <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. During the learning process, only ephemeral, locally processed payloads need to be disclosed by the participants in the federation, making it harder to infer private information about the individuals.</p>
</div>
<div id="S1.p2" class="ltx_para ltx_noindent">
<p id="S1.p2.1" class="ltx_p">Federated Averaging (FedAvg) represents the baseline algorithm for Federated Learning (FL) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>. In FedAvg, collaborative learning proceeds in synchronous rounds by leveraging a client-server paradigm. At the beginning of each round, the server (or aggregator) broadcasts the current parameters of the global model to a fraction of available clients (i.e., the participants). Each learner locally trains the received model parameters on its private data, and sends back an update to the server (e.g. the difference between the received and the locally tuned model parameters). The server collects the updates from the federation, and uses a given strategy (weighted average, according to the amount of local examples held by clients, in the case of FedAvg) to aggregate the gathered contributions. The aggregated updates are then applied to the global model as â€™pseudo-gradientâ€™ <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. At this point, a new round of FL can start by distributing the novel version of the global model.</p>
</div>
<div id="S1.p3" class="ltx_para ltx_noindent">
<p id="S1.p3.1" class="ltx_p">However, parameter-averaging aggregation schemes, such as FedAvg, have well-known limits. Firstly, this class of algorithms implies model homogeneity among the federation, i.e. each client is constrained to use the same neural architecture since the server directly merges clientsâ€™ updates (e.g., by weighted average). This may be an issue when the federation of learners is composed of clients with heterogeneous hardware capabilities. Furthermore, exchanging model parameters and model updates have high communication cost which scales with the number of model parameters â€“ even though a plethora of strategies (e.g., <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>) have been proposed to extremely improve the communication efficiency at the cost of global model performance. In addition, exchanging model parameters/updates exposes client to information leakage, and the server must know the architecture and structure of clientsâ€™ model to broadcast the global parameters, possibly incurring in intellectual property issues (i.e., clients in the federation are unwilling to share the architecture they are using). Lastly, but not less important, when clients hold heterogeneous data, local models tend to diverge from each other during training and fine tune on private examples (i.e., client drift). As a consequence, directly aggregating model parameters/updates degrades global model performances <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para ltx_noindent">
<p id="S1.p4.1" class="ltx_p">This article focuses on reviewing federated adaptations of regular Knowledge Distillation (KD) that have been employed to alleviate the above mentioned weaknesses of FL parameter-averaging aggregation schemes. Initially, KD-based strategies, also motivated by encouraging privacy properties <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, have been introduced to enable model heterogeneity and to reduce the communication cost of the process by exchanging model outputs and/or model-agnostic intermediate representations instead of directly transferring model parameters/model updates <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>.
Then, a set of strategies proposed to enhance the aggregation step of FedAvg with a server-side ensemble distillation phase to enable model heterogeneity and/or improve model fusion in presence of heterogeneous data <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>. Recently, two KD-based lines of work focused on mitigating the phenomenon of client model drift â€“ which makes averaging-based aggregations inefficient â€“ either using regularization terms in clientsâ€™ objective functions <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> or leveraging globally learned data-free generator <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para ltx_noindent">
<p id="S1.p5.1" class="ltx_p">In this article, we provide a review of the current literature about KD-based approach in FL, with the help of tabular comparisons, following an issue-solutions structure. A discussion on the weaknesses of distillation-based FL algorithms and our vision for future research directions close this manuscript.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Knowledge Distillation</h2>

<div id="S2.p1" class="ltx_para ltx_noindent">
<p id="S2.p1.13" class="ltx_p">Knowledge Distillation (KD) methods have been designed to transfer knowledge from a larger deep neural network, the <span id="S2.p1.13.1" class="ltx_text ltx_font_italic">teacher</span>, to a lightweight network, the <span id="S2.p1.13.2" class="ltx_text ltx_font_italic">student</span> <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. In the simplest form of KD, the student model learns by mimicking the (pre-trained) teacher modelâ€™s outputs on a proxy dataset, also called transfer set. If the transfer set is labeled, the student can be trained using a linear combination of two loss functions,</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.5" class="ltx_Math" alttext="\mathcal{L}=(1-\lambda)\mathcal{L}_{CE}(q^{S},y)+\lambda\mathcal{L}_{KL}(q^{S}_{\tau},q^{T}_{\tau})" display="block"><semantics id="S2.E1.m1.5a"><mrow id="S2.E1.m1.5.5" xref="S2.E1.m1.5.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.5.5.6" xref="S2.E1.m1.5.5.6.cmml">â„’</mi><mo id="S2.E1.m1.5.5.5" xref="S2.E1.m1.5.5.5.cmml">=</mo><mrow id="S2.E1.m1.5.5.4" xref="S2.E1.m1.5.5.4.cmml"><mrow id="S2.E1.m1.3.3.2.2" xref="S2.E1.m1.3.3.2.2.cmml"><mrow id="S2.E1.m1.2.2.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.2.2.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.cmml"><mn id="S2.E1.m1.2.2.1.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.1.2.cmml">1</mn><mo id="S2.E1.m1.2.2.1.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.1.cmml">âˆ’</mo><mi id="S2.E1.m1.2.2.1.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.1.3.cmml">Î»</mi></mrow><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.2.2.3" xref="S2.E1.m1.3.3.2.2.3.cmml">â€‹</mo><msub id="S2.E1.m1.3.3.2.2.4" xref="S2.E1.m1.3.3.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.3.3.2.2.4.2" xref="S2.E1.m1.3.3.2.2.4.2.cmml">â„’</mi><mrow id="S2.E1.m1.3.3.2.2.4.3" xref="S2.E1.m1.3.3.2.2.4.3.cmml"><mi id="S2.E1.m1.3.3.2.2.4.3.2" xref="S2.E1.m1.3.3.2.2.4.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.2.2.4.3.1" xref="S2.E1.m1.3.3.2.2.4.3.1.cmml">â€‹</mo><mi id="S2.E1.m1.3.3.2.2.4.3.3" xref="S2.E1.m1.3.3.2.2.4.3.3.cmml">E</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.3.3.2.2.3a" xref="S2.E1.m1.3.3.2.2.3.cmml">â€‹</mo><mrow id="S2.E1.m1.3.3.2.2.2.1" xref="S2.E1.m1.3.3.2.2.2.2.cmml"><mo stretchy="false" id="S2.E1.m1.3.3.2.2.2.1.2" xref="S2.E1.m1.3.3.2.2.2.2.cmml">(</mo><msup id="S2.E1.m1.3.3.2.2.2.1.1" xref="S2.E1.m1.3.3.2.2.2.1.1.cmml"><mi id="S2.E1.m1.3.3.2.2.2.1.1.2" xref="S2.E1.m1.3.3.2.2.2.1.1.2.cmml">q</mi><mi id="S2.E1.m1.3.3.2.2.2.1.1.3" xref="S2.E1.m1.3.3.2.2.2.1.1.3.cmml">S</mi></msup><mo id="S2.E1.m1.3.3.2.2.2.1.3" xref="S2.E1.m1.3.3.2.2.2.2.cmml">,</mo><mi id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">y</mi><mo stretchy="false" id="S2.E1.m1.3.3.2.2.2.1.4" xref="S2.E1.m1.3.3.2.2.2.2.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.5.5.4.5" xref="S2.E1.m1.5.5.4.5.cmml">+</mo><mrow id="S2.E1.m1.5.5.4.4" xref="S2.E1.m1.5.5.4.4.cmml"><mi id="S2.E1.m1.5.5.4.4.4" xref="S2.E1.m1.5.5.4.4.4.cmml">Î»</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.5.5.4.4.3" xref="S2.E1.m1.5.5.4.4.3.cmml">â€‹</mo><msub id="S2.E1.m1.5.5.4.4.5" xref="S2.E1.m1.5.5.4.4.5.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.5.5.4.4.5.2" xref="S2.E1.m1.5.5.4.4.5.2.cmml">â„’</mi><mrow id="S2.E1.m1.5.5.4.4.5.3" xref="S2.E1.m1.5.5.4.4.5.3.cmml"><mi id="S2.E1.m1.5.5.4.4.5.3.2" xref="S2.E1.m1.5.5.4.4.5.3.2.cmml">K</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.5.5.4.4.5.3.1" xref="S2.E1.m1.5.5.4.4.5.3.1.cmml">â€‹</mo><mi id="S2.E1.m1.5.5.4.4.5.3.3" xref="S2.E1.m1.5.5.4.4.5.3.3.cmml">L</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.5.5.4.4.3a" xref="S2.E1.m1.5.5.4.4.3.cmml">â€‹</mo><mrow id="S2.E1.m1.5.5.4.4.2.2" xref="S2.E1.m1.5.5.4.4.2.3.cmml"><mo stretchy="false" id="S2.E1.m1.5.5.4.4.2.2.3" xref="S2.E1.m1.5.5.4.4.2.3.cmml">(</mo><msubsup id="S2.E1.m1.4.4.3.3.1.1.1" xref="S2.E1.m1.4.4.3.3.1.1.1.cmml"><mi id="S2.E1.m1.4.4.3.3.1.1.1.2.2" xref="S2.E1.m1.4.4.3.3.1.1.1.2.2.cmml">q</mi><mi id="S2.E1.m1.4.4.3.3.1.1.1.3" xref="S2.E1.m1.4.4.3.3.1.1.1.3.cmml">Ï„</mi><mi id="S2.E1.m1.4.4.3.3.1.1.1.2.3" xref="S2.E1.m1.4.4.3.3.1.1.1.2.3.cmml">S</mi></msubsup><mo id="S2.E1.m1.5.5.4.4.2.2.4" xref="S2.E1.m1.5.5.4.4.2.3.cmml">,</mo><msubsup id="S2.E1.m1.5.5.4.4.2.2.2" xref="S2.E1.m1.5.5.4.4.2.2.2.cmml"><mi id="S2.E1.m1.5.5.4.4.2.2.2.2.2" xref="S2.E1.m1.5.5.4.4.2.2.2.2.2.cmml">q</mi><mi id="S2.E1.m1.5.5.4.4.2.2.2.3" xref="S2.E1.m1.5.5.4.4.2.2.2.3.cmml">Ï„</mi><mi id="S2.E1.m1.5.5.4.4.2.2.2.2.3" xref="S2.E1.m1.5.5.4.4.2.2.2.2.3.cmml">T</mi></msubsup><mo stretchy="false" id="S2.E1.m1.5.5.4.4.2.2.5" xref="S2.E1.m1.5.5.4.4.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.5b"><apply id="S2.E1.m1.5.5.cmml" xref="S2.E1.m1.5.5"><eq id="S2.E1.m1.5.5.5.cmml" xref="S2.E1.m1.5.5.5"></eq><ci id="S2.E1.m1.5.5.6.cmml" xref="S2.E1.m1.5.5.6">â„’</ci><apply id="S2.E1.m1.5.5.4.cmml" xref="S2.E1.m1.5.5.4"><plus id="S2.E1.m1.5.5.4.5.cmml" xref="S2.E1.m1.5.5.4.5"></plus><apply id="S2.E1.m1.3.3.2.2.cmml" xref="S2.E1.m1.3.3.2.2"><times id="S2.E1.m1.3.3.2.2.3.cmml" xref="S2.E1.m1.3.3.2.2.3"></times><apply id="S2.E1.m1.2.2.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1"><minus id="S2.E1.m1.2.2.1.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1"></minus><cn type="integer" id="S2.E1.m1.2.2.1.1.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.2">1</cn><ci id="S2.E1.m1.2.2.1.1.1.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.3">ğœ†</ci></apply><apply id="S2.E1.m1.3.3.2.2.4.cmml" xref="S2.E1.m1.3.3.2.2.4"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.2.2.4.1.cmml" xref="S2.E1.m1.3.3.2.2.4">subscript</csymbol><ci id="S2.E1.m1.3.3.2.2.4.2.cmml" xref="S2.E1.m1.3.3.2.2.4.2">â„’</ci><apply id="S2.E1.m1.3.3.2.2.4.3.cmml" xref="S2.E1.m1.3.3.2.2.4.3"><times id="S2.E1.m1.3.3.2.2.4.3.1.cmml" xref="S2.E1.m1.3.3.2.2.4.3.1"></times><ci id="S2.E1.m1.3.3.2.2.4.3.2.cmml" xref="S2.E1.m1.3.3.2.2.4.3.2">ğ¶</ci><ci id="S2.E1.m1.3.3.2.2.4.3.3.cmml" xref="S2.E1.m1.3.3.2.2.4.3.3">ğ¸</ci></apply></apply><interval closure="open" id="S2.E1.m1.3.3.2.2.2.2.cmml" xref="S2.E1.m1.3.3.2.2.2.1"><apply id="S2.E1.m1.3.3.2.2.2.1.1.cmml" xref="S2.E1.m1.3.3.2.2.2.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.3.3.2.2.2.1.1.1.cmml" xref="S2.E1.m1.3.3.2.2.2.1.1">superscript</csymbol><ci id="S2.E1.m1.3.3.2.2.2.1.1.2.cmml" xref="S2.E1.m1.3.3.2.2.2.1.1.2">ğ‘</ci><ci id="S2.E1.m1.3.3.2.2.2.1.1.3.cmml" xref="S2.E1.m1.3.3.2.2.2.1.1.3">ğ‘†</ci></apply><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">ğ‘¦</ci></interval></apply><apply id="S2.E1.m1.5.5.4.4.cmml" xref="S2.E1.m1.5.5.4.4"><times id="S2.E1.m1.5.5.4.4.3.cmml" xref="S2.E1.m1.5.5.4.4.3"></times><ci id="S2.E1.m1.5.5.4.4.4.cmml" xref="S2.E1.m1.5.5.4.4.4">ğœ†</ci><apply id="S2.E1.m1.5.5.4.4.5.cmml" xref="S2.E1.m1.5.5.4.4.5"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.4.4.5.1.cmml" xref="S2.E1.m1.5.5.4.4.5">subscript</csymbol><ci id="S2.E1.m1.5.5.4.4.5.2.cmml" xref="S2.E1.m1.5.5.4.4.5.2">â„’</ci><apply id="S2.E1.m1.5.5.4.4.5.3.cmml" xref="S2.E1.m1.5.5.4.4.5.3"><times id="S2.E1.m1.5.5.4.4.5.3.1.cmml" xref="S2.E1.m1.5.5.4.4.5.3.1"></times><ci id="S2.E1.m1.5.5.4.4.5.3.2.cmml" xref="S2.E1.m1.5.5.4.4.5.3.2">ğ¾</ci><ci id="S2.E1.m1.5.5.4.4.5.3.3.cmml" xref="S2.E1.m1.5.5.4.4.5.3.3">ğ¿</ci></apply></apply><interval closure="open" id="S2.E1.m1.5.5.4.4.2.3.cmml" xref="S2.E1.m1.5.5.4.4.2.2"><apply id="S2.E1.m1.4.4.3.3.1.1.1.cmml" xref="S2.E1.m1.4.4.3.3.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.3.3.1.1.1.1.cmml" xref="S2.E1.m1.4.4.3.3.1.1.1">subscript</csymbol><apply id="S2.E1.m1.4.4.3.3.1.1.1.2.cmml" xref="S2.E1.m1.4.4.3.3.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.4.4.3.3.1.1.1.2.1.cmml" xref="S2.E1.m1.4.4.3.3.1.1.1">superscript</csymbol><ci id="S2.E1.m1.4.4.3.3.1.1.1.2.2.cmml" xref="S2.E1.m1.4.4.3.3.1.1.1.2.2">ğ‘</ci><ci id="S2.E1.m1.4.4.3.3.1.1.1.2.3.cmml" xref="S2.E1.m1.4.4.3.3.1.1.1.2.3">ğ‘†</ci></apply><ci id="S2.E1.m1.4.4.3.3.1.1.1.3.cmml" xref="S2.E1.m1.4.4.3.3.1.1.1.3">ğœ</ci></apply><apply id="S2.E1.m1.5.5.4.4.2.2.2.cmml" xref="S2.E1.m1.5.5.4.4.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.4.4.2.2.2.1.cmml" xref="S2.E1.m1.5.5.4.4.2.2.2">subscript</csymbol><apply id="S2.E1.m1.5.5.4.4.2.2.2.2.cmml" xref="S2.E1.m1.5.5.4.4.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.5.5.4.4.2.2.2.2.1.cmml" xref="S2.E1.m1.5.5.4.4.2.2.2">superscript</csymbol><ci id="S2.E1.m1.5.5.4.4.2.2.2.2.2.cmml" xref="S2.E1.m1.5.5.4.4.2.2.2.2.2">ğ‘</ci><ci id="S2.E1.m1.5.5.4.4.2.2.2.2.3.cmml" xref="S2.E1.m1.5.5.4.4.2.2.2.2.3">ğ‘‡</ci></apply><ci id="S2.E1.m1.5.5.4.4.2.2.2.3.cmml" xref="S2.E1.m1.5.5.4.4.2.2.2.3">ğœ</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.5c">\mathcal{L}=(1-\lambda)\mathcal{L}_{CE}(q^{S},y)+\lambda\mathcal{L}_{KL}(q^{S}_{\tau},q^{T}_{\tau})</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.p1.12" class="ltx_p"><math id="S2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{CE}" display="inline"><semantics id="S2.p1.1.m1.1a"><msub id="S2.p1.1.m1.1.1" xref="S2.p1.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p1.1.m1.1.1.2" xref="S2.p1.1.m1.1.1.2.cmml">â„’</mi><mrow id="S2.p1.1.m1.1.1.3" xref="S2.p1.1.m1.1.1.3.cmml"><mi id="S2.p1.1.m1.1.1.3.2" xref="S2.p1.1.m1.1.1.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.p1.1.m1.1.1.3.1" xref="S2.p1.1.m1.1.1.3.1.cmml">â€‹</mo><mi id="S2.p1.1.m1.1.1.3.3" xref="S2.p1.1.m1.1.1.3.3.cmml">E</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.p1.1.m1.1b"><apply id="S2.p1.1.m1.1.1.cmml" xref="S2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.p1.1.m1.1.1.1.cmml" xref="S2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.p1.1.m1.1.1.2.cmml" xref="S2.p1.1.m1.1.1.2">â„’</ci><apply id="S2.p1.1.m1.1.1.3.cmml" xref="S2.p1.1.m1.1.1.3"><times id="S2.p1.1.m1.1.1.3.1.cmml" xref="S2.p1.1.m1.1.1.3.1"></times><ci id="S2.p1.1.m1.1.1.3.2.cmml" xref="S2.p1.1.m1.1.1.3.2">ğ¶</ci><ci id="S2.p1.1.m1.1.1.3.3.cmml" xref="S2.p1.1.m1.1.1.3.3">ğ¸</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.1.m1.1c">\mathcal{L}_{CE}</annotation></semantics></math> is the usual cross-entropy loss between the true label <math id="S2.p1.2.m2.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S2.p1.2.m2.1a"><mi id="S2.p1.2.m2.1.1" xref="S2.p1.2.m2.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.p1.2.m2.1b"><ci id="S2.p1.2.m2.1.1.cmml" xref="S2.p1.2.m2.1.1">ğ‘¦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.2.m2.1c">y</annotation></semantics></math> (e.g., hot encoded) and the class probabilities <math id="S2.p1.3.m3.1" class="ltx_Math" alttext="q" display="inline"><semantics id="S2.p1.3.m3.1a"><mi id="S2.p1.3.m3.1.1" xref="S2.p1.3.m3.1.1.cmml">q</mi><annotation-xml encoding="MathML-Content" id="S2.p1.3.m3.1b"><ci id="S2.p1.3.m3.1.1.cmml" xref="S2.p1.3.m3.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.3.m3.1c">q</annotation></semantics></math> (i.e., soft targets) predicted by the student neural network. <math id="S2.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{L}_{KL}" display="inline"><semantics id="S2.p1.4.m4.1a"><msub id="S2.p1.4.m4.1.1" xref="S2.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.p1.4.m4.1.1.2" xref="S2.p1.4.m4.1.1.2.cmml">â„’</mi><mrow id="S2.p1.4.m4.1.1.3" xref="S2.p1.4.m4.1.1.3.cmml"><mi id="S2.p1.4.m4.1.1.3.2" xref="S2.p1.4.m4.1.1.3.2.cmml">K</mi><mo lspace="0em" rspace="0em" id="S2.p1.4.m4.1.1.3.1" xref="S2.p1.4.m4.1.1.3.1.cmml">â€‹</mo><mi id="S2.p1.4.m4.1.1.3.3" xref="S2.p1.4.m4.1.1.3.3.cmml">L</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.p1.4.m4.1b"><apply id="S2.p1.4.m4.1.1.cmml" xref="S2.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.p1.4.m4.1.1.1.cmml" xref="S2.p1.4.m4.1.1">subscript</csymbol><ci id="S2.p1.4.m4.1.1.2.cmml" xref="S2.p1.4.m4.1.1.2">â„’</ci><apply id="S2.p1.4.m4.1.1.3.cmml" xref="S2.p1.4.m4.1.1.3"><times id="S2.p1.4.m4.1.1.3.1.cmml" xref="S2.p1.4.m4.1.1.3.1"></times><ci id="S2.p1.4.m4.1.1.3.2.cmml" xref="S2.p1.4.m4.1.1.3.2">ğ¾</ci><ci id="S2.p1.4.m4.1.1.3.3.cmml" xref="S2.p1.4.m4.1.1.3.3">ğ¿</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.4.m4.1c">\mathcal{L}_{KL}</annotation></semantics></math> is the Kullback-Leibler (KL) divergence between the student soft targets and the teacher soft targets. Soft targets are typically produced from logits <math id="S2.p1.5.m5.1" class="ltx_Math" alttext="z_{i}" display="inline"><semantics id="S2.p1.5.m5.1a"><msub id="S2.p1.5.m5.1.1" xref="S2.p1.5.m5.1.1.cmml"><mi id="S2.p1.5.m5.1.1.2" xref="S2.p1.5.m5.1.1.2.cmml">z</mi><mi id="S2.p1.5.m5.1.1.3" xref="S2.p1.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.5.m5.1b"><apply id="S2.p1.5.m5.1.1.cmml" xref="S2.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.p1.5.m5.1.1.1.cmml" xref="S2.p1.5.m5.1.1">subscript</csymbol><ci id="S2.p1.5.m5.1.1.2.cmml" xref="S2.p1.5.m5.1.1.2">ğ‘§</ci><ci id="S2.p1.5.m5.1.1.3.cmml" xref="S2.p1.5.m5.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.5.m5.1c">z_{i}</annotation></semantics></math>, where <math id="S2.p1.6.m6.1" class="ltx_Math" alttext="z_{i}" display="inline"><semantics id="S2.p1.6.m6.1a"><msub id="S2.p1.6.m6.1.1" xref="S2.p1.6.m6.1.1.cmml"><mi id="S2.p1.6.m6.1.1.2" xref="S2.p1.6.m6.1.1.2.cmml">z</mi><mi id="S2.p1.6.m6.1.1.3" xref="S2.p1.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p1.6.m6.1b"><apply id="S2.p1.6.m6.1.1.cmml" xref="S2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.p1.6.m6.1.1.1.cmml" xref="S2.p1.6.m6.1.1">subscript</csymbol><ci id="S2.p1.6.m6.1.1.2.cmml" xref="S2.p1.6.m6.1.1.2">ğ‘§</ci><ci id="S2.p1.6.m6.1.1.3.cmml" xref="S2.p1.6.m6.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.6.m6.1c">z_{i}</annotation></semantics></math> is the i-th value of logits vector <math id="S2.p1.7.m7.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S2.p1.7.m7.1a"><mi id="S2.p1.7.m7.1.1" xref="S2.p1.7.m7.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S2.p1.7.m7.1b"><ci id="S2.p1.7.m7.1.1.cmml" xref="S2.p1.7.m7.1.1">ğ‘§</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.7.m7.1c">z</annotation></semantics></math>, by a softmax output layer with <math id="S2.p1.8.m8.3" class="ltx_Math" alttext="q_{\tau}(i)=\frac{exp(z_{i}/\tau)}{\sum_{j}exp(z_{j}/\tau)}" display="inline"><semantics id="S2.p1.8.m8.3a"><mrow id="S2.p1.8.m8.3.4" xref="S2.p1.8.m8.3.4.cmml"><mrow id="S2.p1.8.m8.3.4.2" xref="S2.p1.8.m8.3.4.2.cmml"><msub id="S2.p1.8.m8.3.4.2.2" xref="S2.p1.8.m8.3.4.2.2.cmml"><mi id="S2.p1.8.m8.3.4.2.2.2" xref="S2.p1.8.m8.3.4.2.2.2.cmml">q</mi><mi id="S2.p1.8.m8.3.4.2.2.3" xref="S2.p1.8.m8.3.4.2.2.3.cmml">Ï„</mi></msub><mo lspace="0em" rspace="0em" id="S2.p1.8.m8.3.4.2.1" xref="S2.p1.8.m8.3.4.2.1.cmml">â€‹</mo><mrow id="S2.p1.8.m8.3.4.2.3.2" xref="S2.p1.8.m8.3.4.2.cmml"><mo stretchy="false" id="S2.p1.8.m8.3.4.2.3.2.1" xref="S2.p1.8.m8.3.4.2.cmml">(</mo><mi id="S2.p1.8.m8.3.3" xref="S2.p1.8.m8.3.3.cmml">i</mi><mo stretchy="false" id="S2.p1.8.m8.3.4.2.3.2.2" xref="S2.p1.8.m8.3.4.2.cmml">)</mo></mrow></mrow><mo id="S2.p1.8.m8.3.4.1" xref="S2.p1.8.m8.3.4.1.cmml">=</mo><mfrac id="S2.p1.8.m8.2.2" xref="S2.p1.8.m8.2.2.cmml"><mrow id="S2.p1.8.m8.1.1.1" xref="S2.p1.8.m8.1.1.1.cmml"><mi id="S2.p1.8.m8.1.1.1.3" xref="S2.p1.8.m8.1.1.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.p1.8.m8.1.1.1.2" xref="S2.p1.8.m8.1.1.1.2.cmml">â€‹</mo><mi id="S2.p1.8.m8.1.1.1.4" xref="S2.p1.8.m8.1.1.1.4.cmml">x</mi><mo lspace="0em" rspace="0em" id="S2.p1.8.m8.1.1.1.2a" xref="S2.p1.8.m8.1.1.1.2.cmml">â€‹</mo><mi id="S2.p1.8.m8.1.1.1.5" xref="S2.p1.8.m8.1.1.1.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.p1.8.m8.1.1.1.2b" xref="S2.p1.8.m8.1.1.1.2.cmml">â€‹</mo><mrow id="S2.p1.8.m8.1.1.1.1.1" xref="S2.p1.8.m8.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.p1.8.m8.1.1.1.1.1.2" xref="S2.p1.8.m8.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.p1.8.m8.1.1.1.1.1.1" xref="S2.p1.8.m8.1.1.1.1.1.1.cmml"><msub id="S2.p1.8.m8.1.1.1.1.1.1.2" xref="S2.p1.8.m8.1.1.1.1.1.1.2.cmml"><mi id="S2.p1.8.m8.1.1.1.1.1.1.2.2" xref="S2.p1.8.m8.1.1.1.1.1.1.2.2.cmml">z</mi><mi id="S2.p1.8.m8.1.1.1.1.1.1.2.3" xref="S2.p1.8.m8.1.1.1.1.1.1.2.3.cmml">i</mi></msub><mo id="S2.p1.8.m8.1.1.1.1.1.1.1" xref="S2.p1.8.m8.1.1.1.1.1.1.1.cmml">/</mo><mi id="S2.p1.8.m8.1.1.1.1.1.1.3" xref="S2.p1.8.m8.1.1.1.1.1.1.3.cmml">Ï„</mi></mrow><mo stretchy="false" id="S2.p1.8.m8.1.1.1.1.1.3" xref="S2.p1.8.m8.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mrow id="S2.p1.8.m8.2.2.2" xref="S2.p1.8.m8.2.2.2.cmml"><mstyle displaystyle="false" id="S2.p1.8.m8.2.2.2.2" xref="S2.p1.8.m8.2.2.2.2.cmml"><msub id="S2.p1.8.m8.2.2.2.2a" xref="S2.p1.8.m8.2.2.2.2.cmml"><mo id="S2.p1.8.m8.2.2.2.2.2" xref="S2.p1.8.m8.2.2.2.2.2.cmml">âˆ‘</mo><mi id="S2.p1.8.m8.2.2.2.2.3" xref="S2.p1.8.m8.2.2.2.2.3.cmml">j</mi></msub></mstyle><mrow id="S2.p1.8.m8.2.2.2.1" xref="S2.p1.8.m8.2.2.2.1.cmml"><mi id="S2.p1.8.m8.2.2.2.1.3" xref="S2.p1.8.m8.2.2.2.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.p1.8.m8.2.2.2.1.2" xref="S2.p1.8.m8.2.2.2.1.2.cmml">â€‹</mo><mi id="S2.p1.8.m8.2.2.2.1.4" xref="S2.p1.8.m8.2.2.2.1.4.cmml">x</mi><mo lspace="0em" rspace="0em" id="S2.p1.8.m8.2.2.2.1.2a" xref="S2.p1.8.m8.2.2.2.1.2.cmml">â€‹</mo><mi id="S2.p1.8.m8.2.2.2.1.5" xref="S2.p1.8.m8.2.2.2.1.5.cmml">p</mi><mo lspace="0em" rspace="0em" id="S2.p1.8.m8.2.2.2.1.2b" xref="S2.p1.8.m8.2.2.2.1.2.cmml">â€‹</mo><mrow id="S2.p1.8.m8.2.2.2.1.1.1" xref="S2.p1.8.m8.2.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S2.p1.8.m8.2.2.2.1.1.1.2" xref="S2.p1.8.m8.2.2.2.1.1.1.1.cmml">(</mo><mrow id="S2.p1.8.m8.2.2.2.1.1.1.1" xref="S2.p1.8.m8.2.2.2.1.1.1.1.cmml"><msub id="S2.p1.8.m8.2.2.2.1.1.1.1.2" xref="S2.p1.8.m8.2.2.2.1.1.1.1.2.cmml"><mi id="S2.p1.8.m8.2.2.2.1.1.1.1.2.2" xref="S2.p1.8.m8.2.2.2.1.1.1.1.2.2.cmml">z</mi><mi id="S2.p1.8.m8.2.2.2.1.1.1.1.2.3" xref="S2.p1.8.m8.2.2.2.1.1.1.1.2.3.cmml">j</mi></msub><mo id="S2.p1.8.m8.2.2.2.1.1.1.1.1" xref="S2.p1.8.m8.2.2.2.1.1.1.1.1.cmml">/</mo><mi id="S2.p1.8.m8.2.2.2.1.1.1.1.3" xref="S2.p1.8.m8.2.2.2.1.1.1.1.3.cmml">Ï„</mi></mrow><mo stretchy="false" id="S2.p1.8.m8.2.2.2.1.1.1.3" xref="S2.p1.8.m8.2.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S2.p1.8.m8.3b"><apply id="S2.p1.8.m8.3.4.cmml" xref="S2.p1.8.m8.3.4"><eq id="S2.p1.8.m8.3.4.1.cmml" xref="S2.p1.8.m8.3.4.1"></eq><apply id="S2.p1.8.m8.3.4.2.cmml" xref="S2.p1.8.m8.3.4.2"><times id="S2.p1.8.m8.3.4.2.1.cmml" xref="S2.p1.8.m8.3.4.2.1"></times><apply id="S2.p1.8.m8.3.4.2.2.cmml" xref="S2.p1.8.m8.3.4.2.2"><csymbol cd="ambiguous" id="S2.p1.8.m8.3.4.2.2.1.cmml" xref="S2.p1.8.m8.3.4.2.2">subscript</csymbol><ci id="S2.p1.8.m8.3.4.2.2.2.cmml" xref="S2.p1.8.m8.3.4.2.2.2">ğ‘</ci><ci id="S2.p1.8.m8.3.4.2.2.3.cmml" xref="S2.p1.8.m8.3.4.2.2.3">ğœ</ci></apply><ci id="S2.p1.8.m8.3.3.cmml" xref="S2.p1.8.m8.3.3">ğ‘–</ci></apply><apply id="S2.p1.8.m8.2.2.cmml" xref="S2.p1.8.m8.2.2"><divide id="S2.p1.8.m8.2.2.3.cmml" xref="S2.p1.8.m8.2.2"></divide><apply id="S2.p1.8.m8.1.1.1.cmml" xref="S2.p1.8.m8.1.1.1"><times id="S2.p1.8.m8.1.1.1.2.cmml" xref="S2.p1.8.m8.1.1.1.2"></times><ci id="S2.p1.8.m8.1.1.1.3.cmml" xref="S2.p1.8.m8.1.1.1.3">ğ‘’</ci><ci id="S2.p1.8.m8.1.1.1.4.cmml" xref="S2.p1.8.m8.1.1.1.4">ğ‘¥</ci><ci id="S2.p1.8.m8.1.1.1.5.cmml" xref="S2.p1.8.m8.1.1.1.5">ğ‘</ci><apply id="S2.p1.8.m8.1.1.1.1.1.1.cmml" xref="S2.p1.8.m8.1.1.1.1.1"><divide id="S2.p1.8.m8.1.1.1.1.1.1.1.cmml" xref="S2.p1.8.m8.1.1.1.1.1.1.1"></divide><apply id="S2.p1.8.m8.1.1.1.1.1.1.2.cmml" xref="S2.p1.8.m8.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.p1.8.m8.1.1.1.1.1.1.2.1.cmml" xref="S2.p1.8.m8.1.1.1.1.1.1.2">subscript</csymbol><ci id="S2.p1.8.m8.1.1.1.1.1.1.2.2.cmml" xref="S2.p1.8.m8.1.1.1.1.1.1.2.2">ğ‘§</ci><ci id="S2.p1.8.m8.1.1.1.1.1.1.2.3.cmml" xref="S2.p1.8.m8.1.1.1.1.1.1.2.3">ğ‘–</ci></apply><ci id="S2.p1.8.m8.1.1.1.1.1.1.3.cmml" xref="S2.p1.8.m8.1.1.1.1.1.1.3">ğœ</ci></apply></apply><apply id="S2.p1.8.m8.2.2.2.cmml" xref="S2.p1.8.m8.2.2.2"><apply id="S2.p1.8.m8.2.2.2.2.cmml" xref="S2.p1.8.m8.2.2.2.2"><csymbol cd="ambiguous" id="S2.p1.8.m8.2.2.2.2.1.cmml" xref="S2.p1.8.m8.2.2.2.2">subscript</csymbol><sum id="S2.p1.8.m8.2.2.2.2.2.cmml" xref="S2.p1.8.m8.2.2.2.2.2"></sum><ci id="S2.p1.8.m8.2.2.2.2.3.cmml" xref="S2.p1.8.m8.2.2.2.2.3">ğ‘—</ci></apply><apply id="S2.p1.8.m8.2.2.2.1.cmml" xref="S2.p1.8.m8.2.2.2.1"><times id="S2.p1.8.m8.2.2.2.1.2.cmml" xref="S2.p1.8.m8.2.2.2.1.2"></times><ci id="S2.p1.8.m8.2.2.2.1.3.cmml" xref="S2.p1.8.m8.2.2.2.1.3">ğ‘’</ci><ci id="S2.p1.8.m8.2.2.2.1.4.cmml" xref="S2.p1.8.m8.2.2.2.1.4">ğ‘¥</ci><ci id="S2.p1.8.m8.2.2.2.1.5.cmml" xref="S2.p1.8.m8.2.2.2.1.5">ğ‘</ci><apply id="S2.p1.8.m8.2.2.2.1.1.1.1.cmml" xref="S2.p1.8.m8.2.2.2.1.1.1"><divide id="S2.p1.8.m8.2.2.2.1.1.1.1.1.cmml" xref="S2.p1.8.m8.2.2.2.1.1.1.1.1"></divide><apply id="S2.p1.8.m8.2.2.2.1.1.1.1.2.cmml" xref="S2.p1.8.m8.2.2.2.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.p1.8.m8.2.2.2.1.1.1.1.2.1.cmml" xref="S2.p1.8.m8.2.2.2.1.1.1.1.2">subscript</csymbol><ci id="S2.p1.8.m8.2.2.2.1.1.1.1.2.2.cmml" xref="S2.p1.8.m8.2.2.2.1.1.1.1.2.2">ğ‘§</ci><ci id="S2.p1.8.m8.2.2.2.1.1.1.1.2.3.cmml" xref="S2.p1.8.m8.2.2.2.1.1.1.1.2.3">ğ‘—</ci></apply><ci id="S2.p1.8.m8.2.2.2.1.1.1.1.3.cmml" xref="S2.p1.8.m8.2.2.2.1.1.1.1.3">ğœ</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.8.m8.3c">q_{\tau}(i)=\frac{exp(z_{i}/\tau)}{\sum_{j}exp(z_{j}/\tau)}</annotation></semantics></math>. The temperature <math id="S2.p1.9.m9.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S2.p1.9.m9.1a"><mi id="S2.p1.9.m9.1.1" xref="S2.p1.9.m9.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S2.p1.9.m9.1b"><ci id="S2.p1.9.m9.1.1.cmml" xref="S2.p1.9.m9.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.9.m9.1c">\tau</annotation></semantics></math> controls the softness of the probability distribution. <math id="S2.p1.10.m10.1" class="ltx_Math" alttext="q^{S}" display="inline"><semantics id="S2.p1.10.m10.1a"><msup id="S2.p1.10.m10.1.1" xref="S2.p1.10.m10.1.1.cmml"><mi id="S2.p1.10.m10.1.1.2" xref="S2.p1.10.m10.1.1.2.cmml">q</mi><mi id="S2.p1.10.m10.1.1.3" xref="S2.p1.10.m10.1.1.3.cmml">S</mi></msup><annotation-xml encoding="MathML-Content" id="S2.p1.10.m10.1b"><apply id="S2.p1.10.m10.1.1.cmml" xref="S2.p1.10.m10.1.1"><csymbol cd="ambiguous" id="S2.p1.10.m10.1.1.1.cmml" xref="S2.p1.10.m10.1.1">superscript</csymbol><ci id="S2.p1.10.m10.1.1.2.cmml" xref="S2.p1.10.m10.1.1.2">ğ‘</ci><ci id="S2.p1.10.m10.1.1.3.cmml" xref="S2.p1.10.m10.1.1.3">ğ‘†</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.10.m10.1c">q^{S}</annotation></semantics></math> is computed with <math id="S2.p1.11.m11.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S2.p1.11.m11.1a"><mi id="S2.p1.11.m11.1.1" xref="S2.p1.11.m11.1.1.cmml">Ï„</mi><annotation-xml encoding="MathML-Content" id="S2.p1.11.m11.1b"><ci id="S2.p1.11.m11.1.1.cmml" xref="S2.p1.11.m11.1.1">ğœ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.11.m11.1c">\tau</annotation></semantics></math> set to 1. <math id="S2.p1.12.m12.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S2.p1.12.m12.1a"><mi id="S2.p1.12.m12.1.1" xref="S2.p1.12.m12.1.1.cmml">Î»</mi><annotation-xml encoding="MathML-Content" id="S2.p1.12.m12.1b"><ci id="S2.p1.12.m12.1.1.cmml" xref="S2.p1.12.m12.1.1">ğœ†</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p1.12.m12.1c">\lambda</annotation></semantics></math> weights the impact of the two loss terms.
We refer to <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> for taxonomy and recent progress in the KD area.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Knowledge Distillation for Federated Learning</h2>

<div id="S3.p1" class="ltx_para ltx_noindent">
<p id="S3.p1.1" class="ltx_p">During recent years, KD has been increasingly employed in FL algorithms. In this review article, we make a primary distinction according to the purpose KD is used for, identifying two main lines of work: (1) FL algorithms that use KD to enable model heterogeneity; (2) FL algorithms that use KD to mitigate the impact of data heterogeneity on global model performance. Then, we further structure the review according to how these purposes are achieved. For model-agnostic FL, we distinguish among (a) solutions that leverage server-side ensemble distillation on top of FedAvgâ€™s aggregation phase and (b) communication-efficient strategies that enable model heterogeneity via exchanging locally-computed statistics, model outputs and/or model-agnostic intermediate features instead of model parameters. In regard of strategies to mitigate the degradation introduced by non-IIDness, we differentiate (a) server-side strategies that refine FedAvgâ€™s aggregation with a distillation phase and (b) client-side techniques that locally distill global knowledge to directly tackle client drift. If not differently specified in the text, the reviewed solutions adopt a server-client paradigm â€“ the majority in literature â€“ and implement synchronous protocols, which proceed in rounds.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Model-agnostic FL via KD</h3>

<div id="S3.SS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.p1.1" class="ltx_p">FedAvgâ€™s protocol can be enhanced to enable model heterogeneity by leveraging server-side ensemble distillation on top of the aggregation step <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>. To this end, the server can maintain a set of prototypical models, with each prototype representing all learners with same architecture. After collecting updates from clients, the server firstly performs a per-prototype aggregation and then produces soft targets for each received client model either leveraging unlabeled data or synthetically generated examples. Next, such soft targets are averaged and used to fine tune each aggregated model prototype, exchanging knowledge among clients with different model architecture.
Alternative possible solutions to enable model heterogeneity consist in exploiting distributed adaptations of co-distillation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> instead of parameter-averaging algorithms such as FedAvg, as presented in the following.</p>
</div>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Distributed adaptations of co-distillation</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.SSS1.p1.2" class="ltx_p">The strategies reviewed here can be seen as distributed adaptations of co-distillation (CD) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>, an instance of online KD <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. In CD, students and teacher learn simultaneously, and the teacher knowledge is formed by an ensemble of multiple modelsâ€™ output. In a general federated adaptation of CD, each client at round <math id="S3.SS1.SSS1.p1.1.m1.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS1.SSS1.p1.1.m1.1a"><mi id="S3.SS1.SSS1.p1.1.m1.1.1" xref="S3.SS1.SSS1.p1.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.1.m1.1b"><ci id="S3.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.1.m1.1c">t</annotation></semantics></math> acts as student and sees the ensemble of clients knowledge at round <math id="S3.SS1.SSS1.p1.2.m2.1" class="ltx_Math" alttext="t-1" display="inline"><semantics id="S3.SS1.SSS1.p1.2.m2.1a"><mrow id="S3.SS1.SSS1.p1.2.m2.1.1" xref="S3.SS1.SSS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.SSS1.p1.2.m2.1.1.2" xref="S3.SS1.SSS1.p1.2.m2.1.1.2.cmml">t</mi><mo id="S3.SS1.SSS1.p1.2.m2.1.1.1" xref="S3.SS1.SSS1.p1.2.m2.1.1.1.cmml">âˆ’</mo><mn id="S3.SS1.SSS1.p1.2.m2.1.1.3" xref="S3.SS1.SSS1.p1.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.2.m2.1b"><apply id="S3.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1"><minus id="S3.SS1.SSS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.1"></minus><ci id="S3.SS1.SSS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.2">ğ‘¡</ci><cn type="integer" id="S3.SS1.SSS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.2.m2.1c">t-1</annotation></semantics></math> as the teacher knowledge. The shared knowledge can be of different types, as in regular KD, and can be represented by an ensemble of aggregated statistics of model outputs on local data, by an ensemble of local model outputs computed on a publicly available dataset, or by an ensemble of both model outputs and of model-agnostic intermediate features. It is worth noting that clients and server exchange these kinds of information instead of model parameters. Table <a href="#S3.T1" title="Table 1 â€£ Leveraging intermediate features. â€£ 3.1.1 Distributed adaptations of co-distillation â€£ 3.1 Model-agnostic FL via KD â€£ 3 Knowledge Distillation for Federated Learning â€£ Knowledge Distillation for Federated Learning: a Practical Guide" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> sums up the comparison among FL adaptations of co-distillation.</p>
</div>
<section id="S3.SS1.SSS1.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Disclosing aggregated statistics of model outputs on local data.</h5>

<div id="S3.SS1.SSS1.Px1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.SSS1.Px1.p1.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> Jeong et al. presented a pioneering distillation-based baseline for FL, FedDistill. Participants periodically transmit only per-label mean soft targets computed on their private dataset. The server, in turn, averages such tensors and produces per-label global soft targets to be broadcast the next round. When locally training, clients regularize their local loss with a per-label distillation term which uses the received global soft targets as the teacherâ€™s output. A similar strategy is later presented in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>. It is worth noting that FedDistill is extremely communication efficient with respect to parameter-based schemes.</p>
</div>
</section>
<section id="S3.SS1.SSS1.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Exchanging model responses on proxy data.</h5>

<div id="S3.SS1.SSS1.Px2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.SSS1.Px2.p1.1" class="ltx_p">Here, the approaches in literature are more variegated, but a general skeleton of algorithmic steps can be the following: (i) <span id="S3.SS1.SSS1.Px2.p1.1.1" class="ltx_text ltx_font_italic">broadcast</span>: clients receive the current global logits/soft targets; (ii) <span id="S3.SS1.SSS1.Px2.p1.1.2" class="ltx_text ltx_font_italic">local distillation</span>: clients distill their local model by mimicking the received global logits/soft-labels on a subset of the proxy dataset; (iii) <span id="S3.SS1.SSS1.Px2.p1.1.3" class="ltx_text ltx_font_italic">local training</span>: clients fine-tune the distilled model on local data; (iv) <span id="S3.SS1.SSS1.Px2.p1.1.4" class="ltx_text ltx_font_italic">local prediction</span>: clients compute their local logits/soft targets on the proxy dataset; (v) <span id="S3.SS1.SSS1.Px2.p1.1.5" class="ltx_text ltx_font_italic">aggregation</span>: the server collects the logits/soft targets and aggregates them to produce the updated global logits/soft targets. Next, a new round begins.
<br class="ltx_break">While a subset of solutions use the server entity just as aggregator for locally-computed model outputs <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, more recent strategies add a (vi) <span id="S3.SS1.SSS1.Px2.p1.1.6" class="ltx_text ltx_font_italic">server distillation</span> step to distill a server-side model, which can be used to produce the global logits/soft targets to broadcast <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. Learning a server-side model can improve the training process when there is partial participation of clients <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>.
Also, considering either a labeled or unlabeled proxy dataset influences the design of algorithms. FedMD <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> uses a proxy labeled dataset to perform an initial pretraining phase on clients, before the protocol starts.
<cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib20" title="" class="ltx_ref">Itahara etÂ al.</a></cite> modify the <span id="S3.SS1.SSS1.Px2.p1.1.7" class="ltx_text ltx_font_italic">aggregation</span> step proposing an Entropy Reduction Aggregation (ERA), demonstrating that using a temperature lower than 1 when applying softmax to the aggregated logits reduces the entropy of global soft targets, and can help the training process, especially in non-IID settings <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>.
Compressed Federated Distillation (CFD) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> implements an extreme and effective compression technique for soft targets based on quantization and delta coding, which is applied both by clients and server before communicating.
Cronus <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> merges the <span id="S3.SS1.SSS1.Px2.p1.1.8" class="ltx_text ltx_font_italic">local disitllation</span> and <span id="S3.SS1.SSS1.Px2.p1.1.9" class="ltx_text ltx_font_italic">local training</span> step by directly training on the union (i.e., concatenation) of the private dataset and the soft-labeled public one. In addition, Cronus aggregates (<span id="S3.SS1.SSS1.Px2.p1.1.10" class="ltx_text ltx_font_italic">aggregation</span> step) soft targets following the approach of Diakonikolas et al. <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> for enhanced robustness. Similarly to Cronus, in MATH <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> clients jointly train on private dataset, public dataset, and public dataset tagged with global soft targets. MATH <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> considers a labeled proxy dataset, and distills its server model by training it on the union of such a public dataset with the soft-labeled version of it.
FedGEM <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> adopts a protocol that matches FedMD, additionally enhancing it with a server model similarly to CFD. The intuition of FedGEM is to take advantage of a powerful model server. FedGEMS, a variation of FedGEM, exploits the labels in the public transfer set to enforce a selection and weighting strategy which can improve the knowledge transfer <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS1.SSS1.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Leveraging intermediate features.</h5>

<div id="S3.SS1.SSS1.Px3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS1.SSS1.Px3.p1.1" class="ltx_p">FedAD <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> also uses intermediate features besides model output to extend response-based knowledge distillation. The intermediate features are model-agnostic attention maps <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>, which still enable model heterogeneity as long as there is consensus on attention map shape. FedAD is a one-shot federated learning framework, which means that clients do not have to distill their local model at the beginning of each round, and can participate asynchronously. FedGKT <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> uses intermediate features under an asynchronous split learning paradigm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>. Edge devices train small networks composed of a feature extractor, which produces intermediate feature maps, and a classifier, which produces soft targets. Similarly, the server leverages a deeper network and a classifier. After local training, for each local examples, clients communicate their computed intermediate features, the predicted soft targets and the related ground truth labels. The server takes locally-computed extracted features as input for its deeper network and produces global soft targets. Both clients and server use a linear combination of regular cross-entropy loss and KD-based loss as objective function. The first considers soft targets and ground truth labels, the latter measures the discrepancy among local and global logits. A similar framework is implemented in FedDKC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> on top of which <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib48" title="" class="ltx_ref">Wu etÂ al.</a></cite> also develop server-side knowledge refinement strategies.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Comparison among strategies to enable model heterogeneity via FL adaptations of co-distillation. <math id="S3.T1.4.4.m1.1" class="ltx_Math" alttext="D_{k}" display="inline"><semantics id="S3.T1.4.4.m1.1b"><msub id="S3.T1.4.4.m1.1.1" xref="S3.T1.4.4.m1.1.1.cmml"><mi id="S3.T1.4.4.m1.1.1.2" xref="S3.T1.4.4.m1.1.1.2.cmml">D</mi><mi id="S3.T1.4.4.m1.1.1.3" xref="S3.T1.4.4.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T1.4.4.m1.1c"><apply id="S3.T1.4.4.m1.1.1.cmml" xref="S3.T1.4.4.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.4.4.m1.1.1.1.cmml" xref="S3.T1.4.4.m1.1.1">subscript</csymbol><ci id="S3.T1.4.4.m1.1.1.2.cmml" xref="S3.T1.4.4.m1.1.1.2">ğ·</ci><ci id="S3.T1.4.4.m1.1.1.3.cmml" xref="S3.T1.4.4.m1.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.4.4.m1.1d">D_{k}</annotation></semantics></math> represents the local private dataset of a generic client. <math id="S3.T1.5.5.m2.1" class="ltx_Math" alttext="D_{p}" display="inline"><semantics id="S3.T1.5.5.m2.1b"><msub id="S3.T1.5.5.m2.1.1" xref="S3.T1.5.5.m2.1.1.cmml"><mi id="S3.T1.5.5.m2.1.1.2" xref="S3.T1.5.5.m2.1.1.2.cmml">D</mi><mi id="S3.T1.5.5.m2.1.1.3" xref="S3.T1.5.5.m2.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T1.5.5.m2.1c"><apply id="S3.T1.5.5.m2.1.1.cmml" xref="S3.T1.5.5.m2.1.1"><csymbol cd="ambiguous" id="S3.T1.5.5.m2.1.1.1.cmml" xref="S3.T1.5.5.m2.1.1">subscript</csymbol><ci id="S3.T1.5.5.m2.1.1.2.cmml" xref="S3.T1.5.5.m2.1.1.2">ğ·</ci><ci id="S3.T1.5.5.m2.1.1.3.cmml" xref="S3.T1.5.5.m2.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.5.5.m2.1d">D_{p}</annotation></semantics></math> represents a public transfer set. (<math id="S3.T1.6.6.m3.2" class="ltx_Math" alttext="X_{p},\tilde{Y_{p}}" display="inline"><semantics id="S3.T1.6.6.m3.2b"><mrow id="S3.T1.6.6.m3.2.2.1" xref="S3.T1.6.6.m3.2.2.2.cmml"><msub id="S3.T1.6.6.m3.2.2.1.1" xref="S3.T1.6.6.m3.2.2.1.1.cmml"><mi id="S3.T1.6.6.m3.2.2.1.1.2" xref="S3.T1.6.6.m3.2.2.1.1.2.cmml">X</mi><mi id="S3.T1.6.6.m3.2.2.1.1.3" xref="S3.T1.6.6.m3.2.2.1.1.3.cmml">p</mi></msub><mo id="S3.T1.6.6.m3.2.2.1.2" xref="S3.T1.6.6.m3.2.2.2.cmml">,</mo><mover accent="true" id="S3.T1.6.6.m3.1.1" xref="S3.T1.6.6.m3.1.1.cmml"><msub id="S3.T1.6.6.m3.1.1.2" xref="S3.T1.6.6.m3.1.1.2.cmml"><mi id="S3.T1.6.6.m3.1.1.2.2" xref="S3.T1.6.6.m3.1.1.2.2.cmml">Y</mi><mi id="S3.T1.6.6.m3.1.1.2.3" xref="S3.T1.6.6.m3.1.1.2.3.cmml">p</mi></msub><mo id="S3.T1.6.6.m3.1.1.1" xref="S3.T1.6.6.m3.1.1.1.cmml">~</mo></mover></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.6.6.m3.2c"><list id="S3.T1.6.6.m3.2.2.2.cmml" xref="S3.T1.6.6.m3.2.2.1"><apply id="S3.T1.6.6.m3.2.2.1.1.cmml" xref="S3.T1.6.6.m3.2.2.1.1"><csymbol cd="ambiguous" id="S3.T1.6.6.m3.2.2.1.1.1.cmml" xref="S3.T1.6.6.m3.2.2.1.1">subscript</csymbol><ci id="S3.T1.6.6.m3.2.2.1.1.2.cmml" xref="S3.T1.6.6.m3.2.2.1.1.2">ğ‘‹</ci><ci id="S3.T1.6.6.m3.2.2.1.1.3.cmml" xref="S3.T1.6.6.m3.2.2.1.1.3">ğ‘</ci></apply><apply id="S3.T1.6.6.m3.1.1.cmml" xref="S3.T1.6.6.m3.1.1"><ci id="S3.T1.6.6.m3.1.1.1.cmml" xref="S3.T1.6.6.m3.1.1.1">~</ci><apply id="S3.T1.6.6.m3.1.1.2.cmml" xref="S3.T1.6.6.m3.1.1.2"><csymbol cd="ambiguous" id="S3.T1.6.6.m3.1.1.2.1.cmml" xref="S3.T1.6.6.m3.1.1.2">subscript</csymbol><ci id="S3.T1.6.6.m3.1.1.2.2.cmml" xref="S3.T1.6.6.m3.1.1.2.2">ğ‘Œ</ci><ci id="S3.T1.6.6.m3.1.1.2.3.cmml" xref="S3.T1.6.6.m3.1.1.2.3">ğ‘</ci></apply></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.6.6.m3.2d">X_{p},\tilde{Y_{p}}</annotation></semantics></math>) is the public soft-labeled dataset. Knowledge column is inspired by the classification in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>; response-based methods communicate model outputs, feature-based also share intermediate representations, statistics-based disclose aggregated statistics (e.g., per-label mean logit vector) of client model outputs on local data. </figcaption>
<table id="S3.T1.9.9" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S3.T1.9.9.4.1" class="ltx_tr">
<td id="S3.T1.9.9.4.1.1" class="ltx_td ltx_border_tt"></td>
<th id="S3.T1.9.9.4.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Knowledge</th>
<th id="S3.T1.9.9.4.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Transfer Set</th>
<th id="S3.T1.9.9.4.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Server Model</th>
<th id="S3.T1.9.9.4.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Notes</th>
</tr>
<tr id="S3.T1.9.9.5.2" class="ltx_tr">
<td id="S3.T1.9.9.5.2.1" class="ltx_td ltx_align_center ltx_border_tt">FedDistill <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>
</td>
<td id="S3.T1.9.9.5.2.2" class="ltx_td ltx_align_center ltx_border_tt">statistics</td>
<td id="S3.T1.9.9.5.2.3" class="ltx_td ltx_align_center ltx_border_tt">data-free</td>
<td id="S3.T1.9.9.5.2.4" class="ltx_td ltx_align_center ltx_border_tt">no</td>
<td id="S3.T1.9.9.5.2.5" class="ltx_td ltx_align_center ltx_border_tt">KD-based regularizer</td>
</tr>
<tr id="S3.T1.7.7.1" class="ltx_tr">
<td id="S3.T1.7.7.1.2" class="ltx_td ltx_align_center">FedMD <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>
</td>
<td id="S3.T1.7.7.1.3" class="ltx_td ltx_align_center">response</td>
<td id="S3.T1.7.7.1.4" class="ltx_td ltx_align_center">labeled</td>
<td id="S3.T1.7.7.1.5" class="ltx_td ltx_align_center">no</td>
<td id="S3.T1.7.7.1.1" class="ltx_td ltx_align_center">Pre-training on <math id="S3.T1.7.7.1.1.m1.1" class="ltx_Math" alttext="D_{p}" display="inline"><semantics id="S3.T1.7.7.1.1.m1.1a"><msub id="S3.T1.7.7.1.1.m1.1.1" xref="S3.T1.7.7.1.1.m1.1.1.cmml"><mi id="S3.T1.7.7.1.1.m1.1.1.2" xref="S3.T1.7.7.1.1.m1.1.1.2.cmml">D</mi><mi id="S3.T1.7.7.1.1.m1.1.1.3" xref="S3.T1.7.7.1.1.m1.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.T1.7.7.1.1.m1.1b"><apply id="S3.T1.7.7.1.1.m1.1.1.cmml" xref="S3.T1.7.7.1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.T1.7.7.1.1.m1.1.1.1.cmml" xref="S3.T1.7.7.1.1.m1.1.1">subscript</csymbol><ci id="S3.T1.7.7.1.1.m1.1.1.2.cmml" xref="S3.T1.7.7.1.1.m1.1.1.2">ğ·</ci><ci id="S3.T1.7.7.1.1.m1.1.1.3.cmml" xref="S3.T1.7.7.1.1.m1.1.1.3">ğ‘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.7.7.1.1.m1.1c">D_{p}</annotation></semantics></math>
</td>
</tr>
<tr id="S3.T1.8.8.2" class="ltx_tr">
<td id="S3.T1.8.8.2.2" class="ltx_td ltx_align_center">Cronus <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>
</td>
<td id="S3.T1.8.8.2.3" class="ltx_td ltx_align_center">response</td>
<td id="S3.T1.8.8.2.4" class="ltx_td ltx_align_center">unlabeled</td>
<td id="S3.T1.8.8.2.5" class="ltx_td ltx_align_center">no</td>
<td id="S3.T1.8.8.2.1" class="ltx_td ltx_align_center">Local training on <math id="S3.T1.8.8.2.1.m1.2" class="ltx_Math" alttext="(X_{p},\tilde{Y_{p}})\cup D_{k}" display="inline"><semantics id="S3.T1.8.8.2.1.m1.2a"><mrow id="S3.T1.8.8.2.1.m1.2.2" xref="S3.T1.8.8.2.1.m1.2.2.cmml"><mrow id="S3.T1.8.8.2.1.m1.2.2.1.1" xref="S3.T1.8.8.2.1.m1.2.2.1.2.cmml"><mo stretchy="false" id="S3.T1.8.8.2.1.m1.2.2.1.1.2" xref="S3.T1.8.8.2.1.m1.2.2.1.2.cmml">(</mo><msub id="S3.T1.8.8.2.1.m1.2.2.1.1.1" xref="S3.T1.8.8.2.1.m1.2.2.1.1.1.cmml"><mi id="S3.T1.8.8.2.1.m1.2.2.1.1.1.2" xref="S3.T1.8.8.2.1.m1.2.2.1.1.1.2.cmml">X</mi><mi id="S3.T1.8.8.2.1.m1.2.2.1.1.1.3" xref="S3.T1.8.8.2.1.m1.2.2.1.1.1.3.cmml">p</mi></msub><mo id="S3.T1.8.8.2.1.m1.2.2.1.1.3" xref="S3.T1.8.8.2.1.m1.2.2.1.2.cmml">,</mo><mover accent="true" id="S3.T1.8.8.2.1.m1.1.1" xref="S3.T1.8.8.2.1.m1.1.1.cmml"><msub id="S3.T1.8.8.2.1.m1.1.1.2" xref="S3.T1.8.8.2.1.m1.1.1.2.cmml"><mi id="S3.T1.8.8.2.1.m1.1.1.2.2" xref="S3.T1.8.8.2.1.m1.1.1.2.2.cmml">Y</mi><mi id="S3.T1.8.8.2.1.m1.1.1.2.3" xref="S3.T1.8.8.2.1.m1.1.1.2.3.cmml">p</mi></msub><mo id="S3.T1.8.8.2.1.m1.1.1.1" xref="S3.T1.8.8.2.1.m1.1.1.1.cmml">~</mo></mover><mo stretchy="false" id="S3.T1.8.8.2.1.m1.2.2.1.1.4" xref="S3.T1.8.8.2.1.m1.2.2.1.2.cmml">)</mo></mrow><mo id="S3.T1.8.8.2.1.m1.2.2.2" xref="S3.T1.8.8.2.1.m1.2.2.2.cmml">âˆª</mo><msub id="S3.T1.8.8.2.1.m1.2.2.3" xref="S3.T1.8.8.2.1.m1.2.2.3.cmml"><mi id="S3.T1.8.8.2.1.m1.2.2.3.2" xref="S3.T1.8.8.2.1.m1.2.2.3.2.cmml">D</mi><mi id="S3.T1.8.8.2.1.m1.2.2.3.3" xref="S3.T1.8.8.2.1.m1.2.2.3.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.8.8.2.1.m1.2b"><apply id="S3.T1.8.8.2.1.m1.2.2.cmml" xref="S3.T1.8.8.2.1.m1.2.2"><union id="S3.T1.8.8.2.1.m1.2.2.2.cmml" xref="S3.T1.8.8.2.1.m1.2.2.2"></union><interval closure="open" id="S3.T1.8.8.2.1.m1.2.2.1.2.cmml" xref="S3.T1.8.8.2.1.m1.2.2.1.1"><apply id="S3.T1.8.8.2.1.m1.2.2.1.1.1.cmml" xref="S3.T1.8.8.2.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.T1.8.8.2.1.m1.2.2.1.1.1.1.cmml" xref="S3.T1.8.8.2.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.T1.8.8.2.1.m1.2.2.1.1.1.2.cmml" xref="S3.T1.8.8.2.1.m1.2.2.1.1.1.2">ğ‘‹</ci><ci id="S3.T1.8.8.2.1.m1.2.2.1.1.1.3.cmml" xref="S3.T1.8.8.2.1.m1.2.2.1.1.1.3">ğ‘</ci></apply><apply id="S3.T1.8.8.2.1.m1.1.1.cmml" xref="S3.T1.8.8.2.1.m1.1.1"><ci id="S3.T1.8.8.2.1.m1.1.1.1.cmml" xref="S3.T1.8.8.2.1.m1.1.1.1">~</ci><apply id="S3.T1.8.8.2.1.m1.1.1.2.cmml" xref="S3.T1.8.8.2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.T1.8.8.2.1.m1.1.1.2.1.cmml" xref="S3.T1.8.8.2.1.m1.1.1.2">subscript</csymbol><ci id="S3.T1.8.8.2.1.m1.1.1.2.2.cmml" xref="S3.T1.8.8.2.1.m1.1.1.2.2">ğ‘Œ</ci><ci id="S3.T1.8.8.2.1.m1.1.1.2.3.cmml" xref="S3.T1.8.8.2.1.m1.1.1.2.3">ğ‘</ci></apply></apply></interval><apply id="S3.T1.8.8.2.1.m1.2.2.3.cmml" xref="S3.T1.8.8.2.1.m1.2.2.3"><csymbol cd="ambiguous" id="S3.T1.8.8.2.1.m1.2.2.3.1.cmml" xref="S3.T1.8.8.2.1.m1.2.2.3">subscript</csymbol><ci id="S3.T1.8.8.2.1.m1.2.2.3.2.cmml" xref="S3.T1.8.8.2.1.m1.2.2.3.2">ğ·</ci><ci id="S3.T1.8.8.2.1.m1.2.2.3.3.cmml" xref="S3.T1.8.8.2.1.m1.2.2.3.3">ğ‘˜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.8.8.2.1.m1.2c">(X_{p},\tilde{Y_{p}})\cup D_{k}</annotation></semantics></math>
</td>
</tr>
<tr id="S3.T1.9.9.6.3" class="ltx_tr">
<td id="S3.T1.9.9.6.3.1" class="ltx_td ltx_align_center">DS-FL<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>
</td>
<td id="S3.T1.9.9.6.3.2" class="ltx_td ltx_align_center">response</td>
<td id="S3.T1.9.9.6.3.3" class="ltx_td ltx_align_center">unlabeled</td>
<td id="S3.T1.9.9.6.3.4" class="ltx_td ltx_align_center">no</td>
<td id="S3.T1.9.9.6.3.5" class="ltx_td ltx_align_center">Entropy Reduction Aggregation</td>
</tr>
<tr id="S3.T1.9.9.3" class="ltx_tr">
<td id="S3.T1.9.9.3.2" class="ltx_td ltx_align_center">MATH <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>
</td>
<td id="S3.T1.9.9.3.3" class="ltx_td ltx_align_center">response</td>
<td id="S3.T1.9.9.3.4" class="ltx_td ltx_align_center">labeled</td>
<td id="S3.T1.9.9.3.5" class="ltx_td ltx_align_center">yes</td>
<td id="S3.T1.9.9.3.1" class="ltx_td ltx_align_center">Server training on <math id="S3.T1.9.9.3.1.m1.2" class="ltx_Math" alttext="(X_{p},\tilde{Y_{p}})\cup D_{p}" display="inline"><semantics id="S3.T1.9.9.3.1.m1.2a"><mrow id="S3.T1.9.9.3.1.m1.2.2" xref="S3.T1.9.9.3.1.m1.2.2.cmml"><mrow id="S3.T1.9.9.3.1.m1.2.2.1.1" xref="S3.T1.9.9.3.1.m1.2.2.1.2.cmml"><mo stretchy="false" id="S3.T1.9.9.3.1.m1.2.2.1.1.2" xref="S3.T1.9.9.3.1.m1.2.2.1.2.cmml">(</mo><msub id="S3.T1.9.9.3.1.m1.2.2.1.1.1" xref="S3.T1.9.9.3.1.m1.2.2.1.1.1.cmml"><mi id="S3.T1.9.9.3.1.m1.2.2.1.1.1.2" xref="S3.T1.9.9.3.1.m1.2.2.1.1.1.2.cmml">X</mi><mi id="S3.T1.9.9.3.1.m1.2.2.1.1.1.3" xref="S3.T1.9.9.3.1.m1.2.2.1.1.1.3.cmml">p</mi></msub><mo id="S3.T1.9.9.3.1.m1.2.2.1.1.3" xref="S3.T1.9.9.3.1.m1.2.2.1.2.cmml">,</mo><mover accent="true" id="S3.T1.9.9.3.1.m1.1.1" xref="S3.T1.9.9.3.1.m1.1.1.cmml"><msub id="S3.T1.9.9.3.1.m1.1.1.2" xref="S3.T1.9.9.3.1.m1.1.1.2.cmml"><mi id="S3.T1.9.9.3.1.m1.1.1.2.2" xref="S3.T1.9.9.3.1.m1.1.1.2.2.cmml">Y</mi><mi id="S3.T1.9.9.3.1.m1.1.1.2.3" xref="S3.T1.9.9.3.1.m1.1.1.2.3.cmml">p</mi></msub><mo id="S3.T1.9.9.3.1.m1.1.1.1" xref="S3.T1.9.9.3.1.m1.1.1.1.cmml">~</mo></mover><mo stretchy="false" id="S3.T1.9.9.3.1.m1.2.2.1.1.4" xref="S3.T1.9.9.3.1.m1.2.2.1.2.cmml">)</mo></mrow><mo id="S3.T1.9.9.3.1.m1.2.2.2" xref="S3.T1.9.9.3.1.m1.2.2.2.cmml">âˆª</mo><msub id="S3.T1.9.9.3.1.m1.2.2.3" xref="S3.T1.9.9.3.1.m1.2.2.3.cmml"><mi id="S3.T1.9.9.3.1.m1.2.2.3.2" xref="S3.T1.9.9.3.1.m1.2.2.3.2.cmml">D</mi><mi id="S3.T1.9.9.3.1.m1.2.2.3.3" xref="S3.T1.9.9.3.1.m1.2.2.3.3.cmml">p</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.T1.9.9.3.1.m1.2b"><apply id="S3.T1.9.9.3.1.m1.2.2.cmml" xref="S3.T1.9.9.3.1.m1.2.2"><union id="S3.T1.9.9.3.1.m1.2.2.2.cmml" xref="S3.T1.9.9.3.1.m1.2.2.2"></union><interval closure="open" id="S3.T1.9.9.3.1.m1.2.2.1.2.cmml" xref="S3.T1.9.9.3.1.m1.2.2.1.1"><apply id="S3.T1.9.9.3.1.m1.2.2.1.1.1.cmml" xref="S3.T1.9.9.3.1.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.T1.9.9.3.1.m1.2.2.1.1.1.1.cmml" xref="S3.T1.9.9.3.1.m1.2.2.1.1.1">subscript</csymbol><ci id="S3.T1.9.9.3.1.m1.2.2.1.1.1.2.cmml" xref="S3.T1.9.9.3.1.m1.2.2.1.1.1.2">ğ‘‹</ci><ci id="S3.T1.9.9.3.1.m1.2.2.1.1.1.3.cmml" xref="S3.T1.9.9.3.1.m1.2.2.1.1.1.3">ğ‘</ci></apply><apply id="S3.T1.9.9.3.1.m1.1.1.cmml" xref="S3.T1.9.9.3.1.m1.1.1"><ci id="S3.T1.9.9.3.1.m1.1.1.1.cmml" xref="S3.T1.9.9.3.1.m1.1.1.1">~</ci><apply id="S3.T1.9.9.3.1.m1.1.1.2.cmml" xref="S3.T1.9.9.3.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.T1.9.9.3.1.m1.1.1.2.1.cmml" xref="S3.T1.9.9.3.1.m1.1.1.2">subscript</csymbol><ci id="S3.T1.9.9.3.1.m1.1.1.2.2.cmml" xref="S3.T1.9.9.3.1.m1.1.1.2.2">ğ‘Œ</ci><ci id="S3.T1.9.9.3.1.m1.1.1.2.3.cmml" xref="S3.T1.9.9.3.1.m1.1.1.2.3">ğ‘</ci></apply></apply></interval><apply id="S3.T1.9.9.3.1.m1.2.2.3.cmml" xref="S3.T1.9.9.3.1.m1.2.2.3"><csymbol cd="ambiguous" id="S3.T1.9.9.3.1.m1.2.2.3.1.cmml" xref="S3.T1.9.9.3.1.m1.2.2.3">subscript</csymbol><ci id="S3.T1.9.9.3.1.m1.2.2.3.2.cmml" xref="S3.T1.9.9.3.1.m1.2.2.3.2">ğ·</ci><ci id="S3.T1.9.9.3.1.m1.2.2.3.3.cmml" xref="S3.T1.9.9.3.1.m1.2.2.3.3">ğ‘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.9.9.3.1.m1.2c">(X_{p},\tilde{Y_{p}})\cup D_{p}</annotation></semantics></math>
</td>
</tr>
<tr id="S3.T1.9.9.7.4" class="ltx_tr">
<td id="S3.T1.9.9.7.4.1" class="ltx_td ltx_align_center">CFD <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>
</td>
<td id="S3.T1.9.9.7.4.2" class="ltx_td ltx_align_center">response</td>
<td id="S3.T1.9.9.7.4.3" class="ltx_td ltx_align_center">unlabeled</td>
<td id="S3.T1.9.9.7.4.4" class="ltx_td ltx_align_center">yes</td>
<td id="S3.T1.9.9.7.4.5" class="ltx_td ltx_align_center">Compressed soft targets</td>
</tr>
<tr id="S3.T1.9.9.8.5" class="ltx_tr">
<td id="S3.T1.9.9.8.5.1" class="ltx_td ltx_align_center">FedGEMS <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>
</td>
<td id="S3.T1.9.9.8.5.2" class="ltx_td ltx_align_center">response</td>
<td id="S3.T1.9.9.8.5.3" class="ltx_td ltx_align_center">labeled</td>
<td id="S3.T1.9.9.8.5.4" class="ltx_td ltx_align_center">yes</td>
<td id="S3.T1.9.9.8.5.5" class="ltx_td ltx_align_center">Server-side kowledge refinement</td>
</tr>
<tr id="S3.T1.9.9.9.6" class="ltx_tr">
<td id="S3.T1.9.9.9.6.1" class="ltx_td ltx_align_center">FedAD <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>
</td>
<td id="S3.T1.9.9.9.6.2" class="ltx_td ltx_align_center">feature</td>
<td id="S3.T1.9.9.9.6.3" class="ltx_td ltx_align_center">unlabeled</td>
<td id="S3.T1.9.9.9.6.4" class="ltx_td ltx_align_center">yes</td>
<td id="S3.T1.9.9.9.6.5" class="ltx_td ltx_align_center">One-shot algorithm</td>
</tr>
<tr id="S3.T1.9.9.10.7" class="ltx_tr">
<td id="S3.T1.9.9.10.7.1" class="ltx_td ltx_align_center">FedGKT <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>
</td>
<td id="S3.T1.9.9.10.7.2" class="ltx_td ltx_align_center">feature</td>
<td id="S3.T1.9.9.10.7.3" class="ltx_td ltx_align_center">data-free</td>
<td id="S3.T1.9.9.10.7.4" class="ltx_td ltx_align_center">yes</td>
<td id="S3.T1.9.9.10.7.5" class="ltx_td ltx_align_center">Split learning paradigm</td>
</tr>
<tr id="S3.T1.9.9.11.8" class="ltx_tr">
<td id="S3.T1.9.9.11.8.1" class="ltx_td ltx_align_center">FedDKC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>
</td>
<td id="S3.T1.9.9.11.8.2" class="ltx_td ltx_align_center">feature</td>
<td id="S3.T1.9.9.11.8.3" class="ltx_td ltx_align_center">data-free</td>
<td id="S3.T1.9.9.11.8.4" class="ltx_td ltx_align_center">yes</td>
<td id="S3.T1.9.9.11.8.5" class="ltx_td ltx_align_center">Knowledge refinement</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Data-distribution-agnostic FL via KD</h3>

<div id="S3.SS2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.p1.1" class="ltx_p">KD-based solutions can be used to handle data heterogeneity either at server side, rectifying FedAvgâ€™s global model via ensemble distillation on a proxy dataset <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> or using a data-free generator <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>, or at client side, distilling global knowledge via on-device regularizers <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> or synthetically-generated data <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, directly controlling the phenomenon of client drift.</p>
</div>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1 </span>Server-side KD-based refinement of global model</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p">In <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, the authors propose FedDF, a server-side ensemble distillation approach to both enable model heterogeneity and enhance FedAvgâ€™s aggregation. In FedDF, the global model is fine tuned imitating the ensemble of clientsâ€™ model output on a proxy dataset. FedAUX <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> boosts the performances of FedDF <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite> leveraging unsupervised pre-training on the auxiliary data to find a suitable model initialization for client-side feature extractor. In addition, FedAUX weights the ensemble predictions on the proxy data according to <math id="S3.SS2.SSS1.p1.1.m1.2" class="ltx_Math" alttext="(\epsilon,\delta)" display="inline"><semantics id="S3.SS2.SSS1.p1.1.m1.2a"><mrow id="S3.SS2.SSS1.p1.1.m1.2.3.2" xref="S3.SS2.SSS1.p1.1.m1.2.3.1.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p1.1.m1.2.3.2.1" xref="S3.SS2.SSS1.p1.1.m1.2.3.1.cmml">(</mo><mi id="S3.SS2.SSS1.p1.1.m1.1.1" xref="S3.SS2.SSS1.p1.1.m1.1.1.cmml">Ïµ</mi><mo id="S3.SS2.SSS1.p1.1.m1.2.3.2.2" xref="S3.SS2.SSS1.p1.1.m1.2.3.1.cmml">,</mo><mi id="S3.SS2.SSS1.p1.1.m1.2.2" xref="S3.SS2.SSS1.p1.1.m1.2.2.cmml">Î´</mi><mo stretchy="false" id="S3.SS2.SSS1.p1.1.m1.2.3.2.3" xref="S3.SS2.SSS1.p1.1.m1.2.3.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p1.1.m1.2b"><interval closure="open" id="S3.SS2.SSS1.p1.1.m1.2.3.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.2.3.2"><ci id="S3.SS2.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p1.1.m1.1.1">italic-Ïµ</ci><ci id="S3.SS2.SSS1.p1.1.m1.2.2.cmml" xref="S3.SS2.SSS1.p1.1.m1.2.2">ğ›¿</ci></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p1.1.m1.2c">(\epsilon,\delta)</annotation></semantics></math>-differentially private <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> certainty score of each participant model. FedBE <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> proposes to combine client predictions by means of a Bayesian model ensemble to further improve robustness of the aggregation instead of averaging the model predictions. While server-side ensemble distillation approaches suppose the existence of a proxy dataset, FedFTG <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> performs a server-side refinement of the global model via data-free knowledge distillation where the server adversarially trains a generator model and the global model, and fine-tunes the latter with synthetic data. A data-free generator-based refinement of global model is also proposed in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>.
It is worth noting that server-side global model rectifications are orthogonal to client-side approach to control model drift, and can be used in combination <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2 </span>Local distillation of global knowledge</h4>

<figure id="S3.F1" class="ltx_figure"><img src="/html/2211.04742/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="230" height="126" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Overview of approaches that distill global knowledge using a regularization term during local training. <math id="S3.F1.9.m1.1" class="ltx_Math" alttext="D_{k}" display="inline"><semantics id="S3.F1.9.m1.1b"><msub id="S3.F1.9.m1.1.1" xref="S3.F1.9.m1.1.1.cmml"><mi id="S3.F1.9.m1.1.1.2" xref="S3.F1.9.m1.1.1.2.cmml">D</mi><mi id="S3.F1.9.m1.1.1.3" xref="S3.F1.9.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F1.9.m1.1c"><apply id="S3.F1.9.m1.1.1.cmml" xref="S3.F1.9.m1.1.1"><csymbol cd="ambiguous" id="S3.F1.9.m1.1.1.1.cmml" xref="S3.F1.9.m1.1.1">subscript</csymbol><ci id="S3.F1.9.m1.1.1.2.cmml" xref="S3.F1.9.m1.1.1.2">ğ·</ci><ci id="S3.F1.9.m1.1.1.3.cmml" xref="S3.F1.9.m1.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.9.m1.1d">D_{k}</annotation></semantics></math> is the private dataset at client <math id="S3.F1.10.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.F1.10.m2.1b"><mi id="S3.F1.10.m2.1.1" xref="S3.F1.10.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.F1.10.m2.1c"><ci id="S3.F1.10.m2.1.1.cmml" xref="S3.F1.10.m2.1.1">ğ‘˜</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.10.m2.1d">k</annotation></semantics></math>, with <math id="S3.F1.11.m3.1" class="ltx_Math" alttext="x_{i}" display="inline"><semantics id="S3.F1.11.m3.1b"><msub id="S3.F1.11.m3.1.1" xref="S3.F1.11.m3.1.1.cmml"><mi id="S3.F1.11.m3.1.1.2" xref="S3.F1.11.m3.1.1.2.cmml">x</mi><mi id="S3.F1.11.m3.1.1.3" xref="S3.F1.11.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F1.11.m3.1c"><apply id="S3.F1.11.m3.1.1.cmml" xref="S3.F1.11.m3.1.1"><csymbol cd="ambiguous" id="S3.F1.11.m3.1.1.1.cmml" xref="S3.F1.11.m3.1.1">subscript</csymbol><ci id="S3.F1.11.m3.1.1.2.cmml" xref="S3.F1.11.m3.1.1.2">ğ‘¥</ci><ci id="S3.F1.11.m3.1.1.3.cmml" xref="S3.F1.11.m3.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.11.m3.1d">x_{i}</annotation></semantics></math> and <math id="S3.F1.12.m4.1" class="ltx_Math" alttext="y_{i}" display="inline"><semantics id="S3.F1.12.m4.1b"><msub id="S3.F1.12.m4.1.1" xref="S3.F1.12.m4.1.1.cmml"><mi id="S3.F1.12.m4.1.1.2" xref="S3.F1.12.m4.1.1.2.cmml">y</mi><mi id="S3.F1.12.m4.1.1.3" xref="S3.F1.12.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F1.12.m4.1c"><apply id="S3.F1.12.m4.1.1.cmml" xref="S3.F1.12.m4.1.1"><csymbol cd="ambiguous" id="S3.F1.12.m4.1.1.1.cmml" xref="S3.F1.12.m4.1.1">subscript</csymbol><ci id="S3.F1.12.m4.1.1.2.cmml" xref="S3.F1.12.m4.1.1.2">ğ‘¦</ci><ci id="S3.F1.12.m4.1.1.3.cmml" xref="S3.F1.12.m4.1.1.3">ğ‘–</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.12.m4.1d">y_{i}</annotation></semantics></math> respectively being the data sample <math id="S3.F1.13.m5.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.F1.13.m5.1b"><mi id="S3.F1.13.m5.1.1" xref="S3.F1.13.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.F1.13.m5.1c"><ci id="S3.F1.13.m5.1.1.cmml" xref="S3.F1.13.m5.1.1">ğ‘–</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.13.m5.1d">i</annotation></semantics></math> and the corresponding ground-truth label. <math id="S3.F1.14.m6.1" class="ltx_Math" alttext="w_{t}" display="inline"><semantics id="S3.F1.14.m6.1b"><msub id="S3.F1.14.m6.1.1" xref="S3.F1.14.m6.1.1.cmml"><mi id="S3.F1.14.m6.1.1.2" xref="S3.F1.14.m6.1.1.2.cmml">w</mi><mi id="S3.F1.14.m6.1.1.3" xref="S3.F1.14.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F1.14.m6.1c"><apply id="S3.F1.14.m6.1.1.cmml" xref="S3.F1.14.m6.1.1"><csymbol cd="ambiguous" id="S3.F1.14.m6.1.1.1.cmml" xref="S3.F1.14.m6.1.1">subscript</csymbol><ci id="S3.F1.14.m6.1.1.2.cmml" xref="S3.F1.14.m6.1.1.2">ğ‘¤</ci><ci id="S3.F1.14.m6.1.1.3.cmml" xref="S3.F1.14.m6.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.14.m6.1d">w_{t}</annotation></semantics></math> represents the global model at round <math id="S3.F1.15.m7.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.F1.15.m7.1b"><mi id="S3.F1.15.m7.1.1" xref="S3.F1.15.m7.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.F1.15.m7.1c"><ci id="S3.F1.15.m7.1.1.cmml" xref="S3.F1.15.m7.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.15.m7.1d">t</annotation></semantics></math>. <math id="S3.F1.16.m8.1" class="ltx_Math" alttext="w_{t+1}^{k}" display="inline"><semantics id="S3.F1.16.m8.1b"><msubsup id="S3.F1.16.m8.1.1" xref="S3.F1.16.m8.1.1.cmml"><mi id="S3.F1.16.m8.1.1.2.2" xref="S3.F1.16.m8.1.1.2.2.cmml">w</mi><mrow id="S3.F1.16.m8.1.1.2.3" xref="S3.F1.16.m8.1.1.2.3.cmml"><mi id="S3.F1.16.m8.1.1.2.3.2" xref="S3.F1.16.m8.1.1.2.3.2.cmml">t</mi><mo id="S3.F1.16.m8.1.1.2.3.1" xref="S3.F1.16.m8.1.1.2.3.1.cmml">+</mo><mn id="S3.F1.16.m8.1.1.2.3.3" xref="S3.F1.16.m8.1.1.2.3.3.cmml">1</mn></mrow><mi id="S3.F1.16.m8.1.1.3" xref="S3.F1.16.m8.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.F1.16.m8.1c"><apply id="S3.F1.16.m8.1.1.cmml" xref="S3.F1.16.m8.1.1"><csymbol cd="ambiguous" id="S3.F1.16.m8.1.1.1.cmml" xref="S3.F1.16.m8.1.1">superscript</csymbol><apply id="S3.F1.16.m8.1.1.2.cmml" xref="S3.F1.16.m8.1.1"><csymbol cd="ambiguous" id="S3.F1.16.m8.1.1.2.1.cmml" xref="S3.F1.16.m8.1.1">subscript</csymbol><ci id="S3.F1.16.m8.1.1.2.2.cmml" xref="S3.F1.16.m8.1.1.2.2">ğ‘¤</ci><apply id="S3.F1.16.m8.1.1.2.3.cmml" xref="S3.F1.16.m8.1.1.2.3"><plus id="S3.F1.16.m8.1.1.2.3.1.cmml" xref="S3.F1.16.m8.1.1.2.3.1"></plus><ci id="S3.F1.16.m8.1.1.2.3.2.cmml" xref="S3.F1.16.m8.1.1.2.3.2">ğ‘¡</ci><cn type="integer" id="S3.F1.16.m8.1.1.2.3.3.cmml" xref="S3.F1.16.m8.1.1.2.3.3">1</cn></apply></apply><ci id="S3.F1.16.m8.1.1.3.cmml" xref="S3.F1.16.m8.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F1.16.m8.1d">w_{t+1}^{k}</annotation></semantics></math> represents the local model. </figcaption>
</figure>
<section id="S3.SS2.SSS2.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Local-global distillation via regularization term.</h5>

<div id="S3.SS2.SSS2.Px1.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS2.Px1.p1.2" class="ltx_p">Respectively inspired by fine-tuning optimization ideas and continual learning research, the recent works in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> find that local KD-based regularization is an effective way of reducing the influence of non-IID data in FL settings. <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Local-side regularization strategies, which do not use KD, have been proposed as well <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.</span></span></span> In local-global distillation, the local objective function of clients becomes a linear combination between the cross-entropy loss and a KD-based loss that measures the discrepancy among the global modelâ€™s output (i.e., the teacher modelâ€™s output) and the local modelâ€™s output (i.e., the student model output) on private data, e.g. via Kullback-Leibler divergence. Fig. <a href="#S3.F1" title="Figure 1 â€£ 3.2.2 Local distillation of global knowledge â€£ 3.2 Data-distribution-agnostic FL via KD â€£ 3 Knowledge Distillation for Federated Learning â€£ Knowledge Distillation for Federated Learning: a Practical Guide" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> depicts the basic framework for local-global distillation via regularization term. The inspiration for such a framework is twofold. In <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib52" title="" class="ltx_ref">Yao etÂ al.</a></cite> borrow the idea from the work in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>, where, in a non-federated setting, self-distillation mechanisms are shown to improve the fine-tuning of pre-trained models such as BERT<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. In self-distillation, knowledge from past snapshots <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>, i.e. produced at previous training steps of the in-training model, assists the current step of model training. Orthogonally, in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, <cite class="ltx_cite ltx_citemacro_citeauthor"><a href="#bib.bib25" title="" class="ltx_ref">Lee etÂ al.</a></cite> observe a phenomenon similar to catastrophic forgetting <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> in continual learning research: in presence of heterogeneous data, FedAvg-trained global models exhibit inconsistent predictions on test data between subsequent rounds (i.e., the global model at round <math id="S3.SS2.SSS2.Px1.p1.1.m1.1" class="ltx_Math" alttext="t+1" display="inline"><semantics id="S3.SS2.SSS2.Px1.p1.1.m1.1a"><mrow id="S3.SS2.SSS2.Px1.p1.1.m1.1.1" xref="S3.SS2.SSS2.Px1.p1.1.m1.1.1.cmml"><mi id="S3.SS2.SSS2.Px1.p1.1.m1.1.1.2" xref="S3.SS2.SSS2.Px1.p1.1.m1.1.1.2.cmml">t</mi><mo id="S3.SS2.SSS2.Px1.p1.1.m1.1.1.1" xref="S3.SS2.SSS2.Px1.p1.1.m1.1.1.1.cmml">+</mo><mn id="S3.SS2.SSS2.Px1.p1.1.m1.1.1.3" xref="S3.SS2.SSS2.Px1.p1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.Px1.p1.1.m1.1b"><apply id="S3.SS2.SSS2.Px1.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS2.Px1.p1.1.m1.1.1"><plus id="S3.SS2.SSS2.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.Px1.p1.1.m1.1.1.1"></plus><ci id="S3.SS2.SSS2.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.Px1.p1.1.m1.1.1.2">ğ‘¡</ci><cn type="integer" id="S3.SS2.SSS2.Px1.p1.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.Px1.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.Px1.p1.1.m1.1c">t+1</annotation></semantics></math> shows reduced performance on classes that the global model at round <math id="S3.SS2.SSS2.Px1.p1.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS2.SSS2.Px1.p1.2.m2.1a"><mi id="S3.SS2.SSS2.Px1.p1.2.m2.1.1" xref="S3.SS2.SSS2.Px1.p1.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.Px1.p1.2.m2.1b"><ci id="S3.SS2.SSS2.Px1.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS2.Px1.p1.2.m2.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.Px1.p1.2.m2.1c">t</annotation></semantics></math> predicted correctly). Local distillation of global knowledge is shown to mitigate forgetting among subsequent rounds, and in turn to alleviate the harmfulness of data heterogeneity <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>.</p>
</div>
</section>
<section id="S3.SS2.SSS2.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Local-global distillation via regularization term: further improvements.</h5>

<div id="S3.SS2.SSS2.Px2.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS2.Px2.p1.8" class="ltx_p">FedGKD <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> uses an ensemble of <math id="S3.SS2.SSS2.Px2.p1.1.m1.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS2.SSS2.Px2.p1.1.m1.1a"><mi id="S3.SS2.SSS2.Px2.p1.1.m1.1.1" xref="S3.SS2.SSS2.Px2.p1.1.m1.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.Px2.p1.1.m1.1b"><ci id="S3.SS2.SSS2.Px2.p1.1.m1.1.1.cmml" xref="S3.SS2.SSS2.Px2.p1.1.m1.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.Px2.p1.1.m1.1c">M</annotation></semantics></math> historical global models as teacher for the KD-based regularization where such an ensemble model is computed as the average of <math id="S3.SS2.SSS2.Px2.p1.2.m2.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS2.SSS2.Px2.p1.2.m2.1a"><mi id="S3.SS2.SSS2.Px2.p1.2.m2.1.1" xref="S3.SS2.SSS2.Px2.p1.2.m2.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.Px2.p1.2.m2.1b"><ci id="S3.SS2.SSS2.Px2.p1.2.m2.1.1.cmml" xref="S3.SS2.SSS2.Px2.p1.2.m2.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.Px2.p1.2.m2.1c">M</annotation></semantics></math> past global models. FedGKD-VOTE is also proposed as a variation that considers the averaged discrepancy of all the <math id="S3.SS2.SSS2.Px2.p1.3.m3.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS2.SSS2.Px2.p1.3.m3.1a"><mi id="S3.SS2.SSS2.Px2.p1.3.m3.1.1" xref="S3.SS2.SSS2.Px2.p1.3.m3.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.Px2.p1.3.m3.1b"><ci id="S3.SS2.SSS2.Px2.p1.3.m3.1.1.cmml" xref="S3.SS2.SSS2.Px2.p1.3.m3.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.Px2.p1.3.m3.1c">M</annotation></semantics></math> historical models as the regularization term <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>. In the simplest formulation of FedGKD, i.e. with <math id="S3.SS2.SSS2.Px2.p1.4.m4.1" class="ltx_Math" alttext="M=1" display="inline"><semantics id="S3.SS2.SSS2.Px2.p1.4.m4.1a"><mrow id="S3.SS2.SSS2.Px2.p1.4.m4.1.1" xref="S3.SS2.SSS2.Px2.p1.4.m4.1.1.cmml"><mi id="S3.SS2.SSS2.Px2.p1.4.m4.1.1.2" xref="S3.SS2.SSS2.Px2.p1.4.m4.1.1.2.cmml">M</mi><mo id="S3.SS2.SSS2.Px2.p1.4.m4.1.1.1" xref="S3.SS2.SSS2.Px2.p1.4.m4.1.1.1.cmml">=</mo><mn id="S3.SS2.SSS2.Px2.p1.4.m4.1.1.3" xref="S3.SS2.SSS2.Px2.p1.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.Px2.p1.4.m4.1b"><apply id="S3.SS2.SSS2.Px2.p1.4.m4.1.1.cmml" xref="S3.SS2.SSS2.Px2.p1.4.m4.1.1"><eq id="S3.SS2.SSS2.Px2.p1.4.m4.1.1.1.cmml" xref="S3.SS2.SSS2.Px2.p1.4.m4.1.1.1"></eq><ci id="S3.SS2.SSS2.Px2.p1.4.m4.1.1.2.cmml" xref="S3.SS2.SSS2.Px2.p1.4.m4.1.1.2">ğ‘€</ci><cn type="integer" id="S3.SS2.SSS2.Px2.p1.4.m4.1.1.3.cmml" xref="S3.SS2.SSS2.Px2.p1.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.Px2.p1.4.m4.1c">M=1</annotation></semantics></math>, the communication cost is the same of FedAvg, while for <math id="S3.SS2.SSS2.Px2.p1.5.m5.1" class="ltx_Math" alttext="M&gt;1" display="inline"><semantics id="S3.SS2.SSS2.Px2.p1.5.m5.1a"><mrow id="S3.SS2.SSS2.Px2.p1.5.m5.1.1" xref="S3.SS2.SSS2.Px2.p1.5.m5.1.1.cmml"><mi id="S3.SS2.SSS2.Px2.p1.5.m5.1.1.2" xref="S3.SS2.SSS2.Px2.p1.5.m5.1.1.2.cmml">M</mi><mo id="S3.SS2.SSS2.Px2.p1.5.m5.1.1.1" xref="S3.SS2.SSS2.Px2.p1.5.m5.1.1.1.cmml">&gt;</mo><mn id="S3.SS2.SSS2.Px2.p1.5.m5.1.1.3" xref="S3.SS2.SSS2.Px2.p1.5.m5.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.Px2.p1.5.m5.1b"><apply id="S3.SS2.SSS2.Px2.p1.5.m5.1.1.cmml" xref="S3.SS2.SSS2.Px2.p1.5.m5.1.1"><gt id="S3.SS2.SSS2.Px2.p1.5.m5.1.1.1.cmml" xref="S3.SS2.SSS2.Px2.p1.5.m5.1.1.1"></gt><ci id="S3.SS2.SSS2.Px2.p1.5.m5.1.1.2.cmml" xref="S3.SS2.SSS2.Px2.p1.5.m5.1.1.2">ğ‘€</ci><cn type="integer" id="S3.SS2.SSS2.Px2.p1.5.m5.1.1.3.cmml" xref="S3.SS2.SSS2.Px2.p1.5.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.Px2.p1.5.m5.1c">M&gt;1</annotation></semantics></math> the server-client communication cost is doubled, and for FedGKD-VOTE it scales with <math id="S3.SS2.SSS2.Px2.p1.6.m6.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S3.SS2.SSS2.Px2.p1.6.m6.1a"><mi id="S3.SS2.SSS2.Px2.p1.6.m6.1.1" xref="S3.SS2.SSS2.Px2.p1.6.m6.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.Px2.p1.6.m6.1b"><ci id="S3.SS2.SSS2.Px2.p1.6.m6.1.1.cmml" xref="S3.SS2.SSS2.Px2.p1.6.m6.1.1">ğ‘€</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.Px2.p1.6.m6.1c">M</annotation></semantics></math>. FedNTD <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> locally applies the framework in Fig. <a href="#S3.F1" title="Figure 1 â€£ 3.2.2 Local distillation of global knowledge â€£ 3.2 Data-distribution-agnostic FL via KD â€£ 3 Knowledge Distillation for Federated Learning â€£ Knowledge Distillation for Federated Learning: a Practical Guide" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> but ignoring the logits produced by the true classes when computing the softmax score later fed to the KD-based loss. Inspired by the work of Lukasik et al. <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, He et al. further observe that, in the framework of Fig. <a href="#S3.F1" title="Figure 1 â€£ 3.2.2 Local distillation of global knowledge â€£ 3.2 Data-distribution-agnostic FL via KD â€£ 3 Knowledge Distillation for Federated Learning â€£ Knowledge Distillation for Federated Learning: a Practical Guide" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, leveraging an inaccurate global model (i.e., inaccurate teacher) on specific classification classes might mislead local training <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. To alleviate such phenomenon, a class-wise adaptive weight is proposed in FedCAD <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> to control the impact of distillation: when the global model is accurate on a certain class, local models learn more from the distilled knowledge. FedCAD determines the class-wise adaptive weight based on the performances of the global model on an auxiliary dataset, and the server broadcasts such information along with model parameters round by round. FedSSD <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> extends FedCAD by also considering the credibility of global model at the instance level when computing the distillation term in local training. FedMLB <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> enhances the local-global distillation also using intermediate representations, preventing them from deviating too significantly during local fine tuning. To this end, FedMLB crafts hybrid pathways composed of local and global subnetworks, i.e. of local network blocks followed by non-trainable global blocks. Besides regular cross-entropy, local learning also considers the average cross-entropy from hybrid paths and the average KL divergence between the outputs produced by the hybrid paths and the main path as regularization term. Due to backpropagation through hybrid pathways, FedMLB locally introduces a moderate computation overhead. FedDistill<sup id="S3.SS2.SSS2.Px2.p1.8.1" class="ltx_sup"><span id="S3.SS2.SSS2.Px2.p1.8.1.1" class="ltx_text ltx_font_italic">+</span></sup>, used as alternative baseline in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, extends the work of <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> by exchanging model parameters in addition to per-label local logits on training dataset. With respect to the framework in Fig. <a href="#S3.F1" title="Figure 1 â€£ 3.2.2 Local distillation of global knowledge â€£ 3.2 Data-distribution-agnostic FL via KD â€£ 3 Knowledge Distillation for Federated Learning â€£ Knowledge Distillation for Federated Learning: a Practical Guide" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, FedDistill<sup id="S3.SS2.SSS2.Px2.p1.8.2" class="ltx_sup"><span id="S3.SS2.SSS2.Px2.p1.8.2.1" class="ltx_text ltx_font_italic">+</span></sup> uses the received per-label globally averaged logits â€“ instead of the output of the global model on private data â€“ to calculate the KD loss.</p>
</div>
</section>
<section id="S3.SS2.SSS2.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Local-global distillation via data-free generator models.</h5>

<div id="S3.SS2.SSS2.Px3.p1" class="ltx_para ltx_noindent">
<p id="S3.SS2.SSS2.Px3.p1.1" class="ltx_p">Differently from the other work in this subsection, FedGen <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> learns a lightweight server-side generator which is distributed, round by round, to clients that sample it to obtain augmented training examples, using global knowledge as inductive biases in local learning. To build the generator, FedGen needs to disclose local model parameters (at least the classifier weights) and local label count.</p>
</div>
</section>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Comparison of Existing Solutions and Adoption Guidelines</h2>

<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Concise overview of the surveyed solutions. We have identified 5 possible categories for the primary purpose of the proposed solution, i.e., communication efficiency (CE), model heterogeneity (MH), non-iidness (NIID), server-side aggregation (A), and client drift (CD). Upload refers to the client-to-server link. Symbols: <math id="S4.T2.11.11.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.T2.11.11.m1.1b"><mi id="S4.T2.11.11.m1.1.1" xref="S4.T2.11.11.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.T2.11.11.m1.1c"><ci id="S4.T2.11.11.m1.1.1.cmml" xref="S4.T2.11.11.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.11.11.m1.1d">w</annotation></semantics></math> model parameters,
<math id="S4.T2.12.12.m2.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S4.T2.12.12.m2.1b"><mi id="S4.T2.12.12.m2.1.1" xref="S4.T2.12.12.m2.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S4.T2.12.12.m2.1c"><ci id="S4.T2.12.12.m2.1.1.cmml" xref="S4.T2.12.12.m2.1.1">ğ‘§</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.12.12.m2.1d">z</annotation></semantics></math> logit vectors (model output before softmax), <math id="S4.T2.13.13.m3.1" class="ltx_Math" alttext="\tilde{Y}" display="inline"><semantics id="S4.T2.13.13.m3.1b"><mover accent="true" id="S4.T2.13.13.m3.1.1" xref="S4.T2.13.13.m3.1.1.cmml"><mi id="S4.T2.13.13.m3.1.1.2" xref="S4.T2.13.13.m3.1.1.2.cmml">Y</mi><mo id="S4.T2.13.13.m3.1.1.1" xref="S4.T2.13.13.m3.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.T2.13.13.m3.1c"><apply id="S4.T2.13.13.m3.1.1.cmml" xref="S4.T2.13.13.m3.1.1"><ci id="S4.T2.13.13.m3.1.1.1.cmml" xref="S4.T2.13.13.m3.1.1.1">~</ci><ci id="S4.T2.13.13.m3.1.1.2.cmml" xref="S4.T2.13.13.m3.1.1.2">ğ‘Œ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.13.13.m3.1d">\tilde{Y}</annotation></semantics></math> soft targets (model output after softmax),
<math id="S4.T2.14.14.m4.1" class="ltx_Math" alttext="Z" display="inline"><semantics id="S4.T2.14.14.m4.1b"><mi id="S4.T2.14.14.m4.1.1" xref="S4.T2.14.14.m4.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S4.T2.14.14.m4.1c"><ci id="S4.T2.14.14.m4.1.1.cmml" xref="S4.T2.14.14.m4.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.14.14.m4.1d">Z</annotation></semantics></math> per-label average logit vectors,
<math id="S4.T2.15.15.m5.1" class="ltx_Math" alttext="Y" display="inline"><semantics id="S4.T2.15.15.m5.1b"><mi id="S4.T2.15.15.m5.1.1" xref="S4.T2.15.15.m5.1.1.cmml">Y</mi><annotation-xml encoding="MathML-Content" id="S4.T2.15.15.m5.1c"><ci id="S4.T2.15.15.m5.1.1.cmml" xref="S4.T2.15.15.m5.1.1">ğ‘Œ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.15.15.m5.1d">Y</annotation></semantics></math> labels of local data,
<math id="S4.T2.16.16.m6.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S4.T2.16.16.m6.1b"><mi id="S4.T2.16.16.m6.1.1" xref="S4.T2.16.16.m6.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S4.T2.16.16.m6.1c"><ci id="S4.T2.16.16.m6.1.1.cmml" xref="S4.T2.16.16.m6.1.1">ğ»</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.16.16.m6.1d">H</annotation></semantics></math> intermediate feature maps,
<math id="S4.T2.17.17.m7.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.T2.17.17.m7.1b"><mi id="S4.T2.17.17.m7.1.1" xref="S4.T2.17.17.m7.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.T2.17.17.m7.1c"><ci id="S4.T2.17.17.m7.1.1.cmml" xref="S4.T2.17.17.m7.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.17.17.m7.1d">A</annotation></semantics></math> attention maps,
<math id="S4.T2.18.18.m8.1" class="ltx_Math" alttext="\alpha_{y}" display="inline"><semantics id="S4.T2.18.18.m8.1b"><msub id="S4.T2.18.18.m8.1.1" xref="S4.T2.18.18.m8.1.1.cmml"><mi id="S4.T2.18.18.m8.1.1.2" xref="S4.T2.18.18.m8.1.1.2.cmml">Î±</mi><mi id="S4.T2.18.18.m8.1.1.3" xref="S4.T2.18.18.m8.1.1.3.cmml">y</mi></msub><annotation-xml encoding="MathML-Content" id="S4.T2.18.18.m8.1c"><apply id="S4.T2.18.18.m8.1.1.cmml" xref="S4.T2.18.18.m8.1.1"><csymbol cd="ambiguous" id="S4.T2.18.18.m8.1.1.1.cmml" xref="S4.T2.18.18.m8.1.1">subscript</csymbol><ci id="S4.T2.18.18.m8.1.1.2.cmml" xref="S4.T2.18.18.m8.1.1.2">ğ›¼</ci><ci id="S4.T2.18.18.m8.1.1.3.cmml" xref="S4.T2.18.18.m8.1.1.3">ğ‘¦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.18.18.m8.1d">\alpha_{y}</annotation></semantics></math> per-class adaptive weights,
<math id="S4.T2.19.19.m9.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S4.T2.19.19.m9.1b"><mi id="S4.T2.19.19.m9.1.1" xref="S4.T2.19.19.m9.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S4.T2.19.19.m9.1c"><ci id="S4.T2.19.19.m9.1.1.cmml" xref="S4.T2.19.19.m9.1.1">ğ¶</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.19.19.m9.1d">C</annotation></semantics></math> credibility matrix,
<math id="S4.T2.20.20.m10.1" class="ltx_Math" alttext="c" display="inline"><semantics id="S4.T2.20.20.m10.1b"><mi id="S4.T2.20.20.m10.1.1" xref="S4.T2.20.20.m10.1.1.cmml">c</mi><annotation-xml encoding="MathML-Content" id="S4.T2.20.20.m10.1c"><ci id="S4.T2.20.20.m10.1.1.cmml" xref="S4.T2.20.20.m10.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.20.20.m10.1d">c</annotation></semantics></math> local label count.
For the last column, a regularizer-based approach uses KD to regularize local training, generator-based leverages a generator model, distillation means that knowledge is absorbed by imitating teacher outputs on common data.</figcaption>
<table id="S4.T2.65.65" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T2.65.65.46.1" class="ltx_tr">
<td id="S4.T2.65.65.46.1.1" class="ltx_td ltx_border_tt"></td>
<th id="S4.T2.65.65.46.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Purpose</th>
<th id="S4.T2.65.65.46.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">Exchanged information</th>
<th id="S4.T2.65.65.46.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Auxiliary data</th>
<th id="S4.T2.65.65.46.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2">KD approach</th>
</tr>
<tr id="S4.T2.65.65.47.2" class="ltx_tr">
<td id="S4.T2.65.65.47.2.1" class="ltx_td"></td>
<th id="S4.T2.65.65.47.2.2" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S4.T2.65.65.47.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Upload</th>
<th id="S4.T2.65.65.47.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Download</th>
<th id="S4.T2.65.65.47.2.5" class="ltx_td ltx_th ltx_th_column"></th>
<th id="S4.T2.65.65.47.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Client-side</th>
<th id="S4.T2.65.65.47.2.7" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Server-side</th>
</tr>
<tr id="S4.T2.22.22.2" class="ltx_tr">
<td id="S4.T2.22.22.2.3" class="ltx_td ltx_align_center ltx_border_t">FedDistill <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>
</td>
<td id="S4.T2.22.22.2.4" class="ltx_td ltx_align_center ltx_border_t">CE, MH</td>
<td id="S4.T2.21.21.1.1" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T2.21.21.1.1.m1.1" class="ltx_Math" alttext="Z" display="inline"><semantics id="S4.T2.21.21.1.1.m1.1a"><mi id="S4.T2.21.21.1.1.m1.1.1" xref="S4.T2.21.21.1.1.m1.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S4.T2.21.21.1.1.m1.1b"><ci id="S4.T2.21.21.1.1.m1.1.1.cmml" xref="S4.T2.21.21.1.1.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.21.21.1.1.m1.1c">Z</annotation></semantics></math></td>
<td id="S4.T2.22.22.2.2" class="ltx_td ltx_align_center ltx_border_t"><math id="S4.T2.22.22.2.2.m1.1" class="ltx_Math" alttext="Z" display="inline"><semantics id="S4.T2.22.22.2.2.m1.1a"><mi id="S4.T2.22.22.2.2.m1.1.1" xref="S4.T2.22.22.2.2.m1.1.1.cmml">Z</mi><annotation-xml encoding="MathML-Content" id="S4.T2.22.22.2.2.m1.1b"><ci id="S4.T2.22.22.2.2.m1.1.1.cmml" xref="S4.T2.22.22.2.2.m1.1.1">ğ‘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.22.22.2.2.m1.1c">Z</annotation></semantics></math></td>
<td id="S4.T2.22.22.2.5" class="ltx_td ltx_align_center ltx_border_t">data-free</td>
<td id="S4.T2.22.22.2.6" class="ltx_td ltx_align_center ltx_border_t">regularizer</td>
<td id="S4.T2.22.22.2.7" class="ltx_td ltx_align_center ltx_border_t">-</td>
</tr>
<tr id="S4.T2.24.24.4" class="ltx_tr">
<td id="S4.T2.24.24.4.3" class="ltx_td ltx_align_center">FedMD <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>
</td>
<td id="S4.T2.24.24.4.4" class="ltx_td ltx_align_center">CE, MH</td>
<td id="S4.T2.23.23.3.1" class="ltx_td ltx_align_center"><math id="S4.T2.23.23.3.1.m1.1" class="ltx_Math" alttext="\tilde{Y}" display="inline"><semantics id="S4.T2.23.23.3.1.m1.1a"><mover accent="true" id="S4.T2.23.23.3.1.m1.1.1" xref="S4.T2.23.23.3.1.m1.1.1.cmml"><mi id="S4.T2.23.23.3.1.m1.1.1.2" xref="S4.T2.23.23.3.1.m1.1.1.2.cmml">Y</mi><mo id="S4.T2.23.23.3.1.m1.1.1.1" xref="S4.T2.23.23.3.1.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.T2.23.23.3.1.m1.1b"><apply id="S4.T2.23.23.3.1.m1.1.1.cmml" xref="S4.T2.23.23.3.1.m1.1.1"><ci id="S4.T2.23.23.3.1.m1.1.1.1.cmml" xref="S4.T2.23.23.3.1.m1.1.1.1">~</ci><ci id="S4.T2.23.23.3.1.m1.1.1.2.cmml" xref="S4.T2.23.23.3.1.m1.1.1.2">ğ‘Œ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.23.23.3.1.m1.1c">\tilde{Y}</annotation></semantics></math></td>
<td id="S4.T2.24.24.4.2" class="ltx_td ltx_align_center"><math id="S4.T2.24.24.4.2.m1.1" class="ltx_Math" alttext="\tilde{Y}" display="inline"><semantics id="S4.T2.24.24.4.2.m1.1a"><mover accent="true" id="S4.T2.24.24.4.2.m1.1.1" xref="S4.T2.24.24.4.2.m1.1.1.cmml"><mi id="S4.T2.24.24.4.2.m1.1.1.2" xref="S4.T2.24.24.4.2.m1.1.1.2.cmml">Y</mi><mo id="S4.T2.24.24.4.2.m1.1.1.1" xref="S4.T2.24.24.4.2.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.T2.24.24.4.2.m1.1b"><apply id="S4.T2.24.24.4.2.m1.1.1.cmml" xref="S4.T2.24.24.4.2.m1.1.1"><ci id="S4.T2.24.24.4.2.m1.1.1.1.cmml" xref="S4.T2.24.24.4.2.m1.1.1.1">~</ci><ci id="S4.T2.24.24.4.2.m1.1.1.2.cmml" xref="S4.T2.24.24.4.2.m1.1.1.2">ğ‘Œ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.24.24.4.2.m1.1c">\tilde{Y}</annotation></semantics></math></td>
<td id="S4.T2.24.24.4.5" class="ltx_td ltx_align_center">labeled</td>
<td id="S4.T2.24.24.4.6" class="ltx_td ltx_align_center">distillation</td>
<td id="S4.T2.24.24.4.7" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T2.26.26.6" class="ltx_tr">
<td id="S4.T2.26.26.6.3" class="ltx_td ltx_align_center">Cronus <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>
</td>
<td id="S4.T2.26.26.6.4" class="ltx_td ltx_align_center">CE, MH, A</td>
<td id="S4.T2.25.25.5.1" class="ltx_td ltx_align_center"><math id="S4.T2.25.25.5.1.m1.1" class="ltx_Math" alttext="\tilde{Y}" display="inline"><semantics id="S4.T2.25.25.5.1.m1.1a"><mover accent="true" id="S4.T2.25.25.5.1.m1.1.1" xref="S4.T2.25.25.5.1.m1.1.1.cmml"><mi id="S4.T2.25.25.5.1.m1.1.1.2" xref="S4.T2.25.25.5.1.m1.1.1.2.cmml">Y</mi><mo id="S4.T2.25.25.5.1.m1.1.1.1" xref="S4.T2.25.25.5.1.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.T2.25.25.5.1.m1.1b"><apply id="S4.T2.25.25.5.1.m1.1.1.cmml" xref="S4.T2.25.25.5.1.m1.1.1"><ci id="S4.T2.25.25.5.1.m1.1.1.1.cmml" xref="S4.T2.25.25.5.1.m1.1.1.1">~</ci><ci id="S4.T2.25.25.5.1.m1.1.1.2.cmml" xref="S4.T2.25.25.5.1.m1.1.1.2">ğ‘Œ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.25.25.5.1.m1.1c">\tilde{Y}</annotation></semantics></math></td>
<td id="S4.T2.26.26.6.2" class="ltx_td ltx_align_center"><math id="S4.T2.26.26.6.2.m1.1" class="ltx_Math" alttext="\tilde{Y}" display="inline"><semantics id="S4.T2.26.26.6.2.m1.1a"><mover accent="true" id="S4.T2.26.26.6.2.m1.1.1" xref="S4.T2.26.26.6.2.m1.1.1.cmml"><mi id="S4.T2.26.26.6.2.m1.1.1.2" xref="S4.T2.26.26.6.2.m1.1.1.2.cmml">Y</mi><mo id="S4.T2.26.26.6.2.m1.1.1.1" xref="S4.T2.26.26.6.2.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.T2.26.26.6.2.m1.1b"><apply id="S4.T2.26.26.6.2.m1.1.1.cmml" xref="S4.T2.26.26.6.2.m1.1.1"><ci id="S4.T2.26.26.6.2.m1.1.1.1.cmml" xref="S4.T2.26.26.6.2.m1.1.1.1">~</ci><ci id="S4.T2.26.26.6.2.m1.1.1.2.cmml" xref="S4.T2.26.26.6.2.m1.1.1.2">ğ‘Œ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.26.26.6.2.m1.1c">\tilde{Y}</annotation></semantics></math></td>
<td id="S4.T2.26.26.6.5" class="ltx_td ltx_align_center">unlabeled</td>
<td id="S4.T2.26.26.6.6" class="ltx_td ltx_align_center">distillation</td>
<td id="S4.T2.26.26.6.7" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T2.28.28.8" class="ltx_tr">
<td id="S4.T2.28.28.8.3" class="ltx_td ltx_align_center">DS-FL<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>
</td>
<td id="S4.T2.28.28.8.4" class="ltx_td ltx_align_center">CE, MH</td>
<td id="S4.T2.27.27.7.1" class="ltx_td ltx_align_center"><math id="S4.T2.27.27.7.1.m1.1" class="ltx_Math" alttext="\tilde{Y}" display="inline"><semantics id="S4.T2.27.27.7.1.m1.1a"><mover accent="true" id="S4.T2.27.27.7.1.m1.1.1" xref="S4.T2.27.27.7.1.m1.1.1.cmml"><mi id="S4.T2.27.27.7.1.m1.1.1.2" xref="S4.T2.27.27.7.1.m1.1.1.2.cmml">Y</mi><mo id="S4.T2.27.27.7.1.m1.1.1.1" xref="S4.T2.27.27.7.1.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.T2.27.27.7.1.m1.1b"><apply id="S4.T2.27.27.7.1.m1.1.1.cmml" xref="S4.T2.27.27.7.1.m1.1.1"><ci id="S4.T2.27.27.7.1.m1.1.1.1.cmml" xref="S4.T2.27.27.7.1.m1.1.1.1">~</ci><ci id="S4.T2.27.27.7.1.m1.1.1.2.cmml" xref="S4.T2.27.27.7.1.m1.1.1.2">ğ‘Œ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.27.27.7.1.m1.1c">\tilde{Y}</annotation></semantics></math></td>
<td id="S4.T2.28.28.8.2" class="ltx_td ltx_align_center"><math id="S4.T2.28.28.8.2.m1.1" class="ltx_Math" alttext="\tilde{Y}" display="inline"><semantics id="S4.T2.28.28.8.2.m1.1a"><mover accent="true" id="S4.T2.28.28.8.2.m1.1.1" xref="S4.T2.28.28.8.2.m1.1.1.cmml"><mi id="S4.T2.28.28.8.2.m1.1.1.2" xref="S4.T2.28.28.8.2.m1.1.1.2.cmml">Y</mi><mo id="S4.T2.28.28.8.2.m1.1.1.1" xref="S4.T2.28.28.8.2.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.T2.28.28.8.2.m1.1b"><apply id="S4.T2.28.28.8.2.m1.1.1.cmml" xref="S4.T2.28.28.8.2.m1.1.1"><ci id="S4.T2.28.28.8.2.m1.1.1.1.cmml" xref="S4.T2.28.28.8.2.m1.1.1.1">~</ci><ci id="S4.T2.28.28.8.2.m1.1.1.2.cmml" xref="S4.T2.28.28.8.2.m1.1.1.2">ğ‘Œ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.28.28.8.2.m1.1c">\tilde{Y}</annotation></semantics></math></td>
<td id="S4.T2.28.28.8.5" class="ltx_td ltx_align_center">unlabeled</td>
<td id="S4.T2.28.28.8.6" class="ltx_td ltx_align_center">distillation</td>
<td id="S4.T2.28.28.8.7" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T2.30.30.10" class="ltx_tr">
<td id="S4.T2.30.30.10.3" class="ltx_td ltx_align_center">MATH <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>
</td>
<td id="S4.T2.30.30.10.4" class="ltx_td ltx_align_center">CE, MH</td>
<td id="S4.T2.29.29.9.1" class="ltx_td ltx_align_center"><math id="S4.T2.29.29.9.1.m1.1" class="ltx_Math" alttext="\tilde{Y}" display="inline"><semantics id="S4.T2.29.29.9.1.m1.1a"><mover accent="true" id="S4.T2.29.29.9.1.m1.1.1" xref="S4.T2.29.29.9.1.m1.1.1.cmml"><mi id="S4.T2.29.29.9.1.m1.1.1.2" xref="S4.T2.29.29.9.1.m1.1.1.2.cmml">Y</mi><mo id="S4.T2.29.29.9.1.m1.1.1.1" xref="S4.T2.29.29.9.1.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.T2.29.29.9.1.m1.1b"><apply id="S4.T2.29.29.9.1.m1.1.1.cmml" xref="S4.T2.29.29.9.1.m1.1.1"><ci id="S4.T2.29.29.9.1.m1.1.1.1.cmml" xref="S4.T2.29.29.9.1.m1.1.1.1">~</ci><ci id="S4.T2.29.29.9.1.m1.1.1.2.cmml" xref="S4.T2.29.29.9.1.m1.1.1.2">ğ‘Œ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.29.29.9.1.m1.1c">\tilde{Y}</annotation></semantics></math></td>
<td id="S4.T2.30.30.10.2" class="ltx_td ltx_align_center"><math id="S4.T2.30.30.10.2.m1.1" class="ltx_Math" alttext="\tilde{Y}" display="inline"><semantics id="S4.T2.30.30.10.2.m1.1a"><mover accent="true" id="S4.T2.30.30.10.2.m1.1.1" xref="S4.T2.30.30.10.2.m1.1.1.cmml"><mi id="S4.T2.30.30.10.2.m1.1.1.2" xref="S4.T2.30.30.10.2.m1.1.1.2.cmml">Y</mi><mo id="S4.T2.30.30.10.2.m1.1.1.1" xref="S4.T2.30.30.10.2.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.T2.30.30.10.2.m1.1b"><apply id="S4.T2.30.30.10.2.m1.1.1.cmml" xref="S4.T2.30.30.10.2.m1.1.1"><ci id="S4.T2.30.30.10.2.m1.1.1.1.cmml" xref="S4.T2.30.30.10.2.m1.1.1.1">~</ci><ci id="S4.T2.30.30.10.2.m1.1.1.2.cmml" xref="S4.T2.30.30.10.2.m1.1.1.2">ğ‘Œ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.30.30.10.2.m1.1c">\tilde{Y}</annotation></semantics></math></td>
<td id="S4.T2.30.30.10.5" class="ltx_td ltx_align_center">labeled</td>
<td id="S4.T2.30.30.10.6" class="ltx_td ltx_align_center">distillation</td>
<td id="S4.T2.30.30.10.7" class="ltx_td ltx_align_center">distillation</td>
</tr>
<tr id="S4.T2.32.32.12" class="ltx_tr">
<td id="S4.T2.32.32.12.3" class="ltx_td ltx_align_center">CFD <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>
</td>
<td id="S4.T2.32.32.12.4" class="ltx_td ltx_align_center">CE, MH</td>
<td id="S4.T2.31.31.11.1" class="ltx_td ltx_align_center"><math id="S4.T2.31.31.11.1.m1.1" class="ltx_Math" alttext="\tilde{Y}" display="inline"><semantics id="S4.T2.31.31.11.1.m1.1a"><mover accent="true" id="S4.T2.31.31.11.1.m1.1.1" xref="S4.T2.31.31.11.1.m1.1.1.cmml"><mi id="S4.T2.31.31.11.1.m1.1.1.2" xref="S4.T2.31.31.11.1.m1.1.1.2.cmml">Y</mi><mo id="S4.T2.31.31.11.1.m1.1.1.1" xref="S4.T2.31.31.11.1.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.T2.31.31.11.1.m1.1b"><apply id="S4.T2.31.31.11.1.m1.1.1.cmml" xref="S4.T2.31.31.11.1.m1.1.1"><ci id="S4.T2.31.31.11.1.m1.1.1.1.cmml" xref="S4.T2.31.31.11.1.m1.1.1.1">~</ci><ci id="S4.T2.31.31.11.1.m1.1.1.2.cmml" xref="S4.T2.31.31.11.1.m1.1.1.2">ğ‘Œ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.31.31.11.1.m1.1c">\tilde{Y}</annotation></semantics></math></td>
<td id="S4.T2.32.32.12.2" class="ltx_td ltx_align_center"><math id="S4.T2.32.32.12.2.m1.1" class="ltx_Math" alttext="\tilde{Y}" display="inline"><semantics id="S4.T2.32.32.12.2.m1.1a"><mover accent="true" id="S4.T2.32.32.12.2.m1.1.1" xref="S4.T2.32.32.12.2.m1.1.1.cmml"><mi id="S4.T2.32.32.12.2.m1.1.1.2" xref="S4.T2.32.32.12.2.m1.1.1.2.cmml">Y</mi><mo id="S4.T2.32.32.12.2.m1.1.1.1" xref="S4.T2.32.32.12.2.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.T2.32.32.12.2.m1.1b"><apply id="S4.T2.32.32.12.2.m1.1.1.cmml" xref="S4.T2.32.32.12.2.m1.1.1"><ci id="S4.T2.32.32.12.2.m1.1.1.1.cmml" xref="S4.T2.32.32.12.2.m1.1.1.1">~</ci><ci id="S4.T2.32.32.12.2.m1.1.1.2.cmml" xref="S4.T2.32.32.12.2.m1.1.1.2">ğ‘Œ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.32.32.12.2.m1.1c">\tilde{Y}</annotation></semantics></math></td>
<td id="S4.T2.32.32.12.5" class="ltx_td ltx_align_center">unlabeled</td>
<td id="S4.T2.32.32.12.6" class="ltx_td ltx_align_center">distillation</td>
<td id="S4.T2.32.32.12.7" class="ltx_td ltx_align_center">distillation</td>
</tr>
<tr id="S4.T2.34.34.14" class="ltx_tr">
<td id="S4.T2.34.34.14.3" class="ltx_td ltx_align_center">FedGEMS <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>
</td>
<td id="S4.T2.34.34.14.4" class="ltx_td ltx_align_center">CE, MH</td>
<td id="S4.T2.33.33.13.1" class="ltx_td ltx_align_center"><math id="S4.T2.33.33.13.1.m1.1" class="ltx_Math" alttext="\tilde{Y}" display="inline"><semantics id="S4.T2.33.33.13.1.m1.1a"><mover accent="true" id="S4.T2.33.33.13.1.m1.1.1" xref="S4.T2.33.33.13.1.m1.1.1.cmml"><mi id="S4.T2.33.33.13.1.m1.1.1.2" xref="S4.T2.33.33.13.1.m1.1.1.2.cmml">Y</mi><mo id="S4.T2.33.33.13.1.m1.1.1.1" xref="S4.T2.33.33.13.1.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.T2.33.33.13.1.m1.1b"><apply id="S4.T2.33.33.13.1.m1.1.1.cmml" xref="S4.T2.33.33.13.1.m1.1.1"><ci id="S4.T2.33.33.13.1.m1.1.1.1.cmml" xref="S4.T2.33.33.13.1.m1.1.1.1">~</ci><ci id="S4.T2.33.33.13.1.m1.1.1.2.cmml" xref="S4.T2.33.33.13.1.m1.1.1.2">ğ‘Œ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.33.33.13.1.m1.1c">\tilde{Y}</annotation></semantics></math></td>
<td id="S4.T2.34.34.14.2" class="ltx_td ltx_align_center"><math id="S4.T2.34.34.14.2.m1.1" class="ltx_Math" alttext="\tilde{Y}" display="inline"><semantics id="S4.T2.34.34.14.2.m1.1a"><mover accent="true" id="S4.T2.34.34.14.2.m1.1.1" xref="S4.T2.34.34.14.2.m1.1.1.cmml"><mi id="S4.T2.34.34.14.2.m1.1.1.2" xref="S4.T2.34.34.14.2.m1.1.1.2.cmml">Y</mi><mo id="S4.T2.34.34.14.2.m1.1.1.1" xref="S4.T2.34.34.14.2.m1.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S4.T2.34.34.14.2.m1.1b"><apply id="S4.T2.34.34.14.2.m1.1.1.cmml" xref="S4.T2.34.34.14.2.m1.1.1"><ci id="S4.T2.34.34.14.2.m1.1.1.1.cmml" xref="S4.T2.34.34.14.2.m1.1.1.1">~</ci><ci id="S4.T2.34.34.14.2.m1.1.1.2.cmml" xref="S4.T2.34.34.14.2.m1.1.1.2">ğ‘Œ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.34.34.14.2.m1.1c">\tilde{Y}</annotation></semantics></math></td>
<td id="S4.T2.34.34.14.5" class="ltx_td ltx_align_center">labeled</td>
<td id="S4.T2.34.34.14.6" class="ltx_td ltx_align_center">distillation</td>
<td id="S4.T2.34.34.14.7" class="ltx_td ltx_align_center">distillation</td>
</tr>
<tr id="S4.T2.36.36.16" class="ltx_tr">
<td id="S4.T2.36.36.16.3" class="ltx_td ltx_align_center">FedAD <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>
</td>
<td id="S4.T2.36.36.16.4" class="ltx_td ltx_align_center">CE, MH</td>
<td id="S4.T2.36.36.16.2" class="ltx_td ltx_align_center">
<math id="S4.T2.35.35.15.1.m1.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S4.T2.35.35.15.1.m1.1a"><mi id="S4.T2.35.35.15.1.m1.1.1" xref="S4.T2.35.35.15.1.m1.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S4.T2.35.35.15.1.m1.1b"><ci id="S4.T2.35.35.15.1.m1.1.1.cmml" xref="S4.T2.35.35.15.1.m1.1.1">ğ‘§</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.35.35.15.1.m1.1c">z</annotation></semantics></math>, <math id="S4.T2.36.36.16.2.m2.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.T2.36.36.16.2.m2.1a"><mi id="S4.T2.36.36.16.2.m2.1.1" xref="S4.T2.36.36.16.2.m2.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.T2.36.36.16.2.m2.1b"><ci id="S4.T2.36.36.16.2.m2.1.1.cmml" xref="S4.T2.36.36.16.2.m2.1.1">ğ´</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.36.36.16.2.m2.1c">A</annotation></semantics></math>
</td>
<td id="S4.T2.36.36.16.5" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.36.36.16.6" class="ltx_td ltx_align_center">unlabeled</td>
<td id="S4.T2.36.36.16.7" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.36.36.16.8" class="ltx_td ltx_align_center">distillation</td>
</tr>
<tr id="S4.T2.38.38.18" class="ltx_tr">
<td id="S4.T2.38.38.18.3" class="ltx_td ltx_align_center">FedGKT <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>
</td>
<td id="S4.T2.38.38.18.4" class="ltx_td ltx_align_center">CE, MH</td>
<td id="S4.T2.37.37.17.1" class="ltx_td ltx_align_center"><math id="S4.T2.37.37.17.1.m1.3" class="ltx_Math" alttext="z,H,Y" display="inline"><semantics id="S4.T2.37.37.17.1.m1.3a"><mrow id="S4.T2.37.37.17.1.m1.3.4.2" xref="S4.T2.37.37.17.1.m1.3.4.1.cmml"><mi id="S4.T2.37.37.17.1.m1.1.1" xref="S4.T2.37.37.17.1.m1.1.1.cmml">z</mi><mo id="S4.T2.37.37.17.1.m1.3.4.2.1" xref="S4.T2.37.37.17.1.m1.3.4.1.cmml">,</mo><mi id="S4.T2.37.37.17.1.m1.2.2" xref="S4.T2.37.37.17.1.m1.2.2.cmml">H</mi><mo id="S4.T2.37.37.17.1.m1.3.4.2.2" xref="S4.T2.37.37.17.1.m1.3.4.1.cmml">,</mo><mi id="S4.T2.37.37.17.1.m1.3.3" xref="S4.T2.37.37.17.1.m1.3.3.cmml">Y</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.37.37.17.1.m1.3b"><list id="S4.T2.37.37.17.1.m1.3.4.1.cmml" xref="S4.T2.37.37.17.1.m1.3.4.2"><ci id="S4.T2.37.37.17.1.m1.1.1.cmml" xref="S4.T2.37.37.17.1.m1.1.1">ğ‘§</ci><ci id="S4.T2.37.37.17.1.m1.2.2.cmml" xref="S4.T2.37.37.17.1.m1.2.2">ğ»</ci><ci id="S4.T2.37.37.17.1.m1.3.3.cmml" xref="S4.T2.37.37.17.1.m1.3.3">ğ‘Œ</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.37.37.17.1.m1.3c">z,H,Y</annotation></semantics></math></td>
<td id="S4.T2.38.38.18.2" class="ltx_td ltx_align_center"><math id="S4.T2.38.38.18.2.m1.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S4.T2.38.38.18.2.m1.1a"><mi id="S4.T2.38.38.18.2.m1.1.1" xref="S4.T2.38.38.18.2.m1.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S4.T2.38.38.18.2.m1.1b"><ci id="S4.T2.38.38.18.2.m1.1.1.cmml" xref="S4.T2.38.38.18.2.m1.1.1">ğ‘§</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.38.38.18.2.m1.1c">z</annotation></semantics></math></td>
<td id="S4.T2.38.38.18.5" class="ltx_td ltx_align_center">data-free</td>
<td id="S4.T2.38.38.18.6" class="ltx_td ltx_align_center">regularizer</td>
<td id="S4.T2.38.38.18.7" class="ltx_td ltx_align_center">regularizer</td>
</tr>
<tr id="S4.T2.40.40.20" class="ltx_tr">
<td id="S4.T2.40.40.20.3" class="ltx_td ltx_align_center">FedDKC <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>
</td>
<td id="S4.T2.40.40.20.4" class="ltx_td ltx_align_center">CE, MH</td>
<td id="S4.T2.39.39.19.1" class="ltx_td ltx_align_center"><math id="S4.T2.39.39.19.1.m1.3" class="ltx_Math" alttext="z,H,Y" display="inline"><semantics id="S4.T2.39.39.19.1.m1.3a"><mrow id="S4.T2.39.39.19.1.m1.3.4.2" xref="S4.T2.39.39.19.1.m1.3.4.1.cmml"><mi id="S4.T2.39.39.19.1.m1.1.1" xref="S4.T2.39.39.19.1.m1.1.1.cmml">z</mi><mo id="S4.T2.39.39.19.1.m1.3.4.2.1" xref="S4.T2.39.39.19.1.m1.3.4.1.cmml">,</mo><mi id="S4.T2.39.39.19.1.m1.2.2" xref="S4.T2.39.39.19.1.m1.2.2.cmml">H</mi><mo id="S4.T2.39.39.19.1.m1.3.4.2.2" xref="S4.T2.39.39.19.1.m1.3.4.1.cmml">,</mo><mi id="S4.T2.39.39.19.1.m1.3.3" xref="S4.T2.39.39.19.1.m1.3.3.cmml">Y</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.39.39.19.1.m1.3b"><list id="S4.T2.39.39.19.1.m1.3.4.1.cmml" xref="S4.T2.39.39.19.1.m1.3.4.2"><ci id="S4.T2.39.39.19.1.m1.1.1.cmml" xref="S4.T2.39.39.19.1.m1.1.1">ğ‘§</ci><ci id="S4.T2.39.39.19.1.m1.2.2.cmml" xref="S4.T2.39.39.19.1.m1.2.2">ğ»</ci><ci id="S4.T2.39.39.19.1.m1.3.3.cmml" xref="S4.T2.39.39.19.1.m1.3.3">ğ‘Œ</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.39.39.19.1.m1.3c">z,H,Y</annotation></semantics></math></td>
<td id="S4.T2.40.40.20.2" class="ltx_td ltx_align_center"><math id="S4.T2.40.40.20.2.m1.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S4.T2.40.40.20.2.m1.1a"><mi id="S4.T2.40.40.20.2.m1.1.1" xref="S4.T2.40.40.20.2.m1.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S4.T2.40.40.20.2.m1.1b"><ci id="S4.T2.40.40.20.2.m1.1.1.cmml" xref="S4.T2.40.40.20.2.m1.1.1">ğ‘§</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.40.40.20.2.m1.1c">z</annotation></semantics></math></td>
<td id="S4.T2.40.40.20.5" class="ltx_td ltx_align_center">data-free</td>
<td id="S4.T2.40.40.20.6" class="ltx_td ltx_align_center">regularizer</td>
<td id="S4.T2.40.40.20.7" class="ltx_td ltx_align_center">regularizer</td>
</tr>
<tr id="S4.T2.42.42.22" class="ltx_tr">
<td id="S4.T2.42.42.22.3" class="ltx_td ltx_align_center">FedDF <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>
</td>
<td id="S4.T2.42.42.22.4" class="ltx_td ltx_align_center">MH, NIID, A</td>
<td id="S4.T2.41.41.21.1" class="ltx_td ltx_align_center"><math id="S4.T2.41.41.21.1.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.T2.41.41.21.1.m1.1a"><mi id="S4.T2.41.41.21.1.m1.1.1" xref="S4.T2.41.41.21.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.T2.41.41.21.1.m1.1b"><ci id="S4.T2.41.41.21.1.m1.1.1.cmml" xref="S4.T2.41.41.21.1.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.41.41.21.1.m1.1c">w</annotation></semantics></math></td>
<td id="S4.T2.42.42.22.2" class="ltx_td ltx_align_center"><math id="S4.T2.42.42.22.2.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.T2.42.42.22.2.m1.1a"><mi id="S4.T2.42.42.22.2.m1.1.1" xref="S4.T2.42.42.22.2.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.T2.42.42.22.2.m1.1b"><ci id="S4.T2.42.42.22.2.m1.1.1.cmml" xref="S4.T2.42.42.22.2.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.42.42.22.2.m1.1c">w</annotation></semantics></math></td>
<td id="S4.T2.42.42.22.5" class="ltx_td ltx_align_center">unlabeled</td>
<td id="S4.T2.42.42.22.6" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.42.42.22.7" class="ltx_td ltx_align_center">distillation</td>
</tr>
<tr id="S4.T2.44.44.24" class="ltx_tr">
<td id="S4.T2.44.44.24.3" class="ltx_td ltx_align_center">FedAUX <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>
</td>
<td id="S4.T2.44.44.24.4" class="ltx_td ltx_align_center">MH, NIID, A</td>
<td id="S4.T2.43.43.23.1" class="ltx_td ltx_align_center"><math id="S4.T2.43.43.23.1.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.T2.43.43.23.1.m1.1a"><mi id="S4.T2.43.43.23.1.m1.1.1" xref="S4.T2.43.43.23.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.T2.43.43.23.1.m1.1b"><ci id="S4.T2.43.43.23.1.m1.1.1.cmml" xref="S4.T2.43.43.23.1.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.43.43.23.1.m1.1c">w</annotation></semantics></math></td>
<td id="S4.T2.44.44.24.2" class="ltx_td ltx_align_center"><math id="S4.T2.44.44.24.2.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.T2.44.44.24.2.m1.1a"><mi id="S4.T2.44.44.24.2.m1.1.1" xref="S4.T2.44.44.24.2.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.T2.44.44.24.2.m1.1b"><ci id="S4.T2.44.44.24.2.m1.1.1.cmml" xref="S4.T2.44.44.24.2.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.44.44.24.2.m1.1c">w</annotation></semantics></math></td>
<td id="S4.T2.44.44.24.5" class="ltx_td ltx_align_center">unlabeled</td>
<td id="S4.T2.44.44.24.6" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.44.44.24.7" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T2.46.46.26" class="ltx_tr">
<td id="S4.T2.46.46.26.3" class="ltx_td ltx_align_center">FedBE <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>
</td>
<td id="S4.T2.46.46.26.4" class="ltx_td ltx_align_center">NIID, A</td>
<td id="S4.T2.45.45.25.1" class="ltx_td ltx_align_center"><math id="S4.T2.45.45.25.1.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.T2.45.45.25.1.m1.1a"><mi id="S4.T2.45.45.25.1.m1.1.1" xref="S4.T2.45.45.25.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.T2.45.45.25.1.m1.1b"><ci id="S4.T2.45.45.25.1.m1.1.1.cmml" xref="S4.T2.45.45.25.1.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.45.45.25.1.m1.1c">w</annotation></semantics></math></td>
<td id="S4.T2.46.46.26.2" class="ltx_td ltx_align_center"><math id="S4.T2.46.46.26.2.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.T2.46.46.26.2.m1.1a"><mi id="S4.T2.46.46.26.2.m1.1.1" xref="S4.T2.46.46.26.2.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.T2.46.46.26.2.m1.1b"><ci id="S4.T2.46.46.26.2.m1.1.1.cmml" xref="S4.T2.46.46.26.2.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.46.46.26.2.m1.1c">w</annotation></semantics></math></td>
<td id="S4.T2.46.46.26.5" class="ltx_td ltx_align_center">unlabeled</td>
<td id="S4.T2.46.46.26.6" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.46.46.26.7" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T2.48.48.28" class="ltx_tr">
<td id="S4.T2.48.48.28.3" class="ltx_td ltx_align_center">FedFTG <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>
</td>
<td id="S4.T2.48.48.28.4" class="ltx_td ltx_align_center">NIID, A</td>
<td id="S4.T2.47.47.27.1" class="ltx_td ltx_align_center"><math id="S4.T2.47.47.27.1.m1.2" class="ltx_Math" alttext="w,c" display="inline"><semantics id="S4.T2.47.47.27.1.m1.2a"><mrow id="S4.T2.47.47.27.1.m1.2.3.2" xref="S4.T2.47.47.27.1.m1.2.3.1.cmml"><mi id="S4.T2.47.47.27.1.m1.1.1" xref="S4.T2.47.47.27.1.m1.1.1.cmml">w</mi><mo id="S4.T2.47.47.27.1.m1.2.3.2.1" xref="S4.T2.47.47.27.1.m1.2.3.1.cmml">,</mo><mi id="S4.T2.47.47.27.1.m1.2.2" xref="S4.T2.47.47.27.1.m1.2.2.cmml">c</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.47.47.27.1.m1.2b"><list id="S4.T2.47.47.27.1.m1.2.3.1.cmml" xref="S4.T2.47.47.27.1.m1.2.3.2"><ci id="S4.T2.47.47.27.1.m1.1.1.cmml" xref="S4.T2.47.47.27.1.m1.1.1">ğ‘¤</ci><ci id="S4.T2.47.47.27.1.m1.2.2.cmml" xref="S4.T2.47.47.27.1.m1.2.2">ğ‘</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.47.47.27.1.m1.2c">w,c</annotation></semantics></math></td>
<td id="S4.T2.48.48.28.2" class="ltx_td ltx_align_center"><math id="S4.T2.48.48.28.2.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.T2.48.48.28.2.m1.1a"><mi id="S4.T2.48.48.28.2.m1.1.1" xref="S4.T2.48.48.28.2.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.T2.48.48.28.2.m1.1b"><ci id="S4.T2.48.48.28.2.m1.1.1.cmml" xref="S4.T2.48.48.28.2.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.48.48.28.2.m1.1c">w</annotation></semantics></math></td>
<td id="S4.T2.48.48.28.5" class="ltx_td ltx_align_center">data-free</td>
<td id="S4.T2.48.48.28.6" class="ltx_td ltx_align_center">-</td>
<td id="S4.T2.48.48.28.7" class="ltx_td ltx_align_center">generator</td>
</tr>
<tr id="S4.T2.50.50.30" class="ltx_tr">
<td id="S4.T2.50.50.30.3" class="ltx_td ltx_align_center">FedGKD <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>
</td>
<td id="S4.T2.50.50.30.4" class="ltx_td ltx_align_center">NIID, CD</td>
<td id="S4.T2.49.49.29.1" class="ltx_td ltx_align_center"><math id="S4.T2.49.49.29.1.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.T2.49.49.29.1.m1.1a"><mi id="S4.T2.49.49.29.1.m1.1.1" xref="S4.T2.49.49.29.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.T2.49.49.29.1.m1.1b"><ci id="S4.T2.49.49.29.1.m1.1.1.cmml" xref="S4.T2.49.49.29.1.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.49.49.29.1.m1.1c">w</annotation></semantics></math></td>
<td id="S4.T2.50.50.30.2" class="ltx_td ltx_align_center"><math id="S4.T2.50.50.30.2.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.T2.50.50.30.2.m1.1a"><mi id="S4.T2.50.50.30.2.m1.1.1" xref="S4.T2.50.50.30.2.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.T2.50.50.30.2.m1.1b"><ci id="S4.T2.50.50.30.2.m1.1.1.cmml" xref="S4.T2.50.50.30.2.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.50.50.30.2.m1.1c">w</annotation></semantics></math></td>
<td id="S4.T2.50.50.30.5" class="ltx_td ltx_align_center">data-free</td>
<td id="S4.T2.50.50.30.6" class="ltx_td ltx_align_center">regularizer</td>
<td id="S4.T2.50.50.30.7" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T2.52.52.32" class="ltx_tr">
<td id="S4.T2.52.52.32.3" class="ltx_td ltx_align_center">FedNTD <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>
</td>
<td id="S4.T2.52.52.32.4" class="ltx_td ltx_align_center">NIID, CD</td>
<td id="S4.T2.51.51.31.1" class="ltx_td ltx_align_center"><math id="S4.T2.51.51.31.1.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.T2.51.51.31.1.m1.1a"><mi id="S4.T2.51.51.31.1.m1.1.1" xref="S4.T2.51.51.31.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.T2.51.51.31.1.m1.1b"><ci id="S4.T2.51.51.31.1.m1.1.1.cmml" xref="S4.T2.51.51.31.1.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.51.51.31.1.m1.1c">w</annotation></semantics></math></td>
<td id="S4.T2.52.52.32.2" class="ltx_td ltx_align_center"><math id="S4.T2.52.52.32.2.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.T2.52.52.32.2.m1.1a"><mi id="S4.T2.52.52.32.2.m1.1.1" xref="S4.T2.52.52.32.2.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.T2.52.52.32.2.m1.1b"><ci id="S4.T2.52.52.32.2.m1.1.1.cmml" xref="S4.T2.52.52.32.2.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.52.52.32.2.m1.1c">w</annotation></semantics></math></td>
<td id="S4.T2.52.52.32.5" class="ltx_td ltx_align_center">data-free</td>
<td id="S4.T2.52.52.32.6" class="ltx_td ltx_align_center">regularizer</td>
<td id="S4.T2.52.52.32.7" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T2.54.54.34" class="ltx_tr">
<td id="S4.T2.54.54.34.3" class="ltx_td ltx_align_center">FedCAD <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>
</td>
<td id="S4.T2.54.54.34.4" class="ltx_td ltx_align_center">NIID, CD</td>
<td id="S4.T2.53.53.33.1" class="ltx_td ltx_align_center"><math id="S4.T2.53.53.33.1.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.T2.53.53.33.1.m1.1a"><mi id="S4.T2.53.53.33.1.m1.1.1" xref="S4.T2.53.53.33.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.T2.53.53.33.1.m1.1b"><ci id="S4.T2.53.53.33.1.m1.1.1.cmml" xref="S4.T2.53.53.33.1.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.53.53.33.1.m1.1c">w</annotation></semantics></math></td>
<td id="S4.T2.54.54.34.2" class="ltx_td ltx_align_center"><math id="S4.T2.54.54.34.2.m1.2" class="ltx_Math" alttext="w,\alpha_{y}" display="inline"><semantics id="S4.T2.54.54.34.2.m1.2a"><mrow id="S4.T2.54.54.34.2.m1.2.2.1" xref="S4.T2.54.54.34.2.m1.2.2.2.cmml"><mi id="S4.T2.54.54.34.2.m1.1.1" xref="S4.T2.54.54.34.2.m1.1.1.cmml">w</mi><mo id="S4.T2.54.54.34.2.m1.2.2.1.2" xref="S4.T2.54.54.34.2.m1.2.2.2.cmml">,</mo><msub id="S4.T2.54.54.34.2.m1.2.2.1.1" xref="S4.T2.54.54.34.2.m1.2.2.1.1.cmml"><mi id="S4.T2.54.54.34.2.m1.2.2.1.1.2" xref="S4.T2.54.54.34.2.m1.2.2.1.1.2.cmml">Î±</mi><mi id="S4.T2.54.54.34.2.m1.2.2.1.1.3" xref="S4.T2.54.54.34.2.m1.2.2.1.1.3.cmml">y</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.54.54.34.2.m1.2b"><list id="S4.T2.54.54.34.2.m1.2.2.2.cmml" xref="S4.T2.54.54.34.2.m1.2.2.1"><ci id="S4.T2.54.54.34.2.m1.1.1.cmml" xref="S4.T2.54.54.34.2.m1.1.1">ğ‘¤</ci><apply id="S4.T2.54.54.34.2.m1.2.2.1.1.cmml" xref="S4.T2.54.54.34.2.m1.2.2.1.1"><csymbol cd="ambiguous" id="S4.T2.54.54.34.2.m1.2.2.1.1.1.cmml" xref="S4.T2.54.54.34.2.m1.2.2.1.1">subscript</csymbol><ci id="S4.T2.54.54.34.2.m1.2.2.1.1.2.cmml" xref="S4.T2.54.54.34.2.m1.2.2.1.1.2">ğ›¼</ci><ci id="S4.T2.54.54.34.2.m1.2.2.1.1.3.cmml" xref="S4.T2.54.54.34.2.m1.2.2.1.1.3">ğ‘¦</ci></apply></list></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.54.54.34.2.m1.2c">w,\alpha_{y}</annotation></semantics></math></td>
<td id="S4.T2.54.54.34.5" class="ltx_td ltx_align_center">labeled</td>
<td id="S4.T2.54.54.34.6" class="ltx_td ltx_align_center">regularizer</td>
<td id="S4.T2.54.54.34.7" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T2.56.56.36" class="ltx_tr">
<td id="S4.T2.56.56.36.3" class="ltx_td ltx_align_center">FedSSD <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>
</td>
<td id="S4.T2.56.56.36.4" class="ltx_td ltx_align_center">NIID, CD</td>
<td id="S4.T2.55.55.35.1" class="ltx_td ltx_align_center"><math id="S4.T2.55.55.35.1.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.T2.55.55.35.1.m1.1a"><mi id="S4.T2.55.55.35.1.m1.1.1" xref="S4.T2.55.55.35.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.T2.55.55.35.1.m1.1b"><ci id="S4.T2.55.55.35.1.m1.1.1.cmml" xref="S4.T2.55.55.35.1.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.55.55.35.1.m1.1c">w</annotation></semantics></math></td>
<td id="S4.T2.56.56.36.2" class="ltx_td ltx_align_center"><math id="S4.T2.56.56.36.2.m1.2" class="ltx_Math" alttext="w,C" display="inline"><semantics id="S4.T2.56.56.36.2.m1.2a"><mrow id="S4.T2.56.56.36.2.m1.2.3.2" xref="S4.T2.56.56.36.2.m1.2.3.1.cmml"><mi id="S4.T2.56.56.36.2.m1.1.1" xref="S4.T2.56.56.36.2.m1.1.1.cmml">w</mi><mo id="S4.T2.56.56.36.2.m1.2.3.2.1" xref="S4.T2.56.56.36.2.m1.2.3.1.cmml">,</mo><mi id="S4.T2.56.56.36.2.m1.2.2" xref="S4.T2.56.56.36.2.m1.2.2.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.56.56.36.2.m1.2b"><list id="S4.T2.56.56.36.2.m1.2.3.1.cmml" xref="S4.T2.56.56.36.2.m1.2.3.2"><ci id="S4.T2.56.56.36.2.m1.1.1.cmml" xref="S4.T2.56.56.36.2.m1.1.1">ğ‘¤</ci><ci id="S4.T2.56.56.36.2.m1.2.2.cmml" xref="S4.T2.56.56.36.2.m1.2.2">ğ¶</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.56.56.36.2.m1.2c">w,C</annotation></semantics></math></td>
<td id="S4.T2.56.56.36.5" class="ltx_td ltx_align_center">labeled</td>
<td id="S4.T2.56.56.36.6" class="ltx_td ltx_align_center">regularizer</td>
<td id="S4.T2.56.56.36.7" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T2.58.58.38" class="ltx_tr">
<td id="S4.T2.58.58.38.3" class="ltx_td ltx_align_center">FedMLB<cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>
</td>
<td id="S4.T2.58.58.38.4" class="ltx_td ltx_align_center">NIID, CD</td>
<td id="S4.T2.57.57.37.1" class="ltx_td ltx_align_center"><math id="S4.T2.57.57.37.1.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.T2.57.57.37.1.m1.1a"><mi id="S4.T2.57.57.37.1.m1.1.1" xref="S4.T2.57.57.37.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.T2.57.57.37.1.m1.1b"><ci id="S4.T2.57.57.37.1.m1.1.1.cmml" xref="S4.T2.57.57.37.1.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.57.57.37.1.m1.1c">w</annotation></semantics></math></td>
<td id="S4.T2.58.58.38.2" class="ltx_td ltx_align_center"><math id="S4.T2.58.58.38.2.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.T2.58.58.38.2.m1.1a"><mi id="S4.T2.58.58.38.2.m1.1.1" xref="S4.T2.58.58.38.2.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.T2.58.58.38.2.m1.1b"><ci id="S4.T2.58.58.38.2.m1.1.1.cmml" xref="S4.T2.58.58.38.2.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.58.58.38.2.m1.1c">w</annotation></semantics></math></td>
<td id="S4.T2.58.58.38.5" class="ltx_td ltx_align_center">data-free</td>
<td id="S4.T2.58.58.38.6" class="ltx_td ltx_align_center">regularizer</td>
<td id="S4.T2.58.58.38.7" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T2.61.61.41" class="ltx_tr">
<td id="S4.T2.59.59.39.1" class="ltx_td ltx_align_center">FedDistill<sup id="S4.T2.59.59.39.1.1" class="ltx_sup"><span id="S4.T2.59.59.39.1.1.1" class="ltx_text ltx_font_italic">+</span></sup> <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>
</td>
<td id="S4.T2.61.61.41.4" class="ltx_td ltx_align_center">NIID, CD</td>
<td id="S4.T2.60.60.40.2" class="ltx_td ltx_align_center"><math id="S4.T2.60.60.40.2.m1.2" class="ltx_Math" alttext="w,Z" display="inline"><semantics id="S4.T2.60.60.40.2.m1.2a"><mrow id="S4.T2.60.60.40.2.m1.2.3.2" xref="S4.T2.60.60.40.2.m1.2.3.1.cmml"><mi id="S4.T2.60.60.40.2.m1.1.1" xref="S4.T2.60.60.40.2.m1.1.1.cmml">w</mi><mo id="S4.T2.60.60.40.2.m1.2.3.2.1" xref="S4.T2.60.60.40.2.m1.2.3.1.cmml">,</mo><mi id="S4.T2.60.60.40.2.m1.2.2" xref="S4.T2.60.60.40.2.m1.2.2.cmml">Z</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.60.60.40.2.m1.2b"><list id="S4.T2.60.60.40.2.m1.2.3.1.cmml" xref="S4.T2.60.60.40.2.m1.2.3.2"><ci id="S4.T2.60.60.40.2.m1.1.1.cmml" xref="S4.T2.60.60.40.2.m1.1.1">ğ‘¤</ci><ci id="S4.T2.60.60.40.2.m1.2.2.cmml" xref="S4.T2.60.60.40.2.m1.2.2">ğ‘</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.60.60.40.2.m1.2c">w,Z</annotation></semantics></math></td>
<td id="S4.T2.61.61.41.3" class="ltx_td ltx_align_center"><math id="S4.T2.61.61.41.3.m1.2" class="ltx_Math" alttext="w,Z" display="inline"><semantics id="S4.T2.61.61.41.3.m1.2a"><mrow id="S4.T2.61.61.41.3.m1.2.3.2" xref="S4.T2.61.61.41.3.m1.2.3.1.cmml"><mi id="S4.T2.61.61.41.3.m1.1.1" xref="S4.T2.61.61.41.3.m1.1.1.cmml">w</mi><mo id="S4.T2.61.61.41.3.m1.2.3.2.1" xref="S4.T2.61.61.41.3.m1.2.3.1.cmml">,</mo><mi id="S4.T2.61.61.41.3.m1.2.2" xref="S4.T2.61.61.41.3.m1.2.2.cmml">Z</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.61.61.41.3.m1.2b"><list id="S4.T2.61.61.41.3.m1.2.3.1.cmml" xref="S4.T2.61.61.41.3.m1.2.3.2"><ci id="S4.T2.61.61.41.3.m1.1.1.cmml" xref="S4.T2.61.61.41.3.m1.1.1">ğ‘¤</ci><ci id="S4.T2.61.61.41.3.m1.2.2.cmml" xref="S4.T2.61.61.41.3.m1.2.2">ğ‘</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.61.61.41.3.m1.2c">w,Z</annotation></semantics></math></td>
<td id="S4.T2.61.61.41.5" class="ltx_td ltx_align_center">data-free</td>
<td id="S4.T2.61.61.41.6" class="ltx_td ltx_align_center">regularizer</td>
<td id="S4.T2.61.61.41.7" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T2.63.63.43" class="ltx_tr">
<td id="S4.T2.63.63.43.3" class="ltx_td ltx_align_center">FedGen <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>
</td>
<td id="S4.T2.63.63.43.4" class="ltx_td ltx_align_center">NIID, CD</td>
<td id="S4.T2.62.62.42.1" class="ltx_td ltx_align_center"><math id="S4.T2.62.62.42.1.m1.2" class="ltx_Math" alttext="w,c" display="inline"><semantics id="S4.T2.62.62.42.1.m1.2a"><mrow id="S4.T2.62.62.42.1.m1.2.3.2" xref="S4.T2.62.62.42.1.m1.2.3.1.cmml"><mi id="S4.T2.62.62.42.1.m1.1.1" xref="S4.T2.62.62.42.1.m1.1.1.cmml">w</mi><mo id="S4.T2.62.62.42.1.m1.2.3.2.1" xref="S4.T2.62.62.42.1.m1.2.3.1.cmml">,</mo><mi id="S4.T2.62.62.42.1.m1.2.2" xref="S4.T2.62.62.42.1.m1.2.2.cmml">c</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.T2.62.62.42.1.m1.2b"><list id="S4.T2.62.62.42.1.m1.2.3.1.cmml" xref="S4.T2.62.62.42.1.m1.2.3.2"><ci id="S4.T2.62.62.42.1.m1.1.1.cmml" xref="S4.T2.62.62.42.1.m1.1.1">ğ‘¤</ci><ci id="S4.T2.62.62.42.1.m1.2.2.cmml" xref="S4.T2.62.62.42.1.m1.2.2">ğ‘</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.62.62.42.1.m1.2c">w,c</annotation></semantics></math></td>
<td id="S4.T2.63.63.43.2" class="ltx_td ltx_align_center"><math id="S4.T2.63.63.43.2.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.T2.63.63.43.2.m1.1a"><mi id="S4.T2.63.63.43.2.m1.1.1" xref="S4.T2.63.63.43.2.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.T2.63.63.43.2.m1.1b"><ci id="S4.T2.63.63.43.2.m1.1.1.cmml" xref="S4.T2.63.63.43.2.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.63.63.43.2.m1.1c">w</annotation></semantics></math></td>
<td id="S4.T2.63.63.43.5" class="ltx_td ltx_align_center">data-free</td>
<td id="S4.T2.63.63.43.6" class="ltx_td ltx_align_center">generator</td>
<td id="S4.T2.63.63.43.7" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="S4.T2.65.65.45" class="ltx_tr">
<td id="S4.T2.65.65.45.3" class="ltx_td ltx_align_center ltx_border_bb">FedZKT <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>
</td>
<td id="S4.T2.65.65.45.4" class="ltx_td ltx_align_center ltx_border_bb">NIID, CD</td>
<td id="S4.T2.64.64.44.1" class="ltx_td ltx_align_center ltx_border_bb"><math id="S4.T2.64.64.44.1.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.T2.64.64.44.1.m1.1a"><mi id="S4.T2.64.64.44.1.m1.1.1" xref="S4.T2.64.64.44.1.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.T2.64.64.44.1.m1.1b"><ci id="S4.T2.64.64.44.1.m1.1.1.cmml" xref="S4.T2.64.64.44.1.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.64.64.44.1.m1.1c">w</annotation></semantics></math></td>
<td id="S4.T2.65.65.45.2" class="ltx_td ltx_align_center ltx_border_bb"><math id="S4.T2.65.65.45.2.m1.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S4.T2.65.65.45.2.m1.1a"><mi id="S4.T2.65.65.45.2.m1.1.1" xref="S4.T2.65.65.45.2.m1.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S4.T2.65.65.45.2.m1.1b"><ci id="S4.T2.65.65.45.2.m1.1.1.cmml" xref="S4.T2.65.65.45.2.m1.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T2.65.65.45.2.m1.1c">w</annotation></semantics></math></td>
<td id="S4.T2.65.65.45.5" class="ltx_td ltx_align_center ltx_border_bb">data-free</td>
<td id="S4.T2.65.65.45.6" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="S4.T2.65.65.45.7" class="ltx_td ltx_align_center ltx_border_bb">generator</td>
</tr>
</tbody>
</table>
</figure>
<div id="S4.p1" class="ltx_para ltx_noindent">
<p id="S4.p1.1" class="ltx_p">Table <a href="#S4.T2" title="Table 2 â€£ 4 Comparison of Existing Solutions and Adoption Guidelines â€£ Knowledge Distillation for Federated Learning: a Practical Guide" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> lists the solutions reviewed in this paper, by classifying them according to their primary aim, and by detailing the kind of per-round exchanged information, the need of auxiliary data, and the type of KD involved. In short, the main take away from Table <a href="#S4.T2" title="Table 2 â€£ 4 Comparison of Existing Solutions and Adoption Guidelines â€£ Knowledge Distillation for Federated Learning: a Practical Guide" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> is that KD-based FL solutions can enhance collaborative learning under some perspectives while introducing other trade-offs to consider for an appropriate selection and adoption.</p>
</div>
<section id="S4.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Model-agnostic FL via KD.</h5>

<div id="S4.SS0.SSS0.Px1.p1" class="ltx_para ltx_noindent">
<p id="S4.SS0.SSS0.Px1.p1.1" class="ltx_p">Federated adaptations of co-distillation can enable model heterogeneity, and can reduce the communication requirements at the cost of computation overhead with respect to parameter-based schemes. Hence, despite being extremely communication efficient, it may be not always possible to deploy such algorithms on resource-constrained devices due to the overhead of client-side distillation (in Table <a href="#S4.T2" title="Table 2 â€£ 4 Comparison of Existing Solutions and Adoption Guidelines â€£ Knowledge Distillation for Federated Learning: a Practical Guide" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, solutions which use <span id="S4.SS0.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_italic">distillation</span> at client side), while being a suitable model-agnostic alternative for cross-silo settings.<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>For example, in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> 80000 data points from a public dataset are used to distill on-device model before local training.</span></span></span> Furthermore, this class of solutions usually performs worse than FedAvg-based baselines (in terms of global model accuracy) <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite> â€“ even though they typically improve the performance of non-collaborative training <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. Moreover, most works in this category suppose the existence of a semantically-similar proxy dataset (in some cases even labeled), which may be an unrealistic assumption in some deployment scenarios and use cases (e.g., for specific medical applications). The pioneering communication-efficient data-free strategy in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> does not incur in local computation overhead, but it is far from achieving global model test accuracy comparable to FedAvg, as demonstrated in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, also disclosing possible privacy-sensitive information about private data (i.e., per-label model outputs). Solutions as <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> enable model heterogeneity, are usually more communication efficient than FedAvg, and include resource-constrained devices in the federation, by adopting a split-learning paradigm and by taking advantage of KD-based regularization. However, as shown in Table <a href="#S4.T2" title="Table 2 â€£ 4 Comparison of Existing Solutions and Adoption Guidelines â€£ Knowledge Distillation for Federated Learning: a Practical Guide" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, due to their split-learning approach, the solutions in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> disclose local ground-truth labels, which again may incur in privacy violation. While some seminal efforts are recently emerging in the literature <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, model-agnostic KD-based strategies for collaborative learning are poorly understood theoretically, calling for analysis of convergence properties as happened for parameter-based schemes <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Data-distribution-agnostic FL via KD.</h5>

<div id="S4.SS0.SSS0.Px2.p1" class="ltx_para ltx_noindent">
<p id="S4.SS0.SSS0.Px2.p1.1" class="ltx_p">For what relates to the solutions to tackle non-IIDness, KD-based server-side refinement strategies such as <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> can improve FedAvg global model performance in presence of highly heterogeneous data when semantically-similar unlabeled proxy data are available. It is worth noting that this class of algorithms exhibits most improvements when several local epochs are performed between communication rounds and client models tend to drift apart. Data-free generator models can also be used to perform server-side global model corrections as in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite> or to limit client drift directly at the participating devices as in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>, in both cases at the cost of disclosing local label count. No additional information has to be disclosed from clients and not even proxy data are needed in solutions that regularize local training by employing global model output on local data, as in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>. In addition, this set of strategies do not introduce significant on-device computation overhead and has the same communication requirements as FedAvg.<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>If FedGKD <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> only considers the current global model as its historical model.</span></span></span> If limited labeled proxy data are available, local global knowledge distillation can be improved as in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. When moderate computing overhead is sustainable, local global distillation can be enhanced by using intermediate features and hybrid pathways as in <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, thus significantly improving the performance of the FedAvg global model in presence of highly heterogeneous data.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para ltx_noindent">
<p id="S5.p1.1" class="ltx_p">While distributed adaptations of co-distillation have been initially introduced as a mean for both reducing the communication cost of FedAvg-like algorithms and enabling model heterogeneity, KD has been recently explored to tackle non-IIDness, either rectifying the aggregation phase of FedAvg or directly limiting the client drift. This paper reviews and compares state-of-the-art KD-based techniques for FL, by classifying them according to their purpose and the way to achieve it. We believe that the presented comparison can provide researchers and practitioners in the field with a practical and useful guide to the primary pros/cons of existing solutions, as well as with practical guidelines for the selection of the most appropriate technique depending on the application case and for the identification of still open research challenges for the near future.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Acar etÂ al. [2021]</span>
<span class="ltx_bibblock">
Durmus AlpÂ Emre Acar, Yue Zhao, RamonÂ Matas Navarro, Matthew Mattina, PaulÂ N
Whatmough, and Venkatesh Saligrama.

</span>
<span class="ltx_bibblock">Federated learning based on dynamic regularization.

</span>
<span class="ltx_bibblock"><em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2111.04263</em>, 2021.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Afonin and Karimireddy [2021]</span>
<span class="ltx_bibblock">
Andrei Afonin and SaiÂ Praneeth Karimireddy.

</span>
<span class="ltx_bibblock">Towards model agnostic federated learning using knowledge
distillation.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.15210</em>, 2021.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anil etÂ al. [2018]</span>
<span class="ltx_bibblock">
Rohan Anil, Gabriel Pereyra, Alexandre Passos, Robert Ormandi, GeorgeÂ E Dahl,
and GeoffreyÂ E Hinton.

</span>
<span class="ltx_bibblock">Large scale distributed neural network training through online
distillation.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1804.03235</em>, 2018.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bellavista etÂ al. [2021]</span>
<span class="ltx_bibblock">
Paolo Bellavista, Luca Foschini, and Alessio Mora.

</span>
<span class="ltx_bibblock">Decentralised learning in federated deployment environments: A
system-level survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys (CSUR)</em>, 54(1):1â€“38,
2021.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">BuciluÇ etÂ al. [2006]</span>
<span class="ltx_bibblock">
Cristian BuciluÇ, Rich Caruana, and Alexandru Niculescu-Mizil.

</span>
<span class="ltx_bibblock">Model compression.

</span>
<span class="ltx_bibblock">In <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 12th ACM SIGKDD international conference
on Knowledge discovery and data mining</em>, pages 535â€“541, 2006.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang etÂ al. [2019]</span>
<span class="ltx_bibblock">
Hongyan Chang, Virat Shejwalkar, Reza Shokri, and Amir Houmansadr.

</span>
<span class="ltx_bibblock">Cronus: Robust and heterogeneous collaborative learning with
black-box knowledge transfer.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1912.11279</em>, 2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen and Chao [2020]</span>
<span class="ltx_bibblock">
Hong-You Chen and Wei-Lun Chao.

</span>
<span class="ltx_bibblock">Fedbe: Making bayesian model ensemble applicable to federated
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2009.01974</em>, 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng etÂ al. [2021]</span>
<span class="ltx_bibblock">
Sijie Cheng, Jingwen Wu, Yanghua Xiao, and Yang Liu.

</span>
<span class="ltx_bibblock">Fedgems: Federated learning of larger server models via selective
knowledge fusion.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2110.11027</em>, 2021.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Devlin etÂ al. [2018]</span>
<span class="ltx_bibblock">
Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.

</span>
<span class="ltx_bibblock">Bert: Pre-training of deep bidirectional transformers for language
understanding.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1810.04805</em>, 2018.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Diakonikolas etÂ al. [2017]</span>
<span class="ltx_bibblock">
Ilias Diakonikolas, Gautam Kamath, DanielÂ M Kane, Jerry Li, Ankur Moitra, and
Alistair Stewart.

</span>
<span class="ltx_bibblock">Being robust (in high dimensions) can be practical.

</span>
<span class="ltx_bibblock">In <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
999â€“1008. PMLR, 2017.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork etÂ al. [2014]</span>
<span class="ltx_bibblock">
Cynthia Dwork, Aaron Roth, etÂ al.

</span>
<span class="ltx_bibblock">The algorithmic foundations of differential privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Foundations and TrendsÂ® in Theoretical Computer
Science</em>, 9(3â€“4):211â€“407, 2014.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gong etÂ al. [2021]</span>
<span class="ltx_bibblock">
Xuan Gong, Abhishek Sharma, Srikrishna Karanam, Ziyan Wu, Terrence Chen, David
Doermann, and Arun Innanje.

</span>
<span class="ltx_bibblock">Ensemble attention distillation for privacy-preserving federated
learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF International Conference on
Computer Vision</em>, pages 15076â€“15086, 2021.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow etÂ al. [2013]</span>
<span class="ltx_bibblock">
IanÂ J Goodfellow, Mehdi Mirza, DaÂ Xiao, Aaron Courville, and Yoshua Bengio.

</span>
<span class="ltx_bibblock">An empirical investigation of catastrophic forgetting in
gradient-based neural networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1312.6211</em>, 2013.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gou etÂ al. [2021]</span>
<span class="ltx_bibblock">
Jianping Gou, Baosheng Yu, StephenÂ J Maybank, and Dacheng Tao.

</span>
<span class="ltx_bibblock">Knowledge distillation: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">International Journal of Computer Vision</em>, 129(6):1789â€“1819, 2021.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al. [2020]</span>
<span class="ltx_bibblock">
Chaoyang He, Murali Annavaram, and Salman Avestimehr.

</span>
<span class="ltx_bibblock">Group knowledge transfer: Federated learning of large cnns at the
edge.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
33:14068â€“14080, 2020.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al. [2022a]</span>
<span class="ltx_bibblock">
Yuting He, Yiqiang Chen, XiaoDong Yang, Hanchao Yu, Yi-Hua Huang, and Yang Gu.

</span>
<span class="ltx_bibblock">Learning critically: Selective self-distillation in federated
learning on non-iid data.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Big Data</em>, 2022a.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al. [2022b]</span>
<span class="ltx_bibblock">
Yuting He, Yiqiang Chen, Xiaodong Yang, Yingwei Zhang, and Bixiao Zeng.

</span>
<span class="ltx_bibblock">Class-wise adaptive self distillation for heterogeneous federated
learning.

</span>
<span class="ltx_bibblock">2022b.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hinton etÂ al. [2015]</span>
<span class="ltx_bibblock">
Geoffrey Hinton, Oriol Vinyals, and Jeff Dean.

</span>
<span class="ltx_bibblock">Distilling the knowledge in a neural network.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1503.02531</em>, 2015.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu etÂ al. [2021]</span>
<span class="ltx_bibblock">
LiÂ Hu, Hongyang Yan, Lang Li, Zijie Pan, Xiaozhang Liu, and Zulong Zhang.

</span>
<span class="ltx_bibblock">Mhat: an efficient model-heterogenous aggregation training scheme for
federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">Information Sciences</em>, 560:493â€“503, 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Itahara etÂ al. [2020]</span>
<span class="ltx_bibblock">
Sohei Itahara, Takayuki Nishio, Yusuke Koda, Masahiro Morikura, and Koji
Yamamoto.

</span>
<span class="ltx_bibblock">Distillation-based semi-supervised federated learning for
communication-efficient collaborative training with non-iid private data.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2008.06180</em>, 2020.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jeong etÂ al. [2018]</span>
<span class="ltx_bibblock">
Eunjeong Jeong, Seungeun Oh, Hyesung Kim, Jihong Park, Mehdi Bennis, and
Seong-Lyun Kim.

</span>
<span class="ltx_bibblock">Communication-efficient on-device machine learning: Federated
distillation and augmentation under non-iid private data.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.11479</em>, 2018.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karimireddy etÂ al. [2019]</span>
<span class="ltx_bibblock">
SaiÂ Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, SashankÂ J Reddi,
SebastianÂ U Stich, and AnandaÂ Theertha Suresh.

</span>
<span class="ltx_bibblock">Scaffold: Stochastic controlled averaging for on-device federated
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.06378</em>, 2019.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim etÂ al. [2022]</span>
<span class="ltx_bibblock">
Jinkyu Kim, Geeho Kim, and Bohyung Han.

</span>
<span class="ltx_bibblock">Multi-level branched regularization for federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
11058â€“11073. PMLR, 2022.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">KoneÄná»³ etÂ al. [2016]</span>
<span class="ltx_bibblock">
Jakub KoneÄná»³, HÂ Brendan McMahan, FelixÂ X Yu, Peter RichtÃ¡rik,
AnandaÂ Theertha Suresh, and Dave Bacon.

</span>
<span class="ltx_bibblock">Federated learning: Strategies for improving communication
efficiency.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.05492</em>, 2016.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee etÂ al. [2021]</span>
<span class="ltx_bibblock">
Gihun Lee, Yongjin Shin, Minchan Jeong, and Se-Young Yun.

</span>
<span class="ltx_bibblock">Preservation of the global knowledge by not-true self knowledge
distillation in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.03097</em>, 2021.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Wang [2019]</span>
<span class="ltx_bibblock">
Daliang Li and Junpu Wang.

</span>
<span class="ltx_bibblock">Fedmd: Heterogenous federated learning via model distillation.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.03581</em>, 2019.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. [2022]</span>
<span class="ltx_bibblock">
Qinbin Li, Yiqun Diao, Quan Chen, and Bingsheng He.

</span>
<span class="ltx_bibblock">Federated learning on non-iid data silos: An experimental study.

</span>
<span class="ltx_bibblock">In <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">2022 IEEE 38th International Conference on Data Engineering
(ICDE)</em>, pages 965â€“978. IEEE, 2022.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. [2018]</span>
<span class="ltx_bibblock">
Tian Li, AnitÂ Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
Virginia Smith.

</span>
<span class="ltx_bibblock">Federated optimization in heterogeneous networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.06127</em>, 2018.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. [2019]</span>
<span class="ltx_bibblock">
Xiang Li, Kaixuan Huang, Wenhao Yang, Shusen Wang, and Zhihua Zhang.

</span>
<span class="ltx_bibblock">On the convergence of fedavg on non-iid data.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1907.02189</em>, 2019.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin etÂ al. [2020]</span>
<span class="ltx_bibblock">
Tao Lin, Lingjing Kong, SebastianÂ U Stich, and Martin Jaggi.

</span>
<span class="ltx_bibblock">Ensemble distillation for robust model fusion in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing Systems</em>,
33:2351â€“2363, 2020.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin etÂ al. [2018]</span>
<span class="ltx_bibblock">
Yujun Lin, Song Han, Huizi Mao, YuÂ Wang, and Bill Dally.

</span>
<span class="ltx_bibblock">Deep gradient compression: Reducing the communication bandwidth for
distributed training.

</span>
<span class="ltx_bibblock">In <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">International Conference on Learning Representations</em>, 2018.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. [2020]</span>
<span class="ltx_bibblock">
Wenqian Liu, Runze Li, Meng Zheng, Srikrishna Karanam, Ziyan Wu, Bir Bhanu,
RichardÂ J Radke, and Octavia Camps.

</span>
<span class="ltx_bibblock">Towards visually explaining variational autoencoders.

</span>
<span class="ltx_bibblock">In <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pages 8642â€“8651, 2020.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lukasik etÂ al. [2021]</span>
<span class="ltx_bibblock">
Michal Lukasik, Srinadh Bhojanapalli, AdityaÂ Krishna Menon, and Sanjiv Kumar.

</span>
<span class="ltx_bibblock">Teacherâ€™s pet: understanding and mitigating biases in distillation.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2106.10494</em>, 2021.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan etÂ al. [2016]</span>
<span class="ltx_bibblock">
HÂ Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, etÂ al.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized
data.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1602.05629</em>, 2016.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papernot etÂ al. [2016]</span>
<span class="ltx_bibblock">
Nicolas Papernot, MartÃ­n Abadi, Ulfar Erlingsson, Ian Goodfellow, and
Kunal Talwar.

</span>
<span class="ltx_bibblock">Semi-supervised knowledge transfer for deep learning from private
training data.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.05755</em>, 2016.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Poirot etÂ al. [2019]</span>
<span class="ltx_bibblock">
MaartenÂ G Poirot, Praneeth Vepakomma, Ken Chang, Jayashree Kalpathy-Cramer,
Rajiv Gupta, and Ramesh Raskar.

</span>
<span class="ltx_bibblock">Split learning for collaborative deep learning in healthcare.

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1912.12115</em>, 2019.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reddi etÂ al. [2020]</span>
<span class="ltx_bibblock">
Sashank Reddi, Zachary Charles, Manzil Zaheer, Zachary Garrett, Keith Rush,
Jakub KoneÄná»³, Sanjiv Kumar, and HÂ Brendan McMahan.

</span>
<span class="ltx_bibblock">Adaptive federated optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2003.00295</em>, 2020.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reisizadeh etÂ al. [2020]</span>
<span class="ltx_bibblock">
Amirhossein Reisizadeh, Aryan Mokhtari, Hamed Hassani, Ali Jadbabaie, and
Ramtin Pedarsani.

</span>
<span class="ltx_bibblock">Fedpaq: A communication-efficient federated learning method with
periodic averaging and quantization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">International Conference on Artificial Intelligence and
Statistics</em>, pages 2021â€“2031. PMLR, 2020.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sattler etÂ al. [2019a]</span>
<span class="ltx_bibblock">
Felix Sattler, Simon Wiedemann, Klaus-Robert MÃ¼ller, and Wojciech Samek.

</span>
<span class="ltx_bibblock">Robust and communication-efficient federated learning from non-iid
data.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">IEEE transactions on neural networks and learning systems</em>,
2019a.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sattler etÂ al. [2019b]</span>
<span class="ltx_bibblock">
Felix Sattler, Simon Wiedemann, Klaus-Robert MÃ¼ller, and Wojciech Samek.

</span>
<span class="ltx_bibblock">Sparse binary compression: Towards distributed deep learning with
minimal communication.

</span>
<span class="ltx_bibblock">In <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">2019 International Joint Conference on Neural Networks
(IJCNN)</em>, pages 1â€“8. IEEE, 2019b.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sattler etÂ al. [2021a]</span>
<span class="ltx_bibblock">
Felix Sattler, Tim Korjakow, Roman Rischke, and Wojciech Samek.

</span>
<span class="ltx_bibblock">Fedaux: Leveraging unlabeled auxiliary data in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</em>,
2021a.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sattler etÂ al. [2021b]</span>
<span class="ltx_bibblock">
Felix Sattler, Arturo Marban, Roman Rischke, and Wojciech Samek.

</span>
<span class="ltx_bibblock">Cfd: Communication-efficient federated distillation via soft-label
quantization and delta coding.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Network Science and Engineering</em>,
2021b.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Selvaraju etÂ al. [2017]</span>
<span class="ltx_bibblock">
RamprasaathÂ R Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam,
Devi Parikh, and Dhruv Batra.

</span>
<span class="ltx_bibblock">Grad-cam: Visual explanations from deep networks via gradient-based
localization.

</span>
<span class="ltx_bibblock">In <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE international conference on computer
vision</em>, pages 618â€“626, 2017.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Seo etÂ al. [2020]</span>
<span class="ltx_bibblock">
Hyowoon Seo, Jihong Park, Seungeun Oh, Mehdi Bennis, and Seong-Lyun Kim.

</span>
<span class="ltx_bibblock">Federated knowledge distillation.

</span>
<span class="ltx_bibblock"><em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2011.02367</em>, 2020.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shoham etÂ al. [2019]</span>
<span class="ltx_bibblock">
Neta Shoham, Tomer Avidor, Aviv Keren, Nadav Israel, Daniel Benditkis, Liron
Mor-Yosef, and Itai Zeitak.

</span>
<span class="ltx_bibblock">Overcoming forgetting in federated learning on non-iid data.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1910.07796</em>, 2019.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. [2021]</span>
<span class="ltx_bibblock">
Jianyu Wang, Zachary Charles, Zheng Xu, Gauri Joshi, HÂ Brendan McMahan, Maruan
Al-Shedivat, Galen Andrew, Salman Avestimehr, Katharine Daly, Deepesh Data,
etÂ al.

</span>
<span class="ltx_bibblock">A field guide to federated optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.06917</em>, 2021.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al. [2020]</span>
<span class="ltx_bibblock">
Xueyu Wu, Xin Yao, and Cho-Li Wang.

</span>
<span class="ltx_bibblock">Fedscr: Structure-based communication reduction for federated
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Parallel and Distributed Systems</em>,
32(7):1565â€“1577, 2020.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al. [2022]</span>
<span class="ltx_bibblock">
Zhiyuan Wu, Sheng Sun, Yuwei Wang, Min Liu, and Qingxiang Liu.

</span>
<span class="ltx_bibblock">Exploring the distributed knowledge congruence in proxy-data-free
federated distillation.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2204.07028</em>, 2022.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu etÂ al. [2020a]</span>
<span class="ltx_bibblock">
Jinjin Xu, Wenli Du, Yaochu Jin, Wangli He, and Ran Cheng.

</span>
<span class="ltx_bibblock">Ternary compression for communication-efficient federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks and Learning Systems</em>,
2020a.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu etÂ al. [2020b]</span>
<span class="ltx_bibblock">
Yige Xu, Xipeng Qiu, Ligao Zhou, and Xuanjing Huang.

</span>
<span class="ltx_bibblock">Improving bert fine-tuning via self-ensemble and self-distillation.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.10345</em>, 2020b.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang etÂ al. [2019]</span>
<span class="ltx_bibblock">
Chenglin Yang, Lingxi Xie, Chi Su, and AlanÂ L Yuille.

</span>
<span class="ltx_bibblock">Snapshot distillation: Teacher-student optimization in one
generation.

</span>
<span class="ltx_bibblock">In <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pages 2859â€“2868, 2019.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao etÂ al. [2021]</span>
<span class="ltx_bibblock">
Dezhong Yao, Wanning Pan, Yutong Dai, Yao Wan, Xiaofeng Ding, Hai Jin, Zheng
Xu, and Lichao Sun.

</span>
<span class="ltx_bibblock">Local-global knowledge distillation in heterogeneous federated
learning with non-iid data.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.00051</em>, 2021.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang and Yuan [2021]</span>
<span class="ltx_bibblock">
Lan Zhang and Xiaoyong Yuan.

</span>
<span class="ltx_bibblock">Fedzkt: Zero-shot knowledge transfer towards heterogeneous on-device
models in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2109.03775</em>, 2021.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. [2022]</span>
<span class="ltx_bibblock">
Lin Zhang, LiÂ Shen, Liang Ding, Dacheng Tao, and Ling-Yu Duan.

</span>
<span class="ltx_bibblock">Fine-tuning global model via data-free knowledge distillation for
non-iid federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib54.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE/CVF Conference on Computer Vision
and Pattern Recognition</em>, pages 10174â€“10183, 2022.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao etÂ al. [2018]</span>
<span class="ltx_bibblock">
Yue Zhao, Meng Li, Liangzhen Lai, Naveen Suda, Damon Civin, and Vikas Chandra.

</span>
<span class="ltx_bibblock">Federated learning with non-iid data.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1806.00582</em>, 2018.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou etÂ al. [2022]</span>
<span class="ltx_bibblock">
XuÂ Zhou, Xinyu Lei, Cong Yang, Yichun Shi, Xiao Zhang, and Jingwen Shi.

</span>
<span class="ltx_bibblock">Handling data heterogeneity in federated learning via knowledge
fusion.

</span>
<span class="ltx_bibblock"><em id="bib.bib56.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2207.11447</em>, 2022.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu etÂ al. [2021]</span>
<span class="ltx_bibblock">
Zhuangdi Zhu, Junyuan Hong, and Jiayu Zhou.

</span>
<span class="ltx_bibblock">Data-free knowledge distillation for heterogeneous federated
learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib57.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
12878â€“12889. PMLR, 2021.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2211.04741" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2211.04742" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2211.04742">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2211.04742" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2211.04743" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar 14 06:16:27 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
