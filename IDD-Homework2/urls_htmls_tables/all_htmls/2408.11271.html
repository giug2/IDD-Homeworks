<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2408.11271] On Missing Scores in Evolving Multibiometric Systems</title><meta property="og:description" content="The use of multiple modalities (e.g., face and fingerprint) or multiple algorithms (e.g., three face comparators) has shown to improve the recognition accuracy of an operational biometric system. Over time a biometric …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="On Missing Scores in Evolving Multibiometric Systems">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="On Missing Scores in Evolving Multibiometric Systems">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2408.11271">

<!--Generated on Thu Sep  5 15:20:09 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">On Missing Scores in Evolving Multibiometric Systems</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Melissa R Dale


</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
Michigan State University
<br class="ltx_break">East Lansing, Michigan 48824
<br class="ltx_break">Email: dalemeli@msu.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Anil Jain
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">
Michigan State University
<br class="ltx_break">East Lansing, Michigan 48824
<br class="ltx_break">Email: jain@cse.msu.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Arun Ross
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Michigan State University
<br class="ltx_break">East Lansing, Michigan 48824
<br class="ltx_break">Email: rossarun@msu.edu
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">The use of multiple modalities (e.g., face and fingerprint) or multiple algorithms (e.g., three face comparators) has shown to improve the recognition accuracy of an operational biometric system. Over time a biometric system may evolve to add new modalities, retire old modalities, or be merged with other biometric systems. This can lead to scenarios where there are missing scores corresponding to the input probe set. Previous work on this topic has focused on either the verification or identification tasks, but not both. Further, the proportion of missing data considered has been less than 50%. In this work, we study the impact of missing score data for both the verification and identification tasks. We show that the application of various score imputation methods along with simple sum fusion can improve recognition accuracy, even when the proportion of missing scores increases to 90%. Experiments show that fusion after score imputation outperforms fusion with no imputation. Specifically, iterative imputation with K nearest neighbors consistently surpasses other imputation methods in both the verification and identification tasks, regardless of the amount of scores missing, and provides imputed values that are consistent with the ground truth complete dataset.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Biometrics refers to the task of recognizing individuals based on their unique physical or behavioral traits <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite><span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>The terminology used in this article follows current recommendations for multibiometric fusion defined by International Organization for Standardization [ISO], 2015 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite></span></span></span>. A typical biometric <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">identification</span> system aims to determine a potential set of matching identities, while a <span id="S1.p1.1.2" class="ltx_text ltx_font_italic">verification</span> system aims to determine if a probe’s claimed identity is valid (i.e., genuine) or not (i.e., imposter). To accomplish either goal, the feature set extracted from the probe is compared against a gallery template to produce a similarity score.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Operational or deployed biometric systems evolve as technology evolves. For example, new more advanced sensors may be added to existing systems or outdated sensors removed. In these updated systems, not all enrolled (gallery) identities will have data pertaining to all the modalities. Additionally, consider a scenario where multiple operational biometric systems are to be merged into a single biometric system. The list of available gallery identities for the different modalities may not be the same. In situations like these, the resulting gallery data is likely to be more sparse than the typical biometric galleries often studied in literature. In this paper we explore how to handle missing similarity scores of a probe through a combination of imputation <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>In statistics, imputation refers to the process of replacing missing values with an estimated value</span></span></span> and score fusion.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Background</span>
</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Biometric Systems</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Biometric systems using a single biometric modality are sometimes referred to as <span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_italic">unimodal</span> systems. Relying on a single biometric cue can negatively impact biometric system performance when the input data (probe) is of low quality, such as low-resolution faces, highly distorted fingerprints, and occluded irides. Additionally, disabilities or illnesses may prevent some subjects from providing a a biometric cue <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. The use of multiple biometric cues in a biometric system is often referred to as <span id="S2.SS1.p1.1.2" class="ltx_text ltx_font_italic">multibiometrics</span> and can help address these issues. Leveraging multibiometric approaches has shown to improve recognition performance, enhance system reliability, combat noisy sensor data, address large variations in user samples, and improve the system’s security <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. However, there are also potential drawbacks if the multiple biometric sources are not combined carefully, including an increase in recognition error, the need for additional sensors, longer recognition times, and sometimes lower user convenience <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Once multiple sources of biometric information are identified for an application, the critical question is how to best leverage the information from these sources. <span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_italic">Information fusion</span> has been used to improve classification performance in classical machine learning and has been popular in multibiometrics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. While fusion can occur at any point in the biometric system, this paper focuses on fusion at the similarity score level. Score fusion with multimodal data has been shown to increase the performance of biometric systems <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. There are many existing methods to fuse similarity scores across multiple biometric modalities. One popular fusion technique is the <span id="S2.SS1.p2.1.2" class="ltx_text ltx_font_italic">simple sum rule</span>, which takes the mean of available scores to produce a fused score <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. The simple sum fusion approach is a transformation-based approach to fusion, as the scores are first transformed into a common domain prior to fusing (e.g., scores are normalized into the range [0-1]). Simple sum fusion is a popular choice because of its straightforward approach, flexibility in the data it can be applied to, and it often produces desired results. The work in this paper utilizes the simple sum fusion approach.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">When performing multimodal fusion, it should be noted that auxiliary information may also be combined with score data to improve performance. This auxiliary information can include quality measures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, soft biometrics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, and demographic information <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>. Incorporating additional information into the fusion can require additional design decisions and computational resources.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.1" class="ltx_p">The papers discussed above focus on the verification task (one-to-one comparison), which is a binary classification problem (e.g., “accept” or “reject”). Identification tasks (one-to-many comparisons) are often more complex due to the multi-class nature of the problem. Nandakumar et al. successfully extend the likelihood ratio fusion from verification tasks to identification tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. However, to achieve competitive performances on the identification task, the authors propose a hybrid fusion approach which not only leverages the similarity scores but also incorporates the rank information in the fusion. The authors demonstrate the ability of this approach to handle sparse data by randomly dropping 5%, 10%, and 25% of all partitions in the NIST BSSR1 dataset.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Fusion with Missing Scores</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">Missing scores can present a challenge when designing a multibiometric system since many fusion methods require score data to be complete. In deciding how to handle missing data, it is important to consider <span id="S2.SS2.p1.1.1" class="ltx_text ltx_font_italic">why</span> the data is missing. Patterns of missing values are defined by Rubin in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>:</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Missing Completely at Random (MCAR):</span> MCAR describes missing values where the probability that a value is missing is unaffected by other data, whether observed or unobserved. For example, a patient’s missing weight value cannot be explained by observed data such as their sex or age, or unobserved data such as a scale’s battery malfunctioning. This missing value is MCAR.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Missing at Random (MAR):</span> Values that are MAR are influenced by observed data. Bhaskaran and Smeeth highlight MAR by providing the example of blood pressure records <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>. Records for older people are more likely to be documented because it is more often a regimen of their care. While blood pressure records for younger people may be more sparse compared to their elderly counterparts, this difference can be explained by the observable data of age.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Missing Not at Random (MNAR):</span> If values are neither MCAR nor MAR, missing values are MNAR. An example of a value MNAR is if a patient’s drug test is missing <span id="S2.I1.i3.p1.1.2" class="ltx_text ltx_font_italic">because</span> they intentionally skipped in order to prevent a positive test value.</p>
</div>
</li>
</ul>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">Many methods of addressing missing data require the data to be either MCAR or MAR because MNAR has the potential to skew the data. If data can be assumed to be either MCAR or MAR, the following approaches may be applied.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p">One option for missing data is to simply ignore probes with incomplete scores, i.e., probes which do not have scores corresponding to <span id="S2.SS2.p4.1.1" class="ltx_text ltx_font_italic">all</span> the modalities. This approach works if there are only a small proportion of missing data and that missing data is truly MCAR. Additionally, this approach may not be an effective use of available data if otherwise usable scores are dropped. For example in the multibiometrics context, consider a probe that obtains a similarity score for the face and iris modalities, but is missing a fingerprint similarity score. When the entire probe is removed from consideration, a valid face similarity score and a valid iris similarity score are dropped from the dataset. Ignoring an entire probe from analysis is referred to as <span id="S2.SS2.p4.1.2" class="ltx_text ltx_font_italic">Listwise Deletion</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. When deleting data, it is also important to consider if deleting said data would result in bias. For example, if a sensor in a biometric system is more likely to fail than other sensors in the system, missing scores are not missing at random, but rather likely missing due to the sensor used to collect the data.</p>
</div>
<div id="S2.SS2.p5" class="ltx_para">
<p id="S2.SS2.p5.6" class="ltx_p">Another option to handling missing data is to simply fill missing scores with the modality’s mean or median score value. This univariate approach only requires information about the missing modality’s scores and is unaffected by other modalities. Again consider a situation like that described above and presented in Table <a href="#S2.T1" title="TABLE I ‣ II-B Fusion with Missing Scores ‣ II Background ‣ On Missing Scores in Evolving Multibiometric Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>. Using mean substitution, for example, would replace the face modality’s missing score with <math id="S2.SS2.p5.1.m1.1" class="ltx_Math" alttext="0.51" display="inline"><semantics id="S2.SS2.p5.1.m1.1a"><mn id="S2.SS2.p5.1.m1.1.1" xref="S2.SS2.p5.1.m1.1.1.cmml">0.51</mn><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.1.m1.1b"><cn type="float" id="S2.SS2.p5.1.m1.1.1.cmml" xref="S2.SS2.p5.1.m1.1.1">0.51</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.1.m1.1c">0.51</annotation></semantics></math> (the mean of the given score: <math id="S2.SS2.p5.2.m2.1" class="ltx_Math" alttext="0.51" display="inline"><semantics id="S2.SS2.p5.2.m2.1a"><mn id="S2.SS2.p5.2.m2.1.1" xref="S2.SS2.p5.2.m2.1.1.cmml">0.51</mn><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.2.m2.1b"><cn type="float" id="S2.SS2.p5.2.m2.1.1.cmml" xref="S2.SS2.p5.2.m2.1.1">0.51</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.2.m2.1c">0.51</annotation></semantics></math>=<math id="S2.SS2.p5.3.m3.1" class="ltx_Math" alttext="\frac{0.41+0.27+0.85}{3}" display="inline"><semantics id="S2.SS2.p5.3.m3.1a"><mfrac id="S2.SS2.p5.3.m3.1.1" xref="S2.SS2.p5.3.m3.1.1.cmml"><mrow id="S2.SS2.p5.3.m3.1.1.2" xref="S2.SS2.p5.3.m3.1.1.2.cmml"><mn id="S2.SS2.p5.3.m3.1.1.2.2" xref="S2.SS2.p5.3.m3.1.1.2.2.cmml">0.41</mn><mo id="S2.SS2.p5.3.m3.1.1.2.1" xref="S2.SS2.p5.3.m3.1.1.2.1.cmml">+</mo><mn id="S2.SS2.p5.3.m3.1.1.2.3" xref="S2.SS2.p5.3.m3.1.1.2.3.cmml">0.27</mn><mo id="S2.SS2.p5.3.m3.1.1.2.1a" xref="S2.SS2.p5.3.m3.1.1.2.1.cmml">+</mo><mn id="S2.SS2.p5.3.m3.1.1.2.4" xref="S2.SS2.p5.3.m3.1.1.2.4.cmml">0.85</mn></mrow><mn id="S2.SS2.p5.3.m3.1.1.3" xref="S2.SS2.p5.3.m3.1.1.3.cmml">3</mn></mfrac><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.3.m3.1b"><apply id="S2.SS2.p5.3.m3.1.1.cmml" xref="S2.SS2.p5.3.m3.1.1"><divide id="S2.SS2.p5.3.m3.1.1.1.cmml" xref="S2.SS2.p5.3.m3.1.1"></divide><apply id="S2.SS2.p5.3.m3.1.1.2.cmml" xref="S2.SS2.p5.3.m3.1.1.2"><plus id="S2.SS2.p5.3.m3.1.1.2.1.cmml" xref="S2.SS2.p5.3.m3.1.1.2.1"></plus><cn type="float" id="S2.SS2.p5.3.m3.1.1.2.2.cmml" xref="S2.SS2.p5.3.m3.1.1.2.2">0.41</cn><cn type="float" id="S2.SS2.p5.3.m3.1.1.2.3.cmml" xref="S2.SS2.p5.3.m3.1.1.2.3">0.27</cn><cn type="float" id="S2.SS2.p5.3.m3.1.1.2.4.cmml" xref="S2.SS2.p5.3.m3.1.1.2.4">0.85</cn></apply><cn type="integer" id="S2.SS2.p5.3.m3.1.1.3.cmml" xref="S2.SS2.p5.3.m3.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.3.m3.1c">\frac{0.41+0.27+0.85}{3}</annotation></semantics></math>) and the missing fingerprint score would be replaced with <math id="S2.SS2.p5.4.m4.1" class="ltx_Math" alttext="0.54" display="inline"><semantics id="S2.SS2.p5.4.m4.1a"><mn id="S2.SS2.p5.4.m4.1.1" xref="S2.SS2.p5.4.m4.1.1.cmml">0.54</mn><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.4.m4.1b"><cn type="float" id="S2.SS2.p5.4.m4.1.1.cmml" xref="S2.SS2.p5.4.m4.1.1">0.54</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.4.m4.1c">0.54</annotation></semantics></math>. Likewise, the missing scores may be imputed with the median. For this example the face modality’s missing score is replaced with the median of the face scores <math id="S2.SS2.p5.5.m5.1" class="ltx_Math" alttext="0.25" display="inline"><semantics id="S2.SS2.p5.5.m5.1a"><mn id="S2.SS2.p5.5.m5.1.1" xref="S2.SS2.p5.5.m5.1.1.cmml">0.25</mn><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.5.m5.1b"><cn type="float" id="S2.SS2.p5.5.m5.1.1.cmml" xref="S2.SS2.p5.5.m5.1.1">0.25</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.5.m5.1c">0.25</annotation></semantics></math> and the missing fingerprint score would be replaced with <math id="S2.SS2.p5.6.m6.1" class="ltx_Math" alttext="0.74" display="inline"><semantics id="S2.SS2.p5.6.m6.1a"><mn id="S2.SS2.p5.6.m6.1.1" xref="S2.SS2.p5.6.m6.1.1.cmml">0.74</mn><annotation-xml encoding="MathML-Content" id="S2.SS2.p5.6.m6.1b"><cn type="float" id="S2.SS2.p5.6.m6.1.1.cmml" xref="S2.SS2.p5.6.m6.1.1">0.74</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p5.6.m6.1c">0.74</annotation></semantics></math>.</p>
</div>
<figure id="S2.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S2.T1.2.1.1" class="ltx_text" style="font-size:90%;">TABLE I</span>: </span><span id="S2.T1.3.2" class="ltx_text" style="font-size:90%;">A simple example of a score dataset with missing values, denoted as ?.</span></figcaption>
<table id="S2.T1.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S2.T1.4.1.1" class="ltx_tr">
<th id="S2.T1.4.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S2.T1.4.1.1.1.1" class="ltx_text ltx_font_bold">Subject</span></th>
<th id="S2.T1.4.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S2.T1.4.1.1.2.1" class="ltx_text ltx_font_bold">Face</span></th>
<th id="S2.T1.4.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S2.T1.4.1.1.3.1" class="ltx_text ltx_font_bold">Fingerprint</span></th>
<th id="S2.T1.4.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S2.T1.4.1.1.4.1" class="ltx_text ltx_font_bold">Iris</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S2.T1.4.2.1" class="ltx_tr">
<td id="S2.T1.4.2.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Subject 1</td>
<td id="S2.T1.4.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">?</td>
<td id="S2.T1.4.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.74</td>
<td id="S2.T1.4.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.00</td>
</tr>
<tr id="S2.T1.4.3.2" class="ltx_tr">
<td id="S2.T1.4.3.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Subject 2</td>
<td id="S2.T1.4.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.41</td>
<td id="S2.T1.4.3.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.89</td>
<td id="S2.T1.4.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.47</td>
</tr>
<tr id="S2.T1.4.4.3" class="ltx_tr">
<td id="S2.T1.4.4.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Subject 3</td>
<td id="S2.T1.4.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.27</td>
<td id="S2.T1.4.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">?</td>
<td id="S2.T1.4.4.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">0.03</td>
</tr>
<tr id="S2.T1.4.5.4" class="ltx_tr">
<td id="S2.T1.4.5.4.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Subject 4</td>
<td id="S2.T1.4.5.4.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.85</td>
<td id="S2.T1.4.5.4.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.00</td>
<td id="S2.T1.4.5.4.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">0.31</td>
</tr>
</tbody>
</table>
</figure>
<div id="S2.SS2.p6" class="ltx_para">
<p id="S2.SS2.p6.1" class="ltx_p">Multivariate imputation schemes attempt to map relationships between the modalities. <span id="S2.SS2.p6.1.1" class="ltx_text ltx_font_italic">Multiple Imputations by Chained Equations </span> (MICE) is a popular approach to multiple imputations, where missing values are temporarily filled with a placeholder value and then iteratively updated using a trained machine learning model <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. In the given example, shown in Table <a href="#S2.T1" title="TABLE I ‣ II-B Fusion with Missing Scores ‣ II Background ‣ On Missing Scores in Evolving Multibiometric Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>, both the face and iris missing values are initially filled with each modality’s mean or median. The scores of individual modalities are sequentially and iteratively updated with a specified machine learning classifier. Once the classifier has been trained, the missing values are updated from the initial placeholder value to the value predicted by the trained classifier, and then the next modality’s scores are fixed and the classifier is trained again to update the placeholder values. This process is repeated for a specified number of iterations, or until the imputed values stop changing between iterations.</p>
</div>
<div id="S2.SS2.p7" class="ltx_para">
<p id="S2.SS2.p7.1" class="ltx_p">Missing data within individual biometrics can occur in many different ways, as described in the introduction. In order to better understand the role of missing scores in multibiometric settings, researchers often are required to simulate datasets with missing score values <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>, <a href="#bib.bib26" title="" class="ltx_ref">26</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. In each of these prior studies, missing scores are simulated by randomly dropping scores from complete datasets. The percentage of dropped scores range from 5% to 50%. Simulating missing scores allows researchers to know that missing values truly are MAR, and allows for a fine degree of control over the amount of missing data. However, in real world situations, such as the example of incorporating a new modality to an existing biometric system, the proportion of missing data is likely to exceed 50%. In addition to the likelihood estimation approach proposed by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, additional proposed multimodal imputation methods include classifier based methods such as SVM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, or Naïve Bayes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, and deep learning approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>.</p>
</div>
<div id="S2.SS2.p8" class="ltx_para">
<p id="S2.SS2.p8.1" class="ltx_p">In this work, we focus on Listwise Deletion, Mean (and Median) Substitution, and MICE to understand how performances may vary between simulated missing score data and real world datasets that naturally contain missing score values. We explore how these methods perform as the amount of missing score data increases in multiple biometric system evolution scenarios.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Experiments</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We present 3 sets of experiments modelling 3 real-world biometric scenarios: adding a new modality to an existing multimodal biometric system, merging separate biometric systems into one, and retiring a modality from an existing multimodal system. To facilitate these experiments, we leverage the NIST BSSR1 dataset<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>.<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>NIST BSSR1 dataset is available at <a target="_blank" href="https://www.nist.gov/itl/iad/image-group/nist-biometric-scores-set-bssr1" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.nist.gov/itl/iad/image-group/nist-biometric-scores-set-bssr1</a></span></span></span> This publicly available multimodal dataset is comprised of similarity scores for 4 modalities: one score for the comparison of the user’s right index finger to each gallery identity’s right index finger, one score for comparison of the user’s left index finger to each gallery identity’s left index finger, and two scores reported from two facial comparators (referred to as Face Algorithm C and Face Algorithm G).</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">The NIST BSSR1 Set 1 dataset contains complete score vectors for each of the 517 user comparisons to the 517 templates in the gallery. Table <a href="#S3.T2" title="TABLE II ‣ III Experiments ‣ On Missing Scores in Evolving Multibiometric Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> provides a summary of the scores in this dataset. Figure <a href="#S3.F3" title="Figure 3 ‣ III-A Experiment 1: Adding a New Modality to an Existing Biometric System ‣ III Experiments ‣ On Missing Scores in Evolving Multibiometric Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> shows the receiver operating characteristic (ROC) curves for the complete NIST BSSR1 dataset.</p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T2.2.1.1" class="ltx_text" style="font-size:90%;">TABLE II</span>: </span><span id="S3.T2.3.2" class="ltx_text" style="font-size:90%;">Summary of the scores present in set1 of the NIST BSSR1 multimodal dataset.</span></figcaption>
<table id="S3.T2.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.4.1.1" class="ltx_tr">
<th id="S3.T2.4.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S3.T2.4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T2.4.1.1.2.1" class="ltx_text ltx_font_bold">Per Modality</span></th>
<th id="S3.T2.4.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T2.4.1.1.3.1" class="ltx_text ltx_font_bold">Total</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.4.2.1" class="ltx_tr">
<td id="S3.T2.4.2.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T2.4.2.1.1.1" class="ltx_text ltx_font_bold">Total Number of Scores</span></td>
<td id="S3.T2.4.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">267,289</td>
<td id="S3.T2.4.2.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1,069,156</td>
</tr>
<tr id="S3.T2.4.3.2" class="ltx_tr">
<td id="S3.T2.4.3.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T2.4.3.2.1.1" class="ltx_text ltx_font_bold">Genuine Scores</span></td>
<td id="S3.T2.4.3.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">517</td>
<td id="S3.T2.4.3.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">2,068</td>
</tr>
<tr id="S3.T2.4.4.3" class="ltx_tr">
<td id="S3.T2.4.4.3.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T2.4.4.3.1.1" class="ltx_text ltx_font_bold">Imposter Scores</span></td>
<td id="S3.T2.4.4.3.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">266,772</td>
<td id="S3.T2.4.4.3.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">1,067,088</td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">In addition to the NIST BSSR1 dataset, we generate from the BIOCOP2008 Ocular dataset. Similarity scores were obtained for both the ocular image and iris image using a trained Multi-Channel CNN.<span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>Note that scores here are generated using a sub-optimal technique for the purposes of this experiment.</span></span></span> Figure <a href="#S3.F1" title="Figure 1 ‣ III Experiments ‣ On Missing Scores in Evolving Multibiometric Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> summarizes this breakdown of the provided images.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2408.11271/assets/x1.png" id="S3.F1.g1" class="ltx_graphics ltx_img_landscape" width="138" height="111" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S3.F1.3.2" class="ltx_text" style="font-size:90%;">Breakdown of provided Ocular image in the BIOCOP2008 dataset</span></figcaption>
</figure>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">If we consider “Ocular” and “Iris” as the two modalities in this dataset, the resulting score dataset is complete. That is, for every iris image, there is a corresponding ocular image and vice versa. This is logical, as each iris image is a subset of a corresponding ocular image. This 2-modality formatting is described in Table <a href="#S3.T3" title="TABLE III ‣ III Experiments ‣ On Missing Scores in Evolving Multibiometric Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>. Figure <a href="#S3.F4" title="Figure 4 ‣ III-A Experiment 1: Adding a New Modality to an Existing Biometric System ‣ III Experiments ‣ On Missing Scores in Evolving Multibiometric Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows the ROC curves for the complete BIOCOP2008 dataset.</p>
</div>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T3.2.1.1" class="ltx_text" style="font-size:90%;">TABLE III</span>: </span><span id="S3.T3.3.2" class="ltx_text" style="font-size:90%;">Summary of the scores present in the BIOCOP2008 ocular dataset.</span></figcaption>
<table id="S3.T3.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T3.4.1.1" class="ltx_tr">
<th id="S3.T3.4.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S3.T3.4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T3.4.1.1.2.1" class="ltx_text ltx_font_bold">Per Modality</span></th>
<th id="S3.T3.4.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T3.4.1.1.3.1" class="ltx_text ltx_font_bold">Total</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T3.4.2.1" class="ltx_tr">
<td id="S3.T3.4.2.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T3.4.2.1.1.1" class="ltx_text ltx_font_bold">Total Number of Scores</span></td>
<td id="S3.T3.4.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">312,606</td>
<td id="S3.T3.4.2.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">625,212</td>
</tr>
<tr id="S3.T3.4.3.2" class="ltx_tr">
<td id="S3.T3.4.3.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T3.4.3.2.1.1" class="ltx_text ltx_font_bold">Genuine Scores</span></td>
<td id="S3.T3.4.3.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">998</td>
<td id="S3.T3.4.3.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">1,996</td>
</tr>
<tr id="S3.T3.4.4.3" class="ltx_tr">
<td id="S3.T3.4.4.3.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T3.4.4.3.1.1" class="ltx_text ltx_font_bold">Imposter Scores</span></td>
<td id="S3.T3.4.4.3.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">311,608</td>
<td id="S3.T3.4.4.3.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">623,216</td>
</tr>
</tbody>
</table>
</figure>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.1" class="ltx_p">Each experiment is described in detail below. The experimental design for all experiments is summarized in Table <a href="#S3.T4" title="TABLE IV ‣ III Experiments ‣ On Missing Scores in Evolving Multibiometric Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a> and a diagram of the experiments is presented in Figure <a href="#S3.F2" title="Figure 2 ‣ III Experiments ‣ On Missing Scores in Evolving Multibiometric Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. To perform score fusion, we opt to apply the simple sum fusion as described in Section <a href="#S2" title="II Background ‣ On Missing Scores in Evolving Multibiometric Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>. This fusion technique allows us to compare the performance of fusion with imputed scores to the performance of incomplete score vectors. Many other fusion methods (e.g., score fusion with SVM <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, or Naïve Bayes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>) a complete score vector is required and incomplete score vectors would have to be ignored (listwise deletion). We divide the data into train and test sets, and randomly drop the specified proportion of scores 5 times to obtain mean and standard deviation (s.d.) values.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2408.11271/assets/x2.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="184" height="104" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.2.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.3.2" class="ltx_text" style="font-size:90%;">Experiment contexts for NIST BSSR1 dataset.</span></figcaption>
</figure>
<figure id="S3.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T4.2.1.1" class="ltx_text" style="font-size:90%;">TABLE IV</span>: </span><span id="S3.T4.3.2" class="ltx_text" style="font-size:90%;">Summary of settings used in the experiments.</span></figcaption>
<table id="S3.T4.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T4.4.1.1" class="ltx_tr">
<th id="S3.T4.4.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T4.4.1.1.1.1" class="ltx_text ltx_font_bold">Experimental Parameter</span></th>
<th id="S3.T4.4.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T4.4.1.1.2.1" class="ltx_text ltx_font_bold">Settings</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T4.4.2.1" class="ltx_tr">
<th id="S3.T4.4.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_tt"><span id="S3.T4.4.2.1.1.1" class="ltx_text ltx_font_bold">Training, Testing Split</span></th>
<td id="S3.T4.4.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_tt">80%, 20%</td>
</tr>
<tr id="S3.T4.4.3.2" class="ltx_tr">
<th id="S3.T4.4.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T4.4.3.2.1.1" class="ltx_text ltx_font_bold"># of Missing Score Simulations</span></th>
<td id="S3.T4.4.3.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">5</td>
</tr>
<tr id="S3.T4.4.4.3" class="ltx_tr">
<th id="S3.T4.4.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T4.4.4.3.1.1" class="ltx_text ltx_font_bold">% Missing</span></th>
<td id="S3.T4.4.4.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S3.T4.4.4.3.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.4.4.3.2.1.1" class="ltx_tr">
<td id="S3.T4.4.4.3.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">[0, 10, 20, 30, 40,</td>
</tr>
<tr id="S3.T4.4.4.3.2.1.2" class="ltx_tr">
<td id="S3.T4.4.4.3.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">50, 60, 70, 80, 90]</td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T4.4.5.4" class="ltx_tr">
<th id="S3.T4.4.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T4.4.5.4.1.1" class="ltx_text ltx_font_bold">Univariate Imputations</span></th>
<td id="S3.T4.4.5.4.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S3.T4.4.5.4.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.4.5.4.2.1.1" class="ltx_tr">
<td id="S3.T4.4.5.4.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Mean</td>
</tr>
<tr id="S3.T4.4.5.4.2.1.2" class="ltx_tr">
<td id="S3.T4.4.5.4.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Median</td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T4.4.6.5" class="ltx_tr">
<th id="S3.T4.4.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T4.4.6.5.1.1" class="ltx_text ltx_font_bold">Multivariate Imputations</span></th>
<td id="S3.T4.4.6.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">
<table id="S3.T4.4.6.5.2.1" class="ltx_tabular ltx_align_middle">
<tr id="S3.T4.4.6.5.2.1.1" class="ltx_tr">
<td id="S3.T4.4.6.5.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">Bayesian Regression <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>
</td>
</tr>
<tr id="S3.T4.4.6.5.2.1.2" class="ltx_tr">
<td id="S3.T4.4.6.5.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_left">Decision Tree <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>
</td>
</tr>
<tr id="S3.T4.4.6.5.2.1.3" class="ltx_tr">
<td id="S3.T4.4.6.5.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_left">K Nearest Neighbors <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>
</td>
</tr>
</table>
</td>
</tr>
<tr id="S3.T4.4.7.6" class="ltx_tr">
<th id="S3.T4.4.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T4.4.7.6.1.1" class="ltx_text ltx_font_bold">Fusion Applied</span></th>
<td id="S3.T4.4.7.6.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">Simple Sum Fusion</td>
</tr>
</tbody>
</table>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Experiment 1: Adding a New Modality to an Existing Biometric System</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">To simulate adding a new modality to a biometric system, we set all but one modality with complete score data, and incrementally introduce scores from the remaining modality. We consider the scenario where we introduce the best performing modality, or the worst performing modality. For the NIST BSSR1, the best modality for both the identification and verification tasks is the right fingerprint. While Face Algorithm C is the poorest performing modality on the verification task, it is the second best on the identification task. Face Algorithm G performs relatively poorly on both verification and identification tasks. So we select Face Algorithm G as the worst modality. For the BIOCOP2008 dataset, performance between the 2 modalities are comparable; we consider the Ocular modality the best and the Iris modality the worst performing.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2408.11271/assets/img/NIST-roc.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="240" height="183" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.3.2" class="ltx_text" style="font-size:90%;">ROC Curves for the complete NIST BSSR1 dataset </span></figcaption>
</figure>
<figure id="S3.F4" class="ltx_figure"><img src="/html/2408.11271/assets/img/BIOCOP-roc2.png" id="S3.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="240" height="182" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S3.F4.3.2" class="ltx_text" style="font-size:90%;">ROC Curves for the complete BIOCOP2008 dataset</span></figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Experiment 2: Merging Biometric Systems</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">When merging separate biometric systems, it is very unlikely that the systems share the same gallery of subjects. For this reason, the merged score data can be very sparse and scores can be missing randomly across all modalities. For this experiment, there is no constraint on the number of missing modalities other than to ensure that each probe has at least one score. For context, in the NIST BSSR1 with 90% missing scores, out of the 1,069,156 probes only 145,383 (<math id="S3.SS2.p1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S3.SS2.p1.1.m1.1a"><mo id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><csymbol cd="latexml" id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\pm</annotation></semantics></math>) 257 probes contain scores for all 4 modalities, and up to 296 probes contain only 1 score.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Experiment 3: Retiring a Modality</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">The first 2 scenarios describe situations where biometric systems grow larger either through the addition of a new modality or by combining separate biometric systems into one. Conversely, experiment 3 models a scenario where a biometric system loses a modality. An old sensor might begin malfunctioning or the modality data itself might be outdated. To simulate this situation, we train models on a full training score dataset and use these models to impute missing scores for the missing modalities in the testing set.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">The following describes the questions addressed with this experiment:</p>
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p">If a modality is retired, is it better to continue using imputed scores or retrain the biometric system without the retired modality?</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p">When a modality is starting to malfunction, is there a limit on the number of times imputation can be applied before it is no longer helpful?</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Results</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">In our experiments, we find that imputation and fusion drastically boosts biometric performance for the NIST BSSR1 dataset, both for the verification and identification tasks. Even when 90% of probes are incomplete, NIST BSSR1 recognition performance is drastically improved in all three scenarios. The BIOCOP2008 dataset did not show such strong recognition performance gains, however imputation does appear to bridge the gap between a complete score dataset and analysis performed on an incomplete score dataset. We highlight a few of the results below <span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>Complete results can be viewed <a target="_blank" href="https://melissadale.github.io/ICPR2022/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://melissadale.github.io/ICPR2022/</a></span></span></span>.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Experiment 1: Adding a New Modality to an Existing Biometric System</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p"><span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_bold">Verification Tasks</span> For the NIST BSSR1 dataset, all imputation methods provide recognition performance competitive to the complete dataset, even when 90% of scores are missing from either the best performing modality (Right Index Fingerprint) or the worst performing modality (Face Comparator G), while the fusion performance on the incomplete dataset is very poor across all amounts of missing data, as can be seen in Figure <a href="#S4.F5" title="Figure 5 ‣ IV-A Experiment 1: Adding a New Modality to an Existing Biometric System ‣ IV Results ‣ On Missing Scores in Evolving Multibiometric Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, where only 10% of the Right Fingerprint modality’s scores are missing.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2408.11271/assets/img/Experiment1-level10.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="240" height="190" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S4.F5.3.2" class="ltx_text" style="font-size:90%;">ROC curves for imputation methods on the 10% missing in the NIST BSSR1 dataset scenario in Experiment 1. The curves corresponding to fusion with imputed values overlap near the top with the 0% missing baseline curve, which is shown in pink.</span></figcaption>
</figure>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">Figure <a href="#S4.F6" title="Figure 6 ‣ IV-A Experiment 1: Adding a New Modality to an Existing Biometric System ‣ IV Results ‣ On Missing Scores in Evolving Multibiometric Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> provides the ROC plot for the BIOCOP2008 dataset analysis for experiment 1 when 40% of scores are missing from the ocular modality. We see that no one approach is significantly better than the other, however we see that generally the performance of imputed score values lies between the complete score dataset and the incomplete, non-imputed score dataset.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p">These findings suggest that verification performance can be improved when adding a new modality to an existing biometric system, regardless of the individual performance of the modality, by imputing the modality’s missing scores before performing fusion.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="/html/2408.11271/assets/img/BIO-Experiment1-level40.png" id="S4.F6.g1" class="ltx_graphics ltx_centering ltx_img_square" width="240" height="194" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S4.F6.3.2" class="ltx_text" style="font-size:90%;">ROC curves for imputation methods on the 40% missing scenario on the BIOCOP2008 dataset in Experiment 1.</span></figcaption>
</figure>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p"><span id="S4.SS1.p4.1.1" class="ltx_text ltx_font_bold">Identification Tasks</span>
Identification tasks in experiment 1 in particular appear to benefit from analysis with imputed values for both the NIST BSSR1 dataset and the BIOCOP2008 dataset. In fact, the Rank 1 identification accuracy for the BIOCOP2008 dataset is improved over the performance of the complete dataset, as shown in Figure <a href="#S4.F7" title="Figure 7 ‣ IV-A Experiment 1: Adding a New Modality to an Existing Biometric System ‣ IV Results ‣ On Missing Scores in Evolving Multibiometric Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>.</p>
</div>
<figure id="S4.F7" class="ltx_figure"><img src="/html/2408.11271/assets/img/BIO-Experiment1-Rank1-level70.png" id="S4.F7.g1" class="ltx_graphics ltx_centering ltx_img_square" width="240" height="195" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F7.2.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S4.F7.3.2" class="ltx_text" style="font-size:90%;">Rank 1 accuracies for imputation methods on the 10% missing scenario for the BIOCOP2008 dataset in Experiment 1.</span></figcaption>
</figure>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p">While performance is not maintained across increasing proportions of missing score data, fusion with imputed values consistently outperforms fusion with incomplete score data.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Experiment 2: Merging Biometric Systems</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.2" class="ltx_p">The score data simulated in Experiment 2 turns out to be more complicated than the score data in Experiment 1, because each probe may have up to <math id="S4.SS2.p1.1.m1.1" class="ltx_Math" alttext="N-1" display="inline"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mi id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">N</mi><mo id="S4.SS2.p1.1.m1.1.1.1" xref="S4.SS2.p1.1.m1.1.1.1.cmml">−</mo><mn id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><minus id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1"></minus><ci id="S4.SS2.p1.1.m1.1.1.2.cmml" xref="S4.SS2.p1.1.m1.1.1.2">𝑁</ci><cn type="integer" id="S4.SS2.p1.1.m1.1.1.3.cmml" xref="S4.SS2.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">N-1</annotation></semantics></math> scores missing, where <math id="S4.SS2.p1.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS2.p1.2.m2.1a"><mi id="S4.SS2.p1.2.m2.1.1" xref="S4.SS2.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.2.m2.1b"><ci id="S4.SS2.p1.2.m2.1.1.cmml" xref="S4.SS2.p1.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.2.m2.1c">N</annotation></semantics></math> is the number of modalities in the biometric system. While the recognition performance is not as strong as the performance in Experiment 1, we can see that both verification and identification tasks benefit from applying imputation methods, even when 90% of the probe data is incomplete.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold">Verification Tasks</span>
The verification performance for experiment 2 closely mirrors the verification performance seen in experiment 1 for both NIST BSSR1 dataset and BIOCOP2008 dataset. For example, Figure <a href="#S4.F8" title="Figure 8 ‣ IV-B Experiment 2: Merging Biometric Systems ‣ IV Results ‣ On Missing Scores in Evolving Multibiometric Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> shows the ROC plot for the BIOCOP2008 dataset when 30% of the probes are incomplete.</p>
</div>
<figure id="S4.F8" class="ltx_figure"><img src="/html/2408.11271/assets/img/Experiment2-level30-bio.png" id="S4.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="240" height="193" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F8.2.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S4.F8.3.2" class="ltx_text" style="font-size:90%;">ROC curves for imputation methods on the 30% missing scenario on the BIOCOP2008 in Experiment 2.</span></figcaption>
</figure>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p"><span id="S4.SS2.p3.1.1" class="ltx_text ltx_font_bold">Identification Tasks</span>
Figure <a href="#S4.F9" title="Figure 9 ‣ IV-B Experiment 2: Merging Biometric Systems ‣ IV Results ‣ On Missing Scores in Evolving Multibiometric Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> provides the identification accuracies across the first 10 ranks in the NIST BSSR1 dataset. We can see that when 90% of probes are incomplete, with some incomplete probes containing only 1 similarity score out of a possible 4 modalities, performance is improved with imputation, especially for the KNN and Decision Tree iterative imputation techniques.</p>
</div>
<figure id="S4.F9" class="ltx_figure"><img src="/html/2408.11271/assets/img/RRExperiment2-RANKS-level90.png" id="S4.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="240" height="192" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F9.2.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="S4.F9.3.2" class="ltx_text" style="font-size:90%;">Identification accuracies over the first 10 Ranks for the 90% missing scenario on NIST BSSR1 in Experiment2.</span></figcaption>
</figure>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS3.5.1.1" class="ltx_text">IV-C</span> </span><span id="S4.SS3.6.2" class="ltx_text ltx_font_italic">Experiment 3: Retiring a Modality</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">When removing a modality from the biometric system, we again see that using imputed scores perform better than applying simple sum fusion without imputation. However, we also see that retraining without the retired modality often yields performances similar to the complete dataset.
, as seen in Figure <a href="#S4.F10" title="Figure 10 ‣ IV-C Experiment 3: Retiring a Modality ‣ IV Results ‣ On Missing Scores in Evolving Multibiometric Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a> for verification tasks and Table <a href="#S4.T5" title="TABLE V ‣ IV-C Experiment 3: Retiring a Modality ‣ IV Results ‣ On Missing Scores in Evolving Multibiometric Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> for identification tasks. This suggest that it may be prudent to retrain a biometric system when retiring a modality.</p>
</div>
<figure id="S4.F10" class="ltx_figure"><img src="/html/2408.11271/assets/img/Experiment3-level90.png" id="S4.F10.g1" class="ltx_graphics ltx_centering ltx_img_square" width="240" height="195" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F10.2.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="S4.F10.3.2" class="ltx_text" style="font-size:90%;">ROC plot for NIST BSSR1 dataset for experiment 3 when 90% of the probes are incomplete.</span></figcaption>
</figure>
<figure id="S4.T5" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T5.20.1.1" class="ltx_text" style="font-size:90%;">TABLE V</span>: </span><span id="S4.T5.21.2" class="ltx_text" style="font-size:90%;">The Rank 1, Rank 2, and Rank 3 identification accuracies for the imputation methods on 90% missing data in Experiment 3 on the NIST BSSR1 dataset.</span></figcaption>
<table id="S4.T5.18" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T5.18.19.1" class="ltx_tr">
<th id="S4.T5.18.19.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T5.18.19.1.1.1" class="ltx_text ltx_font_bold">Method</span></th>
<td id="S4.T5.18.19.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T5.18.19.1.2.1" class="ltx_text ltx_font_bold">Rank1</span></td>
<td id="S4.T5.18.19.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T5.18.19.1.3.1" class="ltx_text ltx_font_bold">Rank2</span></td>
<td id="S4.T5.18.19.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T5.18.19.1.4.1" class="ltx_text ltx_font_bold">Rank3</span></td>
</tr>
<tr id="S4.T5.3.3" class="ltx_tr">
<th id="S4.T5.3.3.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Bayesian</th>
<td id="S4.T5.1.1.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.12% <math id="S4.T5.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T5.1.1.1.m1.1a"><mo id="S4.T5.1.1.1.m1.1.1" xref="S4.T5.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T5.1.1.1.m1.1b"><csymbol cd="latexml" id="S4.T5.1.1.1.m1.1.1.cmml" xref="S4.T5.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.1.1.1.m1.1c">\pm</annotation></semantics></math> 1.52</td>
<td id="S4.T5.2.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.85% <math id="S4.T5.2.2.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T5.2.2.2.m1.1a"><mo id="S4.T5.2.2.2.m1.1.1" xref="S4.T5.2.2.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T5.2.2.2.m1.1b"><csymbol cd="latexml" id="S4.T5.2.2.2.m1.1.1.cmml" xref="S4.T5.2.2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.2.2.2.m1.1c">\pm</annotation></semantics></math> 1.05</td>
<td id="S4.T5.3.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.85% <math id="S4.T5.3.3.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T5.3.3.3.m1.1a"><mo id="S4.T5.3.3.3.m1.1.1" xref="S4.T5.3.3.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T5.3.3.3.m1.1b"><csymbol cd="latexml" id="S4.T5.3.3.3.m1.1.1.cmml" xref="S4.T5.3.3.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.3.3.3.m1.1c">\pm</annotation></semantics></math> 1.05</td>
</tr>
<tr id="S4.T5.6.6" class="ltx_tr">
<th id="S4.T5.6.6.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Decision Tree</th>
<td id="S4.T5.4.4.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.38 % <math id="S4.T5.4.4.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T5.4.4.1.m1.1a"><mo id="S4.T5.4.4.1.m1.1.1" xref="S4.T5.4.4.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T5.4.4.1.m1.1b"><csymbol cd="latexml" id="S4.T5.4.4.1.m1.1.1.cmml" xref="S4.T5.4.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.4.4.1.m1.1c">\pm</annotation></semantics></math> 2.49</td>
<td id="S4.T5.5.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.85% <math id="S4.T5.5.5.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T5.5.5.2.m1.1a"><mo id="S4.T5.5.5.2.m1.1.1" xref="S4.T5.5.5.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T5.5.5.2.m1.1b"><csymbol cd="latexml" id="S4.T5.5.5.2.m1.1.1.cmml" xref="S4.T5.5.5.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.5.5.2.m1.1c">\pm</annotation></semantics></math> 1.05</td>
<td id="S4.T5.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.85 % <math id="S4.T5.6.6.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T5.6.6.3.m1.1a"><mo id="S4.T5.6.6.3.m1.1.1" xref="S4.T5.6.6.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T5.6.6.3.m1.1b"><csymbol cd="latexml" id="S4.T5.6.6.3.m1.1.1.cmml" xref="S4.T5.6.6.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.6.6.3.m1.1c">\pm</annotation></semantics></math> 1.05</td>
</tr>
<tr id="S4.T5.9.9" class="ltx_tr">
<th id="S4.T5.9.9.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">KNN</th>
<td id="S4.T5.7.7.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.12 % <math id="S4.T5.7.7.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T5.7.7.1.m1.1a"><mo id="S4.T5.7.7.1.m1.1.1" xref="S4.T5.7.7.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T5.7.7.1.m1.1b"><csymbol cd="latexml" id="S4.T5.7.7.1.m1.1.1.cmml" xref="S4.T5.7.7.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.7.7.1.m1.1c">\pm</annotation></semantics></math> 1.52</td>
<td id="S4.T5.8.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.85 % <math id="S4.T5.8.8.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T5.8.8.2.m1.1a"><mo id="S4.T5.8.8.2.m1.1.1" xref="S4.T5.8.8.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T5.8.8.2.m1.1b"><csymbol cd="latexml" id="S4.T5.8.8.2.m1.1.1.cmml" xref="S4.T5.8.8.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.8.8.2.m1.1c">\pm</annotation></semantics></math> 1.05</td>
<td id="S4.T5.9.9.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.85% <math id="S4.T5.9.9.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T5.9.9.3.m1.1a"><mo id="S4.T5.9.9.3.m1.1.1" xref="S4.T5.9.9.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T5.9.9.3.m1.1b"><csymbol cd="latexml" id="S4.T5.9.9.3.m1.1.1.cmml" xref="S4.T5.9.9.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.9.9.3.m1.1c">\pm</annotation></semantics></math> 1.05</td>
</tr>
<tr id="S4.T5.12.12" class="ltx_tr">
<th id="S4.T5.12.12.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Mean</th>
<td id="S4.T5.10.10.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.27% <math id="S4.T5.10.10.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T5.10.10.1.m1.1a"><mo id="S4.T5.10.10.1.m1.1.1" xref="S4.T5.10.10.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T5.10.10.1.m1.1b"><csymbol cd="latexml" id="S4.T5.10.10.1.m1.1.1.cmml" xref="S4.T5.10.10.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.10.10.1.m1.1c">\pm</annotation></semantics></math> 1.43</td>
<td id="S4.T5.11.11.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.85% <math id="S4.T5.11.11.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T5.11.11.2.m1.1a"><mo id="S4.T5.11.11.2.m1.1.1" xref="S4.T5.11.11.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T5.11.11.2.m1.1b"><csymbol cd="latexml" id="S4.T5.11.11.2.m1.1.1.cmml" xref="S4.T5.11.11.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.11.11.2.m1.1c">\pm</annotation></semantics></math> 1.05</td>
<td id="S4.T5.12.12.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.85 % <math id="S4.T5.12.12.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T5.12.12.3.m1.1a"><mo id="S4.T5.12.12.3.m1.1.1" xref="S4.T5.12.12.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T5.12.12.3.m1.1b"><csymbol cd="latexml" id="S4.T5.12.12.3.m1.1.1.cmml" xref="S4.T5.12.12.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.12.12.3.m1.1c">\pm</annotation></semantics></math> 1.05</td>
</tr>
<tr id="S4.T5.15.15" class="ltx_tr">
<th id="S4.T5.15.15.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Median</th>
<td id="S4.T5.13.13.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.27 % <math id="S4.T5.13.13.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T5.13.13.1.m1.1a"><mo id="S4.T5.13.13.1.m1.1.1" xref="S4.T5.13.13.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T5.13.13.1.m1.1b"><csymbol cd="latexml" id="S4.T5.13.13.1.m1.1.1.cmml" xref="S4.T5.13.13.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.13.13.1.m1.1c">\pm</annotation></semantics></math> 1.43</td>
<td id="S4.T5.14.14.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.85 % <math id="S4.T5.14.14.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T5.14.14.2.m1.1a"><mo id="S4.T5.14.14.2.m1.1.1" xref="S4.T5.14.14.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T5.14.14.2.m1.1b"><csymbol cd="latexml" id="S4.T5.14.14.2.m1.1.1.cmml" xref="S4.T5.14.14.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.14.14.2.m1.1c">\pm</annotation></semantics></math> 1.05</td>
<td id="S4.T5.15.15.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">98.85% <math id="S4.T5.15.15.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T5.15.15.3.m1.1a"><mo id="S4.T5.15.15.3.m1.1.1" xref="S4.T5.15.15.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T5.15.15.3.m1.1b"><csymbol cd="latexml" id="S4.T5.15.15.3.m1.1.1.cmml" xref="S4.T5.15.15.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.15.15.3.m1.1c">\pm</annotation></semantics></math> 1.05</td>
</tr>
<tr id="S4.T5.18.18" class="ltx_tr">
<th id="S4.T5.18.18.4" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">No Imputation</th>
<td id="S4.T5.16.16.1" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">11.35% <math id="S4.T5.16.16.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T5.16.16.1.m1.1a"><mo id="S4.T5.16.16.1.m1.1.1" xref="S4.T5.16.16.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T5.16.16.1.m1.1b"><csymbol cd="latexml" id="S4.T5.16.16.1.m1.1.1.cmml" xref="S4.T5.16.16.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.16.16.1.m1.1c">\pm</annotation></semantics></math> 3.15</td>
<td id="S4.T5.17.17.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">12.12% <math id="S4.T5.17.17.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T5.17.17.2.m1.1a"><mo id="S4.T5.17.17.2.m1.1.1" xref="S4.T5.17.17.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T5.17.17.2.m1.1b"><csymbol cd="latexml" id="S4.T5.17.17.2.m1.1.1.cmml" xref="S4.T5.17.17.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.17.17.2.m1.1c">\pm</annotation></semantics></math> 3.09</td>
<td id="S4.T5.18.18.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">12.31% <math id="S4.T5.18.18.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S4.T5.18.18.3.m1.1a"><mo id="S4.T5.18.18.3.m1.1.1" xref="S4.T5.18.18.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S4.T5.18.18.3.m1.1b"><csymbol cd="latexml" id="S4.T5.18.18.3.m1.1.1.cmml" xref="S4.T5.18.18.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.18.18.3.m1.1c">\pm</annotation></semantics></math> 3.22</td>
</tr>
<tr id="S4.T5.18.20.2" class="ltx_tr">
<th id="S4.T5.18.20.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Retraining</th>
<td id="S4.T5.18.20.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">99.81</td>
<td id="S4.T5.18.20.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">99.81</td>
<td id="S4.T5.18.20.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">99.81</td>
</tr>
<tr id="S4.T5.18.21.3" class="ltx_tr">
<th id="S4.T5.18.21.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">0% Missing</th>
<td id="S4.T5.18.21.3.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">100</td>
<td id="S4.T5.18.21.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">100</td>
<td id="S4.T5.18.21.3.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">100</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Conclusions</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this study, we show that applying imputation to incomplete score data in a multimodal biometric system can improve the performance of both verification and identification tasks. The small, well-groomed multimodal NIST BSSR1 dataset benefits greatly from simple sum fusion, with nearly 100% identification Rank 1 accuracy on the complete dataset. While all imputation methods produced strong recognition performances, iterative imputation with KNN provided the best results in both verification and identification tasks. For the BIOCOP2008 dataset, recognition performance gains over the complete data are not as pronounced, however the recognition performance does not decrease due to the imputed values. Furthermore, in a few situations, fusion with imputed similarity score values outperforms fusion with incomplete score vectors. To better understand how biometric systems are impacted by sparse data, larger multimodal datasets are required. Additionally, multimodal datasets that naturally contain missing score data can better illuminate how these methods perform in situations where the data may not be missing at random.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Future Work</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">This study was applied to missing scores, however as mentioned in Section <a href="#S2" title="II Background ‣ On Missing Scores in Evolving Multibiometric Systems" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>, it is possible scores are considered missing due poor quality data. Further research is needed to understand the impact of score quality when invoking imputation in multibiometric systems. Additionally, this research has focused on score-level fusion. Further research should be conducted on other levels of the biometric system.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
A. A. Ross, K. Nandakumar, and A. K. Jain, <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Handbook of Multibiometrics</em>.   Springer Science &amp; Business Media, 2006.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
International Organization for Standardization. (2015), <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">Information technology — Biometrics — Multimodal and other multibiometric fusion</em>, (ISO/IEC Standard No. 24722) Retrieved from <a target="_blank" href="https://www.iso.org/standard/64061.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.iso.org/standard/64061.html</a>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
N. V. Boulgouris, K. N. Plataniotis, and E. Micheli-Tzanakou, <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Biometrics: Theory, Methods, and Applications</em>.   John Wiley &amp; Sons, 2009.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
A. Mishra, “Multimodal biometrics it is: Need for future systems,” <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">International Journal of Computer Applications</em>, vol. 3, no. 4, pp. 28–33, 2010.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
R. Brunelli and D. Falavigna, “Person identification using multiple cues,” <em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Pattern Analysis and Machine Intelligence</em>, vol. 17, no. 10, pp. 955–966, 1995.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
S. Prabhakar and A. K. Jain, “Decision-level fusion in fingerprint verification,” <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Pattern Recognition</em>, vol. 35, no. 4, pp. 861–874, 2002.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
K.-A. Toh, X. Jiang, and W.-Y. Yau, “Exploiting global and local decisions for multimodal biometrics verification,” <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Signal Processing</em>, vol. 52, no. 10, pp. 3059–3072, 2004.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
A. Ross and A. Jain, “Information fusion in biometrics,” <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">Pattern recognition letters</em>, vol. 24, no. 13, pp. 2115–2125, 2003.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
L. Allano, B. Dorizzi, and S. Garcia-Salicetti, “Tuning cost and performance in multi-biometric systems: A novel and consistent view of fusion strategies based on the sequential probability ratio test (sprt),” <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">Pattern Recognition Letters</em>, vol. 31, no. 9, pp. 884–890, 2010.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
J. Kittler, M. Hatef, R. P. Duin, and J. Matas, “On combining classifiers,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">Transactions on Pattern Analysis and Machine Intelligence</em>, vol. 20, no. 3, pp. 226–239, 1998.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
M. Singh, R. Singh, and A. Ross, “A comprehensive overview of biometric fusion,” <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Information Fusion</em>, vol. 52, pp. 187–205, 2019.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
K. Nandakumar, Y. Chen, S. C. Dass, and A. Jain, “Likelihood ratio-based biometric score fusion,” <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Transactions on Pattern Analysis and Machine Intelligence</em>, vol. 30, no. 2, pp. 342–347, 2007.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
R. Snelick, U. Uludag, A. Mink, M. Indovina, and A. Jain, “Large-scale evaluation of multimodal biometric authentication using state-of-the-art systems,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Transactions on Pattern Analysis and Machine Intelligence</em>, vol. 27, no. 3, pp. 450–455, 2005.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
A. Jain, K. Nandakumar, and A. Ross, “Score normalization in multimodal biometric systems,” <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">Pattern Recognition</em>, vol. 38, no. 12, pp. 2270–2285, 2005.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Y. Ding, A. Rattani, and A. Ross, “Bayesian belief models for integrating match scores with liveness and quality measures in a fingerprint verification system,” in <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">International Conference on Biometrics</em>.   IEEE, 2016, pp. 1–8.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Y. Liu, J. Yan, and W. Ouyang, “Quality aware network for set to set recognition,” in <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</em>, 2017, pp. 5790–5799.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
H. Kazemi, S. Soleymani, A. Dabouei, M. Iranmanesh, and N. M. Nasrabadi, “Attribute-centered loss for soft-biometrics guided face sketch-photo recognition,” in <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops</em>, 2018, pp. 499–507.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
M. Sultana, P. P. Paul, and M. L. Gavrilova, “Social behavioral information fusion in multimodal biometrics,” <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Systems, Man, and Cybernetics: Systems</em>, vol. 48, no. 12, pp. 2176–2187, 2017.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
P. P. Paul, M. L. Gavrilova, and R. Alhajj, “Decision fusion for multimodal biometrics using social network analysis,” <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Systems, Man, and Cybernetics: systems</em>, vol. 44, no. 11, pp. 1522–1533, 2014.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
K. Nandakumar, A. K. Jain, and A. Ross, “Fusion in multibiometric identification systems: What about the missing data?” in <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">International Conference on Biometrics</em>.   Springer, 2009, pp. 743–752.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
D. B. Rubin, “Inference and missing data,” <em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">Biometrika</em>, vol. 63, no. 3, pp. 581–592, 1976.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
K. Bhaskaran and L. Smeeth, “What is the difference between missing completely at random and missing at random?” <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">International Journal of Epidemiology</em>, vol. 43, no. 4, pp. 1336–1339, 2014.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
H. Kang, “The prevention and handling of the missing data,” <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">Korean Journal of Anesthesiology</em>, vol. 64, no. 5, p. 402, 2013.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
S. Van Buuren and K. Groothuis-Oudshoorn, “mice: Multivariate imputation by chained equations in r,” <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Journal of Statistical Software</em>, vol. 45, no. 1, pp. 1–67, 2011.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Q. D. Tran, P. Liatsis, B. Zhu, and C. He, “An approach for multimodal biometric fusion under the missing data scenario,” in <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">International Conference on Uncertainty Reasoning and Knowledge Engineering</em>, vol. 1.   IEEE, 2011, pp. 185–188.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Y. Ding and A. Ross, “A comparison of imputation methods for handling missing scores in biometric fusion,” <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Pattern Recognition</em>, vol. 45, no. 3, pp. 919–933, 2012.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
N. Poh, T. Bourlai, J. Kittler, A. Salah, O. A. John, B. H. Ganster, L. Allano, O. Fatukasi, and O. Ambekar, “A biosecure (ds2) report on the technological evaluation of score-level quality-dependent and cost-sensitive multimodal biometric performance,” 2007, citeseer.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
O. Fatukasi, J. Kittler, and N. Poh, “Estimation of missing values in multimodal biometric fusion,” in <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">IEEE Second International Conference on Biometrics: Theory, Applications and Systems</em>, 2008.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
N. Damer, B. Führer, and A. Kuijper, “Missing data estimation in multi-biometric identification and verification,” in <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">2013 IEEE Workshop on Biometric Measurements and Systems for Security and Medical Applications</em>.   IEEE, 2013, pp. 41–45.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
H.-A. Park and K. R. Park, “Iris recognition based on score level fusion by using svm,” <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">Pattern Recognition Letters</em>, vol. 28, no. 15, pp. 2019–2028, 2007.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
J. Aravinth and S. Valarmathy, “Multi classifier-based score level fusion of multi-modal biometric recognition and its application to remote biometrics authentication,” <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">The Imaging Science Journal</em>, vol. 64, no. 1, pp. 1–14, 2016.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
S. Maity, M. Abdel-Mottaleb, and S. S. Asfour, “Multimodal biometrics recognition from facial video with missing modalities using deep learning,” <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">Journal of Information Processing Systems</em>, vol. 16, no. 1, pp. 6–29, 2020.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
“NIST biometric scores set,” <a target="_blank" href="https://www.nist.gov/itl/iad/ig/biometricscores" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.nist.gov/itl/iad/ig/biometricscores</a>, 2004.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
D. J. MacKay, “Bayesian interpolation,” <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">Neural computation</em>, vol. 4, no. 3, pp. 415–447, 1992.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone, <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">Classification and regression trees</em>.   Routledge, 2017.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
O. Kramer, “K-nearest neighbors,” in <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">Dimensionality reduction with unsupervised nearest neighbors</em>.   Springer, 2013, pp. 13–23.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2408.11270" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2408.11271" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2408.11271">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2408.11271" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2408.11272" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Sep  5 15:20:09 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
