<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2304.07883] Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification</title><meta property="og:description" content="Instance-level object re-identification is a fundamental computer vision task, with applications from image retrieval to intelligent monitoring and fraud detection. In this work, we propose the novel task of damaged ob…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2304.07883">

<!--Generated on Thu Feb 29 14:11:01 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Luca Piano, Filippo Gabriele Pratticò, Alessandro Sebastian Russo, Lorenzo Lanari, Lia Morra, 
<br class="ltx_break">Fabrizio Lamberti 
<br class="ltx_break">Department of Control and Computer Engineering, Politecnico di Torino, Torino, Italy 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter" style="font-size:90%;">{luca.piano,filippogabriele.prattico,alessandrosebastian.russo}@polito.it,

<br class="ltx_break">lorenzo.lanari@studenti.polito.it,{lia.morra,fabrizio.lamberti}@polito.it
</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">Instance-level object re-identification is a fundamental computer vision task, with applications from image retrieval to intelligent monitoring and fraud detection. In this work, we propose the novel task of damaged object re-identification, which aims at distinguishing changes in visual appearance due to deformations or missing parts from subtle intra-class variations. To explore this task, we leverage the power of computer-generated imagery to create, in a semi-automatic fashion, high-quality synthetic images of the same bike before and after a damage occurs. The resulting dataset, Bent &amp; Broken Bicycles (BBBicycles), contains 39,200 images and 2,800 unique bike instances spanning 20 different bike models. As a baseline for this task, we propose TransReI3D, a multi-task, transformer-based deep network unifying damage detection (framed as a multi-label classification task) with object re-identification. The BBBicycles dataset is available at <a target="_blank" href="https://tinyurl.com/37tepf7m" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://tinyurl.com/37tepf7m</a></p>
<p id="id3.id2" class="ltx_p"><span id="id3.id2.1" class="ltx_text ltx_font_bold">keywords</span> instance-level retrieval; re-identification; synthetic data; damage detection; transformers</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Deep learning has fueled unprecedented advances in tasks such as person re-identification (ReID) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, vehicle ReID <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> and instance-level object retrieval <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib54" title="" class="ltx_ref">54</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>. The availability of suitable datasets for training and testing ReID systems is a key ingredient to this success.
Existing ReID benchmarks, typically focusing on persons <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>, <a href="#bib.bib63" title="" class="ltx_ref">63</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> and vehicles <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, are limited in size and variety. Even when they include a large number of IDs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>, <a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite>, they generally cover a limited geographical area (e.g., a town or campus circuit) and time window (e.g., a few hours or days). For this reason, the community has recognized the potential of synthetic data for tasks such as person detection, tracking, and ReID <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. In addition to the sheer volume of generated data, synthetic generation can increase its variety in terms of background, illumination, weather, pose, etc., so that deep neural networks (DNNs) can incorporate all the invariances needed to generalize in real-world conditions.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">In the spirit of pursuing even more robust object ReID, we wish to investigate whether it is possible to make DNNs invariant not only to changes in the environment, but also to changes in the object visual appearance, such as those that could occur due to aging, degradation, damages, or removable/interchangeable parts. Long-term ReID requires the ability to distinguish stable properties over time to account, e.g., for changes in person clothing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> or seasonal changes in places <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>. Here, we propose the novel task of <span id="S1.p2.1.1" class="ltx_text ltx_font_bold">damaged object re-identification</span>, which aims to identify the same object in multiple images even in the presence of breaks, deformations, and missing parts. Besides the theoretical interest, robust object ReID is motivated by practical applications like, e.g., fraud detection and smart contracts in the insurance domain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">As a benchmark for this task, we propose to focus on the study of bicycles, which are characterized by challenging intra-class variations and at the same time allow for a wide range of realistic deformations. Unlike landmarks that have unique and distinctive features, bike instances must be separated based on subtle cues (e.g., color, texture, or stickers). Deformations are inherently different from occlusions, since object parts are visible but with changes in shape (deformation) or texture (e.g., due to mud, dirt, or rust). Therefore, the insights collected from BBBicycles
could be useful for other ReID tasks (e.g., vehicle, person), with similar challenges for long-term ReID. Since acquiring real images of the same bicycle before and after deformation would be prohibitively challenging, we took advantage of computer graphics to generate the Bent &amp; Broken Bicycles (BBBicycles) dataset, which we release as the first dataset for training and testing DNNs for damaged object ReID.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Our <span id="S1.p4.1.1" class="ltx_text ltx_font_bold">contributions</span> can be summarized as follows:</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We design a semi-automatic computer graphics pipeline to simulate different types of damage, breaks, missing parts, and material deterioration. Extensive domain randomization is further employed to train deep networks robust to variations in bicycle pose, background, etc. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>, <a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We release the BBBicycles dataset containing 39,000 annotated images. BBBicycles allows DNNs to (learn to) differentiate subtle intra-class variations (including different setups of the same bike model) from deformations occurring due to incidents, or aging.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We propose TransReI3D (Transformer-based object Re-IDentification &amp; Damage Detection), a novel transformer-based multitask DNN for joint damage detection (DD) and ReID.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Transformer-based re-identification</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">Object ReID is the task of identifying the same object across multiple images, regardless of its pose, illumination, or context. It has many important applications such as intelligent monitoring <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite>, multi-object tracking and robotics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, fraud detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>, etc. The reader is referred to many comprehensive surveys for an introduction to this vast body of literature <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>. In recent years, the Vision Transformer (ViT) architecture <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> has sparked a new wave of transformer-based architectures for many computer vision tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>.
Transformer-based ReID solutions can be broadly categorized in <span id="S2.SS1.p1.1.1" class="ltx_text ltx_font_italic"> hybrid transformer-CNN</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> and <span id="S2.SS1.p1.1.2" class="ltx_text ltx_font_italic">pure ViT-based</span> architectures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">Hybrid architectures combine CNNs as a feature extractor with a transformer-based module that tackles the matching and metric learning problem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>, <a href="#bib.bib60" title="" class="ltx_ref">60</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. This approach leverages, on the one hand, CNNs hard inductive biases (e.g., translation equivariance) to work effectively on small- to medium-scale datasets. On the other hand, transformers enable cross-attention mechanisms between pairs of query and gallery images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>. For instance, the Reranking Transformer <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite> concatenates image patches from both the query and gallery images in a single sequence, which is then fed to a final classifier predicting the probability of two images representing the same object.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.1" class="ltx_p">More recently, a variety of pure transformer-based approaches have achieved state-of-the-art results in several ReID tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>, <a href="#bib.bib66" title="" class="ltx_ref">66</a>, <a href="#bib.bib44" title="" class="ltx_ref">44</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. Compared to CNNs, transformers are better suited to handling long-range dependencies and avoid the use of downsampling operators (e.g., pooling and strided convolutions) that may obscure important visual details <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. The available architectures are typically based on a ViT backbone, pre-trained on very large-scale datasets such as ImageNet21K, and modified to extract both local and global features <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Synthetic data in deep learning</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">The use of synthetic data is becoming increasingly popular for training machine and deep learning models. Although it is being experimented in multiple domains like, e.g., bioinformatics <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>, natural language processing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>, etc., this approach is indeed expected to bring the largest benefits to the field of computer vision.
Synthetic data generation is not only an effective approach to scale data generation and annotation, it can also be used to evaluate the robustness of an algorithm under controlled conditions or to alleviate data privacy issues <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">A recent survey categorized hundreds of synthetic datasets and the use cases they have been devised for <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite>. Initially used to address low-level computer vision tasks such as optical flow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, synthetic datasets are increasingly used to generate training datasets for high-level tasks such as, e.g., object recognition and detection <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, pose estimation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>, segmentation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, human action recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> and pedestrian tracking and ReID <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. Works in this field typically build onto well-known repositories, including millions of virtual models with known categories or properties, which can be programmatically manipulated to automate both data generation and its labelling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">Popular approaches for collecting synthetic data also include the use of video games <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib48" title="" class="ltx_ref">48</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>, <a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite>, or fusing real and virtual data via compositing techniques and placing, e.g., virtual models onto real background images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.</p>
</div>
<div id="S2.SS2.p4" class="ltx_para">
<p id="S2.SS2.p4.1" class="ltx_p">One of the main challenges associated with synthetic data is the domain shift between real and synthetic images, which can be tackled through transfer learning or domain adaptation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>, <a href="#bib.bib46" title="" class="ltx_ref">46</a>, <a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>.
<span id="S2.SS2.p4.1.1" class="ltx_text ltx_font_italic">Domain randomization</span> is a technique used to enhance the variability of synthetic data and has been shown to substantially increase performance in the real world <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>.
With ever increasing CGI fidelity, the synthetic-to-real domain gap is progressively reducing. Recent exciting results showed that training DNNs on very large and diverse synthetic datasets can outperform using public real datasets on tasks such as pedestrian tracking and ReID, even without fine-tuning on real data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span> Dataset</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">This section describes the semiautomatic CGI pipeline designed to generate the BBBicycles dataset, together with its main properties and distribution.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2304.07883/assets/x1.png" id="S3.F1.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="370" height="175" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.3.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S3.F1.4.2" class="ltx_text" style="font-size:90%;">Flowchart illustrating the CGI pipeline. The 3D model is manually prepared (Phase 1) so that it can be easily manipulated by a semi-automatic image rendering script (Phase 2). The script first selects the material textures and colors, thus obtaining a new bike instance (ID). For each ID, multiple images (“before” and “after” the damage) are generated, simulating damages (missing parts, bent and broken frames, etc.) with varying probabilities. Finally, the scene is generated by placing the bike onto a random background.</span></figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>CGI Pipeline</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">The CGI pipeline, depicted in <a href="#S3.F1" title="Figure 1 ‣ 3 Dataset ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 1</span></a>, consists of two main phases. The first phase is model preparation, which is mostly manual and performed once for each bike model. In the second phase, a semi-automatic script generates a set of rendered images, depicting multiple views and variations of a given input bike, along with labeling and segmentation information. We sought to create a pipeline that could be applied to generate new datasets with limited human effort and hardware resources. Following this philosophy, we sacrificed some degree of photorealism in favor of reduced rendering time and increased variability.
Damages and deformations were implemented based on the classical CGI technique of 3D polygonal meshes armature deformation.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">This approach was preferred to, e.g., physics simulations, since it drastically reduces the overall rendering time while maintaining control over the output features desired in terms of missing parts, type of damage, etc.
The whole pipeline was implemented in Blender v2.93 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>
and the automatic procedure was scripted in Python as a custom add-on.</p>
</div>
<section id="S3.SS1.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Model preparation.</h5>

<div id="S3.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p1.1" class="ltx_p">The input can be either a 3D parametric model (e.g., CAD file) or a polygonal mesh. In the former case, a polygonal conversion is first required to generate a polygonal model.
To ensure visually plausible deformations, a retopology operation has to be performed in order to obtain <em id="S3.SS1.SSS0.Px1.p1.1.1" class="ltx_emph ltx_font_italic">quad-flow</em> based topologies with proper vertex density in the parts that will later be subject to deformation.
Afterwards, the model is rigged and skinned (i.e., each vertex is associated with a deformation tool of the rig). To make the model easily controlled, we defined a <em id="S3.SS1.SSS0.Px1.p1.1.2" class="ltx_emph ltx_font_italic">template rig</em> that needs to be adapted to the given bike model.
The template rig is made up
of an “armature”, “lattices”, and “rail guides” (examples are shown in Appendix A).</p>
</div>
<div id="S3.SS1.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p2.1" class="ltx_p">More in detail, the template <span id="S3.SS1.SSS0.Px1.p2.1.1" class="ltx_text ltx_font_bold">Armature</span> includes three groups/layers of “bones”. The red bones are linked to the seat and handlebar meshes (rigid-body movement). The green bones, placed in the salient parts/joints, are used as inverse kinematic controls (targets and poles) by the blue chains. The latter are the so-called deformation bones; only this group was modified by adding/removing bones, if required by the peculiarities of the bike model. These deformation chains are the ones used for the bike frame mesh skinning, whereas other parts (e.g., seat, handlebars, and wheels) are parented (bone relatively) to the dedicated bones of the other two groups. A set of predefined deformations were devised in the form of a pose library to both change the poses of the movable bike components and introduce damages while rendering the images.</p>
</div>
<div id="S3.SS1.SSS0.Px1.p3" class="ltx_para">
<p id="S3.SS1.SSS0.Px1.p3.1" class="ltx_p">The <span id="S3.SS1.SSS0.Px1.p3.1.1" class="ltx_text ltx_font_bold">Lattice</span> is a three-dimensional non-renderable grid of vertices, a.k.a. deformation cage. Lattices are a convenient way of proportionally deforming a dense mesh with fewer control points since, by deforming the cage, the deformation will be transferred to the associated mesh. The lattices were used to damage the wheels. A set of deformations was devised also in this case in the form of a shape key (a.k.a. blend shape) library.
Additionally, <span id="S3.SS1.SSS0.Px1.p3.1.2" class="ltx_text ltx_font_bold">Rail guides</span> were
used to break the bike frame exploiting a boolean mesh operation on a plane that takes the guides as reference.</p>
</div>
</section>
<section id="S3.SS1.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Domain randomization and image rendering.</h5>

<div id="S3.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p1.1" class="ltx_p">After the 3D model is arranged as described, it is possible to automatically render a variety of different pictures, as described in the following. First, the 3D model is configured by randomly selecting a set of materials (texture, color, and decals) from the material library. A physically based rendering (PBR) material library was defined, from which to pick a suitable material, among several possible choices, for each bike part. <span id="S3.SS1.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">A given combination of 3D model and materials corresponds to a single bicycle instance and is therefore assigned a unique ID</span>. Second, for each ID, multiple images are generated, “before” or “after” a damage occurs, by applying the following transformations: i) changing the pose of mobile parts (seat, handlebar, pedals and wheels); ii) (optional) applying mud or rust; iii) (optional) damage simulation; iv) point of view selection; and v) background and lighting selection. All deformations are applied randomly with predetermined probabilities and/or ranges. Possible damages include removal of one or more parts of the bike (seat, pedals, handlebar, and wheels), bent frame, broken frame, and wheel deformation.</p>
</div>
<div id="S3.SS1.SSS0.Px2.p2" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p2.1" class="ltx_p">Finally, the rendered bike must be placed onto a suitable background, adjusting for the specific lighting conditions.</p>
</div>
<div id="S3.SS1.SSS0.Px2.p3" class="ltx_para">
<p id="S3.SS1.SSS0.Px2.p3.1" class="ltx_p">The approach considered in the pipeline takes advantage of the LilyScraper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, a Blender add-on to use a High Dynamic Range Imaging (HDRI) map as background and light source, in combination with a shadow-catcher plane. The setup of the environment and the lighting was performed once for all models.</p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>BBBicycles characteristics</h3>

<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Dataset distribution.</h5>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p1.1" class="ltx_p">The final dataset contains a total of 39,200 images from 2,800 unique IDs (20 models, 140 IDs each).
20 models retrieved from dedicated marketplaces were prepared, including 6 MTBs, 1 Enduro, 6 Road bikes, 1 Circuit, 1 Gravel and 5 Cruiser (following the categorization introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>). For the textures, we collected five patterns of various styles. Both the base and pattern colors were randomly chosen from a pool of 50 colors. Additionally, 10 different decals containing logos from famous bike brands such as <em id="S3.SS2.SSS0.Px1.p1.1.1" class="ltx_emph ltx_font_italic">Bianchi</em> and <em id="S3.SS2.SSS0.Px1.p1.1.2" class="ltx_emph ltx_font_italic">Cannondale</em> were randomly applied. The background was selected from a pool of 11 different 360° HDRIs, varying bike positioning and illumination by rotating the camera.</p>
</div>
<div id="S3.SS2.SSS0.Px1.p2" class="ltx_para">
<p id="S3.SS2.SSS0.Px1.p2.1" class="ltx_p">For each bike ID, up to 14 renderings were generated, evenly divided in “before” and “after” images as shown in the flowchart (<a href="#S3.F1" title="Figure 1 ‣ 3 Dataset ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 1</span></a>). For “before” images, only dirt or rust was applied with 20% probability. For “after” images, dirt/rust was applied with 50% probability, damages to the frame were applied with 75% probability (25% were bent, 25% were broken and 25% were both bent and broken), and finally each removable part (seat, pedals, handlebar, and wheels) was removed (50% probability) or deformed (50% probability). Thus, some of the “after” images are not damaged.
Labels for the ReID task were automatically generated based on the bike unique ID assigned by the pipeline.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Training, validation, and stress test set.</h5>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px2.p1.1" class="ltx_p">The dataset was split into a training, validation, and test set at the level of bike ID and model to test DNNs’ ability to generalize both across IDs and across models. The validation set includes both models seen and unseen during training, whereas the (stress) test set includes only models that were never seen in either the training or validation set, to ensure that it is sufficiently challenging and representative of real operating conditions. Specifically, the training set contains 25,676 images (1,834 IDs, 14 models), the validation set contains 1,128 images (564 IDs, 12 models), and the stress test contains 840 images (420 IDs, 3 models).</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Real dataset.</h5>

<div id="S3.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S3.SS2.SSS0.Px3.p1.1" class="ltx_p">A separate dataset of real photos of damaged and undamaged bikes was also collected to test the ability of TransReI3D to generalize to the real domain.
We combined a subset of the publicly available DelftBikes dataset
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> with images collected by web scraping from popular search engines and e-commerce sites. The images were manually labeled following the same criteria as those used for the synthetic dataset. A total of 6,292 images were collected, of which 106 presented a Bent (64) or Broken (52) frame.
The dataset was split into train, validation and test with a 7:1.5:1.5 split, stratified by damage type.</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Methodology</h2>

<figure id="S4.F2" class="ltx_figure"><img src="/html/2304.07883/assets/x2.png" id="S4.F2.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="396" height="205" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.8.3.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S4.F2.5.2" class="ltx_text" style="font-size:90%;">TransReI3D architecture. Embeddings are enriched with position and camera information (side information embedding). A learnable [<span id="S4.F2.5.2.1" class="ltx_text ltx_font_italic">cls</span>] token is prepended to the embeddings which are input to a shared backbone. Task-specific branches (DD branch, Global ReID branch and Jigsaw Branch with JPM) include a separate transformer layer to adapt global features to each task. The Jigsaw Module, <math id="S4.F2.4.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{ID}" display="inline"><semantics id="S4.F2.4.1.m1.1b"><msub id="S4.F2.4.1.m1.1.1" xref="S4.F2.4.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.F2.4.1.m1.1.1.2" xref="S4.F2.4.1.m1.1.1.2.cmml">ℒ</mi><mrow id="S4.F2.4.1.m1.1.1.3" xref="S4.F2.4.1.m1.1.1.3.cmml"><mi id="S4.F2.4.1.m1.1.1.3.2" xref="S4.F2.4.1.m1.1.1.3.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="S4.F2.4.1.m1.1.1.3.1" xref="S4.F2.4.1.m1.1.1.3.1.cmml">​</mo><mi id="S4.F2.4.1.m1.1.1.3.3" xref="S4.F2.4.1.m1.1.1.3.3.cmml">D</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.F2.4.1.m1.1c"><apply id="S4.F2.4.1.m1.1.1.cmml" xref="S4.F2.4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.F2.4.1.m1.1.1.1.cmml" xref="S4.F2.4.1.m1.1.1">subscript</csymbol><ci id="S4.F2.4.1.m1.1.1.2.cmml" xref="S4.F2.4.1.m1.1.1.2">ℒ</ci><apply id="S4.F2.4.1.m1.1.1.3.cmml" xref="S4.F2.4.1.m1.1.1.3"><times id="S4.F2.4.1.m1.1.1.3.1.cmml" xref="S4.F2.4.1.m1.1.1.3.1"></times><ci id="S4.F2.4.1.m1.1.1.3.2.cmml" xref="S4.F2.4.1.m1.1.1.3.2">𝐼</ci><ci id="S4.F2.4.1.m1.1.1.3.3.cmml" xref="S4.F2.4.1.m1.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.4.1.m1.1d">\mathcal{L}_{ID}</annotation></semantics></math>, and <math id="S4.F2.5.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{T}" display="inline"><semantics id="S4.F2.5.2.m2.1b"><msub id="S4.F2.5.2.m2.1.1" xref="S4.F2.5.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.F2.5.2.m2.1.1.2" xref="S4.F2.5.2.m2.1.1.2.cmml">ℒ</mi><mi id="S4.F2.5.2.m2.1.1.3" xref="S4.F2.5.2.m2.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.F2.5.2.m2.1c"><apply id="S4.F2.5.2.m2.1.1.cmml" xref="S4.F2.5.2.m2.1.1"><csymbol cd="ambiguous" id="S4.F2.5.2.m2.1.1.1.cmml" xref="S4.F2.5.2.m2.1.1">subscript</csymbol><ci id="S4.F2.5.2.m2.1.1.2.cmml" xref="S4.F2.5.2.m2.1.1.2">ℒ</ci><ci id="S4.F2.5.2.m2.1.1.3.cmml" xref="S4.F2.5.2.m2.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.F2.5.2.m2.1d">\mathcal{L}_{T}</annotation></semantics></math> are described in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>.
</span></figcaption>
</figure>
<section id="S4.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Problem setting</h5>

<div id="S4.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px1.p1.13" class="ltx_p">We assume that the training set <math id="S4.SS0.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.1.m1.1a"><mi id="S4.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.1.m1.1b"><ci id="S4.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.1.m1.1c">D</annotation></semantics></math> consists of <math id="S4.SS0.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.2.m2.1a"><mi id="S4.SS0.SSS0.Px1.p1.2.m2.1.1" xref="S4.SS0.SSS0.Px1.p1.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.2.m2.1b"><ci id="S4.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.2.m2.1c">N</annotation></semantics></math> sequences of synthetic images <math id="S4.SS0.SSS0.Px1.p1.3.m3.2" class="ltx_Math" alttext="D={\{(x^{1}_{i},...,x^{M}_{i})\}}_{i=1}^{N}" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.3.m3.2a"><mrow id="S4.SS0.SSS0.Px1.p1.3.m3.2.2" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.cmml"><mi id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.3" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.3.cmml">D</mi><mo id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.2" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.2.cmml">=</mo><msubsup id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.cmml"><mrow id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.2.cmml"><mo stretchy="false" id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.2" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.2.cmml">{</mo><mrow id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.3" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.3.cmml">(</mo><msubsup id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1.cmml"><mi id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1.2.2" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1.3" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1.3.cmml">i</mi><mn id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1.2.3" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1.2.3.cmml">1</mn></msubsup><mo id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.4" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.3.cmml">,</mo><mi mathvariant="normal" id="S4.SS0.SSS0.Px1.p1.3.m3.1.1" xref="S4.SS0.SSS0.Px1.p1.3.m3.1.1.cmml">…</mi><mo id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.5" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.3.cmml">,</mo><msubsup id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2.cmml"><mi id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2.2.2" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2.2.2.cmml">x</mi><mi id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2.3" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2.3.cmml">i</mi><mi id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2.2.3" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2.2.3.cmml">M</mi></msubsup><mo stretchy="false" id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.6" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.3.cmml">)</mo></mrow><mo stretchy="false" id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.3" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.2.cmml">}</mo></mrow><mrow id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.3" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.3.cmml"><mi id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.3.2" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.3.2.cmml">i</mi><mo id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.3.1" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.3.1.cmml">=</mo><mn id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.3.3" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.3.3.cmml">1</mn></mrow><mi id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.3" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.3.cmml">N</mi></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.3.m3.2b"><apply id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2"><eq id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.2"></eq><ci id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.3.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.3">𝐷</ci><apply id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1">superscript</csymbol><apply id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1">subscript</csymbol><set id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1"><vector id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.3.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2"><apply id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1">subscript</csymbol><apply id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1.2.1.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1">superscript</csymbol><ci id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1.2.2">𝑥</ci><cn type="integer" id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1.2.3.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1.2.3">1</cn></apply><ci id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1.3.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.1.1.3">𝑖</ci></apply><ci id="S4.SS0.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.1.1">…</ci><apply id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2.1.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2">subscript</csymbol><apply id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2.2.1.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2">superscript</csymbol><ci id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2.2.2">𝑥</ci><ci id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2.2.3.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2.2.3">𝑀</ci></apply><ci id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2.3.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.1.1.1.2.2.3">𝑖</ci></apply></vector></set><apply id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.3.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.3"><eq id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.3.1.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.3.1"></eq><ci id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.3.2.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.3.2">𝑖</ci><cn type="integer" id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.3.3.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.1.3.3">1</cn></apply></apply><ci id="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.3.cmml" xref="S4.SS0.SSS0.Px1.p1.3.m3.2.2.1.3">𝑁</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.3.m3.2c">D={\{(x^{1}_{i},...,x^{M}_{i})\}}_{i=1}^{N}</annotation></semantics></math>, where all images <math id="S4.SS0.SSS0.Px1.p1.4.m4.1" class="ltx_Math" alttext="x^{j}_{i}" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.4.m4.1a"><msubsup id="S4.SS0.SSS0.Px1.p1.4.m4.1.1" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1.cmml"><mi id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2.2" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2.2.cmml">x</mi><mi id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.3" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1.3.cmml">i</mi><mi id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2.3" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2.3.cmml">j</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.4.m4.1b"><apply id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1">subscript</csymbol><apply id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2.1.cmml" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1">superscript</csymbol><ci id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2.2">𝑥</ci><ci id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2.3.cmml" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1.2.3">𝑗</ci></apply><ci id="S4.SS0.SSS0.Px1.p1.4.m4.1.1.3.cmml" xref="S4.SS0.SSS0.Px1.p1.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.4.m4.1c">x^{j}_{i}</annotation></semantics></math> in a sequence are associated with the same ID <math id="S4.SS0.SSS0.Px1.p1.5.m5.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.5.m5.1a"><mi id="S4.SS0.SSS0.Px1.p1.5.m5.1.1" xref="S4.SS0.SSS0.Px1.p1.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.5.m5.1b"><ci id="S4.SS0.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.5.m5.1c">i</annotation></semantics></math> and represent the same bike instance. We additionally assume that each image is associated with a set of binary attributes, each representing the presence of a specific kind of damage ( <math id="S4.SS0.SSS0.Px1.p1.6.m6.3" class="ltx_Math" alttext="a^{j}_{i}\in\mathcal{A}=\{BD,BK,P_{n}\}" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.6.m6.3a"><mrow id="S4.SS0.SSS0.Px1.p1.6.m6.3.3" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.cmml"><msubsup id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5.cmml"><mi id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5.2.2" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5.2.2.cmml">a</mi><mi id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5.3" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5.3.cmml">i</mi><mi id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5.2.3" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5.2.3.cmml">j</mi></msubsup><mo id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.6" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.6.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.7" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.7.cmml">𝒜</mi><mo id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.8" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.8.cmml">=</mo><mrow id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.3" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.4.cmml"><mo stretchy="false" id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.3.4" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.4.cmml">{</mo><mrow id="S4.SS0.SSS0.Px1.p1.6.m6.1.1.1.1.1" xref="S4.SS0.SSS0.Px1.p1.6.m6.1.1.1.1.1.cmml"><mi id="S4.SS0.SSS0.Px1.p1.6.m6.1.1.1.1.1.2" xref="S4.SS0.SSS0.Px1.p1.6.m6.1.1.1.1.1.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S4.SS0.SSS0.Px1.p1.6.m6.1.1.1.1.1.1" xref="S4.SS0.SSS0.Px1.p1.6.m6.1.1.1.1.1.1.cmml">​</mo><mi id="S4.SS0.SSS0.Px1.p1.6.m6.1.1.1.1.1.3" xref="S4.SS0.SSS0.Px1.p1.6.m6.1.1.1.1.1.3.cmml">D</mi></mrow><mo id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.3.5" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.4.cmml">,</mo><mrow id="S4.SS0.SSS0.Px1.p1.6.m6.2.2.2.2.2" xref="S4.SS0.SSS0.Px1.p1.6.m6.2.2.2.2.2.cmml"><mi id="S4.SS0.SSS0.Px1.p1.6.m6.2.2.2.2.2.2" xref="S4.SS0.SSS0.Px1.p1.6.m6.2.2.2.2.2.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S4.SS0.SSS0.Px1.p1.6.m6.2.2.2.2.2.1" xref="S4.SS0.SSS0.Px1.p1.6.m6.2.2.2.2.2.1.cmml">​</mo><mi id="S4.SS0.SSS0.Px1.p1.6.m6.2.2.2.2.2.3" xref="S4.SS0.SSS0.Px1.p1.6.m6.2.2.2.2.2.3.cmml">K</mi></mrow><mo id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.3.6" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.4.cmml">,</mo><msub id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.3.3" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.3.3.cmml"><mi id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.3.3.2" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.3.3.2.cmml">P</mi><mi id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.3.3.3" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.3.3.3.cmml">n</mi></msub><mo stretchy="false" id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.3.7" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.4.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.6.m6.3b"><apply id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3"><and id="S4.SS0.SSS0.Px1.p1.6.m6.3.3a.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3"></and><apply id="S4.SS0.SSS0.Px1.p1.6.m6.3.3b.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3"><in id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.6.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.6"></in><apply id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5.1.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5">subscript</csymbol><apply id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5.2.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5.2.1.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5">superscript</csymbol><ci id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5.2.2">𝑎</ci><ci id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5.2.3.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5.2.3">𝑗</ci></apply><ci id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5.3.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.5.3">𝑖</ci></apply><ci id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.7.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.7">𝒜</ci></apply><apply id="S4.SS0.SSS0.Px1.p1.6.m6.3.3c.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3"><eq id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.8.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.8"></eq><share href="#S4.SS0.SSS0.Px1.p1.6.m6.3.3.7.cmml" id="S4.SS0.SSS0.Px1.p1.6.m6.3.3d.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3"></share><set id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.4.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.3"><apply id="S4.SS0.SSS0.Px1.p1.6.m6.1.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.1.1.1.1.1"><times id="S4.SS0.SSS0.Px1.p1.6.m6.1.1.1.1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.1.1.1.1.1.1"></times><ci id="S4.SS0.SSS0.Px1.p1.6.m6.1.1.1.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.1.1.1.1.1.2">𝐵</ci><ci id="S4.SS0.SSS0.Px1.p1.6.m6.1.1.1.1.1.3.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.1.1.1.1.1.3">𝐷</ci></apply><apply id="S4.SS0.SSS0.Px1.p1.6.m6.2.2.2.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.2.2.2.2.2"><times id="S4.SS0.SSS0.Px1.p1.6.m6.2.2.2.2.2.1.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.2.2.2.2.2.1"></times><ci id="S4.SS0.SSS0.Px1.p1.6.m6.2.2.2.2.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.2.2.2.2.2.2">𝐵</ci><ci id="S4.SS0.SSS0.Px1.p1.6.m6.2.2.2.2.2.3.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.2.2.2.2.2.3">𝐾</ci></apply><apply id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.3.3.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.3.3"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.3.3.1.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.3.3">subscript</csymbol><ci id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.3.3.2.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.3.3.2">𝑃</ci><ci id="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.3.3.3.cmml" xref="S4.SS0.SSS0.Px1.p1.6.m6.3.3.3.3.3.3">𝑛</ci></apply></set></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.6.m6.3c">a^{j}_{i}\in\mathcal{A}=\{BD,BK,P_{n}\}</annotation></semantics></math>); <math id="S4.SS0.SSS0.Px1.p1.7.m7.1" class="ltx_Math" alttext="P_{n}" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.7.m7.1a"><msub id="S4.SS0.SSS0.Px1.p1.7.m7.1.1" xref="S4.SS0.SSS0.Px1.p1.7.m7.1.1.cmml"><mi id="S4.SS0.SSS0.Px1.p1.7.m7.1.1.2" xref="S4.SS0.SSS0.Px1.p1.7.m7.1.1.2.cmml">P</mi><mi id="S4.SS0.SSS0.Px1.p1.7.m7.1.1.3" xref="S4.SS0.SSS0.Px1.p1.7.m7.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.7.m7.1b"><apply id="S4.SS0.SSS0.Px1.p1.7.m7.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.7.m7.1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.7.m7.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px1.p1.7.m7.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.7.m7.1.1.2">𝑃</ci><ci id="S4.SS0.SSS0.Px1.p1.7.m7.1.1.3.cmml" xref="S4.SS0.SSS0.Px1.p1.7.m7.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.7.m7.1c">P_{n}</annotation></semantics></math> indicates whether the <math id="S4.SS0.SSS0.Px1.p1.8.m8.1" class="ltx_Math" alttext="n^{th}" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.8.m8.1a"><msup id="S4.SS0.SSS0.Px1.p1.8.m8.1.1" xref="S4.SS0.SSS0.Px1.p1.8.m8.1.1.cmml"><mi id="S4.SS0.SSS0.Px1.p1.8.m8.1.1.2" xref="S4.SS0.SSS0.Px1.p1.8.m8.1.1.2.cmml">n</mi><mrow id="S4.SS0.SSS0.Px1.p1.8.m8.1.1.3" xref="S4.SS0.SSS0.Px1.p1.8.m8.1.1.3.cmml"><mi id="S4.SS0.SSS0.Px1.p1.8.m8.1.1.3.2" xref="S4.SS0.SSS0.Px1.p1.8.m8.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S4.SS0.SSS0.Px1.p1.8.m8.1.1.3.1" xref="S4.SS0.SSS0.Px1.p1.8.m8.1.1.3.1.cmml">​</mo><mi id="S4.SS0.SSS0.Px1.p1.8.m8.1.1.3.3" xref="S4.SS0.SSS0.Px1.p1.8.m8.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.8.m8.1b"><apply id="S4.SS0.SSS0.Px1.p1.8.m8.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.8.m8.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.8.m8.1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.8.m8.1.1">superscript</csymbol><ci id="S4.SS0.SSS0.Px1.p1.8.m8.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.8.m8.1.1.2">𝑛</ci><apply id="S4.SS0.SSS0.Px1.p1.8.m8.1.1.3.cmml" xref="S4.SS0.SSS0.Px1.p1.8.m8.1.1.3"><times id="S4.SS0.SSS0.Px1.p1.8.m8.1.1.3.1.cmml" xref="S4.SS0.SSS0.Px1.p1.8.m8.1.1.3.1"></times><ci id="S4.SS0.SSS0.Px1.p1.8.m8.1.1.3.2.cmml" xref="S4.SS0.SSS0.Px1.p1.8.m8.1.1.3.2">𝑡</ci><ci id="S4.SS0.SSS0.Px1.p1.8.m8.1.1.3.3.cmml" xref="S4.SS0.SSS0.Px1.p1.8.m8.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.8.m8.1c">n^{th}</annotation></semantics></math> part is present or missing. Given <math id="S4.SS0.SSS0.Px1.p1.9.m9.1" class="ltx_Math" alttext="D" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.9.m9.1a"><mi id="S4.SS0.SSS0.Px1.p1.9.m9.1.1" xref="S4.SS0.SSS0.Px1.p1.9.m9.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.9.m9.1b"><ci id="S4.SS0.SSS0.Px1.p1.9.m9.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.9.m9.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.9.m9.1c">D</annotation></semantics></math>, our aim is to learn an embedding space <math id="S4.SS0.SSS0.Px1.p1.10.m10.1" class="ltx_Math" alttext="x^{j}_{i}\in\mathbb{R}^{h\times w\times ch}\mapsto e^{j}_{i}\in\mathbb{R}^{m}" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.10.m10.1a"><mrow id="S4.SS0.SSS0.Px1.p1.10.m10.1.1" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.cmml"><msubsup id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2.cmml"><mi id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2.2.2" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2.2.2.cmml">x</mi><mi id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2.3" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2.3.cmml">i</mi><mi id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2.2.3" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2.2.3.cmml">j</mi></msubsup><mo id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.3" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.3.cmml">∈</mo><msup id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.cmml"><mi id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.2" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.2.cmml">ℝ</mi><mrow id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.cmml"><mrow id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2.cmml"><mi id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2.2" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2.2.cmml">h</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2.1" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2.1.cmml">×</mo><mi id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2.3" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2.3.cmml">w</mi><mo lspace="0.222em" rspace="0.222em" id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2.1a" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2.1.cmml">×</mo><mi id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2.4" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2.4.cmml">c</mi></mrow><mo lspace="0em" rspace="0em" id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.1" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.1.cmml">​</mo><mi id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.3" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.3.cmml">h</mi></mrow></msup><mo stretchy="false" id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.5" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.5.cmml">↦</mo><msubsup id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6.cmml"><mi id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6.2.2" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6.2.2.cmml">e</mi><mi id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6.3" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6.3.cmml">i</mi><mi id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6.2.3" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6.2.3.cmml">j</mi></msubsup><mo id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.7" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.7.cmml">∈</mo><msup id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.8" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.8.cmml"><mi id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.8.2" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.8.2.cmml">ℝ</mi><mi id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.8.3" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.8.3.cmml">m</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.10.m10.1b"><apply id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1"><and id="S4.SS0.SSS0.Px1.p1.10.m10.1.1a.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1"></and><apply id="S4.SS0.SSS0.Px1.p1.10.m10.1.1b.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1"><in id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.3.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.3"></in><apply id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2.1.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2">subscript</csymbol><apply id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2.2.1.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2">superscript</csymbol><ci id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2.2.2">𝑥</ci><ci id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2.2.3.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2.2.3">𝑗</ci></apply><ci id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2.3.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.2.3">𝑖</ci></apply><apply id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.1.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4">superscript</csymbol><ci id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.2.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.2">ℝ</ci><apply id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3"><times id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.1.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.1"></times><apply id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2"><times id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2.1.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2.1"></times><ci id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2.2">ℎ</ci><ci id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2.3.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2.3">𝑤</ci><ci id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2.4.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.2.4">𝑐</ci></apply><ci id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.3.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.3.3">ℎ</ci></apply></apply></apply><apply id="S4.SS0.SSS0.Px1.p1.10.m10.1.1c.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1"><csymbol cd="latexml" id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.5.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.5">maps-to</csymbol><share href="#S4.SS0.SSS0.Px1.p1.10.m10.1.1.4.cmml" id="S4.SS0.SSS0.Px1.p1.10.m10.1.1d.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1"></share><apply id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6.1.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6">subscript</csymbol><apply id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6.2.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6.2.1.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6">superscript</csymbol><ci id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6.2.2">𝑒</ci><ci id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6.2.3.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6.2.3">𝑗</ci></apply><ci id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6.3.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.6.3">𝑖</ci></apply></apply><apply id="S4.SS0.SSS0.Px1.p1.10.m10.1.1e.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1"><in id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.7.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.7"></in><share href="#S4.SS0.SSS0.Px1.p1.10.m10.1.1.6.cmml" id="S4.SS0.SSS0.Px1.p1.10.m10.1.1f.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1"></share><apply id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.8.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.8"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.8.1.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.8">superscript</csymbol><ci id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.8.2.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.8.2">ℝ</ci><ci id="S4.SS0.SSS0.Px1.p1.10.m10.1.1.8.3.cmml" xref="S4.SS0.SSS0.Px1.p1.10.m10.1.1.8.3">𝑚</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.10.m10.1c">x^{j}_{i}\in\mathbb{R}^{h\times w\times ch}\mapsto e^{j}_{i}\in\mathbb{R}^{m}</annotation></semantics></math> such that all images associated with a given ID <math id="S4.SS0.SSS0.Px1.p1.11.m11.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.11.m11.1a"><mi id="S4.SS0.SSS0.Px1.p1.11.m11.1.1" xref="S4.SS0.SSS0.Px1.p1.11.m11.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.11.m11.1b"><ci id="S4.SS0.SSS0.Px1.p1.11.m11.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.11.m11.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.11.m11.1c">i</annotation></semantics></math> are closer in the embedding space than other IDs, regardless of the attributes <math id="S4.SS0.SSS0.Px1.p1.12.m12.1" class="ltx_Math" alttext="a^{j}_{i}" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.12.m12.1a"><msubsup id="S4.SS0.SSS0.Px1.p1.12.m12.1.1" xref="S4.SS0.SSS0.Px1.p1.12.m12.1.1.cmml"><mi id="S4.SS0.SSS0.Px1.p1.12.m12.1.1.2.2" xref="S4.SS0.SSS0.Px1.p1.12.m12.1.1.2.2.cmml">a</mi><mi id="S4.SS0.SSS0.Px1.p1.12.m12.1.1.3" xref="S4.SS0.SSS0.Px1.p1.12.m12.1.1.3.cmml">i</mi><mi id="S4.SS0.SSS0.Px1.p1.12.m12.1.1.2.3" xref="S4.SS0.SSS0.Px1.p1.12.m12.1.1.2.3.cmml">j</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.12.m12.1b"><apply id="S4.SS0.SSS0.Px1.p1.12.m12.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.12.m12.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.12.m12.1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.12.m12.1.1">subscript</csymbol><apply id="S4.SS0.SSS0.Px1.p1.12.m12.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.12.m12.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.12.m12.1.1.2.1.cmml" xref="S4.SS0.SSS0.Px1.p1.12.m12.1.1">superscript</csymbol><ci id="S4.SS0.SSS0.Px1.p1.12.m12.1.1.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.12.m12.1.1.2.2">𝑎</ci><ci id="S4.SS0.SSS0.Px1.p1.12.m12.1.1.2.3.cmml" xref="S4.SS0.SSS0.Px1.p1.12.m12.1.1.2.3">𝑗</ci></apply><ci id="S4.SS0.SSS0.Px1.p1.12.m12.1.1.3.cmml" xref="S4.SS0.SSS0.Px1.p1.12.m12.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.12.m12.1c">a^{j}_{i}</annotation></semantics></math>. We further define the DD task as predicting the values of <math id="S4.SS0.SSS0.Px1.p1.13.m13.1" class="ltx_Math" alttext="a^{j}_{i}" display="inline"><semantics id="S4.SS0.SSS0.Px1.p1.13.m13.1a"><msubsup id="S4.SS0.SSS0.Px1.p1.13.m13.1.1" xref="S4.SS0.SSS0.Px1.p1.13.m13.1.1.cmml"><mi id="S4.SS0.SSS0.Px1.p1.13.m13.1.1.2.2" xref="S4.SS0.SSS0.Px1.p1.13.m13.1.1.2.2.cmml">a</mi><mi id="S4.SS0.SSS0.Px1.p1.13.m13.1.1.3" xref="S4.SS0.SSS0.Px1.p1.13.m13.1.1.3.cmml">i</mi><mi id="S4.SS0.SSS0.Px1.p1.13.m13.1.1.2.3" xref="S4.SS0.SSS0.Px1.p1.13.m13.1.1.2.3.cmml">j</mi></msubsup><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px1.p1.13.m13.1b"><apply id="S4.SS0.SSS0.Px1.p1.13.m13.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.13.m13.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.13.m13.1.1.1.cmml" xref="S4.SS0.SSS0.Px1.p1.13.m13.1.1">subscript</csymbol><apply id="S4.SS0.SSS0.Px1.p1.13.m13.1.1.2.cmml" xref="S4.SS0.SSS0.Px1.p1.13.m13.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px1.p1.13.m13.1.1.2.1.cmml" xref="S4.SS0.SSS0.Px1.p1.13.m13.1.1">superscript</csymbol><ci id="S4.SS0.SSS0.Px1.p1.13.m13.1.1.2.2.cmml" xref="S4.SS0.SSS0.Px1.p1.13.m13.1.1.2.2">𝑎</ci><ci id="S4.SS0.SSS0.Px1.p1.13.m13.1.1.2.3.cmml" xref="S4.SS0.SSS0.Px1.p1.13.m13.1.1.2.3">𝑗</ci></apply><ci id="S4.SS0.SSS0.Px1.p1.13.m13.1.1.3.cmml" xref="S4.SS0.SSS0.Px1.p1.13.m13.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px1.p1.13.m13.1c">a^{j}_{i}</annotation></semantics></math> (multi-label binary classification). At inference time, a query image is compared against the gallery, and the correct ID must be retrieved on the basis of the embedding distance. We assume that the damaged bikes are the queries, inspired by applications in the insurance domain (fraud detection).</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">TransReI3D architecture</h5>

<div id="S4.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px2.p1.1" class="ltx_p">The TransReI3D architecture for joint DD and ReID, shown in <a href="#S4.F2" title="Figure 2 ‣ 4 Methodology ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 2</span></a>, builds on the TransReID <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> architecture, which achieved state-of-the-art performance among ViT-based models for vehicle ReID, and enriches it with an additional multi-label DD branch.</p>
</div>
<div id="S4.SS0.SSS0.Px2.p2" class="ltx_para">
<p id="S4.SS0.SSS0.Px2.p2.3" class="ltx_p">The TransReID architecture <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> builds on the ViT architecture <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>, but includes additional components to capture more robust and fine-grained features. Specifically, the Side Information Embedding (SIE) module encodes non-visual information such as camera or viewpoint, and is input to a transformer encoder together with learnable patch and position embeddings. The global ReID branch and the Jigsaw branch then jointly learn the ReID task, encoding global (<math id="S4.SS0.SSS0.Px2.p2.1.m1.1" class="ltx_Math" alttext="f_{g}" display="inline"><semantics id="S4.SS0.SSS0.Px2.p2.1.m1.1a"><msub id="S4.SS0.SSS0.Px2.p2.1.m1.1.1" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.cmml"><mi id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.2" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml">f</mi><mi id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p2.1.m1.1b"><apply id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.2">𝑓</ci><ci id="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3.cmml" xref="S4.SS0.SSS0.Px2.p2.1.m1.1.1.3">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p2.1.m1.1c">f_{g}</annotation></semantics></math>) and local (<math id="S4.SS0.SSS0.Px2.p2.2.m2.1" class="ltx_Math" alttext="f_{l}" display="inline"><semantics id="S4.SS0.SSS0.Px2.p2.2.m2.1a"><msub id="S4.SS0.SSS0.Px2.p2.2.m2.1.1" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.cmml"><mi id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.2" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.2.cmml">f</mi><mi id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p2.2.m2.1b"><apply id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.cmml" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.2">𝑓</ci><ci id="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3.cmml" xref="S4.SS0.SSS0.Px2.p2.2.m2.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p2.2.m2.1c">f_{l}</annotation></semantics></math>) features, respectively. The Jigsaw branch is based on the Jigsaw Patch Module (JPM), which shuffles all patches and regroups them into several groups, all of which are input to a shared transformer layer to learn local features <math id="S4.SS0.SSS0.Px2.p2.3.m3.1" class="ltx_Math" alttext="f_{l}" display="inline"><semantics id="S4.SS0.SSS0.Px2.p2.3.m3.1a"><msub id="S4.SS0.SSS0.Px2.p2.3.m3.1.1" xref="S4.SS0.SSS0.Px2.p2.3.m3.1.1.cmml"><mi id="S4.SS0.SSS0.Px2.p2.3.m3.1.1.2" xref="S4.SS0.SSS0.Px2.p2.3.m3.1.1.2.cmml">f</mi><mi id="S4.SS0.SSS0.Px2.p2.3.m3.1.1.3" xref="S4.SS0.SSS0.Px2.p2.3.m3.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px2.p2.3.m3.1b"><apply id="S4.SS0.SSS0.Px2.p2.3.m3.1.1.cmml" xref="S4.SS0.SSS0.Px2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px2.p2.3.m3.1.1.1.cmml" xref="S4.SS0.SSS0.Px2.p2.3.m3.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px2.p2.3.m3.1.1.2.cmml" xref="S4.SS0.SSS0.Px2.p2.3.m3.1.1.2">𝑓</ci><ci id="S4.SS0.SSS0.Px2.p2.3.m3.1.1.3.cmml" xref="S4.SS0.SSS0.Px2.p2.3.m3.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px2.p2.3.m3.1c">f_{l}</annotation></semantics></math>, as detailed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Damage branch and multi-task learning.</h5>

<div id="S4.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px3.p1.1" class="ltx_p">Multi-task learning is implemented using one shared transformer backbone and an additional separate transformer layer for each task <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>, <a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>.
The DD branch is a multi-label classifier with seven output heads: two for Bent and Broken frame labels, and five for missing parts (front wheel, rear wheel, seat, handlebar or pedals). Each output head takes as input the [<span id="S4.SS0.SSS0.Px3.p1.1.1" class="ltx_text ltx_font_italic">cls</span>] token and passes it through a batch normalization (BN) layer followed by a fully connected (FC) layer.</p>
</div>
<div id="S4.SS0.SSS0.Px3.p2" class="ltx_para">
<p id="S4.SS0.SSS0.Px3.p2.1" class="ltx_p">TransReI3D combines two tasks, one executed on image pairs (ReID) and one executed on individual images (DD). In addition, the ReID task is not defined for real images. For this reason, a multi-task diversion mechanism was implemented which selects the tasks that need to be executed upon the extracted features of each training batch. Hence, synthetic images are forwarded to all branches, whereas real images are directed to the DD branch only.</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Loss computation.</h5>

<div id="S4.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px4.p1.1" class="ltx_p">The loss combines the ReID loss, including global and local features, with the DD loss:</p>
</div>
<div id="S4.SS0.SSS0.Px4.p2" class="ltx_para">
<table id="S4.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E1.m1.68" class="ltx_Math" alttext="\begin{split}\mathcal{L}=\alpha\mathcal{L}_{ID}\left(f_{g}\right)+\beta\mathcal{L}_{T}\left(f_{g}\right)+\gamma\mathcal{L_{D}}\left(f_{g}^{a},f_{g}^{p},f_{g}^{n}\right)\\
+\frac{1}{k}\sum_{j=1}^{k}\left(\mathcal{L}_{ID}\left(f_{l}^{j}\right)+\mathcal{L}_{T}\left(f_{l}^{j}\right)\right)\end{split}" display="block"><semantics id="S4.E1.m1.68a"><mtable displaystyle="true" rowspacing="0pt" id="S4.E1.m1.68.68.12" xref="S4.E1.m1.62.62.6.cmml"><mtr id="S4.E1.m1.68.68.12a" xref="S4.E1.m1.62.62.6.cmml"><mtd class="ltx_align_right" columnalign="right" id="S4.E1.m1.68.68.12b" xref="S4.E1.m1.62.62.6.cmml"><mrow id="S4.E1.m1.67.67.11.61.39.39" xref="S4.E1.m1.62.62.6.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.1.1.1.1.1.1" xref="S4.E1.m1.1.1.1.1.1.1.cmml">ℒ</mi><mo id="S4.E1.m1.2.2.2.2.2.2" xref="S4.E1.m1.2.2.2.2.2.2.cmml">=</mo><mrow id="S4.E1.m1.67.67.11.61.39.39.39" xref="S4.E1.m1.62.62.6.cmml"><mrow id="S4.E1.m1.63.63.7.57.35.35.35.1" xref="S4.E1.m1.62.62.6.cmml"><mi id="S4.E1.m1.3.3.3.3.3.3" xref="S4.E1.m1.3.3.3.3.3.3.cmml">α</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.63.63.7.57.35.35.35.1.2" xref="S4.E1.m1.62.62.6.cmml">​</mo><msub id="S4.E1.m1.63.63.7.57.35.35.35.1.3" xref="S4.E1.m1.62.62.6.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.4.4.4.4.4.4" xref="S4.E1.m1.4.4.4.4.4.4.cmml">ℒ</mi><mrow id="S4.E1.m1.5.5.5.5.5.5.1" xref="S4.E1.m1.5.5.5.5.5.5.1.cmml"><mi id="S4.E1.m1.5.5.5.5.5.5.1.2" xref="S4.E1.m1.5.5.5.5.5.5.1.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.5.5.5.5.5.5.1.1" xref="S4.E1.m1.5.5.5.5.5.5.1.1.cmml">​</mo><mi id="S4.E1.m1.5.5.5.5.5.5.1.3" xref="S4.E1.m1.5.5.5.5.5.5.1.3.cmml">D</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.E1.m1.63.63.7.57.35.35.35.1.2a" xref="S4.E1.m1.62.62.6.cmml">​</mo><mrow id="S4.E1.m1.63.63.7.57.35.35.35.1.1.1" xref="S4.E1.m1.62.62.6.cmml"><mo id="S4.E1.m1.6.6.6.6.6.6" xref="S4.E1.m1.62.62.6.cmml">(</mo><msub id="S4.E1.m1.63.63.7.57.35.35.35.1.1.1.1" xref="S4.E1.m1.62.62.6.cmml"><mi id="S4.E1.m1.7.7.7.7.7.7" xref="S4.E1.m1.7.7.7.7.7.7.cmml">f</mi><mi id="S4.E1.m1.8.8.8.8.8.8.1" xref="S4.E1.m1.8.8.8.8.8.8.1.cmml">g</mi></msub><mo id="S4.E1.m1.9.9.9.9.9.9" xref="S4.E1.m1.62.62.6.cmml">)</mo></mrow></mrow><mo id="S4.E1.m1.10.10.10.10.10.10" xref="S4.E1.m1.10.10.10.10.10.10.cmml">+</mo><mrow id="S4.E1.m1.64.64.8.58.36.36.36.2" xref="S4.E1.m1.62.62.6.cmml"><mi id="S4.E1.m1.11.11.11.11.11.11" xref="S4.E1.m1.11.11.11.11.11.11.cmml">β</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.64.64.8.58.36.36.36.2.2" xref="S4.E1.m1.62.62.6.cmml">​</mo><msub id="S4.E1.m1.64.64.8.58.36.36.36.2.3" xref="S4.E1.m1.62.62.6.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.12.12.12.12.12.12" xref="S4.E1.m1.12.12.12.12.12.12.cmml">ℒ</mi><mi id="S4.E1.m1.13.13.13.13.13.13.1" xref="S4.E1.m1.13.13.13.13.13.13.1.cmml">T</mi></msub><mo lspace="0em" rspace="0em" id="S4.E1.m1.64.64.8.58.36.36.36.2.2a" xref="S4.E1.m1.62.62.6.cmml">​</mo><mrow id="S4.E1.m1.64.64.8.58.36.36.36.2.1.1" xref="S4.E1.m1.62.62.6.cmml"><mo id="S4.E1.m1.14.14.14.14.14.14" xref="S4.E1.m1.62.62.6.cmml">(</mo><msub id="S4.E1.m1.64.64.8.58.36.36.36.2.1.1.1" xref="S4.E1.m1.62.62.6.cmml"><mi id="S4.E1.m1.15.15.15.15.15.15" xref="S4.E1.m1.15.15.15.15.15.15.cmml">f</mi><mi id="S4.E1.m1.16.16.16.16.16.16.1" xref="S4.E1.m1.16.16.16.16.16.16.1.cmml">g</mi></msub><mo id="S4.E1.m1.17.17.17.17.17.17" xref="S4.E1.m1.62.62.6.cmml">)</mo></mrow></mrow><mo id="S4.E1.m1.10.10.10.10.10.10a" xref="S4.E1.m1.10.10.10.10.10.10.cmml">+</mo><mrow id="S4.E1.m1.67.67.11.61.39.39.39.5" xref="S4.E1.m1.62.62.6.cmml"><mi id="S4.E1.m1.19.19.19.19.19.19" xref="S4.E1.m1.19.19.19.19.19.19.cmml">γ</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.67.67.11.61.39.39.39.5.4" xref="S4.E1.m1.62.62.6.cmml">​</mo><msub id="S4.E1.m1.67.67.11.61.39.39.39.5.5" xref="S4.E1.m1.62.62.6.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.20.20.20.20.20.20" xref="S4.E1.m1.20.20.20.20.20.20.cmml">ℒ</mi><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.21.21.21.21.21.21.1" xref="S4.E1.m1.21.21.21.21.21.21.1.cmml">𝒟</mi></msub><mo lspace="0em" rspace="0em" id="S4.E1.m1.67.67.11.61.39.39.39.5.4a" xref="S4.E1.m1.62.62.6.cmml">​</mo><mrow id="S4.E1.m1.67.67.11.61.39.39.39.5.3.3" xref="S4.E1.m1.62.62.6.cmml"><mo id="S4.E1.m1.22.22.22.22.22.22" xref="S4.E1.m1.62.62.6.cmml">(</mo><msubsup id="S4.E1.m1.65.65.9.59.37.37.37.3.1.1.1" xref="S4.E1.m1.62.62.6.cmml"><mi id="S4.E1.m1.23.23.23.23.23.23" xref="S4.E1.m1.23.23.23.23.23.23.cmml">f</mi><mi id="S4.E1.m1.24.24.24.24.24.24.1" xref="S4.E1.m1.24.24.24.24.24.24.1.cmml">g</mi><mi id="S4.E1.m1.25.25.25.25.25.25.1" xref="S4.E1.m1.25.25.25.25.25.25.1.cmml">a</mi></msubsup><mo id="S4.E1.m1.26.26.26.26.26.26" xref="S4.E1.m1.62.62.6.cmml">,</mo><msubsup id="S4.E1.m1.66.66.10.60.38.38.38.4.2.2.2" xref="S4.E1.m1.62.62.6.cmml"><mi id="S4.E1.m1.27.27.27.27.27.27" xref="S4.E1.m1.27.27.27.27.27.27.cmml">f</mi><mi id="S4.E1.m1.28.28.28.28.28.28.1" xref="S4.E1.m1.28.28.28.28.28.28.1.cmml">g</mi><mi id="S4.E1.m1.29.29.29.29.29.29.1" xref="S4.E1.m1.29.29.29.29.29.29.1.cmml">p</mi></msubsup><mo id="S4.E1.m1.30.30.30.30.30.30" xref="S4.E1.m1.62.62.6.cmml">,</mo><msubsup id="S4.E1.m1.67.67.11.61.39.39.39.5.3.3.3" xref="S4.E1.m1.62.62.6.cmml"><mi id="S4.E1.m1.31.31.31.31.31.31" xref="S4.E1.m1.31.31.31.31.31.31.cmml">f</mi><mi id="S4.E1.m1.32.32.32.32.32.32.1" xref="S4.E1.m1.32.32.32.32.32.32.1.cmml">g</mi><mi id="S4.E1.m1.33.33.33.33.33.33.1" xref="S4.E1.m1.33.33.33.33.33.33.1.cmml">n</mi></msubsup><mo id="S4.E1.m1.34.34.34.34.34.34" xref="S4.E1.m1.62.62.6.cmml">)</mo></mrow></mrow></mrow></mrow></mtd></mtr><mtr id="S4.E1.m1.68.68.12c" xref="S4.E1.m1.62.62.6.cmml"><mtd class="ltx_align_right" columnalign="right" id="S4.E1.m1.68.68.12d" xref="S4.E1.m1.62.62.6.cmml"><mrow id="S4.E1.m1.68.68.12.62.23.23" xref="S4.E1.m1.62.62.6.cmml"><mo id="S4.E1.m1.68.68.12.62.23.23a" xref="S4.E1.m1.62.62.6.cmml">+</mo><mrow id="S4.E1.m1.68.68.12.62.23.23.23" xref="S4.E1.m1.62.62.6.cmml"><mfrac id="S4.E1.m1.36.36.36.2.2.2" xref="S4.E1.m1.36.36.36.2.2.2.cmml"><mn id="S4.E1.m1.36.36.36.2.2.2.2" xref="S4.E1.m1.36.36.36.2.2.2.2.cmml">1</mn><mi id="S4.E1.m1.36.36.36.2.2.2.3" xref="S4.E1.m1.36.36.36.2.2.2.3.cmml">k</mi></mfrac><mo lspace="0em" rspace="0em" id="S4.E1.m1.68.68.12.62.23.23.23.2" xref="S4.E1.m1.62.62.6.cmml">​</mo><mrow id="S4.E1.m1.68.68.12.62.23.23.23.1" xref="S4.E1.m1.62.62.6.cmml"><munderover id="S4.E1.m1.68.68.12.62.23.23.23.1.2" xref="S4.E1.m1.62.62.6.cmml"><mo movablelimits="false" rspace="0em" id="S4.E1.m1.37.37.37.3.3.3" xref="S4.E1.m1.37.37.37.3.3.3.cmml">∑</mo><mrow id="S4.E1.m1.38.38.38.4.4.4.1" xref="S4.E1.m1.38.38.38.4.4.4.1.cmml"><mi id="S4.E1.m1.38.38.38.4.4.4.1.2" xref="S4.E1.m1.38.38.38.4.4.4.1.2.cmml">j</mi><mo id="S4.E1.m1.38.38.38.4.4.4.1.1" xref="S4.E1.m1.38.38.38.4.4.4.1.1.cmml">=</mo><mn id="S4.E1.m1.38.38.38.4.4.4.1.3" xref="S4.E1.m1.38.38.38.4.4.4.1.3.cmml">1</mn></mrow><mi id="S4.E1.m1.39.39.39.5.5.5.1" xref="S4.E1.m1.39.39.39.5.5.5.1.cmml">k</mi></munderover><mrow id="S4.E1.m1.68.68.12.62.23.23.23.1.1.1" xref="S4.E1.m1.62.62.6.cmml"><mo id="S4.E1.m1.40.40.40.6.6.6" xref="S4.E1.m1.62.62.6.cmml">(</mo><mrow id="S4.E1.m1.68.68.12.62.23.23.23.1.1.1.1" xref="S4.E1.m1.62.62.6.cmml"><mrow id="S4.E1.m1.68.68.12.62.23.23.23.1.1.1.1.1" xref="S4.E1.m1.62.62.6.cmml"><msub id="S4.E1.m1.68.68.12.62.23.23.23.1.1.1.1.1.3" xref="S4.E1.m1.62.62.6.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.41.41.41.7.7.7" xref="S4.E1.m1.41.41.41.7.7.7.cmml">ℒ</mi><mrow id="S4.E1.m1.42.42.42.8.8.8.1" xref="S4.E1.m1.42.42.42.8.8.8.1.cmml"><mi id="S4.E1.m1.42.42.42.8.8.8.1.2" xref="S4.E1.m1.42.42.42.8.8.8.1.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="S4.E1.m1.42.42.42.8.8.8.1.1" xref="S4.E1.m1.42.42.42.8.8.8.1.1.cmml">​</mo><mi id="S4.E1.m1.42.42.42.8.8.8.1.3" xref="S4.E1.m1.42.42.42.8.8.8.1.3.cmml">D</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.E1.m1.68.68.12.62.23.23.23.1.1.1.1.1.2" xref="S4.E1.m1.62.62.6.cmml">​</mo><mrow id="S4.E1.m1.68.68.12.62.23.23.23.1.1.1.1.1.1.1" xref="S4.E1.m1.62.62.6.cmml"><mo id="S4.E1.m1.43.43.43.9.9.9" xref="S4.E1.m1.62.62.6.cmml">(</mo><msubsup id="S4.E1.m1.68.68.12.62.23.23.23.1.1.1.1.1.1.1.1" xref="S4.E1.m1.62.62.6.cmml"><mi id="S4.E1.m1.44.44.44.10.10.10" xref="S4.E1.m1.44.44.44.10.10.10.cmml">f</mi><mi id="S4.E1.m1.45.45.45.11.11.11.1" xref="S4.E1.m1.45.45.45.11.11.11.1.cmml">l</mi><mi id="S4.E1.m1.46.46.46.12.12.12.1" xref="S4.E1.m1.46.46.46.12.12.12.1.cmml">j</mi></msubsup><mo id="S4.E1.m1.47.47.47.13.13.13" xref="S4.E1.m1.62.62.6.cmml">)</mo></mrow></mrow><mo id="S4.E1.m1.48.48.48.14.14.14" xref="S4.E1.m1.48.48.48.14.14.14.cmml">+</mo><mrow id="S4.E1.m1.68.68.12.62.23.23.23.1.1.1.1.2" xref="S4.E1.m1.62.62.6.cmml"><msub id="S4.E1.m1.68.68.12.62.23.23.23.1.1.1.1.2.3" xref="S4.E1.m1.62.62.6.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E1.m1.49.49.49.15.15.15" xref="S4.E1.m1.49.49.49.15.15.15.cmml">ℒ</mi><mi id="S4.E1.m1.50.50.50.16.16.16.1" xref="S4.E1.m1.50.50.50.16.16.16.1.cmml">T</mi></msub><mo lspace="0em" rspace="0em" id="S4.E1.m1.68.68.12.62.23.23.23.1.1.1.1.2.2" xref="S4.E1.m1.62.62.6.cmml">​</mo><mrow id="S4.E1.m1.68.68.12.62.23.23.23.1.1.1.1.2.1.1" xref="S4.E1.m1.62.62.6.cmml"><mo id="S4.E1.m1.51.51.51.17.17.17" xref="S4.E1.m1.62.62.6.cmml">(</mo><msubsup id="S4.E1.m1.68.68.12.62.23.23.23.1.1.1.1.2.1.1.1" xref="S4.E1.m1.62.62.6.cmml"><mi id="S4.E1.m1.52.52.52.18.18.18" xref="S4.E1.m1.52.52.52.18.18.18.cmml">f</mi><mi id="S4.E1.m1.53.53.53.19.19.19.1" xref="S4.E1.m1.53.53.53.19.19.19.1.cmml">l</mi><mi id="S4.E1.m1.54.54.54.20.20.20.1" xref="S4.E1.m1.54.54.54.20.20.20.1.cmml">j</mi></msubsup><mo id="S4.E1.m1.55.55.55.21.21.21" xref="S4.E1.m1.62.62.6.cmml">)</mo></mrow></mrow></mrow><mo id="S4.E1.m1.56.56.56.22.22.22" xref="S4.E1.m1.62.62.6.cmml">)</mo></mrow></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S4.E1.m1.68b"><apply id="S4.E1.m1.62.62.6.cmml" xref="S4.E1.m1.68.68.12"><eq id="S4.E1.m1.2.2.2.2.2.2.cmml" xref="S4.E1.m1.2.2.2.2.2.2"></eq><ci id="S4.E1.m1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.1.1.1.1.1.1">ℒ</ci><apply id="S4.E1.m1.62.62.6.6.cmml" xref="S4.E1.m1.68.68.12"><plus id="S4.E1.m1.10.10.10.10.10.10.cmml" xref="S4.E1.m1.10.10.10.10.10.10"></plus><apply id="S4.E1.m1.57.57.1.1.1.cmml" xref="S4.E1.m1.68.68.12"><times id="S4.E1.m1.57.57.1.1.1.2.cmml" xref="S4.E1.m1.68.68.12"></times><ci id="S4.E1.m1.3.3.3.3.3.3.cmml" xref="S4.E1.m1.3.3.3.3.3.3">𝛼</ci><apply id="S4.E1.m1.57.57.1.1.1.4.cmml" xref="S4.E1.m1.68.68.12"><csymbol cd="ambiguous" id="S4.E1.m1.57.57.1.1.1.4.1.cmml" xref="S4.E1.m1.68.68.12">subscript</csymbol><ci id="S4.E1.m1.4.4.4.4.4.4.cmml" xref="S4.E1.m1.4.4.4.4.4.4">ℒ</ci><apply id="S4.E1.m1.5.5.5.5.5.5.1.cmml" xref="S4.E1.m1.5.5.5.5.5.5.1"><times id="S4.E1.m1.5.5.5.5.5.5.1.1.cmml" xref="S4.E1.m1.5.5.5.5.5.5.1.1"></times><ci id="S4.E1.m1.5.5.5.5.5.5.1.2.cmml" xref="S4.E1.m1.5.5.5.5.5.5.1.2">𝐼</ci><ci id="S4.E1.m1.5.5.5.5.5.5.1.3.cmml" xref="S4.E1.m1.5.5.5.5.5.5.1.3">𝐷</ci></apply></apply><apply id="S4.E1.m1.57.57.1.1.1.1.1.1.cmml" xref="S4.E1.m1.68.68.12"><csymbol cd="ambiguous" id="S4.E1.m1.57.57.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.68.68.12">subscript</csymbol><ci id="S4.E1.m1.7.7.7.7.7.7.cmml" xref="S4.E1.m1.7.7.7.7.7.7">𝑓</ci><ci id="S4.E1.m1.8.8.8.8.8.8.1.cmml" xref="S4.E1.m1.8.8.8.8.8.8.1">𝑔</ci></apply></apply><apply id="S4.E1.m1.58.58.2.2.2.cmml" xref="S4.E1.m1.68.68.12"><times id="S4.E1.m1.58.58.2.2.2.2.cmml" xref="S4.E1.m1.68.68.12"></times><ci id="S4.E1.m1.11.11.11.11.11.11.cmml" xref="S4.E1.m1.11.11.11.11.11.11">𝛽</ci><apply id="S4.E1.m1.58.58.2.2.2.4.cmml" xref="S4.E1.m1.68.68.12"><csymbol cd="ambiguous" id="S4.E1.m1.58.58.2.2.2.4.1.cmml" xref="S4.E1.m1.68.68.12">subscript</csymbol><ci id="S4.E1.m1.12.12.12.12.12.12.cmml" xref="S4.E1.m1.12.12.12.12.12.12">ℒ</ci><ci id="S4.E1.m1.13.13.13.13.13.13.1.cmml" xref="S4.E1.m1.13.13.13.13.13.13.1">𝑇</ci></apply><apply id="S4.E1.m1.58.58.2.2.2.1.1.1.cmml" xref="S4.E1.m1.68.68.12"><csymbol cd="ambiguous" id="S4.E1.m1.58.58.2.2.2.1.1.1.1.cmml" xref="S4.E1.m1.68.68.12">subscript</csymbol><ci id="S4.E1.m1.15.15.15.15.15.15.cmml" xref="S4.E1.m1.15.15.15.15.15.15">𝑓</ci><ci id="S4.E1.m1.16.16.16.16.16.16.1.cmml" xref="S4.E1.m1.16.16.16.16.16.16.1">𝑔</ci></apply></apply><apply id="S4.E1.m1.61.61.5.5.5.cmml" xref="S4.E1.m1.68.68.12"><times id="S4.E1.m1.61.61.5.5.5.4.cmml" xref="S4.E1.m1.68.68.12"></times><ci id="S4.E1.m1.19.19.19.19.19.19.cmml" xref="S4.E1.m1.19.19.19.19.19.19">𝛾</ci><apply id="S4.E1.m1.61.61.5.5.5.6.cmml" xref="S4.E1.m1.68.68.12"><csymbol cd="ambiguous" id="S4.E1.m1.61.61.5.5.5.6.1.cmml" xref="S4.E1.m1.68.68.12">subscript</csymbol><ci id="S4.E1.m1.20.20.20.20.20.20.cmml" xref="S4.E1.m1.20.20.20.20.20.20">ℒ</ci><ci id="S4.E1.m1.21.21.21.21.21.21.1.cmml" xref="S4.E1.m1.21.21.21.21.21.21.1">𝒟</ci></apply><vector id="S4.E1.m1.61.61.5.5.5.3.4.cmml" xref="S4.E1.m1.68.68.12"><apply id="S4.E1.m1.59.59.3.3.3.1.1.1.cmml" xref="S4.E1.m1.68.68.12"><csymbol cd="ambiguous" id="S4.E1.m1.59.59.3.3.3.1.1.1.1.cmml" xref="S4.E1.m1.68.68.12">superscript</csymbol><apply id="S4.E1.m1.59.59.3.3.3.1.1.1.2.cmml" xref="S4.E1.m1.68.68.12"><csymbol cd="ambiguous" id="S4.E1.m1.59.59.3.3.3.1.1.1.2.1.cmml" xref="S4.E1.m1.68.68.12">subscript</csymbol><ci id="S4.E1.m1.23.23.23.23.23.23.cmml" xref="S4.E1.m1.23.23.23.23.23.23">𝑓</ci><ci id="S4.E1.m1.24.24.24.24.24.24.1.cmml" xref="S4.E1.m1.24.24.24.24.24.24.1">𝑔</ci></apply><ci id="S4.E1.m1.25.25.25.25.25.25.1.cmml" xref="S4.E1.m1.25.25.25.25.25.25.1">𝑎</ci></apply><apply id="S4.E1.m1.60.60.4.4.4.2.2.2.cmml" xref="S4.E1.m1.68.68.12"><csymbol cd="ambiguous" id="S4.E1.m1.60.60.4.4.4.2.2.2.1.cmml" xref="S4.E1.m1.68.68.12">superscript</csymbol><apply id="S4.E1.m1.60.60.4.4.4.2.2.2.2.cmml" xref="S4.E1.m1.68.68.12"><csymbol cd="ambiguous" id="S4.E1.m1.60.60.4.4.4.2.2.2.2.1.cmml" xref="S4.E1.m1.68.68.12">subscript</csymbol><ci id="S4.E1.m1.27.27.27.27.27.27.cmml" xref="S4.E1.m1.27.27.27.27.27.27">𝑓</ci><ci id="S4.E1.m1.28.28.28.28.28.28.1.cmml" xref="S4.E1.m1.28.28.28.28.28.28.1">𝑔</ci></apply><ci id="S4.E1.m1.29.29.29.29.29.29.1.cmml" xref="S4.E1.m1.29.29.29.29.29.29.1">𝑝</ci></apply><apply id="S4.E1.m1.61.61.5.5.5.3.3.3.cmml" xref="S4.E1.m1.68.68.12"><csymbol cd="ambiguous" id="S4.E1.m1.61.61.5.5.5.3.3.3.1.cmml" xref="S4.E1.m1.68.68.12">superscript</csymbol><apply id="S4.E1.m1.61.61.5.5.5.3.3.3.2.cmml" xref="S4.E1.m1.68.68.12"><csymbol cd="ambiguous" id="S4.E1.m1.61.61.5.5.5.3.3.3.2.1.cmml" xref="S4.E1.m1.68.68.12">subscript</csymbol><ci id="S4.E1.m1.31.31.31.31.31.31.cmml" xref="S4.E1.m1.31.31.31.31.31.31">𝑓</ci><ci id="S4.E1.m1.32.32.32.32.32.32.1.cmml" xref="S4.E1.m1.32.32.32.32.32.32.1">𝑔</ci></apply><ci id="S4.E1.m1.33.33.33.33.33.33.1.cmml" xref="S4.E1.m1.33.33.33.33.33.33.1">𝑛</ci></apply></vector></apply><apply id="S4.E1.m1.62.62.6.6.6.cmml" xref="S4.E1.m1.68.68.12"><times id="S4.E1.m1.62.62.6.6.6.2.cmml" xref="S4.E1.m1.68.68.12"></times><apply id="S4.E1.m1.36.36.36.2.2.2.cmml" xref="S4.E1.m1.36.36.36.2.2.2"><divide id="S4.E1.m1.36.36.36.2.2.2.1.cmml" xref="S4.E1.m1.36.36.36.2.2.2"></divide><cn type="integer" id="S4.E1.m1.36.36.36.2.2.2.2.cmml" xref="S4.E1.m1.36.36.36.2.2.2.2">1</cn><ci id="S4.E1.m1.36.36.36.2.2.2.3.cmml" xref="S4.E1.m1.36.36.36.2.2.2.3">𝑘</ci></apply><apply id="S4.E1.m1.62.62.6.6.6.1.cmml" xref="S4.E1.m1.68.68.12"><apply id="S4.E1.m1.62.62.6.6.6.1.2.cmml" xref="S4.E1.m1.68.68.12"><csymbol cd="ambiguous" id="S4.E1.m1.62.62.6.6.6.1.2.1.cmml" xref="S4.E1.m1.68.68.12">superscript</csymbol><apply id="S4.E1.m1.62.62.6.6.6.1.2.2.cmml" xref="S4.E1.m1.68.68.12"><csymbol cd="ambiguous" id="S4.E1.m1.62.62.6.6.6.1.2.2.1.cmml" xref="S4.E1.m1.68.68.12">subscript</csymbol><sum id="S4.E1.m1.37.37.37.3.3.3.cmml" xref="S4.E1.m1.37.37.37.3.3.3"></sum><apply id="S4.E1.m1.38.38.38.4.4.4.1.cmml" xref="S4.E1.m1.38.38.38.4.4.4.1"><eq id="S4.E1.m1.38.38.38.4.4.4.1.1.cmml" xref="S4.E1.m1.38.38.38.4.4.4.1.1"></eq><ci id="S4.E1.m1.38.38.38.4.4.4.1.2.cmml" xref="S4.E1.m1.38.38.38.4.4.4.1.2">𝑗</ci><cn type="integer" id="S4.E1.m1.38.38.38.4.4.4.1.3.cmml" xref="S4.E1.m1.38.38.38.4.4.4.1.3">1</cn></apply></apply><ci id="S4.E1.m1.39.39.39.5.5.5.1.cmml" xref="S4.E1.m1.39.39.39.5.5.5.1">𝑘</ci></apply><apply id="S4.E1.m1.62.62.6.6.6.1.1.1.1.cmml" xref="S4.E1.m1.68.68.12"><plus id="S4.E1.m1.48.48.48.14.14.14.cmml" xref="S4.E1.m1.48.48.48.14.14.14"></plus><apply id="S4.E1.m1.62.62.6.6.6.1.1.1.1.1.cmml" xref="S4.E1.m1.68.68.12"><times id="S4.E1.m1.62.62.6.6.6.1.1.1.1.1.2.cmml" xref="S4.E1.m1.68.68.12"></times><apply id="S4.E1.m1.62.62.6.6.6.1.1.1.1.1.3.cmml" xref="S4.E1.m1.68.68.12"><csymbol cd="ambiguous" id="S4.E1.m1.62.62.6.6.6.1.1.1.1.1.3.1.cmml" xref="S4.E1.m1.68.68.12">subscript</csymbol><ci id="S4.E1.m1.41.41.41.7.7.7.cmml" xref="S4.E1.m1.41.41.41.7.7.7">ℒ</ci><apply id="S4.E1.m1.42.42.42.8.8.8.1.cmml" xref="S4.E1.m1.42.42.42.8.8.8.1"><times id="S4.E1.m1.42.42.42.8.8.8.1.1.cmml" xref="S4.E1.m1.42.42.42.8.8.8.1.1"></times><ci id="S4.E1.m1.42.42.42.8.8.8.1.2.cmml" xref="S4.E1.m1.42.42.42.8.8.8.1.2">𝐼</ci><ci id="S4.E1.m1.42.42.42.8.8.8.1.3.cmml" xref="S4.E1.m1.42.42.42.8.8.8.1.3">𝐷</ci></apply></apply><apply id="S4.E1.m1.62.62.6.6.6.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.68.68.12"><csymbol cd="ambiguous" id="S4.E1.m1.62.62.6.6.6.1.1.1.1.1.1.1.1.1.cmml" xref="S4.E1.m1.68.68.12">superscript</csymbol><apply id="S4.E1.m1.62.62.6.6.6.1.1.1.1.1.1.1.1.2.cmml" xref="S4.E1.m1.68.68.12"><csymbol cd="ambiguous" id="S4.E1.m1.62.62.6.6.6.1.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E1.m1.68.68.12">subscript</csymbol><ci id="S4.E1.m1.44.44.44.10.10.10.cmml" xref="S4.E1.m1.44.44.44.10.10.10">𝑓</ci><ci id="S4.E1.m1.45.45.45.11.11.11.1.cmml" xref="S4.E1.m1.45.45.45.11.11.11.1">𝑙</ci></apply><ci id="S4.E1.m1.46.46.46.12.12.12.1.cmml" xref="S4.E1.m1.46.46.46.12.12.12.1">𝑗</ci></apply></apply><apply id="S4.E1.m1.62.62.6.6.6.1.1.1.1.2.cmml" xref="S4.E1.m1.68.68.12"><times id="S4.E1.m1.62.62.6.6.6.1.1.1.1.2.2.cmml" xref="S4.E1.m1.68.68.12"></times><apply id="S4.E1.m1.62.62.6.6.6.1.1.1.1.2.3.cmml" xref="S4.E1.m1.68.68.12"><csymbol cd="ambiguous" id="S4.E1.m1.62.62.6.6.6.1.1.1.1.2.3.1.cmml" xref="S4.E1.m1.68.68.12">subscript</csymbol><ci id="S4.E1.m1.49.49.49.15.15.15.cmml" xref="S4.E1.m1.49.49.49.15.15.15">ℒ</ci><ci id="S4.E1.m1.50.50.50.16.16.16.1.cmml" xref="S4.E1.m1.50.50.50.16.16.16.1">𝑇</ci></apply><apply id="S4.E1.m1.62.62.6.6.6.1.1.1.1.2.1.1.1.cmml" xref="S4.E1.m1.68.68.12"><csymbol cd="ambiguous" id="S4.E1.m1.62.62.6.6.6.1.1.1.1.2.1.1.1.1.cmml" xref="S4.E1.m1.68.68.12">superscript</csymbol><apply id="S4.E1.m1.62.62.6.6.6.1.1.1.1.2.1.1.1.2.cmml" xref="S4.E1.m1.68.68.12"><csymbol cd="ambiguous" id="S4.E1.m1.62.62.6.6.6.1.1.1.1.2.1.1.1.2.1.cmml" xref="S4.E1.m1.68.68.12">subscript</csymbol><ci id="S4.E1.m1.52.52.52.18.18.18.cmml" xref="S4.E1.m1.52.52.52.18.18.18">𝑓</ci><ci id="S4.E1.m1.53.53.53.19.19.19.1.cmml" xref="S4.E1.m1.53.53.53.19.19.19.1">𝑙</ci></apply><ci id="S4.E1.m1.54.54.54.20.20.20.1.cmml" xref="S4.E1.m1.54.54.54.20.20.20.1">𝑗</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E1.m1.68c">\begin{split}\mathcal{L}=\alpha\mathcal{L}_{ID}\left(f_{g}\right)+\beta\mathcal{L}_{T}\left(f_{g}\right)+\gamma\mathcal{L_{D}}\left(f_{g}^{a},f_{g}^{p},f_{g}^{n}\right)\\
+\frac{1}{k}\sum_{j=1}^{k}\left(\mathcal{L}_{ID}\left(f_{l}^{j}\right)+\mathcal{L}_{T}\left(f_{l}^{j}\right)\right)\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S4.SS0.SSS0.Px4.p3" class="ltx_para">
<p id="S4.SS0.SSS0.Px4.p3.2" class="ltx_p">where <math id="S4.SS0.SSS0.Px4.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{L}_{T}" display="inline"><semantics id="S4.SS0.SSS0.Px4.p3.1.m1.1a"><msub id="S4.SS0.SSS0.Px4.p3.1.m1.1.1" xref="S4.SS0.SSS0.Px4.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px4.p3.1.m1.1.1.2" xref="S4.SS0.SSS0.Px4.p3.1.m1.1.1.2.cmml">ℒ</mi><mi id="S4.SS0.SSS0.Px4.p3.1.m1.1.1.3" xref="S4.SS0.SSS0.Px4.p3.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p3.1.m1.1b"><apply id="S4.SS0.SSS0.Px4.p3.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px4.p3.1.m1.1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p3.1.m1.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px4.p3.1.m1.1.1.2.cmml" xref="S4.SS0.SSS0.Px4.p3.1.m1.1.1.2">ℒ</ci><ci id="S4.SS0.SSS0.Px4.p3.1.m1.1.1.3.cmml" xref="S4.SS0.SSS0.Px4.p3.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p3.1.m1.1c">\mathcal{L}_{T}</annotation></semantics></math> and <math id="S4.SS0.SSS0.Px4.p3.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{ID}" display="inline"><semantics id="S4.SS0.SSS0.Px4.p3.2.m2.1a"><msub id="S4.SS0.SSS0.Px4.p3.2.m2.1.1" xref="S4.SS0.SSS0.Px4.p3.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px4.p3.2.m2.1.1.2" xref="S4.SS0.SSS0.Px4.p3.2.m2.1.1.2.cmml">ℒ</mi><mrow id="S4.SS0.SSS0.Px4.p3.2.m2.1.1.3" xref="S4.SS0.SSS0.Px4.p3.2.m2.1.1.3.cmml"><mi id="S4.SS0.SSS0.Px4.p3.2.m2.1.1.3.2" xref="S4.SS0.SSS0.Px4.p3.2.m2.1.1.3.2.cmml">I</mi><mo lspace="0em" rspace="0em" id="S4.SS0.SSS0.Px4.p3.2.m2.1.1.3.1" xref="S4.SS0.SSS0.Px4.p3.2.m2.1.1.3.1.cmml">​</mo><mi id="S4.SS0.SSS0.Px4.p3.2.m2.1.1.3.3" xref="S4.SS0.SSS0.Px4.p3.2.m2.1.1.3.3.cmml">D</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p3.2.m2.1b"><apply id="S4.SS0.SSS0.Px4.p3.2.m2.1.1.cmml" xref="S4.SS0.SSS0.Px4.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px4.p3.2.m2.1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p3.2.m2.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px4.p3.2.m2.1.1.2.cmml" xref="S4.SS0.SSS0.Px4.p3.2.m2.1.1.2">ℒ</ci><apply id="S4.SS0.SSS0.Px4.p3.2.m2.1.1.3.cmml" xref="S4.SS0.SSS0.Px4.p3.2.m2.1.1.3"><times id="S4.SS0.SSS0.Px4.p3.2.m2.1.1.3.1.cmml" xref="S4.SS0.SSS0.Px4.p3.2.m2.1.1.3.1"></times><ci id="S4.SS0.SSS0.Px4.p3.2.m2.1.1.3.2.cmml" xref="S4.SS0.SSS0.Px4.p3.2.m2.1.1.3.2">𝐼</ci><ci id="S4.SS0.SSS0.Px4.p3.2.m2.1.1.3.3.cmml" xref="S4.SS0.SSS0.Px4.p3.2.m2.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p3.2.m2.1c">\mathcal{L}_{ID}</annotation></semantics></math> are the triplet loss and the ID cross-entropy loss (which treats each ID as a separate class, as defined in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>),</p>
</div>
<div id="S4.SS0.SSS0.Px4.p4" class="ltx_para">
<p id="S4.SS0.SSS0.Px4.p4.6" class="ltx_p"><math id="S4.SS0.SSS0.Px4.p4.1.m1.1" class="ltx_Math" alttext="{\mathcal{L}_{D}}" display="inline"><semantics id="S4.SS0.SSS0.Px4.p4.1.m1.1a"><msub id="S4.SS0.SSS0.Px4.p4.1.m1.1.1" xref="S4.SS0.SSS0.Px4.p4.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px4.p4.1.m1.1.1.2" xref="S4.SS0.SSS0.Px4.p4.1.m1.1.1.2.cmml">ℒ</mi><mi id="S4.SS0.SSS0.Px4.p4.1.m1.1.1.3" xref="S4.SS0.SSS0.Px4.p4.1.m1.1.1.3.cmml">D</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p4.1.m1.1b"><apply id="S4.SS0.SSS0.Px4.p4.1.m1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px4.p4.1.m1.1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.1.m1.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px4.p4.1.m1.1.1.2.cmml" xref="S4.SS0.SSS0.Px4.p4.1.m1.1.1.2">ℒ</ci><ci id="S4.SS0.SSS0.Px4.p4.1.m1.1.1.3.cmml" xref="S4.SS0.SSS0.Px4.p4.1.m1.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p4.1.m1.1c">{\mathcal{L}_{D}}</annotation></semantics></math> is the DD loss, and <math id="S4.SS0.SSS0.Px4.p4.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S4.SS0.SSS0.Px4.p4.2.m2.1a"><mi id="S4.SS0.SSS0.Px4.p4.2.m2.1.1" xref="S4.SS0.SSS0.Px4.p4.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p4.2.m2.1b"><ci id="S4.SS0.SSS0.Px4.p4.2.m2.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p4.2.m2.1c">k</annotation></semantics></math> (= 4) is the number of classification heads of the JPM branch. All loss components are calculated on the [<span id="S4.SS0.SSS0.Px4.p4.6.1" class="ltx_text ltx_font_italic">cls</span>] token (<math id="S4.SS0.SSS0.Px4.p4.3.m3.1" class="ltx_Math" alttext="f_{g}" display="inline"><semantics id="S4.SS0.SSS0.Px4.p4.3.m3.1a"><msub id="S4.SS0.SSS0.Px4.p4.3.m3.1.1" xref="S4.SS0.SSS0.Px4.p4.3.m3.1.1.cmml"><mi id="S4.SS0.SSS0.Px4.p4.3.m3.1.1.2" xref="S4.SS0.SSS0.Px4.p4.3.m3.1.1.2.cmml">f</mi><mi id="S4.SS0.SSS0.Px4.p4.3.m3.1.1.3" xref="S4.SS0.SSS0.Px4.p4.3.m3.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p4.3.m3.1b"><apply id="S4.SS0.SSS0.Px4.p4.3.m3.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px4.p4.3.m3.1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.3.m3.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px4.p4.3.m3.1.1.2.cmml" xref="S4.SS0.SSS0.Px4.p4.3.m3.1.1.2">𝑓</ci><ci id="S4.SS0.SSS0.Px4.p4.3.m3.1.1.3.cmml" xref="S4.SS0.SSS0.Px4.p4.3.m3.1.1.3">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p4.3.m3.1c">f_{g}</annotation></semantics></math>: global branch, <math id="S4.SS0.SSS0.Px4.p4.4.m4.1" class="ltx_Math" alttext="f_{l}" display="inline"><semantics id="S4.SS0.SSS0.Px4.p4.4.m4.1a"><msub id="S4.SS0.SSS0.Px4.p4.4.m4.1.1" xref="S4.SS0.SSS0.Px4.p4.4.m4.1.1.cmml"><mi id="S4.SS0.SSS0.Px4.p4.4.m4.1.1.2" xref="S4.SS0.SSS0.Px4.p4.4.m4.1.1.2.cmml">f</mi><mi id="S4.SS0.SSS0.Px4.p4.4.m4.1.1.3" xref="S4.SS0.SSS0.Px4.p4.4.m4.1.1.3.cmml">l</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p4.4.m4.1b"><apply id="S4.SS0.SSS0.Px4.p4.4.m4.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px4.p4.4.m4.1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.4.m4.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px4.p4.4.m4.1.1.2.cmml" xref="S4.SS0.SSS0.Px4.p4.4.m4.1.1.2">𝑓</ci><ci id="S4.SS0.SSS0.Px4.p4.4.m4.1.1.3.cmml" xref="S4.SS0.SSS0.Px4.p4.4.m4.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p4.4.m4.1c">f_{l}</annotation></semantics></math>: Jigsaw branch). To compute <math id="S4.SS0.SSS0.Px4.p4.5.m5.1" class="ltx_Math" alttext="\mathcal{L}_{T}" display="inline"><semantics id="S4.SS0.SSS0.Px4.p4.5.m5.1a"><msub id="S4.SS0.SSS0.Px4.p4.5.m5.1.1" xref="S4.SS0.SSS0.Px4.p4.5.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px4.p4.5.m5.1.1.2" xref="S4.SS0.SSS0.Px4.p4.5.m5.1.1.2.cmml">ℒ</mi><mi id="S4.SS0.SSS0.Px4.p4.5.m5.1.1.3" xref="S4.SS0.SSS0.Px4.p4.5.m5.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p4.5.m5.1b"><apply id="S4.SS0.SSS0.Px4.p4.5.m5.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px4.p4.5.m5.1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.5.m5.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px4.p4.5.m5.1.1.2.cmml" xref="S4.SS0.SSS0.Px4.p4.5.m5.1.1.2">ℒ</ci><ci id="S4.SS0.SSS0.Px4.p4.5.m5.1.1.3.cmml" xref="S4.SS0.SSS0.Px4.p4.5.m5.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p4.5.m5.1c">\mathcal{L}_{T}</annotation></semantics></math>, triplets are online sampled from each batch with hard negative and positive mining.
<math id="S4.SS0.SSS0.Px4.p4.6.m6.1" class="ltx_Math" alttext="{\mathcal{L}_{D}}" display="inline"><semantics id="S4.SS0.SSS0.Px4.p4.6.m6.1a"><msub id="S4.SS0.SSS0.Px4.p4.6.m6.1.1" xref="S4.SS0.SSS0.Px4.p4.6.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px4.p4.6.m6.1.1.2" xref="S4.SS0.SSS0.Px4.p4.6.m6.1.1.2.cmml">ℒ</mi><mi id="S4.SS0.SSS0.Px4.p4.6.m6.1.1.3" xref="S4.SS0.SSS0.Px4.p4.6.m6.1.1.3.cmml">D</mi></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p4.6.m6.1b"><apply id="S4.SS0.SSS0.Px4.p4.6.m6.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.6.m6.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px4.p4.6.m6.1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.6.m6.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px4.p4.6.m6.1.1.2.cmml" xref="S4.SS0.SSS0.Px4.p4.6.m6.1.1.2">ℒ</ci><ci id="S4.SS0.SSS0.Px4.p4.6.m6.1.1.3.cmml" xref="S4.SS0.SSS0.Px4.p4.6.m6.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p4.6.m6.1c">{\mathcal{L}_{D}}</annotation></semantics></math> is a weighted binary cross-entropy loss:</p>
<table id="S4.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S4.E2.m1.31" class="ltx_Math" alttext="\begin{split}\mathcal{L}_{D}=\lambda\mathcal{L}_{BD}\left(\cdot\right)+\mu\mathcal{L}_{BK}\left(\cdot\right)+\nu\frac{1}{n}\sum_{j=1}^{n}\left(\mathcal{L}_{P_{n}}\left(\cdot\right)\right)\end{split}" display="block"><semantics id="S4.E2.m1.31a"><mtable displaystyle="true" id="S4.E2.m1.31.31.2" xref="S4.E2.m1.30.30.1.cmml"><mtr id="S4.E2.m1.31.31.2a" xref="S4.E2.m1.30.30.1.cmml"><mtd class="ltx_align_right" columnalign="right" id="S4.E2.m1.31.31.2b" xref="S4.E2.m1.30.30.1.cmml"><mrow id="S4.E2.m1.31.31.2.30.30.30" xref="S4.E2.m1.30.30.1.cmml"><msub id="S4.E2.m1.31.31.2.30.30.30.31" xref="S4.E2.m1.30.30.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E2.m1.1.1.1.1.1.1" xref="S4.E2.m1.1.1.1.1.1.1.cmml">ℒ</mi><mi id="S4.E2.m1.2.2.2.2.2.2.1" xref="S4.E2.m1.2.2.2.2.2.2.1.cmml">D</mi></msub><mo id="S4.E2.m1.3.3.3.3.3.3" xref="S4.E2.m1.3.3.3.3.3.3.cmml">=</mo><mrow id="S4.E2.m1.31.31.2.30.30.30.30" xref="S4.E2.m1.30.30.1.cmml"><mrow id="S4.E2.m1.31.31.2.30.30.30.30.2" xref="S4.E2.m1.30.30.1.cmml"><mi id="S4.E2.m1.4.4.4.4.4.4" xref="S4.E2.m1.4.4.4.4.4.4.cmml">λ</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.31.31.2.30.30.30.30.2.1" xref="S4.E2.m1.30.30.1.cmml">​</mo><msub id="S4.E2.m1.31.31.2.30.30.30.30.2.2" xref="S4.E2.m1.30.30.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E2.m1.5.5.5.5.5.5" xref="S4.E2.m1.5.5.5.5.5.5.cmml">ℒ</mi><mrow id="S4.E2.m1.6.6.6.6.6.6.1" xref="S4.E2.m1.6.6.6.6.6.6.1.cmml"><mi id="S4.E2.m1.6.6.6.6.6.6.1.2" xref="S4.E2.m1.6.6.6.6.6.6.1.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.6.6.6.6.6.6.1.1" xref="S4.E2.m1.6.6.6.6.6.6.1.1.cmml">​</mo><mi id="S4.E2.m1.6.6.6.6.6.6.1.3" xref="S4.E2.m1.6.6.6.6.6.6.1.3.cmml">D</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.E2.m1.31.31.2.30.30.30.30.2.1a" xref="S4.E2.m1.30.30.1.cmml">​</mo><mrow id="S4.E2.m1.31.31.2.30.30.30.30.2.3" xref="S4.E2.m1.30.30.1.cmml"><mo id="S4.E2.m1.7.7.7.7.7.7" xref="S4.E2.m1.30.30.1.cmml">(</mo><mo lspace="0em" rspace="0em" id="S4.E2.m1.8.8.8.8.8.8" xref="S4.E2.m1.8.8.8.8.8.8.cmml">⋅</mo><mo id="S4.E2.m1.9.9.9.9.9.9" xref="S4.E2.m1.30.30.1.cmml">)</mo></mrow></mrow><mo id="S4.E2.m1.10.10.10.10.10.10" xref="S4.E2.m1.10.10.10.10.10.10.cmml">+</mo><mrow id="S4.E2.m1.31.31.2.30.30.30.30.3" xref="S4.E2.m1.30.30.1.cmml"><mi id="S4.E2.m1.11.11.11.11.11.11" xref="S4.E2.m1.11.11.11.11.11.11.cmml">μ</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.31.31.2.30.30.30.30.3.1" xref="S4.E2.m1.30.30.1.cmml">​</mo><msub id="S4.E2.m1.31.31.2.30.30.30.30.3.2" xref="S4.E2.m1.30.30.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E2.m1.12.12.12.12.12.12" xref="S4.E2.m1.12.12.12.12.12.12.cmml">ℒ</mi><mrow id="S4.E2.m1.13.13.13.13.13.13.1" xref="S4.E2.m1.13.13.13.13.13.13.1.cmml"><mi id="S4.E2.m1.13.13.13.13.13.13.1.2" xref="S4.E2.m1.13.13.13.13.13.13.1.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.13.13.13.13.13.13.1.1" xref="S4.E2.m1.13.13.13.13.13.13.1.1.cmml">​</mo><mi id="S4.E2.m1.13.13.13.13.13.13.1.3" xref="S4.E2.m1.13.13.13.13.13.13.1.3.cmml">K</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S4.E2.m1.31.31.2.30.30.30.30.3.1a" xref="S4.E2.m1.30.30.1.cmml">​</mo><mrow id="S4.E2.m1.31.31.2.30.30.30.30.3.3" xref="S4.E2.m1.30.30.1.cmml"><mo id="S4.E2.m1.14.14.14.14.14.14" xref="S4.E2.m1.30.30.1.cmml">(</mo><mo lspace="0em" rspace="0em" id="S4.E2.m1.15.15.15.15.15.15" xref="S4.E2.m1.15.15.15.15.15.15.cmml">⋅</mo><mo id="S4.E2.m1.16.16.16.16.16.16" xref="S4.E2.m1.30.30.1.cmml">)</mo></mrow></mrow><mo id="S4.E2.m1.10.10.10.10.10.10a" xref="S4.E2.m1.10.10.10.10.10.10.cmml">+</mo><mrow id="S4.E2.m1.31.31.2.30.30.30.30.1" xref="S4.E2.m1.30.30.1.cmml"><mi id="S4.E2.m1.18.18.18.18.18.18" xref="S4.E2.m1.18.18.18.18.18.18.cmml">ν</mi><mo lspace="0em" rspace="0em" id="S4.E2.m1.31.31.2.30.30.30.30.1.2" xref="S4.E2.m1.30.30.1.cmml">​</mo><mfrac id="S4.E2.m1.19.19.19.19.19.19" xref="S4.E2.m1.19.19.19.19.19.19.cmml"><mn id="S4.E2.m1.19.19.19.19.19.19.2" xref="S4.E2.m1.19.19.19.19.19.19.2.cmml">1</mn><mi id="S4.E2.m1.19.19.19.19.19.19.3" xref="S4.E2.m1.19.19.19.19.19.19.3.cmml">n</mi></mfrac><mo lspace="0em" rspace="0em" id="S4.E2.m1.31.31.2.30.30.30.30.1.2a" xref="S4.E2.m1.30.30.1.cmml">​</mo><mrow id="S4.E2.m1.31.31.2.30.30.30.30.1.1" xref="S4.E2.m1.30.30.1.cmml"><munderover id="S4.E2.m1.31.31.2.30.30.30.30.1.1.2" xref="S4.E2.m1.30.30.1.cmml"><mo movablelimits="false" rspace="0em" id="S4.E2.m1.20.20.20.20.20.20" xref="S4.E2.m1.20.20.20.20.20.20.cmml">∑</mo><mrow id="S4.E2.m1.21.21.21.21.21.21.1" xref="S4.E2.m1.21.21.21.21.21.21.1.cmml"><mi id="S4.E2.m1.21.21.21.21.21.21.1.2" xref="S4.E2.m1.21.21.21.21.21.21.1.2.cmml">j</mi><mo id="S4.E2.m1.21.21.21.21.21.21.1.1" xref="S4.E2.m1.21.21.21.21.21.21.1.1.cmml">=</mo><mn id="S4.E2.m1.21.21.21.21.21.21.1.3" xref="S4.E2.m1.21.21.21.21.21.21.1.3.cmml">1</mn></mrow><mi id="S4.E2.m1.22.22.22.22.22.22.1" xref="S4.E2.m1.22.22.22.22.22.22.1.cmml">n</mi></munderover><mrow id="S4.E2.m1.31.31.2.30.30.30.30.1.1.1.1" xref="S4.E2.m1.30.30.1.cmml"><mo id="S4.E2.m1.23.23.23.23.23.23" xref="S4.E2.m1.30.30.1.cmml">(</mo><mrow id="S4.E2.m1.31.31.2.30.30.30.30.1.1.1.1.1" xref="S4.E2.m1.30.30.1.cmml"><msub id="S4.E2.m1.31.31.2.30.30.30.30.1.1.1.1.1.2" xref="S4.E2.m1.30.30.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.E2.m1.24.24.24.24.24.24" xref="S4.E2.m1.24.24.24.24.24.24.cmml">ℒ</mi><msub id="S4.E2.m1.25.25.25.25.25.25.1" xref="S4.E2.m1.25.25.25.25.25.25.1.cmml"><mi id="S4.E2.m1.25.25.25.25.25.25.1.2" xref="S4.E2.m1.25.25.25.25.25.25.1.2.cmml">P</mi><mi id="S4.E2.m1.25.25.25.25.25.25.1.3" xref="S4.E2.m1.25.25.25.25.25.25.1.3.cmml">n</mi></msub></msub><mo lspace="0em" rspace="0em" id="S4.E2.m1.31.31.2.30.30.30.30.1.1.1.1.1.1" xref="S4.E2.m1.30.30.1.cmml">​</mo><mrow id="S4.E2.m1.31.31.2.30.30.30.30.1.1.1.1.1.3" xref="S4.E2.m1.30.30.1.cmml"><mo id="S4.E2.m1.26.26.26.26.26.26" xref="S4.E2.m1.30.30.1.cmml">(</mo><mo lspace="0em" rspace="0em" id="S4.E2.m1.27.27.27.27.27.27" xref="S4.E2.m1.27.27.27.27.27.27.cmml">⋅</mo><mo id="S4.E2.m1.28.28.28.28.28.28" xref="S4.E2.m1.30.30.1.cmml">)</mo></mrow></mrow><mo id="S4.E2.m1.29.29.29.29.29.29" xref="S4.E2.m1.30.30.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S4.E2.m1.31b"><apply id="S4.E2.m1.30.30.1.cmml" xref="S4.E2.m1.31.31.2"><eq id="S4.E2.m1.3.3.3.3.3.3.cmml" xref="S4.E2.m1.3.3.3.3.3.3"></eq><apply id="S4.E2.m1.30.30.1.3.cmml" xref="S4.E2.m1.31.31.2"><csymbol cd="ambiguous" id="S4.E2.m1.30.30.1.3.1.cmml" xref="S4.E2.m1.31.31.2">subscript</csymbol><ci id="S4.E2.m1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.1.1.1.1.1.1">ℒ</ci><ci id="S4.E2.m1.2.2.2.2.2.2.1.cmml" xref="S4.E2.m1.2.2.2.2.2.2.1">𝐷</ci></apply><apply id="S4.E2.m1.30.30.1.1.cmml" xref="S4.E2.m1.31.31.2"><plus id="S4.E2.m1.10.10.10.10.10.10.cmml" xref="S4.E2.m1.10.10.10.10.10.10"></plus><apply id="S4.E2.m1.30.30.1.1.3.cmml" xref="S4.E2.m1.31.31.2"><times id="S4.E2.m1.30.30.1.1.3.1.cmml" xref="S4.E2.m1.31.31.2"></times><ci id="S4.E2.m1.4.4.4.4.4.4.cmml" xref="S4.E2.m1.4.4.4.4.4.4">𝜆</ci><apply id="S4.E2.m1.30.30.1.1.3.3.cmml" xref="S4.E2.m1.31.31.2"><csymbol cd="ambiguous" id="S4.E2.m1.30.30.1.1.3.3.1.cmml" xref="S4.E2.m1.31.31.2">subscript</csymbol><ci id="S4.E2.m1.5.5.5.5.5.5.cmml" xref="S4.E2.m1.5.5.5.5.5.5">ℒ</ci><apply id="S4.E2.m1.6.6.6.6.6.6.1.cmml" xref="S4.E2.m1.6.6.6.6.6.6.1"><times id="S4.E2.m1.6.6.6.6.6.6.1.1.cmml" xref="S4.E2.m1.6.6.6.6.6.6.1.1"></times><ci id="S4.E2.m1.6.6.6.6.6.6.1.2.cmml" xref="S4.E2.m1.6.6.6.6.6.6.1.2">𝐵</ci><ci id="S4.E2.m1.6.6.6.6.6.6.1.3.cmml" xref="S4.E2.m1.6.6.6.6.6.6.1.3">𝐷</ci></apply></apply><ci id="S4.E2.m1.8.8.8.8.8.8.cmml" xref="S4.E2.m1.8.8.8.8.8.8">⋅</ci></apply><apply id="S4.E2.m1.30.30.1.1.4.cmml" xref="S4.E2.m1.31.31.2"><times id="S4.E2.m1.30.30.1.1.4.1.cmml" xref="S4.E2.m1.31.31.2"></times><ci id="S4.E2.m1.11.11.11.11.11.11.cmml" xref="S4.E2.m1.11.11.11.11.11.11">𝜇</ci><apply id="S4.E2.m1.30.30.1.1.4.3.cmml" xref="S4.E2.m1.31.31.2"><csymbol cd="ambiguous" id="S4.E2.m1.30.30.1.1.4.3.1.cmml" xref="S4.E2.m1.31.31.2">subscript</csymbol><ci id="S4.E2.m1.12.12.12.12.12.12.cmml" xref="S4.E2.m1.12.12.12.12.12.12">ℒ</ci><apply id="S4.E2.m1.13.13.13.13.13.13.1.cmml" xref="S4.E2.m1.13.13.13.13.13.13.1"><times id="S4.E2.m1.13.13.13.13.13.13.1.1.cmml" xref="S4.E2.m1.13.13.13.13.13.13.1.1"></times><ci id="S4.E2.m1.13.13.13.13.13.13.1.2.cmml" xref="S4.E2.m1.13.13.13.13.13.13.1.2">𝐵</ci><ci id="S4.E2.m1.13.13.13.13.13.13.1.3.cmml" xref="S4.E2.m1.13.13.13.13.13.13.1.3">𝐾</ci></apply></apply><ci id="S4.E2.m1.15.15.15.15.15.15.cmml" xref="S4.E2.m1.15.15.15.15.15.15">⋅</ci></apply><apply id="S4.E2.m1.30.30.1.1.1.cmml" xref="S4.E2.m1.31.31.2"><times id="S4.E2.m1.30.30.1.1.1.2.cmml" xref="S4.E2.m1.31.31.2"></times><ci id="S4.E2.m1.18.18.18.18.18.18.cmml" xref="S4.E2.m1.18.18.18.18.18.18">𝜈</ci><apply id="S4.E2.m1.19.19.19.19.19.19.cmml" xref="S4.E2.m1.19.19.19.19.19.19"><divide id="S4.E2.m1.19.19.19.19.19.19.1.cmml" xref="S4.E2.m1.19.19.19.19.19.19"></divide><cn type="integer" id="S4.E2.m1.19.19.19.19.19.19.2.cmml" xref="S4.E2.m1.19.19.19.19.19.19.2">1</cn><ci id="S4.E2.m1.19.19.19.19.19.19.3.cmml" xref="S4.E2.m1.19.19.19.19.19.19.3">𝑛</ci></apply><apply id="S4.E2.m1.30.30.1.1.1.1.cmml" xref="S4.E2.m1.31.31.2"><apply id="S4.E2.m1.30.30.1.1.1.1.2.cmml" xref="S4.E2.m1.31.31.2"><csymbol cd="ambiguous" id="S4.E2.m1.30.30.1.1.1.1.2.1.cmml" xref="S4.E2.m1.31.31.2">superscript</csymbol><apply id="S4.E2.m1.30.30.1.1.1.1.2.2.cmml" xref="S4.E2.m1.31.31.2"><csymbol cd="ambiguous" id="S4.E2.m1.30.30.1.1.1.1.2.2.1.cmml" xref="S4.E2.m1.31.31.2">subscript</csymbol><sum id="S4.E2.m1.20.20.20.20.20.20.cmml" xref="S4.E2.m1.20.20.20.20.20.20"></sum><apply id="S4.E2.m1.21.21.21.21.21.21.1.cmml" xref="S4.E2.m1.21.21.21.21.21.21.1"><eq id="S4.E2.m1.21.21.21.21.21.21.1.1.cmml" xref="S4.E2.m1.21.21.21.21.21.21.1.1"></eq><ci id="S4.E2.m1.21.21.21.21.21.21.1.2.cmml" xref="S4.E2.m1.21.21.21.21.21.21.1.2">𝑗</ci><cn type="integer" id="S4.E2.m1.21.21.21.21.21.21.1.3.cmml" xref="S4.E2.m1.21.21.21.21.21.21.1.3">1</cn></apply></apply><ci id="S4.E2.m1.22.22.22.22.22.22.1.cmml" xref="S4.E2.m1.22.22.22.22.22.22.1">𝑛</ci></apply><apply id="S4.E2.m1.30.30.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.31.31.2"><times id="S4.E2.m1.30.30.1.1.1.1.1.1.1.1.cmml" xref="S4.E2.m1.31.31.2"></times><apply id="S4.E2.m1.30.30.1.1.1.1.1.1.1.2.cmml" xref="S4.E2.m1.31.31.2"><csymbol cd="ambiguous" id="S4.E2.m1.30.30.1.1.1.1.1.1.1.2.1.cmml" xref="S4.E2.m1.31.31.2">subscript</csymbol><ci id="S4.E2.m1.24.24.24.24.24.24.cmml" xref="S4.E2.m1.24.24.24.24.24.24">ℒ</ci><apply id="S4.E2.m1.25.25.25.25.25.25.1.cmml" xref="S4.E2.m1.25.25.25.25.25.25.1"><csymbol cd="ambiguous" id="S4.E2.m1.25.25.25.25.25.25.1.1.cmml" xref="S4.E2.m1.25.25.25.25.25.25.1">subscript</csymbol><ci id="S4.E2.m1.25.25.25.25.25.25.1.2.cmml" xref="S4.E2.m1.25.25.25.25.25.25.1.2">𝑃</ci><ci id="S4.E2.m1.25.25.25.25.25.25.1.3.cmml" xref="S4.E2.m1.25.25.25.25.25.25.1.3">𝑛</ci></apply></apply><ci id="S4.E2.m1.27.27.27.27.27.27.cmml" xref="S4.E2.m1.27.27.27.27.27.27">⋅</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.E2.m1.31c">\begin{split}\mathcal{L}_{D}=\lambda\mathcal{L}_{BD}\left(\cdot\right)+\mu\mathcal{L}_{BK}\left(\cdot\right)+\nu\frac{1}{n}\sum_{j=1}^{n}\left(\mathcal{L}_{P_{n}}\left(\cdot\right)\right)\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S4.SS0.SSS0.Px4.p4.12" class="ltx_p">where <math id="S4.SS0.SSS0.Px4.p4.7.m1.1" class="ltx_Math" alttext="\mathcal{L}_{BD}" display="inline"><semantics id="S4.SS0.SSS0.Px4.p4.7.m1.1a"><msub id="S4.SS0.SSS0.Px4.p4.7.m1.1.1" xref="S4.SS0.SSS0.Px4.p4.7.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px4.p4.7.m1.1.1.2" xref="S4.SS0.SSS0.Px4.p4.7.m1.1.1.2.cmml">ℒ</mi><mrow id="S4.SS0.SSS0.Px4.p4.7.m1.1.1.3" xref="S4.SS0.SSS0.Px4.p4.7.m1.1.1.3.cmml"><mi id="S4.SS0.SSS0.Px4.p4.7.m1.1.1.3.2" xref="S4.SS0.SSS0.Px4.p4.7.m1.1.1.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S4.SS0.SSS0.Px4.p4.7.m1.1.1.3.1" xref="S4.SS0.SSS0.Px4.p4.7.m1.1.1.3.1.cmml">​</mo><mi id="S4.SS0.SSS0.Px4.p4.7.m1.1.1.3.3" xref="S4.SS0.SSS0.Px4.p4.7.m1.1.1.3.3.cmml">D</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p4.7.m1.1b"><apply id="S4.SS0.SSS0.Px4.p4.7.m1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.7.m1.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px4.p4.7.m1.1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.7.m1.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px4.p4.7.m1.1.1.2.cmml" xref="S4.SS0.SSS0.Px4.p4.7.m1.1.1.2">ℒ</ci><apply id="S4.SS0.SSS0.Px4.p4.7.m1.1.1.3.cmml" xref="S4.SS0.SSS0.Px4.p4.7.m1.1.1.3"><times id="S4.SS0.SSS0.Px4.p4.7.m1.1.1.3.1.cmml" xref="S4.SS0.SSS0.Px4.p4.7.m1.1.1.3.1"></times><ci id="S4.SS0.SSS0.Px4.p4.7.m1.1.1.3.2.cmml" xref="S4.SS0.SSS0.Px4.p4.7.m1.1.1.3.2">𝐵</ci><ci id="S4.SS0.SSS0.Px4.p4.7.m1.1.1.3.3.cmml" xref="S4.SS0.SSS0.Px4.p4.7.m1.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p4.7.m1.1c">\mathcal{L}_{BD}</annotation></semantics></math> and <math id="S4.SS0.SSS0.Px4.p4.8.m2.1" class="ltx_Math" alttext="\mathcal{L}_{BK}" display="inline"><semantics id="S4.SS0.SSS0.Px4.p4.8.m2.1a"><msub id="S4.SS0.SSS0.Px4.p4.8.m2.1.1" xref="S4.SS0.SSS0.Px4.p4.8.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px4.p4.8.m2.1.1.2" xref="S4.SS0.SSS0.Px4.p4.8.m2.1.1.2.cmml">ℒ</mi><mrow id="S4.SS0.SSS0.Px4.p4.8.m2.1.1.3" xref="S4.SS0.SSS0.Px4.p4.8.m2.1.1.3.cmml"><mi id="S4.SS0.SSS0.Px4.p4.8.m2.1.1.3.2" xref="S4.SS0.SSS0.Px4.p4.8.m2.1.1.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S4.SS0.SSS0.Px4.p4.8.m2.1.1.3.1" xref="S4.SS0.SSS0.Px4.p4.8.m2.1.1.3.1.cmml">​</mo><mi id="S4.SS0.SSS0.Px4.p4.8.m2.1.1.3.3" xref="S4.SS0.SSS0.Px4.p4.8.m2.1.1.3.3.cmml">K</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p4.8.m2.1b"><apply id="S4.SS0.SSS0.Px4.p4.8.m2.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.8.m2.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px4.p4.8.m2.1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.8.m2.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px4.p4.8.m2.1.1.2.cmml" xref="S4.SS0.SSS0.Px4.p4.8.m2.1.1.2">ℒ</ci><apply id="S4.SS0.SSS0.Px4.p4.8.m2.1.1.3.cmml" xref="S4.SS0.SSS0.Px4.p4.8.m2.1.1.3"><times id="S4.SS0.SSS0.Px4.p4.8.m2.1.1.3.1.cmml" xref="S4.SS0.SSS0.Px4.p4.8.m2.1.1.3.1"></times><ci id="S4.SS0.SSS0.Px4.p4.8.m2.1.1.3.2.cmml" xref="S4.SS0.SSS0.Px4.p4.8.m2.1.1.3.2">𝐵</ci><ci id="S4.SS0.SSS0.Px4.p4.8.m2.1.1.3.3.cmml" xref="S4.SS0.SSS0.Px4.p4.8.m2.1.1.3.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p4.8.m2.1c">\mathcal{L}_{BK}</annotation></semantics></math> refer to the Bent and Broken frame labels losses, and <math id="S4.SS0.SSS0.Px4.p4.9.m3.1" class="ltx_Math" alttext="\mathcal{L}_{P_{n}}" display="inline"><semantics id="S4.SS0.SSS0.Px4.p4.9.m3.1a"><msub id="S4.SS0.SSS0.Px4.p4.9.m3.1.1" xref="S4.SS0.SSS0.Px4.p4.9.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px4.p4.9.m3.1.1.2" xref="S4.SS0.SSS0.Px4.p4.9.m3.1.1.2.cmml">ℒ</mi><msub id="S4.SS0.SSS0.Px4.p4.9.m3.1.1.3" xref="S4.SS0.SSS0.Px4.p4.9.m3.1.1.3.cmml"><mi id="S4.SS0.SSS0.Px4.p4.9.m3.1.1.3.2" xref="S4.SS0.SSS0.Px4.p4.9.m3.1.1.3.2.cmml">P</mi><mi id="S4.SS0.SSS0.Px4.p4.9.m3.1.1.3.3" xref="S4.SS0.SSS0.Px4.p4.9.m3.1.1.3.3.cmml">n</mi></msub></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p4.9.m3.1b"><apply id="S4.SS0.SSS0.Px4.p4.9.m3.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.9.m3.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px4.p4.9.m3.1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.9.m3.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px4.p4.9.m3.1.1.2.cmml" xref="S4.SS0.SSS0.Px4.p4.9.m3.1.1.2">ℒ</ci><apply id="S4.SS0.SSS0.Px4.p4.9.m3.1.1.3.cmml" xref="S4.SS0.SSS0.Px4.p4.9.m3.1.1.3"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px4.p4.9.m3.1.1.3.1.cmml" xref="S4.SS0.SSS0.Px4.p4.9.m3.1.1.3">subscript</csymbol><ci id="S4.SS0.SSS0.Px4.p4.9.m3.1.1.3.2.cmml" xref="S4.SS0.SSS0.Px4.p4.9.m3.1.1.3.2">𝑃</ci><ci id="S4.SS0.SSS0.Px4.p4.9.m3.1.1.3.3.cmml" xref="S4.SS0.SSS0.Px4.p4.9.m3.1.1.3.3">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p4.9.m3.1c">\mathcal{L}_{P_{n}}</annotation></semantics></math> to the <math id="S4.SS0.SSS0.Px4.p4.10.m4.1" class="ltx_Math" alttext="n=5" display="inline"><semantics id="S4.SS0.SSS0.Px4.p4.10.m4.1a"><mrow id="S4.SS0.SSS0.Px4.p4.10.m4.1.1" xref="S4.SS0.SSS0.Px4.p4.10.m4.1.1.cmml"><mi id="S4.SS0.SSS0.Px4.p4.10.m4.1.1.2" xref="S4.SS0.SSS0.Px4.p4.10.m4.1.1.2.cmml">n</mi><mo id="S4.SS0.SSS0.Px4.p4.10.m4.1.1.1" xref="S4.SS0.SSS0.Px4.p4.10.m4.1.1.1.cmml">=</mo><mn id="S4.SS0.SSS0.Px4.p4.10.m4.1.1.3" xref="S4.SS0.SSS0.Px4.p4.10.m4.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p4.10.m4.1b"><apply id="S4.SS0.SSS0.Px4.p4.10.m4.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.10.m4.1.1"><eq id="S4.SS0.SSS0.Px4.p4.10.m4.1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.10.m4.1.1.1"></eq><ci id="S4.SS0.SSS0.Px4.p4.10.m4.1.1.2.cmml" xref="S4.SS0.SSS0.Px4.p4.10.m4.1.1.2">𝑛</ci><cn type="integer" id="S4.SS0.SSS0.Px4.p4.10.m4.1.1.3.cmml" xref="S4.SS0.SSS0.Px4.p4.10.m4.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p4.10.m4.1c">n=5</annotation></semantics></math> specific missing parts losses. In the case of real images, for the sake of simplicity we consider only <math id="S4.SS0.SSS0.Px4.p4.11.m5.1" class="ltx_Math" alttext="\mathcal{L}_{BD}" display="inline"><semantics id="S4.SS0.SSS0.Px4.p4.11.m5.1a"><msub id="S4.SS0.SSS0.Px4.p4.11.m5.1.1" xref="S4.SS0.SSS0.Px4.p4.11.m5.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px4.p4.11.m5.1.1.2" xref="S4.SS0.SSS0.Px4.p4.11.m5.1.1.2.cmml">ℒ</mi><mrow id="S4.SS0.SSS0.Px4.p4.11.m5.1.1.3" xref="S4.SS0.SSS0.Px4.p4.11.m5.1.1.3.cmml"><mi id="S4.SS0.SSS0.Px4.p4.11.m5.1.1.3.2" xref="S4.SS0.SSS0.Px4.p4.11.m5.1.1.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S4.SS0.SSS0.Px4.p4.11.m5.1.1.3.1" xref="S4.SS0.SSS0.Px4.p4.11.m5.1.1.3.1.cmml">​</mo><mi id="S4.SS0.SSS0.Px4.p4.11.m5.1.1.3.3" xref="S4.SS0.SSS0.Px4.p4.11.m5.1.1.3.3.cmml">D</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p4.11.m5.1b"><apply id="S4.SS0.SSS0.Px4.p4.11.m5.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.11.m5.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px4.p4.11.m5.1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.11.m5.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px4.p4.11.m5.1.1.2.cmml" xref="S4.SS0.SSS0.Px4.p4.11.m5.1.1.2">ℒ</ci><apply id="S4.SS0.SSS0.Px4.p4.11.m5.1.1.3.cmml" xref="S4.SS0.SSS0.Px4.p4.11.m5.1.1.3"><times id="S4.SS0.SSS0.Px4.p4.11.m5.1.1.3.1.cmml" xref="S4.SS0.SSS0.Px4.p4.11.m5.1.1.3.1"></times><ci id="S4.SS0.SSS0.Px4.p4.11.m5.1.1.3.2.cmml" xref="S4.SS0.SSS0.Px4.p4.11.m5.1.1.3.2">𝐵</ci><ci id="S4.SS0.SSS0.Px4.p4.11.m5.1.1.3.3.cmml" xref="S4.SS0.SSS0.Px4.p4.11.m5.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p4.11.m5.1c">\mathcal{L}_{BD}</annotation></semantics></math> and <math id="S4.SS0.SSS0.Px4.p4.12.m6.1" class="ltx_Math" alttext="\mathcal{L}_{BK}" display="inline"><semantics id="S4.SS0.SSS0.Px4.p4.12.m6.1a"><msub id="S4.SS0.SSS0.Px4.p4.12.m6.1.1" xref="S4.SS0.SSS0.Px4.p4.12.m6.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S4.SS0.SSS0.Px4.p4.12.m6.1.1.2" xref="S4.SS0.SSS0.Px4.p4.12.m6.1.1.2.cmml">ℒ</mi><mrow id="S4.SS0.SSS0.Px4.p4.12.m6.1.1.3" xref="S4.SS0.SSS0.Px4.p4.12.m6.1.1.3.cmml"><mi id="S4.SS0.SSS0.Px4.p4.12.m6.1.1.3.2" xref="S4.SS0.SSS0.Px4.p4.12.m6.1.1.3.2.cmml">B</mi><mo lspace="0em" rspace="0em" id="S4.SS0.SSS0.Px4.p4.12.m6.1.1.3.1" xref="S4.SS0.SSS0.Px4.p4.12.m6.1.1.3.1.cmml">​</mo><mi id="S4.SS0.SSS0.Px4.p4.12.m6.1.1.3.3" xref="S4.SS0.SSS0.Px4.p4.12.m6.1.1.3.3.cmml">K</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS0.SSS0.Px4.p4.12.m6.1b"><apply id="S4.SS0.SSS0.Px4.p4.12.m6.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.12.m6.1.1"><csymbol cd="ambiguous" id="S4.SS0.SSS0.Px4.p4.12.m6.1.1.1.cmml" xref="S4.SS0.SSS0.Px4.p4.12.m6.1.1">subscript</csymbol><ci id="S4.SS0.SSS0.Px4.p4.12.m6.1.1.2.cmml" xref="S4.SS0.SSS0.Px4.p4.12.m6.1.1.2">ℒ</ci><apply id="S4.SS0.SSS0.Px4.p4.12.m6.1.1.3.cmml" xref="S4.SS0.SSS0.Px4.p4.12.m6.1.1.3"><times id="S4.SS0.SSS0.Px4.p4.12.m6.1.1.3.1.cmml" xref="S4.SS0.SSS0.Px4.p4.12.m6.1.1.3.1"></times><ci id="S4.SS0.SSS0.Px4.p4.12.m6.1.1.3.2.cmml" xref="S4.SS0.SSS0.Px4.p4.12.m6.1.1.3.2">𝐵</ci><ci id="S4.SS0.SSS0.Px4.p4.12.m6.1.1.3.3.cmml" xref="S4.SS0.SSS0.Px4.p4.12.m6.1.1.3.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS0.SSS0.Px4.p4.12.m6.1c">\mathcal{L}_{BK}</annotation></semantics></math>.</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px5" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Domain adaptation.</h5>

<div id="S4.SS0.SSS0.Px5.p1" class="ltx_para">
<p id="S4.SS0.SSS0.Px5.p1.1" class="ltx_p">In the baseline, TransReI3D is trained on BBBicycles and tested on the real data set, without adaptation or fine-tuning. We further explored different domain adaptation strategies. For <span id="S4.SS0.SSS0.Px5.p1.1.1" class="ltx_text ltx_font_italic">supervised domain adaptation</span>, we simply leveraged the multi-task training strategy to train the model on real and synthetic data. For <span id="S4.SS0.SSS0.Px5.p1.1.2" class="ltx_text ltx_font_italic">unsupervised domain adaption</span>, we experimented with the well-known domain adversarial technique DANN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite> and with partial domain adaptation PADA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. Experiments with PADA were motivated by the observation that BBBicycles includes a wider range of bike models and setups compared to the real dataset, and therefore forcing the feature distributions to align could lead to negative transfer. PADA assumes that the target domain contains different labels than the source, whereas in our setting DD labels are the same (additionally, all labels are binary given the multi-label setting). Therefore, we introduced the auxiliary task of bike model classification (model information is available for synthetic images); PADA exploits these predictions to enhance the contribution of (samples of) bike models that are present both in the synthetic and real datasets. Further details are available in Appendix B.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experimental settings</h2>

<section id="S5.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">TransReI3D Training and hyper-parameter settings.</h5>

<div id="S5.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px1.p1.3" class="ltx_p">All images were resized to <math id="S5.SS0.SSS0.Px1.p1.1.m1.1" class="ltx_Math" alttext="256\times 256" display="inline"><semantics id="S5.SS0.SSS0.Px1.p1.1.m1.1a"><mrow id="S5.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.cmml"><mn id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.2" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml">256</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.1" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.1.cmml">×</mo><mn id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.3" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml">256</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p1.1.m1.1b"><apply id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1"><times id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.1"></times><cn type="integer" id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.2">256</cn><cn type="integer" id="S5.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S5.SS0.SSS0.Px1.p1.1.m1.1.1.3">256</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p1.1.m1.1c">256\times 256</annotation></semantics></math>, and normalized with the mean and standard deviation calculated on the synthetic training set. Data augmentation was performed with random color- and texture-preserving transformations (horizontal flip, crop, blurring, and gaussian noise). Each image was split into overlapping <math id="S5.SS0.SSS0.Px1.p1.2.m2.1" class="ltx_Math" alttext="16\times 16" display="inline"><semantics id="S5.SS0.SSS0.Px1.p1.2.m2.1a"><mrow id="S5.SS0.SSS0.Px1.p1.2.m2.1.1" xref="S5.SS0.SSS0.Px1.p1.2.m2.1.1.cmml"><mn id="S5.SS0.SSS0.Px1.p1.2.m2.1.1.2" xref="S5.SS0.SSS0.Px1.p1.2.m2.1.1.2.cmml">16</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS0.SSS0.Px1.p1.2.m2.1.1.1" xref="S5.SS0.SSS0.Px1.p1.2.m2.1.1.1.cmml">×</mo><mn id="S5.SS0.SSS0.Px1.p1.2.m2.1.1.3" xref="S5.SS0.SSS0.Px1.p1.2.m2.1.1.3.cmml">16</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p1.2.m2.1b"><apply id="S5.SS0.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.2.m2.1.1"><times id="S5.SS0.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.2.m2.1.1.1"></times><cn type="integer" id="S5.SS0.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S5.SS0.SSS0.Px1.p1.2.m2.1.1.2">16</cn><cn type="integer" id="S5.SS0.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S5.SS0.SSS0.Px1.p1.2.m2.1.1.3">16</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p1.2.m2.1c">16\times 16</annotation></semantics></math> patches, with patch stride set to <math id="S5.SS0.SSS0.Px1.p1.3.m3.1" class="ltx_Math" alttext="12\times 12" display="inline"><semantics id="S5.SS0.SSS0.Px1.p1.3.m3.1a"><mrow id="S5.SS0.SSS0.Px1.p1.3.m3.1.1" xref="S5.SS0.SSS0.Px1.p1.3.m3.1.1.cmml"><mn id="S5.SS0.SSS0.Px1.p1.3.m3.1.1.2" xref="S5.SS0.SSS0.Px1.p1.3.m3.1.1.2.cmml">12</mn><mo lspace="0.222em" rspace="0.222em" id="S5.SS0.SSS0.Px1.p1.3.m3.1.1.1" xref="S5.SS0.SSS0.Px1.p1.3.m3.1.1.1.cmml">×</mo><mn id="S5.SS0.SSS0.Px1.p1.3.m3.1.1.3" xref="S5.SS0.SSS0.Px1.p1.3.m3.1.1.3.cmml">12</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p1.3.m3.1b"><apply id="S5.SS0.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.3.m3.1.1"><times id="S5.SS0.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S5.SS0.SSS0.Px1.p1.3.m3.1.1.1"></times><cn type="integer" id="S5.SS0.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S5.SS0.SSS0.Px1.p1.3.m3.1.1.2">12</cn><cn type="integer" id="S5.SS0.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S5.SS0.SSS0.Px1.p1.3.m3.1.1.3">12</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p1.3.m3.1c">12\times 12</annotation></semantics></math>. Batches containing either real or synthetic images were alternated, and the real dataset was iterated twice per epoch to counterbalance the smaller size.</p>
</div>
<div id="S5.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="S5.SS0.SSS0.Px1.p2.1" class="ltx_p">For all experiments, the model backbone was pre-trained on ImageNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, and the remaining weights were initialized by Kaiming normal initialization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. All models were trained for 20 epochs. The SGD optimizer was used with batch size set to 32, momentum to 0.9 and weight decay to 1e-4. The cosine learning rate scheduler was used (initial learning rate 0.01, linear warmup for 5 epochs).</p>
</div>
<div id="S5.SS0.SSS0.Px1.p3" class="ltx_para">
<p id="S5.SS0.SSS0.Px1.p3.7" class="ltx_p">Regarding the loss, we set <math id="S5.SS0.SSS0.Px1.p3.1.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S5.SS0.SSS0.Px1.p3.1.m1.1a"><mi id="S5.SS0.SSS0.Px1.p3.1.m1.1.1" xref="S5.SS0.SSS0.Px1.p3.1.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p3.1.m1.1b"><ci id="S5.SS0.SSS0.Px1.p3.1.m1.1.1.cmml" xref="S5.SS0.SSS0.Px1.p3.1.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p3.1.m1.1c">\alpha</annotation></semantics></math>, <math id="S5.SS0.SSS0.Px1.p3.2.m2.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S5.SS0.SSS0.Px1.p3.2.m2.1a"><mi id="S5.SS0.SSS0.Px1.p3.2.m2.1.1" xref="S5.SS0.SSS0.Px1.p3.2.m2.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p3.2.m2.1b"><ci id="S5.SS0.SSS0.Px1.p3.2.m2.1.1.cmml" xref="S5.SS0.SSS0.Px1.p3.2.m2.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p3.2.m2.1c">\beta</annotation></semantics></math> and <math id="S5.SS0.SSS0.Px1.p3.3.m3.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S5.SS0.SSS0.Px1.p3.3.m3.1a"><mi id="S5.SS0.SSS0.Px1.p3.3.m3.1.1" xref="S5.SS0.SSS0.Px1.p3.3.m3.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p3.3.m3.1b"><ci id="S5.SS0.SSS0.Px1.p3.3.m3.1.1.cmml" xref="S5.SS0.SSS0.Px1.p3.3.m3.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p3.3.m3.1c">\gamma</annotation></semantics></math> to 1, whereas for <math id="S5.SS0.SSS0.Px1.p3.4.m4.1" class="ltx_Math" alttext="\mathcal{L}_{D}" display="inline"><semantics id="S5.SS0.SSS0.Px1.p3.4.m4.1a"><msub id="S5.SS0.SSS0.Px1.p3.4.m4.1.1" xref="S5.SS0.SSS0.Px1.p3.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.SS0.SSS0.Px1.p3.4.m4.1.1.2" xref="S5.SS0.SSS0.Px1.p3.4.m4.1.1.2.cmml">ℒ</mi><mi id="S5.SS0.SSS0.Px1.p3.4.m4.1.1.3" xref="S5.SS0.SSS0.Px1.p3.4.m4.1.1.3.cmml">D</mi></msub><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p3.4.m4.1b"><apply id="S5.SS0.SSS0.Px1.p3.4.m4.1.1.cmml" xref="S5.SS0.SSS0.Px1.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S5.SS0.SSS0.Px1.p3.4.m4.1.1.1.cmml" xref="S5.SS0.SSS0.Px1.p3.4.m4.1.1">subscript</csymbol><ci id="S5.SS0.SSS0.Px1.p3.4.m4.1.1.2.cmml" xref="S5.SS0.SSS0.Px1.p3.4.m4.1.1.2">ℒ</ci><ci id="S5.SS0.SSS0.Px1.p3.4.m4.1.1.3.cmml" xref="S5.SS0.SSS0.Px1.p3.4.m4.1.1.3">𝐷</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p3.4.m4.1c">\mathcal{L}_{D}</annotation></semantics></math>, we set <math id="S5.SS0.SSS0.Px1.p3.5.m5.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S5.SS0.SSS0.Px1.p3.5.m5.1a"><mi id="S5.SS0.SSS0.Px1.p3.5.m5.1.1" xref="S5.SS0.SSS0.Px1.p3.5.m5.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p3.5.m5.1b"><ci id="S5.SS0.SSS0.Px1.p3.5.m5.1.1.cmml" xref="S5.SS0.SSS0.Px1.p3.5.m5.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p3.5.m5.1c">\lambda</annotation></semantics></math>, <math id="S5.SS0.SSS0.Px1.p3.6.m6.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="S5.SS0.SSS0.Px1.p3.6.m6.1a"><mi id="S5.SS0.SSS0.Px1.p3.6.m6.1.1" xref="S5.SS0.SSS0.Px1.p3.6.m6.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p3.6.m6.1b"><ci id="S5.SS0.SSS0.Px1.p3.6.m6.1.1.cmml" xref="S5.SS0.SSS0.Px1.p3.6.m6.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p3.6.m6.1c">\mu</annotation></semantics></math>, <math id="S5.SS0.SSS0.Px1.p3.7.m7.1" class="ltx_Math" alttext="\nu" display="inline"><semantics id="S5.SS0.SSS0.Px1.p3.7.m7.1a"><mi id="S5.SS0.SSS0.Px1.p3.7.m7.1.1" xref="S5.SS0.SSS0.Px1.p3.7.m7.1.1.cmml">ν</mi><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px1.p3.7.m7.1b"><ci id="S5.SS0.SSS0.Px1.p3.7.m7.1.1.cmml" xref="S5.SS0.SSS0.Px1.p3.7.m7.1.1">𝜈</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px1.p3.7.m7.1c">\nu</annotation></semantics></math> to 0.25, 0.25 and 0.5, respectively.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Other baselines.</h5>

<div id="S5.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px2.p1.1" class="ltx_p">TransReI3D was compared against the Reranking Transformers (RRT) Global retrieval baseline <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>. RRT was trained on BBBicyclesfor 50 epochs. The training setting is the same as the default one used in the original code, with learning rate of 1e-3, SGD optimizer with 0.9 momentum, batch size 128, weight decay of 4e-4, MultiStep learning rate scheduler with a 0.1 decay at epochs 30 and 40, contrastive loss and ResNet-50 backbone. However, since RRT does not perform damage detection, it was evaluated only on the ReID task.</p>
</div>
</section>
<section id="S5.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Evaluation protocol.</h5>

<div id="S5.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S5.SS0.SSS0.Px3.p1.3" class="ltx_p">Performance on the ReID task was measured using common metrics for vehicle and object ReID, i.e., mean Average Precision (mAP) and Cumulative Matching Characteristics (CMC) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. CMC-<math id="S5.SS0.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S5.SS0.SSS0.Px3.p1.1.m1.1a"><mi id="S5.SS0.SSS0.Px3.p1.1.m1.1.1" xref="S5.SS0.SSS0.Px3.p1.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px3.p1.1.m1.1b"><ci id="S5.SS0.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S5.SS0.SSS0.Px3.p1.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px3.p1.1.m1.1c">K</annotation></semantics></math>, with <math id="S5.SS0.SSS0.Px3.p1.2.m2.3" class="ltx_Math" alttext="K=\{1,5,10\}" display="inline"><semantics id="S5.SS0.SSS0.Px3.p1.2.m2.3a"><mrow id="S5.SS0.SSS0.Px3.p1.2.m2.3.4" xref="S5.SS0.SSS0.Px3.p1.2.m2.3.4.cmml"><mi id="S5.SS0.SSS0.Px3.p1.2.m2.3.4.2" xref="S5.SS0.SSS0.Px3.p1.2.m2.3.4.2.cmml">K</mi><mo id="S5.SS0.SSS0.Px3.p1.2.m2.3.4.1" xref="S5.SS0.SSS0.Px3.p1.2.m2.3.4.1.cmml">=</mo><mrow id="S5.SS0.SSS0.Px3.p1.2.m2.3.4.3.2" xref="S5.SS0.SSS0.Px3.p1.2.m2.3.4.3.1.cmml"><mo stretchy="false" id="S5.SS0.SSS0.Px3.p1.2.m2.3.4.3.2.1" xref="S5.SS0.SSS0.Px3.p1.2.m2.3.4.3.1.cmml">{</mo><mn id="S5.SS0.SSS0.Px3.p1.2.m2.1.1" xref="S5.SS0.SSS0.Px3.p1.2.m2.1.1.cmml">1</mn><mo id="S5.SS0.SSS0.Px3.p1.2.m2.3.4.3.2.2" xref="S5.SS0.SSS0.Px3.p1.2.m2.3.4.3.1.cmml">,</mo><mn id="S5.SS0.SSS0.Px3.p1.2.m2.2.2" xref="S5.SS0.SSS0.Px3.p1.2.m2.2.2.cmml">5</mn><mo id="S5.SS0.SSS0.Px3.p1.2.m2.3.4.3.2.3" xref="S5.SS0.SSS0.Px3.p1.2.m2.3.4.3.1.cmml">,</mo><mn id="S5.SS0.SSS0.Px3.p1.2.m2.3.3" xref="S5.SS0.SSS0.Px3.p1.2.m2.3.3.cmml">10</mn><mo stretchy="false" id="S5.SS0.SSS0.Px3.p1.2.m2.3.4.3.2.4" xref="S5.SS0.SSS0.Px3.p1.2.m2.3.4.3.1.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px3.p1.2.m2.3b"><apply id="S5.SS0.SSS0.Px3.p1.2.m2.3.4.cmml" xref="S5.SS0.SSS0.Px3.p1.2.m2.3.4"><eq id="S5.SS0.SSS0.Px3.p1.2.m2.3.4.1.cmml" xref="S5.SS0.SSS0.Px3.p1.2.m2.3.4.1"></eq><ci id="S5.SS0.SSS0.Px3.p1.2.m2.3.4.2.cmml" xref="S5.SS0.SSS0.Px3.p1.2.m2.3.4.2">𝐾</ci><set id="S5.SS0.SSS0.Px3.p1.2.m2.3.4.3.1.cmml" xref="S5.SS0.SSS0.Px3.p1.2.m2.3.4.3.2"><cn type="integer" id="S5.SS0.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S5.SS0.SSS0.Px3.p1.2.m2.1.1">1</cn><cn type="integer" id="S5.SS0.SSS0.Px3.p1.2.m2.2.2.cmml" xref="S5.SS0.SSS0.Px3.p1.2.m2.2.2">5</cn><cn type="integer" id="S5.SS0.SSS0.Px3.p1.2.m2.3.3.cmml" xref="S5.SS0.SSS0.Px3.p1.2.m2.3.3">10</cn></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px3.p1.2.m2.3c">K=\{1,5,10\}</annotation></semantics></math>, represents the average probability of observing the correct identity within the top-<math id="S5.SS0.SSS0.Px3.p1.3.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S5.SS0.SSS0.Px3.p1.3.m3.1a"><mi id="S5.SS0.SSS0.Px3.p1.3.m3.1.1" xref="S5.SS0.SSS0.Px3.p1.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S5.SS0.SSS0.Px3.p1.3.m3.1b"><ci id="S5.SS0.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S5.SS0.SSS0.Px3.p1.3.m3.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.SS0.SSS0.Px3.p1.3.m3.1c">K</annotation></semantics></math> ranked results. Since the gallery contains one instance per bike ID, it is equivalent to Recall@K. For each pair of images in the validation and stress test, we set the “after” image as Query and the “before” image as Gallery. All images from other IDs (including those derived from the same 3D bike model) were used as distractors.</p>
</div>
<div id="S5.SS0.SSS0.Px3.p2" class="ltx_para">
<p id="S5.SS0.SSS0.Px3.p2.1" class="ltx_p">For the DD task, performance was measured using the Area under the Receiver Operating Characteristic Curve (AUROC), macro-averaged across all labels. For the sake of conciseness, we report only results for Bent and Broken labels, since damages to the frame are more challenging to detect than missing parts. All performance metrics were averaged over three runs.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Results</h2>

<figure id="S6.T1" class="ltx_table">
<table id="S6.T1.15.15" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S6.T1.15.15.16.1" class="ltx_tr">
<th id="S6.T1.15.15.16.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="S6.T1.15.15.16.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="6">
<span id="S6.T1.15.15.16.1.2.1" class="ltx_ERROR undefined">\cellcolor</span>[HTML]EFEFEF<span id="S6.T1.15.15.16.1.2.2" class="ltx_text ltx_font_bold">Validation</span>
</td>
</tr>
<tr id="S6.T1.15.15.17.2" class="ltx_tr">
<th id="S6.T1.15.15.17.2.1" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="S6.T1.15.15.17.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><span id="S6.T1.15.15.17.2.2.1" class="ltx_text ltx_font_bold">Damage Detection</span></td>
<td id="S6.T1.15.15.17.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="4"><span id="S6.T1.15.15.17.2.3.1" class="ltx_text ltx_font_bold">Re-identification (Synthetic)</span></td>
</tr>
<tr id="S6.T1.15.15.18.3" class="ltx_tr">
<th id="S6.T1.15.15.18.3.1" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="S6.T1.15.15.18.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S6.T1.15.15.18.3.2.1" class="ltx_text ltx_font_bold">Real AUC</span></td>
<td id="S6.T1.15.15.18.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S6.T1.15.15.18.3.3.1" class="ltx_text ltx_font_bold">Synthetic AUC</span></td>
<td id="S6.T1.15.15.18.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S6.T1.15.15.18.3.4.1" class="ltx_text ltx_font_bold">mAP</span></td>
<td id="S6.T1.15.15.18.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S6.T1.15.15.18.3.5.1" class="ltx_text ltx_font_bold">CMC-1</span></td>
<td id="S6.T1.15.15.18.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S6.T1.15.15.18.3.6.1" class="ltx_text ltx_font_bold">CMC-5</span></td>
<td id="S6.T1.15.15.18.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S6.T1.15.15.18.3.7.1" class="ltx_text ltx_font_bold">CMC-10</span></td>
</tr>
<tr id="S6.T1.15.15.19.4" class="ltx_tr">
<th id="S6.T1.15.15.19.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">BL</th>
<td id="S6.T1.15.15.19.4.2" class="ltx_td ltx_align_center ltx_border_t">93.4 ± 1.5</td>
<td id="S6.T1.15.15.19.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">92.1 ± 0.5</td>
<td id="S6.T1.15.15.19.4.4" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T1.15.15.19.4.4.1" class="ltx_text ltx_font_bold">85.3 ± 0.2</span></td>
<td id="S6.T1.15.15.19.4.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T1.15.15.19.4.5.1" class="ltx_text ltx_font_bold">79.8 ± 0.5</span></td>
<td id="S6.T1.15.15.19.4.6" class="ltx_td ltx_align_center ltx_border_t">91.9 ± 1.1</td>
<td id="S6.T1.15.15.19.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.3 ± 0.5</td>
</tr>
<tr id="S6.T1.1.1.1" class="ltx_tr">
<th id="S6.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">BL + Real<sup id="S6.T1.1.1.1.1.1" class="ltx_sup"><math id="S6.T1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S6.T1.1.1.1.1.1.m1.1a"><mo id="S6.T1.1.1.1.1.1.m1.1.1" xref="S6.T1.1.1.1.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S6.T1.1.1.1.1.1.m1.1b"><ci id="S6.T1.1.1.1.1.1.m1.1.1.cmml" xref="S6.T1.1.1.1.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.1.1.1.1.1.m1.1c">\dagger</annotation></semantics></math></sup>
</th>
<td id="S6.T1.1.1.1.2" class="ltx_td ltx_align_center"><span id="S6.T1.1.1.1.2.1" class="ltx_text ltx_font_bold">97.3 ± 2.2</span></td>
<td id="S6.T1.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r">91.4 ± 0.2</td>
<td id="S6.T1.1.1.1.4" class="ltx_td ltx_align_center"><span id="S6.T1.1.1.1.4.1" class="ltx_text ltx_font_bold">85.3 ± 0.2</span></td>
<td id="S6.T1.1.1.1.5" class="ltx_td ltx_align_center">79.4 ± 0.1</td>
<td id="S6.T1.1.1.1.6" class="ltx_td ltx_align_center"><span id="S6.T1.1.1.1.6.1" class="ltx_text ltx_font_bold">92.9 ± 0.4</span></td>
<td id="S6.T1.1.1.1.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T1.1.1.1.7.1" class="ltx_text ltx_font_bold">96.6 ± 0.4</span></td>
</tr>
<tr id="S6.T1.15.15.20.5" class="ltx_tr">
<th id="S6.T1.15.15.20.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">RRT (Global)</th>
<td id="S6.T1.15.15.20.5.2" class="ltx_td ltx_align_center">-</td>
<td id="S6.T1.15.15.20.5.3" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S6.T1.15.15.20.5.4" class="ltx_td ltx_align_center">80.5 ± 1</td>
<td id="S6.T1.15.15.20.5.5" class="ltx_td ltx_align_center">74.1 ± 1.6</td>
<td id="S6.T1.15.15.20.5.6" class="ltx_td ltx_align_center">88.3 ± 1.1</td>
<td id="S6.T1.15.15.20.5.7" class="ltx_td ltx_align_center ltx_border_r">93.4 ± 1.2</td>
</tr>
<tr id="S6.T1.2.2.2" class="ltx_tr">
<th id="S6.T1.2.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">BG Places365 + Real <sup id="S6.T1.2.2.2.1.1" class="ltx_sup"><math id="S6.T1.2.2.2.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S6.T1.2.2.2.1.1.m1.1a"><mo id="S6.T1.2.2.2.1.1.m1.1.1" xref="S6.T1.2.2.2.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S6.T1.2.2.2.1.1.m1.1b"><ci id="S6.T1.2.2.2.1.1.m1.1.1.cmml" xref="S6.T1.2.2.2.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.2.2.2.1.1.m1.1c">\dagger</annotation></semantics></math></sup>
</th>
<td id="S6.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">96.3 ± 1.9</td>
<td id="S6.T1.2.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">90.4 ± 0.2</td>
<td id="S6.T1.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t">85 ± 0.1</td>
<td id="S6.T1.2.2.2.5" class="ltx_td ltx_align_center ltx_border_t">79.0 ± 0.4</td>
<td id="S6.T1.2.2.2.6" class="ltx_td ltx_align_center ltx_border_t">92.8 ± 0.3</td>
<td id="S6.T1.2.2.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.3 ± 0.2</td>
</tr>
<tr id="S6.T1.3.3.3" class="ltx_tr">
<th id="S6.T1.3.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">BG Uniform + Real <sup id="S6.T1.3.3.3.1.1" class="ltx_sup"><math id="S6.T1.3.3.3.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S6.T1.3.3.3.1.1.m1.1a"><mo id="S6.T1.3.3.3.1.1.m1.1.1" xref="S6.T1.3.3.3.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S6.T1.3.3.3.1.1.m1.1b"><ci id="S6.T1.3.3.3.1.1.m1.1.1.cmml" xref="S6.T1.3.3.3.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.3.3.3.1.1.m1.1c">\dagger</annotation></semantics></math></sup>
</th>
<td id="S6.T1.3.3.3.2" class="ltx_td ltx_align_center">95.2 ± 3.4</td>
<td id="S6.T1.3.3.3.3" class="ltx_td ltx_align_center ltx_border_r">87.4 ± 1.5</td>
<td id="S6.T1.3.3.3.4" class="ltx_td ltx_align_center">48.5 ± 3.4</td>
<td id="S6.T1.3.3.3.5" class="ltx_td ltx_align_center">39.2 ± 1.9</td>
<td id="S6.T1.3.3.3.6" class="ltx_td ltx_align_center">59.4 ± 5.6</td>
<td id="S6.T1.3.3.3.7" class="ltx_td ltx_align_center ltx_border_r">66.0 ± 5.7</td>
</tr>
<tr id="S6.T1.4.4.4" class="ltx_tr">
<th id="S6.T1.4.4.4.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">ReID (single task)<sup id="S6.T1.4.4.4.1.1" class="ltx_sup"><math id="S6.T1.4.4.4.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S6.T1.4.4.4.1.1.m1.1a"><mo id="S6.T1.4.4.4.1.1.m1.1.1" xref="S6.T1.4.4.4.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S6.T1.4.4.4.1.1.m1.1b"><ci id="S6.T1.4.4.4.1.1.m1.1.1.cmml" xref="S6.T1.4.4.4.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.4.4.4.1.1.m1.1c">\dagger</annotation></semantics></math></sup>
</th>
<td id="S6.T1.4.4.4.2" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S6.T1.4.4.4.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
<td id="S6.T1.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">83.3 ± 1.2</td>
<td id="S6.T1.4.4.4.5" class="ltx_td ltx_align_center ltx_border_t">77.0 ± 1.2</td>
<td id="S6.T1.4.4.4.6" class="ltx_td ltx_align_center ltx_border_t">91.2 ± 1.5</td>
<td id="S6.T1.4.4.4.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">95.1 ± 1.4</td>
</tr>
<tr id="S6.T1.5.5.5" class="ltx_tr">
<th id="S6.T1.5.5.5.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">Damage detection (single task)<sup id="S6.T1.5.5.5.1.1" class="ltx_sup"><math id="S6.T1.5.5.5.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S6.T1.5.5.5.1.1.m1.1a"><mo id="S6.T1.5.5.5.1.1.m1.1.1" xref="S6.T1.5.5.5.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S6.T1.5.5.5.1.1.m1.1b"><ci id="S6.T1.5.5.5.1.1.m1.1.1.cmml" xref="S6.T1.5.5.5.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.5.5.5.1.1.m1.1c">\dagger</annotation></semantics></math></sup>
</th>
<td id="S6.T1.5.5.5.2" class="ltx_td ltx_align_center"><span id="S6.T1.5.5.5.2.1" class="ltx_text ltx_font_bold">97.5 ± 1.5</span></td>
<td id="S6.T1.5.5.5.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T1.5.5.5.3.1" class="ltx_text ltx_font_bold">94.5 ± 0.5</span></td>
<td id="S6.T1.5.5.5.4" class="ltx_td ltx_align_center">-</td>
<td id="S6.T1.5.5.5.5" class="ltx_td ltx_align_center">-</td>
<td id="S6.T1.5.5.5.6" class="ltx_td ltx_align_center">-</td>
<td id="S6.T1.5.5.5.7" class="ltx_td ltx_align_center ltx_border_r">-</td>
</tr>
<tr id="S6.T1.6.6.6" class="ltx_tr">
<th id="S6.T1.6.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">BL + DANN<sup id="S6.T1.6.6.6.1.1" class="ltx_sup"><math id="S6.T1.6.6.6.1.1.m1.1" class="ltx_Math" alttext="\ddagger" display="inline"><semantics id="S6.T1.6.6.6.1.1.m1.1a"><mo id="S6.T1.6.6.6.1.1.m1.1.1" xref="S6.T1.6.6.6.1.1.m1.1.1.cmml">‡</mo><annotation-xml encoding="MathML-Content" id="S6.T1.6.6.6.1.1.m1.1b"><ci id="S6.T1.6.6.6.1.1.m1.1.1.cmml" xref="S6.T1.6.6.6.1.1.m1.1.1">‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.6.6.6.1.1.m1.1c">\ddagger</annotation></semantics></math></sup>
</th>
<td id="S6.T1.6.6.6.2" class="ltx_td ltx_align_center ltx_border_t">93.9 ± 1.1</td>
<td id="S6.T1.6.6.6.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">91.7 ± 0.9</td>
<td id="S6.T1.6.6.6.4" class="ltx_td ltx_align_center ltx_border_t">85.2 ± 0.2</td>
<td id="S6.T1.6.6.6.5" class="ltx_td ltx_align_center ltx_border_t">79.4 ± 0.4</td>
<td id="S6.T1.6.6.6.6" class="ltx_td ltx_align_center ltx_border_t">92.3 ± 1.0</td>
<td id="S6.T1.6.6.6.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.4 ± 0.5</td>
</tr>
<tr id="S6.T1.7.7.7" class="ltx_tr">
<th id="S6.T1.7.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">BL + Real + DANN<sup id="S6.T1.7.7.7.1.1" class="ltx_sup"><math id="S6.T1.7.7.7.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S6.T1.7.7.7.1.1.m1.1a"><mo id="S6.T1.7.7.7.1.1.m1.1.1" xref="S6.T1.7.7.7.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S6.T1.7.7.7.1.1.m1.1b"><ci id="S6.T1.7.7.7.1.1.m1.1.1.cmml" xref="S6.T1.7.7.7.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.7.7.7.1.1.m1.1c">\dagger</annotation></semantics></math></sup>
</th>
<td id="S6.T1.7.7.7.2" class="ltx_td ltx_align_center">97.0 ± 1.8</td>
<td id="S6.T1.7.7.7.3" class="ltx_td ltx_align_center ltx_border_r">91.0 ± 0.6</td>
<td id="S6.T1.7.7.7.4" class="ltx_td ltx_align_center">85.2 ± 0.5</td>
<td id="S6.T1.7.7.7.5" class="ltx_td ltx_align_center">78.9 ± 0.8</td>
<td id="S6.T1.7.7.7.6" class="ltx_td ltx_align_center">92.8 ± 0.4</td>
<td id="S6.T1.7.7.7.7" class="ltx_td ltx_align_center ltx_border_r">96.4 ± 0.7</td>
</tr>
<tr id="S6.T1.8.8.8" class="ltx_tr">
<th id="S6.T1.8.8.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">BL + PADA <sup id="S6.T1.8.8.8.1.1" class="ltx_sup"><math id="S6.T1.8.8.8.1.1.m1.1" class="ltx_Math" alttext="\ddagger" display="inline"><semantics id="S6.T1.8.8.8.1.1.m1.1a"><mo id="S6.T1.8.8.8.1.1.m1.1.1" xref="S6.T1.8.8.8.1.1.m1.1.1.cmml">‡</mo><annotation-xml encoding="MathML-Content" id="S6.T1.8.8.8.1.1.m1.1b"><ci id="S6.T1.8.8.8.1.1.m1.1.1.cmml" xref="S6.T1.8.8.8.1.1.m1.1.1">‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.8.8.8.1.1.m1.1c">\ddagger</annotation></semantics></math></sup>
</th>
<td id="S6.T1.8.8.8.2" class="ltx_td ltx_align_center ltx_border_t">94.4 ± 0.5</td>
<td id="S6.T1.8.8.8.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">90.8 ± 1.2</td>
<td id="S6.T1.8.8.8.4" class="ltx_td ltx_align_center ltx_border_t">84.8 ± 0.2</td>
<td id="S6.T1.8.8.8.5" class="ltx_td ltx_align_center ltx_border_t">78.6 ± 0.4</td>
<td id="S6.T1.8.8.8.6" class="ltx_td ltx_align_center ltx_border_t">92.6 ± 0.3</td>
<td id="S6.T1.8.8.8.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.4 ± 0.5</td>
</tr>
<tr id="S6.T1.9.9.9" class="ltx_tr">
<th id="S6.T1.9.9.9.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">BL + Real + Model labels<sup id="S6.T1.9.9.9.1.1" class="ltx_sup"><math id="S6.T1.9.9.9.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S6.T1.9.9.9.1.1.m1.1a"><mo id="S6.T1.9.9.9.1.1.m1.1.1" xref="S6.T1.9.9.9.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S6.T1.9.9.9.1.1.m1.1b"><ci id="S6.T1.9.9.9.1.1.m1.1.1.cmml" xref="S6.T1.9.9.9.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.9.9.9.1.1.m1.1c">\dagger</annotation></semantics></math></sup>
</th>
<td id="S6.T1.9.9.9.2" class="ltx_td ltx_align_center">96.9 ± 1.9</td>
<td id="S6.T1.9.9.9.3" class="ltx_td ltx_align_center ltx_border_r">90.7 ± 1.0</td>
<td id="S6.T1.9.9.9.4" class="ltx_td ltx_align_center">84.6 ± 0.4</td>
<td id="S6.T1.9.9.9.5" class="ltx_td ltx_align_center">77.9 ± 0.7</td>
<td id="S6.T1.9.9.9.6" class="ltx_td ltx_align_center"><span id="S6.T1.9.9.9.6.1" class="ltx_text ltx_font_bold">93.0 ± 0.4</span></td>
<td id="S6.T1.9.9.9.7" class="ltx_td ltx_align_center ltx_border_r">96.6 ± 0.1</td>
</tr>
<tr id="S6.T1.10.10.10" class="ltx_tr">
<th id="S6.T1.10.10.10.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">BL + Real + PADA<sup id="S6.T1.10.10.10.1.1" class="ltx_sup"><math id="S6.T1.10.10.10.1.1.m1.1" class="ltx_Math" alttext="\ddagger" display="inline"><semantics id="S6.T1.10.10.10.1.1.m1.1a"><mo id="S6.T1.10.10.10.1.1.m1.1.1" xref="S6.T1.10.10.10.1.1.m1.1.1.cmml">‡</mo><annotation-xml encoding="MathML-Content" id="S6.T1.10.10.10.1.1.m1.1b"><ci id="S6.T1.10.10.10.1.1.m1.1.1.cmml" xref="S6.T1.10.10.10.1.1.m1.1.1">‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.10.10.10.1.1.m1.1c">\ddagger</annotation></semantics></math></sup>
</th>
<td id="S6.T1.10.10.10.2" class="ltx_td ltx_align_center">96.2 ± 3.1</td>
<td id="S6.T1.10.10.10.3" class="ltx_td ltx_align_center ltx_border_r">90.9 ± 1.9</td>
<td id="S6.T1.10.10.10.4" class="ltx_td ltx_align_center">84.7 ± 0.1</td>
<td id="S6.T1.10.10.10.5" class="ltx_td ltx_align_center">78.4 ± 0.2</td>
<td id="S6.T1.10.10.10.6" class="ltx_td ltx_align_center">92.4 ± 0.3</td>
<td id="S6.T1.10.10.10.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T1.10.10.10.7.1" class="ltx_text ltx_font_bold">96.9 ± 0.6</span></td>
</tr>
<tr id="S6.T1.15.15.21.6" class="ltx_tr">
<th id="S6.T1.15.15.21.6.1" class="ltx_td ltx_th ltx_th_row ltx_border_r ltx_border_t"></th>
<td id="S6.T1.15.15.21.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt" colspan="6">
<span id="S6.T1.15.15.21.6.2.1" class="ltx_ERROR undefined">\cellcolor</span>[HTML]EFEFEF<span id="S6.T1.15.15.21.6.2.2" class="ltx_text ltx_font_bold">Stress test</span>
</td>
</tr>
<tr id="S6.T1.15.15.22.7" class="ltx_tr">
<th id="S6.T1.15.15.22.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Baseline</th>
<td id="S6.T1.15.15.22.7.2" class="ltx_td ltx_align_center ltx_border_tt">-</td>
<td id="S6.T1.15.15.22.7.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt">94.1 ± 0.2</td>
<td id="S6.T1.15.15.22.7.4" class="ltx_td ltx_align_center ltx_border_tt"><span id="S6.T1.15.15.22.7.4.1" class="ltx_text ltx_font_bold">79.3 ± 0.2</span></td>
<td id="S6.T1.15.15.22.7.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S6.T1.15.15.22.7.5.1" class="ltx_text ltx_font_bold">72.5 ± 0.2</span></td>
<td id="S6.T1.15.15.22.7.6" class="ltx_td ltx_align_center ltx_border_tt">87.4 ± 0.3</td>
<td id="S6.T1.15.15.22.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_tt"><span id="S6.T1.15.15.22.7.7.1" class="ltx_text ltx_font_bold">92.2 ± 0.1</span></td>
</tr>
<tr id="S6.T1.11.11.11" class="ltx_tr">
<th id="S6.T1.11.11.11.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">BL + Real<sup id="S6.T1.11.11.11.1.1" class="ltx_sup"><math id="S6.T1.11.11.11.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S6.T1.11.11.11.1.1.m1.1a"><mo id="S6.T1.11.11.11.1.1.m1.1.1" xref="S6.T1.11.11.11.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S6.T1.11.11.11.1.1.m1.1b"><ci id="S6.T1.11.11.11.1.1.m1.1.1.cmml" xref="S6.T1.11.11.11.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.11.11.11.1.1.m1.1c">\dagger</annotation></semantics></math></sup>
</th>
<td id="S6.T1.11.11.11.2" class="ltx_td ltx_align_center">-</td>
<td id="S6.T1.11.11.11.3" class="ltx_td ltx_align_center ltx_border_r">93.5 ± 0.23</td>
<td id="S6.T1.11.11.11.4" class="ltx_td ltx_align_center">79.2 ± 0.1</td>
<td id="S6.T1.11.11.11.5" class="ltx_td ltx_align_center">72.1 ± 0.4</td>
<td id="S6.T1.11.11.11.6" class="ltx_td ltx_align_center">88.0 ± 0.1</td>
<td id="S6.T1.11.11.11.7" class="ltx_td ltx_align_center ltx_border_r"><span id="S6.T1.11.11.11.7.1" class="ltx_text ltx_font_bold">92.2 ± 0.1</span></td>
</tr>
<tr id="S6.T1.15.15.23.8" class="ltx_tr">
<th id="S6.T1.15.15.23.8.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">RRT (Global)</th>
<td id="S6.T1.15.15.23.8.2" class="ltx_td ltx_align_center">-</td>
<td id="S6.T1.15.15.23.8.3" class="ltx_td ltx_align_center ltx_border_r">-</td>
<td id="S6.T1.15.15.23.8.4" class="ltx_td ltx_align_center">76.1 ± 1.3</td>
<td id="S6.T1.15.15.23.8.5" class="ltx_td ltx_align_center">65.7 ± 2.3</td>
<td id="S6.T1.15.15.23.8.6" class="ltx_td ltx_align_center">85.4 ± 2.2</td>
<td id="S6.T1.15.15.23.8.7" class="ltx_td ltx_align_center ltx_border_r">90.6 ± 0.9</td>
</tr>
<tr id="S6.T1.12.12.12" class="ltx_tr">
<th id="S6.T1.12.12.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">BL + DANN<sup id="S6.T1.12.12.12.1.1" class="ltx_sup"><math id="S6.T1.12.12.12.1.1.m1.1" class="ltx_Math" alttext="\ddagger" display="inline"><semantics id="S6.T1.12.12.12.1.1.m1.1a"><mo id="S6.T1.12.12.12.1.1.m1.1.1" xref="S6.T1.12.12.12.1.1.m1.1.1.cmml">‡</mo><annotation-xml encoding="MathML-Content" id="S6.T1.12.12.12.1.1.m1.1b"><ci id="S6.T1.12.12.12.1.1.m1.1.1.cmml" xref="S6.T1.12.12.12.1.1.m1.1.1">‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.12.12.12.1.1.m1.1c">\ddagger</annotation></semantics></math></sup>
</th>
<td id="S6.T1.12.12.12.2" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S6.T1.12.12.12.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">93.4 ± 1.1</td>
<td id="S6.T1.12.12.12.4" class="ltx_td ltx_align_center ltx_border_t">78.7 ± 0.5</td>
<td id="S6.T1.12.12.12.5" class="ltx_td ltx_align_center ltx_border_t">71.6 ± 0.5</td>
<td id="S6.T1.12.12.12.6" class="ltx_td ltx_align_center ltx_border_t">87.9 ± 0.5</td>
<td id="S6.T1.12.12.12.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">91.3 ± 0.7</td>
</tr>
<tr id="S6.T1.13.13.13" class="ltx_tr">
<th id="S6.T1.13.13.13.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r">BL + Real + DANN<sup id="S6.T1.13.13.13.1.1" class="ltx_sup"><math id="S6.T1.13.13.13.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S6.T1.13.13.13.1.1.m1.1a"><mo id="S6.T1.13.13.13.1.1.m1.1.1" xref="S6.T1.13.13.13.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S6.T1.13.13.13.1.1.m1.1b"><ci id="S6.T1.13.13.13.1.1.m1.1.1.cmml" xref="S6.T1.13.13.13.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.13.13.13.1.1.m1.1c">\dagger</annotation></semantics></math></sup>
</th>
<td id="S6.T1.13.13.13.2" class="ltx_td ltx_align_center">-</td>
<td id="S6.T1.13.13.13.3" class="ltx_td ltx_align_center ltx_border_r">93.5 ± 0.3</td>
<td id="S6.T1.13.13.13.4" class="ltx_td ltx_align_center">79.1 ± 0.2</td>
<td id="S6.T1.13.13.13.5" class="ltx_td ltx_align_center">71.7 ± 0.2</td>
<td id="S6.T1.13.13.13.6" class="ltx_td ltx_align_center">87.9 ± 0.2</td>
<td id="S6.T1.13.13.13.7" class="ltx_td ltx_align_center ltx_border_r">92.1 ± 0.2</td>
</tr>
<tr id="S6.T1.14.14.14" class="ltx_tr">
<th id="S6.T1.14.14.14.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">BL + PADA<sup id="S6.T1.14.14.14.1.1" class="ltx_sup"><math id="S6.T1.14.14.14.1.1.m1.1" class="ltx_Math" alttext="\ddagger" display="inline"><semantics id="S6.T1.14.14.14.1.1.m1.1a"><mo id="S6.T1.14.14.14.1.1.m1.1.1" xref="S6.T1.14.14.14.1.1.m1.1.1.cmml">‡</mo><annotation-xml encoding="MathML-Content" id="S6.T1.14.14.14.1.1.m1.1b"><ci id="S6.T1.14.14.14.1.1.m1.1.1.cmml" xref="S6.T1.14.14.14.1.1.m1.1.1">‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.14.14.14.1.1.m1.1c">\ddagger</annotation></semantics></math></sup>
</th>
<td id="S6.T1.14.14.14.2" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="S6.T1.14.14.14.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S6.T1.14.14.14.3.1" class="ltx_text ltx_font_bold">94.2 ± 0.4</span></td>
<td id="S6.T1.14.14.14.4" class="ltx_td ltx_align_center ltx_border_t">79.2 ± 0.4</td>
<td id="S6.T1.14.14.14.5" class="ltx_td ltx_align_center ltx_border_t">72.3 ± 0.8</td>
<td id="S6.T1.14.14.14.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S6.T1.14.14.14.6.1" class="ltx_text ltx_font_bold">88.1 ± 0.1</span></td>
<td id="S6.T1.14.14.14.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S6.T1.14.14.14.7.1" class="ltx_text ltx_font_bold">92.2 ± 0.5</span></td>
</tr>
<tr id="S6.T1.15.15.15" class="ltx_tr">
<th id="S6.T1.15.15.15.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r">BL + Real + PADA<sup id="S6.T1.15.15.15.1.1" class="ltx_sup"><math id="S6.T1.15.15.15.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S6.T1.15.15.15.1.1.m1.1a"><mo id="S6.T1.15.15.15.1.1.m1.1.1" xref="S6.T1.15.15.15.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S6.T1.15.15.15.1.1.m1.1b"><ci id="S6.T1.15.15.15.1.1.m1.1.1.cmml" xref="S6.T1.15.15.15.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.15.15.15.1.1.m1.1c">\dagger</annotation></semantics></math></sup>
</th>
<td id="S6.T1.15.15.15.2" class="ltx_td ltx_align_center ltx_border_b">-</td>
<td id="S6.T1.15.15.15.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">92.9 ± 1</td>
<td id="S6.T1.15.15.15.4" class="ltx_td ltx_align_center ltx_border_b">78.9 ± 0.7</td>
<td id="S6.T1.15.15.15.5" class="ltx_td ltx_align_center ltx_border_b">71.9 ± 0.7</td>
<td id="S6.T1.15.15.15.6" class="ltx_td ltx_align_center ltx_border_b">87.8 ± 0.8</td>
<td id="S6.T1.15.15.15.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">91.9 ± 0.1</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="S6.T1.21.3.1" class="ltx_text" style="font-size:90%;">Table 1</span>: </span><span id="S6.T1.19.2" class="ltx_text" style="font-size:90%;">Performance on the validation and stress set. All networks trained on synthetic data except for <math id="S6.T1.18.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="S6.T1.18.1.m1.1b"><mo id="S6.T1.18.1.m1.1.1" xref="S6.T1.18.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="S6.T1.18.1.m1.1c"><ci id="S6.T1.18.1.m1.1.1.cmml" xref="S6.T1.18.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.18.1.m1.1d">\dagger</annotation></semantics></math> (labeled real images available at training time) and <math id="S6.T1.19.2.m2.1" class="ltx_Math" alttext="\ddagger" display="inline"><semantics id="S6.T1.19.2.m2.1b"><mo id="S6.T1.19.2.m2.1.1" xref="S6.T1.19.2.m2.1.1.cmml">‡</mo><annotation-xml encoding="MathML-Content" id="S6.T1.19.2.m2.1c"><ci id="S6.T1.19.2.m2.1.1.cmml" xref="S6.T1.19.2.m2.1.1">‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.19.2.m2.1d">\ddagger</annotation></semantics></math> (unlabelled real images available at training time). Best results are in bold. </span></figcaption>
</figure>
<section id="S6.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">What is the DD and ReID performance of the baseline, with and without real labeled images at training time?</h5>

<div id="S6.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S6.SS0.SSS0.Px1.p1.1" class="ltx_p">The baseline was trained in two different settings: one assuming that only synthetic data is available at training time (BL), and one assuming that a small sample of labeled images is available at training time (BL+Real).
As shown in <a href="#S6.T1" title="Table 1 ‣ 6 Results ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 1</span></a>, <span id="S6.SS0.SSS0.Px1.p1.1.1" class="ltx_text ltx_font_italic">on the DD task</span> BL achieves an average AUC of 92.1 ± 0.5 for synthetic images and of 93.4 ± 1.5 for real images.
However, we postulate that there is still a domain shift between the synthetic and the real data, since performance on the DD task improved when the network was exposed to the real domain during training (AUC=97.3 ± 2.2).</p>
</div>
<div id="S6.SS0.SSS0.Px1.p2" class="ltx_para">
<p id="S6.SS0.SSS0.Px1.p2.1" class="ltx_p">Delving deeper in the DD task, <span id="S6.SS0.SSS0.Px1.p2.1.1" class="ltx_text ltx_font_italic">the performance varies for different damage types on the synthetic dataset</span>, with higher AUC on Broken (100 ± 0.0) than Bent frames (81.5 ± 2). Bent frames are more challenging to detect since some frames (e.g., Cruiser) may include both straight and curved lines, and BBBicycles includes a range of both subtle and heavy damages. On the other hand, the visual features associated with broken frames are well defined and stable between different bike models.</p>
</div>
<div id="S6.SS0.SSS0.Px1.p3" class="ltx_para">
<p id="S6.SS0.SSS0.Px1.p3.1" class="ltx_p"><span id="S6.SS0.SSS0.Px1.p3.1.1" class="ltx_text ltx_font_italic">On the ReID task,</span> TransReI3D achieved a mAP of 85.3 ± 0.2 (BL and BL+Real) and a CMC-1 of 79.8 ± 0.5 (BL) and 79.4 ± 0.1 (BL+Real), with minor variations when exposed to real data during training. <a href="#S6.F3" title="Figure 3 ‣ What is the DD and ReID performance of the baseline, with and without real labeled images at training time? ‣ 6 Results ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 3</span></a> shows how TransReI3D is able to predict the correct ID and distinguish damage-induced variations from different setups of the same (or similar) bike models.</p>
</div>
<div id="S6.SS0.SSS0.Px1.p4" class="ltx_para">
<p id="S6.SS0.SSS0.Px1.p4.3" class="ltx_p">We further investigated the <span id="S6.SS0.SSS0.Px1.p4.3.1" class="ltx_text ltx_font_italic">effect of the background</span> on the ReID and DD performance. Specifically, we compared three choices of background: (i) HDRI images, as detailed in Section <a href="#S3" title="3 Dataset ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>; (ii) random selection from Places365 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite>, and (iii) a simple uniform background (see Appendix C for examples). On the DD task, all transfer scenarios (<math id="S6.SS0.SSS0.Px1.p4.1.m1.1" class="ltx_Math" alttext="\text{HDRI (BL)}\to\text{Real}" display="inline"><semantics id="S6.SS0.SSS0.Px1.p4.1.m1.1a"><mrow id="S6.SS0.SSS0.Px1.p4.1.m1.1.1" xref="S6.SS0.SSS0.Px1.p4.1.m1.1.1.cmml"><mtext id="S6.SS0.SSS0.Px1.p4.1.m1.1.1.2" xref="S6.SS0.SSS0.Px1.p4.1.m1.1.1.2a.cmml">HDRI (BL)</mtext><mo stretchy="false" id="S6.SS0.SSS0.Px1.p4.1.m1.1.1.1" xref="S6.SS0.SSS0.Px1.p4.1.m1.1.1.1.cmml">→</mo><mtext id="S6.SS0.SSS0.Px1.p4.1.m1.1.1.3" xref="S6.SS0.SSS0.Px1.p4.1.m1.1.1.3a.cmml">Real</mtext></mrow><annotation-xml encoding="MathML-Content" id="S6.SS0.SSS0.Px1.p4.1.m1.1b"><apply id="S6.SS0.SSS0.Px1.p4.1.m1.1.1.cmml" xref="S6.SS0.SSS0.Px1.p4.1.m1.1.1"><ci id="S6.SS0.SSS0.Px1.p4.1.m1.1.1.1.cmml" xref="S6.SS0.SSS0.Px1.p4.1.m1.1.1.1">→</ci><ci id="S6.SS0.SSS0.Px1.p4.1.m1.1.1.2a.cmml" xref="S6.SS0.SSS0.Px1.p4.1.m1.1.1.2"><mtext id="S6.SS0.SSS0.Px1.p4.1.m1.1.1.2.cmml" xref="S6.SS0.SSS0.Px1.p4.1.m1.1.1.2">HDRI (BL)</mtext></ci><ci id="S6.SS0.SSS0.Px1.p4.1.m1.1.1.3a.cmml" xref="S6.SS0.SSS0.Px1.p4.1.m1.1.1.3"><mtext id="S6.SS0.SSS0.Px1.p4.1.m1.1.1.3.cmml" xref="S6.SS0.SSS0.Px1.p4.1.m1.1.1.3">Real</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS0.SSS0.Px1.p4.1.m1.1c">\text{HDRI (BL)}\to\text{Real}</annotation></semantics></math>, <math id="S6.SS0.SSS0.Px1.p4.2.m2.1" class="ltx_Math" alttext="\text{ BG Places365}\to\text{Real}" display="inline"><semantics id="S6.SS0.SSS0.Px1.p4.2.m2.1a"><mrow id="S6.SS0.SSS0.Px1.p4.2.m2.1.1" xref="S6.SS0.SSS0.Px1.p4.2.m2.1.1.cmml"><mtext id="S6.SS0.SSS0.Px1.p4.2.m2.1.1.2" xref="S6.SS0.SSS0.Px1.p4.2.m2.1.1.2a.cmml"> BG Places365</mtext><mo stretchy="false" id="S6.SS0.SSS0.Px1.p4.2.m2.1.1.1" xref="S6.SS0.SSS0.Px1.p4.2.m2.1.1.1.cmml">→</mo><mtext id="S6.SS0.SSS0.Px1.p4.2.m2.1.1.3" xref="S6.SS0.SSS0.Px1.p4.2.m2.1.1.3a.cmml">Real</mtext></mrow><annotation-xml encoding="MathML-Content" id="S6.SS0.SSS0.Px1.p4.2.m2.1b"><apply id="S6.SS0.SSS0.Px1.p4.2.m2.1.1.cmml" xref="S6.SS0.SSS0.Px1.p4.2.m2.1.1"><ci id="S6.SS0.SSS0.Px1.p4.2.m2.1.1.1.cmml" xref="S6.SS0.SSS0.Px1.p4.2.m2.1.1.1">→</ci><ci id="S6.SS0.SSS0.Px1.p4.2.m2.1.1.2a.cmml" xref="S6.SS0.SSS0.Px1.p4.2.m2.1.1.2"><mtext id="S6.SS0.SSS0.Px1.p4.2.m2.1.1.2.cmml" xref="S6.SS0.SSS0.Px1.p4.2.m2.1.1.2"> BG Places365</mtext></ci><ci id="S6.SS0.SSS0.Px1.p4.2.m2.1.1.3a.cmml" xref="S6.SS0.SSS0.Px1.p4.2.m2.1.1.3"><mtext id="S6.SS0.SSS0.Px1.p4.2.m2.1.1.3.cmml" xref="S6.SS0.SSS0.Px1.p4.2.m2.1.1.3">Real</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS0.SSS0.Px1.p4.2.m2.1c">\text{ BG Places365}\to\text{Real}</annotation></semantics></math> and <math id="S6.SS0.SSS0.Px1.p4.3.m3.1" class="ltx_Math" alttext="\text{BG Uniform}\to\text{Real}" display="inline"><semantics id="S6.SS0.SSS0.Px1.p4.3.m3.1a"><mrow id="S6.SS0.SSS0.Px1.p4.3.m3.1.1" xref="S6.SS0.SSS0.Px1.p4.3.m3.1.1.cmml"><mtext id="S6.SS0.SSS0.Px1.p4.3.m3.1.1.2" xref="S6.SS0.SSS0.Px1.p4.3.m3.1.1.2a.cmml">BG Uniform</mtext><mo stretchy="false" id="S6.SS0.SSS0.Px1.p4.3.m3.1.1.1" xref="S6.SS0.SSS0.Px1.p4.3.m3.1.1.1.cmml">→</mo><mtext id="S6.SS0.SSS0.Px1.p4.3.m3.1.1.3" xref="S6.SS0.SSS0.Px1.p4.3.m3.1.1.3a.cmml">Real</mtext></mrow><annotation-xml encoding="MathML-Content" id="S6.SS0.SSS0.Px1.p4.3.m3.1b"><apply id="S6.SS0.SSS0.Px1.p4.3.m3.1.1.cmml" xref="S6.SS0.SSS0.Px1.p4.3.m3.1.1"><ci id="S6.SS0.SSS0.Px1.p4.3.m3.1.1.1.cmml" xref="S6.SS0.SSS0.Px1.p4.3.m3.1.1.1">→</ci><ci id="S6.SS0.SSS0.Px1.p4.3.m3.1.1.2a.cmml" xref="S6.SS0.SSS0.Px1.p4.3.m3.1.1.2"><mtext id="S6.SS0.SSS0.Px1.p4.3.m3.1.1.2.cmml" xref="S6.SS0.SSS0.Px1.p4.3.m3.1.1.2">BG Uniform</mtext></ci><ci id="S6.SS0.SSS0.Px1.p4.3.m3.1.1.3a.cmml" xref="S6.SS0.SSS0.Px1.p4.3.m3.1.1.3"><mtext id="S6.SS0.SSS0.Px1.p4.3.m3.1.1.3.cmml" xref="S6.SS0.SSS0.Px1.p4.3.m3.1.1.3">Real</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.SS0.SSS0.Px1.p4.3.m3.1c">\text{BG Uniform}\to\text{Real}</annotation></semantics></math>) achieved similar results (<a href="#S6.T1" title="Table 1 ‣ 6 Results ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 1</span></a>). HDRI slightly outperforms Places365: the latter contains a wider range of scenes, but the resulting blend is not as realistic as the proposed HDRI technique. On the ReID task, performance substantially drops when training on a uniform background, as the network does not learn to separate the bike from the background.</p>
</div>
<figure id="S6.F3" class="ltx_figure"><img src="/html/2304.07883/assets/x3.png" id="S6.F3.1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="528" height="205" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S6.F3.3.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S6.F3.4.2" class="ltx_text" style="font-size:90%;">Retrieval results (Top-5 images) for the BL network (ID and similarity scores).
The correct ID is retrieved despite the presence of missing parts (ID 15), bent (ID 15) or broken (ID 21) frame, deformed wheels (ID 21), and rust (ID 21).</span></figcaption>
</figure>
</section>
<section id="S6.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Is multi-tasking beneficial for damaged object re-identification?</h5>

<div id="S6.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S6.SS0.SSS0.Px2.p1.1" class="ltx_p">We compared TransReI3D against single-task ReID and DD networks – the former reduces to the original TransReID architecture, whereas the latter becomes a ViT-based multi-label classifier. As shown in <a href="#S6.T1" title="Table 1 ‣ 6 Results ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 1</span></a>, TransReI3D outperforms the single-task ReID architecture both in terms of mAP (85.3 ± 0.2 vs. 83.3 ± 1.2) and CMC (CMC-1 79.9 ± 0.4 vs. 77.0 ± 1.2). This is further confirmed by the performance of RTT (mAP 80.5 ± 1 vs. 85.3 ± 0.2). On the other hand, DD improves in the single-task setting on both real (97.5 ± 1.5) and synthetic (94.5 ± 0.5) images. A possible explanation is that the ReID task forces the network to take into account the entire bicycle, whereas for DD simpler, more localized visual cues are sufficient. Conversely, the ReID task can leverage the DD labels to learn visual properties invariant to the presence of damage.</p>
</div>
</section>
<section id="S6.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Are feature-level domain adaptation strategies helpful to reduce the synthetic-to-real gap?</h5>

<div id="S6.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S6.SS0.SSS0.Px3.p1.1" class="ltx_p">The BL results indicate that, at least for the DD task, a certain domain shift still exists. Besides low-level differences due to CGI, we postulate that this domain shift may be attributed to different reasons: on the one hand, few examples of damaged bikes are available; on the other hand, the synthetic dataset contains more bike models (for instance, most images in the Delft Bikes dataset are minor variations of a typical city bike). As detailed in Section <a href="#S5" title="5 Experimental settings ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, we have tested two techniques, DANN and PADA, focusing on the DD task.</p>
</div>
<div id="S6.SS0.SSS0.Px3.p2" class="ltx_para">
<p id="S6.SS0.SSS0.Px3.p2.1" class="ltx_p">When labeled real images are available during training, neither DANN (97.0 ± 1.8) nor PADA (96.2 ± 3.1) outperforms BL + Real (97.3 ± 2.2). On the other hand, if we assume that labels are not available at training time, both DANN (93.8 ± 1.1) and PADA (94.4±0.5) improved over BL (93.4 ± 1.5), but did not match the supervised setting (97.3 ± 2.2). On the ReID task, domain adaptation slightly hurts the performance in terms of CMC-1, bearing however in mind that this task is evaluated only on synthetic images. t-SNE plots of the [<span id="S6.SS0.SSS0.Px3.p2.1.1" class="ltx_text ltx_font_italic">cls</span>] token extracted from the backbone (Appendix C) show only partial overlap between the real and synthetic domains. Saliency (attention) maps generated following the approach in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> highlight how the network correctly focused its attention on the bike frame (and occasionally the wheels) (<a href="#A3.F22" title="Figure 22 ‣ C.3 Additional explainability and t-SNE plot ‣ Appendix C Additional results ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 22</span></a>). Different training regimes consistently yield similar visual keys (Appendix C).</p>
</div>
</section>
<section id="S6.SS0.SSS0.Px4" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">How does the network generalize to previously unseen bike models?</h5>

<div id="S6.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="S6.SS0.SSS0.Px4.p1.1" class="ltx_p">Overall, the DD task generalizes well to previously unseen models, while performance is more dependent on the specific type of damage. When training on synthetic data alone (BL), we observed an increase in performance for the DD task from 92.1 ± 0.2 to 94.1 ± 0.2 (<a href="#S6.T1" title="Table 1 ‣ 6 Results ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 1</span></a>). Again, forcing the network to improve on real images lowers the performance on synthetic images for all strategies but BL + PADA (94.2 ± 0.4). However, the latter incorporates an additional bike model classification task, which may help TransReI3D to better generalize to previously unseen models. On the other hand, in the ReID task both TransReI3D and RRT struggle to generalize to completely novel bike models, with a moderate decrease in performance both in terms of mAP (79.3±0.1 vs. 85.3±0.2) and CMC-1 (72.5±0.2 vs. 79.8±0.5).</p>
</div>
<figure id="S6.F4" class="ltx_figure"><img src="/html/2304.07883/assets/x4.png" id="S6.F4.1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="138" height="138" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S6.F4.5.2.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S6.F4.3.2.1" class="ltx_text" style="font-size:90%;">Attention maps of TransReI3D for BL + REAL + DANN, with Bent frame labels (y) and predictions (<math id="S6.F4.3.2.1.m1.1" class="ltx_Math" alttext="\hat{y}" display="inline"><semantics id="S6.F4.3.2.1.m1.1b"><mover accent="true" id="S6.F4.3.2.1.m1.1.1" xref="S6.F4.3.2.1.m1.1.1.cmml"><mi id="S6.F4.3.2.1.m1.1.1.2" xref="S6.F4.3.2.1.m1.1.1.2.cmml">y</mi><mo id="S6.F4.3.2.1.m1.1.1.1" xref="S6.F4.3.2.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="S6.F4.3.2.1.m1.1c"><apply id="S6.F4.3.2.1.m1.1.1.cmml" xref="S6.F4.3.2.1.m1.1.1"><ci id="S6.F4.3.2.1.m1.1.1.1.cmml" xref="S6.F4.3.2.1.m1.1.1.1">^</ci><ci id="S6.F4.3.2.1.m1.1.1.2.cmml" xref="S6.F4.3.2.1.m1.1.1.2">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.F4.3.2.1.m1.1d">\hat{y}</annotation></semantics></math>). </span></figcaption>
</figure>
</section>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusions</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">In this work, we introduced the novel task of damaged object re-identification. As a benchmark for this task, we introduced the synthetic BBBicycles dataset which contains paired images of the same bike with and without damages. As a baseline, we proposed TransReI3D, a multi-task tranformer-based architecture for joint DD and ReID. Experimental results showed how the DD task improves performance on the ReID task, but not viceversa.
The main limitation of the present work is the lack of real paired images of bikes, before and after damage; for this reason, only the DD task was analyzed for real images. As collecting such a dataset would be prohibitively expensive, an option to be explored is simulation, e.g., through data augmentation or generative models. Given the novelty of the task, there is ample room for future expansion in several directions. First, concerning the ReID task, the ability to generalize to previously unseen models should be improved. Experiments should also be extended to include more traditional convolutional architectures. Second, techniques for bridging the synthetic-to-real gap could be further investigated, e.g. by looking at the few-shot and partial/universal domain adaptation literature. Third, segmentation could be leveraged to improve foreground/background differentiation.
Finally, other tasks could be explored using the proposed pipeline and the collected 3D models in combination with rendered images, e.g., cross-modal image retrieval <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>, segmentation, and 3D part recognition <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite>.</p>
</div>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">The authors gratefully acknowledge the financial support of Reale Mutua Assicurazioni.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span id="bib.bib1.1.1" class="ltx_text" style="font-size:90%;">
Blender.
</span>
</span>
<span class="ltx_bibblock"><a href="hhttps://www.blender.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">hhttps://www.blender.org/</a><span id="bib.bib1.2.1" class="ltx_text" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib1.3.1" class="ltx_text" style="font-size:90%;">Accessed: 2022-08-29.
</span>
</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text" style="font-size:90%;">
Lily surface scraper.
</span>
</span>
<span class="ltx_bibblock"><a target="_blank" href="https://github.com/eliemichel/LilySurfaceScraper" title="" class="ltx_ref ltx_url ltx_font_typewriter" style="font-size:90%;">https://github.com/eliemichel/LilySurfaceScraper</a><span id="bib.bib2.2.1" class="ltx_text" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib2.3.1" class="ltx_text" style="font-size:90%;">Accessed: 2022-08-29.
</span>
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text" style="font-size:90%;">
Giuseppe Amato, Fabio Carrara, Fabrizio Falchi, Claudio Gennaro, and Lucia
Vadicamo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.2.1" class="ltx_text" style="font-size:90%;">Large-scale instance-level image retrieval.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib3.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Information Processing &amp; Management</span><span id="bib.bib3.4.2" class="ltx_text" style="font-size:90%;">, 57(6):102100, 2020.
</span>
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span id="bib.bib4.1.1" class="ltx_text" style="font-size:90%;">
Zhangjie Cao, Lijia Ma, Mingsheng Long, and Jianmin Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.2.1" class="ltx_text" style="font-size:90%;">Partial adversarial domain adaptation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib4.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib4.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the European Conference on Computer Vision
(ECCV)</span><span id="bib.bib4.5.3" class="ltx_text" style="font-size:90%;">, pages 135–150, 2018.
</span>
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span id="bib.bib5.1.1" class="ltx_text" style="font-size:90%;">
A. X. Chang, T. A. Funkhouser, L. J. Guibas, P. Hanrahan, Q. X. Huang, Z. Li,
S. Savarese, M. Savva, S. Song, H. Su, J. Xiao, L. Yi, and F. Yu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.2.1" class="ltx_text" style="font-size:90%;">Shapenet: An information-rich 3D model repository.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib5.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint: 1512.03012</span><span id="bib.bib5.4.2" class="ltx_text" style="font-size:90%;">, 2015.
</span>
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text" style="font-size:90%;">
Hila Chefer, Shir Gur, and Lior Wolf.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.2.1" class="ltx_text" style="font-size:90%;">Generic attention-model explainability for interpreting bi-modal and
encoder-decoder transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib6.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib6.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib6.5.3" class="ltx_text" style="font-size:90%;">, pages 397–406, 2021.
</span>
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span id="bib.bib7.1.1" class="ltx_text" style="font-size:90%;">
Wei Chen, Yu Liu, Weiping Wang, Erwin Bakker, Theodoros Georgiou, Paul Fieguth,
Li Liu, and Michael S Lew.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.2.1" class="ltx_text" style="font-size:90%;">Deep image retrieval: A survey.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib7.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2101.11282</span><span id="bib.bib7.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text" style="font-size:90%;">
J. Courbon, Y. Mezouar, N. Guenard, and P. Martinet.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.2.1" class="ltx_text" style="font-size:90%;">Vision-based navigation of unmanned aerial vehicles.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib8.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Control Engineering Practice</span><span id="bib.bib8.4.2" class="ltx_text" style="font-size:90%;">, 18:7:789–799, 2010.
</span>
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text" style="font-size:90%;">
Rita Cucchiara and Matteo Fabbri.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.2.1" class="ltx_text" style="font-size:90%;">Fine-grained human analysis under occlusions and perspective
constraints in multimedia surveillance.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib9.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ACM Transactions on Multimedia Computing, Communications, and
Applications (TOMM)</span><span id="bib.bib9.4.2" class="ltx_text" style="font-size:90%;">, 18(1s):1–23, 2022.
</span>
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text" style="font-size:90%;">
C. R. d. Souza, A. Gaidon, Y. Cabon, , and A. M. Lopez.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.2.1" class="ltx_text" style="font-size:90%;">Procedural generation of videos to train deep action recognition
networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib10.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib10.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition</span><span id="bib.bib10.5.3" class="ltx_text" style="font-size:90%;">,
pages 2594–2604, 2017.
</span>
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text" style="font-size:90%;">
Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.2.1" class="ltx_text" style="font-size:90%;">Imagenet: A large-scale hierarchical image database.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib11.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib11.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2009 IEEE conference on computer vision and pattern
recognition</span><span id="bib.bib11.5.3" class="ltx_text" style="font-size:90%;">, pages 248–255. Ieee, 2009.
</span>
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text" style="font-size:90%;">
Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, Dirk Weissenborn,
Xiaohua Zhai, Thomas Unterthiner, Mostafa Dehghani, Matthias Minderer, Georg
Heigold, Sylvain Gelly, Jakob Uszkoreit, and Neil Houlsby.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.2.1" class="ltx_text" style="font-size:90%;">An image is worth 16x16 words: Transformers for image recognition at
scale.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib12.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib12.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the International Conference on Learning
Representations (ICLR)</span><span id="bib.bib12.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text" style="font-size:90%;">
N. Dvornik, J. Mairal, and C. Schmid.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.2.1" class="ltx_text" style="font-size:90%;">Modeling visual context is key to augmenting object detection
datasets.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib13.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib13.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</span><span id="bib.bib13.5.3" class="ltx_text" style="font-size:90%;">, pages 375–391,
2018.
</span>
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span id="bib.bib14.1.1" class="ltx_text" style="font-size:90%;">
Matteo Fabbri, Guillem Brasó, Gianluca Maugeri, Orcun Cetintas, Riccardo
Gasparini, Aljoša Ošep, Simone Calderara, Laura Leal-Taixé,
and Rita Cucchiara.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.2.1" class="ltx_text" style="font-size:90%;">MOTSynth: How can synthetic data help pedestrian detection and
tracking?
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib14.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib14.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib14.5.3" class="ltx_text" style="font-size:90%;">, pages 10849–10859, 2021.
</span>
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text" style="font-size:90%;">
Yaroslav Ganin, Evgeniya Ustinova, Hana Ajakan, Pascal Germain, Hugo
Larochelle, François Laviolette, Mario Marchand, and Victor Lempitsky.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.2.1" class="ltx_text" style="font-size:90%;">Domain-adversarial training of neural networks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib15.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">The journal of machine learning research</span><span id="bib.bib15.4.2" class="ltx_text" style="font-size:90%;">, 17(1):2096–2030,
2016.
</span>
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span id="bib.bib16.1.1" class="ltx_text" style="font-size:90%;">
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.2.1" class="ltx_text" style="font-size:90%;">Delving deep into rectifiers: Surpassing human-level performance on
imagenet classification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib16.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib16.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE international conference on computer
vision</span><span id="bib.bib16.5.3" class="ltx_text" style="font-size:90%;">, pages 1026–1034, 2015.
</span>
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text" style="font-size:90%;">
Shuting He, Hao Luo, Pichao Wang, Fan Wang, Hao Li, and Wei Jiang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.2.1" class="ltx_text" style="font-size:90%;">Transreid: Transformer-based object re-identification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib17.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib17.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib17.5.3" class="ltx_text" style="font-size:90%;">, pages 15013–15022, 2021.
</span>
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text" style="font-size:90%;">
Christof Henkel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.2.1" class="ltx_text" style="font-size:90%;">Efficient large-scale image retrieval with deep feature orthogonality
and hybrid-swin-transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib18.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2110.03786</span><span id="bib.bib18.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span id="bib.bib19.1.1" class="ltx_text" style="font-size:90%;">
Yan Huang, Qiang Wu, JingSong Xu, Yi Zhong, and ZhaoXiang Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.2.1" class="ltx_text" style="font-size:90%;">Clothing status awareness for long-term person re-identification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib19.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib19.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib19.5.3" class="ltx_text" style="font-size:90%;">, pages 11895–11904, 2021.
</span>
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span id="bib.bib20.1.1" class="ltx_text" style="font-size:90%;">
Longlong Jing, Elahe Vahdani, Jiaxing Tan, and Yingli Tian.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.2.1" class="ltx_text" style="font-size:90%;">Cross-modal center loss for 3d cross-modal retrieval.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib20.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib20.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib20.5.3" class="ltx_text" style="font-size:90%;">, pages 3142–3151, 2021.
</span>
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text" style="font-size:90%;">
Amlan Kar, Aayush Prakash, Ming-Yu Liu, Eric Cameracci, Justin Yuan, Matt
Rusiniak, David Acuna, A. Torralba, and S. Fidler.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.2.1" class="ltx_text" style="font-size:90%;">Meta-Sim: Learning to generate synthetic datasets.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib21.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">2019 IEEE/CVF International Conference on Computer Vision
(ICCV)</span><span id="bib.bib21.4.2" class="ltx_text" style="font-size:90%;">, pages 4550–4559, 2019.
</span>
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text" style="font-size:90%;">
Osman Semih Kayhan, Bart Vredebregt, and Jan C van Gemert.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.2.1" class="ltx_text" style="font-size:90%;">Hallucination in object detection—a study in visual part
verification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib22.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib22.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2021 IEEE International Conference on Image Processing
(ICIP)</span><span id="bib.bib22.5.3" class="ltx_text" style="font-size:90%;">, pages 2234–2238. IEEE, 2021.
</span>
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text" style="font-size:90%;">
Salman Khan, Muzammal Naseer, Munawar Hayat, Syed Waqas Zamir, Fahad Shahbaz
Khan, and Mubarak Shah.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.2.1" class="ltx_text" style="font-size:90%;">Transformers in vision: A survey.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib23.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">ACM Computing Surveys (CSUR)</span><span id="bib.bib23.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span id="bib.bib24.1.1" class="ltx_text" style="font-size:90%;">
Sultan Daud Khan and Habib Ullah.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.2.1" class="ltx_text" style="font-size:90%;">A survey of advances in vision-based vehicle re-identification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib24.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Computer Vision and Image Understanding</span><span id="bib.bib24.4.2" class="ltx_text" style="font-size:90%;">, 182:50–63, 2019.
</span>
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span id="bib.bib25.1.1" class="ltx_text" style="font-size:90%;">
M. Khodabandeh, H. R. V. Joze, I. Zharkov, and V. Pradeep.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.2.1" class="ltx_text" style="font-size:90%;">DIY human action dataset generation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib25.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib25.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE/CVF Conference on Computer Vision and Pattern
Recognition Workshops</span><span id="bib.bib25.5.3" class="ltx_text" style="font-size:90%;">, page 1529–152910, 2018.
</span>
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span id="bib.bib26.1.1" class="ltx_text" style="font-size:90%;">
Jun Li, Bo Yang, Wankou Yang, Changyin Sun, and Hong Zhang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.2.1" class="ltx_text" style="font-size:90%;">When deep meets shallow: subspace-based multi-view fusion for
instance-level image retrieval.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib26.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib26.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2018 IEEE International Conference on Robotics and
Biomimetics (ROBIO)</span><span id="bib.bib26.5.3" class="ltx_text" style="font-size:90%;">, pages 486–492. IEEE, 2018.
</span>
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span id="bib.bib27.1.1" class="ltx_text" style="font-size:90%;">
Pei Li, Bingyu Shen, and Weishan Dong.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.2.1" class="ltx_text" style="font-size:90%;">An anti-fraud system for car insurance claim based on visual
evidence.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib27.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:1804.11207</span><span id="bib.bib27.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span id="bib.bib28.1.1" class="ltx_text" style="font-size:90%;">
Wei Li, Rui Zhao, Tong Xiao, and Xiaogang Wang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.2.1" class="ltx_text" style="font-size:90%;">Deepreid: Deep filter pairing neural network for person
re-identification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib28.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib28.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision (CVPR)</span><span id="bib.bib28.5.3" class="ltx_text" style="font-size:90%;">, 2014.
</span>
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span id="bib.bib29.1.1" class="ltx_text" style="font-size:90%;">
Shengcai Liao and Ling Shao.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.2.1" class="ltx_text" style="font-size:90%;">Transmatcher: Deep image matching through transformers for
generalizable person re-identification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib29.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib29.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Annual Conference on Neural Information Processing Systems
(NeurIPS)</span><span id="bib.bib29.5.3" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span id="bib.bib30.1.1" class="ltx_text" style="font-size:90%;">
Hongye Liu, Yonghong Tian, Yaowei Wang, Lu Pang, and Tiejun Huang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.2.1" class="ltx_text" style="font-size:90%;">Deep relative distance learning: Tell the difference between similar
vehicles.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib30.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib30.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition</span><span id="bib.bib30.5.3" class="ltx_text" style="font-size:90%;">, pages 2167–2175, 2016.
</span>
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span id="bib.bib31.1.1" class="ltx_text" style="font-size:90%;">
Xinchen Liu, Wu Liu, Tao Mei, and Huadong Ma.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.2.1" class="ltx_text" style="font-size:90%;">Provid: Progressive and multimodal vehicle reidentification for
large-scale urban surveillance.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib31.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Transactions on Multimedia</span><span id="bib.bib31.4.2" class="ltx_text" style="font-size:90%;">, 20(3):645–658, 2017.
</span>
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span id="bib.bib32.1.1" class="ltx_text" style="font-size:90%;">
Carlo Masone and Barbara Caputo.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.2.1" class="ltx_text" style="font-size:90%;">A survey on deep visual place recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib32.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Access</span><span id="bib.bib32.4.2" class="ltx_text" style="font-size:90%;">, 9:19516–19547, 2021.
</span>
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span id="bib.bib33.1.1" class="ltx_text" style="font-size:90%;">
N. Mayer, E. Ilg, P. Hausser, P. Fischer, D. Cremers, A. Dosovitskiy, and T.
Brox.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.2.1" class="ltx_text" style="font-size:90%;">A large dataset to train convolutional networks for disparity,
optical flow, and scene flow estimation.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib33.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib33.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition</span><span id="bib.bib33.5.3" class="ltx_text" style="font-size:90%;">,
2015.
</span>
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span id="bib.bib34.1.1" class="ltx_text" style="font-size:90%;">
J. McCormac, A. Handa, S. Leutenegger, , and A. J. Davison.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.2.1" class="ltx_text" style="font-size:90%;">Scenenet RGB-D: Can 5m synthetic images beat generic imagenet
pre-training on indoor segmentation?
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib34.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib34.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE International Conference on Computer Vision</span><span id="bib.bib34.5.3" class="ltx_text" style="font-size:90%;">, pages
2697–2706, 2017.
</span>
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span id="bib.bib35.1.1" class="ltx_text" style="font-size:90%;">
Lia Morra and Fabrizio Lamberti.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.2.1" class="ltx_text" style="font-size:90%;">Benchmarking unsupervised near-duplicate image detection.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib35.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Expert Systems with Applications</span><span id="bib.bib35.4.2" class="ltx_text" style="font-size:90%;">, 135:313–326, 2019.
</span>
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span id="bib.bib36.1.1" class="ltx_text" style="font-size:90%;">
L. Morra, F. Manigrasso, and F. Lamberti.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.2.1" class="ltx_text" style="font-size:90%;">SoccER: Computer graphics meets sports analytics for soccer event
recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib36.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">SoftwareX</span><span id="bib.bib36.4.2" class="ltx_text" style="font-size:90%;">, 12:100612, 2020.
</span>
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span id="bib.bib37.1.1" class="ltx_text" style="font-size:90%;">
S. I. Nikolenko.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.2.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Synthetic Data for Deep Learning</span><span id="bib.bib37.3.2" class="ltx_text" style="font-size:90%;">.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib37.4.1" class="ltx_text" style="font-size:90%;">Springer, 2021.
</span>
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span id="bib.bib38.1.1" class="ltx_text" style="font-size:90%;">
X. Peng, B. Sun, K. Ali, and K. Saenko.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.2.1" class="ltx_text" style="font-size:90%;">Learning deep object detectors from 3D models.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib38.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib38.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE International Conference on Computer Vision</span><span id="bib.bib38.5.3" class="ltx_text" style="font-size:90%;">, pages
1278–1286, 2015.
</span>
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span id="bib.bib39.1.1" class="ltx_text" style="font-size:90%;">
Yifan Peng, Qingyu Chen, and Zhiyong Lu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.2.1" class="ltx_text" style="font-size:90%;">An empirical study of multi-task learning on bert for biomedical text
mining.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib39.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib39.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 19th SIGBioMed Workshop on Biomedical
Language Processing</span><span id="bib.bib39.5.3" class="ltx_text" style="font-size:90%;">, pages 205–214, 2020.
</span>
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock"><span id="bib.bib40.1.1" class="ltx_text" style="font-size:90%;">
E. Perot, M. Jaritz, M. Toromanoff, and R. d. Charette.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.2.1" class="ltx_text" style="font-size:90%;">End-to-end driving in a realistic racing game with deep reinforcement
learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib40.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib40.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Conference on Computer Vision and Pattern Recognition
Workshops</span><span id="bib.bib40.5.3" class="ltx_text" style="font-size:90%;">, pages 474–475, 2017.
</span>
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock"><span id="bib.bib41.1.1" class="ltx_text" style="font-size:90%;">
Lyle Regenwetter, Brent Curry, and Faez Ahmed.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.2.1" class="ltx_text" style="font-size:90%;">BIKED: A dataset for computational bicycle design with machine
learning benchmarks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib41.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Journal of Mechanical Design</span><span id="bib.bib41.4.2" class="ltx_text" style="font-size:90%;">, 144(3), 2022.
</span>
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock"><span id="bib.bib42.1.1" class="ltx_text" style="font-size:90%;">
V. Vineet S. R. Richter, Stefan Roth, and Vladlen Koltun.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.2.1" class="ltx_text" style="font-size:90%;">Playing for data: Ground truth from computer games.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib42.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib42.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</span><span id="bib.bib42.5.3" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock"><span id="bib.bib43.1.1" class="ltx_text" style="font-size:90%;">
P. Schneider and G. Schneider.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.2.1" class="ltx_text" style="font-size:90%;">De novo design at the edge of chaos.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib43.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">Journal of Medicinal Chemistry</span><span id="bib.bib43.4.2" class="ltx_text" style="font-size:90%;">, 59:9:4077–4086, 2016.
</span>
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock"><span id="bib.bib44.1.1" class="ltx_text" style="font-size:90%;">
Charu Sharma, Siddhant R Kapil, and David Chapman.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.2.1" class="ltx_text" style="font-size:90%;">Person re-identification with a locally aware transformer.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib44.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2106.03720</span><span id="bib.bib44.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock"><span id="bib.bib45.1.1" class="ltx_text" style="font-size:90%;">
Fei Shen, Yi Xie, Jianqing Zhu, Xiaobin Zhu, and Huanqiang Zeng.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.2.1" class="ltx_text" style="font-size:90%;">Git: Graph interactive transformer for vehicle re-identification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib45.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2107.05475</span><span id="bib.bib45.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock"><span id="bib.bib46.1.1" class="ltx_text" style="font-size:90%;">
Ashish Shrivastava, Tomas Pfister, Oncel Tuzel, J. Susskind, Wenda Wang, and
Russ Webb.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.2.1" class="ltx_text" style="font-size:90%;">Learning from simulated and unsupervised images through adversarial
training.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib46.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">2017 IEEE Conference on Computer Vision and Pattern Recognition
(CVPR)</span><span id="bib.bib46.4.2" class="ltx_text" style="font-size:90%;">, pages 2242–2251, 2017.
</span>
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock"><span id="bib.bib47.1.1" class="ltx_text" style="font-size:90%;">
Xiujun Shu, Ge Li, Xiao Wang, Weijian Ruan, and Qi Tian.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.2.1" class="ltx_text" style="font-size:90%;">Semantic-guided pixel sampling for cloth-changing person
re-identification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib47.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE Signal Processing Letters</span><span id="bib.bib47.4.2" class="ltx_text" style="font-size:90%;">, 28:1365–1369, 2021.
</span>
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock"><span id="bib.bib48.1.1" class="ltx_text" style="font-size:90%;">
P. Solovev, V. Aliev, P. Ostyakov, G. Sterkin, E. Logacheva, S. Troeshestov, R.
Suvorov, A. Mashikhin, O. Khomenko, and S. I. Nikolenko.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.2.1" class="ltx_text" style="font-size:90%;">Learning state representations in complex systems with multimodal
data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib48.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint: 1811.11067</span><span id="bib.bib48.4.2" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock"><span id="bib.bib49.1.1" class="ltx_text" style="font-size:90%;">
Fuwen Tan, Jiangbo Yuan, and Vicente Ordonez.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.2.1" class="ltx_text" style="font-size:90%;">Instance-level image retrieval using reranking transformers.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib49.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib49.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision (ICCV)</span><span id="bib.bib49.5.3" class="ltx_text" style="font-size:90%;">, pages 12105–12115, 2021.
</span>
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock"><span id="bib.bib50.1.1" class="ltx_text" style="font-size:90%;">
Zheng Tang, Milind Naphade, Stan Birchfield, Jonathan Tremblay, William Hodge,
Ratnesh Kumar, Shuo Wang, and Xiaodong Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.2.1" class="ltx_text" style="font-size:90%;">Pamtri: Pose-aware multi-task learning for vehicle re-identification
using highly randomized synthetic data.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib50.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib50.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib50.5.3" class="ltx_text" style="font-size:90%;">, pages 211–220, 2019.
</span>
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock"><span id="bib.bib51.1.1" class="ltx_text" style="font-size:90%;">
Josh Tobin, Rachel Fong, Alex Ray, Jonas Schneider, Wojciech Zaremba, and
Pieter Abbeel.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.2.1" class="ltx_text" style="font-size:90%;">Domain randomization for transferring deep neural networks from
simulation to the real world.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib51.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib51.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">2017 IEEE/RSJ international conference on intelligent robots
and systems (IROS)</span><span id="bib.bib51.5.3" class="ltx_text" style="font-size:90%;">, pages 23–30. IEEE, 2017.
</span>
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock"><span id="bib.bib52.1.1" class="ltx_text" style="font-size:90%;">
J. Tremblay, B. Sundaralingam T. To, Y. Xiang, D. Fox, and S. T. Birchfield.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.2.1" class="ltx_text" style="font-size:90%;">Deep object pose estimation for semantic robotic grasping of
household objects.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib52.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib52.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Conference on Robot Learning</span><span id="bib.bib52.5.3" class="ltx_text" style="font-size:90%;">, 2018.
</span>
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock"><span id="bib.bib53.1.1" class="ltx_text" style="font-size:90%;">
Mikaela Angelina Uy, Jingwei Huang, Minhyuk Sung, Tolga Birdal, and Leonidas
Guibas.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.2.1" class="ltx_text" style="font-size:90%;">Deformation-aware 3d model embedding and retrieval.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib53.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib53.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">European Conference on Computer Vision</span><span id="bib.bib53.5.3" class="ltx_text" style="font-size:90%;">, pages 397–413.
Springer, 2020.
</span>
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock"><span id="bib.bib54.1.1" class="ltx_text" style="font-size:90%;">
W. Y. Wan and D. Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.2.1" class="ltx_text" style="font-size:90%;">That’s so annoying!!!: A lexical and frame-semantic embedding based
data augmentation approach to automatic categorization of annoying behaviors
using petpeeve tweets.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib54.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib54.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Empirical Methods in Natural Language Processing</span><span id="bib.bib54.5.3" class="ltx_text" style="font-size:90%;">, pages
2557–2563, 2015.
</span>
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock"><span id="bib.bib55.1.1" class="ltx_text" style="font-size:90%;">
Q. Wang, J. Gao, W. Lin, and Y. Yuan.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.2.1" class="ltx_text" style="font-size:90%;">Learning from synthetic data for crowd counting in the wild.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib55.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib55.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE/CVF Conference on Computer Vision and Pattern
Recognition</span><span id="bib.bib55.5.3" class="ltx_text" style="font-size:90%;">, pages 8190–8199, 2019.
</span>
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock"><span id="bib.bib56.1.1" class="ltx_text" style="font-size:90%;">
Longhui Wei, Shiliang Zhang, Wen Gao, and Qi Tian.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.2.1" class="ltx_text" style="font-size:90%;">Person transfer gan to bridge domain gap for person
re-identification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib56.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib56.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE conference on computer vision and
pattern recognition</span><span id="bib.bib56.5.3" class="ltx_text" style="font-size:90%;">, pages 79–88, 2018.
</span>
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock"><span id="bib.bib57.1.1" class="ltx_text" style="font-size:90%;">
Cameron R Wolfe and Keld T Lundgaard.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.2.1" class="ltx_text" style="font-size:90%;">Exceeding the limits of visual-linguistic multi-task learning.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib57.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2107.13054</span><span id="bib.bib57.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock"><span id="bib.bib58.1.1" class="ltx_text" style="font-size:90%;">
Chun-Han Yao, Wei-Chih Hung, Varun Jampani, and Ming-Hsuan Yang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.2.1" class="ltx_text" style="font-size:90%;">Discovering 3d parts from image collections.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib58.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib58.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE/CVF International Conference on
Computer Vision</span><span id="bib.bib58.5.3" class="ltx_text" style="font-size:90%;">, pages 12981–12990, 2021.
</span>
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock"><span id="bib.bib59.1.1" class="ltx_text" style="font-size:90%;">
Dominik Zapletal and Adam Herout.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.2.1" class="ltx_text" style="font-size:90%;">Vehicle re-identification for automatic video traffic surveillance.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib59.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib59.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE Conference on Computer Vision and
Pattern Recognition Workshops</span><span id="bib.bib59.5.3" class="ltx_text" style="font-size:90%;">, pages 25–31, 2016.
</span>
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock"><span id="bib.bib60.1.1" class="ltx_text" style="font-size:90%;">
Guowen Zhang, Pingping Zhang, Jinqing Qi, and Huchuan Lu.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.2.1" class="ltx_text" style="font-size:90%;">HAT: Hierarchical aggregation transformers for person
re-identification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib60.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib60.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the 29th ACM International Conference on
Multimedia</span><span id="bib.bib60.5.3" class="ltx_text" style="font-size:90%;">, pages 516–525, 2021.
</span>
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock"><span id="bib.bib61.1.1" class="ltx_text" style="font-size:90%;">
Y. Zhang, W. Qiu, Q. Chen, X. C. Hu, and A. L. Yuille.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.2.1" class="ltx_text" style="font-size:90%;">Unrealstereo: A synthetic dataset for analyzing stereo vision.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib61.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint: 1612.04647</span><span id="bib.bib61.4.2" class="ltx_text" style="font-size:90%;">, 2016.
</span>
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock"><span id="bib.bib62.1.1" class="ltx_text" style="font-size:90%;">
Chuanxia Zheng, Tat-Jen Cham, and Jianfei Cai.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.2.1" class="ltx_text" style="font-size:90%;">T2net: Synthetic-to-realistic translation for solving single-image
depth estimation tasks.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib62.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib62.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the European Conference on Computer Vision
(ECCV)</span><span id="bib.bib62.5.3" class="ltx_text" style="font-size:90%;">, pages 767–783, 2018.
</span>
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock"><span id="bib.bib63.1.1" class="ltx_text" style="font-size:90%;">
Liang Zheng, Liyue Shen, Lu Tian, Shengjin Wang, Jingdong Wang, and Qi Tian.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.2.1" class="ltx_text" style="font-size:90%;">Scalable person re-identification: A benchmark.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib63.3.1" class="ltx_text" style="font-size:90%;">In </span><span id="bib.bib63.4.2" class="ltx_text ltx_font_italic" style="font-size:90%;">Proceedings of the IEEE international conference on computer
vision (ICCV)</span><span id="bib.bib63.5.3" class="ltx_text" style="font-size:90%;">, pages 1116–1124, 2015.
</span>
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock"><span id="bib.bib64.1.1" class="ltx_text" style="font-size:90%;">
Liang Zheng, Yi Yang, and Qi Tian.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.2.1" class="ltx_text" style="font-size:90%;">SIFT meets CNN: A decade survey of instance retrieval.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib64.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE transactions on pattern analysis and machine intelligence</span><span id="bib.bib64.4.2" class="ltx_text" style="font-size:90%;">,
40(5):1224–1244, 2017.
</span>
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock"><span id="bib.bib65.1.1" class="ltx_text" style="font-size:90%;">
Bolei Zhou, Agata Lapedriza, Aditya Khosla, Aude Oliva, and Antonio Torralba.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib65.2.1" class="ltx_text" style="font-size:90%;">Places: A 10 million image database for scene recognition.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib65.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">IEEE transactions on pattern analysis and machine intelligence</span><span id="bib.bib65.4.2" class="ltx_text" style="font-size:90%;">,
40(6):1452–1464, 2017.
</span>
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock"><span id="bib.bib66.1.1" class="ltx_text" style="font-size:90%;">
Kuan Zhu, Haiyun Guo, Shiliang Zhang, Yaowei Wang, Gaopan Huang, Honglin Qiao,
Jing Liu, Jinqiao Wang, and Ming Tang.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.2.1" class="ltx_text" style="font-size:90%;">AAformer: Auto-aligned transformer for person re-identification.
</span>
</span>
<span class="ltx_bibblock"><span id="bib.bib66.3.1" class="ltx_text ltx_font_italic" style="font-size:90%;">arXiv preprint arXiv:2104.00921</span><span id="bib.bib66.4.2" class="ltx_text" style="font-size:90%;">, 2021.
</span>
</span>
</li>
</ul>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Dataset</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>CGI Pipeline implementation details</h3>

<div id="A1.SS1.p1" class="ltx_para">
<p id="A1.SS1.p1.1" class="ltx_p">In this section we provide additional details on the CGI pipeline used to implement the BBBicycles dataset, and in particular on the transformations that are randomly applied to generate “before” and “after” images.</p>
</div>
<section id="A1.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.1.1 </span>Template rig. </h4>

<div id="A1.SS1.SSS1.p1" class="ltx_para">
<p id="A1.SS1.SSS1.p1.1" class="ltx_p">A bike contains many movable elements which need to be positioned (to randomly change the bike pose) or deformed (to simulate damages). In order to randomly apply these transformations, we defined a <em id="A1.SS1.SSS1.p1.1.1" class="ltx_emph ltx_font_italic">template rig</em> that needs to be adapted to match the given bike model. The template rig is composed of an “armature” (<a href="#A1.F5.sf1" title="5(a) ‣ Figure 5 ‣ A.1.1 Template rig. ‣ A.1 CGI Pipeline implementation details ‣ Appendix A Dataset ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">5(a)</span></a>), “lattices” (<a href="#A1.F5.sf2" title="5(b) ‣ Figure 5 ‣ A.1.1 Template rig. ‣ A.1 CGI Pipeline implementation details ‣ Appendix A Dataset ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">5(b)</span></a>), and “rail guides”, placed as depicted in <a href="#A1.F5.sf3" title="5(c) ‣ Figure 5 ‣ A.1.1 Template rig. ‣ A.1 CGI Pipeline implementation details ‣ Appendix A Dataset ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">5(c)</span></a>.</p>
</div>
<figure id="A1.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/images/pipeline/RIG.png" id="A1.F5.sf1.g1" class="ltx_graphics ltx_img_landscape" width="276" height="106" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F5.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/images/pipeline/lattice.png" id="A1.F5.sf2.g1" class="ltx_graphics ltx_img_portrait" width="80" height="106" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F5.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F5.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/images/pipeline/breakguides.png" id="A1.F5.sf3.g1" class="ltx_graphics ltx_img_square" width="108" height="106" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F5.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="A1.F5.3.2" class="ltx_text" style="font-size:90%;">Template rig adaptation and skinning: (a) armature with bone groups and layers, (b) fitting lattice to wheel meshes, and (c) rail guides positioning.
</span></figcaption>
</figure>
</section>
<section id="A1.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.1.2 </span>Image rendering.</h4>

<div id="A1.SS1.SSS2.p1" class="ltx_para">
<p id="A1.SS1.SSS2.p1.1" class="ltx_p">For each ID, multiple images are generated by applying the following transformations:</p>
<ol id="A1.I1" class="ltx_enumerate">
<li id="A1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="A1.I1.i1.p1" class="ltx_para">
<p id="A1.I1.i1.p1.1" class="ltx_p">Mobile parts composition. This is accomplished by randomly performing one or more actions among: translating the seat and handlebar; rotating the seat, handlebar, pedals, and wheels. The allowed range of movement for each model is set during the rig adaptation.</p>
</div>
</li>
<li id="A1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="A1.I1.i2.p1" class="ltx_para">
<p id="A1.I1.i2.p1.1" class="ltx_p">Dirt. A custom shader is used to randomly apply dirt in the form of mud or rust, with a predetermined probability.</p>
</div>
</li>
<li id="A1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="A1.I1.i3.p1" class="ltx_para">
<p id="A1.I1.i3.p1.1" class="ltx_p">(Optional) Removing parts. The seat, pedals, handlebar and wheels can be removed with a predetermined probability.</p>
</div>
</li>
<li id="A1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="A1.I1.i4.p1" class="ltx_para">
<p id="A1.I1.i4.p1.1" class="ltx_p">(Optional) Damaging parts (frame excluded). Parts of the bikes can be damaged, by selecting a deformation either from the wheels’ library or from the pose library.</p>
</div>
</li>
<li id="A1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="A1.I1.i5.p1" class="ltx_para">
<p id="A1.I1.i5.p1.1" class="ltx_p">(Optional) Damaging the frame. The frame can be damaged either by picking a deformation from the pose library (Bent Frame) and/or by breaking it using the rail guides-boolean system (Broken frame). Hence, four possible damage categories are possible: normal frame, bent frame, broken frame, or bent &amp; broken frame.</p>
</div>
</li>
<li id="A1.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">6.</span> 
<div id="A1.I1.i6.p1" class="ltx_para">
<p id="A1.I1.i6.p1.1" class="ltx_p">Point of View selection. The virtual camera position is chosen randomly within a given boundary, by randomly switching the visible side of the bike, as well as randomly adjusting the camera focal length within a parametrized range.</p>
</div>
</li>
<li id="A1.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">7.</span> 
<div id="A1.I1.i7.p1" class="ltx_para">
<p id="A1.I1.i7.p1.1" class="ltx_p">Environment and Lighting. A combination of background and lighting setup is picked.</p>
</div>
</li>
<li id="A1.I1.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">8.</span> 
<div id="A1.I1.i8.p1" class="ltx_para">
<p id="A1.I1.i8.p1.1" class="ltx_p">Segmentation. The bike is segmented in the following classes: “Front Wheel”, “Rear Wheel”, “Seat”, “Crankset”, and “Frame”. Segmentation was implemented using the <span id="A1.I1.i8.p1.1.1" class="ltx_text ltx_font_italic">bpycv</span> <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/DIYer22/bpycv" title="" class="ltx_ref ltx_href">https://github.com/DIYer22/bpycv</a></span></span></span> library. An example of segmentation is shown in <a href="#A1.F6" title="Figure 6 ‣ A.1.2 Image rendering. ‣ A.1 CGI Pipeline implementation details ‣ Appendix A Dataset ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 6</span></a></p>
</div>
</li>
</ol>
</div>
<figure id="A1.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/images/dataset/before_dep_seg.jpg" id="A1.F6.sf1.g1" class="ltx_graphics ltx_img_landscape" width="685" height="229" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F6.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/images/dataset/after_dep_seg.jpg" id="A1.F6.sf2.g1" class="ltx_graphics ltx_img_landscape" width="685" height="229" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F6.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="A1.F6.3.2" class="ltx_text" style="font-size:90%;">Examples of the CGI pipeline auxiliary outputs. From right to left: segmentation, rendered image, and depth map.</span></figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>The BBBicycles dataset</h3>

<div id="A1.SS2.p1" class="ltx_para">
<p id="A1.SS2.p1.1" class="ltx_p">In this section we provide additional details on the generated dataset to better illustrate the variety of models and damages/deformations included in the BBBicycles dataset.</p>
</div>
<section id="A1.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.2.1 </span>3D Bike models</h4>

<div id="A1.SS2.SSS1.p1" class="ltx_para">
<p id="A1.SS2.SSS1.p1.1" class="ltx_p">BBBicycles contains images generated from 20 3D bike models retrieved from dedicated marketplaces. It includes several variants of popular bikes such as Road, Cruiser and MTB. In particular, it contains 6 MTB, 1 Enduro, 6 Road, 1 Circuit, 1 Gravel, and 5 Cruiser. The list of bike models per category is illustrated in <a href="#A1.T2" title="Table 2 ‣ A.2.1 3D Bike models ‣ A.2 The BBBicycles dataset ‣ Appendix A Dataset ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 2</span></a>: each bike model was assigned to either the training, validation, or (stress) test set. Examples of renderings from each model are shown in <a href="#A1.F7" title="Figure 7 ‣ A.2.1 3D Bike models ‣ A.2 The BBBicycles dataset ‣ Appendix A Dataset ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 7</span></a>.</p>
</div>
<figure id="A1.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="A1.T2.2.1.1" class="ltx_text" style="font-size:90%;">Table 2</span>: </span><span id="A1.T2.3.2" class="ltx_text" style="font-size:90%;">Bike model distribution across BBBicycles in the training, validation and test set. Models marked with (*) are shared between Train and Validation.</span></figcaption>
<div id="A1.T2.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:347.8pt;height:589.7pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(73.1pt,-123.9pt) scale(1.72437655055241,1.72437655055241) ;">
<table id="A1.T2.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A1.T2.4.1.1.1" class="ltx_tr">
<th id="A1.T2.4.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="A1.T2.4.1.1.1.1.1" class="ltx_text ltx_font_bold">Category</span></th>
<td id="A1.T2.4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A1.T2.4.1.1.1.2.1" class="ltx_text ltx_font_bold">Train</span></td>
<td id="A1.T2.4.1.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A1.T2.4.1.1.1.3.1" class="ltx_text ltx_font_bold">Validation</span></td>
<td id="A1.T2.4.1.1.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A1.T2.4.1.1.1.4.1" class="ltx_text ltx_font_bold">Test</span></td>
</tr>
<tr id="A1.T2.4.1.2.2" class="ltx_tr">
<th id="A1.T2.4.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">MTB</th>
<td id="A1.T2.4.1.2.2.2" class="ltx_td ltx_align_center ltx_border_t">mfactory</td>
<td id="A1.T2.4.1.2.2.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">becane</td>
<td id="A1.T2.4.1.2.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="A1.T2.4.1.3.3" class="ltx_tr">
<th id="A1.T2.4.1.3.3.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<td id="A1.T2.4.1.3.3.2" class="ltx_td ltx_align_center">ghost</td>
<td id="A1.T2.4.1.3.3.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r">btwin</td>
<td id="A1.T2.4.1.3.3.4" class="ltx_td ltx_border_r"></td>
</tr>
<tr id="A1.T2.4.1.4.4" class="ltx_tr">
<th id="A1.T2.4.1.4.4.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<td id="A1.T2.4.1.4.4.2" class="ltx_td ltx_align_center ltx_border_r" colspan="2">freeride*</td>
<td id="A1.T2.4.1.4.4.3" class="ltx_td ltx_border_r"></td>
</tr>
<tr id="A1.T2.4.1.5.5" class="ltx_tr">
<th id="A1.T2.4.1.5.5.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<td id="A1.T2.4.1.5.5.2" class="ltx_td ltx_align_center ltx_border_r" colspan="2">scalpel*</td>
<td id="A1.T2.4.1.5.5.3" class="ltx_td ltx_border_r"></td>
</tr>
<tr id="A1.T2.4.1.6.6" class="ltx_tr">
<th id="A1.T2.4.1.6.6.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Road</th>
<td id="A1.T2.4.1.6.6.2" class="ltx_td ltx_align_center ltx_border_t">rondo</td>
<td id="A1.T2.4.1.6.6.3" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">croad</td>
<td id="A1.T2.4.1.6.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="A1.T2.4.1.7.7" class="ltx_tr">
<th id="A1.T2.4.1.7.7.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<td id="A1.T2.4.1.7.7.2" class="ltx_td ltx_align_center">verdona</td>
<td id="A1.T2.4.1.7.7.3" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="A1.T2.4.1.7.7.4" class="ltx_td ltx_border_r"></td>
</tr>
<tr id="A1.T2.4.1.8.8" class="ltx_tr">
<th id="A1.T2.4.1.8.8.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<td id="A1.T2.4.1.8.8.2" class="ltx_td ltx_align_center">ghost</td>
<td id="A1.T2.4.1.8.8.3" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="A1.T2.4.1.8.8.4" class="ltx_td ltx_border_r"></td>
</tr>
<tr id="A1.T2.4.1.9.9" class="ltx_tr">
<th id="A1.T2.4.1.9.9.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<td id="A1.T2.4.1.9.9.2" class="ltx_td ltx_align_center ltx_border_r" colspan="2">domane*</td>
<td id="A1.T2.4.1.9.9.3" class="ltx_td ltx_border_r"></td>
</tr>
<tr id="A1.T2.4.1.10.10" class="ltx_tr">
<th id="A1.T2.4.1.10.10.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<td id="A1.T2.4.1.10.10.2" class="ltx_td ltx_align_center ltx_border_r" colspan="2">g1*</td>
<td id="A1.T2.4.1.10.10.3" class="ltx_td ltx_border_r"></td>
</tr>
<tr id="A1.T2.4.1.11.11" class="ltx_tr">
<th id="A1.T2.4.1.11.11.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<td id="A1.T2.4.1.11.11.2" class="ltx_td ltx_align_center ltx_border_r" colspan="2">kuota*</td>
<td id="A1.T2.4.1.11.11.3" class="ltx_td ltx_border_r"></td>
</tr>
<tr id="A1.T2.4.1.12.12" class="ltx_tr">
<th id="A1.T2.4.1.12.12.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Cruiser</th>
<td id="A1.T2.4.1.12.12.2" class="ltx_td ltx_align_center ltx_border_t">oldbike</td>
<td id="A1.T2.4.1.12.12.3" class="ltx_td ltx_border_l ltx_border_r ltx_border_t"></td>
<td id="A1.T2.4.1.12.12.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">-</td>
</tr>
<tr id="A1.T2.4.1.13.13" class="ltx_tr">
<th id="A1.T2.4.1.13.13.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<td id="A1.T2.4.1.13.13.2" class="ltx_td ltx_align_center ltx_border_r" colspan="2">holland*</td>
<td id="A1.T2.4.1.13.13.3" class="ltx_td ltx_border_r"></td>
</tr>
<tr id="A1.T2.4.1.14.14" class="ltx_tr">
<th id="A1.T2.4.1.14.14.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<td id="A1.T2.4.1.14.14.2" class="ltx_td ltx_align_center ltx_border_r" colspan="2">huffy*</td>
<td id="A1.T2.4.1.14.14.3" class="ltx_td ltx_border_r"></td>
</tr>
<tr id="A1.T2.4.1.15.15" class="ltx_tr">
<th id="A1.T2.4.1.15.15.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<td id="A1.T2.4.1.15.15.2" class="ltx_td ltx_align_center ltx_border_r" colspan="2">vintage*</td>
<td id="A1.T2.4.1.15.15.3" class="ltx_td ltx_border_r"></td>
</tr>
<tr id="A1.T2.4.1.16.16" class="ltx_tr">
<th id="A1.T2.4.1.16.16.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<td id="A1.T2.4.1.16.16.2" class="ltx_td ltx_align_center ltx_border_r" colspan="2">wbike*</td>
<td id="A1.T2.4.1.16.16.3" class="ltx_td ltx_border_r"></td>
</tr>
<tr id="A1.T2.4.1.17.17" class="ltx_tr">
<th id="A1.T2.4.1.17.17.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Enduro</th>
<td id="A1.T2.4.1.17.17.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">-</td>
<td id="A1.T2.4.1.17.17.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">enduro</td>
</tr>
<tr id="A1.T2.4.1.18.18" class="ltx_tr">
<th id="A1.T2.4.1.18.18.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">Circuit</th>
<td id="A1.T2.4.1.18.18.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2">-</td>
<td id="A1.T2.4.1.18.18.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">mirage</td>
</tr>
<tr id="A1.T2.4.1.19.19" class="ltx_tr">
<th id="A1.T2.4.1.19.19.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">Gravel</th>
<td id="A1.T2.4.1.19.19.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t" colspan="2">-</td>
<td id="A1.T2.4.1.19.19.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">gbike</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="A1.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<table id="A1.F7.2" class="ltx_tabular ltx_figure_panel ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A1.F7.2.1.1" class="ltx_tr">
<td id="A1.F7.2.1.1.1" class="ltx_td ltx_align_center"></td>
<td id="A1.F7.2.1.1.2" class="ltx_td ltx_align_center"></td>
<td id="A1.F7.2.1.1.3" class="ltx_td ltx_align_center"></td>
<td id="A1.F7.2.1.1.4" class="ltx_td ltx_align_center"></td>
</tr>
<tr id="A1.F7.2.2.2" class="ltx_tr">
<td id="A1.F7.2.2.2.1" class="ltx_td ltx_align_center"></td>
<td id="A1.F7.2.2.2.2" class="ltx_td ltx_align_center"></td>
<td id="A1.F7.2.2.2.3" class="ltx_td ltx_align_center"></td>
<td id="A1.F7.2.2.2.4" class="ltx_td ltx_align_center"></td>
</tr>
<tr id="A1.F7.2.3.3" class="ltx_tr">
<td id="A1.F7.2.3.3.1" class="ltx_td ltx_align_center"></td>
<td id="A1.F7.2.3.3.2" class="ltx_td ltx_align_center"></td>
<td id="A1.F7.2.3.3.3" class="ltx_td ltx_align_center"></td>
<td id="A1.F7.2.3.3.4" class="ltx_td ltx_align_center"></td>
</tr>
<tr id="A1.F7.2.4.4" class="ltx_tr">
<td id="A1.F7.2.4.4.1" class="ltx_td ltx_align_center"></td>
<td id="A1.F7.2.4.4.2" class="ltx_td ltx_align_center"></td>
<td id="A1.F7.2.4.4.3" class="ltx_td ltx_align_center"></td>
<td id="A1.F7.2.4.4.4" class="ltx_td ltx_align_center"></td>
</tr>
<tr id="A1.F7.2.5.5" class="ltx_tr">
<td id="A1.F7.2.5.5.1" class="ltx_td ltx_align_center"></td>
<td id="A1.F7.2.5.5.2" class="ltx_td ltx_align_center"></td>
<td id="A1.F7.2.5.5.3" class="ltx_td ltx_align_center"></td>
<td id="A1.F7.2.5.5.4" class="ltx_td ltx_align_center"></td>
</tr>
</tbody>
</table>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F7.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2304.07883/assets/images/bikes/all_models/becane-min.png" id="A1.F7.sf1.g1" class="ltx_graphics ltx_img_square" width="151" height="151" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F7.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2304.07883/assets/images/bikes/all_models/btwin-min.png" id="A1.F7.sf2.g1" class="ltx_graphics ltx_img_square" width="151" height="151" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F7.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/2304.07883/assets/images/bikes/all_models/croad-min.png" id="A1.F7.sf3.g1" class="ltx_graphics ltx_img_square" width="151" height="151" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F7.sf4" class="ltx_figure ltx_figure_panel"><img src="/html/2304.07883/assets/images/bikes/all_models/domane-min.png" id="A1.F7.sf4.g1" class="ltx_graphics ltx_img_square" width="151" height="151" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F7.sf5" class="ltx_figure ltx_figure_panel"><img src="/html/2304.07883/assets/images/bikes/all_models/enduro-min.png" id="A1.F7.sf5.g1" class="ltx_graphics ltx_img_square" width="151" height="151" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.sf5.2.1.1" class="ltx_text" style="font-size:90%;">(e)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F7.sf6" class="ltx_figure ltx_figure_panel"><img src="/html/2304.07883/assets/images/bikes/all_models/freeride-min.png" id="A1.F7.sf6.g1" class="ltx_graphics ltx_img_square" width="151" height="151" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.sf6.2.1.1" class="ltx_text" style="font-size:90%;">(f)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F7.sf7" class="ltx_figure ltx_figure_panel"><img src="/html/2304.07883/assets/images/bikes/all_models/g1-min.png" id="A1.F7.sf7.g1" class="ltx_graphics ltx_img_square" width="151" height="151" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.sf7.2.1.1" class="ltx_text" style="font-size:90%;">(g)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F7.sf8" class="ltx_figure ltx_figure_panel"><img src="/html/2304.07883/assets/images/bikes/all_models/gbike-min.png" id="A1.F7.sf8.g1" class="ltx_graphics ltx_img_square" width="151" height="151" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.sf8.2.1.1" class="ltx_text" style="font-size:90%;">(h)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F7.sf9" class="ltx_figure ltx_figure_panel"><img src="/html/2304.07883/assets/images/bikes/all_models/ghost-min.png" id="A1.F7.sf9.g1" class="ltx_graphics ltx_img_square" width="151" height="151" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.sf9.2.1.1" class="ltx_text" style="font-size:90%;">(i)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F7.sf10" class="ltx_figure ltx_figure_panel"><img src="/html/2304.07883/assets/images/bikes/all_models/holland-min.png" id="A1.F7.sf10.g1" class="ltx_graphics ltx_img_square" width="151" height="151" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.sf10.2.1.1" class="ltx_text" style="font-size:90%;">(j)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F7.sf11" class="ltx_figure ltx_figure_panel"><img src="/html/2304.07883/assets/images/bikes/all_models/huffy-min.png" id="A1.F7.sf11.g1" class="ltx_graphics ltx_img_square" width="151" height="151" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.sf11.2.1.1" class="ltx_text" style="font-size:90%;">(k)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F7.sf12" class="ltx_figure ltx_figure_panel"><img src="/html/2304.07883/assets/images/bikes/all_models/kuota-min.png" id="A1.F7.sf12.g1" class="ltx_graphics ltx_img_square" width="151" height="151" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.sf12.2.1.1" class="ltx_text" style="font-size:90%;">(l)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F7.sf13" class="ltx_figure ltx_figure_panel"><img src="/html/2304.07883/assets/images/bikes/all_models/mfactory-min.png" id="A1.F7.sf13.g1" class="ltx_graphics ltx_img_square" width="151" height="151" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.sf13.2.1.1" class="ltx_text" style="font-size:90%;">(m)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F7.sf14" class="ltx_figure ltx_figure_panel"><img src="/html/2304.07883/assets/images/bikes/all_models/mirage-min.png" id="A1.F7.sf14.g1" class="ltx_graphics ltx_img_square" width="151" height="151" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.sf14.2.1.1" class="ltx_text" style="font-size:90%;">(n)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F7.sf15" class="ltx_figure ltx_figure_panel"><img src="/html/2304.07883/assets/images/bikes/all_models/oldbike-min.png" id="A1.F7.sf15.g1" class="ltx_graphics ltx_img_square" width="151" height="151" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.sf15.2.1.1" class="ltx_text" style="font-size:90%;">(o)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F7.sf16" class="ltx_figure ltx_figure_panel"><img src="/html/2304.07883/assets/images/bikes/all_models/rondo-min.png" id="A1.F7.sf16.g1" class="ltx_graphics ltx_img_square" width="151" height="151" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.sf16.2.1.1" class="ltx_text" style="font-size:90%;">(p)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F7.sf17" class="ltx_figure ltx_figure_panel"><img src="/html/2304.07883/assets/images/bikes/all_models/scalpel-min.png" id="A1.F7.sf17.g1" class="ltx_graphics ltx_img_square" width="151" height="151" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.sf17.2.1.1" class="ltx_text" style="font-size:90%;">(q)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F7.sf18" class="ltx_figure ltx_figure_panel"><img src="/html/2304.07883/assets/images/bikes/all_models/verdona-min.png" id="A1.F7.sf18.g1" class="ltx_graphics ltx_img_square" width="151" height="151" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.sf18.2.1.1" class="ltx_text" style="font-size:90%;">(r)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F7.sf19" class="ltx_figure ltx_figure_panel"><img src="/html/2304.07883/assets/images/bikes/all_models/vintage-min.png" id="A1.F7.sf19.g1" class="ltx_graphics ltx_img_square" width="151" height="151" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.sf19.2.1.1" class="ltx_text" style="font-size:90%;">(s)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F7.sf20" class="ltx_figure ltx_figure_panel"><img src="/html/2304.07883/assets/images/bikes/all_models/wbike-min.png" id="A1.F7.sf20.g1" class="ltx_graphics ltx_img_square" width="151" height="151" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.sf20.2.1.1" class="ltx_text" style="font-size:90%;">(t)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F7.3.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="A1.F7.4.2" class="ltx_text" style="font-size:90%;">Examples of each model used to generate the dataset.</span></figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A1.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.2.2 </span>Damage distribution and examples</h4>

<div id="A1.SS2.SSS2.p1" class="ltx_para">
<p id="A1.SS2.SSS2.p1.1" class="ltx_p">As illustrated in Section 3, in BBBicycles 50% of the images are generated “before” and 50% “after” a damage occurs. “Before” bikes have a 25% probability of being dirty, while “after” bikes have a 50% chance. “After” bikes are further divided into 25% undamaged and 75% bent, broken or both. As a result, 37% of the total images are damaged (see <a href="#A1.F8" title="Figure 8 ‣ A.2.2 Damage distribution and examples ‣ A.2 The BBBicycles dataset ‣ Appendix A Dataset ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 8</span></a>). Examples of damaged and undamaged synthetic bike renderings are shown in <a href="#A1.F9" title="Figure 9 ‣ A.2.2 Damage distribution and examples ‣ A.2 The BBBicycles dataset ‣ Appendix A Dataset ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 9</span></a>, <a href="#A1.F10" title="Figure 10 ‣ A.2.2 Damage distribution and examples ‣ A.2 The BBBicycles dataset ‣ Appendix A Dataset ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 10</span></a>, <a href="#A1.F11" title="Figure 11 ‣ A.2.2 Damage distribution and examples ‣ A.2 The BBBicycles dataset ‣ Appendix A Dataset ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 11</span></a> and <a href="#A1.F12" title="Figure 12 ‣ A.2.2 Damage distribution and examples ‣ A.2 The BBBicycles dataset ‣ Appendix A Dataset ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 12</span></a>.</p>
</div>
<figure id="A1.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F8.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/x5.png" id="A1.F8.sf1.g1" class="ltx_graphics ltx_img_landscape" width="253" height="147" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F8.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F8.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/x6.png" id="A1.F8.sf2.g1" class="ltx_graphics ltx_img_landscape" width="253" height="153" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F8.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F8.2.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="A1.F8.3.2" class="ltx_text" style="font-size:90%;">Distribution of damages and missing parts across the synthethic dataset.</span></figcaption>
</figure>
<figure id="A1.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F9.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/images/dmg0before.png" id="A1.F9.sf1.g1" class="ltx_graphics ltx_img_square" width="274" height="274" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F9.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F9.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/images/dmg0after.png" id="A1.F9.sf2.g1" class="ltx_graphics ltx_img_square" width="274" height="274" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F9.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F9.2.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="A1.F9.3.2" class="ltx_text" style="font-size:90%;">Examples of bike renderings without damages (to the frame). </span></figcaption>
</figure>
<figure id="A1.F10" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F10.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/images/dmg1_1.png" id="A1.F10.sf1.g1" class="ltx_graphics ltx_img_square" width="274" height="274" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F10.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F10.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/images/dmg1_2.png" id="A1.F10.sf2.g1" class="ltx_graphics ltx_img_square" width="274" height="274" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F10.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F10.2.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="A1.F10.3.2" class="ltx_text" style="font-size:90%;">Examples of bike renderings with bent frames. </span></figcaption>
</figure>
<figure id="A1.F11" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F11.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/images/dmg2_1.png" id="A1.F11.sf1.g1" class="ltx_graphics ltx_img_square" width="274" height="274" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F11.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F11.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/images/dmg2_2.png" id="A1.F11.sf2.g1" class="ltx_graphics ltx_img_square" width="274" height="274" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F11.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F11.2.1.1" class="ltx_text" style="font-size:90%;">Figure 11</span>: </span><span id="A1.F11.3.2" class="ltx_text" style="font-size:90%;">Examples of bike renderings with broken frames. </span></figcaption>
</figure>
<figure id="A1.F12" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F12.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/images/dmg3_1.png" id="A1.F12.sf1.g1" class="ltx_graphics ltx_img_square" width="274" height="274" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F12.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F12.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/images/dmg3_2.png" id="A1.F12.sf2.g1" class="ltx_graphics ltx_img_square" width="274" height="274" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A1.F12.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F12.2.1.1" class="ltx_text" style="font-size:90%;">Figure 12</span>: </span><span id="A1.F12.3.2" class="ltx_text" style="font-size:90%;">Examples of bike renderings with bent and broken frames.</span></figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
<div id="A1.SS2.SSS2.p2" class="ltx_para">
<p id="A1.SS2.SSS2.p2.1" class="ltx_p">Moreover, we set additional labels for each image according to the missing parts of the bike, namely: Front Wheel, Rear Wheel, Seat, Handlebar, Pedals. In the annotations, missing parts are represented by a One-hot vector encoding, where each vector value indicates if the corresponding part is present (0) or
not (1), as exemplified in Fig. <a href="#A1.F15" title="Figure 15 ‣ A.3.3 Labelling. ‣ A.3 Real dataset acquisition: additional details. ‣ Appendix A Dataset ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">15</span></a>.</p>
</div>
<figure id="A1.F13" class="ltx_figure"><img src="/html/2304.07883/assets/images/Synth_missing_1.png" id="A1.F13.g1" class="ltx_graphics ltx_centering ltx_img_square" width="411" height="411" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F13.2.1.1" class="ltx_text" style="font-size:90%;">Figure 13</span>: </span><span id="A1.F13.3.2" class="ltx_text" style="font-size:90%;">One-hot encoding example: the illustrated image only misses the “Rear Wheel”, “Seat” and “Handlebar” parts, hence it has been labeled as “01110”.</span></figcaption>
</figure>
</section>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Real dataset acquisition: additional details.</h3>

<div id="A1.SS3.p1" class="ltx_para">
<p id="A1.SS3.p1.1" class="ltx_p">In this section, we provide additional details on how the real dataset was assembled and annotated.</p>
</div>
<section id="A1.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.3.1 </span>Delft Bikes.</h4>

<div id="A1.SS3.SSS1.p1" class="ltx_para">
<p id="A1.SS3.SSS1.p1.1" class="ltx_p">The DelftBikes dataset<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a target="_blank" href="https://data.4tu.nl/articles/dataset/DelftBikes_data_underlying_the_publication_Hallucination_In_Object_Detection-A_Study_In_Visual_Part_Verification/14866116" title="" class="ltx_ref ltx_href">https://data.4tu.nl/articles/dataset/DelftBikes_data_underlying_the_publication_Hallucination_In_Object_DetectionA_Study_In_Visual_Part_Verification/14866116</a>.</span></span></span> was originally designed to study whether deep neural networks could hallucinate missing parts in objects. It contains 10,000 bike images with 22 densely annotated parts for each bike. All part locations and part states (i.e., missing, intact, damaged, occluded) are explicitly annotated.</p>
</div>
<div id="A1.SS3.SSS1.p2" class="ltx_para">
<p id="A1.SS3.SSS1.p2.1" class="ltx_p">Specifically, we retained only the images from the DelftBikes training set with complete annotations (for some images missing parts annotations were not available), for a total of 8,000 images. Then, we translated the Delftbikes annotations to be compatible with the synthetic dataset annotations, as follows:</p>
<ul id="A1.I2" class="ltx_itemize">
<li id="A1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I2.i1.p1" class="ltx_para">
<p id="A1.I2.i1.p1.1" class="ltx_p">For Front Wheel, Rear Wheel and Seat, we labeled the part as missing if the corresponding part was labeled in the same way (i.e., object state class = missing) in the Delftbikes dataset.</p>
</div>
</li>
<li id="A1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I2.i2.p1" class="ltx_para">
<p id="A1.I2.i2.p1.1" class="ltx_p">For Handlebar, we labeled the part as missing if all parts belonging to the group {back handle, front handle, back hand break, front hand break, steer} were also labeled in the same way (i.e., object state class = missing) in the Delftbikes dataset.</p>
</div>
</li>
<li id="A1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I2.i3.p1" class="ltx_para">
<p id="A1.I2.i3.p1.1" class="ltx_p">For Pedals, we labeled the part as missing if both parts in the group {front_pedal, back_pedal} were also labeled in the same way (i.e, object state class = 2) in the Delftbikes dataset.</p>
</div>
</li>
</ul>
</div>
<div id="A1.SS3.SSS1.p3" class="ltx_para">
<p id="A1.SS3.SSS1.p3.1" class="ltx_p">None of the bike instances in the DelftBikes dataset presented damages to the frame.</p>
</div>
</section>
<section id="A1.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.3.2 </span>Web scraping details</h4>

<div id="A1.SS3.SSS2.p1" class="ltx_para">
<p id="A1.SS3.SSS2.p1.1" class="ltx_p">We collected samples of real damaged bikes by querying popular search engines (i.e., Google, Bing) and online forums (i.e., Reddit and other dedicated forums). We used different keywords (i.e., “damaged bike”, “bici danneggiata”, etc.) in different languages (i.e., English, Italian, Spanish, French, etc.) in order to increase the number of matches. In particular, we selected countries with higher bike usage like the Netherlands and Denmark. Synonyms of damage were searched to amplify the number of returned images (for instance, “broken bike” and “damaged bike” produce different search results). Additional images of normal bikes were retrieved from second-hand e-commerce sites.</p>
</div>
<div id="A1.SS3.SSS2.p2" class="ltx_para">
<p id="A1.SS3.SSS2.p2.1" class="ltx_p">For each scraped image, the origin URL has been serialized as a source reference. The results have then been pruned from unrelated (e.g., excluding images about bike helmets, cycling suits, etc.) and duplicated images by hand and by means of automatic de-duplication techniques, respectively. In particular, we chose a de-duplication technique based on pre-trained CNNs, which marks as duplicated images those with a pairwise similarity score above a given threshold value (experimentally set to 85%).</p>
</div>
</section>
<section id="A1.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.3.3 </span>Labelling.</h4>

<div id="A1.SS3.SSS3.p1" class="ltx_para">
<p id="A1.SS3.SSS3.p1.1" class="ltx_p">All images were manually labeled indicating the damage type and missing parts. Labels were assigned as uniformly as possible to the synthetic dataset. Concerning damage labeling, we set four different labels based on the type of damage present on the bike frame:</p>
<ul id="A1.I3" class="ltx_itemize">
<li id="A1.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I3.i1.p1" class="ltx_para">
<p id="A1.I3.i1.p1.1" class="ltx_p">normal: the bike frame is intact, regardless of the condition of the other parts of the bike (e.g., missing parts, damaged wheels, damaged seat).</p>
</div>
</li>
<li id="A1.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I3.i2.p1" class="ltx_para">
<p id="A1.I3.i2.p1.1" class="ltx_p">bent: the bike frame is bent or presents damage, but it is broken in multiple pieces.</p>
</div>
</li>
<li id="A1.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I3.i3.p1" class="ltx_para">
<p id="A1.I3.i3.p1.1" class="ltx_p">broken: the bike frame is broken and clearly divided in pieces, and each piece does not present any bending.</p>
</div>
</li>
<li id="A1.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I3.i4.p1" class="ltx_para">
<p id="A1.I3.i4.p1.1" class="ltx_p">bent &amp; broken: the bike frame is broken and the frame pieces show signs of bending.</p>
</div>
</li>
</ul>
</div>
<figure id="A1.F14" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F14.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/x7.png" id="A1.F14.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="761" height="515" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F14.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="A1.F14.sf1.3.2" class="ltx_text" style="font-size:90%;">Normal</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F14.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/x8.png" id="A1.F14.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="761" height="275" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F14.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="A1.F14.sf2.3.2" class="ltx_text" style="font-size:90%;">Bent</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F14.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/x9.png" id="A1.F14.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="761" height="287" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F14.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="A1.F14.sf3.3.2" class="ltx_text" style="font-size:90%;">Broken</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A1.F14.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/x10.png" id="A1.F14.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="761" height="293" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F14.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="A1.F14.sf4.3.2" class="ltx_text" style="font-size:90%;">Bent &amp; broken</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F14.2.1.1" class="ltx_text" style="font-size:90%;">Figure 14</span>: </span><span id="A1.F14.3.2" class="ltx_text" style="font-size:90%;">Examples of real images with normal (a), bent (b), broken (c) and bent &amp; broken (d) frames. </span></figcaption>
</figure>
<div id="A1.SS3.SSS3.p2" class="ltx_para">
<p id="A1.SS3.SSS3.p2.1" class="ltx_p">For missing parts, we follow the same convention of the synthetic dataset and set additional labels for the following parts: Front Wheel, Rear Wheel, Seat, Handlebar, Pedals. Missing parts are represented by a One-hot vector encoding, where each vector value indicates if the corresponding part is present (0) or
not (1), as exemplified in Fig. <a href="#A1.F15" title="Figure 15 ‣ A.3.3 Labelling. ‣ A.3 Real dataset acquisition: additional details. ‣ Appendix A Dataset ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">15</span></a>.</p>
</div>
<figure id="A1.F15" class="ltx_figure"><img src="/html/2304.07883/assets/x11.png" id="A1.F15.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="380" height="257" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A1.F15.2.1.1" class="ltx_text" style="font-size:90%;">Figure 15</span>: </span><span id="A1.F15.3.2" class="ltx_text" style="font-size:90%;">Example of real image with missing parts: the illustrated image only misses the “Front wheel” and “Seat” parts, hence it has been labeled with “10100”.</span></figcaption>
</figure>
</section>
</section>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Experimental settings</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.3" class="ltx_p"><span id="A2.p1.3.1" class="ltx_text ltx_font_italic">classification [cls] embedding</span>, which encodes image global features, is prepended to the sequence of <math id="A2.p1.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="A2.p1.1.m1.1a"><mi id="A2.p1.1.m1.1.1" xref="A2.p1.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="A2.p1.1.m1.1b"><ci id="A2.p1.1.m1.1.1.cmml" xref="A2.p1.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.1.m1.1c">N</annotation></semantics></math> <span id="A2.p1.3.2" class="ltx_text ltx_font_italic">patch tokens</span>. Each token is encoded by the combination (sum) of the corresponding patch embedding, learnable positional embedding, and SIE embeddings. The <math id="A2.p1.2.m2.1" class="ltx_Math" alttext="N+1" display="inline"><semantics id="A2.p1.2.m2.1a"><mrow id="A2.p1.2.m2.1.1" xref="A2.p1.2.m2.1.1.cmml"><mi id="A2.p1.2.m2.1.1.2" xref="A2.p1.2.m2.1.1.2.cmml">N</mi><mo id="A2.p1.2.m2.1.1.1" xref="A2.p1.2.m2.1.1.1.cmml">+</mo><mn id="A2.p1.2.m2.1.1.3" xref="A2.p1.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.2.m2.1b"><apply id="A2.p1.2.m2.1.1.cmml" xref="A2.p1.2.m2.1.1"><plus id="A2.p1.2.m2.1.1.1.cmml" xref="A2.p1.2.m2.1.1.1"></plus><ci id="A2.p1.2.m2.1.1.2.cmml" xref="A2.p1.2.m2.1.1.2">𝑁</ci><cn type="integer" id="A2.p1.2.m2.1.1.3.cmml" xref="A2.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.2.m2.1c">N+1</annotation></semantics></math> input tokens, inclusive of the [<span id="A2.p1.3.3" class="ltx_text ltx_font_italic">cls</span>] token for a total size of <math id="A2.p1.3.m3.3" class="ltx_Math" alttext="[1,N+1,768]" display="inline"><semantics id="A2.p1.3.m3.3a"><mrow id="A2.p1.3.m3.3.3.1" xref="A2.p1.3.m3.3.3.2.cmml"><mo stretchy="false" id="A2.p1.3.m3.3.3.1.2" xref="A2.p1.3.m3.3.3.2.cmml">[</mo><mn id="A2.p1.3.m3.1.1" xref="A2.p1.3.m3.1.1.cmml">1</mn><mo id="A2.p1.3.m3.3.3.1.3" xref="A2.p1.3.m3.3.3.2.cmml">,</mo><mrow id="A2.p1.3.m3.3.3.1.1" xref="A2.p1.3.m3.3.3.1.1.cmml"><mi id="A2.p1.3.m3.3.3.1.1.2" xref="A2.p1.3.m3.3.3.1.1.2.cmml">N</mi><mo id="A2.p1.3.m3.3.3.1.1.1" xref="A2.p1.3.m3.3.3.1.1.1.cmml">+</mo><mn id="A2.p1.3.m3.3.3.1.1.3" xref="A2.p1.3.m3.3.3.1.1.3.cmml">1</mn></mrow><mo id="A2.p1.3.m3.3.3.1.4" xref="A2.p1.3.m3.3.3.2.cmml">,</mo><mn id="A2.p1.3.m3.2.2" xref="A2.p1.3.m3.2.2.cmml">768</mn><mo stretchy="false" id="A2.p1.3.m3.3.3.1.5" xref="A2.p1.3.m3.3.3.2.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.p1.3.m3.3b"><list id="A2.p1.3.m3.3.3.2.cmml" xref="A2.p1.3.m3.3.3.1"><cn type="integer" id="A2.p1.3.m3.1.1.cmml" xref="A2.p1.3.m3.1.1">1</cn><apply id="A2.p1.3.m3.3.3.1.1.cmml" xref="A2.p1.3.m3.3.3.1.1"><plus id="A2.p1.3.m3.3.3.1.1.1.cmml" xref="A2.p1.3.m3.3.3.1.1.1"></plus><ci id="A2.p1.3.m3.3.3.1.1.2.cmml" xref="A2.p1.3.m3.3.3.1.1.2">𝑁</ci><cn type="integer" id="A2.p1.3.m3.3.3.1.1.3.cmml" xref="A2.p1.3.m3.3.3.1.1.3">1</cn></apply><cn type="integer" id="A2.p1.3.m3.2.2.cmml" xref="A2.p1.3.m3.2.2">768</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A2.p1.3.m3.3c">[1,N+1,768]</annotation></semantics></math>, are then input into the transformer backbone.</p>
</div>
<div id="A2.p2" class="ltx_para">
<ul id="A2.I1" class="ltx_itemize">
<li id="A2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A2.I1.i1.p1" class="ltx_para">
<p id="A2.I1.i1.p1.3" class="ltx_p"><span id="A2.I1.i1.p1.3.1" class="ltx_text ltx_font_bold">Shared ViT Network</span>: a ViT-like structure including <math id="A2.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="L-1" display="inline"><semantics id="A2.I1.i1.p1.1.m1.1a"><mrow id="A2.I1.i1.p1.1.m1.1.1" xref="A2.I1.i1.p1.1.m1.1.1.cmml"><mi id="A2.I1.i1.p1.1.m1.1.1.2" xref="A2.I1.i1.p1.1.m1.1.1.2.cmml">L</mi><mo id="A2.I1.i1.p1.1.m1.1.1.1" xref="A2.I1.i1.p1.1.m1.1.1.1.cmml">−</mo><mn id="A2.I1.i1.p1.1.m1.1.1.3" xref="A2.I1.i1.p1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.I1.i1.p1.1.m1.1b"><apply id="A2.I1.i1.p1.1.m1.1.1.cmml" xref="A2.I1.i1.p1.1.m1.1.1"><minus id="A2.I1.i1.p1.1.m1.1.1.1.cmml" xref="A2.I1.i1.p1.1.m1.1.1.1"></minus><ci id="A2.I1.i1.p1.1.m1.1.1.2.cmml" xref="A2.I1.i1.p1.1.m1.1.1.2">𝐿</ci><cn type="integer" id="A2.I1.i1.p1.1.m1.1.1.3.cmml" xref="A2.I1.i1.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i1.p1.1.m1.1c">L-1</annotation></semantics></math> layers (<math id="A2.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="L=12" display="inline"><semantics id="A2.I1.i1.p1.2.m2.1a"><mrow id="A2.I1.i1.p1.2.m2.1.1" xref="A2.I1.i1.p1.2.m2.1.1.cmml"><mi id="A2.I1.i1.p1.2.m2.1.1.2" xref="A2.I1.i1.p1.2.m2.1.1.2.cmml">L</mi><mo id="A2.I1.i1.p1.2.m2.1.1.1" xref="A2.I1.i1.p1.2.m2.1.1.1.cmml">=</mo><mn id="A2.I1.i1.p1.2.m2.1.1.3" xref="A2.I1.i1.p1.2.m2.1.1.3.cmml">12</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.I1.i1.p1.2.m2.1b"><apply id="A2.I1.i1.p1.2.m2.1.1.cmml" xref="A2.I1.i1.p1.2.m2.1.1"><eq id="A2.I1.i1.p1.2.m2.1.1.1.cmml" xref="A2.I1.i1.p1.2.m2.1.1.1"></eq><ci id="A2.I1.i1.p1.2.m2.1.1.2.cmml" xref="A2.I1.i1.p1.2.m2.1.1.2">𝐿</ci><cn type="integer" id="A2.I1.i1.p1.2.m2.1.1.3.cmml" xref="A2.I1.i1.p1.2.m2.1.1.3">12</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i1.p1.2.m2.1c">L=12</annotation></semantics></math>) is used as a shared backbone, whose output is then passed to each task-dedicated branch, each including an additional separate <math id="A2.I1.i1.p1.3.m3.1" class="ltx_Math" alttext="L^{th}" display="inline"><semantics id="A2.I1.i1.p1.3.m3.1a"><msup id="A2.I1.i1.p1.3.m3.1.1" xref="A2.I1.i1.p1.3.m3.1.1.cmml"><mi id="A2.I1.i1.p1.3.m3.1.1.2" xref="A2.I1.i1.p1.3.m3.1.1.2.cmml">L</mi><mrow id="A2.I1.i1.p1.3.m3.1.1.3" xref="A2.I1.i1.p1.3.m3.1.1.3.cmml"><mi id="A2.I1.i1.p1.3.m3.1.1.3.2" xref="A2.I1.i1.p1.3.m3.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="A2.I1.i1.p1.3.m3.1.1.3.1" xref="A2.I1.i1.p1.3.m3.1.1.3.1.cmml">​</mo><mi id="A2.I1.i1.p1.3.m3.1.1.3.3" xref="A2.I1.i1.p1.3.m3.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A2.I1.i1.p1.3.m3.1b"><apply id="A2.I1.i1.p1.3.m3.1.1.cmml" xref="A2.I1.i1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="A2.I1.i1.p1.3.m3.1.1.1.cmml" xref="A2.I1.i1.p1.3.m3.1.1">superscript</csymbol><ci id="A2.I1.i1.p1.3.m3.1.1.2.cmml" xref="A2.I1.i1.p1.3.m3.1.1.2">𝐿</ci><apply id="A2.I1.i1.p1.3.m3.1.1.3.cmml" xref="A2.I1.i1.p1.3.m3.1.1.3"><times id="A2.I1.i1.p1.3.m3.1.1.3.1.cmml" xref="A2.I1.i1.p1.3.m3.1.1.3.1"></times><ci id="A2.I1.i1.p1.3.m3.1.1.3.2.cmml" xref="A2.I1.i1.p1.3.m3.1.1.3.2">𝑡</ci><ci id="A2.I1.i1.p1.3.m3.1.1.3.3.cmml" xref="A2.I1.i1.p1.3.m3.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i1.p1.3.m3.1c">L^{th}</annotation></semantics></math> transformer layer; each layer attention module has 12 attention heads.</p>
</div>
</li>
<li id="A2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A2.I1.i2.p1" class="ltx_para">
<p id="A2.I1.i2.p1.1" class="ltx_p"><span id="A2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">ReID global branch</span>: the ReID task is performed based on the <math id="A2.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="[cls]" display="inline"><semantics id="A2.I1.i2.p1.1.m1.1a"><mrow id="A2.I1.i2.p1.1.m1.1.1.1" xref="A2.I1.i2.p1.1.m1.1.1.2.cmml"><mo stretchy="false" id="A2.I1.i2.p1.1.m1.1.1.1.2" xref="A2.I1.i2.p1.1.m1.1.1.2.1.cmml">[</mo><mrow id="A2.I1.i2.p1.1.m1.1.1.1.1" xref="A2.I1.i2.p1.1.m1.1.1.1.1.cmml"><mi id="A2.I1.i2.p1.1.m1.1.1.1.1.2" xref="A2.I1.i2.p1.1.m1.1.1.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="A2.I1.i2.p1.1.m1.1.1.1.1.1" xref="A2.I1.i2.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="A2.I1.i2.p1.1.m1.1.1.1.1.3" xref="A2.I1.i2.p1.1.m1.1.1.1.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="A2.I1.i2.p1.1.m1.1.1.1.1.1a" xref="A2.I1.i2.p1.1.m1.1.1.1.1.1.cmml">​</mo><mi id="A2.I1.i2.p1.1.m1.1.1.1.1.4" xref="A2.I1.i2.p1.1.m1.1.1.1.1.4.cmml">s</mi></mrow><mo stretchy="false" id="A2.I1.i2.p1.1.m1.1.1.1.3" xref="A2.I1.i2.p1.1.m1.1.1.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.I1.i2.p1.1.m1.1b"><apply id="A2.I1.i2.p1.1.m1.1.1.2.cmml" xref="A2.I1.i2.p1.1.m1.1.1.1"><csymbol cd="latexml" id="A2.I1.i2.p1.1.m1.1.1.2.1.cmml" xref="A2.I1.i2.p1.1.m1.1.1.1.2">delimited-[]</csymbol><apply id="A2.I1.i2.p1.1.m1.1.1.1.1.cmml" xref="A2.I1.i2.p1.1.m1.1.1.1.1"><times id="A2.I1.i2.p1.1.m1.1.1.1.1.1.cmml" xref="A2.I1.i2.p1.1.m1.1.1.1.1.1"></times><ci id="A2.I1.i2.p1.1.m1.1.1.1.1.2.cmml" xref="A2.I1.i2.p1.1.m1.1.1.1.1.2">𝑐</ci><ci id="A2.I1.i2.p1.1.m1.1.1.1.1.3.cmml" xref="A2.I1.i2.p1.1.m1.1.1.1.1.3">𝑙</ci><ci id="A2.I1.i2.p1.1.m1.1.1.1.1.4.cmml" xref="A2.I1.i2.p1.1.m1.1.1.1.1.4">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i2.p1.1.m1.1c">[cls]</annotation></semantics></math> token alone (which is a global representation of the image features). The token is first passed through a Batch Normalization (BN) layer, whose output is first used for the triplet loss calculation and then passed to a FC layer for performing the ID cross-entropy loss computation.</p>
</div>
</li>
<li id="A2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A2.I1.i3.p1" class="ltx_para">
<p id="A2.I1.i3.p1.6" class="ltx_p"><span id="A2.I1.i3.p1.6.1" class="ltx_text ltx_font_bold">Jigsaw Branch and Jigsaw Patch Module</span>: in the Jigsaw branch, the Jigsaw Patch Module (JPM) module is applied on the output of the <math id="A2.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="L-1" display="inline"><semantics id="A2.I1.i3.p1.1.m1.1a"><mrow id="A2.I1.i3.p1.1.m1.1.1" xref="A2.I1.i3.p1.1.m1.1.1.cmml"><mi id="A2.I1.i3.p1.1.m1.1.1.2" xref="A2.I1.i3.p1.1.m1.1.1.2.cmml">L</mi><mo id="A2.I1.i3.p1.1.m1.1.1.1" xref="A2.I1.i3.p1.1.m1.1.1.1.cmml">−</mo><mn id="A2.I1.i3.p1.1.m1.1.1.3" xref="A2.I1.i3.p1.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.1.m1.1b"><apply id="A2.I1.i3.p1.1.m1.1.1.cmml" xref="A2.I1.i3.p1.1.m1.1.1"><minus id="A2.I1.i3.p1.1.m1.1.1.1.cmml" xref="A2.I1.i3.p1.1.m1.1.1.1"></minus><ci id="A2.I1.i3.p1.1.m1.1.1.2.cmml" xref="A2.I1.i3.p1.1.m1.1.1.2">𝐿</ci><cn type="integer" id="A2.I1.i3.p1.1.m1.1.1.3.cmml" xref="A2.I1.i3.p1.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.1.m1.1c">L-1</annotation></semantics></math> shared transformer layers: first the <math id="A2.I1.i3.p1.2.m2.1" class="ltx_Math" alttext="[cls]" display="inline"><semantics id="A2.I1.i3.p1.2.m2.1a"><mrow id="A2.I1.i3.p1.2.m2.1.1.1" xref="A2.I1.i3.p1.2.m2.1.1.2.cmml"><mo stretchy="false" id="A2.I1.i3.p1.2.m2.1.1.1.2" xref="A2.I1.i3.p1.2.m2.1.1.2.1.cmml">[</mo><mrow id="A2.I1.i3.p1.2.m2.1.1.1.1" xref="A2.I1.i3.p1.2.m2.1.1.1.1.cmml"><mi id="A2.I1.i3.p1.2.m2.1.1.1.1.2" xref="A2.I1.i3.p1.2.m2.1.1.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="A2.I1.i3.p1.2.m2.1.1.1.1.1" xref="A2.I1.i3.p1.2.m2.1.1.1.1.1.cmml">​</mo><mi id="A2.I1.i3.p1.2.m2.1.1.1.1.3" xref="A2.I1.i3.p1.2.m2.1.1.1.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="A2.I1.i3.p1.2.m2.1.1.1.1.1a" xref="A2.I1.i3.p1.2.m2.1.1.1.1.1.cmml">​</mo><mi id="A2.I1.i3.p1.2.m2.1.1.1.1.4" xref="A2.I1.i3.p1.2.m2.1.1.1.1.4.cmml">s</mi></mrow><mo stretchy="false" id="A2.I1.i3.p1.2.m2.1.1.1.3" xref="A2.I1.i3.p1.2.m2.1.1.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.2.m2.1b"><apply id="A2.I1.i3.p1.2.m2.1.1.2.cmml" xref="A2.I1.i3.p1.2.m2.1.1.1"><csymbol cd="latexml" id="A2.I1.i3.p1.2.m2.1.1.2.1.cmml" xref="A2.I1.i3.p1.2.m2.1.1.1.2">delimited-[]</csymbol><apply id="A2.I1.i3.p1.2.m2.1.1.1.1.cmml" xref="A2.I1.i3.p1.2.m2.1.1.1.1"><times id="A2.I1.i3.p1.2.m2.1.1.1.1.1.cmml" xref="A2.I1.i3.p1.2.m2.1.1.1.1.1"></times><ci id="A2.I1.i3.p1.2.m2.1.1.1.1.2.cmml" xref="A2.I1.i3.p1.2.m2.1.1.1.1.2">𝑐</ci><ci id="A2.I1.i3.p1.2.m2.1.1.1.1.3.cmml" xref="A2.I1.i3.p1.2.m2.1.1.1.1.3">𝑙</ci><ci id="A2.I1.i3.p1.2.m2.1.1.1.1.4.cmml" xref="A2.I1.i3.p1.2.m2.1.1.1.1.4">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.2.m2.1c">[cls]</annotation></semantics></math> token is separated from the output of the <math id="A2.I1.i3.p1.3.m3.1" class="ltx_Math" alttext="L-1" display="inline"><semantics id="A2.I1.i3.p1.3.m3.1a"><mrow id="A2.I1.i3.p1.3.m3.1.1" xref="A2.I1.i3.p1.3.m3.1.1.cmml"><mi id="A2.I1.i3.p1.3.m3.1.1.2" xref="A2.I1.i3.p1.3.m3.1.1.2.cmml">L</mi><mo id="A2.I1.i3.p1.3.m3.1.1.1" xref="A2.I1.i3.p1.3.m3.1.1.1.cmml">−</mo><mn id="A2.I1.i3.p1.3.m3.1.1.3" xref="A2.I1.i3.p1.3.m3.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.3.m3.1b"><apply id="A2.I1.i3.p1.3.m3.1.1.cmml" xref="A2.I1.i3.p1.3.m3.1.1"><minus id="A2.I1.i3.p1.3.m3.1.1.1.cmml" xref="A2.I1.i3.p1.3.m3.1.1.1"></minus><ci id="A2.I1.i3.p1.3.m3.1.1.2.cmml" xref="A2.I1.i3.p1.3.m3.1.1.2">𝐿</ci><cn type="integer" id="A2.I1.i3.p1.3.m3.1.1.3.cmml" xref="A2.I1.i3.p1.3.m3.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.3.m3.1c">L-1</annotation></semantics></math> layers, while the remaining part of the output, consisting only of the patch tokens, is randomly rearranged into four equally <math id="A2.I1.i3.p1.4.m4.1" class="ltx_Math" alttext="N/4" display="inline"><semantics id="A2.I1.i3.p1.4.m4.1a"><mrow id="A2.I1.i3.p1.4.m4.1.1" xref="A2.I1.i3.p1.4.m4.1.1.cmml"><mi id="A2.I1.i3.p1.4.m4.1.1.2" xref="A2.I1.i3.p1.4.m4.1.1.2.cmml">N</mi><mo id="A2.I1.i3.p1.4.m4.1.1.1" xref="A2.I1.i3.p1.4.m4.1.1.1.cmml">/</mo><mn id="A2.I1.i3.p1.4.m4.1.1.3" xref="A2.I1.i3.p1.4.m4.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.4.m4.1b"><apply id="A2.I1.i3.p1.4.m4.1.1.cmml" xref="A2.I1.i3.p1.4.m4.1.1"><divide id="A2.I1.i3.p1.4.m4.1.1.1.cmml" xref="A2.I1.i3.p1.4.m4.1.1.1"></divide><ci id="A2.I1.i3.p1.4.m4.1.1.2.cmml" xref="A2.I1.i3.p1.4.m4.1.1.2">𝑁</ci><cn type="integer" id="A2.I1.i3.p1.4.m4.1.1.3.cmml" xref="A2.I1.i3.p1.4.m4.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.4.m4.1c">N/4</annotation></semantics></math> sized groups. Then, the previously extracted <math id="A2.I1.i3.p1.5.m5.1" class="ltx_Math" alttext="[cls]" display="inline"><semantics id="A2.I1.i3.p1.5.m5.1a"><mrow id="A2.I1.i3.p1.5.m5.1.1.1" xref="A2.I1.i3.p1.5.m5.1.1.2.cmml"><mo stretchy="false" id="A2.I1.i3.p1.5.m5.1.1.1.2" xref="A2.I1.i3.p1.5.m5.1.1.2.1.cmml">[</mo><mrow id="A2.I1.i3.p1.5.m5.1.1.1.1" xref="A2.I1.i3.p1.5.m5.1.1.1.1.cmml"><mi id="A2.I1.i3.p1.5.m5.1.1.1.1.2" xref="A2.I1.i3.p1.5.m5.1.1.1.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="A2.I1.i3.p1.5.m5.1.1.1.1.1" xref="A2.I1.i3.p1.5.m5.1.1.1.1.1.cmml">​</mo><mi id="A2.I1.i3.p1.5.m5.1.1.1.1.3" xref="A2.I1.i3.p1.5.m5.1.1.1.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="A2.I1.i3.p1.5.m5.1.1.1.1.1a" xref="A2.I1.i3.p1.5.m5.1.1.1.1.1.cmml">​</mo><mi id="A2.I1.i3.p1.5.m5.1.1.1.1.4" xref="A2.I1.i3.p1.5.m5.1.1.1.1.4.cmml">s</mi></mrow><mo stretchy="false" id="A2.I1.i3.p1.5.m5.1.1.1.3" xref="A2.I1.i3.p1.5.m5.1.1.2.1.cmml">]</mo></mrow><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.5.m5.1b"><apply id="A2.I1.i3.p1.5.m5.1.1.2.cmml" xref="A2.I1.i3.p1.5.m5.1.1.1"><csymbol cd="latexml" id="A2.I1.i3.p1.5.m5.1.1.2.1.cmml" xref="A2.I1.i3.p1.5.m5.1.1.1.2">delimited-[]</csymbol><apply id="A2.I1.i3.p1.5.m5.1.1.1.1.cmml" xref="A2.I1.i3.p1.5.m5.1.1.1.1"><times id="A2.I1.i3.p1.5.m5.1.1.1.1.1.cmml" xref="A2.I1.i3.p1.5.m5.1.1.1.1.1"></times><ci id="A2.I1.i3.p1.5.m5.1.1.1.1.2.cmml" xref="A2.I1.i3.p1.5.m5.1.1.1.1.2">𝑐</ci><ci id="A2.I1.i3.p1.5.m5.1.1.1.1.3.cmml" xref="A2.I1.i3.p1.5.m5.1.1.1.1.3">𝑙</ci><ci id="A2.I1.i3.p1.5.m5.1.1.1.1.4.cmml" xref="A2.I1.i3.p1.5.m5.1.1.1.1.4">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.5.m5.1c">[cls]</annotation></semantics></math> token is added to each group so obtained, and each group is finally passed to <math id="A2.I1.i3.p1.6.m6.1" class="ltx_Math" alttext="L^{th}" display="inline"><semantics id="A2.I1.i3.p1.6.m6.1a"><msup id="A2.I1.i3.p1.6.m6.1.1" xref="A2.I1.i3.p1.6.m6.1.1.cmml"><mi id="A2.I1.i3.p1.6.m6.1.1.2" xref="A2.I1.i3.p1.6.m6.1.1.2.cmml">L</mi><mrow id="A2.I1.i3.p1.6.m6.1.1.3" xref="A2.I1.i3.p1.6.m6.1.1.3.cmml"><mi id="A2.I1.i3.p1.6.m6.1.1.3.2" xref="A2.I1.i3.p1.6.m6.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="A2.I1.i3.p1.6.m6.1.1.3.1" xref="A2.I1.i3.p1.6.m6.1.1.3.1.cmml">​</mo><mi id="A2.I1.i3.p1.6.m6.1.1.3.3" xref="A2.I1.i3.p1.6.m6.1.1.3.3.cmml">h</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="A2.I1.i3.p1.6.m6.1b"><apply id="A2.I1.i3.p1.6.m6.1.1.cmml" xref="A2.I1.i3.p1.6.m6.1.1"><csymbol cd="ambiguous" id="A2.I1.i3.p1.6.m6.1.1.1.cmml" xref="A2.I1.i3.p1.6.m6.1.1">superscript</csymbol><ci id="A2.I1.i3.p1.6.m6.1.1.2.cmml" xref="A2.I1.i3.p1.6.m6.1.1.2">𝐿</ci><apply id="A2.I1.i3.p1.6.m6.1.1.3.cmml" xref="A2.I1.i3.p1.6.m6.1.1.3"><times id="A2.I1.i3.p1.6.m6.1.1.3.1.cmml" xref="A2.I1.i3.p1.6.m6.1.1.3.1"></times><ci id="A2.I1.i3.p1.6.m6.1.1.3.2.cmml" xref="A2.I1.i3.p1.6.m6.1.1.3.2">𝑡</ci><ci id="A2.I1.i3.p1.6.m6.1.1.3.3.cmml" xref="A2.I1.i3.p1.6.m6.1.1.3.3">ℎ</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I1.i3.p1.6.m6.1c">L^{th}</annotation></semantics></math> transformer layer of the JPM branch; the output of the JPM branch is a set of classification tokens, one for each group. In the same way as in the global branch, each output [<span id="A2.I1.i3.p1.6.2" class="ltx_text ltx_font_italic">cls</span>] token is passed through a corresponding BN layer, whose output is used for the triplet loss calculation and then passed to the corresponding FC layer for the ID cross-entropy loss. These loss components are added to the combined loss of the global branch to be minimized. In this way, the ReID model learns more discriminative parts and becomes more robust with respect to perturbations.</p>
</div>
</li>
<li id="A2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A2.I1.i4.p1" class="ltx_para">
<p id="A2.I1.i4.p1.1" class="ltx_p"><span id="A2.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Damage branch</span>: like for the ReID task, the damage classification is performed on the [<span id="A2.I1.i4.p1.1.2" class="ltx_text ltx_font_italic">cls</span>] token alone. The token is first passed through 7 different BN layers (one per head), and each output is passed to a corresponding FC layer, one for Bend frame classification, one for Broken frame classification, and one for each missing part classification. The scores and cross-entropy losses produced by each of these heads are then combined by weighted averaging for the final damage loss.</p>
</div>
</li>
</ul>
</div>
<section id="A2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Domain adaptation</h3>

<div id="A2.SS1.p1" class="ltx_para">
<p id="A2.SS1.p1.1" class="ltx_p">The resulting architecture configurations after the addition of DANN and PADA are depicted in Fig.<a href="#A2.F16" title="Figure 16 ‣ B.1 Domain adaptation ‣ Appendix B Experimental settings ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">16</span></a> and Fig.<a href="#A2.F17" title="Figure 17 ‣ B.1 Domain adaptation ‣ Appendix B Experimental settings ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref"><span class="ltx_text ltx_ref_tag">17</span></a>, respectively.</p>
</div>
<div id="A2.SS1.p2" class="ltx_para">
<p id="A2.SS1.p2.1" class="ltx_p">Parameters used for domain adaptation are:</p>
<ul id="A2.I2" class="ltx_itemize">
<li id="A2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A2.I2.i1.p1" class="ltx_para">
<p id="A2.I2.i1.p1.2" class="ltx_p"><math id="A2.I2.i1.p1.1.m1.1" class="ltx_Math" alttext="\theta=1.0" display="inline"><semantics id="A2.I2.i1.p1.1.m1.1a"><mrow id="A2.I2.i1.p1.1.m1.1.1" xref="A2.I2.i1.p1.1.m1.1.1.cmml"><mi id="A2.I2.i1.p1.1.m1.1.1.2" xref="A2.I2.i1.p1.1.m1.1.1.2.cmml">θ</mi><mo id="A2.I2.i1.p1.1.m1.1.1.1" xref="A2.I2.i1.p1.1.m1.1.1.1.cmml">=</mo><mn id="A2.I2.i1.p1.1.m1.1.1.3" xref="A2.I2.i1.p1.1.m1.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.I2.i1.p1.1.m1.1b"><apply id="A2.I2.i1.p1.1.m1.1.1.cmml" xref="A2.I2.i1.p1.1.m1.1.1"><eq id="A2.I2.i1.p1.1.m1.1.1.1.cmml" xref="A2.I2.i1.p1.1.m1.1.1.1"></eq><ci id="A2.I2.i1.p1.1.m1.1.1.2.cmml" xref="A2.I2.i1.p1.1.m1.1.1.2">𝜃</ci><cn type="float" id="A2.I2.i1.p1.1.m1.1.1.3.cmml" xref="A2.I2.i1.p1.1.m1.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I2.i1.p1.1.m1.1c">\theta=1.0</annotation></semantics></math> as weight for the domain discriminator loss <math id="A2.I2.i1.p1.2.m2.1" class="ltx_Math" alttext="mathcal{L}_{dmn}" display="inline"><semantics id="A2.I2.i1.p1.2.m2.1a"><mrow id="A2.I2.i1.p1.2.m2.1.1" xref="A2.I2.i1.p1.2.m2.1.1.cmml"><mi id="A2.I2.i1.p1.2.m2.1.1.2" xref="A2.I2.i1.p1.2.m2.1.1.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="A2.I2.i1.p1.2.m2.1.1.1" xref="A2.I2.i1.p1.2.m2.1.1.1.cmml">​</mo><mi id="A2.I2.i1.p1.2.m2.1.1.3" xref="A2.I2.i1.p1.2.m2.1.1.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="A2.I2.i1.p1.2.m2.1.1.1a" xref="A2.I2.i1.p1.2.m2.1.1.1.cmml">​</mo><mi id="A2.I2.i1.p1.2.m2.1.1.4" xref="A2.I2.i1.p1.2.m2.1.1.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="A2.I2.i1.p1.2.m2.1.1.1b" xref="A2.I2.i1.p1.2.m2.1.1.1.cmml">​</mo><mi id="A2.I2.i1.p1.2.m2.1.1.5" xref="A2.I2.i1.p1.2.m2.1.1.5.cmml">h</mi><mo lspace="0em" rspace="0em" id="A2.I2.i1.p1.2.m2.1.1.1c" xref="A2.I2.i1.p1.2.m2.1.1.1.cmml">​</mo><mi id="A2.I2.i1.p1.2.m2.1.1.6" xref="A2.I2.i1.p1.2.m2.1.1.6.cmml">c</mi><mo lspace="0em" rspace="0em" id="A2.I2.i1.p1.2.m2.1.1.1d" xref="A2.I2.i1.p1.2.m2.1.1.1.cmml">​</mo><mi id="A2.I2.i1.p1.2.m2.1.1.7" xref="A2.I2.i1.p1.2.m2.1.1.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="A2.I2.i1.p1.2.m2.1.1.1e" xref="A2.I2.i1.p1.2.m2.1.1.1.cmml">​</mo><mi id="A2.I2.i1.p1.2.m2.1.1.8" xref="A2.I2.i1.p1.2.m2.1.1.8.cmml">l</mi><mo lspace="0em" rspace="0em" id="A2.I2.i1.p1.2.m2.1.1.1f" xref="A2.I2.i1.p1.2.m2.1.1.1.cmml">​</mo><msub id="A2.I2.i1.p1.2.m2.1.1.9" xref="A2.I2.i1.p1.2.m2.1.1.9.cmml"><mi id="A2.I2.i1.p1.2.m2.1.1.9.2" xref="A2.I2.i1.p1.2.m2.1.1.9.2.cmml">L</mi><mrow id="A2.I2.i1.p1.2.m2.1.1.9.3" xref="A2.I2.i1.p1.2.m2.1.1.9.3.cmml"><mi id="A2.I2.i1.p1.2.m2.1.1.9.3.2" xref="A2.I2.i1.p1.2.m2.1.1.9.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="A2.I2.i1.p1.2.m2.1.1.9.3.1" xref="A2.I2.i1.p1.2.m2.1.1.9.3.1.cmml">​</mo><mi id="A2.I2.i1.p1.2.m2.1.1.9.3.3" xref="A2.I2.i1.p1.2.m2.1.1.9.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="A2.I2.i1.p1.2.m2.1.1.9.3.1a" xref="A2.I2.i1.p1.2.m2.1.1.9.3.1.cmml">​</mo><mi id="A2.I2.i1.p1.2.m2.1.1.9.3.4" xref="A2.I2.i1.p1.2.m2.1.1.9.3.4.cmml">n</mi></mrow></msub></mrow><annotation-xml encoding="MathML-Content" id="A2.I2.i1.p1.2.m2.1b"><apply id="A2.I2.i1.p1.2.m2.1.1.cmml" xref="A2.I2.i1.p1.2.m2.1.1"><times id="A2.I2.i1.p1.2.m2.1.1.1.cmml" xref="A2.I2.i1.p1.2.m2.1.1.1"></times><ci id="A2.I2.i1.p1.2.m2.1.1.2.cmml" xref="A2.I2.i1.p1.2.m2.1.1.2">𝑚</ci><ci id="A2.I2.i1.p1.2.m2.1.1.3.cmml" xref="A2.I2.i1.p1.2.m2.1.1.3">𝑎</ci><ci id="A2.I2.i1.p1.2.m2.1.1.4.cmml" xref="A2.I2.i1.p1.2.m2.1.1.4">𝑡</ci><ci id="A2.I2.i1.p1.2.m2.1.1.5.cmml" xref="A2.I2.i1.p1.2.m2.1.1.5">ℎ</ci><ci id="A2.I2.i1.p1.2.m2.1.1.6.cmml" xref="A2.I2.i1.p1.2.m2.1.1.6">𝑐</ci><ci id="A2.I2.i1.p1.2.m2.1.1.7.cmml" xref="A2.I2.i1.p1.2.m2.1.1.7">𝑎</ci><ci id="A2.I2.i1.p1.2.m2.1.1.8.cmml" xref="A2.I2.i1.p1.2.m2.1.1.8">𝑙</ci><apply id="A2.I2.i1.p1.2.m2.1.1.9.cmml" xref="A2.I2.i1.p1.2.m2.1.1.9"><csymbol cd="ambiguous" id="A2.I2.i1.p1.2.m2.1.1.9.1.cmml" xref="A2.I2.i1.p1.2.m2.1.1.9">subscript</csymbol><ci id="A2.I2.i1.p1.2.m2.1.1.9.2.cmml" xref="A2.I2.i1.p1.2.m2.1.1.9.2">𝐿</ci><apply id="A2.I2.i1.p1.2.m2.1.1.9.3.cmml" xref="A2.I2.i1.p1.2.m2.1.1.9.3"><times id="A2.I2.i1.p1.2.m2.1.1.9.3.1.cmml" xref="A2.I2.i1.p1.2.m2.1.1.9.3.1"></times><ci id="A2.I2.i1.p1.2.m2.1.1.9.3.2.cmml" xref="A2.I2.i1.p1.2.m2.1.1.9.3.2">𝑑</ci><ci id="A2.I2.i1.p1.2.m2.1.1.9.3.3.cmml" xref="A2.I2.i1.p1.2.m2.1.1.9.3.3">𝑚</ci><ci id="A2.I2.i1.p1.2.m2.1.1.9.3.4.cmml" xref="A2.I2.i1.p1.2.m2.1.1.9.3.4">𝑛</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I2.i1.p1.2.m2.1c">mathcal{L}_{dmn}</annotation></semantics></math> (<a href="#A2.E3" title="3 ‣ B.1 Domain adaptation ‣ Appendix B Experimental settings ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Equation 3</span></a>).</p>
</div>
</li>
<li id="A2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A2.I2.i2.p1" class="ltx_para">
<p id="A2.I2.i2.p1.2" class="ltx_p"><math id="A2.I2.i2.p1.1.m1.1" class="ltx_Math" alttext="\delta=1.0" display="inline"><semantics id="A2.I2.i2.p1.1.m1.1a"><mrow id="A2.I2.i2.p1.1.m1.1.1" xref="A2.I2.i2.p1.1.m1.1.1.cmml"><mi id="A2.I2.i2.p1.1.m1.1.1.2" xref="A2.I2.i2.p1.1.m1.1.1.2.cmml">δ</mi><mo id="A2.I2.i2.p1.1.m1.1.1.1" xref="A2.I2.i2.p1.1.m1.1.1.1.cmml">=</mo><mn id="A2.I2.i2.p1.1.m1.1.1.3" xref="A2.I2.i2.p1.1.m1.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.I2.i2.p1.1.m1.1b"><apply id="A2.I2.i2.p1.1.m1.1.1.cmml" xref="A2.I2.i2.p1.1.m1.1.1"><eq id="A2.I2.i2.p1.1.m1.1.1.1.cmml" xref="A2.I2.i2.p1.1.m1.1.1.1"></eq><ci id="A2.I2.i2.p1.1.m1.1.1.2.cmml" xref="A2.I2.i2.p1.1.m1.1.1.2">𝛿</ci><cn type="float" id="A2.I2.i2.p1.1.m1.1.1.3.cmml" xref="A2.I2.i2.p1.1.m1.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I2.i2.p1.1.m1.1c">\delta=1.0</annotation></semantics></math> as weight for the model classification loss <math id="A2.I2.i2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{L}_{mdl}" display="inline"><semantics id="A2.I2.i2.p1.2.m2.1a"><msub id="A2.I2.i2.p1.2.m2.1.1" xref="A2.I2.i2.p1.2.m2.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="A2.I2.i2.p1.2.m2.1.1.2" xref="A2.I2.i2.p1.2.m2.1.1.2.cmml">ℒ</mi><mrow id="A2.I2.i2.p1.2.m2.1.1.3" xref="A2.I2.i2.p1.2.m2.1.1.3.cmml"><mi id="A2.I2.i2.p1.2.m2.1.1.3.2" xref="A2.I2.i2.p1.2.m2.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="A2.I2.i2.p1.2.m2.1.1.3.1" xref="A2.I2.i2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="A2.I2.i2.p1.2.m2.1.1.3.3" xref="A2.I2.i2.p1.2.m2.1.1.3.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="A2.I2.i2.p1.2.m2.1.1.3.1a" xref="A2.I2.i2.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="A2.I2.i2.p1.2.m2.1.1.3.4" xref="A2.I2.i2.p1.2.m2.1.1.3.4.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A2.I2.i2.p1.2.m2.1b"><apply id="A2.I2.i2.p1.2.m2.1.1.cmml" xref="A2.I2.i2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A2.I2.i2.p1.2.m2.1.1.1.cmml" xref="A2.I2.i2.p1.2.m2.1.1">subscript</csymbol><ci id="A2.I2.i2.p1.2.m2.1.1.2.cmml" xref="A2.I2.i2.p1.2.m2.1.1.2">ℒ</ci><apply id="A2.I2.i2.p1.2.m2.1.1.3.cmml" xref="A2.I2.i2.p1.2.m2.1.1.3"><times id="A2.I2.i2.p1.2.m2.1.1.3.1.cmml" xref="A2.I2.i2.p1.2.m2.1.1.3.1"></times><ci id="A2.I2.i2.p1.2.m2.1.1.3.2.cmml" xref="A2.I2.i2.p1.2.m2.1.1.3.2">𝑚</ci><ci id="A2.I2.i2.p1.2.m2.1.1.3.3.cmml" xref="A2.I2.i2.p1.2.m2.1.1.3.3">𝑑</ci><ci id="A2.I2.i2.p1.2.m2.1.1.3.4.cmml" xref="A2.I2.i2.p1.2.m2.1.1.3.4">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I2.i2.p1.2.m2.1c">\mathcal{L}_{mdl}</annotation></semantics></math>, when PADA is active, otherwise 0 (<a href="#A2.E3" title="3 ‣ B.1 Domain adaptation ‣ Appendix B Experimental settings ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Equation 3</span></a>).</p>
</div>
</li>
<li id="A2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A2.I2.i3.p1" class="ltx_para">
<p id="A2.I2.i3.p1.2" class="ltx_p">Gradient Reversal Layer weight <math id="A2.I2.i3.p1.1.m1.1" class="ltx_Math" alttext="\iota=1.0" display="inline"><semantics id="A2.I2.i3.p1.1.m1.1a"><mrow id="A2.I2.i3.p1.1.m1.1.1" xref="A2.I2.i3.p1.1.m1.1.1.cmml"><mi id="A2.I2.i3.p1.1.m1.1.1.2" xref="A2.I2.i3.p1.1.m1.1.1.2.cmml">ι</mi><mo id="A2.I2.i3.p1.1.m1.1.1.1" xref="A2.I2.i3.p1.1.m1.1.1.1.cmml">=</mo><mn id="A2.I2.i3.p1.1.m1.1.1.3" xref="A2.I2.i3.p1.1.m1.1.1.3.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.I2.i3.p1.1.m1.1b"><apply id="A2.I2.i3.p1.1.m1.1.1.cmml" xref="A2.I2.i3.p1.1.m1.1.1"><eq id="A2.I2.i3.p1.1.m1.1.1.1.cmml" xref="A2.I2.i3.p1.1.m1.1.1.1"></eq><ci id="A2.I2.i3.p1.1.m1.1.1.2.cmml" xref="A2.I2.i3.p1.1.m1.1.1.2">𝜄</ci><cn type="float" id="A2.I2.i3.p1.1.m1.1.1.3.cmml" xref="A2.I2.i3.p1.1.m1.1.1.3">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I2.i3.p1.1.m1.1c">\iota=1.0</annotation></semantics></math> in all DANN and PADA experiments except for the Base + Real + DANN experiment, in which <math id="A2.I2.i3.p1.2.m2.1" class="ltx_Math" alttext="\iota=10.0" display="inline"><semantics id="A2.I2.i3.p1.2.m2.1a"><mrow id="A2.I2.i3.p1.2.m2.1.1" xref="A2.I2.i3.p1.2.m2.1.1.cmml"><mi id="A2.I2.i3.p1.2.m2.1.1.2" xref="A2.I2.i3.p1.2.m2.1.1.2.cmml">ι</mi><mo id="A2.I2.i3.p1.2.m2.1.1.1" xref="A2.I2.i3.p1.2.m2.1.1.1.cmml">=</mo><mn id="A2.I2.i3.p1.2.m2.1.1.3" xref="A2.I2.i3.p1.2.m2.1.1.3.cmml">10.0</mn></mrow><annotation-xml encoding="MathML-Content" id="A2.I2.i3.p1.2.m2.1b"><apply id="A2.I2.i3.p1.2.m2.1.1.cmml" xref="A2.I2.i3.p1.2.m2.1.1"><eq id="A2.I2.i3.p1.2.m2.1.1.1.cmml" xref="A2.I2.i3.p1.2.m2.1.1.1"></eq><ci id="A2.I2.i3.p1.2.m2.1.1.2.cmml" xref="A2.I2.i3.p1.2.m2.1.1.2">𝜄</ci><cn type="float" id="A2.I2.i3.p1.2.m2.1.1.3.cmml" xref="A2.I2.i3.p1.2.m2.1.1.3">10.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.I2.i3.p1.2.m2.1c">\iota=10.0</annotation></semantics></math> (<a href="#A2.E3" title="3 ‣ B.1 Domain adaptation ‣ Appendix B Experimental settings ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Equation 3</span></a>).</p>
</div>
</li>
</ul>
</div>
<div id="A2.SS1.p3" class="ltx_para">
<table id="A2.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="A2.E3.m1.1" class="ltx_Math" alttext="\mathcal{L}_{D\_tot}=\mathcal{L}_{D}+\theta\mathcal{L}_{dmn}+\delta\mathcal{L}_{mdl}-\iota\frac{\partial\mathcal{L}_{DMN}}{\partial f_{g}}" display="block"><semantics id="A2.E3.m1.1a"><mrow id="A2.E3.m1.1.1" xref="A2.E3.m1.1.1.cmml"><msub id="A2.E3.m1.1.1.2" xref="A2.E3.m1.1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="A2.E3.m1.1.1.2.2" xref="A2.E3.m1.1.1.2.2.cmml">ℒ</mi><mrow id="A2.E3.m1.1.1.2.3" xref="A2.E3.m1.1.1.2.3.cmml"><mi id="A2.E3.m1.1.1.2.3.2" xref="A2.E3.m1.1.1.2.3.2.cmml">D</mi><mo lspace="0em" rspace="0em" id="A2.E3.m1.1.1.2.3.1" xref="A2.E3.m1.1.1.2.3.1.cmml">​</mo><mi mathvariant="normal" id="A2.E3.m1.1.1.2.3.3" xref="A2.E3.m1.1.1.2.3.3.cmml">_</mi><mo lspace="0em" rspace="0em" id="A2.E3.m1.1.1.2.3.1a" xref="A2.E3.m1.1.1.2.3.1.cmml">​</mo><mi id="A2.E3.m1.1.1.2.3.4" xref="A2.E3.m1.1.1.2.3.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="A2.E3.m1.1.1.2.3.1b" xref="A2.E3.m1.1.1.2.3.1.cmml">​</mo><mi id="A2.E3.m1.1.1.2.3.5" xref="A2.E3.m1.1.1.2.3.5.cmml">o</mi><mo lspace="0em" rspace="0em" id="A2.E3.m1.1.1.2.3.1c" xref="A2.E3.m1.1.1.2.3.1.cmml">​</mo><mi id="A2.E3.m1.1.1.2.3.6" xref="A2.E3.m1.1.1.2.3.6.cmml">t</mi></mrow></msub><mo id="A2.E3.m1.1.1.1" xref="A2.E3.m1.1.1.1.cmml">=</mo><mrow id="A2.E3.m1.1.1.3" xref="A2.E3.m1.1.1.3.cmml"><mrow id="A2.E3.m1.1.1.3.2" xref="A2.E3.m1.1.1.3.2.cmml"><msub id="A2.E3.m1.1.1.3.2.2" xref="A2.E3.m1.1.1.3.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="A2.E3.m1.1.1.3.2.2.2" xref="A2.E3.m1.1.1.3.2.2.2.cmml">ℒ</mi><mi id="A2.E3.m1.1.1.3.2.2.3" xref="A2.E3.m1.1.1.3.2.2.3.cmml">D</mi></msub><mo id="A2.E3.m1.1.1.3.2.1" xref="A2.E3.m1.1.1.3.2.1.cmml">+</mo><mrow id="A2.E3.m1.1.1.3.2.3" xref="A2.E3.m1.1.1.3.2.3.cmml"><mi id="A2.E3.m1.1.1.3.2.3.2" xref="A2.E3.m1.1.1.3.2.3.2.cmml">θ</mi><mo lspace="0em" rspace="0em" id="A2.E3.m1.1.1.3.2.3.1" xref="A2.E3.m1.1.1.3.2.3.1.cmml">​</mo><msub id="A2.E3.m1.1.1.3.2.3.3" xref="A2.E3.m1.1.1.3.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A2.E3.m1.1.1.3.2.3.3.2" xref="A2.E3.m1.1.1.3.2.3.3.2.cmml">ℒ</mi><mrow id="A2.E3.m1.1.1.3.2.3.3.3" xref="A2.E3.m1.1.1.3.2.3.3.3.cmml"><mi id="A2.E3.m1.1.1.3.2.3.3.3.2" xref="A2.E3.m1.1.1.3.2.3.3.3.2.cmml">d</mi><mo lspace="0em" rspace="0em" id="A2.E3.m1.1.1.3.2.3.3.3.1" xref="A2.E3.m1.1.1.3.2.3.3.3.1.cmml">​</mo><mi id="A2.E3.m1.1.1.3.2.3.3.3.3" xref="A2.E3.m1.1.1.3.2.3.3.3.3.cmml">m</mi><mo lspace="0em" rspace="0em" id="A2.E3.m1.1.1.3.2.3.3.3.1a" xref="A2.E3.m1.1.1.3.2.3.3.3.1.cmml">​</mo><mi id="A2.E3.m1.1.1.3.2.3.3.3.4" xref="A2.E3.m1.1.1.3.2.3.3.3.4.cmml">n</mi></mrow></msub></mrow><mo id="A2.E3.m1.1.1.3.2.1a" xref="A2.E3.m1.1.1.3.2.1.cmml">+</mo><mrow id="A2.E3.m1.1.1.3.2.4" xref="A2.E3.m1.1.1.3.2.4.cmml"><mi id="A2.E3.m1.1.1.3.2.4.2" xref="A2.E3.m1.1.1.3.2.4.2.cmml">δ</mi><mo lspace="0em" rspace="0em" id="A2.E3.m1.1.1.3.2.4.1" xref="A2.E3.m1.1.1.3.2.4.1.cmml">​</mo><msub id="A2.E3.m1.1.1.3.2.4.3" xref="A2.E3.m1.1.1.3.2.4.3.cmml"><mi class="ltx_font_mathcaligraphic" id="A2.E3.m1.1.1.3.2.4.3.2" xref="A2.E3.m1.1.1.3.2.4.3.2.cmml">ℒ</mi><mrow id="A2.E3.m1.1.1.3.2.4.3.3" xref="A2.E3.m1.1.1.3.2.4.3.3.cmml"><mi id="A2.E3.m1.1.1.3.2.4.3.3.2" xref="A2.E3.m1.1.1.3.2.4.3.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="A2.E3.m1.1.1.3.2.4.3.3.1" xref="A2.E3.m1.1.1.3.2.4.3.3.1.cmml">​</mo><mi id="A2.E3.m1.1.1.3.2.4.3.3.3" xref="A2.E3.m1.1.1.3.2.4.3.3.3.cmml">d</mi><mo lspace="0em" rspace="0em" id="A2.E3.m1.1.1.3.2.4.3.3.1a" xref="A2.E3.m1.1.1.3.2.4.3.3.1.cmml">​</mo><mi id="A2.E3.m1.1.1.3.2.4.3.3.4" xref="A2.E3.m1.1.1.3.2.4.3.3.4.cmml">l</mi></mrow></msub></mrow></mrow><mo id="A2.E3.m1.1.1.3.1" xref="A2.E3.m1.1.1.3.1.cmml">−</mo><mrow id="A2.E3.m1.1.1.3.3" xref="A2.E3.m1.1.1.3.3.cmml"><mi id="A2.E3.m1.1.1.3.3.2" xref="A2.E3.m1.1.1.3.3.2.cmml">ι</mi><mo lspace="0em" rspace="0em" id="A2.E3.m1.1.1.3.3.1" xref="A2.E3.m1.1.1.3.3.1.cmml">​</mo><mfrac id="A2.E3.m1.1.1.3.3.3" xref="A2.E3.m1.1.1.3.3.3.cmml"><mrow id="A2.E3.m1.1.1.3.3.3.2" xref="A2.E3.m1.1.1.3.3.3.2.cmml"><mo rspace="0em" id="A2.E3.m1.1.1.3.3.3.2.1" xref="A2.E3.m1.1.1.3.3.3.2.1.cmml">∂</mo><msub id="A2.E3.m1.1.1.3.3.3.2.2" xref="A2.E3.m1.1.1.3.3.3.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="A2.E3.m1.1.1.3.3.3.2.2.2" xref="A2.E3.m1.1.1.3.3.3.2.2.2.cmml">ℒ</mi><mrow id="A2.E3.m1.1.1.3.3.3.2.2.3" xref="A2.E3.m1.1.1.3.3.3.2.2.3.cmml"><mi id="A2.E3.m1.1.1.3.3.3.2.2.3.2" xref="A2.E3.m1.1.1.3.3.3.2.2.3.2.cmml">D</mi><mo lspace="0em" rspace="0em" id="A2.E3.m1.1.1.3.3.3.2.2.3.1" xref="A2.E3.m1.1.1.3.3.3.2.2.3.1.cmml">​</mo><mi id="A2.E3.m1.1.1.3.3.3.2.2.3.3" xref="A2.E3.m1.1.1.3.3.3.2.2.3.3.cmml">M</mi><mo lspace="0em" rspace="0em" id="A2.E3.m1.1.1.3.3.3.2.2.3.1a" xref="A2.E3.m1.1.1.3.3.3.2.2.3.1.cmml">​</mo><mi id="A2.E3.m1.1.1.3.3.3.2.2.3.4" xref="A2.E3.m1.1.1.3.3.3.2.2.3.4.cmml">N</mi></mrow></msub></mrow><mrow id="A2.E3.m1.1.1.3.3.3.3" xref="A2.E3.m1.1.1.3.3.3.3.cmml"><mo rspace="0em" id="A2.E3.m1.1.1.3.3.3.3.1" xref="A2.E3.m1.1.1.3.3.3.3.1.cmml">∂</mo><msub id="A2.E3.m1.1.1.3.3.3.3.2" xref="A2.E3.m1.1.1.3.3.3.3.2.cmml"><mi id="A2.E3.m1.1.1.3.3.3.3.2.2" xref="A2.E3.m1.1.1.3.3.3.3.2.2.cmml">f</mi><mi id="A2.E3.m1.1.1.3.3.3.3.2.3" xref="A2.E3.m1.1.1.3.3.3.3.2.3.cmml">g</mi></msub></mrow></mfrac></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="A2.E3.m1.1b"><apply id="A2.E3.m1.1.1.cmml" xref="A2.E3.m1.1.1"><eq id="A2.E3.m1.1.1.1.cmml" xref="A2.E3.m1.1.1.1"></eq><apply id="A2.E3.m1.1.1.2.cmml" xref="A2.E3.m1.1.1.2"><csymbol cd="ambiguous" id="A2.E3.m1.1.1.2.1.cmml" xref="A2.E3.m1.1.1.2">subscript</csymbol><ci id="A2.E3.m1.1.1.2.2.cmml" xref="A2.E3.m1.1.1.2.2">ℒ</ci><apply id="A2.E3.m1.1.1.2.3.cmml" xref="A2.E3.m1.1.1.2.3"><times id="A2.E3.m1.1.1.2.3.1.cmml" xref="A2.E3.m1.1.1.2.3.1"></times><ci id="A2.E3.m1.1.1.2.3.2.cmml" xref="A2.E3.m1.1.1.2.3.2">𝐷</ci><ci id="A2.E3.m1.1.1.2.3.3.cmml" xref="A2.E3.m1.1.1.2.3.3">_</ci><ci id="A2.E3.m1.1.1.2.3.4.cmml" xref="A2.E3.m1.1.1.2.3.4">𝑡</ci><ci id="A2.E3.m1.1.1.2.3.5.cmml" xref="A2.E3.m1.1.1.2.3.5">𝑜</ci><ci id="A2.E3.m1.1.1.2.3.6.cmml" xref="A2.E3.m1.1.1.2.3.6">𝑡</ci></apply></apply><apply id="A2.E3.m1.1.1.3.cmml" xref="A2.E3.m1.1.1.3"><minus id="A2.E3.m1.1.1.3.1.cmml" xref="A2.E3.m1.1.1.3.1"></minus><apply id="A2.E3.m1.1.1.3.2.cmml" xref="A2.E3.m1.1.1.3.2"><plus id="A2.E3.m1.1.1.3.2.1.cmml" xref="A2.E3.m1.1.1.3.2.1"></plus><apply id="A2.E3.m1.1.1.3.2.2.cmml" xref="A2.E3.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="A2.E3.m1.1.1.3.2.2.1.cmml" xref="A2.E3.m1.1.1.3.2.2">subscript</csymbol><ci id="A2.E3.m1.1.1.3.2.2.2.cmml" xref="A2.E3.m1.1.1.3.2.2.2">ℒ</ci><ci id="A2.E3.m1.1.1.3.2.2.3.cmml" xref="A2.E3.m1.1.1.3.2.2.3">𝐷</ci></apply><apply id="A2.E3.m1.1.1.3.2.3.cmml" xref="A2.E3.m1.1.1.3.2.3"><times id="A2.E3.m1.1.1.3.2.3.1.cmml" xref="A2.E3.m1.1.1.3.2.3.1"></times><ci id="A2.E3.m1.1.1.3.2.3.2.cmml" xref="A2.E3.m1.1.1.3.2.3.2">𝜃</ci><apply id="A2.E3.m1.1.1.3.2.3.3.cmml" xref="A2.E3.m1.1.1.3.2.3.3"><csymbol cd="ambiguous" id="A2.E3.m1.1.1.3.2.3.3.1.cmml" xref="A2.E3.m1.1.1.3.2.3.3">subscript</csymbol><ci id="A2.E3.m1.1.1.3.2.3.3.2.cmml" xref="A2.E3.m1.1.1.3.2.3.3.2">ℒ</ci><apply id="A2.E3.m1.1.1.3.2.3.3.3.cmml" xref="A2.E3.m1.1.1.3.2.3.3.3"><times id="A2.E3.m1.1.1.3.2.3.3.3.1.cmml" xref="A2.E3.m1.1.1.3.2.3.3.3.1"></times><ci id="A2.E3.m1.1.1.3.2.3.3.3.2.cmml" xref="A2.E3.m1.1.1.3.2.3.3.3.2">𝑑</ci><ci id="A2.E3.m1.1.1.3.2.3.3.3.3.cmml" xref="A2.E3.m1.1.1.3.2.3.3.3.3">𝑚</ci><ci id="A2.E3.m1.1.1.3.2.3.3.3.4.cmml" xref="A2.E3.m1.1.1.3.2.3.3.3.4">𝑛</ci></apply></apply></apply><apply id="A2.E3.m1.1.1.3.2.4.cmml" xref="A2.E3.m1.1.1.3.2.4"><times id="A2.E3.m1.1.1.3.2.4.1.cmml" xref="A2.E3.m1.1.1.3.2.4.1"></times><ci id="A2.E3.m1.1.1.3.2.4.2.cmml" xref="A2.E3.m1.1.1.3.2.4.2">𝛿</ci><apply id="A2.E3.m1.1.1.3.2.4.3.cmml" xref="A2.E3.m1.1.1.3.2.4.3"><csymbol cd="ambiguous" id="A2.E3.m1.1.1.3.2.4.3.1.cmml" xref="A2.E3.m1.1.1.3.2.4.3">subscript</csymbol><ci id="A2.E3.m1.1.1.3.2.4.3.2.cmml" xref="A2.E3.m1.1.1.3.2.4.3.2">ℒ</ci><apply id="A2.E3.m1.1.1.3.2.4.3.3.cmml" xref="A2.E3.m1.1.1.3.2.4.3.3"><times id="A2.E3.m1.1.1.3.2.4.3.3.1.cmml" xref="A2.E3.m1.1.1.3.2.4.3.3.1"></times><ci id="A2.E3.m1.1.1.3.2.4.3.3.2.cmml" xref="A2.E3.m1.1.1.3.2.4.3.3.2">𝑚</ci><ci id="A2.E3.m1.1.1.3.2.4.3.3.3.cmml" xref="A2.E3.m1.1.1.3.2.4.3.3.3">𝑑</ci><ci id="A2.E3.m1.1.1.3.2.4.3.3.4.cmml" xref="A2.E3.m1.1.1.3.2.4.3.3.4">𝑙</ci></apply></apply></apply></apply><apply id="A2.E3.m1.1.1.3.3.cmml" xref="A2.E3.m1.1.1.3.3"><times id="A2.E3.m1.1.1.3.3.1.cmml" xref="A2.E3.m1.1.1.3.3.1"></times><ci id="A2.E3.m1.1.1.3.3.2.cmml" xref="A2.E3.m1.1.1.3.3.2">𝜄</ci><apply id="A2.E3.m1.1.1.3.3.3.cmml" xref="A2.E3.m1.1.1.3.3.3"><divide id="A2.E3.m1.1.1.3.3.3.1.cmml" xref="A2.E3.m1.1.1.3.3.3"></divide><apply id="A2.E3.m1.1.1.3.3.3.2.cmml" xref="A2.E3.m1.1.1.3.3.3.2"><partialdiff id="A2.E3.m1.1.1.3.3.3.2.1.cmml" xref="A2.E3.m1.1.1.3.3.3.2.1"></partialdiff><apply id="A2.E3.m1.1.1.3.3.3.2.2.cmml" xref="A2.E3.m1.1.1.3.3.3.2.2"><csymbol cd="ambiguous" id="A2.E3.m1.1.1.3.3.3.2.2.1.cmml" xref="A2.E3.m1.1.1.3.3.3.2.2">subscript</csymbol><ci id="A2.E3.m1.1.1.3.3.3.2.2.2.cmml" xref="A2.E3.m1.1.1.3.3.3.2.2.2">ℒ</ci><apply id="A2.E3.m1.1.1.3.3.3.2.2.3.cmml" xref="A2.E3.m1.1.1.3.3.3.2.2.3"><times id="A2.E3.m1.1.1.3.3.3.2.2.3.1.cmml" xref="A2.E3.m1.1.1.3.3.3.2.2.3.1"></times><ci id="A2.E3.m1.1.1.3.3.3.2.2.3.2.cmml" xref="A2.E3.m1.1.1.3.3.3.2.2.3.2">𝐷</ci><ci id="A2.E3.m1.1.1.3.3.3.2.2.3.3.cmml" xref="A2.E3.m1.1.1.3.3.3.2.2.3.3">𝑀</ci><ci id="A2.E3.m1.1.1.3.3.3.2.2.3.4.cmml" xref="A2.E3.m1.1.1.3.3.3.2.2.3.4">𝑁</ci></apply></apply></apply><apply id="A2.E3.m1.1.1.3.3.3.3.cmml" xref="A2.E3.m1.1.1.3.3.3.3"><partialdiff id="A2.E3.m1.1.1.3.3.3.3.1.cmml" xref="A2.E3.m1.1.1.3.3.3.3.1"></partialdiff><apply id="A2.E3.m1.1.1.3.3.3.3.2.cmml" xref="A2.E3.m1.1.1.3.3.3.3.2"><csymbol cd="ambiguous" id="A2.E3.m1.1.1.3.3.3.3.2.1.cmml" xref="A2.E3.m1.1.1.3.3.3.3.2">subscript</csymbol><ci id="A2.E3.m1.1.1.3.3.3.3.2.2.cmml" xref="A2.E3.m1.1.1.3.3.3.3.2.2">𝑓</ci><ci id="A2.E3.m1.1.1.3.3.3.3.2.3.cmml" xref="A2.E3.m1.1.1.3.3.3.3.2.3">𝑔</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.E3.m1.1c">\mathcal{L}_{D\_tot}=\mathcal{L}_{D}+\theta\mathcal{L}_{dmn}+\delta\mathcal{L}_{mdl}-\iota\frac{\partial\mathcal{L}_{DMN}}{\partial f_{g}}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
</div>
<figure id="A2.F16" class="ltx_figure"><img src="/html/2304.07883/assets/x12.png" id="A2.F16.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="528" height="207" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F16.2.1.1" class="ltx_text" style="font-size:90%;">Figure 16</span>: </span><span id="A2.F16.3.2" class="ltx_text" style="font-size:90%;"> TransReI3D architecture with the addition of DANN components.</span></figcaption>
</figure>
<figure id="A2.F17" class="ltx_figure"><img src="/html/2304.07883/assets/x13.png" id="A2.F17.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="475" height="160" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A2.F17.2.1.1" class="ltx_text" style="font-size:90%;">Figure 17</span>: </span><span id="A2.F17.3.2" class="ltx_text" style="font-size:90%;"> TransReI3D architecture with the addition of the PADA module.</span></figcaption>
</figure>
</section>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Additional results</h2>

<section id="A3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Retrieval examples</h3>

<div id="A3.SS1.p1" class="ltx_para">
<p id="A3.SS1.p1.1" class="ltx_p"><a href="#A3.F18" title="Figure 18 ‣ C.1 Retrieval examples ‣ Appendix C Additional results ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 18</span></a> depicts some example predictions of TransReI3D on the ReID task.</p>
</div>
<figure id="A3.F18" class="ltx_figure"><img src="/html/2304.07883/assets/x14.png" id="A3.F18.g1" class="ltx_graphics ltx_img_square" width="528" height="627" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A3.F18.2.1.1" class="ltx_text" style="font-size:90%;">Figure 18</span>: </span><span id="A3.F18.3.2" class="ltx_text" style="font-size:90%;">Retrieval results (Top-5 images) for the Baseline configuration, and corresponding model, bike ID, similarity scores. In most cases, the correct result (shown with a green border) is within the Top-5 predictions.</span></figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>Effect of the background on ReID and DD tasks</h3>

<div id="A3.SS2.p1" class="ltx_para">
<p id="A3.SS2.p1.1" class="ltx_p">In this section, we report additional experiments with different backgrounds to understand its effect on the ReID and DD tasks. Specifically, we compared three techniques: (i) the use of HDRI images, with random camera position, to generate the background, as detailed in Section 3; (ii) randomly picking an image from Places365 as background, and (iii) the use of a simple uniform background. To generate samples with Places365 images as backgrounds, we leveraged the original pipeline to render an auxiliary image with a transparent background and overlay it over the photo taken from the dataset. Examples are shown in <a href="#A3.F19" title="Figure 19 ‣ C.2 Effect of the background on ReID and DD tasks ‣ Appendix C Additional results ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 19</span></a>. It should be noticed that the proposed pipeline leverages a limited number of 360° HDRI maps, and even if the proposed pipeline can generate a virtually infinite number of backgrounds by varying the bike position, camera and illumination, the backgrounds will be visually correlated. On the other hand, Places365 contains a much wider range of scenes, but since the bike is randomly positioned, the resulting blend is not always realistic, and the foreground and background are not as consistent as with HDRI maps.</p>
</div>
<figure id="A3.F19" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A3.F19.1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/images/Places_1.png" id="A3.F19.1.g1" class="ltx_graphics ltx_img_landscape" width="685" height="229" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A3.F19.2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/images/Places_2.png" id="A3.F19.2.g1" class="ltx_graphics ltx_img_landscape" width="685" height="229" alt="Refer to caption">
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A3.F19.3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/images/Places_3.png" id="A3.F19.3.g1" class="ltx_graphics ltx_img_landscape" width="685" height="229" alt="Refer to caption">
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F19.5.1.1" class="ltx_text" style="font-size:90%;">Figure 19</span>: </span><span id="A3.F19.6.2" class="ltx_text" style="font-size:90%;">Examples of synthetic bike rendering placed against a 360 HDR background, a uniform background, and random scene from the Places365 dataset.</span></figcaption>
</figure>
<div id="A3.SS2.p2" class="ltx_para">
<p id="A3.SS2.p2.3" class="ltx_p">In <a href="#A3.T3" title="Table 3 ‣ C.2 Effect of the background on ReID and DD tasks ‣ Appendix C Additional results ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Table 3</span></a>, we evaluate the ability of TransReI3D to generalize to the real domain in the following transfer scenarios: <math id="A3.SS2.p2.1.m1.1" class="ltx_Math" alttext="\text{HDRI}\to\text{Real}" display="inline"><semantics id="A3.SS2.p2.1.m1.1a"><mrow id="A3.SS2.p2.1.m1.1.1" xref="A3.SS2.p2.1.m1.1.1.cmml"><mtext id="A3.SS2.p2.1.m1.1.1.2" xref="A3.SS2.p2.1.m1.1.1.2a.cmml">HDRI</mtext><mo stretchy="false" id="A3.SS2.p2.1.m1.1.1.1" xref="A3.SS2.p2.1.m1.1.1.1.cmml">→</mo><mtext id="A3.SS2.p2.1.m1.1.1.3" xref="A3.SS2.p2.1.m1.1.1.3a.cmml">Real</mtext></mrow><annotation-xml encoding="MathML-Content" id="A3.SS2.p2.1.m1.1b"><apply id="A3.SS2.p2.1.m1.1.1.cmml" xref="A3.SS2.p2.1.m1.1.1"><ci id="A3.SS2.p2.1.m1.1.1.1.cmml" xref="A3.SS2.p2.1.m1.1.1.1">→</ci><ci id="A3.SS2.p2.1.m1.1.1.2a.cmml" xref="A3.SS2.p2.1.m1.1.1.2"><mtext id="A3.SS2.p2.1.m1.1.1.2.cmml" xref="A3.SS2.p2.1.m1.1.1.2">HDRI</mtext></ci><ci id="A3.SS2.p2.1.m1.1.1.3a.cmml" xref="A3.SS2.p2.1.m1.1.1.3"><mtext id="A3.SS2.p2.1.m1.1.1.3.cmml" xref="A3.SS2.p2.1.m1.1.1.3">Real</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p2.1.m1.1c">\text{HDRI}\to\text{Real}</annotation></semantics></math>, <math id="A3.SS2.p2.2.m2.1" class="ltx_Math" alttext="\text{Places365}\to\text{Real}" display="inline"><semantics id="A3.SS2.p2.2.m2.1a"><mrow id="A3.SS2.p2.2.m2.1.1" xref="A3.SS2.p2.2.m2.1.1.cmml"><mtext id="A3.SS2.p2.2.m2.1.1.2" xref="A3.SS2.p2.2.m2.1.1.2a.cmml">Places365</mtext><mo stretchy="false" id="A3.SS2.p2.2.m2.1.1.1" xref="A3.SS2.p2.2.m2.1.1.1.cmml">→</mo><mtext id="A3.SS2.p2.2.m2.1.1.3" xref="A3.SS2.p2.2.m2.1.1.3a.cmml">Real</mtext></mrow><annotation-xml encoding="MathML-Content" id="A3.SS2.p2.2.m2.1b"><apply id="A3.SS2.p2.2.m2.1.1.cmml" xref="A3.SS2.p2.2.m2.1.1"><ci id="A3.SS2.p2.2.m2.1.1.1.cmml" xref="A3.SS2.p2.2.m2.1.1.1">→</ci><ci id="A3.SS2.p2.2.m2.1.1.2a.cmml" xref="A3.SS2.p2.2.m2.1.1.2"><mtext id="A3.SS2.p2.2.m2.1.1.2.cmml" xref="A3.SS2.p2.2.m2.1.1.2">Places365</mtext></ci><ci id="A3.SS2.p2.2.m2.1.1.3a.cmml" xref="A3.SS2.p2.2.m2.1.1.3"><mtext id="A3.SS2.p2.2.m2.1.1.3.cmml" xref="A3.SS2.p2.2.m2.1.1.3">Real</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p2.2.m2.1c">\text{Places365}\to\text{Real}</annotation></semantics></math> and <math id="A3.SS2.p2.3.m3.1" class="ltx_Math" alttext="\text{Uniform}\to\text{Real}" display="inline"><semantics id="A3.SS2.p2.3.m3.1a"><mrow id="A3.SS2.p2.3.m3.1.1" xref="A3.SS2.p2.3.m3.1.1.cmml"><mtext id="A3.SS2.p2.3.m3.1.1.2" xref="A3.SS2.p2.3.m3.1.1.2a.cmml">Uniform</mtext><mo stretchy="false" id="A3.SS2.p2.3.m3.1.1.1" xref="A3.SS2.p2.3.m3.1.1.1.cmml">→</mo><mtext id="A3.SS2.p2.3.m3.1.1.3" xref="A3.SS2.p2.3.m3.1.1.3a.cmml">Real</mtext></mrow><annotation-xml encoding="MathML-Content" id="A3.SS2.p2.3.m3.1b"><apply id="A3.SS2.p2.3.m3.1.1.cmml" xref="A3.SS2.p2.3.m3.1.1"><ci id="A3.SS2.p2.3.m3.1.1.1.cmml" xref="A3.SS2.p2.3.m3.1.1.1">→</ci><ci id="A3.SS2.p2.3.m3.1.1.2a.cmml" xref="A3.SS2.p2.3.m3.1.1.2"><mtext id="A3.SS2.p2.3.m3.1.1.2.cmml" xref="A3.SS2.p2.3.m3.1.1.2">Uniform</mtext></ci><ci id="A3.SS2.p2.3.m3.1.1.3a.cmml" xref="A3.SS2.p2.3.m3.1.1.3"><mtext id="A3.SS2.p2.3.m3.1.1.3.cmml" xref="A3.SS2.p2.3.m3.1.1.3">Real</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p2.3.m3.1c">\text{Uniform}\to\text{Real}</annotation></semantics></math>. We found moderately better results when employing the HDRI results, although when real images are available at training time, with HDRI yielding a marginal improvement over Places365.</p>
</div>
<div id="A3.SS2.p3" class="ltx_para">
<p id="A3.SS2.p3.2" class="ltx_p">We further assess the ability to transfer across synthetic domains, specifically we evaluate the following scenarios: <math id="A3.SS2.p3.1.m1.1" class="ltx_Math" alttext="\text{Places 365}\to\text{HDRI}" display="inline"><semantics id="A3.SS2.p3.1.m1.1a"><mrow id="A3.SS2.p3.1.m1.1.1" xref="A3.SS2.p3.1.m1.1.1.cmml"><mtext id="A3.SS2.p3.1.m1.1.1.2" xref="A3.SS2.p3.1.m1.1.1.2a.cmml">Places 365</mtext><mo stretchy="false" id="A3.SS2.p3.1.m1.1.1.1" xref="A3.SS2.p3.1.m1.1.1.1.cmml">→</mo><mtext id="A3.SS2.p3.1.m1.1.1.3" xref="A3.SS2.p3.1.m1.1.1.3a.cmml">HDRI</mtext></mrow><annotation-xml encoding="MathML-Content" id="A3.SS2.p3.1.m1.1b"><apply id="A3.SS2.p3.1.m1.1.1.cmml" xref="A3.SS2.p3.1.m1.1.1"><ci id="A3.SS2.p3.1.m1.1.1.1.cmml" xref="A3.SS2.p3.1.m1.1.1.1">→</ci><ci id="A3.SS2.p3.1.m1.1.1.2a.cmml" xref="A3.SS2.p3.1.m1.1.1.2"><mtext id="A3.SS2.p3.1.m1.1.1.2.cmml" xref="A3.SS2.p3.1.m1.1.1.2">Places 365</mtext></ci><ci id="A3.SS2.p3.1.m1.1.1.3a.cmml" xref="A3.SS2.p3.1.m1.1.1.3"><mtext id="A3.SS2.p3.1.m1.1.1.3.cmml" xref="A3.SS2.p3.1.m1.1.1.3">HDRI</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p3.1.m1.1c">\text{Places 365}\to\text{HDRI}</annotation></semantics></math> and <math id="A3.SS2.p3.2.m2.1" class="ltx_Math" alttext="\text{Uniform}\to\text{HDRI}" display="inline"><semantics id="A3.SS2.p3.2.m2.1a"><mrow id="A3.SS2.p3.2.m2.1.1" xref="A3.SS2.p3.2.m2.1.1.cmml"><mtext id="A3.SS2.p3.2.m2.1.1.2" xref="A3.SS2.p3.2.m2.1.1.2a.cmml">Uniform</mtext><mo stretchy="false" id="A3.SS2.p3.2.m2.1.1.1" xref="A3.SS2.p3.2.m2.1.1.1.cmml">→</mo><mtext id="A3.SS2.p3.2.m2.1.1.3" xref="A3.SS2.p3.2.m2.1.1.3a.cmml">HDRI</mtext></mrow><annotation-xml encoding="MathML-Content" id="A3.SS2.p3.2.m2.1b"><apply id="A3.SS2.p3.2.m2.1.1.cmml" xref="A3.SS2.p3.2.m2.1.1"><ci id="A3.SS2.p3.2.m2.1.1.1.cmml" xref="A3.SS2.p3.2.m2.1.1.1">→</ci><ci id="A3.SS2.p3.2.m2.1.1.2a.cmml" xref="A3.SS2.p3.2.m2.1.1.2"><mtext id="A3.SS2.p3.2.m2.1.1.2.cmml" xref="A3.SS2.p3.2.m2.1.1.2">Uniform</mtext></ci><ci id="A3.SS2.p3.2.m2.1.1.3a.cmml" xref="A3.SS2.p3.2.m2.1.1.3"><mtext id="A3.SS2.p3.2.m2.1.1.3.cmml" xref="A3.SS2.p3.2.m2.1.1.3">HDRI</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS2.p3.2.m2.1c">\text{Uniform}\to\text{HDRI}</annotation></semantics></math>. We found that the network generalizes quite well across different strategies to insert the background, as long as it is not uniform. In the latter case, the performance significantly drops as the network is no longer able to separate the bike from the background.</p>
</div>
<div id="A3.SS2.p4" class="ltx_para">
<p id="A3.SS2.p4.1" class="ltx_p">Based on these results, we conclude that the proposed pipeline contains sufficiently varied backgrounds, and the higher consistency improves the generalization capabilities.</p>
</div>
<figure id="A3.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table"><span id="A3.T3.9.3.1" class="ltx_text" style="font-size:90%;">Table 3</span>: </span><span id="A3.T3.4.2" class="ltx_text" style="font-size:90%;">TransReI3D performance on the validation set with different strategies to generate the background. The network was trained on synthetic data except for <math id="A3.T3.3.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="A3.T3.3.1.m1.1b"><mo id="A3.T3.3.1.m1.1.1" xref="A3.T3.3.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="A3.T3.3.1.m1.1c"><ci id="A3.T3.3.1.m1.1.1.cmml" xref="A3.T3.3.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.3.1.m1.1d">\dagger</annotation></semantics></math> (labeled real images available at training time) and <math id="A3.T3.4.2.m2.1" class="ltx_Math" alttext="\ddagger" display="inline"><semantics id="A3.T3.4.2.m2.1b"><mo id="A3.T3.4.2.m2.1.1" xref="A3.T3.4.2.m2.1.1.cmml">‡</mo><annotation-xml encoding="MathML-Content" id="A3.T3.4.2.m2.1c"><ci id="A3.T3.4.2.m2.1.1.cmml" xref="A3.T3.4.2.m2.1.1">‡</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.4.2.m2.1d">\ddagger</annotation></semantics></math> (unlabelled real images available at training time). </span></figcaption>
<div id="A3.T3.7" class="ltx_inline-block ltx_transformed_outer" style="width:496.9pt;height:112.3pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(9.5pt,-2.1pt) scale(1.03971838237276,1.03971838237276) ;">
<table id="A3.T3.7.3" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A3.T3.7.3.4.1" class="ltx_tr">
<th id="A3.T3.7.3.4.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="A3.T3.7.3.4.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="6">
<span id="A3.T3.7.3.4.1.2.1" class="ltx_ERROR undefined">\cellcolor</span>[HTML]EFEFEF<span id="A3.T3.7.3.4.1.2.2" class="ltx_text ltx_font_bold">Validation</span>
</td>
</tr>
<tr id="A3.T3.7.3.5.2" class="ltx_tr">
<th id="A3.T3.7.3.5.2.1" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="A3.T3.7.3.5.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="2"><span id="A3.T3.7.3.5.2.2.1" class="ltx_text ltx_font_bold">Damage Detection</span></td>
<td id="A3.T3.7.3.5.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="4"><span id="A3.T3.7.3.5.2.3.1" class="ltx_text ltx_font_bold">Re-identification (Synthetic)</span></td>
</tr>
<tr id="A3.T3.7.3.6.3" class="ltx_tr">
<th id="A3.T3.7.3.6.3.1" class="ltx_td ltx_th ltx_th_row ltx_border_r"></th>
<td id="A3.T3.7.3.6.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A3.T3.7.3.6.3.2.1" class="ltx_text ltx_font_bold">Real AUC</span></td>
<td id="A3.T3.7.3.6.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A3.T3.7.3.6.3.3.1" class="ltx_text ltx_font_bold">Synthetic AUC</span></td>
<td id="A3.T3.7.3.6.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A3.T3.7.3.6.3.4.1" class="ltx_text ltx_font_bold">mAP</span></td>
<td id="A3.T3.7.3.6.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A3.T3.7.3.6.3.5.1" class="ltx_text ltx_font_bold">CMC-1</span></td>
<td id="A3.T3.7.3.6.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A3.T3.7.3.6.3.6.1" class="ltx_text ltx_font_bold">CMC-5</span></td>
<td id="A3.T3.7.3.6.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A3.T3.7.3.6.3.7.1" class="ltx_text ltx_font_bold">CMC-10</span></td>
</tr>
<tr id="A3.T3.5.1.1" class="ltx_tr">
<th id="A3.T3.5.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">BG HDRI + Real<sup id="A3.T3.5.1.1.1.1" class="ltx_sup"><math id="A3.T3.5.1.1.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="A3.T3.5.1.1.1.1.m1.1a"><mo id="A3.T3.5.1.1.1.1.m1.1.1" xref="A3.T3.5.1.1.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="A3.T3.5.1.1.1.1.m1.1b"><ci id="A3.T3.5.1.1.1.1.m1.1.1.cmml" xref="A3.T3.5.1.1.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.5.1.1.1.1.m1.1c">\dagger</annotation></semantics></math></sup>
</th>
<td id="A3.T3.5.1.1.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A3.T3.5.1.1.2.1" class="ltx_text ltx_font_bold">97.3 ± 2.2</span></td>
<td id="A3.T3.5.1.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A3.T3.5.1.1.3.1" class="ltx_text ltx_font_bold">91.4 ± 0.2</span></td>
<td id="A3.T3.5.1.1.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A3.T3.5.1.1.4.1" class="ltx_text ltx_font_bold">85.3 ± 0.2</span></td>
<td id="A3.T3.5.1.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="A3.T3.5.1.1.5.1" class="ltx_text ltx_font_bold">79.4 ± 0.1</span></td>
<td id="A3.T3.5.1.1.6" class="ltx_td ltx_align_center ltx_border_t"><span id="A3.T3.5.1.1.6.1" class="ltx_text ltx_font_bold">92.9 ± 0.4</span></td>
<td id="A3.T3.5.1.1.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="A3.T3.5.1.1.7.1" class="ltx_text ltx_font_bold">96.6 ± 0.4</span></td>
</tr>
<tr id="A3.T3.6.2.2" class="ltx_tr">
<th id="A3.T3.6.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">BG Places365 + Real <sup id="A3.T3.6.2.2.1.1" class="ltx_sup"><math id="A3.T3.6.2.2.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="A3.T3.6.2.2.1.1.m1.1a"><mo id="A3.T3.6.2.2.1.1.m1.1.1" xref="A3.T3.6.2.2.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="A3.T3.6.2.2.1.1.m1.1b"><ci id="A3.T3.6.2.2.1.1.m1.1.1.cmml" xref="A3.T3.6.2.2.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.6.2.2.1.1.m1.1c">\dagger</annotation></semantics></math></sup>
</th>
<td id="A3.T3.6.2.2.2" class="ltx_td ltx_align_center ltx_border_t">96.3 ± 1.9</td>
<td id="A3.T3.6.2.2.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">90.4 ± 0.2</td>
<td id="A3.T3.6.2.2.4" class="ltx_td ltx_align_center ltx_border_t">85 ± 0</td>
<td id="A3.T3.6.2.2.5" class="ltx_td ltx_align_center ltx_border_t">79.0 ± 0.4</td>
<td id="A3.T3.6.2.2.6" class="ltx_td ltx_align_center ltx_border_t">92.8 ± 0.3</td>
<td id="A3.T3.6.2.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">96.3 ± 0.2</td>
</tr>
<tr id="A3.T3.7.3.3" class="ltx_tr">
<th id="A3.T3.7.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r">BG Uniform + Real <sup id="A3.T3.7.3.3.1.1" class="ltx_sup"><math id="A3.T3.7.3.3.1.1.m1.1" class="ltx_Math" alttext="\dagger" display="inline"><semantics id="A3.T3.7.3.3.1.1.m1.1a"><mo id="A3.T3.7.3.3.1.1.m1.1.1" xref="A3.T3.7.3.3.1.1.m1.1.1.cmml">†</mo><annotation-xml encoding="MathML-Content" id="A3.T3.7.3.3.1.1.m1.1b"><ci id="A3.T3.7.3.3.1.1.m1.1.1.cmml" xref="A3.T3.7.3.3.1.1.m1.1.1">†</ci></annotation-xml><annotation encoding="application/x-tex" id="A3.T3.7.3.3.1.1.m1.1c">\dagger</annotation></semantics></math></sup>
</th>
<td id="A3.T3.7.3.3.2" class="ltx_td ltx_align_center ltx_border_b">95.2 ± 3.4</td>
<td id="A3.T3.7.3.3.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">87.4 ± 1.5</td>
<td id="A3.T3.7.3.3.4" class="ltx_td ltx_align_center ltx_border_b">48.5 ± 3.4</td>
<td id="A3.T3.7.3.3.5" class="ltx_td ltx_align_center ltx_border_b">39.2 ± 1.9</td>
<td id="A3.T3.7.3.3.6" class="ltx_td ltx_align_center ltx_border_b">59.4 ± 5.6</td>
<td id="A3.T3.7.3.3.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">66.0 ± 5.7</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.3 </span>Additional explainability and t-SNE plot</h3>

<div id="A3.SS3.p1" class="ltx_para">
<p id="A3.SS3.p1.1" class="ltx_p">The t-SNE plots of the [<span id="A3.SS3.p1.1.1" class="ltx_text ltx_font_italic">cls</span>] token extracted from the backbone (<a href="#A3.F20" title="Figure 20 ‣ C.3 Additional explainability and t-SNE plot ‣ Appendix C Additional results ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 20</span></a>) show partial overlap between the real and synthetic domains, and highlight how real images from various sources yield very different distributions.</p>
</div>
<figure id="A3.F20" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A3.F20.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/x15.png" id="A3.F20.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="528" height="528" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F20.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="A3.F20.sf1.3.2" class="ltx_text" style="font-size:90%;">Baseline</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A3.F20.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/x16.png" id="A3.F20.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="528" height="528" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F20.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="A3.F20.sf2.3.2" class="ltx_text" style="font-size:90%;">BL + Real</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A3.F20.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/x17.png" id="A3.F20.sf3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="528" height="528" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F20.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="A3.F20.sf3.3.2" class="ltx_text" style="font-size:90%;">BL + R + DANN</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A3.F20.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/x18.png" id="A3.F20.sf4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="528" height="528" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F20.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="A3.F20.sf4.3.2" class="ltx_text" style="font-size:90%;">BL + R + PADA</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F20.6.1.1" class="ltx_text" style="font-size:90%;">Figure 20</span>: </span><span id="A3.F20.7.2" class="ltx_text" style="font-size:90%;">t-SNE plot of the [<span id="A3.F20.7.2.1" class="ltx_text ltx_font_italic">cls</span>] token extracted from the DD branch under different training regimes. <span id="A3.F20.7.2.2" class="ltx_text" style="color:#5F57DB;">•</span> DelftBikes (real) <span id="A3.F20.7.2.3" class="ltx_text" style="color:#57DB5F;">•</span> Web scraping (real) <span id="A3.F20.7.2.4" class="ltx_text" style="color:#DB5F57;">•</span> BBBicycles (synth) </span></figcaption>
</figure>
<div id="A3.SS3.p2" class="ltx_para">
<p id="A3.SS3.p2.1" class="ltx_p">The t-SNE plots in <a href="#A3.F21" title="Figure 21 ‣ C.3 Additional explainability and t-SNE plot ‣ Appendix C Additional results ‣ Bent &amp; Broken Bicycles: Leveraging synthetic data for damaged object re-identification" class="ltx_ref ltx_refmacro_autoref"><span class="ltx_text ltx_ref_tag">Figure 21</span></a> illustrate the distribution of the [<span id="A3.SS3.p2.1.1" class="ltx_text ltx_font_italic">cls</span>] tokens from the DD branch and the backbone. By comparing synthetic damaged (red) and undamaged (cyan) examples, it can be seen how the backbone captures features related to the bike model and invariant to the presence of damage, whereas the DD branch clearly distinguishes damaged vs. non-damaged bikes.</p>
</div>
<figure id="A3.F21" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A3.F21.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/x19.png" id="A3.F21.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="528" height="528" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F21.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="A3.F21.sf1.3.2" class="ltx_text" style="font-size:90%;">Damage branch</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="A3.F21.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/x20.png" id="A3.F21.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="528" height="528" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F21.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="A3.F21.sf2.3.2" class="ltx_text" style="font-size:90%;">Backbone</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="A3.F21.7.1.1" class="ltx_text" style="font-size:90%;">Figure 21</span>: </span><span id="A3.F21.8.2" class="ltx_text" style="font-size:90%;">t-SNE plot of the [<span id="A3.F21.8.2.1" class="ltx_text ltx_font_italic">cls</span>] token extracted from DD branch (a) and backbone (b) for damaged and non-damaged bike instances (BL + Real setting). <span id="A3.F21.8.2.2" class="ltx_text" style="color:#57D3DB;">•</span> Synthetic no damage <span id="A3.F21.8.2.3" class="ltx_text" style="color:#DB5F57;">•</span> Synthetic damaged <span id="A3.F21.8.2.4" class="ltx_text" style="color:#DB57D3;">•</span> Real no damage <span id="A3.F21.8.2.5" class="ltx_text" style="color:#57DB5F;">•</span> Real damaged </span></figcaption>
</figure>
<figure id="A3.F22" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A3.F22.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/x21.png" id="A3.F22.sf1.g1" class="ltx_graphics ltx_centering ltx_img_square" width="528" height="528" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F22.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="A3.F22.sf1.3.2" class="ltx_text" style="font-size:90%;">BL + Real</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A3.F22.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/x22.png" id="A3.F22.sf2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="528" height="528" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F22.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="A3.F22.sf2.3.2" class="ltx_text" style="font-size:90%;">BL + Real + DANN</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="A3.F22.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2304.07883/assets/x23.png" id="A3.F22.sf3.g1" class="ltx_graphics ltx_centering ltx_img_square" width="528" height="528" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F22.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="A3.F22.sf3.3.2" class="ltx_text" style="font-size:90%;">BL + Real + PADA</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="A3.F22.4.2.1" class="ltx_text" style="font-size:90%;">Figure 22</span>: </span><span id="A3.F22.2.1" class="ltx_text" style="font-size:90%;">Attention maps of TransReI3D under different training regimes. Values for Bent frame labels (y) and predictions (<math id="A3.F22.2.1.m1.1" class="ltx_Math" alttext="\hat{y}" display="inline"><semantics id="A3.F22.2.1.m1.1b"><mover accent="true" id="A3.F22.2.1.m1.1.1" xref="A3.F22.2.1.m1.1.1.cmml"><mi id="A3.F22.2.1.m1.1.1.2" xref="A3.F22.2.1.m1.1.1.2.cmml">y</mi><mo id="A3.F22.2.1.m1.1.1.1" xref="A3.F22.2.1.m1.1.1.1.cmml">^</mo></mover><annotation-xml encoding="MathML-Content" id="A3.F22.2.1.m1.1c"><apply id="A3.F22.2.1.m1.1.1.cmml" xref="A3.F22.2.1.m1.1.1"><ci id="A3.F22.2.1.m1.1.1.1.cmml" xref="A3.F22.2.1.m1.1.1.1">^</ci><ci id="A3.F22.2.1.m1.1.1.2.cmml" xref="A3.F22.2.1.m1.1.1.2">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.F22.2.1.m1.1d">\hat{y}</annotation></semantics></math>) are superimposed on the image. </span></figcaption>
</figure>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2304.07882" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2304.07883" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2304.07883">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2304.07883" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2304.07884" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Feb 29 14:11:01 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
