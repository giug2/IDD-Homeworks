<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server</title>
<!--Generated on Thu Oct 10 03:58:46 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.05725v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S1" title="In KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S2" title="In KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S2.SS1" title="In 2 Related Work ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Privacy Concerns with Fine-tuning on Private Data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S2.SS2" title="In 2 Related Work ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Synthetic Text Generation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S3" title="In KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S3.SS1" title="In 3 Method ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Problem Setup</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S3.SS2" title="In 3 Method ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>System Overview</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S3.SS3" title="In 3 Method ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Client Side</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S3.SS3.SSS0.Px1" title="In 3.3 Client Side ‣ 3 Method ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">DP-based Local Learning.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S3.SS3.SSS0.Px2" title="In 3.3 Client Side ‣ 3 Method ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">LoRA Adaptation.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S3.SS4" title="In 3 Method ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.4 </span>Server Side</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S3.SS4.SSS0.Px1" title="In 3.4 Server Side ‣ 3 Method ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Synthetic Instructions Generation.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S3.SS4.SSS0.Px2" title="In 3.4 Server Side ‣ 3 Method ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Synthetic Instruction Filtration.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S3.SS4.SSS0.Px3" title="In 3.4 Server Side ‣ 3 Method ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Efficient Knowledge Distillation.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S3.SS5" title="In 3 Method ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.5 </span>Communication between Client &amp; Server</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S3.SS5.SSS0.Px1" title="In 3.5 Communication between Client &amp; Server ‣ 3 Method ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Federated Model Transmission.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S3.SS5.SSS0.Px2" title="In 3.5 Communication between Client &amp; Server ‣ 3 Method ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Proposed Transmitting Unit.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4" title="In KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS1" title="In 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Basic Setups</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS1.SSS0.Px1" title="In 4.1 Basic Setups ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Models and Datasets.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS1.SSS0.Px2" title="In 4.1 Basic Setups ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Baselines.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS2" title="In 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Privacy Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS2.SSS0.Px1" title="In 4.2 Privacy Evaluation ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Setups.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS2.SSS0.Px2" title="In 4.2 Privacy Evaluation ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Results.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS3" title="In 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Financial Benchmarks</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS3.SSS0.Px1" title="In 4.3 Financial Benchmarks ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Setups.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS3.SSS0.Px2" title="In 4.3 Financial Benchmarks ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Results.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS4" title="In 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.4 </span>Medical Free-Form Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS4.SSS0.Px1" title="In 4.4 Medical Free-Form Evaluation ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Setups.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS4.SSS0.Px2" title="In 4.4 Medical Free-Form Evaluation ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Results.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS5" title="In 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.5 </span>Data Quality Measurement.</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS5.SSS0.Px1" title="In 4.5 Data Quality Measurement. ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Embedding Distribution Similarity.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS5.SSS0.Px2" title="In 4.5 Data Quality Measurement. ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Instruction Following Difficulty.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS5.SSS0.Px3" title="In 4.5 Data Quality Measurement. ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Results.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS6" title="In 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.6 </span>Ablation on Dataset Size</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS6.SSS0.Px1" title="In 4.6 Ablation on Dataset Size ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Setups.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS6.SSS0.Px2" title="In 4.6 Ablation on Dataset Size ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Results.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS7" title="In 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.7 </span>Transmitting Unit</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS7.SSS0.Px1" title="In 4.7 Transmitting Unit ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Setups.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS7.SSS0.Px2" title="In 4.7 Transmitting Unit ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Results.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S5" title="In KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Discussions</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S5.SS1" title="In 5 Discussions ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Why not Scrubbing</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S5.SS2" title="In 5 Discussions ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Why not DP-SGD only</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S6" title="In KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Conclusions</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S7" title="In KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Limitations</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A1" title="In KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Privacy Analysis</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A1.SS1" title="In Appendix A Privacy Analysis ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.1 </span>Potential Privacy Risks</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A1.SS2" title="In Appendix A Privacy Analysis ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.2 </span>Theoretical Privacy Elaborations</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A1.SS2.SSS0.Px1" title="In A.2 Theoretical Privacy Elaborations ‣ Appendix A Privacy Analysis ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Interchangeability of Models.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A1.SS2.SSS0.Px2" title="In A.2 Theoretical Privacy Elaborations ‣ Appendix A Privacy Analysis ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Theoretical Guarantee of Differential Privacy.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A1.SS3" title="In Appendix A Privacy Analysis ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A.3 </span>Experimental Results</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A1.SS3.SSS0.Px1" title="In A.3 Experimental Results ‣ Appendix A Privacy Analysis ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Setups.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A1.SS3.SSS0.Px2" title="In A.3 Experimental Results ‣ Appendix A Privacy Analysis ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Results.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A2" title="In KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Additional Techniques</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A2.SS1" title="In Appendix B Additional Techniques ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.1 </span>Filtration with Models</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A2.SS2" title="In Appendix B Additional Techniques ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B.2 </span>Name Substitution</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A3" title="In KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Additional Experiments</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A3.SS1" title="In Appendix C Additional Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.1 </span>Medical Benchmarks</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A3.SS1.SSS0.Px1" title="In C.1 Medical Benchmarks ‣ Appendix C Additional Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Setups.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A3.SS1.SSS0.Px2" title="In C.1 Medical Benchmarks ‣ Appendix C Additional Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Results.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A3.SS1.SSS0.Px3" title="In C.1 Medical Benchmarks ‣ Appendix C Additional Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Distinctions in Medical Evaluations.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A3.SS2" title="In Appendix C Additional Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.2 </span>DP-SGD Performance Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A3.SS3" title="In Appendix C Additional Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C.3 </span>Generalizability in Other Domains</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A3.SS3.SSS0.Px1" title="In C.3 Generalizability in Other Domains ‣ Appendix C Additional Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Setups.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A3.SS3.SSS0.Px2" title="In C.3 Generalizability in Other Domains ‣ Appendix C Additional Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Results.</span></a></li>
</ol>
</li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A4" title="In KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>Definition of PII</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A5" title="In KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E </span>Differences of Domain-Specific Data from General Data</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A5.SS1" title="In Appendix E Differences of Domain-Specific Data from General Data ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.1 </span>Illustration</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A5.SS2" title="In Appendix E Differences of Domain-Specific Data from General Data ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">E.2 </span>Gap Ratio</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A6" title="In KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F </span>Implementation Details</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A6.SS1" title="In Appendix F Implementation Details ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F.1 </span>Training Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A6.SS2" title="In Appendix F Implementation Details ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F.2 </span>Inferencing Details</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A6.SS3" title="In Appendix F Implementation Details ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">F.3 </span>Baselines</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix">
<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A7" title="In KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">G </span>Deployment Guidance</span></a>
<ol class="ltx_toclist ltx_toclist_appendix">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A7.SS0.SSS0.Px1" title="In Appendix G Deployment Guidance ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Preparations and Transmitting Unit.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A7.SS0.SSS0.Px2" title="In Appendix G Deployment Guidance ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Client Side.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A7.SS0.SSS0.Px3" title="In Appendix G Deployment Guidance ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title">Server Side.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A8" title="In KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">H </span>Templates</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
<span class="ltx_text ltx_font_bold" id="id1.1.id1">Wenhao Wang<sup class="ltx_sup" id="id1.1.id1.1">1,3,4</sup></span>,
<span class="ltx_text ltx_font_bold" id="id2.2.id2">Xiaoyu Liang<sup class="ltx_sup" id="id2.2.id2.1">1</sup></span>,
<span class="ltx_text ltx_font_bold" id="id3.3.id3">Rui Ye<sup class="ltx_sup" id="id3.3.id3.1">2,4</sup></span>,
<span class="ltx_text ltx_font_bold" id="id4.4.id4">Jingyi Chai<sup class="ltx_sup" id="id4.4.id4.1">2,4</sup></span>, 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id5.5.id5">Siheng Chen<sup class="ltx_sup" id="id5.5.id5.1">2,3,4 *</sup></span>,
<span class="ltx_text ltx_font_bold" id="id6.6.id6">Yanfeng Wang<sup class="ltx_sup" id="id6.6.id6.1">2,3 *</sup></span>,

<br class="ltx_break"/><sup class="ltx_sup" id="id7.7.id7">1</sup>Zhejiang University,
<sup class="ltx_sup" id="id8.8.id8">2</sup>Shanghai Jiao Tong University, 
<br class="ltx_break"/><sup class="ltx_sup" id="id9.9.id9">3</sup>Shanghai AI Laboratory, 
<br class="ltx_break"/><sup class="ltx_sup" id="id10.10.id10">4</sup>Multi-Agent Governance &amp; Intelligence Crew (MAGIC)

<br class="ltx_break"/>12321254@zju.edu.cn
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id11.id1">The success of large language models (LLMs) facilitate many parties to fine-tune LLMs on their own private data. However, this practice raises privacy concerns due to the memorization of LLMs.
Existing solutions, such as utilizing synthetic data for substitution, struggle to simultaneously improve performance and preserve privacy.
They either rely on a local model for generation, resulting in a performance decline, or take advantage of APIs, directly exposing the data to API servers.
To address this issue, we propose <span class="ltx_text ltx_font_italic" id="id11.id1.1">KnowledgeSG</span>, a novel client-server framework which enhances synthetic data quality and improves model performance while ensuring privacy.
We achieve this by learning local knowledge from the private data with differential privacy (DP) and distilling professional knowledge from the server. Additionally, inspired by federated learning, we transmit models rather than data between the client and server to prevent privacy leakage.
Extensive experiments in medical and financial domains demonstrate the effectiveness of <span class="ltx_text ltx_font_italic" id="id11.id1.2">KnowledgeSG</span>. Our code is now publicly available at <a class="ltx_ref ltx_href" href="https://github.com/wwh0411/KnowledgeSG" title="">https://github.com/wwh0411/KnowledgeSG</a>.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.1">
<p class="ltx_p" id="p1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1.1">KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.1.2" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.1.2.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.2.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.2.1.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1.1">
Wenhao Wang<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.1">1,3,4</sup>,
Xiaoyu Liang<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.2">1</sup>,
Rui Ye<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.3">2,4</sup>,
Jingyi Chai<sup class="ltx_sup" id="p1.1.2.1.1.1.1.1.1.4">2,4</sup>,</span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.2.2">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.2.2.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.2.2.1.1">Siheng Chen<sup class="ltx_sup" id="p1.1.2.1.1.2.2.1.1.1">2,3,4 *</sup></span>,
<span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.2.2.1.2">Yanfeng Wang<sup class="ltx_sup" id="p1.1.2.1.1.2.2.1.2.1">2,3 *</sup></span>,</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.3.3">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.3.3.1"><sup class="ltx_sup" id="p1.1.2.1.1.3.3.1.1">1</sup>Zhejiang University,
<sup class="ltx_sup" id="p1.1.2.1.1.3.3.1.2">2</sup>Shanghai Jiao Tong University,</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.4.4">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.4.4.1"><sup class="ltx_sup" id="p1.1.2.1.1.4.4.1.1">3</sup>Shanghai AI Laboratory,</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.5.5">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.5.5.1"><sup class="ltx_sup" id="p1.1.2.1.1.5.5.1.1">4</sup>Multi-Agent Governance &amp; Intelligence Crew (MAGIC)</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.6.6">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.6.6.1">12321254@zju.edu.cn</span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<span class="ltx_note ltx_role_footnotetext" id="footnotex1"><sup class="ltx_note_mark">$*$</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">$*$</sup><span class="ltx_note_type">footnotetext: </span>Corresponding author.</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">The world has witnessed the tremendous success of large language models (LLMs) across a variety of tasks <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib58" title="">2023b</a>); OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib47" title="">2023</a>)</cite>.
Such success has attracted numerous parties to fine-tune their customized LLMs by leveraging their local private data <cite class="ltx_cite ltx_citemacro_cite">Wu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib63" title="">2023</a>); Xue et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib67" title="">2023</a>); Zhou et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib81" title="">2024</a>); Singhal et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib55" title="">2023</a>)</cite>.
Nonetheless, training such LLMs on private data could cause significant privacy concerns, since LLMs are shown to memorize sensitive information from the training data <cite class="ltx_cite ltx_citemacro_cite">Carlini et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib6" title="">2021</a>); Lukas et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib39" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">To address this privacy issue, a series of methods have been proposed to circumvent the direct usage of private data by
using synthetic data for substitution <cite class="ltx_cite ltx_citemacro_cite">Xie et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib65" title="">2024</a>); Yue et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib75" title="">2023</a>); Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib32" title="">2024a</a>)</cite>. Specifically, some methods use Application Programming Interface (APIs) to generate diverse instructions, directly exposing private data to the API server <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib61" title="">2022</a>)</cite>. While others rely solely on a local base model, which leads to a quality degradation in synthetic data and eventually lower model performance <cite class="ltx_cite ltx_citemacro_cite">Kurakin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib30" title="">2024</a>)</cite>.
Therefore, existing methods suffer from the trade-off between privacy risk and model performance.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="425" id="S1.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The dilemma of current synthetic data methods. API-based methods involve more privacy risks while methods based on local models face performance degradation due to lower synthetic data quality.</figcaption>
</figure>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">In this work, we aim to efficiently enhance synthetic data quality
while maintaining strict privacy protection. To achieve this goal, we propose <span class="ltx_text ltx_font_italic" id="S1.p3.1.1">KnowledgeSG</span> (<span class="ltx_text ltx_font_bold" id="S1.p3.1.2">Knowledge</span>-based <span class="ltx_text ltx_font_bold" id="S1.p3.1.3">S</span>ynthetic data <span class="ltx_text ltx_font_bold" id="S1.p3.1.4">G</span>eneration), a novel client-server framework which leverages a professional server to assist the local client in data generation under theoretical privacy guarantee.
Our framework compensates the quality gap between synthetic and original data observed in previous works <cite class="ltx_cite ltx_citemacro_cite">Jordon et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib28" title="">2022</a>); Arnold and Neunhoeffer (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib3" title="">2021</a>)</cite> by efficiently distilling knowledge from the professional model deployed on the server, rather than relying merely on the local model.
Additionally, unlike API-based methods, we draw inspiration from federated learning <cite class="ltx_cite ltx_citemacro_cite">McMahan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib44" title="">2017</a>)</cite> by transmitting model weights instead of data for knowledge exchange, thereby improving privacy protection.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Specifically, on the client side, we fine-tune the local model with differentially privacy (DP) to learn local knowledge from private data within a privacy budget.
For convenient and secure communication between the client and server, we transmit only the LoRA <cite class="ltx_cite ltx_citemacro_cite">Hu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib22" title="">2021</a>)</cite> adapter of the DP-finetuned model instead of directly transmitting private data.
On the server side, raw synthetic instructions are first generated using the uploaded local model. These instructions are then judged by the professional model for quality filtration in an efficient manner <cite class="ltx_cite ltx_citemacro_cite">Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib25" title="">2023</a>)</cite>. Once filtered, the top instructions are fed directly into the professional model to generate accurate responses, bypassing the need to generate potentially incorrect responses from the local model.
Finally, the DP-finetuned local model is further optimized by fine-tuning it with the top instructions and corresponding responses to boost its performance. Upon completion, the optimized model is transmitted back to the client, concluding the entire process.
</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">We conduct a series of experiments on two privacy-sensitive domains: medicine and finance. The results prove the effectiveness of our proposed framework on both privacy and performance benchmarks.
It is worth mentioning that our method gains a relative improvement of <math alttext="120.39\%" class="ltx_Math" display="inline" id="S1.p5.1.m1.1"><semantics id="S1.p5.1.m1.1a"><mrow id="S1.p5.1.m1.1.1" xref="S1.p5.1.m1.1.1.cmml"><mn id="S1.p5.1.m1.1.1.2" xref="S1.p5.1.m1.1.1.2.cmml">120.39</mn><mo id="S1.p5.1.m1.1.1.1" xref="S1.p5.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S1.p5.1.m1.1b"><apply id="S1.p5.1.m1.1.1.cmml" xref="S1.p5.1.m1.1.1"><csymbol cd="latexml" id="S1.p5.1.m1.1.1.1.cmml" xref="S1.p5.1.m1.1.1.1">percent</csymbol><cn id="S1.p5.1.m1.1.1.2.cmml" type="float" xref="S1.p5.1.m1.1.1.2">120.39</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.p5.1.m1.1c">120.39\%</annotation><annotation encoding="application/x-llamapun" id="S1.p5.1.m1.1d">120.39 %</annotation></semantics></math> than Non-Private training measured by medical free-form evaluation, even surpassing AlpaCare <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib77" title="">2023</a>)</cite>, the professional model we deploy.
To conclude, our main contributions are:</p>
<ol class="ltx_enumerate" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We propose a novel privacy-preserving client-server framework called <span class="ltx_text ltx_font_italic" id="S1.I1.i1.p1.1.1">KnowledgeSG</span>, which enhances synthetic data quality by leveraging server-side knowledge distillation to assist the client in data generation.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We propose a novel server-side synthetic data generation method that employs a professional model to distill knowledge by providing both judgments and corrections for the raw synthetic data.
</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">Extensive experiments validate the effectiveness of our proposed framework.</p>
</div>
</li>
</ol>
</div>
<figure class="ltx_figure" id="S1.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="415" id="S1.F2.g1" src="x2.png" width="747"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Overview of <span class="ltx_text ltx_font_italic" id="S1.F2.16.1">KnowledgeSG</span>’s system architecture. <math alttext="\mathbb{W}_{Loc}" class="ltx_Math" display="inline" id="S1.F2.8.m1.1"><semantics id="S1.F2.8.m1.1b"><msub id="S1.F2.8.m1.1.1" xref="S1.F2.8.m1.1.1.cmml"><mi id="S1.F2.8.m1.1.1.2" xref="S1.F2.8.m1.1.1.2.cmml">𝕎</mi><mrow id="S1.F2.8.m1.1.1.3" xref="S1.F2.8.m1.1.1.3.cmml"><mi id="S1.F2.8.m1.1.1.3.2" xref="S1.F2.8.m1.1.1.3.2.cmml">L</mi><mo id="S1.F2.8.m1.1.1.3.1" xref="S1.F2.8.m1.1.1.3.1.cmml">⁢</mo><mi id="S1.F2.8.m1.1.1.3.3" xref="S1.F2.8.m1.1.1.3.3.cmml">o</mi><mo id="S1.F2.8.m1.1.1.3.1b" xref="S1.F2.8.m1.1.1.3.1.cmml">⁢</mo><mi id="S1.F2.8.m1.1.1.3.4" xref="S1.F2.8.m1.1.1.3.4.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S1.F2.8.m1.1c"><apply id="S1.F2.8.m1.1.1.cmml" xref="S1.F2.8.m1.1.1"><csymbol cd="ambiguous" id="S1.F2.8.m1.1.1.1.cmml" xref="S1.F2.8.m1.1.1">subscript</csymbol><ci id="S1.F2.8.m1.1.1.2.cmml" xref="S1.F2.8.m1.1.1.2">𝕎</ci><apply id="S1.F2.8.m1.1.1.3.cmml" xref="S1.F2.8.m1.1.1.3"><times id="S1.F2.8.m1.1.1.3.1.cmml" xref="S1.F2.8.m1.1.1.3.1"></times><ci id="S1.F2.8.m1.1.1.3.2.cmml" xref="S1.F2.8.m1.1.1.3.2">𝐿</ci><ci id="S1.F2.8.m1.1.1.3.3.cmml" xref="S1.F2.8.m1.1.1.3.3">𝑜</ci><ci id="S1.F2.8.m1.1.1.3.4.cmml" xref="S1.F2.8.m1.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.8.m1.1d">\mathbb{W}_{Loc}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.8.m1.1e">blackboard_W start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT</annotation></semantics></math>: the local base model; <math alttext="\mathbb{W}_{DP}" class="ltx_Math" display="inline" id="S1.F2.9.m2.1"><semantics id="S1.F2.9.m2.1b"><msub id="S1.F2.9.m2.1.1" xref="S1.F2.9.m2.1.1.cmml"><mi id="S1.F2.9.m2.1.1.2" xref="S1.F2.9.m2.1.1.2.cmml">𝕎</mi><mrow id="S1.F2.9.m2.1.1.3" xref="S1.F2.9.m2.1.1.3.cmml"><mi id="S1.F2.9.m2.1.1.3.2" xref="S1.F2.9.m2.1.1.3.2.cmml">D</mi><mo id="S1.F2.9.m2.1.1.3.1" xref="S1.F2.9.m2.1.1.3.1.cmml">⁢</mo><mi id="S1.F2.9.m2.1.1.3.3" xref="S1.F2.9.m2.1.1.3.3.cmml">P</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S1.F2.9.m2.1c"><apply id="S1.F2.9.m2.1.1.cmml" xref="S1.F2.9.m2.1.1"><csymbol cd="ambiguous" id="S1.F2.9.m2.1.1.1.cmml" xref="S1.F2.9.m2.1.1">subscript</csymbol><ci id="S1.F2.9.m2.1.1.2.cmml" xref="S1.F2.9.m2.1.1.2">𝕎</ci><apply id="S1.F2.9.m2.1.1.3.cmml" xref="S1.F2.9.m2.1.1.3"><times id="S1.F2.9.m2.1.1.3.1.cmml" xref="S1.F2.9.m2.1.1.3.1"></times><ci id="S1.F2.9.m2.1.1.3.2.cmml" xref="S1.F2.9.m2.1.1.3.2">𝐷</ci><ci id="S1.F2.9.m2.1.1.3.3.cmml" xref="S1.F2.9.m2.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.9.m2.1d">\mathbb{W}_{DP}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.9.m2.1e">blackboard_W start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT</annotation></semantics></math>: DP-finetuned <math alttext="\mathbb{W}_{Loc}" class="ltx_Math" display="inline" id="S1.F2.10.m3.1"><semantics id="S1.F2.10.m3.1b"><msub id="S1.F2.10.m3.1.1" xref="S1.F2.10.m3.1.1.cmml"><mi id="S1.F2.10.m3.1.1.2" xref="S1.F2.10.m3.1.1.2.cmml">𝕎</mi><mrow id="S1.F2.10.m3.1.1.3" xref="S1.F2.10.m3.1.1.3.cmml"><mi id="S1.F2.10.m3.1.1.3.2" xref="S1.F2.10.m3.1.1.3.2.cmml">L</mi><mo id="S1.F2.10.m3.1.1.3.1" xref="S1.F2.10.m3.1.1.3.1.cmml">⁢</mo><mi id="S1.F2.10.m3.1.1.3.3" xref="S1.F2.10.m3.1.1.3.3.cmml">o</mi><mo id="S1.F2.10.m3.1.1.3.1b" xref="S1.F2.10.m3.1.1.3.1.cmml">⁢</mo><mi id="S1.F2.10.m3.1.1.3.4" xref="S1.F2.10.m3.1.1.3.4.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S1.F2.10.m3.1c"><apply id="S1.F2.10.m3.1.1.cmml" xref="S1.F2.10.m3.1.1"><csymbol cd="ambiguous" id="S1.F2.10.m3.1.1.1.cmml" xref="S1.F2.10.m3.1.1">subscript</csymbol><ci id="S1.F2.10.m3.1.1.2.cmml" xref="S1.F2.10.m3.1.1.2">𝕎</ci><apply id="S1.F2.10.m3.1.1.3.cmml" xref="S1.F2.10.m3.1.1.3"><times id="S1.F2.10.m3.1.1.3.1.cmml" xref="S1.F2.10.m3.1.1.3.1"></times><ci id="S1.F2.10.m3.1.1.3.2.cmml" xref="S1.F2.10.m3.1.1.3.2">𝐿</ci><ci id="S1.F2.10.m3.1.1.3.3.cmml" xref="S1.F2.10.m3.1.1.3.3">𝑜</ci><ci id="S1.F2.10.m3.1.1.3.4.cmml" xref="S1.F2.10.m3.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.10.m3.1d">\mathbb{W}_{Loc}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.10.m3.1e">blackboard_W start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT</annotation></semantics></math>; <math alttext="\mathbb{W}_{Target}" class="ltx_Math" display="inline" id="S1.F2.11.m4.1"><semantics id="S1.F2.11.m4.1b"><msub id="S1.F2.11.m4.1.1" xref="S1.F2.11.m4.1.1.cmml"><mi id="S1.F2.11.m4.1.1.2" xref="S1.F2.11.m4.1.1.2.cmml">𝕎</mi><mrow id="S1.F2.11.m4.1.1.3" xref="S1.F2.11.m4.1.1.3.cmml"><mi id="S1.F2.11.m4.1.1.3.2" xref="S1.F2.11.m4.1.1.3.2.cmml">T</mi><mo id="S1.F2.11.m4.1.1.3.1" xref="S1.F2.11.m4.1.1.3.1.cmml">⁢</mo><mi id="S1.F2.11.m4.1.1.3.3" xref="S1.F2.11.m4.1.1.3.3.cmml">a</mi><mo id="S1.F2.11.m4.1.1.3.1b" xref="S1.F2.11.m4.1.1.3.1.cmml">⁢</mo><mi id="S1.F2.11.m4.1.1.3.4" xref="S1.F2.11.m4.1.1.3.4.cmml">r</mi><mo id="S1.F2.11.m4.1.1.3.1c" xref="S1.F2.11.m4.1.1.3.1.cmml">⁢</mo><mi id="S1.F2.11.m4.1.1.3.5" xref="S1.F2.11.m4.1.1.3.5.cmml">g</mi><mo id="S1.F2.11.m4.1.1.3.1d" xref="S1.F2.11.m4.1.1.3.1.cmml">⁢</mo><mi id="S1.F2.11.m4.1.1.3.6" xref="S1.F2.11.m4.1.1.3.6.cmml">e</mi><mo id="S1.F2.11.m4.1.1.3.1e" xref="S1.F2.11.m4.1.1.3.1.cmml">⁢</mo><mi id="S1.F2.11.m4.1.1.3.7" xref="S1.F2.11.m4.1.1.3.7.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S1.F2.11.m4.1c"><apply id="S1.F2.11.m4.1.1.cmml" xref="S1.F2.11.m4.1.1"><csymbol cd="ambiguous" id="S1.F2.11.m4.1.1.1.cmml" xref="S1.F2.11.m4.1.1">subscript</csymbol><ci id="S1.F2.11.m4.1.1.2.cmml" xref="S1.F2.11.m4.1.1.2">𝕎</ci><apply id="S1.F2.11.m4.1.1.3.cmml" xref="S1.F2.11.m4.1.1.3"><times id="S1.F2.11.m4.1.1.3.1.cmml" xref="S1.F2.11.m4.1.1.3.1"></times><ci id="S1.F2.11.m4.1.1.3.2.cmml" xref="S1.F2.11.m4.1.1.3.2">𝑇</ci><ci id="S1.F2.11.m4.1.1.3.3.cmml" xref="S1.F2.11.m4.1.1.3.3">𝑎</ci><ci id="S1.F2.11.m4.1.1.3.4.cmml" xref="S1.F2.11.m4.1.1.3.4">𝑟</ci><ci id="S1.F2.11.m4.1.1.3.5.cmml" xref="S1.F2.11.m4.1.1.3.5">𝑔</ci><ci id="S1.F2.11.m4.1.1.3.6.cmml" xref="S1.F2.11.m4.1.1.3.6">𝑒</ci><ci id="S1.F2.11.m4.1.1.3.7.cmml" xref="S1.F2.11.m4.1.1.3.7">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.11.m4.1d">\mathbb{W}_{Target}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.11.m4.1e">blackboard_W start_POSTSUBSCRIPT italic_T italic_a italic_r italic_g italic_e italic_t end_POSTSUBSCRIPT</annotation></semantics></math>: the final target model; <math alttext="\mathbb{W}_{Pro}" class="ltx_Math" display="inline" id="S1.F2.12.m5.1"><semantics id="S1.F2.12.m5.1b"><msub id="S1.F2.12.m5.1.1" xref="S1.F2.12.m5.1.1.cmml"><mi id="S1.F2.12.m5.1.1.2" xref="S1.F2.12.m5.1.1.2.cmml">𝕎</mi><mrow id="S1.F2.12.m5.1.1.3" xref="S1.F2.12.m5.1.1.3.cmml"><mi id="S1.F2.12.m5.1.1.3.2" xref="S1.F2.12.m5.1.1.3.2.cmml">P</mi><mo id="S1.F2.12.m5.1.1.3.1" xref="S1.F2.12.m5.1.1.3.1.cmml">⁢</mo><mi id="S1.F2.12.m5.1.1.3.3" xref="S1.F2.12.m5.1.1.3.3.cmml">r</mi><mo id="S1.F2.12.m5.1.1.3.1b" xref="S1.F2.12.m5.1.1.3.1.cmml">⁢</mo><mi id="S1.F2.12.m5.1.1.3.4" xref="S1.F2.12.m5.1.1.3.4.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S1.F2.12.m5.1c"><apply id="S1.F2.12.m5.1.1.cmml" xref="S1.F2.12.m5.1.1"><csymbol cd="ambiguous" id="S1.F2.12.m5.1.1.1.cmml" xref="S1.F2.12.m5.1.1">subscript</csymbol><ci id="S1.F2.12.m5.1.1.2.cmml" xref="S1.F2.12.m5.1.1.2">𝕎</ci><apply id="S1.F2.12.m5.1.1.3.cmml" xref="S1.F2.12.m5.1.1.3"><times id="S1.F2.12.m5.1.1.3.1.cmml" xref="S1.F2.12.m5.1.1.3.1"></times><ci id="S1.F2.12.m5.1.1.3.2.cmml" xref="S1.F2.12.m5.1.1.3.2">𝑃</ci><ci id="S1.F2.12.m5.1.1.3.3.cmml" xref="S1.F2.12.m5.1.1.3.3">𝑟</ci><ci id="S1.F2.12.m5.1.1.3.4.cmml" xref="S1.F2.12.m5.1.1.3.4">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.12.m5.1d">\mathbb{W}_{Pro}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.12.m5.1e">blackboard_W start_POSTSUBSCRIPT italic_P italic_r italic_o end_POSTSUBSCRIPT</annotation></semantics></math>: the professional model. From left to right, <math alttext="\mathbb{W}_{Loc}" class="ltx_Math" display="inline" id="S1.F2.13.m6.1"><semantics id="S1.F2.13.m6.1b"><msub id="S1.F2.13.m6.1.1" xref="S1.F2.13.m6.1.1.cmml"><mi id="S1.F2.13.m6.1.1.2" xref="S1.F2.13.m6.1.1.2.cmml">𝕎</mi><mrow id="S1.F2.13.m6.1.1.3" xref="S1.F2.13.m6.1.1.3.cmml"><mi id="S1.F2.13.m6.1.1.3.2" xref="S1.F2.13.m6.1.1.3.2.cmml">L</mi><mo id="S1.F2.13.m6.1.1.3.1" xref="S1.F2.13.m6.1.1.3.1.cmml">⁢</mo><mi id="S1.F2.13.m6.1.1.3.3" xref="S1.F2.13.m6.1.1.3.3.cmml">o</mi><mo id="S1.F2.13.m6.1.1.3.1b" xref="S1.F2.13.m6.1.1.3.1.cmml">⁢</mo><mi id="S1.F2.13.m6.1.1.3.4" xref="S1.F2.13.m6.1.1.3.4.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S1.F2.13.m6.1c"><apply id="S1.F2.13.m6.1.1.cmml" xref="S1.F2.13.m6.1.1"><csymbol cd="ambiguous" id="S1.F2.13.m6.1.1.1.cmml" xref="S1.F2.13.m6.1.1">subscript</csymbol><ci id="S1.F2.13.m6.1.1.2.cmml" xref="S1.F2.13.m6.1.1.2">𝕎</ci><apply id="S1.F2.13.m6.1.1.3.cmml" xref="S1.F2.13.m6.1.1.3"><times id="S1.F2.13.m6.1.1.3.1.cmml" xref="S1.F2.13.m6.1.1.3.1"></times><ci id="S1.F2.13.m6.1.1.3.2.cmml" xref="S1.F2.13.m6.1.1.3.2">𝐿</ci><ci id="S1.F2.13.m6.1.1.3.3.cmml" xref="S1.F2.13.m6.1.1.3.3">𝑜</ci><ci id="S1.F2.13.m6.1.1.3.4.cmml" xref="S1.F2.13.m6.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.13.m6.1d">\mathbb{W}_{Loc}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.13.m6.1e">blackboard_W start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT</annotation></semantics></math> learns knowledge from private data on the client side and acquires knowledge distillation from <math alttext="\mathbb{W}_{Pro}" class="ltx_Math" display="inline" id="S1.F2.14.m7.1"><semantics id="S1.F2.14.m7.1b"><msub id="S1.F2.14.m7.1.1" xref="S1.F2.14.m7.1.1.cmml"><mi id="S1.F2.14.m7.1.1.2" xref="S1.F2.14.m7.1.1.2.cmml">𝕎</mi><mrow id="S1.F2.14.m7.1.1.3" xref="S1.F2.14.m7.1.1.3.cmml"><mi id="S1.F2.14.m7.1.1.3.2" xref="S1.F2.14.m7.1.1.3.2.cmml">P</mi><mo id="S1.F2.14.m7.1.1.3.1" xref="S1.F2.14.m7.1.1.3.1.cmml">⁢</mo><mi id="S1.F2.14.m7.1.1.3.3" xref="S1.F2.14.m7.1.1.3.3.cmml">r</mi><mo id="S1.F2.14.m7.1.1.3.1b" xref="S1.F2.14.m7.1.1.3.1.cmml">⁢</mo><mi id="S1.F2.14.m7.1.1.3.4" xref="S1.F2.14.m7.1.1.3.4.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S1.F2.14.m7.1c"><apply id="S1.F2.14.m7.1.1.cmml" xref="S1.F2.14.m7.1.1"><csymbol cd="ambiguous" id="S1.F2.14.m7.1.1.1.cmml" xref="S1.F2.14.m7.1.1">subscript</csymbol><ci id="S1.F2.14.m7.1.1.2.cmml" xref="S1.F2.14.m7.1.1.2">𝕎</ci><apply id="S1.F2.14.m7.1.1.3.cmml" xref="S1.F2.14.m7.1.1.3"><times id="S1.F2.14.m7.1.1.3.1.cmml" xref="S1.F2.14.m7.1.1.3.1"></times><ci id="S1.F2.14.m7.1.1.3.2.cmml" xref="S1.F2.14.m7.1.1.3.2">𝑃</ci><ci id="S1.F2.14.m7.1.1.3.3.cmml" xref="S1.F2.14.m7.1.1.3.3">𝑟</ci><ci id="S1.F2.14.m7.1.1.3.4.cmml" xref="S1.F2.14.m7.1.1.3.4">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S1.F2.14.m7.1d">\mathbb{W}_{Pro}</annotation><annotation encoding="application/x-llamapun" id="S1.F2.14.m7.1e">blackboard_W start_POSTSUBSCRIPT italic_P italic_r italic_o end_POSTSUBSCRIPT</annotation></semantics></math> on the server side.</figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Privacy Concerns with Fine-tuning on Private Data</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Fine-tuning large language models is crucial for enhancing their instruction following ability and improving performance on certain downstream tasks <cite class="ltx_cite ltx_citemacro_cite">Conover et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib12" title="">2023</a>); Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib60" title="">2023</a>); Jang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib24" title="">2023</a>)</cite>.
In order to deliver a satisfactory user experience <cite class="ltx_cite ltx_citemacro_cite">Zhao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib79" title="">2024</a>)</cite> or achieve professional-level expertise <cite class="ltx_cite ltx_citemacro_cite">Chaudhary (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib7" title="">2023</a>); Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib66" title="">2023</a>)</cite>, it is inevitable to fine-tune LLMs on user-related private data or proprietary data owned by institutions.
However, recent studies <cite class="ltx_cite ltx_citemacro_cite">Kandpal et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib29" title="">2023</a>); Carlini et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib6" title="">2021</a>)</cite> have experimentally demonstrated that LLMs can memorize their training datasets, leaving possibilities of leaking private information through either simple prompts <cite class="ltx_cite ltx_citemacro_cite">Carlini et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib6" title="">2021</a>); Nasr et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib46" title="">2023</a>)</cite> or delicately designed attacks <cite class="ltx_cite ltx_citemacro_cite">Lukas et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib39" title="">2023</a>); Gupta et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib18" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">Continuing to improve the quality and coverage of fine-tuned large language models necessitates the development of alternative approaches to utilizing private data without memorizing it.
To mitigate this issue, two mainstream solutions have emerged. The first involves fine-tuning LLMs with differential privacy techniques <cite class="ltx_cite ltx_citemacro_cite">Abadi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib1" title="">2016</a>); Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib74" title="">2022</a>)</cite>, while the second focuses on substituting original private data with high-fidelity synthetic ones for fine-tuning <cite class="ltx_cite ltx_citemacro_cite">Yue et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib75" title="">2023</a>); Xie et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib65" title="">2024</a>)</cite>.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Synthetic Text Generation</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Two widely adopted approaches for generating private synthetic text in practice are In-Context Learning (ICL) <cite class="ltx_cite ltx_citemacro_cite">Dong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib14" title="">2022</a>); Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib8" title="">2024</a>); Ye et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib70" title="">2024a</a>)</cite> and Self-Instruction <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib61" title="">2022</a>)</cite>.
Largely relying on prompt design and the base model’s comprehension, they suffer from either low data fidelity yielded by the base model, or privacy concerns requesting API servers. What makes it worse, with private data included directly in prompts, these methods pose an additional risk of revealing sensitive information.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">Recently, researchers have recognized the feasibility and effectiveness of the DP generator method <cite class="ltx_cite ltx_citemacro_cite">Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib73" title="">2024</a>); Yue et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib75" title="">2023</a>); Kurakin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib30" title="">2024</a>)</cite>. This approach first trains an LLM on private data with DP, and then repeatedly samples the DP-finetuned model to generate synthetic text sequences.
Although proved to gain improvements in distribution similarity, previous works primarily concentrate on generating diverse synthetic instructions. They ignore or skip the practical scenarios where responses are equally crucial for instruction tuning of LLMs.
Moreover, current DP generator methods only focus on general knowledge, leading to significantly poorer performance in domain-specific scenarios such as finance and medicine where privacy draws considerable attention.
Therefore, <span class="ltx_text ltx_font_italic" id="S2.SS2.p2.1.1">KnowledgeSG</span> intends to improve the quality of both synthetic instructions and responses by distilling the professional model, especially on domain-specific tasks.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Problem Setup</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.7">Let <math alttext="\mathbb{D}_{Pri}" class="ltx_Math" display="inline" id="S3.SS1.p1.1.m1.1"><semantics id="S3.SS1.p1.1.m1.1a"><msub id="S3.SS1.p1.1.m1.1.1" xref="S3.SS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.p1.1.m1.1.1.2" xref="S3.SS1.p1.1.m1.1.1.2.cmml">𝔻</mi><mrow id="S3.SS1.p1.1.m1.1.1.3" xref="S3.SS1.p1.1.m1.1.1.3.cmml"><mi id="S3.SS1.p1.1.m1.1.1.3.2" xref="S3.SS1.p1.1.m1.1.1.3.2.cmml">P</mi><mo id="S3.SS1.p1.1.m1.1.1.3.1" xref="S3.SS1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.1.m1.1.1.3.3" xref="S3.SS1.p1.1.m1.1.1.3.3.cmml">r</mi><mo id="S3.SS1.p1.1.m1.1.1.3.1a" xref="S3.SS1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.1.m1.1.1.3.4" xref="S3.SS1.p1.1.m1.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.1.m1.1b"><apply id="S3.SS1.p1.1.m1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.p1.1.m1.1.1.2">𝔻</ci><apply id="S3.SS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3"><times id="S3.SS1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS1.p1.1.m1.1.1.3.1"></times><ci id="S3.SS1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS1.p1.1.m1.1.1.3.2">𝑃</ci><ci id="S3.SS1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS1.p1.1.m1.1.1.3.3">𝑟</ci><ci id="S3.SS1.p1.1.m1.1.1.3.4.cmml" xref="S3.SS1.p1.1.m1.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.1.m1.1c">\mathbb{D}_{Pri}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.1.m1.1d">blackboard_D start_POSTSUBSCRIPT italic_P italic_r italic_i end_POSTSUBSCRIPT</annotation></semantics></math> represent the private dataset possessed by the client, which contains privacy from patients. <math alttext="\mathbb{W}_{Loc}" class="ltx_Math" display="inline" id="S3.SS1.p1.2.m2.1"><semantics id="S3.SS1.p1.2.m2.1a"><msub id="S3.SS1.p1.2.m2.1.1" xref="S3.SS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.p1.2.m2.1.1.2" xref="S3.SS1.p1.2.m2.1.1.2.cmml">𝕎</mi><mrow id="S3.SS1.p1.2.m2.1.1.3" xref="S3.SS1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS1.p1.2.m2.1.1.3.2" xref="S3.SS1.p1.2.m2.1.1.3.2.cmml">L</mi><mo id="S3.SS1.p1.2.m2.1.1.3.1" xref="S3.SS1.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.2.m2.1.1.3.3" xref="S3.SS1.p1.2.m2.1.1.3.3.cmml">o</mi><mo id="S3.SS1.p1.2.m2.1.1.3.1a" xref="S3.SS1.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.2.m2.1.1.3.4" xref="S3.SS1.p1.2.m2.1.1.3.4.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.2.m2.1b"><apply id="S3.SS1.p1.2.m2.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.p1.2.m2.1.1.2">𝕎</ci><apply id="S3.SS1.p1.2.m2.1.1.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3"><times id="S3.SS1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.p1.2.m2.1.1.3.1"></times><ci id="S3.SS1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.p1.2.m2.1.1.3.2">𝐿</ci><ci id="S3.SS1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.p1.2.m2.1.1.3.3">𝑜</ci><ci id="S3.SS1.p1.2.m2.1.1.3.4.cmml" xref="S3.SS1.p1.2.m2.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.2.m2.1c">\mathbb{W}_{Loc}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.2.m2.1d">blackboard_W start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT</annotation></semantics></math> is the local base model pre-trained on general data that needs to acquire medical knowledge from <math alttext="\mathbb{D}_{Pri}" class="ltx_Math" display="inline" id="S3.SS1.p1.3.m3.1"><semantics id="S3.SS1.p1.3.m3.1a"><msub id="S3.SS1.p1.3.m3.1.1" xref="S3.SS1.p1.3.m3.1.1.cmml"><mi id="S3.SS1.p1.3.m3.1.1.2" xref="S3.SS1.p1.3.m3.1.1.2.cmml">𝔻</mi><mrow id="S3.SS1.p1.3.m3.1.1.3" xref="S3.SS1.p1.3.m3.1.1.3.cmml"><mi id="S3.SS1.p1.3.m3.1.1.3.2" xref="S3.SS1.p1.3.m3.1.1.3.2.cmml">P</mi><mo id="S3.SS1.p1.3.m3.1.1.3.1" xref="S3.SS1.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.3.m3.1.1.3.3" xref="S3.SS1.p1.3.m3.1.1.3.3.cmml">r</mi><mo id="S3.SS1.p1.3.m3.1.1.3.1a" xref="S3.SS1.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.3.m3.1.1.3.4" xref="S3.SS1.p1.3.m3.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.3.m3.1b"><apply id="S3.SS1.p1.3.m3.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.3.m3.1.1.1.cmml" xref="S3.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p1.3.m3.1.1.2.cmml" xref="S3.SS1.p1.3.m3.1.1.2">𝔻</ci><apply id="S3.SS1.p1.3.m3.1.1.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3"><times id="S3.SS1.p1.3.m3.1.1.3.1.cmml" xref="S3.SS1.p1.3.m3.1.1.3.1"></times><ci id="S3.SS1.p1.3.m3.1.1.3.2.cmml" xref="S3.SS1.p1.3.m3.1.1.3.2">𝑃</ci><ci id="S3.SS1.p1.3.m3.1.1.3.3.cmml" xref="S3.SS1.p1.3.m3.1.1.3.3">𝑟</ci><ci id="S3.SS1.p1.3.m3.1.1.3.4.cmml" xref="S3.SS1.p1.3.m3.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.3.m3.1c">\mathbb{D}_{Pri}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.3.m3.1d">blackboard_D start_POSTSUBSCRIPT italic_P italic_r italic_i end_POSTSUBSCRIPT</annotation></semantics></math>. <math alttext="\mathbb{W}_{Pro}" class="ltx_Math" display="inline" id="S3.SS1.p1.4.m4.1"><semantics id="S3.SS1.p1.4.m4.1a"><msub id="S3.SS1.p1.4.m4.1.1" xref="S3.SS1.p1.4.m4.1.1.cmml"><mi id="S3.SS1.p1.4.m4.1.1.2" xref="S3.SS1.p1.4.m4.1.1.2.cmml">𝕎</mi><mrow id="S3.SS1.p1.4.m4.1.1.3" xref="S3.SS1.p1.4.m4.1.1.3.cmml"><mi id="S3.SS1.p1.4.m4.1.1.3.2" xref="S3.SS1.p1.4.m4.1.1.3.2.cmml">P</mi><mo id="S3.SS1.p1.4.m4.1.1.3.1" xref="S3.SS1.p1.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.4.m4.1.1.3.3" xref="S3.SS1.p1.4.m4.1.1.3.3.cmml">r</mi><mo id="S3.SS1.p1.4.m4.1.1.3.1a" xref="S3.SS1.p1.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.4.m4.1.1.3.4" xref="S3.SS1.p1.4.m4.1.1.3.4.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.4.m4.1b"><apply id="S3.SS1.p1.4.m4.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.4.m4.1.1.1.cmml" xref="S3.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS1.p1.4.m4.1.1.2.cmml" xref="S3.SS1.p1.4.m4.1.1.2">𝕎</ci><apply id="S3.SS1.p1.4.m4.1.1.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3"><times id="S3.SS1.p1.4.m4.1.1.3.1.cmml" xref="S3.SS1.p1.4.m4.1.1.3.1"></times><ci id="S3.SS1.p1.4.m4.1.1.3.2.cmml" xref="S3.SS1.p1.4.m4.1.1.3.2">𝑃</ci><ci id="S3.SS1.p1.4.m4.1.1.3.3.cmml" xref="S3.SS1.p1.4.m4.1.1.3.3">𝑟</ci><ci id="S3.SS1.p1.4.m4.1.1.3.4.cmml" xref="S3.SS1.p1.4.m4.1.1.3.4">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.4.m4.1c">\mathbb{W}_{Pro}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.4.m4.1d">blackboard_W start_POSTSUBSCRIPT italic_P italic_r italic_o end_POSTSUBSCRIPT</annotation></semantics></math> refers to the professional model hosted by the server which is relatively larger than <math alttext="\mathbb{W}_{Loc}" class="ltx_Math" display="inline" id="S3.SS1.p1.5.m5.1"><semantics id="S3.SS1.p1.5.m5.1a"><msub id="S3.SS1.p1.5.m5.1.1" xref="S3.SS1.p1.5.m5.1.1.cmml"><mi id="S3.SS1.p1.5.m5.1.1.2" xref="S3.SS1.p1.5.m5.1.1.2.cmml">𝕎</mi><mrow id="S3.SS1.p1.5.m5.1.1.3" xref="S3.SS1.p1.5.m5.1.1.3.cmml"><mi id="S3.SS1.p1.5.m5.1.1.3.2" xref="S3.SS1.p1.5.m5.1.1.3.2.cmml">L</mi><mo id="S3.SS1.p1.5.m5.1.1.3.1" xref="S3.SS1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.5.m5.1.1.3.3" xref="S3.SS1.p1.5.m5.1.1.3.3.cmml">o</mi><mo id="S3.SS1.p1.5.m5.1.1.3.1a" xref="S3.SS1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.5.m5.1.1.3.4" xref="S3.SS1.p1.5.m5.1.1.3.4.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.5.m5.1b"><apply id="S3.SS1.p1.5.m5.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.5.m5.1.1.1.cmml" xref="S3.SS1.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS1.p1.5.m5.1.1.2.cmml" xref="S3.SS1.p1.5.m5.1.1.2">𝕎</ci><apply id="S3.SS1.p1.5.m5.1.1.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3"><times id="S3.SS1.p1.5.m5.1.1.3.1.cmml" xref="S3.SS1.p1.5.m5.1.1.3.1"></times><ci id="S3.SS1.p1.5.m5.1.1.3.2.cmml" xref="S3.SS1.p1.5.m5.1.1.3.2">𝐿</ci><ci id="S3.SS1.p1.5.m5.1.1.3.3.cmml" xref="S3.SS1.p1.5.m5.1.1.3.3">𝑜</ci><ci id="S3.SS1.p1.5.m5.1.1.3.4.cmml" xref="S3.SS1.p1.5.m5.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.5.m5.1c">\mathbb{W}_{Loc}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.5.m5.1d">blackboard_W start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT</annotation></semantics></math> and is assumed to have extensive knowledge of the medical domain.
To formalize our problem setup, we assume that <math alttext="\mathbb{D}_{Pri}" class="ltx_Math" display="inline" id="S3.SS1.p1.6.m6.1"><semantics id="S3.SS1.p1.6.m6.1a"><msub id="S3.SS1.p1.6.m6.1.1" xref="S3.SS1.p1.6.m6.1.1.cmml"><mi id="S3.SS1.p1.6.m6.1.1.2" xref="S3.SS1.p1.6.m6.1.1.2.cmml">𝔻</mi><mrow id="S3.SS1.p1.6.m6.1.1.3" xref="S3.SS1.p1.6.m6.1.1.3.cmml"><mi id="S3.SS1.p1.6.m6.1.1.3.2" xref="S3.SS1.p1.6.m6.1.1.3.2.cmml">P</mi><mo id="S3.SS1.p1.6.m6.1.1.3.1" xref="S3.SS1.p1.6.m6.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.6.m6.1.1.3.3" xref="S3.SS1.p1.6.m6.1.1.3.3.cmml">r</mi><mo id="S3.SS1.p1.6.m6.1.1.3.1a" xref="S3.SS1.p1.6.m6.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.6.m6.1.1.3.4" xref="S3.SS1.p1.6.m6.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.6.m6.1b"><apply id="S3.SS1.p1.6.m6.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.6.m6.1.1.1.cmml" xref="S3.SS1.p1.6.m6.1.1">subscript</csymbol><ci id="S3.SS1.p1.6.m6.1.1.2.cmml" xref="S3.SS1.p1.6.m6.1.1.2">𝔻</ci><apply id="S3.SS1.p1.6.m6.1.1.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3"><times id="S3.SS1.p1.6.m6.1.1.3.1.cmml" xref="S3.SS1.p1.6.m6.1.1.3.1"></times><ci id="S3.SS1.p1.6.m6.1.1.3.2.cmml" xref="S3.SS1.p1.6.m6.1.1.3.2">𝑃</ci><ci id="S3.SS1.p1.6.m6.1.1.3.3.cmml" xref="S3.SS1.p1.6.m6.1.1.3.3">𝑟</ci><ci id="S3.SS1.p1.6.m6.1.1.3.4.cmml" xref="S3.SS1.p1.6.m6.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.6.m6.1c">\mathbb{D}_{Pri}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.6.m6.1d">blackboard_D start_POSTSUBSCRIPT italic_P italic_r italic_i end_POSTSUBSCRIPT</annotation></semantics></math> used for instruction tuning consists of two components: <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.7.1">Instruction</span> and <span class="ltx_text ltx_font_italic" id="S3.SS1.p1.7.2">Response</span>, both of which contain Personal Identifiable Information (PII), e.g. patients’ names. Therefore, <math alttext="\mathbb{D}_{Pri}" class="ltx_Math" display="inline" id="S3.SS1.p1.7.m7.1"><semantics id="S3.SS1.p1.7.m7.1a"><msub id="S3.SS1.p1.7.m7.1.1" xref="S3.SS1.p1.7.m7.1.1.cmml"><mi id="S3.SS1.p1.7.m7.1.1.2" xref="S3.SS1.p1.7.m7.1.1.2.cmml">𝔻</mi><mrow id="S3.SS1.p1.7.m7.1.1.3" xref="S3.SS1.p1.7.m7.1.1.3.cmml"><mi id="S3.SS1.p1.7.m7.1.1.3.2" xref="S3.SS1.p1.7.m7.1.1.3.2.cmml">P</mi><mo id="S3.SS1.p1.7.m7.1.1.3.1" xref="S3.SS1.p1.7.m7.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.7.m7.1.1.3.3" xref="S3.SS1.p1.7.m7.1.1.3.3.cmml">r</mi><mo id="S3.SS1.p1.7.m7.1.1.3.1a" xref="S3.SS1.p1.7.m7.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p1.7.m7.1.1.3.4" xref="S3.SS1.p1.7.m7.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p1.7.m7.1b"><apply id="S3.SS1.p1.7.m7.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.p1.7.m7.1.1.1.cmml" xref="S3.SS1.p1.7.m7.1.1">subscript</csymbol><ci id="S3.SS1.p1.7.m7.1.1.2.cmml" xref="S3.SS1.p1.7.m7.1.1.2">𝔻</ci><apply id="S3.SS1.p1.7.m7.1.1.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3"><times id="S3.SS1.p1.7.m7.1.1.3.1.cmml" xref="S3.SS1.p1.7.m7.1.1.3.1"></times><ci id="S3.SS1.p1.7.m7.1.1.3.2.cmml" xref="S3.SS1.p1.7.m7.1.1.3.2">𝑃</ci><ci id="S3.SS1.p1.7.m7.1.1.3.3.cmml" xref="S3.SS1.p1.7.m7.1.1.3.3">𝑟</ci><ci id="S3.SS1.p1.7.m7.1.1.3.4.cmml" xref="S3.SS1.p1.7.m7.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p1.7.m7.1c">\mathbb{D}_{Pri}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p1.7.m7.1d">blackboard_D start_POSTSUBSCRIPT italic_P italic_r italic_i end_POSTSUBSCRIPT</annotation></semantics></math> can not be directly transmitted over networks due to privacy concerns. We present a detailed definition of PII in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A4" title="Appendix D Definition of PII ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">D</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.3">Our ultimate objective is to generate a synthetic dataset <math alttext="\mathbb{D}_{Syn}" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><msub id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">𝔻</mi><mrow id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml"><mi id="S3.SS1.p2.1.m1.1.1.3.2" xref="S3.SS1.p2.1.m1.1.1.3.2.cmml">S</mi><mo id="S3.SS1.p2.1.m1.1.1.3.1" xref="S3.SS1.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p2.1.m1.1.1.3.3" xref="S3.SS1.p2.1.m1.1.1.3.3.cmml">y</mi><mo id="S3.SS1.p2.1.m1.1.1.3.1a" xref="S3.SS1.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p2.1.m1.1.1.3.4" xref="S3.SS1.p2.1.m1.1.1.3.4.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">𝔻</ci><apply id="S3.SS1.p2.1.m1.1.1.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3"><times id="S3.SS1.p2.1.m1.1.1.3.1.cmml" xref="S3.SS1.p2.1.m1.1.1.3.1"></times><ci id="S3.SS1.p2.1.m1.1.1.3.2.cmml" xref="S3.SS1.p2.1.m1.1.1.3.2">𝑆</ci><ci id="S3.SS1.p2.1.m1.1.1.3.3.cmml" xref="S3.SS1.p2.1.m1.1.1.3.3">𝑦</ci><ci id="S3.SS1.p2.1.m1.1.1.3.4.cmml" xref="S3.SS1.p2.1.m1.1.1.3.4">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">\mathbb{D}_{Syn}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">blackboard_D start_POSTSUBSCRIPT italic_S italic_y italic_n end_POSTSUBSCRIPT</annotation></semantics></math> that maintains high data quality while containing no trace of PIIs. This allows us to fine-tune <math alttext="\mathbb{W}_{Loc}" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><msub id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">𝕎</mi><mrow id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml"><mi id="S3.SS1.p2.2.m2.1.1.3.2" xref="S3.SS1.p2.2.m2.1.1.3.2.cmml">L</mi><mo id="S3.SS1.p2.2.m2.1.1.3.1" xref="S3.SS1.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p2.2.m2.1.1.3.3" xref="S3.SS1.p2.2.m2.1.1.3.3.cmml">o</mi><mo id="S3.SS1.p2.2.m2.1.1.3.1a" xref="S3.SS1.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p2.2.m2.1.1.3.4" xref="S3.SS1.p2.2.m2.1.1.3.4.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">𝕎</ci><apply id="S3.SS1.p2.2.m2.1.1.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3"><times id="S3.SS1.p2.2.m2.1.1.3.1.cmml" xref="S3.SS1.p2.2.m2.1.1.3.1"></times><ci id="S3.SS1.p2.2.m2.1.1.3.2.cmml" xref="S3.SS1.p2.2.m2.1.1.3.2">𝐿</ci><ci id="S3.SS1.p2.2.m2.1.1.3.3.cmml" xref="S3.SS1.p2.2.m2.1.1.3.3">𝑜</ci><ci id="S3.SS1.p2.2.m2.1.1.3.4.cmml" xref="S3.SS1.p2.2.m2.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">\mathbb{W}_{Loc}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">blackboard_W start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT</annotation></semantics></math> on <math alttext="\mathbb{D}_{Syn}" class="ltx_Math" display="inline" id="S3.SS1.p2.3.m3.1"><semantics id="S3.SS1.p2.3.m3.1a"><msub id="S3.SS1.p2.3.m3.1.1" xref="S3.SS1.p2.3.m3.1.1.cmml"><mi id="S3.SS1.p2.3.m3.1.1.2" xref="S3.SS1.p2.3.m3.1.1.2.cmml">𝔻</mi><mrow id="S3.SS1.p2.3.m3.1.1.3" xref="S3.SS1.p2.3.m3.1.1.3.cmml"><mi id="S3.SS1.p2.3.m3.1.1.3.2" xref="S3.SS1.p2.3.m3.1.1.3.2.cmml">S</mi><mo id="S3.SS1.p2.3.m3.1.1.3.1" xref="S3.SS1.p2.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p2.3.m3.1.1.3.3" xref="S3.SS1.p2.3.m3.1.1.3.3.cmml">y</mi><mo id="S3.SS1.p2.3.m3.1.1.3.1a" xref="S3.SS1.p2.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS1.p2.3.m3.1.1.3.4" xref="S3.SS1.p2.3.m3.1.1.3.4.cmml">n</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.3.m3.1b"><apply id="S3.SS1.p2.3.m3.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p2.3.m3.1.1.1.cmml" xref="S3.SS1.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p2.3.m3.1.1.2.cmml" xref="S3.SS1.p2.3.m3.1.1.2">𝔻</ci><apply id="S3.SS1.p2.3.m3.1.1.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3"><times id="S3.SS1.p2.3.m3.1.1.3.1.cmml" xref="S3.SS1.p2.3.m3.1.1.3.1"></times><ci id="S3.SS1.p2.3.m3.1.1.3.2.cmml" xref="S3.SS1.p2.3.m3.1.1.3.2">𝑆</ci><ci id="S3.SS1.p2.3.m3.1.1.3.3.cmml" xref="S3.SS1.p2.3.m3.1.1.3.3">𝑦</ci><ci id="S3.SS1.p2.3.m3.1.1.3.4.cmml" xref="S3.SS1.p2.3.m3.1.1.3.4">𝑛</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.3.m3.1c">\mathbb{D}_{Syn}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.3.m3.1d">blackboard_D start_POSTSUBSCRIPT italic_S italic_y italic_n end_POSTSUBSCRIPT</annotation></semantics></math> to facilitate improvements in privacy-performance trade-off.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>System Overview</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">We introduce a novel client-server framework called <span class="ltx_text ltx_font_italic" id="S3.SS2.p1.1.1">KnowledgeSG</span> (<span class="ltx_text ltx_font_bold" id="S3.SS2.p1.1.2">Knowledge</span>-based <span class="ltx_text ltx_font_bold" id="S3.SS2.p1.1.3">S</span>ynthetic data <span class="ltx_text ltx_font_bold" id="S3.SS2.p1.1.4">G</span>eneration), which aims to improve synthetic data quality and further promote model performance without violating privacy.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.2">We attribute the quality gap between synthetic data and original private data to the comprehension deficiency of the local model <math alttext="\mathbb{W}_{Loc}" class="ltx_Math" display="inline" id="S3.SS2.p2.1.m1.1"><semantics id="S3.SS2.p2.1.m1.1a"><msub id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">𝕎</mi><mrow id="S3.SS2.p2.1.m1.1.1.3" xref="S3.SS2.p2.1.m1.1.1.3.cmml"><mi id="S3.SS2.p2.1.m1.1.1.3.2" xref="S3.SS2.p2.1.m1.1.1.3.2.cmml">L</mi><mo id="S3.SS2.p2.1.m1.1.1.3.1" xref="S3.SS2.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.1.m1.1.1.3.3" xref="S3.SS2.p2.1.m1.1.1.3.3.cmml">o</mi><mo id="S3.SS2.p2.1.m1.1.1.3.1a" xref="S3.SS2.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.1.m1.1.1.3.4" xref="S3.SS2.p2.1.m1.1.1.3.4.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">𝕎</ci><apply id="S3.SS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3"><times id="S3.SS2.p2.1.m1.1.1.3.1.cmml" xref="S3.SS2.p2.1.m1.1.1.3.1"></times><ci id="S3.SS2.p2.1.m1.1.1.3.2.cmml" xref="S3.SS2.p2.1.m1.1.1.3.2">𝐿</ci><ci id="S3.SS2.p2.1.m1.1.1.3.3.cmml" xref="S3.SS2.p2.1.m1.1.1.3.3">𝑜</ci><ci id="S3.SS2.p2.1.m1.1.1.3.4.cmml" xref="S3.SS2.p2.1.m1.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">\mathbb{W}_{Loc}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.1.m1.1d">blackboard_W start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT</annotation></semantics></math> used for generation.
Due to privacy concern, previous works place all generation on the client side without involving the server.
To compensate for the aforementioned comprehension deficiency, we further extend previous setting into a client-server framework to leverage the knowledge from the server-side professional model <math alttext="\mathbb{W}_{Pro}" class="ltx_Math" display="inline" id="S3.SS2.p2.2.m2.1"><semantics id="S3.SS2.p2.2.m2.1a"><msub id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mi id="S3.SS2.p2.2.m2.1.1.2" xref="S3.SS2.p2.2.m2.1.1.2.cmml">𝕎</mi><mrow id="S3.SS2.p2.2.m2.1.1.3" xref="S3.SS2.p2.2.m2.1.1.3.cmml"><mi id="S3.SS2.p2.2.m2.1.1.3.2" xref="S3.SS2.p2.2.m2.1.1.3.2.cmml">P</mi><mo id="S3.SS2.p2.2.m2.1.1.3.1" xref="S3.SS2.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.2.m2.1.1.3.3" xref="S3.SS2.p2.2.m2.1.1.3.3.cmml">r</mi><mo id="S3.SS2.p2.2.m2.1.1.3.1a" xref="S3.SS2.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p2.2.m2.1.1.3.4" xref="S3.SS2.p2.2.m2.1.1.3.4.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2">𝕎</ci><apply id="S3.SS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3"><times id="S3.SS2.p2.2.m2.1.1.3.1.cmml" xref="S3.SS2.p2.2.m2.1.1.3.1"></times><ci id="S3.SS2.p2.2.m2.1.1.3.2.cmml" xref="S3.SS2.p2.2.m2.1.1.3.2">𝑃</ci><ci id="S3.SS2.p2.2.m2.1.1.3.3.cmml" xref="S3.SS2.p2.2.m2.1.1.3.3">𝑟</ci><ci id="S3.SS2.p2.2.m2.1.1.3.4.cmml" xref="S3.SS2.p2.2.m2.1.1.3.4">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">\mathbb{W}_{Pro}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p2.2.m2.1d">blackboard_W start_POSTSUBSCRIPT italic_P italic_r italic_o end_POSTSUBSCRIPT</annotation></semantics></math>. We give further elaboration of the quality gap in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A5" title="Appendix E Differences of Domain-Specific Data from General Data ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">E</span></a>.</p>
</div>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1">The client-server framework of <span class="ltx_text ltx_font_italic" id="S3.SS2.p3.1.1">KnowledgeSG</span> involves learning local knowledge from private data on the client side and acquiring knowledge distillation from the professional model on the server side. We also design a convenient transmitting unit to mitigate potential eavesdropping.
In this way, we manage to achieve superior performance results while preventing memorization or leakage of the private dataset <math alttext="\mathbb{D}_{Pri}" class="ltx_Math" display="inline" id="S3.SS2.p3.1.m1.1"><semantics id="S3.SS2.p3.1.m1.1a"><msub id="S3.SS2.p3.1.m1.1.1" xref="S3.SS2.p3.1.m1.1.1.cmml"><mi id="S3.SS2.p3.1.m1.1.1.2" xref="S3.SS2.p3.1.m1.1.1.2.cmml">𝔻</mi><mrow id="S3.SS2.p3.1.m1.1.1.3" xref="S3.SS2.p3.1.m1.1.1.3.cmml"><mi id="S3.SS2.p3.1.m1.1.1.3.2" xref="S3.SS2.p3.1.m1.1.1.3.2.cmml">P</mi><mo id="S3.SS2.p3.1.m1.1.1.3.1" xref="S3.SS2.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.1.m1.1.1.3.3" xref="S3.SS2.p3.1.m1.1.1.3.3.cmml">r</mi><mo id="S3.SS2.p3.1.m1.1.1.3.1a" xref="S3.SS2.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS2.p3.1.m1.1.1.3.4" xref="S3.SS2.p3.1.m1.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.p3.1.m1.1b"><apply id="S3.SS2.p3.1.m1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.p3.1.m1.1.1.1.cmml" xref="S3.SS2.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.p3.1.m1.1.1.2.cmml" xref="S3.SS2.p3.1.m1.1.1.2">𝔻</ci><apply id="S3.SS2.p3.1.m1.1.1.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3"><times id="S3.SS2.p3.1.m1.1.1.3.1.cmml" xref="S3.SS2.p3.1.m1.1.1.3.1"></times><ci id="S3.SS2.p3.1.m1.1.1.3.2.cmml" xref="S3.SS2.p3.1.m1.1.1.3.2">𝑃</ci><ci id="S3.SS2.p3.1.m1.1.1.3.3.cmml" xref="S3.SS2.p3.1.m1.1.1.3.3">𝑟</ci><ci id="S3.SS2.p3.1.m1.1.1.3.4.cmml" xref="S3.SS2.p3.1.m1.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p3.1.m1.1c">\mathbb{D}_{Pri}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p3.1.m1.1d">blackboard_D start_POSTSUBSCRIPT italic_P italic_r italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Client Side</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">On the client side, our framework is primarily designed to extract knowledge from the private data <math alttext="\mathbb{D}_{Pri}" class="ltx_Math" display="inline" id="S3.SS3.p1.1.m1.1"><semantics id="S3.SS3.p1.1.m1.1a"><msub id="S3.SS3.p1.1.m1.1.1" xref="S3.SS3.p1.1.m1.1.1.cmml"><mi id="S3.SS3.p1.1.m1.1.1.2" xref="S3.SS3.p1.1.m1.1.1.2.cmml">𝔻</mi><mrow id="S3.SS3.p1.1.m1.1.1.3" xref="S3.SS3.p1.1.m1.1.1.3.cmml"><mi id="S3.SS3.p1.1.m1.1.1.3.2" xref="S3.SS3.p1.1.m1.1.1.3.2.cmml">P</mi><mo id="S3.SS3.p1.1.m1.1.1.3.1" xref="S3.SS3.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p1.1.m1.1.1.3.3" xref="S3.SS3.p1.1.m1.1.1.3.3.cmml">r</mi><mo id="S3.SS3.p1.1.m1.1.1.3.1a" xref="S3.SS3.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p1.1.m1.1.1.3.4" xref="S3.SS3.p1.1.m1.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p1.1.m1.1b"><apply id="S3.SS3.p1.1.m1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p1.1.m1.1.1.1.cmml" xref="S3.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p1.1.m1.1.1.2.cmml" xref="S3.SS3.p1.1.m1.1.1.2">𝔻</ci><apply id="S3.SS3.p1.1.m1.1.1.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3"><times id="S3.SS3.p1.1.m1.1.1.3.1.cmml" xref="S3.SS3.p1.1.m1.1.1.3.1"></times><ci id="S3.SS3.p1.1.m1.1.1.3.2.cmml" xref="S3.SS3.p1.1.m1.1.1.3.2">𝑃</ci><ci id="S3.SS3.p1.1.m1.1.1.3.3.cmml" xref="S3.SS3.p1.1.m1.1.1.3.3">𝑟</ci><ci id="S3.SS3.p1.1.m1.1.1.3.4.cmml" xref="S3.SS3.p1.1.m1.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p1.1.m1.1c">\mathbb{D}_{Pri}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p1.1.m1.1d">blackboard_D start_POSTSUBSCRIPT italic_P italic_r italic_i end_POSTSUBSCRIPT</annotation></semantics></math> without memorization and subordinately designed to be lightweight.</p>
</div>
<section class="ltx_paragraph" id="S3.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">DP-based Local Learning.</h4>
<div class="ltx_para" id="S3.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS3.SSS0.Px1.p1.2">Due to its direct access to <math alttext="\mathbb{D}_{Pri}" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px1.p1.1.m1.1"><semantics id="S3.SS3.SSS0.Px1.p1.1.m1.1a"><msub id="S3.SS3.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.2" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.2.cmml">𝔻</mi><mrow id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.cmml"><mi id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.2" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.2.cmml">P</mi><mo id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.1" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.cmml">r</mi><mo id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.1a" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.4" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px1.p1.1.m1.1b"><apply id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.2">𝔻</ci><apply id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3"><times id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.1"></times><ci id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.2">𝑃</ci><ci id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.3">𝑟</ci><ci id="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.4.cmml" xref="S3.SS3.SSS0.Px1.p1.1.m1.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px1.p1.1.m1.1c">\mathbb{D}_{Pri}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS0.Px1.p1.1.m1.1d">blackboard_D start_POSTSUBSCRIPT italic_P italic_r italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, the client side must comply with strict privacy constraint while still enabling effective knowledge learning from the private dataset <math alttext="\mathbb{D}_{Pri}" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px1.p1.2.m2.1"><semantics id="S3.SS3.SSS0.Px1.p1.2.m2.1a"><msub id="S3.SS3.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1.2.cmml">𝔻</mi><mrow id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.2" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.2.cmml">P</mi><mo id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.1" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.3" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.3.cmml">r</mi><mo id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.1a" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.4" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1.2">𝔻</ci><apply id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3"><times id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.1"></times><ci id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.2">𝑃</ci><ci id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.3">𝑟</ci><ci id="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.4.cmml" xref="S3.SS3.SSS0.Px1.p1.2.m2.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px1.p1.2.m2.1c">\mathbb{D}_{Pri}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS0.Px1.p1.2.m2.1d">blackboard_D start_POSTSUBSCRIPT italic_P italic_r italic_i end_POSTSUBSCRIPT</annotation></semantics></math>.
To achieve this primary goal, we adopt Differentially Private SGD (DP-SGD) <cite class="ltx_cite ltx_citemacro_cite">Abadi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib1" title="">2016</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS0.Px1.p2">
<p class="ltx_p" id="S3.SS3.SSS0.Px1.p2.5">DP-SGD is a privacy-preserving optimization algorithm that improves upon traditional Stochastic Gradient Descend (SGD) by adding noise to the gradients during training. This noise ensures that the inclusion or exclusion of any individual data sample has a minimal impact on the resulting fine-tuned model <math alttext="\mathbb{W}_{DP}" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px1.p2.1.m1.1"><semantics id="S3.SS3.SSS0.Px1.p2.1.m1.1a"><msub id="S3.SS3.SSS0.Px1.p2.1.m1.1.1" xref="S3.SS3.SSS0.Px1.p2.1.m1.1.1.cmml"><mi id="S3.SS3.SSS0.Px1.p2.1.m1.1.1.2" xref="S3.SS3.SSS0.Px1.p2.1.m1.1.1.2.cmml">𝕎</mi><mrow id="S3.SS3.SSS0.Px1.p2.1.m1.1.1.3" xref="S3.SS3.SSS0.Px1.p2.1.m1.1.1.3.cmml"><mi id="S3.SS3.SSS0.Px1.p2.1.m1.1.1.3.2" xref="S3.SS3.SSS0.Px1.p2.1.m1.1.1.3.2.cmml">D</mi><mo id="S3.SS3.SSS0.Px1.p2.1.m1.1.1.3.1" xref="S3.SS3.SSS0.Px1.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.SSS0.Px1.p2.1.m1.1.1.3.3" xref="S3.SS3.SSS0.Px1.p2.1.m1.1.1.3.3.cmml">P</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px1.p2.1.m1.1b"><apply id="S3.SS3.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S3.SS3.SSS0.Px1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px1.p2.1.m1.1.1.1.cmml" xref="S3.SS3.SSS0.Px1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.SSS0.Px1.p2.1.m1.1.1.2.cmml" xref="S3.SS3.SSS0.Px1.p2.1.m1.1.1.2">𝕎</ci><apply id="S3.SS3.SSS0.Px1.p2.1.m1.1.1.3.cmml" xref="S3.SS3.SSS0.Px1.p2.1.m1.1.1.3"><times id="S3.SS3.SSS0.Px1.p2.1.m1.1.1.3.1.cmml" xref="S3.SS3.SSS0.Px1.p2.1.m1.1.1.3.1"></times><ci id="S3.SS3.SSS0.Px1.p2.1.m1.1.1.3.2.cmml" xref="S3.SS3.SSS0.Px1.p2.1.m1.1.1.3.2">𝐷</ci><ci id="S3.SS3.SSS0.Px1.p2.1.m1.1.1.3.3.cmml" xref="S3.SS3.SSS0.Px1.p2.1.m1.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px1.p2.1.m1.1c">\mathbb{W}_{DP}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS0.Px1.p2.1.m1.1d">blackboard_W start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT</annotation></semantics></math>, offering strong privacy guarantees.
We follow the first step of previous works <cite class="ltx_cite ltx_citemacro_cite">Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib74" title="">2022</a>); Kurakin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib30" title="">2024</a>); Yue et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib75" title="">2023</a>)</cite> and adopt DP-SGD as our local training approach.
The local base model <math alttext="\mathbb{W}_{Loc}" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px1.p2.2.m2.1"><semantics id="S3.SS3.SSS0.Px1.p2.2.m2.1a"><msub id="S3.SS3.SSS0.Px1.p2.2.m2.1.1" xref="S3.SS3.SSS0.Px1.p2.2.m2.1.1.cmml"><mi id="S3.SS3.SSS0.Px1.p2.2.m2.1.1.2" xref="S3.SS3.SSS0.Px1.p2.2.m2.1.1.2.cmml">𝕎</mi><mrow id="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3" xref="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3.cmml"><mi id="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3.2" xref="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3.2.cmml">L</mi><mo id="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3.1" xref="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3.3" xref="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3.3.cmml">o</mi><mo id="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3.1a" xref="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3.4" xref="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3.4.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px1.p2.2.m2.1b"><apply id="S3.SS3.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S3.SS3.SSS0.Px1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px1.p2.2.m2.1.1.1.cmml" xref="S3.SS3.SSS0.Px1.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.SSS0.Px1.p2.2.m2.1.1.2.cmml" xref="S3.SS3.SSS0.Px1.p2.2.m2.1.1.2">𝕎</ci><apply id="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3.cmml" xref="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3"><times id="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3.1.cmml" xref="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3.1"></times><ci id="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3.2.cmml" xref="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3.2">𝐿</ci><ci id="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3.3.cmml" xref="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3.3">𝑜</ci><ci id="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3.4.cmml" xref="S3.SS3.SSS0.Px1.p2.2.m2.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px1.p2.2.m2.1c">\mathbb{W}_{Loc}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS0.Px1.p2.2.m2.1d">blackboard_W start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT</annotation></semantics></math> pre-trained on general corpora, is fine-tuned through DP-SGD, i.e. DP-finetuned on <math alttext="\mathbb{D}_{Pri}" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px1.p2.3.m3.1"><semantics id="S3.SS3.SSS0.Px1.p2.3.m3.1a"><msub id="S3.SS3.SSS0.Px1.p2.3.m3.1.1" xref="S3.SS3.SSS0.Px1.p2.3.m3.1.1.cmml"><mi id="S3.SS3.SSS0.Px1.p2.3.m3.1.1.2" xref="S3.SS3.SSS0.Px1.p2.3.m3.1.1.2.cmml">𝔻</mi><mrow id="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3" xref="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3.cmml"><mi id="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3.2" xref="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3.2.cmml">P</mi><mo id="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3.1" xref="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3.3" xref="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3.3.cmml">r</mi><mo id="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3.1a" xref="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3.4" xref="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px1.p2.3.m3.1b"><apply id="S3.SS3.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S3.SS3.SSS0.Px1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px1.p2.3.m3.1.1.1.cmml" xref="S3.SS3.SSS0.Px1.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.SSS0.Px1.p2.3.m3.1.1.2.cmml" xref="S3.SS3.SSS0.Px1.p2.3.m3.1.1.2">𝔻</ci><apply id="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3.cmml" xref="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3"><times id="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3.1.cmml" xref="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3.1"></times><ci id="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3.2.cmml" xref="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3.2">𝑃</ci><ci id="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3.3.cmml" xref="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3.3">𝑟</ci><ci id="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3.4.cmml" xref="S3.SS3.SSS0.Px1.p2.3.m3.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px1.p2.3.m3.1c">\mathbb{D}_{Pri}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS0.Px1.p2.3.m3.1d">blackboard_D start_POSTSUBSCRIPT italic_P italic_r italic_i end_POSTSUBSCRIPT</annotation></semantics></math> to gain local knowledge under a privacy budget <math alttext="(\epsilon,\delta)-DP" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px1.p2.4.m4.2"><semantics id="S3.SS3.SSS0.Px1.p2.4.m4.2a"><mrow id="S3.SS3.SSS0.Px1.p2.4.m4.2.3" xref="S3.SS3.SSS0.Px1.p2.4.m4.2.3.cmml"><mrow id="S3.SS3.SSS0.Px1.p2.4.m4.2.3.2.2" xref="S3.SS3.SSS0.Px1.p2.4.m4.2.3.2.1.cmml"><mo id="S3.SS3.SSS0.Px1.p2.4.m4.2.3.2.2.1" stretchy="false" xref="S3.SS3.SSS0.Px1.p2.4.m4.2.3.2.1.cmml">(</mo><mi id="S3.SS3.SSS0.Px1.p2.4.m4.1.1" xref="S3.SS3.SSS0.Px1.p2.4.m4.1.1.cmml">ϵ</mi><mo id="S3.SS3.SSS0.Px1.p2.4.m4.2.3.2.2.2" xref="S3.SS3.SSS0.Px1.p2.4.m4.2.3.2.1.cmml">,</mo><mi id="S3.SS3.SSS0.Px1.p2.4.m4.2.2" xref="S3.SS3.SSS0.Px1.p2.4.m4.2.2.cmml">δ</mi><mo id="S3.SS3.SSS0.Px1.p2.4.m4.2.3.2.2.3" stretchy="false" xref="S3.SS3.SSS0.Px1.p2.4.m4.2.3.2.1.cmml">)</mo></mrow><mo id="S3.SS3.SSS0.Px1.p2.4.m4.2.3.1" xref="S3.SS3.SSS0.Px1.p2.4.m4.2.3.1.cmml">−</mo><mrow id="S3.SS3.SSS0.Px1.p2.4.m4.2.3.3" xref="S3.SS3.SSS0.Px1.p2.4.m4.2.3.3.cmml"><mi id="S3.SS3.SSS0.Px1.p2.4.m4.2.3.3.2" xref="S3.SS3.SSS0.Px1.p2.4.m4.2.3.3.2.cmml">D</mi><mo id="S3.SS3.SSS0.Px1.p2.4.m4.2.3.3.1" xref="S3.SS3.SSS0.Px1.p2.4.m4.2.3.3.1.cmml">⁢</mo><mi id="S3.SS3.SSS0.Px1.p2.4.m4.2.3.3.3" xref="S3.SS3.SSS0.Px1.p2.4.m4.2.3.3.3.cmml">P</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px1.p2.4.m4.2b"><apply id="S3.SS3.SSS0.Px1.p2.4.m4.2.3.cmml" xref="S3.SS3.SSS0.Px1.p2.4.m4.2.3"><minus id="S3.SS3.SSS0.Px1.p2.4.m4.2.3.1.cmml" xref="S3.SS3.SSS0.Px1.p2.4.m4.2.3.1"></minus><interval closure="open" id="S3.SS3.SSS0.Px1.p2.4.m4.2.3.2.1.cmml" xref="S3.SS3.SSS0.Px1.p2.4.m4.2.3.2.2"><ci id="S3.SS3.SSS0.Px1.p2.4.m4.1.1.cmml" xref="S3.SS3.SSS0.Px1.p2.4.m4.1.1">italic-ϵ</ci><ci id="S3.SS3.SSS0.Px1.p2.4.m4.2.2.cmml" xref="S3.SS3.SSS0.Px1.p2.4.m4.2.2">𝛿</ci></interval><apply id="S3.SS3.SSS0.Px1.p2.4.m4.2.3.3.cmml" xref="S3.SS3.SSS0.Px1.p2.4.m4.2.3.3"><times id="S3.SS3.SSS0.Px1.p2.4.m4.2.3.3.1.cmml" xref="S3.SS3.SSS0.Px1.p2.4.m4.2.3.3.1"></times><ci id="S3.SS3.SSS0.Px1.p2.4.m4.2.3.3.2.cmml" xref="S3.SS3.SSS0.Px1.p2.4.m4.2.3.3.2">𝐷</ci><ci id="S3.SS3.SSS0.Px1.p2.4.m4.2.3.3.3.cmml" xref="S3.SS3.SSS0.Px1.p2.4.m4.2.3.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px1.p2.4.m4.2c">(\epsilon,\delta)-DP</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS0.Px1.p2.4.m4.2d">( italic_ϵ , italic_δ ) - italic_D italic_P</annotation></semantics></math>.
This budget theoretically guarantees the process of DP-finetuning without any leakage of private information, providing the basis for us to transmit the fine-tuned model <math alttext="\mathbb{W}_{DP}" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px1.p2.5.m5.1"><semantics id="S3.SS3.SSS0.Px1.p2.5.m5.1a"><msub id="S3.SS3.SSS0.Px1.p2.5.m5.1.1" xref="S3.SS3.SSS0.Px1.p2.5.m5.1.1.cmml"><mi id="S3.SS3.SSS0.Px1.p2.5.m5.1.1.2" xref="S3.SS3.SSS0.Px1.p2.5.m5.1.1.2.cmml">𝕎</mi><mrow id="S3.SS3.SSS0.Px1.p2.5.m5.1.1.3" xref="S3.SS3.SSS0.Px1.p2.5.m5.1.1.3.cmml"><mi id="S3.SS3.SSS0.Px1.p2.5.m5.1.1.3.2" xref="S3.SS3.SSS0.Px1.p2.5.m5.1.1.3.2.cmml">D</mi><mo id="S3.SS3.SSS0.Px1.p2.5.m5.1.1.3.1" xref="S3.SS3.SSS0.Px1.p2.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.SSS0.Px1.p2.5.m5.1.1.3.3" xref="S3.SS3.SSS0.Px1.p2.5.m5.1.1.3.3.cmml">P</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px1.p2.5.m5.1b"><apply id="S3.SS3.SSS0.Px1.p2.5.m5.1.1.cmml" xref="S3.SS3.SSS0.Px1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px1.p2.5.m5.1.1.1.cmml" xref="S3.SS3.SSS0.Px1.p2.5.m5.1.1">subscript</csymbol><ci id="S3.SS3.SSS0.Px1.p2.5.m5.1.1.2.cmml" xref="S3.SS3.SSS0.Px1.p2.5.m5.1.1.2">𝕎</ci><apply id="S3.SS3.SSS0.Px1.p2.5.m5.1.1.3.cmml" xref="S3.SS3.SSS0.Px1.p2.5.m5.1.1.3"><times id="S3.SS3.SSS0.Px1.p2.5.m5.1.1.3.1.cmml" xref="S3.SS3.SSS0.Px1.p2.5.m5.1.1.3.1"></times><ci id="S3.SS3.SSS0.Px1.p2.5.m5.1.1.3.2.cmml" xref="S3.SS3.SSS0.Px1.p2.5.m5.1.1.3.2">𝐷</ci><ci id="S3.SS3.SSS0.Px1.p2.5.m5.1.1.3.3.cmml" xref="S3.SS3.SSS0.Px1.p2.5.m5.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px1.p2.5.m5.1c">\mathbb{W}_{DP}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS0.Px1.p2.5.m5.1d">blackboard_W start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT</annotation></semantics></math> to the server later.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS3.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">LoRA Adaptation.</h4>
<div class="ltx_para" id="S3.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS3.SSS0.Px2.p1.1">The second characteristic of the client side in <span class="ltx_text ltx_font_italic" id="S3.SS3.SSS0.Px2.p1.1.1">Knowledge</span> is lightweight, since we do not expect the client to have substantial hardware resources compared to the server.
Therefore, we minimize the workload on the client by shifting the resource-intensive data generation process to the server.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS0.Px2.p2">
<p class="ltx_p" id="S3.SS3.SSS0.Px2.p2.1">Besides, we apply Low-Rank Adaptation (LoRA) <cite class="ltx_cite ltx_citemacro_cite">Hu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib22" title="">2021</a>)</cite> using the implementation of <cite class="ltx_cite ltx_citemacro_citet">Wutschitz et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib64" title="">2022</a>)</cite>, as our training approach.
LoRA is an efficient fine-tuning technique for large language models. It reduces the number of trainable parameters by introducing low-rank decomposition into the weight matrices of the model, allowing for faster and more resource-efficient adaptation to new tasks.</p>
</div>
<div class="ltx_para" id="S3.SS3.SSS0.Px2.p3">
<p class="ltx_p" id="S3.SS3.SSS0.Px2.p3.2">Even when considered relatively "small", the full size of the base model such as Llama2-7B, still occupies a significant amount of storage.
The resulting inconvenience for transmitting the full model weights of <math alttext="\mathbb{W}_{DP}" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px2.p3.1.m1.1"><semantics id="S3.SS3.SSS0.Px2.p3.1.m1.1a"><msub id="S3.SS3.SSS0.Px2.p3.1.m1.1.1" xref="S3.SS3.SSS0.Px2.p3.1.m1.1.1.cmml"><mi id="S3.SS3.SSS0.Px2.p3.1.m1.1.1.2" xref="S3.SS3.SSS0.Px2.p3.1.m1.1.1.2.cmml">𝕎</mi><mrow id="S3.SS3.SSS0.Px2.p3.1.m1.1.1.3" xref="S3.SS3.SSS0.Px2.p3.1.m1.1.1.3.cmml"><mi id="S3.SS3.SSS0.Px2.p3.1.m1.1.1.3.2" xref="S3.SS3.SSS0.Px2.p3.1.m1.1.1.3.2.cmml">D</mi><mo id="S3.SS3.SSS0.Px2.p3.1.m1.1.1.3.1" xref="S3.SS3.SSS0.Px2.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.SSS0.Px2.p3.1.m1.1.1.3.3" xref="S3.SS3.SSS0.Px2.p3.1.m1.1.1.3.3.cmml">P</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px2.p3.1.m1.1b"><apply id="S3.SS3.SSS0.Px2.p3.1.m1.1.1.cmml" xref="S3.SS3.SSS0.Px2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px2.p3.1.m1.1.1.1.cmml" xref="S3.SS3.SSS0.Px2.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.SSS0.Px2.p3.1.m1.1.1.2.cmml" xref="S3.SS3.SSS0.Px2.p3.1.m1.1.1.2">𝕎</ci><apply id="S3.SS3.SSS0.Px2.p3.1.m1.1.1.3.cmml" xref="S3.SS3.SSS0.Px2.p3.1.m1.1.1.3"><times id="S3.SS3.SSS0.Px2.p3.1.m1.1.1.3.1.cmml" xref="S3.SS3.SSS0.Px2.p3.1.m1.1.1.3.1"></times><ci id="S3.SS3.SSS0.Px2.p3.1.m1.1.1.3.2.cmml" xref="S3.SS3.SSS0.Px2.p3.1.m1.1.1.3.2">𝐷</ci><ci id="S3.SS3.SSS0.Px2.p3.1.m1.1.1.3.3.cmml" xref="S3.SS3.SSS0.Px2.p3.1.m1.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px2.p3.1.m1.1c">\mathbb{W}_{DP}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS0.Px2.p3.1.m1.1d">blackboard_W start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT</annotation></semantics></math> is plain to see.
In contrast, LoRA adaptation significantly reduces the transmission burden by allowing us to send only the LoRA adapter <math alttext="\mathbb{A}_{DP}" class="ltx_Math" display="inline" id="S3.SS3.SSS0.Px2.p3.2.m2.1"><semantics id="S3.SS3.SSS0.Px2.p3.2.m2.1a"><msub id="S3.SS3.SSS0.Px2.p3.2.m2.1.1" xref="S3.SS3.SSS0.Px2.p3.2.m2.1.1.cmml"><mi id="S3.SS3.SSS0.Px2.p3.2.m2.1.1.2" xref="S3.SS3.SSS0.Px2.p3.2.m2.1.1.2.cmml">𝔸</mi><mrow id="S3.SS3.SSS0.Px2.p3.2.m2.1.1.3" xref="S3.SS3.SSS0.Px2.p3.2.m2.1.1.3.cmml"><mi id="S3.SS3.SSS0.Px2.p3.2.m2.1.1.3.2" xref="S3.SS3.SSS0.Px2.p3.2.m2.1.1.3.2.cmml">D</mi><mo id="S3.SS3.SSS0.Px2.p3.2.m2.1.1.3.1" xref="S3.SS3.SSS0.Px2.p3.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.SSS0.Px2.p3.2.m2.1.1.3.3" xref="S3.SS3.SSS0.Px2.p3.2.m2.1.1.3.3.cmml">P</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS0.Px2.p3.2.m2.1b"><apply id="S3.SS3.SSS0.Px2.p3.2.m2.1.1.cmml" xref="S3.SS3.SSS0.Px2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS0.Px2.p3.2.m2.1.1.1.cmml" xref="S3.SS3.SSS0.Px2.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.SSS0.Px2.p3.2.m2.1.1.2.cmml" xref="S3.SS3.SSS0.Px2.p3.2.m2.1.1.2">𝔸</ci><apply id="S3.SS3.SSS0.Px2.p3.2.m2.1.1.3.cmml" xref="S3.SS3.SSS0.Px2.p3.2.m2.1.1.3"><times id="S3.SS3.SSS0.Px2.p3.2.m2.1.1.3.1.cmml" xref="S3.SS3.SSS0.Px2.p3.2.m2.1.1.3.1"></times><ci id="S3.SS3.SSS0.Px2.p3.2.m2.1.1.3.2.cmml" xref="S3.SS3.SSS0.Px2.p3.2.m2.1.1.3.2">𝐷</ci><ci id="S3.SS3.SSS0.Px2.p3.2.m2.1.1.3.3.cmml" xref="S3.SS3.SSS0.Px2.p3.2.m2.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS0.Px2.p3.2.m2.1c">\mathbb{A}_{DP}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.SSS0.Px2.p3.2.m2.1d">blackboard_A start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT</annotation></semantics></math>, resulting in a far more manageable model size.
Detailed comparison of model sizes is shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S3.T1" title="Table 1 ‣ LoRA Adaptation. ‣ 3.3 Client Side ‣ 3 Method ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.3.1.1">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.3.1.1.1" style="padding-left:3.3pt;padding-right:3.3pt;">Model Type</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.3.1.1.2" style="padding-left:3.3pt;padding-right:3.3pt;">Params</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.3.1.1.3" style="padding-left:3.3pt;padding-right:3.3pt;">Size</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.3.2.1">
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.2.1.1" style="padding-left:3.3pt;padding-right:3.3pt;">Base Model</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.2.1.2" style="padding-left:3.3pt;padding-right:3.3pt;">6738 M</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.3.2.1.3" style="padding-left:3.3pt;padding-right:3.3pt;">26 GB</td>
</tr>
<tr class="ltx_tr" id="S3.T1.3.3.2">
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.3.2.1" style="padding-left:3.3pt;padding-right:3.3pt;">LoRA Adapter</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.3.2.2" style="padding-left:3.3pt;padding-right:3.3pt;">4.2 M</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.3.3.2.3" style="padding-left:3.3pt;padding-right:3.3pt;">33 MB</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>The parameter numbers and model sizes for Llama2-7B with &amp; without LoRA rank of <math alttext="16" class="ltx_Math" display="inline" id="S3.T1.2.m1.1"><semantics id="S3.T1.2.m1.1b"><mn id="S3.T1.2.m1.1.1" xref="S3.T1.2.m1.1.1.cmml">16</mn><annotation-xml encoding="MathML-Content" id="S3.T1.2.m1.1c"><cn id="S3.T1.2.m1.1.1.cmml" type="integer" xref="S3.T1.2.m1.1.1">16</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.T1.2.m1.1d">16</annotation><annotation encoding="application/x-llamapun" id="S3.T1.2.m1.1e">16</annotation></semantics></math>.</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S3.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Server Side</h3>
<div class="ltx_para" id="S3.SS4.p1">
<p class="ltx_p" id="S3.SS4.p1.1">The server side of <span class="ltx_text ltx_font_italic" id="S3.SS4.p1.1.1">KnowledgeSG</span> is designed to improve data quality beyond what can be achieved by relying solely on the client. It operates through three stages: raw synthetic data generation, refinement of raw synthetic data and normal fine-tuning of local model.</p>
</div>
<section class="ltx_paragraph" id="S3.SS4.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Synthetic Instructions Generation.</h4>
<div class="ltx_para" id="S3.SS4.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS4.SSS0.Px1.p1.5">The first step on the server side is to recover the full model <math alttext="\mathbb{W}_{DP}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p1.1.m1.1"><semantics id="S3.SS4.SSS0.Px1.p1.1.m1.1a"><msub id="S3.SS4.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.2" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.2.cmml">𝕎</mi><mrow id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.2" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.2.cmml">D</mi><mo id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.1" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.3" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.3.cmml">P</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p1.1.m1.1b"><apply id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.2">𝕎</ci><apply id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3"><times id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.2">𝐷</ci><ci id="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px1.p1.1.m1.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p1.1.m1.1c">\mathbb{W}_{DP}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p1.1.m1.1d">blackboard_W start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT</annotation></semantics></math> from <math alttext="\mathbb{A}_{DP}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p1.2.m2.1"><semantics id="S3.SS4.SSS0.Px1.p1.2.m2.1a"><msub id="S3.SS4.SSS0.Px1.p1.2.m2.1.1" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.2" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.2.cmml">𝔸</mi><mrow id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.2" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.2.cmml">D</mi><mo id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.1" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.3" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.3.cmml">P</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p1.2.m2.1b"><apply id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.2">𝔸</ci><apply id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3"><times id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.2">𝐷</ci><ci id="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px1.p1.2.m2.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p1.2.m2.1c">\mathbb{A}_{DP}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p1.2.m2.1d">blackboard_A start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT</annotation></semantics></math>, assuming the server has the same base model <math alttext="\mathbb{W}_{Loc}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p1.3.m3.1"><semantics id="S3.SS4.SSS0.Px1.p1.3.m3.1a"><msub id="S3.SS4.SSS0.Px1.p1.3.m3.1.1" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1.cmml"><mi id="S3.SS4.SSS0.Px1.p1.3.m3.1.1.2" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1.2.cmml">𝕎</mi><mrow id="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.2" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.2.cmml">L</mi><mo id="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.1" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.3" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.3.cmml">o</mi><mo id="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.1a" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.4" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.4.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p1.3.m3.1b"><apply id="S3.SS4.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1.2">𝕎</ci><apply id="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3"><times id="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.2">𝐿</ci><ci id="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.3">𝑜</ci><ci id="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.4.cmml" xref="S3.SS4.SSS0.Px1.p1.3.m3.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p1.3.m3.1c">\mathbb{W}_{Loc}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p1.3.m3.1d">blackboard_W start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT</annotation></semantics></math> as the client prior to communication.
Afterward, we prompt the DP-finetuned model <math alttext="\mathbb{W}_{DP}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p1.4.m4.1"><semantics id="S3.SS4.SSS0.Px1.p1.4.m4.1a"><msub id="S3.SS4.SSS0.Px1.p1.4.m4.1.1" xref="S3.SS4.SSS0.Px1.p1.4.m4.1.1.cmml"><mi id="S3.SS4.SSS0.Px1.p1.4.m4.1.1.2" xref="S3.SS4.SSS0.Px1.p1.4.m4.1.1.2.cmml">𝕎</mi><mrow id="S3.SS4.SSS0.Px1.p1.4.m4.1.1.3" xref="S3.SS4.SSS0.Px1.p1.4.m4.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px1.p1.4.m4.1.1.3.2" xref="S3.SS4.SSS0.Px1.p1.4.m4.1.1.3.2.cmml">D</mi><mo id="S3.SS4.SSS0.Px1.p1.4.m4.1.1.3.1" xref="S3.SS4.SSS0.Px1.p1.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px1.p1.4.m4.1.1.3.3" xref="S3.SS4.SSS0.Px1.p1.4.m4.1.1.3.3.cmml">P</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p1.4.m4.1b"><apply id="S3.SS4.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.4.m4.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S3.SS4.SSS0.Px1.p1.4.m4.1.1.2">𝕎</ci><apply id="S3.SS4.SSS0.Px1.p1.4.m4.1.1.3.cmml" xref="S3.SS4.SSS0.Px1.p1.4.m4.1.1.3"><times id="S3.SS4.SSS0.Px1.p1.4.m4.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px1.p1.4.m4.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px1.p1.4.m4.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px1.p1.4.m4.1.1.3.2">𝐷</ci><ci id="S3.SS4.SSS0.Px1.p1.4.m4.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px1.p1.4.m4.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p1.4.m4.1c">\mathbb{W}_{DP}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p1.4.m4.1d">blackboard_W start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT</annotation></semantics></math>, which has knowledge of the private data <math alttext="\mathbb{D}_{Pri}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p1.5.m5.1"><semantics id="S3.SS4.SSS0.Px1.p1.5.m5.1a"><msub id="S3.SS4.SSS0.Px1.p1.5.m5.1.1" xref="S3.SS4.SSS0.Px1.p1.5.m5.1.1.cmml"><mi id="S3.SS4.SSS0.Px1.p1.5.m5.1.1.2" xref="S3.SS4.SSS0.Px1.p1.5.m5.1.1.2.cmml">𝔻</mi><mrow id="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3" xref="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3.2" xref="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3.2.cmml">P</mi><mo id="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3.1" xref="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3.3" xref="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3.3.cmml">r</mi><mo id="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3.1a" xref="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3.4" xref="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p1.5.m5.1b"><apply id="S3.SS4.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px1.p1.5.m5.1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p1.5.m5.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S3.SS4.SSS0.Px1.p1.5.m5.1.1.2">𝔻</ci><apply id="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3.cmml" xref="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3"><times id="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3.2">𝑃</ci><ci id="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3.3">𝑟</ci><ci id="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3.4.cmml" xref="S3.SS4.SSS0.Px1.p1.5.m5.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p1.5.m5.1c">\mathbb{D}_{Pri}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p1.5.m5.1d">blackboard_D start_POSTSUBSCRIPT italic_P italic_r italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, to generate raw synthetic instructions.</p>
</div>
<div class="ltx_para" id="S3.SS4.SSS0.Px1.p2">
<p class="ltx_p" id="S3.SS4.SSS0.Px1.p2.4">The post-processing property of DP <cite class="ltx_cite ltx_citemacro_cite">Dwork and Roth (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib16" title="">2014</a>)</cite> ensures that once the model <math alttext="\mathbb{W}_{Loc}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p2.1.m1.1"><semantics id="S3.SS4.SSS0.Px1.p2.1.m1.1a"><msub id="S3.SS4.SSS0.Px1.p2.1.m1.1.1" xref="S3.SS4.SSS0.Px1.p2.1.m1.1.1.cmml"><mi id="S3.SS4.SSS0.Px1.p2.1.m1.1.1.2" xref="S3.SS4.SSS0.Px1.p2.1.m1.1.1.2.cmml">𝕎</mi><mrow id="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3" xref="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3.2" xref="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3.2.cmml">L</mi><mo id="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3.1" xref="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3.3" xref="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3.3.cmml">o</mi><mo id="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3.1a" xref="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3.4" xref="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3.4.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p2.1.m1.1b"><apply id="S3.SS4.SSS0.Px1.p2.1.m1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px1.p2.1.m1.1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px1.p2.1.m1.1.1.2.cmml" xref="S3.SS4.SSS0.Px1.p2.1.m1.1.1.2">𝕎</ci><apply id="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3.cmml" xref="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3"><times id="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3.2">𝐿</ci><ci id="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3.3">𝑜</ci><ci id="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3.4.cmml" xref="S3.SS4.SSS0.Px1.p2.1.m1.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p2.1.m1.1c">\mathbb{W}_{Loc}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p2.1.m1.1d">blackboard_W start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT</annotation></semantics></math> has been fine-tuned with DP, sampling from the fine-tuned model <math alttext="\mathbb{W}_{DP}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p2.2.m2.1"><semantics id="S3.SS4.SSS0.Px1.p2.2.m2.1a"><msub id="S3.SS4.SSS0.Px1.p2.2.m2.1.1" xref="S3.SS4.SSS0.Px1.p2.2.m2.1.1.cmml"><mi id="S3.SS4.SSS0.Px1.p2.2.m2.1.1.2" xref="S3.SS4.SSS0.Px1.p2.2.m2.1.1.2.cmml">𝕎</mi><mrow id="S3.SS4.SSS0.Px1.p2.2.m2.1.1.3" xref="S3.SS4.SSS0.Px1.p2.2.m2.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px1.p2.2.m2.1.1.3.2" xref="S3.SS4.SSS0.Px1.p2.2.m2.1.1.3.2.cmml">D</mi><mo id="S3.SS4.SSS0.Px1.p2.2.m2.1.1.3.1" xref="S3.SS4.SSS0.Px1.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px1.p2.2.m2.1.1.3.3" xref="S3.SS4.SSS0.Px1.p2.2.m2.1.1.3.3.cmml">P</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p2.2.m2.1b"><apply id="S3.SS4.SSS0.Px1.p2.2.m2.1.1.cmml" xref="S3.SS4.SSS0.Px1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px1.p2.2.m2.1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px1.p2.2.m2.1.1.2.cmml" xref="S3.SS4.SSS0.Px1.p2.2.m2.1.1.2">𝕎</ci><apply id="S3.SS4.SSS0.Px1.p2.2.m2.1.1.3.cmml" xref="S3.SS4.SSS0.Px1.p2.2.m2.1.1.3"><times id="S3.SS4.SSS0.Px1.p2.2.m2.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px1.p2.2.m2.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px1.p2.2.m2.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px1.p2.2.m2.1.1.3.2">𝐷</ci><ci id="S3.SS4.SSS0.Px1.p2.2.m2.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px1.p2.2.m2.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p2.2.m2.1c">\mathbb{W}_{DP}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p2.2.m2.1d">blackboard_W start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT</annotation></semantics></math> incurs no extra privacy loss. As a result, when the LoRA adapter <math alttext="\mathbb{A}_{DP}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p2.3.m3.1"><semantics id="S3.SS4.SSS0.Px1.p2.3.m3.1a"><msub id="S3.SS4.SSS0.Px1.p2.3.m3.1.1" xref="S3.SS4.SSS0.Px1.p2.3.m3.1.1.cmml"><mi id="S3.SS4.SSS0.Px1.p2.3.m3.1.1.2" xref="S3.SS4.SSS0.Px1.p2.3.m3.1.1.2.cmml">𝔸</mi><mrow id="S3.SS4.SSS0.Px1.p2.3.m3.1.1.3" xref="S3.SS4.SSS0.Px1.p2.3.m3.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px1.p2.3.m3.1.1.3.2" xref="S3.SS4.SSS0.Px1.p2.3.m3.1.1.3.2.cmml">D</mi><mo id="S3.SS4.SSS0.Px1.p2.3.m3.1.1.3.1" xref="S3.SS4.SSS0.Px1.p2.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px1.p2.3.m3.1.1.3.3" xref="S3.SS4.SSS0.Px1.p2.3.m3.1.1.3.3.cmml">P</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p2.3.m3.1b"><apply id="S3.SS4.SSS0.Px1.p2.3.m3.1.1.cmml" xref="S3.SS4.SSS0.Px1.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px1.p2.3.m3.1.1.1.cmml" xref="S3.SS4.SSS0.Px1.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px1.p2.3.m3.1.1.2.cmml" xref="S3.SS4.SSS0.Px1.p2.3.m3.1.1.2">𝔸</ci><apply id="S3.SS4.SSS0.Px1.p2.3.m3.1.1.3.cmml" xref="S3.SS4.SSS0.Px1.p2.3.m3.1.1.3"><times id="S3.SS4.SSS0.Px1.p2.3.m3.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px1.p2.3.m3.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px1.p2.3.m3.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px1.p2.3.m3.1.1.3.2">𝐷</ci><ci id="S3.SS4.SSS0.Px1.p2.3.m3.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px1.p2.3.m3.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p2.3.m3.1c">\mathbb{A}_{DP}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p2.3.m3.1d">blackboard_A start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT</annotation></semantics></math> is uploaded to the server, it can generate synthetic data without exceeding the privacy budget <math alttext="(\epsilon,\delta)-DP" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px1.p2.4.m4.2"><semantics id="S3.SS4.SSS0.Px1.p2.4.m4.2a"><mrow id="S3.SS4.SSS0.Px1.p2.4.m4.2.3" xref="S3.SS4.SSS0.Px1.p2.4.m4.2.3.cmml"><mrow id="S3.SS4.SSS0.Px1.p2.4.m4.2.3.2.2" xref="S3.SS4.SSS0.Px1.p2.4.m4.2.3.2.1.cmml"><mo id="S3.SS4.SSS0.Px1.p2.4.m4.2.3.2.2.1" stretchy="false" xref="S3.SS4.SSS0.Px1.p2.4.m4.2.3.2.1.cmml">(</mo><mi id="S3.SS4.SSS0.Px1.p2.4.m4.1.1" xref="S3.SS4.SSS0.Px1.p2.4.m4.1.1.cmml">ϵ</mi><mo id="S3.SS4.SSS0.Px1.p2.4.m4.2.3.2.2.2" xref="S3.SS4.SSS0.Px1.p2.4.m4.2.3.2.1.cmml">,</mo><mi id="S3.SS4.SSS0.Px1.p2.4.m4.2.2" xref="S3.SS4.SSS0.Px1.p2.4.m4.2.2.cmml">δ</mi><mo id="S3.SS4.SSS0.Px1.p2.4.m4.2.3.2.2.3" stretchy="false" xref="S3.SS4.SSS0.Px1.p2.4.m4.2.3.2.1.cmml">)</mo></mrow><mo id="S3.SS4.SSS0.Px1.p2.4.m4.2.3.1" xref="S3.SS4.SSS0.Px1.p2.4.m4.2.3.1.cmml">−</mo><mrow id="S3.SS4.SSS0.Px1.p2.4.m4.2.3.3" xref="S3.SS4.SSS0.Px1.p2.4.m4.2.3.3.cmml"><mi id="S3.SS4.SSS0.Px1.p2.4.m4.2.3.3.2" xref="S3.SS4.SSS0.Px1.p2.4.m4.2.3.3.2.cmml">D</mi><mo id="S3.SS4.SSS0.Px1.p2.4.m4.2.3.3.1" xref="S3.SS4.SSS0.Px1.p2.4.m4.2.3.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px1.p2.4.m4.2.3.3.3" xref="S3.SS4.SSS0.Px1.p2.4.m4.2.3.3.3.cmml">P</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px1.p2.4.m4.2b"><apply id="S3.SS4.SSS0.Px1.p2.4.m4.2.3.cmml" xref="S3.SS4.SSS0.Px1.p2.4.m4.2.3"><minus id="S3.SS4.SSS0.Px1.p2.4.m4.2.3.1.cmml" xref="S3.SS4.SSS0.Px1.p2.4.m4.2.3.1"></minus><interval closure="open" id="S3.SS4.SSS0.Px1.p2.4.m4.2.3.2.1.cmml" xref="S3.SS4.SSS0.Px1.p2.4.m4.2.3.2.2"><ci id="S3.SS4.SSS0.Px1.p2.4.m4.1.1.cmml" xref="S3.SS4.SSS0.Px1.p2.4.m4.1.1">italic-ϵ</ci><ci id="S3.SS4.SSS0.Px1.p2.4.m4.2.2.cmml" xref="S3.SS4.SSS0.Px1.p2.4.m4.2.2">𝛿</ci></interval><apply id="S3.SS4.SSS0.Px1.p2.4.m4.2.3.3.cmml" xref="S3.SS4.SSS0.Px1.p2.4.m4.2.3.3"><times id="S3.SS4.SSS0.Px1.p2.4.m4.2.3.3.1.cmml" xref="S3.SS4.SSS0.Px1.p2.4.m4.2.3.3.1"></times><ci id="S3.SS4.SSS0.Px1.p2.4.m4.2.3.3.2.cmml" xref="S3.SS4.SSS0.Px1.p2.4.m4.2.3.3.2">𝐷</ci><ci id="S3.SS4.SSS0.Px1.p2.4.m4.2.3.3.3.cmml" xref="S3.SS4.SSS0.Px1.p2.4.m4.2.3.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px1.p2.4.m4.2c">(\epsilon,\delta)-DP</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px1.p2.4.m4.2d">( italic_ϵ , italic_δ ) - italic_D italic_P</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS4.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Synthetic Instruction Filtration.</h4>
<div class="ltx_para" id="S3.SS4.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS4.SSS0.Px2.p1.1">During the second stage, to realize optimal results, we apply two compatible filtration methods distinguished by whether assistance from the professional model <math alttext="\mathbb{W}_{Pro}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px2.p1.1.m1.1"><semantics id="S3.SS4.SSS0.Px2.p1.1.m1.1a"><msub id="S3.SS4.SSS0.Px2.p1.1.m1.1.1" xref="S3.SS4.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="S3.SS4.SSS0.Px2.p1.1.m1.1.1.2" xref="S3.SS4.SSS0.Px2.p1.1.m1.1.1.2.cmml">𝕎</mi><mrow id="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3" xref="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3.2" xref="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3.2.cmml">P</mi><mo id="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3.1" xref="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3.3" xref="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3.3.cmml">r</mi><mo id="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3.1a" xref="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3.4" xref="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3.4.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px2.p1.1.m1.1b"><apply id="S3.SS4.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S3.SS4.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S3.SS4.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="S3.SS4.SSS0.Px2.p1.1.m1.1.1.2">𝕎</ci><apply id="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3"><times id="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3.2">𝑃</ci><ci id="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3.3">𝑟</ci><ci id="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3.4.cmml" xref="S3.SS4.SSS0.Px2.p1.1.m1.1.1.3.4">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px2.p1.1.m1.1c">\mathbb{W}_{Pro}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px2.p1.1.m1.1d">blackboard_W start_POSTSUBSCRIPT italic_P italic_r italic_o end_POSTSUBSCRIPT</annotation></semantics></math> is required.</p>
</div>
<div class="ltx_para" id="S3.SS4.SSS0.Px2.p2">
<p class="ltx_p" id="S3.SS4.SSS0.Px2.p2.2">Filtration without <math alttext="\mathbb{W}_{Pro}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px2.p2.1.m1.1"><semantics id="S3.SS4.SSS0.Px2.p2.1.m1.1a"><msub id="S3.SS4.SSS0.Px2.p2.1.m1.1.1" xref="S3.SS4.SSS0.Px2.p2.1.m1.1.1.cmml"><mi id="S3.SS4.SSS0.Px2.p2.1.m1.1.1.2" xref="S3.SS4.SSS0.Px2.p2.1.m1.1.1.2.cmml">𝕎</mi><mrow id="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3" xref="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3.2" xref="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3.2.cmml">P</mi><mo id="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3.1" xref="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3.3" xref="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3.3.cmml">r</mi><mo id="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3.1a" xref="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3.4" xref="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3.4.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px2.p2.1.m1.1b"><apply id="S3.SS4.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S3.SS4.SSS0.Px2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="S3.SS4.SSS0.Px2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="S3.SS4.SSS0.Px2.p2.1.m1.1.1.2">𝕎</ci><apply id="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3.cmml" xref="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3"><times id="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3.2">𝑃</ci><ci id="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3.3">𝑟</ci><ci id="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3.4.cmml" xref="S3.SS4.SSS0.Px2.p2.1.m1.1.1.3.4">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px2.p2.1.m1.1c">\mathbb{W}_{Pro}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px2.p2.1.m1.1d">blackboard_W start_POSTSUBSCRIPT italic_P italic_r italic_o end_POSTSUBSCRIPT</annotation></semantics></math> uses similarity de-duplication via the BLEU score <cite class="ltx_cite ltx_citemacro_cite">Papineni et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib50" title="">2002</a>)</cite>.
Bilingual Evaluation Understudy (BLEU) is a widely used automated evaluation metric for measuring the similarity between machine translation outputs and reference translations to assess translation quality. We adopt it to determine if an synthetic instruction is too similar to any example from the private dataset <math alttext="\mathbb{D}_{Pri}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px2.p2.2.m2.1"><semantics id="S3.SS4.SSS0.Px2.p2.2.m2.1a"><msub id="S3.SS4.SSS0.Px2.p2.2.m2.1.1" xref="S3.SS4.SSS0.Px2.p2.2.m2.1.1.cmml"><mi id="S3.SS4.SSS0.Px2.p2.2.m2.1.1.2" xref="S3.SS4.SSS0.Px2.p2.2.m2.1.1.2.cmml">𝔻</mi><mrow id="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3" xref="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3.2" xref="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3.2.cmml">P</mi><mo id="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3.1" xref="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3.3" xref="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3.3.cmml">r</mi><mo id="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3.1a" xref="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3.4" xref="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px2.p2.2.m2.1b"><apply id="S3.SS4.SSS0.Px2.p2.2.m2.1.1.cmml" xref="S3.SS4.SSS0.Px2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px2.p2.2.m2.1.1.1.cmml" xref="S3.SS4.SSS0.Px2.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px2.p2.2.m2.1.1.2.cmml" xref="S3.SS4.SSS0.Px2.p2.2.m2.1.1.2">𝔻</ci><apply id="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3.cmml" xref="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3"><times id="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3.2">𝑃</ci><ci id="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3.3">𝑟</ci><ci id="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3.4.cmml" xref="S3.SS4.SSS0.Px2.p2.2.m2.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px2.p2.2.m2.1c">\mathbb{D}_{Pri}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px2.p2.2.m2.1d">blackboard_D start_POSTSUBSCRIPT italic_P italic_r italic_i end_POSTSUBSCRIPT</annotation></semantics></math> to raise possibilities of leaking privacy. This method is much faster compared with the other model-based method.</p>
</div>
<div class="ltx_para" id="S3.SS4.SSS0.Px2.p3">
<p class="ltx_p" id="S3.SS4.SSS0.Px2.p3.4">For the filtration method involving <math alttext="\mathbb{W}_{Pro}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px2.p3.1.m1.1"><semantics id="S3.SS4.SSS0.Px2.p3.1.m1.1a"><msub id="S3.SS4.SSS0.Px2.p3.1.m1.1.1" xref="S3.SS4.SSS0.Px2.p3.1.m1.1.1.cmml"><mi id="S3.SS4.SSS0.Px2.p3.1.m1.1.1.2" xref="S3.SS4.SSS0.Px2.p3.1.m1.1.1.2.cmml">𝕎</mi><mrow id="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3" xref="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3.2" xref="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3.2.cmml">P</mi><mo id="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3.1" xref="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3.3" xref="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3.3.cmml">r</mi><mo id="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3.1a" xref="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3.4" xref="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3.4.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px2.p3.1.m1.1b"><apply id="S3.SS4.SSS0.Px2.p3.1.m1.1.1.cmml" xref="S3.SS4.SSS0.Px2.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px2.p3.1.m1.1.1.1.cmml" xref="S3.SS4.SSS0.Px2.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px2.p3.1.m1.1.1.2.cmml" xref="S3.SS4.SSS0.Px2.p3.1.m1.1.1.2">𝕎</ci><apply id="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3.cmml" xref="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3"><times id="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3.2">𝑃</ci><ci id="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3.3">𝑟</ci><ci id="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3.4.cmml" xref="S3.SS4.SSS0.Px2.p3.1.m1.1.1.3.4">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px2.p3.1.m1.1c">\mathbb{W}_{Pro}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px2.p3.1.m1.1d">blackboard_W start_POSTSUBSCRIPT italic_P italic_r italic_o end_POSTSUBSCRIPT</annotation></semantics></math>, we prompt the raw instructions into <math alttext="\mathbb{W}_{Pro}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px2.p3.2.m2.1"><semantics id="S3.SS4.SSS0.Px2.p3.2.m2.1a"><msub id="S3.SS4.SSS0.Px2.p3.2.m2.1.1" xref="S3.SS4.SSS0.Px2.p3.2.m2.1.1.cmml"><mi id="S3.SS4.SSS0.Px2.p3.2.m2.1.1.2" xref="S3.SS4.SSS0.Px2.p3.2.m2.1.1.2.cmml">𝕎</mi><mrow id="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3" xref="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3.2" xref="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3.2.cmml">P</mi><mo id="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3.1" xref="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3.3" xref="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3.3.cmml">r</mi><mo id="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3.1a" xref="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3.4" xref="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3.4.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px2.p3.2.m2.1b"><apply id="S3.SS4.SSS0.Px2.p3.2.m2.1.1.cmml" xref="S3.SS4.SSS0.Px2.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px2.p3.2.m2.1.1.1.cmml" xref="S3.SS4.SSS0.Px2.p3.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px2.p3.2.m2.1.1.2.cmml" xref="S3.SS4.SSS0.Px2.p3.2.m2.1.1.2">𝕎</ci><apply id="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3.cmml" xref="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3"><times id="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3.2">𝑃</ci><ci id="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3.3">𝑟</ci><ci id="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3.4.cmml" xref="S3.SS4.SSS0.Px2.p3.2.m2.1.1.3.4">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px2.p3.2.m2.1c">\mathbb{W}_{Pro}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px2.p3.2.m2.1d">blackboard_W start_POSTSUBSCRIPT italic_P italic_r italic_o end_POSTSUBSCRIPT</annotation></semantics></math> for judgements. If the instruction is domain-specific, <math alttext="\mathbb{W}_{Pro}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px2.p3.3.m3.1"><semantics id="S3.SS4.SSS0.Px2.p3.3.m3.1a"><msub id="S3.SS4.SSS0.Px2.p3.3.m3.1.1" xref="S3.SS4.SSS0.Px2.p3.3.m3.1.1.cmml"><mi id="S3.SS4.SSS0.Px2.p3.3.m3.1.1.2" xref="S3.SS4.SSS0.Px2.p3.3.m3.1.1.2.cmml">𝕎</mi><mrow id="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3" xref="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3.2" xref="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3.2.cmml">P</mi><mo id="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3.1" xref="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3.3" xref="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3.3.cmml">r</mi><mo id="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3.1a" xref="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3.4" xref="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3.4.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px2.p3.3.m3.1b"><apply id="S3.SS4.SSS0.Px2.p3.3.m3.1.1.cmml" xref="S3.SS4.SSS0.Px2.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px2.p3.3.m3.1.1.1.cmml" xref="S3.SS4.SSS0.Px2.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px2.p3.3.m3.1.1.2.cmml" xref="S3.SS4.SSS0.Px2.p3.3.m3.1.1.2">𝕎</ci><apply id="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3.cmml" xref="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3"><times id="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3.2">𝑃</ci><ci id="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3.3">𝑟</ci><ci id="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3.4.cmml" xref="S3.SS4.SSS0.Px2.p3.3.m3.1.1.3.4">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px2.p3.3.m3.1c">\mathbb{W}_{Pro}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px2.p3.3.m3.1d">blackboard_W start_POSTSUBSCRIPT italic_P italic_r italic_o end_POSTSUBSCRIPT</annotation></semantics></math> assesses whether it is relevant to its domain.
If it is domain-specific, <math alttext="\mathbb{W}_{Pro}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px2.p3.4.m4.1"><semantics id="S3.SS4.SSS0.Px2.p3.4.m4.1a"><msub id="S3.SS4.SSS0.Px2.p3.4.m4.1.1" xref="S3.SS4.SSS0.Px2.p3.4.m4.1.1.cmml"><mi id="S3.SS4.SSS0.Px2.p3.4.m4.1.1.2" xref="S3.SS4.SSS0.Px2.p3.4.m4.1.1.2.cmml">𝕎</mi><mrow id="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3" xref="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3.2" xref="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3.2.cmml">P</mi><mo id="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3.1" xref="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3.3" xref="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3.3.cmml">r</mi><mo id="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3.1a" xref="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3.4" xref="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3.4.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px2.p3.4.m4.1b"><apply id="S3.SS4.SSS0.Px2.p3.4.m4.1.1.cmml" xref="S3.SS4.SSS0.Px2.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px2.p3.4.m4.1.1.1.cmml" xref="S3.SS4.SSS0.Px2.p3.4.m4.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px2.p3.4.m4.1.1.2.cmml" xref="S3.SS4.SSS0.Px2.p3.4.m4.1.1.2">𝕎</ci><apply id="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3.cmml" xref="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3"><times id="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3.2">𝑃</ci><ci id="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3.3">𝑟</ci><ci id="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3.4.cmml" xref="S3.SS4.SSS0.Px2.p3.4.m4.1.1.3.4">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px2.p3.4.m4.1c">\mathbb{W}_{Pro}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px2.p3.4.m4.1d">blackboard_W start_POSTSUBSCRIPT italic_P italic_r italic_o end_POSTSUBSCRIPT</annotation></semantics></math> judges an instructions based on whether this instruction is related to its domain. The detailed prompt we use is provided in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A8" title="Appendix H Templates ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">H</span></a>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS4.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Efficient Knowledge Distillation.</h4>
<div class="ltx_para" id="S3.SS4.SSS0.Px3.p1">
<p class="ltx_p" id="S3.SS4.SSS0.Px3.p1.3">Without the need to derive loss from <math alttext="\mathbb{W}_{Pro}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px3.p1.1.m1.1"><semantics id="S3.SS4.SSS0.Px3.p1.1.m1.1a"><msub id="S3.SS4.SSS0.Px3.p1.1.m1.1.1" xref="S3.SS4.SSS0.Px3.p1.1.m1.1.1.cmml"><mi id="S3.SS4.SSS0.Px3.p1.1.m1.1.1.2" xref="S3.SS4.SSS0.Px3.p1.1.m1.1.1.2.cmml">𝕎</mi><mrow id="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3" xref="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3.2" xref="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3.2.cmml">P</mi><mo id="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3.1" xref="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3.3" xref="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3.3.cmml">r</mi><mo id="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3.1a" xref="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3.4" xref="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3.4.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px3.p1.1.m1.1b"><apply id="S3.SS4.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S3.SS4.SSS0.Px3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px3.p1.1.m1.1.1.1.cmml" xref="S3.SS4.SSS0.Px3.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px3.p1.1.m1.1.1.2.cmml" xref="S3.SS4.SSS0.Px3.p1.1.m1.1.1.2">𝕎</ci><apply id="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3.cmml" xref="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3"><times id="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3.2">𝑃</ci><ci id="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3.3">𝑟</ci><ci id="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3.4.cmml" xref="S3.SS4.SSS0.Px3.p1.1.m1.1.1.3.4">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px3.p1.1.m1.1c">\mathbb{W}_{Pro}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px3.p1.1.m1.1d">blackboard_W start_POSTSUBSCRIPT italic_P italic_r italic_o end_POSTSUBSCRIPT</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">Flemings and Annavaram (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib17" title="">2024</a>)</cite>, we use a convenient method of knowledge distillation by feeding top instructions into <math alttext="\mathbb{W}_{Pro}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px3.p1.2.m2.1"><semantics id="S3.SS4.SSS0.Px3.p1.2.m2.1a"><msub id="S3.SS4.SSS0.Px3.p1.2.m2.1.1" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1.cmml"><mi id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.2" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1.2.cmml">𝕎</mi><mrow id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.2" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.2.cmml">P</mi><mo id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.1" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.3" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.3.cmml">r</mi><mo id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.1a" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.4" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.4.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px3.p1.2.m2.1b"><apply id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.1.cmml" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.2.cmml" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1.2">𝕎</ci><apply id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.cmml" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3"><times id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.2">𝑃</ci><ci id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.3">𝑟</ci><ci id="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.4.cmml" xref="S3.SS4.SSS0.Px3.p1.2.m2.1.1.3.4">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px3.p1.2.m2.1c">\mathbb{W}_{Pro}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px3.p1.2.m2.1d">blackboard_W start_POSTSUBSCRIPT italic_P italic_r italic_o end_POSTSUBSCRIPT</annotation></semantics></math> to generate preferable responses corresponding to these instructions after filtration <cite class="ltx_cite ltx_citemacro_cite">Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib66" title="">2023</a>); Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib61" title="">2022</a>); Jiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib25" title="">2023</a>)</cite>.
This step is crucial as the knowledge is embedded in these responses which are subsequently distilled into the local model <math alttext="\mathbb{W}_{DP}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px3.p1.3.m3.1"><semantics id="S3.SS4.SSS0.Px3.p1.3.m3.1a"><msub id="S3.SS4.SSS0.Px3.p1.3.m3.1.1" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1.cmml"><mi id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.2" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1.2.cmml">𝕎</mi><mrow id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.3" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.3.2" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1.3.2.cmml">D</mi><mo id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.3.1" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.3.3" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1.3.3.cmml">P</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px3.p1.3.m3.1b"><apply id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.1.cmml" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.2.cmml" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1.2">𝕎</ci><apply id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.3.cmml" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1.3"><times id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1.3.2">𝐷</ci><ci id="S3.SS4.SSS0.Px3.p1.3.m3.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px3.p1.3.m3.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px3.p1.3.m3.1c">\mathbb{W}_{DP}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px3.p1.3.m3.1d">blackboard_W start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT</annotation></semantics></math> through fine-tuning.</p>
</div>
<div class="ltx_para" id="S3.SS4.SSS0.Px3.p2">
<p class="ltx_p" id="S3.SS4.SSS0.Px3.p2.2">Finally, we use the generated instructions and responses sorted by the IFD score <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib34" title="">2023a</a>)</cite> to normally (non-DP) fine-tune <math alttext="\mathbb{W}_{DP}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px3.p2.1.m1.1"><semantics id="S3.SS4.SSS0.Px3.p2.1.m1.1a"><msub id="S3.SS4.SSS0.Px3.p2.1.m1.1.1" xref="S3.SS4.SSS0.Px3.p2.1.m1.1.1.cmml"><mi id="S3.SS4.SSS0.Px3.p2.1.m1.1.1.2" xref="S3.SS4.SSS0.Px3.p2.1.m1.1.1.2.cmml">𝕎</mi><mrow id="S3.SS4.SSS0.Px3.p2.1.m1.1.1.3" xref="S3.SS4.SSS0.Px3.p2.1.m1.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px3.p2.1.m1.1.1.3.2" xref="S3.SS4.SSS0.Px3.p2.1.m1.1.1.3.2.cmml">D</mi><mo id="S3.SS4.SSS0.Px3.p2.1.m1.1.1.3.1" xref="S3.SS4.SSS0.Px3.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px3.p2.1.m1.1.1.3.3" xref="S3.SS4.SSS0.Px3.p2.1.m1.1.1.3.3.cmml">P</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px3.p2.1.m1.1b"><apply id="S3.SS4.SSS0.Px3.p2.1.m1.1.1.cmml" xref="S3.SS4.SSS0.Px3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px3.p2.1.m1.1.1.1.cmml" xref="S3.SS4.SSS0.Px3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px3.p2.1.m1.1.1.2.cmml" xref="S3.SS4.SSS0.Px3.p2.1.m1.1.1.2">𝕎</ci><apply id="S3.SS4.SSS0.Px3.p2.1.m1.1.1.3.cmml" xref="S3.SS4.SSS0.Px3.p2.1.m1.1.1.3"><times id="S3.SS4.SSS0.Px3.p2.1.m1.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px3.p2.1.m1.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px3.p2.1.m1.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px3.p2.1.m1.1.1.3.2">𝐷</ci><ci id="S3.SS4.SSS0.Px3.p2.1.m1.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px3.p2.1.m1.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px3.p2.1.m1.1c">\mathbb{W}_{DP}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px3.p2.1.m1.1d">blackboard_W start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT</annotation></semantics></math> and obtain the desired model <math alttext="\mathbb{W}_{Target}" class="ltx_Math" display="inline" id="S3.SS4.SSS0.Px3.p2.2.m2.1"><semantics id="S3.SS4.SSS0.Px3.p2.2.m2.1a"><msub id="S3.SS4.SSS0.Px3.p2.2.m2.1.1" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.cmml"><mi id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.2" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.2.cmml">𝕎</mi><mrow id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.cmml"><mi id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.2" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.2.cmml">T</mi><mo id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.1" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.3" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.3.cmml">a</mi><mo id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.1a" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.4" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.4.cmml">r</mi><mo id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.1b" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.5" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.5.cmml">g</mi><mo id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.1c" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.6" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.6.cmml">e</mi><mo id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.1d" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.7" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.7.cmml">t</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS4.SSS0.Px3.p2.2.m2.1b"><apply id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.cmml" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.1.cmml" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.2.cmml" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.2">𝕎</ci><apply id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.cmml" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3"><times id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.1.cmml" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.1"></times><ci id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.2.cmml" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.2">𝑇</ci><ci id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.3.cmml" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.3">𝑎</ci><ci id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.4.cmml" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.4">𝑟</ci><ci id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.5.cmml" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.5">𝑔</ci><ci id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.6.cmml" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.6">𝑒</ci><ci id="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.7.cmml" xref="S3.SS4.SSS0.Px3.p2.2.m2.1.1.3.7">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.SSS0.Px3.p2.2.m2.1c">\mathbb{W}_{Target}</annotation><annotation encoding="application/x-llamapun" id="S3.SS4.SSS0.Px3.p2.2.m2.1d">blackboard_W start_POSTSUBSCRIPT italic_T italic_a italic_r italic_g italic_e italic_t end_POSTSUBSCRIPT</annotation></semantics></math>.
Further details and results regarding the IFD score are presented in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS5" title="4.5 Data Quality Measurement. ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">4.5</span></a>.
At this stage, DP-finetuning is not needed, as we assume the refined synthetic data contains no sensitive information.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S3.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Communication between Client &amp; Server</h3>
<section class="ltx_paragraph" id="S3.SS5.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Federated Model Transmission.</h4>
<div class="ltx_para" id="S3.SS5.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS5.SSS0.Px1.p1.1">Although synthetic data is supposed to contain no privacy, i.e. PIIs, two non-negligible concerns remain:
(1) The size of the data prepared for fine-tuning are relatively larger than that of the LoRA adapter <math alttext="\mathbb{A}_{DP}" class="ltx_Math" display="inline" id="S3.SS5.SSS0.Px1.p1.1.m1.1"><semantics id="S3.SS5.SSS0.Px1.p1.1.m1.1a"><msub id="S3.SS5.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS5.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S3.SS5.SSS0.Px1.p1.1.m1.1.1.2" xref="S3.SS5.SSS0.Px1.p1.1.m1.1.1.2.cmml">𝔸</mi><mrow id="S3.SS5.SSS0.Px1.p1.1.m1.1.1.3" xref="S3.SS5.SSS0.Px1.p1.1.m1.1.1.3.cmml"><mi id="S3.SS5.SSS0.Px1.p1.1.m1.1.1.3.2" xref="S3.SS5.SSS0.Px1.p1.1.m1.1.1.3.2.cmml">D</mi><mo id="S3.SS5.SSS0.Px1.p1.1.m1.1.1.3.1" xref="S3.SS5.SSS0.Px1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.SSS0.Px1.p1.1.m1.1.1.3.3" xref="S3.SS5.SSS0.Px1.p1.1.m1.1.1.3.3.cmml">P</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px1.p1.1.m1.1b"><apply id="S3.SS5.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS5.SSS0.Px1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS5.SSS0.Px1.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS5.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS5.SSS0.Px1.p1.1.m1.1.1.2">𝔸</ci><apply id="S3.SS5.SSS0.Px1.p1.1.m1.1.1.3.cmml" xref="S3.SS5.SSS0.Px1.p1.1.m1.1.1.3"><times id="S3.SS5.SSS0.Px1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS5.SSS0.Px1.p1.1.m1.1.1.3.1"></times><ci id="S3.SS5.SSS0.Px1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS5.SSS0.Px1.p1.1.m1.1.1.3.2">𝐷</ci><ci id="S3.SS5.SSS0.Px1.p1.1.m1.1.1.3.3.cmml" xref="S3.SS5.SSS0.Px1.p1.1.m1.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px1.p1.1.m1.1c">\mathbb{A}_{DP}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.SSS0.Px1.p1.1.m1.1d">blackboard_A start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT</annotation></semantics></math>.
(2) Leakage of synthetic data can potentially reveal approximate data distribution or other sensitive information.</p>
</div>
<div class="ltx_para" id="S3.SS5.SSS0.Px1.p2">
<p class="ltx_p" id="S3.SS5.SSS0.Px1.p2.1">Therefore, inspired by federated fine-tuning of language models <cite class="ltx_cite ltx_citemacro_cite">Wei et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib62" title="">2020</a>); Ye et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib71" title="">2024b</a>)</cite>, we propose to apply transmitting the fine-tuned version of model into our new setting which only has one client and one server, rather than directly transmitting data.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS5.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Proposed Transmitting Unit.</h4>
<div class="ltx_para" id="S3.SS5.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS5.SSS0.Px2.p1.1">Moreover, to reduce the potential risk of eavesdropping, i.e. an unauthorized party intercepts and steals the transmitted model, we introduce an efficient transmitting unit. Note that this unit is compatible and optional if the client using <span class="ltx_text ltx_font_italic" id="S3.SS5.SSS0.Px2.p1.1.1">KnowledgeSG</span> has no concerns about eavesdropping.</p>
</div>
<div class="ltx_para" id="S3.SS5.SSS0.Px2.p2">
<p class="ltx_p" id="S3.SS5.SSS0.Px2.p2.9">We start by sampling a small amount of data from public datasets, e.g. Alpaca <cite class="ltx_cite ltx_citemacro_cite">Taori et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib56" title="">2023</a>)</cite>, as the seed dataset <math alttext="\mathbb{D}_{Seed}" class="ltx_Math" display="inline" id="S3.SS5.SSS0.Px2.p2.1.m1.1"><semantics id="S3.SS5.SSS0.Px2.p2.1.m1.1a"><msub id="S3.SS5.SSS0.Px2.p2.1.m1.1.1" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.cmml"><mi id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.2" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.2.cmml">𝔻</mi><mrow id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.cmml"><mi id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.2" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.2.cmml">S</mi><mo id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.1" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.3" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.3.cmml">e</mi><mo id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.1a" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.4" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.4.cmml">e</mi><mo id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.1b" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.5" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px2.p2.1.m1.1b"><apply id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.2">𝔻</ci><apply id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.cmml" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3"><times id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.1.cmml" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.1"></times><ci id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.2.cmml" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.2">𝑆</ci><ci id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.3.cmml" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.3">𝑒</ci><ci id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.4.cmml" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.4">𝑒</ci><ci id="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.5.cmml" xref="S3.SS5.SSS0.Px2.p2.1.m1.1.1.3.5">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px2.p2.1.m1.1c">\mathbb{D}_{Seed}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.SSS0.Px2.p2.1.m1.1d">blackboard_D start_POSTSUBSCRIPT italic_S italic_e italic_e italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, which is agreed and shared by the client and server at the beginning. Then we fine-tune the original base model <math alttext="\mathbb{W}_{Loc}" class="ltx_Math" display="inline" id="S3.SS5.SSS0.Px2.p2.2.m2.1"><semantics id="S3.SS5.SSS0.Px2.p2.2.m2.1a"><msub id="S3.SS5.SSS0.Px2.p2.2.m2.1.1" xref="S3.SS5.SSS0.Px2.p2.2.m2.1.1.cmml"><mi id="S3.SS5.SSS0.Px2.p2.2.m2.1.1.2" xref="S3.SS5.SSS0.Px2.p2.2.m2.1.1.2.cmml">𝕎</mi><mrow id="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3" xref="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3.cmml"><mi id="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3.2" xref="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3.2.cmml">L</mi><mo id="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3.1" xref="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3.3" xref="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3.3.cmml">o</mi><mo id="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3.1a" xref="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3.4" xref="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3.4.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px2.p2.2.m2.1b"><apply id="S3.SS5.SSS0.Px2.p2.2.m2.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px2.p2.2.m2.1.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.2.m2.1.1">subscript</csymbol><ci id="S3.SS5.SSS0.Px2.p2.2.m2.1.1.2.cmml" xref="S3.SS5.SSS0.Px2.p2.2.m2.1.1.2">𝕎</ci><apply id="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3.cmml" xref="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3"><times id="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3.1.cmml" xref="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3.1"></times><ci id="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3.2.cmml" xref="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3.2">𝐿</ci><ci id="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3.3.cmml" xref="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3.3">𝑜</ci><ci id="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3.4.cmml" xref="S3.SS5.SSS0.Px2.p2.2.m2.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px2.p2.2.m2.1c">\mathbb{W}_{Loc}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.SSS0.Px2.p2.2.m2.1d">blackboard_W start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT</annotation></semantics></math> on <math alttext="\mathbb{D}_{Seed}" class="ltx_Math" display="inline" id="S3.SS5.SSS0.Px2.p2.3.m3.1"><semantics id="S3.SS5.SSS0.Px2.p2.3.m3.1a"><msub id="S3.SS5.SSS0.Px2.p2.3.m3.1.1" xref="S3.SS5.SSS0.Px2.p2.3.m3.1.1.cmml"><mi id="S3.SS5.SSS0.Px2.p2.3.m3.1.1.2" xref="S3.SS5.SSS0.Px2.p2.3.m3.1.1.2.cmml">𝔻</mi><mrow id="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3" xref="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.cmml"><mi id="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.2" xref="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.2.cmml">S</mi><mo id="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.1" xref="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.3" xref="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.3.cmml">e</mi><mo id="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.1a" xref="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.4" xref="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.4.cmml">e</mi><mo id="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.1b" xref="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.5" xref="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px2.p2.3.m3.1b"><apply id="S3.SS5.SSS0.Px2.p2.3.m3.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px2.p2.3.m3.1.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m3.1.1">subscript</csymbol><ci id="S3.SS5.SSS0.Px2.p2.3.m3.1.1.2.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m3.1.1.2">𝔻</ci><apply id="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3"><times id="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.1.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.1"></times><ci id="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.2.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.2">𝑆</ci><ci id="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.3.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.3">𝑒</ci><ci id="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.4.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.4">𝑒</ci><ci id="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.5.cmml" xref="S3.SS5.SSS0.Px2.p2.3.m3.1.1.3.5">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px2.p2.3.m3.1c">\mathbb{D}_{Seed}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.SSS0.Px2.p2.3.m3.1d">blackboard_D start_POSTSUBSCRIPT italic_S italic_e italic_e italic_d end_POSTSUBSCRIPT</annotation></semantics></math> to create a full adaption of model weights and replace original <math alttext="\mathbb{W}_{Loc}" class="ltx_Math" display="inline" id="S3.SS5.SSS0.Px2.p2.4.m4.1"><semantics id="S3.SS5.SSS0.Px2.p2.4.m4.1a"><msub id="S3.SS5.SSS0.Px2.p2.4.m4.1.1" xref="S3.SS5.SSS0.Px2.p2.4.m4.1.1.cmml"><mi id="S3.SS5.SSS0.Px2.p2.4.m4.1.1.2" xref="S3.SS5.SSS0.Px2.p2.4.m4.1.1.2.cmml">𝕎</mi><mrow id="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3" xref="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3.cmml"><mi id="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3.2" xref="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3.2.cmml">L</mi><mo id="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3.1" xref="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3.3" xref="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3.3.cmml">o</mi><mo id="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3.1a" xref="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3.4" xref="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3.4.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px2.p2.4.m4.1b"><apply id="S3.SS5.SSS0.Px2.p2.4.m4.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px2.p2.4.m4.1.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.4.m4.1.1">subscript</csymbol><ci id="S3.SS5.SSS0.Px2.p2.4.m4.1.1.2.cmml" xref="S3.SS5.SSS0.Px2.p2.4.m4.1.1.2">𝕎</ci><apply id="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3.cmml" xref="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3"><times id="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3.1.cmml" xref="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3.1"></times><ci id="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3.2.cmml" xref="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3.2">𝐿</ci><ci id="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3.3.cmml" xref="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3.3">𝑜</ci><ci id="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3.4.cmml" xref="S3.SS5.SSS0.Px2.p2.4.m4.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px2.p2.4.m4.1c">\mathbb{W}_{Loc}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.SSS0.Px2.p2.4.m4.1d">blackboard_W start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT</annotation></semantics></math> with the new model <math alttext="\mathbb{W}^{{}^{\prime}}_{Loc}" class="ltx_Math" display="inline" id="S3.SS5.SSS0.Px2.p2.5.m5.1"><semantics id="S3.SS5.SSS0.Px2.p2.5.m5.1a"><msubsup id="S3.SS5.SSS0.Px2.p2.5.m5.1.1" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1.cmml"><mi id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.2.2" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1.2.2.cmml">𝕎</mi><mrow id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3.cmml"><mi id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3.2" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3.2.cmml">L</mi><mo id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3.1" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3.3" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3.3.cmml">o</mi><mo id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3.1a" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3.4" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3.4.cmml">c</mi></mrow><msup id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.2.3" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1.2.3.cmml"><mi id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.2.3a" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1.2.3.cmml"></mi><mo id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.2.3.1" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1.2.3.1.cmml">′</mo></msup></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px2.p2.5.m5.1b"><apply id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1">subscript</csymbol><apply id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.2.cmml" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.2.1.cmml" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1">superscript</csymbol><ci id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.2.2.cmml" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1.2.2">𝕎</ci><apply id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.2.3.cmml" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1.2.3"><ci id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.2.3.1.cmml" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1.2.3.1">′</ci></apply></apply><apply id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3.cmml" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3"><times id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3.1.cmml" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3.1"></times><ci id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3.2.cmml" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3.2">𝐿</ci><ci id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3.3.cmml" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3.3">𝑜</ci><ci id="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3.4.cmml" xref="S3.SS5.SSS0.Px2.p2.5.m5.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px2.p2.5.m5.1c">\mathbb{W}^{{}^{\prime}}_{Loc}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.SSS0.Px2.p2.5.m5.1d">blackboard_W start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT ′ end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT</annotation></semantics></math>. The local learning process described in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S3.SS3" title="3.3 Client Side ‣ 3 Method ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">3.3</span></a> is based on <math alttext="\mathbb{W}^{{}^{\prime}}_{Loc}" class="ltx_Math" display="inline" id="S3.SS5.SSS0.Px2.p2.6.m6.1"><semantics id="S3.SS5.SSS0.Px2.p2.6.m6.1a"><msubsup id="S3.SS5.SSS0.Px2.p2.6.m6.1.1" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1.cmml"><mi id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.2.2" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1.2.2.cmml">𝕎</mi><mrow id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3.cmml"><mi id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3.2" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3.2.cmml">L</mi><mo id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3.1" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3.3" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3.3.cmml">o</mi><mo id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3.1a" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3.4" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3.4.cmml">c</mi></mrow><msup id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.2.3" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1.2.3.cmml"><mi id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.2.3a" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1.2.3.cmml"></mi><mo id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.2.3.1" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1.2.3.1.cmml">′</mo></msup></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px2.p2.6.m6.1b"><apply id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1">subscript</csymbol><apply id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.2.cmml" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.2.1.cmml" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1">superscript</csymbol><ci id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.2.2.cmml" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1.2.2">𝕎</ci><apply id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.2.3.cmml" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1.2.3"><ci id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.2.3.1.cmml" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1.2.3.1">′</ci></apply></apply><apply id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3.cmml" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3"><times id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3.1.cmml" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3.1"></times><ci id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3.2.cmml" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3.2">𝐿</ci><ci id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3.3.cmml" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3.3">𝑜</ci><ci id="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3.4.cmml" xref="S3.SS5.SSS0.Px2.p2.6.m6.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px2.p2.6.m6.1c">\mathbb{W}^{{}^{\prime}}_{Loc}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.SSS0.Px2.p2.6.m6.1d">blackboard_W start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT ′ end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT</annotation></semantics></math> afterwards.
In this way, we make sure that, even if an adversarial eavesdropper intercepts the LoRA adapter <math alttext="\mathbb{A}_{DP}" class="ltx_Math" display="inline" id="S3.SS5.SSS0.Px2.p2.7.m7.1"><semantics id="S3.SS5.SSS0.Px2.p2.7.m7.1a"><msub id="S3.SS5.SSS0.Px2.p2.7.m7.1.1" xref="S3.SS5.SSS0.Px2.p2.7.m7.1.1.cmml"><mi id="S3.SS5.SSS0.Px2.p2.7.m7.1.1.2" xref="S3.SS5.SSS0.Px2.p2.7.m7.1.1.2.cmml">𝔸</mi><mrow id="S3.SS5.SSS0.Px2.p2.7.m7.1.1.3" xref="S3.SS5.SSS0.Px2.p2.7.m7.1.1.3.cmml"><mi id="S3.SS5.SSS0.Px2.p2.7.m7.1.1.3.2" xref="S3.SS5.SSS0.Px2.p2.7.m7.1.1.3.2.cmml">D</mi><mo id="S3.SS5.SSS0.Px2.p2.7.m7.1.1.3.1" xref="S3.SS5.SSS0.Px2.p2.7.m7.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.SSS0.Px2.p2.7.m7.1.1.3.3" xref="S3.SS5.SSS0.Px2.p2.7.m7.1.1.3.3.cmml">P</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px2.p2.7.m7.1b"><apply id="S3.SS5.SSS0.Px2.p2.7.m7.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px2.p2.7.m7.1.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.7.m7.1.1">subscript</csymbol><ci id="S3.SS5.SSS0.Px2.p2.7.m7.1.1.2.cmml" xref="S3.SS5.SSS0.Px2.p2.7.m7.1.1.2">𝔸</ci><apply id="S3.SS5.SSS0.Px2.p2.7.m7.1.1.3.cmml" xref="S3.SS5.SSS0.Px2.p2.7.m7.1.1.3"><times id="S3.SS5.SSS0.Px2.p2.7.m7.1.1.3.1.cmml" xref="S3.SS5.SSS0.Px2.p2.7.m7.1.1.3.1"></times><ci id="S3.SS5.SSS0.Px2.p2.7.m7.1.1.3.2.cmml" xref="S3.SS5.SSS0.Px2.p2.7.m7.1.1.3.2">𝐷</ci><ci id="S3.SS5.SSS0.Px2.p2.7.m7.1.1.3.3.cmml" xref="S3.SS5.SSS0.Px2.p2.7.m7.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px2.p2.7.m7.1c">\mathbb{A}_{DP}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.SSS0.Px2.p2.7.m7.1d">blackboard_A start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT</annotation></semantics></math>, he cannot recover our entire model with the old version of base model <math alttext="\mathbb{W}_{Loc}" class="ltx_Math" display="inline" id="S3.SS5.SSS0.Px2.p2.8.m8.1"><semantics id="S3.SS5.SSS0.Px2.p2.8.m8.1a"><msub id="S3.SS5.SSS0.Px2.p2.8.m8.1.1" xref="S3.SS5.SSS0.Px2.p2.8.m8.1.1.cmml"><mi id="S3.SS5.SSS0.Px2.p2.8.m8.1.1.2" xref="S3.SS5.SSS0.Px2.p2.8.m8.1.1.2.cmml">𝕎</mi><mrow id="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3" xref="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3.cmml"><mi id="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3.2" xref="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3.2.cmml">L</mi><mo id="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3.1" xref="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3.3" xref="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3.3.cmml">o</mi><mo id="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3.1a" xref="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3.4" xref="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3.4.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px2.p2.8.m8.1b"><apply id="S3.SS5.SSS0.Px2.p2.8.m8.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px2.p2.8.m8.1.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.8.m8.1.1">subscript</csymbol><ci id="S3.SS5.SSS0.Px2.p2.8.m8.1.1.2.cmml" xref="S3.SS5.SSS0.Px2.p2.8.m8.1.1.2">𝕎</ci><apply id="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3.cmml" xref="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3"><times id="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3.1.cmml" xref="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3.1"></times><ci id="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3.2.cmml" xref="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3.2">𝐿</ci><ci id="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3.3.cmml" xref="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3.3">𝑜</ci><ci id="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3.4.cmml" xref="S3.SS5.SSS0.Px2.p2.8.m8.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px2.p2.8.m8.1c">\mathbb{W}_{Loc}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.SSS0.Px2.p2.8.m8.1d">blackboard_W start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT</annotation></semantics></math> instead of <math alttext="\mathbb{W}^{{}^{\prime}}_{Loc}" class="ltx_Math" display="inline" id="S3.SS5.SSS0.Px2.p2.9.m9.1"><semantics id="S3.SS5.SSS0.Px2.p2.9.m9.1a"><msubsup id="S3.SS5.SSS0.Px2.p2.9.m9.1.1" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1.cmml"><mi id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.2.2" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1.2.2.cmml">𝕎</mi><mrow id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3.cmml"><mi id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3.2" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3.2.cmml">L</mi><mo id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3.1" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3.3" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3.3.cmml">o</mi><mo id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3.1a" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3.1.cmml">⁢</mo><mi id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3.4" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3.4.cmml">c</mi></mrow><msup id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.2.3" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1.2.3.cmml"><mi id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.2.3a" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1.2.3.cmml"></mi><mo id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.2.3.1" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1.2.3.1.cmml">′</mo></msup></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS5.SSS0.Px2.p2.9.m9.1b"><apply id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.1.cmml" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1">subscript</csymbol><apply id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.2.cmml" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.2.1.cmml" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1">superscript</csymbol><ci id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.2.2.cmml" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1.2.2">𝕎</ci><apply id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.2.3.cmml" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1.2.3"><ci id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.2.3.1.cmml" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1.2.3.1">′</ci></apply></apply><apply id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3.cmml" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3"><times id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3.1.cmml" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3.1"></times><ci id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3.2.cmml" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3.2">𝐿</ci><ci id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3.3.cmml" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3.3">𝑜</ci><ci id="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3.4.cmml" xref="S3.SS5.SSS0.Px2.p2.9.m9.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS5.SSS0.Px2.p2.9.m9.1c">\mathbb{W}^{{}^{\prime}}_{Loc}</annotation><annotation encoding="application/x-llamapun" id="S3.SS5.SSS0.Px2.p2.9.m9.1d">blackboard_W start_POSTSUPERSCRIPT start_FLOATSUPERSCRIPT ′ end_FLOATSUPERSCRIPT end_POSTSUPERSCRIPT start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Basic Setups</h3>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Models and Datasets.</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">If not otherwise mentioned, our base model is pre-trained Llama2-7B <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib58" title="">2023b</a>)</cite>.
We choose FinGPT <cite class="ltx_cite ltx_citemacro_cite">Yang (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib68" title="">2023</a>)</cite> and AlpaCare <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib77" title="">2023</a>)</cite> as our professional models for financial and medical domains respectively.
The dataset sample is kept to <math alttext="500" class="ltx_Math" display="inline" id="S4.SS1.SSS0.Px1.p1.1.m1.1"><semantics id="S4.SS1.SSS0.Px1.p1.1.m1.1a"><mn id="S4.SS1.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.SSS0.Px1.p1.1.m1.1b"><cn id="S4.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS1.SSS0.Px1.p1.1.m1.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.SSS0.Px1.p1.1.m1.1c">500</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.SSS0.Px1.p1.1.m1.1d">500</annotation></semantics></math> for any comparison except the ablation study in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS6" title="4.6 Ablation on Dataset Size ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">4.6</span></a>.
We use the name substitution technique in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A2.SS2" title="B.2 Name Substitution ‣ Appendix B Additional Techniques ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">B.2</span></a> to pre-process datasets, preventing inaccurate evaluation on privacy.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Baselines.</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">Our baselines comprise one None-Private approach, one private approach with DP-SGD <cite class="ltx_cite ltx_citemacro_cite">Abadi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib1" title="">2016</a>)</cite>, and six private approaches using synthetic data generation, i.e. ICL <cite class="ltx_cite ltx_citemacro_cite">Dong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib14" title="">2022</a>)</cite>, Self-Instruct <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib61" title="">2022</a>)</cite>, Self-Instruct-ICL, DP-Gene <cite class="ltx_cite ltx_citemacro_cite">Kurakin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib30" title="">2024</a>)</cite>, DP-Instruct <cite class="ltx_cite ltx_citemacro_cite">Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib73" title="">2024</a>)</cite> and DP-Instruct-ICL.
The detailed comparison of baselines is shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A6.T14" title="Table 14 ‣ F.3 Baselines ‣ Appendix F Implementation Details ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">14</span></a> in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A6.SS3" title="F.3 Baselines ‣ Appendix F Implementation Details ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">F.3</span></a>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Privacy Evaluation</h3>
<figure class="ltx_table" id="S4.T2">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T2.18">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T2.18.19.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T2.18.19.1.1">Baselines</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S4.T2.18.19.1.2"><span class="ltx_text" id="S4.T2.18.19.1.2.1" style="color:#ACACEA;">Medical</span></th>
<th class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S4.T2.18.19.1.3">Inc</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S4.T2.18.19.1.4"><span class="ltx_text" id="S4.T2.18.19.1.4.1" style="color:#F1CD7A;">Financial</span></th>
<th class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_tt" id="S4.T2.18.19.1.5">Inc</th>
</tr>
<tr class="ltx_tr" id="S4.T2.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T2.2.2.3">Random</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T2.2.2.4">1.56</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T2.1.1.1">
<svg class="ltx_picture" height="9.21" id="S4.T2.1.1.1.pic1" overflow="visible" version="1.1" width="12.84"><g color="#E6E6FA" fill="#E6E6FA" stroke="#E6E6FA" stroke-width="0.4pt" transform="translate(0,9.21) matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,4.21)"><path d="M 0 -3.94 M 0 -3.94 L 0 4.72 L 12.28 4.72 L 12.28 -3.94 Z M 12.28 4.72"></path></g></svg></th>
<th class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_r ltx_border_t" id="S4.T2.2.2.5">0</th>
<th class="ltx_td ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T2.2.2.6">1.56</th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t" id="S4.T2.2.2.2">
<svg class="ltx_picture" height="9.21" id="S4.T2.2.2.2.pic1" overflow="visible" version="1.1" width="12.84"><g color="#FFF0CD" fill="#FFF0CD" stroke="#FFF0CD" stroke-width="0.4pt" transform="translate(0,9.21) matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,4.21)"><path d="M 0 -3.94 M 0 -3.94 L 0 4.72 L 12.28 4.72 L 12.28 -3.94 Z M 12.28 4.72"></path></g></svg></th>
<th class="ltx_td ltx_nopad_l ltx_align_right ltx_th ltx_th_column ltx_border_t" id="S4.T2.2.2.7">0</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T2.4.4">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S4.T2.4.4.3">Non-Private</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.4.4.4">97.13</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.3.3.1">
<svg class="ltx_picture" height="9.21" id="S4.T2.3.3.1.pic1" overflow="visible" version="1.1" width="138.35"><g color="#E6E6FA" fill="#E6E6FA" stroke="#E6E6FA" stroke-width="0.4pt" transform="translate(0,9.21) matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,4.21)"><path d="M 0 -3.94 M 0 -3.94 L 0 4.72 L 137.8 4.72 L 137.8 -3.94 Z M 137.8 4.72"></path></g></svg></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r ltx_border_t" id="S4.T2.4.4.5">95.57</td>
<td class="ltx_td ltx_align_right ltx_border_t" id="S4.T2.4.4.6">96.23</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="S4.T2.4.4.2">
<svg class="ltx_picture" height="9.21" id="S4.T2.4.4.2.pic1" overflow="visible" version="1.1" width="138.35"><g color="#FFF0CD" fill="#FFF0CD" stroke="#FFF0CD" stroke-width="0.4pt" transform="translate(0,9.21) matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,4.21)"><path d="M 0 -3.94 M 0 -3.94 L 0 4.72 L 137.8 4.72 L 137.8 -3.94 Z M 137.8 4.72"></path></g></svg></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_t" id="S4.T2.4.4.7">94.67</td>
</tr>
<tr class="ltx_tr" id="S4.T2.6.6">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.6.6.3">ICL</td>
<td class="ltx_td ltx_align_right" id="S4.T2.6.6.4">5.47</td>
<td class="ltx_td ltx_align_left" id="S4.T2.5.5.1">
<svg class="ltx_picture" height="9.21" id="S4.T2.5.5.1.pic1" overflow="visible" version="1.1" width="43.62"><g color="#E6E6FA" fill="#E6E6FA" stroke="#E6E6FA" stroke-width="0.4pt" transform="translate(0,9.21) matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,4.21)"><path d="M 0 -3.94 M 0 -3.94 L 0 4.72 L 43.07 4.72 L 43.07 -3.94 Z M 43.07 4.72"></path></g></svg></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r" id="S4.T2.6.6.5">3.91</td>
<td class="ltx_td ltx_align_right" id="S4.T2.6.6.6">7.40</td>
<td class="ltx_td ltx_align_left" id="S4.T2.6.6.2">
<svg class="ltx_picture" height="9.21" id="S4.T2.6.6.2.pic1" overflow="visible" version="1.1" width="43.62"><g color="#FFF0CD" fill="#FFF0CD" stroke="#FFF0CD" stroke-width="0.4pt" transform="translate(0,9.21) matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,4.21)"><path d="M 0 -3.94 M 0 -3.94 L 0 4.72 L 43.07 4.72 L 43.07 -3.94 Z M 43.07 4.72"></path></g></svg></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T2.6.6.7">5.84</td>
</tr>
<tr class="ltx_tr" id="S4.T2.8.8">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.8.8.3">Self-Instruct</td>
<td class="ltx_td ltx_align_right" id="S4.T2.8.8.4">1.46</td>
<td class="ltx_td ltx_align_left" id="S4.T2.7.7.1">
<svg class="ltx_picture" height="9.21" id="S4.T2.7.7.1.pic1" overflow="visible" version="1.1" width="12.05"><g color="#E6E6FA" fill="#E6E6FA" stroke="#E6E6FA" stroke-width="0.4pt" transform="translate(0,9.21) matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,4.21)"><path d="M 0 -3.94 M 0 -3.94 L 0 4.72 L 11.5 4.72 L 11.5 -3.94 Z M 11.5 4.72"></path></g></svg></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r" id="S4.T2.8.8.5">-0.10</td>
<td class="ltx_td ltx_align_right" id="S4.T2.8.8.6">1.89</td>
<td class="ltx_td ltx_align_left" id="S4.T2.8.8.2">
<svg class="ltx_picture" height="9.21" id="S4.T2.8.8.2.pic1" overflow="visible" version="1.1" width="15.44"><g color="#FFF0CD" fill="#FFF0CD" stroke="#FFF0CD" stroke-width="0.4pt" transform="translate(0,9.21) matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,4.21)"><path d="M 0 -3.94 M 0 -3.94 L 0 4.72 L 14.88 4.72 L 14.88 -3.94 Z M 14.88 4.72"></path></g></svg></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T2.8.8.7">0.33</td>
</tr>
<tr class="ltx_tr" id="S4.T2.10.10">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.10.10.3">Self-Instruct-ICL</td>
<td class="ltx_td ltx_align_right" id="S4.T2.10.10.4">3.33</td>
<td class="ltx_td ltx_align_left" id="S4.T2.9.9.1">
<svg class="ltx_picture" height="9.21" id="S4.T2.9.9.1.pic1" overflow="visible" version="1.1" width="26.77"><g color="#E6E6FA" fill="#E6E6FA" stroke="#E6E6FA" stroke-width="0.4pt" transform="translate(0,9.21) matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,4.21)"><path d="M 0 -3.94 M 0 -3.94 L 0 4.72 L 26.22 4.72 L 26.22 -3.94 Z M 26.22 4.72"></path></g></svg></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r" id="S4.T2.10.10.5">1.77</td>
<td class="ltx_td ltx_align_right" id="S4.T2.10.10.6">3.77</td>
<td class="ltx_td ltx_align_left" id="S4.T2.10.10.2">
<svg class="ltx_picture" height="9.21" id="S4.T2.10.10.2.pic1" overflow="visible" version="1.1" width="27.09"><g color="#FFF0CD" fill="#FFF0CD" stroke="#FFF0CD" stroke-width="0.4pt" transform="translate(0,9.21) matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,4.21)"><path d="M 0 -3.94 M 0 -3.94 L 0 4.72 L 26.54 4.72 L 26.54 -3.94 Z M 26.54 4.72"></path></g></svg></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T2.10.10.7">1.81</td>
</tr>
<tr class="ltx_tr" id="S4.T2.12.12">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.12.12.3">DP-Gene</td>
<td class="ltx_td ltx_align_right" id="S4.T2.12.12.4">2.26</td>
<td class="ltx_td ltx_align_left" id="S4.T2.11.11.1">
<svg class="ltx_picture" height="9.21" id="S4.T2.11.11.1.pic1" overflow="visible" version="1.1" width="18.35"><g color="#E6E6FA" fill="#E6E6FA" stroke="#E6E6FA" stroke-width="0.4pt" transform="translate(0,9.21) matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,4.21)"><path d="M 0 -3.94 M 0 -3.94 L 0 4.72 L 17.8 4.72 L 17.8 -3.94 Z M 17.8 4.72"></path></g></svg></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r" id="S4.T2.12.12.5">0.70</td>
<td class="ltx_td ltx_align_right" id="S4.T2.12.12.6">2.52</td>
<td class="ltx_td ltx_align_left" id="S4.T2.12.12.2">
<svg class="ltx_picture" height="9.21" id="S4.T2.12.12.2.pic1" overflow="visible" version="1.1" width="20.4"><g color="#FFF0CD" fill="#FFF0CD" stroke="#FFF0CD" stroke-width="0.4pt" transform="translate(0,9.21) matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,4.21)"><path d="M 0 -3.94 M 0 -3.94 L 0 4.72 L 19.84 4.72 L 19.84 -3.94 Z M 19.84 4.72"></path></g></svg></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T2.12.12.7">0.96</td>
</tr>
<tr class="ltx_tr" id="S4.T2.14.14">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.14.14.3">DP-Instruct</td>
<td class="ltx_td ltx_align_right" id="S4.T2.14.14.4">1.07</td>
<td class="ltx_td ltx_align_left" id="S4.T2.13.13.1">
<svg class="ltx_picture" height="9.21" id="S4.T2.13.13.1.pic1" overflow="visible" version="1.1" width="8.98"><g color="#E6E6FA" fill="#E6E6FA" stroke="#E6E6FA" stroke-width="0.4pt" transform="translate(0,9.21) matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,4.21)"><path d="M 0 -3.94 M 0 -3.94 L 0 4.72 L 8.43 4.72 L 8.43 -3.94 Z M 8.43 4.72"></path></g></svg></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r" id="S4.T2.14.14.5">-0.49</td>
<td class="ltx_td ltx_align_right" id="S4.T2.14.14.6">3.14</td>
<td class="ltx_td ltx_align_left" id="S4.T2.14.14.2">
<svg class="ltx_picture" height="9.21" id="S4.T2.14.14.2.pic1" overflow="visible" version="1.1" width="25.28"><g color="#FFF0CD" fill="#FFF0CD" stroke="#FFF0CD" stroke-width="0.4pt" transform="translate(0,9.21) matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,4.21)"><path d="M 0 -3.94 M 0 -3.94 L 0 4.72 L 24.72 4.72 L 24.72 -3.94 Z M 24.72 4.72"></path></g></svg></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T2.14.14.7">1.58</td>
</tr>
<tr class="ltx_tr" id="S4.T2.16.16">
<td class="ltx_td ltx_align_left ltx_border_r" id="S4.T2.16.16.3">DP-Instruct-ICL</td>
<td class="ltx_td ltx_align_right" id="S4.T2.16.16.4">3.60</td>
<td class="ltx_td ltx_align_left" id="S4.T2.15.15.1">
<svg class="ltx_picture" height="9.21" id="S4.T2.15.15.1.pic1" overflow="visible" version="1.1" width="28.9"><g color="#E6E6FA" fill="#E6E6FA" stroke="#E6E6FA" stroke-width="0.4pt" transform="translate(0,9.21) matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,4.21)"><path d="M 0 -3.94 M 0 -3.94 L 0 4.72 L 28.35 4.72 L 28.35 -3.94 Z M 28.35 4.72"></path></g></svg></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_r" id="S4.T2.16.16.5">2.04</td>
<td class="ltx_td ltx_align_right" id="S4.T2.16.16.6">5.03</td>
<td class="ltx_td ltx_align_left" id="S4.T2.16.16.2">
<svg class="ltx_picture" height="9.21" id="S4.T2.16.16.2.pic1" overflow="visible" version="1.1" width="40.16"><g color="#FFF0CD" fill="#FFF0CD" stroke="#FFF0CD" stroke-width="0.4pt" transform="translate(0,9.21) matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,4.21)"><path d="M 0 -3.94 M 0 -3.94 L 0 4.72 L 39.61 4.72 L 39.61 -3.94 Z M 39.61 4.72"></path></g></svg></td>
<td class="ltx_td ltx_nopad_l ltx_align_right" id="S4.T2.16.16.7">3.47</td>
</tr>
<tr class="ltx_tr" id="S4.T2.18.18">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S4.T2.18.18.3">KnowledgeSG</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T2.18.18.4">0.87</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.17.17.1">
<svg class="ltx_picture" height="9.21" id="S4.T2.17.17.1.pic1" overflow="visible" version="1.1" width="7.4"><g color="#E6E6FA" fill="#E6E6FA" stroke="#E6E6FA" stroke-width="0.4pt" transform="translate(0,9.21) matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,4.21)"><path d="M 0 -3.94 M 0 -3.94 L 0 4.72 L 6.85 4.72 L 6.85 -3.94 Z M 6.85 4.72"></path></g></svg></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb ltx_border_r" id="S4.T2.18.18.5">-0.69</td>
<td class="ltx_td ltx_align_right ltx_border_bb" id="S4.T2.18.18.6">1.89</td>
<td class="ltx_td ltx_align_left ltx_border_bb" id="S4.T2.18.18.2">
<svg class="ltx_picture" height="9.21" id="S4.T2.18.18.2.pic1" overflow="visible" version="1.1" width="15.44"><g color="#FFF0CD" fill="#FFF0CD" stroke="#FFF0CD" stroke-width="0.4pt" transform="translate(0,9.21) matrix(1 0 0 -1 0 0) translate(0.28,0) translate(0,4.21)"><path d="M 0 -3.94 M 0 -3.94 L 0 4.72 L 14.88 4.72 L 14.88 -3.94 Z M 14.88 4.72"></path></g></svg></td>
<td class="ltx_td ltx_nopad_l ltx_align_right ltx_border_bb" id="S4.T2.18.18.7">0.33</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Reconstruction rate comparison between different baselines on the medical and financial domains. <span class="ltx_text ltx_font_italic" id="S4.T2.21.1">Inc</span> represents the increase of reconstruction rate between certain baseline and random guessing. Higher reconstruction rate indicates more memorization of the private data. Results in both domains demonstrate that synthetic data methods, including <span class="ltx_text ltx_font_italic" id="S4.T2.22.2">KnowledgeSG</span>, achieve significantly better privacy protection than non-private methods.</figcaption>
</figure>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Setups.</h4>
<div class="ltx_para" id="S4.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px1.p1.1">We study the privacy leakage of LLM by measuring the reconstruction rates following <cite class="ltx_cite ltx_citemacro_citet">Lukas et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib39" title="">2023</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_href" href="https://github.com/microsoft/analysing_pii_leakage" title="">https://github.com/microsoft/analysing_pii_leakage</a></span></span></span>. In this approach, the attacker is given a sentence with multiple masked pieces of PII and asked to reconstruct the target PII from given candidates.
The reconstruction rate is then calculated as the success ratio over attempt times.</p>
</div>
<div class="ltx_para" id="S4.SS2.SSS0.Px1.p2">
<p class="ltx_p" id="S4.SS2.SSS0.Px1.p2.2">In practice, for each sample in our training dataset, we mask all individual names and randomly choose one as the target. Then we use the PII reconstruction attack <cite class="ltx_cite ltx_citemacro_cite">Lukas et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib39" title="">2023</a>)</cite> to predict the targeted individual name from a list of candidates and report the average prediction accuracy.
Concretely, each time we sample <math alttext="64" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px1.p2.1.m1.1"><semantics id="S4.SS2.SSS0.Px1.p2.1.m1.1a"><mn id="S4.SS2.SSS0.Px1.p2.1.m1.1.1" xref="S4.SS2.SSS0.Px1.p2.1.m1.1.1.cmml">64</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p2.1.m1.1b"><cn id="S4.SS2.SSS0.Px1.p2.1.m1.1.1.cmml" type="integer" xref="S4.SS2.SSS0.Px1.p2.1.m1.1.1">64</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p2.1.m1.1c">64</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS0.Px1.p2.1.m1.1d">64</annotation></semantics></math> names as candidates from our datasets, making sure one of them is correct, and decode from the model using top-k sampling with k set to <math alttext="40" class="ltx_Math" display="inline" id="S4.SS2.SSS0.Px1.p2.2.m2.1"><semantics id="S4.SS2.SSS0.Px1.p2.2.m2.1a"><mn id="S4.SS2.SSS0.Px1.p2.2.m2.1.1" xref="S4.SS2.SSS0.Px1.p2.2.m2.1.1.cmml">40</mn><annotation-xml encoding="MathML-Content" id="S4.SS2.SSS0.Px1.p2.2.m2.1b"><cn id="S4.SS2.SSS0.Px1.p2.2.m2.1.1.cmml" type="integer" xref="S4.SS2.SSS0.Px1.p2.2.m2.1.1">40</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.SSS0.Px1.p2.2.m2.1c">40</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.SSS0.Px1.p2.2.m2.1d">40</annotation></semantics></math>.
We employ Flair<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_href" href="https://github.com/flairNLP/flair" title="">https://github.com/flairNLP/flair</a></span></span></span> models <cite class="ltx_cite ltx_citemacro_cite">Akbik et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib2" title="">2018</a>)</cite> to tag individual names in the datasets.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Results.</h4>
<div class="ltx_para" id="S4.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS2.SSS0.Px2.p1.1">From Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.T2" title="Table 2 ‣ 4.2 Privacy Evaluation ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">2</span></a>, we can see that:
(1) Using synthetic data instead of original data successfully reduces the PII reconstruction rate by a tremendous margin, demonstrating superior privacy protection over Non-Private method.
(2) Differentially private training can preserve data privacy to a great content, but is still not on par with synthetic data approaches.
(3) The privacy protection capabilities of different baselines exploiting synthetic data are closely aligned, with <span class="ltx_text ltx_font_italic" id="S4.SS2.SSS0.Px2.p1.1.1">KnowledgeSG</span> ranking first and ICL lagging behind, which validates the effectiveness of our method. This is reasonable in that ICL-related methods require few-shot examples from the original dataset to generate responses, thus introducing greater privacy risks.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Financial Benchmarks</h3>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Setups.</h4>
<div class="ltx_para" id="S4.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p1.1">We use the financial sentiment analysis dataset<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_href" href="https://huggingface.co/datasets/FinGPT/fingpt-sentiment-train" title="">https://huggingface.co/datasets/FinGPT/fingpt-sentiment-train</a></span></span></span> as the training dataset <cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib69" title="">2023</a>)</cite>.
During the evaluation, we employ the code from <cite class="ltx_cite ltx_citemacro_citet">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib69" title="">2023</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_href" href="https://github.com/AI4Finance-Foundation/FinGPT" title="">https://github.com/AI4Finance-Foundation/FinGPT</a></span></span></span> and consider four financial sentiment analysis benchmarks, including FPB <cite class="ltx_cite ltx_citemacro_cite">Malo et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib43" title="">2014</a>)</cite>, FIQA-SA <cite class="ltx_cite ltx_citemacro_cite">Maia et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib42" title="">2018</a>)</cite>, TFNS <cite class="ltx_cite ltx_citemacro_cite">Magic (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib41" title="">2022</a>)</cite>, and NWGI <cite class="ltx_cite ltx_citemacro_cite">Yang (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib68" title="">2023</a>)</cite>, where both accuracy and F1 score are measured.
Besides, we also report the performance of GPT-3.5 <cite class="ltx_cite ltx_citemacro_cite">Ouyang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib48" title="">2022</a>)</cite> and GPT-4 <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib47" title="">2023</a>)</cite> for reference.
Since NWGI cannot be measured using GPT-3.5/4, we report the average metric of the first three and four evaluation datasets for an overall comparison.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Results.</h4>
<div class="ltx_para" id="S4.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px2.p1.3">Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.T3" title="Table 3 ‣ Results. ‣ 4.3 Financial Benchmarks ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">3</span></a> demonstrates the results of our method and six other baselines using synthetic data generation on financial benchmarks. From the table, we can conclude that:
(1) <span class="ltx_text ltx_font_italic" id="S4.SS3.SSS0.Px2.p1.3.1">KnowledgeSG</span> outperforms all other baselines on average, even better than using original private data, proving the effectiveness of knowledge distillation from professional model through our framework, not to mention our privacy-preserving nature.
(2) For the FiQA-SA dataset, a large portion of the evaluation sample labels are <span class="ltx_text ltx_font_italic" id="S4.SS3.SSS0.Px2.p1.3.2">Neutral</span>. Following the evaluation benchmarks <cite class="ltx_cite ltx_citemacro_cite">Yang (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib68" title="">2023</a>)</cite>, we treat responses with no predictions (Positive/Negative/Neutral) as <span class="ltx_text ltx_font_italic" id="S4.SS3.SSS0.Px2.p1.3.3">Neutral</span>. This situation rarely happens except for pre-trained models that struggle with instruction following. Most of LLaMA2-7B’s responses are classified as <span class="ltx_text ltx_font_italic" id="S4.SS3.SSS0.Px2.p1.3.4">Neutral</span>, thus explaining its unexpectedly strong performance on FiQA-SA.
(3) Ignoring FiQA-SA, some synthetic generation baselines still perform even worse than the pre-trained Llama2 on FPB and TFNS. This phenomenon shows evidence for the quality issue we found for domain-specific data after generation. The <span class="ltx_text ltx_font_italic" id="S4.SS3.SSS0.Px2.p1.3.5">Gap Ratio</span>, as introduced in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A5.SS2" title="E.2 Gap Ratio ‣ Appendix E Differences of Domain-Specific Data from General Data ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">E.2</span></a> is <math alttext="0.4682" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.1.m1.1"><semantics id="S4.SS3.SSS0.Px2.p1.1.m1.1a"><mn id="S4.SS3.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.cmml">0.4682</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.1.m1.1b"><cn id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.cmml" type="float" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1">0.4682</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.1.m1.1c">0.4682</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px2.p1.1.m1.1d">0.4682</annotation></semantics></math> for FPB and <math alttext="0.3663" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.2.m2.1"><semantics id="S4.SS3.SSS0.Px2.p1.2.m2.1a"><mn id="S4.SS3.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.cmml">0.3663</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.2.m2.1b"><cn id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.cmml" type="float" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1">0.3663</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.2.m2.1c">0.3663</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px2.p1.2.m2.1d">0.3663</annotation></semantics></math> for TFNS, both below the heuristically drawn datum line of <math alttext="0.5" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.3.m3.1"><semantics id="S4.SS3.SSS0.Px2.p1.3.m3.1a"><mn id="S4.SS3.SSS0.Px2.p1.3.m3.1.1" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.3.m3.1b"><cn id="S4.SS3.SSS0.Px2.p1.3.m3.1.1.cmml" type="float" xref="S4.SS3.SSS0.Px2.p1.3.m3.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.3.m3.1c">0.5</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px2.p1.3.m3.1d">0.5</annotation></semantics></math>.</p>
</div>
<figure class="ltx_table" id="S4.T3">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T3.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T3.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="S4.T3.1.1.1.1" rowspan="2"><span class="ltx_text" id="S4.T3.1.1.1.1.1">Evaluation</span></th>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T3.1.1.1.2">FPB</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T3.1.1.1.3">FiQA-SA</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T3.1.1.1.4">TFNS</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T3.1.1.1.5">NWGI</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T3.1.1.1.6">Avg:3</td>
<td class="ltx_td ltx_align_center ltx_border_tt" colspan="2" id="S4.T3.1.1.1.7">Avg:4</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.2.2">
<td class="ltx_td ltx_align_center" id="S4.T3.1.2.2.1">Acc</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.2.2.2">F1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.2.2.3">Acc</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.2.2.4">F1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.2.2.5">Acc</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.2.2.6">F1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.2.2.7">Acc</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.2.2.8">F1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.2.2.9">Acc</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.2.2.10">F1</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.2.2.11">Acc</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.2.2.12">F1</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.1.3.3.1">GPT-3.5</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.3.3.2">0.781</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.3.3.3">0.781</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.3.3.4">0.662</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.3.3.5">0.730</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.3.3.6">0.731</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.3.3.7">0.736</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.3.3.8">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.3.3.9">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.3.3.10">0.725</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.3.3.11">0.749</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.3.3.12">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.3.3.13">-</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.1.4.4.1">GPT-4</th>
<td class="ltx_td ltx_align_center" id="S4.T3.1.4.4.2">0.834</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.4.4.3">0.833</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.4.4.4">0.545</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.4.4.5">0.630</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.4.4.6">0.813</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.4.4.7">0.808</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.4.4.8">-</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.4.4.9">-</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.4.4.10">0.731</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.4.4.11">0.757</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.4.4.12">-</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.4.4.13">-</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.1.5.5.1">Llama2-7B</th>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.5.2">0.462</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.5.3">0.390</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.5.4">0.822</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.5.5">0.800</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.5.6">0.386</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.5.7">0.296</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.5.8">0.583</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.5.9">0.503</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.5.10">0.557</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.5.11">0.495</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.5.12">0.563</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.5.5.13">0.497</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.1.6.6.1">FinGPT v3.3</th>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.6.2">0.882</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.6.3">0.882</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.6.4">0.858</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.6.5">0.874</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.6.6">0.903</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.6.7">0.903</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.6.8">0.643</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.6.9">0.643</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.6.10">0.881</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.6.11">0.886</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.6.12">0.822</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.6.6.13">0.826</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.7.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T3.1.7.7.1">Non-Private</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.7.7.2">0.753</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.7.7.3">0.752</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.7.7.4">0.724</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.7.7.5">0.767</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.7.7.6">0.622</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.7.7.7">0.639</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.7.7.8">0.657</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.7.7.9">0.656</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.7.7.10">0.699</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.7.7.11">0.719</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.7.7.12">0.689</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T3.1.7.7.13">0.703</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.8.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.1.8.8.1">ICL</th>
<td class="ltx_td ltx_align_center" id="S4.T3.1.8.8.2">0.366</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.8.8.3">0.251</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.8.8.4">0.724</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.8.8.5">0.725</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.8.8.6">0.418</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.8.8.7">0.421</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.8.8.8">0.563</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.8.8.9">0.532</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.8.8.10">0.502</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.8.8.11">0.466</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.8.8.12">0.517</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.8.8.13">0.482</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.9.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.1.9.9.1">Self-Instruct</th>
<td class="ltx_td ltx_align_center" id="S4.T3.1.9.9.2">0.317</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.9.9.3">0.185</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.9.9.4">0.695</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.9.9.5">0.661</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.9.9.6">0.304</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.9.9.7">0.257</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.9.9.8">0.489</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.9.9.9">0.404</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.9.9.10">0.439</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.9.9.11">0.368</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.9.9.12">0.451</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.9.9.13">0.377</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.10.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.1.10.10.1">Self-Instruct-ICL</th>
<td class="ltx_td ltx_align_center" id="S4.T3.1.10.10.2">0.295</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.10.10.3">0.153</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.10.10.4">0.644</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.10.10.5">0.561</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.10.10.6">0.483</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.10.10.7">0.483</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.10.10.8">0.461</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.10.10.9">0.347</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.10.10.10">0.474</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.10.10.11">0.399</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.10.10.12">0.470</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.10.10.13">0.386</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.11.11">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.1.11.11.1">DP-Gene</th>
<td class="ltx_td ltx_align_center" id="S4.T3.1.11.11.2">0.308</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.11.11.3">0.181</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.11.11.4">0.618</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.11.11.5">0.519</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.11.11.6">0.397</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.11.11.7">0.371</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.11.11.8">0.453</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.11.11.9">0.366</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.11.11.10">0.441</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.11.11.11">0.357</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.11.11.12">0.444</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.11.11.13">0.359</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.12.12">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.1.12.12.1">DP-Instruct</th>
<td class="ltx_td ltx_align_center" id="S4.T3.1.12.12.2">0.296</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.12.12.3">0.285</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.12.12.4">0.615</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.12.12.5">0.489</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.12.12.6">0.439</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.12.12.7">0.439</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.12.12.8">0.421</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.12.12.9">0.300</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.12.12.10">0.450</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.12.12.11">0.404</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.12.12.12">0.443</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.12.12.13">0.378</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.13.13">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T3.1.13.13.1">DP-Instruct-ICL</th>
<td class="ltx_td ltx_align_center" id="S4.T3.1.13.13.2">0.332</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.13.13.3">0.299</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.13.13.4">0.666</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.13.13.5">0.588</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.13.13.6">0.399</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.13.13.7">0.345</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.13.13.8">0.472</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.13.13.9">0.382</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.13.13.10">0.465</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.13.13.11">0.410</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.13.13.12">0.467</td>
<td class="ltx_td ltx_align_center" id="S4.T3.1.13.13.13">0.403</td>
</tr>
<tr class="ltx_tr" id="S4.T3.1.14.14">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T3.1.14.14.1">KnowledgeSG</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.14.14.2"><span class="ltx_text ltx_font_bold" id="S4.T3.1.14.14.2.1">0.779</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.14.14.3"><span class="ltx_text ltx_font_bold" id="S4.T3.1.14.14.3.1">0.775</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.14.14.4"><span class="ltx_text ltx_font_bold" id="S4.T3.1.14.14.4.1">0.791</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.14.14.5"><span class="ltx_text ltx_font_bold" id="S4.T3.1.14.14.5.1">0.806</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.14.14.6"><span class="ltx_text ltx_font_bold" id="S4.T3.1.14.14.6.1">0.782</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.14.14.7"><span class="ltx_text ltx_font_bold" id="S4.T3.1.14.14.7.1">0.743</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.14.14.8"><span class="ltx_text ltx_font_bold" id="S4.T3.1.14.14.8.1">0.658</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.14.14.9"><span class="ltx_text ltx_font_bold" id="S4.T3.1.14.14.9.1">0.658</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.14.14.10"><span class="ltx_text ltx_font_bold" id="S4.T3.1.14.14.10.1">0.784</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.14.14.11"><span class="ltx_text ltx_font_bold" id="S4.T3.1.14.14.11.1">0.775</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.14.14.12"><span class="ltx_text ltx_font_bold" id="S4.T3.1.14.14.12.1">0.752</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T3.1.14.14.13"><span class="ltx_text ltx_font_bold" id="S4.T3.1.14.14.13.1">0.745</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Comparison with baselines on the financial benchmarks, where the sentiment analysis dataset from FinGPT <cite class="ltx_cite ltx_citemacro_cite">Yang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib69" title="">2023</a>)</cite> is used. Four evaluation datasets are considered, including FPB, FIQA-SA, TFNS, and NWGI. We also show results of GPT-3.5/4, Llama2-7B and FinGPT v3.3 for reference. We leverage Llama2-7B as the base model and FinGPT v3.3 as the professional model. The results demonstrate that <span class="ltx_text ltx_font_italic" id="S4.T3.3.1">KnowledgeSG</span> outperforms all other baselines and is on par with the performance of GPT3.5/4.</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S4.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Medical Free-Form Evaluation</h3>
<section class="ltx_paragraph" id="S4.SS4.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Setups.</h4>
<div class="ltx_para" id="S4.SS4.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS4.SSS0.Px1.p1.1">We utilize the HealthCareMagic-100k dataset<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_href" href="https://huggingface.co/datasets/lavita/ChatDoctor-HealthCareMagic-100k" title="">https://huggingface.co/datasets/lavita/ChatDoctor-HealthCareMagic-100k</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib36" title="">2023c</a>)</cite> as our training dataset, since it contains many individual names (e.g. see Fig <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A4.F4" title="Figure 4 ‣ Appendix D Definition of PII ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">4</span></a>). This dataset consists of real conversations between patients and doctors collected from the HealthCareMagic website.</p>
</div>
<div class="ltx_para" id="S4.SS4.SSS0.Px1.p2">
<p class="ltx_p" id="S4.SS4.SSS0.Px1.p2.1">Following <cite class="ltx_cite ltx_citemacro_citet">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib77" title="">2023</a>)</cite>, we conduct free-form evaluation by employing GPT-3.5-turbo <cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib80" title="">2023</a>)</cite> to serve as a judge. For each instruction in the test dataset, the judge pairwise compares two responses resulting from the target model and THE reference model, respectively.
We employ text-davinci-003, GPT-3.5-turbo, GPT-4 and Claude-2 as reference models.
To avoid positional bias, we evaluate each sample twice with exchanged positions of different responses generated by the test and reference models. We follow <cite class="ltx_cite ltx_citemacro_citet">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib35" title="">2023b</a>)</cite> to score the models by calculating the win rate.
Additional experiments on medical benchmarks are attached in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A3.SS1" title="C.1 Medical Benchmarks ‣ Appendix C Additional Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">C.1</span></a>.</p>
</div>
<figure class="ltx_table" id="S4.T4">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T4.3">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T4.3.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T4.3.1.1.1">Evaluation</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T4.3.1.1.2"><span class="ltx_text ltx_inline-block" id="S4.T4.3.1.1.2.1" style="width:51.2pt;">Text-davinci-003</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T4.3.1.1.3"><span class="ltx_text ltx_inline-block" id="S4.T4.3.1.1.3.1" style="width:51.2pt;">GPT-3.5-turbo</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T4.3.1.1.4"><span class="ltx_text ltx_inline-block" id="S4.T4.3.1.1.4.1" style="width:51.2pt;">GPT-4</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T4.3.1.1.5"><span class="ltx_text ltx_inline-block" id="S4.T4.3.1.1.5.1" style="width:51.2pt;">Claude-2</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T4.3.1.1.6"><span class="ltx_text ltx_inline-block" id="S4.T4.3.1.1.6.1" style="width:51.2pt;">Avg</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T4.3.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.3.2.1.1">AlpaCare <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib77" title="">2023</a>)</cite>
</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.2.1.2">0.666</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.2.1.3">0.506</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.2.1.4">0.474</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.2.1.5">0.497</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.2.1.6">0.536</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.3.2.1">Llama2-7B</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.3.2.2">0.135</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.3.2.3">0.104</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.3.2.4">0.038</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.3.2.5">0.046</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.3.2.6">0.081</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T4.3.4.3.1">Non-Private</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.4.3.2">0.389</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.4.3.3">0.303</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.4.3.4">0.151</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.4.3.5">0.179</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T4.3.4.3.6">0.255</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.5.4.1">ICL <cite class="ltx_cite ltx_citemacro_cite">Dong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib14" title="">2022</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.5.4.2">0.380</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.5.4.3">0.280</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.5.4.4">0.141</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.5.4.5">0.166</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.5.4.6">0.241</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.6.5.1">Self-Instruct <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib61" title="">2022</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.6.5.2">0.208</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.6.5.3">0.152</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.6.5.4">0.054</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.6.5.5">0.054</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.6.5.6">0.117</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.7.6.1">Self-Instruct-ICL</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.7.6.2">0.247</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.7.6.3">0.167</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.7.6.4">0.064</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.7.6.5">0.089</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.7.6.6">0.142</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.8.7.1">DP-Gene <cite class="ltx_cite ltx_citemacro_cite">Kurakin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib30" title="">2024</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.8.7.2">0.307</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.8.7.3">0.235</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.8.7.4">0.097</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.8.7.5">0.121</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.8.7.6">0.190</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.9.8.1">DP-Instruct <cite class="ltx_cite ltx_citemacro_cite">Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib73" title="">2024</a>)</cite>
</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.9.8.2">0.255</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.9.8.3">0.184</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.9.8.4">0.076</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.9.8.5">0.097</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.9.8.6">0.153</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.10.9">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T4.3.10.9.1">DP-Instruct-ICL</th>
<td class="ltx_td ltx_align_center" id="S4.T4.3.10.9.2">0.382</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.10.9.3">0.295</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.10.9.4">0.187</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.10.9.5">0.199</td>
<td class="ltx_td ltx_align_center" id="S4.T4.3.10.9.6">0.266</td>
</tr>
<tr class="ltx_tr" id="S4.T4.3.11.10">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T4.3.11.10.1">KnowledgeSG</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.3.11.10.2"><span class="ltx_text ltx_ulem_uline ltx_font_bold" id="S4.T4.3.11.10.2.1">0.776</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.3.11.10.3"><span class="ltx_text ltx_ulem_uline ltx_font_bold" id="S4.T4.3.11.10.3.1">0.530</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.3.11.10.4"><span class="ltx_text ltx_font_bold" id="S4.T4.3.11.10.4.1">0.457</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.3.11.10.5"><span class="ltx_text ltx_font_bold" id="S4.T4.3.11.10.5.1">0.488</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T4.3.11.10.6"><span class="ltx_text ltx_ulem_uline ltx_font_bold" id="S4.T4.3.11.10.6.1">0.562</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Performance results and comparative analysis of free-form instruction evaluation in the medical domain. <span class="ltx_text ltx_font_italic" id="S4.T4.5.1">KnowledgeSG</span> outperforms all other baselines and has a relative improvement of <math alttext="120.39\%" class="ltx_Math" display="inline" id="S4.T4.2.m1.1"><semantics id="S4.T4.2.m1.1b"><mrow id="S4.T4.2.m1.1.1" xref="S4.T4.2.m1.1.1.cmml"><mn id="S4.T4.2.m1.1.1.2" xref="S4.T4.2.m1.1.1.2.cmml">120.39</mn><mo id="S4.T4.2.m1.1.1.1" xref="S4.T4.2.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T4.2.m1.1c"><apply id="S4.T4.2.m1.1.1.cmml" xref="S4.T4.2.m1.1.1"><csymbol cd="latexml" id="S4.T4.2.m1.1.1.1.cmml" xref="S4.T4.2.m1.1.1.1">percent</csymbol><cn id="S4.T4.2.m1.1.1.2.cmml" type="float" xref="S4.T4.2.m1.1.1.2">120.39</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T4.2.m1.1d">120.39\%</annotation><annotation encoding="application/x-llamapun" id="S4.T4.2.m1.1e">120.39 %</annotation></semantics></math> than Non-Private method. Numbers with underlines represent performance surpassing the professional model AlpaCare <cite class="ltx_cite ltx_citemacro_cite">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib77" title="">2023</a>)</cite>.</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S4.SS4.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Results.</h4>
<div class="ltx_para" id="S4.SS4.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS4.SSS0.Px2.p1.1">From Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.T4" title="Table 4 ‣ Setups. ‣ 4.4 Medical Free-Form Evaluation ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">4</span></a> and Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A3.T10" title="Table 10 ‣ Setups. ‣ C.1 Medical Benchmarks ‣ Appendix C Additional Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">10</span></a>, we can conclude that:
(1) Considering both benchmark and free-form results, <span class="ltx_text ltx_font_italic" id="S4.SS4.SSS0.Px2.p1.1.1">KnowledgeSG</span> consistently and significantly surpasses all other baselines in the medical domain.
Particularly in the free-from evaluation, our method outperforms all other synthetic text generation baselines to a large margin, even doubling the performance of the None-private approach using original private data.
(2) DP-based generation methods achieve much higher win rate scores than that of Self-instruction-based methods.
This is expected because DP-based methods require additionally differentially private fine-tuning of the base model on private data.
(3) The free-form results of <span class="ltx_text ltx_font_italic" id="S4.SS4.SSS0.Px2.p1.1.2">KnowledgeSG</span> surpassing AlpaCare (underlined in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.T4" title="Table 4 ‣ Setups. ‣ 4.4 Medical Free-Form Evaluation ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">4</span></a>) highlight the immense potential of synthetic generation approaches which acquire knowledge distillation from a professional model, inspiring future research to further explore this area.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5 </span>Data Quality Measurement.</h3>
<section class="ltx_paragraph" id="S4.SS5.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Embedding Distribution Similarity.</h4>
<div class="ltx_para" id="S4.SS5.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS5.SSS0.Px1.p1.1">As shown in <cite class="ltx_cite ltx_citemacro_citet">Yue et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib75" title="">2023</a>)</cite>, the similarity of synthetic data to the original data implicitly indicates its quality.
Unlike typical natural language generation (NLG) tasks such as machine translation, which have ground truth references for evaluation, quantifying the similarity between synthetic and original private samples is non-trivial due to the absence of one-to-one mapping between them.</p>
</div>
<div class="ltx_para" id="S4.SS5.SSS0.Px1.p2">
<p class="ltx_p" id="S4.SS5.SSS0.Px1.p2.1">To measure the embedding distribution distance between synthetic and original data, we use sentence-transformers<span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_href" href="https://huggingface.co/sentence-transformers" title="">https://huggingface.co/sentence-transformers</a></span></span></span> library <cite class="ltx_cite ltx_citemacro_cite">Reimers and Gurevych (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib54" title="">2019</a>)</cite> to embed both datasets. After that, we calculate the distance between these two embeddings using two widely-adopted metrics as <cite class="ltx_cite ltx_citemacro_citet">Yue et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib75" title="">2023</a>)</cite> does:
(1) MAUVE<span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span><a class="ltx_ref ltx_href" href="https://github.com/krishnap25/mauve" title="">https://github.com/krishnap25/mauve</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">Pillutla et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib52" title="">2023</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib53" title="">2021</a>)</cite>: MAUVE first clusters the samples in each dataset into a histogram (i.e. two histograms for two datasets), and then uses divergence frontiers <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib37" title="">2021</a>)</cite> to calculate the divergence between the two histograms.
(2) Fréchet Inception Distance (FID) <cite class="ltx_cite ltx_citemacro_cite">Heusel et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib21" title="">2018</a>)</cite>: FID calculates the feature-wise mean and covariance matrices of the embedding vectors and then measures the Fréchet distance between the two sets.</p>
</div>
<div class="ltx_para" id="S4.SS5.SSS0.Px1.p3">
<p class="ltx_p" id="S4.SS5.SSS0.Px1.p3.1">Note that the experiments in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS5" title="4.5 Data Quality Measurement. ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">4.5</span></a> are based on the same datasets we generated in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS4" title="4.4 Medical Free-Form Evaluation ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">4.4</span></a>. For paraphrase-MiniLM-L6-v2, its FID score is about 10 times the absolute value of other embedding models. Therefore for an unbiased comparison, we scale its score to match the magnitude of others.</p>
</div>
<figure class="ltx_table" id="S4.T5">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T5.8">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T5.8.9.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T5.8.9.1.1" rowspan="2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text" id="S4.T5.8.9.1.1.1">Baselines</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2" id="S4.T5.8.9.1.2" style="padding-left:3.0pt;padding-right:3.0pt;">Paraphrase-MiniLM-L6-V2</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2" id="S4.T5.8.9.1.3" style="padding-left:3.0pt;padding-right:3.0pt;">All-Mpnet-Base-V2</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_tt" colspan="2" id="S4.T5.8.9.1.4" style="padding-left:3.0pt;padding-right:3.0pt;">All-MiniLM-L6-V2</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S4.T5.8.9.1.5" style="padding-left:3.0pt;padding-right:3.0pt;">Avg</th>
</tr>
<tr class="ltx_tr" id="S4.T5.8.8">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T5.1.1.1" style="padding-left:3.0pt;padding-right:3.0pt;">MAUVE (<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T5.1.1.1.m1.1"><semantics id="S4.T5.1.1.1.m1.1a"><mo id="S4.T5.1.1.1.m1.1.1" stretchy="false" xref="S4.T5.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.1.1.1.m1.1b"><ci id="S4.T5.1.1.1.m1.1.1.cmml" xref="S4.T5.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.1.1.1.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.1.1.1.m1.1d">↑</annotation></semantics></math>)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S4.T5.2.2.2" style="padding-left:3.0pt;padding-right:3.0pt;">FID (<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T5.2.2.2.m1.1"><semantics id="S4.T5.2.2.2.m1.1a"><mo id="S4.T5.2.2.2.m1.1.1" stretchy="false" xref="S4.T5.2.2.2.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.2.2.2.m1.1b"><ci id="S4.T5.2.2.2.m1.1.1.cmml" xref="S4.T5.2.2.2.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.2.2.2.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.2.2.2.m1.1d">↓</annotation></semantics></math>)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T5.3.3.3" style="padding-left:3.0pt;padding-right:3.0pt;">MAUVE (<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T5.3.3.3.m1.1"><semantics id="S4.T5.3.3.3.m1.1a"><mo id="S4.T5.3.3.3.m1.1.1" stretchy="false" xref="S4.T5.3.3.3.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.3.3.3.m1.1b"><ci id="S4.T5.3.3.3.m1.1.1.cmml" xref="S4.T5.3.3.3.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.3.3.3.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.3.3.3.m1.1d">↑</annotation></semantics></math>)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S4.T5.4.4.4" style="padding-left:3.0pt;padding-right:3.0pt;">FID (<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T5.4.4.4.m1.1"><semantics id="S4.T5.4.4.4.m1.1a"><mo id="S4.T5.4.4.4.m1.1.1" stretchy="false" xref="S4.T5.4.4.4.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.4.4.4.m1.1b"><ci id="S4.T5.4.4.4.m1.1.1.cmml" xref="S4.T5.4.4.4.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.4.4.4.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.4.4.4.m1.1d">↓</annotation></semantics></math>)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T5.5.5.5" style="padding-left:3.0pt;padding-right:3.0pt;">MAUVE (<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T5.5.5.5.m1.1"><semantics id="S4.T5.5.5.5.m1.1a"><mo id="S4.T5.5.5.5.m1.1.1" stretchy="false" xref="S4.T5.5.5.5.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.5.5.5.m1.1b"><ci id="S4.T5.5.5.5.m1.1.1.cmml" xref="S4.T5.5.5.5.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.5.5.5.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.5.5.5.m1.1d">↑</annotation></semantics></math>)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r" id="S4.T5.6.6.6" style="padding-left:3.0pt;padding-right:3.0pt;">FID (<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T5.6.6.6.m1.1"><semantics id="S4.T5.6.6.6.m1.1a"><mo id="S4.T5.6.6.6.m1.1.1" stretchy="false" xref="S4.T5.6.6.6.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.6.6.6.m1.1b"><ci id="S4.T5.6.6.6.m1.1.1.cmml" xref="S4.T5.6.6.6.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.6.6.6.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.6.6.6.m1.1d">↓</annotation></semantics></math>)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T5.7.7.7" style="padding-left:3.0pt;padding-right:3.0pt;">MAUVE (<math alttext="\uparrow" class="ltx_Math" display="inline" id="S4.T5.7.7.7.m1.1"><semantics id="S4.T5.7.7.7.m1.1a"><mo id="S4.T5.7.7.7.m1.1.1" stretchy="false" xref="S4.T5.7.7.7.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S4.T5.7.7.7.m1.1b"><ci id="S4.T5.7.7.7.m1.1.1.cmml" xref="S4.T5.7.7.7.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.7.7.7.m1.1c">\uparrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.7.7.7.m1.1d">↑</annotation></semantics></math>)</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T5.8.8.8" style="padding-left:3.0pt;padding-right:3.0pt;">FID (<math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T5.8.8.8.m1.1"><semantics id="S4.T5.8.8.8.m1.1a"><mo id="S4.T5.8.8.8.m1.1.1" stretchy="false" xref="S4.T5.8.8.8.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T5.8.8.8.m1.1b"><ci id="S4.T5.8.8.8.m1.1.1.cmml" xref="S4.T5.8.8.8.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T5.8.8.8.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T5.8.8.8.m1.1d">↓</annotation></semantics></math>)</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T5.8.10.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T5.8.10.1.1" style="padding-left:3.0pt;padding-right:3.0pt;">ICL</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.8.10.1.2" style="padding-left:3.0pt;padding-right:3.0pt;">69.83</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T5.8.10.1.3" style="padding-left:3.0pt;padding-right:3.0pt;">59.96</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.8.10.1.4" style="padding-left:3.0pt;padding-right:3.0pt;">71.73</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T5.8.10.1.5" style="padding-left:3.0pt;padding-right:3.0pt;">52.33</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.8.10.1.6" style="padding-left:3.0pt;padding-right:3.0pt;">85.00</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t" id="S4.T5.8.10.1.7" style="padding-left:3.0pt;padding-right:3.0pt;">53.76</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.8.10.1.8" style="padding-left:3.0pt;padding-right:3.0pt;">75.52</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T5.8.10.1.9" style="padding-left:3.0pt;padding-right:3.0pt;">55.35</td>
</tr>
<tr class="ltx_tr" id="S4.T5.8.11.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.8.11.2.1" style="padding-left:3.0pt;padding-right:3.0pt;">Self-Instruct</th>
<td class="ltx_td ltx_align_center" id="S4.T5.8.11.2.2" style="padding-left:3.0pt;padding-right:3.0pt;">72.26</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.8.11.2.3" style="padding-left:3.0pt;padding-right:3.0pt;">61.27</td>
<td class="ltx_td ltx_align_center" id="S4.T5.8.11.2.4" style="padding-left:3.0pt;padding-right:3.0pt;">91.72</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.8.11.2.5" style="padding-left:3.0pt;padding-right:3.0pt;">50.05</td>
<td class="ltx_td ltx_align_center" id="S4.T5.8.11.2.6" style="padding-left:3.0pt;padding-right:3.0pt;">67.72</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.8.11.2.7" style="padding-left:3.0pt;padding-right:3.0pt;">52.82</td>
<td class="ltx_td ltx_align_center" id="S4.T5.8.11.2.8" style="padding-left:3.0pt;padding-right:3.0pt;">77.07</td>
<td class="ltx_td ltx_align_center" id="S4.T5.8.11.2.9" style="padding-left:3.0pt;padding-right:3.0pt;">54.21</td>
</tr>
<tr class="ltx_tr" id="S4.T5.8.12.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.8.12.3.1" style="padding-left:3.0pt;padding-right:3.0pt;">Self-Instruct-ICL</th>
<td class="ltx_td ltx_align_center" id="S4.T5.8.12.3.2" style="padding-left:3.0pt;padding-right:3.0pt;">71.77</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.8.12.3.3" style="padding-left:3.0pt;padding-right:3.0pt;">59.75</td>
<td class="ltx_td ltx_align_center" id="S4.T5.8.12.3.4" style="padding-left:3.0pt;padding-right:3.0pt;">77.61</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.8.12.3.5" style="padding-left:3.0pt;padding-right:3.0pt;">53.49</td>
<td class="ltx_td ltx_align_center" id="S4.T5.8.12.3.6" style="padding-left:3.0pt;padding-right:3.0pt;">78.55</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.8.12.3.7" style="padding-left:3.0pt;padding-right:3.0pt;">53.06</td>
<td class="ltx_td ltx_align_center" id="S4.T5.8.12.3.8" style="padding-left:3.0pt;padding-right:3.0pt;">76.14</td>
<td class="ltx_td ltx_align_center" id="S4.T5.8.12.3.9" style="padding-left:3.0pt;padding-right:3.0pt;">55.94</td>
</tr>
<tr class="ltx_tr" id="S4.T5.8.13.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.8.13.4.1" style="padding-left:3.0pt;padding-right:3.0pt;">DP-Gene</th>
<td class="ltx_td ltx_align_center" id="S4.T5.8.13.4.2" style="padding-left:3.0pt;padding-right:3.0pt;">83.23</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.8.13.4.3" style="padding-left:3.0pt;padding-right:3.0pt;">59.41</td>
<td class="ltx_td ltx_align_center" id="S4.T5.8.13.4.4" style="padding-left:3.0pt;padding-right:3.0pt;">89.58</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.8.13.4.5" style="padding-left:3.0pt;padding-right:3.0pt;">51.42</td>
<td class="ltx_td ltx_align_center" id="S4.T5.8.13.4.6" style="padding-left:3.0pt;padding-right:3.0pt;">84.47</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.8.13.4.7" style="padding-left:3.0pt;padding-right:3.0pt;">53.58</td>
<td class="ltx_td ltx_align_center" id="S4.T5.8.13.4.8" style="padding-left:3.0pt;padding-right:3.0pt;">85.76</td>
<td class="ltx_td ltx_align_center" id="S4.T5.8.13.4.9" style="padding-left:3.0pt;padding-right:3.0pt;">54.80</td>
</tr>
<tr class="ltx_tr" id="S4.T5.8.14.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.8.14.5.1" style="padding-left:3.0pt;padding-right:3.0pt;">DP-Instruct</th>
<td class="ltx_td ltx_align_center" id="S4.T5.8.14.5.2" style="padding-left:3.0pt;padding-right:3.0pt;">81.29</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.8.14.5.3" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.8.14.5.3.1">58.92</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.8.14.5.4" style="padding-left:3.0pt;padding-right:3.0pt;">83.18</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.8.14.5.5" style="padding-left:3.0pt;padding-right:3.0pt;">50.10</td>
<td class="ltx_td ltx_align_center" id="S4.T5.8.14.5.6" style="padding-left:3.0pt;padding-right:3.0pt;">89.14</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.8.14.5.7" style="padding-left:3.0pt;padding-right:3.0pt;">51.95</td>
<td class="ltx_td ltx_align_center" id="S4.T5.8.14.5.8" style="padding-left:3.0pt;padding-right:3.0pt;">84.54</td>
<td class="ltx_td ltx_align_center" id="S4.T5.8.14.5.9" style="padding-left:3.0pt;padding-right:3.0pt;">53.66</td>
</tr>
<tr class="ltx_tr" id="S4.T5.8.15.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T5.8.15.6.1" style="padding-left:3.0pt;padding-right:3.0pt;">DP-Instruct-ICL</th>
<td class="ltx_td ltx_align_center" id="S4.T5.8.15.6.2" style="padding-left:3.0pt;padding-right:3.0pt;">81.97</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.8.15.6.3" style="padding-left:3.0pt;padding-right:3.0pt;">60.00</td>
<td class="ltx_td ltx_align_center" id="S4.T5.8.15.6.4" style="padding-left:3.0pt;padding-right:3.0pt;">92.20</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.8.15.6.5" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.8.15.6.5.1">49.45</span></td>
<td class="ltx_td ltx_align_center" id="S4.T5.8.15.6.6" style="padding-left:3.0pt;padding-right:3.0pt;">82.06</td>
<td class="ltx_td ltx_align_center ltx_border_r" id="S4.T5.8.15.6.7" style="padding-left:3.0pt;padding-right:3.0pt;">52.36</td>
<td class="ltx_td ltx_align_center" id="S4.T5.8.15.6.8" style="padding-left:3.0pt;padding-right:3.0pt;">85.41</td>
<td class="ltx_td ltx_align_center" id="S4.T5.8.15.6.9" style="padding-left:3.0pt;padding-right:3.0pt;">53.94</td>
</tr>
<tr class="ltx_tr" id="S4.T5.8.16.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T5.8.16.7.1" style="padding-left:3.0pt;padding-right:3.0pt;">KnowledgeSG</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.8.16.7.2" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.8.16.7.2.1">90.77</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T5.8.16.7.3" style="padding-left:3.0pt;padding-right:3.0pt;">59.01</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.8.16.7.4" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.8.16.7.4.1">96.48</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T5.8.16.7.5" style="padding-left:3.0pt;padding-right:3.0pt;">50.04</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.8.16.7.6" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.8.16.7.6.1">92.82</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_r" id="S4.T5.8.16.7.7" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.8.16.7.7.1">51.75</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.8.16.7.8" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.8.16.7.8.1">93.36</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T5.8.16.7.9" style="padding-left:3.0pt;padding-right:3.0pt;"><span class="ltx_text ltx_font_bold" id="S4.T5.8.16.7.9.1">53.60</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Embedding distribution distance between the synthetic and original data measured by the MAUVE and FID score. Better similarity indicates better quality of the synthetic data. The results on average reaffirm that <span class="ltx_text ltx_font_italic" id="S4.T5.10.1">KnowledgeSG</span> has best data quality compared to other baselines.</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S4.SS5.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Instruction Following Difficulty.</h4>
<div class="ltx_para" id="S4.SS5.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS5.SSS0.Px2.p1.1">Instruction following difficulty (IFD) introduced by <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib34" title="">2023a</a>)</cite>, evaluates how much help the instruction provides for the generation of corresponding response. It compares the change of losses in model responses with and without the instructional context, and outputs a ratio as the final score.
A lower IFD score indicates better quality of the evaluated sample. Thus we apply IFD score to measure the utility and quality of the generated instruction tuning datasets.
The average IFD scores of dataset samples before filtering are presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.F3" title="Figure 3 ‣ Instruction Following Difficulty. ‣ 4.5 Data Quality Measurement. ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">3</span></a>, exhibiting the disparity in the generation capabilities across various baselines.
In practice, we deploy IFD score as the data filtering measure <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib33" title="">2024b</a>); Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib78" title="">2024</a>)</cite> in our framework. However, in consideration of fair comparison with other baselines, we exclude it from the experiments in Sections <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS3" title="4.3 Financial Benchmarks ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">4.3</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS4" title="4.4 Medical Free-Form Evaluation ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">4.4</span></a>.</p>
</div>
<figure class="ltx_figure" id="S4.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="321" id="S4.F3.g1" src="extracted/5915286/assets/ifd.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Instruction following difficulty of different baselines exploiting Llama2-7B as the base model. Lower IFD score indicates better quality of synthetic data. We evaluate on the synthetic datasets which are generated during the experiments in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS4" title="4.4 Medical Free-Form Evaluation ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">4.4</span></a>.</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S4.SS5.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Results.</h4>
<div class="ltx_para" id="S4.SS5.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS5.SSS0.Px3.p1.1">From Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.T5" title="Table 5 ‣ Embedding Distribution Similarity. ‣ 4.5 Data Quality Measurement. ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">5</span></a> and Fig <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.F3" title="Figure 3 ‣ Instruction Following Difficulty. ‣ 4.5 Data Quality Measurement. ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">3</span></a>, We can conclude that:
(1) Although the absolute values of MAUVE and FID are influenced by the specific settings used in its calculation, e.g. scalar scaling constants, the relative rankings of different synthetic datasets remain consistent.
Still, <span class="ltx_text ltx_font_italic" id="S4.SS5.SSS0.Px3.p1.1.1">KnowledgeSG</span> achieves the best similarity measured by the MAUVE score. For the FID score, our method is only second to DP-Instruct-ICL, an improved version we adopt from <cite class="ltx_cite ltx_citemacro_citet">Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib73" title="">2024</a>)</cite>.
(2) The leading performance of <span class="ltx_text ltx_font_italic" id="S4.SS5.SSS0.Px3.p1.1.2">KnowledgeSG</span> indicates better quality of synthetic data compared to other baselines. This is consistent with the performance results in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS4" title="4.4 Medical Free-Form Evaluation ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">4.4</span></a>
(3) For instruction following difficulty, the results conform to those of embedding distribution similarity, further proving the effectiveness of our proposed method.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.6 </span>Ablation on Dataset Size</h3>
<section class="ltx_paragraph" id="S4.SS6.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Setups.</h4>
<div class="ltx_para" id="S4.SS6.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS6.SSS0.Px1.p1.3">We perform an ablation study on dataset size to investigate its impact on the model’s final performance through synthetic data generation. The training and evaluation setups are the same as Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS4" title="4.4 Medical Free-Form Evaluation ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">4.4</span></a>.
For a fair comparison, we make sure that each data sample is iterated <math alttext="5" class="ltx_Math" display="inline" id="S4.SS6.SSS0.Px1.p1.1.m1.1"><semantics id="S4.SS6.SSS0.Px1.p1.1.m1.1a"><mn id="S4.SS6.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS6.SSS0.Px1.p1.1.m1.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="S4.SS6.SSS0.Px1.p1.1.m1.1b"><cn id="S4.SS6.SSS0.Px1.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS6.SSS0.Px1.p1.1.m1.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.SSS0.Px1.p1.1.m1.1c">5</annotation><annotation encoding="application/x-llamapun" id="S4.SS6.SSS0.Px1.p1.1.m1.1d">5</annotation></semantics></math> times by training the models for corresponding rounds wile keeping other parameters fixed (e.g., the 500-sample dataset is trained for <math alttext="50" class="ltx_Math" display="inline" id="S4.SS6.SSS0.Px1.p1.2.m2.1"><semantics id="S4.SS6.SSS0.Px1.p1.2.m2.1a"><mn id="S4.SS6.SSS0.Px1.p1.2.m2.1.1" xref="S4.SS6.SSS0.Px1.p1.2.m2.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S4.SS6.SSS0.Px1.p1.2.m2.1b"><cn id="S4.SS6.SSS0.Px1.p1.2.m2.1.1.cmml" type="integer" xref="S4.SS6.SSS0.Px1.p1.2.m2.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.SSS0.Px1.p1.2.m2.1c">50</annotation><annotation encoding="application/x-llamapun" id="S4.SS6.SSS0.Px1.p1.2.m2.1d">50</annotation></semantics></math> rounds, and the 1000-sample dataset for <math alttext="100" class="ltx_Math" display="inline" id="S4.SS6.SSS0.Px1.p1.3.m3.1"><semantics id="S4.SS6.SSS0.Px1.p1.3.m3.1a"><mn id="S4.SS6.SSS0.Px1.p1.3.m3.1.1" xref="S4.SS6.SSS0.Px1.p1.3.m3.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="S4.SS6.SSS0.Px1.p1.3.m3.1b"><cn id="S4.SS6.SSS0.Px1.p1.3.m3.1.1.cmml" type="integer" xref="S4.SS6.SSS0.Px1.p1.3.m3.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS6.SSS0.Px1.p1.3.m3.1c">100</annotation><annotation encoding="application/x-llamapun" id="S4.SS6.SSS0.Px1.p1.3.m3.1d">100</annotation></semantics></math> rounds).</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS6.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Results.</h4>
<div class="ltx_para" id="S4.SS6.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS6.SSS0.Px2.p1.1">For all methods shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.T6" title="Table 6 ‣ Results. ‣ 4.6 Ablation on Dataset Size ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">6</span></a>, the results indicate that as the amount of involved data increases, the performance of the trained model improves correspondingly.
However, the last row of <span class="ltx_text ltx_font_italic" id="S4.SS6.SSS0.Px2.p1.1.1">KnowledgeSG</span> suggests that the improvement from accumulating additional data may reach a potential threshold. We leave further exploration of this for future work.</p>
</div>
<figure class="ltx_table" id="S4.T6">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T6.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T6.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T6.1.1.1.1">Dataset Size</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T6.1.1.1.2">500</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T6.1.1.1.3">1000</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T6.1.1.1.4">2000</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S4.T6.1.1.1.5">3000</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T6.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T6.1.2.1.1">Non-Private</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.1.2.1.2">0.325</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.1.2.1.3">0.371</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.1.2.1.4">0.379</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T6.1.2.1.5">0.391</td>
</tr>
<tr class="ltx_tr" id="S4.T6.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T6.1.3.2.1">ICL</th>
<td class="ltx_td ltx_align_center" id="S4.T6.1.3.2.2">0.329</td>
<td class="ltx_td ltx_align_center" id="S4.T6.1.3.2.3">0.335</td>
<td class="ltx_td ltx_align_center" id="S4.T6.1.3.2.4">0.364</td>
<td class="ltx_td ltx_align_center" id="S4.T6.1.3.2.5">0.368</td>
</tr>
<tr class="ltx_tr" id="S4.T6.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T6.1.4.3.1">KnowledgeSG</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T6.1.4.3.2">0.708</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T6.1.4.3.3">0.724</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T6.1.4.3.4">0.747</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T6.1.4.3.5">0.757</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>Ablations on dataset size. With more data involved, the model performance improves as expected.</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S4.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.7 </span>Transmitting Unit</h3>
<section class="ltx_paragraph" id="S4.SS7.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Setups.</h4>
<div class="ltx_para" id="S4.SS7.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS7.SSS0.Px1.p1.5">We employ alpaca <cite class="ltx_cite ltx_citemacro_cite">Peng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib51" title="">2023</a>)</cite> and randomly select <math alttext="50" class="ltx_Math" display="inline" id="S4.SS7.SSS0.Px1.p1.1.m1.1"><semantics id="S4.SS7.SSS0.Px1.p1.1.m1.1a"><mn id="S4.SS7.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS7.SSS0.Px1.p1.1.m1.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="S4.SS7.SSS0.Px1.p1.1.m1.1b"><cn id="S4.SS7.SSS0.Px1.p1.1.m1.1.1.cmml" type="integer" xref="S4.SS7.SSS0.Px1.p1.1.m1.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.SSS0.Px1.p1.1.m1.1c">50</annotation><annotation encoding="application/x-llamapun" id="S4.SS7.SSS0.Px1.p1.1.m1.1d">50</annotation></semantics></math> samples to form our seed dataset <math alttext="\mathbb{D}_{Seed}" class="ltx_Math" display="inline" id="S4.SS7.SSS0.Px1.p1.2.m2.1"><semantics id="S4.SS7.SSS0.Px1.p1.2.m2.1a"><msub id="S4.SS7.SSS0.Px1.p1.2.m2.1.1" xref="S4.SS7.SSS0.Px1.p1.2.m2.1.1.cmml"><mi id="S4.SS7.SSS0.Px1.p1.2.m2.1.1.2" xref="S4.SS7.SSS0.Px1.p1.2.m2.1.1.2.cmml">𝔻</mi><mrow id="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3" xref="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.cmml"><mi id="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.2" xref="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.2.cmml">S</mi><mo id="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.1" xref="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.3" xref="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.3.cmml">e</mi><mo id="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.1a" xref="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.4" xref="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.4.cmml">e</mi><mo id="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.1b" xref="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.5" xref="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS7.SSS0.Px1.p1.2.m2.1b"><apply id="S4.SS7.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S4.SS7.SSS0.Px1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS7.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S4.SS7.SSS0.Px1.p1.2.m2.1.1">subscript</csymbol><ci id="S4.SS7.SSS0.Px1.p1.2.m2.1.1.2.cmml" xref="S4.SS7.SSS0.Px1.p1.2.m2.1.1.2">𝔻</ci><apply id="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.cmml" xref="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3"><times id="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.1.cmml" xref="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.1"></times><ci id="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.2.cmml" xref="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.2">𝑆</ci><ci id="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.3.cmml" xref="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.3">𝑒</ci><ci id="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.4.cmml" xref="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.4">𝑒</ci><ci id="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.5.cmml" xref="S4.SS7.SSS0.Px1.p1.2.m2.1.1.3.5">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.SSS0.Px1.p1.2.m2.1c">\mathbb{D}_{Seed}</annotation><annotation encoding="application/x-llamapun" id="S4.SS7.SSS0.Px1.p1.2.m2.1d">blackboard_D start_POSTSUBSCRIPT italic_S italic_e italic_e italic_d end_POSTSUBSCRIPT</annotation></semantics></math>.
We first fine-tune Llama2-7B on <math alttext="\mathbb{D}_{Seed}" class="ltx_Math" display="inline" id="S4.SS7.SSS0.Px1.p1.3.m3.1"><semantics id="S4.SS7.SSS0.Px1.p1.3.m3.1a"><msub id="S4.SS7.SSS0.Px1.p1.3.m3.1.1" xref="S4.SS7.SSS0.Px1.p1.3.m3.1.1.cmml"><mi id="S4.SS7.SSS0.Px1.p1.3.m3.1.1.2" xref="S4.SS7.SSS0.Px1.p1.3.m3.1.1.2.cmml">𝔻</mi><mrow id="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3" xref="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.cmml"><mi id="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.2" xref="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.2.cmml">S</mi><mo id="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.1" xref="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.3" xref="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.3.cmml">e</mi><mo id="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.1a" xref="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.4" xref="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.4.cmml">e</mi><mo id="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.1b" xref="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.5" xref="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS7.SSS0.Px1.p1.3.m3.1b"><apply id="S4.SS7.SSS0.Px1.p1.3.m3.1.1.cmml" xref="S4.SS7.SSS0.Px1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.SS7.SSS0.Px1.p1.3.m3.1.1.1.cmml" xref="S4.SS7.SSS0.Px1.p1.3.m3.1.1">subscript</csymbol><ci id="S4.SS7.SSS0.Px1.p1.3.m3.1.1.2.cmml" xref="S4.SS7.SSS0.Px1.p1.3.m3.1.1.2">𝔻</ci><apply id="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.cmml" xref="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3"><times id="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.1.cmml" xref="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.1"></times><ci id="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.2.cmml" xref="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.2">𝑆</ci><ci id="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.3.cmml" xref="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.3">𝑒</ci><ci id="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.4.cmml" xref="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.4">𝑒</ci><ci id="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.5.cmml" xref="S4.SS7.SSS0.Px1.p1.3.m3.1.1.3.5">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.SSS0.Px1.p1.3.m3.1c">\mathbb{D}_{Seed}</annotation><annotation encoding="application/x-llamapun" id="S4.SS7.SSS0.Px1.p1.3.m3.1d">blackboard_D start_POSTSUBSCRIPT italic_S italic_e italic_e italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, then replace the original model with its fine-tuned version.
We assume the attacker only has access to the transmitting process, meaning he can intercept the LoRA adapter fine-tuned on the new base model.
Without access to <math alttext="\mathbb{D}_{Seed}" class="ltx_Math" display="inline" id="S4.SS7.SSS0.Px1.p1.4.m4.1"><semantics id="S4.SS7.SSS0.Px1.p1.4.m4.1a"><msub id="S4.SS7.SSS0.Px1.p1.4.m4.1.1" xref="S4.SS7.SSS0.Px1.p1.4.m4.1.1.cmml"><mi id="S4.SS7.SSS0.Px1.p1.4.m4.1.1.2" xref="S4.SS7.SSS0.Px1.p1.4.m4.1.1.2.cmml">𝔻</mi><mrow id="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3" xref="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.cmml"><mi id="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.2" xref="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.2.cmml">S</mi><mo id="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.1" xref="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.3" xref="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.3.cmml">e</mi><mo id="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.1a" xref="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.4" xref="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.4.cmml">e</mi><mo id="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.1b" xref="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.5" xref="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.5.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S4.SS7.SSS0.Px1.p1.4.m4.1b"><apply id="S4.SS7.SSS0.Px1.p1.4.m4.1.1.cmml" xref="S4.SS7.SSS0.Px1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S4.SS7.SSS0.Px1.p1.4.m4.1.1.1.cmml" xref="S4.SS7.SSS0.Px1.p1.4.m4.1.1">subscript</csymbol><ci id="S4.SS7.SSS0.Px1.p1.4.m4.1.1.2.cmml" xref="S4.SS7.SSS0.Px1.p1.4.m4.1.1.2">𝔻</ci><apply id="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.cmml" xref="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3"><times id="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.1.cmml" xref="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.1"></times><ci id="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.2.cmml" xref="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.2">𝑆</ci><ci id="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.3.cmml" xref="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.3">𝑒</ci><ci id="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.4.cmml" xref="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.4">𝑒</ci><ci id="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.5.cmml" xref="S4.SS7.SSS0.Px1.p1.4.m4.1.1.3.5">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.SSS0.Px1.p1.4.m4.1c">\mathbb{D}_{Seed}</annotation><annotation encoding="application/x-llamapun" id="S4.SS7.SSS0.Px1.p1.4.m4.1d">blackboard_D start_POSTSUBSCRIPT italic_S italic_e italic_e italic_d end_POSTSUBSCRIPT</annotation></semantics></math>, the attacker can only attempt to merge the adapter with the original base model, i.e. open-sourced Llama2-7B, thus unable to reproduce the full performance of our model
<span class="ltx_text ltx_font_italic" id="S4.SS7.SSS0.Px1.p1.5.1">Relative Drop</span> is calculated by <math alttext="Relative\ Drop=\frac{(KnowledgeSG-Attacker)}{KnowledgeSG}" class="ltx_Math" display="inline" id="S4.SS7.SSS0.Px1.p1.5.m5.1"><semantics id="S4.SS7.SSS0.Px1.p1.5.m5.1a"><mrow id="S4.SS7.SSS0.Px1.p1.5.m5.1.2" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.cmml"><mrow id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.cmml"><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.2" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.2.cmml">R</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.3" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.3.cmml">e</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1a" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.4" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.4.cmml">l</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1b" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.5" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.5.cmml">a</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1c" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.6" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.6.cmml">t</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1d" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.7" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.7.cmml">i</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1e" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.8" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.8.cmml">v</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1f" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.9" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.9.cmml">e</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1g" lspace="0.500em" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.10" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.10.cmml">D</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1h" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.11" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.11.cmml">r</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1i" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.12" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.12.cmml">o</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1j" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.13" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.13.cmml">p</mi></mrow><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.1" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.1.cmml">=</mo><mfrac id="S4.SS7.SSS0.Px1.p1.5.m5.1.1" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.cmml"><mrow id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.cmml"><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.2" stretchy="false" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.cmml">(</mo><mrow id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.cmml"><mrow id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.cmml"><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.2" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.2.cmml">K</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.3" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.3.cmml">n</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1a" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.4" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.4.cmml">o</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1b" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.5" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.5.cmml">w</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1c" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.6" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.6.cmml">l</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1d" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.7" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.7.cmml">e</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1e" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.8" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.8.cmml">d</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1f" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.9" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.9.cmml">g</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1g" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.10" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.10.cmml">e</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1h" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.11" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.11.cmml">S</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1i" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.12" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.12.cmml">G</mi></mrow><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.1" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.1.cmml">−</mo><mrow id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.cmml"><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.2" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.2.cmml">A</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.1" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.3" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.3.cmml">t</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.1a" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.4" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.4.cmml">t</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.1b" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.5" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.5.cmml">a</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.1c" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.6" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.6.cmml">c</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.1d" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.7" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.7.cmml">k</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.1e" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.8" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.8.cmml">e</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.1f" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.9" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.9.cmml">r</mi></mrow></mrow><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.3" stretchy="false" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.cmml">)</mo></mrow><mrow id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.cmml"><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.2" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.2.cmml">K</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.3" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.3.cmml">n</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1a" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.4" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.4.cmml">o</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1b" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.5" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.5.cmml">w</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1c" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.6" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.6.cmml">l</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1d" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.7" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.7.cmml">e</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1e" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.8" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.8.cmml">d</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1f" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.9" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.9.cmml">g</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1g" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.10" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.10.cmml">e</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1h" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.11" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.11.cmml">S</mi><mo id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1i" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.12" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.12.cmml">G</mi></mrow></mfrac></mrow><annotation-xml encoding="MathML-Content" id="S4.SS7.SSS0.Px1.p1.5.m5.1b"><apply id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2"><eq id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.1.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.1"></eq><apply id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2"><times id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.1"></times><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.2.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.2">𝑅</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.3.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.3">𝑒</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.4.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.4">𝑙</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.5.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.5">𝑎</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.6.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.6">𝑡</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.7.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.7">𝑖</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.8.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.8">𝑣</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.9.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.9">𝑒</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.10.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.10">𝐷</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.11.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.11">𝑟</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.12.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.12">𝑜</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.13.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.2.2.13">𝑝</ci></apply><apply id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1"><divide id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.2.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1"></divide><apply id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1"><minus id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.1.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.1"></minus><apply id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2"><times id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.1"></times><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.2.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.2">𝐾</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.3.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.3">𝑛</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.4.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.4">𝑜</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.5.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.5">𝑤</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.6.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.6">𝑙</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.7.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.7">𝑒</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.8.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.8">𝑑</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.9.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.9">𝑔</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.10.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.10">𝑒</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.11.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.11">𝑆</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.12.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.2.12">𝐺</ci></apply><apply id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3"><times id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.1.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.1"></times><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.2.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.2">𝐴</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.3.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.3">𝑡</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.4.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.4">𝑡</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.5.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.5">𝑎</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.6.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.6">𝑐</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.7.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.7">𝑘</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.8.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.8">𝑒</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.9.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.1.1.1.3.9">𝑟</ci></apply></apply><apply id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3"><times id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.1"></times><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.2.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.2">𝐾</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.3.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.3">𝑛</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.4.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.4">𝑜</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.5.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.5">𝑤</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.6.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.6">𝑙</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.7.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.7">𝑒</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.8.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.8">𝑑</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.9.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.9">𝑔</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.10.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.10">𝑒</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.11.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.11">𝑆</ci><ci id="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.12.cmml" xref="S4.SS7.SSS0.Px1.p1.5.m5.1.1.3.12">𝐺</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS7.SSS0.Px1.p1.5.m5.1c">Relative\ Drop=\frac{(KnowledgeSG-Attacker)}{KnowledgeSG}</annotation><annotation encoding="application/x-llamapun" id="S4.SS7.SSS0.Px1.p1.5.m5.1d">italic_R italic_e italic_l italic_a italic_t italic_i italic_v italic_e italic_D italic_r italic_o italic_p = divide start_ARG ( italic_K italic_n italic_o italic_w italic_l italic_e italic_d italic_g italic_e italic_S italic_G - italic_A italic_t italic_t italic_a italic_c italic_k italic_e italic_r ) end_ARG start_ARG italic_K italic_n italic_o italic_w italic_l italic_e italic_d italic_g italic_e italic_S italic_G end_ARG</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS7.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Results.</h4>
<div class="ltx_para" id="S4.SS7.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS7.SSS0.Px2.p1.1">Results in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.T7" title="Table 7 ‣ Results. ‣ 4.7 Transmitting Unit ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">7</span></a> show that the performance of model stolen by the attacker drops significantly compared to <span class="ltx_text ltx_font_italic" id="S4.SS7.SSS0.Px2.p1.1.1">KnowledgeSG</span>. This demonstrates that our model is not compromised, confirming the efficacy of proposed transmitting unit.</p>
</div>
<figure class="ltx_table" id="S4.T7">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T7.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T7.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="S4.T7.1.1.1.1" rowspan="2"><span class="ltx_text" id="S4.T7.1.1.1.1.1">Evaluation</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S4.T7.1.1.1.2">Avg:3</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="S4.T7.1.1.1.3">Avg:4</th>
</tr>
<tr class="ltx_tr" id="S4.T7.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T7.1.2.2.1">Acc</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T7.1.2.2.2">F1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T7.1.2.2.3">Acc</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="S4.T7.1.2.2.4">F1</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T7.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="S4.T7.1.3.1.1">Llama2-7B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.1.3.1.2">0.557</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.1.3.1.3">0.495</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.1.3.1.4">0.563</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S4.T7.1.3.1.5">0.497</td>
</tr>
<tr class="ltx_tr" id="S4.T7.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.1.4.2.1">KnowledgeSG</th>
<td class="ltx_td ltx_align_center" id="S4.T7.1.4.2.2">0.784</td>
<td class="ltx_td ltx_align_center" id="S4.T7.1.4.2.3">0.775</td>
<td class="ltx_td ltx_align_center" id="S4.T7.1.4.2.4">0.752</td>
<td class="ltx_td ltx_align_center" id="S4.T7.1.4.2.5">0.745</td>
</tr>
<tr class="ltx_tr" id="S4.T7.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="S4.T7.1.5.3.1">Attacker</th>
<td class="ltx_td ltx_align_center" id="S4.T7.1.5.3.2">0.419</td>
<td class="ltx_td ltx_align_center" id="S4.T7.1.5.3.3">0.343</td>
<td class="ltx_td ltx_align_center" id="S4.T7.1.5.3.4">0.428</td>
<td class="ltx_td ltx_align_center" id="S4.T7.1.5.3.5">0.350</td>
</tr>
<tr class="ltx_tr" id="S4.T7.1.6.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="S4.T7.1.6.4.1">Relative Drop</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.1.6.4.2">46.49%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.1.6.4.3">55.76%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.1.6.4.4">43.06%</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S4.T7.1.6.4.5">53.08%</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Experiments of proposed transmitting unit.
The <span class="ltx_text ltx_font_italic" id="S4.T7.3.1">Relative Drop</span> in performance suggests that our model is safeguarded against the attacker during transmission.
</figcaption>
</figure>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Discussions</h2>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Why not Scrubbing</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.2">The most intuitive way of privacy-preserving is PII scrubbing.
PII scrubbing is a dataset curation technique that removes PII from text, relying on Named Entity Recognition (NER) to tag PII.
In practice, using scrubbing to mask or add noise to original data, is flawed and must balance the trade-off between minimizing disclosure and preserving the utility of the dataset.
Nonetheless, modern NER has mixed recall of <math alttext="97\%" class="ltx_Math" display="inline" id="S5.SS1.p1.1.m1.1"><semantics id="S5.SS1.p1.1.m1.1a"><mrow id="S5.SS1.p1.1.m1.1.1" xref="S5.SS1.p1.1.m1.1.1.cmml"><mn id="S5.SS1.p1.1.m1.1.1.2" xref="S5.SS1.p1.1.m1.1.1.2.cmml">97</mn><mo id="S5.SS1.p1.1.m1.1.1.1" xref="S5.SS1.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.1.m1.1b"><apply id="S5.SS1.p1.1.m1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1"><csymbol cd="latexml" id="S5.SS1.p1.1.m1.1.1.1.cmml" xref="S5.SS1.p1.1.m1.1.1.1">percent</csymbol><cn id="S5.SS1.p1.1.m1.1.1.2.cmml" type="integer" xref="S5.SS1.p1.1.m1.1.1.2">97</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.1.m1.1c">97\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.1.m1.1d">97 %</annotation></semantics></math> for names and <math alttext="80\%" class="ltx_Math" display="inline" id="S5.SS1.p1.2.m2.1"><semantics id="S5.SS1.p1.2.m2.1a"><mrow id="S5.SS1.p1.2.m2.1.1" xref="S5.SS1.p1.2.m2.1.1.cmml"><mn id="S5.SS1.p1.2.m2.1.1.2" xref="S5.SS1.p1.2.m2.1.1.2.cmml">80</mn><mo id="S5.SS1.p1.2.m2.1.1.1" xref="S5.SS1.p1.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S5.SS1.p1.2.m2.1b"><apply id="S5.SS1.p1.2.m2.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1"><csymbol cd="latexml" id="S5.SS1.p1.2.m2.1.1.1.cmml" xref="S5.SS1.p1.2.m2.1.1.1">percent</csymbol><cn id="S5.SS1.p1.2.m2.1.1.2.cmml" type="integer" xref="S5.SS1.p1.2.m2.1.1.2">80</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS1.p1.2.m2.1c">80\%</annotation><annotation encoding="application/x-llamapun" id="S5.SS1.p1.2.m2.1d">80 %</annotation></semantics></math> for care unit numbers on medical data <cite class="ltx_cite ltx_citemacro_cite">Vakili et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib59" title="">2022</a>); Lukas et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib39" title="">2023</a>)</cite>, indicating that many PIIs are still retained after scrubbing.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Why not DP-SGD only</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">Fine-tuning models to satisfies DP can only address the risk of memorization. There is no protection during the data collection stage where the user instructions are exposed to human annotators for response generation <cite class="ltx_cite ltx_citemacro_cite">Yu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib73" title="">2024</a>)</cite>.
Moreover, using DP-SGD to prevent memorization by adding noise into the training process is destined to sacrifice performance.
As proved in our experiments in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A3.T11" title="Table 11 ‣ C.2 DP-SGD Performance Evaluation ‣ Appendix C Additional Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">11</span></a>, employing DP-SGD alone leads to considerable performance drop.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusions</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">This paper addresses the challenge of preserving privacy while fine-tuning large language models on sensitive data. To improve the quality of synthetic data, an aspect often overlooked in previous works, we introduce a novel client-server framework called <span class="ltx_text ltx_font_italic" id="S6.p1.1.1">KnowledgeSG</span>. Specifically, <span class="ltx_text ltx_font_italic" id="S6.p1.1.2">KnowledgeSG</span> leverages knowledge distillation from a professional server, by prompting it to provide judgments and corrections for raw synthetic data generated by the DP-finetuned base model. Inspired by federated learning, <span class="ltx_text ltx_font_italic" id="S6.p1.1.3">KnowledgeSG</span> transmits models rather than data through a specially designed transmitting unit to ensure privacy.
We conduct extensive experiments, and the results validate the effectiveness of <span class="ltx_text ltx_font_italic" id="S6.p1.1.4">KnowledgeSG</span>. The framework achieves a relative improvement of <math alttext="120.39\%" class="ltx_Math" display="inline" id="S6.p1.1.m1.1"><semantics id="S6.p1.1.m1.1a"><mrow id="S6.p1.1.m1.1.1" xref="S6.p1.1.m1.1.1.cmml"><mn id="S6.p1.1.m1.1.1.2" xref="S6.p1.1.m1.1.1.2.cmml">120.39</mn><mo id="S6.p1.1.m1.1.1.1" xref="S6.p1.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.p1.1.m1.1b"><apply id="S6.p1.1.m1.1.1.cmml" xref="S6.p1.1.m1.1.1"><csymbol cd="latexml" id="S6.p1.1.m1.1.1.1.cmml" xref="S6.p1.1.m1.1.1.1">percent</csymbol><cn id="S6.p1.1.m1.1.1.2.cmml" type="float" xref="S6.p1.1.m1.1.1.2">120.39</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.m1.1c">120.39\%</annotation><annotation encoding="application/x-llamapun" id="S6.p1.1.m1.1d">120.39 %</annotation></semantics></math> compared to the Non-Private training, as measured by medical free-form evaluation. Additionally, <span class="ltx_text ltx_font_italic" id="S6.p1.1.5">KnowledgeSG</span> significantly reduces the reconstruction rate from 97.13 to 0.87, demonstrating its strong privacy-preserving capabilities.</p>
</div>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Limitations</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">While <span class="ltx_text ltx_font_italic" id="S7.p1.1.1">KnowledgeSG</span> offers best privacy and performance trade-off across various domain-specific scenarios, its effectiveness on general tasks remains to be fully explored. Further experiments are needed to test its generalizability in broader contexts.</p>
</div>
<div class="ltx_para" id="S7.p2">
<p class="ltx_p" id="S7.p2.1">Also, <span class="ltx_text ltx_font_italic" id="S7.p2.1.1">KnowledgeSG</span> involves more communication and computation cost than Non-Private fine-tuning, as it requires DP-finetuning the base model and leveraging a professional model for knowledge distillation. However, we believe these costs are justified, given the significant reduction in memorization concerns and the substantial performance improvements.</p>
</div>
<div class="ltx_para" id="S7.p3">
<p class="ltx_p" id="S7.p3.1">For future directions, we plan to conduct experiments on more general tasks and seek ways to optimize communication and computation costs. Additionally, we aim to make the deployment of <span class="ltx_text ltx_font_italic" id="S7.p3.1.1">KnowledgeSG</span> more compatible and lightweight.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">This research is supported by the National Key R&amp;D Program of China under Grant 2021ZD0112801, NSFC under Grant 62171276 and the Science and Technology Commission of Shanghai Municipal under Grant 21511100900 and 22DZ2229005.
We are grateful to Yifei Zhang, Changyu Miu, Huiyao Chen and Mengying Yuan, for their valuable discussions as well as feedback on the manuscript. We also thank TruthAI, for its GPU support.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abadi et al. (2016)</span>
<span class="ltx_bibblock">
Martin Abadi, Andy Chu, Ian Goodfellow, H. Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. 2016.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/2976749.2978318" title="">Deep learning with differential privacy</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security</em>, CCS’16. ACM.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Akbik et al. (2018)</span>
<span class="ltx_bibblock">
Alan Akbik, Duncan Blythe, and Roland Vollgraf. 2018.

</span>
<span class="ltx_bibblock">Contextual string embeddings for sequence labeling.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">COLING 2018, 27th International Conference on Computational Linguistics</em>, pages 1638–1649.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arnold and Neunhoeffer (2021)</span>
<span class="ltx_bibblock">
Christian Arnold and Marcel Neunhoeffer. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2004.07740" title="">Really useful synthetic data – a framework to evaluate the quality of differentially private synthetic data</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Preprint</em>, arXiv:2004.07740.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ben Allal et al. (2022)</span>
<span class="ltx_bibblock">
Loubna Ben Allal, Niklas Muennighoff, Logesh Kumar Umapathi, Ben Lipkin, and Leandro von Werra. 2022.

</span>
<span class="ltx_bibblock">A framework for the evaluation of code generation models.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/bigcode-project/bigcode-evaluation-harness" title="">https://github.com/bigcode-project/bigcode-evaluation-harness</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. (2022)</span>
<span class="ltx_bibblock">
Hannah Brown, Katherine Lee, Fatemehsadat Mireshghallah, Reza Shokri, and Florian Tramèr. 2022.

</span>
<span class="ltx_bibblock">What does it mean for a language model to preserve privacy?

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the 2022 ACM Conference on Fairness, Accountability, and Transparency</em>, pages 2280–2292.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carlini et al. (2021)</span>
<span class="ltx_bibblock">
Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Ulfar Erlingsson, Alina Oprea, and Colin Raffel. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2012.07805" title="">Extracting training data from large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">Preprint</em>, arXiv:2012.07805.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chaudhary (2023)</span>
<span class="ltx_bibblock">
Sahil Chaudhary. 2023.

</span>
<span class="ltx_bibblock">Code alpaca: An instruction-following llama model for code generation.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/sahil280114/codealpaca" title="">https://github.com/sahil280114/codealpaca</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2024)</span>
<span class="ltx_bibblock">
Huiyao Chen, Yu Zhao, Zulong Chen, Mengjia Wang, Liangyue Li, Meishan Zhang, and Min Zhang. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2406.17534" title="">Retrieval-style in-context learning for few-shot hierarchical text classification</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">Preprint</em>, arXiv:2406.17534.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2021)</span>
<span class="ltx_bibblock">
Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2107.03374" title="">Evaluating large language models trained on code</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chiang et al. (2024)</span>
<span class="ltx_bibblock">
Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios Nikolas Angelopoulos, Tianle Li, Dacheng Li, Hao Zhang, Banghua Zhu, Michael Jordan, Joseph E. Gonzalez, and Ion Stoica. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2403.04132" title="">Chatbot arena: An open platform for evaluating llms by human preference</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Preprint</em>, arXiv:2403.04132.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cobbe et al. (2021)</span>
<span class="ltx_bibblock">
Karl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser, Matthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, Christopher Hesse, and John Schulman. 2021.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2110.14168" title="">Training verifiers to solve math word problems</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Preprint</em>, arXiv:2110.14168.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Conover et al. (2023)</span>
<span class="ltx_bibblock">
Mike Conover, Matt Hayes, Ankit Mathur, Jianwei Xie, Jun Wan, Sam Shah, Ali Ghodsi, Patrick Wendell, Matei Zaharia, and Reynold Xin. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://www.databricks.com/blog/2023/04/12/dolly-first-open-commercially-viable-instruction-tuned-llm" title="">Free dolly: Introducing the world’s first truly open instruction-tuned llm</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Diao et al. (2023)</span>
<span class="ltx_bibblock">
Shizhe Diao, Rui Pan, Hanze Dong, Ka Shun Shum, Jipeng Zhang, Wei Xiong, and Tong Zhang. 2023.

</span>
<span class="ltx_bibblock">Lmflow: An extensible toolkit for finetuning and inference of large foundation models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:2306.12420</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dong et al. (2022)</span>
<span class="ltx_bibblock">
Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Zhiyong Wu, Baobao Chang, Xu Sun, Jingjing Xu, and Zhifang Sui. 2022.

</span>
<span class="ltx_bibblock">A survey for in-context learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2301.00234</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et al. (2022)</span>
<span class="ltx_bibblock">
Zhengxiao Du, Yujie Qian, Xiao Liu, Ming Ding, Jiezhong Qiu, Zhilin Yang, and Jie Tang. 2022.

</span>
<span class="ltx_bibblock">Glm: General language model pretraining with autoregressive blank infilling.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 320–335.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork and Roth (2014)</span>
<span class="ltx_bibblock">
Cynthia Dwork and Aaron Roth. 2014.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:207178262" title="">The algorithmic foundations of differential privacy</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Found. Trends Theor. Comput. Sci.</em>, 9:211–407.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Flemings and Annavaram (2024)</span>
<span class="ltx_bibblock">
James Flemings and Murali Annavaram. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2403.00932" title="">Differentially private knowledge distillation via synthetic text generation</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Preprint</em>, arXiv:2403.00932.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gupta et al. (2022)</span>
<span class="ltx_bibblock">
Samyak Gupta, Yangsibo Huang, Zexuan Zhong, Tianyu Gao, Kai Li, and Danqi Chen. 2022.

</span>
<span class="ltx_bibblock">Recovering Private Text in Federated Learning of Language Models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Advances in Neural Information Processing Systems</em>, 35:8130–8143.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et al. (2021a)</span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song, and Jacob Steinhardt. 2021a.

</span>
<span class="ltx_bibblock">Measuring massive multitask language understanding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Proceedings of the International Conference on Learning Representations (ICLR)</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hendrycks et al. (2021b)</span>
<span class="ltx_bibblock">
Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. 2021b.

</span>
<span class="ltx_bibblock">Measuring mathematical problem solving with the math dataset.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">NeurIPS</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Heusel et al. (2018)</span>
<span class="ltx_bibblock">
Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/1706.08500" title="">Gans trained by a two time-scale update rule converge to a local nash equilibrium</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">Preprint</em>, arXiv:1706.08500.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al. (2021)</span>
<span class="ltx_bibblock">
Edward J Hu, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, Weizhu Chen, et al. 2021.

</span>
<span class="ltx_bibblock">Lora: Low-rank adaptation of large language models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">ICLR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Igamberdiev et al. (2022)</span>
<span class="ltx_bibblock">
Timour Igamberdiev, Thomas Arnold, and Ivan Habernal. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://aclanthology.org/2022.coling-1.258" title="">DP-rewrite: Towards reproducibility and transparency in differentially private text rewriting</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Proceedings of the 29th International Conference on Computational Linguistics</em>, pages 2927–2933, Gyeongju, Republic of Korea. International Committee on Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jang et al. (2023)</span>
<span class="ltx_bibblock">
Joel Jang, Seungone Kim, Seonghyeon Ye, Doyoung Kim, Lajanugen Logeswaran, Moontae Lee, Kyungjae Lee, and Minjoon Seo. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.mlr.press/v202/jang23a.html" title="">Exploring the benefits of training expert language models over instruction tuning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">Proceedings of the 40th International Conference on Machine Learning</em>, volume 202 of <em class="ltx_emph ltx_font_italic" id="bib.bib24.2.2">Proceedings of Machine Learning Research</em>, pages 14702–14729. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2023)</span>
<span class="ltx_bibblock">
Yuxin Jiang, Chunkit Chan, Mingyang Chen, and Wei Wang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2305.12870" title="">Lion: Adversarial distillation of proprietary large language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Preprint</em>, arXiv:2305.12870.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin et al. (2021)</span>
<span class="ltx_bibblock">
Di Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi Fang, and Peter Szolovits. 2021.

</span>
<span class="ltx_bibblock">What disease does this patient have? a large-scale open domain question answering dataset from medical exams.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">Applied Sciences</em>, 11(14):6421.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jin et al. (2019)</span>
<span class="ltx_bibblock">
Qiao Jin, Bhuwan Dhingra, Zhengping Liu, William Cohen, and Xinghua Lu. 2019.

</span>
<span class="ltx_bibblock">Pubmedqa: A dataset for biomedical research question answering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</em>, pages 2567–2577.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jordon et al. (2022)</span>
<span class="ltx_bibblock">
James Jordon, Lukasz Szpruch, Florimond Houssiau, Mirko Bottarelli, Giovanni Cherubin, Carsten Maple, Samuel N. Cohen, and Adrian Weller. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2205.03257" title="">Synthetic data – what, why and how?</a>
</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Preprint</em>, arXiv:2205.03257.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kandpal et al. (2023)</span>
<span class="ltx_bibblock">
Nikhil Kandpal, Krishna Pillutla, Alina Oprea, Peter Kairouz, Christopher A. Choquette-Choo, and Zheng Xu. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2310.09266" title="">User Inference Attacks on Large Language Models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib29.1.1">Preprint</em>, arxiv:2310.09266.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kurakin et al. (2024)</span>
<span class="ltx_bibblock">
Alexey Kurakin, Natalia Ponomareva, Umar Syed, Liam MacDermed, and Andreas Terzis. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2306.01684" title="">Harnessing large-language models to generate private synthetic text</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Preprint</em>, arxiv:2306.01684.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kwon et al. (2023)</span>
<span class="ltx_bibblock">
Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gonzalez, Hao Zhang, and Ion Stoica. 2023.

</span>
<span class="ltx_bibblock">Efficient memory management for large language model serving with pagedattention.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2024a)</span>
<span class="ltx_bibblock">
Haoran Li, Qingxiu Dong, Zhengyang Tang, Chaojun Wang, Xingxing Zhang, Haoyang Huang, Shaohan Huang, Xiaolong Huang, Zeqiang Huang, Dongdong Zhang, Yuxian Gu, Xin Cheng, Xun Wang, Si-Qing Chen, Li Dong, Wei Lu, Zhifang Sui, Benyou Wang, Wai Lam, and Furu Wei. 2024a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2402.13064" title="">Synthetic Data (Almost) from Scratch: Generalized Instruction Tuning for Language Models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib32.1.1">Preprint</em>, arxiv:2402.13064.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2024b)</span>
<span class="ltx_bibblock">
Ming Li, Yong Zhang, Shwai He, Zhitao Li, Hongyu Zhao, Jianzong Wang, Ning Cheng, and Tianyi Zhou. 2024b.

</span>
<span class="ltx_bibblock">Superfiltering: Weak-to-strong data filtering for fast instruction-tuning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib33.1.1">arXiv preprint arXiv:2402.00530</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023a)</span>
<span class="ltx_bibblock">
Ming Li, Yong Zhang, Zhitao Li, Jiuhai Chen, Lichang Chen, Ning Cheng, Jianzong Wang, Tianyi Zhou, and Jing Xiao. 2023a.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:261076515" title="">From quantity to quality: Boosting llm performance with self-guided data selection for instruction tuning</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib34.1.1">ArXiv</em>, abs/2308.12032.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023b)</span>
<span class="ltx_bibblock">
Xuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori, Ishaan Gulrajani, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023b.

</span>
<span class="ltx_bibblock">Alpacaeval: An automatic evaluator of instruction-following models.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/tatsu-lab/alpaca_eval" title="">https://github.com/tatsu-lab/alpaca_eval</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023c)</span>
<span class="ltx_bibblock">
Yunxiang Li, Zihan Li, Kai Zhang, Ruilong Dan, Steve Jiang, and You Zhang. 2023c.

</span>
<span class="ltx_bibblock">Chatdoctor: A medical chat model fine-tuned on a large language model meta-ai (llama) using medical domain knowledge.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib36.1.1">Cureus</em>, 15(6).

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2021)</span>
<span class="ltx_bibblock">
Lang Liu, Krishna Pillutla, Sean Welleck, Sewoong Oh, Yejin Choi, and Zaid Harchaoui. 2021.

</span>
<span class="ltx_bibblock">Divergence Frontiers for Generative Models: Sample Complexity, Quantization Effects, and Frontier Integrals.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">NeurIPS</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Loshchilov and Hutter (2018)</span>
<span class="ltx_bibblock">
Ilya Loshchilov and Frank Hutter. 2018.

</span>
<span class="ltx_bibblock">Decoupled weight decay regularization.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib38.1.1">International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lukas et al. (2023)</span>
<span class="ltx_bibblock">
Nils Lukas, Ahmed Salem, Robert Sim, Shruti Tople, Lukas Wutschitz, and Santiago Zanella-Béguelin. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1109/SP46215.2023.00154" title="">Analyzing Leakage of Personally Identifiable Information in Language Models</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">2023 IEEE Symposium on Security and Privacy (SP)</em>, pages 346–363. IEEE Computer Society.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo et al. (2023)</span>
<span class="ltx_bibblock">
Ziyang Luo, Can Xu, Pu Zhao, Qingfeng Sun, Xiubo Geng, Wenxiang Hu, Chongyang Tao, Jing Ma, Qingwei Lin, and Daxin Jiang. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2306.08568" title="">Wizardcoder: Empowering code large language models with evol-instruct</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">Preprint</em>, arXiv:2306.08568.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Magic (2022)</span>
<span class="ltx_bibblock">
Neural Magic. 2022.

</span>
<span class="ltx_bibblock">Twitter financial news sentiment.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/datasets/zeroshot/twitter-financial-news-sentiment" title="">https://huggingface.co/datasets/zeroshot/twitter-financial-news-sentiment</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maia et al. (2018)</span>
<span class="ltx_bibblock">
Macedo Maia, Siegfried Handschuh, André Freitas, Brian Davis, Ross McDermott, Manel Zarrouk, and Alexandra Balahur. 2018.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:13866508" title="">Www’18 open challenge: Financial opinion mining and question answering</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Companion Proceedings of the The Web Conference 2018</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib43">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Malo et al. (2014)</span>
<span class="ltx_bibblock">
P. Malo, A. Sinha, P. Korhonen, J. Wallenius, and P. Takala. 2014.

</span>
<span class="ltx_bibblock">Good debt or bad debt: Detecting semantic orientations in economic texts.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib43.1.1">Journal of the Association for Information Science and Technology</em>, 65.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib44">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. (2017)</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas. 2017.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized data.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib44.1.1">Artificial intelligence and statistics</em>, pages 1273–1282. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib45">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nakamura et al. (2020)</span>
<span class="ltx_bibblock">
Yuta Nakamura, Shouhei Hanaoka, Yukihiro Nomura, Naoto Hayashi, Osamu Abe, Shuntaro Yada, Shoko Wakamiya, and Eiji Aramaki. 2020.

</span>
<span class="ltx_bibblock">Kart: Privacy leakage framework of language models pre-trained with clinical records.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib45.1.1">arXiv preprint arXiv:2101.00036</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib46">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nasr et al. (2023)</span>
<span class="ltx_bibblock">
Milad Nasr, Nicholas Carlini, Jonathan Hayase, Matthew Jagielski, A. Feder Cooper, Daphne Ippolito, Christopher A. Choquette-Choo, Eric Wallace, Florian Tramèr, and Katherine Lee. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2311.17035" title="">Scalable Extraction of Training Data from (Production) Language Models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib46.1.1">Preprint</em>, arxiv:2311.17035.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib47">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2023)</span>
<span class="ltx_bibblock">
OpenAI. 2023.

</span>
<span class="ltx_bibblock">Gpt-4 technical report.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib47.1.1">arXiv preprint arXiv:2303.08774</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib48">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang et al. (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib48.1.1">NIPS</em>, 35:27730–27744.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib49">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pal et al. (2022)</span>
<span class="ltx_bibblock">
Ankit Pal, Logesh Kumar Umapathi, and Malaikannan Sankarasubbu. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://proceedings.mlr.press/v174/pal22a.html" title="">Medmcqa: A large-scale multi-subject multi-choice dataset for medical domain question answering</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib49.1.1">Proceedings of the Conference on Health, Inference, and Learning</em>, volume 174 of <em class="ltx_emph ltx_font_italic" id="bib.bib49.2.2">Proceedings of Machine Learning Research</em>, pages 248–260. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib50">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et al. (2002)</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei jing Zhu. 2002.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.3115/1073083.1073135" title="">Bleu: a method for automatic evaluation of machine translation</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib50.1.1">Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics</em>, pages 311–318, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib51">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Peng et al. (2023)</span>
<span class="ltx_bibblock">
Baolin Peng, Chunyuan Li, Pengcheng He, Michel Galley, and Jianfeng Gao. 2023.

</span>
<span class="ltx_bibblock">Instruction tuning with gpt-4.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib51.1.1">arXiv preprint arXiv:2304.03277</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib52">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pillutla et al. (2023)</span>
<span class="ltx_bibblock">
Krishna Pillutla, Lang Liu, John Thickstun, Sean Welleck, Swabha Swayamdipta, Rowan Zellers, Sewoong Oh, Yejin Choi, and Zaid Harchaoui. 2023.

</span>
<span class="ltx_bibblock">MAUVE Scores for Generative Models: Theory and Practice.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib52.1.1">JMLR</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib53">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pillutla et al. (2021)</span>
<span class="ltx_bibblock">
Krishna Pillutla, Swabha Swayamdipta, Rowan Zellers, John Thickstun, Sean Welleck, Yejin Choi, and Zaid Harchaoui. 2021.

</span>
<span class="ltx_bibblock">Mauve: Measuring the gap between neural text and human text using divergence frontiers.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib53.1.1">NeurIPS</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib54">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reimers and Gurevych (2019)</span>
<span class="ltx_bibblock">
Nils Reimers and Iryna Gurevych. 2019.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/1908.10084" title="">Sentence-bert: Sentence embeddings using siamese bert-networks</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib54.1.1">Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing</em>. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib55">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singhal et al. (2023)</span>
<span class="ltx_bibblock">
Karan Singhal, Shekoofeh Azizi, Tao Tu, S Sara Mahdavi, Jason Wei, Hyung Won Chung, Nathan Scales, Ajay Tanwani, Heather Cole-Lewis, Stephen Pfohl, et al. 2023.

</span>
<span class="ltx_bibblock">Large language models encode clinical knowledge.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib55.1.1">Nature</em>, 620(7972):172–180.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib56">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Taori et al. (2023)</span>
<span class="ltx_bibblock">
Rohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, and Tatsunori B. Hashimoto. 2023.

</span>
<span class="ltx_bibblock">Stanford alpaca: An instruction-following llama model.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/tatsu-lab/stanford_alpaca" title="">https://github.com/tatsu-lab/stanford_alpaca</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib57">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023a)</span>
<span class="ltx_bibblock">
Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, et al. 2023a.

</span>
<span class="ltx_bibblock">Llama: Open and efficient foundation language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib57.1.1">arXiv preprint arXiv:2302.13971</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib58">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023b)</span>
<span class="ltx_bibblock">
Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. 2023b.

</span>
<span class="ltx_bibblock">Llama 2: Open foundation and fine-tuned chat models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib58.1.1">arXiv preprint arXiv:2307.09288</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib59">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vakili et al. (2022)</span>
<span class="ltx_bibblock">
Thomas Vakili, Anastasios Lamproudis, Aron Henriksson, and Hercules Dalianis. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://api.semanticscholar.org/CorpusID:251880789" title="">Downstream task performance of bert models pre-trained using automatically de-identified clinical data</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib59.1.1">International Conference on Language Resources and Evaluation</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib60">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023)</span>
<span class="ltx_bibblock">
Yizhong Wang, Hamish Ivison, Pradeep Dasigi, Jack Hessel, Tushar Khot, Khyathi Raghavi Chandu, David Wadden, Kelsey MacMillan, Noah A Smith, Iz Beltagy, et al. 2023.

</span>
<span class="ltx_bibblock">How far can camels go? exploring the state of instruction tuning on open resources.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib60.1.1">arXiv preprint arXiv:2306.04751</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib61">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2022)</span>
<span class="ltx_bibblock">
Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, and Hannaneh Hajishirzi. 2022.

</span>
<span class="ltx_bibblock">Self-instruct: Aligning language model with self generated instructions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib61.1.1">arXiv preprint arXiv:2212.10560</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib62">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2020)</span>
<span class="ltx_bibblock">
Kang Wei, Jun Li, Ming Ding, Chuan Ma, Howard H Yang, Farhad Farokhi, Shi Jin, Tony QS Quek, and H Vincent Poor. 2020.

</span>
<span class="ltx_bibblock">Federated learning with differential privacy: Algorithms and performance analysis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib62.1.1">IEEE Transactions on Information Forensics and Security</em>, 15:3454–3469.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib63">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2023)</span>
<span class="ltx_bibblock">
Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon Mann. 2023.

</span>
<span class="ltx_bibblock">Bloomberggpt: A large language model for finance.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib63.1.1">arXiv preprint arXiv:2303.17564</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib64">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wutschitz et al. (2022)</span>
<span class="ltx_bibblock">
Lukas Wutschitz, Huseyin A. Inan, and Andre Manoel. 2022.

</span>
<span class="ltx_bibblock">dp-transformers: Training transformer models with differential privacy.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.microsoft.com/en-us/research/project/dp-transformers" title="">https://www.microsoft.com/en-us/research/project/dp-transformers</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib65">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al. (2024)</span>
<span class="ltx_bibblock">
Chulin Xie, Zinan Lin, Arturs Backurs, Sivakanth Gopi, Da Yu, Huseyin A. Inan, Harsha Nori, Haotian Jiang, Huishuai Zhang, Yin Tat Lee, Bo Li, and Sergey Yekhanin. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2403.01749" title="">Differentially Private Synthetic Data via Foundation Model APIs 2: Text</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib65.1.1">Preprint</em>, arxiv:2403.01749.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib66">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al. (2023)</span>
<span class="ltx_bibblock">
Can Xu, Qingfeng Sun, Kai Zheng, Xiubo Geng, Pu Zhao, Jiazhan Feng, Chongyang Tao, and Daxin Jiang. 2023.

</span>
<span class="ltx_bibblock">Wizardlm: Empowering large language models to follow complex instructions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib66.1.1">arXiv preprint arXiv:2304.12244</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib67">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xue et al. (2023)</span>
<span class="ltx_bibblock">
Siqiao Xue, Caigao Jiang, Wenhui Shi, Fangyin Cheng, Keting Chen, Hongjun Yang, Zhiping Zhang, Jianshan He, Hongyang Zhang, Ganglin Wei, et al. 2023.

</span>
<span class="ltx_bibblock">Db-gpt: Empowering database interactions with private large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib67.1.1">arXiv preprint arXiv:2312.17449</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib68">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang (2023)</span>
<span class="ltx_bibblock">
Hongyang Yang. 2023.

</span>
<span class="ltx_bibblock">Data-centric fingpt. open-source for open finance.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/AI4Finance-Foundation/FinGPT" title="">https://github.com/AI4Finance-Foundation/FinGPT</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib69">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al. (2023)</span>
<span class="ltx_bibblock">
Hongyang Yang, Xiao-Yang Liu, and Christina Dan Wang. 2023.

</span>
<span class="ltx_bibblock">Fingpt: Open-source financial large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib69.1.1">FinLLM Symposium at IJCAI 2023</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib70">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al. (2024a)</span>
<span class="ltx_bibblock">
Rui Ye, Rui Ge, Yuchi Fengting, Jingyi Chai, Yanfeng Wang, and Siheng Chen. 2024a.

</span>
<span class="ltx_bibblock">Leveraging unstructured text data for federated instruction tuning of large language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib70.1.1">arXiv preprint arXiv:2409.07136</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib71">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al. (2024b)</span>
<span class="ltx_bibblock">
Rui Ye, WenHao Wang, Jingyi Chai, Dihan Li, Zexi Li, Yinda Xu, Yaxin Du, Yanfeng Wang, and Siheng Chen. 2024b.

</span>
<span class="ltx_bibblock">OpenFedLLM: Training Large Language Models on Decentralized Private Data via Federated Learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib71.1.1">ICLR 2024 Workshop on Navigating and Addressing Data Problems for Foundation Models</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib72">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yousefpour et al. (2021)</span>
<span class="ltx_bibblock">
Ashkan Yousefpour, Igor Shilov, Alexandre Sablayrolles, Davide Testuggine, Karthik Prasad, Mani Malek, John Nguyen, Sayan Ghosh, Akash Bharadwaj, Jessica Zhao, Graham Cormode, and Ilya Mironov. 2021.

</span>
<span class="ltx_bibblock">Opacus: User-friendly differential privacy library in PyTorch.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib72.1.1">arXiv preprint arXiv:2109.12298</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib73">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2024)</span>
<span class="ltx_bibblock">
Da Yu, Peter Kairouz, Sewoong Oh, and Zheng Xu. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2402.13659" title="">Privacy-Preserving Instructions for Aligning Large Language Models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib73.1.1">Preprint</em>, arxiv:2402.13659.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib74">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2022)</span>
<span class="ltx_bibblock">
Da Yu, Saurabh Naik, Arturs Backurs, Sivakanth Gopi, Huseyin A. Inan, Gautam Kamath, Janardhan Kulkarni, Yin Tat Lee, Andre Manoel, Lukas Wutschitz, Sergey Yekhanin, and Huishuai Zhang. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.48550/arXiv.2110.06500" title="">Differentially Private Fine-tuning of Language Models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib74.1.1">Preprint</em>, arxiv:2110.06500.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib75">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yue et al. (2023)</span>
<span class="ltx_bibblock">
Xiang Yue, Huseyin Inan, Xuechen Li, Girish Kumar, Julia McAnallen, Hoda Shajari, Huan Sun, David Levitan, and Robert Sim. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.18653/v1/2023.acl-long.74" title="">Synthetic Text Generation with Differential Privacy: A Simple and Practical Recipe</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib75.1.1">Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</em>, pages 1321–1342, Toronto, Canada. Association for Computational Linguistics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib76">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yue et al. (2024)</span>
<span class="ltx_bibblock">
Xiang Yue, Xingwei Qu, Ge Zhang, Yao Fu, Wenhao Huang, Huan Sun, Yu Su, and Wenhu Chen. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://openreview.net/forum?id=yLClGs770I" title="">MAmmoTH: Building math generalist models through hybrid instruction tuning</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib76.1.1">The Twelfth International Conference on Learning Representations</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib77">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023)</span>
<span class="ltx_bibblock">
Xinlu Zhang, Chenxin Tian, Xianjun Yang, Lichang Chen, Zekun Li, and Linda Ruth Petzold. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2310.14558" title="">Alpacare:instruction-tuned large language models for medical application</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib77.1.1">Preprint</em>, arXiv:2310.14558.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib78">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2024)</span>
<span class="ltx_bibblock">
Zhuo Zhang, Jingyuan Zhang, Jintao Huang, Lizhen Qu, Hongzhi Zhang, and Zenglin Xu. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2403.06131" title="">FedPIT: Towards Privacy-preserving and Few-shot Federated Instruction Tuning</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib78.1.1">Preprint</em>, arxiv:2403.06131.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib79">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. (2024)</span>
<span class="ltx_bibblock">
Wenting Zhao, Xiang Ren, Jack Hessel, Claire Cardie, Yejin Choi, and Yuntian Deng. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2405.01470" title="">Wildchat: 1m chatgpt interaction logs in the wild</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib79.1.1">Preprint</em>, arXiv:2405.01470.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib80">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al. (2023)</span>
<span class="ltx_bibblock">
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang, Joseph E. Gonzalez, and Ion Stoica. 2023.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2306.05685" title="">Judging llm-as-a-judge with mt-bench and chatbot arena</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib80.1.1">Preprint</em>, arXiv:2306.05685.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib81">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou et al. (2024)</span>
<span class="ltx_bibblock">
Zhi Zhou, Jiang-Xin Shi, Peng-Xiao Song, Xiao-Wen Yang, Yi-Xuan Jin, Lan-Zhe Guo, and Yu-Feng Li. 2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2406.04614" title="">Lawgpt: A chinese legal knowledge-enhanced large language model</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib81.1.1">Preprint</em>, arXiv:2406.04614.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Privacy Analysis</h2>
<section class="ltx_subsection" id="A1.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Potential Privacy Risks</h3>
<div class="ltx_para" id="A1.SS1.p1">
<p class="ltx_p" id="A1.SS1.p1.6">There is a potential privacy concern that the base model may have already encountered the private dataset <math alttext="\mathbb{D}_{Pri}" class="ltx_Math" display="inline" id="A1.SS1.p1.1.m1.1"><semantics id="A1.SS1.p1.1.m1.1a"><msub id="A1.SS1.p1.1.m1.1.1" xref="A1.SS1.p1.1.m1.1.1.cmml"><mi id="A1.SS1.p1.1.m1.1.1.2" xref="A1.SS1.p1.1.m1.1.1.2.cmml">𝔻</mi><mrow id="A1.SS1.p1.1.m1.1.1.3" xref="A1.SS1.p1.1.m1.1.1.3.cmml"><mi id="A1.SS1.p1.1.m1.1.1.3.2" xref="A1.SS1.p1.1.m1.1.1.3.2.cmml">P</mi><mo id="A1.SS1.p1.1.m1.1.1.3.1" xref="A1.SS1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A1.SS1.p1.1.m1.1.1.3.3" xref="A1.SS1.p1.1.m1.1.1.3.3.cmml">r</mi><mo id="A1.SS1.p1.1.m1.1.1.3.1a" xref="A1.SS1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A1.SS1.p1.1.m1.1.1.3.4" xref="A1.SS1.p1.1.m1.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.1.m1.1b"><apply id="A1.SS1.p1.1.m1.1.1.cmml" xref="A1.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS1.p1.1.m1.1.1.1.cmml" xref="A1.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="A1.SS1.p1.1.m1.1.1.2.cmml" xref="A1.SS1.p1.1.m1.1.1.2">𝔻</ci><apply id="A1.SS1.p1.1.m1.1.1.3.cmml" xref="A1.SS1.p1.1.m1.1.1.3"><times id="A1.SS1.p1.1.m1.1.1.3.1.cmml" xref="A1.SS1.p1.1.m1.1.1.3.1"></times><ci id="A1.SS1.p1.1.m1.1.1.3.2.cmml" xref="A1.SS1.p1.1.m1.1.1.3.2">𝑃</ci><ci id="A1.SS1.p1.1.m1.1.1.3.3.cmml" xref="A1.SS1.p1.1.m1.1.1.3.3">𝑟</ci><ci id="A1.SS1.p1.1.m1.1.1.3.4.cmml" xref="A1.SS1.p1.1.m1.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.1.m1.1c">\mathbb{D}_{Pri}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.1.m1.1d">blackboard_D start_POSTSUBSCRIPT italic_P italic_r italic_i end_POSTSUBSCRIPT</annotation></semantics></math> during pre-training. If this is the case, synthetic data generated by the base model <math alttext="\mathbb{W}_{Loc}" class="ltx_Math" display="inline" id="A1.SS1.p1.2.m2.1"><semantics id="A1.SS1.p1.2.m2.1a"><msub id="A1.SS1.p1.2.m2.1.1" xref="A1.SS1.p1.2.m2.1.1.cmml"><mi id="A1.SS1.p1.2.m2.1.1.2" xref="A1.SS1.p1.2.m2.1.1.2.cmml">𝕎</mi><mrow id="A1.SS1.p1.2.m2.1.1.3" xref="A1.SS1.p1.2.m2.1.1.3.cmml"><mi id="A1.SS1.p1.2.m2.1.1.3.2" xref="A1.SS1.p1.2.m2.1.1.3.2.cmml">L</mi><mo id="A1.SS1.p1.2.m2.1.1.3.1" xref="A1.SS1.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="A1.SS1.p1.2.m2.1.1.3.3" xref="A1.SS1.p1.2.m2.1.1.3.3.cmml">o</mi><mo id="A1.SS1.p1.2.m2.1.1.3.1a" xref="A1.SS1.p1.2.m2.1.1.3.1.cmml">⁢</mo><mi id="A1.SS1.p1.2.m2.1.1.3.4" xref="A1.SS1.p1.2.m2.1.1.3.4.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.2.m2.1b"><apply id="A1.SS1.p1.2.m2.1.1.cmml" xref="A1.SS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A1.SS1.p1.2.m2.1.1.1.cmml" xref="A1.SS1.p1.2.m2.1.1">subscript</csymbol><ci id="A1.SS1.p1.2.m2.1.1.2.cmml" xref="A1.SS1.p1.2.m2.1.1.2">𝕎</ci><apply id="A1.SS1.p1.2.m2.1.1.3.cmml" xref="A1.SS1.p1.2.m2.1.1.3"><times id="A1.SS1.p1.2.m2.1.1.3.1.cmml" xref="A1.SS1.p1.2.m2.1.1.3.1"></times><ci id="A1.SS1.p1.2.m2.1.1.3.2.cmml" xref="A1.SS1.p1.2.m2.1.1.3.2">𝐿</ci><ci id="A1.SS1.p1.2.m2.1.1.3.3.cmml" xref="A1.SS1.p1.2.m2.1.1.3.3">𝑜</ci><ci id="A1.SS1.p1.2.m2.1.1.3.4.cmml" xref="A1.SS1.p1.2.m2.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.2.m2.1c">\mathbb{W}_{Loc}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.2.m2.1d">blackboard_W start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT</annotation></semantics></math> or its DP-finetuned variant <math alttext="\mathbb{W}_{DP}" class="ltx_Math" display="inline" id="A1.SS1.p1.3.m3.1"><semantics id="A1.SS1.p1.3.m3.1a"><msub id="A1.SS1.p1.3.m3.1.1" xref="A1.SS1.p1.3.m3.1.1.cmml"><mi id="A1.SS1.p1.3.m3.1.1.2" xref="A1.SS1.p1.3.m3.1.1.2.cmml">𝕎</mi><mrow id="A1.SS1.p1.3.m3.1.1.3" xref="A1.SS1.p1.3.m3.1.1.3.cmml"><mi id="A1.SS1.p1.3.m3.1.1.3.2" xref="A1.SS1.p1.3.m3.1.1.3.2.cmml">D</mi><mo id="A1.SS1.p1.3.m3.1.1.3.1" xref="A1.SS1.p1.3.m3.1.1.3.1.cmml">⁢</mo><mi id="A1.SS1.p1.3.m3.1.1.3.3" xref="A1.SS1.p1.3.m3.1.1.3.3.cmml">P</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.3.m3.1b"><apply id="A1.SS1.p1.3.m3.1.1.cmml" xref="A1.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="A1.SS1.p1.3.m3.1.1.1.cmml" xref="A1.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="A1.SS1.p1.3.m3.1.1.2.cmml" xref="A1.SS1.p1.3.m3.1.1.2">𝕎</ci><apply id="A1.SS1.p1.3.m3.1.1.3.cmml" xref="A1.SS1.p1.3.m3.1.1.3"><times id="A1.SS1.p1.3.m3.1.1.3.1.cmml" xref="A1.SS1.p1.3.m3.1.1.3.1"></times><ci id="A1.SS1.p1.3.m3.1.1.3.2.cmml" xref="A1.SS1.p1.3.m3.1.1.3.2">𝐷</ci><ci id="A1.SS1.p1.3.m3.1.1.3.3.cmml" xref="A1.SS1.p1.3.m3.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.3.m3.1c">\mathbb{W}_{DP}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.3.m3.1d">blackboard_W start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT</annotation></semantics></math> may still violate privacy requirements <cite class="ltx_cite ltx_citemacro_cite">Igamberdiev et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib23" title="">2022</a>)</cite>. Additionally, if the professional model <math alttext="\mathbb{W}_{Pro}" class="ltx_Math" display="inline" id="A1.SS1.p1.4.m4.1"><semantics id="A1.SS1.p1.4.m4.1a"><msub id="A1.SS1.p1.4.m4.1.1" xref="A1.SS1.p1.4.m4.1.1.cmml"><mi id="A1.SS1.p1.4.m4.1.1.2" xref="A1.SS1.p1.4.m4.1.1.2.cmml">𝕎</mi><mrow id="A1.SS1.p1.4.m4.1.1.3" xref="A1.SS1.p1.4.m4.1.1.3.cmml"><mi id="A1.SS1.p1.4.m4.1.1.3.2" xref="A1.SS1.p1.4.m4.1.1.3.2.cmml">P</mi><mo id="A1.SS1.p1.4.m4.1.1.3.1" xref="A1.SS1.p1.4.m4.1.1.3.1.cmml">⁢</mo><mi id="A1.SS1.p1.4.m4.1.1.3.3" xref="A1.SS1.p1.4.m4.1.1.3.3.cmml">r</mi><mo id="A1.SS1.p1.4.m4.1.1.3.1a" xref="A1.SS1.p1.4.m4.1.1.3.1.cmml">⁢</mo><mi id="A1.SS1.p1.4.m4.1.1.3.4" xref="A1.SS1.p1.4.m4.1.1.3.4.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.4.m4.1b"><apply id="A1.SS1.p1.4.m4.1.1.cmml" xref="A1.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="A1.SS1.p1.4.m4.1.1.1.cmml" xref="A1.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="A1.SS1.p1.4.m4.1.1.2.cmml" xref="A1.SS1.p1.4.m4.1.1.2">𝕎</ci><apply id="A1.SS1.p1.4.m4.1.1.3.cmml" xref="A1.SS1.p1.4.m4.1.1.3"><times id="A1.SS1.p1.4.m4.1.1.3.1.cmml" xref="A1.SS1.p1.4.m4.1.1.3.1"></times><ci id="A1.SS1.p1.4.m4.1.1.3.2.cmml" xref="A1.SS1.p1.4.m4.1.1.3.2">𝑃</ci><ci id="A1.SS1.p1.4.m4.1.1.3.3.cmml" xref="A1.SS1.p1.4.m4.1.1.3.3">𝑟</ci><ci id="A1.SS1.p1.4.m4.1.1.3.4.cmml" xref="A1.SS1.p1.4.m4.1.1.3.4">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.4.m4.1c">\mathbb{W}_{Pro}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.4.m4.1d">blackboard_W start_POSTSUBSCRIPT italic_P italic_r italic_o end_POSTSUBSCRIPT</annotation></semantics></math> has been trained on <math alttext="\mathbb{D}_{Pri}" class="ltx_Math" display="inline" id="A1.SS1.p1.5.m5.1"><semantics id="A1.SS1.p1.5.m5.1a"><msub id="A1.SS1.p1.5.m5.1.1" xref="A1.SS1.p1.5.m5.1.1.cmml"><mi id="A1.SS1.p1.5.m5.1.1.2" xref="A1.SS1.p1.5.m5.1.1.2.cmml">𝔻</mi><mrow id="A1.SS1.p1.5.m5.1.1.3" xref="A1.SS1.p1.5.m5.1.1.3.cmml"><mi id="A1.SS1.p1.5.m5.1.1.3.2" xref="A1.SS1.p1.5.m5.1.1.3.2.cmml">P</mi><mo id="A1.SS1.p1.5.m5.1.1.3.1" xref="A1.SS1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="A1.SS1.p1.5.m5.1.1.3.3" xref="A1.SS1.p1.5.m5.1.1.3.3.cmml">r</mi><mo id="A1.SS1.p1.5.m5.1.1.3.1a" xref="A1.SS1.p1.5.m5.1.1.3.1.cmml">⁢</mo><mi id="A1.SS1.p1.5.m5.1.1.3.4" xref="A1.SS1.p1.5.m5.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.5.m5.1b"><apply id="A1.SS1.p1.5.m5.1.1.cmml" xref="A1.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="A1.SS1.p1.5.m5.1.1.1.cmml" xref="A1.SS1.p1.5.m5.1.1">subscript</csymbol><ci id="A1.SS1.p1.5.m5.1.1.2.cmml" xref="A1.SS1.p1.5.m5.1.1.2">𝔻</ci><apply id="A1.SS1.p1.5.m5.1.1.3.cmml" xref="A1.SS1.p1.5.m5.1.1.3"><times id="A1.SS1.p1.5.m5.1.1.3.1.cmml" xref="A1.SS1.p1.5.m5.1.1.3.1"></times><ci id="A1.SS1.p1.5.m5.1.1.3.2.cmml" xref="A1.SS1.p1.5.m5.1.1.3.2">𝑃</ci><ci id="A1.SS1.p1.5.m5.1.1.3.3.cmml" xref="A1.SS1.p1.5.m5.1.1.3.3">𝑟</ci><ci id="A1.SS1.p1.5.m5.1.1.3.4.cmml" xref="A1.SS1.p1.5.m5.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.5.m5.1c">\mathbb{D}_{Pri}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.5.m5.1d">blackboard_D start_POSTSUBSCRIPT italic_P italic_r italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, it could inadvertently produce sensitive information such as individual names, when we utilize it to distill knowledge and improve the synthetic data generated by <math alttext="\mathbb{W}_{DP}" class="ltx_Math" display="inline" id="A1.SS1.p1.6.m6.1"><semantics id="A1.SS1.p1.6.m6.1a"><msub id="A1.SS1.p1.6.m6.1.1" xref="A1.SS1.p1.6.m6.1.1.cmml"><mi id="A1.SS1.p1.6.m6.1.1.2" xref="A1.SS1.p1.6.m6.1.1.2.cmml">𝕎</mi><mrow id="A1.SS1.p1.6.m6.1.1.3" xref="A1.SS1.p1.6.m6.1.1.3.cmml"><mi id="A1.SS1.p1.6.m6.1.1.3.2" xref="A1.SS1.p1.6.m6.1.1.3.2.cmml">D</mi><mo id="A1.SS1.p1.6.m6.1.1.3.1" xref="A1.SS1.p1.6.m6.1.1.3.1.cmml">⁢</mo><mi id="A1.SS1.p1.6.m6.1.1.3.3" xref="A1.SS1.p1.6.m6.1.1.3.3.cmml">P</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.SS1.p1.6.m6.1b"><apply id="A1.SS1.p1.6.m6.1.1.cmml" xref="A1.SS1.p1.6.m6.1.1"><csymbol cd="ambiguous" id="A1.SS1.p1.6.m6.1.1.1.cmml" xref="A1.SS1.p1.6.m6.1.1">subscript</csymbol><ci id="A1.SS1.p1.6.m6.1.1.2.cmml" xref="A1.SS1.p1.6.m6.1.1.2">𝕎</ci><apply id="A1.SS1.p1.6.m6.1.1.3.cmml" xref="A1.SS1.p1.6.m6.1.1.3"><times id="A1.SS1.p1.6.m6.1.1.3.1.cmml" xref="A1.SS1.p1.6.m6.1.1.3.1"></times><ci id="A1.SS1.p1.6.m6.1.1.3.2.cmml" xref="A1.SS1.p1.6.m6.1.1.3.2">𝐷</ci><ci id="A1.SS1.p1.6.m6.1.1.3.3.cmml" xref="A1.SS1.p1.6.m6.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.p1.6.m6.1c">\mathbb{W}_{DP}</annotation><annotation encoding="application/x-llamapun" id="A1.SS1.p1.6.m6.1d">blackboard_W start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="A1.SS1.p2">
<p class="ltx_p" id="A1.SS1.p2.1">To address this concern in <span class="ltx_text ltx_font_italic" id="A1.SS1.p2.1.1">KnowledgeSG</span>, we will provide both theoretical elaborations and experimental results.
It is important to note that the likelihood of private datasets being leaked and pre-trained by models is minimal in real-world applications. Our work focuses on preventing further memorization when using sensitive data, rather than reversing any memorization that has already occurred.</p>
</div>
</section>
<section class="ltx_subsection" id="A1.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Theoretical Privacy Elaborations</h3>
<section class="ltx_paragraph" id="A1.SS2.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Interchangeability of Models.</h4>
<div class="ltx_para" id="A1.SS2.SSS0.Px1.p1">
<p class="ltx_p" id="A1.SS2.SSS0.Px1.p1.1">In our framework, both the base model and professional model are interchangeable. <span class="ltx_text ltx_font_italic" id="A1.SS2.SSS0.Px1.p1.1.1">KnowledgeSG</span> is not dependent on any specified LLM, e.g. Llama2-7B. The clients using <span class="ltx_text ltx_font_italic" id="A1.SS2.SSS0.Px1.p1.1.2">KnowledgeSG</span> can select any other LLM that has not been pre-trained on their private datasets to mitigate the risk.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS2.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Theoretical Guarantee of Differential Privacy.</h4>
<div class="ltx_para" id="A1.SS2.SSS0.Px2.p1">
<p class="ltx_p" id="A1.SS2.SSS0.Px2.p1.2">Based on previous works, we assert the privacy-preserving nature of our framework is justified by differential privacy theory.
First, on the client side, we follow <cite class="ltx_cite ltx_citemacro_citet">Abadi et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib1" title="">2016</a>); Yue et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib75" title="">2023</a>)</cite> to DP-fintuned the base model <math alttext="\mathbb{W}_{Loc}" class="ltx_Math" display="inline" id="A1.SS2.SSS0.Px2.p1.1.m1.1"><semantics id="A1.SS2.SSS0.Px2.p1.1.m1.1a"><msub id="A1.SS2.SSS0.Px2.p1.1.m1.1.1" xref="A1.SS2.SSS0.Px2.p1.1.m1.1.1.cmml"><mi id="A1.SS2.SSS0.Px2.p1.1.m1.1.1.2" xref="A1.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml">𝕎</mi><mrow id="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3" xref="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml"><mi id="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3.2" xref="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3.2.cmml">L</mi><mo id="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3.1" xref="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3.3" xref="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3.3.cmml">o</mi><mo id="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3.1a" xref="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3.4" xref="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3.4.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS0.Px2.p1.1.m1.1b"><apply id="A1.SS2.SSS0.Px2.p1.1.m1.1.1.cmml" xref="A1.SS2.SSS0.Px2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS2.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="A1.SS2.SSS0.Px2.p1.1.m1.1.1">subscript</csymbol><ci id="A1.SS2.SSS0.Px2.p1.1.m1.1.1.2.cmml" xref="A1.SS2.SSS0.Px2.p1.1.m1.1.1.2">𝕎</ci><apply id="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3.cmml" xref="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3"><times id="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3.1.cmml" xref="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3.1"></times><ci id="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3.2.cmml" xref="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3.2">𝐿</ci><ci id="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3.3.cmml" xref="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3.3">𝑜</ci><ci id="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3.4.cmml" xref="A1.SS2.SSS0.Px2.p1.1.m1.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS0.Px2.p1.1.m1.1c">\mathbb{W}_{Loc}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS0.Px2.p1.1.m1.1d">blackboard_W start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT</annotation></semantics></math>. This provides us with a strong theoretical guarantee against memorization within the privacy budget <math alttext="(\epsilon,\delta)-DP" class="ltx_Math" display="inline" id="A1.SS2.SSS0.Px2.p1.2.m2.2"><semantics id="A1.SS2.SSS0.Px2.p1.2.m2.2a"><mrow id="A1.SS2.SSS0.Px2.p1.2.m2.2.3" xref="A1.SS2.SSS0.Px2.p1.2.m2.2.3.cmml"><mrow id="A1.SS2.SSS0.Px2.p1.2.m2.2.3.2.2" xref="A1.SS2.SSS0.Px2.p1.2.m2.2.3.2.1.cmml"><mo id="A1.SS2.SSS0.Px2.p1.2.m2.2.3.2.2.1" stretchy="false" xref="A1.SS2.SSS0.Px2.p1.2.m2.2.3.2.1.cmml">(</mo><mi id="A1.SS2.SSS0.Px2.p1.2.m2.1.1" xref="A1.SS2.SSS0.Px2.p1.2.m2.1.1.cmml">ϵ</mi><mo id="A1.SS2.SSS0.Px2.p1.2.m2.2.3.2.2.2" xref="A1.SS2.SSS0.Px2.p1.2.m2.2.3.2.1.cmml">,</mo><mi id="A1.SS2.SSS0.Px2.p1.2.m2.2.2" xref="A1.SS2.SSS0.Px2.p1.2.m2.2.2.cmml">δ</mi><mo id="A1.SS2.SSS0.Px2.p1.2.m2.2.3.2.2.3" stretchy="false" xref="A1.SS2.SSS0.Px2.p1.2.m2.2.3.2.1.cmml">)</mo></mrow><mo id="A1.SS2.SSS0.Px2.p1.2.m2.2.3.1" xref="A1.SS2.SSS0.Px2.p1.2.m2.2.3.1.cmml">−</mo><mrow id="A1.SS2.SSS0.Px2.p1.2.m2.2.3.3" xref="A1.SS2.SSS0.Px2.p1.2.m2.2.3.3.cmml"><mi id="A1.SS2.SSS0.Px2.p1.2.m2.2.3.3.2" xref="A1.SS2.SSS0.Px2.p1.2.m2.2.3.3.2.cmml">D</mi><mo id="A1.SS2.SSS0.Px2.p1.2.m2.2.3.3.1" xref="A1.SS2.SSS0.Px2.p1.2.m2.2.3.3.1.cmml">⁢</mo><mi id="A1.SS2.SSS0.Px2.p1.2.m2.2.3.3.3" xref="A1.SS2.SSS0.Px2.p1.2.m2.2.3.3.3.cmml">P</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS0.Px2.p1.2.m2.2b"><apply id="A1.SS2.SSS0.Px2.p1.2.m2.2.3.cmml" xref="A1.SS2.SSS0.Px2.p1.2.m2.2.3"><minus id="A1.SS2.SSS0.Px2.p1.2.m2.2.3.1.cmml" xref="A1.SS2.SSS0.Px2.p1.2.m2.2.3.1"></minus><interval closure="open" id="A1.SS2.SSS0.Px2.p1.2.m2.2.3.2.1.cmml" xref="A1.SS2.SSS0.Px2.p1.2.m2.2.3.2.2"><ci id="A1.SS2.SSS0.Px2.p1.2.m2.1.1.cmml" xref="A1.SS2.SSS0.Px2.p1.2.m2.1.1">italic-ϵ</ci><ci id="A1.SS2.SSS0.Px2.p1.2.m2.2.2.cmml" xref="A1.SS2.SSS0.Px2.p1.2.m2.2.2">𝛿</ci></interval><apply id="A1.SS2.SSS0.Px2.p1.2.m2.2.3.3.cmml" xref="A1.SS2.SSS0.Px2.p1.2.m2.2.3.3"><times id="A1.SS2.SSS0.Px2.p1.2.m2.2.3.3.1.cmml" xref="A1.SS2.SSS0.Px2.p1.2.m2.2.3.3.1"></times><ci id="A1.SS2.SSS0.Px2.p1.2.m2.2.3.3.2.cmml" xref="A1.SS2.SSS0.Px2.p1.2.m2.2.3.3.2">𝐷</ci><ci id="A1.SS2.SSS0.Px2.p1.2.m2.2.3.3.3.cmml" xref="A1.SS2.SSS0.Px2.p1.2.m2.2.3.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS0.Px2.p1.2.m2.2c">(\epsilon,\delta)-DP</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS0.Px2.p1.2.m2.2d">( italic_ϵ , italic_δ ) - italic_D italic_P</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="A1.SS2.SSS0.Px2.p2">
<p class="ltx_p" id="A1.SS2.SSS0.Px2.p2.3">Second, on the server side, the post-processing property of DP <cite class="ltx_cite ltx_citemacro_cite">Dwork and Roth (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib16" title="">2014</a>)</cite> ensures that once the model <math alttext="\mathbb{W}_{Loc}" class="ltx_Math" display="inline" id="A1.SS2.SSS0.Px2.p2.1.m1.1"><semantics id="A1.SS2.SSS0.Px2.p2.1.m1.1a"><msub id="A1.SS2.SSS0.Px2.p2.1.m1.1.1" xref="A1.SS2.SSS0.Px2.p2.1.m1.1.1.cmml"><mi id="A1.SS2.SSS0.Px2.p2.1.m1.1.1.2" xref="A1.SS2.SSS0.Px2.p2.1.m1.1.1.2.cmml">𝕎</mi><mrow id="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3" xref="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3.cmml"><mi id="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3.2" xref="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3.2.cmml">L</mi><mo id="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3.1" xref="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3.3" xref="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3.3.cmml">o</mi><mo id="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3.1a" xref="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3.4" xref="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3.4.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS0.Px2.p2.1.m1.1b"><apply id="A1.SS2.SSS0.Px2.p2.1.m1.1.1.cmml" xref="A1.SS2.SSS0.Px2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS2.SSS0.Px2.p2.1.m1.1.1.1.cmml" xref="A1.SS2.SSS0.Px2.p2.1.m1.1.1">subscript</csymbol><ci id="A1.SS2.SSS0.Px2.p2.1.m1.1.1.2.cmml" xref="A1.SS2.SSS0.Px2.p2.1.m1.1.1.2">𝕎</ci><apply id="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3.cmml" xref="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3"><times id="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3.1.cmml" xref="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3.1"></times><ci id="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3.2.cmml" xref="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3.2">𝐿</ci><ci id="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3.3.cmml" xref="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3.3">𝑜</ci><ci id="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3.4.cmml" xref="A1.SS2.SSS0.Px2.p2.1.m1.1.1.3.4">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS0.Px2.p2.1.m1.1c">\mathbb{W}_{Loc}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS0.Px2.p2.1.m1.1d">blackboard_W start_POSTSUBSCRIPT italic_L italic_o italic_c end_POSTSUBSCRIPT</annotation></semantics></math> has been fine-tuned with DP, sampling from the fine-tuned model <math alttext="\mathbb{W}_{DP}" class="ltx_Math" display="inline" id="A1.SS2.SSS0.Px2.p2.2.m2.1"><semantics id="A1.SS2.SSS0.Px2.p2.2.m2.1a"><msub id="A1.SS2.SSS0.Px2.p2.2.m2.1.1" xref="A1.SS2.SSS0.Px2.p2.2.m2.1.1.cmml"><mi id="A1.SS2.SSS0.Px2.p2.2.m2.1.1.2" xref="A1.SS2.SSS0.Px2.p2.2.m2.1.1.2.cmml">𝕎</mi><mrow id="A1.SS2.SSS0.Px2.p2.2.m2.1.1.3" xref="A1.SS2.SSS0.Px2.p2.2.m2.1.1.3.cmml"><mi id="A1.SS2.SSS0.Px2.p2.2.m2.1.1.3.2" xref="A1.SS2.SSS0.Px2.p2.2.m2.1.1.3.2.cmml">D</mi><mo id="A1.SS2.SSS0.Px2.p2.2.m2.1.1.3.1" xref="A1.SS2.SSS0.Px2.p2.2.m2.1.1.3.1.cmml">⁢</mo><mi id="A1.SS2.SSS0.Px2.p2.2.m2.1.1.3.3" xref="A1.SS2.SSS0.Px2.p2.2.m2.1.1.3.3.cmml">P</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS0.Px2.p2.2.m2.1b"><apply id="A1.SS2.SSS0.Px2.p2.2.m2.1.1.cmml" xref="A1.SS2.SSS0.Px2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="A1.SS2.SSS0.Px2.p2.2.m2.1.1.1.cmml" xref="A1.SS2.SSS0.Px2.p2.2.m2.1.1">subscript</csymbol><ci id="A1.SS2.SSS0.Px2.p2.2.m2.1.1.2.cmml" xref="A1.SS2.SSS0.Px2.p2.2.m2.1.1.2">𝕎</ci><apply id="A1.SS2.SSS0.Px2.p2.2.m2.1.1.3.cmml" xref="A1.SS2.SSS0.Px2.p2.2.m2.1.1.3"><times id="A1.SS2.SSS0.Px2.p2.2.m2.1.1.3.1.cmml" xref="A1.SS2.SSS0.Px2.p2.2.m2.1.1.3.1"></times><ci id="A1.SS2.SSS0.Px2.p2.2.m2.1.1.3.2.cmml" xref="A1.SS2.SSS0.Px2.p2.2.m2.1.1.3.2">𝐷</ci><ci id="A1.SS2.SSS0.Px2.p2.2.m2.1.1.3.3.cmml" xref="A1.SS2.SSS0.Px2.p2.2.m2.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS0.Px2.p2.2.m2.1c">\mathbb{W}_{DP}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS0.Px2.p2.2.m2.1d">blackboard_W start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT</annotation></semantics></math> does not result in extra privacy loss. Therefore, when the LoRA adapter <math alttext="\mathbb{A}_{DP}" class="ltx_Math" display="inline" id="A1.SS2.SSS0.Px2.p2.3.m3.1"><semantics id="A1.SS2.SSS0.Px2.p2.3.m3.1a"><msub id="A1.SS2.SSS0.Px2.p2.3.m3.1.1" xref="A1.SS2.SSS0.Px2.p2.3.m3.1.1.cmml"><mi id="A1.SS2.SSS0.Px2.p2.3.m3.1.1.2" xref="A1.SS2.SSS0.Px2.p2.3.m3.1.1.2.cmml">𝔸</mi><mrow id="A1.SS2.SSS0.Px2.p2.3.m3.1.1.3" xref="A1.SS2.SSS0.Px2.p2.3.m3.1.1.3.cmml"><mi id="A1.SS2.SSS0.Px2.p2.3.m3.1.1.3.2" xref="A1.SS2.SSS0.Px2.p2.3.m3.1.1.3.2.cmml">D</mi><mo id="A1.SS2.SSS0.Px2.p2.3.m3.1.1.3.1" xref="A1.SS2.SSS0.Px2.p2.3.m3.1.1.3.1.cmml">⁢</mo><mi id="A1.SS2.SSS0.Px2.p2.3.m3.1.1.3.3" xref="A1.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.cmml">P</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A1.SS2.SSS0.Px2.p2.3.m3.1b"><apply id="A1.SS2.SSS0.Px2.p2.3.m3.1.1.cmml" xref="A1.SS2.SSS0.Px2.p2.3.m3.1.1"><csymbol cd="ambiguous" id="A1.SS2.SSS0.Px2.p2.3.m3.1.1.1.cmml" xref="A1.SS2.SSS0.Px2.p2.3.m3.1.1">subscript</csymbol><ci id="A1.SS2.SSS0.Px2.p2.3.m3.1.1.2.cmml" xref="A1.SS2.SSS0.Px2.p2.3.m3.1.1.2">𝔸</ci><apply id="A1.SS2.SSS0.Px2.p2.3.m3.1.1.3.cmml" xref="A1.SS2.SSS0.Px2.p2.3.m3.1.1.3"><times id="A1.SS2.SSS0.Px2.p2.3.m3.1.1.3.1.cmml" xref="A1.SS2.SSS0.Px2.p2.3.m3.1.1.3.1"></times><ci id="A1.SS2.SSS0.Px2.p2.3.m3.1.1.3.2.cmml" xref="A1.SS2.SSS0.Px2.p2.3.m3.1.1.3.2">𝐷</ci><ci id="A1.SS2.SSS0.Px2.p2.3.m3.1.1.3.3.cmml" xref="A1.SS2.SSS0.Px2.p2.3.m3.1.1.3.3">𝑃</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS2.SSS0.Px2.p2.3.m3.1c">\mathbb{A}_{DP}</annotation><annotation encoding="application/x-llamapun" id="A1.SS2.SSS0.Px2.p2.3.m3.1d">blackboard_A start_POSTSUBSCRIPT italic_D italic_P end_POSTSUBSCRIPT</annotation></semantics></math> is uploaded to the server, it can generate synthetic data without exceeding the privacy budget, mitigating associated privacy risks.</p>
</div>
<figure class="ltx_table" id="A1.T8">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T8.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T8.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="A1.T8.1.1.1.1">Evaluation</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A1.T8.1.1.1.2">GPT-3.5-turbo</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T8.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A1.T8.1.2.1.1">Llama2-7B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A1.T8.1.2.1.2">12.96</td>
</tr>
<tr class="ltx_tr" id="A1.T8.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T8.1.3.2.1">Non-Private</th>
<td class="ltx_td ltx_align_center" id="A1.T8.1.3.2.2">0.254</td>
</tr>
<tr class="ltx_tr" id="A1.T8.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A1.T8.1.4.3.1">ICL</th>
<td class="ltx_td ltx_align_center" id="A1.T8.1.4.3.2">0.133</td>
</tr>
<tr class="ltx_tr" id="A1.T8.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="A1.T8.1.5.4.1">KnowledgeSG</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A1.T8.1.5.4.2"><span class="ltx_text ltx_font_bold" id="A1.T8.1.5.4.2.1">0.499</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 8: </span>Free-form evaluation results using medical-ai-chatbot as the private dataset.</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="A1.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Experimental Results</h3>
<section class="ltx_paragraph" id="A1.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Setups.</h4>
<div class="ltx_para" id="A1.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="A1.SS3.SSS0.Px1.p1.1">To further validate the effectiveness of <span class="ltx_text ltx_font_italic" id="A1.SS3.SSS0.Px1.p1.1.1">KnowledgeSG</span> and ensure that no private data has been accessed by either the base model or the professional model, we conducted additional experiments using the ai-medical-chatbot dataset<span class="ltx_note ltx_role_footnote" id="footnote8"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span><a class="ltx_ref ltx_href" href="https://huggingface.co/datasets/ruslanmv/ai-medical-chatbot" title="">https://huggingface.co/datasets/ruslanmv/ai-medical-chatbot</a></span></span></span>, which was collected and released six months later than Llama2-7B and AlpaCare. We adhere to the experimental setups described in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS4" title="4.4 Medical Free-Form Evaluation ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">4.4</span></a> and also employ Llama2-7B as the base model.</p>
</div>
</section>
<section class="ltx_paragraph" id="A1.SS3.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Results.</h4>
<div class="ltx_para" id="A1.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="A1.SS3.SSS0.Px2.p1.1">The results presented in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A1.T8" title="Table 8 ‣ Theoretical Guarantee of Differential Privacy. ‣ A.2 Theoretical Privacy Elaborations ‣ Appendix A Privacy Analysis ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">8</span></a>, reaffirm the effectiveness of <span class="ltx_text ltx_font_italic" id="A1.SS3.SSS0.Px2.p1.1.1">KnowledgeSG</span>, regardless of whether the models had access to the private dataset. It also shows that <span class="ltx_text ltx_font_italic" id="A1.SS3.SSS0.Px2.p1.1.2">KnowledgeSG</span> can generalize well across different datasets. Additionally, they demonstrate that <span class="ltx_text ltx_font_italic" id="A1.SS3.SSS0.Px2.p1.1.3">KnowledgeSG</span> generalizes well across different datasets.
Llama2 trained on the ai-medical-chatbot dataset yields lower scores compared to its training on HealthCareMagic, indicating that the latter dataset may have higher quality.</p>
</div>
<div class="ltx_para" id="A1.SS3.SSS0.Px2.p2">
<p class="ltx_p" id="A1.SS3.SSS0.Px2.p2.1">Llama2 trained on the ai-medical-chatbot dataset yields lower scores compared to its training on HealthCareMagic, suggesting that the latter dataset may have higher quality.</p>
</div>
</section>
</section>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Additional Techniques</h2>
<section class="ltx_subsection" id="A2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.1 </span>Filtration with Models</h3>
<div class="ltx_para" id="A2.SS1.p1">
<p class="ltx_p" id="A2.SS1.p1.1">As mentioned in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S3" title="3 Method ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">3</span></a>, filtration with model means that we prompt the professional model <math alttext="\mathbb{W}_{Pro}" class="ltx_Math" display="inline" id="A2.SS1.p1.1.m1.1"><semantics id="A2.SS1.p1.1.m1.1a"><msub id="A2.SS1.p1.1.m1.1.1" xref="A2.SS1.p1.1.m1.1.1.cmml"><mi id="A2.SS1.p1.1.m1.1.1.2" xref="A2.SS1.p1.1.m1.1.1.2.cmml">𝕎</mi><mrow id="A2.SS1.p1.1.m1.1.1.3" xref="A2.SS1.p1.1.m1.1.1.3.cmml"><mi id="A2.SS1.p1.1.m1.1.1.3.2" xref="A2.SS1.p1.1.m1.1.1.3.2.cmml">P</mi><mo id="A2.SS1.p1.1.m1.1.1.3.1" xref="A2.SS1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A2.SS1.p1.1.m1.1.1.3.3" xref="A2.SS1.p1.1.m1.1.1.3.3.cmml">r</mi><mo id="A2.SS1.p1.1.m1.1.1.3.1a" xref="A2.SS1.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A2.SS1.p1.1.m1.1.1.3.4" xref="A2.SS1.p1.1.m1.1.1.3.4.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A2.SS1.p1.1.m1.1b"><apply id="A2.SS1.p1.1.m1.1.1.cmml" xref="A2.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A2.SS1.p1.1.m1.1.1.1.cmml" xref="A2.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="A2.SS1.p1.1.m1.1.1.2.cmml" xref="A2.SS1.p1.1.m1.1.1.2">𝕎</ci><apply id="A2.SS1.p1.1.m1.1.1.3.cmml" xref="A2.SS1.p1.1.m1.1.1.3"><times id="A2.SS1.p1.1.m1.1.1.3.1.cmml" xref="A2.SS1.p1.1.m1.1.1.3.1"></times><ci id="A2.SS1.p1.1.m1.1.1.3.2.cmml" xref="A2.SS1.p1.1.m1.1.1.3.2">𝑃</ci><ci id="A2.SS1.p1.1.m1.1.1.3.3.cmml" xref="A2.SS1.p1.1.m1.1.1.3.3">𝑟</ci><ci id="A2.SS1.p1.1.m1.1.1.3.4.cmml" xref="A2.SS1.p1.1.m1.1.1.3.4">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS1.p1.1.m1.1c">\mathbb{W}_{Pro}</annotation><annotation encoding="application/x-llamapun" id="A2.SS1.p1.1.m1.1d">blackboard_W start_POSTSUBSCRIPT italic_P italic_r italic_o end_POSTSUBSCRIPT</annotation></semantics></math> with raw instructions for judgments. Then we filter out subpar instructions based on judgements.</p>
</div>
<div class="ltx_para" id="A2.SS1.p2">
<p class="ltx_p" id="A2.SS1.p2.1">For domain-specific settings such as the medical domain, the judgements are mainly based on whether the tested instructions are related to particular medical knowledge.
We first prompt AlpaCare using the template written in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A8.F10" title="Figure 10 ‣ Appendix H Templates ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">10</span></a>, then extract judgements from the model outputs.
In experiments, we also try GPT-3.5-turbo as the domain classifier of instructions and receive acceptable results.</p>
</div>
</section>
<section class="ltx_subsection" id="A2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">B.2 </span>Name Substitution</h3>
<div class="ltx_para" id="A2.SS2.p1">
<p class="ltx_p" id="A2.SS2.p1.1">In order to discard the possibility that the pre-trained model has already seen those individual names (e.g. <span class="ltx_text ltx_font_italic" id="A2.SS2.p1.1.1">John, Trump</span>) in our training datasets <math alttext="\mathbb{D}_{Pri}" class="ltx_Math" display="inline" id="A2.SS2.p1.1.m1.1"><semantics id="A2.SS2.p1.1.m1.1a"><msub id="A2.SS2.p1.1.m1.1.1" xref="A2.SS2.p1.1.m1.1.1.cmml"><mi id="A2.SS2.p1.1.m1.1.1.2" xref="A2.SS2.p1.1.m1.1.1.2.cmml">𝔻</mi><mrow id="A2.SS2.p1.1.m1.1.1.3" xref="A2.SS2.p1.1.m1.1.1.3.cmml"><mi id="A2.SS2.p1.1.m1.1.1.3.2" xref="A2.SS2.p1.1.m1.1.1.3.2.cmml">P</mi><mo id="A2.SS2.p1.1.m1.1.1.3.1" xref="A2.SS2.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A2.SS2.p1.1.m1.1.1.3.3" xref="A2.SS2.p1.1.m1.1.1.3.3.cmml">r</mi><mo id="A2.SS2.p1.1.m1.1.1.3.1a" xref="A2.SS2.p1.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A2.SS2.p1.1.m1.1.1.3.4" xref="A2.SS2.p1.1.m1.1.1.3.4.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A2.SS2.p1.1.m1.1b"><apply id="A2.SS2.p1.1.m1.1.1.cmml" xref="A2.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A2.SS2.p1.1.m1.1.1.1.cmml" xref="A2.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="A2.SS2.p1.1.m1.1.1.2.cmml" xref="A2.SS2.p1.1.m1.1.1.2">𝔻</ci><apply id="A2.SS2.p1.1.m1.1.1.3.cmml" xref="A2.SS2.p1.1.m1.1.1.3"><times id="A2.SS2.p1.1.m1.1.1.3.1.cmml" xref="A2.SS2.p1.1.m1.1.1.3.1"></times><ci id="A2.SS2.p1.1.m1.1.1.3.2.cmml" xref="A2.SS2.p1.1.m1.1.1.3.2">𝑃</ci><ci id="A2.SS2.p1.1.m1.1.1.3.3.cmml" xref="A2.SS2.p1.1.m1.1.1.3.3">𝑟</ci><ci id="A2.SS2.p1.1.m1.1.1.3.4.cmml" xref="A2.SS2.p1.1.m1.1.1.3.4">𝑖</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A2.SS2.p1.1.m1.1c">\mathbb{D}_{Pri}</annotation><annotation encoding="application/x-llamapun" id="A2.SS2.p1.1.m1.1d">blackboard_D start_POSTSUBSCRIPT italic_P italic_r italic_i end_POSTSUBSCRIPT</annotation></semantics></math>, we ask GPT-4 <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib47" title="">2023</a>)</cite> to generate hundreds of unique names (e.g. <span class="ltx_text ltx_font_italic" id="A2.SS2.p1.1.2">Anastasija, Melangell</span>) to substitute the original names. This technique addresses the potential privacy risk discussed in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A1" title="Appendix A Privacy Analysis ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">A</span></a> and pave the groundwork for accurate experiments in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS2" title="4.2 Privacy Evaluation ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">4.2</span></a>.</p>
</div>
<div class="ltx_para" id="A2.SS2.p2">
<p class="ltx_p" id="A2.SS2.p2.1">To evaluate the name substitution technique, we follow the experimental setups in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS2" title="4.2 Privacy Evaluation ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">4.2</span></a>, and compare reconstruction rates of different baselines before and after name substitution.
The results in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A2.T9" title="Table 9 ‣ B.2 Name Substitution ‣ Appendix B Additional Techniques ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">9</span></a> reveal the effectiveness of our approach.
Before name substitution, there is no distinguished gap between the different models. After name substitution, as expected, the pre-trained Llama2 exhibits no memorization, while the Non-private approach shows high memorization because of fine-tuning over private data. And the memorization issue is addressed through synthetic text generation.</p>
</div>
<figure class="ltx_table" id="A2.T9">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A2.T9.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T9.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="A2.T9.1.1.1.1" style="padding-left:3.3pt;padding-right:3.3pt;">Reconstruction</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A2.T9.1.1.1.2" style="padding-left:3.3pt;padding-right:3.3pt;">Llama2-7B</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A2.T9.1.1.1.3" style="padding-left:3.3pt;padding-right:3.3pt;">None-Private</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A2.T9.1.1.1.4" style="padding-left:3.3pt;padding-right:3.3pt;">Synthetic</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T9.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A2.T9.1.2.1.1" style="padding-left:3.3pt;padding-right:3.3pt;">Before</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T9.1.2.1.2" style="padding-left:3.3pt;padding-right:3.3pt;">40.23</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T9.1.2.1.3" style="padding-left:3.3pt;padding-right:3.3pt;">43.73</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A2.T9.1.2.1.4" style="padding-left:3.3pt;padding-right:3.3pt;">42.57</td>
</tr>
<tr class="ltx_tr" id="A2.T9.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="A2.T9.1.3.2.1" style="padding-left:3.3pt;padding-right:3.3pt;">After</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T9.1.3.2.2" style="padding-left:3.3pt;padding-right:3.3pt;">1.89</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T9.1.3.2.3" style="padding-left:3.3pt;padding-right:3.3pt;">96.23</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A2.T9.1.3.2.4" style="padding-left:3.3pt;padding-right:3.3pt;">3.77</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 9: </span>Reconstruction rate comparison <span class="ltx_text ltx_font_italic" id="A2.T9.4.1">Before</span> and <span class="ltx_text ltx_font_italic" id="A2.T9.5.2">After</span> name substitution using Flair as the NER extraction tool. The expansion of the gap between Non-Private and Synthetic methods validates our name substitution approach.</figcaption>
</figure>
</section>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Additional Experiments</h2>
<section class="ltx_subsection" id="A3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.1 </span>Medical Benchmarks</h3>
<section class="ltx_paragraph" id="A3.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Setups.</h4>
<div class="ltx_para" id="A3.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="A3.SS1.SSS0.Px1.p1.1">We evaluate the same models as Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS4" title="4.4 Medical Free-Form Evaluation ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">4.4</span></a> on <math alttext="3" class="ltx_Math" display="inline" id="A3.SS1.SSS0.Px1.p1.1.m1.1"><semantics id="A3.SS1.SSS0.Px1.p1.1.m1.1a"><mn id="A3.SS1.SSS0.Px1.p1.1.m1.1.1" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml">3</mn><annotation-xml encoding="MathML-Content" id="A3.SS1.SSS0.Px1.p1.1.m1.1b"><cn id="A3.SS1.SSS0.Px1.p1.1.m1.1.1.cmml" type="integer" xref="A3.SS1.SSS0.Px1.p1.1.m1.1.1">3</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.SS1.SSS0.Px1.p1.1.m1.1c">3</annotation><annotation encoding="application/x-llamapun" id="A3.SS1.SSS0.Px1.p1.1.m1.1d">3</annotation></semantics></math> medical question answering benchmarks including MedQA <cite class="ltx_cite ltx_citemacro_cite">Jin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib26" title="">2021</a>)</cite>, PubMedQA <cite class="ltx_cite ltx_citemacro_cite">Jin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib27" title="">2019</a>)</cite>, and MedMCQA <cite class="ltx_cite ltx_citemacro_cite">Pal et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib49" title="">2022</a>)</cite>.
We follow the code base of LMflow<span class="ltx_note ltx_role_footnote" id="footnote9"><sup class="ltx_note_mark">9</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">9</sup><span class="ltx_tag ltx_tag_note">9</span><a class="ltx_ref ltx_href" href="https://github.com/OptimalScale/LMFlow" title="">https://github.com/OptimalScale/LMFlow</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">Diao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib13" title="">2023</a>)</cite> and use the prompt shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A8.F6" title="Figure 6 ‣ Appendix H Templates ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">6</span></a> to inference answers.</p>
</div>
<figure class="ltx_table" id="A3.T10">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A3.T10.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A3.T10.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="A3.T10.1.1.1.1" style="padding-left:2.0pt;padding-right:2.0pt;">Evaluation</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A3.T10.1.1.1.2" style="padding-left:2.0pt;padding-right:2.0pt;">PubMedQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A3.T10.1.1.1.3" style="padding-left:2.0pt;padding-right:2.0pt;">MedQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A3.T10.1.1.1.4" style="padding-left:2.0pt;padding-right:2.0pt;">MedMCQA</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A3.T10.1.1.1.5" style="padding-left:2.0pt;padding-right:2.0pt;">Avg</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T10.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T10.1.2.1.1" style="padding-left:2.0pt;padding-right:2.0pt;">Non-Private</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T10.1.2.1.2" style="padding-left:2.0pt;padding-right:2.0pt;">41</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T10.1.2.1.3" style="padding-left:2.0pt;padding-right:2.0pt;">27.57</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T10.1.2.1.4" style="padding-left:2.0pt;padding-right:2.0pt;">25.79</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T10.1.2.1.5" style="padding-left:2.0pt;padding-right:2.0pt;">31.45</td>
</tr>
<tr class="ltx_tr" id="A3.T10.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T10.1.3.2.1" style="padding-left:2.0pt;padding-right:2.0pt;">ICL</th>
<td class="ltx_td ltx_align_center" id="A3.T10.1.3.2.2" style="padding-left:2.0pt;padding-right:2.0pt;">40.9</td>
<td class="ltx_td ltx_align_center" id="A3.T10.1.3.2.3" style="padding-left:2.0pt;padding-right:2.0pt;">28.75</td>
<td class="ltx_td ltx_align_center" id="A3.T10.1.3.2.4" style="padding-left:2.0pt;padding-right:2.0pt;">15.31</td>
<td class="ltx_td ltx_align_center" id="A3.T10.1.3.2.5" style="padding-left:2.0pt;padding-right:2.0pt;">28.32</td>
</tr>
<tr class="ltx_tr" id="A3.T10.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T10.1.4.3.1" style="padding-left:2.0pt;padding-right:2.0pt;">Self-Instruct</th>
<td class="ltx_td ltx_align_center" id="A3.T10.1.4.3.2" style="padding-left:2.0pt;padding-right:2.0pt;">44.4</td>
<td class="ltx_td ltx_align_center" id="A3.T10.1.4.3.3" style="padding-left:2.0pt;padding-right:2.0pt;">24.27</td>
<td class="ltx_td ltx_align_center" id="A3.T10.1.4.3.4" style="padding-left:2.0pt;padding-right:2.0pt;">19.85</td>
<td class="ltx_td ltx_align_center" id="A3.T10.1.4.3.5" style="padding-left:2.0pt;padding-right:2.0pt;">29.51</td>
</tr>
<tr class="ltx_tr" id="A3.T10.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T10.1.5.4.1" style="padding-left:2.0pt;padding-right:2.0pt;">Self-Instruct-ICL</th>
<td class="ltx_td ltx_align_center" id="A3.T10.1.5.4.2" style="padding-left:2.0pt;padding-right:2.0pt;">48.1</td>
<td class="ltx_td ltx_align_center" id="A3.T10.1.5.4.3" style="padding-left:2.0pt;padding-right:2.0pt;">28.91</td>
<td class="ltx_td ltx_align_center" id="A3.T10.1.5.4.4" style="padding-left:2.0pt;padding-right:2.0pt;">25.51</td>
<td class="ltx_td ltx_align_center" id="A3.T10.1.5.4.5" style="padding-left:2.0pt;padding-right:2.0pt;">34.17</td>
</tr>
<tr class="ltx_tr" id="A3.T10.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T10.1.6.5.1" style="padding-left:2.0pt;padding-right:2.0pt;">DP-Gene</th>
<td class="ltx_td ltx_align_center" id="A3.T10.1.6.5.2" style="padding-left:2.0pt;padding-right:2.0pt;">43.2</td>
<td class="ltx_td ltx_align_center" id="A3.T10.1.6.5.3" style="padding-left:2.0pt;padding-right:2.0pt;">26.08</td>
<td class="ltx_td ltx_align_center" id="A3.T10.1.6.5.4" style="padding-left:2.0pt;padding-right:2.0pt;">22.53</td>
<td class="ltx_td ltx_align_center" id="A3.T10.1.6.5.5" style="padding-left:2.0pt;padding-right:2.0pt;">30.60</td>
</tr>
<tr class="ltx_tr" id="A3.T10.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T10.1.7.6.1" style="padding-left:2.0pt;padding-right:2.0pt;">DP-Instruct</th>
<td class="ltx_td ltx_align_center" id="A3.T10.1.7.6.2" style="padding-left:2.0pt;padding-right:2.0pt;">36.8</td>
<td class="ltx_td ltx_align_center" id="A3.T10.1.7.6.3" style="padding-left:2.0pt;padding-right:2.0pt;">26.24</td>
<td class="ltx_td ltx_align_center" id="A3.T10.1.7.6.4" style="padding-left:2.0pt;padding-right:2.0pt;">26.46</td>
<td class="ltx_td ltx_align_center" id="A3.T10.1.7.6.5" style="padding-left:2.0pt;padding-right:2.0pt;">29.83</td>
</tr>
<tr class="ltx_tr" id="A3.T10.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T10.1.8.7.1" style="padding-left:2.0pt;padding-right:2.0pt;">DP-Instruct-ICL</th>
<td class="ltx_td ltx_align_center" id="A3.T10.1.8.7.2" style="padding-left:2.0pt;padding-right:2.0pt;">54.5</td>
<td class="ltx_td ltx_align_center" id="A3.T10.1.8.7.3" style="padding-left:2.0pt;padding-right:2.0pt;">23.88</td>
<td class="ltx_td ltx_align_center" id="A3.T10.1.8.7.4" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="A3.T10.1.8.7.4.1">27.37</span></td>
<td class="ltx_td ltx_align_center" id="A3.T10.1.8.7.5" style="padding-left:2.0pt;padding-right:2.0pt;">35.25</td>
</tr>
<tr class="ltx_tr" id="A3.T10.1.9.8">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="A3.T10.1.9.8.1" style="padding-left:2.0pt;padding-right:2.0pt;">KnowledgeSG</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T10.1.9.8.2" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="A3.T10.1.9.8.2.1">58.3</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T10.1.9.8.3" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="A3.T10.1.9.8.3.1">30.24</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T10.1.9.8.4" style="padding-left:2.0pt;padding-right:2.0pt;">26.8</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T10.1.9.8.5" style="padding-left:2.0pt;padding-right:2.0pt;"><span class="ltx_text ltx_font_bold" id="A3.T10.1.9.8.5.1">38.45</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 10: </span>Performance results on medical domain. Comparative analysis of free-form instruction evaluation.</figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="A3.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Results.</h4>
<div class="ltx_para" id="A3.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="A3.SS1.SSS0.Px2.p1.1">From Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A3.T10" title="Table 10 ‣ Setups. ‣ C.1 Medical Benchmarks ‣ Appendix C Additional Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">10</span></a>, we can conclude that:
(1) Compared to free-form evaluation in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.T4" title="Table 4 ‣ Setups. ‣ 4.4 Medical Free-Form Evaluation ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">4</span></a>, the results on medical benchmarks are more random. Along with the limit of performance ceiling, the gap between different methods are narrowed especially on MedQA and MedMCQA.
(2) Our method still performs the best on average.</p>
</div>
</section>
<section class="ltx_paragraph" id="A3.SS1.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Distinctions in Medical Evaluations.</h4>
<div class="ltx_para" id="A3.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="A3.SS1.SSS0.Px3.p1.1">Compared to the benchmark results in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A3.T10" title="Table 10 ‣ Setups. ‣ C.1 Medical Benchmarks ‣ Appendix C Additional Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">10</span></a>, the gap between different baselines is much more pronounced and noticeable in the free-form evaluation in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.T4" title="Table 4 ‣ Setups. ‣ 4.4 Medical Free-Form Evaluation ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">4</span></a>, aligning more closely with expectations. We attribute the reasons as:
(1) For MedQA and MedMCQA, the dataset we use is HealthCareMagic, whose purpose is to provide patients with consultant. This may not correspond with the nature of benchmarks to choose the right answer to a medicine-related question.
(2) Benchmark results involve more randomness, thus improving the performance of inferior competitors to some extent.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="A3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.2 </span>DP-SGD Performance Evaluation</h3>
<div class="ltx_para" id="A3.SS2.p1">
<p class="ltx_p" id="A3.SS2.p1.1">We follow the details for DP-finetuning in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A6.SS1" title="F.1 Training Details ‣ Appendix F Implementation Details ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">F.1</span></a> and evaluate its performance on the financial domain, same as Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4.SS3" title="4.3 Financial Benchmarks ‣ 4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">4.3</span></a>.</p>
</div>
<div class="ltx_para" id="A3.SS2.p2">
<p class="ltx_p" id="A3.SS2.p2.1">From the results in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A3.T11" title="Table 11 ‣ C.2 DP-SGD Performance Evaluation ‣ Appendix C Additional Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">11</span></a>, we can conclude that relying on DP-SGD only results in a considerable decline of performance, necessitating our approach of synthetic data generation with knowledge distillation from server.</p>
</div>
<figure class="ltx_table" id="A3.T11">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A3.T11.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A3.T11.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="A3.T11.1.1.1.1" rowspan="2" style="padding-left:9.0pt;padding-right:9.0pt;"><span class="ltx_text" id="A3.T11.1.1.1.1.1">Evaluation</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="A3.T11.1.1.1.2" style="padding-left:9.0pt;padding-right:9.0pt;">Avg:3</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="2" id="A3.T11.1.1.1.3" style="padding-left:9.0pt;padding-right:9.0pt;">Avg:4</th>
</tr>
<tr class="ltx_tr" id="A3.T11.1.2.2">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A3.T11.1.2.2.1" style="padding-left:9.0pt;padding-right:9.0pt;">Acc</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A3.T11.1.2.2.2" style="padding-left:9.0pt;padding-right:9.0pt;">F1</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A3.T11.1.2.2.3" style="padding-left:9.0pt;padding-right:9.0pt;">Acc</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column" id="A3.T11.1.2.2.4" style="padding-left:9.0pt;padding-right:9.0pt;">F1</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T11.1.3.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T11.1.3.1.1" style="padding-left:9.0pt;padding-right:9.0pt;">Non-Private</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T11.1.3.1.2" style="padding-left:9.0pt;padding-right:9.0pt;">0.699</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T11.1.3.1.3" style="padding-left:9.0pt;padding-right:9.0pt;">0.719</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T11.1.3.1.4" style="padding-left:9.0pt;padding-right:9.0pt;">0.689</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T11.1.3.1.5" style="padding-left:9.0pt;padding-right:9.0pt;">0.703</td>
</tr>
<tr class="ltx_tr" id="A3.T11.1.4.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T11.1.4.2.1" style="padding-left:9.0pt;padding-right:9.0pt;">DP-SGD</th>
<td class="ltx_td ltx_align_center" id="A3.T11.1.4.2.2" style="padding-left:9.0pt;padding-right:9.0pt;">0.419</td>
<td class="ltx_td ltx_align_center" id="A3.T11.1.4.2.3" style="padding-left:9.0pt;padding-right:9.0pt;">0.343</td>
<td class="ltx_td ltx_align_center" id="A3.T11.1.4.2.4" style="padding-left:9.0pt;padding-right:9.0pt;">0.428</td>
<td class="ltx_td ltx_align_center" id="A3.T11.1.4.2.5" style="padding-left:9.0pt;padding-right:9.0pt;">0.350</td>
</tr>
<tr class="ltx_tr" id="A3.T11.1.5.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="A3.T11.1.5.3.1" style="padding-left:9.0pt;padding-right:9.0pt;">KnowledgeSG</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T11.1.5.3.2" style="padding-left:9.0pt;padding-right:9.0pt;">0.784</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T11.1.5.3.3" style="padding-left:9.0pt;padding-right:9.0pt;">0.775</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T11.1.5.3.4" style="padding-left:9.0pt;padding-right:9.0pt;">0.752</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T11.1.5.3.5" style="padding-left:9.0pt;padding-right:9.0pt;">0.745</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 11: </span>Comparison of Non-Private approach with DP-SGD. The drop in performance validates the limitations of relying on DP-SGD only.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">C.3 </span>Generalizability in Other Domains</h3>
<section class="ltx_paragraph" id="A3.SS3.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Setups.</h4>
<div class="ltx_para" id="A3.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="A3.SS3.SSS0.Px1.p1.1">To evaluate the generalizability of <span class="ltx_text ltx_font_italic" id="A3.SS3.SSS0.Px1.p1.1.1">KnowledgeSG</span>, we conduct additional experiments in the mathematical and code domains.</p>
</div>
<div class="ltx_para" id="A3.SS3.SSS0.Px1.p2">
<p class="ltx_p" id="A3.SS3.SSS0.Px1.p2.1">For the experimental setup of mathematical domain, we utilize <math alttext="500" class="ltx_Math" display="inline" id="A3.SS3.SSS0.Px1.p2.1.m1.1"><semantics id="A3.SS3.SSS0.Px1.p2.1.m1.1a"><mn id="A3.SS3.SSS0.Px1.p2.1.m1.1.1" xref="A3.SS3.SSS0.Px1.p2.1.m1.1.1.cmml">500</mn><annotation-xml encoding="MathML-Content" id="A3.SS3.SSS0.Px1.p2.1.m1.1b"><cn id="A3.SS3.SSS0.Px1.p2.1.m1.1.1.cmml" type="integer" xref="A3.SS3.SSS0.Px1.p2.1.m1.1.1">500</cn></annotation-xml><annotation encoding="application/x-tex" id="A3.SS3.SSS0.Px1.p2.1.m1.1c">500</annotation><annotation encoding="application/x-llamapun" id="A3.SS3.SSS0.Px1.p2.1.m1.1d">500</annotation></semantics></math> samples from the lighteval/MATH dataset<span class="ltx_note ltx_role_footnote" id="footnote10"><sup class="ltx_note_mark">10</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">10</sup><span class="ltx_tag ltx_tag_note">10</span><a class="ltx_ref ltx_href" href="https://huggingface.co/datasets/lighteval/MATH" title="">https://huggingface.co/datasets/lighteval/MATH</a></span></span></span>, employing MAmmoTH-7B <cite class="ltx_cite ltx_citemacro_cite">Yue et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib76" title="">2024</a>)</cite> as the professional model and Llama2-7B as the base model. Following <cite class="ltx_cite ltx_citemacro_citet">Yue et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib76" title="">2024</a>)</cite>, we evaluate models on the GSM8K dataset <cite class="ltx_cite ltx_citemacro_cite">Cobbe et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib11" title="">2021</a>)</cite> using the public benchmark MAmmoTH<span class="ltx_note ltx_role_footnote" id="footnote11"><sup class="ltx_note_mark">11</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">11</sup><span class="ltx_tag ltx_tag_note">11</span><a class="ltx_ref ltx_href" href="https://github.com/TIGER-AI-Lab/MAmmoTH" title="">https://github.com/TIGER-AI-Lab/MAmmoTH</a></span></span></span>.
For the code domain, we utilize the PythonCodeInstructions-18k dataset<span class="ltx_note ltx_role_footnote" id="footnote12"><sup class="ltx_note_mark">12</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">12</sup><span class="ltx_tag ltx_tag_note">12</span><a class="ltx_ref ltx_href" href="https://huggingface.co/datasets/iamtarun/python_code_instructions_18k_alpaca" title="">https://huggingface.co/datasets/iamtarun/python_code_
instructions_18k_alpaca</a></span></span></span>, employing Llama3-8B-Instruct<span class="ltx_note ltx_role_footnote" id="footnote13"><sup class="ltx_note_mark">13</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">13</sup><span class="ltx_tag ltx_tag_note">13</span><a class="ltx_ref ltx_href" href="https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct" title="">https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct</a></span></span></span> as the professional model. We evaluate models on HumanEval dataset <cite class="ltx_cite ltx_citemacro_cite">Chen et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib9" title="">2021</a>)</cite> using the bigcode-evaluation-harness benchmark<span class="ltx_note ltx_role_footnote" id="footnote14"><sup class="ltx_note_mark">14</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">14</sup><span class="ltx_tag ltx_tag_note">14</span><a class="ltx_ref ltx_href" href="https://github.com/bigcode-project/bigcode-evaluation-harness" title="">https://github.com/bigcode-project/bigcode-evaluation-harness</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">Ben Allal et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib4" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="A3.SS3.SSS0.Px1.p3">
<p class="ltx_p" id="A3.SS3.SSS0.Px1.p3.1">We compare three representative methods: Non-Private fine-tuning, In-Context Learning (ICL), and a simplified version of <span class="ltx_text ltx_font_italic" id="A3.SS3.SSS0.Px1.p3.1.1">KnowledgeSG</span> that replaces the synthetic responses in ICL with those generated by the professional model <math alttext="\mathbb{W}_{Pro}" class="ltx_Math" display="inline" id="A3.SS3.SSS0.Px1.p3.1.m1.1"><semantics id="A3.SS3.SSS0.Px1.p3.1.m1.1a"><msub id="A3.SS3.SSS0.Px1.p3.1.m1.1.1" xref="A3.SS3.SSS0.Px1.p3.1.m1.1.1.cmml"><mi id="A3.SS3.SSS0.Px1.p3.1.m1.1.1.2" xref="A3.SS3.SSS0.Px1.p3.1.m1.1.1.2.cmml">𝕎</mi><mrow id="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3" xref="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3.cmml"><mi id="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3.2" xref="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3.2.cmml">P</mi><mo id="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3.1" xref="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3.3" xref="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3.3.cmml">r</mi><mo id="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3.1a" xref="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3.1.cmml">⁢</mo><mi id="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3.4" xref="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3.4.cmml">o</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="A3.SS3.SSS0.Px1.p3.1.m1.1b"><apply id="A3.SS3.SSS0.Px1.p3.1.m1.1.1.cmml" xref="A3.SS3.SSS0.Px1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="A3.SS3.SSS0.Px1.p3.1.m1.1.1.1.cmml" xref="A3.SS3.SSS0.Px1.p3.1.m1.1.1">subscript</csymbol><ci id="A3.SS3.SSS0.Px1.p3.1.m1.1.1.2.cmml" xref="A3.SS3.SSS0.Px1.p3.1.m1.1.1.2">𝕎</ci><apply id="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3.cmml" xref="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3"><times id="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3.1.cmml" xref="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3.1"></times><ci id="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3.2.cmml" xref="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3.2">𝑃</ci><ci id="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3.3.cmml" xref="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3.3">𝑟</ci><ci id="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3.4.cmml" xref="A3.SS3.SSS0.Px1.p3.1.m1.1.1.3.4">𝑜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A3.SS3.SSS0.Px1.p3.1.m1.1c">\mathbb{W}_{Pro}</annotation><annotation encoding="application/x-llamapun" id="A3.SS3.SSS0.Px1.p3.1.m1.1d">blackboard_W start_POSTSUBSCRIPT italic_P italic_r italic_o end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_paragraph" id="A3.SS3.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Results.</h4>
<div class="ltx_para" id="A3.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="A3.SS3.SSS0.Px2.p1.1">As shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A3.T12" title="Table 12 ‣ Results. ‣ C.3 Generalizability in Other Domains ‣ Appendix C Additional Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">12</span></a>, <span class="ltx_text ltx_font_italic" id="A3.SS3.SSS0.Px2.p1.1.1">KnowledgeSG</span> outperforms ICL and Non-Private methods. The results confirm the effectiveness of <span class="ltx_text ltx_font_italic" id="A3.SS3.SSS0.Px2.p1.1.2">KnowledgeSG</span> in the math and code domain, further proving its generalizability.
However, in the code domain, the performance gap between different methods is less pronounced compared to other domains. We attribute this to the suboptimal coding performance of pre-trained Llama2-7B, which may lack the capacity to generalize effectively on coding tasks. This finding aligns with related studies, where experiments on HumanEval are primarily conducted using the Llama2-13B model or larger variants <cite class="ltx_cite ltx_citemacro_cite">Luo et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib40" title="">2023</a>); Xu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib66" title="">2023</a>)</cite>.
The reason we prefer financial and medical domain than code and math is that math solving and code writing tasks are not directly related to privacy because there usually is no PIIs in these datasets.</p>
</div>
<div class="ltx_para" id="A3.SS3.SSS0.Px2.p2">
<p class="ltx_p" id="A3.SS3.SSS0.Px2.p2.1">Our preference for the financial and medical domains over the code and math domains in our experiments stems from the fact that datasets involving math solving and code writing are not directly related to privacy concerns, as they typically do not contain personally identifiable information (PII).</p>
</div>
<figure class="ltx_table" id="A3.T12">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A3.T12.1">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A3.T12.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_tt" id="A3.T12.1.1.1.1">Evaluation</th>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A3.T12.1.1.1.2">GSM8K</td>
<td class="ltx_td ltx_align_center ltx_border_tt" id="A3.T12.1.1.1.3">HumanEval</td>
</tr>
<tr class="ltx_tr" id="A3.T12.1.2.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T12.1.2.2.1">Metric</th>
<td class="ltx_td ltx_align_center" id="A3.T12.1.2.2.2">Accuracy</td>
<td class="ltx_td ltx_align_center" id="A3.T12.1.2.2.3">Pass@10</td>
</tr>
<tr class="ltx_tr" id="A3.T12.1.3.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A3.T12.1.3.3.1">Llama2-7B</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T12.1.3.3.2">12.96</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A3.T12.1.3.3.3">17.68</td>
</tr>
<tr class="ltx_tr" id="A3.T12.1.4.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T12.1.4.4.1">Non-Private</th>
<td class="ltx_td ltx_align_center" id="A3.T12.1.4.4.2">21.30</td>
<td class="ltx_td ltx_align_center" id="A3.T12.1.4.4.3">18.90</td>
</tr>
<tr class="ltx_tr" id="A3.T12.1.5.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A3.T12.1.5.5.1">ICL</th>
<td class="ltx_td ltx_align_center" id="A3.T12.1.5.5.2">14.27</td>
<td class="ltx_td ltx_align_center" id="A3.T12.1.5.5.3">18.29</td>
</tr>
<tr class="ltx_tr" id="A3.T12.1.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="A3.T12.1.6.6.1">KnowledgeSG*</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T12.1.6.6.2"><span class="ltx_text ltx_font_bold" id="A3.T12.1.6.6.2.1">33.83</span></td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A3.T12.1.6.6.3"><span class="ltx_text ltx_font_bold" id="A3.T12.1.6.6.3.1">20.73</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 12: </span>Performance results on mathematical and code domains. The relative improvement of KnowledgeSG over Non-Private and ICL demonstrates the generalizability of <span class="ltx_text ltx_font_italic" id="A3.T12.3.1">KnowledgeSG</span>. We show accuracy and Pass@10 for GSM8K and HumanEval respectively. 
<br class="ltx_break"/>*: Given that privacy concerns are not the primary issue in the generation of synthetic data for mathematical and code domains, we adopt a simplified version which focuses on knowledge distillation for convenience. This approach excludes differential privacy fine-tuning, instruction filtration, and the transmitting unit.</figcaption>
</figure>
</section>
</section>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>Definition of PII</h2>
<div class="ltx_para" id="A4.p1">
<p class="ltx_p" id="A4.p1.1">There are various definitions of <span class="ltx_text ltx_font_bold" id="A4.p1.1.1">Privacy</span> catering to different privacy concerns in different scenarios. A LLM can know your preference by digging into your search histories. It can also infer that you have a girlfriend from your recent query of buying flowers on Valentine’s day.
In this work, we mainly research on one of the definitions of privacy, i.e. PII which is well-studied by the community.</p>
</div>
<div class="ltx_para" id="A4.p2">
<p class="ltx_p" id="A4.p2.1">PII is short for Personal Identifiable Information, representing data that can identify an individual. As detailed elaborated in <cite class="ltx_cite ltx_citemacro_citet">Lukas et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib39" title="">2023</a>)</cite>, PII can be a direct identifier when leakage of that data alone is sufficient to re-identify an individual, or quasi-identifier when only an aggregation of many quasi-identifiers can reliably re-identify an individual. Apart from names and addresses, PII could also be ticker symbol, transaction figures and credit securities accounts in financial domain, and health insurance card numbers in medical domain.</p>
</div>
<div class="ltx_para" id="A4.p3">
<p class="ltx_p" id="A4.p3.1">We show examples of PII from HealthCareMagic dataset in Fig <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A4.F4" title="Figure 4 ‣ Appendix D Definition of PII ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">4</span></a>. Since our current focus is not on any specific category of leaked PII, we only evaluate Individual Name in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#S4" title="4 Experiments ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">4</span></a> for convenience.</p>
</div>
<figure class="ltx_figure" id="A4.F4"><svg class="ltx_picture ltx_centering" height="153.9" id="A4.F4.pic1" overflow="visible" version="1.1" width="600"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,153.9) matrix(1 0 0 -1 0 0) translate(156,0)"><g fill="#000000" fill-opacity="1.0"><path d="M 0 5.91 L 0 148 C 0 151.26 2.64 153.9 5.91 153.9 L 282.09 153.9 C 285.35 153.9 288 151.26 288 148 L 288 5.91 C 288 2.64 285.35 0 282.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#FFFFFF" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 148 C 1.97 150.17 3.73 151.94 5.91 151.94 L 282.09 151.94 C 284.27 151.94 286.03 150.17 286.03 148 L 286.03 5.91 C 286.03 3.73 284.27 1.97 282.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="113.46" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="244.69">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A4.F4.pic1.1.1.1.1.1" style="width:176.8pt;">
<span class="ltx_block ltx_parbox ltx_align_middle" id="A4.F4.pic1.1.1.1.1.1.1" style="width:433.6pt;"><pre class="ltx_verbatim ltx_font_typewriter" id="A4.F4.pic1.1.1.1.1.1.1.1">
<span class="ltx_text ltx_font_serif ltx_font_bold" id="A4.F4.pic1.1.1.1.1.1.1.1.1">[ Patient’s question reveals patient’s PII name. ]
<br class="ltx_break"/></span>Patient: "Hi my name is <span class="ltx_text" id="A4.F4.pic1.1.1.1.1.1.1.1.2" style="background-color:#FFFF00;">Anastasija</span>. I’ve been having an issue for ..."
<br class="ltx_break"/>Doctor: "Hello. Thanks for query ..."
<br class="ltx_break"/>

<span class="ltx_text ltx_font_serif ltx_font_bold" id="A4.F4.pic1.1.1.1.1.1.1.1.3">[ Patient’s question reveals doctor’s PII name. ]</span>

Patient: "Dear <span class="ltx_text" id="A4.F4.pic1.1.1.1.1.1.1.1.4" style="background-color:#FFFF00;">Dr Eluned</span>. I would like to ask you..."

Doctor: "Hello and welcome to Chat Doctor ..."
<br class="ltx_break"/>

<span class="ltx_text ltx_font_serif ltx_font_bold" id="A4.F4.pic1.1.1.1.1.1.1.1.5">[ Doctor’s answer reveals patient’s PII name. ]</span>

Patient: "Hi, and thanks for checking up on me ..."

Doctor: "Hi <span class="ltx_text" id="A4.F4.pic1.1.1.1.1.1.1.1.6" style="background-color:#FFFF00;">Elaine</span>, Thanks for asking ...."

</pre>
</span>
</span></foreignobject></g></g></svg>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Examples of individual names contained in the ICliniq dataset <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib36" title="">2023c</a>)</cite>. Individual names as one form of PII, can be used to identify corresponding individuals. For anonymity, we substitute the original names with synthetic ones as mentioned in Appendix <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A2.SS2" title="B.2 Name Substitution ‣ Appendix B Additional Techniques ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">B.2</span></a>.</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A5">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix E </span>Differences of Domain-Specific Data from General Data</h2>
<figure class="ltx_table" id="A5.T13">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A5.T13.6">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A5.T13.6.7.1">
<th class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="A5.T13.6.7.1.1"></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T13.6.7.1.2">Chatbot Arena<span class="ltx_note ltx_role_footnote" id="footnote15"><sup class="ltx_note_mark">15</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">15</sup><span class="ltx_tag ltx_tag_note">15</span><a class="ltx_ref ltx_href" href="https://chat.lmsys.org/?leaderboard" title="">Results come from https://chat.lmsys.org/?leaderboard</a></span></span></span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T13.6.7.1.3">MT-Bench</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T13.6.7.1.4">MMLU</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T13.6.7.1.5">Datum</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T13.6.7.1.6">FPB</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A5.T13.6.7.1.7">PubMedQA</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A5.T13.6.8.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A5.T13.6.8.1.1">GPT-4</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T13.6.8.1.2">1189</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T13.6.8.1.3">8.96</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T13.6.8.1.4">86.4</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T13.6.8.1.5">-</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T13.6.8.1.6">0.833</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A5.T13.6.8.1.7">-</td>
</tr>
<tr class="ltx_tr" id="A5.T13.6.9.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A5.T13.6.9.2.1">ChatGPT</th>
<td class="ltx_td ltx_align_center" id="A5.T13.6.9.2.2">-</td>
<td class="ltx_td ltx_align_center" id="A5.T13.6.9.2.3">-</td>
<td class="ltx_td ltx_align_center" id="A5.T13.6.9.2.4">70.0</td>
<td class="ltx_td ltx_align_center" id="A5.T13.6.9.2.5">-</td>
<td class="ltx_td ltx_align_center" id="A5.T13.6.9.2.6">0.781</td>
<td class="ltx_td ltx_align_center" id="A5.T13.6.9.2.7">63.9*</td>
</tr>
<tr class="ltx_tr" id="A5.T13.6.10.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A5.T13.6.10.3.1">Llama2-7B-Chat</th>
<td class="ltx_td ltx_align_center" id="A5.T13.6.10.3.2">1037</td>
<td class="ltx_td ltx_align_center" id="A5.T13.6.10.3.3">6.27</td>
<td class="ltx_td ltx_align_center" id="A5.T13.6.10.3.4">45.8</td>
<td class="ltx_td ltx_align_center" id="A5.T13.6.10.3.5">-</td>
<td class="ltx_td ltx_align_center" id="A5.T13.6.10.3.6">-</td>
<td class="ltx_td ltx_align_center" id="A5.T13.6.10.3.7">-</td>
</tr>
<tr class="ltx_tr" id="A5.T13.6.11.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A5.T13.6.11.4.1">Llama2-7B</th>
<td class="ltx_td ltx_align_center" id="A5.T13.6.11.4.2">-</td>
<td class="ltx_td ltx_align_center" id="A5.T13.6.11.4.3">-</td>
<td class="ltx_td ltx_align_center" id="A5.T13.6.11.4.4">-</td>
<td class="ltx_td ltx_align_center" id="A5.T13.6.11.4.5">-</td>
<td class="ltx_td ltx_align_center" id="A5.T13.6.11.4.6">0.39</td>
<td class="ltx_td ltx_align_center" id="A5.T13.6.11.4.7">7.2</td>
</tr>
<tr class="ltx_tr" id="A5.T13.6.12.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A5.T13.6.12.5.1">Llama-7B</th>
<td class="ltx_td ltx_align_center" id="A5.T13.6.12.5.2">-</td>
<td class="ltx_td ltx_align_center" id="A5.T13.6.12.5.3">-</td>
<td class="ltx_td ltx_align_center" id="A5.T13.6.12.5.4">35.2</td>
<td class="ltx_td ltx_align_center" id="A5.T13.6.12.5.5">-</td>
<td class="ltx_td ltx_align_center" id="A5.T13.6.12.5.6">-</td>
<td class="ltx_td ltx_align_center" id="A5.T13.6.12.5.7">5.2*</td>
</tr>
<tr class="ltx_tr" id="A5.T13.6.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r ltx_border_t" id="A5.T13.6.6.7">Gap Ratio</th>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A5.T13.1.1.1">0.8722<sup class="ltx_sup" id="A5.T13.1.1.1.1">↑</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A5.T13.2.2.2">0.6998<sup class="ltx_sup" id="A5.T13.2.2.2.1">↑</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A5.T13.3.3.3">0.5301<sup class="ltx_sup" id="A5.T13.3.3.3.1">↑</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A5.T13.4.4.4">0.5<sup class="ltx_sup" id="A5.T13.4.4.4.1">-</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A5.T13.5.5.5">0.4682<sup class="ltx_sup" id="A5.T13.5.5.5.1">↓</sup>
</td>
<td class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" id="A5.T13.6.6.6">0.1127<sup class="ltx_sup" id="A5.T13.6.6.6.1">↓</sup>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 13: </span>Comparison between {Llama2-7B, Llam2-7B-Chat} and {GPT-4, ChatGPT } on general benchmarks including Chatbot Arena Leaderboard, MT-Bench, MMLU <cite class="ltx_cite ltx_citemacro_cite">Chiang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib10" title="">2024</a>); Hendrycks et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib19" title="">2021a</a>); Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib80" title="">2023</a>)</cite> and domain-specific benchmarks including FPB, PubMedQA<cite class="ltx_cite ltx_citemacro_cite">Malo et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib43" title="">2014</a>); Jin et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib27" title="">2019</a>)</cite>. Results with tagger* is collected from <cite class="ltx_cite ltx_citemacro_citet">Zhang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib77" title="">2023</a>)</cite>. Results with <sup class="ltx_sup" id="A5.T13.16.1">↑</sup> and <sup class="ltx_sup" id="A5.T13.17.2">↓</sup> indicate whether the <span class="ltx_text ltx_font_italic" id="A5.T13.18.3">Gap Ratio</span> exceeds the datum line of <math alttext="0.5" class="ltx_Math" display="inline" id="A5.T13.12.m3.1"><semantics id="A5.T13.12.m3.1b"><mn id="A5.T13.12.m3.1.1" xref="A5.T13.12.m3.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="A5.T13.12.m3.1c"><cn id="A5.T13.12.m3.1.1.cmml" type="float" xref="A5.T13.12.m3.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.T13.12.m3.1d">0.5</annotation><annotation encoding="application/x-llamapun" id="A5.T13.12.m3.1e">0.5</annotation></semantics></math> or not.</figcaption>
</figure>
<section class="ltx_subsection" id="A5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.1 </span>Illustration</h3>
<div class="ltx_para" id="A5.SS1.p1">
<p class="ltx_p" id="A5.SS1.p1.1">We give additional illustration in this section to explain the performance discrepancies of domain-specific data and general data after synthetic data generation.</p>
</div>
<div class="ltx_para" id="A5.SS1.p2">
<p class="ltx_p" id="A5.SS1.p2.1">Deploying an LLM to generate new synthetic data from the original private data is just like asking a student to read an examination question and try to create a new copy of it.
Naturally, the quality of the rewritten question is highly dependent on how the student understands the original question, and how he may generalize.
As illustrated in Fig <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A5.F5" title="Figure 5 ‣ E.1 Illustration ‣ Appendix E Differences of Domain-Specific Data from General Data ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">5</span></a>, a Ph.D. student will behave well on general questions, e.g. Alpaca<span class="ltx_note ltx_role_footnote" id="footnote16"><sup class="ltx_note_mark">16</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">16</sup><span class="ltx_tag ltx_tag_note">16</span><a class="ltx_ref ltx_href" href="https://huggingface.co/datasets/tatsu-lab/alpaca" title="">https://huggingface.co/datasets/tatsu-lab/alpaca</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">Taori et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib56" title="">2023</a>)</cite>.
But if you ask a kindergarten student to create a new calculus test based on several examples, e.g. Math<span class="ltx_note ltx_role_footnote" id="footnote17"><sup class="ltx_note_mark">17</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">17</sup><span class="ltx_tag ltx_tag_note">17</span><a class="ltx_ref ltx_href" href="https://huggingface.co/datasets/lighteval/MATH" title="">https://huggingface.co/datasets/lighteval/MATH</a></span></span></span> <cite class="ltx_cite ltx_citemacro_cite">Hendrycks et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib20" title="">2021b</a>)</cite>, it is highly unlikely that he can fulfil this task.</p>
</div>
<div class="ltx_para" id="A5.SS1.p3">
<p class="ltx_p" id="A5.SS1.p3.1">In practical applications, it is the same nature for LLM-based synthetic data generation where domain-specific data, i.e. the calculus test is more difficult for general foundation models to comprehend. In real-world scenarios when a financial or medical facility tries to train a domain-specific LLM without memorizing its high-value private data <cite class="ltx_cite ltx_citemacro_cite">Nakamura et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib45" title="">2020</a>); Brown et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib5" title="">2022</a>)</cite>, he is inclined to deploy the synthetic text generation approach. With consideration of resources, he has no choice but to fine-tune a limited-size LLM. However, due to the speciality of original data, small models pre-trained on general data (e.g. Llama2-7B <cite class="ltx_cite ltx_citemacro_cite">Touvron et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib57" title="">2023a</a>, <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib58" title="">b</a>)</cite> and ChatGlm 6B <cite class="ltx_cite ltx_citemacro_cite">Du et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib15" title="">2022</a>)</cite>) are unable to fully understand the domain knowledge and consequently fail to maintain high utility of original data after synthetic generation.</p>
</div>
<figure class="ltx_figure" id="A5.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="374" id="A5.F5.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Illustration of our identified gap between model comprehension and data complexity. We make an analogy by describing a situation where a student is asked to create a new question based on given examples.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="A5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">E.2 </span>Gap Ratio</h3>
<div class="ltx_para" id="A5.SS2.p1">
<p class="ltx_p" id="A5.SS2.p1.1">For the purpose of quantifying the gap between domain-specific data and general data
and providing better understanding of the proposed problem, we heuristically define a ratio called <span class="ltx_text ltx_font_italic" id="A5.SS2.p1.1.1">Gap Ratio</span>.</p>
</div>
<div class="ltx_para" id="A5.SS2.p2">
<p class="ltx_p" id="A5.SS2.p2.2">We choose GPT-4 <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib47" title="">2023</a>)</cite> to be the datum model as we assume it is an all-around player that behaves well both on general tasks and domain-specific tasks. And the <span class="ltx_text ltx_font_italic" id="A5.SS2.p2.2.1">Gap Ratio</span> is calculated by the ratio of target model results and GPT-4 results on the same evaluation benchmark.
For example, from Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A5.T13" title="Table 13 ‣ Appendix E Differences of Domain-Specific Data from General Data ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">13</span></a>, Llama2-7B’s <span class="ltx_text ltx_font_italic" id="A5.SS2.p2.2.2">Gap Ratio</span> is <math alttext="0.8722" class="ltx_Math" display="inline" id="A5.SS2.p2.1.m1.1"><semantics id="A5.SS2.p2.1.m1.1a"><mn id="A5.SS2.p2.1.m1.1.1" xref="A5.SS2.p2.1.m1.1.1.cmml">0.8722</mn><annotation-xml encoding="MathML-Content" id="A5.SS2.p2.1.m1.1b"><cn id="A5.SS2.p2.1.m1.1.1.cmml" type="float" xref="A5.SS2.p2.1.m1.1.1">0.8722</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p2.1.m1.1c">0.8722</annotation><annotation encoding="application/x-llamapun" id="A5.SS2.p2.1.m1.1d">0.8722</annotation></semantics></math> on Chatbot Arena and <math alttext="0.7007" class="ltx_Math" display="inline" id="A5.SS2.p2.2.m2.1"><semantics id="A5.SS2.p2.2.m2.1a"><mn id="A5.SS2.p2.2.m2.1.1" xref="A5.SS2.p2.2.m2.1.1.cmml">0.7007</mn><annotation-xml encoding="MathML-Content" id="A5.SS2.p2.2.m2.1b"><cn id="A5.SS2.p2.2.m2.1.1.cmml" type="float" xref="A5.SS2.p2.2.m2.1.1">0.7007</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p2.2.m2.1c">0.7007</annotation><annotation encoding="application/x-llamapun" id="A5.SS2.p2.2.m2.1d">0.7007</annotation></semantics></math> on general benchmarks on average.</p>
</div>
<div class="ltx_para" id="A5.SS2.p3">
<p class="ltx_p" id="A5.SS2.p3.1">No matter what the absolute value is in different measurements of model performance, we can apparently see that the gap between Llama2 and GPT will be greatly widened if changed from general to a specific domain.
As in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A5.T13" title="Table 13 ‣ Appendix E Differences of Domain-Specific Data from General Data ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">13</span></a>, we draw a datum line of <math alttext="0.5" class="ltx_Math" display="inline" id="A5.SS2.p3.1.m1.1"><semantics id="A5.SS2.p3.1.m1.1a"><mn id="A5.SS2.p3.1.m1.1.1" xref="A5.SS2.p3.1.m1.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="A5.SS2.p3.1.m1.1b"><cn id="A5.SS2.p3.1.m1.1.1.cmml" type="float" xref="A5.SS2.p3.1.m1.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="A5.SS2.p3.1.m1.1c">0.5</annotation><annotation encoding="application/x-llamapun" id="A5.SS2.p3.1.m1.1d">0.5</annotation></semantics></math>, smaller than which indicates a tendency of worse synthetic generation.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A6">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix F </span>Implementation Details</h2>
<section class="ltx_subsection" id="A6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">F.1 </span>Training Details</h3>
<div class="ltx_para" id="A6.SS1.p1">
<p class="ltx_p" id="A6.SS1.p1.7">For normal fine-tuning (not DP), we follow the codebase of <cite class="ltx_cite ltx_citemacro_cite">Ye et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib71" title="">2024b</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote18"><sup class="ltx_note_mark">18</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">18</sup><span class="ltx_tag ltx_tag_note">18</span><a class="ltx_ref ltx_href" href="https://github.com/rui-ye/OpenFedLLM" title="">https://github.com/rui-ye/OpenFedLLM</a></span></span></span> and use the local training algorithm to train the model for <math alttext="100" class="ltx_Math" display="inline" id="A6.SS1.p1.1.m1.1"><semantics id="A6.SS1.p1.1.m1.1a"><mn id="A6.SS1.p1.1.m1.1.1" xref="A6.SS1.p1.1.m1.1.1.cmml">100</mn><annotation-xml encoding="MathML-Content" id="A6.SS1.p1.1.m1.1b"><cn id="A6.SS1.p1.1.m1.1.1.cmml" type="integer" xref="A6.SS1.p1.1.m1.1.1">100</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p1.1.m1.1c">100</annotation><annotation encoding="application/x-llamapun" id="A6.SS1.p1.1.m1.1d">100</annotation></semantics></math> rounds in total.
For each round, we train for <math alttext="10" class="ltx_Math" display="inline" id="A6.SS1.p1.2.m2.1"><semantics id="A6.SS1.p1.2.m2.1a"><mn id="A6.SS1.p1.2.m2.1.1" xref="A6.SS1.p1.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A6.SS1.p1.2.m2.1b"><cn id="A6.SS1.p1.2.m2.1.1.cmml" type="integer" xref="A6.SS1.p1.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p1.2.m2.1c">10</annotation><annotation encoding="application/x-llamapun" id="A6.SS1.p1.2.m2.1d">10</annotation></semantics></math> steps with batch-size set to <math alttext="5" class="ltx_Math" display="inline" id="A6.SS1.p1.3.m3.1"><semantics id="A6.SS1.p1.3.m3.1a"><mn id="A6.SS1.p1.3.m3.1.1" xref="A6.SS1.p1.3.m3.1.1.cmml">5</mn><annotation-xml encoding="MathML-Content" id="A6.SS1.p1.3.m3.1b"><cn id="A6.SS1.p1.3.m3.1.1.cmml" type="integer" xref="A6.SS1.p1.3.m3.1.1">5</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p1.3.m3.1c">5</annotation><annotation encoding="application/x-llamapun" id="A6.SS1.p1.3.m3.1d">5</annotation></semantics></math> using AdamW <cite class="ltx_cite ltx_citemacro_cite">Loshchilov and Hutter (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib38" title="">2018</a>)</cite> optimizer. This means each sample in the training dataset is iterated for <math alttext="10" class="ltx_Math" display="inline" id="A6.SS1.p1.4.m4.1"><semantics id="A6.SS1.p1.4.m4.1a"><mn id="A6.SS1.p1.4.m4.1.1" xref="A6.SS1.p1.4.m4.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A6.SS1.p1.4.m4.1b"><cn id="A6.SS1.p1.4.m4.1.1.cmml" type="integer" xref="A6.SS1.p1.4.m4.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p1.4.m4.1c">10</annotation><annotation encoding="application/x-llamapun" id="A6.SS1.p1.4.m4.1d">10</annotation></semantics></math> times on average, equal to training the model for <math alttext="10" class="ltx_Math" display="inline" id="A6.SS1.p1.5.m5.1"><semantics id="A6.SS1.p1.5.m5.1a"><mn id="A6.SS1.p1.5.m5.1.1" xref="A6.SS1.p1.5.m5.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A6.SS1.p1.5.m5.1b"><cn id="A6.SS1.p1.5.m5.1.1.cmml" type="integer" xref="A6.SS1.p1.5.m5.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p1.5.m5.1c">10</annotation><annotation encoding="application/x-llamapun" id="A6.SS1.p1.5.m5.1d">10</annotation></semantics></math> epochs without setting max-steps.
We apply a cosine learning rate schedule according to the round index.
The initial learning rate in the first round is <math alttext="5e-5" class="ltx_Math" display="inline" id="A6.SS1.p1.6.m6.1"><semantics id="A6.SS1.p1.6.m6.1a"><mrow id="A6.SS1.p1.6.m6.1.1" xref="A6.SS1.p1.6.m6.1.1.cmml"><mrow id="A6.SS1.p1.6.m6.1.1.2" xref="A6.SS1.p1.6.m6.1.1.2.cmml"><mn id="A6.SS1.p1.6.m6.1.1.2.2" xref="A6.SS1.p1.6.m6.1.1.2.2.cmml">5</mn><mo id="A6.SS1.p1.6.m6.1.1.2.1" xref="A6.SS1.p1.6.m6.1.1.2.1.cmml">⁢</mo><mi id="A6.SS1.p1.6.m6.1.1.2.3" xref="A6.SS1.p1.6.m6.1.1.2.3.cmml">e</mi></mrow><mo id="A6.SS1.p1.6.m6.1.1.1" xref="A6.SS1.p1.6.m6.1.1.1.cmml">−</mo><mn id="A6.SS1.p1.6.m6.1.1.3" xref="A6.SS1.p1.6.m6.1.1.3.cmml">5</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.SS1.p1.6.m6.1b"><apply id="A6.SS1.p1.6.m6.1.1.cmml" xref="A6.SS1.p1.6.m6.1.1"><minus id="A6.SS1.p1.6.m6.1.1.1.cmml" xref="A6.SS1.p1.6.m6.1.1.1"></minus><apply id="A6.SS1.p1.6.m6.1.1.2.cmml" xref="A6.SS1.p1.6.m6.1.1.2"><times id="A6.SS1.p1.6.m6.1.1.2.1.cmml" xref="A6.SS1.p1.6.m6.1.1.2.1"></times><cn id="A6.SS1.p1.6.m6.1.1.2.2.cmml" type="integer" xref="A6.SS1.p1.6.m6.1.1.2.2">5</cn><ci id="A6.SS1.p1.6.m6.1.1.2.3.cmml" xref="A6.SS1.p1.6.m6.1.1.2.3">𝑒</ci></apply><cn id="A6.SS1.p1.6.m6.1.1.3.cmml" type="integer" xref="A6.SS1.p1.6.m6.1.1.3">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p1.6.m6.1c">5e-5</annotation><annotation encoding="application/x-llamapun" id="A6.SS1.p1.6.m6.1d">5 italic_e - 5</annotation></semantics></math>, and the final learning rate in the last round is <math alttext="1e-6" class="ltx_Math" display="inline" id="A6.SS1.p1.7.m7.1"><semantics id="A6.SS1.p1.7.m7.1a"><mrow id="A6.SS1.p1.7.m7.1.1" xref="A6.SS1.p1.7.m7.1.1.cmml"><mrow id="A6.SS1.p1.7.m7.1.1.2" xref="A6.SS1.p1.7.m7.1.1.2.cmml"><mn id="A6.SS1.p1.7.m7.1.1.2.2" xref="A6.SS1.p1.7.m7.1.1.2.2.cmml">1</mn><mo id="A6.SS1.p1.7.m7.1.1.2.1" xref="A6.SS1.p1.7.m7.1.1.2.1.cmml">⁢</mo><mi id="A6.SS1.p1.7.m7.1.1.2.3" xref="A6.SS1.p1.7.m7.1.1.2.3.cmml">e</mi></mrow><mo id="A6.SS1.p1.7.m7.1.1.1" xref="A6.SS1.p1.7.m7.1.1.1.cmml">−</mo><mn id="A6.SS1.p1.7.m7.1.1.3" xref="A6.SS1.p1.7.m7.1.1.3.cmml">6</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.SS1.p1.7.m7.1b"><apply id="A6.SS1.p1.7.m7.1.1.cmml" xref="A6.SS1.p1.7.m7.1.1"><minus id="A6.SS1.p1.7.m7.1.1.1.cmml" xref="A6.SS1.p1.7.m7.1.1.1"></minus><apply id="A6.SS1.p1.7.m7.1.1.2.cmml" xref="A6.SS1.p1.7.m7.1.1.2"><times id="A6.SS1.p1.7.m7.1.1.2.1.cmml" xref="A6.SS1.p1.7.m7.1.1.2.1"></times><cn id="A6.SS1.p1.7.m7.1.1.2.2.cmml" type="integer" xref="A6.SS1.p1.7.m7.1.1.2.2">1</cn><ci id="A6.SS1.p1.7.m7.1.1.2.3.cmml" xref="A6.SS1.p1.7.m7.1.1.2.3">𝑒</ci></apply><cn id="A6.SS1.p1.7.m7.1.1.3.cmml" type="integer" xref="A6.SS1.p1.7.m7.1.1.3">6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p1.7.m7.1c">1e-6</annotation><annotation encoding="application/x-llamapun" id="A6.SS1.p1.7.m7.1d">1 italic_e - 6</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="A6.SS1.p2">
<p class="ltx_p" id="A6.SS1.p2.5">For DP fine-tuning, we follow the codebase of dp-transformers library <cite class="ltx_cite ltx_citemacro_cite">Wutschitz et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib64" title="">2022</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote19"><sup class="ltx_note_mark">19</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">19</sup><span class="ltx_tag ltx_tag_note">19</span><a class="ltx_ref ltx_href" href="https://github.com/microsoft/dp-transformers" title="">https://github.com/microsoft/dp-transformers</a></span></span></span>, which is a wrapper around Opacus <cite class="ltx_cite ltx_citemacro_cite">Yousefpour et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib72" title="">2021</a>)</cite><span class="ltx_note ltx_role_footnote" id="footnote20"><sup class="ltx_note_mark">20</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">20</sup><span class="ltx_tag ltx_tag_note">20</span><a class="ltx_ref ltx_href" href="https://github.com/pytorch/opacus" title="">https://github.com/pytorch/opacus</a></span></span></span>.
We train the model for <math alttext="4" class="ltx_Math" display="inline" id="A6.SS1.p2.1.m1.1"><semantics id="A6.SS1.p2.1.m1.1a"><mn id="A6.SS1.p2.1.m1.1.1" xref="A6.SS1.p2.1.m1.1.1.cmml">4</mn><annotation-xml encoding="MathML-Content" id="A6.SS1.p2.1.m1.1b"><cn id="A6.SS1.p2.1.m1.1.1.cmml" type="integer" xref="A6.SS1.p2.1.m1.1.1">4</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p2.1.m1.1c">4</annotation><annotation encoding="application/x-llamapun" id="A6.SS1.p2.1.m1.1d">4</annotation></semantics></math> epochs for the first stage of generation, and <math alttext="10" class="ltx_Math" display="inline" id="A6.SS1.p2.2.m2.1"><semantics id="A6.SS1.p2.2.m2.1a"><mn id="A6.SS1.p2.2.m2.1.1" xref="A6.SS1.p2.2.m2.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="A6.SS1.p2.2.m2.1b"><cn id="A6.SS1.p2.2.m2.1.1.cmml" type="integer" xref="A6.SS1.p2.2.m2.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p2.2.m2.1c">10</annotation><annotation encoding="application/x-llamapun" id="A6.SS1.p2.2.m2.1d">10</annotation></semantics></math> epochs for fair comparison between training on private data with DP and training on synthetic data.
The target epsilon is set to <math alttext="8" class="ltx_Math" display="inline" id="A6.SS1.p2.3.m3.1"><semantics id="A6.SS1.p2.3.m3.1a"><mn id="A6.SS1.p2.3.m3.1.1" xref="A6.SS1.p2.3.m3.1.1.cmml">8</mn><annotation-xml encoding="MathML-Content" id="A6.SS1.p2.3.m3.1b"><cn id="A6.SS1.p2.3.m3.1.1.cmml" type="integer" xref="A6.SS1.p2.3.m3.1.1">8</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p2.3.m3.1c">8</annotation><annotation encoding="application/x-llamapun" id="A6.SS1.p2.3.m3.1d">8</annotation></semantics></math> and maximum per-sample gradient norm is set to <math alttext="1.0" class="ltx_Math" display="inline" id="A6.SS1.p2.4.m4.1"><semantics id="A6.SS1.p2.4.m4.1a"><mn id="A6.SS1.p2.4.m4.1.1" xref="A6.SS1.p2.4.m4.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="A6.SS1.p2.4.m4.1b"><cn id="A6.SS1.p2.4.m4.1.1.cmml" type="float" xref="A6.SS1.p2.4.m4.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p2.4.m4.1c">1.0</annotation><annotation encoding="application/x-llamapun" id="A6.SS1.p2.4.m4.1d">1.0</annotation></semantics></math> for differentially private training. The privacy budget we use is <math alttext="(\epsilon,\delta)=(8,\frac{1}{N})" class="ltx_Math" display="inline" id="A6.SS1.p2.5.m5.4"><semantics id="A6.SS1.p2.5.m5.4a"><mrow id="A6.SS1.p2.5.m5.4.5" xref="A6.SS1.p2.5.m5.4.5.cmml"><mrow id="A6.SS1.p2.5.m5.4.5.2.2" xref="A6.SS1.p2.5.m5.4.5.2.1.cmml"><mo id="A6.SS1.p2.5.m5.4.5.2.2.1" stretchy="false" xref="A6.SS1.p2.5.m5.4.5.2.1.cmml">(</mo><mi id="A6.SS1.p2.5.m5.1.1" xref="A6.SS1.p2.5.m5.1.1.cmml">ϵ</mi><mo id="A6.SS1.p2.5.m5.4.5.2.2.2" xref="A6.SS1.p2.5.m5.4.5.2.1.cmml">,</mo><mi id="A6.SS1.p2.5.m5.2.2" xref="A6.SS1.p2.5.m5.2.2.cmml">δ</mi><mo id="A6.SS1.p2.5.m5.4.5.2.2.3" stretchy="false" xref="A6.SS1.p2.5.m5.4.5.2.1.cmml">)</mo></mrow><mo id="A6.SS1.p2.5.m5.4.5.1" xref="A6.SS1.p2.5.m5.4.5.1.cmml">=</mo><mrow id="A6.SS1.p2.5.m5.4.5.3.2" xref="A6.SS1.p2.5.m5.4.5.3.1.cmml"><mo id="A6.SS1.p2.5.m5.4.5.3.2.1" stretchy="false" xref="A6.SS1.p2.5.m5.4.5.3.1.cmml">(</mo><mn id="A6.SS1.p2.5.m5.3.3" xref="A6.SS1.p2.5.m5.3.3.cmml">8</mn><mo id="A6.SS1.p2.5.m5.4.5.3.2.2" xref="A6.SS1.p2.5.m5.4.5.3.1.cmml">,</mo><mfrac id="A6.SS1.p2.5.m5.4.4" xref="A6.SS1.p2.5.m5.4.4.cmml"><mn id="A6.SS1.p2.5.m5.4.4.2" xref="A6.SS1.p2.5.m5.4.4.2.cmml">1</mn><mi id="A6.SS1.p2.5.m5.4.4.3" xref="A6.SS1.p2.5.m5.4.4.3.cmml">N</mi></mfrac><mo id="A6.SS1.p2.5.m5.4.5.3.2.3" stretchy="false" xref="A6.SS1.p2.5.m5.4.5.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="A6.SS1.p2.5.m5.4b"><apply id="A6.SS1.p2.5.m5.4.5.cmml" xref="A6.SS1.p2.5.m5.4.5"><eq id="A6.SS1.p2.5.m5.4.5.1.cmml" xref="A6.SS1.p2.5.m5.4.5.1"></eq><interval closure="open" id="A6.SS1.p2.5.m5.4.5.2.1.cmml" xref="A6.SS1.p2.5.m5.4.5.2.2"><ci id="A6.SS1.p2.5.m5.1.1.cmml" xref="A6.SS1.p2.5.m5.1.1">italic-ϵ</ci><ci id="A6.SS1.p2.5.m5.2.2.cmml" xref="A6.SS1.p2.5.m5.2.2">𝛿</ci></interval><interval closure="open" id="A6.SS1.p2.5.m5.4.5.3.1.cmml" xref="A6.SS1.p2.5.m5.4.5.3.2"><cn id="A6.SS1.p2.5.m5.3.3.cmml" type="integer" xref="A6.SS1.p2.5.m5.3.3">8</cn><apply id="A6.SS1.p2.5.m5.4.4.cmml" xref="A6.SS1.p2.5.m5.4.4"><divide id="A6.SS1.p2.5.m5.4.4.1.cmml" xref="A6.SS1.p2.5.m5.4.4"></divide><cn id="A6.SS1.p2.5.m5.4.4.2.cmml" type="integer" xref="A6.SS1.p2.5.m5.4.4.2">1</cn><ci id="A6.SS1.p2.5.m5.4.4.3.cmml" xref="A6.SS1.p2.5.m5.4.4.3">𝑁</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p2.5.m5.4c">(\epsilon,\delta)=(8,\frac{1}{N})</annotation><annotation encoding="application/x-llamapun" id="A6.SS1.p2.5.m5.4d">( italic_ϵ , italic_δ ) = ( 8 , divide start_ARG 1 end_ARG start_ARG italic_N end_ARG )</annotation></semantics></math>. According to <cite class="ltx_cite ltx_citemacro_cite">Lukas et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib39" title="">2023</a>)</cite>, these values are close to established DP deployments such as Apple’s QuickType and Google’s models.</p>
</div>
<div class="ltx_para" id="A6.SS1.p3">
<p class="ltx_p" id="A6.SS1.p3.1">The max sequence length is set to <math alttext="512" class="ltx_Math" display="inline" id="A6.SS1.p3.1.m1.1"><semantics id="A6.SS1.p3.1.m1.1a"><mn id="A6.SS1.p3.1.m1.1.1" xref="A6.SS1.p3.1.m1.1.1.cmml">512</mn><annotation-xml encoding="MathML-Content" id="A6.SS1.p3.1.m1.1b"><cn id="A6.SS1.p3.1.m1.1.1.cmml" type="integer" xref="A6.SS1.p3.1.m1.1.1">512</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p3.1.m1.1c">512</annotation><annotation encoding="application/x-llamapun" id="A6.SS1.p3.1.m1.1d">512</annotation></semantics></math> for training in both normal and DP fine-tuning.
All the training experiments are conducted on one NVIDIA GeForce RTX 3090.</p>
</div>
<div class="ltx_para" id="A6.SS1.p4">
<p class="ltx_p" id="A6.SS1.p4.2">The rank of LoRA <cite class="ltx_cite ltx_citemacro_cite">Hu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib22" title="">2021</a>)</cite> is <math alttext="32" class="ltx_Math" display="inline" id="A6.SS1.p4.1.m1.1"><semantics id="A6.SS1.p4.1.m1.1a"><mn id="A6.SS1.p4.1.m1.1.1" xref="A6.SS1.p4.1.m1.1.1.cmml">32</mn><annotation-xml encoding="MathML-Content" id="A6.SS1.p4.1.m1.1b"><cn id="A6.SS1.p4.1.m1.1.1.cmml" type="integer" xref="A6.SS1.p4.1.m1.1.1">32</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p4.1.m1.1c">32</annotation><annotation encoding="application/x-llamapun" id="A6.SS1.p4.1.m1.1d">32</annotation></semantics></math> with a scalar <math alttext="\alpha=64" class="ltx_Math" display="inline" id="A6.SS1.p4.2.m2.1"><semantics id="A6.SS1.p4.2.m2.1a"><mrow id="A6.SS1.p4.2.m2.1.1" xref="A6.SS1.p4.2.m2.1.1.cmml"><mi id="A6.SS1.p4.2.m2.1.1.2" xref="A6.SS1.p4.2.m2.1.1.2.cmml">α</mi><mo id="A6.SS1.p4.2.m2.1.1.1" xref="A6.SS1.p4.2.m2.1.1.1.cmml">=</mo><mn id="A6.SS1.p4.2.m2.1.1.3" xref="A6.SS1.p4.2.m2.1.1.3.cmml">64</mn></mrow><annotation-xml encoding="MathML-Content" id="A6.SS1.p4.2.m2.1b"><apply id="A6.SS1.p4.2.m2.1.1.cmml" xref="A6.SS1.p4.2.m2.1.1"><eq id="A6.SS1.p4.2.m2.1.1.1.cmml" xref="A6.SS1.p4.2.m2.1.1.1"></eq><ci id="A6.SS1.p4.2.m2.1.1.2.cmml" xref="A6.SS1.p4.2.m2.1.1.2">𝛼</ci><cn id="A6.SS1.p4.2.m2.1.1.3.cmml" type="integer" xref="A6.SS1.p4.2.m2.1.1.3">64</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A6.SS1.p4.2.m2.1c">\alpha=64</annotation><annotation encoding="application/x-llamapun" id="A6.SS1.p4.2.m2.1d">italic_α = 64</annotation></semantics></math>.
We use the Alpaca <cite class="ltx_cite ltx_citemacro_cite">Taori et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib56" title="">2023</a>)</cite> template to format the instruction.</p>
</div>
</section>
<section class="ltx_subsection" id="A6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">F.2 </span>Inferencing Details</h3>
<div class="ltx_para" id="A6.SS2.p1">
<p class="ltx_p" id="A6.SS2.p1.1">We use VLLM <cite class="ltx_cite ltx_citemacro_cite">Kwon et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib31" title="">2023</a>)</cite> for faster inferencing and set the max-model-len to as long as <math alttext="2048" class="ltx_Math" display="inline" id="A6.SS2.p1.1.m1.1"><semantics id="A6.SS2.p1.1.m1.1a"><mn id="A6.SS2.p1.1.m1.1.1" xref="A6.SS2.p1.1.m1.1.1.cmml">2048</mn><annotation-xml encoding="MathML-Content" id="A6.SS2.p1.1.m1.1b"><cn id="A6.SS2.p1.1.m1.1.1.cmml" type="integer" xref="A6.SS2.p1.1.m1.1.1">2048</cn></annotation-xml><annotation encoding="application/x-tex" id="A6.SS2.p1.1.m1.1c">2048</annotation><annotation encoding="application/x-llamapun" id="A6.SS2.p1.1.m1.1d">2048</annotation></semantics></math> to obtain more information.
The inferencing experiments are mostly conducted on A100 40G.
We set temperature to 0.7 to encourage diversity.
We follow in-context learning <cite class="ltx_cite ltx_citemacro_cite">Dong et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib14" title="">2022</a>)</cite> and self-instruct <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#bib.bib61" title="">2022</a>)</cite> to formulate our prompts. The prompt templates we employ are shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A8.F7" title="Figure 7 ‣ Appendix H Templates ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">7</span></a> and <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A8.F8" title="Figure 8 ‣ Appendix H Templates ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">8</span></a>.
To make sure we have enough instructions for subsequent filtering, the generation times are set two times of the original dataset size. To ensure sufficient instructions for subsequent filtering, the generation count is set to twice the size of the original dataset.
For instruction extraction and pre-processing, we extract the first instruction the model generates and filter those shorter than 2 tokens.</p>
</div>
</section>
<section class="ltx_subsection" id="A6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">F.3 </span>Baselines</h3>
<div class="ltx_para" id="A6.SS3.p1">
<p class="ltx_p" id="A6.SS3.p1.1">To give a detailed comparison between different baselines in our experiments, we elaborate on three aspects in Table <a class="ltx_ref" href="https://arxiv.org/html/2410.05725v2#A6.T14" title="Table 14 ‣ F.3 Baselines ‣ Appendix F Implementation Details ‣ KnowledgeSG: Privacy-Preserving Synthetic Text Generation with Knowledge Distillation from Server"><span class="ltx_text ltx_ref_tag">14</span></a>, ranging from the model used for generating instructions, whether the baseline first generates instructions then responses and whether the baseline requires few-shot examples to generate response if it is twp-step.
DP-Instruct-ICL and Self-Instruct-ICL are different from DP-Instruct and Self-Instruct in that they require few-shot examples from original dataset to produce better responses during the second stage of generation while the others do not.
Theoretically, DP-Instruct performs better than Self-Instruct and DP-Gene performs better than ICL because of additional DP-finetuning of base model.</p>
</div>
<figure class="ltx_table" id="A6.T14">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A6.T14.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A6.T14.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_r ltx_border_tt" id="A6.T14.1.1.1.1" style="padding-left:4.0pt;padding-right:4.0pt;">Baselines</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A6.T14.1.1.1.2" style="padding-left:4.0pt;padding-right:4.0pt;">Model</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A6.T14.1.1.1.3" style="padding-left:4.0pt;padding-right:4.0pt;">Two-Step</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="A6.T14.1.1.1.4" style="padding-left:4.0pt;padding-right:4.0pt;">ICL</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A6.T14.1.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r ltx_border_t" id="A6.T14.1.2.1.1" style="padding-left:4.0pt;padding-right:4.0pt;">ICL</th>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T14.1.2.1.2" style="padding-left:4.0pt;padding-right:4.0pt;">Pre-trained</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T14.1.2.1.3" style="padding-left:4.0pt;padding-right:4.0pt;">✗</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="A6.T14.1.2.1.4" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
</tr>
<tr class="ltx_tr" id="A6.T14.1.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A6.T14.1.3.2.1" style="padding-left:4.0pt;padding-right:4.0pt;">Self-Instruct</th>
<td class="ltx_td ltx_align_center" id="A6.T14.1.3.2.2" style="padding-left:4.0pt;padding-right:4.0pt;">Pre-trained</td>
<td class="ltx_td ltx_align_center" id="A6.T14.1.3.2.3" style="padding-left:4.0pt;padding-right:4.0pt;">✓</td>
<td class="ltx_td ltx_align_center" id="A6.T14.1.3.2.4" style="padding-left:4.0pt;padding-right:4.0pt;">✗</td>
</tr>
<tr class="ltx_tr" id="A6.T14.1.4.3">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A6.T14.1.4.3.1" style="padding-left:4.0pt;padding-right:4.0pt;">Self-Instruct-ICL</th>
<td class="ltx_td ltx_align_center" id="A6.T14.1.4.3.2" style="padding-left:4.0pt;padding-right:4.0pt;">Pre-trained</td>
<td class="ltx_td ltx_align_center" id="A6.T14.1.4.3.3" style="padding-left:4.0pt;padding-right:4.0pt;">✓</td>
<td class="ltx_td ltx_align_center" id="A6.T14.1.4.3.4" style="padding-left:4.0pt;padding-right:4.0pt;">✓</td>
</tr>
<tr class="ltx_tr" id="A6.T14.1.5.4">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A6.T14.1.5.4.1" style="padding-left:4.0pt;padding-right:4.0pt;">DP-Gene</th>
<td class="ltx_td ltx_align_center" id="A6.T14.1.5.4.2" style="padding-left:4.0pt;padding-right:4.0pt;">DP-finetuned</td>
<td class="ltx_td ltx_align_center" id="A6.T14.1.5.4.3" style="padding-left:4.0pt;padding-right:4.0pt;">✗</td>
<td class="ltx_td ltx_align_center" id="A6.T14.1.5.4.4" style="padding-left:4.0pt;padding-right:4.0pt;">-</td>
</tr>
<tr class="ltx_tr" id="A6.T14.1.6.5">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A6.T14.1.6.5.1" style="padding-left:4.0pt;padding-right:4.0pt;">DP-Instruct</th>
<td class="ltx_td ltx_align_center" id="A6.T14.1.6.5.2" style="padding-left:4.0pt;padding-right:4.0pt;">DP-finetuned</td>
<td class="ltx_td ltx_align_center" id="A6.T14.1.6.5.3" style="padding-left:4.0pt;padding-right:4.0pt;">✓</td>
<td class="ltx_td ltx_align_center" id="A6.T14.1.6.5.4" style="padding-left:4.0pt;padding-right:4.0pt;">✗</td>
</tr>
<tr class="ltx_tr" id="A6.T14.1.7.6">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_r" id="A6.T14.1.7.6.1" style="padding-left:4.0pt;padding-right:4.0pt;">DP-Instruct-ICL</th>
<td class="ltx_td ltx_align_center" id="A6.T14.1.7.6.2" style="padding-left:4.0pt;padding-right:4.0pt;">DP-finetuned</td>
<td class="ltx_td ltx_align_center" id="A6.T14.1.7.6.3" style="padding-left:4.0pt;padding-right:4.0pt;">✓</td>
<td class="ltx_td ltx_align_center" id="A6.T14.1.7.6.4" style="padding-left:4.0pt;padding-right:4.0pt;">✓</td>
</tr>
<tr class="ltx_tr" id="A6.T14.1.8.7">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_r" id="A6.T14.1.8.7.1" style="padding-left:4.0pt;padding-right:4.0pt;">KnowledgeSG</th>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T14.1.8.7.2" style="padding-left:4.0pt;padding-right:4.0pt;">DP-finetuned</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T14.1.8.7.3" style="padding-left:4.0pt;padding-right:4.0pt;">✓</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="A6.T14.1.8.7.4" style="padding-left:4.0pt;padding-right:4.0pt;">✗</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 14: </span>Elaboration of baselines. <span class="ltx_text ltx_font_italic" id="A6.T14.5.1">Model</span> means the generative model used for generating synthetic instructions. <span class="ltx_text ltx_font_italic" id="A6.T14.6.2">Twp-Step</span> means whether the baseline first generates instructions then responses or generates both instructions and responses meanwhile. <span class="ltx_text ltx_font_italic" id="A6.T14.7.3">ICL</span> means whether the baseline requires few-shot examples from original dataset to generate response at the second stage.</figcaption>
</figure>
</section>
</section>
<section class="ltx_appendix" id="A7">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix G </span>Deployment Guidance</h2>
<div class="ltx_para" id="A7.p1">
<p class="ltx_p" id="A7.p1.1">To facilitate real-world applications and future work, we provide a detailed guidance on the deployment of <span class="ltx_text ltx_font_italic" id="A7.p1.1.1">KnowledgeSG</span>. The framework involves three main stages.</p>
</div>
<section class="ltx_paragraph" id="A7.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Preparations and Transmitting Unit.</h4>
<div class="ltx_para" id="A7.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="A7.SS0.SSS0.Px1.p1.1">(1) Prepare the base model, e.g. Llama2-7B and establish a code base that can do normal-finetuning of LLMs, e.g. LlamaFactory.
(2) Establish a communication channel and sample a small amount of data to construct the seed dataset sharing between the client and server.
(3) Fine-tune the base model on this seed dataset to obtain a modified base model on both client side and server side.</p>
</div>
</section>
<section class="ltx_paragraph" id="A7.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Client Side.</h4>
<div class="ltx_para" id="A7.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="A7.SS0.SSS0.Px2.p1.1">(1) Prepare the private dataset intended for use.
(2) Establish a code base that can achieve DP-finetuning of LLMs.</p>
</div>
</section>
<section class="ltx_paragraph" id="A7.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Server Side.</h4>
<div class="ltx_para" id="A7.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="A7.SS0.SSS0.Px3.p1.1">(1) Prepare the professional model. Most of open-sourced large language models can be easily downloaded from the HuggingFace website.
(2) Write a code that can inference LLMs and design the prompts which are related to the professional model we choose.</p>
</div>
<div class="ltx_para" id="A7.SS0.SSS0.Px3.p2">
<p class="ltx_p" id="A7.SS0.SSS0.Px3.p2.1">After this deployment, we can apply <span class="ltx_text ltx_font_italic" id="A7.SS0.SSS0.Px3.p2.1.1">KnowledgeSG</span> in a client-server framework and obtain the desired model.</p>
</div>
</section>
</section>
<section class="ltx_appendix" id="A8">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix H </span>Templates</h2>
<figure class="ltx_figure" id="A8.F6">
<div class="ltx_logical-block ltx_parbox ltx_align_middle" id="A8.F6.1" style="width:216.8pt;">
<div class="ltx_para ltx_noindent" id="A8.F6.1.p1">
<svg class="ltx_picture" height="156.09" id="A8.F6.1.p1.pic1" overflow="visible" version="1.1" width="290.58"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,156.09) matrix(1 0 0 -1 0 0)"><g fill="#000000" fill-opacity="1.0"><path d="M 0 5.91 L 0 150.18 C 0 153.45 2.64 156.09 5.91 156.09 L 284.67 156.09 C 287.93 156.09 290.58 153.45 290.58 150.18 L 290.58 5.91 C 290.58 2.64 287.93 0 284.67 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F9F9F9" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 150.18 C 1.97 152.36 3.73 154.12 5.91 154.12 L 284.67 154.12 C 286.85 154.12 288.61 152.36 288.61 150.18 L 288.61 5.91 C 288.61 3.73 286.85 1.97 284.67 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="128.53" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="247.27">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A8.F6.1.p1.pic1.1.1.1.1.1" style="width:178.7pt;">
<span class="ltx_p" id="A8.F6.1.p1.pic1.1.1.1.1.1.1">Below is an instruction that describes a task. Write a response that appropriately completes the request.</span>
<span class="ltx_p" id="A8.F6.1.p1.pic1.1.1.1.1.1.2">### Instruction:</span>
<span class="ltx_p" id="A8.F6.1.p1.pic1.1.1.1.1.1.3">{Instruction}</span>
<span class="ltx_p" id="A8.F6.1.p1.pic1.1.1.1.1.1.4">### Response:</span>
</span></foreignobject></g></g></svg>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Templates-1</figcaption>
</figure>
<figure class="ltx_figure" id="A8.F7"><svg class="ltx_picture" height="309.83" id="A8.F7.pic1" overflow="visible" version="1.1" width="290.58"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,309.83) matrix(1 0 0 -1 0 0)"><g fill="#000000" fill-opacity="1.0"><path d="M 0 5.91 L 0 303.93 C 0 307.19 2.64 309.83 5.91 309.83 L 284.67 309.83 C 287.93 309.83 290.58 307.19 290.58 303.93 L 290.58 5.91 C 290.58 2.64 287.93 0 284.67 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F9F9F9" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 303.93 C 1.97 306.1 3.73 307.87 5.91 307.87 L 284.67 307.87 C 286.85 307.87 288.61 306.1 288.61 303.93 L 288.61 5.91 C 288.61 3.73 286.85 1.97 284.67 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="282.27" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="247.27">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A8.F7.pic1.1.1.1.1.1" style="width:178.7pt;">
<span class="ltx_p" id="A8.F7.pic1.1.1.1.1.1.1">Based on the following examples, please generate a new and unique example that is different and follows the underlying pattern or theme. Try to make your generation as diverse as possible.</span>
<span class="ltx_p" id="A8.F7.pic1.1.1.1.1.1.2">## Example:</span>
<span class="ltx_p" id="A8.F7.pic1.1.1.1.1.1.3">### Instruction: {Instruction 1}</span>
<span class="ltx_p" id="A8.F7.pic1.1.1.1.1.1.4">### Response: {Response 1}</span>
<span class="ltx_p" id="A8.F7.pic1.1.1.1.1.1.5">## Example:</span>
<span class="ltx_p" id="A8.F7.pic1.1.1.1.1.1.6">### Instruction: {Instruction 2}</span>
<span class="ltx_p" id="A8.F7.pic1.1.1.1.1.1.7">### Response: {Response 2}</span>
<span class="ltx_p" id="A8.F7.pic1.1.1.1.1.1.8">## Example:</span>
</span></foreignobject></g></g></svg>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Templates-2</figcaption>
</figure>
<figure class="ltx_figure" id="A8.F8"><svg class="ltx_picture" height="172.69" id="A8.F8.pic1" overflow="visible" version="1.1" width="290.58"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,172.69) matrix(1 0 0 -1 0 0)"><g fill="#000000" fill-opacity="1.0"><path d="M 0 5.91 L 0 166.79 C 0 170.05 2.64 172.69 5.91 172.69 L 284.67 172.69 C 287.93 172.69 290.58 170.05 290.58 166.79 L 290.58 5.91 C 290.58 2.64 287.93 0 284.67 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F9F9F9" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 166.79 C 1.97 168.96 3.73 170.73 5.91 170.73 L 284.67 170.73 C 286.85 170.73 288.61 168.96 288.61 166.79 L 288.61 5.91 C 288.61 3.73 286.85 1.97 284.67 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="145.13" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="247.27">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A8.F8.pic1.1.1.1.1.1" style="width:178.7pt;">
<span class="ltx_p" id="A8.F8.pic1.1.1.1.1.1.1">Come up with a series of tasks:</span>
<span class="ltx_p" id="A8.F8.pic1.1.1.1.1.1.2">## Example:</span>
<span class="ltx_p" id="A8.F8.pic1.1.1.1.1.1.3">### Instruction: {Instruction 1}</span>
<span class="ltx_p" id="A8.F8.pic1.1.1.1.1.1.4">## Example:</span>
<span class="ltx_p" id="A8.F8.pic1.1.1.1.1.1.5">### Instruction: {Instruction 2}</span>
<span class="ltx_p" id="A8.F8.pic1.1.1.1.1.1.6">## Example:</span>
<span class="ltx_p" id="A8.F8.pic1.1.1.1.1.1.7">### Instruction:</span>
</span></foreignobject></g></g></svg>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Templates-3</figcaption>
</figure>
<figure class="ltx_figure" id="A8.F9"><svg class="ltx_picture" height="205.9" id="A8.F9.pic1" overflow="visible" version="1.1" width="290.58"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,205.9) matrix(1 0 0 -1 0 0)"><g fill="#000000" fill-opacity="1.0"><path d="M 0 5.91 L 0 200 C 0 203.26 2.64 205.9 5.91 205.9 L 284.67 205.9 C 287.93 205.9 290.58 203.26 290.58 200 L 290.58 5.91 C 290.58 2.64 287.93 0 284.67 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F9F9F9" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 200 C 1.97 202.17 3.73 203.93 5.91 203.93 L 284.67 203.93 C 286.85 203.93 288.61 202.17 288.61 200 L 288.61 5.91 C 288.61 3.73 286.85 1.97 284.67 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="178.34" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="247.27">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A8.F9.pic1.1.1.1.1.1" style="width:178.7pt;">
<span class="ltx_p" id="A8.F9.pic1.1.1.1.1.1.1">Come up with examples for the following tasks. Try to generate multiple examples when possible. If the task doesn’t require additional input, you can generate the output directly.</span>
<span class="ltx_p" id="A8.F9.pic1.1.1.1.1.1.2">{Examples if ICL used}</span>
<span class="ltx_p" id="A8.F9.pic1.1.1.1.1.1.3">### {Generated_Instruction}</span>
<span class="ltx_p" id="A8.F9.pic1.1.1.1.1.1.4">### Response:</span>
</span></foreignobject></g></g></svg>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Templates-4</figcaption>
</figure>
<figure class="ltx_figure" id="A8.F10"><svg class="ltx_picture" height="103.59" id="A8.F10.pic1" overflow="visible" version="1.1" width="290.58"><g fill="#000000" stroke="#000000" stroke-width="0.4pt" transform="translate(0,103.59) matrix(1 0 0 -1 0 0)"><g fill="#000000" fill-opacity="1.0"><path d="M 0 5.91 L 0 97.68 C 0 100.94 2.64 103.59 5.91 103.59 L 284.67 103.59 C 287.93 103.59 290.58 100.94 290.58 97.68 L 290.58 5.91 C 290.58 2.64 287.93 0 284.67 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F9F9F9" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 97.68 C 1.97 99.85 3.73 101.62 5.91 101.62 L 284.67 101.62 C 286.85 101.62 288.61 99.85 288.61 97.68 L 288.61 5.91 C 288.61 3.73 286.85 1.97 284.67 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 21.65 13.78)"><foreignobject color="#000000" height="76.03" overflow="visible" transform="matrix(1 0 0 -1 0 16.6)" width="247.27">
<span class="ltx_inline-block ltx_minipage ltx_align_bottom" id="A8.F10.pic1.1.1.1.1.1" style="width:178.7pt;">
<span class="ltx_p" id="A8.F10.pic1.1.1.1.1.1.1">If you are a doctor, please answer the medical questions based on the patient’s description.</span>
<span class="ltx_p" id="A8.F10.pic1.1.1.1.1.1.2">Patient: {instruction} Does my instruction invovles medicine?</span>
<span class="ltx_p" id="A8.F10.pic1.1.1.1.1.1.3">ChatDoctor:</span>
</span></foreignobject></g></g></svg>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Templates-5</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Oct 10 03:58:46 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
