<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2211.07893] Federated Learning for Healthcare Domain - Pipeline, Applications and Challenges</title><meta property="og:description" content="Federated learning is the process of developing machine learning models over datasets distributed across data centers such as hospitals, clinical research labs, and mobile devices while preventing data leakage. This suâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Learning for Healthcare Domain - Pipeline, Applications and Challenges">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Learning for Healthcare Domain - Pipeline, Applications and Challenges">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2211.07893">

<!--Generated on Thu Mar 14 06:44:18 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="federated learning,  GDPR,  transfer learning">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line ltx_leqno">
<h1 class="ltx_title ltx_title_document">Federated Learning for Healthcare Domain - Pipeline, Applications and Challenges</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Madhura Joshi
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:m.joshi@saama.com">m.joshi@saama.com</a>
</span></span></span>
<span class="ltx_author_before">,Â </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ankit Pal
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:ankit.pal@saama.com">ankit.pal@saama.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_text ltx_affiliation_institution">Saama AI Research</span><span id="id2.2.id2" class="ltx_text ltx_affiliation_city">Chennai</span><span id="id3.3.id3" class="ltx_text ltx_affiliation_country">India</span>
</span></span></span>
<span class="ltx_author_before">Â andÂ </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Malaikannan Sankarasubbu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id4.1.id1" class="ltx_text ltx_affiliation_institution">Saama AI Research</span><span id="id5.2.id2" class="ltx_text ltx_affiliation_city">Chennai</span><span id="id6.3.id3" class="ltx_text ltx_affiliation_country">India</span>
</span>
<span class="ltx_contact ltx_role_email"><a href="mailto:malaikannan.sankarasubbu@saama.com">malaikannan.sankarasubbu@saama.com</a>
</span></span></span>
</div>
<div class="ltx_dates">(2022)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id7.id1" class="ltx_p">Federated learning is the process of developing machine learning models over datasets distributed across data centers such as hospitals, clinical research labs, and mobile devices while preventing data leakage. This survey examines previous research and studies on federated learning in the healthcare sector across a range of use cases and applications. Our survey shows what challenges, methods, and applications a practitioner should be aware of in the topic of federated learning. This paper aims to lay out existing research and list the possibilities of federated learning for healthcare industries.</p>
</div>
<div class="ltx_keywords">federated learning, GDPR, transfer learning
</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_journalyear"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">journalyear: </span>2022</span></span></span><span id="id2" class="ltx_note ltx_note_frontmatter ltx_role_doi"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">doi: </span>10.1145/3533708</span></span></span><span id="id3" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Security and privacy</span></span></span><span id="id4" class="ltx_note ltx_note_frontmatter ltx_role_ccs"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">â€ </sup><span class="ltx_note_type">ccs: </span>Computing methodologiesÂ Artificial intelligence</span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span><span id="S1.1.1" class="ltx_text ltx_font_bold">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">In the last few years, digital healthcare data has grown significantly. At the same time, recent breakthroughs in deep learning (DL) have been used in a variety of current medical data processes, including automatic disease diagnosis <cite class="ltx_cite ltx_citemacro_citep">(Liu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib75" title="" class="ltx_ref">2020</a>; Rajan
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib94" title="" class="ltx_ref">2019</a>)</cite>, classification, biomedical data analysis, Question Answering in the medical domain <cite class="ltx_cite ltx_citemacro_citep">(Pal
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib86" title="" class="ltx_ref">2022</a>)</cite> and segmentation <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib70" title="" class="ltx_ref">2015</a>; Menze etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib79" title="" class="ltx_ref">2015</a>)</cite>. These methods hold immense promise and innovation in this field. In the coming future, the advancement of these methods will refine health care systems and improve medical practices worldwide.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Diagnostic tools, machine learning (ML) based healthcare solutions, and models must be exposed to a wide variety of cases and data that cover a full range of possible anatomies to capture more informative patterns in the medical data. It is well known that data from a single source can be significantly biased by the equipment, demographics, and acquisition protocol. Therefore, training a model on data from a single source would skew its prediction performance towards the population. Moreover, it is computationally expensive and time-consuming.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Training models in a parallelized manner <cite class="ltx_cite ltx_citemacro_citep">(Dean
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib31" title="" class="ltx_ref">2012</a>)</cite> and within small batches can mitigate a few of these challenges. However, though this approach addresses computation challenges, it does not necessarily preserve the privacy of data.
Clinical research often involves studies from a large amount of data collected from various sources. Health institutions, individuals, insurance companies, and the pharmaceutical industry all have access to medical data. Furthermore, each institution may be linked to a unique collection of stakeholders. These data are often sensitive and cannot be aggregated or accessed.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Access to a large amount of high-quality medical data is possibly the most crucial factor for enhancing Machine Learning (ML) applications in the healthcare domain. However, security and privacy issues of healthcare data have raised broad ethical and legal concerns in recent years, given the sensitive nature of health information <cite class="ltx_cite ltx_citemacro_citep">(Adam
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib2" title="" class="ltx_ref">2007</a>)</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">The assembly and transmission of these datasets are ethically and legally required to protect patient privacy. Most healthcare centers, laws at the country level, and regulatory bodies, e.g., the General Data Protection Regulation (GDPR) and the Health Insurance Portability and Accountability Act (HIPAA), have passed new laws that control sharing data while preserving user security and privacy<cite class="ltx_cite ltx_citemacro_citep">(Yang
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib129" title="" class="ltx_ref">2019b</a>; Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2020a</a>)</cite>. Moreover, information and control about medical data storage, transmission, and usage are central to patient rights.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">The sensitive and distributed nature of EHR (Electronic Health Records) in real-world scenarios simulates a need for an effective mechanism to learn from data residing in health-related institutions, hospitals while accounting for data privacy. This motivates us to examine the potential and value of federated learning for the healthcare domain. Federated Learning is an advanced distributed learning technique that leverages datasets from various universities without explicitly centralizing or sharing the training data. <cite class="ltx_cite ltx_citemacro_citep">(Li
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2020b</a>; Yang
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib128" title="" class="ltx_ref">2019a</a>)</cite>.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">Federated learning provides many advantages as compared to centralized learning. It enables training a global model from distributed data. This method also focuses on preserving data privacy by only sharing mathematical parameters and metadata while keeping the actual data as secure as possible and preventing attacks and tracebacks.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">The global ML model is distributed to each client site, where an instance is trained locally. The updates from locally trained instances are then aggregated at regular intervals to improve the global model. The updated global model is then sent back to the local devices, where the learning continues. These steps are repeated until a particular convergence threshold is satisfied or lasts for a long time to improve the deep learning model continuously.</p>
</div>
<div id="S1.p9" class="ltx_para">
<p id="S1.p9.1" class="ltx_p">The parameters and metadata sharing depend on many factors such as use cases, data management and regulation, business agreement and protection, pipeline, and infrastructure. In this article, we provide an overview of the federated learning approach in the healthcare domain. Our contribution is as follows</p>
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We demonstrate the components of the federated learning setup and discuss the communication architecture and building blocks of a federated learning system.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We examine the various challenges that a federated learning setup faces in terms of privacy, data, and communication in the healthcare system.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We survey existing works on federated learning in the health sector and propose a comprehensive list of applications classified into prognosis, diagnosis, and clinical workflow.</p>
</div>
</li>
</ul>
</div>
<div id="S1.p10" class="ltx_para">
<p id="S1.p10.1" class="ltx_p">The structure of the paper is as follows; the first section describes the components of a federated learning setup as well as a federated learning pipeline. Section 2 discusses the challenges and concerns of federated learning in the healthcare area. Section 3 concludes with a study of federated learning applications in the health care area and the tools required for implementation.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span><span id="S2.1.1" class="ltx_text ltx_font_bold">PIPELINE</span>
</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span><span id="S2.SS1.1.1" class="ltx_text ltx_font_bold">Architecture of Communication</span>
</h3>

<section id="S2.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.1. </span>Centralized</h4>

<div id="S2.SS1.SSS1.p1" class="ltx_para">
<p id="S2.SS1.SSS1.p1.1" class="ltx_p">Centralized federated learning architecture is the most commonly used architecture.
In this setting, data flows in asymmetric nature. A central server is responsible for aggregating the information (e.g., local models) from the data owners, coordinating with all the participating client devices, and sending back the model updates. Client devices usually communicate only with the server; hence the server acts as a system bottleneck. However, Single-point failure is one of the drawbacks in a centralized setting.</p>
</div>
<div id="S2.SS1.SSS1.p2" class="ltx_para">
<p id="S2.SS1.SSS1.p2.1" class="ltx_p">The following is the architecture of centralized federated learning: first, a global model is sent to client devices. Second, the global model is being updated with client data. Third, the revised model is sent back to the server. Finally, local models are averaged on the server to create a new global model. Furthermore, this process is repeated. The architecture of centralized federated learning is shown in figure 1.</p>
</div>
<div id="S2.SS1.SSS1.p3" class="ltx_para">
<p id="S2.SS1.SSS1.p3.1" class="ltx_p">Google uses the centralized architecture design in their Android keyboard setting. The central server collects the local model information from usersâ€™ mobile devices and updates the global model, and later the updates are sent back to the users for inferences. FedAvg is one such example of a centralized framework<cite class="ltx_cite ltx_citemacro_citep">(McMahan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib78" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<figure id="S2.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2211.07893/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="302" height="140" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span>Illustration of centralized architecture in federated learning</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S2.F1.1" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S2.F1.2" class="ltx_p ltx_figure_panel ltx_align_center">A woman and a girl in white dresses sit in an open car.</p>
</div>
</div>
</figure>
</section>
<section id="S2.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.1.2. </span>Decentralized</h4>

<div id="S2.SS1.SSS2.p1" class="ltx_para">
<p id="S2.SS1.SSS2.p1.1" class="ltx_p">In the decentralized, federated learning architecture, the client devices can communicate to train a global model and update it directly without any central server. A decentralized setup prevents the single point failure issue. SimFL is a federated, decentralized framework <cite class="ltx_cite ltx_citemacro_citep">(Li
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib69" title="" class="ltx_ref">2020b</a>)</cite>.</p>
</div>
<div id="S2.SS1.SSS2.p2" class="ltx_para">
<p id="S2.SS1.SSS2.p2.1" class="ltx_p">The following is the architecture of decentralized, federated learning: first, the local gradients are updated. Second, these gradients are sent to selected parties. Third, the model is updated with local data and gradients. Lastly, the updated model is sent to other parties, and the process continues. The architecture of decentralized, federated learning is shown in figure 2. This method is usually preferred because it involves exchanging of local models which are aggregations of large quantity of data. However, decentralized federated learning works on the concept of mutual trust between the users which leads to few drawbacks.The question arises when one has to use DFL in a single sided trust environment. A decentralized learning algorithm called Online Push Sum (OPS)<cite class="ltx_cite ltx_citemacro_citep">(He
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib48" title="" class="ltx_ref">2020d</a>)</cite> addresses this challenge.It involves a rigorous regret analysis, tested and compared with other algorithms like Decentralized Online Gradient (DOG) and Centralized Online Gradient (COG).</p>
</div>
<div id="S2.SS1.SSS2.p3" class="ltx_para">
<p id="S2.SS1.SSS2.p3.1" class="ltx_p">Blockchain is an excellent example of a decentralized platform <cite class="ltx_cite ltx_citemacro_citep">(Zheng
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib135" title="" class="ltx_ref">2018</a>)</cite>. Another example of a similar design is the decentralized cancer diagnostic system amongst hospitals/medical institutions. Each hospital distributes the local model that has been trained with patient data and acquires the global model for future diagnosis <cite class="ltx_cite ltx_citemacro_citep">(Sarma etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib100" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<figure id="S2.F2" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2211.07893/assets/x2.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="242" height="134" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span>Illustration of decentralized architecture in federated learning</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S2.F2.1" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S2.F2.2" class="ltx_p ltx_figure_panel ltx_align_center">A woman and a girl in white dresses sit in an open car.</p>
</div>
</div>
</figure>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span><span id="S2.SS2.1.1" class="ltx_text ltx_font_bold">Scale of Federated Learning system</span>
</h3>

<section id="S2.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.1. </span>Cross-Silo</h4>

<div id="S2.SS2.SSS1.p1" class="ltx_para">
<p id="S2.SS2.SSS1.p1.1" class="ltx_p">In a Cross-Silo federated learning setting, small numbers of organizations or data centers (e.g., medical or financial) train a global model with a large amount of data along with computation power. In an environment where organizations are prohibited from sharing their data due to data privacy and security reasons, cross-silo federated learning comes into the picture. The computation and storage capacity of the cross-silo setting is high on a relatively small scale, while the stability is low compared to cross-device.</p>
</div>
</section>
<section id="S2.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.2.2. </span>Cross-Device</h4>

<div id="S2.SS2.SSS2.p1" class="ltx_para">
<p id="S2.SS2.SSS2.p1.1" class="ltx_p">In a Cross-Device federated learning setting, there are a scalable number of clients with small amounts of data compared to a cross-silo setting where there are only a few clients with large amounts of data. As a result, the cross-device system develops models for large-scale dispersed data inside the same application <cite class="ltx_cite ltx_citemacro_citep">(Lo
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib76" title="" class="ltx_ref">2021</a>)</cite>; the clients can be enabled and disabled as per the requirement and are usually mobile and IoT devices. The system should be powerful enough to manage many devices and handle common failures such as unstable connections, power failure, etc.</p>
</div>
</section>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span><span id="S2.SS3.1.1" class="ltx_text ltx_font_bold">Federated Server</span>
</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p">The central server serves as a manager in a cross-device environment. It oversees the communication between the client devices, the server, and the global machine learning model. At the beginning of the federated learning training process, the client starts a server training service; a login request is required from each client-side to join the server training session.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">The server will check the credentials to validate the request and allow the clients to join the session only in a successful authentication. The server session decides the minimum and a maximum number of client devices that need to be added to start the training process.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">In a decentralized environment, all devices interact directly with one another and participate equally in global model training. The server, in this case, is all of the local devices. Practical Federated Gradient Boosting Decision Trees <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib71" title="" class="ltx_ref">2019</a>)</cite> is an example of such a framework, in which each device trains decision trees sequentially, and the final model is the sum of all the trees. Designing a completely decentralized FLS with appropriate communication overhead is difficult.</p>
</div>
<div id="S2.SS3.p4" class="ltx_para">
<p id="S2.SS3.p4.1" class="ltx_p">Each local model training happens on the clientâ€™s side, so the server does not need access to the model training data. Moreover, local models only share the model updates instead of the actual copy of data. The clientâ€™s devices decide the number of epochs to run during each round of training. Typically, the computing is used for model training and aggregation, while the communication is used to exchange model parameters.</p>
</div>
<div id="S2.SS3.p5" class="ltx_para">
<p id="S2.SS3.p5.1" class="ltx_p">Once the server receives all the model updates from all the participating devices, it performs the model aggregation based on the selected aggregation algorithm and gets the overall updated global model. This process completes the single round of the Federated Learning session. Furthermore, the next round starts and training continues until the maximum number of rounds on the server is completed. The aggregation technique aids in the gathering of model updates from local models of the devices. Listed below are some popular application-oriented aggregation algorithms in detail.</p>
</div>
<div id="S2.SS3.p6" class="ltx_para">
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p"><span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">FedAvg Algorithm</span>
FedAvg is the first and most widely used Federated learning algorithm proposed by Google <cite class="ltx_cite ltx_citemacro_citep">(McMahan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib78" title="" class="ltx_ref">2017</a>)</cite>. It distributes training data across mobile devices and trains a shared model by combining locally calculated updates. The FedAvg algorithm is a robust approach experimented on five different architectures, four kinds of datasets, and combined stochastic gradient descent on each client with a server that performs model averaging. The algorithm can be written as</p>
</div>
<div id="S2.I1.i1.p2" class="ltx_para">
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_left"><span class="ltx_tag ltx_tag_equation ltx_align_left">(1)</span></td>
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.7" class="ltx_Math" alttext="f(w)=\sum_{k=1}^{K}\frac{n_{k}}{n}F_{k}(w)\quad\text{ where }\quad F_{k}(w)=\frac{1}{n_{k}}\sum_{i\in\mathcal{P}_{k}}f_{i}(w)" display="block"><semantics id="S2.E1.m1.7a"><mrow id="S2.E1.m1.7.7.2" xref="S2.E1.m1.7.7.3.cmml"><mrow id="S2.E1.m1.6.6.1.1" xref="S2.E1.m1.6.6.1.1.cmml"><mrow id="S2.E1.m1.6.6.1.1.3" xref="S2.E1.m1.6.6.1.1.3.cmml"><mi id="S2.E1.m1.6.6.1.1.3.2" xref="S2.E1.m1.6.6.1.1.3.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.6.6.1.1.3.1" xref="S2.E1.m1.6.6.1.1.3.1.cmml">â€‹</mo><mrow id="S2.E1.m1.6.6.1.1.3.3.2" xref="S2.E1.m1.6.6.1.1.3.cmml"><mo stretchy="false" id="S2.E1.m1.6.6.1.1.3.3.2.1" xref="S2.E1.m1.6.6.1.1.3.cmml">(</mo><mi id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">w</mi><mo stretchy="false" id="S2.E1.m1.6.6.1.1.3.3.2.2" xref="S2.E1.m1.6.6.1.1.3.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S2.E1.m1.6.6.1.1.2" xref="S2.E1.m1.6.6.1.1.2.cmml">=</mo><mrow id="S2.E1.m1.6.6.1.1.1.1" xref="S2.E1.m1.6.6.1.1.1.2.cmml"><mrow id="S2.E1.m1.6.6.1.1.1.1.1" xref="S2.E1.m1.6.6.1.1.1.1.1.cmml"><munderover id="S2.E1.m1.6.6.1.1.1.1.1.1" xref="S2.E1.m1.6.6.1.1.1.1.1.1.cmml"><mo movablelimits="false" id="S2.E1.m1.6.6.1.1.1.1.1.1.2.2" xref="S2.E1.m1.6.6.1.1.1.1.1.1.2.2.cmml">âˆ‘</mo><mrow id="S2.E1.m1.6.6.1.1.1.1.1.1.2.3" xref="S2.E1.m1.6.6.1.1.1.1.1.1.2.3.cmml"><mi id="S2.E1.m1.6.6.1.1.1.1.1.1.2.3.2" xref="S2.E1.m1.6.6.1.1.1.1.1.1.2.3.2.cmml">k</mi><mo id="S2.E1.m1.6.6.1.1.1.1.1.1.2.3.1" xref="S2.E1.m1.6.6.1.1.1.1.1.1.2.3.1.cmml">=</mo><mn id="S2.E1.m1.6.6.1.1.1.1.1.1.2.3.3" xref="S2.E1.m1.6.6.1.1.1.1.1.1.2.3.3.cmml">1</mn></mrow><mi id="S2.E1.m1.6.6.1.1.1.1.1.1.3" xref="S2.E1.m1.6.6.1.1.1.1.1.1.3.cmml">K</mi></munderover><mrow id="S2.E1.m1.6.6.1.1.1.1.1.2" xref="S2.E1.m1.6.6.1.1.1.1.1.2.cmml"><mfrac id="S2.E1.m1.6.6.1.1.1.1.1.2.2" xref="S2.E1.m1.6.6.1.1.1.1.1.2.2.cmml"><msub id="S2.E1.m1.6.6.1.1.1.1.1.2.2.2" xref="S2.E1.m1.6.6.1.1.1.1.1.2.2.2.cmml"><mi id="S2.E1.m1.6.6.1.1.1.1.1.2.2.2.2" xref="S2.E1.m1.6.6.1.1.1.1.1.2.2.2.2.cmml">n</mi><mi id="S2.E1.m1.6.6.1.1.1.1.1.2.2.2.3" xref="S2.E1.m1.6.6.1.1.1.1.1.2.2.2.3.cmml">k</mi></msub><mi id="S2.E1.m1.6.6.1.1.1.1.1.2.2.3" xref="S2.E1.m1.6.6.1.1.1.1.1.2.2.3.cmml">n</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.E1.m1.6.6.1.1.1.1.1.2.1" xref="S2.E1.m1.6.6.1.1.1.1.1.2.1.cmml">â€‹</mo><msub id="S2.E1.m1.6.6.1.1.1.1.1.2.3" xref="S2.E1.m1.6.6.1.1.1.1.1.2.3.cmml"><mi id="S2.E1.m1.6.6.1.1.1.1.1.2.3.2" xref="S2.E1.m1.6.6.1.1.1.1.1.2.3.2.cmml">F</mi><mi id="S2.E1.m1.6.6.1.1.1.1.1.2.3.3" xref="S2.E1.m1.6.6.1.1.1.1.1.2.3.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.6.6.1.1.1.1.1.2.1a" xref="S2.E1.m1.6.6.1.1.1.1.1.2.1.cmml">â€‹</mo><mrow id="S2.E1.m1.6.6.1.1.1.1.1.2.4.2" xref="S2.E1.m1.6.6.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.E1.m1.6.6.1.1.1.1.1.2.4.2.1" xref="S2.E1.m1.6.6.1.1.1.1.1.2.cmml">(</mo><mi id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml">w</mi><mo stretchy="false" id="S2.E1.m1.6.6.1.1.1.1.1.2.4.2.2" xref="S2.E1.m1.6.6.1.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow><mspace width="1em" id="S2.E1.m1.6.6.1.1.1.1.2" xref="S2.E1.m1.6.6.1.1.1.2.cmml"></mspace><mtext id="S2.E1.m1.5.5" xref="S2.E1.m1.5.5a.cmml">Â whereÂ </mtext></mrow></mrow><mspace width="1em" id="S2.E1.m1.7.7.2.3" xref="S2.E1.m1.7.7.3a.cmml"></mspace><mrow id="S2.E1.m1.7.7.2.2" xref="S2.E1.m1.7.7.2.2.cmml"><mrow id="S2.E1.m1.7.7.2.2.2" xref="S2.E1.m1.7.7.2.2.2.cmml"><msub id="S2.E1.m1.7.7.2.2.2.2" xref="S2.E1.m1.7.7.2.2.2.2.cmml"><mi id="S2.E1.m1.7.7.2.2.2.2.2" xref="S2.E1.m1.7.7.2.2.2.2.2.cmml">F</mi><mi id="S2.E1.m1.7.7.2.2.2.2.3" xref="S2.E1.m1.7.7.2.2.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.7.7.2.2.2.1" xref="S2.E1.m1.7.7.2.2.2.1.cmml">â€‹</mo><mrow id="S2.E1.m1.7.7.2.2.2.3.2" xref="S2.E1.m1.7.7.2.2.2.cmml"><mo stretchy="false" id="S2.E1.m1.7.7.2.2.2.3.2.1" xref="S2.E1.m1.7.7.2.2.2.cmml">(</mo><mi id="S2.E1.m1.3.3" xref="S2.E1.m1.3.3.cmml">w</mi><mo stretchy="false" id="S2.E1.m1.7.7.2.2.2.3.2.2" xref="S2.E1.m1.7.7.2.2.2.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.7.7.2.2.1" xref="S2.E1.m1.7.7.2.2.1.cmml">=</mo><mrow id="S2.E1.m1.7.7.2.2.3" xref="S2.E1.m1.7.7.2.2.3.cmml"><mfrac id="S2.E1.m1.7.7.2.2.3.2" xref="S2.E1.m1.7.7.2.2.3.2.cmml"><mn id="S2.E1.m1.7.7.2.2.3.2.2" xref="S2.E1.m1.7.7.2.2.3.2.2.cmml">1</mn><msub id="S2.E1.m1.7.7.2.2.3.2.3" xref="S2.E1.m1.7.7.2.2.3.2.3.cmml"><mi id="S2.E1.m1.7.7.2.2.3.2.3.2" xref="S2.E1.m1.7.7.2.2.3.2.3.2.cmml">n</mi><mi id="S2.E1.m1.7.7.2.2.3.2.3.3" xref="S2.E1.m1.7.7.2.2.3.2.3.3.cmml">k</mi></msub></mfrac><mo lspace="0em" rspace="0em" id="S2.E1.m1.7.7.2.2.3.1" xref="S2.E1.m1.7.7.2.2.3.1.cmml">â€‹</mo><mrow id="S2.E1.m1.7.7.2.2.3.3" xref="S2.E1.m1.7.7.2.2.3.3.cmml"><munder id="S2.E1.m1.7.7.2.2.3.3.1" xref="S2.E1.m1.7.7.2.2.3.3.1.cmml"><mo movablelimits="false" id="S2.E1.m1.7.7.2.2.3.3.1.2" xref="S2.E1.m1.7.7.2.2.3.3.1.2.cmml">âˆ‘</mo><mrow id="S2.E1.m1.7.7.2.2.3.3.1.3" xref="S2.E1.m1.7.7.2.2.3.3.1.3.cmml"><mi id="S2.E1.m1.7.7.2.2.3.3.1.3.2" xref="S2.E1.m1.7.7.2.2.3.3.1.3.2.cmml">i</mi><mo id="S2.E1.m1.7.7.2.2.3.3.1.3.1" xref="S2.E1.m1.7.7.2.2.3.3.1.3.1.cmml">âˆˆ</mo><msub id="S2.E1.m1.7.7.2.2.3.3.1.3.3" xref="S2.E1.m1.7.7.2.2.3.3.1.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.7.7.2.2.3.3.1.3.3.2" xref="S2.E1.m1.7.7.2.2.3.3.1.3.3.2.cmml">ğ’«</mi><mi id="S2.E1.m1.7.7.2.2.3.3.1.3.3.3" xref="S2.E1.m1.7.7.2.2.3.3.1.3.3.3.cmml">k</mi></msub></mrow></munder><mrow id="S2.E1.m1.7.7.2.2.3.3.2" xref="S2.E1.m1.7.7.2.2.3.3.2.cmml"><msub id="S2.E1.m1.7.7.2.2.3.3.2.2" xref="S2.E1.m1.7.7.2.2.3.3.2.2.cmml"><mi id="S2.E1.m1.7.7.2.2.3.3.2.2.2" xref="S2.E1.m1.7.7.2.2.3.3.2.2.2.cmml">f</mi><mi id="S2.E1.m1.7.7.2.2.3.3.2.2.3" xref="S2.E1.m1.7.7.2.2.3.3.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.7.7.2.2.3.3.2.1" xref="S2.E1.m1.7.7.2.2.3.3.2.1.cmml">â€‹</mo><mrow id="S2.E1.m1.7.7.2.2.3.3.2.3.2" xref="S2.E1.m1.7.7.2.2.3.3.2.cmml"><mo stretchy="false" id="S2.E1.m1.7.7.2.2.3.3.2.3.2.1" xref="S2.E1.m1.7.7.2.2.3.3.2.cmml">(</mo><mi id="S2.E1.m1.4.4" xref="S2.E1.m1.4.4.cmml">w</mi><mo stretchy="false" id="S2.E1.m1.7.7.2.2.3.3.2.3.2.2" xref="S2.E1.m1.7.7.2.2.3.3.2.cmml">)</mo></mrow></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.7b"><apply id="S2.E1.m1.7.7.3.cmml" xref="S2.E1.m1.7.7.2"><csymbol cd="ambiguous" id="S2.E1.m1.7.7.3a.cmml" xref="S2.E1.m1.7.7.2.3">formulae-sequence</csymbol><apply id="S2.E1.m1.6.6.1.1.cmml" xref="S2.E1.m1.6.6.1.1"><eq id="S2.E1.m1.6.6.1.1.2.cmml" xref="S2.E1.m1.6.6.1.1.2"></eq><apply id="S2.E1.m1.6.6.1.1.3.cmml" xref="S2.E1.m1.6.6.1.1.3"><times id="S2.E1.m1.6.6.1.1.3.1.cmml" xref="S2.E1.m1.6.6.1.1.3.1"></times><ci id="S2.E1.m1.6.6.1.1.3.2.cmml" xref="S2.E1.m1.6.6.1.1.3.2">ğ‘“</ci><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">ğ‘¤</ci></apply><list id="S2.E1.m1.6.6.1.1.1.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1"><apply id="S2.E1.m1.6.6.1.1.1.1.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1"><apply id="S2.E1.m1.6.6.1.1.1.1.1.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1">superscript</csymbol><apply id="S2.E1.m1.6.6.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.6.6.1.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1">subscript</csymbol><sum id="S2.E1.m1.6.6.1.1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.2.2"></sum><apply id="S2.E1.m1.6.6.1.1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.2.3"><eq id="S2.E1.m1.6.6.1.1.1.1.1.1.2.3.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.2.3.1"></eq><ci id="S2.E1.m1.6.6.1.1.1.1.1.1.2.3.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.2.3.2">ğ‘˜</ci><cn type="integer" id="S2.E1.m1.6.6.1.1.1.1.1.1.2.3.3.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.2.3.3">1</cn></apply></apply><ci id="S2.E1.m1.6.6.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.1.3">ğ¾</ci></apply><apply id="S2.E1.m1.6.6.1.1.1.1.1.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.2"><times id="S2.E1.m1.6.6.1.1.1.1.1.2.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.2.1"></times><apply id="S2.E1.m1.6.6.1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.2.2"><divide id="S2.E1.m1.6.6.1.1.1.1.1.2.2.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.2.2"></divide><apply id="S2.E1.m1.6.6.1.1.1.1.1.2.2.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.6.6.1.1.1.1.1.2.2.2.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S2.E1.m1.6.6.1.1.1.1.1.2.2.2.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.2.2.2.2">ğ‘›</ci><ci id="S2.E1.m1.6.6.1.1.1.1.1.2.2.2.3.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.2.2.2.3">ğ‘˜</ci></apply><ci id="S2.E1.m1.6.6.1.1.1.1.1.2.2.3.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.2.2.3">ğ‘›</ci></apply><apply id="S2.E1.m1.6.6.1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.6.6.1.1.1.1.1.2.3.1.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.2.3">subscript</csymbol><ci id="S2.E1.m1.6.6.1.1.1.1.1.2.3.2.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.2.3.2">ğ¹</ci><ci id="S2.E1.m1.6.6.1.1.1.1.1.2.3.3.cmml" xref="S2.E1.m1.6.6.1.1.1.1.1.2.3.3">ğ‘˜</ci></apply><ci id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2">ğ‘¤</ci></apply></apply><ci id="S2.E1.m1.5.5a.cmml" xref="S2.E1.m1.5.5"><mtext id="S2.E1.m1.5.5.cmml" xref="S2.E1.m1.5.5">Â whereÂ </mtext></ci></list></apply><apply id="S2.E1.m1.7.7.2.2.cmml" xref="S2.E1.m1.7.7.2.2"><eq id="S2.E1.m1.7.7.2.2.1.cmml" xref="S2.E1.m1.7.7.2.2.1"></eq><apply id="S2.E1.m1.7.7.2.2.2.cmml" xref="S2.E1.m1.7.7.2.2.2"><times id="S2.E1.m1.7.7.2.2.2.1.cmml" xref="S2.E1.m1.7.7.2.2.2.1"></times><apply id="S2.E1.m1.7.7.2.2.2.2.cmml" xref="S2.E1.m1.7.7.2.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.7.7.2.2.2.2.1.cmml" xref="S2.E1.m1.7.7.2.2.2.2">subscript</csymbol><ci id="S2.E1.m1.7.7.2.2.2.2.2.cmml" xref="S2.E1.m1.7.7.2.2.2.2.2">ğ¹</ci><ci id="S2.E1.m1.7.7.2.2.2.2.3.cmml" xref="S2.E1.m1.7.7.2.2.2.2.3">ğ‘˜</ci></apply><ci id="S2.E1.m1.3.3.cmml" xref="S2.E1.m1.3.3">ğ‘¤</ci></apply><apply id="S2.E1.m1.7.7.2.2.3.cmml" xref="S2.E1.m1.7.7.2.2.3"><times id="S2.E1.m1.7.7.2.2.3.1.cmml" xref="S2.E1.m1.7.7.2.2.3.1"></times><apply id="S2.E1.m1.7.7.2.2.3.2.cmml" xref="S2.E1.m1.7.7.2.2.3.2"><divide id="S2.E1.m1.7.7.2.2.3.2.1.cmml" xref="S2.E1.m1.7.7.2.2.3.2"></divide><cn type="integer" id="S2.E1.m1.7.7.2.2.3.2.2.cmml" xref="S2.E1.m1.7.7.2.2.3.2.2">1</cn><apply id="S2.E1.m1.7.7.2.2.3.2.3.cmml" xref="S2.E1.m1.7.7.2.2.3.2.3"><csymbol cd="ambiguous" id="S2.E1.m1.7.7.2.2.3.2.3.1.cmml" xref="S2.E1.m1.7.7.2.2.3.2.3">subscript</csymbol><ci id="S2.E1.m1.7.7.2.2.3.2.3.2.cmml" xref="S2.E1.m1.7.7.2.2.3.2.3.2">ğ‘›</ci><ci id="S2.E1.m1.7.7.2.2.3.2.3.3.cmml" xref="S2.E1.m1.7.7.2.2.3.2.3.3">ğ‘˜</ci></apply></apply><apply id="S2.E1.m1.7.7.2.2.3.3.cmml" xref="S2.E1.m1.7.7.2.2.3.3"><apply id="S2.E1.m1.7.7.2.2.3.3.1.cmml" xref="S2.E1.m1.7.7.2.2.3.3.1"><csymbol cd="ambiguous" id="S2.E1.m1.7.7.2.2.3.3.1.1.cmml" xref="S2.E1.m1.7.7.2.2.3.3.1">subscript</csymbol><sum id="S2.E1.m1.7.7.2.2.3.3.1.2.cmml" xref="S2.E1.m1.7.7.2.2.3.3.1.2"></sum><apply id="S2.E1.m1.7.7.2.2.3.3.1.3.cmml" xref="S2.E1.m1.7.7.2.2.3.3.1.3"><in id="S2.E1.m1.7.7.2.2.3.3.1.3.1.cmml" xref="S2.E1.m1.7.7.2.2.3.3.1.3.1"></in><ci id="S2.E1.m1.7.7.2.2.3.3.1.3.2.cmml" xref="S2.E1.m1.7.7.2.2.3.3.1.3.2">ğ‘–</ci><apply id="S2.E1.m1.7.7.2.2.3.3.1.3.3.cmml" xref="S2.E1.m1.7.7.2.2.3.3.1.3.3"><csymbol cd="ambiguous" id="S2.E1.m1.7.7.2.2.3.3.1.3.3.1.cmml" xref="S2.E1.m1.7.7.2.2.3.3.1.3.3">subscript</csymbol><ci id="S2.E1.m1.7.7.2.2.3.3.1.3.3.2.cmml" xref="S2.E1.m1.7.7.2.2.3.3.1.3.3.2">ğ’«</ci><ci id="S2.E1.m1.7.7.2.2.3.3.1.3.3.3.cmml" xref="S2.E1.m1.7.7.2.2.3.3.1.3.3.3">ğ‘˜</ci></apply></apply></apply><apply id="S2.E1.m1.7.7.2.2.3.3.2.cmml" xref="S2.E1.m1.7.7.2.2.3.3.2"><times id="S2.E1.m1.7.7.2.2.3.3.2.1.cmml" xref="S2.E1.m1.7.7.2.2.3.3.2.1"></times><apply id="S2.E1.m1.7.7.2.2.3.3.2.2.cmml" xref="S2.E1.m1.7.7.2.2.3.3.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.7.7.2.2.3.3.2.2.1.cmml" xref="S2.E1.m1.7.7.2.2.3.3.2.2">subscript</csymbol><ci id="S2.E1.m1.7.7.2.2.3.3.2.2.2.cmml" xref="S2.E1.m1.7.7.2.2.3.3.2.2.2">ğ‘“</ci><ci id="S2.E1.m1.7.7.2.2.3.3.2.2.3.cmml" xref="S2.E1.m1.7.7.2.2.3.3.2.2.3">ğ‘–</ci></apply><ci id="S2.E1.m1.4.4.cmml" xref="S2.E1.m1.4.4">ğ‘¤</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.7c">f(w)=\sum_{k=1}^{K}\frac{n_{k}}{n}F_{k}(w)\quad\text{ where }\quad F_{k}(w)=\frac{1}{n_{k}}\sum_{i\in\mathcal{P}_{k}}f_{i}(w)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
</div>
<div id="S2.I1.i1.p3" class="ltx_para">
<p id="S2.I1.i1.p3.4" class="ltx_p">Where <math id="S2.I1.i1.p3.1.m1.1" class="ltx_Math" alttext="\mathcal{P}_{k}" display="inline"><semantics id="S2.I1.i1.p3.1.m1.1a"><msub id="S2.I1.i1.p3.1.m1.1.1" xref="S2.I1.i1.p3.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I1.i1.p3.1.m1.1.1.2" xref="S2.I1.i1.p3.1.m1.1.1.2.cmml">ğ’«</mi><mi id="S2.I1.i1.p3.1.m1.1.1.3" xref="S2.I1.i1.p3.1.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p3.1.m1.1b"><apply id="S2.I1.i1.p3.1.m1.1.1.cmml" xref="S2.I1.i1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p3.1.m1.1.1.1.cmml" xref="S2.I1.i1.p3.1.m1.1.1">subscript</csymbol><ci id="S2.I1.i1.p3.1.m1.1.1.2.cmml" xref="S2.I1.i1.p3.1.m1.1.1.2">ğ’«</ci><ci id="S2.I1.i1.p3.1.m1.1.1.3.cmml" xref="S2.I1.i1.p3.1.m1.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p3.1.m1.1c">\mathcal{P}_{k}</annotation></semantics></math> the set of indexes of data points on client k, distributed uniformly at random, with <math id="S2.I1.i1.p3.2.m2.1" class="ltx_Math" alttext="{n_{k}}" display="inline"><semantics id="S2.I1.i1.p3.2.m2.1a"><msub id="S2.I1.i1.p3.2.m2.1.1" xref="S2.I1.i1.p3.2.m2.1.1.cmml"><mi id="S2.I1.i1.p3.2.m2.1.1.2" xref="S2.I1.i1.p3.2.m2.1.1.2.cmml">n</mi><mi id="S2.I1.i1.p3.2.m2.1.1.3" xref="S2.I1.i1.p3.2.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p3.2.m2.1b"><apply id="S2.I1.i1.p3.2.m2.1.1.cmml" xref="S2.I1.i1.p3.2.m2.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p3.2.m2.1.1.1.cmml" xref="S2.I1.i1.p3.2.m2.1.1">subscript</csymbol><ci id="S2.I1.i1.p3.2.m2.1.1.2.cmml" xref="S2.I1.i1.p3.2.m2.1.1.2">ğ‘›</ci><ci id="S2.I1.i1.p3.2.m2.1.1.3.cmml" xref="S2.I1.i1.p3.2.m2.1.1.3">ğ‘˜</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p3.2.m2.1c">{n_{k}}</annotation></semantics></math> = <math id="S2.I1.i1.p3.3.m3.1" class="ltx_Math" alttext="|Pk|" display="inline"><semantics id="S2.I1.i1.p3.3.m3.1a"><mrow id="S2.I1.i1.p3.3.m3.1.1.1" xref="S2.I1.i1.p3.3.m3.1.1.2.cmml"><mo stretchy="false" id="S2.I1.i1.p3.3.m3.1.1.1.2" xref="S2.I1.i1.p3.3.m3.1.1.2.1.cmml">|</mo><mrow id="S2.I1.i1.p3.3.m3.1.1.1.1" xref="S2.I1.i1.p3.3.m3.1.1.1.1.cmml"><mi id="S2.I1.i1.p3.3.m3.1.1.1.1.2" xref="S2.I1.i1.p3.3.m3.1.1.1.1.2.cmml">P</mi><mo lspace="0em" rspace="0em" id="S2.I1.i1.p3.3.m3.1.1.1.1.1" xref="S2.I1.i1.p3.3.m3.1.1.1.1.1.cmml">â€‹</mo><mi id="S2.I1.i1.p3.3.m3.1.1.1.1.3" xref="S2.I1.i1.p3.3.m3.1.1.1.1.3.cmml">k</mi></mrow><mo stretchy="false" id="S2.I1.i1.p3.3.m3.1.1.1.3" xref="S2.I1.i1.p3.3.m3.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p3.3.m3.1b"><apply id="S2.I1.i1.p3.3.m3.1.1.2.cmml" xref="S2.I1.i1.p3.3.m3.1.1.1"><abs id="S2.I1.i1.p3.3.m3.1.1.2.1.cmml" xref="S2.I1.i1.p3.3.m3.1.1.1.2"></abs><apply id="S2.I1.i1.p3.3.m3.1.1.1.1.cmml" xref="S2.I1.i1.p3.3.m3.1.1.1.1"><times id="S2.I1.i1.p3.3.m3.1.1.1.1.1.cmml" xref="S2.I1.i1.p3.3.m3.1.1.1.1.1"></times><ci id="S2.I1.i1.p3.3.m3.1.1.1.1.2.cmml" xref="S2.I1.i1.p3.3.m3.1.1.1.1.2">ğ‘ƒ</ci><ci id="S2.I1.i1.p3.3.m3.1.1.1.1.3.cmml" xref="S2.I1.i1.p3.3.m3.1.1.1.1.3">ğ‘˜</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p3.3.m3.1c">|Pk|</annotation></semantics></math> and <math id="S2.I1.i1.p3.4.m4.1" class="ltx_Math" alttext="w" display="inline"><semantics id="S2.I1.i1.p3.4.m4.1a"><mi id="S2.I1.i1.p3.4.m4.1.1" xref="S2.I1.i1.p3.4.m4.1.1.cmml">w</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p3.4.m4.1b"><ci id="S2.I1.i1.p3.4.m4.1.1.cmml" xref="S2.I1.i1.p3.4.m4.1.1">ğ‘¤</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p3.4.m4.1c">w</annotation></semantics></math> are model parameters. The focus of the proposed research is on the optimizationâ€™s non-IID data distributions and imbalanced properties, as well as the nature of the communication constraints.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p"><span id="S2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">FedMa Algorithm</span>
FedMA <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib116" title="" class="ltx_ref">2020</a>)</cite> is a federated learning method for current neural network designs such as Convolutional Neural Networks (CNNs) and LSTMs. FedMA builds the shared global model layer by layer by matching and averaging hidden components with comparable feature extraction signatures (i.e. channels for convolution layers; hidden states for LSTM; neurons for fully connected layers).</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p"><span id="S2.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">FedNAS Algorithm</span>
One of the major issues on working with Non-I.I.D data is that it requires the developers to design and choose multiple architectures that tunes the hyper parameters and fits the scattered data. This is design process is expensive due to large number of communication rounds and computational burden. FedNAS - Federated Neural Architecture Search <cite class="ltx_cite ltx_citemacro_citep">(He
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib45" title="" class="ltx_ref">2020a</a>)</cite> is an algorithm that improves the model accuracy by automating the manual design process. The algorithm helps scattered workers to collaboratively search for a better architecture.</p>
</div>
</li>
<li id="S2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i4.p1" class="ltx_para">
<p id="S2.I1.i4.p1.1" class="ltx_p"><span id="S2.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">FedGKT Algorithm</span>
The fact that federated learning ensures privacy and confidentiality is one of its most appealing features. There is, however, a limit to the computation capabilities of the edge nodes. Convolutional neural networks are used to boost the modelâ€™s performance and accuracy, however when employed with FL restrictions, large models might burden edge nodes and increase communication costs. A group knowledge transfer training technique intends to reduce the need for edge compute while keeping edge training inexpensive by lowering communication bandwidths for training with CNNs at the edge. FedGKT <cite class="ltx_cite ltx_citemacro_citep">(He
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib46" title="" class="ltx_ref">2020b</a>)</cite> requires 9 to 17 times less computing resources on edge devices than FedAvg. In comparison to FedAvg, the authors claim that this algorithm can achieve the same or slightly higher accuracy.</p>
</div>
</li>
<li id="S2.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i5.p1" class="ltx_para">
<p id="S2.I1.i5.p1.1" class="ltx_p"><span id="S2.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Secured Weighted Aggregation</span>
The proposed algorithm <cite class="ltx_cite ltx_citemacro_citep">(Guo
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib43" title="" class="ltx_ref">2021</a>)</cite> is relying on homomorphic encryption - cryptosystem for calculating the clientâ€™s weights in a privacy-preserving manner. The algorithm adopts a Zero-Knowledge Proof(ZKP) based verification scheme to prevent the central servers and clients from receiving fraudulent messages from each other. This is the first aggregation algorithm that deals with Data disparity and fraudulent messages</p>
</div>
</li>
<li id="S2.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i6.p1" class="ltx_para">
<p id="S2.I1.i6.p1.1" class="ltx_p"><span id="S2.I1.i6.p1.1.1" class="ltx_text ltx_font_bold">Secure Federated matrix factorization</span>
The authors of this research offer a Federated Matrix Factorization Framework to address the problem of disclosing data through gradients FedMF <cite class="ltx_cite ltx_citemacro_citep">(Chai
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib18" title="" class="ltx_ref">2019</a>)</cite>. Distributed machine learning and homomorphic encryption techniques are used in the system. FedMF is a user-level distributed matrix factorization framework that allows the model to be learned by uploading the gradient information to the server rather than the raw preference information. The authors utilize homomorphic encryption to improve distributed matrix factorization and boost security since gradient information can leak user information to some extent.</p>
</div>
</li>
<li id="S2.I1.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i7.p1" class="ltx_para">
<p id="S2.I1.i7.p1.1" class="ltx_p"><span id="S2.I1.i7.p1.1.1" class="ltx_text ltx_font_bold">Inprivate Digging</span>
The authors concentrate on a tree-based data mining concept and provide privacy-preserving approaches for two of the most popular tasks: Regression and Binary Classification, in which individual data owners can train locally in a differentially private way <cite class="ltx_cite ltx_citemacro_citep">(Zhao
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib134" title="" class="ltx_ref">2018</a>)</cite>. They created and implemented a privacy-preserving Gradient Boosting Decision Tree (GBDT) system that allows several regression trees trained by distinct data owners to be safely aggregated into an ensemble without the need of a third party.</p>
</div>
</li>
<li id="S2.I1.i8" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i8.p1" class="ltx_para">
<p id="S2.I1.i8.p1.1" class="ltx_p"><span id="S2.I1.i8.p1.1.1" class="ltx_text ltx_font_bold">Federated Forest</span>
The authors provided a system that allows random forests to be trained in a vertical FL scenario <cite class="ltx_cite ltx_citemacro_citep">(Liu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib75" title="" class="ltx_ref">2020</a>)</cite>. Throughout the development of each node, the party with the related split feature is in charge of splitting the samples and exchanging the results. To safeguard privacy, they encrypt the data that is sent. Their method is equally accurate as of the non-federated one. Both classification and regression tasks are supported by the model.</p>
</div>
</li>
</ul>
</div>
<section id="S2.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.3.1. </span>Model Evaluation</h4>

<div id="S2.SS3.SSS1.p1" class="ltx_para">
<p id="S2.SS3.SSS1.p1.1" class="ltx_p">In traditional centralized machine learning, evaluation metrics are used to assess the performance and measure the quality of the model. Evaluation metrics mainly include accuracy, precision, and recall, etc. Accuracy is a fraction of the correct samples to all samples. Precision is the fraction of actual positive samples among the positive samples, while recall is the fraction of actual positive samples among the samples from true positive or false negative.</p>
</div>
<div id="S2.SS3.SSS1.p2" class="ltx_para">
<p id="S2.SS3.SSS1.p2.1" class="ltx_p">In a federated learning setup, the above metrics are insufficient to evaluate the performance of the models. In this setting, it is intended to identify the evaluation metrics for both qualitative and quantitative methods. Training speed, performance, and the quantity of data transferred are utilized as assessment measures in existing federated learning studies. An FL model is evaluated by examining the aggregated model after being assigned to each clientsâ€™ local evaluation dataset. Following then, the server shares each clientâ€™s performance with it, aggregating the local results to produce global assessment metrics.</p>
</div>
<div id="S2.SS3.SSS1.p3" class="ltx_para">
<p id="S2.SS3.SSS1.p3.1" class="ltx_p">FedEval <cite class="ltx_cite ltx_citemacro_citep">(Chai
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib19" title="" class="ltx_ref">2020</a>)</cite> is an evaluation framework for FL systems. It introduces the â€œACTPRâ€ model, i.e., using accuracy, communication, time consumption, privacy, and robustness as its evaluation targets.</p>
</div>
</section>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4. </span><span id="S2.SS4.1.1" class="ltx_text ltx_font_bold">Federated Client</span>
</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p">In a federated learning setting, the client devices are the hardware components that perform the local model training and loss minimization The main objective is to train local device models on their private data and share the updates with the federated server where the aggregation is performed. In a decentralized federated learning system, the client devices communicate among themselves without the interference of the central server. Typical clients in federated learning settings could be smartphones, IoT devices, or organizations such as hospitals. Each client has its specific private training dataset and its local model.</p>
</div>
<div id="S2.SS4.p2" class="ltx_para">
<p id="S2.SS4.p2.1" class="ltx_p">A study in <cite class="ltx_cite ltx_citemacro_citep">(Lo
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib76" title="" class="ltx_ref">2021</a>)</cite> describes the client management patterns that control the local devicesâ€™ information and their connection with the central server. The client registry is the initial component, and it controls the information about the participating devices. The second component, the client selector, selects the devices for the federated training task. To improve the training modelâ€™s performance and efficiency, the third component, client cluster, clusters client devices depending on particular parameters (e.g., data distribution, available resources).</p>
</div>
<section id="S2.SS4.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.4.1. </span>Data Partitioning</h4>

<div id="S2.SS4.SSS1.p1" class="ltx_para">
<p id="S2.SS4.SSS1.p1.1" class="ltx_p">Federated learning systems are commonly classified as horizontal, vertical, or hybrid based on how data is spread through the sample and feature spaces.</p>
</div>
<div id="S2.SS4.SSS1.p3" class="ltx_para">
<ul id="S2.I2" class="ltx_itemize">
<li id="S2.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I2.i1.p1" class="ltx_para">
<p id="S2.I2.i1.p1.1" class="ltx_p"><span id="S2.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Horizontal Federated Learning</span></p>
</div>
<div id="S2.I2.i1.p2" class="ltx_para ltx_noindent">
<ul id="S2.I2.i1.I1" class="ltx_itemize">
<li id="S2.I2.i1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S2.I2.i1.I1.i1.1.1.1" class="ltx_text ltx_font_bold">â€“</span></span> 
<div id="S2.I2.i1.I1.i1.p1" class="ltx_para">
<p id="S2.I2.i1.I1.i1.p1.1" class="ltx_p"><span id="S2.I2.i1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Concept</span>
Horizontal federated learning involves data that is shared horizontally which involves datasets sharing the same feature space but being different in samples <cite class="ltx_cite ltx_citemacro_citep">(Yang
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib128" title="" class="ltx_ref">2019a</a>)</cite>. Each group in horizontal FL has access to the entire feature set and labels, allowing them to train their local model using their dataset. After that, all of the parties exchange their model updates with an aggregator and then generate a global model by combining, for example, the model weights obtained from different parties. <cite class="ltx_cite ltx_citemacro_citep">(Xu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib123" title="" class="ltx_ref">2021a</a>)</cite> An example of horizontal data split in federated learning setup is shown in figure 3. Assuming there is a blood bank laboratory having details of the patients stored as groups in a database collected under Name, Age, and Blood Person features. In figure 3, persons 1, 2, and 3 represent groups of patientsâ€™ data samples sharing the same features â€“ Name, Age and Blood Group. Suppose a Horizontal Federated learning method is to be used. In that case, the machine learning model will run on each of these samples (person) individually, allowing them to train the local model and finally exchange and aggregate model weights to generate a global model.</p>
</div>
</li>
<li id="S2.I2.i1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S2.I2.i1.I1.i2.1.1.1" class="ltx_text ltx_font_bold">â€“</span></span> 
<div id="S2.I2.i1.I1.i2.p1" class="ltx_para">
<p id="S2.I2.i1.I1.i2.p1.1" class="ltx_p"><span id="S2.I2.i1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Applications</span>
The FedAvg algorithm proposed in <cite class="ltx_cite ltx_citemacro_citep">(Shi
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib104" title="" class="ltx_ref">2020</a>)</cite> is the best example of a typical horizontal federated learning setup. Although horizontal federated learning protects user privacy and aims to control the communication cost, it poses challenges compared to distributed learning. Keeping in mind the protocols of federated learning and applications of neural networks, a new algorithm titled â€œFederated neural networkâ€ was proposed for single and multi-objective search purposes <cite class="ltx_cite ltx_citemacro_citep">(Zhu
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib137" title="" class="ltx_ref">2021</a>)</cite>. In comparison to Secure Multiparty Computation and Homomorphic Encryption, this study also analyzes how Differential Privacy may be employed best in horizontal federated learning.</p>
</div>
<div id="S2.I2.i1.I1.i2.p2" class="ltx_para">
<p id="S2.I2.i1.I1.i2.p2.1" class="ltx_p">EHRs have proven to be an aid for the development of scientific evidence for improving the quality of healthcare systems and they are also used as a data resource for laboratory-based public health surveillance. Techniques have been created for computing statistics on distributed databases without disclosing any personal details other than the statistical results. In a distributed dataset, duplicate records can lead to incorrect statistical findings. As a result, safe deduplication is an effective preprocessing step for improving the precision of statistical analysis of a distributed dataset. A stable protocol using a deterministic record linking algorithm for deduplication of horizontally partitioned datasets <cite class="ltx_cite ltx_citemacro_citep">(Yigzaw
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib132" title="" class="ltx_ref">2017</a>)</cite>. They introduced a new robust and scalable protocol for privacy-preserving deduplication of a horizontally partitioned dataset based on Bloom filters. According to the results of the experiments, within 45 seconds, one million virtual documents were deduplicated across 20 data custodians. The protocol is proven to be more effective and flexible than previous protocols for the same problem.</p>
</div>
<figure id="S2.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2211.07893/assets/x3.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="423" height="150" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span>Horizontal Data split by examples</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S2.F3.1" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S2.F3.2" class="ltx_p ltx_figure_panel ltx_align_center">A woman and a girl in white dresses sit in an open car.</p>
</div>
</div>
</figure>
</li>
</ul>
</div>
</li>
<li id="S2.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I2.i2.p1" class="ltx_para">
<p id="S2.I2.i2.p1.1" class="ltx_p"><span id="S2.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Vertical Federated Learning</span></p>
</div>
<div id="S2.I2.i2.p2" class="ltx_para">
<ul id="S2.I2.i2.I1" class="ltx_itemize">
<li id="S2.I2.i2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S2.I2.i2.I1.i1.1.1.1" class="ltx_text ltx_font_bold">â€“</span></span> 
<div id="S2.I2.i2.I1.i1.p1" class="ltx_para">
<p id="S2.I2.i2.I1.i1.p1.1" class="ltx_p"><span id="S2.I2.i2.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Concept</span>
Vertical federated learning can also be called feature-based federated learning. This is used when the data shared among them contains different features but similar samples. This requires a different kind of training architecture when compared to horizontal federated learning. It may or may not involve a central server or a third neutral party. Vertical FL (VFL) applies to collective situations in which individual parties do not have access to the whole collection of features and labels and thus are unable to train a model locally using their datasets. Partiesâ€™ datasets, in particular, must be synchronized to construct the full function vector without revealing their respective training data, and model training must be performed in a privacy-preserving manner. <cite class="ltx_cite ltx_citemacro_citep">(Xu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib124" title="" class="ltx_ref">2021b</a>)</cite> An example of vertical data split by examples is shown in figure 4.Assuming a blood bank laboratory in a hospital has data from the same group of patients. As seen in figure 4., the blood bank database stores the details of the patient groups under Name, Age, and Blood group. At the same time, the hospital database stores the details of the same patient groups under Name, Age, Date of Birth, Blood group, and Medical History.
If a Vertical Federated learning method is to be used, the first dataset for the machine learning model would be the data sample from Person 1 of the Blood Bank Database and Hospital Database. Furthermore, the second dataset will be data samples from Person 2 of the Blood Bank database and Hospital Database, respectively.</p>
</div>
</li>
<li id="S2.I2.i2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S2.I2.i2.I1.i2.1.1.1" class="ltx_text ltx_font_bold">â€“</span></span> 
<div id="S2.I2.i2.I1.i2.p1" class="ltx_para">
<p id="S2.I2.i2.I1.i2.p1.1" class="ltx_p"><span id="S2.I2.i2.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Applications</span>
FedAI uses horizontal federated learning for improving an anti-money laundering model and the use of vertical federated learning to obtain a better risk management model. Homomorphic Encryption is the privacy-preserving technique that is usually adopted when the data is distributed vertically. Recently, a two-party design has been proposed by eliminating the trusted coordinator, which considerably decreases the systemâ€™s complexity <cite class="ltx_cite ltx_citemacro_citep">(Yang
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib129" title="" class="ltx_ref">2019b</a>)</cite>.</p>
</div>
<div id="S2.I2.i2.I1.i2.p2" class="ltx_para">
<p id="S2.I2.i2.I1.i2.p2.1" class="ltx_p">In the healthcare sector, information sharing is becoming increasingly relevant. First and foremost for medical reasons, such as the sharing of treatment records between healthcare providers, but also for secondary purposes, such as the implementation of value-based healthcare and processes. While these requirements allow information to be transferred, they also pose concerns regarding maintainability and possession, as well as protection and privacy. Provenance and permission become more complicated as data is shared by various health care providers. Sending programs containing queries and algorithms to the data source is one of the alternatives to data transfer. To address these problems, the authors in <cite class="ltx_cite ltx_citemacro_citep">(Soest etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib106" title="" class="ltx_ref">2018</a>)</cite> provide an architecture to enable algorithm conversion and execution, and use this infrastructure in a proof-of-concept setup. The proof-of-concept (PoC) focuses on processing data that has been vertically partitioned from two institutes. In a population cohort analysis, the PoC is used as a baseline to look at the causes of diabetes initiation and development, including social and environmental conditions.</p>
</div>
<div id="S2.I2.i2.I1.i2.p3" class="ltx_para">
<p id="S2.I2.i2.I1.i2.p3.1" class="ltx_p">Since full collections of labels and functions are not controlled by one person, privacy-preserving vertical FL is difficult. Existing vertical FL approaches necessitate multiple peer-to-peer interactions among parties, resulting in longer training periods, and are limited to (roughly) linear models and only two parties. To bridge this void, the authors of <cite class="ltx_cite ltx_citemacro_citep">(Xu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib124" title="" class="ltx_ref">2021b</a>)</cite> suggest FedV, a framework for safe gradient computing in vertical settings for a variety of commonly used machine learning models. Linear simulations, logistic regression, and support vectors are examples of these types of models. FedV uses functional encryption mechanisms to eliminate the need for peer-to-peer correspondence between parties. FedV can attain shorter preparation times as a result of this. Itâ€™s also successful for wider and ever-changing groups of parties.</p>
</div>
<figure id="S2.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2211.07893/assets/x4.png" id="S2.F4.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="423" height="317" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4. </span>Vertical Data split by examples</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S2.F4.1" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S2.F4.2" class="ltx_p ltx_figure_panel ltx_align_center">A woman and a girl in white dresses sit in an open car.</p>
</div>
</div>
</figure>
</li>
</ul>
</div>
</li>
<li id="S2.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I2.i3.p1" class="ltx_para">
<p id="S2.I2.i3.p1.1" class="ltx_p"><span id="S2.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">Hybrid/Transfer Federated Learning</span></p>
</div>
<div id="S2.I2.i3.p2" class="ltx_para">
<ul id="S2.I2.i3.I1" class="ltx_itemize">
<li id="S2.I2.i3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S2.I2.i3.I1.i1.1.1.1" class="ltx_text ltx_font_bold">â€“</span></span> 
<div id="S2.I2.i3.I1.i1.p1" class="ltx_para">
<p id="S2.I2.i3.I1.i1.p1.1" class="ltx_p"><span id="S2.I2.i3.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Concept</span>
Federated transfer learning <cite class="ltx_cite ltx_citemacro_citep">(Yang
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib128" title="" class="ltx_ref">2019a</a>)</cite> was introduced to tackle the challenge of integrating the scattered data and improve statistical modeling while performing data federation. It is also studied that this framework requires minimal modifications to the model structure and the result produced are as efficient as the non-privacy preserving transfer learning. Federated transfer learning does not depend on any requirement such as common feature space or common sample space and it supports transfer learning in providing solutions for the entire sample and feature space while data federation is taking place.</p>
</div>
<div id="S2.I2.i3.I1.i1.p2" class="ltx_para">
<p id="S2.I2.i3.I1.i1.p2.1" class="ltx_p">Federated transfer learning is a term that recognizes difficult situations in which data parties only have partial overlap in the user or function space and uses current transfer learning strategies to collaboratively construct models. The current formulation is only good for two clients <cite class="ltx_cite ltx_citemacro_citep">(Kairouz
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2021a</a>)</cite>. An illustration of hybrid/transfer federated learning is shown in figure 5.</p>
</div>
</li>
<li id="S2.I2.i3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item"><span id="S2.I2.i3.I1.i2.1.1.1" class="ltx_text ltx_font_bold">â€“</span></span> 
<div id="S2.I2.i3.I1.i2.p1" class="ltx_para">
<p id="S2.I2.i3.I1.i2.p1.1" class="ltx_p"><span id="S2.I2.i3.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Applications</span>
FedHealth is one such algorithm that uses the concept of federated transfer learning in smart wearable healthcare devices <cite class="ltx_cite ltx_citemacro_citep">(Ju etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2020b</a>)</cite>. The algorithm performs data aggregation through federated learning and builds personalized models by transfer learning without compromising on the privacy and security of the model and data.</p>
</div>
<div id="S2.I2.i3.I1.i2.p2" class="ltx_para">
<p id="S2.I2.i3.I1.i2.p2.1" class="ltx_p">The shortage of massive datasets has hampered the progress of deep learning (DL) approaches in the field of Brain-Computer Interfaces (BCI) for the classification of electroencephalographic (EEG) recordings<cite class="ltx_cite ltx_citemacro_citep">(Ju etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2020b</a>)</cite>. The ability to create a large EEG BCI dataset by combining several small ones for jointly training machine learning models is limited due to privacy issues associated with EEG signals. Addressing this issue, a novel privacy-preserving deep learning architecture centered on the federated learning system, for EEG classification called Federated Transfer Learning (FTL) <cite class="ltx_cite ltx_citemacro_citep">(Ju etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2020b</a>)</cite>.As a result, in a subject-adaptive study, the FTL method had a 2% better classification accuracy.</p>
</div>
<div id="S2.I2.i3.I1.i2.p3" class="ltx_para">
<p id="S2.I2.i3.I1.i2.p3.1" class="ltx_p">Although current federated learning systems (FLSs) primarily focus on one type of partition, data partitioning among parties in many other applications can be a combination of horizontal and vertical partitioning. As an example, consider a cancer detection method. A consortium of hospitals needs to build a FLS for cancer diagnosis, but each hospital has separate patients and medical test outcomes. In such cases, transfer learning could be an option. <cite class="ltx_cite ltx_citemacro_citep">(Shi
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib104" title="" class="ltx_ref">2020</a>)</cite> suggest a stable federated transfer learning method that can learn a representation of a partyâ€™s features using similar instances. This framework involves only minor changes to the original model layout and achieves the same degree of consistency as non-privacy-preserving transfer learning. It is adaptable and can be used for a variety of stable multi-party machine learning activities.</p>
</div>
</li>
</ul>
</div>
<figure id="S2.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2211.07893/assets/x5.png" id="S2.F5.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="363" height="226" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5. </span>Transfer learning in federated learning</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S2.F5.1" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S2.F5.2" class="ltx_p ltx_figure_panel ltx_align_center">A woman and a girl in white dresses sit in an open car.</p>
</div>
</div>
</figure>
</li>
</ul>
</div>
</section>
<section id="S2.SS4.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.4.2. </span>Data Pre-processing and Feature Engineering</h4>

<div id="S2.SS4.SSS2.p1" class="ltx_para">
<p id="S2.SS4.SSS2.p1.1" class="ltx_p">Data Preprocessing is an essential and challenging task in the FL training process due to the sensitive and distributed nature of the data. Moreover, it takes a long time to adapt centralized preprocessing approaches to federated data. Data preprocessing involves data cleaning, missing values imputation, and other steps to maintain consistency between distributed datasets of different clients without knowing the underlying distribution.</p>
</div>
<div id="S2.SS4.SSS2.p2" class="ltx_para">
<p id="S2.SS4.SSS2.p2.1" class="ltx_p">A few scenarios require domain knowledge to clean, structure the data, and extract data features (properties, characteristics, attributes) from raw data. <cite class="ltx_cite ltx_citemacro_citep">(Ju etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2020b</a>)</cite> used medical knowledge and AI techniques to clean and normalize the raw patient data collected from hospitals. The data from the hospital includes outpatient/in-patient prescriptions, outpatient/in-patient EHRs, and other metadata.</p>
</div>
</section>
<section id="S2.SS4.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.4.3. </span>Privacy Preservation in FL</h4>

<div id="S2.SS4.SSS3.p1" class="ltx_para">
<p id="S2.SS4.SSS3.p1.1" class="ltx_p">Federated learning involves the participation of thousands or millions of devices <cite class="ltx_cite ltx_citemacro_citep">(Yang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib130" title="" class="ltx_ref">2018</a>)</cite> such as phones, cars, medical institutions, etc. The federated learning environment, where the model is learned locally without disclosing to any clients the input data or the output of the model, avoids direct leakage when training or using the model assuring the clientâ€™s (health systems from medical institutions in this case) dataset is kept as private as possible. This is demonstrated by a model developed using patient Electronic Health Records (EHR) and a consumer-based application such as screening atrial fibrillation with electrocardiograms obtained by smartwatches <cite class="ltx_cite ltx_citemacro_citep">(Perez
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib88" title="" class="ltx_ref">2019</a>)</cite>. Sensitive patient data is kept in local institutions or with individual consumers rather than being exposed to the federated model learning process, ensuring the patientâ€™s privacy. The â€˜No peekâ€™ rule <cite class="ltx_cite ltx_citemacro_citep">(Vepakomma etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib114" title="" class="ltx_ref">2018</a>)</cite> refers to techniques of distributed deep learning models that do not look at raw data once it leaves the clients. A good example explaining this would be, hospitals or healthcare systems at institutions that are not allowed to share data with for-profit entities due to trust issues. Such institutions are also restricted from sharing it with outside entities due to the consent of patients and various regulations like HIPAA <cite class="ltx_cite ltx_citemacro_citep">(Vepakomma etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib114" title="" class="ltx_ref">2018</a>)</cite> Listed below are few methods of privacy-preserving in FL.</p>
</div>
<div id="S2.SS4.SSS3.p2" class="ltx_para">
<p id="S2.SS4.SSS3.p2.1" class="ltx_p">Secure Privacy-preserving learning on medical data mainly involves protecting the collection of personal data used in ML model training and inference in such a way that it does not reveal any additional information about the subjects. Cryptographic techniques and differential privacy techniques are the most extensively utilized methods for privacy-preserving ML <cite class="ltx_cite ltx_citemacro_citep">(Al-Rubaie and
Chang, <a href="#bib.bib5" title="" class="ltx_ref">2019</a>)</cite></p>
<ul id="S2.I3" class="ltx_itemize">
<li id="S2.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I3.i1.p1" class="ltx_para">
<p id="S2.I3.i1.p1.1" class="ltx_p"><span id="S2.I3.i1.p1.1.1" class="ltx_text ltx_font_bold">Cryptographic methods</span>
are used when encrypted data is required during testing and training phases. The widely used method under this is Homomorphic encryption and Secret sharing. Homomorphic encryption involves the encryption of data using ciphertext and public keys. It enables computations like addition and multiplication, which is a base for other complex functions, on encrypted data.</p>
</div>
</li>
<li id="S2.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I3.i2.p1" class="ltx_para">
<p id="S2.I3.i2.p1.1" class="ltx_p"><span id="S2.I3.i2.p1.1.1" class="ltx_text ltx_font_bold">Secret Sharing</span>
The technique of transmitting secrets to various parties is known as secret sharing while keeping a â€shareâ€ of the secret. Only when all individual shares are merged will the secret be reconstructed. The secret is reconstructed in some configurations that wonâ€™t need all shares to be merged. A privacy-preserving system for emotion detection is introduced in <cite class="ltx_cite ltx_citemacro_citep">(Hossain and
Muhammad, <a href="#bib.bib50" title="" class="ltx_ref">2019</a>)</cite>. The authors used a multi-secret sharing method to transfer audio-visual data gathered from users to the cloud using edge devices where a CNN and sparse auto-encoder were applied for the extraction of features. The vector machine (SVM) was used for emotion and support identification.</p>
</div>
</li>
<li id="S2.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I3.i3.p1" class="ltx_para">
<p id="S2.I3.i3.p1.1" class="ltx_p"><span id="S2.I3.i3.p1.1.1" class="ltx_text ltx_font_bold">Differential privacy</span>
Differential Privacy (DP) is another technique to protect the privacy of individual data which has been used in areas that use algorithms like boosting <cite class="ltx_cite ltx_citemacro_citep">(Dwork
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib35" title="" class="ltx_ref">2010</a>)</cite>, principal component analysis <cite class="ltx_cite ltx_citemacro_citep">(Chaudhuri
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib20" title="" class="ltx_ref">2013</a>)</cite>, and support vector machines. Differential privacy involves the addition of noise to model updates as they communicate with servers and clients<cite class="ltx_cite ltx_citemacro_citep">(Dwork etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib34" title="" class="ltx_ref">2006</a>)</cite> . Differential privacy, on the other hand, is known to shield users from data leakage to a limited level and may lower prediction accuracy performance <cite class="ltx_cite ltx_citemacro_citep">(Cheng
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib23" title="" class="ltx_ref">2019</a>)</cite>. Hence many researchers combine DP with the Secured Multiparty computations technique to decrease the growth of noise injection and data poisoning attacks <cite class="ltx_cite ltx_citemacro_citep">(Alfeld
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib6" title="" class="ltx_ref">2016</a>)</cite>. While there is an exchange in convergence rates at the participant level - Differential Privacy (DP) may not help much in the protection of users and also may affect the accuracy of the model. Participant level DP is good when a large pool of devices are participating in the process. The ability of participant-level DP for a small pool of participants is yet to be improved and focused on working for a better convergence at this small level.</p>
</div>
</li>
<li id="S2.I3.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I3.i4.p1" class="ltx_para">
<p id="S2.I3.i4.p1.1" class="ltx_p"><span id="S2.I3.i4.p1.1.1" class="ltx_text ltx_font_bold">SMPC - Secure MultiParty Computation</span>
Secured MultiParty Computation approach provides clear security guarantees even though it is in general a less efficient approach. Privacy-Preserving Record Linkage (PPRL) <cite class="ltx_cite ltx_citemacro_citep">(Laud and Pankova, <a href="#bib.bib64" title="" class="ltx_ref">2018</a>)</cite> is one such example where secured multi-party computation is being used. SMC was also introduced to Quantitative Structure-Activity Relationship (QSAR) and drug-target Interaction prediction for drug discovery <cite class="ltx_cite ltx_citemacro_citep">(Laud and Pankova, <a href="#bib.bib64" title="" class="ltx_ref">2018</a>)</cite>.
SMC applies the concept of three distinct responsibilities for parties. There are input parties who contribute data to the calculation that must be protected. Computation parties carry out the privacy-preserving computation on the data given. Apart from what is revealed through the architecture of the application, the computation parties should not learn anything new from the execution. Finally, there are result parties who are given the computationâ€™s results.</p>
</div>
</li>
</ul>
</div>
<div id="S2.SS4.SSS3.p3" class="ltx_para">
<span id="S2.SS4.SSS3.p3.1" class="ltx_ERROR undefined">{longtblr}</span>
<p id="S2.SS4.SSS3.p3.2" class="ltx_p">[
caption = Summary of existing studies on FL in Healthcare since 2015,
label = Tab:dcnnarchitectures,
]

rowhead=1,
hline1,2,Z = 1pt, hline3-Y,
colsep = 3pt,
colspec = @ X[j,h] Q[c,m] Q[c,m] Q[c,m] X[j,h] @,
rows = font=,
row1 = font=,

Title &amp; Ref  Year  Category  Content 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p4" class="ltx_para">
<p id="S2.SS4.SSS3.p4.1" class="ltx_p">A Federated Network for Translational Cancer Research Using Clinical Data and Biospecimens
 <cite class="ltx_cite ltx_citemacro_citep">(Jacobson etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2015</a>)</cite>
 2015
 Learning 
<br class="ltx_break">Systems
 This report describes a fully functional federated data and biospecimen sharing network for cross-institutional cancer research collaboration 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p5" class="ltx_para">
<p id="S2.SS4.SSS3.p5.1" class="ltx_p">Privacy-preserving GWAS analysis on federated genomic datasets
 <cite class="ltx_cite ltx_citemacro_citep">(Constable etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2015</a>)</cite>
 2015  Framework
 On federated genomic datasets, this research proposes a privacy-preserving GWAS methodology 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p6" class="ltx_para">
<p id="S2.SS4.SSS3.p6.1" class="ltx_p">Privacy-Preserving Integration of Medical Data
 <cite class="ltx_cite ltx_citemacro_citep">(Miyaji
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib81" title="" class="ltx_ref">2017</a>)</cite>
 2017
 Protocol
 This work presents a safe and privacy-preserving method for searching and integrating health care data from diverse sources 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p7" class="ltx_para">
<p id="S2.SS4.SSS3.p7.1" class="ltx_p">LoAdaBoost: loss-based AdaBoost federated machine learning with reduced computational complexity on IID and non-IID intensive care data
 <cite class="ltx_cite ltx_citemacro_citep">(Huang
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib52" title="" class="ltx_ref">2020</a>)</cite>
 2018
 Learning 
<br class="ltx_break">Systems
 LoAdaBoost, a methodology for increasing the efficiency of federated machine learning, was suggested in this research, and the algorithm was evaluated using data from intensive care units in hospitals 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p8" class="ltx_para">
<p id="S2.SS4.SSS3.p8.1" class="ltx_p">Federated learning of predictive models from federated electronic health records
 <cite class="ltx_cite ltx_citemacro_citep">(Brisimi etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2018</a>)</cite>
 2018
 Framework
 A novel FL framework is presented that can train predictive models through peer-to-peer cooperation instead of exchanging raw EHR data 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p9" class="ltx_para">
<p id="S2.SS4.SSS3.p9.1" class="ltx_p">FADL:Federated-Autonomous Deep Learning for Distributed Electronic Health Record
 <cite class="ltx_cite ltx_citemacro_citep">(Liu
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib73" title="" class="ltx_ref">2018</a>)</cite>
 2018
 Learning 
<br class="ltx_break">Systems
 By presenting a novel approach called Federated-Autonomous Deep Learning, this study illustrates the efficacy of FL by using ICU data from 58 different hospitals to predict patient mortality can be trained quickly without transferring health data out of their silos under FL environment (FADL) 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p10" class="ltx_para">
<p id="S2.SS4.SSS3.p10.1" class="ltx_p">Patient Clustering Improves Efficiency of Federated Machine Learning to predict mortality and hospital stay time using distributed Electronic Medical Records
 <cite class="ltx_cite ltx_citemacro_citep">(Huang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2019</a>)</cite>
 2019
 FL in 
<br class="ltx_break">Biomedical</p>
</div>
<div id="S2.SS4.SSS3.p11" class="ltx_para">
<p id="S2.SS4.SSS3.p11.1" class="ltx_p">The community-based federated machine learning (CBFL) technique is described in this research, and it is tested on non-IID ICU EMRs. 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p12" class="ltx_para">
<p id="S2.SS4.SSS3.p12.1" class="ltx_p">FedHealth: A Federated Transfer Learning Framework for Wearable Healthcare
 <cite class="ltx_cite ltx_citemacro_citep">(Chen
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2020</a>)</cite>
 2019
 FL in 
<br class="ltx_break">Healthcare IoT
 To address data privacy concerns, this paper proposes a federated transfer learning system for wearable healthcare 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p13" class="ltx_para">
<p id="S2.SS4.SSS3.p13.1" class="ltx_p">Communication-Efficient Federated Deep Learning with Asynchronous Model Update and Temporally Weighted Aggregation
 <cite class="ltx_cite ltx_citemacro_citep">(Chen
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib21" title="" class="ltx_ref">2020</a>)</cite>
 2019
 Learning 
<br class="ltx_break">Systems
 This paper presents a synchronous learning strategy for FL clients 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p14" class="ltx_para">
<p id="S2.SS4.SSS3.p14.1" class="ltx_p">Federated deep learning for detecting COVID-19 lung abnormalities in CT: a privacy-preserving multinational validation study
 <cite class="ltx_cite ltx_citemacro_citep">(Dou etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib33" title="" class="ltx_ref">2021</a>)</cite>
 2019
 Diagnosis
 With external validation on patients from a global cohort, this report reveals the efficiency of an FL system for identifying COVID-19 associated CT anomalies 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p15" class="ltx_para">
<p id="S2.SS4.SSS3.p15.1" class="ltx_p">Federated Learning for Healthcare Informatics
 <cite class="ltx_cite ltx_citemacro_citep">(Xu
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib122" title="" class="ltx_ref">2021c</a>)</cite>
 2019
 Survey
 This survey study provides an overview of federated learning systems, focusing on biomedical applications 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p16" class="ltx_para">
<p id="S2.SS4.SSS3.p16.1" class="ltx_p">Federated electronic health records research technology to support clinical trial protocol optimization: Evidence from EHR4CR and the InSite platform
 <cite class="ltx_cite ltx_citemacro_citep">(Claerhout
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2019</a>)</cite>
 2019
 FL in
<br class="ltx_break">EHR data
 This paper determines if inclusion/exclusion (I/E) criteria of clinical trial protocols can be represented as structured queries along with those executed using a secure federated research platform (InSite) on hospital electronic health records (EHR) 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p17" class="ltx_para">
<p id="S2.SS4.SSS3.p17.1" class="ltx_p">Predicting Adverse Drug Reactions on Distributed Health Data using Federated Learning
 <cite class="ltx_cite ltx_citemacro_citep">(Choudhury etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2019</a>)</cite>
 2019
 Framework
 To increase the global modelâ€™s predictive power, this research proposes two unique approaches to local model aggregation 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p18" class="ltx_para">
<p id="S2.SS4.SSS3.p18.1" class="ltx_p">Privacy-preserving Federated Brain Tumour Segmentation
 <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib71" title="" class="ltx_ref">2019</a>)</cite>
 2019
 FL in 
<br class="ltx_break">Biomedical
 Adopting the BraTS dataset for brain tumor segmentation, this research investigates the possibility of using differential-privacy approaches to secure patient data in a federated learning context 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p19" class="ltx_para">
<p id="S2.SS4.SSS3.p19.1" class="ltx_p">Multi-site fMRI Analysis Using Privacy-preserving Federated Learning and Domain Adaptation: ABIDE Results
 <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2020a</a>)</cite>
 2020
 Medical Image 
<br class="ltx_break">Analysis
 This work proposes a privacy-preserving multi-site fMRI classification that ensures that private information cannot be retrieved from model gradients or weights 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p20" class="ltx_para">
<p id="S2.SS4.SSS3.p20.1" class="ltx_p">Stochastic Channel-Based Federated Learning With Neural Network Pruning for Medical Data Privacy Preservation: Model Development and Experimental Validation
 <cite class="ltx_cite ltx_citemacro_citep">(Shao
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib102" title="" class="ltx_ref">2020</a>)</cite>
 2020
 Learning 
<br class="ltx_break">Systems
 For the study of distributed medical data, this research proposes a privacy-preserving approach called stochastic channel-based federated learning (SCBFL) 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p21" class="ltx_para">
<p id="S2.SS4.SSS3.p21.1" class="ltx_p">Federated learning in medicine: facilitating multi-institutional collaborations without sharing patient data
 <cite class="ltx_cite ltx_citemacro_citep">(Sheller
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib103" title="" class="ltx_ref">2020</a>)</cite>
 2020
 Medicine
 This research shows that utilizing data from ten universities, the models achieve 99 percent model quality and discuss the impact of data distribution across participating institutions 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p22" class="ltx_para">
<p id="S2.SS4.SSS3.p22.1" class="ltx_p">FedHome: Cloud-Edge based Personalized Federated Learning for In-Home Health Monitoring
 <cite class="ltx_cite ltx_citemacro_citep">(Wu
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib118" title="" class="ltx_ref">2020a</a>)</cite>
 2020
 FL in 
<br class="ltx_break">Healthcare IoT
 FedHome, a cloud-edge-based federated learning architecture for in-home health monitoring, is proposed in this research 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p23" class="ltx_para">
<p id="S2.SS4.SSS3.p23.1" class="ltx_p">The future of digital health with federated learning
 <cite class="ltx_cite ltx_citemacro_citep">(Rieke etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib96" title="" class="ltx_ref">2020</a>)</cite>
 2020
 Survey
 This survey report looks at how FL could help with the future of digital health, as well as the obstacles 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p24" class="ltx_para">
<p id="S2.SS4.SSS3.p24.1" class="ltx_p">Federated Learning on Clinical Benchmark Data: Performance Assessment
 <cite class="ltx_cite ltx_citemacro_citep">(Lee and Shin, <a href="#bib.bib66" title="" class="ltx_ref">2020</a>)</cite>
 2020
 Benchmark
 The research uses three benchmark datasets, including a clinical benchmark dataset, to assess the reliability and performance of FL 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p25" class="ltx_para">
<p id="S2.SS4.SSS3.p25.1" class="ltx_p">FedMed: A Federated Learning Framework for Language Modeling
 <cite class="ltx_cite ltx_citemacro_citep">(Wu
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib119" title="" class="ltx_ref">2020b</a>)</cite>
 2020
 Framework
 To address model aggregation and communication costs in the FL environment, this study provides a unique Federated Mediation (FedMed) framework with adaptive aggregation, mediation incentive scheme, and topK method 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p26" class="ltx_para">
<p id="S2.SS4.SSS3.p26.1" class="ltx_p">Federated Learning for Breast Density Classification: A Real-World Implementation
 <cite class="ltx_cite ltx_citemacro_citep">(Roth
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib97" title="" class="ltx_ref">2020</a>)</cite>
 2020
 Medical Image 
<br class="ltx_break">Analysis
 This article demonstrates the efficacy of FL by training a model for breast density categorization based on Breast Imaging, Reporting, and Data systems utilizing data from seven clinical institutions across the world (BI-RADS) 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p27" class="ltx_para">
<p id="S2.SS4.SSS3.p27.1" class="ltx_p">Federated Transfer Learning for EEG Signal Classification
 <cite class="ltx_cite ltx_citemacro_citep">(Ju
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2020a</a>)</cite>
 2020
 Learning 
<br class="ltx_break">Systems
 This work proposes a unique privacy-preserving DL architecture called federated transfer learning that uses the FL in EEG classification (FTL) 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p28" class="ltx_para">
<p id="S2.SS4.SSS3.p28.1" class="ltx_p">COVID-19 detection using federated machine learning
 <cite class="ltx_cite ltx_citemacro_citep">(Salam
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib99" title="" class="ltx_ref">2021</a>)</cite>
 2021
 Diagnosis
 To determine which parameters impact model prediction accuracy and loss, this study employed a descriptive dataset and chest x-ray (CXR) images from COVID-19 patients in an FL context 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p29" class="ltx_para">
<p id="S2.SS4.SSS3.p29.1" class="ltx_p">Implementing Vertical Federated Learning Using Autoencoders: Practical Application, Generalizability, and Utility Study
 <cite class="ltx_cite ltx_citemacro_citep">(Cha
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib17" title="" class="ltx_ref">2021</a>)</cite>
 2021
 Learning 
<br class="ltx_break">Systems
 Without revealing the raw data, this research shows that FL on vertically partitioned data may perform equivalent to centralized models 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p30" class="ltx_para">
<p id="S2.SS4.SSS3.p30.1" class="ltx_p">Federated Learning Meets Human Emotions: A Decentralized Framework for Humanâ€“Computer Interaction for IoT Applications
 <cite class="ltx_cite ltx_citemacro_citep">(Chhikara etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib24" title="" class="ltx_ref">2021</a>)</cite>
 2021
 FL in 
<br class="ltx_break">Biomedical
 This article combines facial expression and voice inputs to construct an emotion monitoring &amp; analysis system using FL 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p31" class="ltx_para">
<p id="S2.SS4.SSS3.p31.1" class="ltx_p">FeARH: Federated machine learning with anonymous random hybridization on electronic medical records
 <cite class="ltx_cite ltx_citemacro_citep">(Cui
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib29" title="" class="ltx_ref">2021</a>)</cite>
 2021
 Learning 
<br class="ltx_break">Systems
 This research study suggests a novel FL method to deal with untrustworthy conditions 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p32" class="ltx_para">
<p id="S2.SS4.SSS3.p32.1" class="ltx_p">Federated Learning for Thyroid Ultrasound Image Analysis to Protect Personal Information: Validation Study in a Real Health Care Environment
 <cite class="ltx_cite ltx_citemacro_citep">(Lee
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib67" title="" class="ltx_ref">2021</a>)</cite>
 2021
 Diagnosis
 The purpose of this research is to see if FLâ€™s performance is equivalent to that of traditional deep learning 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p33" class="ltx_para">
<p id="S2.SS4.SSS3.p33.1" class="ltx_p">Learning From Others Without Sacrificing Privacy: Simulation Comparing Centralized and Federated Machine Learning on Mobile Health Data
 <cite class="ltx_cite ltx_citemacro_citep">(Liu
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib74" title="" class="ltx_ref">2021</a>)</cite>
 2021
 FL in 
<br class="ltx_break">Healthcare IoT
 The research explores FL use cases in a mHealth environment and uses a mHealth data set to simulate federated learning 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p34" class="ltx_para">
<p id="S2.SS4.SSS3.p34.1" class="ltx_p">Cloud-Based Federated Learning Implementation Across Medical Centers
 <cite class="ltx_cite ltx_citemacro_citep">(Rajendran
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib95" title="" class="ltx_ref">2021</a>)</cite>
 2021
 FL in
<br class="ltx_break">EHR data
 This research mimics an FL environment in order to investigate multiple federated learning implementations and apply FL algorithms to data from two academic medical facilitiesâ€™ electronic health records 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p35" class="ltx_para">
<p id="S2.SS4.SSS3.p35.1" class="ltx_p">Federated learning improves site performance in multicenter deep learning without data sharing
 <cite class="ltx_cite ltx_citemacro_citep">(Sarma etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib100" title="" class="ltx_ref">2021</a>)</cite>
 2021
 FL in
<br class="ltx_break">EHR data
 This study demonstrates how to provide multi-institutional training in a FL environment without centralization 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p36" class="ltx_para">
<p id="S2.SS4.SSS3.p36.1" class="ltx_p">A Resource-Constrained and Privacy-Preserving Edge-Computing-Enabled Clinical Decision System: A Federated Reinforcement Learning Approach
 <cite class="ltx_cite ltx_citemacro_citep">(Xue
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib125" title="" class="ltx_ref">2021</a>)</cite>
 2021
 FL in
<br class="ltx_break">EHR data
 This article combines mobile-edge computing (MEC) with software-defined networking to make use of the processing and storage capabilities available among edge nodes (ENs) (i.e., MEC servers) in the Fl environment 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p37" class="ltx_para">
<p id="S2.SS4.SSS3.p37.1" class="ltx_p">Variation-Aware Federated Learning with Multi-Source Decentralized Medical Image Data
 <cite class="ltx_cite ltx_citemacro_citep">(Yan
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib126" title="" class="ltx_ref">2021</a>)</cite>
 2021
 Learning 
<br class="ltx_break">Systems
 Variation-aware federated learning (VAFL) is a methodology proposed in this research for minimising client variations by transforming all clientsâ€™ images into a shared image space 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p38" class="ltx_para">
<p id="S2.SS4.SSS3.p38.1" class="ltx_p">Federated Learning in a Medical Context: A Systematic Literature Review
 <cite class="ltx_cite ltx_citemacro_citep">(Pfitzner
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib90" title="" class="ltx_ref">2021</a>)</cite>
 2021
 Survey
 This survey article examines federated learning and its relevance to sensitive healthcare data 
<br class="ltx_break"></p>
</div>
<div id="S2.SS4.SSS3.p39" class="ltx_para">
<p id="S2.SS4.SSS3.p39.1" class="ltx_p">Federated Learning for Smart Healthcare: A Survey
 <cite class="ltx_cite ltx_citemacro_citep">(Nguyen etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib83" title="" class="ltx_ref">2021</a>)</cite>
 2021
 Survey
 The application of FL in smart healthcare and IoT devices are reviewed and surveyed in this survey report 
<br class="ltx_break"></p>
</div>
</section>
</section>
<section id="S2.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5. </span><span id="S2.SS5.1.1" class="ltx_text ltx_font_bold">Machine Learning Pipeline</span>
</h3>

<div id="S2.SS5.p1" class="ltx_para">
<p id="S2.SS5.p1.1" class="ltx_p">The life cycle of a federated learning system consists of 8 primary steps which include task initialisation, selection, configuration, model training, client server communication, scheduling and optimisation, versioning testing deployment and termination. The steps are illustrated in the diagram shown below. (fig 6)</p>
</div>
<figure id="S2.F6" class="ltx_figure"><img src="/html/2211.07893/assets/x6.png" id="S2.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="174" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6. </span>Machine Learning Pipeline</figcaption>
</figure>
<div id="S2.SS5.p2" class="ltx_para">
<p id="S2.SS5.p2.1" class="ltx_p">In FL settings, three major machine learning steps include model selection, model training, and hyperparameter tuning.</p>
</div>
<section id="S2.SS5.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.5.1. </span>Model Selection</h4>

<div id="S2.SS5.SSS1.p1" class="ltx_para">
<p id="S2.SS5.SSS1.p1.1" class="ltx_p">The model selection stage includes the process of selecting the optimal model for federated data. Model selection depends on the type of task as well as size, quality, and type of the federated data. For example, if the problem is classification on diagnostic images, A convolution neural network is the best choice for this task. There have been several attempts in recent years to propose and create new models for federated settings. However, most FL tasks consider state-of-the-art, widely used models in their setting. Neural networks (NN) are the most popular and state-of-the-art in many machine learning tasks in the FL setting. For example, <cite class="ltx_cite ltx_citemacro_citep">(Hard etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib44" title="" class="ltx_ref">2019</a>)</cite> uses a variant of LSTM called Coupled Input and Forget Gate (CIFG) to predict the next word in the mobile keyboard. <cite class="ltx_cite ltx_citemacro_citep">(Chen
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib22" title="" class="ltx_ref">2021</a>)</cite> uses a specific Convolutional Neural Network (CNN) network with a transfer learning method for the classification task. A tree-based FLS has shown impressive performance on classification and regression tasks. <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib68" title="" class="ltx_ref">2021</a>)</cite> used the FLSs for Gradient boosting decision trees (GBDTs) on horizontally and vertically federated data, respectively. Most Federated Learning frameworks use stochastic gradient descent methods to optimize machine learning models such as neural networks and logistic regression. Besides Neural Networks and tree-based networks, linear models (e.g., linear regression, support vector machines) are standard and easy-to-use methods.</p>
</div>
</section>
<section id="S2.SS5.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.5.2. </span>Model Training</h4>

<div id="S2.SS5.SSS2.p1" class="ltx_para">
<p id="S2.SS5.SSS2.p1.1" class="ltx_p">Following the selection of a model, the next stage in the ML pipeline is model training. Different variants of the model and a combination of optimizing hyperparameters are used to decide the final model with good accuracy. This process <cite class="ltx_cite ltx_citemacro_citep">(Barroso etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite> involves the following steps</p>
<ul id="S2.I4" class="ltx_itemize">
<li id="S2.I4.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I4.i1.p1" class="ltx_para">
<p id="S2.I4.i1.p1.1" class="ltx_p">Training the local models on their local training dataset</p>
</div>
</li>
<li id="S2.I4.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I4.i2.p1" class="ltx_para">
<p id="S2.I4.i2.p1.1" class="ltx_p">Sharing of the local parameters to the server</p>
</div>
</li>
<li id="S2.I4.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I4.i3.p1" class="ltx_para">
<p id="S2.I4.i3.p1.1" class="ltx_p">Aggregation of local modelsâ€™ parameters on the server using the aggregation operator and</p>
</div>
</li>
<li id="S2.I4.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I4.i4.p1" class="ltx_para">
<p id="S2.I4.i4.p1.1" class="ltx_p">Updating the local models with the aggregated global model</p>
</div>
</li>
<li id="S2.I4.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I4.i5.p1" class="ltx_para">
<p id="S2.I4.i5.p1.1" class="ltx_p">Repeat the loop</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2.SS5.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">2.5.3. </span>Model Parameters</h4>

<div id="S2.SS5.SSS3.p1" class="ltx_para">
<p id="S2.SS5.SSS3.p1.1" class="ltx_p">The parameters are learned from federated data, and hyper-parameters are utilized to fine-tune the output for the best match. The hyper-parameters such as learning rate, number of training epochs, mini-batch size, and optimizer have to be tuned based on the constraints of the ML application (e.g., available computing power, available memory, bandwidth). <cite class="ltx_cite ltx_citemacro_citep">(Wang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib117" title="" class="ltx_ref">2019</a>)</cite> demonstrated how local data could be used to fine-tune federated models. They provided methods for determining the appropriate hyper-parameters for fine-tuning and proved that it enhances modelsâ€™ next word prediction in mobile keyboards. <cite class="ltx_cite ltx_citemacro_citep">(Yu
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib133" title="" class="ltx_ref">2020</a>)</cite> offered numerous variations of the fine-tuning strategy to improve the local adaptation.
The network architecture is designed manually, which takes a significant amount of effort and experience in that field. Neural Architecture Search (NAS) is an algorithmic-based method to search the neural network design utilizing optimization algorithms. In recent years there has been progress in federated neural architecture search. It aims to optimize the design of models in the federated learning environment. The offline federated NAS framework proposed by <cite class="ltx_cite ltx_citemacro_citep">(Zhu
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib136" title="" class="ltx_ref">2020</a>)</cite> uses a multi-objective evolutionary algorithm to design the optimal network.</p>
</div>
</section>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span><span id="S3.1.1" class="ltx_text ltx_font_bold">Challenges &amp; Issues</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Some various challenges and issues can be found at each step in the implementation of a federated learning system. In this paper, we classify the challenges and issues into three major subcategories. The first subcategory involves all issues related to the privacy of the model and the attacks that happen on the system. The second subcategory consists of papers that describe the issues related to data such as limited data, data bias, or data poisoning.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">The kinds of communication that can take place in a federated learning setup are between a server and an edge device, between two edge devices, and or between more than one server. The main challenge here is to answer some of the following questions: how effective can this communication be without having to lose the participating devices? How can the number of communication rounds be reduced to avoid large usage of battery or net on edge devices? And, how can all of this be done without affecting the model and its result metrics? This subsection brings down papers addressing these major issues. Hence, the third subsection speaks about communication challenges. An illustration of this section is presented in figure 7.</p>
</div>
<figure id="S3.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2211.07893/assets/x7.png" id="S3.F7.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="461" height="148" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7. </span>Challenges of Federated Learning in healthcare</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S3.F7.1" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S3.F7.2" class="ltx_p ltx_figure_panel ltx_align_center">A woman and a girl in white dresses sit in an open car.</p>
</div>
</div>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span><span id="S3.SS1.1.1" class="ltx_text ltx_font_bold">Privacy and attacks</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<ul id="S3.I1" class="ltx_itemize">
<li id="S3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i1.p1" class="ltx_para">
<p id="S3.I1.i1.p1.1" class="ltx_p"><span id="S3.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Adversarial Attacks</span>
Improper or inadequate learning refers to cases where improper hyperparameters are learned in the ML/DL model, e.g., learning rate, epochs, batch size. In a predictive healthcare setting, machine learning models are created using previous patient data and then evaluated on new patients, raising concerns about the validity of the predictions.This is because of distribution shifts.And such differences can be exploited for generating adversarial examples <cite class="ltx_cite ltx_citemacro_citep">(Papernot etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib87" title="" class="ltx_ref">2016</a>)</cite> which is now a huge concern. In addition, ML/DL versions are strictly susceptible to various risks to the protection and privacy, such as adversarial attacks <cite class="ltx_cite ltx_citemacro_citep">(Szegedy etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib109" title="" class="ltx_ref">2014</a>; Biggio
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib12" title="" class="ltx_ref">2013</a>)</cite></p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i2.p1" class="ltx_para">
<p id="S3.I1.i2.p1.1" class="ltx_p"><span id="S3.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Inference and poisoning attacks</span>
Federated learning systems are yet to be aware of the future federated learning algorithm design on privacy preservation. <cite class="ltx_cite ltx_citemacro_citep">(Lyu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib77" title="" class="ltx_ref">2020</a>)</cite> This survey on threats to federated learning provides a concise introduction to the topic of federated learning and the two major federated learning methods are exposed to, inference attacks and poisoning attacks. It also summarizes the kinds of threat models a system can be prone to and highlights the key techniques as well as fundamental assumptions adopted by various attackers.</p>
</div>
</li>
<li id="S3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i3.p1" class="ltx_para">
<p id="S3.I1.i3.p1.1" class="ltx_p"><span id="S3.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Evasion Attack</span>
Evasion/exploratory attacks are among the most common adversarial attacks and are carried out during the inference time. This setting does not imply any influence over the training data. In this attack, an adversary attempts to evade the deployed model by feeding malicious data samples or collecting evidence about the model features during the inference phase. The amount of knowledge available to the adversary about the model determines the efficiency of such attacks. Various methods have been presented to make the FL models more robust against evasion attacks.</p>
</div>
</li>
<li id="S3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i4.p1" class="ltx_para">
<p id="S3.I1.i4.p1.1" class="ltx_p"><span id="S3.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Inadequate model training</span></p>
</div>
<div id="S3.I1.i4.p2" class="ltx_para">
<p id="S3.I1.i4.p2.1" class="ltx_p">Machine learning models while training may involve flaws. The model training flaws include improper or inadequate training, violations of privacy, model poisoning, or theft. Improper or inadequate learning refers to cases where improper parameters are learned in the ML/DL model, e.g., learning rate, epochs, batch size. The deployment of the model involving ML/DL techniques mainly revolves around human-centric decisions. And hence, considering fairness, accountability while ensuring the robustness of the system is crucial at this stage. The deployment stage can involve Evasion attacks, System Disruption, Network Issues, etc.</p>
</div>
</li>
<li id="S3.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i5.p1" class="ltx_para">
<p id="S3.I1.i5.p1.1" class="ltx_p"><span id="S3.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Gradient Inversion Attack</span></p>
</div>
<div id="S3.I1.i5.p2" class="ltx_para">
<p id="S3.I1.i5.p2.1" class="ltx_p">This attack strategy implies that it is possible to recover and reconstruct input data from the gradient knowledge of trained and untrained model parameters. <cite class="ltx_cite ltx_citemacro_citep">(Geiping etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib40" title="" class="ltx_ref">2020</a>)</cite> investigates the impact of design and settings on the difficulty of reconstructing an input image from grading data and demonstrates that any input to a fully connected layer could be reconstructed analytically without regard to the rest of the model design.</p>
</div>
</li>
<li id="S3.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I1.i6.p1" class="ltx_para">
<p id="S3.I1.i6.p1.1" class="ltx_p"><span id="S3.I1.i6.p1.1.1" class="ltx_text ltx_font_bold">Privacy in Genomic Data</span></p>
</div>
<div id="S3.I1.i6.p2" class="ltx_para">
<p id="S3.I1.i6.p2.1" class="ltx_p">The human genome is a complete set of genetic information of a human living organism composed of 4 different bases (A, T, G, C) and can provide a treasure of highly sensitive and personal information of an individual. With the innovation in the next-generation technologies, a whole new genome complex can be determined of an organism. The use of genome sequencing is used for purposes like personalized genomic medicine, disease diagnosis, and preventive treatment. <cite class="ltx_cite ltx_citemacro_citep">(AkgÃ¼n etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib3" title="" class="ltx_ref">2015</a>)</cite> discusses the various privacy issues in genomic data processing such as querying on genomic data and carrying alignment processes on commercial public clouds in a privacy-preserving and effective manner. The paper also concludes that despite the innovations and study in medicines and health science, the use of sequencing technology still lacks privacy preservation of genomic data leading to a lot of genomic data leakage.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span><span id="S3.SS2.1.1" class="ltx_text ltx_font_bold">Challenges related to Data</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<ul id="S3.I2" class="ltx_itemize">
<li id="S3.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I2.i1.p1" class="ltx_para">
<p id="S3.I2.i1.p1.1" class="ltx_p"><span id="S3.I2.i1.p1.1.1" class="ltx_text ltx_font_bold">Noises in different kinds of data</span>
The healthcare industries face a huge threat when it comes to data collection. Large amounts of clinical data are collected in the form of EHRs, medical images, radiology reports, etc.. which requires a lot of human effort and is time-consuming. Multishot MRI, one of the widely used imaging modalities used to acquire high-resolution medical images can involve Instrumental and Environmental Noise due to some undesirable artifacts in the resulting image <cite class="ltx_cite ltx_citemacro_citep">(Qayyum
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib93" title="" class="ltx_ref">2020</a>)</cite>
A variety of health data including patient data from multi-omic approaches, as well as clinical, behavioral, environmental, and drug data can be analyzed using the AI technologies being developed at the present. <cite class="ltx_cite ltx_citemacro_citep">(Wang and
Preininger, <a href="#bib.bib115" title="" class="ltx_ref">2019</a>)</cite> mentions five major types of data used in AI for health such as multi-omics data, clinical data, behavioral/wellness data, environmental data, as well as research and development data. Each data type has its challenges, implications, and future directions.</p>
</div>
</li>
<li id="S3.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I2.i2.p1" class="ltx_para">
<p id="S3.I2.i2.p1.1" class="ltx_p"><span id="S3.I2.i2.p1.1.1" class="ltx_text ltx_font_bold">Improper annotation of data</span></p>
</div>
<div id="S3.I2.i2.p2" class="ltx_para">
<p id="S3.I2.i2.p2.1" class="ltx_p">Healthcare datasets involve annotation of data samples which is a crucial step in the process of healthcare applications. Hence, they should be performed by legally keeping privacy concerns in mind and with proper guidelines. The inability to perform labeling rightly leads to improper annotations and many efficiency challenges like imbalanced dataset, class imbalance, and Bias and data sparsity <cite class="ltx_cite ltx_citemacro_citep">(Qayyum
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib93" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
</li>
<li id="S3.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I2.i3.p1" class="ltx_para">
<p id="S3.I2.i3.p1.1" class="ltx_p"><span id="S3.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">Data biases</span>
Data biases <cite class="ltx_cite ltx_citemacro_citep">(Kairouz
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib60" title="" class="ltx_ref">2021a</a>)</cite> act as the main driver of unfairness in machine learning models. It can result in high risks when used in federated learning systems. Moreover, biases can end up affecting areas like training data, cognitive sampling, reporting, and confirmation biases.
Artificial intelligence (AI) models often need a vast volume of high-quality training data, which contrasts sharply with the existing drug development pipelinesâ€™ limited and skewed data. And, this decentralized machine learning paradigm has a high scope in contributing to the improvement of AI-Based drug discovery <cite class="ltx_cite ltx_citemacro_citep">(Xiong etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib121" title="" class="ltx_ref">2020</a>)</cite>. The superiority of the federated learning mechanism is demonstrated on pooled datasets with 7 aqueous solubility datasets including high and low biases. The authors also address the small data and biased data dilemma in drug discovery and prove the promising role of federated learning.</p>
</div>
</li>
<li id="S3.I2.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I2.i4.p1" class="ltx_para">
<p id="S3.I2.i4.p1.1" class="ltx_p"><span id="S3.I2.i4.p1.1.1" class="ltx_text ltx_font_bold">False positives and false negatives</span>
The Healthcare industry deals with a large amount of patient data and this involves high chances of containing missing observations or variables. However, ignoring these values during analysis by knowing their relationships with already observed and unobserved data is the simplest way to avoid them. On the other hand, using these missing observations leads to well-known problems like false positives and false negatives and thus there is a need for complete and compact healthcare data. Issues like false positives and false negatives not only are caused due to the use of missing values but also due to incomplete training or inefficient training of the model. The root cause behind inefficient training is the incomplete data being fed for inference. ML-powered healthcare demands cautious applications of analytical methods <cite class="ltx_cite ltx_citemacro_citep">(Pollard etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib91" title="" class="ltx_ref">2019</a>)</cite>. And that is why along with quantity, quality of data also plays a major role.</p>
</div>
</li>
<li id="S3.I2.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I2.i5.p1" class="ltx_para">
<p id="S3.I2.i5.p1.1" class="ltx_p"><span id="S3.I2.i5.p1.1.1" class="ltx_text ltx_font_bold">Data Quality</span>
<cite class="ltx_cite ltx_citemacro_citep">(Carlsson, <a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite> A survey paper on applicable machine learning algorithms in a federated environment mentions the importance of Independent and Identically Distributed (IID) Data points and their contribution to the factor of lowering the chances of class imbalance. Many times the local data collected can lack in size and major data points which may obstruct representing the underlying structure of a federated learning system. Using such a small-sized imbalance dataset has high chances of hindering the globe model and its accuracy.
<cite class="ltx_cite ltx_citemacro_citep">(Jochems etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib56" title="" class="ltx_ref">2017</a>)</cite> has trained the global model on historical patient data of Radiation Therapy (RT); because RT technique is constantly evolving, such models provide little value to clinical practice today. In addition, Phase III clinical trials give high-quality evidence, but they have the drawback of taking a long time to complete. However, Including more recent patient data and updating the model with the most up-to-date practice insights might help alleviate the problem.
According to the author of the <cite class="ltx_cite ltx_citemacro_citep">(Yigzaw etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib131" title="" class="ltx_ref">2020</a>)</cite>, federated learning for an institution/hospital takes several months to develop. Furthermore, obtaining data from electronic health records(EHR) remains challenging since data is typically dispersed across several databases and apps.</p>
</div>
</li>
<li id="S3.I2.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I2.i6.p1" class="ltx_para">
<p id="S3.I2.i6.p1.1" class="ltx_p"><span id="S3.I2.i6.p1.1.1" class="ltx_text ltx_font_bold">Data Leakage</span>
Federated learning provides a solution that enhances data privacy, which is a crucial concern of FL training. However, some work has proposed showing the leakage in federated learning representing a still unexplored area of research due to several factors that may result in security issues. A quantifiable method of measuring privacy would enable better choices about the minimum privacy settings required to sustain clinically acceptable results <cite class="ltx_cite ltx_citemacro_citep">(Flores etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2021a</a>)</cite>.</p>
</div>
</li>
<li id="S3.I2.i7" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I2.i7.p1" class="ltx_para">
<p id="S3.I2.i7.p1.1" class="ltx_p"><span id="S3.I2.i7.p1.1.1" class="ltx_text ltx_font_bold">Patient Variability</span></p>
</div>
<div id="S3.I2.i7.p2" class="ltx_para">
<p id="S3.I2.i7.p2.1" class="ltx_p">Care varies widely between locations, with significant variation in performance across indicators. Hospital levels could explain more of the observed diversity than clinician levels.</p>
</div>
<div id="S3.I2.i7.p3" class="ltx_para">
<p id="S3.I2.i7.p3.1" class="ltx_p">In a study, more than 7,000 cardiovascular patients were treated with adult stem cells <cite class="ltx_cite ltx_citemacro_citep">(FernÃ¡ndezâ€AvilÃ©s
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib37" title="" class="ltx_ref">2017</a>)</cite>
However, the data so far has revealed neutral or minor advantages. One of the most important questions to explore when thinking about designing better trials is why there is so much variation both across and within trials. Patients in the FOCUS-CCTRN trial <cite class="ltx_cite ltx_citemacro_citep">(Perin etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib89" title="" class="ltx_ref">2012</a>)</cite> received autologous bone marrow cells to treat chronic ischemic heart disease. Several cardiac clinical outcomes showed no improvement when compared to placebo. On the other hand, individual patient outcomes were highly varied <cite class="ltx_cite ltx_citemacro_citep">(Beachy
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib11" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S3.I2.i7.p4" class="ltx_para">
<p id="S3.I2.i7.p4.1" class="ltx_p">Care variability or uneven care practices has an impact on many elements of healthcare delivery. It can assist improve patient safety, reducing healthcare expenditures, and improving key performance indicators (KPIs) for both people and the healthcare system by minimizing variability of care.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span><span id="S3.SS3.1.1" class="ltx_text ltx_font_bold">Communication Challenges</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<ul id="S3.I3" class="ltx_itemize">
<li id="S3.I3.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I3.i1.p1" class="ltx_para">
<p id="S3.I3.i1.p1.1" class="ltx_p"><span id="S3.I3.i1.p1.1.1" class="ltx_text ltx_font_bold">Failure or dropouts during communication</span>
While distributed learning conjointly aims at training one model on multiple servers, a standard underlying assumption is that the native datasets are Identically Distributed (IID) and roughly have constant size. None of those hypotheses are created for federated learning; instead, the datasets are usually heterogeneous and their sizes could span over many orders of magnitude. Moreover, the clients concerned in federated learning could also be unreliable as theyâ€™re subject to a lot of failures or drop out. Some clientsâ€™ models do not get included in every FL round due to interrupted connectivity or slow internet conditions. Those devices or models are called stragglers. <cite class="ltx_cite ltx_citemacro_citep">(Flores etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2021a</a>)</cite> Since the clients usually trust less powerful communication media (i.e. Wi-fi) and powered systems (i.e. smartphones and IoT devices) compared to distributed learning where nodes are usually data centers that have powerful procedure capabilities and are connected to at least one another with quick networks.</p>
</div>
<div id="S3.I3.i1.p2" class="ltx_para">
<p id="S3.I3.i1.p2.1" class="ltx_p">For an Edge AI task to be accomplished there are multiple communication rounds between edge nodes. Edge nodes are usually smartphones or devices. Small access to training data is available at every edge node that is participating in the training. These nodes then perform edge training which results in high communication costs especially in case of limited bandwidth. <cite class="ltx_cite ltx_citemacro_citep">(Zhao
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib134" title="" class="ltx_ref">2018</a>)</cite> The aim of communication in every round is to compute a certain function value concerning intermediate value at edge devices. The paper points out a challenge of alleviating communication overheads under privacy and resource constraints and the need of reducing the communication rounds for training and inference. The paper also introduces communication efficient methods to achieve efficient results. Communication methods for edge AI at the algorithmic level, zeroth-order method, first-order method, second-order method, and federated optimizations have been well illustrated and explained.</p>
</div>
</li>
<li id="S3.I3.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I3.i2.p1" class="ltx_para">
<p id="S3.I3.i2.p1.1" class="ltx_p"><span id="S3.I3.i2.p1.1.1" class="ltx_text ltx_font_bold">Computational and Communication Overhead</span></p>
</div>
<div id="S3.I3.i2.p2" class="ltx_para">
<p id="S3.I3.i2.p2.1" class="ltx_p">Communication has become one of the primary challenges for federated learning as the wireless networks and end-user internet connections can potentially become expensive and unreliable soon. <cite class="ltx_cite ltx_citemacro_citep">(Kairouz
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib61" title="" class="ltx_ref">2021b</a>)</cite> mentions how federated averaging and sparsification and/or quantization of model updates have demonstrated a significant reduction in communication cost with minimal impact on training accuracy.
<cite class="ltx_cite ltx_citemacro_citep">(Constable etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2015</a>)</cite> demonstrates that employing secure MPC experiments to do privacy-preserving federated genomic data analysis is more costly than performing the exact computation in a centralized non-encrypted environment.</p>
</div>
</li>
<li id="S3.I3.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S3.I3.i3.p1" class="ltx_para">
<p id="S3.I3.i3.p1.1" class="ltx_p"><span id="S3.I3.i3.p1.1.1" class="ltx_text ltx_font_bold">Energy consumption while communication</span></p>
</div>
<div id="S3.I3.i3.p2" class="ltx_para">
<p id="S3.I3.i3.p2.1" class="ltx_p">IoT(Internet of Things) involves widespread use of mobile devices involving computing and sensing capabilities which involves a collection of data at a societal scale. Valuable data collection and maintenance backed with centralized machine learning models entail security and privacy issues leading to less participation of devices in smart city methods. While the mechanics of privacy preservation in federated learning ensures the privacy of data is preserved, mobile crowdsensing involves a huge amount of energy consumption. Federated learning involves on-device training in turn earning leading to high consumption of batteries from local devices which inturn deters users from participating in the process. For instance, this <cite class="ltx_cite ltx_citemacro_citep">(Jiang
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib55" title="" class="ltx_ref">2020</a>)</cite> survey paper presents the potential of federated learning along with the overview of challenges and issues faced while incorporating federated learning into smart city sensing.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span><span id="S4.1.1" class="ltx_text ltx_font_bold">Application</span>
</h2>

<figure id="S4.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2211.07893/assets/x8.png" id="S4.F8.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="461" height="148" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8. </span>Applications of federated learning in healthcare</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S4.F8.1" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S4.F8.2" class="ltx_p ltx_figure_panel ltx_align_center">A woman and a girl in white dresses sit in an open car.</p>
</div>
</div>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span><span id="S4.SS1.1.1" class="ltx_text ltx_font_bold">Prognosis</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">Prognosis is a diagnostic term that refers to assessing the possible or potential progression of an illness, such as whether the signs and effects will change or worsen (and how quickly) or stay constant over time. The natural course of the diagnosed illness, the individualâ€™s physical and emotional health, the current medications, and other considerations are used to make a prognosis. Listed below are healthcare-related applications helping to perform a prognosis on a particular disease or type of data.</p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p"><span id="S4.SS1.p2.1.1" class="ltx_text ltx_font_bold">Privacy preserving stroke prevention</span>
An investigation into Facebookâ€™s data protection breaches in processing consumer information for uninformed usage has sparked recent data privacy issues. As a result, legislation such as the General Data Protection Regulation (GDPR) [Regulation, 2016] has been proposed to prevent organizations from sharing data without prior user consent. To fix data privacy, they use a new and efficient methodology called federated learning platform, which allows them to jointly train a machine learning model using data from multiple clients without directly exchanging data between them. Tencent and WeBank collaborated to create a privacy-preserving stroke prediction technology. Stroke prevention, as well as the risk factors associated with it, has long been a public health priority around the world. The scientists and engineers suggest a privacy-preserving scheme for predicting stroke risk and intend to use cloud servers to deploy the federated prediction model <cite class="ltx_cite ltx_citemacro_citep">(Ju etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib59" title="" class="ltx_ref">2020b</a>)</cite>.</p>
</div>
<div id="S4.SS1.p3" class="ltx_para">
<p id="S4.SS1.p3.1" class="ltx_p"><span id="S4.SS1.p3.1.1" class="ltx_text ltx_font_bold">Meta analysis on brain data</span>
In reality, data sharing is limited by the need to migrate vast amounts of biomedical data, as well as the administrative workload that comes with it. Researchers sought an analysis approach in meta-analysis or federated learning paradigms as a result of this situation. The Enhancing NeuroImaging Genetics by Meta-Analysis (ENIGMA) consortium is one of the best examples of this kind of research method. Brain scans of previously unimaginable amounts can be found in data banks all around the world. Due to various privacy and legal considerations, separate databases held at multiple locations cannot always be exchanged directly, restricting the use of big data in the study of brain disorders. A Federated learning platform allows them to jointly train a machine learning model using data from multiple clients without directly exchanging data between them. Addressing the issue of privacy and restrictions on sharing the data, the authors propose a federated learning system for safely accessing and meta-analyzing any biomedical data while maintaining individual privacy. They demonstrate the framework by using the ENIGMA Shape platform to provide the first implementation of federated analysis that is consistent with ENIGMAâ€™s standard pipelines <cite class="ltx_cite ltx_citemacro_citep">(Silva etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib105" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S4.SS1.p4" class="ltx_para">
<p id="S4.SS1.p4.1" class="ltx_p"><span id="S4.SS1.p4.1.1" class="ltx_text ltx_font_bold">Brain tumor segmentation</span>
Classification of electroencephalographic (EEG) recordings and brain tumor segmentation was difficult due to the need of large datasets <cite class="ltx_cite ltx_citemacro_citep">(Ju
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2020a</a>; Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib71" title="" class="ltx_ref">2019</a>)</cite>. This lack of large datasets has led to the success of deep learning (DL) methods in the field of Brain-Computer Interfaces (BCI). A novel privacy-preserving DL architecture has been suggested for EEG classification called federated transfer learning (FTL). A test proposed architectureâ€™s success on the PhysioNet dataset for 2-class motor imagery classification. <cite class="ltx_cite ltx_citemacro_citep">(Ju
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib58" title="" class="ltx_ref">2020a</a>)</cite> Demonstrating the possibility of implementing differential-privacy strategies to secure the patient data in a federated learning setup, a brain tumor segmentation was performed on the BraTS dataset <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib71" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S4.SS1.p5" class="ltx_para">
<p id="S4.SS1.p5.1" class="ltx_p"><span id="S4.SS1.p5.1.1" class="ltx_text ltx_font_bold">Breast density classification<cite class="ltx_cite ltx_citemacro_citep">(Roth
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib97" title="" class="ltx_ref">2020</a>)</cite></span>
For the advancement of clinically relevant models, hospitals and other academic institutes often need to partner and host centralized databases. Owing to data protection and ethical issues involved with data sharing in healthcare, this overhead will easily become a technical problem and typically necessitates a time-consuming approval process. And if these issues are overcome, data is precious, and organizations may choose not to exchange complete datasets. In a real-world collaborative environment, the use of federated learning (FL) to create a medical imaging classification model was demonstrated bringing together seven health organizations from around the world to train a model for breast density classification focused on Breast Imaging, Reporting, and Data System (BIRADS) <cite class="ltx_cite ltx_citemacro_citep">(Roth
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib97" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S4.SS1.p6" class="ltx_para">
<p id="S4.SS1.p6.1" class="ltx_p"><span id="S4.SS1.p6.1.1" class="ltx_text ltx_font_bold">Multi-Disease Chest X-ray classification</span></p>
</div>
<div id="S4.SS1.p7" class="ltx_para">
<p id="S4.SS1.p7.1" class="ltx_p">Deep learning approaches can yield important results in medical imaging analysis, although they involve a large volume of high-quality data. Since a client cannot have enough data to train and construct a quality model, working with multiple clients may address data insufficiency problems in deep learning but add privacy restrictions. This paper <cite class="ltx_cite ltx_citemacro_citep">(McMahan etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib78" title="" class="ltx_ref">2017</a>)</cite> proposes a federated deep learning method for multi-disease classification from chest X-rays, with pneumonia as an example. The FDL technique measures pneumonia from a chest X-ray and distinguishes between viral and bacterial pneumonia. Clients train local models with minimal private data at the edge server and send them to the central server for global aggregation without sending the chest-X-ray images to a central server <cite class="ltx_cite ltx_citemacro_citep">(Banerjee etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib9" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S4.SS1.p8" class="ltx_para">
<p id="S4.SS1.p8.1" class="ltx_p"><span id="S4.SS1.p8.1.1" class="ltx_text ltx_font_bold">Adverse Drug Reaction prediction</span></p>
</div>
<div id="S4.SS1.p9" class="ltx_para">
<p id="S4.SS1.p9.1" class="ltx_p">Since healthcare data is scattered, collecting a sufficiently comprehensive dataset to track rare cases entails combining data from various data silos. Analyses derived from various data sources may be contradictory or inaccurate, necessitating the use of tools to properly aggregate the information. A time lag exists between the ADR (adverse drug reaction) case, claim filing, adjudication, and claim consolidation into a database of current claims-based systems. As a result, there is an unmet need for reliable, flexible, and effective methods for forecasting ADRs using distributed health data while maintaining patient privacy. Since healthcare data is dispersed, assembling a robust dataset to document unusual events necessitates merging data from several data silos. To address the issue a federated learning-based system has been proposed, which allows health data to be shared across several platforms. Without ever transferring the raw data from their respective pages, the architecture helps one to train a global model based on each siteâ€™s local data. It is the first time federated machine learning algorithms have been used to forecast ADRs using distributed electronic health data <cite class="ltx_cite ltx_citemacro_citep">(Choudhury etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib25" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S4.SS1.p10" class="ltx_para">
<p id="S4.SS1.p10.1" class="ltx_p"><span id="S4.SS1.p10.1.1" class="ltx_text ltx_font_bold">Predictions on SARS-COV-2 chest X Rays</span></p>
</div>
<div id="S4.SS1.p11" class="ltx_para">
<p id="S4.SS1.p11.1" class="ltx_p">Confidential data all pose realistic difficulties when using electronic health data to forecast adverse drug reactions (ADR). Another example where there is a need for data collaboration is within clinical and science communities. When adapting to rapidly changing and pervasive environmental threats, the pandemic has highlighted the importance of quickly conducting data collaborations. One recent work on an AI-based SARS-COV-2 Clinical Decision Support (CDS) algorithm is a concrete example of these forms of partnerships. Another example is during the SARS-COV-2 pandemic, 20 institutes partnered on a healthcare FL study that used vital signs, laboratory results, and chest x-rays to predict possible oxygen needs of infected patients, resulting in the â€œEXAMâ€ (EMR CXR AI Model) <cite class="ltx_cite ltx_citemacro_citep">(Flores etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib38" title="" class="ltx_ref">2021a</a>)</cite>.</p>
</div>
<div id="S4.SS1.p12" class="ltx_para">
<p id="S4.SS1.p12.1" class="ltx_p"><span id="S4.SS1.p12.1.1" class="ltx_text ltx_font_bold">GWAS analysis on genomic datasets</span></p>
</div>
<div id="S4.SS1.p13" class="ltx_para">
<p id="S4.SS1.p13.1" class="ltx_p">The biomedical community benefits from the growing availability of genomic data for scientific studies, such as Genome-Wide Association Studies (GWAS). However, high-quality GWAS typically necessitates a large number of tests, which may exceed a single institutionâ€™s ability. Concerns regarding patient safety and clinical knowledge security arise from federated genomic data analysis (as data are being exchanged across institutional boundaries). On federated genomic databases, a privacy-preserving GWAS architecture. has been proposed where computations are layered on top of stable multi-party computation (MPC) structures <cite class="ltx_cite ltx_citemacro_citep">(Constable etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib28" title="" class="ltx_ref">2015</a>)</cite>.</p>
</div>
<div id="S4.SS1.p14" class="ltx_para">
<p id="S4.SS1.p14.1" class="ltx_p"><span id="S4.SS1.p14.1.1" class="ltx_text ltx_font_bold">NeuroLOG</span>
A creation of a framework OntoNeuroLOG was implemented by federating five neuroimaging data repositories in Paris, Rennes, Grenoble, and Sophia Antipolis. The creation of the framework OntoNeuroLOG and its use to confirm heterogeneous data to a standard model are the main features of this work. The project focuses on research implementations that need a multi-center, multi-disciplinary approach: 1) epilepsy (surgical treatment of drug-resistant epilepsy) and 2) neurodegenerative disorders (Alzheimerâ€™s disease) <cite class="ltx_cite ltx_citemacro_citep">(Gibaud etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib41" title="" class="ltx_ref">2011</a>)</cite></p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span><span id="S4.SS2.1.1" class="ltx_text ltx_font_bold">Diagnosis</span>
</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">The description of the type and origin of a certain phenomenon is referred to as diagnosis. Diagnosis is used in many different fields to assess â€cause and effect,â€ with differences in the application of logic, analytics, and practice. Listed below are healthcare-related applications helping to perform a diagnosis on a particular disease or type of data such as drug discovery, COVID-19 prediction at the edge, and the use of EHRs to improve mortality prediction.</p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p"><span id="S4.SS2.p2.1.1" class="ltx_text ltx_font_bold">COVID-19 diagnosis at the edge</span></p>
</div>
<div id="S4.SS2.p3" class="ltx_para">
<p id="S4.SS2.p3.1" class="ltx_p">COVID-19 has been a major focus of research in 2020, especially after the World Health Organization (WHO) declared it a pandemic in March, with various activities focused on diagnosis, prevention, and the production of a possible vaccine. Risk identification <cite class="ltx_cite ltx_citemacro_citep">(Pal and
Sankarasubbu, <a href="#bib.bib85" title="" class="ltx_ref">2021</a>)</cite>, touch monitoring, false news identification, emotion analysis, and screening and diagnosis are some of the main applications of data science approaches, especially machine learning and data visualization techniques, in the international response to the COVID-19 pandemic. Despite major advancements in recent years, cloud-based healthcare systems appear to be underutilized due to their shortcomings in meeting rigorous protection, privacy, and quality of service criteria (such as low latency). The authors take advantage of edge computingâ€™s capabilities in medicine by exploring and testing the ability of intelligent analysis of clinical visual data linked to COVID19 at the edge. They also enable remote healthcare centers to benefit from a multi-modal shared learning model without having to share any knowledge about the local dataâ€™s modality or the data itself. The authors suggest a CFL-based collective learning system for the role of COVID19 diagnosis with visual evidence such as X-rays, Ultrasound images, and CT Scans, based on an emerging idea of clustered federated learning (CFL) <cite class="ltx_cite ltx_citemacro_citep">(Qayyum etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib92" title="" class="ltx_ref">2021</a>)</cite></p>
</div>
<div id="S4.SS2.p4" class="ltx_para">
<p id="S4.SS2.p4.1" class="ltx_p"><span id="S4.SS2.p4.1.1" class="ltx_text ltx_font_bold">Estimation of blood pressure</span></p>
</div>
<div id="S4.SS2.p5" class="ltx_para">
<p id="S4.SS2.p5.1" class="ltx_p">According to the World Health Organization (WHO), chronic heart disease was the leading cause of death from 2000 to 2019, accounting for 16% of all global deaths in 2019. During this time, most deaths have been caused by heart disease. This not only has a significant impact on the lives of those involved but also on public healthcare services. Electrocardiogram (ECG) and blood pressure (BP) readings are widely used by clinicians to consider the dynamics between the healthy and dysfunctional core. These methods are also very invasive, particularly when continuous arterial blood pressure (ABP) readings are taken, and they are often quite expensive. To address the problem, the authors present a decentralized learning approach to continuous ABP calculation that is capable of large-scale real-world deployment while protecting patient privacy. This architecture, to their knowledge, is the first example of a GAN capable of continuous ABP generation from an input PPG signal and using a federated learning methodology <cite class="ltx_cite ltx_citemacro_citep">(Brophy
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib15" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S4.SS2.p6" class="ltx_para">
<p id="S4.SS2.p6.1" class="ltx_p"><span id="S4.SS2.p6.1.1" class="ltx_text ltx_font_bold">Data Variability in Medical Imaging</span></p>
</div>
<div id="S4.SS2.p7" class="ltx_para">
<p id="S4.SS2.p7.1" class="ltx_p">Deep learning has made rapid strides in image recognition and target detection in recent years. These advancements have also led to improvements in automating clinical processes within medical imaging, thanks to Convolutional Neural Networks (CNNs) pattern recognition abilities. Deep CNNs, for example, has paved the way for breakthroughs in retinopathy diagnosis, lung nodule identification, and brain tumor segmentation. Insufficient patient data makes it difficult to train deep learning models for medical applications, particularly for rare diseases. Efforts to share patient data are often hampered by legal, technological, and privacy issues. The current implementation of CWT has a major flaw in that it isnâ€™t designed to accommodate differences in sample sizes, mark distributions, resolution, and acquisition settings in training data through organizations. The authors <cite class="ltx_cite ltx_citemacro_citep">(Balachandar etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite> present CWT modifications to reduce output losses caused by heterogeneity in training sample sizes and mark ranges through academic training splits, and test the effectiveness of their changes on virtual dispersed tasks for (DR) identification and irregular chest radiograph classification. This is the first research to show that data heterogeneity in training sample sizes and mark distributions across institutions can cause distributed learning models for medical imaging to perform poorly <cite class="ltx_cite ltx_citemacro_citep">(Balachandar etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib8" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S4.SS2.p8" class="ltx_para">
<p id="S4.SS2.p8.1" class="ltx_p"><span id="S4.SS2.p8.1.1" class="ltx_text ltx_font_bold">A federated network for translational cancer research</span></p>
</div>
<div id="S4.SS2.p9" class="ltx_para">
<p id="S4.SS2.p9.1" class="ltx_p">Obtaining adequate quantities of annotated human tissues remains a major barrier to translational cancer science, which is needed to move cancer treatment closer to precision medicine. Major new bridging infrastructures, including more functional biorepositories that connect human tissue to clinical phenotypes and outcomes, are required for advancements in cancer science and personalized medicine. Cancer researchers have been at the forefront of creating biomedical data and resource sharing consortia, but they have traditionally relied on centralized structures in which a single organization serves as a middleman between requesting researchers and participating institutions. The downside of centralization is that as the number of organizations grows, it becomes precarious. The TIES (Text Information Extraction System) Cancer Research Network was established by four cancer centers as a federated network that allows member organizations to share data and biospecimen.<cite class="ltx_cite ltx_citemacro_citep">(Jacobson etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2015</a>)</cite> mentions pathology data that has been de-identified and analyzed with the TIES natural language processing framework can be accessed by member sites, resulting in a pool of rich phenotype data linked to clinical biospecimens. The possible effect of federated quests around the network on translational science can be seen in studies involving rare diseases, uncommon phenotypes, and complex biological behaviors. The network meets many main criteria, including local data and credentialing power, the inclusion of rich phenotype data, and applicability to a wide range of study goals <cite class="ltx_cite ltx_citemacro_citep">(Jacobson etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib54" title="" class="ltx_ref">2015</a>)</cite>.</p>
</div>
<div id="S4.SS2.p10" class="ltx_para">
<p id="S4.SS2.p10.1" class="ltx_p"><span id="S4.SS2.p10.1.1" class="ltx_text ltx_font_bold">Multi-site fMRI analysis</span></p>
</div>
<div id="S4.SS2.p11" class="ltx_para">
<p id="S4.SS2.p11.1" class="ltx_p">Data has a â€œnon-rivalrousâ€ value, which means it can be used by several parties at the same time to produce new data items or services, according to economics literature, Data pooling would have a synergistic impact. Sharing vast volumes of medical data is critical for precision medicine, with functional MRI (fMRI) data relating to certain neurological conditions or disorders being an interesting example. Deep learning models have shown to be useful in a variety of functions, including neuroimage processing. However, to successfully train a high-quality deep learning algorithm, a large volume of patient data must be gathered. The time and cost of acquiring and annotating massive fMRI datasets, for example, make it impossible to obtain a large number at a single location. The authors of the paper<cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2020a</a>)</cite> use a privacy-preserving approach to solve the issue of multi-site fMRI classification. They suggest a federated learning approach to solve the problem, in which a decentralized iterative optimization algorithm is used and mutual local model weights are changed by a randomization mechanism. Overall, the findings show that using multi-site data without exchanging data can improve neuroimage analysis accuracy and help discover accurate disease-related biomarkers <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib72" title="" class="ltx_ref">2020a</a>)</cite>.</p>
</div>
<div id="S4.SS2.p12" class="ltx_para">
<p id="S4.SS2.p12.1" class="ltx_p"><span id="S4.SS2.p12.1.1" class="ltx_text ltx_font_bold">Patch-Based Surface Morphometry for Alzheimerâ€™s Disease</span></p>
</div>
<div id="S4.SS2.p13" class="ltx_para">
<p id="S4.SS2.p13.1" class="ltx_p">In hospitals and academic centers, unprecedented rates of brain magnetic resonance imaging (MRI) currently exist. Simultaneously, the rapid advancement of software and hardware has made it scientifically possible to extract useful knowledge about the underpinnings of brain diseases such as Alzheimerâ€™s disease from these combined databases (AD). Researchers have faced significant challenges in obtaining or sharing these details due to patient safety issues, data limitations, and legal complications. To address this issue, large-scale collaborative networks, such as the ENIGMA Consortium1, were established, which used secure meta-analyses to study data from hundreds of institutions around the world without sharing patientsâ€™ scans or protected information. Seeking major causal factors that may predict/relate to health conditions or cognitive function, such as finding anatomically irregular regions in the brains of Alzheimerâ€™s Disease (AD) patients, is more interesting in brain imaging studies. As a result, the authors suggest a novel federated feature selection scheme based on group lasso regression using patch-based surface morphometry features from T1-weighted brain MRI images of AD, mild cognitive impairment (MCI), and stable elderly test subjects. By deliberately choosing (and visualizing) core functions, their work generalizes and enriches federated learning science. The method can discover new important features to be used as imaging biomarkers of MCI and AD by expanding access to information from large imaging datasets <cite class="ltx_cite ltx_citemacro_citep">(Wu
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib119" title="" class="ltx_ref">2020b</a>)</cite>.</p>
</div>
<div id="S4.SS2.p14" class="ltx_para">
<p id="S4.SS2.p14.1" class="ltx_p"><span id="S4.SS2.p14.1.1" class="ltx_text ltx_font_bold">FADL: Federated-Autonomous Deep Learning for Distributed Electronic Health Record</span></p>
</div>
<div id="S4.SS2.p15" class="ltx_para">
<p id="S4.SS2.p15.1" class="ltx_p">Data from electronic health records (EHRs), patient-generated health data from mobile devices, and other health-related information are useful for optimizing health outcomes, especially in precision medicine. Healthcare records are kept in various locations and data silos, such as clinics, pharmacies, payors, and mobile computers. Traditionally, healthcare data are disseminated through several locations and consolidated in a network for review. However, due to stringent rules and the sensitivity of the results, healthcare data transfers are complicated. These impediments not only make data usage costly, but also slow down knowledge delivery in healthcare, where timely changes are often needed. Using ICU data from 58 independent hospitals, the authors<cite class="ltx_cite ltx_citemacro_citep">(Liu
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib73" title="" class="ltx_ref">2018</a>)</cite> demonstrate that machine learning models used to forecast patient mortality can be trained effectively without taking health data out of silos using a distributed machine learning approach. They suggest a new approach called Federated-Autonomous Deep Learning (FADL), which trains a portion of the algorithm using data from all data sources in a distributed manner and another portion using data from individual data sources <cite class="ltx_cite ltx_citemacro_citep">(Liu
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib73" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
<div id="S4.SS2.p16" class="ltx_para">
<p id="S4.SS2.p16.1" class="ltx_p"><span id="S4.SS2.p16.1.1" class="ltx_text ltx_font_bold">Clinical trial protocol optimization</span></p>
</div>
<div id="S4.SS2.p17" class="ltx_para">
<p id="S4.SS2.p17.1" class="ltx_p">Clinical science is a time-consuming, labor-intensive, and expensive undertaking. Specific challenges associated with these bottlenecks include problems assessing patient demographics, determining eligible patients for enrollment, optimizing procedures, manual and inefficient data collection, data source reliability, and the difficulty of recognizing and monitoring infrequent adverse incidents. Furthermore, there are workflow problems and bottlenecks that hinder clinical trial behavior, such as suboptimal research design, slow and lengthy patient registration, site selection, and procedure optimization, all of which contribute to time and cost requirements. Some of these problems, such as protocol optimization and patient selection, can be mitigated by prudent re-use of data found in Electronic Health Records (EHRs). The growing use of EHRs in Europe and elsewhere provides a large, rich, and highly important pool of health data that has the potential to enhance clinical trial delivery. This data may be used to assess clinical trial viability using computable representations of the parameters, improve patient identification, clinical trial execution, and adverse effect monitoring. The authors in <cite class="ltx_cite ltx_citemacro_citep">(Claerhout
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2019</a>)</cite> investigated the concerns by examining the Inclusion and Exclusion (I/E) criteria of 23 completed trials in a variety of therapeutic areas that were sponsored by seven pharmaceutical companies to determine the proportion of I/E criteria that could be represented in a computable format and the right to query hospital EHRs to determine the number of currently qualifying patients correctly <cite class="ltx_cite ltx_citemacro_citep">(Claerhout
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib26" title="" class="ltx_ref">2019</a>)</cite>.</p>
</div>
<div id="S4.SS2.p18" class="ltx_para">
<p id="S4.SS2.p18.1" class="ltx_p"><span id="S4.SS2.p18.1.1" class="ltx_text ltx_font_bold">Heart Disease predictions from Electronic Health Records</span></p>
</div>
<div id="S4.SS2.p19" class="ltx_para">
<p id="S4.SS2.p19.1" class="ltx_p">In the age of â€big data,â€ computationally efficient and privacy-aware solutions for large-scale machine learning problems are critical, especially in the healthcare context, where large volumes of data are processed in several locations and owned by various institutions. The authors here discuss three issues concerning healthcare data: (1) data exist in several places (e.g., clinics, physiciansâ€™ offices, home-based computers, patientsâ€™ smartphones); (2) data access is increasing, necessitating the use of scalable frameworks; and (3) aggregating data in a centralized database is infeasible or impractical due to size and/or data protection issues. Based on their medical histories as outlined in their Electronic Health Records, the authors create a distributed (federated) approach to forecast hospitalizations for patients with heart diseases within a target year (EHRs). They devise a federated optimization scheme (cPDS) to address the sparse Support Vector Machine problem. they apply their latest approach to a dataset of de-identified Electronic Cardiac Records from the Boston Medical Center, which includes patients with heart disorders <cite class="ltx_cite ltx_citemacro_citep">(Brisimi etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib14" title="" class="ltx_ref">2018</a>)</cite>.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span><span id="S4.SS3.1.1" class="ltx_text ltx_font_bold">Clinical Workflow</span>
</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Clinical workflow is often conducted to optimize consistency in the workflow, analyze current frameworks, research a process and its implementation, and so on. The health care applications mentioned below conduct or include a clinical workflow on a specific disease, analysis on drug sensitivity, an EHR linking platform, and cloud-based output of federated learning on EHRâ€™s obtained from two healthcare systems to predict the risks of diseases linked to tobacco and radon.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p"><span id="S4.SS3.p2.1.1" class="ltx_text ltx_font_bold">FedMed: A Federated Learning Framework for Language Modelling</span></p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p">Society is entering a smart age, with the latest breakthroughs of the modern technological revolutionâ€”Industry 4.0 and Internet of Things (IoT) technologiesâ€”where all items are enclosed with a network of interconnectivity and automation through intelligent digital technique. Meanwhile, edging systems are flooded with heterogeneous data, ranging from real-time sensor activity logs to consumer data. During the migration process, however, data is quickly attacked and poisoned. This increases the difficulty of machine learning. The emergence of federated learning techniques, as well as the obstacles and risks it poses, has occurred in recent years. Traditional FL strategies depend on averaging aggregation or donâ€™t take into account connectivity costs. The authors suggest a novel Federated Mediation (FedMed) paradigm with adaptive aggregation, mediation reward system, and topK strategy to solve concept aggregation and coordination costs in federated language modeling. Perplexity and contact rounds are used to test the results. Three datasets are used in the experiments (i.e., Penn Treebank, WikiText-2, and Yelp) <cite class="ltx_cite ltx_citemacro_citep">(Wu
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib119" title="" class="ltx_ref">2020b</a>)</cite></p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p"><span id="S4.SS3.p4.1.1" class="ltx_text ltx_font_bold">Federated learning on clinical benchmark data</span></p>
</div>
<div id="S4.SS3.p5" class="ltx_para">
<p id="S4.SS3.p5.1" class="ltx_p">FL may be used to address privacy concerns and reduce the possibility of a data violation in clinical records so data transfer and centralization are not necessary. Since medical data is among the most vulnerable forms of personal data, privacy protection is especially important for medical data processing. De-identification techniques have traditionally been used to protect patientsâ€™ privacy. A performance evaluation using federated learning on clinical benchmark data was performed. The Modified National Institute of Standards and Technology (MNIST) dataset, Medical Information Mart for Intensive Care-III (MIMIC-III) dataset, and PhysioNet Electrocardiogram (ECG) dataset were used in a federated learning analysis. By changing the MNIST, MIMIC-III, and ECG datasets, they also validated FL in environments that simulate real-world data distributions <cite class="ltx_cite ltx_citemacro_citep">(Lee and Shin, <a href="#bib.bib66" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S4.SS3.p6" class="ltx_para">
<p id="S4.SS3.p6.1" class="ltx_p"><span id="S4.SS3.p6.1.1" class="ltx_text ltx_font_bold">Identifying potential risk variants in ankylosing spondylitis</span></p>
</div>
<div id="S4.SS3.p7" class="ltx_para">
<p id="S4.SS3.p7.1" class="ltx_p">Genome-wide association studies (GWAS) have been common for detecting possible risk variants in a variety of diseases. Large sample size is usually needed for a statistically significant GWAS to identify disease-associated single nucleotide polymorphisms (SNPs). A single institution, on the other hand, normally only has a small number of samples. As a result, cross-institutional collaboration is expected to maximize sample size and statistical capacity. However, cross-institutional collaborations present serious problems, one of which is data protection. While data sharing within a broad network can greatly support biomedical science, it also poses potential threats to data privacy due to the exchanging of personal information about individuals. The consequences of patient private information leaks include, but are not limited to, workplace discrimination, denial of benefits, higher insurance premiums, and so on. To address the problems of data privacy due to the exchange of personal information, the authors suggest a novel privacy-preserving federated GWAS architecture (iPRIVATES). iPRIVATES, which includes privacy-preserving federated processing, allows various organizations to collaborate on GWAS analysis without disclosing patient-level genotyping results <cite class="ltx_cite ltx_citemacro_citep">(Wu etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib120" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S4.SS3.p8" class="ltx_para">
<p id="S4.SS3.p8.1" class="ltx_p"><span id="S4.SS3.p8.1.1" class="ltx_text ltx_font_bold">Drug sensitivity prediction</span></p>
</div>
<div id="S4.SS3.p9" class="ltx_para">
<p id="S4.SS3.p9.1" class="ltx_p">Users with a personalized recommendation framework face a conundrum: learning from data will boost recommendations, but only when other users can share their private anonymization. Good personalized forecasts are critical in precision medicine, but the genetic knowledge from which the predictions are based is often especially vulnerable since it clearly describes the patients and therefore cannot be conveniently anonymized. Genomics is a critical domain for privacy-aware modeling, especially in precision medicine. Many people like to keep their and their descendantsâ€™ genomes secret, but basic anonymization is insufficient since a genome is inherently recognizable. As a result, the hospital or clinic that holds the genomic data must be very vigilant about privacy concerns when disclosing the genomic data, even though the data is required and helpful for potential diagnosis and care decisions. Even with moderate-sized data, the proposed differentially private regression approach <cite class="ltx_cite ltx_citemacro_citep">(Honkela
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2017</a>)</cite> combines the theoretical appeal and asymptotic efficiency with good prediction accuracy. Under comparatively strict differential privacy assurances, their approach exceeds the predictive precision of state-of-the-art non-private lasso regression with just 4x more tests <cite class="ltx_cite ltx_citemacro_citep">(Honkela
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib49" title="" class="ltx_ref">2017</a>)</cite>.</p>
</div>
<div id="S4.SS3.p10" class="ltx_para">
<p id="S4.SS3.p10.1" class="ltx_p"><span id="S4.SS3.p10.1.1" class="ltx_text ltx_font_bold">Integration of Medical Data</span></p>
</div>
<div id="S4.SS3.p11" class="ltx_para">
<p id="S4.SS3.p11.1" class="ltx_p">Medical evidence is often maintained by many organizations. However, comprehensive evaluations can necessitate the integration of these datasets without jeopardizing patient or commercial privacy. An effective privacy-preserving algorithm, Multiparty Private Set Intersection (MPSI), computes the intersection of several private datasets. Multiparty Private Set Intersection (MPSI), computes the intersection of several private datasets using this, the authors suggest a functional MPSI with the following characteristics: the size of each partyâ€™s datasets is independent of that of the other parties, and the statistical complexity for each party is independent of the number of parties <cite class="ltx_cite ltx_citemacro_citep">(Miyaji
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib80" title="" class="ltx_ref">2016</a>)</cite>.</p>
</div>
<div id="S4.SS3.p12" class="ltx_para">
<p id="S4.SS3.p12.1" class="ltx_p"><span id="S4.SS3.p12.1.1" class="ltx_text ltx_font_bold">Design and implementation of EHRs</span></p>
</div>
<div id="S4.SS3.p13" class="ltx_para">
<p id="S4.SS3.p13.1" class="ltx_p">Electronic clinical evidence has increased dramatically as a result of healthcare laws and government incentives encouraging the use of Electronic Health Records (EHRs). As a result, academics and public health authorities have shown a growing interest in data linkage that can be used in cross-site health studies. Linking EHR data through healthcare agencies, on the other hand, necessitates striking a balance between data accessibility and privacy. Some regions have adopted health information exchange (HIE) programs to provide healthcare facilities with up-to-date clinical data on patients through hospitals for better and more organized treatment, as part of inter-institutional arrangements for the sharing of PHI. However, owing to concerns about reliability, anonymity, and protection, as well as other problems, organizational HIEs exchanging patient-level identifiers, are still not commonly used. The authors define a real-world implementation of a software framework (Distributed Common Identity for the Integration of Regional Health Data â€“ DCIFIRHD) that uses a structured and distributed encryption algorithm to conduct stable, cross-site aggregation and linking of EHR data for analysis. As part of the HealthLNK study initiative, they applied the application in a major metropolitan area (Chicago, IL, USA), aggregating over 5 million patientsâ€™ clinical records through six healthcare institutions <cite class="ltx_cite ltx_citemacro_citep">(Kho etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib63" title="" class="ltx_ref">2015</a>)</cite>.</p>
</div>
<div id="S4.SS3.p14" class="ltx_para">
<p id="S4.SS3.p14.1" class="ltx_p"><span id="S4.SS3.p14.1.1" class="ltx_text ltx_font_bold">Cloud-based FL</span></p>
</div>
<div id="S4.SS3.p15" class="ltx_para">
<p id="S4.SS3.p15.1" class="ltx_p">From diagnosis to medication decisions, machine learning (ML) models can improve health care. However, ML model generalizability is jeopardized due to a lack of adequate heterogeneous data due to patient privacy concerns. When compared to a simulation in a single organization, heterogeneous data from multiple centers increased model accuracy. Furthermore, cloud systems come equipped with the required tools and security measures to support federated learning deployments. The amount and quality of data used to train an ML algorithm are extremely important, particularly for more complex models. The availability of diverse multidimensional patient data sets in the age of precision medicine necessitates greater population surveys for generalization. Furthermore, data shortage of underrepresented communities may contribute to prejudices if training data does not adequately portray these populationsâ€™ characteristics. Quality of healthcare data and algorithmic problems are also well-known ML roadblocks. To assess the federated machine learning solution, the authors use electronic health record data from two academic medical centers on a Microsoft Azure Cloud Databricks network to test various federated learning applications in both a virtual and real-world setting. Using data from two healthcare systemsâ€™ electronic health records (EHRs), they trained machine learning models to forecast the risks of diseases linked to tobacco and radon <cite class="ltx_cite ltx_citemacro_citep">(Rajendran
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib95" title="" class="ltx_ref">2021</a>)</cite>.</p>
</div>
<div id="S4.SS3.p16" class="ltx_para">
<p id="S4.SS3.p16.1" class="ltx_p"><span id="S4.SS3.p16.1.1" class="ltx_text ltx_font_bold">Clinical decision support system</span></p>
</div>
<div id="S4.SS3.p17" class="ltx_para">
<p id="S4.SS3.p17.1" class="ltx_p">Clinical decision support systems (CDSS) are computer-based applications designed to improve patient care and healthcare delivery by assisting clinicians in analyzing health information better and enhancing medical decisions. <cite class="ltx_cite ltx_citemacro_citep">(Sutton etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib108" title="" class="ltx_ref">2020</a>; Kawamoto etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib62" title="" class="ltx_ref">2005</a>)</cite> A CDSS uses knowledge management to get clinical insights from the patient and health-related data based on multiple factors. Clinical decision support systems assist the clinicians at the time of care and help to make a better care plan <cite class="ltx_cite ltx_citemacro_citep">(Bright
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib13" title="" class="ltx_ref">2012</a>; Al-Hyari
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib4" title="" class="ltx_ref">2013</a>)</cite>.</p>
</div>
<div id="S4.SS3.p18" class="ltx_para">
<p id="S4.SS3.p18.1" class="ltx_p">CDSS comprises three main components, including Base, inference engine, and Communication Mechanism. The base can be classified into two types of systems called knowledge-based and non-knowledge-based.</p>
</div>
<div id="S4.SS3.p19" class="ltx_para">
<p id="S4.SS3.p19.1" class="ltx_p">Knowledge-based support systems are defined by well-established rules(IF-THEN statements) that determine â€™what is true?â€™.
Support systems without a knowledge base, on the other hand, answer the question â€what to do?â€ advising on the next steps for treatments, which drug to prescribe, etc. These systems still require a data source and use artificial intelligence (AI), statistical pattern recognition, or machine learning (ML) to make medical decisions and provide recommendations <cite class="ltx_cite ltx_citemacro_citep">(Gultepe etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib42" title="" class="ltx_ref">2014</a>; Valdes etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib113" title="" class="ltx_ref">2017</a>; Baig
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib7" title="" class="ltx_ref">2016</a>)</cite>.</p>
</div>
<div id="S4.SS3.p20" class="ltx_para">
<p id="S4.SS3.p20.1" class="ltx_p">A large amount of data is often required to train an AI system, but clinical dataâ€™s varied and sensitive aspects present a barrier to the standard centralized network. The author of the paper <cite class="ltx_cite ltx_citemacro_citep">(Thwal
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib111" title="" class="ltx_ref">2021</a>)</cite> proposed a deep learning-based clinical decision support system trained and managed under a federated learning paradigm to solve the data and privacy challenges. The paper utilized a novel strategy to ensure the safety of patient privacy and overcome the risk of cyberattacks while enabling large-scale clinical data mining.</p>
</div>
<div id="S4.SS3.p21" class="ltx_para">
<span id="S4.SS3.p21.1" class="ltx_ERROR undefined">{longtblr}</span>
<p id="S4.SS3.p21.2" class="ltx_p">[
caption = Summary of existing studies on Deployment of ML and FL in Healthcare since 2016,
label = Tab:dcnnarchitectures1,
]

rowhead=1,
hline1,2,Z = 1pt, hline3-Y,
colsep = 3pt,
colspec = @ X[j,h] Q[c,m] Q[c,m] Q[c,m] Q[c,m] Q[c,m] Q[c,m] @,
rows = font=,
row1 = font=,

Title &amp; Ref  ML Model  Data Type  Year  #Hospitals/clients  #Samples 
<br class="ltx_break"></p>
</div>
<div id="S4.SS3.p22" class="ltx_para">
<p id="S4.SS3.p22.1" class="ltx_p">Distributed learning: Developing a predictive model based on data from multiple hospitals without data leaving the hospital â€“ A real life proof of concept
 <cite class="ltx_cite ltx_citemacro_citep">(Jochems etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib57" title="" class="ltx_ref">2016</a>)</cite>
 Bayesian network
 EHR
 2016
 5
 287 
<br class="ltx_break"></p>
</div>
<div id="S4.SS3.p23" class="ltx_para">
<p id="S4.SS3.p23.1" class="ltx_p">Developing and Validating a Survival Prediction Model for NSCLC Patients Through Distributed Learning Across 3 Countries
 <cite class="ltx_cite ltx_citemacro_citep">(Jochems etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib56" title="" class="ltx_ref">2017</a>)</cite>
 SVM
 EHR
 2017
 3
 894 
<br class="ltx_break"></p>
</div>
<div id="S4.SS3.p24" class="ltx_para">
<p id="S4.SS3.p24.1" class="ltx_p">Patient clustering improves efficiency of federated machine learning to predict mortality and hospital stay time using distributed electronic medical records
 <cite class="ltx_cite ltx_citemacro_citep">(Huang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib51" title="" class="ltx_ref">2019</a>)</cite>
 k-means
 EHR
 2019
 208
 200,859 
<br class="ltx_break"></p>
</div>
<div id="S4.SS3.p25" class="ltx_para">
<p id="S4.SS3.p25.1" class="ltx_p">Distributed learning on 20 000+ lung cancer patients â€“ The Personal Health Train
 <cite class="ltx_cite ltx_citemacro_citep">(Deist etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib32" title="" class="ltx_ref">2020</a>)</cite>
 Logistic regression
 EHR
 2020
 8
 23,203 
<br class="ltx_break"></p>
</div>
<div id="S4.SS3.p26" class="ltx_para">
<p id="S4.SS3.p26.1" class="ltx_p">Federated Learning of Electronic Health Records Improves Mortality Prediction in Patients Hospitalized with COVID-19
 <cite class="ltx_cite ltx_citemacro_citep">(Vaid
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib112" title="" class="ltx_ref">2021</a>)</cite>
 Federated MLP,LASSO
 EHR  2020
 5
 4029 
<br class="ltx_break"></p>
</div>
<div id="S4.SS3.p27" class="ltx_para">
<p id="S4.SS3.p27.1" class="ltx_p">Joint Imaging Platform for Federated Clinical Data Analytics
 <cite class="ltx_cite ltx_citemacro_citep">(Scherer etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib101" title="" class="ltx_ref">2020</a>)</cite>
 CNN based organ segmentation
 Images
 2020
 10
 - 
<br class="ltx_break"></p>
</div>
<div id="S4.SS3.p28" class="ltx_para">
<p id="S4.SS3.p28.1" class="ltx_p">Stochastic Channel-Based Federated Learning With Neural Network Pruning for Medical Data Privacy Preservation: Model Development and Experimental Validation
 <cite class="ltx_cite ltx_citemacro_citep">(Shao
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib102" title="" class="ltx_ref">2020</a>)</cite>
 MLP
 EHR
 2020
 5
 30,760 
<br class="ltx_break"></p>
</div>
<div id="S4.SS3.p29" class="ltx_para">
<p id="S4.SS3.p29.1" class="ltx_p">Federated learning in medicine: facilitating multi-institutional collaborations without sharing patient data
 <cite class="ltx_cite ltx_citemacro_citep">(Sheller
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib103" title="" class="ltx_ref">2020</a>)</cite>
 U-Net
 Images
 2020
 13
 352 
<br class="ltx_break"></p>
</div>
<div id="S4.SS3.p30" class="ltx_para">
<p id="S4.SS3.p30.1" class="ltx_p">Federated semi-supervised learning for COVID region segmentation in chest CT using multi-national data from China, Italy, Japan
 <cite class="ltx_cite ltx_citemacro_citep">(Yang etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib127" title="" class="ltx_ref">2021</a>)</cite>
 Fully Convolutional Network (FCN)
 Images
 2021
 3
 1704 
<br class="ltx_break"></p>
</div>
<div id="S4.SS3.p31" class="ltx_para">
<p id="S4.SS3.p31.1" class="ltx_p">Real-Time Electronic Health Record Mortality Prediction During the COVID-19 Pandemic: A Prospective Cohort Study
 <cite class="ltx_cite ltx_citemacro_citep">(Sottile etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib107" title="" class="ltx_ref">2021</a>)</cite>
 Stacked regression model
 EHR
 2021
 12
 28,538 
<br class="ltx_break"></p>
</div>
<div id="S4.SS3.p32" class="ltx_para">
<p id="S4.SS3.p32.1" class="ltx_p">Federated Learning used for predicting outcomes in SARS-COV-2 patients
 <cite class="ltx_cite ltx_citemacro_citep">(Flores etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib39" title="" class="ltx_ref">2021b</a>)</cite>
 ResNet-34
 Images
 2021
 20
 16,148 
<br class="ltx_break"></p>
</div>
<div id="S4.SS3.p33" class="ltx_para">
<p id="S4.SS3.p33.1" class="ltx_p">Cloud-Based Federated Learning Implementation Across Medical Centers
 <cite class="ltx_cite ltx_citemacro_citep">(Rajendran
etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib95" title="" class="ltx_ref">2021</a>)</cite>
 ANN / Logistic regression
 EHR
 2021
 2
 10,000 
<br class="ltx_break"></p>
</div>
<div id="S4.SS3.p34" class="ltx_para">
<p id="S4.SS3.p34.1" class="ltx_p">Federated learning improves site performance in multicenter deep learning without data sharing
 <cite class="ltx_cite ltx_citemacro_citep">(Sarma etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib100" title="" class="ltx_ref">2021</a>)</cite>
 3D Anisotropic Hybrid Network
 Images
 2021
 3
 300 
<br class="ltx_break"></p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span><span id="S5.1.1" class="ltx_text ltx_font_bold">Tools</span>
</h2>

<figure id="S5.F9" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2211.07893/assets/x9.png" id="S5.F9.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_square" width="242" height="241" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9. </span>Tools of federated learning</figcaption><div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S5.F9.1" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\Description</span></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<p id="S5.F9.2" class="ltx_p ltx_figure_panel ltx_align_center">A woman and a girl in white dresses sit in an open car.</p>
</div>
</div>
</figure>
<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1. </span><span id="S5.SS1.1.1" class="ltx_text ltx_font_bold">TensorFlow Federated</span>
</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">TFF <cite class="ltx_cite ltx_citemacro_citep">(TFL, <a href="#bib.bib110" title="" class="ltx_ref">2019</a>)</cite> is an open-source framework to perform machine learning and computations on localized information. TFF allows developers to simulate federated learning algorithms on the models and data. TFFâ€™s interfaces are unionized in 2 layers. Federate Core(FC) and Federate Learning (FL) APIs.Federated Core API is the foundation layer upon which is built the Federated Learning API. This is a strong functional programming environment that involves a combination of novel federated learning algorithms and TensorFlow with distributing higher-revelations operators at the core of the system. Whereas Federated learning API is at a higher-level interface. This API allows developers to use the existing FL algorithms (training and evaluation) in their models.
Developers can incorporate their functions and interfaces within the federated heart. FC, as a Python package, includes Python interfaces that can be used to create new Python features. It supports several styles, including Tensor types, sequence types, tuple types, and function types, to make it simple to use, particularly for developers familiar with TensorFlow. It supports a wide range of federated operators, including federated sum, federated minimize, and federated broadcast.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">TFF currently only supports FedAvg and does not provide any privacy mechanisms. It can now only be deployed on a single computer, with the federated setting applied by simulation.</p>
</div>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2. </span><span id="S5.SS2.1.1" class="ltx_text ltx_font_bold">Federated AI Technology Enabler (FATE) </span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">Webankâ€™s AI Department initiated an open-source project called FATE <cite class="ltx_cite ltx_citemacro_citep">(Fate, <a href="#bib.bib36" title="" class="ltx_ref">2019</a>)</cite>. This framework provides a secure computing framework supporting the AI Ecosystem. It uses privacy-preserving techniques like Homomorphic encryption and Secured Multi-Party Computation. It also supports ML algorithms like Logistic regression, Deep learning, tree-based algorithms, and transfer learning. EggRoll, FederatedML, FATE-Flow, FATE-Serving, FATE-Board, and KubeFATE are its six main modules.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.1" class="ltx_p">The federated algorithms and stable protocols are used in FederatedML. It currently supports training a variety of machine learning models, including NNs, GBDTs, and logistic regression, in both horizontal and vertical federated settings. To ensure anonymity, it also incorporates safe multi-party computing and homomorphic encryption. To run an FL algorithm, users simply set the parameters. FATE also includes comprehensive documentation of how to deploy and use it.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p">Practitioners must change FATEâ€™s source code to incorporate their federated algorithms because FATE has algorithm-level interfaces. Non-expert consumers would find this difficult.</p>
</div>
</section>
<section id="S5.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3. </span><span id="S5.SS3.1.1" class="ltx_text ltx_font_bold">PySyft</span>
</h3>

<div id="S5.SS3.p1" class="ltx_para">
<p id="S5.SS3.p1.1" class="ltx_p">PySyft <cite class="ltx_cite ltx_citemacro_citep">(Ryffel etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib98" title="" class="ltx_ref">2018</a>)</cite> is a secure and private deep learning library. It is a library for answering questions using data you cannot see. It uses privacy-preserving techniques like Differential Privacy, Homomorphic Encryption, and multi-party computation with deep learning frameworks like Pytorch, and Tensorflow.</p>
</div>
<div id="S5.SS3.p2" class="ltx_para">
<p id="S5.SS3.p2.1" class="ltx_p">Both PyTorch and TensorFlow can be used with PySyft. It can be installed on a single computer or several computers, with the WebSocket API used to communicate between clients.</p>
</div>
<div id="S5.SS3.p3" class="ltx_para">
<p id="S5.SS3.p3.1" class="ltx_p">Though PySyft offers several tutorials, there is no comprehensive documentation on the systemâ€™s interfaces or architecture. PySyft does not support a diversified computing paradigm like on-device training on Mobile or IoT.</p>
</div>
</section>
<section id="S5.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4. </span><span id="S5.SS4.1.1" class="ltx_text ltx_font_bold">Leaf</span>
</h3>

<div id="S5.SS4.p1" class="ltx_para">
<p id="S5.SS4.p1.1" class="ltx_p">LEAF <cite class="ltx_cite ltx_citemacro_citep">(Leaf, <a href="#bib.bib65" title="" class="ltx_ref">2019</a>)</cite> is a benchmarking framework for studying in federated settings, with programs consisting of federated learning, multi-task mastering, meta-learning, and on-tool learning.</p>
</div>
<div id="S5.SS4.p2" class="ltx_para">
<p id="S5.SS4.p2.1" class="ltx_p">It includes six databases that cover a variety of topics, such as image recognition, emotion analysis, and next-character prediction. A collection of utilities is given to split datasets into separate parties in an IID or non-IID manner. A reference implementation is also presented for each dataset to explain how to use the dataset in a training phase.</p>
</div>
<div id="S5.SS4.p3" class="ltx_para">
<p id="S5.SS4.p3.1" class="ltx_p">Leaf databases have enough clients to model cross-device FL scenarios, but they may be too limited for questions where size is especially relevant. It only supports standardized algorithm implementations such as Fed Avg and does not support decentralized federated learning, split learning, and vertical federated learning.</p>
</div>
</section>
<section id="S5.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.5. </span><span id="S5.SS5.1.1" class="ltx_text ltx_font_bold">Paddle FL</span>
</h3>

<div id="S5.SS5.p1" class="ltx_para">
<p id="S5.SS5.p1.1" class="ltx_p">Paddle FL <cite class="ltx_cite ltx_citemacro_citep">(PaddleFL, <a href="#bib.bib84" title="" class="ltx_ref">2019</a>)</cite> provides applications in Natural Language Processing, Computer Vision, and recommendation systems. Paddle FL allowing the deployment of federated learning systems in the form of distributed clusters at a large scale has been proven to be of great benefit to developers. PaddleFL is an open-source framework based on PaddlePaddle.</p>
</div>
<div id="S5.SS5.p2" class="ltx_para">
<p id="S5.SS5.p2.1" class="ltx_p">FL methods, user-specified models and algorithms, distributed training setup, and FL task generator are all included in the compile time. The horizontal FL algorithms, such as FedAvg, are among the FL techniques. Users are allowed to create their models and training algorithms in addition to the FL techniques offered.</p>
</div>
<div id="S5.SS5.p3" class="ltx_para">
<p id="S5.SS5.p3.1" class="ltx_p">PaddleFL is still in its early stages of production, and the documentation and samples are lacking. It also lacks in performance with standardized benchmarks such as Model DNN (eg: ResNet) and vertical federated learning. Paddle FL does not involve a flexible and generic API design with topology customization and flexible message flow.</p>
</div>
</section>
<section id="S5.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.6. </span><span id="S5.SS6.1.1" class="ltx_text ltx_font_bold">Clara Training Framework</span>
</h3>

<div id="S5.SS6.p1" class="ltx_para">
<p id="S5.SS6.p1.1" class="ltx_p">Clara Train SDK <cite class="ltx_cite ltx_citemacro_citep">(Clara, <a href="#bib.bib27" title="" class="ltx_ref">2019</a>)</cite> is a domain-optimized developer software framework that consists of APIs for AI-Assisted Annotation. This allows any clinical viewer to be AI successful and allows a TensorFlow-based framework with pre-skilled models to begin AI improvement with strategies including Transfer Learning, Federated Learning, and AutoML.</p>
</div>
<div id="S5.SS6.p2" class="ltx_para">
<p id="S5.SS6.p2.1" class="ltx_p">Developers may use the Clara Train SDKâ€™s configurable MMAR (Medical Model ARchive) function to carry their models and components to conduct Federated Learning, as well as monitor whether the local training is run on a single GPU or multiple GPUs.</p>
</div>
</section>
<section id="S5.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.7. </span><span id="S5.SS7.1.1" class="ltx_text ltx_font_bold">Fed ML</span>
</h3>

<div id="S5.SS7.p1" class="ltx_para">
<p id="S5.SS7.p1.1" class="ltx_p">FedML <cite class="ltx_cite ltx_citemacro_citep">(He etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2020c</a>)</cite> serves as a tool for federated learning as well as a forum for FL benchmarking. Its core structure is split into two layers as an FL system. On-device training for IoT and mobile computers, distributed computing, and single-machine emulation are all supported. FedML also embraces a variety of algorithms, prototypes, and databases for study variability (e.g., decentralized learning, vertical FL, and split learning).</p>
</div>
<div id="S5.SS7.p2" class="ltx_para">
<p id="S5.SS7.p2.1" class="ltx_p">FedML offers a simulation environment for a wide range of hardware specifications while supporting three computing paradigms <cite class="ltx_cite ltx_citemacro_citep">(He etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib47" title="" class="ltx_ref">2020c</a>)</cite>: standalone simulation, distributed computing, and on-device training.</p>
</div>
</section>
<section id="S5.SS8" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.8. </span><span id="S5.SS8.1.1" class="ltx_text ltx_font_bold">IBM Federated Learning</span>
</h3>

<div id="S5.SS8.p1" class="ltx_para">
<p id="S5.SS8.p1.1" class="ltx_p">A python framework library for distributed machine learning processes in an enterprise environment <cite class="ltx_cite ltx_citemacro_citep">(IBMFL, <a href="#bib.bib53" title="" class="ltx_ref">2020</a>)</cite>.IBM Federated Learning focuses on enterprise environments where safe rollout, failure tolerance, and fast model specification are critical; these must make use of existing machine learning libraries that enable enterprise users to access a robust collection of state-of-the-art algorithms without learning new languages. Enterprise professionals will be able to easily implement federated learning using IBM Federated Learning.</p>
</div>
<div id="S5.SS8.p2" class="ltx_para">
<p id="S5.SS8.p2.1" class="ltx_p">Apart from neural networks and decision trees, IBM Federated Learning facilitates the learning of a variety of machine learning models such as multi-class classification,regression,linear classifiers and adaptation of XGBoost. IBM Federated Learning also gives you the ability to apply differential privacy to a variety of models, from basic Naive Bayes to more sophisticated differential privacy structures like those used in neural networks.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6. </span><span id="S6.1.1" class="ltx_text ltx_font_bold">CONCLUSION &amp; FUTURE DIRECTIONS</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">Federated learning is a learning paradigm where machine learning models are trained at the edge. It was originally designed for a variety of domains, including mobile and edge device use cases, but it has recently acquired popularity in healthcare applications.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">The development of federated learning systems for healthcare has sparked a lot of interest from both industry and academics. As a result, a comprehensive overview and summary of existing FLSs in the healthcare domain is required.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">Not all technological concerns have been solved, and FL will undoubtedly be a focus of study in the coming decade.
Even though 5G networks are not yet widely available and commercially implemented worldwide, significant research and development efforts have been directed toward future 6G wireless systems.<cite class="ltx_cite ltx_citemacro_citep">(deÂ Alwis etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib30" title="" class="ltx_ref">2021</a>)</cite></p>
</div>
<div id="S6.p4" class="ltx_para">
<p id="S6.p4.1" class="ltx_p">Future research will focus on incorporating FL functionalities into future 5G/6G medical devices, how to use 6G devices, such as intelligent implants and wearables, for large-scale FL-based healthcare, and what new healthcare services 6G enables.
Future e-health services, for example, will be enhanced by AI and FL capabilities, improving patient quality of life and lowering hospitalizations <cite class="ltx_cite ltx_citemacro_citep">(Mucchi etÂ al<span class="ltx_text">.</span>, <a href="#bib.bib82" title="" class="ltx_ref">2020</a>)</cite>.</p>
</div>
<div id="S6.p5" class="ltx_para">
<p id="S6.p5.1" class="ltx_p">In this article, we presented an overview of federated learning in the healthcare industry. We conducted a comprehensive survey of recent work in the healthcare sector, with a focus on federated settings. We also discussed how to employ federated learning in healthcare, as well as the methods, applications, and issues that come with it.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Adam
etÂ al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2007)</span>
<span class="ltx_bibblock">
Nabil Adam, Tom White,
Basit Shafiq, Jaideep Vaidya, and
Xiaoyun He. 2007.

</span>
<span class="ltx_bibblock">Privacy preserving integration of health care
data.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.3.1" class="ltx_emph ltx_font_italic">AMIA â€¦ Annual Symposium proceedings. AMIA
Symposium</em> (10 2007),
1â€”5.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://europepmc.org/articles/PMC2655922" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://europepmc.org/articles/PMC2655922</a>

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">AkgÃ¼n etÂ al<span id="bib.bib3.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Mete AkgÃ¼n, A.Â Osman
Bayrak, Bugra Ozer, and M. Åamil
SaÄŸÄ±roÄŸlu. 2015.

</span>
<span class="ltx_bibblock">Privacy preserving processing of genomic data: A
survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.3.1" class="ltx_emph ltx_font_italic">Journal of Biomedical Informatics</em>
56 (2015), 103â€“111.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/j.jbi.2015.05.022" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.jbi.2015.05.022</a>

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Al-Hyari
etÂ al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2013)</span>
<span class="ltx_bibblock">
AbeerÂ Y Al-Hyari, AhmadÂ M
Al-Taee, and MajidÂ A Al-Taee.
2013.

</span>
<span class="ltx_bibblock">Clinical decision support system for diagnosis and
management of chronic renal failure. In <em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">2013 IEEE
Jordan Conference on Applied Electrical Engineering and Computing
Technologies (AEECT)</em>. IEEE, 1â€“6.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Al-Rubaie and
Chang (2019)</span>
<span class="ltx_bibblock">
Mohammad Al-Rubaie and
J.Â Morris Chang. 2019.

</span>
<span class="ltx_bibblock">Privacy-Preserving Machine Learning: Threats and
Solutions.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">IEEE Security &amp; Privacy</em>
17 (3 2019).

</span>
<span class="ltx_bibblock">Issue 2.


<a target="_blank" href="https://doi.org/10.1109/MSEC.2018.2888775" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/MSEC.2018.2888775</a>

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alfeld
etÂ al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Scott Alfeld, Xiaojin
Zhu, and Paul Barford. 2016.

</span>
<span class="ltx_bibblock">Data Poisoning Attacks against Autoregressive
Models.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Thirtieth AAAI Conference
on Artificial Intelligence</em>, 1452â€“1458.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baig
etÂ al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
MirzaÂ Mansoor Baig,
HamidÂ Gholam Hosseini, and Maria
LindÃ©n. 2016.

</span>
<span class="ltx_bibblock">Machine learning-based clinical decision support
system for early diagnosis from real-time physiological data. In
<em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">2016 IEEE region 10 conference (TENCON)</em>. IEEE,
2943â€“2946.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Balachandar etÂ al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
N Balachandar, Ken Chang,
J Kalpathy-Cramer, and D Rubin.
2020.

</span>
<span class="ltx_bibblock">Accounting for data variability in
multi-institutional distributed deep learning for medical imaging.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.3.1" class="ltx_emph ltx_font_italic">Journal of the American Medical Informatics
Association : JAMIA</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Banerjee etÂ al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Sourasekhar Banerjee,
Rajiv Misra, Mukesh Prasad,
Erik Elmroth, and MonowarÂ H. Bhuyan.
2020.

</span>
<span class="ltx_bibblock">Multi-diseases Classification from Chest-X-ray: A
Federated Deep Learning Approach.

</span>
<span class="ltx_bibblock">(2020).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1007/978-3-030-64984-5_1" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/978-3-030-64984-5_1</a>

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Barroso etÂ al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
NuriaÂ RodrÃ­guez Barroso,
Goran Stipcich, Daniel
JimÃ©nez-LÃ³pez, JosÃ©Â Antonio
Ruiz-MillÃ¡n, Eugenio
MartÃ­nez-CÃ¡mara, Gerardo
GonzÃ¡lez-Seco, M.Â Victoria LuzÃ³n,
MiguelÂ Ãngel Veganzones, and
Francisco Herrera. 2020.

</span>
<span class="ltx_bibblock">Federated Learning and Differential Privacy:
Software tools analysis, the Sherpa.ai FL framework and methodological
guidelines for preserving data privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/2007.00914
(2020).

</span>
<span class="ltx_bibblock">arXiv:2007.00914

<a target="_blank" href="https://arxiv.org/abs/2007.00914" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2007.00914</a>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Beachy
etÂ al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Sarah Beachy, TheresaÂ M.
Wizemann, and Meredith Hackmann.
2019.

</span>
<span class="ltx_bibblock">Exploring Sources of Variability Related to the
Clinical Translation of Regenerative Engineering Products.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Biggio
etÂ al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2013)</span>
<span class="ltx_bibblock">
Battista Biggio, Blaine
Nelson, and Pavel Laskov.
2013.

</span>
<span class="ltx_bibblock">Poisoning Attacks against Support Vector Machines.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1206.6389Â [cs.LG]

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bright
etÂ al<span id="bib.bib13.3.3.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
TiffaniÂ J Bright, Anthony
Wong, Ravi Dhurjati, Erin Bristow,
Lori Bastian, RemyÂ R Coeytaux,
Gregory Samsa, Vic Hasselblad,
JohnÂ W Williams, MichaelÂ D Musty,
etÂ al<span id="bib.bib13.4.1" class="ltx_text">.</span> 2012.

</span>
<span class="ltx_bibblock">Effect of clinical decision-support systems: a
systematic review.

</span>
<span class="ltx_bibblock"><em id="bib.bib13.5.1" class="ltx_emph ltx_font_italic">Annals of internal medicine</em>
157, 1 (2012),
29â€“43.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brisimi etÂ al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
TheodoraÂ S Brisimi, R
Chen, T Mela, A Olshevsky,
I Paschalidis, and Wei Shi.
2018.

</span>
<span class="ltx_bibblock">Federated learning of predictive models from
federated Electronic Health Records.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">International journal of medical
informatics</em> 112 (2018),
59â€“67.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brophy
etÂ al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Eoin Brophy, M Vos,
Geraldine Boylan, and T Ward.
2021.

</span>
<span class="ltx_bibblock">Estimation of Continuous Blood Pressure from PPG
via a Federated Learning Approach.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.3.1" class="ltx_emph ltx_font_italic">ArXiv</em> abs/2102.12245
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Carlsson (2020)</span>
<span class="ltx_bibblock">
Robert Carlsson.
2020.

</span>
<span class="ltx_bibblock">Privacy-Preserved Federated Learning: A survey of
applicable machine learning algorithms in a federated environment.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cha
etÂ al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Dongchul Cha, MinDong
Sung, and Yu-Rang Park.
2021.

</span>
<span class="ltx_bibblock">Implementing Vertical Federated Learning Using
Autoencoders: Practical Application, Generalizability, and Utility Study.

</span>
<span class="ltx_bibblock"><em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">JMIR Medical Informatics</em>
9 (6 2021).

</span>
<span class="ltx_bibblock">Issue 6.


<a target="_blank" href="https://doi.org/10.2196/26598" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.2196/26598</a>

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chai
etÂ al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Di Chai, Leye Wang,
Kai Chen, and Qiang Yang.
2019.

</span>
<span class="ltx_bibblock">Secure Federated Matrix Factorization.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chai
etÂ al<span id="bib.bib19.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Di Chai, Leye Wang,
Kai Chen, and Qiang Yang.
2020.

</span>
<span class="ltx_bibblock">FedEval: A Benchmark System with a Comprehensive
Evaluation Model for Federated Learning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2011.09655Â [cs.LG]

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chaudhuri
etÂ al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2013)</span>
<span class="ltx_bibblock">
Kamalika Chaudhuri, A
Sarwate, and Kaushik Sinha.
2013.

</span>
<span class="ltx_bibblock">A near-optimal algorithm for differentially-private
principal components.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">ArXiv</em> abs/1207.2812
(2013).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen
etÂ al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yang Chen, Xiaoyan Sun,
and Yaochu Jin. 2020.

</span>
<span class="ltx_bibblock">Communication-Efficient Federated Deep Learning
With Layerwise Asynchronous Model Update and Temporally Weighted
Aggregation.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Neural Networks and
Learning Systems</em> 31 (10
2020).

</span>
<span class="ltx_bibblock">Issue 10.


<a target="_blank" href="https://doi.org/10.1109/TNNLS.2019.2953131" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TNNLS.2019.2953131</a>

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen
etÂ al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Yiqiang Chen, Jindong
Wang, Chaohui Yu, Wen Gao, and
Xin Qin. 2021.

</span>
<span class="ltx_bibblock">FedHealth: A Federated Transfer Learning Framework
for Wearable Healthcare.

</span>
<span class="ltx_bibblock">(2021).

</span>
<span class="ltx_bibblock">arXiv:1907.09173Â [cs.LG]

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng
etÂ al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Kewei Cheng, Tao Fan,
Yilun Jin, Yang Liu,
Tianjian Chen, and Qiang Yang.
2019.

</span>
<span class="ltx_bibblock">SecureBoost: A Lossless Federated Learning
Framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">ArXiv</em> abs/1901.08755
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chhikara etÂ al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Prateek Chhikara, Prabhjot
Singh, Rajkumar Tekchandani, Neeraj
Kumar, and Mohsen Guizani.
2021.

</span>
<span class="ltx_bibblock">Federated Learning Meets Human Emotions: A
Decentralized Framework for Humanâ€“Computer Interaction for IoT
Applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib24.3.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>
8 (4 2021).

</span>
<span class="ltx_bibblock">Issue 8.


<a target="_blank" href="https://doi.org/10.1109/JIOT.2020.3037207" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/JIOT.2020.3037207</a>

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Choudhury etÂ al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Olivia Choudhury,
Yoonyoung Park, Theodoros Salonidis,
A Gkoulalas-Divanis, I Sylla, and
AmarÂ K Das. 2019.

</span>
<span class="ltx_bibblock">Predicting Adverse Drug Reactions on Distributed
Health Data using Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.3.1" class="ltx_emph ltx_font_italic">AMIA â€¦ Annual Symposium proceedings. AMIA
Symposium</em> 2019 (2019),
313â€“322.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Claerhout
etÂ al<span id="bib.bib26.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
B Claerhout, D Kalra,
C Mueller, Gurparkash Singh,
N Ammour, L Meloni, J
Blomster, M Hopley, G Kafatos,
Almenia Garvey, Peter Kuhn,
Martine Lewi, B Vannieuwenhuyse,
BenoÃ®t Marchal, K Mayer-Patel,
Christoph Schindler, and M Sundgren.
2019.

</span>
<span class="ltx_bibblock">Federated electronic health records research
technology to support clinical trial protocol optimization: Evidence from
EHR4CR and the InSite platform.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.3.1" class="ltx_emph ltx_font_italic">Journal of biomedical informatics</em>
90 (2019), 103090.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Clara (2019)</span>
<span class="ltx_bibblock">
Clara. 2019.

</span>
<span class="ltx_bibblock">NVIDIA Clara.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">https://docs.nvidia.com/clara/</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Constable etÂ al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
ScottÂ D Constable, Y
Tang, Shuang Wang, Xiaoqian Jiang, and
S Chapin. 2015.

</span>
<span class="ltx_bibblock">Privacy-preserving GWAS analysis on federated
genomic datasets.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.3.1" class="ltx_emph ltx_font_italic">BMC Medical Informatics and Decision Making</em>
15 (2015), S2 â€“ S2.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui
etÂ al<span id="bib.bib29.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Jianfei Cui, He Zhu,
Hao Deng, Ziwei Chen, and
Dianbo Liu. 2021.

</span>
<span class="ltx_bibblock">FeARH: Federated machine learning with anonymous
random hybridization on electronic medical records.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.3.1" class="ltx_emph ltx_font_italic">Journal of Biomedical Informatics</em>
117 (5 2021).

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/j.jbi.2021.103735" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.jbi.2021.103735</a>

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">deÂ Alwis etÂ al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Chamitha de Alwis,
Anshuman Kalla, Quoc-Viet Pham,
Pardeep Kumar, Kapal Dev,
Won-Joo Hwang, and Madhusanka
Liyanage. 2021.

</span>
<span class="ltx_bibblock">Survey on 6G Frontiers: Trends, Applications,
Requirements, Technologies and Future Research.

</span>
<span class="ltx_bibblock"><em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">IEEE Open Journal of the Communications
Society</em> 2 (2021),
836â€“886.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dean
etÂ al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
Jeffrey Dean, Greg
Corrado, Rajat Monga, Kai Chen,
Matthieu Devin, Mark Mao,
Marc aurelio Ranzato, Andrew Senior,
Paul Tucker, Ke Yang,
Quoc Le, and Andrew Ng.
2012.

</span>
<span class="ltx_bibblock">Large Scale Distributed Deep Networks,
FÂ Pereira, CÂ JÂ C
Burges, LÂ Bottou, and KÂ Q Weinberger
(Eds.).

</span>
<span class="ltx_bibblock"><em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">Advances in Neural Information Processing
Systems</em> 25.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://proceedings.neurips.cc/paper/2012/file/6aca97005c68f1206823815f66102863-Paper.pdf" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.neurips.cc/paper/2012/file/6aca97005c68f1206823815f66102863-Paper.pdf</a>

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deist etÂ al<span id="bib.bib32.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
TimoÂ M. Deist,
FrankÂ J.W.M. Dankers, Priyanka Ojha,
M.Â Scott Marshall, Tomas Janssen,
Corinne Faivre-Finn, Carlotta Masciocchi,
Vincenzo Valentini, Jiazhou Wang,
Jiayan Chen, Zhen Zhang,
Emiliano Spezi, Mick Button,
JoostÂ Jan Nuyttens, RenÃ© Vernhout,
Johan van Soest, Arthur Jochems,
RenÃ© Monshouwer, Johan Bussink,
Gareth Price, Philippe Lambin, and
Andre Dekker. 2020.

</span>
<span class="ltx_bibblock">Distributed learning on 20 000+ lung cancer
patients â€“ The Personal Health Train.

</span>
<span class="ltx_bibblock"><em id="bib.bib32.3.1" class="ltx_emph ltx_font_italic">Radiotherapy and Oncology</em>
144 (3 2020).

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/j.radonc.2019.11.019" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.radonc.2019.11.019</a>

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dou etÂ al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Qi Dou, TiffanyÂ Y. So,
Meirui Jiang, Quande Liu,
Varut Vardhanabhuti, Georgios Kaissis,
Zeju Li, Weixin Si,
Heather H.Â C. Lee, Kevin Yu,
Zuxin Feng, Li Dong,
Egon Burian, Friederike Jungmann,
Rickmer Braren, Marcus Makowski,
Bernhard Kainz, Daniel Rueckert,
Ben Glocker, Simon C.Â H. Yu, and
PhengÂ Ann Heng. 2021.

</span>
<span class="ltx_bibblock">Federated deep learning for detecting COVID-19 lung
abnormalities in CT: a privacy-preserving multinational validation study.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.3.1" class="ltx_emph ltx_font_italic">npj Digital Medicine</em> 4
(12 2021).

</span>
<span class="ltx_bibblock">Issue 1.


<a target="_blank" href="https://doi.org/10.1038/s41746-021-00431-6" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1038/s41746-021-00431-6</a>

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork etÂ al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2006)</span>
<span class="ltx_bibblock">
Cynthia Dwork, Krishnaram
Kenthapadi, Frank McSherry, Ilya
Mironov, and Moni Naor.
2006.

</span>
<span class="ltx_bibblock">Our Data, Ourselves: Privacy Via Distributed Noise
Generation.

</span>
<span class="ltx_bibblock">(2006).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1007/11761679_29" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/11761679_29</a>

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dwork
etÂ al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2010)</span>
<span class="ltx_bibblock">
Cynthia Dwork, GuyÂ N.
Rothblum, and Salil Vadhan.
2010.

</span>
<span class="ltx_bibblock">Boosting and Differential Privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">2010 IEEE 51st Annual Symposium on
Foundations of Computer Science</em>.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/FOCS.2010.12" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/FOCS.2010.12</a>

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fate (2019)</span>
<span class="ltx_bibblock">
Fate. 2019.

</span>
<span class="ltx_bibblock">Federated AI Technology Enabler (FATE).

</span>
<span class="ltx_bibblock"><em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">https://github.com/FederatedAI/FATE</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">FernÃ¡ndezâ€AvilÃ©s
etÂ al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Francisco FernÃ¡ndezâ€AvilÃ©s,
Ricardo Sanzâ€Ruiz, AndreuÂ M. Climent,
Lina BadimÃ³n, R. Bolli,
Dominique Charron, Valentin Fuster,
Stefan Janssens, Jens Kastrup,
Hyo-Soo Kim, ThomasÂ Felix LÃ¼scher,
JohnÂ F. Martin, Philippe MenaschÃ©,
RobertÂ D. Simari, GreggÂ W. Stone,
Andre Terzic, JamesÂ T. Willerson,
JosephÂ C. Wu, Francisco Andre
FernÃ¡ndez-AvilÃ©s Terzic, Lina Kathleen Darcy L.
Stefanie Rosalinda Marc S. Mark Badimon Broughton DiFede Dimmeler
MadonnaÂ Penn Sus, KathleenÂ M. Broughton,
DarcyÂ L. DiFede, Stefanie Dimmeler,
Rosalinda Madonna, MarcÂ S. Penn,
MarkÂ A Sussman, Joost PÂ G Sluijter,
KaiÂ C. Wollert, Wayne Roberto Steven
Dominique MarÃ­a Eugenia Valentin Ge Balkan Bolli Chamuleau Charron
FernÃ¡ndez-Santos Fu, Wayne Balkan,
StevenÂ A.J. Chamuleau, MarÃ­aÂ Eugenia
FernÃ¡ndez-Santos, Georg Goliasch,
Mariann GyÃ¶ngyÃ¶si, JoshuaÂ M.
Hare, BryonÂ A Tompkins, Johannes
Winkler, Antoni Timothy D. Doris A.
BayÃ©s-GenÃ­sÂ Henry Taylor, Antoni
BayÃ©sâ€GenÃ­s, TimothyÂ D. Henry,
DorisÂ A Taylor, Andreu M. Amir Beatriz
Felipe Climent LermanÂ Pelacho Prosper, Amir Lerman,
Beatriz Pelacho, Felipe Prosper,
Ricardo Emerson C. Giulio Sanz-RuizÂ Perin Pompilio,
EmersonÂ C. Perin, Giulio Pompilio,
Bernard Jozef Eric PÃ©ter Stefan Douglas W. Pedro L.
Warren Gersh Bartunek Duckers FerdinandyÂ Janssens Losordo,
BernardÂ J. Gersh, Jozef Bartunek,
Eric Duckers, PÃ©ter Ferdinandy,
Douglas Losordo, PedroÂ L. SÃ¡nchez,
Warren Sherman, Wojtek Wojakowski,
AndreasÂ M. Zeiher, JÃ©rÃ´me
Roncalli, Anthony Mathur, Filippo
Domenico Thomas J. Jay Seppo Crea DÂ´Amario PovsicÂ Traverse
YlÃ¤-Herttuala, Filippo Crea, Domenico
DÂ´Amario, ThomasÂ J. Povsic, JayÂ H.
Traverse, and Seppo YlÃ¤-Herttuala.
2017.

</span>
<span class="ltx_bibblock">Global position paper on cardiovascular
regenerative medicine.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.3.1" class="ltx_emph ltx_font_italic">European Heart Journal</em>
38 (2017), 2532 â€“ 2546.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Flores etÂ al<span id="bib.bib38.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Mona Flores, I. Dayan,
H. Roth, Aoxiao Zhong,
A. Harouni, Amilcare Gentili,
A. Abidin, Andrew Liu,
A. Costa, B. Wood,
Chien-Sung Tsai, Chih-Hung Wang,
C. Hsu, CK Lee, Colleen
Ruan, Daguang Xu, Dufan Wu,
E. Huang, F. Kitamura,
G. Lacey, G. Corradi,
Hao-Hsin Shin, Hirofumi Obinata,
Hui Ren, Jason Crane,
Jesse Tetreault, Jiahui Guan,
J. Garrett, J. Park, K.
Dreyer, K. Juluru, Kristopher Kersten,
Marcio A. B.Â C. Rockenbach, M. Linguraru,
M. Haider, M. Abdelmaseeh,
Nicola Rieke, P. Damasceno,
Pedro Silva, Pochuan Wang,
Sheng Xu, Shuichi Kawano,
Sira Sriswa, S. Park, T.
Grist, V. Buch, W. Jantarabenjakul,
Weichung Wang, W. Tak,
Xiang Li, Xihong Lin,
Fred Kwon, Fiona Gilbert,
J. Kaggie, Quanzheng Li,
Abood Quraini, Andrew Feng,
A. Priest, B. Turkbey,
B. Glicksberg, B. Bizzo,
B.Â S. Kim, Carlos Tor-DÃ­ez,
Chia-Cheng Lee, Chia-Jung Hsu,
Chin-Hsien Lin, C. Lai,
Christopher Hess, ColinÂ B. Compas,
D. Bhatia, E. Oermann,
E. Leibovitz, H. Sasaki,
Hitoshi Mori, Isaac Yang,
J.Â H. Sohn, Krishna NandÂ Keshava Murthy,
Lijuan Fu, Matheus RibeiroÂ Furtado de
MendonÃ§a, Mike Fralick, M. Kang,
M. Adil, Natalie Gangai,
P. Vateekul, P. Elnajjar,
Sara Hickman, S. Majumdar,
S. McLeod, Sheridan Reed,
Stefan Graf, S. Harmon,
T. Kodama, T. Puthanakit,
T. Mazzulli, Vitor Lavor,
Y. Rakvongthai, YuÂ Rim Lee, and
Yuhong Wen. 2021a.

</span>
<span class="ltx_bibblock">Federated Learning used for predicting outcomes in
SARS-COV-2 patients.

</span>
<span class="ltx_bibblock"><em id="bib.bib38.3.1" class="ltx_emph ltx_font_italic">Research Square</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Flores etÂ al<span id="bib.bib39.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Mona Flores, I Dayan,
H Roth, Aoxiao Zhong, A
Harouni, Amilcare Gentili, A Abidin,
Andrew Liu, A Costa, B
Wood, Chien-Sung Tsai, Chih-Hung Wang,
C Hsu, CÂ K Lee, Colleen
Ruan, Daguang Xu, Dufan Wu,
E Huang, F Kitamura, G
Lacey, G Corradi, Hao-Hsin Shin,
Hirofumi Obinata, Hui Ren,
Jason Crane, Jesse Tetreault,
Jiahui Guan, J Garrett,
J Park, K Dreyer, K
Juluru, Kristopher Kersten, Marcio A BÂ C
Rockenbach, M Linguraru, M Haider,
M Abdelmaseeh, Nicola Rieke,
P Damasceno, Pedro Silva,
Pochuan Wang, Sheng Xu,
Shuichi Kawano, Sira Sriswa,
S Park, T Grist, V
Buch, W Jantarabenjakul, Weichung Wang,
W Tak, Xiang Li, Xihong
Lin, Fred Kwon, Fiona Gilbert,
J Kaggie, Quanzheng Li,
Abood Quraini, Andrew Feng,
A Priest, B Turkbey, B
Glicksberg, B Bizzo, BÂ S Kim,
Carlos Tor-DÃ­ez, Chia-Cheng Lee,
Chia-Jung Hsu, Chin-Hsien Lin,
C Lai, Christopher Hess,
ColinÂ B Compas, D Bhatia,
E Oermann, E Leibovitz,
H Sasaki, Hitoshi Mori,
Isaac Yang, JÂ H Sohn,
Krishna NandÂ Keshava Murthy, Lijuan Fu,
Matheus RibeiroÂ Furtado de Mendon, Mike
Fralick, M Kang, M Adil,
Natalie Gangai, P Vateekul,
P Elnajjar, Sara Hickman,
S Majumdar, S McLeod,
Sheridan Reed, Stefan Graf,
S Harmon, T Kodama, T
Puthanakit, T Mazzulli, Vitor Lavor,
Y Rakvongthai, YuÂ Rim Lee, and
Yuhong Wen. 2021b.

</span>
<span class="ltx_bibblock">Federated Learning used for predicting outcomes in
SARS-COV-2 patients.

</span>
<span class="ltx_bibblock"><em id="bib.bib39.3.1" class="ltx_emph ltx_font_italic">Research Square</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Geiping etÂ al<span id="bib.bib40.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Jonas Geiping, Hartmut
Bauermeister, Hannah DrÃ¶ge, and
Michael Moeller. 2020.

</span>
<span class="ltx_bibblock">Inverting Gradients â€“ How easy is it to break
privacy in federated learning?

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2003.14053Â [cs.CV]

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gibaud etÂ al<span id="bib.bib41.2.2.1" class="ltx_text">.</span> (2011)</span>
<span class="ltx_bibblock">
B Gibaud, G Kassel,
M Dojat, B Batrancourt,
Franck Michel, A Gaignard, and
J Montagnat. 2011.

</span>
<span class="ltx_bibblock">NeuroLOG: sharing neuroimaging data using an
ontology-based federated approach.

</span>
<span class="ltx_bibblock"><em id="bib.bib41.3.1" class="ltx_emph ltx_font_italic">AMIA â€¦ Annual Symposium proceedings. AMIA
Symposium</em> 2011 (2011),
472â€“80.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gultepe etÂ al<span id="bib.bib42.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Eren Gultepe, JeffreyÂ P
Green, Hien Nguyen, Jason Adams,
Timothy Albertson, and Ilias
Tagkopoulos. 2014.

</span>
<span class="ltx_bibblock">From vital signs to clinical outcomes for patients
with sepsis: a machine learning basis for a clinical decision support
system.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.3.1" class="ltx_emph ltx_font_italic">Journal of the American Medical Informatics
Association</em> 21, 2
(2014), 315â€“325.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo
etÂ al<span id="bib.bib43.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Jiale Guo, Ziyao Liu,
Kwok-Yan Lam, Jun Zhao,
Yiqiang Chen, and Chaoping Xing.
2021.

</span>
<span class="ltx_bibblock">Secure Weighted Aggregation for Federated
Learning.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hard etÂ al<span id="bib.bib44.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Andrew Hard, Kanishka
Rao, Rajiv Mathews, Swaroop Ramaswamy,
FranÃ§oise Beaufays, Sean Augenstein,
Hubert Eichner, ChloÃ© Kiddon, and
Daniel Ramage. 2019.

</span>
<span class="ltx_bibblock">Federated Learning for Mobile Keyboard Prediction.

</span>
<span class="ltx_bibblock">(2019).

</span>
<span class="ltx_bibblock">arXiv:1811.03604Â [cs.CL]

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He
etÂ al<span id="bib.bib45.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Chaoyang He, Murali
Annavaram, and Salman Avestimehr.
2020a.

</span>
<span class="ltx_bibblock">FedNAS: Federated Deep Learning via Neural
Architecture Search.

</span>
<span class="ltx_bibblock"><em id="bib.bib45.3.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/2004.08546
(2020).

</span>
<span class="ltx_bibblock">arXiv:2004.08546

<a target="_blank" href="https://arxiv.org/abs/2004.08546" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2004.08546</a>

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He
etÂ al<span id="bib.bib46.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Chaoyang He, Murali
Annavaram, and Salman Avestimehr.
2020b.

</span>
<span class="ltx_bibblock">Group Knowledge Transfer: Collaborative Training of
Large CNNs on the Edge.

</span>
<span class="ltx_bibblock"><em id="bib.bib46.3.1" class="ltx_emph ltx_font_italic">CoRR</em> abs/2007.14513
(2020).

</span>
<span class="ltx_bibblock">arXiv:2007.14513

<a target="_blank" href="https://arxiv.org/abs/2007.14513" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/2007.14513</a>

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al<span id="bib.bib47.2.2.1" class="ltx_text">.</span> (2020c)</span>
<span class="ltx_bibblock">
Chaoyang He, Songze Li,
Jinhyun So, Mi Zhang,
Hongyi Wang, Xiaoyang Wang,
Praneeth Vepakomma, Abhishek Singh,
Hang Qiu, Li Shen,
Peilin Zhao, Yan Kang,
Yang Liu, Ramesh Raskar,
Qiang Yang, Murali Annavaram, and
Salman Avestimehr. 2020c.

</span>
<span class="ltx_bibblock">FedML: A Research Library and Benchmark for
Federated Machine Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib47.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.13518</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He
etÂ al<span id="bib.bib48.2.2.1" class="ltx_text">.</span> (2020d)</span>
<span class="ltx_bibblock">
Chaoyang He, Conghui Tan,
Hanlin Tang, Shuang Qiu, and
Ji Liu. 2020d.

</span>
<span class="ltx_bibblock">Central Server Free Federated Learning over
Single-sided Trust Social Networks.

</span>
<span class="ltx_bibblock">(2020).

</span>
<span class="ltx_bibblock">arXiv:1910.04956Â [cs.LG]

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Honkela
etÂ al<span id="bib.bib49.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
A Honkela, Mrinal Das,
O Dikmen, and Samuel Kaski.
2017.

</span>
<span class="ltx_bibblock">Efficient differentially private learning improves
drug sensitivity prediction.

</span>
<span class="ltx_bibblock"><em id="bib.bib49.3.1" class="ltx_emph ltx_font_italic">Biology Direct</em> 13
(2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hossain and
Muhammad (2019)</span>
<span class="ltx_bibblock">
M.Â Shamim Hossain and
Ghulam Muhammad. 2019.

</span>
<span class="ltx_bibblock">Emotion recognition using secure edge and cloud
computing.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">Information Sciences</em> 504
(12 2019).

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/j.ins.2019.07.040" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.ins.2019.07.040</a>

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang etÂ al<span id="bib.bib51.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Li Huang, AndrewÂ L. Shea,
Huining Qian, Aditya Masurkar,
Hao Deng, and Dianbo Liu.
2019.

</span>
<span class="ltx_bibblock">Patient clustering improves efficiency of federated
machine learning to predict mortality and hospital stay time using
distributed electronic medical records.

</span>
<span class="ltx_bibblock"><em id="bib.bib51.3.1" class="ltx_emph ltx_font_italic">Journal of Biomedical Informatics</em>
99 (11 2019).

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/j.jbi.2019.103291" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.jbi.2019.103291</a>

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang
etÂ al<span id="bib.bib52.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Li Huang, Yifeng Yin,
Zeng Fu, Shifa Zhang,
Hao Deng, and Dianbo Liu.
2020.

</span>
<span class="ltx_bibblock">LoAdaBoost: Loss-based AdaBoost federated machine
learning with reduced computational complexity on IID and non-IID intensive
care data.

</span>
<span class="ltx_bibblock"><em id="bib.bib52.3.1" class="ltx_emph ltx_font_italic">PLOS ONE</em> 15
(4 2020).

</span>
<span class="ltx_bibblock">Issue 4.


<a target="_blank" href="https://doi.org/10.1371/journal.pone.0230706" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1371/journal.pone.0230706</a>

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">IBMFL (2020)</span>
<span class="ltx_bibblock">
IBMFL. 2020.

</span>
<span class="ltx_bibblock">IBM Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">https://github.com/IBM/federated-learning-lib</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jacobson etÂ al<span id="bib.bib54.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
RebeccaÂ S Jacobson, M
Becich, R Bollag, G Chavan,
Julia Corrigan, R Dhir,
M Feldman, Carmelo Gaudioso,
Elizabeth Legowski, N Maihle,
K Mitchell, Monica Murphy,
Mayurapriyan Sakthivel, Eugene Tseytlin,
and J Weaver. 2015.

</span>
<span class="ltx_bibblock">A Federated Network for Translational Cancer
Research Using Clinical Data and Biospecimens.

</span>
<span class="ltx_bibblock"><em id="bib.bib54.3.1" class="ltx_emph ltx_font_italic">Cancer research</em> 75 24
(2015), 5194â€“201.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang
etÂ al<span id="bib.bib55.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
JiÂ Chu Jiang, B.
Kantarci, S. Oktug, and T. Soyata.
2020.

</span>
<span class="ltx_bibblock">Federated Learning in Smart City Sensing:
Challenges and Opportunities.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.3.1" class="ltx_emph ltx_font_italic">Sensors (Basel, Switzerland)</em>
20 (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jochems etÂ al<span id="bib.bib56.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
A. Jochems, T. Deist,
I.Â El Naqa, M. Kessler,
C. Mayo, J. Reeves, S.
Jolly, M. Matuszak, R.Â Ten Haken,
J. van Soest, C. Oberije,
C. Faivre-Finn, G. Price,
D.Â D.Â De Ruysscher, P. Lambin, and
A. Dekker. 2017.

</span>
<span class="ltx_bibblock">Developing and Validating a Survival Prediction
Model for NSCLC Patients Through Distributed Learning Across 3 Countries.

</span>
<span class="ltx_bibblock"><em id="bib.bib56.3.1" class="ltx_emph ltx_font_italic">International Journal of Radiation Oncology,
Biology, Physics</em> 99 (2017),
344 â€“ 352.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jochems etÂ al<span id="bib.bib57.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Arthur Jochems, TimoÂ M.
Deist, Johan van Soest, Michael Eble,
Paul Bulens, Philippe Coucke,
Wim Dries, Philippe Lambin, and
Andre Dekker. 2016.

</span>
<span class="ltx_bibblock">Distributed learning: Developing a predictive model
based on data from multiple hospitals without data leaving the hospital â€“ A
real life proof of concept.

</span>
<span class="ltx_bibblock"><em id="bib.bib57.3.1" class="ltx_emph ltx_font_italic">Radiotherapy and Oncology</em>
121 (12 2016).

</span>
<span class="ltx_bibblock">Issue 3.


<a target="_blank" href="https://doi.org/10.1016/j.radonc.2016.10.002" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.radonc.2016.10.002</a>

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ju
etÂ al<span id="bib.bib58.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Ce Ju, Dashan Gao,
Ravikiran Mane, Ben Tan,
Yang Liu, and Cuntai Guan.
2020a.

</span>
<span class="ltx_bibblock">Federated Transfer Learning for EEG Signal
Classification.

</span>
<span class="ltx_bibblock"><em id="bib.bib58.3.1" class="ltx_emph ltx_font_italic">2020 42nd Annual International Conference of
the IEEE Engineering in Medicine &amp; Biology Society (EMBC)</em>
(Jul 2020).

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/embc44109.2020.9175344" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/embc44109.2020.9175344</a>

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ju etÂ al<span id="bib.bib59.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Ce Ju, Ruihui Zhao,
Jichao Sun, Xiguang Wei,
Bo Zhao, Yang Liu,
Hongshan Li, Tianjian Chen,
Xinwei Zhang, Dashan Gao,
Ben Tan, Han Yu, Chuning
He, and Yuan Jin. 2020b.

</span>
<span class="ltx_bibblock">Privacy-Preserving Technology to Help Millions of
People: Federated Prediction Model for Stroke Prevention.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kairouz
etÂ al<span id="bib.bib60.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Peter Kairouz, H.Â Brendan
McMahan, Brendan Avent, AurÃ©lien
Bellet, Mehdi Bennis, ArjunÂ Nitin
Bhagoji, Kallista Bonawitz, Zachary
Charles, Graham Cormode, Rachel
Cummings, Rafael G.Â L. Dâ€™Oliveira, Hubert
Eichner, SalimÂ El Rouayheb, David Evans,
Josh Gardner, Zachary Garrett,
AdriÃ  GascÃ³n, Badih Ghazi,
PhillipÂ B. Gibbons, Marco Gruteser,
Zaid Harchaoui, Chaoyang He,
Lie He, Zhouyuan Huo,
Ben Hutchinson, Justin Hsu,
Martin Jaggi, Tara Javidi,
Gauri Joshi, Mikhail Khodak,
Jakub KoneÄnÃ½, Aleksandra Korolova,
Farinaz Koushanfar, Sanmi Koyejo,
TancrÃ¨de Lepoint, Yang Liu,
Prateek Mittal, Mehryar Mohri,
Richard Nock, Ayfer Ã–zgÃ¼r,
Rasmus Pagh, Mariana Raykova,
Hang Qi, Daniel Ramage,
Ramesh Raskar, Dawn Song,
Weikang Song, SebastianÂ U. Stich,
Ziteng Sun, AnandaÂ Theertha Suresh,
Florian TramÃ¨r, Praneeth Vepakomma,
Jianyu Wang, Li Xiong,
Zheng Xu, Qiang Yang,
FelixÂ X. Yu, Han Yu, and
Sen Zhao. 2021a.

</span>
<span class="ltx_bibblock">Advances and Open Problems in Federated Learning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1912.04977Â [cs.LG]

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kairouz
etÂ al<span id="bib.bib61.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Peter Kairouz, HÂ Brendan
McMahan, Brendan Avent, AurÃ©lien
Bellet, Mehdi Bennis, ArjunÂ Nitin
Bhagoji, Kallista Bonawitz, Zachary
Charles, Graham Cormode, Rachel
Cummings, Rafael GÂ L Dâ€™Oliveira, Hubert
Eichner, SalimÂ El Rouayheb, David Evans,
Josh Gardner, Zachary Garrett,
AdriÃ  GascÃ³n, Badih Ghazi,
PhillipÂ B Gibbons, Marco Gruteser,
Zaid Harchaoui, Chaoyang He,
Lie He, Zhouyuan Huo,
Ben Hutchinson, Justin Hsu,
Martin Jaggi, Tara Javidi,
Gauri Joshi, Mikhail Khodak,
Jakub KoneÄnÃ½, Aleksandra Korolova,
Farinaz Koushanfar, Sanmi Koyejo,
TancrÃ¨de Lepoint, Yang Liu,
Prateek Mittal, Mehryar Mohri,
Richard Nock, Ayfer Ã–zgÃ¼r,
Rasmus Pagh, Mariana Raykova,
Hang Qi, Daniel Ramage,
Ramesh Raskar, Dawn Song,
Weikang Song, SebastianÂ U Stich,
Ziteng Sun, AnandaÂ Theertha Suresh,
Florian TramÃ¨r, Praneeth Vepakomma,
Jianyu Wang, Li Xiong,
Zheng Xu, Qiang Yang,
FelixÂ X Yu, Han Yu, and
Sen Zhao. 2021b.

</span>
<span class="ltx_bibblock">Advances and Open Problems in Federated Learning.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kawamoto etÂ al<span id="bib.bib62.2.2.1" class="ltx_text">.</span> (2005)</span>
<span class="ltx_bibblock">
Kensaku Kawamoto,
CaitlinÂ A Houlihan, E.Â Andrew Balas,
and DavidÂ F. Lobach. 2005.

</span>
<span class="ltx_bibblock">Improving clinical practice using clinical decision
support systems: a systematic review of trials to identify features critical
to success.

</span>
<span class="ltx_bibblock"><em id="bib.bib62.3.1" class="ltx_emph ltx_font_italic">BMJ : British Medical Journal</em>
330 (2005), 765.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kho etÂ al<span id="bib.bib63.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
A Kho, J Cashy,
K Jackson, A Pah,
Satyender Goel, J Boehnke,
J Humphries, S Kominers,
B Hota, S Sims, B
Malin, D French, T Walunas,
D Meltzer, E Kaleba, RÂ C
Jones, and W Galanter. 2015.

</span>
<span class="ltx_bibblock">Design and implementation of a privacy preserving
electronic health record linkage tool in Chicago.

</span>
<span class="ltx_bibblock"><em id="bib.bib63.3.1" class="ltx_emph ltx_font_italic">Journal of the American Medical Informatics
Association : JAMIA</em> 22 5 (2015),
1072â€“80.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Laud and Pankova (2018)</span>
<span class="ltx_bibblock">
Peeter Laud and Alisa
Pankova. 2018.

</span>
<span class="ltx_bibblock">Privacy-preserving record linkage in large
databases using secure multiparty computation.

</span>
<span class="ltx_bibblock"><em id="bib.bib64.1.1" class="ltx_emph ltx_font_italic">BMC Medical Genomics</em> 11
(10 2018).

</span>
<span class="ltx_bibblock">Issue S4.


<a target="_blank" href="https://doi.org/10.1186/s12920-018-0400-8" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1186/s12920-018-0400-8</a>

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Leaf (2019)</span>
<span class="ltx_bibblock">
Leaf. 2019.

</span>
<span class="ltx_bibblock">Benchmarking framework for studying in federated
settings.

</span>
<span class="ltx_bibblock"><em id="bib.bib65.1.1" class="ltx_emph ltx_font_italic">https://leaf.cmu.edu/</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee and Shin (2020)</span>
<span class="ltx_bibblock">
G Lee and S Shin.
2020.

</span>
<span class="ltx_bibblock">Federated Learning on Clinical Benchmark Data:
Performance Assessment.

</span>
<span class="ltx_bibblock"><em id="bib.bib66.1.1" class="ltx_emph ltx_font_italic">Journal of Medical Internet Research</em>
22 (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee
etÂ al<span id="bib.bib67.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Haeyun Lee, YoungÂ Jun
Chai, Hyunjin Joo, Kyungsu Lee,
JaeÂ Youn Hwang, Seok-Mo Kim,
Kwangsoon Kim, Inn-Chul Nam,
JuneÂ Young Choi, HyeongÂ Won Yu,
Myung-Chul Lee, Hiroo Masuoka,
Akira Miyauchi, KyuÂ Eun Lee,
Sungwan Kim, and Hyoun-Joong Kong.
2021.

</span>
<span class="ltx_bibblock">Federated Learning for Thyroid Ultrasound Image
Analysis to Protect Personal Information: Validation Study in a Real Health
Care Environment.

</span>
<span class="ltx_bibblock"><em id="bib.bib67.3.1" class="ltx_emph ltx_font_italic">JMIR Medical Informatics</em>
9 (5 2021).

</span>
<span class="ltx_bibblock">Issue 5.


<a target="_blank" href="https://doi.org/10.2196/25869" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.2196/25869</a>

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al<span id="bib.bib68.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Qinbin Li, Zhaomin Wu,
Zeyi Wen, and Bingsheng He.
2021.

</span>
<span class="ltx_bibblock">Privacy-Preserving Gradient Boosting Decision
Trees.

</span>
<span class="ltx_bibblock">(2021).

</span>
<span class="ltx_bibblock">arXiv:1911.04209Â [cs.LG]

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li
etÂ al<span id="bib.bib69.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Tian Li, AnitÂ Kumar Sahu,
AmeetÂ S. Talwalkar, and Virginia
Smith. 2020b.

</span>
<span class="ltx_bibblock">Federated Learning: Challenges, Methods, and Future
Directions.

</span>
<span class="ltx_bibblock"><em id="bib.bib69.3.1" class="ltx_emph ltx_font_italic">IEEE Signal Processing Magazine</em>
37 (2020), 50â€“60.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al<span id="bib.bib70.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Wen Li, Fucang Jia, and
Qingmao Hu. 2015.

</span>
<span class="ltx_bibblock">Automatic Segmentation of Liver Tumor in CT Images
with Deep Convolutional Neural Networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib70.3.1" class="ltx_emph ltx_font_italic">Journal of Computer and Communications</em>
03 (2015).

</span>
<span class="ltx_bibblock">Issue 11.


<a target="_blank" href="https://doi.org/10.4236/jcc.2015.311023" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.4236/jcc.2015.311023</a>

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al<span id="bib.bib71.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Wenqi Li, Fausto
MilletarÃ¬, Daguang Xu, Nicola Rieke,
Jonny Hancox, Wentao Zhu,
Maximilian Baust, Yan Cheng,
SÃ©bastien Ourselin, MÂ Jorge Cardoso,
and Andrew Feng. 2019.

</span>
<span class="ltx_bibblock">Privacy-preserving Federated Brain Tumour
Segmentation.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al<span id="bib.bib72.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Xiaoxiao Li, Yufeng Gu,
N Dvornek, L Staib, P
Ventola, and J Duncan.
2020a.

</span>
<span class="ltx_bibblock">Multi-site fMRI Analysis Using Privacy-preserving
Federated Learning and Domain Adaptation: ABIDE Results.

</span>
<span class="ltx_bibblock"><em id="bib.bib72.3.1" class="ltx_emph ltx_font_italic">Medical image analysis</em>
65 (2020), 101765.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu
etÂ al<span id="bib.bib73.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Dianbo Liu, Timothy
Miller, Raheel Sayeed, and KennethÂ D.
Mandl. 2018.

</span>
<span class="ltx_bibblock">FADL:Federated-Autonomous Deep Learning for
Distributed Electronic Health Record.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1811.11400Â [cs.CY]

</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu
etÂ al<span id="bib.bib74.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
JessicaÂ Chia Liu, Jack
Goetz, Srijan Sen, and Ambuj Tewari.
2021.

</span>
<span class="ltx_bibblock">Learning From Others Without Sacrificing Privacy:
Simulation Comparing Centralized and Federated Machine Learning on Mobile
Health Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib74.3.1" class="ltx_emph ltx_font_italic">JMIR mHealth and uHealth</em>
9 (3 2021).

</span>
<span class="ltx_bibblock">Issue 3.


<a target="_blank" href="https://doi.org/10.2196/23728" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.2196/23728</a>

</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al<span id="bib.bib75.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yang Liu, Yingting Liu,
Zhijie Liu, Yuxuan Liang,
Chuishi Meng, Junbo Zhang, and
Yu Zheng. 2020.

</span>
<span class="ltx_bibblock">Federated Forest.

</span>
<span class="ltx_bibblock"><em id="bib.bib75.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Big Data</em>
(2020).

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/TBDATA.2020.2992755" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TBDATA.2020.2992755</a>

</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lo
etÂ al<span id="bib.bib76.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
SinÂ Kit Lo, Qinghua Lu,
Liming Zhu, Hye young Paik,
Xiwei Xu, and Chen Wang.
2021.

</span>
<span class="ltx_bibblock">Architectural Patterns for the Design of Federated
Learning Systems.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2101.02373Â [cs.LG]

</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lyu etÂ al<span id="bib.bib77.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Lingjuan Lyu, Han Yu,
and Qiang Yang. 2020.

</span>
<span class="ltx_bibblock">Threats to Federated Learning: A Survey.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2003.02133Â [cs.CR]

</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan etÂ al<span id="bib.bib78.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
HÂ Brendan McMahan, Eider
Moore, Daniel Ramage, Seth Hampson,
and BlaiseÂ AgÃ¼era y Arcas.
2017.

</span>
<span class="ltx_bibblock">Communication-Efficient Learning of Deep Networks
from Decentralized Data.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Menze etÂ al<span id="bib.bib79.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
BjoernÂ H. Menze, Andras
Jakab, Stefan Bauer, Jayashree
Kalpathy-Cramer, Keyvan Farahani, Justin
Kirby, Yuliya Burren, Nicole Porz,
Johannes Slotboom, Roland Wiest,
Levente Lanczi, Elizabeth Gerstner,
Marc-Andre Weber, Tal Arbel,
BrianÂ B. Avants, Nicholas Ayache,
Patricia Buendia, D.Â Louis Collins,
Nicolas Cordier, JasonÂ J. Corso,
Antonio Criminisi, Tilak Das,
Herve Delingette, Cagatay Demiralp,
ChristopherÂ R. Durst, Michel Dojat,
Senan Doyle, Joana Festa,
Florence Forbes, Ezequiel Geremia,
Ben Glocker, Polina Golland,
Xiaotao Guo, Andac Hamamci,
KhanÂ M. Iftekharuddin, Raj Jena,
NigelÂ M. John, Ender Konukoglu,
Danial Lashkari, JoseÂ Antonio Mariz,
Raphael Meier, Sergio Pereira,
Doina Precup, StephenÂ J. Price,
TammyÂ Riklin Raviv, Syed M.Â S. Reza,
Michael Ryan, Duygu Sarikaya,
Lawrence Schwartz, Hoo-Chang Shin,
Jamie Shotton, CarlosÂ A. Silva,
Nuno Sousa, NageshÂ K. Subbanna,
Gabor Szekely, ThomasÂ J. Taylor,
OwenÂ M. Thomas, NicholasÂ J. Tustison,
Gozde Unal, Flor Vasseur,
Max Wintermark, DongÂ Hye Ye,
Liang Zhao, Binsheng Zhao,
Darko Zikic, Marcel Prastawa,
Mauricio Reyes, and KoenÂ Van Leemput.
2015.

</span>
<span class="ltx_bibblock">The Multimodal Brain Tumor Image Segmentation
Benchmark (BRATS).

</span>
<span class="ltx_bibblock"><em id="bib.bib79.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Medical Imaging</em>
34 (10 2015).

</span>
<span class="ltx_bibblock">Issue 10.


<a target="_blank" href="https://doi.org/10.1109/TMI.2014.2377694" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TMI.2014.2377694</a>

</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Miyaji
etÂ al<span id="bib.bib80.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
A Miyaji, Kazuhisa
Nakasho, and Shohei Nishida.
2016.

</span>
<span class="ltx_bibblock">Privacy-Preserving Integration of Medical Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib80.3.1" class="ltx_emph ltx_font_italic">Journal of Medical Systems</em>
41 (2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Miyaji
etÂ al<span id="bib.bib81.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Atsuko Miyaji, Kazuhisa
Nakasho, and Shohei Nishida.
2017.

</span>
<span class="ltx_bibblock">Privacy-Preserving Integration of Medical Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib81.3.1" class="ltx_emph ltx_font_italic">Journal of Medical Systems</em>
41 (3 2017).

</span>
<span class="ltx_bibblock">Issue 3.


<a target="_blank" href="https://doi.org/10.1007/s10916-016-0657-4" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/s10916-016-0657-4</a>

</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mucchi etÂ al<span id="bib.bib82.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Lorenzo Mucchi, Sara
Jayousi, Stefano Caputo, Elisabetta
Paoletti, Paolo Zoppi, Simona Geli,
and Pietro Dioniso. 2020.

</span>
<span class="ltx_bibblock">How 6G Technology Can Change the Future Wireless
Healthcare.

</span>
<span class="ltx_bibblock"><em id="bib.bib82.3.1" class="ltx_emph ltx_font_italic">2020 2nd 6G Wireless Summit (6G SUMMIT)</em>
(2020), 1â€“6.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen etÂ al<span id="bib.bib83.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
DinhÂ C Nguyen, Quoc-Viet
Pham, PubuduÂ N Pathirana, Ming Ding,
ArunaÂ Prasad Seneviratne, Zihuai Lin,
OctaviaÂ A Dobre, and WonÂ Joo Hwang.
2021.

</span>
<span class="ltx_bibblock">Federated Learning for Smart Healthcare: A Survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib83.3.1" class="ltx_emph ltx_font_italic">ArXiv</em> abs/2111.08834
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">PaddleFL (2019)</span>
<span class="ltx_bibblock">
PaddleFL. 2019.

</span>
<span class="ltx_bibblock">PaddleFL.

</span>
<span class="ltx_bibblock"><em id="bib.bib84.1.1" class="ltx_emph ltx_font_italic">https://github.com/PaddlePaddle/PaddleFL/</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pal and
Sankarasubbu (2021)</span>
<span class="ltx_bibblock">
Ankit Pal and
Malaikannan Sankarasubbu. 2021.

</span>
<span class="ltx_bibblock">Pay attention to the cough.

</span>
<span class="ltx_bibblock"><em id="bib.bib85.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 36th Annual ACM Symposium
on Applied Computing</em>.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3412841.3441943" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3412841.3441943</a>

</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pal
etÂ al<span id="bib.bib86.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Ankit Pal, LogeshÂ Kumar
Umapathi, and Malaikannan Sankarasubbu.
2022.

</span>
<span class="ltx_bibblock">MedMCQA: A Large-scale Multi-Subject Multi-Choice
Dataset for Medical domain Question Answering. In
<em id="bib.bib86.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Conference on Health, Inference,
and Learning</em> <em id="bib.bib86.4.2" class="ltx_emph ltx_font_italic">(Proceedings of Machine Learning
Research, Vol.Â 174)</em>,
Gerardo Flores, GeorgeÂ H
Chen, Tom Pollard, JoyceÂ C Ho, and
Tristan Naumann (Eds.). PMLR,
248â€“260.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://proceedings.mlr.press/v174/pal22a.html" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://proceedings.mlr.press/v174/pal22a.html</a>

</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papernot etÂ al<span id="bib.bib87.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Nicolas Papernot, Patrick
McDaniel, Arunesh Sinha, and Michael
Wellman. 2016.

</span>
<span class="ltx_bibblock">Towards the Science of Security and Privacy in
Machine Learning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1611.03814Â [cs.CR]

</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Perez
etÂ al<span id="bib.bib88.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
MarcoÂ V. Perez, KennethÂ W.
Mahaffey, Haley Hedlin, JohnÂ S.
Rumsfeld, Ariadna Garcia, Todd Ferris,
Vidhya Balasubramanian, AndreaÂ M. Russo,
Amol Rajmane, Lauren Cheung,
Grace Hung, Justin Lee,
Peter Kowey, Nisha Talati,
Divya Nag, SantoshÂ E. Gummidipundi,
Alexis Beatty, MellanieÂ True Hills,
Sumbul Desai, ChristopherÂ B. Granger,
Manisha Desai, and MintuÂ P. Turakhia.
2019.

</span>
<span class="ltx_bibblock">Large-Scale Assessment of a Smartwatch to Identify
Atrial Fibrillation.

</span>
<span class="ltx_bibblock"><em id="bib.bib88.3.1" class="ltx_emph ltx_font_italic">New England Journal of Medicine</em>
381 (11 2019).

</span>
<span class="ltx_bibblock">Issue 20.


<a target="_blank" href="https://doi.org/10.1056/NEJMoa1901183" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1056/NEJMoa1901183</a>

</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Perin etÂ al<span id="bib.bib89.2.2.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
EmersonÂ C. Perin, JamesÂ T.
Willerson, CarlÂ J. Pepine, TimothyÂ D.
Henry, StephenÂ G. Ellis, David XÂ M Zhao,
GuilhermeÂ V. Silva, Dejian Lai,
JamesÂ D. Thomas, MarvinÂ W. Kronenberg,
A.Â Daniel Martin, R.Â David Anderson,
JayÂ H. Traverse, MarcÂ S. Penn,
Saif Anwaruddin, AntonisÂ K. Hatzopoulos,
AdrianÂ P. Gee, DorisÂ A Taylor,
ChristopherÂ R. Cogle, Deirdre Smith,
Lynette Westbrook, James Chen,
EileenÂ M. Handberg, RachelÂ E. Olson,
Carrie Geither, Sherry Bowman,
Judy Francescon, Sarah Baraniuk,
LindaÂ B. Piller, LaraÂ M. Simpson,
Catalin Loghin, David Aguilar,
Sara Richman, Claudia Zierold,
Judy Bettencourt, ShellyÂ L. Sayre,
RachelÂ W. Vojvodic, SoniaÂ I. Skarlatos,
DavidÂ J. Gordon, RayÂ Francis Ebert,
Minjung Kwak, LemuelÂ A. MoyÃ©, and
RobertÂ D. Simari. 2012.

</span>
<span class="ltx_bibblock">Effect of transendocardial delivery of autologous
bone marrow mononuclear cells on functional capacity, left ventricular
function, and perfusion in chronic heart failure: the FOCUS-CCTRN trial.

</span>
<span class="ltx_bibblock"><em id="bib.bib89.3.1" class="ltx_emph ltx_font_italic">JAMA</em> 307 16
(2012), 1717â€“26.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pfitzner
etÂ al<span id="bib.bib90.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Bjarne Pfitzner, Nico
Steckhan, and Bert Arnrich.
2021.

</span>
<span class="ltx_bibblock">Federated Learning in a Medical Context: A
Systematic Literature Review.

</span>
<span class="ltx_bibblock"><em id="bib.bib90.3.1" class="ltx_emph ltx_font_italic">ACM Transactions on Internet Technology</em>
21 (6 2021).

</span>
<span class="ltx_bibblock">Issue 2.


<a target="_blank" href="https://doi.org/10.1145/3412357" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3412357</a>

</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pollard etÂ al<span id="bib.bib91.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Tom Pollard, Irene Chen,
Jenna Wiens, Steven Horng,
Danny Wong, Marzyeh Ghassemi,
Heather Mattie, Emily Lindmeer, and
Trishan Panch. 2019.

</span>
<span class="ltx_bibblock">Turning the crank for machine learning: ease, at
what expense?

</span>
<span class="ltx_bibblock"><em id="bib.bib91.3.1" class="ltx_emph ltx_font_italic">The Lancet Digital Health</em>
1 (09 2019),
e198â€“e199.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1016/S2589-7500(19)30112-8" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/S2589-7500(19)30112-8</a>

</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qayyum etÂ al<span id="bib.bib92.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Adnan Qayyum, Kashif
Ahmad, MuhammadÂ Ahtazaz Ahsan, Ala
Al-Fuqaha, and Junaid Qadir.
2021.

</span>
<span class="ltx_bibblock">Collaborative Federated Learning For Healthcare:
Multi-Modal COVID-19 Diagnosis at the Edge.

</span>
<span class="ltx_bibblock"><em id="bib.bib92.3.1" class="ltx_emph ltx_font_italic">ArXiv</em> abs/2101.07511
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qayyum
etÂ al<span id="bib.bib93.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Adnan Qayyum, Junaid
Qadir, Muhammad Bilal, and Ala
Al-Fuqaha. 2020.

</span>
<span class="ltx_bibblock">Secure and Robust Machine Learning for Healthcare: A
Survey.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2001.08103Â [cs.LG]

</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajan
etÂ al<span id="bib.bib94.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Deepta Rajan, David
Beymer, Shafiqul Abedin, and Ehsan
Dehghan. 2019.

</span>
<span class="ltx_bibblock">Pi-PE: A Pipeline for Pulmonary Embolism Detection
using Sparsely Annotated 3D CT Images.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rajendran
etÂ al<span id="bib.bib95.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Suraj Rajendran, J Obeid,
H Binol, RalphÂ D Agostino,
K Foley, Wei Zhang, P
Austin, Joey Brakefield, M Gurcan, and
U Topaloglu. 2021.

</span>
<span class="ltx_bibblock">Cloud-Based Federated Learning Implementation
Across Medical Centers.

</span>
<span class="ltx_bibblock"><em id="bib.bib95.3.1" class="ltx_emph ltx_font_italic">JCO clinical cancer informatics</em>
5 (2021), 1â€“11.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rieke etÂ al<span id="bib.bib96.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Nicola Rieke, Jonny
Hancox, Wenqi Li, Fausto MilletarÃ¬,
HolgerÂ R. Roth, Shadi Albarqouni,
Spyridon Bakas, MathieuÂ N. Galtier,
BennettÂ A. Landman, Klaus Maier-Hein,
SÃ©bastien Ourselin, Micah Sheller,
RonaldÂ M. Summers, Andrew Trask,
Daguang Xu, Maximilian Baust, and
M.Â Jorge Cardoso. 2020.

</span>
<span class="ltx_bibblock">The future of digital health with federated
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib96.3.1" class="ltx_emph ltx_font_italic">npj Digital Medicine</em> 3
(12 2020).

</span>
<span class="ltx_bibblock">Issue 1.


<a target="_blank" href="https://doi.org/10.1038/s41746-020-00323-1" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1038/s41746-020-00323-1</a>

</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roth
etÂ al<span id="bib.bib97.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
HolgerÂ R. Roth, Ken
Chang, Praveer Singh, Nir Neumark,
Wenqi Li, Vikash Gupta,
Sharut Gupta, Liangqiong Qu,
Alvin Ihsani, BernardoÂ C. Bizzo,
Yuhong Wen, Varun Buch,
Meesam Shah, Felipe Kitamura,
Matheus MendonÃ§a, Vitor Lavor,
Ahmed Harouni, Colin Compas,
Jesse Tetreault, Prerna Dogra,
Yan Cheng, Selnur Erdal,
Richard White, Behrooz Hashemian,
Thomas Schultz, Miao Zhang,
Adam McCarthy, B.Â Min Yun,
Elshaimaa Sharaf, KatharinaÂ V. Hoebel,
JayÂ B. Patel, Bryan Chen,
Sean Ko, Evan Leibovitz,
EttaÂ D. Pisano, Laura Coombs,
Daguang Xu, KeithÂ J. Dreyer,
Ittai Dayan, RamÂ C. Naidu,
Mona Flores, Daniel Rubin, and
Jayashree Kalpathy-Cramer.
2020.

</span>
<span class="ltx_bibblock">Federated Learning for Breast Density
Classification: A Real-World Implementation.

</span>
<span class="ltx_bibblock">(2020).

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1007/978-3-030-60548-3_18" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/978-3-030-60548-3_18</a>

</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ryffel etÂ al<span id="bib.bib98.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Theo Ryffel, Andrew
Trask, Morten Dahl, Bobby Wagner,
Jason Mancuso, Daniel Rueckert, and
Jonathan Passerat-Palmbach.
2018.

</span>
<span class="ltx_bibblock">A generic framework for privacy preserving deep
learning.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1811.04017Â [cs.LG]

</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Salam
etÂ al<span id="bib.bib99.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
MustafaÂ Abdul Salam, Sanaa
Taha, and Mohamed Ramadan.
2021.

</span>
<span class="ltx_bibblock">COVID-19 detection using federated machine
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib99.3.1" class="ltx_emph ltx_font_italic">PLOS ONE</em> 16
(6 2021).

</span>
<span class="ltx_bibblock">Issue 6.


<a target="_blank" href="https://doi.org/10.1371/journal.pone.0252573" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1371/journal.pone.0252573</a>

</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sarma etÂ al<span id="bib.bib100.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
KarthikÂ V Sarma, Stephanie
Harmon, Thomas Sanford, HolgerÂ R Roth,
Ziyue Xu, Jesse Tetreault,
Daguang Xu, MonaÂ G Flores,
AlexÂ G Raman, Rushikesh Kulkarni,
BradfordÂ J Wood, PeterÂ L Choyke,
AlanÂ M Priester, LeonardÂ S Marks,
StevenÂ S Raman, Dieter Enzmann,
Baris Turkbey, William Speier, and
CoreyÂ W Arnold. 2021.

</span>
<span class="ltx_bibblock">Federated learning improves site performance in
multicenter deep learning without data sharing.

</span>
<span class="ltx_bibblock"><em id="bib.bib100.3.1" class="ltx_emph ltx_font_italic">Journal of the American Medical Informatics
Association</em> 28 (6 2021).

</span>
<span class="ltx_bibblock">Issue 6.


<a target="_blank" href="https://doi.org/10.1093/jamia/ocaa341" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1093/jamia/ocaa341</a>

</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Scherer etÂ al<span id="bib.bib101.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Jonas Scherer, Marco
Nolden, Jens Kleesiek, Jasmin Metzger,
Klaus Kades, Verena Schneider,
Michael Bach, Oliver Sedlaczek,
AndreasÂ M. Bucher, ThomasÂ J. Vogl,
Frank GrÃ¼nwald, Jens-Peter KÃ¼hn,
Ralf-Thorsten Hoffmann, JÃ¶rg Kotzerke,
Oliver Bethge, Lars SchimmÃ¶ller,
Gerald Antoch, Hans-Wilhelm MÃ¼ller,
Andreas Daul, Konstantin Nikolaou,
Christian la FougÃ¨re, WolfgangÂ G. Kunz,
Michael Ingrisch, Balthasar Schachtner,
Jens Ricke, Peter Bartenstein,
Felix Nensa, Alexander Radbruch,
Lale Umutlu, Michael Forsting,
Robert Seifert, Ken Herrmann,
Philipp Mayer, Hans-Ulrich Kauczor,
Tobias Penzkofer, Bernd Hamm,
Winfried Brenner, Roman Kloeckner,
Christoph DÃ¼ber, Mathias
Schreckenberger, Rickmer Braren, Georgios
Kaissis, Marcus Makowski, Matthias
Eiber, Andrei Gafita, Rupert Trager,
WolfgangÂ A. Weber, Jakob Neubauer,
Marco Reisert, Michael Bock,
Fabian Bamberg, JÃ¼rgen Hennig,
PhilippÂ Tobias Meyer, Juri Ruf,
Uwe Haberkorn, StefanÂ O. Schoenberg,
Tristan Kuder, Peter Neher,
Ralf Floca, Heinz-Peter Schlemmer, and
Klaus Maier-Hein. 2020.

</span>
<span class="ltx_bibblock">Joint Imaging Platform for Federated Clinical Data
Analytics.

</span>
<span class="ltx_bibblock"><em id="bib.bib101.3.1" class="ltx_emph ltx_font_italic">JCO Clinical Cancer Informatics</em>
(11 2020).

</span>
<span class="ltx_bibblock">Issue 4.


<a target="_blank" href="https://doi.org/10.1200/CCI.20.00045" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1200/CCI.20.00045</a>

</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shao
etÂ al<span id="bib.bib102.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Rulin Shao, Hongyu He,
Ziwei Chen, Hui Liu, and
Dianbo Liu. 2020.

</span>
<span class="ltx_bibblock">Stochastic Channel-Based Federated Learning With
Neural Network Pruning for Medical Data Privacy Preservation: Model
Development and Experimental Validation.

</span>
<span class="ltx_bibblock"><em id="bib.bib102.3.1" class="ltx_emph ltx_font_italic">JMIR Formative Research</em>
4 (12 2020).

</span>
<span class="ltx_bibblock">Issue 12.


<a target="_blank" href="https://doi.org/10.2196/17265" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.2196/17265</a>

</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sheller
etÂ al<span id="bib.bib103.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
MicahÂ J. Sheller, Brandon
Edwards, G.Â Anthony Reina, Jason Martin,
Sarthak Pati, Aikaterini Kotrotsou,
Mikhail Milchenko, Weilin Xu,
Daniel Marcus, RivkaÂ R. Colen, and
Spyridon Bakas. 2020.

</span>
<span class="ltx_bibblock">Federated learning in medicine: facilitating
multi-institutional collaborations without sharing patient data.

</span>
<span class="ltx_bibblock"><em id="bib.bib103.3.1" class="ltx_emph ltx_font_italic">Scientific Reports</em> 10
(12 2020).

</span>
<span class="ltx_bibblock">Issue 1.


<a target="_blank" href="https://doi.org/10.1038/s41598-020-69250-1" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1038/s41598-020-69250-1</a>

</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi
etÂ al<span id="bib.bib104.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yuanming Shi, Kai Yang,
Tao Jiang, Jun Zhang, and
KhaledÂ B. Letaief. 2020.

</span>
<span class="ltx_bibblock">Communication-Efficient Edge AI: Algorithms and
Systems.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2002.09668Â [cs.IT]

</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Silva etÂ al<span id="bib.bib105.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Santiago Silva, Boris
Gutman, Eduardo Romero, PaulÂ M Thompson,
Andre Altmann, and Marco Lorenzi.
2019.

</span>
<span class="ltx_bibblock">Federated Learning in Distributed Medical
Databases: Meta-Analysis of Large-Scale Subcortical Brain Data.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Soest etÂ al<span id="bib.bib106.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Johan Soest, Chang Sun,
Ole Mussmann, Marco Puts,
Bob Berg, Alexander Malic,
Claudia Oppen, David Towend,
AndrÃ© Dekker, and Michel Dumontier.
2018.

</span>
<span class="ltx_bibblock">Using the Personal Health Train for Automated and
Privacy-Preserving Analytics on Vertically Partitioned Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib106.3.1" class="ltx_emph ltx_font_italic">Studies in health technology and
informatics</em> 247 (7
2018), 581â€“585.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sottile etÂ al<span id="bib.bib107.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
PeterÂ D Sottile, David
Albers, PeterÂ E DeWitt, Seth Russell,
JÂ N Stroh, DavidÂ P Kao,
Bonnie Adrian, MatthewÂ E Levine,
Ryan Mooney, Lenny Larchick,
JeanÂ S Kutner, MatthewÂ K Wynia,
JeffreyÂ J Glasheen, and TellenÂ D
Bennett. 2021.

</span>
<span class="ltx_bibblock">Real-time electronic health record mortality
prediction during the COVID-19 pandemic: a prospective cohort study.

</span>
<span class="ltx_bibblock"><em id="bib.bib107.3.1" class="ltx_emph ltx_font_italic">Journal of the American Medical Informatics
Association</em> 28 (10
2021).

</span>
<span class="ltx_bibblock">Issue 11.


<a target="_blank" href="https://doi.org/10.1093/jamia/ocab100" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1093/jamia/ocab100</a>

</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sutton etÂ al<span id="bib.bib108.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
ReedÂ Taylor Sutton, David
Pincock, DanielÂ C. Baumgart, DanielÂ C.
Sadowski, RichardÂ N Fedorak, and
KarenÂ I Kroeker. 2020.

</span>
<span class="ltx_bibblock">An overview of clinical decision support systems:
benefits, risks, and strategies for success.

</span>
<span class="ltx_bibblock"><em id="bib.bib108.3.1" class="ltx_emph ltx_font_italic">NPJ Digital Medicine</em> 3
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Szegedy etÂ al<span id="bib.bib109.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Christian Szegedy,
Wojciech Zaremba, Ilya Sutskever,
Joan Bruna, Dumitru Erhan,
Ian Goodfellow, and Rob Fergus.
2014.

</span>
<span class="ltx_bibblock">Intriguing properties of neural networks.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:1312.6199Â [cs.CV]

</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">TFL (2019)</span>
<span class="ltx_bibblock">
TFL. 2019.

</span>
<span class="ltx_bibblock">Tensorflow Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib110.1.1" class="ltx_emph ltx_font_italic">https://www.tensorflow.org/federated/federated
learning/</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Thwal
etÂ al<span id="bib.bib111.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
ChuÂ Myaet Thwal, Kyi
Thar, YeÂ Lin Tun, and ChoongÂ Seon
Hong. 2021.

</span>
<span class="ltx_bibblock">Attention on Personalized Clinical Decision Support
System: Federated Learning Approach.

</span>
<span class="ltx_bibblock"><em id="bib.bib111.3.1" class="ltx_emph ltx_font_italic">2021 IEEE International Conference on Big
Data and Smart Computing (BigComp)</em> (2021),
141â€“147.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vaid
etÂ al<span id="bib.bib112.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Akhil Vaid, SurajÂ K
Jaladanki, Jie Xu, Shelly Teng,
Arvind Kumar, Samuel Lee,
Sulaiman Somani, Ishan Paranjpe,
Jessica KÂ De Freitas, Tingyi Wanyan,
KippÂ W Johnson, Mesude Bicak,
Eyal Klang, YoungÂ Joon Kwon,
Anthony Costa, Shan Zhao,
Riccardo Miotto, AlexanderÂ W Charney,
Erwin BÃ¶ttinger, ZahiÂ A Fayad,
GirishÂ N Nadkarni, Fei Wang, and
BenjaminÂ S Glicksberg. 2021.

</span>
<span class="ltx_bibblock">Federated Learning of Electronic Health Records to
Improve Mortality Prediction in Hospitalized Patients With COVID-19: Machine
Learning Approach.

</span>
<span class="ltx_bibblock"><em id="bib.bib112.3.1" class="ltx_emph ltx_font_italic">JMIR Medical Informatics</em>
9 (1 2021).

</span>
<span class="ltx_bibblock">Issue 1.


<a target="_blank" href="https://doi.org/10.2196/24207" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.2196/24207</a>

</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Valdes etÂ al<span id="bib.bib113.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Gilmer Valdes, CharlesÂ B
SimoneÂ II, Josephine Chen, Alexander
Lin, SueÂ S Yom, AdamÂ J Pattison,
ColinÂ M Carpenter, and TimothyÂ D
Solberg. 2017.

</span>
<span class="ltx_bibblock">Clinical decision support of radiotherapy treatment
planning: A data-driven machine learning strategy for patient-specific
dosimetric decision making.

</span>
<span class="ltx_bibblock"><em id="bib.bib113.3.1" class="ltx_emph ltx_font_italic">Radiotherapy and Oncology</em>
125, 3 (2017),
392â€“397.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vepakomma etÂ al<span id="bib.bib114.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Praneeth Vepakomma,
Tristan Swedish, Ramesh Raskar,
Otkrist Gupta, and Abhimanyu Dubey.
2018.

</span>
<span class="ltx_bibblock">No Peek: A Survey of private distributed deep
learning.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang and
Preininger (2019)</span>
<span class="ltx_bibblock">
Fei Wang and Anita
Preininger. 2019.

</span>
<span class="ltx_bibblock">AI in Health: State of the Art, Challenges, and
Future Directions.

</span>
<span class="ltx_bibblock">, 016-026Â pages.

</span>
<span class="ltx_bibblock">
<a target="_blank" href="https://doi.org/10.1055/s-0039-1677908" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1055/s-0039-1677908</a>

</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al<span id="bib.bib116.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Hongyi Wang, Mikhail
Yurochkin, Yuekai Sun, Dimitris
Papailiopoulos, and Yasaman Khazaeni.
2020.

</span>
<span class="ltx_bibblock">Federated Learning with Matched Averaging.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al<span id="bib.bib117.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Kangkang Wang, Rajiv
Mathews, ChloÃ© Kiddon, Hubert Eichner,
FranÃ§oise Beaufays, and Daniel
Ramage. 2019.

</span>
<span class="ltx_bibblock">Federated Evaluation of On-device Personalization.

</span>
<span class="ltx_bibblock">(2019).

</span>
<span class="ltx_bibblock">arXiv:1910.10252Â [cs.LG]

</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu
etÂ al<span id="bib.bib118.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Qiong Wu, Xu Chen,
Zhi Zhou, and Junshan Zhang.
2020a.

</span>
<span class="ltx_bibblock">FedHome: Cloud-Edge based Personalized Federated
Learning for In-Home Health Monitoring.

</span>
<span class="ltx_bibblock"><em id="bib.bib118.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Mobile Computing</em>
(2020).

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/TMC.2020.3045266" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/TMC.2020.3045266</a>

</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu
etÂ al<span id="bib.bib119.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Xing Wu, Zhaowang Liang,
and Jianjia Wang. 2020b.

</span>
<span class="ltx_bibblock">FedMed: A Federated Learning Framework for Language
Modeling.

</span>
<span class="ltx_bibblock"><em id="bib.bib119.3.1" class="ltx_emph ltx_font_italic">Sensors (Basel, Switzerland)</em>
20 (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu etÂ al<span id="bib.bib120.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
X Wu, Hao Zheng,
Zuochao Dou, F Chen,
Jieren Deng, Xiang Chen,
Shengqian Xu, Guanmin Gao,
M Li, Z Wang, Yuhui
Xiao, Kang Xie, Shuang Wang, and
Huji Xu. 2021.

</span>
<span class="ltx_bibblock">A novel privacy-preserving federated genome-wide
association study framework and its application in identifying potential risk
variants in ankylosing spondylitis.

</span>
<span class="ltx_bibblock"><em id="bib.bib120.3.1" class="ltx_emph ltx_font_italic">Briefings in bioinformatics</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiong etÂ al<span id="bib.bib121.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Zhaoping Xiong, Ziqiang
Cheng, Chi Xu, Xinyuan Lin,
Xiaohong Liu, Dingyan Wang,
Xiaomin Luo, Y. Zhang,
Nan Qiao, M. Zheng, and
Hualiang Jiang. 2020.

</span>
<span class="ltx_bibblock">Facing small and biased data dilemma in drug
discovery with federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib121.3.1" class="ltx_emph ltx_font_italic">bioRxiv</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu
etÂ al<span id="bib.bib122.2.2.1" class="ltx_text">.</span> (2021c)</span>
<span class="ltx_bibblock">
Jie Xu, BenjaminÂ S.
Glicksberg, Chang Su, Peter Walker,
Jiang Bian, and Fei Wang.
2021c.

</span>
<span class="ltx_bibblock">Federated Learning for Healthcare Informatics.

</span>
<span class="ltx_bibblock"><em id="bib.bib122.3.1" class="ltx_emph ltx_font_italic">Journal of Healthcare Informatics Research</em>
5 (3 2021).

</span>
<span class="ltx_bibblock">Issue 1.


<a target="_blank" href="https://doi.org/10.1007/s41666-020-00082-4" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/s41666-020-00082-4</a>

</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu etÂ al<span id="bib.bib123.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Runhua Xu, Nathalie
Baracaldo, Yi Zhou, Ali Anwar,
James Joshi, and Heiko Ludwig.
2021a.

</span>
<span class="ltx_bibblock">FedV: Privacy-Preserving Federated Learning over
Vertically Partitioned Data.

</span>
<span class="ltx_bibblock">
</span>
<span class="ltx_bibblock">arXiv:2103.03918Â [cs.LG]

</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu etÂ al<span id="bib.bib124.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Runhua Xu, Nathalie
Baracaldo, Yi Zhou, Ali Anwar,
James Joshi, and Heiko Ludwig.
2021b.

</span>
<span class="ltx_bibblock">FedV: Privacy-Preserving Federated Learning over
Vertically Partitioned Data.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xue
etÂ al<span id="bib.bib125.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Zeyue Xue, Pan Zhou,
Zichuan Xu, Xiumin Wang,
Yulai Xie, Xiaofeng Ding, and
Shiping Wen. 2021.

</span>
<span class="ltx_bibblock">A Resource-Constrained and Privacy-Preserving
Edge-Computing-Enabled Clinical Decision System: A Federated Reinforcement
Learning Approach.

</span>
<span class="ltx_bibblock"><em id="bib.bib125.3.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>
8 (6 2021).

</span>
<span class="ltx_bibblock">Issue 11.


<a target="_blank" href="https://doi.org/10.1109/JIOT.2021.3057653" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/JIOT.2021.3057653</a>

</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yan
etÂ al<span id="bib.bib126.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Zengqiang Yan, Jeffry
Wicaksana, Zhiwei Wang, Xin Yang, and
Kwang-Ting Cheng. 2021.

</span>
<span class="ltx_bibblock">Variation-Aware Federated Learning With
Multi-Source Decentralized Medical Image Data.

</span>
<span class="ltx_bibblock"><em id="bib.bib126.3.1" class="ltx_emph ltx_font_italic">IEEE Journal of Biomedical and Health
Informatics</em> 25 (7 2021).

</span>
<span class="ltx_bibblock">Issue 7.


<a target="_blank" href="https://doi.org/10.1109/JBHI.2020.3040015" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/JBHI.2020.3040015</a>

</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang etÂ al<span id="bib.bib127.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Dong Yang, Ziyue Xu,
Wenqi Li, Andriy Myronenko,
HolgerÂ R. Roth, Stephanie Harmon,
Sheng Xu, Baris Turkbey,
Evrim Turkbey, Xiaosong Wang,
Wentao Zhu, Gianpaolo Carrafiello,
Francesca Patella, Maurizio Cariati,
Hirofumi Obinata, Hitoshi Mori,
Kaku Tamura, Peng An,
BradfordÂ J. Wood, and Daguang Xu.
2021.

</span>
<span class="ltx_bibblock">Federated semi-supervised learning for COVID region
segmentation in chest CT using multi-national data from China, Italy, Japan.

</span>
<span class="ltx_bibblock"><em id="bib.bib127.3.1" class="ltx_emph ltx_font_italic">Medical Image Analysis</em>
70 (5 2021).

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1016/j.media.2021.101992" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1016/j.media.2021.101992</a>

</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang
etÂ al<span id="bib.bib128.2.2.1" class="ltx_text">.</span> (2019a)</span>
<span class="ltx_bibblock">
Qiang Yang, Yang Liu,
Tianjian Chen, and Yongxin Tong.
2019a.

</span>
<span class="ltx_bibblock">Federated Machine Learning: Concept and
Applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib128.3.1" class="ltx_emph ltx_font_italic">ACM Trans. Intell. Syst. Technol.</em>
10, 2, Article 12
(Jan. 2019), 19Â pages.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1145/3298981" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1145/3298981</a>

</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang
etÂ al<span id="bib.bib129.2.2.1" class="ltx_text">.</span> (2019b)</span>
<span class="ltx_bibblock">
Shengwen Yang, Bing Ren,
Xuhui Zhou, and Liping Liu.
2019b.

</span>
<span class="ltx_bibblock">Parallel Distributed Logistic Regression for
Vertical Federated Learning without Third-Party Coordinator.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang etÂ al<span id="bib.bib130.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Timothy Yang, Galen
Andrew, Hubert Eichner, Haicheng Sun,
Wei Li, Nicholas Kong,
Daniel Ramage, and FranÃ§oise
Beaufays. 2018.

</span>
<span class="ltx_bibblock">Applied Federated Learning: Improving Google
Keyboard Query Suggestions.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yigzaw etÂ al<span id="bib.bib131.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
K.Â Y. Yigzaw, A.
Budrionis, Luis Marco-Ruiz, TorjeÂ Dahle
Henriksen, P. Halvorsen, and J.
Bellika. 2020.

</span>
<span class="ltx_bibblock">Privacy-preserving architecture for providing
feedback to clinicians on their clinical performance.

</span>
<span class="ltx_bibblock"><em id="bib.bib131.3.1" class="ltx_emph ltx_font_italic">BMC Medical Informatics and Decision Making</em>
20 (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yigzaw
etÂ al<span id="bib.bib132.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
KassayeÂ Yitbarek Yigzaw,
Antonis Michalas, and JohanÂ Gustav
Bellika. 2017.

</span>
<span class="ltx_bibblock">Secure and scalable deduplication of horizontally
partitioned health data for privacy-preserving distributed statistical
computation.

</span>
<span class="ltx_bibblock"><em id="bib.bib132.3.1" class="ltx_emph ltx_font_italic">BMC Medical Informatics and Decision Making</em>
17 (12 2017).

</span>
<span class="ltx_bibblock">Issue 1.


<a target="_blank" href="https://doi.org/10.1186/s12911-016-0389-x" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1186/s12911-016-0389-x</a>

</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu
etÂ al<span id="bib.bib133.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Tao Yu, Eugene
Bagdasaryan, and Vitaly Shmatikov.
2020.

</span>
<span class="ltx_bibblock">Salvaging Federated Learning by Local Adaptation.

</span>
<span class="ltx_bibblock">(2020).

</span>
<span class="ltx_bibblock">arXiv:2002.04758Â [cs.LG]

</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao
etÂ al<span id="bib.bib134.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Lingchen Zhao, Lihao Ni,
Shengshan Hu, Yaniiao Chen,
Pan Zhou, Fu Xiao, and
Libing Wu. 2018.

</span>
<span class="ltx_bibblock">InPrivate Digging: Enabling Tree-based Distributed
Data Mining with Differential Privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib134.3.1" class="ltx_emph ltx_font_italic">IEEE INFOCOM 2018 - IEEE Conference on
Computer Communications</em>.

</span>
<span class="ltx_bibblock">

<a target="_blank" href="https://doi.org/10.1109/INFOCOM.2018.8486352" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1109/INFOCOM.2018.8486352</a>

</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng
etÂ al<span id="bib.bib135.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Zibin Zheng, Shaoan Xie,
HongÂ Ning Dai, Xiangping Chen, and
Huaimin Wang. 2018.

</span>
<span class="ltx_bibblock">Blockchain challenges and opportunities: a survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib135.3.1" class="ltx_emph ltx_font_italic">International Journal of Web and Grid
Services</em> 14 (2018).

</span>
<span class="ltx_bibblock">Issue 4.


<a target="_blank" href="https://doi.org/10.1504/IJWGS.2018.095647" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1504/IJWGS.2018.095647</a>

</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu
etÂ al<span id="bib.bib136.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Hangyu Zhu, Haoyu Zhang,
and Yaochu Jin. 2020.

</span>
<span class="ltx_bibblock">From Federated Learning to Federated Neural
Architecture Search: A Survey.

</span>
<span class="ltx_bibblock">(2020).

</span>
<span class="ltx_bibblock">arXiv:2009.05868Â [cs.DC]

</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu
etÂ al<span id="bib.bib137.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Hangyu Zhu, Haoyu Zhang,
and Yaochu Jin. 2021.

</span>
<span class="ltx_bibblock">From federated learning to federated neural
architecture search: a survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib137.3.1" class="ltx_emph ltx_font_italic">Complex &amp; Intelligent Systems</em>
7 (4 2021).

</span>
<span class="ltx_bibblock">Issue 2.


<a target="_blank" href="https://doi.org/10.1007/s40747-020-00247-z" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://doi.org/10.1007/s40747-020-00247-z</a>

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2211.07892" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2211.07893" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2211.07893">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2211.07893" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2211.07894" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar 14 06:44:18 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
