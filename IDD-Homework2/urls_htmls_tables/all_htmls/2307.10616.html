<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2307.10616] Heterogeneous Federated Learning: State-of-the-art and Research Challenges</title><meta property="og:description" content="Federated learning (FL) has drawn increasing attention owing to its potential use in large-scale industrial applications. Existing federated learning works mainly focus on model homogeneous settings. However, practical…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Heterogeneous Federated Learning: State-of-the-art and Research Challenges">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Heterogeneous Federated Learning: State-of-the-art and Research Challenges">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2307.10616">

<!--Generated on Wed Feb 28 17:27:49 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Survey,  Federated Learning,  Trustworthy AI">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div id="p1" class="ltx_para">
<span id="p1.1" class="ltx_ERROR undefined">\setcopyright</span>
<p id="p1.2" class="ltx_p">acmcopyright

<span id="p1.2.1" class="ltx_ERROR undefined">\acmYear</span>2022
<span id="p1.2.2" class="ltx_ERROR undefined">\acmDOI</span>XXXXXXX.XXXXXXX
<span id="p1.2.3" class="ltx_ERROR undefined">\acmPrice</span>15.00
<span id="p1.2.4" class="ltx_ERROR undefined">\acmISBN</span>978-1-4503-XXXX-X/18/06</p>
</div>
<h1 class="ltx_title ltx_title_document">Heterogeneous Federated Learning: State-of-the-art and Research Challenges</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Mang Ye
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:yemang@whu.edu.cn">yemang@whu.edu.cn</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xiuwen Fang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:fangxiuwen@whu.edu.cn">fangxiuwen@whu.edu.cn</a>
</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Bo Du
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:dubo@whu.edu.cn">dubo@whu.edu.cn</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id1.1.id1" class="ltx_ERROR undefined">\institution</span>School of Computer Science, Wuhan University
<span id="id2.2.id2" class="ltx_ERROR undefined">\city</span>Wuhan
<span id="id3.3.id3" class="ltx_ERROR undefined">\country</span>China

</span></span></span>
<span class="ltx_author_before">, </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Pong C. Yuen
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:pcyuen@comp.hkbu.edu.hk">pcyuen@comp.hkbu.edu.hk</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id4.1.id1" class="ltx_ERROR undefined">\institution</span>Department of Computer Science, Hong Kong Baptist University
<span id="id5.2.id2" class="ltx_ERROR undefined">\city</span>Hong Kong
<span id="id6.3.id3" class="ltx_ERROR undefined">\country</span>China

</span></span></span>
<span class="ltx_author_before"> and </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Dacheng Tao
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_email"><a href="mailto:dacheng.tao@gmail.com">dacheng.tao@gmail.com</a>
</span>
<span class="ltx_contact ltx_role_affiliation"><span id="id7.1.id1" class="ltx_ERROR undefined">\institution</span>The University of Sydney
<span id="id8.2.id2" class="ltx_ERROR undefined">\country</span>Australia

</span></span></span>
</div>
<div class="ltx_dates">(2022)</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract.</h6>
<p id="id9.id1" class="ltx_p">Federated learning (FL) has drawn increasing attention owing to its potential use in large-scale industrial applications. Existing federated learning works mainly focus on model homogeneous settings. However, practical federated learning typically faces the heterogeneity of data distributions, model architectures, network environments, and hardware devices among participant clients. Heterogeneous Federated Learning (HFL) is much more challenging, and corresponding solutions are diverse and complex. Therefore, a systematic survey on this topic about the research challenges and state-of-the-art is essential. In this survey, we firstly summarize the various research challenges in HFL from five aspects: statistical heterogeneity, model heterogeneity, communication heterogeneity, device heterogeneity, and additional challenges. In addition, recent advances in HFL are reviewed and a new taxonomy of existing HFL methods is proposed with an in-depth analysis of their pros and cons. We classify existing methods from three different levels according to the HFL procedure: data-level, model-level, and server-level. Finally, several critical and promising future research directions in HFL are discussed, which may facilitate further developments in this field. A periodically updated collection on HFL is available at <a target="_blank" href="https://github.com/marswhu/HFL_Survey" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/marswhu/HFL_Survey</a>.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Key words and phrases: </h6>Survey, Federated Learning, Trustworthy AI
</div>
<div id="p2" class="ltx_para">
<span id="p2.1" class="ltx_ERROR undefined">{CCSXML}</span>
<p id="p2.2" class="ltx_p">&lt;ccs2012&gt;
&lt;concept&gt;
&lt;concept_id&gt;10010520.10010553.10010562&lt;/concept_id&gt;
&lt;concept_desc&gt;Computer systems organization Embedded systems&lt;/concept_desc&gt;
&lt;concept_significance&gt;500&lt;/concept_significance&gt;
&lt;/concept&gt;
&lt;concept&gt;
&lt;concept_id&gt;10010520.10010575.10010755&lt;/concept_id&gt;
&lt;concept_desc&gt;Computer systems organization Redundancy&lt;/concept_desc&gt;
&lt;concept_significance&gt;300&lt;/concept_significance&gt;
&lt;/concept&gt;
&lt;concept&gt;
&lt;concept_id&gt;10010520.10010553.10010554&lt;/concept_id&gt;
&lt;concept_desc&gt;Computer systems organization Robotics&lt;/concept_desc&gt;
&lt;concept_significance&gt;100&lt;/concept_significance&gt;
&lt;/concept&gt;
&lt;concept&gt;
&lt;concept_id&gt;10003033.10003083.10003095&lt;/concept_id&gt;
&lt;concept_desc&gt;Networks Network reliability&lt;/concept_desc&gt;
&lt;concept_significance&gt;100&lt;/concept_significance&gt;
&lt;/concept&gt;
&lt;/ccs2012&gt;</p>
</div>
<div id="p3" class="ltx_para">
<span id="p3.1" class="ltx_ERROR undefined">\ccsdesc</span>
<p id="p3.2" class="ltx_p">[500]General and reference Surveys and overviews
<span id="p3.2.1" class="ltx_ERROR undefined">\ccsdesc</span>[500]Security and privacy Privacy-preserving protocols
<span id="p3.2.2" class="ltx_ERROR undefined">\ccsdesc</span>[300]Computing methodologies Computer vision</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1. </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">With the popularization of smartphones, wearable devices, mobile networks, etc., edge devices have become ubiquitous in modern society. An effective method to better utilize the abundant private data in edge devices without compromising privacy is federated learning, which aims to collaboratively train machine learning models while keeping the data decentralized <cite class="ltx_cite ltx_citemacro_cite">Yang et al<span class="ltx_text">.</span> (<a href="#bib.bib227" title="" class="ltx_ref">2019</a>)</cite>, <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">i.e.</span>, following the data-stay-local policy. The participating devices in the federated learning system are regarded as different clients. Federated learning is a distributed machine learning framework with secure encryption technology, which enables multiple institutions to conduct joint machine learning modeling under the requirement of protecting data privacy <cite class="ltx_cite ltx_citemacro_cite">Gürsoy et al<span class="ltx_text">.</span> (<a href="#bib.bib68" title="" class="ltx_ref">2022</a>)</cite>. Federated learning has drawn increasing attention in both academia and industry owing to its potential utility in large-scale applications <cite class="ltx_cite ltx_citemacro_cite">Fang and Ye (<a href="#bib.bib49" title="" class="ltx_ref">2022</a>); Huang et al<span class="ltx_text">.</span> (<a href="#bib.bib86" title="" class="ltx_ref">2022b</a>); Shao et al<span class="ltx_text">.</span> (<a href="#bib.bib186" title="" class="ltx_ref">2022</a>)</cite>, which has been widely explored in the fields of healthcare <cite class="ltx_cite ltx_citemacro_cite">Dayan et al<span class="ltx_text">.</span> (<a href="#bib.bib40" title="" class="ltx_ref">2021</a>); Wu et al<span class="ltx_text">.</span> (<a href="#bib.bib215" title="" class="ltx_ref">2022b</a>); Sadilek et al<span class="ltx_text">.</span> (<a href="#bib.bib179" title="" class="ltx_ref">2021</a>)</cite>, medical analysis <cite class="ltx_cite ltx_citemacro_cite">Kaissis et al<span class="ltx_text">.</span> (<a href="#bib.bib98" title="" class="ltx_ref">2021</a>); Froelicher et al<span class="ltx_text">.</span> (<a href="#bib.bib55" title="" class="ltx_ref">2021</a>)</cite>, and data security <cite class="ltx_cite ltx_citemacro_cite">Usynin et al<span class="ltx_text">.</span> (<a href="#bib.bib206" title="" class="ltx_ref">2021</a>)</cite>, etc.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Despite the great success in homogeneous federated learning, where it heavily relies on the assumption that all the participants share the same network structure and possess similar data distributions <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib124" title="" class="ltx_ref">2020c</a>)</cite>. However, in practical large-scale situations, there may be considerable differences between data distributions, model structures, communication networks, and system edge devices, which make it challenging to realize federated collaboration. The federated learning associated with these situations is denoted as heterogeneous federated learning, where this heterogeneity can be categorized into four classes according to the federated learning process: statistical heterogeneity, model heterogeneity, communication heterogeneity, and device heterogeneity. These are shown in Fig. <a href="#S1.F1" title="Figure 1 ‣ 1. Introduction ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and detailed as follows.
1) <span id="S1.p2.1.1" class="ltx_text ltx_font_italic">Statistical heterogeneity</span>: the collected data in different participants may be Non-Independent Identically Distributed (Non-IID) <cite class="ltx_cite ltx_citemacro_cite">Zhu et al<span class="ltx_text">.</span> (<a href="#bib.bib255" title="" class="ltx_ref">2021b</a>)</cite> or unbalanced, resulting in inconsistent update optimization directions of participants. Original methods would fail in biased collaboration. Therefore, many recent approaches
<cite class="ltx_cite ltx_citemacro_cite">Qu et al<span class="ltx_text">.</span> (<a href="#bib.bib174" title="" class="ltx_ref">2022b</a>); Tang et al<span class="ltx_text">.</span> (<a href="#bib.bib203" title="" class="ltx_ref">2022c</a>); Qu et al<span class="ltx_text">.</span> (<a href="#bib.bib176" title="" class="ltx_ref">2022a</a>); Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib250" title="" class="ltx_ref">2022b</a>)</cite>
attempt to tackle this challenge from various aspects.
2) <span id="S1.p2.1.2" class="ltx_text ltx_font_italic">Model heterogeneity</span>: Clients may have different tasks and specific requirements. Consequently, each client may expect to design its local model independently <cite class="ltx_cite ltx_citemacro_cite">Wu et al<span class="ltx_text">.</span> (<a href="#bib.bib217" title="" class="ltx_ref">2020a</a>); Makhija et al<span class="ltx_text">.</span> (<a href="#bib.bib151" title="" class="ltx_ref">2022</a>)</cite>, resulting in knowledge transfer barriers among heterogeneous participants, where the widely-used model aggregation or gradients operation cannot be applied.
3) <span id="S1.p2.1.3" class="ltx_text ltx_font_italic">Communication heterogeneity</span>: Considering that clients may be deployed under varying network environments <cite class="ltx_cite ltx_citemacro_cite">Sattler et al<span class="ltx_text">.</span> (<a href="#bib.bib183" title="" class="ltx_ref">2019</a>)</cite>, this brings in communication inconsistency and unsynchronization, which is also ignored in existing works. This challenge might affect the learning efficiency, especially when the client number is large, which greatly limits the application in large-scale industry scenarios.
4) <span id="S1.p2.1.4" class="ltx_text ltx_font_italic">Device heterogeneity</span>: The storage and computation capabilities of the devices for different participants may be diverse <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib124" title="" class="ltx_ref">2020c</a>)</cite>, which may cause faults and inactivation of some participating nodes, <span id="S1.p2.1.5" class="ltx_text ltx_font_italic">i.e.</span> stragglers. There are several methods <cite class="ltx_cite ltx_citemacro_cite">Hong et al<span class="ltx_text">.</span> (<a href="#bib.bib75" title="" class="ltx_ref">2022</a>); Yoon et al<span class="ltx_text">.</span> (<a href="#bib.bib234" title="" class="ltx_ref">2022</a>); Marfoq et al<span class="ltx_text">.</span> (<a href="#bib.bib154" title="" class="ltx_ref">2022</a>)</cite>
developed to deal with this challenge at different stages.
<span id="S1.p2.1.6" class="ltx_text" style="color:#000000;">Compared with traditional homogeneous federated learning environments, heterogeneous federated learning has several benefits. First and foremost, it is more flexible and adaptable to the diverse and dynamic scenarios of different clients, which may have inconsistent data distributions, model structures, communication networks, and hardware capabilities. Second, it takes full advantage of the complementary information and knowledge among heterogeneous clients, thus improving learning performance and robustness under complex and uncertain environments. Finally, it can also handle heterogeneous tasks, that is, different clients can pursue different learning tasks or objectives according to their own needs, thus improving the adaptability and flexibility of the model.</span></p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2307.10616/assets/x1.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="179" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1. </span><span id="S1.F1.2.1" class="ltx_text" style="font-size:90%;color:#000000;">Schematic of heterogeneous federated learning. The figure includes cloud, fog nodes, and IoT edge devices, which constitute the multi-layer heterogeneous federated learning framework. Different devices represent participating clients with heterogeneous local models and Non-IID private data. Each client cannot access the private data from others. The clients upload model-related information to the server, and the server aggregates and broadcasts the knowledge.</span></figcaption>
</figure>
<figure id="S1.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 1. </span><span id="S1.T1.20.1" class="ltx_text" style="color:#000000;"> Related federated learning survey.</span></figcaption>
<table id="S1.T1.17" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S1.T1.3.3" class="ltx_tr">
<td id="S1.T1.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:65.4pt;"><span id="S1.T1.1.1.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S1.T1.1.1.1.1.p1" class="ltx_para ltx_noindent">
<span id="S1.T1.1.1.1.1.p1.1" class="ltx_p"><span id="S1.T1.1.1.1.1.p1.1.1" class="ltx_text"></span><span id="S1.T1.1.1.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S1.T1.1.1.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S1.T1.1.1.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.1.1.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S1.T1.1.1.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Surveys</span></span>
</span></span><span id="S1.T1.1.1.1.1.p1.1.4" class="ltx_text"></span><span id="S1.T1.1.1.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S1.T1.2.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:165.0pt;"><span id="S1.T1.2.2.2.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S1.T1.2.2.2.1.p1" class="ltx_para ltx_noindent">
<span id="S1.T1.2.2.2.1.p1.1" class="ltx_p"><span id="S1.T1.2.2.2.1.p1.1.1" class="ltx_text"></span><span id="S1.T1.2.2.2.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S1.T1.2.2.2.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S1.T1.2.2.2.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.2.2.2.1.p1.1.3.1.1" class="ltx_tr">
<span id="S1.T1.2.2.2.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Key Contributions</span></span>
</span></span><span id="S1.T1.2.2.2.1.p1.1.4" class="ltx_text"></span><span id="S1.T1.2.2.2.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S1.T1.3.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:167.9pt;"><span id="S1.T1.3.3.3.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S1.T1.3.3.3.1.p1" class="ltx_para ltx_noindent">
<span id="S1.T1.3.3.3.1.p1.1" class="ltx_p"><span id="S1.T1.3.3.3.1.p1.1.1" class="ltx_text"></span><span id="S1.T1.3.3.3.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S1.T1.3.3.3.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S1.T1.3.3.3.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.3.3.3.1.p1.1.3.1.1" class="ltx_tr">
<span id="S1.T1.3.3.3.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Differences from Our Survey</span></span>
</span></span><span id="S1.T1.3.3.3.1.p1.1.4" class="ltx_text"></span><span id="S1.T1.3.3.3.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
</tr>
<tr id="S1.T1.4.4" class="ltx_tr">
<td id="S1.T1.4.4.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:65.4pt;"><span id="S1.T1.4.4.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S1.T1.4.4.1.1.p1" class="ltx_para ltx_noindent">
<span id="S1.T1.4.4.1.1.p1.1" class="ltx_p"><span id="S1.T1.4.4.1.1.p1.1.1" class="ltx_text"></span><span id="S1.T1.4.4.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S1.T1.4.4.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S1.T1.4.4.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.4.4.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S1.T1.4.4.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Kairouz <span id="S1.T1.4.4.1.1.p1.1.3.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Kairouz et al<span class="ltx_text">.</span> (<a href="#bib.bib97" title="" class="ltx_ref">2019</a>)</cite></span></span>
</span></span><span id="S1.T1.4.4.1.1.p1.1.4" class="ltx_text"></span><span id="S1.T1.4.4.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S1.T1.4.4.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:165.0pt;">
<span id="S1.T1.4.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.4.4.2.1.1" class="ltx_p"><span id="S1.T1.4.4.2.1.1.1" class="ltx_text" style="font-size:90%;">They discuss recent advances in federated learning and provide a survey of open problems and challenges.</span></span>
</span>
</td>
<td id="S1.T1.4.4.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:167.9pt;">
<span id="S1.T1.4.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.4.4.3.1.1" class="ltx_p"><span id="S1.T1.4.4.3.1.1.1" class="ltx_text" style="font-size:90%;">This work comprehensively demonstrates the advance in federated learning, but lacks the fine-grained classification of existing methods.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.5.5" class="ltx_tr">
<td id="S1.T1.5.5.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:65.4pt;"><span id="S1.T1.5.5.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S1.T1.5.5.1.1.p1" class="ltx_para ltx_noindent">
<span id="S1.T1.5.5.1.1.p1.1" class="ltx_p"><span id="S1.T1.5.5.1.1.p1.1.1" class="ltx_text"></span><span id="S1.T1.5.5.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S1.T1.5.5.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S1.T1.5.5.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.5.5.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S1.T1.5.5.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Li <span id="S1.T1.5.5.1.1.p1.1.3.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib124" title="" class="ltx_ref">2020c</a>)</cite></span></span>
</span></span><span id="S1.T1.5.5.1.1.p1.1.4" class="ltx_text"></span><span id="S1.T1.5.5.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S1.T1.5.5.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:165.0pt;">
<span id="S1.T1.5.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.5.5.2.1.1" class="ltx_p"><span id="S1.T1.5.5.2.1.1.1" class="ltx_text" style="font-size:90%;">They discuss the challenges of federated learning from the perspectives of efficiency, heterogeneity and privacy, and list several future directions.</span></span>
</span>
</td>
<td id="S1.T1.5.5.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:167.9pt;">
<span id="S1.T1.5.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.5.5.3.1.1" class="ltx_p"><span id="S1.T1.5.5.3.1.1.1" class="ltx_text" style="font-size:90%;">Our survey focuses on the challenges of heterogeneity and provides a more comprehensive and detailed classification of heterogeneity.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.6.6" class="ltx_tr">
<td id="S1.T1.6.6.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:65.4pt;"><span id="S1.T1.6.6.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S1.T1.6.6.1.1.p1" class="ltx_para ltx_noindent">
<span id="S1.T1.6.6.1.1.p1.1" class="ltx_p"><span id="S1.T1.6.6.1.1.p1.1.1" class="ltx_text"></span><span id="S1.T1.6.6.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S1.T1.6.6.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S1.T1.6.6.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.6.6.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S1.T1.6.6.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Wahab <span id="S1.T1.6.6.1.1.p1.1.3.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Wahab et al<span class="ltx_text">.</span> (<a href="#bib.bib209" title="" class="ltx_ref">2021</a>)</cite></span></span>
</span></span><span id="S1.T1.6.6.1.1.p1.1.4" class="ltx_text"></span><span id="S1.T1.6.6.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S1.T1.6.6.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:165.0pt;">
<span id="S1.T1.6.6.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.6.6.2.1.1" class="ltx_p"><span id="S1.T1.6.6.2.1.1.1" class="ltx_text" style="font-size:90%;">They provide a fine-grained classification scheme of existing challenges and approaches.</span></span>
</span>
</td>
<td id="S1.T1.6.6.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:167.9pt;">
<span id="S1.T1.6.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.6.6.3.1.1" class="ltx_p"><span id="S1.T1.6.6.3.1.1.1" class="ltx_text" style="font-size:90%;">Our survey focuses on the challenges of heterogeneity and provides a more comprehensive classification of heterogeneity.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.7.7" class="ltx_tr">
<td id="S1.T1.7.7.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:65.4pt;"><span id="S1.T1.7.7.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S1.T1.7.7.1.1.p1" class="ltx_para ltx_noindent">
<span id="S1.T1.7.7.1.1.p1.1" class="ltx_p"><span id="S1.T1.7.7.1.1.p1.1.1" class="ltx_text"></span><span id="S1.T1.7.7.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S1.T1.7.7.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S1.T1.7.7.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.7.7.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S1.T1.7.7.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Li <span id="S1.T1.7.7.1.1.p1.1.3.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib120" title="" class="ltx_ref">2021g</a>)</cite></span></span>
</span></span><span id="S1.T1.7.7.1.1.p1.1.4" class="ltx_text"></span><span id="S1.T1.7.7.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S1.T1.7.7.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:165.0pt;">
<span id="S1.T1.7.7.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.7.7.2.1.1" class="ltx_p"><span id="S1.T1.7.7.2.1.1.1" class="ltx_text" style="font-size:90%;">They provide a comprehensive analysis on federated learning from systems perspective, including system components, taxonomy, summary, design, and vision.</span></span>
</span>
</td>
<td id="S1.T1.7.7.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:167.9pt;">
<span id="S1.T1.7.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.7.7.3.1.1" class="ltx_p"><span id="S1.T1.7.7.3.1.1.1" class="ltx_text" style="font-size:90%;">The taxonomy proposed in this work is not based on a uniform standard.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.8.8" class="ltx_tr">
<td id="S1.T1.8.8.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:65.4pt;"><span id="S1.T1.8.8.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S1.T1.8.8.1.1.p1" class="ltx_para ltx_noindent">
<span id="S1.T1.8.8.1.1.p1.1" class="ltx_p"><span id="S1.T1.8.8.1.1.p1.1.1" class="ltx_text"></span><span id="S1.T1.8.8.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S1.T1.8.8.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S1.T1.8.8.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.8.8.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S1.T1.8.8.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Lim <span id="S1.T1.8.8.1.1.p1.1.3.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Lim et al<span class="ltx_text">.</span> (<a href="#bib.bib130" title="" class="ltx_ref">2020</a>)</cite></span></span>
</span></span><span id="S1.T1.8.8.1.1.p1.1.4" class="ltx_text"></span><span id="S1.T1.8.8.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S1.T1.8.8.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:165.0pt;">
<span id="S1.T1.8.8.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.8.8.2.1.1" class="ltx_p"><span id="S1.T1.8.8.2.1.1.1" class="ltx_text" style="font-size:90%;">They survey federated learning in mobile edge networks.</span></span>
</span>
</td>
<td id="S1.T1.8.8.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:167.9pt;">
<span id="S1.T1.8.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.8.8.3.1.1" class="ltx_p"><span id="S1.T1.8.8.3.1.1.1" class="ltx_text" style="font-size:90%;">This work is based on federated learning in mobile edge network optimization, while our work investigates from a more general perspective.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.9.9" class="ltx_tr">
<td id="S1.T1.9.9.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:65.4pt;"><span id="S1.T1.9.9.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S1.T1.9.9.1.1.p1" class="ltx_para ltx_noindent">
<span id="S1.T1.9.9.1.1.p1.1" class="ltx_p"><span id="S1.T1.9.9.1.1.p1.1.1" class="ltx_text"></span><span id="S1.T1.9.9.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S1.T1.9.9.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S1.T1.9.9.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.9.9.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S1.T1.9.9.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Niknam <span id="S1.T1.9.9.1.1.p1.1.3.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Niknam et al<span class="ltx_text">.</span> (<a href="#bib.bib166" title="" class="ltx_ref">2020</a>)</cite></span></span>
</span></span><span id="S1.T1.9.9.1.1.p1.1.4" class="ltx_text"></span><span id="S1.T1.9.9.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S1.T1.9.9.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:165.0pt;">
<span id="S1.T1.9.9.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.9.9.2.1.1" class="ltx_p"><span id="S1.T1.9.9.2.1.1.1" class="ltx_text" style="font-size:90%;">They discuss the applications and challenges of federated learning in wireless communication environments.</span></span>
</span>
</td>
<td id="S1.T1.9.9.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:167.9pt;">
<span id="S1.T1.9.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.9.9.3.1.1" class="ltx_p"><span id="S1.T1.9.9.3.1.1.1" class="ltx_text" style="font-size:90%;">This work discusses applications of federated learning in wireless communication, while we surveys federated learning from a more general perspective.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.10.10" class="ltx_tr">
<td id="S1.T1.10.10.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:65.4pt;"><span id="S1.T1.10.10.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S1.T1.10.10.1.1.p1" class="ltx_para ltx_noindent">
<span id="S1.T1.10.10.1.1.p1.1" class="ltx_p"><span id="S1.T1.10.10.1.1.p1.1.1" class="ltx_text"></span><span id="S1.T1.10.10.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S1.T1.10.10.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S1.T1.10.10.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.10.10.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S1.T1.10.10.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Khan <span id="S1.T1.10.10.1.1.p1.1.3.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Khan et al<span class="ltx_text">.</span> (<a href="#bib.bib101" title="" class="ltx_ref">2021</a>)</cite></span></span>
</span></span><span id="S1.T1.10.10.1.1.p1.1.4" class="ltx_text"></span><span id="S1.T1.10.10.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S1.T1.10.10.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:165.0pt;">
<span id="S1.T1.10.10.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.10.10.2.1.1" class="ltx_p"><span id="S1.T1.10.10.2.1.1.1" class="ltx_text" style="font-size:90%;">They present advances in federated learning for IoT applications and provide a taxonomy using various parameters.</span></span>
</span>
</td>
<td id="S1.T1.10.10.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:167.9pt;">
<span id="S1.T1.10.10.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.10.10.3.1.1" class="ltx_p"><span id="S1.T1.10.10.3.1.1.1" class="ltx_text" style="font-size:90%;">This work explores federated learning for IoT networks and identifies issues of robustness, privacy and communication cost, while our work targets heterogeneity issues</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.11.11" class="ltx_tr">
<td id="S1.T1.11.11.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:65.4pt;"><span id="S1.T1.11.11.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S1.T1.11.11.1.1.p1" class="ltx_para ltx_noindent">
<span id="S1.T1.11.11.1.1.p1.1" class="ltx_p"><span id="S1.T1.11.11.1.1.p1.1.1" class="ltx_text"></span><span id="S1.T1.11.11.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S1.T1.11.11.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S1.T1.11.11.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.11.11.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S1.T1.11.11.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Nguyen <span id="S1.T1.11.11.1.1.p1.1.3.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Nguyen et al<span class="ltx_text">.</span> (<a href="#bib.bib163" title="" class="ltx_ref">2021</a>)</cite></span></span>
</span></span><span id="S1.T1.11.11.1.1.p1.1.4" class="ltx_text"></span><span id="S1.T1.11.11.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S1.T1.11.11.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:165.0pt;">
<span id="S1.T1.11.11.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.11.11.2.1.1" class="ltx_p"><span id="S1.T1.11.11.2.1.1.1" class="ltx_text" style="font-size:90%;">They survey and analyze the services applications of federated learning in IoT networks.</span></span>
</span>
</td>
<td id="S1.T1.11.11.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:167.9pt;">
<span id="S1.T1.11.11.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.11.11.3.1.1" class="ltx_p"><span id="S1.T1.11.11.3.1.1.1" class="ltx_text" style="font-size:90%;">This work focuses on the characteristics and requirements of IoT networks, rather than covering all possible federated learning scenarios.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.12.12" class="ltx_tr">
<td id="S1.T1.12.12.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:65.4pt;"><span id="S1.T1.12.12.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S1.T1.12.12.1.1.p1" class="ltx_para ltx_noindent">
<span id="S1.T1.12.12.1.1.p1.1" class="ltx_p"><span id="S1.T1.12.12.1.1.p1.1.1" class="ltx_text"></span><span id="S1.T1.12.12.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S1.T1.12.12.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S1.T1.12.12.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.12.12.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S1.T1.12.12.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Yang <span id="S1.T1.12.12.1.1.p1.1.3.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Yang et al<span class="ltx_text">.</span> (<a href="#bib.bib227" title="" class="ltx_ref">2019</a>)</cite></span></span>
</span></span><span id="S1.T1.12.12.1.1.p1.1.4" class="ltx_text"></span><span id="S1.T1.12.12.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S1.T1.12.12.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:165.0pt;">
<span id="S1.T1.12.12.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.12.12.2.1.1" class="ltx_p"><span id="S1.T1.12.12.2.1.1.1" class="ltx_text" style="font-size:90%;">They divide federated learning into three categories according to the data distribution characteristics.</span></span>
</span>
</td>
<td id="S1.T1.12.12.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:167.9pt;">
<span id="S1.T1.12.12.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.12.12.3.1.1" class="ltx_p"><span id="S1.T1.12.12.3.1.1.1" class="ltx_text" style="font-size:90%;">This work provides an overview of federated learning but lacks a detailed classification and summary of existing methods.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.13.13" class="ltx_tr">
<td id="S1.T1.13.13.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:65.4pt;"><span id="S1.T1.13.13.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S1.T1.13.13.1.1.p1" class="ltx_para ltx_noindent">
<span id="S1.T1.13.13.1.1.p1.1" class="ltx_p"><span id="S1.T1.13.13.1.1.p1.1.1" class="ltx_text"></span><span id="S1.T1.13.13.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S1.T1.13.13.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S1.T1.13.13.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.13.13.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S1.T1.13.13.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Gao <span id="S1.T1.13.13.1.1.p1.1.3.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Gao et al<span class="ltx_text">.</span> (<a href="#bib.bib59" title="" class="ltx_ref">2022</a>)</cite></span></span>
</span></span><span id="S1.T1.13.13.1.1.p1.1.4" class="ltx_text"></span><span id="S1.T1.13.13.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S1.T1.13.13.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:165.0pt;">
<span id="S1.T1.13.13.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.13.13.2.1.1" class="ltx_p"><span id="S1.T1.13.13.2.1.1.1" class="ltx_text" style="font-size:90%;">They investigate the domain of heterogeneous FL in terms of data space, statistical, system, and model heterogeneity.</span></span>
</span>
</td>
<td id="S1.T1.13.13.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:167.9pt;">
<span id="S1.T1.13.13.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.13.13.3.1.1" class="ltx_p"><span id="S1.T1.13.13.3.1.1.1" class="ltx_text" style="font-size:90%;">This work classifies existing methods based on problem settings and learning objectives, while our survey classifies methods based on specific techniques.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.14.14" class="ltx_tr">
<td id="S1.T1.14.14.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:65.4pt;"><span id="S1.T1.14.14.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S1.T1.14.14.1.1.p1" class="ltx_para ltx_noindent">
<span id="S1.T1.14.14.1.1.p1.1" class="ltx_p"><span id="S1.T1.14.14.1.1.p1.1.1" class="ltx_text"></span><span id="S1.T1.14.14.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S1.T1.14.14.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S1.T1.14.14.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.14.14.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S1.T1.14.14.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Zhu <span id="S1.T1.14.14.1.1.p1.1.3.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Zhu et al<span class="ltx_text">.</span> (<a href="#bib.bib255" title="" class="ltx_ref">2021b</a>)</cite></span></span>
</span></span><span id="S1.T1.14.14.1.1.p1.1.4" class="ltx_text"></span><span id="S1.T1.14.14.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S1.T1.14.14.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:165.0pt;">
<span id="S1.T1.14.14.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.14.14.2.1.1" class="ltx_p"><span id="S1.T1.14.14.2.1.1.1" class="ltx_text" style="font-size:90%;">They analyze the impact of non-IID data in federated learning and provide a survey of the research on handling non-IID data.</span></span>
</span>
</td>
<td id="S1.T1.14.14.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:167.9pt;">
<span id="S1.T1.14.14.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.14.14.3.1.1" class="ltx_p"><span id="S1.T1.14.14.3.1.1.1" class="ltx_text" style="font-size:90%;">This work analyzes the impact of Non-IID data on federated learning, but ignores other challenges and related research.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.15.15" class="ltx_tr">
<td id="S1.T1.15.15.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:65.4pt;"><span id="S1.T1.15.15.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S1.T1.15.15.1.1.p1" class="ltx_para ltx_noindent">
<span id="S1.T1.15.15.1.1.p1.1" class="ltx_p"><span id="S1.T1.15.15.1.1.p1.1.1" class="ltx_text"></span><span id="S1.T1.15.15.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S1.T1.15.15.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S1.T1.15.15.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.15.15.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S1.T1.15.15.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Kulkarni <span id="S1.T1.15.15.1.1.p1.1.3.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Kulkarni et al<span class="ltx_text">.</span> (<a href="#bib.bib107" title="" class="ltx_ref">2020</a>)</cite></span></span>
</span></span><span id="S1.T1.15.15.1.1.p1.1.4" class="ltx_text"></span><span id="S1.T1.15.15.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S1.T1.15.15.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:165.0pt;">
<span id="S1.T1.15.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.15.15.2.1.1" class="ltx_p"><span id="S1.T1.15.15.2.1.1.1" class="ltx_text" style="font-size:90%;">They point out that statistical heterogeneity can hinder federated learning and highlight the need for personalization.</span></span>
</span>
</td>
<td id="S1.T1.15.15.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:167.9pt;">
<span id="S1.T1.15.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.15.15.3.1.1" class="ltx_p"><span id="S1.T1.15.15.3.1.1.1" class="ltx_text" style="font-size:90%;">This work focuses on the challenges posed by statistical heterogeneity while ignoring other issues.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.16.16" class="ltx_tr">
<td id="S1.T1.16.16.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:65.4pt;"><span id="S1.T1.16.16.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S1.T1.16.16.1.1.p1" class="ltx_para ltx_noindent">
<span id="S1.T1.16.16.1.1.p1.1" class="ltx_p"><span id="S1.T1.16.16.1.1.p1.1.1" class="ltx_text"></span><span id="S1.T1.16.16.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S1.T1.16.16.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S1.T1.16.16.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.16.16.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S1.T1.16.16.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Tan <span id="S1.T1.16.16.1.1.p1.1.3.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Tan et al<span class="ltx_text">.</span> (<a href="#bib.bib199" title="" class="ltx_ref">2022b</a>)</cite></span></span>
</span></span><span id="S1.T1.16.16.1.1.p1.1.4" class="ltx_text"></span><span id="S1.T1.16.16.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S1.T1.16.16.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:165.0pt;">
<span id="S1.T1.16.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.16.16.2.1.1" class="ltx_p"><span id="S1.T1.16.16.2.1.1.1" class="ltx_text" style="font-size:90%;">They explore the field of personalized federated learning and conduct a taxonomic survey of existing methods.</span></span>
</span>
</td>
<td id="S1.T1.16.16.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:167.9pt;">
<span id="S1.T1.16.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.16.16.3.1.1" class="ltx_p"><span id="S1.T1.16.16.3.1.1.1" class="ltx_text" style="font-size:90%;">This work briefly explains statistical heterogeneity, but lacks a comprehensive taxonomy and analysis of the challenges in federated learning.</span></span>
</span>
</td>
</tr>
<tr id="S1.T1.17.17" class="ltx_tr">
<td id="S1.T1.17.17.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_l ltx_border_r ltx_border_t" style="width:65.4pt;"><span id="S1.T1.17.17.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S1.T1.17.17.1.1.p1" class="ltx_para ltx_noindent">
<span id="S1.T1.17.17.1.1.p1.1" class="ltx_p"><span id="S1.T1.17.17.1.1.p1.1.1" class="ltx_text"></span><span id="S1.T1.17.17.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S1.T1.17.17.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S1.T1.17.17.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S1.T1.17.17.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S1.T1.17.17.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Wu <span id="S1.T1.17.17.1.1.p1.1.3.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Wu et al<span class="ltx_text">.</span> (<a href="#bib.bib217" title="" class="ltx_ref">2020a</a>)</cite></span></span>
</span></span><span id="S1.T1.17.17.1.1.p1.1.4" class="ltx_text"></span><span id="S1.T1.17.17.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S1.T1.17.17.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:165.0pt;">
<span id="S1.T1.17.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.17.17.2.1.1" class="ltx_p"><span id="S1.T1.17.17.2.1.1.1" class="ltx_text" style="font-size:90%;">They provide a personalized federated learning framework in a cloud-edge architecture for intelligent IoT applications.</span></span>
</span>
</td>
<td id="S1.T1.17.17.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:167.9pt;">
<span id="S1.T1.17.17.3.1" class="ltx_inline-block ltx_align_top">
<span id="S1.T1.17.17.3.1.1" class="ltx_p"><span id="S1.T1.17.17.3.1.1.1" class="ltx_text" style="font-size:90%;">This work focuses on personalized federated learning schemes, whereas our survey encompasses broader federated learning schemes.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p"><span id="S1.p3.1.1" class="ltx_text" style="color:#000000;">Several surveys have been released on federated learning in general or specific aspects of federated learning. However, none of them provide a reasonable and comprehensive taxonomy of the research challenges and state-of-the-art of heterogeneous federated learning, which is an important and emerging research direction in federated learning. Heterogeneous federated learning aims to address the heterogeneity issues that arise from different aspects, such as statistical distribution, model architecture, communication setting, and device condition. Therefore, we discuss the main contributions and limitations of existing related surveys and highlight the unique contributions of our work in Tab. <a href="#S1.T1" title="Table 1 ‣ 1. Introduction ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.
Kairouz <span id="S1.p3.1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Kairouz et al<span class="ltx_text">.</span> (<a href="#bib.bib97" title="" class="ltx_ref">2019</a>)</cite> discuss recent advances in federated learning and provide a survey of open problems and challenges, including communication efficiency, privacy preservation, attack defense, and federated fairness.
Li <span id="S1.p3.1.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib124" title="" class="ltx_ref">2020c</a>)</cite> discuss the challenges faced by federated learning from four perspectives: communication efficiency, system heterogeneity, statistical heterogeneity, and privacy concern, and briefly listed several future research directions.
Wahab <span id="S1.p3.1.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Wahab et al<span class="ltx_text">.</span> (<a href="#bib.bib209" title="" class="ltx_ref">2021</a>)</cite> provide a fine-grained classification scheme of existing challenges and approaches.
Li <span id="S1.p3.1.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib120" title="" class="ltx_ref">2021g</a>)</cite> classify federated learning systems from six aspects, including data distribution, machine learning model, privacy mechanism, communication architecture, federated scale, and federated motivation.
Lim <span id="S1.p3.1.1.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Lim et al<span class="ltx_text">.</span> (<a href="#bib.bib130" title="" class="ltx_ref">2020</a>)</cite> study federated learning in mobile edge networks and divided the existing methods into methods that solve the fundamental problems of federated learning and methods that use federated learning to solve edge computing problems.
Niknam <span id="S1.p3.1.1.6" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Niknam et al<span class="ltx_text">.</span> (<a href="#bib.bib166" title="" class="ltx_ref">2020</a>)</cite> mainly enumerate and discuss several possible applications of federated learning in 5G networks, and described the key issues faced by federated learning in wireless communication settings.
There are some surveys <cite class="ltx_cite ltx_citemacro_cite">Khan et al<span class="ltx_text">.</span> (<a href="#bib.bib101" title="" class="ltx_ref">2021</a>); Nguyen et al<span class="ltx_text">.</span> (<a href="#bib.bib163" title="" class="ltx_ref">2021</a>)</cite> exploring federated learning for IoT Networks.
Khan <span id="S1.p3.1.1.7" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Khan et al<span class="ltx_text">.</span> (<a href="#bib.bib101" title="" class="ltx_ref">2021</a>)</cite> present advances in federated learning for IoT applications and provide a taxonomy using various operation modes as parameters (<span id="S1.p3.1.1.8" class="ltx_text ltx_font_italic">e.g.</span>, global aggregation, resource, local learning model, etc.). Besides, they identify important issues (robustness, privacy, and communication cost) and open challenges in federated learning, and propose corresponding guidelines.
Nguyen <span id="S1.p3.1.1.9" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Nguyen et al<span class="ltx_text">.</span> (<a href="#bib.bib163" title="" class="ltx_ref">2021</a>)</cite> provide a survey and analysis of federated learning in IoT services (<span id="S1.p3.1.1.10" class="ltx_text ltx_font_italic">e.g.</span>, IoT data sharing, data offloading and caching, attack detection, etc.) and IoT applications (<span id="S1.p3.1.1.11" class="ltx_text ltx_font_italic">e.g.</span>, smart healthcare, smart transportation, unmanned aerial vehicles, etc.).
Yang <span id="S1.p3.1.1.12" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Yang et al<span class="ltx_text">.</span> (<a href="#bib.bib227" title="" class="ltx_ref">2019</a>)</cite> divide federated learning into three categories: horizontal federated learning, vertical federated learning, and federated transfer learning according to the distribution characteristics of data. But they mainly introduce the concept and application of federated learning, lacking a detailed classification and summary of existing methods.
Gao <span id="S1.p3.1.1.13" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Gao et al<span class="ltx_text">.</span> (<a href="#bib.bib59" title="" class="ltx_ref">2022</a>)</cite> discuss data space, statistics, system, and model heterogeneity in FL, respectively, and provide a classification and introduction of scenarios, goals, and methods under each heterogeneity problem.
Zhu <span id="S1.p3.1.1.14" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Zhu et al<span class="ltx_text">.</span> (<a href="#bib.bib255" title="" class="ltx_ref">2021b</a>)</cite> analyze the impact of Non-IID data in federated learning and provide a survey of the researches on handling Non-IID data, but overlook several other heterogeneity issues and related research.
Kulkarni <span id="S1.p3.1.1.15" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Kulkarni et al<span class="ltx_text">.</span> (<a href="#bib.bib107" title="" class="ltx_ref">2020</a>)</cite> point out that statistical heterogeneity can deprive high-performance clients of incentives to participate in federated learning, highlight the need for personalization, and surveys work on this topic. They focus on the challenges posed by statistical heterogeneity while ignoring other issues.
Tan <span id="S1.p3.1.1.16" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Tan et al<span class="ltx_text">.</span> (<a href="#bib.bib199" title="" class="ltx_ref">2022b</a>)</cite> explore the field of personalized federated learning, which studies the problem of learning personalized models to handle statistical heterogeneity, and conduct a taxonomic survey of existing methods. But it lacks a comprehensive taxonomy and systematic analysis of the challenges in federated learning.
Wu <span id="S1.p3.1.1.17" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Wu et al<span class="ltx_text">.</span> (<a href="#bib.bib217" title="" class="ltx_ref">2020a</a>)</cite> provide a personalized federated learning framework in a cloud-edge architecture for intelligent IoT applications. But their classification of existing methods is not reasonable enough, which is only a small part of heterogeneous federated learning. In addition, the existing methods are diverse and vary widely in their own settings without a standard setting, making it challenging for readers to keep abreast of advancements in this field.
Consequently, a comprehensive and systematic survey on the research challenges, methods, limitations, and future directions associated with heterogeneous federated learning is urgently needed.</span></p>
</div>
<figure id="S1.F2" class="ltx_figure"><img src="/html/2307.10616/assets/x2.png" id="S1.F2.g1" class="ltx_graphics ltx_centering ltx_img_square" width="461" height="471" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2. </span><span id="S1.F2.2.1" class="ltx_text" style="font-size:90%;">The outline structure of our survey. It contains three different parts: Research challenges, State-of-the-Art, and Discussion of future directions.</span></figcaption>
</figure>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In this paper, we survey recently published or pre-printed papers on heterogeneous federated learning from top-tier conferences and journals. In particular, we not only investigate the problem of statistical heterogeneity and model heterogeneity but also analyze the aspects of privacy preservation and storage computational capacity during federated communication, which are particularly important for heterogeneous federated learning. Unlike other related surveys <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib124" title="" class="ltx_ref">2020c</a>); Tan et al<span class="ltx_text">.</span> (<a href="#bib.bib199" title="" class="ltx_ref">2022b</a>)</cite>, this survey consists of three major parts (Fig. <a href="#S1.F2" title="Figure 2 ‣ 1. Introduction ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). 1) We firstly systematically summarize the research challenges from five different aspects (Section <a href="#S2" title="2. Problems: Research Challenges in Heterogeneous Federated Learning ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). 2) We then review the current state-of-the-art methods with in-depth discussions about their advantages and limitations in the context of a new taxonomy (Section <a href="#S3" title="3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>). 3) Finally, we will present a thorough outlook analysis of the unsolved issues and open problems for future development (Section <a href="#S4" title="4. Future Directions ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). An outline structure of our survey is illustrated in Fig. <a href="#S1.F2" title="Figure 2 ‣ 1. Introduction ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">For the research challenges of heterogeneous federated learning, we focus on the above-mentioned five aspects, <span id="S1.p5.1.1" class="ltx_text ltx_font_italic">i.e.</span>, statistical heterogeneity, model heterogeneity, communication heterogeneity, device heterogeneity, and additional challenges. Considering that the data distribution of each client may be different, we discuss the Non-IID data from four perspectives: label skew, feature skew, quality skew, and quantity skew. Model heterogeneity is divided into partial heterogeneity and complete heterogeneity, according to the architectural models trained in the federated learning process. <span id="S1.p5.1.2" class="ltx_text" style="color:#000000;">Communication heterogeneity refers to the differences in communication resources and environments of clients, which are affected by the bandwidth, reliability, and topology of communication channels. Device heterogeneity is mainly caused by differences in the storage and computational capability of devices. Furthermore, the above four heterogeneous challenges may exacerbate two additional challenges, namely knowledge transfer barriers and privacy leakage. Knowledge transfer barriers indicate difficulties in effectively learning from each other. Privacy leakage refers to the sensitive information of local data sources being exposed to other parties.</span> By extensively analyzing the research challenges in heterogeneous federated learning, the research priorities in this field can be identified.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">To review the state-of-the-art methods, we introduce a new taxonomy to categorize existing heterogeneous federated learning approaches (Fig. <a href="#S2.F5" title="Figure 5 ‣ 2.5. Additional Challenges ‣ 2. Problems: Research Challenges in Heterogeneous Federated Learning ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>) into three levels, <span id="S1.p6.1.1" class="ltx_text ltx_font_italic">i.e.</span>, data-level, model-level, and server-level.
Data-level approaches focus on smoothing the statistical heterogeneity of local data across clients at the data level to support heterogeneous federated learning, such as data augmentation <cite class="ltx_cite ltx_citemacro_cite">Yoon et al<span class="ltx_text">.</span> (<a href="#bib.bib235" title="" class="ltx_ref">2021</a>); Jeong et al<span class="ltx_text">.</span> (<a href="#bib.bib93" title="" class="ltx_ref">2018</a>); Duan et al<span class="ltx_text">.</span> (<a href="#bib.bib44" title="" class="ltx_ref">2019</a>)</cite>. Model-level methods tend to operate at the model level for heterogeneous federated learning, <span id="S1.p6.1.2" class="ltx_text ltx_font_italic">e.g.</span>, sharing partial structures <cite class="ltx_cite ltx_citemacro_cite">Collins et al<span class="ltx_text">.</span> (<a href="#bib.bib36" title="" class="ltx_ref">2021</a>); Luo et al<span class="ltx_text">.</span> (<a href="#bib.bib140" title="" class="ltx_ref">2021</a>)</cite>, model optimization <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib125" title="" class="ltx_ref">2020d</a>, <a href="#bib.bib119" title="" class="ltx_ref">2021c</a>); Fallah et al<span class="ltx_text">.</span> (<a href="#bib.bib47" title="" class="ltx_ref">2020</a>)</cite>, knowledge transfer <cite class="ltx_cite ltx_citemacro_cite">Fang and Ye (<a href="#bib.bib49" title="" class="ltx_ref">2022</a>); Huang et al<span class="ltx_text">.</span> (<a href="#bib.bib86" title="" class="ltx_ref">2022b</a>)</cite>. The server-level methods require server participation, such as participating client selection <cite class="ltx_cite ltx_citemacro_cite">Wang et al<span class="ltx_text">.</span> (<a href="#bib.bib210" title="" class="ltx_ref">2020a</a>); Yang et al<span class="ltx_text">.</span> (<a href="#bib.bib226" title="" class="ltx_ref">2021</a>)</cite>, or client clustering <cite class="ltx_cite ltx_citemacro_cite">Sattler et al<span class="ltx_text">.</span> (<a href="#bib.bib181" title="" class="ltx_ref">2020b</a>); van Berlo et al<span class="ltx_text">.</span> (<a href="#bib.bib207" title="" class="ltx_ref">2020</a>); Ghosh et al<span class="ltx_text">.</span> (<a href="#bib.bib61" title="" class="ltx_ref">2020</a>)</cite>.
This new taxonomy of existing methods will facilitate the understanding of the state-of-the-art in heterogeneous federated learning, providing further guidelines for our following discussion.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">Last but not least, this survey also provides several perspectives to highlight the scope for the future development of heterogeneous federated learning. For example, how to reduce resource consumption and training time while improving model performance in heterogeneous scenarios is a key challenge, that is, we need to improve the efficiency and effectiveness of federated learning by conquering the heterogeneities. Besides, the emphasis on fairness will continue to grow as practical deployments of federated learning expand to more users and enterprises. This aspect is especially important for heterogeneous participants with unequal initial states, as they may have personalized requirements and characteristics.
To ensure the privacy protection of heterogeneous federated learning, it is crucial to establish stricter and more flexible privacy constraint policies, enforcing secure federated communication in all zones. In addition, the robustness of federated systems against attacks and failures requires increasing attention, especially in cases involving heterogeneous models with varying patterns against the attacks. At present, there is a lack of widely recognized benchmark datasets and benchmark testing frameworks for heterogeneous federated learning. This highlights the need to establish systematic evaluation metrics to promote the research on and the development of heterogeneous federated learning.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2. </span>Problems: Research Challenges in Heterogeneous Federated Learning</h2>

<figure id="S2.F3" class="ltx_figure"><img src="/html/2307.10616/assets/x3.png" id="S2.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="245" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3. </span><span id="S2.F3.2.1" class="ltx_text" style="font-size:90%;color:#000000;">General multi-layer federated learning architecture diagram.</span></figcaption>
</figure>
<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">First, this section provides a formulaic definition of federated learning and illustrates a typical federated learning process. Additionally, we present a detailed taxonomy of the problems encountered in heterogeneous federated learning. 1) Data is the primary element in HFL. Considering that the data distribution may differ across clients, we discuss <span id="S2.p1.1.1" class="ltx_text ltx_font_italic">statistical heterogeneity</span> from the four perspectives of label skew, feature skew, quality skew, and quantity skew in <span id="S2.p1.1.2" class="ltx_text" style="color:#000000;">Subsection</span> <a href="#S2.SS1" title="2.1. Statistical Heterogeneity ‣ 2. Problems: Research Challenges in Heterogeneous Federated Learning ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>. Besides, this Non-IID phenomenon may hinder subsequent model training. 2) According to the different architectural models trained in the federated learning process, <span id="S2.p1.1.3" class="ltx_text ltx_font_italic">model heterogeneity</span> can be divided into partial heterogeneity and complete heterogeneity, as described in <span id="S2.p1.1.4" class="ltx_text" style="color:#000000;">Subsection</span> <a href="#S2.SS2" title="2.2. Model Heterogeneity ‣ 2. Problems: Research Challenges in Heterogeneous Federated Learning ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.2</span></a>. 3) For the problem of <span id="S2.p1.1.5" class="ltx_text ltx_font_italic">communication heterogeneity</span> caused by different network environments such as high communication costs and low communication efficiency, we will discuss this issue in <span id="S2.p1.1.6" class="ltx_text" style="color:#000000;">Subsection</span> <a href="#S2.SS3" title="2.3. Communication Heterogeneity ‣ 2. Problems: Research Challenges in Heterogeneous Federated Learning ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.3</span></a>. 4) <span id="S2.p1.1.7" class="ltx_text" style="color:#000000;">The challenges of <span id="S2.p1.1.7.1" class="ltx_text ltx_font_italic">device heterogeneity</span>, which result from differences in device storage and computation capabilities and may lead to stragglers, fault issues, and low communication efficiency, are discussed in Subsection <a href="#S2.SS4" title="2.4. Device Heterogeneity ‣ 2. Problems: Research Challenges in Heterogeneous Federated Learning ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.4</span></a>.</span> The various forms of heterogeneities introduce additional challenges associated with knowledge transfer barriers and privacy leakage, as presented in <span id="S2.p1.1.8" class="ltx_text" style="color:#000000;">Subsection</span> <a href="#S2.SS5" title="2.5. Additional Challenges ‣ 2. Problems: Research Challenges in Heterogeneous Federated Learning ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.5</span></a>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.18" class="ltx_p"><span id="S2.p2.18.1" class="ltx_text ltx_font_bold">Preliminaries.</span> In the typical federated learning framework, we assume that it involves <math id="S2.p2.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.p2.1.m1.1a"><mi id="S2.p2.1.m1.1.1" xref="S2.p2.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.p2.1.m1.1b"><ci id="S2.p2.1.m1.1.1.cmml" xref="S2.p2.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.1.m1.1c">K</annotation></semantics></math> participating clients <math id="S2.p2.2.m2.4" class="ltx_Math" alttext="\{C_{1},C_{2},...,C_{K}\}" display="inline"><semantics id="S2.p2.2.m2.4a"><mrow id="S2.p2.2.m2.4.4.3" xref="S2.p2.2.m2.4.4.4.cmml"><mo stretchy="false" id="S2.p2.2.m2.4.4.3.4" xref="S2.p2.2.m2.4.4.4.cmml">{</mo><msub id="S2.p2.2.m2.2.2.1.1" xref="S2.p2.2.m2.2.2.1.1.cmml"><mi id="S2.p2.2.m2.2.2.1.1.2" xref="S2.p2.2.m2.2.2.1.1.2.cmml">C</mi><mn id="S2.p2.2.m2.2.2.1.1.3" xref="S2.p2.2.m2.2.2.1.1.3.cmml">1</mn></msub><mo id="S2.p2.2.m2.4.4.3.5" xref="S2.p2.2.m2.4.4.4.cmml">,</mo><msub id="S2.p2.2.m2.3.3.2.2" xref="S2.p2.2.m2.3.3.2.2.cmml"><mi id="S2.p2.2.m2.3.3.2.2.2" xref="S2.p2.2.m2.3.3.2.2.2.cmml">C</mi><mn id="S2.p2.2.m2.3.3.2.2.3" xref="S2.p2.2.m2.3.3.2.2.3.cmml">2</mn></msub><mo id="S2.p2.2.m2.4.4.3.6" xref="S2.p2.2.m2.4.4.4.cmml">,</mo><mi mathvariant="normal" id="S2.p2.2.m2.1.1" xref="S2.p2.2.m2.1.1.cmml">…</mi><mo id="S2.p2.2.m2.4.4.3.7" xref="S2.p2.2.m2.4.4.4.cmml">,</mo><msub id="S2.p2.2.m2.4.4.3.3" xref="S2.p2.2.m2.4.4.3.3.cmml"><mi id="S2.p2.2.m2.4.4.3.3.2" xref="S2.p2.2.m2.4.4.3.3.2.cmml">C</mi><mi id="S2.p2.2.m2.4.4.3.3.3" xref="S2.p2.2.m2.4.4.3.3.3.cmml">K</mi></msub><mo stretchy="false" id="S2.p2.2.m2.4.4.3.8" xref="S2.p2.2.m2.4.4.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.2.m2.4b"><set id="S2.p2.2.m2.4.4.4.cmml" xref="S2.p2.2.m2.4.4.3"><apply id="S2.p2.2.m2.2.2.1.1.cmml" xref="S2.p2.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S2.p2.2.m2.2.2.1.1.1.cmml" xref="S2.p2.2.m2.2.2.1.1">subscript</csymbol><ci id="S2.p2.2.m2.2.2.1.1.2.cmml" xref="S2.p2.2.m2.2.2.1.1.2">𝐶</ci><cn type="integer" id="S2.p2.2.m2.2.2.1.1.3.cmml" xref="S2.p2.2.m2.2.2.1.1.3">1</cn></apply><apply id="S2.p2.2.m2.3.3.2.2.cmml" xref="S2.p2.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S2.p2.2.m2.3.3.2.2.1.cmml" xref="S2.p2.2.m2.3.3.2.2">subscript</csymbol><ci id="S2.p2.2.m2.3.3.2.2.2.cmml" xref="S2.p2.2.m2.3.3.2.2.2">𝐶</ci><cn type="integer" id="S2.p2.2.m2.3.3.2.2.3.cmml" xref="S2.p2.2.m2.3.3.2.2.3">2</cn></apply><ci id="S2.p2.2.m2.1.1.cmml" xref="S2.p2.2.m2.1.1">…</ci><apply id="S2.p2.2.m2.4.4.3.3.cmml" xref="S2.p2.2.m2.4.4.3.3"><csymbol cd="ambiguous" id="S2.p2.2.m2.4.4.3.3.1.cmml" xref="S2.p2.2.m2.4.4.3.3">subscript</csymbol><ci id="S2.p2.2.m2.4.4.3.3.2.cmml" xref="S2.p2.2.m2.4.4.3.3.2">𝐶</ci><ci id="S2.p2.2.m2.4.4.3.3.3.cmml" xref="S2.p2.2.m2.4.4.3.3.3">𝐾</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.2.m2.4c">\{C_{1},C_{2},...,C_{K}\}</annotation></semantics></math>. For each client, the <math id="S2.p2.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.p2.3.m3.1a"><mi id="S2.p2.3.m3.1.1" xref="S2.p2.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.p2.3.m3.1b"><ci id="S2.p2.3.m3.1.1.cmml" xref="S2.p2.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.3.m3.1c">k</annotation></semantics></math>-th client <math id="S2.p2.4.m4.1" class="ltx_Math" alttext="C_{k}" display="inline"><semantics id="S2.p2.4.m4.1a"><msub id="S2.p2.4.m4.1.1" xref="S2.p2.4.m4.1.1.cmml"><mi id="S2.p2.4.m4.1.1.2" xref="S2.p2.4.m4.1.1.2.cmml">C</mi><mi id="S2.p2.4.m4.1.1.3" xref="S2.p2.4.m4.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p2.4.m4.1b"><apply id="S2.p2.4.m4.1.1.cmml" xref="S2.p2.4.m4.1.1"><csymbol cd="ambiguous" id="S2.p2.4.m4.1.1.1.cmml" xref="S2.p2.4.m4.1.1">subscript</csymbol><ci id="S2.p2.4.m4.1.1.2.cmml" xref="S2.p2.4.m4.1.1.2">𝐶</ci><ci id="S2.p2.4.m4.1.1.3.cmml" xref="S2.p2.4.m4.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.4.m4.1c">C_{k}</annotation></semantics></math> has a private dataset <math id="S2.p2.5.m5.1" class="ltx_Math" alttext="D_{k}=\{(x_{i}^{k},y_{i}^{k})\}_{i=1}^{N_{k}}" display="inline"><semantics id="S2.p2.5.m5.1a"><mrow id="S2.p2.5.m5.1.1" xref="S2.p2.5.m5.1.1.cmml"><msub id="S2.p2.5.m5.1.1.3" xref="S2.p2.5.m5.1.1.3.cmml"><mi id="S2.p2.5.m5.1.1.3.2" xref="S2.p2.5.m5.1.1.3.2.cmml">D</mi><mi id="S2.p2.5.m5.1.1.3.3" xref="S2.p2.5.m5.1.1.3.3.cmml">k</mi></msub><mo id="S2.p2.5.m5.1.1.2" xref="S2.p2.5.m5.1.1.2.cmml">=</mo><msubsup id="S2.p2.5.m5.1.1.1" xref="S2.p2.5.m5.1.1.1.cmml"><mrow id="S2.p2.5.m5.1.1.1.1.1.1" xref="S2.p2.5.m5.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.p2.5.m5.1.1.1.1.1.1.2" xref="S2.p2.5.m5.1.1.1.1.1.2.cmml">{</mo><mrow id="S2.p2.5.m5.1.1.1.1.1.1.1.2" xref="S2.p2.5.m5.1.1.1.1.1.1.1.3.cmml"><mo stretchy="false" id="S2.p2.5.m5.1.1.1.1.1.1.1.2.3" xref="S2.p2.5.m5.1.1.1.1.1.1.1.3.cmml">(</mo><msubsup id="S2.p2.5.m5.1.1.1.1.1.1.1.1.1" xref="S2.p2.5.m5.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.p2.5.m5.1.1.1.1.1.1.1.1.1.2.2" xref="S2.p2.5.m5.1.1.1.1.1.1.1.1.1.2.2.cmml">x</mi><mi id="S2.p2.5.m5.1.1.1.1.1.1.1.1.1.2.3" xref="S2.p2.5.m5.1.1.1.1.1.1.1.1.1.2.3.cmml">i</mi><mi id="S2.p2.5.m5.1.1.1.1.1.1.1.1.1.3" xref="S2.p2.5.m5.1.1.1.1.1.1.1.1.1.3.cmml">k</mi></msubsup><mo id="S2.p2.5.m5.1.1.1.1.1.1.1.2.4" xref="S2.p2.5.m5.1.1.1.1.1.1.1.3.cmml">,</mo><msubsup id="S2.p2.5.m5.1.1.1.1.1.1.1.2.2" xref="S2.p2.5.m5.1.1.1.1.1.1.1.2.2.cmml"><mi id="S2.p2.5.m5.1.1.1.1.1.1.1.2.2.2.2" xref="S2.p2.5.m5.1.1.1.1.1.1.1.2.2.2.2.cmml">y</mi><mi id="S2.p2.5.m5.1.1.1.1.1.1.1.2.2.2.3" xref="S2.p2.5.m5.1.1.1.1.1.1.1.2.2.2.3.cmml">i</mi><mi id="S2.p2.5.m5.1.1.1.1.1.1.1.2.2.3" xref="S2.p2.5.m5.1.1.1.1.1.1.1.2.2.3.cmml">k</mi></msubsup><mo stretchy="false" id="S2.p2.5.m5.1.1.1.1.1.1.1.2.5" xref="S2.p2.5.m5.1.1.1.1.1.1.1.3.cmml">)</mo></mrow><mo stretchy="false" id="S2.p2.5.m5.1.1.1.1.1.1.3" xref="S2.p2.5.m5.1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S2.p2.5.m5.1.1.1.1.3" xref="S2.p2.5.m5.1.1.1.1.3.cmml"><mi id="S2.p2.5.m5.1.1.1.1.3.2" xref="S2.p2.5.m5.1.1.1.1.3.2.cmml">i</mi><mo id="S2.p2.5.m5.1.1.1.1.3.1" xref="S2.p2.5.m5.1.1.1.1.3.1.cmml">=</mo><mn id="S2.p2.5.m5.1.1.1.1.3.3" xref="S2.p2.5.m5.1.1.1.1.3.3.cmml">1</mn></mrow><msub id="S2.p2.5.m5.1.1.1.3" xref="S2.p2.5.m5.1.1.1.3.cmml"><mi id="S2.p2.5.m5.1.1.1.3.2" xref="S2.p2.5.m5.1.1.1.3.2.cmml">N</mi><mi id="S2.p2.5.m5.1.1.1.3.3" xref="S2.p2.5.m5.1.1.1.3.3.cmml">k</mi></msub></msubsup></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.5.m5.1b"><apply id="S2.p2.5.m5.1.1.cmml" xref="S2.p2.5.m5.1.1"><eq id="S2.p2.5.m5.1.1.2.cmml" xref="S2.p2.5.m5.1.1.2"></eq><apply id="S2.p2.5.m5.1.1.3.cmml" xref="S2.p2.5.m5.1.1.3"><csymbol cd="ambiguous" id="S2.p2.5.m5.1.1.3.1.cmml" xref="S2.p2.5.m5.1.1.3">subscript</csymbol><ci id="S2.p2.5.m5.1.1.3.2.cmml" xref="S2.p2.5.m5.1.1.3.2">𝐷</ci><ci id="S2.p2.5.m5.1.1.3.3.cmml" xref="S2.p2.5.m5.1.1.3.3">𝑘</ci></apply><apply id="S2.p2.5.m5.1.1.1.cmml" xref="S2.p2.5.m5.1.1.1"><csymbol cd="ambiguous" id="S2.p2.5.m5.1.1.1.2.cmml" xref="S2.p2.5.m5.1.1.1">superscript</csymbol><apply id="S2.p2.5.m5.1.1.1.1.cmml" xref="S2.p2.5.m5.1.1.1"><csymbol cd="ambiguous" id="S2.p2.5.m5.1.1.1.1.2.cmml" xref="S2.p2.5.m5.1.1.1">subscript</csymbol><set id="S2.p2.5.m5.1.1.1.1.1.2.cmml" xref="S2.p2.5.m5.1.1.1.1.1.1"><interval closure="open" id="S2.p2.5.m5.1.1.1.1.1.1.1.3.cmml" xref="S2.p2.5.m5.1.1.1.1.1.1.1.2"><apply id="S2.p2.5.m5.1.1.1.1.1.1.1.1.1.cmml" xref="S2.p2.5.m5.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p2.5.m5.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.p2.5.m5.1.1.1.1.1.1.1.1.1">superscript</csymbol><apply id="S2.p2.5.m5.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.p2.5.m5.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p2.5.m5.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.p2.5.m5.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.p2.5.m5.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.p2.5.m5.1.1.1.1.1.1.1.1.1.2.2">𝑥</ci><ci id="S2.p2.5.m5.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.p2.5.m5.1.1.1.1.1.1.1.1.1.2.3">𝑖</ci></apply><ci id="S2.p2.5.m5.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.p2.5.m5.1.1.1.1.1.1.1.1.1.3">𝑘</ci></apply><apply id="S2.p2.5.m5.1.1.1.1.1.1.1.2.2.cmml" xref="S2.p2.5.m5.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.p2.5.m5.1.1.1.1.1.1.1.2.2.1.cmml" xref="S2.p2.5.m5.1.1.1.1.1.1.1.2.2">superscript</csymbol><apply id="S2.p2.5.m5.1.1.1.1.1.1.1.2.2.2.cmml" xref="S2.p2.5.m5.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.p2.5.m5.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S2.p2.5.m5.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S2.p2.5.m5.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S2.p2.5.m5.1.1.1.1.1.1.1.2.2.2.2">𝑦</ci><ci id="S2.p2.5.m5.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S2.p2.5.m5.1.1.1.1.1.1.1.2.2.2.3">𝑖</ci></apply><ci id="S2.p2.5.m5.1.1.1.1.1.1.1.2.2.3.cmml" xref="S2.p2.5.m5.1.1.1.1.1.1.1.2.2.3">𝑘</ci></apply></interval></set><apply id="S2.p2.5.m5.1.1.1.1.3.cmml" xref="S2.p2.5.m5.1.1.1.1.3"><eq id="S2.p2.5.m5.1.1.1.1.3.1.cmml" xref="S2.p2.5.m5.1.1.1.1.3.1"></eq><ci id="S2.p2.5.m5.1.1.1.1.3.2.cmml" xref="S2.p2.5.m5.1.1.1.1.3.2">𝑖</ci><cn type="integer" id="S2.p2.5.m5.1.1.1.1.3.3.cmml" xref="S2.p2.5.m5.1.1.1.1.3.3">1</cn></apply></apply><apply id="S2.p2.5.m5.1.1.1.3.cmml" xref="S2.p2.5.m5.1.1.1.3"><csymbol cd="ambiguous" id="S2.p2.5.m5.1.1.1.3.1.cmml" xref="S2.p2.5.m5.1.1.1.3">subscript</csymbol><ci id="S2.p2.5.m5.1.1.1.3.2.cmml" xref="S2.p2.5.m5.1.1.1.3.2">𝑁</ci><ci id="S2.p2.5.m5.1.1.1.3.3.cmml" xref="S2.p2.5.m5.1.1.1.3.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.5.m5.1c">D_{k}=\{(x_{i}^{k},y_{i}^{k})\}_{i=1}^{N_{k}}</annotation></semantics></math> with <math id="S2.p2.6.m6.1" class="ltx_Math" alttext="|x^{k}|=N_{k}" display="inline"><semantics id="S2.p2.6.m6.1a"><mrow id="S2.p2.6.m6.1.1" xref="S2.p2.6.m6.1.1.cmml"><mrow id="S2.p2.6.m6.1.1.1.1" xref="S2.p2.6.m6.1.1.1.2.cmml"><mo stretchy="false" id="S2.p2.6.m6.1.1.1.1.2" xref="S2.p2.6.m6.1.1.1.2.1.cmml">|</mo><msup id="S2.p2.6.m6.1.1.1.1.1" xref="S2.p2.6.m6.1.1.1.1.1.cmml"><mi id="S2.p2.6.m6.1.1.1.1.1.2" xref="S2.p2.6.m6.1.1.1.1.1.2.cmml">x</mi><mi id="S2.p2.6.m6.1.1.1.1.1.3" xref="S2.p2.6.m6.1.1.1.1.1.3.cmml">k</mi></msup><mo stretchy="false" id="S2.p2.6.m6.1.1.1.1.3" xref="S2.p2.6.m6.1.1.1.2.1.cmml">|</mo></mrow><mo id="S2.p2.6.m6.1.1.2" xref="S2.p2.6.m6.1.1.2.cmml">=</mo><msub id="S2.p2.6.m6.1.1.3" xref="S2.p2.6.m6.1.1.3.cmml"><mi id="S2.p2.6.m6.1.1.3.2" xref="S2.p2.6.m6.1.1.3.2.cmml">N</mi><mi id="S2.p2.6.m6.1.1.3.3" xref="S2.p2.6.m6.1.1.3.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.6.m6.1b"><apply id="S2.p2.6.m6.1.1.cmml" xref="S2.p2.6.m6.1.1"><eq id="S2.p2.6.m6.1.1.2.cmml" xref="S2.p2.6.m6.1.1.2"></eq><apply id="S2.p2.6.m6.1.1.1.2.cmml" xref="S2.p2.6.m6.1.1.1.1"><abs id="S2.p2.6.m6.1.1.1.2.1.cmml" xref="S2.p2.6.m6.1.1.1.1.2"></abs><apply id="S2.p2.6.m6.1.1.1.1.1.cmml" xref="S2.p2.6.m6.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p2.6.m6.1.1.1.1.1.1.cmml" xref="S2.p2.6.m6.1.1.1.1.1">superscript</csymbol><ci id="S2.p2.6.m6.1.1.1.1.1.2.cmml" xref="S2.p2.6.m6.1.1.1.1.1.2">𝑥</ci><ci id="S2.p2.6.m6.1.1.1.1.1.3.cmml" xref="S2.p2.6.m6.1.1.1.1.1.3">𝑘</ci></apply></apply><apply id="S2.p2.6.m6.1.1.3.cmml" xref="S2.p2.6.m6.1.1.3"><csymbol cd="ambiguous" id="S2.p2.6.m6.1.1.3.1.cmml" xref="S2.p2.6.m6.1.1.3">subscript</csymbol><ci id="S2.p2.6.m6.1.1.3.2.cmml" xref="S2.p2.6.m6.1.1.3.2">𝑁</ci><ci id="S2.p2.6.m6.1.1.3.3.cmml" xref="S2.p2.6.m6.1.1.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.6.m6.1c">|x^{k}|=N_{k}</annotation></semantics></math> and <math id="S2.p2.7.m7.1" class="ltx_Math" alttext="N=\sum_{k=1}^{K}N_{k}" display="inline"><semantics id="S2.p2.7.m7.1a"><mrow id="S2.p2.7.m7.1.1" xref="S2.p2.7.m7.1.1.cmml"><mi id="S2.p2.7.m7.1.1.2" xref="S2.p2.7.m7.1.1.2.cmml">N</mi><mo rspace="0.111em" id="S2.p2.7.m7.1.1.1" xref="S2.p2.7.m7.1.1.1.cmml">=</mo><mrow id="S2.p2.7.m7.1.1.3" xref="S2.p2.7.m7.1.1.3.cmml"><msubsup id="S2.p2.7.m7.1.1.3.1" xref="S2.p2.7.m7.1.1.3.1.cmml"><mo id="S2.p2.7.m7.1.1.3.1.2.2" xref="S2.p2.7.m7.1.1.3.1.2.2.cmml">∑</mo><mrow id="S2.p2.7.m7.1.1.3.1.2.3" xref="S2.p2.7.m7.1.1.3.1.2.3.cmml"><mi id="S2.p2.7.m7.1.1.3.1.2.3.2" xref="S2.p2.7.m7.1.1.3.1.2.3.2.cmml">k</mi><mo id="S2.p2.7.m7.1.1.3.1.2.3.1" xref="S2.p2.7.m7.1.1.3.1.2.3.1.cmml">=</mo><mn id="S2.p2.7.m7.1.1.3.1.2.3.3" xref="S2.p2.7.m7.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.p2.7.m7.1.1.3.1.3" xref="S2.p2.7.m7.1.1.3.1.3.cmml">K</mi></msubsup><msub id="S2.p2.7.m7.1.1.3.2" xref="S2.p2.7.m7.1.1.3.2.cmml"><mi id="S2.p2.7.m7.1.1.3.2.2" xref="S2.p2.7.m7.1.1.3.2.2.cmml">N</mi><mi id="S2.p2.7.m7.1.1.3.2.3" xref="S2.p2.7.m7.1.1.3.2.3.cmml">k</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.7.m7.1b"><apply id="S2.p2.7.m7.1.1.cmml" xref="S2.p2.7.m7.1.1"><eq id="S2.p2.7.m7.1.1.1.cmml" xref="S2.p2.7.m7.1.1.1"></eq><ci id="S2.p2.7.m7.1.1.2.cmml" xref="S2.p2.7.m7.1.1.2">𝑁</ci><apply id="S2.p2.7.m7.1.1.3.cmml" xref="S2.p2.7.m7.1.1.3"><apply id="S2.p2.7.m7.1.1.3.1.cmml" xref="S2.p2.7.m7.1.1.3.1"><csymbol cd="ambiguous" id="S2.p2.7.m7.1.1.3.1.1.cmml" xref="S2.p2.7.m7.1.1.3.1">superscript</csymbol><apply id="S2.p2.7.m7.1.1.3.1.2.cmml" xref="S2.p2.7.m7.1.1.3.1"><csymbol cd="ambiguous" id="S2.p2.7.m7.1.1.3.1.2.1.cmml" xref="S2.p2.7.m7.1.1.3.1">subscript</csymbol><sum id="S2.p2.7.m7.1.1.3.1.2.2.cmml" xref="S2.p2.7.m7.1.1.3.1.2.2"></sum><apply id="S2.p2.7.m7.1.1.3.1.2.3.cmml" xref="S2.p2.7.m7.1.1.3.1.2.3"><eq id="S2.p2.7.m7.1.1.3.1.2.3.1.cmml" xref="S2.p2.7.m7.1.1.3.1.2.3.1"></eq><ci id="S2.p2.7.m7.1.1.3.1.2.3.2.cmml" xref="S2.p2.7.m7.1.1.3.1.2.3.2">𝑘</ci><cn type="integer" id="S2.p2.7.m7.1.1.3.1.2.3.3.cmml" xref="S2.p2.7.m7.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S2.p2.7.m7.1.1.3.1.3.cmml" xref="S2.p2.7.m7.1.1.3.1.3">𝐾</ci></apply><apply id="S2.p2.7.m7.1.1.3.2.cmml" xref="S2.p2.7.m7.1.1.3.2"><csymbol cd="ambiguous" id="S2.p2.7.m7.1.1.3.2.1.cmml" xref="S2.p2.7.m7.1.1.3.2">subscript</csymbol><ci id="S2.p2.7.m7.1.1.3.2.2.cmml" xref="S2.p2.7.m7.1.1.3.2.2">𝑁</ci><ci id="S2.p2.7.m7.1.1.3.2.3.cmml" xref="S2.p2.7.m7.1.1.3.2.3">𝑘</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.7.m7.1c">N=\sum_{k=1}^{K}N_{k}</annotation></semantics></math>. Moreover,
the client <math id="S2.p2.8.m8.1" class="ltx_Math" alttext="C_{K}" display="inline"><semantics id="S2.p2.8.m8.1a"><msub id="S2.p2.8.m8.1.1" xref="S2.p2.8.m8.1.1.cmml"><mi id="S2.p2.8.m8.1.1.2" xref="S2.p2.8.m8.1.1.2.cmml">C</mi><mi id="S2.p2.8.m8.1.1.3" xref="S2.p2.8.m8.1.1.3.cmml">K</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p2.8.m8.1b"><apply id="S2.p2.8.m8.1.1.cmml" xref="S2.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S2.p2.8.m8.1.1.1.cmml" xref="S2.p2.8.m8.1.1">subscript</csymbol><ci id="S2.p2.8.m8.1.1.2.cmml" xref="S2.p2.8.m8.1.1.2">𝐶</ci><ci id="S2.p2.8.m8.1.1.3.cmml" xref="S2.p2.8.m8.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.8.m8.1c">C_{K}</annotation></semantics></math> usually has a learned local network model or initialized model, denoted by <math id="S2.p2.9.m9.1" class="ltx_Math" alttext="f(\theta_{k})" display="inline"><semantics id="S2.p2.9.m9.1a"><mrow id="S2.p2.9.m9.1.1" xref="S2.p2.9.m9.1.1.cmml"><mi id="S2.p2.9.m9.1.1.3" xref="S2.p2.9.m9.1.1.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.p2.9.m9.1.1.2" xref="S2.p2.9.m9.1.1.2.cmml">​</mo><mrow id="S2.p2.9.m9.1.1.1.1" xref="S2.p2.9.m9.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.p2.9.m9.1.1.1.1.2" xref="S2.p2.9.m9.1.1.1.1.1.cmml">(</mo><msub id="S2.p2.9.m9.1.1.1.1.1" xref="S2.p2.9.m9.1.1.1.1.1.cmml"><mi id="S2.p2.9.m9.1.1.1.1.1.2" xref="S2.p2.9.m9.1.1.1.1.1.2.cmml">θ</mi><mi id="S2.p2.9.m9.1.1.1.1.1.3" xref="S2.p2.9.m9.1.1.1.1.1.3.cmml">k</mi></msub><mo stretchy="false" id="S2.p2.9.m9.1.1.1.1.3" xref="S2.p2.9.m9.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.9.m9.1b"><apply id="S2.p2.9.m9.1.1.cmml" xref="S2.p2.9.m9.1.1"><times id="S2.p2.9.m9.1.1.2.cmml" xref="S2.p2.9.m9.1.1.2"></times><ci id="S2.p2.9.m9.1.1.3.cmml" xref="S2.p2.9.m9.1.1.3">𝑓</ci><apply id="S2.p2.9.m9.1.1.1.1.1.cmml" xref="S2.p2.9.m9.1.1.1.1"><csymbol cd="ambiguous" id="S2.p2.9.m9.1.1.1.1.1.1.cmml" xref="S2.p2.9.m9.1.1.1.1">subscript</csymbol><ci id="S2.p2.9.m9.1.1.1.1.1.2.cmml" xref="S2.p2.9.m9.1.1.1.1.1.2">𝜃</ci><ci id="S2.p2.9.m9.1.1.1.1.1.3.cmml" xref="S2.p2.9.m9.1.1.1.1.1.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.9.m9.1c">f(\theta_{k})</annotation></semantics></math>. Therefore, <math id="S2.p2.10.m10.2" class="ltx_Math" alttext="f(x^{k},\theta_{k})" display="inline"><semantics id="S2.p2.10.m10.2a"><mrow id="S2.p2.10.m10.2.2" xref="S2.p2.10.m10.2.2.cmml"><mi id="S2.p2.10.m10.2.2.4" xref="S2.p2.10.m10.2.2.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.p2.10.m10.2.2.3" xref="S2.p2.10.m10.2.2.3.cmml">​</mo><mrow id="S2.p2.10.m10.2.2.2.2" xref="S2.p2.10.m10.2.2.2.3.cmml"><mo stretchy="false" id="S2.p2.10.m10.2.2.2.2.3" xref="S2.p2.10.m10.2.2.2.3.cmml">(</mo><msup id="S2.p2.10.m10.1.1.1.1.1" xref="S2.p2.10.m10.1.1.1.1.1.cmml"><mi id="S2.p2.10.m10.1.1.1.1.1.2" xref="S2.p2.10.m10.1.1.1.1.1.2.cmml">x</mi><mi id="S2.p2.10.m10.1.1.1.1.1.3" xref="S2.p2.10.m10.1.1.1.1.1.3.cmml">k</mi></msup><mo id="S2.p2.10.m10.2.2.2.2.4" xref="S2.p2.10.m10.2.2.2.3.cmml">,</mo><msub id="S2.p2.10.m10.2.2.2.2.2" xref="S2.p2.10.m10.2.2.2.2.2.cmml"><mi id="S2.p2.10.m10.2.2.2.2.2.2" xref="S2.p2.10.m10.2.2.2.2.2.2.cmml">θ</mi><mi id="S2.p2.10.m10.2.2.2.2.2.3" xref="S2.p2.10.m10.2.2.2.2.2.3.cmml">k</mi></msub><mo stretchy="false" id="S2.p2.10.m10.2.2.2.2.5" xref="S2.p2.10.m10.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.10.m10.2b"><apply id="S2.p2.10.m10.2.2.cmml" xref="S2.p2.10.m10.2.2"><times id="S2.p2.10.m10.2.2.3.cmml" xref="S2.p2.10.m10.2.2.3"></times><ci id="S2.p2.10.m10.2.2.4.cmml" xref="S2.p2.10.m10.2.2.4">𝑓</ci><interval closure="open" id="S2.p2.10.m10.2.2.2.3.cmml" xref="S2.p2.10.m10.2.2.2.2"><apply id="S2.p2.10.m10.1.1.1.1.1.cmml" xref="S2.p2.10.m10.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.p2.10.m10.1.1.1.1.1.1.cmml" xref="S2.p2.10.m10.1.1.1.1.1">superscript</csymbol><ci id="S2.p2.10.m10.1.1.1.1.1.2.cmml" xref="S2.p2.10.m10.1.1.1.1.1.2">𝑥</ci><ci id="S2.p2.10.m10.1.1.1.1.1.3.cmml" xref="S2.p2.10.m10.1.1.1.1.1.3">𝑘</ci></apply><apply id="S2.p2.10.m10.2.2.2.2.2.cmml" xref="S2.p2.10.m10.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.p2.10.m10.2.2.2.2.2.1.cmml" xref="S2.p2.10.m10.2.2.2.2.2">subscript</csymbol><ci id="S2.p2.10.m10.2.2.2.2.2.2.cmml" xref="S2.p2.10.m10.2.2.2.2.2.2">𝜃</ci><ci id="S2.p2.10.m10.2.2.2.2.2.3.cmml" xref="S2.p2.10.m10.2.2.2.2.2.3">𝑘</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.10.m10.2c">f(x^{k},\theta_{k})</annotation></semantics></math> represents the predicted output of the private sample <math id="S2.p2.11.m11.1" class="ltx_Math" alttext="x^{k}" display="inline"><semantics id="S2.p2.11.m11.1a"><msup id="S2.p2.11.m11.1.1" xref="S2.p2.11.m11.1.1.cmml"><mi id="S2.p2.11.m11.1.1.2" xref="S2.p2.11.m11.1.1.2.cmml">x</mi><mi id="S2.p2.11.m11.1.1.3" xref="S2.p2.11.m11.1.1.3.cmml">k</mi></msup><annotation-xml encoding="MathML-Content" id="S2.p2.11.m11.1b"><apply id="S2.p2.11.m11.1.1.cmml" xref="S2.p2.11.m11.1.1"><csymbol cd="ambiguous" id="S2.p2.11.m11.1.1.1.cmml" xref="S2.p2.11.m11.1.1">superscript</csymbol><ci id="S2.p2.11.m11.1.1.2.cmml" xref="S2.p2.11.m11.1.1.2">𝑥</ci><ci id="S2.p2.11.m11.1.1.3.cmml" xref="S2.p2.11.m11.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.11.m11.1c">x^{k}</annotation></semantics></math> on the local model <math id="S2.p2.12.m12.1" class="ltx_Math" alttext="\theta_{k}" display="inline"><semantics id="S2.p2.12.m12.1a"><msub id="S2.p2.12.m12.1.1" xref="S2.p2.12.m12.1.1.cmml"><mi id="S2.p2.12.m12.1.1.2" xref="S2.p2.12.m12.1.1.2.cmml">θ</mi><mi id="S2.p2.12.m12.1.1.3" xref="S2.p2.12.m12.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p2.12.m12.1b"><apply id="S2.p2.12.m12.1.1.cmml" xref="S2.p2.12.m12.1.1"><csymbol cd="ambiguous" id="S2.p2.12.m12.1.1.1.cmml" xref="S2.p2.12.m12.1.1">subscript</csymbol><ci id="S2.p2.12.m12.1.1.2.cmml" xref="S2.p2.12.m12.1.1.2">𝜃</ci><ci id="S2.p2.12.m12.1.1.3.cmml" xref="S2.p2.12.m12.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.12.m12.1c">\theta_{k}</annotation></semantics></math>. Traditional centralized machine learning frameworks are typically built on a larger centralized dataset <math id="S2.p2.13.m13.1" class="ltx_Math" alttext="D_{central}=D_{1}\cup D_{2}\cup...\cup D_{K}" display="inline"><semantics id="S2.p2.13.m13.1a"><mrow id="S2.p2.13.m13.1.1" xref="S2.p2.13.m13.1.1.cmml"><msub id="S2.p2.13.m13.1.1.2" xref="S2.p2.13.m13.1.1.2.cmml"><mi id="S2.p2.13.m13.1.1.2.2" xref="S2.p2.13.m13.1.1.2.2.cmml">D</mi><mrow id="S2.p2.13.m13.1.1.2.3" xref="S2.p2.13.m13.1.1.2.3.cmml"><mi id="S2.p2.13.m13.1.1.2.3.2" xref="S2.p2.13.m13.1.1.2.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.p2.13.m13.1.1.2.3.1" xref="S2.p2.13.m13.1.1.2.3.1.cmml">​</mo><mi id="S2.p2.13.m13.1.1.2.3.3" xref="S2.p2.13.m13.1.1.2.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.p2.13.m13.1.1.2.3.1a" xref="S2.p2.13.m13.1.1.2.3.1.cmml">​</mo><mi id="S2.p2.13.m13.1.1.2.3.4" xref="S2.p2.13.m13.1.1.2.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.p2.13.m13.1.1.2.3.1b" xref="S2.p2.13.m13.1.1.2.3.1.cmml">​</mo><mi id="S2.p2.13.m13.1.1.2.3.5" xref="S2.p2.13.m13.1.1.2.3.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.p2.13.m13.1.1.2.3.1c" xref="S2.p2.13.m13.1.1.2.3.1.cmml">​</mo><mi id="S2.p2.13.m13.1.1.2.3.6" xref="S2.p2.13.m13.1.1.2.3.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.p2.13.m13.1.1.2.3.1d" xref="S2.p2.13.m13.1.1.2.3.1.cmml">​</mo><mi id="S2.p2.13.m13.1.1.2.3.7" xref="S2.p2.13.m13.1.1.2.3.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.p2.13.m13.1.1.2.3.1e" xref="S2.p2.13.m13.1.1.2.3.1.cmml">​</mo><mi id="S2.p2.13.m13.1.1.2.3.8" xref="S2.p2.13.m13.1.1.2.3.8.cmml">l</mi></mrow></msub><mo id="S2.p2.13.m13.1.1.1" xref="S2.p2.13.m13.1.1.1.cmml">=</mo><mrow id="S2.p2.13.m13.1.1.3" xref="S2.p2.13.m13.1.1.3.cmml"><msub id="S2.p2.13.m13.1.1.3.2" xref="S2.p2.13.m13.1.1.3.2.cmml"><mi id="S2.p2.13.m13.1.1.3.2.2" xref="S2.p2.13.m13.1.1.3.2.2.cmml">D</mi><mn id="S2.p2.13.m13.1.1.3.2.3" xref="S2.p2.13.m13.1.1.3.2.3.cmml">1</mn></msub><mo id="S2.p2.13.m13.1.1.3.1" xref="S2.p2.13.m13.1.1.3.1.cmml">∪</mo><msub id="S2.p2.13.m13.1.1.3.3" xref="S2.p2.13.m13.1.1.3.3.cmml"><mi id="S2.p2.13.m13.1.1.3.3.2" xref="S2.p2.13.m13.1.1.3.3.2.cmml">D</mi><mn id="S2.p2.13.m13.1.1.3.3.3" xref="S2.p2.13.m13.1.1.3.3.3.cmml">2</mn></msub><mo id="S2.p2.13.m13.1.1.3.1a" xref="S2.p2.13.m13.1.1.3.1.cmml">∪</mo><mi mathvariant="normal" id="S2.p2.13.m13.1.1.3.4" xref="S2.p2.13.m13.1.1.3.4.cmml">…</mi><mo id="S2.p2.13.m13.1.1.3.1b" xref="S2.p2.13.m13.1.1.3.1.cmml">∪</mo><msub id="S2.p2.13.m13.1.1.3.5" xref="S2.p2.13.m13.1.1.3.5.cmml"><mi id="S2.p2.13.m13.1.1.3.5.2" xref="S2.p2.13.m13.1.1.3.5.2.cmml">D</mi><mi id="S2.p2.13.m13.1.1.3.5.3" xref="S2.p2.13.m13.1.1.3.5.3.cmml">K</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.p2.13.m13.1b"><apply id="S2.p2.13.m13.1.1.cmml" xref="S2.p2.13.m13.1.1"><eq id="S2.p2.13.m13.1.1.1.cmml" xref="S2.p2.13.m13.1.1.1"></eq><apply id="S2.p2.13.m13.1.1.2.cmml" xref="S2.p2.13.m13.1.1.2"><csymbol cd="ambiguous" id="S2.p2.13.m13.1.1.2.1.cmml" xref="S2.p2.13.m13.1.1.2">subscript</csymbol><ci id="S2.p2.13.m13.1.1.2.2.cmml" xref="S2.p2.13.m13.1.1.2.2">𝐷</ci><apply id="S2.p2.13.m13.1.1.2.3.cmml" xref="S2.p2.13.m13.1.1.2.3"><times id="S2.p2.13.m13.1.1.2.3.1.cmml" xref="S2.p2.13.m13.1.1.2.3.1"></times><ci id="S2.p2.13.m13.1.1.2.3.2.cmml" xref="S2.p2.13.m13.1.1.2.3.2">𝑐</ci><ci id="S2.p2.13.m13.1.1.2.3.3.cmml" xref="S2.p2.13.m13.1.1.2.3.3">𝑒</ci><ci id="S2.p2.13.m13.1.1.2.3.4.cmml" xref="S2.p2.13.m13.1.1.2.3.4">𝑛</ci><ci id="S2.p2.13.m13.1.1.2.3.5.cmml" xref="S2.p2.13.m13.1.1.2.3.5">𝑡</ci><ci id="S2.p2.13.m13.1.1.2.3.6.cmml" xref="S2.p2.13.m13.1.1.2.3.6">𝑟</ci><ci id="S2.p2.13.m13.1.1.2.3.7.cmml" xref="S2.p2.13.m13.1.1.2.3.7">𝑎</ci><ci id="S2.p2.13.m13.1.1.2.3.8.cmml" xref="S2.p2.13.m13.1.1.2.3.8">𝑙</ci></apply></apply><apply id="S2.p2.13.m13.1.1.3.cmml" xref="S2.p2.13.m13.1.1.3"><union id="S2.p2.13.m13.1.1.3.1.cmml" xref="S2.p2.13.m13.1.1.3.1"></union><apply id="S2.p2.13.m13.1.1.3.2.cmml" xref="S2.p2.13.m13.1.1.3.2"><csymbol cd="ambiguous" id="S2.p2.13.m13.1.1.3.2.1.cmml" xref="S2.p2.13.m13.1.1.3.2">subscript</csymbol><ci id="S2.p2.13.m13.1.1.3.2.2.cmml" xref="S2.p2.13.m13.1.1.3.2.2">𝐷</ci><cn type="integer" id="S2.p2.13.m13.1.1.3.2.3.cmml" xref="S2.p2.13.m13.1.1.3.2.3">1</cn></apply><apply id="S2.p2.13.m13.1.1.3.3.cmml" xref="S2.p2.13.m13.1.1.3.3"><csymbol cd="ambiguous" id="S2.p2.13.m13.1.1.3.3.1.cmml" xref="S2.p2.13.m13.1.1.3.3">subscript</csymbol><ci id="S2.p2.13.m13.1.1.3.3.2.cmml" xref="S2.p2.13.m13.1.1.3.3.2">𝐷</ci><cn type="integer" id="S2.p2.13.m13.1.1.3.3.3.cmml" xref="S2.p2.13.m13.1.1.3.3.3">2</cn></apply><ci id="S2.p2.13.m13.1.1.3.4.cmml" xref="S2.p2.13.m13.1.1.3.4">…</ci><apply id="S2.p2.13.m13.1.1.3.5.cmml" xref="S2.p2.13.m13.1.1.3.5"><csymbol cd="ambiguous" id="S2.p2.13.m13.1.1.3.5.1.cmml" xref="S2.p2.13.m13.1.1.3.5">subscript</csymbol><ci id="S2.p2.13.m13.1.1.3.5.2.cmml" xref="S2.p2.13.m13.1.1.3.5.2">𝐷</ci><ci id="S2.p2.13.m13.1.1.3.5.3.cmml" xref="S2.p2.13.m13.1.1.3.5.3">𝐾</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.13.m13.1c">D_{central}=D_{1}\cup D_{2}\cup...\cup D_{K}</annotation></semantics></math> by directly integrating the private datasets of each client, which is then used to train a better performing centralized model <math id="S2.p2.14.m14.1" class="ltx_Math" alttext="\theta_{central}" display="inline"><semantics id="S2.p2.14.m14.1a"><msub id="S2.p2.14.m14.1.1" xref="S2.p2.14.m14.1.1.cmml"><mi id="S2.p2.14.m14.1.1.2" xref="S2.p2.14.m14.1.1.2.cmml">θ</mi><mrow id="S2.p2.14.m14.1.1.3" xref="S2.p2.14.m14.1.1.3.cmml"><mi id="S2.p2.14.m14.1.1.3.2" xref="S2.p2.14.m14.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S2.p2.14.m14.1.1.3.1" xref="S2.p2.14.m14.1.1.3.1.cmml">​</mo><mi id="S2.p2.14.m14.1.1.3.3" xref="S2.p2.14.m14.1.1.3.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S2.p2.14.m14.1.1.3.1a" xref="S2.p2.14.m14.1.1.3.1.cmml">​</mo><mi id="S2.p2.14.m14.1.1.3.4" xref="S2.p2.14.m14.1.1.3.4.cmml">n</mi><mo lspace="0em" rspace="0em" id="S2.p2.14.m14.1.1.3.1b" xref="S2.p2.14.m14.1.1.3.1.cmml">​</mo><mi id="S2.p2.14.m14.1.1.3.5" xref="S2.p2.14.m14.1.1.3.5.cmml">t</mi><mo lspace="0em" rspace="0em" id="S2.p2.14.m14.1.1.3.1c" xref="S2.p2.14.m14.1.1.3.1.cmml">​</mo><mi id="S2.p2.14.m14.1.1.3.6" xref="S2.p2.14.m14.1.1.3.6.cmml">r</mi><mo lspace="0em" rspace="0em" id="S2.p2.14.m14.1.1.3.1d" xref="S2.p2.14.m14.1.1.3.1.cmml">​</mo><mi id="S2.p2.14.m14.1.1.3.7" xref="S2.p2.14.m14.1.1.3.7.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.p2.14.m14.1.1.3.1e" xref="S2.p2.14.m14.1.1.3.1.cmml">​</mo><mi id="S2.p2.14.m14.1.1.3.8" xref="S2.p2.14.m14.1.1.3.8.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.p2.14.m14.1b"><apply id="S2.p2.14.m14.1.1.cmml" xref="S2.p2.14.m14.1.1"><csymbol cd="ambiguous" id="S2.p2.14.m14.1.1.1.cmml" xref="S2.p2.14.m14.1.1">subscript</csymbol><ci id="S2.p2.14.m14.1.1.2.cmml" xref="S2.p2.14.m14.1.1.2">𝜃</ci><apply id="S2.p2.14.m14.1.1.3.cmml" xref="S2.p2.14.m14.1.1.3"><times id="S2.p2.14.m14.1.1.3.1.cmml" xref="S2.p2.14.m14.1.1.3.1"></times><ci id="S2.p2.14.m14.1.1.3.2.cmml" xref="S2.p2.14.m14.1.1.3.2">𝑐</ci><ci id="S2.p2.14.m14.1.1.3.3.cmml" xref="S2.p2.14.m14.1.1.3.3">𝑒</ci><ci id="S2.p2.14.m14.1.1.3.4.cmml" xref="S2.p2.14.m14.1.1.3.4">𝑛</ci><ci id="S2.p2.14.m14.1.1.3.5.cmml" xref="S2.p2.14.m14.1.1.3.5">𝑡</ci><ci id="S2.p2.14.m14.1.1.3.6.cmml" xref="S2.p2.14.m14.1.1.3.6">𝑟</ci><ci id="S2.p2.14.m14.1.1.3.7.cmml" xref="S2.p2.14.m14.1.1.3.7">𝑎</ci><ci id="S2.p2.14.m14.1.1.3.8.cmml" xref="S2.p2.14.m14.1.1.3.8">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.14.m14.1c">\theta_{central}</annotation></semantics></math>. However, owing to the constraints of data silos and data privacy, traditional centralized learning cannot be applied in real-world privacy-sensitive scenarios. As an alternative, federated learning enables each client <math id="S2.p2.15.m15.1" class="ltx_Math" alttext="C_{k}" display="inline"><semantics id="S2.p2.15.m15.1a"><msub id="S2.p2.15.m15.1.1" xref="S2.p2.15.m15.1.1.cmml"><mi id="S2.p2.15.m15.1.1.2" xref="S2.p2.15.m15.1.1.2.cmml">C</mi><mi id="S2.p2.15.m15.1.1.3" xref="S2.p2.15.m15.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p2.15.m15.1b"><apply id="S2.p2.15.m15.1.1.cmml" xref="S2.p2.15.m15.1.1"><csymbol cd="ambiguous" id="S2.p2.15.m15.1.1.1.cmml" xref="S2.p2.15.m15.1.1">subscript</csymbol><ci id="S2.p2.15.m15.1.1.2.cmml" xref="S2.p2.15.m15.1.1.2">𝐶</ci><ci id="S2.p2.15.m15.1.1.3.cmml" xref="S2.p2.15.m15.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.15.m15.1c">C_{k}</annotation></semantics></math> to collaboratively train machine learning models without exposing the private data <math id="S2.p2.16.m16.1" class="ltx_Math" alttext="D_{k}" display="inline"><semantics id="S2.p2.16.m16.1a"><msub id="S2.p2.16.m16.1.1" xref="S2.p2.16.m16.1.1.cmml"><mi id="S2.p2.16.m16.1.1.2" xref="S2.p2.16.m16.1.1.2.cmml">D</mi><mi id="S2.p2.16.m16.1.1.3" xref="S2.p2.16.m16.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.p2.16.m16.1b"><apply id="S2.p2.16.m16.1.1.cmml" xref="S2.p2.16.m16.1.1"><csymbol cd="ambiguous" id="S2.p2.16.m16.1.1.1.cmml" xref="S2.p2.16.m16.1.1">subscript</csymbol><ci id="S2.p2.16.m16.1.1.2.cmml" xref="S2.p2.16.m16.1.1.2">𝐷</ci><ci id="S2.p2.16.m16.1.1.3.cmml" xref="S2.p2.16.m16.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.16.m16.1c">D_{k}</annotation></semantics></math> to other clients <math id="S2.p2.17.m17.1" class="ltx_Math" alttext="C_{k_{0}\neq k}" display="inline"><semantics id="S2.p2.17.m17.1a"><msub id="S2.p2.17.m17.1.1" xref="S2.p2.17.m17.1.1.cmml"><mi id="S2.p2.17.m17.1.1.2" xref="S2.p2.17.m17.1.1.2.cmml">C</mi><mrow id="S2.p2.17.m17.1.1.3" xref="S2.p2.17.m17.1.1.3.cmml"><msub id="S2.p2.17.m17.1.1.3.2" xref="S2.p2.17.m17.1.1.3.2.cmml"><mi id="S2.p2.17.m17.1.1.3.2.2" xref="S2.p2.17.m17.1.1.3.2.2.cmml">k</mi><mn id="S2.p2.17.m17.1.1.3.2.3" xref="S2.p2.17.m17.1.1.3.2.3.cmml">0</mn></msub><mo id="S2.p2.17.m17.1.1.3.1" xref="S2.p2.17.m17.1.1.3.1.cmml">≠</mo><mi id="S2.p2.17.m17.1.1.3.3" xref="S2.p2.17.m17.1.1.3.3.cmml">k</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.p2.17.m17.1b"><apply id="S2.p2.17.m17.1.1.cmml" xref="S2.p2.17.m17.1.1"><csymbol cd="ambiguous" id="S2.p2.17.m17.1.1.1.cmml" xref="S2.p2.17.m17.1.1">subscript</csymbol><ci id="S2.p2.17.m17.1.1.2.cmml" xref="S2.p2.17.m17.1.1.2">𝐶</ci><apply id="S2.p2.17.m17.1.1.3.cmml" xref="S2.p2.17.m17.1.1.3"><neq id="S2.p2.17.m17.1.1.3.1.cmml" xref="S2.p2.17.m17.1.1.3.1"></neq><apply id="S2.p2.17.m17.1.1.3.2.cmml" xref="S2.p2.17.m17.1.1.3.2"><csymbol cd="ambiguous" id="S2.p2.17.m17.1.1.3.2.1.cmml" xref="S2.p2.17.m17.1.1.3.2">subscript</csymbol><ci id="S2.p2.17.m17.1.1.3.2.2.cmml" xref="S2.p2.17.m17.1.1.3.2.2">𝑘</ci><cn type="integer" id="S2.p2.17.m17.1.1.3.2.3.cmml" xref="S2.p2.17.m17.1.1.3.2.3">0</cn></apply><ci id="S2.p2.17.m17.1.1.3.3.cmml" xref="S2.p2.17.m17.1.1.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.17.m17.1c">C_{k_{0}\neq k}</annotation></semantics></math>. Here we take FedAvg <cite class="ltx_cite ltx_citemacro_cite">McMahan et al<span class="ltx_text">.</span> (<a href="#bib.bib156" title="" class="ltx_ref">2017</a>)</cite> as a typical federated learning process (Fig.<a href="#S2.F3" title="Figure 3 ‣ 2. Problems: Research Challenges in Heterogeneous Federated Learning ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>). In the following, we show the steps involved in federated learning at the <math id="S2.p2.18.m18.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S2.p2.18.m18.1a"><mi id="S2.p2.18.m18.1.1" xref="S2.p2.18.m18.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.p2.18.m18.1b"><ci id="S2.p2.18.m18.1.1.cmml" xref="S2.p2.18.m18.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.p2.18.m18.1c">t</annotation></semantics></math>-th epoch, in which the federated system iterates the steps for several epochs until the end of the federated training process.</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.2" class="ltx_p"><span id="S2.I1.i1.p1.2.1" class="ltx_text ltx_font_bold">Model Initialization.</span> The server selects eligible clients <math id="S2.I1.i1.p1.1.m1.4" class="ltx_Math" alttext="\{C_{1},C_{2},...,C_{K}\}" display="inline"><semantics id="S2.I1.i1.p1.1.m1.4a"><mrow id="S2.I1.i1.p1.1.m1.4.4.3" xref="S2.I1.i1.p1.1.m1.4.4.4.cmml"><mo stretchy="false" id="S2.I1.i1.p1.1.m1.4.4.3.4" xref="S2.I1.i1.p1.1.m1.4.4.4.cmml">{</mo><msub id="S2.I1.i1.p1.1.m1.2.2.1.1" xref="S2.I1.i1.p1.1.m1.2.2.1.1.cmml"><mi id="S2.I1.i1.p1.1.m1.2.2.1.1.2" xref="S2.I1.i1.p1.1.m1.2.2.1.1.2.cmml">C</mi><mn id="S2.I1.i1.p1.1.m1.2.2.1.1.3" xref="S2.I1.i1.p1.1.m1.2.2.1.1.3.cmml">1</mn></msub><mo id="S2.I1.i1.p1.1.m1.4.4.3.5" xref="S2.I1.i1.p1.1.m1.4.4.4.cmml">,</mo><msub id="S2.I1.i1.p1.1.m1.3.3.2.2" xref="S2.I1.i1.p1.1.m1.3.3.2.2.cmml"><mi id="S2.I1.i1.p1.1.m1.3.3.2.2.2" xref="S2.I1.i1.p1.1.m1.3.3.2.2.2.cmml">C</mi><mn id="S2.I1.i1.p1.1.m1.3.3.2.2.3" xref="S2.I1.i1.p1.1.m1.3.3.2.2.3.cmml">2</mn></msub><mo id="S2.I1.i1.p1.1.m1.4.4.3.6" xref="S2.I1.i1.p1.1.m1.4.4.4.cmml">,</mo><mi mathvariant="normal" id="S2.I1.i1.p1.1.m1.1.1" xref="S2.I1.i1.p1.1.m1.1.1.cmml">…</mi><mo id="S2.I1.i1.p1.1.m1.4.4.3.7" xref="S2.I1.i1.p1.1.m1.4.4.4.cmml">,</mo><msub id="S2.I1.i1.p1.1.m1.4.4.3.3" xref="S2.I1.i1.p1.1.m1.4.4.3.3.cmml"><mi id="S2.I1.i1.p1.1.m1.4.4.3.3.2" xref="S2.I1.i1.p1.1.m1.4.4.3.3.2.cmml">C</mi><mi id="S2.I1.i1.p1.1.m1.4.4.3.3.3" xref="S2.I1.i1.p1.1.m1.4.4.3.3.3.cmml">K</mi></msub><mo stretchy="false" id="S2.I1.i1.p1.1.m1.4.4.3.8" xref="S2.I1.i1.p1.1.m1.4.4.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.1.m1.4b"><set id="S2.I1.i1.p1.1.m1.4.4.4.cmml" xref="S2.I1.i1.p1.1.m1.4.4.3"><apply id="S2.I1.i1.p1.1.m1.2.2.1.1.cmml" xref="S2.I1.i1.p1.1.m1.2.2.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p1.1.m1.2.2.1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.2.2.1.1">subscript</csymbol><ci id="S2.I1.i1.p1.1.m1.2.2.1.1.2.cmml" xref="S2.I1.i1.p1.1.m1.2.2.1.1.2">𝐶</ci><cn type="integer" id="S2.I1.i1.p1.1.m1.2.2.1.1.3.cmml" xref="S2.I1.i1.p1.1.m1.2.2.1.1.3">1</cn></apply><apply id="S2.I1.i1.p1.1.m1.3.3.2.2.cmml" xref="S2.I1.i1.p1.1.m1.3.3.2.2"><csymbol cd="ambiguous" id="S2.I1.i1.p1.1.m1.3.3.2.2.1.cmml" xref="S2.I1.i1.p1.1.m1.3.3.2.2">subscript</csymbol><ci id="S2.I1.i1.p1.1.m1.3.3.2.2.2.cmml" xref="S2.I1.i1.p1.1.m1.3.3.2.2.2">𝐶</ci><cn type="integer" id="S2.I1.i1.p1.1.m1.3.3.2.2.3.cmml" xref="S2.I1.i1.p1.1.m1.3.3.2.2.3">2</cn></apply><ci id="S2.I1.i1.p1.1.m1.1.1.cmml" xref="S2.I1.i1.p1.1.m1.1.1">…</ci><apply id="S2.I1.i1.p1.1.m1.4.4.3.3.cmml" xref="S2.I1.i1.p1.1.m1.4.4.3.3"><csymbol cd="ambiguous" id="S2.I1.i1.p1.1.m1.4.4.3.3.1.cmml" xref="S2.I1.i1.p1.1.m1.4.4.3.3">subscript</csymbol><ci id="S2.I1.i1.p1.1.m1.4.4.3.3.2.cmml" xref="S2.I1.i1.p1.1.m1.4.4.3.3.2">𝐶</ci><ci id="S2.I1.i1.p1.1.m1.4.4.3.3.3.cmml" xref="S2.I1.i1.p1.1.m1.4.4.3.3.3">𝐾</ci></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.1.m1.4c">\{C_{1},C_{2},...,C_{K}\}</annotation></semantics></math> as participants, and initializes the global model <math id="S2.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="\theta_{global}^{1}" display="inline"><semantics id="S2.I1.i1.p1.2.m2.1a"><msubsup id="S2.I1.i1.p1.2.m2.1.1" xref="S2.I1.i1.p1.2.m2.1.1.cmml"><mi id="S2.I1.i1.p1.2.m2.1.1.2.2" xref="S2.I1.i1.p1.2.m2.1.1.2.2.cmml">θ</mi><mrow id="S2.I1.i1.p1.2.m2.1.1.2.3" xref="S2.I1.i1.p1.2.m2.1.1.2.3.cmml"><mi id="S2.I1.i1.p1.2.m2.1.1.2.3.2" xref="S2.I1.i1.p1.2.m2.1.1.2.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.2.m2.1.1.2.3.1" xref="S2.I1.i1.p1.2.m2.1.1.2.3.1.cmml">​</mo><mi id="S2.I1.i1.p1.2.m2.1.1.2.3.3" xref="S2.I1.i1.p1.2.m2.1.1.2.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.2.m2.1.1.2.3.1a" xref="S2.I1.i1.p1.2.m2.1.1.2.3.1.cmml">​</mo><mi id="S2.I1.i1.p1.2.m2.1.1.2.3.4" xref="S2.I1.i1.p1.2.m2.1.1.2.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.2.m2.1.1.2.3.1b" xref="S2.I1.i1.p1.2.m2.1.1.2.3.1.cmml">​</mo><mi id="S2.I1.i1.p1.2.m2.1.1.2.3.5" xref="S2.I1.i1.p1.2.m2.1.1.2.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.2.m2.1.1.2.3.1c" xref="S2.I1.i1.p1.2.m2.1.1.2.3.1.cmml">​</mo><mi id="S2.I1.i1.p1.2.m2.1.1.2.3.6" xref="S2.I1.i1.p1.2.m2.1.1.2.3.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.I1.i1.p1.2.m2.1.1.2.3.1d" xref="S2.I1.i1.p1.2.m2.1.1.2.3.1.cmml">​</mo><mi id="S2.I1.i1.p1.2.m2.1.1.2.3.7" xref="S2.I1.i1.p1.2.m2.1.1.2.3.7.cmml">l</mi></mrow><mn id="S2.I1.i1.p1.2.m2.1.1.3" xref="S2.I1.i1.p1.2.m2.1.1.3.cmml">1</mn></msubsup><annotation-xml encoding="MathML-Content" id="S2.I1.i1.p1.2.m2.1b"><apply id="S2.I1.i1.p1.2.m2.1.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p1.2.m2.1.1.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1">superscript</csymbol><apply id="S2.I1.i1.p1.2.m2.1.1.2.cmml" xref="S2.I1.i1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.I1.i1.p1.2.m2.1.1.2.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1">subscript</csymbol><ci id="S2.I1.i1.p1.2.m2.1.1.2.2.cmml" xref="S2.I1.i1.p1.2.m2.1.1.2.2">𝜃</ci><apply id="S2.I1.i1.p1.2.m2.1.1.2.3.cmml" xref="S2.I1.i1.p1.2.m2.1.1.2.3"><times id="S2.I1.i1.p1.2.m2.1.1.2.3.1.cmml" xref="S2.I1.i1.p1.2.m2.1.1.2.3.1"></times><ci id="S2.I1.i1.p1.2.m2.1.1.2.3.2.cmml" xref="S2.I1.i1.p1.2.m2.1.1.2.3.2">𝑔</ci><ci id="S2.I1.i1.p1.2.m2.1.1.2.3.3.cmml" xref="S2.I1.i1.p1.2.m2.1.1.2.3.3">𝑙</ci><ci id="S2.I1.i1.p1.2.m2.1.1.2.3.4.cmml" xref="S2.I1.i1.p1.2.m2.1.1.2.3.4">𝑜</ci><ci id="S2.I1.i1.p1.2.m2.1.1.2.3.5.cmml" xref="S2.I1.i1.p1.2.m2.1.1.2.3.5">𝑏</ci><ci id="S2.I1.i1.p1.2.m2.1.1.2.3.6.cmml" xref="S2.I1.i1.p1.2.m2.1.1.2.3.6">𝑎</ci><ci id="S2.I1.i1.p1.2.m2.1.1.2.3.7.cmml" xref="S2.I1.i1.p1.2.m2.1.1.2.3.7">𝑙</ci></apply></apply><cn type="integer" id="S2.I1.i1.p1.2.m2.1.1.3.cmml" xref="S2.I1.i1.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i1.p1.2.m2.1c">\theta_{global}^{1}</annotation></semantics></math> in the first round.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.2" class="ltx_p"><span id="S2.I1.i2.p1.2.1" class="ltx_text ltx_font_bold">Model Broadcast.</span> The server sends the current global model <math id="S2.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="\theta_{global}^{t-1}" display="inline"><semantics id="S2.I1.i2.p1.1.m1.1a"><msubsup id="S2.I1.i2.p1.1.m1.1.1" xref="S2.I1.i2.p1.1.m1.1.1.cmml"><mi id="S2.I1.i2.p1.1.m1.1.1.2.2" xref="S2.I1.i2.p1.1.m1.1.1.2.2.cmml">θ</mi><mrow id="S2.I1.i2.p1.1.m1.1.1.2.3" xref="S2.I1.i2.p1.1.m1.1.1.2.3.cmml"><mi id="S2.I1.i2.p1.1.m1.1.1.2.3.2" xref="S2.I1.i2.p1.1.m1.1.1.2.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.I1.i2.p1.1.m1.1.1.2.3.1" xref="S2.I1.i2.p1.1.m1.1.1.2.3.1.cmml">​</mo><mi id="S2.I1.i2.p1.1.m1.1.1.2.3.3" xref="S2.I1.i2.p1.1.m1.1.1.2.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.I1.i2.p1.1.m1.1.1.2.3.1a" xref="S2.I1.i2.p1.1.m1.1.1.2.3.1.cmml">​</mo><mi id="S2.I1.i2.p1.1.m1.1.1.2.3.4" xref="S2.I1.i2.p1.1.m1.1.1.2.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.I1.i2.p1.1.m1.1.1.2.3.1b" xref="S2.I1.i2.p1.1.m1.1.1.2.3.1.cmml">​</mo><mi id="S2.I1.i2.p1.1.m1.1.1.2.3.5" xref="S2.I1.i2.p1.1.m1.1.1.2.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S2.I1.i2.p1.1.m1.1.1.2.3.1c" xref="S2.I1.i2.p1.1.m1.1.1.2.3.1.cmml">​</mo><mi id="S2.I1.i2.p1.1.m1.1.1.2.3.6" xref="S2.I1.i2.p1.1.m1.1.1.2.3.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.I1.i2.p1.1.m1.1.1.2.3.1d" xref="S2.I1.i2.p1.1.m1.1.1.2.3.1.cmml">​</mo><mi id="S2.I1.i2.p1.1.m1.1.1.2.3.7" xref="S2.I1.i2.p1.1.m1.1.1.2.3.7.cmml">l</mi></mrow><mrow id="S2.I1.i2.p1.1.m1.1.1.3" xref="S2.I1.i2.p1.1.m1.1.1.3.cmml"><mi id="S2.I1.i2.p1.1.m1.1.1.3.2" xref="S2.I1.i2.p1.1.m1.1.1.3.2.cmml">t</mi><mo id="S2.I1.i2.p1.1.m1.1.1.3.1" xref="S2.I1.i2.p1.1.m1.1.1.3.1.cmml">−</mo><mn id="S2.I1.i2.p1.1.m1.1.1.3.3" xref="S2.I1.i2.p1.1.m1.1.1.3.3.cmml">1</mn></mrow></msubsup><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.1.m1.1b"><apply id="S2.I1.i2.p1.1.m1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.1.m1.1.1.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1">superscript</csymbol><apply id="S2.I1.i2.p1.1.m1.1.1.2.cmml" xref="S2.I1.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.1.m1.1.1.2.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.I1.i2.p1.1.m1.1.1.2.2.cmml" xref="S2.I1.i2.p1.1.m1.1.1.2.2">𝜃</ci><apply id="S2.I1.i2.p1.1.m1.1.1.2.3.cmml" xref="S2.I1.i2.p1.1.m1.1.1.2.3"><times id="S2.I1.i2.p1.1.m1.1.1.2.3.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1.2.3.1"></times><ci id="S2.I1.i2.p1.1.m1.1.1.2.3.2.cmml" xref="S2.I1.i2.p1.1.m1.1.1.2.3.2">𝑔</ci><ci id="S2.I1.i2.p1.1.m1.1.1.2.3.3.cmml" xref="S2.I1.i2.p1.1.m1.1.1.2.3.3">𝑙</ci><ci id="S2.I1.i2.p1.1.m1.1.1.2.3.4.cmml" xref="S2.I1.i2.p1.1.m1.1.1.2.3.4">𝑜</ci><ci id="S2.I1.i2.p1.1.m1.1.1.2.3.5.cmml" xref="S2.I1.i2.p1.1.m1.1.1.2.3.5">𝑏</ci><ci id="S2.I1.i2.p1.1.m1.1.1.2.3.6.cmml" xref="S2.I1.i2.p1.1.m1.1.1.2.3.6">𝑎</ci><ci id="S2.I1.i2.p1.1.m1.1.1.2.3.7.cmml" xref="S2.I1.i2.p1.1.m1.1.1.2.3.7">𝑙</ci></apply></apply><apply id="S2.I1.i2.p1.1.m1.1.1.3.cmml" xref="S2.I1.i2.p1.1.m1.1.1.3"><minus id="S2.I1.i2.p1.1.m1.1.1.3.1.cmml" xref="S2.I1.i2.p1.1.m1.1.1.3.1"></minus><ci id="S2.I1.i2.p1.1.m1.1.1.3.2.cmml" xref="S2.I1.i2.p1.1.m1.1.1.3.2">𝑡</ci><cn type="integer" id="S2.I1.i2.p1.1.m1.1.1.3.3.cmml" xref="S2.I1.i2.p1.1.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.1.m1.1c">\theta_{global}^{t-1}</annotation></semantics></math> to all participating clients as the initialization of local models <math id="S2.I1.i2.p1.2.m2.4" class="ltx_Math" alttext="\{\theta_{1}^{t-1},\theta_{2}^{t-1},...,\theta_{K}^{t-1}\}" display="inline"><semantics id="S2.I1.i2.p1.2.m2.4a"><mrow id="S2.I1.i2.p1.2.m2.4.4.3" xref="S2.I1.i2.p1.2.m2.4.4.4.cmml"><mo stretchy="false" id="S2.I1.i2.p1.2.m2.4.4.3.4" xref="S2.I1.i2.p1.2.m2.4.4.4.cmml">{</mo><msubsup id="S2.I1.i2.p1.2.m2.2.2.1.1" xref="S2.I1.i2.p1.2.m2.2.2.1.1.cmml"><mi id="S2.I1.i2.p1.2.m2.2.2.1.1.2.2" xref="S2.I1.i2.p1.2.m2.2.2.1.1.2.2.cmml">θ</mi><mn id="S2.I1.i2.p1.2.m2.2.2.1.1.2.3" xref="S2.I1.i2.p1.2.m2.2.2.1.1.2.3.cmml">1</mn><mrow id="S2.I1.i2.p1.2.m2.2.2.1.1.3" xref="S2.I1.i2.p1.2.m2.2.2.1.1.3.cmml"><mi id="S2.I1.i2.p1.2.m2.2.2.1.1.3.2" xref="S2.I1.i2.p1.2.m2.2.2.1.1.3.2.cmml">t</mi><mo id="S2.I1.i2.p1.2.m2.2.2.1.1.3.1" xref="S2.I1.i2.p1.2.m2.2.2.1.1.3.1.cmml">−</mo><mn id="S2.I1.i2.p1.2.m2.2.2.1.1.3.3" xref="S2.I1.i2.p1.2.m2.2.2.1.1.3.3.cmml">1</mn></mrow></msubsup><mo id="S2.I1.i2.p1.2.m2.4.4.3.5" xref="S2.I1.i2.p1.2.m2.4.4.4.cmml">,</mo><msubsup id="S2.I1.i2.p1.2.m2.3.3.2.2" xref="S2.I1.i2.p1.2.m2.3.3.2.2.cmml"><mi id="S2.I1.i2.p1.2.m2.3.3.2.2.2.2" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.2.cmml">θ</mi><mn id="S2.I1.i2.p1.2.m2.3.3.2.2.2.3" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.3.cmml">2</mn><mrow id="S2.I1.i2.p1.2.m2.3.3.2.2.3" xref="S2.I1.i2.p1.2.m2.3.3.2.2.3.cmml"><mi id="S2.I1.i2.p1.2.m2.3.3.2.2.3.2" xref="S2.I1.i2.p1.2.m2.3.3.2.2.3.2.cmml">t</mi><mo id="S2.I1.i2.p1.2.m2.3.3.2.2.3.1" xref="S2.I1.i2.p1.2.m2.3.3.2.2.3.1.cmml">−</mo><mn id="S2.I1.i2.p1.2.m2.3.3.2.2.3.3" xref="S2.I1.i2.p1.2.m2.3.3.2.2.3.3.cmml">1</mn></mrow></msubsup><mo id="S2.I1.i2.p1.2.m2.4.4.3.6" xref="S2.I1.i2.p1.2.m2.4.4.4.cmml">,</mo><mi mathvariant="normal" id="S2.I1.i2.p1.2.m2.1.1" xref="S2.I1.i2.p1.2.m2.1.1.cmml">…</mi><mo id="S2.I1.i2.p1.2.m2.4.4.3.7" xref="S2.I1.i2.p1.2.m2.4.4.4.cmml">,</mo><msubsup id="S2.I1.i2.p1.2.m2.4.4.3.3" xref="S2.I1.i2.p1.2.m2.4.4.3.3.cmml"><mi id="S2.I1.i2.p1.2.m2.4.4.3.3.2.2" xref="S2.I1.i2.p1.2.m2.4.4.3.3.2.2.cmml">θ</mi><mi id="S2.I1.i2.p1.2.m2.4.4.3.3.2.3" xref="S2.I1.i2.p1.2.m2.4.4.3.3.2.3.cmml">K</mi><mrow id="S2.I1.i2.p1.2.m2.4.4.3.3.3" xref="S2.I1.i2.p1.2.m2.4.4.3.3.3.cmml"><mi id="S2.I1.i2.p1.2.m2.4.4.3.3.3.2" xref="S2.I1.i2.p1.2.m2.4.4.3.3.3.2.cmml">t</mi><mo id="S2.I1.i2.p1.2.m2.4.4.3.3.3.1" xref="S2.I1.i2.p1.2.m2.4.4.3.3.3.1.cmml">−</mo><mn id="S2.I1.i2.p1.2.m2.4.4.3.3.3.3" xref="S2.I1.i2.p1.2.m2.4.4.3.3.3.3.cmml">1</mn></mrow></msubsup><mo stretchy="false" id="S2.I1.i2.p1.2.m2.4.4.3.8" xref="S2.I1.i2.p1.2.m2.4.4.4.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i2.p1.2.m2.4b"><set id="S2.I1.i2.p1.2.m2.4.4.4.cmml" xref="S2.I1.i2.p1.2.m2.4.4.3"><apply id="S2.I1.i2.p1.2.m2.2.2.1.1.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.2.2.1.1.1.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1">superscript</csymbol><apply id="S2.I1.i2.p1.2.m2.2.2.1.1.2.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.2.2.1.1.2.1.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1">subscript</csymbol><ci id="S2.I1.i2.p1.2.m2.2.2.1.1.2.2.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1.2.2">𝜃</ci><cn type="integer" id="S2.I1.i2.p1.2.m2.2.2.1.1.2.3.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1.2.3">1</cn></apply><apply id="S2.I1.i2.p1.2.m2.2.2.1.1.3.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1.3"><minus id="S2.I1.i2.p1.2.m2.2.2.1.1.3.1.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1.3.1"></minus><ci id="S2.I1.i2.p1.2.m2.2.2.1.1.3.2.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1.3.2">𝑡</ci><cn type="integer" id="S2.I1.i2.p1.2.m2.2.2.1.1.3.3.cmml" xref="S2.I1.i2.p1.2.m2.2.2.1.1.3.3">1</cn></apply></apply><apply id="S2.I1.i2.p1.2.m2.3.3.2.2.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.3.3.2.2.1.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2">superscript</csymbol><apply id="S2.I1.i2.p1.2.m2.3.3.2.2.2.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.3.3.2.2.2.1.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2">subscript</csymbol><ci id="S2.I1.i2.p1.2.m2.3.3.2.2.2.2.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.2">𝜃</ci><cn type="integer" id="S2.I1.i2.p1.2.m2.3.3.2.2.2.3.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2.2.3">2</cn></apply><apply id="S2.I1.i2.p1.2.m2.3.3.2.2.3.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2.3"><minus id="S2.I1.i2.p1.2.m2.3.3.2.2.3.1.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2.3.1"></minus><ci id="S2.I1.i2.p1.2.m2.3.3.2.2.3.2.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2.3.2">𝑡</ci><cn type="integer" id="S2.I1.i2.p1.2.m2.3.3.2.2.3.3.cmml" xref="S2.I1.i2.p1.2.m2.3.3.2.2.3.3">1</cn></apply></apply><ci id="S2.I1.i2.p1.2.m2.1.1.cmml" xref="S2.I1.i2.p1.2.m2.1.1">…</ci><apply id="S2.I1.i2.p1.2.m2.4.4.3.3.cmml" xref="S2.I1.i2.p1.2.m2.4.4.3.3"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.4.4.3.3.1.cmml" xref="S2.I1.i2.p1.2.m2.4.4.3.3">superscript</csymbol><apply id="S2.I1.i2.p1.2.m2.4.4.3.3.2.cmml" xref="S2.I1.i2.p1.2.m2.4.4.3.3"><csymbol cd="ambiguous" id="S2.I1.i2.p1.2.m2.4.4.3.3.2.1.cmml" xref="S2.I1.i2.p1.2.m2.4.4.3.3">subscript</csymbol><ci id="S2.I1.i2.p1.2.m2.4.4.3.3.2.2.cmml" xref="S2.I1.i2.p1.2.m2.4.4.3.3.2.2">𝜃</ci><ci id="S2.I1.i2.p1.2.m2.4.4.3.3.2.3.cmml" xref="S2.I1.i2.p1.2.m2.4.4.3.3.2.3">𝐾</ci></apply><apply id="S2.I1.i2.p1.2.m2.4.4.3.3.3.cmml" xref="S2.I1.i2.p1.2.m2.4.4.3.3.3"><minus id="S2.I1.i2.p1.2.m2.4.4.3.3.3.1.cmml" xref="S2.I1.i2.p1.2.m2.4.4.3.3.3.1"></minus><ci id="S2.I1.i2.p1.2.m2.4.4.3.3.3.2.cmml" xref="S2.I1.i2.p1.2.m2.4.4.3.3.3.2">𝑡</ci><cn type="integer" id="S2.I1.i2.p1.2.m2.4.4.3.3.3.3.cmml" xref="S2.I1.i2.p1.2.m2.4.4.3.3.3.3">1</cn></apply></apply></set></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i2.p1.2.m2.4c">\{\theta_{1}^{t-1},\theta_{2}^{t-1},...,\theta_{K}^{t-1}\}</annotation></semantics></math>.</p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.2" class="ltx_p"><span id="S2.I1.i3.p1.2.1" class="ltx_text ltx_font_bold">Local Update.</span> Each participating client <math id="S2.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="C_{k}" display="inline"><semantics id="S2.I1.i3.p1.1.m1.1a"><msub id="S2.I1.i3.p1.1.m1.1.1" xref="S2.I1.i3.p1.1.m1.1.1.cmml"><mi id="S2.I1.i3.p1.1.m1.1.1.2" xref="S2.I1.i3.p1.1.m1.1.1.2.cmml">C</mi><mi id="S2.I1.i3.p1.1.m1.1.1.3" xref="S2.I1.i3.p1.1.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.1.m1.1b"><apply id="S2.I1.i3.p1.1.m1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.I1.i3.p1.1.m1.1.1.1.cmml" xref="S2.I1.i3.p1.1.m1.1.1">subscript</csymbol><ci id="S2.I1.i3.p1.1.m1.1.1.2.cmml" xref="S2.I1.i3.p1.1.m1.1.1.2">𝐶</ci><ci id="S2.I1.i3.p1.1.m1.1.1.3.cmml" xref="S2.I1.i3.p1.1.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.1.m1.1c">C_{k}</annotation></semantics></math> utilizes the private dataset <math id="S2.I1.i3.p1.2.m2.1" class="ltx_Math" alttext="D_{k}" display="inline"><semantics id="S2.I1.i3.p1.2.m2.1a"><msub id="S2.I1.i3.p1.2.m2.1.1" xref="S2.I1.i3.p1.2.m2.1.1.cmml"><mi id="S2.I1.i3.p1.2.m2.1.1.2" xref="S2.I1.i3.p1.2.m2.1.1.2.cmml">D</mi><mi id="S2.I1.i3.p1.2.m2.1.1.3" xref="S2.I1.i3.p1.2.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.2.m2.1b"><apply id="S2.I1.i3.p1.2.m2.1.1.cmml" xref="S2.I1.i3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.I1.i3.p1.2.m2.1.1.1.cmml" xref="S2.I1.i3.p1.2.m2.1.1">subscript</csymbol><ci id="S2.I1.i3.p1.2.m2.1.1.2.cmml" xref="S2.I1.i3.p1.2.m2.1.1.2">𝐷</ci><ci id="S2.I1.i3.p1.2.m2.1.1.3.cmml" xref="S2.I1.i3.p1.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.2.m2.1c">D_{k}</annotation></semantics></math> for local model updating as follows:</p>
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.1" class="ltx_Math" alttext="\theta_{k}^{t}\leftarrow\theta_{k}^{t-1}-\alpha\nabla_{\theta}\mathcal{L}_{k}(f(x^{k},\theta_{k}^{t-1}),y^{k})," display="block"><semantics id="S2.E1.m1.1a"><mrow id="S2.E1.m1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><mrow id="S2.E1.m1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.cmml"><msubsup id="S2.E1.m1.1.1.1.1.4" xref="S2.E1.m1.1.1.1.1.4.cmml"><mi id="S2.E1.m1.1.1.1.1.4.2.2" xref="S2.E1.m1.1.1.1.1.4.2.2.cmml">θ</mi><mi id="S2.E1.m1.1.1.1.1.4.2.3" xref="S2.E1.m1.1.1.1.1.4.2.3.cmml">k</mi><mi id="S2.E1.m1.1.1.1.1.4.3" xref="S2.E1.m1.1.1.1.1.4.3.cmml">t</mi></msubsup><mo stretchy="false" id="S2.E1.m1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.3.cmml">←</mo><mrow id="S2.E1.m1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.2.cmml"><msubsup id="S2.E1.m1.1.1.1.1.2.4" xref="S2.E1.m1.1.1.1.1.2.4.cmml"><mi id="S2.E1.m1.1.1.1.1.2.4.2.2" xref="S2.E1.m1.1.1.1.1.2.4.2.2.cmml">θ</mi><mi id="S2.E1.m1.1.1.1.1.2.4.2.3" xref="S2.E1.m1.1.1.1.1.2.4.2.3.cmml">k</mi><mrow id="S2.E1.m1.1.1.1.1.2.4.3" xref="S2.E1.m1.1.1.1.1.2.4.3.cmml"><mi id="S2.E1.m1.1.1.1.1.2.4.3.2" xref="S2.E1.m1.1.1.1.1.2.4.3.2.cmml">t</mi><mo id="S2.E1.m1.1.1.1.1.2.4.3.1" xref="S2.E1.m1.1.1.1.1.2.4.3.1.cmml">−</mo><mn id="S2.E1.m1.1.1.1.1.2.4.3.3" xref="S2.E1.m1.1.1.1.1.2.4.3.3.cmml">1</mn></mrow></msubsup><mo id="S2.E1.m1.1.1.1.1.2.3" xref="S2.E1.m1.1.1.1.1.2.3.cmml">−</mo><mrow id="S2.E1.m1.1.1.1.1.2.2" xref="S2.E1.m1.1.1.1.1.2.2.cmml"><mi id="S2.E1.m1.1.1.1.1.2.2.4" xref="S2.E1.m1.1.1.1.1.2.2.4.cmml">α</mi><mo lspace="0.167em" rspace="0em" id="S2.E1.m1.1.1.1.1.2.2.3" xref="S2.E1.m1.1.1.1.1.2.2.3.cmml">​</mo><mrow id="S2.E1.m1.1.1.1.1.2.2.5" xref="S2.E1.m1.1.1.1.1.2.2.5.cmml"><msub id="S2.E1.m1.1.1.1.1.2.2.5.1" xref="S2.E1.m1.1.1.1.1.2.2.5.1.cmml"><mo rspace="0.167em" id="S2.E1.m1.1.1.1.1.2.2.5.1.2" xref="S2.E1.m1.1.1.1.1.2.2.5.1.2.cmml">∇</mo><mi id="S2.E1.m1.1.1.1.1.2.2.5.1.3" xref="S2.E1.m1.1.1.1.1.2.2.5.1.3.cmml">θ</mi></msub><msub id="S2.E1.m1.1.1.1.1.2.2.5.2" xref="S2.E1.m1.1.1.1.1.2.2.5.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.E1.m1.1.1.1.1.2.2.5.2.2" xref="S2.E1.m1.1.1.1.1.2.2.5.2.2.cmml">ℒ</mi><mi id="S2.E1.m1.1.1.1.1.2.2.5.2.3" xref="S2.E1.m1.1.1.1.1.2.2.5.2.3.cmml">k</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.2.2.3a" xref="S2.E1.m1.1.1.1.1.2.2.3.cmml">​</mo><mrow id="S2.E1.m1.1.1.1.1.2.2.2.2" xref="S2.E1.m1.1.1.1.1.2.2.2.3.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.1.1.2.2.2.2.3" xref="S2.E1.m1.1.1.1.1.2.2.2.3.cmml">(</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.4" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.3.cmml">​</mo><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml"><mo stretchy="false" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml">(</mo><msup id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">x</mi><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml">k</mi></msup><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.4" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml">,</mo><msubsup id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.2.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml">θ</mi><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.2.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.cmml">k</mi><mrow id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml"><mi id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.3.2" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.3.2.cmml">t</mi><mo id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.3.1" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.3.1.cmml">−</mo><mn id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.3.3" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.3.3.cmml">1</mn></mrow></msubsup><mo stretchy="false" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.5" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.1.1.1.1.2.2.2.2.4" xref="S2.E1.m1.1.1.1.1.2.2.2.3.cmml">,</mo><msup id="S2.E1.m1.1.1.1.1.2.2.2.2.2" xref="S2.E1.m1.1.1.1.1.2.2.2.2.2.cmml"><mi id="S2.E1.m1.1.1.1.1.2.2.2.2.2.2" xref="S2.E1.m1.1.1.1.1.2.2.2.2.2.2.cmml">y</mi><mi id="S2.E1.m1.1.1.1.1.2.2.2.2.2.3" xref="S2.E1.m1.1.1.1.1.2.2.2.2.2.3.cmml">k</mi></msup><mo stretchy="false" id="S2.E1.m1.1.1.1.1.2.2.2.2.5" xref="S2.E1.m1.1.1.1.1.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S2.E1.m1.1.1.1.2" xref="S2.E1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.1b"><apply id="S2.E1.m1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1"><ci id="S2.E1.m1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.3">←</ci><apply id="S2.E1.m1.1.1.1.1.4.cmml" xref="S2.E1.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.4.1.cmml" xref="S2.E1.m1.1.1.1.1.4">superscript</csymbol><apply id="S2.E1.m1.1.1.1.1.4.2.cmml" xref="S2.E1.m1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.4.2.1.cmml" xref="S2.E1.m1.1.1.1.1.4">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.4.2.2.cmml" xref="S2.E1.m1.1.1.1.1.4.2.2">𝜃</ci><ci id="S2.E1.m1.1.1.1.1.4.2.3.cmml" xref="S2.E1.m1.1.1.1.1.4.2.3">𝑘</ci></apply><ci id="S2.E1.m1.1.1.1.1.4.3.cmml" xref="S2.E1.m1.1.1.1.1.4.3">𝑡</ci></apply><apply id="S2.E1.m1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2"><minus id="S2.E1.m1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.1.1.2.3"></minus><apply id="S2.E1.m1.1.1.1.1.2.4.cmml" xref="S2.E1.m1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.2.4.1.cmml" xref="S2.E1.m1.1.1.1.1.2.4">superscript</csymbol><apply id="S2.E1.m1.1.1.1.1.2.4.2.cmml" xref="S2.E1.m1.1.1.1.1.2.4"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.2.4.2.1.cmml" xref="S2.E1.m1.1.1.1.1.2.4">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.2.4.2.2.cmml" xref="S2.E1.m1.1.1.1.1.2.4.2.2">𝜃</ci><ci id="S2.E1.m1.1.1.1.1.2.4.2.3.cmml" xref="S2.E1.m1.1.1.1.1.2.4.2.3">𝑘</ci></apply><apply id="S2.E1.m1.1.1.1.1.2.4.3.cmml" xref="S2.E1.m1.1.1.1.1.2.4.3"><minus id="S2.E1.m1.1.1.1.1.2.4.3.1.cmml" xref="S2.E1.m1.1.1.1.1.2.4.3.1"></minus><ci id="S2.E1.m1.1.1.1.1.2.4.3.2.cmml" xref="S2.E1.m1.1.1.1.1.2.4.3.2">𝑡</ci><cn type="integer" id="S2.E1.m1.1.1.1.1.2.4.3.3.cmml" xref="S2.E1.m1.1.1.1.1.2.4.3.3">1</cn></apply></apply><apply id="S2.E1.m1.1.1.1.1.2.2.cmml" xref="S2.E1.m1.1.1.1.1.2.2"><times id="S2.E1.m1.1.1.1.1.2.2.3.cmml" xref="S2.E1.m1.1.1.1.1.2.2.3"></times><ci id="S2.E1.m1.1.1.1.1.2.2.4.cmml" xref="S2.E1.m1.1.1.1.1.2.2.4">𝛼</ci><apply id="S2.E1.m1.1.1.1.1.2.2.5.cmml" xref="S2.E1.m1.1.1.1.1.2.2.5"><apply id="S2.E1.m1.1.1.1.1.2.2.5.1.cmml" xref="S2.E1.m1.1.1.1.1.2.2.5.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.2.2.5.1.1.cmml" xref="S2.E1.m1.1.1.1.1.2.2.5.1">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.2.2.5.1.2.cmml" xref="S2.E1.m1.1.1.1.1.2.2.5.1.2">∇</ci><ci id="S2.E1.m1.1.1.1.1.2.2.5.1.3.cmml" xref="S2.E1.m1.1.1.1.1.2.2.5.1.3">𝜃</ci></apply><apply id="S2.E1.m1.1.1.1.1.2.2.5.2.cmml" xref="S2.E1.m1.1.1.1.1.2.2.5.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.2.2.5.2.1.cmml" xref="S2.E1.m1.1.1.1.1.2.2.5.2">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.2.2.5.2.2.cmml" xref="S2.E1.m1.1.1.1.1.2.2.5.2.2">ℒ</ci><ci id="S2.E1.m1.1.1.1.1.2.2.5.2.3.cmml" xref="S2.E1.m1.1.1.1.1.2.2.5.2.3">𝑘</ci></apply></apply><interval closure="open" id="S2.E1.m1.1.1.1.1.2.2.2.3.cmml" xref="S2.E1.m1.1.1.1.1.2.2.2.2"><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1"><times id="S2.E1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.3"></times><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.4.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.4">𝑓</ci><interval closure="open" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2"><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1">superscript</csymbol><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.2">𝑥</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.1.1.1.3">𝑘</ci></apply><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2">superscript</csymbol><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.2.2">𝜃</ci><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.2.3">𝑘</ci></apply><apply id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.3"><minus id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.3.1.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.3.1"></minus><ci id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.3.2.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.3.2">𝑡</ci><cn type="integer" id="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.3.3.cmml" xref="S2.E1.m1.1.1.1.1.1.1.1.1.1.2.2.2.3.3">1</cn></apply></apply></interval></apply><apply id="S2.E1.m1.1.1.1.1.2.2.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.E1.m1.1.1.1.1.2.2.2.2.2.1.cmml" xref="S2.E1.m1.1.1.1.1.2.2.2.2.2">superscript</csymbol><ci id="S2.E1.m1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S2.E1.m1.1.1.1.1.2.2.2.2.2.2">𝑦</ci><ci id="S2.E1.m1.1.1.1.1.2.2.2.2.2.3.cmml" xref="S2.E1.m1.1.1.1.1.2.2.2.2.2.3">𝑘</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.1c">\theta_{k}^{t}\leftarrow\theta_{k}^{t-1}-\alpha\nabla_{\theta}\mathcal{L}_{k}(f(x^{k},\theta_{k}^{t-1}),y^{k}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S2.I1.i3.p1.5" class="ltx_p">where <math id="S2.I1.i3.p1.3.m1.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S2.I1.i3.p1.3.m1.1a"><mi id="S2.I1.i3.p1.3.m1.1.1" xref="S2.I1.i3.p1.3.m1.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.3.m1.1b"><ci id="S2.I1.i3.p1.3.m1.1.1.cmml" xref="S2.I1.i3.p1.3.m1.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.3.m1.1c">\alpha</annotation></semantics></math> represents the learning rate and <math id="S2.I1.i3.p1.4.m2.1" class="ltx_Math" alttext="\mathcal{L}_{k}(\cdot)" display="inline"><semantics id="S2.I1.i3.p1.4.m2.1a"><mrow id="S2.I1.i3.p1.4.m2.1.2" xref="S2.I1.i3.p1.4.m2.1.2.cmml"><msub id="S2.I1.i3.p1.4.m2.1.2.2" xref="S2.I1.i3.p1.4.m2.1.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.I1.i3.p1.4.m2.1.2.2.2" xref="S2.I1.i3.p1.4.m2.1.2.2.2.cmml">ℒ</mi><mi id="S2.I1.i3.p1.4.m2.1.2.2.3" xref="S2.I1.i3.p1.4.m2.1.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.I1.i3.p1.4.m2.1.2.1" xref="S2.I1.i3.p1.4.m2.1.2.1.cmml">​</mo><mrow id="S2.I1.i3.p1.4.m2.1.2.3.2" xref="S2.I1.i3.p1.4.m2.1.2.cmml"><mo stretchy="false" id="S2.I1.i3.p1.4.m2.1.2.3.2.1" xref="S2.I1.i3.p1.4.m2.1.2.cmml">(</mo><mo lspace="0em" rspace="0em" id="S2.I1.i3.p1.4.m2.1.1" xref="S2.I1.i3.p1.4.m2.1.1.cmml">⋅</mo><mo stretchy="false" id="S2.I1.i3.p1.4.m2.1.2.3.2.2" xref="S2.I1.i3.p1.4.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.4.m2.1b"><apply id="S2.I1.i3.p1.4.m2.1.2.cmml" xref="S2.I1.i3.p1.4.m2.1.2"><times id="S2.I1.i3.p1.4.m2.1.2.1.cmml" xref="S2.I1.i3.p1.4.m2.1.2.1"></times><apply id="S2.I1.i3.p1.4.m2.1.2.2.cmml" xref="S2.I1.i3.p1.4.m2.1.2.2"><csymbol cd="ambiguous" id="S2.I1.i3.p1.4.m2.1.2.2.1.cmml" xref="S2.I1.i3.p1.4.m2.1.2.2">subscript</csymbol><ci id="S2.I1.i3.p1.4.m2.1.2.2.2.cmml" xref="S2.I1.i3.p1.4.m2.1.2.2.2">ℒ</ci><ci id="S2.I1.i3.p1.4.m2.1.2.2.3.cmml" xref="S2.I1.i3.p1.4.m2.1.2.2.3">𝑘</ci></apply><ci id="S2.I1.i3.p1.4.m2.1.1.cmml" xref="S2.I1.i3.p1.4.m2.1.1">⋅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.4.m2.1c">\mathcal{L}_{k}(\cdot)</annotation></semantics></math> denotes the calculated loss for each client <math id="S2.I1.i3.p1.5.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.I1.i3.p1.5.m3.1a"><mi id="S2.I1.i3.p1.5.m3.1.1" xref="S2.I1.i3.p1.5.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.I1.i3.p1.5.m3.1b"><ci id="S2.I1.i3.p1.5.m3.1.1.cmml" xref="S2.I1.i3.p1.5.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i3.p1.5.m3.1c">k</annotation></semantics></math>.</p>
</div>
</li>
<li id="S2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i4.p1" class="ltx_para">
<p id="S2.I1.i4.p1.1" class="ltx_p"><span id="S2.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Model Aggregation.</span> The server calculates the aggregation <math id="S2.I1.i4.p1.1.m1.1" class="ltx_Math" alttext="\sum\nolimits_{k=1}^{K}\frac{N_{k}}{N}\theta_{k}^{t}" display="inline"><semantics id="S2.I1.i4.p1.1.m1.1a"><mrow id="S2.I1.i4.p1.1.m1.1.1" xref="S2.I1.i4.p1.1.m1.1.1.cmml"><msubsup id="S2.I1.i4.p1.1.m1.1.1.1" xref="S2.I1.i4.p1.1.m1.1.1.1.cmml"><mo id="S2.I1.i4.p1.1.m1.1.1.1.2.2" xref="S2.I1.i4.p1.1.m1.1.1.1.2.2.cmml">∑</mo><mrow id="S2.I1.i4.p1.1.m1.1.1.1.2.3" xref="S2.I1.i4.p1.1.m1.1.1.1.2.3.cmml"><mi id="S2.I1.i4.p1.1.m1.1.1.1.2.3.2" xref="S2.I1.i4.p1.1.m1.1.1.1.2.3.2.cmml">k</mi><mo id="S2.I1.i4.p1.1.m1.1.1.1.2.3.1" xref="S2.I1.i4.p1.1.m1.1.1.1.2.3.1.cmml">=</mo><mn id="S2.I1.i4.p1.1.m1.1.1.1.2.3.3" xref="S2.I1.i4.p1.1.m1.1.1.1.2.3.3.cmml">1</mn></mrow><mi id="S2.I1.i4.p1.1.m1.1.1.1.3" xref="S2.I1.i4.p1.1.m1.1.1.1.3.cmml">K</mi></msubsup><mrow id="S2.I1.i4.p1.1.m1.1.1.2" xref="S2.I1.i4.p1.1.m1.1.1.2.cmml"><mfrac id="S2.I1.i4.p1.1.m1.1.1.2.2" xref="S2.I1.i4.p1.1.m1.1.1.2.2.cmml"><msub id="S2.I1.i4.p1.1.m1.1.1.2.2.2" xref="S2.I1.i4.p1.1.m1.1.1.2.2.2.cmml"><mi id="S2.I1.i4.p1.1.m1.1.1.2.2.2.2" xref="S2.I1.i4.p1.1.m1.1.1.2.2.2.2.cmml">N</mi><mi id="S2.I1.i4.p1.1.m1.1.1.2.2.2.3" xref="S2.I1.i4.p1.1.m1.1.1.2.2.2.3.cmml">k</mi></msub><mi id="S2.I1.i4.p1.1.m1.1.1.2.2.3" xref="S2.I1.i4.p1.1.m1.1.1.2.2.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.I1.i4.p1.1.m1.1.1.2.1" xref="S2.I1.i4.p1.1.m1.1.1.2.1.cmml">​</mo><msubsup id="S2.I1.i4.p1.1.m1.1.1.2.3" xref="S2.I1.i4.p1.1.m1.1.1.2.3.cmml"><mi id="S2.I1.i4.p1.1.m1.1.1.2.3.2.2" xref="S2.I1.i4.p1.1.m1.1.1.2.3.2.2.cmml">θ</mi><mi id="S2.I1.i4.p1.1.m1.1.1.2.3.2.3" xref="S2.I1.i4.p1.1.m1.1.1.2.3.2.3.cmml">k</mi><mi id="S2.I1.i4.p1.1.m1.1.1.2.3.3" xref="S2.I1.i4.p1.1.m1.1.1.2.3.3.cmml">t</mi></msubsup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.I1.i4.p1.1.m1.1b"><apply id="S2.I1.i4.p1.1.m1.1.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1"><apply id="S2.I1.i4.p1.1.m1.1.1.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1.1"><csymbol cd="ambiguous" id="S2.I1.i4.p1.1.m1.1.1.1.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1.1">superscript</csymbol><apply id="S2.I1.i4.p1.1.m1.1.1.1.2.cmml" xref="S2.I1.i4.p1.1.m1.1.1.1"><csymbol cd="ambiguous" id="S2.I1.i4.p1.1.m1.1.1.1.2.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1.1">subscript</csymbol><sum id="S2.I1.i4.p1.1.m1.1.1.1.2.2.cmml" xref="S2.I1.i4.p1.1.m1.1.1.1.2.2"></sum><apply id="S2.I1.i4.p1.1.m1.1.1.1.2.3.cmml" xref="S2.I1.i4.p1.1.m1.1.1.1.2.3"><eq id="S2.I1.i4.p1.1.m1.1.1.1.2.3.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1.1.2.3.1"></eq><ci id="S2.I1.i4.p1.1.m1.1.1.1.2.3.2.cmml" xref="S2.I1.i4.p1.1.m1.1.1.1.2.3.2">𝑘</ci><cn type="integer" id="S2.I1.i4.p1.1.m1.1.1.1.2.3.3.cmml" xref="S2.I1.i4.p1.1.m1.1.1.1.2.3.3">1</cn></apply></apply><ci id="S2.I1.i4.p1.1.m1.1.1.1.3.cmml" xref="S2.I1.i4.p1.1.m1.1.1.1.3">𝐾</ci></apply><apply id="S2.I1.i4.p1.1.m1.1.1.2.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2"><times id="S2.I1.i4.p1.1.m1.1.1.2.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2.1"></times><apply id="S2.I1.i4.p1.1.m1.1.1.2.2.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2.2"><divide id="S2.I1.i4.p1.1.m1.1.1.2.2.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2.2"></divide><apply id="S2.I1.i4.p1.1.m1.1.1.2.2.2.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.I1.i4.p1.1.m1.1.1.2.2.2.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2.2.2">subscript</csymbol><ci id="S2.I1.i4.p1.1.m1.1.1.2.2.2.2.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2.2.2.2">𝑁</ci><ci id="S2.I1.i4.p1.1.m1.1.1.2.2.2.3.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2.2.2.3">𝑘</ci></apply><ci id="S2.I1.i4.p1.1.m1.1.1.2.2.3.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2.2.3">𝑁</ci></apply><apply id="S2.I1.i4.p1.1.m1.1.1.2.3.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2.3"><csymbol cd="ambiguous" id="S2.I1.i4.p1.1.m1.1.1.2.3.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2.3">superscript</csymbol><apply id="S2.I1.i4.p1.1.m1.1.1.2.3.2.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2.3"><csymbol cd="ambiguous" id="S2.I1.i4.p1.1.m1.1.1.2.3.2.1.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2.3">subscript</csymbol><ci id="S2.I1.i4.p1.1.m1.1.1.2.3.2.2.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2.3.2.2">𝜃</ci><ci id="S2.I1.i4.p1.1.m1.1.1.2.3.2.3.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2.3.2.3">𝑘</ci></apply><ci id="S2.I1.i4.p1.1.m1.1.1.2.3.3.cmml" xref="S2.I1.i4.p1.1.m1.1.1.2.3.3">𝑡</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.I1.i4.p1.1.m1.1c">\sum\nolimits_{k=1}^{K}\frac{N_{k}}{N}\theta_{k}^{t}</annotation></semantics></math> of the updated client model parameters.</p>
</div>
</li>
<li id="S2.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i5.p1" class="ltx_para">
<p id="S2.I1.i5.p1.1" class="ltx_p"><span id="S2.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Global Update.</span> The server updates the global model for the next epoch based on the aggregated result, as follows:</p>
<table id="S2.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E2.m1.1" class="ltx_Math" alttext="\theta_{global}^{t+1}\leftarrow\sum\nolimits_{k=1}^{K}\frac{N_{k}}{N}\theta_{k}^{t}." display="block"><semantics id="S2.E2.m1.1a"><mrow id="S2.E2.m1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml"><mrow id="S2.E2.m1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.cmml"><msubsup id="S2.E2.m1.1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.2.cmml"><mi id="S2.E2.m1.1.1.1.1.2.2.2" xref="S2.E2.m1.1.1.1.1.2.2.2.cmml">θ</mi><mrow id="S2.E2.m1.1.1.1.1.2.2.3" xref="S2.E2.m1.1.1.1.1.2.2.3.cmml"><mi id="S2.E2.m1.1.1.1.1.2.2.3.2" xref="S2.E2.m1.1.1.1.1.2.2.3.2.cmml">g</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.2.2.3.1" xref="S2.E2.m1.1.1.1.1.2.2.3.1.cmml">​</mo><mi id="S2.E2.m1.1.1.1.1.2.2.3.3" xref="S2.E2.m1.1.1.1.1.2.2.3.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.2.2.3.1a" xref="S2.E2.m1.1.1.1.1.2.2.3.1.cmml">​</mo><mi id="S2.E2.m1.1.1.1.1.2.2.3.4" xref="S2.E2.m1.1.1.1.1.2.2.3.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.2.2.3.1b" xref="S2.E2.m1.1.1.1.1.2.2.3.1.cmml">​</mo><mi id="S2.E2.m1.1.1.1.1.2.2.3.5" xref="S2.E2.m1.1.1.1.1.2.2.3.5.cmml">b</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.2.2.3.1c" xref="S2.E2.m1.1.1.1.1.2.2.3.1.cmml">​</mo><mi id="S2.E2.m1.1.1.1.1.2.2.3.6" xref="S2.E2.m1.1.1.1.1.2.2.3.6.cmml">a</mi><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.2.2.3.1d" xref="S2.E2.m1.1.1.1.1.2.2.3.1.cmml">​</mo><mi id="S2.E2.m1.1.1.1.1.2.2.3.7" xref="S2.E2.m1.1.1.1.1.2.2.3.7.cmml">l</mi></mrow><mrow id="S2.E2.m1.1.1.1.1.2.3" xref="S2.E2.m1.1.1.1.1.2.3.cmml"><mi id="S2.E2.m1.1.1.1.1.2.3.2" xref="S2.E2.m1.1.1.1.1.2.3.2.cmml">t</mi><mo id="S2.E2.m1.1.1.1.1.2.3.1" xref="S2.E2.m1.1.1.1.1.2.3.1.cmml">+</mo><mn id="S2.E2.m1.1.1.1.1.2.3.3" xref="S2.E2.m1.1.1.1.1.2.3.3.cmml">1</mn></mrow></msubsup><mo rspace="0.111em" stretchy="false" id="S2.E2.m1.1.1.1.1.1" xref="S2.E2.m1.1.1.1.1.1.cmml">←</mo><mrow id="S2.E2.m1.1.1.1.1.3" xref="S2.E2.m1.1.1.1.1.3.cmml"><msubsup id="S2.E2.m1.1.1.1.1.3.1" xref="S2.E2.m1.1.1.1.1.3.1.cmml"><mo id="S2.E2.m1.1.1.1.1.3.1.2.2" xref="S2.E2.m1.1.1.1.1.3.1.2.2.cmml">∑</mo><mrow id="S2.E2.m1.1.1.1.1.3.1.2.3" xref="S2.E2.m1.1.1.1.1.3.1.2.3.cmml"><mi id="S2.E2.m1.1.1.1.1.3.1.2.3.2" xref="S2.E2.m1.1.1.1.1.3.1.2.3.2.cmml">k</mi><mo id="S2.E2.m1.1.1.1.1.3.1.2.3.1" xref="S2.E2.m1.1.1.1.1.3.1.2.3.1.cmml">=</mo><mn id="S2.E2.m1.1.1.1.1.3.1.2.3.3" xref="S2.E2.m1.1.1.1.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.E2.m1.1.1.1.1.3.1.3" xref="S2.E2.m1.1.1.1.1.3.1.3.cmml">K</mi></msubsup><mrow id="S2.E2.m1.1.1.1.1.3.2" xref="S2.E2.m1.1.1.1.1.3.2.cmml"><mfrac id="S2.E2.m1.1.1.1.1.3.2.2" xref="S2.E2.m1.1.1.1.1.3.2.2.cmml"><msub id="S2.E2.m1.1.1.1.1.3.2.2.2" xref="S2.E2.m1.1.1.1.1.3.2.2.2.cmml"><mi id="S2.E2.m1.1.1.1.1.3.2.2.2.2" xref="S2.E2.m1.1.1.1.1.3.2.2.2.2.cmml">N</mi><mi id="S2.E2.m1.1.1.1.1.3.2.2.2.3" xref="S2.E2.m1.1.1.1.1.3.2.2.2.3.cmml">k</mi></msub><mi id="S2.E2.m1.1.1.1.1.3.2.2.3" xref="S2.E2.m1.1.1.1.1.3.2.2.3.cmml">N</mi></mfrac><mo lspace="0em" rspace="0em" id="S2.E2.m1.1.1.1.1.3.2.1" xref="S2.E2.m1.1.1.1.1.3.2.1.cmml">​</mo><msubsup id="S2.E2.m1.1.1.1.1.3.2.3" xref="S2.E2.m1.1.1.1.1.3.2.3.cmml"><mi id="S2.E2.m1.1.1.1.1.3.2.3.2.2" xref="S2.E2.m1.1.1.1.1.3.2.3.2.2.cmml">θ</mi><mi id="S2.E2.m1.1.1.1.1.3.2.3.2.3" xref="S2.E2.m1.1.1.1.1.3.2.3.2.3.cmml">k</mi><mi id="S2.E2.m1.1.1.1.1.3.2.3.3" xref="S2.E2.m1.1.1.1.1.3.2.3.3.cmml">t</mi></msubsup></mrow></mrow></mrow><mo lspace="0em" id="S2.E2.m1.1.1.1.2" xref="S2.E2.m1.1.1.1.1.cmml">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.1b"><apply id="S2.E2.m1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1"><ci id="S2.E2.m1.1.1.1.1.1.cmml" xref="S2.E2.m1.1.1.1.1.1">←</ci><apply id="S2.E2.m1.1.1.1.1.2.cmml" xref="S2.E2.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.2.1.cmml" xref="S2.E2.m1.1.1.1.1.2">superscript</csymbol><apply id="S2.E2.m1.1.1.1.1.2.2.cmml" xref="S2.E2.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.2.2.1.cmml" xref="S2.E2.m1.1.1.1.1.2">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.2.2.2.cmml" xref="S2.E2.m1.1.1.1.1.2.2.2">𝜃</ci><apply id="S2.E2.m1.1.1.1.1.2.2.3.cmml" xref="S2.E2.m1.1.1.1.1.2.2.3"><times id="S2.E2.m1.1.1.1.1.2.2.3.1.cmml" xref="S2.E2.m1.1.1.1.1.2.2.3.1"></times><ci id="S2.E2.m1.1.1.1.1.2.2.3.2.cmml" xref="S2.E2.m1.1.1.1.1.2.2.3.2">𝑔</ci><ci id="S2.E2.m1.1.1.1.1.2.2.3.3.cmml" xref="S2.E2.m1.1.1.1.1.2.2.3.3">𝑙</ci><ci id="S2.E2.m1.1.1.1.1.2.2.3.4.cmml" xref="S2.E2.m1.1.1.1.1.2.2.3.4">𝑜</ci><ci id="S2.E2.m1.1.1.1.1.2.2.3.5.cmml" xref="S2.E2.m1.1.1.1.1.2.2.3.5">𝑏</ci><ci id="S2.E2.m1.1.1.1.1.2.2.3.6.cmml" xref="S2.E2.m1.1.1.1.1.2.2.3.6">𝑎</ci><ci id="S2.E2.m1.1.1.1.1.2.2.3.7.cmml" xref="S2.E2.m1.1.1.1.1.2.2.3.7">𝑙</ci></apply></apply><apply id="S2.E2.m1.1.1.1.1.2.3.cmml" xref="S2.E2.m1.1.1.1.1.2.3"><plus id="S2.E2.m1.1.1.1.1.2.3.1.cmml" xref="S2.E2.m1.1.1.1.1.2.3.1"></plus><ci id="S2.E2.m1.1.1.1.1.2.3.2.cmml" xref="S2.E2.m1.1.1.1.1.2.3.2">𝑡</ci><cn type="integer" id="S2.E2.m1.1.1.1.1.2.3.3.cmml" xref="S2.E2.m1.1.1.1.1.2.3.3">1</cn></apply></apply><apply id="S2.E2.m1.1.1.1.1.3.cmml" xref="S2.E2.m1.1.1.1.1.3"><apply id="S2.E2.m1.1.1.1.1.3.1.cmml" xref="S2.E2.m1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.3.1.1.cmml" xref="S2.E2.m1.1.1.1.1.3.1">superscript</csymbol><apply id="S2.E2.m1.1.1.1.1.3.1.2.cmml" xref="S2.E2.m1.1.1.1.1.3.1"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.3.1.2.1.cmml" xref="S2.E2.m1.1.1.1.1.3.1">subscript</csymbol><sum id="S2.E2.m1.1.1.1.1.3.1.2.2.cmml" xref="S2.E2.m1.1.1.1.1.3.1.2.2"></sum><apply id="S2.E2.m1.1.1.1.1.3.1.2.3.cmml" xref="S2.E2.m1.1.1.1.1.3.1.2.3"><eq id="S2.E2.m1.1.1.1.1.3.1.2.3.1.cmml" xref="S2.E2.m1.1.1.1.1.3.1.2.3.1"></eq><ci id="S2.E2.m1.1.1.1.1.3.1.2.3.2.cmml" xref="S2.E2.m1.1.1.1.1.3.1.2.3.2">𝑘</ci><cn type="integer" id="S2.E2.m1.1.1.1.1.3.1.2.3.3.cmml" xref="S2.E2.m1.1.1.1.1.3.1.2.3.3">1</cn></apply></apply><ci id="S2.E2.m1.1.1.1.1.3.1.3.cmml" xref="S2.E2.m1.1.1.1.1.3.1.3">𝐾</ci></apply><apply id="S2.E2.m1.1.1.1.1.3.2.cmml" xref="S2.E2.m1.1.1.1.1.3.2"><times id="S2.E2.m1.1.1.1.1.3.2.1.cmml" xref="S2.E2.m1.1.1.1.1.3.2.1"></times><apply id="S2.E2.m1.1.1.1.1.3.2.2.cmml" xref="S2.E2.m1.1.1.1.1.3.2.2"><divide id="S2.E2.m1.1.1.1.1.3.2.2.1.cmml" xref="S2.E2.m1.1.1.1.1.3.2.2"></divide><apply id="S2.E2.m1.1.1.1.1.3.2.2.2.cmml" xref="S2.E2.m1.1.1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.3.2.2.2.1.cmml" xref="S2.E2.m1.1.1.1.1.3.2.2.2">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.3.2.2.2.2.cmml" xref="S2.E2.m1.1.1.1.1.3.2.2.2.2">𝑁</ci><ci id="S2.E2.m1.1.1.1.1.3.2.2.2.3.cmml" xref="S2.E2.m1.1.1.1.1.3.2.2.2.3">𝑘</ci></apply><ci id="S2.E2.m1.1.1.1.1.3.2.2.3.cmml" xref="S2.E2.m1.1.1.1.1.3.2.2.3">𝑁</ci></apply><apply id="S2.E2.m1.1.1.1.1.3.2.3.cmml" xref="S2.E2.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.3.2.3.1.cmml" xref="S2.E2.m1.1.1.1.1.3.2.3">superscript</csymbol><apply id="S2.E2.m1.1.1.1.1.3.2.3.2.cmml" xref="S2.E2.m1.1.1.1.1.3.2.3"><csymbol cd="ambiguous" id="S2.E2.m1.1.1.1.1.3.2.3.2.1.cmml" xref="S2.E2.m1.1.1.1.1.3.2.3">subscript</csymbol><ci id="S2.E2.m1.1.1.1.1.3.2.3.2.2.cmml" xref="S2.E2.m1.1.1.1.1.3.2.3.2.2">𝜃</ci><ci id="S2.E2.m1.1.1.1.1.3.2.3.2.3.cmml" xref="S2.E2.m1.1.1.1.1.3.2.3.2.3">𝑘</ci></apply><ci id="S2.E2.m1.1.1.1.1.3.2.3.3.cmml" xref="S2.E2.m1.1.1.1.1.3.2.3.3">𝑡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.1c">\theta_{global}^{t+1}\leftarrow\sum\nolimits_{k=1}^{K}\frac{N_{k}}{N}\theta_{k}^{t}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
</div>
</li>
<li id="S2.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i6.p1" class="ltx_para">
<p id="S2.I1.i6.p1.1" class="ltx_p"><span id="S2.I1.i6.p1.1.1" class="ltx_text ltx_font_bold">Model Deployment.</span> The server distributes the global model to the participating clients.</p>
</div>
</li>
</ul>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text" style="color:#000000;">In the cloud-fog-IoT computing environment, federated learning is usually considered as decentralized and multi-layered <cite class="ltx_cite ltx_citemacro_cite">Hosseinalipour et al<span class="ltx_text">.</span> (<a href="#bib.bib78" title="" class="ltx_ref">2020</a>)</cite>, as illustrated in Fig.<a href="#S2.F3" title="Figure 3 ‣ 2. Problems: Research Challenges in Heterogeneous Federated Learning ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. The participants will be divided into different layers according to their roles and capabilities, including the cloud layer, fog layers and IoT layers. The cloud layer is the central server that performs global model aggregation and updates <cite class="ltx_cite ltx_citemacro_cite">Nguyen et al<span class="ltx_text">.</span> (<a href="#bib.bib165" title="" class="ltx_ref">2022a</a>)</cite>. It has high computing and storage capabilities, but the communication cost with edge nodes is also high. The fog layers are intermediate layers composed of multiple edge servers (<span id="S2.p3.1.1.1" class="ltx_text ltx_font_italic">e.g.</span>, base stations) that can communicate with the cloud layer and the IoT layers <cite class="ltx_cite ltx_citemacro_cite">Perera et al<span class="ltx_text">.</span> (<a href="#bib.bib170" title="" class="ltx_ref">2017</a>)</cite>. The IoT layers are composed of edge devices (<span id="S2.p3.1.1.2" class="ltx_text ltx_font_italic">e.g.</span>, smartphones, sensors), performing local model training and communicating with the fog layers. And the IoT devices are allowed to communicate with their neighbors in a peer-to-peer manner <cite class="ltx_cite ltx_citemacro_cite">Lim et al<span class="ltx_text">.</span> (<a href="#bib.bib130" title="" class="ltx_ref">2020</a>)</cite>. Compared with the general federated learning process, the cloud-fog-IoT federated learning introduces the middle layer of the fog server between the cloud server and the IoT device <cite class="ltx_cite ltx_citemacro_cite">Liu et al<span class="ltx_text">.</span> (<a href="#bib.bib135" title="" class="ltx_ref">2020b</a>)</cite>. Therefore, there will be an additional step of model distribution and model aggregation in the fog layers, which can relieve the communication pressure between the cloud layer and the IoT layers <cite class="ltx_cite ltx_citemacro_cite">Qu et al<span class="ltx_text">.</span> (<a href="#bib.bib175" title="" class="ltx_ref">2020</a>)</cite>. In addition, the cloud-fog-IoT systems have greater flexibility and adaptability in handling various heterogeneities in federated learning.</span></p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1. </span>Statistical Heterogeneity</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.6" class="ltx_p"><span id="S2.SS1.p1.6.1" class="ltx_text" style="color:#000000;">Statistical heterogeneity refers to the case where the data distribution across clients in federated learning is inconsistent and does not obey the same sampling, <span id="S2.SS1.p1.6.1.1" class="ltx_text ltx_font_italic">i.e.</span>, Non-IID.</span> To explore the difficulties of the statistical heterogeneity with the Non-IID phenomenon, we classify statistical heterogeneity from a distribution perspective <cite class="ltx_cite ltx_citemacro_cite">Kairouz et al<span class="ltx_text">.</span> (<a href="#bib.bib97" title="" class="ltx_ref">2019</a>); Li et al<span class="ltx_text">.</span> (<a href="#bib.bib118" title="" class="ltx_ref">2021a</a>)</cite>. Specifically, we distinguish different categories of Non-IID data in terms of four different skew patterns as shown in Fig. <a href="#S2.F4" title="Figure 4 ‣ 2.1. Statistical Heterogeneity ‣ 2. Problems: Research Challenges in Heterogeneous Federated Learning ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, including label skew, feature skew, quality skew, and quantity skew. We define two different clients <math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mi id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><ci id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">i</annotation></semantics></math> and <math id="S2.SS1.p1.2.m2.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S2.SS1.p1.2.m2.1a"><mi id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><ci id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">j</annotation></semantics></math>. Therefore, the local data distribution of client <math id="S2.SS1.p1.3.m3.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS1.p1.3.m3.1a"><mi id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><ci id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">i</annotation></semantics></math> is denoted as <math id="S2.SS1.p1.4.m4.2" class="ltx_Math" alttext="P_{i}(x,y)" display="inline"><semantics id="S2.SS1.p1.4.m4.2a"><mrow id="S2.SS1.p1.4.m4.2.3" xref="S2.SS1.p1.4.m4.2.3.cmml"><msub id="S2.SS1.p1.4.m4.2.3.2" xref="S2.SS1.p1.4.m4.2.3.2.cmml"><mi id="S2.SS1.p1.4.m4.2.3.2.2" xref="S2.SS1.p1.4.m4.2.3.2.2.cmml">P</mi><mi id="S2.SS1.p1.4.m4.2.3.2.3" xref="S2.SS1.p1.4.m4.2.3.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p1.4.m4.2.3.1" xref="S2.SS1.p1.4.m4.2.3.1.cmml">​</mo><mrow id="S2.SS1.p1.4.m4.2.3.3.2" xref="S2.SS1.p1.4.m4.2.3.3.1.cmml"><mo stretchy="false" id="S2.SS1.p1.4.m4.2.3.3.2.1" xref="S2.SS1.p1.4.m4.2.3.3.1.cmml">(</mo><mi id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml">x</mi><mo id="S2.SS1.p1.4.m4.2.3.3.2.2" xref="S2.SS1.p1.4.m4.2.3.3.1.cmml">,</mo><mi id="S2.SS1.p1.4.m4.2.2" xref="S2.SS1.p1.4.m4.2.2.cmml">y</mi><mo stretchy="false" id="S2.SS1.p1.4.m4.2.3.3.2.3" xref="S2.SS1.p1.4.m4.2.3.3.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.2b"><apply id="S2.SS1.p1.4.m4.2.3.cmml" xref="S2.SS1.p1.4.m4.2.3"><times id="S2.SS1.p1.4.m4.2.3.1.cmml" xref="S2.SS1.p1.4.m4.2.3.1"></times><apply id="S2.SS1.p1.4.m4.2.3.2.cmml" xref="S2.SS1.p1.4.m4.2.3.2"><csymbol cd="ambiguous" id="S2.SS1.p1.4.m4.2.3.2.1.cmml" xref="S2.SS1.p1.4.m4.2.3.2">subscript</csymbol><ci id="S2.SS1.p1.4.m4.2.3.2.2.cmml" xref="S2.SS1.p1.4.m4.2.3.2.2">𝑃</ci><ci id="S2.SS1.p1.4.m4.2.3.2.3.cmml" xref="S2.SS1.p1.4.m4.2.3.2.3">𝑖</ci></apply><interval closure="open" id="S2.SS1.p1.4.m4.2.3.3.1.cmml" xref="S2.SS1.p1.4.m4.2.3.3.2"><ci id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1">𝑥</ci><ci id="S2.SS1.p1.4.m4.2.2.cmml" xref="S2.SS1.p1.4.m4.2.2">𝑦</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.2c">P_{i}(x,y)</annotation></semantics></math>, where <math id="S2.SS1.p1.5.m5.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.SS1.p1.5.m5.1a"><mi id="S2.SS1.p1.5.m5.1.1" xref="S2.SS1.p1.5.m5.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.1b"><ci id="S2.SS1.p1.5.m5.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.1c">x</annotation></semantics></math> and <math id="S2.SS1.p1.6.m6.1" class="ltx_Math" alttext="y" display="inline"><semantics id="S2.SS1.p1.6.m6.1a"><mi id="S2.SS1.p1.6.m6.1.1" xref="S2.SS1.p1.6.m6.1.1.cmml">y</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m6.1b"><ci id="S2.SS1.p1.6.m6.1.1.cmml" xref="S2.SS1.p1.6.m6.1.1">𝑦</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m6.1c">y</annotation></semantics></math> represent the features and labels of the data samples, respectively. <span id="S2.SS1.p1.6.2" class="ltx_text" style="color:#000000;">Numerous studies <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib125" title="" class="ltx_ref">2020d</a>, <a href="#bib.bib118" title="" class="ltx_ref">2021a</a>); Karimireddy et al<span class="ltx_text">.</span> (<a href="#bib.bib100" title="" class="ltx_ref">2020</a>)</cite> indicate that the local optimization objectives of the clients are inconsistent with the global optimization objective due to the differences in the local data distribution of the clients. Therefore, statistical heterogeneity may cause local models to converge in different directions, reaching local optima rather than global optima, thus degrading the federated learning performance, which might be even worse than the local learning stage without federated communication.</span></p>
</div>
<figure id="S2.F4" class="ltx_figure"><img src="/html/2307.10616/assets/x4.png" id="S2.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="205" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4. </span><span id="S2.F4.2.1" class="ltx_text" style="font-size:90%;">Illustration of four different skew patterns in statistical heterogeneity.</span></figcaption>
</figure>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p"><span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_bold">Label Skew.</span> It means that the label distributions across participating clients are different.
This phenomenon is commonly encountered in practical applications in which the data collection or annotation is inconsistent. To characterize the various label skew scenarios, we introduce two different settings: <span id="S2.SS1.p2.1.2" class="ltx_text ltx_font_italic">label distribution skew</span> <cite class="ltx_cite ltx_citemacro_cite">Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib244" title="" class="ltx_ref">2022c</a>)</cite> and <span id="S2.SS1.p2.1.3" class="ltx_text ltx_font_italic">label preference skew</span> <cite class="ltx_cite ltx_citemacro_cite">Kairouz et al<span class="ltx_text">.</span> (<a href="#bib.bib97" title="" class="ltx_ref">2019</a>)</cite>. A visual example is illustrated in Fig. <a href="#S2.F4" title="Figure 4 ‣ 2.1. Statistical Heterogeneity ‣ 2. Problems: Research Challenges in Heterogeneous Federated Learning ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>(a).</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.2" class="ltx_p"><span id="S2.SS1.p3.2.1" class="ltx_text ltx_font_italic">Label distribution skew</span> indicates that the label distributions may be different for different clients, <span id="S2.SS1.p3.2.2" class="ltx_text ltx_font_italic">i.e.</span>, <math id="S2.SS1.p3.1.m1.2" class="ltx_Math" alttext="P_{i}(y)\neq P_{j}(y)" display="inline"><semantics id="S2.SS1.p3.1.m1.2a"><mrow id="S2.SS1.p3.1.m1.2.3" xref="S2.SS1.p3.1.m1.2.3.cmml"><mrow id="S2.SS1.p3.1.m1.2.3.2" xref="S2.SS1.p3.1.m1.2.3.2.cmml"><msub id="S2.SS1.p3.1.m1.2.3.2.2" xref="S2.SS1.p3.1.m1.2.3.2.2.cmml"><mi id="S2.SS1.p3.1.m1.2.3.2.2.2" xref="S2.SS1.p3.1.m1.2.3.2.2.2.cmml">P</mi><mi id="S2.SS1.p3.1.m1.2.3.2.2.3" xref="S2.SS1.p3.1.m1.2.3.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p3.1.m1.2.3.2.1" xref="S2.SS1.p3.1.m1.2.3.2.1.cmml">​</mo><mrow id="S2.SS1.p3.1.m1.2.3.2.3.2" xref="S2.SS1.p3.1.m1.2.3.2.cmml"><mo stretchy="false" id="S2.SS1.p3.1.m1.2.3.2.3.2.1" xref="S2.SS1.p3.1.m1.2.3.2.cmml">(</mo><mi id="S2.SS1.p3.1.m1.1.1" xref="S2.SS1.p3.1.m1.1.1.cmml">y</mi><mo stretchy="false" id="S2.SS1.p3.1.m1.2.3.2.3.2.2" xref="S2.SS1.p3.1.m1.2.3.2.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p3.1.m1.2.3.1" xref="S2.SS1.p3.1.m1.2.3.1.cmml">≠</mo><mrow id="S2.SS1.p3.1.m1.2.3.3" xref="S2.SS1.p3.1.m1.2.3.3.cmml"><msub id="S2.SS1.p3.1.m1.2.3.3.2" xref="S2.SS1.p3.1.m1.2.3.3.2.cmml"><mi id="S2.SS1.p3.1.m1.2.3.3.2.2" xref="S2.SS1.p3.1.m1.2.3.3.2.2.cmml">P</mi><mi id="S2.SS1.p3.1.m1.2.3.3.2.3" xref="S2.SS1.p3.1.m1.2.3.3.2.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p3.1.m1.2.3.3.1" xref="S2.SS1.p3.1.m1.2.3.3.1.cmml">​</mo><mrow id="S2.SS1.p3.1.m1.2.3.3.3.2" xref="S2.SS1.p3.1.m1.2.3.3.cmml"><mo stretchy="false" id="S2.SS1.p3.1.m1.2.3.3.3.2.1" xref="S2.SS1.p3.1.m1.2.3.3.cmml">(</mo><mi id="S2.SS1.p3.1.m1.2.2" xref="S2.SS1.p3.1.m1.2.2.cmml">y</mi><mo stretchy="false" id="S2.SS1.p3.1.m1.2.3.3.3.2.2" xref="S2.SS1.p3.1.m1.2.3.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.2b"><apply id="S2.SS1.p3.1.m1.2.3.cmml" xref="S2.SS1.p3.1.m1.2.3"><neq id="S2.SS1.p3.1.m1.2.3.1.cmml" xref="S2.SS1.p3.1.m1.2.3.1"></neq><apply id="S2.SS1.p3.1.m1.2.3.2.cmml" xref="S2.SS1.p3.1.m1.2.3.2"><times id="S2.SS1.p3.1.m1.2.3.2.1.cmml" xref="S2.SS1.p3.1.m1.2.3.2.1"></times><apply id="S2.SS1.p3.1.m1.2.3.2.2.cmml" xref="S2.SS1.p3.1.m1.2.3.2.2"><csymbol cd="ambiguous" id="S2.SS1.p3.1.m1.2.3.2.2.1.cmml" xref="S2.SS1.p3.1.m1.2.3.2.2">subscript</csymbol><ci id="S2.SS1.p3.1.m1.2.3.2.2.2.cmml" xref="S2.SS1.p3.1.m1.2.3.2.2.2">𝑃</ci><ci id="S2.SS1.p3.1.m1.2.3.2.2.3.cmml" xref="S2.SS1.p3.1.m1.2.3.2.2.3">𝑖</ci></apply><ci id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1">𝑦</ci></apply><apply id="S2.SS1.p3.1.m1.2.3.3.cmml" xref="S2.SS1.p3.1.m1.2.3.3"><times id="S2.SS1.p3.1.m1.2.3.3.1.cmml" xref="S2.SS1.p3.1.m1.2.3.3.1"></times><apply id="S2.SS1.p3.1.m1.2.3.3.2.cmml" xref="S2.SS1.p3.1.m1.2.3.3.2"><csymbol cd="ambiguous" id="S2.SS1.p3.1.m1.2.3.3.2.1.cmml" xref="S2.SS1.p3.1.m1.2.3.3.2">subscript</csymbol><ci id="S2.SS1.p3.1.m1.2.3.3.2.2.cmml" xref="S2.SS1.p3.1.m1.2.3.3.2.2">𝑃</ci><ci id="S2.SS1.p3.1.m1.2.3.3.2.3.cmml" xref="S2.SS1.p3.1.m1.2.3.3.2.3">𝑗</ci></apply><ci id="S2.SS1.p3.1.m1.2.2.cmml" xref="S2.SS1.p3.1.m1.2.2">𝑦</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.2c">P_{i}(y)\neq P_{j}(y)</annotation></semantics></math>, even if the feature distribution is shared <span id="S2.SS1.p3.2.3" class="ltx_text" style="color:#000000;">(the features of the data samples are similar for each label, regardless of which client they belong to)</span>, <span id="S2.SS1.p3.2.4" class="ltx_text ltx_font_italic">i.e.</span>, <math id="S2.SS1.p3.2.m2.2" class="ltx_Math" alttext="P_{i}(x|y)=P_{j}(x|y)" display="inline"><semantics id="S2.SS1.p3.2.m2.2a"><mrow id="S2.SS1.p3.2.m2.2.2" xref="S2.SS1.p3.2.m2.2.2.cmml"><mrow id="S2.SS1.p3.2.m2.1.1.1" xref="S2.SS1.p3.2.m2.1.1.1.cmml"><msub id="S2.SS1.p3.2.m2.1.1.1.3" xref="S2.SS1.p3.2.m2.1.1.1.3.cmml"><mi id="S2.SS1.p3.2.m2.1.1.1.3.2" xref="S2.SS1.p3.2.m2.1.1.1.3.2.cmml">P</mi><mi id="S2.SS1.p3.2.m2.1.1.1.3.3" xref="S2.SS1.p3.2.m2.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p3.2.m2.1.1.1.2" xref="S2.SS1.p3.2.m2.1.1.1.2.cmml">​</mo><mrow id="S2.SS1.p3.2.m2.1.1.1.1.1" xref="S2.SS1.p3.2.m2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p3.2.m2.1.1.1.1.1.2" xref="S2.SS1.p3.2.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS1.p3.2.m2.1.1.1.1.1.1" xref="S2.SS1.p3.2.m2.1.1.1.1.1.1.cmml"><mi id="S2.SS1.p3.2.m2.1.1.1.1.1.1.2" xref="S2.SS1.p3.2.m2.1.1.1.1.1.1.2.cmml">x</mi><mo fence="false" id="S2.SS1.p3.2.m2.1.1.1.1.1.1.1" xref="S2.SS1.p3.2.m2.1.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS1.p3.2.m2.1.1.1.1.1.1.3" xref="S2.SS1.p3.2.m2.1.1.1.1.1.1.3.cmml">y</mi></mrow><mo stretchy="false" id="S2.SS1.p3.2.m2.1.1.1.1.1.3" xref="S2.SS1.p3.2.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p3.2.m2.2.2.3" xref="S2.SS1.p3.2.m2.2.2.3.cmml">=</mo><mrow id="S2.SS1.p3.2.m2.2.2.2" xref="S2.SS1.p3.2.m2.2.2.2.cmml"><msub id="S2.SS1.p3.2.m2.2.2.2.3" xref="S2.SS1.p3.2.m2.2.2.2.3.cmml"><mi id="S2.SS1.p3.2.m2.2.2.2.3.2" xref="S2.SS1.p3.2.m2.2.2.2.3.2.cmml">P</mi><mi id="S2.SS1.p3.2.m2.2.2.2.3.3" xref="S2.SS1.p3.2.m2.2.2.2.3.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p3.2.m2.2.2.2.2" xref="S2.SS1.p3.2.m2.2.2.2.2.cmml">​</mo><mrow id="S2.SS1.p3.2.m2.2.2.2.1.1" xref="S2.SS1.p3.2.m2.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p3.2.m2.2.2.2.1.1.2" xref="S2.SS1.p3.2.m2.2.2.2.1.1.1.cmml">(</mo><mrow id="S2.SS1.p3.2.m2.2.2.2.1.1.1" xref="S2.SS1.p3.2.m2.2.2.2.1.1.1.cmml"><mi id="S2.SS1.p3.2.m2.2.2.2.1.1.1.2" xref="S2.SS1.p3.2.m2.2.2.2.1.1.1.2.cmml">x</mi><mo fence="false" id="S2.SS1.p3.2.m2.2.2.2.1.1.1.1" xref="S2.SS1.p3.2.m2.2.2.2.1.1.1.1.cmml">|</mo><mi id="S2.SS1.p3.2.m2.2.2.2.1.1.1.3" xref="S2.SS1.p3.2.m2.2.2.2.1.1.1.3.cmml">y</mi></mrow><mo stretchy="false" id="S2.SS1.p3.2.m2.2.2.2.1.1.3" xref="S2.SS1.p3.2.m2.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.2.m2.2b"><apply id="S2.SS1.p3.2.m2.2.2.cmml" xref="S2.SS1.p3.2.m2.2.2"><eq id="S2.SS1.p3.2.m2.2.2.3.cmml" xref="S2.SS1.p3.2.m2.2.2.3"></eq><apply id="S2.SS1.p3.2.m2.1.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1.1"><times id="S2.SS1.p3.2.m2.1.1.1.2.cmml" xref="S2.SS1.p3.2.m2.1.1.1.2"></times><apply id="S2.SS1.p3.2.m2.1.1.1.3.cmml" xref="S2.SS1.p3.2.m2.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p3.2.m2.1.1.1.3.1.cmml" xref="S2.SS1.p3.2.m2.1.1.1.3">subscript</csymbol><ci id="S2.SS1.p3.2.m2.1.1.1.3.2.cmml" xref="S2.SS1.p3.2.m2.1.1.1.3.2">𝑃</ci><ci id="S2.SS1.p3.2.m2.1.1.1.3.3.cmml" xref="S2.SS1.p3.2.m2.1.1.1.3.3">𝑖</ci></apply><apply id="S2.SS1.p3.2.m2.1.1.1.1.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1.1.1.1"><csymbol cd="latexml" id="S2.SS1.p3.2.m2.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS1.p3.2.m2.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p3.2.m2.1.1.1.1.1.1.2">𝑥</ci><ci id="S2.SS1.p3.2.m2.1.1.1.1.1.1.3.cmml" xref="S2.SS1.p3.2.m2.1.1.1.1.1.1.3">𝑦</ci></apply></apply><apply id="S2.SS1.p3.2.m2.2.2.2.cmml" xref="S2.SS1.p3.2.m2.2.2.2"><times id="S2.SS1.p3.2.m2.2.2.2.2.cmml" xref="S2.SS1.p3.2.m2.2.2.2.2"></times><apply id="S2.SS1.p3.2.m2.2.2.2.3.cmml" xref="S2.SS1.p3.2.m2.2.2.2.3"><csymbol cd="ambiguous" id="S2.SS1.p3.2.m2.2.2.2.3.1.cmml" xref="S2.SS1.p3.2.m2.2.2.2.3">subscript</csymbol><ci id="S2.SS1.p3.2.m2.2.2.2.3.2.cmml" xref="S2.SS1.p3.2.m2.2.2.2.3.2">𝑃</ci><ci id="S2.SS1.p3.2.m2.2.2.2.3.3.cmml" xref="S2.SS1.p3.2.m2.2.2.2.3.3">𝑗</ci></apply><apply id="S2.SS1.p3.2.m2.2.2.2.1.1.1.cmml" xref="S2.SS1.p3.2.m2.2.2.2.1.1"><csymbol cd="latexml" id="S2.SS1.p3.2.m2.2.2.2.1.1.1.1.cmml" xref="S2.SS1.p3.2.m2.2.2.2.1.1.1.1">conditional</csymbol><ci id="S2.SS1.p3.2.m2.2.2.2.1.1.1.2.cmml" xref="S2.SS1.p3.2.m2.2.2.2.1.1.1.2">𝑥</ci><ci id="S2.SS1.p3.2.m2.2.2.2.1.1.1.3.cmml" xref="S2.SS1.p3.2.m2.2.2.2.1.1.1.3">𝑦</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.2.m2.2c">P_{i}(x|y)=P_{j}(x|y)</annotation></semantics></math>. For example, in handwriting number recognition, different users may contain different numbers.</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<p id="S2.SS1.p4.2" class="ltx_p"><span id="S2.SS1.p4.2.1" class="ltx_text ltx_font_italic">Label preference skew</span> implies that even when the feature distribution is consistent across clients, <span id="S2.SS1.p4.2.2" class="ltx_text ltx_font_italic">i.e.</span>, <math id="S2.SS1.p4.1.m1.2" class="ltx_Math" alttext="P_{i}(x)=P_{j}(x)" display="inline"><semantics id="S2.SS1.p4.1.m1.2a"><mrow id="S2.SS1.p4.1.m1.2.3" xref="S2.SS1.p4.1.m1.2.3.cmml"><mrow id="S2.SS1.p4.1.m1.2.3.2" xref="S2.SS1.p4.1.m1.2.3.2.cmml"><msub id="S2.SS1.p4.1.m1.2.3.2.2" xref="S2.SS1.p4.1.m1.2.3.2.2.cmml"><mi id="S2.SS1.p4.1.m1.2.3.2.2.2" xref="S2.SS1.p4.1.m1.2.3.2.2.2.cmml">P</mi><mi id="S2.SS1.p4.1.m1.2.3.2.2.3" xref="S2.SS1.p4.1.m1.2.3.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p4.1.m1.2.3.2.1" xref="S2.SS1.p4.1.m1.2.3.2.1.cmml">​</mo><mrow id="S2.SS1.p4.1.m1.2.3.2.3.2" xref="S2.SS1.p4.1.m1.2.3.2.cmml"><mo stretchy="false" id="S2.SS1.p4.1.m1.2.3.2.3.2.1" xref="S2.SS1.p4.1.m1.2.3.2.cmml">(</mo><mi id="S2.SS1.p4.1.m1.1.1" xref="S2.SS1.p4.1.m1.1.1.cmml">x</mi><mo stretchy="false" id="S2.SS1.p4.1.m1.2.3.2.3.2.2" xref="S2.SS1.p4.1.m1.2.3.2.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p4.1.m1.2.3.1" xref="S2.SS1.p4.1.m1.2.3.1.cmml">=</mo><mrow id="S2.SS1.p4.1.m1.2.3.3" xref="S2.SS1.p4.1.m1.2.3.3.cmml"><msub id="S2.SS1.p4.1.m1.2.3.3.2" xref="S2.SS1.p4.1.m1.2.3.3.2.cmml"><mi id="S2.SS1.p4.1.m1.2.3.3.2.2" xref="S2.SS1.p4.1.m1.2.3.3.2.2.cmml">P</mi><mi id="S2.SS1.p4.1.m1.2.3.3.2.3" xref="S2.SS1.p4.1.m1.2.3.3.2.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p4.1.m1.2.3.3.1" xref="S2.SS1.p4.1.m1.2.3.3.1.cmml">​</mo><mrow id="S2.SS1.p4.1.m1.2.3.3.3.2" xref="S2.SS1.p4.1.m1.2.3.3.cmml"><mo stretchy="false" id="S2.SS1.p4.1.m1.2.3.3.3.2.1" xref="S2.SS1.p4.1.m1.2.3.3.cmml">(</mo><mi id="S2.SS1.p4.1.m1.2.2" xref="S2.SS1.p4.1.m1.2.2.cmml">x</mi><mo stretchy="false" id="S2.SS1.p4.1.m1.2.3.3.3.2.2" xref="S2.SS1.p4.1.m1.2.3.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.1.m1.2b"><apply id="S2.SS1.p4.1.m1.2.3.cmml" xref="S2.SS1.p4.1.m1.2.3"><eq id="S2.SS1.p4.1.m1.2.3.1.cmml" xref="S2.SS1.p4.1.m1.2.3.1"></eq><apply id="S2.SS1.p4.1.m1.2.3.2.cmml" xref="S2.SS1.p4.1.m1.2.3.2"><times id="S2.SS1.p4.1.m1.2.3.2.1.cmml" xref="S2.SS1.p4.1.m1.2.3.2.1"></times><apply id="S2.SS1.p4.1.m1.2.3.2.2.cmml" xref="S2.SS1.p4.1.m1.2.3.2.2"><csymbol cd="ambiguous" id="S2.SS1.p4.1.m1.2.3.2.2.1.cmml" xref="S2.SS1.p4.1.m1.2.3.2.2">subscript</csymbol><ci id="S2.SS1.p4.1.m1.2.3.2.2.2.cmml" xref="S2.SS1.p4.1.m1.2.3.2.2.2">𝑃</ci><ci id="S2.SS1.p4.1.m1.2.3.2.2.3.cmml" xref="S2.SS1.p4.1.m1.2.3.2.2.3">𝑖</ci></apply><ci id="S2.SS1.p4.1.m1.1.1.cmml" xref="S2.SS1.p4.1.m1.1.1">𝑥</ci></apply><apply id="S2.SS1.p4.1.m1.2.3.3.cmml" xref="S2.SS1.p4.1.m1.2.3.3"><times id="S2.SS1.p4.1.m1.2.3.3.1.cmml" xref="S2.SS1.p4.1.m1.2.3.3.1"></times><apply id="S2.SS1.p4.1.m1.2.3.3.2.cmml" xref="S2.SS1.p4.1.m1.2.3.3.2"><csymbol cd="ambiguous" id="S2.SS1.p4.1.m1.2.3.3.2.1.cmml" xref="S2.SS1.p4.1.m1.2.3.3.2">subscript</csymbol><ci id="S2.SS1.p4.1.m1.2.3.3.2.2.cmml" xref="S2.SS1.p4.1.m1.2.3.3.2.2">𝑃</ci><ci id="S2.SS1.p4.1.m1.2.3.3.2.3.cmml" xref="S2.SS1.p4.1.m1.2.3.3.2.3">𝑗</ci></apply><ci id="S2.SS1.p4.1.m1.2.2.cmml" xref="S2.SS1.p4.1.m1.2.2">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.1.m1.2c">P_{i}(x)=P_{j}(x)</annotation></semantics></math>, the label distribution may be different for different clients, <span id="S2.SS1.p4.2.3" class="ltx_text ltx_font_italic">i.e.</span>, <math id="S2.SS1.p4.2.m2.2" class="ltx_Math" alttext="P_{i}(y|x)\neq P_{j}(y|x)" display="inline"><semantics id="S2.SS1.p4.2.m2.2a"><mrow id="S2.SS1.p4.2.m2.2.2" xref="S2.SS1.p4.2.m2.2.2.cmml"><mrow id="S2.SS1.p4.2.m2.1.1.1" xref="S2.SS1.p4.2.m2.1.1.1.cmml"><msub id="S2.SS1.p4.2.m2.1.1.1.3" xref="S2.SS1.p4.2.m2.1.1.1.3.cmml"><mi id="S2.SS1.p4.2.m2.1.1.1.3.2" xref="S2.SS1.p4.2.m2.1.1.1.3.2.cmml">P</mi><mi id="S2.SS1.p4.2.m2.1.1.1.3.3" xref="S2.SS1.p4.2.m2.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p4.2.m2.1.1.1.2" xref="S2.SS1.p4.2.m2.1.1.1.2.cmml">​</mo><mrow id="S2.SS1.p4.2.m2.1.1.1.1.1" xref="S2.SS1.p4.2.m2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p4.2.m2.1.1.1.1.1.2" xref="S2.SS1.p4.2.m2.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS1.p4.2.m2.1.1.1.1.1.1" xref="S2.SS1.p4.2.m2.1.1.1.1.1.1.cmml"><mi id="S2.SS1.p4.2.m2.1.1.1.1.1.1.2" xref="S2.SS1.p4.2.m2.1.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S2.SS1.p4.2.m2.1.1.1.1.1.1.1" xref="S2.SS1.p4.2.m2.1.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS1.p4.2.m2.1.1.1.1.1.1.3" xref="S2.SS1.p4.2.m2.1.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S2.SS1.p4.2.m2.1.1.1.1.1.3" xref="S2.SS1.p4.2.m2.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p4.2.m2.2.2.3" xref="S2.SS1.p4.2.m2.2.2.3.cmml">≠</mo><mrow id="S2.SS1.p4.2.m2.2.2.2" xref="S2.SS1.p4.2.m2.2.2.2.cmml"><msub id="S2.SS1.p4.2.m2.2.2.2.3" xref="S2.SS1.p4.2.m2.2.2.2.3.cmml"><mi id="S2.SS1.p4.2.m2.2.2.2.3.2" xref="S2.SS1.p4.2.m2.2.2.2.3.2.cmml">P</mi><mi id="S2.SS1.p4.2.m2.2.2.2.3.3" xref="S2.SS1.p4.2.m2.2.2.2.3.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p4.2.m2.2.2.2.2" xref="S2.SS1.p4.2.m2.2.2.2.2.cmml">​</mo><mrow id="S2.SS1.p4.2.m2.2.2.2.1.1" xref="S2.SS1.p4.2.m2.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p4.2.m2.2.2.2.1.1.2" xref="S2.SS1.p4.2.m2.2.2.2.1.1.1.cmml">(</mo><mrow id="S2.SS1.p4.2.m2.2.2.2.1.1.1" xref="S2.SS1.p4.2.m2.2.2.2.1.1.1.cmml"><mi id="S2.SS1.p4.2.m2.2.2.2.1.1.1.2" xref="S2.SS1.p4.2.m2.2.2.2.1.1.1.2.cmml">y</mi><mo fence="false" id="S2.SS1.p4.2.m2.2.2.2.1.1.1.1" xref="S2.SS1.p4.2.m2.2.2.2.1.1.1.1.cmml">|</mo><mi id="S2.SS1.p4.2.m2.2.2.2.1.1.1.3" xref="S2.SS1.p4.2.m2.2.2.2.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S2.SS1.p4.2.m2.2.2.2.1.1.3" xref="S2.SS1.p4.2.m2.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p4.2.m2.2b"><apply id="S2.SS1.p4.2.m2.2.2.cmml" xref="S2.SS1.p4.2.m2.2.2"><neq id="S2.SS1.p4.2.m2.2.2.3.cmml" xref="S2.SS1.p4.2.m2.2.2.3"></neq><apply id="S2.SS1.p4.2.m2.1.1.1.cmml" xref="S2.SS1.p4.2.m2.1.1.1"><times id="S2.SS1.p4.2.m2.1.1.1.2.cmml" xref="S2.SS1.p4.2.m2.1.1.1.2"></times><apply id="S2.SS1.p4.2.m2.1.1.1.3.cmml" xref="S2.SS1.p4.2.m2.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p4.2.m2.1.1.1.3.1.cmml" xref="S2.SS1.p4.2.m2.1.1.1.3">subscript</csymbol><ci id="S2.SS1.p4.2.m2.1.1.1.3.2.cmml" xref="S2.SS1.p4.2.m2.1.1.1.3.2">𝑃</ci><ci id="S2.SS1.p4.2.m2.1.1.1.3.3.cmml" xref="S2.SS1.p4.2.m2.1.1.1.3.3">𝑖</ci></apply><apply id="S2.SS1.p4.2.m2.1.1.1.1.1.1.cmml" xref="S2.SS1.p4.2.m2.1.1.1.1.1"><csymbol cd="latexml" id="S2.SS1.p4.2.m2.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p4.2.m2.1.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS1.p4.2.m2.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p4.2.m2.1.1.1.1.1.1.2">𝑦</ci><ci id="S2.SS1.p4.2.m2.1.1.1.1.1.1.3.cmml" xref="S2.SS1.p4.2.m2.1.1.1.1.1.1.3">𝑥</ci></apply></apply><apply id="S2.SS1.p4.2.m2.2.2.2.cmml" xref="S2.SS1.p4.2.m2.2.2.2"><times id="S2.SS1.p4.2.m2.2.2.2.2.cmml" xref="S2.SS1.p4.2.m2.2.2.2.2"></times><apply id="S2.SS1.p4.2.m2.2.2.2.3.cmml" xref="S2.SS1.p4.2.m2.2.2.2.3"><csymbol cd="ambiguous" id="S2.SS1.p4.2.m2.2.2.2.3.1.cmml" xref="S2.SS1.p4.2.m2.2.2.2.3">subscript</csymbol><ci id="S2.SS1.p4.2.m2.2.2.2.3.2.cmml" xref="S2.SS1.p4.2.m2.2.2.2.3.2">𝑃</ci><ci id="S2.SS1.p4.2.m2.2.2.2.3.3.cmml" xref="S2.SS1.p4.2.m2.2.2.2.3.3">𝑗</ci></apply><apply id="S2.SS1.p4.2.m2.2.2.2.1.1.1.cmml" xref="S2.SS1.p4.2.m2.2.2.2.1.1"><csymbol cd="latexml" id="S2.SS1.p4.2.m2.2.2.2.1.1.1.1.cmml" xref="S2.SS1.p4.2.m2.2.2.2.1.1.1.1">conditional</csymbol><ci id="S2.SS1.p4.2.m2.2.2.2.1.1.1.2.cmml" xref="S2.SS1.p4.2.m2.2.2.2.1.1.1.2">𝑦</ci><ci id="S2.SS1.p4.2.m2.2.2.2.1.1.1.3.cmml" xref="S2.SS1.p4.2.m2.2.2.2.1.1.1.3">𝑥</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p4.2.m2.2c">P_{i}(y|x)\neq P_{j}(y|x)</annotation></semantics></math>. The local training datasets of different clients may overlap horizontally, leading to label preference skew, <span id="S2.SS1.p4.2.4" class="ltx_text ltx_font_italic">i.e.</span>, the same features have different labels. That is, different clients may annotate the same data samples with different labels owing to individual annotation preferences.
For example, for a visual intent understanding task <cite class="ltx_cite ltx_citemacro_cite">Jia et al<span class="ltx_text">.</span> (<a href="#bib.bib94" title="" class="ltx_ref">2021</a>)</cite>, the same image may be annotated with different labels according to the personal preferences of users.</p>
</div>
<div id="S2.SS1.p5" class="ltx_para">
<p id="S2.SS1.p5.1" class="ltx_p"><span id="S2.SS1.p5.1.1" class="ltx_text ltx_font_bold">Feature Skew.</span> It refers to the scenario that the feature distributions across participant clients are different.
This phenomenon often occurs in complex real-world environments, implying that the feature distribution of local data on individual clients may be significantly different <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib118" title="" class="ltx_ref">2021a</a>); Luo et al<span class="ltx_text">.</span> (<a href="#bib.bib141" title="" class="ltx_ref">2022</a>)</cite>. Feature skew can be divided into the following two settings, which are shown in Fig. <a href="#S2.F4" title="Figure 4 ‣ 2.1. Statistical Heterogeneity ‣ 2. Problems: Research Challenges in Heterogeneous Federated Learning ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>(b):</p>
</div>
<div id="S2.SS1.p6" class="ltx_para">
<p id="S2.SS1.p6.2" class="ltx_p"><span id="S2.SS1.p6.2.1" class="ltx_text ltx_font_italic">Feature distribution skew</span> implies that the label distribution is consistent, <span id="S2.SS1.p6.2.2" class="ltx_text ltx_font_italic">i.e.</span>, <math id="S2.SS1.p6.1.m1.2" class="ltx_Math" alttext="P_{i}(y|x)=P_{j}(y|x)" display="inline"><semantics id="S2.SS1.p6.1.m1.2a"><mrow id="S2.SS1.p6.1.m1.2.2" xref="S2.SS1.p6.1.m1.2.2.cmml"><mrow id="S2.SS1.p6.1.m1.1.1.1" xref="S2.SS1.p6.1.m1.1.1.1.cmml"><msub id="S2.SS1.p6.1.m1.1.1.1.3" xref="S2.SS1.p6.1.m1.1.1.1.3.cmml"><mi id="S2.SS1.p6.1.m1.1.1.1.3.2" xref="S2.SS1.p6.1.m1.1.1.1.3.2.cmml">P</mi><mi id="S2.SS1.p6.1.m1.1.1.1.3.3" xref="S2.SS1.p6.1.m1.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p6.1.m1.1.1.1.2" xref="S2.SS1.p6.1.m1.1.1.1.2.cmml">​</mo><mrow id="S2.SS1.p6.1.m1.1.1.1.1.1" xref="S2.SS1.p6.1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p6.1.m1.1.1.1.1.1.2" xref="S2.SS1.p6.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS1.p6.1.m1.1.1.1.1.1.1" xref="S2.SS1.p6.1.m1.1.1.1.1.1.1.cmml"><mi id="S2.SS1.p6.1.m1.1.1.1.1.1.1.2" xref="S2.SS1.p6.1.m1.1.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S2.SS1.p6.1.m1.1.1.1.1.1.1.1" xref="S2.SS1.p6.1.m1.1.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS1.p6.1.m1.1.1.1.1.1.1.3" xref="S2.SS1.p6.1.m1.1.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S2.SS1.p6.1.m1.1.1.1.1.1.3" xref="S2.SS1.p6.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p6.1.m1.2.2.3" xref="S2.SS1.p6.1.m1.2.2.3.cmml">=</mo><mrow id="S2.SS1.p6.1.m1.2.2.2" xref="S2.SS1.p6.1.m1.2.2.2.cmml"><msub id="S2.SS1.p6.1.m1.2.2.2.3" xref="S2.SS1.p6.1.m1.2.2.2.3.cmml"><mi id="S2.SS1.p6.1.m1.2.2.2.3.2" xref="S2.SS1.p6.1.m1.2.2.2.3.2.cmml">P</mi><mi id="S2.SS1.p6.1.m1.2.2.2.3.3" xref="S2.SS1.p6.1.m1.2.2.2.3.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p6.1.m1.2.2.2.2" xref="S2.SS1.p6.1.m1.2.2.2.2.cmml">​</mo><mrow id="S2.SS1.p6.1.m1.2.2.2.1.1" xref="S2.SS1.p6.1.m1.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p6.1.m1.2.2.2.1.1.2" xref="S2.SS1.p6.1.m1.2.2.2.1.1.1.cmml">(</mo><mrow id="S2.SS1.p6.1.m1.2.2.2.1.1.1" xref="S2.SS1.p6.1.m1.2.2.2.1.1.1.cmml"><mi id="S2.SS1.p6.1.m1.2.2.2.1.1.1.2" xref="S2.SS1.p6.1.m1.2.2.2.1.1.1.2.cmml">y</mi><mo fence="false" id="S2.SS1.p6.1.m1.2.2.2.1.1.1.1" xref="S2.SS1.p6.1.m1.2.2.2.1.1.1.1.cmml">|</mo><mi id="S2.SS1.p6.1.m1.2.2.2.1.1.1.3" xref="S2.SS1.p6.1.m1.2.2.2.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S2.SS1.p6.1.m1.2.2.2.1.1.3" xref="S2.SS1.p6.1.m1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.1.m1.2b"><apply id="S2.SS1.p6.1.m1.2.2.cmml" xref="S2.SS1.p6.1.m1.2.2"><eq id="S2.SS1.p6.1.m1.2.2.3.cmml" xref="S2.SS1.p6.1.m1.2.2.3"></eq><apply id="S2.SS1.p6.1.m1.1.1.1.cmml" xref="S2.SS1.p6.1.m1.1.1.1"><times id="S2.SS1.p6.1.m1.1.1.1.2.cmml" xref="S2.SS1.p6.1.m1.1.1.1.2"></times><apply id="S2.SS1.p6.1.m1.1.1.1.3.cmml" xref="S2.SS1.p6.1.m1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p6.1.m1.1.1.1.3.1.cmml" xref="S2.SS1.p6.1.m1.1.1.1.3">subscript</csymbol><ci id="S2.SS1.p6.1.m1.1.1.1.3.2.cmml" xref="S2.SS1.p6.1.m1.1.1.1.3.2">𝑃</ci><ci id="S2.SS1.p6.1.m1.1.1.1.3.3.cmml" xref="S2.SS1.p6.1.m1.1.1.1.3.3">𝑖</ci></apply><apply id="S2.SS1.p6.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS1.p6.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S2.SS1.p6.1.m1.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p6.1.m1.1.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS1.p6.1.m1.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p6.1.m1.1.1.1.1.1.1.2">𝑦</ci><ci id="S2.SS1.p6.1.m1.1.1.1.1.1.1.3.cmml" xref="S2.SS1.p6.1.m1.1.1.1.1.1.1.3">𝑥</ci></apply></apply><apply id="S2.SS1.p6.1.m1.2.2.2.cmml" xref="S2.SS1.p6.1.m1.2.2.2"><times id="S2.SS1.p6.1.m1.2.2.2.2.cmml" xref="S2.SS1.p6.1.m1.2.2.2.2"></times><apply id="S2.SS1.p6.1.m1.2.2.2.3.cmml" xref="S2.SS1.p6.1.m1.2.2.2.3"><csymbol cd="ambiguous" id="S2.SS1.p6.1.m1.2.2.2.3.1.cmml" xref="S2.SS1.p6.1.m1.2.2.2.3">subscript</csymbol><ci id="S2.SS1.p6.1.m1.2.2.2.3.2.cmml" xref="S2.SS1.p6.1.m1.2.2.2.3.2">𝑃</ci><ci id="S2.SS1.p6.1.m1.2.2.2.3.3.cmml" xref="S2.SS1.p6.1.m1.2.2.2.3.3">𝑗</ci></apply><apply id="S2.SS1.p6.1.m1.2.2.2.1.1.1.cmml" xref="S2.SS1.p6.1.m1.2.2.2.1.1"><csymbol cd="latexml" id="S2.SS1.p6.1.m1.2.2.2.1.1.1.1.cmml" xref="S2.SS1.p6.1.m1.2.2.2.1.1.1.1">conditional</csymbol><ci id="S2.SS1.p6.1.m1.2.2.2.1.1.1.2.cmml" xref="S2.SS1.p6.1.m1.2.2.2.1.1.1.2">𝑦</ci><ci id="S2.SS1.p6.1.m1.2.2.2.1.1.1.3.cmml" xref="S2.SS1.p6.1.m1.2.2.2.1.1.1.3">𝑥</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.1.m1.2c">P_{i}(y|x)=P_{j}(y|x)</annotation></semantics></math>, but the feature distribution may be different, <span id="S2.SS1.p6.2.3" class="ltx_text ltx_font_italic">i.e.</span>, <math id="S2.SS1.p6.2.m2.2" class="ltx_Math" alttext="P_{i}(x)\neq P_{j}(x)" display="inline"><semantics id="S2.SS1.p6.2.m2.2a"><mrow id="S2.SS1.p6.2.m2.2.3" xref="S2.SS1.p6.2.m2.2.3.cmml"><mrow id="S2.SS1.p6.2.m2.2.3.2" xref="S2.SS1.p6.2.m2.2.3.2.cmml"><msub id="S2.SS1.p6.2.m2.2.3.2.2" xref="S2.SS1.p6.2.m2.2.3.2.2.cmml"><mi id="S2.SS1.p6.2.m2.2.3.2.2.2" xref="S2.SS1.p6.2.m2.2.3.2.2.2.cmml">P</mi><mi id="S2.SS1.p6.2.m2.2.3.2.2.3" xref="S2.SS1.p6.2.m2.2.3.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p6.2.m2.2.3.2.1" xref="S2.SS1.p6.2.m2.2.3.2.1.cmml">​</mo><mrow id="S2.SS1.p6.2.m2.2.3.2.3.2" xref="S2.SS1.p6.2.m2.2.3.2.cmml"><mo stretchy="false" id="S2.SS1.p6.2.m2.2.3.2.3.2.1" xref="S2.SS1.p6.2.m2.2.3.2.cmml">(</mo><mi id="S2.SS1.p6.2.m2.1.1" xref="S2.SS1.p6.2.m2.1.1.cmml">x</mi><mo stretchy="false" id="S2.SS1.p6.2.m2.2.3.2.3.2.2" xref="S2.SS1.p6.2.m2.2.3.2.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p6.2.m2.2.3.1" xref="S2.SS1.p6.2.m2.2.3.1.cmml">≠</mo><mrow id="S2.SS1.p6.2.m2.2.3.3" xref="S2.SS1.p6.2.m2.2.3.3.cmml"><msub id="S2.SS1.p6.2.m2.2.3.3.2" xref="S2.SS1.p6.2.m2.2.3.3.2.cmml"><mi id="S2.SS1.p6.2.m2.2.3.3.2.2" xref="S2.SS1.p6.2.m2.2.3.3.2.2.cmml">P</mi><mi id="S2.SS1.p6.2.m2.2.3.3.2.3" xref="S2.SS1.p6.2.m2.2.3.3.2.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p6.2.m2.2.3.3.1" xref="S2.SS1.p6.2.m2.2.3.3.1.cmml">​</mo><mrow id="S2.SS1.p6.2.m2.2.3.3.3.2" xref="S2.SS1.p6.2.m2.2.3.3.cmml"><mo stretchy="false" id="S2.SS1.p6.2.m2.2.3.3.3.2.1" xref="S2.SS1.p6.2.m2.2.3.3.cmml">(</mo><mi id="S2.SS1.p6.2.m2.2.2" xref="S2.SS1.p6.2.m2.2.2.cmml">x</mi><mo stretchy="false" id="S2.SS1.p6.2.m2.2.3.3.3.2.2" xref="S2.SS1.p6.2.m2.2.3.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p6.2.m2.2b"><apply id="S2.SS1.p6.2.m2.2.3.cmml" xref="S2.SS1.p6.2.m2.2.3"><neq id="S2.SS1.p6.2.m2.2.3.1.cmml" xref="S2.SS1.p6.2.m2.2.3.1"></neq><apply id="S2.SS1.p6.2.m2.2.3.2.cmml" xref="S2.SS1.p6.2.m2.2.3.2"><times id="S2.SS1.p6.2.m2.2.3.2.1.cmml" xref="S2.SS1.p6.2.m2.2.3.2.1"></times><apply id="S2.SS1.p6.2.m2.2.3.2.2.cmml" xref="S2.SS1.p6.2.m2.2.3.2.2"><csymbol cd="ambiguous" id="S2.SS1.p6.2.m2.2.3.2.2.1.cmml" xref="S2.SS1.p6.2.m2.2.3.2.2">subscript</csymbol><ci id="S2.SS1.p6.2.m2.2.3.2.2.2.cmml" xref="S2.SS1.p6.2.m2.2.3.2.2.2">𝑃</ci><ci id="S2.SS1.p6.2.m2.2.3.2.2.3.cmml" xref="S2.SS1.p6.2.m2.2.3.2.2.3">𝑖</ci></apply><ci id="S2.SS1.p6.2.m2.1.1.cmml" xref="S2.SS1.p6.2.m2.1.1">𝑥</ci></apply><apply id="S2.SS1.p6.2.m2.2.3.3.cmml" xref="S2.SS1.p6.2.m2.2.3.3"><times id="S2.SS1.p6.2.m2.2.3.3.1.cmml" xref="S2.SS1.p6.2.m2.2.3.3.1"></times><apply id="S2.SS1.p6.2.m2.2.3.3.2.cmml" xref="S2.SS1.p6.2.m2.2.3.3.2"><csymbol cd="ambiguous" id="S2.SS1.p6.2.m2.2.3.3.2.1.cmml" xref="S2.SS1.p6.2.m2.2.3.3.2">subscript</csymbol><ci id="S2.SS1.p6.2.m2.2.3.3.2.2.cmml" xref="S2.SS1.p6.2.m2.2.3.3.2.2">𝑃</ci><ci id="S2.SS1.p6.2.m2.2.3.3.2.3.cmml" xref="S2.SS1.p6.2.m2.2.3.3.2.3">𝑗</ci></apply><ci id="S2.SS1.p6.2.m2.2.2.cmml" xref="S2.SS1.p6.2.m2.2.2">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p6.2.m2.2c">P_{i}(x)\neq P_{j}(x)</annotation></semantics></math>. For instance, in handwriting number recognition, different users may write the same number with different styles, stroke thicknesses, etc.</p>
</div>
<div id="S2.SS1.p7" class="ltx_para">
<p id="S2.SS1.p7.2" class="ltx_p"><span id="S2.SS1.p7.2.1" class="ltx_text ltx_font_italic">Feature condition skew</span> means that the feature distributions may vary across clients, <span id="S2.SS1.p7.2.2" class="ltx_text ltx_font_italic">i.e.</span>, <math id="S2.SS1.p7.1.m1.2" class="ltx_Math" alttext="P_{i}(x|y)\neq P_{j}(x|y)" display="inline"><semantics id="S2.SS1.p7.1.m1.2a"><mrow id="S2.SS1.p7.1.m1.2.2" xref="S2.SS1.p7.1.m1.2.2.cmml"><mrow id="S2.SS1.p7.1.m1.1.1.1" xref="S2.SS1.p7.1.m1.1.1.1.cmml"><msub id="S2.SS1.p7.1.m1.1.1.1.3" xref="S2.SS1.p7.1.m1.1.1.1.3.cmml"><mi id="S2.SS1.p7.1.m1.1.1.1.3.2" xref="S2.SS1.p7.1.m1.1.1.1.3.2.cmml">P</mi><mi id="S2.SS1.p7.1.m1.1.1.1.3.3" xref="S2.SS1.p7.1.m1.1.1.1.3.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p7.1.m1.1.1.1.2" xref="S2.SS1.p7.1.m1.1.1.1.2.cmml">​</mo><mrow id="S2.SS1.p7.1.m1.1.1.1.1.1" xref="S2.SS1.p7.1.m1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p7.1.m1.1.1.1.1.1.2" xref="S2.SS1.p7.1.m1.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS1.p7.1.m1.1.1.1.1.1.1" xref="S2.SS1.p7.1.m1.1.1.1.1.1.1.cmml"><mi id="S2.SS1.p7.1.m1.1.1.1.1.1.1.2" xref="S2.SS1.p7.1.m1.1.1.1.1.1.1.2.cmml">x</mi><mo fence="false" id="S2.SS1.p7.1.m1.1.1.1.1.1.1.1" xref="S2.SS1.p7.1.m1.1.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS1.p7.1.m1.1.1.1.1.1.1.3" xref="S2.SS1.p7.1.m1.1.1.1.1.1.1.3.cmml">y</mi></mrow><mo stretchy="false" id="S2.SS1.p7.1.m1.1.1.1.1.1.3" xref="S2.SS1.p7.1.m1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p7.1.m1.2.2.3" xref="S2.SS1.p7.1.m1.2.2.3.cmml">≠</mo><mrow id="S2.SS1.p7.1.m1.2.2.2" xref="S2.SS1.p7.1.m1.2.2.2.cmml"><msub id="S2.SS1.p7.1.m1.2.2.2.3" xref="S2.SS1.p7.1.m1.2.2.2.3.cmml"><mi id="S2.SS1.p7.1.m1.2.2.2.3.2" xref="S2.SS1.p7.1.m1.2.2.2.3.2.cmml">P</mi><mi id="S2.SS1.p7.1.m1.2.2.2.3.3" xref="S2.SS1.p7.1.m1.2.2.2.3.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p7.1.m1.2.2.2.2" xref="S2.SS1.p7.1.m1.2.2.2.2.cmml">​</mo><mrow id="S2.SS1.p7.1.m1.2.2.2.1.1" xref="S2.SS1.p7.1.m1.2.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p7.1.m1.2.2.2.1.1.2" xref="S2.SS1.p7.1.m1.2.2.2.1.1.1.cmml">(</mo><mrow id="S2.SS1.p7.1.m1.2.2.2.1.1.1" xref="S2.SS1.p7.1.m1.2.2.2.1.1.1.cmml"><mi id="S2.SS1.p7.1.m1.2.2.2.1.1.1.2" xref="S2.SS1.p7.1.m1.2.2.2.1.1.1.2.cmml">x</mi><mo fence="false" id="S2.SS1.p7.1.m1.2.2.2.1.1.1.1" xref="S2.SS1.p7.1.m1.2.2.2.1.1.1.1.cmml">|</mo><mi id="S2.SS1.p7.1.m1.2.2.2.1.1.1.3" xref="S2.SS1.p7.1.m1.2.2.2.1.1.1.3.cmml">y</mi></mrow><mo stretchy="false" id="S2.SS1.p7.1.m1.2.2.2.1.1.3" xref="S2.SS1.p7.1.m1.2.2.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p7.1.m1.2b"><apply id="S2.SS1.p7.1.m1.2.2.cmml" xref="S2.SS1.p7.1.m1.2.2"><neq id="S2.SS1.p7.1.m1.2.2.3.cmml" xref="S2.SS1.p7.1.m1.2.2.3"></neq><apply id="S2.SS1.p7.1.m1.1.1.1.cmml" xref="S2.SS1.p7.1.m1.1.1.1"><times id="S2.SS1.p7.1.m1.1.1.1.2.cmml" xref="S2.SS1.p7.1.m1.1.1.1.2"></times><apply id="S2.SS1.p7.1.m1.1.1.1.3.cmml" xref="S2.SS1.p7.1.m1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p7.1.m1.1.1.1.3.1.cmml" xref="S2.SS1.p7.1.m1.1.1.1.3">subscript</csymbol><ci id="S2.SS1.p7.1.m1.1.1.1.3.2.cmml" xref="S2.SS1.p7.1.m1.1.1.1.3.2">𝑃</ci><ci id="S2.SS1.p7.1.m1.1.1.1.3.3.cmml" xref="S2.SS1.p7.1.m1.1.1.1.3.3">𝑖</ci></apply><apply id="S2.SS1.p7.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS1.p7.1.m1.1.1.1.1.1"><csymbol cd="latexml" id="S2.SS1.p7.1.m1.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p7.1.m1.1.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS1.p7.1.m1.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p7.1.m1.1.1.1.1.1.1.2">𝑥</ci><ci id="S2.SS1.p7.1.m1.1.1.1.1.1.1.3.cmml" xref="S2.SS1.p7.1.m1.1.1.1.1.1.1.3">𝑦</ci></apply></apply><apply id="S2.SS1.p7.1.m1.2.2.2.cmml" xref="S2.SS1.p7.1.m1.2.2.2"><times id="S2.SS1.p7.1.m1.2.2.2.2.cmml" xref="S2.SS1.p7.1.m1.2.2.2.2"></times><apply id="S2.SS1.p7.1.m1.2.2.2.3.cmml" xref="S2.SS1.p7.1.m1.2.2.2.3"><csymbol cd="ambiguous" id="S2.SS1.p7.1.m1.2.2.2.3.1.cmml" xref="S2.SS1.p7.1.m1.2.2.2.3">subscript</csymbol><ci id="S2.SS1.p7.1.m1.2.2.2.3.2.cmml" xref="S2.SS1.p7.1.m1.2.2.2.3.2">𝑃</ci><ci id="S2.SS1.p7.1.m1.2.2.2.3.3.cmml" xref="S2.SS1.p7.1.m1.2.2.2.3.3">𝑗</ci></apply><apply id="S2.SS1.p7.1.m1.2.2.2.1.1.1.cmml" xref="S2.SS1.p7.1.m1.2.2.2.1.1"><csymbol cd="latexml" id="S2.SS1.p7.1.m1.2.2.2.1.1.1.1.cmml" xref="S2.SS1.p7.1.m1.2.2.2.1.1.1.1">conditional</csymbol><ci id="S2.SS1.p7.1.m1.2.2.2.1.1.1.2.cmml" xref="S2.SS1.p7.1.m1.2.2.2.1.1.1.2">𝑥</ci><ci id="S2.SS1.p7.1.m1.2.2.2.1.1.1.3.cmml" xref="S2.SS1.p7.1.m1.2.2.2.1.1.1.3">𝑦</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p7.1.m1.2c">P_{i}(x|y)\neq P_{j}(x|y)</annotation></semantics></math>, even if <math id="S2.SS1.p7.2.m2.2" class="ltx_Math" alttext="P_{i}(y)=P_{j}(y)" display="inline"><semantics id="S2.SS1.p7.2.m2.2a"><mrow id="S2.SS1.p7.2.m2.2.3" xref="S2.SS1.p7.2.m2.2.3.cmml"><mrow id="S2.SS1.p7.2.m2.2.3.2" xref="S2.SS1.p7.2.m2.2.3.2.cmml"><msub id="S2.SS1.p7.2.m2.2.3.2.2" xref="S2.SS1.p7.2.m2.2.3.2.2.cmml"><mi id="S2.SS1.p7.2.m2.2.3.2.2.2" xref="S2.SS1.p7.2.m2.2.3.2.2.2.cmml">P</mi><mi id="S2.SS1.p7.2.m2.2.3.2.2.3" xref="S2.SS1.p7.2.m2.2.3.2.2.3.cmml">i</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p7.2.m2.2.3.2.1" xref="S2.SS1.p7.2.m2.2.3.2.1.cmml">​</mo><mrow id="S2.SS1.p7.2.m2.2.3.2.3.2" xref="S2.SS1.p7.2.m2.2.3.2.cmml"><mo stretchy="false" id="S2.SS1.p7.2.m2.2.3.2.3.2.1" xref="S2.SS1.p7.2.m2.2.3.2.cmml">(</mo><mi id="S2.SS1.p7.2.m2.1.1" xref="S2.SS1.p7.2.m2.1.1.cmml">y</mi><mo stretchy="false" id="S2.SS1.p7.2.m2.2.3.2.3.2.2" xref="S2.SS1.p7.2.m2.2.3.2.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p7.2.m2.2.3.1" xref="S2.SS1.p7.2.m2.2.3.1.cmml">=</mo><mrow id="S2.SS1.p7.2.m2.2.3.3" xref="S2.SS1.p7.2.m2.2.3.3.cmml"><msub id="S2.SS1.p7.2.m2.2.3.3.2" xref="S2.SS1.p7.2.m2.2.3.3.2.cmml"><mi id="S2.SS1.p7.2.m2.2.3.3.2.2" xref="S2.SS1.p7.2.m2.2.3.3.2.2.cmml">P</mi><mi id="S2.SS1.p7.2.m2.2.3.3.2.3" xref="S2.SS1.p7.2.m2.2.3.3.2.3.cmml">j</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p7.2.m2.2.3.3.1" xref="S2.SS1.p7.2.m2.2.3.3.1.cmml">​</mo><mrow id="S2.SS1.p7.2.m2.2.3.3.3.2" xref="S2.SS1.p7.2.m2.2.3.3.cmml"><mo stretchy="false" id="S2.SS1.p7.2.m2.2.3.3.3.2.1" xref="S2.SS1.p7.2.m2.2.3.3.cmml">(</mo><mi id="S2.SS1.p7.2.m2.2.2" xref="S2.SS1.p7.2.m2.2.2.cmml">y</mi><mo stretchy="false" id="S2.SS1.p7.2.m2.2.3.3.3.2.2" xref="S2.SS1.p7.2.m2.2.3.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p7.2.m2.2b"><apply id="S2.SS1.p7.2.m2.2.3.cmml" xref="S2.SS1.p7.2.m2.2.3"><eq id="S2.SS1.p7.2.m2.2.3.1.cmml" xref="S2.SS1.p7.2.m2.2.3.1"></eq><apply id="S2.SS1.p7.2.m2.2.3.2.cmml" xref="S2.SS1.p7.2.m2.2.3.2"><times id="S2.SS1.p7.2.m2.2.3.2.1.cmml" xref="S2.SS1.p7.2.m2.2.3.2.1"></times><apply id="S2.SS1.p7.2.m2.2.3.2.2.cmml" xref="S2.SS1.p7.2.m2.2.3.2.2"><csymbol cd="ambiguous" id="S2.SS1.p7.2.m2.2.3.2.2.1.cmml" xref="S2.SS1.p7.2.m2.2.3.2.2">subscript</csymbol><ci id="S2.SS1.p7.2.m2.2.3.2.2.2.cmml" xref="S2.SS1.p7.2.m2.2.3.2.2.2">𝑃</ci><ci id="S2.SS1.p7.2.m2.2.3.2.2.3.cmml" xref="S2.SS1.p7.2.m2.2.3.2.2.3">𝑖</ci></apply><ci id="S2.SS1.p7.2.m2.1.1.cmml" xref="S2.SS1.p7.2.m2.1.1">𝑦</ci></apply><apply id="S2.SS1.p7.2.m2.2.3.3.cmml" xref="S2.SS1.p7.2.m2.2.3.3"><times id="S2.SS1.p7.2.m2.2.3.3.1.cmml" xref="S2.SS1.p7.2.m2.2.3.3.1"></times><apply id="S2.SS1.p7.2.m2.2.3.3.2.cmml" xref="S2.SS1.p7.2.m2.2.3.3.2"><csymbol cd="ambiguous" id="S2.SS1.p7.2.m2.2.3.3.2.1.cmml" xref="S2.SS1.p7.2.m2.2.3.3.2">subscript</csymbol><ci id="S2.SS1.p7.2.m2.2.3.3.2.2.cmml" xref="S2.SS1.p7.2.m2.2.3.3.2.2">𝑃</ci><ci id="S2.SS1.p7.2.m2.2.3.3.2.3.cmml" xref="S2.SS1.p7.2.m2.2.3.3.2.3">𝑗</ci></apply><ci id="S2.SS1.p7.2.m2.2.2.cmml" xref="S2.SS1.p7.2.m2.2.2">𝑦</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p7.2.m2.2c">P_{i}(y)=P_{j}(y)</annotation></semantics></math>. The data features across clients may not fully overlap, and this situation is mainly related to vertical federated learning <cite class="ltx_cite ltx_citemacro_cite">Chen et al<span class="ltx_text">.</span> (<a href="#bib.bib28" title="" class="ltx_ref">2020a</a>)</cite>, which is commonly performed in medical applications.
<span id="S2.SS1.p7.2.3" class="ltx_text" style="color:#000000;">For example, when individual clients link regions, the Japan region contains a large number of Shiba Inu samples, while the Siberia region contains a large number of Husky samples, but their labels are all dogs.</span></p>
</div>
<div id="S2.SS1.p8" class="ltx_para">
<p id="S2.SS1.p8.1" class="ltx_p"><span id="S2.SS1.p8.1.1" class="ltx_text ltx_font_bold">Quality Skew.</span> It demonstrates that the annotation or data collection qualities are inconsistent for different clients.
In general, federated learning typically involves a large number of clients, each of whom may have different data synthesis capabilities. There is no guarantee that all clients have data samples of the same quality, and they may hold unequal proportions of noisy data <cite class="ltx_cite ltx_citemacro_cite">Yang et al<span class="ltx_text">.</span> (<a href="#bib.bib228" title="" class="ltx_ref">2020</a>)</cite>. Therefore, we divide the quality skew into label noise skew and sample noise skew, as shown in Fig. <a href="#S2.F4" title="Figure 4 ‣ 2.1. Statistical Heterogeneity ‣ 2. Problems: Research Challenges in Heterogeneous Federated Learning ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>(c).</p>
</div>
<div id="S2.SS1.p9" class="ltx_para">
<p id="S2.SS1.p9.1" class="ltx_p"><span id="S2.SS1.p9.1.1" class="ltx_text ltx_font_italic">Label noise skew</span> represents that the proportion of noisy labels contained differs across clients. Owing to the differences in expertise and input costs, the quality of data annotations tends to vary widely across clients, which means that clients contain data with varying degrees of label noise. This challenge intensifies when the architectures of participating clients are different since the decision boundaries are inconsistent.</p>
</div>
<div id="S2.SS1.p10" class="ltx_para">
<p id="S2.SS1.p10.1" class="ltx_p"><span id="S2.SS1.p10.1.1" class="ltx_text ltx_font_italic">Sample noise skew</span> refers that each client holds private data with different qualities, where the data collection process inevitably introduces varying levels of sample noise. Owing to differences in the abilities of clients to synthesize and collect data, several clients may collect data containing redundant or noisy information, which makes communication across different clients uncertain and complex.</p>
</div>
<div id="S2.SS1.p11" class="ltx_para">
<p id="S2.SS1.p11.1" class="ltx_p"><span id="S2.SS1.p11.1.1" class="ltx_text ltx_font_bold">Quantity Skew.</span>
It means that the amount of local data may be extremely unbalanced across clients <cite class="ltx_cite ltx_citemacro_cite">Zhu et al<span class="ltx_text">.</span> (<a href="#bib.bib255" title="" class="ltx_ref">2021b</a>)</cite>, <span id="S2.SS1.p11.1.2" class="ltx_text ltx_font_italic">i.e.</span>, long-tail distributed data <cite class="ltx_cite ltx_citemacro_cite">Shang et al<span class="ltx_text">.</span> (<a href="#bib.bib185" title="" class="ltx_ref">2022</a>)</cite>. An example is illustrated in Fig. <a href="#S2.F4" title="Figure 4 ‣ 2.1. Statistical Heterogeneity ‣ 2. Problems: Research Challenges in Heterogeneous Federated Learning ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>(d). In such a situation, several clients may have problems with data scarcity <cite class="ltx_cite ltx_citemacro_cite">Huang et al<span class="ltx_text">.</span> (<a href="#bib.bib87" title="" class="ltx_ref">2022c</a>)</cite>, which reinforces the need for federated learning. However, existing methods cannot adaptively balance the contribution of each client in the server aggregation process.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2. </span>Model Heterogeneity</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">In the widely-studied federated learning paradigm, each participating client is required to use a local model with the same architecture. Thus the network parameters of the local model can be aggregated into a global model on the server side. In practical IoT applications, each client may expect to design their own local model architecture in a unique manner owing to differences in individual requirements and hardware constraints <cite class="ltx_cite ltx_citemacro_cite">Wu et al<span class="ltx_text">.</span> (<a href="#bib.bib217" title="" class="ltx_ref">2020a</a>)</cite>. Additionally, clients are often reluctant to reveal or share the details of model design, as they wish to safeguard their commercial proprietary information and privacy. For example, when healthcare institutions conduct collaborative learning without sharing patient information, they may design models with different structures to meet the properties of different tasks. Therefore, model heterogeneous federated learning requires learning knowledge from others without sharing private data or disclosing local model structure information. <span id="S2.SS2.p1.1.1" class="ltx_text" style="color:#000000;">The main challenge of model heterogeneity would be the difficulty of transferring knowledge between model heterogeneous clients in a model-agnostic manner.</span> To this end, we categorize model heterogeneity into partial heterogeneity and complete heterogeneity.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p"><span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_bold">Partial Heterogeneity.</span>
It is commonly encountered in real-life scenarios, where some of the clients are using the same model structure while others do not. When client subsets are divided based on the local model structure, at least one client subset is expected to have no less than two elements <cite class="ltx_cite ltx_citemacro_cite">Sattler et al<span class="ltx_text">.</span> (<a href="#bib.bib181" title="" class="ltx_ref">2020b</a>)</cite>. In this analysis, we consider the federated system to be a partial model heterogeneity. A federated learning model needs to be trained for each client subset whose models are isomorphic. Through the clustering algorithms, participating clients can be divided into many clusters, <span id="S2.SS2.p2.1.2" class="ltx_text ltx_font_italic">i.e.,</span> the structures are the same within each cluster. <span id="S2.SS2.p2.1.3" class="ltx_text" style="color:#000000;">Therefore, some common techniques, such as weighted averaging of model parameters, can be directly used to realize the aggregation of intra-cluster models. However, the communication of inter-cluster models requires the design of some special techniques, such as knowledge distillation.</span></p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p"><span id="S2.SS2.p3.1.1" class="ltx_text ltx_font_bold">Complete Heterogeneity.</span>
It is a special case of partial heterogeneity, in which all the network structures of participant models are completely different in the federated learning framework. Complete model heterogeneity occurs when the individual clients in a federated system have local model structures that differ from each other <cite class="ltx_cite ltx_citemacro_cite">Smith et al<span class="ltx_text">.</span> (<a href="#bib.bib192" title="" class="ltx_ref">2017</a>)</cite>. In this context, it is necessary to learn a unique model for each client, which can better handle different data distributions but may eventually lead to high learning costs and low communication efficiency. Ensuring communication between complete heterogeneous models is challenging because the widely-used network parameter aggregation or gradient operations cannot be performed.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3. </span>Communication Heterogeneity</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.1" class="ltx_p"><span id="S2.SS3.p1.1.1" class="ltx_text" style="color:#000000;">In practical IoT applications, the devices are typically deployed in different network environments and have different network connectivity settings (3G, 4G, 5G, Wi-Fi) <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib124" title="" class="ltx_ref">2020c</a>); Chen et al<span class="ltx_text">.</span> (<a href="#bib.bib27" title="" class="ltx_ref">2021</a>)</cite>, which leads to inconsistent communication bandwidth, latency, and reliability, <span id="S2.SS3.p1.1.1.1" class="ltx_text ltx_font_italic">i.e.</span>, communication heterogeneity <cite class="ltx_cite ltx_citemacro_cite">Chen et al<span class="ltx_text">.</span> (<a href="#bib.bib25" title="" class="ltx_ref">2023b</a>)</cite>. For example, a central hospital may have a high-speed fiber optic network, while a rural clinic may only have a low-speed wireless network. This leads to the problem of communication heterogeneity. When these medical institutions perform operations such as uploading and downloading with the server, delays, and failures may occur, thereby hindering the effect of federated learning <cite class="ltx_cite ltx_citemacro_cite">McMahan et al<span class="ltx_text">.</span> (<a href="#bib.bib156" title="" class="ltx_ref">2017</a>)</cite>.</span></p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p"><span id="S2.SS3.p2.1.1" class="ltx_text" style="color:#000000;">Communication heterogeneity increases communication cost and complexity to some extent. Considering the differences in the network connectivity settings of IoT devices, different devices may require different amounts of data or time to connect and communicate with the server <cite class="ltx_cite ltx_citemacro_cite">Hou et al<span class="ltx_text">.</span> (<a href="#bib.bib79" title="" class="ltx_ref">2022</a>); Hyeon-Woo et al<span class="ltx_text">.</span> (<a href="#bib.bib90" title="" class="ltx_ref">2022</a>)</cite>. Some devices may connect slowly, rendering them expensive and unreliable to communicate with. Besides, in the training process, there may be offline devices due to network bandwidth and energy constraints. Communication heterogeneity may also reduce communication efficiency and effectiveness <cite class="ltx_cite ltx_citemacro_cite">Hönig et al<span class="ltx_text">.</span> (<a href="#bib.bib76" title="" class="ltx_ref">2022</a>)</cite>. Some IoT devices have problems such as low-quality network environments, slow device connection, and limited network bandwidth. Therefore, the clients may encounter varying degrees of noise, delay, or loss during the communication process, which severely reduces communication efficiency <cite class="ltx_cite ltx_citemacro_cite">Wang et al<span class="ltx_text">.</span> (<a href="#bib.bib214" title="" class="ltx_ref">2022a</a>); Yue et al<span class="ltx_text">.</span> (<a href="#bib.bib238" title="" class="ltx_ref">2022</a>)</cite>.</span> To enhance communication efficiency, stragglers and offline devices with a significant time difference may be discarded after a sufficient number of clients have transmitted their feedback results to the server side. Notably, communication heterogeneity can be viewed as a strategy to address the differences in device computing power <cite class="ltx_cite ltx_citemacro_cite">Dai et al<span class="ltx_text">.</span> (<a href="#bib.bib39" title="" class="ltx_ref">2015</a>)</cite> by using bounded-delay assumptions to control devices latencies. <span id="S2.SS3.p2.1.2" class="ltx_text" style="color:#000000;">Communication heterogeneity is very prevalent in complex IoT environments, which may lead to high-cost and low-efficiency communication, thereby diminishing the effectiveness of federated learning.</span> Therefore, how to adaptively adjust federated communication in heterogeneous network environments is worth studying.</p>
</div>
</section>
<section id="S2.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4. </span>Device Heterogeneity</h3>

<div id="S2.SS4.p1" class="ltx_para">
<p id="S2.SS4.p1.1" class="ltx_p"><span id="S2.SS4.p1.1.1" class="ltx_text" style="color:#000000;">In practical applications, federated learning networks may involve a large number of participating IoT devices. The differences in device hardware capabilities (CPU, memory, battery life) may lead to different storage and computation capabilities <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib124" title="" class="ltx_ref">2020c</a>)</cite>, which inevitably lead to device heterogeneity. For example, one client is a smartphone, while another client is a smartwatch. The smartphones have larger storage capacity and stronger computing capacity than smartwatches, which brings device heterogeneity. Therefore, during federated communication, smartwatches may have longer local runtimes and may be dropped or lost, reducing system efficiency and stability.</span></p>
</div>
<div id="S2.SS4.p2" class="ltx_para">
<p id="S2.SS4.p2.1" class="ltx_p">In federated learning, clients need to perform local updates and seed the updates back to the server side. However, the participating clients may encounter faults during this process. When the model is updated synchronously, devices with limited computation capabilities may consume a significant amount of time to update the model and may become stragglers. <span id="S2.SS4.p2.1.1" class="ltx_text" style="color:#000000;">Overall, device heterogeneity poses several challenges to federated learning. First, it leads to system imbalance and inefficiency, as different clients may have different computing speeds or resources, causing system lags or bottlenecks. Second, it introduces uncertainty and instability to the system, since different clients may have different device states, including states that lead to system failure or loss <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib124" title="" class="ltx_ref">2020c</a>)</cite>. Therefore, device heterogeneity introduces constraints such as straggler mitigation and fault tolerance into the federated learning process, which necessitates the adaptive adjustment of the feedback for different devices in large-scale federated learning scenarios.</span></p>
</div>
</section>
<section id="S2.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.5. </span>Additional Challenges</h3>

<div id="S2.SS5.p1" class="ltx_para">
<p id="S2.SS5.p1.1" class="ltx_p">Apart from the above-mentioned heterogeneities, this part also discusses some additional challenges in heterogeneous federated learning, including knowledge transfer barriers and privacy leakage.</p>
</div>
<div id="S2.SS5.p2" class="ltx_para">
<p id="S2.SS5.p2.1" class="ltx_p"><span id="S2.SS5.p2.1.1" class="ltx_text ltx_font_bold">Knowledge Transfer Barriers.</span>
Federated learning is aimed at transferring knowledge between different clients to collaboratively learn models with superior performance. However, the above-mentioned heterogeneous characteristics cause knowledge transfer barriers to different degrees. The client collects data in a Non-IID way, which leads to statistical heterogeneity. Under the combined influence of multiple skew patterns, the domain knowledge of all clients cannot be sufficiently learned. When the clients have models with different structures, the general average parameter strategy cannot be used for model aggregation, resulting in barriers to knowledge exchange between heterogeneous models. Besides, communication heterogeneity and device heterogeneity in the complex Internet of Things (IoT) environments weaken the efficiency of knowledge transfer. Therefore, how to achieve efficient knowledge transfer in heterogeneous scenarios is a problem that current researches need to focus on.</p>
</div>
<div id="S2.SS5.p3" class="ltx_para">
<p id="S2.SS5.p3.1" class="ltx_p"><span id="S2.SS5.p3.1.1" class="ltx_text ltx_font_bold">Privacy Leakage.</span>
It is now well-understood that privacy is one of the first-order concerns in federated learning <cite class="ltx_cite ltx_citemacro_cite">Kairouz et al<span class="ltx_text">.</span> (<a href="#bib.bib97" title="" class="ltx_ref">2019</a>)</cite>, <span id="S2.SS5.p3.1.2" class="ltx_text" style="color:#000000;">because protecting the local data of clients from being leaked is a fundamental principle of federated learning.</span> In the communication process, each client never shares private data with the server or other clients to ensure basic privacy <cite class="ltx_cite ltx_citemacro_cite">Mothukuri et al<span class="ltx_text">.</span> (<a href="#bib.bib161" title="" class="ltx_ref">2021b</a>)</cite>. <span id="S2.SS5.p3.1.3" class="ltx_text" style="color:#000000;">However, federated learning by itself cannot guarantee perfect data security, as there are still potential privacy risks or attacks on data privacy.</span> Moreover, the above-mentioned four types of heterogeneity inevitably exacerbate privacy leakage in different learning stages. <span id="S2.SS5.p3.1.4" class="ltx_text" style="color:#000000;">For example, when clients implement federated learning by sharing model gradient updates, logits output, etc., attackers can infer the private information of clients by injecting malicious data or models into the system, or by analyzing their model gradients. This may result in the unavoidable leakage of sensitive information to the server or other clients.</span></p>
</div>
<div id="S2.SS5.p4" class="ltx_para">
<p id="S2.SS5.p4.1" class="ltx_p"><span id="S2.SS5.p4.1.1" class="ltx_text" style="color:#000000;">Several methods have been investigated to enhance the privacy protection of federated learning, mainly containing anonymization, secure aggregation, Differential Privacy(DP), homomorphic encryption, Secure Multi-party Computation(SMC), and so on. Anonymization conceals the identity of the client by using cryptography so that model updates or gradients cannot reveal anything unique to the client.
Data aggregation enhances the privacy of federated learning by combining data or gradients from multiple clients, reducing the information from a specific client in the shared information <cite class="ltx_cite ltx_citemacro_cite">Kairouz et al<span class="ltx_text">.</span> (<a href="#bib.bib96" title="" class="ltx_ref">2021</a>)</cite>. DP hides real original information by adding noise to the data or gradients before sending them to the server, including local DP <cite class="ltx_cite ltx_citemacro_cite">Truex et al<span class="ltx_text">.</span> (<a href="#bib.bib205" title="" class="ltx_ref">2020</a>)</cite>, hybrid DP <cite class="ltx_cite ltx_citemacro_cite">Liu et al<span class="ltx_text">.</span> (<a href="#bib.bib136" title="" class="ltx_ref">2022</a>)</cite>, shuffle model <cite class="ltx_cite ltx_citemacro_cite">Girgis et al<span class="ltx_text">.</span> (<a href="#bib.bib62" title="" class="ltx_ref">2021</a>)</cite>, etc. Homomorphic encryption allows a server to perform computations on encrypted data or gradients without decrypting them. Secure multi-party computing is based on the SMC encryption protocol, enabling multiple clients to jointly calculate functions applicable to their private data without sharing the original data.</span> Typically, they achieve privacy protection at the expense of model performance and communication efficiency. Therefore, how to ensure privacy protection without compromising the model performance is a key challenge in federated communication.</p>
</div>
<figure id="S2.F5" class="ltx_figure"><img src="/html/2307.10616/assets/x5.png" id="S2.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="158" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5. </span><span id="S2.F5.2.1" class="ltx_text" style="font-size:90%;">Illustration of the state-of-the-art methods in our taxonomy at three different levels.</span></figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3. </span>Methods: State-of-the-art</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">This section reviews existing heterogeneous federated learning approaches by dividing them into three parts (Fig. <a href="#S2.F5" title="Figure 5 ‣ 2.5. Additional Challenges ‣ 2. Problems: Research Challenges in Heterogeneous Federated Learning ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>), <span id="S3.p1.1.1" class="ltx_text ltx_font_italic">i.e.</span>, data-level, model-level, and server-level methods. The data-level methods refer to operations at the data level that smooth the statistical heterogeneity of local data across clients or improve data privacy, such as data augmentation and anonymization techniques. The model-level methods refer to operations designed at the model level, <span id="S3.p1.1.2" class="ltx_text ltx_font_italic">e.g.</span>, sharing partial structures, and model optimization. The server-level methods require server engagement, such as participating client selection, or clients clustering.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1. </span>Data-Level Methods</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p"><span id="S3.SS1.p1.1.1" class="ltx_text" style="color:#000000;">In this subsection, we introduce the classification of data-level methods and some representative methods in each category, as shown in Tab. <a href="#S3.T2" title="Table 2 ‣ 3.1. Data-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Data-level methods refer to operations performed at the data level, including private data processing and external data utilization. Private data processing means that clients internally process private data to improve data quality, diversity, and security, thereby optimizing the performance of federated learning. These methods include data preparation and data privacy protection. Data preparation includes operations such as data collection, filtering, cleaning, and augmentation, which can directly alleviate statistical heterogeneity. Data privacy protection aims to ensure that the original data information is not disclosed. External data utilization refers to performing model knowledge distillation or imposing constraints on model updates by introducing additional data. Knowledge distillation is usually employed to deal with communication difficulties caused by model heterogeneity and can alleviate data heterogeneity and communication heterogeneity to some extent. Unsupervised representation learning can alleviate the statistical heterogeneity between the local data of clients.</span></p>
</div>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 2. </span> <span id="S3.T2.20.1" class="ltx_text" style="color:#000000;">Data-level methods.</span></figcaption>
<table id="S3.T2.16" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T2.3.3" class="ltx_tr">
<td id="S3.T2.3.3.4" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="2"><span id="S3.T2.3.3.4.1" class="ltx_text" style="font-size:90%;">Methods</span></td>
<td id="S3.T2.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;"><span id="S3.T2.1.1.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T2.1.1.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T2.1.1.1.1.p1.1" class="ltx_p"><span id="S3.T2.1.1.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T2.1.1.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T2.1.1.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T2.1.1.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.1.1.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T2.1.1.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Advantages</span></span>
</span></span><span id="S3.T2.1.1.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T2.1.1.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T2.3.3.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;">
<span id="S3.T2.3.3.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.3.3.5.1.1" class="ltx_p"><span id="S3.T2.3.3.5.1.1.1" class="ltx_text" style="font-size:90%;">Ref.</span></span>
</span>
</td>
<td id="S3.T2.2.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;"><span id="S3.T2.2.2.2.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T2.2.2.2.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T2.2.2.2.1.p1.1" class="ltx_p"><span id="S3.T2.2.2.2.1.p1.1.1" class="ltx_text"></span><span id="S3.T2.2.2.2.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T2.2.2.2.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T2.2.2.2.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.2.2.2.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T2.2.2.2.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Key Contributions</span></span>
</span></span><span id="S3.T2.2.2.2.1.p1.1.4" class="ltx_text"></span><span id="S3.T2.2.2.2.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T2.3.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;"><span id="S3.T2.3.3.3.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T2.3.3.3.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T2.3.3.3.1.p1.1" class="ltx_p"><span id="S3.T2.3.3.3.1.p1.1.1" class="ltx_text"></span><span id="S3.T2.3.3.3.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T2.3.3.3.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T2.3.3.3.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.3.3.3.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T2.3.3.3.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Limitations</span></span>
</span></span><span id="S3.T2.3.3.3.1.p1.1.4" class="ltx_text"></span><span id="S3.T2.3.3.3.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
</tr>
<tr id="S3.T2.4.4" class="ltx_tr">
<td id="S3.T2.4.4.2" class="ltx_td ltx_border_l ltx_border_r ltx_border_t"></td>
<td id="S3.T2.4.4.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S3.T2.4.4.4" class="ltx_td ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;"></td>
<td id="S3.T2.4.4.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T2.4.4.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T2.4.4.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T2.4.4.1.1.p1.1" class="ltx_p"><span id="S3.T2.4.4.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T2.4.4.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T2.4.4.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T2.4.4.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.4.4.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T2.4.4.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Xu et al<span class="ltx_text">.</span> (<a href="#bib.bib225" title="" class="ltx_ref">2022b</a>)</cite></span></span>
</span></span><span id="S3.T2.4.4.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T2.4.4.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T2.4.4.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T2.4.4.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.4.5.1.1" class="ltx_p"><span id="S3.T2.4.4.5.1.1.1" class="ltx_text" style="font-size:90%;">Safe detects and filters out poisoned data from attacked devices through a clustering algorithm.</span></span>
</span>
</td>
<td id="S3.T2.4.4.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T2.4.4.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.4.4.6.1.1" class="ltx_p"><span id="S3.T2.4.4.6.1.1.1" class="ltx_text" style="font-size:90%;">Filtering poisoned data by clustering requires proper selection of attacking clients.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.5.5" class="ltx_tr">
<td id="S3.T2.5.5.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T2.5.5.3" class="ltx_td ltx_border_r"></td>
<td id="S3.T2.5.5.4" class="ltx_td ltx_align_middle ltx_border_r" style="width:56.9pt;"></td>
<td id="S3.T2.5.5.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T2.5.5.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T2.5.5.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T2.5.5.1.1.p1.1" class="ltx_p"><span id="S3.T2.5.5.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T2.5.5.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T2.5.5.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T2.5.5.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.5.5.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T2.5.5.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Yoon et al<span class="ltx_text">.</span> (<a href="#bib.bib235" title="" class="ltx_ref">2021</a>)</cite></span></span>
</span></span><span id="S3.T2.5.5.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T2.5.5.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T2.5.5.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T2.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.5.5.5.1.1" class="ltx_p"><span id="S3.T2.5.5.5.1.1.1" class="ltx_text" style="font-size:90%;">FedMix performs data augmentation based on the MixUp strategy.</span></span>
</span>
</td>
<td id="S3.T2.5.5.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T2.5.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.5.5.6.1.1" class="ltx_p"><span id="S3.T2.5.5.6.1.1.1" class="ltx_text" style="font-size:90%;">Collecting local data distributions may bring potential information leakage.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.6.6" class="ltx_tr">
<td id="S3.T2.6.6.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T2.6.6.3" class="ltx_td ltx_border_r"></td>
<td id="S3.T2.6.6.4" class="ltx_td ltx_align_middle ltx_border_r" style="width:56.9pt;"></td>
<td id="S3.T2.6.6.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T2.6.6.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T2.6.6.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T2.6.6.1.1.p1.1" class="ltx_p"><span id="S3.T2.6.6.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T2.6.6.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T2.6.6.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T2.6.6.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.6.6.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T2.6.6.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Duan et al<span class="ltx_text">.</span> (<a href="#bib.bib44" title="" class="ltx_ref">2019</a>)</cite></span></span>
</span></span><span id="S3.T2.6.6.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T2.6.6.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T2.6.6.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T2.6.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.6.6.5.1.1" class="ltx_p"><span id="S3.T2.6.6.5.1.1.1" class="ltx_text" style="font-size:90%;">Astraea performs data augmentation based on the global data distribution, generated by collecting the local data distribution.</span></span>
</span>
</td>
<td id="S3.T2.6.6.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T2.6.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.6.6.6.1.1" class="ltx_p"><span id="S3.T2.6.6.6.1.1.1" class="ltx_text" style="font-size:90%;">Uploading local data distributions may expose potential backdoors to attacks.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.7.7" class="ltx_tr">
<td id="S3.T2.7.7.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T2.7.7.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T2.7.7.3.1" class="ltx_text" style="font-size:90%;"><span id="S3.T2.7.7.3.1.1" class="ltx_text"></span> <span id="S3.T2.7.7.3.1.2" class="ltx_text">
<span id="S3.T2.7.7.3.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.7.7.3.1.2.1.1" class="ltx_tr">
<span id="S3.T2.7.7.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Data</span></span>
<span id="S3.T2.7.7.3.1.2.1.2" class="ltx_tr">
<span id="S3.T2.7.7.3.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Preparation</span></span>
</span></span> <span id="S3.T2.7.7.3.1.3" class="ltx_text"></span></span></td>
<td id="S3.T2.7.7.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:56.9pt;">
<span id="S3.T2.7.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.7.7.4.1.1" class="ltx_p"><span id="S3.T2.7.7.4.1.1.1" class="ltx_text" style="font-size:90%;">These methods effectively improve the quality and security of private data, and alleviate statistical heterogeneity.</span></span>
</span>
</td>
<td id="S3.T2.7.7.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T2.7.7.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T2.7.7.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T2.7.7.1.1.p1.1" class="ltx_p"><span id="S3.T2.7.7.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T2.7.7.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T2.7.7.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T2.7.7.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.7.7.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T2.7.7.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Jeong et al<span class="ltx_text">.</span> (<a href="#bib.bib93" title="" class="ltx_ref">2018</a>)</cite></span></span>
</span></span><span id="S3.T2.7.7.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T2.7.7.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T2.7.7.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T2.7.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.7.7.5.1.1" class="ltx_p"><span id="S3.T2.7.7.5.1.1.1" class="ltx_text" style="font-size:90%;">FAug studies the trade-off between privacy leakage and communication overhead through a GAN-based data augmentation scheme.</span></span>
</span>
</td>
<td id="S3.T2.7.7.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T2.7.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.7.7.6.1.1" class="ltx_p"><span id="S3.T2.7.7.6.1.1.1" class="ltx_text" style="font-size:90%;">Transferring local data to the server violates the privacy requirements of federated learning.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.8.8" class="ltx_tr">
<td id="S3.T2.8.8.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T2.8.8.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S3.T2.8.8.4" class="ltx_td ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;"></td>
<td id="S3.T2.8.8.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T2.8.8.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T2.8.8.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T2.8.8.1.1.p1.1" class="ltx_p"><span id="S3.T2.8.8.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T2.8.8.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T2.8.8.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T2.8.8.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.8.8.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T2.8.8.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Hu et al<span class="ltx_text">.</span> (<a href="#bib.bib81" title="" class="ltx_ref">2020a</a>)</cite></span></span>
</span></span><span id="S3.T2.8.8.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T2.8.8.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T2.8.8.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T2.8.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.8.8.5.1.1" class="ltx_p"><span id="S3.T2.8.8.5.1.1.1" class="ltx_text" style="font-size:90%;">PLDP-PFL performs personalized differential privacy according to the sensitivity of private data.</span></span>
</span>
</td>
<td id="S3.T2.8.8.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T2.8.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.8.8.6.1.1" class="ltx_p"><span id="S3.T2.8.8.6.1.1.1" class="ltx_text" style="font-size:90%;">DP can degrade model performance due to its clipping and noise-adding operations</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.9.9" class="ltx_tr">
<td id="S3.T2.9.9.2" class="ltx_td ltx_align_center ltx_border_l ltx_border_r"><span id="S3.T2.9.9.2.1" class="ltx_text" style="font-size:90%;"><span id="S3.T2.9.9.2.1.1" class="ltx_text"></span> <span id="S3.T2.9.9.2.1.2" class="ltx_text">
<span id="S3.T2.9.9.2.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.9.9.2.1.2.1.1" class="ltx_tr">
<span id="S3.T2.9.9.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Private</span></span>
<span id="S3.T2.9.9.2.1.2.1.2" class="ltx_tr">
<span id="S3.T2.9.9.2.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Data</span></span>
<span id="S3.T2.9.9.2.1.2.1.3" class="ltx_tr">
<span id="S3.T2.9.9.2.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">Processing</span></span>
<span id="S3.T2.9.9.2.1.2.1.4" class="ltx_tr">
<span id="S3.T2.9.9.2.1.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center"><a href="#S3.SS1.SSS1" title="3.1.1. Private Data Processing ‣ 3.1. Data-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1.1</span></a></span></span>
</span></span> <span id="S3.T2.9.9.2.1.3" class="ltx_text"></span></span></td>
<td id="S3.T2.9.9.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T2.9.9.3.1" class="ltx_text" style="font-size:90%;"><span id="S3.T2.9.9.3.1.1" class="ltx_text"></span> <span id="S3.T2.9.9.3.1.2" class="ltx_text">
<span id="S3.T2.9.9.3.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.9.9.3.1.2.1.1" class="ltx_tr">
<span id="S3.T2.9.9.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Data Privacy</span></span>
<span id="S3.T2.9.9.3.1.2.1.2" class="ltx_tr">
<span id="S3.T2.9.9.3.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Protection</span></span>
</span></span> <span id="S3.T2.9.9.3.1.3" class="ltx_text"></span></span></td>
<td id="S3.T2.9.9.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:56.9pt;">
<span id="S3.T2.9.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.9.9.4.1.1" class="ltx_p"><span id="S3.T2.9.9.4.1.1.1" class="ltx_text" style="font-size:90%;">These methods ensure the local data privacy.</span></span>
</span>
</td>
<td id="S3.T2.9.9.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T2.9.9.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T2.9.9.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T2.9.9.1.1.p1.1" class="ltx_p"><span id="S3.T2.9.9.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T2.9.9.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T2.9.9.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T2.9.9.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.9.9.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T2.9.9.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Choudhury et al<span class="ltx_text">.</span> (<a href="#bib.bib34" title="" class="ltx_ref">2020</a>)</cite></span></span>
</span></span><span id="S3.T2.9.9.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T2.9.9.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T2.9.9.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T2.9.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.9.9.5.1.1" class="ltx_p"><span id="S3.T2.9.9.5.1.1.1" class="ltx_text" style="font-size:90%;">They use anonymization technology to desensitize local private data.</span></span>
</span>
</td>
<td id="S3.T2.9.9.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T2.9.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.9.9.6.1.1" class="ltx_p"><span id="S3.T2.9.9.6.1.1.1" class="ltx_text" style="font-size:90%;">Anonymization processing may may reduce data quality and availability.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.10.10" class="ltx_tr">
<td id="S3.T2.10.10.2" class="ltx_td ltx_border_l ltx_border_r ltx_border_t"></td>
<td id="S3.T2.10.10.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S3.T2.10.10.4" class="ltx_td ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;"></td>
<td id="S3.T2.10.10.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T2.10.10.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T2.10.10.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T2.10.10.1.1.p1.1" class="ltx_p"><span id="S3.T2.10.10.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T2.10.10.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T2.10.10.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T2.10.10.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.10.10.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T2.10.10.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Li and Wang (<a href="#bib.bib114" title="" class="ltx_ref">2019</a>)</cite></span></span>
</span></span><span id="S3.T2.10.10.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T2.10.10.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T2.10.10.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T2.10.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.10.10.5.1.1" class="ltx_p"><span id="S3.T2.10.10.5.1.1.1" class="ltx_text" style="font-size:90%;">FedMD enables clients to independently design their models and implements communication between heterogeneous models.</span></span>
</span>
</td>
<td id="S3.T2.10.10.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T2.10.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.10.10.6.1.1" class="ltx_p"><span id="S3.T2.10.10.6.1.1.1" class="ltx_text" style="font-size:90%;">Global knowledge cannot describe rich domain knowledge in feature skew scenarios.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.11.11" class="ltx_tr">
<td id="S3.T2.11.11.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T2.11.11.3" class="ltx_td ltx_border_r"></td>
<td id="S3.T2.11.11.4" class="ltx_td ltx_align_middle ltx_border_r" style="width:56.9pt;"></td>
<td id="S3.T2.11.11.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T2.11.11.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T2.11.11.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T2.11.11.1.1.p1.1" class="ltx_p"><span id="S3.T2.11.11.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T2.11.11.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T2.11.11.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T2.11.11.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.11.11.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T2.11.11.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Yu et al<span class="ltx_text">.</span> (<a href="#bib.bib237" title="" class="ltx_ref">2020</a>)</cite></span></span>
</span></span><span id="S3.T2.11.11.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T2.11.11.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T2.11.11.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T2.11.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.11.11.5.1.1" class="ltx_p"><span id="S3.T2.11.11.5.1.1.1" class="ltx_text" style="font-size:90%;">They mitigate overfitting in personalized updates by enhancing the logits similarity between the global model and the local models.</span></span>
</span>
</td>
<td id="S3.T2.11.11.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T2.11.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.11.11.6.1.1" class="ltx_p"><span id="S3.T2.11.11.6.1.1.1" class="ltx_text" style="font-size:90%;">Logits Exploitation may lead to insufficient learning of local information.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.12.12" class="ltx_tr">
<td id="S3.T2.12.12.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T2.12.12.3" class="ltx_td ltx_border_r"></td>
<td id="S3.T2.12.12.4" class="ltx_td ltx_align_middle ltx_border_r" style="width:56.9pt;"></td>
<td id="S3.T2.12.12.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T2.12.12.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T2.12.12.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T2.12.12.1.1.p1.1" class="ltx_p"><span id="S3.T2.12.12.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T2.12.12.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T2.12.12.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T2.12.12.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.12.12.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T2.12.12.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">He et al<span class="ltx_text">.</span> (<a href="#bib.bib72" title="" class="ltx_ref">2020a</a>)</cite></span></span>
</span></span><span id="S3.T2.12.12.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T2.12.12.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T2.12.12.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T2.12.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.12.12.5.1.1" class="ltx_p"><span id="S3.T2.12.12.5.1.1.1" class="ltx_text" style="font-size:90%;">FedGKT extracts knowledge on resource-constrained edge devices through knowledge distillation.</span></span>
</span>
</td>
<td id="S3.T2.12.12.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T2.12.12.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.12.12.6.1.1" class="ltx_p"><span id="S3.T2.12.12.6.1.1.1" class="ltx_text" style="font-size:90%;">Uploading prediction vectors to the server may not satisfy DP guarantees.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.13.13" class="ltx_tr">
<td id="S3.T2.13.13.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T2.13.13.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T2.13.13.3.1" class="ltx_text" style="font-size:90%;"><span id="S3.T2.13.13.3.1.1" class="ltx_text"></span> <span id="S3.T2.13.13.3.1.2" class="ltx_text">
<span id="S3.T2.13.13.3.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.13.13.3.1.2.1.1" class="ltx_tr">
<span id="S3.T2.13.13.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Knowledge</span></span>
<span id="S3.T2.13.13.3.1.2.1.2" class="ltx_tr">
<span id="S3.T2.13.13.3.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Distillation</span></span>
</span></span> <span id="S3.T2.13.13.3.1.3" class="ltx_text"></span></span></td>
<td id="S3.T2.13.13.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:56.9pt;">
<span id="S3.T2.13.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.13.13.4.1.1" class="ltx_p"><span id="S3.T2.13.13.4.1.1.1" class="ltx_text" style="font-size:90%;">These methods overcome model heterogeneity to achieve communication between heterogeneous models and effectively decrease communication overhead.</span></span>
</span>
</td>
<td id="S3.T2.13.13.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T2.13.13.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T2.13.13.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T2.13.13.1.1.p1.1" class="ltx_p"><span id="S3.T2.13.13.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T2.13.13.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T2.13.13.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T2.13.13.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.13.13.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T2.13.13.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib246" title="" class="ltx_ref">2022e</a>)</cite></span></span>
</span></span><span id="S3.T2.13.13.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T2.13.13.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T2.13.13.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T2.13.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.13.13.5.1.1" class="ltx_p"><span id="S3.T2.13.13.5.1.1.1" class="ltx_text" style="font-size:90%;">FedFTG trains a conditional generator to fit the input space of a local model, and uses it to generate pseudo data.</span></span>
</span>
</td>
<td id="S3.T2.13.13.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T2.13.13.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.13.13.6.1.1" class="ltx_p"><span id="S3.T2.13.13.6.1.1.1" class="ltx_text" style="font-size:90%;">Training the generator and using FL-div to learn the global knowledge may increase the computation cost.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.14.14" class="ltx_tr">
<td id="S3.T2.14.14.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T2.14.14.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S3.T2.14.14.4" class="ltx_td ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;"></td>
<td id="S3.T2.14.14.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T2.14.14.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T2.14.14.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T2.14.14.1.1.p1.1" class="ltx_p"><span id="S3.T2.14.14.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T2.14.14.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T2.14.14.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T2.14.14.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.14.14.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T2.14.14.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib240" title="" class="ltx_ref">2020c</a>)</cite></span></span>
</span></span><span id="S3.T2.14.14.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T2.14.14.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T2.14.14.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T2.14.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.14.14.5.1.1" class="ltx_p"><span id="S3.T2.14.14.5.1.1.1" class="ltx_text" style="font-size:90%;">A novel problem named FURL is proposed. And the corresponding solution algorithm, namely FedCA, is designed.</span></span>
</span>
</td>
<td id="S3.T2.14.14.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T2.14.14.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.14.14.6.1.1" class="ltx_p"><span id="S3.T2.14.14.6.1.1.1" class="ltx_text" style="font-size:90%;">Directly sharing the features of local data may introduce potential privacy risks.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.15.15" class="ltx_tr">
<td id="S3.T2.15.15.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T2.15.15.3" class="ltx_td ltx_border_r"></td>
<td id="S3.T2.15.15.4" class="ltx_td ltx_align_middle ltx_border_r" style="width:56.9pt;"></td>
<td id="S3.T2.15.15.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T2.15.15.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T2.15.15.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T2.15.15.1.1.p1.1" class="ltx_p"><span id="S3.T2.15.15.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T2.15.15.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T2.15.15.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T2.15.15.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.15.15.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T2.15.15.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib119" title="" class="ltx_ref">2021c</a>)</cite></span></span>
</span></span><span id="S3.T2.15.15.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T2.15.15.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T2.15.15.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T2.15.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.15.15.5.1.1" class="ltx_p"><span id="S3.T2.15.15.5.1.1.1" class="ltx_text" style="font-size:90%;">MOON solves the Non-IID data issues through model-based contrastive learning.</span></span>
</span>
</td>
<td id="S3.T2.15.15.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T2.15.15.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.15.15.6.1.1" class="ltx_p"><span id="S3.T2.15.15.6.1.1.1" class="ltx_text" style="font-size:90%;">Storing multiple models simultaneously may require significant additional resources.</span></span>
</span>
</td>
</tr>
<tr id="S3.T2.16.16" class="ltx_tr">
<td id="S3.T2.16.16.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r"><span id="S3.T2.16.16.2.1" class="ltx_text" style="font-size:90%;"><span id="S3.T2.16.16.2.1.1" class="ltx_text"></span> <span id="S3.T2.16.16.2.1.2" class="ltx_text">
<span id="S3.T2.16.16.2.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.16.16.2.1.2.1.1" class="ltx_tr">
<span id="S3.T2.16.16.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">External</span></span>
<span id="S3.T2.16.16.2.1.2.1.2" class="ltx_tr">
<span id="S3.T2.16.16.2.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Data</span></span>
<span id="S3.T2.16.16.2.1.2.1.3" class="ltx_tr">
<span id="S3.T2.16.16.2.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">Utilization</span></span>
<span id="S3.T2.16.16.2.1.2.1.4" class="ltx_tr">
<span id="S3.T2.16.16.2.1.2.1.4.1" class="ltx_td ltx_nopad_r ltx_align_center"><a href="#S3.SS1.SSS2" title="3.1.2. External Data Utilization ‣ 3.1. Data-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.1.2</span></a></span></span>
</span></span> <span id="S3.T2.16.16.2.1.3" class="ltx_text"></span></span></td>
<td id="S3.T2.16.16.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span id="S3.T2.16.16.3.1" class="ltx_text" style="font-size:90%;"><span id="S3.T2.16.16.3.1.1" class="ltx_text"></span> <span id="S3.T2.16.16.3.1.2" class="ltx_text">
<span id="S3.T2.16.16.3.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.16.16.3.1.2.1.1" class="ltx_tr">
<span id="S3.T2.16.16.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Unsupervised</span></span>
<span id="S3.T2.16.16.3.1.2.1.2" class="ltx_tr">
<span id="S3.T2.16.16.3.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Representation</span></span>
<span id="S3.T2.16.16.3.1.2.1.3" class="ltx_tr">
<span id="S3.T2.16.16.3.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center">Learning</span></span>
</span></span> <span id="S3.T2.16.16.3.1.3" class="ltx_text"></span></span></td>
<td id="S3.T2.16.16.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r" style="width:56.9pt;">
<span id="S3.T2.16.16.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.16.16.4.1.1" class="ltx_p"><span id="S3.T2.16.16.4.1.1.1" class="ltx_text" style="font-size:90%;">These approaches enable local models to learn consistent representations while keeping private data decentralized and unlabeled.</span></span>
</span>
</td>
<td id="S3.T2.16.16.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T2.16.16.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T2.16.16.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T2.16.16.1.1.p1.1" class="ltx_p"><span id="S3.T2.16.16.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T2.16.16.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T2.16.16.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T2.16.16.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T2.16.16.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T2.16.16.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Mu et al<span class="ltx_text">.</span> (<a href="#bib.bib162" title="" class="ltx_ref">2021</a>)</cite></span></span>
</span></span><span id="S3.T2.16.16.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T2.16.16.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T2.16.16.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:113.8pt;">
<span id="S3.T2.16.16.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.16.16.5.1.1" class="ltx_p"><span id="S3.T2.16.16.5.1.1.1" class="ltx_text" style="font-size:90%;">FedProc mitigates statistical heterogeneity through prototype-based contrastive learning.</span></span>
</span>
</td>
<td id="S3.T2.16.16.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T2.16.16.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T2.16.16.6.1.1" class="ltx_p"><span id="S3.T2.16.16.6.1.1.1" class="ltx_text" style="font-size:90%;">Unprocessed logits transmissions may lead to privacy leakage of local data.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<figure id="S3.F6" class="ltx_figure"><img src="/html/2307.10616/assets/x6.png" id="S3.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="203" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6. </span><span id="S3.F6.2.1" class="ltx_text" style="font-size:90%;color:#000000;">Illustration of private data processing methods in heterogeneous federated learning.</span></figcaption>
</figure>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1. </span> <span id="S3.SS1.SSS1.1.1" class="ltx_text" style="color:#000000;">Private Data Processing</span>
</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.1" class="ltx_p"><span id="S3.SS1.SSS1.p1.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">Data Preparation.</span>
<span id="S3.SS1.SSS1.p1.1.2" class="ltx_text" style="color:#000000;">Private data preparation in federated learning includes data collection, filtering, cleaning, augmentation, and more (Fig. <a href="#S3.F6" title="Figure 6 ‣ 3.1. Data-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>). These operations are aimed at ensuring the data quality and security on each client, thereby improving the efficiency and effectiveness of federated learning. Data collection refers to the process of obtaining data from participating clients. Data filtering refers to the removal of irrelevant data. Data cleaning refers to the correction of inaccurate data. Data augmentation is the process of enhancing or augmenting data with additional information or features, and it has been widely explored in federated learning to address statistical heterogeneity.</span></p>
</div>
<div id="S3.SS1.SSS1.p2" class="ltx_para">
<p id="S3.SS1.SSS1.p2.1" class="ltx_p"><span id="S3.SS1.SSS1.p2.1.1" class="ltx_text" style="color:#000000;">Data collection refers to the process of obtaining data from participating clients. In federated learning, the quantity, quality, and diversity of data collection determine how much useful information the client provides to the federated learning system. Therefore, local data collection is an important part to be optimized in federated learning. Data filtering is the process of removing or excluding irrelevant, noisy or malicious data from federated learning. Therefore, Li <span id="S3.SS1.SSS1.p2.1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib112" title="" class="ltx_ref">2021h</a>)</cite> consider various data-related factors (error rate, classification distribution, content diversity and data size) that affect model performance to measure the data quality of samples. Then they select the optimal sample combination with the highest total quality under the monetary budget constraint. Besides, data filtering can effectively prevent the federated learning system from being negatively affected by malicious data. For example, Xu <span id="S3.SS1.SSS1.p2.1.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Xu et al<span class="ltx_text">.</span> (<a href="#bib.bib225" title="" class="ltx_ref">2022b</a>)</cite> propose a collaborative data filtering method, Safe, for data selection, which can detect and filter out poisoned data from attacked devices in a federated learning system. Specifically, Safe first clusters the local data, then measures the distance between each sample and its cluster center, and finally discards samples far from the cluster center as poisoned data. Data cleaning is the process of correcting or improving incomplete, inaccurate, or inconsistent data in federated learning, usually by applying relevant techniques locally on the client side to impute missing values, resolve conflicts, and standardize data.</span></p>
</div>
<div id="S3.SS1.SSS1.p3" class="ltx_para">
<p id="S3.SS1.SSS1.p3.1" class="ltx_p">Data augmentation is a technique of artificially expanding training datasets by generating more data from limited raw data, which can effectively alleviate the problem of data deficiency in deep learning. In addition, popular data augmentation operations include flipping, rotating, scaling, cropping, shifting, Gaussian noise introduction, and MixUp <cite class="ltx_cite ltx_citemacro_cite">Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib241" title="" class="ltx_ref">2018</a>); Shin et al<span class="ltx_text">.</span> (<a href="#bib.bib190" title="" class="ltx_ref">2020</a>)</cite>. Additional data can also be artificially synthesized using Generative Adversarial Networks (GAN) <cite class="ltx_cite ltx_citemacro_cite">Goodfellow et al<span class="ltx_text">.</span> (<a href="#bib.bib64" title="" class="ltx_ref">2014</a>)</cite>. However, statistical heterogeneity of client datasets is commonly encountered in federated settings, and private data augmentation techniques can be directly used to smooth the data distribution across multiple clients and mitigate statistical heterogeneity. Federated data augmentation typically requires users to upload a few local data samples, which increases the risk of data privacy breaches. To circumvent this risk, several approaches require a proxy dataset that can represent the overall data distribution of a federated system. Owing to these aspects, data augmentation in federated settings is highly challenging.</p>
</div>
<div id="S3.SS1.SSS1.p4" class="ltx_para">
<p id="S3.SS1.SSS1.p4.3" class="ltx_p">In a Non-IID environment with uneven data distributions on the clients, Yoon <span id="S3.SS1.SSS1.p4.3.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Yoon et al<span class="ltx_text">.</span> (<a href="#bib.bib235" title="" class="ltx_ref">2021</a>)</cite> construct a Mean Augmented Federated Learning (MAFL) framework, in which clients exchange mean local data to obtain global information while maintaining privacy requirements. Furthermore, they designed a data augmentation algorithm FedMix under the MAFL framework, which approximates the loss function of the global mixup through Taylor expansion without accessing the raw data of other clients.
Consider the client <math id="S3.SS1.SSS1.p4.1.m1.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.SS1.SSS1.p4.1.m1.1a"><mi id="S3.SS1.SSS1.p4.1.m1.1.1" xref="S3.SS1.SSS1.p4.1.m1.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p4.1.m1.1b"><ci id="S3.SS1.SSS1.p4.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p4.1.m1.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p4.1.m1.1c">i</annotation></semantics></math> has a private local dataset <math id="S3.SS1.SSS1.p4.2.m2.2" class="ltx_Math" alttext="(x_{i},y_{i})" display="inline"><semantics id="S3.SS1.SSS1.p4.2.m2.2a"><mrow id="S3.SS1.SSS1.p4.2.m2.2.2.2" xref="S3.SS1.SSS1.p4.2.m2.2.2.3.cmml"><mo stretchy="false" id="S3.SS1.SSS1.p4.2.m2.2.2.2.3" xref="S3.SS1.SSS1.p4.2.m2.2.2.3.cmml">(</mo><msub id="S3.SS1.SSS1.p4.2.m2.1.1.1.1" xref="S3.SS1.SSS1.p4.2.m2.1.1.1.1.cmml"><mi id="S3.SS1.SSS1.p4.2.m2.1.1.1.1.2" xref="S3.SS1.SSS1.p4.2.m2.1.1.1.1.2.cmml">x</mi><mi id="S3.SS1.SSS1.p4.2.m2.1.1.1.1.3" xref="S3.SS1.SSS1.p4.2.m2.1.1.1.1.3.cmml">i</mi></msub><mo id="S3.SS1.SSS1.p4.2.m2.2.2.2.4" xref="S3.SS1.SSS1.p4.2.m2.2.2.3.cmml">,</mo><msub id="S3.SS1.SSS1.p4.2.m2.2.2.2.2" xref="S3.SS1.SSS1.p4.2.m2.2.2.2.2.cmml"><mi id="S3.SS1.SSS1.p4.2.m2.2.2.2.2.2" xref="S3.SS1.SSS1.p4.2.m2.2.2.2.2.2.cmml">y</mi><mi id="S3.SS1.SSS1.p4.2.m2.2.2.2.2.3" xref="S3.SS1.SSS1.p4.2.m2.2.2.2.2.3.cmml">i</mi></msub><mo stretchy="false" id="S3.SS1.SSS1.p4.2.m2.2.2.2.5" xref="S3.SS1.SSS1.p4.2.m2.2.2.3.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p4.2.m2.2b"><interval closure="open" id="S3.SS1.SSS1.p4.2.m2.2.2.3.cmml" xref="S3.SS1.SSS1.p4.2.m2.2.2.2"><apply id="S3.SS1.SSS1.p4.2.m2.1.1.1.1.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p4.2.m2.1.1.1.1.1.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p4.2.m2.1.1.1.1.2.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.1.1.2">𝑥</ci><ci id="S3.SS1.SSS1.p4.2.m2.1.1.1.1.3.cmml" xref="S3.SS1.SSS1.p4.2.m2.1.1.1.1.3">𝑖</ci></apply><apply id="S3.SS1.SSS1.p4.2.m2.2.2.2.2.cmml" xref="S3.SS1.SSS1.p4.2.m2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p4.2.m2.2.2.2.2.1.cmml" xref="S3.SS1.SSS1.p4.2.m2.2.2.2.2">subscript</csymbol><ci id="S3.SS1.SSS1.p4.2.m2.2.2.2.2.2.cmml" xref="S3.SS1.SSS1.p4.2.m2.2.2.2.2.2">𝑦</ci><ci id="S3.SS1.SSS1.p4.2.m2.2.2.2.2.3.cmml" xref="S3.SS1.SSS1.p4.2.m2.2.2.2.2.3">𝑖</ci></apply></interval></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p4.2.m2.2c">(x_{i},y_{i})</annotation></semantics></math>, and <math id="S3.SS1.SSS1.p4.3.m3.1" class="ltx_math_unparsed" alttext="f(,)" display="inline"><semantics id="S3.SS1.SSS1.p4.3.m3.1a"><mrow id="S3.SS1.SSS1.p4.3.m3.1b"><mi id="S3.SS1.SSS1.p4.3.m3.1.1">f</mi><mrow id="S3.SS1.SSS1.p4.3.m3.1.2"><mo stretchy="false" id="S3.SS1.SSS1.p4.3.m3.1.2.1">(</mo><mo id="S3.SS1.SSS1.p4.3.m3.1.2.2">,</mo><mo stretchy="false" id="S3.SS1.SSS1.p4.3.m3.1.2.3">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p4.3.m3.1c">f(,)</annotation></semantics></math> is the model output. Therefore, the approximated FedMix loss can be expressed as:</p>
<table id="S3.E3" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E3.m1.50" class="ltx_Math" alttext="\begin{split}\mathcal{L}_{FedMix}=(1-\lambda)\mathcal{L}(f((1-\lambda)x_{i}),y_{i})+\lambda\mathcal{L}(f((1-\lambda)x_{i}),\bar{y}_{j})+\lambda{\frac{\partial\mathcal{L}}{\partial x}}\bar{x}_{j},\end{split}" display="block"><semantics id="S3.E3.m1.50a"><mtable displaystyle="true" id="S3.E3.m1.50.50.2"><mtr id="S3.E3.m1.50.50.2a"><mtd class="ltx_align_right" columnalign="right" id="S3.E3.m1.50.50.2b"><mrow id="S3.E3.m1.50.50.2.49.49.49.49"><mrow id="S3.E3.m1.50.50.2.49.49.49.49.1"><msub id="S3.E3.m1.50.50.2.49.49.49.49.1.6"><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.1.1.1.1.1.1" xref="S3.E3.m1.1.1.1.1.1.1.cmml">ℒ</mi><mrow id="S3.E3.m1.2.2.2.2.2.2.1" xref="S3.E3.m1.2.2.2.2.2.2.1.cmml"><mi id="S3.E3.m1.2.2.2.2.2.2.1.2" xref="S3.E3.m1.2.2.2.2.2.2.1.2.cmml">F</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.2.2.2.2.1.1" xref="S3.E3.m1.2.2.2.2.2.2.1.1.cmml">​</mo><mi id="S3.E3.m1.2.2.2.2.2.2.1.3" xref="S3.E3.m1.2.2.2.2.2.2.1.3.cmml">e</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.2.2.2.2.1.1a" xref="S3.E3.m1.2.2.2.2.2.2.1.1.cmml">​</mo><mi id="S3.E3.m1.2.2.2.2.2.2.1.4" xref="S3.E3.m1.2.2.2.2.2.2.1.4.cmml">d</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.2.2.2.2.1.1b" xref="S3.E3.m1.2.2.2.2.2.2.1.1.cmml">​</mo><mi id="S3.E3.m1.2.2.2.2.2.2.1.5" xref="S3.E3.m1.2.2.2.2.2.2.1.5.cmml">M</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.2.2.2.2.1.1c" xref="S3.E3.m1.2.2.2.2.2.2.1.1.cmml">​</mo><mi id="S3.E3.m1.2.2.2.2.2.2.1.6" xref="S3.E3.m1.2.2.2.2.2.2.1.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.2.2.2.2.2.2.1.1d" xref="S3.E3.m1.2.2.2.2.2.2.1.1.cmml">​</mo><mi id="S3.E3.m1.2.2.2.2.2.2.1.7" xref="S3.E3.m1.2.2.2.2.2.2.1.7.cmml">x</mi></mrow></msub><mo id="S3.E3.m1.3.3.3.3.3.3" xref="S3.E3.m1.3.3.3.3.3.3.cmml">=</mo><mrow id="S3.E3.m1.50.50.2.49.49.49.49.1.5"><mrow id="S3.E3.m1.50.50.2.49.49.49.49.1.3.3"><mrow id="S3.E3.m1.50.50.2.49.49.49.49.1.1.1.1.1"><mo stretchy="false" id="S3.E3.m1.4.4.4.4.4.4" xref="S3.E3.m1.49.49.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.50.50.2.49.49.49.49.1.1.1.1.1.1"><mn id="S3.E3.m1.5.5.5.5.5.5" xref="S3.E3.m1.5.5.5.5.5.5.cmml">1</mn><mo id="S3.E3.m1.6.6.6.6.6.6" xref="S3.E3.m1.6.6.6.6.6.6.cmml">−</mo><mi id="S3.E3.m1.7.7.7.7.7.7" xref="S3.E3.m1.7.7.7.7.7.7.cmml">λ</mi></mrow><mo stretchy="false" id="S3.E3.m1.8.8.8.8.8.8" xref="S3.E3.m1.49.49.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.50.50.2.49.49.49.49.1.3.3.4" xref="S3.E3.m1.49.49.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.9.9.9.9.9.9" xref="S3.E3.m1.9.9.9.9.9.9.cmml">ℒ</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.50.50.2.49.49.49.49.1.3.3.4a" xref="S3.E3.m1.49.49.1.1.1.cmml">​</mo><mrow id="S3.E3.m1.50.50.2.49.49.49.49.1.3.3.3.2"><mo stretchy="false" id="S3.E3.m1.10.10.10.10.10.10" xref="S3.E3.m1.49.49.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.50.50.2.49.49.49.49.1.2.2.2.1.1"><mi id="S3.E3.m1.11.11.11.11.11.11" xref="S3.E3.m1.11.11.11.11.11.11.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.50.50.2.49.49.49.49.1.2.2.2.1.1.2" xref="S3.E3.m1.49.49.1.1.1.cmml">​</mo><mrow id="S3.E3.m1.50.50.2.49.49.49.49.1.2.2.2.1.1.1.1"><mo stretchy="false" id="S3.E3.m1.12.12.12.12.12.12" xref="S3.E3.m1.49.49.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.50.50.2.49.49.49.49.1.2.2.2.1.1.1.1.1"><mrow id="S3.E3.m1.50.50.2.49.49.49.49.1.2.2.2.1.1.1.1.1.1.1"><mo stretchy="false" id="S3.E3.m1.13.13.13.13.13.13" xref="S3.E3.m1.49.49.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.50.50.2.49.49.49.49.1.2.2.2.1.1.1.1.1.1.1.1"><mn id="S3.E3.m1.14.14.14.14.14.14" xref="S3.E3.m1.14.14.14.14.14.14.cmml">1</mn><mo id="S3.E3.m1.15.15.15.15.15.15" xref="S3.E3.m1.15.15.15.15.15.15.cmml">−</mo><mi id="S3.E3.m1.16.16.16.16.16.16" xref="S3.E3.m1.16.16.16.16.16.16.cmml">λ</mi></mrow><mo stretchy="false" id="S3.E3.m1.17.17.17.17.17.17" xref="S3.E3.m1.49.49.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.50.50.2.49.49.49.49.1.2.2.2.1.1.1.1.1.2" xref="S3.E3.m1.49.49.1.1.1.cmml">​</mo><msub id="S3.E3.m1.50.50.2.49.49.49.49.1.2.2.2.1.1.1.1.1.3"><mi id="S3.E3.m1.18.18.18.18.18.18" xref="S3.E3.m1.18.18.18.18.18.18.cmml">x</mi><mi id="S3.E3.m1.19.19.19.19.19.19.1" xref="S3.E3.m1.19.19.19.19.19.19.1.cmml">i</mi></msub></mrow><mo stretchy="false" id="S3.E3.m1.20.20.20.20.20.20" xref="S3.E3.m1.49.49.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.21.21.21.21.21.21" xref="S3.E3.m1.49.49.1.1.1.cmml">,</mo><msub id="S3.E3.m1.50.50.2.49.49.49.49.1.3.3.3.2.2"><mi id="S3.E3.m1.22.22.22.22.22.22" xref="S3.E3.m1.22.22.22.22.22.22.cmml">y</mi><mi id="S3.E3.m1.23.23.23.23.23.23.1" xref="S3.E3.m1.23.23.23.23.23.23.1.cmml">i</mi></msub><mo stretchy="false" id="S3.E3.m1.24.24.24.24.24.24" xref="S3.E3.m1.49.49.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.25.25.25.25.25.25" xref="S3.E3.m1.25.25.25.25.25.25.cmml">+</mo><mrow id="S3.E3.m1.50.50.2.49.49.49.49.1.5.5"><mi id="S3.E3.m1.26.26.26.26.26.26" xref="S3.E3.m1.26.26.26.26.26.26.cmml">λ</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.50.50.2.49.49.49.49.1.5.5.3" xref="S3.E3.m1.49.49.1.1.1.cmml">​</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.27.27.27.27.27.27" xref="S3.E3.m1.27.27.27.27.27.27.cmml">ℒ</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.50.50.2.49.49.49.49.1.5.5.3a" xref="S3.E3.m1.49.49.1.1.1.cmml">​</mo><mrow id="S3.E3.m1.50.50.2.49.49.49.49.1.5.5.2.2"><mo stretchy="false" id="S3.E3.m1.28.28.28.28.28.28" xref="S3.E3.m1.49.49.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.50.50.2.49.49.49.49.1.4.4.1.1.1"><mi id="S3.E3.m1.29.29.29.29.29.29" xref="S3.E3.m1.29.29.29.29.29.29.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.50.50.2.49.49.49.49.1.4.4.1.1.1.2" xref="S3.E3.m1.49.49.1.1.1.cmml">​</mo><mrow id="S3.E3.m1.50.50.2.49.49.49.49.1.4.4.1.1.1.1.1"><mo stretchy="false" id="S3.E3.m1.30.30.30.30.30.30" xref="S3.E3.m1.49.49.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.50.50.2.49.49.49.49.1.4.4.1.1.1.1.1.1"><mrow id="S3.E3.m1.50.50.2.49.49.49.49.1.4.4.1.1.1.1.1.1.1.1"><mo stretchy="false" id="S3.E3.m1.31.31.31.31.31.31" xref="S3.E3.m1.49.49.1.1.1.cmml">(</mo><mrow id="S3.E3.m1.50.50.2.49.49.49.49.1.4.4.1.1.1.1.1.1.1.1.1"><mn id="S3.E3.m1.32.32.32.32.32.32" xref="S3.E3.m1.32.32.32.32.32.32.cmml">1</mn><mo id="S3.E3.m1.33.33.33.33.33.33" xref="S3.E3.m1.33.33.33.33.33.33.cmml">−</mo><mi id="S3.E3.m1.34.34.34.34.34.34" xref="S3.E3.m1.34.34.34.34.34.34.cmml">λ</mi></mrow><mo stretchy="false" id="S3.E3.m1.35.35.35.35.35.35" xref="S3.E3.m1.49.49.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.E3.m1.50.50.2.49.49.49.49.1.4.4.1.1.1.1.1.1.2" xref="S3.E3.m1.49.49.1.1.1.cmml">​</mo><msub id="S3.E3.m1.50.50.2.49.49.49.49.1.4.4.1.1.1.1.1.1.3"><mi id="S3.E3.m1.36.36.36.36.36.36" xref="S3.E3.m1.36.36.36.36.36.36.cmml">x</mi><mi id="S3.E3.m1.37.37.37.37.37.37.1" xref="S3.E3.m1.37.37.37.37.37.37.1.cmml">i</mi></msub></mrow><mo stretchy="false" id="S3.E3.m1.38.38.38.38.38.38" xref="S3.E3.m1.49.49.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.39.39.39.39.39.39" xref="S3.E3.m1.49.49.1.1.1.cmml">,</mo><msub id="S3.E3.m1.50.50.2.49.49.49.49.1.5.5.2.2.2"><mover accent="true" id="S3.E3.m1.40.40.40.40.40.40" xref="S3.E3.m1.40.40.40.40.40.40.cmml"><mi id="S3.E3.m1.40.40.40.40.40.40.2" xref="S3.E3.m1.40.40.40.40.40.40.2.cmml">y</mi><mo id="S3.E3.m1.40.40.40.40.40.40.1" xref="S3.E3.m1.40.40.40.40.40.40.1.cmml">¯</mo></mover><mi id="S3.E3.m1.41.41.41.41.41.41.1" xref="S3.E3.m1.41.41.41.41.41.41.1.cmml">j</mi></msub><mo stretchy="false" id="S3.E3.m1.42.42.42.42.42.42" xref="S3.E3.m1.49.49.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.25.25.25.25.25.25a" xref="S3.E3.m1.25.25.25.25.25.25.cmml">+</mo><mrow id="S3.E3.m1.50.50.2.49.49.49.49.1.5.6"><mi id="S3.E3.m1.44.44.44.44.44.44" xref="S3.E3.m1.44.44.44.44.44.44.cmml">λ</mi><mo lspace="0em" rspace="0em" id="S3.E3.m1.50.50.2.49.49.49.49.1.5.6.1" xref="S3.E3.m1.49.49.1.1.1.cmml">​</mo><mfrac id="S3.E3.m1.45.45.45.45.45.45" xref="S3.E3.m1.45.45.45.45.45.45.cmml"><mrow id="S3.E3.m1.45.45.45.45.45.45.2" xref="S3.E3.m1.45.45.45.45.45.45.2.cmml"><mo rspace="0em" id="S3.E3.m1.45.45.45.45.45.45.2.1" xref="S3.E3.m1.45.45.45.45.45.45.2.1.cmml">∂</mo><mi class="ltx_font_mathcaligraphic" id="S3.E3.m1.45.45.45.45.45.45.2.2" xref="S3.E3.m1.45.45.45.45.45.45.2.2.cmml">ℒ</mi></mrow><mrow id="S3.E3.m1.45.45.45.45.45.45.3" xref="S3.E3.m1.45.45.45.45.45.45.3.cmml"><mo rspace="0em" id="S3.E3.m1.45.45.45.45.45.45.3.1" xref="S3.E3.m1.45.45.45.45.45.45.3.1.cmml">∂</mo><mi id="S3.E3.m1.45.45.45.45.45.45.3.2" xref="S3.E3.m1.45.45.45.45.45.45.3.2.cmml">x</mi></mrow></mfrac><mo lspace="0em" rspace="0em" id="S3.E3.m1.50.50.2.49.49.49.49.1.5.6.1a" xref="S3.E3.m1.49.49.1.1.1.cmml">​</mo><msub id="S3.E3.m1.50.50.2.49.49.49.49.1.5.6.2"><mover accent="true" id="S3.E3.m1.46.46.46.46.46.46" xref="S3.E3.m1.46.46.46.46.46.46.cmml"><mi id="S3.E3.m1.46.46.46.46.46.46.2" xref="S3.E3.m1.46.46.46.46.46.46.2.cmml">x</mi><mo id="S3.E3.m1.46.46.46.46.46.46.1" xref="S3.E3.m1.46.46.46.46.46.46.1.cmml">¯</mo></mover><mi id="S3.E3.m1.47.47.47.47.47.47.1" xref="S3.E3.m1.47.47.47.47.47.47.1.cmml">j</mi></msub></mrow></mrow></mrow><mo id="S3.E3.m1.48.48.48.48.48.48" xref="S3.E3.m1.49.49.1.1.1.cmml">,</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S3.E3.m1.50b"><apply id="S3.E3.m1.49.49.1.1.1.cmml" xref="S3.E3.m1.4.4.4.4.4.4"><eq id="S3.E3.m1.3.3.3.3.3.3.cmml" xref="S3.E3.m1.3.3.3.3.3.3"></eq><apply id="S3.E3.m1.49.49.1.1.1.7.cmml" xref="S3.E3.m1.4.4.4.4.4.4"><csymbol cd="ambiguous" id="S3.E3.m1.49.49.1.1.1.7.1.cmml" xref="S3.E3.m1.4.4.4.4.4.4">subscript</csymbol><ci id="S3.E3.m1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.1.1.1.1.1.1">ℒ</ci><apply id="S3.E3.m1.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1"><times id="S3.E3.m1.2.2.2.2.2.2.1.1.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1.1"></times><ci id="S3.E3.m1.2.2.2.2.2.2.1.2.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1.2">𝐹</ci><ci id="S3.E3.m1.2.2.2.2.2.2.1.3.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1.3">𝑒</ci><ci id="S3.E3.m1.2.2.2.2.2.2.1.4.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1.4">𝑑</ci><ci id="S3.E3.m1.2.2.2.2.2.2.1.5.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1.5">𝑀</ci><ci id="S3.E3.m1.2.2.2.2.2.2.1.6.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1.6">𝑖</ci><ci id="S3.E3.m1.2.2.2.2.2.2.1.7.cmml" xref="S3.E3.m1.2.2.2.2.2.2.1.7">𝑥</ci></apply></apply><apply id="S3.E3.m1.49.49.1.1.1.5.cmml" xref="S3.E3.m1.4.4.4.4.4.4"><plus id="S3.E3.m1.25.25.25.25.25.25.cmml" xref="S3.E3.m1.25.25.25.25.25.25"></plus><apply id="S3.E3.m1.49.49.1.1.1.3.3.cmml" xref="S3.E3.m1.4.4.4.4.4.4"><times id="S3.E3.m1.49.49.1.1.1.3.3.4.cmml" xref="S3.E3.m1.4.4.4.4.4.4"></times><apply id="S3.E3.m1.49.49.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.4.4.4.4.4.4"><minus id="S3.E3.m1.6.6.6.6.6.6.cmml" xref="S3.E3.m1.6.6.6.6.6.6"></minus><cn type="integer" id="S3.E3.m1.5.5.5.5.5.5.cmml" xref="S3.E3.m1.5.5.5.5.5.5">1</cn><ci id="S3.E3.m1.7.7.7.7.7.7.cmml" xref="S3.E3.m1.7.7.7.7.7.7">𝜆</ci></apply><ci id="S3.E3.m1.9.9.9.9.9.9.cmml" xref="S3.E3.m1.9.9.9.9.9.9">ℒ</ci><interval closure="open" id="S3.E3.m1.49.49.1.1.1.3.3.3.3.cmml" xref="S3.E3.m1.4.4.4.4.4.4"><apply id="S3.E3.m1.49.49.1.1.1.2.2.2.1.1.cmml" xref="S3.E3.m1.4.4.4.4.4.4"><times id="S3.E3.m1.49.49.1.1.1.2.2.2.1.1.2.cmml" xref="S3.E3.m1.4.4.4.4.4.4"></times><ci id="S3.E3.m1.11.11.11.11.11.11.cmml" xref="S3.E3.m1.11.11.11.11.11.11">𝑓</ci><apply id="S3.E3.m1.49.49.1.1.1.2.2.2.1.1.1.1.1.cmml" xref="S3.E3.m1.4.4.4.4.4.4"><times id="S3.E3.m1.49.49.1.1.1.2.2.2.1.1.1.1.1.2.cmml" xref="S3.E3.m1.4.4.4.4.4.4"></times><apply id="S3.E3.m1.49.49.1.1.1.2.2.2.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.4.4.4.4.4.4"><minus id="S3.E3.m1.15.15.15.15.15.15.cmml" xref="S3.E3.m1.15.15.15.15.15.15"></minus><cn type="integer" id="S3.E3.m1.14.14.14.14.14.14.cmml" xref="S3.E3.m1.14.14.14.14.14.14">1</cn><ci id="S3.E3.m1.16.16.16.16.16.16.cmml" xref="S3.E3.m1.16.16.16.16.16.16">𝜆</ci></apply><apply id="S3.E3.m1.49.49.1.1.1.2.2.2.1.1.1.1.1.3.cmml" xref="S3.E3.m1.4.4.4.4.4.4"><csymbol cd="ambiguous" id="S3.E3.m1.49.49.1.1.1.2.2.2.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.4.4.4.4.4.4">subscript</csymbol><ci id="S3.E3.m1.18.18.18.18.18.18.cmml" xref="S3.E3.m1.18.18.18.18.18.18">𝑥</ci><ci id="S3.E3.m1.19.19.19.19.19.19.1.cmml" xref="S3.E3.m1.19.19.19.19.19.19.1">𝑖</ci></apply></apply></apply><apply id="S3.E3.m1.49.49.1.1.1.3.3.3.2.2.cmml" xref="S3.E3.m1.4.4.4.4.4.4"><csymbol cd="ambiguous" id="S3.E3.m1.49.49.1.1.1.3.3.3.2.2.1.cmml" xref="S3.E3.m1.4.4.4.4.4.4">subscript</csymbol><ci id="S3.E3.m1.22.22.22.22.22.22.cmml" xref="S3.E3.m1.22.22.22.22.22.22">𝑦</ci><ci id="S3.E3.m1.23.23.23.23.23.23.1.cmml" xref="S3.E3.m1.23.23.23.23.23.23.1">𝑖</ci></apply></interval></apply><apply id="S3.E3.m1.49.49.1.1.1.5.5.cmml" xref="S3.E3.m1.4.4.4.4.4.4"><times id="S3.E3.m1.49.49.1.1.1.5.5.3.cmml" xref="S3.E3.m1.4.4.4.4.4.4"></times><ci id="S3.E3.m1.26.26.26.26.26.26.cmml" xref="S3.E3.m1.26.26.26.26.26.26">𝜆</ci><ci id="S3.E3.m1.27.27.27.27.27.27.cmml" xref="S3.E3.m1.27.27.27.27.27.27">ℒ</ci><interval closure="open" id="S3.E3.m1.49.49.1.1.1.5.5.2.3.cmml" xref="S3.E3.m1.4.4.4.4.4.4"><apply id="S3.E3.m1.49.49.1.1.1.4.4.1.1.1.cmml" xref="S3.E3.m1.4.4.4.4.4.4"><times id="S3.E3.m1.49.49.1.1.1.4.4.1.1.1.2.cmml" xref="S3.E3.m1.4.4.4.4.4.4"></times><ci id="S3.E3.m1.29.29.29.29.29.29.cmml" xref="S3.E3.m1.29.29.29.29.29.29">𝑓</ci><apply id="S3.E3.m1.49.49.1.1.1.4.4.1.1.1.1.1.1.cmml" xref="S3.E3.m1.4.4.4.4.4.4"><times id="S3.E3.m1.49.49.1.1.1.4.4.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.4.4.4.4.4.4"></times><apply id="S3.E3.m1.49.49.1.1.1.4.4.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.4.4.4.4.4.4"><minus id="S3.E3.m1.33.33.33.33.33.33.cmml" xref="S3.E3.m1.33.33.33.33.33.33"></minus><cn type="integer" id="S3.E3.m1.32.32.32.32.32.32.cmml" xref="S3.E3.m1.32.32.32.32.32.32">1</cn><ci id="S3.E3.m1.34.34.34.34.34.34.cmml" xref="S3.E3.m1.34.34.34.34.34.34">𝜆</ci></apply><apply id="S3.E3.m1.49.49.1.1.1.4.4.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.4.4.4.4.4.4"><csymbol cd="ambiguous" id="S3.E3.m1.49.49.1.1.1.4.4.1.1.1.1.1.1.3.1.cmml" xref="S3.E3.m1.4.4.4.4.4.4">subscript</csymbol><ci id="S3.E3.m1.36.36.36.36.36.36.cmml" xref="S3.E3.m1.36.36.36.36.36.36">𝑥</ci><ci id="S3.E3.m1.37.37.37.37.37.37.1.cmml" xref="S3.E3.m1.37.37.37.37.37.37.1">𝑖</ci></apply></apply></apply><apply id="S3.E3.m1.49.49.1.1.1.5.5.2.2.2.cmml" xref="S3.E3.m1.4.4.4.4.4.4"><csymbol cd="ambiguous" id="S3.E3.m1.49.49.1.1.1.5.5.2.2.2.1.cmml" xref="S3.E3.m1.4.4.4.4.4.4">subscript</csymbol><apply id="S3.E3.m1.40.40.40.40.40.40.cmml" xref="S3.E3.m1.40.40.40.40.40.40"><ci id="S3.E3.m1.40.40.40.40.40.40.1.cmml" xref="S3.E3.m1.40.40.40.40.40.40.1">¯</ci><ci id="S3.E3.m1.40.40.40.40.40.40.2.cmml" xref="S3.E3.m1.40.40.40.40.40.40.2">𝑦</ci></apply><ci id="S3.E3.m1.41.41.41.41.41.41.1.cmml" xref="S3.E3.m1.41.41.41.41.41.41.1">𝑗</ci></apply></interval></apply><apply id="S3.E3.m1.49.49.1.1.1.5.7.cmml" xref="S3.E3.m1.4.4.4.4.4.4"><times id="S3.E3.m1.49.49.1.1.1.5.7.1.cmml" xref="S3.E3.m1.4.4.4.4.4.4"></times><ci id="S3.E3.m1.44.44.44.44.44.44.cmml" xref="S3.E3.m1.44.44.44.44.44.44">𝜆</ci><apply id="S3.E3.m1.45.45.45.45.45.45.cmml" xref="S3.E3.m1.45.45.45.45.45.45"><divide id="S3.E3.m1.45.45.45.45.45.45.1.cmml" xref="S3.E3.m1.45.45.45.45.45.45"></divide><apply id="S3.E3.m1.45.45.45.45.45.45.2.cmml" xref="S3.E3.m1.45.45.45.45.45.45.2"><partialdiff id="S3.E3.m1.45.45.45.45.45.45.2.1.cmml" xref="S3.E3.m1.45.45.45.45.45.45.2.1"></partialdiff><ci id="S3.E3.m1.45.45.45.45.45.45.2.2.cmml" xref="S3.E3.m1.45.45.45.45.45.45.2.2">ℒ</ci></apply><apply id="S3.E3.m1.45.45.45.45.45.45.3.cmml" xref="S3.E3.m1.45.45.45.45.45.45.3"><partialdiff id="S3.E3.m1.45.45.45.45.45.45.3.1.cmml" xref="S3.E3.m1.45.45.45.45.45.45.3.1"></partialdiff><ci id="S3.E3.m1.45.45.45.45.45.45.3.2.cmml" xref="S3.E3.m1.45.45.45.45.45.45.3.2">𝑥</ci></apply></apply><apply id="S3.E3.m1.49.49.1.1.1.5.7.4.cmml" xref="S3.E3.m1.4.4.4.4.4.4"><csymbol cd="ambiguous" id="S3.E3.m1.49.49.1.1.1.5.7.4.1.cmml" xref="S3.E3.m1.4.4.4.4.4.4">subscript</csymbol><apply id="S3.E3.m1.46.46.46.46.46.46.cmml" xref="S3.E3.m1.46.46.46.46.46.46"><ci id="S3.E3.m1.46.46.46.46.46.46.1.cmml" xref="S3.E3.m1.46.46.46.46.46.46.1">¯</ci><ci id="S3.E3.m1.46.46.46.46.46.46.2.cmml" xref="S3.E3.m1.46.46.46.46.46.46.2">𝑥</ci></apply><ci id="S3.E3.m1.47.47.47.47.47.47.1.cmml" xref="S3.E3.m1.47.47.47.47.47.47.1">𝑗</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.50c">\begin{split}\mathcal{L}_{FedMix}=(1-\lambda)\mathcal{L}(f((1-\lambda)x_{i}),y_{i})+\lambda\mathcal{L}(f((1-\lambda)x_{i}),\bar{y}_{j})+\lambda{\frac{\partial\mathcal{L}}{\partial x}}\bar{x}_{j},\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS1.p4.7" class="ltx_p"><span id="S3.SS1.SSS1.p4.7.4" class="ltx_text" style="color:#000000;">where <math id="S3.SS1.SSS1.p4.4.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S3.SS1.SSS1.p4.4.1.m1.1a"><mi mathcolor="#000000" id="S3.SS1.SSS1.p4.4.1.m1.1.1" xref="S3.SS1.SSS1.p4.4.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p4.4.1.m1.1b"><ci id="S3.SS1.SSS1.p4.4.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p4.4.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p4.4.1.m1.1c">\lambda</annotation></semantics></math> represents the mixup rate, and <math id="S3.SS1.SSS1.p4.5.2.m2.1" class="ltx_Math" alttext="\bar{x}_{j}" display="inline"><semantics id="S3.SS1.SSS1.p4.5.2.m2.1a"><msub id="S3.SS1.SSS1.p4.5.2.m2.1.1" xref="S3.SS1.SSS1.p4.5.2.m2.1.1.cmml"><mover accent="true" id="S3.SS1.SSS1.p4.5.2.m2.1.1.2" xref="S3.SS1.SSS1.p4.5.2.m2.1.1.2.cmml"><mi mathcolor="#000000" id="S3.SS1.SSS1.p4.5.2.m2.1.1.2.2" xref="S3.SS1.SSS1.p4.5.2.m2.1.1.2.2.cmml">x</mi><mo mathcolor="#000000" id="S3.SS1.SSS1.p4.5.2.m2.1.1.2.1" xref="S3.SS1.SSS1.p4.5.2.m2.1.1.2.1.cmml">¯</mo></mover><mi mathcolor="#000000" id="S3.SS1.SSS1.p4.5.2.m2.1.1.3" xref="S3.SS1.SSS1.p4.5.2.m2.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p4.5.2.m2.1b"><apply id="S3.SS1.SSS1.p4.5.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p4.5.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p4.5.2.m2.1.1.1.cmml" xref="S3.SS1.SSS1.p4.5.2.m2.1.1">subscript</csymbol><apply id="S3.SS1.SSS1.p4.5.2.m2.1.1.2.cmml" xref="S3.SS1.SSS1.p4.5.2.m2.1.1.2"><ci id="S3.SS1.SSS1.p4.5.2.m2.1.1.2.1.cmml" xref="S3.SS1.SSS1.p4.5.2.m2.1.1.2.1">¯</ci><ci id="S3.SS1.SSS1.p4.5.2.m2.1.1.2.2.cmml" xref="S3.SS1.SSS1.p4.5.2.m2.1.1.2.2">𝑥</ci></apply><ci id="S3.SS1.SSS1.p4.5.2.m2.1.1.3.cmml" xref="S3.SS1.SSS1.p4.5.2.m2.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p4.5.2.m2.1c">\bar{x}_{j}</annotation></semantics></math> and <math id="S3.SS1.SSS1.p4.6.3.m3.1" class="ltx_Math" alttext="\bar{y}_{j}" display="inline"><semantics id="S3.SS1.SSS1.p4.6.3.m3.1a"><msub id="S3.SS1.SSS1.p4.6.3.m3.1.1" xref="S3.SS1.SSS1.p4.6.3.m3.1.1.cmml"><mover accent="true" id="S3.SS1.SSS1.p4.6.3.m3.1.1.2" xref="S3.SS1.SSS1.p4.6.3.m3.1.1.2.cmml"><mi mathcolor="#000000" id="S3.SS1.SSS1.p4.6.3.m3.1.1.2.2" xref="S3.SS1.SSS1.p4.6.3.m3.1.1.2.2.cmml">y</mi><mo mathcolor="#000000" id="S3.SS1.SSS1.p4.6.3.m3.1.1.2.1" xref="S3.SS1.SSS1.p4.6.3.m3.1.1.2.1.cmml">¯</mo></mover><mi mathcolor="#000000" id="S3.SS1.SSS1.p4.6.3.m3.1.1.3" xref="S3.SS1.SSS1.p4.6.3.m3.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p4.6.3.m3.1b"><apply id="S3.SS1.SSS1.p4.6.3.m3.1.1.cmml" xref="S3.SS1.SSS1.p4.6.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p4.6.3.m3.1.1.1.cmml" xref="S3.SS1.SSS1.p4.6.3.m3.1.1">subscript</csymbol><apply id="S3.SS1.SSS1.p4.6.3.m3.1.1.2.cmml" xref="S3.SS1.SSS1.p4.6.3.m3.1.1.2"><ci id="S3.SS1.SSS1.p4.6.3.m3.1.1.2.1.cmml" xref="S3.SS1.SSS1.p4.6.3.m3.1.1.2.1">¯</ci><ci id="S3.SS1.SSS1.p4.6.3.m3.1.1.2.2.cmml" xref="S3.SS1.SSS1.p4.6.3.m3.1.1.2.2">𝑦</ci></apply><ci id="S3.SS1.SSS1.p4.6.3.m3.1.1.3.cmml" xref="S3.SS1.SSS1.p4.6.3.m3.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p4.6.3.m3.1c">\bar{y}_{j}</annotation></semantics></math> refer to the means of all inputs and labels received from client <math id="S3.SS1.SSS1.p4.7.4.m4.1" class="ltx_Math" alttext="j" display="inline"><semantics id="S3.SS1.SSS1.p4.7.4.m4.1a"><mi mathcolor="#000000" id="S3.SS1.SSS1.p4.7.4.m4.1.1" xref="S3.SS1.SSS1.p4.7.4.m4.1.1.cmml">j</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p4.7.4.m4.1b"><ci id="S3.SS1.SSS1.p4.7.4.m4.1.1.cmml" xref="S3.SS1.SSS1.p4.7.4.m4.1.1">𝑗</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p4.7.4.m4.1c">j</annotation></semantics></math>.</span> However, MAFL may pose a threat to privacy security. Especially when there are insufficient local data, the averaged data contain a large amount of raw relevant information, and adequate privacy restrictions for the raw data cannot be ensured. In Astraea <cite class="ltx_cite ltx_citemacro_cite">Duan et al<span class="ltx_text">.</span> (<a href="#bib.bib44" title="" class="ltx_ref">2019</a>)</cite>, the server collects the local data distributions of the clients in the initialization phase and then performs data augmentation based on the global data distribution. To alleviate data distribution imbalance, Astraea creates mediators that rearrange the training of clients based on the KullbackLeibler (KL) divergence of the local data distributions. Federated augmentation (FAug) <cite class="ltx_cite ltx_citemacro_cite">Jeong et al<span class="ltx_text">.</span> (<a href="#bib.bib93" title="" class="ltx_ref">2018</a>)</cite> is a data augmentation scheme using GAN. Each client can identify target labels that are lacking in data samples. Subsequently, the clients upload partial data samples of the target labels to the server, and the server oversamples the uploaded data samples to train a conditional GAN. In this manner, the clients effectively enhance the statistical homogeneity of the local data by generating missing data samples using the received GAN.</p>
</div>
<div id="S3.SS1.SSS1.p5" class="ltx_para">
<p id="S3.SS1.SSS1.p5.1" class="ltx_p"><span id="S3.SS1.SSS1.p5.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">Data Privacy Protection.</span>
<span id="S3.SS1.SSS1.p5.1.2" class="ltx_text" style="color:#000000;">To ensure that original information about commercial encryption, user privacy, etc. is not leaked to other clients, methods for data privacy protection at the local level have been extensively studied. These methods generally fall into three categories <cite class="ltx_cite ltx_citemacro_cite">Yin et al<span class="ltx_text">.</span> (<a href="#bib.bib233" title="" class="ltx_ref">2021</a>)</cite>, namely data encryption, perturbation and anonymization (Fig. <a href="#S3.F6" title="Figure 6 ‣ 3.1. Data-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>).</span></p>
</div>
<div id="S3.SS1.SSS1.p6" class="ltx_para">
<p id="S3.SS1.SSS1.p6.1" class="ltx_p"><span id="S3.SS1.SSS1.p6.1.1" class="ltx_text" style="color:#000000;">Homomorphic encryption is a commonly used data encryption method that allows computations to be performed using encrypted data without decryption. Asad <span id="S3.SS1.SSS1.p6.1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Asad et al<span class="ltx_text">.</span> (<a href="#bib.bib8" title="" class="ltx_ref">2020</a>); Fang et al<span class="ltx_text">.</span> (<a href="#bib.bib48" title="" class="ltx_ref">2020</a>)</cite> apply homomorphic encryption to federated learning, enabling the client to encrypt its local model with a private key and then send it to the server. So the server can only get encrypted model parameters and cannot deduce any private information. DP is the most commonly used method when using data perturbation to achieve privacy protection. It protects the client’s private information by clipping and adding noise to local updates. Hu <span id="S3.SS1.SSS1.p6.1.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Hu et al<span class="ltx_text">.</span> (<a href="#bib.bib81" title="" class="ltx_ref">2020a</a>)</cite> propose a federated learning method for personalized local DP, PLDP-PFL. It allows each client to choose an appropriate privacy budget for personalized differential privacy according to the sensitivity of its private data. To alleviate the model performance degradation caused by DP, Shi <span id="S3.SS1.SSS1.p6.1.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Shi et al<span class="ltx_text">.</span> (<a href="#bib.bib188" title="" class="ltx_ref">2023a</a>)</cite> propose a federated learning framework with DP, DP-FedSAM. It leverages the sharpness aware minimization optimizer while updating locally to generate a local flatness model with better stability and robustness to weight perturbations, thus improving its robustness to DP noise. Data anonymization makes it difficult for data subjects to be identified by removing or replacing identifiable sensitive information in the data. Choudhury <span id="S3.SS1.SSS1.p6.1.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Choudhury et al<span class="ltx_text">.</span> (<a href="#bib.bib34" title="" class="ltx_ref">2020</a>)</cite> make the clients generate their own anonymous data mapping according to the characteristics of the local data set, that is, convert the original data into some random numbers or symbols, so as to desensitize the original data.</span></p>
</div>
<figure id="S3.F7" class="ltx_figure"><img src="/html/2307.10616/assets/x7.png" id="S3.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="327" height="204" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7. </span><span id="S3.F7.2.1" class="ltx_text" style="font-size:90%;">Illustration of external data utilization methods in heterogeneous federated learning.</span></figcaption>
</figure>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2. </span> External Data Utilization</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.1" class="ltx_p"><span id="S3.SS1.SSS2.p1.1.1" class="ltx_text ltx_font_bold">Knowledge Distillation from External Data.</span>
<span id="S3.SS1.SSS2.p1.1.2" class="ltx_text" style="color:#000000;">This method leverages external data sources for knowledge distillation to improve federated learning performance (Fig. <a href="#S3.F7" title="Figure 7 ‣ 3.1.1. Private Data Processing ‣ 3.1. Data-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>), where external data usually refers to public data. The idea is to use a global teacher model trained on an external dataset to help clients generate soft labels for local data. Then, clients utilize these soft labels as an additional supervision for local updates, thereby improving the generalization ability of the model and mitigating the impact of data heterogeneity. Besides, the distillation methods are often used to address model heterogeneity by utilizing external easily accessed data <cite class="ltx_cite ltx_citemacro_cite">Huang et al<span class="ltx_text">.</span> (<a href="#bib.bib86" title="" class="ltx_ref">2022b</a>); Fang and Ye (<a href="#bib.bib49" title="" class="ltx_ref">2022</a>)</cite>. Specifically, each client computes the output prediction distribution of the local model on external data, and sends the output as local knowledge to the server or other clients. And distillation means that other clients update their own local model parameters based on the received knowledge. In this way, clients with heterogeneous models can share local information in a blackbox manner, thereby alleviating the impact of model heterogeneity.</span></p>
</div>
<div id="S3.SS1.SSS2.p2" class="ltx_para">
<p id="S3.SS1.SSS2.p2.1" class="ltx_p">FAug <cite class="ltx_cite ltx_citemacro_cite">Jeong et al<span class="ltx_text">.</span> (<a href="#bib.bib93" title="" class="ltx_ref">2018</a>)</cite> and FedMD <cite class="ltx_cite ltx_citemacro_cite">Li and Wang (<a href="#bib.bib114" title="" class="ltx_ref">2019</a>)</cite> utilize Federated Distillation (FD), also known as Co-Distillation (CD), to learn knowledge from other clients. Each client stores a local model output and considers the average local model output of all clients as the global output. Huang <span id="S3.SS1.SSS2.p2.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Huang et al<span class="ltx_text">.</span> (<a href="#bib.bib87" title="" class="ltx_ref">2022c</a>)</cite> adopt a federated communication strategy similar to FedMD, and innovatively adds a latent embedding adaptation module, which alleviates the impact of the large domain gap between public dataset and private datasets. Considering the global model as a teacher and the local model as a student, Yu <span id="S3.SS1.SSS2.p2.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Yu et al<span class="ltx_text">.</span> (<a href="#bib.bib237" title="" class="ltx_ref">2020</a>)</cite> attempt to mitigate overfitting in personalized updates by enhancing the logits similarity between the global model and the local models. FedGKT <cite class="ltx_cite ltx_citemacro_cite">He et al<span class="ltx_text">.</span> (<a href="#bib.bib72" title="" class="ltx_ref">2020a</a>)</cite> periodically transfers the knowledge of small CNNs on edges to the large server-side CNN through knowledge distillation, thereby decreasing the burden of edge training. Besides, several recent approaches utilize knowledge distillation to mitigate statistical heterogeneity among clients. FedFTG <cite class="ltx_cite ltx_citemacro_cite">Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib246" title="" class="ltx_ref">2022e</a>)</cite> trains a conditional generator to fit the input space of a local model, which is then used to generate pseudo data. These pseudo data are input to the global model and the local model for knowledge distillation, and the knowledge of the local model is transferred to the global model by narrowing the Kullback-Leibler divergence between their output predictions.</p>
</div>
<div id="S3.SS1.SSS2.p3" class="ltx_para">
<p id="S3.SS1.SSS2.p3.1" class="ltx_p"><span id="S3.SS1.SSS2.p3.1.1" class="ltx_text ltx_font_bold">Unsupervised Representation Learning.</span>
Since the private data from clients are usually difficult to annotation <cite class="ltx_cite ltx_citemacro_cite">Ye et al<span class="ltx_text">.</span> (<a href="#bib.bib231" title="" class="ltx_ref">2020</a>)</cite> and it usually involves huge manual cost, Federated Unsupervised Representation Learning (FURL) <cite class="ltx_cite ltx_citemacro_cite">van Berlo et al<span class="ltx_text">.</span> (<a href="#bib.bib207" title="" class="ltx_ref">2020</a>); Lubana et al<span class="ltx_text">.</span> (<a href="#bib.bib138" title="" class="ltx_ref">2022</a>)</cite> is discussed to learn a common representation model while keeping private data decentralized and unlabeled (Fig. <a href="#S3.F7" title="Figure 7 ‣ 3.1.1. Private Data Processing ‣ 3.1. Data-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>).</p>
</div>
<div id="S3.SS1.SSS2.p4" class="ltx_para">
<p id="S3.SS1.SSS2.p4.3" class="ltx_p">FedCA <cite class="ltx_cite ltx_citemacro_cite">Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib240" title="" class="ltx_ref">2020c</a>)</cite> is a federated unsupervised representation learning algorithm based on contrastive loss, which can address data distribution inconsistencies and representation misalignment across clients. FedCA includes a dictionary module that aggregates sample representations from all clients and sharing them with clients, and an alignment module that aligns the representations of each client on public data. Briefly, the clients generate local dictionaries through the above two contrastive learning modules, and then the server aggregates the trained local models and integrates the local dictionaries into the global dictionary. Similarly, MOON <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib119" title="" class="ltx_ref">2021c</a>)</cite> and FedProc <cite class="ltx_cite ltx_citemacro_cite">Mu et al<span class="ltx_text">.</span> (<a href="#bib.bib162" title="" class="ltx_ref">2021</a>)</cite> also use contrastive learning to address statistical heterogeneity in federated learning. MOON corrects the update direction by introducing a model-contrastive loss. Its objective is to drive the representation learned by the current local model to be consistent with that learned by the global model, while increasing the distance between the representation learned by the current local model and that learned by the previous local model. <math id="S3.SS1.SSS2.p4.1.m1.1" class="ltx_Math" alttext="z" display="inline"><semantics id="S3.SS1.SSS2.p4.1.m1.1a"><mi id="S3.SS1.SSS2.p4.1.m1.1.1" xref="S3.SS1.SSS2.p4.1.m1.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p4.1.m1.1b"><ci id="S3.SS1.SSS2.p4.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p4.1.m1.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p4.1.m1.1c">z</annotation></semantics></math>, <math id="S3.SS1.SSS2.p4.2.m2.1" class="ltx_Math" alttext="z_{p}" display="inline"><semantics id="S3.SS1.SSS2.p4.2.m2.1a"><msub id="S3.SS1.SSS2.p4.2.m2.1.1" xref="S3.SS1.SSS2.p4.2.m2.1.1.cmml"><mi id="S3.SS1.SSS2.p4.2.m2.1.1.2" xref="S3.SS1.SSS2.p4.2.m2.1.1.2.cmml">z</mi><mi id="S3.SS1.SSS2.p4.2.m2.1.1.3" xref="S3.SS1.SSS2.p4.2.m2.1.1.3.cmml">p</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p4.2.m2.1b"><apply id="S3.SS1.SSS2.p4.2.m2.1.1.cmml" xref="S3.SS1.SSS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p4.2.m2.1.1.1.cmml" xref="S3.SS1.SSS2.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p4.2.m2.1.1.2.cmml" xref="S3.SS1.SSS2.p4.2.m2.1.1.2">𝑧</ci><ci id="S3.SS1.SSS2.p4.2.m2.1.1.3.cmml" xref="S3.SS1.SSS2.p4.2.m2.1.1.3">𝑝</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p4.2.m2.1c">z_{p}</annotation></semantics></math>, and <math id="S3.SS1.SSS2.p4.3.m3.1" class="ltx_Math" alttext="z_{g}" display="inline"><semantics id="S3.SS1.SSS2.p4.3.m3.1a"><msub id="S3.SS1.SSS2.p4.3.m3.1.1" xref="S3.SS1.SSS2.p4.3.m3.1.1.cmml"><mi id="S3.SS1.SSS2.p4.3.m3.1.1.2" xref="S3.SS1.SSS2.p4.3.m3.1.1.2.cmml">z</mi><mi id="S3.SS1.SSS2.p4.3.m3.1.1.3" xref="S3.SS1.SSS2.p4.3.m3.1.1.3.cmml">g</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p4.3.m3.1b"><apply id="S3.SS1.SSS2.p4.3.m3.1.1.cmml" xref="S3.SS1.SSS2.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p4.3.m3.1.1.1.cmml" xref="S3.SS1.SSS2.p4.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p4.3.m3.1.1.2.cmml" xref="S3.SS1.SSS2.p4.3.m3.1.1.2">𝑧</ci><ci id="S3.SS1.SSS2.p4.3.m3.1.1.3.cmml" xref="S3.SS1.SSS2.p4.3.m3.1.1.3">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p4.3.m3.1c">z_{g}</annotation></semantics></math> denote the representations from the current local model, previous local model, and global model, respectively. Therefore, the model-contrastive loss can be defined as:</p>
<table id="S3.E4" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E4.m1.9" class="ltx_Math" alttext="\begin{split}\mathcal{L}_{con}=-\log\frac{\exp(sim(z,z_{g})/\tau)}{\exp(sim(z,z_{g})/\tau)+\exp(sim(z,z_{p})/\tau)},\end{split}" display="block"><semantics id="S3.E4.m1.9a"><mtable displaystyle="true" id="S3.E4.m1.9.9.2"><mtr id="S3.E4.m1.9.9.2a"><mtd class="ltx_align_right" columnalign="right" id="S3.E4.m1.9.9.2b"><mrow id="S3.E4.m1.9.9.2.8.8.8.8"><mrow id="S3.E4.m1.9.9.2.8.8.8.8.1"><msub id="S3.E4.m1.9.9.2.8.8.8.8.1.1"><mi class="ltx_font_mathcaligraphic" id="S3.E4.m1.1.1.1.1.1.1" xref="S3.E4.m1.1.1.1.1.1.1.cmml">ℒ</mi><mrow id="S3.E4.m1.2.2.2.2.2.2.1" xref="S3.E4.m1.2.2.2.2.2.2.1.cmml"><mi id="S3.E4.m1.2.2.2.2.2.2.1.2" xref="S3.E4.m1.2.2.2.2.2.2.1.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.2.2.2.2.1.1" xref="S3.E4.m1.2.2.2.2.2.2.1.1.cmml">​</mo><mi id="S3.E4.m1.2.2.2.2.2.2.1.3" xref="S3.E4.m1.2.2.2.2.2.2.1.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.2.2.2.2.2.2.1.1a" xref="S3.E4.m1.2.2.2.2.2.2.1.1.cmml">​</mo><mi id="S3.E4.m1.2.2.2.2.2.2.1.4" xref="S3.E4.m1.2.2.2.2.2.2.1.4.cmml">n</mi></mrow></msub><mo id="S3.E4.m1.3.3.3.3.3.3" xref="S3.E4.m1.3.3.3.3.3.3.cmml">=</mo><mrow id="S3.E4.m1.9.9.2.8.8.8.8.1.2"><mo rspace="0.167em" id="S3.E4.m1.9.9.2.8.8.8.8.1.2a" xref="S3.E4.m1.8.8.1.1.1.cmml">−</mo><mrow id="S3.E4.m1.9.9.2.8.8.8.8.1.2.1"><mi id="S3.E4.m1.5.5.5.5.5.5" xref="S3.E4.m1.5.5.5.5.5.5.cmml">log</mi><mo lspace="0.167em" id="S3.E4.m1.9.9.2.8.8.8.8.1.2.1a" xref="S3.E4.m1.8.8.1.1.1.cmml">⁡</mo><mfrac id="S3.E4.m1.6.6.6.6.6.6" xref="S3.E4.m1.6.6.6.6.6.6.cmml"><mrow id="S3.E4.m1.6.6.6.6.6.6.3.3" xref="S3.E4.m1.6.6.6.6.6.6.3.4.cmml"><mi id="S3.E4.m1.6.6.6.6.6.6.2.2" xref="S3.E4.m1.6.6.6.6.6.6.2.2.cmml">exp</mi><mo id="S3.E4.m1.6.6.6.6.6.6.3.3a" xref="S3.E4.m1.6.6.6.6.6.6.3.4.cmml">⁡</mo><mrow id="S3.E4.m1.6.6.6.6.6.6.3.3.1" xref="S3.E4.m1.6.6.6.6.6.6.3.4.cmml"><mo stretchy="false" id="S3.E4.m1.6.6.6.6.6.6.3.3.1.2" xref="S3.E4.m1.6.6.6.6.6.6.3.4.cmml">(</mo><mrow id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.cmml"><mrow id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.cmml"><mi id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.3" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.2" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.2.cmml">​</mo><mi id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.4" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.2a" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.2.cmml">​</mo><mi id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.5" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.5.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.2b" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.2.cmml">​</mo><mrow id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.1" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.1.2" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.2.cmml">(</mo><mi id="S3.E4.m1.6.6.6.6.6.6.1.1" xref="S3.E4.m1.6.6.6.6.6.6.1.1.cmml">z</mi><mo id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.1.3" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.2.cmml">,</mo><msub id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.1.1" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.1.1.2" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.1.1.2.cmml">z</mi><mi id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.1.1.3" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.1.1.3.cmml">g</mi></msub><mo stretchy="false" id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.1.4" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.2" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.2.cmml">/</mo><mi id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.3" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.3.cmml">τ</mi></mrow><mo stretchy="false" id="S3.E4.m1.6.6.6.6.6.6.3.3.1.3" xref="S3.E4.m1.6.6.6.6.6.6.3.4.cmml">)</mo></mrow></mrow><mrow id="S3.E4.m1.6.6.6.6.6.6.9" xref="S3.E4.m1.6.6.6.6.6.6.9.cmml"><mrow id="S3.E4.m1.6.6.6.6.6.6.8.5.1" xref="S3.E4.m1.6.6.6.6.6.6.8.5.2.cmml"><mi id="S3.E4.m1.6.6.6.6.6.6.5.2" xref="S3.E4.m1.6.6.6.6.6.6.5.2.cmml">exp</mi><mo id="S3.E4.m1.6.6.6.6.6.6.8.5.1a" xref="S3.E4.m1.6.6.6.6.6.6.8.5.2.cmml">⁡</mo><mrow id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1" xref="S3.E4.m1.6.6.6.6.6.6.8.5.2.cmml"><mo stretchy="false" id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.2" xref="S3.E4.m1.6.6.6.6.6.6.8.5.2.cmml">(</mo><mrow id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.cmml"><mrow id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.cmml"><mi id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.3" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.2" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.2.cmml">​</mo><mi id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.4" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.2a" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.2.cmml">​</mo><mi id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.5" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.5.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.2b" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.2.cmml">​</mo><mrow id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.1" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.1.2" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.2.cmml">(</mo><mi id="S3.E4.m1.6.6.6.6.6.6.4.1" xref="S3.E4.m1.6.6.6.6.6.6.4.1.cmml">z</mi><mo id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.1.3" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.2.cmml">,</mo><msub id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.1.1" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.1.1.2" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.1.1.2.cmml">z</mi><mi id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.1.1.3" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.1.1.3.cmml">g</mi></msub><mo stretchy="false" id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.1.4" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.2" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.2.cmml">/</mo><mi id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.3" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.3.cmml">τ</mi></mrow><mo stretchy="false" id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.3" xref="S3.E4.m1.6.6.6.6.6.6.8.5.2.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.6.6.6.6.6.6.9.7" xref="S3.E4.m1.6.6.6.6.6.6.9.7.cmml">+</mo><mrow id="S3.E4.m1.6.6.6.6.6.6.9.6.1" xref="S3.E4.m1.6.6.6.6.6.6.9.6.2.cmml"><mi id="S3.E4.m1.6.6.6.6.6.6.7.4" xref="S3.E4.m1.6.6.6.6.6.6.7.4.cmml">exp</mi><mo id="S3.E4.m1.6.6.6.6.6.6.9.6.1a" xref="S3.E4.m1.6.6.6.6.6.6.9.6.2.cmml">⁡</mo><mrow id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1" xref="S3.E4.m1.6.6.6.6.6.6.9.6.2.cmml"><mo stretchy="false" id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.2" xref="S3.E4.m1.6.6.6.6.6.6.9.6.2.cmml">(</mo><mrow id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.cmml"><mrow id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.cmml"><mi id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.3" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.3.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.2" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.2.cmml">​</mo><mi id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.4" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.4.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.2a" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.2.cmml">​</mo><mi id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.5" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.5.cmml">m</mi><mo lspace="0em" rspace="0em" id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.2b" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.2.cmml">​</mo><mrow id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.1" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.1.2" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.2.cmml">(</mo><mi id="S3.E4.m1.6.6.6.6.6.6.6.3" xref="S3.E4.m1.6.6.6.6.6.6.6.3.cmml">z</mi><mo id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.1.3" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.2.cmml">,</mo><msub id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.1.1" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.1.1.cmml"><mi id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.1.1.2" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.1.1.2.cmml">z</mi><mi id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.1.1.3" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.1.1.3.cmml">p</mi></msub><mo stretchy="false" id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.1.4" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.2.cmml">)</mo></mrow></mrow><mo id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.2" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.2.cmml">/</mo><mi id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.3" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.3.cmml">τ</mi></mrow><mo stretchy="false" id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.3" xref="S3.E4.m1.6.6.6.6.6.6.9.6.2.cmml">)</mo></mrow></mrow></mrow></mfrac></mrow></mrow></mrow><mo id="S3.E4.m1.7.7.7.7.7.7" xref="S3.E4.m1.8.8.1.1.1.cmml">,</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S3.E4.m1.9b"><apply id="S3.E4.m1.8.8.1.1.1.cmml" xref="S3.E4.m1.9.9.2.8.8.8.8.1.2a"><eq id="S3.E4.m1.3.3.3.3.3.3.cmml" xref="S3.E4.m1.3.3.3.3.3.3"></eq><apply id="S3.E4.m1.8.8.1.1.1.2.cmml" xref="S3.E4.m1.9.9.2.8.8.8.8.1.2a"><csymbol cd="ambiguous" id="S3.E4.m1.8.8.1.1.1.2.1.cmml" xref="S3.E4.m1.9.9.2.8.8.8.8.1.2a">subscript</csymbol><ci id="S3.E4.m1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.1.1.1.1.1.1">ℒ</ci><apply id="S3.E4.m1.2.2.2.2.2.2.1.cmml" xref="S3.E4.m1.2.2.2.2.2.2.1"><times id="S3.E4.m1.2.2.2.2.2.2.1.1.cmml" xref="S3.E4.m1.2.2.2.2.2.2.1.1"></times><ci id="S3.E4.m1.2.2.2.2.2.2.1.2.cmml" xref="S3.E4.m1.2.2.2.2.2.2.1.2">𝑐</ci><ci id="S3.E4.m1.2.2.2.2.2.2.1.3.cmml" xref="S3.E4.m1.2.2.2.2.2.2.1.3">𝑜</ci><ci id="S3.E4.m1.2.2.2.2.2.2.1.4.cmml" xref="S3.E4.m1.2.2.2.2.2.2.1.4">𝑛</ci></apply></apply><apply id="S3.E4.m1.8.8.1.1.1.3.cmml" xref="S3.E4.m1.9.9.2.8.8.8.8.1.2a"><minus id="S3.E4.m1.4.4.4.4.4.4.cmml" xref="S3.E4.m1.9.9.2.8.8.8.8.1.2a"></minus><apply id="S3.E4.m1.8.8.1.1.1.3.2.cmml" xref="S3.E4.m1.9.9.2.8.8.8.8.1.2a"><log id="S3.E4.m1.5.5.5.5.5.5.cmml" xref="S3.E4.m1.5.5.5.5.5.5"></log><apply id="S3.E4.m1.6.6.6.6.6.6.cmml" xref="S3.E4.m1.6.6.6.6.6.6"><divide id="S3.E4.m1.6.6.6.6.6.6.10.cmml" xref="S3.E4.m1.6.6.6.6.6.6"></divide><apply id="S3.E4.m1.6.6.6.6.6.6.3.4.cmml" xref="S3.E4.m1.6.6.6.6.6.6.3.3"><exp id="S3.E4.m1.6.6.6.6.6.6.2.2.cmml" xref="S3.E4.m1.6.6.6.6.6.6.2.2"></exp><apply id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.cmml" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1"><divide id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.2.cmml" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.2"></divide><apply id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.cmml" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1"><times id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.2.cmml" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.2"></times><ci id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.3.cmml" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.3">𝑠</ci><ci id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.4.cmml" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.4">𝑖</ci><ci id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.5.cmml" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.5">𝑚</ci><interval closure="open" id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.2.cmml" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.1"><ci id="S3.E4.m1.6.6.6.6.6.6.1.1.cmml" xref="S3.E4.m1.6.6.6.6.6.6.1.1">𝑧</ci><apply id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.1.1.cmml" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.1.1.2">𝑧</ci><ci id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.1.1.1.1.3">𝑔</ci></apply></interval></apply><ci id="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.3.cmml" xref="S3.E4.m1.6.6.6.6.6.6.3.3.1.1.3">𝜏</ci></apply></apply><apply id="S3.E4.m1.6.6.6.6.6.6.9.cmml" xref="S3.E4.m1.6.6.6.6.6.6.9"><plus id="S3.E4.m1.6.6.6.6.6.6.9.7.cmml" xref="S3.E4.m1.6.6.6.6.6.6.9.7"></plus><apply id="S3.E4.m1.6.6.6.6.6.6.8.5.2.cmml" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1"><exp id="S3.E4.m1.6.6.6.6.6.6.5.2.cmml" xref="S3.E4.m1.6.6.6.6.6.6.5.2"></exp><apply id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.cmml" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1"><divide id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.2.cmml" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.2"></divide><apply id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.cmml" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1"><times id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.2.cmml" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.2"></times><ci id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.3.cmml" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.3">𝑠</ci><ci id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.4.cmml" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.4">𝑖</ci><ci id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.5.cmml" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.5">𝑚</ci><interval closure="open" id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.2.cmml" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.1"><ci id="S3.E4.m1.6.6.6.6.6.6.4.1.cmml" xref="S3.E4.m1.6.6.6.6.6.6.4.1">𝑧</ci><apply id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.1.1.2">𝑧</ci><ci id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.1.1.1.1.3">𝑔</ci></apply></interval></apply><ci id="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.3.cmml" xref="S3.E4.m1.6.6.6.6.6.6.8.5.1.1.1.3">𝜏</ci></apply></apply><apply id="S3.E4.m1.6.6.6.6.6.6.9.6.2.cmml" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1"><exp id="S3.E4.m1.6.6.6.6.6.6.7.4.cmml" xref="S3.E4.m1.6.6.6.6.6.6.7.4"></exp><apply id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.cmml" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1"><divide id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.2.cmml" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.2"></divide><apply id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.cmml" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1"><times id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.2.cmml" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.2"></times><ci id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.3.cmml" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.3">𝑠</ci><ci id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.4.cmml" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.4">𝑖</ci><ci id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.5.cmml" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.5">𝑚</ci><interval closure="open" id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.2.cmml" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.1"><ci id="S3.E4.m1.6.6.6.6.6.6.6.3.cmml" xref="S3.E4.m1.6.6.6.6.6.6.6.3">𝑧</ci><apply id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.1.1.1.cmml" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.1.1.2.cmml" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.1.1.2">𝑧</ci><ci id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.1.1.3.cmml" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.1.1.1.1.3">𝑝</ci></apply></interval></apply><ci id="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.3.cmml" xref="S3.E4.m1.6.6.6.6.6.6.9.6.1.1.1.3">𝜏</ci></apply></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E4.m1.9c">\begin{split}\mathcal{L}_{con}=-\log\frac{\exp(sim(z,z_{g})/\tau)}{\exp(sim(z,z_{g})/\tau)+\exp(sim(z,z_{p})/\tau)},\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(4)</span></td>
</tr></tbody>
</table>
<p id="S3.SS1.SSS2.p4.4" class="ltx_p">where <math id="S3.SS1.SSS2.p4.4.m1.1" class="ltx_Math" alttext="\tau" display="inline"><semantics id="S3.SS1.SSS2.p4.4.m1.1a"><mi id="S3.SS1.SSS2.p4.4.m1.1.1" xref="S3.SS1.SSS2.p4.4.m1.1.1.cmml">τ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p4.4.m1.1b"><ci id="S3.SS1.SSS2.p4.4.m1.1.1.cmml" xref="S3.SS1.SSS2.p4.4.m1.1.1">𝜏</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p4.4.m1.1c">\tau</annotation></semantics></math> represents a temperature parameter. The main idea of FedProc is to treat the global prototype as global knowledge, and use a local network architecture and a global prototype contrastive loss to constrain the training of the local model. <span id="S3.SS1.SSS2.p4.4.1" class="ltx_text" style="color:#000000;">Different from MOON, Tan et al. <cite class="ltx_cite ltx_citemacro_cite">Tan et al<span class="ltx_text">.</span> (<a href="#bib.bib200" title="" class="ltx_ref">2022a</a>)</cite> propose FedProto, which only transfers the prototype to the client without transferring the model parameters and gradients. This method can handle various heterogeneous problems more efficiently.</span></p>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2. </span>Model-Level Methods</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p"><span id="S3.SS2.p1.1.1" class="ltx_text" style="color:#000000;">In this subsection, we categorize model-level methods, introduce representative methods in each category, and discuss their contributions and limitations, as shown in Tab. <a href="#S3.T3" title="Table 3 ‣ 3.2. Model-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Model-level methods represent methods for innovative design at the model level, mainly including federated optimization, knowledge transfer across models, and architecture sharing. Federated optimization aims to adapt the model to the local distribution while learning the global information. They can effectively realize local model personalization under statistical heterogeneity. Knowledge transfer across models enables multi-party collaboration in a model-agnostic manner and thus is usually used to solve model and communication heterogeneity. Architecture sharing realizes personalized federated learning by sharing part of the model structure and can solve statistical, model and device heterogeneity simultaneously to some extent. The data-level methods can solve the problem associated with large differences in data distribution to a certain extent and accelerate convergence by smoothing the statistical heterogeneity among data.
In contrast, the model-level methods aim to learn a local model for each client that adapts to its private data distribution, and thus such methods have been extensively researched.</span></p>
</div>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 3. </span> Model-level methods.</figcaption>
<table id="S3.T3.18" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T3.4.4" class="ltx_tr">
<td id="S3.T3.4.4.5" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t" colspan="2"><span id="S3.T3.4.4.5.1" class="ltx_text" style="font-size:90%;">Methods</span></td>
<td id="S3.T3.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:59.8pt;"><span id="S3.T3.1.1.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T3.1.1.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T3.1.1.1.1.p1.1" class="ltx_p"><span id="S3.T3.1.1.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T3.1.1.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T3.1.1.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T3.1.1.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.1.1.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T3.1.1.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Advantages</span></span>
</span></span><span id="S3.T3.1.1.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T3.1.1.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T3.2.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T3.2.2.2.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T3.2.2.2.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T3.2.2.2.1.p1.1" class="ltx_p"><span id="S3.T3.2.2.2.1.p1.1.1" class="ltx_text"></span><span id="S3.T3.2.2.2.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T3.2.2.2.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T3.2.2.2.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.2.2.2.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T3.2.2.2.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Ref.</span></span>
</span></span><span id="S3.T3.2.2.2.1.p1.1.4" class="ltx_text"></span><span id="S3.T3.2.2.2.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T3.3.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:105.3pt;"><span id="S3.T3.3.3.3.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T3.3.3.3.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T3.3.3.3.1.p1.1" class="ltx_p"><span id="S3.T3.3.3.3.1.p1.1.1" class="ltx_text"></span><span id="S3.T3.3.3.3.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T3.3.3.3.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T3.3.3.3.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.3.3.3.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T3.3.3.3.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Key Contributions</span></span>
</span></span><span id="S3.T3.3.3.3.1.p1.1.4" class="ltx_text"></span><span id="S3.T3.3.3.3.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T3.4.4.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;"><span id="S3.T3.4.4.4.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T3.4.4.4.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T3.4.4.4.1.p1.1" class="ltx_p"><span id="S3.T3.4.4.4.1.p1.1.1" class="ltx_text"></span><span id="S3.T3.4.4.4.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T3.4.4.4.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T3.4.4.4.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.4.4.4.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T3.4.4.4.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Limitations</span></span>
</span></span><span id="S3.T3.4.4.4.1.p1.1.4" class="ltx_text"></span><span id="S3.T3.4.4.4.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
</tr>
<tr id="S3.T3.5.5" class="ltx_tr">
<td id="S3.T3.5.5.2" class="ltx_td ltx_border_l ltx_border_r ltx_border_t"></td>
<td id="S3.T3.5.5.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S3.T3.5.5.4" class="ltx_td ltx_align_middle ltx_border_r ltx_border_t" style="width:59.8pt;"></td>
<td id="S3.T3.5.5.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T3.5.5.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T3.5.5.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T3.5.5.1.1.p1.1" class="ltx_p"><span id="S3.T3.5.5.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T3.5.5.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T3.5.5.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T3.5.5.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.5.5.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T3.5.5.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib125" title="" class="ltx_ref">2020d</a>)</cite></span></span>
</span></span><span id="S3.T3.5.5.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T3.5.5.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T3.5.5.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:105.3pt;">
<span id="S3.T3.5.5.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.5.5.1.1" class="ltx_p"><span id="S3.T3.5.5.5.1.1.1" class="ltx_text" style="font-size:90%;">FedProx is a federated optimization algorithm that adds a proximal term to FedAvg.</span></span>
</span>
</td>
<td id="S3.T3.5.5.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T3.5.5.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.5.5.6.1.1" class="ltx_p"><span id="S3.T3.5.5.6.1.1.1" class="ltx_text" style="font-size:90%;">Adding a regularization term may result in slower convergence.</span></span>
</span>
</td>
</tr>
<tr id="S3.T3.6.6" class="ltx_tr">
<td id="S3.T3.6.6.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T3.6.6.3" class="ltx_td ltx_border_r"></td>
<td id="S3.T3.6.6.4" class="ltx_td ltx_align_middle ltx_border_r" style="width:59.8pt;"></td>
<td id="S3.T3.6.6.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T3.6.6.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T3.6.6.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T3.6.6.1.1.p1.1" class="ltx_p"><span id="S3.T3.6.6.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T3.6.6.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T3.6.6.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T3.6.6.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.6.6.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T3.6.6.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Shoham et al<span class="ltx_text">.</span> (<a href="#bib.bib191" title="" class="ltx_ref">2019</a>)</cite></span></span>
</span></span><span id="S3.T3.6.6.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T3.6.6.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T3.6.6.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:105.3pt;">
<span id="S3.T3.6.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.6.6.5.1.1" class="ltx_p"><span id="S3.T3.6.6.5.1.1.1" class="ltx_text" style="font-size:90%;">FedCurv uses the EWC algorithm to prevent catastrophic forgetting when transferring tasks.</span></span>
</span>
</td>
<td id="S3.T3.6.6.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T3.6.6.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.6.6.6.1.1" class="ltx_p"><span id="S3.T3.6.6.6.1.1.1" class="ltx_text" style="font-size:90%;">It may ignore the differences in the extent to which clients are affected by catastrophic forgetting.</span></span>
</span>
</td>
</tr>
<tr id="S3.T3.7.7" class="ltx_tr">
<td id="S3.T3.7.7.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T3.7.7.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T3.7.7.3.1" class="ltx_text" style="font-size:90%;">Regularization</span></td>
<td id="S3.T3.7.7.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:59.8pt;">
<span id="S3.T3.7.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.7.7.4.1.1" class="ltx_p"><span id="S3.T3.7.7.4.1.1.1" class="ltx_text" style="font-size:90%;">These methods provide convergence guarantee under statistical heterogeneity.</span></span>
</span>
</td>
<td id="S3.T3.7.7.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T3.7.7.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T3.7.7.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T3.7.7.1.1.p1.1" class="ltx_p"><span id="S3.T3.7.7.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T3.7.7.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T3.7.7.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T3.7.7.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.7.7.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T3.7.7.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">T Dinh et al<span class="ltx_text">.</span> (<a href="#bib.bib198" title="" class="ltx_ref">2020</a>)</cite></span></span>
</span></span><span id="S3.T3.7.7.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T3.7.7.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T3.7.7.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:105.3pt;">
<span id="S3.T3.7.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.7.7.5.1.1" class="ltx_p"><span id="S3.T3.7.7.5.1.1.1" class="ltx_text" style="font-size:90%;">pFedME utilizes the Moreau envelope function as a regularized loss function.</span></span>
</span>
</td>
<td id="S3.T3.7.7.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T3.7.7.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.7.7.6.1.1" class="ltx_p"><span id="S3.T3.7.7.6.1.1.1" class="ltx_text" style="font-size:90%;">Tuning the regularization parameters may be labour intensive.</span></span>
</span>
</td>
</tr>
<tr id="S3.T3.8.8" class="ltx_tr">
<td id="S3.T3.8.8.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T3.8.8.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S3.T3.8.8.4" class="ltx_td ltx_align_middle ltx_border_r ltx_border_t" style="width:59.8pt;"></td>
<td id="S3.T3.8.8.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T3.8.8.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T3.8.8.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T3.8.8.1.1.p1.1" class="ltx_p"><span id="S3.T3.8.8.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T3.8.8.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T3.8.8.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T3.8.8.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.8.8.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T3.8.8.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Jiang et al<span class="ltx_text">.</span> (<a href="#bib.bib95" title="" class="ltx_ref">2019</a>)</cite></span></span>
</span></span><span id="S3.T3.8.8.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T3.8.8.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T3.8.8.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:105.3pt;">
<span id="S3.T3.8.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.8.8.5.1.1" class="ltx_p"><span id="S3.T3.8.8.5.1.1.1" class="ltx_text" style="font-size:90%;">Similarities between the MAML setting and the personalized objectives of HFL are pointed out.</span></span>
</span>
</td>
<td id="S3.T3.8.8.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T3.8.8.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.8.8.6.1.1" class="ltx_p"><span id="S3.T3.8.8.6.1.1.1" class="ltx_text" style="font-size:90%;">The two stages of meta-training and meta-testing may introduce additional communication overhead.</span></span>
</span>
</td>
</tr>
<tr id="S3.T3.9.9" class="ltx_tr">
<td id="S3.T3.9.9.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T3.9.9.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T3.9.9.3.1" class="ltx_text" style="font-size:90%;"><span id="S3.T3.9.9.3.1.1" class="ltx_text"></span> <span id="S3.T3.9.9.3.1.2" class="ltx_text">
<span id="S3.T3.9.9.3.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.9.9.3.1.2.1.1" class="ltx_tr">
<span id="S3.T3.9.9.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Meta-</span></span>
<span id="S3.T3.9.9.3.1.2.1.2" class="ltx_tr">
<span id="S3.T3.9.9.3.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">learning</span></span>
</span></span> <span id="S3.T3.9.9.3.1.3" class="ltx_text"></span></span></td>
<td id="S3.T3.9.9.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:59.8pt;">
<span id="S3.T3.9.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.9.9.4.1.1" class="ltx_p"><span id="S3.T3.9.9.4.1.1.1" class="ltx_text" style="font-size:90%;">These methods use meta-learning to achieve the personalized objectives under HFL.</span></span>
</span>
</td>
<td id="S3.T3.9.9.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T3.9.9.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T3.9.9.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T3.9.9.1.1.p1.1" class="ltx_p"><span id="S3.T3.9.9.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T3.9.9.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T3.9.9.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T3.9.9.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.9.9.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T3.9.9.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Fallah et al<span class="ltx_text">.</span> (<a href="#bib.bib47" title="" class="ltx_ref">2020</a>)</cite></span></span>
</span></span><span id="S3.T3.9.9.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T3.9.9.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T3.9.9.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:105.3pt;">
<span id="S3.T3.9.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.9.9.5.1.1" class="ltx_p"><span id="S3.T3.9.9.5.1.1.1" class="ltx_text" style="font-size:90%;">Per-FedAvg is a personalized variant of FedAvg algorithm based on the MAML formula.</span></span>
</span>
</td>
<td id="S3.T3.9.9.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T3.9.9.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.9.9.6.1.1" class="ltx_p"><span id="S3.T3.9.9.6.1.1.1" class="ltx_text" style="font-size:90%;">It may not apply to scenarios with significant feature skew.</span></span>
</span>
</td>
</tr>
<tr id="S3.T3.10.10" class="ltx_tr">
<td id="S3.T3.10.10.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T3.10.10.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S3.T3.10.10.4" class="ltx_td ltx_align_middle ltx_border_r ltx_border_t" style="width:59.8pt;"></td>
<td id="S3.T3.10.10.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T3.10.10.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T3.10.10.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T3.10.10.1.1.p1.1" class="ltx_p"><span id="S3.T3.10.10.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T3.10.10.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T3.10.10.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T3.10.10.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.10.10.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T3.10.10.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Smith et al<span class="ltx_text">.</span> (<a href="#bib.bib192" title="" class="ltx_ref">2017</a>)</cite></span></span>
</span></span><span id="S3.T3.10.10.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T3.10.10.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T3.10.10.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:105.3pt;">
<span id="S3.T3.10.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.10.10.5.1.1" class="ltx_p"><span id="S3.T3.10.10.5.1.1.1" class="ltx_text" style="font-size:90%;">A system-aware optimization framework for FMTL is built.</span></span>
</span>
</td>
<td id="S3.T3.10.10.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T3.10.10.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.10.10.6.1.1" class="ltx_p"><span id="S3.T3.10.10.6.1.1.1" class="ltx_text" style="font-size:90%;">It cannot be applied to non-convex deep learning models.</span></span>
</span>
</td>
</tr>
<tr id="S3.T3.11.11" class="ltx_tr">
<td id="S3.T3.11.11.2" class="ltx_td ltx_align_center ltx_border_l ltx_border_r"><span id="S3.T3.11.11.2.1" class="ltx_text" style="font-size:90%;"><span id="S3.T3.11.11.2.1.1" class="ltx_text"></span> <span id="S3.T3.11.11.2.1.2" class="ltx_text">
<span id="S3.T3.11.11.2.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.11.11.2.1.2.1.1" class="ltx_tr">
<span id="S3.T3.11.11.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Federated</span></span>
<span id="S3.T3.11.11.2.1.2.1.2" class="ltx_tr">
<span id="S3.T3.11.11.2.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Optimization</span></span>
<span id="S3.T3.11.11.2.1.2.1.3" class="ltx_tr">
<span id="S3.T3.11.11.2.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><a href="#S3.SS2.SSS1" title="3.2.1. Federated Optimization ‣ 3.2. Model-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.1</span></a></span></span>
</span></span> <span id="S3.T3.11.11.2.1.3" class="ltx_text"></span></span></td>
<td id="S3.T3.11.11.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T3.11.11.3.1" class="ltx_text" style="font-size:90%;"><span id="S3.T3.11.11.3.1.1" class="ltx_text"></span> <span id="S3.T3.11.11.3.1.2" class="ltx_text">
<span id="S3.T3.11.11.3.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.11.11.3.1.2.1.1" class="ltx_tr">
<span id="S3.T3.11.11.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Multi-task</span></span>
<span id="S3.T3.11.11.3.1.2.1.2" class="ltx_tr">
<span id="S3.T3.11.11.3.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Learning</span></span>
</span></span> <span id="S3.T3.11.11.3.1.3" class="ltx_text"></span></span></td>
<td id="S3.T3.11.11.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:59.8pt;">
<span id="S3.T3.11.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.11.11.4.1.1" class="ltx_p"><span id="S3.T3.11.11.4.1.1.1" class="ltx_text" style="font-size:90%;">These methods leverage multi-task learning to learn personalized local models.</span></span>
</span>
</td>
<td id="S3.T3.11.11.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T3.11.11.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T3.11.11.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T3.11.11.1.1.p1.1" class="ltx_p"><span id="S3.T3.11.11.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T3.11.11.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T3.11.11.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T3.11.11.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.11.11.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T3.11.11.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib123" title="" class="ltx_ref">2021d</a>)</cite></span></span>
</span></span><span id="S3.T3.11.11.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T3.11.11.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T3.11.11.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:105.3pt;">
<span id="S3.T3.11.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.11.11.5.1.1" class="ltx_p"><span id="S3.T3.11.11.5.1.1.1" class="ltx_text" style="font-size:90%;">Ditto is a scalable federated multi-task learning framework with two tasks: global goal and local goal.</span></span>
</span>
</td>
<td id="S3.T3.11.11.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T3.11.11.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.11.11.6.1.1" class="ltx_p"><span id="S3.T3.11.11.6.1.1.1" class="ltx_text" style="font-size:90%;">Tuning the regularization parameters may take much effort.</span></span>
</span>
</td>
</tr>
<tr id="S3.T3.12.12" class="ltx_tr">
<td id="S3.T3.12.12.2" class="ltx_td ltx_border_l ltx_border_r ltx_border_t"></td>
<td id="S3.T3.12.12.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T3.12.12.3.1" class="ltx_text" style="font-size:90%;"><span id="S3.T3.12.12.3.1.1" class="ltx_text"></span> <span id="S3.T3.12.12.3.1.2" class="ltx_text">
<span id="S3.T3.12.12.3.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.12.12.3.1.2.1.1" class="ltx_tr">
<span id="S3.T3.12.12.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Knowledge</span></span>
<span id="S3.T3.12.12.3.1.2.1.2" class="ltx_tr">
<span id="S3.T3.12.12.3.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Distillation</span></span>
</span></span> <span id="S3.T3.12.12.3.1.3" class="ltx_text"></span></span></td>
<td id="S3.T3.12.12.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:59.8pt;">
<span id="S3.T3.12.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.12.12.4.1.1" class="ltx_p"><span id="S3.T3.12.12.4.1.1.1" class="ltx_text" style="font-size:90%;">These methods refine knowledge distribution of each client.</span></span>
</span>
</td>
<td id="S3.T3.12.12.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T3.12.12.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T3.12.12.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T3.12.12.1.1.p1.1" class="ltx_p"><span id="S3.T3.12.12.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T3.12.12.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T3.12.12.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T3.12.12.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.12.12.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T3.12.12.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Fang and Ye (<a href="#bib.bib49" title="" class="ltx_ref">2022</a>)</cite></span></span>
</span></span><span id="S3.T3.12.12.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T3.12.12.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T3.12.12.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:105.3pt;">
<span id="S3.T3.12.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.12.12.5.1.1" class="ltx_p"><span id="S3.T3.12.12.5.1.1.1" class="ltx_text" style="font-size:90%;">RHFL uses irrelevant data for knowledge distillation, thereby solving the problem of model heterogeneity.</span></span>
</span>
</td>
<td id="S3.T3.12.12.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T3.12.12.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.12.12.6.1.1" class="ltx_p"><span id="S3.T3.12.12.6.1.1.1" class="ltx_text" style="font-size:90%;">Using logits output on irrelevant data as local knowledge may underutilize local information.</span></span>
</span>
</td>
</tr>
<tr id="S3.T3.13.13" class="ltx_tr">
<td id="S3.T3.13.13.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T3.13.13.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S3.T3.13.13.4" class="ltx_td ltx_align_middle ltx_border_r ltx_border_t" style="width:59.8pt;"></td>
<td id="S3.T3.13.13.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T3.13.13.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T3.13.13.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T3.13.13.1.1.p1.1" class="ltx_p"><span id="S3.T3.13.13.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T3.13.13.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T3.13.13.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T3.13.13.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.13.13.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T3.13.13.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib243" title="" class="ltx_ref">2021a</a>)</cite></span></span>
</span></span><span id="S3.T3.13.13.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T3.13.13.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T3.13.13.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:105.3pt;">
<span id="S3.T3.13.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.13.13.5.1.1" class="ltx_p"><span id="S3.T3.13.13.5.1.1.1" class="ltx_text" style="font-size:90%;">FT-pFL achieves personalized knowledge transfer via a knowledge coefficient matrix.</span></span>
</span>
</td>
<td id="S3.T3.13.13.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T3.13.13.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.13.13.6.1.1" class="ltx_p"><span id="S3.T3.13.13.6.1.1.1" class="ltx_text" style="font-size:90%;">The logits output on public dataset may not describe rich local information.</span></span>
</span>
</td>
</tr>
<tr id="S3.T3.14.14" class="ltx_tr">
<td id="S3.T3.14.14.2" class="ltx_td ltx_align_center ltx_border_l ltx_border_r"><span id="S3.T3.14.14.2.1" class="ltx_text" style="font-size:90%;"><span id="S3.T3.14.14.2.1.1" class="ltx_text"></span> <span id="S3.T3.14.14.2.1.2" class="ltx_text">
<span id="S3.T3.14.14.2.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.14.14.2.1.2.1.1" class="ltx_tr">
<span id="S3.T3.14.14.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Knowledge</span></span>
<span id="S3.T3.14.14.2.1.2.1.2" class="ltx_tr">
<span id="S3.T3.14.14.2.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Transfer</span></span>
<span id="S3.T3.14.14.2.1.2.1.3" class="ltx_tr">
<span id="S3.T3.14.14.2.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><a href="#S3.SS2.SSS2" title="3.2.2. Knowledge Transfer across Models ‣ 3.2. Model-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.2</span></a></span></span>
</span></span> <span id="S3.T3.14.14.2.1.3" class="ltx_text"></span></span></td>
<td id="S3.T3.14.14.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T3.14.14.3.1" class="ltx_text" style="font-size:90%;"><span id="S3.T3.14.14.3.1.1" class="ltx_text"></span> <span id="S3.T3.14.14.3.1.2" class="ltx_text">
<span id="S3.T3.14.14.3.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.14.14.3.1.2.1.1" class="ltx_tr">
<span id="S3.T3.14.14.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Transfer</span></span>
<span id="S3.T3.14.14.3.1.2.1.2" class="ltx_tr">
<span id="S3.T3.14.14.3.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Learning</span></span>
</span></span> <span id="S3.T3.14.14.3.1.3" class="ltx_text"></span></span></td>
<td id="S3.T3.14.14.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:59.8pt;">
<span id="S3.T3.14.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.14.14.4.1.1" class="ltx_p"><span id="S3.T3.14.14.4.1.1.1" class="ltx_text" style="font-size:90%;">These methods transfer the local knowledge in a model-agnostic manner.</span></span>
</span>
</td>
<td id="S3.T3.14.14.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T3.14.14.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T3.14.14.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T3.14.14.1.1.p1.1" class="ltx_p"><span id="S3.T3.14.14.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T3.14.14.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T3.14.14.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T3.14.14.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.14.14.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T3.14.14.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Chen et al<span class="ltx_text">.</span> (<a href="#bib.bib31" title="" class="ltx_ref">2020b</a>)</cite></span></span>
</span></span><span id="S3.T3.14.14.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T3.14.14.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T3.14.14.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:105.3pt;">
<span id="S3.T3.14.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.14.14.5.1.1" class="ltx_p"><span id="S3.T3.14.14.5.1.1.1" class="ltx_text" style="font-size:90%;">FedHealth is a federated transfer learning framework applied in the healthcare domain.</span></span>
</span>
</td>
<td id="S3.T3.14.14.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T3.14.14.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.14.14.6.1.1" class="ltx_p"><span id="S3.T3.14.14.6.1.1.1" class="ltx_text" style="font-size:90%;">Its generality may be decreased owing to the model heterogeneity in real medical scenarios.</span></span>
</span>
</td>
</tr>
<tr id="S3.T3.15.15" class="ltx_tr">
<td id="S3.T3.15.15.2" class="ltx_td ltx_border_l ltx_border_r ltx_border_t"></td>
<td id="S3.T3.15.15.3" class="ltx_td ltx_border_r ltx_border_t"></td>
<td id="S3.T3.15.15.4" class="ltx_td ltx_align_middle ltx_border_r ltx_border_t" style="width:59.8pt;"></td>
<td id="S3.T3.15.15.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T3.15.15.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T3.15.15.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T3.15.15.1.1.p1.1" class="ltx_p"><span id="S3.T3.15.15.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T3.15.15.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T3.15.15.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T3.15.15.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.15.15.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T3.15.15.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Arivazhagan et al<span class="ltx_text">.</span> (<a href="#bib.bib7" title="" class="ltx_ref">2019</a>)</cite></span></span>
</span></span><span id="S3.T3.15.15.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T3.15.15.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T3.15.15.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:105.3pt;">
<span id="S3.T3.15.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.15.15.5.1.1" class="ltx_p"><span id="S3.T3.15.15.5.1.1.1" class="ltx_text" style="font-size:90%;">FedPer combines base layers and personalized layers for federated training.</span></span>
</span>
</td>
<td id="S3.T3.15.15.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T3.15.15.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.15.15.6.1.1" class="ltx_p"><span id="S3.T3.15.15.6.1.1.1" class="ltx_text" style="font-size:90%;">Excessive resource may be consumed owing to the activation of all clients in each round.</span></span>
</span>
</td>
</tr>
<tr id="S3.T3.16.16" class="ltx_tr">
<td id="S3.T3.16.16.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T3.16.16.3" class="ltx_td ltx_align_center ltx_border_r"><span id="S3.T3.16.16.3.1" class="ltx_text" style="font-size:90%;"><span id="S3.T3.16.16.3.1.1" class="ltx_text"></span> <span id="S3.T3.16.16.3.1.2" class="ltx_text">
<span id="S3.T3.16.16.3.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.16.16.3.1.2.1.1" class="ltx_tr">
<span id="S3.T3.16.16.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Backbone</span></span>
<span id="S3.T3.16.16.3.1.2.1.2" class="ltx_tr">
<span id="S3.T3.16.16.3.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Sharing</span></span>
</span></span> <span id="S3.T3.16.16.3.1.3" class="ltx_text"></span></span></td>
<td id="S3.T3.16.16.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:59.8pt;">
<span id="S3.T3.16.16.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.16.16.4.1.1" class="ltx_p"><span id="S3.T3.16.16.4.1.1.1" class="ltx_text" style="font-size:90%;">These methods decrease computation costs while satisfying personalized demands.</span></span>
</span>
</td>
<td id="S3.T3.16.16.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T3.16.16.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T3.16.16.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T3.16.16.1.1.p1.1" class="ltx_p"><span id="S3.T3.16.16.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T3.16.16.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T3.16.16.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T3.16.16.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.16.16.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T3.16.16.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Collins et al<span class="ltx_text">.</span> (<a href="#bib.bib36" title="" class="ltx_ref">2021</a>)</cite></span></span>
</span></span><span id="S3.T3.16.16.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T3.16.16.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T3.16.16.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:105.3pt;">
<span id="S3.T3.16.16.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.16.16.5.1.1" class="ltx_p"><span id="S3.T3.16.16.5.1.1.1" class="ltx_text" style="font-size:90%;">FedRep enables all clients jointly train global representation learning structure, and then uses private data to train their own heads.</span></span>
</span>
</td>
<td id="S3.T3.16.16.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T3.16.16.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.16.16.6.1.1" class="ltx_p"><span id="S3.T3.16.16.6.1.1.1" class="ltx_text" style="font-size:90%;">The base layers learn a global representation that may limit the personalization.</span></span>
</span>
</td>
</tr>
<tr id="S3.T3.17.17" class="ltx_tr">
<td id="S3.T3.17.17.2" class="ltx_td ltx_border_l ltx_border_r"></td>
<td id="S3.T3.17.17.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S3.T3.17.17.3.1" class="ltx_text" style="font-size:90%;"><span id="S3.T3.17.17.3.1.1" class="ltx_text"></span> <span id="S3.T3.17.17.3.1.2" class="ltx_text">
<span id="S3.T3.17.17.3.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.17.17.3.1.2.1.1" class="ltx_tr">
<span id="S3.T3.17.17.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Classifier</span></span>
<span id="S3.T3.17.17.3.1.2.1.2" class="ltx_tr">
<span id="S3.T3.17.17.3.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Sharing</span></span>
</span></span> <span id="S3.T3.17.17.3.1.3" class="ltx_text"></span></span></td>
<td id="S3.T3.17.17.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:59.8pt;">
<span id="S3.T3.17.17.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.17.17.4.1.1" class="ltx_p"><span id="S3.T3.17.17.4.1.1.1" class="ltx_text" style="font-size:90%;">These methods leverage the personalized layers to extract features.</span></span>
</span>
</td>
<td id="S3.T3.17.17.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T3.17.17.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T3.17.17.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T3.17.17.1.1.p1.1" class="ltx_p"><span id="S3.T3.17.17.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T3.17.17.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T3.17.17.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T3.17.17.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.17.17.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T3.17.17.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Liang et al<span class="ltx_text">.</span> (<a href="#bib.bib129" title="" class="ltx_ref">2020</a>)</cite></span></span>
</span></span><span id="S3.T3.17.17.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T3.17.17.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T3.17.17.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:105.3pt;">
<span id="S3.T3.17.17.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.17.17.5.1.1" class="ltx_p"><span id="S3.T3.17.17.5.1.1.1" class="ltx_text" style="font-size:90%;">LG-FedAvg uses personalized layers to extract high-level features and server-shared base layers for classification.</span></span>
</span>
</td>
<td id="S3.T3.17.17.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T3.17.17.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.17.17.6.1.1" class="ltx_p"><span id="S3.T3.17.17.6.1.1.1" class="ltx_text" style="font-size:90%;">Assuming that all clients have sufficient training data may decrease the generality.</span></span>
</span>
</td>
</tr>
<tr id="S3.T3.18.18" class="ltx_tr">
<td id="S3.T3.18.18.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r"><span id="S3.T3.18.18.2.1" class="ltx_text" style="font-size:90%;"><span id="S3.T3.18.18.2.1.1" class="ltx_text"></span> <span id="S3.T3.18.18.2.1.2" class="ltx_text">
<span id="S3.T3.18.18.2.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.18.18.2.1.2.1.1" class="ltx_tr">
<span id="S3.T3.18.18.2.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Architecture</span></span>
<span id="S3.T3.18.18.2.1.2.1.2" class="ltx_tr">
<span id="S3.T3.18.18.2.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Sharing</span></span>
<span id="S3.T3.18.18.2.1.2.1.3" class="ltx_tr">
<span id="S3.T3.18.18.2.1.2.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><a href="#S3.SS2.SSS3" title="3.2.3. Architecture Sharing ‣ 3.2. Model-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.2.3</span></a></span></span>
</span></span> <span id="S3.T3.18.18.2.1.3" class="ltx_text"></span></span></td>
<td id="S3.T3.18.18.3" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S3.T3.18.18.3.1" class="ltx_text" style="font-size:90%;"><span id="S3.T3.18.18.3.1.1" class="ltx_text"></span> <span id="S3.T3.18.18.3.1.2" class="ltx_text">
<span id="S3.T3.18.18.3.1.2.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.18.18.3.1.2.1.1" class="ltx_tr">
<span id="S3.T3.18.18.3.1.2.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Other Part</span></span>
<span id="S3.T3.18.18.3.1.2.1.2" class="ltx_tr">
<span id="S3.T3.18.18.3.1.2.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center">Sharing</span></span>
</span></span> <span id="S3.T3.18.18.3.1.3" class="ltx_text"></span></span></td>
<td id="S3.T3.18.18.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:59.8pt;">
<span id="S3.T3.18.18.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.18.18.4.1.1" class="ltx_p"><span id="S3.T3.18.18.4.1.1.1" class="ltx_text" style="font-size:90%;">These methods share part of the model according to local conditions.</span></span>
</span>
</td>
<td id="S3.T3.18.18.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T3.18.18.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T3.18.18.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T3.18.18.1.1.p1.1" class="ltx_p"><span id="S3.T3.18.18.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T3.18.18.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T3.18.18.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T3.18.18.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T3.18.18.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T3.18.18.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Diao et al<span class="ltx_text">.</span> (<a href="#bib.bib41" title="" class="ltx_ref">2021</a>)</cite></span></span>
</span></span><span id="S3.T3.18.18.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T3.18.18.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T3.18.18.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:105.3pt;">
<span id="S3.T3.18.18.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.18.18.5.1.1" class="ltx_p"><span id="S3.T3.18.18.5.1.1.1" class="ltx_text" style="font-size:90%;">HeteroFL allocates local models of different sizes according to the computational and communication capabilities of each client.</span></span>
</span>
</td>
<td id="S3.T3.18.18.6" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:93.9pt;">
<span id="S3.T3.18.18.6.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T3.18.18.6.1.1" class="ltx_p"><span id="S3.T3.18.18.6.1.1.1" class="ltx_text" style="font-size:90%;">It may not satisfy practical scenarios with high model heterogeneity.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<section id="S3.SS2.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.1. </span>Federated Optimization</h4>

<div id="S3.SS2.SSS1.p1" class="ltx_para">
<p id="S3.SS2.SSS1.p1.1" class="ltx_p"><span id="S3.SS2.SSS1.p1.1.1" class="ltx_text ltx_font_bold">Regularization.</span>
Regularization is a technique that helps prevent overfitting by adding a penalty term to the loss function. This strategy decreases the model complexity by dynamically estimating the parameter values, and decreases variance by adding bias terms (Fig. <a href="#S3.F8" title="Figure 8 ‣ 3.2.1. Federated Optimization ‣ 3.2. Model-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>). Therefore, many federated learning frameworks implement regularization to provide convergence guarantees when learning under statistical heterogeneity <cite class="ltx_cite ltx_citemacro_cite">Kim et al<span class="ltx_text">.</span> (<a href="#bib.bib103" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S3.SS2.SSS1.p2" class="ltx_para">
<p id="S3.SS2.SSS1.p2.6" class="ltx_p">FedProx <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib125" title="" class="ltx_ref">2020d</a>)</cite> adds a proximal term on the basis of FedAvg <cite class="ltx_cite ltx_citemacro_cite">McMahan et al<span class="ltx_text">.</span> (<a href="#bib.bib156" title="" class="ltx_ref">2017</a>)</cite>. The server distributes the global model <math id="S3.SS2.SSS1.p2.1.m1.1" class="ltx_Math" alttext="\theta^{t}" display="inline"><semantics id="S3.SS2.SSS1.p2.1.m1.1a"><msup id="S3.SS2.SSS1.p2.1.m1.1.1" xref="S3.SS2.SSS1.p2.1.m1.1.1.cmml"><mi id="S3.SS2.SSS1.p2.1.m1.1.1.2" xref="S3.SS2.SSS1.p2.1.m1.1.1.2.cmml">θ</mi><mi id="S3.SS2.SSS1.p2.1.m1.1.1.3" xref="S3.SS2.SSS1.p2.1.m1.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.1.m1.1b"><apply id="S3.SS2.SSS1.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.1.m1.1.1.1.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1">superscript</csymbol><ci id="S3.SS2.SSS1.p2.1.m1.1.1.2.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1.2">𝜃</ci><ci id="S3.SS2.SSS1.p2.1.m1.1.1.3.cmml" xref="S3.SS2.SSS1.p2.1.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.1.m1.1c">\theta^{t}</annotation></semantics></math> of the previous epoch <math id="S3.SS2.SSS1.p2.2.m2.1" class="ltx_Math" alttext="t" display="inline"><semantics id="S3.SS2.SSS1.p2.2.m2.1a"><mi id="S3.SS2.SSS1.p2.2.m2.1.1" xref="S3.SS2.SSS1.p2.2.m2.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.2.m2.1b"><ci id="S3.SS2.SSS1.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS1.p2.2.m2.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.2.m2.1c">t</annotation></semantics></math> to clients, and the client <math id="S3.SS2.SSS1.p2.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.SSS1.p2.3.m3.1a"><mi id="S3.SS2.SSS1.p2.3.m3.1.1" xref="S3.SS2.SSS1.p2.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.3.m3.1b"><ci id="S3.SS2.SSS1.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS1.p2.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.3.m3.1c">k</annotation></semantics></math> computes the local empirical risk <math id="S3.SS2.SSS1.p2.4.m4.1" class="ltx_Math" alttext="f_{k}(\theta)" display="inline"><semantics id="S3.SS2.SSS1.p2.4.m4.1a"><mrow id="S3.SS2.SSS1.p2.4.m4.1.2" xref="S3.SS2.SSS1.p2.4.m4.1.2.cmml"><msub id="S3.SS2.SSS1.p2.4.m4.1.2.2" xref="S3.SS2.SSS1.p2.4.m4.1.2.2.cmml"><mi id="S3.SS2.SSS1.p2.4.m4.1.2.2.2" xref="S3.SS2.SSS1.p2.4.m4.1.2.2.2.cmml">f</mi><mi id="S3.SS2.SSS1.p2.4.m4.1.2.2.3" xref="S3.SS2.SSS1.p2.4.m4.1.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS2.SSS1.p2.4.m4.1.2.1" xref="S3.SS2.SSS1.p2.4.m4.1.2.1.cmml">​</mo><mrow id="S3.SS2.SSS1.p2.4.m4.1.2.3.2" xref="S3.SS2.SSS1.p2.4.m4.1.2.cmml"><mo stretchy="false" id="S3.SS2.SSS1.p2.4.m4.1.2.3.2.1" xref="S3.SS2.SSS1.p2.4.m4.1.2.cmml">(</mo><mi id="S3.SS2.SSS1.p2.4.m4.1.1" xref="S3.SS2.SSS1.p2.4.m4.1.1.cmml">θ</mi><mo stretchy="false" id="S3.SS2.SSS1.p2.4.m4.1.2.3.2.2" xref="S3.SS2.SSS1.p2.4.m4.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.4.m4.1b"><apply id="S3.SS2.SSS1.p2.4.m4.1.2.cmml" xref="S3.SS2.SSS1.p2.4.m4.1.2"><times id="S3.SS2.SSS1.p2.4.m4.1.2.1.cmml" xref="S3.SS2.SSS1.p2.4.m4.1.2.1"></times><apply id="S3.SS2.SSS1.p2.4.m4.1.2.2.cmml" xref="S3.SS2.SSS1.p2.4.m4.1.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.4.m4.1.2.2.1.cmml" xref="S3.SS2.SSS1.p2.4.m4.1.2.2">subscript</csymbol><ci id="S3.SS2.SSS1.p2.4.m4.1.2.2.2.cmml" xref="S3.SS2.SSS1.p2.4.m4.1.2.2.2">𝑓</ci><ci id="S3.SS2.SSS1.p2.4.m4.1.2.2.3.cmml" xref="S3.SS2.SSS1.p2.4.m4.1.2.2.3">𝑘</ci></apply><ci id="S3.SS2.SSS1.p2.4.m4.1.1.cmml" xref="S3.SS2.SSS1.p2.4.m4.1.1">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.4.m4.1c">f_{k}(\theta)</annotation></semantics></math> on the private dataset. Furthermore, the client <math id="S3.SS2.SSS1.p2.5.m5.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.SSS1.p2.5.m5.1a"><mi id="S3.SS2.SSS1.p2.5.m5.1.1" xref="S3.SS2.SSS1.p2.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.5.m5.1b"><ci id="S3.SS2.SSS1.p2.5.m5.1.1.cmml" xref="S3.SS2.SSS1.p2.5.m5.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.5.m5.1c">k</annotation></semantics></math> approximately minimizes the objective <math id="S3.SS2.SSS1.p2.6.m6.1" class="ltx_Math" alttext="h_{k}" display="inline"><semantics id="S3.SS2.SSS1.p2.6.m6.1a"><msub id="S3.SS2.SSS1.p2.6.m6.1.1" xref="S3.SS2.SSS1.p2.6.m6.1.1.cmml"><mi id="S3.SS2.SSS1.p2.6.m6.1.1.2" xref="S3.SS2.SSS1.p2.6.m6.1.1.2.cmml">h</mi><mi id="S3.SS2.SSS1.p2.6.m6.1.1.3" xref="S3.SS2.SSS1.p2.6.m6.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.6.m6.1b"><apply id="S3.SS2.SSS1.p2.6.m6.1.1.cmml" xref="S3.SS2.SSS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.6.m6.1.1.1.cmml" xref="S3.SS2.SSS1.p2.6.m6.1.1">subscript</csymbol><ci id="S3.SS2.SSS1.p2.6.m6.1.1.2.cmml" xref="S3.SS2.SSS1.p2.6.m6.1.1.2">ℎ</ci><ci id="S3.SS2.SSS1.p2.6.m6.1.1.3.cmml" xref="S3.SS2.SSS1.p2.6.m6.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.6.m6.1c">h_{k}</annotation></semantics></math> as follows:</p>
<table id="S3.E5" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E5.m1.30" class="ltx_Math" alttext="\begin{split}\min\limits_{\theta}h_{k}(\theta,\theta^{t})=f_{k}(\theta)+\frac{\lambda}{2}||\theta-\theta^{t}||^{2},\end{split}" display="block"><semantics id="S3.E5.m1.30a"><mtable displaystyle="true" id="S3.E5.m1.30.30.2"><mtr id="S3.E5.m1.30.30.2a"><mtd class="ltx_align_right" columnalign="right" id="S3.E5.m1.30.30.2b"><mrow id="S3.E5.m1.30.30.2.29.29.29.29"><mrow id="S3.E5.m1.30.30.2.29.29.29.29.1"><mrow id="S3.E5.m1.30.30.2.29.29.29.29.1.1"><mrow id="S3.E5.m1.30.30.2.29.29.29.29.1.1.3"><munder id="S3.E5.m1.30.30.2.29.29.29.29.1.1.3.1"><mi id="S3.E5.m1.1.1.1.1.1.1" xref="S3.E5.m1.1.1.1.1.1.1.cmml">min</mi><mi id="S3.E5.m1.2.2.2.2.2.2.1" xref="S3.E5.m1.2.2.2.2.2.2.1.cmml">θ</mi></munder><mo lspace="0.167em" id="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a" xref="S3.E5.m1.29.29.1.1.1.cmml">⁡</mo><msub id="S3.E5.m1.30.30.2.29.29.29.29.1.1.3.2"><mi id="S3.E5.m1.3.3.3.3.3.3" xref="S3.E5.m1.3.3.3.3.3.3.cmml">h</mi><mi id="S3.E5.m1.4.4.4.4.4.4.1" xref="S3.E5.m1.4.4.4.4.4.4.1.cmml">k</mi></msub></mrow><mo lspace="0em" rspace="0em" id="S3.E5.m1.30.30.2.29.29.29.29.1.1.2" xref="S3.E5.m1.29.29.1.1.1.cmml">​</mo><mrow id="S3.E5.m1.30.30.2.29.29.29.29.1.1.1.1"><mo stretchy="false" id="S3.E5.m1.5.5.5.5.5.5" xref="S3.E5.m1.29.29.1.1.1.cmml">(</mo><mi id="S3.E5.m1.6.6.6.6.6.6" xref="S3.E5.m1.6.6.6.6.6.6.cmml">θ</mi><mo id="S3.E5.m1.7.7.7.7.7.7" xref="S3.E5.m1.29.29.1.1.1.cmml">,</mo><msup id="S3.E5.m1.30.30.2.29.29.29.29.1.1.1.1.1"><mi id="S3.E5.m1.8.8.8.8.8.8" xref="S3.E5.m1.8.8.8.8.8.8.cmml">θ</mi><mi id="S3.E5.m1.9.9.9.9.9.9.1" xref="S3.E5.m1.9.9.9.9.9.9.1.cmml">t</mi></msup><mo stretchy="false" id="S3.E5.m1.10.10.10.10.10.10" xref="S3.E5.m1.29.29.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.11.11.11.11.11.11" xref="S3.E5.m1.11.11.11.11.11.11.cmml">=</mo><mrow id="S3.E5.m1.30.30.2.29.29.29.29.1.2"><mrow id="S3.E5.m1.30.30.2.29.29.29.29.1.2.2"><msub id="S3.E5.m1.30.30.2.29.29.29.29.1.2.2.2"><mi id="S3.E5.m1.12.12.12.12.12.12" xref="S3.E5.m1.12.12.12.12.12.12.cmml">f</mi><mi id="S3.E5.m1.13.13.13.13.13.13.1" xref="S3.E5.m1.13.13.13.13.13.13.1.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S3.E5.m1.30.30.2.29.29.29.29.1.2.2.1" xref="S3.E5.m1.29.29.1.1.1.cmml">​</mo><mrow id="S3.E5.m1.30.30.2.29.29.29.29.1.2.2.3"><mo stretchy="false" id="S3.E5.m1.14.14.14.14.14.14" xref="S3.E5.m1.29.29.1.1.1.cmml">(</mo><mi id="S3.E5.m1.15.15.15.15.15.15" xref="S3.E5.m1.15.15.15.15.15.15.cmml">θ</mi><mo stretchy="false" id="S3.E5.m1.16.16.16.16.16.16" xref="S3.E5.m1.29.29.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E5.m1.17.17.17.17.17.17" xref="S3.E5.m1.17.17.17.17.17.17.cmml">+</mo><mrow id="S3.E5.m1.30.30.2.29.29.29.29.1.2.1"><mfrac id="S3.E5.m1.18.18.18.18.18.18" xref="S3.E5.m1.18.18.18.18.18.18.cmml"><mi id="S3.E5.m1.18.18.18.18.18.18.2" xref="S3.E5.m1.18.18.18.18.18.18.2.cmml">λ</mi><mn id="S3.E5.m1.18.18.18.18.18.18.3" xref="S3.E5.m1.18.18.18.18.18.18.3.cmml">2</mn></mfrac><mo lspace="0em" rspace="0em" id="S3.E5.m1.30.30.2.29.29.29.29.1.2.1.2" xref="S3.E5.m1.29.29.1.1.1.cmml">​</mo><msup id="S3.E5.m1.30.30.2.29.29.29.29.1.2.1.1"><mrow id="S3.E5.m1.30.30.2.29.29.29.29.1.2.1.1.1.1"><mo stretchy="false" id="S3.E5.m1.19.19.19.19.19.19b" xref="S3.E5.m1.29.29.1.1.1.cmml">‖</mo><mrow id="S3.E5.m1.30.30.2.29.29.29.29.1.2.1.1.1.1.1"><mi id="S3.E5.m1.21.21.21.21.21.21" xref="S3.E5.m1.21.21.21.21.21.21.cmml">θ</mi><mo id="S3.E5.m1.22.22.22.22.22.22" xref="S3.E5.m1.22.22.22.22.22.22.cmml">−</mo><msup id="S3.E5.m1.30.30.2.29.29.29.29.1.2.1.1.1.1.1.1"><mi id="S3.E5.m1.23.23.23.23.23.23" xref="S3.E5.m1.23.23.23.23.23.23.cmml">θ</mi><mi id="S3.E5.m1.24.24.24.24.24.24.1" xref="S3.E5.m1.24.24.24.24.24.24.1.cmml">t</mi></msup></mrow><mo stretchy="false" id="S3.E5.m1.25.25.25.25.25.25b" xref="S3.E5.m1.29.29.1.1.1.cmml">‖</mo></mrow><mn id="S3.E5.m1.27.27.27.27.27.27.1" xref="S3.E5.m1.27.27.27.27.27.27.1.cmml">2</mn></msup></mrow></mrow></mrow><mo id="S3.E5.m1.28.28.28.28.28.28" xref="S3.E5.m1.29.29.1.1.1.cmml">,</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S3.E5.m1.30b"><apply id="S3.E5.m1.29.29.1.1.1.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a"><eq id="S3.E5.m1.11.11.11.11.11.11.cmml" xref="S3.E5.m1.11.11.11.11.11.11"></eq><apply id="S3.E5.m1.29.29.1.1.1.1.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a"><times id="S3.E5.m1.29.29.1.1.1.1.2.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a"></times><apply id="S3.E5.m1.29.29.1.1.1.1.3.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a"><apply id="S3.E5.m1.29.29.1.1.1.1.3.1.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a"><csymbol cd="ambiguous" id="S3.E5.m1.29.29.1.1.1.1.3.1.1.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a">subscript</csymbol><min id="S3.E5.m1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.1.1.1.1.1.1"></min><ci id="S3.E5.m1.2.2.2.2.2.2.1.cmml" xref="S3.E5.m1.2.2.2.2.2.2.1">𝜃</ci></apply><apply id="S3.E5.m1.29.29.1.1.1.1.3.2.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a"><csymbol cd="ambiguous" id="S3.E5.m1.29.29.1.1.1.1.3.2.1.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a">subscript</csymbol><ci id="S3.E5.m1.3.3.3.3.3.3.cmml" xref="S3.E5.m1.3.3.3.3.3.3">ℎ</ci><ci id="S3.E5.m1.4.4.4.4.4.4.1.cmml" xref="S3.E5.m1.4.4.4.4.4.4.1">𝑘</ci></apply></apply><interval closure="open" id="S3.E5.m1.29.29.1.1.1.1.1.2.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a"><ci id="S3.E5.m1.6.6.6.6.6.6.cmml" xref="S3.E5.m1.6.6.6.6.6.6">𝜃</ci><apply id="S3.E5.m1.29.29.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a"><csymbol cd="ambiguous" id="S3.E5.m1.29.29.1.1.1.1.1.1.1.1.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a">superscript</csymbol><ci id="S3.E5.m1.8.8.8.8.8.8.cmml" xref="S3.E5.m1.8.8.8.8.8.8">𝜃</ci><ci id="S3.E5.m1.9.9.9.9.9.9.1.cmml" xref="S3.E5.m1.9.9.9.9.9.9.1">𝑡</ci></apply></interval></apply><apply id="S3.E5.m1.29.29.1.1.1.2.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a"><plus id="S3.E5.m1.17.17.17.17.17.17.cmml" xref="S3.E5.m1.17.17.17.17.17.17"></plus><apply id="S3.E5.m1.29.29.1.1.1.2.3.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a"><times id="S3.E5.m1.29.29.1.1.1.2.3.1.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a"></times><apply id="S3.E5.m1.29.29.1.1.1.2.3.2.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a"><csymbol cd="ambiguous" id="S3.E5.m1.29.29.1.1.1.2.3.2.1.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a">subscript</csymbol><ci id="S3.E5.m1.12.12.12.12.12.12.cmml" xref="S3.E5.m1.12.12.12.12.12.12">𝑓</ci><ci id="S3.E5.m1.13.13.13.13.13.13.1.cmml" xref="S3.E5.m1.13.13.13.13.13.13.1">𝑘</ci></apply><ci id="S3.E5.m1.15.15.15.15.15.15.cmml" xref="S3.E5.m1.15.15.15.15.15.15">𝜃</ci></apply><apply id="S3.E5.m1.29.29.1.1.1.2.1.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a"><times id="S3.E5.m1.29.29.1.1.1.2.1.2.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a"></times><apply id="S3.E5.m1.18.18.18.18.18.18.cmml" xref="S3.E5.m1.18.18.18.18.18.18"><divide id="S3.E5.m1.18.18.18.18.18.18.1.cmml" xref="S3.E5.m1.18.18.18.18.18.18"></divide><ci id="S3.E5.m1.18.18.18.18.18.18.2.cmml" xref="S3.E5.m1.18.18.18.18.18.18.2">𝜆</ci><cn type="integer" id="S3.E5.m1.18.18.18.18.18.18.3.cmml" xref="S3.E5.m1.18.18.18.18.18.18.3">2</cn></apply><apply id="S3.E5.m1.29.29.1.1.1.2.1.1.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a"><csymbol cd="ambiguous" id="S3.E5.m1.29.29.1.1.1.2.1.1.2.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a">superscript</csymbol><apply id="S3.E5.m1.29.29.1.1.1.2.1.1.1.2.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a"><csymbol cd="latexml" id="S3.E5.m1.29.29.1.1.1.2.1.1.1.2.1.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a">norm</csymbol><apply id="S3.E5.m1.29.29.1.1.1.2.1.1.1.1.1.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a"><minus id="S3.E5.m1.22.22.22.22.22.22.cmml" xref="S3.E5.m1.22.22.22.22.22.22"></minus><ci id="S3.E5.m1.21.21.21.21.21.21.cmml" xref="S3.E5.m1.21.21.21.21.21.21">𝜃</ci><apply id="S3.E5.m1.29.29.1.1.1.2.1.1.1.1.1.3.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a"><csymbol cd="ambiguous" id="S3.E5.m1.29.29.1.1.1.2.1.1.1.1.1.3.1.cmml" xref="S3.E5.m1.30.30.2.29.29.29.29.1.1.3a">superscript</csymbol><ci id="S3.E5.m1.23.23.23.23.23.23.cmml" xref="S3.E5.m1.23.23.23.23.23.23">𝜃</ci><ci id="S3.E5.m1.24.24.24.24.24.24.1.cmml" xref="S3.E5.m1.24.24.24.24.24.24.1">𝑡</ci></apply></apply></apply><cn type="integer" id="S3.E5.m1.27.27.27.27.27.27.1.cmml" xref="S3.E5.m1.27.27.27.27.27.27.1">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E5.m1.30c">\begin{split}\min\limits_{\theta}h_{k}(\theta,\theta^{t})=f_{k}(\theta)+\frac{\lambda}{2}||\theta-\theta^{t}||^{2},\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(5)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS1.p2.9" class="ltx_p">where <math id="S3.SS2.SSS1.p2.7.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S3.SS2.SSS1.p2.7.m1.1a"><mi id="S3.SS2.SSS1.p2.7.m1.1.1" xref="S3.SS2.SSS1.p2.7.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.7.m1.1b"><ci id="S3.SS2.SSS1.p2.7.m1.1.1.cmml" xref="S3.SS2.SSS1.p2.7.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.7.m1.1c">\lambda</annotation></semantics></math> is the regularization parameter to control the strength of <math id="S3.SS2.SSS1.p2.8.m2.1" class="ltx_Math" alttext="\theta^{t}" display="inline"><semantics id="S3.SS2.SSS1.p2.8.m2.1a"><msup id="S3.SS2.SSS1.p2.8.m2.1.1" xref="S3.SS2.SSS1.p2.8.m2.1.1.cmml"><mi id="S3.SS2.SSS1.p2.8.m2.1.1.2" xref="S3.SS2.SSS1.p2.8.m2.1.1.2.cmml">θ</mi><mi id="S3.SS2.SSS1.p2.8.m2.1.1.3" xref="S3.SS2.SSS1.p2.8.m2.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.8.m2.1b"><apply id="S3.SS2.SSS1.p2.8.m2.1.1.cmml" xref="S3.SS2.SSS1.p2.8.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS1.p2.8.m2.1.1.1.cmml" xref="S3.SS2.SSS1.p2.8.m2.1.1">superscript</csymbol><ci id="S3.SS2.SSS1.p2.8.m2.1.1.2.cmml" xref="S3.SS2.SSS1.p2.8.m2.1.1.2">𝜃</ci><ci id="S3.SS2.SSS1.p2.8.m2.1.1.3.cmml" xref="S3.SS2.SSS1.p2.8.m2.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.8.m2.1c">\theta^{t}</annotation></semantics></math> to the personalized model, and FedAvg is a special case with <math id="S3.SS2.SSS1.p2.9.m3.1" class="ltx_Math" alttext="\lambda=0" display="inline"><semantics id="S3.SS2.SSS1.p2.9.m3.1a"><mrow id="S3.SS2.SSS1.p2.9.m3.1.1" xref="S3.SS2.SSS1.p2.9.m3.1.1.cmml"><mi id="S3.SS2.SSS1.p2.9.m3.1.1.2" xref="S3.SS2.SSS1.p2.9.m3.1.1.2.cmml">λ</mi><mo id="S3.SS2.SSS1.p2.9.m3.1.1.1" xref="S3.SS2.SSS1.p2.9.m3.1.1.1.cmml">=</mo><mn id="S3.SS2.SSS1.p2.9.m3.1.1.3" xref="S3.SS2.SSS1.p2.9.m3.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS1.p2.9.m3.1b"><apply id="S3.SS2.SSS1.p2.9.m3.1.1.cmml" xref="S3.SS2.SSS1.p2.9.m3.1.1"><eq id="S3.SS2.SSS1.p2.9.m3.1.1.1.cmml" xref="S3.SS2.SSS1.p2.9.m3.1.1.1"></eq><ci id="S3.SS2.SSS1.p2.9.m3.1.1.2.cmml" xref="S3.SS2.SSS1.p2.9.m3.1.1.2">𝜆</ci><cn type="integer" id="S3.SS2.SSS1.p2.9.m3.1.1.3.cmml" xref="S3.SS2.SSS1.p2.9.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS1.p2.9.m3.1c">\lambda=0</annotation></semantics></math>. The essence of the proximal term is to constrain the difference between the local model and the global model, so as to effectively increase the stability of model training and accelerate model convergence. FedCurv <cite class="ltx_cite ltx_citemacro_cite">Shoham et al<span class="ltx_text">.</span> (<a href="#bib.bib191" title="" class="ltx_ref">2019</a>)</cite> and FedCL <cite class="ltx_cite ltx_citemacro_cite">Yao and Sun (<a href="#bib.bib230" title="" class="ltx_ref">2020</a>)</cite> are adaptations of the Elastic Weight Consolidation (EWC) <cite class="ltx_cite ltx_citemacro_cite">Kirkpatrick et al<span class="ltx_text">.</span> (<a href="#bib.bib104" title="" class="ltx_ref">2017</a>)</cite> algorithm to federated learning scenarios. FedCurv uses the EWC algorithm to prevent catastrophic forgetting when transferring to different learning tasks. Its main idea is to selectively penalize certain parameter vectors far from the network parameters learned in the previous task. FedCL adopts the EWC algorithm to estimate the importance weight matrix of the global model and integrates the knowledge of each client into the global model. pFedME <cite class="ltx_cite ltx_citemacro_cite">T Dinh et al<span class="ltx_text">.</span> (<a href="#bib.bib198" title="" class="ltx_ref">2020</a>)</cite> utilizes the Moreau envelope function as a regularized loss function, which decouples the personalized model optimization process from global model learning. Zhang <span id="S3.SS2.SSS1.p2.9.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib247" title="" class="ltx_ref">2021b</a>)</cite> highlight that the clients should consider the suitability of other models to their goals when downloading personalized weighted combinations, and thus devised a personalized federated learning framework named FedFomo. FedAMP <cite class="ltx_cite ltx_citemacro_cite">Huang et al<span class="ltx_text">.</span> (<a href="#bib.bib89" title="" class="ltx_ref">2021</a>)</cite> builds a positive feedback loop, iteratively promotes similar client models to collaborate more strongly than dissimilar client models, and adaptively groups similar clients to promote effective collaboration. FedBN <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib127" title="" class="ltx_ref">2021e</a>)</cite> solves the problem of feature skew in statistical heterogeneity by adding a batch normalization layer to the local model. SCAFFOLD <cite class="ltx_cite ltx_citemacro_cite">Karimireddy et al<span class="ltx_text">.</span> (<a href="#bib.bib100" title="" class="ltx_ref">2020</a>)</cite> uses variance reduction to correct the client-drift caused by statistical heterogeneity. Specifically, SCAFFOLD estimates the update direction of the server model and the local model and then uses the difference between the server model and the local model to correct the local model update. Instead of learning a single global model, Hanzely <span id="S3.SS2.SSS1.p2.9.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Hanzely and Richtárik (<a href="#bib.bib70" title="" class="ltx_ref">2020</a>)</cite> find a trade-off between the global and local models by adding a regularization term, and learn an implicit mixture model of the global and local models. Unlike these methods, MOON <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib119" title="" class="ltx_ref">2021c</a>)</cite> considers not only the regularization between the global model and the local model but also the regularization between the current local model and the previous local model. To deal with statistical heterogeneity and to improve training stability, Xu <span id="S3.SS2.SSS1.p2.9.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Xu et al<span class="ltx_text">.</span> (<a href="#bib.bib223" title="" class="ltx_ref">2022a</a>)</cite> introduce an adaptive weighted proximal regularization term based on the estimated noise level.
To address the problem of statistical heterogeneity and device heterogeneity, Pillutla <span id="S3.SS2.SSS1.p2.9.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Pillutla et al<span class="ltx_text">.</span> (<a href="#bib.bib171" title="" class="ltx_ref">2023</a>); Laguel et al<span class="ltx_text">.</span> (<a href="#bib.bib109" title="" class="ltx_ref">2021</a>, <a href="#bib.bib108" title="" class="ltx_ref">2020</a>)</cite> improves the performance of the worse-off clients while maintaining the average performance using a risk measure known as the superquantile (or CVaR), which is able to capture the tail statistical characteristics of the client error distribution. Huang <span id="S3.SS2.SSS1.p2.9.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Huang et al<span class="ltx_text">.</span> (<a href="#bib.bib88" title="" class="ltx_ref">2023</a>)</cite> propose FPL to make sample embeddings closer to cluster prototypes of the same domain and category. Meanwhile, a consistency regularization is introduced to align sample embeddings with homogeneous unbiased prototypes that do not contain domain information. Chen <span id="S3.SS2.SSS1.p2.9.6" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Chen et al<span class="ltx_text">.</span> (<a href="#bib.bib24" title="" class="ltx_ref">2023a</a>)</cite> design an elastic aggregation strategy that adaptively interpolates client-side models based on parameter sensitivity, measured by computing the impact of each parameter variation on the output of the overall prediction function. It is an implicit regularization method. In terms of practical technical applications, FedHumor <cite class="ltx_cite ltx_citemacro_cite">Guo et al<span class="ltx_text">.</span> (<a href="#bib.bib67" title="" class="ltx_ref">2022</a>)</cite> applies federated learning to personalized humor recognition in texts, and considers the distribution of humor preferences of different clients to perform domain adaptive fine-tuning training, achieving personalized federated learning.</p>
</div>
<figure id="S3.F8" class="ltx_figure"><img src="/html/2307.10616/assets/x8.png" id="S3.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="321" height="190" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8. </span><span id="S3.F8.2.1" class="ltx_text" style="font-size:90%;">Illustration of federated optimization in heterogeneous federated learning.</span></figcaption>
</figure>
<div id="S3.SS2.SSS1.p3" class="ltx_para">
<p id="S3.SS2.SSS1.p3.1" class="ltx_p"><span id="S3.SS2.SSS1.p3.1.1" class="ltx_text ltx_font_bold">Meta-learning.</span>
This technique is also known as "learning to learn". Previous experience is used to guide the learning of new tasks, thereby allowing a machine to learn a model by itself for different tasks (Fig. <a href="#S3.F8" title="Figure 8 ‣ 3.2.1. Federated Optimization ‣ 3.2. Model-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>). Recently, a meta-learning algorithm named Model-Agnostic Meta-Learning (MAML) <cite class="ltx_cite ltx_citemacro_cite">Finn et al<span class="ltx_text">.</span> (<a href="#bib.bib52" title="" class="ltx_ref">2017</a>)</cite> has attracted widespread attention, as it can be directly applied to any method based on gradient descent. In brief, MAML first trains the initialized model. When training on new tasks, a satisfactory learning performance can be achieved by performing fine-tuning based on the initial model with only a small amount of data. In this manner, the personalization ability of meta-learning can solve the problem of statistical heterogeneity in federated learning.</p>
</div>
<div id="S3.SS2.SSS1.p4" class="ltx_para">
<p id="S3.SS2.SSS1.p4.1" class="ltx_p">Jiang <span id="S3.SS2.SSS1.p4.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Jiang et al<span class="ltx_text">.</span> (<a href="#bib.bib95" title="" class="ltx_ref">2019</a>)</cite> point out that the MAML setting is consistent with the personalized objectives of heterogeneous federated learning. The MAML algorithm is divided into two phases: meta-training and meta-testing, corresponding to the global model training and local model personalization in federated learning, respectively. They also observe that the FedAvg algorithm is very similar to the Reptile <cite class="ltx_cite ltx_citemacro_cite">Alex et al<span class="ltx_text">.</span> (<a href="#bib.bib4" title="" class="ltx_ref">2018</a>)</cite> algorithm. Careful fine-tuning yields a global model with a high accuracy, and the local models are easy to personalize. Per-FedAvg <cite class="ltx_cite ltx_citemacro_cite">Fallah et al<span class="ltx_text">.</span> (<a href="#bib.bib47" title="" class="ltx_ref">2020</a>)</cite> is a personalized variant of the FedAvg algorithm based on the MAML formula. Per-FedAvg aims to learn a high-performance initial global model to ensure that each heterogeneous client can obtain a high-performance local model after personalized updating on the global model. Compared with Per-FedAvg, which performs only one-step gradient updates to obtain personalized models, pFedMe <cite class="ltx_cite ltx_citemacro_cite">T Dinh et al<span class="ltx_text">.</span> (<a href="#bib.bib198" title="" class="ltx_ref">2020</a>)</cite> implements multi-step updates. Chen <span id="S3.SS2.SSS1.p4.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Chen et al<span class="ltx_text">.</span> (<a href="#bib.bib26" title="" class="ltx_ref">2018</a>)</cite> propose a federated meta-learning framework, FedMeta. An algorithm is maintained on the server and distributed to the client for training, after which the test results on the query set are uploaded to the server for algorithm update. ARUBA <cite class="ltx_cite ltx_citemacro_cite">Khodak et al<span class="ltx_text">.</span> (<a href="#bib.bib102" title="" class="ltx_ref">2019</a>)</cite> utilizes online convex optimization and sequence prediction algorithms to adaptively learn the task-similarity and test the federated learning performance. To combat the possible vulnerabilities of meta-learning algorithms, a federated meta-learning method named FedML <cite class="ltx_cite ltx_citemacro_cite">Lin et al<span class="ltx_text">.</span> (<a href="#bib.bib133" title="" class="ltx_ref">2020b</a>)</cite> is established based on distribution robust optimization (DRO). Zheng <span id="S3.SS2.SSS1.p4.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Zheng et al<span class="ltx_text">.</span> (<a href="#bib.bib254" title="" class="ltx_ref">2021</a>)</cite> apply federated meta-learning to fraudulent credit card detection. This method enables the collaboration between different banks through federated learning, improves the triplet loss function, and designs a meta-learning-based classifier for local model updates. <span id="S3.SS2.SSS1.p4.1.4" class="ltx_text" style="color:#000000;">Chu <span id="S3.SS2.SSS1.p4.1.4.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Chu et al<span class="ltx_text">.</span> (<a href="#bib.bib35" title="" class="ltx_ref">2022</a>)</cite> propose a multi-layer personalized federated learning method, MLPFL, to optimize the inference accuracy of different levels of device grouping criteria. MLPFL trains a personalized model with meta-gradient updates for all groups of edge devices.</span></p>
</div>
<div id="S3.SS2.SSS1.p5" class="ltx_para">
<p id="S3.SS2.SSS1.p5.1" class="ltx_p"><span id="S3.SS2.SSS1.p5.1.1" class="ltx_text ltx_font_bold">Multi-task Learning.</span>
Multi-task learning enables models learned on a single task to help learn other tasks by using shared representations or models for relevant tasks. If the local model learning for each client is considered as a separate task, the idea of multi-task learning can be implemented to solve the federated learning problem. To this end, multi-task learning aims to solve different tasks on multiple clients simultaneously and train a model that jointly learns the relevant tasks (Fig. <a href="#S3.F8" title="Figure 8 ‣ 3.2.1. Federated Optimization ‣ 3.2. Model-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>). All participating clients collaboratively train their local models, thereby effectively mitigating statistical heterogeneity and yielding high-performance personalized local models.</p>
</div>
<div id="S3.SS2.SSS1.p6" class="ltx_para">
<p id="S3.SS2.SSS1.p6.1" class="ltx_p">MOCHA <cite class="ltx_cite ltx_citemacro_cite">Smith et al<span class="ltx_text">.</span> (<a href="#bib.bib192" title="" class="ltx_ref">2017</a>)</cite> is a system-aware optimization framework for federated multi-task learning(FMTL), which attempts to address the problems of high communication cost, stragglers, and fault tolerance for distributed multi-task learning. To address statistical heterogeneity and system challenges, MOCHA employs the distributed optimization method COCOA <cite class="ltx_cite ltx_citemacro_cite">Jaggi et al<span class="ltx_text">.</span> (<a href="#bib.bib91" title="" class="ltx_ref">2014</a>); Ma et al<span class="ltx_text">.</span> (<a href="#bib.bib147" title="" class="ltx_ref">2015</a>)</cite>, and trains a unique model for each client. However, MOCHA has some limitations in that it requires all clients to participate in each iteration, which is clearly impractical, and this method cannot be applied to non-convex deep learning models. To ensure that the FMTL algorithm can be applied to general non-convex models, VIRTUAL <cite class="ltx_cite ltx_citemacro_cite">Corinzia et al<span class="ltx_text">.</span> (<a href="#bib.bib37" title="" class="ltx_ref">2019</a>)</cite> considers the federation of a central server and clients as a Bayesian network and employs approximated variational inference for training. OFMTL <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib121" title="" class="ltx_ref">2019</a>)</cite> simulates the relationship between different devices by introducing an accuracy matrix, through which personalized models for new devices can be inferred without revisiting the original device data. Besides, Dinh <span id="S3.SS2.SSS1.p6.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Dinh et al<span class="ltx_text">.</span> (<a href="#bib.bib42" title="" class="ltx_ref">2021</a>)</cite> advise a communication centralized FMTL algorithm FedU, which uses Laplacian regularization to capture the relationship between client models. Ditto <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib123" title="" class="ltx_ref">2021d</a>)</cite> is a scalable FMTL framework with two tasks, a global objective and a local objective. This method ensures that the personalized model is close to the global optimization model by introducing a regularization term. Marfoq <span id="S3.SS2.SSS1.p6.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Marfoq et al<span class="ltx_text">.</span> (<a href="#bib.bib153" title="" class="ltx_ref">2021</a>)</cite> study FMTL under the assumption that each local data distribution is a mixture of unknown underlying distributions. Therefore, each client can benefit from the knowledge distilled from the local data of other clients by modeling the distributions.</p>
</div>
</section>
<section id="S3.SS2.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.2. </span> Knowledge Transfer across Models</h4>

<figure id="S3.F9" class="ltx_figure"><img src="/html/2307.10616/assets/x9.png" id="S3.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="326" height="187" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9. </span><span id="S3.F9.2.1" class="ltx_text" style="font-size:90%;">Illustration of the knowledge transfer approaches across models in heterogeneous federated learning.</span></figcaption>
</figure>
<div id="S3.SS2.SSS2.p1" class="ltx_para">
<p id="S3.SS2.SSS2.p1.1" class="ltx_p"><span id="S3.SS2.SSS2.p1.1.1" class="ltx_text ltx_font_bold">Knowledge Distillation across Models.</span>
In practical federated learning applications, clients may expect to design unique model structures and be reluctant to share the model details. To address the challenges associated with model heterogeneity, knowledge distillation is widely applied in model heterogeneous federated learning. The objective is to refine the knowledge distribution on clients, and then transfer the learned knowledge in a model-agnostic way (Fig. <a href="#S3.F9" title="Figure 9 ‣ 3.2.2. Knowledge Transfer across Models ‣ 3.2. Model-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>).</p>
</div>
<div id="S3.SS2.SSS2.p2" class="ltx_para">
<p id="S3.SS2.SSS2.p2.4" class="ltx_p">FedMD <cite class="ltx_cite ltx_citemacro_cite">Li and Wang (<a href="#bib.bib114" title="" class="ltx_ref">2019</a>)</cite> implements client-side communication by leveraging knowledge distillation and transfer learning. The logits output of the local model <math id="S3.SS2.SSS2.p2.1.m1.1" class="ltx_Math" alttext="f_{k}" display="inline"><semantics id="S3.SS2.SSS2.p2.1.m1.1a"><msub id="S3.SS2.SSS2.p2.1.m1.1.1" xref="S3.SS2.SSS2.p2.1.m1.1.1.cmml"><mi id="S3.SS2.SSS2.p2.1.m1.1.1.2" xref="S3.SS2.SSS2.p2.1.m1.1.1.2.cmml">f</mi><mi id="S3.SS2.SSS2.p2.1.m1.1.1.3" xref="S3.SS2.SSS2.p2.1.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.1.m1.1b"><apply id="S3.SS2.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1.2">𝑓</ci><ci id="S3.SS2.SSS2.p2.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p2.1.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.1.m1.1c">f_{k}</annotation></semantics></math> on the public dataset <math id="S3.SS2.SSS2.p2.2.m2.1" class="ltx_Math" alttext="D_{0}=\{x_{i}^{0}\}" display="inline"><semantics id="S3.SS2.SSS2.p2.2.m2.1a"><mrow id="S3.SS2.SSS2.p2.2.m2.1.1" xref="S3.SS2.SSS2.p2.2.m2.1.1.cmml"><msub id="S3.SS2.SSS2.p2.2.m2.1.1.3" xref="S3.SS2.SSS2.p2.2.m2.1.1.3.cmml"><mi id="S3.SS2.SSS2.p2.2.m2.1.1.3.2" xref="S3.SS2.SSS2.p2.2.m2.1.1.3.2.cmml">D</mi><mn id="S3.SS2.SSS2.p2.2.m2.1.1.3.3" xref="S3.SS2.SSS2.p2.2.m2.1.1.3.3.cmml">0</mn></msub><mo id="S3.SS2.SSS2.p2.2.m2.1.1.2" xref="S3.SS2.SSS2.p2.2.m2.1.1.2.cmml">=</mo><mrow id="S3.SS2.SSS2.p2.2.m2.1.1.1.1" xref="S3.SS2.SSS2.p2.2.m2.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS2.SSS2.p2.2.m2.1.1.1.1.2" xref="S3.SS2.SSS2.p2.2.m2.1.1.1.2.cmml">{</mo><msubsup id="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1" xref="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1.2.2" xref="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1.2.2.cmml">x</mi><mi id="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1.2.3" xref="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1.2.3.cmml">i</mi><mn id="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1.3" xref="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1.3.cmml">0</mn></msubsup><mo stretchy="false" id="S3.SS2.SSS2.p2.2.m2.1.1.1.1.3" xref="S3.SS2.SSS2.p2.2.m2.1.1.1.2.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.2.m2.1b"><apply id="S3.SS2.SSS2.p2.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1"><eq id="S3.SS2.SSS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.2"></eq><apply id="S3.SS2.SSS2.p2.2.m2.1.1.3.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p2.2.m2.1.1.3.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS2.p2.2.m2.1.1.3.2.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.3.2">𝐷</ci><cn type="integer" id="S3.SS2.SSS2.p2.2.m2.1.1.3.3.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.3.3">0</cn></apply><set id="S3.SS2.SSS2.p2.2.m2.1.1.1.2.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.1.1"><apply id="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1">superscript</csymbol><apply id="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1.2.1.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1.2.2.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1.2.2">𝑥</ci><ci id="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1.2.3.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1.2.3">𝑖</ci></apply><cn type="integer" id="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS2.p2.2.m2.1.1.1.1.1.3">0</cn></apply></set></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.2.m2.1c">D_{0}=\{x_{i}^{0}\}</annotation></semantics></math> can be considered as the knowledge distribution of the client <math id="S3.SS2.SSS2.p2.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.SSS2.p2.3.m3.1a"><mi id="S3.SS2.SSS2.p2.3.m3.1.1" xref="S3.SS2.SSS2.p2.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.3.m3.1b"><ci id="S3.SS2.SSS2.p2.3.m3.1.1.cmml" xref="S3.SS2.SSS2.p2.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.3.m3.1c">k</annotation></semantics></math>. The server collects this knowledge to compute the average logits output as a global consensus <math id="S3.SS2.SSS2.p2.4.m4.1" class="ltx_Math" alttext="\tilde{f}" display="inline"><semantics id="S3.SS2.SSS2.p2.4.m4.1a"><mover accent="true" id="S3.SS2.SSS2.p2.4.m4.1.1" xref="S3.SS2.SSS2.p2.4.m4.1.1.cmml"><mi id="S3.SS2.SSS2.p2.4.m4.1.1.2" xref="S3.SS2.SSS2.p2.4.m4.1.1.2.cmml">f</mi><mo id="S3.SS2.SSS2.p2.4.m4.1.1.1" xref="S3.SS2.SSS2.p2.4.m4.1.1.1.cmml">~</mo></mover><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p2.4.m4.1b"><apply id="S3.SS2.SSS2.p2.4.m4.1.1.cmml" xref="S3.SS2.SSS2.p2.4.m4.1.1"><ci id="S3.SS2.SSS2.p2.4.m4.1.1.1.cmml" xref="S3.SS2.SSS2.p2.4.m4.1.1.1">~</ci><ci id="S3.SS2.SSS2.p2.4.m4.1.1.2.cmml" xref="S3.SS2.SSS2.p2.4.m4.1.1.2">𝑓</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p2.4.m4.1c">\tilde{f}</annotation></semantics></math>, which can be expressed as:</p>
<table id="S3.E6" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E6.m1.21" class="ltx_Math" alttext="\begin{split}\tilde{f}(x_{i}^{0})=\frac{1}{K}\sum\nolimits_{k=1}^{K}f_{k}(x_{i}^{0}),\end{split}" display="block"><semantics id="S3.E6.m1.21a"><mtable displaystyle="true" id="S3.E6.m1.21.21.2"><mtr id="S3.E6.m1.21.21.2a"><mtd class="ltx_align_right" columnalign="right" id="S3.E6.m1.21.21.2b"><mrow id="S3.E6.m1.21.21.2.20.20.20.20"><mrow id="S3.E6.m1.21.21.2.20.20.20.20.1"><mrow id="S3.E6.m1.21.21.2.20.20.20.20.1.1"><mover accent="true" id="S3.E6.m1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.cmml"><mi id="S3.E6.m1.1.1.1.1.1.1.2" xref="S3.E6.m1.1.1.1.1.1.1.2.cmml">f</mi><mo id="S3.E6.m1.1.1.1.1.1.1.1" xref="S3.E6.m1.1.1.1.1.1.1.1.cmml">~</mo></mover><mo lspace="0em" rspace="0em" id="S3.E6.m1.21.21.2.20.20.20.20.1.1.2" xref="S3.E6.m1.20.20.1.1.1.cmml">​</mo><mrow id="S3.E6.m1.21.21.2.20.20.20.20.1.1.1.1"><mo stretchy="false" id="S3.E6.m1.2.2.2.2.2.2" xref="S3.E6.m1.20.20.1.1.1.cmml">(</mo><msubsup id="S3.E6.m1.21.21.2.20.20.20.20.1.1.1.1.1"><mi id="S3.E6.m1.3.3.3.3.3.3" xref="S3.E6.m1.3.3.3.3.3.3.cmml">x</mi><mi id="S3.E6.m1.4.4.4.4.4.4.1" xref="S3.E6.m1.4.4.4.4.4.4.1.cmml">i</mi><mn id="S3.E6.m1.5.5.5.5.5.5.1" xref="S3.E6.m1.5.5.5.5.5.5.1.cmml">0</mn></msubsup><mo stretchy="false" id="S3.E6.m1.6.6.6.6.6.6" xref="S3.E6.m1.20.20.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E6.m1.7.7.7.7.7.7" xref="S3.E6.m1.7.7.7.7.7.7.cmml">=</mo><mrow id="S3.E6.m1.21.21.2.20.20.20.20.1.2"><mfrac id="S3.E6.m1.8.8.8.8.8.8" xref="S3.E6.m1.8.8.8.8.8.8.cmml"><mn id="S3.E6.m1.8.8.8.8.8.8.2" xref="S3.E6.m1.8.8.8.8.8.8.2.cmml">1</mn><mi id="S3.E6.m1.8.8.8.8.8.8.3" xref="S3.E6.m1.8.8.8.8.8.8.3.cmml">K</mi></mfrac><mo lspace="0em" rspace="0em" id="S3.E6.m1.21.21.2.20.20.20.20.1.2.2" xref="S3.E6.m1.20.20.1.1.1.cmml">​</mo><mrow id="S3.E6.m1.21.21.2.20.20.20.20.1.2.1"><msubsup id="S3.E6.m1.21.21.2.20.20.20.20.1.2.1.2"><mo id="S3.E6.m1.9.9.9.9.9.9" xref="S3.E6.m1.9.9.9.9.9.9.cmml">∑</mo><mrow id="S3.E6.m1.10.10.10.10.10.10.1" xref="S3.E6.m1.10.10.10.10.10.10.1.cmml"><mi id="S3.E6.m1.10.10.10.10.10.10.1.2" xref="S3.E6.m1.10.10.10.10.10.10.1.2.cmml">k</mi><mo id="S3.E6.m1.10.10.10.10.10.10.1.1" xref="S3.E6.m1.10.10.10.10.10.10.1.1.cmml">=</mo><mn id="S3.E6.m1.10.10.10.10.10.10.1.3" xref="S3.E6.m1.10.10.10.10.10.10.1.3.cmml">1</mn></mrow><mi id="S3.E6.m1.11.11.11.11.11.11.1" xref="S3.E6.m1.11.11.11.11.11.11.1.cmml">K</mi></msubsup><mrow id="S3.E6.m1.21.21.2.20.20.20.20.1.2.1.1"><msub id="S3.E6.m1.21.21.2.20.20.20.20.1.2.1.1.3"><mi id="S3.E6.m1.12.12.12.12.12.12" xref="S3.E6.m1.12.12.12.12.12.12.cmml">f</mi><mi id="S3.E6.m1.13.13.13.13.13.13.1" xref="S3.E6.m1.13.13.13.13.13.13.1.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S3.E6.m1.21.21.2.20.20.20.20.1.2.1.1.2" xref="S3.E6.m1.20.20.1.1.1.cmml">​</mo><mrow id="S3.E6.m1.21.21.2.20.20.20.20.1.2.1.1.1.1"><mo stretchy="false" id="S3.E6.m1.14.14.14.14.14.14" xref="S3.E6.m1.20.20.1.1.1.cmml">(</mo><msubsup id="S3.E6.m1.21.21.2.20.20.20.20.1.2.1.1.1.1.1"><mi id="S3.E6.m1.15.15.15.15.15.15" xref="S3.E6.m1.15.15.15.15.15.15.cmml">x</mi><mi id="S3.E6.m1.16.16.16.16.16.16.1" xref="S3.E6.m1.16.16.16.16.16.16.1.cmml">i</mi><mn id="S3.E6.m1.17.17.17.17.17.17.1" xref="S3.E6.m1.17.17.17.17.17.17.1.cmml">0</mn></msubsup><mo stretchy="false" id="S3.E6.m1.18.18.18.18.18.18" xref="S3.E6.m1.20.20.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo id="S3.E6.m1.19.19.19.19.19.19" xref="S3.E6.m1.20.20.1.1.1.cmml">,</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S3.E6.m1.21b"><apply id="S3.E6.m1.20.20.1.1.1.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2"><eq id="S3.E6.m1.7.7.7.7.7.7.cmml" xref="S3.E6.m1.7.7.7.7.7.7"></eq><apply id="S3.E6.m1.20.20.1.1.1.1.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2"><times id="S3.E6.m1.20.20.1.1.1.1.2.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2"></times><apply id="S3.E6.m1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1"><ci id="S3.E6.m1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.1.1.1.1.1.1.1">~</ci><ci id="S3.E6.m1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.1.1.1.1.1.1.2">𝑓</ci></apply><apply id="S3.E6.m1.20.20.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.20.20.1.1.1.1.1.1.1.1.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2">superscript</csymbol><apply id="S3.E6.m1.20.20.1.1.1.1.1.1.1.2.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.20.20.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2">subscript</csymbol><ci id="S3.E6.m1.3.3.3.3.3.3.cmml" xref="S3.E6.m1.3.3.3.3.3.3">𝑥</ci><ci id="S3.E6.m1.4.4.4.4.4.4.1.cmml" xref="S3.E6.m1.4.4.4.4.4.4.1">𝑖</ci></apply><cn type="integer" id="S3.E6.m1.5.5.5.5.5.5.1.cmml" xref="S3.E6.m1.5.5.5.5.5.5.1">0</cn></apply></apply><apply id="S3.E6.m1.20.20.1.1.1.2.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2"><times id="S3.E6.m1.20.20.1.1.1.2.2.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2"></times><apply id="S3.E6.m1.8.8.8.8.8.8.cmml" xref="S3.E6.m1.8.8.8.8.8.8"><divide id="S3.E6.m1.8.8.8.8.8.8.1.cmml" xref="S3.E6.m1.8.8.8.8.8.8"></divide><cn type="integer" id="S3.E6.m1.8.8.8.8.8.8.2.cmml" xref="S3.E6.m1.8.8.8.8.8.8.2">1</cn><ci id="S3.E6.m1.8.8.8.8.8.8.3.cmml" xref="S3.E6.m1.8.8.8.8.8.8.3">𝐾</ci></apply><apply id="S3.E6.m1.20.20.1.1.1.2.1.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2"><apply id="S3.E6.m1.20.20.1.1.1.2.1.2.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.20.20.1.1.1.2.1.2.1.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2">superscript</csymbol><apply id="S3.E6.m1.20.20.1.1.1.2.1.2.2.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.20.20.1.1.1.2.1.2.2.1.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2">subscript</csymbol><sum id="S3.E6.m1.9.9.9.9.9.9.cmml" xref="S3.E6.m1.9.9.9.9.9.9"></sum><apply id="S3.E6.m1.10.10.10.10.10.10.1.cmml" xref="S3.E6.m1.10.10.10.10.10.10.1"><eq id="S3.E6.m1.10.10.10.10.10.10.1.1.cmml" xref="S3.E6.m1.10.10.10.10.10.10.1.1"></eq><ci id="S3.E6.m1.10.10.10.10.10.10.1.2.cmml" xref="S3.E6.m1.10.10.10.10.10.10.1.2">𝑘</ci><cn type="integer" id="S3.E6.m1.10.10.10.10.10.10.1.3.cmml" xref="S3.E6.m1.10.10.10.10.10.10.1.3">1</cn></apply></apply><ci id="S3.E6.m1.11.11.11.11.11.11.1.cmml" xref="S3.E6.m1.11.11.11.11.11.11.1">𝐾</ci></apply><apply id="S3.E6.m1.20.20.1.1.1.2.1.1.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2"><times id="S3.E6.m1.20.20.1.1.1.2.1.1.2.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2"></times><apply id="S3.E6.m1.20.20.1.1.1.2.1.1.3.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.20.20.1.1.1.2.1.1.3.1.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2">subscript</csymbol><ci id="S3.E6.m1.12.12.12.12.12.12.cmml" xref="S3.E6.m1.12.12.12.12.12.12">𝑓</ci><ci id="S3.E6.m1.13.13.13.13.13.13.1.cmml" xref="S3.E6.m1.13.13.13.13.13.13.1">𝑘</ci></apply><apply id="S3.E6.m1.20.20.1.1.1.2.1.1.1.1.1.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.20.20.1.1.1.2.1.1.1.1.1.1.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2">superscript</csymbol><apply id="S3.E6.m1.20.20.1.1.1.2.1.1.1.1.1.2.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2"><csymbol cd="ambiguous" id="S3.E6.m1.20.20.1.1.1.2.1.1.1.1.1.2.1.cmml" xref="S3.E6.m1.21.21.2.20.20.20.20.1.1.2">subscript</csymbol><ci id="S3.E6.m1.15.15.15.15.15.15.cmml" xref="S3.E6.m1.15.15.15.15.15.15">𝑥</ci><ci id="S3.E6.m1.16.16.16.16.16.16.1.cmml" xref="S3.E6.m1.16.16.16.16.16.16.1">𝑖</ci></apply><cn type="integer" id="S3.E6.m1.17.17.17.17.17.17.1.cmml" xref="S3.E6.m1.17.17.17.17.17.17.1">0</cn></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E6.m1.21c">\begin{split}\tilde{f}(x_{i}^{0})=\frac{1}{K}\sum\nolimits_{k=1}^{K}f_{k}(x_{i}^{0}),\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(6)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS2.p2.5" class="ltx_p">Subsequently, each client learns the information from other clients by training its local model to approach the global consensus. The basic ideas of Cronus <cite class="ltx_cite ltx_citemacro_cite">Chang et al<span class="ltx_text">.</span> (<a href="#bib.bib22" title="" class="ltx_ref">2019</a>)</cite> and FedMD are similar as they both operate on public data via knowledge distillation. However, FedMD calculates a global consensus through a common averaging strategy, whereas Cronus designs an aggregation algorithm that is robust against poisoning attacks. The performance of the aforementioned methods depends heavily on the public data quality. To alleviate the reliance on public data, FedDF <cite class="ltx_cite ltx_citemacro_cite">Lin et al<span class="ltx_text">.</span> (<a href="#bib.bib134" title="" class="ltx_ref">2020a</a>)</cite> utilizes unlabeled or generated data for ensemble distillation. To perform federated learning with heterogeneous clients without relying on a global consensus or shared public models, RHFL <cite class="ltx_cite ltx_citemacro_cite">Huang et al<span class="ltx_text">.</span> (<a href="#bib.bib86" title="" class="ltx_ref">2022b</a>); Fang and Ye (<a href="#bib.bib49" title="" class="ltx_ref">2022</a>)</cite> learns the knowledge distribution of other clients by aligning models feedback on irrelevant public data.
To improve the communication efficiency of federated learning, Sattler <span id="S3.SS2.SSS2.p2.5.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Sattler et al<span class="ltx_text">.</span> (<a href="#bib.bib180" title="" class="ltx_ref">2020a</a>)</cite> develop a compressed federated distillation method CFD, which employs distilled data curation, soft-label quantization and delta-encoding to reduce the communication from client to server. Unlike these approaches, FedGEN <cite class="ltx_cite ltx_citemacro_cite">Zhu et al<span class="ltx_text">.</span> (<a href="#bib.bib256" title="" class="ltx_ref">2021a</a>)</cite> does not rely on the server side to possess a proxy dataset. FedGEN performs statistical heterogeneous federated learning through a data-free knowledge distillation approach, in which the server learns a lightweight generator derived only from the prediction rules of client models, thereby integrating client information in a data-free manner. The generator is then broadcast to the clients, using the learned knowledge as an inductive bias to guide local model training.</p>
</div>
<div id="S3.SS2.SSS2.p3" class="ltx_para">
<p id="S3.SS2.SSS2.p3.1" class="ltx_p"><span id="S3.SS2.SSS2.p3.1.1" class="ltx_text ltx_font_bold">Transfer Learning.</span>
The goal of transfer learning is to apply the knowledge learned on the source domain to different but related target domains (Fig. <a href="#S3.F9" title="Figure 9 ‣ 3.2.2. Knowledge Transfer across Models ‣ 3.2. Model-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>). In the federated learning scenarios, the clients typically belong to different but related domains and wish to learn knowledge from other domains. Therefore, transfer learning is widely applied in the federated learning field. Knowledge distillation is an effective strategy for transfer learning. Accordingly, federated transfer learning aims to transfer the knowledge learned on clients to the public server for aggregation or to transfer the global consensus to clients for personalization.</p>
</div>
<div id="S3.SS2.SSS2.p4" class="ltx_para">
<p id="S3.SS2.SSS2.p4.4" class="ltx_p">In the healthcare domain, FedHealth <cite class="ltx_cite ltx_citemacro_cite">Chen et al<span class="ltx_text">.</span> (<a href="#bib.bib31" title="" class="ltx_ref">2020b</a>)</cite> is established as a federated transfer learning framework. FedHealth performs data aggregation through federated learning and then builds personalized models through transfer learning. Considering the large distribution differences between the server model and the client models, FedHealth allows clients to train personalized models through transfer learning. In FedMD, transfer learning is a key approach to address the problem of private data scarcity and personalize the local models. In the transfer learning phase, the clients first fully train the local models on the public dataset and then train them on the private datasets until convergence. To solve the problem of slow convergence and degraded learning performance in heterogeneous scenarios, the decentralized federated learning via mutual knowledge transfer (Def-KT) algorithm is designed by Li <span id="S3.SS2.SSS2.p4.4.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib113" title="" class="ltx_ref">2021f</a>)</cite>. Def-KT does not require the participation of the server, and each client directly transfers the knowledge in a point-to-point manner. In the personalized knowledge transfer phase, KT-pFL <cite class="ltx_cite ltx_citemacro_cite">Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib243" title="" class="ltx_ref">2021a</a>)</cite> linearly combines the soft predictions of all clients through the knowledge coefficient matrix to identify the mutual contribution of clients, thereby enhancing the collaboration between clients with similar data distributions. The soft prediction of the local model <math id="S3.SS2.SSS2.p4.1.m1.1" class="ltx_Math" alttext="\theta_{n}" display="inline"><semantics id="S3.SS2.SSS2.p4.1.m1.1a"><msub id="S3.SS2.SSS2.p4.1.m1.1.1" xref="S3.SS2.SSS2.p4.1.m1.1.1.cmml"><mi id="S3.SS2.SSS2.p4.1.m1.1.1.2" xref="S3.SS2.SSS2.p4.1.m1.1.1.2.cmml">θ</mi><mi id="S3.SS2.SSS2.p4.1.m1.1.1.3" xref="S3.SS2.SSS2.p4.1.m1.1.1.3.cmml">n</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.1.m1.1b"><apply id="S3.SS2.SSS2.p4.1.m1.1.1.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p4.1.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p4.1.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1.2">𝜃</ci><ci id="S3.SS2.SSS2.p4.1.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p4.1.m1.1.1.3">𝑛</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.1.m1.1c">\theta_{n}</annotation></semantics></math> on the public dataset <math id="S3.SS2.SSS2.p4.2.m2.1" class="ltx_Math" alttext="D_{0}" display="inline"><semantics id="S3.SS2.SSS2.p4.2.m2.1a"><msub id="S3.SS2.SSS2.p4.2.m2.1.1" xref="S3.SS2.SSS2.p4.2.m2.1.1.cmml"><mi id="S3.SS2.SSS2.p4.2.m2.1.1.2" xref="S3.SS2.SSS2.p4.2.m2.1.1.2.cmml">D</mi><mn id="S3.SS2.SSS2.p4.2.m2.1.1.3" xref="S3.SS2.SSS2.p4.2.m2.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.2.m2.1b"><apply id="S3.SS2.SSS2.p4.2.m2.1.1.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p4.2.m2.1.1.1.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p4.2.m2.1.1.2.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.2">𝐷</ci><cn type="integer" id="S3.SS2.SSS2.p4.2.m2.1.1.3.cmml" xref="S3.SS2.SSS2.p4.2.m2.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.2.m2.1c">D_{0}</annotation></semantics></math> represents the collaborative knowledge <math id="S3.SS2.SSS2.p4.3.m3.2" class="ltx_Math" alttext="f(\theta_{n},D_{0})" display="inline"><semantics id="S3.SS2.SSS2.p4.3.m3.2a"><mrow id="S3.SS2.SSS2.p4.3.m3.2.2" xref="S3.SS2.SSS2.p4.3.m3.2.2.cmml"><mi id="S3.SS2.SSS2.p4.3.m3.2.2.4" xref="S3.SS2.SSS2.p4.3.m3.2.2.4.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.SS2.SSS2.p4.3.m3.2.2.3" xref="S3.SS2.SSS2.p4.3.m3.2.2.3.cmml">​</mo><mrow id="S3.SS2.SSS2.p4.3.m3.2.2.2.2" xref="S3.SS2.SSS2.p4.3.m3.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS2.SSS2.p4.3.m3.2.2.2.2.3" xref="S3.SS2.SSS2.p4.3.m3.2.2.2.3.cmml">(</mo><msub id="S3.SS2.SSS2.p4.3.m3.1.1.1.1.1" xref="S3.SS2.SSS2.p4.3.m3.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS2.p4.3.m3.1.1.1.1.1.2" xref="S3.SS2.SSS2.p4.3.m3.1.1.1.1.1.2.cmml">θ</mi><mi id="S3.SS2.SSS2.p4.3.m3.1.1.1.1.1.3" xref="S3.SS2.SSS2.p4.3.m3.1.1.1.1.1.3.cmml">n</mi></msub><mo id="S3.SS2.SSS2.p4.3.m3.2.2.2.2.4" xref="S3.SS2.SSS2.p4.3.m3.2.2.2.3.cmml">,</mo><msub id="S3.SS2.SSS2.p4.3.m3.2.2.2.2.2" xref="S3.SS2.SSS2.p4.3.m3.2.2.2.2.2.cmml"><mi id="S3.SS2.SSS2.p4.3.m3.2.2.2.2.2.2" xref="S3.SS2.SSS2.p4.3.m3.2.2.2.2.2.2.cmml">D</mi><mn id="S3.SS2.SSS2.p4.3.m3.2.2.2.2.2.3" xref="S3.SS2.SSS2.p4.3.m3.2.2.2.2.2.3.cmml">0</mn></msub><mo stretchy="false" id="S3.SS2.SSS2.p4.3.m3.2.2.2.2.5" xref="S3.SS2.SSS2.p4.3.m3.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.3.m3.2b"><apply id="S3.SS2.SSS2.p4.3.m3.2.2.cmml" xref="S3.SS2.SSS2.p4.3.m3.2.2"><times id="S3.SS2.SSS2.p4.3.m3.2.2.3.cmml" xref="S3.SS2.SSS2.p4.3.m3.2.2.3"></times><ci id="S3.SS2.SSS2.p4.3.m3.2.2.4.cmml" xref="S3.SS2.SSS2.p4.3.m3.2.2.4">𝑓</ci><interval closure="open" id="S3.SS2.SSS2.p4.3.m3.2.2.2.3.cmml" xref="S3.SS2.SSS2.p4.3.m3.2.2.2.2"><apply id="S3.SS2.SSS2.p4.3.m3.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p4.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p4.3.m3.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS2.p4.3.m3.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p4.3.m3.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS2.p4.3.m3.1.1.1.1.1.2">𝜃</ci><ci id="S3.SS2.SSS2.p4.3.m3.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS2.p4.3.m3.1.1.1.1.1.3">𝑛</ci></apply><apply id="S3.SS2.SSS2.p4.3.m3.2.2.2.2.2.cmml" xref="S3.SS2.SSS2.p4.3.m3.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p4.3.m3.2.2.2.2.2.1.cmml" xref="S3.SS2.SSS2.p4.3.m3.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.SSS2.p4.3.m3.2.2.2.2.2.2.cmml" xref="S3.SS2.SSS2.p4.3.m3.2.2.2.2.2.2">𝐷</ci><cn type="integer" id="S3.SS2.SSS2.p4.3.m3.2.2.2.2.2.3.cmml" xref="S3.SS2.SSS2.p4.3.m3.2.2.2.2.2.3">0</cn></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.3.m3.2c">f(\theta_{n},D_{0})</annotation></semantics></math> from client <math id="S3.SS2.SSS2.p4.4.m4.1" class="ltx_Math" alttext="n" display="inline"><semantics id="S3.SS2.SSS2.p4.4.m4.1a"><mi id="S3.SS2.SSS2.p4.4.m4.1.1" xref="S3.SS2.SSS2.p4.4.m4.1.1.cmml">n</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.4.m4.1b"><ci id="S3.SS2.SSS2.p4.4.m4.1.1.cmml" xref="S3.SS2.SSS2.p4.4.m4.1.1">𝑛</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.4.m4.1c">n</annotation></semantics></math>. Furthermore, KL divergence is utilized to transfer knowledge across clients, and then the local update can be phrased as:</p>
<table id="S3.E7" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E7.m1.39" class="ltx_Math" alttext="\begin{split}{\theta_{n}}\leftarrow{\theta_{n}-\alpha{\nabla_{\theta}}\mathcal{L}_{kl}(\sum_{m=1}^{N}\mathcal{M}_{m}\cdot f(\theta_{m},D_{0}),f(\theta_{n},D_{0}))},\end{split}" display="block"><semantics id="S3.E7.m1.39a"><mtable displaystyle="true" id="S3.E7.m1.39.39.2"><mtr id="S3.E7.m1.39.39.2a"><mtd class="ltx_align_right" columnalign="right" id="S3.E7.m1.39.39.2b"><mrow id="S3.E7.m1.39.39.2.38.38.38.38"><mrow id="S3.E7.m1.39.39.2.38.38.38.38.1"><msub id="S3.E7.m1.39.39.2.38.38.38.38.1.3"><mi id="S3.E7.m1.1.1.1.1.1.1" xref="S3.E7.m1.1.1.1.1.1.1.cmml">θ</mi><mi id="S3.E7.m1.2.2.2.2.2.2.1" xref="S3.E7.m1.2.2.2.2.2.2.1.cmml">n</mi></msub><mo stretchy="false" id="S3.E7.m1.3.3.3.3.3.3" xref="S3.E7.m1.3.3.3.3.3.3.cmml">←</mo><mrow id="S3.E7.m1.39.39.2.38.38.38.38.1.2"><msub id="S3.E7.m1.39.39.2.38.38.38.38.1.2.3"><mi id="S3.E7.m1.4.4.4.4.4.4" xref="S3.E7.m1.4.4.4.4.4.4.cmml">θ</mi><mi id="S3.E7.m1.5.5.5.5.5.5.1" xref="S3.E7.m1.5.5.5.5.5.5.1.cmml">n</mi></msub><mo id="S3.E7.m1.6.6.6.6.6.6" xref="S3.E7.m1.6.6.6.6.6.6.cmml">−</mo><mrow id="S3.E7.m1.39.39.2.38.38.38.38.1.2.2"><mi id="S3.E7.m1.7.7.7.7.7.7" xref="S3.E7.m1.7.7.7.7.7.7.cmml">α</mi><mo lspace="0.167em" rspace="0em" id="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3" xref="S3.E7.m1.38.38.1.1.1.cmml">​</mo><mrow id="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.4"><msub id="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.4.1"><mo rspace="0.167em" id="S3.E7.m1.8.8.8.8.8.8" xref="S3.E7.m1.8.8.8.8.8.8.cmml">∇</mo><mi id="S3.E7.m1.9.9.9.9.9.9.1" xref="S3.E7.m1.9.9.9.9.9.9.1.cmml">θ</mi></msub><msub id="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.4.2"><mi class="ltx_font_mathcaligraphic" id="S3.E7.m1.10.10.10.10.10.10" xref="S3.E7.m1.10.10.10.10.10.10.cmml">ℒ</mi><mrow id="S3.E7.m1.11.11.11.11.11.11.1" xref="S3.E7.m1.11.11.11.11.11.11.1.cmml"><mi id="S3.E7.m1.11.11.11.11.11.11.1.2" xref="S3.E7.m1.11.11.11.11.11.11.1.2.cmml">k</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.11.11.11.11.11.11.1.1" xref="S3.E7.m1.11.11.11.11.11.11.1.1.cmml">​</mo><mi id="S3.E7.m1.11.11.11.11.11.11.1.3" xref="S3.E7.m1.11.11.11.11.11.11.1.3.cmml">l</mi></mrow></msub></mrow><mo lspace="0em" rspace="0em" id="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3a" xref="S3.E7.m1.38.38.1.1.1.cmml">​</mo><mrow id="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.2.2"><mo stretchy="false" id="S3.E7.m1.12.12.12.12.12.12" xref="S3.E7.m1.38.38.1.1.1.cmml">(</mo><mrow id="S3.E7.m1.39.39.2.38.38.38.38.1.1.1.1.1.1"><munderover id="S3.E7.m1.39.39.2.38.38.38.38.1.1.1.1.1.1.3"><mo lspace="0em" movablelimits="false" id="S3.E7.m1.13.13.13.13.13.13" xref="S3.E7.m1.13.13.13.13.13.13.cmml">∑</mo><mrow id="S3.E7.m1.14.14.14.14.14.14.1" xref="S3.E7.m1.14.14.14.14.14.14.1.cmml"><mi id="S3.E7.m1.14.14.14.14.14.14.1.2" xref="S3.E7.m1.14.14.14.14.14.14.1.2.cmml">m</mi><mo id="S3.E7.m1.14.14.14.14.14.14.1.1" xref="S3.E7.m1.14.14.14.14.14.14.1.1.cmml">=</mo><mn id="S3.E7.m1.14.14.14.14.14.14.1.3" xref="S3.E7.m1.14.14.14.14.14.14.1.3.cmml">1</mn></mrow><mi id="S3.E7.m1.15.15.15.15.15.15.1" xref="S3.E7.m1.15.15.15.15.15.15.1.cmml">N</mi></munderover><mrow id="S3.E7.m1.39.39.2.38.38.38.38.1.1.1.1.1.1.2"><mrow id="S3.E7.m1.39.39.2.38.38.38.38.1.1.1.1.1.1.2.4"><msub id="S3.E7.m1.39.39.2.38.38.38.38.1.1.1.1.1.1.2.4.1"><mi class="ltx_font_mathcaligraphic" id="S3.E7.m1.16.16.16.16.16.16" xref="S3.E7.m1.16.16.16.16.16.16.cmml">ℳ</mi><mi id="S3.E7.m1.17.17.17.17.17.17.1" xref="S3.E7.m1.17.17.17.17.17.17.1.cmml">m</mi></msub><mo lspace="0.222em" rspace="0.222em" id="S3.E7.m1.18.18.18.18.18.18" xref="S3.E7.m1.18.18.18.18.18.18.cmml">⋅</mo><mi id="S3.E7.m1.19.19.19.19.19.19" xref="S3.E7.m1.19.19.19.19.19.19.cmml">f</mi></mrow><mo lspace="0em" rspace="0em" id="S3.E7.m1.39.39.2.38.38.38.38.1.1.1.1.1.1.2.3" xref="S3.E7.m1.38.38.1.1.1.cmml">​</mo><mrow id="S3.E7.m1.39.39.2.38.38.38.38.1.1.1.1.1.1.2.2.2"><mo stretchy="false" id="S3.E7.m1.20.20.20.20.20.20" xref="S3.E7.m1.38.38.1.1.1.cmml">(</mo><msub id="S3.E7.m1.39.39.2.38.38.38.38.1.1.1.1.1.1.1.1.1.1"><mi id="S3.E7.m1.21.21.21.21.21.21" xref="S3.E7.m1.21.21.21.21.21.21.cmml">θ</mi><mi id="S3.E7.m1.22.22.22.22.22.22.1" xref="S3.E7.m1.22.22.22.22.22.22.1.cmml">m</mi></msub><mo id="S3.E7.m1.23.23.23.23.23.23" xref="S3.E7.m1.38.38.1.1.1.cmml">,</mo><msub id="S3.E7.m1.39.39.2.38.38.38.38.1.1.1.1.1.1.2.2.2.2"><mi id="S3.E7.m1.24.24.24.24.24.24" xref="S3.E7.m1.24.24.24.24.24.24.cmml">D</mi><mn id="S3.E7.m1.25.25.25.25.25.25.1" xref="S3.E7.m1.25.25.25.25.25.25.1.cmml">0</mn></msub><mo stretchy="false" id="S3.E7.m1.26.26.26.26.26.26" xref="S3.E7.m1.38.38.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S3.E7.m1.27.27.27.27.27.27" xref="S3.E7.m1.38.38.1.1.1.cmml">,</mo><mrow id="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.2.2.2"><mi id="S3.E7.m1.28.28.28.28.28.28" xref="S3.E7.m1.28.28.28.28.28.28.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.2.2.2.3" xref="S3.E7.m1.38.38.1.1.1.cmml">​</mo><mrow id="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.2.2.2.2.2"><mo stretchy="false" id="S3.E7.m1.29.29.29.29.29.29" xref="S3.E7.m1.38.38.1.1.1.cmml">(</mo><msub id="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.2.2.2.1.1.1"><mi id="S3.E7.m1.30.30.30.30.30.30" xref="S3.E7.m1.30.30.30.30.30.30.cmml">θ</mi><mi id="S3.E7.m1.31.31.31.31.31.31.1" xref="S3.E7.m1.31.31.31.31.31.31.1.cmml">n</mi></msub><mo id="S3.E7.m1.32.32.32.32.32.32" xref="S3.E7.m1.38.38.1.1.1.cmml">,</mo><msub id="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.2.2.2.2.2.2"><mi id="S3.E7.m1.33.33.33.33.33.33" xref="S3.E7.m1.33.33.33.33.33.33.cmml">D</mi><mn id="S3.E7.m1.34.34.34.34.34.34.1" xref="S3.E7.m1.34.34.34.34.34.34.1.cmml">0</mn></msub><mo stretchy="false" id="S3.E7.m1.35.35.35.35.35.35" xref="S3.E7.m1.38.38.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E7.m1.36.36.36.36.36.36" xref="S3.E7.m1.38.38.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E7.m1.37.37.37.37.37.37" xref="S3.E7.m1.38.38.1.1.1.cmml">,</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S3.E7.m1.39b"><apply id="S3.E7.m1.38.38.1.1.1.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><ci id="S3.E7.m1.3.3.3.3.3.3.cmml" xref="S3.E7.m1.3.3.3.3.3.3">←</ci><apply id="S3.E7.m1.38.38.1.1.1.4.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><csymbol cd="ambiguous" id="S3.E7.m1.38.38.1.1.1.4.1.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3">subscript</csymbol><ci id="S3.E7.m1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.1.1.1.1.1.1">𝜃</ci><ci id="S3.E7.m1.2.2.2.2.2.2.1.cmml" xref="S3.E7.m1.2.2.2.2.2.2.1">𝑛</ci></apply><apply id="S3.E7.m1.38.38.1.1.1.2.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><minus id="S3.E7.m1.6.6.6.6.6.6.cmml" xref="S3.E7.m1.6.6.6.6.6.6"></minus><apply id="S3.E7.m1.38.38.1.1.1.2.4.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><csymbol cd="ambiguous" id="S3.E7.m1.38.38.1.1.1.2.4.1.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3">subscript</csymbol><ci id="S3.E7.m1.4.4.4.4.4.4.cmml" xref="S3.E7.m1.4.4.4.4.4.4">𝜃</ci><ci id="S3.E7.m1.5.5.5.5.5.5.1.cmml" xref="S3.E7.m1.5.5.5.5.5.5.1">𝑛</ci></apply><apply id="S3.E7.m1.38.38.1.1.1.2.2.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><times id="S3.E7.m1.38.38.1.1.1.2.2.3.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"></times><ci id="S3.E7.m1.7.7.7.7.7.7.cmml" xref="S3.E7.m1.7.7.7.7.7.7">𝛼</ci><apply id="S3.E7.m1.38.38.1.1.1.2.2.5.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><apply id="S3.E7.m1.38.38.1.1.1.2.2.5.1.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><csymbol cd="ambiguous" id="S3.E7.m1.38.38.1.1.1.2.2.5.1.1.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3">subscript</csymbol><ci id="S3.E7.m1.8.8.8.8.8.8.cmml" xref="S3.E7.m1.8.8.8.8.8.8">∇</ci><ci id="S3.E7.m1.9.9.9.9.9.9.1.cmml" xref="S3.E7.m1.9.9.9.9.9.9.1">𝜃</ci></apply><apply id="S3.E7.m1.38.38.1.1.1.2.2.5.2.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><csymbol cd="ambiguous" id="S3.E7.m1.38.38.1.1.1.2.2.5.2.1.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3">subscript</csymbol><ci id="S3.E7.m1.10.10.10.10.10.10.cmml" xref="S3.E7.m1.10.10.10.10.10.10">ℒ</ci><apply id="S3.E7.m1.11.11.11.11.11.11.1.cmml" xref="S3.E7.m1.11.11.11.11.11.11.1"><times id="S3.E7.m1.11.11.11.11.11.11.1.1.cmml" xref="S3.E7.m1.11.11.11.11.11.11.1.1"></times><ci id="S3.E7.m1.11.11.11.11.11.11.1.2.cmml" xref="S3.E7.m1.11.11.11.11.11.11.1.2">𝑘</ci><ci id="S3.E7.m1.11.11.11.11.11.11.1.3.cmml" xref="S3.E7.m1.11.11.11.11.11.11.1.3">𝑙</ci></apply></apply></apply><interval closure="open" id="S3.E7.m1.38.38.1.1.1.2.2.2.3.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><apply id="S3.E7.m1.38.38.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><apply id="S3.E7.m1.38.38.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><csymbol cd="ambiguous" id="S3.E7.m1.38.38.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3">superscript</csymbol><apply id="S3.E7.m1.38.38.1.1.1.1.1.1.1.1.3.2.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><csymbol cd="ambiguous" id="S3.E7.m1.38.38.1.1.1.1.1.1.1.1.3.2.1.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3">subscript</csymbol><sum id="S3.E7.m1.13.13.13.13.13.13.cmml" xref="S3.E7.m1.13.13.13.13.13.13"></sum><apply id="S3.E7.m1.14.14.14.14.14.14.1.cmml" xref="S3.E7.m1.14.14.14.14.14.14.1"><eq id="S3.E7.m1.14.14.14.14.14.14.1.1.cmml" xref="S3.E7.m1.14.14.14.14.14.14.1.1"></eq><ci id="S3.E7.m1.14.14.14.14.14.14.1.2.cmml" xref="S3.E7.m1.14.14.14.14.14.14.1.2">𝑚</ci><cn type="integer" id="S3.E7.m1.14.14.14.14.14.14.1.3.cmml" xref="S3.E7.m1.14.14.14.14.14.14.1.3">1</cn></apply></apply><ci id="S3.E7.m1.15.15.15.15.15.15.1.cmml" xref="S3.E7.m1.15.15.15.15.15.15.1">𝑁</ci></apply><apply id="S3.E7.m1.38.38.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><times id="S3.E7.m1.38.38.1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"></times><apply id="S3.E7.m1.38.38.1.1.1.1.1.1.1.1.2.4.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><ci id="S3.E7.m1.18.18.18.18.18.18.cmml" xref="S3.E7.m1.18.18.18.18.18.18">⋅</ci><apply id="S3.E7.m1.38.38.1.1.1.1.1.1.1.1.2.4.2.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><csymbol cd="ambiguous" id="S3.E7.m1.38.38.1.1.1.1.1.1.1.1.2.4.2.1.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3">subscript</csymbol><ci id="S3.E7.m1.16.16.16.16.16.16.cmml" xref="S3.E7.m1.16.16.16.16.16.16">ℳ</ci><ci id="S3.E7.m1.17.17.17.17.17.17.1.cmml" xref="S3.E7.m1.17.17.17.17.17.17.1">𝑚</ci></apply><ci id="S3.E7.m1.19.19.19.19.19.19.cmml" xref="S3.E7.m1.19.19.19.19.19.19">𝑓</ci></apply><interval closure="open" id="S3.E7.m1.38.38.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><apply id="S3.E7.m1.38.38.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><csymbol cd="ambiguous" id="S3.E7.m1.38.38.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3">subscript</csymbol><ci id="S3.E7.m1.21.21.21.21.21.21.cmml" xref="S3.E7.m1.21.21.21.21.21.21">𝜃</ci><ci id="S3.E7.m1.22.22.22.22.22.22.1.cmml" xref="S3.E7.m1.22.22.22.22.22.22.1">𝑚</ci></apply><apply id="S3.E7.m1.38.38.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><csymbol cd="ambiguous" id="S3.E7.m1.38.38.1.1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3">subscript</csymbol><ci id="S3.E7.m1.24.24.24.24.24.24.cmml" xref="S3.E7.m1.24.24.24.24.24.24">𝐷</ci><cn type="integer" id="S3.E7.m1.25.25.25.25.25.25.1.cmml" xref="S3.E7.m1.25.25.25.25.25.25.1">0</cn></apply></interval></apply></apply><apply id="S3.E7.m1.38.38.1.1.1.2.2.2.2.2.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><times id="S3.E7.m1.38.38.1.1.1.2.2.2.2.2.3.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"></times><ci id="S3.E7.m1.28.28.28.28.28.28.cmml" xref="S3.E7.m1.28.28.28.28.28.28">𝑓</ci><interval closure="open" id="S3.E7.m1.38.38.1.1.1.2.2.2.2.2.2.3.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><apply id="S3.E7.m1.38.38.1.1.1.2.2.2.2.2.1.1.1.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><csymbol cd="ambiguous" id="S3.E7.m1.38.38.1.1.1.2.2.2.2.2.1.1.1.1.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3">subscript</csymbol><ci id="S3.E7.m1.30.30.30.30.30.30.cmml" xref="S3.E7.m1.30.30.30.30.30.30">𝜃</ci><ci id="S3.E7.m1.31.31.31.31.31.31.1.cmml" xref="S3.E7.m1.31.31.31.31.31.31.1">𝑛</ci></apply><apply id="S3.E7.m1.38.38.1.1.1.2.2.2.2.2.2.2.2.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3"><csymbol cd="ambiguous" id="S3.E7.m1.38.38.1.1.1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E7.m1.39.39.2.38.38.38.38.1.2.2.3">subscript</csymbol><ci id="S3.E7.m1.33.33.33.33.33.33.cmml" xref="S3.E7.m1.33.33.33.33.33.33">𝐷</ci><cn type="integer" id="S3.E7.m1.34.34.34.34.34.34.1.cmml" xref="S3.E7.m1.34.34.34.34.34.34.1">0</cn></apply></interval></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E7.m1.39c">\begin{split}{\theta_{n}}\leftarrow{\theta_{n}-\alpha{\nabla_{\theta}}\mathcal{L}_{kl}(\sum_{m=1}^{N}\mathcal{M}_{m}\cdot f(\theta_{m},D_{0}),f(\theta_{n},D_{0}))},\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(7)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS2.p4.8" class="ltx_p">where <math id="S3.SS2.SSS2.p4.5.m1.1" class="ltx_Math" alttext="D_{0}" display="inline"><semantics id="S3.SS2.SSS2.p4.5.m1.1a"><msub id="S3.SS2.SSS2.p4.5.m1.1.1" xref="S3.SS2.SSS2.p4.5.m1.1.1.cmml"><mi id="S3.SS2.SSS2.p4.5.m1.1.1.2" xref="S3.SS2.SSS2.p4.5.m1.1.1.2.cmml">D</mi><mn id="S3.SS2.SSS2.p4.5.m1.1.1.3" xref="S3.SS2.SSS2.p4.5.m1.1.1.3.cmml">0</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.5.m1.1b"><apply id="S3.SS2.SSS2.p4.5.m1.1.1.cmml" xref="S3.SS2.SSS2.p4.5.m1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p4.5.m1.1.1.1.cmml" xref="S3.SS2.SSS2.p4.5.m1.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p4.5.m1.1.1.2.cmml" xref="S3.SS2.SSS2.p4.5.m1.1.1.2">𝐷</ci><cn type="integer" id="S3.SS2.SSS2.p4.5.m1.1.1.3.cmml" xref="S3.SS2.SSS2.p4.5.m1.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.5.m1.1c">D_{0}</annotation></semantics></math> represents a mini-batch of the public dataset, <math id="S3.SS2.SSS2.p4.6.m2.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="S3.SS2.SSS2.p4.6.m2.1a"><mi id="S3.SS2.SSS2.p4.6.m2.1.1" xref="S3.SS2.SSS2.p4.6.m2.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.6.m2.1b"><ci id="S3.SS2.SSS2.p4.6.m2.1.1.cmml" xref="S3.SS2.SSS2.p4.6.m2.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.6.m2.1c">\alpha</annotation></semantics></math> is the learning rate, and <math id="S3.SS2.SSS2.p4.7.m3.1" class="ltx_Math" alttext="\mathcal{M}_{m}" display="inline"><semantics id="S3.SS2.SSS2.p4.7.m3.1a"><msub id="S3.SS2.SSS2.p4.7.m3.1.1" xref="S3.SS2.SSS2.p4.7.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS2.p4.7.m3.1.1.2" xref="S3.SS2.SSS2.p4.7.m3.1.1.2.cmml">ℳ</mi><mi id="S3.SS2.SSS2.p4.7.m3.1.1.3" xref="S3.SS2.SSS2.p4.7.m3.1.1.3.cmml">m</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.7.m3.1b"><apply id="S3.SS2.SSS2.p4.7.m3.1.1.cmml" xref="S3.SS2.SSS2.p4.7.m3.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS2.p4.7.m3.1.1.1.cmml" xref="S3.SS2.SSS2.p4.7.m3.1.1">subscript</csymbol><ci id="S3.SS2.SSS2.p4.7.m3.1.1.2.cmml" xref="S3.SS2.SSS2.p4.7.m3.1.1.2">ℳ</ci><ci id="S3.SS2.SSS2.p4.7.m3.1.1.3.cmml" xref="S3.SS2.SSS2.p4.7.m3.1.1.3">𝑚</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.7.m3.1c">\mathcal{M}_{m}</annotation></semantics></math> denotes the knowledge coefficient vector of client <math id="S3.SS2.SSS2.p4.8.m4.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S3.SS2.SSS2.p4.8.m4.1a"><mi id="S3.SS2.SSS2.p4.8.m4.1.1" xref="S3.SS2.SSS2.p4.8.m4.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS2.p4.8.m4.1b"><ci id="S3.SS2.SSS2.p4.8.m4.1.1.cmml" xref="S3.SS2.SSS2.p4.8.m4.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS2.p4.8.m4.1c">m</annotation></semantics></math>. Gao <span id="S3.SS2.SSS2.p4.8.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Gao et al<span class="ltx_text">.</span> (<a href="#bib.bib58" title="" class="ltx_ref">2019</a>)</cite> design a privacy-preserving transfer learning method to remove covariate shifts in homogeneous feature spaces and bridge heterogeneous feature spaces of different clients. Unlike the above methods that transfer the entire global model to the client, FedPer <cite class="ltx_cite ltx_citemacro_cite">Arivazhagan et al<span class="ltx_text">.</span> (<a href="#bib.bib7" title="" class="ltx_ref">2019</a>)</cite> trains the model base layers on the server side based on FedAvg, and then transfers the globally shared base layers to the client. The clients train the model personalization layers on local data with stochastic gradient descent, thereby mitigating the impact of statistical heterogeneity.</p>
</div>
<figure id="S3.F10" class="ltx_figure"><img src="/html/2307.10616/assets/x10.png" id="S3.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="320" height="200" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10. </span><span id="S3.F10.2.1" class="ltx_text" style="font-size:90%;">Illustration of the architecture sharing approaches in heterogeneous federated learning.</span></figcaption>
</figure>
</section>
<section id="S3.SS2.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.2.3. </span>Architecture Sharing</h4>

<div id="S3.SS2.SSS3.p1" class="ltx_para">
<p id="S3.SS2.SSS3.p1.1" class="ltx_p"><span id="S3.SS2.SSS3.p1.1.1" class="ltx_text ltx_font_bold">Backbone Sharing.</span>
In heterogeneous scenarios, the private datasets of clients may be Non-IID. To mitigate the negative effects caused by statistical heterogeneity, clients may share the backbone, but they design personalized layers in the neural network models for personalized demands (Fig. <a href="#S3.F10" title="Figure 10 ‣ 3.2.2. Knowledge Transfer across Models ‣ 3.2. Model-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>). Furthermore, the clients only need to upload the backbone to the server-side in the aggregation phase, thereby decreasing the communication cost to some extent.</p>
</div>
<div id="S3.SS2.SSS3.p2" class="ltx_para">
<p id="S3.SS2.SSS3.p2.1" class="ltx_p">For example, the aforementioned FedPer <cite class="ltx_cite ltx_citemacro_cite">Arivazhagan et al<span class="ltx_text">.</span> (<a href="#bib.bib7" title="" class="ltx_ref">2019</a>)</cite>, which combines the base layers and the personalized layers for federated training of deep feedforward neural networks, can effectively capture the personalization aspects of clients. Intuitively, FedPer first uses a FedAvg-based approach to globally train the base layers on the public dataset. Subsequently, each client updates the personalized layers with the private dataset using an SGD-style algorithm. The base layers consist of shallow neural networks for high-level feature extraction, and the personalized layers are deep neural networks for classification. This framework can avoid the problem of retraining in federated transfer learning. In the training process of federated representation learning (FedRep) <cite class="ltx_cite ltx_citemacro_cite">Collins et al<span class="ltx_text">.</span> (<a href="#bib.bib36" title="" class="ltx_ref">2021</a>)</cite>, all clients jointly train the global representation learning structure, and then use their private datasets to train their own client-special heads. Here the heads of clients represent personalized, low-dimensional classifiers. Classifier Calibration with Virtual Representations (CCVR) <cite class="ltx_cite ltx_citemacro_cite">Luo et al<span class="ltx_text">.</span> (<a href="#bib.bib140" title="" class="ltx_ref">2021</a>)</cite> generates approximate Gaussian mixture model (GMM) based virtual representations in feature space via learned feature extractors. To mitigate the problem that the classifier can be easily biased to the heterogeneous local data, CCVR eliminates the bias of the classifier by regularizing or calibrating the classifier weights. To further consider the problem of long-tail distribution, Classifier Re-training with Federated Features (CReFF) <cite class="ltx_cite ltx_citemacro_cite">Shang et al<span class="ltx_text">.</span> (<a href="#bib.bib185" title="" class="ltx_ref">2022</a>)</cite> learns federated features to re-train the classifier, which approximates training the classifier on real data.</p>
</div>
<div id="S3.SS2.SSS3.p3" class="ltx_para">
<p id="S3.SS2.SSS3.p3.1" class="ltx_p"><span id="S3.SS2.SSS3.p3.1.1" class="ltx_text ltx_font_bold">Classifier Sharing.</span>
To handle heterogeneous data and tasks, several methods share a classifier instead of a backbone (Fig. <a href="#S3.F10" title="Figure 10 ‣ 3.2.2. Knowledge Transfer across Models ‣ 3.2. Model-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>). Intuitively, the clients perform feature extraction through their own backbones and share a public classifier for classification. In this way, clients can learn from each other while satisfying personalization and without compromising their data privacy or task specificity.</p>
</div>
<div id="S3.SS2.SSS3.p4" class="ltx_para">
<p id="S3.SS2.SSS3.p4.8" class="ltx_p">The recently devised LG-FedAvg <cite class="ltx_cite ltx_citemacro_cite">Liang et al<span class="ltx_text">.</span> (<a href="#bib.bib129" title="" class="ltx_ref">2020</a>)</cite> jointly learns compact local representations on all clients and a global model across all clients. In contrast to FedPer, LG-FedAvg uses personalized layers to extract high-level, compact features that are important for prediction and uses the base layers shared by the server for classification. In LG-FedAvg, the client <math id="S3.SS2.SSS3.p4.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.SSS3.p4.1.m1.1a"><mi id="S3.SS2.SSS3.p4.1.m1.1.1" xref="S3.SS2.SSS3.p4.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.1.m1.1b"><ci id="S3.SS2.SSS3.p4.1.m1.1.1.cmml" xref="S3.SS2.SSS3.p4.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.1.m1.1c">k</annotation></semantics></math> possesses a private dataset <math id="S3.SS2.SSS3.p4.2.m2.4" class="ltx_Math" alttext="\{(x,y)|x\in X_{k},y\in Y_{k}\}" display="inline"><semantics id="S3.SS2.SSS3.p4.2.m2.4a"><mrow id="S3.SS2.SSS3.p4.2.m2.4.4.2" xref="S3.SS2.SSS3.p4.2.m2.4.4.3.cmml"><mo stretchy="false" id="S3.SS2.SSS3.p4.2.m2.4.4.2.3" xref="S3.SS2.SSS3.p4.2.m2.4.4.3.1.cmml">{</mo><mrow id="S3.SS2.SSS3.p4.2.m2.3.3.1.1.2" xref="S3.SS2.SSS3.p4.2.m2.3.3.1.1.1.cmml"><mo stretchy="false" id="S3.SS2.SSS3.p4.2.m2.3.3.1.1.2.1" xref="S3.SS2.SSS3.p4.2.m2.3.3.1.1.1.cmml">(</mo><mi id="S3.SS2.SSS3.p4.2.m2.1.1" xref="S3.SS2.SSS3.p4.2.m2.1.1.cmml">x</mi><mo id="S3.SS2.SSS3.p4.2.m2.3.3.1.1.2.2" xref="S3.SS2.SSS3.p4.2.m2.3.3.1.1.1.cmml">,</mo><mi id="S3.SS2.SSS3.p4.2.m2.2.2" xref="S3.SS2.SSS3.p4.2.m2.2.2.cmml">y</mi><mo stretchy="false" id="S3.SS2.SSS3.p4.2.m2.3.3.1.1.2.3" xref="S3.SS2.SSS3.p4.2.m2.3.3.1.1.1.cmml">)</mo></mrow><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.2.m2.4.4.2.4" xref="S3.SS2.SSS3.p4.2.m2.4.4.3.1.cmml">|</mo><mrow id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.3.cmml"><mrow id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.cmml"><mi id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.2" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.2.cmml">x</mi><mo id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.1" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.1.cmml">∈</mo><msub id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.3" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.3.cmml"><mi id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.3.2" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.3.2.cmml">X</mi><mi id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.3.3" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.3.3.cmml">k</mi></msub></mrow><mo id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.3" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.3a.cmml">,</mo><mrow id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.cmml"><mi id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.2" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.2.cmml">y</mi><mo id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.1" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.1.cmml">∈</mo><msub id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.3" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.3.cmml"><mi id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.3.2" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.3.2.cmml">Y</mi><mi id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.3.3" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.3.3.cmml">k</mi></msub></mrow></mrow><mo stretchy="false" id="S3.SS2.SSS3.p4.2.m2.4.4.2.5" xref="S3.SS2.SSS3.p4.2.m2.4.4.3.1.cmml">}</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.2.m2.4b"><apply id="S3.SS2.SSS3.p4.2.m2.4.4.3.cmml" xref="S3.SS2.SSS3.p4.2.m2.4.4.2"><csymbol cd="latexml" id="S3.SS2.SSS3.p4.2.m2.4.4.3.1.cmml" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.3">conditional-set</csymbol><interval closure="open" id="S3.SS2.SSS3.p4.2.m2.3.3.1.1.1.cmml" xref="S3.SS2.SSS3.p4.2.m2.3.3.1.1.2"><ci id="S3.SS2.SSS3.p4.2.m2.1.1.cmml" xref="S3.SS2.SSS3.p4.2.m2.1.1">𝑥</ci><ci id="S3.SS2.SSS3.p4.2.m2.2.2.cmml" xref="S3.SS2.SSS3.p4.2.m2.2.2">𝑦</ci></interval><apply id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.3.cmml" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.3a.cmml" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.3">formulae-sequence</csymbol><apply id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.cmml" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1"><in id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.1.cmml" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.1"></in><ci id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.2.cmml" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.2">𝑥</ci><apply id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.3.cmml" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.3.1.cmml" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.3.2.cmml" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.3.2">𝑋</ci><ci id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.3.3.cmml" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.1.1.3.3">𝑘</ci></apply></apply><apply id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.cmml" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2"><in id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.1.cmml" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.1"></in><ci id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.2.cmml" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.2">𝑦</ci><apply id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.3.cmml" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.3.1.cmml" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.3">subscript</csymbol><ci id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.3.2.cmml" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.3.2">𝑌</ci><ci id="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.3.3.cmml" xref="S3.SS2.SSS3.p4.2.m2.4.4.2.2.2.2.3.3">𝑘</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.2.m2.4c">\{(x,y)|x\in X_{k},y\in Y_{k}\}</annotation></semantics></math>. Furthermore, the client <math id="S3.SS2.SSS3.p4.3.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.SSS3.p4.3.m3.1a"><mi id="S3.SS2.SSS3.p4.3.m3.1.1" xref="S3.SS2.SSS3.p4.3.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.3.m3.1b"><ci id="S3.SS2.SSS3.p4.3.m3.1.1.cmml" xref="S3.SS2.SSS3.p4.3.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.3.m3.1c">k</annotation></semantics></math> extracts the feature <math id="S3.SS2.SSS3.p4.4.m4.2" class="ltx_Math" alttext="\mathcal{F}_{k}=l_{k}(X_{k},\theta_{k}^{l})" display="inline"><semantics id="S3.SS2.SSS3.p4.4.m4.2a"><mrow id="S3.SS2.SSS3.p4.4.m4.2.2" xref="S3.SS2.SSS3.p4.4.m4.2.2.cmml"><msub id="S3.SS2.SSS3.p4.4.m4.2.2.4" xref="S3.SS2.SSS3.p4.4.m4.2.2.4.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS3.p4.4.m4.2.2.4.2" xref="S3.SS2.SSS3.p4.4.m4.2.2.4.2.cmml">ℱ</mi><mi id="S3.SS2.SSS3.p4.4.m4.2.2.4.3" xref="S3.SS2.SSS3.p4.4.m4.2.2.4.3.cmml">k</mi></msub><mo id="S3.SS2.SSS3.p4.4.m4.2.2.3" xref="S3.SS2.SSS3.p4.4.m4.2.2.3.cmml">=</mo><mrow id="S3.SS2.SSS3.p4.4.m4.2.2.2" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.cmml"><msub id="S3.SS2.SSS3.p4.4.m4.2.2.2.4" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.4.cmml"><mi id="S3.SS2.SSS3.p4.4.m4.2.2.2.4.2" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.4.2.cmml">l</mi><mi id="S3.SS2.SSS3.p4.4.m4.2.2.2.4.3" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.4.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S3.SS2.SSS3.p4.4.m4.2.2.2.3" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.3.cmml">​</mo><mrow id="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.3" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.2.3.cmml">(</mo><msub id="S3.SS2.SSS3.p4.4.m4.1.1.1.1.1.1" xref="S3.SS2.SSS3.p4.4.m4.1.1.1.1.1.1.cmml"><mi id="S3.SS2.SSS3.p4.4.m4.1.1.1.1.1.1.2" xref="S3.SS2.SSS3.p4.4.m4.1.1.1.1.1.1.2.cmml">X</mi><mi id="S3.SS2.SSS3.p4.4.m4.1.1.1.1.1.1.3" xref="S3.SS2.SSS3.p4.4.m4.1.1.1.1.1.1.3.cmml">k</mi></msub><mo id="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.4" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.2.3.cmml">,</mo><msubsup id="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2.cmml"><mi id="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2.2.2" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2.2.2.cmml">θ</mi><mi id="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2.2.3" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2.2.3.cmml">k</mi><mi id="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2.3" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2.3.cmml">l</mi></msubsup><mo stretchy="false" id="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.5" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.4.m4.2b"><apply id="S3.SS2.SSS3.p4.4.m4.2.2.cmml" xref="S3.SS2.SSS3.p4.4.m4.2.2"><eq id="S3.SS2.SSS3.p4.4.m4.2.2.3.cmml" xref="S3.SS2.SSS3.p4.4.m4.2.2.3"></eq><apply id="S3.SS2.SSS3.p4.4.m4.2.2.4.cmml" xref="S3.SS2.SSS3.p4.4.m4.2.2.4"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.4.m4.2.2.4.1.cmml" xref="S3.SS2.SSS3.p4.4.m4.2.2.4">subscript</csymbol><ci id="S3.SS2.SSS3.p4.4.m4.2.2.4.2.cmml" xref="S3.SS2.SSS3.p4.4.m4.2.2.4.2">ℱ</ci><ci id="S3.SS2.SSS3.p4.4.m4.2.2.4.3.cmml" xref="S3.SS2.SSS3.p4.4.m4.2.2.4.3">𝑘</ci></apply><apply id="S3.SS2.SSS3.p4.4.m4.2.2.2.cmml" xref="S3.SS2.SSS3.p4.4.m4.2.2.2"><times id="S3.SS2.SSS3.p4.4.m4.2.2.2.3.cmml" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.3"></times><apply id="S3.SS2.SSS3.p4.4.m4.2.2.2.4.cmml" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.4"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.4.m4.2.2.2.4.1.cmml" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.4">subscript</csymbol><ci id="S3.SS2.SSS3.p4.4.m4.2.2.2.4.2.cmml" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.4.2">𝑙</ci><ci id="S3.SS2.SSS3.p4.4.m4.2.2.2.4.3.cmml" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.4.3">𝑘</ci></apply><interval closure="open" id="S3.SS2.SSS3.p4.4.m4.2.2.2.2.3.cmml" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2"><apply id="S3.SS2.SSS3.p4.4.m4.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS3.p4.4.m4.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.4.m4.1.1.1.1.1.1.1.cmml" xref="S3.SS2.SSS3.p4.4.m4.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p4.4.m4.1.1.1.1.1.1.2.cmml" xref="S3.SS2.SSS3.p4.4.m4.1.1.1.1.1.1.2">𝑋</ci><ci id="S3.SS2.SSS3.p4.4.m4.1.1.1.1.1.1.3.cmml" xref="S3.SS2.SSS3.p4.4.m4.1.1.1.1.1.1.3">𝑘</ci></apply><apply id="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2.cmml" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2.1.cmml" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2">superscript</csymbol><apply id="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2.2.cmml" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2.2.1.cmml" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2">subscript</csymbol><ci id="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2.2.2.cmml" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2.2.2">𝜃</ci><ci id="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2.2.3.cmml" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2.2.3">𝑘</ci></apply><ci id="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2.3.cmml" xref="S3.SS2.SSS3.p4.4.m4.2.2.2.2.2.2.3">𝑙</ci></apply></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.4.m4.2c">\mathcal{F}_{k}=l_{k}(X_{k},\theta_{k}^{l})</annotation></semantics></math> of the private data samples through the local model <math id="S3.SS2.SSS3.p4.5.m5.1" class="ltx_Math" alttext="\theta_{k}^{l}" display="inline"><semantics id="S3.SS2.SSS3.p4.5.m5.1a"><msubsup id="S3.SS2.SSS3.p4.5.m5.1.1" xref="S3.SS2.SSS3.p4.5.m5.1.1.cmml"><mi id="S3.SS2.SSS3.p4.5.m5.1.1.2.2" xref="S3.SS2.SSS3.p4.5.m5.1.1.2.2.cmml">θ</mi><mi id="S3.SS2.SSS3.p4.5.m5.1.1.2.3" xref="S3.SS2.SSS3.p4.5.m5.1.1.2.3.cmml">k</mi><mi id="S3.SS2.SSS3.p4.5.m5.1.1.3" xref="S3.SS2.SSS3.p4.5.m5.1.1.3.cmml">l</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.5.m5.1b"><apply id="S3.SS2.SSS3.p4.5.m5.1.1.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.5.m5.1.1.1.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1">superscript</csymbol><apply id="S3.SS2.SSS3.p4.5.m5.1.1.2.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.5.m5.1.1.2.1.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p4.5.m5.1.1.2.2.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1.2.2">𝜃</ci><ci id="S3.SS2.SSS3.p4.5.m5.1.1.2.3.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1.2.3">𝑘</ci></apply><ci id="S3.SS2.SSS3.p4.5.m5.1.1.3.cmml" xref="S3.SS2.SSS3.p4.5.m5.1.1.3">𝑙</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.5.m5.1c">\theta_{k}^{l}</annotation></semantics></math>. These features <math id="S3.SS2.SSS3.p4.6.m6.1" class="ltx_Math" alttext="f\in\mathcal{F}_{k}" display="inline"><semantics id="S3.SS2.SSS3.p4.6.m6.1a"><mrow id="S3.SS2.SSS3.p4.6.m6.1.1" xref="S3.SS2.SSS3.p4.6.m6.1.1.cmml"><mi id="S3.SS2.SSS3.p4.6.m6.1.1.2" xref="S3.SS2.SSS3.p4.6.m6.1.1.2.cmml">f</mi><mo id="S3.SS2.SSS3.p4.6.m6.1.1.1" xref="S3.SS2.SSS3.p4.6.m6.1.1.1.cmml">∈</mo><msub id="S3.SS2.SSS3.p4.6.m6.1.1.3" xref="S3.SS2.SSS3.p4.6.m6.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.SSS3.p4.6.m6.1.1.3.2" xref="S3.SS2.SSS3.p4.6.m6.1.1.3.2.cmml">ℱ</mi><mi id="S3.SS2.SSS3.p4.6.m6.1.1.3.3" xref="S3.SS2.SSS3.p4.6.m6.1.1.3.3.cmml">k</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.6.m6.1b"><apply id="S3.SS2.SSS3.p4.6.m6.1.1.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1"><in id="S3.SS2.SSS3.p4.6.m6.1.1.1.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1.1"></in><ci id="S3.SS2.SSS3.p4.6.m6.1.1.2.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1.2">𝑓</ci><apply id="S3.SS2.SSS3.p4.6.m6.1.1.3.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1.3"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.6.m6.1.1.3.1.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1.3">subscript</csymbol><ci id="S3.SS2.SSS3.p4.6.m6.1.1.3.2.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1.3.2">ℱ</ci><ci id="S3.SS2.SSS3.p4.6.m6.1.1.3.3.cmml" xref="S3.SS2.SSS3.p4.6.m6.1.1.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.6.m6.1c">f\in\mathcal{F}_{k}</annotation></semantics></math> are predicted by the global model <math id="S3.SS2.SSS3.p4.7.m7.1" class="ltx_Math" alttext="\theta_{k}^{g}" display="inline"><semantics id="S3.SS2.SSS3.p4.7.m7.1a"><msubsup id="S3.SS2.SSS3.p4.7.m7.1.1" xref="S3.SS2.SSS3.p4.7.m7.1.1.cmml"><mi id="S3.SS2.SSS3.p4.7.m7.1.1.2.2" xref="S3.SS2.SSS3.p4.7.m7.1.1.2.2.cmml">θ</mi><mi id="S3.SS2.SSS3.p4.7.m7.1.1.2.3" xref="S3.SS2.SSS3.p4.7.m7.1.1.2.3.cmml">k</mi><mi id="S3.SS2.SSS3.p4.7.m7.1.1.3" xref="S3.SS2.SSS3.p4.7.m7.1.1.3.cmml">g</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.7.m7.1b"><apply id="S3.SS2.SSS3.p4.7.m7.1.1.cmml" xref="S3.SS2.SSS3.p4.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.7.m7.1.1.1.cmml" xref="S3.SS2.SSS3.p4.7.m7.1.1">superscript</csymbol><apply id="S3.SS2.SSS3.p4.7.m7.1.1.2.cmml" xref="S3.SS2.SSS3.p4.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS2.SSS3.p4.7.m7.1.1.2.1.cmml" xref="S3.SS2.SSS3.p4.7.m7.1.1">subscript</csymbol><ci id="S3.SS2.SSS3.p4.7.m7.1.1.2.2.cmml" xref="S3.SS2.SSS3.p4.7.m7.1.1.2.2">𝜃</ci><ci id="S3.SS2.SSS3.p4.7.m7.1.1.2.3.cmml" xref="S3.SS2.SSS3.p4.7.m7.1.1.2.3">𝑘</ci></apply><ci id="S3.SS2.SSS3.p4.7.m7.1.1.3.cmml" xref="S3.SS2.SSS3.p4.7.m7.1.1.3">𝑔</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.7.m7.1c">\theta_{k}^{g}</annotation></semantics></math>. The overall loss on the client <math id="S3.SS2.SSS3.p4.8.m8.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS2.SSS3.p4.8.m8.1a"><mi id="S3.SS2.SSS3.p4.8.m8.1.1" xref="S3.SS2.SSS3.p4.8.m8.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.SSS3.p4.8.m8.1b"><ci id="S3.SS2.SSS3.p4.8.m8.1.1.cmml" xref="S3.SS2.SSS3.p4.8.m8.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.SSS3.p4.8.m8.1c">k</annotation></semantics></math> can be expressed as:</p>
<table id="S3.E8" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E8.m1.39" class="ltx_Math" alttext="\begin{split}\mathcal{L}_{k}(\theta_{k}^{l},\theta_{k}^{g})=\mathbb{E}[-\log\sum_{f}(p_{\theta_{k}^{g}}(y|f),p_{\theta_{k}^{l}}(f|x))],\end{split}" display="block"><semantics id="S3.E8.m1.39a"><mtable displaystyle="true" id="S3.E8.m1.39.39.2"><mtr id="S3.E8.m1.39.39.2a"><mtd class="ltx_align_right" columnalign="right" id="S3.E8.m1.39.39.2b"><mrow id="S3.E8.m1.39.39.2.38.38.38.38"><mrow id="S3.E8.m1.39.39.2.38.38.38.38.1"><mrow id="S3.E8.m1.39.39.2.38.38.38.38.1.2"><msub id="S3.E8.m1.39.39.2.38.38.38.38.1.2.4"><mi class="ltx_font_mathcaligraphic" id="S3.E8.m1.1.1.1.1.1.1" xref="S3.E8.m1.1.1.1.1.1.1.cmml">ℒ</mi><mi id="S3.E8.m1.2.2.2.2.2.2.1" xref="S3.E8.m1.2.2.2.2.2.2.1.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S3.E8.m1.39.39.2.38.38.38.38.1.2.3" xref="S3.E8.m1.38.38.1.1.1.cmml">​</mo><mrow id="S3.E8.m1.39.39.2.38.38.38.38.1.2.2.2"><mo stretchy="false" id="S3.E8.m1.3.3.3.3.3.3" xref="S3.E8.m1.38.38.1.1.1.cmml">(</mo><msubsup id="S3.E8.m1.39.39.2.38.38.38.38.1.1.1.1.1"><mi id="S3.E8.m1.4.4.4.4.4.4" xref="S3.E8.m1.4.4.4.4.4.4.cmml">θ</mi><mi id="S3.E8.m1.5.5.5.5.5.5.1" xref="S3.E8.m1.5.5.5.5.5.5.1.cmml">k</mi><mi id="S3.E8.m1.6.6.6.6.6.6.1" xref="S3.E8.m1.6.6.6.6.6.6.1.cmml">l</mi></msubsup><mo id="S3.E8.m1.7.7.7.7.7.7" xref="S3.E8.m1.38.38.1.1.1.cmml">,</mo><msubsup id="S3.E8.m1.39.39.2.38.38.38.38.1.2.2.2.2"><mi id="S3.E8.m1.8.8.8.8.8.8" xref="S3.E8.m1.8.8.8.8.8.8.cmml">θ</mi><mi id="S3.E8.m1.9.9.9.9.9.9.1" xref="S3.E8.m1.9.9.9.9.9.9.1.cmml">k</mi><mi id="S3.E8.m1.10.10.10.10.10.10.1" xref="S3.E8.m1.10.10.10.10.10.10.1.cmml">g</mi></msubsup><mo stretchy="false" id="S3.E8.m1.11.11.11.11.11.11" xref="S3.E8.m1.38.38.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E8.m1.12.12.12.12.12.12" xref="S3.E8.m1.12.12.12.12.12.12.cmml">=</mo><mrow id="S3.E8.m1.39.39.2.38.38.38.38.1.3"><mi id="S3.E8.m1.13.13.13.13.13.13" xref="S3.E8.m1.13.13.13.13.13.13.cmml">𝔼</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.39.39.2.38.38.38.38.1.3.2" xref="S3.E8.m1.38.38.1.1.1.cmml">​</mo><mrow id="S3.E8.m1.39.39.2.38.38.38.38.1.3.1.1"><mo stretchy="false" id="S3.E8.m1.14.14.14.14.14.14" xref="S3.E8.m1.38.38.1.1.1.cmml">[</mo><mrow id="S3.E8.m1.39.39.2.38.38.38.38.1.3.1.1.1"><mo rspace="0.167em" id="S3.E8.m1.39.39.2.38.38.38.38.1.3.1.1.1a" xref="S3.E8.m1.38.38.1.1.1.cmml">−</mo><mrow id="S3.E8.m1.39.39.2.38.38.38.38.1.3.1.1.1.2"><mi id="S3.E8.m1.16.16.16.16.16.16" xref="S3.E8.m1.16.16.16.16.16.16.cmml">log</mi><mo lspace="0em" rspace="0em" id="S3.E8.m1.39.39.2.38.38.38.38.1.3.1.1.1.2.3" xref="S3.E8.m1.38.38.1.1.1.cmml">​</mo><mrow id="S3.E8.m1.39.39.2.38.38.38.38.1.3.1.1.1.2.2"><munder id="S3.E8.m1.39.39.2.38.38.38.38.1.3.1.1.1.2.2.3"><mo movablelimits="false" rspace="0em" id="S3.E8.m1.17.17.17.17.17.17" xref="S3.E8.m1.17.17.17.17.17.17.cmml">∑</mo><mi id="S3.E8.m1.18.18.18.18.18.18.1" xref="S3.E8.m1.18.18.18.18.18.18.1.cmml">f</mi></munder><mrow id="S3.E8.m1.39.39.2.38.38.38.38.1.3.1.1.1.2.2.2.2"><mo stretchy="false" id="S3.E8.m1.19.19.19.19.19.19" xref="S3.E8.m1.38.38.1.1.1.cmml">(</mo><mrow id="S3.E8.m1.39.39.2.38.38.38.38.1.3.1.1.1.1.1.1.1.1"><msub id="S3.E8.m1.39.39.2.38.38.38.38.1.3.1.1.1.1.1.1.1.1.3"><mi id="S3.E8.m1.20.20.20.20.20.20" xref="S3.E8.m1.20.20.20.20.20.20.cmml">p</mi><msubsup id="S3.E8.m1.21.21.21.21.21.21.1" xref="S3.E8.m1.21.21.21.21.21.21.1.cmml"><mi id="S3.E8.m1.21.21.21.21.21.21.1.2.2" xref="S3.E8.m1.21.21.21.21.21.21.1.2.2.cmml">θ</mi><mi id="S3.E8.m1.21.21.21.21.21.21.1.2.3" xref="S3.E8.m1.21.21.21.21.21.21.1.2.3.cmml">k</mi><mi id="S3.E8.m1.21.21.21.21.21.21.1.3" xref="S3.E8.m1.21.21.21.21.21.21.1.3.cmml">g</mi></msubsup></msub><mo lspace="0em" rspace="0em" id="S3.E8.m1.39.39.2.38.38.38.38.1.3.1.1.1.1.1.1.1.1.2" xref="S3.E8.m1.38.38.1.1.1.cmml">​</mo><mrow id="S3.E8.m1.39.39.2.38.38.38.38.1.3.1.1.1.1.1.1.1.1.1.1"><mo stretchy="false" id="S3.E8.m1.22.22.22.22.22.22" xref="S3.E8.m1.38.38.1.1.1.cmml">(</mo><mrow id="S3.E8.m1.39.39.2.38.38.38.38.1.3.1.1.1.1.1.1.1.1.1.1.1"><mi id="S3.E8.m1.23.23.23.23.23.23" xref="S3.E8.m1.23.23.23.23.23.23.cmml">y</mi><mo fence="false" id="S3.E8.m1.24.24.24.24.24.24" xref="S3.E8.m1.24.24.24.24.24.24.cmml">|</mo><mi id="S3.E8.m1.25.25.25.25.25.25" xref="S3.E8.m1.25.25.25.25.25.25.cmml">f</mi></mrow><mo stretchy="false" id="S3.E8.m1.26.26.26.26.26.26" xref="S3.E8.m1.38.38.1.1.1.cmml">)</mo></mrow></mrow><mo id="S3.E8.m1.27.27.27.27.27.27" xref="S3.E8.m1.38.38.1.1.1.cmml">,</mo><mrow id="S3.E8.m1.39.39.2.38.38.38.38.1.3.1.1.1.2.2.2.2.2"><msub id="S3.E8.m1.39.39.2.38.38.38.38.1.3.1.1.1.2.2.2.2.2.3"><mi id="S3.E8.m1.28.28.28.28.28.28" xref="S3.E8.m1.28.28.28.28.28.28.cmml">p</mi><msubsup id="S3.E8.m1.29.29.29.29.29.29.1" xref="S3.E8.m1.29.29.29.29.29.29.1.cmml"><mi id="S3.E8.m1.29.29.29.29.29.29.1.2.2" xref="S3.E8.m1.29.29.29.29.29.29.1.2.2.cmml">θ</mi><mi id="S3.E8.m1.29.29.29.29.29.29.1.2.3" xref="S3.E8.m1.29.29.29.29.29.29.1.2.3.cmml">k</mi><mi id="S3.E8.m1.29.29.29.29.29.29.1.3" xref="S3.E8.m1.29.29.29.29.29.29.1.3.cmml">l</mi></msubsup></msub><mo lspace="0em" rspace="0em" id="S3.E8.m1.39.39.2.38.38.38.38.1.3.1.1.1.2.2.2.2.2.2" xref="S3.E8.m1.38.38.1.1.1.cmml">​</mo><mrow id="S3.E8.m1.39.39.2.38.38.38.38.1.3.1.1.1.2.2.2.2.2.1.1"><mo stretchy="false" id="S3.E8.m1.30.30.30.30.30.30" xref="S3.E8.m1.38.38.1.1.1.cmml">(</mo><mrow id="S3.E8.m1.39.39.2.38.38.38.38.1.3.1.1.1.2.2.2.2.2.1.1.1"><mi id="S3.E8.m1.31.31.31.31.31.31" xref="S3.E8.m1.31.31.31.31.31.31.cmml">f</mi><mo fence="false" id="S3.E8.m1.32.32.32.32.32.32" xref="S3.E8.m1.32.32.32.32.32.32.cmml">|</mo><mi id="S3.E8.m1.33.33.33.33.33.33" xref="S3.E8.m1.33.33.33.33.33.33.cmml">x</mi></mrow><mo stretchy="false" id="S3.E8.m1.34.34.34.34.34.34" xref="S3.E8.m1.38.38.1.1.1.cmml">)</mo></mrow></mrow><mo stretchy="false" id="S3.E8.m1.35.35.35.35.35.35" xref="S3.E8.m1.38.38.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><mo stretchy="false" id="S3.E8.m1.36.36.36.36.36.36" xref="S3.E8.m1.38.38.1.1.1.cmml">]</mo></mrow></mrow></mrow><mo id="S3.E8.m1.37.37.37.37.37.37" xref="S3.E8.m1.38.38.1.1.1.cmml">,</mo></mrow></mtd></mtr></mtable><annotation-xml encoding="MathML-Content" id="S3.E8.m1.39b"><apply id="S3.E8.m1.38.38.1.1.1.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"><eq id="S3.E8.m1.12.12.12.12.12.12.cmml" xref="S3.E8.m1.12.12.12.12.12.12"></eq><apply id="S3.E8.m1.38.38.1.1.1.2.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"><times id="S3.E8.m1.38.38.1.1.1.2.3.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"></times><apply id="S3.E8.m1.38.38.1.1.1.2.4.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"><csymbol cd="ambiguous" id="S3.E8.m1.38.38.1.1.1.2.4.1.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3">subscript</csymbol><ci id="S3.E8.m1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.1.1.1.1.1.1">ℒ</ci><ci id="S3.E8.m1.2.2.2.2.2.2.1.cmml" xref="S3.E8.m1.2.2.2.2.2.2.1">𝑘</ci></apply><interval closure="open" id="S3.E8.m1.38.38.1.1.1.2.2.3.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"><apply id="S3.E8.m1.38.38.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"><csymbol cd="ambiguous" id="S3.E8.m1.38.38.1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3">superscript</csymbol><apply id="S3.E8.m1.38.38.1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"><csymbol cd="ambiguous" id="S3.E8.m1.38.38.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3">subscript</csymbol><ci id="S3.E8.m1.4.4.4.4.4.4.cmml" xref="S3.E8.m1.4.4.4.4.4.4">𝜃</ci><ci id="S3.E8.m1.5.5.5.5.5.5.1.cmml" xref="S3.E8.m1.5.5.5.5.5.5.1">𝑘</ci></apply><ci id="S3.E8.m1.6.6.6.6.6.6.1.cmml" xref="S3.E8.m1.6.6.6.6.6.6.1">𝑙</ci></apply><apply id="S3.E8.m1.38.38.1.1.1.2.2.2.2.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"><csymbol cd="ambiguous" id="S3.E8.m1.38.38.1.1.1.2.2.2.2.1.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3">superscript</csymbol><apply id="S3.E8.m1.38.38.1.1.1.2.2.2.2.2.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"><csymbol cd="ambiguous" id="S3.E8.m1.38.38.1.1.1.2.2.2.2.2.1.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3">subscript</csymbol><ci id="S3.E8.m1.8.8.8.8.8.8.cmml" xref="S3.E8.m1.8.8.8.8.8.8">𝜃</ci><ci id="S3.E8.m1.9.9.9.9.9.9.1.cmml" xref="S3.E8.m1.9.9.9.9.9.9.1">𝑘</ci></apply><ci id="S3.E8.m1.10.10.10.10.10.10.1.cmml" xref="S3.E8.m1.10.10.10.10.10.10.1">𝑔</ci></apply></interval></apply><apply id="S3.E8.m1.38.38.1.1.1.3.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"><times id="S3.E8.m1.38.38.1.1.1.3.2.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"></times><ci id="S3.E8.m1.13.13.13.13.13.13.cmml" xref="S3.E8.m1.13.13.13.13.13.13">𝔼</ci><apply id="S3.E8.m1.38.38.1.1.1.3.1.2.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"><csymbol cd="latexml" id="S3.E8.m1.38.38.1.1.1.3.1.2.1.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3">delimited-[]</csymbol><apply id="S3.E8.m1.38.38.1.1.1.3.1.1.1.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"><minus id="S3.E8.m1.15.15.15.15.15.15.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"></minus><apply id="S3.E8.m1.38.38.1.1.1.3.1.1.1.2.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"><times id="S3.E8.m1.38.38.1.1.1.3.1.1.1.2.3.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"></times><log id="S3.E8.m1.16.16.16.16.16.16.cmml" xref="S3.E8.m1.16.16.16.16.16.16"></log><apply id="S3.E8.m1.38.38.1.1.1.3.1.1.1.2.2.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"><apply id="S3.E8.m1.38.38.1.1.1.3.1.1.1.2.2.3.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"><csymbol cd="ambiguous" id="S3.E8.m1.38.38.1.1.1.3.1.1.1.2.2.3.1.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3">subscript</csymbol><sum id="S3.E8.m1.17.17.17.17.17.17.cmml" xref="S3.E8.m1.17.17.17.17.17.17"></sum><ci id="S3.E8.m1.18.18.18.18.18.18.1.cmml" xref="S3.E8.m1.18.18.18.18.18.18.1">𝑓</ci></apply><interval closure="open" id="S3.E8.m1.38.38.1.1.1.3.1.1.1.2.2.2.3.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"><apply id="S3.E8.m1.38.38.1.1.1.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"><times id="S3.E8.m1.38.38.1.1.1.3.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"></times><apply id="S3.E8.m1.38.38.1.1.1.3.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"><csymbol cd="ambiguous" id="S3.E8.m1.38.38.1.1.1.3.1.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3">subscript</csymbol><ci id="S3.E8.m1.20.20.20.20.20.20.cmml" xref="S3.E8.m1.20.20.20.20.20.20">𝑝</ci><apply id="S3.E8.m1.21.21.21.21.21.21.1.cmml" xref="S3.E8.m1.21.21.21.21.21.21.1"><csymbol cd="ambiguous" id="S3.E8.m1.21.21.21.21.21.21.1.1.cmml" xref="S3.E8.m1.21.21.21.21.21.21.1">superscript</csymbol><apply id="S3.E8.m1.21.21.21.21.21.21.1.2.cmml" xref="S3.E8.m1.21.21.21.21.21.21.1"><csymbol cd="ambiguous" id="S3.E8.m1.21.21.21.21.21.21.1.2.1.cmml" xref="S3.E8.m1.21.21.21.21.21.21.1">subscript</csymbol><ci id="S3.E8.m1.21.21.21.21.21.21.1.2.2.cmml" xref="S3.E8.m1.21.21.21.21.21.21.1.2.2">𝜃</ci><ci id="S3.E8.m1.21.21.21.21.21.21.1.2.3.cmml" xref="S3.E8.m1.21.21.21.21.21.21.1.2.3">𝑘</ci></apply><ci id="S3.E8.m1.21.21.21.21.21.21.1.3.cmml" xref="S3.E8.m1.21.21.21.21.21.21.1.3">𝑔</ci></apply></apply><apply id="S3.E8.m1.38.38.1.1.1.3.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"><csymbol cd="latexml" id="S3.E8.m1.24.24.24.24.24.24.cmml" xref="S3.E8.m1.24.24.24.24.24.24">conditional</csymbol><ci id="S3.E8.m1.23.23.23.23.23.23.cmml" xref="S3.E8.m1.23.23.23.23.23.23">𝑦</ci><ci id="S3.E8.m1.25.25.25.25.25.25.cmml" xref="S3.E8.m1.25.25.25.25.25.25">𝑓</ci></apply></apply><apply id="S3.E8.m1.38.38.1.1.1.3.1.1.1.2.2.2.2.2.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"><times id="S3.E8.m1.38.38.1.1.1.3.1.1.1.2.2.2.2.2.2.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"></times><apply id="S3.E8.m1.38.38.1.1.1.3.1.1.1.2.2.2.2.2.3.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"><csymbol cd="ambiguous" id="S3.E8.m1.38.38.1.1.1.3.1.1.1.2.2.2.2.2.3.1.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3">subscript</csymbol><ci id="S3.E8.m1.28.28.28.28.28.28.cmml" xref="S3.E8.m1.28.28.28.28.28.28">𝑝</ci><apply id="S3.E8.m1.29.29.29.29.29.29.1.cmml" xref="S3.E8.m1.29.29.29.29.29.29.1"><csymbol cd="ambiguous" id="S3.E8.m1.29.29.29.29.29.29.1.1.cmml" xref="S3.E8.m1.29.29.29.29.29.29.1">superscript</csymbol><apply id="S3.E8.m1.29.29.29.29.29.29.1.2.cmml" xref="S3.E8.m1.29.29.29.29.29.29.1"><csymbol cd="ambiguous" id="S3.E8.m1.29.29.29.29.29.29.1.2.1.cmml" xref="S3.E8.m1.29.29.29.29.29.29.1">subscript</csymbol><ci id="S3.E8.m1.29.29.29.29.29.29.1.2.2.cmml" xref="S3.E8.m1.29.29.29.29.29.29.1.2.2">𝜃</ci><ci id="S3.E8.m1.29.29.29.29.29.29.1.2.3.cmml" xref="S3.E8.m1.29.29.29.29.29.29.1.2.3">𝑘</ci></apply><ci id="S3.E8.m1.29.29.29.29.29.29.1.3.cmml" xref="S3.E8.m1.29.29.29.29.29.29.1.3">𝑙</ci></apply></apply><apply id="S3.E8.m1.38.38.1.1.1.3.1.1.1.2.2.2.2.2.1.1.1.cmml" xref="S3.E8.m1.39.39.2.38.38.38.38.1.2.3"><csymbol cd="latexml" id="S3.E8.m1.32.32.32.32.32.32.cmml" xref="S3.E8.m1.32.32.32.32.32.32">conditional</csymbol><ci id="S3.E8.m1.31.31.31.31.31.31.cmml" xref="S3.E8.m1.31.31.31.31.31.31">𝑓</ci><ci id="S3.E8.m1.33.33.33.33.33.33.cmml" xref="S3.E8.m1.33.33.33.33.33.33">𝑥</ci></apply></apply></interval></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E8.m1.39c">\begin{split}\mathcal{L}_{k}(\theta_{k}^{l},\theta_{k}^{g})=\mathbb{E}[-\log\sum_{f}(p_{\theta_{k}^{g}}(y|f),p_{\theta_{k}^{l}}(f|x))],\end{split}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(8)</span></td>
</tr></tbody>
</table>
<p id="S3.SS2.SSS3.p4.9" class="ltx_p">LG-FedAvg thus effectively decreases the communication cost by extracting useful lower-dimensional representations. Xu <span id="S3.SS2.SSS3.p4.9.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Xu et al<span class="ltx_text">.</span> (<a href="#bib.bib224" title="" class="ltx_ref">2023</a>)</cite> propose FedPAC, which reduces inter-client feature variance by constraining each sample feature vector to be close to the global feature centroid of its category. Then, the server performs an optimal weighted aggregation of the personalized classifier headers of the clients.</p>
</div>
<div id="S3.SS2.SSS3.p5" class="ltx_para">
<p id="S3.SS2.SSS3.p5.1" class="ltx_p"><span id="S3.SS2.SSS3.p5.1.1" class="ltx_text ltx_font_bold">Other Part Sharing.</span>
<span id="S3.SS2.SSS3.p5.1.2" class="ltx_text" style="color:#000000;">Apart from the case of backbone or classifier sharing, several methods employ other part sharing strategies, that is, adaptively share a subset of the local model parameters according to local conditions (<span id="S3.SS2.SSS3.p5.1.2.1" class="ltx_text ltx_font_italic">e.g.</span>, data distribution, computing capability, network bandwidth, privacy preference, etc.) as shown in Fig. <a href="#S3.F10" title="Figure 10 ‣ 3.2.2. Knowledge Transfer across Models ‣ 3.2. Model-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>. This approach effectively enhances the applicability of federated learning in scenarios involving different resource and network environment constraints across clients, thereby alleviating device heterogeneity and communication heterogeneity.</span> Furthermore, sharing part of the model for personalization can avoid catastrophic forgetting to some extent <cite class="ltx_cite ltx_citemacro_cite">Pillutla et al<span class="ltx_text">.</span> (<a href="#bib.bib172" title="" class="ltx_ref">2022</a>); McCloskey and Cohen (<a href="#bib.bib155" title="" class="ltx_ref">1989</a>)</cite>, which is extremely important for clients with large differences in data distributions.</p>
</div>
<div id="S3.SS2.SSS3.p6" class="ltx_para">
<p id="S3.SS2.SSS3.p6.1" class="ltx_p">To alleviate the effect of communication heterogeneity and device heterogeneity, HeteroFL <cite class="ltx_cite ltx_citemacro_cite">Diao et al<span class="ltx_text">.</span> (<a href="#bib.bib41" title="" class="ltx_ref">2021</a>)</cite> allocates local models of different sizes according to the computing and communication capabilities of each client. The local model parameters are a subset of the global model parameters, which effectively decreases the computation of local clients. Different from the prevailing methods that divide the shared layers and the personalization layers in a layer-wise mechanism, CD<sup id="S3.SS2.SSS3.p6.1.1" class="ltx_sup">2</sup>-pFed <cite class="ltx_cite ltx_citemacro_cite">Shen et al<span class="ltx_text">.</span> (<a href="#bib.bib187" title="" class="ltx_ref">2022</a>)</cite> dynamically decouples the global model parameters for personalization, which is known as channel decoupling. Concretely, a personalization rate is also defined to assign global shared weights and local private weights to each layer of the objective model. <span id="S3.SS2.SSS3.p6.1.2" class="ltx_text" style="color:#000000;">FedLA <cite class="ltx_cite ltx_citemacro_cite">Ma et al<span class="ltx_text">.</span> (<a href="#bib.bib148" title="" class="ltx_ref">2022</a>)</cite> leverages a hypernetwork on the server to evaluate the importance of each client model layer and generate aggregation weights for each model layer, thereby realizing personalized layer-wised model aggregation.</span></p>
</div>
<figure id="S3.F11" class="ltx_figure"><img src="/html/2307.10616/assets/x11.png" id="S3.F11.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="411" height="160" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11. </span><span id="S3.F11.2.1" class="ltx_text" style="font-size:90%;">Illustration of the server-level methods in heterogeneous federated learning.</span></figcaption>
</figure>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3. </span>Server-Level Methods</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p"><span id="S3.SS3.p1.1.1" class="ltx_text" style="color:#000000;">In this subsection, we categorize server-level methods and discuss the advantages and disadvantages of existing methods in Tab. <a href="#S3.T4" title="Table 4 ‣ 3.3. Server-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. Server-level methods refer to methods that rely on server-side operations, including client selection, client clustering and decentralized communication. Client selection aims to select the appropriate client to participate in the federated learning process for each iteration, which can solve various heterogeneous challenges. Client clustering improves the federated learning efficiency by aggregating similar clients, thereby alleviating communication and device heterogeneity. Decentralized communication enables peer-to-peer collaboration between devices without relying on a central server.</span></p>
</div>
<figure id="S3.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 4. </span> <span id="S3.T4.18.1" class="ltx_text" style="color:#000000;">Server-level methods.</span></figcaption>
<table id="S3.T4.14" class="ltx_tabular ltx_centering ltx_align_middle">
<tr id="S3.T4.5.5" class="ltx_tr">
<td id="S3.T4.1.1.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:62.6pt;"><span id="S3.T4.1.1.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T4.1.1.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T4.1.1.1.1.p1.1" class="ltx_p"><span id="S3.T4.1.1.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T4.1.1.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T4.1.1.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T4.1.1.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.1.1.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T4.1.1.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Methods</span></span>
</span></span><span id="S3.T4.1.1.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T4.1.1.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T4.2.2.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;"><span id="S3.T4.2.2.2.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T4.2.2.2.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T4.2.2.2.1.p1.1" class="ltx_p"><span id="S3.T4.2.2.2.1.p1.1.1" class="ltx_text"></span><span id="S3.T4.2.2.2.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T4.2.2.2.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T4.2.2.2.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.2.2.2.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T4.2.2.2.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Advantages</span></span>
</span></span><span id="S3.T4.2.2.2.1.p1.1.4" class="ltx_text"></span><span id="S3.T4.2.2.2.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T4.3.3.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T4.3.3.3.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T4.3.3.3.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T4.3.3.3.1.p1.1" class="ltx_p"><span id="S3.T4.3.3.3.1.p1.1.1" class="ltx_text"></span><span id="S3.T4.3.3.3.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T4.3.3.3.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T4.3.3.3.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.3.3.3.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T4.3.3.3.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Ref.</span></span>
</span></span><span id="S3.T4.3.3.3.1.p1.1.4" class="ltx_text"></span><span id="S3.T4.3.3.3.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T4.4.4.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;"><span id="S3.T4.4.4.4.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T4.4.4.4.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T4.4.4.4.1.p1.1" class="ltx_p"><span id="S3.T4.4.4.4.1.p1.1.1" class="ltx_text"></span><span id="S3.T4.4.4.4.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T4.4.4.4.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T4.4.4.4.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.4.4.4.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T4.4.4.4.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Key Contributions</span></span>
</span></span><span id="S3.T4.4.4.4.1.p1.1.4" class="ltx_text"></span><span id="S3.T4.4.4.4.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T4.5.5.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:102.4pt;"><span id="S3.T4.5.5.5.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T4.5.5.5.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T4.5.5.5.1.p1.1" class="ltx_p"><span id="S3.T4.5.5.5.1.p1.1.1" class="ltx_text"></span><span id="S3.T4.5.5.5.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T4.5.5.5.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T4.5.5.5.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.5.5.5.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T4.5.5.5.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Limitations</span></span>
</span></span><span id="S3.T4.5.5.5.1.p1.1.4" class="ltx_text"></span><span id="S3.T4.5.5.5.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
</tr>
<tr id="S3.T4.6.6" class="ltx_tr">
<td id="S3.T4.6.6.2" class="ltx_td ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:62.6pt;"></td>
<td id="S3.T4.6.6.3" class="ltx_td ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;"></td>
<td id="S3.T4.6.6.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T4.6.6.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T4.6.6.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T4.6.6.1.1.p1.1" class="ltx_p"><span id="S3.T4.6.6.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T4.6.6.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T4.6.6.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T4.6.6.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.6.6.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T4.6.6.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Wang et al<span class="ltx_text">.</span> (<a href="#bib.bib210" title="" class="ltx_ref">2020a</a>)</cite></span></span>
</span></span><span id="S3.T4.6.6.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T4.6.6.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T4.6.6.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;">
<span id="S3.T4.6.6.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.6.6.4.1.1" class="ltx_p"><span id="S3.T4.6.6.4.1.1.1" class="ltx_text" style="font-size:90%;">Favor is an experience-driven control framework that actively selects the best subset of clients to participate in federated learning iterations.</span></span>
</span>
</td>
<td id="S3.T4.6.6.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:102.4pt;">
<span id="S3.T4.6.6.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.6.6.5.1.1" class="ltx_p"><span id="S3.T4.6.6.5.1.1.1" class="ltx_text" style="font-size:90%;">Training reinforcement learning models may be data-hungry.</span></span>
</span>
</td>
</tr>
<tr id="S3.T4.7.7" class="ltx_tr">
<td id="S3.T4.7.7.2" class="ltx_td ltx_align_middle ltx_border_l ltx_border_r" style="width:62.6pt;"></td>
<td id="S3.T4.7.7.3" class="ltx_td ltx_align_middle ltx_border_r" style="width:56.9pt;"></td>
<td id="S3.T4.7.7.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T4.7.7.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T4.7.7.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T4.7.7.1.1.p1.1" class="ltx_p"><span id="S3.T4.7.7.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T4.7.7.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T4.7.7.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T4.7.7.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.7.7.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T4.7.7.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Yang et al<span class="ltx_text">.</span> (<a href="#bib.bib226" title="" class="ltx_ref">2021</a>)</cite></span></span>
</span></span><span id="S3.T4.7.7.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T4.7.7.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T4.7.7.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;">
<span id="S3.T4.7.7.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.7.7.4.1.1" class="ltx_p"><span id="S3.T4.7.7.4.1.1.1" class="ltx_text" style="font-size:90%;">CUCB is a client selection algorithm that minimizes the class imbalance and facilitates the global model convergence.</span></span>
</span>
</td>
<td id="S3.T4.7.7.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:102.4pt;">
<span id="S3.T4.7.7.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.7.7.5.1.1" class="ltx_p"><span id="S3.T4.7.7.5.1.1.1" class="ltx_text" style="font-size:90%;">Revealing the class distribution based on updated gradients may be vulnerable to inference attacks.</span></span>
</span>
</td>
</tr>
<tr id="S3.T4.8.8" class="ltx_tr">
<td id="S3.T4.8.8.2" class="ltx_td ltx_align_middle ltx_border_l ltx_border_r" style="width:62.6pt;"></td>
<td id="S3.T4.8.8.3" class="ltx_td ltx_align_middle ltx_border_r" style="width:56.9pt;"></td>
<td id="S3.T4.8.8.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T4.8.8.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T4.8.8.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T4.8.8.1.1.p1.1" class="ltx_p"><span id="S3.T4.8.8.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T4.8.8.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T4.8.8.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T4.8.8.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.8.8.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T4.8.8.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib116" title="" class="ltx_ref">2021b</a>)</cite></span></span>
</span></span><span id="S3.T4.8.8.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T4.8.8.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T4.8.8.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;">
<span id="S3.T4.8.8.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.8.8.4.1.1" class="ltx_p"><span id="S3.T4.8.8.4.1.1.1" class="ltx_text" style="font-size:90%;">FedSAE estimates the reliability of each device and performs client selection based on training losses.</span></span>
</span>
</td>
<td id="S3.T4.8.8.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:102.4pt;">
<span id="S3.T4.8.8.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.8.8.5.1.1" class="ltx_p"><span id="S3.T4.8.8.5.1.1.1" class="ltx_text" style="font-size:90%;">Adjusting workloads based on the training history of clients may be delayed.</span></span>
</span>
</td>
</tr>
<tr id="S3.T4.14.15" class="ltx_tr">
<td id="S3.T4.14.15.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:62.6pt;">
<span id="S3.T4.14.15.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.14.15.1.1.1" class="ltx_p"><span id="S3.T4.14.15.1.1.1.1" class="ltx_text"></span><span id="S3.T4.14.15.1.1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T4.14.15.1.1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T4.14.15.1.1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.14.15.1.1.1.3.1.1" class="ltx_tr">
<span id="S3.T4.14.15.1.1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Client Selection</span></span>
<span id="S3.T4.14.15.1.1.1.3.1.2" class="ltx_tr">
<span id="S3.T4.14.15.1.1.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><a href="#S3.SS3.SSS1" title="3.3.1. Client Selection ‣ 3.3. Server-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3.1</span></a></span></span>
</span></span><span id="S3.T4.14.15.1.1.1.4" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T4.14.15.1.1.1.5" class="ltx_text"></span></span>
</span>
</td>
<td id="S3.T4.14.15.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:56.9pt;">
<span id="S3.T4.14.15.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.14.15.2.1.1" class="ltx_p"><span id="S3.T4.14.15.2.1.1.1" class="ltx_text" style="font-size:90%;">These methods accelerate convergence by formulating client selection strategies.</span></span>
</span>
</td>
<td id="S3.T4.14.15.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;">
<span id="S3.T4.14.15.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.14.15.3.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">Nishio and Yonetani <span id="S3.T4.14.15.3.1.1.1.1.1.1" class="ltx_text" style="font-size:90%;">(</span><a href="#bib.bib167" title="" class="ltx_ref">2019</a><span id="S3.T4.14.15.3.1.1.2.2.2.1" class="ltx_text" style="font-size:90%;">)</span></cite></span>
</span>
</td>
<td id="S3.T4.14.15.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;">
<span id="S3.T4.14.15.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.14.15.4.1.1" class="ltx_p"><span id="S3.T4.14.15.4.1.1.1" class="ltx_text" style="font-size:90%;">FedCS performs client selection operations based on data resources, computing capabilities, and wireless channel conditions.</span></span>
</span>
</td>
<td id="S3.T4.14.15.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:102.4pt;">
<span id="S3.T4.14.15.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.14.15.5.1.1" class="ltx_p"><span id="S3.T4.14.15.5.1.1.1" class="ltx_text" style="font-size:90%;">Estimating training time for complex models may be difficult.</span></span>
</span>
</td>
</tr>
<tr id="S3.T4.9.9" class="ltx_tr">
<td id="S3.T4.9.9.2" class="ltx_td ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:62.6pt;"></td>
<td id="S3.T4.9.9.3" class="ltx_td ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;"></td>
<td id="S3.T4.9.9.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T4.9.9.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T4.9.9.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T4.9.9.1.1.p1.1" class="ltx_p"><span id="S3.T4.9.9.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T4.9.9.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T4.9.9.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T4.9.9.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.9.9.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T4.9.9.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Briggs et al<span class="ltx_text">.</span> (<a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite></span></span>
</span></span><span id="S3.T4.9.9.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T4.9.9.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T4.9.9.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;">
<span id="S3.T4.9.9.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.9.9.4.1.1" class="ltx_p"><span id="S3.T4.9.9.4.1.1.1" class="ltx_text" style="font-size:90%;">FL+HC introduces a hierarchical clustering step to separate client clusters based on the similarity of client updates to the global joint model.</span></span>
</span>
</td>
<td id="S3.T4.9.9.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:102.4pt;">
<span id="S3.T4.9.9.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.9.9.5.1.1" class="ltx_p"><span id="S3.T4.9.9.5.1.1.1" class="ltx_text" style="font-size:90%;">The effect of communication heterogeneity and device heterogeneity may be ignored.</span></span>
</span>
</td>
</tr>
<tr id="S3.T4.10.10" class="ltx_tr">
<td id="S3.T4.10.10.2" class="ltx_td ltx_align_middle ltx_border_l ltx_border_r" style="width:62.6pt;"></td>
<td id="S3.T4.10.10.3" class="ltx_td ltx_align_middle ltx_border_r" style="width:56.9pt;"></td>
<td id="S3.T4.10.10.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T4.10.10.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T4.10.10.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T4.10.10.1.1.p1.1" class="ltx_p"><span id="S3.T4.10.10.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T4.10.10.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T4.10.10.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T4.10.10.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.10.10.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T4.10.10.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Xie et al<span class="ltx_text">.</span> (<a href="#bib.bib221" title="" class="ltx_ref">2020</a>)</cite></span></span>
</span></span><span id="S3.T4.10.10.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T4.10.10.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T4.10.10.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;">
<span id="S3.T4.10.10.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.10.10.4.1.1" class="ltx_p"><span id="S3.T4.10.10.4.1.1.1" class="ltx_text" style="font-size:90%;">FeSEM employs SEM optimization to calculate the distance between local models and cluster centers.</span></span>
</span>
</td>
<td id="S3.T4.10.10.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:102.4pt;">
<span id="S3.T4.10.10.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.10.10.5.1.1" class="ltx_p"><span id="S3.T4.10.10.5.1.1.1" class="ltx_text" style="font-size:90%;">Compared with single-center clustering, multi-center clustering may require higher storage capability.</span></span>
</span>
</td>
</tr>
<tr id="S3.T4.11.11" class="ltx_tr">
<td id="S3.T4.11.11.2" class="ltx_td ltx_align_middle ltx_border_l ltx_border_r" style="width:62.6pt;"></td>
<td id="S3.T4.11.11.3" class="ltx_td ltx_align_middle ltx_border_r" style="width:56.9pt;"></td>
<td id="S3.T4.11.11.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T4.11.11.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T4.11.11.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T4.11.11.1.1.p1.1" class="ltx_p"><span id="S3.T4.11.11.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T4.11.11.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T4.11.11.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T4.11.11.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.11.11.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T4.11.11.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Sattler et al<span class="ltx_text">.</span> (<a href="#bib.bib181" title="" class="ltx_ref">2020b</a>)</cite></span></span>
</span></span><span id="S3.T4.11.11.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T4.11.11.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T4.11.11.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;">
<span id="S3.T4.11.11.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.11.11.4.1.1" class="ltx_p"><span id="S3.T4.11.11.4.1.1.1" class="ltx_text" style="font-size:90%;">CFL clusters similar clients by the cosine similarity between their gradient updates.</span></span>
</span>
</td>
<td id="S3.T4.11.11.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:102.4pt;">
<span id="S3.T4.11.11.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.11.11.5.1.1" class="ltx_p"><span id="S3.T4.11.11.5.1.1.1" class="ltx_text" style="font-size:90%;">It is vulnerable to backdoor attacks in federated learning.</span></span>
</span>
</td>
</tr>
<tr id="S3.T4.14.16" class="ltx_tr">
<td id="S3.T4.14.16.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_l ltx_border_r" style="width:62.6pt;">
<span id="S3.T4.14.16.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.14.16.1.1.1" class="ltx_p"><span id="S3.T4.14.16.1.1.1.1" class="ltx_text"></span><span id="S3.T4.14.16.1.1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T4.14.16.1.1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T4.14.16.1.1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.14.16.1.1.1.3.1.1" class="ltx_tr">
<span id="S3.T4.14.16.1.1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center">Client Clustering</span></span>
<span id="S3.T4.14.16.1.1.1.3.1.2" class="ltx_tr">
<span id="S3.T4.14.16.1.1.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><a href="#S3.SS3.SSS2" title="3.3.2. Client Clustering ‣ 3.3. Server-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3.2</span></a></span></span>
</span></span><span id="S3.T4.14.16.1.1.1.4" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T4.14.16.1.1.1.5" class="ltx_text"></span></span>
</span>
</td>
<td id="S3.T4.14.16.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r" style="width:56.9pt;">
<span id="S3.T4.14.16.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.14.16.2.1.1" class="ltx_p"><span id="S3.T4.14.16.2.1.1.1" class="ltx_text" style="font-size:90%;">These methods enhance HFL efficiency by personalized clustering clients.</span></span>
</span>
</td>
<td id="S3.T4.14.16.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;">
<span id="S3.T4.14.16.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.14.16.3.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">Nguyen et al<span class="ltx_text">.</span> <span id="S3.T4.14.16.3.1.1.1.1.1.1" class="ltx_text" style="font-size:90%;">(</span><a href="#bib.bib164" title="" class="ltx_ref">2022b</a><span id="S3.T4.14.16.3.1.1.2.2.2.1" class="ltx_text" style="font-size:90%;">)</span></cite></span>
</span>
</td>
<td id="S3.T4.14.16.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;">
<span id="S3.T4.14.16.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.14.16.4.1.1" class="ltx_p"><span id="S3.T4.14.16.4.1.1.1" class="ltx_text" style="font-size:90%;">FLAME detects adversarial model updates through a clustering strategy that limits the noise scale of backdoor noise removal.</span></span>
</span>
</td>
<td id="S3.T4.14.16.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:102.4pt;">
<span id="S3.T4.14.16.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.14.16.5.1.1" class="ltx_p"><span id="S3.T4.14.16.5.1.1.1" class="ltx_text" style="font-size:90%;">Building trusted server in practical settings may be challenging.</span></span>
</span>
</td>
</tr>
<tr id="S3.T4.12.12" class="ltx_tr">
<td id="S3.T4.12.12.2" class="ltx_td ltx_align_middle ltx_border_l ltx_border_r ltx_border_t" style="width:62.6pt;"></td>
<td id="S3.T4.12.12.3" class="ltx_td ltx_align_middle ltx_border_r ltx_border_t" style="width:56.9pt;"></td>
<td id="S3.T4.12.12.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T4.12.12.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T4.12.12.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T4.12.12.1.1.p1.1" class="ltx_p"><span id="S3.T4.12.12.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T4.12.12.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T4.12.12.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T4.12.12.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.12.12.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T4.12.12.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Roy et al<span class="ltx_text">.</span> (<a href="#bib.bib177" title="" class="ltx_ref">2019</a>)</cite></span></span>
</span></span><span id="S3.T4.12.12.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T4.12.12.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T4.12.12.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;">
<span id="S3.T4.12.12.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.12.12.4.1.1" class="ltx_p"><span id="S3.T4.12.12.4.1.1.1" class="ltx_text" style="font-size:90%;">BrainTorrent randomly selects a client as a temporary server in each round, and then coordinates updates with other clients.</span></span>
</span>
</td>
<td id="S3.T4.12.12.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:102.4pt;">
<span id="S3.T4.12.12.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.12.12.5.1.1" class="ltx_p"><span id="S3.T4.12.12.5.1.1.1" class="ltx_text" style="font-size:90%;">It requires high computational and storage resources for temporary servers.</span></span>
</span>
</td>
</tr>
<tr id="S3.T4.13.13" class="ltx_tr">
<td id="S3.T4.13.13.2" class="ltx_td ltx_align_middle ltx_border_l ltx_border_r" style="width:62.6pt;"></td>
<td id="S3.T4.13.13.3" class="ltx_td ltx_align_middle ltx_border_r" style="width:56.9pt;"></td>
<td id="S3.T4.13.13.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T4.13.13.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T4.13.13.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T4.13.13.1.1.p1.1" class="ltx_p"><span id="S3.T4.13.13.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T4.13.13.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T4.13.13.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T4.13.13.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.13.13.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T4.13.13.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Hu et al<span class="ltx_text">.</span> (<a href="#bib.bib80" title="" class="ltx_ref">2019</a>)</cite></span></span>
</span></span><span id="S3.T4.13.13.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T4.13.13.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T4.13.13.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;">
<span id="S3.T4.13.13.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.13.13.4.1.1" class="ltx_p"><span id="S3.T4.13.13.4.1.1.1" class="ltx_text" style="font-size:90%;">Combo divides the local model into model segments, and then randomly selects some clients to transfer the model segments.</span></span>
</span>
</td>
<td id="S3.T4.13.13.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:102.4pt;">
<span id="S3.T4.13.13.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.13.13.5.1.1" class="ltx_p"><span id="S3.T4.13.13.5.1.1.1" class="ltx_text" style="font-size:90%;">Transferring model segments alleviate communication delays, but do not reduce overall communication overhead.</span></span>
</span>
</td>
</tr>
<tr id="S3.T4.14.14" class="ltx_tr">
<td id="S3.T4.14.14.2" class="ltx_td ltx_align_middle ltx_border_l ltx_border_r" style="width:62.6pt;"></td>
<td id="S3.T4.14.14.3" class="ltx_td ltx_align_middle ltx_border_r" style="width:56.9pt;"></td>
<td id="S3.T4.14.14.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:17.1pt;"><span id="S3.T4.14.14.1.1" class="ltx_inline-logical-block ltx_align_top">
<span id="S3.T4.14.14.1.1.p1" class="ltx_para ltx_noindent">
<span id="S3.T4.14.14.1.1.p1.1" class="ltx_p"><span id="S3.T4.14.14.1.1.p1.1.1" class="ltx_text"></span><span id="S3.T4.14.14.1.1.p1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T4.14.14.1.1.p1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T4.14.14.1.1.p1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.14.14.1.1.p1.1.3.1.1" class="ltx_tr">
<span id="S3.T4.14.14.1.1.p1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><cite class="ltx_cite ltx_citemacro_cite">Kalra et al<span class="ltx_text">.</span> (<a href="#bib.bib99" title="" class="ltx_ref">2023</a>)</cite></span></span>
</span></span><span id="S3.T4.14.14.1.1.p1.1.4" class="ltx_text"></span><span id="S3.T4.14.14.1.1.p1.1.5" class="ltx_text" style="font-size:90%;"></span></span>
</span></span></td>
<td id="S3.T4.14.14.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:136.6pt;">
<span id="S3.T4.14.14.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.14.14.4.1.1" class="ltx_p"><span id="S3.T4.14.14.4.1.1.1" class="ltx_text" style="font-size:90%;">ProxyFL makes each client maintain two models, a private model and a publicly shared proxy model for exchanges.</span></span>
</span>
</td>
<td id="S3.T4.14.14.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_r ltx_border_t" style="width:102.4pt;">
<span id="S3.T4.14.14.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.14.14.5.1.1" class="ltx_p"><span id="S3.T4.14.14.5.1.1.1" class="ltx_text" style="font-size:90%;">Proxy models may not capture all the information or complexity of private models.</span></span>
</span>
</td>
</tr>
<tr id="S3.T4.14.17" class="ltx_tr">
<td id="S3.T4.14.17.1" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_l ltx_border_r" style="width:62.6pt;">
<span id="S3.T4.14.17.1.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.14.17.1.1.1" class="ltx_p"><span id="S3.T4.14.17.1.1.1.1" class="ltx_text"></span><span id="S3.T4.14.17.1.1.1.2" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T4.14.17.1.1.1.3" class="ltx_text" style="font-size:90%;">
<span id="S3.T4.14.17.1.1.1.3.1" class="ltx_tabular ltx_align_middle">
<span id="S3.T4.14.17.1.1.1.3.1.1" class="ltx_tr">
<span id="S3.T4.14.17.1.1.1.3.1.1.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T4.14.17.1.1.1.3.1.1.1.1" class="ltx_text" style="color:#000000;">Decentralized</span></span></span>
<span id="S3.T4.14.17.1.1.1.3.1.2" class="ltx_tr">
<span id="S3.T4.14.17.1.1.1.3.1.2.1" class="ltx_td ltx_nopad_r ltx_align_center"><span id="S3.T4.14.17.1.1.1.3.1.2.1.1" class="ltx_text" style="color:#000000;">Communication</span></span></span>
<span id="S3.T4.14.17.1.1.1.3.1.3" class="ltx_tr">
<span id="S3.T4.14.17.1.1.1.3.1.3.1" class="ltx_td ltx_nopad_r ltx_align_center"><a href="#S3.SS3.SSS3" title="3.3.3. Decentralized Communication ‣ 3.3. Server-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3.3.3</span></a></span></span>
</span></span><span id="S3.T4.14.17.1.1.1.4" class="ltx_text" style="font-size:90%;"> </span><span id="S3.T4.14.17.1.1.1.5" class="ltx_text"></span></span>
</span>
</td>
<td id="S3.T4.14.17.2" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r" style="width:56.9pt;">
<span id="S3.T4.14.17.2.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.14.17.2.1.1" class="ltx_p"><span id="S3.T4.14.17.2.1.1.1" class="ltx_text" style="font-size:90%;">These methods can effectively reduce the reliance on the secure central server and alleviate the communication bottleneck.</span></span>
</span>
</td>
<td id="S3.T4.14.17.3" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:17.1pt;">
<span id="S3.T4.14.17.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.14.17.3.1.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> <span id="S3.T4.14.17.3.1.1.1.1.1.1" class="ltx_text" style="font-size:90%;">(</span><a href="#bib.bib128" title="" class="ltx_ref">2020a</a><span id="S3.T4.14.17.3.1.1.2.2.2.1" class="ltx_text" style="font-size:90%;">)</span></cite></span>
</span>
</td>
<td id="S3.T4.14.17.4" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:136.6pt;">
<span id="S3.T4.14.17.4.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.14.17.4.1.1" class="ltx_p"><span id="S3.T4.14.17.4.1.1.1" class="ltx_text" style="font-size:90%;">BFLC utilizes the blockchain for global model storage and local model update exchange to enhance the security of federated learning.</span></span>
</span>
</td>
<td id="S3.T4.14.17.5" class="ltx_td ltx_align_justify ltx_align_middle ltx_border_b ltx_border_r ltx_border_t" style="width:102.4pt;">
<span id="S3.T4.14.17.5.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T4.14.17.5.1.1" class="ltx_p"><span id="S3.T4.14.17.5.1.1.1" class="ltx_text" style="font-size:90%;">Maintaining and validating blockchain ledgers can incur high computational and storage costs.</span></span>
</span>
</td>
</tr>
</table>
</figure>
<section id="S3.SS3.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.1. </span> Client Selection</h4>

<div id="S3.SS3.SSS1.p1" class="ltx_para">
<p id="S3.SS3.SSS1.p1.1" class="ltx_p">Client selection is typically performed by the server, so that data can be sampled from clients with uniform data distributions (Fig. <a href="#S3.F11" title="Figure 11 ‣ 3.2.3. Architecture Sharing ‣ 3.2. Model-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>). Moreover, constraints such as the network bandwidth, computation capability, and local resources of different clients are considered when formulating selection strategies. Consequently, client selection can accelerate convergence and substantially improve the model accuracy.</p>
</div>
<div id="S3.SS3.SSS1.p2" class="ltx_para">
<p id="S3.SS3.SSS1.p2.1" class="ltx_p">The performance of traditional federated learning on Non-IID datasets is inferior to its performance on IID datasets, and the convergence speed on Non-IID datasets is also much slower than that on IID datasets. Several methods <cite class="ltx_cite ltx_citemacro_cite">Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib248" title="" class="ltx_ref">2021d</a>); Huang et al<span class="ltx_text">.</span> (<a href="#bib.bib83" title="" class="ltx_ref">2022a</a>); Wang and Kantarci (<a href="#bib.bib213" title="" class="ltx_ref">2020</a>); Balakrishnan et al<span class="ltx_text">.</span> (<a href="#bib.bib11" title="" class="ltx_ref">2022</a>)</cite> are devised to alleviate the bias introduced by Non-IID data. Favor <cite class="ltx_cite ltx_citemacro_cite">Wang et al<span class="ltx_text">.</span> (<a href="#bib.bib210" title="" class="ltx_ref">2020a</a>)</cite> is an experience-driven control framework that actively selects the best subset of clients to participate in federated learning iterations. Innovatively, they define device selection for federated learning as a deep reinforcement learning problem that aims to train an agent to learn an appropriate selection policy. In addition, class imbalance may occur when the client data distribution is inconsistent. To address this problem, Yang <span id="S3.SS3.SSS1.p2.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Yang et al<span class="ltx_text">.</span> (<a href="#bib.bib226" title="" class="ltx_ref">2021</a>)</cite> devise an estimation scheme that clarifies the client class distribution based on the gradient of client service updates without considering the original data. Moreover, they design a client selection algorithm for the minimal class imbalance to improve the global model convergence. <span id="S3.SS3.SSS1.p2.1.2" class="ltx_text" style="color:#000000;">Tang <span id="S3.SS3.SSS1.p2.1.2.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Tang et al<span class="ltx_text">.</span> (<a href="#bib.bib201" title="" class="ltx_ref">2022a</a>)</cite> propose a correlation-based client selection strategy, using a Gaussian process to model loss changes of clients, and then selecting one client in each iteration to reduce the overall loss expectation. Qin <span id="S3.SS3.SSS1.p2.1.2.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Qin et al<span class="ltx_text">.</span> (<a href="#bib.bib173" title="" class="ltx_ref">2023</a>)</cite> believe that when selecting clients for collaborative training, in addition to considering the independent characteristics of clients, it is necessary to pay attention to the synergy between clients.</span></p>
</div>
<div id="S3.SS3.SSS1.p3" class="ltx_para">
<p id="S3.SS3.SSS1.p3.1" class="ltx_p">The differences in the hardware and the network connectivity capabilities across clients may lead to high communication costs, low training efficiency, and wasted computing resources, etc. Thus, a large number of client selection strategies <cite class="ltx_cite ltx_citemacro_cite">Cho et al<span class="ltx_text">.</span> (<a href="#bib.bib33" title="" class="ltx_ref">2020</a>); Huang et al<span class="ltx_text">.</span> (<a href="#bib.bib84" title="" class="ltx_ref">2020b</a>); Bonawitz et al<span class="ltx_text">.</span> (<a href="#bib.bib15" title="" class="ltx_ref">2019</a>); AbdulRahman et al<span class="ltx_text">.</span> (<a href="#bib.bib2" title="" class="ltx_ref">2020</a>); Yoshida et al<span class="ltx_text">.</span> (<a href="#bib.bib236" title="" class="ltx_ref">2020</a>)</cite> aim to address these issues. In FedSAE <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib116" title="" class="ltx_ref">2021b</a>)</cite>, the server estimates the reliability of each device based on the complete information of the client training history tasks, thereby adjusting the training load of each client. Furthermore, the server selects the clients with higher values based on the training losses of the clients to improve communication efficiency. FedCS <cite class="ltx_cite ltx_citemacro_cite">Nishio and Yonetani (<a href="#bib.bib167" title="" class="ltx_ref">2019</a>)</cite> performs the client selection operation based on the differences in data resources, computing capabilities and wireless channel conditions across client models and uses the selected clients <math id="S3.SS3.SSS1.p3.1.m1.1" class="ltx_Math" alttext="\mathbb{C}" display="inline"><semantics id="S3.SS3.SSS1.p3.1.m1.1a"><mi id="S3.SS3.SSS1.p3.1.m1.1.1" xref="S3.SS3.SSS1.p3.1.m1.1.1.cmml">ℂ</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p3.1.m1.1b"><ci id="S3.SS3.SSS1.p3.1.m1.1.1.cmml" xref="S3.SS3.SSS1.p3.1.m1.1.1">ℂ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p3.1.m1.1c">\mathbb{C}</annotation></semantics></math> for aggregation. The core idea of client selection is to solve the following maximization problem:</p>
<table id="S3.E9" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S3.E9X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E9X.2.1.1.m1.3" class="ltx_math_unparsed" alttext="\displaystyle\max_{\mathbb{C}}|\mathbb{C}|s.t.\quad T_{epoch}\geq T_{cs}+T_{\mathbb{C}}^{d}+T_{\mathbb{C}}^{u}+T_{agg}," display="inline"><semantics id="S3.E9X.2.1.1.m1.3a"><mrow id="S3.E9X.2.1.1.m1.3b"><munder id="S3.E9X.2.1.1.m1.3.4"><mi id="S3.E9X.2.1.1.m1.3.4.2">max</mi><mi id="S3.E9X.2.1.1.m1.3.4.3">ℂ</mi></munder><mo fence="false" rspace="0.167em" stretchy="false" id="S3.E9X.2.1.1.m1.3.5">|</mo><mi id="S3.E9X.2.1.1.m1.3.3">ℂ</mi><mo fence="false" rspace="0.167em" stretchy="false" id="S3.E9X.2.1.1.m1.3.6">|</mo><mi id="S3.E9X.2.1.1.m1.1.1">s</mi><mo lspace="0em" rspace="0.167em" id="S3.E9X.2.1.1.m1.3.7">.</mo><mi id="S3.E9X.2.1.1.m1.2.2">t</mi><mo lspace="0em" id="S3.E9X.2.1.1.m1.3.8">.</mo><mspace width="1.167em" id="S3.E9X.2.1.1.m1.3.9"></mspace><msub id="S3.E9X.2.1.1.m1.3.10"><mi id="S3.E9X.2.1.1.m1.3.10.2">T</mi><mrow id="S3.E9X.2.1.1.m1.3.10.3"><mi id="S3.E9X.2.1.1.m1.3.10.3.2">e</mi><mo lspace="0em" rspace="0em" id="S3.E9X.2.1.1.m1.3.10.3.1">​</mo><mi id="S3.E9X.2.1.1.m1.3.10.3.3">p</mi><mo lspace="0em" rspace="0em" id="S3.E9X.2.1.1.m1.3.10.3.1a">​</mo><mi id="S3.E9X.2.1.1.m1.3.10.3.4">o</mi><mo lspace="0em" rspace="0em" id="S3.E9X.2.1.1.m1.3.10.3.1b">​</mo><mi id="S3.E9X.2.1.1.m1.3.10.3.5">c</mi><mo lspace="0em" rspace="0em" id="S3.E9X.2.1.1.m1.3.10.3.1c">​</mo><mi id="S3.E9X.2.1.1.m1.3.10.3.6">h</mi></mrow></msub><mo id="S3.E9X.2.1.1.m1.3.11">≥</mo><msub id="S3.E9X.2.1.1.m1.3.12"><mi id="S3.E9X.2.1.1.m1.3.12.2">T</mi><mrow id="S3.E9X.2.1.1.m1.3.12.3"><mi id="S3.E9X.2.1.1.m1.3.12.3.2">c</mi><mo lspace="0em" rspace="0em" id="S3.E9X.2.1.1.m1.3.12.3.1">​</mo><mi id="S3.E9X.2.1.1.m1.3.12.3.3">s</mi></mrow></msub><mo id="S3.E9X.2.1.1.m1.3.13">+</mo><msubsup id="S3.E9X.2.1.1.m1.3.14"><mi id="S3.E9X.2.1.1.m1.3.14.2.2">T</mi><mi id="S3.E9X.2.1.1.m1.3.14.2.3">ℂ</mi><mi id="S3.E9X.2.1.1.m1.3.14.3">d</mi></msubsup><mo id="S3.E9X.2.1.1.m1.3.15">+</mo><msubsup id="S3.E9X.2.1.1.m1.3.16"><mi id="S3.E9X.2.1.1.m1.3.16.2.2">T</mi><mi id="S3.E9X.2.1.1.m1.3.16.2.3">ℂ</mi><mi id="S3.E9X.2.1.1.m1.3.16.3">u</mi></msubsup><mo id="S3.E9X.2.1.1.m1.3.17">+</mo><msub id="S3.E9X.2.1.1.m1.3.18"><mi id="S3.E9X.2.1.1.m1.3.18.2">T</mi><mrow id="S3.E9X.2.1.1.m1.3.18.3"><mi id="S3.E9X.2.1.1.m1.3.18.3.2">a</mi><mo lspace="0em" rspace="0em" id="S3.E9X.2.1.1.m1.3.18.3.1">​</mo><mi id="S3.E9X.2.1.1.m1.3.18.3.3">g</mi><mo lspace="0em" rspace="0em" id="S3.E9X.2.1.1.m1.3.18.3.1a">​</mo><mi id="S3.E9X.2.1.1.m1.3.18.3.4">g</mi></mrow></msub><mo id="S3.E9X.2.1.1.m1.3.19">,</mo></mrow><annotation encoding="application/x-tex" id="S3.E9X.2.1.1.m1.3c">\displaystyle\max_{\mathbb{C}}|\mathbb{C}|s.t.\quad T_{epoch}\geq T_{cs}+T_{\mathbb{C}}^{d}+T_{\mathbb{C}}^{u}+T_{agg},</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(9)</span></td>
</tr>
</tbody>
</table>
<p id="S3.SS3.SSS1.p3.6" class="ltx_p">where <math id="S3.SS3.SSS1.p3.2.m1.1" class="ltx_Math" alttext="T_{round}" display="inline"><semantics id="S3.SS3.SSS1.p3.2.m1.1a"><msub id="S3.SS3.SSS1.p3.2.m1.1.1" xref="S3.SS3.SSS1.p3.2.m1.1.1.cmml"><mi id="S3.SS3.SSS1.p3.2.m1.1.1.2" xref="S3.SS3.SSS1.p3.2.m1.1.1.2.cmml">T</mi><mrow id="S3.SS3.SSS1.p3.2.m1.1.1.3" xref="S3.SS3.SSS1.p3.2.m1.1.1.3.cmml"><mi id="S3.SS3.SSS1.p3.2.m1.1.1.3.2" xref="S3.SS3.SSS1.p3.2.m1.1.1.3.2.cmml">r</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.p3.2.m1.1.1.3.1" xref="S3.SS3.SSS1.p3.2.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS3.SSS1.p3.2.m1.1.1.3.3" xref="S3.SS3.SSS1.p3.2.m1.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.p3.2.m1.1.1.3.1a" xref="S3.SS3.SSS1.p3.2.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS3.SSS1.p3.2.m1.1.1.3.4" xref="S3.SS3.SSS1.p3.2.m1.1.1.3.4.cmml">u</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.p3.2.m1.1.1.3.1b" xref="S3.SS3.SSS1.p3.2.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS3.SSS1.p3.2.m1.1.1.3.5" xref="S3.SS3.SSS1.p3.2.m1.1.1.3.5.cmml">n</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.p3.2.m1.1.1.3.1c" xref="S3.SS3.SSS1.p3.2.m1.1.1.3.1.cmml">​</mo><mi id="S3.SS3.SSS1.p3.2.m1.1.1.3.6" xref="S3.SS3.SSS1.p3.2.m1.1.1.3.6.cmml">d</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p3.2.m1.1b"><apply id="S3.SS3.SSS1.p3.2.m1.1.1.cmml" xref="S3.SS3.SSS1.p3.2.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p3.2.m1.1.1.1.cmml" xref="S3.SS3.SSS1.p3.2.m1.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.p3.2.m1.1.1.2.cmml" xref="S3.SS3.SSS1.p3.2.m1.1.1.2">𝑇</ci><apply id="S3.SS3.SSS1.p3.2.m1.1.1.3.cmml" xref="S3.SS3.SSS1.p3.2.m1.1.1.3"><times id="S3.SS3.SSS1.p3.2.m1.1.1.3.1.cmml" xref="S3.SS3.SSS1.p3.2.m1.1.1.3.1"></times><ci id="S3.SS3.SSS1.p3.2.m1.1.1.3.2.cmml" xref="S3.SS3.SSS1.p3.2.m1.1.1.3.2">𝑟</ci><ci id="S3.SS3.SSS1.p3.2.m1.1.1.3.3.cmml" xref="S3.SS3.SSS1.p3.2.m1.1.1.3.3">𝑜</ci><ci id="S3.SS3.SSS1.p3.2.m1.1.1.3.4.cmml" xref="S3.SS3.SSS1.p3.2.m1.1.1.3.4">𝑢</ci><ci id="S3.SS3.SSS1.p3.2.m1.1.1.3.5.cmml" xref="S3.SS3.SSS1.p3.2.m1.1.1.3.5">𝑛</ci><ci id="S3.SS3.SSS1.p3.2.m1.1.1.3.6.cmml" xref="S3.SS3.SSS1.p3.2.m1.1.1.3.6">𝑑</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p3.2.m1.1c">T_{round}</annotation></semantics></math> is the deadline for each round. In addition, <math id="S3.SS3.SSS1.p3.3.m2.1" class="ltx_Math" alttext="T_{cs}" display="inline"><semantics id="S3.SS3.SSS1.p3.3.m2.1a"><msub id="S3.SS3.SSS1.p3.3.m2.1.1" xref="S3.SS3.SSS1.p3.3.m2.1.1.cmml"><mi id="S3.SS3.SSS1.p3.3.m2.1.1.2" xref="S3.SS3.SSS1.p3.3.m2.1.1.2.cmml">T</mi><mrow id="S3.SS3.SSS1.p3.3.m2.1.1.3" xref="S3.SS3.SSS1.p3.3.m2.1.1.3.cmml"><mi id="S3.SS3.SSS1.p3.3.m2.1.1.3.2" xref="S3.SS3.SSS1.p3.3.m2.1.1.3.2.cmml">c</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.p3.3.m2.1.1.3.1" xref="S3.SS3.SSS1.p3.3.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS3.SSS1.p3.3.m2.1.1.3.3" xref="S3.SS3.SSS1.p3.3.m2.1.1.3.3.cmml">s</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p3.3.m2.1b"><apply id="S3.SS3.SSS1.p3.3.m2.1.1.cmml" xref="S3.SS3.SSS1.p3.3.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p3.3.m2.1.1.1.cmml" xref="S3.SS3.SSS1.p3.3.m2.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.p3.3.m2.1.1.2.cmml" xref="S3.SS3.SSS1.p3.3.m2.1.1.2">𝑇</ci><apply id="S3.SS3.SSS1.p3.3.m2.1.1.3.cmml" xref="S3.SS3.SSS1.p3.3.m2.1.1.3"><times id="S3.SS3.SSS1.p3.3.m2.1.1.3.1.cmml" xref="S3.SS3.SSS1.p3.3.m2.1.1.3.1"></times><ci id="S3.SS3.SSS1.p3.3.m2.1.1.3.2.cmml" xref="S3.SS3.SSS1.p3.3.m2.1.1.3.2">𝑐</ci><ci id="S3.SS3.SSS1.p3.3.m2.1.1.3.3.cmml" xref="S3.SS3.SSS1.p3.3.m2.1.1.3.3">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p3.3.m2.1c">T_{cs}</annotation></semantics></math>, <math id="S3.SS3.SSS1.p3.4.m3.1" class="ltx_Math" alttext="T_{\mathbb{C}}^{d}" display="inline"><semantics id="S3.SS3.SSS1.p3.4.m3.1a"><msubsup id="S3.SS3.SSS1.p3.4.m3.1.1" xref="S3.SS3.SSS1.p3.4.m3.1.1.cmml"><mi id="S3.SS3.SSS1.p3.4.m3.1.1.2.2" xref="S3.SS3.SSS1.p3.4.m3.1.1.2.2.cmml">T</mi><mi id="S3.SS3.SSS1.p3.4.m3.1.1.2.3" xref="S3.SS3.SSS1.p3.4.m3.1.1.2.3.cmml">ℂ</mi><mi id="S3.SS3.SSS1.p3.4.m3.1.1.3" xref="S3.SS3.SSS1.p3.4.m3.1.1.3.cmml">d</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p3.4.m3.1b"><apply id="S3.SS3.SSS1.p3.4.m3.1.1.cmml" xref="S3.SS3.SSS1.p3.4.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p3.4.m3.1.1.1.cmml" xref="S3.SS3.SSS1.p3.4.m3.1.1">superscript</csymbol><apply id="S3.SS3.SSS1.p3.4.m3.1.1.2.cmml" xref="S3.SS3.SSS1.p3.4.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p3.4.m3.1.1.2.1.cmml" xref="S3.SS3.SSS1.p3.4.m3.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.p3.4.m3.1.1.2.2.cmml" xref="S3.SS3.SSS1.p3.4.m3.1.1.2.2">𝑇</ci><ci id="S3.SS3.SSS1.p3.4.m3.1.1.2.3.cmml" xref="S3.SS3.SSS1.p3.4.m3.1.1.2.3">ℂ</ci></apply><ci id="S3.SS3.SSS1.p3.4.m3.1.1.3.cmml" xref="S3.SS3.SSS1.p3.4.m3.1.1.3">𝑑</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p3.4.m3.1c">T_{\mathbb{C}}^{d}</annotation></semantics></math>, <math id="S3.SS3.SSS1.p3.5.m4.1" class="ltx_Math" alttext="T_{\mathbb{C}}^{u}" display="inline"><semantics id="S3.SS3.SSS1.p3.5.m4.1a"><msubsup id="S3.SS3.SSS1.p3.5.m4.1.1" xref="S3.SS3.SSS1.p3.5.m4.1.1.cmml"><mi id="S3.SS3.SSS1.p3.5.m4.1.1.2.2" xref="S3.SS3.SSS1.p3.5.m4.1.1.2.2.cmml">T</mi><mi id="S3.SS3.SSS1.p3.5.m4.1.1.2.3" xref="S3.SS3.SSS1.p3.5.m4.1.1.2.3.cmml">ℂ</mi><mi id="S3.SS3.SSS1.p3.5.m4.1.1.3" xref="S3.SS3.SSS1.p3.5.m4.1.1.3.cmml">u</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p3.5.m4.1b"><apply id="S3.SS3.SSS1.p3.5.m4.1.1.cmml" xref="S3.SS3.SSS1.p3.5.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p3.5.m4.1.1.1.cmml" xref="S3.SS3.SSS1.p3.5.m4.1.1">superscript</csymbol><apply id="S3.SS3.SSS1.p3.5.m4.1.1.2.cmml" xref="S3.SS3.SSS1.p3.5.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p3.5.m4.1.1.2.1.cmml" xref="S3.SS3.SSS1.p3.5.m4.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.p3.5.m4.1.1.2.2.cmml" xref="S3.SS3.SSS1.p3.5.m4.1.1.2.2">𝑇</ci><ci id="S3.SS3.SSS1.p3.5.m4.1.1.2.3.cmml" xref="S3.SS3.SSS1.p3.5.m4.1.1.2.3">ℂ</ci></apply><ci id="S3.SS3.SSS1.p3.5.m4.1.1.3.cmml" xref="S3.SS3.SSS1.p3.5.m4.1.1.3">𝑢</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p3.5.m4.1c">T_{\mathbb{C}}^{u}</annotation></semantics></math>, and <math id="S3.SS3.SSS1.p3.6.m5.1" class="ltx_Math" alttext="T_{agg}" display="inline"><semantics id="S3.SS3.SSS1.p3.6.m5.1a"><msub id="S3.SS3.SSS1.p3.6.m5.1.1" xref="S3.SS3.SSS1.p3.6.m5.1.1.cmml"><mi id="S3.SS3.SSS1.p3.6.m5.1.1.2" xref="S3.SS3.SSS1.p3.6.m5.1.1.2.cmml">T</mi><mrow id="S3.SS3.SSS1.p3.6.m5.1.1.3" xref="S3.SS3.SSS1.p3.6.m5.1.1.3.cmml"><mi id="S3.SS3.SSS1.p3.6.m5.1.1.3.2" xref="S3.SS3.SSS1.p3.6.m5.1.1.3.2.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.p3.6.m5.1.1.3.1" xref="S3.SS3.SSS1.p3.6.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS3.SSS1.p3.6.m5.1.1.3.3" xref="S3.SS3.SSS1.p3.6.m5.1.1.3.3.cmml">g</mi><mo lspace="0em" rspace="0em" id="S3.SS3.SSS1.p3.6.m5.1.1.3.1a" xref="S3.SS3.SSS1.p3.6.m5.1.1.3.1.cmml">​</mo><mi id="S3.SS3.SSS1.p3.6.m5.1.1.3.4" xref="S3.SS3.SSS1.p3.6.m5.1.1.3.4.cmml">g</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS1.p3.6.m5.1b"><apply id="S3.SS3.SSS1.p3.6.m5.1.1.cmml" xref="S3.SS3.SSS1.p3.6.m5.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS1.p3.6.m5.1.1.1.cmml" xref="S3.SS3.SSS1.p3.6.m5.1.1">subscript</csymbol><ci id="S3.SS3.SSS1.p3.6.m5.1.1.2.cmml" xref="S3.SS3.SSS1.p3.6.m5.1.1.2">𝑇</ci><apply id="S3.SS3.SSS1.p3.6.m5.1.1.3.cmml" xref="S3.SS3.SSS1.p3.6.m5.1.1.3"><times id="S3.SS3.SSS1.p3.6.m5.1.1.3.1.cmml" xref="S3.SS3.SSS1.p3.6.m5.1.1.3.1"></times><ci id="S3.SS3.SSS1.p3.6.m5.1.1.3.2.cmml" xref="S3.SS3.SSS1.p3.6.m5.1.1.3.2">𝑎</ci><ci id="S3.SS3.SSS1.p3.6.m5.1.1.3.3.cmml" xref="S3.SS3.SSS1.p3.6.m5.1.1.3.3">𝑔</ci><ci id="S3.SS3.SSS1.p3.6.m5.1.1.3.4.cmml" xref="S3.SS3.SSS1.p3.6.m5.1.1.3.4">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS1.p3.6.m5.1c">T_{agg}</annotation></semantics></math> represent the time of client selection, distribution, scheduled update and upload, and aggregation, respectively. In this manner, FedCS effectively alleviates the effects of communication heterogeneity and device heterogeneity, while maximizing the number of participants in a round and improving the training efficiency. To better deal with the deviation problem caused by statistical, communication and device heterogeneity, TiFL <cite class="ltx_cite ltx_citemacro_cite">Chai et al<span class="ltx_text">.</span> (<a href="#bib.bib21" title="" class="ltx_ref">2020a</a>)</cite> adopts an adaptive layer selection method that divides clients into different layers according to the training time and then selects clients from the same layer in each training round. <span id="S3.SS3.SSS1.p3.6.1" class="ltx_text" style="color:#000000;">Li <span id="S3.SS3.SSS1.p3.6.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib117" title="" class="ltx_ref">2020f</a>)</cite> propose a multi-layer online coordination framework for high-performance energy-efficient federated learning, MCFL, which selects suitable devices by simultaneously considering the training data volume, computing power, and runtime training behavior of each device. Wu <span id="S3.SS3.SSS1.p3.6.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Wu et al<span class="ltx_text">.</span> (<a href="#bib.bib218" title="" class="ltx_ref">2020b</a>)</cite> propose a multi-layer federated learning protocol, HybridFL, where each edge node randomly selects a subset of clients according to a specific probability distribution depending on the region slack factor. Regulating the proportion of selected clients mitigates the straggler and dropout problems caused by communication and device heterogeneity.</span></p>
</div>
</section>
<section id="S3.SS3.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.2. </span> Client Clustering</h4>

<div id="S3.SS3.SSS2.p1" class="ltx_para">
<p id="S3.SS3.SSS2.p1.1" class="ltx_p">The model performance for all clients may not be satisfactory if the entire federated system shares one global model. Therefore, many existing approaches <cite class="ltx_cite ltx_citemacro_cite">Sattler et al<span class="ltx_text">.</span> (<a href="#bib.bib181" title="" class="ltx_ref">2020b</a>); Ruan and Joe-Wong (<a href="#bib.bib178" title="" class="ltx_ref">2022</a>)</cite> perform the personalized clustering of all clients by considering the similarities of the data distributions, the local models and the parameter updates of different clients (Fig. <a href="#S3.F11" title="Figure 11 ‣ 3.2.3. Architecture Sharing ‣ 3.2. Model-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>).</p>
</div>
<div id="S3.SS3.SSS2.p2" class="ltx_para">
<p id="S3.SS3.SSS2.p2.6" class="ltx_p">Briggs <span id="S3.SS3.SSS2.p2.6.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Briggs et al<span class="ltx_text">.</span> (<a href="#bib.bib16" title="" class="ltx_ref">2020</a>)</cite> aim to decrease the number of communication rounds required to reach convergence while improving the test accuracy. To this end, a hierarchical clustering step is introduced to separate client clusters by the similarity of client updates to the global joint model. In addition, Xie <span id="S3.SS3.SSS2.p2.6.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Xie et al<span class="ltx_text">.</span> (<a href="#bib.bib221" title="" class="ltx_ref">2020</a>)</cite> leverage a novel multi-center aggregation mechanism to address the problem of statistical heterogeneity. It utilizes a distance-based multi-center loss function to minimize the distance between a local model and its nearest global model, while constraining the variations in the local model updates. The local models <math id="S3.SS3.SSS2.p2.1.m1.1" class="ltx_Math" alttext="\{\theta_{m}\}_{m=1}^{M}" display="inline"><semantics id="S3.SS3.SSS2.p2.1.m1.1a"><msubsup id="S3.SS3.SSS2.p2.1.m1.1.1" xref="S3.SS3.SSS2.p2.1.m1.1.1.cmml"><mrow id="S3.SS3.SSS2.p2.1.m1.1.1.1.1.1" xref="S3.SS3.SSS2.p2.1.m1.1.1.1.1.2.cmml"><mo stretchy="false" id="S3.SS3.SSS2.p2.1.m1.1.1.1.1.1.2" xref="S3.SS3.SSS2.p2.1.m1.1.1.1.1.2.cmml">{</mo><msub id="S3.SS3.SSS2.p2.1.m1.1.1.1.1.1.1" xref="S3.SS3.SSS2.p2.1.m1.1.1.1.1.1.1.cmml"><mi id="S3.SS3.SSS2.p2.1.m1.1.1.1.1.1.1.2" xref="S3.SS3.SSS2.p2.1.m1.1.1.1.1.1.1.2.cmml">θ</mi><mi id="S3.SS3.SSS2.p2.1.m1.1.1.1.1.1.1.3" xref="S3.SS3.SSS2.p2.1.m1.1.1.1.1.1.1.3.cmml">m</mi></msub><mo stretchy="false" id="S3.SS3.SSS2.p2.1.m1.1.1.1.1.1.3" xref="S3.SS3.SSS2.p2.1.m1.1.1.1.1.2.cmml">}</mo></mrow><mrow id="S3.SS3.SSS2.p2.1.m1.1.1.1.3" xref="S3.SS3.SSS2.p2.1.m1.1.1.1.3.cmml"><mi id="S3.SS3.SSS2.p2.1.m1.1.1.1.3.2" xref="S3.SS3.SSS2.p2.1.m1.1.1.1.3.2.cmml">m</mi><mo id="S3.SS3.SSS2.p2.1.m1.1.1.1.3.1" xref="S3.SS3.SSS2.p2.1.m1.1.1.1.3.1.cmml">=</mo><mn id="S3.SS3.SSS2.p2.1.m1.1.1.1.3.3" xref="S3.SS3.SSS2.p2.1.m1.1.1.1.3.3.cmml">1</mn></mrow><mi id="S3.SS3.SSS2.p2.1.m1.1.1.3" xref="S3.SS3.SSS2.p2.1.m1.1.1.3.cmml">M</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.1.m1.1b"><apply id="S3.SS3.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p2.1.m1.1.1.2.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1">superscript</csymbol><apply id="S3.SS3.SSS2.p2.1.m1.1.1.1.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p2.1.m1.1.1.1.2.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1">subscript</csymbol><set id="S3.SS3.SSS2.p2.1.m1.1.1.1.1.2.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1.1.1.1"><apply id="S3.SS3.SSS2.p2.1.m1.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p2.1.m1.1.1.1.1.1.1.1.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.SSS2.p2.1.m1.1.1.1.1.1.1.2.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1.1.1.1.1.2">𝜃</ci><ci id="S3.SS3.SSS2.p2.1.m1.1.1.1.1.1.1.3.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1.1.1.1.1.3">𝑚</ci></apply></set><apply id="S3.SS3.SSS2.p2.1.m1.1.1.1.3.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1.1.3"><eq id="S3.SS3.SSS2.p2.1.m1.1.1.1.3.1.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1.1.3.1"></eq><ci id="S3.SS3.SSS2.p2.1.m1.1.1.1.3.2.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1.1.3.2">𝑚</ci><cn type="integer" id="S3.SS3.SSS2.p2.1.m1.1.1.1.3.3.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1.1.3.3">1</cn></apply></apply><ci id="S3.SS3.SSS2.p2.1.m1.1.1.3.cmml" xref="S3.SS3.SSS2.p2.1.m1.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.1.m1.1c">\{\theta_{m}\}_{m=1}^{M}</annotation></semantics></math> are divided into <math id="S3.SS3.SSS2.p2.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S3.SS3.SSS2.p2.2.m2.1a"><mi id="S3.SS3.SSS2.p2.2.m2.1.1" xref="S3.SS3.SSS2.p2.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.2.m2.1b"><ci id="S3.SS3.SSS2.p2.2.m2.1.1.cmml" xref="S3.SS3.SSS2.p2.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.2.m2.1c">K</annotation></semantics></math> clusters, <span id="S3.SS3.SSS2.p2.6.3" class="ltx_text ltx_font_italic">i.e.</span> cluster <math id="S3.SS3.SSS2.p2.3.m3.1" class="ltx_Math" alttext="1" display="inline"><semantics id="S3.SS3.SSS2.p2.3.m3.1a"><mn id="S3.SS3.SSS2.p2.3.m3.1.1" xref="S3.SS3.SSS2.p2.3.m3.1.1.cmml">1</mn><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.3.m3.1b"><cn type="integer" id="S3.SS3.SSS2.p2.3.m3.1.1.cmml" xref="S3.SS3.SSS2.p2.3.m3.1.1">1</cn></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.3.m3.1c">1</annotation></semantics></math>,…, cluster <math id="S3.SS3.SSS2.p2.4.m4.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS3.SSS2.p2.4.m4.1a"><mi id="S3.SS3.SSS2.p2.4.m4.1.1" xref="S3.SS3.SSS2.p2.4.m4.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.4.m4.1b"><ci id="S3.SS3.SSS2.p2.4.m4.1.1.cmml" xref="S3.SS3.SSS2.p2.4.m4.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.4.m4.1c">k</annotation></semantics></math>. The cluster <math id="S3.SS3.SSS2.p2.5.m5.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS3.SSS2.p2.5.m5.1a"><mi id="S3.SS3.SSS2.p2.5.m5.1.1" xref="S3.SS3.SSS2.p2.5.m5.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.5.m5.1b"><ci id="S3.SS3.SSS2.p2.5.m5.1.1.cmml" xref="S3.SS3.SSS2.p2.5.m5.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.5.m5.1c">k</annotation></semantics></math> has an aggregated model <math id="S3.SS3.SSS2.p2.6.m6.1" class="ltx_Math" alttext="\tilde{\theta}^{k}" display="inline"><semantics id="S3.SS3.SSS2.p2.6.m6.1a"><msup id="S3.SS3.SSS2.p2.6.m6.1.1" xref="S3.SS3.SSS2.p2.6.m6.1.1.cmml"><mover accent="true" id="S3.SS3.SSS2.p2.6.m6.1.1.2" xref="S3.SS3.SSS2.p2.6.m6.1.1.2.cmml"><mi id="S3.SS3.SSS2.p2.6.m6.1.1.2.2" xref="S3.SS3.SSS2.p2.6.m6.1.1.2.2.cmml">θ</mi><mo id="S3.SS3.SSS2.p2.6.m6.1.1.2.1" xref="S3.SS3.SSS2.p2.6.m6.1.1.2.1.cmml">~</mo></mover><mi id="S3.SS3.SSS2.p2.6.m6.1.1.3" xref="S3.SS3.SSS2.p2.6.m6.1.1.3.cmml">k</mi></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.6.m6.1b"><apply id="S3.SS3.SSS2.p2.6.m6.1.1.cmml" xref="S3.SS3.SSS2.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p2.6.m6.1.1.1.cmml" xref="S3.SS3.SSS2.p2.6.m6.1.1">superscript</csymbol><apply id="S3.SS3.SSS2.p2.6.m6.1.1.2.cmml" xref="S3.SS3.SSS2.p2.6.m6.1.1.2"><ci id="S3.SS3.SSS2.p2.6.m6.1.1.2.1.cmml" xref="S3.SS3.SSS2.p2.6.m6.1.1.2.1">~</ci><ci id="S3.SS3.SSS2.p2.6.m6.1.1.2.2.cmml" xref="S3.SS3.SSS2.p2.6.m6.1.1.2.2">𝜃</ci></apply><ci id="S3.SS3.SSS2.p2.6.m6.1.1.3.cmml" xref="S3.SS3.SSS2.p2.6.m6.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.6.m6.1c">\tilde{\theta}^{k}</annotation></semantics></math> of multiple local models, and the multi-center loss function can be formulated as:</p>
<table id="S3.E10" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S3.E10X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_eqn_cell"></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math id="S3.E10X.2.1.1.m1.1" class="ltx_Math" alttext="\displaystyle\min_{\tilde{\theta^{k}}}\frac{1}{M}\sum_{k=1}^{K}\sum_{m=1}^{M}r_{m}^{k}Dist(\theta_{m},\tilde{\theta}^{k})," display="inline"><semantics id="S3.E10X.2.1.1.m1.1a"><mrow id="S3.E10X.2.1.1.m1.1.1.1" xref="S3.E10X.2.1.1.m1.1.1.1.1.cmml"><mrow id="S3.E10X.2.1.1.m1.1.1.1.1" xref="S3.E10X.2.1.1.m1.1.1.1.1.cmml"><mrow id="S3.E10X.2.1.1.m1.1.1.1.1.4" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.cmml"><munder id="S3.E10X.2.1.1.m1.1.1.1.1.4.1" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.1.cmml"><mi id="S3.E10X.2.1.1.m1.1.1.1.1.4.1.2" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.1.2.cmml">min</mi><mover accent="true" id="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3.cmml"><msup id="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3.2" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3.2.cmml"><mi id="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3.2.2" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3.2.2.cmml">θ</mi><mi id="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3.2.3" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3.2.3.cmml">k</mi></msup><mo id="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3.1" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3.1.cmml">~</mo></mover></munder><mo lspace="0.167em" id="S3.E10X.2.1.1.m1.1.1.1.1.4a" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.cmml">⁡</mo><mstyle displaystyle="true" id="S3.E10X.2.1.1.m1.1.1.1.1.4.2" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.2.cmml"><mfrac id="S3.E10X.2.1.1.m1.1.1.1.1.4.2a" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.2.cmml"><mn id="S3.E10X.2.1.1.m1.1.1.1.1.4.2.2" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.2.2.cmml">1</mn><mi id="S3.E10X.2.1.1.m1.1.1.1.1.4.2.3" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.2.3.cmml">M</mi></mfrac></mstyle></mrow><mo lspace="0em" rspace="0em" id="S3.E10X.2.1.1.m1.1.1.1.1.3" xref="S3.E10X.2.1.1.m1.1.1.1.1.3.cmml">​</mo><mrow id="S3.E10X.2.1.1.m1.1.1.1.1.2" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.cmml"><mstyle displaystyle="true" id="S3.E10X.2.1.1.m1.1.1.1.1.2.3" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.3.cmml"><munderover id="S3.E10X.2.1.1.m1.1.1.1.1.2.3a" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.3.cmml"><mo movablelimits="false" id="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.2" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.2.cmml">∑</mo><mrow id="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.3" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.3.cmml"><mi id="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.3.2" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.3.2.cmml">k</mi><mo id="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.3.1" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.3.1.cmml">=</mo><mn id="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.3.3" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.3.3.cmml">1</mn></mrow><mi id="S3.E10X.2.1.1.m1.1.1.1.1.2.3.3" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.3.3.cmml">K</mi></munderover></mstyle><mrow id="S3.E10X.2.1.1.m1.1.1.1.1.2.2" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.cmml"><mstyle displaystyle="true" id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.cmml"><munderover id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3a" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.cmml"><mo movablelimits="false" id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.2" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.2.cmml">∑</mo><mrow id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.3" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.3.cmml"><mi id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.3.2" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.3.2.cmml">m</mi><mo id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.3.1" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.3.1.cmml">=</mo><mn id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.3.3" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.3.3.cmml">1</mn></mrow><mi id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.3" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.3.cmml">M</mi></munderover></mstyle><mrow id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.cmml"><msubsup id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4.cmml"><mi id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4.2.2" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4.2.2.cmml">r</mi><mi id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4.2.3" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4.2.3.cmml">m</mi><mi id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4.3" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4.3.cmml">k</mi></msubsup><mo lspace="0em" rspace="0em" id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.3" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.3.cmml">​</mo><mi id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.5" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.5.cmml">D</mi><mo lspace="0em" rspace="0em" id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.3a" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.3.cmml">​</mo><mi id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.6" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.6.cmml">i</mi><mo lspace="0em" rspace="0em" id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.3b" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.3.cmml">​</mo><mi id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.7" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.7.cmml">s</mi><mo lspace="0em" rspace="0em" id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.3c" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.3.cmml">​</mo><mi id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.8" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.8.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.3d" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.3.cmml">​</mo><mrow id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.3.cmml"><mo stretchy="false" id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.3" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.3.cmml">(</mo><msub id="S3.E10X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1" xref="S3.E10X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E10X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E10X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml">θ</mi><mi id="S3.E10X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3" xref="S3.E10X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml">m</mi></msub><mo id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.4" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.3.cmml">,</mo><msup id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2.cmml"><mover accent="true" id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2.2" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2.2.cmml"><mi id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2.2.2" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2.2.2.cmml">θ</mi><mo id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2.2.1" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2.2.1.cmml">~</mo></mover><mi id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2.3" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2.3.cmml">k</mi></msup><mo stretchy="false" id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.5" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><mo id="S3.E10X.2.1.1.m1.1.1.1.2" xref="S3.E10X.2.1.1.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E10X.2.1.1.m1.1b"><apply id="S3.E10X.2.1.1.m1.1.1.1.1.cmml" xref="S3.E10X.2.1.1.m1.1.1.1"><times id="S3.E10X.2.1.1.m1.1.1.1.1.3.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.3"></times><apply id="S3.E10X.2.1.1.m1.1.1.1.1.4.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.4"><apply id="S3.E10X.2.1.1.m1.1.1.1.1.4.1.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.1"><csymbol cd="ambiguous" id="S3.E10X.2.1.1.m1.1.1.1.1.4.1.1.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.1">subscript</csymbol><min id="S3.E10X.2.1.1.m1.1.1.1.1.4.1.2.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.1.2"></min><apply id="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3"><ci id="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3.1.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3.1">~</ci><apply id="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3.2.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3.2"><csymbol cd="ambiguous" id="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3.2.1.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3.2">superscript</csymbol><ci id="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3.2.2.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3.2.2">𝜃</ci><ci id="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3.2.3.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.1.3.2.3">𝑘</ci></apply></apply></apply><apply id="S3.E10X.2.1.1.m1.1.1.1.1.4.2.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.2"><divide id="S3.E10X.2.1.1.m1.1.1.1.1.4.2.1.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.2"></divide><cn type="integer" id="S3.E10X.2.1.1.m1.1.1.1.1.4.2.2.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.2.2">1</cn><ci id="S3.E10X.2.1.1.m1.1.1.1.1.4.2.3.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.4.2.3">𝑀</ci></apply></apply><apply id="S3.E10X.2.1.1.m1.1.1.1.1.2.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2"><apply id="S3.E10X.2.1.1.m1.1.1.1.1.2.3.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E10X.2.1.1.m1.1.1.1.1.2.3.1.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.3">superscript</csymbol><apply id="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.1.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.3">subscript</csymbol><sum id="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.2.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.2"></sum><apply id="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.3.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.3"><eq id="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.3.1.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.3.1"></eq><ci id="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.3.2.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.3.2">𝑘</ci><cn type="integer" id="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.3.3.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.3.2.3.3">1</cn></apply></apply><ci id="S3.E10X.2.1.1.m1.1.1.1.1.2.3.3.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.3.3">𝐾</ci></apply><apply id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2"><apply id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.1.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3">superscript</csymbol><apply id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3"><csymbol cd="ambiguous" id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.1.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3">subscript</csymbol><sum id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.2.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.2"></sum><apply id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.3.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.3"><eq id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.3.1.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.3.1"></eq><ci id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.3.2.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.3.2">𝑚</ci><cn type="integer" id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.3.3.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.2.3.3">1</cn></apply></apply><ci id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.3.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.3.3">𝑀</ci></apply><apply id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2"><times id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.3.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.3"></times><apply id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4"><csymbol cd="ambiguous" id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4.1.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4">superscript</csymbol><apply id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4.2.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4"><csymbol cd="ambiguous" id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4.2.1.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4">subscript</csymbol><ci id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4.2.2.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4.2.2">𝑟</ci><ci id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4.2.3.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4.2.3">𝑚</ci></apply><ci id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4.3.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.4.3">𝑘</ci></apply><ci id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.5.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.5">𝐷</ci><ci id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.6.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.6">𝑖</ci><ci id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.7.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.7">𝑠</ci><ci id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.8.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.8">𝑡</ci><interval closure="open" id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2"><apply id="S3.E10X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E10X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E10X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.2">𝜃</ci><ci id="S3.E10X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.1.1.1.1.1.1.3">𝑚</ci></apply><apply id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2.1.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2">superscript</csymbol><apply id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2.2.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2.2"><ci id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2.2.1.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2.2.1">~</ci><ci id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2.2.2.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2.2.2">𝜃</ci></apply><ci id="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2.3.cmml" xref="S3.E10X.2.1.1.m1.1.1.1.1.2.2.2.2.2.2.3">𝑘</ci></apply></interval></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E10X.2.1.1.m1.1c">\displaystyle\min_{\tilde{\theta^{k}}}\frac{1}{M}\sum_{k=1}^{K}\sum_{m=1}^{M}r_{m}^{k}Dist(\theta_{m},\tilde{\theta}^{k}),</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(10)</span></td>
</tr>
</tbody>
</table>
<p id="S3.SS3.SSS2.p2.9" class="ltx_p">where <math id="S3.SS3.SSS2.p2.7.m1.1" class="ltx_Math" alttext="r_{m}^{k}" display="inline"><semantics id="S3.SS3.SSS2.p2.7.m1.1a"><msubsup id="S3.SS3.SSS2.p2.7.m1.1.1" xref="S3.SS3.SSS2.p2.7.m1.1.1.cmml"><mi id="S3.SS3.SSS2.p2.7.m1.1.1.2.2" xref="S3.SS3.SSS2.p2.7.m1.1.1.2.2.cmml">r</mi><mi id="S3.SS3.SSS2.p2.7.m1.1.1.2.3" xref="S3.SS3.SSS2.p2.7.m1.1.1.2.3.cmml">m</mi><mi id="S3.SS3.SSS2.p2.7.m1.1.1.3" xref="S3.SS3.SSS2.p2.7.m1.1.1.3.cmml">k</mi></msubsup><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.7.m1.1b"><apply id="S3.SS3.SSS2.p2.7.m1.1.1.cmml" xref="S3.SS3.SSS2.p2.7.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p2.7.m1.1.1.1.cmml" xref="S3.SS3.SSS2.p2.7.m1.1.1">superscript</csymbol><apply id="S3.SS3.SSS2.p2.7.m1.1.1.2.cmml" xref="S3.SS3.SSS2.p2.7.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS2.p2.7.m1.1.1.2.1.cmml" xref="S3.SS3.SSS2.p2.7.m1.1.1">subscript</csymbol><ci id="S3.SS3.SSS2.p2.7.m1.1.1.2.2.cmml" xref="S3.SS3.SSS2.p2.7.m1.1.1.2.2">𝑟</ci><ci id="S3.SS3.SSS2.p2.7.m1.1.1.2.3.cmml" xref="S3.SS3.SSS2.p2.7.m1.1.1.2.3">𝑚</ci></apply><ci id="S3.SS3.SSS2.p2.7.m1.1.1.3.cmml" xref="S3.SS3.SSS2.p2.7.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.7.m1.1c">r_{m}^{k}</annotation></semantics></math> represents the client <math id="S3.SS3.SSS2.p2.8.m2.1" class="ltx_Math" alttext="m" display="inline"><semantics id="S3.SS3.SSS2.p2.8.m2.1a"><mi id="S3.SS3.SSS2.p2.8.m2.1.1" xref="S3.SS3.SSS2.p2.8.m2.1.1.cmml">m</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.8.m2.1b"><ci id="S3.SS3.SSS2.p2.8.m2.1.1.cmml" xref="S3.SS3.SSS2.p2.8.m2.1.1">𝑚</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.8.m2.1c">m</annotation></semantics></math> is assigned to the cluster <math id="S3.SS3.SSS2.p2.9.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS3.SSS2.p2.9.m3.1a"><mi id="S3.SS3.SSS2.p2.9.m3.1.1" xref="S3.SS3.SSS2.p2.9.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS2.p2.9.m3.1b"><ci id="S3.SS3.SSS2.p2.9.m3.1.1.cmml" xref="S3.SS3.SSS2.p2.9.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS2.p2.9.m3.1c">k</annotation></semantics></math>. Then they propose FeSEM, which employs Stochastic Expectation Maximization (SEM) <cite class="ltx_cite ltx_citemacro_cite">Cappé and Moulines (<a href="#bib.bib19" title="" class="ltx_ref">2009</a>)</cite> optimization to calculate the distance between the local models and the cluster centers to ensure that an optimal match can be derived. To alleviate the high communication cost incurred by clustering, FedFMC <cite class="ltx_cite ltx_citemacro_cite">Kopparapu and Lin (<a href="#bib.bib106" title="" class="ltx_ref">2020</a>)</cite> dynamically groups devices of similar prototypes in certain epochs and then merges them into a single model. To improve the clustering efficiency, FedGroup <cite class="ltx_cite ltx_citemacro_cite">Duan et al<span class="ltx_text">.</span> (<a href="#bib.bib45" title="" class="ltx_ref">2021</a>)</cite> designs a Euclidean distance of Decomposed Cosine similarity (EDC) to perform clustering based on the similarities between the optimization directions of the clients. A novel method called Clustered Federated Learning (CFL) <cite class="ltx_cite ltx_citemacro_cite">Sattler et al<span class="ltx_text">.</span> (<a href="#bib.bib181" title="" class="ltx_ref">2020b</a>)</cite> measures the similarity between the data distributions of different clients in terms of the cosine similarity between their gradient updates. The above operations can effectively identify the cluster structure, and thus clients with similar data can benefit from one another, while weakening harmful interference between clients with different data. Other methods measure the similarity of the models by comparing their loss values. For example, Iterative Federated Clustering Algorithm (IFCA) <cite class="ltx_cite ltx_citemacro_cite">Ghosh et al<span class="ltx_text">.</span> (<a href="#bib.bib61" title="" class="ltx_ref">2020</a>)</cite> minimizes the loss functions by alternately optimizing the cluster model parameters through gradient descent while estimating the client’s cluster identity. <span id="S3.SS3.SSS2.p2.9.1" class="ltx_text" style="color:#000000;">Lim <span id="S3.SS3.SSS2.p2.9.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Lim et al<span class="ltx_text">.</span> (<a href="#bib.bib131" title="" class="ltx_ref">2021a</a>, <a href="#bib.bib132" title="" class="ltx_ref">b</a>)</cite> propose a hierarchical federated learning framework to solve a two-level resource allocation and incentive mechanism design problem. At the edge layer, edge devices choose any cluster to join, and intermediate nodes provide rewards for the participation of edge devices. In the cloud layer, each intermediate node chooses any server, and the servers have to compete with each other for the service of the intermediate node. Feraudo <span id="S3.SS3.SSS2.p2.9.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Feraudo et al<span class="ltx_text">.</span> (<a href="#bib.bib51" title="" class="ltx_ref">2020</a>)</cite> propose CoLearn, which leverages manufacturer usage description profiles of IoT devices to cluster devices with similar learning tasks and network requirements. CoLearn also uses a publish/subscribe messaging system to coordinate the learning process between edge devices and cloud servers.</span></p>
</div>
<div id="S3.SS3.SSS2.p3" class="ltx_para">
<p id="S3.SS3.SSS2.p3.1" class="ltx_p">Several recent methods aim to improve the attack robustness of federated learning systems through client clustering. Sattler <span id="S3.SS3.SSS2.p3.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Sattler et al<span class="ltx_text">.</span> (<a href="#bib.bib182" title="" class="ltx_ref">2020c</a>)</cite> apply Clustered Federated Learning (CFL) to the Byzantine scenario, in which a subset of clients interferes with federated training in a detrimental way. A large number of clients are declared benign, and other clients are declared adversarial and excluded from training. This method decreases the computation cost while enhancing the robustness and flexibility of the federated framework. However, it is vulnerable to backdoor attacks (including data poisoning and model poisoning) in federated learning scenarios. To address this problem, Nguyen <span id="S3.SS3.SSS2.p3.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Nguyen et al<span class="ltx_text">.</span> (<a href="#bib.bib164" title="" class="ltx_ref">2022b</a>)</cite> propose FLAME, which does not rely on the underlying data distributions for benign and adversarial datasets. FLAME detects adversarial model updates through a clustering strategy that limits the noise scale of backdoor noise removal. To improve the performance of the aggregated model, FLAME implements a weighting method to limit the adversary models.</p>
</div>
</section>
<section id="S3.SS3.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.3.3. </span> <span id="S3.SS3.SSS3.1.1" class="ltx_text" style="color:#000000;">Decentralized Communication</span>
</h4>

<div id="S3.SS3.SSS3.p1" class="ltx_para">
<p id="S3.SS3.SSS3.p1.1" class="ltx_p"><span id="S3.SS3.SSS3.p1.1.1" class="ltx_text" style="color:#000000;">The general federated learning algorithm relies on a central server, which requires all clients to trust a central institution, and the failure of this institution will destroy the entire federated learning process. Therefore, some algorithms adopt decentralized communication <cite class="ltx_cite ltx_citemacro_cite">Shi et al<span class="ltx_text">.</span> (<a href="#bib.bib189" title="" class="ltx_ref">2023b</a>)</cite>, which conducts peer-to-peer communication between various devices without relying on a central server (Fig. <a href="#S3.F11" title="Figure 11 ‣ 3.2.3. Architecture Sharing ‣ 3.2. Model-Level Methods ‣ 3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>).</span></p>
</div>
<div id="S3.SS3.SSS3.p2" class="ltx_para">
<p id="S3.SS3.SSS3.p2.11" class="ltx_p"><span id="S3.SS3.SSS3.p2.11.11" class="ltx_text" style="color:#000000;">Roy <span id="S3.SS3.SSS3.p2.11.11.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Roy et al<span class="ltx_text">.</span> (<a href="#bib.bib177" title="" class="ltx_ref">2019</a>)</cite> propose a peer-to-peer federated learning framework without a central server, BrainTorrent, that is, direct communication between clients. Specifically, in each round, a client is randomly selected as a temporary server, and then cooperates with other clients that have completed the model update for collaborative update. In this way, any client can dynamically start an update process at any time. Lalitha <span id="S3.SS3.SSS3.p2.11.11.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Lalitha et al<span class="ltx_text">.</span> (<a href="#bib.bib111" title="" class="ltx_ref">2018</a>)</cite> propose a fully distributed federated learning algorithm, where clients can only communicate with their one-hop neighbors without relying on a centralized server. Clients update their local models by aggregating information obtained from one-hop neighbors to obtain an optimal resulting model. To sufficiently utilize the bandwidth capacity between clients while maintaining convergence performance, some decentralized federated training algorithms <cite class="ltx_cite ltx_citemacro_cite">Hu et al<span class="ltx_text">.</span> (<a href="#bib.bib80" title="" class="ltx_ref">2019</a>); Tang et al<span class="ltx_text">.</span> (<a href="#bib.bib202" title="" class="ltx_ref">2022b</a>)</cite> are designed based on the Gossip protocol. For example, in GossipFL <cite class="ltx_cite ltx_citemacro_cite">Tang et al<span class="ltx_text">.</span> (<a href="#bib.bib202" title="" class="ltx_ref">2022b</a>)</cite>, each client dynamically selects a peer client based on its network bandwidth to fully utilize the global bandwidth resource. Then, the client exchanges a highly compressed model with its peer client, reducing communication traffic. Hu <span id="S3.SS3.SSS3.p2.11.11.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Hu et al<span class="ltx_text">.</span> (<a href="#bib.bib80" title="" class="ltx_ref">2019</a>)</cite> propose a segmented gossip approach, Combo, where the client <math id="S3.SS3.SSS3.p2.1.1.m1.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS3.SSS3.p2.1.1.m1.1a"><mi mathcolor="#000000" id="S3.SS3.SSS3.p2.1.1.m1.1.1" xref="S3.SS3.SSS3.p2.1.1.m1.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.1.1.m1.1b"><ci id="S3.SS3.SSS3.p2.1.1.m1.1.1.cmml" xref="S3.SS3.SSS3.p2.1.1.m1.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.1.1.m1.1c">k</annotation></semantics></math> divides the local model <math id="S3.SS3.SSS3.p2.2.2.m2.1" class="ltx_Math" alttext="W_{K}" display="inline"><semantics id="S3.SS3.SSS3.p2.2.2.m2.1a"><msub id="S3.SS3.SSS3.p2.2.2.m2.1.1" xref="S3.SS3.SSS3.p2.2.2.m2.1.1.cmml"><mi mathcolor="#000000" id="S3.SS3.SSS3.p2.2.2.m2.1.1.2" xref="S3.SS3.SSS3.p2.2.2.m2.1.1.2.cmml">W</mi><mi mathcolor="#000000" id="S3.SS3.SSS3.p2.2.2.m2.1.1.3" xref="S3.SS3.SSS3.p2.2.2.m2.1.1.3.cmml">K</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.2.2.m2.1b"><apply id="S3.SS3.SSS3.p2.2.2.m2.1.1.cmml" xref="S3.SS3.SSS3.p2.2.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS3.p2.2.2.m2.1.1.1.cmml" xref="S3.SS3.SSS3.p2.2.2.m2.1.1">subscript</csymbol><ci id="S3.SS3.SSS3.p2.2.2.m2.1.1.2.cmml" xref="S3.SS3.SSS3.p2.2.2.m2.1.1.2">𝑊</ci><ci id="S3.SS3.SSS3.p2.2.2.m2.1.1.3.cmml" xref="S3.SS3.SSS3.p2.2.2.m2.1.1.3">𝐾</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.2.2.m2.1c">W_{K}</annotation></semantics></math> into <math id="S3.SS3.SSS3.p2.3.3.m3.1" class="ltx_Math" alttext="S" display="inline"><semantics id="S3.SS3.SSS3.p2.3.3.m3.1a"><mi mathcolor="#000000" id="S3.SS3.SSS3.p2.3.3.m3.1.1" xref="S3.SS3.SSS3.p2.3.3.m3.1.1.cmml">S</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.3.3.m3.1b"><ci id="S3.SS3.SSS3.p2.3.3.m3.1.1.cmml" xref="S3.SS3.SSS3.p2.3.3.m3.1.1">𝑆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.3.3.m3.1c">S</annotation></semantics></math> segments, and then randomly selects some clients to transfer the model segments. <math id="S3.SS3.SSS3.p2.4.4.m4.1" class="ltx_Math" alttext="K_{s}" display="inline"><semantics id="S3.SS3.SSS3.p2.4.4.m4.1a"><msub id="S3.SS3.SSS3.p2.4.4.m4.1.1" xref="S3.SS3.SSS3.p2.4.4.m4.1.1.cmml"><mi mathcolor="#000000" id="S3.SS3.SSS3.p2.4.4.m4.1.1.2" xref="S3.SS3.SSS3.p2.4.4.m4.1.1.2.cmml">K</mi><mi mathcolor="#000000" id="S3.SS3.SSS3.p2.4.4.m4.1.1.3" xref="S3.SS3.SSS3.p2.4.4.m4.1.1.3.cmml">s</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.4.4.m4.1b"><apply id="S3.SS3.SSS3.p2.4.4.m4.1.1.cmml" xref="S3.SS3.SSS3.p2.4.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS3.p2.4.4.m4.1.1.1.cmml" xref="S3.SS3.SSS3.p2.4.4.m4.1.1">subscript</csymbol><ci id="S3.SS3.SSS3.p2.4.4.m4.1.1.2.cmml" xref="S3.SS3.SSS3.p2.4.4.m4.1.1.2">𝐾</ci><ci id="S3.SS3.SSS3.p2.4.4.m4.1.1.3.cmml" xref="S3.SS3.SSS3.p2.4.4.m4.1.1.3">𝑠</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.4.4.m4.1c">K_{s}</annotation></semantics></math> represents the set of clients providing segment <math id="S3.SS3.SSS3.p2.5.5.m5.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS3.SSS3.p2.5.5.m5.1a"><mi mathcolor="#000000" id="S3.SS3.SSS3.p2.5.5.m5.1.1" xref="S3.SS3.SSS3.p2.5.5.m5.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.5.5.m5.1b"><ci id="S3.SS3.SSS3.p2.5.5.m5.1.1.cmml" xref="S3.SS3.SSS3.p2.5.5.m5.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.5.5.m5.1c">s</annotation></semantics></math> with <math id="S3.SS3.SSS3.p2.6.6.m6.1" class="ltx_Math" alttext="s\in S" display="inline"><semantics id="S3.SS3.SSS3.p2.6.6.m6.1a"><mrow id="S3.SS3.SSS3.p2.6.6.m6.1.1" xref="S3.SS3.SSS3.p2.6.6.m6.1.1.cmml"><mi mathcolor="#000000" id="S3.SS3.SSS3.p2.6.6.m6.1.1.2" xref="S3.SS3.SSS3.p2.6.6.m6.1.1.2.cmml">s</mi><mo mathcolor="#000000" id="S3.SS3.SSS3.p2.6.6.m6.1.1.1" xref="S3.SS3.SSS3.p2.6.6.m6.1.1.1.cmml">∈</mo><mi mathcolor="#000000" id="S3.SS3.SSS3.p2.6.6.m6.1.1.3" xref="S3.SS3.SSS3.p2.6.6.m6.1.1.3.cmml">S</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.6.6.m6.1b"><apply id="S3.SS3.SSS3.p2.6.6.m6.1.1.cmml" xref="S3.SS3.SSS3.p2.6.6.m6.1.1"><in id="S3.SS3.SSS3.p2.6.6.m6.1.1.1.cmml" xref="S3.SS3.SSS3.p2.6.6.m6.1.1.1"></in><ci id="S3.SS3.SSS3.p2.6.6.m6.1.1.2.cmml" xref="S3.SS3.SSS3.p2.6.6.m6.1.1.2">𝑠</ci><ci id="S3.SS3.SSS3.p2.6.6.m6.1.1.3.cmml" xref="S3.SS3.SSS3.p2.6.6.m6.1.1.3">𝑆</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.6.6.m6.1c">s\in S</annotation></semantics></math> and <math id="S3.SS3.SSS3.p2.7.7.m7.1" class="ltx_Math" alttext="D_{k}" display="inline"><semantics id="S3.SS3.SSS3.p2.7.7.m7.1a"><msub id="S3.SS3.SSS3.p2.7.7.m7.1.1" xref="S3.SS3.SSS3.p2.7.7.m7.1.1.cmml"><mi mathcolor="#000000" id="S3.SS3.SSS3.p2.7.7.m7.1.1.2" xref="S3.SS3.SSS3.p2.7.7.m7.1.1.2.cmml">D</mi><mi mathcolor="#000000" id="S3.SS3.SSS3.p2.7.7.m7.1.1.3" xref="S3.SS3.SSS3.p2.7.7.m7.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.7.7.m7.1b"><apply id="S3.SS3.SSS3.p2.7.7.m7.1.1.cmml" xref="S3.SS3.SSS3.p2.7.7.m7.1.1"><csymbol cd="ambiguous" id="S3.SS3.SSS3.p2.7.7.m7.1.1.1.cmml" xref="S3.SS3.SSS3.p2.7.7.m7.1.1">subscript</csymbol><ci id="S3.SS3.SSS3.p2.7.7.m7.1.1.2.cmml" xref="S3.SS3.SSS3.p2.7.7.m7.1.1.2">𝐷</ci><ci id="S3.SS3.SSS3.p2.7.7.m7.1.1.3.cmml" xref="S3.SS3.SSS3.p2.7.7.m7.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.7.7.m7.1c">D_{k}</annotation></semantics></math> represents the private dataset of client <math id="S3.SS3.SSS3.p2.8.8.m8.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.SS3.SSS3.p2.8.8.m8.1a"><mi mathcolor="#000000" id="S3.SS3.SSS3.p2.8.8.m8.1.1" xref="S3.SS3.SSS3.p2.8.8.m8.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.8.8.m8.1b"><ci id="S3.SS3.SSS3.p2.8.8.m8.1.1.cmml" xref="S3.SS3.SSS3.p2.8.8.m8.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.8.8.m8.1c">k</annotation></semantics></math>. The segment <math id="S3.SS3.SSS3.p2.9.9.m9.1" class="ltx_Math" alttext="s" display="inline"><semantics id="S3.SS3.SSS3.p2.9.9.m9.1a"><mi mathcolor="#000000" id="S3.SS3.SSS3.p2.9.9.m9.1.1" xref="S3.SS3.SSS3.p2.9.9.m9.1.1.cmml">s</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.9.9.m9.1b"><ci id="S3.SS3.SSS3.p2.9.9.m9.1.1.cmml" xref="S3.SS3.SSS3.p2.9.9.m9.1.1">𝑠</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.9.9.m9.1c">s</annotation></semantics></math> can be aggregated with the private dataset size as the weights to get <math id="S3.SS3.SSS3.p2.10.10.m10.1" class="ltx_Math" alttext="\tilde{W}[s]" display="inline"><semantics id="S3.SS3.SSS3.p2.10.10.m10.1a"><mrow id="S3.SS3.SSS3.p2.10.10.m10.1.2" xref="S3.SS3.SSS3.p2.10.10.m10.1.2.cmml"><mover accent="true" id="S3.SS3.SSS3.p2.10.10.m10.1.2.2" xref="S3.SS3.SSS3.p2.10.10.m10.1.2.2.cmml"><mi mathcolor="#000000" id="S3.SS3.SSS3.p2.10.10.m10.1.2.2.2" xref="S3.SS3.SSS3.p2.10.10.m10.1.2.2.2.cmml">W</mi><mo mathcolor="#000000" id="S3.SS3.SSS3.p2.10.10.m10.1.2.2.1" xref="S3.SS3.SSS3.p2.10.10.m10.1.2.2.1.cmml">~</mo></mover><mo lspace="0em" rspace="0em" id="S3.SS3.SSS3.p2.10.10.m10.1.2.1" xref="S3.SS3.SSS3.p2.10.10.m10.1.2.1.cmml">​</mo><mrow id="S3.SS3.SSS3.p2.10.10.m10.1.2.3.2" xref="S3.SS3.SSS3.p2.10.10.m10.1.2.3.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S3.SS3.SSS3.p2.10.10.m10.1.2.3.2.1" xref="S3.SS3.SSS3.p2.10.10.m10.1.2.3.1.1.cmml">[</mo><mi mathcolor="#000000" id="S3.SS3.SSS3.p2.10.10.m10.1.1" xref="S3.SS3.SSS3.p2.10.10.m10.1.1.cmml">s</mi><mo mathcolor="#000000" stretchy="false" id="S3.SS3.SSS3.p2.10.10.m10.1.2.3.2.2" xref="S3.SS3.SSS3.p2.10.10.m10.1.2.3.1.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.10.10.m10.1b"><apply id="S3.SS3.SSS3.p2.10.10.m10.1.2.cmml" xref="S3.SS3.SSS3.p2.10.10.m10.1.2"><times id="S3.SS3.SSS3.p2.10.10.m10.1.2.1.cmml" xref="S3.SS3.SSS3.p2.10.10.m10.1.2.1"></times><apply id="S3.SS3.SSS3.p2.10.10.m10.1.2.2.cmml" xref="S3.SS3.SSS3.p2.10.10.m10.1.2.2"><ci id="S3.SS3.SSS3.p2.10.10.m10.1.2.2.1.cmml" xref="S3.SS3.SSS3.p2.10.10.m10.1.2.2.1">~</ci><ci id="S3.SS3.SSS3.p2.10.10.m10.1.2.2.2.cmml" xref="S3.SS3.SSS3.p2.10.10.m10.1.2.2.2">𝑊</ci></apply><apply id="S3.SS3.SSS3.p2.10.10.m10.1.2.3.1.cmml" xref="S3.SS3.SSS3.p2.10.10.m10.1.2.3.2"><csymbol cd="latexml" id="S3.SS3.SSS3.p2.10.10.m10.1.2.3.1.1.cmml" xref="S3.SS3.SSS3.p2.10.10.m10.1.2.3.2.1">delimited-[]</csymbol><ci id="S3.SS3.SSS3.p2.10.10.m10.1.1.cmml" xref="S3.SS3.SSS3.p2.10.10.m10.1.1">𝑠</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.10.10.m10.1c">\tilde{W}[s]</annotation></semantics></math>. Then, merge all aggregated segments to get the complete aggregated model <math id="S3.SS3.SSS3.p2.11.11.m11.1" class="ltx_Math" alttext="W" display="inline"><semantics id="S3.SS3.SSS3.p2.11.11.m11.1a"><mi mathcolor="#000000" id="S3.SS3.SSS3.p2.11.11.m11.1.1" xref="S3.SS3.SSS3.p2.11.11.m11.1.1.cmml">W</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.SSS3.p2.11.11.m11.1b"><ci id="S3.SS3.SSS3.p2.11.11.m11.1.1.cmml" xref="S3.SS3.SSS3.p2.11.11.m11.1.1">𝑊</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.SSS3.p2.11.11.m11.1c">W</annotation></semantics></math> as follows:</span></p>
<table id="S3.E11" class="ltx_equationgroup ltx_eqn_table">
<tbody>
<tr id="S3.E11X" class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math id="S3.E11X.2.1.1.m1.9" class="ltx_Math" alttext="\displaystyle{\color[rgb]{0,0,0}W=(\tilde{W}[1],\tilde{W}[2],...\tilde{W}[s],...\tilde{W}[S]),\tilde{W}[s]=\frac{\sum_{k\in{K_{s}}}W_{k}[s]\cdot|D_{k}|}{\sum_{k\in{K_{s}}}|D_{k}|}}." display="inline"><semantics id="S3.E11X.2.1.1.m1.9a"><mrow id="S3.E11X.2.1.1.m1.9.9.1"><mrow id="S3.E11X.2.1.1.m1.9.9.1.1.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.3.cmml"><mrow id="S3.E11X.2.1.1.m1.9.9.1.1.1.1" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.cmml"><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.6" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.6.cmml">W</mi><mo mathcolor="#000000" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.5" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.5.cmml">=</mo><mrow id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.5.cmml"><mo mathcolor="#000000" stretchy="false" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.5" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.5.cmml">(</mo><mrow id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.cmml"><mover accent="true" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.2.cmml"><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.2.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.2.2.cmml">W</mi><mo mathcolor="#000000" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.2.1" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.2.1.cmml">~</mo></mover><mo lspace="0em" rspace="0em" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.1" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.1.cmml">​</mo><mrow id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.3.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.3.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.3.2.1" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.3.1.1.cmml">[</mo><mn mathcolor="#000000" id="S3.E11X.2.1.1.m1.4.4" xref="S3.E11X.2.1.1.m1.4.4.cmml">1</mn><mo mathcolor="#000000" stretchy="false" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.3.2.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.3.1.1.cmml">]</mo></mrow></mrow><mo mathcolor="#000000" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.6" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.5.cmml">,</mo><mrow id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.cmml"><mover accent="true" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.2.cmml"><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.2.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.2.2.cmml">W</mi><mo mathcolor="#000000" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.2.1" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.2.1.cmml">~</mo></mover><mo lspace="0em" rspace="0em" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.1" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.1.cmml">​</mo><mrow id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.3.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.3.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.3.2.1" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.3.1.1.cmml">[</mo><mn mathcolor="#000000" id="S3.E11X.2.1.1.m1.5.5" xref="S3.E11X.2.1.1.m1.5.5.cmml">2</mn><mo mathcolor="#000000" stretchy="false" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.3.2.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.3.1.1.cmml">]</mo></mrow></mrow><mo mathcolor="#000000" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.7" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.5.cmml">,</mo><mrow id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.cmml"><mi mathcolor="#000000" mathvariant="normal" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.2.cmml">…</mi><mo lspace="0em" rspace="0em" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.1" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.1.cmml">​</mo><mover accent="true" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.3" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.3.cmml"><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.3.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.3.2.cmml">W</mi><mo mathcolor="#000000" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.3.1" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.3.1.cmml">~</mo></mover><mo lspace="0em" rspace="0em" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.1a" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.1.cmml">​</mo><mrow id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.4.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.4.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.4.2.1" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.4.1.1.cmml">[</mo><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.6.6" xref="S3.E11X.2.1.1.m1.6.6.cmml">s</mi><mo mathcolor="#000000" stretchy="false" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.4.2.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.4.1.1.cmml">]</mo></mrow></mrow><mo mathcolor="#000000" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.8" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.5.cmml">,</mo><mrow id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.cmml"><mi mathcolor="#000000" mathvariant="normal" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.2.cmml">…</mi><mo lspace="0em" rspace="0em" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.1" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.1.cmml">​</mo><mover accent="true" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.3" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.3.cmml"><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.3.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.3.2.cmml">W</mi><mo mathcolor="#000000" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.3.1" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.3.1.cmml">~</mo></mover><mo lspace="0em" rspace="0em" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.1a" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.1.cmml">​</mo><mrow id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.4.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.4.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.4.2.1" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.4.1.1.cmml">[</mo><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.7.7" xref="S3.E11X.2.1.1.m1.7.7.cmml">S</mi><mo mathcolor="#000000" stretchy="false" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.4.2.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.4.1.1.cmml">]</mo></mrow></mrow><mo mathcolor="#000000" stretchy="false" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.9" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.5.cmml">)</mo></mrow></mrow><mo mathcolor="#000000" id="S3.E11X.2.1.1.m1.9.9.1.1.2.3" xref="S3.E11X.2.1.1.m1.9.9.1.1.3a.cmml">,</mo><mrow id="S3.E11X.2.1.1.m1.9.9.1.1.2.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.2.2.cmml"><mrow id="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.cmml"><mover accent="true" id="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.2.cmml"><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.2.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.2.2.cmml">W</mi><mo mathcolor="#000000" id="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.2.1" xref="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.2.1.cmml">~</mo></mover><mo lspace="0em" rspace="0em" id="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.1" xref="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.1.cmml">​</mo><mrow id="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.3.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.3.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.3.2.1" xref="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.3.1.1.cmml">[</mo><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.8.8" xref="S3.E11X.2.1.1.m1.8.8.cmml">s</mi><mo mathcolor="#000000" stretchy="false" id="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.3.2.2" xref="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.3.1.1.cmml">]</mo></mrow></mrow><mo mathcolor="#000000" id="S3.E11X.2.1.1.m1.9.9.1.1.2.2.1" xref="S3.E11X.2.1.1.m1.9.9.1.1.2.2.1.cmml">=</mo><mstyle displaystyle="true" id="S3.E11X.2.1.1.m1.3.3" xref="S3.E11X.2.1.1.m1.3.3.cmml"><mfrac mathcolor="#000000" id="S3.E11X.2.1.1.m1.3.3a" xref="S3.E11X.2.1.1.m1.3.3.cmml"><mrow id="S3.E11X.2.1.1.m1.2.2.2" xref="S3.E11X.2.1.1.m1.2.2.2.cmml"><msub id="S3.E11X.2.1.1.m1.2.2.2.3" xref="S3.E11X.2.1.1.m1.2.2.2.3.cmml"><mo mathcolor="#000000" id="S3.E11X.2.1.1.m1.2.2.2.3.2" xref="S3.E11X.2.1.1.m1.2.2.2.3.2.cmml">∑</mo><mrow id="S3.E11X.2.1.1.m1.2.2.2.3.3" xref="S3.E11X.2.1.1.m1.2.2.2.3.3.cmml"><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.2.2.2.3.3.2" xref="S3.E11X.2.1.1.m1.2.2.2.3.3.2.cmml">k</mi><mo mathcolor="#000000" id="S3.E11X.2.1.1.m1.2.2.2.3.3.1" xref="S3.E11X.2.1.1.m1.2.2.2.3.3.1.cmml">∈</mo><msub id="S3.E11X.2.1.1.m1.2.2.2.3.3.3" xref="S3.E11X.2.1.1.m1.2.2.2.3.3.3.cmml"><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.2.2.2.3.3.3.2" xref="S3.E11X.2.1.1.m1.2.2.2.3.3.3.2.cmml">K</mi><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.2.2.2.3.3.3.3" xref="S3.E11X.2.1.1.m1.2.2.2.3.3.3.3.cmml">s</mi></msub></mrow></msub><mrow id="S3.E11X.2.1.1.m1.2.2.2.2" xref="S3.E11X.2.1.1.m1.2.2.2.2.cmml"><mrow id="S3.E11X.2.1.1.m1.2.2.2.2.3" xref="S3.E11X.2.1.1.m1.2.2.2.2.3.cmml"><msub id="S3.E11X.2.1.1.m1.2.2.2.2.3.2" xref="S3.E11X.2.1.1.m1.2.2.2.2.3.2.cmml"><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.2.2.2.2.3.2.2" xref="S3.E11X.2.1.1.m1.2.2.2.2.3.2.2.cmml">W</mi><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.2.2.2.2.3.2.3" xref="S3.E11X.2.1.1.m1.2.2.2.2.3.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S3.E11X.2.1.1.m1.2.2.2.2.3.1" xref="S3.E11X.2.1.1.m1.2.2.2.2.3.1.cmml">​</mo><mrow id="S3.E11X.2.1.1.m1.2.2.2.2.3.3.2" xref="S3.E11X.2.1.1.m1.2.2.2.2.3.3.1.cmml"><mo mathcolor="#000000" stretchy="false" id="S3.E11X.2.1.1.m1.2.2.2.2.3.3.2.1" xref="S3.E11X.2.1.1.m1.2.2.2.2.3.3.1.1.cmml">[</mo><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.1.1.1.1" xref="S3.E11X.2.1.1.m1.1.1.1.1.cmml">s</mi><mo mathcolor="#000000" rspace="0.055em" stretchy="false" id="S3.E11X.2.1.1.m1.2.2.2.2.3.3.2.2" xref="S3.E11X.2.1.1.m1.2.2.2.2.3.3.1.1.cmml">]</mo></mrow></mrow><mo mathcolor="#000000" rspace="0.222em" id="S3.E11X.2.1.1.m1.2.2.2.2.2" xref="S3.E11X.2.1.1.m1.2.2.2.2.2.cmml">⋅</mo><mrow id="S3.E11X.2.1.1.m1.2.2.2.2.1.1" xref="S3.E11X.2.1.1.m1.2.2.2.2.1.2.cmml"><mo mathcolor="#000000" stretchy="false" id="S3.E11X.2.1.1.m1.2.2.2.2.1.1.2" xref="S3.E11X.2.1.1.m1.2.2.2.2.1.2.1.cmml">|</mo><msub id="S3.E11X.2.1.1.m1.2.2.2.2.1.1.1" xref="S3.E11X.2.1.1.m1.2.2.2.2.1.1.1.cmml"><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.2.2.2.2.1.1.1.2" xref="S3.E11X.2.1.1.m1.2.2.2.2.1.1.1.2.cmml">D</mi><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.2.2.2.2.1.1.1.3" xref="S3.E11X.2.1.1.m1.2.2.2.2.1.1.1.3.cmml">k</mi></msub><mo mathcolor="#000000" stretchy="false" id="S3.E11X.2.1.1.m1.2.2.2.2.1.1.3" xref="S3.E11X.2.1.1.m1.2.2.2.2.1.2.1.cmml">|</mo></mrow></mrow></mrow><mrow id="S3.E11X.2.1.1.m1.3.3.3" xref="S3.E11X.2.1.1.m1.3.3.3.cmml"><msub id="S3.E11X.2.1.1.m1.3.3.3.2" xref="S3.E11X.2.1.1.m1.3.3.3.2.cmml"><mo mathcolor="#000000" id="S3.E11X.2.1.1.m1.3.3.3.2.2" xref="S3.E11X.2.1.1.m1.3.3.3.2.2.cmml">∑</mo><mrow id="S3.E11X.2.1.1.m1.3.3.3.2.3" xref="S3.E11X.2.1.1.m1.3.3.3.2.3.cmml"><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.3.3.3.2.3.2" xref="S3.E11X.2.1.1.m1.3.3.3.2.3.2.cmml">k</mi><mo mathcolor="#000000" id="S3.E11X.2.1.1.m1.3.3.3.2.3.1" xref="S3.E11X.2.1.1.m1.3.3.3.2.3.1.cmml">∈</mo><msub id="S3.E11X.2.1.1.m1.3.3.3.2.3.3" xref="S3.E11X.2.1.1.m1.3.3.3.2.3.3.cmml"><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.3.3.3.2.3.3.2" xref="S3.E11X.2.1.1.m1.3.3.3.2.3.3.2.cmml">K</mi><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.3.3.3.2.3.3.3" xref="S3.E11X.2.1.1.m1.3.3.3.2.3.3.3.cmml">s</mi></msub></mrow></msub><mrow id="S3.E11X.2.1.1.m1.3.3.3.1.1" xref="S3.E11X.2.1.1.m1.3.3.3.1.2.cmml"><mo lspace="0em" mathcolor="#000000" stretchy="false" id="S3.E11X.2.1.1.m1.3.3.3.1.1.2" xref="S3.E11X.2.1.1.m1.3.3.3.1.2.1.cmml">|</mo><msub id="S3.E11X.2.1.1.m1.3.3.3.1.1.1" xref="S3.E11X.2.1.1.m1.3.3.3.1.1.1.cmml"><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.3.3.3.1.1.1.2" xref="S3.E11X.2.1.1.m1.3.3.3.1.1.1.2.cmml">D</mi><mi mathcolor="#000000" id="S3.E11X.2.1.1.m1.3.3.3.1.1.1.3" xref="S3.E11X.2.1.1.m1.3.3.3.1.1.1.3.cmml">k</mi></msub><mo mathcolor="#000000" stretchy="false" id="S3.E11X.2.1.1.m1.3.3.3.1.1.3" xref="S3.E11X.2.1.1.m1.3.3.3.1.2.1.cmml">|</mo></mrow></mrow></mfrac></mstyle></mrow></mrow><mo lspace="0em" id="S3.E11X.2.1.1.m1.9.9.1.2">.</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E11X.2.1.1.m1.9b"><apply id="S3.E11X.2.1.1.m1.9.9.1.1.3.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.2"><csymbol cd="ambiguous" id="S3.E11X.2.1.1.m1.9.9.1.1.3a.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.2.3">formulae-sequence</csymbol><apply id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1"><eq id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.5.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.5"></eq><ci id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.6.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.6">𝑊</ci><vector id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.5.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4"><apply id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1"><times id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.1"></times><apply id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.2.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.2"><ci id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.2.1">~</ci><ci id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.2.2">𝑊</ci></apply><apply id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.3.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.3.2"><csymbol cd="latexml" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.3.1.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.1.1.1.3.2.1">delimited-[]</csymbol><cn type="integer" id="S3.E11X.2.1.1.m1.4.4.cmml" xref="S3.E11X.2.1.1.m1.4.4">1</cn></apply></apply><apply id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2"><times id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.1"></times><apply id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.2.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.2"><ci id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.2.1">~</ci><ci id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.2.2">𝑊</ci></apply><apply id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.3.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.3.2"><csymbol cd="latexml" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.3.1.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.2.2.2.3.2.1">delimited-[]</csymbol><cn type="integer" id="S3.E11X.2.1.1.m1.5.5.cmml" xref="S3.E11X.2.1.1.m1.5.5">2</cn></apply></apply><apply id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3"><times id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.1"></times><ci id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.2.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.2">…</ci><apply id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.3.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.3"><ci id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.3.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.3.1">~</ci><ci id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.3.2.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.3.2">𝑊</ci></apply><apply id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.4.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.4.2"><csymbol cd="latexml" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.4.1.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.3.3.3.4.2.1">delimited-[]</csymbol><ci id="S3.E11X.2.1.1.m1.6.6.cmml" xref="S3.E11X.2.1.1.m1.6.6">𝑠</ci></apply></apply><apply id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4"><times id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.1"></times><ci id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.2.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.2">…</ci><apply id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.3.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.3"><ci id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.3.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.3.1">~</ci><ci id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.3.2.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.3.2">𝑊</ci></apply><apply id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.4.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.4.2"><csymbol cd="latexml" id="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.4.1.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.1.1.4.4.4.4.2.1">delimited-[]</csymbol><ci id="S3.E11X.2.1.1.m1.7.7.cmml" xref="S3.E11X.2.1.1.m1.7.7">𝑆</ci></apply></apply></vector></apply><apply id="S3.E11X.2.1.1.m1.9.9.1.1.2.2.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.2.2"><eq id="S3.E11X.2.1.1.m1.9.9.1.1.2.2.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.2.2.1"></eq><apply id="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2"><times id="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.1"></times><apply id="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.2.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.2"><ci id="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.2.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.2.1">~</ci><ci id="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.2.2.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.2.2">𝑊</ci></apply><apply id="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.3.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.3.2"><csymbol cd="latexml" id="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.3.1.1.cmml" xref="S3.E11X.2.1.1.m1.9.9.1.1.2.2.2.3.2.1">delimited-[]</csymbol><ci id="S3.E11X.2.1.1.m1.8.8.cmml" xref="S3.E11X.2.1.1.m1.8.8">𝑠</ci></apply></apply><apply id="S3.E11X.2.1.1.m1.3.3.cmml" xref="S3.E11X.2.1.1.m1.3.3"><divide id="S3.E11X.2.1.1.m1.3.3.4.cmml" xref="S3.E11X.2.1.1.m1.3.3"></divide><apply id="S3.E11X.2.1.1.m1.2.2.2.cmml" xref="S3.E11X.2.1.1.m1.2.2.2"><apply id="S3.E11X.2.1.1.m1.2.2.2.3.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.3"><csymbol cd="ambiguous" id="S3.E11X.2.1.1.m1.2.2.2.3.1.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.3">subscript</csymbol><sum id="S3.E11X.2.1.1.m1.2.2.2.3.2.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.3.2"></sum><apply id="S3.E11X.2.1.1.m1.2.2.2.3.3.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.3.3"><in id="S3.E11X.2.1.1.m1.2.2.2.3.3.1.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.3.3.1"></in><ci id="S3.E11X.2.1.1.m1.2.2.2.3.3.2.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.3.3.2">𝑘</ci><apply id="S3.E11X.2.1.1.m1.2.2.2.3.3.3.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.3.3.3"><csymbol cd="ambiguous" id="S3.E11X.2.1.1.m1.2.2.2.3.3.3.1.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.3.3.3">subscript</csymbol><ci id="S3.E11X.2.1.1.m1.2.2.2.3.3.3.2.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.3.3.3.2">𝐾</ci><ci id="S3.E11X.2.1.1.m1.2.2.2.3.3.3.3.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.3.3.3.3">𝑠</ci></apply></apply></apply><apply id="S3.E11X.2.1.1.m1.2.2.2.2.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.2"><ci id="S3.E11X.2.1.1.m1.2.2.2.2.2.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.2.2">⋅</ci><apply id="S3.E11X.2.1.1.m1.2.2.2.2.3.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.2.3"><times id="S3.E11X.2.1.1.m1.2.2.2.2.3.1.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.2.3.1"></times><apply id="S3.E11X.2.1.1.m1.2.2.2.2.3.2.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.2.3.2"><csymbol cd="ambiguous" id="S3.E11X.2.1.1.m1.2.2.2.2.3.2.1.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.2.3.2">subscript</csymbol><ci id="S3.E11X.2.1.1.m1.2.2.2.2.3.2.2.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.2.3.2.2">𝑊</ci><ci id="S3.E11X.2.1.1.m1.2.2.2.2.3.2.3.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.2.3.2.3">𝑘</ci></apply><apply id="S3.E11X.2.1.1.m1.2.2.2.2.3.3.1.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.2.3.3.2"><csymbol cd="latexml" id="S3.E11X.2.1.1.m1.2.2.2.2.3.3.1.1.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.2.3.3.2.1">delimited-[]</csymbol><ci id="S3.E11X.2.1.1.m1.1.1.1.1.cmml" xref="S3.E11X.2.1.1.m1.1.1.1.1">𝑠</ci></apply></apply><apply id="S3.E11X.2.1.1.m1.2.2.2.2.1.2.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.2.1.1"><abs id="S3.E11X.2.1.1.m1.2.2.2.2.1.2.1.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.2.1.1.2"></abs><apply id="S3.E11X.2.1.1.m1.2.2.2.2.1.1.1.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E11X.2.1.1.m1.2.2.2.2.1.1.1.1.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.2.1.1.1">subscript</csymbol><ci id="S3.E11X.2.1.1.m1.2.2.2.2.1.1.1.2.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.2.1.1.1.2">𝐷</ci><ci id="S3.E11X.2.1.1.m1.2.2.2.2.1.1.1.3.cmml" xref="S3.E11X.2.1.1.m1.2.2.2.2.1.1.1.3">𝑘</ci></apply></apply></apply></apply><apply id="S3.E11X.2.1.1.m1.3.3.3.cmml" xref="S3.E11X.2.1.1.m1.3.3.3"><apply id="S3.E11X.2.1.1.m1.3.3.3.2.cmml" xref="S3.E11X.2.1.1.m1.3.3.3.2"><csymbol cd="ambiguous" id="S3.E11X.2.1.1.m1.3.3.3.2.1.cmml" xref="S3.E11X.2.1.1.m1.3.3.3.2">subscript</csymbol><sum id="S3.E11X.2.1.1.m1.3.3.3.2.2.cmml" xref="S3.E11X.2.1.1.m1.3.3.3.2.2"></sum><apply id="S3.E11X.2.1.1.m1.3.3.3.2.3.cmml" xref="S3.E11X.2.1.1.m1.3.3.3.2.3"><in id="S3.E11X.2.1.1.m1.3.3.3.2.3.1.cmml" xref="S3.E11X.2.1.1.m1.3.3.3.2.3.1"></in><ci id="S3.E11X.2.1.1.m1.3.3.3.2.3.2.cmml" xref="S3.E11X.2.1.1.m1.3.3.3.2.3.2">𝑘</ci><apply id="S3.E11X.2.1.1.m1.3.3.3.2.3.3.cmml" xref="S3.E11X.2.1.1.m1.3.3.3.2.3.3"><csymbol cd="ambiguous" id="S3.E11X.2.1.1.m1.3.3.3.2.3.3.1.cmml" xref="S3.E11X.2.1.1.m1.3.3.3.2.3.3">subscript</csymbol><ci id="S3.E11X.2.1.1.m1.3.3.3.2.3.3.2.cmml" xref="S3.E11X.2.1.1.m1.3.3.3.2.3.3.2">𝐾</ci><ci id="S3.E11X.2.1.1.m1.3.3.3.2.3.3.3.cmml" xref="S3.E11X.2.1.1.m1.3.3.3.2.3.3.3">𝑠</ci></apply></apply></apply><apply id="S3.E11X.2.1.1.m1.3.3.3.1.2.cmml" xref="S3.E11X.2.1.1.m1.3.3.3.1.1"><abs id="S3.E11X.2.1.1.m1.3.3.3.1.2.1.cmml" xref="S3.E11X.2.1.1.m1.3.3.3.1.1.2"></abs><apply id="S3.E11X.2.1.1.m1.3.3.3.1.1.1.cmml" xref="S3.E11X.2.1.1.m1.3.3.3.1.1.1"><csymbol cd="ambiguous" id="S3.E11X.2.1.1.m1.3.3.3.1.1.1.1.cmml" xref="S3.E11X.2.1.1.m1.3.3.3.1.1.1">subscript</csymbol><ci id="S3.E11X.2.1.1.m1.3.3.3.1.1.1.2.cmml" xref="S3.E11X.2.1.1.m1.3.3.3.1.1.1.2">𝐷</ci><ci id="S3.E11X.2.1.1.m1.3.3.3.1.1.1.3.cmml" xref="S3.E11X.2.1.1.m1.3.3.3.1.1.1.3">𝑘</ci></apply></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E11X.2.1.1.m1.9c">\displaystyle{\color[rgb]{0,0,0}W=(\tilde{W}[1],\tilde{W}[2],...\tilde{W}[s],...\tilde{W}[S]),\tilde{W}[s]=\frac{\sum_{k\in{K_{s}}}W_{k}[s]\cdot|D_{k}|}{\sum_{k\in{K_{s}}}|D_{k}|}}.</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(11)</span></td>
</tr>
</tbody>
</table>
<p id="S3.SS3.SSS3.p2.12" class="ltx_p"><span id="S3.SS3.SSS3.p2.12.1" class="ltx_text" style="color:#000000;">Similar to the idea of this model segmentation, Pappas <span id="S3.SS3.SSS3.p2.12.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Pappas et al<span class="ltx_text">.</span> (<a href="#bib.bib169" title="" class="ltx_ref">2021</a>)</cite> introduce a fully decentralized federated learning framework, IPLS. Each client retains some model segments. Before model training, it obtains model segments that are not available locally from other clients and combines them into a complete model. Then, the client uses the full model to update locally and then shares the update gradient with other clients. Kalra <span id="S3.SS3.SSS3.p2.12.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Kalra et al<span class="ltx_text">.</span> (<a href="#bib.bib99" title="" class="ltx_ref">2023</a>)</cite> design a proxy-based decentralized federated learning scheme, ProxyFL, in which each client maintains two models, a private model and a publicly shared proxy model. During collaborative learning, clients communicate with others by exchanging their proxy models. The way of sharing the proxy model can effectively deal with the challenge of model heterogeneity. To improve the security of decentralized federated learning, Li <span id="S3.SS3.SSS3.p2.12.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib128" title="" class="ltx_ref">2020a</a>)</cite> propose a blockchain-based decentralized federated learning framework, BFLC. The framework leverages blockchain for global model storage and local model update exchange. A committee consisting of honest clients verifies other clients so that the most reliable clients learn from each other, and a small number of malicious client updates are ignored.</span></p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4. </span>Future Directions</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1. </span>Improving Communication Efficiency</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">In federated learning, the heterogeneous environment can decrease the training efficiency to some extent. Therefore, improving communication efficiency and effectiveness is the focus of many existing approaches <cite class="ltx_cite ltx_citemacro_cite">Hamer et al<span class="ltx_text">.</span> (<a href="#bib.bib69" title="" class="ltx_ref">2020</a>); Gao et al<span class="ltx_text">.</span> (<a href="#bib.bib60" title="" class="ltx_ref">2021</a>); Bibikar et al<span class="ltx_text">.</span> (<a href="#bib.bib12" title="" class="ltx_ref">2022</a>); Wang et al<span class="ltx_text">.</span> (<a href="#bib.bib212" title="" class="ltx_ref">2022b</a>)</cite>. For example, Konečnỳ <span id="S4.SS1.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Konečnỳ et al<span class="ltx_text">.</span> (<a href="#bib.bib105" title="" class="ltx_ref">2016</a>)</cite> study two methods, one to learn an update from a finite space, and the other to update the model and send the compressed model to the server. Communication-Mitigated Federated Learning (CMFL) <cite class="ltx_cite ltx_citemacro_cite">Luping et al<span class="ltx_text">.</span> (<a href="#bib.bib142" title="" class="ltx_ref">2019</a>)</cite> avoids the transmission of irrelevant updates to the server by measuring whether local updates are consistent with global updates, which effectively decreases the overhead of communication transmission. Federated Maximum and Mean Discrepancy (FedMMD) <cite class="ltx_cite ltx_citemacro_cite">Yao et al<span class="ltx_text">.</span> (<a href="#bib.bib229" title="" class="ltx_ref">2019</a>)</cite> decreases the number of communication rounds by introducing the Maximum Mean Discrepancy (MMD) constraint into the loss function. In addition, Caldas <span id="S4.SS1.p1.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Caldas et al<span class="ltx_text">.</span> (<a href="#bib.bib18" title="" class="ltx_ref">2018</a>)</cite> develop a Fed-Dropout scheme by extending the concept presented in <cite class="ltx_cite ltx_citemacro_cite">Srivastava et al<span class="ltx_text">.</span> (<a href="#bib.bib193" title="" class="ltx_ref">2014</a>)</cite>. Fed-Dropout derives a small sub-model of the global model for local updates and exchanges the sub-models between the server and the clients to decrease the communication cost. Xiong <span id="S4.SS1.p1.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Xiong et al<span class="ltx_text">.</span> (<a href="#bib.bib222" title="" class="ltx_ref">2023</a>)</cite> propose FedDM to construct some synthetic data locally on the client so that it has a similar distribution to the original data on the loss function, and then send these synthetic data to the server for global model update. Compared with transmitting model parameters, transmitting a small amount of synthetic data can effectively reduce communication overhead and increase the amount of information. <span id="S4.SS1.p1.1.4" class="ltx_text" style="color:#000000;">Dai <span id="S4.SS1.p1.1.4.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Dai et al<span class="ltx_text">.</span> (<a href="#bib.bib38" title="" class="ltx_ref">2022</a>)</cite> adopt a decentralized sparse training technique, so that each local model uses a personalized sparse mask to select its own active parameters, and maintains a fixed number of active parameters during local training and peer-to-peer communication. This way, each local model only needs to transmit the index of its active parameters once. In the subsequent communication process, only the values of these active parameters need to be transmitted instead of the entire model, thus greatly reducing the communication overhead. Besides, the multi-layer decentralized federated learning framework can alleviate the communication load and overhead on the server and client to some extent. However, it still faces challenges such as multi-hop communication delay, unbalanced communication load, and asynchronous communication.</span></p>
</div>
<div id="S4.SS1.p2" class="ltx_para">
<p id="S4.SS1.p2.1" class="ltx_p">Nevertheless, heterogeneous federated learning encounters the following challenges to communication efficiency <cite class="ltx_cite ltx_citemacro_cite">Shahid et al<span class="ltx_text">.</span> (<a href="#bib.bib184" title="" class="ltx_ref">2021</a>); Asad et al<span class="ltx_text">.</span> (<a href="#bib.bib9" title="" class="ltx_ref">2021</a>)</cite>. The existence of a large number of edge nodes can increase computing costs and the required computing power and storage capacity. The differences in the network bandwidth can lead to delays or even losses in sending the local models from clients to the server <cite class="ltx_cite ltx_citemacro_cite">Yi et al<span class="ltx_text">.</span> (<a href="#bib.bib232" title="" class="ltx_ref">2022</a>); Vargaftik et al<span class="ltx_text">.</span> (<a href="#bib.bib208" title="" class="ltx_ref">2022</a>)</cite>. In addition, the differences in the sizes of private datasets can also lead to delays in model updates. Thus, in practical application scenarios, a good trade-off between communication efficiency and model accuracy needs to be guaranteed.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2. </span>Federated Fairness</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">In real-world scenarios, heterogeneous federated learning encounters the security issues associated with model fairness <cite class="ltx_cite ltx_citemacro_cite">Du et al<span class="ltx_text">.</span> (<a href="#bib.bib43" title="" class="ltx_ref">2021</a>); Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib239" title="" class="ltx_ref">2020b</a>)</cite>. The contribution of participating clients to collaborative learning varies and can be exacerbated by heterogeneity. However, the differences in the contribution of the participating clients in the collaborative process are ignored in most of the existing federated learning frameworks. In a fair collaborative federated system, clients with more contributions should be able to learn more from other clients and obtain superior models through collaborative training. In the case of general machine learning, the training data and the training patterns of models may be biased <cite class="ltx_cite ltx_citemacro_cite">Hardt et al<span class="ltx_text">.</span> (<a href="#bib.bib71" title="" class="ltx_ref">2016</a>)</cite>, and some data sample groups may be discriminated against. In the federated learning scenario, there may exist several free-riding participants <cite class="ltx_cite ltx_citemacro_cite">Fraboni et al<span class="ltx_text">.</span> (<a href="#bib.bib54" title="" class="ltx_ref">2021</a>)</cite> in the system who want to learn from others in federated communication without providing useful information. Additionally, a global model learned under the constraints common to all clients may be biased towards clients with larger amounts of data or frequent occurrences, and the overall loss function may implicitly advantage or disadvantage certain clients <cite class="ltx_cite ltx_citemacro_cite">Wang et al<span class="ltx_text">.</span> (<a href="#bib.bib211" title="" class="ltx_ref">2020b</a>)</cite>. Therefore, the emphasis on fairness is expected to continue growing with extended practical deployments of federated learning to more users and enterprises. <span id="S4.SS2.p1.1.1" class="ltx_text" style="color:#000000;">Furthermore, multi-layer decentralized federated learning scenarios will face more difficult fairness problems, for example, the trade-off between fairness and efficiency in multi-layer communication protocols, and the inconsistency of fairness criteria between different layers.</span></p>
</div>
<div id="S4.SS2.p2" class="ltx_para">
<p id="S4.SS2.p2.1" class="ltx_p">Several recently developed federated learning paradigms <cite class="ltx_cite ltx_citemacro_cite">Horvath et al<span class="ltx_text">.</span> (<a href="#bib.bib77" title="" class="ltx_ref">2021</a>); Mohri et al<span class="ltx_text">.</span> (<a href="#bib.bib159" title="" class="ltx_ref">2019</a>); Huang et al<span class="ltx_text">.</span> (<a href="#bib.bib85" title="" class="ltx_ref">2020a</a>)</cite> aim to ensure fairness while maintaining high accuracies.
FPFL <cite class="ltx_cite ltx_citemacro_cite">Gálvez et al<span class="ltx_text">.</span> (<a href="#bib.bib57" title="" class="ltx_ref">2021</a>)</cite> regards the fairness problem in federated learning as an optimization problem subject to the constraints of fairness, and enhances the system fairness by improving the differential multiplier MMDM. q-FedAvg <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib126" title="" class="ltx_ref">2020e</a>)</cite> improves the fairness by narrowing the differences between the accuracies of client models. Besides, CFFL <cite class="ltx_cite ltx_citemacro_cite">Lyu et al<span class="ltx_text">.</span> (<a href="#bib.bib143" title="" class="ltx_ref">2020a</a>)</cite> achieves collaborative fairness by assigning models with different performances based on the contributions of each client in federated learning. However, these methods cannot be well applied to heterogeneous federated learning scenarios. Besides, the potential relationship between collaborative fairness and privacy protection <cite class="ltx_cite ltx_citemacro_cite">Jagielski et al<span class="ltx_text">.</span> (<a href="#bib.bib92" title="" class="ltx_ref">2019</a>); Lyu et al<span class="ltx_text">.</span> (<a href="#bib.bib146" title="" class="ltx_ref">2020d</a>)</cite> needs to be further investigated.</p>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3. </span>Privacy Protection</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Privacy protection is the first and foremost principle of federated learning, and the clients typically safeguard basic privacy constraints by never sharing local data <cite class="ltx_cite ltx_citemacro_cite">Chen et al<span class="ltx_text">.</span> (<a href="#bib.bib29" title="" class="ltx_ref">2022a</a>); Feng et al<span class="ltx_text">.</span> (<a href="#bib.bib50" title="" class="ltx_ref">2020</a>)</cite>. However, the clients may leak private information to the server, for instance, to infer sensitive private data samples as the client has memorized the previous model and gradient updates <cite class="ltx_cite ltx_citemacro_cite">Mai et al<span class="ltx_text">.</span> (<a href="#bib.bib150" title="" class="ltx_ref">2018</a>)</cite> or information feedback <cite class="ltx_cite ltx_citemacro_cite">Huang et al<span class="ltx_text">.</span> (<a href="#bib.bib86" title="" class="ltx_ref">2022b</a>)</cite>. In addition, many methods, such as sharing few samples during data augmentation, and sharing local data distributions during knowledge transfer, inevitably result in privacy leakage to some extent <cite class="ltx_cite ltx_citemacro_cite">Chen et al<span class="ltx_text">.</span> (<a href="#bib.bib30" title="" class="ltx_ref">2022c</a>); Elgabli et al<span class="ltx_text">.</span> (<a href="#bib.bib46" title="" class="ltx_ref">2022</a>)</cite>.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">Currently, many researches <cite class="ltx_cite ltx_citemacro_cite">Lyu et al<span class="ltx_text">.</span> (<a href="#bib.bib144" title="" class="ltx_ref">2020c</a>); Bietti et al<span class="ltx_text">.</span> (<a href="#bib.bib13" title="" class="ltx_ref">2022</a>); Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib249" title="" class="ltx_ref">2022a</a>)</cite> dedicate to addressing privacy issues in federated learning. <span id="S4.SS3.p2.1.1" class="ltx_text" style="color:#000000;">In federated learning, one of the most popular privacy-preserving techniques is DP, which adds noise to local updates and clips the norm of local updates to preserve the original private information.</span> In FedAvg, larger updates introduce more noise, and a smaller number of iterations decreases the privacy consumption. Therefore, DP-FedAvg <cite class="ltx_cite ltx_citemacro_cite">McMahan et al<span class="ltx_text">.</span> (<a href="#bib.bib157" title="" class="ltx_ref">2018</a>)</cite> applies a Gaussian mechanism to add user-level privacy protection in FedAvg, making large updates by user-level data. To ensure user-level privacy protection without compromising model performance, Cheng <span id="S4.SS3.p2.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Cheng et al<span class="ltx_text">.</span> (<a href="#bib.bib32" title="" class="ltx_ref">2022</a>)</cite> improve DP-FedAvg by adding regularization and sparsification processes to the local updates. Similarly, FedMD-NFDP <cite class="ltx_cite ltx_citemacro_cite">Sun and Lyu (<a href="#bib.bib196" title="" class="ltx_ref">2021</a>)</cite> claims that random noise perturbations can alleviate privacy concerns, but this process may sacrifice the model performance. Therefore, FedMD-NFDP adds a noise-free DP mechanism to FedMD <cite class="ltx_cite ltx_citemacro_cite">Li and Wang (<a href="#bib.bib114" title="" class="ltx_ref">2019</a>)</cite>, which protects data privacy without introducing noise. Moreover, in practical heterogeneous scenarios, different clients or data samples may have varying privacy concerns.
Consequently, it is critical to build stricter and more flexible privacy constraint policies, which can measure and set more fine-grained privacy constraints for each client and sample while providing sufficient privacy guarantees. <span id="S4.SS3.p2.1.3" class="ltx_text" style="color:#000000;">Compared with the general federated learning scenario, it is more urgent to solve the privacy protection problem in the multi-layer decentralized federated learning scenario. Since edge devices may communicate directly with their neighbors, this may expose their raw data or model updates to other devices.</span></p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.1" class="ltx_p"><span id="S4.SS3.p3.1.1" class="ltx_text" style="color:#000000;">Besides, additional privacy concerns regarding personally sensitive information need to be considered when processing and using biometric data in federated learning. The corresponding solutions include raw data anonymization and feature template protection. Raw data anonymization means that when raw biometric data is preprocessed, a method is adopted so that personally identifiable information or other sensitive information such as gender, age, and health status cannot be extracted from the data<cite class="ltx_cite ltx_citemacro_cite">Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib245" title="" class="ltx_ref">2022f</a>)</cite>. This information may be used by malicious attackers, or correlated with information from other sources, thereby revealing personal privacy. Although existing federated learning frameworks adopt a data-stay-local policy, this cannot completely prevent local clients or other third parties from accessing and analyzing raw data. Therefore, several methods <cite class="ltx_cite ltx_citemacro_cite">Yin et al<span class="ltx_text">.</span> (<a href="#bib.bib233" title="" class="ltx_ref">2021</a>); Grama et al<span class="ltx_text">.</span> (<a href="#bib.bib65" title="" class="ltx_ref">2020</a>)</cite> remove identifiable information through anonymization techniques, thereby protecting local sensitive information from being leaked while maintaining the practicability of published data. However, novel raw data anonymization schemes need to be designed, which can effectively protect the privacy of raw data and retain enough personally identifiable information for model training in federated learning. Meanwhile, the trade-off between privacy and practicality of data anonymization will also be a major challenge. Feature template protection means that after feature templates are extracted from the original biometric data, a method is adopted so that the original biometric data or other sensitive information cannot be reconstructed from these feature templates. A feature template is a representation that encodes and compresses raw biometric data. However, recent studies have indicated that raw biometric data can be reconstructed from feature templates <cite class="ltx_cite ltx_citemacro_cite">Mai et al<span class="ltx_text">.</span> (<a href="#bib.bib149" title="" class="ltx_ref">2020</a>)</cite>. Therefore, an irreversible, updateable, and verifiable feature template protection scheme is needed, while maintaining the distinguishability of the protected feature templates under the federated learning framework. In summary, in order to improve the security and efficiency of processing and using biometric data in federated learning systems, the raw data anonymization and the feature template protection in federated learning need further investigation.</span></p>
</div>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4. </span>Attack Robustness</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p id="S4.SS4.p1.1" class="ltx_p">Federated systems may be vulnerable to two major types of attacks <cite class="ltx_cite ltx_citemacro_cite">Lyu et al<span class="ltx_text">.</span> (<a href="#bib.bib145" title="" class="ltx_ref">2020b</a>)</cite>: poisoning attacks and inference attacks. 1) Poisoning attacks attempt to prevent the models from being learned and make the learning directions of the models deviate from the original goal. Such attacks involve data poisoning and model poisoning. Data poisoning <cite class="ltx_cite ltx_citemacro_cite">Biggio et al<span class="ltx_text">.</span> (<a href="#bib.bib14" title="" class="ltx_ref">2012</a>)</cite> means that the adversaries compromise the integrity of the training data through methods such as label flipping <cite class="ltx_cite ltx_citemacro_cite">Fung et al<span class="ltx_text">.</span> (<a href="#bib.bib56" title="" class="ltx_ref">2018</a>)</cite> and backdoor insertion <cite class="ltx_cite ltx_citemacro_cite">Gu et al<span class="ltx_text">.</span> (<a href="#bib.bib66" title="" class="ltx_ref">2017</a>); Sun et al<span class="ltx_text">.</span> (<a href="#bib.bib197" title="" class="ltx_ref">2019</a>)</cite>, thereby deteriorating the model performance. In model poisoning <cite class="ltx_cite ltx_citemacro_cite">Bagdasaryan et al<span class="ltx_text">.</span> (<a href="#bib.bib10" title="" class="ltx_ref">2020</a>)</cite>, adversaries cannot directly operate on private data, but they can change the learning direction of the model by destroying client updates. 2) Inference attacks infer information about private user data, thereby compromising user privacy. For example, in the process of parameter transmission, the malicious clients can infer the sensitive data of other clients according to the differences of gradient parameters in each round <cite class="ltx_cite ltx_citemacro_cite">Aono et al<span class="ltx_text">.</span> (<a href="#bib.bib6" title="" class="ltx_ref">2017</a>)</cite>. <span id="S4.SS4.p1.1.1" class="ltx_text" style="color:#000000;">Moreover, compared with the server-client federated learning scenario, there are more intermediate nodes that can be attacked in the multi-layer decentralized federated learning scenario, so it may face more serious malicious attacks and require stricter defense mechanisms.</span></p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p id="S4.SS4.p2.1" class="ltx_p">Attack methods <cite class="ltx_cite ltx_citemacro_cite">Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib242" title="" class="ltx_ref">2020a</a>); Tolpegin et al<span class="ltx_text">.</span> (<a href="#bib.bib204" title="" class="ltx_ref">2020</a>); Liu et al<span class="ltx_text">.</span> (<a href="#bib.bib137" title="" class="ltx_ref">2020a</a>); Gong et al<span class="ltx_text">.</span> (<a href="#bib.bib63" title="" class="ltx_ref">2022</a>)</cite> in federated learning settings should be studied to improve the attack robustness of federated systems. Xie <span id="S4.SS4.p2.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Xie et al<span class="ltx_text">.</span> (<a href="#bib.bib220" title="" class="ltx_ref">2019</a>)</cite> propose the Distributed Backdoor Attack (DBA) strategy, in which a global trigger is decomposed into local triggers, and they are injected into multiple malicious clients. Such distributed backdoor attacks are more stealthy and effective than centralized backdoor attacks. Moreover, Nguyen <span id="S4.SS4.p2.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Wang et al<span class="ltx_text">.</span> (<a href="#bib.bib211" title="" class="ltx_ref">2020b</a>)</cite> propose edge-case backdoors, which consider poisoning edge-case samples. Edge-case samples typically represent the tail data of the data distributions and are unlikely to be used as training or test data. Fowl <span id="S4.SS4.p2.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Fowl et al<span class="ltx_text">.</span> (<a href="#bib.bib53" title="" class="ltx_ref">2022</a>)</cite> propose an attack method based on the imprint module, so that the server directly obtains a copy of the original data from the gradient uploaded by the clients. The imprint module is a special convolutional layer that can directly copy the input feature map to the output feature map, so that the original input information is contained in the gradient.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p id="S4.SS4.p3.1" class="ltx_p"><span id="S4.SS4.p3.1.1" class="ltx_text" style="color:#000000;">These attacks pose a significant threat to federated learning, and thus several defense strategies <cite class="ltx_cite ltx_citemacro_cite">Sun et al<span class="ltx_text">.</span> (<a href="#bib.bib194" title="" class="ltx_ref">2021a</a>); Mao et al<span class="ltx_text">.</span> (<a href="#bib.bib152" title="" class="ltx_ref">2021</a>); Ozdayi et al<span class="ltx_text">.</span> (<a href="#bib.bib168" title="" class="ltx_ref">2021</a>); Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib252" title="" class="ltx_ref">2022d</a>)</cite> have been developed to enhance system robustness. Xie <span id="S4.SS4.p3.1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Xie et al<span class="ltx_text">.</span> (<a href="#bib.bib219" title="" class="ltx_ref">2021</a>)</cite> improve the robustness against backdoor attacks by clipping the model and adding smooth noise. To counteract model poisoning attacks, Li <span id="S4.SS4.p3.1.1.2" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib122" title="" class="ltx_ref">2020b</a>)</cite> learn a detection model on the server side to identify and remove malicious model updates, thereby removing irrelevant features while retaining valid basic features. Wu <span id="S4.SS4.p3.1.1.3" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Wu et al<span class="ltx_text">.</span> (<a href="#bib.bib216" title="" class="ltx_ref">2022a</a>)</cite> propose a robust blockchain multi-layer decentralized federated learning framework, RBML-DFL, which can prevent central server failures or malfunctions through blockchain encrypted transactions. To deal with inference attacks, ResSFL <cite class="ltx_cite ltx_citemacro_cite">Li et al<span class="ltx_text">.</span> (<a href="#bib.bib115" title="" class="ltx_ref">2022</a>)</cite> is trained by experts through attacker perception to obtain a resistant feature extractor that can initialize the client models. Besides, Soteria <cite class="ltx_cite ltx_citemacro_cite">Sun et al<span class="ltx_text">.</span> (<a href="#bib.bib195" title="" class="ltx_ref">2021b</a>)</cite> performs attack defense by generating perturbed data representations, thereby decreasing the quality of reconstructed data. Several approaches <cite class="ltx_cite ltx_citemacro_cite">Mothukuri et al<span class="ltx_text">.</span> (<a href="#bib.bib160" title="" class="ltx_ref">2021a</a>); Zhao et al<span class="ltx_text">.</span> (<a href="#bib.bib253" title="" class="ltx_ref">2021</a>)</cite> implement attack detection to proactively identify the malicious intrusions in federated systems. In BaFFle <cite class="ltx_cite ltx_citemacro_cite">Andreina et al<span class="ltx_text">.</span> (<a href="#bib.bib5" title="" class="ltx_ref">2021</a>)</cite>, the server trains backdoor filters and sends them randomly to clients to detect backdoor instances. The client then removes the backdoor instances from the training data, thereby training a backdoor-free local model. Different from other methods that are studied in the federated setting, Abeshu <span id="S4.SS4.p3.1.1.4" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Abeshu and Chilamkurti (<a href="#bib.bib3" title="" class="ltx_ref">2018</a>)</cite> apply federated learning to network attack detection, and propose a network attack detection model based on federated learning-authorized edge network. This enables edge devices to learn from each other without sharing data to improve the accuracy of network detection attacks. Recently, hardware-based Trusted Execution Environment (TEE) that allocates an isolated block of memory for private computing of sensitive data has attracted significant attention from the industry. Unlike general privacy-preserving technologies, TEE is committed to providing a secure platform for federated learning with low computational overhead and high computational efficiency, and protecting models from inference attacks. Therefore, it is suitable for federated learning scenarios with limited computing resources <cite class="ltx_cite ltx_citemacro_cite">Grama et al<span class="ltx_text">.</span> (<a href="#bib.bib65" title="" class="ltx_ref">2020</a>)</cite>. Mo <span id="S4.SS4.p3.1.1.5" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Mo et al<span class="ltx_text">.</span> (<a href="#bib.bib158" title="" class="ltx_ref">2021</a>)</cite> propose a privacy-preserving federated learning framework for mobile systems, PPFL, which uses TEE for secure training of local models and secure aggregation on the server, thereby hiding gradient updates and preventing adversary attacks. Zhang <span id="S4.SS4.p3.1.1.6" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Zhang et al<span class="ltx_text">.</span> (<a href="#bib.bib251" title="" class="ltx_ref">2021c</a>)</cite> utilize TEE to protect the integrity and privacy of gradients and prevent adversary models from inferring or modifying gradients through side-channel attacks. Specifically, they use TEE for local training, randomly group gradients into gradient segments for encryption, and then send them to the server. The server decrypts and securely aggregates gradient segments from the same group with TEE.</span></p>
</div>
<div id="S4.SS4.p4" class="ltx_para">
<p id="S4.SS4.p4.1" class="ltx_p">The inference attacks aim to obtain the information of the clients, and thus inevitably threaten user privacy and security. Therefore, the attack defense strategies can decrease the risk of privacy leakage. Several privacy-preserving mechanisms can not only reduce inference attacks, but also improve robustness against poisoning attacks. Future work should be aimed at exploring the close relationships between attack robustness and privacy protection to enable a better trade-off between these two aspects.</p>
</div>
</section>
<section id="S4.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.5. </span>Uniform Benchmarks</h3>

<div id="S4.SS5.p1" class="ltx_para">
<p id="S4.SS5.p1.1" class="ltx_p">The federated learning concept was first proposed by McMahan <span id="S4.SS5.p1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">McMahan et al<span class="ltx_text">.</span> (<a href="#bib.bib156" title="" class="ltx_ref">2017</a>)</cite> in 2016. As this field has been developed for a relatively short period of time, there is a lack of widely recognized benchmark datasets and benchmark testing frameworks for heterogeneous scenarios. The development of unified benchmark datasets and benchmark testing frameworks can facilitate the reproduction of experimental results and widespread application of novel algorithms. Heterogeneous benchmark frameworks provide various possibilities for client-side data distributions and model structures. Moreover, the statistical and model discrepancies of different clients can validate the generalization ability of heterogeneous federated learning algorithms to some extent. Systematic evaluation indicators should be developed to promote the research and development of heterogeneous federated learning. The indicators can fairly and comprehensively evaluate the security, convergence, accuracy, and generalization ability of different algorithms. <span id="S4.SS5.p1.1.2" class="ltx_text" style="color:#000000;">Therefore, benchmark is very important to promote the development of heterogeneous federated learning field. Several recent works have explored benchmark frameworks and datasets, which we group into the following three categories:</span></p>
</div>
<div id="S4.SS5.p2" class="ltx_para">
<p id="S4.SS5.p2.1" class="ltx_p"><span id="S4.SS5.p2.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">General Federated Learning Systems.<span id="S4.SS5.p2.1.1.1" class="ltx_text ltx_font_medium">
FedML <cite class="ltx_cite ltx_citemacro_cite">He et al<span class="ltx_text">.</span> (<a href="#bib.bib74" title="" class="ltx_ref">2020b</a>)</cite> is a research library that supports distributed training, mobile on-device training, and stand-alone simulation training. It provides standardized implementations of many existing federated learning algorithms, and provides standardized benchmark settings for a variety of datasets, including Non-IID partition methods, number of devices and baseline models.
FedScale <cite class="ltx_cite ltx_citemacro_cite">Lai et al<span class="ltx_text">.</span> (<a href="#bib.bib110" title="" class="ltx_ref">2022</a>)</cite> is a federated learning benchmark suite that provides real-world datasets covering a wide range of federated learning tasks, including image classification, object detection, language modeling, and speech recognition. Additionally, FedScale includes a scalable and extensible FedScale Runtime to enable and standardize real-world end-point deployments of federated learning.
OARF <cite class="ltx_cite ltx_citemacro_cite">Hu et al<span class="ltx_text">.</span> (<a href="#bib.bib82" title="" class="ltx_ref">2020b</a>)</cite> leverages public datasets collected from different sources to simulate real-world data distributions. In addition, OARF quantitatively studies the preliminary relationship among various design metrics such as data partitioning and privacy mechanisms in federated learning systems.
FedEval <cite class="ltx_cite ltx_citemacro_cite">Chai et al<span class="ltx_text">.</span> (<a href="#bib.bib20" title="" class="ltx_ref">2020b</a>)</cite> is a federated learning evaluation model with five metrics including accuracy, communication, time consumption, privacy and robustness. FedEval is implemented and evaluated on two of the most widely used algorithms, FedSGD and FedAvg.
</span></span></p>
</div>
<div id="S4.SS5.p3" class="ltx_para">
<p id="S4.SS5.p3.1" class="ltx_p"><span id="S4.SS5.p3.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">Specific Federated Learning Systems.<span id="S4.SS5.p3.1.1.1" class="ltx_text ltx_font_medium">
FedReIDBench <cite class="ltx_cite ltx_citemacro_cite">Zhuang et al<span class="ltx_text">.</span> (<a href="#bib.bib257" title="" class="ltx_ref">2020</a>)</cite> is a new benchmark for implementing federated learning to person ReID, which includes nine different datasets and two federated scenarios. Specifically, the two federated scenarios are federated-by-camera scenario and federated-by-dataset scenario, which respectively represent the standard server-client architecture and client-edge-cloud architecture.
pFL-Bench <cite class="ltx_cite ltx_citemacro_cite">Chen et al<span class="ltx_text">.</span> (<a href="#bib.bib23" title="" class="ltx_ref">2022b</a>)</cite> is a benchmark for personalized federated learning, which covers twelve different dataset variants, including image, text, graph and recommendation data, with unified data partitioning and realistic heterogeneous settings. And pFL-Bench provides more than 20 competitive personalized federated learning baseline implementations to help them with standardized evaluation.
FedGraphNN <cite class="ltx_cite ltx_citemacro_cite">He et al<span class="ltx_text">.</span> (<a href="#bib.bib73" title="" class="ltx_ref">2021</a>)</cite> is a benchmark system built on a unified formulation of graph federated learning, including extensive datasets from seven different fields, popular Graph Neural Network (GNN) models and federated learning algorithms.
</span></span></p>
</div>
<div id="S4.SS5.p4" class="ltx_para">
<p id="S4.SS5.p4.1" class="ltx_p"><span id="S4.SS5.p4.1.1" class="ltx_text ltx_font_bold" style="color:#000000;">Datasets.<span id="S4.SS5.p4.1.1.1" class="ltx_text ltx_font_medium">
LEAF <cite class="ltx_cite ltx_citemacro_cite">Caldas et al<span class="ltx_text">.</span> (<a href="#bib.bib17" title="" class="ltx_ref">2019</a>)</cite> contains 6 types of federated datasets covering different fields, including image classification (FEMNIST, Synthetic Dataset), image recognition (Celeba), sentiment analysis (Sentiment140) and next character prediction (Shakespeare, Reddit). In addition, LEAF provides two sampling methods of ’IID’ and ’Non-IID’ to divide the dataset to different clients.
Luo <span id="S4.SS5.p4.1.1.1.1" class="ltx_text ltx_font_italic">et al.</span> <cite class="ltx_cite ltx_citemacro_cite">Luo et al<span class="ltx_text">.</span> (<a href="#bib.bib139" title="" class="ltx_ref">2019</a>)</cite> introduce a federated dataset for object detection. The dataset contains over 900 images generated from 26 street cameras and 7 object categories annotated with detailed bounding boxes. Besides, the article provides the data division of 5 or 20 clients, in which their data distribution is Non-IID and unbalanced, reflecting the characteristics of real-world federated learning scenarios.
</span></span></p>
</div>
<div id="S4.SS5.p5" class="ltx_para">
<p id="S4.SS5.p5.1" class="ltx_p">Although several federated learning benchmarks are devised, more realistic datasets containing extensive machine learning tasks should be established to facilitate the development of federated learning. In heterogeneous scenarios, the scales and the distributions of local data on different clients may differ significantly, and it is generally difficult to benchmark the Non-IID performance under different algorithms. The Non-IID setting requires a sufficient understanding of the statistical heterogeneity in real-world scenarios, including the four statistical heterogeneity cases we discussed in <span id="S4.SS5.p5.1.1" class="ltx_text" style="color:#000000;">Subsection</span> <a href="#S2.SS1" title="2.1. Statistical Heterogeneity ‣ 2. Problems: Research Challenges in Heterogeneous Federated Learning ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2.1</span></a>. <span id="S4.SS5.p5.1.2" class="ltx_text" style="color:#000000;">Therefore, developing a realistic benchmark framework that incorporates the four heterogeneities is a challenging task.</span></p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5. </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">This survey aims to provide a comprehensive and systematic understanding of heterogeneous federated learning. First, a detailed overview of the research challenges in heterogeneous federated learning is demonstrated in <span id="S5.p1.1.1" class="ltx_text" style="color:#000000;">Section</span> <a href="#S2" title="2. Problems: Research Challenges in Heterogeneous Federated Learning ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. Different from existing surveys on federated learning, we focus on the heterogeneity problems in federated learning and categorize them into four categories: statistical heterogeneity, model heterogeneity, communication heterogeneity, and device heterogeneity. Subsequently, we survey the recently published and pre-printed papers on heterogeneous federated learning and provide a reasonable and comprehensive taxonomy of existing techniques in <span id="S5.p1.1.2" class="ltx_text" style="color:#000000;">Section</span> <a href="#S3" title="3. Methods: State-of-the-art ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. This taxonomy divides the state-of-the-art methods at three different levels: data level, model level, and server level. Finally, we provide an outlook analysis on the directions worthy of further exploration and open problems for future development in heterogeneous federated learning in <span id="S5.p1.1.3" class="ltx_text" style="color:#000000;">Section</span> <a href="#S4" title="4. Future Directions ‣ Heterogeneous Federated Learning: State-of-the-art and Research Challenges" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. We believe that these valuable discussions can promote the high-quality development of the heterogeneous federated learning community.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">(1)</span>
<span class="ltx_bibblock">        




</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">AbdulRahman et al<span id="bib.bib2.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Sawsan AbdulRahman, Hanine
Tout, Azzam Mourad, and Chamseddine
Talhi. 2020.

</span>
<span class="ltx_bibblock">FedMCCS: Multicriteria client selection model for
optimal IoT federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.3.1" class="ltx_emph ltx_font_italic">IEEE IoT</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abeshu and Chilamkurti (2018)</span>
<span class="ltx_bibblock">
Abebe Abeshu and Naveen
Chilamkurti. 2018.

</span>
<span class="ltx_bibblock">Deep learning: The frontier for distributed attack
detection in fog-to-things computing.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Magazine</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alex et al<span id="bib.bib4.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Nichol Alex, Achiam
Joshua, and Schulman John.
2018.

</span>
<span class="ltx_bibblock">On First-Order Meta-Learning Algorithms.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.3.1" class="ltx_emph ltx_font_italic">CoRR</em> (2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Andreina et al<span id="bib.bib5.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Sebastien Andreina,
Giorgia Azzurra Marson, Helen
Möllering, and Ghassan Karame.
2021.

</span>
<span class="ltx_bibblock">Baffle: Backdoor detection via feedback-based
federated learning. In <em id="bib.bib5.3.1" class="ltx_emph ltx_font_italic">ICDCS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aono et al<span id="bib.bib6.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Yoshinori Aono, Takuya
Hayashi, Lihua Wang, Shiho Moriai,
et al<span id="bib.bib6.3.1" class="ltx_text">.</span> 2017.

</span>
<span class="ltx_bibblock">Privacy-preserving deep learning via additively
homomorphic encryption.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.4.1" class="ltx_emph ltx_font_italic">IEEE TIFS</em> (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arivazhagan et al<span id="bib.bib7.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Manoj Ghuhan Arivazhagan,
Vinay Aggarwal, Aaditya Kumar Singh,
and Sunav Choudhary. 2019.

</span>
<span class="ltx_bibblock">Federated learning with personalization layers.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1912.00818</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Asad et al<span id="bib.bib8.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Muhammad Asad, Ahmed
Moustafa, and Takayuki Ito.
2020.

</span>
<span class="ltx_bibblock">FedOpt: Towards communication efficiency and
privacy preservation in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.3.1" class="ltx_emph ltx_font_italic">Applied Sciences</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Asad et al<span id="bib.bib9.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Muhammad Asad, Ahmed
Moustafa, Takayuki Ito, and Muhammad
Aslam. 2021.

</span>
<span class="ltx_bibblock">Evaluating the communication efficiency in
federated learning algorithms. In <em id="bib.bib9.3.1" class="ltx_emph ltx_font_italic">IEEE CSCWD</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bagdasaryan et al<span id="bib.bib10.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Eugene Bagdasaryan,
Andreas Veit, Yiqing Hua,
Deborah Estrin, and Vitaly Shmatikov.
2020.

</span>
<span class="ltx_bibblock">How to backdoor federated learning. In
<em id="bib.bib10.3.1" class="ltx_emph ltx_font_italic">AISTATS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Balakrishnan et al<span id="bib.bib11.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Ravikumar Balakrishnan,
Tian Li, Tianyi Zhou,
Nageen Himayat, Virginia Smith, and
Jeff Bilmes. 2022.

</span>
<span class="ltx_bibblock">Diverse client selection for federated learning via
submodular maximization. In <em id="bib.bib11.3.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bibikar et al<span id="bib.bib12.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Sameer Bibikar, Haris
Vikalo, Zhangyang Wang, and Xiaohan
Chen. 2022.

</span>
<span class="ltx_bibblock">Federated dynamic sparse training: Computing less,
communicating less, yet learning better. In
<em id="bib.bib12.3.1" class="ltx_emph ltx_font_italic">AAAI</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bietti et al<span id="bib.bib13.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Alberto Bietti, Chen-Yu
Wei, Miroslav Dudik, John Langford,
and Steven Wu. 2022.

</span>
<span class="ltx_bibblock">Personalization Improves Privacy-Accuracy Tradeoffs
in Federated Learning. In <em id="bib.bib13.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Biggio et al<span id="bib.bib14.2.2.1" class="ltx_text">.</span> (2012)</span>
<span class="ltx_bibblock">
Battista Biggio, Blaine
Nelson, and Pavel Laskov.
2012.

</span>
<span class="ltx_bibblock">Poisoning attacks against support vector machines.
In <em id="bib.bib14.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bonawitz et al<span id="bib.bib15.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Keith Bonawitz, Hubert
Eichner, Wolfgang Grieskamp, Dzmitry
Huba, Alex Ingerman, Vladimir Ivanov,
Chloe Kiddon, Jakub Konečnỳ,
Stefano Mazzocchi, Brendan McMahan,
et al<span id="bib.bib15.3.1" class="ltx_text">.</span> 2019.

</span>
<span class="ltx_bibblock">Towards federated learning at scale: System
design.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.4.1" class="ltx_emph ltx_font_italic">SysML</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Briggs et al<span id="bib.bib16.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Christopher Briggs, Zhong
Fan, and Peter Andras. 2020.

</span>
<span class="ltx_bibblock">Federated learning with hierarchical clustering of
local updates to improve training on non-IID data. In
<em id="bib.bib16.3.1" class="ltx_emph ltx_font_italic">IJCNN</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caldas et al<span id="bib.bib17.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Sebastian Caldas, Sai
Meher Karthik Duddu, Peter Wu, Tian Li,
Jakub Konečnỳ, H Brendan
McMahan, Virginia Smith, and Ameet
Talwalkar. 2019.

</span>
<span class="ltx_bibblock">Leaf: A benchmark for federated settings. In
<em id="bib.bib17.3.1" class="ltx_emph ltx_font_italic">NeurIPS Workshop</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Caldas et al<span id="bib.bib18.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Sebastian Caldas, Jakub
Konečny, H Brendan McMahan, and
Ameet Talwalkar. 2018.

</span>
<span class="ltx_bibblock">Expanding the reach of federated learning by
reducing client resource requirements.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.07210</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cappé and Moulines (2009)</span>
<span class="ltx_bibblock">
Olivier Cappé and
Eric Moulines. 2009.

</span>
<span class="ltx_bibblock">On-line expectation–maximization algorithm for
latent data models.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">J R STAT SOC B</em> (2009).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chai et al<span id="bib.bib20.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Di Chai, Leye Wang,
Kai Chen, and Qiang Yang.
2020b.

</span>
<span class="ltx_bibblock">FedEval: A Holistic Evaluation Framework for
Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib20.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2011.09655</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chai et al<span id="bib.bib21.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Zheng Chai, Ahsan Ali,
Syed Zawad, Stacey Truex,
Ali Anwar, Nathalie Baracaldo,
Yi Zhou, Heiko Ludwig,
Feng Yan, and Yue Cheng.
2020a.

</span>
<span class="ltx_bibblock">Tifl: A tier-based federated learning system. In
<em id="bib.bib21.3.1" class="ltx_emph ltx_font_italic">ACM HPDC</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang et al<span id="bib.bib22.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Hongyan Chang, Virat
Shejwalkar, Reza Shokri, and Amir
Houmansadr. 2019.

</span>
<span class="ltx_bibblock">Cronus: Robust and heterogeneous collaborative
learning with black-box knowledge transfer.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1912.11279</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib23.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Daoyuan Chen, Dawei Gao,
Weirui Kuang, Yaliang Li, and
Bolin Ding. 2022b.

</span>
<span class="ltx_bibblock">pFL-Bench: A Comprehensive Benchmark for
Personalized Federated Learning. In <em id="bib.bib23.3.1" class="ltx_emph ltx_font_italic">NeurIPS Track
on Datasets and Benchmarks</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib24.2.2.1" class="ltx_text">.</span> (2023a)</span>
<span class="ltx_bibblock">
Dengsheng Chen, Jie Hu,
Vince Junkai Tan, Xiaoming Wei, and
Enhua Wu. 2023a.

</span>
<span class="ltx_bibblock">Elastic Aggregation for Federated Optimization. In
<em id="bib.bib24.3.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib25.2.2.1" class="ltx_text">.</span> (2023b)</span>
<span class="ltx_bibblock">
Daoyuan Chen, Liuyi Yao,
Dawei Gao, Bolin Ding, and
Yaliang Li. 2023b.

</span>
<span class="ltx_bibblock">Efficient Personalized Federated Learning via
Sparse Model-Adaptation.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib26.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Fei Chen, Mi Luo,
Zhenhua Dong, Zhenguo Li, and
Xiuqiang He. 2018.

</span>
<span class="ltx_bibblock">Federated meta-learning with fast convergence and
efficient communication.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1802.07876</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib27.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Mingzhe Chen, Nir
Shlezinger, H Vincent Poor, Yonina C
Eldar, and Shuguang Cui.
2021.

</span>
<span class="ltx_bibblock">Communication-efficient federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.3.1" class="ltx_emph ltx_font_italic">PNAS</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib28.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Tianyi Chen, Xiao Jin,
Yuejiao Sun, and Wotao Yin.
2020a.

</span>
<span class="ltx_bibblock">Vafl: a method of vertical asynchronous federated
learning. In <em id="bib.bib28.3.1" class="ltx_emph ltx_font_italic">ICML Workshop</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib29.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Wei-Ning Chen, Christopher
A Choquette Choo, Peter Kairouz, and
Ananda Theertha Suresh. 2022a.

</span>
<span class="ltx_bibblock">The fundamental price of secure aggregation in
differentially private federated learning. In
<em id="bib.bib29.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib30.2.2.1" class="ltx_text">.</span> (2022c)</span>
<span class="ltx_bibblock">
Wei-Ning Chen, Ayfer
Ozgur, and Peter Kairouz.
2022c.

</span>
<span class="ltx_bibblock">The Poisson Binomial Mechanism for Unbiased
Federated Learning with Secure Aggregation. In
<em id="bib.bib30.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al<span id="bib.bib31.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Yiqiang Chen, Xin Qin,
Jindong Wang, Chaohui Yu, and
Wen Gao. 2020b.

</span>
<span class="ltx_bibblock">Fedhealth: A federated transfer learning framework
for wearable healthcare.

</span>
<span class="ltx_bibblock"><em id="bib.bib31.3.1" class="ltx_emph ltx_font_italic">IEEE Intelligent Systems</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cheng et al<span id="bib.bib32.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Anda Cheng, Peisong Wang,
Xi Sheryl Zhang, and Jian Cheng.
2022.

</span>
<span class="ltx_bibblock">Differentially Private Federated Learning with
Local Regularization and Sparsification. In
<em id="bib.bib32.3.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cho et al<span id="bib.bib33.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yae Jee Cho, Jianyu Wang,
and Gauri Joshi. 2020.

</span>
<span class="ltx_bibblock">Client selection in federated learning: Convergence
analysis and power-of-choice selection strategies.

</span>
<span class="ltx_bibblock"><em id="bib.bib33.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.01243</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Choudhury et al<span id="bib.bib34.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Olivia Choudhury, Aris
Gkoulalas-Divanis, Theodoros Salonidis,
Issa Sylla, Yoonyoung Park,
Grace Hsu, and Amar Das.
2020.

</span>
<span class="ltx_bibblock">Anonymizing data for privacy-preserving federated
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib34.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.09096</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chu et al<span id="bib.bib35.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Yun-Wei Chu, Seyyedali
Hosseinalipour, Elizabeth Tenorio, Laura
Cruz, Kerrie Douglas, Andrew Lan, and
Christopher Brinton. 2022.

</span>
<span class="ltx_bibblock">Multi-Layer Personalized Federated Learning for
Mitigating Biases in Student Predictive Analytics.

</span>
<span class="ltx_bibblock"><em id="bib.bib35.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2212.02985</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Collins et al<span id="bib.bib36.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Liam Collins, Hamed
Hassani, Aryan Mokhtari, and Sanjay
Shakkottai. 2021.

</span>
<span class="ltx_bibblock">Exploiting shared representations for personalized
federated learning. In <em id="bib.bib36.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Corinzia et al<span id="bib.bib37.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Luca Corinzia, Ami
Beuret, and Joachim M Buhmann.
2019.

</span>
<span class="ltx_bibblock">Variational federated multi-task learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib37.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1906.06268</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai et al<span id="bib.bib38.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Rong Dai, Li Shen,
Fengxiang He, Xinmei Tian, and
Dacheng Tao. 2022.

</span>
<span class="ltx_bibblock">DisPFL: Towards Communication-Efficient
Personalized Federated Learning via Decentralized Sparse Training. In
<em id="bib.bib38.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai et al<span id="bib.bib39.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Wei Dai, Abhimanu Kumar,
Jinliang Wei, Qirong Ho,
Garth Gibson, and Eric Xing.
2015.

</span>
<span class="ltx_bibblock">High-performance distributed ML at scale through
parameter server consistency models. In <em id="bib.bib39.3.1" class="ltx_emph ltx_font_italic">AAAI</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dayan et al<span id="bib.bib40.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Ittai Dayan, Holger R
Roth, Aoxiao Zhong, Ahmed Harouni,
Amilcare Gentili, Anas Z Abidin,
Andrew Liu, Anthony Beardsworth Costa,
Bradford J Wood, Chien-Sung Tsai,
et al<span id="bib.bib40.3.1" class="ltx_text">.</span> 2021.

</span>
<span class="ltx_bibblock">Federated learning for predicting clinical outcomes
in patients with COVID-19.

</span>
<span class="ltx_bibblock"><em id="bib.bib40.4.1" class="ltx_emph ltx_font_italic">Nature medicine</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Diao et al<span id="bib.bib41.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Enmao Diao, Jie Ding,
and Vahid Tarokh. 2021.

</span>
<span class="ltx_bibblock">Heterofl: Computation and communication efficient
federated learning for heterogeneous clients. In
<em id="bib.bib41.3.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dinh et al<span id="bib.bib42.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Canh T Dinh, Tung T Vu,
Nguyen H Tran, Minh N Dao, and
Hongyu Zhang. 2021.

</span>
<span class="ltx_bibblock">FedU: A Unified Framework for Federated Multi-Task
Learning with Laplacian Regularization.

</span>
<span class="ltx_bibblock"><em id="bib.bib42.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2102.07148</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Du et al<span id="bib.bib43.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Wei Du, Depeng Xu,
Xintao Wu, and Hanghang Tong.
2021.

</span>
<span class="ltx_bibblock">Fairness-aware agnostic federated learning. In
<em id="bib.bib43.3.1" class="ltx_emph ltx_font_italic">SDM</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Duan et al<span id="bib.bib44.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Moming Duan, Duo Liu,
Xianzhang Chen, Yujuan Tan,
Jinting Ren, Lei Qiao, and
Liang Liang. 2019.

</span>
<span class="ltx_bibblock">Astraea: Self-balancing federated learning for
improving classification accuracy of mobile deep learning applications. In
<em id="bib.bib44.3.1" class="ltx_emph ltx_font_italic">ICCD</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Duan et al<span id="bib.bib45.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Moming Duan, Duo Liu,
Xinyuan Ji, Renping Liu,
Liang Liang, Xianzhang Chen, and
Yujuan Tan. 2021.

</span>
<span class="ltx_bibblock">FedGroup: Efficient Federated Learning via
Decomposed Similarity-Based Clustering. In <em id="bib.bib45.3.1" class="ltx_emph ltx_font_italic">IEEE
ISPA</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Elgabli et al<span id="bib.bib46.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Anis Elgabli, Chaouki Ben
Issaid, Amrit Singh Bedi, Ketan Rajawat,
Mehdi Bennis, and Vaneet Aggarwal.
2022.

</span>
<span class="ltx_bibblock">FedNew: A Communication-Efficient and
Privacy-Preserving Newton-Type Method for Federated Learning. In
<em id="bib.bib46.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fallah et al<span id="bib.bib47.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Alireza Fallah, Aryan
Mokhtari, and Asuman Ozdaglar.
2020.

</span>
<span class="ltx_bibblock">Personalized federated learning with theoretical
guarantees: A model-agnostic meta-learning approach. In
<em id="bib.bib47.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang et al<span id="bib.bib48.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Chen Fang, Yuanbo Guo,
Na Wang, and Ankang Ju.
2020.

</span>
<span class="ltx_bibblock">Highly efficient federated learning with strong
privacy preservation in cloud computing.

</span>
<span class="ltx_bibblock"><em id="bib.bib48.3.1" class="ltx_emph ltx_font_italic">Computers &amp; Security</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fang and Ye (2022)</span>
<span class="ltx_bibblock">
Xiuwen Fang and Mang
Ye. 2022.

</span>
<span class="ltx_bibblock">Robust Federated Learning with Noisy and
Heterogeneous Clients. In <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feng et al<span id="bib.bib50.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Jie Feng, Can Rong,
Funing Sun, Diansheng Guo, and
Yong Li. 2020.

</span>
<span class="ltx_bibblock">PMF: A privacy-preserving human mobility prediction
framework via federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib50.3.1" class="ltx_emph ltx_font_italic">ACM IMWUT</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Feraudo et al<span id="bib.bib51.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Angelo Feraudo, Poonam
Yadav, Vadim Safronov, Diana Andreea
Popescu, Richard Mortier, Shiqiang Wang,
Paolo Bellavista, and Jon Crowcroft.
2020.

</span>
<span class="ltx_bibblock">CoLearn: Enabling federated learning in
MUD-compliant IoT edge networks. In <em id="bib.bib51.3.1" class="ltx_emph ltx_font_italic">ACM EdgeSys</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Finn et al<span id="bib.bib52.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Chelsea Finn, Pieter
Abbeel, and Sergey Levine.
2017.

</span>
<span class="ltx_bibblock">Model-agnostic meta-learning for fast adaptation of
deep networks. In <em id="bib.bib52.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fowl et al<span id="bib.bib53.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Liam Fowl, Jonas Geiping,
Wojtek Czaja, Micah Goldblum, and
Tom Goldstein. 2022.

</span>
<span class="ltx_bibblock">Robbing the fed: Directly obtaining private data in
federated learning with modified models. In
<em id="bib.bib53.3.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fraboni et al<span id="bib.bib54.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Yann Fraboni, Richard
Vidal, and Marco Lorenzi.
2021.

</span>
<span class="ltx_bibblock">Free-rider attacks on model aggregation in
federated learning. In <em id="bib.bib54.3.1" class="ltx_emph ltx_font_italic">AISTATS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Froelicher et al<span id="bib.bib55.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
David Froelicher, Juan R
Troncoso-Pastoriza, Jean Louis Raisaro,
Michel A Cuendet, Joao Sa Sousa,
Hyunghoon Cho, Bonnie Berger,
Jacques Fellay, and Jean-Pierre
Hubaux. 2021.

</span>
<span class="ltx_bibblock">Truly privacy-preserving federated analytics for
precision medicine with multiparty homomorphic encryption.

</span>
<span class="ltx_bibblock"><em id="bib.bib55.3.1" class="ltx_emph ltx_font_italic">Nature communications</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fung et al<span id="bib.bib56.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Clement Fung, Chris JM
Yoon, and Ivan Beschastnikh.
2018.

</span>
<span class="ltx_bibblock">Mitigating sybils in federated learning poisoning.

</span>
<span class="ltx_bibblock"><em id="bib.bib56.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1808.04866</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gálvez et al<span id="bib.bib57.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Borja Rodríguez Gálvez,
Filip Granqvist, Rogier van Dalen, and
Matt Seigel. 2021.

</span>
<span class="ltx_bibblock">Enforcing fairness in private federated learning
via the modified method of differential multipliers. In
<em id="bib.bib57.3.1" class="ltx_emph ltx_font_italic">NeurIPS Workshop</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al<span id="bib.bib58.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Dashan Gao, Yang Liu,
Anbu Huang, Ce Ju, Han
Yu, and Qiang Yang. 2019.

</span>
<span class="ltx_bibblock">Privacy-preserving heterogeneous federated transfer
learning. In <em id="bib.bib58.3.1" class="ltx_emph ltx_font_italic">IEEE Big Data</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al<span id="bib.bib59.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Dashan Gao, Xin Yao,
and Qiang Yang. 2022.

</span>
<span class="ltx_bibblock">A survey on heterogeneous federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib59.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2210.04505</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao et al<span id="bib.bib60.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Hongchang Gao, An Xu,
and Heng Huang. 2021.

</span>
<span class="ltx_bibblock">On the convergence of communication-efficient local
SGD for federated learning. In <em id="bib.bib60.3.1" class="ltx_emph ltx_font_italic">AAAI</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ghosh et al<span id="bib.bib61.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Avishek Ghosh, Jichan
Chung, Dong Yin, and Kannan
Ramchandran. 2020.

</span>
<span class="ltx_bibblock">An efficient framework for clustered federated
learning. In <em id="bib.bib61.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Girgis et al<span id="bib.bib62.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Antonious Girgis, Deepesh
Data, Suhas Diggavi, Peter Kairouz,
and Ananda Theertha Suresh.
2021.

</span>
<span class="ltx_bibblock">Shuffled model of differential privacy in federated
learning. In <em id="bib.bib62.3.1" class="ltx_emph ltx_font_italic">AISTATS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gong et al<span id="bib.bib63.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Xueluan Gong, Yanjiao
Chen, Huayang Huang, Yuqing Liao,
Shuai Wang, and Qian Wang.
2022.

</span>
<span class="ltx_bibblock">Coordinated Backdoor Attacks against Federated
Learning with Model-Dependent Triggers.

</span>
<span class="ltx_bibblock"><em id="bib.bib63.3.1" class="ltx_emph ltx_font_italic">IEEE Network</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goodfellow et al<span id="bib.bib64.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Ian Goodfellow, Jean
Pouget-Abadie, Mehdi Mirza, Bing Xu,
David Warde-Farley, Sherjil Ozair,
Aaron Courville, and Yoshua Bengio.
2014.

</span>
<span class="ltx_bibblock">Generative adversarial nets. In
<em id="bib.bib64.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Grama et al<span id="bib.bib65.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Matei Grama, Maria Musat,
Luis Muñoz-González, Jonathan
Passerat-Palmbach, Daniel Rueckert, and
Amir Alansary. 2020.

</span>
<span class="ltx_bibblock">Robust aggregation for adaptive privacy preserving
federated learning in healthcare.

</span>
<span class="ltx_bibblock"><em id="bib.bib65.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2009.08294</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gu et al<span id="bib.bib66.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Tianyu Gu, Brendan
Dolan-Gavitt, and Siddharth Garg.
2017.

</span>
<span class="ltx_bibblock">Badnets: Identifying vulnerabilities in the machine
learning model supply chain.

</span>
<span class="ltx_bibblock"><em id="bib.bib66.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1708.06733</em>
(2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo et al<span id="bib.bib67.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Xu Guo, Han Yu,
Boyang Li, Hao Wang,
Pengwei Xing, Siwei Feng,
Zaiqing Nie, and Chunyan Miao.
2022.

</span>
<span class="ltx_bibblock">Federated Learning for Personalized Humor
Recognition. In <em id="bib.bib67.3.1" class="ltx_emph ltx_font_italic">ACM TIST</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gürsoy et al<span id="bib.bib68.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Gamze Gürsoy, Tianxiao
Li, Susanna Liu, Eric Ni,
Charlotte M Brannon, and Mark B
Gerstein. 2022.

</span>
<span class="ltx_bibblock">Functional genomics data: privacy risk assessment
and technological mitigation.

</span>
<span class="ltx_bibblock"><em id="bib.bib68.3.1" class="ltx_emph ltx_font_italic">Nature Reviews Genetics</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hamer et al<span id="bib.bib69.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Jenny Hamer, Mehryar
Mohri, and Ananda Theertha Suresh.
2020.

</span>
<span class="ltx_bibblock">Fedboost: A communication-efficient algorithm for
federated learning. In <em id="bib.bib69.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hanzely and Richtárik (2020)</span>
<span class="ltx_bibblock">
Filip Hanzely and Peter
Richtárik. 2020.

</span>
<span class="ltx_bibblock">Federated learning of a mixture of global and local
models.

</span>
<span class="ltx_bibblock"><em id="bib.bib70.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.05516</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hardt et al<span id="bib.bib71.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Moritz Hardt, Eric Price,
and Nati Srebro. 2016.

</span>
<span class="ltx_bibblock">Equality of opportunity in supervised learning. In
<em id="bib.bib71.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib72" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al<span id="bib.bib72.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Chaoyang He, Murali
Annavaram, and Salman Avestimehr.
2020a.

</span>
<span class="ltx_bibblock">Group knowledge transfer: Federated learning of
large cnns at the edge. In <em id="bib.bib72.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib73" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al<span id="bib.bib73.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Chaoyang He, Keshav
Balasubramanian, Emir Ceyani, Carl Yang,
Han Xie, Lichao Sun,
Lifang He, Liangwei Yang,
Philip S Yu, Yu Rong, et al<span id="bib.bib73.3.1" class="ltx_text">.</span>
2021.

</span>
<span class="ltx_bibblock">Fedgraphnn: A federated learning system and
benchmark for graph neural networks. In <em id="bib.bib73.4.1" class="ltx_emph ltx_font_italic">ICLR
Workshop</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib74" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He et al<span id="bib.bib74.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Chaoyang He, Songze Li,
Jinhyun So, Xiao Zeng,
Mi Zhang, Hongyi Wang,
Xiaoyang Wang, Praneeth Vepakomma,
Abhishek Singh, Hang Qiu,
et al<span id="bib.bib74.3.1" class="ltx_text">.</span> 2020b.

</span>
<span class="ltx_bibblock">Fedml: A research library and benchmark for
federated machine learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib74.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2007.13518</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib75" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hong et al<span id="bib.bib75.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Junyuan Hong, Haotao
Wang, Zhangyang Wang, and Jiayu Zhou.
2022.

</span>
<span class="ltx_bibblock">Efficient Split-Mix Federated Learning for
On-Demand and In-Situ Customization. In <em id="bib.bib75.3.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib76" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hönig et al<span id="bib.bib76.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Robert Hönig, Yiren
Zhao, and Robert Mullins.
2022.

</span>
<span class="ltx_bibblock">DAdaQuant: Doubly-adaptive quantization for
communication-efficient Federated Learning. In
<em id="bib.bib76.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib77" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Horvath et al<span id="bib.bib77.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Samuel Horvath, Stefanos
Laskaridis, Mario Almeida, Ilias
Leontiadis, Stylianos Venieris, and
Nicholas Lane. 2021.

</span>
<span class="ltx_bibblock">Fjord: Fair and accurate federated learning under
heterogeneous targets with ordered dropout. In
<em id="bib.bib77.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib78" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hosseinalipour et al<span id="bib.bib78.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Seyyedali Hosseinalipour,
Christopher G Brinton, Vaneet Aggarwal,
Huaiyu Dai, and Mung Chiang.
2020.

</span>
<span class="ltx_bibblock">From federated to fog learning: Distributed machine
learning over heterogeneous wireless networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib78.3.1" class="ltx_emph ltx_font_italic">IEEE Communications Magazine</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib79" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hou et al<span id="bib.bib79.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Charlie Hou, Kiran Koshy
Thekumparampil, Giulia Fanti, and
Sewoong Oh. 2022.

</span>
<span class="ltx_bibblock">FedChain: Chained Algorithms for Near-optimal
Communication Cost in Federated Learning. In
<em id="bib.bib79.3.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib80" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al<span id="bib.bib80.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Chenghao Hu, Jingyan
Jiang, and Zhi Wang. 2019.

</span>
<span class="ltx_bibblock">Decentralized federated learning: A segmented
gossip approach. In <em id="bib.bib80.3.1" class="ltx_emph ltx_font_italic">FML Workshop</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib81" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al<span id="bib.bib81.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Rui Hu, Yuanxiong Guo,
Hongning Li, Qingqi Pei, and
Yanmin Gong. 2020a.

</span>
<span class="ltx_bibblock">Personalized federated learning with differential
privacy.

</span>
<span class="ltx_bibblock"><em id="bib.bib81.3.1" class="ltx_emph ltx_font_italic">IEEE IoT</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib82" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hu et al<span id="bib.bib82.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Sixu Hu, Yuan Li,
Xu Liu, Qinbin Li,
Zhaomin Wu, and Bingsheng He.
2020b.

</span>
<span class="ltx_bibblock">The oarf benchmark suite: Characterization and
implications for federated learning systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib82.3.1" class="ltx_emph ltx_font_italic">Intelligent Systems and Technology</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib83" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span id="bib.bib83.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Tiansheng Huang, Weiwei
Lin, Li Shen, Keqin Li, and
Albert Y Zomaya. 2022a.

</span>
<span class="ltx_bibblock">Stochastic client selection for federated learning
with volatile clients.

</span>
<span class="ltx_bibblock"><em id="bib.bib83.3.1" class="ltx_emph ltx_font_italic">IEEE IoT</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib84" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span id="bib.bib84.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Tiansheng Huang, Weiwei
Lin, Wentai Wu, Ligang He,
Keqin Li, and Albert Y Zomaya.
2020b.

</span>
<span class="ltx_bibblock">An efficiency-boosting client selection scheme for
federated learning with fairness guarantee.

</span>
<span class="ltx_bibblock"><em id="bib.bib84.3.1" class="ltx_emph ltx_font_italic">IEEE TPDS</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib85" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span id="bib.bib85.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Wei Huang, Tianrui Li,
Dexian Wang, Shengdong Du, and
Junbo Zhang. 2020a.

</span>
<span class="ltx_bibblock">Fairness and accuracy in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib85.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.10069</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib86" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span id="bib.bib86.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Wenke Huang, Mang Ye,
and Bo Du. 2022b.

</span>
<span class="ltx_bibblock">Learn from Others and Be Yourself in Heterogeneous
Federated Learning. In <em id="bib.bib86.3.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib87" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span id="bib.bib87.2.2.1" class="ltx_text">.</span> (2022c)</span>
<span class="ltx_bibblock">
Wenke Huang, Mang Ye,
Xiang Gao, and Bo Du.
2022c.

</span>
<span class="ltx_bibblock">Few-Shot Model Agnostic Federated Learning. In
<em id="bib.bib87.3.1" class="ltx_emph ltx_font_italic">ACM Multimedia</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib88" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span id="bib.bib88.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Wenke Huang, Mang Ye,
Zekun Shi, He Li, and
Bo Du. 2023.

</span>
<span class="ltx_bibblock">Rethinking Federated Learning With Domain Shift: A
Prototype View. In <em id="bib.bib88.3.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib89" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang et al<span id="bib.bib89.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Yutao Huang, Lingyang
Chu, Zirui Zhou, Lanjun Wang,
Jiangchuan Liu, Jian Pei, and
Yong Zhang. 2021.

</span>
<span class="ltx_bibblock">Personalized cross-silo federated learning on
non-iid data. In <em id="bib.bib89.3.1" class="ltx_emph ltx_font_italic">AAAI</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib90" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hyeon-Woo et al<span id="bib.bib90.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Nam Hyeon-Woo, Moon
Ye-Bin, and Tae-Hyun Oh.
2022.

</span>
<span class="ltx_bibblock">FedPara: Low-rank Hadamard Product for
Communication-Efficient Federated Learning. In
<em id="bib.bib90.3.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib91" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jaggi et al<span id="bib.bib91.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Martin Jaggi, Virginia
Smith, Martin Takác, Jonathan
Terhorst, Sanjay Krishnan, Thomas
Hofmann, and Michael I Jordan.
2014.

</span>
<span class="ltx_bibblock">Communication-efficient distributed dual coordinate
ascent. In <em id="bib.bib91.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib92" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jagielski et al<span id="bib.bib92.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Matthew Jagielski, Michael
Kearns, Jieming Mao, Alina Oprea,
Aaron Roth, Saeed Sharifi-Malvajerdi,
and Jonathan Ullman. 2019.

</span>
<span class="ltx_bibblock">Differentially private fair learning. In
<em id="bib.bib92.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib93" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jeong et al<span id="bib.bib93.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Eunjeong Jeong, Seungeun
Oh, Hyesung Kim, Jihong Park,
Mehdi Bennis, and Seong-Lyun Kim.
2018.

</span>
<span class="ltx_bibblock">Communication-efficient on-device machine learning:
Federated distillation and augmentation under non-iid private data.

</span>
<span class="ltx_bibblock"><em id="bib.bib93.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1811.11479</em>
(2018).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib94" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jia et al<span id="bib.bib94.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Menglin Jia, Zuxuan Wu,
Austin Reiter, Claire Cardie,
Serge Belongie, and Ser-Nam Lim.
2021.

</span>
<span class="ltx_bibblock">Intentonomy: a dataset and study towards human
intent understanding. In <em id="bib.bib94.3.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib95" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al<span id="bib.bib95.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Yihan Jiang, Jakub
Konečnỳ, Keith Rush, and
Sreeram Kannan. 2019.

</span>
<span class="ltx_bibblock">Improving federated learning personalization via
model agnostic meta learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib95.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.12488</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib96" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kairouz et al<span id="bib.bib96.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Peter Kairouz, Ziyu Liu,
and Thomas Steinke. 2021.

</span>
<span class="ltx_bibblock">The distributed discrete gaussian mechanism for
federated learning with secure aggregation. In
<em id="bib.bib96.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib97" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kairouz et al<span id="bib.bib97.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Peter Kairouz, H Brendan
McMahan, Brendan Avent, Aurélien
Bellet, Mehdi Bennis, Arjun Nitin
Bhagoji, Kallista Bonawitz, Zachary
Charles, Graham Cormode, Rachel
Cummings, et al<span id="bib.bib97.3.1" class="ltx_text">.</span> 2019.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib97.4.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1912.04977</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib98" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kaissis et al<span id="bib.bib98.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Georgios Kaissis,
Alexander Ziller, Jonathan
Passerat-Palmbach, Théo Ryffel,
Dmitrii Usynin, Andrew Trask,
Ionésio Lima, Jason Mancuso,
Friederike Jungmann, Marc-Matthias
Steinborn, et al<span id="bib.bib98.3.1" class="ltx_text">.</span> 2021.

</span>
<span class="ltx_bibblock">End-to-end privacy preserving deep learning on
multi-institutional medical imaging.

</span>
<span class="ltx_bibblock"><em id="bib.bib98.4.1" class="ltx_emph ltx_font_italic">Nature Machine Intelligence</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib99" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kalra et al<span id="bib.bib99.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Shivam Kalra, Junfeng
Wen, Jesse C Cresswell, Maksims Volkovs,
and HR Tizhoosh. 2023.

</span>
<span class="ltx_bibblock">Decentralized federated learning through proxy
model sharing.

</span>
<span class="ltx_bibblock"><em id="bib.bib99.3.1" class="ltx_emph ltx_font_italic">Nature communications</em>
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib100" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karimireddy et al<span id="bib.bib100.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Sai Praneeth Karimireddy,
Satyen Kale, Mehryar Mohri,
Sashank Reddi, Sebastian Stich, and
Ananda Theertha Suresh. 2020.

</span>
<span class="ltx_bibblock">Scaffold: Stochastic controlled averaging for
federated learning. In <em id="bib.bib100.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib101" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khan et al<span id="bib.bib101.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Latif U Khan, Walid Saad,
Zhu Han, Ekram Hossain, and
Choong Seon Hong. 2021.

</span>
<span class="ltx_bibblock">Federated learning for internet of things: Recent
advances, taxonomy, and open challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib101.3.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib102" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Khodak et al<span id="bib.bib102.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Mikhail Khodak,
Maria-Florina F Balcan, and Ameet S
Talwalkar. 2019.

</span>
<span class="ltx_bibblock">Adaptive gradient-based meta-learning methods. In
<em id="bib.bib102.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib103" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al<span id="bib.bib103.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Jinkyu Kim, Geeho Kim,
and Bohyung Han. 2022.

</span>
<span class="ltx_bibblock">Multi-Level Branched Regularization for Federated
Learning. In <em id="bib.bib103.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib104" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kirkpatrick et al<span id="bib.bib104.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
James Kirkpatrick, Razvan
Pascanu, Neil Rabinowitz, Joel Veness,
Guillaume Desjardins, Andrei A Rusu,
Kieran Milan, John Quan,
Tiago Ramalho, Agnieszka
Grabska-Barwinska, et al<span id="bib.bib104.3.1" class="ltx_text">.</span> 2017.

</span>
<span class="ltx_bibblock">Overcoming catastrophic forgetting in neural
networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib104.4.1" class="ltx_emph ltx_font_italic">PNAS</em> (2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib105" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Konečnỳ et al<span id="bib.bib105.2.2.1" class="ltx_text">.</span> (2016)</span>
<span class="ltx_bibblock">
Jakub Konečnỳ,
H Brendan McMahan, Felix X Yu,
Peter Richtárik, Ananda Theertha
Suresh, and Dave Bacon.
2016.

</span>
<span class="ltx_bibblock">Federated learning: Strategies for improving
communication efficiency.

</span>
<span class="ltx_bibblock"><em id="bib.bib105.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1610.05492</em>
(2016).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib106" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kopparapu and Lin (2020)</span>
<span class="ltx_bibblock">
Kavya Kopparapu and Eric
Lin. 2020.

</span>
<span class="ltx_bibblock">Fedfmc: Sequential efficient federated learning on
non-iid data.

</span>
<span class="ltx_bibblock"><em id="bib.bib106.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2006.10937</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib107" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kulkarni et al<span id="bib.bib107.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Viraj Kulkarni, Milind
Kulkarni, and Aniruddha Pant.
2020.

</span>
<span class="ltx_bibblock">Survey of personalization techniques for federated
learning. In <em id="bib.bib107.3.1" class="ltx_emph ltx_font_italic">IEEE WorldS4</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib108" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Laguel et al<span id="bib.bib108.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Yassine Laguel, Krishna
Pillutla, Jérôme Malick, and
Zaid Harchaoui. 2020.

</span>
<span class="ltx_bibblock">Device heterogeneity in federated learning: A
superquantile approach.

</span>
<span class="ltx_bibblock"><em id="bib.bib108.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.11223</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib109" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Laguel et al<span id="bib.bib109.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Yassine Laguel, Krishna
Pillutla, Jérôme Malick, and
Zaid Harchaoui. 2021.

</span>
<span class="ltx_bibblock">A superquantile approach to federated learning with
heterogeneous devices. In <em id="bib.bib109.3.1" class="ltx_emph ltx_font_italic">IEEE CISS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib110" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lai et al<span id="bib.bib110.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Fan Lai, Yinwei Dai,
Xiangfeng Zhu, Harsha V Madhyastha, and
Mosharaf Chowdhury. 2022.

</span>
<span class="ltx_bibblock">FedScale: Benchmarking Model and System Performance
of Federated Learning at Scale. In <em id="bib.bib110.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib111" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lalitha et al<span id="bib.bib111.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Anusha Lalitha, Shubhanshu
Shekhar, Tara Javidi, and Farinaz
Koushanfar. 2018.

</span>
<span class="ltx_bibblock">Fully decentralized federated learning. In
<em id="bib.bib111.3.1" class="ltx_emph ltx_font_italic">NeurIPS Workshop</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib112" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib112.2.2.1" class="ltx_text">.</span> (2021h)</span>
<span class="ltx_bibblock">
Anran Li, Lan Zhang,
Juntao Tan, Yaxuan Qin,
Junhao Wang, and Xiang-Yang Li.
2021h.

</span>
<span class="ltx_bibblock">Sample-level data selection for federated
learning. In <em id="bib.bib112.3.1" class="ltx_emph ltx_font_italic">IEEE INFOCOM</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib113" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib113.2.2.1" class="ltx_text">.</span> (2021f)</span>
<span class="ltx_bibblock">
Chengxi Li, Gang Li,
and Pramod K Varshney. 2021f.

</span>
<span class="ltx_bibblock">Decentralized federated learning via mutual
knowledge transfer.

</span>
<span class="ltx_bibblock"><em id="bib.bib113.3.1" class="ltx_emph ltx_font_italic">IEEE IoT</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib114" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li and Wang (2019)</span>
<span class="ltx_bibblock">
Daliang Li and Junpu
Wang. 2019.

</span>
<span class="ltx_bibblock">Fedmd: Heterogenous federated learning via model
distillation. In <em id="bib.bib114.1.1" class="ltx_emph ltx_font_italic">NeurIPS Workshop</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib115" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib115.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Jingtao Li, Adnan Siraj
Rakin, Xing Chen, Zhezhi He,
Deliang Fan, and Chaitali Chakrabarti.
2022.

</span>
<span class="ltx_bibblock">ResSFL: A Resistance Transfer Framework for
Defending Model Inversion Attack in Split Federated Learning. In
<em id="bib.bib115.3.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib116" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib116.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Li Li, Moming Duan,
Duo Liu, Yu Zhang, Ao
Ren, Xianzhang Chen, Yujuan Tan, and
Chengliang Wang. 2021b.

</span>
<span class="ltx_bibblock">FedSAE: A novel self-adaptive federated learning
framework in heterogeneous systems. In <em id="bib.bib116.3.1" class="ltx_emph ltx_font_italic">IJCNN</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib117" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib117.2.2.1" class="ltx_text">.</span> (2020f)</span>
<span class="ltx_bibblock">
Li Li, Jun Wang,
Xu Chen, and Cheng-Zhong Xu.
2020f.

</span>
<span class="ltx_bibblock">Multi-layer coordination for high-performance
energy-efficient federated learning. In <em id="bib.bib117.3.1" class="ltx_emph ltx_font_italic">IWQoS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib118" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib118.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Qinbin Li, Yiqun Diao,
Quan Chen, and Bingsheng He.
2021a.

</span>
<span class="ltx_bibblock">Federated learning on non-iid data silos: An
experimental study.

</span>
<span class="ltx_bibblock"><em id="bib.bib118.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2102.02079</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib119" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib119.2.2.1" class="ltx_text">.</span> (2021c)</span>
<span class="ltx_bibblock">
Qinbin Li, Bingsheng He,
and Dawn Song. 2021c.

</span>
<span class="ltx_bibblock">Model-Contrastive Federated Learning. In
<em id="bib.bib119.3.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib120" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib120.2.2.1" class="ltx_text">.</span> (2021g)</span>
<span class="ltx_bibblock">
Qinbin Li, Zeyi Wen,
Zhaomin Wu, Sixu Hu,
Naibo Wang, Yuan Li, Xu
Liu, and Bingsheng He.
2021g.

</span>
<span class="ltx_bibblock">A survey on federated learning systems: vision,
hype and reality for data privacy and protection.

</span>
<span class="ltx_bibblock"><em id="bib.bib120.3.1" class="ltx_emph ltx_font_italic">IEEE TKDE</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib121" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib121.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Rui Li, Fenglong Ma,
Wenjun Jiang, and Jing Gao.
2019.

</span>
<span class="ltx_bibblock">Online federated multitask learning. In
<em id="bib.bib121.3.1" class="ltx_emph ltx_font_italic">IEEE Big Data</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib122" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib122.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Suyi Li, Yong Cheng,
Wei Wang, Yang Liu, and
Tianjian Chen. 2020b.

</span>
<span class="ltx_bibblock">Learning to detect malicious clients for robust
federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib122.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.00211</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib123" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib123.2.2.1" class="ltx_text">.</span> (2021d)</span>
<span class="ltx_bibblock">
Tian Li, Shengyuan Hu,
Ahmad Beirami, and Virginia Smith.
2021d.

</span>
<span class="ltx_bibblock">Ditto: Fair and robust federated learning through
personalization. In <em id="bib.bib123.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib124" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib124.2.2.1" class="ltx_text">.</span> (2020c)</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu,
Ameet Talwalkar, and Virginia Smith.
2020c.

</span>
<span class="ltx_bibblock">Federated Learning: Challenges, Methods, and Future
Directions.

</span>
<span class="ltx_bibblock"><em id="bib.bib124.3.1" class="ltx_emph ltx_font_italic">IEEE Signal Process Mag</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib125" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib125.2.2.1" class="ltx_text">.</span> (2020d)</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu,
Manzil Zaheer, Maziar Sanjabi,
Ameet Talwalkar, and Virginia Smith.
2020d.

</span>
<span class="ltx_bibblock">Federated optimization in heterogeneous networks.
In <em id="bib.bib125.3.1" class="ltx_emph ltx_font_italic">MLSys</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib126" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib126.2.2.1" class="ltx_text">.</span> (2020e)</span>
<span class="ltx_bibblock">
Tian Li, Maziar Sanjabi,
Ahmad Beirami, and Virginia Smith.
2020e.

</span>
<span class="ltx_bibblock">Fair Resource Allocation in Federated Learning. In
<em id="bib.bib126.3.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib127" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib127.2.2.1" class="ltx_text">.</span> (2021e)</span>
<span class="ltx_bibblock">
Xiaoxiao Li, Meirui
Jiang, Xiaofei Zhang, Michael Kamp,
and Qi Dou. 2021e.

</span>
<span class="ltx_bibblock">Fedbn: Federated learning on non-iid features via
local batch normalization. In <em id="bib.bib127.3.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib128" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al<span id="bib.bib128.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Yuzheng Li, Chuan Chen,
Nan Liu, Huawei Huang,
Zibin Zheng, and Qiang Yan.
2020a.

</span>
<span class="ltx_bibblock">A blockchain-based decentralized federated learning
framework with committee consensus.

</span>
<span class="ltx_bibblock"><em id="bib.bib128.3.1" class="ltx_emph ltx_font_italic">IEEE Network</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib129" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et al<span id="bib.bib129.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Paul Pu Liang, Terrance
Liu, Liu Ziyin, Nicholas B Allen,
Randy P Auerbach, David Brent,
Ruslan Salakhutdinov, and Louis-Philippe
Morency. 2020.

</span>
<span class="ltx_bibblock">Think locally, act globally: Federated learning
with local and global representations.

</span>
<span class="ltx_bibblock"><em id="bib.bib129.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2001.01523</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib130" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lim et al<span id="bib.bib130.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Wei Yang Bryan Lim,
Nguyen Cong Luong, Dinh Thai Hoang,
Yutao Jiao, Ying-Chang Liang,
Qiang Yang, Dusit Niyato, and
Chunyan Miao. 2020.

</span>
<span class="ltx_bibblock">Federated learning in mobile edge networks: A
comprehensive survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib130.3.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib131" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lim et al<span id="bib.bib131.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Wei Yang Bryan Lim,
Jer Shyuan Ng, Zehui Xiong,
Jiangming Jin, Yang Zhang,
Dusit Niyato, Cyril Leung, and
Chunyan Miao. 2021a.

</span>
<span class="ltx_bibblock">Decentralized edge intelligence: A dynamic resource
allocation framework for hierarchical federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib131.3.1" class="ltx_emph ltx_font_italic">IEEE TPDS</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib132" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lim et al<span id="bib.bib132.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Wei Yang Bryan Lim,
Jer Shyuan Ng, Zehui Xiong,
Dusit Niyato, Chunyan Miao, and
Dong In Kim. 2021b.

</span>
<span class="ltx_bibblock">Dynamic edge association and resource allocation in
self-organizing hierarchical federated learning networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib132.3.1" class="ltx_emph ltx_font_italic">IEEE JSAC</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib133" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al<span id="bib.bib133.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Sen Lin, Guang Yang,
and Junshan Zhang. 2020b.

</span>
<span class="ltx_bibblock">A collaborative learning framework via federated
meta-learning. In <em id="bib.bib133.3.1" class="ltx_emph ltx_font_italic">IEEE ICDCS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib134" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al<span id="bib.bib134.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Tao Lin, Lingjing Kong,
Sebastian U Stich, and Martin Jaggi.
2020a.

</span>
<span class="ltx_bibblock">Ensemble distillation for robust model fusion in
federated learning. In <em id="bib.bib134.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib135" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib135.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Lumin Liu, Jun Zhang,
SH Song, and Khaled B Letaief.
2020b.

</span>
<span class="ltx_bibblock">Client-edge-cloud hierarchical federated learning.
In <em id="bib.bib135.3.1" class="ltx_emph ltx_font_italic">IEEE ICC</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib136" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib136.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Wenyan Liu, Junhong
Cheng, Xiaoling Wang, Xingjian Lu, and
Jianwei Yin. 2022.

</span>
<span class="ltx_bibblock">Hybrid differential privacy based federated
learning for Internet of Things.

</span>
<span class="ltx_bibblock"><em id="bib.bib136.3.1" class="ltx_emph ltx_font_italic">JSA</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib137" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al<span id="bib.bib137.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Yang Liu, Zhihao Yi,
and Tianjian Chen. 2020a.

</span>
<span class="ltx_bibblock">Backdoor attacks and defenses in
feature-partitioned collaborative learning. In
<em id="bib.bib137.3.1" class="ltx_emph ltx_font_italic">FL-ICML workshop</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib138" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lubana et al<span id="bib.bib138.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Ekdeep Singh Lubana,
Chi Ian Tang, Fahim Kawsar,
Robert P Dick, and Akhil Mathur.
2022.

</span>
<span class="ltx_bibblock">Orchestra: Unsupervised Federated Learning via
Globally Consistent Clustering.

</span>
<span class="ltx_bibblock">(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib139" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo et al<span id="bib.bib139.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Jiahuan Luo, Xueyang Wu,
Yun Luo, Anbu Huang,
Yunfeng Huang, Yang Liu, and
Qiang Yang. 2019.

</span>
<span class="ltx_bibblock">Real-world image datasets for federated learning.

</span>
<span class="ltx_bibblock">(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib140" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo et al<span id="bib.bib140.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Mi Luo, Fei Chen,
Dapeng Hu, Yifan Zhang,
Jian Liang, and Jiashi Feng.
2021.

</span>
<span class="ltx_bibblock">No fear of heterogeneity: Classifier calibration
for federated learning with non-iid data. In
<em id="bib.bib140.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib141" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo et al<span id="bib.bib141.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Zhengquan Luo, Yunlong
Wang, Zilei Wang, Zhenan Sun, and
Tieniu Tan. 2022.

</span>
<span class="ltx_bibblock">Disentangled Federated Learning for Tackling
Attributes Skew via Invariant Aggregation and Diversity Transferring. In
<em id="bib.bib141.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib142" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luping et al<span id="bib.bib142.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Wang Luping, Wang Wei,
and LI Bo. 2019.

</span>
<span class="ltx_bibblock">CMFL: Mitigating communication overhead for
federated learning. In <em id="bib.bib142.3.1" class="ltx_emph ltx_font_italic">IEEE ICDCS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib143" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lyu et al<span id="bib.bib143.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Lingjuan Lyu, Xinyi Xu,
and Qian Wang. 2020a.

</span>
<span class="ltx_bibblock">Collaborative Fairness in Federated Learning. In
<em id="bib.bib143.3.1" class="ltx_emph ltx_font_italic">FL-IJCAI’20 workshop</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib144" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lyu et al<span id="bib.bib144.2.2.1" class="ltx_text">.</span> (2020c)</span>
<span class="ltx_bibblock">
Lingjuan Lyu, Han Yu,
Xingjun Ma, Lichao Sun,
Jun Zhao, Qiang Yang, and
Philip S Yu. 2020c.

</span>
<span class="ltx_bibblock">Privacy and robustness in federated learning:
Attacks and defenses.

</span>
<span class="ltx_bibblock"><em id="bib.bib144.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.06337</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib145" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lyu et al<span id="bib.bib145.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Lingjuan Lyu, Han Yu,
and Qiang Yang. 2020b.

</span>
<span class="ltx_bibblock">Threats to federated learning: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib145.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2003.02133</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib146" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lyu et al<span id="bib.bib146.2.2.1" class="ltx_text">.</span> (2020d)</span>
<span class="ltx_bibblock">
Lingjuan Lyu, Jiangshan
Yu, Karthik Nandakumar, Yitong Li,
Xingjun Ma, Jiong Jin,
Han Yu, and Kee Siong Ng.
2020d.

</span>
<span class="ltx_bibblock">Towards fair and privacy-preserving federated deep
models. In <em id="bib.bib146.3.1" class="ltx_emph ltx_font_italic">TPDS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib147" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al<span id="bib.bib147.2.2.1" class="ltx_text">.</span> (2015)</span>
<span class="ltx_bibblock">
Chenxin Ma, Virginia
Smith, Martin Jaggi, Michael Jordan,
Peter Richtárik, and Martin
Takác. 2015.

</span>
<span class="ltx_bibblock">Adding vs. averaging in distributed primal-dual
optimization. In <em id="bib.bib147.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib148" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al<span id="bib.bib148.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Xiaosong Ma, Jie Zhang,
Song Guo, and Wenchao Xu.
2022.

</span>
<span class="ltx_bibblock">Layer-wised Model Aggregation for Personalized
Federated Learning. In <em id="bib.bib148.3.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib149" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mai et al<span id="bib.bib149.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Guangcan Mai, Kai Cao,
Xiangyuan Lan, and Pong C Yuen.
2020.

</span>
<span class="ltx_bibblock">Secureface: Face template protection.

</span>
<span class="ltx_bibblock"><em id="bib.bib149.3.1" class="ltx_emph ltx_font_italic">IEEE TIFS</em> 16
(2020), 262–277.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib150" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mai et al<span id="bib.bib150.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Guangcan Mai, Kai Cao,
Pong C Yuen, and Anil K Jain.
2018.

</span>
<span class="ltx_bibblock">On the reconstruction of face images from deep face
templates.

</span>
<span class="ltx_bibblock"><em id="bib.bib150.3.1" class="ltx_emph ltx_font_italic">IEEE TPAMI</em> 41,
5 (2018), 1188–1202.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib151" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Makhija et al<span id="bib.bib151.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Disha Makhija, Xing Han,
Nhat Ho, and Joydeep Ghosh.
2022.

</span>
<span class="ltx_bibblock">Architecture Agnostic Federated Learning for Neural
Networks. In <em id="bib.bib151.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib152" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mao et al<span id="bib.bib152.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Yunlong Mao, Xinyu Yuan,
Xinyang Zhao, and Sheng Zhong.
2021.

</span>
<span class="ltx_bibblock">Romoa: Robust model aggregation for the resistance
of federated learning to model poisoning attacks. In
<em id="bib.bib152.3.1" class="ltx_emph ltx_font_italic">ESORICS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib153" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marfoq et al<span id="bib.bib153.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Othmane Marfoq, Giovanni
Neglia, Aurélien Bellet, Laetitia
Kameni, and Richard Vidal.
2021.

</span>
<span class="ltx_bibblock">Federated multi-task learning under a mixture of
distributions. In <em id="bib.bib153.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib154" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Marfoq et al<span id="bib.bib154.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Othmane Marfoq, Giovanni
Neglia, Richard Vidal, and Laetitia
Kameni. 2022.

</span>
<span class="ltx_bibblock">Personalized Federated Learning through Local
Memorization. In <em id="bib.bib154.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib155" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McCloskey and Cohen (1989)</span>
<span class="ltx_bibblock">
Michael McCloskey and
Neal J Cohen. 1989.

</span>
<span class="ltx_bibblock">Catastrophic interference in connectionist
networks: The sequential learning problem.

</span>
<span class="ltx_bibblock">(1989).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib156" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al<span id="bib.bib156.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider
Moore, Daniel Ramage, Seth Hampson,
and Blaise Aguera y Arcas.
2017.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks
from decentralized data. In <em id="bib.bib156.3.1" class="ltx_emph ltx_font_italic">AISTATS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib157" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al<span id="bib.bib157.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
H Brendan McMahan, Daniel
Ramage, Kunal Talwar, and Li Zhang.
2018.

</span>
<span class="ltx_bibblock">Learning Differentially Private Recurrent Language
Models. In <em id="bib.bib157.3.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib158" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mo et al<span id="bib.bib158.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Fan Mo, Hamed Haddadi,
Kleomenis Katevas, Eduard Marin,
Diego Perino, and Nicolas Kourtellis.
2021.

</span>
<span class="ltx_bibblock">PPFL: privacy-preserving federated learning with
trusted execution environments. In <em id="bib.bib158.3.1" class="ltx_emph ltx_font_italic">MobiSys</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib159" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mohri et al<span id="bib.bib159.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Mehryar Mohri, Gary
Sivek, and Ananda Theertha Suresh.
2019.

</span>
<span class="ltx_bibblock">Agnostic federated learning. In
<em id="bib.bib159.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib160" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mothukuri et al<span id="bib.bib160.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Viraaji Mothukuri, Prachi
Khare, Reza M Parizi, Seyedamin
Pouriyeh, Ali Dehghantanha, and Gautam
Srivastava. 2021a.

</span>
<span class="ltx_bibblock">Federated-Learning-Based Anomaly Detection for IoT
Security Attacks.

</span>
<span class="ltx_bibblock"><em id="bib.bib160.3.1" class="ltx_emph ltx_font_italic">IEEE IoT</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib161" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mothukuri et al<span id="bib.bib161.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Viraaji Mothukuri, Reza M
Parizi, Seyedamin Pouriyeh, Yan Huang,
Ali Dehghantanha, and Gautam
Srivastava. 2021b.

</span>
<span class="ltx_bibblock">A survey on security and privacy of federated
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib161.3.1" class="ltx_emph ltx_font_italic">FGCS</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib162" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mu et al<span id="bib.bib162.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Xutong Mu, Yulong Shen,
Ke Cheng, Xueli Geng,
Jiaxuan Fu, Tao Zhang, and
Zhiwei Zhang. 2021.

</span>
<span class="ltx_bibblock">FedProc: Prototypical Contrastive Federated
Learning on Non-IID data.

</span>
<span class="ltx_bibblock"><em id="bib.bib162.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2109.12273</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib163" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et al<span id="bib.bib163.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Dinh C Nguyen, Ming Ding,
Pubudu N Pathirana, Aruna Seneviratne,
Jun Li, and H Vincent Poor.
2021.

</span>
<span class="ltx_bibblock">Federated learning for internet of things: A
comprehensive survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib163.3.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib164" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et al<span id="bib.bib164.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Thien Duc Nguyen, Phillip
Rieger, Huili Chen, Hossein Yalame,
Helen Möllering, Hossein Fereidooni,
Samuel Marchal, Markus Miettinen,
Azalia Mirhoseini, Shaza Zeitouni,
et al<span id="bib.bib164.3.1" class="ltx_text">.</span> 2022b.

</span>
<span class="ltx_bibblock">FLAME: Taming Backdoors in Federated Learning. In
<em id="bib.bib164.4.1" class="ltx_emph ltx_font_italic">USENIX Security</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib165" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nguyen et al<span id="bib.bib165.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Van-Dinh Nguyen, Symeon
Chatzinotas, Björn Ottersten, and
Trung Q Duong. 2022a.

</span>
<span class="ltx_bibblock">FedFog: Network-aware optimization of federated
learning over wireless fog-cloud systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib165.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Wireless
Communications</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib166" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Niknam et al<span id="bib.bib166.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Solmaz Niknam, Harpreet S
Dhillon, and Jeffrey H Reed.
2020.

</span>
<span class="ltx_bibblock">Federated learning for wireless communications:
Motivation, opportunities, and challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib166.3.1" class="ltx_emph ltx_font_italic">IEEE Communications Magazine</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib167" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Nishio and Yonetani (2019)</span>
<span class="ltx_bibblock">
Takayuki Nishio and Ryo
Yonetani. 2019.

</span>
<span class="ltx_bibblock">Client selection for federated learning with
heterogeneous resources in mobile edge. In <em id="bib.bib167.1.1" class="ltx_emph ltx_font_italic">ICC</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib168" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ozdayi et al<span id="bib.bib168.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Mustafa Safa Ozdayi, Murat
Kantarcioglu, and Yulia R Gel.
2021.

</span>
<span class="ltx_bibblock">Defending against backdoors in federated learning
with robust learning rate. In <em id="bib.bib168.3.1" class="ltx_emph ltx_font_italic">AAAI</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib169" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pappas et al<span id="bib.bib169.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Christodoulos Pappas,
Dimitris Chatzopoulos, Spyros Lalis,
and Manolis Vavalis. 2021.

</span>
<span class="ltx_bibblock">Ipls: A framework for decentralized federated
learning. In <em id="bib.bib169.3.1" class="ltx_emph ltx_font_italic">IFIP Networking</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib170" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Perera et al<span id="bib.bib170.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Charith Perera, Yongrui
Qin, Julio C Estrella, Stephan
Reiff-Marganiec, and Athanasios V Vasilakos.
2017.

</span>
<span class="ltx_bibblock">Fog computing for sustainable smart cities: A
survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib170.3.1" class="ltx_emph ltx_font_italic">ACM Computing Surveys (CSUR)</em>
(2017).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib171" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pillutla et al<span id="bib.bib171.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Krishna Pillutla, Yassine
Laguel, Jérôme Malick, and Zaid
Harchaoui. 2023.

</span>
<span class="ltx_bibblock">Federated learning with superquantile aggregation
for heterogeneous data.

</span>
<span class="ltx_bibblock"><em id="bib.bib171.3.1" class="ltx_emph ltx_font_italic">Springer Machine Learning</em>
(2023).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib172" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pillutla et al<span id="bib.bib172.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Krishna Pillutla, Kshitiz
Malik, Abdel-Rahman Mohamed, Mike
Rabbat, Maziar Sanjabi, and Lin Xiao.
2022.

</span>
<span class="ltx_bibblock">Federated Learning with Partial Model
Personalization. In <em id="bib.bib172.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib173" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qin et al<span id="bib.bib173.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Zixuan Qin, Liu Yang,
Qilong Wang, Yahong Han, and
Qinghua Hu. 2023.

</span>
<span class="ltx_bibblock">Reliable and Interpretable Personalized Federated
Learning. In <em id="bib.bib173.3.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib174" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qu et al<span id="bib.bib174.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Liangqiong Qu, Yuyin
Zhou, Paul Pu Liang, Yingda Xia,
Feifei Wang, Ehsan Adeli,
Li Fei-Fei, and Daniel Rubin.
2022b.

</span>
<span class="ltx_bibblock">Rethinking architecture design for tackling data
heterogeneity in federated learning. In <em id="bib.bib174.3.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib175" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qu et al<span id="bib.bib175.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Youyang Qu, Longxiang
Gao, Tom H Luan, Yong Xiang,
Shui Yu, Bai Li, and
Gavin Zheng. 2020.

</span>
<span class="ltx_bibblock">Decentralized privacy using blockchain-enabled
federated learning in fog computing.

</span>
<span class="ltx_bibblock"><em id="bib.bib175.3.1" class="ltx_emph ltx_font_italic">IEEE Internet of Things Journal</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib176" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qu et al<span id="bib.bib176.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Zhe Qu, Xingyu Li,
Rui Duan, Yao Liu, Bo
Tang, and Zhuo Lu. 2022a.

</span>
<span class="ltx_bibblock">Generalized Federated Learning via Sharpness Aware
Minimization. In <em id="bib.bib176.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib177" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Roy et al<span id="bib.bib177.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Abhijit Guha Roy, Shayan
Siddiqui, Sebastian Pölsterl, Nassir
Navab, and Christian Wachinger.
2019.

</span>
<span class="ltx_bibblock">Braintorrent: A peer-to-peer environment for
decentralized federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib177.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1905.06731</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib178" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ruan and Joe-Wong (2022)</span>
<span class="ltx_bibblock">
Yichen Ruan and Carlee
Joe-Wong. 2022.

</span>
<span class="ltx_bibblock">FedSoft: Soft Clustered Federated Learning with
Proximal Local Updating. In <em id="bib.bib178.1.1" class="ltx_emph ltx_font_italic">AAAI</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib179" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sadilek et al<span id="bib.bib179.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Adam Sadilek, Luyang Liu,
Dung Nguyen, Methun Kamruzzaman,
Stylianos Serghiou, Benjamin Rader,
Alex Ingerman, Stefan Mellem,
Peter Kairouz, Elaine O Nsoesie,
et al<span id="bib.bib179.3.1" class="ltx_text">.</span> 2021.

</span>
<span class="ltx_bibblock">Privacy-first health research with federated
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib179.4.1" class="ltx_emph ltx_font_italic">NPJ digital medicine</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib180" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sattler et al<span id="bib.bib180.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Felix Sattler, Arturo
Marban, Roman Rischke, and Wojciech
Samek. 2020a.

</span>
<span class="ltx_bibblock">Communication-efficient federated distillation.

</span>
<span class="ltx_bibblock"><em id="bib.bib180.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.00632</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib181" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sattler et al<span id="bib.bib181.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Felix Sattler,
Klaus-Robert Müller, and Wojciech
Samek. 2020b.

</span>
<span class="ltx_bibblock">Clustered federated learning: Model-agnostic
distributed multitask optimization under privacy constraints. In
<em id="bib.bib181.3.1" class="ltx_emph ltx_font_italic">IEEE TNNLS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib182" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sattler et al<span id="bib.bib182.2.2.1" class="ltx_text">.</span> (2020c)</span>
<span class="ltx_bibblock">
Felix Sattler,
Klaus-Robert Müller, Thomas Wiegand,
and Wojciech Samek. 2020c.

</span>
<span class="ltx_bibblock">On the byzantine robustness of clustered federated
learning. In <em id="bib.bib182.3.1" class="ltx_emph ltx_font_italic">IEEE ICASSP</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib183" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sattler et al<span id="bib.bib183.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Felix Sattler, Simon
Wiedemann, Klaus-Robert Müller, and
Wojciech Samek. 2019.

</span>
<span class="ltx_bibblock">Robust and communication-efficient federated
learning from non-iid data.

</span>
<span class="ltx_bibblock"><em id="bib.bib183.3.1" class="ltx_emph ltx_font_italic">IEEE TNNLS</em> (2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib184" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shahid et al<span id="bib.bib184.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Osama Shahid, Seyedamin
Pouriyeh, Reza M Parizi, Quan Z Sheng,
Gautam Srivastava, and Liang Zhao.
2021.

</span>
<span class="ltx_bibblock">Communication Efficiency in Federated Learning:
Achievements and Challenges.

</span>
<span class="ltx_bibblock"><em id="bib.bib184.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2107.10996</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib185" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shang et al<span id="bib.bib185.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Xinyi Shang, Yang Lu,
Gang Huang, and Hanzi Wang.
2022.

</span>
<span class="ltx_bibblock">Federated Learning on Heterogeneous and Long-Tailed
Data via Classifier Re-Training with Federated Features. In
<em id="bib.bib185.3.1" class="ltx_emph ltx_font_italic">IJCAI</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib186" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shao et al<span id="bib.bib186.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Rui Shao, Pramuditha
Perera, Pong C Yuen, and Vishal M
Patel. 2022.

</span>
<span class="ltx_bibblock">Federated Generalized Face Presentation Attack
Detection. In <em id="bib.bib186.3.1" class="ltx_emph ltx_font_italic">IEEE TNNLS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib187" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shen et al<span id="bib.bib187.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Yiqing Shen, Yuyin Zhou,
and Lequan Yu. 2022.

</span>
<span class="ltx_bibblock">CD2-pFed: Cyclic Distillation-guided Channel
Decoupling for Model Personalization in Federated Learning. In
<em id="bib.bib187.3.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib188" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al<span id="bib.bib188.2.2.1" class="ltx_text">.</span> (2023a)</span>
<span class="ltx_bibblock">
Yifan Shi, Yingqi Liu,
Kang Wei, Li Shen,
Xueqian Wang, and Dacheng Tao.
2023a.

</span>
<span class="ltx_bibblock">Make landscape flatter in differentially private
federated learning. In <em id="bib.bib188.3.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib189" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shi et al<span id="bib.bib189.2.2.1" class="ltx_text">.</span> (2023b)</span>
<span class="ltx_bibblock">
Yifan Shi, Li Shen,
Kang Wei, Yan Sun, Bo
Yuan, Xueqian Wang, and Dacheng Tao.
2023b.

</span>
<span class="ltx_bibblock">Improving the Model Consistency of Decentralized
Federated Learning. In <em id="bib.bib189.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib190" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shin et al<span id="bib.bib190.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
MyungJae Shin, Chihoon
Hwang, Joongheon Kim, Jihong Park,
Mehdi Bennis, and Seong-Lyun Kim.
2020.

</span>
<span class="ltx_bibblock">Xor mixup: Privacy-preserving data augmentation for
one-shot federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib190.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2006.05148</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib191" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shoham et al<span id="bib.bib191.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Neta Shoham, Tomer
Avidor, Aviv Keren, Nadav Israel,
Daniel Benditkis, Liron Mor-Yosef, and
Itai Zeitak. 2019.

</span>
<span class="ltx_bibblock">Overcoming forgetting in federated learning on
non-iid data. In <em id="bib.bib191.3.1" class="ltx_emph ltx_font_italic">NeurIPS Workshop</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib192" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smith et al<span id="bib.bib192.2.2.1" class="ltx_text">.</span> (2017)</span>
<span class="ltx_bibblock">
Virginia Smith, Chao-Kai
Chiang, Maziar Sanjabi, and Ameet S
Talwalkar. 2017.

</span>
<span class="ltx_bibblock">Federated multi-task learning. In
<em id="bib.bib192.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib193" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Srivastava et al<span id="bib.bib193.2.2.1" class="ltx_text">.</span> (2014)</span>
<span class="ltx_bibblock">
Nitish Srivastava,
Geoffrey Hinton, Alex Krizhevsky,
Ilya Sutskever, and Ruslan
Salakhutdinov. 2014.

</span>
<span class="ltx_bibblock">Dropout: a simple way to prevent neural networks
from overfitting.

</span>
<span class="ltx_bibblock"><em id="bib.bib193.3.1" class="ltx_emph ltx_font_italic">JMLR</em> (2014).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib194" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span id="bib.bib194.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Jingwei Sun, Ang Li,
Louis DiValentin, Amin Hassanzadeh,
Yiran Chen, and Hai Li.
2021a.

</span>
<span class="ltx_bibblock">Fl-wbc: Enhancing robustness against model
poisoning attacks in federated learning from a client perspective. In
<em id="bib.bib194.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib195" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span id="bib.bib195.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Jingwei Sun, Ang Li,
Binghui Wang, Huanrui Yang,
Hai Li, and Yiran Chen.
2021b.

</span>
<span class="ltx_bibblock">Soteria: Provable defense against privacy leakage
in federated learning from representation perspective. In
<em id="bib.bib195.3.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib196" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun and Lyu (2021)</span>
<span class="ltx_bibblock">
Lichao Sun and Lingjuan
Lyu. 2021.

</span>
<span class="ltx_bibblock">Federated model distillation with noise-free
differential privacy. In <em id="bib.bib196.1.1" class="ltx_emph ltx_font_italic">IJCAI</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib197" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al<span id="bib.bib197.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Ziteng Sun, Peter
Kairouz, Ananda Theertha Suresh, and
H Brendan McMahan. 2019.

</span>
<span class="ltx_bibblock">Can you really backdoor federated learning?. In
<em id="bib.bib197.3.1" class="ltx_emph ltx_font_italic">NeurIPS Workshop</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib198" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">T Dinh et al<span id="bib.bib198.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Canh T Dinh, Nguyen Tran,
and Josh Nguyen. 2020.

</span>
<span class="ltx_bibblock">Personalized federated learning with moreau
envelopes. In <em id="bib.bib198.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib199" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan et al<span id="bib.bib199.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Alysa Ziying Tan, Han Yu,
Lizhen Cui, and Qiang Yang.
2022b.

</span>
<span class="ltx_bibblock">Towards Personalized Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib199.3.1" class="ltx_emph ltx_font_italic">IEEE TNNLS</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib200" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tan et al<span id="bib.bib200.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Yue Tan, Guodong Long,
Lu Liu, Tianyi Zhou,
Qinghua Lu, Jing Jiang, and
Chengqi Zhang. 2022a.

</span>
<span class="ltx_bibblock">Fedproto: Federated prototype learning across
heterogeneous clients. In <em id="bib.bib200.3.1" class="ltx_emph ltx_font_italic">AAAI</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib201" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al<span id="bib.bib201.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Minxue Tang, Xuefei Ning,
Yitu Wang, Jingwei Sun,
Yu Wang, Hai Li, and
Yiran Chen. 2022a.

</span>
<span class="ltx_bibblock">FedCor: Correlation-Based Active Client Selection
Strategy for Heterogeneous Federated Learning. In
<em id="bib.bib201.3.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib202" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al<span id="bib.bib202.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Zhenheng Tang, Shaohuai
Shi, Bo Li, and Xiaowen Chu.
2022b.

</span>
<span class="ltx_bibblock">GossipFL: A decentralized federated learning
framework with sparsified and adaptive communication.

</span>
<span class="ltx_bibblock"><em id="bib.bib202.3.1" class="ltx_emph ltx_font_italic">IEEE TPDS</em> (2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib203" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tang et al<span id="bib.bib203.2.2.1" class="ltx_text">.</span> (2022c)</span>
<span class="ltx_bibblock">
Zhenheng Tang, Yonggang
Zhang, Shaohuai Shi, Xin He,
Bo Han, and Xiaowen Chu.
2022c.

</span>
<span class="ltx_bibblock">Virtual Homogeneity Learning: Defending against
Data Heterogeneity in Federated Learning. In
<em id="bib.bib203.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib204" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Tolpegin et al<span id="bib.bib204.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Vale Tolpegin, Stacey
Truex, Mehmet Emre Gursoy, and Ling
Liu. 2020.

</span>
<span class="ltx_bibblock">Data poisoning attacks against federated learning
systems. In <em id="bib.bib204.3.1" class="ltx_emph ltx_font_italic">ESORICS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib205" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Truex et al<span id="bib.bib205.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Stacey Truex, Ling Liu,
Ka-Ho Chow, Mehmet Emre Gursoy, and
Wenqi Wei. 2020.

</span>
<span class="ltx_bibblock">LDP-Fed: Federated learning with local differential
privacy. In <em id="bib.bib205.3.1" class="ltx_emph ltx_font_italic">Proceedings of the Third ACM
International Workshop on Edge Systems, Analytics and Networking</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib206" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Usynin et al<span id="bib.bib206.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Dmitrii Usynin, Alexander
Ziller, Marcus Makowski, Rickmer Braren,
Daniel Rueckert, Ben Glocker,
Georgios Kaissis, and Jonathan
Passerat-Palmbach. 2021.

</span>
<span class="ltx_bibblock">Adversarial interference and its mitigations in
privacy-preserving collaborative machine learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib206.3.1" class="ltx_emph ltx_font_italic">Nature Machine Intelligence</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib207" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">van Berlo et al<span id="bib.bib207.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Bram van Berlo, Aaqib
Saeed, and Tanir Ozcelebi.
2020.

</span>
<span class="ltx_bibblock">Towards federated unsupervised representation
learning. In <em id="bib.bib207.3.1" class="ltx_emph ltx_font_italic">ACM EdgeSys</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib208" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vargaftik et al<span id="bib.bib208.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Shay Vargaftik, Ran Ben
Basat, Amit Portnoy, Gal Mendelson,
Yaniv Ben Itzhak, and Michael
Mitzenmacher. 2022.

</span>
<span class="ltx_bibblock">Eden: Communication-efficient and robust
distributed mean estimation for federated learning. In
<em id="bib.bib208.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib209" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wahab et al<span id="bib.bib209.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Omar Abdel Wahab, Azzam
Mourad, Hadi Otrok, and Tarik Taleb.
2021.

</span>
<span class="ltx_bibblock">Federated machine learning: Survey, multi-level
classification, desirable criteria and future directions in communication and
networking systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib209.3.1" class="ltx_emph ltx_font_italic">IEEE Communications Surveys &amp; Tutorials</em>
(2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib210" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib210.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Hao Wang, Zakhary Kaplan,
Di Niu, and Baochun Li.
2020a.

</span>
<span class="ltx_bibblock">Optimizing federated learning on non-iid data with
reinforcement learning. In <em id="bib.bib210.3.1" class="ltx_emph ltx_font_italic">IEEE INFOCOM</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib211" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib211.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Hongyi Wang, Kartik
Sreenivasan, Shashank Rajput, and
et al. Vishwakarma. 2020b.

</span>
<span class="ltx_bibblock">Attack of the tails: Yes, you really can backdoor
federated learning. In <em id="bib.bib211.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib212" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib212.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Hui-Po Wang, Sebastian U
Stich, Yang He, and Mario Fritz.
2022b.

</span>
<span class="ltx_bibblock">ProgFed: Effective, Communication, and Computation
Efficient Federated Learning by Progressive Training. In
<em id="bib.bib212.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib213" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang and Kantarci (2020)</span>
<span class="ltx_bibblock">
Yuwei Wang and Burak
Kantarci. 2020.

</span>
<span class="ltx_bibblock">A novel reputation-aware client selection scheme
for federated learning within mobile environments. In
<em id="bib.bib213.1.1" class="ltx_emph ltx_font_italic">IEEE CAMAD</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib214" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al<span id="bib.bib214.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Yujia Wang, Lu Lin, and
Jinghui Chen. 2022a.

</span>
<span class="ltx_bibblock">Communication-Efficient Adaptive Federated
Learning. In <em id="bib.bib214.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib215" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span id="bib.bib215.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Chuhan Wu, Fangzhao Wu,
Lingjuan Lyu, Yongfeng Huang, and
Xing Xie. 2022b.

</span>
<span class="ltx_bibblock">Communication-efficient federated learning via
knowledge distillation.

</span>
<span class="ltx_bibblock"><em id="bib.bib215.3.1" class="ltx_emph ltx_font_italic">Nature communications</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib216" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span id="bib.bib216.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Di Wu, Nai Wang,
Jiale Zhang, Yuan Zhang,
Yong Xiang, and Longxiang Gao.
2022a.

</span>
<span class="ltx_bibblock">A Blockchain-based Multi-layer Decentralized
Framework for Robust Federated Learning. In <em id="bib.bib216.3.1" class="ltx_emph ltx_font_italic">2022
International Joint Conference on Neural Networks (IJCNN)</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib217" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span id="bib.bib217.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Qiong Wu, Kaiwen He,
and Xu Chen. 2020a.

</span>
<span class="ltx_bibblock">Personalized federated learning for intelligent IoT
applications: A cloud-edge based framework.

</span>
<span class="ltx_bibblock"><em id="bib.bib217.3.1" class="ltx_emph ltx_font_italic">IEEE OJ-CS</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib218" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al<span id="bib.bib218.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Wentai Wu, Ligang He,
Weiwei Lin, and Rui Mao.
2020b.

</span>
<span class="ltx_bibblock">Accelerating federated learning over
reliability-agnostic clients in mobile edge computing systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib218.3.1" class="ltx_emph ltx_font_italic">IEEE TPDS</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib219" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al<span id="bib.bib219.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Chulin Xie, Minghao Chen,
Pin-Yu Chen, and Bo Li.
2021.

</span>
<span class="ltx_bibblock">Crfl: Certifiably robust federated learning against
backdoor attacks. In <em id="bib.bib219.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib220" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al<span id="bib.bib220.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Chulin Xie, Keli Huang,
Pin-Yu Chen, and Bo Li.
2019.

</span>
<span class="ltx_bibblock">Dba: Distributed backdoor attacks against federated
learning. In <em id="bib.bib220.3.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib221" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xie et al<span id="bib.bib221.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Ming Xie, Guodong Long,
Tao Shen, Tianyi Zhou,
Xianzhi Wang, Jing Jiang, and
Chengqi Zhang. 2020.

</span>
<span class="ltx_bibblock">Multi-center federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib221.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2005.01026</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib222" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiong et al<span id="bib.bib222.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Yuanhao Xiong, Ruochen
Wang, Minhao Cheng, Felix Yu, and
Cho-Jui Hsieh. 2023.

</span>
<span class="ltx_bibblock">Feddm: Iterative distribution matching for
communication-efficient federated learning. In
<em id="bib.bib222.3.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib223" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span id="bib.bib223.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Jingyi Xu, Zihan Chen,
Tony QS Quek, and Kai Fong Ernest
Chong. 2022a.

</span>
<span class="ltx_bibblock">FedCorr: Multi-Stage Federated Learning for Label
Noise Correction. In <em id="bib.bib223.3.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib224" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span id="bib.bib224.2.2.1" class="ltx_text">.</span> (2023)</span>
<span class="ltx_bibblock">
Jian Xu, Xinyi Tong,
and Shao-Lun Huang. 2023.

</span>
<span class="ltx_bibblock">Personalized Federated Learning with Feature
Alignment and Classifier Collaboration. In <em id="bib.bib224.3.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib225" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu et al<span id="bib.bib225.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Xiaolong Xu, Haoyuan Li,
Zheng Li, and Xiaokang Zhou.
2022b.

</span>
<span class="ltx_bibblock">Safe: Synergic data filtering for federated
learning in cloud-edge computing.

</span>
<span class="ltx_bibblock"><em id="bib.bib225.3.1" class="ltx_emph ltx_font_italic">IEEE Transactions on Industrial Informatics</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib226" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib226.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Miao Yang, Ximin Wang,
Hongbin Zhu, Haifeng Wang, and
Hua Qian. 2021.

</span>
<span class="ltx_bibblock">Federated learning with class imbalance reduction.
In <em id="bib.bib226.3.1" class="ltx_emph ltx_font_italic">EUSIPCO</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib227" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib227.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Qiang Yang, Yang Liu,
Tianjian Chen, and Yongxin Tong.
2019.

</span>
<span class="ltx_bibblock">Federated machine learning: Concept and
applications. In <em id="bib.bib227.3.1" class="ltx_emph ltx_font_italic">ACM TIST</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib228" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yang et al<span id="bib.bib228.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Seunghan Yang, Hyoungseob
Park, Junyoung Byun, and et al.
2020.

</span>
<span class="ltx_bibblock">Robust Federated Learning with Noisy Labels.

</span>
<span class="ltx_bibblock"><em id="bib.bib228.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2012.01700</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib229" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et al<span id="bib.bib229.2.2.1" class="ltx_text">.</span> (2019)</span>
<span class="ltx_bibblock">
Xin Yao, Tianchi Huang,
Chenglei Wu, Rui-Xiao Zhang, and
Lifeng Sun. 2019.

</span>
<span class="ltx_bibblock">Federated learning with additional mechanisms on
clients to reduce communication costs.

</span>
<span class="ltx_bibblock"><em id="bib.bib229.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1908.05891</em>
(2019).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib230" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao and Sun (2020)</span>
<span class="ltx_bibblock">
Xin Yao and Lifeng
Sun. 2020.

</span>
<span class="ltx_bibblock">Continual local training for better initialization
of federated models. In <em id="bib.bib230.1.1" class="ltx_emph ltx_font_italic">IEEE ICIP</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib231" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ye et al<span id="bib.bib231.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Mang Ye, Jianbing Shen,
Xu Zhang, Pong C Yuen, and
Shih-Fu Chang. 2020.

</span>
<span class="ltx_bibblock">Augmentation invariant and instance spreading
feature for softmax embedding.

</span>
<span class="ltx_bibblock"><em id="bib.bib231.3.1" class="ltx_emph ltx_font_italic">IEEE TPAMI</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib232" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yi et al<span id="bib.bib232.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Liping Yi, Wang Gang,
and Liu Xiaoguang. 2022.

</span>
<span class="ltx_bibblock">QSFL: A Two-Level Uplink Communication Optimization
Framework for Federated Learning. In <em id="bib.bib232.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib233" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yin et al<span id="bib.bib233.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Xuefei Yin, Yanming Zhu,
and Jiankun Hu. 2021.

</span>
<span class="ltx_bibblock">A comprehensive survey of privacy-preserving
federated learning: A taxonomy, review, and future directions.

</span>
<span class="ltx_bibblock"><em id="bib.bib233.3.1" class="ltx_emph ltx_font_italic">ACM CSUR</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib234" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoon et al<span id="bib.bib234.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Jaehong Yoon, Geon Park,
Wonyong Jeong, and Sung Ju Hwang.
2022.

</span>
<span class="ltx_bibblock">Bitwidth Heterogeneous Federated Learning with
Progressive Weight Dequantization. In <em id="bib.bib234.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib235" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoon et al<span id="bib.bib235.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Tehrim Yoon, Sumin Shin,
Sung Ju Hwang, and Eunho Yang.
2021.

</span>
<span class="ltx_bibblock">Fedmix: Approximation of mixup under mean augmented
federated learning. In <em id="bib.bib235.3.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib236" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yoshida et al<span id="bib.bib236.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Naoya Yoshida, Takayuki
Nishio, Masahiro Morikura, and Koji
Yamamoto. 2020.

</span>
<span class="ltx_bibblock">Mab-based client selection for federated learning
with uncertain resources in mobile networks. In
<em id="bib.bib236.3.1" class="ltx_emph ltx_font_italic">IEEE GC Workshops</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib237" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al<span id="bib.bib237.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Tao Yu, Eugene
Bagdasaryan, and Vitaly Shmatikov.
2020.

</span>
<span class="ltx_bibblock">Salvaging federated learning by local adaptation.

</span>
<span class="ltx_bibblock"><em id="bib.bib237.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.04758</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib238" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yue et al<span id="bib.bib238.2.2.1" class="ltx_text">.</span> (2022)</span>
<span class="ltx_bibblock">
Kai Yue, Richeng Jin,
Ryan Pilgrim, Chau-Wai Wong,
Dror Baron, and Huaiyu Dai.
2022.

</span>
<span class="ltx_bibblock">Neural Tangent Kernel Empowered Federated
Learning. In <em id="bib.bib238.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib239" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib239.2.2.1" class="ltx_text">.</span> (2020b)</span>
<span class="ltx_bibblock">
Daniel Yue Zhang, Ziyi
Kou, and Dong Wang. 2020b.

</span>
<span class="ltx_bibblock">Fairfl: A fair federated learning approach to
reducing demographic bias in privacy-sensitive classification models. In
<em id="bib.bib239.3.1" class="ltx_emph ltx_font_italic">IEEE Big Data</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib240" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib240.2.2.1" class="ltx_text">.</span> (2020c)</span>
<span class="ltx_bibblock">
Fengda Zhang, Kun Kuang,
Zhaoyang You, and et al.
2020c.

</span>
<span class="ltx_bibblock">Federated unsupervised representation learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib240.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2010.08982</em>
(2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib241" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib241.2.2.1" class="ltx_text">.</span> (2018)</span>
<span class="ltx_bibblock">
Hongyi Zhang, Moustapha
Cisse, Yann N Dauphin, and David
Lopez-Paz. 2018.

</span>
<span class="ltx_bibblock">mixup: Beyond Empirical Risk Minimization. In
<em id="bib.bib241.3.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib242" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib242.2.2.1" class="ltx_text">.</span> (2020a)</span>
<span class="ltx_bibblock">
Jiale Zhang, Bing Chen,
Xiang Cheng, Huynh Thi Thanh Binh, and
Shui Yu. 2020a.

</span>
<span class="ltx_bibblock">Poisongan: Generative poisoning attacks against
federated learning in edge computing systems.

</span>
<span class="ltx_bibblock"><em id="bib.bib242.3.1" class="ltx_emph ltx_font_italic">IEEE IoT</em> (2020).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib243" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib243.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Jie Zhang, Song Guo,
Xiaosong Ma, Haozhao Wang,
Wenchao Xu, and Feijie Wu.
2021a.

</span>
<span class="ltx_bibblock">Parameterized Knowledge Transfer for Personalized
Federated Learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib243.3.1" class="ltx_emph ltx_font_italic">NeurIPS</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib244" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib244.2.2.1" class="ltx_text">.</span> (2022c)</span>
<span class="ltx_bibblock">
Jie Zhang, Zhiqi Li,
Bo Li, Jianghe Xu,
Shuang Wu, Shouhong Ding, and
Chao Wu. 2022c.

</span>
<span class="ltx_bibblock">Federated Learning with Label Distribution Skew via
Logits Calibration. In <em id="bib.bib244.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib245" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib245.2.2.1" class="ltx_text">.</span> (2022f)</span>
<span class="ltx_bibblock">
Junwu Zhang, Mang Ye,
and Yao Yang. 2022f.

</span>
<span class="ltx_bibblock">Learnable Privacy-Preserving Anonymization for
Pedestrian Images.

</span>
<span class="ltx_bibblock"><em id="bib.bib245.3.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2207.11677</em>
(2022).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib246" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib246.2.2.1" class="ltx_text">.</span> (2022e)</span>
<span class="ltx_bibblock">
Lin Zhang, Li Shen,
Liang Ding, Dacheng Tao, and
Ling-Yu Duan. 2022e.

</span>
<span class="ltx_bibblock">Fine-tuning global model via data-free knowledge
distillation for non-iid federated learning. In
<em id="bib.bib246.3.1" class="ltx_emph ltx_font_italic">CVPR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib247" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib247.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Michael Zhang, Karan
Sapra, Sanja Fidler, Serena Yeung, and
Jose M Alvarez. 2021b.

</span>
<span class="ltx_bibblock">Personalized federated learning with first order
model optimization. In <em id="bib.bib247.3.1" class="ltx_emph ltx_font_italic">ICLR</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib248" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib248.2.2.1" class="ltx_text">.</span> (2021d)</span>
<span class="ltx_bibblock">
Wenyu Zhang, Xiumin Wang,
Pan Zhou, Weiwei Wu, and
Xinglin Zhang. 2021d.

</span>
<span class="ltx_bibblock">Client selection for federated learning with
non-iid data in mobile edge computing.

</span>
<span class="ltx_bibblock"><em id="bib.bib248.3.1" class="ltx_emph ltx_font_italic">IEEE Access</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib249" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib249.2.2.1" class="ltx_text">.</span> (2022a)</span>
<span class="ltx_bibblock">
Xinwei Zhang, Xiangyi
Chen, Mingyi Hong, Steven Wu, and
Jinfeng Yi. 2022a.

</span>
<span class="ltx_bibblock">Understanding Clipping for Federated Learning:
Convergence and Client-Level Differential Privacy. In
<em id="bib.bib249.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib250" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib250.2.2.1" class="ltx_text">.</span> (2022b)</span>
<span class="ltx_bibblock">
Xu Zhang, Yinchuan Li,
Wenpeng Li, Kaiyang Guo, and
Yunfeng Shao. 2022b.

</span>
<span class="ltx_bibblock">Personalized Federated Learning via Variational
Bayesian Inference. In <em id="bib.bib250.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib251" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib251.2.2.1" class="ltx_text">.</span> (2021c)</span>
<span class="ltx_bibblock">
Yuhui Zhang, Zhiwei Wang,
Jiangfeng Cao, Rui Hou, and
Dan Meng. 2021c.

</span>
<span class="ltx_bibblock">ShuffleFL: Gradient-preserving federated learning
using trusted execution environment. In <em id="bib.bib251.3.1" class="ltx_emph ltx_font_italic">ACM CF</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib252" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al<span id="bib.bib252.2.2.1" class="ltx_text">.</span> (2022d)</span>
<span class="ltx_bibblock">
Zhengming Zhang, Ashwinee
Panda, Linyue Song, Yaoqing Yang,
Michael Mahoney, Prateek Mittal,
Ramchandran Kannan, and Joseph
Gonzalez. 2022d.

</span>
<span class="ltx_bibblock">Neurotoxin: Durable Backdoors in Federated
Learning. In <em id="bib.bib252.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib253" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al<span id="bib.bib253.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Chen Zhao, Yu Wen,
Shuailou Li, Fucheng Liu, and
Dan Meng. 2021.

</span>
<span class="ltx_bibblock">Federatedreverse: A detection and defense method
against backdoor attacks in federated learning. In
<em id="bib.bib253.3.1" class="ltx_emph ltx_font_italic">IH&amp;MMSec</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib254" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al<span id="bib.bib254.2.2.1" class="ltx_text">.</span> (2021)</span>
<span class="ltx_bibblock">
Wenbo Zheng, Lan Yan,
Chao Gou, and Fei-Yue Wang.
2021.

</span>
<span class="ltx_bibblock">Federated meta-learning for fraudulent credit card
detection. In <em id="bib.bib254.3.1" class="ltx_emph ltx_font_italic">IJCAI</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib255" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al<span id="bib.bib255.2.2.1" class="ltx_text">.</span> (2021b)</span>
<span class="ltx_bibblock">
Hangyu Zhu, Jinjin Xu,
Shiqing Liu, and Yaochu Jin.
2021b.

</span>
<span class="ltx_bibblock">Federated learning on non-IID data: A survey.

</span>
<span class="ltx_bibblock"><em id="bib.bib255.3.1" class="ltx_emph ltx_font_italic">Neurocomputing</em> (2021).

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib256" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhu et al<span id="bib.bib256.2.2.1" class="ltx_text">.</span> (2021a)</span>
<span class="ltx_bibblock">
Zhuangdi Zhu, Junyuan
Hong, and Jiayu Zhou. 2021a.

</span>
<span class="ltx_bibblock">Data-free knowledge distillation for heterogeneous
federated learning. In <em id="bib.bib256.3.1" class="ltx_emph ltx_font_italic">ICML</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
<li id="bib.bib257" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhuang et al<span id="bib.bib257.2.2.1" class="ltx_text">.</span> (2020)</span>
<span class="ltx_bibblock">
Weiming Zhuang, Yonggang
Wen, Xuesen Zhang, Xin Gan,
Daiying Yin, Dongzhan Zhou,
Shuai Zhang, and Shuai Yi.
2020.

</span>
<span class="ltx_bibblock">Performance optimization of federated person
re-identification via benchmark analysis. In <em id="bib.bib257.3.1" class="ltx_emph ltx_font_italic">ACM
MM</em>.

</span>
<span class="ltx_bibblock">
</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2307.10615" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2307.10616" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2307.10616">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2307.10616" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2307.10618" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 17:27:49 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
