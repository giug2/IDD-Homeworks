<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2107.12603] Federated Learning Meets Natural Language Processing: A Survey</title><meta property="og:description" content="Federated Learning aims to learn machine learning models from multiple decentralized edge devices (e.g. mobiles) or servers without sacrificing local data privacy. Recent Natural Language Processing techniques rely on …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Federated Learning Meets Natural Language Processing: A Survey">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Federated Learning Meets Natural Language Processing: A Survey">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2107.12603">

<!--Generated on Tue Mar 19 13:53:05 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="Federated Learning Natural Language Processing Language Modelling Privacy.">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span id="id1" class="ltx_note ltx_role_institutetext"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>Deakin University</span></span></span>
<h1 class="ltx_title ltx_title_document">Federated Learning Meets Natural Language Processing: A Survey</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Ming Liu
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Stella Ho
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Mengqi Wang
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Longxiang Gao
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> Yuan Jin
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname"> He Zhang
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Federated Learning aims to learn machine learning models from multiple decentralized edge devices (e.g. mobiles) or servers without sacrificing local data privacy. Recent Natural Language Processing techniques rely on deep learning and large pre-trained language models. However, both big deep neural and language models are trained with huge amounts of data which often lies on the server side. Since text data is widely originated from end users, in this work, we look into recent NLP models and techniques which use federated learning as the learning framework. Our survey discusses major challenges in federated natural language processing, including the algorithm challenges, system challenges as well as the privacy issues. We also provide a critical review of the existing Federated NLP evaluation methods and tools. Finally, we highlight the current research gaps and future directions.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Keywords: </h6>Federated Learning Natural Language Processing Language Modelling Privacy.
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Modern machine learning algorithms rely on big amounts of data, especially when training deep neural models from high dimensional data such as text and image. Most data naturally come from end users, which are distributed and separated by different end devices. It is necessary to learn well performed machine learning models while preserving users’ privacy. Federated learning (FL) has become a new machine learning paradigm to train a model across multiple decentralized edge devices or servers holding local data samples without exchanging them. The term <span id="S1.p1.1.1" class="ltx_text ltx_font_italic">federated learning</span> was first proposed in 2016 by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>: ”We term our approach Federated Learning, since the learning task is solved by a loose federation of participating devices (which we refer to as clients) which are coordinated by a central server.” In the real world scenario, organizations such as different hospitals hold confidential data, while these hospitals would like to train a disease classification model for common use, it is hard to ask them to upload their own data to the cloud. Even within the same hospital, different departments often save patients’ information locally. Another example is human beings create lots of text data by their smartphones, these data are building blocks for now-days big language models. However, it is shown that most language models suffer from ethic problems, since they may leak users’ personal information in an unexpected way.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Recent efforts in federated learning have been devoted to interdisciplinary areas: not only machine learning is required, but also techniques from distributed optimization, statistics, cybersecurity, communication, systems, cryptography and many more. Meanwhile, the data ranges from structured to unstructured format, which is not limited to tabulars, time series and images. Among most federated learning studies, Google has led the use of federated learning in Natural Language Processing through Gboard mobile keyboard, Pixel phones and Android Messages. While Google has launched several applications on langauge modeling tasks, Apple is using FL for wake-up word detection in Siri, doc.ai is developing cross-device FL solutions for biomedical research, and Snips has introduced cross-device FL for hotword detection.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In this paper, we take a survey on the existing FL algorithms for Natural Language Processing (NLP). Starting from language modeling, we will review current federated learning algorithms on various NLP tasks: classification, recommendation, speech recognition and health text mining and others . We organize the survey as follows: in Section 2, basic federated learning concepts, frameworks, optimization toward non-IID data, privacy are discussed. Section 3 reviews federated learning in NLP. Section 4 discusses the common evaluation aspects and tools. Section 5 highlights current research challenges and some future directions. Section 6 gives the conclusion.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Federated learning</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In this section, we first review basics of federated learning, including the problem setup, non-iid data distribution, frameworks, optimization algorithms and privacy preservation. Then, we extend federated learning to other distributed machine learning paradigms and discuss their difference.</p>
</div>
<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Problem formulation</h4>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px1.p1.13" class="ltx_p">In this wrok, we consider the following distributed optimization process:</p>
<p id="S2.SS0.SSS0.Px1.p1.1.1" class="ltx_p ltx_align_center"><math id="S2.SS0.SSS0.Px1.p1.1.1.m1.4" class="ltx_Math" alttext="\min_{\textbf{w}}\{\mathcal{L}(\textbf{w})=\sum_{k=1}^{N}p_{k}\mathcal{L}_{k}(\textbf{w})\}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.1.1.m1.4a"><mrow id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.3.cmml"><msub id="S2.SS0.SSS0.Px1.p1.1.1.m1.3.3.1.1" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.3.3.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p1.1.1.m1.3.3.1.1.2" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.3.3.1.1.2.cmml">min</mi><mtext class="ltx_mathvariant_bold" id="S2.SS0.SSS0.Px1.p1.1.1.m1.3.3.1.1.3" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.3.3.1.1.3a.cmml">w</mtext></msub><mo id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2a" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.3.cmml">⁡</mo><mrow id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.3.cmml"><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.2" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.3.cmml">{</mo><mrow id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.cmml"><mrow id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.2" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.2.2" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.2.2.cmml">ℒ</mi><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.2.1" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.2.1.cmml">​</mo><mrow id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.2.3.2" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.1.1a.cmml"><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.2.3.2.1" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.1.1a.cmml">(</mo><mtext class="ltx_mathvariant_bold" id="S2.SS0.SSS0.Px1.p1.1.1.m1.1.1" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.1.1.cmml">w</mtext><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.2.3.2.2" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.1.1a.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.1" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.1.cmml">=</mo><mrow id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.cmml"><msubsup id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.cmml"><mo id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.2" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.2.cmml">∑</mo><mrow id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.3" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.3.cmml"><mi id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.3.2" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.3.2.cmml">k</mi><mo id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.3.1" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.3.1.cmml">=</mo><mn id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.3.3" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.3.3.cmml">1</mn></mrow><mi id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.3" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.3.cmml">N</mi></msubsup><mrow id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.cmml"><msub id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.2" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.2.cmml"><mi id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.2.2" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.2.2.cmml">p</mi><mi id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.2.3" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.1" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.1.cmml">​</mo><msub id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.3" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.3.2" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.3.2.cmml">ℒ</mi><mi id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.3.3" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.3.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.1a" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.1.cmml">​</mo><mrow id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.4.2" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.2.2a.cmml"><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.4.2.1" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.2.2a.cmml">(</mo><mtext class="ltx_mathvariant_bold" id="S2.SS0.SSS0.Px1.p1.1.1.m1.2.2" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.2.2.cmml">w</mtext><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.4.2.2" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.2.2a.cmml">)</mo></mrow></mrow></mrow></mrow><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.3" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.3.cmml">}</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.1.1.m1.4b"><apply id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.3.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2"><apply id="S2.SS0.SSS0.Px1.p1.1.1.m1.3.3.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.3.3.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.1.1.m1.3.3.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.3.3.1.1">subscript</csymbol><min id="S2.SS0.SSS0.Px1.p1.1.1.m1.3.3.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.3.3.1.1.2"></min><ci id="S2.SS0.SSS0.Px1.p1.1.1.m1.3.3.1.1.3a.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.3.3.1.1.3"><mtext class="ltx_mathvariant_bold" mathsize="70%" id="S2.SS0.SSS0.Px1.p1.1.1.m1.3.3.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.3.3.1.1.3">w</mtext></ci></apply><apply id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1"><eq id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.1"></eq><apply id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.2"><times id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.2.1"></times><ci id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.2.2">ℒ</ci><ci id="S2.SS0.SSS0.Px1.p1.1.1.m1.1.1a.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.2.3.2"><mtext class="ltx_mathvariant_bold" id="S2.SS0.SSS0.Px1.p1.1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.1.1">w</mtext></ci></apply><apply id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3"><apply id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1">superscript</csymbol><apply id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1">subscript</csymbol><sum id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.2"></sum><apply id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.3"><eq id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.3.1"></eq><ci id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.3.2">𝑘</ci><cn type="integer" id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.3.3.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.2.3.3">1</cn></apply></apply><ci id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.1.3">𝑁</ci></apply><apply id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2"><times id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.1"></times><apply id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.2">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.2.2">𝑝</ci><ci id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.2.3">𝑘</ci></apply><apply id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.3">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.3.2">ℒ</ci><ci id="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.3.3.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.3.3">𝑘</ci></apply><ci id="S2.SS0.SSS0.Px1.p1.1.1.m1.2.2a.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.4.4.2.2.1.3.2.4.2"><mtext class="ltx_mathvariant_bold" id="S2.SS0.SSS0.Px1.p1.1.1.m1.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.1.1.m1.2.2">w</mtext></ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.1.1.m1.4c">\min_{\textbf{w}}\{\mathcal{L}(\textbf{w})=\sum_{k=1}^{N}p_{k}\mathcal{L}_{k}(\textbf{w})\}</annotation></semantics></math>,</p>
<p id="S2.SS0.SSS0.Px1.p1.10" class="ltx_p">where <math id="S2.SS0.SSS0.Px1.p1.2.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.2.m1.1a"><mi id="S2.SS0.SSS0.Px1.p1.2.m1.1.1" xref="S2.SS0.SSS0.Px1.p1.2.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.2.m1.1b"><ci id="S2.SS0.SSS0.Px1.p1.2.m1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.2.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.2.m1.1c">N</annotation></semantics></math> is the total number of user devices, <math id="S2.SS0.SSS0.Px1.p1.3.m2.1" class="ltx_Math" alttext="p_{k}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.3.m2.1a"><msub id="S2.SS0.SSS0.Px1.p1.3.m2.1.1" xref="S2.SS0.SSS0.Px1.p1.3.m2.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p1.3.m2.1.1.2" xref="S2.SS0.SSS0.Px1.p1.3.m2.1.1.2.cmml">p</mi><mi id="S2.SS0.SSS0.Px1.p1.3.m2.1.1.3" xref="S2.SS0.SSS0.Px1.p1.3.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.3.m2.1b"><apply id="S2.SS0.SSS0.Px1.p1.3.m2.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m2.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.3.m2.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m2.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.3.m2.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m2.1.1.2">𝑝</ci><ci id="S2.SS0.SSS0.Px1.p1.3.m2.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.3.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.3.m2.1c">p_{k}</annotation></semantics></math> is the weight of the <math id="S2.SS0.SSS0.Px1.p1.4.m3.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.4.m3.1a"><mi id="S2.SS0.SSS0.Px1.p1.4.m3.1.1" xref="S2.SS0.SSS0.Px1.p1.4.m3.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.4.m3.1b"><ci id="S2.SS0.SSS0.Px1.p1.4.m3.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.4.m3.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.4.m3.1c">k</annotation></semantics></math>-th device such that <math id="S2.SS0.SSS0.Px1.p1.5.m4.1" class="ltx_Math" alttext="p_{k}\geq 0" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.5.m4.1a"><mrow id="S2.SS0.SSS0.Px1.p1.5.m4.1.1" xref="S2.SS0.SSS0.Px1.p1.5.m4.1.1.cmml"><msub id="S2.SS0.SSS0.Px1.p1.5.m4.1.1.2" xref="S2.SS0.SSS0.Px1.p1.5.m4.1.1.2.cmml"><mi id="S2.SS0.SSS0.Px1.p1.5.m4.1.1.2.2" xref="S2.SS0.SSS0.Px1.p1.5.m4.1.1.2.2.cmml">p</mi><mi id="S2.SS0.SSS0.Px1.p1.5.m4.1.1.2.3" xref="S2.SS0.SSS0.Px1.p1.5.m4.1.1.2.3.cmml">k</mi></msub><mo id="S2.SS0.SSS0.Px1.p1.5.m4.1.1.1" xref="S2.SS0.SSS0.Px1.p1.5.m4.1.1.1.cmml">≥</mo><mn id="S2.SS0.SSS0.Px1.p1.5.m4.1.1.3" xref="S2.SS0.SSS0.Px1.p1.5.m4.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.5.m4.1b"><apply id="S2.SS0.SSS0.Px1.p1.5.m4.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m4.1.1"><geq id="S2.SS0.SSS0.Px1.p1.5.m4.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m4.1.1.1"></geq><apply id="S2.SS0.SSS0.Px1.p1.5.m4.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m4.1.1.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.5.m4.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m4.1.1.2">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.5.m4.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m4.1.1.2.2">𝑝</ci><ci id="S2.SS0.SSS0.Px1.p1.5.m4.1.1.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m4.1.1.2.3">𝑘</ci></apply><cn type="integer" id="S2.SS0.SSS0.Px1.p1.5.m4.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.5.m4.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.5.m4.1c">p_{k}\geq 0</annotation></semantics></math> and <math id="S2.SS0.SSS0.Px1.p1.6.m5.1" class="ltx_Math" alttext="\sum_{k=1}^{N}p_{k}=1" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.6.m5.1a"><mrow id="S2.SS0.SSS0.Px1.p1.6.m5.1.1" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.cmml"><mrow id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.cmml"><msubsup id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.cmml"><mo id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.2" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.2.cmml">∑</mo><mrow id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.3" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.3.cmml"><mi id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.3.2" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.3.2.cmml">k</mi><mo id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.3.1" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.3.1.cmml">=</mo><mn id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.3.3" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.3.3.cmml">1</mn></mrow><mi id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.3" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.3.cmml">N</mi></msubsup><msub id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.2" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.2.cmml"><mi id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.2.2" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.2.2.cmml">p</mi><mi id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.2.3" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.2.3.cmml">k</mi></msub></mrow><mo id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.1" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.1.cmml">=</mo><mn id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.3" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.6.m5.1b"><apply id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1"><eq id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.1"></eq><apply id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2"><apply id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1">superscript</csymbol><apply id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1">subscript</csymbol><sum id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.2"></sum><apply id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.3"><eq id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.3.1"></eq><ci id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.3.2">𝑘</ci><cn type="integer" id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.3.3.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.2.3.3">1</cn></apply></apply><ci id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.1.3">𝑁</ci></apply><apply id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.2">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.2.2">𝑝</ci><ci id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.2.2.3">𝑘</ci></apply></apply><cn type="integer" id="S2.SS0.SSS0.Px1.p1.6.m5.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.6.m5.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.6.m5.1c">\sum_{k=1}^{N}p_{k}=1</annotation></semantics></math>. Suppose the <math id="S2.SS0.SSS0.Px1.p1.7.m6.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.7.m6.1a"><mi id="S2.SS0.SSS0.Px1.p1.7.m6.1.1" xref="S2.SS0.SSS0.Px1.p1.7.m6.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.7.m6.1b"><ci id="S2.SS0.SSS0.Px1.p1.7.m6.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.7.m6.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.7.m6.1c">k</annotation></semantics></math>-th device has the amount of <math id="S2.SS0.SSS0.Px1.p1.8.m7.1" class="ltx_Math" alttext="n_{k}" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.8.m7.1a"><msub id="S2.SS0.SSS0.Px1.p1.8.m7.1.1" xref="S2.SS0.SSS0.Px1.p1.8.m7.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p1.8.m7.1.1.2" xref="S2.SS0.SSS0.Px1.p1.8.m7.1.1.2.cmml">n</mi><mi id="S2.SS0.SSS0.Px1.p1.8.m7.1.1.3" xref="S2.SS0.SSS0.Px1.p1.8.m7.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.8.m7.1b"><apply id="S2.SS0.SSS0.Px1.p1.8.m7.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.8.m7.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.8.m7.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.8.m7.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.8.m7.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.8.m7.1.1.2">𝑛</ci><ci id="S2.SS0.SSS0.Px1.p1.8.m7.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.8.m7.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.8.m7.1c">n_{k}</annotation></semantics></math> training data: <math id="S2.SS0.SSS0.Px1.p1.9.m8.10" class="ltx_Math" alttext="\textbf{x}_{k}=(x_{k,1},x_{k,2},...,x_{k,n_{k}})" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.9.m8.10a"><mrow id="S2.SS0.SSS0.Px1.p1.9.m8.10.10" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.cmml"><msub id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.5" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.5.cmml"><mtext class="ltx_mathvariant_bold" id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.5.2" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.5.2a.cmml">x</mtext><mi id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.5.3" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.5.3.cmml">k</mi></msub><mo id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.4" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.4.cmml">=</mo><mrow id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.3" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.4.cmml"><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.3.4" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.4.cmml">(</mo><msub id="S2.SS0.SSS0.Px1.p1.9.m8.8.8.1.1.1" xref="S2.SS0.SSS0.Px1.p1.9.m8.8.8.1.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p1.9.m8.8.8.1.1.1.2" xref="S2.SS0.SSS0.Px1.p1.9.m8.8.8.1.1.1.2.cmml">x</mi><mrow id="S2.SS0.SSS0.Px1.p1.9.m8.2.2.2.4" xref="S2.SS0.SSS0.Px1.p1.9.m8.2.2.2.3.cmml"><mi id="S2.SS0.SSS0.Px1.p1.9.m8.1.1.1.1" xref="S2.SS0.SSS0.Px1.p1.9.m8.1.1.1.1.cmml">k</mi><mo id="S2.SS0.SSS0.Px1.p1.9.m8.2.2.2.4.1" xref="S2.SS0.SSS0.Px1.p1.9.m8.2.2.2.3.cmml">,</mo><mn id="S2.SS0.SSS0.Px1.p1.9.m8.2.2.2.2" xref="S2.SS0.SSS0.Px1.p1.9.m8.2.2.2.2.cmml">1</mn></mrow></msub><mo id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.3.5" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.4.cmml">,</mo><msub id="S2.SS0.SSS0.Px1.p1.9.m8.9.9.2.2.2" xref="S2.SS0.SSS0.Px1.p1.9.m8.9.9.2.2.2.cmml"><mi id="S2.SS0.SSS0.Px1.p1.9.m8.9.9.2.2.2.2" xref="S2.SS0.SSS0.Px1.p1.9.m8.9.9.2.2.2.2.cmml">x</mi><mrow id="S2.SS0.SSS0.Px1.p1.9.m8.4.4.2.4" xref="S2.SS0.SSS0.Px1.p1.9.m8.4.4.2.3.cmml"><mi id="S2.SS0.SSS0.Px1.p1.9.m8.3.3.1.1" xref="S2.SS0.SSS0.Px1.p1.9.m8.3.3.1.1.cmml">k</mi><mo id="S2.SS0.SSS0.Px1.p1.9.m8.4.4.2.4.1" xref="S2.SS0.SSS0.Px1.p1.9.m8.4.4.2.3.cmml">,</mo><mn id="S2.SS0.SSS0.Px1.p1.9.m8.4.4.2.2" xref="S2.SS0.SSS0.Px1.p1.9.m8.4.4.2.2.cmml">2</mn></mrow></msub><mo id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.3.6" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.4.cmml">,</mo><mi mathvariant="normal" id="S2.SS0.SSS0.Px1.p1.9.m8.7.7" xref="S2.SS0.SSS0.Px1.p1.9.m8.7.7.cmml">…</mi><mo id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.3.7" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.4.cmml">,</mo><msub id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.3.3" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.3.3.cmml"><mi id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.3.3.2" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.3.3.2.cmml">x</mi><mrow id="S2.SS0.SSS0.Px1.p1.9.m8.6.6.2.2" xref="S2.SS0.SSS0.Px1.p1.9.m8.6.6.2.3.cmml"><mi id="S2.SS0.SSS0.Px1.p1.9.m8.5.5.1.1" xref="S2.SS0.SSS0.Px1.p1.9.m8.5.5.1.1.cmml">k</mi><mo id="S2.SS0.SSS0.Px1.p1.9.m8.6.6.2.2.2" xref="S2.SS0.SSS0.Px1.p1.9.m8.6.6.2.3.cmml">,</mo><msub id="S2.SS0.SSS0.Px1.p1.9.m8.6.6.2.2.1" xref="S2.SS0.SSS0.Px1.p1.9.m8.6.6.2.2.1.cmml"><mi id="S2.SS0.SSS0.Px1.p1.9.m8.6.6.2.2.1.2" xref="S2.SS0.SSS0.Px1.p1.9.m8.6.6.2.2.1.2.cmml">n</mi><mi id="S2.SS0.SSS0.Px1.p1.9.m8.6.6.2.2.1.3" xref="S2.SS0.SSS0.Px1.p1.9.m8.6.6.2.2.1.3.cmml">k</mi></msub></mrow></msub><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.3.8" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.4.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.9.m8.10b"><apply id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10"><eq id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.4.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.4"></eq><apply id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.5.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.5"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.5.1.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.5">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.5.2a.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.5.2"><mtext class="ltx_mathvariant_bold" id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.5.2.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.5.2">x</mtext></ci><ci id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.5.3.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.5.3">𝑘</ci></apply><vector id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.4.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.3"><apply id="S2.SS0.SSS0.Px1.p1.9.m8.8.8.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.8.8.1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.9.m8.8.8.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.8.8.1.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.9.m8.8.8.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.8.8.1.1.1.2">𝑥</ci><list id="S2.SS0.SSS0.Px1.p1.9.m8.2.2.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.2.2.2.4"><ci id="S2.SS0.SSS0.Px1.p1.9.m8.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.1.1.1.1">𝑘</ci><cn type="integer" id="S2.SS0.SSS0.Px1.p1.9.m8.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.2.2.2.2">1</cn></list></apply><apply id="S2.SS0.SSS0.Px1.p1.9.m8.9.9.2.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.9.9.2.2.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.9.m8.9.9.2.2.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.9.9.2.2.2">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.9.m8.9.9.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.9.9.2.2.2.2">𝑥</ci><list id="S2.SS0.SSS0.Px1.p1.9.m8.4.4.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.4.4.2.4"><ci id="S2.SS0.SSS0.Px1.p1.9.m8.3.3.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.3.3.1.1">𝑘</ci><cn type="integer" id="S2.SS0.SSS0.Px1.p1.9.m8.4.4.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.4.4.2.2">2</cn></list></apply><ci id="S2.SS0.SSS0.Px1.p1.9.m8.7.7.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.7.7">…</ci><apply id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.3.3.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.3.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.3.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.3.3">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.3.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.10.10.3.3.3.2">𝑥</ci><list id="S2.SS0.SSS0.Px1.p1.9.m8.6.6.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.6.6.2.2"><ci id="S2.SS0.SSS0.Px1.p1.9.m8.5.5.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.5.5.1.1">𝑘</ci><apply id="S2.SS0.SSS0.Px1.p1.9.m8.6.6.2.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.6.6.2.2.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.9.m8.6.6.2.2.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.6.6.2.2.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.9.m8.6.6.2.2.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.6.6.2.2.1.2">𝑛</ci><ci id="S2.SS0.SSS0.Px1.p1.9.m8.6.6.2.2.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.9.m8.6.6.2.2.1.3">𝑘</ci></apply></list></apply></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.9.m8.10c">\textbf{x}_{k}=(x_{k,1},x_{k,2},...,x_{k,n_{k}})</annotation></semantics></math>. The local training objective <math id="S2.SS0.SSS0.Px1.p1.10.m9.1" class="ltx_math_unparsed" alttext="\mathcal{L}_{k}(.)" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.10.m9.1a"><mrow id="S2.SS0.SSS0.Px1.p1.10.m9.1b"><msub id="S2.SS0.SSS0.Px1.p1.10.m9.1.1"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p1.10.m9.1.1.2">ℒ</mi><mi id="S2.SS0.SSS0.Px1.p1.10.m9.1.1.3">k</mi></msub><mrow id="S2.SS0.SSS0.Px1.p1.10.m9.1.2"><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.10.m9.1.2.1">(</mo><mo lspace="0em" rspace="0.167em" id="S2.SS0.SSS0.Px1.p1.10.m9.1.2.2">.</mo><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.10.m9.1.2.3">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.10.m9.1c">\mathcal{L}_{k}(.)</annotation></semantics></math>is defined by:</p>
<p id="S2.SS0.SSS0.Px1.p1.11.1" class="ltx_p ltx_align_center"><math id="S2.SS0.SSS0.Px1.p1.11.1.m1.5" class="ltx_Math" alttext="\mathcal{L}_{k}(\textbf{w})=\frac{1}{n_{k}}\sum_{j=1}^{n_{k}}l(\textbf{w};x_{k,j})" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.11.1.m1.5a"><mrow id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.cmml"><mrow id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.cmml"><msub id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.2" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.2.2" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.2.2.cmml">ℒ</mi><mi id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.2.3" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.1" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.1.cmml">​</mo><mrow id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.3.2" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.3.3a.cmml"><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.3.2.1" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.3.3a.cmml">(</mo><mtext class="ltx_mathvariant_bold" id="S2.SS0.SSS0.Px1.p1.11.1.m1.3.3" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.3.3.cmml">w</mtext><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.3.2.2" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.3.3a.cmml">)</mo></mrow></mrow><mo id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.2" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.2.cmml">=</mo><mrow id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.cmml"><mfrac id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3.cmml"><mn id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3.2" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3.2.cmml">1</mn><msub id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3.3" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3.3.cmml"><mi id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3.3.2" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3.3.2.cmml">n</mi><mi id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3.3.3" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3.3.3.cmml">k</mi></msub></mfrac><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.2" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.2.cmml">​</mo><mrow id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.cmml"><msubsup id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.cmml"><mo id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.2" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.2.cmml">∑</mo><mrow id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.3" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.3.cmml"><mi id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.3.2" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.3.2.cmml">j</mi><mo id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.3.1" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.3.1.cmml">=</mo><mn id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.3.3" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.3.3.cmml">1</mn></mrow><msub id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.3" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.3.cmml"><mi id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.3.2" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.3.2.cmml">n</mi><mi id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.3.3" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.3.3.cmml">k</mi></msub></msubsup><mrow id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.3" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.3.cmml">l</mi><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.2" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.2.cmml">​</mo><mrow id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.1.1" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.1.2.cmml"><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.1.2.cmml">(</mo><mtext class="ltx_mathvariant_bold" id="S2.SS0.SSS0.Px1.p1.11.1.m1.4.4" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.4.4a.cmml">w</mtext><mo id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.1.2.cmml">;</mo><msub id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.1.1.1" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.1.1.1.cmml"><mi id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.1.1.1.2.cmml">x</mi><mrow id="S2.SS0.SSS0.Px1.p1.11.1.m1.2.2.2.4" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.2.2.2.3.cmml"><mi id="S2.SS0.SSS0.Px1.p1.11.1.m1.1.1.1.1" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.1.1.1.1.cmml">k</mi><mo id="S2.SS0.SSS0.Px1.p1.11.1.m1.2.2.2.4.1" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.2.2.2.3.cmml">,</mo><mi id="S2.SS0.SSS0.Px1.p1.11.1.m1.2.2.2.2" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.2.2.2.2.cmml">j</mi></mrow></msub><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.1.1.4" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.1.2.cmml">)</mo></mrow></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px1.p1.11.1.m1.5b"><apply id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5"><eq id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.2.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.2"></eq><apply id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3"><times id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.1"></times><apply id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.2">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.2.2">ℒ</ci><ci id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.2.3">𝑘</ci></apply><ci id="S2.SS0.SSS0.Px1.p1.11.1.m1.3.3a.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.3.3.2"><mtext class="ltx_mathvariant_bold" id="S2.SS0.SSS0.Px1.p1.11.1.m1.3.3.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.3.3">w</mtext></ci></apply><apply id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1"><times id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.2"></times><apply id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3"><divide id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3"></divide><cn type="integer" id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3.2">1</cn><apply id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3.3.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3.3">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3.3.2">𝑛</ci><ci id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3.3.3.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.3.3.3">𝑘</ci></apply></apply><apply id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1"><apply id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2">superscript</csymbol><apply id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.1.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2">subscript</csymbol><sum id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.2"></sum><apply id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.3"><eq id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.3.1"></eq><ci id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.3.2">𝑗</ci><cn type="integer" id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.3.3.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.2.3.3">1</cn></apply></apply><apply id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.3.1.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.3">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.3.2.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.3.2">𝑛</ci><ci id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.3.3.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.2.3.3">𝑘</ci></apply></apply><apply id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1"><times id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.2"></times><ci id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.3">𝑙</ci><list id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.1.1"><ci id="S2.SS0.SSS0.Px1.p1.11.1.m1.4.4a.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.4.4"><mtext class="ltx_mathvariant_bold" id="S2.SS0.SSS0.Px1.p1.11.1.m1.4.4.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.4.4">w</mtext></ci><apply id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.5.5.1.1.1.1.1.1.2">𝑥</ci><list id="S2.SS0.SSS0.Px1.p1.11.1.m1.2.2.2.3.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.2.2.2.4"><ci id="S2.SS0.SSS0.Px1.p1.11.1.m1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.1.1.1.1">𝑘</ci><ci id="S2.SS0.SSS0.Px1.p1.11.1.m1.2.2.2.2.cmml" xref="S2.SS0.SSS0.Px1.p1.11.1.m1.2.2.2.2">𝑗</ci></list></apply></list></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.11.1.m1.5c">\mathcal{L}_{k}(\textbf{w})=\frac{1}{n_{k}}\sum_{j=1}^{n_{k}}l(\textbf{w};x_{k,j})</annotation></semantics></math>,</p>
<p id="S2.SS0.SSS0.Px1.p1.12" class="ltx_p">where <math id="S2.SS0.SSS0.Px1.p1.12.m1.1" class="ltx_math_unparsed" alttext="l(.;.)" display="inline"><semantics id="S2.SS0.SSS0.Px1.p1.12.m1.1a"><mrow id="S2.SS0.SSS0.Px1.p1.12.m1.1b"><mi id="S2.SS0.SSS0.Px1.p1.12.m1.1.1">l</mi><mrow id="S2.SS0.SSS0.Px1.p1.12.m1.1.2"><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.12.m1.1.2.1">(</mo><mo lspace="0em" rspace="0.167em" id="S2.SS0.SSS0.Px1.p1.12.m1.1.2.2">.</mo><mo id="S2.SS0.SSS0.Px1.p1.12.m1.1.2.3">;</mo><mo lspace="0em" rspace="0.167em" id="S2.SS0.SSS0.Px1.p1.12.m1.1.2.4">.</mo><mo stretchy="false" id="S2.SS0.SSS0.Px1.p1.12.m1.1.2.5">)</mo></mrow></mrow><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px1.p1.12.m1.1c">l(.;.)</annotation></semantics></math> is a user-specified loss function.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Non-IID data and Learning Strategies</h4>

<div id="S2.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p1.7" class="ltx_p">Typical centralized supervised learning algorithms have the IID assumption, i.e., the training and test data is independently identically distributed. In decentralized settings like federated learning, non-IID poses a challenge because the different data distribution result in significant skewness across devices or locations. Non-IID data among devices/locations encompass many different forms. There can be skewed distribution of features (probability <math id="S2.SS0.SSS0.Px2.p1.1.m1.1" class="ltx_Math" alttext="\mathcal{P}(x)" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.1.m1.1a"><mrow id="S2.SS0.SSS0.Px2.p1.1.m1.1.2" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px2.p1.1.m1.1.2.2" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.2.2.cmml">𝒫</mi><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px2.p1.1.m1.1.2.1" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.2.1.cmml">​</mo><mrow id="S2.SS0.SSS0.Px2.p1.1.m1.1.2.3.2" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.2.cmml"><mo stretchy="false" id="S2.SS0.SSS0.Px2.p1.1.m1.1.2.3.2.1" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.2.cmml">(</mo><mi id="S2.SS0.SSS0.Px2.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml">x</mi><mo stretchy="false" id="S2.SS0.SSS0.Px2.p1.1.m1.1.2.3.2.2" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.1.m1.1b"><apply id="S2.SS0.SSS0.Px2.p1.1.m1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.2"><times id="S2.SS0.SSS0.Px2.p1.1.m1.1.2.1.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.2.1"></times><ci id="S2.SS0.SSS0.Px2.p1.1.m1.1.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.2.2">𝒫</ci><ci id="S2.SS0.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.1.m1.1.1">𝑥</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.1.m1.1c">\mathcal{P}(x)</annotation></semantics></math>), labels (probability <math id="S2.SS0.SSS0.Px2.p1.2.m2.1" class="ltx_Math" alttext="\mathcal{P}(y)" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.2.m2.1a"><mrow id="S2.SS0.SSS0.Px2.p1.2.m2.1.2" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px2.p1.2.m2.1.2.2" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.2.2.cmml">𝒫</mi><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px2.p1.2.m2.1.2.1" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.2.1.cmml">​</mo><mrow id="S2.SS0.SSS0.Px2.p1.2.m2.1.2.3.2" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.2.cmml"><mo stretchy="false" id="S2.SS0.SSS0.Px2.p1.2.m2.1.2.3.2.1" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.2.cmml">(</mo><mi id="S2.SS0.SSS0.Px2.p1.2.m2.1.1" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1.cmml">y</mi><mo stretchy="false" id="S2.SS0.SSS0.Px2.p1.2.m2.1.2.3.2.2" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.2.m2.1b"><apply id="S2.SS0.SSS0.Px2.p1.2.m2.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.2"><times id="S2.SS0.SSS0.Px2.p1.2.m2.1.2.1.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.2.1"></times><ci id="S2.SS0.SSS0.Px2.p1.2.m2.1.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.2.2">𝒫</ci><ci id="S2.SS0.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.2.m2.1.1">𝑦</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.2.m2.1c">\mathcal{P}(y)</annotation></semantics></math>), or the relationship between features and labels (e.g., varying <math id="S2.SS0.SSS0.Px2.p1.3.m3.1" class="ltx_Math" alttext="\mathcal{P}(y|x)" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.3.m3.1a"><mrow id="S2.SS0.SSS0.Px2.p1.3.m3.1.1" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3.cmml">𝒫</mi><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2.cmml">​</mo><mrow id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.2" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.2.cmml">y</mi><mo fence="false" id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.3.cmml">x</mi></mrow><mo stretchy="false" id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.3" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.3.m3.1b"><apply id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1"><times id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.2"></times><ci id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.3">𝒫</ci><apply id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1"><csymbol cd="latexml" id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.2">𝑦</ci><ci id="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.3.m3.1.1.1.1.1.3">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.3.m3.1c">\mathcal{P}(y|x)</annotation></semantics></math> or <math id="S2.SS0.SSS0.Px2.p1.4.m4.1" class="ltx_Math" alttext="\mathcal{P}(x|y)" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.4.m4.1a"><mrow id="S2.SS0.SSS0.Px2.p1.4.m4.1.1" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.3" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.3.cmml">𝒫</mi><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.2" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.2.cmml">​</mo><mrow id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1.2" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1.1.2.cmml">x</mi><mo fence="false" id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1.1.1" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1.1.1.cmml">|</mo><mi id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1.1.3.cmml">y</mi></mrow><mo stretchy="false" id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1.3" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.4.m4.1b"><apply id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1"><times id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.2"></times><ci id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.3">𝒫</ci><apply id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1"><csymbol cd="latexml" id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1.1.1">conditional</csymbol><ci id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1.1.2">𝑥</ci><ci id="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.4.m4.1.1.1.1.1.3">𝑦</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.4.m4.1c">\mathcal{P}(x|y)</annotation></semantics></math>) among devices/locations. Previous reviews categorized this this as horizontal, vertical and hybrid data partitions in Federated Learning. In this review, we focus on skewed distribution of labels, i.e., <math id="S2.SS0.SSS0.Px2.p1.5.m5.2" class="ltx_Math" alttext="\mathcal{P}_{P_{i}}(y)\not=\mathcal{P}_{P_{j}}(y)" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.5.m5.2a"><mrow id="S2.SS0.SSS0.Px2.p1.5.m5.2.3" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.cmml"><mrow id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.cmml"><msub id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2.2" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2.2.cmml">𝒫</mi><msub id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2.3" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2.3.cmml"><mi id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2.3.2" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2.3.2.cmml">P</mi><mi id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2.3.3" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2.3.3.cmml">i</mi></msub></msub><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.1" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.1.cmml">​</mo><mrow id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.3.2" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.cmml"><mo stretchy="false" id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.3.2.1" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.cmml">(</mo><mi id="S2.SS0.SSS0.Px2.p1.5.m5.1.1" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1.cmml">y</mi><mo stretchy="false" id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.3.2.2" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.cmml">)</mo></mrow></mrow><mo id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.1" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.1.cmml">≠</mo><mrow id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.cmml"><msub id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2.2" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2.2.cmml">𝒫</mi><msub id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2.3" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2.3.cmml"><mi id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2.3.2" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2.3.2.cmml">P</mi><mi id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2.3.3" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2.3.3.cmml">j</mi></msub></msub><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.1" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.1.cmml">​</mo><mrow id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.3.2" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.cmml"><mo stretchy="false" id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.3.2.1" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.cmml">(</mo><mi id="S2.SS0.SSS0.Px2.p1.5.m5.2.2" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.2.cmml">y</mi><mo stretchy="false" id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.3.2.2" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.5.m5.2b"><apply id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3"><neq id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.1.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.1"></neq><apply id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2"><times id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.1.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.1"></times><apply id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2.1.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2.2">𝒫</ci><apply id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2.3.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2.3.1.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2.3">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2.3.2.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2.3.2">𝑃</ci><ci id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2.3.3.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.2.2.3.3">𝑖</ci></apply></apply><ci id="S2.SS0.SSS0.Px2.p1.5.m5.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.1.1">𝑦</ci></apply><apply id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3"><times id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.1.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.1"></times><apply id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2.1.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2.2">𝒫</ci><apply id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2.3.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2.3.1.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2.3">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2.3.2.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2.3.2">𝑃</ci><ci id="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2.3.3.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.3.3.2.3.3">𝑗</ci></apply></apply><ci id="S2.SS0.SSS0.Px2.p1.5.m5.2.2.cmml" xref="S2.SS0.SSS0.Px2.p1.5.m5.2.2">𝑦</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.5.m5.2c">\mathcal{P}_{P_{i}}(y)\not=\mathcal{P}_{P_{j}}(y)</annotation></semantics></math> for different data partitions <math id="S2.SS0.SSS0.Px2.p1.6.m6.1" class="ltx_Math" alttext="P_{i}" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.6.m6.1a"><msub id="S2.SS0.SSS0.Px2.p1.6.m6.1.1" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p1.6.m6.1.1.2" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1.2.cmml">P</mi><mi id="S2.SS0.SSS0.Px2.p1.6.m6.1.1.3" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.6.m6.1b"><apply id="S2.SS0.SSS0.Px2.p1.6.m6.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.6.m6.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.6.m6.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1.2">𝑃</ci><ci id="S2.SS0.SSS0.Px2.p1.6.m6.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.6.m6.1c">P_{i}</annotation></semantics></math> and <math id="S2.SS0.SSS0.Px2.p1.7.m7.1" class="ltx_Math" alttext="P_{j}" display="inline"><semantics id="S2.SS0.SSS0.Px2.p1.7.m7.1a"><msub id="S2.SS0.SSS0.Px2.p1.7.m7.1.1" xref="S2.SS0.SSS0.Px2.p1.7.m7.1.1.cmml"><mi id="S2.SS0.SSS0.Px2.p1.7.m7.1.1.2" xref="S2.SS0.SSS0.Px2.p1.7.m7.1.1.2.cmml">P</mi><mi id="S2.SS0.SSS0.Px2.p1.7.m7.1.1.3" xref="S2.SS0.SSS0.Px2.p1.7.m7.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px2.p1.7.m7.1b"><apply id="S2.SS0.SSS0.Px2.p1.7.m7.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px2.p1.7.m7.1.1.1.cmml" xref="S2.SS0.SSS0.Px2.p1.7.m7.1.1">subscript</csymbol><ci id="S2.SS0.SSS0.Px2.p1.7.m7.1.1.2.cmml" xref="S2.SS0.SSS0.Px2.p1.7.m7.1.1.2">𝑃</ci><ci id="S2.SS0.SSS0.Px2.p1.7.m7.1.1.3.cmml" xref="S2.SS0.SSS0.Px2.p1.7.m7.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px2.p1.7.m7.1c">P_{j}</annotation></semantics></math>.</p>
</div>
<div id="S2.SS0.SSS0.Px2.p2" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p2.1" class="ltx_p">Previous study has shown DNN models with batch normalization suffer from Non-IID data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, the accuracy of FL reduces significantly by up to 55% for neural networks trained for highly skewed non-IID data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite>, where each clinet device trains only on a single class of data.</p>
</div>
<div id="S2.SS0.SSS0.Px2.p3" class="ltx_para">
<p id="S2.SS0.SSS0.Px2.p3.1" class="ltx_p">Common techiniques to deal with non-IID include:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p">data augmentation: create a common dataset which can be shared globally, the dataset can come from a publicly available proxy data source <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib69" title="" class="ltx_ref">69</a>]</cite>, or perhaps a distillation of the raw data following <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite>.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p">schedule client participation during training : FedFMC, FedCD, cluster similar devices / multi-center/ hirarchical clustering of local updates, FedPD, adapts the communication frequency of decentralized learning algorithms to the (skew-induced) accuracy loss between data partitions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite></p>
</div>
</li>
<li id="S2.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i3.p1" class="ltx_para">
<p id="S2.I1.i3.p1.1" class="ltx_p">greater number of models, but more communication cost:</p>
</div>
</li>
<li id="S2.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i4.p1" class="ltx_para">
<p id="S2.I1.i4.p1.1" class="ltx_p">ensemble: similar to scheduling</p>
</div>
</li>
<li id="S2.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i5.p1" class="ltx_para">
<p id="S2.I1.i5.p1.1" class="ltx_p">regularization on the server, e.g. FedAwS, server imposes a geo- metric regularizer after each round to encourage classes to be spreadout in the embedding space</p>
</div>
</li>
<li id="S2.I1.i6" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S2.I1.i6.p1" class="ltx_para">
<p id="S2.I1.i6.p1.1" class="ltx_p">personalized FL/ continual local training, based on MAML</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S2.SS0.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Optimization</h4>

<div id="S2.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px3.p1.12" class="ltx_p">While a variety of studies have made assumptions for the per-client optimization functions in the IID setting, we review basic convergence results for <math id="S2.SS0.SSS0.Px3.p1.1.m1.1" class="ltx_Math" alttext="H" display="inline"><semantics id="S2.SS0.SSS0.Px3.p1.1.m1.1a"><mi id="S2.SS0.SSS0.Px3.p1.1.m1.1.1" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1.cmml">H</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.1.m1.1b"><ci id="S2.SS0.SSS0.Px3.p1.1.m1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.1.m1.1.1">𝐻</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.1.m1.1c">H</annotation></semantics></math>-smooth convex functions under the assumption that the variance of the stochastic gradients is bounded by <math id="S2.SS0.SSS0.Px3.p1.2.m2.1" class="ltx_Math" alttext="\sigma^{2}" display="inline"><semantics id="S2.SS0.SSS0.Px3.p1.2.m2.1a"><msup id="S2.SS0.SSS0.Px3.p1.2.m2.1.1" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.cmml"><mi id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.2" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.2.cmml">σ</mi><mn id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.3" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.3.cmml">2</mn></msup><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.2.m2.1b"><apply id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1">superscript</csymbol><ci id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.2.cmml" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.2">𝜎</ci><cn type="integer" id="S2.SS0.SSS0.Px3.p1.2.m2.1.1.3.cmml" xref="S2.SS0.SSS0.Px3.p1.2.m2.1.1.3">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.2.m2.1c">\sigma^{2}</annotation></semantics></math>. Given the following notations in a standard FL setting: <math id="S2.SS0.SSS0.Px3.p1.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S2.SS0.SSS0.Px3.p1.3.m3.1a"><mi id="S2.SS0.SSS0.Px3.p1.3.m3.1.1" xref="S2.SS0.SSS0.Px3.p1.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.3.m3.1b"><ci id="S2.SS0.SSS0.Px3.p1.3.m3.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.3.m3.1c">N</annotation></semantics></math> is the total number of clients, <math id="S2.SS0.SSS0.Px3.p1.4.m4.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.SS0.SSS0.Px3.p1.4.m4.1a"><mi id="S2.SS0.SSS0.Px3.p1.4.m4.1.1" xref="S2.SS0.SSS0.Px3.p1.4.m4.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.4.m4.1b"><ci id="S2.SS0.SSS0.Px3.p1.4.m4.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.4.m4.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.4.m4.1c">M</annotation></semantics></math> is the number of participated clients per round, <math id="S2.SS0.SSS0.Px3.p1.5.m5.1" class="ltx_Math" alttext="T" display="inline"><semantics id="S2.SS0.SSS0.Px3.p1.5.m5.1a"><mi id="S2.SS0.SSS0.Px3.p1.5.m5.1.1" xref="S2.SS0.SSS0.Px3.p1.5.m5.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.5.m5.1b"><ci id="S2.SS0.SSS0.Px3.p1.5.m5.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.5.m5.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.5.m5.1c">T</annotation></semantics></math> is the total number of communication rounds, <math id="S2.SS0.SSS0.Px3.p1.6.m6.1" class="ltx_Math" alttext="K" display="inline"><semantics id="S2.SS0.SSS0.Px3.p1.6.m6.1a"><mi id="S2.SS0.SSS0.Px3.p1.6.m6.1.1" xref="S2.SS0.SSS0.Px3.p1.6.m6.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.6.m6.1b"><ci id="S2.SS0.SSS0.Px3.p1.6.m6.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.6.m6.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.6.m6.1c">K</annotation></semantics></math> is the local SGD steps per round. Federated averaging can conducted in either of the following two settings: one is to keep <math id="S2.SS0.SSS0.Px3.p1.7.m7.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.SS0.SSS0.Px3.p1.7.m7.1a"><mi id="S2.SS0.SSS0.Px3.p1.7.m7.1.1" xref="S2.SS0.SSS0.Px3.p1.7.m7.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.7.m7.1b"><ci id="S2.SS0.SSS0.Px3.p1.7.m7.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.7.m7.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.7.m7.1c">x</annotation></semantics></math> fixed in local updates during each round and compute a total of <math id="S2.SS0.SSS0.Px3.p1.8.m8.1" class="ltx_Math" alttext="KM" display="inline"><semantics id="S2.SS0.SSS0.Px3.p1.8.m8.1a"><mrow id="S2.SS0.SSS0.Px3.p1.8.m8.1.1" xref="S2.SS0.SSS0.Px3.p1.8.m8.1.1.cmml"><mi id="S2.SS0.SSS0.Px3.p1.8.m8.1.1.2" xref="S2.SS0.SSS0.Px3.p1.8.m8.1.1.2.cmml">K</mi><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px3.p1.8.m8.1.1.1" xref="S2.SS0.SSS0.Px3.p1.8.m8.1.1.1.cmml">​</mo><mi id="S2.SS0.SSS0.Px3.p1.8.m8.1.1.3" xref="S2.SS0.SSS0.Px3.p1.8.m8.1.1.3.cmml">M</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.8.m8.1b"><apply id="S2.SS0.SSS0.Px3.p1.8.m8.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.8.m8.1.1"><times id="S2.SS0.SSS0.Px3.p1.8.m8.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.8.m8.1.1.1"></times><ci id="S2.SS0.SSS0.Px3.p1.8.m8.1.1.2.cmml" xref="S2.SS0.SSS0.Px3.p1.8.m8.1.1.2">𝐾</ci><ci id="S2.SS0.SSS0.Px3.p1.8.m8.1.1.3.cmml" xref="S2.SS0.SSS0.Px3.p1.8.m8.1.1.3">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.8.m8.1c">KM</annotation></semantics></math> gradients at the current <math id="S2.SS0.SSS0.Px3.p1.9.m9.1" class="ltx_Math" alttext="x" display="inline"><semantics id="S2.SS0.SSS0.Px3.p1.9.m9.1a"><mi id="S2.SS0.SSS0.Px3.p1.9.m9.1.1" xref="S2.SS0.SSS0.Px3.p1.9.m9.1.1.cmml">x</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.9.m9.1b"><ci id="S2.SS0.SSS0.Px3.p1.9.m9.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.9.m9.1.1">𝑥</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.9.m9.1c">x</annotation></semantics></math>, in order to run accelerated minibatch SGD, the convergence rate is then upper bounded by <math id="S2.SS0.SSS0.Px3.p1.10.m10.1" class="ltx_Math" alttext="O(\frac{H}{T^{2}}+\frac{\mu}{\sqrt{TKM}})" display="inline"><semantics id="S2.SS0.SSS0.Px3.p1.10.m10.1a"><mrow id="S2.SS0.SSS0.Px3.p1.10.m10.1.1" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.cmml"><mi id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.3" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.2" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.2.cmml">​</mo><mrow id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.2" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.cmml"><mfrac id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2.cmml"><mi id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2.2" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2.2.cmml">H</mi><msup id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2.3" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2.3.cmml"><mi id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2.3.2" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2.3.2.cmml">T</mi><mn id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2.3.3" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2.3.3.cmml">2</mn></msup></mfrac><mo id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.1" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.1.cmml">+</mo><mfrac id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.cmml"><mi id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.2" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.2.cmml">μ</mi><msqrt id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.cmml"><mrow id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2.cmml"><mi id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2.2" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2.1" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2.1.cmml">​</mo><mi id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2.3" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2.3.cmml">K</mi><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2.1a" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2.1.cmml">​</mo><mi id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2.4" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2.4.cmml">M</mi></mrow></msqrt></mfrac></mrow><mo stretchy="false" id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.3" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.10.m10.1b"><apply id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1"><times id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.2.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.2"></times><ci id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.3.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.3">𝑂</ci><apply id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1"><plus id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.1"></plus><apply id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2"><divide id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2"></divide><ci id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2.2">𝐻</ci><apply id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2.3.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2.3"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2.3.1.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2.3">superscript</csymbol><ci id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2.3.2.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2.3.2">𝑇</ci><cn type="integer" id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2.3.3.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.2.3.3">2</cn></apply></apply><apply id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3"><divide id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.1.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3"></divide><ci id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.2.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.2">𝜇</ci><apply id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3"><root id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3a.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3"></root><apply id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2"><times id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2.1.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2.1"></times><ci id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2.2.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2.2">𝑇</ci><ci id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2.3.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2.3">𝐾</ci><ci id="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2.4.cmml" xref="S2.SS0.SSS0.Px3.p1.10.m10.1.1.1.1.1.3.3.2.4">𝑀</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.10.m10.1c">O(\frac{H}{T^{2}}+\frac{\mu}{\sqrt{TKM}})</annotation></semantics></math>. The other is to ignore all but 1 of the M active clients, which allows sequential SGD to run for <math id="S2.SS0.SSS0.Px3.p1.11.m11.1" class="ltx_Math" alttext="KT" display="inline"><semantics id="S2.SS0.SSS0.Px3.p1.11.m11.1a"><mrow id="S2.SS0.SSS0.Px3.p1.11.m11.1.1" xref="S2.SS0.SSS0.Px3.p1.11.m11.1.1.cmml"><mi id="S2.SS0.SSS0.Px3.p1.11.m11.1.1.2" xref="S2.SS0.SSS0.Px3.p1.11.m11.1.1.2.cmml">K</mi><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px3.p1.11.m11.1.1.1" xref="S2.SS0.SSS0.Px3.p1.11.m11.1.1.1.cmml">​</mo><mi id="S2.SS0.SSS0.Px3.p1.11.m11.1.1.3" xref="S2.SS0.SSS0.Px3.p1.11.m11.1.1.3.cmml">T</mi></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.11.m11.1b"><apply id="S2.SS0.SSS0.Px3.p1.11.m11.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.11.m11.1.1"><times id="S2.SS0.SSS0.Px3.p1.11.m11.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.11.m11.1.1.1"></times><ci id="S2.SS0.SSS0.Px3.p1.11.m11.1.1.2.cmml" xref="S2.SS0.SSS0.Px3.p1.11.m11.1.1.2">𝐾</ci><ci id="S2.SS0.SSS0.Px3.p1.11.m11.1.1.3.cmml" xref="S2.SS0.SSS0.Px3.p1.11.m11.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.11.m11.1c">KT</annotation></semantics></math> steps, this approach has an upper bound of <math id="S2.SS0.SSS0.Px3.p1.12.m12.2" class="ltx_Math" alttext="O(\frac{H}{(TK)^{2}}+\frac{\mu}{\sqrt{TK}})" display="inline"><semantics id="S2.SS0.SSS0.Px3.p1.12.m12.2a"><mrow id="S2.SS0.SSS0.Px3.p1.12.m12.2.2" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.cmml"><mi id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.3" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.3.cmml">O</mi><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.2" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.2.cmml">​</mo><mrow id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.cmml"><mo stretchy="false" id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.2" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.cmml">(</mo><mrow id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.cmml"><mfrac id="S2.SS0.SSS0.Px3.p1.12.m12.1.1" xref="S2.SS0.SSS0.Px3.p1.12.m12.1.1.cmml"><mi id="S2.SS0.SSS0.Px3.p1.12.m12.1.1.3" xref="S2.SS0.SSS0.Px3.p1.12.m12.1.1.3.cmml">H</mi><msup id="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1" xref="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.cmml"><mrow id="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1" xref="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1.1" xref="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1.1.cmml"><mi id="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1.1.2" xref="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1.1.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1.1.1" xref="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1.1.1.cmml">​</mo><mi id="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1.1.3.cmml">K</mi></mrow><mo stretchy="false" id="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1.3" xref="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1.1.cmml">)</mo></mrow><mn id="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.3" xref="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.3.cmml">2</mn></msup></mfrac><mo id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.1" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.1.cmml">+</mo><mfrac id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.cmml"><mi id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.2" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.2.cmml">μ</mi><msqrt id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3.cmml"><mrow id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3.2" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3.2.cmml"><mi id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3.2.2" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3.2.2.cmml">T</mi><mo lspace="0em" rspace="0em" id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3.2.1" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3.2.1.cmml">​</mo><mi id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3.2.3" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3.2.3.cmml">K</mi></mrow></msqrt></mfrac></mrow><mo stretchy="false" id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.3" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS0.SSS0.Px3.p1.12.m12.2b"><apply id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2"><times id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.2.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.2"></times><ci id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.3.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.3">𝑂</ci><apply id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1"><plus id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.1"></plus><apply id="S2.SS0.SSS0.Px3.p1.12.m12.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.1.1"><divide id="S2.SS0.SSS0.Px3.p1.12.m12.1.1.2.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.1.1"></divide><ci id="S2.SS0.SSS0.Px3.p1.12.m12.1.1.3.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.1.1.3">𝐻</ci><apply id="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1"><csymbol cd="ambiguous" id="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1">superscript</csymbol><apply id="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1"><times id="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1.1.1.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1.1.1"></times><ci id="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1.1.2">𝑇</ci><ci id="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.1.1.1.3">𝐾</ci></apply><cn type="integer" id="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.3.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.1.1.1.3">2</cn></apply></apply><apply id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2"><divide id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.1.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2"></divide><ci id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.2.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.2">𝜇</ci><apply id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3"><root id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3a.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3"></root><apply id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3.2.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3.2"><times id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3.2.1.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3.2.1"></times><ci id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3.2.2.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3.2.2">𝑇</ci><ci id="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3.2.3.cmml" xref="S2.SS0.SSS0.Px3.p1.12.m12.2.2.1.1.1.2.3.2.3">𝐾</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSS0.Px3.p1.12.m12.2c">O(\frac{H}{(TK)^{2}}+\frac{\mu}{\sqrt{TK}})</annotation></semantics></math>. As in the non-IID settings, key assumptions are given for inter-client gradient, local functions on each client and other participation constraints. A detailed discussion of different convergence rates for non-IID setting can be found in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Frameworks</h4>

<div id="S2.SS0.SSS0.Px4.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px4.p1.1" class="ltx_p">There are three basic frameworks for FL: centralized, decentralized and heterogeneous. In the centralized federated learning setting, a central server is used to orchestrate the different steps of the algorithms and coordinate all the participating nodes during the learning process. The server is responsible for the nodes selection at the beginning of the training process and for the aggregation of the received model updates. Since all the selected nodes have to send updates to a single entity, the server may become a bottleneck of the system. Most NLP applications like keyboard word prediction is using the cetralized setting.
In the decentralized federated learning setting, the nodes are able to coordinate themselves to obtain the global model. This setup prevents single point failures as the model updates are exchanged only between interconnected nodes without the orchestration of the central server. Nevertheless, the specific network topology may affect the performances of the learning process. Most blockchain-based federated learning falls into the decentralized setting. An increasing number of application domains involve a large set of heterogeneous clients, e.g., mobile phones and IoT devices. Most of the existing Federated learning strategies assume that local models share the same global model architecture. Recently, a new federated learning framework named HeteroFL was developed to address heterogeneous clients equipped with very different computation and communication capabilities. The HeteroFL technique can enable the training of heterogeneous local models with dynamically-varying computation complexities while still producing a single global inference model.</p>
</div>
</section>
<section id="S2.SS0.SSS0.Px5" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Privacy</h4>

<div id="S2.SS0.SSS0.Px5.p1" class="ltx_para">
<p id="S2.SS0.SSS0.Px5.p1.1" class="ltx_p">In most FL settings, privacy preservation is conducted to make sure users’ information is not leaked during the learning process. Physically, local data is not allowed to leave end users’ devises. However, it is still possible to reconstruct the original data by taking the model weights or gradients. Therefore, we consider privacy preservstion on three aspects in FL: users’ personal information, local data and machine learning models. Take the smart phone keyboard next word prediction as an example, users personal information refers to facts about their location, name, sex as well as hidden information like keyboard typing pattern. Local data then concludes the messages, photos and videos in their phones, while a machine learning model could be the a language model which predicts the next word given some preceding words. Users’ personal information is often correlated with the local data, e.g., a person’s age can be inferred with his/her chat messages.</p>
</div>
<div id="S2.SS0.SSS0.Px5.p2" class="ltx_para">
<p id="S2.SS0.SSS0.Px5.p2.1" class="ltx_p">Common techniques for privacy preservation of user data includes: differential privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>, secure Multi-Party Computation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, homomorphic encryption <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite> and trusted execution environments <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. Verifiability enables parties to prove that they have executed their parts of a computation faithfully. Techniques for verifiability include both zero knowledge proofs (ZKPs) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> and trusted execution
environments (TEEs) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. As for model attack, adversarial learning techniques can be leveraged in FL setting,</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Federated learning in NLP</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Language modeling</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">A language model (LM) refers to a model that provides probabilities of word sequences through an unsupervised distribution estimation. As an essential component for NLP systems, LM is utilised in a variety of NLP tasks, i.e., machine translation, text classification, relation extraction, question-answering, etc. In FL, most LMs are deployed on a virtual mobile keyboard, i.e., the Google Keyboard (Gboard). Thereby, recent literature are mostly produced by authors from Google, LLC. Recent works on language modelling in Federated NLP mainly target on solving a word-level LM problem in mobile industry. That is mobile keyboard suggestion, which is a well representative of federated NLP applications. To improve mobile keyboard suggestions, federated NLP models aim to be more reliable and resilient. Existing models offer quality improvements in typing or even expression (e.g., emoji) domains, such as next-world predictions, emoji predictions, query suggestions, etc.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">Considering the characteristics of mobile devices, a decentralized computation approach is constrained by computation resource and low-latency requirement. A mobile device has limited RAM and CPU budgets, while we expect keyboards to provide a quick and visible response of an input event within 20 milliseconds. Thereby, the model deployed in client sides should perform fast inference.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">Most works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> consider variants of LSTMs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> as the client model. Given the limited computation budget on each device, we expect the parameter space of a neural language model to be as small as possible without degrading model performance. CIFG <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> is a promising candidate to diminish LM’s complexity and inference-time latency. It employs a single gate to harness both the input and recurrent cell self-connections. In such a way, the amount of parameters is downsized by 25 <math id="S3.SS1.p3.1.m1.1" class="ltx_Math" alttext="\%" display="inline"><semantics id="S3.SS1.p3.1.m1.1a"><mo id="S3.SS1.p3.1.m1.1.1" xref="S3.SS1.p3.1.m1.1.1.cmml">%</mo><annotation-xml encoding="MathML-Content" id="S3.SS1.p3.1.m1.1b"><csymbol cd="latexml" id="S3.SS1.p3.1.m1.1.1.cmml" xref="S3.SS1.p3.1.m1.1.1">percent</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p3.1.m1.1c">\%</annotation></semantics></math> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> leverages CIFG for next word predictions, and simplifies the CIFG model by removing peephole connections. To further optimise the model in size and training time, they ties input embedding and CIFG output projection matrices. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> applies a pretrained CIFG network as an emoji prediction model. In particular, the pretraining process involves all layers, excluding the output projection layer, using a language learning task. To enhance performance, the authors enable embedding sharing between inputs and outputs. The pretraining of LM exhibits fast convergence for the emoji model. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> employs a character-level RNN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib63" title="" class="ltx_ref">63</a>]</cite>, targeting on out-of-vocabulary(OOV) learning tasks, under FL settings. Specifically, they use CIFG with peephole connections and a projection layer. The projection layer diminishes the dimension of output and accelerates the training. They use multi-layer LSTMs to enhance the representation power of the model, which learns the probability of word occurrence. GRU <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> is another simpler variant of the LSTM. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> leverage GRU as the neural language model for mobile keyboard next-word predictions. Similar to CIFG, it reduces the model complexity on parameter spaces without hurting the model performance. To downsize the amount of trainable parameters, they also apply tied embedding in the embedding layer and output layer by share of the weights and biases.</p>
</div>
<div id="S3.SS1.p4" class="ltx_para">
<p id="S3.SS1.p4.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>]</cite> proposes another LM for keyboard query suggestions to reduce the burden of training LSTMs. Specifically, they train a LSTM model on the server for generating suggestion candidates, while merely federated training a triggering model, that decides the occurrence of the candidates. The triggering model uses logistic regression to infer the probability of a user click, significantly lessening the computation budgets in comparison of RNN models. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> also states the direct use of RNN is not the proper means to decode due to its large parameters size, which further causes slow inference. Hereby, they propose to leverage a n-gram LM that derived from a federated RNN for decoding. In particular, they overcome large memory footprints problem and enhance model performance by introducing an approximation algorithm based on SampleApprox <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite>. It approximates RNN models into n-gram models. Still, they use CIFG and group-LSTM (GLSTM) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> for approximation. While, GPT2 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> is one of the state-of-the-art transformer-based LMs with 1.5 billion parameters. Considering its performance on centralized language modeling tasks, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> uses GPT2 as LM. They propose a dimensionality reduction algorithm to downsize the dimension of GPT2 word embedding to desired values (100 and 300).</p>
</div>
<div id="S3.SS1.p5" class="ltx_para">
<p id="S3.SS1.p5.1" class="ltx_p">For federated optimization, existing federated optimization algorithms differ in client model aggregation on the server-side. In federated language modeling, most existing works <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib67" title="" class="ltx_ref">67</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib47" title="" class="ltx_ref">47</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib52" title="" class="ltx_ref">52</a>, <a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> use FedAvg as the federated optimization algorithm. Another optimization strategy, called FedAtt, has also shown its feasibility and validity in language models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>.</p>
</div>
<div id="S3.SS1.p6" class="ltx_para">
<p id="S3.SS1.p6.1" class="ltx_p">In FedAvg, gradients, that computed locally over a large population of clients, are aggregated by the server to build a novel global model. Every client is trained by locally stored data and computes the average gradient with the current global model via one or more steps of SGD. Then, it communicates model updates with the server. The server performs the weighted aggregation of the client updates to build a novel global model. Client updates are immediately abandoned on the sever once the accumulation is completed. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> trains the global model from scratch in the server, using FedAvg. Specifically, the initial global model has either been randomly initialized or pretrained on proxy data. However, it increases the federated training rounds on clients. Thereby, it leads to a high communication and computation costs in FL. They also use SGD as the server-sided optimizer for training. They found Adam and AdaGrad provide no beneficial improvement on convergence. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite> introduces a novel federated training approach, called central pre-training with federated fine-tuning. To address the drawback in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>, the server pretrains a model with centralized and public data as the global model at the initial time. Each clients then obtains the pretrained weights as the initial weights, and later trained on local data in a federated fashion. But the improvement is limited to large network, i.e., GPT2. They also propose a pretrained word embedding layer for federated training, which only enhance accuracy for the large word embedding network (i.e., GPT2). Whereas, with the combination of pretraining models, it harms the performance. They leverage Adam as the optimizer for training. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> uses momentum and adaptive L2-norm clipping on each client’s gradient in FedAvg, leading to a faster convergence. The authors argue momentum and adaptive clipping performed on gradients improves the robustness of model convergence and performance. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> also uses clipping for regularization in FedAvg by setting the upper bound of user updating to constrain each client contribution (i.e., clipping). In addition, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> founds using momentum with Nesterov accelerated gradients significantly outperforms using SGD as server optimizer, in terms of convergence rate and model performance. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> applies Nesterov momentum as both the local and the server optimizer.</p>
</div>
<div id="S3.SS1.p7" class="ltx_para">
<p id="S3.SS1.p7.1" class="ltx_p"><cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> first introduces the attention mechanism into federated aggregation of client models. This optimization algorithm is referred as Attentive Federated Aggregation (FedAtt). It is a layer-wise soft attention mechanism applied on the trained parameters of the NN model. Intuitively, the federated optimization algorithm learns to optimize the global model by providing a good generalization on each client model for a quick local adaptation. Hereby, it reduces local training rounds and saves the computation budgets, further accelerating the learning process. The generalization in FedAtt is decided by the similarity between each client and the server, and the relative importance of each client. For a good generalization, they minimise the weighted summed distance of each client model and the global model on parameters spaces. They introduce attentive weights as the weights of the client models. Particularly, the attentive weight of each client model is a non-parametric attention score derived from each layer of NN. Differ from pre-trained FedAvg, FedAtt finds a well-generalized global model on each federated training round by iteratively updating parameters. Consequently, it further lessens the federated communication budgets. For local training, the client-sided optimizer is momentum. While, for global parameters updates, they uses SGD.</p>
</div>
<div id="S3.SS1.p8" class="ltx_para">
<p id="S3.SS1.p8.2" class="ltx_p">The existing works on federated language modeling mainly contribute on optimizing model aggregation process, but not focusing on privacy preserving approach. Adding privacy preserving techniques into federated optimization process is seen as a bonus, rather than an essential means of privacy guarantees. In Federated LMs, the commonly used privacy preserving technique is differential privacy (DP) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. A DP algorithm is expected to characterize the underlying probability distribution without compromising personally identifiable data. In general, it injects calibrated noise into the aggregated data while not affecting the outcomes. Most DP approaches are used for user-level privacy guarantees. In FL, we define user-level DP as a privacy guarantees, to preserve the trained models with or without the presence of any one client’s data. DP usually serves on the client sides before model aggregation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib62" title="" class="ltx_ref">62</a>]</cite>. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> integrates a randomized mechanism in FedAtt optimization by introducing a white noise with the mean of 0 and the standard deviation <math id="S3.SS1.p8.1.m1.1" class="ltx_Math" alttext="\sigma" display="inline"><semantics id="S3.SS1.p8.1.m1.1a"><mi id="S3.SS1.p8.1.m1.1.1" xref="S3.SS1.p8.1.m1.1.1.cmml">σ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.1.m1.1b"><ci id="S3.SS1.p8.1.m1.1.1.cmml" xref="S3.SS1.p8.1.m1.1.1">𝜎</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.1.m1.1c">\sigma</annotation></semantics></math>. They also introduce a magnitude coefficient <math id="S3.SS1.p8.2.m2.2" class="ltx_Math" alttext="\beta\in(0,1]" display="inline"><semantics id="S3.SS1.p8.2.m2.2a"><mrow id="S3.SS1.p8.2.m2.2.3" xref="S3.SS1.p8.2.m2.2.3.cmml"><mi id="S3.SS1.p8.2.m2.2.3.2" xref="S3.SS1.p8.2.m2.2.3.2.cmml">β</mi><mo id="S3.SS1.p8.2.m2.2.3.1" xref="S3.SS1.p8.2.m2.2.3.1.cmml">∈</mo><mrow id="S3.SS1.p8.2.m2.2.3.3.2" xref="S3.SS1.p8.2.m2.2.3.3.1.cmml"><mo stretchy="false" id="S3.SS1.p8.2.m2.2.3.3.2.1" xref="S3.SS1.p8.2.m2.2.3.3.1.cmml">(</mo><mn id="S3.SS1.p8.2.m2.1.1" xref="S3.SS1.p8.2.m2.1.1.cmml">0</mn><mo id="S3.SS1.p8.2.m2.2.3.3.2.2" xref="S3.SS1.p8.2.m2.2.3.3.1.cmml">,</mo><mn id="S3.SS1.p8.2.m2.2.2" xref="S3.SS1.p8.2.m2.2.2.cmml">1</mn><mo stretchy="false" id="S3.SS1.p8.2.m2.2.3.3.2.3" xref="S3.SS1.p8.2.m2.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p8.2.m2.2b"><apply id="S3.SS1.p8.2.m2.2.3.cmml" xref="S3.SS1.p8.2.m2.2.3"><in id="S3.SS1.p8.2.m2.2.3.1.cmml" xref="S3.SS1.p8.2.m2.2.3.1"></in><ci id="S3.SS1.p8.2.m2.2.3.2.cmml" xref="S3.SS1.p8.2.m2.2.3.2">𝛽</ci><interval closure="open-closed" id="S3.SS1.p8.2.m2.2.3.3.1.cmml" xref="S3.SS1.p8.2.m2.2.3.3.2"><cn type="integer" id="S3.SS1.p8.2.m2.1.1.cmml" xref="S3.SS1.p8.2.m2.1.1">0</cn><cn type="integer" id="S3.SS1.p8.2.m2.2.2.cmml" xref="S3.SS1.p8.2.m2.2.2">1</cn></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p8.2.m2.2c">\beta\in(0,1]</annotation></semantics></math> to govern the effect of the randomization in FL. However, the level of its DP guarantees is unrevealed. Hereby, it fails to show the trade-off between data utility and privacy protection for its privacy-preserving countermeasure implementation. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> incorporates the Gaussian mechanism in FedAvg to cope with the user-based heterogeneity of data in language models. In particular, it perform DP guarantees by adding Gaussian noise with a noise multiplier of 1, after clipping. They argue a high level of DP guarantees exhibits a notable reduction in unintended memorization, caused by heterogeneity of training data.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Classification</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Text Classification is procedure of identifying the pre-defined Text Classification is the procedure of identifying the pre-defined category for varied-length of text <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. It can be extended to many NLP applications including sentiment analysis, question answering and topic labeling .
Traditional text classification tasks can be deconstructed into four steps: text preprocessing, dimension reduction, classification and evaluation.
Though the deep learning models have achieved state-of-the-art results in text classification <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, uploading or sharing text data to improve model performance is not always feasible due to different privacy requirements of clients. For example, financial institutions that wish to train a chatbot for their clients cannot be allowed to upload all text data from the client-side to their central server due to strict privacy protection statements. Then applying the federated learning paradigm is an approach to solve the dilemma due to its advances in privacy preservation and collaborative training. In which, the central server can train a powerful model collaboratively with different local labeled data at client devices without uploading the raw data considering increasing privacy concerns in public.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">However, there are several challenges for applying federated learning to text classification tasks in NLP. One is to design proper aggregating algorithms to handle the gradients or weights uploaded by different client models. Traditional federated learning can be considered as a special paradigm of distributed learning, thus aggregating algorithms, such as FedAvg <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite>, FedAtt <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> has been proposed to generalize the model on the central server. Considering the unevenly distributed data at different client devices and different amounts of data at the different local datasets.
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite> has attempted the text classification using the standard FedAvg algorithm to update the model parameter with local trained models. It uses different local datasets to pre-train the word embeddings, and then concatenate all word embeddings. After filtering the widths and feature maps from the concatenated word embeddings, the max-over-time pooling was used to aggregate the features, thus getting vectors with the same length. Finally, they use softmax activation on the fully connected layer, it will translate the vectors to the final sentence classification results (categories).
Later, scientists from the Machine learning area brought in new approaches of uploading and aggregating, for example, using Knowledge distillation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> however use fine-tuning instead of FedAvg to update parameters. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> average the logits outputs from the last layer of the model instead of directly take the average of model parameters. It then uses knowledge distillation to learn the knowledge from the client devices instead of traditional.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">In addition, model compression has been introduced to federated text classification tasks due to the dilemma of computation restraints on the client-side. They attempted to reduce the model size on the client-side to enable the real application of federated learning. The computation restriction on the client devices limits the application of traditional FL. For example, 4-layer BERT or 6-layer BERT is still too large for mobile devices such as smartphones. The scholars then focus to perform the model compression while still following the federated learning paradigm. The knowledge distillation then has been applied to transfer local model information while keeping the model size small at the local devices in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite>. It utilises knowledge distillation instead of model parameter fusion to update parameters. The soft-label predictions on a public distillation dataset are sent to the central model to be distilled. Thus, the central model can learn the local knowledge on client devices through distilling the logits of different client models without sharing or uploading the local model parameters and gradients.</p>
</div>
<div id="S3.SS2.p4" class="ltx_para">
<p id="S3.SS2.p4.1" class="ltx_p">To ensure the privacy preservation of FL while keeping the communication, the encryption of data is one of the top priority considerations in applying federated learning in NLP. Encryption on communication between edge-device and central server is a standard approach in federated learning to preserve privacy for end-users on edge devices. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib71" title="" class="ltx_ref">71</a>]</cite> adds encryption on client-central server communication using differential privacy. It used the approach <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib60" title="" class="ltx_ref">60</a>]</cite> proposed the attack-adaptive aggregation which prevent the attack at the central server aggregation module.</p>
</div>
<div id="S3.SS2.p5" class="ltx_para">
<p id="S3.SS2.p5.1" class="ltx_p">To overcome the communication dilemma of FL, one-shot or few-shot federated learning was proposed to allow the central server can successfully train the central model with only one or a few rounds of communication under poor communication scenarios. However, the shared data restriction of federated learning is still left to be solved. Considering the trend of higher restriction of data sharing and uploading, it will be harder to get a sufficient size of data shared to both central servers and client servers. In this way, the knowledge distillation cannot be used to solve the model compression problem in federated learning.
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite> reduced the communication of previous federated learning by utilising the soft labels dataset distillation mentioned in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>. It thus successfully extend the soft-labeling methods to two new techniques: soft-reset and random masking, and then successfully using the dataset distillation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib61" title="" class="ltx_ref">61</a>]</cite> to realise the one-round communication federated learning for text classification tasks. Each client in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib70" title="" class="ltx_ref">70</a>]</cite> distils their local dataset to a much smaller synthetic one, and then only uploads the small-sized synthetic dataset to the server. Thus, no gradients or weights is transmitting from the client model to the central server model. The distilled dataset can be as small as one data sample per category, in this way the communication in federated learning can be reduced to as low as one round.</p>
</div>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Speech Recognition</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Speech recognition is the task of recognising speech within audio and converting it into text. Voice assistants such as Amazon Alexa or Apple Siri use on-device processing to detect wake-up words (e.g. ”Hey Siri”), which is a typical usage for speech recognition on smartphones. Only when the wake-up words are detected, further processing like information retrieval or question answering will be running on the cloud. Methods for speech recognition include dynamic time wraping <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite>, Hidden Markov Models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite> and modern end-to-end deep neural models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>. More recently, wav2vec <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> masks the speech input in the latent space and solves a contrastive task defined over a quantization of the latent representations which are jointly learned, this method demonstrates the feasibility of speech recognition with limited amounts of labeled data.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">On device wake-up word detectors face two main challenges: First, it should run with minimal memory footprint and computational cost. Second, the wake word detector should behave consistently in any usage setting, and show robustness to background noise. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib68" title="" class="ltx_ref">68</a>]</cite> performed neural network architecture evaluation and exploration for running keyword spotting on resource-constrained microcontrollers, they showed that it is possible to optimize these neural network architectures to fit within the memory and compute constraints of microcontrollers without sacrificing accuracy. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite> investigated the use of federated learning on
crowdsourced speech data to learn a resource-constrained wake word detector. They showed that a revisited Federated Averaging algorithm with per-coordinate averaging based on Adam in place of standard global averaging allows the training to reach a target stopping criterion of 95% recall per 5 FAH within 100 communication rounds on their crowdsourced dataset for an associated upstream communication costs per client of 8MB.
They also open sourced the Hey Snips wake word dataset <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>http:// research.snips.ai/datasets/keyword-spotting</span></span></span>. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib65" title="" class="ltx_ref">65</a>]</cite> proposed a decentralized feature extraction approach in federated learning to address privacy-preservation issues for speech
recognition, which is built upon a quantum convolutional neural network (QCNN) composed of a quantum circuit encoder for feature extraction, and a recurrent neural network (RNN) based end-to-end acoustic model (AM). The proposed decentralized framework takes advantage of the quantum learning progress to secure models and to avoid privacy leakage attacks. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> introduced a framework for speech recognition by which the degree of non-IID-ness can be varied, consequently illustrating a trade-off between model quality and the computational cost of federated training. They also showed that hyperparameter optimization and appropriate use of variational noise are sufficient to compensate for the quality impact of non-IID distributions, while decreasing the cost.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Sequence Tagging</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">Sequence tagging, e.g. POS tagging, Named Entity Recognition, plays an important role in both natural language understanding and information extraction. Statistical models like Hidden Markov Model and Conditional Random Fields were heavily used, modern approaches rely on deep representations from Recurrent Neural Net, Convolution Neural Net or transformer like architectures. A few recent works focus on biomedical Named Entity Recognition in the federated setting. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> pretrained and fine tuned BERT models for NER tasks in a federated manner using clinical texts, their results suggested that conducting pretraining and fine tuning in a federated manner using
data from different silos resulted in reduced performance compared with training on centralized
data. This loss of performance is mainly due
to separation of data as ”federated communication
loss” . Given the limit of data access, the experiments were conducted with clinical notes from a single healthcare system to simulate different silos. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> proposed a FedNER method for medical NER, they decomposed the medical NER model in each platform into
a shared module and a private module. The private
module was updated in each platform using the local
data to model the platform-specific characteristics.
The shared module was used to capture the shareable
knowledge among different platforms, and was updated in a server based on the aggregated gradients from multiple platforms. The private module consists of two top layers in our medical NER model, i.e, Bi-LSTM and CRF, which aim to learn
platform-specific context representations and label
decoding strategies. The private module
was only trained with local data and exchange neither its parameters nor gradients. The shared module consisted
of the other bottom layers in our NER model, such
as the word-level CNN and all types of embedding.
Different from the private module, the shared one
mainly aims to capture the semantic information in
texts. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> introduced a privacy preserving medical relation extraction model
based on federated learning, they leveraged a strategy based on knowledge distillation. Such a strategy uses the uploaded predictions of ensemble local models to train the central model without requiring uploading local parameters.</p>
</div>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.5 </span>Recommendation</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">Recommendation systems are heavily data-driven. Typical recommendation models use collaborative filtering methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>, in which past user item interactions are sufficient to detect similar users and/or similar items and make predictions based on these estimated proximities. Collaborative filtering algorithms can be further divided into two sub-categories that are generally called memory based and model based approaches. Memory based approaches directly works with values of recorded interactions, assuming no model, and are essentially based on nearest neighbours search (for example, find the closest users from a user of interest and suggest the most popular items among these neighbours). Model based approaches assume an underlying “generative” model that explains the user-item interactions and try to discover it in order to make new predictions. Unlike collaborative methods that only rely on the user-item interactions, content based approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> use additional information about users and/or items. If we consider the example of a movies recommendation system, this additional information can be, for example, the age, the sex, the job or any other personal information for users as well as the category, the main actors, the duration or other characteristics for the movies (items).</p>
</div>
<div id="S3.SS5.p2" class="ltx_para">
<p id="S3.SS5.p2.1" class="ltx_p">Given different partitions of users and items, federated recommendation models can be horizontal, vertical or transfered. In horizontal federated recommendation systems, items are shared but users belong to different parties. A typical work is Federated Collaborative Filter (FCF) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> proposed to use a central server to keep the item latent factor matrix, while the user latent factors are stored locally on each device. In the training time, the server distributes the item latent factor to each party, the participants update their user latent factor by local rating matrix data and send the item latent factor updates back to the server for aggregation. To avoid the inter trust problem, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> introduced a fully decentralized setting where participants have full access to the item latent factor and communicate with each other to update the model. Moreover, meta learning has been used for personalized federated recommendation. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> designed a meta learner to learn generalized model parameters for each participant, then each participant’s recommendation is regarded as a personalized task where a support set is used to generate the recommendation model and the gradient is computed on a query set. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> introduced another fedrated meta learning algorithm for recommendation, in which separate support and query sets are not necessary. Their approach performs relatively well within less amount of training episodes. Besides, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite> proposed DiFacto, which is a distributed factorization method and addressed the efficiency problem when it comes to large scale user item matrices. In comparison, vertical federated systems have been designed for feature distributed learning problem where participants hold different feature sets. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> proposed an
asynchronous stochastic gradient descent algorithm. Each party could use an
arbitrary model to map its local features to a local prediction. Then local predictions from different parties are aggregated into a final output using linear and
nonlinear transformations. The training procedure of each party is allowed to be
at various iterations up to a bounded delay. This approach does not share any
raw data and local models. Therefore, it has fewer privacy risks. Besides, for a
higher level of privacy, it can easily incorporate the DP technique. Similar to
horizontal FedRec, there are also works that further utilize cryptography techniques.
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> presented a secure gradient-tree boosting algorithm. This algorithm
adopts HE methods to provide lossless performance as well as preserving privacy.
And <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite> proposed a secure linear regression algorithm. MPC protocols are
designed using garbled circuits to obtain a highly scalable solution.
Parties of vertical FedRec could also be two recommenders with different item
sets. For instance, a movie RecSys and a book RecSys have a large user overlapping
but different items to recommend. It is assumed that users share a similar
taste in movies with books. With FedRec, the two parties want to train better
recommendation algorithms together in a secure and privacy-preserving way.
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite> proposed a secure, distributed item-based CF method. It jointly improves
the effect of several RecSys, which offer different subsets of items to the same
underlying population of users. Both the predicted ratings of items and their
predicted rankings could be computed without compromising privacy nor predictions’ accuracy. We refer readers to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib66" title="" class="ltx_ref">66</a>]</cite> for more detailed discussion for federated recommendation systems.</p>
</div>
</section>
<section id="S3.SS6" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.6 </span>Health Text Mining</h3>

<div id="S3.SS6.p1" class="ltx_para">
<p id="S3.SS6.p1.1" class="ltx_p">Federated learning has emerged as an important framework for health text mining, due to the privacy concern among different hospitals and medical organizations. Besides, most health data exhibits systemic bias towards some specific groups or patterns, e.g. hospitals, diseases and communities. Again, this non-IID issue raises big challenges when applying federated learning into heath text mining tasks. There have been some tasks that were studied in federated learning setting in healthcare, including patient similarity learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, patient representation learning and phenotyping <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite>, predictive or classification modeling <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>, biomedical named entity recognition.</p>
</div>
<div id="S3.SS6.p2" class="ltx_para">
<p id="S3.SS6.p2.1" class="ltx_p">Specifically, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>]</cite> designed a two-stage federated approach for medical record classification. In the first stage, they pre-trained a patient representation model by training an neural network to predict ICD and CPT codes from the text of the notes.
In the second stage, a phenotyping machine learning model was trained in a federated manner using clinical notes that are distributed across multiple sites for the target phenotype. In this stage, the notes mapped to fixed-length representations from stage one are used as input features and whether the patient has a certain disease is used as a label with one of the three classes: presence, absence or questionable. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> proposed a simple federated architecture for early detection of Type-2 diabetes. After comparing the proposed
federated learning model against the centralised approach, they showed that the federated learning model ensures significant privacy over
centralised learning model whereas compromising accuracy for a subtle extend. To cope with the imbalanced and non-IID distribution inherent in user’s monitoring data, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib64" title="" class="ltx_ref">64</a>]</cite> designed a generative convolutional autoencoder (GCAE), which aims to achieve accurate and personalized health monitoring by refining the model with a generated class-balanced dataset from user’s personal data. It is noticed that GCAE is lightweight to transfer between the cloud and edges, which is useful to reduce the communication cost of federated learning in FedHome. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite> described a federated approach on a brain age prediction model on structural MRI scans distributed across multiple sites with diverse amounts of data and subject (age) distributions. In these heterogeneous environments, a Semi-Synchronous protocol provides faster convergence.</p>
</div>
</section>
<section id="S3.SS7" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.7 </span>Other NLP Tasks</h3>

<div id="S3.SS7.p1" class="ltx_para">
<p id="S3.SS7.p1.1" class="ltx_p">More recently, FedNLP provided a research-oriented benchmarking framework for advancing federated learning (FL) in natural language processing (NLP). It uses FedML repository as the git submodule. In other words, FedNLP only focuses on adavanced models and dataset, while FedML supports various federated optimizers (e.g., FedAvg) and platforms (Distributed Computing, IoT/Mobile, Standalone). A text generation example can also be found in TensorFlow Tutorial <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://colab.research.google.com/github/tensorflow/federated/blob/master/docs/tutorials 
<br class="ltx_break">/federated_learning_for_text_generation.ipynb#scrollTo=iPFgLeZIsZ3Q</span></span></span>. So far, we have not found any work on other generation works on Machine Translation and Summatization.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Benchmarks</h2>

<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Evaluation Aspects</h3>

<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Model Evaluation</h4>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px1.p1.1" class="ltx_p">In principle, FL based NLP models should not only be evaluated against traditional performance metrics (such
as model accuracy), but also the change of model performance with different system and data settings. Various systems settings consider the number of nodes, the weight of the nodes, the quality of the nodes. While the data setting focus on different data distribution caused by either label bias or feature bias.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Communication Evaluation</h4>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px2.p1.1" class="ltx_p">There is no doubt that the communication rounds of nodes play an important role
in the performance of the model. Due to the uncertainty of the federated network, communication is huge resource consumption. There is always a natural trade off between computation and communication among the nodes and server.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Privacy Evaluation</h4>

<div id="S4.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px3.p1.1" class="ltx_p">The goal of privacy metrics is to measure the degree of privacy enjoyed by users in a system and the amount of protection offered by privacy-enhancing technologies. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib59" title="" class="ltx_ref">59</a>]</cite> discussed a selection of over eighty
privacy metrics and introduce categorizations based on the aspect of privacy they measure, their required
inputs, and the type of data that needs protection. In general, privacy metrics can be classified with four common characteristics: adversary models, data sources, inputs and output meatures.</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px4" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">User Response Evaluation</h4>

<div id="S4.SS1.SSS0.Px4.p1" class="ltx_para">
<p id="S4.SS1.SSS0.Px4.p1.1" class="ltx_p">Apart from the above automatic evaluation methods, on-line FL-based NLP models also consider the response from users, e.g. FL language models take next word click rate as an important metric, FL recommendation systems would not only like to keep old customers but also attract new customers.</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Tools</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">There are a few tools for common federated learning, including PySyft <span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://github.com/OpenMined/PySyft</span></span></span>, TFF <span id="footnote4" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span>https://www.tensorflow.org/federated</span></span></span>, FATE <span id="footnote5" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>https://github.com/FederatedAI/FATE</span></span></span>, Tensor/IO <span id="footnote6" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span>https://doc-ai.github.io/tensorio/</span></span></span>, FedML <span id="footnote7" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>https://github.com/FedML-AI/FedML</span></span></span> and FedNLP <span id="footnote8" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">8</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">8</sup><span class="ltx_tag ltx_tag_note">8</span>https://github.com/FedML-AI/FedNLP</span></span></span>.
PySyft decouples private data from model training using federated learning, DP and MPC within PyTorch. With TFF, TensorFlow provides users
with a flexible and open framework
through which they can simulate distributed
computing locally. FATE support the Federated AI
ecosystem, where a secure computing
protocol is implemented based on
homomorphic encryption and MPC. Tensor/IO is a lightweight crossplatform
library for on-device
machine learning, bringing the power
of TensorFlow and TensorFlow Lite
to iOS, Android, and React native
applications.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Challenges and Future Directions</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Algorithm-Level</h3>

<section id="S5.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Big language models</h4>

<div id="S5.SS1.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px1.p1.1" class="ltx_p">Since the paradigm pre-training + fine tuning has dominated most NLP tasks, pre-trained language models such as BERT and GPT are useful and transferable to develop downstream tasks. Often times the larger the pre-trained language model is, the more likely it will be for downstream model performance. However, in the FL setting, it is not possible to allocate large size language models like GPT-3 on the participants. Technique like knowledge distillation could be useful, it remains unknown whether downsized language can maintain the performance.</p>
</div>
</section>
<section id="S5.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Non-iid Data distributions</h4>

<div id="S5.SS1.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px2.p1.1" class="ltx_p">Real world data from different participants is always non-iid, the challenge is how to learn from high quality data and labels. Given a fixed annotation budget, active learning may be leveraged to not only select significant data points, but also actively choose worthwhile participants. Furthermore, weakly supervised learning and meta learning algorithms may also be used to use more unlabeled data from different participants.</p>
</div>
</section>
<section id="S5.SS1.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Personalization</h4>

<div id="S5.SS1.SSS0.Px3.p1" class="ltx_para">
<p id="S5.SS1.SSS0.Px3.p1.1" class="ltx_p">Personalized FL can be
viewed as an intermediate paradigm between the server-based
FL paradigm that produces a global model and the local
model training paradigm. The challenge is to strike a careful balance between local task-specific knowledge and shared knowledge useful for the generalization properties of FL models. For most deep NLP models, techniques like early shaping, sample weighing and transfer learning can be explored.</p>
</div>
</section>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>System-Level</h3>

<section id="S5.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Spatial Adaptability</h4>

<div id="S5.SS2.SSS0.Px1.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px1.p1.1" class="ltx_p">This refers to the ability of the FL system to handle variations across client data sets as a result of
(i) the addition of new clients, and/or (ii) dropouts and stragglers. These are practical issues prevalent in complex edge computing environments, where there is significant variability in hardware capabilities in terms of computation, memory, power and network connectivity</p>
</div>
</section>
<section id="S5.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Computation Communication Trade-off</h4>

<div id="S5.SS2.SSS0.Px2.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px2.p1.1" class="ltx_p">Frequent and large scale deployment of updates, monitoring, and debugging for FL NLP models is challenging. The trade-off between local and global update frequency, as well as the communication frequency can be explored.</p>
</div>
</section>
<section id="S5.SS2.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Privacy concern</h4>

<div id="S5.SS2.SSS0.Px3.p1" class="ltx_para">
<p id="S5.SS2.SSS0.Px3.p1.1" class="ltx_p">Even though FL assumes the data never leave the device, it is still possible to reconstruct the original data by taking the model weights or gradients. Privacy preservation on three aspects in FL can be explored: users’ personal information, local data and machine learning models.</p>
</div>
</section>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this paper, we review common NLP tasks in the FL setting, including language modeling, text classification, speech recognition, sequence tagging, recommendation, health text mining and other tasks. In general, the performance federated NLP models still lie behind that of centralized ones. Also, large scale pre-trained language models and advanced privacy preservation techniques have not widely been used in the FL based NLP, which could be the potentials for future research. We point out both algorithm and system level challenges for FL based NLP models. In the future, we will further evaluate representative NLP models (e.g. transformers) in the FL environment and give more comparable insights on real world applications.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Aggarwal, C.C., Zhai, C.: A survey of text classification algorithms. In:
Mining text data, pp. 163–222. Springer (2012)

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Ammad-Ud-Din, M., Ivannikova, E., Khan, S.A., Oyomno, W., Fu, Q., Tan, K.E.,
Flanagan, A.: Federated collaborative filtering for privacy-preserving
personalized recommendation system. arXiv preprint arXiv:1901.09888 (2019)

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Baevski, A., Zhou, H., Mohamed, A., Auli, M.: wav2vec 2.0: A framework for
self-supervised learning of speech representations. arXiv preprint
arXiv:2006.11477 (2020)

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Brisimi, T.S., Chen, R., Mela, T., Olshevsky, A., Paschalidis, I.C., Shi, W.:
Federated learning of predictive models from federated electronic health
records. International journal of medical informatics <span id="bib.bib4.1.1" class="ltx_text ltx_font_bold">112</span>, 59–67
(2018)

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Chen, M., Mathews, R., Ouyang, T., Beaufays, F.: Federated learning of
out-of-vocabulary words. ArXiv <span id="bib.bib5.1.1" class="ltx_text ltx_font_bold">abs/1903.10635</span> (2019)

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Chen, M., Suresh, A.T., Mathews, R., Wong, A., Allauzen, C., Beaufays, F.,
Riley, M.: Federated learning of n-gram language models. In: Proceedings of
the 23rd Conference on Computational Natural Language Learning (CoNLL). pp.
121–130. Association for Computational Linguistics, Hong Kong, China (Nov
2019). https://doi.org/10.18653/v1/K19-1012,
<a target="_blank" href="https://www.aclweb.org/anthology/K19-1012" title="" class="ltx_ref">https://www.aclweb.org/anthology/K19-1012</a>

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Cheng, K., Fan, T., Jin, Y., Liu, Y., Chen, T., Yang, Q.: Secureboost: A
lossless federated learning framework. arXiv preprint arXiv:1901.08755
(2019)

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Cho, K., Merrienboer, B.V., Gulcehre, C., Ba Hdanau, D., Bougares, F., Schwenk,
H., Bengio, Y.: Learning phrase representations using rnn encoder-decoder for
statistical machine translation. Computer Science (2014)

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Dwork, C., Mcsherry, F., Nissim, K., Smith, A.: Calibrating noise to
sensitivity in private data analysis. In: Proceedings of the Third conference
on Theory of Cryptography (2006)

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
Dwork, C.: Differential privacy: A survey of results. In: International
conference on theory and applications of models of computation. pp. 1–19.
Springer (2008)

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Ekberg, J.E., Kostiainen, K., Asokan, N.: Trusted execution environments on
mobile devices. In: Proceedings of the 2013 ACM SIGSAC conference on Computer
&amp; communications security. pp. 1497–1498 (2013)

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Fallah, A., Mokhtari, A., Ozdaglar, A.: Personalized federated learning: A
meta-learning approach. arXiv preprint arXiv:2002.07948 (2020)

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Feige, U., Fiat, A., Shamir, A.: Zero-knowledge proofs of identity. Journal of
cryptology <span id="bib.bib13.1.1" class="ltx_text ltx_font_bold">1</span>(2), 77–94 (1988)

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Ge, S., Wu, F., Wu, C., Qi, T., Huang, Y., Xie, X.: Fedner: Privacy-preserving
medical named entity recognition with federated learning. arXiv e-prints pp.
arXiv–2003 (2020)

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Goldreich, O.: Secure multi-party computation. Manuscript. Preliminary version
<span id="bib.bib15.1.1" class="ltx_text ltx_font_bold">78</span> (1998)

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Graves, A., Jaitly, N.: Towards end-to-end speech recognition with recurrent
neural networks. In: International conference on machine learning. pp.
1764–1772. PMLR (2014)

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Greff, K., Srivastava, R., Koutník, J., Steunebrink, B., Schmidhuber, J.:
Lstm: A search space odyssey. IEEE Transactions on Neural Networks and
Learning Systems <span id="bib.bib17.1.1" class="ltx_text ltx_font_bold">28</span>, 2222–2232 (2017)

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Guha, N., Talwalkar, A., Smith, V.: One-shot federated learning. arXiv preprint
arXiv:1902.11175 (2019)

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Guliani, D., Beaufays, F., Motta, G.: Training speech recognition models with
federated learning: A quality/cost framework. arXiv preprint arXiv:2010.15965
(2020)

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Hard, A., Rao, K., Mathews, R., Beaufays, F., Augenstein, S., Eichner, H.,
Kiddon, C., Ramage, D.: Federated learning for mobile keyboard prediction.
ArXiv <span id="bib.bib20.1.1" class="ltx_text ltx_font_bold">abs/1811.03604</span> (2018)

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Hegedűs, I., Danner, G., Jelasity, M.: Decentralized recommendation based
on matrix factorization: a comparison of gossip and federated learning. In:
Joint European Conference on Machine Learning and Knowledge Discovery in
Databases. pp. 317–332. Springer (2019)

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Hilmkil, A., Callh, S., Barbieri, M., Sütfeld, L.R., Zec, E.L., Mogren, O.:
Scaling federated learning for fine-tuning of large language models. arXiv
preprint arXiv:2102.00875 (2021)

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Hinton, G., Vinyals, O., Dean, J.: Distilling the knowledge in a neural
network. arXiv preprint arXiv:1503.02531 (2015)

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
Hochreiter, Sepp, Schmidhuber, Jurgen: Long short-term memory. Neural
Computation (1997)

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
Hsieh, K., Phanishayee, A., Mutlu, O., Gibbons, P.: The non-iid data quagmire
of decentralized machine learning. In: International Conference on Machine
Learning. pp. 4387–4398. PMLR (2020)

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
Hu, Y., Niu, D., Yang, J., Zhou, S.: Fdml: A collaborative machine learning
framework for distributed features. In: Proceedings of the 25th ACM SIGKDD
International Conference on Knowledge Discovery &amp; Data Mining. pp.
2232–2240 (2019)

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
Huang, L., Shea, A.L., Qian, H., Masurkar, A., Deng, H., Liu, D.: Patient
clustering improves efficiency of federated machine learning to predict
mortality and hospital stay time using distributed electronic medical
records. Journal of biomedical informatics <span id="bib.bib27.1.1" class="ltx_text ltx_font_bold">99</span>, 103291 (2019)

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
Jalalirad, A., Scavuzzo, M., Capota, C., Sprague, M.: A simple and efficient
federated recommender system. In: Proceedings of the 6th IEEE/ACM
International Conference on Big Data Computing, Applications and
Technologies. pp. 53–58 (2019)

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
Ji, S., Pan, S., Long, G., Li, X., Jiang, J., Huang, Z.: Learning private
neural language modeling with attentive aggregation. 2019 International Joint
Conference on Neural Networks (IJCNN) pp. 1–8 (2019)

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
Kairouz, P., McMahan, H.B., Avent, B., Bellet, A., Bennis, M., Bhagoji, A.N.,
Bonawitz, K., Charles, Z., Cormode, G., Cummings, R., et al.: Advances and
open problems in federated learning. arXiv preprint arXiv:1912.04977 (2019)

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
Kim, Y., Sun, J., Yu, H., Jiang, X.: Federated tensor factorization for
computational phenotyping. In: Proceedings of the 23rd ACM SIGKDD
International Conference on Knowledge Discovery and Data Mining. pp. 887–895
(2017)

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
Kuchaiev, O., Ginsburg, B.: Factorization tricks for lstm networks (2017)

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
Lee, J., Sun, J., Wang, F., Wang, S., Jun, C.H., Jiang, X.: Privacy-preserving
patient similarity learning in a federated environment: development and
analysis. JMIR medical informatics <span id="bib.bib33.1.1" class="ltx_text ltx_font_bold">6</span>(2),  e20 (2018)

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Leroy, D., Coucke, A., Lavril, T., Gisselbrecht, T., Dureau, J.: Federated
learning for keyword spotting. In: ICASSP 2019-2019 IEEE International
Conference on Acoustics, Speech and Signal Processing (ICASSP). pp.
6341–6345. IEEE (2019)

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
Li, M., Liu, Z., Smola, A.J., Wang, Y.X.: Difacto: Distributed factorization
machines. In: Proceedings of the Ninth ACM International Conference on Web
Search and Data Mining. pp. 377–386 (2016)

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
Lin, T., Kong, L., Stich, S.U., Jaggi, M.: Ensemble distillation for robust
model fusion in federated learning (2021)

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
Lincy, M., Kowshalya, A.M.: Early detection of type-2 diabetes using federated
learning (2020)

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
Liu, D., Dligach, D., Miller, T.: Two-stage federated phenotyping and patient
representation learning. arXiv preprint arXiv:1908.05596 (2019)

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
Liu, D., Miller, T.: Federated pretraining and fine tuning of bert using
clinical notes from multiple silos. arXiv preprint arXiv:2002.08562 (2020)

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
McMahan, H.B., Moore, E., Ramage, D., y Arcas, B.A.: Federated learning of deep
networks using model averaging. CoRR <span id="bib.bib40.1.1" class="ltx_text ltx_font_bold">abs/1602.05629</span> (2016),
<a target="_blank" href="http://arxiv.org/abs/1602.05629" title="" class="ltx_ref">http://arxiv.org/abs/1602.05629</a>

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
Minaee, S., Kalchbrenner, N., Cambria, E., Nikzad, N., Chenaghlu, M., Gao, J.:
Deep learning–based text classification: A comprehensive review. ACM
Computing Surveys (CSUR) <span id="bib.bib41.1.1" class="ltx_text ltx_font_bold">54</span>(3), 1–40 (2021)

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
Müller, M.: Dynamic time warping. Information retrieval for music and
motion pp. 69–84 (2007)

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
Naehrig, M., Lauter, K., Vaikuntanathan, V.: Can homomorphic encryption be
practical? In: Proceedings of the 3rd ACM workshop on Cloud computing
security workshop. pp. 113–124 (2011)

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
Pazzani, M.J., Billsus, D.: Content-based recommendation systems. In: The
adaptive web, pp. 325–341. Springer (2007)

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
Rabiner, L., Juang, B.: An introduction to hidden markov models. ieee assp
magazine <span id="bib.bib45.1.1" class="ltx_text ltx_font_bold">3</span>(1), 4–16 (1986)

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
Radford, A.: Language models are unsupervised multitask learners

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
Ramaswamy, S.I., Mathews, R., Rao, K., Beaufays, F.: Federated learning for
emoji prediction in a mobile keyboard. ArXiv <span id="bib.bib47.1.1" class="ltx_text ltx_font_bold">abs/1906.04329</span> (2019)

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
Sattler, F., Marban, A., Rischke, R., Samek, W.: Communication-efficient
federated distillation. arXiv preprint arXiv:2012.00632 (2020)

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
Sharma, P., Shamout, F.E., Clifton, D.A.: Preserving patient privacy while
training a predictive model of in-hospital mortality. arXiv preprint
arXiv:1912.00354 (2019)

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
Shmueli, E., Tassa, T.: Secure multi-party protocols for item-based
collaborative filtering. In: Proceedings of the eleventh ACM conference on
recommender systems. pp. 89–97 (2017)

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Slavkovic, A.B., Nardi, Y., Tibbits, M.M.: ” secure” logistic regression of
horizontally and vertically partitioned distributed databases. In: Seventh
IEEE International Conference on Data Mining Workshops (ICDMW 2007). pp.
723–728. IEEE (2007)

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
Stremmel, J., Singh, A.: Pretraining federated text models for next word
prediction. ArXiv <span id="bib.bib52.1.1" class="ltx_text ltx_font_bold">abs/2005.04828</span> (2020)

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
Stripelis, D., Ambite, J.L., Lam, P., Thompson, P.: Scaling neuroscience
research using federated learning. arXiv preprint arXiv:2102.08440 (2021)

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
Sucholutsky, I., Schonlau, M.: Soft-label dataset distillation and text dataset
distillation. arXiv preprint arXiv:1910.02551 (2019)

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Suganeshwari, G., Ibrahim, S.S.: A survey on collaborative filtering based
recommendation system. In: Proceedings of the 3rd International Symposium on
Big Data and Cloud Computing Challenges (ISBCC–16’). pp. 503–518.
Springer (2016)

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Sui, D., Chen, Y., Zhao, J., Jia, Y., Xie, Y., Sun, W.: Feded: Federated
learning via ensemble distillation for medical relation extraction. In:
Proceedings of the 2020 Conference on Empirical Methods in Natural Language
Processing (EMNLP). pp. 2118–2128 (2020)

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
Suresh, A.T., Roark, B., Riley, M., Schogol, V.: Approximating probabilistic
models as weighted finite automata. ArXiv <span id="bib.bib57.1.1" class="ltx_text ltx_font_bold">abs/1905.08701</span> (2019)

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
Thakkar, O., Ramaswamy, S.I., Mathews, R., Beaufays, F.: Understanding
unintended memorization in federated learning. ArXiv <span id="bib.bib58.1.1" class="ltx_text ltx_font_bold">abs/2006.07490</span>
(2020)

</span>
</li>
<li id="bib.bib59" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[59]</span>
<span class="ltx_bibblock">
Wagner, I., Eckhoff, D.: Technical privacy metrics: a systematic survey. ACM
Computing Surveys (CSUR) <span id="bib.bib59.1.1" class="ltx_text ltx_font_bold">51</span>(3), 1–38 (2018)

</span>
</li>
<li id="bib.bib60" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[60]</span>
<span class="ltx_bibblock">
Wan, C.P., Chen, Q.: Robust federated learning with attack-adaptive
aggregation. arXiv preprint arXiv:2102.05257 (2021)

</span>
</li>
<li id="bib.bib61" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[61]</span>
<span class="ltx_bibblock">
Wang, T., Zhu, J.Y., Torralba, A., Efros, A.A.: Dataset distillation. arXiv
preprint arXiv:1811.10959 (2018)

</span>
</li>
<li id="bib.bib62" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[62]</span>
<span class="ltx_bibblock">
Wei, K., Li, J., Ding, M., Ma, C., Yang, H.H., Farhad, F., Jin, S., Quek, T.,
Poor, H.: Federated learning with differential privacy: Algorithms and
performance analysis. IEEE Transactions on Information Forensics and Security
<span id="bib.bib62.1.1" class="ltx_text ltx_font_bold">15</span>, 3454–3469 (2020)

</span>
</li>
<li id="bib.bib63" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[63]</span>
<span class="ltx_bibblock">
Williams, R.J., Zipser, D.: A learning algorithm for continually running fully
recurrent neural networks. Neural Computation <span id="bib.bib63.1.1" class="ltx_text ltx_font_bold">1</span>(2) (1998)

</span>
</li>
<li id="bib.bib64" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[64]</span>
<span class="ltx_bibblock">
Wu, Q., Chen, X., Zhou, Z., Zhang, J.: Fedhome: Cloud-edge based personalized
federated learning for in-home health monitoring. IEEE Transactions on Mobile
Computing (2020)

</span>
</li>
<li id="bib.bib65" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[65]</span>
<span class="ltx_bibblock">
Yang, C.H.H., Qi, J., Chen, S.Y.C., Chen, P.Y., Siniscalchi, S.M., Ma, X., Lee,
C.H.: Decentralizing feature extraction with quantum convolutional neural
network for automatic speech recognition. arXiv preprint arXiv:2010.13309
(2020)

</span>
</li>
<li id="bib.bib66" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[66]</span>
<span class="ltx_bibblock">
Yang, L., Tan, B., Zheng, V.W., Chen, K., Yang, Q.: Federated recommendation
systems. In: Federated Learning, pp. 225–239. Springer (2020)

</span>
</li>
<li id="bib.bib67" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[67]</span>
<span class="ltx_bibblock">
Yang, T., Andrew, G., Eichner, H., Sun, H., Li, W., Kong, N., Ramage, D.,
Beaufays, F.: Applied federated learning: Improving google keyboard query
suggestions. ArXiv <span id="bib.bib67.1.1" class="ltx_text ltx_font_bold">abs/1812.02903</span> (2018)

</span>
</li>
<li id="bib.bib68" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[68]</span>
<span class="ltx_bibblock">
Zhang, Y., Suda, N., Lai, L., Chandra, V.: Hello edge: Keyword spotting on
microcontrollers. arXiv preprint arXiv:1711.07128 (2017)

</span>
</li>
<li id="bib.bib69" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[69]</span>
<span class="ltx_bibblock">
Zhao, Y., Li, M., Lai, L., Suda, N., Civin, D., Chandra, V.: Federated learning
with non-iid data. arXiv preprint arXiv:1806.00582 (2018)

</span>
</li>
<li id="bib.bib70" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[70]</span>
<span class="ltx_bibblock">
Zhou, Y., Pu, G., Ma, X., Li, X., Wu, D.: Distilled one-shot federated learning
(2020)

</span>
</li>
<li id="bib.bib71" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[71]</span>
<span class="ltx_bibblock">
Zhu, X., Wang, J., Hong, Z., Xiao, J.: Empirical studies of institutional
federated learning for natural language processing. In: Proceedings of the
2020 Conference on Empirical Methods in Natural Language Processing:
Findings. pp. 625–634 (2020)

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2107.12602" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2107.12603" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2107.12603">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2107.12603" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2107.12604" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar 19 13:53:05 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
