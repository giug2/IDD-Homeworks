<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Agentic Information Retrieval</title>
<!--Generated on Sun Oct 13 03:43:58 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.09713v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S1" title="In Agentic Information Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>The Trends of IR</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S2" title="In Agentic Information Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Agentic IR</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S2.SS1" title="In 2 Agentic IR â€£ Agentic Information Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Task Formulation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S2.SS2" title="In 2 Agentic IR â€£ Agentic Information Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Architecture</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S2.SS3" title="In 2 Agentic IR â€£ Agentic Information Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Key Methods</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S3" title="In Agentic Information Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Application Scenarios and Case Studies</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S3.SS1" title="In 3 Application Scenarios and Case Studies â€£ Agentic Information Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Life Assistant</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S3.SS2" title="In 3 Application Scenarios and Case Studies â€£ Agentic Information Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Business Assistant</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S3.SS3" title="In 3 Application Scenarios and Case Studies â€£ Agentic Information Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Coding Assistant</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S4" title="In Agentic Information Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Challenges</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S5" title="In Agentic Information Retrieval"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusions</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Agentic Information Retrieval</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Weinan Zhang, Junwei Liao, Ning Li, Kounianhua Du
<br class="ltx_break"/>Shanghai Jiao Tong University
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id1.1.id1">wnzhang@sjtu.edu.cn</span>
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id2.id1">What will information entry look like in the next generation of digital products? Since the 1970s, user access to relevant information has relied on domain-specific architectures of information retrieval (IR). Over the past two decades, the advent of modern IR systems, including web search engines and personalized recommender systems, has greatly improved the efficiency of retrieving relevant information from vast data corpora. However, the core paradigm of these IR systems remains largely unchanged, relying on filtering a predefined set of candidate items. Since 2022, breakthroughs in large language models (LLMs) have begun transforming how information is accessed, establishing a new technical paradigm. In this position paper, we introduce Agentic Information Retrieval (Agentic IR), a novel IR paradigm shaped by the capabilities of LLM agents. Agentic IR expands the scope of accessible tasks and leverages a suite of new techniques to redefine information retrieval. We discuss three types of cutting-edge applications of agentic IR and the challenges faced. We propose that agentic IR holds promise for generating innovative applications, potentially becoming a central information entry point in future digital ecosystems.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>The Trends of IR</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Information retrieval (IR) refers to the tasks or techniques of finding information items to match the userâ€™s needs from a large corpus. Broadly speaking, there exists a wide range of real-world IR applications, including web search, item recommendation, online advertising, online travel agency, online shopping, online food delivery, etc. <cite class="ltx_cite ltx_citemacro_citep">(Singhal etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib1" title="">2001</a>; Wang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib2" title="">2017</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">As an automated information filtering system,
the traditional IR generally employs a specialized architecture to retrieve, rank, and select the information item according to the query.
Web search engines, a remarkable example of IR, employ an inverted index system to maintain the posting list of documents for each term (or word). Given a query, the candidate documents containing the query terms are retrieved using the inverted index, and then ranked using a refined or learned scoring function. Finally, the top-ranked documents are presented on the search engine result page (SERP) <cite class="ltx_cite ltx_citemacro_citep">(Baeza-Yates etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib3" title="">1999</a>)</cite>.
Personalized recommender systems, another major IR example, typically involve retrieval, pre-ranking (optional), ranking, and re-ranking stages to perform a funnel-like filtering of the items and finally present the re-ranked top items to the user <cite class="ltx_cite ltx_citemacro_citep">(Qin etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib4" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">Despite their technical and business success, the above IR architectures need to be predefined from the very beginning of the application, and, once built, remain unchanged throughout the lifetime of the IR systems, so as to the information flow during each IR process.
Based on the fixed information flow of the predefined architectures, it is difficult to perform interactive or complex IR tasks (with multiple-step reasoning and actions). For example, on a search engine, the user needs to carefully refine the search keywords to iteratively get the updated SERPs to find the webpage he is seeking; on an e-commerce recommender system, the user has no effective way to change the recommended item list for him rapidly. Moreover, the returned items are as they are â€” there is no way to manipulate the information items across the IR process â€” which keeps the IR scenarios simple and limited.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Since the beginning of 2023, with the success of large language models (LLMs) such as ChatGPT, Claude, and GPT4, the generative question-answering applications become much popular. Furthermore, by wrapping an LLM as an AI agent to interact with the environment, it becomes feasible to let the agent to perform multiple (or/and multi-round) reasoning-action steps to accomplish completed tasks. In addition, a variety of tools, including search engines, calculators, weather forecasters, databases, can be accessed by the agents via APIs, which largely enhance the task-solving abilities of the AI agents. With such a background, it is good timing to think about the next-generation IR architectures in the era of LLM-driven AI agents.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In this position paper, we introduce the concept of <em class="ltx_emph ltx_font_italic" id="S1.p5.1.1">agentic information retrieval</em> (Agentic IR), a novel paradigm of IR techniques that could serve as the key architecture form of the next-generation information retrieval. In general, agentic IR differs from traditional IR in the following aspects.</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i1.p1.1.1">Task scope.</span>
Agentic IR deals with a much wider scope of tasks. For agentic IR, the user shows an expected information state, while the agent takes actions to reach the user to that information state. As such, the traditional IR is a special case of agentic IR, i.e., to present the relevant information items to the user.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i2.p1.1.1">Architecture.</span>
Unlike the fixed domain-specific architecture for the served scenario in traditional IR, agentic IR generically employs a unified architecture, i.e., the AI agent, to different scenarios, as illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S1.F1" title="Figure 1 â€£ 1 The Trends of IR â€£ Agentic Information Retrieval"><span class="ltx_text ltx_ref_tag">1</span></a>. The key difference between the architectures of agentic IR and traditional IR is that the agent solves the problem with the recurrence architecture of observation, reasoning, and action across multiple steps, while the traditional IR tries to solve the problem in one interaction step with a large architecture.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S1.I1.i3.p1.1.1">Key methods.</span>
The key methods of agentic IR include prompt engineering, retrieval-augmented generation, fine-tuning with supervised and reinforcement learning, multi-agent systems, which are essentially different from those of traditional IR, such as indexing, retrieval methods, scoring function, learning to rank, and pseudo relevance feedback.</p>
</div>
</li>
</ul>
</div>
<div class="ltx_para" id="S1.p6">
<p class="ltx_p" id="S1.p6.1">The remaining part of this paper is organized as follows. In Section <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S2" title="2 Agentic IR â€£ Agentic Information Retrieval"><span class="ltx_text ltx_ref_tag">2</span></a>, we formally present agentic IR including task formulation, architecture form, and some key methods. Then, in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S3" title="3 Application Scenarios and Case Studies â€£ Agentic Information Retrieval"><span class="ltx_text ltx_ref_tag">3</span></a>, we describe several emergent representative applications of agentic IR, namely life assistant, business assistant, and coding assistant. Later we discuss the current challenges of agentic IR in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S4" title="4 Challenges â€£ Agentic Information Retrieval"><span class="ltx_text ltx_ref_tag">4</span></a>. Finally we conclude this paper in Section <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S5" title="5 Conclusions â€£ Agentic Information Retrieval"><span class="ltx_text ltx_ref_tag">5</span></a>.</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="227" id="S1.F1.g1" src="x1.png" width="822"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The paradigms of traditional IR vs. agentic IR.</figcaption>
</figure>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Agentic IR</h2>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Task Formulation</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.3">Let <math alttext="s_{*}" class="ltx_Math" display="inline" id="S2.SS1.p1.1.m1.1"><semantics id="S2.SS1.p1.1.m1.1a"><msub id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml"><mi id="S2.SS1.p1.1.m1.1.1.2" xref="S2.SS1.p1.1.m1.1.1.2.cmml">s</mi><mo id="S2.SS1.p1.1.m1.1.1.3" xref="S2.SS1.p1.1.m1.1.1.3.cmml">âˆ—</mo></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><apply id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.p1.1.m1.1.1.2.cmml" xref="S2.SS1.p1.1.m1.1.1.2">ğ‘ </ci><times id="S2.SS1.p1.1.m1.1.1.3.cmml" xref="S2.SS1.p1.1.m1.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">s_{*}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.1.m1.1d">italic_s start_POSTSUBSCRIPT âˆ— end_POSTSUBSCRIPT</annotation></semantics></math> denote the userâ€™s target information state, which can be a desired document in a document retrieval task, a satisfying answer in a QA task, or an accomplished accurate order for an online shopping task, etc.
Let <math alttext="x(s_{*})" class="ltx_Math" display="inline" id="S2.SS1.p1.2.m2.1"><semantics id="S2.SS1.p1.2.m2.1a"><mrow id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml"><mi id="S2.SS1.p1.2.m2.1.1.3" xref="S2.SS1.p1.2.m2.1.1.3.cmml">x</mi><mo id="S2.SS1.p1.2.m2.1.1.2" xref="S2.SS1.p1.2.m2.1.1.2.cmml">â¢</mo><mrow id="S2.SS1.p1.2.m2.1.1.1.1" xref="S2.SS1.p1.2.m2.1.1.1.1.1.cmml"><mo id="S2.SS1.p1.2.m2.1.1.1.1.2" stretchy="false" xref="S2.SS1.p1.2.m2.1.1.1.1.1.cmml">(</mo><msub id="S2.SS1.p1.2.m2.1.1.1.1.1" xref="S2.SS1.p1.2.m2.1.1.1.1.1.cmml"><mi id="S2.SS1.p1.2.m2.1.1.1.1.1.2" xref="S2.SS1.p1.2.m2.1.1.1.1.1.2.cmml">s</mi><mo id="S2.SS1.p1.2.m2.1.1.1.1.1.3" xref="S2.SS1.p1.2.m2.1.1.1.1.1.3.cmml">âˆ—</mo></msub><mo id="S2.SS1.p1.2.m2.1.1.1.1.3" stretchy="false" xref="S2.SS1.p1.2.m2.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><apply id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1"><times id="S2.SS1.p1.2.m2.1.1.2.cmml" xref="S2.SS1.p1.2.m2.1.1.2"></times><ci id="S2.SS1.p1.2.m2.1.1.3.cmml" xref="S2.SS1.p1.2.m2.1.1.3">ğ‘¥</ci><apply id="S2.SS1.p1.2.m2.1.1.1.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.2.m2.1.1.1.1.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p1.2.m2.1.1.1.1.1.2.cmml" xref="S2.SS1.p1.2.m2.1.1.1.1.1.2">ğ‘ </ci><times id="S2.SS1.p1.2.m2.1.1.1.1.1.3.cmml" xref="S2.SS1.p1.2.m2.1.1.1.1.1.3"></times></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">x(s_{*})</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.2.m2.1d">italic_x ( italic_s start_POSTSUBSCRIPT âˆ— end_POSTSUBSCRIPT )</annotation></semantics></math> denote the instruction text provided by the user describing his target information state <math alttext="s_{*}" class="ltx_Math" display="inline" id="S2.SS1.p1.3.m3.1"><semantics id="S2.SS1.p1.3.m3.1a"><msub id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml"><mi id="S2.SS1.p1.3.m3.1.1.2" xref="S2.SS1.p1.3.m3.1.1.2.cmml">s</mi><mo id="S2.SS1.p1.3.m3.1.1.3" xref="S2.SS1.p1.3.m3.1.1.3.cmml">âˆ—</mo></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><apply id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.3.m3.1.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS1.p1.3.m3.1.1.2.cmml" xref="S2.SS1.p1.3.m3.1.1.2">ğ‘ </ci><times id="S2.SS1.p1.3.m3.1.1.3.cmml" xref="S2.SS1.p1.3.m3.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">s_{*}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.3.m3.1d">italic_s start_POSTSUBSCRIPT âˆ— end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.10">Let <math alttext="\pi(a_{t}|x(s_{t}))" class="ltx_Math" display="inline" id="S2.SS1.p2.1.m1.1"><semantics id="S2.SS1.p2.1.m1.1a"><mrow id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml"><mi id="S2.SS1.p2.1.m1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.3.cmml">Ï€</mi><mo id="S2.SS1.p2.1.m1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.2.cmml">â¢</mo><mrow id="S2.SS1.p2.1.m1.1.1.1.1" xref="S2.SS1.p2.1.m1.1.1.1.1.1.cmml"><mo id="S2.SS1.p2.1.m1.1.1.1.1.2" stretchy="false" xref="S2.SS1.p2.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS1.p2.1.m1.1.1.1.1.1" xref="S2.SS1.p2.1.m1.1.1.1.1.1.cmml"><msub id="S2.SS1.p2.1.m1.1.1.1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.1.1.1.3.cmml"><mi id="S2.SS1.p2.1.m1.1.1.1.1.1.3.2" xref="S2.SS1.p2.1.m1.1.1.1.1.1.3.2.cmml">a</mi><mi id="S2.SS1.p2.1.m1.1.1.1.1.1.3.3" xref="S2.SS1.p2.1.m1.1.1.1.1.1.3.3.cmml">t</mi></msub><mo fence="false" id="S2.SS1.p2.1.m1.1.1.1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.1.1.1.2.cmml">|</mo><mrow id="S2.SS1.p2.1.m1.1.1.1.1.1.1" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.cmml"><mi id="S2.SS1.p2.1.m1.1.1.1.1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.3.cmml">x</mi><mo id="S2.SS1.p2.1.m1.1.1.1.1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.1" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.2.cmml">s</mi><mi id="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S2.SS1.p2.1.m1.1.1.1.1.3" stretchy="false" xref="S2.SS1.p2.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><apply id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1"><times id="S2.SS1.p2.1.m1.1.1.2.cmml" xref="S2.SS1.p2.1.m1.1.1.2"></times><ci id="S2.SS1.p2.1.m1.1.1.3.cmml" xref="S2.SS1.p2.1.m1.1.1.3">ğœ‹</ci><apply id="S2.SS1.p2.1.m1.1.1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1"><csymbol cd="latexml" id="S2.SS1.p2.1.m1.1.1.1.1.1.2.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.2">conditional</csymbol><apply id="S2.SS1.p2.1.m1.1.1.1.1.1.3.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p2.1.m1.1.1.1.1.1.3.1.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.SS1.p2.1.m1.1.1.1.1.1.3.2.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.3.2">ğ‘</ci><ci id="S2.SS1.p2.1.m1.1.1.1.1.1.3.3.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.3.3">ğ‘¡</ci></apply><apply id="S2.SS1.p2.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1"><times id="S2.SS1.p2.1.m1.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.2"></times><ci id="S2.SS1.p2.1.m1.1.1.1.1.1.1.3.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.3">ğ‘¥</ci><apply id="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.2">ğ‘ </ci><ci id="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.SS1.p2.1.m1.1.1.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">\pi(a_{t}|x(s_{t}))</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.1.m1.1d">italic_Ï€ ( italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_x ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) )</annotation></semantics></math> denote the policy of the agent, where <math alttext="s_{t}" class="ltx_Math" display="inline" id="S2.SS1.p2.2.m2.1"><semantics id="S2.SS1.p2.2.m2.1a"><msub id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml"><mi id="S2.SS1.p2.2.m2.1.1.2" xref="S2.SS1.p2.2.m2.1.1.2.cmml">s</mi><mi id="S2.SS1.p2.2.m2.1.1.3" xref="S2.SS1.p2.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><apply id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.2.m2.1.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.p2.2.m2.1.1.2.cmml" xref="S2.SS1.p2.2.m2.1.1.2">ğ‘ </ci><ci id="S2.SS1.p2.2.m2.1.1.3.cmml" xref="S2.SS1.p2.2.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">s_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.2.m2.1d">italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> denotes the information state at step <math alttext="t" class="ltx_Math" display="inline" id="S2.SS1.p2.3.m3.1"><semantics id="S2.SS1.p2.3.m3.1a"><mi id="S2.SS1.p2.3.m3.1.1" xref="S2.SS1.p2.3.m3.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.m3.1b"><ci id="S2.SS1.p2.3.m3.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.3.m3.1c">t</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.3.m3.1d">italic_t</annotation></semantics></math>, <math alttext="x(s_{t})" class="ltx_Math" display="inline" id="S2.SS1.p2.4.m4.1"><semantics id="S2.SS1.p2.4.m4.1a"><mrow id="S2.SS1.p2.4.m4.1.1" xref="S2.SS1.p2.4.m4.1.1.cmml"><mi id="S2.SS1.p2.4.m4.1.1.3" xref="S2.SS1.p2.4.m4.1.1.3.cmml">x</mi><mo id="S2.SS1.p2.4.m4.1.1.2" xref="S2.SS1.p2.4.m4.1.1.2.cmml">â¢</mo><mrow id="S2.SS1.p2.4.m4.1.1.1.1" xref="S2.SS1.p2.4.m4.1.1.1.1.1.cmml"><mo id="S2.SS1.p2.4.m4.1.1.1.1.2" stretchy="false" xref="S2.SS1.p2.4.m4.1.1.1.1.1.cmml">(</mo><msub id="S2.SS1.p2.4.m4.1.1.1.1.1" xref="S2.SS1.p2.4.m4.1.1.1.1.1.cmml"><mi id="S2.SS1.p2.4.m4.1.1.1.1.1.2" xref="S2.SS1.p2.4.m4.1.1.1.1.1.2.cmml">s</mi><mi id="S2.SS1.p2.4.m4.1.1.1.1.1.3" xref="S2.SS1.p2.4.m4.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.SS1.p2.4.m4.1.1.1.1.3" stretchy="false" xref="S2.SS1.p2.4.m4.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.4.m4.1b"><apply id="S2.SS1.p2.4.m4.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1"><times id="S2.SS1.p2.4.m4.1.1.2.cmml" xref="S2.SS1.p2.4.m4.1.1.2"></times><ci id="S2.SS1.p2.4.m4.1.1.3.cmml" xref="S2.SS1.p2.4.m4.1.1.3">ğ‘¥</ci><apply id="S2.SS1.p2.4.m4.1.1.1.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.4.m4.1.1.1.1.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p2.4.m4.1.1.1.1.1.2.cmml" xref="S2.SS1.p2.4.m4.1.1.1.1.1.2">ğ‘ </ci><ci id="S2.SS1.p2.4.m4.1.1.1.1.1.3.cmml" xref="S2.SS1.p2.4.m4.1.1.1.1.1.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.4.m4.1c">x(s_{t})</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.4.m4.1d">italic_x ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math> denotes the corresponding transformed text input to the policy, and <math alttext="a_{t}" class="ltx_Math" display="inline" id="S2.SS1.p2.5.m5.1"><semantics id="S2.SS1.p2.5.m5.1a"><msub id="S2.SS1.p2.5.m5.1.1" xref="S2.SS1.p2.5.m5.1.1.cmml"><mi id="S2.SS1.p2.5.m5.1.1.2" xref="S2.SS1.p2.5.m5.1.1.2.cmml">a</mi><mi id="S2.SS1.p2.5.m5.1.1.3" xref="S2.SS1.p2.5.m5.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.5.m5.1b"><apply id="S2.SS1.p2.5.m5.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.5.m5.1.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1">subscript</csymbol><ci id="S2.SS1.p2.5.m5.1.1.2.cmml" xref="S2.SS1.p2.5.m5.1.1.2">ğ‘</ci><ci id="S2.SS1.p2.5.m5.1.1.3.cmml" xref="S2.SS1.p2.5.m5.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.5.m5.1c">a_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.5.m5.1d">italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> denotes the corresponding action <math alttext="a_{t}" class="ltx_Math" display="inline" id="S2.SS1.p2.6.m6.1"><semantics id="S2.SS1.p2.6.m6.1a"><msub id="S2.SS1.p2.6.m6.1.1" xref="S2.SS1.p2.6.m6.1.1.cmml"><mi id="S2.SS1.p2.6.m6.1.1.2" xref="S2.SS1.p2.6.m6.1.1.2.cmml">a</mi><mi id="S2.SS1.p2.6.m6.1.1.3" xref="S2.SS1.p2.6.m6.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.6.m6.1b"><apply id="S2.SS1.p2.6.m6.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.6.m6.1.1.1.cmml" xref="S2.SS1.p2.6.m6.1.1">subscript</csymbol><ci id="S2.SS1.p2.6.m6.1.1.2.cmml" xref="S2.SS1.p2.6.m6.1.1.2">ğ‘</ci><ci id="S2.SS1.p2.6.m6.1.1.3.cmml" xref="S2.SS1.p2.6.m6.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.6.m6.1c">a_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.6.m6.1d">italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> taken by the agent. The action is then delivered to the environment
and environment accordingly transits to the next state <math alttext="s_{t+1}" class="ltx_Math" display="inline" id="S2.SS1.p2.7.m7.1"><semantics id="S2.SS1.p2.7.m7.1a"><msub id="S2.SS1.p2.7.m7.1.1" xref="S2.SS1.p2.7.m7.1.1.cmml"><mi id="S2.SS1.p2.7.m7.1.1.2" xref="S2.SS1.p2.7.m7.1.1.2.cmml">s</mi><mrow id="S2.SS1.p2.7.m7.1.1.3" xref="S2.SS1.p2.7.m7.1.1.3.cmml"><mi id="S2.SS1.p2.7.m7.1.1.3.2" xref="S2.SS1.p2.7.m7.1.1.3.2.cmml">t</mi><mo id="S2.SS1.p2.7.m7.1.1.3.1" xref="S2.SS1.p2.7.m7.1.1.3.1.cmml">+</mo><mn id="S2.SS1.p2.7.m7.1.1.3.3" xref="S2.SS1.p2.7.m7.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.7.m7.1b"><apply id="S2.SS1.p2.7.m7.1.1.cmml" xref="S2.SS1.p2.7.m7.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.7.m7.1.1.1.cmml" xref="S2.SS1.p2.7.m7.1.1">subscript</csymbol><ci id="S2.SS1.p2.7.m7.1.1.2.cmml" xref="S2.SS1.p2.7.m7.1.1.2">ğ‘ </ci><apply id="S2.SS1.p2.7.m7.1.1.3.cmml" xref="S2.SS1.p2.7.m7.1.1.3"><plus id="S2.SS1.p2.7.m7.1.1.3.1.cmml" xref="S2.SS1.p2.7.m7.1.1.3.1"></plus><ci id="S2.SS1.p2.7.m7.1.1.3.2.cmml" xref="S2.SS1.p2.7.m7.1.1.3.2">ğ‘¡</ci><cn id="S2.SS1.p2.7.m7.1.1.3.3.cmml" type="integer" xref="S2.SS1.p2.7.m7.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.7.m7.1c">s_{t+1}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.7.m7.1d">italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT</annotation></semantics></math> conditioned on the current state <math alttext="s_{t}" class="ltx_Math" display="inline" id="S2.SS1.p2.8.m8.1"><semantics id="S2.SS1.p2.8.m8.1a"><msub id="S2.SS1.p2.8.m8.1.1" xref="S2.SS1.p2.8.m8.1.1.cmml"><mi id="S2.SS1.p2.8.m8.1.1.2" xref="S2.SS1.p2.8.m8.1.1.2.cmml">s</mi><mi id="S2.SS1.p2.8.m8.1.1.3" xref="S2.SS1.p2.8.m8.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.8.m8.1b"><apply id="S2.SS1.p2.8.m8.1.1.cmml" xref="S2.SS1.p2.8.m8.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.8.m8.1.1.1.cmml" xref="S2.SS1.p2.8.m8.1.1">subscript</csymbol><ci id="S2.SS1.p2.8.m8.1.1.2.cmml" xref="S2.SS1.p2.8.m8.1.1.2">ğ‘ </ci><ci id="S2.SS1.p2.8.m8.1.1.3.cmml" xref="S2.SS1.p2.8.m8.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.8.m8.1c">s_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.8.m8.1d">italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and the action taken <math alttext="a_{t}" class="ltx_Math" display="inline" id="S2.SS1.p2.9.m9.1"><semantics id="S2.SS1.p2.9.m9.1a"><msub id="S2.SS1.p2.9.m9.1.1" xref="S2.SS1.p2.9.m9.1.1.cmml"><mi id="S2.SS1.p2.9.m9.1.1.2" xref="S2.SS1.p2.9.m9.1.1.2.cmml">a</mi><mi id="S2.SS1.p2.9.m9.1.1.3" xref="S2.SS1.p2.9.m9.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.9.m9.1b"><apply id="S2.SS1.p2.9.m9.1.1.cmml" xref="S2.SS1.p2.9.m9.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.9.m9.1.1.1.cmml" xref="S2.SS1.p2.9.m9.1.1">subscript</csymbol><ci id="S2.SS1.p2.9.m9.1.1.2.cmml" xref="S2.SS1.p2.9.m9.1.1.2">ğ‘</ci><ci id="S2.SS1.p2.9.m9.1.1.3.cmml" xref="S2.SS1.p2.9.m9.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.9.m9.1c">a_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.9.m9.1d">italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> based on its dynamics <math alttext="p(s_{t+1}|s_{t},a_{t})" class="ltx_Math" display="inline" id="S2.SS1.p2.10.m10.1"><semantics id="S2.SS1.p2.10.m10.1a"><mrow id="S2.SS1.p2.10.m10.1.1" xref="S2.SS1.p2.10.m10.1.1.cmml"><mi id="S2.SS1.p2.10.m10.1.1.3" xref="S2.SS1.p2.10.m10.1.1.3.cmml">p</mi><mo id="S2.SS1.p2.10.m10.1.1.2" xref="S2.SS1.p2.10.m10.1.1.2.cmml">â¢</mo><mrow id="S2.SS1.p2.10.m10.1.1.1.1" xref="S2.SS1.p2.10.m10.1.1.1.1.1.cmml"><mo id="S2.SS1.p2.10.m10.1.1.1.1.2" stretchy="false" xref="S2.SS1.p2.10.m10.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS1.p2.10.m10.1.1.1.1.1" xref="S2.SS1.p2.10.m10.1.1.1.1.1.cmml"><msub id="S2.SS1.p2.10.m10.1.1.1.1.1.4" xref="S2.SS1.p2.10.m10.1.1.1.1.1.4.cmml"><mi id="S2.SS1.p2.10.m10.1.1.1.1.1.4.2" xref="S2.SS1.p2.10.m10.1.1.1.1.1.4.2.cmml">s</mi><mrow id="S2.SS1.p2.10.m10.1.1.1.1.1.4.3" xref="S2.SS1.p2.10.m10.1.1.1.1.1.4.3.cmml"><mi id="S2.SS1.p2.10.m10.1.1.1.1.1.4.3.2" xref="S2.SS1.p2.10.m10.1.1.1.1.1.4.3.2.cmml">t</mi><mo id="S2.SS1.p2.10.m10.1.1.1.1.1.4.3.1" xref="S2.SS1.p2.10.m10.1.1.1.1.1.4.3.1.cmml">+</mo><mn id="S2.SS1.p2.10.m10.1.1.1.1.1.4.3.3" xref="S2.SS1.p2.10.m10.1.1.1.1.1.4.3.3.cmml">1</mn></mrow></msub><mo fence="false" id="S2.SS1.p2.10.m10.1.1.1.1.1.3" xref="S2.SS1.p2.10.m10.1.1.1.1.1.3.cmml">|</mo><mrow id="S2.SS1.p2.10.m10.1.1.1.1.1.2.2" xref="S2.SS1.p2.10.m10.1.1.1.1.1.2.3.cmml"><msub id="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.cmml"><mi id="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.2" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.2.cmml">s</mi><mi id="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.3" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.SS1.p2.10.m10.1.1.1.1.1.2.2.3" xref="S2.SS1.p2.10.m10.1.1.1.1.1.2.3.cmml">,</mo><msub id="S2.SS1.p2.10.m10.1.1.1.1.1.2.2.2" xref="S2.SS1.p2.10.m10.1.1.1.1.1.2.2.2.cmml"><mi id="S2.SS1.p2.10.m10.1.1.1.1.1.2.2.2.2" xref="S2.SS1.p2.10.m10.1.1.1.1.1.2.2.2.2.cmml">a</mi><mi id="S2.SS1.p2.10.m10.1.1.1.1.1.2.2.2.3" xref="S2.SS1.p2.10.m10.1.1.1.1.1.2.2.2.3.cmml">t</mi></msub></mrow></mrow><mo id="S2.SS1.p2.10.m10.1.1.1.1.3" stretchy="false" xref="S2.SS1.p2.10.m10.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.10.m10.1b"><apply id="S2.SS1.p2.10.m10.1.1.cmml" xref="S2.SS1.p2.10.m10.1.1"><times id="S2.SS1.p2.10.m10.1.1.2.cmml" xref="S2.SS1.p2.10.m10.1.1.2"></times><ci id="S2.SS1.p2.10.m10.1.1.3.cmml" xref="S2.SS1.p2.10.m10.1.1.3">ğ‘</ci><apply id="S2.SS1.p2.10.m10.1.1.1.1.1.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1"><csymbol cd="latexml" id="S2.SS1.p2.10.m10.1.1.1.1.1.3.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.3">conditional</csymbol><apply id="S2.SS1.p2.10.m10.1.1.1.1.1.4.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.4"><csymbol cd="ambiguous" id="S2.SS1.p2.10.m10.1.1.1.1.1.4.1.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.4">subscript</csymbol><ci id="S2.SS1.p2.10.m10.1.1.1.1.1.4.2.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.4.2">ğ‘ </ci><apply id="S2.SS1.p2.10.m10.1.1.1.1.1.4.3.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.4.3"><plus id="S2.SS1.p2.10.m10.1.1.1.1.1.4.3.1.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.4.3.1"></plus><ci id="S2.SS1.p2.10.m10.1.1.1.1.1.4.3.2.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.4.3.2">ğ‘¡</ci><cn id="S2.SS1.p2.10.m10.1.1.1.1.1.4.3.3.cmml" type="integer" xref="S2.SS1.p2.10.m10.1.1.1.1.1.4.3.3">1</cn></apply></apply><list id="S2.SS1.p2.10.m10.1.1.1.1.1.2.3.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.2.2"><apply id="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.2.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.2">ğ‘ </ci><ci id="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.3.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply><apply id="S2.SS1.p2.10.m10.1.1.1.1.1.2.2.2.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p2.10.m10.1.1.1.1.1.2.2.2.1.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S2.SS1.p2.10.m10.1.1.1.1.1.2.2.2.2.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.2.2.2.2">ğ‘</ci><ci id="S2.SS1.p2.10.m10.1.1.1.1.1.2.2.2.3.cmml" xref="S2.SS1.p2.10.m10.1.1.1.1.1.2.2.2.3">ğ‘¡</ci></apply></list></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.10.m10.1c">p(s_{t+1}|s_{t},a_{t})</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p2.10.m10.1d">italic_p ( italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT | italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.3">When the environment reaches a resulting information state <math alttext="s_{T}" class="ltx_Math" display="inline" id="S2.SS1.p3.1.m1.1"><semantics id="S2.SS1.p3.1.m1.1a"><msub id="S2.SS1.p3.1.m1.1.1" xref="S2.SS1.p3.1.m1.1.1.cmml"><mi id="S2.SS1.p3.1.m1.1.1.2" xref="S2.SS1.p3.1.m1.1.1.2.cmml">s</mi><mi id="S2.SS1.p3.1.m1.1.1.3" xref="S2.SS1.p3.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.1b"><apply id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.1.m1.1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.p3.1.m1.1.1.2.cmml" xref="S2.SS1.p3.1.m1.1.1.2">ğ‘ </ci><ci id="S2.SS1.p3.1.m1.1.1.3.cmml" xref="S2.SS1.p3.1.m1.1.1.3">ğ‘‡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.1c">s_{T}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.1.m1.1d">italic_s start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT</annotation></semantics></math> at a certain step <math alttext="T" class="ltx_Math" display="inline" id="S2.SS1.p3.2.m2.1"><semantics id="S2.SS1.p3.2.m2.1a"><mi id="S2.SS1.p3.2.m2.1.1" xref="S2.SS1.p3.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.2.m2.1b"><ci id="S2.SS1.p3.2.m2.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1">ğ‘‡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.2.m2.1c">T</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.2.m2.1d">italic_T</annotation></semantics></math>, the agentic IR process terminates. Then, the corresponding success or failure result can be calculated by a predefined rule (or verifier) <math alttext="r(s_{*},s_{T})" class="ltx_Math" display="inline" id="S2.SS1.p3.3.m3.2"><semantics id="S2.SS1.p3.3.m3.2a"><mrow id="S2.SS1.p3.3.m3.2.2" xref="S2.SS1.p3.3.m3.2.2.cmml"><mi id="S2.SS1.p3.3.m3.2.2.4" xref="S2.SS1.p3.3.m3.2.2.4.cmml">r</mi><mo id="S2.SS1.p3.3.m3.2.2.3" xref="S2.SS1.p3.3.m3.2.2.3.cmml">â¢</mo><mrow id="S2.SS1.p3.3.m3.2.2.2.2" xref="S2.SS1.p3.3.m3.2.2.2.3.cmml"><mo id="S2.SS1.p3.3.m3.2.2.2.2.3" stretchy="false" xref="S2.SS1.p3.3.m3.2.2.2.3.cmml">(</mo><msub id="S2.SS1.p3.3.m3.1.1.1.1.1" xref="S2.SS1.p3.3.m3.1.1.1.1.1.cmml"><mi id="S2.SS1.p3.3.m3.1.1.1.1.1.2" xref="S2.SS1.p3.3.m3.1.1.1.1.1.2.cmml">s</mi><mo id="S2.SS1.p3.3.m3.1.1.1.1.1.3" xref="S2.SS1.p3.3.m3.1.1.1.1.1.3.cmml">âˆ—</mo></msub><mo id="S2.SS1.p3.3.m3.2.2.2.2.4" xref="S2.SS1.p3.3.m3.2.2.2.3.cmml">,</mo><msub id="S2.SS1.p3.3.m3.2.2.2.2.2" xref="S2.SS1.p3.3.m3.2.2.2.2.2.cmml"><mi id="S2.SS1.p3.3.m3.2.2.2.2.2.2" xref="S2.SS1.p3.3.m3.2.2.2.2.2.2.cmml">s</mi><mi id="S2.SS1.p3.3.m3.2.2.2.2.2.3" xref="S2.SS1.p3.3.m3.2.2.2.2.2.3.cmml">T</mi></msub><mo id="S2.SS1.p3.3.m3.2.2.2.2.5" stretchy="false" xref="S2.SS1.p3.3.m3.2.2.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.3.m3.2b"><apply id="S2.SS1.p3.3.m3.2.2.cmml" xref="S2.SS1.p3.3.m3.2.2"><times id="S2.SS1.p3.3.m3.2.2.3.cmml" xref="S2.SS1.p3.3.m3.2.2.3"></times><ci id="S2.SS1.p3.3.m3.2.2.4.cmml" xref="S2.SS1.p3.3.m3.2.2.4">ğ‘Ÿ</ci><interval closure="open" id="S2.SS1.p3.3.m3.2.2.2.3.cmml" xref="S2.SS1.p3.3.m3.2.2.2.2"><apply id="S2.SS1.p3.3.m3.1.1.1.1.1.cmml" xref="S2.SS1.p3.3.m3.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.3.m3.1.1.1.1.1.1.cmml" xref="S2.SS1.p3.3.m3.1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p3.3.m3.1.1.1.1.1.2.cmml" xref="S2.SS1.p3.3.m3.1.1.1.1.1.2">ğ‘ </ci><times id="S2.SS1.p3.3.m3.1.1.1.1.1.3.cmml" xref="S2.SS1.p3.3.m3.1.1.1.1.1.3"></times></apply><apply id="S2.SS1.p3.3.m3.2.2.2.2.2.cmml" xref="S2.SS1.p3.3.m3.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p3.3.m3.2.2.2.2.2.1.cmml" xref="S2.SS1.p3.3.m3.2.2.2.2.2">subscript</csymbol><ci id="S2.SS1.p3.3.m3.2.2.2.2.2.2.cmml" xref="S2.SS1.p3.3.m3.2.2.2.2.2.2">ğ‘ </ci><ci id="S2.SS1.p3.3.m3.2.2.2.2.2.3.cmml" xref="S2.SS1.p3.3.m3.2.2.2.2.2.3">ğ‘‡</ci></apply></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.3.m3.2c">r(s_{*},s_{T})</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p3.3.m3.2d">italic_r ( italic_s start_POSTSUBSCRIPT âˆ— end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT )</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S2.SS1.p4">
<p class="ltx_p" id="S2.SS1.p4.1">In such a framework, the target of an agentic IR algorithm is to acquire an optimal agent policy that maximizes the expectation of success as</p>
<table class="ltx_equationgroup ltx_eqn_table" id="S2.E1">
<tbody>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S2.E1X">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle\max_{\pi}{}" class="ltx_Math" display="inline" id="S2.E1X.2.1.1.m1.1"><semantics id="S2.E1X.2.1.1.m1.1a"><munder id="S2.E1X.2.1.1.m1.1.1" xref="S2.E1X.2.1.1.m1.1.1.cmml"><mi id="S2.E1X.2.1.1.m1.1.1.2" xref="S2.E1X.2.1.1.m1.1.1.2.cmml">max</mi><mi id="S2.E1X.2.1.1.m1.1.1.3" xref="S2.E1X.2.1.1.m1.1.1.3.cmml">Ï€</mi></munder><annotation-xml encoding="MathML-Content" id="S2.E1X.2.1.1.m1.1b"><apply id="S2.E1X.2.1.1.m1.1.1.cmml" xref="S2.E1X.2.1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.E1X.2.1.1.m1.1.1.1.cmml" xref="S2.E1X.2.1.1.m1.1.1">subscript</csymbol><max id="S2.E1X.2.1.1.m1.1.1.2.cmml" xref="S2.E1X.2.1.1.m1.1.1.2"></max><ci id="S2.E1X.2.1.1.m1.1.1.3.cmml" xref="S2.E1X.2.1.1.m1.1.1.3">ğœ‹</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1X.2.1.1.m1.1c">\displaystyle\max_{\pi}{}</annotation><annotation encoding="application/x-llamapun" id="S2.E1X.2.1.1.m1.1d">roman_max start_POSTSUBSCRIPT italic_Ï€ end_POSTSUBSCRIPT</annotation></semantics></math></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle\mathbb{E}_{s_{*}}[r(s_{*},s_{T})]" class="ltx_Math" display="inline" id="S2.E1X.3.2.2.m1.1"><semantics id="S2.E1X.3.2.2.m1.1a"><mrow id="S2.E1X.3.2.2.m1.1.1" xref="S2.E1X.3.2.2.m1.1.1.cmml"><msub id="S2.E1X.3.2.2.m1.1.1.3" xref="S2.E1X.3.2.2.m1.1.1.3.cmml"><mi id="S2.E1X.3.2.2.m1.1.1.3.2" xref="S2.E1X.3.2.2.m1.1.1.3.2.cmml">ğ”¼</mi><msub id="S2.E1X.3.2.2.m1.1.1.3.3" xref="S2.E1X.3.2.2.m1.1.1.3.3.cmml"><mi id="S2.E1X.3.2.2.m1.1.1.3.3.2" xref="S2.E1X.3.2.2.m1.1.1.3.3.2.cmml">s</mi><mo id="S2.E1X.3.2.2.m1.1.1.3.3.3" xref="S2.E1X.3.2.2.m1.1.1.3.3.3.cmml">âˆ—</mo></msub></msub><mo id="S2.E1X.3.2.2.m1.1.1.2" xref="S2.E1X.3.2.2.m1.1.1.2.cmml">â¢</mo><mrow id="S2.E1X.3.2.2.m1.1.1.1.1" xref="S2.E1X.3.2.2.m1.1.1.1.2.cmml"><mo id="S2.E1X.3.2.2.m1.1.1.1.1.2" stretchy="false" xref="S2.E1X.3.2.2.m1.1.1.1.2.1.cmml">[</mo><mrow id="S2.E1X.3.2.2.m1.1.1.1.1.1" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.cmml"><mi id="S2.E1X.3.2.2.m1.1.1.1.1.1.4" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.4.cmml">r</mi><mo id="S2.E1X.3.2.2.m1.1.1.1.1.1.3" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.3.cmml">â¢</mo><mrow id="S2.E1X.3.2.2.m1.1.1.1.1.1.2.2" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.2.3.cmml"><mo id="S2.E1X.3.2.2.m1.1.1.1.1.1.2.2.3" stretchy="false" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.2.3.cmml">(</mo><msub id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.1.1" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.1.1.2" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.1.1.2.cmml">s</mi><mo id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.1.1.3" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.1.1.3.cmml">âˆ—</mo></msub><mo id="S2.E1X.3.2.2.m1.1.1.1.1.1.2.2.4" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.2.3.cmml">,</mo><msub id="S2.E1X.3.2.2.m1.1.1.1.1.1.2.2.2" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.2.2.2.cmml"><mi id="S2.E1X.3.2.2.m1.1.1.1.1.1.2.2.2.2" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.2.2.2.2.cmml">s</mi><mi id="S2.E1X.3.2.2.m1.1.1.1.1.1.2.2.2.3" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.2.2.2.3.cmml">T</mi></msub><mo id="S2.E1X.3.2.2.m1.1.1.1.1.1.2.2.5" stretchy="false" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.2.3.cmml">)</mo></mrow></mrow><mo id="S2.E1X.3.2.2.m1.1.1.1.1.3" stretchy="false" xref="S2.E1X.3.2.2.m1.1.1.1.2.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1X.3.2.2.m1.1b"><apply id="S2.E1X.3.2.2.m1.1.1.cmml" xref="S2.E1X.3.2.2.m1.1.1"><times id="S2.E1X.3.2.2.m1.1.1.2.cmml" xref="S2.E1X.3.2.2.m1.1.1.2"></times><apply id="S2.E1X.3.2.2.m1.1.1.3.cmml" xref="S2.E1X.3.2.2.m1.1.1.3"><csymbol cd="ambiguous" id="S2.E1X.3.2.2.m1.1.1.3.1.cmml" xref="S2.E1X.3.2.2.m1.1.1.3">subscript</csymbol><ci id="S2.E1X.3.2.2.m1.1.1.3.2.cmml" xref="S2.E1X.3.2.2.m1.1.1.3.2">ğ”¼</ci><apply id="S2.E1X.3.2.2.m1.1.1.3.3.cmml" xref="S2.E1X.3.2.2.m1.1.1.3.3"><csymbol cd="ambiguous" id="S2.E1X.3.2.2.m1.1.1.3.3.1.cmml" xref="S2.E1X.3.2.2.m1.1.1.3.3">subscript</csymbol><ci id="S2.E1X.3.2.2.m1.1.1.3.3.2.cmml" xref="S2.E1X.3.2.2.m1.1.1.3.3.2">ğ‘ </ci><times id="S2.E1X.3.2.2.m1.1.1.3.3.3.cmml" xref="S2.E1X.3.2.2.m1.1.1.3.3.3"></times></apply></apply><apply id="S2.E1X.3.2.2.m1.1.1.1.2.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1"><csymbol cd="latexml" id="S2.E1X.3.2.2.m1.1.1.1.2.1.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.2">delimited-[]</csymbol><apply id="S2.E1X.3.2.2.m1.1.1.1.1.1.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1"><times id="S2.E1X.3.2.2.m1.1.1.1.1.1.3.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.3"></times><ci id="S2.E1X.3.2.2.m1.1.1.1.1.1.4.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.4">ğ‘Ÿ</ci><interval closure="open" id="S2.E1X.3.2.2.m1.1.1.1.1.1.2.3.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.2.2"><apply id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.1.1.2">ğ‘ </ci><times id="S2.E1X.3.2.2.m1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.1.1.1.3"></times></apply><apply id="S2.E1X.3.2.2.m1.1.1.1.1.1.2.2.2.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.2.2.2"><csymbol cd="ambiguous" id="S2.E1X.3.2.2.m1.1.1.1.1.1.2.2.2.1.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.2.2.2">subscript</csymbol><ci id="S2.E1X.3.2.2.m1.1.1.1.1.1.2.2.2.2.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.2.2.2.2">ğ‘ </ci><ci id="S2.E1X.3.2.2.m1.1.1.1.1.1.2.2.2.3.cmml" xref="S2.E1X.3.2.2.m1.1.1.1.1.1.2.2.2.3">ğ‘‡</ci></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1X.3.2.2.m1.1c">\displaystyle\mathbb{E}_{s_{*}}[r(s_{*},s_{T})]</annotation><annotation encoding="application/x-llamapun" id="S2.E1X.3.2.2.m1.1d">blackboard_E start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT âˆ— end_POSTSUBSCRIPT end_POSTSUBSCRIPT [ italic_r ( italic_s start_POSTSUBSCRIPT âˆ— end_POSTSUBSCRIPT , italic_s start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT ) ]</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="2"><span class="ltx_tag ltx_tag_equationgroup ltx_align_right">(1)</span></td>
</tr>
<tr class="ltx_equation ltx_eqn_row ltx_align_baseline" id="S2.E1Xa">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><span class="ltx_text ltx_markedasmath ltx_font_italic" id="S2.E1Xa.2.1.1.1">such that</span></td>
<td class="ltx_td ltx_align_left ltx_eqn_cell"><math alttext="\displaystyle s_{t+1}\sim p(\cdot|s_{t},a_{t}),a_{t}\sim\pi(\cdot|x(s_{t})),%
\text{~{}for~{}}t=1\ldots T-1." class="ltx_math_unparsed" display="inline" id="S2.E1Xa.3.2.2.m1.1"><semantics id="S2.E1Xa.3.2.2.m1.1a"><mrow id="S2.E1Xa.3.2.2.m1.1b"><msub id="S2.E1Xa.3.2.2.m1.1.1"><mi id="S2.E1Xa.3.2.2.m1.1.1.2">s</mi><mrow id="S2.E1Xa.3.2.2.m1.1.1.3"><mi id="S2.E1Xa.3.2.2.m1.1.1.3.2">t</mi><mo id="S2.E1Xa.3.2.2.m1.1.1.3.1">+</mo><mn id="S2.E1Xa.3.2.2.m1.1.1.3.3">1</mn></mrow></msub><mo id="S2.E1Xa.3.2.2.m1.1.2">âˆ¼</mo><mi id="S2.E1Xa.3.2.2.m1.1.3">p</mi><mrow id="S2.E1Xa.3.2.2.m1.1.4"><mo id="S2.E1Xa.3.2.2.m1.1.4.1" stretchy="false">(</mo><mo id="S2.E1Xa.3.2.2.m1.1.4.2" lspace="0em" rspace="0em">â‹…</mo><mo fence="false" id="S2.E1Xa.3.2.2.m1.1.4.3" rspace="0.167em" stretchy="false">|</mo><msub id="S2.E1Xa.3.2.2.m1.1.4.4"><mi id="S2.E1Xa.3.2.2.m1.1.4.4.2">s</mi><mi id="S2.E1Xa.3.2.2.m1.1.4.4.3">t</mi></msub><mo id="S2.E1Xa.3.2.2.m1.1.4.5">,</mo><msub id="S2.E1Xa.3.2.2.m1.1.4.6"><mi id="S2.E1Xa.3.2.2.m1.1.4.6.2">a</mi><mi id="S2.E1Xa.3.2.2.m1.1.4.6.3">t</mi></msub><mo id="S2.E1Xa.3.2.2.m1.1.4.7" stretchy="false">)</mo></mrow><mo id="S2.E1Xa.3.2.2.m1.1.5">,</mo><msub id="S2.E1Xa.3.2.2.m1.1.6"><mi id="S2.E1Xa.3.2.2.m1.1.6.2">a</mi><mi id="S2.E1Xa.3.2.2.m1.1.6.3">t</mi></msub><mo id="S2.E1Xa.3.2.2.m1.1.7">âˆ¼</mo><mi id="S2.E1Xa.3.2.2.m1.1.8">Ï€</mi><mrow id="S2.E1Xa.3.2.2.m1.1.9"><mo id="S2.E1Xa.3.2.2.m1.1.9.1" stretchy="false">(</mo><mo id="S2.E1Xa.3.2.2.m1.1.9.2" lspace="0em" rspace="0em">â‹…</mo><mo fence="false" id="S2.E1Xa.3.2.2.m1.1.9.3" rspace="0.167em" stretchy="false">|</mo><mi id="S2.E1Xa.3.2.2.m1.1.9.4">x</mi><mrow id="S2.E1Xa.3.2.2.m1.1.9.5"><mo id="S2.E1Xa.3.2.2.m1.1.9.5.1" stretchy="false">(</mo><msub id="S2.E1Xa.3.2.2.m1.1.9.5.2"><mi id="S2.E1Xa.3.2.2.m1.1.9.5.2.2">s</mi><mi id="S2.E1Xa.3.2.2.m1.1.9.5.2.3">t</mi></msub><mo id="S2.E1Xa.3.2.2.m1.1.9.5.3" stretchy="false">)</mo></mrow><mo id="S2.E1Xa.3.2.2.m1.1.9.6" stretchy="false">)</mo></mrow><mo id="S2.E1Xa.3.2.2.m1.1.10">,</mo><mtext id="S2.E1Xa.3.2.2.m1.1.11">Â forÂ </mtext><mi id="S2.E1Xa.3.2.2.m1.1.12">t</mi><mo id="S2.E1Xa.3.2.2.m1.1.13">=</mo><mn id="S2.E1Xa.3.2.2.m1.1.14">1</mn><mi id="S2.E1Xa.3.2.2.m1.1.15" mathvariant="normal">â€¦</mi><mi id="S2.E1Xa.3.2.2.m1.1.16">T</mi><mo id="S2.E1Xa.3.2.2.m1.1.17">âˆ’</mo><mn id="S2.E1Xa.3.2.2.m1.1.18">1</mn><mo id="S2.E1Xa.3.2.2.m1.1.19" lspace="0em">.</mo></mrow><annotation encoding="application/x-tex" id="S2.E1Xa.3.2.2.m1.1c">\displaystyle s_{t+1}\sim p(\cdot|s_{t},a_{t}),a_{t}\sim\pi(\cdot|x(s_{t})),%
\text{~{}for~{}}t=1\ldots T-1.</annotation><annotation encoding="application/x-llamapun" id="S2.E1Xa.3.2.2.m1.1d">italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT âˆ¼ italic_p ( â‹… | italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) , italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT âˆ¼ italic_Ï€ ( â‹… | italic_x ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) ) , for italic_t = 1 â€¦ italic_T - 1 .</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr>
</tbody>
</table>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Architecture</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">The agent policy <math alttext="\pi(a_{t}|x(s_{t}))" class="ltx_Math" display="inline" id="S2.SS2.p1.1.m1.1"><semantics id="S2.SS2.p1.1.m1.1a"><mrow id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml"><mi id="S2.SS2.p1.1.m1.1.1.3" xref="S2.SS2.p1.1.m1.1.1.3.cmml">Ï€</mi><mo id="S2.SS2.p1.1.m1.1.1.2" xref="S2.SS2.p1.1.m1.1.1.2.cmml">â¢</mo><mrow id="S2.SS2.p1.1.m1.1.1.1.1" xref="S2.SS2.p1.1.m1.1.1.1.1.1.cmml"><mo id="S2.SS2.p1.1.m1.1.1.1.1.2" stretchy="false" xref="S2.SS2.p1.1.m1.1.1.1.1.1.cmml">(</mo><mrow id="S2.SS2.p1.1.m1.1.1.1.1.1" xref="S2.SS2.p1.1.m1.1.1.1.1.1.cmml"><msub id="S2.SS2.p1.1.m1.1.1.1.1.1.3" xref="S2.SS2.p1.1.m1.1.1.1.1.1.3.cmml"><mi id="S2.SS2.p1.1.m1.1.1.1.1.1.3.2" xref="S2.SS2.p1.1.m1.1.1.1.1.1.3.2.cmml">a</mi><mi id="S2.SS2.p1.1.m1.1.1.1.1.1.3.3" xref="S2.SS2.p1.1.m1.1.1.1.1.1.3.3.cmml">t</mi></msub><mo fence="false" id="S2.SS2.p1.1.m1.1.1.1.1.1.2" xref="S2.SS2.p1.1.m1.1.1.1.1.1.2.cmml">|</mo><mrow id="S2.SS2.p1.1.m1.1.1.1.1.1.1" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.cmml"><mi id="S2.SS2.p1.1.m1.1.1.1.1.1.1.3" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.3.cmml">x</mi><mo id="S2.SS2.p1.1.m1.1.1.1.1.1.1.2" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.2.cmml">â¢</mo><mrow id="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.1" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.cmml"><mo id="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.2" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml">s</mi><mi id="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.3" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo id="S2.SS2.p1.1.m1.1.1.1.1.3" stretchy="false" xref="S2.SS2.p1.1.m1.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><apply id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1"><times id="S2.SS2.p1.1.m1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.1.2"></times><ci id="S2.SS2.p1.1.m1.1.1.3.cmml" xref="S2.SS2.p1.1.m1.1.1.3">ğœ‹</ci><apply id="S2.SS2.p1.1.m1.1.1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1"><csymbol cd="latexml" id="S2.SS2.p1.1.m1.1.1.1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1.2">conditional</csymbol><apply id="S2.SS2.p1.1.m1.1.1.1.1.1.3.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.1.1.1.1.1.3.1.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.SS2.p1.1.m1.1.1.1.1.1.3.2.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1.3.2">ğ‘</ci><ci id="S2.SS2.p1.1.m1.1.1.1.1.1.3.3.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1.3.3">ğ‘¡</ci></apply><apply id="S2.SS2.p1.1.m1.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1"><times id="S2.SS2.p1.1.m1.1.1.1.1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.2"></times><ci id="S2.SS2.p1.1.m1.1.1.1.1.1.1.3.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.3">ğ‘¥</ci><apply id="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.2">ğ‘ </ci><ci id="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.SS2.p1.1.m1.1.1.1.1.1.1.1.1.1.3">ğ‘¡</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">\pi(a_{t}|x(s_{t}))</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p1.1.m1.1d">italic_Ï€ ( italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_x ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) )</annotation></semantics></math>, as shown in the central module of the agentic IR subplot in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S1.F1" title="Figure 1 â€£ 1 The Trends of IR â€£ Agentic Information Retrieval"><span class="ltx_text ltx_ref_tag">1</span></a>, takes the userâ€™s language instruction as input, then interacts with the environment with single or multiple turns, and finally reaches the resulting information state.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">The inner-architecture modules of the agent generally include memory and thought. Generally, the memory means the the log history, experience that can be stored in the disk, while the thought is the information stored in the context window of the LLM.
Additionally, there is a pool of external tools for the agent to call <cite class="ltx_cite ltx_citemacro_citep">(Patil etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib5" title="">2023</a>; Lin etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib6" title="">2024</a>)</cite>. A tool can be regarded as a function (with input arguments) that cannot be replaced by a neural net model, such as web search engine, relational DB, real-time weather app, calculator, etc.</p>
</div>
<div class="ltx_para" id="S2.SS2.p3">
<p class="ltx_p" id="S2.SS2.p3.1">As such, the textual description of the information state of the agent at step <math alttext="t" class="ltx_Math" display="inline" id="S2.SS2.p3.1.m1.1"><semantics id="S2.SS2.p3.1.m1.1a"><mi id="S2.SS2.p3.1.m1.1.1" xref="S2.SS2.p3.1.m1.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.1.m1.1b"><ci id="S2.SS2.p3.1.m1.1.1.cmml" xref="S2.SS2.p3.1.m1.1.1">ğ‘¡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.1.m1.1c">t</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.1.m1.1d">italic_t</annotation></semantics></math> can be written as</p>
<table class="ltx_equationgroup ltx_eqn_align ltx_eqn_table" id="Sx1.EGx1">
<tbody id="S2.E2"><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_td ltx_align_right ltx_eqn_cell"><math alttext="\displaystyle x(s_{t})=g(s_{t},h_{t},\textsc{Mem},\textsc{Tht},\textsc{Tool})," class="ltx_Math" display="inline" id="S2.E2.m1.4"><semantics id="S2.E2.m1.4a"><mrow id="S2.E2.m1.4.4.1" xref="S2.E2.m1.4.4.1.1.cmml"><mrow id="S2.E2.m1.4.4.1.1" xref="S2.E2.m1.4.4.1.1.cmml"><mrow id="S2.E2.m1.4.4.1.1.1" xref="S2.E2.m1.4.4.1.1.1.cmml"><mi id="S2.E2.m1.4.4.1.1.1.3" xref="S2.E2.m1.4.4.1.1.1.3.cmml">x</mi><mo id="S2.E2.m1.4.4.1.1.1.2" xref="S2.E2.m1.4.4.1.1.1.2.cmml">â¢</mo><mrow id="S2.E2.m1.4.4.1.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.cmml"><mo id="S2.E2.m1.4.4.1.1.1.1.1.2" stretchy="false" xref="S2.E2.m1.4.4.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E2.m1.4.4.1.1.1.1.1.1" xref="S2.E2.m1.4.4.1.1.1.1.1.1.cmml"><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.2" xref="S2.E2.m1.4.4.1.1.1.1.1.1.2.cmml">s</mi><mi id="S2.E2.m1.4.4.1.1.1.1.1.1.3" xref="S2.E2.m1.4.4.1.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.E2.m1.4.4.1.1.1.1.1.3" stretchy="false" xref="S2.E2.m1.4.4.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E2.m1.4.4.1.1.4" xref="S2.E2.m1.4.4.1.1.4.cmml">=</mo><mrow id="S2.E2.m1.4.4.1.1.3" xref="S2.E2.m1.4.4.1.1.3.cmml"><mi id="S2.E2.m1.4.4.1.1.3.4" xref="S2.E2.m1.4.4.1.1.3.4.cmml">g</mi><mo id="S2.E2.m1.4.4.1.1.3.3" xref="S2.E2.m1.4.4.1.1.3.3.cmml">â¢</mo><mrow id="S2.E2.m1.4.4.1.1.3.2.2" xref="S2.E2.m1.4.4.1.1.3.2.3.cmml"><mo id="S2.E2.m1.4.4.1.1.3.2.2.3" stretchy="false" xref="S2.E2.m1.4.4.1.1.3.2.3.cmml">(</mo><msub id="S2.E2.m1.4.4.1.1.2.1.1.1" xref="S2.E2.m1.4.4.1.1.2.1.1.1.cmml"><mi id="S2.E2.m1.4.4.1.1.2.1.1.1.2" xref="S2.E2.m1.4.4.1.1.2.1.1.1.2.cmml">s</mi><mi id="S2.E2.m1.4.4.1.1.2.1.1.1.3" xref="S2.E2.m1.4.4.1.1.2.1.1.1.3.cmml">t</mi></msub><mo id="S2.E2.m1.4.4.1.1.3.2.2.4" xref="S2.E2.m1.4.4.1.1.3.2.3.cmml">,</mo><msub id="S2.E2.m1.4.4.1.1.3.2.2.2" xref="S2.E2.m1.4.4.1.1.3.2.2.2.cmml"><mi id="S2.E2.m1.4.4.1.1.3.2.2.2.2" xref="S2.E2.m1.4.4.1.1.3.2.2.2.2.cmml">h</mi><mi id="S2.E2.m1.4.4.1.1.3.2.2.2.3" xref="S2.E2.m1.4.4.1.1.3.2.2.2.3.cmml">t</mi></msub><mo id="S2.E2.m1.4.4.1.1.3.2.2.5" xref="S2.E2.m1.4.4.1.1.3.2.3.cmml">,</mo><mtext class="ltx_font_smallcaps" id="S2.E2.m1.1.1" xref="S2.E2.m1.1.1a.cmml">Mem</mtext><mo id="S2.E2.m1.4.4.1.1.3.2.2.6" xref="S2.E2.m1.4.4.1.1.3.2.3.cmml">,</mo><mtext class="ltx_font_smallcaps" id="S2.E2.m1.2.2" xref="S2.E2.m1.2.2a.cmml">Tht</mtext><mo id="S2.E2.m1.4.4.1.1.3.2.2.7" xref="S2.E2.m1.4.4.1.1.3.2.3.cmml">,</mo><mtext class="ltx_font_smallcaps" id="S2.E2.m1.3.3" xref="S2.E2.m1.3.3a.cmml">Tool</mtext><mo id="S2.E2.m1.4.4.1.1.3.2.2.8" stretchy="false" xref="S2.E2.m1.4.4.1.1.3.2.3.cmml">)</mo></mrow></mrow></mrow><mo id="S2.E2.m1.4.4.1.2" xref="S2.E2.m1.4.4.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E2.m1.4b"><apply id="S2.E2.m1.4.4.1.1.cmml" xref="S2.E2.m1.4.4.1"><eq id="S2.E2.m1.4.4.1.1.4.cmml" xref="S2.E2.m1.4.4.1.1.4"></eq><apply id="S2.E2.m1.4.4.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1"><times id="S2.E2.m1.4.4.1.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1.2"></times><ci id="S2.E2.m1.4.4.1.1.1.3.cmml" xref="S2.E2.m1.4.4.1.1.1.3">ğ‘¥</ci><apply id="S2.E2.m1.4.4.1.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.1.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1">subscript</csymbol><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.2">ğ‘ </ci><ci id="S2.E2.m1.4.4.1.1.1.1.1.1.3.cmml" xref="S2.E2.m1.4.4.1.1.1.1.1.1.3">ğ‘¡</ci></apply></apply><apply id="S2.E2.m1.4.4.1.1.3.cmml" xref="S2.E2.m1.4.4.1.1.3"><times id="S2.E2.m1.4.4.1.1.3.3.cmml" xref="S2.E2.m1.4.4.1.1.3.3"></times><ci id="S2.E2.m1.4.4.1.1.3.4.cmml" xref="S2.E2.m1.4.4.1.1.3.4">ğ‘”</ci><vector id="S2.E2.m1.4.4.1.1.3.2.3.cmml" xref="S2.E2.m1.4.4.1.1.3.2.2"><apply id="S2.E2.m1.4.4.1.1.2.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.2.1.1.1"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.2.1.1.1.1.cmml" xref="S2.E2.m1.4.4.1.1.2.1.1.1">subscript</csymbol><ci id="S2.E2.m1.4.4.1.1.2.1.1.1.2.cmml" xref="S2.E2.m1.4.4.1.1.2.1.1.1.2">ğ‘ </ci><ci id="S2.E2.m1.4.4.1.1.2.1.1.1.3.cmml" xref="S2.E2.m1.4.4.1.1.2.1.1.1.3">ğ‘¡</ci></apply><apply id="S2.E2.m1.4.4.1.1.3.2.2.2.cmml" xref="S2.E2.m1.4.4.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S2.E2.m1.4.4.1.1.3.2.2.2.1.cmml" xref="S2.E2.m1.4.4.1.1.3.2.2.2">subscript</csymbol><ci id="S2.E2.m1.4.4.1.1.3.2.2.2.2.cmml" xref="S2.E2.m1.4.4.1.1.3.2.2.2.2">â„</ci><ci id="S2.E2.m1.4.4.1.1.3.2.2.2.3.cmml" xref="S2.E2.m1.4.4.1.1.3.2.2.2.3">ğ‘¡</ci></apply><ci id="S2.E2.m1.1.1a.cmml" xref="S2.E2.m1.1.1"><mtext class="ltx_font_smallcaps" id="S2.E2.m1.1.1.cmml" xref="S2.E2.m1.1.1">Mem</mtext></ci><ci id="S2.E2.m1.2.2a.cmml" xref="S2.E2.m1.2.2"><mtext class="ltx_font_smallcaps" id="S2.E2.m1.2.2.cmml" xref="S2.E2.m1.2.2">Tht</mtext></ci><ci id="S2.E2.m1.3.3a.cmml" xref="S2.E2.m1.3.3"><mtext class="ltx_font_smallcaps" id="S2.E2.m1.3.3.cmml" xref="S2.E2.m1.3.3">Tool</mtext></ci></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E2.m1.4c">\displaystyle x(s_{t})=g(s_{t},h_{t},\textsc{Mem},\textsc{Tht},\textsc{Tool}),</annotation><annotation encoding="application/x-llamapun" id="S2.E2.m1.4d">italic_x ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ) = italic_g ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , italic_h start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT , Mem , Tht , Tool ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS2.p3.7">where <span class="ltx_text ltx_font_smallcaps" id="S2.SS2.p3.7.1">Mem</span>, <span class="ltx_text ltx_font_smallcaps" id="S2.SS2.p3.7.2">Tht</span>, and <span class="ltx_text ltx_font_smallcaps" id="S2.SS2.p3.7.3">Tool</span> denote three functions that update memory, manipulate thoughts, and call tools, respectively. <math alttext="g" class="ltx_Math" display="inline" id="S2.SS2.p3.2.m1.1"><semantics id="S2.SS2.p3.2.m1.1a"><mi id="S2.SS2.p3.2.m1.1.1" xref="S2.SS2.p3.2.m1.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.2.m1.1b"><ci id="S2.SS2.p3.2.m1.1.1.cmml" xref="S2.SS2.p3.2.m1.1.1">ğ‘”</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.2.m1.1c">g</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.2.m1.1d">italic_g</annotation></semantics></math> denotes a composite function based on the above three functions, takes the current state <math alttext="s_{t}" class="ltx_Math" display="inline" id="S2.SS2.p3.3.m2.1"><semantics id="S2.SS2.p3.3.m2.1a"><msub id="S2.SS2.p3.3.m2.1.1" xref="S2.SS2.p3.3.m2.1.1.cmml"><mi id="S2.SS2.p3.3.m2.1.1.2" xref="S2.SS2.p3.3.m2.1.1.2.cmml">s</mi><mi id="S2.SS2.p3.3.m2.1.1.3" xref="S2.SS2.p3.3.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.3.m2.1b"><apply id="S2.SS2.p3.3.m2.1.1.cmml" xref="S2.SS2.p3.3.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.3.m2.1.1.1.cmml" xref="S2.SS2.p3.3.m2.1.1">subscript</csymbol><ci id="S2.SS2.p3.3.m2.1.1.2.cmml" xref="S2.SS2.p3.3.m2.1.1.2">ğ‘ </ci><ci id="S2.SS2.p3.3.m2.1.1.3.cmml" xref="S2.SS2.p3.3.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.3.m2.1c">s_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.3.m2.1d">italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> and the memory <math alttext="h_{t}" class="ltx_Math" display="inline" id="S2.SS2.p3.4.m3.1"><semantics id="S2.SS2.p3.4.m3.1a"><msub id="S2.SS2.p3.4.m3.1.1" xref="S2.SS2.p3.4.m3.1.1.cmml"><mi id="S2.SS2.p3.4.m3.1.1.2" xref="S2.SS2.p3.4.m3.1.1.2.cmml">h</mi><mi id="S2.SS2.p3.4.m3.1.1.3" xref="S2.SS2.p3.4.m3.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.4.m3.1b"><apply id="S2.SS2.p3.4.m3.1.1.cmml" xref="S2.SS2.p3.4.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.4.m3.1.1.1.cmml" xref="S2.SS2.p3.4.m3.1.1">subscript</csymbol><ci id="S2.SS2.p3.4.m3.1.1.2.cmml" xref="S2.SS2.p3.4.m3.1.1.2">â„</ci><ci id="S2.SS2.p3.4.m3.1.1.3.cmml" xref="S2.SS2.p3.4.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.4.m3.1c">h_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.4.m3.1d">italic_h start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> as the raw input, and outputs the intermediate representation of the state <math alttext="s_{t}" class="ltx_Math" display="inline" id="S2.SS2.p3.5.m4.1"><semantics id="S2.SS2.p3.5.m4.1a"><msub id="S2.SS2.p3.5.m4.1.1" xref="S2.SS2.p3.5.m4.1.1.cmml"><mi id="S2.SS2.p3.5.m4.1.1.2" xref="S2.SS2.p3.5.m4.1.1.2.cmml">s</mi><mi id="S2.SS2.p3.5.m4.1.1.3" xref="S2.SS2.p3.5.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.5.m4.1b"><apply id="S2.SS2.p3.5.m4.1.1.cmml" xref="S2.SS2.p3.5.m4.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.5.m4.1.1.1.cmml" xref="S2.SS2.p3.5.m4.1.1">subscript</csymbol><ci id="S2.SS2.p3.5.m4.1.1.2.cmml" xref="S2.SS2.p3.5.m4.1.1.2">ğ‘ </ci><ci id="S2.SS2.p3.5.m4.1.1.3.cmml" xref="S2.SS2.p3.5.m4.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.5.m4.1c">s_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.5.m4.1d">italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>, which is normally the language prompt <math alttext="x(s_{t})" class="ltx_Math" display="inline" id="S2.SS2.p3.6.m5.1"><semantics id="S2.SS2.p3.6.m5.1a"><mrow id="S2.SS2.p3.6.m5.1.1" xref="S2.SS2.p3.6.m5.1.1.cmml"><mi id="S2.SS2.p3.6.m5.1.1.3" xref="S2.SS2.p3.6.m5.1.1.3.cmml">x</mi><mo id="S2.SS2.p3.6.m5.1.1.2" xref="S2.SS2.p3.6.m5.1.1.2.cmml">â¢</mo><mrow id="S2.SS2.p3.6.m5.1.1.1.1" xref="S2.SS2.p3.6.m5.1.1.1.1.1.cmml"><mo id="S2.SS2.p3.6.m5.1.1.1.1.2" stretchy="false" xref="S2.SS2.p3.6.m5.1.1.1.1.1.cmml">(</mo><msub id="S2.SS2.p3.6.m5.1.1.1.1.1" xref="S2.SS2.p3.6.m5.1.1.1.1.1.cmml"><mi id="S2.SS2.p3.6.m5.1.1.1.1.1.2" xref="S2.SS2.p3.6.m5.1.1.1.1.1.2.cmml">s</mi><mi id="S2.SS2.p3.6.m5.1.1.1.1.1.3" xref="S2.SS2.p3.6.m5.1.1.1.1.1.3.cmml">t</mi></msub><mo id="S2.SS2.p3.6.m5.1.1.1.1.3" stretchy="false" xref="S2.SS2.p3.6.m5.1.1.1.1.1.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.6.m5.1b"><apply id="S2.SS2.p3.6.m5.1.1.cmml" xref="S2.SS2.p3.6.m5.1.1"><times id="S2.SS2.p3.6.m5.1.1.2.cmml" xref="S2.SS2.p3.6.m5.1.1.2"></times><ci id="S2.SS2.p3.6.m5.1.1.3.cmml" xref="S2.SS2.p3.6.m5.1.1.3">ğ‘¥</ci><apply id="S2.SS2.p3.6.m5.1.1.1.1.1.cmml" xref="S2.SS2.p3.6.m5.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p3.6.m5.1.1.1.1.1.1.cmml" xref="S2.SS2.p3.6.m5.1.1.1.1">subscript</csymbol><ci id="S2.SS2.p3.6.m5.1.1.1.1.1.2.cmml" xref="S2.SS2.p3.6.m5.1.1.1.1.1.2">ğ‘ </ci><ci id="S2.SS2.p3.6.m5.1.1.1.1.1.3.cmml" xref="S2.SS2.p3.6.m5.1.1.1.1.1.3">ğ‘¡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.6.m5.1c">x(s_{t})</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.6.m5.1d">italic_x ( italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math> to further feed into the LLM agent.
Note that the specific design of <math alttext="g" class="ltx_Math" display="inline" id="S2.SS2.p3.7.m6.1"><semantics id="S2.SS2.p3.7.m6.1a"><mi id="S2.SS2.p3.7.m6.1.1" xref="S2.SS2.p3.7.m6.1.1.cmml">g</mi><annotation-xml encoding="MathML-Content" id="S2.SS2.p3.7.m6.1b"><ci id="S2.SS2.p3.7.m6.1.1.cmml" xref="S2.SS2.p3.7.m6.1.1">ğ‘”</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p3.7.m6.1c">g</annotation><annotation encoding="application/x-llamapun" id="S2.SS2.p3.7.m6.1d">italic_g</annotation></semantics></math> directly determines the agent, along with the used LLM, which is still underexplored.</p>
</div>
<div class="ltx_para" id="S2.SS2.p4">
<p class="ltx_p" id="S2.SS2.p4.1">With such a framework, the specific architecture of the agent can be instantiated by creating a direct acyclic graph over the three functions, which can be implemented by changing the prompts of the LLMs. A previous study of similar architectures is provided by <cite class="ltx_cite ltx_citemacro_cite">Christianos etÂ al. (<a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib7" title="">2023</a>)</cite>.
As a result, the architecture of the agentic IR can be built in a unified way.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Key Methods</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">Given the above task formulation and agent architecture, the key methods to improve the performance of agentic IR, namely Eq.Â (<a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S2.E1" title="In 2.1 Task Formulation â€£ 2 Agentic IR â€£ Agentic Information Retrieval"><span class="ltx_text ltx_ref_tag">1</span></a>), would include but not be limited to prompt engineering, retrieval-augmented generation, reflection, supervised fine-tuning, preference learning, reinforcement (learning) fine-tuning, complex reasoning, reward modeling, multi-agent systems, etc.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<ul class="ltx_itemize" id="S2.I1">
<li class="ltx_item" id="S2.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S2.I1.i1.p1">
<p class="ltx_p" id="S2.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i1.p1.1.1">Prompt engineering.</span> Prompts are the task-based language token input to the LLM to enable its ability for the task <cite class="ltx_cite ltx_citemacro_citep">(Liu etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib8" title="">2023</a>)</cite>. For an LLM, the prompt is a human-controllable way to set its hidden state in comparison to the model parameters, including the chain-of-thought prompting.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S2.I1.i2.p1">
<p class="ltx_p" id="S2.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i2.p1.1.1">Retrieval-augmented generation (RAG).</span> The task-specifically retrieved demonstrations play a crucial role in LLM-based applications. In agentic IR, the retrieved demonstrations can be on the action level or the thought level <cite class="ltx_cite ltx_citemacro_citep">(Zhou etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib9" title="">2024</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S2.I1.i3.p1">
<p class="ltx_p" id="S2.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i3.p1.1.1">Reflection.</span> The agent may use the failure or suboptimal results of its interactions with the environment to update its thoughts, so as to make further attempts to refine its actions and thus the resulting information state <cite class="ltx_cite ltx_citemacro_citep">(Shinn etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib10" title="">2024</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S2.I1.i4.p1">
<p class="ltx_p" id="S2.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i4.p1.1.1">Supervised fine-tuning (SFT).</span> As a basic methods for fine-tuning LLMs, SFT can be seamlessly adapted to agentic IR tasks, where the successful historic trajectories are used as the training data with each step of action or the output of each inner function as the label to fit. SFT corresponds to the behavioral cloning imitation learning methods in reinforcement learning. Despite simplicity, SFT does not directly optimize the objective (<a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S2.E1" title="In 2.1 Task Formulation â€£ 2 Agentic IR â€£ Agentic Information Retrieval"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S2.I1.i5.p1">
<p class="ltx_p" id="S2.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i5.p1.1.1">Preference learning.</span> One step further based on SFT, fine-tuning LLMs based on a preference objective over a pair of outputs may improve the performance of the agentic IR models <cite class="ltx_cite ltx_citemacro_citep">(Rafailov etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib11" title="">2024</a>)</cite>. Note that such methods are to some extent similar to the pairwise learning to rank techniques in traditional IR <cite class="ltx_cite ltx_citemacro_citep">(Burges etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib12" title="">2005</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i6" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S2.I1.i6.p1">
<p class="ltx_p" id="S2.I1.i6.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i6.p1.1.1">Reinforcement fine-tuning (RFT).</span> Regarding the environment as a Markov decision process, reinforcement learning methods, including PPO <cite class="ltx_cite ltx_citemacro_citep">(Schulman etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib13" title="">2017</a>)</cite> and AlphaZero <cite class="ltx_cite ltx_citemacro_citep">(Silver etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib14" title="">2018</a>)</cite>, directly optimize the objective (<a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S2.E1" title="In 2.1 Task Formulation â€£ 2 Agentic IR â€£ Agentic Information Retrieval"><span class="ltx_text ltx_ref_tag">1</span></a>), given the reward signal from the environment or human feedbacks (RLHF) <cite class="ltx_cite ltx_citemacro_citep">(Ouyang etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib15" title="">2022</a>)</cite>. Compared with SFT and preference tuning, RFT usually requests larger computational resources to explore the environment, accumulate experience data, and update the model parameters <cite class="ltx_cite ltx_citemacro_citep">(Christianos etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib7" title="">2023</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i7" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S2.I1.i7.p1">
<p class="ltx_p" id="S2.I1.i7.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i7.p1.1.1">Complex reasoning.</span> For non-trivial tasks, the agent needs to perform task planning and complex reasoning before taking actions. The recent success of OpenAI o1 <cite class="ltx_cite ltx_citemacro_citep">(OpenAI, <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib16" title="">2014</a>)</cite> indicates the great potential of a strong reasoner for improving the agentâ€™s task-solving performance. In contrast, RAG can be regarded as a case-based reasoning <cite class="ltx_cite ltx_citemacro_citep">(Guo etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib17" title="">2024</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i8" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S2.I1.i8.p1">
<p class="ltx_p" id="S2.I1.i8.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i8.p1.1.1">Reward modeling.</span> As a judge of the resulting information state or intermediate states in the process, the reward function modeling is crucial to enable RFT or search-based decoding techniques in complex agentic IR tasks. Referring to recent advances in solving math reasoning problems, the outcome reward models and process reward models are essential modules to yield high-performance math agents <cite class="ltx_cite ltx_citemacro_citep">(Uesato etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib18" title="">2022</a>; Luo etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib19" title="">2024</a>)</cite>.</p>
</div>
</li>
<li class="ltx_item" id="S2.I1.i9" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S2.I1.i9.p1">
<p class="ltx_p" id="S2.I1.i9.p1.1"><span class="ltx_text ltx_font_bold" id="S2.I1.i9.p1.1.1">Multi-agent systems (MAS).</span> A MAS contains multiple homogeneous or heterogeneous agents, each of which could be equipped with a special role or resources. With proper mechanisms, the team of agents manages to coordinate to achieve remarkable collective intelligence <cite class="ltx_cite ltx_citemacro_citep">(Chen etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib20" title="">2023</a>; Li etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib21" title="">2024a</a>)</cite>.</p>
</div>
</li>
</ul>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Application Scenarios and Case Studies</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">In this section, we briefly discuss three types of applications with case studies of agent IR, i.e., life assistant, business assistant, and coding assistant. As their names are, the agent IR would play more like an assistant for users with a certain level of autonomy. The traditional IR, by contrast, is like a tool to call in agent IR, which is non-autonomous.</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Life Assistant</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">In recent years, life assistants have evolved from simple voice-activated tools into sophisticated systems capable of supporting users across a wide array of daily tasks. At the core of this transformation is a significant advancement in IR technologies. Agentic IR empowers these assistants not only to gather and deliver information but also to proactively support planning and decision-making with a deep understanding of the userâ€™s needs, context, and preferences. This shift enables life assistants to act as active, autonomous agents that adapt seamlessly to a userâ€™s lifestyle, offering guidance and taking actions in real time.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.1">Agentic IR capabilities are already present in major products like Appleâ€™s ecosystem, where Apple Intelligence<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_href" href="https://www.apple.com/apple-intelligence/" title="">https://www.apple.com/apple-intelligence/</a></span></span></span> powers advanced assistant features across devices such as iPhone, iPad, and Mac <cite class="ltx_cite ltx_citemacro_citep">(Apple, <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib22" title="">2024</a>)</cite>. Apple Intelligence enhances user experience by seamlessly integrating with apps, services, and smart devices, embodying the proactive and contextual characteristics of agentic IR. Beyond Apple, other life assistants, such as Google Assistant<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span><a class="ltx_ref ltx_href" href="https://assistant.google.com/" title="">https://assistant.google.com/</a></span></span></span>, Amazon Alexa<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_href" href="https://www.alexa.com/" title="">https://www.alexa.com/</a></span></span></span>, Oppo Breeno, and Huawei Celia<span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_href" href="https://consumer.huawei.com/en/emui/celia/" title="">https://consumer.huawei.com/en/emui/celia/</a></span></span></span>, operate across diverse platforms, including smartphones, smart home devices, and wearables. These assistants empower users with convenient control over both digital and physical environments, enabling them to make informed plans and adjustments anytime, anywhere <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib23" title="">2024b</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S3.SS1.p3">
<p class="ltx_p" id="S3.SS1.p3.1">Consider the following scenario: Jane is a busy professional who uses a life assistant integrated into her smartphone and other devices. Agentic IR allows her assistant to anticipate her needs, gather relevant information, and autonomously perform tasks without constant user intervention. FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S3.F2" title="Figure 2 â€£ 3.1 Life Assistant â€£ 3 Application Scenarios and Case Studies â€£ Agentic Information Retrieval"><span class="ltx_text ltx_ref_tag">2</span></a> illustrate how the various features of agentic IR play out in Janeâ€™s daily life.</p>
</div>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="457" id="S3.F2.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Illustration of agentic IR in life assistant scenarios.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.p4">
<p class="ltx_p" id="S3.SS1.p4.3"><span class="ltx_text ltx_font_bold" id="S3.SS1.p4.3.1">Proactive information gathering and state transition.</span>
Each step taken by the assistant is a transition from one intermediate information state to another, achieved through actions <math alttext="(a_{t})" class="ltx_Math" display="inline" id="S3.SS1.p4.1.m1.1"><semantics id="S3.SS1.p4.1.m1.1a"><mrow id="S3.SS1.p4.1.m1.1.1.1" xref="S3.SS1.p4.1.m1.1.1.1.1.cmml"><mo id="S3.SS1.p4.1.m1.1.1.1.2" stretchy="false" xref="S3.SS1.p4.1.m1.1.1.1.1.cmml">(</mo><msub id="S3.SS1.p4.1.m1.1.1.1.1" xref="S3.SS1.p4.1.m1.1.1.1.1.cmml"><mi id="S3.SS1.p4.1.m1.1.1.1.1.2" xref="S3.SS1.p4.1.m1.1.1.1.1.2.cmml">a</mi><mi id="S3.SS1.p4.1.m1.1.1.1.1.3" xref="S3.SS1.p4.1.m1.1.1.1.1.3.cmml">t</mi></msub><mo id="S3.SS1.p4.1.m1.1.1.1.3" stretchy="false" xref="S3.SS1.p4.1.m1.1.1.1.1.cmml">)</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.1.m1.1b"><apply id="S3.SS1.p4.1.m1.1.1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.1.m1.1.1.1.1.1.cmml" xref="S3.SS1.p4.1.m1.1.1.1">subscript</csymbol><ci id="S3.SS1.p4.1.m1.1.1.1.1.2.cmml" xref="S3.SS1.p4.1.m1.1.1.1.1.2">ğ‘</ci><ci id="S3.SS1.p4.1.m1.1.1.1.1.3.cmml" xref="S3.SS1.p4.1.m1.1.1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.1.m1.1c">(a_{t})</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.1.m1.1d">( italic_a start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT )</annotation></semantics></math> that are dynamically informed by Janeâ€™s requests and surrounding context. If Janeâ€™s meeting is across town during rush hour, her assistant identifies the information state <math alttext="s_{t}" class="ltx_Math" display="inline" id="S3.SS1.p4.2.m2.1"><semantics id="S3.SS1.p4.2.m2.1a"><msub id="S3.SS1.p4.2.m2.1.1" xref="S3.SS1.p4.2.m2.1.1.cmml"><mi id="S3.SS1.p4.2.m2.1.1.2" xref="S3.SS1.p4.2.m2.1.1.2.cmml">s</mi><mi id="S3.SS1.p4.2.m2.1.1.3" xref="S3.SS1.p4.2.m2.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.2.m2.1b"><apply id="S3.SS1.p4.2.m2.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.2.m2.1.1.1.cmml" xref="S3.SS1.p4.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.p4.2.m2.1.1.2.cmml" xref="S3.SS1.p4.2.m2.1.1.2">ğ‘ </ci><ci id="S3.SS1.p4.2.m2.1.1.3.cmml" xref="S3.SS1.p4.2.m2.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.2.m2.1c">s_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.2.m2.1d">italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> that includes traffic conditions and suggests an earlier departure time. This suggestion is the next intermediate state for that interaction, precisely capturing the assistantâ€™s proactive adaptation to Janeâ€™s immediate needs. Each conversation round refines the assistantâ€™s understanding, moving incrementally closer to the target information state <math alttext="s_{*}" class="ltx_Math" display="inline" id="S3.SS1.p4.3.m3.1"><semantics id="S3.SS1.p4.3.m3.1a"><msub id="S3.SS1.p4.3.m3.1.1" xref="S3.SS1.p4.3.m3.1.1.cmml"><mi id="S3.SS1.p4.3.m3.1.1.2" xref="S3.SS1.p4.3.m3.1.1.2.cmml">s</mi><mo id="S3.SS1.p4.3.m3.1.1.3" xref="S3.SS1.p4.3.m3.1.1.3.cmml">âˆ—</mo></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p4.3.m3.1b"><apply id="S3.SS1.p4.3.m3.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.p4.3.m3.1.1.1.cmml" xref="S3.SS1.p4.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.p4.3.m3.1.1.2.cmml" xref="S3.SS1.p4.3.m3.1.1.2">ğ‘ </ci><times id="S3.SS1.p4.3.m3.1.1.3.cmml" xref="S3.SS1.p4.3.m3.1.1.3"></times></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p4.3.m3.1c">s_{*}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p4.3.m3.1d">italic_s start_POSTSUBSCRIPT âˆ— end_POSTSUBSCRIPT</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS1.p5">
<p class="ltx_p" id="S3.SS1.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p5.1.1">Modular design using memory, thought, and tools.</span>
In reaching each intermediate information state, the assistant employs a modular structure with memory (<span class="ltx_text ltx_font_smallcaps" id="S3.SS1.p5.1.2">Mem</span>) for context, manipulate thought (<span class="ltx_text ltx_font_smallcaps" id="S3.SS1.p5.1.3">Tht</span>) for processing Janeâ€™s preferences, and tools (<span class="ltx_text ltx_font_smallcaps" id="S3.SS1.p5.1.4">Tool</span>) for external information sources like real-time traffic or weather data. For example, before Janeâ€™s business trip, the assistant integrates data from her calendar (via <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.p5.1.5">Mem</span>) with travel conditions (accessed via <span class="ltx_text ltx_font_smallcaps" id="S3.SS1.p5.1.6">Tool</span>). Each round of action culminates in a specific intermediate information state <math alttext="s_{t}" class="ltx_Math" display="inline" id="S3.SS1.p5.1.m1.1"><semantics id="S3.SS1.p5.1.m1.1a"><msub id="S3.SS1.p5.1.m1.1.1" xref="S3.SS1.p5.1.m1.1.1.cmml"><mi id="S3.SS1.p5.1.m1.1.1.2" xref="S3.SS1.p5.1.m1.1.1.2.cmml">s</mi><mi id="S3.SS1.p5.1.m1.1.1.3" xref="S3.SS1.p5.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p5.1.m1.1b"><apply id="S3.SS1.p5.1.m1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p5.1.m1.1.1.1.cmml" xref="S3.SS1.p5.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p5.1.m1.1.1.2.cmml" xref="S3.SS1.p5.1.m1.1.1.2">ğ‘ </ci><ci id="S3.SS1.p5.1.m1.1.1.3.cmml" xref="S3.SS1.p5.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p5.1.m1.1c">s_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p5.1.m1.1d">italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>, gradually advancing toward the target information state and bringing Jane closer to her goal, such as having "all travel preparations confirmed".</p>
</div>
<div class="ltx_para" id="S3.SS1.p6">
<p class="ltx_p" id="S3.SS1.p6.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p6.1.1">Adaptation through contextual understanding and interactive refinement.</span>
Agentic IR enables the assistant to adapt seamlessly by refining its actions based on both explicit queries and passive contextual cues, allowing continuous updates to the information state <math alttext="s_{t}" class="ltx_Math" display="inline" id="S3.SS1.p6.1.m1.1"><semantics id="S3.SS1.p6.1.m1.1a"><msub id="S3.SS1.p6.1.m1.1.1" xref="S3.SS1.p6.1.m1.1.1.cmml"><mi id="S3.SS1.p6.1.m1.1.1.2" xref="S3.SS1.p6.1.m1.1.1.2.cmml">s</mi><mi id="S3.SS1.p6.1.m1.1.1.3" xref="S3.SS1.p6.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.p6.1.m1.1b"><apply id="S3.SS1.p6.1.m1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.p6.1.m1.1.1.1.cmml" xref="S3.SS1.p6.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.p6.1.m1.1.1.2.cmml" xref="S3.SS1.p6.1.m1.1.1.2">ğ‘ </ci><ci id="S3.SS1.p6.1.m1.1.1.3.cmml" xref="S3.SS1.p6.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p6.1.m1.1c">s_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p6.1.m1.1d">italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> without needing repeated user input. For example, when Jane arrives at a grocery store, the assistant references her shopping list based on location; if a previous item is missing, it suggests adding it without requiring her to ask. Similarly, if Jane requests a restaurant recommendation, the assistant interactively clarifies her preferences, such as cuisine and view, to better align with her needs. By adapting to both explicit responses and situational context, the assistant effectively progresses toward the target information state, underscoring agentic IRâ€™s capacity for flexible, accurate assistance with minimal input.</p>
</div>
<div class="ltx_para" id="S3.SS1.p7">
<p class="ltx_p" id="S3.SS1.p7.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p7.1.1">Autonomous task execution and final information states.</span>
Beyond simply gathering information, agentic IR enables the assistant to autonomously execute tasks, such as booking a dinner reservation or setting reminders. When Janeâ€™s assistant books a restaurant, it concludes that conversation round in an information state where the booking is completed and confirmed in her calendar. This autonomous capability frees Jane from cognitive overhead, allowing her to focus on higher-priority tasks as the assistant seamlessly progresses from one target information state to the next.</p>
</div>
<div class="ltx_para" id="S3.SS1.p8">
<p class="ltx_p" id="S3.SS1.p8.1"><span class="ltx_text ltx_font_bold" id="S3.SS1.p8.1.1">Seamless integration across devices and services.</span>
The assistantâ€™s ability to unify various devices and services allows it to operate as a fully integrated agentic IR system. By combining memory and real-time inputs across her smart home and calendar applications, Janeâ€™s assistant ensures that her arrival time and thermostat settings are in harmony. This synchronization allows the assistant to present a resulting information state where her physical environment aligns with her personal schedule, streamlining her routines.</p>
</div>
<div class="ltx_para" id="S3.SS1.p9">
<p class="ltx_p" id="S3.SS1.p9.1">Agentic IR represents a fundamental shift in how life assistants interact with users. By anticipating needs, understanding context, and performing tasks autonomously, agentic IR makes life assistants not just more useful, but indispensable. The proactive nature of these systems â€” along with their ability to integrate multiple sources of information, learn from interactions, and act independently â€” enables them to provide a uniquely tailored and efficient user experience.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Business Assistant</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Business assistant is designed to support enterprise users by providing relevant business knowledge and insights based on various documents and data sources. With agentic IR capabilities, the business assistant goes beyond passive information retrieval to actively participate in intention recognition and response generation. Leveraging powerful information retrieval and generation capabilities, business assistants can address a wide range of business-related queries, from financial analysis to marketing strategies, helping users make better decisions.</p>
</div>
<div class="ltx_para" id="S3.SS2.p2">
<p class="ltx_p" id="S3.SS2.p2.1">The business assistant workflow generally involves four stages: query understanding, document retrieval, information integration, and response generation, as illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S3.F3" title="Figure 3 â€£ 3.2 Business Assistant â€£ 3 Application Scenarios and Case Studies â€£ Agentic Information Retrieval"><span class="ltx_text ltx_ref_tag">3</span></a>. Today, there are already several business assistants powered by agentic IR in use, such as Amazon Q Business<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span><a class="ltx_ref ltx_href" href="https://aws.amazon.com/q/business/" title="">https://aws.amazon.com/q/business/</a></span></span></span>. Below, we will illustrate each stage with reference to this example.</p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="461" id="S3.F3.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Illustration of agentic IR in business assistant scenarios.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS2.p3">
<p class="ltx_p" id="S3.SS2.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p3.1.1">Query understanding.</span> Given a business-related query, the agent, core of the business assistant, first attempts to understand and analyze the userâ€™s intention. For complex queries, the agent can generate thoughts (<span class="ltx_text ltx_font_smallcaps" id="S3.SS2.p3.1.2">Tht</span>) with CoT to break down the problem into smaller, manageable steps, allowing for multi-step reasoning. In Amazon Q Business, conversations are continuous, allowing the historical dialogues to serve as memory (<span class="ltx_text ltx_font_smallcaps" id="S3.SS2.p3.1.3">Mem</span>), helping the agent better understand the context and user intention.</p>
</div>
<div class="ltx_para" id="S3.SS2.p4">
<p class="ltx_p" id="S3.SS2.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p4.1.1">Document retrieval.</span> Based on the query, the agent retrieves relevant information from external and internal documents to extract the most pertinent data. Given the diverse formats of documents (e.g., PDFs, figures, tables), the agent may utilize tools (<span class="ltx_text ltx_font_smallcaps" id="S3.SS2.p4.1.2">Tool</span>) such as OCR for scanned text or SQL for structured data. In addition, the agent can leverage semantic search capabilities to go beyond simple keyword matching, ensuring that the retrieved information aligns more closely with the intent of the query.</p>
</div>
<div class="ltx_para" id="S3.SS2.p5">
<p class="ltx_p" id="S3.SS2.p5.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p5.1.1">Information integration.</span> In many cases, the retrieved information is scattered across multiple sections or even across different documents. Before responding to the query, the agent generates thoughts (<span class="ltx_text ltx_font_smallcaps" id="S3.SS2.p5.1.2">Tht</span>) or uses tools (<span class="ltx_text ltx_font_smallcaps" id="S3.SS2.p5.1.3">Tool</span>) to combine and condense the information. In Amazon Q Business, the system is equipped with the RAG framework by default and supports various plugins to generate responses or complete tasks.</p>
</div>
<div class="ltx_para" id="S3.SS2.p6">
<p class="ltx_p" id="S3.SS2.p6.1"><span class="ltx_text ltx_font_bold" id="S3.SS2.p6.1.1">Response generation.</span> Finally, the agent generates a response, reaching the resulting information state. Depending on the query and the retrieved data, the resulting information state can take various forms. The response may be presented in multiple formats, including plain text, tables, visualized charts, etc. The assistant can also complete tasks and return an action state. In Amazon Q Business, it also links the answer back to its source documents to ensure transparency, allowing users to trace how the response was derived.</p>
</div>
<div class="ltx_para" id="S3.SS2.p7">
<p class="ltx_p" id="S3.SS2.p7.1">The application of business assistant is continuously evolving with advancements in agentic IR and growing market demand. Key trends include enhanced contextual understanding and multi-step reasoning, enabling business assistants to comprehend and execute more complex instructions. Additionally, in business scenarios where data is generated continuously, business assistants will need to retrieve and integrate information from ever-updating sources. Security is also a critical concern, including the protection of internal enterprise data and ensuring the safety of the responses generated by the agent.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Coding Assistant</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Interactive programming assistance and automatic program synthesis play important roles in liberating productivity and improving development efficiency. Industrial programming assistant products like Copilot <span class="ltx_note ltx_role_footnote" id="footnote6"><sup class="ltx_note_mark">6</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">6</sup><span class="ltx_tag ltx_tag_note">6</span><a class="ltx_ref ltx_href" href="https://github.com/features/copilot" title="">https://github.com/features/copilot</a></span></span></span> emerge, offering an interactive environment for developers to gather information from open world and reach their programming needs. Agentic information retrieval in the context of coding assistants refers to systems designed to autonomously retrieve and provide relevant information based on developer queries and contextual needs. This approach emphasizes the ability of the assistant not just to respond to requests but to proactively understand developer intent, code context, and potential challenges the user may face.
The main stages of Developer - Coding Assistant interaction process can be summarized into information need diagnosis, knowledge content generation, and information state update. An illustration is provided in FigureÂ <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#S3.F4" title="Figure 4 â€£ 3.3 Coding Assistant â€£ 3 Application Scenarios and Case Studies â€£ Agentic Information Retrieval"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="560" id="S3.F4.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Illustration of agentic IR in coding assistant scenarios.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p2.1.1">Information need diagnosis.</span>
At a certain state <math alttext="s_{t}" class="ltx_Math" display="inline" id="S3.SS3.p2.1.m1.1"><semantics id="S3.SS3.p2.1.m1.1a"><msub id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mi id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml">s</mi><mi id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2">ğ‘ </ci><ci id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">s_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.1.m1.1d">italic_s start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math>, the developerâ€™s information need can be conscious and unconscious. On the one hand, developers can consciously input their requirements like "Generate docs" or call â€˜<span class="ltx_text ltx_font_italic" id="S3.SS3.p2.1.2">/doc</span>â€™ to retrieve documentary knowledge from the coding assistant to suit the need. On the other hand, the information need can be unconscious. For example, during the programming procedure, a developer may write a function declaration, while the functionality to be achieved can be automatically identified by the coding assistant and then used to query itself for corresponding assistance. This unconscious information need diagnosis makes agentic IR distinct and advanced compared to the traditional IR, offering timely and tailored knowledge assistance. Another characteristic of agentic IR is the memory module (<span class="ltx_text ltx_font_smallcaps" id="S3.SS3.p2.1.3">Mem</span>), which allows the coding assistant to remember previous interactions, including developer preferences, past queries, debugging histories, and specific coding projects. This enables the assistant to maintain context over time, providing more tailored information need diagnosis.</p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p3.1.1">Knowledge content generation.</span>
After the information need is identified, it is then used to query the code assistant for corresponding knowledge content. Powered by the intelligent large language model like OpenAI CodeX <span class="ltx_note ltx_role_footnote" id="footnote7"><sup class="ltx_note_mark">7</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">7</sup><span class="ltx_tag ltx_tag_note">7</span>https://openai.com/index/openai-codex</span></span></span>, the coding assistant enables the developerâ€™ access to public documents and a professional programming assistant. As a high reasoning-demand task, code generation and debugging often requires an intermediate thinking process (<span class="ltx_text ltx_font_smallcaps" id="S3.SS3.p3.1.2">Tht</span>) <cite class="ltx_cite ltx_citemacro_citep">(Li etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib24" title="">2024c</a>)</cite>, seeking an optimal knowledge content.
In addition, integrated with various coding tools (<span class="ltx_text ltx_font_smallcaps" id="S3.SS3.p3.1.3">Tool</span>), like debuggers, compilers, and linters, the coding assistant can provide reliable and non-parametric knowledge to suit the developerâ€™s information need.
For example, the coding assistant can synthesize the codes to be completed enhanced by <span class="ltx_text ltx_font_smallcaps" id="S3.SS3.p3.1.4">Tht</span>, call test generation to generate tests and provide compiler feedback enhanced by <span class="ltx_text ltx_font_smallcaps" id="S3.SS3.p3.1.5">Tool</span> for debugging purpose, retrieve and complement documents for codes refinement, etc. The generated knowledge content is then presented to the developer.</p>
</div>
<div class="ltx_para" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.1"><span class="ltx_text ltx_font_bold" id="S3.SS3.p4.1.1">Information state update.</span>
After the knowledge content is generated, the developer can then perceive the knowledge and proceed to refine its work. This refinement updates the information state of the developer to reach <math alttext="s_{t+1}" class="ltx_Math" display="inline" id="S3.SS3.p4.1.m1.1"><semantics id="S3.SS3.p4.1.m1.1a"><msub id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml"><mi id="S3.SS3.p4.1.m1.1.1.2" xref="S3.SS3.p4.1.m1.1.1.2.cmml">s</mi><mrow id="S3.SS3.p4.1.m1.1.1.3" xref="S3.SS3.p4.1.m1.1.1.3.cmml"><mi id="S3.SS3.p4.1.m1.1.1.3.2" xref="S3.SS3.p4.1.m1.1.1.3.2.cmml">t</mi><mo id="S3.SS3.p4.1.m1.1.1.3.1" xref="S3.SS3.p4.1.m1.1.1.3.1.cmml">+</mo><mn id="S3.SS3.p4.1.m1.1.1.3.3" xref="S3.SS3.p4.1.m1.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><apply id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p4.1.m1.1.1.2.cmml" xref="S3.SS3.p4.1.m1.1.1.2">ğ‘ </ci><apply id="S3.SS3.p4.1.m1.1.1.3.cmml" xref="S3.SS3.p4.1.m1.1.1.3"><plus id="S3.SS3.p4.1.m1.1.1.3.1.cmml" xref="S3.SS3.p4.1.m1.1.1.3.1"></plus><ci id="S3.SS3.p4.1.m1.1.1.3.2.cmml" xref="S3.SS3.p4.1.m1.1.1.3.2">ğ‘¡</ci><cn id="S3.SS3.p4.1.m1.1.1.3.3.cmml" type="integer" xref="S3.SS3.p4.1.m1.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">s_{t+1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.1.m1.1d">italic_s start_POSTSUBSCRIPT italic_t + 1 end_POSTSUBSCRIPT</annotation></semantics></math>, where a new round of interaction is then activated.</p>
</div>
<div class="ltx_para" id="S3.SS3.p5">
<p class="ltx_p" id="S3.SS3.p5.1">During the interaction process, the developer gathers timely, tailored, and evolving information from the coding assistant, proceeding to the resulting information state <math alttext="s_{T}" class="ltx_Math" display="inline" id="S3.SS3.p5.1.m1.1"><semantics id="S3.SS3.p5.1.m1.1a"><msub id="S3.SS3.p5.1.m1.1.1" xref="S3.SS3.p5.1.m1.1.1.cmml"><mi id="S3.SS3.p5.1.m1.1.1.2" xref="S3.SS3.p5.1.m1.1.1.2.cmml">s</mi><mi id="S3.SS3.p5.1.m1.1.1.3" xref="S3.SS3.p5.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.1.m1.1b"><apply id="S3.SS3.p5.1.m1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p5.1.m1.1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p5.1.m1.1.1.2.cmml" xref="S3.SS3.p5.1.m1.1.1.2">ğ‘ </ci><ci id="S3.SS3.p5.1.m1.1.1.3.cmml" xref="S3.SS3.p5.1.m1.1.1.3">ğ‘‡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.1.m1.1c">s_{T}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.1.m1.1d">italic_s start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT</annotation></semantics></math> where a qualified code or project is accomplished.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Challenges</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">As a branding-new paradigm of IR, most of the techniques and engineering modules of agentic IR are still in their infancy and facing challenges in different aspects.</p>
</div>
<div class="ltx_para" id="S4.p2">
<ul class="ltx_itemize" id="S4.I1">
<li class="ltx_item" id="S4.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I1.i1.p1">
<p class="ltx_p" id="S4.I1.i1.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i1.p1.1.1">Data acquisition.</span>
As a decision-making task, the logged data of agentic IR largely comes from the agentâ€™s interaction with the environment, which is determined by the usersâ€™ instructions, the agent policy, and the environment dynamics. The exploration-exploitation tradeoff will be crucial to collecting high-quality and wide coverage data. Directly labeling the correct trajectories to achieve the target state is still possible, but highly expensive.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I1.i2.p1">
<p class="ltx_p" id="S4.I1.i2.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i2.p1.1.1">Model training.</span>
As the agent policy would consist of a DAG of functions, i.e., memory update, thought manipulation, and tool use, it is highly challenging to effectively update the parameters of these functions and the total composite policy function. Some recent attempts to tackle this challenge via RFT <cite class="ltx_cite ltx_citemacro_citep">(Christianos etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib7" title="">2023</a>)</cite> and action decomposition <cite class="ltx_cite ltx_citemacro_citep">(Wen etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib25" title="">2024</a>)</cite> have been performed.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I1.i3.p1">
<p class="ltx_p" id="S4.I1.i3.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i3.p1.1.1">Inference cost.</span>
Due to the large parameter size and the autoregressive nature, the inference of LLMs is both GPU-heavy and time-consuming. Thus, the system optimization of agentic IR is crucial for practical service deployment.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i4" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I1.i4.p1">
<p class="ltx_p" id="S4.I1.i4.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i4.p1.1.1">Safety.</span>
As the agent directly interacts with the real environment, its decision of action will change the environment and carry the user to different resulting information states. Thus, it is even more important than the chat applications to guarantee safety across the user journey. Alignment techniques <cite class="ltx_cite ltx_citemacro_citep">(Ji etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib26" title="">2023</a>)</cite> can be helpful but the safety is not guaranteed. A recent proposal of â€œworld model + verifier" framework <cite class="ltx_cite ltx_citemacro_citep">(Dalrymple etÂ al., <a class="ltx_ref" href="https://arxiv.org/html/2410.09713v1#bib.bib27" title="">2024</a>)</cite> can be a way to explore safety for agentic IR.</p>
</div>
</li>
<li class="ltx_item" id="S4.I1.i5" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span>
<div class="ltx_para" id="S4.I1.i5.p1">
<p class="ltx_p" id="S4.I1.i5.p1.1"><span class="ltx_text ltx_font_bold" id="S4.I1.i5.p1.1.1">Interacting with users.</span>
Finally, given the differences from traditional IR in almost all aspects, including inference latency, data manipulation, information state representation, etc., the product form of agentic IR is still under-explored. There is still a long way to go to find the product-market fit for agentic IR.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusions</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">In this position paper, we conceptualize a new technical paradigm of information retrieval in the era of LLMs, named <span class="ltx_text ltx_font_italic" id="S5.p1.1.1">Agentic IR</span>. Unlike the traditional IR that filters the item corpus and returns the relevant items to the user, in agentic IR, the agent automatically interacts with the environment to reach the userâ€™s target information state. As such, the agentic IR serves a broad task scope, employs a unified agent architecture, and involves different key methods compared to traditional IR. Although facing challenges in multiple aspects, it can be expected that agentic IR will be highly developed and promoted in the coming couple of years.</p>
</div>
</section>
<section class="ltx_section" id="Sx1">
<h2 class="ltx_title ltx_title_section">Acknowledgments</h2>
<div class="ltx_para" id="Sx1.p1">
<p class="ltx_p" id="Sx1.p1.1">We thank the insightful discussions with Jie Fu, Jun Wang, Ying Wen, Zheng Tian, Minjie Wang, David Wipf, Quan Gan, Qiuying Peng, and Grace Hui Yang.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Singhal etÂ al. (2001)</span>
<span class="ltx_bibblock">
Amit Singhal etÂ al.

</span>
<span class="ltx_bibblock">Modern information retrieval: A brief overview.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">IEEE Data Eng. Bull.</em>, 24(4):35â€“43, 2001.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang etÂ al. (2017)</span>
<span class="ltx_bibblock">
Jun Wang, Lantao Yu, Weinan Zhang, YuÂ Gong, Yinghui Xu, Benyou Wang, Peng
Zhang, and Dell Zhang.

</span>
<span class="ltx_bibblock">Irgan: A minimax game for unifying generative and discriminative
information retrieval models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">Proceedings of the 40th International ACM SIGIR conference
on Research and Development in Information Retrieval</em>, pages 515â€“524, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Baeza-Yates etÂ al. (1999)</span>
<span class="ltx_bibblock">
Ricardo Baeza-Yates, Berthier Ribeiro-Neto, etÂ al.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Modern information retrieval</em>, volume 463.

</span>
<span class="ltx_bibblock">ACM press New York, 1999.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Qin etÂ al. (2022)</span>
<span class="ltx_bibblock">
Jiarui Qin, Jiachen Zhu, BoÂ Chen, Zhirong Liu, Weiwen Liu, Ruiming Tang, Rui
Zhang, Yong Yu, and Weinan Zhang.

</span>
<span class="ltx_bibblock">Rankflow: Joint optimization of multi-stage cascade ranking systems
as flows.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">Proceedings of the 45th International ACM SIGIR Conference
on Research and Development in Information Retrieval</em>, pages 814â€“824, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Patil etÂ al. (2023)</span>
<span class="ltx_bibblock">
ShishirÂ G Patil, Tianjun Zhang, Xin Wang, and JosephÂ E Gonzalez.

</span>
<span class="ltx_bibblock">Gorilla: Large language model connected with massive apis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">arXiv preprint arXiv:2305.15334</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin etÂ al. (2024)</span>
<span class="ltx_bibblock">
Qiqiang Lin, Muning Wen, Qiuying Peng, Guanyu Nie, Junwei Liao, Jun Wang,
Xiaoyun Mo, Jiamu Zhou, Cheng Cheng, Yin Zhao, Jun Wang, and Weinan Zhang.

</span>
<span class="ltx_bibblock">Hammer: Robust function-calling for on-device language models via
function masking.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2410.04587</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Christianos etÂ al. (2023)</span>
<span class="ltx_bibblock">
Filippos Christianos, Georgios Papoudakis, Matthieu Zimmer, Thomas Coste,
Zhihao Wu, Jingxuan Chen, Khyati Khandelwal, James Doran, Xidong Feng,
Jiacheng Liu, etÂ al.

</span>
<span class="ltx_bibblock">Pangu-agent: A fine-tunable generalist agent with structured
reasoning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">arXiv preprint arXiv:2312.14878</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu etÂ al. (2023)</span>
<span class="ltx_bibblock">
Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and
Graham Neubig.

</span>
<span class="ltx_bibblock">Pre-train, prompt, and predict: A systematic survey of prompting
methods in natural language processing.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">ACM Computing Surveys</em>, 55(9):1â€“35, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou etÂ al. (2024)</span>
<span class="ltx_bibblock">
Ruiwen Zhou, Yingxuan Yang, Muning Wen, Ying Wen, Wenhao Wang, Chunling Xi,
Guoqiang Xu, Yong Yu, and Weinan Zhang.

</span>
<span class="ltx_bibblock">Trad: Enhancing llm agents with step-wise thought retrieval and
aligned decision.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">Proceedings of the 47th International ACM SIGIR Conference
on Research and Development in Information Retrieval</em>, pages 3â€“13, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Shinn etÂ al. (2024)</span>
<span class="ltx_bibblock">
Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu
Yao.

</span>
<span class="ltx_bibblock">Reflexion: Language agents with verbal reinforcement learning.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">Advances in Neural Information Processing Systems</em>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Rafailov etÂ al. (2024)</span>
<span class="ltx_bibblock">
Rafael Rafailov, Archit Sharma, Eric Mitchell, ChristopherÂ D Manning, Stefano
Ermon, and Chelsea Finn.

</span>
<span class="ltx_bibblock">Direct preference optimization: Your language model is secretly a
reward model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Advances in Neural Information Processing Systems</em>, 36, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Burges etÂ al. (2005)</span>
<span class="ltx_bibblock">
Chris Burges, Tal Shaked, Erin Renshaw, Ari Lazier, Matt Deeds, Nicole
Hamilton, and Greg Hullender.

</span>
<span class="ltx_bibblock">Learning to rank using gradient descent.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">Proceedings of the 22nd international conference on Machine
learning</em>, pages 89â€“96, 2005.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Schulman etÂ al. (2017)</span>
<span class="ltx_bibblock">
John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov.

</span>
<span class="ltx_bibblock">Proximal policy optimization algorithms.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">arXiv preprint arXiv:1707.06347</em>, 2017.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Silver etÂ al. (2018)</span>
<span class="ltx_bibblock">
David Silver, Thomas Hubert, Julian Schrittwieser, Ioannis Antonoglou, Matthew
Lai, Arthur Guez, Marc Lanctot, Laurent Sifre, Dharshan Kumaran, Thore
Graepel, etÂ al.

</span>
<span class="ltx_bibblock">A general reinforcement learning algorithm that masters chess, shogi,
and go through self-play.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">Science</em>, 362(6419):1140â€“1144, 2018.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ouyang etÂ al. (2022)</span>
<span class="ltx_bibblock">
Long Ouyang, Jeffrey Wu, XuÂ Jiang, Diogo Almeida, Carroll Wainwright, Pamela
Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, etÂ al.

</span>
<span class="ltx_bibblock">Training language models to follow instructions with human feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">Advances in neural information processing systems</em>,
35:27730â€“27744, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (2014)</span>
<span class="ltx_bibblock">
OpenAI.

</span>
<span class="ltx_bibblock">Learning to reason with llms.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/index/learning-to-reason-with-llms/" title="">https://openai.com/index/learning-to-reason-with-llms/</a>, 2014.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guo etÂ al. (2024)</span>
<span class="ltx_bibblock">
Siyuan Guo, Cheng Deng, Ying Wen, Hechang Chen, YiÂ Chang, and Jun Wang.

</span>
<span class="ltx_bibblock">Ds-agent: Automated data science by empowering large language models
with case-based reasoning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">Forty-first International Conference on Machine Learning</em>,
2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Uesato etÂ al. (2022)</span>
<span class="ltx_bibblock">
Jonathan Uesato, Nate Kushman, Ramana Kumar, Francis Song, Noah Siegel, Lisa
Wang, Antonia Creswell, Geoffrey Irving, and Irina Higgins.

</span>
<span class="ltx_bibblock">Solving math word problems with process-and outcome-based feedback.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">arXiv preprint arXiv:2211.14275</em>, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Luo etÂ al. (2024)</span>
<span class="ltx_bibblock">
Liangchen Luo, Yinxiao Liu, Rosanne Liu, Samrat Phatale, Harsh Lara, Yunxuan
Li, Lei Shu, Yun Zhu, Lei Meng, Jiao Sun, etÂ al.

</span>
<span class="ltx_bibblock">Improve mathematical reasoning in language models by automated
process supervision.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">arXiv preprint arXiv:2406.06592</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen etÂ al. (2023)</span>
<span class="ltx_bibblock">
Weize Chen, Yusheng Su, Jingwei Zuo, Cheng Yang, Chenfei Yuan, Chi-Min Chan,
Heyang Yu, Yaxi Lu, Yi-Hsin Hung, Chen Qian, etÂ al.

</span>
<span class="ltx_bibblock">Agentverse: Facilitating multi-agent collaboration and exploring
emergent behaviors.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">The Twelfth International Conference on Learning
Representations</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2024a)</span>
<span class="ltx_bibblock">
Junyou Li, Qin Zhang, Yangbin Yu, Qiang Fu, and Deheng Ye.

</span>
<span class="ltx_bibblock">More agents is all you need.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2402.05120</em>, 2024a.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Apple (2024)</span>
<span class="ltx_bibblock">
Apple.

</span>
<span class="ltx_bibblock">Apple intelligence foundation language models, 2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2407.21075" title="">https://arxiv.org/abs/2407.21075</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2024b)</span>
<span class="ltx_bibblock">
Yuanchun Li, Hao Wen, Weijun Wang, Xiangyu Li, Yizhen Yuan, Guohong Liu,
Jiacheng Liu, Wenxing Xu, Xiang Wang, YiÂ Sun, Rui Kong, Yile Wang, Hanfei
Geng, Jian Luan, Xuefeng Jin, Zilong Ye, Guanjing Xiong, Fan Zhang, Xiang Li,
Mengwei Xu, Zhijun Li, Peng Li, Yang Liu, Ya-Qin Zhang, and Yunxin Liu.

</span>
<span class="ltx_bibblock">Personal llm agents: Insights and survey about the capability,
efficiency and security, 2024b.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2401.05459" title="">https://arxiv.org/abs/2401.05459</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2024c)</span>
<span class="ltx_bibblock">
Qingyao Li, Wei Xia, Kounianhua Du, Xinyi Dai, Ruiming Tang, Yasheng Wang, Yong
Yu, and Weinan Zhang.

</span>
<span class="ltx_bibblock">Rethinkmcts: Refining erroneous thoughts in monte carlo tree search
for code generation, 2024c.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://arxiv.org/abs/2409.09584" title="">https://arxiv.org/abs/2409.09584</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wen etÂ al. (2024)</span>
<span class="ltx_bibblock">
Muning Wen, Ziyu Wan, Weinan Zhang, Jun Wang, and Ying Wen.

</span>
<span class="ltx_bibblock">Reinforcing language agents via policy optimization with action
decomposition.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">arXiv preprint arXiv:2405.15821</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ji etÂ al. (2023)</span>
<span class="ltx_bibblock">
Jiaming Ji, Tianyi Qiu, Boyuan Chen, Borong Zhang, Hantao Lou, Kaile Wang,
Yawen Duan, Zhonghao He, Jiayi Zhou, Zhaowei Zhang, etÂ al.

</span>
<span class="ltx_bibblock">Ai alignment: A comprehensive survey.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:2310.19852</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dalrymple etÂ al. (2024)</span>
<span class="ltx_bibblock">
David Dalrymple, Joar Skalse, Yoshua Bengio, Stuart Russell, Max Tegmark,
Sanjit Seshia, Steve Omohundro, Christian Szegedy, Ben Goldhaber, Nora
Ammann, etÂ al.

</span>
<span class="ltx_bibblock">Towards guaranteed safe ai: A framework for ensuring robust and
reliable ai systems.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2405.06624</em>, 2024.

</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Sun Oct 13 03:43:58 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
