<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice</title>
<!--Generated on Thu Sep 12 02:37:16 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<meta content="" lang="en" name="keywords"/>
<base href="/html/2409.07713v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S1" title="In Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S2" title="In Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Prior Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S2.SS0.SSS0.Px1" title="In 2 Prior Work ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_title">Retrieval Augmented Generation.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S2.SS0.SSS0.Px2" title="In 2 Prior Work ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_title">Datasets and Legal AI Benchmarks.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S2.SS0.SSS0.Px3" title="In 2 Prior Work ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_title">Better Data for Better AI.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S2.SS0.SSS0.Px4" title="In 2 Prior Work ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_title">Automatic Evaluation.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S3" title="In Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Methods</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S3.SS0.SSS0.Px1" title="In 3 Methods ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_title">Retrieval Methods.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S3.SS0.SSS0.Px2" title="In 3 Methods ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_title">Generative Baselines.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S4" title="In Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results and Discussion</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S4.SS0.SSS0.Px1" title="In 4 Results and Discussion ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_title">Open-source models fall behind.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S4.SS0.SSS0.Px2" title="In 4 Results and Discussion ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_title">Using limited legal documents is just as useful as the entire internet.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S4.SS0.SSS0.Px3" title="In 4 Results and Discussion ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_title">GPT-4 outperforms retrieval.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S4.SS0.SSS0.Px4" title="In 4 Results and Discussion ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_title">Some categories of questions are more difficult to answer accurately.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S4.SS0.SSS0.Px5" title="In 4 Results and Discussion ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_title">In what situations does legal retrieval help?</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S4.SS1" title="In 4 Results and Discussion ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Future Directions</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S4.SS1.SSS0.Px1" title="In 4.1 Future Directions ‣ 4 Results and Discussion ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_title">Closing the gap between open-sourced and closed-sourced models.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S4.SS1.SSS0.Px2" title="In 4.1 Future Directions ‣ 4 Results and Discussion ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_title">Continual Updating.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_paragraph"><a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S4.SS1.SSS0.Px3" title="In 4.1 Future Directions ‣ 4 Results and Discussion ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_title">Unstructured Legal Data.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S4.SS2" title="In 4 Results and Discussion ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Conclusions</span></a></li>
</ol>
</li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_pruned_first">
<h1 class="ltx_title ltx_title_document">Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jonathan Li
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Rohan V Bhambhoria
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Samuel Dahan
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Xiaodan Zhu
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">Generative AI models, such as the GPT and Llama series, have significant potential to assist laypeople in answering legal questions. However, little prior work focuses on the data sourcing, inference, and evaluation of these models in the context of laypersons. To this end, we propose a <span class="ltx_text ltx_font_italic" id="id1.id1.1">human-centric</span> legal NLP pipeline, covering data sourcing, inference, and evaluation. We introduce and release a dataset, LegalQA, with real and specific legal questions spanning from employment law to criminal law, corresponding answers written by legal experts, and citations for each answer. We develop an automatic evaluation protocol for this dataset, then show that retrieval-augmented generation from only 850 citations in the train set can match or outperform internet-wide retrieval, despite containing 9 orders of magnitude less data. Finally, we propose future directions for open-sourced efforts, which fall behind closed-sourced models.</p>
</div>
<div class="ltx_keywords">
</div>
<div class="ltx_para" id="p2">
<br class="ltx_break"/>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Today, much of natural language processing rests on <span class="ltx_text ltx_font_italic" id="S1.p1.1.1">high-quality data</span>. Advances in unstructured data for pre-training have allowed general language models to be more lightweight, performant, and therefore accessible <cite class="ltx_cite ltx_citemacro_citep">(Abdin et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib1" title="">2024</a>; Team et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib32" title="">2024</a>)</cite>. Language models are promising in providing legal advice to laypeople, but prior work suggests that they struggle with hallucination <cite class="ltx_cite ltx_citemacro_citep">(Dahan et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib11" title="">2023</a>)</cite>. Inspired by the high-quality data that powers general domains, we identify a gap in high-quality structured legal data (e.g., question-answer pairs) approved by legal experts. In this work, we hope to build more <span class="ltx_text ltx_font_italic" id="S1.p1.1.2">human-centric legal AI</span> systems by improving the data source to address laypeople. We use this data at <span class="ltx_text ltx_font_italic" id="S1.p1.1.3">retrieval time</span> to improve model performance, which does not require additional training or fine-tuning.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">Little prior work focuses on optimizing legal AI systems from start to finish for factors that matter to laypeople. Among these factors are accessibility of the services due to cost, factual correctness, and ease of understanding. In this paper, we propose an end-to-end <span class="ltx_text ltx_font_italic" id="S1.p2.1.1">human-centeric legal AI</span> framework, which covers data sourcing, training/inference, and evaluation to improve these factors; importantly, we put laypeople first by ensuring each step of the process is backed by high-quality data from legal experts (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_tag">1</span></a>). To our knowledge, this type of <span class="ltx_text ltx_font_italic" id="S1.p2.1.2">human-centric legal framework</span> is the first of its kind.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">First, we construct a high-quality evaluation dataset of 323 questions asked by laypeople on real legal questions and answers vetted by legal experts. We ask law students to write expert answers to these questions and release this dataset to the public. Then, we develop an automatic evaluation protocol based on the <span class="ltx_text ltx_font_italic" id="S1.p3.1.1">factuality</span> of the generated answer, as a legal expert would. Inspired by massive improvements to model quality through higher quality data at <span class="ltx_text ltx_font_italic" id="S1.p3.1.2">training time</span> (e.g., Phi-3; <cite class="ltx_cite ltx_citemacro_citep">Abdin et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib1" title="">2024</a></cite>), we improve the data sourcing process at <span class="ltx_text ltx_font_italic" id="S1.p3.1.3">retrieval time</span>. Specifically, we propose domain-specific retrieval, bolstering the performance of existing LLMs on legal question-answering by retrieving from sources trusted by legal experts. We show that retrieval from under a thousand legal-expert-approved articles matches or exceeds the performance of retrieval from hundreds of millions of internet articles.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Overall, our contributions are as follows:</p>
</div>
<figure class="ltx_figure" id="S1.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="304" id="S1.F1.g1" src="x1.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S1.F1.2.1.1" style="font-size:90%;">Figure 1</span>: </span><span class="ltx_text" id="S1.F1.3.2" style="font-size:90%;">An overview of our framework for human-centric legal AI.</span></figcaption>
</figure>
<div class="ltx_para" id="S1.p5">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We construct a dataset containing real legal questions and high-quality answers labelled by legal experts. We release the evaluation dataset publically.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We create an evaluation protocol vetted by legal experts and find that existing models have room for improvement in factuality.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We show that domain-specific retrieval from relatively few sources trusted by legal experts can outperform existing non-retrieval models and match or exceed retrieval-augmented models that rely on the entirety of the internet.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Prior Work</h2>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Retrieval Augmented Generation.</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p1.1">Large language models often hallucinate and contain outdated information <cite class="ltx_cite ltx_citemacro_citep">(Zhang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib40" title="">2023</a>)</cite>. Retrieval augmented generation (RAG) is an emerging approach to reduce the prevalence of hallucinations by grounding a model’s generations in a data source besides the model’s weights. Retrieval has been used extensively in single-hop <cite class="ltx_cite ltx_citemacro_citep">(Ke et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib21" title="">2024</a>)</cite>, multi-hop <cite class="ltx_cite ltx_citemacro_citep">(Sun et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib31" title="">2023</a>)</cite>, and long-form open-ended question answering <cite class="ltx_cite ltx_citemacro_citep">(Lin et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib26" title="">2023</a>)</cite>. With the rise of instruction-following language models <cite class="ltx_cite ltx_citemacro_citep">(Touvron et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib33" title="">2023</a>; Chung et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib9" title="">2022</a>; Brown et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib6" title="">2020</a>)</cite>, retrieval methods often insert context directly into the context of the language model <cite class="ltx_cite ltx_citemacro_citep">(Ma et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib28" title="">2023</a>; Chen et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib8" title="">2023</a>)</cite>. We focus on this setting because it is possible to integrate with existing well-performing models (such as OpenAI’s GPT-3.5), further supporting our human-centric goal of making legal AI more accessible.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px1.p2.1">Very recently, commercial RAG efforts such as Cohere’s <span class="ltx_text ltx_font_typewriter" id="S2.SS0.SSS0.Px1.p2.1.1">Command R+</span> models, have been applied to legal domains with a focus on trustworthiness and data privacy <cite class="ltx_cite ltx_citemacro_citep">(Gainer &amp; Starostin, <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib15" title="">2024</a>)</cite>. Their retrieval method passes the retrieved documents directly into the context of a language model, such that the model generations are grounded in the context provided. In this work, we build off this line of research by focusing on retrieval from a trusted source.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Datasets and Legal AI Benchmarks.</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p1.1">NLP has been applied to various fields in law, such as question answering, relation extraction, or text summarization <cite class="ltx_cite ltx_citemacro_citep">(Zhong et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib42" title="">2020</a>)</cite>. Previously, work was focused on domain-specific fine-tuned models <cite class="ltx_cite ltx_citemacro_citep">(Chalkidis et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib7" title="">2020</a>; Zheng et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib41" title="">2021</a>)</cite>. Recently, existing work has focused more on the ability of <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px2.p1.1.1">general LLMs</span> to perform legal reasoning <cite class="ltx_cite ltx_citemacro_citep">(Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib38" title="">2022</a>; Jiang &amp; Yang, <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib20" title="">2023</a>; Blair-Stanek et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib5" title="">2023</a>; Yu et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib39" title="">2023</a>)</cite>. Regarding benchmarks for LLMs in legal applications, existing benchmarks exist in Chinese <cite class="ltx_cite ltx_citemacro_citep">(Duan et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib13" title="">2019</a>; Dai et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib12" title="">2024</a>)</cite> and American <cite class="ltx_cite ltx_citemacro_citep">(Guha et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib17" title="">2023</a>)</cite> law. However, many existing benchmarks lack evaluation of open-ended responses which are of interest to laypeople who ask language models for legal advice directly.</p>
</div>
<div class="ltx_para" id="S2.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S2.SS0.SSS0.Px2.p2.1">We source our legal questions from a public legal advice forum (though answers are written in-house by legal experts). These online forums have been used extensively as sources of data for machine learning. For instance, <cite class="ltx_cite ltx_citemacro_citet">Yao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib37" title="">2020</a>)</cite> uses data from a mental-health advice sub-community on Reddit (known as a “subreddit”) to detect suicidality in opioid users. <cite class="ltx_cite ltx_citemacro_citet">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib24" title="">2022</a>)</cite> uses the “r/legaladvice” subreddit for classification of Reddit posts in evaluation. We extend this work on forum-based data by considering a much more difficult task: generating a factually accurate legal answer to a given legal question.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Better Data for Better AI.</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px3.p1.1">Existing work has found that sourcing better data can lead to model improvements in the pretraining stage. <cite class="ltx_cite ltx_citemacro_citet">Eldan &amp; Li (<a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib14" title="">2023</a>)</cite> create a high-quality machine-generated dataset, then shows that very small models (order of tens of millions of parameters) can learn perfect grammar from this high-quality data. Taking this a step further, <cite class="ltx_cite ltx_citemacro_citet">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib25" title="">2023</a>)</cite> and <cite class="ltx_cite ltx_citemacro_citet">Gunasekar et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib18" title="">2023</a>)</cite> introduce the Phi series models, which gain impressive performance despite their small size, driven by high-quality data. Very recently, open-sourced state-of-the-art language models Llama 3 <cite class="ltx_cite ltx_citemacro_citep">(AI@Meta, <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib3" title="">2024</a>)</cite> and Phi-3 <cite class="ltx_cite ltx_citemacro_citep">(Abdin et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib1" title="">2024</a>)</cite> build off this idea, reaching state-of-the-art performance by improving data sourcing. Inspired by this work, we review a related but orthogonal direction: improving the reliability of data sourcing at <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px3.p1.1.1">retrieval time</span>, rather than just at <span class="ltx_text ltx_font_italic" id="S2.SS0.SSS0.Px3.p1.1.2">pre-training time</span> like in prior work.</p>
</div>
</section>
<section class="ltx_paragraph" id="S2.SS0.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Automatic Evaluation.</h4>
<div class="ltx_para" id="S2.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="S2.SS0.SSS0.Px4.p1.1">As LLMs become better at problem-solving, their potential to evaluate responses relative to a gold answer becomes increasingly attractive <cite class="ltx_cite ltx_citemacro_citep">(Oh et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib29" title="">2024</a>)</cite>. Current work has focused on evaluation of open-ended model generations for general domains, such as trivia question answering <cite class="ltx_cite ltx_citemacro_citep">(Wang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib34" title="">2023</a>)</cite> or everyday conversational settings <cite class="ltx_cite ltx_citemacro_citep">(Lin &amp; Chen, <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib27" title="">2023</a>)</cite>. In legal AI, however, most models are evaluated on closed-ended tasks that can be trivially graded <cite class="ltx_cite ltx_citemacro_citep">(Koniaris et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib22" title="">2023</a>; Xu &amp; Ashley, <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib36" title="">2023</a>; Savelka, <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib30" title="">2023</a>)</cite>. <cite class="ltx_cite ltx_citemacro_citet">Cui et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib10" title="">2023</a>)</cite> evaluates model generations using crowd-sourced human preference ratings in Chinese (with an ELO system), a step in evaluation for open-ended generations. <cite class="ltx_cite ltx_citemacro_citet">Bhambhoria et al. (<a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib4" title="">2024</a>)</cite> explores the possibility of automatic evaluation in the legal domain, showing that most classified samples align with the expert opinion. In this work, we aim to capitalize on the benefits of automatic evaluation while optimizing the process for legal factuality evaluation by consulting with legal experts.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methods</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">To build a source of structured and expert-approved legal data that is effective at <span class="ltx_text ltx_font_italic" id="S3.p1.1.1">retrieval time</span>, we construct a new dataset from real legal questions and ask law professors and law students to answer these questions. Then, we use this data during our retrieval process to ground model answers in citations vetted by legal experts. During the evaluation process, we also ground our evaluations with this dataset, establishing an end-to-end legal-expert-driven framework (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_tag">1</span></a>).</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">Specifically, we source questions from an online community<span class="ltx_note ltx_role_footnote" id="footnote1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.reddit.com/r/legaladvice/" title="">https://www.reddit.com/r/legaladvice/</a></span></span></span>, collected from January 2021 to October 2022. These questions are specific (e.g., Table <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S3.T2" title="Table 2 ‣ 3 Methods ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_tag">2</span></a>) situations that real laypeople have, not hypotheticals<span class="ltx_note ltx_role_footnote" id="footnote2"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>As per the legal advice community guidelines, the questions must be real questions, not hypothetical questions</span></span></span>. For instance, the example sample in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S3.T2" title="Table 2 ‣ 3 Methods ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_tag">2</span></a> outlines a specific scenario. This real-world focus allows our evaluations to be closer to a target domain that is helpful to laypeople. Then, we ask law professors and law students to provide golden answers to these questions. Since this research was done in Canada, the legal experts we worked with were knowledgeable primarily in Canadian law. Therefore, we asked these annotators to answer these legal questions according to Canadian law. Human answers are typically concise (shorter than the questions) and under 100 tokens (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S3.F2" title="Figure 2 ‣ 3 Methods ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_tag">2</span></a>). Each answer contains a citation with more information relevant to the question. To perform a rigorous performance analysis across legal areas of practice, we classify each question into six categories relevant to laypeople, shown in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S3.T1" title="Table 1 ‣ 3 Methods ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_tag">1</span></a>. The classification was done through a zero-shot classification approach <cite class="ltx_cite ltx_citemacro_citep">(Laurer et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib23" title="">2023</a>)</cite> and manually inspected for correctness. To aid the community in evaluating existing LLMs, we release our evaluation dataset (<math alttext="n=323" class="ltx_Math" display="inline" id="S3.p2.1.m1.1"><semantics id="S3.p2.1.m1.1a"><mrow id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml"><mi id="S3.p2.1.m1.1.1.2" xref="S3.p2.1.m1.1.1.2.cmml">n</mi><mo id="S3.p2.1.m1.1.1.1" xref="S3.p2.1.m1.1.1.1.cmml">=</mo><mn id="S3.p2.1.m1.1.1.3" xref="S3.p2.1.m1.1.1.3.cmml">323</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><apply id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1"><eq id="S3.p2.1.m1.1.1.1.cmml" xref="S3.p2.1.m1.1.1.1"></eq><ci id="S3.p2.1.m1.1.1.2.cmml" xref="S3.p2.1.m1.1.1.2">𝑛</ci><cn id="S3.p2.1.m1.1.1.3.cmml" type="integer" xref="S3.p2.1.m1.1.1.3">323</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">n=323</annotation><annotation encoding="application/x-llamapun" id="S3.p2.1.m1.1d">italic_n = 323</annotation></semantics></math>) publicly<span class="ltx_note ltx_role_footnote" id="footnote3"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://huggingface.co/datasets/jonathanli/law_qa_eval" title="">https://huggingface.co/datasets/jonathanli/law_qa_eval</a></span></span></span>.</p>
</div>
<figure class="ltx_table" id="S3.T1">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span class="ltx_text" id="S3.T1.2.1.1" style="font-size:90%;">Table 1</span>: </span><span class="ltx_text" id="S3.T1.3.2" style="font-size:90%;">Composition of the area of law for each question in our dataset.</span></figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T1.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T1.4.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_tt" id="S3.T1.4.1.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Category</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" id="S3.T1.4.1.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">Percent</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T1.4.2.1">
<td class="ltx_td ltx_align_left ltx_border_r ltx_border_t" id="S3.T1.4.2.1.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Employment and labour law</td>
<td class="ltx_td ltx_align_center ltx_border_t" id="S3.T1.4.2.1.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">27.9</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.3.2">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.4.3.2.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Family and juvenile law</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.3.2.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">27.1</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.4.3">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.4.4.3.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Real estate law</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.4.3.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">21.4</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.5.4">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.4.5.4.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Corporate law</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.5.4.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">9.2</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.6.5">
<td class="ltx_td ltx_align_left ltx_border_r" id="S3.T1.4.6.5.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Personal injury law</td>
<td class="ltx_td ltx_align_center" id="S3.T1.4.6.5.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">9.2</td>
</tr>
<tr class="ltx_tr" id="S3.T1.4.7.6">
<td class="ltx_td ltx_align_left ltx_border_bb ltx_border_r" id="S3.T1.4.7.6.1" style="padding-top:0.5pt;padding-bottom:0.5pt;">Civil rights law</td>
<td class="ltx_td ltx_align_center ltx_border_bb" id="S3.T1.4.7.6.2" style="padding-top:0.5pt;padding-bottom:0.5pt;">5.2</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="540" id="S3.F2.g1" src="x2.png" width="829"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F2.2.1.1" style="font-size:90%;">Figure 2</span>: </span><span class="ltx_text" id="S3.F2.3.2" style="font-size:90%;">Distribution of question lengths and response lengths. Responses are concise and specific.</span></figcaption>
</figure>
<figure class="ltx_table" id="S3.T2">
<figcaption class="ltx_caption ltx_centering" style="font-size:90%;"><span class="ltx_tag ltx_tag_table">Table 2: </span>Example question (“source”) and provided answers and citation.</figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S3.T2.4">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.T2.4.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S3.T2.4.1.1.1"><span class="ltx_text" id="S3.T2.4.1.1.1.1" style="font-size:90%;">Source</span></th>
<th class="ltx_td ltx_align_justify ltx_th ltx_th_column ltx_border_tt" id="S3.T2.4.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.4.1.1.2.1">
<span class="ltx_p" id="S3.T2.4.1.1.2.1.1"><span class="ltx_text" id="S3.T2.4.1.1.2.1.1.1" style="font-size:90%;">Father took family pet during divorce and probably will give him away.
My parents recently got a divorce a few months back and my father has been sending very disgusting harassing messages any way he can. He already has escapee warrants and now he is also getting more added to him due to his messages. He took the family dog who is legally under my mothers name and we know he is not safe with him. We have no idea where he is at but we know he is not a very safe person with our dog. We really fear of him giving the dog away to his friend and we wouldn’t see him ever again. What do we do if that’s the case? Can we fight to get him back if he gives him to his friend?</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.T2.4.2.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S3.T2.4.2.1.1"><span class="ltx_text" id="S3.T2.4.2.1.1.1" style="font-size:90%;">Answer</span></th>
<td class="ltx_td ltx_align_justify ltx_border_t" id="S3.T2.4.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.4.2.1.2.1">
<span class="ltx_p" id="S3.T2.4.2.1.2.1.1"><span class="ltx_text" id="S3.T2.4.2.1.2.1.1.1" style="font-size:90%;">In Ontario, dogs are considered personal property. In determining which spouse has a right to the dog, a court will consider ownership papers as well as several factors such as: Is the pet more bonded to one person over the other? Who can best provide continued care? Who paid for the pet?</span></span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="S3.T2.4.3.2">
<th class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb ltx_border_t" id="S3.T2.4.3.2.1"><span class="ltx_text" id="S3.T2.4.3.2.1.1" style="font-size:90%;">Citation</span></th>
<td class="ltx_td ltx_align_justify ltx_border_bb ltx_border_t" id="S3.T2.4.3.2.2">
<span class="ltx_inline-block ltx_align_top" id="S3.T2.4.3.2.2.1">
<span class="ltx_p" id="S3.T2.4.3.2.2.1.1"><span class="ltx_text ltx_font_typewriter" id="S3.T2.4.3.2.2.1.1.1" style="font-size:90%;">https://www.siskinds.com/pet-c ustody-laws-in-ontario</span></span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
<figure class="ltx_figure" id="S3.F3">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F3.sf1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="263" id="S3.F3.sf1.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F3.sf1.2.1.1" style="font-size:90%;">(a)</span> </span><span class="ltx_text" id="S3.F3.sf1.3.2" style="font-size:90%;">Internet-wide retrieval</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure class="ltx_figure ltx_figure_panel ltx_align_center" id="S3.F3.sf2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="263" id="S3.F3.sf2.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F3.sf2.4.1.1" style="font-size:90%;">(b)</span> </span><span class="ltx_text ltx_font_italic" id="S3.F3.sf2.5.2" style="font-size:90%;">Human-centric<span class="ltx_text ltx_font_upright" id="S3.F3.sf2.5.2.1"> legal retrieval <span class="ltx_text ltx_font_bold" id="S3.F3.sf2.5.2.1.1">(ours)</span></span></span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F3.2.1.1" style="font-size:90%;">Figure 3</span>: </span><span class="ltx_text" id="S3.F3.3.2" style="font-size:90%;">Retrieval-based methods used for our experiments. Given a legal question, retrieval is performed to generate a relevant answer.</span></figcaption>
</figure>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">Inspired by <cite class="ltx_cite ltx_citemacro_citet">Lin &amp; Chen (<a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib27" title="">2023</a>)</cite>, we employ human-grounded automatic evaluation of the generated answers. We use golden labels written by legal experts as ”grounding” for the language model, then ask the LLM (<span class="ltx_text ltx_font_typewriter" id="S3.p3.1.1">GPT-4-0613</span>) to rate the answer’s factuality relative to the expert answer. If there is a factual contradiction with the expert answer, we treat the model response as factually disagreeing. We run the automatic evaluator with a temperature of zero (since we only need the prediction ”factual” or ”not factual”). In our study, we minimize this factual disagreement to build factually accurate models. This approach is among the criteria that legal experts use to evaluate answers by law students <cite class="ltx_cite ltx_citemacro_citep">(Bhambhoria et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib4" title="">2024</a>)</cite>.</p>
</div>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Retrieval Methods.</h4>
<div class="ltx_para" id="S3.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p1.1">In addition to using existing language models to answer legal questions, we also consider grounding a model’s responses in the context of a relevant article. As previously discussed, we believe the retrieval process could also benefit from high-quality legal data. In this work, we try to retrieve from only trusted legal sources, as shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S3.F3.sf2" title="Figure 3(b) ‣ Figure 3 ‣ 3 Methods ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_tag">3(b)</span></a>. Since we split the dataset into a train and test set, we use the citations from the train set (<math alttext="n=850" class="ltx_Math" display="inline" id="S3.SS0.SSS0.Px1.p1.1.m1.1"><semantics id="S3.SS0.SSS0.Px1.p1.1.m1.1a"><mrow id="S3.SS0.SSS0.Px1.p1.1.m1.1.1" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.cmml"><mi id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.2" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml">n</mi><mo id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.1" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml">850</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS0.SSS0.Px1.p1.1.m1.1b"><apply id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1"><eq id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.1"></eq><ci id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.2.cmml" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.2">𝑛</ci><cn id="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3.cmml" type="integer" xref="S3.SS0.SSS0.Px1.p1.1.m1.1.1.3">850</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS0.SSS0.Px1.p1.1.m1.1c">n=850</annotation><annotation encoding="application/x-llamapun" id="S3.SS0.SSS0.Px1.p1.1.m1.1d">italic_n = 850</annotation></semantics></math>) as a set of trusted legal documents and only retrieve from these documents. This offers two main benefits: (a) the documents used by the model are known to be factual and helpful by legal experts, which is not the case for any document on the internet, and (b) searching a smaller subset of legal-expert-approved documents provides computational and storage benefits.</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px1.p2">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p2.1">As shown in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S3.F3.sf2" title="Figure 3(b) ‣ Figure 3 ‣ 3 Methods ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_tag">3(b)</span></a>, we embed both the context and the question using an existing state-of-the-art embedding model, <span class="ltx_text ltx_font_typewriter" id="S3.SS0.SSS0.Px1.p2.1.1">BAAI/bge-large-en-v1.5</span> <cite class="ltx_cite ltx_citemacro_citep">(Xiao et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib35" title="">2023</a>)</cite>. Then, we compute the dot product between the question and each document, selecting the document with the greatest dot product as the most relevant sample. Then we provide this document in the context of an existing language model (<span class="ltx_text ltx_font_typewriter" id="S3.SS0.SSS0.Px1.p2.1.2">GPT-3.5-turbo</span>), using prompts containing both the context and question. Unlike prior work, we evaluate retrieval from only legal expert sources rather than the entirety of the internet. This constitutes our model inference part in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_tag">1</span></a>. We call this ”legal retrieval”.</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px1.p3">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p3.1">As a baseline, we evaluate (a) GPT-3.5-turbo without retrieval augmented generation and (b) GPT-3.5-turbo with retrieval from the entire internet. For (b), we use a language model to produce a query for a legal question that can be queried for in a search engine (Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S3.F3.sf1" title="Figure 3(a) ‣ Figure 3 ‣ 3 Methods ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_tag">3(a)</span></a>). Then we use an existing web search engine (Google) to find the most relevant article and inject it into the context of the language model while answering this question. This article is used to provide context to the model. We call (b) ”internet retrieval”.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="367" id="S3.F4.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S3.F4.2.1.1" style="font-size:90%;">Figure 4</span>: </span><span class="ltx_text" id="S3.F4.3.2" style="font-size:90%;">Factual disagreement of each model by category. Lower is better.</span></figcaption>
</figure>
<div class="ltx_para" id="S3.SS0.SSS0.Px1.p4">
<p class="ltx_p" id="S3.SS0.SSS0.Px1.p4.1">Internet retrieval is not as simple as retrieval from only legal documents, since a Google search is performed. Search engines likely contain more sophisticated methods than a simple embedding similarity check. When evaluating the performance of retrieval from the entirety of the internet against retrieval from only legal documents, more computation occurs using an internet-wide search.</p>
</div>
</section>
<section class="ltx_paragraph" id="S3.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Generative Baselines.</h4>
<div class="ltx_para" id="S3.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p1.1">As a further baseline, we evaluate the state-of-the-art open-source models on this legal task. We use the state-of-the-art <span class="ltx_text ltx_font_typewriter" id="S3.SS0.SSS0.Px2.p1.1.1">Mixtral-8x7B</span> <cite class="ltx_cite ltx_citemacro_citep">(Jiang et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib19" title="">2024</a>)</cite> for non-retrieval generation and the state-of-the-art Cohere Command R+ model <cite class="ltx_cite ltx_citemacro_citep">(Aiden, <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib2" title="">2024</a>)</cite> for retrieval-augmented generation. We rely on Cohere’s pipeline for retrieval-augmented generation, whose model is purposefully tuned for this purpose.</p>
</div>
<div class="ltx_para" id="S3.SS0.SSS0.Px2.p2">
<p class="ltx_p" id="S3.SS0.SSS0.Px2.p2.1">For each method, we pass three samples from a separate train split as fewshot examples into the input prompt. We use the default generation and sampling settings (i.e., temperature and top-p) for each model.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results and Discussion</h2>
<figure class="ltx_figure" id="S4.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="505" id="S4.F5.g1" src="x6.png" width="829"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F5.2.1.1" style="font-size:90%;">Figure 5</span>: </span><span class="ltx_text" id="S4.F5.3.2" style="font-size:90%;">Factual disagreement for each model. “GPT-3.5 Legal” is retrieval using only legal documents, and “GPT-3.5 Internet” is retrieval from the entire internet.</span></figcaption>
</figure>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">As seen in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S4.F5" title="Figure 5 ‣ 4 Results and Discussion ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_tag">5</span></a>, the retrieval-based approaches tested typically perform better than their tested non-retrieval counterparts. Additionally, we make various observations:</p>
</div>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Open-source models fall behind.</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px1.p1.1">Mixtral-8x7B and Command R+, state-of-the-art open language models perform worse than current closed-source models. Future work should continue testing the newest state-of-the-art open-sourced models for this task. Though we recognize the importance of open-source models, we also note that practically, the inference costs associated with using open-sourced models are nonzero for a layperson. Therefore, closed-sourced models like GPT-3.5 are still appealing from a cost perspective compared to other open-sourced models.</p>
</div>
<figure class="ltx_figure" id="S4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="439" id="S4.F6.g1" src="x7.png" width="830"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span class="ltx_text" id="S4.F6.2.1.1" style="font-size:90%;">Figure 6</span>: </span><span class="ltx_text" id="S4.F6.3.2" style="font-size:90%;">Qualitative example showcasing retrieval from the entire internet and our high-quality source of legal documents. In this case, retrieval from the entire internet provides a less nuanced source of information.</span></figcaption>
</figure>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Using limited legal documents is just as useful as the entire internet.</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px2.p1.1">Retrieval from limited legal sources (just 850 documents) performs similarly to searching the entirety of the internet (hundreds of billions of documents). In the case of Cohere Command R+, a state-of-the-art enterprise retrieval system used in law <span class="ltx_note ltx_role_footnote" id="footnote4"><sup class="ltx_note_mark">4</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">4</sup><span class="ltx_tag ltx_tag_note">4</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://txt.cohere.com/how-llms-can-boost-legal-productivity-with-accuracy-and-privacy/" title="">https://txt.cohere.com/how-llms-can-boost-legal-productivity-with-accuracy-and-privacy/</a></span></span></span>, our simple retrieval method improves performance, despite Command R+ performing retrieval across the entire internet. The indexable internet contains more information than just our limited legal information, but the vastness of the space also make retrieval of documents much more difficult. Surprisingly, narrowing down the number of retrievable documents by 9 orders of magnitude<span class="ltx_note ltx_role_footnote" id="footnote5"><sup class="ltx_note_mark">5</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">5</sup><span class="ltx_tag ltx_tag_note">5</span>This was roughly calculated based on the “hundreds of billions” of pages that Google indexes <cite class="ltx_cite ltx_citemacro_citep">(Google, <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib16" title="">2023</a>)</cite> compared to our dataset of under a thousand samples.</span></span></span> retains enough information to perform similarly to retrieval from the entire internet. By reducing the number of documents that can possibly be retrieved, human-driven review of individual documents is more feasible, and storage and computational costs decrease.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">GPT-4 outperforms retrieval.</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px3.p1.1">We find that <span class="ltx_text ltx_font_typewriter" id="S4.SS0.SSS0.Px3.p1.1.1">gpt-4-turbo-1106</span> outperforms even retrieval models. However, we note that use of GPT-4 often has prohibitive costs (in some cases, 60x more), especially when paired with retrieval-augmented generations which span multiple contexts. Therefore, we still believe that relative improvements to GPT-3.5-turbo, a much more cost-effective model, continue to benefit the layperson despite the existence of more expensive and well-performing models.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px4">
<h4 class="ltx_title ltx_title_paragraph">Some categories of questions are more difficult to answer accurately.</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px4.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px4.p1.1">We find that some categories, such as “civil rights” and “real estate” are the most challenging for existing language models, illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S3.F4" title="Figure 4 ‣ Retrieval Methods. ‣ 3 Methods ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_tag">4</span></a>. Qualitatively, we observed that questions falling under these areas of law contained the most specific and personal questions, and also had more nuanced cases (e.g., a highly specific question about a tenant’s landlord).</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS0.SSS0.Px5">
<h4 class="ltx_title ltx_title_paragraph">In what situations does legal retrieval help?</h4>
<div class="ltx_para" id="S4.SS0.SSS0.Px5.p1">
<p class="ltx_p" id="S4.SS0.SSS0.Px5.p1.1">Apparent in Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S4.F6" title="Figure 6 ‣ Open-source models fall behind. ‣ 4 Results and Discussion ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_tag">6</span></a>, in some cases retrieval from the entire internet can provide a lack of nuanced information, making the response factually incorrect compared to retrieval from only vetted legal documents. In the specific example presented, the retrieved web article failed to capture nuance when describing the punishment for damaging a vehicle during a traffic infraction, while the retrieved legal article from a vetted legal source did.</p>
</div>
<div class="ltx_para" id="S4.SS0.SSS0.Px5.p2">
<p class="ltx_p" id="S4.SS0.SSS0.Px5.p2.1">Figure <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S3.F4" title="Figure 4 ‣ Retrieval Methods. ‣ 3 Methods ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_tag">4</span></a> shows the strengths and weaknesses of each approach by category. Using retrieval from our expert source of legal documents is almost always better than or similar to the performance of non-retrieval methods. Additionally, retrieval from vetted legal sources performs on par with or better than retrieval from the entire internet, except for “employment and labour” and “corporate” categories. Further experiments are required to investigate the cause of this disparity, though we hypothesize it is because these categories have questions that span a larger space of questions, implying that retrieval from the internet is more applicable.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Future Directions</h3>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px1">
<h4 class="ltx_title ltx_title_paragraph">Closing the gap between open-sourced and closed-sourced models.</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px1.p1.1">As shown in Section <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#S4" title="4 Results and Discussion ‣ Experimenting with Legal AI Solutions: The Case of Question-Answering for Access to Justice"><span class="ltx_text ltx_ref_tag">4</span></a>, the gap between the top open-sourced model and the closed-sourced models (<span class="ltx_text ltx_font_typewriter" id="S4.SS1.SSS0.Px1.p1.1.1">GPT-4</span>) is substantial. From the perspective of human-centric legal AI, this is problematic as these black-box models often lack accountability in their data sources, which is especially important in the legal domain <cite class="ltx_cite ltx_citemacro_citep">(Dahan et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib11" title="">2023</a>)</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px2">
<h4 class="ltx_title ltx_title_paragraph">Continual Updating.</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px2.p1.1">Laws and regulations constantly evolve, and legal AI systems need to stay up-to-date with the latest changes. Investigating techniques that can efficiently integrate new legal information and adapt models accordingly would better reflect the dynamic nature of the legal landscape. Currently, our methodology focuses on retrieving from a static set of documents, though the set of documents could be continually pruned and updated <cite class="ltx_cite ltx_citemacro_citep">(Bhambhoria et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib4" title="">2024</a>)</cite>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS1.SSS0.Px3">
<h4 class="ltx_title ltx_title_paragraph">Unstructured Legal Data.</h4>
<div class="ltx_para" id="S4.SS1.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS1.SSS0.Px3.p1.1">In this work, we focus on sourcing high-quality structured data for use during retrieval and evaluation. Expert involvement in the data selection process could extend to unstructured data during the pre-training phase for the legal domain, which has already shown promise in general domains <cite class="ltx_cite ltx_citemacro_citep">(Gunasekar et al., <a class="ltx_ref" href="https://arxiv.org/html/2409.07713v1#bib.bib18" title="">2023</a>)</cite>.</p>
</div>
</section>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Conclusions</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Towards the goal of building more accessible and human-centric legal AI, a high-quality novel dataset containing question-answer pairs was produced and publically released, addressing a previous lack of expert-involved structured data. Existing open-sourced and closed-sourced language models were evaluated using an automatic evaluation framework based on the factuality of answers. We found that retrieval from a small set of legal documents can match or outperform the performance of retrieval from the entire internet, despite requiring many orders of magnitude less data.</p>
</div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Abdin et al. (2024)</span>
<span class="ltx_bibblock">
Abdin, M., Jacobs, S. A., Awan, A. A., Aneja, J., Awadallah, A., Awadalla, H.,
Bach, N., Bahree, A., Bakhtiari, A., Behl, H., Benhaim, A., Bilenko, M.,
Bjorck, J., Bubeck, S., Cai, M., Mendes, C. C. T., Chen, W., Chaudhary, V.,
Chopra, P., Giorno, A. D., de Rosa, G., Dixon, M., Eldan, R., Iter, D., Garg,
A., Goswami, A., Gunasekar, S., Haider, E., Hao, J., Hewett, R. J., Huynh,
J., Javaheripi, M., Jin, X., Kauffmann, P., Karampatziakis, N., Kim, D.,
Khademi, M., Kurilenko, L., Lee, J. R., Lee, Y. T., Li, Y., Liang, C., Liu,
W., Lin, E., Lin, Z., Madan, P., Mitra, A., Modi, H., Nguyen, A., Norick, B.,
Patra, B., Perez-Becker, D., Portet, T., Pryzant, R., Qin, H., Radmilac, M.,
Rosset, C., Roy, S., Ruwase, O., Saarikivi, O., Saied, A., Salim, A.,
Santacroce, M., Shah, S., Shang, N., Sharma, H., Song, X., Tanaka, M., Wang,
X., Ward, R., Wang, G., Witte, P., Wyatt, M., Xu, C., Xu, J., Yadav, S.,
Yang, F., Yang, Z., Yu, D., Zhang, C., Zhang, C., Zhang, J., Zhang, L. L.,
Zhang, Y., Zhang, Y., Zhang, Y., and Zhou, X.

</span>
<span class="ltx_bibblock">Phi-3 technical report: A highly capable language model locally on
your phone, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Aiden (2024)</span>
<span class="ltx_bibblock">
Aiden, G.

</span>
<span class="ltx_bibblock">Introducing Command R+: A Scalable LLM Built for Business, Apr
2024.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://txt.cohere.com/command-r-plus-microsoft-azure/" title="">https://txt.cohere.com/command-r-plus-microsoft-azure/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">AI@Meta (2024)</span>
<span class="ltx_bibblock">
AI@Meta.

</span>
<span class="ltx_bibblock">Llama 3 model card.

</span>
<span class="ltx_bibblock">2024.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md" title="">https://github.com/meta-llama/llama3/blob/main/MODEL_CARD.md</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bhambhoria et al. (2024)</span>
<span class="ltx_bibblock">
Bhambhoria, R., Dahan, S., Li, J., and Zhu, X.

</span>
<span class="ltx_bibblock">Evaluating AI for Law: Bridging the Gap with Open-Source Solutions,
2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blair-Stanek et al. (2023)</span>
<span class="ltx_bibblock">
Blair-Stanek, A., Holzenberger, N., and Durme, B. V.

</span>
<span class="ltx_bibblock">Can GPT-3 Perform Statutory Reasoning?, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Brown et al. (2020)</span>
<span class="ltx_bibblock">
Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P.,
Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S.,
Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler,
D. M., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray,
S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever,
I., and Amodei, D.

</span>
<span class="ltx_bibblock">Language Models are Few-Shot Learners, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chalkidis et al. (2020)</span>
<span class="ltx_bibblock">
Chalkidis, I., Fergadiotis, M., Malakasiotis, P., Aletras, N., and
Androutsopoulos, I.

</span>
<span class="ltx_bibblock">LEGAL-BERT: The muppets straight out of law school.

</span>
<span class="ltx_bibblock">In Cohn, T., He, Y., and Liu, Y. (eds.), <em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Findings of the
Association for Computational Linguistics: EMNLP 2020</em>, pp.  2898–2904,
Online, November 2020. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.findings-emnlp.261</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2020.findings-emnlp.261" title="">https://aclanthology.org/2020.findings-emnlp.261</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chen et al. (2023)</span>
<span class="ltx_bibblock">
Chen, H.-T., Xu, F., Arora, S., and Choi, E.

</span>
<span class="ltx_bibblock">Understanding Retrieval Augmentation for Long-Form Question
Answering, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chung et al. (2022)</span>
<span class="ltx_bibblock">
Chung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, Y., Wang,
X., Dehghani, M., Brahma, S., Webson, A., Gu, S. S., Dai, Z., Suzgun, M.,
Chen, X., Chowdhery, A., Castro-Ros, A., Pellat, M., Robinson, K., Valter,
D., Narang, S., Mishra, G., Yu, A., Zhao, V., Huang, Y., Dai, A., Yu, H.,
Petrov, S., Chi, E. H., Dean, J., Devlin, J., Roberts, A., Zhou, D., Le,
Q. V., and Wei, J.

</span>
<span class="ltx_bibblock">Scaling Instruction-Finetuned Language Models, 2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cui et al. (2023)</span>
<span class="ltx_bibblock">
Cui, J., Li, Z., Yan, Y., Chen, B., and Yuan, L.

</span>
<span class="ltx_bibblock">ChatLaw: Open-Source Legal Large Language Model with Integrated
External Knowledge Bases.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">ArXiv</em>, abs/2306.16092, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://api.semanticscholar.org/CorpusID:259274889" title="">https://api.semanticscholar.org/CorpusID:259274889</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dahan et al. (2023)</span>
<span class="ltx_bibblock">
Dahan, S., Bhambhoria, R., Liang, D., and Zhu, X.

</span>
<span class="ltx_bibblock">Lawyers should not trust ai: A call for an open-source legal
language model.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">Available at SSRN 4587092</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Dai et al. (2024)</span>
<span class="ltx_bibblock">
Dai, Y., Feng, D., Huang, J., Jia, H., Xie, Q., Zhang, Y., Han, W., Tian, W.,
and Wang, H.

</span>
<span class="ltx_bibblock">LAiW: A Chinese Legal Large Language Models Benchmark, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Duan et al. (2019)</span>
<span class="ltx_bibblock">
Duan, X., Wang, B., Wang, Z., Ma, W., Cui, Y., Wu, D., Wang, S., Liu, T., Huo,
T., Hu, Z., Wang, H., and Liu, Z.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">CJRC: A Reliable Human-Annotated Benchmark DataSet for Chinese
Judicial Reading Comprehension</em>, pp.  439–451.

</span>
<span class="ltx_bibblock">Springer International Publishing, 2019.

</span>
<span class="ltx_bibblock">ISBN 9783030323813.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1007/978-3-030-32381-3˙36</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://dx.doi.org/10.1007/978-3-030-32381-3_36" title="">http://dx.doi.org/10.1007/978-3-030-32381-3_36</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Eldan &amp; Li (2023)</span>
<span class="ltx_bibblock">
Eldan, R. and Li, Y.

</span>
<span class="ltx_bibblock">Tinystories: How small can language models be and still speak
coherent english?, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gainer &amp; Starostin (2024)</span>
<span class="ltx_bibblock">
Gainer, R. and Starostin, K.

</span>
<span class="ltx_bibblock">How LLMs Can Boost Legal Productivity (with Accuracy and Privacy),
Apr 2024.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://cohere.com/blog/how-llms-can-boost-legal-productivity-with-accuracy-and-privacy" title="">https://cohere.com/blog/how-llms-can-boost-legal-productivity-with-accuracy-and-privacy</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Google (2023)</span>
<span class="ltx_bibblock">
Google.

</span>
<span class="ltx_bibblock">How google search organizes information, 2023.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.google.com/search/howsearchworks/how-search-works/organizing-information/" title="">https://www.google.com/search/howsearchworks/how-search-works/organizing-information/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Guha et al. (2023)</span>
<span class="ltx_bibblock">
Guha, N., Nyarko, J., Ho, D. E., Ré, C., Chilton, A., Narayana, A.,
Chohlas-Wood, A., Peters, A., Waldon, B., Rockmore, D. N., Zambrano, D.,
Talisman, D., Hoque, E., Surani, F., Fagan, F., Sarfaty, G., Dickinson,
G. M., Porat, H., Hegland, J., Wu, J., Nudell, J., Niklaus, J., Nay, J.,
Choi, J. H., Tobia, K., Hagan, M., Ma, M., Livermore, M., Rasumov-Rahe, N.,
Holzenberger, N., Kolt, N., Henderson, P., Rehaag, S., Goel, S., Gao, S.,
Williams, S., Gandhi, S., Zur, T., Iyer, V., and Li, Z.

</span>
<span class="ltx_bibblock">LegalBench: A Collaboratively Built Benchmark for Measuring Legal
Reasoning in Large Language Models, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gunasekar et al. (2023)</span>
<span class="ltx_bibblock">
Gunasekar, S., Zhang, Y., Aneja, J., Cesar, C., Mendes, T., Giorno, A. D.,
Gopi, S., Javaheripi, M., Kauffmann, P., de Rosa, G., Saarikivi, O., Salim,
A., Shah, S., Singh Behl, H., Wang, X., Bubeck, S., Eldan, R., Kalai, A. T.,
Lee, Y. T., and Li, Y.

</span>
<span class="ltx_bibblock">Textbooks are all you need, June 2023.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/" title="">https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. (2024)</span>
<span class="ltx_bibblock">
Jiang, A. Q., Sablayrolles, A., Roux, A., Mensch, A., Savary, B., Bamford, C.,
Chaplot, D. S., de las Casas, D., Hanna, E. B., Bressand, F., Lengyel, G.,
Bour, G., Lample, G., Lavaud, L. R., Saulnier, L., Lachaux, M.-A., Stock, P.,
Subramanian, S., Yang, S., Antoniak, S., Scao, T. L., Gervet, T., Lavril, T.,
Wang, T., Lacroix, T., and Sayed, W. E.

</span>
<span class="ltx_bibblock">Mixtral of experts, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang &amp; Yang (2023)</span>
<span class="ltx_bibblock">
Jiang, C. and Yang, X.

</span>
<span class="ltx_bibblock">Legal Syllogism Prompting: Teaching Large Language Models for Legal
Judgment Prediction.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Proceedings of the Nineteenth International Conference on
Artificial Intelligence and Law</em>, ICAIL ’23, pp.  417–421, New York, NY,
USA, 2023. Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 9798400701979.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3594536.3595170</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3594536.3595170" title="">https://doi.org/10.1145/3594536.3595170</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ke et al. (2024)</span>
<span class="ltx_bibblock">
Ke, Z., Kong, W., Li, C., Zhang, M., Mei, Q., and Bendersky, M.

</span>
<span class="ltx_bibblock">Bridging the Preference Gap between Retrievers and LLMs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2401.06954</em>, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Koniaris et al. (2023)</span>
<span class="ltx_bibblock">
Koniaris, M., Galanis, D., Giannini, E., and Tsanakas, P.

</span>
<span class="ltx_bibblock">Evaluation of Automatic Legal Text Summarization Techniques for
Greek Case Law.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Information</em>, 14(4), 2023.

</span>
<span class="ltx_bibblock">ISSN 2078-2489.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.3390/info14040250</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.mdpi.com/2078-2489/14/4/250" title="">https://www.mdpi.com/2078-2489/14/4/250</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Laurer et al. (2023)</span>
<span class="ltx_bibblock">
Laurer, M., van Atteveldt, W., Casas, A., and Welbers, K.

</span>
<span class="ltx_bibblock">Building Efficient Universal Classifiers with Natural
Language Inference, December 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://arxiv.org/abs/2312.17543" title="">http://arxiv.org/abs/2312.17543</a>.

</span>
<span class="ltx_bibblock">arXiv:2312.17543 [cs].

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2022)</span>
<span class="ltx_bibblock">
Li, J., Bhambhoria, R., and Zhu, X.

</span>
<span class="ltx_bibblock">Parameter-efficient legal domain adaptation.

</span>
<span class="ltx_bibblock">In Aletras, N., Chalkidis, I., Barrett, L.,
Goan<span class="ltx_ERROR undefined" id="bib.bib24.1.1">\textcommabelow</span>tă, C., and Preo<span class="ltx_ERROR undefined" id="bib.bib24.2.2">\textcommabelow</span>tiuc-Pietro,
D. (eds.), <em class="ltx_emph ltx_font_italic" id="bib.bib24.3.3">Proceedings of the Natural Legal Language Processing
Workshop 2022</em>, pp.  119–129, Abu Dhabi, United Arab Emirates (Hybrid),
December 2022. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2022.nllp-1.10</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.nllp-1.10" title="">https://aclanthology.org/2022.nllp-1.10</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023)</span>
<span class="ltx_bibblock">
Li, Y., Bubeck, S., Eldan, R., Giorno, A. D., Gunasekar, S., and Lee, Y. T.

</span>
<span class="ltx_bibblock">Textbooks are all you need ii: phi-1.5 technical report.

</span>
<span class="ltx_bibblock">September 2023.

</span>
<span class="ltx_bibblock">URL
<a class="ltx_ref ltx_url ltx_font_typewriter" href="https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need-ii-phi-1-5-technical-report/" title="">https://www.microsoft.com/en-us/research/publication/textbooks-are-all-you-need-ii-phi-1-5-technical-report/</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin et al. (2023)</span>
<span class="ltx_bibblock">
Lin, X. V., Chen, X., Chen, M., Shi, W., Lomeli, M., James, R., Rodriguez, P.,
Kahn, J., Szilvasy, G., Lewis, M., et al.

</span>
<span class="ltx_bibblock">RA-DIT: Retrieval-Augmented Dual Instruction Tuning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">The Twelfth International Conference on Learning
Representations</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin &amp; Chen (2023)</span>
<span class="ltx_bibblock">
Lin, Y.-T. and Chen, Y.-N.

</span>
<span class="ltx_bibblock">LLM-eval: Unified multi-dimensional automatic evaluation for
open-domain conversations with large language models.

</span>
<span class="ltx_bibblock">In Chen, Y.-N. and Rastogi, A. (eds.), <em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">Proceedings of the 5th
Workshop on NLP for Conversational AI (NLP4ConvAI 2023)</em>, pp.  47–58,
Toronto, Canada, July 2023. Association for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2023.nlp4convai-1.5</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.nlp4convai-1.5" title="">https://aclanthology.org/2023.nlp4convai-1.5</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ma et al. (2023)</span>
<span class="ltx_bibblock">
Ma, X., Gong, Y., He, P., Zhao, H., and Duan, N.

</span>
<span class="ltx_bibblock">Query rewriting in retrieval-augmented large language models.

</span>
<span class="ltx_bibblock">In Bouamor, H., Pino, J., and Bali, K. (eds.), <em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">Proceedings of
the 2023 Conference on Empirical Methods in Natural Language Processing</em>,
pp.  5303–5315, Singapore, December 2023. Association for Computational
Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2023.emnlp-main.322</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.emnlp-main.322" title="">https://aclanthology.org/2023.emnlp-main.322</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Oh et al. (2024)</span>
<span class="ltx_bibblock">
Oh, J., Kim, E., Cha, I., and Oh, A.

</span>
<span class="ltx_bibblock">The Generative AI Paradox on Evaluation: What It Can Solve, It May
Not Evaluate, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Savelka (2023)</span>
<span class="ltx_bibblock">
Savelka, J.

</span>
<span class="ltx_bibblock">Unlocking Practical Applications in Legal Domain: Evaluation of GPT
for Zero-Shot Semantic Annotation of Legal Texts.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib30.1.1">Proceedings of the Nineteenth International Conference on
Artificial Intelligence and Law</em>, ICAIL ’23, pp.  447–451, New York, NY,
USA, 2023. Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 9798400701979.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3594536.3595161</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3594536.3595161" title="">https://doi.org/10.1145/3594536.3595161</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sun et al. (2023)</span>
<span class="ltx_bibblock">
Sun, Z., Wang, X., Tay, Y., Yang, Y., and Zhou, D.

</span>
<span class="ltx_bibblock">Recitation-Augmented Language Models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib31.1.1">International Conference on Learning Representations</em>, 2023.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=-cqvvvb-NkI" title="">https://openreview.net/forum?id=-cqvvvb-NkI</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team et al. (2024)</span>
<span class="ltx_bibblock">
Team, G., Mesnard, T., Hardin, C., Dadashi, R., Bhupatiraju, S., Pathak, S.,
Sifre, L., Rivière, M., Kale, M. S., Love, J., Tafti, P., Hussenot, L.,
Sessa, P. G., Chowdhery, A., Roberts, A., Barua, A., Botev, A., Castro-Ros,
A., Slone, A., Héliou, A., Tacchetti, A., Bulanova, A., Paterson, A., Tsai,
B., Shahriari, B., Lan, C. L., Choquette-Choo, C. A., Crepy, C., Cer, D.,
Ippolito, D., Reid, D., Buchatskaya, E., Ni, E., Noland, E., Yan, G., Tucker,
G., Muraru, G.-C., Rozhdestvenskiy, G., Michalewski, H., Tenney, I.,
Grishchenko, I., Austin, J., Keeling, J., Labanowski, J., Lespiau, J.-B.,
Stanway, J., Brennan, J., Chen, J., Ferret, J., Chiu, J., Mao-Jones, J., Lee,
K., Yu, K., Millican, K., Sjoesund, L. L., Lee, L., Dixon, L., Reid, M.,
Mikuła, M., Wirth, M., Sharman, M., Chinaev, N., Thain, N., Bachem, O.,
Chang, O., Wahltinez, O., Bailey, P., Michel, P., Yotov, P., Chaabouni, R.,
Comanescu, R., Jana, R., Anil, R., McIlroy, R., Liu, R., Mullins, R., Smith,
S. L., Borgeaud, S., Girgin, S., Douglas, S., Pandya, S., Shakeri, S., De,
S., Klimenko, T., Hennigan, T., Feinberg, V., Stokowiec, W., hui Chen, Y.,
Ahmed, Z., Gong, Z., Warkentin, T., Peran, L., Giang, M., Farabet, C.,
Vinyals, O., Dean, J., Kavukcuoglu, K., Hassabis, D., Ghahramani, Z., Eck,
D., Barral, J., Pereira, F., Collins, E., Joulin, A., Fiedel, N., Senter, E.,
Andreev, A., and Kenealy, K.

</span>
<span class="ltx_bibblock">Gemma: Open models based on gemini research and technology, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib33">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Touvron et al. (2023)</span>
<span class="ltx_bibblock">
Touvron, H., Martin, L., Stone, K., Albert, P., Almahairi, A., Babaei, Y.,
Bashlykov, N., Batra, S., Bhargava, P., Bhosale, S., Bikel, D., Blecher, L.,
Ferrer, C. C., Chen, M., Cucurull, G., Esiobu, D., Fernandes, J., Fu, J., Fu,
W., Fuller, B., Gao, C., Goswami, V., Goyal, N., Hartshorn, A., Hosseini, S.,
Hou, R., Inan, H., Kardas, M., Kerkez, V., Khabsa, M., Kloumann, I., Korenev,
A., Koura, P. S., Lachaux, M.-A., Lavril, T., Lee, J., Liskovich, D., Lu, Y.,
Mao, Y., Martinet, X., Mihaylov, T., Mishra, P., Molybog, I., Nie, Y.,
Poulton, A., Reizenstein, J., Rungta, R., Saladi, K., Schelten, A., Silva,
R., Smith, E. M., Subramanian, R., Tan, X. E., Tang, B., Taylor, R.,
Williams, A., Kuan, J. X., Xu, P., Yan, Z., Zarov, I., Zhang, Y., Fan, A.,
Kambadur, M., Narang, S., Rodriguez, A., Stojnic, R., Edunov, S., and
Scialom, T.

</span>
<span class="ltx_bibblock">Llama 2: Open Foundation and Fine-Tuned Chat Models, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib34">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023)</span>
<span class="ltx_bibblock">
Wang, C., Cheng, S., Guo, Q., Yue, Y., Ding, B., Xu, Z., Wang, Y., Hu, X.,
Zhang, Z., and Zhang, Y.

</span>
<span class="ltx_bibblock">Evaluating Open-QA Evaluation, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib35">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao et al. (2023)</span>
<span class="ltx_bibblock">
Xiao, S., Liu, Z., Zhang, P., and Muennighoff, N.

</span>
<span class="ltx_bibblock">C-pack: Packaged resources to advance general chinese embedding,
2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib36">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xu &amp; Ashley (2023)</span>
<span class="ltx_bibblock">
Xu, H. and Ashley, K.

</span>
<span class="ltx_bibblock">Argumentative Segmentation Enhancement for Legal Summarization,
2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib37">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yao et al. (2020)</span>
<span class="ltx_bibblock">
Yao, H., Rashidian, S., Dong, X., Duanmu, H., Rosenthal, R. N., and Wang, F.

</span>
<span class="ltx_bibblock">Detection of suicidality among opioid users on reddit: machine
learning–based approach.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib37.1.1">Journal of medical internet research</em>, 22(11):e15293, 2020.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib38">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2022)</span>
<span class="ltx_bibblock">
Yu, F., Quartey, L., and Schilder, F.

</span>
<span class="ltx_bibblock">Legal Prompting: Teaching a Language Model to Think Like a Lawyer,
2022.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib39">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. (2023)</span>
<span class="ltx_bibblock">
Yu, F., Quartey, L., and Schilder, F.

</span>
<span class="ltx_bibblock">Exploring the effectiveness of prompt engineering for legal reasoning
tasks.

</span>
<span class="ltx_bibblock">In Rogers, A., Boyd-Graber, J., and Okazaki, N. (eds.),
<em class="ltx_emph ltx_font_italic" id="bib.bib39.1.1">Findings of the Association for Computational Linguistics: ACL 2023</em>,
pp.  13582–13596, Toronto, Canada, July 2023. Association for Computational
Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2023.findings-acl.858</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2023.findings-acl.858" title="">https://aclanthology.org/2023.findings-acl.858</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib40">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang et al. (2023)</span>
<span class="ltx_bibblock">
Zhang, Y., Li, Y., Cui, L., Cai, D., Liu, L., Fu, T., Huang, X., Zhao, E.,
Zhang, Y., Chen, Y., et al.

</span>
<span class="ltx_bibblock">Siren’s song in the AI ocean: a survey on hallucination in large
language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib40.1.1">arXiv preprint arXiv:2309.01219</em>, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib41">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al. (2021)</span>
<span class="ltx_bibblock">
Zheng, L., Guha, N., Anderson, B. R., Henderson, P., and Ho, D. E.

</span>
<span class="ltx_bibblock">When does pretraining help? assessing self-supervised learning for
law and the CaseHOLD dataset of 53,000+ legal holdings.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib41.1.1">Proceedings of the Eighteenth International Conference on
Artificial Intelligence and Law</em>, ICAIL ’21, pp.  159–168, New York, NY,
USA, 2021. Association for Computing Machinery.

</span>
<span class="ltx_bibblock">ISBN 9781450385268.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1145/3462757.3466088</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://doi.org/10.1145/3462757.3466088" title="">https://doi.org/10.1145/3462757.3466088</a>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib42">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhong et al. (2020)</span>
<span class="ltx_bibblock">
Zhong, H., Xiao, C., Tu, C., Zhang, T., Liu, Z., and Sun, M.

</span>
<span class="ltx_bibblock">How does NLP benefit legal system: A summary of legal artificial
intelligence.

</span>
<span class="ltx_bibblock">In Jurafsky, D., Chai, J., Schluter, N., and Tetreault, J. (eds.),
<em class="ltx_emph ltx_font_italic" id="bib.bib42.1.1">Proceedings of the 58th Annual Meeting of the Association for
Computational Linguistics</em>, pp.  5218–5230, Online, July 2020. Association
for Computational Linguistics.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.18653/v1/2020.acl-main.466</span>.

</span>
<span class="ltx_bibblock">URL <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2020.acl-main.466" title="">https://aclanthology.org/2020.acl-main.466</a>.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Sep 12 02:37:16 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
