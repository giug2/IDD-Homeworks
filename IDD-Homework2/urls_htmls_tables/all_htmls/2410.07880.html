<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Unsupervised Data Validation Methods for Efficient Model Training</title>
<!--Generated on Thu Oct 10 12:57:48 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2410.07880v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#S1" title="In Unsupervised Data Validation Methods for Efficient Model Training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#S2" title="In Unsupervised Data Validation Methods for Efficient Model Training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#S2.SS1" title="In 2 Related Work ‣ Unsupervised Data Validation Methods for Efficient Model Training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Data Scarcity Solutions for Low-Resource Languages</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#S2.SS2" title="In 2 Related Work ‣ Unsupervised Data Validation Methods for Efficient Model Training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Synthetic data</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#S2.SS3" title="In 2 Related Work ‣ Unsupervised Data Validation Methods for Efficient Model Training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Model Architecture Improvements and Computational Limits</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#S3" title="In Unsupervised Data Validation Methods for Efficient Model Training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Research Gaps</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#S3.SS0.SSS1" title="In 3 Research Gaps ‣ Unsupervised Data Validation Methods for Efficient Model Training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.0.1 </span>Question 1.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#S3.SS0.SSS2" title="In 3 Research Gaps ‣ Unsupervised Data Validation Methods for Efficient Model Training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.0.2 </span>Question 2.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#S3.SS0.SSS3" title="In 3 Research Gaps ‣ Unsupervised Data Validation Methods for Efficient Model Training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.0.3 </span>Question 3.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#S3.SS0.SSS4" title="In 3 Research Gaps ‣ Unsupervised Data Validation Methods for Efficient Model Training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.0.4 </span>Question 4.</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#S3.SS0.SSS5" title="In 3 Research Gaps ‣ Unsupervised Data Validation Methods for Efficient Model Training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.0.5 </span>Question 5.</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#S4" title="In Unsupervised Data Validation Methods for Efficient Model Training"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line"><span class="ltx_note ltx_role_institutetext" id="id1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">institutetext: </span>Ukrainian Catholic University
<br class="ltx_break"/><span class="ltx_note ltx_role_email" id="id1.1"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_note_type">email: </span>paniv@ucu.edu.ua</span></span></span>
<br class="ltx_break"/></span></span></span>
<h1 class="ltx_title ltx_title_document">Unsupervised Data Validation Methods for Efficient Model Training</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Yurii Paniv 
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id1.id1">This paper investigates the challenges and potential solutions for improving machine learning systems for low-resource languages. State-of-the-art models in natural language processing (NLP), text-to-speech (TTS), speech-to-text (STT), and vision-language models (VLM) rely heavily on large datasets, which are often unavailable for low-resource languages. This research explores key areas such as defining "quality data," developing methods for generating appropriate data and enhancing accessibility to model training. A comprehensive review of current methodologies, including data augmentation, multilingual transfer learning, synthetic data generation, and data selection techniques, highlights both advancements and limitations. Several open research questions are identified, providing a framework for future studies aimed at optimizing data utilization, reducing the required data quantity, and maintaining high-quality model performance. By addressing these challenges, the paper aims to make advanced machine learning models more accessible for low-resource languages, enhancing their utility and impact across various sectors.</p>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">State-of-the-art (SOTA) machine learning systems, particularly those utilized in natural language processing (NLP), text-to-speech (TTS) <cite class="ltx_cite ltx_citemacro_cite">Casanova <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib5" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite>, speech-to-text (STT) <cite class="ltx_cite ltx_citemacro_cite">Radford <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib24" title=""><span class="ltx_ERROR undefined">\APACyear</span>2023</a>)</cite>, and combined modalities models, like vision-language models (VLM) <cite class="ltx_cite ltx_citemacro_cite">Liu <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib15" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite>, depend heavily on large datasets to achieve optimal performance. However, low-resource languages face significant challenges due to the lack of extensive datasets. The collection of data for these languages is often impractical, too costly, or even unfeasible, especially in cases involving nearly extinct languages or those spoken by a very limited number of individuals.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">The prevalence of large language models (LLMs) in various applications underscores the data disparity issue. These models, which have become integral to NLP, TTS, STT, and VLM applications, require substantial quantities of training data.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">This context prompts several critical questions: What constitutes "quality data" necessary for effective model training? How can the appropriate type of data be generated? Furthermore, how can model training be made more accessible given these requirements?</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">Addressing these questions is crucial not only for advancing technical capabilities but also for broader economic and social impacts. Enhanced language tools can improve economic productivity by increasing the accessibility of technology. The current direction of research <cite class="ltx_cite ltx_citemacro_cite">Team (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib26" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite> and industry <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib21" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite> is in integrating multiple modalities, which have significant applications in fields such as robotics.</p>
</div>
<div class="ltx_para" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">This research proposal aims to investigate methods for optimizing data utilization, thereby reducing the quantity required while maintaining high-quality model performance. By tackling these issues, we seek to make advanced machine learning models more accessible for low-resource languages, thus enhancing their utility and impact across various sectors.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">This section reviews existing strategies and methodologies developed to address the challenges associated with data scarcity in low-resource languages, including data quality evaluation and modern methods to address them.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Data Scarcity Solutions for Low-Resource Languages</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">In addressing the challenges posed by low-resource languages, recent advancements in model architectures such as GPT-4o <cite class="ltx_cite ltx_citemacro_cite">OpenAI (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib21" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite> and Chameleon <cite class="ltx_cite ltx_citemacro_cite">Team (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib26" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite> have demonstrated superior performance compared to text-only language models. Additionally, models like LLava <cite class="ltx_cite ltx_citemacro_cite">Liu <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib15" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite> provide methods for extending large language models (LLMs) into the image modality, enhancing their applicability. However, the implementation of such models often requires massive datasets, as exemplified by the Whisper paper <cite class="ltx_cite ltx_citemacro_cite">Radford <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib24" title=""><span class="ltx_ERROR undefined">\APACyear</span>2023</a>)</cite>, in which authors trained a state-of-the-art speech recognition system on a vast corpus of weakly-labeled data, necessitating substantial resources not readily available to all researchers.
On the other hand, in <cite class="ltx_cite ltx_citemacro_cite">Pratap <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib23" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite> paper researchers explore how to train models for low-resource languages using multilingual transfer, enabling a single model capable of performing speech recognition on 1406 languages, addressing very low-resource languages in the process.</p>
</div>
<div class="ltx_para" id="S2.SS1.p2">
<p class="ltx_p" id="S2.SS1.p2.1">Various approaches have been proposed to address the data scarcity challenge in low-resource languages. <cite class="ltx_cite ltx_citemacro_cite">Hedderich <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib9" title=""><span class="ltx_ERROR undefined">\APACyear</span>2021</a>)</cite> discuss different approaches to how researchers tackle the problem of lack of data for low-resource languages, ranging from data augmentation, learning with noisy labels, transfer learning, domain-specific pertaining, and multilingual language models. <cite class="ltx_cite ltx_citemacro_cite">McKinzie <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib16" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite> describe their experience of building a multi-modal language model. They mix image-text data, text-only data, and visual instruction tuning data, showing a transfer from text-only knowledge to vision-language one. Another technique for compute-efficient data selection is described in <cite class="ltx_cite ltx_citemacro_cite">Ankner <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib2" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite>. The authors find that with a limited compute and data budget, one can filter data based on the perplexity of smaller-language model, leading to a 1.45x reduction in pretraining steps. Recent work like Llama 3 disproves a claim from Chinchilla’s paper about underperformance for small models <cite class="ltx_cite ltx_citemacro_cite">Meta (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib17" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite>, suggesting even better improvements for larger models for particular tasks.</p>
</div>
<div class="ltx_para" id="S2.SS1.p3">
<p class="ltx_p" id="S2.SS1.p3.1">Current literature contains a plethora of data selection methods.
<cite class="ltx_cite ltx_citemacro_cite">Northcutt <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib20" title=""><span class="ltx_ERROR undefined">\APACyear</span>2021</a>)</cite> explore the idea that current approaches to machine learning focus commonly on model predictions, not data. They present a method for dealing with noisy data, which can improve model performance substantially. A method is to estimate joint distribution between noisy and uncorrupted labels. Similarly, using a perplexity as filtering criteria, <cite class="ltx_cite ltx_citemacro_cite">Paniv <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib22" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite> discovered that finetuning on selected 20% of data provides the same performance improvement as training on the full dataset, data even providing performance improvements by selecting 60% as a threshold for filtering. This indicates that the model itself could assess the quality of the data and be used for data selection.
it isn’t limited to supervised learning: <cite class="ltx_cite ltx_citemacro_cite">Vo <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib29" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite>
use automatic data curation for self-supervised learning. Researchers were able to curate image and text data using unsupervised clustering approach, creating a balanced dataset across concepts using automated k-means iterations.
Unsupervised data curation was applied even more deeply in <cite class="ltx_cite ltx_citemacro_cite">Kaddour <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib12" title=""><span class="ltx_ERROR undefined">\APACyear</span>2023</a>)</cite>, where authors explored data selection methods during training, such as selective backdrop, but haven’t found any performance improvements. Another angle to attack this problem is removing social bias. It could be considered a data selection technique, especially in vision-language models. Researchers from Google describe how filtering social bias improved model performance by exposing hidden relations in models <cite class="ltx_cite ltx_citemacro_cite">Alabdulmohsin <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib1" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite>. Data selection could be even extended to "unlearn" the data <cite class="ltx_cite ltx_citemacro_cite">Sepahvand <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib25" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite>. This approach could be helpful for data validation purposes by "forgetting" the point which we would like to assess with the model.</p>
</div>
<div class="ltx_para" id="S2.SS1.p4">
<p class="ltx_p" id="S2.SS1.p4.1">Besides Llama 3, <cite class="ltx_cite ltx_citemacro_cite">Young <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib31" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite> train models for English and Chinese, but apply custom filtering rules, employing smaller models for filtering, like Quality Scorer, a classifier trained to recognize and favor pages, similar to Wikipedia in quality, Document Coherence Scorer and Safety Scorer, designed to remove undesirable content, clustering based filtering and simple ones like deduplication.</p>
</div>
<div class="ltx_para" id="S2.SS1.p5">
<p class="ltx_p" id="S2.SS1.p5.1">There are methods to perform filtering, but how to quantify an impact? <cite class="ltx_cite ltx_citemacro_cite">Blakeney <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib3" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite> describe a technique for evaluating the quality of a particular dataset on model performance by appending it to the end of the training and measuring it on downstream benchmarks, providing a FLOPS-efficient way to estimate the quality of data (given enough compute is available for pretraining). There are other works, like <cite class="ltx_cite ltx_citemacro_cite">Covert <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib6" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite>, where researchers test the impact of individual datapoints on model training and provide a method for evaluating that impact, but, unfortunately, it could be not used for data selection.</p>
</div>
<div class="ltx_para" id="S2.SS1.p6">
<p class="ltx_p" id="S2.SS1.p6.1">Another thing to consider is data contamination. <cite class="ltx_cite ltx_citemacro_cite">Blevins <span class="ltx_ERROR undefined">\BBA</span> Zettlemoyer (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib4" title=""><span class="ltx_ERROR undefined">\APACyear</span>2022</a>)</cite> investigate origins of cross-lingual capabilities of large language models, finding that there are a lot of non-English data present in those datasets, helping explain the transfer of knowledge from one language to another. This finding affirms that multilingual training, even with such a small mixture, could transfer capabilities from one language to another. <cite class="ltx_cite ltx_citemacro_cite">Udandarao <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib27" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite> complete this point of view, finding that "zero-shot" capabilities of multi-modal models have a direct relationship with the appearance of that concept in a training dataset. This implies that in the context of low-resource languages, a need for new architecture or adding a mixture of English data to have a transfer of that performance to low-resource language.</p>
</div>
<div class="ltx_para" id="S2.SS1.p7">
<p class="ltx_p" id="S2.SS1.p7.1">However, with every technique applied, researchers should be cautious. As shown in <cite class="ltx_cite ltx_citemacro_cite">Goyal <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib8" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite>, there are scaling laws for data filtering. Researchers discovered that LAION filtering leads to worse downstream performance than training a vision transformer on the unfiltered dataset. As a conclusion, no data cleaning methods should be applied blindly with an expectation of improved performance.</p>
</div>
<div class="ltx_para" id="S2.SS1.p8">
<p class="ltx_p" id="S2.SS1.p8.1">One of the other promising approaches is tokenizer transfer <cite class="ltx_cite ltx_citemacro_cite">Minixhofer <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib19" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite>. This work indicates a promising research direction to improve model tokenization, and, subsequently, compression, and will lead to performance improvement and enable transfer learning to a new language.</p>
</div>
<div class="ltx_para" id="S2.SS1.p9">
<p class="ltx_p" id="S2.SS1.p9.1">In <cite class="ltx_cite ltx_citemacro_cite">Team (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib26" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite> researchers show that adding an additional vision modality contributes to performance improvements on downstream tasks, even for text-only tasks. We can assume that this would help train low-resource languages more efficiently and serve as a call to train combined modalities models for those languages.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Synthetic data</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Synthetic data is data that has been generated using a purpose-built mathematical model or algorithm, with the aim of solving a (set of ) data
science task(s) <cite class="ltx_cite ltx_citemacro_cite">Jordon <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib11" title=""><span class="ltx_ERROR undefined">\APACyear</span>2022</a>)</cite>. In the scope of this paper, synthetic data is generated using large language models and used for further training. They are used to improve model performance without gathering additional data. For example, <cite class="ltx_cite ltx_citemacro_cite">Lee <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib14" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite> describes a pipeline of how to augment data for small dataset for specific task by asking teacher LM to generate synthetic data based on incorrect data points, improving performance on more challenging examples. This could be used for low-resource languages to improve performance with that small amount of data. Another approach is demonstrated in <cite class="ltx_cite ltx_citemacro_cite">Yuan <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib32" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite>, where authors present a method to improve model capabilities by a round of self-improvements using Llama 2 70B model, finding a limit of 3 iterations that can improve model performance. This is a promising way for low-resource languages to improve its training data, and it would be interesting to test it in a multi-modal fashion.</p>
</div>
<div class="ltx_para" id="S2.SS2.p2">
<p class="ltx_p" id="S2.SS2.p2.1">Additionally, there is a demonstrated capability of cross-modal models to self-improve <cite class="ltx_cite ltx_citemacro_cite">Wang <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib30" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite>. Using self-critic approach, they were able to improve model performance on vision-language hallucination benchmarks, improving alignment between images and corresponding captions, potentially improving performance in low-resource settings. Self-improving is quite popular, for example, for training Llama 3, SOTA large language model, data was generated from Llama 2 for text-quality classifiers <cite class="ltx_cite ltx_citemacro_cite">Meta (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib17" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite>, pushing a new boundary for the performance of open source models.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Model Architecture Improvements and Computational Limits</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">According to <cite class="ltx_cite ltx_citemacro_cite">Godey <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib7" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite>, there is a need for sufficiently large models to address optimization bottlenecks. The authors argue that even with the best data selection algorithms, new models and methods are necessary to enhance downstream performance.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1"><cite class="ltx_cite ltx_citemacro_cite">Huang <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib10" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite> indicate that the downstream performance of models is almost linearly related to the efficiency of the model’s ability to compress information. This suggests a need for improved compression algorithms and advancements in tokenization techniques.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Research Gaps</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Even though LLMs are a hot area of research, there are a number of questions that, to the best of my knowledge, don’t currently have an answer in existing literature.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS0.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.0.1 </span>Question 1.</h4>
<div class="ltx_para" id="S3.SS0.SSS1.p1">
<p class="ltx_p" id="S3.SS0.SSS1.p1.1">What is a formal definition of low-resource language?
There is no formal definition of what is a "low-resource language". The most cited work from <cite class="ltx_cite ltx_citemacro_cite">Hedderich <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib9" title=""><span class="ltx_ERROR undefined">\APACyear</span>2021</a>)</cite> defines this term as "availability of datasets per specific task", but there is no overview available of which languages are low-resource and what is a threshold to cross from low-resource to medium-resource to high-resource language.
Can we define what is a threshold (resources needed) to cross to medium-resource and high-resource? As a part of my PhD work, I would like to clarify that issue and give certainty to that definition.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS0.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.0.2 </span>Question 2.</h4>
<div class="ltx_para" id="S3.SS0.SSS2.p1">
<p class="ltx_p" id="S3.SS0.SSS2.p1.1">How can we assess the validity of a specific datapoint to select it for training? As described in the "Related works" section, there are plenty of ways to assess that impact. As part of my PhD work, it would be crucial to make an overview of data selection methods and their impact on downstream performance.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS0.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.0.3 </span>Question 3.</h4>
<div class="ltx_para" id="S3.SS0.SSS3.p1">
<p class="ltx_p" id="S3.SS0.SSS3.p1.1">What methods are available for data selection and data cleaning and what is their impact on training multimodal language models? Providing an overview of these methods and their impact on downstream performance would be beneficial for other researchers to use for their training regimes.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS0.SSS4">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.0.4 </span>Question 4.</h4>
<div class="ltx_para" id="S3.SS0.SSS4.p1">
<p class="ltx_p" id="S3.SS0.SSS4.p1.1">How to validate performance on downstream tasks in low-resource languages? Quite commonly, low-resource languages lack human-created benchmarks, having only a common like machine translation, so it would be, in some cases, the only measure to track. In some cases, there is unlabeled data, and efforts to fix this like Bible TTS <cite class="ltx_cite ltx_citemacro_cite">Meyer <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib18" title=""><span class="ltx_ERROR undefined">\APACyear</span>2022</a>)</cite> to create new labeled datasets for low-resource languages. The lack of benchmarks is addressed in <cite class="ltx_cite ltx_citemacro_cite">Pratap <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib23" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite>, where researchers create benchmarks for low-resource languages by themselves using newly extracted data. I argue for unsupervised methods that can preprocess and create such kinds of datasets automatically.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS0.SSS5">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.0.5 </span>Question 5.</h4>
<div class="ltx_para" id="S3.SS0.SSS5.p1">
<p class="ltx_p" id="S3.SS0.SSS5.p1.1">Extending to additional modalities such as audio, images, or even videos can improve downstream performance for low-resource languages <cite class="ltx_cite ltx_citemacro_cite">Team (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib26" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite>. How to construct such a multimodal dataset for model to perform for low-resource languages in unsupervised manner? Even with datasets available, as we show in <cite class="ltx_cite ltx_citemacro_cite">Paniv <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib22" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite>, most of the dataset could be discarded without a degradation of performance, even improving it. Ukrainian is considered a low-resource language, but taking into account vast quantities of unlabelled multimodal data, such as Ukrainika <cite class="ltx_cite ltx_citemacro_cite">Ukrainika (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib28" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite> library, which contains nearly 34 TB of books, there is a case to use that data to improve language understanding. The pros and cons of this approach should be measured on downstream tasks as described in Question 4. Additionally, to track knowledge transfer across modalities, we should set an experiment to test this explicitly, for example, present a concept that would be explained only in speech modality (like prosody which could impact meaning of a sentence) or image modality (like the Visual Word Sense Disambiguation benchmark <cite class="ltx_cite ltx_citemacro_cite">Laba <span class="ltx_ERROR undefined">\BOthers</span>. (<a class="ltx_ref" href="https://arxiv.org/html/2410.07880v1#bib.bib13" title=""><span class="ltx_ERROR undefined">\APACyear</span>2024</a>)</cite>).</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Conclusion</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">In this paper, I investigated the significant challenges and potential solutions for training large language models for low-resource languages. The reliance on large datasets for training state-of-the-art models in natural language processing (NLP), text-to-speech (TTS), speech-to-text (STT), and vision-language models (VLM) is well-established. However, the scarcity of data for low-resource languages presents a substantial barrier to achieving optimal performance in these systems.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">The research highlighted several critical areas, including defining "quality data," developing methods for generating appropriate data and making model training more accessible. These issues are crucial for advancing both the technical capabilities and the socio-economic impacts of language technologies. Enhanced language tools can improve economic productivity, increase accessibility, and facilitate the creation of robust and diverse datasets, which are essential for integrating multiple modalities in future technologies, particularly in robotics.</p>
</div>
<div class="ltx_para" id="S4.p3">
<p class="ltx_p" id="S4.p3.1">The review of related work underscored advancements and limitations in current methodologies. Various strategies such as data augmentation, multilingual transfer learning, data selection, and synthetic data generation have been proposed to address data scarcity. Notably, synthetic data and self-improvement mechanisms, as demonstrated in models like LLaMa and Chameleon, offer promising directions for enhancing model performance with limited data.</p>
</div>
<div class="ltx_para" id="S4.p4">
<p class="ltx_p" id="S4.p4.1">Several open research questions were identified to guide future studies. These include defining what constitutes a low-resource language, validating performance on downstream tasks, constructing multimodal datasets, assessing data validity, and evaluating the impact of data selection and cleaning methods. These questions aim to provide a comprehensive framework for advancing research in this area and developing more effective machine learning models for low-resource languages.</p>
</div>
<div class="ltx_para" id="S4.p5">
<p class="ltx_p" id="S4.p5.1">In conclusion, this research proposal aims to optimize data utilization for model training, reduce the quantity required, and maintain high-quality model performance. By addressing these challenges, advanced machine learning models would be more accessible for low-resource languages. Continued exploration and development of innovative solutions will be crucial in bridging the data disparity gap and advancing the capabilities of machine learning systems globally. Last but not least, better performance with limited data should have downstream effects on high-resource languages such as English, enabling researchers to use less data for training and, subsequently, iterate faster to create new model architectures.</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Alabdulmohsin <span class="ltx_ERROR undefined" id="bib.bib1.4.4.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib1.5.5.2">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib1.6.1">\APACinsertmetastar</span>alabdulmohsin2024clip<span class="ltx_ERROR undefined" id="bib.bib1.7.2">{APACrefauthors}</span>Alabdulmohsin, I., Wang, X., Steiner, A<span class="ltx_ERROR undefined" id="bib.bib1.8.3">\BPBI</span>P., Goyal, P., D’Amour, A.<span class="ltx_ERROR undefined" id="bib.bib1.9.4">\BCBL</span> <span class="ltx_ERROR undefined" id="bib.bib1.10.5">\BBA</span> Zhai, X. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib1.11.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib1.12.1">\BBOQ</span><span class="ltx_ERROR undefined" id="bib.bib1.13.2">\APACrefatitle</span>CLIP the Bias: How Useful is Balancing Data in Multimodal Learning? CLIP the bias: How useful is balancing data in multimodal learning?<span class="ltx_ERROR undefined" id="bib.bib1.14.3">\BBCQ</span>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib1.15.1">\BIn</span> <span class="ltx_ERROR undefined" id="bib.bib1.16.2">\APACrefbtitle</span>The Twelfth International Conference on Learning Representations. The twelfth international conference on learning representations.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib1.17.1">{APACrefURL}</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=FIGXAxr9E4" title="">https://openreview.net/forum?id=FIGXAxr9E4</a>
<span class="ltx_ERROR undefined" id="bib.bib1.18.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib1.19.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ankner <span class="ltx_ERROR undefined" id="bib.bib2.4.4.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib2.5.5.2">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib2.6.1">\APACinsertmetastar</span>ankner2024perplexed<span class="ltx_ERROR undefined" id="bib.bib2.7.2">{APACrefauthors}</span>Ankner, Z., Blakeney, C., Sreenivasan, K., Marion, M., Leavitt, M<span class="ltx_ERROR undefined" id="bib.bib2.8.3">\BPBI</span>L.<span class="ltx_ERROR undefined" id="bib.bib2.9.4">\BCBL</span> <span class="ltx_ERROR undefined" id="bib.bib2.10.5">\BBA</span> Paul, M. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib2.11.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib2.12.1">\APACrefbtitle</span>Perplexed by Perplexity: Perplexity-Based Data Pruning With Small Reference Models. Perplexed by perplexity: Perplexity-based data pruning with small reference models.
<span class="ltx_ERROR undefined" id="bib.bib2.13.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib2.14.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blakeney <span class="ltx_ERROR undefined" id="bib.bib3.5.5.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib3.6.6.2">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib3.7.1">\APACinsertmetastar</span>blakeney2024does<span class="ltx_ERROR undefined" id="bib.bib3.8.2">{APACrefauthors}</span>Blakeney, C., Paul, M., Larsen, B<span class="ltx_ERROR undefined" id="bib.bib3.9.3">\BPBI</span>W., Owen, S.<span class="ltx_ERROR undefined" id="bib.bib3.10.4">\BCBL</span> <span class="ltx_ERROR undefined" id="bib.bib3.11.5">\BBA</span> Frankle, J. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib3.12.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib3.13.1">\BBOQ</span><span class="ltx_ERROR undefined" id="bib.bib3.14.2">\APACrefatitle</span>Does your data spark joy? Performance gains from domain upsampling at the end of training Does your data spark joy? performance gains from domain upsampling at the end of training.<span class="ltx_ERROR undefined" id="bib.bib3.15.3">\BBCQ</span>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib3.16.1">\APACjournalVolNumPages</span>arXiv e-printsarXiv–2406.
<span class="ltx_ERROR undefined" id="bib.bib3.17.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib3.18.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Blevins <span class="ltx_ERROR undefined" id="bib.bib4.4.4.1">\BBA</span> Zettlemoyer (<span class="ltx_ERROR undefined" id="bib.bib4.5.5.2">\APACyear</span>2022)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib4.6.1">\APACinsertmetastar</span>blevins-zettlemoyer-2022-language<span class="ltx_ERROR undefined" id="bib.bib4.7.2">{APACrefauthors}</span>Blevins, T.<span class="ltx_ERROR undefined" id="bib.bib4.8.3">\BCBT</span> <span class="ltx_ERROR undefined" id="bib.bib4.9.4">\BBA</span> Zettlemoyer, L. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib4.10.1">\APACrefYearMonthDay</span>2022<span class="ltx_ERROR undefined" id="bib.bib4.11.2">\APACmonth</span>12.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib4.12.1">\BBOQ</span><span class="ltx_ERROR undefined" id="bib.bib4.13.2">\APACrefatitle</span>Language Contamination Helps Explains the Cross-lingual Capabilities of English Pretrained Models Language contamination helps explains the cross-lingual capabilities of English pretrained models.<span class="ltx_ERROR undefined" id="bib.bib4.14.3">\BBCQ</span>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib4.15.1">\BIn</span> Y. Goldberg, Z. Kozareva<span class="ltx_ERROR undefined" id="bib.bib4.16.2">\BCBL</span> <span class="ltx_ERROR undefined" id="bib.bib4.17.3">\BBA</span> Y. Zhang (<span class="ltx_ERROR undefined" id="bib.bib4.18.4">\BEDS</span>), <span class="ltx_ERROR undefined" id="bib.bib4.19.5">\APACrefbtitle</span>Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing Proceedings of the 2022 conference on empirical methods in natural language processing (<span class="ltx_ERROR undefined" id="bib.bib4.20.6">\BPGS</span> 3563–3574).

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib4.21.1">\APACaddressPublisher</span>Abu Dhabi, United Arab EmiratesAssociation for Computational Linguistics.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib4.22.1">{APACrefURL}</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2022.emnlp-main.233" title="">https://aclanthology.org/2022.emnlp-main.233</a>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib4.23.1">{APACrefDOI}</span> <span class="ltx_ERROR undefined" id="bib.bib4.24.2">\doi</span>10.18653/v1/2022.emnlp-main.233 
<span class="ltx_ERROR undefined" id="bib.bib4.25.3">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib4.26.4">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Casanova <span class="ltx_ERROR undefined" id="bib.bib5.4.4.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib5.5.5.2">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib5.6.1">\APACinsertmetastar</span>casanova2024xtts<span class="ltx_ERROR undefined" id="bib.bib5.7.2">{APACrefauthors}</span>Casanova, E., Davis, K., Gölge, E., Göknar, G., Gulea, I., Hart, L.<span class="ltx_ERROR undefined" id="bib.bib5.8.3">\BDBL</span>Weber, J. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib5.9.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib5.10.1">\APACrefbtitle</span>XTTS: a Massively Multilingual Zero-Shot Text-to-Speech Model. Xtts: a massively multilingual zero-shot text-to-speech model.
<span class="ltx_ERROR undefined" id="bib.bib5.11.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib5.12.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Covert <span class="ltx_ERROR undefined" id="bib.bib6.5.5.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib6.6.6.2">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib6.7.1">\APACinsertmetastar</span>covert2024scaling<span class="ltx_ERROR undefined" id="bib.bib6.8.2">{APACrefauthors}</span>Covert, I<span class="ltx_ERROR undefined" id="bib.bib6.9.3">\BPBI</span>C., Ji, W., Hashimoto, T.<span class="ltx_ERROR undefined" id="bib.bib6.10.4">\BCBL</span> <span class="ltx_ERROR undefined" id="bib.bib6.11.5">\BBA</span> Zou, J. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib6.12.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib6.13.1">\BBOQ</span><span class="ltx_ERROR undefined" id="bib.bib6.14.2">\APACrefatitle</span>Scaling Laws for the Value of Individual Data Points in Machine Learning Scaling laws for the value of individual data points in machine learning.<span class="ltx_ERROR undefined" id="bib.bib6.15.3">\BBCQ</span>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib6.16.1">\BIn</span> <span class="ltx_ERROR undefined" id="bib.bib6.17.2">\APACrefbtitle</span>Forty-first International Conference on Machine Learning. Forty-first international conference on machine learning.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib6.18.1">{APACrefURL}</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openreview.net/forum?id=scSB9RynSd" title="">https://openreview.net/forum?id=scSB9RynSd</a>
<span class="ltx_ERROR undefined" id="bib.bib6.19.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib6.20.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Godey <span class="ltx_ERROR undefined" id="bib.bib7.5.5.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib7.6.6.2">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib7.7.1">\APACinsertmetastar</span>godey2024small<span class="ltx_ERROR undefined" id="bib.bib7.8.2">{APACrefauthors}</span>Godey, N., de la Clergerie, É.<span class="ltx_ERROR undefined" id="bib.bib7.9.3">\BCBL</span> <span class="ltx_ERROR undefined" id="bib.bib7.10.4">\BBA</span> Sagot, B. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib7.11.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib7.12.1">\BBOQ</span><span class="ltx_ERROR undefined" id="bib.bib7.13.2">\APACrefatitle</span>Why do small language models underperform? Studying Language Model Saturation via the Softmax Bottleneck Why do small language models underperform? studying language model saturation via the softmax bottleneck.<span class="ltx_ERROR undefined" id="bib.bib7.14.3">\BBCQ</span>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib7.15.1">\APACjournalVolNumPages</span>arXiv preprint arXiv:2404.07647.
<span class="ltx_ERROR undefined" id="bib.bib7.16.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib7.17.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Goyal <span class="ltx_ERROR undefined" id="bib.bib8.5.5.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib8.6.6.2">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib8.7.1">\APACinsertmetastar</span>goyal2024scaling<span class="ltx_ERROR undefined" id="bib.bib8.8.2">{APACrefauthors}</span>Goyal, S., Maini, P., Lipton, Z<span class="ltx_ERROR undefined" id="bib.bib8.9.3">\BPBI</span>C., Raghunathan, A.<span class="ltx_ERROR undefined" id="bib.bib8.10.4">\BCBL</span> <span class="ltx_ERROR undefined" id="bib.bib8.11.5">\BBA</span> Kolter, J<span class="ltx_ERROR undefined" id="bib.bib8.12.6">\BPBI</span>Z. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib8.13.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib8.14.1">\BBOQ</span><span class="ltx_ERROR undefined" id="bib.bib8.15.2">\APACrefatitle</span>Scaling Laws for Data Filtering–Data Curation cannot be Compute Agnostic Scaling laws for data filtering–data curation cannot be compute agnostic.<span class="ltx_ERROR undefined" id="bib.bib8.16.3">\BBCQ</span>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib8.17.1">\APACjournalVolNumPages</span>arXiv preprint arXiv:2404.07177.
<span class="ltx_ERROR undefined" id="bib.bib8.18.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib8.19.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hedderich <span class="ltx_ERROR undefined" id="bib.bib9.5.5.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib9.6.6.2">\APACyear</span>2021)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib9.7.1">\APACinsertmetastar</span>hedderich-etal-2021-survey<span class="ltx_ERROR undefined" id="bib.bib9.8.2">{APACrefauthors}</span>Hedderich, M<span class="ltx_ERROR undefined" id="bib.bib9.9.3">\BPBI</span>A., Lange, L., Adel, H., Strötgen, J.<span class="ltx_ERROR undefined" id="bib.bib9.10.4">\BCBL</span> <span class="ltx_ERROR undefined" id="bib.bib9.11.5">\BBA</span> Klakow, D. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib9.12.1">\APACrefYearMonthDay</span>2021<span class="ltx_ERROR undefined" id="bib.bib9.13.2">\APACmonth</span>06.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib9.14.1">\BBOQ</span><span class="ltx_ERROR undefined" id="bib.bib9.15.2">\APACrefatitle</span>A Survey on Recent Approaches for Natural Language Processing in Low-Resource Scenarios A survey on recent approaches for natural language processing in low-resource scenarios.<span class="ltx_ERROR undefined" id="bib.bib9.16.3">\BBCQ</span>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib9.17.1">\BIn</span> K. Toutanova <span class="ltx_ERROR undefined" id="bib.bib9.18.2">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib9.19.3">\BEDS</span>), <span class="ltx_ERROR undefined" id="bib.bib9.20.4">\APACrefbtitle</span>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies Proceedings of the 2021 conference of the north american chapter of the association for computational linguistics: Human language technologies (<span class="ltx_ERROR undefined" id="bib.bib9.21.5">\BPGS</span> 2545–2568).

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib9.22.1">\APACaddressPublisher</span>OnlineAssociation for Computational Linguistics.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib9.23.1">{APACrefURL}</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2021.naacl-main.201" title="">https://aclanthology.org/2021.naacl-main.201</a>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib9.24.1">{APACrefDOI}</span> <span class="ltx_ERROR undefined" id="bib.bib9.25.2">\doi</span>10.18653/v1/2021.naacl-main.201 
<span class="ltx_ERROR undefined" id="bib.bib9.26.3">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib9.27.4">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Huang <span class="ltx_ERROR undefined" id="bib.bib10.5.5.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib10.6.6.2">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib10.7.1">\APACinsertmetastar</span>huang2024compression<span class="ltx_ERROR undefined" id="bib.bib10.8.2">{APACrefauthors}</span>Huang, Y., Zhang, J., Shan, Z.<span class="ltx_ERROR undefined" id="bib.bib10.9.3">\BCBL</span> <span class="ltx_ERROR undefined" id="bib.bib10.10.4">\BBA</span> He, J. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib10.11.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib10.12.1">\BBOQ</span><span class="ltx_ERROR undefined" id="bib.bib10.13.2">\APACrefatitle</span>Compression represents intelligence linearly Compression represents intelligence linearly.<span class="ltx_ERROR undefined" id="bib.bib10.14.3">\BBCQ</span>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib10.15.1">\APACjournalVolNumPages</span>arXiv preprint arXiv:2404.09937.
<span class="ltx_ERROR undefined" id="bib.bib10.16.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib10.17.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jordon <span class="ltx_ERROR undefined" id="bib.bib11.4.4.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib11.5.5.2">\APACyear</span>2022)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib11.6.1">\APACinsertmetastar</span>jordon2022synthetic<span class="ltx_ERROR undefined" id="bib.bib11.7.2">{APACrefauthors}</span>Jordon, J., Szpruch, L., Houssiau, F., Bottarelli, M., Cherubin, G., Maple, C.<span class="ltx_ERROR undefined" id="bib.bib11.8.3">\BDBL</span>Weller, A. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib11.9.1">\APACrefYearMonthDay</span>2022.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib11.10.1">\BBOQ</span><span class="ltx_ERROR undefined" id="bib.bib11.11.2">\APACrefatitle</span>Synthetic Data–what, why and how? Synthetic data–what, why and how?<span class="ltx_ERROR undefined" id="bib.bib11.12.3">\BBCQ</span>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib11.13.1">\APACjournalVolNumPages</span>arXiv preprint arXiv:2205.03257.
<span class="ltx_ERROR undefined" id="bib.bib11.14.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib11.15.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kaddour <span class="ltx_ERROR undefined" id="bib.bib12.5.5.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib12.6.6.2">\APACyear</span>2023)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib12.7.1">\APACinsertmetastar</span>NEURIPS2023_51f3d625<span class="ltx_ERROR undefined" id="bib.bib12.8.2">{APACrefauthors}</span>Kaddour, J., Key, O., Nawrot, P., Minervini, P.<span class="ltx_ERROR undefined" id="bib.bib12.9.3">\BCBL</span> <span class="ltx_ERROR undefined" id="bib.bib12.10.4">\BBA</span> Kusner, M<span class="ltx_ERROR undefined" id="bib.bib12.11.5">\BPBI</span>J. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib12.12.1">\APACrefYearMonthDay</span>2023.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib12.13.1">\BBOQ</span><span class="ltx_ERROR undefined" id="bib.bib12.14.2">\APACrefatitle</span>No Train No Gain: Revisiting Efficient Training Algorithms For Transformer-based Language Models No train no gain: Revisiting efficient training algorithms for transformer-based language models.<span class="ltx_ERROR undefined" id="bib.bib12.15.3">\BBCQ</span>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib12.16.1">\BIn</span> A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt<span class="ltx_ERROR undefined" id="bib.bib12.17.2">\BCBL</span> <span class="ltx_ERROR undefined" id="bib.bib12.18.3">\BBA</span> S. Levine (<span class="ltx_ERROR undefined" id="bib.bib12.19.4">\BEDS</span>), <span class="ltx_ERROR undefined" id="bib.bib12.20.5">\APACrefbtitle</span>Advances in Neural Information Processing Systems Advances in neural information processing systems (<span class="ltx_ERROR undefined" id="bib.bib12.21.6">\BVOL</span> 36, <span class="ltx_ERROR undefined" id="bib.bib12.22.7">\BPGS</span> 25793–25818).

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib12.23.1">\APACaddressPublisher</span>Curran Associates, Inc.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib12.24.1">{APACrefURL}</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://proceedings.neurips.cc/paper_files/paper/2023/file/51f3d6252706100325ddc435ba0ade0e-Paper-Conference.pdf" title="">https://proceedings.neurips.cc/paper_files/paper/2023/file/51f3d6252706100325ddc435ba0ade0e-Paper-Conference.pdf</a>
<span class="ltx_ERROR undefined" id="bib.bib12.25.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib12.26.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Laba <span class="ltx_ERROR undefined" id="bib.bib13.4.4.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib13.5.5.2">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib13.6.1">\APACinsertmetastar</span>laba2024ukrainian<span class="ltx_ERROR undefined" id="bib.bib13.7.2">{APACrefauthors}</span>Laba, Y., Mohytych, Y., Rohulia, I., Kyryleyza, H., Dydyk-Meush, H., Dobosevych, O.<span class="ltx_ERROR undefined" id="bib.bib13.8.3">\BCBL</span> <span class="ltx_ERROR undefined" id="bib.bib13.9.4">\BBA</span> Hryniv, R. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib13.10.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib13.11.1">\BBOQ</span><span class="ltx_ERROR undefined" id="bib.bib13.12.2">\APACrefatitle</span>Ukrainian Visual Word Sense Disambiguation Benchmark Ukrainian visual word sense disambiguation benchmark.<span class="ltx_ERROR undefined" id="bib.bib13.13.3">\BBCQ</span>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib13.14.1">\BIn</span> <span class="ltx_ERROR undefined" id="bib.bib13.15.2">\APACrefbtitle</span>Proceedings of the Third Ukrainian Natural Language Processing Workshop (UNLP)@ LREC-COLING 2024 Proceedings of the third ukrainian natural language processing workshop (unlp)@ lrec-coling 2024 (<span class="ltx_ERROR undefined" id="bib.bib13.16.3">\BPGS</span> 61–66).
<span class="ltx_ERROR undefined" id="bib.bib13.17.4">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib13.18.5">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee <span class="ltx_ERROR undefined" id="bib.bib14.4.4.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib14.5.5.2">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib14.6.1">\APACinsertmetastar</span>lee2024llm2llm<span class="ltx_ERROR undefined" id="bib.bib14.7.2">{APACrefauthors}</span>Lee, N., Wattanawong, T., Kim, S., Mangalam, K., Shen, S., Anumanchipali, G.<span class="ltx_ERROR undefined" id="bib.bib14.8.3">\BDBL</span>Gholami, A. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib14.9.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib14.10.1">\BBOQ</span><span class="ltx_ERROR undefined" id="bib.bib14.11.2">\APACrefatitle</span>LLM2LLM: Boosting LLMs with Novel Iterative Data Enhancement Llm2llm: Boosting llms with novel iterative data enhancement.<span class="ltx_ERROR undefined" id="bib.bib14.12.3">\BBCQ</span>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib14.13.1">\APACjournalVolNumPages</span>arXiv preprint arXiv:2403.15042.
<span class="ltx_ERROR undefined" id="bib.bib14.14.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib14.15.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu <span class="ltx_ERROR undefined" id="bib.bib15.5.5.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib15.6.6.2">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib15.7.1">\APACinsertmetastar</span>liu2024visual<span class="ltx_ERROR undefined" id="bib.bib15.8.2">{APACrefauthors}</span>Liu, H., Li, C., Wu, Q.<span class="ltx_ERROR undefined" id="bib.bib15.9.3">\BCBL</span> <span class="ltx_ERROR undefined" id="bib.bib15.10.4">\BBA</span> Lee, Y<span class="ltx_ERROR undefined" id="bib.bib15.11.5">\BPBI</span>J. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib15.12.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib15.13.1">\BBOQ</span><span class="ltx_ERROR undefined" id="bib.bib15.14.2">\APACrefatitle</span>Visual instruction tuning Visual instruction tuning.<span class="ltx_ERROR undefined" id="bib.bib15.15.3">\BBCQ</span>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib15.16.1">\APACjournalVolNumPages</span>Advances in neural information processing systems36.
<span class="ltx_ERROR undefined" id="bib.bib15.17.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib15.18.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McKinzie <span class="ltx_ERROR undefined" id="bib.bib16.4.4.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib16.5.5.2">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib16.6.1">\APACinsertmetastar</span>mckinzie2024mm1<span class="ltx_ERROR undefined" id="bib.bib16.7.2">{APACrefauthors}</span>McKinzie, B., Gan, Z., Fauconnier, J<span class="ltx_ERROR undefined" id="bib.bib16.8.3">\BHBI</span>P., Dodge, S., Zhang, B., Dufter, P.<span class="ltx_ERROR undefined" id="bib.bib16.9.4">\BDBL</span>Yang, Y. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib16.10.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib16.11.1">\APACrefbtitle</span>MM1: Methods, Analysis &amp; Insights from Multimodal LLM Pre-training. Mm1: Methods, analysis &amp; insights from multimodal llm pre-training.
<span class="ltx_ERROR undefined" id="bib.bib16.12.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib16.13.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meta (<span class="ltx_ERROR undefined" id="bib.bib17.2.2.1">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib17.3.1">\APACinsertmetastar</span>metaIntroducingMeta<span class="ltx_ERROR undefined" id="bib.bib17.4.2">{APACrefauthors}</span>Meta. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib17.5.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib17.6.1">\APACrefbtitle</span>Introducing Meta Llama 3: The most capable openly available LLM to date — ai.meta.com. Introducing Meta Llama 3: The most capable openly available LLM to date — ai.meta.com.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib17.7.1">\APAChowpublished</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://ai.meta.com/blog/meta-llama-3/" title="">https://ai.meta.com/blog/meta-llama-3/</a>.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib17.8.1">\APACrefnote</span>[Accessed 11-06-2024]
<span class="ltx_ERROR undefined" id="bib.bib17.9.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib17.10.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Meyer <span class="ltx_ERROR undefined" id="bib.bib18.4.4.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib18.5.5.2">\APACyear</span>2022)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib18.6.1">\APACinsertmetastar</span>meyer2022bibletts<span class="ltx_ERROR undefined" id="bib.bib18.7.2">{APACrefauthors}</span>Meyer, J., Adelani, D<span class="ltx_ERROR undefined" id="bib.bib18.8.3">\BPBI</span>I., Casanova, E., Öktem, A., Weber, D<span class="ltx_ERROR undefined" id="bib.bib18.9.4">\BPBI</span>W<span class="ltx_ERROR undefined" id="bib.bib18.10.5">\BPBI</span>J., Kabongo, S.<span class="ltx_ERROR undefined" id="bib.bib18.11.6">\BDBL</span>others 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib18.12.1">\APACrefYearMonthDay</span>2022.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib18.13.1">\BBOQ</span><span class="ltx_ERROR undefined" id="bib.bib18.14.2">\APACrefatitle</span>Bibletts: a large, high-fidelity, multilingual, and uniquely african speech corpus Bibletts: a large, high-fidelity, multilingual, and uniquely african speech corpus.<span class="ltx_ERROR undefined" id="bib.bib18.15.3">\BBCQ</span>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib18.16.1">\APACjournalVolNumPages</span>arXiv preprint arXiv:2207.03546.
<span class="ltx_ERROR undefined" id="bib.bib18.17.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib18.18.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Minixhofer <span class="ltx_ERROR undefined" id="bib.bib19.5.5.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib19.6.6.2">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib19.7.1">\APACinsertmetastar</span>minixhofer2024zero<span class="ltx_ERROR undefined" id="bib.bib19.8.2">{APACrefauthors}</span>Minixhofer, B., Ponti, E<span class="ltx_ERROR undefined" id="bib.bib19.9.3">\BPBI</span>M.<span class="ltx_ERROR undefined" id="bib.bib19.10.4">\BCBL</span> <span class="ltx_ERROR undefined" id="bib.bib19.11.5">\BBA</span> Vulić, I. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib19.12.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib19.13.1">\BBOQ</span><span class="ltx_ERROR undefined" id="bib.bib19.14.2">\APACrefatitle</span>Zero-Shot Tokenizer Transfer Zero-shot tokenizer transfer.<span class="ltx_ERROR undefined" id="bib.bib19.15.3">\BBCQ</span>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib19.16.1">\APACjournalVolNumPages</span>arXiv preprint arXiv:2405.07883.
<span class="ltx_ERROR undefined" id="bib.bib19.17.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib19.18.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Northcutt <span class="ltx_ERROR undefined" id="bib.bib20.5.5.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib20.6.6.2">\APACyear</span>2021)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib20.7.1">\APACinsertmetastar</span>northcutt2021confident<span class="ltx_ERROR undefined" id="bib.bib20.8.2">{APACrefauthors}</span>Northcutt, C., Jiang, L.<span class="ltx_ERROR undefined" id="bib.bib20.9.3">\BCBL</span> <span class="ltx_ERROR undefined" id="bib.bib20.10.4">\BBA</span> Chuang, I. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib20.11.1">\APACrefYearMonthDay</span>2021.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib20.12.1">\BBOQ</span><span class="ltx_ERROR undefined" id="bib.bib20.13.2">\APACrefatitle</span>Confident learning: Estimating uncertainty in dataset labels Confident learning: Estimating uncertainty in dataset labels.<span class="ltx_ERROR undefined" id="bib.bib20.14.3">\BBCQ</span>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib20.15.1">\APACjournalVolNumPages</span>Journal of Artificial Intelligence Research701373–1411.
<span class="ltx_ERROR undefined" id="bib.bib20.16.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib20.17.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">OpenAI (<span class="ltx_ERROR undefined" id="bib.bib21.2.2.1">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib21.3.1">\APACinsertmetastar</span>openai2024gpt4o<span class="ltx_ERROR undefined" id="bib.bib21.4.2">{APACrefauthors}</span>OpenAI. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib21.5.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib21.6.1">\APACrefbtitle</span>Hello GPT-4o. Hello GPT-4o.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib21.7.1">\APAChowpublished</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="https://openai.com/index/hello-gpt-4o/" title="">https://openai.com/index/hello-gpt-4o/</a>.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib21.8.1">\APACrefnote</span>[Accessed 12-06-2024]
<span class="ltx_ERROR undefined" id="bib.bib21.9.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib21.10.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paniv <span class="ltx_ERROR undefined" id="bib.bib22.5.5.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib22.6.6.2">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib22.7.1">\APACinsertmetastar</span>paniv-etal-2024-setting<span class="ltx_ERROR undefined" id="bib.bib22.8.2">{APACrefauthors}</span>Paniv, Y., Chaplynskyi, D., Trynus, N.<span class="ltx_ERROR undefined" id="bib.bib22.9.3">\BCBL</span> <span class="ltx_ERROR undefined" id="bib.bib22.10.4">\BBA</span> Kyrylov, V. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib22.11.1">\APACrefYearMonthDay</span>2024<span class="ltx_ERROR undefined" id="bib.bib22.12.2">\APACmonth</span>05.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib22.13.1">\BBOQ</span><span class="ltx_ERROR undefined" id="bib.bib22.14.2">\APACrefatitle</span>Setting up the Data Printer with Improved English to Ukrainian Machine Translation Setting up the data printer with improved English to Ukrainian machine translation.<span class="ltx_ERROR undefined" id="bib.bib22.15.3">\BBCQ</span>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib22.16.1">\BIn</span> M. Romanyshyn, N. Romanyshyn, A. Hlybovets<span class="ltx_ERROR undefined" id="bib.bib22.17.2">\BCBL</span> <span class="ltx_ERROR undefined" id="bib.bib22.18.3">\BBA</span> O. Ignatenko (<span class="ltx_ERROR undefined" id="bib.bib22.19.4">\BEDS</span>), <span class="ltx_ERROR undefined" id="bib.bib22.20.5">\APACrefbtitle</span>Proceedings of the Third Ukrainian Natural Language Processing Workshop (UNLP) @ LREC-COLING 2024 Proceedings of the third ukrainian natural language processing workshop (unlp) @ lrec-coling 2024 (<span class="ltx_ERROR undefined" id="bib.bib22.21.6">\BPGS</span> 41–50).

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib22.22.1">\APACaddressPublisher</span>Torino, ItaliaELRA and ICCL.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib22.23.1">{APACrefURL}</span> <a class="ltx_ref ltx_url ltx_font_typewriter" href="https://aclanthology.org/2024.unlp-1.6" title="">https://aclanthology.org/2024.unlp-1.6</a>
<span class="ltx_ERROR undefined" id="bib.bib22.24.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib22.25.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Pratap <span class="ltx_ERROR undefined" id="bib.bib23.4.4.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib23.5.5.2">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib23.6.1">\APACinsertmetastar</span>pratap2024scaling<span class="ltx_ERROR undefined" id="bib.bib23.7.2">{APACrefauthors}</span>Pratap, V., Tjandra, A., Shi, B., Tomasello, P., Babu, A., Kundu, S.<span class="ltx_ERROR undefined" id="bib.bib23.8.3">\BDBL</span>others 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib23.9.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib23.10.1">\BBOQ</span><span class="ltx_ERROR undefined" id="bib.bib23.11.2">\APACrefatitle</span>Scaling speech technology to 1,000+ languages Scaling speech technology to 1,000+ languages.<span class="ltx_ERROR undefined" id="bib.bib23.12.3">\BBCQ</span>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib23.13.1">\APACjournalVolNumPages</span>Journal of Machine Learning Research25971–52.
<span class="ltx_ERROR undefined" id="bib.bib23.14.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib23.15.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Radford <span class="ltx_ERROR undefined" id="bib.bib24.4.4.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib24.5.5.2">\APACyear</span>2023)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib24.6.1">\APACinsertmetastar</span>radford2023robust<span class="ltx_ERROR undefined" id="bib.bib24.7.2">{APACrefauthors}</span>Radford, A., Kim, J<span class="ltx_ERROR undefined" id="bib.bib24.8.3">\BPBI</span>W., Xu, T., Brockman, G., McLeavey, C.<span class="ltx_ERROR undefined" id="bib.bib24.9.4">\BCBL</span> <span class="ltx_ERROR undefined" id="bib.bib24.10.5">\BBA</span> Sutskever, I. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib24.11.1">\APACrefYearMonthDay</span>2023.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib24.12.1">\BBOQ</span><span class="ltx_ERROR undefined" id="bib.bib24.13.2">\APACrefatitle</span>Robust speech recognition via large-scale weak supervision Robust speech recognition via large-scale weak supervision.<span class="ltx_ERROR undefined" id="bib.bib24.14.3">\BBCQ</span>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib24.15.1">\BIn</span> <span class="ltx_ERROR undefined" id="bib.bib24.16.2">\APACrefbtitle</span>International Conference on Machine Learning International conference on machine learning (<span class="ltx_ERROR undefined" id="bib.bib24.17.3">\BPGS</span> 28492–28518).
<span class="ltx_ERROR undefined" id="bib.bib24.18.4">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib24.19.5">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Sepahvand <span class="ltx_ERROR undefined" id="bib.bib25.5.5.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib25.6.6.2">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib25.7.1">\APACinsertmetastar</span>sepahvand2024data<span class="ltx_ERROR undefined" id="bib.bib25.8.2">{APACrefauthors}</span>Sepahvand, N<span class="ltx_ERROR undefined" id="bib.bib25.9.3">\BPBI</span>M., Dumoulin, V., Triantafillou, E.<span class="ltx_ERROR undefined" id="bib.bib25.10.4">\BCBL</span> <span class="ltx_ERROR undefined" id="bib.bib25.11.5">\BBA</span> Dziugaite, G<span class="ltx_ERROR undefined" id="bib.bib25.12.6">\BPBI</span>K. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib25.13.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib25.14.1">\APACrefbtitle</span>Data Selection for Transfer Unlearning. Data selection for transfer unlearning.
<span class="ltx_ERROR undefined" id="bib.bib25.15.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib25.16.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Team (<span class="ltx_ERROR undefined" id="bib.bib26.2.2.1">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib26.3.1">\APACinsertmetastar</span>chameleonteam2024chameleon<span class="ltx_ERROR undefined" id="bib.bib26.4.2">{APACrefauthors}</span>Team, C. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib26.5.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib26.6.1">\APACrefbtitle</span>Chameleon: Mixed-Modal Early-Fusion Foundation Models. Chameleon: Mixed-modal early-fusion foundation models.
<span class="ltx_ERROR undefined" id="bib.bib26.7.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib26.8.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Udandarao <span class="ltx_ERROR undefined" id="bib.bib27.4.4.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib27.5.5.2">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib27.6.1">\APACinsertmetastar</span>udandarao2024no<span class="ltx_ERROR undefined" id="bib.bib27.7.2">{APACrefauthors}</span>Udandarao, V., Prabhu, A., Ghosh, A., Sharma, Y., Torr, P<span class="ltx_ERROR undefined" id="bib.bib27.8.3">\BPBI</span>H., Bibi, A.<span class="ltx_ERROR undefined" id="bib.bib27.9.4">\BDBL</span>Bethge, M. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib27.10.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib27.11.1">\BBOQ</span><span class="ltx_ERROR undefined" id="bib.bib27.12.2">\APACrefatitle</span>No" zero-shot" without exponential data: Pretraining concept frequency determines multimodal model performance No" zero-shot" without exponential data: Pretraining concept frequency determines multimodal model performance.<span class="ltx_ERROR undefined" id="bib.bib27.13.3">\BBCQ</span>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib27.14.1">\APACjournalVolNumPages</span>arXiv preprint arXiv:2404.04125.
<span class="ltx_ERROR undefined" id="bib.bib27.15.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib27.16.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ukrainika (<span class="ltx_ERROR undefined" id="bib.bib28.2.2.1">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib28.3.1">\APACinsertmetastar</span>ukrainica<span class="ltx_ERROR undefined" id="bib.bib28.4.2">{APACrefauthors}</span>Ukrainika. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib28.5.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib28.6.1">\APACrefbtitle</span>Electronic library "Ukrainika" - an integrated national electronic information resource National Library of Ukraine named after V. I. Vernadskyi; — nbuv.gov.ua. Electronic library "ukrainika" - an integrated national electronic information resource national library of ukraine named after v. i. vernadskyi; — nbuv.gov.ua.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib28.7.1">\APAChowpublished</span><a class="ltx_ref ltx_url ltx_font_typewriter" href="http://www.nbuv.gov.ua/node/3699" title="">http://www.nbuv.gov.ua/node/3699</a>.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib28.8.1">\APACrefnote</span>[Accessed 12-06-2024]
<span class="ltx_ERROR undefined" id="bib.bib28.9.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib28.10.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib29">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Vo <span class="ltx_ERROR undefined" id="bib.bib29.4.4.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib29.5.5.2">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib29.6.1">\APACinsertmetastar</span>vo2024automatic<span class="ltx_ERROR undefined" id="bib.bib29.7.2">{APACrefauthors}</span>Vo, H<span class="ltx_ERROR undefined" id="bib.bib29.8.3">\BPBI</span>V., Khalidov, V., Darcet, T., Moutakanni, T., Smetanin, N., Szafraniec, M.<span class="ltx_ERROR undefined" id="bib.bib29.9.4">\BDBL</span>Bojanowski, P. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib29.10.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib29.11.1">\APACrefbtitle</span>Automatic Data Curation for Self-Supervised Learning: A Clustering-Based Approach. Automatic data curation for self-supervised learning: A clustering-based approach.
<span class="ltx_ERROR undefined" id="bib.bib29.12.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib29.13.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib30">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang <span class="ltx_ERROR undefined" id="bib.bib30.4.4.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib30.5.5.2">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib30.6.1">\APACinsertmetastar</span>wang2024enhancing<span class="ltx_ERROR undefined" id="bib.bib30.7.2">{APACrefauthors}</span>Wang, X., Chen, J., Wang, Z., Zhou, Y., Zhou, Y., Yao, H.<span class="ltx_ERROR undefined" id="bib.bib30.8.3">\BDBL</span>Xiao, C. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib30.9.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib30.10.1">\APACrefbtitle</span>Enhancing Visual-Language Modality Alignment in Large Vision Language Models via Self-Improvement. Enhancing visual-language modality alignment in large vision language models via self-improvement.
<span class="ltx_ERROR undefined" id="bib.bib30.11.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib30.12.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib31">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Young <span class="ltx_ERROR undefined" id="bib.bib31.4.4.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib31.5.5.2">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib31.6.1">\APACinsertmetastar</span>young2024yi<span class="ltx_ERROR undefined" id="bib.bib31.7.2">{APACrefauthors}</span>Young, A., Chen, B., Li, C., Huang, C., Zhang, G., Zhang, G.<span class="ltx_ERROR undefined" id="bib.bib31.8.3">\BDBL</span>others 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib31.9.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib31.10.1">\BBOQ</span><span class="ltx_ERROR undefined" id="bib.bib31.11.2">\APACrefatitle</span>Yi: Open foundation models by 01. ai Yi: Open foundation models by 01. ai.<span class="ltx_ERROR undefined" id="bib.bib31.12.3">\BBCQ</span>
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib31.13.1">\APACjournalVolNumPages</span>arXiv preprint arXiv:2403.04652.
<span class="ltx_ERROR undefined" id="bib.bib31.14.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib31.15.3">\CurrentBib</span>
</span>
</li>
<li class="ltx_bibitem" id="bib.bib32">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan <span class="ltx_ERROR undefined" id="bib.bib32.4.4.1">\BOthers</span>. (<span class="ltx_ERROR undefined" id="bib.bib32.5.5.2">\APACyear</span>2024)</span>
<span class="ltx_bibblock">
<span class="ltx_ERROR undefined" id="bib.bib32.6.1">\APACinsertmetastar</span>yuan2024selfrewarding<span class="ltx_ERROR undefined" id="bib.bib32.7.2">{APACrefauthors}</span>Yuan, W., Pang, R<span class="ltx_ERROR undefined" id="bib.bib32.8.3">\BPBI</span>Y., Cho, K., Li, X., Sukhbaatar, S., Xu, J.<span class="ltx_ERROR undefined" id="bib.bib32.9.4">\BCBL</span> <span class="ltx_ERROR undefined" id="bib.bib32.10.5">\BBA</span> Weston, J. 
</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib32.11.1">\APACrefYearMonthDay</span>2024.

</span>
<span class="ltx_bibblock"><span class="ltx_ERROR undefined" id="bib.bib32.12.1">\APACrefbtitle</span>Self-Rewarding Language Models. Self-rewarding language models.
<span class="ltx_ERROR undefined" id="bib.bib32.13.2">\PrintBackRefs</span><span class="ltx_ERROR undefined" id="bib.bib32.14.3">\CurrentBib</span>
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Thu Oct 10 12:57:48 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
