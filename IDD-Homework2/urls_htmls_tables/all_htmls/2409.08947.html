<!DOCTYPE html>
<html lang="en" prefix="dcterms: http://purl.org/dc/terms/">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis</title>
<!--Generated on Tue Sep 17 12:16:40 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2409.08947v2/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S1" title="In A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S2" title="In A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related Work</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S2.SS1" title="In 2 Related Work ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.1 </span>Radiance Fields</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S2.SS2" title="In 2 Related Work ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.2 </span>Single Image Relighting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S2.SS3" title="In 2 Related Work ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.3 </span>Multi-view Relighting</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S2.SS4" title="In 2 Related Work ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2.4 </span>Diffusion Models</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3" title="In A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>Method</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.SS1" title="In 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Single-View Relighting with 2D Diffusion Priors</span></a>
<ol class="ltx_toclist ltx_toclist_subsection">
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.SS1.SSS1" title="In 3.1 Single-View Relighting with 2D Diffusion Priors ‣ 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.1 </span>Lighting Direction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.SS1.SSS2" title="In 3.1 Single-View Relighting with 2D Diffusion Priors ‣ 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.2 </span>Controlling Relighting Diffusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsubsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.SS1.SSS3" title="In 3.1 Single-View Relighting with 2D Diffusion Priors ‣ 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1.3 </span>Improving the Diffusion Quality</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.SS2" title="In 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Augmenting Multi-View/Single-Lighting Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.SS3" title="In 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Training a Lighting-Consistent Radiance Field</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S4" title="In A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Results and Evaluation</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S4.SS1" title="In 4 Results and Evaluation ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Test Datasets</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S4.SS2" title="In 4 Results and Evaluation ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>3D Relighting Results</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S4.SS3" title="In 4 Results and Evaluation ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.3 </span>Evaluation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S5" title="In A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Conclusion</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<div class="ltx_para" id="p1">
<span class="ltx_ERROR undefined" id="p1.1">\SpecialIssuePaper</span><span class="ltx_ERROR undefined" id="p1.2">\CGFStandardLicense</span><span class="ltx_ERROR undefined" id="p1.3">\BibtexOrBiblatex</span><span class="ltx_ERROR undefined" id="p1.4">\electronicVersion</span><span class="ltx_ERROR undefined" id="p1.5">\PrintedOrElectronic</span>
</div>
<div class="ltx_para" id="p2">
<span class="ltx_ERROR undefined" id="p2.9">\teaser</span>
<p class="ltx_p ltx_parbox ltx_align_middle" id="p2.5.5" style="width:433.6pt;">Y. Poirier-Ginter<sup class="ltx_sup" id="p2.5.5.1"><span class="ltx_text ltx_font_italic" id="p2.5.5.1.1">1,2</span></sup><span class="ltx_ERROR undefined" id="p2.5.5.2">\orcid</span>0009-0001-5806-5136, A. Gauthier<sup class="ltx_sup" id="p2.5.5.3"><span class="ltx_text ltx_font_italic" id="p2.5.5.3.1">1</span></sup><span class="ltx_ERROR undefined" id="p2.5.5.4">\orcid</span>0000-0002-3710-0879, J. Philip<sup class="ltx_sup" id="p2.5.5.5"><span class="ltx_text ltx_font_italic" id="p2.5.5.5.1">3</span></sup><span class="ltx_ERROR undefined" id="p2.5.5.6">\orcid</span>0000-0003-3125-1614, J.-F. Lalonde<sup class="ltx_sup" id="p2.5.5.7"><span class="ltx_text ltx_font_italic" id="p2.5.5.7.1">2</span></sup><span class="ltx_ERROR undefined" id="p2.5.5.8">\orcid</span>0000-0002-6583-2364 and G. Drettakis<sup class="ltx_sup" id="p2.5.5.9"><span class="ltx_text ltx_font_italic" id="p2.5.5.9.1">1</span></sup><span class="ltx_ERROR undefined" id="p2.5.5.10">\orcid</span>0000-0002-9254-4819</p>
<p class="ltx_p ltx_parbox ltx_align_middle" id="p2.8.3" style="width:433.6pt;"><sup class="ltx_sup" id="p2.8.3.1">1</sup>Inria, Université Côte d’Azur, France; <sup class="ltx_sup" id="p2.8.3.2">2</sup>Université Laval, Canada; <sup class="ltx_sup" id="p2.8.3.3">3</sup>Adobe Research, United Kingdom</p>
</div>
<div class="ltx_para" id="p3">
<img alt="[Uncaptioned image]" class="ltx_graphics ltx_img_landscape" height="333" id="p3.g1" src="x1.png" width="789"/>
<p class="ltx_p" id="p3.1"><span class="ltx_text ltx_caption" id="p3.1.1">
Our method produces relightable radiance fields directly from single-illumination multi-view dataset, by using priors from generative data in the place of an actual multi-illumination capture.</span></p>
</div>
<h1 class="ltx_title ltx_title_document">A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="1.1">Relighting radiance fields is severely underconstrained for multi-view data, which is most often captured under a single illumination condition; It is especially hard for full scenes containing multiple objects. We introduce a method to create relightable radiance fields using such single-illumination data by exploiting priors extracted from 2D image diffusion models. We first fine-tune a 2D diffusion model on a multi-illumination dataset conditioned by light direction, allowing us to augment a single-illumination capture into a realistic – but possibly inconsistent – multi-illumination dataset from directly defined light directions.
We use this augmented data to create a relightable radiance field represented by 3D Gaussian splats. To allow direct control of light direction for low-frequency lighting, we represent appearance with a multi-layer perceptron parameterized on light direction. To enforce multi-view consistency and overcome inaccuracies we optimize a per-image auxiliary feature vector. We show results on synthetic and real multi-view data under single illumination, demonstrating that our method successfully exploits 2D diffusion model priors to allow realistic 3D relighting for complete scenes.</p>
</div>
<div class="ltx_classification">
<h6 class="ltx_title ltx_title_classification">keywords: </h6>NeRF, Radiance Field, Relighting
</div>
<span class="ltx_note ltx_note_frontmatter ltx_role_volume" id="2"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">volume: </span>43</span></span></span><span class="ltx_note ltx_note_frontmatter ltx_role_issue" id="3"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">issue: </span>4</span></span></span>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Radiance fields have recently revolutionized 3D scene capture from images <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx37" title="">MST<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>20</a>]</cite>.
Such captures typically involve a multi-view set of photographs taken under the <em class="ltx_emph ltx_font_italic" id="S1.p1.1.1">same</em> lighting conditions.
<em class="ltx_emph ltx_font_italic" id="S1.p1.1.2">Relighting</em> such radiance fields is hard since lighting and material properties are entangled (e.g., is this a shadow or simply a darker color?) and the inverse problem ill-posed.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">One approach to overcome this difficulty is to capture a multi-illumination dataset which better conditions the inverse problem but comes at the cost of a heavy capture setup <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx10" title="">DHT<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>00</a>]</cite>.
Another option is to use <em class="ltx_emph ltx_font_italic" id="S1.p2.1.1">priors</em>, which is typically done by training a neural network on synthetic data to predict intrinsic properties or relit images.
However, creating sufficiently large, varied and photorealistic 3D scenes is both challenging and time-consuming.
As such, methods relying on these—or simpler—priors often demonstrate results on isolated masked objects <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx1" title="">BBJ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>21</a>]</cite>, or make simplifying assumptions such as distant environment lighting <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx4" title="">BJB<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx79" title="">ZSD<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>21</a>]</cite>.
Other methods have handled more complex illumination models, including full scenes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx43" title="">PMGD21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx41" title="">PGZ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>19</a>]</cite>, but can be limited in the complexity of the geometry and materials that must reconstruct well.
Finally, methods that depend on accurate estimates of surface normals <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx18" title="">JLX<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx14" title="">GGL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite> often produce limited levels of realism when relighting.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">At the other end of the spectrum, diffusion models (DMs, e.g., <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx45" title="">RBL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>22</a>]</cite>), trained on billions of natural images, have shown exceptional abilities to capture real image distribution priors and can synthesize complex lighting effects. While recent progress shows they can be controlled in various ways <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx78" title="">ZRA23</a>]</cite>, extracting lighting-specific priors from these models, especially for full 3D scenes, has not yet been demonstrated.</p>
</div>
<div class="ltx_para" id="S1.p4">
<p class="ltx_p" id="S1.p4.1">In this paper, we build on these observations and present a new method that demonstrates that it is possible to create relightable radiance fields for complete scenes from single low-frequency lighting condition captures by exploiting 2D diffusion model priors.
We first propose to fine-tune a pre-trained DM conditioned on the dominant light source direction.
For this, we leverage a dataset of images with many lighting conditions of the same scene <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx35" title="">MGAD19</a>]</cite>, which enables the DM to produce relit versions of an image with explicit control over the dominant lighting direction.
We use this 2D relighting network to augment any standard multi-view dataset taken under single lighting by generating multiple relit versions of each image, effectively transforming it into a multi-illumination dataset.
Given this augmented dataset, we train a new <em class="ltx_emph ltx_font_italic" id="S1.p4.1.1">relightable radiance field</em> with direct control on lighting direction, which in turn enables realistic interactive relighting of full scenes with lighting and camera view control in real time for low-frequency lighting.
We build on 3D Gaussian Splatting <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx21" title="">KKLD23</a>]</cite>, enhancing the radiance field with a small Multi-Layer Perceptron and an auxiliary feature vector to account for the approximate nature of the generated lightings and to handle lighting inconsistencies between views.</p>
</div>
<div class="ltx_para ltx_noindent" id="S1.p5">
<p class="ltx_p" id="S1.p5.1">In summary, our contributions are:</p>
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">A new 2D relighting neural network with direct control on lighting direction, created by fine-tuning a DM with multi-lighting data.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">A method to augment single-lighting multi-view capture to an approximate multi-lighting dataset, by exploiting the 2D relighting network.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">An interactive relightable radiance field that provides direct control on lighting direction, and corrects for inconsistencies in the neural relighting.</p>
</div>
</li>
</ul>
<p class="ltx_p" id="S1.p5.2">We demonstrate our solution on synthetic and real indoor scenes, showing that it provides realistic relighting of multi-view datasets captured under a single lighting condition in real time.</p>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">Our method proposes a relightable radiance field. We review work on radiance fields and their relightable variants, and discuss diffusion models and fine-tuning methods we build on.</p>
</div>
<section class="ltx_subsection" id="S2.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Radiance Fields</h3>
<div class="ltx_para" id="S2.SS1.p1">
<p class="ltx_p" id="S2.SS1.p1.1">Radiance field methods have revolutionized 3D scene capture using multi-view datasets (photos or video) as input.
In particular, Neural Radiance Fields (NeRFs) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx37" title="">MST<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>20</a>]</cite> learn to synthesize novel views of a given scene by regressing its radiance from a set of input images (multiple photos or videos of a 3D scene).
Structure from motion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx62" title="">Ull79</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx50" title="">SF16</a>]</cite> is used to estimate the camera poses for all images and rays are cast through the center of all pixels.
A multi-layer perceptron (MLP) <math alttext="\boldsymbol{c}_{\theta}" class="ltx_Math" display="inline" id="S2.SS1.p1.1.m1.1"><semantics id="S2.SS1.p1.1.m1.1a"><msub id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml"><mi id="S2.SS1.p1.1.m1.1.1.2" xref="S2.SS1.p1.1.m1.1.1.2.cmml">𝒄</mi><mi id="S2.SS1.p1.1.m1.1.1.3" xref="S2.SS1.p1.1.m1.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><apply id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.p1.1.m1.1.1.2.cmml" xref="S2.SS1.p1.1.m1.1.1.2">𝒄</ci><ci id="S2.SS1.p1.1.m1.1.1.3.cmml" xref="S2.SS1.p1.1.m1.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">\boldsymbol{c}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.1.m1.1d">bold_italic_c start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> parameterized by 3D position and view direction is used to represent the radiance and opacity of the scene.
The optimization objective is simply the mean squared error:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.Ex1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\mathrm{NeRF}}=\mathbb{E}_{\boldsymbol{o},\boldsymbol{d},%
\boldsymbol{c}^{\ast}}\Big{[}||\boldsymbol{c}_{\theta}(\boldsymbol{o},%
\boldsymbol{d})-\boldsymbol{c}^{\ast}||_{2}^{2}\Big{]}\,," class="ltx_Math" display="block" id="S2.Ex1.m1.6"><semantics id="S2.Ex1.m1.6a"><mrow id="S2.Ex1.m1.6.6.1" xref="S2.Ex1.m1.6.6.1.1.cmml"><mrow id="S2.Ex1.m1.6.6.1.1" xref="S2.Ex1.m1.6.6.1.1.cmml"><msub id="S2.Ex1.m1.6.6.1.1.3" xref="S2.Ex1.m1.6.6.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.Ex1.m1.6.6.1.1.3.2" xref="S2.Ex1.m1.6.6.1.1.3.2.cmml">ℒ</mi><mi id="S2.Ex1.m1.6.6.1.1.3.3" xref="S2.Ex1.m1.6.6.1.1.3.3.cmml">NeRF</mi></msub><mo id="S2.Ex1.m1.6.6.1.1.2" xref="S2.Ex1.m1.6.6.1.1.2.cmml">=</mo><mrow id="S2.Ex1.m1.6.6.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.cmml"><msub id="S2.Ex1.m1.6.6.1.1.1.3" xref="S2.Ex1.m1.6.6.1.1.1.3.cmml"><mi id="S2.Ex1.m1.6.6.1.1.1.3.2" xref="S2.Ex1.m1.6.6.1.1.1.3.2.cmml">𝔼</mi><mrow id="S2.Ex1.m1.3.3.3.3" xref="S2.Ex1.m1.3.3.3.4.cmml"><mi id="S2.Ex1.m1.1.1.1.1" xref="S2.Ex1.m1.1.1.1.1.cmml">𝒐</mi><mo id="S2.Ex1.m1.3.3.3.3.2" xref="S2.Ex1.m1.3.3.3.4.cmml">,</mo><mi id="S2.Ex1.m1.2.2.2.2" xref="S2.Ex1.m1.2.2.2.2.cmml">𝒅</mi><mo id="S2.Ex1.m1.3.3.3.3.3" xref="S2.Ex1.m1.3.3.3.4.cmml">,</mo><msup id="S2.Ex1.m1.3.3.3.3.1" xref="S2.Ex1.m1.3.3.3.3.1.cmml"><mi id="S2.Ex1.m1.3.3.3.3.1.2" xref="S2.Ex1.m1.3.3.3.3.1.2.cmml">𝒄</mi><mo id="S2.Ex1.m1.3.3.3.3.1.3" xref="S2.Ex1.m1.3.3.3.3.1.3.cmml">∗</mo></msup></mrow></msub><mo id="S2.Ex1.m1.6.6.1.1.1.2" xref="S2.Ex1.m1.6.6.1.1.1.2.cmml">⁢</mo><mrow id="S2.Ex1.m1.6.6.1.1.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.1.2.cmml"><mo id="S2.Ex1.m1.6.6.1.1.1.1.1.2" maxsize="160%" minsize="160%" xref="S2.Ex1.m1.6.6.1.1.1.1.2.1.cmml">[</mo><msubsup id="S2.Ex1.m1.6.6.1.1.1.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.cmml"><mrow id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.cmml"><mo id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.cmml"><msub id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.2.cmml"><mi id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.2.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml">𝒄</mi><mi id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.2.3" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.2.3.cmml">θ</mi></msub><mo id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.1" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.1.cmml">⁢</mo><mrow id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.3.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.3.1.cmml"><mo id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.3.2.1" stretchy="false" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.3.1.cmml">(</mo><mi id="S2.Ex1.m1.4.4" xref="S2.Ex1.m1.4.4.cmml">𝒐</mi><mo id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.3.2.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.3.1.cmml">,</mo><mi id="S2.Ex1.m1.5.5" xref="S2.Ex1.m1.5.5.cmml">𝒅</mi><mo id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.3.2.3" stretchy="false" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.3.1.cmml">)</mo></mrow></mrow><mo id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.1" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.cmml">−</mo><msup id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.3" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.cmml"><mi id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.2" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.2.cmml">𝒄</mi><mo id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.3" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.3.cmml">∗</mo></msup></mrow><mo id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.3" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.3.cmml">2</mn><mn id="S2.Ex1.m1.6.6.1.1.1.1.1.1.3" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.3.cmml">2</mn></msubsup><mo id="S2.Ex1.m1.6.6.1.1.1.1.1.3" maxsize="160%" minsize="160%" rspace="0.110em" xref="S2.Ex1.m1.6.6.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><mo id="S2.Ex1.m1.6.6.1.2" xref="S2.Ex1.m1.6.6.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.Ex1.m1.6b"><apply id="S2.Ex1.m1.6.6.1.1.cmml" xref="S2.Ex1.m1.6.6.1"><eq id="S2.Ex1.m1.6.6.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.2"></eq><apply id="S2.Ex1.m1.6.6.1.1.3.cmml" xref="S2.Ex1.m1.6.6.1.1.3"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.1.1.3.1.cmml" xref="S2.Ex1.m1.6.6.1.1.3">subscript</csymbol><ci id="S2.Ex1.m1.6.6.1.1.3.2.cmml" xref="S2.Ex1.m1.6.6.1.1.3.2">ℒ</ci><ci id="S2.Ex1.m1.6.6.1.1.3.3.cmml" xref="S2.Ex1.m1.6.6.1.1.3.3">NeRF</ci></apply><apply id="S2.Ex1.m1.6.6.1.1.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1"><times id="S2.Ex1.m1.6.6.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.2"></times><apply id="S2.Ex1.m1.6.6.1.1.1.3.cmml" xref="S2.Ex1.m1.6.6.1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.1.1.1.3.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.3">subscript</csymbol><ci id="S2.Ex1.m1.6.6.1.1.1.3.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.3.2">𝔼</ci><list id="S2.Ex1.m1.3.3.3.4.cmml" xref="S2.Ex1.m1.3.3.3.3"><ci id="S2.Ex1.m1.1.1.1.1.cmml" xref="S2.Ex1.m1.1.1.1.1">𝒐</ci><ci id="S2.Ex1.m1.2.2.2.2.cmml" xref="S2.Ex1.m1.2.2.2.2">𝒅</ci><apply id="S2.Ex1.m1.3.3.3.3.1.cmml" xref="S2.Ex1.m1.3.3.3.3.1"><csymbol cd="ambiguous" id="S2.Ex1.m1.3.3.3.3.1.1.cmml" xref="S2.Ex1.m1.3.3.3.3.1">superscript</csymbol><ci id="S2.Ex1.m1.3.3.3.3.1.2.cmml" xref="S2.Ex1.m1.3.3.3.3.1.2">𝒄</ci><ci id="S2.Ex1.m1.3.3.3.3.1.3.cmml" xref="S2.Ex1.m1.3.3.3.3.1.3">∗</ci></apply></list></apply><apply id="S2.Ex1.m1.6.6.1.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1"><csymbol cd="latexml" id="S2.Ex1.m1.6.6.1.1.1.1.2.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S2.Ex1.m1.6.6.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1">superscript</csymbol><apply id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1">subscript</csymbol><apply id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1"><minus id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.1"></minus><apply id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2"><times id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.1"></times><apply id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.2"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.2.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.2">subscript</csymbol><ci id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.2.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.2.2">𝒄</ci><ci id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.2.3.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.2.3">𝜃</ci></apply><interval closure="open" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.2.3.2"><ci id="S2.Ex1.m1.4.4.cmml" xref="S2.Ex1.m1.4.4">𝒐</ci><ci id="S2.Ex1.m1.5.5.cmml" xref="S2.Ex1.m1.5.5">𝒅</ci></interval></apply><apply id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.1.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.3">superscript</csymbol><ci id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.2.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.2">𝒄</ci><ci id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.3.cmml" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.1.1.1.3.3">∗</ci></apply></apply></apply><cn id="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.1.3">2</cn></apply><cn id="S2.Ex1.m1.6.6.1.1.1.1.1.1.3.cmml" type="integer" xref="S2.Ex1.m1.6.6.1.1.1.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.Ex1.m1.6c">\mathcal{L}_{\mathrm{NeRF}}=\mathbb{E}_{\boldsymbol{o},\boldsymbol{d},%
\boldsymbol{c}^{\ast}}\Big{[}||\boldsymbol{c}_{\theta}(\boldsymbol{o},%
\boldsymbol{d})-\boldsymbol{c}^{\ast}||_{2}^{2}\Big{]}\,,</annotation><annotation encoding="application/x-llamapun" id="S2.Ex1.m1.6d">caligraphic_L start_POSTSUBSCRIPT roman_NeRF end_POSTSUBSCRIPT = blackboard_E start_POSTSUBSCRIPT bold_italic_o , bold_italic_d , bold_italic_c start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT end_POSTSUBSCRIPT [ | | bold_italic_c start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( bold_italic_o , bold_italic_d ) - bold_italic_c start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT | | start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ] ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS1.p1.6">where <math alttext="\boldsymbol{o}" class="ltx_Math" display="inline" id="S2.SS1.p1.2.m1.1"><semantics id="S2.SS1.p1.2.m1.1a"><mi id="S2.SS1.p1.2.m1.1.1" xref="S2.SS1.p1.2.m1.1.1.cmml">𝒐</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m1.1b"><ci id="S2.SS1.p1.2.m1.1.1.cmml" xref="S2.SS1.p1.2.m1.1.1">𝒐</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m1.1c">\boldsymbol{o}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.2.m1.1d">bold_italic_o</annotation></semantics></math> is a ray’s origin, <math alttext="\boldsymbol{d}" class="ltx_Math" display="inline" id="S2.SS1.p1.3.m2.1"><semantics id="S2.SS1.p1.3.m2.1a"><mi id="S2.SS1.p1.3.m2.1.1" xref="S2.SS1.p1.3.m2.1.1.cmml">𝒅</mi><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m2.1b"><ci id="S2.SS1.p1.3.m2.1.1.cmml" xref="S2.SS1.p1.3.m2.1.1">𝒅</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m2.1c">\boldsymbol{d}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.3.m2.1d">bold_italic_d</annotation></semantics></math> its direction, and <math alttext="\boldsymbol{c}^{\ast}" class="ltx_Math" display="inline" id="S2.SS1.p1.4.m3.1"><semantics id="S2.SS1.p1.4.m3.1a"><msup id="S2.SS1.p1.4.m3.1.1" xref="S2.SS1.p1.4.m3.1.1.cmml"><mi id="S2.SS1.p1.4.m3.1.1.2" xref="S2.SS1.p1.4.m3.1.1.2.cmml">𝒄</mi><mo id="S2.SS1.p1.4.m3.1.1.3" xref="S2.SS1.p1.4.m3.1.1.3.cmml">∗</mo></msup><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m3.1b"><apply id="S2.SS1.p1.4.m3.1.1.cmml" xref="S2.SS1.p1.4.m3.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.4.m3.1.1.1.cmml" xref="S2.SS1.p1.4.m3.1.1">superscript</csymbol><ci id="S2.SS1.p1.4.m3.1.1.2.cmml" xref="S2.SS1.p1.4.m3.1.1.2">𝒄</ci><ci id="S2.SS1.p1.4.m3.1.1.3.cmml" xref="S2.SS1.p1.4.m3.1.1.3">∗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m3.1c">\boldsymbol{c}^{\ast}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.4.m3.1d">bold_italic_c start_POSTSUPERSCRIPT ∗ end_POSTSUPERSCRIPT</annotation></semantics></math> the target RGB color value of its corresponding pixel.
The predicted color for that pixel is obtained by integrating a color field <math alttext="\boldsymbol{c}_{\theta}" class="ltx_Math" display="inline" id="S2.SS1.p1.5.m4.1"><semantics id="S2.SS1.p1.5.m4.1a"><msub id="S2.SS1.p1.5.m4.1.1" xref="S2.SS1.p1.5.m4.1.1.cmml"><mi id="S2.SS1.p1.5.m4.1.1.2" xref="S2.SS1.p1.5.m4.1.1.2.cmml">𝒄</mi><mi id="S2.SS1.p1.5.m4.1.1.3" xref="S2.SS1.p1.5.m4.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m4.1b"><apply id="S2.SS1.p1.5.m4.1.1.cmml" xref="S2.SS1.p1.5.m4.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m4.1.1.1.cmml" xref="S2.SS1.p1.5.m4.1.1">subscript</csymbol><ci id="S2.SS1.p1.5.m4.1.1.2.cmml" xref="S2.SS1.p1.5.m4.1.1.2">𝒄</ci><ci id="S2.SS1.p1.5.m4.1.1.3.cmml" xref="S2.SS1.p1.5.m4.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m4.1c">\boldsymbol{c}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.5.m4.1d">bold_italic_c start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> weighted by a density field <math alttext="\sigma_{\theta}" class="ltx_Math" display="inline" id="S2.SS1.p1.6.m5.1"><semantics id="S2.SS1.p1.6.m5.1a"><msub id="S2.SS1.p1.6.m5.1.1" xref="S2.SS1.p1.6.m5.1.1.cmml"><mi id="S2.SS1.p1.6.m5.1.1.2" xref="S2.SS1.p1.6.m5.1.1.2.cmml">σ</mi><mi id="S2.SS1.p1.6.m5.1.1.3" xref="S2.SS1.p1.6.m5.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.6.m5.1b"><apply id="S2.SS1.p1.6.m5.1.1.cmml" xref="S2.SS1.p1.6.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.6.m5.1.1.1.cmml" xref="S2.SS1.p1.6.m5.1.1">subscript</csymbol><ci id="S2.SS1.p1.6.m5.1.1.2.cmml" xref="S2.SS1.p1.6.m5.1.1.2">𝜎</ci><ci id="S2.SS1.p1.6.m5.1.1.3.cmml" xref="S2.SS1.p1.6.m5.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.6.m5.1c">\sigma_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S2.SS1.p1.6.m5.1d">italic_σ start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> following the equation of volume rendering.
The original NeRF was slow to train and to render; A vast number of methods <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx61" title="">TTM<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>22</a>]</cite> have been proposed to improve the original technique, e.g., acceleration structures <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx34" title="">MESK22</a>]</cite>, antialiasing <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx6" title="">BMT<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>21</a>]</cite>, handling larger scenes <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx7" title="">BMV<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>22</a>]</cite> etc.
Recently, 3D Gaussian Splatting (3DGS) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx21" title="">KKLD23</a>]</cite> introduces an explicit, primitive-based representation of radiance fields.
The anisotropic nature of the 3D Gaussians allows the efficient representation of fine detail, and the fast GPU-accelerated rasterization used allows real-time rendering.
We use 3DGS to represent radiance fields mainly for performance, but any other radiance representation, e.g., <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx9" title="">CXG<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>22</a>]</cite>, could be used instead.
Radiance fields are most commonly used in the context of <em class="ltx_emph ltx_font_italic" id="S2.SS1.p1.6.1">single-light condition</em> captures, i.e., the images are all captured under the same lighting.
As a result, there is no direct way to change the lighting of captured scenes, severely restricting the utility of radiance fields compared to traditional 3D graphics assets.
Our method uses diffusion models to simulate multi-light conditions from a single-light capture thus allowing the relighting of radiance fields.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Single Image Relighting</h3>
<div class="ltx_para" id="S2.SS2.p1">
<p class="ltx_p" id="S2.SS2.p1.1">Single image relighting approaches have mostly been restricted to human faces, with the most recent methods using generative priors <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx66" title="">WZL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>08</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx56" title="">SYH<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>17</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx52" title="">SKCJ18</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx11" title="">FRV<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx44" title="">PTS23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx42" title="">PLMZ23</a>]</cite>. Recently, human body relighting has also been studied  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx20" title="">KE19</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx29" title="">LSY<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>21</a>]</cite> as their structure also allows for the design of effective priors.
Because they are much less constrained, relighting generic scenes from a single image is a much harder problem that has eluded researchers until recently.
While some approaches have focused on specific relighting effects such as shadows <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx27" title="">LLZ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx53" title="">SLZ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx57" title="">SZB21</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx63" title="">VZG<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite>, they are applicable solely for the purpose of object compositing.
Full scene relighting has been explored by Murmann et al. <span class="ltx_ERROR undefined" id="S2.SS2.p1.1.1">\shortcite</span>multilum, who present a dataset of real indoor scenes lit by multiple lighting directions.
They show that training a U-net on their dataset allows for full scene relighting—in this work, we also leverage their dataset but train a more powerful ControlNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx78" title="">ZRA23</a>]</cite> for the relighting task.
Other works include <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx59" title="">TÇE<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>21</a>]</cite> who focus on sky relighting and <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx28" title="">LSB<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx77" title="">ZLZ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>22</a>]</cite> which leverage image-to-image translation.
Methods for outdoor scenes have also been proposed <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx68" title="">YME<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx25" title="">LGZ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>20</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx69" title="">YS22</a>]</cite>.
Of note, SIMBAR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx81" title="">ZTS<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>22</a>]</cite>
and OutCast <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx15" title="">GRP22</a>]</cite> produces realistic, user-controllable, hard, cast shadows from the sun.
In contrast, we focus on indoor scenes which often exhibit soft shadows and more complex lighting effects. Finally, the concurrent work of Zeng et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx72" title="">ZDP<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>24</a>]</cite> uses diffusion models to relight isolated objects using environment maps. In contrast to these solutions, we focus on cluttered indoor scenes which often exhibit soft shadows and more complex lighting effects.</p>
</div>
</section>
<section class="ltx_subsection" id="S2.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Multi-view Relighting</h3>
<div class="ltx_para" id="S2.SS3.p1">
<p class="ltx_p" id="S2.SS3.p1.1">While single-view methods produce good results on restricted datasets such as faces, they are often limited by the lack of accurate geometry, required to simulate light transport.
To this point, multi-view data can provide a more accurate and complete geometric reconstruction.
For example Philip et al. <span class="ltx_ERROR undefined" id="S2.SS3.p1.1.1">\shortcite</span>philip2021free,philip2019multi build on multi-view stereo (MVS) reconstruction of the scene, and learn a prior from synthetic data rendered under multiple lighting conditions.
Despite correcting for many of the reconstruction artifacts, these methods are restricted by the quality of MVS reconstruction.
Nimier et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx38" title="">NDDJK21</a>]</cite> also present a scene-scale solution but require a complex pipeline that optimizes in texture space. Gao et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx13" title="">GCD<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>20</a>]</cite> use a rough proxy and neural textures to allow object relighting.</p>
</div>
<div class="ltx_para" id="S2.SS3.p2">
<p class="ltx_p" id="S2.SS3.p2.1">More recently radiance fields have also been used as a geometric representation for relighting.
Most methods work on the simple case of a single isolated object while we target larger scenes.
Such methods typically assume lighting to be distant, often provided as an environment map.
NeRFactor <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx79" title="">ZSD<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>21</a>]</cite> uses a Bi-Directional Reflectance Distribution Function (BRDF) prior from measurements and estimates normals and visibility, while NERV <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx49" title="">SDZ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>21</a>]</cite> and Zhang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx80" title="">ZSH<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>22</a>]</cite> predicts visibility to allow indirect illumination estimation.
NERD <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx1" title="">BBJ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>21</a>]</cite>, PhySG <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx76" title="">ZLW<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>21</a>]</cite>, and DE-NeRF <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx65" title="">WSLG23</a>]</cite> use efficient physically-based material and lighting models to decompose a radiance field into spatially varying BRDFs, while Neural-PIL <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx4" title="">BJB<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>21</a>]</cite> learns the illumination integration and low-dimensional BRDF priors using auto-encoders.
TensorIR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx18" title="">JLX<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite> uses a mixed radiance and physics-based formulation to recover intrinsic properties.
NeRO <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx31" title="">LWL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite> focuses on specular objects showing very promising results.
Relightable Gaussians <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx14" title="">GGL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite> use the more recent 3D Gaussian representation along with ray-tracing to estimate properties of objects.
GS-IR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx32" title="">LZF<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>24</a>]</cite>, GaussianShader <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx19" title="">JTL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>24</a>]</cite> and GIR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx55" title="">SWW<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite> also build on 3D Gaussian splatting, proposing different approaches to estimate more reliable normals while approximating visibility and indirect illumination; these work well for isolated objects under distant lighting. However, these methods struggle with more complex scene-scale input and near-field illumination but can work or be adapted to both single and multi-illumination input data.</p>
</div>
<div class="ltx_para" id="S2.SS3.p3">
<p class="ltx_p" id="S2.SS3.p3.1">Feeding multi-view multi-illumination data to a relightable radiance field indeed enables better relighting but at the cost of highly-controlled capture conditions <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx67" title="">XZC<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx71" title="">ZCD<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx60" title="">TDMS<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite> or an extended dataset of unconstrained illuminations <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx2" title="">BEK<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx24" title="">LGF<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>22</a>]</cite>.
In our method, we use a Diffusion Model to simulate multi-illumination data, lifting the capture constraints while benefiting from the lighting variations.
Another body of work <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx36" title="">MHS<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx16" title="">HHM22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx70" title="">YZL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>22</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx82" title="">ZYL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx30" title="">LWC<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx23" title="">LCL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite> achieve object or scene relighting from multi-view images by extracting traditional 3D assets (meshes and SVBRDFs) and applying physically-based rendering algorithms. IBL-NeRF <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx8" title="">CKK23</a>]</cite> allows for scene-scale material estimation but bakes the illumination into a prefiltered light-field which prevents relighting.
Recently, NeRF-OSR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx46" title="">RES<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>22</a>]</cite>, <math alttext="\text{I}^{\text{2}}" class="ltx_Math" display="inline" id="S2.SS3.p3.1.m1.1"><semantics id="S2.SS3.p3.1.m1.1a"><msup id="S2.SS3.p3.1.m1.1.1" xref="S2.SS3.p3.1.m1.1.1.cmml"><mtext id="S2.SS3.p3.1.m1.1.1.2" xref="S2.SS3.p3.1.m1.1.1.2a.cmml">I</mtext><mtext id="S2.SS3.p3.1.m1.1.1.3" xref="S2.SS3.p3.1.m1.1.1.3a.cmml">2</mtext></msup><annotation-xml encoding="MathML-Content" id="S2.SS3.p3.1.m1.1b"><apply id="S2.SS3.p3.1.m1.1.1.cmml" xref="S2.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p3.1.m1.1.1.1.cmml" xref="S2.SS3.p3.1.m1.1.1">superscript</csymbol><ci id="S2.SS3.p3.1.m1.1.1.2a.cmml" xref="S2.SS3.p3.1.m1.1.1.2"><mtext id="S2.SS3.p3.1.m1.1.1.2.cmml" xref="S2.SS3.p3.1.m1.1.1.2">I</mtext></ci><ci id="S2.SS3.p3.1.m1.1.1.3a.cmml" xref="S2.SS3.p3.1.m1.1.1.3"><mtext id="S2.SS3.p3.1.m1.1.1.3.cmml" mathsize="70%" xref="S2.SS3.p3.1.m1.1.1.3">2</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p3.1.m1.1c">\text{I}^{\text{2}}</annotation><annotation encoding="application/x-llamapun" id="S2.SS3.p3.1.m1.1d">I start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT</annotation></semantics></math>-SDF <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx74" title="">ZHY<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite>, and Wang et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx64" title="">WSG<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite> focused on scene scale, single illumination relighting scenes using both implicit and explicit representations.
While they can achieve reasonable results, they often lack overall realism, exhibiting bumpy or overly smooth shading during relighting.
In contrast, our use of diffusion priors provides realistic-looking output.</p>
</div>
<figure class="ltx_figure" id="S2.F1"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="232" id="S2.F1.g1" src="x2.png" width="830"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>We use the single-view, multi-illumination dataset of Murmann et al. <span class="ltx_ERROR undefined" id="S2.F1.2.1">\shortcite</span>multilum to train ControlNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx78" title="">ZRA23</a>]</cite> on single view supervised relighting. The network accepts an image (along with its estimated depth map) and a target light direction as input and produces a relit version of the same scene under the desired target lighting.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S2.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.4 </span>Diffusion Models</h3>
<div class="ltx_para" id="S2.SS4.p1">
<p class="ltx_p" id="S2.SS4.p1.4">Diffusion Models (DMs) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx48" title="">SDWMG15</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx17" title="">HJA20</a>]</cite> made it possible to train generative models on diverse, high-resolution datasets of billions of images.
These models learn to invert a forward diffusion process that gradually transforms images into isotropic Gaussian noise, by adding random Gaussian noise <math alttext="\boldsymbol{\epsilon}_{t}\sim\mathcal{N}(\boldsymbol{0},\boldsymbol{I})" class="ltx_Math" display="inline" id="S2.SS4.p1.1.m1.2"><semantics id="S2.SS4.p1.1.m1.2a"><mrow id="S2.SS4.p1.1.m1.2.3" xref="S2.SS4.p1.1.m1.2.3.cmml"><msub id="S2.SS4.p1.1.m1.2.3.2" xref="S2.SS4.p1.1.m1.2.3.2.cmml"><mi class="ltx_mathvariant_bold-italic" id="S2.SS4.p1.1.m1.2.3.2.2" mathvariant="bold-italic" xref="S2.SS4.p1.1.m1.2.3.2.2.cmml">ϵ</mi><mi id="S2.SS4.p1.1.m1.2.3.2.3" xref="S2.SS4.p1.1.m1.2.3.2.3.cmml">t</mi></msub><mo id="S2.SS4.p1.1.m1.2.3.1" xref="S2.SS4.p1.1.m1.2.3.1.cmml">∼</mo><mrow id="S2.SS4.p1.1.m1.2.3.3" xref="S2.SS4.p1.1.m1.2.3.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S2.SS4.p1.1.m1.2.3.3.2" xref="S2.SS4.p1.1.m1.2.3.3.2.cmml">𝒩</mi><mo id="S2.SS4.p1.1.m1.2.3.3.1" xref="S2.SS4.p1.1.m1.2.3.3.1.cmml">⁢</mo><mrow id="S2.SS4.p1.1.m1.2.3.3.3.2" xref="S2.SS4.p1.1.m1.2.3.3.3.1.cmml"><mo id="S2.SS4.p1.1.m1.2.3.3.3.2.1" stretchy="false" xref="S2.SS4.p1.1.m1.2.3.3.3.1.cmml">(</mo><mn id="S2.SS4.p1.1.m1.1.1" xref="S2.SS4.p1.1.m1.1.1.cmml">𝟎</mn><mo id="S2.SS4.p1.1.m1.2.3.3.3.2.2" xref="S2.SS4.p1.1.m1.2.3.3.3.1.cmml">,</mo><mi id="S2.SS4.p1.1.m1.2.2" xref="S2.SS4.p1.1.m1.2.2.cmml">𝑰</mi><mo id="S2.SS4.p1.1.m1.2.3.3.3.2.3" stretchy="false" xref="S2.SS4.p1.1.m1.2.3.3.3.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.1.m1.2b"><apply id="S2.SS4.p1.1.m1.2.3.cmml" xref="S2.SS4.p1.1.m1.2.3"><csymbol cd="latexml" id="S2.SS4.p1.1.m1.2.3.1.cmml" xref="S2.SS4.p1.1.m1.2.3.1">similar-to</csymbol><apply id="S2.SS4.p1.1.m1.2.3.2.cmml" xref="S2.SS4.p1.1.m1.2.3.2"><csymbol cd="ambiguous" id="S2.SS4.p1.1.m1.2.3.2.1.cmml" xref="S2.SS4.p1.1.m1.2.3.2">subscript</csymbol><ci id="S2.SS4.p1.1.m1.2.3.2.2.cmml" xref="S2.SS4.p1.1.m1.2.3.2.2">bold-italic-ϵ</ci><ci id="S2.SS4.p1.1.m1.2.3.2.3.cmml" xref="S2.SS4.p1.1.m1.2.3.2.3">𝑡</ci></apply><apply id="S2.SS4.p1.1.m1.2.3.3.cmml" xref="S2.SS4.p1.1.m1.2.3.3"><times id="S2.SS4.p1.1.m1.2.3.3.1.cmml" xref="S2.SS4.p1.1.m1.2.3.3.1"></times><ci id="S2.SS4.p1.1.m1.2.3.3.2.cmml" xref="S2.SS4.p1.1.m1.2.3.3.2">𝒩</ci><interval closure="open" id="S2.SS4.p1.1.m1.2.3.3.3.1.cmml" xref="S2.SS4.p1.1.m1.2.3.3.3.2"><cn id="S2.SS4.p1.1.m1.1.1.cmml" type="integer" xref="S2.SS4.p1.1.m1.1.1">0</cn><ci id="S2.SS4.p1.1.m1.2.2.cmml" xref="S2.SS4.p1.1.m1.2.2">𝑰</ci></interval></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.1.m1.2c">\boldsymbol{\epsilon}_{t}\sim\mathcal{N}(\boldsymbol{0},\boldsymbol{I})</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.1.m1.2d">bold_italic_ϵ start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT ∼ caligraphic_N ( bold_0 , bold_italic_I )</annotation></semantics></math> to an image in <math alttext="T" class="ltx_Math" display="inline" id="S2.SS4.p1.2.m2.1"><semantics id="S2.SS4.p1.2.m2.1a"><mi id="S2.SS4.p1.2.m2.1.1" xref="S2.SS4.p1.2.m2.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.2.m2.1b"><ci id="S2.SS4.p1.2.m2.1.1.cmml" xref="S2.SS4.p1.2.m2.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.2.m2.1c">T</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.2.m2.1d">italic_T</annotation></semantics></math> steps.
DMs train a neural network <math alttext="\boldsymbol{g}_{\phi}" class="ltx_Math" display="inline" id="S2.SS4.p1.3.m3.1"><semantics id="S2.SS4.p1.3.m3.1a"><msub id="S2.SS4.p1.3.m3.1.1" xref="S2.SS4.p1.3.m3.1.1.cmml"><mi id="S2.SS4.p1.3.m3.1.1.2" xref="S2.SS4.p1.3.m3.1.1.2.cmml">𝒈</mi><mi id="S2.SS4.p1.3.m3.1.1.3" xref="S2.SS4.p1.3.m3.1.1.3.cmml">ϕ</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.3.m3.1b"><apply id="S2.SS4.p1.3.m3.1.1.cmml" xref="S2.SS4.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS4.p1.3.m3.1.1.1.cmml" xref="S2.SS4.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS4.p1.3.m3.1.1.2.cmml" xref="S2.SS4.p1.3.m3.1.1.2">𝒈</ci><ci id="S2.SS4.p1.3.m3.1.1.3.cmml" xref="S2.SS4.p1.3.m3.1.1.3">italic-ϕ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.3.m3.1c">\boldsymbol{g}_{\phi}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.3.m3.1d">bold_italic_g start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT</annotation></semantics></math> with parameters <math alttext="\phi" class="ltx_Math" display="inline" id="S2.SS4.p1.4.m4.1"><semantics id="S2.SS4.p1.4.m4.1a"><mi id="S2.SS4.p1.4.m4.1.1" xref="S2.SS4.p1.4.m4.1.1.cmml">ϕ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.4.m4.1b"><ci id="S2.SS4.p1.4.m4.1.1.cmml" xref="S2.SS4.p1.4.m4.1.1">italic-ϕ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.4.m4.1c">\phi</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.4.m4.1d">italic_ϕ</annotation></semantics></math> to learn to denoise with the objective:</p>
<table class="ltx_equation ltx_eqn_table" id="S2.Ex2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\mathrm{Diffusion}}=\mathbb{E}_{\boldsymbol{x},\boldsymbol{%
\epsilon},1\leq t\leq T}\Big{[}||\boldsymbol{g}_{\phi}(\boldsymbol{x}_{t}|t)-%
\boldsymbol{y}_{t}||_{2}^{2}\Big{]}\,," class="ltx_math_unparsed" display="block" id="S2.Ex2.m1.3"><semantics id="S2.Ex2.m1.3a"><mrow id="S2.Ex2.m1.3b"><msub id="S2.Ex2.m1.3.4"><mi class="ltx_font_mathcaligraphic" id="S2.Ex2.m1.3.4.2">ℒ</mi><mi id="S2.Ex2.m1.3.4.3">Diffusion</mi></msub><mo id="S2.Ex2.m1.3.5">=</mo><msub id="S2.Ex2.m1.3.6"><mi id="S2.Ex2.m1.3.6.2">𝔼</mi><mrow id="S2.Ex2.m1.3.3.3"><mrow id="S2.Ex2.m1.3.3.3.5.2"><mi id="S2.Ex2.m1.1.1.1.1">𝒙</mi><mo id="S2.Ex2.m1.3.3.3.5.2.1">,</mo><mi class="ltx_mathvariant_bold-italic" id="S2.Ex2.m1.2.2.2.2" mathvariant="bold-italic">ϵ</mi><mo id="S2.Ex2.m1.3.3.3.5.2.2">,</mo><mn id="S2.Ex2.m1.3.3.3.3">1</mn></mrow><mo id="S2.Ex2.m1.3.3.3.6">≤</mo><mi id="S2.Ex2.m1.3.3.3.7">t</mi><mo id="S2.Ex2.m1.3.3.3.8">≤</mo><mi id="S2.Ex2.m1.3.3.3.9">T</mi></mrow></msub><mrow id="S2.Ex2.m1.3.7"><mo id="S2.Ex2.m1.3.7.1" maxsize="160%" minsize="160%">[</mo><mo fence="false" id="S2.Ex2.m1.3.7.2" rspace="0.167em" stretchy="false">|</mo><mo fence="false" id="S2.Ex2.m1.3.7.3" rspace="0.167em" stretchy="false">|</mo><msub id="S2.Ex2.m1.3.7.4"><mi id="S2.Ex2.m1.3.7.4.2">𝒈</mi><mi id="S2.Ex2.m1.3.7.4.3">ϕ</mi></msub><mrow id="S2.Ex2.m1.3.7.5"><mo id="S2.Ex2.m1.3.7.5.1" stretchy="false">(</mo><msub id="S2.Ex2.m1.3.7.5.2"><mi id="S2.Ex2.m1.3.7.5.2.2">𝒙</mi><mi id="S2.Ex2.m1.3.7.5.2.3">t</mi></msub><mo fence="false" id="S2.Ex2.m1.3.7.5.3" rspace="0.167em" stretchy="false">|</mo><mi id="S2.Ex2.m1.3.7.5.4">t</mi><mo id="S2.Ex2.m1.3.7.5.5" stretchy="false">)</mo></mrow><mo id="S2.Ex2.m1.3.7.6">−</mo><msub id="S2.Ex2.m1.3.7.7"><mi id="S2.Ex2.m1.3.7.7.2">𝒚</mi><mi id="S2.Ex2.m1.3.7.7.3">t</mi></msub><mo fence="false" id="S2.Ex2.m1.3.7.8" rspace="0.167em" stretchy="false">|</mo><msubsup id="S2.Ex2.m1.3.7.9"><mo fence="false" id="S2.Ex2.m1.3.7.9.2.2" rspace="0.167em" stretchy="false">|</mo><mn id="S2.Ex2.m1.3.7.9.2.3">2</mn><mn id="S2.Ex2.m1.3.7.9.3">2</mn></msubsup><mo id="S2.Ex2.m1.3.7.10" maxsize="160%" minsize="160%" rspace="0.110em">]</mo></mrow><mo id="S2.Ex2.m1.3.8">,</mo></mrow><annotation encoding="application/x-tex" id="S2.Ex2.m1.3c">\mathcal{L}_{\mathrm{Diffusion}}=\mathbb{E}_{\boldsymbol{x},\boldsymbol{%
\epsilon},1\leq t\leq T}\Big{[}||\boldsymbol{g}_{\phi}(\boldsymbol{x}_{t}|t)-%
\boldsymbol{y}_{t}||_{2}^{2}\Big{]}\,,</annotation><annotation encoding="application/x-llamapun" id="S2.Ex2.m1.3d">caligraphic_L start_POSTSUBSCRIPT roman_Diffusion end_POSTSUBSCRIPT = blackboard_E start_POSTSUBSCRIPT bold_italic_x , bold_italic_ϵ , 1 ≤ italic_t ≤ italic_T end_POSTSUBSCRIPT [ | | bold_italic_g start_POSTSUBSCRIPT italic_ϕ end_POSTSUBSCRIPT ( bold_italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | italic_t ) - bold_italic_y start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | | start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT ] ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S2.SS4.p1.13">in which target <math alttext="\boldsymbol{y}_{t}" class="ltx_Math" display="inline" id="S2.SS4.p1.5.m1.1"><semantics id="S2.SS4.p1.5.m1.1a"><msub id="S2.SS4.p1.5.m1.1.1" xref="S2.SS4.p1.5.m1.1.1.cmml"><mi id="S2.SS4.p1.5.m1.1.1.2" xref="S2.SS4.p1.5.m1.1.1.2.cmml">𝒚</mi><mi id="S2.SS4.p1.5.m1.1.1.3" xref="S2.SS4.p1.5.m1.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.5.m1.1b"><apply id="S2.SS4.p1.5.m1.1.1.cmml" xref="S2.SS4.p1.5.m1.1.1"><csymbol cd="ambiguous" id="S2.SS4.p1.5.m1.1.1.1.cmml" xref="S2.SS4.p1.5.m1.1.1">subscript</csymbol><ci id="S2.SS4.p1.5.m1.1.1.2.cmml" xref="S2.SS4.p1.5.m1.1.1.2">𝒚</ci><ci id="S2.SS4.p1.5.m1.1.1.3.cmml" xref="S2.SS4.p1.5.m1.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.5.m1.1c">\boldsymbol{y}_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.5.m1.1d">bold_italic_y start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> is often set to <math alttext="\boldsymbol{\epsilon}" class="ltx_Math" display="inline" id="S2.SS4.p1.6.m2.1"><semantics id="S2.SS4.p1.6.m2.1a"><mi class="ltx_mathvariant_bold-italic" id="S2.SS4.p1.6.m2.1.1" mathvariant="bold-italic" xref="S2.SS4.p1.6.m2.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.6.m2.1b"><ci id="S2.SS4.p1.6.m2.1.1.cmml" xref="S2.SS4.p1.6.m2.1.1">bold-italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.6.m2.1c">\boldsymbol{\epsilon}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.6.m2.1d">bold_italic_ϵ</annotation></semantics></math>.
After training, sampling can be performed step-by-step, by predicting <math alttext="\boldsymbol{x}_{t-1}" class="ltx_Math" display="inline" id="S2.SS4.p1.7.m3.1"><semantics id="S2.SS4.p1.7.m3.1a"><msub id="S2.SS4.p1.7.m3.1.1" xref="S2.SS4.p1.7.m3.1.1.cmml"><mi id="S2.SS4.p1.7.m3.1.1.2" xref="S2.SS4.p1.7.m3.1.1.2.cmml">𝒙</mi><mrow id="S2.SS4.p1.7.m3.1.1.3" xref="S2.SS4.p1.7.m3.1.1.3.cmml"><mi id="S2.SS4.p1.7.m3.1.1.3.2" xref="S2.SS4.p1.7.m3.1.1.3.2.cmml">t</mi><mo id="S2.SS4.p1.7.m3.1.1.3.1" xref="S2.SS4.p1.7.m3.1.1.3.1.cmml">−</mo><mn id="S2.SS4.p1.7.m3.1.1.3.3" xref="S2.SS4.p1.7.m3.1.1.3.3.cmml">1</mn></mrow></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.7.m3.1b"><apply id="S2.SS4.p1.7.m3.1.1.cmml" xref="S2.SS4.p1.7.m3.1.1"><csymbol cd="ambiguous" id="S2.SS4.p1.7.m3.1.1.1.cmml" xref="S2.SS4.p1.7.m3.1.1">subscript</csymbol><ci id="S2.SS4.p1.7.m3.1.1.2.cmml" xref="S2.SS4.p1.7.m3.1.1.2">𝒙</ci><apply id="S2.SS4.p1.7.m3.1.1.3.cmml" xref="S2.SS4.p1.7.m3.1.1.3"><minus id="S2.SS4.p1.7.m3.1.1.3.1.cmml" xref="S2.SS4.p1.7.m3.1.1.3.1"></minus><ci id="S2.SS4.p1.7.m3.1.1.3.2.cmml" xref="S2.SS4.p1.7.m3.1.1.3.2">𝑡</ci><cn id="S2.SS4.p1.7.m3.1.1.3.3.cmml" type="integer" xref="S2.SS4.p1.7.m3.1.1.3.3">1</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.7.m3.1c">\boldsymbol{x}_{t-1}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.7.m3.1d">bold_italic_x start_POSTSUBSCRIPT italic_t - 1 end_POSTSUBSCRIPT</annotation></semantics></math> from <math alttext="\boldsymbol{x}_{t}" class="ltx_Math" display="inline" id="S2.SS4.p1.8.m4.1"><semantics id="S2.SS4.p1.8.m4.1a"><msub id="S2.SS4.p1.8.m4.1.1" xref="S2.SS4.p1.8.m4.1.1.cmml"><mi id="S2.SS4.p1.8.m4.1.1.2" xref="S2.SS4.p1.8.m4.1.1.2.cmml">𝒙</mi><mi id="S2.SS4.p1.8.m4.1.1.3" xref="S2.SS4.p1.8.m4.1.1.3.cmml">t</mi></msub><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.8.m4.1b"><apply id="S2.SS4.p1.8.m4.1.1.cmml" xref="S2.SS4.p1.8.m4.1.1"><csymbol cd="ambiguous" id="S2.SS4.p1.8.m4.1.1.1.cmml" xref="S2.SS4.p1.8.m4.1.1">subscript</csymbol><ci id="S2.SS4.p1.8.m4.1.1.2.cmml" xref="S2.SS4.p1.8.m4.1.1.2">𝒙</ci><ci id="S2.SS4.p1.8.m4.1.1.3.cmml" xref="S2.SS4.p1.8.m4.1.1.3">𝑡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.8.m4.1c">\boldsymbol{x}_{t}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.8.m4.1d">bold_italic_x start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> for each timestep <math alttext="t" class="ltx_Math" display="inline" id="S2.SS4.p1.9.m5.1"><semantics id="S2.SS4.p1.9.m5.1a"><mi id="S2.SS4.p1.9.m5.1.1" xref="S2.SS4.p1.9.m5.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.9.m5.1b"><ci id="S2.SS4.p1.9.m5.1.1.cmml" xref="S2.SS4.p1.9.m5.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.9.m5.1c">t</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.9.m5.1d">italic_t</annotation></semantics></math> which is expensive since <math alttext="T" class="ltx_Math" display="inline" id="S2.SS4.p1.10.m6.1"><semantics id="S2.SS4.p1.10.m6.1a"><mi id="S2.SS4.p1.10.m6.1.1" xref="S2.SS4.p1.10.m6.1.1.cmml">T</mi><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.10.m6.1b"><ci id="S2.SS4.p1.10.m6.1.1.cmml" xref="S2.SS4.p1.10.m6.1.1">𝑇</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.10.m6.1c">T</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.10.m6.1d">italic_T</annotation></semantics></math> can be high (e.g., 1000); faster alternatives include deterministic DDIM <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx54" title="">SME20</a>]</cite> sampling, that can perform sampling of comparable quality with fewer steps (i.e., <math alttext="10" class="ltx_Math" display="inline" id="S2.SS4.p1.11.m7.1"><semantics id="S2.SS4.p1.11.m7.1a"><mn id="S2.SS4.p1.11.m7.1.1" xref="S2.SS4.p1.11.m7.1.1.cmml">10</mn><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.11.m7.1b"><cn id="S2.SS4.p1.11.m7.1.1.cmml" type="integer" xref="S2.SS4.p1.11.m7.1.1">10</cn></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.11.m7.1c">10</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.11.m7.1d">10</annotation></semantics></math>-<math alttext="50\times" class="ltx_math_unparsed" display="inline" id="S2.SS4.p1.12.m8.1"><semantics id="S2.SS4.p1.12.m8.1a"><mrow id="S2.SS4.p1.12.m8.1b"><mn id="S2.SS4.p1.12.m8.1.1">50</mn><mo id="S2.SS4.p1.12.m8.1.2" lspace="0.222em">×</mo></mrow><annotation encoding="application/x-tex" id="S2.SS4.p1.12.m8.1c">50\times</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.12.m8.1d">50 ×</annotation></semantics></math> larger steps).
Stable Diffusion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx45" title="">RBL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>22</a>]</cite> performs denoising in a lower-dimensional latent space, by first training a variational encoder to compress images; for instance, in Stable Diffusion XL <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx40" title="">PEL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite>, images are mapped to a latent space of size <math alttext="\mathbb{R}^{128\times 128\times 4}" class="ltx_Math" display="inline" id="S2.SS4.p1.13.m9.1"><semantics id="S2.SS4.p1.13.m9.1a"><msup id="S2.SS4.p1.13.m9.1.1" xref="S2.SS4.p1.13.m9.1.1.cmml"><mi id="S2.SS4.p1.13.m9.1.1.2" xref="S2.SS4.p1.13.m9.1.1.2.cmml">ℝ</mi><mrow id="S2.SS4.p1.13.m9.1.1.3" xref="S2.SS4.p1.13.m9.1.1.3.cmml"><mn id="S2.SS4.p1.13.m9.1.1.3.2" xref="S2.SS4.p1.13.m9.1.1.3.2.cmml">128</mn><mo id="S2.SS4.p1.13.m9.1.1.3.1" lspace="0.222em" rspace="0.222em" xref="S2.SS4.p1.13.m9.1.1.3.1.cmml">×</mo><mn id="S2.SS4.p1.13.m9.1.1.3.3" xref="S2.SS4.p1.13.m9.1.1.3.3.cmml">128</mn><mo id="S2.SS4.p1.13.m9.1.1.3.1a" lspace="0.222em" rspace="0.222em" xref="S2.SS4.p1.13.m9.1.1.3.1.cmml">×</mo><mn id="S2.SS4.p1.13.m9.1.1.3.4" xref="S2.SS4.p1.13.m9.1.1.3.4.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S2.SS4.p1.13.m9.1b"><apply id="S2.SS4.p1.13.m9.1.1.cmml" xref="S2.SS4.p1.13.m9.1.1"><csymbol cd="ambiguous" id="S2.SS4.p1.13.m9.1.1.1.cmml" xref="S2.SS4.p1.13.m9.1.1">superscript</csymbol><ci id="S2.SS4.p1.13.m9.1.1.2.cmml" xref="S2.SS4.p1.13.m9.1.1.2">ℝ</ci><apply id="S2.SS4.p1.13.m9.1.1.3.cmml" xref="S2.SS4.p1.13.m9.1.1.3"><times id="S2.SS4.p1.13.m9.1.1.3.1.cmml" xref="S2.SS4.p1.13.m9.1.1.3.1"></times><cn id="S2.SS4.p1.13.m9.1.1.3.2.cmml" type="integer" xref="S2.SS4.p1.13.m9.1.1.3.2">128</cn><cn id="S2.SS4.p1.13.m9.1.1.3.3.cmml" type="integer" xref="S2.SS4.p1.13.m9.1.1.3.3">128</cn><cn id="S2.SS4.p1.13.m9.1.1.3.4.cmml" type="integer" xref="S2.SS4.p1.13.m9.1.1.3.4">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS4.p1.13.m9.1c">\mathbb{R}^{128\times 128\times 4}</annotation><annotation encoding="application/x-llamapun" id="S2.SS4.p1.13.m9.1d">blackboard_R start_POSTSUPERSCRIPT 128 × 128 × 4 end_POSTSUPERSCRIPT</annotation></semantics></math>.
In a pre-pass, the dataset is compressed using this autoencoder, and a text-conditioned diffusion model is then trained directly in this latent space.</p>
</div>
<div class="ltx_para" id="S2.SS4.p2">
<p class="ltx_p" id="S2.SS4.p2.1">Diffusion models have an impressive capacity to synthesize highly realistic images, typically conditioned on text prompts. The power of DMs lies in the fact that the billions of images used for training contain an extremely rich representation of the visual world.
However, <em class="ltx_emph ltx_font_italic" id="S2.SS4.p2.1.1">extracting</em> the required information for specific tasks, without incurring the (unrealistic) cost of retraining DMs is not straightforward.
A set of recent methods show that it is possible to fine-tune DMs with a typically much shorter training process to perform specific tasks (e.g., <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx12" title="">GAA<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx47" title="">RLJ<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite>).
A notable example is ControlNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx78" title="">ZRA23</a>]</cite> which proposed an efficient method for fine-tuning Stable Diffusion with added conditioning.
In particular, they demonstrated conditional generation from depth, Canny edges, etc., with and without text prompts; We will build on this solution for our 2D relighting method.</p>
</div>
<div class="ltx_para" id="S2.SS4.p3">
<p class="ltx_p" id="S2.SS4.p3.1">In a similar spirit, there has been significant evidence in recent years that latent spaces of generative models encode material information <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx5" title="">BMHF23</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx3" title="">BF24</a>]</cite>.
Recent work shows the potential to fine-tune DMs to allow direct material editing  <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx51" title="">SJL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite>.
Nonetheless, we are unaware of published methods that use DM fine-tuning to perform realistic relighting of full and cluttered scenes.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Method</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">Our method is composed of three main parts. First, we create a 2D relighting neural network with direct control of lighting direction (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.SS1" title="3.1 Single-View Relighting with 2D Diffusion Priors ‣ 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">3.1</span></a>).
Second, we use this network to augment a multi-view capture with single lighting into a multi-lighting dataset, by using our relighting network.
The resulting dataset can be used to create a radiance field representation of the 3D scene (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.SS2" title="3.2 Augmenting Multi-View/Single-Lighting Datasets ‣ 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">3.2</span></a>).
Finally, we create a relightable radiance field that accounts for inaccuracies in the synthesized relit input images and provides a multi-view consistent lighting solution (Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.SS3" title="3.3 Training a Lighting-Consistent Radiance Field ‣ 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">3.3</span></a>).</p>
</div>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Single-View Relighting with 2D Diffusion Priors</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">Relighting a scene captured under a single lighting condition is severely underconstrained, given the lighting/material ambiguity, and thus requires priors about how appearance changes with illumination.
Arguably, large DMs must internally encode such priors since they can generate realistic complex lighting effects, but existing architectures do not allow for explicit control over lighting.</p>
</div>
<div class="ltx_para" id="S3.SS1.p2">
<p class="ltx_p" id="S3.SS1.p2.2">We propose to provide explicit control over lighting by fine-tuning a pre-trained Stable Diffusion (SD) <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx45" title="">RBL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>22</a>]</cite> model using ControlNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx78" title="">ZRA23</a>]</cite> on a multi-illumination dataset.
As illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S2.F1" title="Figure 1 ‣ 2.3 Multi-view Relighting ‣ 2 Related Work ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">1</span></a>, the ControlNet accepts as input an image as well as a target light direction, and produces a relit version of the same scene under the desired lighting.
To train the ControlNet, we leverage the dataset of Murmann et al. <span class="ltx_ERROR undefined" id="S3.SS1.p2.2.1">\shortcite</span>multilum, which contains <math alttext="N=1015" class="ltx_Math" display="inline" id="S3.SS1.p2.1.m1.1"><semantics id="S3.SS1.p2.1.m1.1a"><mrow id="S3.SS1.p2.1.m1.1.1" xref="S3.SS1.p2.1.m1.1.1.cmml"><mi id="S3.SS1.p2.1.m1.1.1.2" xref="S3.SS1.p2.1.m1.1.1.2.cmml">N</mi><mo id="S3.SS1.p2.1.m1.1.1.1" xref="S3.SS1.p2.1.m1.1.1.1.cmml">=</mo><mn id="S3.SS1.p2.1.m1.1.1.3" xref="S3.SS1.p2.1.m1.1.1.3.cmml">1015</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.1.m1.1b"><apply id="S3.SS1.p2.1.m1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1"><eq id="S3.SS1.p2.1.m1.1.1.1.cmml" xref="S3.SS1.p2.1.m1.1.1.1"></eq><ci id="S3.SS1.p2.1.m1.1.1.2.cmml" xref="S3.SS1.p2.1.m1.1.1.2">𝑁</ci><cn id="S3.SS1.p2.1.m1.1.1.3.cmml" type="integer" xref="S3.SS1.p2.1.m1.1.1.3">1015</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.1.m1.1c">N=1015</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.1.m1.1d">italic_N = 1015</annotation></semantics></math> real indoor scenes captured from a single viewpoint, each lit under <math alttext="M=25" class="ltx_Math" display="inline" id="S3.SS1.p2.2.m2.1"><semantics id="S3.SS1.p2.2.m2.1a"><mrow id="S3.SS1.p2.2.m2.1.1" xref="S3.SS1.p2.2.m2.1.1.cmml"><mi id="S3.SS1.p2.2.m2.1.1.2" xref="S3.SS1.p2.2.m2.1.1.2.cmml">M</mi><mo id="S3.SS1.p2.2.m2.1.1.1" xref="S3.SS1.p2.2.m2.1.1.1.cmml">=</mo><mn id="S3.SS1.p2.2.m2.1.1.3" xref="S3.SS1.p2.2.m2.1.1.3.cmml">25</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.p2.2.m2.1b"><apply id="S3.SS1.p2.2.m2.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1"><eq id="S3.SS1.p2.2.m2.1.1.1.cmml" xref="S3.SS1.p2.2.m2.1.1.1"></eq><ci id="S3.SS1.p2.2.m2.1.1.2.cmml" xref="S3.SS1.p2.2.m2.1.1.2">𝑀</ci><cn id="S3.SS1.p2.2.m2.1.1.3.cmml" type="integer" xref="S3.SS1.p2.2.m2.1.1.3">25</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.p2.2.m2.1c">M=25</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.p2.2.m2.1d">italic_M = 25</annotation></semantics></math> different, controlled lighting directions. We only keep the 18 non-front facing light directions.</p>
</div>
<section class="ltx_subsubsection" id="S3.SS1.SSS1">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Lighting Direction</h4>
<figure class="ltx_figure" id="S3.F2"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="240" id="S3.F2.g1" src="extracted/5860470/figures/directions.jpg" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Top row: five diffuse sphere rendered by our optimized lighting direction and shading parameters — the direction is indicated by a blue dot at the point of maximum specular intensity; Bottom row: the corresponding target gray spheres obtained by averaging the diffuse spheres captured in all spheres. We found the lighting directions by minimizing the <math alttext="L_{1}" class="ltx_Math" display="inline" id="S3.F2.2.m1.1"><semantics id="S3.F2.2.m1.1b"><msub id="S3.F2.2.m1.1.1" xref="S3.F2.2.m1.1.1.cmml"><mi id="S3.F2.2.m1.1.1.2" xref="S3.F2.2.m1.1.1.2.cmml">L</mi><mn id="S3.F2.2.m1.1.1.3" xref="S3.F2.2.m1.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.F2.2.m1.1c"><apply id="S3.F2.2.m1.1.1.cmml" xref="S3.F2.2.m1.1.1"><csymbol cd="ambiguous" id="S3.F2.2.m1.1.1.1.cmml" xref="S3.F2.2.m1.1.1">subscript</csymbol><ci id="S3.F2.2.m1.1.1.2.cmml" xref="S3.F2.2.m1.1.1.2">𝐿</ci><cn id="S3.F2.2.m1.1.1.3.cmml" type="integer" xref="S3.F2.2.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.2.m1.1d">L_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.F2.2.m1.1e">italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> distance between the top and bottom row.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.SSS1.p1">
<p class="ltx_p" id="S3.SS1.SSS1.p1.2">To capture the scenes using similar light directions, Murmann et al. relied on a camera-mounted directional flash controlled by a servo motor.
A pair of diffuse and metallic spheres are also visible in each scene; we leverage the former to obtain the effective lighting directions. Using as target the average of all diffuse spheres produced by the same flash direction, we find the lighting direction <math alttext="l\in\mathbb{R}^{3}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p1.1.m1.1"><semantics id="S3.SS1.SSS1.p1.1.m1.1a"><mrow id="S3.SS1.SSS1.p1.1.m1.1.1" xref="S3.SS1.SSS1.p1.1.m1.1.1.cmml"><mi id="S3.SS1.SSS1.p1.1.m1.1.1.2" xref="S3.SS1.SSS1.p1.1.m1.1.1.2.cmml">l</mi><mo id="S3.SS1.SSS1.p1.1.m1.1.1.1" xref="S3.SS1.SSS1.p1.1.m1.1.1.1.cmml">∈</mo><msup id="S3.SS1.SSS1.p1.1.m1.1.1.3" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.cmml"><mi id="S3.SS1.SSS1.p1.1.m1.1.1.3.2" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.2.cmml">ℝ</mi><mn id="S3.SS1.SSS1.p1.1.m1.1.1.3.3" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.3.cmml">3</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.1.m1.1b"><apply id="S3.SS1.SSS1.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1"><in id="S3.SS1.SSS1.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.1"></in><ci id="S3.SS1.SSS1.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.2">𝑙</ci><apply id="S3.SS1.SSS1.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p1.1.m1.1.1.3.1.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.3">superscript</csymbol><ci id="S3.SS1.SSS1.p1.1.m1.1.1.3.2.cmml" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.2">ℝ</ci><cn id="S3.SS1.SSS1.p1.1.m1.1.1.3.3.cmml" type="integer" xref="S3.SS1.SSS1.p1.1.m1.1.1.3.3">3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.1.m1.1c">l\in\mathbb{R}^{3}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p1.1.m1.1d">italic_l ∈ blackboard_R start_POSTSUPERSCRIPT 3 end_POSTSUPERSCRIPT</annotation></semantics></math> which best reproduces this target when rendering a gray ball with a simplistic Phong shading model. More specifically, we minimize the <math alttext="L_{1}" class="ltx_Math" display="inline" id="S3.SS1.SSS1.p1.2.m2.1"><semantics id="S3.SS1.SSS1.p1.2.m2.1a"><msub id="S3.SS1.SSS1.p1.2.m2.1.1" xref="S3.SS1.SSS1.p1.2.m2.1.1.cmml"><mi id="S3.SS1.SSS1.p1.2.m2.1.1.2" xref="S3.SS1.SSS1.p1.2.m2.1.1.2.cmml">L</mi><mn id="S3.SS1.SSS1.p1.2.m2.1.1.3" xref="S3.SS1.SSS1.p1.2.m2.1.1.3.cmml">1</mn></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS1.p1.2.m2.1b"><apply id="S3.SS1.SSS1.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS1.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS1.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS1.p1.2.m2.1.1.2">𝐿</ci><cn id="S3.SS1.SSS1.p1.2.m2.1.1.3.cmml" type="integer" xref="S3.SS1.SSS1.p1.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS1.p1.2.m2.1c">L_{1}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS1.p1.2.m2.1d">italic_L start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT</annotation></semantics></math> error when jointly optimizing for an ambient light term and shading parameters (albedo, specular intensity and hardness, as well as a Fresnel coefficient). Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.F2" title="Figure 2 ‣ 3.1.1 Lighting Direction ‣ 3.1 Single-View Relighting with 2D Diffusion Priors ‣ 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">2</span></a> illustrates this process.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS2">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>Controlling Relighting Diffusion</h4>
<div class="ltx_para" id="S3.SS1.SSS2.p1">
<p class="ltx_p" id="S3.SS1.SSS2.p1.3">We train ControlNet to predict relit versions of the input image by conditioning it on a target lighting direction. Let us denote a set <math alttext="\mathcal{X}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.1.m1.1"><semantics id="S3.SS1.SSS2.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS2.p1.1.m1.1.1" xref="S3.SS1.SSS2.p1.1.m1.1.1.cmml">𝒳</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.1.m1.1b"><ci id="S3.SS1.SSS2.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p1.1.m1.1.1">𝒳</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.1.m1.1c">\mathcal{X}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.1.m1.1d">caligraphic_X</annotation></semantics></math> of images of a given scene in the multi-light dataset of Murmann et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx35" title="">MGAD19</a>]</cite>, where each image <math alttext="\mathbf{X}_{k}\in\mathcal{X}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.2.m2.1"><semantics id="S3.SS1.SSS2.p1.2.m2.1a"><mrow id="S3.SS1.SSS2.p1.2.m2.1.1" xref="S3.SS1.SSS2.p1.2.m2.1.1.cmml"><msub id="S3.SS1.SSS2.p1.2.m2.1.1.2" xref="S3.SS1.SSS2.p1.2.m2.1.1.2.cmml"><mi id="S3.SS1.SSS2.p1.2.m2.1.1.2.2" xref="S3.SS1.SSS2.p1.2.m2.1.1.2.2.cmml">𝐗</mi><mi id="S3.SS1.SSS2.p1.2.m2.1.1.2.3" xref="S3.SS1.SSS2.p1.2.m2.1.1.2.3.cmml">k</mi></msub><mo id="S3.SS1.SSS2.p1.2.m2.1.1.1" xref="S3.SS1.SSS2.p1.2.m2.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS1.SSS2.p1.2.m2.1.1.3" xref="S3.SS1.SSS2.p1.2.m2.1.1.3.cmml">𝒳</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.2.m2.1b"><apply id="S3.SS1.SSS2.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1"><in id="S3.SS1.SSS2.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.1"></in><apply id="S3.SS1.SSS2.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.2.m2.1.1.2.1.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS2.p1.2.m2.1.1.2.2.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.2.2">𝐗</ci><ci id="S3.SS1.SSS2.p1.2.m2.1.1.2.3.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.2.3">𝑘</ci></apply><ci id="S3.SS1.SSS2.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS2.p1.2.m2.1.1.3">𝒳</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.2.m2.1c">\mathbf{X}_{k}\in\mathcal{X}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.2.m2.1d">bold_X start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT ∈ caligraphic_X</annotation></semantics></math> has associated light direction <math alttext="l_{k}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.3.m3.1"><semantics id="S3.SS1.SSS2.p1.3.m3.1a"><msub id="S3.SS1.SSS2.p1.3.m3.1.1" xref="S3.SS1.SSS2.p1.3.m3.1.1.cmml"><mi id="S3.SS1.SSS2.p1.3.m3.1.1.2" xref="S3.SS1.SSS2.p1.3.m3.1.1.2.cmml">l</mi><mi id="S3.SS1.SSS2.p1.3.m3.1.1.3" xref="S3.SS1.SSS2.p1.3.m3.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.3.m3.1b"><apply id="S3.SS1.SSS2.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.3.m3.1.1.1.cmml" xref="S3.SS1.SSS2.p1.3.m3.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p1.3.m3.1.1.2.cmml" xref="S3.SS1.SSS2.p1.3.m3.1.1.2">𝑙</ci><ci id="S3.SS1.SSS2.p1.3.m3.1.1.3.cmml" xref="S3.SS1.SSS2.p1.3.m3.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.3.m3.1c">l_{k}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.3.m3.1d">italic_l start_POSTSUBSCRIPT italic_k end_POSTSUBSCRIPT</annotation></semantics></math>.
Our approach, illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S2.F1" title="Figure 1 ‣ 2.3 Multi-view Relighting ‣ 2 Related Work ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">1</span></a>, trains on pairs of lighting directions of the same scene (including the identity pair).
The denoising objective becomes</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E1">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\mathcal{L}_{\mathrm{2D}}=\mathbb{E}_{\boldsymbol{\epsilon},\mathbf{X},t,i,j}%
\Big{[}||\boldsymbol{g}_{\psi}(\mathbf{X}_{t,i};t,\mathbf{X}_{j},\mathbf{D}_{j%
},\boldsymbol{l}_{i})-\boldsymbol{y}_{t}||^{2}_{2}\Big{]}\,," class="ltx_Math" display="block" id="S3.E1.m1.9"><semantics id="S3.E1.m1.9a"><mrow id="S3.E1.m1.9.9.1" xref="S3.E1.m1.9.9.1.1.cmml"><mrow id="S3.E1.m1.9.9.1.1" xref="S3.E1.m1.9.9.1.1.cmml"><msub id="S3.E1.m1.9.9.1.1.3" xref="S3.E1.m1.9.9.1.1.3.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.E1.m1.9.9.1.1.3.2" xref="S3.E1.m1.9.9.1.1.3.2.cmml">ℒ</mi><mrow id="S3.E1.m1.9.9.1.1.3.3" xref="S3.E1.m1.9.9.1.1.3.3.cmml"><mn id="S3.E1.m1.9.9.1.1.3.3.2" xref="S3.E1.m1.9.9.1.1.3.3.2.cmml">2</mn><mo id="S3.E1.m1.9.9.1.1.3.3.1" xref="S3.E1.m1.9.9.1.1.3.3.1.cmml">⁢</mo><mi id="S3.E1.m1.9.9.1.1.3.3.3" mathvariant="normal" xref="S3.E1.m1.9.9.1.1.3.3.3.cmml">D</mi></mrow></msub><mo id="S3.E1.m1.9.9.1.1.2" xref="S3.E1.m1.9.9.1.1.2.cmml">=</mo><mrow id="S3.E1.m1.9.9.1.1.1" xref="S3.E1.m1.9.9.1.1.1.cmml"><msub id="S3.E1.m1.9.9.1.1.1.3" xref="S3.E1.m1.9.9.1.1.1.3.cmml"><mi id="S3.E1.m1.9.9.1.1.1.3.2" xref="S3.E1.m1.9.9.1.1.1.3.2.cmml">𝔼</mi><mrow id="S3.E1.m1.5.5.5.7" xref="S3.E1.m1.5.5.5.6.cmml"><mi class="ltx_mathvariant_bold-italic" id="S3.E1.m1.1.1.1.1" mathvariant="bold-italic" xref="S3.E1.m1.1.1.1.1.cmml">ϵ</mi><mo id="S3.E1.m1.5.5.5.7.1" xref="S3.E1.m1.5.5.5.6.cmml">,</mo><mi id="S3.E1.m1.2.2.2.2" xref="S3.E1.m1.2.2.2.2.cmml">𝐗</mi><mo id="S3.E1.m1.5.5.5.7.2" xref="S3.E1.m1.5.5.5.6.cmml">,</mo><mi id="S3.E1.m1.3.3.3.3" xref="S3.E1.m1.3.3.3.3.cmml">t</mi><mo id="S3.E1.m1.5.5.5.7.3" xref="S3.E1.m1.5.5.5.6.cmml">,</mo><mi id="S3.E1.m1.4.4.4.4" xref="S3.E1.m1.4.4.4.4.cmml">i</mi><mo id="S3.E1.m1.5.5.5.7.4" xref="S3.E1.m1.5.5.5.6.cmml">,</mo><mi id="S3.E1.m1.5.5.5.5" xref="S3.E1.m1.5.5.5.5.cmml">j</mi></mrow></msub><mo id="S3.E1.m1.9.9.1.1.1.2" xref="S3.E1.m1.9.9.1.1.1.2.cmml">⁢</mo><mrow id="S3.E1.m1.9.9.1.1.1.1.1" xref="S3.E1.m1.9.9.1.1.1.1.2.cmml"><mo id="S3.E1.m1.9.9.1.1.1.1.1.2" maxsize="160%" minsize="160%" xref="S3.E1.m1.9.9.1.1.1.1.2.1.cmml">[</mo><msubsup id="S3.E1.m1.9.9.1.1.1.1.1.1" xref="S3.E1.m1.9.9.1.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.2.cmml"><mo id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.2" stretchy="false" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.2.1.cmml">‖</mo><mrow id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.cmml"><mrow id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.cmml"><msub id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.6" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.6.cmml"><mi id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.6.2" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.6.2.cmml">𝒈</mi><mi id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.6.3" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.6.3.cmml">ψ</mi></msub><mo id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.5" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.5.cmml">⁢</mo><mrow id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.5.cmml"><mo id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4.5" stretchy="false" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.5.cmml">(</mo><msub id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml"><mi id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml">𝐗</mi><mrow id="S3.E1.m1.7.7.2.4" xref="S3.E1.m1.7.7.2.3.cmml"><mi id="S3.E1.m1.6.6.1.1" xref="S3.E1.m1.6.6.1.1.cmml">t</mi><mo id="S3.E1.m1.7.7.2.4.1" xref="S3.E1.m1.7.7.2.3.cmml">,</mo><mi id="S3.E1.m1.7.7.2.2" xref="S3.E1.m1.7.7.2.2.cmml">i</mi></mrow></msub><mo id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4.6" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.5.cmml">;</mo><mi id="S3.E1.m1.8.8" xref="S3.E1.m1.8.8.cmml">t</mi><mo id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4.7" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.5.cmml">,</mo><msub id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.2.2.2.2" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml"><mi id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.2.2.2.2.2" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml">𝐗</mi><mi id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.cmml">j</mi></msub><mo id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4.8" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.5.cmml">,</mo><msub id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.3.3.3.3" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.3.3.3.3.cmml"><mi id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.3.3.3.3.2" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.3.3.3.3.2.cmml">𝐃</mi><mi id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.3.3.3.3.3" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.3.3.3.3.3.cmml">j</mi></msub><mo id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4.9" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.5.cmml">,</mo><msub id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4.4" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4.4.cmml"><mi id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4.4.2" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4.4.2.cmml">𝒍</mi><mi id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4.4.3" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4.4.3.cmml">i</mi></msub><mo id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4.10" stretchy="false" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.5.cmml">)</mo></mrow></mrow><mo id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.5" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.5.cmml">−</mo><msub id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.6" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.6.cmml"><mi id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.6.2" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.6.2.cmml">𝒚</mi><mi id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.6.3" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.6.3.cmml">t</mi></msub></mrow><mo id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.3" stretchy="false" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.2.1.cmml">‖</mo></mrow><mn id="S3.E1.m1.9.9.1.1.1.1.1.1.3" xref="S3.E1.m1.9.9.1.1.1.1.1.1.3.cmml">2</mn><mn id="S3.E1.m1.9.9.1.1.1.1.1.1.1.3" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.3.cmml">2</mn></msubsup><mo id="S3.E1.m1.9.9.1.1.1.1.1.3" maxsize="160%" minsize="160%" rspace="0.110em" xref="S3.E1.m1.9.9.1.1.1.1.2.1.cmml">]</mo></mrow></mrow></mrow><mo id="S3.E1.m1.9.9.1.2" xref="S3.E1.m1.9.9.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.9b"><apply id="S3.E1.m1.9.9.1.1.cmml" xref="S3.E1.m1.9.9.1"><eq id="S3.E1.m1.9.9.1.1.2.cmml" xref="S3.E1.m1.9.9.1.1.2"></eq><apply id="S3.E1.m1.9.9.1.1.3.cmml" xref="S3.E1.m1.9.9.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.9.9.1.1.3.1.cmml" xref="S3.E1.m1.9.9.1.1.3">subscript</csymbol><ci id="S3.E1.m1.9.9.1.1.3.2.cmml" xref="S3.E1.m1.9.9.1.1.3.2">ℒ</ci><apply id="S3.E1.m1.9.9.1.1.3.3.cmml" xref="S3.E1.m1.9.9.1.1.3.3"><times id="S3.E1.m1.9.9.1.1.3.3.1.cmml" xref="S3.E1.m1.9.9.1.1.3.3.1"></times><cn id="S3.E1.m1.9.9.1.1.3.3.2.cmml" type="integer" xref="S3.E1.m1.9.9.1.1.3.3.2">2</cn><ci id="S3.E1.m1.9.9.1.1.3.3.3.cmml" xref="S3.E1.m1.9.9.1.1.3.3.3">D</ci></apply></apply><apply id="S3.E1.m1.9.9.1.1.1.cmml" xref="S3.E1.m1.9.9.1.1.1"><times id="S3.E1.m1.9.9.1.1.1.2.cmml" xref="S3.E1.m1.9.9.1.1.1.2"></times><apply id="S3.E1.m1.9.9.1.1.1.3.cmml" xref="S3.E1.m1.9.9.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.9.9.1.1.1.3.1.cmml" xref="S3.E1.m1.9.9.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.9.9.1.1.1.3.2.cmml" xref="S3.E1.m1.9.9.1.1.1.3.2">𝔼</ci><list id="S3.E1.m1.5.5.5.6.cmml" xref="S3.E1.m1.5.5.5.7"><ci id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1">bold-italic-ϵ</ci><ci id="S3.E1.m1.2.2.2.2.cmml" xref="S3.E1.m1.2.2.2.2">𝐗</ci><ci id="S3.E1.m1.3.3.3.3.cmml" xref="S3.E1.m1.3.3.3.3">𝑡</ci><ci id="S3.E1.m1.4.4.4.4.cmml" xref="S3.E1.m1.4.4.4.4">𝑖</ci><ci id="S3.E1.m1.5.5.5.5.cmml" xref="S3.E1.m1.5.5.5.5">𝑗</ci></list></apply><apply id="S3.E1.m1.9.9.1.1.1.1.2.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.9.9.1.1.1.1.2.1.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.E1.m1.9.9.1.1.1.1.1.1.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.9.9.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1">subscript</csymbol><apply id="S3.E1.m1.9.9.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.9.9.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1">superscript</csymbol><apply id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1"><csymbol cd="latexml" id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.2">norm</csymbol><apply id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1"><minus id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.5.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.5"></minus><apply id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4"><times id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.5.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.5"></times><apply id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.6.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.6"><csymbol cd="ambiguous" id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.6.1.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.6">subscript</csymbol><ci id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.6.2.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.6.2">𝒈</ci><ci id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.6.3.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.6.3">𝜓</ci></apply><list id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.5.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4"><apply id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.1.1.1.1.2">𝐗</ci><list id="S3.E1.m1.7.7.2.3.cmml" xref="S3.E1.m1.7.7.2.4"><ci id="S3.E1.m1.6.6.1.1.cmml" xref="S3.E1.m1.6.6.1.1">𝑡</ci><ci id="S3.E1.m1.7.7.2.2.cmml" xref="S3.E1.m1.7.7.2.2">𝑖</ci></list></apply><ci id="S3.E1.m1.8.8.cmml" xref="S3.E1.m1.8.8">𝑡</ci><apply id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.2.2.2.2.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.2.2.2.2.1.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.2.2.2.2">subscript</csymbol><ci id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.2.2.2.2.2.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.2.2.2.2.2">𝐗</ci><ci id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.2.2.2.2.3">𝑗</ci></apply><apply id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.3.3.3.3.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.3.3.3.3"><csymbol cd="ambiguous" id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.3.3.3.3.1.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.3.3.3.3">subscript</csymbol><ci id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.3.3.3.3.2.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.3.3.3.3.2">𝐃</ci><ci id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.3.3.3.3.3.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.3.3.3.3.3">𝑗</ci></apply><apply id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4.4.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4.4"><csymbol cd="ambiguous" id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4.4.1.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4.4">subscript</csymbol><ci id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4.4.2.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4.4.2">𝒍</ci><ci id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4.4.3.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.4.4.4.4.3">𝑖</ci></apply></list></apply><apply id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.6.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.6"><csymbol cd="ambiguous" id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.6.1.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.6">subscript</csymbol><ci id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.6.2.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.6.2">𝒚</ci><ci id="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.6.3.cmml" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.1.1.1.6.3">𝑡</ci></apply></apply></apply><cn id="S3.E1.m1.9.9.1.1.1.1.1.1.1.3.cmml" type="integer" xref="S3.E1.m1.9.9.1.1.1.1.1.1.1.3">2</cn></apply><cn id="S3.E1.m1.9.9.1.1.1.1.1.1.3.cmml" type="integer" xref="S3.E1.m1.9.9.1.1.1.1.1.1.3">2</cn></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.9c">\mathcal{L}_{\mathrm{2D}}=\mathbb{E}_{\boldsymbol{\epsilon},\mathbf{X},t,i,j}%
\Big{[}||\boldsymbol{g}_{\psi}(\mathbf{X}_{t,i};t,\mathbf{X}_{j},\mathbf{D}_{j%
},\boldsymbol{l}_{i})-\boldsymbol{y}_{t}||^{2}_{2}\Big{]}\,,</annotation><annotation encoding="application/x-llamapun" id="S3.E1.m1.9d">caligraphic_L start_POSTSUBSCRIPT 2 roman_D end_POSTSUBSCRIPT = blackboard_E start_POSTSUBSCRIPT bold_italic_ϵ , bold_X , italic_t , italic_i , italic_j end_POSTSUBSCRIPT [ | | bold_italic_g start_POSTSUBSCRIPT italic_ψ end_POSTSUBSCRIPT ( bold_X start_POSTSUBSCRIPT italic_t , italic_i end_POSTSUBSCRIPT ; italic_t , bold_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , bold_D start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT , bold_italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ) - bold_italic_y start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT | | start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT ] ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS1.SSS2.p1.13">where <math alttext="\mathbf{X}_{t,i}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.4.m1.2"><semantics id="S3.SS1.SSS2.p1.4.m1.2a"><msub id="S3.SS1.SSS2.p1.4.m1.2.3" xref="S3.SS1.SSS2.p1.4.m1.2.3.cmml"><mi id="S3.SS1.SSS2.p1.4.m1.2.3.2" xref="S3.SS1.SSS2.p1.4.m1.2.3.2.cmml">𝐗</mi><mrow id="S3.SS1.SSS2.p1.4.m1.2.2.2.4" xref="S3.SS1.SSS2.p1.4.m1.2.2.2.3.cmml"><mi id="S3.SS1.SSS2.p1.4.m1.1.1.1.1" xref="S3.SS1.SSS2.p1.4.m1.1.1.1.1.cmml">t</mi><mo id="S3.SS1.SSS2.p1.4.m1.2.2.2.4.1" xref="S3.SS1.SSS2.p1.4.m1.2.2.2.3.cmml">,</mo><mi id="S3.SS1.SSS2.p1.4.m1.2.2.2.2" xref="S3.SS1.SSS2.p1.4.m1.2.2.2.2.cmml">i</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.4.m1.2b"><apply id="S3.SS1.SSS2.p1.4.m1.2.3.cmml" xref="S3.SS1.SSS2.p1.4.m1.2.3"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.4.m1.2.3.1.cmml" xref="S3.SS1.SSS2.p1.4.m1.2.3">subscript</csymbol><ci id="S3.SS1.SSS2.p1.4.m1.2.3.2.cmml" xref="S3.SS1.SSS2.p1.4.m1.2.3.2">𝐗</ci><list id="S3.SS1.SSS2.p1.4.m1.2.2.2.3.cmml" xref="S3.SS1.SSS2.p1.4.m1.2.2.2.4"><ci id="S3.SS1.SSS2.p1.4.m1.1.1.1.1.cmml" xref="S3.SS1.SSS2.p1.4.m1.1.1.1.1">𝑡</ci><ci id="S3.SS1.SSS2.p1.4.m1.2.2.2.2.cmml" xref="S3.SS1.SSS2.p1.4.m1.2.2.2.2">𝑖</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.4.m1.2c">\mathbf{X}_{t,i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.4.m1.2d">bold_X start_POSTSUBSCRIPT italic_t , italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is the noisy image at timestep <math alttext="t\in[1,T]" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.5.m2.2"><semantics id="S3.SS1.SSS2.p1.5.m2.2a"><mrow id="S3.SS1.SSS2.p1.5.m2.2.3" xref="S3.SS1.SSS2.p1.5.m2.2.3.cmml"><mi id="S3.SS1.SSS2.p1.5.m2.2.3.2" xref="S3.SS1.SSS2.p1.5.m2.2.3.2.cmml">t</mi><mo id="S3.SS1.SSS2.p1.5.m2.2.3.1" xref="S3.SS1.SSS2.p1.5.m2.2.3.1.cmml">∈</mo><mrow id="S3.SS1.SSS2.p1.5.m2.2.3.3.2" xref="S3.SS1.SSS2.p1.5.m2.2.3.3.1.cmml"><mo id="S3.SS1.SSS2.p1.5.m2.2.3.3.2.1" stretchy="false" xref="S3.SS1.SSS2.p1.5.m2.2.3.3.1.cmml">[</mo><mn id="S3.SS1.SSS2.p1.5.m2.1.1" xref="S3.SS1.SSS2.p1.5.m2.1.1.cmml">1</mn><mo id="S3.SS1.SSS2.p1.5.m2.2.3.3.2.2" xref="S3.SS1.SSS2.p1.5.m2.2.3.3.1.cmml">,</mo><mi id="S3.SS1.SSS2.p1.5.m2.2.2" xref="S3.SS1.SSS2.p1.5.m2.2.2.cmml">T</mi><mo id="S3.SS1.SSS2.p1.5.m2.2.3.3.2.3" stretchy="false" xref="S3.SS1.SSS2.p1.5.m2.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.5.m2.2b"><apply id="S3.SS1.SSS2.p1.5.m2.2.3.cmml" xref="S3.SS1.SSS2.p1.5.m2.2.3"><in id="S3.SS1.SSS2.p1.5.m2.2.3.1.cmml" xref="S3.SS1.SSS2.p1.5.m2.2.3.1"></in><ci id="S3.SS1.SSS2.p1.5.m2.2.3.2.cmml" xref="S3.SS1.SSS2.p1.5.m2.2.3.2">𝑡</ci><interval closure="closed" id="S3.SS1.SSS2.p1.5.m2.2.3.3.1.cmml" xref="S3.SS1.SSS2.p1.5.m2.2.3.3.2"><cn id="S3.SS1.SSS2.p1.5.m2.1.1.cmml" type="integer" xref="S3.SS1.SSS2.p1.5.m2.1.1">1</cn><ci id="S3.SS1.SSS2.p1.5.m2.2.2.cmml" xref="S3.SS1.SSS2.p1.5.m2.2.2">𝑇</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.5.m2.2c">t\in[1,T]</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.5.m2.2d">italic_t ∈ [ 1 , italic_T ]</annotation></semantics></math>, where <math alttext="i,j\in[1,M]" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.6.m3.4"><semantics id="S3.SS1.SSS2.p1.6.m3.4a"><mrow id="S3.SS1.SSS2.p1.6.m3.4.5" xref="S3.SS1.SSS2.p1.6.m3.4.5.cmml"><mrow id="S3.SS1.SSS2.p1.6.m3.4.5.2.2" xref="S3.SS1.SSS2.p1.6.m3.4.5.2.1.cmml"><mi id="S3.SS1.SSS2.p1.6.m3.3.3" xref="S3.SS1.SSS2.p1.6.m3.3.3.cmml">i</mi><mo id="S3.SS1.SSS2.p1.6.m3.4.5.2.2.1" xref="S3.SS1.SSS2.p1.6.m3.4.5.2.1.cmml">,</mo><mi id="S3.SS1.SSS2.p1.6.m3.4.4" xref="S3.SS1.SSS2.p1.6.m3.4.4.cmml">j</mi></mrow><mo id="S3.SS1.SSS2.p1.6.m3.4.5.1" xref="S3.SS1.SSS2.p1.6.m3.4.5.1.cmml">∈</mo><mrow id="S3.SS1.SSS2.p1.6.m3.4.5.3.2" xref="S3.SS1.SSS2.p1.6.m3.4.5.3.1.cmml"><mo id="S3.SS1.SSS2.p1.6.m3.4.5.3.2.1" stretchy="false" xref="S3.SS1.SSS2.p1.6.m3.4.5.3.1.cmml">[</mo><mn id="S3.SS1.SSS2.p1.6.m3.1.1" xref="S3.SS1.SSS2.p1.6.m3.1.1.cmml">1</mn><mo id="S3.SS1.SSS2.p1.6.m3.4.5.3.2.2" xref="S3.SS1.SSS2.p1.6.m3.4.5.3.1.cmml">,</mo><mi id="S3.SS1.SSS2.p1.6.m3.2.2" xref="S3.SS1.SSS2.p1.6.m3.2.2.cmml">M</mi><mo id="S3.SS1.SSS2.p1.6.m3.4.5.3.2.3" stretchy="false" xref="S3.SS1.SSS2.p1.6.m3.4.5.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.6.m3.4b"><apply id="S3.SS1.SSS2.p1.6.m3.4.5.cmml" xref="S3.SS1.SSS2.p1.6.m3.4.5"><in id="S3.SS1.SSS2.p1.6.m3.4.5.1.cmml" xref="S3.SS1.SSS2.p1.6.m3.4.5.1"></in><list id="S3.SS1.SSS2.p1.6.m3.4.5.2.1.cmml" xref="S3.SS1.SSS2.p1.6.m3.4.5.2.2"><ci id="S3.SS1.SSS2.p1.6.m3.3.3.cmml" xref="S3.SS1.SSS2.p1.6.m3.3.3">𝑖</ci><ci id="S3.SS1.SSS2.p1.6.m3.4.4.cmml" xref="S3.SS1.SSS2.p1.6.m3.4.4">𝑗</ci></list><interval closure="closed" id="S3.SS1.SSS2.p1.6.m3.4.5.3.1.cmml" xref="S3.SS1.SSS2.p1.6.m3.4.5.3.2"><cn id="S3.SS1.SSS2.p1.6.m3.1.1.cmml" type="integer" xref="S3.SS1.SSS2.p1.6.m3.1.1">1</cn><ci id="S3.SS1.SSS2.p1.6.m3.2.2.cmml" xref="S3.SS1.SSS2.p1.6.m3.2.2">𝑀</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.6.m3.4c">i,j\in[1,M]</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.6.m3.4d">italic_i , italic_j ∈ [ 1 , italic_M ]</annotation></semantics></math>, and where <math alttext="\psi" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.7.m4.1"><semantics id="S3.SS1.SSS2.p1.7.m4.1a"><mi id="S3.SS1.SSS2.p1.7.m4.1.1" xref="S3.SS1.SSS2.p1.7.m4.1.1.cmml">ψ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.7.m4.1b"><ci id="S3.SS1.SSS2.p1.7.m4.1.1.cmml" xref="S3.SS1.SSS2.p1.7.m4.1.1">𝜓</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.7.m4.1c">\psi</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.7.m4.1d">italic_ψ</annotation></semantics></math> are the ControlNet optimizable parameters only. <math alttext="\mathbf{X}_{j}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.8.m5.1"><semantics id="S3.SS1.SSS2.p1.8.m5.1a"><msub id="S3.SS1.SSS2.p1.8.m5.1.1" xref="S3.SS1.SSS2.p1.8.m5.1.1.cmml"><mi id="S3.SS1.SSS2.p1.8.m5.1.1.2" xref="S3.SS1.SSS2.p1.8.m5.1.1.2.cmml">𝐗</mi><mi id="S3.SS1.SSS2.p1.8.m5.1.1.3" xref="S3.SS1.SSS2.p1.8.m5.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.8.m5.1b"><apply id="S3.SS1.SSS2.p1.8.m5.1.1.cmml" xref="S3.SS1.SSS2.p1.8.m5.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.8.m5.1.1.1.cmml" xref="S3.SS1.SSS2.p1.8.m5.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p1.8.m5.1.1.2.cmml" xref="S3.SS1.SSS2.p1.8.m5.1.1.2">𝐗</ci><ci id="S3.SS1.SSS2.p1.8.m5.1.1.3.cmml" xref="S3.SS1.SSS2.p1.8.m5.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.8.m5.1c">\mathbf{X}_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.8.m5.1d">bold_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> is another image from the set and <math alttext="\mathbf{D}_{j}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.9.m6.1"><semantics id="S3.SS1.SSS2.p1.9.m6.1a"><msub id="S3.SS1.SSS2.p1.9.m6.1.1" xref="S3.SS1.SSS2.p1.9.m6.1.1.cmml"><mi id="S3.SS1.SSS2.p1.9.m6.1.1.2" xref="S3.SS1.SSS2.p1.9.m6.1.1.2.cmml">𝐃</mi><mi id="S3.SS1.SSS2.p1.9.m6.1.1.3" xref="S3.SS1.SSS2.p1.9.m6.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.9.m6.1b"><apply id="S3.SS1.SSS2.p1.9.m6.1.1.cmml" xref="S3.SS1.SSS2.p1.9.m6.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.9.m6.1.1.1.cmml" xref="S3.SS1.SSS2.p1.9.m6.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p1.9.m6.1.1.2.cmml" xref="S3.SS1.SSS2.p1.9.m6.1.1.2">𝐃</ci><ci id="S3.SS1.SSS2.p1.9.m6.1.1.3.cmml" xref="S3.SS1.SSS2.p1.9.m6.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.9.m6.1c">\mathbf{D}_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.9.m6.1d">bold_D start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> is its depth map (obtained with the approach of Ke et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx22" title="">KOH<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>24</a>]</cite>)—both are given as input to the ControlNet subnetwork. In short, the network is trained to denoise input image <math alttext="\mathbf{X}_{i}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.10.m7.1"><semantics id="S3.SS1.SSS2.p1.10.m7.1a"><msub id="S3.SS1.SSS2.p1.10.m7.1.1" xref="S3.SS1.SSS2.p1.10.m7.1.1.cmml"><mi id="S3.SS1.SSS2.p1.10.m7.1.1.2" xref="S3.SS1.SSS2.p1.10.m7.1.1.2.cmml">𝐗</mi><mi id="S3.SS1.SSS2.p1.10.m7.1.1.3" xref="S3.SS1.SSS2.p1.10.m7.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.10.m7.1b"><apply id="S3.SS1.SSS2.p1.10.m7.1.1.cmml" xref="S3.SS1.SSS2.p1.10.m7.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.10.m7.1.1.1.cmml" xref="S3.SS1.SSS2.p1.10.m7.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p1.10.m7.1.1.2.cmml" xref="S3.SS1.SSS2.p1.10.m7.1.1.2">𝐗</ci><ci id="S3.SS1.SSS2.p1.10.m7.1.1.3.cmml" xref="S3.SS1.SSS2.p1.10.m7.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.10.m7.1c">\mathbf{X}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.10.m7.1d">bold_X start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> given its light direction <math alttext="l_{i}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.11.m8.1"><semantics id="S3.SS1.SSS2.p1.11.m8.1a"><msub id="S3.SS1.SSS2.p1.11.m8.1.1" xref="S3.SS1.SSS2.p1.11.m8.1.1.cmml"><mi id="S3.SS1.SSS2.p1.11.m8.1.1.2" xref="S3.SS1.SSS2.p1.11.m8.1.1.2.cmml">l</mi><mi id="S3.SS1.SSS2.p1.11.m8.1.1.3" xref="S3.SS1.SSS2.p1.11.m8.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.11.m8.1b"><apply id="S3.SS1.SSS2.p1.11.m8.1.1.cmml" xref="S3.SS1.SSS2.p1.11.m8.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.11.m8.1.1.1.cmml" xref="S3.SS1.SSS2.p1.11.m8.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p1.11.m8.1.1.2.cmml" xref="S3.SS1.SSS2.p1.11.m8.1.1.2">𝑙</ci><ci id="S3.SS1.SSS2.p1.11.m8.1.1.3.cmml" xref="S3.SS1.SSS2.p1.11.m8.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.11.m8.1c">l_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.11.m8.1d">italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> while conditioned on the image <math alttext="\mathbf{X}_{j}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.12.m9.1"><semantics id="S3.SS1.SSS2.p1.12.m9.1a"><msub id="S3.SS1.SSS2.p1.12.m9.1.1" xref="S3.SS1.SSS2.p1.12.m9.1.1.cmml"><mi id="S3.SS1.SSS2.p1.12.m9.1.1.2" xref="S3.SS1.SSS2.p1.12.m9.1.1.2.cmml">𝐗</mi><mi id="S3.SS1.SSS2.p1.12.m9.1.1.3" xref="S3.SS1.SSS2.p1.12.m9.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.12.m9.1b"><apply id="S3.SS1.SSS2.p1.12.m9.1.1.cmml" xref="S3.SS1.SSS2.p1.12.m9.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.12.m9.1.1.1.cmml" xref="S3.SS1.SSS2.p1.12.m9.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p1.12.m9.1.1.2.cmml" xref="S3.SS1.SSS2.p1.12.m9.1.1.2">𝐗</ci><ci id="S3.SS1.SSS2.p1.12.m9.1.1.3.cmml" xref="S3.SS1.SSS2.p1.12.m9.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.12.m9.1c">\mathbf{X}_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.12.m9.1d">bold_X start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> corresponding to another lighting direction <math alttext="l_{j}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p1.13.m10.1"><semantics id="S3.SS1.SSS2.p1.13.m10.1a"><msub id="S3.SS1.SSS2.p1.13.m10.1.1" xref="S3.SS1.SSS2.p1.13.m10.1.1.cmml"><mi id="S3.SS1.SSS2.p1.13.m10.1.1.2" xref="S3.SS1.SSS2.p1.13.m10.1.1.2.cmml">l</mi><mi id="S3.SS1.SSS2.p1.13.m10.1.1.3" xref="S3.SS1.SSS2.p1.13.m10.1.1.3.cmml">j</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p1.13.m10.1b"><apply id="S3.SS1.SSS2.p1.13.m10.1.1.cmml" xref="S3.SS1.SSS2.p1.13.m10.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p1.13.m10.1.1.1.cmml" xref="S3.SS1.SSS2.p1.13.m10.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p1.13.m10.1.1.2.cmml" xref="S3.SS1.SSS2.p1.13.m10.1.1.2">𝑙</ci><ci id="S3.SS1.SSS2.p1.13.m10.1.1.3.cmml" xref="S3.SS1.SSS2.p1.13.m10.1.1.3">𝑗</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p1.13.m10.1c">l_{j}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p1.13.m10.1d">italic_l start_POSTSUBSCRIPT italic_j end_POSTSUBSCRIPT</annotation></semantics></math> of the same scene. Here, we do not use text conditioning: the empty text string is provided to the network.</p>
</div>
<div class="ltx_para" id="S3.SS1.SSS2.p2">
<p class="ltx_p" id="S3.SS1.SSS2.p2.1">Specifically, the light direction <math alttext="\boldsymbol{l}_{i}" class="ltx_Math" display="inline" id="S3.SS1.SSS2.p2.1.m1.1"><semantics id="S3.SS1.SSS2.p2.1.m1.1a"><msub id="S3.SS1.SSS2.p2.1.m1.1.1" xref="S3.SS1.SSS2.p2.1.m1.1.1.cmml"><mi id="S3.SS1.SSS2.p2.1.m1.1.1.2" xref="S3.SS1.SSS2.p2.1.m1.1.1.2.cmml">𝒍</mi><mi id="S3.SS1.SSS2.p2.1.m1.1.1.3" xref="S3.SS1.SSS2.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS2.p2.1.m1.1b"><apply id="S3.SS1.SSS2.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS2.p2.1.m1.1.1.1.cmml" xref="S3.SS1.SSS2.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS2.p2.1.m1.1.1.2.cmml" xref="S3.SS1.SSS2.p2.1.m1.1.1.2">𝒍</ci><ci id="S3.SS1.SSS2.p2.1.m1.1.1.3.cmml" xref="S3.SS1.SSS2.p2.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS2.p2.1.m1.1c">\boldsymbol{l}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS2.p2.1.m1.1d">bold_italic_l start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is encoded using the first 4 bands of spherical harmonics, following the method of Müller et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx34" title="">MESK22</a>]</cite>.
The resulting vector is added to the timestep embedding prior to feeding it to the layers of ControlNet’s trainable copy.</p>
</div>
</section>
<section class="ltx_subsubsection" id="S3.SS1.SSS3">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.3 </span>Improving the Diffusion Quality</h4>
<div class="ltx_para" id="S3.SS1.SSS3.p1">
<p class="ltx_p" id="S3.SS1.SSS3.p1.1">Since ControlNet was not specifically designed for relighting, adapting it naively as described above leads to inaccurate colors and a loss in contrast (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.F3" title="Figure 3 ‣ 3.1.3 Improving the Diffusion Quality ‣ 3.1 Single-View Relighting with 2D Diffusion Priors ‣ 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">3</span></a>), as well as distorted edges (see Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.F4" title="Figure 4 ‣ 3.1.3 Improving the Diffusion Quality ‣ 3.1 Single-View Relighting with 2D Diffusion Priors ‣ 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">4</span></a>). These errors also degrade multi-view consistency.</p>
</div>
<figure class="ltx_figure" id="S3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="199" id="S3.F3.g1" src="extracted/5860470/figures/color_fixes.jpg" width="592"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Importance of post-relighting color and contrast adjustments. Left: input image. Middle: naive ControlNet relighting; the bottle has the wrong color and the contrast is poor. Right: our relighting after training with <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx26" title="">LLLY23</a>]</cite> and after color-matching the input.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.SSS3.p2">
<p class="ltx_p" id="S3.SS1.SSS3.p2.4">We adopt two strategies to improve coloration and contrast. First, we follow the recommendations of <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx26" title="">LLLY23</a>]</cite> to improve image brightness—we found them to also help for color. In particular, using the “v-parameterized” objective <math alttext="y_{t}=\sqrt{\bar{\alpha}_{t}}\cdot\boldsymbol{\epsilon}-\sqrt{1-\bar{\alpha}_{%
t}}\cdot\boldsymbol{x}" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p2.1.m1.1"><semantics id="S3.SS1.SSS3.p2.1.m1.1a"><mrow id="S3.SS1.SSS3.p2.1.m1.1.1" xref="S3.SS1.SSS3.p2.1.m1.1.1.cmml"><msub id="S3.SS1.SSS3.p2.1.m1.1.1.2" xref="S3.SS1.SSS3.p2.1.m1.1.1.2.cmml"><mi id="S3.SS1.SSS3.p2.1.m1.1.1.2.2" xref="S3.SS1.SSS3.p2.1.m1.1.1.2.2.cmml">y</mi><mi id="S3.SS1.SSS3.p2.1.m1.1.1.2.3" xref="S3.SS1.SSS3.p2.1.m1.1.1.2.3.cmml">t</mi></msub><mo id="S3.SS1.SSS3.p2.1.m1.1.1.1" xref="S3.SS1.SSS3.p2.1.m1.1.1.1.cmml">=</mo><mrow id="S3.SS1.SSS3.p2.1.m1.1.1.3" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.cmml"><mrow id="S3.SS1.SSS3.p2.1.m1.1.1.3.2" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.2.cmml"><msqrt id="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.cmml"><msub id="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2.cmml"><mover accent="true" id="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2.2" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2.2.cmml"><mi id="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2.2.2" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2.2.2.cmml">α</mi><mo id="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2.2.1" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2.2.1.cmml">¯</mo></mover><mi id="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2.3" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2.3.cmml">t</mi></msub></msqrt><mo id="S3.SS1.SSS3.p2.1.m1.1.1.3.2.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.2.1.cmml">⋅</mo><mi class="ltx_mathvariant_bold-italic" id="S3.SS1.SSS3.p2.1.m1.1.1.3.2.3" mathvariant="bold-italic" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.2.3.cmml">ϵ</mi></mrow><mo id="S3.SS1.SSS3.p2.1.m1.1.1.3.1" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.1.cmml">−</mo><mrow id="S3.SS1.SSS3.p2.1.m1.1.1.3.3" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.cmml"><msqrt id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.cmml"><mrow id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.cmml"><mn id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.2" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.2.cmml">1</mn><mo id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.1" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.1.cmml">−</mo><msub id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3.cmml"><mover accent="true" id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3.2" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3.2.cmml"><mi id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3.2.2" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3.2.2.cmml">α</mi><mo id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3.2.1" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3.2.1.cmml">¯</mo></mover><mi id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3.3" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3.3.cmml">t</mi></msub></mrow></msqrt><mo id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.1.cmml">⋅</mo><mi id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.3" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.3.cmml">𝒙</mi></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p2.1.m1.1b"><apply id="S3.SS1.SSS3.p2.1.m1.1.1.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1"><eq id="S3.SS1.SSS3.p2.1.m1.1.1.1.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.1"></eq><apply id="S3.SS1.SSS3.p2.1.m1.1.1.2.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p2.1.m1.1.1.2.1.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS3.p2.1.m1.1.1.2.2.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.2.2">𝑦</ci><ci id="S3.SS1.SSS3.p2.1.m1.1.1.2.3.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.2.3">𝑡</ci></apply><apply id="S3.SS1.SSS3.p2.1.m1.1.1.3.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3"><minus id="S3.SS1.SSS3.p2.1.m1.1.1.3.1.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.1"></minus><apply id="S3.SS1.SSS3.p2.1.m1.1.1.3.2.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.2"><ci id="S3.SS1.SSS3.p2.1.m1.1.1.3.2.1.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.2.1">⋅</ci><apply id="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2"><root id="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2a.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2"></root><apply id="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2.1.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2">subscript</csymbol><apply id="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2.2.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2.2"><ci id="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2.2.1.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2.2.1">¯</ci><ci id="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2.2.2.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2.2.2">𝛼</ci></apply><ci id="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2.3.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.2.2.2.3">𝑡</ci></apply></apply><ci id="S3.SS1.SSS3.p2.1.m1.1.1.3.2.3.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.2.3">bold-italic-ϵ</ci></apply><apply id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3"><ci id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.1.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.1">⋅</ci><apply id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2"><root id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2a.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2"></root><apply id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2"><minus id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.1.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.1"></minus><cn id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.2.cmml" type="integer" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.2">1</cn><apply id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3.1.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3">subscript</csymbol><apply id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3.2.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3.2"><ci id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3.2.1.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3.2.1">¯</ci><ci id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3.2.2.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3.2.2">𝛼</ci></apply><ci id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3.3.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.2.2.3.3">𝑡</ci></apply></apply></apply><ci id="S3.SS1.SSS3.p2.1.m1.1.1.3.3.3.cmml" xref="S3.SS1.SSS3.p2.1.m1.1.1.3.3.3">𝒙</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p2.1.m1.1c">y_{t}=\sqrt{\bar{\alpha}_{t}}\cdot\boldsymbol{\epsilon}-\sqrt{1-\bar{\alpha}_{%
t}}\cdot\boldsymbol{x}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p2.1.m1.1d">italic_y start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = square-root start_ARG over¯ start_ARG italic_α end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG ⋅ bold_italic_ϵ - square-root start_ARG 1 - over¯ start_ARG italic_α end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT end_ARG ⋅ bold_italic_x</annotation></semantics></math>, instead of the more usual <math alttext="y_{t}=\epsilon" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p2.2.m2.1"><semantics id="S3.SS1.SSS3.p2.2.m2.1a"><mrow id="S3.SS1.SSS3.p2.2.m2.1.1" xref="S3.SS1.SSS3.p2.2.m2.1.1.cmml"><msub id="S3.SS1.SSS3.p2.2.m2.1.1.2" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.cmml"><mi id="S3.SS1.SSS3.p2.2.m2.1.1.2.2" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.2.cmml">y</mi><mi id="S3.SS1.SSS3.p2.2.m2.1.1.2.3" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.3.cmml">t</mi></msub><mo id="S3.SS1.SSS3.p2.2.m2.1.1.1" xref="S3.SS1.SSS3.p2.2.m2.1.1.1.cmml">=</mo><mi id="S3.SS1.SSS3.p2.2.m2.1.1.3" xref="S3.SS1.SSS3.p2.2.m2.1.1.3.cmml">ϵ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p2.2.m2.1b"><apply id="S3.SS1.SSS3.p2.2.m2.1.1.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1"><eq id="S3.SS1.SSS3.p2.2.m2.1.1.1.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.1"></eq><apply id="S3.SS1.SSS3.p2.2.m2.1.1.2.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p2.2.m2.1.1.2.1.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.2">subscript</csymbol><ci id="S3.SS1.SSS3.p2.2.m2.1.1.2.2.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.2">𝑦</ci><ci id="S3.SS1.SSS3.p2.2.m2.1.1.2.3.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.2.3">𝑡</ci></apply><ci id="S3.SS1.SSS3.p2.2.m2.1.1.3.cmml" xref="S3.SS1.SSS3.p2.2.m2.1.1.3">italic-ϵ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p2.2.m2.1c">y_{t}=\epsilon</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p2.2.m2.1d">italic_y start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT = italic_ϵ</annotation></semantics></math>, proved critical; in this equation, <math alttext="1-\bar{\alpha}_{t}" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p2.3.m3.1"><semantics id="S3.SS1.SSS3.p2.3.m3.1a"><mrow id="S3.SS1.SSS3.p2.3.m3.1.1" xref="S3.SS1.SSS3.p2.3.m3.1.1.cmml"><mn id="S3.SS1.SSS3.p2.3.m3.1.1.2" xref="S3.SS1.SSS3.p2.3.m3.1.1.2.cmml">1</mn><mo id="S3.SS1.SSS3.p2.3.m3.1.1.1" xref="S3.SS1.SSS3.p2.3.m3.1.1.1.cmml">−</mo><msub id="S3.SS1.SSS3.p2.3.m3.1.1.3" xref="S3.SS1.SSS3.p2.3.m3.1.1.3.cmml"><mover accent="true" id="S3.SS1.SSS3.p2.3.m3.1.1.3.2" xref="S3.SS1.SSS3.p2.3.m3.1.1.3.2.cmml"><mi id="S3.SS1.SSS3.p2.3.m3.1.1.3.2.2" xref="S3.SS1.SSS3.p2.3.m3.1.1.3.2.2.cmml">α</mi><mo id="S3.SS1.SSS3.p2.3.m3.1.1.3.2.1" xref="S3.SS1.SSS3.p2.3.m3.1.1.3.2.1.cmml">¯</mo></mover><mi id="S3.SS1.SSS3.p2.3.m3.1.1.3.3" xref="S3.SS1.SSS3.p2.3.m3.1.1.3.3.cmml">t</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p2.3.m3.1b"><apply id="S3.SS1.SSS3.p2.3.m3.1.1.cmml" xref="S3.SS1.SSS3.p2.3.m3.1.1"><minus id="S3.SS1.SSS3.p2.3.m3.1.1.1.cmml" xref="S3.SS1.SSS3.p2.3.m3.1.1.1"></minus><cn id="S3.SS1.SSS3.p2.3.m3.1.1.2.cmml" type="integer" xref="S3.SS1.SSS3.p2.3.m3.1.1.2">1</cn><apply id="S3.SS1.SSS3.p2.3.m3.1.1.3.cmml" xref="S3.SS1.SSS3.p2.3.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p2.3.m3.1.1.3.1.cmml" xref="S3.SS1.SSS3.p2.3.m3.1.1.3">subscript</csymbol><apply id="S3.SS1.SSS3.p2.3.m3.1.1.3.2.cmml" xref="S3.SS1.SSS3.p2.3.m3.1.1.3.2"><ci id="S3.SS1.SSS3.p2.3.m3.1.1.3.2.1.cmml" xref="S3.SS1.SSS3.p2.3.m3.1.1.3.2.1">¯</ci><ci id="S3.SS1.SSS3.p2.3.m3.1.1.3.2.2.cmml" xref="S3.SS1.SSS3.p2.3.m3.1.1.3.2.2">𝛼</ci></apply><ci id="S3.SS1.SSS3.p2.3.m3.1.1.3.3.cmml" xref="S3.SS1.SSS3.p2.3.m3.1.1.3.3">𝑡</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p2.3.m3.1c">1-\bar{\alpha}_{t}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p2.3.m3.1d">1 - over¯ start_ARG italic_α end_ARG start_POSTSUBSCRIPT italic_t end_POSTSUBSCRIPT</annotation></semantics></math> gives the variance of the noise at timestep <math alttext="t" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p2.4.m4.1"><semantics id="S3.SS1.SSS3.p2.4.m4.1a"><mi id="S3.SS1.SSS3.p2.4.m4.1.1" xref="S3.SS1.SSS3.p2.4.m4.1.1.cmml">t</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p2.4.m4.1b"><ci id="S3.SS1.SSS3.p2.4.m4.1.1.cmml" xref="S3.SS1.SSS3.p2.4.m4.1.1">𝑡</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p2.4.m4.1c">t</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p2.4.m4.1d">italic_t</annotation></semantics></math>. Second, after sampling, we color-match predictions to the input image to compensate for the difference between the color distribution of the training data and that of the scene. This is done by subtracting the per-channel mean and dividing by the standard deviation for the prediction, then adding the mean and standard deviation of the input, in the LAB colorspace. This is computed over all 18 lighting conditions together (i.e., the mean over all lighting directions) to conserve relative brightness across all conditions. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.F3" title="Figure 3 ‣ 3.1.3 Improving the Diffusion Quality ‣ 3.1 Single-View Relighting with 2D Diffusion Priors ‣ 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">3</span></a> shows the effect of these changes; without them, the bottle is blue instead of green and overall contrast is poor.</p>
</div>
<figure class="ltx_figure" id="S3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="200" id="S3.F4.g1" src="extracted/5860470/figures/edge_fixes.jpg" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Importance of conserving edge sharpness when relighting. Left: input image. Middle: naive ControlNet relighting; note how the edges do not match the input and how the text is illegible. Right: our final relighting after fine-tuning the conditonal decoder network from <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx73" title="">ZFC<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite>.</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.SSS3.p3">
<p class="ltx_p" id="S3.SS1.SSS3.p3.3">To correct the distorted edges, we adapt the asymmetric autoencoder approach of Zhu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx73" title="">ZFC<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite>, which consists in conditioning the latent space decoder with the (masked) input image for the inpainting task. In our case, we ignore the masking and fine-tune the decoder on the multi-illumination dataset <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx35" title="">MGAD19</a>]</cite>. At each fine-tuning step, we encode an image and condition the decoder on an image from the same scene with another random lighting direction. The decoder is fine-tuned with the Adam optimizer at a learning rate of <math alttext="10^{-4}" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p3.1.m1.1"><semantics id="S3.SS1.SSS3.p3.1.m1.1a"><msup id="S3.SS1.SSS3.p3.1.m1.1.1" xref="S3.SS1.SSS3.p3.1.m1.1.1.cmml"><mn id="S3.SS1.SSS3.p3.1.m1.1.1.2" xref="S3.SS1.SSS3.p3.1.m1.1.1.2.cmml">10</mn><mrow id="S3.SS1.SSS3.p3.1.m1.1.1.3" xref="S3.SS1.SSS3.p3.1.m1.1.1.3.cmml"><mo id="S3.SS1.SSS3.p3.1.m1.1.1.3a" xref="S3.SS1.SSS3.p3.1.m1.1.1.3.cmml">−</mo><mn id="S3.SS1.SSS3.p3.1.m1.1.1.3.2" xref="S3.SS1.SSS3.p3.1.m1.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p3.1.m1.1b"><apply id="S3.SS1.SSS3.p3.1.m1.1.1.cmml" xref="S3.SS1.SSS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS3.p3.1.m1.1.1.1.cmml" xref="S3.SS1.SSS3.p3.1.m1.1.1">superscript</csymbol><cn id="S3.SS1.SSS3.p3.1.m1.1.1.2.cmml" type="integer" xref="S3.SS1.SSS3.p3.1.m1.1.1.2">10</cn><apply id="S3.SS1.SSS3.p3.1.m1.1.1.3.cmml" xref="S3.SS1.SSS3.p3.1.m1.1.1.3"><minus id="S3.SS1.SSS3.p3.1.m1.1.1.3.1.cmml" xref="S3.SS1.SSS3.p3.1.m1.1.1.3"></minus><cn id="S3.SS1.SSS3.p3.1.m1.1.1.3.2.cmml" type="integer" xref="S3.SS1.SSS3.p3.1.m1.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p3.1.m1.1c">10^{-4}</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p3.1.m1.1d">10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math> for 20k steps when training at resolution <math alttext="768\times 512" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p3.2.m2.1"><semantics id="S3.SS1.SSS3.p3.2.m2.1a"><mrow id="S3.SS1.SSS3.p3.2.m2.1.1" xref="S3.SS1.SSS3.p3.2.m2.1.1.cmml"><mn id="S3.SS1.SSS3.p3.2.m2.1.1.2" xref="S3.SS1.SSS3.p3.2.m2.1.1.2.cmml">768</mn><mo id="S3.SS1.SSS3.p3.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.SSS3.p3.2.m2.1.1.1.cmml">×</mo><mn id="S3.SS1.SSS3.p3.2.m2.1.1.3" xref="S3.SS1.SSS3.p3.2.m2.1.1.3.cmml">512</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p3.2.m2.1b"><apply id="S3.SS1.SSS3.p3.2.m2.1.1.cmml" xref="S3.SS1.SSS3.p3.2.m2.1.1"><times id="S3.SS1.SSS3.p3.2.m2.1.1.1.cmml" xref="S3.SS1.SSS3.p3.2.m2.1.1.1"></times><cn id="S3.SS1.SSS3.p3.2.m2.1.1.2.cmml" type="integer" xref="S3.SS1.SSS3.p3.2.m2.1.1.2">768</cn><cn id="S3.SS1.SSS3.p3.2.m2.1.1.3.cmml" type="integer" xref="S3.SS1.SSS3.p3.2.m2.1.1.3">512</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p3.2.m2.1c">768\times 512</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p3.2.m2.1d">768 × 512</annotation></semantics></math> and 50k steps at resolution <math alttext="1536\times 1024" class="ltx_Math" display="inline" id="S3.SS1.SSS3.p3.3.m3.1"><semantics id="S3.SS1.SSS3.p3.3.m3.1a"><mrow id="S3.SS1.SSS3.p3.3.m3.1.1" xref="S3.SS1.SSS3.p3.3.m3.1.1.cmml"><mn id="S3.SS1.SSS3.p3.3.m3.1.1.2" xref="S3.SS1.SSS3.p3.3.m3.1.1.2.cmml">1536</mn><mo id="S3.SS1.SSS3.p3.3.m3.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.SS1.SSS3.p3.3.m3.1.1.1.cmml">×</mo><mn id="S3.SS1.SSS3.p3.3.m3.1.1.3" xref="S3.SS1.SSS3.p3.3.m3.1.1.3.cmml">1024</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS3.p3.3.m3.1b"><apply id="S3.SS1.SSS3.p3.3.m3.1.1.cmml" xref="S3.SS1.SSS3.p3.3.m3.1.1"><times id="S3.SS1.SSS3.p3.3.m3.1.1.1.cmml" xref="S3.SS1.SSS3.p3.3.m3.1.1.1"></times><cn id="S3.SS1.SSS3.p3.3.m3.1.1.2.cmml" type="integer" xref="S3.SS1.SSS3.p3.3.m3.1.1.2">1536</cn><cn id="S3.SS1.SSS3.p3.3.m3.1.1.3.cmml" type="integer" xref="S3.SS1.SSS3.p3.3.m3.1.1.3">1024</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS3.p3.3.m3.1c">1536\times 1024</annotation><annotation encoding="application/x-llamapun" id="S3.SS1.SSS3.p3.3.m3.1d">1536 × 1024</annotation></semantics></math>. Note that this step is independent of the ControlNet training. Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.F4" title="Figure 4 ‣ 3.1.3 Improving the Diffusion Quality ‣ 3.1 Single-View Relighting with 2D Diffusion Priors ‣ 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">4</span></a> shows the effect of these changes; note how the edges are wobbly and the text is illegible without them.</p>
</div>
<figure class="ltx_figure" id="S3.F5">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.F5.8">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S3.F5.8.9.1">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S3.F5.8.9.1.1" style="padding-left:0.4pt;padding-right:0.4pt;"><span class="ltx_text" id="S3.F5.8.9.1.1.1" style="font-size:80%;">Input Image</span></th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column" colspan="3" id="S3.F5.8.9.1.2" style="padding-left:0.4pt;padding-right:0.4pt;"><span class="ltx_text" id="S3.F5.8.9.1.2.1" style="font-size:80%;">ControlNet Relightings</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.F5.4.4">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F5.1.1.1" style="padding-left:0.4pt;padding-right:0.4pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="119" id="S3.F5.1.1.1.g1" src="extracted/5860470/figures/controlnet-relighting/A_input.jpg" width="149"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F5.2.2.2" style="padding-left:0.4pt;padding-right:0.4pt;">
<span class="ltx_text" id="S3.F5.2.2.2.1" style="font-size:80%;">
</span><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="119" id="S3.F5.2.2.2.g1" src="extracted/5860470/figures/controlnet-relighting/A_23.jpg" width="149"/>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F5.3.3.3" style="padding-left:0.4pt;padding-right:0.4pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="119" id="S3.F5.3.3.3.g1" src="extracted/5860470/figures/controlnet-relighting/A_14.jpg" width="149"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F5.4.4.4" style="padding-left:0.4pt;padding-right:0.4pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="119" id="S3.F5.4.4.4.g1" src="extracted/5860470/figures/controlnet-relighting/A_18.jpg" width="149"/></td>
</tr>
<tr class="ltx_tr" id="S3.F5.8.8">
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F5.5.5.1" style="padding-left:0.4pt;padding-right:0.4pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="119" id="S3.F5.5.5.1.g1" src="extracted/5860470/figures/controlnet-relighting/B_input.jpg" width="149"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F5.6.6.2" style="padding-left:0.4pt;padding-right:0.4pt;">
<span class="ltx_text" id="S3.F5.6.6.2.1" style="font-size:80%;">
</span><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="119" id="S3.F5.6.6.2.g1" src="extracted/5860470/figures/controlnet-relighting/B_23.jpg" width="149"/>
</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F5.7.7.3" style="padding-left:0.4pt;padding-right:0.4pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="119" id="S3.F5.7.7.3.g1" src="extracted/5860470/figures/controlnet-relighting/B_14.jpg" width="149"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F5.8.8.4" style="padding-left:0.4pt;padding-right:0.4pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="119" id="S3.F5.8.8.4.g1" src="extracted/5860470/figures/controlnet-relighting/B_18.jpg" width="149"/></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Relighting results with our light-conditioned ControlNet. From a single input image (left column), the ControlNet can generate realistic relit versions for different target light directions (other columns). Please notice realistic changes in highlights for different light directions (top row), as well as the synthesis of cast shadows (bottom row).</figcaption>
</figure>
<div class="ltx_para" id="S3.SS1.SSS3.p4">
<p class="ltx_p" id="S3.SS1.SSS3.p4.1">Example relighting results obtained using our 2D relighting network on images outside of the dataset are shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.F5" title="Figure 5 ‣ 3.1.3 Improving the Diffusion Quality ‣ 3.1 Single-View Relighting with 2D Diffusion Priors ‣ 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">5</span></a>. Observe how the relit images produced by our method are highly realistic and light directions are consistently reproduced across scenes. A naive solution for radiance field relighting would be to apply this 2D network to each synthesized novel view. However, the ControlNet is not multi-view consistent, and such a naive solution results in significant flickering. Please see the accompanying video for a clear illustration.</p>
</div>
<figure class="ltx_figure" id="S3.F6"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="239" id="S3.F6.g1" src="x3.png" width="830"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Given a multi-view, single-illumination dataset we use our relighting ControlNet to generate a multi-view, multi-illumination dataset.</figcaption>
</figure>
</section>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Augmenting Multi-View/Single-Lighting Datasets</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.4">Given a multi-view set <math alttext="\mathcal{I}" class="ltx_Math" display="inline" id="S3.SS2.p1.1.m1.1"><semantics id="S3.SS2.p1.1.m1.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.1.m1.1.1" xref="S3.SS2.p1.1.m1.1.1.cmml">ℐ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.1.m1.1b"><ci id="S3.SS2.p1.1.m1.1.1.cmml" xref="S3.SS2.p1.1.m1.1.1">ℐ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.1.m1.1c">\mathcal{I}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.1.m1.1d">caligraphic_I</annotation></semantics></math> of images of a scene captured under the same lighting (suitable for training a radiance field model), we now leverage our light-conditioned ControlNet model to synthetically relight each image in <math alttext="\mathcal{I}" class="ltx_Math" display="inline" id="S3.SS2.p1.2.m2.1"><semantics id="S3.SS2.p1.2.m2.1a"><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.2.m2.1.1" xref="S3.SS2.p1.2.m2.1.1.cmml">ℐ</mi><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.2.m2.1b"><ci id="S3.SS2.p1.2.m2.1.1.cmml" xref="S3.SS2.p1.2.m2.1.1">ℐ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.2.m2.1c">\mathcal{I}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.2.m2.1d">caligraphic_I</annotation></semantics></math>. We assume the 3D pose of each image <math alttext="\mathbf{I}_{i}\in\mathcal{I}" class="ltx_Math" display="inline" id="S3.SS2.p1.3.m3.1"><semantics id="S3.SS2.p1.3.m3.1a"><mrow id="S3.SS2.p1.3.m3.1.1" xref="S3.SS2.p1.3.m3.1.1.cmml"><msub id="S3.SS2.p1.3.m3.1.1.2" xref="S3.SS2.p1.3.m3.1.1.2.cmml"><mi id="S3.SS2.p1.3.m3.1.1.2.2" xref="S3.SS2.p1.3.m3.1.1.2.2.cmml">𝐈</mi><mi id="S3.SS2.p1.3.m3.1.1.2.3" xref="S3.SS2.p1.3.m3.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS2.p1.3.m3.1.1.1" xref="S3.SS2.p1.3.m3.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.3.m3.1.1.3" xref="S3.SS2.p1.3.m3.1.1.3.cmml">ℐ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.3.m3.1b"><apply id="S3.SS2.p1.3.m3.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1"><in id="S3.SS2.p1.3.m3.1.1.1.cmml" xref="S3.SS2.p1.3.m3.1.1.1"></in><apply id="S3.SS2.p1.3.m3.1.1.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.3.m3.1.1.2.1.cmml" xref="S3.SS2.p1.3.m3.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.3.m3.1.1.2.2.cmml" xref="S3.SS2.p1.3.m3.1.1.2.2">𝐈</ci><ci id="S3.SS2.p1.3.m3.1.1.2.3.cmml" xref="S3.SS2.p1.3.m3.1.1.2.3">𝑖</ci></apply><ci id="S3.SS2.p1.3.m3.1.1.3.cmml" xref="S3.SS2.p1.3.m3.1.1.3">ℐ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.3.m3.1c">\mathbf{I}_{i}\in\mathcal{I}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.3.m3.1d">bold_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ caligraphic_I</annotation></semantics></math> is known a priori, for example via Colmap <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx50" title="">SF16</a>, <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx58" title="">SZPF16</a>]</cite>. We then simply relight each <math alttext="\mathbf{I}_{i}\in\mathcal{I}" class="ltx_Math" display="inline" id="S3.SS2.p1.4.m4.1"><semantics id="S3.SS2.p1.4.m4.1a"><mrow id="S3.SS2.p1.4.m4.1.1" xref="S3.SS2.p1.4.m4.1.1.cmml"><msub id="S3.SS2.p1.4.m4.1.1.2" xref="S3.SS2.p1.4.m4.1.1.2.cmml"><mi id="S3.SS2.p1.4.m4.1.1.2.2" xref="S3.SS2.p1.4.m4.1.1.2.2.cmml">𝐈</mi><mi id="S3.SS2.p1.4.m4.1.1.2.3" xref="S3.SS2.p1.4.m4.1.1.2.3.cmml">i</mi></msub><mo id="S3.SS2.p1.4.m4.1.1.1" xref="S3.SS2.p1.4.m4.1.1.1.cmml">∈</mo><mi class="ltx_font_mathcaligraphic" id="S3.SS2.p1.4.m4.1.1.3" xref="S3.SS2.p1.4.m4.1.1.3.cmml">ℐ</mi></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p1.4.m4.1b"><apply id="S3.SS2.p1.4.m4.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1"><in id="S3.SS2.p1.4.m4.1.1.1.cmml" xref="S3.SS2.p1.4.m4.1.1.1"></in><apply id="S3.SS2.p1.4.m4.1.1.2.cmml" xref="S3.SS2.p1.4.m4.1.1.2"><csymbol cd="ambiguous" id="S3.SS2.p1.4.m4.1.1.2.1.cmml" xref="S3.SS2.p1.4.m4.1.1.2">subscript</csymbol><ci id="S3.SS2.p1.4.m4.1.1.2.2.cmml" xref="S3.SS2.p1.4.m4.1.1.2.2">𝐈</ci><ci id="S3.SS2.p1.4.m4.1.1.2.3.cmml" xref="S3.SS2.p1.4.m4.1.1.2.3">𝑖</ci></apply><ci id="S3.SS2.p1.4.m4.1.1.3.cmml" xref="S3.SS2.p1.4.m4.1.1.3">ℐ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p1.4.m4.1c">\mathbf{I}_{i}\in\mathcal{I}</annotation><annotation encoding="application/x-llamapun" id="S3.SS2.p1.4.m4.1d">bold_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT ∈ caligraphic_I</annotation></semantics></math> to the corresponding 18 known light directions in the dataset from Murmann et al. <span class="ltx_ERROR undefined" id="S3.SS2.p1.4.1">\shortcite</span>multilum (excluding the directions where the flash points forward), (see Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.SS1" title="3.1 Single-View Relighting with 2D Diffusion Priors ‣ 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">3.1</span></a>). We now have a full multi-lighting, multi-view dataset. This process is illustrated in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.F6" title="Figure 6 ‣ 3.1.3 Improving the Diffusion Quality ‣ 3.1 Single-View Relighting with 2D Diffusion Priors ‣ 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">6</span></a>.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Training a Lighting-Consistent Radiance Field</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Given the generated multi-light, multi-view dataset, we now describe our solution to provide a relightable radiance field. In particular, we build on the 3DGS framework of Kerbl et al. <span class="ltx_ERROR undefined" id="S3.SS3.p1.1.1">\shortcite</span>gaussian-splats.
Our requirements are twofold: first, define an augmented radiance field that can represent lighting conditions from different lighting directions; second, allow direct control of the lighting direction used for relighting.</p>
</div>
<div class="ltx_para" id="S3.SS3.p2">
<p class="ltx_p" id="S3.SS3.p2.1">The original 3DGS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx21" title="">KKLD23</a>]</cite> radiance field uses spherical harmonics (SH) to represent view-dependent illumination. To encode varying illumination, we replace the SH coefficients with a 3-layer MLP <math alttext="\boldsymbol{c}_{\theta}" class="ltx_Math" display="inline" id="S3.SS3.p2.1.m1.1"><semantics id="S3.SS3.p2.1.m1.1a"><msub id="S3.SS3.p2.1.m1.1.1" xref="S3.SS3.p2.1.m1.1.1.cmml"><mi id="S3.SS3.p2.1.m1.1.1.2" xref="S3.SS3.p2.1.m1.1.1.2.cmml">𝒄</mi><mi id="S3.SS3.p2.1.m1.1.1.3" xref="S3.SS3.p2.1.m1.1.1.3.cmml">θ</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p2.1.m1.1b"><apply id="S3.SS3.p2.1.m1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p2.1.m1.1.1.1.cmml" xref="S3.SS3.p2.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p2.1.m1.1.1.2.cmml" xref="S3.SS3.p2.1.m1.1.1.2">𝒄</ci><ci id="S3.SS3.p2.1.m1.1.1.3.cmml" xref="S3.SS3.p2.1.m1.1.1.3">𝜃</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p2.1.m1.1c">\boldsymbol{c}_{\theta}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p2.1.m1.1d">bold_italic_c start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT</annotation></semantics></math> of width 128 which takes as input the light direction along with the viewing direction. Both vectors have a size of 16 after encoding.</p>
</div>
<div class="ltx_para" id="S3.SS3.p3">
<p class="ltx_p" id="S3.SS3.p3.4">Since light directions are computed with respect to a local camera reference frame (c.f. Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.SS1" title="3.1 Single-View Relighting with 2D Diffusion Priors ‣ 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">3.1</span></a>), we subsequently register them to the world coordinate system (obtained from Colmap) by rotating them according to their (known) camera rotation parameters:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E2">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\boldsymbol{l}^{\prime}=\boldsymbol{R}_{i}\boldsymbol{l}\,," class="ltx_Math" display="block" id="S3.E2.m1.1"><semantics id="S3.E2.m1.1a"><mrow id="S3.E2.m1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><mrow id="S3.E2.m1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.cmml"><msup id="S3.E2.m1.1.1.1.1.2" xref="S3.E2.m1.1.1.1.1.2.cmml"><mi id="S3.E2.m1.1.1.1.1.2.2" xref="S3.E2.m1.1.1.1.1.2.2.cmml">𝒍</mi><mo id="S3.E2.m1.1.1.1.1.2.3" xref="S3.E2.m1.1.1.1.1.2.3.cmml">′</mo></msup><mo id="S3.E2.m1.1.1.1.1.1" xref="S3.E2.m1.1.1.1.1.1.cmml">=</mo><mrow id="S3.E2.m1.1.1.1.1.3" xref="S3.E2.m1.1.1.1.1.3.cmml"><msub id="S3.E2.m1.1.1.1.1.3.2" xref="S3.E2.m1.1.1.1.1.3.2.cmml"><mi id="S3.E2.m1.1.1.1.1.3.2.2" xref="S3.E2.m1.1.1.1.1.3.2.2.cmml">𝑹</mi><mi id="S3.E2.m1.1.1.1.1.3.2.3" xref="S3.E2.m1.1.1.1.1.3.2.3.cmml">i</mi></msub><mo id="S3.E2.m1.1.1.1.1.3.1" xref="S3.E2.m1.1.1.1.1.3.1.cmml">⁢</mo><mi id="S3.E2.m1.1.1.1.1.3.3" xref="S3.E2.m1.1.1.1.1.3.3.cmml">𝒍</mi></mrow></mrow><mo id="S3.E2.m1.1.1.1.2" lspace="0.110em" xref="S3.E2.m1.1.1.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E2.m1.1b"><apply id="S3.E2.m1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1"><eq id="S3.E2.m1.1.1.1.1.1.cmml" xref="S3.E2.m1.1.1.1.1.1"></eq><apply id="S3.E2.m1.1.1.1.1.2.cmml" xref="S3.E2.m1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.2.1.cmml" xref="S3.E2.m1.1.1.1.1.2">superscript</csymbol><ci id="S3.E2.m1.1.1.1.1.2.2.cmml" xref="S3.E2.m1.1.1.1.1.2.2">𝒍</ci><ci id="S3.E2.m1.1.1.1.1.2.3.cmml" xref="S3.E2.m1.1.1.1.1.2.3">′</ci></apply><apply id="S3.E2.m1.1.1.1.1.3.cmml" xref="S3.E2.m1.1.1.1.1.3"><times id="S3.E2.m1.1.1.1.1.3.1.cmml" xref="S3.E2.m1.1.1.1.1.3.1"></times><apply id="S3.E2.m1.1.1.1.1.3.2.cmml" xref="S3.E2.m1.1.1.1.1.3.2"><csymbol cd="ambiguous" id="S3.E2.m1.1.1.1.1.3.2.1.cmml" xref="S3.E2.m1.1.1.1.1.3.2">subscript</csymbol><ci id="S3.E2.m1.1.1.1.1.3.2.2.cmml" xref="S3.E2.m1.1.1.1.1.3.2.2">𝑹</ci><ci id="S3.E2.m1.1.1.1.1.3.2.3.cmml" xref="S3.E2.m1.1.1.1.1.3.2.3">𝑖</ci></apply><ci id="S3.E2.m1.1.1.1.1.3.3.cmml" xref="S3.E2.m1.1.1.1.1.3.3">𝒍</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E2.m1.1c">\boldsymbol{l}^{\prime}=\boldsymbol{R}_{i}\boldsymbol{l}\,,</annotation><annotation encoding="application/x-llamapun" id="S3.E2.m1.1d">bold_italic_l start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT = bold_italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT bold_italic_l ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p3.3">where <math alttext="\boldsymbol{R}_{i}" class="ltx_Math" display="inline" id="S3.SS3.p3.1.m1.1"><semantics id="S3.SS3.p3.1.m1.1a"><msub id="S3.SS3.p3.1.m1.1.1" xref="S3.SS3.p3.1.m1.1.1.cmml"><mi id="S3.SS3.p3.1.m1.1.1.2" xref="S3.SS3.p3.1.m1.1.1.2.cmml">𝑹</mi><mi id="S3.SS3.p3.1.m1.1.1.3" xref="S3.SS3.p3.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.1.m1.1b"><apply id="S3.SS3.p3.1.m1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.1.m1.1.1.1.cmml" xref="S3.SS3.p3.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p3.1.m1.1.1.2.cmml" xref="S3.SS3.p3.1.m1.1.1.2">𝑹</ci><ci id="S3.SS3.p3.1.m1.1.1.3.cmml" xref="S3.SS3.p3.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.1.m1.1c">\boldsymbol{R}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.1.m1.1d">bold_italic_R start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> is the <math alttext="3\times 3" class="ltx_Math" display="inline" id="S3.SS3.p3.2.m2.1"><semantics id="S3.SS3.p3.2.m2.1a"><mrow id="S3.SS3.p3.2.m2.1.1" xref="S3.SS3.p3.2.m2.1.1.cmml"><mn id="S3.SS3.p3.2.m2.1.1.2" xref="S3.SS3.p3.2.m2.1.1.2.cmml">3</mn><mo id="S3.SS3.p3.2.m2.1.1.1" lspace="0.222em" rspace="0.222em" xref="S3.SS3.p3.2.m2.1.1.1.cmml">×</mo><mn id="S3.SS3.p3.2.m2.1.1.3" xref="S3.SS3.p3.2.m2.1.1.3.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.2.m2.1b"><apply id="S3.SS3.p3.2.m2.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1"><times id="S3.SS3.p3.2.m2.1.1.1.cmml" xref="S3.SS3.p3.2.m2.1.1.1"></times><cn id="S3.SS3.p3.2.m2.1.1.2.cmml" type="integer" xref="S3.SS3.p3.2.m2.1.1.2">3</cn><cn id="S3.SS3.p3.2.m2.1.1.3.cmml" type="integer" xref="S3.SS3.p3.2.m2.1.1.3">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.2.m2.1c">3\times 3</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.2.m2.1d">3 × 3</annotation></semantics></math> camera-to-world rotation matrix of image <math alttext="\mathbf{I}_{i}" class="ltx_Math" display="inline" id="S3.SS3.p3.3.m3.1"><semantics id="S3.SS3.p3.3.m3.1a"><msub id="S3.SS3.p3.3.m3.1.1" xref="S3.SS3.p3.3.m3.1.1.cmml"><mi id="S3.SS3.p3.3.m3.1.1.2" xref="S3.SS3.p3.3.m3.1.1.2.cmml">𝐈</mi><mi id="S3.SS3.p3.3.m3.1.1.3" xref="S3.SS3.p3.3.m3.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p3.3.m3.1b"><apply id="S3.SS3.p3.3.m3.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p3.3.m3.1.1.1.cmml" xref="S3.SS3.p3.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p3.3.m3.1.1.2.cmml" xref="S3.SS3.p3.3.m3.1.1.2">𝐈</ci><ci id="S3.SS3.p3.3.m3.1.1.3.cmml" xref="S3.SS3.p3.3.m3.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p3.3.m3.1c">\mathbf{I}_{i}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p3.3.m3.1d">bold_I start_POSTSUBSCRIPT italic_i end_POSTSUBSCRIPT</annotation></semantics></math> from its known pose.</p>
</div>
<div class="ltx_para" id="S3.SS3.p4">
<p class="ltx_p" id="S3.SS3.p4.1">We condition the MLP with the spherical harmonics encoding of the globally consistent lighting direction <math alttext="\boldsymbol{l}^{\prime}" class="ltx_Math" display="inline" id="S3.SS3.p4.1.m1.1"><semantics id="S3.SS3.p4.1.m1.1a"><msup id="S3.SS3.p4.1.m1.1.1" xref="S3.SS3.p4.1.m1.1.1.cmml"><mi id="S3.SS3.p4.1.m1.1.1.2" xref="S3.SS3.p4.1.m1.1.1.2.cmml">𝒍</mi><mo id="S3.SS3.p4.1.m1.1.1.3" xref="S3.SS3.p4.1.m1.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p4.1.m1.1b"><apply id="S3.SS3.p4.1.m1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p4.1.m1.1.1.1.cmml" xref="S3.SS3.p4.1.m1.1.1">superscript</csymbol><ci id="S3.SS3.p4.1.m1.1.1.2.cmml" xref="S3.SS3.p4.1.m1.1.1.2">𝒍</ci><ci id="S3.SS3.p4.1.m1.1.1.3.cmml" xref="S3.SS3.p4.1.m1.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p4.1.m1.1c">\boldsymbol{l}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p4.1.m1.1d">bold_italic_l start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math>, which enables training a 3DGS representation on our multi-lighting dataset. While this strategy works well for static images, it results in inconsistent lighting across views despite accounting for camera rotation in Eq. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.E2" title="In 3.3 Training a Lighting-Consistent Radiance Field ‣ 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">2</span></a>. Radiance fields like 3DGS rely on multi-view consistency, and breaking it introduces additional floaters and holes in surfaces.</p>
</div>
<div class="ltx_para" id="S3.SS3.p5">
<p class="ltx_p" id="S3.SS3.p5.3">To allow the neural network to account for this inconsistency and correct accordingly, we optimize a per-image auxiliary latent vector <math alttext="\boldsymbol{a}" class="ltx_Math" display="inline" id="S3.SS3.p5.1.m1.1"><semantics id="S3.SS3.p5.1.m1.1a"><mi id="S3.SS3.p5.1.m1.1.1" xref="S3.SS3.p5.1.m1.1.1.cmml">𝒂</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.1.m1.1b"><ci id="S3.SS3.p5.1.m1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1">𝒂</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.1.m1.1c">\boldsymbol{a}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.1.m1.1d">bold_italic_a</annotation></semantics></math> of size 128. Similar approaches for variable appearance have been used for NeRFs <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx33" title="">MBRS<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>21</a>]</cite>.
Therefore, in addition to the lighting direction <math alttext="\boldsymbol{l}^{\prime}" class="ltx_Math" display="inline" id="S3.SS3.p5.2.m2.1"><semantics id="S3.SS3.p5.2.m2.1a"><msup id="S3.SS3.p5.2.m2.1.1" xref="S3.SS3.p5.2.m2.1.1.cmml"><mi id="S3.SS3.p5.2.m2.1.1.2" xref="S3.SS3.p5.2.m2.1.1.2.cmml">𝒍</mi><mo id="S3.SS3.p5.2.m2.1.1.3" xref="S3.SS3.p5.2.m2.1.1.3.cmml">′</mo></msup><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.2.m2.1b"><apply id="S3.SS3.p5.2.m2.1.1.cmml" xref="S3.SS3.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS3.p5.2.m2.1.1.1.cmml" xref="S3.SS3.p5.2.m2.1.1">superscript</csymbol><ci id="S3.SS3.p5.2.m2.1.1.2.cmml" xref="S3.SS3.p5.2.m2.1.1.2">𝒍</ci><ci id="S3.SS3.p5.2.m2.1.1.3.cmml" xref="S3.SS3.p5.2.m2.1.1.3">′</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.2.m2.1c">\boldsymbol{l}^{\prime}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.2.m2.1d">bold_italic_l start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT</annotation></semantics></math>, we condition the MLP with per-view auxiliary parameters <math alttext="\boldsymbol{a}" class="ltx_Math" display="inline" id="S3.SS3.p5.3.m3.1"><semantics id="S3.SS3.p5.3.m3.1a"><mi id="S3.SS3.p5.3.m3.1.1" xref="S3.SS3.p5.3.m3.1.1.cmml">𝒂</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.3.m3.1b"><ci id="S3.SS3.p5.3.m3.1.1.cmml" xref="S3.SS3.p5.3.m3.1.1">𝒂</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.3.m3.1c">\boldsymbol{a}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.3.m3.1d">bold_italic_a</annotation></semantics></math>:</p>
<table class="ltx_equation ltx_eqn_table" id="S3.E3">
<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math alttext="\boldsymbol{c}(\boldsymbol{o},\boldsymbol{d})=\sum_{g=1}^{G}w_{g}\boldsymbol{c%
}_{\theta}(\boldsymbol{x}_{g},\boldsymbol{d}|\boldsymbol{a}_{v},\boldsymbol{l}%
^{\prime})\,," class="ltx_Math" display="block" id="S3.E3.m1.3"><semantics id="S3.E3.m1.3a"><mrow id="S3.E3.m1.3.3.1" xref="S3.E3.m1.3.3.1.1.cmml"><mrow id="S3.E3.m1.3.3.1.1" xref="S3.E3.m1.3.3.1.1.cmml"><mrow id="S3.E3.m1.3.3.1.1.4" xref="S3.E3.m1.3.3.1.1.4.cmml"><mi id="S3.E3.m1.3.3.1.1.4.2" xref="S3.E3.m1.3.3.1.1.4.2.cmml">𝒄</mi><mo id="S3.E3.m1.3.3.1.1.4.1" xref="S3.E3.m1.3.3.1.1.4.1.cmml">⁢</mo><mrow id="S3.E3.m1.3.3.1.1.4.3.2" xref="S3.E3.m1.3.3.1.1.4.3.1.cmml"><mo id="S3.E3.m1.3.3.1.1.4.3.2.1" stretchy="false" xref="S3.E3.m1.3.3.1.1.4.3.1.cmml">(</mo><mi id="S3.E3.m1.1.1" xref="S3.E3.m1.1.1.cmml">𝒐</mi><mo id="S3.E3.m1.3.3.1.1.4.3.2.2" xref="S3.E3.m1.3.3.1.1.4.3.1.cmml">,</mo><mi id="S3.E3.m1.2.2" xref="S3.E3.m1.2.2.cmml">𝒅</mi><mo id="S3.E3.m1.3.3.1.1.4.3.2.3" stretchy="false" xref="S3.E3.m1.3.3.1.1.4.3.1.cmml">)</mo></mrow></mrow><mo id="S3.E3.m1.3.3.1.1.3" rspace="0.111em" xref="S3.E3.m1.3.3.1.1.3.cmml">=</mo><mrow id="S3.E3.m1.3.3.1.1.2" xref="S3.E3.m1.3.3.1.1.2.cmml"><munderover id="S3.E3.m1.3.3.1.1.2.3" xref="S3.E3.m1.3.3.1.1.2.3.cmml"><mo id="S3.E3.m1.3.3.1.1.2.3.2.2" movablelimits="false" xref="S3.E3.m1.3.3.1.1.2.3.2.2.cmml">∑</mo><mrow id="S3.E3.m1.3.3.1.1.2.3.2.3" xref="S3.E3.m1.3.3.1.1.2.3.2.3.cmml"><mi id="S3.E3.m1.3.3.1.1.2.3.2.3.2" xref="S3.E3.m1.3.3.1.1.2.3.2.3.2.cmml">g</mi><mo id="S3.E3.m1.3.3.1.1.2.3.2.3.1" xref="S3.E3.m1.3.3.1.1.2.3.2.3.1.cmml">=</mo><mn id="S3.E3.m1.3.3.1.1.2.3.2.3.3" xref="S3.E3.m1.3.3.1.1.2.3.2.3.3.cmml">1</mn></mrow><mi id="S3.E3.m1.3.3.1.1.2.3.3" xref="S3.E3.m1.3.3.1.1.2.3.3.cmml">G</mi></munderover><mrow id="S3.E3.m1.3.3.1.1.2.2" xref="S3.E3.m1.3.3.1.1.2.2.cmml"><msub id="S3.E3.m1.3.3.1.1.2.2.4" xref="S3.E3.m1.3.3.1.1.2.2.4.cmml"><mi id="S3.E3.m1.3.3.1.1.2.2.4.2" xref="S3.E3.m1.3.3.1.1.2.2.4.2.cmml">w</mi><mi id="S3.E3.m1.3.3.1.1.2.2.4.3" xref="S3.E3.m1.3.3.1.1.2.2.4.3.cmml">g</mi></msub><mo id="S3.E3.m1.3.3.1.1.2.2.3" xref="S3.E3.m1.3.3.1.1.2.2.3.cmml">⁢</mo><msub id="S3.E3.m1.3.3.1.1.2.2.5" xref="S3.E3.m1.3.3.1.1.2.2.5.cmml"><mi id="S3.E3.m1.3.3.1.1.2.2.5.2" xref="S3.E3.m1.3.3.1.1.2.2.5.2.cmml">𝒄</mi><mi id="S3.E3.m1.3.3.1.1.2.2.5.3" xref="S3.E3.m1.3.3.1.1.2.2.5.3.cmml">θ</mi></msub><mo id="S3.E3.m1.3.3.1.1.2.2.3a" xref="S3.E3.m1.3.3.1.1.2.2.3.cmml">⁢</mo><mrow id="S3.E3.m1.3.3.1.1.2.2.2.2" xref="S3.E3.m1.3.3.1.1.2.2.2.3.cmml"><mo id="S3.E3.m1.3.3.1.1.2.2.2.2.3" stretchy="false" xref="S3.E3.m1.3.3.1.1.2.2.2.3.cmml">(</mo><msub id="S3.E3.m1.3.3.1.1.1.1.1.1.1" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.cmml"><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.2" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.2.cmml">𝒙</mi><mi id="S3.E3.m1.3.3.1.1.1.1.1.1.1.3" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.3.cmml">g</mi></msub><mo id="S3.E3.m1.3.3.1.1.2.2.2.2.4" xref="S3.E3.m1.3.3.1.1.2.2.2.3.cmml">,</mo><mrow id="S3.E3.m1.3.3.1.1.2.2.2.2.2" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.cmml"><mi id="S3.E3.m1.3.3.1.1.2.2.2.2.2.4" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.4.cmml">𝒅</mi><mo fence="false" id="S3.E3.m1.3.3.1.1.2.2.2.2.2.3" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.3.cmml">|</mo><mrow id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.3.cmml"><msub id="S3.E3.m1.3.3.1.1.2.2.2.2.2.1.1.1" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.1.1.1.cmml"><mi id="S3.E3.m1.3.3.1.1.2.2.2.2.2.1.1.1.2" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.1.1.1.2.cmml">𝒂</mi><mi id="S3.E3.m1.3.3.1.1.2.2.2.2.2.1.1.1.3" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.1.1.1.3.cmml">v</mi></msub><mo id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.3" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.3.cmml">,</mo><msup id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.2" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.2.cmml"><mi id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.2.2" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.2.2.cmml">𝒍</mi><mo id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.2.3" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.2.3.cmml">′</mo></msup></mrow></mrow><mo id="S3.E3.m1.3.3.1.1.2.2.2.2.5" rspace="0.110em" stretchy="false" xref="S3.E3.m1.3.3.1.1.2.2.2.3.cmml">)</mo></mrow></mrow></mrow></mrow><mo id="S3.E3.m1.3.3.1.2" xref="S3.E3.m1.3.3.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.E3.m1.3b"><apply id="S3.E3.m1.3.3.1.1.cmml" xref="S3.E3.m1.3.3.1"><eq id="S3.E3.m1.3.3.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.3"></eq><apply id="S3.E3.m1.3.3.1.1.4.cmml" xref="S3.E3.m1.3.3.1.1.4"><times id="S3.E3.m1.3.3.1.1.4.1.cmml" xref="S3.E3.m1.3.3.1.1.4.1"></times><ci id="S3.E3.m1.3.3.1.1.4.2.cmml" xref="S3.E3.m1.3.3.1.1.4.2">𝒄</ci><interval closure="open" id="S3.E3.m1.3.3.1.1.4.3.1.cmml" xref="S3.E3.m1.3.3.1.1.4.3.2"><ci id="S3.E3.m1.1.1.cmml" xref="S3.E3.m1.1.1">𝒐</ci><ci id="S3.E3.m1.2.2.cmml" xref="S3.E3.m1.2.2">𝒅</ci></interval></apply><apply id="S3.E3.m1.3.3.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.2"><apply id="S3.E3.m1.3.3.1.1.2.3.cmml" xref="S3.E3.m1.3.3.1.1.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.2.3.1.cmml" xref="S3.E3.m1.3.3.1.1.2.3">superscript</csymbol><apply id="S3.E3.m1.3.3.1.1.2.3.2.cmml" xref="S3.E3.m1.3.3.1.1.2.3"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.2.3.2.1.cmml" xref="S3.E3.m1.3.3.1.1.2.3">subscript</csymbol><sum id="S3.E3.m1.3.3.1.1.2.3.2.2.cmml" xref="S3.E3.m1.3.3.1.1.2.3.2.2"></sum><apply id="S3.E3.m1.3.3.1.1.2.3.2.3.cmml" xref="S3.E3.m1.3.3.1.1.2.3.2.3"><eq id="S3.E3.m1.3.3.1.1.2.3.2.3.1.cmml" xref="S3.E3.m1.3.3.1.1.2.3.2.3.1"></eq><ci id="S3.E3.m1.3.3.1.1.2.3.2.3.2.cmml" xref="S3.E3.m1.3.3.1.1.2.3.2.3.2">𝑔</ci><cn id="S3.E3.m1.3.3.1.1.2.3.2.3.3.cmml" type="integer" xref="S3.E3.m1.3.3.1.1.2.3.2.3.3">1</cn></apply></apply><ci id="S3.E3.m1.3.3.1.1.2.3.3.cmml" xref="S3.E3.m1.3.3.1.1.2.3.3">𝐺</ci></apply><apply id="S3.E3.m1.3.3.1.1.2.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2"><times id="S3.E3.m1.3.3.1.1.2.2.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.3"></times><apply id="S3.E3.m1.3.3.1.1.2.2.4.cmml" xref="S3.E3.m1.3.3.1.1.2.2.4"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.2.2.4.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.4">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.2.2.4.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.4.2">𝑤</ci><ci id="S3.E3.m1.3.3.1.1.2.2.4.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.4.3">𝑔</ci></apply><apply id="S3.E3.m1.3.3.1.1.2.2.5.cmml" xref="S3.E3.m1.3.3.1.1.2.2.5"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.2.2.5.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.5">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.2.2.5.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.5.2">𝒄</ci><ci id="S3.E3.m1.3.3.1.1.2.2.5.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.5.3">𝜃</ci></apply><interval closure="open" id="S3.E3.m1.3.3.1.1.2.2.2.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2"><apply id="S3.E3.m1.3.3.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.1.1.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.2">𝒙</ci><ci id="S3.E3.m1.3.3.1.1.1.1.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.1.1.1.1.1.3">𝑔</ci></apply><apply id="S3.E3.m1.3.3.1.1.2.2.2.2.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2"><csymbol cd="latexml" id="S3.E3.m1.3.3.1.1.2.2.2.2.2.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.3">conditional</csymbol><ci id="S3.E3.m1.3.3.1.1.2.2.2.2.2.4.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.4">𝒅</ci><list id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2"><apply id="S3.E3.m1.3.3.1.1.2.2.2.2.2.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.1.1.1"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.2.2.2.2.2.1.1.1.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.1.1.1">subscript</csymbol><ci id="S3.E3.m1.3.3.1.1.2.2.2.2.2.1.1.1.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.1.1.1.2">𝒂</ci><ci id="S3.E3.m1.3.3.1.1.2.2.2.2.2.1.1.1.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.1.1.1.3">𝑣</ci></apply><apply id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.2"><csymbol cd="ambiguous" id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.2.1.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.2">superscript</csymbol><ci id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.2.2.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.2.2">𝒍</ci><ci id="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.2.3.cmml" xref="S3.E3.m1.3.3.1.1.2.2.2.2.2.2.2.2.3">′</ci></apply></list></apply></interval></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E3.m1.3c">\boldsymbol{c}(\boldsymbol{o},\boldsymbol{d})=\sum_{g=1}^{G}w_{g}\boldsymbol{c%
}_{\theta}(\boldsymbol{x}_{g},\boldsymbol{d}|\boldsymbol{a}_{v},\boldsymbol{l}%
^{\prime})\,,</annotation><annotation encoding="application/x-llamapun" id="S3.E3.m1.3d">bold_italic_c ( bold_italic_o , bold_italic_d ) = ∑ start_POSTSUBSCRIPT italic_g = 1 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT italic_G end_POSTSUPERSCRIPT italic_w start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT bold_italic_c start_POSTSUBSCRIPT italic_θ end_POSTSUBSCRIPT ( bold_italic_x start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT , bold_italic_d | bold_italic_a start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT , bold_italic_l start_POSTSUPERSCRIPT ′ end_POSTSUPERSCRIPT ) ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right" rowspan="1"><span class="ltx_tag ltx_tag_equation ltx_align_right">(3)</span></td>
</tr></tbody>
</table>
<p class="ltx_p" id="S3.SS3.p5.10">where <math alttext="g\in[1,G]" class="ltx_Math" display="inline" id="S3.SS3.p5.4.m1.2"><semantics id="S3.SS3.p5.4.m1.2a"><mrow id="S3.SS3.p5.4.m1.2.3" xref="S3.SS3.p5.4.m1.2.3.cmml"><mi id="S3.SS3.p5.4.m1.2.3.2" xref="S3.SS3.p5.4.m1.2.3.2.cmml">g</mi><mo id="S3.SS3.p5.4.m1.2.3.1" xref="S3.SS3.p5.4.m1.2.3.1.cmml">∈</mo><mrow id="S3.SS3.p5.4.m1.2.3.3.2" xref="S3.SS3.p5.4.m1.2.3.3.1.cmml"><mo id="S3.SS3.p5.4.m1.2.3.3.2.1" stretchy="false" xref="S3.SS3.p5.4.m1.2.3.3.1.cmml">[</mo><mn id="S3.SS3.p5.4.m1.1.1" xref="S3.SS3.p5.4.m1.1.1.cmml">1</mn><mo id="S3.SS3.p5.4.m1.2.3.3.2.2" xref="S3.SS3.p5.4.m1.2.3.3.1.cmml">,</mo><mi id="S3.SS3.p5.4.m1.2.2" xref="S3.SS3.p5.4.m1.2.2.cmml">G</mi><mo id="S3.SS3.p5.4.m1.2.3.3.2.3" stretchy="false" xref="S3.SS3.p5.4.m1.2.3.3.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.4.m1.2b"><apply id="S3.SS3.p5.4.m1.2.3.cmml" xref="S3.SS3.p5.4.m1.2.3"><in id="S3.SS3.p5.4.m1.2.3.1.cmml" xref="S3.SS3.p5.4.m1.2.3.1"></in><ci id="S3.SS3.p5.4.m1.2.3.2.cmml" xref="S3.SS3.p5.4.m1.2.3.2">𝑔</ci><interval closure="closed" id="S3.SS3.p5.4.m1.2.3.3.1.cmml" xref="S3.SS3.p5.4.m1.2.3.3.2"><cn id="S3.SS3.p5.4.m1.1.1.cmml" type="integer" xref="S3.SS3.p5.4.m1.1.1">1</cn><ci id="S3.SS3.p5.4.m1.2.2.cmml" xref="S3.SS3.p5.4.m1.2.2">𝐺</ci></interval></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.4.m1.2c">g\in[1,G]</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.4.m1.2d">italic_g ∈ [ 1 , italic_G ]</annotation></semantics></math> sums over the <math alttext="G" class="ltx_Math" display="inline" id="S3.SS3.p5.5.m2.1"><semantics id="S3.SS3.p5.5.m2.1a"><mi id="S3.SS3.p5.5.m2.1.1" xref="S3.SS3.p5.5.m2.1.1.cmml">G</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.5.m2.1b"><ci id="S3.SS3.p5.5.m2.1.1.cmml" xref="S3.SS3.p5.5.m2.1.1">𝐺</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.5.m2.1c">G</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.5.m2.1d">italic_G</annotation></semantics></math> gaussians (see <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx21" title="">KKLD23</a>]</cite>), <math alttext="\boldsymbol{x}_{g}/w_{g}" class="ltx_Math" display="inline" id="S3.SS3.p5.6.m3.1"><semantics id="S3.SS3.p5.6.m3.1a"><mrow id="S3.SS3.p5.6.m3.1.1" xref="S3.SS3.p5.6.m3.1.1.cmml"><msub id="S3.SS3.p5.6.m3.1.1.2" xref="S3.SS3.p5.6.m3.1.1.2.cmml"><mi id="S3.SS3.p5.6.m3.1.1.2.2" xref="S3.SS3.p5.6.m3.1.1.2.2.cmml">𝒙</mi><mi id="S3.SS3.p5.6.m3.1.1.2.3" xref="S3.SS3.p5.6.m3.1.1.2.3.cmml">g</mi></msub><mo id="S3.SS3.p5.6.m3.1.1.1" xref="S3.SS3.p5.6.m3.1.1.1.cmml">/</mo><msub id="S3.SS3.p5.6.m3.1.1.3" xref="S3.SS3.p5.6.m3.1.1.3.cmml"><mi id="S3.SS3.p5.6.m3.1.1.3.2" xref="S3.SS3.p5.6.m3.1.1.3.2.cmml">w</mi><mi id="S3.SS3.p5.6.m3.1.1.3.3" xref="S3.SS3.p5.6.m3.1.1.3.3.cmml">g</mi></msub></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.6.m3.1b"><apply id="S3.SS3.p5.6.m3.1.1.cmml" xref="S3.SS3.p5.6.m3.1.1"><divide id="S3.SS3.p5.6.m3.1.1.1.cmml" xref="S3.SS3.p5.6.m3.1.1.1"></divide><apply id="S3.SS3.p5.6.m3.1.1.2.cmml" xref="S3.SS3.p5.6.m3.1.1.2"><csymbol cd="ambiguous" id="S3.SS3.p5.6.m3.1.1.2.1.cmml" xref="S3.SS3.p5.6.m3.1.1.2">subscript</csymbol><ci id="S3.SS3.p5.6.m3.1.1.2.2.cmml" xref="S3.SS3.p5.6.m3.1.1.2.2">𝒙</ci><ci id="S3.SS3.p5.6.m3.1.1.2.3.cmml" xref="S3.SS3.p5.6.m3.1.1.2.3">𝑔</ci></apply><apply id="S3.SS3.p5.6.m3.1.1.3.cmml" xref="S3.SS3.p5.6.m3.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p5.6.m3.1.1.3.1.cmml" xref="S3.SS3.p5.6.m3.1.1.3">subscript</csymbol><ci id="S3.SS3.p5.6.m3.1.1.3.2.cmml" xref="S3.SS3.p5.6.m3.1.1.3.2">𝑤</ci><ci id="S3.SS3.p5.6.m3.1.1.3.3.cmml" xref="S3.SS3.p5.6.m3.1.1.3.3">𝑔</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.6.m3.1c">\boldsymbol{x}_{g}/w_{g}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.6.m3.1d">bold_italic_x start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT / italic_w start_POSTSUBSCRIPT italic_g end_POSTSUBSCRIPT</annotation></semantics></math> are their features/weights, <math alttext="\boldsymbol{d}" class="ltx_Math" display="inline" id="S3.SS3.p5.7.m4.1"><semantics id="S3.SS3.p5.7.m4.1a"><mi id="S3.SS3.p5.7.m4.1.1" xref="S3.SS3.p5.7.m4.1.1.cmml">𝒅</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.7.m4.1b"><ci id="S3.SS3.p5.7.m4.1.1.cmml" xref="S3.SS3.p5.7.m4.1.1">𝒅</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.7.m4.1c">\boldsymbol{d}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.7.m4.1d">bold_italic_d</annotation></semantics></math> is the view direction, <math alttext="\boldsymbol{o}" class="ltx_Math" display="inline" id="S3.SS3.p5.8.m5.1"><semantics id="S3.SS3.p5.8.m5.1a"><mi id="S3.SS3.p5.8.m5.1.1" xref="S3.SS3.p5.8.m5.1.1.cmml">𝒐</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.8.m5.1b"><ci id="S3.SS3.p5.8.m5.1.1.cmml" xref="S3.SS3.p5.8.m5.1.1">𝒐</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.8.m5.1c">\boldsymbol{o}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.8.m5.1d">bold_italic_o</annotation></semantics></math> the ray origin, and <math alttext="\boldsymbol{c}" class="ltx_Math" display="inline" id="S3.SS3.p5.9.m6.1"><semantics id="S3.SS3.p5.9.m6.1a"><mi id="S3.SS3.p5.9.m6.1.1" xref="S3.SS3.p5.9.m6.1.1.cmml">𝒄</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.9.m6.1b"><ci id="S3.SS3.p5.9.m6.1.1.cmml" xref="S3.SS3.p5.9.m6.1.1">𝒄</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.9.m6.1c">\boldsymbol{c}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.9.m6.1d">bold_italic_c</annotation></semantics></math> is the predicted pixel color. Note that for novel views at inference, we use as latent vector the mean of all training view latents i.e. <math alttext="\mathbb{E}_{v}[\boldsymbol{a}_{v}]" class="ltx_Math" display="inline" id="S3.SS3.p5.10.m7.1"><semantics id="S3.SS3.p5.10.m7.1a"><mrow id="S3.SS3.p5.10.m7.1.1" xref="S3.SS3.p5.10.m7.1.1.cmml"><msub id="S3.SS3.p5.10.m7.1.1.3" xref="S3.SS3.p5.10.m7.1.1.3.cmml"><mi id="S3.SS3.p5.10.m7.1.1.3.2" xref="S3.SS3.p5.10.m7.1.1.3.2.cmml">𝔼</mi><mi id="S3.SS3.p5.10.m7.1.1.3.3" xref="S3.SS3.p5.10.m7.1.1.3.3.cmml">v</mi></msub><mo id="S3.SS3.p5.10.m7.1.1.2" xref="S3.SS3.p5.10.m7.1.1.2.cmml">⁢</mo><mrow id="S3.SS3.p5.10.m7.1.1.1.1" xref="S3.SS3.p5.10.m7.1.1.1.2.cmml"><mo id="S3.SS3.p5.10.m7.1.1.1.1.2" stretchy="false" xref="S3.SS3.p5.10.m7.1.1.1.2.1.cmml">[</mo><msub id="S3.SS3.p5.10.m7.1.1.1.1.1" xref="S3.SS3.p5.10.m7.1.1.1.1.1.cmml"><mi id="S3.SS3.p5.10.m7.1.1.1.1.1.2" xref="S3.SS3.p5.10.m7.1.1.1.1.1.2.cmml">𝒂</mi><mi id="S3.SS3.p5.10.m7.1.1.1.1.1.3" xref="S3.SS3.p5.10.m7.1.1.1.1.1.3.cmml">v</mi></msub><mo id="S3.SS3.p5.10.m7.1.1.1.1.3" stretchy="false" xref="S3.SS3.p5.10.m7.1.1.1.2.1.cmml">]</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.10.m7.1b"><apply id="S3.SS3.p5.10.m7.1.1.cmml" xref="S3.SS3.p5.10.m7.1.1"><times id="S3.SS3.p5.10.m7.1.1.2.cmml" xref="S3.SS3.p5.10.m7.1.1.2"></times><apply id="S3.SS3.p5.10.m7.1.1.3.cmml" xref="S3.SS3.p5.10.m7.1.1.3"><csymbol cd="ambiguous" id="S3.SS3.p5.10.m7.1.1.3.1.cmml" xref="S3.SS3.p5.10.m7.1.1.3">subscript</csymbol><ci id="S3.SS3.p5.10.m7.1.1.3.2.cmml" xref="S3.SS3.p5.10.m7.1.1.3.2">𝔼</ci><ci id="S3.SS3.p5.10.m7.1.1.3.3.cmml" xref="S3.SS3.p5.10.m7.1.1.3.3">𝑣</ci></apply><apply id="S3.SS3.p5.10.m7.1.1.1.2.cmml" xref="S3.SS3.p5.10.m7.1.1.1.1"><csymbol cd="latexml" id="S3.SS3.p5.10.m7.1.1.1.2.1.cmml" xref="S3.SS3.p5.10.m7.1.1.1.1.2">delimited-[]</csymbol><apply id="S3.SS3.p5.10.m7.1.1.1.1.1.cmml" xref="S3.SS3.p5.10.m7.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p5.10.m7.1.1.1.1.1.1.cmml" xref="S3.SS3.p5.10.m7.1.1.1.1.1">subscript</csymbol><ci id="S3.SS3.p5.10.m7.1.1.1.1.1.2.cmml" xref="S3.SS3.p5.10.m7.1.1.1.1.1.2">𝒂</ci><ci id="S3.SS3.p5.10.m7.1.1.1.1.1.3.cmml" xref="S3.SS3.p5.10.m7.1.1.1.1.1.3">𝑣</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.10.m7.1c">\mathbb{E}_{v}[\boldsymbol{a}_{v}]</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p5.10.m7.1d">blackboard_E start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT [ bold_italic_a start_POSTSUBSCRIPT italic_v end_POSTSUBSCRIPT ]</annotation></semantics></math>.</p>
</div>
<div class="ltx_para" id="S3.SS3.p6">
<p class="ltx_p" id="S3.SS3.p6.3">We first train 3DGS with the unlit images as a “warmup” stage for 5K iterations, then train the full multi-illumination solution for another 25K iterations, using all 18 back-facing light directions (see Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.SS1" title="3.1 Single-View Relighting with 2D Diffusion Priors ‣ 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">3.1</span></a>). The multi-illumination nature of the training results in an increase in “floaters”. As observed by Philip and Deschaintre <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx39" title="">PD23</a>]</cite>, floaters are often present close to the input cameras; the explicit nature of 3DGS allows us to reduce these effectively. In particular, we calculate a <math alttext="z_{near}" class="ltx_Math" display="inline" id="S3.SS3.p6.1.m1.1"><semantics id="S3.SS3.p6.1.m1.1a"><msub id="S3.SS3.p6.1.m1.1.1" xref="S3.SS3.p6.1.m1.1.1.cmml"><mi id="S3.SS3.p6.1.m1.1.1.2" xref="S3.SS3.p6.1.m1.1.1.2.cmml">z</mi><mrow id="S3.SS3.p6.1.m1.1.1.3" xref="S3.SS3.p6.1.m1.1.1.3.cmml"><mi id="S3.SS3.p6.1.m1.1.1.3.2" xref="S3.SS3.p6.1.m1.1.1.3.2.cmml">n</mi><mo id="S3.SS3.p6.1.m1.1.1.3.1" xref="S3.SS3.p6.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p6.1.m1.1.1.3.3" xref="S3.SS3.p6.1.m1.1.1.3.3.cmml">e</mi><mo id="S3.SS3.p6.1.m1.1.1.3.1a" xref="S3.SS3.p6.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p6.1.m1.1.1.3.4" xref="S3.SS3.p6.1.m1.1.1.3.4.cmml">a</mi><mo id="S3.SS3.p6.1.m1.1.1.3.1b" xref="S3.SS3.p6.1.m1.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p6.1.m1.1.1.3.5" xref="S3.SS3.p6.1.m1.1.1.3.5.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.1.m1.1b"><apply id="S3.SS3.p6.1.m1.1.1.cmml" xref="S3.SS3.p6.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.1.m1.1.1.1.cmml" xref="S3.SS3.p6.1.m1.1.1">subscript</csymbol><ci id="S3.SS3.p6.1.m1.1.1.2.cmml" xref="S3.SS3.p6.1.m1.1.1.2">𝑧</ci><apply id="S3.SS3.p6.1.m1.1.1.3.cmml" xref="S3.SS3.p6.1.m1.1.1.3"><times id="S3.SS3.p6.1.m1.1.1.3.1.cmml" xref="S3.SS3.p6.1.m1.1.1.3.1"></times><ci id="S3.SS3.p6.1.m1.1.1.3.2.cmml" xref="S3.SS3.p6.1.m1.1.1.3.2">𝑛</ci><ci id="S3.SS3.p6.1.m1.1.1.3.3.cmml" xref="S3.SS3.p6.1.m1.1.1.3.3">𝑒</ci><ci id="S3.SS3.p6.1.m1.1.1.3.4.cmml" xref="S3.SS3.p6.1.m1.1.1.3.4">𝑎</ci><ci id="S3.SS3.p6.1.m1.1.1.3.5.cmml" xref="S3.SS3.p6.1.m1.1.1.3.5">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.1.m1.1c">z_{near}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p6.1.m1.1d">italic_z start_POSTSUBSCRIPT italic_n italic_e italic_a italic_r end_POSTSUBSCRIPT</annotation></semantics></math> value for all cameras by taking the <math alttext="z" class="ltx_Math" display="inline" id="S3.SS3.p6.2.m2.1"><semantics id="S3.SS3.p6.2.m2.1a"><mi id="S3.SS3.p6.2.m2.1.1" xref="S3.SS3.p6.2.m2.1.1.cmml">z</mi><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.2.m2.1b"><ci id="S3.SS3.p6.2.m2.1.1.cmml" xref="S3.SS3.p6.2.m2.1.1">𝑧</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.2.m2.1c">z</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p6.2.m2.1d">italic_z</annotation></semantics></math> value of the 1st percentile of nearest SfM points and scaling this value down by 0.9. During training, at each step, all gaussian primitives that project within the view frustum of a camera but are located in front of its <math alttext="z_{near}" class="ltx_Math" display="inline" id="S3.SS3.p6.3.m3.1"><semantics id="S3.SS3.p6.3.m3.1a"><msub id="S3.SS3.p6.3.m3.1.1" xref="S3.SS3.p6.3.m3.1.1.cmml"><mi id="S3.SS3.p6.3.m3.1.1.2" xref="S3.SS3.p6.3.m3.1.1.2.cmml">z</mi><mrow id="S3.SS3.p6.3.m3.1.1.3" xref="S3.SS3.p6.3.m3.1.1.3.cmml"><mi id="S3.SS3.p6.3.m3.1.1.3.2" xref="S3.SS3.p6.3.m3.1.1.3.2.cmml">n</mi><mo id="S3.SS3.p6.3.m3.1.1.3.1" xref="S3.SS3.p6.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p6.3.m3.1.1.3.3" xref="S3.SS3.p6.3.m3.1.1.3.3.cmml">e</mi><mo id="S3.SS3.p6.3.m3.1.1.3.1a" xref="S3.SS3.p6.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p6.3.m3.1.1.3.4" xref="S3.SS3.p6.3.m3.1.1.3.4.cmml">a</mi><mo id="S3.SS3.p6.3.m3.1.1.3.1b" xref="S3.SS3.p6.3.m3.1.1.3.1.cmml">⁢</mo><mi id="S3.SS3.p6.3.m3.1.1.3.5" xref="S3.SS3.p6.3.m3.1.1.3.5.cmml">r</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS3.p6.3.m3.1b"><apply id="S3.SS3.p6.3.m3.1.1.cmml" xref="S3.SS3.p6.3.m3.1.1"><csymbol cd="ambiguous" id="S3.SS3.p6.3.m3.1.1.1.cmml" xref="S3.SS3.p6.3.m3.1.1">subscript</csymbol><ci id="S3.SS3.p6.3.m3.1.1.2.cmml" xref="S3.SS3.p6.3.m3.1.1.2">𝑧</ci><apply id="S3.SS3.p6.3.m3.1.1.3.cmml" xref="S3.SS3.p6.3.m3.1.1.3"><times id="S3.SS3.p6.3.m3.1.1.3.1.cmml" xref="S3.SS3.p6.3.m3.1.1.3.1"></times><ci id="S3.SS3.p6.3.m3.1.1.3.2.cmml" xref="S3.SS3.p6.3.m3.1.1.3.2">𝑛</ci><ci id="S3.SS3.p6.3.m3.1.1.3.3.cmml" xref="S3.SS3.p6.3.m3.1.1.3.3">𝑒</ci><ci id="S3.SS3.p6.3.m3.1.1.3.4.cmml" xref="S3.SS3.p6.3.m3.1.1.3.4">𝑎</ci><ci id="S3.SS3.p6.3.m3.1.1.3.5.cmml" xref="S3.SS3.p6.3.m3.1.1.3.5">𝑟</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p6.3.m3.1c">z_{near}</annotation><annotation encoding="application/x-llamapun" id="S3.SS3.p6.3.m3.1d">italic_z start_POSTSUBSCRIPT italic_n italic_e italic_a italic_r end_POSTSUBSCRIPT</annotation></semantics></math> plane are culled. Finally, given the complexity of modeling variable lighting, we observed that the optimization sometimes converges to blurry results. To counter this, we overweight three front-facing views (left, right, and center), by optimizing for one of these views every three iterations. This provides marginal improvement in results; all images shown are computed with this method, but it is optional.</p>
</div>
<div class="ltx_para" id="S3.SS3.p7">
<p class="ltx_p" id="S3.SS3.p7.1">The full method for relightable radiance fields is shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.F7" title="Figure 7 ‣ 3.3 Training a Lighting-Consistent Radiance Field ‣ 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">7</span></a>. At inference, we can directly choose a lighting direction, and use efficient 3DGS rendering for interactive updates with modified lighting. Our latent vectors and floater removal remove most, but not all, artifacts introduced by the multi-view inconsistencies; this can be seen in the ablations at the end of the supplemental video.</p>
</div>
<figure class="ltx_figure" id="S3.F7"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="652" id="S3.F7.g1" src="x4.png" width="830"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Overview of our radiance field training scheme. To alleviate potential inconsistencies in lighting directions, we condition our 3DGS-based radiance field both on the illumination direction encoding and on optimized auxiliary vectors (one per training image). These vectors model the differences between predictions and let us fit each view to convergence.</figcaption>
</figure>
<figure class="ltx_figure" id="S3.F8">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S3.F8.12">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S3.F8.6.6">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S3.F8.1.1.1" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S3.F8.1.1.1.1" style="position:relative; bottom:53.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="24" id="S3.F8.1.1.1.1.g1" src="extracted/5860470/figures/gray_balls/left.png" width="24"/></span></th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F8.2.2.2" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="86" id="S3.F8.2.2.2.g1" src="extracted/5860470/figures/results_real_scene/chestdrawer_2_00023.jpg" width="129"/></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.F8.3.3.3" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="86" id="S3.F8.3.3.3.g1" src="extracted/5860470/figures/results_real_scene/kettle_2_00023.jpg" width="129"/></td>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S3.F8.4.4.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S3.F8.4.4.4.1" style="position:relative; bottom:53.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="24" id="S3.F8.4.4.4.1.g1" src="extracted/5860470/figures/gray_balls/center.png" width="24"/></span></th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F8.5.5.5" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="86" id="S3.F8.5.5.5.g1" src="extracted/5860470/figures/results_real_scene/mipnerf_counter_00010.jpg" width="129"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F8.6.6.6" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="86" id="S3.F8.6.6.6.g1" src="extracted/5860470/figures/results_real_scene/garagewall_00010.jpg" width="129"/></td>
</tr>
<tr class="ltx_tr" id="S3.F8.12.12">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S3.F8.7.7.1" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S3.F8.7.7.1.1" style="position:relative; bottom:53.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="24" id="S3.F8.7.7.1.1.g1" src="extracted/5860470/figures/gray_balls/right.png" width="24"/></span></th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F8.8.8.2" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="86" id="S3.F8.8.8.2.g1" src="extracted/5860470/figures/results_real_scene/chestdrawer_2_00018.jpg" width="129"/></td>
<td class="ltx_td ltx_nopad_l ltx_align_center" id="S3.F8.9.9.3" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="86" id="S3.F8.9.9.3.g1" src="extracted/5860470/figures/results_real_scene/kettle_2_00018.jpg" width="129"/></td>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S3.F8.10.10.4" style="padding-left:1.0pt;padding-right:1.0pt;"><span class="ltx_text" id="S3.F8.10.10.4.1" style="position:relative; bottom:53.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="24" id="S3.F8.10.10.4.1.g1" src="extracted/5860470/figures/gray_balls/top.png" width="24"/></span></th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F8.11.11.5" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="86" id="S3.F8.11.11.5.g1" src="extracted/5860470/figures/results_real_scene/mipnerf_counter_00014.jpg" width="129"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S3.F8.12.12.6" style="padding-left:1.0pt;padding-right:1.0pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="86" id="S3.F8.12.12.6.g1" src="extracted/5860470/figures/results_real_scene/garagewall_00014.jpg" width="129"/></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>

Qualitative relighting results for the real scenes, from left to right: <span class="ltx_text ltx_font_smallcaps" id="S3.F8.17.1">Chest of Drawers</span>, <span class="ltx_text ltx_font_smallcaps" id="S3.F8.18.2">Kettle</span>, <span class="ltx_text ltx_font_smallcaps" id="S3.F8.19.3">MipNeRF Room</span> and <span class="ltx_text ltx_font_smallcaps" id="S3.F8.20.4">Garage Wall</span>, for a moving light source. The lighting direction is indicated in the gray ball in the lower right. Please see the supplemental video for more results. Please note how the highlights (left group) and shadows (right group) have changed.
</figcaption>
</figure>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Results and Evaluation</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">Our method was implemented by leveraging publicly available implementations of ControlNet <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx78" title="">ZRA23</a>]</cite> and 3DGS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx21" title="">KKLD23</a>]</cite>. We use Stable Diffusion <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx45" title="">RBL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>22</a>]</cite> v2.1 as a backbone. Our source code and datasets will be released upon publication.</p>
</div>
<div class="ltx_para" id="S4.p2">
<p class="ltx_p" id="S4.p2.1">We first present the results of our 3D relightable radiance field, both for synthetic and real-world scenes. We then present a quantitative and qualitative evaluation of our method by comparing it to previous work and finally present an ablation of the auxiliary vector <math alttext="a" class="ltx_Math" display="inline" id="S4.p2.1.m1.1"><semantics id="S4.p2.1.m1.1a"><mi id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml">a</mi><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><ci id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1">𝑎</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">a</annotation><annotation encoding="application/x-llamapun" id="S4.p2.1.m1.1d">italic_a</annotation></semantics></math> from Sec. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.SS3" title="3.3 Training a Lighting-Consistent Radiance Field ‣ 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">3.3</span></a>.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Test Datasets</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">Since there are no real <em class="ltx_emph ltx_font_italic" id="S4.SS1.p1.1.1">multi-view</em> multi-illumination indoor datasets of full scenes available for our evaluation, we use synthetic scenes to allow quantitative evaluation. For this purpose, we designed 4 synthetic test scenes (<span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p1.1.2">kitchen</span>, <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p1.1.3">livingroom</span>, <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p1.1.4">office</span>, <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p1.1.5">bedroom</span>). They were created in Blender by downloading artist-made 3D rooms from Evermotion and modifying them to increase clutter: in each room, we gathered objects and placed them on a table or a countertop.
We also created simpler, diffuse-only versions to evaluate how scene clutter affects the relighting results.
For each synthetic scene, we first built a standard multi-view (single-lighting) dataset consisting of 4 camera sweeps (left-to-right, at varying elevations) of 50 frames for training and one (at a different elevation) of 100 frames for testing. We simulated the light direction of the 2D training dataset with a spotlight with intensity of 2 kW and radius 0.1 locating on top of the camera and pointing away from it. We used the same set of camera flash directions as in the dataset of Murmann et al. <span class="ltx_ERROR undefined" id="S4.SS1.p1.1.6">\shortcite</span>multilum. We then render all frames in <math alttext="736\times 512" class="ltx_Math" display="inline" id="S4.SS1.p1.1.m1.1"><semantics id="S4.SS1.p1.1.m1.1a"><mrow id="S4.SS1.p1.1.m1.1.1" xref="S4.SS1.p1.1.m1.1.1.cmml"><mn id="S4.SS1.p1.1.m1.1.1.2" xref="S4.SS1.p1.1.m1.1.1.2.cmml">736</mn><mo id="S4.SS1.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS1.p1.1.m1.1.1.1.cmml">×</mo><mn id="S4.SS1.p1.1.m1.1.1.3" xref="S4.SS1.p1.1.m1.1.1.3.cmml">512</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS1.p1.1.m1.1b"><apply id="S4.SS1.p1.1.m1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1"><times id="S4.SS1.p1.1.m1.1.1.1.cmml" xref="S4.SS1.p1.1.m1.1.1.1"></times><cn id="S4.SS1.p1.1.m1.1.1.2.cmml" type="integer" xref="S4.SS1.p1.1.m1.1.1.2">736</cn><cn id="S4.SS1.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.SS1.p1.1.m1.1.1.3">512</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p1.1.m1.1c">736\times 512</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p1.1.m1.1d">736 × 512</annotation></semantics></math> using the Cycles path tracer. Please note that the effective lighting direction will be dependent on the exact configuration of the room. This configuration is our best effort to produce a ground truth usable for comparison.</p>
</div>
<div class="ltx_para" id="S4.SS1.p2">
<p class="ltx_p" id="S4.SS1.p2.2">In addition, we also captured a set of real scenes (<span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p2.2.1">Kettle</span>, <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p2.2.2">Hot Plates</span>, <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p2.2.3">Paint Gun</span>, <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p2.2.4">Chest of Drawers</span> and <span class="ltx_text ltx_font_smallcaps" id="S4.SS1.p2.2.5">Garage Wall</span>), for which we performed a standard radiance-field multi-view capture, by taking between <math alttext="90" class="ltx_Math" display="inline" id="S4.SS1.p2.1.m1.1"><semantics id="S4.SS1.p2.1.m1.1a"><mn id="S4.SS1.p2.1.m1.1.1" xref="S4.SS1.p2.1.m1.1.1.cmml">90</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.1.m1.1b"><cn id="S4.SS1.p2.1.m1.1.1.cmml" type="integer" xref="S4.SS1.p2.1.m1.1.1">90</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.1.m1.1c">90</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.1.m1.1d">90</annotation></semantics></math>–<math alttext="150" class="ltx_Math" display="inline" id="S4.SS1.p2.2.m2.1"><semantics id="S4.SS1.p2.2.m2.1a"><mn id="S4.SS1.p2.2.m2.1.1" xref="S4.SS1.p2.2.m2.1.1.cmml">150</mn><annotation-xml encoding="MathML-Content" id="S4.SS1.p2.2.m2.1b"><cn id="S4.SS1.p2.2.m2.1.1.cmml" type="integer" xref="S4.SS1.p2.2.m2.1.1">150</cn></annotation-xml><annotation encoding="application/x-tex" id="S4.SS1.p2.2.m2.1c">150</annotation><annotation encoding="application/x-llamapun" id="S4.SS1.p2.2.m2.1d">150</annotation></semantics></math> images of the environment, in an approximate sphere (or hemisphere) around the scene center of interest.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>3D Relighting Results</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">We begin by showing qualitative results on the set of real scenes that we captured. Here, we used a resolution of <math alttext="1536\times 1024" class="ltx_Math" display="inline" id="S4.SS2.p1.1.m1.1"><semantics id="S4.SS2.p1.1.m1.1a"><mrow id="S4.SS2.p1.1.m1.1.1" xref="S4.SS2.p1.1.m1.1.1.cmml"><mn id="S4.SS2.p1.1.m1.1.1.2" xref="S4.SS2.p1.1.m1.1.1.2.cmml">1536</mn><mo id="S4.SS2.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS2.p1.1.m1.1.1.1.cmml">×</mo><mn id="S4.SS2.p1.1.m1.1.1.3" xref="S4.SS2.p1.1.m1.1.1.3.cmml">1024</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS2.p1.1.m1.1b"><apply id="S4.SS2.p1.1.m1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1"><times id="S4.SS2.p1.1.m1.1.1.1.cmml" xref="S4.SS2.p1.1.m1.1.1.1"></times><cn id="S4.SS2.p1.1.m1.1.1.2.cmml" type="integer" xref="S4.SS2.p1.1.m1.1.1.2">1536</cn><cn id="S4.SS2.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.SS2.p1.1.m1.1.1.3">1024</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS2.p1.1.m1.1c">1536\times 1024</annotation><annotation encoding="application/x-llamapun" id="S4.SS2.p1.1.m1.1d">1536 × 1024</annotation></semantics></math>, training for 150K iterations. We show qualitative results for these scenes using our 3D relightable radiance field in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S3.F8" title="Figure 8 ‣ 3.3 Training a Lighting-Consistent Radiance Field ‣ 3 Method ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">8</span></a>. In addition, we also show results for two scenes from the MipNeRF360 dataset, namely <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.p1.1.1">Counter</span> and <span class="ltx_text ltx_font_smallcaps" id="S4.SS2.p1.1.2">Room</span>.</p>
</div>
<div class="ltx_para" id="S4.SS2.p2">
<p class="ltx_p" id="S4.SS2.p2.1">As our method is lightweight and only adds a small MLP over the core 3DGS architecture, it runs interactively for both novel view synthesis and relighting at 30fps on an A6000 GPU. Memory usage is comparable to the original 3DGS. Please see the video for interactive relighting results on these scenes and additional synthetic scenes. We see that our method produces realistic and plausible relighting results. Also, note that our solution is temporally consistent.</p>
</div>
<figure class="ltx_figure" id="S4.F9"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="263" id="S4.F9.g1" src="x5.png" width="830"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Qualitative comparison on real scene <span class="ltx_text ltx_font_smallcaps" id="S4.F9.2.1">Kettle</span>. From left to right, from the same viewpoint: input lighting condition (view reconstructed using 3D Gaussian Splatting), target lighting, our relighting, Philip et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx43" title="">PMGD21</a>]</cite> relighting. Top and bottom rows are two different lighting conditions. Philip et al. <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx43" title="">PMGD21</a>]</cite> exhibits much more geometry and shading artifacts compared to our method; in particular imprecise MVS preprocessing results in missing geometry.</figcaption>
</figure>
</section>
<section class="ltx_subsection" id="S4.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Evaluation</h3>
<figure class="ltx_figure" id="S4.F10">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S4.F10.24">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.F10.24.25.1">
<td class="ltx_td ltx_nopad_l ltx_nopad_r" id="S4.F10.24.25.1.1" style="padding-left:0.2pt;padding-right:0.2pt;"></td>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.F10.24.25.1.2" style="padding-left:0.2pt;padding-right:0.2pt;"><span class="ltx_text" id="S4.F10.24.25.1.2.1" style="font-size:80%;">GT</span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.F10.24.25.1.3" style="padding-left:0.2pt;padding-right:0.2pt;"><span class="ltx_text" id="S4.F10.24.25.1.3.1" style="font-size:80%;">Ours</span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.F10.24.25.1.4" style="padding-left:0.2pt;padding-right:0.2pt;"><span class="ltx_text" id="S4.F10.24.25.1.4.1" style="font-size:80%;">Outcast</span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.F10.24.25.1.5" style="padding-left:0.2pt;padding-right:0.2pt;"><span class="ltx_text" id="S4.F10.24.25.1.5.1" style="font-size:80%;">R3DG</span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.F10.24.25.1.6" style="padding-left:0.2pt;padding-right:0.2pt;"><span class="ltx_text" id="S4.F10.24.25.1.6.1" style="font-size:80%;">TensoIR</span></th>
</tr>
<tr class="ltx_tr" id="S4.F10.6.6">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S4.F10.1.1.1" style="padding-left:0.2pt;padding-right:0.2pt;"><span class="ltx_text" id="S4.F10.1.1.1.1" style="font-size:80%;position:relative; bottom:123.5pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="24" id="S4.F10.1.1.1.1.g1" src="extracted/5860470/figures/gray_balls/left.png" width="24"/></span></th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F10.2.2.2" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="172" id="S4.F10.2.2.2.g1" src="extracted/5860470/figures/synth_comp_inlayed/gts/bedroom/relit_for_eval_dir_23_0050.jpg" width="108"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F10.3.3.3" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="172" id="S4.F10.3.3.3.g1" src="extracted/5860470/figures/synth_comp_inlayed/ours/bedroom/00050_dir_23.jpg" width="108"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F10.4.4.4" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="172" id="S4.F10.4.4.4.g1" src="extracted/5860470/figures/synth_comp_inlayed/outcast/bedroom/dir_23.jpg" width="108"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F10.5.5.5" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="172" id="S4.F10.5.5.5.g1" src="extracted/5860470/figures/synth_comp_inlayed/r3dg/bedroom/color_0050_dir_23.jpg" width="108"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F10.6.6.6" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="172" id="S4.F10.6.6.6.g1" src="extracted/5860470/figures/synth_comp_inlayed/tensoir/bedroom/050_dir_23_0000.jpg" width="108"/></td>
</tr>
<tr class="ltx_tr" id="S4.F10.12.12">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S4.F10.7.7.1" style="padding-left:0.2pt;padding-right:0.2pt;"><span class="ltx_text" id="S4.F10.7.7.1.1" style="font-size:80%;position:relative; bottom:123.5pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="24" id="S4.F10.7.7.1.1.g1" src="extracted/5860470/figures/gray_balls/right.png" width="24"/></span></th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F10.8.8.2" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="172" id="S4.F10.8.8.2.g1" src="extracted/5860470/figures/synth_comp_inlayed/gts/kitchen/relit_for_eval_dir_18_0050.jpg" width="108"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F10.9.9.3" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="172" id="S4.F10.9.9.3.g1" src="extracted/5860470/figures/synth_comp_inlayed/ours/kitchen/00050_dir_18.jpg" width="108"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F10.10.10.4" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="172" id="S4.F10.10.10.4.g1" src="extracted/5860470/figures/synth_comp_inlayed/outcast/kitchen/dir_18.jpg" width="108"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F10.11.11.5" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="172" id="S4.F10.11.11.5.g1" src="extracted/5860470/figures/synth_comp_inlayed/r3dg/kitchen/color_0050_dir_18.jpg" width="108"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F10.12.12.6" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="172" id="S4.F10.12.12.6.g1" src="extracted/5860470/figures/synth_comp_inlayed/tensoir/kitchen/050_dir_18_0000.jpg" width="108"/></td>
</tr>
<tr class="ltx_tr" id="S4.F10.18.18">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S4.F10.13.13.1" style="padding-left:0.2pt;padding-right:0.2pt;"><span class="ltx_text" id="S4.F10.13.13.1.1" style="font-size:80%;position:relative; bottom:123.5pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="24" id="S4.F10.13.13.1.1.g1" src="extracted/5860470/figures/gray_balls/center.png" width="24"/></span></th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F10.14.14.2" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="172" id="S4.F10.14.14.2.g1" src="extracted/5860470/figures/synth_comp_inlayed/gts/office/relit_for_eval_dir_10_0050.jpg" width="108"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F10.15.15.3" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="172" id="S4.F10.15.15.3.g1" src="extracted/5860470/figures/synth_comp_inlayed/ours/office/00050_dir_10.jpg" width="108"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F10.16.16.4" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="172" id="S4.F10.16.16.4.g1" src="extracted/5860470/figures/synth_comp_inlayed/outcast/office/dir_10.jpg" width="108"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F10.17.17.5" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="172" id="S4.F10.17.17.5.g1" src="extracted/5860470/figures/synth_comp_inlayed/r3dg/office/color_0050_dir_10.jpg" width="108"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F10.18.18.6" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="172" id="S4.F10.18.18.6.g1" src="extracted/5860470/figures/synth_comp_inlayed/tensoir/office/050_dir_10_0000.jpg" width="108"/></td>
</tr>
<tr class="ltx_tr" id="S4.F10.24.24">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S4.F10.19.19.1" style="padding-left:0.2pt;padding-right:0.2pt;"><span class="ltx_text" id="S4.F10.19.19.1.1" style="font-size:80%;position:relative; bottom:123.5pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="24" id="S4.F10.19.19.1.1.g1" src="extracted/5860470/figures/gray_balls/top.png" width="24"/></span></th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F10.20.20.2" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="172" id="S4.F10.20.20.2.g1" src="extracted/5860470/figures/synth_comp_inlayed/gts/livingroom/relit_for_eval_dir_14_0050.jpg" width="108"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F10.21.21.3" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="172" id="S4.F10.21.21.3.g1" src="extracted/5860470/figures/synth_comp_inlayed/ours/livingroom/00050_dir_14.jpg" width="108"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F10.22.22.4" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="172" id="S4.F10.22.22.4.g1" src="extracted/5860470/figures/synth_comp_inlayed/outcast/livingroom/dir_14.jpg" width="108"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F10.23.23.5" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="172" id="S4.F10.23.23.5.g1" src="extracted/5860470/figures/synth_comp_inlayed/r3dg/livingroom/color_0050_dir_14.jpg" width="108"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.F10.24.24.6" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_portrait" height="172" id="S4.F10.24.24.6.g1" src="extracted/5860470/figures/synth_comp_inlayed/tensoir/livingroom/050_dir_14_0000.jpg" width="108"/></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>

We show comparative results of our method of synthetic scenes where the (approximate) ground truth is available (left), and compare to previous methods. Our approach is closer to the ground truth lighting, capturing the overall appearance in a realistic manner.
</figcaption>
</figure>
<figure class="ltx_table" id="S4.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="S4.T1.14">
<thead class="ltx_thead">
<tr class="ltx_tr" id="S4.T1.1.1">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt" id="S4.T1.1.1.1" style="padding-left:1.5pt;padding-right:1.5pt;">Method <math alttext="\rightarrow" class="ltx_Math" display="inline" id="S4.T1.1.1.1.m1.1"><semantics id="S4.T1.1.1.1.m1.1a"><mo id="S4.T1.1.1.1.m1.1.1" stretchy="false" xref="S4.T1.1.1.1.m1.1.1.cmml">→</mo><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1">→</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">\rightarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.1.1.1.m1.1d">→</annotation></semantics></math>
</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T1.1.1.2" style="padding-left:1.5pt;padding-right:1.5pt;">Ours</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T1.1.1.3" style="padding-left:1.5pt;padding-right:1.5pt;">Outcast <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx15" title="">GRP22</a>]</cite>
</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T1.1.1.4" style="padding-left:1.5pt;padding-right:1.5pt;">R3DGS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx14" title="">GGL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite>
</th>
<th class="ltx_td ltx_nopad_l ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="3" id="S4.T1.1.1.5" style="padding-left:1.5pt;padding-right:1.5pt;">TensoIR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx18" title="">JLX<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite>
</th>
</tr>
<tr class="ltx_tr" id="S4.T1.14.14">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_th_row" id="S4.T1.2.2.1" style="padding-left:1.5pt;padding-right:1.5pt;">Scene <math alttext="\downarrow" class="ltx_Math" display="inline" id="S4.T1.2.2.1.m1.1"><semantics id="S4.T1.2.2.1.m1.1a"><mo id="S4.T1.2.2.1.m1.1.1" stretchy="false" xref="S4.T1.2.2.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.1.m1.1b"><ci id="S4.T1.2.2.1.m1.1.1.cmml" xref="S4.T1.2.2.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.1.m1.1c">\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.2.2.1.m1.1d">↓</annotation></semantics></math> / Metrics</th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.T1.3.3.2" style="padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.3.3.2.1" style="font-size:80%;">PSNR<sub class="ltx_sub" id="S4.T1.3.3.2.1.1">↑</sub></span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.T1.4.4.3" style="padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.4.4.3.1" style="font-size:80%;">LPIPS<sub class="ltx_sub" id="S4.T1.4.4.3.1.1">↓</sub></span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.T1.5.5.4" style="padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.5.5.4.1" style="font-size:80%;">SSIM<sub class="ltx_sub" id="S4.T1.5.5.4.1.1">↑</sub></span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.T1.6.6.5" style="padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.6.6.5.1" style="font-size:80%;">PSNR<sub class="ltx_sub" id="S4.T1.6.6.5.1.1">↑</sub></span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.T1.7.7.6" style="padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.7.7.6.1" style="font-size:80%;">LPIPS<sub class="ltx_sub" id="S4.T1.7.7.6.1.1">↓</sub></span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.T1.8.8.7" style="padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.8.8.7.1" style="font-size:80%;">SSIM<sub class="ltx_sub" id="S4.T1.8.8.7.1.1">↑</sub></span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.T1.9.9.8" style="padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.9.9.8.1" style="font-size:80%;">PSNR<sub class="ltx_sub" id="S4.T1.9.9.8.1.1">↑</sub></span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.T1.10.10.9" style="padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.10.10.9.1" style="font-size:80%;">LPIPS<sub class="ltx_sub" id="S4.T1.10.10.9.1.1">↓</sub></span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.T1.11.11.10" style="padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.11.11.10.1" style="font-size:80%;">SSIM<sub class="ltx_sub" id="S4.T1.11.11.10.1.1">↑</sub></span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.T1.12.12.11" style="padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.12.12.11.1" style="font-size:80%;">PSNR<sub class="ltx_sub" id="S4.T1.12.12.11.1.1">↑</sub></span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.T1.13.13.12" style="padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.13.13.12.1" style="font-size:80%;">LPIPS<sub class="ltx_sub" id="S4.T1.13.13.12.1.1">↓</sub></span></th>
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_column" id="S4.T1.14.14.13" style="padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.14.13.1" style="font-size:80%;">SSIM<sub class="ltx_sub" id="S4.T1.14.14.13.1.1">↑</sub></span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S4.T1.14.15.1">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_t" id="S4.T1.14.15.1.1" style="padding-left:1.5pt;padding-right:1.5pt;">Simple Bedroom</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T1.14.15.1.2" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.15.1.2.1" style="background-color:#FFBFBF;">20.57</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T1.14.15.1.3" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.15.1.3.1" style="background-color:#FFBFBF;">0.156</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T1.14.15.1.4" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.15.1.4.1" style="background-color:#FFBFBF;">0.868</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T1.14.15.1.5" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.15.1.5.1" style="background-color:#FFFFBF;">17.24</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T1.14.15.1.6" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.15.1.6.1" style="background-color:#FFFFBF;">0.207</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T1.14.15.1.7" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.15.1.7.1" style="background-color:#FFFFBF;">0.808</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T1.14.15.1.8" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.15.1.8.1" style="background-color:#FFDFBF;">17.79</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T1.14.15.1.9" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.15.1.9.1" style="background-color:#FFDFBF;">0.174</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T1.14.15.1.10" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.15.1.10.1" style="background-color:#FFDFBF;">0.830</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T1.14.15.1.11" style="padding-left:1.5pt;padding-right:1.5pt;">15.77</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T1.14.15.1.12" style="padding-left:1.5pt;padding-right:1.5pt;">0.471</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_t" id="S4.T1.14.15.1.13" style="padding-left:1.5pt;padding-right:1.5pt;">0.595</td>
</tr>
<tr class="ltx_tr" id="S4.T1.14.16.2">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S4.T1.14.16.2.1" style="padding-left:1.5pt;padding-right:1.5pt;">Simple Kitchen</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.16.2.2" style="padding-left:1.5pt;padding-right:1.5pt;">17.45</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.16.2.3" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.16.2.3.1" style="background-color:#FFBFBF;">0.154</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.16.2.4" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.16.2.4.1" style="background-color:#FFBFBF;">0.855</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.16.2.5" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.16.2.5.1" style="background-color:#FFFFBF;">17.91</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.16.2.6" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.16.2.6.1" style="background-color:#FFFFBF;">0.205</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.16.2.7" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.16.2.7.1" style="background-color:#FFDFBF;">0.822</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.16.2.8" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.16.2.8.1" style="background-color:#FFDFBF;">18.55</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.16.2.9" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.16.2.9.1" style="background-color:#FFDFBF;">0.197</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.16.2.10" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.16.2.10.1" style="background-color:#FFFFBF;">0.807</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.16.2.11" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.16.2.11.1" style="background-color:#FFBFBF;">20.52</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.16.2.12" style="padding-left:1.5pt;padding-right:1.5pt;">0.382</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.16.2.13" style="padding-left:1.5pt;padding-right:1.5pt;">0.701</td>
</tr>
<tr class="ltx_tr" id="S4.T1.14.17.3">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S4.T1.14.17.3.1" style="padding-left:1.5pt;padding-right:1.5pt;">Simple Livingroom</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.17.3.2" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.17.3.2.1" style="background-color:#FFBFBF;">22.12</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.17.3.3" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.17.3.3.1" style="background-color:#FFDFBF;">0.136</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.17.3.4" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.17.3.4.1" style="background-color:#FFBFBF;">0.884</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.17.3.5" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.17.3.5.1" style="background-color:#FFDFBF;">21.09</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.17.3.6" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.17.3.6.1" style="background-color:#FFBFBF;">0.125</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.17.3.7" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.17.3.7.1" style="background-color:#FFDFBF;">0.878</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.17.3.8" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.17.3.8.1" style="background-color:#FFFFBF;">20.34</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.17.3.9" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.17.3.9.1" style="background-color:#FFFFBF;">0.166</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.17.3.10" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.17.3.10.1" style="background-color:#FFFFBF;">0.857</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.17.3.11" style="padding-left:1.5pt;padding-right:1.5pt;">17.45</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.17.3.12" style="padding-left:1.5pt;padding-right:1.5pt;">0.444</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.17.3.13" style="padding-left:1.5pt;padding-right:1.5pt;">0.598</td>
</tr>
<tr class="ltx_tr" id="S4.T1.14.18.4">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S4.T1.14.18.4.1" style="padding-left:1.5pt;padding-right:1.5pt;">Simple Office</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.18.4.2" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.18.4.2.1" style="background-color:#FFFFBF;">18.59</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.18.4.3" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.18.4.3.1" style="background-color:#FFBFBF;">0.131</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.18.4.4" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.18.4.4.1" style="background-color:#FFBFBF;">0.868</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.18.4.5" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.18.4.5.1" style="background-color:#FFDFBF;">18.97</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.18.4.6" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.18.4.6.1" style="background-color:#FFFFBF;">0.196</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.18.4.7" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.18.4.7.1" style="background-color:#FFDFBF;">0.811</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.18.4.8" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.18.4.8.1" style="background-color:#FFBFBF;">20.40</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.18.4.9" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.18.4.9.1" style="background-color:#FFDFBF;">0.173</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.18.4.10" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.18.4.10.1" style="background-color:#FFFFBF;">0.808</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.18.4.11" style="padding-left:1.5pt;padding-right:1.5pt;">18.22</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.18.4.12" style="padding-left:1.5pt;padding-right:1.5pt;">0.446</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.18.4.13" style="padding-left:1.5pt;padding-right:1.5pt;">0.644</td>
</tr>
<tr class="ltx_tr" id="S4.T1.14.19.5">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S4.T1.14.19.5.1" style="padding-left:1.5pt;padding-right:1.5pt;">Complex Bedroom</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.19.5.2" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.19.5.2.1" style="background-color:#FFBFBF;">17.70</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.19.5.3" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.19.5.3.1" style="background-color:#FFBFBF;">0.145</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.19.5.4" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.19.5.4.1" style="background-color:#FFBFBF;">0.791</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.19.5.5" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.19.5.5.1" style="background-color:#FFFFBF;">15.26</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.19.5.6" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.19.5.6.1" style="background-color:#FFFFBF;">0.221</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.19.5.7" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.19.5.7.1" style="background-color:#FFFFBF;">0.694</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.19.5.8" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.19.5.8.1" style="background-color:#FFDFBF;">16.69</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.19.5.9" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.19.5.9.1" style="background-color:#FFDFBF;">0.186</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.19.5.10" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.19.5.10.1" style="background-color:#FFDFBF;">0.741</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.19.5.11" style="padding-left:1.5pt;padding-right:1.5pt;">14.42</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.19.5.12" style="padding-left:1.5pt;padding-right:1.5pt;">0.434</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.19.5.13" style="padding-left:1.5pt;padding-right:1.5pt;">0.555</td>
</tr>
<tr class="ltx_tr" id="S4.T1.14.20.6">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S4.T1.14.20.6.1" style="padding-left:1.5pt;padding-right:1.5pt;">Complex Kitchen</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.20.6.2" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.20.6.2.1" style="background-color:#FFDFBF;">19.28</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.20.6.3" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.20.6.3.1" style="background-color:#FFBFBF;">0.152</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.20.6.4" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.20.6.4.1" style="background-color:#FFBFBF;">0.811</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.20.6.5" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.20.6.5.1" style="background-color:#FFFFBF;">18.44</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.20.6.6" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.20.6.6.1" style="background-color:#FFFFBF;">0.178</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.20.6.7" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.20.6.7.1" style="background-color:#FFDFBF;">0.771</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.20.6.8" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.20.6.8.1" style="background-color:#FFBFBF;">19.28</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.20.6.9" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.20.6.9.1" style="background-color:#FFDFBF;">0.168</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.20.6.10" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.20.6.10.1" style="background-color:#FFFFBF;">0.755</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.20.6.11" style="padding-left:1.5pt;padding-right:1.5pt;">16.70</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.20.6.12" style="padding-left:1.5pt;padding-right:1.5pt;">0.471</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.20.6.13" style="padding-left:1.5pt;padding-right:1.5pt;">0.533</td>
</tr>
<tr class="ltx_tr" id="S4.T1.14.21.7">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row" id="S4.T1.14.21.7.1" style="padding-left:1.5pt;padding-right:1.5pt;">Complex Livingroom</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.21.7.2" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.21.7.2.1" style="background-color:#FFBFBF;">18.61</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.21.7.3" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.21.7.3.1" style="background-color:#FFBFBF;">0.163</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.21.7.4" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.21.7.4.1" style="background-color:#FFBFBF;">0.800</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.21.7.5" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.21.7.5.1" style="background-color:#FFFFBF;">17.94</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.21.7.6" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.21.7.6.1" style="background-color:#FFFFBF;">0.187</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.21.7.7" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.21.7.7.1" style="background-color:#FFDFBF;">0.783</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.21.7.8" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.21.7.8.1" style="background-color:#FFDFBF;">18.39</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.21.7.9" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.21.7.9.1" style="background-color:#FFDFBF;">0.175</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.21.7.10" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.21.7.10.1" style="background-color:#FFFFBF;">0.770</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.21.7.11" style="padding-left:1.5pt;padding-right:1.5pt;">16.82</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.21.7.12" style="padding-left:1.5pt;padding-right:1.5pt;">0.382</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S4.T1.14.21.7.13" style="padding-left:1.5pt;padding-right:1.5pt;">0.602</td>
</tr>
<tr class="ltx_tr" id="S4.T1.14.22.8">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_left ltx_th ltx_th_row ltx_border_bb" id="S4.T1.14.22.8.1" style="padding-left:1.5pt;padding-right:1.5pt;">Complex Office</th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T1.14.22.8.2" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.22.8.2.1" style="background-color:#FFBFBF;">20.20</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T1.14.22.8.3" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.22.8.3.1" style="background-color:#FFBFBF;">0.096</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T1.14.22.8.4" style="background-color:#FFBFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.22.8.4.1" style="background-color:#FFBFBF;">0.858</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T1.14.22.8.5" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.22.8.5.1" style="background-color:#FFFFBF;">17.22</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T1.14.22.8.6" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.22.8.6.1" style="background-color:#FFFFBF;">0.169</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T1.14.22.8.7" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.22.8.7.1" style="background-color:#FFDFBF;">0.781</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T1.14.22.8.8" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.22.8.8.1" style="background-color:#FFDFBF;">18.93</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T1.14.22.8.9" style="background-color:#FFDFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.22.8.9.1" style="background-color:#FFDFBF;">0.144</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T1.14.22.8.10" style="background-color:#FFFFBF;padding-left:1.5pt;padding-right:1.5pt;"><span class="ltx_text" id="S4.T1.14.22.8.10.1" style="background-color:#FFFFBF;">0.776</span></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T1.14.22.8.11" style="padding-left:1.5pt;padding-right:1.5pt;">15.78</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T1.14.22.8.12" style="padding-left:1.5pt;padding-right:1.5pt;">0.468</td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_border_bb" id="S4.T1.14.22.8.13" style="padding-left:1.5pt;padding-right:1.5pt;">0.529</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>

Quantitative results of our 3D relighting on the synthetic datasets (where ground truth is available), compared to previous work, from left to right: OutCast <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx15" title="">GRP22</a>]</cite> (run on individual images from 3DGS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx21" title="">KKLD23</a>]</cite>), Relightable3DGaussians <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx14" title="">GGL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite>, and
TensoIR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx18" title="">JLX<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite>. Arrows indicate higher/lower (<math alttext="\uparrow/\downarrow" class="ltx_Math" display="inline" id="S4.T1.16.m1.3"><semantics id="S4.T1.16.m1.3b"><mrow id="S4.T1.16.m1.3.4.2" xref="S4.T1.16.m1.3.4.1.cmml"><mo id="S4.T1.16.m1.1.1" stretchy="false" xref="S4.T1.16.m1.1.1.cmml">↑</mo><mo id="S4.T1.16.m1.3.4.2.1" lspace="0em" xref="S4.T1.16.m1.3.4.1.cmml">⁣</mo><mo id="S4.T1.16.m1.2.2" xref="S4.T1.16.m1.2.2.cmml">/</mo><mo id="S4.T1.16.m1.3.4.2.2" lspace="0em" xref="S4.T1.16.m1.3.4.1.cmml">⁣</mo><mo id="S4.T1.16.m1.3.3" stretchy="false" xref="S4.T1.16.m1.3.3.cmml">↓</mo></mrow><annotation-xml encoding="MathML-Content" id="S4.T1.16.m1.3c"><list id="S4.T1.16.m1.3.4.1.cmml" xref="S4.T1.16.m1.3.4.2"><ci id="S4.T1.16.m1.1.1.cmml" xref="S4.T1.16.m1.1.1">↑</ci><divide id="S4.T1.16.m1.2.2.cmml" xref="S4.T1.16.m1.2.2"></divide><ci id="S4.T1.16.m1.3.3.cmml" xref="S4.T1.16.m1.3.3">↓</ci></list></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.16.m1.3d">\uparrow/\downarrow</annotation><annotation encoding="application/x-llamapun" id="S4.T1.16.m1.3e">↑ / ↓</annotation></semantics></math>) is better. Results are color coded by <span class="ltx_text" id="S4.T1.20.1" style="background-color:#FFBFBF;">best</span>, <span class="ltx_text" id="S4.T1.21.2" style="background-color:#FFDFBF;">second-</span> and <span class="ltx_text" id="S4.T1.22.3" style="background-color:#FFFFBF;">third-</span>best.</figcaption>
</figure>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Baselines.</h5>
<div class="ltx_para" id="S4.SS3.SSS0.Px1.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px1.p1.2">We compare our results to the method of <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx43" title="">PMGD21</a>]</cite> which is specifically designed for complete scenes, TensoIR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx18" title="">JLX<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite> and RelightableGaussians <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx14" title="">GGL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite>. Given that most other methods do not handle full scenes well, we also create a new baseline, by first training 3DGS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx21" title="">KKLD23</a>]</cite> on the input data and render a test path using novel view synthesis; We then use OutCast <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx15" title="">GRP22</a>]</cite> to relight each individual rendered frame using the target direction.
We trained TensoIR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx18" title="">JLX<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite> using the default configuration but modified the “density_shift” parameter from <math alttext="-10" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px1.p1.1.m1.1"><semantics id="S4.SS3.SSS0.Px1.p1.1.m1.1a"><mrow id="S4.SS3.SSS0.Px1.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.cmml"><mo id="S4.SS3.SSS0.Px1.p1.1.m1.1.1a" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.cmml">−</mo><mn id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.cmml">10</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.1.m1.1b"><apply id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1"><minus id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1"></minus><cn id="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2.cmml" type="integer" xref="S4.SS3.SSS0.Px1.p1.1.m1.1.1.2">10</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.1.m1.1c">-10</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px1.p1.1.m1.1d">- 10</annotation></semantics></math> to <math alttext="-8" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px1.p1.2.m2.1"><semantics id="S4.SS3.SSS0.Px1.p1.2.m2.1a"><mrow id="S4.SS3.SSS0.Px1.p1.2.m2.1.1" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1.cmml"><mo id="S4.SS3.SSS0.Px1.p1.2.m2.1.1a" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1.cmml">−</mo><mn id="S4.SS3.SSS0.Px1.p1.2.m2.1.1.2" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1.2.cmml">8</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px1.p1.2.m2.1b"><apply id="S4.SS3.SSS0.Px1.p1.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1"><minus id="S4.SS3.SSS0.Px1.p1.2.m2.1.1.1.cmml" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1"></minus><cn id="S4.SS3.SSS0.Px1.p1.2.m2.1.1.2.cmml" type="integer" xref="S4.SS3.SSS0.Px1.p1.2.m2.1.1.2">8</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px1.p1.2.m2.1c">-8</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px1.p1.2.m2.1d">- 8</annotation></semantics></math> to achieve best results on our data.
For Relightable 3D Gaussians <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx14" title="">GGL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite>, we train their “Stage 1” for 30K iterations and “Stage 2” for an additional 10K to recover the BRDF parameters. We then relight the scenes using 360° environment maps rendered in Blender using a generic empty room and a similar camera/flash setup for ground truth.
Finally, to improve the baselines we normalize the predictions of all methods; we first subtract the channel-wise mean and divide out the channel-wise standard deviation, and then multiply and add the corresponding parameters of the ground truths. These operations are performed in LAB space for all methods.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px2">
<h5 class="ltx_title ltx_title_paragraph">Experimental methodology.</h5>
<div class="ltx_para" id="S4.SS3.SSS0.Px2.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px2.p1.2">We use our synthetic test scenes for providing quantitative results. To compare our method, we rendered 200 novel views with 18 different lighting directions to evaluate the relighting quality for each method by computing standard image quality metrics. Given the complexity of setup for <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx43" title="">PMGD21</a>]</cite>, we only show qualitative results for 1 real scene in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S4.F9" title="Figure 9 ‣ 4.2 3D Relighting Results ‣ 4 Results and Evaluation ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">9</span></a>. Here, our method was trained at <math alttext="768\times 512" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.1.m1.1"><semantics id="S4.SS3.SSS0.Px2.p1.1.m1.1a"><mrow id="S4.SS3.SSS0.Px2.p1.1.m1.1.1" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.cmml"><mn id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2.cmml">768</mn><mo id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.1" lspace="0.222em" rspace="0.222em" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.1.cmml">×</mo><mn id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.cmml">512</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.1.m1.1b"><apply id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1"><times id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.1"></times><cn id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2.cmml" type="integer" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.2">768</cn><cn id="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3.cmml" type="integer" xref="S4.SS3.SSS0.Px2.p1.1.m1.1.1.3">512</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.1.m1.1c">768\times 512</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px2.p1.1.m1.1d">768 × 512</annotation></semantics></math> resolution for 200k iterations, with a batch size of 8 and a learning rate of <math alttext="10^{-4}" class="ltx_Math" display="inline" id="S4.SS3.SSS0.Px2.p1.2.m2.1"><semantics id="S4.SS3.SSS0.Px2.p1.2.m2.1a"><msup id="S4.SS3.SSS0.Px2.p1.2.m2.1.1" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.cmml"><mn id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.cmml">10</mn><mrow id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.cmml"><mo id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3a" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.cmml">−</mo><mn id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.2" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.2.cmml">4</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.SSS0.Px2.p1.2.m2.1b"><apply id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.1.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1">superscript</csymbol><cn id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2.cmml" type="integer" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.2">10</cn><apply id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3"><minus id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.1.cmml" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3"></minus><cn id="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.2.cmml" type="integer" xref="S4.SS3.SSS0.Px2.p1.2.m2.1.1.3.2">4</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.SSS0.Px2.p1.2.m2.1c">10^{-4}</annotation><annotation encoding="application/x-llamapun" id="S4.SS3.SSS0.Px2.p1.2.m2.1d">10 start_POSTSUPERSCRIPT - 4 end_POSTSUPERSCRIPT</annotation></semantics></math>.</p>
</div>
</section>
<section class="ltx_paragraph" id="S4.SS3.SSS0.Px3">
<h5 class="ltx_title ltx_title_paragraph">Results.</h5>
<div class="ltx_para" id="S4.SS3.SSS0.Px3.p1">
<p class="ltx_p" id="S4.SS3.SSS0.Px3.p1.1">We present quantitative results in Table <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S4.T1" title="Table 1 ‣ 4.3 Evaluation ‣ 4 Results and Evaluation ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">1</span></a>. We present per-scene results on the following image quality metrics: PSNR, SSIM, and LPIPS <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx75" title="">ZIE<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>18</a>]</cite>.
The results demonstrate that our method outperforms all others in all but a few scenarios, where it still achieves competitive performance.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS0.Px3.p2">
<p class="ltx_p" id="S4.SS3.SSS0.Px3.p2.1">Qualitative comparisons are shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S4.F10" title="Figure 10 ‣ 4.3 Evaluation ‣ 4 Results and Evaluation ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">10</span></a>; on the left we show the ground truth relit image rendered in Blender, and we then show our results, as well as those from Outcast <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx15" title="">GRP22</a>]</cite>, Relightable 3D Gaussians <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx14" title="">GGL<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite> and TensoIR <cite class="ltx_cite ltx_citemacro_cite">[<a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#bib.bibx18" title="">JLX<sup class="ltx_sup"><span class="ltx_text ltx_font_italic">∗</span></sup>23</a>]</cite>. Please refer to the supplementary HTML viewer for more results. We clearly see that our method is closer to the ground truth, visually confirming the quantitative results in Tab. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S4.T1" title="Table 1 ‣ 4.3 Evaluation ‣ 4 Results and Evaluation ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">1</span></a>.
TensoIR has difficulty reconstructing the geometry, and Relightable 3D Gaussians tend to have a “splotchy” look due to inaccurate normals. Outcast has difficulty with the overall lighting condition and can add incorrect shadows, but in many cases produces convincing results since it operates in image space. Our results show that by using the diffusion prior we manage to achieve realistic relighting, surpassing the state of the art.</p>
</div>
<div class="ltx_para" id="S4.SS3.SSS0.Px3.p3">
<p class="ltx_p" id="S4.SS3.SSS0.Px3.p3.1">Our method was trained for indoor scenes; Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S5.F12" title="Figure 12 ‣ 5 Conclusion ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">12</span></a> gives additional ControlNet results on out-of-distribution samples, showing that it can generalize to some extent to unseen scenes and lighting conditions, although the realism is lower than for in-distribution samples.</p>
</div>
</section>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">We have presented the first method to effectively leverage the strong prior of large generative diffusion models in the context of radiance field relighting.
Rather than relying on accurate geometry, material and/or lighting estimation, our approach models realistic illumination directly, by leveraging a general-purpose single-view, multi-illumination dataset and fine-tuning a large pretrained generative model.
Our results show that we can synthesize realistic relighting of captured scenes, while allowing interactive novel-view synthesis by building on such priors.
Our method shows levels of realism for relighting that surpass the state of the art for cluttered indoor scenes (as opposed to isolated objects).</p>
</div>
<figure class="ltx_figure" id="S5.F11"><img alt="Refer to caption" class="ltx_graphics ltx_img_landscape" height="399" id="S5.F11.g1" src="extracted/5860470/figures/limitations.jpg" width="598"/>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Example limitations of our approach, with our prediction (top) vs ground truth (bottom). Our ControlNet mistakenly produces a shadow at the top of the image while there should not be any (red arrow), presumably assuming the presence of another top shelf. Additionally, the highlight position is somewhat incorrect (yellow arrow), ostensibly because we define light direction in a manner that is not fully physically accurate.</figcaption>
</figure>
<div class="ltx_para" id="S5.p2">
<p class="ltx_p" id="S5.p2.1">One limitation of the proposed method is that it does not enforce physical accuracy: the target light direction is noisy and the ControlNet relies mostly on its powerful Stable Diffusion prior to relight rather than performing physics-based reasoning. For example, Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S5.F11" title="Figure 11 ‣ 5 Conclusion ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">11</span></a> shows that ControlNet can hallucinate shadows due to unseen geometry, while there should not be any. Given that we define light direction in a manner that is not fully physically accurate, the positioning of highlight can be inaccurate, as is also shown in Fig. <a class="ltx_ref" href="https://arxiv.org/html/2409.08947v2#S5.F11" title="Figure 11 ‣ 5 Conclusion ‣ A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis"><span class="ltx_text ltx_ref_tag">11</span></a>. In addition, the appearance embeddings can correct for global inconsistencies indirectly and do not explicitly rely on the learned 3D representation of the radiance field.
Our method does not always remove or move shadows in a fully accurate physically-based manner.
While our method clearly demonstrates that 2D diffusion model priors can be used for realistic relighting, the ability to perform more complex relighting—rather than just changing light direction—requires significant future research, e.g., by using more general training data as well as ways to encode and decode complex lighting.</p>
</div>
<div class="ltx_para" id="S5.p3">
<p class="ltx_p" id="S5.p3.1">An interesting direction for future work would be trying to enforce multi-view consistency more explicitly in ControlNet, e.g. by leveraging single-illumination multi-view data. Another interesting direction is to develop solutions that would guide the predicted relighting making it more accurate, leveraging the 3D geometric information available in the radiance field more explicitly.</p>
</div>
<figure class="ltx_figure" id="S5.F12">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle" id="S5.F12.20">
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="S5.F12.5.5">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S5.F12.1.1.1" style="padding-left:0.2pt;padding-right:0.2pt;"><span class="ltx_text" id="S5.F12.1.1.1.1" style="font-size:80%;position:relative; bottom:98.4pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="24" id="S5.F12.1.1.1.1.g1" src="extracted/5860470/figures/gray_balls/left.png" width="24"/></span></th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F12.2.2.2" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="141" id="S5.F12.2.2.2.g1" src="extracted/5860470/figures/ood_samples/woman_dir_23.jpg" width="141"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F12.3.3.3" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="141" id="S5.F12.3.3.3.g1" src="extracted/5860470/figures/ood_samples/bicycle_dir_23.jpg" width="141"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F12.4.4.4" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="141" id="S5.F12.4.4.4.g1" src="extracted/5860470/figures/ood_samples/garden_dir_23.jpg" width="141"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F12.5.5.5" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="141" id="S5.F12.5.5.5.g1" src="extracted/5860470/figures/ood_samples/stump_dir_23.jpg" width="141"/></td>
</tr>
<tr class="ltx_tr" id="S5.F12.10.10">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S5.F12.6.6.1" style="padding-left:0.2pt;padding-right:0.2pt;"><span class="ltx_text" id="S5.F12.6.6.1.1" style="font-size:80%;position:relative; bottom:98.4pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="24" id="S5.F12.6.6.1.1.g1" src="extracted/5860470/figures/gray_balls/right.png" width="24"/></span></th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F12.7.7.2" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="141" id="S5.F12.7.7.2.g1" src="extracted/5860470/figures/ood_samples/woman_dir_18.jpg" width="141"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F12.8.8.3" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="141" id="S5.F12.8.8.3.g1" src="extracted/5860470/figures/ood_samples/bicycle_dir_18.jpg" width="141"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F12.9.9.4" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="141" id="S5.F12.9.9.4.g1" src="extracted/5860470/figures/ood_samples/garden_dir_18.jpg" width="141"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F12.10.10.5" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="141" id="S5.F12.10.10.5.g1" src="extracted/5860470/figures/ood_samples/stump_dir_18.jpg" width="141"/></td>
</tr>
<tr class="ltx_tr" id="S5.F12.15.15">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S5.F12.11.11.1" style="padding-left:0.2pt;padding-right:0.2pt;"><span class="ltx_text" id="S5.F12.11.11.1.1" style="font-size:80%;position:relative; bottom:98.4pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="24" id="S5.F12.11.11.1.1.g1" src="extracted/5860470/figures/gray_balls/top.png" width="24"/></span></th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F12.12.12.2" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="141" id="S5.F12.12.12.2.g1" src="extracted/5860470/figures/ood_samples/woman_dir_14.jpg" width="141"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F12.13.13.3" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="141" id="S5.F12.13.13.3.g1" src="extracted/5860470/figures/ood_samples/bicycle_dir_14.jpg" width="141"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F12.14.14.4" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="141" id="S5.F12.14.14.4.g1" src="extracted/5860470/figures/ood_samples/garden_dir_14.jpg" width="141"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F12.15.15.5" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="141" id="S5.F12.15.15.5.g1" src="extracted/5860470/figures/ood_samples/stump_dir_14.jpg" width="141"/></td>
</tr>
<tr class="ltx_tr" id="S5.F12.20.20">
<th class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center ltx_th ltx_th_row" id="S5.F12.16.16.1" style="padding-left:0.2pt;padding-right:0.2pt;"><span class="ltx_text" id="S5.F12.16.16.1.1" style="font-size:80%;position:relative; bottom:98.4pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="24" id="S5.F12.16.16.1.1.g1" src="extracted/5860470/figures/gray_balls/center.png" width="24"/></span></th>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F12.17.17.2" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="141" id="S5.F12.17.17.2.g1" src="extracted/5860470/figures/ood_samples/woman_dir_10.jpg" width="141"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F12.18.18.3" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="141" id="S5.F12.18.18.3.g1" src="extracted/5860470/figures/ood_samples/bicycle_dir_10.jpg" width="141"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F12.19.19.4" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="141" id="S5.F12.19.19.4.g1" src="extracted/5860470/figures/ood_samples/garden_dir_10.jpg" width="141"/></td>
<td class="ltx_td ltx_nopad_l ltx_nopad_r ltx_align_center" id="S5.F12.20.20.5" style="padding-left:0.2pt;padding-right:0.2pt;"><img alt="Refer to caption" class="ltx_graphics ltx_img_square" height="141" id="S5.F12.20.20.5.g1" src="extracted/5860470/figures/ood_samples/stump_dir_10.jpg" width="141"/></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:80%;"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>

We show the results of our 2D relighting network on out-of-distribution images (StyleGAN-generated woman and MipNeRF360 <span class="ltx_text ltx_font_smallcaps" id="S5.F12.29.1">bicycle</span>, <span class="ltx_text ltx_font_smallcaps" id="S5.F12.30.2">garden</span>, and <span class="ltx_text ltx_font_smallcaps" id="S5.F12.31.3">stump</span>). On human faces, ControlNet may change the expression as well as the lighting, or create excessive shininess; on outdoor scenes, while the overall lighting direction is plausible, the network fails to generate sufficiently hard shadows.
</figcaption>
</figure>
<section class="ltx_paragraph" id="S5.SS0.SSS0.Px1">
<h5 class="ltx_title ltx_title_paragraph">Acknowledgements</h5>
<div class="ltx_para" id="S5.SS0.SSS0.Px1.p1">
<p class="ltx_p" id="S5.SS0.SSS0.Px1.p1.1">This research was funded by the ERC Advanced grant FUNGRAPH No 788065 <a class="ltx_ref ltx_url ltx_font_typewriter" href="http://fungraph.inria.fr/" title="">http://fungraph.inria.fr/</a>, supported by NSERC grant DGPIN 2020-04799 and the Digital Research Alliance Canada. The authors are grateful to Adobe and NVIDIA for generous donations, and the OPAL infrastructure from Université Côte d’Azur. Thanks to Georgios Kopanas and Frédéric Fortier-Chouinard for helpful advice.</p>
</div>
</section>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bibx1">
<span class="ltx_tag ltx_tag_bibitem">[BBJ<sup class="ltx_sup" id="bib.bibx1.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx1.4.4.1.1">∗</span></sup>21]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx1.7.1">Boss M., Braun R., Jampani V., Barron J. T., Liu C., Lensch H.</span>:

</span>
<span class="ltx_bibblock">Nerd: Neural reflectance decomposition from image collections.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx1.8.1">IEEE/CVF Int. Conf. Comput. Vis.</em> (2021).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx2">
<span class="ltx_tag ltx_tag_bibitem">[BEK<sup class="ltx_sup" id="bib.bibx2.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx2.4.4.1.1">∗</span></sup>22]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx2.7.1">Boss M., Engelhardt A., Kar A., Li Y., Sun D., Barron J. T., Lensch H. P., Jampani V.</span>:

</span>
<span class="ltx_bibblock">SAMURAI: Shape and material from unconstrained real-world arbitrary image collections.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx2.8.1">Adv. Neural Inform. Process. Syst.</em> (2022).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx3">
<span class="ltx_tag ltx_tag_bibitem">[BF24]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx3.1.1">Bhattad A., Forsyth D. A.</span>:

</span>
<span class="ltx_bibblock">Stylitgan: Prompting stylegan to produce new illumination conditions.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx3.2.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (2024).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx4">
<span class="ltx_tag ltx_tag_bibitem">[BJB<sup class="ltx_sup" id="bib.bibx4.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx4.4.4.1.1">∗</span></sup>21]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx4.7.1">Boss M., Jampani V., Braun R., Liu C., Barron J., Lensch H.</span>:

</span>
<span class="ltx_bibblock">Neural-pil: Neural pre-integrated lighting for reflectance decomposition.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx4.8.1">Adv. Neural Inform. Process. Syst.</em> (2021).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx5">
<span class="ltx_tag ltx_tag_bibitem">[BMHF23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx5.1.1">Bhattad A., McKee D., Hoiem D., Forsyth D.</span>:

</span>
<span class="ltx_bibblock">Stylegan knows normal, depth, albedo, and more.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx6">
<span class="ltx_tag ltx_tag_bibitem">[BMT<sup class="ltx_sup" id="bib.bibx6.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx6.4.4.1.1">∗</span></sup>21]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx6.7.1">Barron J. T., Mildenhall B., Tancik M., Hedman P., Martin-Brualla R., Srinivasan P. P.</span>:

</span>
<span class="ltx_bibblock">Mip-nerf: A multiscale representation for anti-aliasing neural radiance fields.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx6.8.1">IEEE/CVF Int. Conf. Comput. Vis.</em> (2021).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx7">
<span class="ltx_tag ltx_tag_bibitem">[BMV<sup class="ltx_sup" id="bib.bibx7.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx7.4.4.1.1">∗</span></sup>22]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx7.7.1">Barron J. T., Mildenhall B., Verbin D., Srinivasan P. P., Hedman P.</span>:

</span>
<span class="ltx_bibblock">Mip-nerf 360: Unbounded anti-aliased neural radiance fields.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx7.8.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (2022).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx8">
<span class="ltx_tag ltx_tag_bibitem">[CKK23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx8.1.1">Choi C., Kim J., Kim Y. M.</span>:

</span>
<span class="ltx_bibblock">IBL-NeRF: Image-based lighting formulation of neural radiance fields.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx8.2.1">Comput. Graph. Forum 42</em>, 7 (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx9">
<span class="ltx_tag ltx_tag_bibitem">[CXG<sup class="ltx_sup" id="bib.bibx9.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx9.4.4.1.1">∗</span></sup>22]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx9.7.1">Chen A., Xu Z., Geiger A., Yu J., Su H.</span>:

</span>
<span class="ltx_bibblock">Tensorf: Tensorial radiance fields.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx9.8.1">Eur. Conf. Comput. Vis.</em> (2022).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx10">
<span class="ltx_tag ltx_tag_bibitem">[DHT<sup class="ltx_sup" id="bib.bibx10.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx10.4.4.1.1">∗</span></sup>00]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx10.7.1">Debevec P., Hawkins T., Tchou C., Duiker H.-P., Sarokin W., Sagar M.</span>:

</span>
<span class="ltx_bibblock">Acquiring the reflectance field of a human face.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx10.8.1">Proceedings of the 27th annual conference on Computer graphics and interactive techniques</em> (2000), pp. 145–156.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx11">
<span class="ltx_tag ltx_tag_bibitem">[FRV<sup class="ltx_sup" id="bib.bibx11.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx11.4.4.1.1">∗</span></sup>23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx11.7.1">Futschik D., Ritland K., Vecore J., Fanello S., Orts-Escolano S., Curless B., Sỳkora D., Pandey R.</span>:

</span>
<span class="ltx_bibblock">Controllable light diffusion for portraits.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx11.8.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx12">
<span class="ltx_tag ltx_tag_bibitem">[GAA<sup class="ltx_sup" id="bib.bibx12.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx12.4.4.1.1">∗</span></sup>23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx12.7.1">Gal R., Arar M., Atzmon Y., Bermano A. H., Chechik G., Cohen-Or D.</span>:

</span>
<span class="ltx_bibblock">Encoder-based domain tuning for fast personalization of text-to-image models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx12.8.1">ACM Trans. Graph. 42</em>, 4 (2023), 1–13.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx13">
<span class="ltx_tag ltx_tag_bibitem">[GCD<sup class="ltx_sup" id="bib.bibx13.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx13.4.4.1.1">∗</span></sup>20]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx13.7.1">Gao D., Chen G., Dong Y., Peers P., Xu K., Tong X.</span>:

</span>
<span class="ltx_bibblock">Deferred neural lighting: free-viewpoint relighting from unstructured photographs.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx13.8.1">ACM Trans. Graph. 39</em>, 6 (nov 2020).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx14">
<span class="ltx_tag ltx_tag_bibitem">[GGL<sup class="ltx_sup" id="bib.bibx14.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx14.4.4.1.1">∗</span></sup>23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx14.7.1">Gao J., Gu C., Lin Y., Zhu H., Cao X., Zhang L., Yao Y.</span>:

</span>
<span class="ltx_bibblock">Relightable 3d gaussian: Real-time point cloud relighting with brdf decomposition and ray tracing.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx14.8.1">arXiv:2311.16043</em> (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx15">
<span class="ltx_tag ltx_tag_bibitem">[GRP22]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx15.1.1">Griffiths D., Ritschel T., Philip J.</span>:

</span>
<span class="ltx_bibblock">Outcast: Outdoor single-image relighting with cast shadows.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx15.2.1">Comput. Graph. Forum</em> (2022), vol. 41, pp. 179–193.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx16">
<span class="ltx_tag ltx_tag_bibitem">[HHM22]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx16.1.1">Hasselgren J., Hofmann N., Munkberg J.</span>:

</span>
<span class="ltx_bibblock">Shape, light, and material decomposition from images using monte carlo rendering and denoising.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx16.2.1">Adv. Neural Inform. Process. Syst. 35</em> (2022), 22856–22869.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx17">
<span class="ltx_tag ltx_tag_bibitem">[HJA20]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx17.1.1">Ho J., Jain A., Abbeel P.</span>:

</span>
<span class="ltx_bibblock">Denoising diffusion probabilistic models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx17.2.1">Adv. Neural Inform. Process. Syst.</em> (2020).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx18">
<span class="ltx_tag ltx_tag_bibitem">[JLX<sup class="ltx_sup" id="bib.bibx18.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx18.4.4.1.1">∗</span></sup>23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx18.7.1">Jin H., Liu I., Xu P., Zhang X., Han S., Bi S., Zhou X., Xu Z., Su H.</span>:

</span>
<span class="ltx_bibblock">Tensoir: Tensorial inverse rendering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx18.8.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx19">
<span class="ltx_tag ltx_tag_bibitem">[JTL<sup class="ltx_sup" id="bib.bibx19.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx19.4.4.1.1">∗</span></sup>24]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx19.7.1">Jiang Y., Tu J., Liu Y., Gao X., Long X., Wang W., Ma Y.</span>:

</span>
<span class="ltx_bibblock">Gaussianshader: 3d gaussian splatting with shading functions for reflective surfaces, 2024.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx20">
<span class="ltx_tag ltx_tag_bibitem">[KE19]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx20.1.1">Kanamori Y., Endo Y.</span>:

</span>
<span class="ltx_bibblock">Relighting humans: occlusion-aware inverse rendering for full-body human images.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx20.2.1">ACM Trans. Graph. 37</em>, 6 (2019).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx21">
<span class="ltx_tag ltx_tag_bibitem">[KKLD23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx21.1.1">Kerbl B., Kopanas G., Leimkühler T., Drettakis G.</span>:

</span>
<span class="ltx_bibblock">3d gaussian splatting for real-time radiance field rendering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx21.2.1">ACM Trans. Graph. 42</em>, 4 (July 2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx22">
<span class="ltx_tag ltx_tag_bibitem">[KOH<sup class="ltx_sup" id="bib.bibx22.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx22.4.4.1.1">∗</span></sup>24]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx22.7.1">Ke B., Obukhov A., Huang S., Metzger N., Daudt R. C., Schindler K.</span>:

</span>
<span class="ltx_bibblock">Repurposing diffusion-based image generators for monocular depth estimation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx22.8.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (2024).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx23">
<span class="ltx_tag ltx_tag_bibitem">[LCL<sup class="ltx_sup" id="bib.bibx23.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx23.4.4.1.1">∗</span></sup>23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx23.7.1">Liang R., Chen H., Li C., Chen F., Panneer S., Vijaykumar N.</span>:

</span>
<span class="ltx_bibblock">Envidr: Implicit differentiable renderer with neural environment lighting.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx23.8.1">IEEE/CVF Int. Conf. Comput. Vis.</em> (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx24">
<span class="ltx_tag ltx_tag_bibitem">[LGF<sup class="ltx_sup" id="bib.bibx24.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx24.4.4.1.1">∗</span></sup>22]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx24.7.1">Li Q., Guo J., Fei Y., Li F., Guo Y.</span>:

</span>
<span class="ltx_bibblock">Neulighting: Neural lighting for free viewpoint outdoor scene relighting with unconstrained photo collections.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx24.8.1">SIGGRAPH Asia 2022 Conference Papers</em> (2022).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx25">
<span class="ltx_tag ltx_tag_bibitem">[LGZ<sup class="ltx_sup" id="bib.bibx25.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx25.4.4.1.1">∗</span></sup>20]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx25.7.1">Liu A., Ginosar S., Zhou T., Efros A. A., Snavely N.</span>:

</span>
<span class="ltx_bibblock">Learning to factorize and relight a city.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx25.8.1">Eur. Conf. Comput. Vis.</em> (2020).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx26">
<span class="ltx_tag ltx_tag_bibitem">[LLLY23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx26.1.1">Lin S., Liu B., Li J., Yang X.</span>:

</span>
<span class="ltx_bibblock">Common diffusion noise schedules and sample steps are flawed.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx26.2.1">arXiv preprint arXiv:2305.08891</em> (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx27">
<span class="ltx_tag ltx_tag_bibitem">[LLZ<sup class="ltx_sup" id="bib.bibx27.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx27.4.4.1.1">∗</span></sup>20]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx27.7.1">Liu D., Long C., Zhang H., Yu H., Dong X., Xiao C.</span>:

</span>
<span class="ltx_bibblock">Arshadowgan: Shadow generative adversarial network for augmented reality in single light scenes.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx27.8.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (2020).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx28">
<span class="ltx_tag ltx_tag_bibitem">[LSB<sup class="ltx_sup" id="bib.bibx28.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx28.4.4.1.1">∗</span></sup>22]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx28.7.1">Li Z., Shi J., Bi S., Zhu R., Sunkavalli K., Hašan M., Xu Z., Ramamoorthi R., Chandraker M.</span>:

</span>
<span class="ltx_bibblock">Physically-based editing of indoor scene lighting from a single image.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx28.8.1">Eur. Conf. Comput. Vis.</em> (2022).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx29">
<span class="ltx_tag ltx_tag_bibitem">[LSY<sup class="ltx_sup" id="bib.bibx29.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx29.4.4.1.1">∗</span></sup>21]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx29.7.1">Lagunas M., Sun X., Yang J., Villegas R., Zhang J., Shu Z., Masia B., Gutierrez D.</span>:

</span>
<span class="ltx_bibblock">Single-image full-body human relighting.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx29.8.1">Eur. Graph. Symp. Render.</em> (2021).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx30">
<span class="ltx_tag ltx_tag_bibitem">[LWC<sup class="ltx_sup" id="bib.bibx30.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx30.4.4.1.1">∗</span></sup>23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx30.7.1">Li Z., Wang L., Cheng M., Pan C., Yang J.</span>:

</span>
<span class="ltx_bibblock">Multi-view inverse rendering for large-scale real-world indoor scenes.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx30.8.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx31">
<span class="ltx_tag ltx_tag_bibitem">[LWL<sup class="ltx_sup" id="bib.bibx31.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx31.4.4.1.1">∗</span></sup>23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx31.7.1">Liu Y., Wang P., Lin C., Long X., Wang J., Liu L., Komura T., Wang W.</span>:

</span>
<span class="ltx_bibblock">Nero: Neural geometry and brdf reconstruction of reflective objects from multiview images.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx31.8.1">ACM Trans. Graph.</em> (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx32">
<span class="ltx_tag ltx_tag_bibitem">[LZF<sup class="ltx_sup" id="bib.bibx32.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx32.4.4.1.1">∗</span></sup>24]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx32.7.1">Liang Z., Zhang Q., Feng Y., Shan Y., Jia K.</span>:

</span>
<span class="ltx_bibblock">Gs-ir: 3d gaussian splatting for inverse rendering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx32.8.1">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</em> (2024).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx33">
<span class="ltx_tag ltx_tag_bibitem">[MBRS<sup class="ltx_sup" id="bib.bibx33.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx33.4.4.1.1">∗</span></sup>21]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx33.7.1">Martin-Brualla R., Radwan N., Sajjadi M. S. M., Barron J. T., Dosovitskiy A., Duckworth D.</span>:

</span>
<span class="ltx_bibblock">NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx33.8.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (2021).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx34">
<span class="ltx_tag ltx_tag_bibitem">[MESK22]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx34.1.1">Müller T., Evans A., Schied C., Keller A.</span>:

</span>
<span class="ltx_bibblock">Instant neural graphics primitives with a multiresolution hash encoding.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx34.2.1">ACM Trans. Graph. 41</em>, 4 (July 2022), 102:1–102:15.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx35">
<span class="ltx_tag ltx_tag_bibitem">[MGAD19]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx35.1.1">Murmann L., Gharbi M., Aittala M., Durand F.</span>:

</span>
<span class="ltx_bibblock">A multi-illumination dataset of indoor object appearance.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx35.2.1">IEEE/CVF Int. Conf. Comput. Vis.</em> (2019).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx36">
<span class="ltx_tag ltx_tag_bibitem">[MHS<sup class="ltx_sup" id="bib.bibx36.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx36.4.4.1.1">∗</span></sup>22]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx36.7.1">Munkberg J., Hasselgren J., Shen T., Gao J., Chen W., Evans A., Müller T., Fidler S.</span>:

</span>
<span class="ltx_bibblock">Extracting Triangular 3D Models, Materials, and Lighting From Images.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx36.8.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (June 2022), pp. 8280–8290.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx37">
<span class="ltx_tag ltx_tag_bibitem">[MST<sup class="ltx_sup" id="bib.bibx37.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx37.4.4.1.1">∗</span></sup>20]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx37.7.1">Mildenhall B., Srinivasan P. P., Tancik M., Barron J. T., Ramamoorthi R., Ng R.</span>:

</span>
<span class="ltx_bibblock">Nerf: Representing scenes as neural radiance fields for view synthesis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx37.8.1">Eur. Conf. Comput. Vis.</em> (2020).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx38">
<span class="ltx_tag ltx_tag_bibitem">[NDDJK21]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx38.1.1">Nimier-David M., Dong Z., Jakob W., Kaplanyan A.</span>:

</span>
<span class="ltx_bibblock">Material and lighting reconstruction for complex indoor scenes with texture-space differentiable rendering.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx38.2.1">Comput. Graph. Forum</em> (2021).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx39">
<span class="ltx_tag ltx_tag_bibitem">[PD23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx39.1.1">Philip J., Deschaintre V.</span>:

</span>
<span class="ltx_bibblock">Floaters no more: Radiance field gradient scaling for improved near-camera training.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx39.2.1">EGSR Conference proceedings DL-track</em> (2023), The Eurographics Association.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx40">
<span class="ltx_tag ltx_tag_bibitem">[PEL<sup class="ltx_sup" id="bib.bibx40.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx40.4.4.1.1">∗</span></sup>23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx40.7.1">Podell D., English Z., Lacey K., Blattmann A., Dockhorn T., Müller J., Penna J., Rombach R.</span>:

</span>
<span class="ltx_bibblock">Sdxl: Improving latent diffusion models for high-resolution image synthesis.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx40.8.1">arXiv preprint arXiv:2307.01952</em> (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx41">
<span class="ltx_tag ltx_tag_bibitem">[PGZ<sup class="ltx_sup" id="bib.bibx41.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx41.4.4.1.1">∗</span></sup>19]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx41.7.1">Philip J., Gharbi M., Zhou T., Efros A. A., Drettakis G.</span>:

</span>
<span class="ltx_bibblock">Multi-view relighting using a geometry-aware network.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx41.8.1">ACM Trans. Graph. 38</em>, 4 (2019), 78–1.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx42">
<span class="ltx_tag ltx_tag_bibitem">[PLMZ23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx42.1.1">Papantoniou F. P., Lattas A., Moschoglou S., Zafeiriou S.</span>:

</span>
<span class="ltx_bibblock">Relightify: Relightable 3d faces from a single image via diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx42.2.1">IEEE/CVF Int. Conf. Comput. Vis.</em> (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx43">
<span class="ltx_tag ltx_tag_bibitem">[PMGD21]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx43.1.1">Philip J., Morgenthaler S., Gharbi M., Drettakis G.</span>:

</span>
<span class="ltx_bibblock">Free-viewpoint indoor neural relighting from multi-view stereo.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx43.2.1">ACM Trans. Graph. 40</em>, 5 (2021), 1–18.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx44">
<span class="ltx_tag ltx_tag_bibitem">[PTS23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx44.1.1">Ponglertnapakorn P., Tritrong N., Suwajanakorn S.</span>:

</span>
<span class="ltx_bibblock">Difareli: Diffusion face relighting.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx44.2.1">IEEE/CVF Int. Conf. Comput. Vis.</em> (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx45">
<span class="ltx_tag ltx_tag_bibitem">[RBL<sup class="ltx_sup" id="bib.bibx45.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx45.4.4.1.1">∗</span></sup>22]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx45.7.1">Rombach R., Blattmann A., Lorenz D., Esser P., Ommer B.</span>:

</span>
<span class="ltx_bibblock">High-resolution image synthesis with latent diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx45.8.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (2022).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx46">
<span class="ltx_tag ltx_tag_bibitem">[RES<sup class="ltx_sup" id="bib.bibx46.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx46.4.4.1.1">∗</span></sup>22]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx46.7.1">Rudnev V., Elgharib M., Smith W., Liu L., Golyanik V., Theobalt C.</span>:

</span>
<span class="ltx_bibblock">Nerf for outdoor scene relighting.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx46.8.1">Eur. Conf. Comput. Vis.</em> (2022).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx47">
<span class="ltx_tag ltx_tag_bibitem">[RLJ<sup class="ltx_sup" id="bib.bibx47.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx47.4.4.1.1">∗</span></sup>23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx47.7.1">Ruiz N., Li Y., Jampani V., Pritch Y., Rubinstein M., Aberman K.</span>:

</span>
<span class="ltx_bibblock">Dreambooth: Fine tuning text-to-image diffusion models for subject-driven generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx47.8.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (2023), pp. 22500–22510.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx48">
<span class="ltx_tag ltx_tag_bibitem">[SDWMG15]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx48.1.1">Sohl-Dickstein J., Weiss E., Maheswaranathan N., Ganguli S.</span>:

</span>
<span class="ltx_bibblock">Deep unsupervised learning using nonequilibrium thermodynamics.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx49">
<span class="ltx_tag ltx_tag_bibitem">[SDZ<sup class="ltx_sup" id="bib.bibx49.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx49.4.4.1.1">∗</span></sup>21]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx49.7.1">Srinivasan P. P., Deng B., Zhang X., Tancik M., Mildenhall B., Barron J. T.</span>:

</span>
<span class="ltx_bibblock">Nerv: Neural reflectance and visibility fields for relighting and view synthesis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx49.8.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (2021).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx50">
<span class="ltx_tag ltx_tag_bibitem">[SF16]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx50.1.1">Schönberger J. L., Frahm J.-M.</span>:

</span>
<span class="ltx_bibblock">Structure-from-motion revisited.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx50.2.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (2016).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx51">
<span class="ltx_tag ltx_tag_bibitem">[SJL<sup class="ltx_sup" id="bib.bibx51.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx51.4.4.1.1">∗</span></sup>23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx51.7.1">Sharma P., Jampani V., Li Y., Jia X., Lagun D., Durand F., Freeman W. T., Matthews M.</span>:

</span>
<span class="ltx_bibblock">Alchemist: Parametric control of material properties with diffusion models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx51.8.1">arXiv preprint arXiv:2312.02970</em> (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx52">
<span class="ltx_tag ltx_tag_bibitem">[SKCJ18]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx52.1.1">Sengupta S., Kanazawa A., Castillo C. D., Jacobs D. W.</span>:

</span>
<span class="ltx_bibblock">Sfsnet: Learning shape, reflectance and illuminance of facesin the wild.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx52.2.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (2018).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx53">
<span class="ltx_tag ltx_tag_bibitem">[SLZ<sup class="ltx_sup" id="bib.bibx53.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx53.4.4.1.1">∗</span></sup>22]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx53.7.1">Sheng Y., Liu Y., Zhang J., Yin W., Oztireli A. C., Zhang H., Lin Z., Shechtman E., Benes B.</span>:

</span>
<span class="ltx_bibblock">Controllable shadow generation using pixel height maps.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx53.8.1">Eur. Conf. Comput. Vis.</em> (2022).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx54">
<span class="ltx_tag ltx_tag_bibitem">[SME20]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx54.1.1">Song J., Meng C., Ermon S.</span>:

</span>
<span class="ltx_bibblock">Denoising diffusion implicit models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx54.2.1">Int. Conf. Learn. Represent.</em> (2020).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx55">
<span class="ltx_tag ltx_tag_bibitem">[SWW<sup class="ltx_sup" id="bib.bibx55.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx55.4.4.1.1">∗</span></sup>23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx55.7.1">Shi Y., Wu Y., Wu C., Liu X., Zhao C., Feng H., Liu J., Zhang L., Zhang J., Zhou B., Ding E., Wang J.</span>:

</span>
<span class="ltx_bibblock">Gir: 3d gaussian inverse rendering for relightable scene factorization.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx55.8.1">Arxiv</em> (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx56">
<span class="ltx_tag ltx_tag_bibitem">[SYH<sup class="ltx_sup" id="bib.bibx56.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx56.4.4.1.1">∗</span></sup>17]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx56.7.1">Shu Z., Yumer E., Hadap S., Sunkavalli K., Shechtman E., Samaras D.</span>:

</span>
<span class="ltx_bibblock">Neural face editing with intrinsic image disentangling.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx56.8.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (2017).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx57">
<span class="ltx_tag ltx_tag_bibitem">[SZB21]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx57.1.1">Sheng Y., Zhang J., Benes B.</span>:

</span>
<span class="ltx_bibblock">Ssn: Soft shadow network for image compositing.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx57.2.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (2021).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx58">
<span class="ltx_tag ltx_tag_bibitem">[SZPF16]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx58.1.1">Schönberger J. L., Zheng E., Pollefeys M., Frahm J.-M.</span>:

</span>
<span class="ltx_bibblock">Pixelwise view selection for unstructured multi-view stereo.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx58.2.1">Eur. Conf. Comput. Vis.</em> (2016).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx59">
<span class="ltx_tag ltx_tag_bibitem">[TÇE<sup class="ltx_sup" id="bib.bibx59.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx59.4.4.1.1">∗</span></sup>21]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx59.7.1">Türe M., Çıklabakkal M. E., Erdem A., Erdem E., Satılmış P., Akyüz A. O.</span>:

</span>
<span class="ltx_bibblock">From noon to sunset: Interactive rendering, relighting, and recolouring of landscape photographs by modifying solar position.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx59.8.1">Comput. Graph. Forum</em> (2021), vol. 40, pp. 500–515.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx60">
<span class="ltx_tag ltx_tag_bibitem">[TDMS<sup class="ltx_sup" id="bib.bibx60.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx60.4.4.1.1">∗</span></sup>23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx60.7.1">Toschi M., De Matteo R., Spezialetti R., De Gregorio D., Di Stefano L., Salti S.</span>:

</span>
<span class="ltx_bibblock">Relight my nerf: A dataset for novel view synthesis and relighting of real world objects.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx60.8.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (June 2023), pp. 20762–20772.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx61">
<span class="ltx_tag ltx_tag_bibitem">[TTM<sup class="ltx_sup" id="bib.bibx61.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx61.4.4.1.1">∗</span></sup>22]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx61.7.1">Tewari A., Thies J., Mildenhall B., Srinivasan P., Tretschk E., Yifan W., Lassner C., Sitzmann V., Martin-Brualla R., Lombardi S., et al.</span>:

</span>
<span class="ltx_bibblock">Advances in neural rendering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx61.8.1">Comput. Graph. Forum</em> (2022), vol. 41, Wiley Online Library, pp. 703–735.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx62">
<span class="ltx_tag ltx_tag_bibitem">[Ull79]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx62.1.1">Ullman S.</span>:

</span>
<span class="ltx_bibblock">The interpretation of structure from motion.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx62.2.1">Proceedings of the Royal Society of London. Series B, Biological sciences 203</em>, 1153 (January 1979), 405—426.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx63">
<span class="ltx_tag ltx_tag_bibitem">[VZG<sup class="ltx_sup" id="bib.bibx63.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx63.4.4.1.1">∗</span></sup>23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx63.7.1">Valença L., Zhang J., Gharbi M., Hold-Geoffroy Y., Lalonde J.-F.</span>:

</span>
<span class="ltx_bibblock">Shadow harmonization for realistic compositing.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx63.8.1">SIGGRAPH Asia 2023 Conference Papers</em> (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx64">
<span class="ltx_tag ltx_tag_bibitem">[WSG<sup class="ltx_sup" id="bib.bibx64.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx64.4.4.1.1">∗</span></sup>23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx64.7.1">Wang Z., Shen T., Gao J., Huang S., Munkberg J., Hasselgren J., Gojcic Z., Chen W., Fidler S.</span>:

</span>
<span class="ltx_bibblock">Neural fields meet explicit geometric representations for inverse rendering of urban scenes.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx64.8.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx65">
<span class="ltx_tag ltx_tag_bibitem">[WSLG23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx65.1.1">Wu T., Sun J.-M., Lai Y.-K., Gao L.</span>:

</span>
<span class="ltx_bibblock">De-nerf: Decoupled neural radiance fields for view-consistent appearance editing and high-frequency environmental relighting.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx65.2.1">ACM SIGGRAPH</em> (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx66">
<span class="ltx_tag ltx_tag_bibitem">[WZL<sup class="ltx_sup" id="bib.bibx66.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx66.4.4.1.1">∗</span></sup>08]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx66.7.1">Wang Y., Zhang L., Liu Z., Hua G., Wen Z., Zhang Z., Samaras D.</span>:

</span>
<span class="ltx_bibblock">Face relighting from a single image under arbitrary unknown lighting conditions.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx66.8.1">IEEE Trans. Pattern Anal. Mach. Intell. 31</em>, 11 (2008), 1968–1984.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx67">
<span class="ltx_tag ltx_tag_bibitem">[XZC<sup class="ltx_sup" id="bib.bibx67.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx67.4.4.1.1">∗</span></sup>23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx67.7.1">Xu Y., Zoss G., Chandran P., Gross M., Bradley D., Gotardo P.</span>:

</span>
<span class="ltx_bibblock">Renerf: Relightable neural radiance fields with nearfield lighting.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx67.8.1">IEEE/CVF Int. Conf. Comput. Vis.</em> (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx68">
<span class="ltx_tag ltx_tag_bibitem">[YME<sup class="ltx_sup" id="bib.bibx68.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx68.4.4.1.1">∗</span></sup>20]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx68.7.1">Yu Y., Meka A., Elgharib M., Seidel H.-P., Theobalt C., Smith W. A.</span>:

</span>
<span class="ltx_bibblock">Self-supervised outdoor scene relighting.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx68.8.1">Eur. Conf. Comput. Vis.</em> (2020).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx69">
<span class="ltx_tag ltx_tag_bibitem">[YS22]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx69.1.1">Yu Y., Smith W. A. P.</span>:

</span>
<span class="ltx_bibblock">Outdoor inverse rendering from a single image using multiview self-supervision.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx69.2.1">IEEE Trans. Pattern Anal. Mach. Intell. 44</em>, 7 (2022), 3659–3675.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx70">
<span class="ltx_tag ltx_tag_bibitem">[YZL<sup class="ltx_sup" id="bib.bibx70.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx70.4.4.1.1">∗</span></sup>22]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx70.7.1">Yao Y., Zhang J., Liu J., Qu Y., Fang T., McKinnon D., Tsin Y., Quan L.</span>:

</span>
<span class="ltx_bibblock">Neilf: Neural incident light field for physically-based material estimation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx70.8.1">Eur. Conf. Comput. Vis.</em> (2022).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx71">
<span class="ltx_tag ltx_tag_bibitem">[ZCD<sup class="ltx_sup" id="bib.bibx71.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx71.4.4.1.1">∗</span></sup>23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx71.7.1">Zeng C., Chen G., Dong Y., Peers P., Wu H., Tong X.</span>:

</span>
<span class="ltx_bibblock">Relighting neural radiance fields with shadow and highlight hints.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx71.8.1">ACM SIGGRAPH 2023 Conference Proceedings</em> (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx72">
<span class="ltx_tag ltx_tag_bibitem">[ZDP<sup class="ltx_sup" id="bib.bibx72.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx72.4.4.1.1">∗</span></sup>24]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx72.7.1">Zeng C., Dong Y., Peers P., Kong Y., Wu H., Tong X.</span>:

</span>
<span class="ltx_bibblock">Dilightnet: Fine-grained lighting control for diffusion-based image generation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx72.8.1">ACM SIGGRAPH 2024 Conference Proceedings</em> (2024).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx73">
<span class="ltx_tag ltx_tag_bibitem">[ZFC<sup class="ltx_sup" id="bib.bibx73.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx73.4.4.1.1">∗</span></sup>23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx73.7.1">Zhu Z., Feng X., Chen D., Bao J., Wang L., Chen Y., Yuan L., Hua G.</span>:

</span>
<span class="ltx_bibblock">Designing a better asymmetric vqgan for stablediffusion, 2023.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx74">
<span class="ltx_tag ltx_tag_bibitem">[ZHY<sup class="ltx_sup" id="bib.bibx74.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx74.4.4.1.1">∗</span></sup>23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx74.7.1">Zhu J., Huo Y., Ye Q., Luan F., Li J., Xi D., Wang L., Tang R., Hua W., Bao H., et al.</span>:

</span>
<span class="ltx_bibblock">I2-sdf: Intrinsic indoor scene reconstruction and editing via raytracing in neural sdfs.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx74.8.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx75">
<span class="ltx_tag ltx_tag_bibitem">[ZIE<sup class="ltx_sup" id="bib.bibx75.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx75.4.4.1.1">∗</span></sup>18]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx75.7.1">Zhang R., Isola P., Efros A. A., Shechtman E., Wang O.</span>:

</span>
<span class="ltx_bibblock">The unreasonable effectiveness of deep features as a perceptual metric.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx75.8.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (2018).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx76">
<span class="ltx_tag ltx_tag_bibitem">[ZLW<sup class="ltx_sup" id="bib.bibx76.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx76.4.4.1.1">∗</span></sup>21]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx76.7.1">Zhang K., Luan F., Wang Q., Bala K., Snavely N.</span>:

</span>
<span class="ltx_bibblock">PhySG: Inverse rendering with spherical gaussians for physics-based material editing and relighting.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx76.8.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (2021).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx77">
<span class="ltx_tag ltx_tag_bibitem">[ZLZ<sup class="ltx_sup" id="bib.bibx77.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx77.4.4.1.1">∗</span></sup>22]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx77.7.1">Zhu Z.-L., Li Z., Zhang R.-X., Guo C.-L., Cheng M.-M.</span>:

</span>
<span class="ltx_bibblock">Designing an illumination-aware network for deep image relighting.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx77.8.1">IEEE Trans. Image Process. 31</em> (2022), 5396–5411.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx78">
<span class="ltx_tag ltx_tag_bibitem">[ZRA23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx78.1.1">Zhang L., Rao A., Agrawala M.</span>:

</span>
<span class="ltx_bibblock">Adding conditional control to text-to-image diffusion models.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx78.2.1">IEEE/CVF Int. Conf. Comput. Vis.</em> (2023).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx79">
<span class="ltx_tag ltx_tag_bibitem">[ZSD<sup class="ltx_sup" id="bib.bibx79.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx79.4.4.1.1">∗</span></sup>21]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx79.7.1">Zhang X., Srinivasan P. P., Deng B., Debevec P., Freeman W. T., Barron J. T.</span>:

</span>
<span class="ltx_bibblock">Nerfactor: Neural factorization of shape and reflectance under an unknown illumination.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bibx79.8.1">ACM Trans. Graph. 40</em>, 6 (2021), 1–18.

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx80">
<span class="ltx_tag ltx_tag_bibitem">[ZSH<sup class="ltx_sup" id="bib.bibx80.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx80.4.4.1.1">∗</span></sup>22]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx80.7.1">Zhang Y., Sun J., He X., Fu H., Jia R., Zhou X.</span>:

</span>
<span class="ltx_bibblock">Modeling indirect illumination for inverse rendering.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx80.8.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (2022).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx81">
<span class="ltx_tag ltx_tag_bibitem">[ZTS<sup class="ltx_sup" id="bib.bibx81.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx81.4.4.1.1">∗</span></sup>22]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx81.7.1">Zhang X., Tseng N., Syed A., Bhasin R., Jaipuria N.</span>:

</span>
<span class="ltx_bibblock">Simbar: Single image-based scene relighting for effective data augmentation for automated driving vision tasks.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx81.8.1">IEEE/CVF Conf. Comput. Vis. Pattern Recog.</em> (06 2022).

</span>
</li>
<li class="ltx_bibitem" id="bib.bibx82">
<span class="ltx_tag ltx_tag_bibitem">[ZYL<sup class="ltx_sup" id="bib.bibx82.4.4.1"><span class="ltx_text ltx_font_italic" id="bib.bibx82.4.4.1.1">∗</span></sup>23]</span>
<span class="ltx_bibblock">
<span class="ltx_text ltx_font_smallcaps" id="bib.bibx82.7.1">Zhang J., Yao Y., Li S., Liu J., Fang T., McKinnon D., Tsin Y., Quan L.</span>:

</span>
<span class="ltx_bibblock">Neilf++: Inter-reflectable light fields for geometry and material estimation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bibx82.8.1">IEEE/CVF Int. Conf. Comput. Vis.</em> (2023).

</span>
</li>
</ul>
</section><div about="" class="ltx_rdf" content="{\@shortauthor}" property="dcterms:creator"></div>
<div about="" class="ltx_rdf" content="{Computer Graphics Forum" property="dcterms:subject"></div>
<div about="" class="ltx_rdf" content="{\pdf@Subject}" property="dcterms:subject"></div>
<div about="" class="ltx_rdf" content="{\@shorttitle}" property="dcterms:title"></div>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Tue Sep 17 12:16:40 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
