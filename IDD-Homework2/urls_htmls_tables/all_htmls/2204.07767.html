<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2204.07767] Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M.</title><meta property="og:description" content="Federated Learning (FL) is a machine learning approach that addresses privacy and data transfer costs by computing data at the source. It’s particularly popular for Edge and IoT applications where the aggregator server…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M.">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M.">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2204.07767">

<!--Generated on Wed Feb 28 08:03:22 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="
federated learning,  aggregation,  edge computing
">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">Towards cost-effective and resource-aware aggregation at Edge for Federated Learning
<span id="id4.id1" class="ltx_note ltx_role_thanks"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">thanks: </span>This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M.</span></span></span>
</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">1<sup id="id5.1.id1" class="ltx_sup">st</sup> Ahmad Faraz Khan
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id6.2.id1" class="ltx_text ltx_font_italic">Virginia Tech</span>
<br class="ltx_break">Blacksburg, USA 
<br class="ltx_break">ahmadfk@vt.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">2<sup id="id7.1.id1" class="ltx_sup">nd</sup> Yuze Li
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id8.2.id1" class="ltx_text ltx_font_italic">Virginia Tech</span>
<br class="ltx_break">Blacksburg, USA 
<br class="ltx_break">lyuze@vt.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">3<sup id="id9.1.id1" class="ltx_sup">rd</sup> Xinran Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id10.2.id1" class="ltx_text ltx_font_italic">University of Minnesota</span>
<br class="ltx_break">Minnesota, USA 
<br class="ltx_break">wang8740@umn.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">4<sup id="id11.1.id1" class="ltx_sup">th</sup> Sabaat Haroon
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id12.2.id1" class="ltx_text ltx_font_italic">Virginia Tech</span>
<br class="ltx_break">Blacksburg, USA 
<br class="ltx_break">sabaat@vt.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">5<sup id="id13.1.id1" class="ltx_sup">th</sup> Haider Ali
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id14.2.id1" class="ltx_text ltx_font_italic">Virginia Tech</span>
<br class="ltx_break">Blacksburg, USA 
<br class="ltx_break">haiderali@vt.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">6<sup id="id15.1.id1" class="ltx_sup">th</sup> Yue Cheng
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id16.2.id1" class="ltx_text ltx_font_italic">University of Virginia</span>
<br class="ltx_break">Charlottesville, USA 
<br class="ltx_break">mrz7dp@virginia.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">7<sup id="id17.1.id1" class="ltx_sup">th</sup> Ali R. Butt
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id18.2.id1" class="ltx_text ltx_font_italic">Virginia Tech</span>
<br class="ltx_break">Blacksburg, USA 
<br class="ltx_break">butta@vt.edu
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">8<sup id="id19.1.id1" class="ltx_sup">th</sup> Ali Anwar
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id20.2.id1" class="ltx_text ltx_font_italic">University of Minnesota</span>
<br class="ltx_break">Minnesota, USA 
<br class="ltx_break">aanwar@umn.edu
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id3.3" class="ltx_p">Federated Learning (FL) is a machine learning approach that addresses privacy and data transfer costs by computing data at the source. It’s particularly popular for Edge and IoT applications where the aggregator server of FL is in resource-capped edge data centers for reducing communication costs. Existing cloud-based aggregator solutions are resource-inefficient and expensive at the Edge, leading to low scalability and high latency. To address these challenges, this study compares prior and new aggregation methodologies under the changing demands of IoT and Edge applications. This work is the first to propose an adaptive FL aggregator at the Edge, enabling users to manage the cost and efficiency trade-off. An extensive comparative analysis demonstrates that the design improves scalability by up to <math id="id1.1.m1.1" class="ltx_math_unparsed" alttext="4\times" display="inline"><semantics id="id1.1.m1.1a"><mrow id="id1.1.m1.1b"><mn id="id1.1.m1.1.1">4</mn><mo lspace="0.222em" id="id1.1.m1.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="id1.1.m1.1c">4\times</annotation></semantics></math>, time efficiency by <math id="id2.2.m2.1" class="ltx_math_unparsed" alttext="8\times" display="inline"><semantics id="id2.2.m2.1a"><mrow id="id2.2.m2.1b"><mn id="id2.2.m2.1.1">8</mn><mo lspace="0.222em" id="id2.2.m2.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="id2.2.m2.1c">8\times</annotation></semantics></math>, and reduces costs by more than <math id="id3.3.m3.1" class="ltx_math_unparsed" alttext="2\times" display="inline"><semantics id="id3.3.m3.1a"><mrow id="id3.3.m3.1b"><mn id="id3.3.m3.1.1">2</mn><mo lspace="0.222em" id="id3.3.m3.1.2">×</mo></mrow><annotation encoding="application/x-tex" id="id3.3.m3.1c">2\times</annotation></semantics></math> compared to extant cloud-based static methodologies.</p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
federated learning, aggregation, edge computing

</div>
<span id="id1" class="ltx_note ltx_note_frontmatter ltx_role_publicationid"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup><span class="ltx_note_type">publicationid: </span>pubid: <span id="id1.1" class="ltx_text ltx_inline-block" style="width:433.6pt;">979-8-3503-2445-7/23/$31.00 ©2023 IEEE  </span>
<span id="id1.2" class="ltx_text ltx_inline-block" style="width:433.6pt;"> </span></span></span></span>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">IoT and edge devices generate sensitive data that requires careful handling to prevent security or privacy violations. Traditional machine learning methods <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> that send private data to a centralized location for training pose significant privacy, communication, and security challenges and are unsuitable for sensitive data due to regulations like HIPAA <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> and GDPR <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. Federated Learning (FL) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> is a new technique that enables clients, such as IoT and edge devices, to collaborate in training a model without moving the data outside the system boundaries. FL reduces communication costs and privacy risks and has been adopted for a wide range of IoT and edge applications, including agriculture, healthcare, human behavior recognition, transportation, and smart homes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite>.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p"><span id="S1.p2.1.1" class="ltx_text ltx_font_bold">Problem.</span> At the heart of Federated Learning (FL) lies the parameter/aggregator server, which coordinates the training process, manages client participation, and performs aggregation of model updates. However, when it comes to IoT and edge applications, this server must contend with unique scalability, efficiency, and cost management challenges. This is especially true given the scale of these applications, which often involve millions of client devices with highly segregated data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. As a result, addressing these challenges is critical to the success of FL in edge environments <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. Edge data centers are compact data centers that have a smaller footprint compared to traditional data centers. They typically house only a limited number of servers, usually between 3 to 10, and can be easily moved and deployed in limited spaces such as a factory or an Internet Access point <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>. For this reason, it becomes an attractive option to house aggregator servers at the edge to save communication costs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. The intuition of unlimited resource scalability in existing solutions for cloud aggregator servers becomes an impractical approach at the edge data center. Limited compute, network, and memory resources at the edge data centers raise the requirement for a resource-aware scalable, and efficient aggregator at the edge while maintaining minimal costs.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p"><span id="S1.p3.1.1" class="ltx_text ltx_font_bold">Challenges.</span> Existing studies on FL aggregation services have primarily focused on different aspects such as communication efficiency <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, time efficiency <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, and cost reduction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite>. However, these studies propose solutions for cloud settings where they typically assume no limitations on resources or costs for the aggregation server, therefore, these methodologies cannot be used for edge data center setups where resources are limited. Moreover, current FL frameworks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> rely on a single central node for the aggregator server, leading to inefficiencies, high I/O or communication costs, prolonged aggregation times, and limited scalability. Furthermore, there is a lack of understanding of the complex system challenges that arise when developing scientific FL applications, especially in the context of edge-cloud aggregation jobs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib23" title="" class="ltx_ref">23</a>, <a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>. Thus, there is a need to develop new FL aggregation solutions that can effectively leverage edge data centers’ resources while minimizing costs.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p"><span id="S1.p4.1.1" class="ltx_text ltx_font_bold">Contributions.</span> In this paper, we aim to address the challenges of scalability, efficiency, and cost-effectiveness in FL aggregation at edge data centers. For this, we present a comprehensive analysis of the performance and cost of existing FL frameworks and multi-core, multi-node aggregation methodologies on limited resources, simulating conditions at the edge server. We acknowledge previous works such as serverless parameter servers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>, <a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> and distributed aggregator servers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, but find that they have limited scalability and efficiency or assume unlimited cost spending. Additionally, some designs rely on peer-to-peer communication, which increases communication costs and latency. To address these challenges, we propose a resource-aware adaptive aggregator design that selects the most efficient methodology while keeping resource spending low.
Our design includes a Numba-based method, a Spark-based method <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, and a Serverless tree-reduce method, all integrated into a hybrid setting. This adaptive methodology enables the aggregator to scale according to demand while minimizing cost and latency. We use scalable storage for communication to overcome issues from peer-to-peer intra-aggregator connections. Additionally, users can customize the adaptive policy to achieve a balance between efficiency and cost trade-offs. In summary, this paper presents a novel resource-aware adaptive aggregator design for FL at edge data centers that address the challenges of scalability, time and resource efficiency, and cost-effectiveness. The goal is to reduce costs and spending on resources while maintaining the quality of service (QoS) indicated by low latency and cost-effective scalability for the user. To achieve this, the least costly method is chosen to meet the time efficiency and scalability requirements for particular aggregation jobs. Our approach differs from previous works by considering limited resources at the edge, and we believe this is the first work to do so.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p"><span id="S1.p5.1.1" class="ltx_text ltx_font_bold">Technical Insights.</span> We start by building a predictive model that outputs a methodology for aggregation, minimizing time and monetary costs based on user preferences, using exhaustive profiling data, task-specific information, and system availability as input. To assess the efficacy of the adaptive method, we perform a comprehensive analysis of each technique by highlighting its strengths and weaknesses and comparing it with the adaptive method. We use a client emulator with a large number of clients and perform extensive micro and macro benchmarks to analyze each technique. Our analysis reveals interesting trends, such as serverless being more efficient than Spark for processing data from a large number of clients but costly for other specific workloads compared to Spark. On the other hand, Spark remains cost-effective and efficient for processing larger data chunks. Thus, each method has its pros and cons. No single method can fully address all the challenges in aggregation at the Edge data center, leading to the development of the adaptive aggregator design. Existing works have been done in the cloud setting, where the aggregator has unlimited resources. However, these methodologies cannot be used for edge data center setups with limited resources, a significant challenge our method addresses.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p"><span id="S1.p6.1.1" class="ltx_text ltx_font_bold">Evaluation.</span> The evaluation consists of exhaustive experimentation with up to one million clients. Altogether, the duration of the experiments was approximately 1440 hours, and more than 100k lambda functions were used in total.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p"><span id="S1.p7.1.1" class="ltx_text ltx_font_bold">Summary.</span> Our contributions are as follows:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">Highlight the <span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">limitations of existing FL frameworks</span> by analysis of common basic operations in their aggregation.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">Propose and assess <span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">three different strategies</span> for scalability, efficiency, and cost-effectiveness limitations.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Propose the <span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">first solution for an adaptive aggregator at the Edge</span>. Our adaptive aggregation technique is driven by user preferences to achieve high QoS based on popular FL edge and IoT applications.</p>
</div>
</li>
<li id="S1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">4.</span> 
<div id="S1.I1.i4.p1" class="ltx_para">
<p id="S1.I1.i4.p1.1" class="ltx_p">Provide a <span id="S1.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">client emulator</span> that connects to any cloud-based parameter server to conduct a cost-benefit analysis of static compared to the adaptive method.</p>
</div>
</li>
<li id="S1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">5.</span> 
<div id="S1.I1.i5.p1" class="ltx_para">
<p id="S1.I1.i5.p1.1" class="ltx_p">Offer <span id="S1.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Counter-intuitive insights</span>, like the unexpectedly high costs of Serverless for specific workloads driving the need for resource-efficient and cost-effective aggregation.</p>
</div>
</li>
</ol>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Background &amp; Motivation</span>
</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">In the FL process, devices train local models and share them with an Aggregator (central) server. This Aggregator combines these local models, creating a global model using algorithms like Federated Averaging <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>, Iterative Averaging, Gradient Aggregation, and Coordinate-wise median <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. This global model goes back to clients for further training, repeating until the desired accuracy is reached. We use the IBM Federated Learning Library (IBMFL version 1.0.6) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> as our baseline <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> referred to as Vanilla throughout the paper because it has a similar aggregator architecture as other common frameworks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>.
<span id="S2.p1.1.1" class="ltx_text ltx_font_bold">We only consider synchronous aggregation as it has gained popularity in recent works and is more stable in terms of convergence <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>, <a href="#bib.bib28" title="" class="ltx_ref">28</a>, <a href="#bib.bib29" title="" class="ltx_ref">29</a>, <a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite></span>.
Next, we highlight challenges faced by the aggregator server of IoT and Edge FL applications such as edge data center’s limited resources including computing, communication, and energy, along with varying participation and device damage <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>, <a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">Varying clients’ participation:</span> In IoT and edge FL applications, client participation varies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib33" title="" class="ltx_ref">33</a>]</cite>, leading to varying model updates received by the aggregator. Conventional cloud servers cannot handle this in a resource-efficient manner as they are designed for unlimited scaling. An adaptive approach is needed to upscale for availability, and downscale for reducing cost, while maintaining efficiency.
<span id="S2.p2.1.2" class="ltx_text ltx_font_bold">Varying model sizes:</span> Techniques like model pruning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="" class="ltx_ref">34</a>]</cite>, sparsification <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib35" title="" class="ltx_ref">35</a>]</cite>, and quantization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="" class="ltx_ref">36</a>]</cite> reduce communication costs for IoT. Models differ in size per client, posing a challenge for FL cloud solutions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> lacking resource-aware scaling. Advanced methods using salient parameters <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="" class="ltx_ref">37</a>]</cite> also cause varied model sizes per client device. Thus, an adaptive strategy is crucial to select the best aggregation method based on costs and resources.
<span id="S2.p2.1.3" class="ltx_text ltx_font_bold">Multi-tenancy Absence:</span> Edge cloud’s parameter and aggregator servers with multi-tenancy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite> share limited resources at the edge data center. Existing FL aggregation techniques falter on Edge data centers because they assume unlimited resources for scaling. Thus, shifting to an efficient approach within confined resources is crucial.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">Scaling for Dynamic Workloads:</span>
IoT and Edge FL applications depend on Edge data centers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib40" title="" class="ltx_ref">40</a>]</cite> for aggregation. These applications have inconsistent participation rates due to limited resources <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, and damage to client devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. Furthermore, Aggregator servers are kept close to IoT devices in Edge datacenters to cut communication cost. However, they face challenges such as limited resources while serving multiple applications. Existing FL aggregator designs <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>, <a href="#bib.bib27" title="" class="ltx_ref">27</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> lack the ability of resource-aware scaling for these variable workloads under limited resources. An adaptive aggregator is essential for flexible, resource-efficient scaling.
<span id="S2.p3.1.2" class="ltx_text ltx_font_bold">Improving Efficiency Performance:</span>

Aggregation is performed after each epoch in the training process. Therefore, efficient aggregation can benefit all FL applications by reducing the waiting times of idle client devices <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib42" title="" class="ltx_ref">42</a>]</cite> between training rounds, thus improving the quality of service (QoS) for clients and allowing them to utilize their resources for training.
<span id="S2.p3.1.3" class="ltx_text ltx_font_bold">User Autonomy for Controlling Costs:</span>
Edge centers manage many applications <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>, <a href="#bib.bib43" title="" class="ltx_ref">43</a>]</cite>, and FL training is lengthy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. Saving energy and resources on edge aggregators is vital. A static approach might not scale well, costing more without downsizing.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">We propose an adaptive aggregator design that dynamically adjusts its scale based on incoming workload, preventing overspending on resources and catering to workload surges. This flexibility enables users to balance between efficiency and cost, adapting to changing device and workload dynamics while prioritizing cost savings.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Methodologies and their Analysis</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We present three diverse Federated Learning (FL) aggregation methods, leveraging technologies like Numba, Spark MapReduce, and Serverless with shared I/O channels, alongside implementation guidance and evaluations for limitations.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S3.T1.2.1.1" class="ltx_text" style="font-size:90%;">TABLE I</span>: </span><span id="S3.T1.3.2" class="ltx_text" style="font-size:90%;">Specifications of models</span></figcaption>
<div id="S3.T1.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:346.9pt;height:152.6pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(-31.2pt,13.7pt) scale(0.847582021834511,0.847582021834511) ;">
<table id="S3.T1.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.4.1.1.1" class="ltx_tr">
<th id="S3.T1.4.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S3.T1.4.1.1.1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Model</span></th>
<th id="S3.T1.4.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T1.4.1.1.1.2.1" class="ltx_text ltx_font_bold ltx_font_italic">Model Size</span></th>
<th id="S3.T1.4.1.1.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span id="S3.T1.4.1.1.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.4.1.1.1.3.1.1" class="ltx_p" style="width:130.1pt;"><span id="S3.T1.4.1.1.1.3.1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Convolutional layers</span></span>
</span>
</th>
<th id="S3.T1.4.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S3.T1.4.1.1.1.4.1" class="ltx_text ltx_font_bold ltx_font_italic">Dense layers</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.4.1.2.1" class="ltx_tr">
<td id="S3.T1.4.1.2.1.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">CNN4.6</td>
<td id="S3.T1.4.1.2.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">4.6 MB</td>
<td id="S3.T1.4.1.2.1.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.4.1.2.1.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.4.1.2.1.3.1.1" class="ltx_p" style="width:130.1pt;">32, 64</span>
</span>
</td>
<td id="S3.T1.4.1.2.1.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">128</td>
</tr>
<tr id="S3.T1.4.1.3.2" class="ltx_tr">
<td id="S3.T1.4.1.3.2.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">CNN73</td>
<td id="S3.T1.4.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">73 MB</td>
<td id="S3.T1.4.1.3.2.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.4.1.3.2.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.4.1.3.2.3.1.1" class="ltx_p" style="width:130.1pt;">32, 256, 512, 1024</span>
</span>
</td>
<td id="S3.T1.4.1.3.2.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">128</td>
</tr>
<tr id="S3.T1.4.1.4.3" class="ltx_tr">
<td id="S3.T1.4.1.4.3.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">CNN179</td>
<td id="S3.T1.4.1.4.3.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">179 MB</td>
<td id="S3.T1.4.1.4.3.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.4.1.4.3.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.4.1.4.3.3.1.1" class="ltx_p" style="width:130.1pt;">32, 512, 1024, 1900</span>
</span>
</td>
<td id="S3.T1.4.1.4.3.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">128</td>
</tr>
<tr id="S3.T1.4.1.5.4" class="ltx_tr">
<td id="S3.T1.4.1.5.4.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">CNN239</td>
<td id="S3.T1.4.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">239 MB</td>
<td id="S3.T1.4.1.5.4.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.4.1.5.4.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.4.1.5.4.3.1.1" class="ltx_p" style="width:130.1pt;">32, 1024, 1900, 2400</span>
</span>
</td>
<td id="S3.T1.4.1.5.4.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">128</td>
</tr>
<tr id="S3.T1.4.1.6.5" class="ltx_tr">
<td id="S3.T1.4.1.6.5.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">CNN478</td>
<td id="S3.T1.4.1.6.5.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">478 MB</td>
<td id="S3.T1.4.1.6.5.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.4.1.6.5.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.4.1.6.5.3.1.1" class="ltx_p" style="width:130.1pt;">32*2,1024*2, 1900*2, 2400*2</span>
</span>
</td>
<td id="S3.T1.4.1.6.5.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">128*2</td>
</tr>
<tr id="S3.T1.4.1.7.6" class="ltx_tr">
<td id="S3.T1.4.1.7.6.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">CNN717</td>
<td id="S3.T1.4.1.7.6.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">717 MB</td>
<td id="S3.T1.4.1.7.6.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.4.1.7.6.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.4.1.7.6.3.1.1" class="ltx_p" style="width:130.1pt;">32*3, 1024*3, 1900*3, 2400*3</span>
</span>
</td>
<td id="S3.T1.4.1.7.6.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">128*3</td>
</tr>
<tr id="S3.T1.4.1.8.7" class="ltx_tr">
<td id="S3.T1.4.1.8.7.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">CNN956</td>
<td id="S3.T1.4.1.8.7.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">956 MB</td>
<td id="S3.T1.4.1.8.7.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.4.1.8.7.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.4.1.8.7.3.1.1" class="ltx_p" style="width:130.1pt;">32*2,1024*2, 1900*2, 2400*2</span>
</span>
</td>
<td id="S3.T1.4.1.8.7.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">128*4</td>
</tr>
<tr id="S3.T1.4.1.9.8" class="ltx_tr">
<td id="S3.T1.4.1.9.8.1" class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">Resnet50</td>
<td id="S3.T1.4.1.9.8.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">91 MB</td>
<td id="S3.T1.4.1.9.8.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="S3.T1.4.1.9.8.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.4.1.9.8.3.1.1" class="ltx_p" style="width:130.1pt;"> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite></span>
</span>
</td>
<td id="S3.T1.4.1.9.8.4" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite>
</td>
</tr>
<tr id="S3.T1.4.1.10.9" class="ltx_tr">
<td id="S3.T1.4.1.10.9.1" class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t">VGG16</td>
<td id="S3.T1.4.1.10.9.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">528 MB</td>
<td id="S3.T1.4.1.10.9.3" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_r ltx_border_t">
<span id="S3.T1.4.1.10.9.3.1" class="ltx_inline-block ltx_align_top">
<span id="S3.T1.4.1.10.9.3.1.1" class="ltx_p" style="width:130.1pt;"> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite></span>
</span>
</td>
<td id="S3.T1.4.1.10.9.4" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>
</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p"><span id="S3.p2.1.1" class="ltx_text ltx_font_bold">Focus of Analysis:</span> We analyze the conditions favoring each method’s performance to inform the design of an adaptive aggregation policy balancing time and cost efficiency. Through experimental analysis, we seek to address these key questions:
①  What are the precise gains achieved by parallel fusion algorithm computation? (Section  <a href="#S3.SS2" title="III-B Multi-core Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-B</span></span></a>) ②  How does horizontal scaling impact time efficiency and cost in multi-node methodologies, and what is the upper limit on number of clients? (Section  <a href="#S3.SS3" title="III-C Spark-based Multi-node Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-C</span></span></a>) ③  How does the complexity of fusion algorithms affect memory and CPU bottlenecks in both multi-core and multi-node methods? (Sections  <a href="#S3.SS2" title="III-B Multi-core Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-B</span></span></a> &amp;  <a href="#S3.SS3" title="III-C Spark-based Multi-node Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-C</span></span></a>) ④  What bottlenecks emerge in horizontally scalable multi-node fusion algorithms? (Section  <a href="#S3.SS3" title="III-C Spark-based Multi-node Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-C</span></span></a>) ⑤ Which method suits specific use cases outlined in Section  <a href="#S2" title="II Background &amp; Motivation ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>, and what are their performance and cost advantages? (Section  <a href="#S3" title="III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>)</p>
</div>
<figure id="S3.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2204.07767/assets/x1.png" id="S3.F1.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="333" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F1.sf1.3.2" class="ltx_text" style="font-size:90%;">Iteravg (CNN4.6)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2204.07767/assets/x2.png" id="S3.F1.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="333" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F1.sf2.3.2" class="ltx_text" style="font-size:90%;">Fedavg (CNN4.6)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F1.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2204.07767/assets/x3.png" id="S3.F1.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="333" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S3.F1.sf3.3.2" class="ltx_text" style="font-size:90%;">Iteravg (Resnet50)</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F1.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2204.07767/assets/x4.png" id="S3.F1.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="333" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S3.F1.sf4.3.2" class="ltx_text" style="font-size:90%;">Fedavg (Resnet50)</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.2.1.1" class="ltx_text" style="font-size:90%;">Figure 1</span>: </span><span id="S3.F1.3.2" class="ltx_text" style="font-size:90%;">Average aggregation time comparison of Vanilla and Numba for smaller (CNN4.6) model and Resnet50 model</span></figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Experimental Setup</span>
</h3>

<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS1.5.1.1" class="ltx_text">III-A</span>1 </span><span id="S3.SS1.SSS1.6.2" class="ltx_text ltx_font_bold">Models</span>
</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.1" class="ltx_p">We experimented with various CNN models, including Resnet50 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="" class="ltx_ref">44</a>]</cite> and VGG16 <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib45" title="" class="ltx_ref">45</a>]</cite>, in different sizes listed in Table <a href="#S3.T1" title="TABLE I ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>, systematically increasing model sizes for comprehensive analysis, with model sizes comparable to <span id="S3.SS1.SSS1.p1.1.1" class="ltx_text ltx_font_bold">MobileNetV2 (4.2 MB)</span>, <span id="S3.SS1.SSS1.p1.1.2" class="ltx_text ltx_font_bold">ShuffleNetV2 (70 MB)</span>, <span id="S3.SS1.SSS1.p1.1.3" class="ltx_text ltx_font_bold">ResNet50 (224 MB)</span>, <span id="S3.SS1.SSS1.p1.1.4" class="ltx_text ltx_font_bold">InceptionV3 (450 MB)</span>, and <span id="S3.SS1.SSS1.p1.1.5" class="ltx_text ltx_font_bold">VGG19 (518 MB)</span>.</p>
</div>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS2.5.1.1" class="ltx_text">III-A</span>2 </span><span id="S3.SS1.SSS2.6.2" class="ltx_text ltx_font_bold">Client Emulator</span>
</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.1" class="ltx_p">The client emulator streamlines client simulation for researchers by simplifying technical intricacies. It comprises three stages, utilizing AWS S3: first, it sends an HTTP request to AWS S3 to move files from client to aggregator buckets, adjusting to regions and model quantities. Then, it uses monitoring to wait for the aggregated model in the aggregator’s bucket. Finally, it triggers multiple S3 requests to return the model to the clients’ bucket. Furthermore, the client emulator allows the simulation of user-defined randomized dropouts.</p>
</div>
</section>
<section id="S3.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS3.5.1.1" class="ltx_text">III-A</span>3 </span><span id="S3.SS1.SSS3.6.2" class="ltx_text ltx_font_bold">Testbed</span>
</h4>

<div id="S3.SS1.SSS3.p1" class="ltx_para">
<p id="S3.SS1.SSS3.p1.1" class="ltx_p"><span id="S3.SS1.SSS3.p1.1.1" class="ltx_text ltx_font_bold">Spark-based Methodology:</span>
We evaluated the Spark-based method using a Spark cluster with 256 cores and 452 GB of memory. Apache Spark <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> version 3.2.0 ran on Apache Hadoop Yarn <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib46" title="" class="ltx_ref">46</a>]</cite> version 3.2.2. Executors in Spark had a 35 GB memory limit. We used HDFS with 2.6 TB storage for model updates, and executor container specifications were adjusted based on workload.
<span id="S3.SS1.SSS3.p1.1.2" class="ltx_text ltx_font_bold">Serverless Methodology:</span>
For the Serverless method, we employed AWS Lambda with a 4 GB memory limit per function.
<span id="S3.SS1.SSS3.p1.1.3" class="ltx_text ltx_font_bold">Numba-based Methodology:</span>
To compare the Numba-based method, we used a containerized setup on a single node with 64 cores, 256 GB memory, and 10 Gbit/s network bandwidth. The client emulator from Section <a href="#S3.SS1.SSS2" title="III-A2 Client Emulator ‣ III-A Experimental Setup ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span>2</span></a> was used, with a five percent client sample in all experiments. Our analysis design was implemented in around 2K lines of Python code.</p>
</div>
</section>
<section id="S3.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS4.5.1.1" class="ltx_text">III-A</span>4 </span><span id="S3.SS1.SSS4.6.2" class="ltx_text ltx_font_bold">Metrics</span>
</h4>

<div id="S3.SS1.SSS4.p1" class="ltx_para">
<p id="S3.SS1.SSS4.p1.1" class="ltx_p">We assessed four key metrics to evaluate the efficiency of each methodology: <span id="S3.SS1.SSS4.p1.1.1" class="ltx_text" style="position:relative; bottom:0.5pt;">\raisebox{-.9pt} {1}⃝</span> Client sampling rate for aggregation per round (default at 5% of total clients), indicating scale achieved. <span id="S3.SS1.SSS4.p1.1.2" class="ltx_text" style="position:relative; bottom:0.5pt;">\raisebox{-.9pt} {2}⃝</span> Time for aggregation, assessing its efficiency. <span id="S3.SS1.SSS4.p1.1.3" class="ltx_text" style="position:relative; bottom:0.5pt;">\raisebox{-.9pt} {3}⃝</span> Aggregation cost, reflecting the value for money spent. <span id="S3.SS1.SSS4.p1.1.4" class="ltx_text" style="position:relative; bottom:0.5pt;">\raisebox{-.9pt} {4}⃝</span> Communication time, representing latency in model updates between clients. We also measured client write and read efficiency from the scalable storage used by the aggregator in our client emulator. These metrics collectively offer insights into the resource efficiency of each approach.</p>
</div>
</section>
<section id="S3.SS1.SSS5" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S3.SS1.SSS5.5.1.1" class="ltx_text">III-A</span>5 </span><span id="S3.SS1.SSS5.6.2" class="ltx_text ltx_font_bold">Fusion Algorithms</span>
</h4>

<div id="S3.SS1.SSS5.p1" class="ltx_para">
<p id="S3.SS1.SSS5.p1.4" class="ltx_p">We analyzed two fundamental averaging-based fusion algorithms: Federated averaging (FedAvg) and Iterative averaging (IterAvg) from Vanilla. These serve as the basis for various fusion methods, including ClippedAveraging, ConditionalThresholdAveraging (discussed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite>), and Gradient Aggregation algorithms (mentioned in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>). FedAvg, defined in Equation <a href="#S3.E1" title="In III-A5 Fusion Algorithms ‣ III-A Experimental Setup ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, employs client weights (<math id="S3.SS1.SSS5.p1.1.m1.1" class="ltx_Math" alttext="w_{i}" display="inline"><semantics id="S3.SS1.SSS5.p1.1.m1.1a"><msub id="S3.SS1.SSS5.p1.1.m1.1.1" xref="S3.SS1.SSS5.p1.1.m1.1.1.cmml"><mi id="S3.SS1.SSS5.p1.1.m1.1.1.2" xref="S3.SS1.SSS5.p1.1.m1.1.1.2.cmml">w</mi><mi id="S3.SS1.SSS5.p1.1.m1.1.1.3" xref="S3.SS1.SSS5.p1.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS5.p1.1.m1.1b"><apply id="S3.SS1.SSS5.p1.1.m1.1.1.cmml" xref="S3.SS1.SSS5.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS5.p1.1.m1.1.1.1.cmml" xref="S3.SS1.SSS5.p1.1.m1.1.1">subscript</csymbol><ci id="S3.SS1.SSS5.p1.1.m1.1.1.2.cmml" xref="S3.SS1.SSS5.p1.1.m1.1.1.2">𝑤</ci><ci id="S3.SS1.SSS5.p1.1.m1.1.1.3.cmml" xref="S3.SS1.SSS5.p1.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS5.p1.1.m1.1c">w_{i}</annotation></semantics></math>) with a total client count (<math id="S3.SS1.SSS5.p1.2.m2.1" class="ltx_Math" alttext="n_{total}" display="inline"><semantics id="S3.SS1.SSS5.p1.2.m2.1a"><msub id="S3.SS1.SSS5.p1.2.m2.1.1" xref="S3.SS1.SSS5.p1.2.m2.1.1.cmml"><mi id="S3.SS1.SSS5.p1.2.m2.1.1.2" xref="S3.SS1.SSS5.p1.2.m2.1.1.2.cmml">n</mi><mrow id="S3.SS1.SSS5.p1.2.m2.1.1.3" xref="S3.SS1.SSS5.p1.2.m2.1.1.3.cmml"><mi id="S3.SS1.SSS5.p1.2.m2.1.1.3.2" xref="S3.SS1.SSS5.p1.2.m2.1.1.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS5.p1.2.m2.1.1.3.1" xref="S3.SS1.SSS5.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS1.SSS5.p1.2.m2.1.1.3.3" xref="S3.SS1.SSS5.p1.2.m2.1.1.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS5.p1.2.m2.1.1.3.1a" xref="S3.SS1.SSS5.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS1.SSS5.p1.2.m2.1.1.3.4" xref="S3.SS1.SSS5.p1.2.m2.1.1.3.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS5.p1.2.m2.1.1.3.1b" xref="S3.SS1.SSS5.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS1.SSS5.p1.2.m2.1.1.3.5" xref="S3.SS1.SSS5.p1.2.m2.1.1.3.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.SS1.SSS5.p1.2.m2.1.1.3.1c" xref="S3.SS1.SSS5.p1.2.m2.1.1.3.1.cmml">​</mo><mi id="S3.SS1.SSS5.p1.2.m2.1.1.3.6" xref="S3.SS1.SSS5.p1.2.m2.1.1.3.6.cmml">l</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS5.p1.2.m2.1b"><apply id="S3.SS1.SSS5.p1.2.m2.1.1.cmml" xref="S3.SS1.SSS5.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS5.p1.2.m2.1.1.1.cmml" xref="S3.SS1.SSS5.p1.2.m2.1.1">subscript</csymbol><ci id="S3.SS1.SSS5.p1.2.m2.1.1.2.cmml" xref="S3.SS1.SSS5.p1.2.m2.1.1.2">𝑛</ci><apply id="S3.SS1.SSS5.p1.2.m2.1.1.3.cmml" xref="S3.SS1.SSS5.p1.2.m2.1.1.3"><times id="S3.SS1.SSS5.p1.2.m2.1.1.3.1.cmml" xref="S3.SS1.SSS5.p1.2.m2.1.1.3.1"></times><ci id="S3.SS1.SSS5.p1.2.m2.1.1.3.2.cmml" xref="S3.SS1.SSS5.p1.2.m2.1.1.3.2">𝑡</ci><ci id="S3.SS1.SSS5.p1.2.m2.1.1.3.3.cmml" xref="S3.SS1.SSS5.p1.2.m2.1.1.3.3">𝑜</ci><ci id="S3.SS1.SSS5.p1.2.m2.1.1.3.4.cmml" xref="S3.SS1.SSS5.p1.2.m2.1.1.3.4">𝑡</ci><ci id="S3.SS1.SSS5.p1.2.m2.1.1.3.5.cmml" xref="S3.SS1.SSS5.p1.2.m2.1.1.3.5">𝑎</ci><ci id="S3.SS1.SSS5.p1.2.m2.1.1.3.6.cmml" xref="S3.SS1.SSS5.p1.2.m2.1.1.3.6">𝑙</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS5.p1.2.m2.1c">n_{total}</annotation></semantics></math>) and a small <math id="S3.SS1.SSS5.p1.3.m3.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S3.SS1.SSS5.p1.3.m3.1a"><mi id="S3.SS1.SSS5.p1.3.m3.1.1" xref="S3.SS1.SSS5.p1.3.m3.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS5.p1.3.m3.1b"><ci id="S3.SS1.SSS5.p1.3.m3.1.1.cmml" xref="S3.SS1.SSS5.p1.3.m3.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS5.p1.3.m3.1c">\epsilon</annotation></semantics></math> value of <math id="S3.SS1.SSS5.p1.4.m4.1" class="ltx_Math" alttext="10^{-6}" display="inline"><semantics id="S3.SS1.SSS5.p1.4.m4.1a"><msup id="S3.SS1.SSS5.p1.4.m4.1.1" xref="S3.SS1.SSS5.p1.4.m4.1.1.cmml"><mn id="S3.SS1.SSS5.p1.4.m4.1.1.2" xref="S3.SS1.SSS5.p1.4.m4.1.1.2.cmml">10</mn><mrow id="S3.SS1.SSS5.p1.4.m4.1.1.3" xref="S3.SS1.SSS5.p1.4.m4.1.1.3.cmml"><mo id="S3.SS1.SSS5.p1.4.m4.1.1.3a" xref="S3.SS1.SSS5.p1.4.m4.1.1.3.cmml">−</mo><mn id="S3.SS1.SSS5.p1.4.m4.1.1.3.2" xref="S3.SS1.SSS5.p1.4.m4.1.1.3.2.cmml">6</mn></mrow></msup><annotation-xml encoding="MathML-Content" id="S3.SS1.SSS5.p1.4.m4.1b"><apply id="S3.SS1.SSS5.p1.4.m4.1.1.cmml" xref="S3.SS1.SSS5.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S3.SS1.SSS5.p1.4.m4.1.1.1.cmml" xref="S3.SS1.SSS5.p1.4.m4.1.1">superscript</csymbol><cn type="integer" id="S3.SS1.SSS5.p1.4.m4.1.1.2.cmml" xref="S3.SS1.SSS5.p1.4.m4.1.1.2">10</cn><apply id="S3.SS1.SSS5.p1.4.m4.1.1.3.cmml" xref="S3.SS1.SSS5.p1.4.m4.1.1.3"><minus id="S3.SS1.SSS5.p1.4.m4.1.1.3.1.cmml" xref="S3.SS1.SSS5.p1.4.m4.1.1.3"></minus><cn type="integer" id="S3.SS1.SSS5.p1.4.m4.1.1.3.2.cmml" xref="S3.SS1.SSS5.p1.4.m4.1.1.3.2">6</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS1.SSS5.p1.4.m4.1c">10^{-6}</annotation></semantics></math>. Additionally, we are exploring more advanced fusion techniques like Zeno <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib47" title="" class="ltx_ref">47</a>]</cite> and Coordinate-wise median <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>.</p>
</div>
<div id="S3.SS1.SSS5.p2" class="ltx_para">
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.1" class="ltx_Math" alttext="M=\sum_{i=1}^{n}w_{i}/(n_{total}+\epsilon)" display="block"><semantics id="S3.E1.m1.1a"><mrow id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml"><mi id="S3.E1.m1.1.1.3" xref="S3.E1.m1.1.1.3.cmml">M</mi><mo rspace="0.111em" id="S3.E1.m1.1.1.2" xref="S3.E1.m1.1.1.2.cmml">=</mo><mrow id="S3.E1.m1.1.1.1" xref="S3.E1.m1.1.1.1.cmml"><munderover id="S3.E1.m1.1.1.1.2" xref="S3.E1.m1.1.1.1.2.cmml"><mo movablelimits="false" id="S3.E1.m1.1.1.1.2.2.2" xref="S3.E1.m1.1.1.1.2.2.2.cmml">∑</mo><mrow id="S3.E1.m1.1.1.1.2.2.3" xref="S3.E1.m1.1.1.1.2.2.3.cmml"><mi id="S3.E1.m1.1.1.1.2.2.3.2" xref="S3.E1.m1.1.1.1.2.2.3.2.cmml">i</mi><mo id="S3.E1.m1.1.1.1.2.2.3.1" xref="S3.E1.m1.1.1.1.2.2.3.1.cmml">=</mo><mn id="S3.E1.m1.1.1.1.2.2.3.3" xref="S3.E1.m1.1.1.1.2.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.2.3.cmml">n</mi></munderover><mrow id="S3.E1.m1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.3.cmml"><mi id="S3.E1.m1.1.1.1.1.3.2" xref="S3.E1.m1.1.1.1.1.3.2.cmml">w</mi><mi id="S3.E1.m1.1.1.1.1.3.3" xref="S3.E1.m1.1.1.1.1.3.3.cmml">i</mi></msub><mo id="S3.E1.m1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.2.cmml">/</mo><mrow id="S3.E1.m1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml">(</mo><mrow id="S3.E1.m1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml"><msub id="S3.E1.m1.1.1.1.1.1.1.1.2" xref="S3.E1.m1.1.1.1.1.1.1.1.2.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.2.2" xref="S3.E1.m1.1.1.1.1.1.1.1.2.2.cmml">n</mi><mrow id="S3.E1.m1.1.1.1.1.1.1.1.2.3" xref="S3.E1.m1.1.1.1.1.1.1.1.2.3.cmml"><mi id="S3.E1.m1.1.1.1.1.1.1.1.2.3.2" xref="S3.E1.m1.1.1.1.1.1.1.1.2.3.2.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.1.1.1.2.3.1" xref="S3.E1.m1.1.1.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.1.1.1.2.3.3" xref="S3.E1.m1.1.1.1.1.1.1.1.2.3.3.cmml">o</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.1.1.1.2.3.1a" xref="S3.E1.m1.1.1.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.1.1.1.2.3.4" xref="S3.E1.m1.1.1.1.1.1.1.1.2.3.4.cmml">t</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.1.1.1.2.3.1b" xref="S3.E1.m1.1.1.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.1.1.1.2.3.5" xref="S3.E1.m1.1.1.1.1.1.1.1.2.3.5.cmml">a</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.1.1.1.1.1.1.1.2.3.1c" xref="S3.E1.m1.1.1.1.1.1.1.1.2.3.1.cmml">​</mo><mi id="S3.E1.m1.1.1.1.1.1.1.1.2.3.6" xref="S3.E1.m1.1.1.1.1.1.1.1.2.3.6.cmml">l</mi></mrow></msub><mo id="S3.E1.m1.1.1.1.1.1.1.1.1" xref="S3.E1.m1.1.1.1.1.1.1.1.1.cmml">+</mo><mi id="S3.E1.m1.1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.3.cmml">ϵ</mi></mrow><mo stretchy="false" id="S3.E1.m1.1.1.1.1.1.1.3" xref="S3.E1.m1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.1b"><apply id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1"><eq id="S3.E1.m1.1.1.2.cmml" xref="S3.E1.m1.1.1.2"></eq><ci id="S3.E1.m1.1.1.3.cmml" xref="S3.E1.m1.1.1.3">𝑀</ci><apply id="S3.E1.m1.1.1.1.cmml" xref="S3.E1.m1.1.1.1"><apply id="S3.E1.m1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.2">superscript</csymbol><apply id="S3.E1.m1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.2.2.1.cmml" xref="S3.E1.m1.1.1.1.2">subscript</csymbol><sum id="S3.E1.m1.1.1.1.2.2.2.cmml" xref="S3.E1.m1.1.1.1.2.2.2"></sum><apply id="S3.E1.m1.1.1.1.2.2.3.cmml" xref="S3.E1.m1.1.1.1.2.2.3"><eq id="S3.E1.m1.1.1.1.2.2.3.1.cmml" xref="S3.E1.m1.1.1.1.2.2.3.1"></eq><ci id="S3.E1.m1.1.1.1.2.2.3.2.cmml" xref="S3.E1.m1.1.1.1.2.2.3.2">𝑖</ci><cn type="integer" id="S3.E1.m1.1.1.1.2.2.3.3.cmml" xref="S3.E1.m1.1.1.1.2.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.2.3">𝑛</ci></apply><apply id="S3.E1.m1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1"><divide id="S3.E1.m1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.2"></divide><apply id="S3.E1.m1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.3"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.3.1.cmml" xref="S3.E1.m1.1.1.1.1.3">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.3.2.cmml" xref="S3.E1.m1.1.1.1.1.3.2">𝑤</ci><ci id="S3.E1.m1.1.1.1.1.3.3.cmml" xref="S3.E1.m1.1.1.1.1.3.3">𝑖</ci></apply><apply id="S3.E1.m1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1"><plus id="S3.E1.m1.1.1.1.1.1.1.1.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.1"></plus><apply id="S3.E1.m1.1.1.1.1.1.1.1.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2"><csymbol cd="ambiguous" id="S3.E1.m1.1.1.1.1.1.1.1.2.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2">subscript</csymbol><ci id="S3.E1.m1.1.1.1.1.1.1.1.2.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2.2">𝑛</ci><apply id="S3.E1.m1.1.1.1.1.1.1.1.2.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2.3"><times id="S3.E1.m1.1.1.1.1.1.1.1.2.3.1.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2.3.1"></times><ci id="S3.E1.m1.1.1.1.1.1.1.1.2.3.2.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2.3.2">𝑡</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.2.3.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2.3.3">𝑜</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.2.3.4.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2.3.4">𝑡</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.2.3.5.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2.3.5">𝑎</ci><ci id="S3.E1.m1.1.1.1.1.1.1.1.2.3.6.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.2.3.6">𝑙</ci></apply></apply><ci id="S3.E1.m1.1.1.1.1.1.1.1.3.cmml" xref="S3.E1.m1.1.1.1.1.1.1.1.3">italic-ϵ</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.1c">M=\sum_{i=1}^{n}w_{i}/(n_{total}+\epsilon)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Multi-core Aggregation</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">Our FL aggregation was optimized by switching from Numpy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="" class="ltx_ref">48</a>]</cite> to Numba <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="" class="ltx_ref">49</a>]</cite>, enhancing parallel processing. This change, implemented in IBMFL’s FedAvg and IterAvg classes, retained the original communication and client training functions. It enabled storing client updates in the aggregator’s memory for quicker, more efficient aggregation, especially beneficial for IoT applications with simpler models. This transition to Numba required only minor code modifications within the FL framework.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.2" class="ltx_p">To answer question <span id="S3.SS2.p2.2.1" class="ltx_text" style="position:relative; bottom:0.5pt;">\raisebox{-.9pt} {1}⃝</span> in section <a href="#S2" title="II Background &amp; Motivation ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>, we created micro-benchmarks to analyze the Numba-based aggregation method compared to the Vanilla implementations of FedAvg and IterAvg algorithms. Figures <a href="#S3.F1.sf3" title="In Figure 1 ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(c)</span></a> and <a href="#S3.F1.sf4" title="In Figure 1 ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(d)</span></a> show the aggregation time comparison for the Resnet50 model. For Fedavg, we observed a <math id="S3.SS2.p2.1.m1.1" class="ltx_Math" alttext="40.44\%" display="inline"><semantics id="S3.SS2.p2.1.m1.1a"><mrow id="S3.SS2.p2.1.m1.1.1" xref="S3.SS2.p2.1.m1.1.1.cmml"><mn id="S3.SS2.p2.1.m1.1.1.2" xref="S3.SS2.p2.1.m1.1.1.2.cmml">40.44</mn><mo id="S3.SS2.p2.1.m1.1.1.1" xref="S3.SS2.p2.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.1.m1.1b"><apply id="S3.SS2.p2.1.m1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1"><csymbol cd="latexml" id="S3.SS2.p2.1.m1.1.1.1.cmml" xref="S3.SS2.p2.1.m1.1.1.1">percent</csymbol><cn type="float" id="S3.SS2.p2.1.m1.1.1.2.cmml" xref="S3.SS2.p2.1.m1.1.1.2">40.44</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.1.m1.1c">40.44\%</annotation></semantics></math> reduction in execution time using the Numba-based method with 1.8k clients. However, due to fixed single-node memory, the number of clients supported by Resnet50 is lower compared to a smaller model like CNN4.6, which is why the Numba-based method performs similarly to Vanilla for the Resnet50 model. With higher participation, the Numba-based method can parallelize computations and improve time efficiency. This is evident in Figures <a href="#S3.F1.sf1" title="In Figure 1 ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(a)</span></a> and <a href="#S3.F1.sf2" title="In Figure 1 ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1(b)</span></a> for the CNN4.6 model, where the Numba-based method reduced aggregation time by <math id="S3.SS2.p2.2.m2.1" class="ltx_Math" alttext="56.85\%" display="inline"><semantics id="S3.SS2.p2.2.m2.1a"><mrow id="S3.SS2.p2.2.m2.1.1" xref="S3.SS2.p2.2.m2.1.1.cmml"><mn id="S3.SS2.p2.2.m2.1.1.2" xref="S3.SS2.p2.2.m2.1.1.2.cmml">56.85</mn><mo id="S3.SS2.p2.2.m2.1.1.1" xref="S3.SS2.p2.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS2.p2.2.m2.1b"><apply id="S3.SS2.p2.2.m2.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1"><csymbol cd="latexml" id="S3.SS2.p2.2.m2.1.1.1.cmml" xref="S3.SS2.p2.2.m2.1.1.1">percent</csymbol><cn type="float" id="S3.SS2.p2.2.m2.1.1.2.cmml" xref="S3.SS2.p2.2.m2.1.1.2">56.85</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS2.p2.2.m2.1c">56.85\%</annotation></semantics></math>. Moreover, the efficiency of the Numba-based method depends on the fusion algorithm used. Numba parallelizes loops to compute weighted averages in Fedavg, resulting in greater efficiency, while simpler calculation in Iteravg means fewer efficiency gains from parallel computation.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">In summary, the Numba-based method outperforms IBMFL and other FL frameworks that use the Numpy library for implementing fusion algorithms when client participation rates increase. It is also more resource-efficient as it utilizes all available cores to maintain efficiency reducing resource idling. However, for a smaller number of clients, parallel processing is less beneficial. These insights can be extended to other frameworks such as TensorFlow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, Microsoft FLUTE <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, and FLOWER <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib50" title="" class="ltx_ref">50</a>]</cite>. This analysis also suggests that multiple resources (CPU, Memory) act as bottlenecks during aggregation. We also note that when we move from IterAvg to FedAvg, which is a slightly more complex algorithm, the CPU becomes a bottleneck. We conclude that the <span id="S3.SS2.p3.1.1" class="ltx_text ltx_font_bold">CPU bottleneck is directly related to the complexity of the algorithm</span>, and as we move to more complex algorithms, the bottleneck induced by CPU resources will increase, answering question <span id="S3.SS2.p3.1.2" class="ltx_text" style="position:relative; bottom:0.5pt;">\raisebox{-.9pt} {3}⃝</span> raised in section <a href="#S2" title="II Background &amp; Motivation ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>. Considering this result, we argue that <span id="S3.SS2.p3.1.3" class="ltx_text ltx_font_bold">specialized hardware (GPU)</span> as a solution cannot fully resolve multiple bottlenecks and can be expensive. This motivates us to explore and analyze further aggregation methodologies that can be used for larger workloads using CPU.</p>
</div>
<figure id="S3.F2" class="ltx_figure">
<p id="S3.F2.1" class="ltx_p ltx_align_center ltx_align_center"><span id="S3.F2.1.1" class="ltx_text"><img src="/html/2204.07767/assets/x5.png" id="S3.F2.1.1.g1" class="ltx_graphics ltx_img_landscape" width="410" height="98" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F2.3.1.1" class="ltx_text" style="font-size:90%;">Figure 2</span>: </span><span id="S3.F2.4.2" class="ltx_text" style="font-size:90%;">Multi-node module design</span></figcaption>
</figure>
<figure id="S3.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2204.07767/assets/x6.png" id="S3.F3.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="322" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F3.sf1.3.2" class="ltx_text" style="font-size:90%;">Fedavg</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2204.07767/assets/x7.png" id="S3.F3.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="322" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F3.sf2.3.2" class="ltx_text" style="font-size:90%;">Iteravg</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F3.2.1.1" class="ltx_text" style="font-size:90%;">Figure 3</span>: </span><span id="S3.F3.3.2" class="ltx_text" style="font-size:90%;">Average aggregation time comparison of the Spark method with Fedavg and Iteravg on the CNN4.6 model</span></figcaption>
</figure>
<figure id="S3.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2204.07767/assets/x8.png" id="S3.F4.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="335" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F4.sf1.3.2" class="ltx_text" style="font-size:90%;">CNN4.6</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2204.07767/assets/x9.png" id="S3.F4.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="335" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F4.sf2.3.2" class="ltx_text" style="font-size:90%;">CNN73</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F4.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2204.07767/assets/x10.png" id="S3.F4.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="335" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S3.F4.sf3.3.2" class="ltx_text" style="font-size:90%;">CNN179</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F4.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2204.07767/assets/x11.png" id="S3.F4.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="335" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S3.F4.sf4.3.2" class="ltx_text" style="font-size:90%;">Resnet50</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F4.2.1.1" class="ltx_text" style="font-size:90%;">Figure 4</span>: </span><span id="S3.F4.3.2" class="ltx_text" style="font-size:90%;">Average aggregation time comparison for Vanilla and Spark-based method for FedAvg with model compression</span></figcaption>
</figure>
<figure id="S3.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2204.07767/assets/x12.png" id="S3.F5.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="335" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F5.sf1.3.2" class="ltx_text" style="font-size:90%;">CNN4.6</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2204.07767/assets/x13.png" id="S3.F5.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="335" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F5.sf2.3.2" class="ltx_text" style="font-size:90%;">CNN73</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F5.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2204.07767/assets/x14.png" id="S3.F5.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="335" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S3.F5.sf3.3.2" class="ltx_text" style="font-size:90%;">CNN179</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F5.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2204.07767/assets/x15.png" id="S3.F5.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="335" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S3.F5.sf4.3.2" class="ltx_text" style="font-size:90%;">Resnet50</span></figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F5.sf5" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2204.07767/assets/x16.png" id="S3.F5.sf5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="335" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.sf5.2.1.1" class="ltx_text" style="font-size:90%;">(e)</span> </span><span id="S3.F5.sf5.3.2" class="ltx_text" style="font-size:90%;">CNN239</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F5.2.1.1" class="ltx_text" style="font-size:90%;">Figure 5</span>: </span><span id="S3.F5.3.2" class="ltx_text" style="font-size:90%;">Average aggregation time comparison for Vanilla and Spark-based method using for IterAvg with model compression</span></figcaption>
</figure>
<figure id="S3.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F6.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2204.07767/assets/x17.png" id="S3.F6.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="335" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F6.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F6.sf1.3.2" class="ltx_text" style="font-size:90%;">CNN4.6</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F6.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2204.07767/assets/x18.png" id="S3.F6.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="335" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F6.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F6.sf2.3.2" class="ltx_text" style="font-size:90%;">CNN73</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F6.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2204.07767/assets/x19.png" id="S3.F6.sf3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="335" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F6.sf3.2.1.1" class="ltx_text" style="font-size:90%;">(c)</span> </span><span id="S3.F6.sf3.3.2" class="ltx_text" style="font-size:90%;">CNN179</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_4">
<figure id="S3.F6.sf4" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2204.07767/assets/x20.png" id="S3.F6.sf4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="335" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F6.sf4.2.1.1" class="ltx_text" style="font-size:90%;">(d)</span> </span><span id="S3.F6.sf4.3.2" class="ltx_text" style="font-size:90%;">CNN239</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F6.2.1.1" class="ltx_text" style="font-size:90%;">Figure 6</span>: </span><span id="S3.F6.3.2" class="ltx_text" style="font-size:90%;">Average aggregation time comparison for Vanilla and Spark-based method for FedAvg without model compression</span></figcaption>
</figure>
<figure id="S3.F7" class="ltx_figure">
<p id="S3.F7.1" class="ltx_p ltx_align_center ltx_align_center"><span id="S3.F7.1.1" class="ltx_text"><img src="/html/2204.07767/assets/x21.png" id="S3.F7.1.1.g1" class="ltx_graphics ltx_img_landscape" width="230" height="161" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F7.3.1.1" class="ltx_text" style="font-size:90%;">Figure 7</span>: </span><span id="S3.F7.4.2" class="ltx_text" style="font-size:90%;">Average aggregation time for Spark with FedAvg on CNN4.6 model with and without model compression</span></figcaption>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Spark-based Multi-node Aggregation</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">The Spark-based aggregator in the adaptive aggregation methodology, shown in Figure <a href="#S3.F2" title="Figure 2 ‣ III-B Multi-core Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, includes a scalable storage monitor. This monitor activates Spark for aggregation after a timeout or a set number of client updates. The threshold is adjustable to mitigate stragglers. This lightweight monitor runs efficiently as a single-threaded process.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">The Spark module performs aggregation in the following steps: ➊ After each training round, client-sent model updates are stored in Hadoop Distributed File System (HDFS) using the webHDFS Rest API. ➋ The monitor waits for a threshold to be reached and triggers the Spark cluster module to initiate aggregation. ➌ Spark partitions the data and employs the binary files method to read data as bytes in executor containers. The map function converts RDD bytes into RDDs of the Numpy object type. ➍ Lastly, Spark MapReduce processes RDDs, applies the fusion algorithm, and stores updated model weights in HDFS for client access via the WebHDFS API.</p>
</div>
<div id="S3.SS3.p3" class="ltx_para">
<p id="S3.SS3.p3.1" class="ltx_p">In a detailed experiment, we tested the Spark-based method with an increasing number of clients using the FedAvg algorithm and the CNN4.6 model. The results in Figure <a href="#S3.F3.sf1" title="In Figure 3 ‣ III-B Multi-core Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">3(a)</span></a> show ”MapReduce Time” as the time for weighted averaging of partitions by this method. We used a ”lazy read” approach for efficiency, reading only the partition in use. Smaller models were cached, with most RDDs of model weights cached on worker nodes until the reduction step. However, caching was less effective for larger models due to memory constraints.</p>
</div>
<div id="S3.SS3.p4" class="ltx_para ltx_noindent">
<svg id="S3.SS3.p4.pic1" class="ltx_picture" height="73.92" overflow="visible" version="1.1" width="600"><g transform="translate(0,73.92) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 68.02 C 0 71.28 2.64 73.92 5.91 73.92 L 594.09 73.92 C 597.36 73.92 600 71.28 600 68.02 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 68.02 C 1.97 70.19 3.73 71.96 5.91 71.96 L 594.09 71.96 C 596.27 71.96 598.03 70.19 598.03 68.02 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 5.91 5.91)"><foreignObject width="588.19" height="62.11" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S3.SS3.p4.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:425.1pt;">
<span id="S3.SS3.p4.pic1.1.1.1.1.1.1" class="ltx_p">IoT and Edge devices have limited network resources <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>, <a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>. Compression techniques can affect computation cost, scalability, and aggregator efficiency. In Figure <a href="#S3.F4" title="Figure 4 ‣ III-B Multi-core Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>, multi-node approaches prove more effective for aggregating compressed models in IoT and Edge FL, reducing compute cost, network usage, and aggregation time for clients.</span>
</span></foreignObject></g></g></svg>
</div>
<div id="S3.SS3.p5" class="ltx_para">
<p id="S3.SS3.p5.3" class="ltx_p">Figure <a href="#S3.F3" title="Figure 3 ‣ III-B Multi-core Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> displays the total time required for the Iteravg method, which involves only two simple steps of sum and division for a mean calculation. The number of clients selected per training round was increased iteratively up to 100k in Figure <a href="#S3.F3" title="Figure 3 ‣ III-B Multi-core Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Both FedAvg and Iteravg displayed a linear trend in the time required to aggregate, and no limitations were observed in their ability to scale horizontally using this Spark-based method. The number of clients supported per training round increased by <math id="S3.SS3.p5.1.m1.1" class="ltx_Math" alttext="429.1\%" display="inline"><semantics id="S3.SS3.p5.1.m1.1a"><mrow id="S3.SS3.p5.1.m1.1.1" xref="S3.SS3.p5.1.m1.1.1.cmml"><mn id="S3.SS3.p5.1.m1.1.1.2" xref="S3.SS3.p5.1.m1.1.1.2.cmml">429.1</mn><mo id="S3.SS3.p5.1.m1.1.1.1" xref="S3.SS3.p5.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.1.m1.1b"><apply id="S3.SS3.p5.1.m1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1"><csymbol cd="latexml" id="S3.SS3.p5.1.m1.1.1.1.cmml" xref="S3.SS3.p5.1.m1.1.1.1">percent</csymbol><cn type="float" id="S3.SS3.p5.1.m1.1.1.2.cmml" xref="S3.SS3.p5.1.m1.1.1.2">429.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.1.m1.1c">429.1\%</annotation></semantics></math> for FedAvg and <math id="S3.SS3.p5.2.m2.1" class="ltx_Math" alttext="207.7\%" display="inline"><semantics id="S3.SS3.p5.2.m2.1a"><mrow id="S3.SS3.p5.2.m2.1.1" xref="S3.SS3.p5.2.m2.1.1.cmml"><mn id="S3.SS3.p5.2.m2.1.1.2" xref="S3.SS3.p5.2.m2.1.1.2.cmml">207.7</mn><mo id="S3.SS3.p5.2.m2.1.1.1" xref="S3.SS3.p5.2.m2.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.2.m2.1b"><apply id="S3.SS3.p5.2.m2.1.1.cmml" xref="S3.SS3.p5.2.m2.1.1"><csymbol cd="latexml" id="S3.SS3.p5.2.m2.1.1.1.cmml" xref="S3.SS3.p5.2.m2.1.1.1">percent</csymbol><cn type="float" id="S3.SS3.p5.2.m2.1.1.2.cmml" xref="S3.SS3.p5.2.m2.1.1.2">207.7</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.2.m2.1c">207.7\%</annotation></semantics></math> for Iteravg compared to Vanilla. It is important to note that the figure only shows up to 100k clients, but the adaptive method which includes the Spark-based method has the potential to scale for even more clients and 100k represents only <math id="S3.SS3.p5.3.m3.1" class="ltx_Math" alttext="5\%" display="inline"><semantics id="S3.SS3.p5.3.m3.1a"><mrow id="S3.SS3.p5.3.m3.1.1" xref="S3.SS3.p5.3.m3.1.1.cmml"><mn id="S3.SS3.p5.3.m3.1.1.2" xref="S3.SS3.p5.3.m3.1.1.2.cmml">5</mn><mo id="S3.SS3.p5.3.m3.1.1.1" xref="S3.SS3.p5.3.m3.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS3.p5.3.m3.1b"><apply id="S3.SS3.p5.3.m3.1.1.cmml" xref="S3.SS3.p5.3.m3.1.1"><csymbol cd="latexml" id="S3.SS3.p5.3.m3.1.1.1.cmml" xref="S3.SS3.p5.3.m3.1.1.1">percent</csymbol><cn type="integer" id="S3.SS3.p5.3.m3.1.1.2.cmml" xref="S3.SS3.p5.3.m3.1.1.2">5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS3.p5.3.m3.1c">5\%</annotation></semantics></math> of the clients that are selected from the total available clients per round for aggregation which means the total clients can be as much as 2 million. This analysis provides an answer to the scalability question <span id="S3.SS3.p5.3.1" class="ltx_text" style="position:relative; bottom:0.5pt;">\raisebox{-.9pt} {2}⃝</span> (raised in section <a href="#S2" title="II Background &amp; Motivation ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>). Although Spark showed scalability, a detailed analysis of its resource efficiency and costs is necessary to examine its practicality for the edge aggregator, which is performed in section <a href="#S4" title="IV Adaptive Aggregator ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>.</p>
</div>
<figure id="S3.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F8.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2204.07767/assets/x22.png" id="S3.F8.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="322" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F8.sf1.2.1.1" class="ltx_text" style="font-size:90%;">(a)</span> </span><span id="S3.F8.sf1.3.2" class="ltx_text" style="font-size:90%;">Fedavg</span></figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S3.F8.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2204.07767/assets/x23.png" id="S3.F8.sf2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="461" height="322" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F8.sf2.2.1.1" class="ltx_text" style="font-size:90%;">(b)</span> </span><span id="S3.F8.sf2.3.2" class="ltx_text" style="font-size:90%;">Iteravg</span></figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F8.2.1.1" class="ltx_text" style="font-size:90%;">Figure 8</span>: </span><span id="S3.F8.3.2" class="ltx_text" style="font-size:90%;">Average aggregation time for Fedavg and Iteravg algorithms on varying model sizes with Spark</span></figcaption>
</figure>
<div id="S3.SS3.p6" class="ltx_para">
<p id="S3.SS3.p6.1" class="ltx_p">We also evaluated various benchmark models that use compressed model updates, which is a technique commonly used to reduce communication costs at edge data centers and IoT devices with limited network bandwidth <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>. The evaluation results are presented in Figures <a href="#S3.F4" title="Figure 4 ‣ III-B Multi-core Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and <a href="#S3.F5" title="Figure 5 ‣ III-B Multi-core Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. The Spark-based method was found to be the most time-efficient when there was a large number of clients, as shown in Figures <a href="#S3.F4.sf1" title="In Figure 4 ‣ III-B Multi-core Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(a)</span></a> and <a href="#S3.F5.sf1" title="In Figure 5 ‣ III-B Multi-core Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(a)</span></a>. This is because Spark enables parallel tasks to be executed across multiple executors, thereby increasing the efficiency with higher client participation. To ensure unbiased results, we also conducted the same evaluation without compression. The results, as illustrated in Figure <a href="#S3.F6" title="Figure 6 ‣ III-B Multi-core Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, exhibit a similar trend. However, the time efficiency gain is more significant compared to Vanilla with compression in Figure <a href="#S3.F4" title="Figure 4 ‣ III-B Multi-core Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure id="S3.F9" class="ltx_figure">
<p id="S3.F9.1" class="ltx_p ltx_align_center ltx_align_center"><span id="S3.F9.1.1" class="ltx_text"><img src="/html/2204.07767/assets/x24.png" id="S3.F9.1.1.g1" class="ltx_graphics ltx_img_landscape" width="461" height="184" alt="Refer to caption"></span></p>
<br class="ltx_break ltx_break">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F9.3.1.1" class="ltx_text" style="font-size:90%;">Figure 9</span>: </span><span id="S3.F9.4.2" class="ltx_text" style="font-size:90%;">Average aggregation time of Vanilla with varying models &amp; compression under 170 GB total available memory</span></figcaption>
</figure>
<div id="S3.SS3.p7" class="ltx_para">
<p id="S3.SS3.p7.1" class="ltx_p">In the Spark-based method, the workload is split into multiple workers with separate system resources, reducing the latency involved in the decompression phase as each worker only has to decompress a portion of the total compressed workload. This is more clearly demonstrated in Figure <a href="#S3.F7" title="Figure 7 ‣ III-B Multi-core Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, where the aggregation latency is similar with or without compressed model updates. In the Vanilla method, decompression with multi-threading is still slow due to the limited memory and CPU resources. This is further evidenced by the Vanilla latency difference between Figures <a href="#S3.F4.sf1" title="In Figure 4 ‣ III-B Multi-core Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(a)</span></a> and <a href="#S3.F6.sf1" title="In Figure 6 ‣ III-B Multi-core Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a>.</p>
</div>
<div id="S3.SS3.p8" class="ltx_para">
<p id="S3.SS3.p8.1" class="ltx_p">In summary, while compression increases latency and memory use, thus limiting scalability with Vanilla and Numba methods, it boosts efficiency and scalability with Spark due to its parallel task handling and workload distribution abilities. This makes the Spark-based method more resource-efficient at scale, reducing communication costs at the edge aggregator and maintaining time efficiency.</p>
</div>
<div id="S3.SS3.p9" class="ltx_para ltx_noindent">
<svg id="S3.SS3.p9.pic1" class="ltx_picture" height="73.92" overflow="visible" version="1.1" width="600"><g transform="translate(0,73.92) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 68.02 C 0 71.28 2.64 73.92 5.91 73.92 L 594.09 73.92 C 597.36 73.92 600 71.28 600 68.02 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 68.02 C 1.97 70.19 3.73 71.96 5.91 71.96 L 594.09 71.96 C 596.27 71.96 598.03 70.19 598.03 68.02 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 5.91 5.91)"><foreignObject width="588.19" height="62.11" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S3.SS3.p9.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:425.1pt;">
<span id="S3.SS3.p9.pic1.1.1.1.1.1.1" class="ltx_p">Figure <a href="#S3.F6" title="Figure 6 ‣ III-B Multi-core Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows that Spark works better for heavy models and high client participation surpassing the I/O cost, while Numba is more efficient and cost-effective for lighter models and low participation rates (Sections <a href="#S3" title="III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> and <a href="#S4.SS1.SSS2" title="IV-A2 Multi-core in Adaptive Aggregator ‣ IV-A Cost-benefit Study with Adaptive Method ‣ IV Adaptive Aggregator ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">IV-A</span>2</span></a>). Thus, an adaptive aggregator is crucial to choose the right method based on IoT and Edge workload and participation rates, ensuring cost-effectiveness.</span>
</span></foreignObject></g></g></svg>
</div>
<div id="S3.SS3.p10" class="ltx_para">
<p id="S3.SS3.p10.1" class="ltx_p">The analysis is extended with compression for different models and increasing numbers of clients in Figure <a href="#S3.F8" title="Figure 8 ‣ III-C Spark-based Multi-node Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. For Fedavg, the Spark-based method shows a 3X increase in scalability compared to Vanilla. For the CNN73 model, the Spark-based method shown in Figure <a href="#S3.F8.sf1" title="In Figure 8 ‣ III-C Spark-based Multi-node Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(a)</span></a> can scale to more than 2.1k clients while Vanilla in Figure <a href="#S3.F9" title="Figure 9 ‣ III-C Spark-based Multi-node Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a> only scales to 700 clients under the same evaluation settings described in section <a href="#S3.SS1.SSS3" title="III-A3 Testbed ‣ III-A Experimental Setup ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span>3</span></a>. Similarly, IterAvg in Figure <a href="#S3.F8.sf2" title="In Figure 8 ‣ III-C Spark-based Multi-node Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">8(b)</span></a> also shows a 3X improvement in scalability compared to Vanilla in Figure <a href="#S3.F9" title="Figure 9 ‣ III-C Spark-based Multi-node Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS4.5.1.1" class="ltx_text">III-D</span> </span><span id="S3.SS4.6.2" class="ltx_text ltx_font_italic">Serverless-based Multi-node Aggregation</span>
</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">The Serverless method uses the tree-reduce principle and the monitor shown in Figure <a href="#S3.F2" title="Figure 2 ‣ III-B Multi-core Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> to control the multi-level reduction of updates. At each reduction step, the monitor launches multiple Lambda functions concurrently, with the number of updates handled per function dynamically calculated to ensure the memory per function is a maximum of 4 GB. More functions are launched for horizontal scaling to handle additional clients. The Lambda functions take input from the scalable storage used by the Spark module, and the intermediate and final updates are stored in the same scalable storage. In step ➌, the monitor sends AWS Simple Notification Service (SNS) messages to launch Lambda functions for aggregation. Users can adjust the number of Lambda functions and memory limits for each function to optimize efficiency and cost.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para ltx_noindent">
<svg id="S3.SS4.p2.pic1" class="ltx_picture" height="73.92" overflow="visible" version="1.1" width="600"><g transform="translate(0,73.92) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 68.02 C 0 71.28 2.64 73.92 5.91 73.92 L 594.09 73.92 C 597.36 73.92 600 71.28 600 68.02 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 68.02 C 1.97 70.19 3.73 71.96 5.91 71.96 L 594.09 71.96 C 596.27 71.96 598.03 70.19 598.03 68.02 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 5.91 5.91)"><foreignObject width="588.19" height="62.11" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S3.SS4.p2.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:425.1pt;">
<span id="S3.SS4.p2.pic1.1.1.1.1.1.1" class="ltx_p">Tree-reduce algorithm efficiently distributes workloads in multi-node settings, as demonstrated in Figures  <a href="#S3.F4.sf1" title="In Figure 4 ‣ III-B Multi-core Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">4(a)</span></a>,  <a href="#S3.F5.sf1" title="In Figure 5 ‣ III-B Multi-core Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">5(a)</span></a>, and  <a href="#S3.F6.sf1" title="In Figure 6 ‣ III-B Multi-core Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">6(a)</span></a>. This makes multi-core and multi-node aggregator architectures more suitable for Edge and IoT FL applications than Vanilla and other frameworks due to their ability to process workloads in parallel.</span>
</span></foreignObject></g></g></svg>
</div>
<div id="S3.SS4.p3" class="ltx_para ltx_noindent">
<svg id="S3.SS4.p3.pic1" class="ltx_picture" height="75.46" overflow="visible" version="1.1" width="600"><g transform="translate(0,75.46) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 69.56 C 0 72.82 2.64 75.46 5.91 75.46 L 594.09 75.46 C 597.36 75.46 600 72.82 600 69.56 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 69.56 C 1.97 71.73 3.73 73.49 5.91 73.49 L 594.09 73.49 C 596.27 73.49 598.03 71.73 598.03 69.56 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 5.91 5.91)"><foreignObject width="588.19" height="63.65" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S3.SS4.p3.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:425.1pt;">
<span id="S3.SS4.p3.pic1.1.1.1.1.1.1" class="ltx_p">For complex workloads in IoT and edge FL applications, Spark excels in efficiency over Serverless, while Serverless is more economical and quicker for simpler models due to reduced per-function costs. Thus, in general, Spark is better for heavier models <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib51" title="" class="ltx_ref">51</a>]</cite>, and Serverless for lighter ones <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
</span>
</span></foreignObject></g></g></svg>
</div>
<div id="S3.SS4.p4" class="ltx_para">
<p id="S3.SS4.p4.1" class="ltx_p">Experimental analysis shows in Figures <a href="#S3.F11" title="Figure 11 ‣ III-D Serverless-based Multi-node Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> and <a href="#S3.F11" title="Figure 11 ‣ III-D Serverless-based Multi-node Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> that the Serverless method is more efficient and less costly than the Spark-based method for lighter models, but more costly than the Numba-based method when the participation rate of clients is low. Compared to Spark, the Serverless method improves the aggregation efficiency by up to <math id="S3.SS4.p4.1.m1.1" class="ltx_Math" alttext="87\%" display="inline"><semantics id="S3.SS4.p4.1.m1.1a"><mrow id="S3.SS4.p4.1.m1.1.1" xref="S3.SS4.p4.1.m1.1.1.cmml"><mn id="S3.SS4.p4.1.m1.1.1.2" xref="S3.SS4.p4.1.m1.1.1.2.cmml">87</mn><mo id="S3.SS4.p4.1.m1.1.1.1" xref="S3.SS4.p4.1.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.SS4.p4.1.m1.1b"><apply id="S3.SS4.p4.1.m1.1.1.cmml" xref="S3.SS4.p4.1.m1.1.1"><csymbol cd="latexml" id="S3.SS4.p4.1.m1.1.1.1.cmml" xref="S3.SS4.p4.1.m1.1.1.1">percent</csymbol><cn type="integer" id="S3.SS4.p4.1.m1.1.1.2.cmml" xref="S3.SS4.p4.1.m1.1.1.2">87</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.SS4.p4.1.m1.1c">87\%</annotation></semantics></math> for both FedAvg and IterAvg. This analysis emphasizes the need for an adaptive aggregator, as the Serverless method becomes cost-effective for lighter workloads and can handle unpredictable participation rates of IoT devices, but becomes more costly when the participation rates are lower or the aggregator is dealing with heavier models. The next section provides a more detailed analysis of the Serverless method.</p>
</div>
<figure id="S3.F10" class="ltx_figure">
<p id="S3.F10.1" class="ltx_p ltx_align_center ltx_align_center"><span id="S3.F10.1.1" class="ltx_text"><img src="/html/2204.07767/assets/x25.png" id="S3.F10.1.1.g1" class="ltx_graphics ltx_img_landscape" width="368" height="116" alt="Refer to caption"></span></p>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F10.3.1.1" class="ltx_text" style="font-size:90%;">Figure 10</span>: </span><span id="S3.F10.4.2" class="ltx_text" style="font-size:90%;">Adaptive Aggregator Design</span></figcaption>
</figure>
<figure id="S3.F11" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F11.1" class="ltx_figure ltx_figure_panel">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2204.07767/assets/Figures/pyspark_lambda_adaptive_fedavg_comparison_no_compression_diff_models_one_technique.png" id="S3.F11.1.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="598" height="180" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S3.F11.1.1" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\phantomcaption</span></div>
</div>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S3.F11.2" class="ltx_figure ltx_figure_panel">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1"><img src="/html/2204.07767/assets/Figures/pyspark_lambda_adaptive_iteravg_comparison_no_compression_diff_models_one_technique.png" id="S3.F11.2.g1" class="ltx_graphics ltx_figure_panel ltx_img_landscape" width="598" height="180" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1"><span id="S3.F11.2.1" class="ltx_ERROR ltx_centering ltx_figure_panel undefined">\phantomcaption</span></div>
</div>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S3.F11.4.1.1" class="ltx_text" style="font-size:90%;">Figure 11</span>: </span><span id="S3.F11.5.2" class="ltx_text" style="font-size:90%;">Comparison of different methodologies for FedAvg (top) and IterAvg (bottom) without compression.</span></figcaption>
</figure>
<figure id="alg1" class="ltx_float ltx_algorithm">
<div id="alg1.27" class="ltx_listing ltx_lst_numbers_left ltx_listing">
<div id="alg1.27.28" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">1</span>




</div>
<div id="alg1.9.9" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">2</span><span id="alg1.1.1.1" class="ltx_text ltx_font_bold">Input: <math id="alg1.1.1.1.m1.1" class="ltx_Math" alttext="S_{T}" display="inline"><semantics id="alg1.1.1.1.m1.1a"><msub id="alg1.1.1.1.m1.1.1" xref="alg1.1.1.1.m1.1.1.cmml"><mi id="alg1.1.1.1.m1.1.1.2" xref="alg1.1.1.1.m1.1.1.2.cmml">S</mi><mi id="alg1.1.1.1.m1.1.1.3" xref="alg1.1.1.1.m1.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.1.1.1.m1.1b"><apply id="alg1.1.1.1.m1.1.1.cmml" xref="alg1.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="alg1.1.1.1.m1.1.1.1.cmml" xref="alg1.1.1.1.m1.1.1">subscript</csymbol><ci id="alg1.1.1.1.m1.1.1.2.cmml" xref="alg1.1.1.1.m1.1.1.2">𝑆</ci><ci id="alg1.1.1.1.m1.1.1.3.cmml" xref="alg1.1.1.1.m1.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.1.1.1.m1.1c">S_{T}</annotation></semantics></math></span>: Task-specific information, <math id="alg1.2.2.m1.1" class="ltx_Math" alttext="S_{R}" display="inline"><semantics id="alg1.2.2.m1.1a"><msub id="alg1.2.2.m1.1.1" xref="alg1.2.2.m1.1.1.cmml"><mi id="alg1.2.2.m1.1.1.2" xref="alg1.2.2.m1.1.1.2.cmml">S</mi><mi id="alg1.2.2.m1.1.1.3" xref="alg1.2.2.m1.1.1.3.cmml">R</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.2.2.m1.1b"><apply id="alg1.2.2.m1.1.1.cmml" xref="alg1.2.2.m1.1.1"><csymbol cd="ambiguous" id="alg1.2.2.m1.1.1.1.cmml" xref="alg1.2.2.m1.1.1">subscript</csymbol><ci id="alg1.2.2.m1.1.1.2.cmml" xref="alg1.2.2.m1.1.1.2">𝑆</ci><ci id="alg1.2.2.m1.1.1.3.cmml" xref="alg1.2.2.m1.1.1.3">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.2.2.m1.1c">S_{R}</annotation></semantics></math>: System resources information, <math id="alg1.3.3.m2.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="alg1.3.3.m2.1a"><mi id="alg1.3.3.m2.1.1" xref="alg1.3.3.m2.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="alg1.3.3.m2.1b"><ci id="alg1.3.3.m2.1.1.cmml" xref="alg1.3.3.m2.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.3.3.m2.1c">\epsilon</annotation></semantics></math>: Exploration probability, <math id="alg1.4.4.m3.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="alg1.4.4.m3.1a"><mi id="alg1.4.4.m3.1.1" xref="alg1.4.4.m3.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="alg1.4.4.m3.1b"><ci id="alg1.4.4.m3.1.1.cmml" xref="alg1.4.4.m3.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.4.4.m3.1c">\gamma</annotation></semantics></math>: Learning rate, <math id="alg1.5.5.m4.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="alg1.5.5.m4.1a"><mi id="alg1.5.5.m4.1.1" xref="alg1.5.5.m4.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="alg1.5.5.m4.1b"><ci id="alg1.5.5.m4.1.1.cmml" xref="alg1.5.5.m4.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.5.5.m4.1c">\mu</annotation></semantics></math>: Discount factor, <math id="alg1.6.6.m5.1" class="ltx_Math" alttext="N" display="inline"><semantics id="alg1.6.6.m5.1a"><mi id="alg1.6.6.m5.1.1" xref="alg1.6.6.m5.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="alg1.6.6.m5.1b"><ci id="alg1.6.6.m5.1.1.cmml" xref="alg1.6.6.m5.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.6.6.m5.1c">N</annotation></semantics></math>: Number of epochs, <math id="alg1.7.7.m6.1" class="ltx_Math" alttext="T/C" display="inline"><semantics id="alg1.7.7.m6.1a"><mrow id="alg1.7.7.m6.1.1" xref="alg1.7.7.m6.1.1.cmml"><mi id="alg1.7.7.m6.1.1.2" xref="alg1.7.7.m6.1.1.2.cmml">T</mi><mo id="alg1.7.7.m6.1.1.1" xref="alg1.7.7.m6.1.1.1.cmml">/</mo><mi id="alg1.7.7.m6.1.1.3" xref="alg1.7.7.m6.1.1.3.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.7.7.m6.1b"><apply id="alg1.7.7.m6.1.1.cmml" xref="alg1.7.7.m6.1.1"><divide id="alg1.7.7.m6.1.1.1.cmml" xref="alg1.7.7.m6.1.1.1"></divide><ci id="alg1.7.7.m6.1.1.2.cmml" xref="alg1.7.7.m6.1.1.2">𝑇</ci><ci id="alg1.7.7.m6.1.1.3.cmml" xref="alg1.7.7.m6.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.7.7.m6.1c">T/C</annotation></semantics></math>: User preference for time efficiency or cost-effectiveness, if True user prefers efficiency, <math id="alg1.8.8.m7.1" class="ltx_Math" alttext="P_{c}" display="inline"><semantics id="alg1.8.8.m7.1a"><msub id="alg1.8.8.m7.1.1" xref="alg1.8.8.m7.1.1.cmml"><mi id="alg1.8.8.m7.1.1.2" xref="alg1.8.8.m7.1.1.2.cmml">P</mi><mi id="alg1.8.8.m7.1.1.3" xref="alg1.8.8.m7.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.8.8.m7.1b"><apply id="alg1.8.8.m7.1.1.cmml" xref="alg1.8.8.m7.1.1"><csymbol cd="ambiguous" id="alg1.8.8.m7.1.1.1.cmml" xref="alg1.8.8.m7.1.1">subscript</csymbol><ci id="alg1.8.8.m7.1.1.2.cmml" xref="alg1.8.8.m7.1.1.2">𝑃</ci><ci id="alg1.8.8.m7.1.1.3.cmml" xref="alg1.8.8.m7.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.8.8.m7.1c">P_{c}</annotation></semantics></math>: Penalty factor for completion time, <math id="alg1.9.9.m8.1" class="ltx_Math" alttext="C_{a}" display="inline"><semantics id="alg1.9.9.m8.1a"><msub id="alg1.9.9.m8.1.1" xref="alg1.9.9.m8.1.1.cmml"><mi id="alg1.9.9.m8.1.1.2" xref="alg1.9.9.m8.1.1.2.cmml">C</mi><mi id="alg1.9.9.m8.1.1.3" xref="alg1.9.9.m8.1.1.3.cmml">a</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.9.9.m8.1b"><apply id="alg1.9.9.m8.1.1.cmml" xref="alg1.9.9.m8.1.1"><csymbol cd="ambiguous" id="alg1.9.9.m8.1.1.1.cmml" xref="alg1.9.9.m8.1.1">subscript</csymbol><ci id="alg1.9.9.m8.1.1.2.cmml" xref="alg1.9.9.m8.1.1.2">𝐶</ci><ci id="alg1.9.9.m8.1.1.3.cmml" xref="alg1.9.9.m8.1.1.3">𝑎</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.9.9.m8.1c">C_{a}</annotation></semantics></math>: Cost of aggregation

</div>
<div id="alg1.10.10" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">3</span>Initialize Q-values <math id="alg1.10.10.m1.3" class="ltx_Math" alttext="Q(S_{T},S_{R},A)" display="inline"><semantics id="alg1.10.10.m1.3a"><mrow id="alg1.10.10.m1.3.3" xref="alg1.10.10.m1.3.3.cmml"><mi id="alg1.10.10.m1.3.3.4" xref="alg1.10.10.m1.3.3.4.cmml">Q</mi><mo lspace="0em" rspace="0em" id="alg1.10.10.m1.3.3.3" xref="alg1.10.10.m1.3.3.3.cmml">​</mo><mrow id="alg1.10.10.m1.3.3.2.2" xref="alg1.10.10.m1.3.3.2.3.cmml"><mo stretchy="false" id="alg1.10.10.m1.3.3.2.2.3" xref="alg1.10.10.m1.3.3.2.3.cmml">(</mo><msub id="alg1.10.10.m1.2.2.1.1.1" xref="alg1.10.10.m1.2.2.1.1.1.cmml"><mi id="alg1.10.10.m1.2.2.1.1.1.2" xref="alg1.10.10.m1.2.2.1.1.1.2.cmml">S</mi><mi id="alg1.10.10.m1.2.2.1.1.1.3" xref="alg1.10.10.m1.2.2.1.1.1.3.cmml">T</mi></msub><mo id="alg1.10.10.m1.3.3.2.2.4" xref="alg1.10.10.m1.3.3.2.3.cmml">,</mo><msub id="alg1.10.10.m1.3.3.2.2.2" xref="alg1.10.10.m1.3.3.2.2.2.cmml"><mi id="alg1.10.10.m1.3.3.2.2.2.2" xref="alg1.10.10.m1.3.3.2.2.2.2.cmml">S</mi><mi id="alg1.10.10.m1.3.3.2.2.2.3" xref="alg1.10.10.m1.3.3.2.2.2.3.cmml">R</mi></msub><mo id="alg1.10.10.m1.3.3.2.2.5" xref="alg1.10.10.m1.3.3.2.3.cmml">,</mo><mi id="alg1.10.10.m1.1.1" xref="alg1.10.10.m1.1.1.cmml">A</mi><mo stretchy="false" id="alg1.10.10.m1.3.3.2.2.6" xref="alg1.10.10.m1.3.3.2.3.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.10.10.m1.3b"><apply id="alg1.10.10.m1.3.3.cmml" xref="alg1.10.10.m1.3.3"><times id="alg1.10.10.m1.3.3.3.cmml" xref="alg1.10.10.m1.3.3.3"></times><ci id="alg1.10.10.m1.3.3.4.cmml" xref="alg1.10.10.m1.3.3.4">𝑄</ci><vector id="alg1.10.10.m1.3.3.2.3.cmml" xref="alg1.10.10.m1.3.3.2.2"><apply id="alg1.10.10.m1.2.2.1.1.1.cmml" xref="alg1.10.10.m1.2.2.1.1.1"><csymbol cd="ambiguous" id="alg1.10.10.m1.2.2.1.1.1.1.cmml" xref="alg1.10.10.m1.2.2.1.1.1">subscript</csymbol><ci id="alg1.10.10.m1.2.2.1.1.1.2.cmml" xref="alg1.10.10.m1.2.2.1.1.1.2">𝑆</ci><ci id="alg1.10.10.m1.2.2.1.1.1.3.cmml" xref="alg1.10.10.m1.2.2.1.1.1.3">𝑇</ci></apply><apply id="alg1.10.10.m1.3.3.2.2.2.cmml" xref="alg1.10.10.m1.3.3.2.2.2"><csymbol cd="ambiguous" id="alg1.10.10.m1.3.3.2.2.2.1.cmml" xref="alg1.10.10.m1.3.3.2.2.2">subscript</csymbol><ci id="alg1.10.10.m1.3.3.2.2.2.2.cmml" xref="alg1.10.10.m1.3.3.2.2.2.2">𝑆</ci><ci id="alg1.10.10.m1.3.3.2.2.2.3.cmml" xref="alg1.10.10.m1.3.3.2.2.2.3">𝑅</ci></apply><ci id="alg1.10.10.m1.1.1.cmml" xref="alg1.10.10.m1.1.1">𝐴</ci></vector></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.10.10.m1.3c">Q(S_{T},S_{R},A)</annotation></semantics></math> with random values

</div>
<div id="alg1.12.12" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">4</span><span id="alg1.12.12.3" class="ltx_text ltx_font_bold">for</span> <em id="alg1.12.12.2" class="ltx_emph ltx_font_italic"><math id="alg1.11.11.1.m1.1" class="ltx_Math" alttext="epoch=1" display="inline"><semantics id="alg1.11.11.1.m1.1a"><mrow id="alg1.11.11.1.m1.1.1" xref="alg1.11.11.1.m1.1.1.cmml"><mrow id="alg1.11.11.1.m1.1.1.2" xref="alg1.11.11.1.m1.1.1.2.cmml"><mi id="alg1.11.11.1.m1.1.1.2.2" xref="alg1.11.11.1.m1.1.1.2.2.cmml">e</mi><mo lspace="0em" rspace="0em" id="alg1.11.11.1.m1.1.1.2.1" xref="alg1.11.11.1.m1.1.1.2.1.cmml">​</mo><mi id="alg1.11.11.1.m1.1.1.2.3" xref="alg1.11.11.1.m1.1.1.2.3.cmml">p</mi><mo lspace="0em" rspace="0em" id="alg1.11.11.1.m1.1.1.2.1a" xref="alg1.11.11.1.m1.1.1.2.1.cmml">​</mo><mi id="alg1.11.11.1.m1.1.1.2.4" xref="alg1.11.11.1.m1.1.1.2.4.cmml">o</mi><mo lspace="0em" rspace="0em" id="alg1.11.11.1.m1.1.1.2.1b" xref="alg1.11.11.1.m1.1.1.2.1.cmml">​</mo><mi id="alg1.11.11.1.m1.1.1.2.5" xref="alg1.11.11.1.m1.1.1.2.5.cmml">c</mi><mo lspace="0em" rspace="0em" id="alg1.11.11.1.m1.1.1.2.1c" xref="alg1.11.11.1.m1.1.1.2.1.cmml">​</mo><mi id="alg1.11.11.1.m1.1.1.2.6" xref="alg1.11.11.1.m1.1.1.2.6.cmml">h</mi></mrow><mo id="alg1.11.11.1.m1.1.1.1" xref="alg1.11.11.1.m1.1.1.1.cmml">=</mo><mn id="alg1.11.11.1.m1.1.1.3" xref="alg1.11.11.1.m1.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="alg1.11.11.1.m1.1b"><apply id="alg1.11.11.1.m1.1.1.cmml" xref="alg1.11.11.1.m1.1.1"><eq id="alg1.11.11.1.m1.1.1.1.cmml" xref="alg1.11.11.1.m1.1.1.1"></eq><apply id="alg1.11.11.1.m1.1.1.2.cmml" xref="alg1.11.11.1.m1.1.1.2"><times id="alg1.11.11.1.m1.1.1.2.1.cmml" xref="alg1.11.11.1.m1.1.1.2.1"></times><ci id="alg1.11.11.1.m1.1.1.2.2.cmml" xref="alg1.11.11.1.m1.1.1.2.2">𝑒</ci><ci id="alg1.11.11.1.m1.1.1.2.3.cmml" xref="alg1.11.11.1.m1.1.1.2.3">𝑝</ci><ci id="alg1.11.11.1.m1.1.1.2.4.cmml" xref="alg1.11.11.1.m1.1.1.2.4">𝑜</ci><ci id="alg1.11.11.1.m1.1.1.2.5.cmml" xref="alg1.11.11.1.m1.1.1.2.5">𝑐</ci><ci id="alg1.11.11.1.m1.1.1.2.6.cmml" xref="alg1.11.11.1.m1.1.1.2.6">ℎ</ci></apply><cn type="integer" id="alg1.11.11.1.m1.1.1.3.cmml" xref="alg1.11.11.1.m1.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.11.11.1.m1.1c">epoch=1</annotation></semantics></math> <span id="alg1.12.12.2.1" class="ltx_text ltx_font_bold ltx_font_upright">to</span> <math id="alg1.12.12.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="alg1.12.12.2.m2.1a"><mi id="alg1.12.12.2.m2.1.1" xref="alg1.12.12.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="alg1.12.12.2.m2.1b"><ci id="alg1.12.12.2.m2.1.1.cmml" xref="alg1.12.12.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.12.12.2.m2.1c">N</annotation></semantics></math></em> <span id="alg1.12.12.4" class="ltx_text ltx_font_bold">do</span> 
</div>
<div id="alg1.15.15" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">5</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
Observe state variables <math id="alg1.13.13.m1.1" class="ltx_Math" alttext="S_{uc}" display="inline"><semantics id="alg1.13.13.m1.1a"><msub id="alg1.13.13.m1.1.1" xref="alg1.13.13.m1.1.1.cmml"><mi id="alg1.13.13.m1.1.1.2" xref="alg1.13.13.m1.1.1.2.cmml">S</mi><mrow id="alg1.13.13.m1.1.1.3" xref="alg1.13.13.m1.1.1.3.cmml"><mi id="alg1.13.13.m1.1.1.3.2" xref="alg1.13.13.m1.1.1.3.2.cmml">u</mi><mo lspace="0em" rspace="0em" id="alg1.13.13.m1.1.1.3.1" xref="alg1.13.13.m1.1.1.3.1.cmml">​</mo><mi id="alg1.13.13.m1.1.1.3.3" xref="alg1.13.13.m1.1.1.3.3.cmml">c</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="alg1.13.13.m1.1b"><apply id="alg1.13.13.m1.1.1.cmml" xref="alg1.13.13.m1.1.1"><csymbol cd="ambiguous" id="alg1.13.13.m1.1.1.1.cmml" xref="alg1.13.13.m1.1.1">subscript</csymbol><ci id="alg1.13.13.m1.1.1.2.cmml" xref="alg1.13.13.m1.1.1.2">𝑆</ci><apply id="alg1.13.13.m1.1.1.3.cmml" xref="alg1.13.13.m1.1.1.3"><times id="alg1.13.13.m1.1.1.3.1.cmml" xref="alg1.13.13.m1.1.1.3.1"></times><ci id="alg1.13.13.m1.1.1.3.2.cmml" xref="alg1.13.13.m1.1.1.3.2">𝑢</ci><ci id="alg1.13.13.m1.1.1.3.3.cmml" xref="alg1.13.13.m1.1.1.3.3">𝑐</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.13.13.m1.1c">S_{uc}</annotation></semantics></math>, <math id="alg1.14.14.m2.1" class="ltx_Math" alttext="S_{T}" display="inline"><semantics id="alg1.14.14.m2.1a"><msub id="alg1.14.14.m2.1.1" xref="alg1.14.14.m2.1.1.cmml"><mi id="alg1.14.14.m2.1.1.2" xref="alg1.14.14.m2.1.1.2.cmml">S</mi><mi id="alg1.14.14.m2.1.1.3" xref="alg1.14.14.m2.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.14.14.m2.1b"><apply id="alg1.14.14.m2.1.1.cmml" xref="alg1.14.14.m2.1.1"><csymbol cd="ambiguous" id="alg1.14.14.m2.1.1.1.cmml" xref="alg1.14.14.m2.1.1">subscript</csymbol><ci id="alg1.14.14.m2.1.1.2.cmml" xref="alg1.14.14.m2.1.1.2">𝑆</ci><ci id="alg1.14.14.m2.1.1.3.cmml" xref="alg1.14.14.m2.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.14.14.m2.1c">S_{T}</annotation></semantics></math>, <math id="alg1.15.15.m3.1" class="ltx_Math" alttext="S_{R}" display="inline"><semantics id="alg1.15.15.m3.1a"><msub id="alg1.15.15.m3.1.1" xref="alg1.15.15.m3.1.1.cmml"><mi id="alg1.15.15.m3.1.1.2" xref="alg1.15.15.m3.1.1.2.cmml">S</mi><mi id="alg1.15.15.m3.1.1.3" xref="alg1.15.15.m3.1.1.3.cmml">R</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.15.15.m3.1b"><apply id="alg1.15.15.m3.1.1.cmml" xref="alg1.15.15.m3.1.1"><csymbol cd="ambiguous" id="alg1.15.15.m3.1.1.1.cmml" xref="alg1.15.15.m3.1.1">subscript</csymbol><ci id="alg1.15.15.m3.1.1.2.cmml" xref="alg1.15.15.m3.1.1.2">𝑆</ci><ci id="alg1.15.15.m3.1.1.3.cmml" xref="alg1.15.15.m3.1.1.3">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.15.15.m3.1c">S_{R}</annotation></semantics></math>

</div>
<div id="alg1.16.16" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">6</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   <span id="alg1.16.16.2" class="ltx_text ltx_font_bold">if</span> <em id="alg1.16.16.1" class="ltx_emph ltx_font_italic">random value <math id="alg1.16.16.1.m1.1" class="ltx_Math" alttext="&lt;\epsilon" display="inline"><semantics id="alg1.16.16.1.m1.1a"><mrow id="alg1.16.16.1.m1.1.1" xref="alg1.16.16.1.m1.1.1.cmml"><mi id="alg1.16.16.1.m1.1.1.2" xref="alg1.16.16.1.m1.1.1.2.cmml"></mi><mo id="alg1.16.16.1.m1.1.1.1" xref="alg1.16.16.1.m1.1.1.1.cmml">&lt;</mo><mi id="alg1.16.16.1.m1.1.1.3" xref="alg1.16.16.1.m1.1.1.3.cmml">ϵ</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.16.16.1.m1.1b"><apply id="alg1.16.16.1.m1.1.1.cmml" xref="alg1.16.16.1.m1.1.1"><lt id="alg1.16.16.1.m1.1.1.1.cmml" xref="alg1.16.16.1.m1.1.1.1"></lt><csymbol cd="latexml" id="alg1.16.16.1.m1.1.1.2.cmml" xref="alg1.16.16.1.m1.1.1.2">absent</csymbol><ci id="alg1.16.16.1.m1.1.1.3.cmml" xref="alg1.16.16.1.m1.1.1.3">italic-ϵ</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.16.16.1.m1.1c">&lt;\epsilon</annotation></semantics></math></em> <span id="alg1.16.16.3" class="ltx_text ltx_font_bold">then</span>
</div>
<div id="alg1.17.17" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">7</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
Select <math id="alg1.17.17.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="alg1.17.17.m1.1a"><mi id="alg1.17.17.m1.1.1" xref="alg1.17.17.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="alg1.17.17.m1.1b"><ci id="alg1.17.17.m1.1.1.cmml" xref="alg1.17.17.m1.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.17.17.m1.1c">A</annotation></semantics></math> randomly for exploration

</div>
<div id="alg1.27.29" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">8</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="alg1.27.29.1" class="ltx_text ltx_font_bold">else</span> 
</div>
<div id="alg1.19.19" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">9</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
Choose <math id="alg1.18.18.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="alg1.18.18.m1.1a"><mi id="alg1.18.18.m1.1.1" xref="alg1.18.18.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="alg1.18.18.m1.1b"><ci id="alg1.18.18.m1.1.1.cmml" xref="alg1.18.18.m1.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.18.18.m1.1c">A</annotation></semantics></math> with highest <math id="alg1.19.19.m2.1" class="ltx_Math" alttext="Q" display="inline"><semantics id="alg1.19.19.m2.1a"><mi id="alg1.19.19.m2.1.1" xref="alg1.19.19.m2.1.1.cmml">Q</mi><annotation-xml encoding="MathML-Content" id="alg1.19.19.m2.1b"><ci id="alg1.19.19.m2.1.1.cmml" xref="alg1.19.19.m2.1.1">𝑄</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.19.19.m2.1c">Q</annotation></semantics></math>-value for exploitation

</div>
<div id="alg1.27.30" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">10</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>    end if
</div>
<div id="alg1.27.31" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">11</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
</div>
<div id="alg1.20.20" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">12</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   Execute aggregation method <math id="alg1.20.20.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="alg1.20.20.m1.1a"><mi id="alg1.20.20.m1.1.1" xref="alg1.20.20.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="alg1.20.20.m1.1b"><ci id="alg1.20.20.m1.1.1.cmml" xref="alg1.20.20.m1.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.20.20.m1.1c">A</annotation></semantics></math>

</div>
<div id="alg1.21.21" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">13</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   Observe completion time <math id="alg1.21.21.m1.1" class="ltx_Math" alttext="Y_{i}" display="inline"><semantics id="alg1.21.21.m1.1a"><msub id="alg1.21.21.m1.1.1" xref="alg1.21.21.m1.1.1.cmml"><mi id="alg1.21.21.m1.1.1.2" xref="alg1.21.21.m1.1.1.2.cmml">Y</mi><mi id="alg1.21.21.m1.1.1.3" xref="alg1.21.21.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="alg1.21.21.m1.1b"><apply id="alg1.21.21.m1.1.1.cmml" xref="alg1.21.21.m1.1.1"><csymbol cd="ambiguous" id="alg1.21.21.m1.1.1.1.cmml" xref="alg1.21.21.m1.1.1">subscript</csymbol><ci id="alg1.21.21.m1.1.1.2.cmml" xref="alg1.21.21.m1.1.1.2">𝑌</ci><ci id="alg1.21.21.m1.1.1.3.cmml" xref="alg1.21.21.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.21.21.m1.1c">Y_{i}</annotation></semantics></math>

</div>
<div id="alg1.22.22" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">14</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   <span id="alg1.22.22.2" class="ltx_text ltx_font_bold">if</span> <em id="alg1.22.22.1" class="ltx_emph ltx_font_italic"><math id="alg1.22.22.1.m1.1" class="ltx_Math" alttext="T/C" display="inline"><semantics id="alg1.22.22.1.m1.1a"><mrow id="alg1.22.22.1.m1.1.1" xref="alg1.22.22.1.m1.1.1.cmml"><mi id="alg1.22.22.1.m1.1.1.2" xref="alg1.22.22.1.m1.1.1.2.cmml">T</mi><mo id="alg1.22.22.1.m1.1.1.1" xref="alg1.22.22.1.m1.1.1.1.cmml">/</mo><mi id="alg1.22.22.1.m1.1.1.3" xref="alg1.22.22.1.m1.1.1.3.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="alg1.22.22.1.m1.1b"><apply id="alg1.22.22.1.m1.1.1.cmml" xref="alg1.22.22.1.m1.1.1"><divide id="alg1.22.22.1.m1.1.1.1.cmml" xref="alg1.22.22.1.m1.1.1.1"></divide><ci id="alg1.22.22.1.m1.1.1.2.cmml" xref="alg1.22.22.1.m1.1.1.2">𝑇</ci><ci id="alg1.22.22.1.m1.1.1.3.cmml" xref="alg1.22.22.1.m1.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.22.22.1.m1.1c">T/C</annotation></semantics></math> is True</em> <span id="alg1.22.22.3" class="ltx_text ltx_font_bold">then</span>
</div>
<div id="alg1.23.23" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">15</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="alg1.23.23.m1.1" class="ltx_Math" alttext="R=-Y_{i}" display="inline"><semantics id="alg1.23.23.m1.1a"><mrow id="alg1.23.23.m1.1.1" xref="alg1.23.23.m1.1.1.cmml"><mi id="alg1.23.23.m1.1.1.2" xref="alg1.23.23.m1.1.1.2.cmml">R</mi><mo id="alg1.23.23.m1.1.1.1" xref="alg1.23.23.m1.1.1.1.cmml">=</mo><mrow id="alg1.23.23.m1.1.1.3" xref="alg1.23.23.m1.1.1.3.cmml"><mo id="alg1.23.23.m1.1.1.3a" xref="alg1.23.23.m1.1.1.3.cmml">−</mo><msub id="alg1.23.23.m1.1.1.3.2" xref="alg1.23.23.m1.1.1.3.2.cmml"><mi id="alg1.23.23.m1.1.1.3.2.2" xref="alg1.23.23.m1.1.1.3.2.2.cmml">Y</mi><mi id="alg1.23.23.m1.1.1.3.2.3" xref="alg1.23.23.m1.1.1.3.2.3.cmml">i</mi></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.23.23.m1.1b"><apply id="alg1.23.23.m1.1.1.cmml" xref="alg1.23.23.m1.1.1"><eq id="alg1.23.23.m1.1.1.1.cmml" xref="alg1.23.23.m1.1.1.1"></eq><ci id="alg1.23.23.m1.1.1.2.cmml" xref="alg1.23.23.m1.1.1.2">𝑅</ci><apply id="alg1.23.23.m1.1.1.3.cmml" xref="alg1.23.23.m1.1.1.3"><minus id="alg1.23.23.m1.1.1.3.1.cmml" xref="alg1.23.23.m1.1.1.3"></minus><apply id="alg1.23.23.m1.1.1.3.2.cmml" xref="alg1.23.23.m1.1.1.3.2"><csymbol cd="ambiguous" id="alg1.23.23.m1.1.1.3.2.1.cmml" xref="alg1.23.23.m1.1.1.3.2">subscript</csymbol><ci id="alg1.23.23.m1.1.1.3.2.2.cmml" xref="alg1.23.23.m1.1.1.3.2.2">𝑌</ci><ci id="alg1.23.23.m1.1.1.3.2.3.cmml" xref="alg1.23.23.m1.1.1.3.2.3">𝑖</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.23.23.m1.1c">R=-Y_{i}</annotation></semantics></math>

</div>
<div id="alg1.27.32" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">16</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<span id="alg1.27.32.1" class="ltx_text ltx_font_bold">else</span> 
</div>
<div id="alg1.24.24" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">17</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>     <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
<math id="alg1.24.24.m1.1" class="ltx_Math" alttext="R=-C_{a}+P_{c}\cdot Y_{i}" display="inline"><semantics id="alg1.24.24.m1.1a"><mrow id="alg1.24.24.m1.1.1" xref="alg1.24.24.m1.1.1.cmml"><mi id="alg1.24.24.m1.1.1.2" xref="alg1.24.24.m1.1.1.2.cmml">R</mi><mo id="alg1.24.24.m1.1.1.1" xref="alg1.24.24.m1.1.1.1.cmml">=</mo><mrow id="alg1.24.24.m1.1.1.3" xref="alg1.24.24.m1.1.1.3.cmml"><mrow id="alg1.24.24.m1.1.1.3.2" xref="alg1.24.24.m1.1.1.3.2.cmml"><mo id="alg1.24.24.m1.1.1.3.2a" xref="alg1.24.24.m1.1.1.3.2.cmml">−</mo><msub id="alg1.24.24.m1.1.1.3.2.2" xref="alg1.24.24.m1.1.1.3.2.2.cmml"><mi id="alg1.24.24.m1.1.1.3.2.2.2" xref="alg1.24.24.m1.1.1.3.2.2.2.cmml">C</mi><mi id="alg1.24.24.m1.1.1.3.2.2.3" xref="alg1.24.24.m1.1.1.3.2.2.3.cmml">a</mi></msub></mrow><mo id="alg1.24.24.m1.1.1.3.1" xref="alg1.24.24.m1.1.1.3.1.cmml">+</mo><mrow id="alg1.24.24.m1.1.1.3.3" xref="alg1.24.24.m1.1.1.3.3.cmml"><msub id="alg1.24.24.m1.1.1.3.3.2" xref="alg1.24.24.m1.1.1.3.3.2.cmml"><mi id="alg1.24.24.m1.1.1.3.3.2.2" xref="alg1.24.24.m1.1.1.3.3.2.2.cmml">P</mi><mi id="alg1.24.24.m1.1.1.3.3.2.3" xref="alg1.24.24.m1.1.1.3.3.2.3.cmml">c</mi></msub><mo lspace="0.222em" rspace="0.222em" id="alg1.24.24.m1.1.1.3.3.1" xref="alg1.24.24.m1.1.1.3.3.1.cmml">⋅</mo><msub id="alg1.24.24.m1.1.1.3.3.3" xref="alg1.24.24.m1.1.1.3.3.3.cmml"><mi id="alg1.24.24.m1.1.1.3.3.3.2" xref="alg1.24.24.m1.1.1.3.3.3.2.cmml">Y</mi><mi id="alg1.24.24.m1.1.1.3.3.3.3" xref="alg1.24.24.m1.1.1.3.3.3.3.cmml">i</mi></msub></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.24.24.m1.1b"><apply id="alg1.24.24.m1.1.1.cmml" xref="alg1.24.24.m1.1.1"><eq id="alg1.24.24.m1.1.1.1.cmml" xref="alg1.24.24.m1.1.1.1"></eq><ci id="alg1.24.24.m1.1.1.2.cmml" xref="alg1.24.24.m1.1.1.2">𝑅</ci><apply id="alg1.24.24.m1.1.1.3.cmml" xref="alg1.24.24.m1.1.1.3"><plus id="alg1.24.24.m1.1.1.3.1.cmml" xref="alg1.24.24.m1.1.1.3.1"></plus><apply id="alg1.24.24.m1.1.1.3.2.cmml" xref="alg1.24.24.m1.1.1.3.2"><minus id="alg1.24.24.m1.1.1.3.2.1.cmml" xref="alg1.24.24.m1.1.1.3.2"></minus><apply id="alg1.24.24.m1.1.1.3.2.2.cmml" xref="alg1.24.24.m1.1.1.3.2.2"><csymbol cd="ambiguous" id="alg1.24.24.m1.1.1.3.2.2.1.cmml" xref="alg1.24.24.m1.1.1.3.2.2">subscript</csymbol><ci id="alg1.24.24.m1.1.1.3.2.2.2.cmml" xref="alg1.24.24.m1.1.1.3.2.2.2">𝐶</ci><ci id="alg1.24.24.m1.1.1.3.2.2.3.cmml" xref="alg1.24.24.m1.1.1.3.2.2.3">𝑎</ci></apply></apply><apply id="alg1.24.24.m1.1.1.3.3.cmml" xref="alg1.24.24.m1.1.1.3.3"><ci id="alg1.24.24.m1.1.1.3.3.1.cmml" xref="alg1.24.24.m1.1.1.3.3.1">⋅</ci><apply id="alg1.24.24.m1.1.1.3.3.2.cmml" xref="alg1.24.24.m1.1.1.3.3.2"><csymbol cd="ambiguous" id="alg1.24.24.m1.1.1.3.3.2.1.cmml" xref="alg1.24.24.m1.1.1.3.3.2">subscript</csymbol><ci id="alg1.24.24.m1.1.1.3.3.2.2.cmml" xref="alg1.24.24.m1.1.1.3.3.2.2">𝑃</ci><ci id="alg1.24.24.m1.1.1.3.3.2.3.cmml" xref="alg1.24.24.m1.1.1.3.3.2.3">𝑐</ci></apply><apply id="alg1.24.24.m1.1.1.3.3.3.cmml" xref="alg1.24.24.m1.1.1.3.3.3"><csymbol cd="ambiguous" id="alg1.24.24.m1.1.1.3.3.3.1.cmml" xref="alg1.24.24.m1.1.1.3.3.3">subscript</csymbol><ci id="alg1.24.24.m1.1.1.3.3.3.2.cmml" xref="alg1.24.24.m1.1.1.3.3.3.2">𝑌</ci><ci id="alg1.24.24.m1.1.1.3.3.3.3.cmml" xref="alg1.24.24.m1.1.1.3.3.3.3">𝑖</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.24.24.m1.1c">R=-C_{a}+P_{c}\cdot Y_{i}</annotation></semantics></math>

</div>
<div id="alg1.27.33" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">18</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>    end if
</div>
<div id="alg1.27.34" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">19</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   
</div>
<div id="alg1.25.25" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">20</span>  <span class="ltx_rule" style="width:1px;height:100%;background:black;display:inline-block;"> </span>   Update Q-value: <math id="alg1.25.25.m1.8" class="ltx_Math" alttext="Q(S_{T},S_{R},A)\leftarrow(1-\gamma)\cdot Q(S_{T},S_{R},A)+\gamma\cdot(R+\mu\cdot\max_{A^{\prime}}Q(S_{T},S_{R},A^{\prime}))" display="inline"><semantics id="alg1.25.25.m1.8a"><mrow id="alg1.25.25.m1.8.8" xref="alg1.25.25.m1.8.8.cmml"><mrow id="alg1.25.25.m1.4.4.2" xref="alg1.25.25.m1.4.4.2.cmml"><mi id="alg1.25.25.m1.4.4.2.4" xref="alg1.25.25.m1.4.4.2.4.cmml">Q</mi><mo lspace="0em" rspace="0em" id="alg1.25.25.m1.4.4.2.3" xref="alg1.25.25.m1.4.4.2.3.cmml">​</mo><mrow id="alg1.25.25.m1.4.4.2.2.2" xref="alg1.25.25.m1.4.4.2.2.3.cmml"><mo stretchy="false" id="alg1.25.25.m1.4.4.2.2.2.3" xref="alg1.25.25.m1.4.4.2.2.3.cmml">(</mo><msub id="alg1.25.25.m1.3.3.1.1.1.1" xref="alg1.25.25.m1.3.3.1.1.1.1.cmml"><mi id="alg1.25.25.m1.3.3.1.1.1.1.2" xref="alg1.25.25.m1.3.3.1.1.1.1.2.cmml">S</mi><mi id="alg1.25.25.m1.3.3.1.1.1.1.3" xref="alg1.25.25.m1.3.3.1.1.1.1.3.cmml">T</mi></msub><mo id="alg1.25.25.m1.4.4.2.2.2.4" xref="alg1.25.25.m1.4.4.2.2.3.cmml">,</mo><msub id="alg1.25.25.m1.4.4.2.2.2.2" xref="alg1.25.25.m1.4.4.2.2.2.2.cmml"><mi id="alg1.25.25.m1.4.4.2.2.2.2.2" xref="alg1.25.25.m1.4.4.2.2.2.2.2.cmml">S</mi><mi id="alg1.25.25.m1.4.4.2.2.2.2.3" xref="alg1.25.25.m1.4.4.2.2.2.2.3.cmml">R</mi></msub><mo id="alg1.25.25.m1.4.4.2.2.2.5" xref="alg1.25.25.m1.4.4.2.2.3.cmml">,</mo><mi id="alg1.25.25.m1.1.1" xref="alg1.25.25.m1.1.1.cmml">A</mi><mo stretchy="false" id="alg1.25.25.m1.4.4.2.2.2.6" xref="alg1.25.25.m1.4.4.2.2.3.cmml">)</mo></mrow></mrow><mo stretchy="false" id="alg1.25.25.m1.8.8.7" xref="alg1.25.25.m1.8.8.7.cmml">←</mo><mrow id="alg1.25.25.m1.8.8.6" xref="alg1.25.25.m1.8.8.6.cmml"><mrow id="alg1.25.25.m1.7.7.5.3" xref="alg1.25.25.m1.7.7.5.3.cmml"><mrow id="alg1.25.25.m1.5.5.3.1.1" xref="alg1.25.25.m1.5.5.3.1.1.cmml"><mrow id="alg1.25.25.m1.5.5.3.1.1.1.1" xref="alg1.25.25.m1.5.5.3.1.1.1.1.1.cmml"><mo stretchy="false" id="alg1.25.25.m1.5.5.3.1.1.1.1.2" xref="alg1.25.25.m1.5.5.3.1.1.1.1.1.cmml">(</mo><mrow id="alg1.25.25.m1.5.5.3.1.1.1.1.1" xref="alg1.25.25.m1.5.5.3.1.1.1.1.1.cmml"><mn id="alg1.25.25.m1.5.5.3.1.1.1.1.1.2" xref="alg1.25.25.m1.5.5.3.1.1.1.1.1.2.cmml">1</mn><mo id="alg1.25.25.m1.5.5.3.1.1.1.1.1.1" xref="alg1.25.25.m1.5.5.3.1.1.1.1.1.1.cmml">−</mo><mi id="alg1.25.25.m1.5.5.3.1.1.1.1.1.3" xref="alg1.25.25.m1.5.5.3.1.1.1.1.1.3.cmml">γ</mi></mrow><mo rspace="0.055em" stretchy="false" id="alg1.25.25.m1.5.5.3.1.1.1.1.3" xref="alg1.25.25.m1.5.5.3.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="alg1.25.25.m1.5.5.3.1.1.2" xref="alg1.25.25.m1.5.5.3.1.1.2.cmml">⋅</mo><mi id="alg1.25.25.m1.5.5.3.1.1.3" xref="alg1.25.25.m1.5.5.3.1.1.3.cmml">Q</mi></mrow><mo lspace="0em" rspace="0em" id="alg1.25.25.m1.7.7.5.3.4" xref="alg1.25.25.m1.7.7.5.3.4.cmml">​</mo><mrow id="alg1.25.25.m1.7.7.5.3.3.2" xref="alg1.25.25.m1.7.7.5.3.3.3.cmml"><mo stretchy="false" id="alg1.25.25.m1.7.7.5.3.3.2.3" xref="alg1.25.25.m1.7.7.5.3.3.3.cmml">(</mo><msub id="alg1.25.25.m1.6.6.4.2.2.1.1" xref="alg1.25.25.m1.6.6.4.2.2.1.1.cmml"><mi id="alg1.25.25.m1.6.6.4.2.2.1.1.2" xref="alg1.25.25.m1.6.6.4.2.2.1.1.2.cmml">S</mi><mi id="alg1.25.25.m1.6.6.4.2.2.1.1.3" xref="alg1.25.25.m1.6.6.4.2.2.1.1.3.cmml">T</mi></msub><mo id="alg1.25.25.m1.7.7.5.3.3.2.4" xref="alg1.25.25.m1.7.7.5.3.3.3.cmml">,</mo><msub id="alg1.25.25.m1.7.7.5.3.3.2.2" xref="alg1.25.25.m1.7.7.5.3.3.2.2.cmml"><mi id="alg1.25.25.m1.7.7.5.3.3.2.2.2" xref="alg1.25.25.m1.7.7.5.3.3.2.2.2.cmml">S</mi><mi id="alg1.25.25.m1.7.7.5.3.3.2.2.3" xref="alg1.25.25.m1.7.7.5.3.3.2.2.3.cmml">R</mi></msub><mo id="alg1.25.25.m1.7.7.5.3.3.2.5" xref="alg1.25.25.m1.7.7.5.3.3.3.cmml">,</mo><mi id="alg1.25.25.m1.2.2" xref="alg1.25.25.m1.2.2.cmml">A</mi><mo stretchy="false" id="alg1.25.25.m1.7.7.5.3.3.2.6" xref="alg1.25.25.m1.7.7.5.3.3.3.cmml">)</mo></mrow></mrow><mo id="alg1.25.25.m1.8.8.6.5" xref="alg1.25.25.m1.8.8.6.5.cmml">+</mo><mrow id="alg1.25.25.m1.8.8.6.4" xref="alg1.25.25.m1.8.8.6.4.cmml"><mi id="alg1.25.25.m1.8.8.6.4.3" xref="alg1.25.25.m1.8.8.6.4.3.cmml">γ</mi><mo lspace="0.222em" rspace="0.222em" id="alg1.25.25.m1.8.8.6.4.2" xref="alg1.25.25.m1.8.8.6.4.2.cmml">⋅</mo><mrow id="alg1.25.25.m1.8.8.6.4.1.1" xref="alg1.25.25.m1.8.8.6.4.1.1.1.cmml"><mo stretchy="false" id="alg1.25.25.m1.8.8.6.4.1.1.2" xref="alg1.25.25.m1.8.8.6.4.1.1.1.cmml">(</mo><mrow id="alg1.25.25.m1.8.8.6.4.1.1.1" xref="alg1.25.25.m1.8.8.6.4.1.1.1.cmml"><mi id="alg1.25.25.m1.8.8.6.4.1.1.1.5" xref="alg1.25.25.m1.8.8.6.4.1.1.1.5.cmml">R</mi><mo id="alg1.25.25.m1.8.8.6.4.1.1.1.4" xref="alg1.25.25.m1.8.8.6.4.1.1.1.4.cmml">+</mo><mrow id="alg1.25.25.m1.8.8.6.4.1.1.1.3" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.cmml"><mrow id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.cmml"><mi id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.2" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.2.cmml">μ</mi><mo lspace="0.222em" rspace="0.222em" id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.1" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.1.cmml">⋅</mo><mrow id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.cmml"><msub id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1.cmml"><mi id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1.2" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1.2.cmml">max</mi><msup id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1.3" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1.3.cmml"><mi id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1.3.2" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1.3.2.cmml">A</mi><mo id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1.3.3" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1.3.3.cmml">′</mo></msup></msub><mo lspace="0.167em" id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3a" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.cmml">⁡</mo><mi id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.2" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.2.cmml">Q</mi></mrow></mrow><mo lspace="0em" rspace="0em" id="alg1.25.25.m1.8.8.6.4.1.1.1.3.4" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.4.cmml">​</mo><mrow id="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.3" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.4.cmml"><mo stretchy="false" id="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.3.4" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.4.cmml">(</mo><msub id="alg1.25.25.m1.8.8.6.4.1.1.1.1.1.1.1" xref="alg1.25.25.m1.8.8.6.4.1.1.1.1.1.1.1.cmml"><mi id="alg1.25.25.m1.8.8.6.4.1.1.1.1.1.1.1.2" xref="alg1.25.25.m1.8.8.6.4.1.1.1.1.1.1.1.2.cmml">S</mi><mi id="alg1.25.25.m1.8.8.6.4.1.1.1.1.1.1.1.3" xref="alg1.25.25.m1.8.8.6.4.1.1.1.1.1.1.1.3.cmml">T</mi></msub><mo id="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.3.5" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.4.cmml">,</mo><msub id="alg1.25.25.m1.8.8.6.4.1.1.1.2.2.2.2" xref="alg1.25.25.m1.8.8.6.4.1.1.1.2.2.2.2.cmml"><mi id="alg1.25.25.m1.8.8.6.4.1.1.1.2.2.2.2.2" xref="alg1.25.25.m1.8.8.6.4.1.1.1.2.2.2.2.2.cmml">S</mi><mi id="alg1.25.25.m1.8.8.6.4.1.1.1.2.2.2.2.3" xref="alg1.25.25.m1.8.8.6.4.1.1.1.2.2.2.2.3.cmml">R</mi></msub><mo id="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.3.6" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.4.cmml">,</mo><msup id="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.3.3" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.3.3.cmml"><mi id="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.3.3.2" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.3.3.2.cmml">A</mi><mo id="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.3.3.3" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.3.3.3.cmml">′</mo></msup><mo stretchy="false" id="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.3.7" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.4.cmml">)</mo></mrow></mrow></mrow><mo stretchy="false" id="alg1.25.25.m1.8.8.6.4.1.1.3" xref="alg1.25.25.m1.8.8.6.4.1.1.1.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.25.25.m1.8b"><apply id="alg1.25.25.m1.8.8.cmml" xref="alg1.25.25.m1.8.8"><ci id="alg1.25.25.m1.8.8.7.cmml" xref="alg1.25.25.m1.8.8.7">←</ci><apply id="alg1.25.25.m1.4.4.2.cmml" xref="alg1.25.25.m1.4.4.2"><times id="alg1.25.25.m1.4.4.2.3.cmml" xref="alg1.25.25.m1.4.4.2.3"></times><ci id="alg1.25.25.m1.4.4.2.4.cmml" xref="alg1.25.25.m1.4.4.2.4">𝑄</ci><vector id="alg1.25.25.m1.4.4.2.2.3.cmml" xref="alg1.25.25.m1.4.4.2.2.2"><apply id="alg1.25.25.m1.3.3.1.1.1.1.cmml" xref="alg1.25.25.m1.3.3.1.1.1.1"><csymbol cd="ambiguous" id="alg1.25.25.m1.3.3.1.1.1.1.1.cmml" xref="alg1.25.25.m1.3.3.1.1.1.1">subscript</csymbol><ci id="alg1.25.25.m1.3.3.1.1.1.1.2.cmml" xref="alg1.25.25.m1.3.3.1.1.1.1.2">𝑆</ci><ci id="alg1.25.25.m1.3.3.1.1.1.1.3.cmml" xref="alg1.25.25.m1.3.3.1.1.1.1.3">𝑇</ci></apply><apply id="alg1.25.25.m1.4.4.2.2.2.2.cmml" xref="alg1.25.25.m1.4.4.2.2.2.2"><csymbol cd="ambiguous" id="alg1.25.25.m1.4.4.2.2.2.2.1.cmml" xref="alg1.25.25.m1.4.4.2.2.2.2">subscript</csymbol><ci id="alg1.25.25.m1.4.4.2.2.2.2.2.cmml" xref="alg1.25.25.m1.4.4.2.2.2.2.2">𝑆</ci><ci id="alg1.25.25.m1.4.4.2.2.2.2.3.cmml" xref="alg1.25.25.m1.4.4.2.2.2.2.3">𝑅</ci></apply><ci id="alg1.25.25.m1.1.1.cmml" xref="alg1.25.25.m1.1.1">𝐴</ci></vector></apply><apply id="alg1.25.25.m1.8.8.6.cmml" xref="alg1.25.25.m1.8.8.6"><plus id="alg1.25.25.m1.8.8.6.5.cmml" xref="alg1.25.25.m1.8.8.6.5"></plus><apply id="alg1.25.25.m1.7.7.5.3.cmml" xref="alg1.25.25.m1.7.7.5.3"><times id="alg1.25.25.m1.7.7.5.3.4.cmml" xref="alg1.25.25.m1.7.7.5.3.4"></times><apply id="alg1.25.25.m1.5.5.3.1.1.cmml" xref="alg1.25.25.m1.5.5.3.1.1"><ci id="alg1.25.25.m1.5.5.3.1.1.2.cmml" xref="alg1.25.25.m1.5.5.3.1.1.2">⋅</ci><apply id="alg1.25.25.m1.5.5.3.1.1.1.1.1.cmml" xref="alg1.25.25.m1.5.5.3.1.1.1.1"><minus id="alg1.25.25.m1.5.5.3.1.1.1.1.1.1.cmml" xref="alg1.25.25.m1.5.5.3.1.1.1.1.1.1"></minus><cn type="integer" id="alg1.25.25.m1.5.5.3.1.1.1.1.1.2.cmml" xref="alg1.25.25.m1.5.5.3.1.1.1.1.1.2">1</cn><ci id="alg1.25.25.m1.5.5.3.1.1.1.1.1.3.cmml" xref="alg1.25.25.m1.5.5.3.1.1.1.1.1.3">𝛾</ci></apply><ci id="alg1.25.25.m1.5.5.3.1.1.3.cmml" xref="alg1.25.25.m1.5.5.3.1.1.3">𝑄</ci></apply><vector id="alg1.25.25.m1.7.7.5.3.3.3.cmml" xref="alg1.25.25.m1.7.7.5.3.3.2"><apply id="alg1.25.25.m1.6.6.4.2.2.1.1.cmml" xref="alg1.25.25.m1.6.6.4.2.2.1.1"><csymbol cd="ambiguous" id="alg1.25.25.m1.6.6.4.2.2.1.1.1.cmml" xref="alg1.25.25.m1.6.6.4.2.2.1.1">subscript</csymbol><ci id="alg1.25.25.m1.6.6.4.2.2.1.1.2.cmml" xref="alg1.25.25.m1.6.6.4.2.2.1.1.2">𝑆</ci><ci id="alg1.25.25.m1.6.6.4.2.2.1.1.3.cmml" xref="alg1.25.25.m1.6.6.4.2.2.1.1.3">𝑇</ci></apply><apply id="alg1.25.25.m1.7.7.5.3.3.2.2.cmml" xref="alg1.25.25.m1.7.7.5.3.3.2.2"><csymbol cd="ambiguous" id="alg1.25.25.m1.7.7.5.3.3.2.2.1.cmml" xref="alg1.25.25.m1.7.7.5.3.3.2.2">subscript</csymbol><ci id="alg1.25.25.m1.7.7.5.3.3.2.2.2.cmml" xref="alg1.25.25.m1.7.7.5.3.3.2.2.2">𝑆</ci><ci id="alg1.25.25.m1.7.7.5.3.3.2.2.3.cmml" xref="alg1.25.25.m1.7.7.5.3.3.2.2.3">𝑅</ci></apply><ci id="alg1.25.25.m1.2.2.cmml" xref="alg1.25.25.m1.2.2">𝐴</ci></vector></apply><apply id="alg1.25.25.m1.8.8.6.4.cmml" xref="alg1.25.25.m1.8.8.6.4"><ci id="alg1.25.25.m1.8.8.6.4.2.cmml" xref="alg1.25.25.m1.8.8.6.4.2">⋅</ci><ci id="alg1.25.25.m1.8.8.6.4.3.cmml" xref="alg1.25.25.m1.8.8.6.4.3">𝛾</ci><apply id="alg1.25.25.m1.8.8.6.4.1.1.1.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1"><plus id="alg1.25.25.m1.8.8.6.4.1.1.1.4.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.4"></plus><ci id="alg1.25.25.m1.8.8.6.4.1.1.1.5.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.5">𝑅</ci><apply id="alg1.25.25.m1.8.8.6.4.1.1.1.3.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3"><times id="alg1.25.25.m1.8.8.6.4.1.1.1.3.4.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.4"></times><apply id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5"><ci id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.1.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.1">⋅</ci><ci id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.2.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.2">𝜇</ci><apply id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3"><apply id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1"><csymbol cd="ambiguous" id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1.1.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1">subscript</csymbol><max id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1.2.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1.2"></max><apply id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1.3.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1.3"><csymbol cd="ambiguous" id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1.3.1.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1.3">superscript</csymbol><ci id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1.3.2.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1.3.2">𝐴</ci><ci id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1.3.3.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.1.3.3">′</ci></apply></apply><ci id="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.2.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.5.3.2">𝑄</ci></apply></apply><vector id="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.4.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.3"><apply id="alg1.25.25.m1.8.8.6.4.1.1.1.1.1.1.1.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="alg1.25.25.m1.8.8.6.4.1.1.1.1.1.1.1.1.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.1.1.1.1">subscript</csymbol><ci id="alg1.25.25.m1.8.8.6.4.1.1.1.1.1.1.1.2.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.1.1.1.1.2">𝑆</ci><ci id="alg1.25.25.m1.8.8.6.4.1.1.1.1.1.1.1.3.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.1.1.1.1.3">𝑇</ci></apply><apply id="alg1.25.25.m1.8.8.6.4.1.1.1.2.2.2.2.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.2.2.2.2"><csymbol cd="ambiguous" id="alg1.25.25.m1.8.8.6.4.1.1.1.2.2.2.2.1.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.2.2.2.2">subscript</csymbol><ci id="alg1.25.25.m1.8.8.6.4.1.1.1.2.2.2.2.2.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.2.2.2.2.2">𝑆</ci><ci id="alg1.25.25.m1.8.8.6.4.1.1.1.2.2.2.2.3.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.2.2.2.2.3">𝑅</ci></apply><apply id="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.3.3.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.3.3"><csymbol cd="ambiguous" id="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.3.3.1.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.3.3">superscript</csymbol><ci id="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.3.3.2.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.3.3.2">𝐴</ci><ci id="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.3.3.3.cmml" xref="alg1.25.25.m1.8.8.6.4.1.1.1.3.3.3.3.3">′</ci></apply></vector></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.25.25.m1.8c">Q(S_{T},S_{R},A)\leftarrow(1-\gamma)\cdot Q(S_{T},S_{R},A)+\gamma\cdot(R+\mu\cdot\max_{A^{\prime}}Q(S_{T},S_{R},A^{\prime}))</annotation></semantics></math>

</div>
<div id="alg1.27.35" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">21</span> end for
</div>
<div id="alg1.27.36" class="ltx_listingline">
<span class="ltx_tag ltx_tag_listingline">22</span>
</div>
<div id="alg1.27.27" class="ltx_listingline">
<span id="alg1.27.27.1" class="ltx_text ltx_font_bold">Return</span> aggregation method <math id="alg1.26.26.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="alg1.26.26.m1.1a"><mi id="alg1.26.26.m1.1.1" xref="alg1.26.26.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="alg1.26.26.m1.1b"><ci id="alg1.26.26.m1.1.1.cmml" xref="alg1.26.26.m1.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="alg1.26.26.m1.1c">A</annotation></semantics></math> with highest Q-value: <math id="alg1.27.27.m2.3" class="ltx_Math" alttext="A=\arg\max_{A}Q(S_{T},S_{R},A)" display="inline"><semantics id="alg1.27.27.m2.3a"><mrow id="alg1.27.27.m2.3.3" xref="alg1.27.27.m2.3.3.cmml"><mi id="alg1.27.27.m2.3.3.4" xref="alg1.27.27.m2.3.3.4.cmml">A</mi><mo id="alg1.27.27.m2.3.3.3" xref="alg1.27.27.m2.3.3.3.cmml">=</mo><mrow id="alg1.27.27.m2.3.3.2" xref="alg1.27.27.m2.3.3.2.cmml"><mrow id="alg1.27.27.m2.3.3.2.4" xref="alg1.27.27.m2.3.3.2.4.cmml"><mi id="alg1.27.27.m2.3.3.2.4.1" xref="alg1.27.27.m2.3.3.2.4.1.cmml">arg</mi><mo lspace="0.167em" id="alg1.27.27.m2.3.3.2.4a" xref="alg1.27.27.m2.3.3.2.4.cmml">⁡</mo><mrow id="alg1.27.27.m2.3.3.2.4.2" xref="alg1.27.27.m2.3.3.2.4.2.cmml"><msub id="alg1.27.27.m2.3.3.2.4.2.1" xref="alg1.27.27.m2.3.3.2.4.2.1.cmml"><mi id="alg1.27.27.m2.3.3.2.4.2.1.2" xref="alg1.27.27.m2.3.3.2.4.2.1.2.cmml">max</mi><mi id="alg1.27.27.m2.3.3.2.4.2.1.3" xref="alg1.27.27.m2.3.3.2.4.2.1.3.cmml">A</mi></msub><mo lspace="0.167em" id="alg1.27.27.m2.3.3.2.4.2a" xref="alg1.27.27.m2.3.3.2.4.2.cmml">⁡</mo><mi id="alg1.27.27.m2.3.3.2.4.2.2" xref="alg1.27.27.m2.3.3.2.4.2.2.cmml">Q</mi></mrow></mrow><mo lspace="0em" rspace="0em" id="alg1.27.27.m2.3.3.2.3" xref="alg1.27.27.m2.3.3.2.3.cmml">​</mo><mrow id="alg1.27.27.m2.3.3.2.2.2" xref="alg1.27.27.m2.3.3.2.2.3.cmml"><mo stretchy="false" id="alg1.27.27.m2.3.3.2.2.2.3" xref="alg1.27.27.m2.3.3.2.2.3.cmml">(</mo><msub id="alg1.27.27.m2.2.2.1.1.1.1" xref="alg1.27.27.m2.2.2.1.1.1.1.cmml"><mi id="alg1.27.27.m2.2.2.1.1.1.1.2" xref="alg1.27.27.m2.2.2.1.1.1.1.2.cmml">S</mi><mi id="alg1.27.27.m2.2.2.1.1.1.1.3" xref="alg1.27.27.m2.2.2.1.1.1.1.3.cmml">T</mi></msub><mo id="alg1.27.27.m2.3.3.2.2.2.4" xref="alg1.27.27.m2.3.3.2.2.3.cmml">,</mo><msub id="alg1.27.27.m2.3.3.2.2.2.2" xref="alg1.27.27.m2.3.3.2.2.2.2.cmml"><mi id="alg1.27.27.m2.3.3.2.2.2.2.2" xref="alg1.27.27.m2.3.3.2.2.2.2.2.cmml">S</mi><mi id="alg1.27.27.m2.3.3.2.2.2.2.3" xref="alg1.27.27.m2.3.3.2.2.2.2.3.cmml">R</mi></msub><mo id="alg1.27.27.m2.3.3.2.2.2.5" xref="alg1.27.27.m2.3.3.2.2.3.cmml">,</mo><mi id="alg1.27.27.m2.1.1" xref="alg1.27.27.m2.1.1.cmml">A</mi><mo stretchy="false" id="alg1.27.27.m2.3.3.2.2.2.6" xref="alg1.27.27.m2.3.3.2.2.3.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="alg1.27.27.m2.3b"><apply id="alg1.27.27.m2.3.3.cmml" xref="alg1.27.27.m2.3.3"><eq id="alg1.27.27.m2.3.3.3.cmml" xref="alg1.27.27.m2.3.3.3"></eq><ci id="alg1.27.27.m2.3.3.4.cmml" xref="alg1.27.27.m2.3.3.4">𝐴</ci><apply id="alg1.27.27.m2.3.3.2.cmml" xref="alg1.27.27.m2.3.3.2"><times id="alg1.27.27.m2.3.3.2.3.cmml" xref="alg1.27.27.m2.3.3.2.3"></times><apply id="alg1.27.27.m2.3.3.2.4.cmml" xref="alg1.27.27.m2.3.3.2.4"><arg id="alg1.27.27.m2.3.3.2.4.1.cmml" xref="alg1.27.27.m2.3.3.2.4.1"></arg><apply id="alg1.27.27.m2.3.3.2.4.2.cmml" xref="alg1.27.27.m2.3.3.2.4.2"><apply id="alg1.27.27.m2.3.3.2.4.2.1.cmml" xref="alg1.27.27.m2.3.3.2.4.2.1"><csymbol cd="ambiguous" id="alg1.27.27.m2.3.3.2.4.2.1.1.cmml" xref="alg1.27.27.m2.3.3.2.4.2.1">subscript</csymbol><max id="alg1.27.27.m2.3.3.2.4.2.1.2.cmml" xref="alg1.27.27.m2.3.3.2.4.2.1.2"></max><ci id="alg1.27.27.m2.3.3.2.4.2.1.3.cmml" xref="alg1.27.27.m2.3.3.2.4.2.1.3">𝐴</ci></apply><ci id="alg1.27.27.m2.3.3.2.4.2.2.cmml" xref="alg1.27.27.m2.3.3.2.4.2.2">𝑄</ci></apply></apply><vector id="alg1.27.27.m2.3.3.2.2.3.cmml" xref="alg1.27.27.m2.3.3.2.2.2"><apply id="alg1.27.27.m2.2.2.1.1.1.1.cmml" xref="alg1.27.27.m2.2.2.1.1.1.1"><csymbol cd="ambiguous" id="alg1.27.27.m2.2.2.1.1.1.1.1.cmml" xref="alg1.27.27.m2.2.2.1.1.1.1">subscript</csymbol><ci id="alg1.27.27.m2.2.2.1.1.1.1.2.cmml" xref="alg1.27.27.m2.2.2.1.1.1.1.2">𝑆</ci><ci id="alg1.27.27.m2.2.2.1.1.1.1.3.cmml" xref="alg1.27.27.m2.2.2.1.1.1.1.3">𝑇</ci></apply><apply id="alg1.27.27.m2.3.3.2.2.2.2.cmml" xref="alg1.27.27.m2.3.3.2.2.2.2"><csymbol cd="ambiguous" id="alg1.27.27.m2.3.3.2.2.2.2.1.cmml" xref="alg1.27.27.m2.3.3.2.2.2.2">subscript</csymbol><ci id="alg1.27.27.m2.3.3.2.2.2.2.2.cmml" xref="alg1.27.27.m2.3.3.2.2.2.2.2">𝑆</ci><ci id="alg1.27.27.m2.3.3.2.2.2.2.3.cmml" xref="alg1.27.27.m2.3.3.2.2.2.2.3">𝑅</ci></apply><ci id="alg1.27.27.m2.1.1.cmml" xref="alg1.27.27.m2.1.1">𝐴</ci></vector></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="alg1.27.27.m2.3c">A=\arg\max_{A}Q(S_{T},S_{R},A)</annotation></semantics></math>

</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_float"><span id="alg1.29.1.1" class="ltx_text ltx_font_bold">Algorithm 1</span> </span>RL-based Adaptive Aggregator</figcaption>
</figure>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Adaptive Aggregator</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">This section presents the design of the adaptive aggregator given in Figure  <a href="#S3.F10" title="Figure 10 ‣ III-D Serverless-based Multi-node Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>, which uses insights from the analysis in section <a href="#S3" title="III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> to develop a predictive model for estimating the completion time of aggregation tasks for each available method. We also conduct an exhaustive analysis of the adaptive method and demonstrate its advantages through a cost, scalability, and efficiency comparison with other methodologies.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.5" class="ltx_p">We employ a Q-learning-based Reinforcement Learning (RL) agent to optimize the tradeoff between cost, resource utilization, and time efficiency. Let <math id="S4.p2.1.m1.1" class="ltx_Math" alttext="Y_{i}" display="inline"><semantics id="S4.p2.1.m1.1a"><msub id="S4.p2.1.m1.1.1" xref="S4.p2.1.m1.1.1.cmml"><mi id="S4.p2.1.m1.1.1.2" xref="S4.p2.1.m1.1.1.2.cmml">Y</mi><mi id="S4.p2.1.m1.1.1.3" xref="S4.p2.1.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.1.m1.1b"><apply id="S4.p2.1.m1.1.1.cmml" xref="S4.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p2.1.m1.1.1.1.cmml" xref="S4.p2.1.m1.1.1">subscript</csymbol><ci id="S4.p2.1.m1.1.1.2.cmml" xref="S4.p2.1.m1.1.1.2">𝑌</ci><ci id="S4.p2.1.m1.1.1.3.cmml" xref="S4.p2.1.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.1.m1.1c">Y_{i}</annotation></semantics></math> represent the time taken for a user’s aggregation task, which depends on multiple state variables: task-specific information (<math id="S4.p2.2.m2.1" class="ltx_Math" alttext="S_{T}" display="inline"><semantics id="S4.p2.2.m2.1a"><msub id="S4.p2.2.m2.1.1" xref="S4.p2.2.m2.1.1.cmml"><mi id="S4.p2.2.m2.1.1.2" xref="S4.p2.2.m2.1.1.2.cmml">S</mi><mi id="S4.p2.2.m2.1.1.3" xref="S4.p2.2.m2.1.1.3.cmml">T</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.2.m2.1b"><apply id="S4.p2.2.m2.1.1.cmml" xref="S4.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p2.2.m2.1.1.1.cmml" xref="S4.p2.2.m2.1.1">subscript</csymbol><ci id="S4.p2.2.m2.1.1.2.cmml" xref="S4.p2.2.m2.1.1.2">𝑆</ci><ci id="S4.p2.2.m2.1.1.3.cmml" xref="S4.p2.2.m2.1.1.3">𝑇</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.2.m2.1c">S_{T}</annotation></semantics></math>), and system resource data (<math id="S4.p2.3.m3.1" class="ltx_Math" alttext="S_{R}" display="inline"><semantics id="S4.p2.3.m3.1a"><msub id="S4.p2.3.m3.1.1" xref="S4.p2.3.m3.1.1.cmml"><mi id="S4.p2.3.m3.1.1.2" xref="S4.p2.3.m3.1.1.2.cmml">S</mi><mi id="S4.p2.3.m3.1.1.3" xref="S4.p2.3.m3.1.1.3.cmml">R</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.3.m3.1b"><apply id="S4.p2.3.m3.1.1.cmml" xref="S4.p2.3.m3.1.1"><csymbol cd="ambiguous" id="S4.p2.3.m3.1.1.1.cmml" xref="S4.p2.3.m3.1.1">subscript</csymbol><ci id="S4.p2.3.m3.1.1.2.cmml" xref="S4.p2.3.m3.1.1.2">𝑆</ci><ci id="S4.p2.3.m3.1.1.3.cmml" xref="S4.p2.3.m3.1.1.3">𝑅</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.3.m3.1c">S_{R}</annotation></semantics></math>). Task-specific information includes workload, calculated as the product of the number of clients and the size of model parameters. System information includes available memory, CPU capacity, and the number of executor containers/functions for Spark or Serverless computing. The RL agent learns from these state variables and selects an aggregation method (<math id="S4.p2.4.m4.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S4.p2.4.m4.1a"><mi id="S4.p2.4.m4.1.1" xref="S4.p2.4.m4.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S4.p2.4.m4.1b"><ci id="S4.p2.4.m4.1.1.cmml" xref="S4.p2.4.m4.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.4.m4.1c">A</annotation></semantics></math>) to optimize the tradeoff between cost and completion time (<math id="S4.p2.5.m5.1" class="ltx_Math" alttext="Y_{i}" display="inline"><semantics id="S4.p2.5.m5.1a"><msub id="S4.p2.5.m5.1.1" xref="S4.p2.5.m5.1.1.cmml"><mi id="S4.p2.5.m5.1.1.2" xref="S4.p2.5.m5.1.1.2.cmml">Y</mi><mi id="S4.p2.5.m5.1.1.3" xref="S4.p2.5.m5.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p2.5.m5.1b"><apply id="S4.p2.5.m5.1.1.cmml" xref="S4.p2.5.m5.1.1"><csymbol cd="ambiguous" id="S4.p2.5.m5.1.1.1.cmml" xref="S4.p2.5.m5.1.1">subscript</csymbol><ci id="S4.p2.5.m5.1.1.2.cmml" xref="S4.p2.5.m5.1.1.2">𝑌</ci><ci id="S4.p2.5.m5.1.1.3.cmml" xref="S4.p2.5.m5.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p2.5.m5.1c">Y_{i}</annotation></semantics></math>), refining its understanding through interactions with the environment. Here’s an overview of the algorithm:</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.9" class="ltx_p">Algorithm <a href="#alg1" title="In III-D Serverless-based Multi-node Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> optimizes aggregation selection through RL. It initializes Q-values (Line 2), explores or exploits based on Q-values (Lines 3-9), executes aggregation methods (Line 10), observes completion time and calculates rewards based on user preferences (Lines 11-16), and updates Q-values (Line 17). Ultimately, the method with the highest Q-value is chosen for efficiency (Line 19).
Q-value is updated for the chosen action using the Q-learning update equation, incorporating the observed reward, learning rate (<math id="S4.p3.1.m1.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S4.p3.1.m1.1a"><mi id="S4.p3.1.m1.1.1" xref="S4.p3.1.m1.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.1b"><ci id="S4.p3.1.m1.1.1.cmml" xref="S4.p3.1.m1.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.1c">\gamma</annotation></semantics></math>), and discount factor (<math id="S4.p3.2.m2.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="S4.p3.2.m2.1a"><mi id="S4.p3.2.m2.1.1" xref="S4.p3.2.m2.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="S4.p3.2.m2.1b"><ci id="S4.p3.2.m2.1.1.cmml" xref="S4.p3.2.m2.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.2.m2.1c">\mu</annotation></semantics></math>).
The reward calculation takes into account the user’s preference for either time efficiency or cost-effectiveness. If <math id="S4.p3.3.m3.1" class="ltx_Math" alttext="T/C" display="inline"><semantics id="S4.p3.3.m3.1a"><mrow id="S4.p3.3.m3.1.1" xref="S4.p3.3.m3.1.1.cmml"><mi id="S4.p3.3.m3.1.1.2" xref="S4.p3.3.m3.1.1.2.cmml">T</mi><mo id="S4.p3.3.m3.1.1.1" xref="S4.p3.3.m3.1.1.1.cmml">/</mo><mi id="S4.p3.3.m3.1.1.3" xref="S4.p3.3.m3.1.1.3.cmml">C</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.3.m3.1b"><apply id="S4.p3.3.m3.1.1.cmml" xref="S4.p3.3.m3.1.1"><divide id="S4.p3.3.m3.1.1.1.cmml" xref="S4.p3.3.m3.1.1.1"></divide><ci id="S4.p3.3.m3.1.1.2.cmml" xref="S4.p3.3.m3.1.1.2">𝑇</ci><ci id="S4.p3.3.m3.1.1.3.cmml" xref="S4.p3.3.m3.1.1.3">𝐶</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.3.m3.1c">T/C</annotation></semantics></math> is True, it implies the user prefers time efficiency, so the reward is based on negative completion time (-<math id="S4.p3.4.m4.1" class="ltx_Math" alttext="Y_{i}" display="inline"><semantics id="S4.p3.4.m4.1a"><msub id="S4.p3.4.m4.1.1" xref="S4.p3.4.m4.1.1.cmml"><mi id="S4.p3.4.m4.1.1.2" xref="S4.p3.4.m4.1.1.2.cmml">Y</mi><mi id="S4.p3.4.m4.1.1.3" xref="S4.p3.4.m4.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p3.4.m4.1b"><apply id="S4.p3.4.m4.1.1.cmml" xref="S4.p3.4.m4.1.1"><csymbol cd="ambiguous" id="S4.p3.4.m4.1.1.1.cmml" xref="S4.p3.4.m4.1.1">subscript</csymbol><ci id="S4.p3.4.m4.1.1.2.cmml" xref="S4.p3.4.m4.1.1.2">𝑌</ci><ci id="S4.p3.4.m4.1.1.3.cmml" xref="S4.p3.4.m4.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.4.m4.1c">Y_{i}</annotation></semantics></math>). If T/C is False, indicating the user prefers cost-effectiveness, the reward is calculated by subtracting the cost of aggregation and adding a penalty based on completion time (<math id="S4.p3.5.m5.1" class="ltx_Math" alttext="P_{c}" display="inline"><semantics id="S4.p3.5.m5.1a"><msub id="S4.p3.5.m5.1.1" xref="S4.p3.5.m5.1.1.cmml"><mi id="S4.p3.5.m5.1.1.2" xref="S4.p3.5.m5.1.1.2.cmml">P</mi><mi id="S4.p3.5.m5.1.1.3" xref="S4.p3.5.m5.1.1.3.cmml">c</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p3.5.m5.1b"><apply id="S4.p3.5.m5.1.1.cmml" xref="S4.p3.5.m5.1.1"><csymbol cd="ambiguous" id="S4.p3.5.m5.1.1.1.cmml" xref="S4.p3.5.m5.1.1">subscript</csymbol><ci id="S4.p3.5.m5.1.1.2.cmml" xref="S4.p3.5.m5.1.1.2">𝑃</ci><ci id="S4.p3.5.m5.1.1.3.cmml" xref="S4.p3.5.m5.1.1.3">𝑐</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.5.m5.1c">P_{c}</annotation></semantics></math> * <math id="S4.p3.6.m6.1" class="ltx_Math" alttext="Y_{i}" display="inline"><semantics id="S4.p3.6.m6.1a"><msub id="S4.p3.6.m6.1.1" xref="S4.p3.6.m6.1.1.cmml"><mi id="S4.p3.6.m6.1.1.2" xref="S4.p3.6.m6.1.1.2.cmml">Y</mi><mi id="S4.p3.6.m6.1.1.3" xref="S4.p3.6.m6.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S4.p3.6.m6.1b"><apply id="S4.p3.6.m6.1.1.cmml" xref="S4.p3.6.m6.1.1"><csymbol cd="ambiguous" id="S4.p3.6.m6.1.1.1.cmml" xref="S4.p3.6.m6.1.1">subscript</csymbol><ci id="S4.p3.6.m6.1.1.2.cmml" xref="S4.p3.6.m6.1.1.2">𝑌</ci><ci id="S4.p3.6.m6.1.1.3.cmml" xref="S4.p3.6.m6.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.6.m6.1c">Y_{i}</annotation></semantics></math>). This encourages the agent to minimize completion time while taking into account the user’s preference for time efficiency and cost-effectiveness. Hyperparameters <math id="S4.p3.7.m7.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S4.p3.7.m7.1a"><mi id="S4.p3.7.m7.1.1" xref="S4.p3.7.m7.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S4.p3.7.m7.1b"><ci id="S4.p3.7.m7.1.1.cmml" xref="S4.p3.7.m7.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.7.m7.1c">\epsilon</annotation></semantics></math>, <math id="S4.p3.8.m8.1" class="ltx_Math" alttext="\gamma" display="inline"><semantics id="S4.p3.8.m8.1a"><mi id="S4.p3.8.m8.1.1" xref="S4.p3.8.m8.1.1.cmml">γ</mi><annotation-xml encoding="MathML-Content" id="S4.p3.8.m8.1b"><ci id="S4.p3.8.m8.1.1.cmml" xref="S4.p3.8.m8.1.1">𝛾</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.8.m8.1c">\gamma</annotation></semantics></math>, and <math id="S4.p3.9.m9.1" class="ltx_Math" alttext="\mu" display="inline"><semantics id="S4.p3.9.m9.1a"><mi id="S4.p3.9.m9.1.1" xref="S4.p3.9.m9.1.1.cmml">μ</mi><annotation-xml encoding="MathML-Content" id="S4.p3.9.m9.1b"><ci id="S4.p3.9.m9.1.1.cmml" xref="S4.p3.9.m9.1.1">𝜇</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.9.m9.1c">\mu</annotation></semantics></math> are fine-tuned through sensitivity analysis and experimentation to achieve the desired balances between exploration and exploitation, learning rate, and discount factor.
The adaptive aggregator RL agent optimally adjusts aggregation methods based on Q-values and observed state variables, ensuring efficient tradeoffs between cost, resource use, and time, outperforming other methods in scalability, efficiency, and cost-effectiveness.</p>
</div>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS1.5.1.1" class="ltx_text">IV-A</span> </span><span id="S4.SS1.6.2" class="ltx_text ltx_font_italic">Cost-benefit Study with Adaptive Method</span>
</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">The adaptive aggregator can customize cost, scalability, and efficiency requirements for FL aggregators at the edge, making it the first adaptive FL aggregator for Edge and IoT applications. By default, the system chooses the most resource-efficient method based on cost, which is directly translated from resource consumption. This is done while ensuring that the QoS requirements, including time efficiency and scalability, are maintained for the user.</p>
</div>
<section id="S4.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS1.SSS1.5.1.1" class="ltx_text">IV-A</span>1 </span>Cost Calculation</h4>

<div id="S4.SS1.SSS1.p1" class="ltx_para">
<p id="S4.SS1.SSS1.p1.1" class="ltx_p">The Serverless method’s cost is determined by AWS Lambda and depends on function memory and billing duration. Storage costs (S3) are variable and depend on storage characteristics. For the Spark-based method, cost calculation is possible using the pay-to-use AWS Glue API, supporting Serverless ETL operations with PySpark <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib52" title="" class="ltx_ref">52</a>]</cite>.</p>
</div>
</section>
<section id="S4.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS1.SSS2.5.1.1" class="ltx_text">IV-A</span>2 </span>Multi-core in Adaptive Aggregator</h4>

<div id="S4.SS1.SSS2.p1" class="ltx_para">
<p id="S4.SS1.SSS2.p1.1" class="ltx_p">In fewer-participant IoT applications, both FedAvg and IterAvg start strong with Numba, but face efficiency drops from memory-induced CPU bottlenecks as memory limits are reached, regardless of fusion algorithm complexity, as shown in Figure <a href="#S3.F11" title="Figure 11 ‣ III-D Serverless-based Multi-node Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> with log scales.</p>
</div>
<div id="S4.SS1.SSS2.p2" class="ltx_para ltx_noindent">
<svg id="S4.SS1.SSS2.p2.pic1" class="ltx_picture" height="40.71" overflow="visible" version="1.1" width="600"><g transform="translate(0,40.71) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 34.81 C 0 38.07 2.64 40.71 5.91 40.71 L 594.09 40.71 C 597.36 40.71 600 38.07 600 34.81 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 34.81 C 1.97 36.98 3.73 38.75 5.91 38.75 L 594.09 38.75 C 596.27 38.75 598.03 36.98 598.03 34.81 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 5.91 5.91)"><foreignObject width="588.19" height="28.9" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S4.SS1.SSS2.p2.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:425.1pt;">
<span id="S4.SS1.SSS2.p2.pic1.1.1.1.1.1.1" class="ltx_p">Figure <a href="#S3.F11" title="Figure 11 ‣ III-D Serverless-based Multi-node Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> shows that a fixed multi-node method is overkill for less complex models with low participation rates which makes it more expensive and less efficient than Numba.</span>
</span></foreignObject></g></g></svg>
</div>
<figure id="S4.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T2.2.1.1" class="ltx_text" style="font-size:90%;">TABLE II</span>: </span><span id="S4.T2.3.2" class="ltx_text" style="font-size:90%;">Total aggregation time comparison of different aggregation methodologies with the Adaptive method</span></figcaption>
<div id="S4.T2.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:303.5pt;height:53.6pt;vertical-align:-0.6pt;"><span class="ltx_transformed_inner" style="transform:translate(-106.0pt,18.5pt) scale(0.588779571035988,0.588779571035988) ;">
<table id="S4.T2.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T2.4.1.1.1" class="ltx_tr">
<th id="S4.T2.4.1.1.1.1" class="ltx_td ltx_th ltx_th_column ltx_border_r"></th>
<th id="S4.T2.4.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T2.4.1.1.1.2.1" class="ltx_text ltx_font_bold">Supported Model Size</span></th>
<th id="S4.T2.4.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T2.4.1.1.1.3.1" class="ltx_text ltx_font_bold">Scalability</span></th>
<th id="S4.T2.4.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T2.4.1.1.1.4.1" class="ltx_text ltx_font_bold">Latency</span></th>
<th id="S4.T2.4.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T2.4.1.1.1.5.1" class="ltx_text ltx_font_bold">Average Cost</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T2.4.1.2.1" class="ltx_tr">
<td id="S4.T2.4.1.2.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T2.4.1.2.1.1.1" class="ltx_text ltx_font_bold">Single Node</span></td>
<td id="S4.T2.4.1.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Very Small</td>
<td id="S4.T2.4.1.2.1.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Does not scale</td>
<td id="S4.T2.4.1.2.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Low</td>
<td id="S4.T2.4.1.2.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T2.4.1.2.1.5.1" class="ltx_text" style="color:#008000;">$</span></td>
</tr>
<tr id="S4.T2.4.1.3.2" class="ltx_tr">
<td id="S4.T2.4.1.3.2.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T2.4.1.3.2.1.1" class="ltx_text ltx_font_bold">Serverless-TreeReduce</span></td>
<td id="S4.T2.4.1.3.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Medium</td>
<td id="S4.T2.4.1.3.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">High (except large models)</td>
<td id="S4.T2.4.1.3.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Medium</td>
<td id="S4.T2.4.1.3.2.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T2.4.1.3.2.5.1" class="ltx_text" style="color:#008000;">$$</span></td>
</tr>
<tr id="S4.T2.4.1.4.3" class="ltx_tr">
<td id="S4.T2.4.1.4.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T2.4.1.4.3.1.1" class="ltx_text ltx_font_bold">Spark</span></td>
<td id="S4.T2.4.1.4.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Large</td>
<td id="S4.T2.4.1.4.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">High</td>
<td id="S4.T2.4.1.4.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">High</td>
<td id="S4.T2.4.1.4.3.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><span id="S4.T2.4.1.4.3.5.1" class="ltx_text" style="color:#008000;">$$$</span></td>
</tr>
<tr id="S4.T2.4.1.5.4" class="ltx_tr">
<td id="S4.T2.4.1.5.4.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T2.4.1.5.4.1.1" class="ltx_text ltx_font_bold">Adaptive</span></td>
<td id="S4.T2.4.1.5.4.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">All</td>
<td id="S4.T2.4.1.5.4.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">High</td>
<td id="S4.T2.4.1.5.4.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">Method dependent</td>
<td id="S4.T2.4.1.5.4.5" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T2.4.1.5.4.5.1" class="ltx_text" style="color:#008000;">$$</span></td>
</tr>
</tbody>
</table>
</span></div>
</figure>
</section>
<section id="S4.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S4.SS1.SSS3.5.1.1" class="ltx_text">IV-A</span>3 </span>Multi-Node in Adaptive Aggregator</h4>

<div id="S4.SS1.SSS3.p1" class="ltx_para">
<p id="S4.SS1.SSS3.p1.1" class="ltx_p">Algorithm <a href="#alg1" title="In III-D Serverless-based Multi-node Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> provides an optimal performance in time and cost, as Figure <a href="#S3.F11" title="Figure 11 ‣ III-D Serverless-based Multi-node Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a> illustrates. This adaptive aggregator switches to a Serverless method when client numbers surpass 15k for various CNN models, resulting in significant time and cost savings. For CNN4.6, it reduces latency by 88% and for CNN73 by 85.59%, with a $0.2 cost saving per run compared to a static Spark method. With CNN478, latency decreases by 63.51%, while for heavier models like CNN956, where Serverless costs increase due to higher cold-start container requirements, the aggregator opts for Spark-based methods, increasing efficiency by 28.73% and cutting costs by $1. Although with CNN717 the adaptive method’s costs are higher at greater participation levels, favoring efficiency, it can be adjusted to prefer the less expensive Spark-based method, saving $0.6 each round.</p>
</div>
<div id="S4.SS1.SSS3.p2" class="ltx_para ltx_noindent">
<svg id="S4.SS1.SSS3.p2.pic1" class="ltx_picture" height="57.32" overflow="visible" version="1.1" width="600"><g transform="translate(0,57.32) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 51.41 C 0 54.68 2.64 57.32 5.91 57.32 L 594.09 57.32 C 597.36 57.32 600 54.68 600 51.41 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 51.41 C 1.97 53.59 3.73 55.35 5.91 55.35 L 594.09 55.35 C 596.27 55.35 598.03 53.59 598.03 51.41 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 5.91 5.91)"><foreignObject width="588.19" height="45.51" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S4.SS1.SSS3.p2.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:425.1pt;">
<span id="S4.SS1.SSS3.p2.pic1.1.1.1.1.1.1" class="ltx_p">The key point from the analysis in Section  <a href="#S3" title="III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> is that an adaptive approach is best for addressing diverse workloads in various FL applications. This approach can strike a balance between enhancing efficiency and scalability while also lowering costs through resource-efficient decision-making.</span>
</span></foreignObject></g></g></svg>
</div>
<div id="S4.SS1.SSS3.p3" class="ltx_para">
<p id="S4.SS1.SSS3.p3.1" class="ltx_p">Similar patterns are observed with the IterAvg algorithm in Figure  <a href="#S3.F11" title="Figure 11 ‣ III-D Serverless-based Multi-node Aggregation ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>, where the adaptive method yields savings in both time and cost. Specifically for workloads like CNN956, the adaptive approach reduces time by 118s and saves over 1 dollar each training round, substantial savings over the hundreds to thousands of rounds in a single FL training job. This algorithm dynamically switches between Numba, Serverless-based, and Spark-based methods, achieving notable cost reductions per round and enhancing QoS, as summarized in Table  <a href="#S4.T2" title="TABLE II ‣ IV-A2 Multi-core in Adaptive Aggregator ‣ IV-A Cost-benefit Study with Adaptive Method ‣ IV Adaptive Aggregator ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>.</p>
</div>
<div id="S4.SS1.SSS3.p4" class="ltx_para ltx_noindent">
<svg id="S4.SS1.SSS3.p4.pic1" class="ltx_picture" height="67.58" overflow="visible" version="1.1" width="600"><g transform="translate(0,67.58) matrix(1 0 0 -1 0 0)" fill="#000000" stroke="#000000" stroke-width="0.4pt"><g fill="#404040" fill-opacity="1.0"><path d="M 0 5.91 L 0 61.68 C 0 64.94 2.64 67.58 5.91 67.58 L 594.09 67.58 C 597.36 67.58 600 64.94 600 61.68 L 600 5.91 C 600 2.64 597.36 0 594.09 0 L 5.91 0 C 2.64 0 0 2.64 0 5.91 Z" style="stroke:none"></path></g><g fill="#F2F2F2" fill-opacity="1.0"><path d="M 1.97 5.91 L 1.97 61.68 C 1.97 63.85 3.73 65.61 5.91 65.61 L 594.09 65.61 C 596.27 65.61 598.03 63.85 598.03 61.68 L 598.03 5.91 C 598.03 3.73 596.27 1.97 594.09 1.97 L 5.91 1.97 C 3.73 1.97 1.97 3.73 1.97 5.91 Z" style="stroke:none"></path></g><g fill-opacity="1.0" transform="matrix(1.0 0.0 0.0 1.0 5.91 5.91)"><foreignObject width="588.19" height="55.77" transform="matrix(1 0 0 -1 0 16.6)" overflow="visible" color="#000000">
<span id="S4.SS1.SSS3.p4.pic1.1.1.1.1.1" class="ltx_inline-block ltx_minipage ltx_align_bottom" style="width:425.1pt;">
<span id="S4.SS1.SSS3.p4.pic1.1.1.1.1.1.1" class="ltx_p">Thundering herd problem can occur if all clients send their data at the same time <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, especially with millions of IoT or edge devices with unpredictable participation rates <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="" class="ltx_ref">42</a>, <a href="#bib.bib53" title="" class="ltx_ref">53</a>]</cite>, but this effect can be mitigated by using scalable storage (S3/HDFS) with multi-node aggregation.</span>
</span></foreignObject></g></g></svg>
</div>
<figure id="S4.F12" class="ltx_figure">
<p id="S4.F12.1" class="ltx_p ltx_align_center ltx_align_center"><span id="S4.F12.1.1" class="ltx_text"><img src="/html/2204.07767/assets/x26.png" id="S4.F12.1.1.g1" class="ltx_graphics ltx_img_square" width="322" height="269" alt="Refer to caption"></span></p>
<br class="ltx_break ltx_break">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F12.3.1.1" class="ltx_text" style="font-size:90%;">Figure 12</span>: </span><span id="S4.F12.4.2" class="ltx_text" style="font-size:90%;">An end-to-end working comparison of the Spark method with simulated clients for varying models using FedAvg (y-axis on the right shows the number of clients and Partitions, y-axis on the left represents all the bars)</span></figcaption>
</figure>
<div id="S4.SS1.SSS3.p5" class="ltx_para">
<p id="S4.SS1.SSS3.p5.1" class="ltx_p"><em id="S4.SS1.SSS3.p5.1.1" class="ltx_emph ltx_font_italic">Communication in Adaptive Aggregation: </em>
We assessed the adaptive method’s end-to-end latency in small-sized edge data centers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>, <a href="#bib.bib41" title="" class="ltx_ref">41</a>]</cite>, focusing on the Spark-based method within the adaptive aggregator. Our experiment involved simulated clients on 6 machines connected via a 1 Gigabit Ethernet switch and used scalable HDFS storage for communication (details in section <a href="#S3.SS1.SSS3" title="III-A3 Testbed ‣ III-A Experimental Setup ‣ III Methodologies and their Analysis ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag"><span class="ltx_text">III-A</span>3</span></a>). To avoid client-side network bottlenecks, we adjusted the number of simulated clients based on network and machine capacities for various model sizes, ensuring the aggregator’s write throughput was tested without network constraints on the client side. The results in Figure <a href="#S4.F12" title="Figure 12 ‣ IV-A3 Multi-Node in Adaptive Aggregator ‣ IV-A Cost-benefit Study with Adaptive Method ‣ IV Adaptive Aggregator ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a> reveal that even with model update sizes increasing by over 9X, the write time only slightly varied. The figure also presents the number of clients, Spark’s task partitions for each model aggregation, and the time for reading, writing, and fusion. The average write time refers to the time for writing a single model update from a client, while the reduced time pertains to the MapReduce time for computing the weighted average of partitioned data. We maintained constant partition numbers (Spark tasks) to observe the impact of model size increase on fusion time. Thus, the adaptive aggregator efficiently utilizes scalable storage for client I/O and data input to aggregation task executors (Serverless functions/Spark executors).</p>
</div>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S4.SS2.5.1.1" class="ltx_text">IV-B</span> </span><span id="S4.SS2.6.2" class="ltx_text ltx_font_italic">Supplementary Features</span>
</h3>

<figure id="S4.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T3.3.1.1" class="ltx_text" style="font-size:90%;">TABLE III</span>: </span><span id="S4.T3.4.2" class="ltx_text" style="font-size:90%;">Aggregation with multiple tenants</span></figcaption>
<div id="S4.T3.1" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:137.5pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(18.1pt,-5.7pt) scale(1.09124793483383,1.09124793483383) ;">
<table id="S4.T3.1.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T3.1.1.1" class="ltx_tr">
<th id="S4.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.2.1" class="ltx_text ltx_font_bold">Methodologies</span></th>
<th id="S4.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.3.1" class="ltx_text ltx_font_bold">Models</span></th>
<th id="S4.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<math id="S4.T3.1.1.1.1.m1.1" class="ltx_Math" alttext="\#" display="inline"><semantics id="S4.T3.1.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T3.1.1.1.1.m1.1.1" xref="S4.T3.1.1.1.1.m1.1.1.cmml">#</mi><annotation-xml encoding="MathML-Content" id="S4.T3.1.1.1.1.m1.1b"><ci id="S4.T3.1.1.1.1.m1.1.1.cmml" xref="S4.T3.1.1.1.1.m1.1.1">#</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T3.1.1.1.1.m1.1c">\#</annotation></semantics></math><span id="S4.T3.1.1.1.1.1" class="ltx_text ltx_font_bold"> of Sampled Clients</span>
</th>
<th id="S4.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.4.1" class="ltx_text ltx_font_bold">Cost ($)</span></th>
<th id="S4.T3.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T3.1.1.1.5.1" class="ltx_text ltx_font_bold">Total Time (s)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T3.1.1.2.1" class="ltx_tr">
<td id="S4.T3.1.1.2.1.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T3.1.1.2.1.1.1" class="ltx_text">Serverless Tree-Reduce</span></td>
<td id="S4.T3.1.1.2.1.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Resnet50</td>
<td id="S4.T3.1.1.2.1.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">900</td>
<td id="S4.T3.1.1.2.1.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.088</td>
<td id="S4.T3.1.1.2.1.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">50.05</td>
</tr>
<tr id="S4.T3.1.1.3.2" class="ltx_tr">
<td id="S4.T3.1.1.3.2.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Vgg16</td>
<td id="S4.T3.1.1.3.2.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">100</td>
<td id="S4.T3.1.1.3.2.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.153</td>
<td id="S4.T3.1.1.3.2.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">117.73</td>
</tr>
<tr id="S4.T3.1.1.4.3" class="ltx_tr">
<td id="S4.T3.1.1.4.3.1" class="ltx_td ltx_align_left ltx_border_l ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T3.1.1.4.3.1.1" class="ltx_text">Spark MapReduce</span></td>
<td id="S4.T3.1.1.4.3.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Resnet50</td>
<td id="S4.T3.1.1.4.3.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">900</td>
<td id="S4.T3.1.1.4.3.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.217</td>
<td id="S4.T3.1.1.4.3.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">93.60</td>
</tr>
<tr id="S4.T3.1.1.5.4" class="ltx_tr">
<td id="S4.T3.1.1.5.4.1" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Vgg16</td>
<td id="S4.T3.1.1.5.4.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">100</td>
<td id="S4.T3.1.1.5.4.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.307</td>
<td id="S4.T3.1.1.5.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">132.36</td>
</tr>
<tr id="S4.T3.1.1.6.5" class="ltx_tr">
<td id="S4.T3.1.1.6.5.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_l ltx_border_r ltx_border_t" rowspan="2"><span id="S4.T3.1.1.6.5.1.1" class="ltx_text">Numba</span></td>
<td id="S4.T3.1.1.6.5.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Resnet50</td>
<td id="S4.T3.1.1.6.5.3" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">400</td>
<td id="S4.T3.1.1.6.5.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">0.019</td>
<td id="S4.T3.1.1.6.5.5" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">29.94</td>
</tr>
<tr id="S4.T3.1.1.7.6" class="ltx_tr">
<td id="S4.T3.1.1.7.6.1" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">Vgg16</td>
<td id="S4.T3.1.1.7.6.2" class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t">80</td>
<td id="S4.T3.1.1.7.6.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">0.038</td>
<td id="S4.T3.1.1.7.6.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t">59.74</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<figure id="S4.T4" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table"><span id="S4.T4.2.1.1" class="ltx_text" style="font-size:90%;">TABLE IV</span>: </span><span id="S4.T4.3.2" class="ltx_text" style="font-size:90%;">Emulator write throughput</span></figcaption>
<div id="S4.T4.4" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:148.5pt;vertical-align:-0.8pt;"><span class="ltx_transformed_inner" style="transform:translate(-47.4pt,16.1pt) scale(0.8206443319913,0.8206443319913) ;">
<table id="S4.T4.4.1" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S4.T4.4.1.1.1" class="ltx_tr">
<th id="S4.T4.4.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_rr ltx_border_t" colspan="4"><span id="S4.T4.4.1.1.1.1.1" class="ltx_text ltx_font_bold">No drop out</span></th>
<td id="S4.T4.4.1.1.1.2" class="ltx_td ltx_align_center ltx_border_r ltx_border_t" colspan="4"><span id="S4.T4.4.1.1.1.2.1" class="ltx_text ltx_font_bold">Drop out 5%</span></td>
</tr>
<tr id="S4.T4.4.1.2.2" class="ltx_tr">
<th id="S4.T4.4.1.2.2.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span id="S4.T4.4.1.2.2.1.1" class="ltx_text ltx_font_bold"># Clients</span></th>
<th id="S4.T4.4.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T4.4.1.2.2.2.1" class="ltx_text ltx_font_bold">Client Locations</span></th>
<th id="S4.T4.4.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t"><span id="S4.T4.4.1.2.2.3.1" class="ltx_text ltx_font_bold">CNN4.6 (s)</span></th>
<th id="S4.T4.4.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t"><span id="S4.T4.4.1.2.2.4.1" class="ltx_text ltx_font_bold">CNN478 (s)</span></th>
<td id="S4.T4.4.1.2.2.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.4.1.2.2.5.1" class="ltx_text ltx_font_bold"># Clients</span></td>
<td id="S4.T4.4.1.2.2.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.4.1.2.2.6.1" class="ltx_text ltx_font_bold">Client Locations</span></td>
<td id="S4.T4.4.1.2.2.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.4.1.2.2.7.1" class="ltx_text ltx_font_bold">CNN4.6 (s)</span></td>
<td id="S4.T4.4.1.2.2.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T4.4.1.2.2.8.1" class="ltx_text ltx_font_bold">CNN478 (s)</span></td>
</tr>
<tr id="S4.T4.4.1.3.3" class="ltx_tr">
<th id="S4.T4.4.1.3.3.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">1000</th>
<th id="S4.T4.4.1.3.3.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Ireland</th>
<th id="S4.T4.4.1.3.3.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">1.99</th>
<th id="S4.T4.4.1.3.3.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t">109.77</th>
<td id="S4.T4.4.1.3.3.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1000</td>
<td id="S4.T4.4.1.3.3.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Ireland</td>
<td id="S4.T4.4.1.3.3.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.64</td>
<td id="S4.T4.4.1.3.3.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">97.42</td>
</tr>
<tr id="S4.T4.4.1.4.4" class="ltx_tr">
<th id="S4.T4.4.1.4.4.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S4.T4.4.1.4.4.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Seoul</th>
<th id="S4.T4.4.1.4.4.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">3.401</th>
<th id="S4.T4.4.1.4.4.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr">120.84</th>
<td id="S4.T4.4.1.4.4.5" class="ltx_td ltx_border_r"></td>
<td id="S4.T4.4.1.4.4.6" class="ltx_td ltx_align_center ltx_border_r">Seoul</td>
<td id="S4.T4.4.1.4.4.7" class="ltx_td ltx_align_center ltx_border_r">2.55</td>
<td id="S4.T4.4.1.4.4.8" class="ltx_td ltx_align_center ltx_border_r">97.58</td>
</tr>
<tr id="S4.T4.4.1.5.5" class="ltx_tr">
<th id="S4.T4.4.1.5.5.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S4.T4.4.1.5.5.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">California</th>
<th id="S4.T4.4.1.5.5.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">1.84</th>
<th id="S4.T4.4.1.5.5.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr">98</th>
<td id="S4.T4.4.1.5.5.5" class="ltx_td ltx_border_r"></td>
<td id="S4.T4.4.1.5.5.6" class="ltx_td ltx_align_center ltx_border_r">California</td>
<td id="S4.T4.4.1.5.5.7" class="ltx_td ltx_align_center ltx_border_r">1.66</td>
<td id="S4.T4.4.1.5.5.8" class="ltx_td ltx_align_center ltx_border_r">99.65</td>
</tr>
<tr id="S4.T4.4.1.6.6" class="ltx_tr">
<th id="S4.T4.4.1.6.6.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S4.T4.4.1.6.6.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Total Time</th>
<th id="S4.T4.4.1.6.6.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">13.98</th>
<th id="S4.T4.4.1.6.6.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr">238.19</th>
<td id="S4.T4.4.1.6.6.5" class="ltx_td ltx_border_r"></td>
<td id="S4.T4.4.1.6.6.6" class="ltx_td ltx_align_center ltx_border_r">Total Time</td>
<td id="S4.T4.4.1.6.6.7" class="ltx_td ltx_align_center ltx_border_r">3.69</td>
<td id="S4.T4.4.1.6.6.8" class="ltx_td ltx_align_center ltx_border_r">116.29</td>
</tr>
<tr id="S4.T4.4.1.7.7" class="ltx_tr">
<th id="S4.T4.4.1.7.7.1" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">50000</th>
<th id="S4.T4.4.1.7.7.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">Ireland</th>
<th id="S4.T4.4.1.7.7.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r ltx_border_t">1.65</th>
<th id="S4.T4.4.1.7.7.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr ltx_border_t">114.27</th>
<td id="S4.T4.4.1.7.7.5" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">50000</td>
<td id="S4.T4.4.1.7.7.6" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">Ireland</td>
<td id="S4.T4.4.1.7.7.7" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">1.8</td>
<td id="S4.T4.4.1.7.7.8" class="ltx_td ltx_align_center ltx_border_r ltx_border_t">113.83</td>
</tr>
<tr id="S4.T4.4.1.8.8" class="ltx_tr">
<th id="S4.T4.4.1.8.8.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S4.T4.4.1.8.8.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">Seoul</th>
<th id="S4.T4.4.1.8.8.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">5.441</th>
<th id="S4.T4.4.1.8.8.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr">126.76</th>
<td id="S4.T4.4.1.8.8.5" class="ltx_td ltx_border_r"></td>
<td id="S4.T4.4.1.8.8.6" class="ltx_td ltx_align_center ltx_border_r">Seoul</td>
<td id="S4.T4.4.1.8.8.7" class="ltx_td ltx_align_center ltx_border_r">5.15</td>
<td id="S4.T4.4.1.8.8.8" class="ltx_td ltx_align_center ltx_border_r">125.79</td>
</tr>
<tr id="S4.T4.4.1.9.9" class="ltx_tr">
<th id="S4.T4.4.1.9.9.1" class="ltx_td ltx_th ltx_th_row ltx_border_l ltx_border_r"></th>
<th id="S4.T4.4.1.9.9.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">California</th>
<th id="S4.T4.4.1.9.9.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_r">1.59</th>
<th id="S4.T4.4.1.9.9.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_rr">116.68</th>
<td id="S4.T4.4.1.9.9.5" class="ltx_td ltx_border_r"></td>
<td id="S4.T4.4.1.9.9.6" class="ltx_td ltx_align_center ltx_border_r">California</td>
<td id="S4.T4.4.1.9.9.7" class="ltx_td ltx_align_center ltx_border_r">1.73</td>
<td id="S4.T4.4.1.9.9.8" class="ltx_td ltx_align_center ltx_border_r">111.64</td>
</tr>
<tr id="S4.T4.4.1.10.10" class="ltx_tr">
<th id="S4.T4.4.1.10.10.1" class="ltx_td ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r"></th>
<th id="S4.T4.4.1.10.10.2" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">Total Time</th>
<th id="S4.T4.4.1.10.10.3" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_r">114.48</th>
<th id="S4.T4.4.1.10.10.4" class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_rr">12195.45</th>
<td id="S4.T4.4.1.10.10.5" class="ltx_td ltx_border_b ltx_border_r"></td>
<td id="S4.T4.4.1.10.10.6" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">Total Time</td>
<td id="S4.T4.4.1.10.10.7" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">84.42</td>
<td id="S4.T4.4.1.10.10.8" class="ltx_td ltx_align_center ltx_border_b ltx_border_r">11670.50</td>
</tr>
</tbody>
</table>
</span></div>
</figure>
<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p"><span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_bold">Multi-tenant Isolation: </span> The edge data center’s adaptive aggregation service supports multi-tenancy and was tested with VGG16 and Resnet50 models. The results in Table <a href="#S4.T3" title="TABLE III ‣ IV-B Supplementary Features ‣ IV Adaptive Aggregator ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> show that Serverless and Spark performed well with many clients, while the Numba-based method had a limit of 400 clients due to memory constraints. Resource management for multiple tenants is a well-researched topic in cloud services <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="" class="ltx_ref">38</a>, <a href="#bib.bib39" title="" class="ltx_ref">39</a>]</cite>, but it’s outside our paper’s scope.
<span id="S4.SS2.p1.1.2" class="ltx_text ltx_font_bold">Emulator Evaluation: </span>
Table  <a href="#S4.T4" title="TABLE IV ‣ IV-B Supplementary Features ‣ IV Adaptive Aggregator ‣ Towards cost-effective and resource-aware aggregation at Edge for Federated Learning This work is sponsored in part by the NSF under the grants: CSR-2106634/2312785, CCF-1919113/1919075, OAC-2004751, and 3M." class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a> summarizes our emulator evaluation. We tested clients in three global regions, using both small (1000) and large (50k) client numbers, with simpler (CNN4.6) and more complex (CNN478) models. The aggregator server was in Virginia, USA. We measured average client write times and total write times in seconds. Closer locations to the aggregator server (e.g., California) had lower latency, while distant ones (e.g., Seoul) had higher latency due to longer network distances. We also simulated dropouts, randomly dropping 5% of clients as stragglers, which reduced latency, improving performance. This emulator is valuable for assessing parameter server and FL aggregator performance.
<span id="S4.SS2.p1.1.3" class="ltx_text ltx_font_bold">Other Multi-node Methods: </span>

We also did an experimental evaluation with Dask, however, it performed less efficiently than Spark due to spending more time on I/O and conversion to its native Bag type. Spark offers better read-and-write throughput with cloud storage and efficiently partitions data for MapReduce computations.
<span id="S4.SS2.p1.1.4" class="ltx_text ltx_font_bold">Seamless Transition: </span>
The adaptive aggregation service seamlessly switches methodologies for different workload sizes to avoid disrupting clients during FL. The I/O channel remains the same in all methods, facilitating smooth transitions. We use the WebHDFS Rest API for HDFS transfers and the Boto3 AWS SDK for Python for S3 storage and retrieval. Clients employ the same APIs for updates. Serverless startup costs are minimal, while Spark context startup costs are hidden during training.
<span id="S4.SS2.p1.1.5" class="ltx_text ltx_font_bold">Deployment to the Edge: </span>
The adaptive aggregator can be deployed at the edge using services like AWS Lambda@Edge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib54" title="" class="ltx_ref">54</a>]</cite>, AzureIoTEdge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib55" title="" class="ltx_ref">55</a>]</cite>, and OpenEdge <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib56" title="" class="ltx_ref">56</a>]</cite> for serverless deployment. Numba can run on a simple Linux container, and Spark on Linux-based nodes.
<span id="S4.SS2.p1.1.6" class="ltx_text ltx_font_bold">Convergence Guarantees: </span>
In terms of convergence guarantees, the adaptive aggregator ensures the same level of convergence as other systems, as it uses the same fusion algorithm and formula. The difference lies only in the computation technique, without affecting the number of training rounds or final accuracy.</p>
</div>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Related Work</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p"><em id="S5.p1.1.1" class="ltx_emph ltx_font_italic">Heterogeneity Aware FL: </em>
Lai et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> proposes Oort, a new participation selection scheme for FL clients. This work looks at improving efficiency from the client’s side. It evaluates up to 1.3k clients with small-sized models, out of which 100 are selected by default for aggregation which is approximately 1000X less than the scale we demonstrate.
<em id="S5.p1.1.2" class="ltx_emph ltx_font_italic">Hierarchical Aggregation: </em>
Bonawitz et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> suggest selecting a smaller ratio from available clients to train and creating a hierarchy in the aggregator for scaling but this increases the number of rounds to converge.
Liu et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite> suggest a hierarchical FL system in which partial aggregation is done at the edge to distribute load but does not consider the fault tolerance or robustness in the edge and cloud aggregators.
Having such geographically distributed partial aggregators increases communication time between aggregators and adds extra I/O at each partial aggregator. This work only claims to support up to 1000 lightweight clients in cross-device settings and only a few heavier model clients in cross-silo settings.
<em id="S5.p1.1.3" class="ltx_emph ltx_font_italic">Serverless Aggregation: </em>
Grafberger et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> propose a serverless solution for both the client and the server. Due to the short-lived nature of Lambda functions it needs to create special provisions to support larger model training and does not mention aggregator scalability.
Jayaram et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> suggest a serverless aggregator which is horizontally scalable with a Kubernetes <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib57" title="" class="ltx_ref">57</a>]</cite> cluster. This reduces the cost of aggregation by using the pay-to-execute model with serverless functions but has the same limitations as <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib58" title="" class="ltx_ref">58</a>]</cite> proposes PAPAYA: An asynchronous FL system, however in this paper our main focus is on synchronous FL solutions.
Almost all the fore-mentioned methods assume that there are unlimited network, computation, and memory resources at the Edge, which is unrealistic. In addition, these static techniques are all cloud-based solutions that cannot handle each workload with cost-effectiveness and resource-efficiency, leading to a degradation in the QoS for the user. Furthermore, none of the works tackle all three challenges of scalability, efficiency, and cost reduction.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">VI </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">FL is increasingly used in Edge and IoT with edge data center servers to cut communication costs. However, conventional cloud-based aggregators, designed for unlimited resources, face challenges with scalability and efficiency, resulting in higher latency and costs. This study introduces an adaptive aggregator that selects from three methodologies to improve scalability and resource efficiency, and to reduce costs and latency. This adaptive approach also provides users control over cost and efficiency, offering insights into FL aggregation’s challenges in edge data centers for IoT and Edge applications, emphasizing the need for flexible solutions.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
M. Abadi <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Tensorflow: a system for large-scale machine
learning.” in <em id="bib.bib1.2.2" class="ltx_emph ltx_font_italic">OSDI</em>, 2016.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
T. Chilimbi <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Project adam: Building an efficient and scalable
deep learning training system,” in <em id="bib.bib2.2.2" class="ltx_emph ltx_font_italic">OSDI</em>, 2014.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
H. Ali <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Acadia: Efficient and robust adversarial attacks
against deep reinforcement learning,” in <em id="bib.bib3.2.2" class="ltx_emph ltx_font_italic">IEEE CNS</em>, 2022.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
A. Act, “Health insurance portability and accountability act of 1996,”
<em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Public law</em>, vol. 104, p. 191, 1996.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
G. D. P. Regulation, “General data protection regulation (gdpr),”
<em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Intersoft Consulting, Accessed in October</em>, vol. 24, no. 1, 2018.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
B. McMahan <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Communication-efficient learning of deep networks
from decentralized data,” in <em id="bib.bib6.2.2" class="ltx_emph ltx_font_italic">AISTATS</em>, 2017.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
A. Maroli <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Applications of iot for achieving sustainability in
agricultural sector: A comprehensive review,” <em id="bib.bib7.2.2" class="ltx_emph ltx_font_italic">Journal of Environmental
Management</em>, vol. 298, p. 113488, 2021.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
K. S. Arikumar <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Fl-pmi: Federated learning-based person
movement identification through wearable devices in smart healthcare
systems,” <em id="bib.bib8.2.2" class="ltx_emph ltx_font_italic">Sensors</em>, vol. 22, 2022.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
M. Abdel-Basset <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated intrusion detection in
blockchain-based smart transportation systems,” <em id="bib.bib9.2.2" class="ltx_emph ltx_font_italic">IEEE Transactions on
Intelligent Transportation Systems</em>, pp. 2523–2537, 2022.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
T. Zhang <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning for the internet of things:
Applications, challenges, and opportunities,” <em id="bib.bib10.2.2" class="ltx_emph ltx_font_italic">IEEE Internet of Things
Magazine</em>, pp. 24–29, 2022.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
K. A. Bonawitz <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Towards federated learning at scale: System
design,” in <em id="bib.bib11.2.2" class="ltx_emph ltx_font_italic">SysML 2019</em>, 2019.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
F. Lai <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Oort: Efficient federated learning via guided
participant selection,” in <em id="bib.bib12.2.2" class="ltx_emph ltx_font_italic">15th USENIX Symposium on Operating
Systems Design and Implementation (OSDI 21)</em>, 2021, pp. 19–35.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
P. Kairouz <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Advances and open problems in federated learning,”
2019. [Online]. Available: <a target="_blank" href="https://arxiv.org/abs/1912.04977" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://arxiv.org/abs/1912.04977</a>

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Gartner <em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Predicts 2022: The distributed enterprise drives
computing to the edge,” <a href="www.gartner.com/document/4007176" title="" class="ltx_ref ltx_url ltx_font_typewriter">www.gartner.com/document/4007176</a>, 2022.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
J. Kone <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning: Strategies for improving
communication efficiency,” <em id="bib.bib15.2.2" class="ltx_emph ltx_font_italic">CoRR</em>, 2016.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
M. Ekmefjord <em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Scalable federated machine learning with fedn,”
<em id="bib.bib16.2.2" class="ltx_emph ltx_font_italic">arXiv</em>, 2021.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
A. Grafberger <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Fedless: Secure and scalable federated learning
using serverless computing,” in <em id="bib.bib17.2.2" class="ltx_emph ltx_font_italic">IEEE Big Data</em>, 2021, pp. 164–173.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
K. R. Jayaram <em id="bib.bib18.2.1" class="ltx_emph ltx_font_italic">et al.</em>, “<math id="bib.bib18.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="bib.bib18.1.m1.1a"><mi id="bib.bib18.1.m1.1.1" xref="bib.bib18.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="bib.bib18.1.m1.1b"><ci id="bib.bib18.1.m1.1.1.cmml" xref="bib.bib18.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="bib.bib18.1.m1.1c">\lambda</annotation></semantics></math>-fl : Serverless aggregation for
federated learning,” 2022.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
G. A. Reina <em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Openfl: An open-source framework for federated
learning,” 2021.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
H. Ludwig <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Ibm federated learning: an enterprise framework
white paper v0. 1,” 2020.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
M. Abadi, “TensorFlow: Large-scale machine learning on heterogeneous
systems,” 2015. [Online]. Available: <a href="www.tensorflow.org/" title="" class="ltx_ref ltx_url ltx_font_typewriter">www.tensorflow.org/</a>

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
G. Premsankar <em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Edge computing for the internet of things: A
case study,” <em id="bib.bib22.2.2" class="ltx_emph ltx_font_italic">IEEE IoT-J</em>, pp. 1275–1284, 2018.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
I. Thangakrishnan <em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Herring: Rethinking the parameter server at
scale for the cloud,” in <em id="bib.bib23.2.2" class="ltx_emph ltx_font_italic">SC</em>, 2020.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock">
L. Liu <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Client-edge-cloud hierarchical federated learning,” in
<em id="bib.bib24.2.2" class="ltx_emph ltx_font_italic">ICC</em>, 2020, pp. 1–6.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock">
M. Zaharia <em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Spark: Cluster computing with working sets,” in
<em id="bib.bib25.2.2" class="ltx_emph ltx_font_italic">USENIX Conference on Hot Topics in Cloud Computing</em>, 2010.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock">
D. Yin <em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Byzantine-robust distributed learning: Towards
optimal statistical rates,” in <em id="bib.bib26.2.2" class="ltx_emph ltx_font_italic">ICML</em>, 2018.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock">
D. Dimitriadis <em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Flute: A scalable, extensible framework for
high-performance federated learning simulations,” 2022.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock">
M. Aledhari <em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning: A survey on enabling
technologies, protocols, and applications,” <em id="bib.bib28.2.2" class="ltx_emph ltx_font_italic">IEEE Access</em>, 2020.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock">
A. F. Khan <em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Pi-fl: Personalized and incentivized federated
learning,” <em id="bib.bib29.2.2" class="ltx_emph ltx_font_italic">arXiv</em>, 2023.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock">
J. Han <em id="bib.bib30.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Tiff: Tokenized incentive for federated learning,” in
<em id="bib.bib30.2.2" class="ltx_emph ltx_font_italic">IEEE CLOUD</em>, 2022, pp. 407–416.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock">
M. M. Hossain <em id="bib.bib31.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Towards an analysis of security issues,
challenges, and open problems in the internet of things,” in <em id="bib.bib31.2.2" class="ltx_emph ltx_font_italic">2015 IEEE
World Congress on Services</em>, 2015.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock">
H. Ali <em id="bib.bib32.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “A survey on attacks and their countermeasures in deep
learning: Applications in deep neural networks, federated, transfer, and deep
reinforcement learning,” <em id="bib.bib32.2.2" class="ltx_emph ltx_font_italic">IEEE Access</em>, vol. 11, 2023.

</span>
</li>
<li id="bib.bib33" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock">
J. Han <em id="bib.bib33.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Heterogeneity-aware adaptive federated learning
scheduling,” in <em id="bib.bib33.2.2" class="ltx_emph ltx_font_italic">IEEE Big Data</em>, 2022, pp. 911–920.

</span>
</li>
<li id="bib.bib34" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock">
Y. Jiang <em id="bib.bib34.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Model pruning enables efficient federated learning on
edge devices,” <em id="bib.bib34.2.2" class="ltx_emph ltx_font_italic">IEEE TNLS</em>, 2022.

</span>
</li>
<li id="bib.bib35" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock">
A. Albasyoni <em id="bib.bib35.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Optimal gradient compression for distributed and
federated learning,” <em id="bib.bib35.2.2" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/2010.03246, 2020.

</span>
</li>
<li id="bib.bib36" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock">
S. Zheng <em id="bib.bib36.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Design and analysis of uplink and downlink
communications for federated learning,” <em id="bib.bib36.2.2" class="ltx_emph ltx_font_italic">IEEE Journal on Selected Areas
in Communications</em>, vol. 39, pp. 2150–2167, 2021.

</span>
</li>
<li id="bib.bib37" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock">
S. Yu <em id="bib.bib37.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Spatl: Salient parameter aggregation and transfer
learning for heterogeneous clients in federated learning,” 2021.

</span>
</li>
<li id="bib.bib38" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock">
J. Mace <em id="bib.bib38.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “2dfq: Two-dimensional fair queuing for multi-tenant
cloud services,” in <em id="bib.bib38.2.2" class="ltx_emph ltx_font_italic">SIGCOMM</em>, 2016.

</span>
</li>
<li id="bib.bib39" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock">
B. P. Rimal and M. Maier, “Workflow scheduling in multi-tenant cloud computing
environments,” <em id="bib.bib39.1.1" class="ltx_emph ltx_font_italic">IEEE TPDS</em>, 2017.

</span>
</li>
<li id="bib.bib40" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[40]</span>
<span class="ltx_bibblock">
J. Pan and J. McElhannon, “Future edge cloud and edge computing for internet
of things applications,” <em id="bib.bib40.1.1" class="ltx_emph ltx_font_italic">IEEE IoT-J</em>, 2018 pages=439-449,.

</span>
</li>
<li id="bib.bib41" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[41]</span>
<span class="ltx_bibblock">
S. Dey <em id="bib.bib41.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Challenges of using edge devices in iot computation
grids,” in <em id="bib.bib41.2.2" class="ltx_emph ltx_font_italic">ICPADS</em>, 2013.

</span>
</li>
<li id="bib.bib42" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[42]</span>
<span class="ltx_bibblock">
J. Kang <em id="bib.bib42.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Reliable federated learning for mobile networks,”
<em id="bib.bib42.2.2" class="ltx_emph ltx_font_italic">IEEE Wireless Communications</em>, 2020.

</span>
</li>
<li id="bib.bib43" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[43]</span>
<span class="ltx_bibblock">
S. Khalid and C. Brown, “Software engineering approaches adopted by blockchain
developers,” in <em id="bib.bib43.1.1" class="ltx_emph ltx_font_italic">IEEE SDS</em>, 2023.

</span>
</li>
<li id="bib.bib44" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[44]</span>
<span class="ltx_bibblock">
K. He <em id="bib.bib44.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Deep residual learning for image recognition,” 2015.

</span>
</li>
<li id="bib.bib45" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[45]</span>
<span class="ltx_bibblock">
K. Simonyan and A. Zisserman, “Very deep convolutional networks for
large-scale image recognition,” 2014.

</span>
</li>
<li id="bib.bib46" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[46]</span>
<span class="ltx_bibblock">
V. K. Vavilapalli <em id="bib.bib46.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Apache hadoop yarn: yet another resource
negotiator,” <em id="bib.bib46.2.2" class="ltx_emph ltx_font_italic">SOCC</em>, 2013.

</span>
</li>
<li id="bib.bib47" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[47]</span>
<span class="ltx_bibblock">
C. Xie <em id="bib.bib47.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Zeno: Byzantine-suspicious stochastic gradient
descent,” <em id="bib.bib47.2.2" class="ltx_emph ltx_font_italic">CoRR</em>, vol. abs/1805.10032, 2018.

</span>
</li>
<li id="bib.bib48" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[48]</span>
<span class="ltx_bibblock">
C. R. Harris <em id="bib.bib48.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Array programming with NumPy,” <em id="bib.bib48.2.2" class="ltx_emph ltx_font_italic">Nature</em>,
vol. 585, pp. 357–362, 2020.

</span>
</li>
<li id="bib.bib49" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[49]</span>
<span class="ltx_bibblock">
S. K. Lam <em id="bib.bib49.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Numba: A llvm-based python jit compiler,” in
<em id="bib.bib49.2.2" class="ltx_emph ltx_font_italic">Workshop on the LLVM Compiler Infrastructure in HPC</em>, 2015.

</span>
</li>
<li id="bib.bib50" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[50]</span>
<span class="ltx_bibblock">
D. J. Beutel <em id="bib.bib50.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Flower: A friendly federated learning research
framework,” 2022.

</span>
</li>
<li id="bib.bib51" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[51]</span>
<span class="ltx_bibblock">
Y. Niu <em id="bib.bib51.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Federated learning of large models at the edge via
principal sub-model training,” in <em id="bib.bib51.2.2" class="ltx_emph ltx_font_italic">Workshop on Federated Learning:
Recent Advances and New Challenges (in Conjunction with NIPS)</em>, 2022.

</span>
</li>
<li id="bib.bib52" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[52]</span>
<span class="ltx_bibblock">
K. Sudhakar, “Amazon web services (aws) glue,” <em id="bib.bib52.1.1" class="ltx_emph ltx_font_italic">International Journal of
Management, IT and Engineering</em>, vol. 8, pp. 108–122, 2018.

</span>
</li>
<li id="bib.bib53" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[53]</span>
<span class="ltx_bibblock">
T.-C. Chiu <em id="bib.bib53.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Semisupervised distributed learning with non-iid
data for aiot service platform,” <em id="bib.bib53.2.2" class="ltx_emph ltx_font_italic">IEEE IoT-J</em>, pp. 9266–9277, 2020.

</span>
</li>
<li id="bib.bib54" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[54]</span>
<span class="ltx_bibblock">
“AWS Lambda@Edge,” <a target="_blank" href="https://aws.amazon.com/lambda/edge/" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://aws.amazon.com/lambda/edge/</a>.

</span>
</li>
<li id="bib.bib55" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[55]</span>
<span class="ltx_bibblock">
Microsoft, “Azure iot edge,” <a target="_blank" href="https://github.com/Azure/iotedge" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Azure/iotedge</a>, 2021.

</span>
</li>
<li id="bib.bib56" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[56]</span>
<span class="ltx_bibblock">
Baidu, “Openedge,” <a target="_blank" href="https://github.com/baidu/openedge" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/baidu/openedge</a>, 2021.

</span>
</li>
<li id="bib.bib57" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[57]</span>
<span class="ltx_bibblock">
“Kubernetes Manual,” 2017.

</span>
</li>
<li id="bib.bib58" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[58]</span>
<span class="ltx_bibblock">
D. Huba <em id="bib.bib58.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Papaya: Practical, private, and scalable federated
learning,” in <em id="bib.bib58.2.2" class="ltx_emph ltx_font_italic">Proceedings of Machine Learning and Systems</em>, 2022.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2204.07766" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2204.07767" class="ar5iv-text-button ar5iv-severity-error">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2204.07767">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2204.07767" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2204.07768" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Wed Feb 28 08:03:22 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
