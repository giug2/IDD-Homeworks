<!DOCTYPE html>
<html lang="en">
<head>
<meta content="text/html; charset=utf-8" http-equiv="content-type"/>
<title>Human-Centered Design Recommendations for LLM-as-a-Judge</title>
<!--Generated on Wed Jul  3 19:42:33 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport"/>
<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/ar5iv-fonts.0.7.9.min.css" rel="stylesheet" type="text/css"/>
<link href="/static/browse/0.3.4/css/latexml_styles.css" rel="stylesheet" type="text/css"/>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.0/dist/js/bootstrap.bundle.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/html2canvas/1.3.3/html2canvas.min.js"></script>
<script src="/static/browse/0.3.4/js/addons_new.js"></script>
<script src="/static/browse/0.3.4/js/feedbackOverlay.js"></script>
<base href="/html/2407.03479v1/"/></head>
<body>
<nav class="ltx_page_navbar">
<nav class="ltx_TOC">
<ol class="ltx_toclist">
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S1" title="In Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">1 </span>Introduction</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S2" title="In Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">2 </span>Related work</span></a></li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S3" title="In Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3 </span>EvaluLLM</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S3.SS1" title="In 3 EvaluLLM ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.1 </span>Build</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S3.SS2" title="In 3 EvaluLLM ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.2 </span>Review</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S3.SS3" title="In 3 EvaluLLM ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">3.3 </span>Inspect</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S4" title="In Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4 </span>Methodology</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S4.SS1" title="In 4 Methodology ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.1 </span>Participants</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S4.SS2" title="In 4 Methodology ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">4.2 </span>Data Analysis</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S5" title="In Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5 </span>Results</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S5.SS1" title="In 5 Results ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.1 </span>Use Case Challenges</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S5.SS2" title="In 5 Results ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.2 </span>Evaluation Criteria</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S5.SS3" title="In 5 Results ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.3 </span>Evaluation Workflow</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S5.SS4" title="In 5 Results ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">5.4 </span>Limitations</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section">
<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S6" title="In Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6 </span>Discussion and Design Recommendations</span></a>
<ol class="ltx_toclist ltx_toclist_section">
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S6.SS1" title="In 6 Discussion and Design Recommendations ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.1 </span>Efficient Criteria Iteration</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S6.SS2" title="In 6 Discussion and Design Recommendations ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.2 </span>Structured and Customizable Templates</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S6.SS3" title="In 6 Discussion and Design Recommendations ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.3 </span>Interactive Criteria Iteration</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S6.SS4" title="In 6 Discussion and Design Recommendations ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.4 </span>Ensure Consistency</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S6.SS5" title="In 6 Discussion and Design Recommendations ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.5 </span>Support Different Setups</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S6.SS6" title="In 6 Discussion and Design Recommendations ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.6 </span>Adaptable Reference-Based Evaluation</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S6.SS7" title="In 6 Discussion and Design Recommendations ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.7 </span>Enhance System Transparency</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S6.SS8" title="In 6 Discussion and Design Recommendations ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.8 </span>Proactively Mitigate Potential Bias</span></a></li>
<li class="ltx_tocentry ltx_tocentry_subsection"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S6.SS9" title="In 6 Discussion and Design Recommendations ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">6.9 </span>Explore Further Automation</span></a></li>
</ol>
</li>
<li class="ltx_tocentry ltx_tocentry_section"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S7" title="In Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">7 </span>Conclusion</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A1" title="In Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">A </span>Participant Information</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A2" title="In Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">B </span>Summary of Evaluation Themes and Examples</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A3" title="In Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">C </span>Recommended Designs</span></a></li>
<li class="ltx_tocentry ltx_tocentry_appendix"><a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A4" title="In Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_title"><span class="ltx_tag ltx_tag_ref">D </span>EvaluLLM Evaluation Workflow</span></a></li>
</ol></nav>
</nav>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document">
<h1 class="ltx_title ltx_title_document">Human-Centered Design Recommendations for LLM-as-a-Judge</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Qian Pan 
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Zahra Ashktorab
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Michael Desmond
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Martin Santillan Cooper 
<br class="ltx_break"/><span class="ltx_text ltx_font_bold" id="id1.1.id1">James Johnson  and Rahul Nair  and Elizabeth Daly  and Werner Geyer</span>
<br class="ltx_break"/>IBM Research
</span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Qian Pan 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id2.1.id1">Qian.Pan@ibm.com
<br class="ltx_break"/></span>IBM Research 
<br class="ltx_break"/>Cambridge, MA, USA
<span class="ltx_ERROR undefined" id="id3.2.id2">\And</span>Zahra Ashktorab 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id4.3.id3">zahra.ashktorab1@ibm.com</span>
<br class="ltx_break"/>IBM Research
<br class="ltx_break"/>Yorktown Heights, NY, USA
<span class="ltx_ERROR undefined" id="id5.4.id4">\And</span>Michael Desmond 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id6.5.id5">mdesmond@us.ibm.com</span>
<br class="ltx_break"/>IBM Research
<br class="ltx_break"/>Yorktown Heights, NY, USA
<span class="ltx_ERROR undefined" id="id7.6.id6">\AND</span>Martin Santillan Cooper 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id8.7.id7">msantillancooper@ibm.com
<br class="ltx_break"/></span>IBM Research 
<br class="ltx_break"/>Capital Federal, Argentina
<span class="ltx_ERROR undefined" id="id9.8.id8">\And</span>James Johnson 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id10.9.id9">jmjohnson@us.ibm.com</span>
<br class="ltx_break"/>IBM Research
<br class="ltx_break"/>Cambridge, MA, USA
<span class="ltx_ERROR undefined" id="id11.10.id10">\And</span>Rahul Nair 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id12.11.id11">rahul.nair@ie.ibm.com</span>
<br class="ltx_break"/>IBM Research
<br class="ltx_break"/>Mulhuddart, Dublin, Ireland
<span class="ltx_ERROR undefined" id="id13.12.id12">\AND</span>Elizabeth Daly 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id14.13.id13">elizabeth.daly@ie.ibm.com
<br class="ltx_break"/></span>IBM Research 
<br class="ltx_break"/>Mulhuddart, Dublin, Ireland
<span class="ltx_ERROR undefined" id="id15.14.id14">\And</span>Werner Geyer 
<br class="ltx_break"/><span class="ltx_text ltx_font_typewriter" id="id16.15.id15">werner.geyer@us.ibm.com</span>
<br class="ltx_break"/>IBM Research
<br class="ltx_break"/>Cambridge, MA, USA
</span></span>
</div>
<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p" id="id17.id1">Traditional reference-based metrics, such as BLEU and ROUGE, are less effective for assessing outputs from Large Language Models (LLMs) that produce highly creative or superior-quality text, or in situations where reference outputs are unavailable. While human evaluation remains an option, it is costly and difficult to scale. Recent work using LLMs as evaluators (LLM-as-a-judge) is promising, but trust and reliability remain a significant concern. Integrating human input is crucial to ensure criteria used to evaluate are aligned with the human’s intent, and evaluations are robust and consistent. This paper presents a user study of a design exploration called EvaluLLM, that enables users to leverage LLMs as customizable judges, promoting human involvement to balance trust and cost-saving potential with caution. Through interviews with eight domain experts, we identified the need for assistance in developing effective evaluation criteria aligning the LLM-as-a-judge with practitioners’ preferences and expectations. We offer findings and design recommendations to optimize human-assisted LLM-as-judge systems.</p>
</div>
<div class="ltx_para ltx_noindent" id="p1">
<div class="ltx_block ltx_align_bottom" id="p1.1">
<p class="ltx_p" id="p1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.1.1">Human-Centered Design Recommendations for LLM-as-a-Judge</span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.1.2" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.1.2.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.2.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.2.1.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.1.1.1.1.1.1">Qian Pan</span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.2.2">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.2.2.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.2.1.1.2.2.1.1">Qian.Pan@ibm.com</span></span></span>
<span class="ltx_tr" id="p1.1.2.1.1.3.3">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.3.3.1">IBM Research</span></span>
<span class="ltx_tr" id="p1.1.2.1.1.4.4">
<span class="ltx_td ltx_align_center" id="p1.1.2.1.1.4.4.1">Cambridge, MA, USA</span></span>
</span>
</span></span>                      <span class="ltx_text ltx_inline-block" id="p1.1.2.2" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.2.2.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.2.2.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.2.2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.2.1.1.1.1.1">Zahra Ashktorab</span></span></span>
<span class="ltx_tr" id="p1.1.2.2.1.2.2">
<span class="ltx_td ltx_align_center" id="p1.1.2.2.1.2.2.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.2.2.1.2.2.1.1">zahra.ashktorab1@ibm.com</span></span></span>
<span class="ltx_tr" id="p1.1.2.2.1.3.3">
<span class="ltx_td ltx_align_center" id="p1.1.2.2.1.3.3.1">IBM Research</span></span>
<span class="ltx_tr" id="p1.1.2.2.1.4.4">
<span class="ltx_td ltx_align_center" id="p1.1.2.2.1.4.4.1">Yorktown Heights, NY, USA</span></span>
</span>
</span></span>                      <span class="ltx_text ltx_inline-block" id="p1.1.2.3" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.2.3.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.2.3.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.2.3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.2.3.1.1.1.1.1">Michael Desmond</span></span></span>
<span class="ltx_tr" id="p1.1.2.3.1.2.2">
<span class="ltx_td ltx_align_center" id="p1.1.2.3.1.2.2.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.2.3.1.2.2.1.1">mdesmond@us.ibm.com</span></span></span>
<span class="ltx_tr" id="p1.1.2.3.1.3.3">
<span class="ltx_td ltx_align_center" id="p1.1.2.3.1.3.3.1">IBM Research</span></span>
<span class="ltx_tr" id="p1.1.2.3.1.4.4">
<span class="ltx_td ltx_align_center" id="p1.1.2.3.1.4.4.1">Yorktown Heights, NY, USA</span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.1.3" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.1.3.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.3.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.3.1.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.3.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.3.1.1.1.1.1.1">Martin Santillan Cooper</span></span></span>
<span class="ltx_tr" id="p1.1.3.1.1.2.2">
<span class="ltx_td ltx_align_center" id="p1.1.3.1.1.2.2.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.3.1.1.2.2.1.1">msantillancooper@ibm.com</span></span></span>
<span class="ltx_tr" id="p1.1.3.1.1.3.3">
<span class="ltx_td ltx_align_center" id="p1.1.3.1.1.3.3.1">IBM Research</span></span>
<span class="ltx_tr" id="p1.1.3.1.1.4.4">
<span class="ltx_td ltx_align_center" id="p1.1.3.1.1.4.4.1">Capital Federal, Argentina</span></span>
</span>
</span></span>                      <span class="ltx_text ltx_inline-block" id="p1.1.3.2" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.3.2.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.3.2.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.3.2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.3.2.1.1.1.1.1">James Johnson</span></span></span>
<span class="ltx_tr" id="p1.1.3.2.1.2.2">
<span class="ltx_td ltx_align_center" id="p1.1.3.2.1.2.2.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.3.2.1.2.2.1.1">jmjohnson@us.ibm.com</span></span></span>
<span class="ltx_tr" id="p1.1.3.2.1.3.3">
<span class="ltx_td ltx_align_center" id="p1.1.3.2.1.3.3.1">IBM Research</span></span>
<span class="ltx_tr" id="p1.1.3.2.1.4.4">
<span class="ltx_td ltx_align_center" id="p1.1.3.2.1.4.4.1">Cambridge, MA, USA</span></span>
</span>
</span></span>                      <span class="ltx_text ltx_inline-block" id="p1.1.3.3" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.3.3.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.3.3.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.3.3.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.3.3.1.1.1.1.1">Rahul Nair</span></span></span>
<span class="ltx_tr" id="p1.1.3.3.1.2.2">
<span class="ltx_td ltx_align_center" id="p1.1.3.3.1.2.2.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.3.3.1.2.2.1.1">rahul.nair@ie.ibm.com</span></span></span>
<span class="ltx_tr" id="p1.1.3.3.1.3.3">
<span class="ltx_td ltx_align_center" id="p1.1.3.3.1.3.3.1">IBM Research</span></span>
<span class="ltx_tr" id="p1.1.3.3.1.4.4">
<span class="ltx_td ltx_align_center" id="p1.1.3.3.1.4.4.1">Mulhuddart, Dublin, Ireland</span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
<p class="ltx_p ltx_align_center" id="p1.1.4" style="width:433.6pt;"><span class="ltx_text ltx_inline-block" id="p1.1.4.1" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.4.1.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.4.1.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.4.1.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.4.1.1.1.1.1.1">Elizabeth Daly</span></span></span>
<span class="ltx_tr" id="p1.1.4.1.1.2.2">
<span class="ltx_td ltx_align_center" id="p1.1.4.1.1.2.2.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.4.1.1.2.2.1.1">elizabeth.daly@ie.ibm.com</span></span></span>
<span class="ltx_tr" id="p1.1.4.1.1.3.3">
<span class="ltx_td ltx_align_center" id="p1.1.4.1.1.3.3.1">IBM Research</span></span>
<span class="ltx_tr" id="p1.1.4.1.1.4.4">
<span class="ltx_td ltx_align_center" id="p1.1.4.1.1.4.4.1">Mulhuddart, Dublin, Ireland</span></span>
</span>
</span></span>                      <span class="ltx_text ltx_inline-block" id="p1.1.4.2" style="width:0.0pt;">
<span class="ltx_tabular ltx_align_top" id="p1.1.4.2.1">
<span class="ltx_tbody">
<span class="ltx_tr" id="p1.1.4.2.1.1.1">
<span class="ltx_td ltx_align_center" id="p1.1.4.2.1.1.1.1"><span class="ltx_text ltx_font_bold" id="p1.1.4.2.1.1.1.1.1">Werner Geyer</span></span></span>
<span class="ltx_tr" id="p1.1.4.2.1.2.2">
<span class="ltx_td ltx_align_center" id="p1.1.4.2.1.2.2.1"><span class="ltx_text ltx_font_typewriter" id="p1.1.4.2.1.2.2.1.1">werner.geyer@us.ibm.com</span></span></span>
<span class="ltx_tr" id="p1.1.4.2.1.3.3">
<span class="ltx_td ltx_align_center" id="p1.1.4.2.1.3.3.1">IBM Research</span></span>
<span class="ltx_tr" id="p1.1.4.2.1.4.4">
<span class="ltx_td ltx_align_center" id="p1.1.4.2.1.4.4.1">Cambridge, MA, USA</span></span>
</span>
</span></span></p>
<br class="ltx_break ltx_centering"/>
</div>
</div>
<section class="ltx_section" id="S1">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>
<div class="ltx_para" id="S1.p1">
<p class="ltx_p" id="S1.p1.1">Recent advancements in Large Language Models (LLMs) challenge traditional methods of assessing natural language generation (NLG) quality, as known metrics, such as BLEU <cite class="ltx_cite ltx_citemacro_cite">Papineni et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib16" title="">2002</a>)</cite> and ROUGE <cite class="ltx_cite ltx_citemacro_cite">Lin (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib13" title="">2004</a>)</cite>, fall short for creative tasks. The diverse and expanding capabilities of LLMs <cite class="ltx_cite ltx_citemacro_cite">Liang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib12" title="">2022</a>)</cite> present a selection challenge for practitioners, requiring evaluations of extensive outputs across contexts like summarization and retrieval-augmented generation (RAG). The subjective and use case-specific nature of emerging NLG tasks often demands human review, making the evaluation process hard to scale without suitable automatic metrics. While experts can perform evaluations, this is costly and impractical for rapid iteration in early development stages. <cite class="ltx_cite ltx_citemacro_cite">Gehrmann et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib7" title="">2023</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S1.p2">
<p class="ltx_p" id="S1.p2.1">One potential solution to these challenges is to leverage the capabilities of LLMs to aid in the evaluation process. Despite not always being accurate, LLMs have the potential to significantly reduce the workload by identifying outputs where they are not confident, thus indicating where human input may be required. Additionally, LLMs can assist practitioners in identifying and customizing criteria specific to their use case—such as, for example, faithfulness to contextual information, naturalness of the conversation, and succinctness—with which they wish to conduct their evaluations. This customization enables a more targeted and effective assessment of model outputs, tailored to the specific requirements of their tasks. In this paper, we present results from a user study of EvaluLLM <cite class="ltx_cite ltx_citemacro_cite">Desmond et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib3" title="">2024</a>)</cite>, a tool designed to facilitate the evaluation of model outputs. EvaluLLM simplifies how practitioners choose LLMs by offering a quick way to assess and compare their performance across various tasks. This method accelerates the development of evaluation criteria and helps manage the growing variety and capabilities of LLMs.</p>
</div>
<div class="ltx_para" id="S1.p3">
<p class="ltx_p" id="S1.p3.1">To understand the challenges and user needs in model evaluation that leverage LLM-as-a-Judge to automate the process, we conducted formative, semi-structured interviews with 8 practitioners (data scientists, software engineers, and AI engineers) who have been involved in model performance evaluation projects over the past year. Our interviews revealed various challenges and needs. For instance, practitioners highlighted the necessity for rapid performance comparison across different setups, the importance of defining evaluation criteria (e.g., structured and customizable templates aligned with specific use cases), and strategies for effectively integrating LLM-as-a-Judge into their workflow (e.g., starting with a small subset of data before scaling up).
In this paper, we present the following contributions:</p>
</div>
<div class="ltx_para" id="S1.p4">
<ul class="ltx_itemize" id="S1.I1">
<li class="ltx_item" id="S1.I1.i1" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i1.p1">
<p class="ltx_p" id="S1.I1.i1.p1.1">We describe EvaluLLM <cite class="ltx_cite ltx_citemacro_cite">Desmond et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib3" title="">2024</a>)</cite>,
an LLM-Assisted evaluation tool that enables users to select multiple models, define custom metrics for NLG evaluation, and review the results while providing feedback to observe the agreement between human and AI evaluations.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i2" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i2.p1">
<p class="ltx_p" id="S1.I1.i2.p1.1">We present qualitative findings from interviews with domain experts (N = 8) revealing challenges and user needs for model evaluation workflows including LLM-as-a-judge.</p>
</div>
</li>
<li class="ltx_item" id="S1.I1.i3" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span>
<div class="ltx_para" id="S1.I1.i3.p1">
<p class="ltx_p" id="S1.I1.i3.p1.1">We make design recommendations and provide example feature designs to enable users to define criteria interactively, ensuring transparent and rapid access to LLM-as-a-judge’s preferences while balancing trade-offs across multiple dimensions in a self-consistent manner.</p>
</div>
</li>
</ul>
</div>
</section>
<section class="ltx_section" id="S2">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>
<div class="ltx_para" id="S2.p1">
<p class="ltx_p" id="S2.p1.1">LLMs trained to follow instructions can generate results that surpass the quality of data produced by humans. This makes it increasingly challenging to assess the quality of natural language generation (NLG) outputs <cite class="ltx_cite ltx_citemacro_cite">Liang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib12" title="">2022</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Xiao et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib26" title="">2023</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib15" title="">2023b</a>)</cite>. Traditional reference-based metrics, such as ROUGE <cite class="ltx_cite ltx_citemacro_cite">Lin (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib13" title="">2004</a>)</cite> and BLEU <cite class="ltx_cite ltx_citemacro_cite">Papineni et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib16" title="">2002</a>)</cite>, might not effectively capture the essence of LLM outputs, especially in scenarios where the output space is broad and varied. This means multiple different outcomes can all be valid, making it nearly impossible to create sufficiently comprehensive reference sets. Consequently, these metrics may not be reliable indicators of NLG output quality, as they often demonstrate a low correlation with human judgments <cite class="ltx_cite ltx_citemacro_cite">Freitag et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib5" title="">2022</a>)</cite>.</p>
</div>
<div class="ltx_para" id="S2.p2">
<p class="ltx_p" id="S2.p2.1">Recent advances highlight LLMs’ potential as customizable judges, <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib14" title="">2023a</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib21" title="">2023a</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib28" title="">2023</a>)</cite> capable of adapting to various tasks beyond traditional evaluation methods. Techniques like G-Eval <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib14" title="">2023a</a>)</cite> use chain-of-thought prompting and form-filling to assess NLG quality, while GPTScore <cite class="ltx_cite ltx_citemacro_cite">Fu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib6" title="">2023</a>)</cite> evaluates using conditional token probabilities, enhancing scoring granularity. AlpacaEval <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib11" title="">2023</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Yuan et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib27" title="">2024</a>)</cite> compares model win rates, and Prometheus <cite class="ltx_cite ltx_citemacro_cite">Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib8" title="">2023a</a>)</cite> is a fine-tuned LLM specifically designed for evaluation tasks. These methods align closely with human preferences, especially in creative tasks, emphasizing LLMs’ ability to mimic human judgment. Their effectiveness relies on tailored prompt design and user-defined criteria for precise evaluations.
While not part of this paper, in our own work, we have also done comprehensive benchmarking of human agreement of different LLM-as-a-judge approaches for different use cases and we found that depending on use case, LLMs as judges, and judging approach, we were able to achieve good results. Note that this is often a hard problem for humans too and inter-rater reliability can be a good reference.</p>
</div>
<div class="ltx_para" id="S2.p3">
<p class="ltx_p" id="S2.p3.1">Previous research has investigated using expert-labeled data to develop custom evaluation metrics like AUTOCALIBRATE <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib15" title="">2023b</a>)</cite>, but this method is limited by the availability of such data. For reference-free evaluations, interactive human involvement is preferable, allowing users to refine criteria effectively by reviewing outputs. ConstitutionMaker <cite class="ltx_cite ltx_citemacro_cite">Petridis et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib17" title="">2023</a>)</cite> enables feedback on model outputs to iteratively refine prompts, focusing more on AI prototyping than evaluation. Other tools like Zeno <cite class="ltx_cite ltx_citemacro_cite">Cabrera et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib1" title="">2023</a>)</cite>, the What-If Tool <cite class="ltx_cite ltx_citemacro_cite">Wexler et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib24" title="">2019</a>)</cite>, and Errudite <cite class="ltx_cite ltx_citemacro_cite">Wu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib25" title="">2019</a>)</cite> help identify model vulnerabilities by analyzing specific data segments.
EvalLM <cite class="ltx_cite ltx_citemacro_cite">Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib9" title="">2023b</a>)</cite> allows users to define criteria interactively, using LLM-as-a-judges for output ratings, although this can be limited by LLM reasoning capabilities <cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib28" title="">2023</a>)</cite>. Our study builds on these insights, proposing a system where practitioners define criteria in natural language for LLMs to perform pairwise comparisons, enhancing trust through a "human-in-the-loop" blind review process that eliminates the need for expert data.</p>
</div>
</section>
<section class="ltx_section" id="S3">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>EvaluLLM</h2>
<div class="ltx_para" id="S3.p1">
<p class="ltx_p" id="S3.p1.1">To explore how to support users in developing their own custom evaluation criteria for accurate and reliable evaluations that align with human preferences in a trustworthy manner, we designed and deployed EvaluLLM <cite class="ltx_cite ltx_citemacro_cite">Desmond et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib3" title="">2024</a>)</cite>. This tool enables users to generate evaluation outputs by providing a prompt, selecting multiple models, and defining LLM-as-a-Judge with custom metrics using natural language. Users can then review the results and provide feedback, inspecting the agreement between human and AI evaluations through a blind review process. In this paper, we use EvaluLLM as a conceptual design probe with users to explore the design space of how to support development of custom evaluation criteria for accurate and reliable evaluations that align with human preferences in a trustworthy manner.</p>
</div>
<div class="ltx_para" id="S3.p2">
<p class="ltx_p" id="S3.p2.1">The overall user flow of EvaluLLM comprises of three stages (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S3.F1" title="Figure 1 ‣ 3 EvaluLLM ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">1</span></a>). The build experience focuses on defining the LLM-assisted evaluation experience to initiate the auto-evaluation process, the review experience, providing a high-level summary of the evaluation results, and the inspect experience allows users to manually examine the generated outputs through a blind review process. The data generated from this process can be used to calculate the agreement rate, assisting practitioners in better assessing the agreement between human and LLM-as-a-judges. This assessment is crucial for calibrating trust and aids in making informed decisions about whether to change configurations and rerun the evaluation.</p>
</div>
<div class="ltx_para" id="S3.p3">
<p class="ltx_p" id="S3.p3.1">In the absence of reference data, related studies suggest that LLMs may not be entirely suitable for use as numerical judges <cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib28" title="">2023</a>)</cite>. This is because grading based on single answers may fail to detect minor distinctions between specific pairs. Furthermore, the outcomes could become unreliable, as absolute scores tend to vary more than relative pairwise results when there are changes in the judging model <cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib28" title="">2023</a>)</cite>. To mitigate these challenges, EvaluLLM uses a pairwise comparison approach, as it can reduce the complexity of the evaluation task by breaking down the comparison of multiple outputs into smaller decisions between pairs of data which might yield to more accurate evaluation results at the cost of additional inference operations. The evaluation method involves making pairwise comparisons between the outputs of different models, similar to the AlpacaEval approach <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib11" title="">2023</a>)</cite>. However, instead of comparing outputs to a single reference, they are compared against one another.</p>
</div>
<figure class="ltx_figure" id="S3.F1"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="257" id="S3.F1.g1" src="extracted/5708510/revfig2.png" width="598"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>EvaluLLM interfaces and key features</figcaption>
</figure>
<section class="ltx_subsection" id="S3.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Build</h3>
<div class="ltx_para" id="S3.SS1.p1">
<p class="ltx_p" id="S3.SS1.p1.1">The build experience (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S3.F1" title="Figure 1 ‣ 3 EvaluLLM ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">1</span></a>) includes two major components: the Generator (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S3.F1" title="Figure 1 ‣ 3 EvaluLLM ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">1</span></a>A) and the Evaluator (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S3.F1" title="Figure 1 ‣ 3 EvaluLLM ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">1</span></a>B).
The Generator section (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S3.F1" title="Figure 1 ‣ 3 EvaluLLM ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">1</span></a>A) is designed to produce evaluation data, supporting users in selecting a pre-uploaded dataset and inputting their task prompts. Users can incorporate data variables from the dataset’s structure into the task prompt using the conventional curly bracket format. Additionally, the system provides a range of LLMs for users to choose from for the purpose of performance evaluation. The Evaluator section (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S3.F1" title="Figure 1 ‣ 3 EvaluLLM ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">1</span></a>B) is where users can choose the LLM-as-a-judge model for automatic evaluation and specify the custom metrics that the judge will use to assess the outputs from the generator. This initial version of EvaluLLM, deliberately provides only a freeform input box to support maximum creativity, as the aim was to gain more insights into the types of inputs users would provide to define criteria in natural language and the kind of support users might need to define custom metrics. Once the user completes the setup, they can click the "Run Evaluation" button to initiate the evaluation.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Review</h3>
<div class="ltx_para" id="S3.SS2.p1">
<p class="ltx_p" id="S3.SS2.p1.1">Upon completion of the automatic evaluation, results are available for review. Users can view a high-level performance summary and a detailed results table. The summary includes a model leader board (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S3.F1" title="Figure 1 ‣ 3 EvaluLLM ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">1</span></a>C), ranking selected LLMs by their win rates derived from evaluated output pairs. The performance visualization (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S3.F1" title="Figure 1 ‣ 3 EvaluLLM ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">1</span></a>D) shows detailed win-loss statistics for each model based on pairwise comparisons by the LLM-as-a-judge. Additionally, the agreement rate (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S3.F1" title="Figure 1 ‣ 3 EvaluLLM ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">1</span></a>E) indicates the alignment between human and LLM-as-judges, helping users gauge the reliability of evaluations. This feature becomes available after users manually rate output samples.</p>
</div>
</section>
<section class="ltx_subsection" id="S3.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Inspect</h3>
<div class="ltx_para" id="S3.SS3.p1">
<p class="ltx_p" id="S3.SS3.p1.1">Users can examine auto-evaluation results through two main methods. First, users can conduct a blind review, manually inspecting data to assess the reliability of LLM evaluations (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S3.F1" title="Figure 1 ‣ 3 EvaluLLM ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">1</span></a>G). In this process, models’ names are hidden to prevent bias, and users select the best output from all presented outputs. Ratings from this process are used to calculate an agreement score, which measures alignment between user and LLM-as-a-judge preferences (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S3.F1" title="Figure 1 ‣ 3 EvaluLLM ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">1</span></a>E, I). After rating, users can view model identities and the updated agreement score (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S3.F1" title="Figure 1 ‣ 3 EvaluLLM ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">1</span></a>H, I), providing insight into the effectiveness of the evaluation criteria. Users can also access detailed results on the review page, which displays the LLM-as-a-Judge’s aggregated rankings and win rates from pairwise comparisons (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S3.F1" title="Figure 1 ‣ 3 EvaluLLM ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">1</span></a>J). Evaluation rationales are provided next to each comparison result (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S3.F1" title="Figure 1 ‣ 3 EvaluLLM ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">1</span></a>L, K), helping users decide whether to trust the results or adjust settings for a reevaluation.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S4">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Methodology</h2>
<div class="ltx_para" id="S4.p1">
<p class="ltx_p" id="S4.p1.1">Our goal was to explore the challenges users encounter during LLM-assisted model evaluations and, based on our observations, to design a framework that meets their needs and supports effective collaboration between humans and LLM-as-a-judges. We used EvaluLLM to facilitate the creation of evaluation tasks and conducted our research through semi-structured interviews using Webex. Participants accessed a prototype of EvaluLLM, shared their screens, and used think-aloud methods to create evaluation tasks. Each participant worked on the same task: using an LLM-as-a-judge to identify the best model for generating headlines from the CNN/Daily Mail dataset.</p>
</div>
<section class="ltx_subsection" id="S4.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Participants</h3>
<div class="ltx_para" id="S4.SS1.p1">
<p class="ltx_p" id="S4.SS1.p1.1">We recruited 8 industry professionals (Appendix Table <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A1.T1" title="Table 1 ‣ Appendix A Participant Information ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">1</span></a>) with deep domain knowledge in model evaluation at a large technology company (2 females and 6 males) via social media recruiting, with participation and recommendations from various individuals. These industry professionals primarily consist of data scientists, software engineers, and AI engineers. Eligible participants were those who had hands-on experience evaluating large language model performance in their projects in the past year. The interviews were conducted remotely, and participants volunteered and consented to the recording of the session, as well as to the use of the interview results for research purposes.</p>
</div>
</section>
<section class="ltx_subsection" id="S4.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Data Analysis</h3>
<div class="ltx_para" id="S4.SS2.p1">
<p class="ltx_p" id="S4.SS2.p1.1">Two authors independently reviewed the transcripts from recorded video sessions to pinpoint users’ needs, system shortcomings, and challenges in the evaluation workflow. This independent review helped minimize bias and allowed for a comprehensive data exploration. Each author used a codebook of example quotes to support the identified themes. The authors then met to merge similar themes and address any initially missed, resulting in three main categories: use case challenges, evaluation criteria, and evaluation workflow, detailed in Appendix Table <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A2.T2" title="Table 2 ‣ Appendix B Summary of Evaluation Themes and Examples ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">2</span></a>. This classification captures the complexities of the evaluation process, encompassing users’ needs, system limitations, and evaluative challenges.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S5">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>
<div class="ltx_para" id="S5.p1">
<p class="ltx_p" id="S5.p1.1">Our data analysis identified nine themes, categorized into use case challenges, evaluation criteria, and evaluation workflow (for a full list with example quotes see Table <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A2.T2" title="Table 2 ‣ Appendix B Summary of Evaluation Themes and Examples ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">2</span></a> in the Appendix).</p>
</div>
<section class="ltx_subsection" id="S5.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Use Case Challenges</h3>
<div class="ltx_para" id="S5.SS1.p1">
<p class="ltx_p" id="S5.SS1.p1.1">The system requires users to input a prompt for their specific task, after which it generates the output and proceeds with the evaluation. This approach involves sending the identical prompt to various models for output evaluation. However, this methodology poses limitations for experienced users who tailor prompts for specific models, such as LLaMA. Our participants described instances of <span class="ltx_text ltx_font_bold" id="S5.SS1.p1.1.1">absence of specifications</span> where clients lack clarity on the task’s data requirements.</p>
</div>
<div class="ltx_para" id="S5.SS1.p2">
<p class="ltx_p" id="S5.SS1.p2.1">Additionally, there are numerous open-source and closed-source LLM models available, and users would like to test various setups, e.g., model selections, model configurations, and prompts. They would like the system to <span class="ltx_text ltx_font_bold" id="S5.SS1.p2.1.1">support comparison with different setups.</span> Given time constraints and limited investment resources, it is often impractical to test all models with their use case data.
Teams usually begin with top-performing models, either from public benchmarks close to their use case or chosen based on their well-known reputation. Model selection is transient and highly constrained by project requirements. Instead of evaluating multiple models’ performance with different prompts, they typically start with 1-2 models and improve performance through prompt engineering. This involves running the model with various prompts and parameter settings, where they often iterate over the setup to match specific baseline performance. It requires rapid performance comparison and support for evaluation data, accommodating multiple models and considering combinations with different setups.</p>
</div>
<div class="ltx_para" id="S5.SS1.p3">
<p class="ltx_p" id="S5.SS1.p3.1"><span class="ltx_text ltx_font_bold" id="S5.SS1.p3.1.1">Shifting evaluation priority </span>often occurs as the project progresses. At the beginning of the project, where the main purpose is often the proof of concept for a specific proposed solution, the evaluation focus is mainly around feasibility testing. This involves assessing whether the proposed system or solution can produce accurate answers. However, as the project progresses into production, the evaluation purpose might shift from rapid model performance comparison to continual improvement with user feedback, performance monitoring, and reporting potential issues to draw developers’ attentions. As evaluation priorities might differ for various use cases in different project phases, when designing an LLM-as-a-Judge solution, shared needs among these different phases and unique requirements in each phase need to be clearly articulated. This could help better define and design the experience and interaction to effectively support the diverse requirements for each phase.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Evaluation Criteria</h3>
<div class="ltx_para" id="S5.SS2.p1">
<p class="ltx_p" id="S5.SS2.p1.1">We identified several themes related to how users developed, changed, and trusted the evaluation criteria they were working with. While participants appreciated the flexibility of using the freeform approach in EvaluLLM, many expressed that they <span class="ltx_text ltx_font_bold" id="S5.SS2.p1.1.1">desire structured and customizable templates</span> for specific use cases that can be tweaked for their purposes. They believe such templates would help them start with an evaluation baseline.</p>
</div>
<div class="ltx_para" id="S5.SS2.p2">
<p class="ltx_p" id="S5.SS2.p2.1">Moreover, participants highlighted the necessity of distinct evaluation criteria for various tasks. For example, they noted that a RAG task might require one set of criteria, while a creative task might demand another. Participants often crafted criteria complete with descriptions and scoring. One typical approach involved naming each criterion, defining it, and then assigning a score.</p>
</div>
<div class="ltx_para" id="S5.SS2.p3">
<p class="ltx_p" id="S5.SS2.p3.1">Evaluation criteria serve as a medium to communicate user preferences to the model. An effective criterion not only needs to reflect the user’s preferences but also must function well to enable the model to understand and follow instructions. When reflecting on evaluation criteria, participants expressed the <span class="ltx_text ltx_font_bold" id="S5.SS2.p3.1.1">need for multiple rounds of iterations</span> when refining their criteria. <span class="ltx_text ltx_font_italic" id="S5.SS2.p3.1.2">"It can be really hard to figure out how to express the evaluation criteria in a way that makes sense to the model. But it can also just be hard in your own mind to figure out what it means for a title to be good." P2 </span></p>
</div>
<div class="ltx_para" id="S5.SS2.p4">
<p class="ltx_p" id="S5.SS2.p4.1">The importance of giving supporting multiple rounds to refine and expand criteria emerged when looking at the types of dimensions participants created. We found that users tend to prioritize more objective metrics such as accuracy before they start to consider the styling of the outcome. At the beginning of the project, the primary concern for a client is getting the correct answer from the model. That is not to say, that our participants did not care about more subjective criteria, but that happens later in the process.</p>
</div>
<div class="ltx_para" id="S5.SS2.p5">
<p class="ltx_p" id="S5.SS2.p5.1">Although users might have a rough idea of what they want, it is challenging to describe everything at the beginning, especially when they don’t have access to the evaluation data. One participant struggled during the criteria definition process as he was required to define the criteria before he could see the output data. Providing the output might help users articulate what they want or don’t want, assisting them in iterating the criteria description or adding examples to better align with their preferences.</p>
</div>
<div class="ltx_para" id="S5.SS2.p6">
<p class="ltx_p" id="S5.SS2.p6.1">Users express a desire for more than just a high-level result summary; they are keen on obtaining a detailed breakdown of each dimension and a need for the system to <span class="ltx_text ltx_font_bold" id="S5.SS2.p6.1.1">display performance for each criteria individually</span>. EvaluLLM currently only presents a win rate as a high-level performance summary metric to showcase the winning model on the leaderboard. Participants expressed the desire to view performance across each dimension rather than a high level win-rate.</p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.3 </span>Evaluation Workflow</h3>
<div class="ltx_para" id="S5.SS3.p1">
<p class="ltx_p" id="S5.SS3.p1.1">While presenting the tool to users, we probed them on their current evaluation workflows and how they would imagine incorporating EvaluLLM. Users expressed the challenges they faced when doing manual evaluations and how they would use automated methods and the EvaluLLM experience to address those challenges. Although there are only 10 examples in our testing dataset, generating the evaluation results after user created the evaluation is time consuming because of calls to the model. Model calls are expensive and time consuming and one potential way to address this is to <span class="ltx_text ltx_font_bold" id="S5.SS3.p1.1.1">run the evaluation on a subset of the data first</span>.</p>
</div>
<div class="ltx_para" id="S5.SS3.p2">
<p class="ltx_p" id="S5.SS3.p2.1">To evaluate the agreement of the LLM-as-a-Judge preferences with humans, participants were asked to conduct blind reviews of the model’s output. These reviews would be utilized to calculate the agreement between the LLM-as-a-judge and the participants. While it is beneficial to observe the agreement rate in the summary page, users also desire more control over the workflow and seek instant feedback during the manual review process. They would like to see how much the LLM-as-a-judge agrees with them once they provide feedback and wish for the system to proactively provide criteria modification suggestions. One way of providing <span class="ltx_text ltx_font_bold" id="S5.SS3.p2.1.1">instant feedback on human-AI agreement</span> is to allow users to either initially upload human evaluations for comparison with the automatic evaluations. Another way is to conduct a blind review before the evaluations are presented, ensuring that users receive instant feedback on human-AI agreement as soon as the evaluations are ready.</p>
</div>
<div class="ltx_para" id="S5.SS3.p3">
<p class="ltx_p" id="S5.SS3.p3.1">During testing, we observed that some participants might provide overly detailed instructions for both the task prompt and the evaluation criteria. The design intention was to simplify the user input requirements, seeking only the evaluation criteria rather than a complete evaluation prompt with detailed evaluation process. However, some participants included the step-by-step evaluation process in the criteria definition input. Additionally, some participants inquired about adjusting their evaluations per judge.</p>
</div>
<div class="ltx_para" id="S5.SS3.p4">
<p class="ltx_p" id="S5.SS3.p4.1">As our participants are domain experts in model evaluation, they are well aware of potential biases in the model. They actively seek transparency regarding the bias mitigation strategy to effectively calibrate their trust in LLM-as-a-Judge results. Additionally, participants were cognizant of self-enhancement bias <cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib28" title="">2023</a>)</cite> and expressed concerns about the LLM-as-a-judge being one of the models to be evaluated. <span class="ltx_text ltx_font_bold" id="S5.SS3.p4.1.1">Ensuring transparency for trustworthy evaluation</span> was deemed crucial by users, such as transparency concerning the prompts sent to the judge and whether bias mitigation has been implemented. One user remarked, <span class="ltx_text ltx_font_italic" id="S5.SS3.p4.1.2">"It seems like Granite always displays first, and Flan-UL-2 always comes second. Does the system randomly switch positions?" P5</span></p>
</div>
</section>
<section class="ltx_subsection" id="S5.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.4 </span>Limitations</h3>
<div class="ltx_para" id="S5.SS4.p1">
<p class="ltx_p" id="S5.SS4.p1.1">Our study is based on a small sample of only 8 domain experts, potentially impacting the generalizability of our findings. In addition, our methodology primarily concentrated on observing users utilizing our specific evaluation tool with one pre-defined dataset. This approach may restrict the broader applicability of our results. Note that EvaluLLM at the time of this study was a functioning proof-of-concept but not yet a scalable systems that can be deployed to a large user population. However, we believe our findings still offer relevant insights into the challenges and needs users encounter when using LLM-as-a-Judge tools, as evidenced by our focused line of questioning aimed at understanding how more automated evaluations integrate into users’ workflows.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S6">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Discussion and Design Recommendations</h2>
<div class="ltx_para" id="S6.p1">
<p class="ltx_p" id="S6.p1.1">Our findings highlight user needs across different use cases when using LLM-as-a-judge. Users require guidance to evaluate model outputs effectively. We discuss the implications of our findings and propose design recommendations for LLM-as-a-judge tools and user experiences.</p>
</div>
<figure class="ltx_figure" id="S6.F2"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="94" id="S6.F2.g1" src="extracted/5708510/Workflow.png" width="538"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Recommended evaluation workflow: interactive refinement of criteria with a subset of data prior to applying evaluation to entire dataset can potentially improve preference alignment and trust calibration.</figcaption>
</figure>
<section class="ltx_subsection" id="S6.SS1">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.1 </span>Efficient Criteria Iteration</h3>
<div class="ltx_para" id="S6.SS1.p1">
<p class="ltx_p" id="S6.SS1.p1.1">LLMs can generate high-quality outputs aligned with human preferences, but processing the entire dataset is costly and time-consuming, especially with methods like pairwise comparisons, which increase compute costs significantly. To optimize efficiency, it’s advisable to start a project by allowing users to refine their evaluation criteria using a representative data sample before scaling up to the full dataset (see Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#S6.F2" title="Figure 2 ‣ 6 Discussion and Design Recommendations ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">2</span></a>). Effective sampling enhances learning for LLM-as-a-Judge by selecting diverse and representative outputs. Techniques like clustering <cite class="ltx_cite ltx_citemacro_cite">Chang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib2" title="">2021</a>)</cite> or graph-based search <cite class="ltx_cite ltx_citemacro_cite">Su et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib20" title="">2022</a>)</cite> can aid in output selection for human evaluation. Addressing misalignments and manually reviewing low-confidence outputs <cite class="ltx_cite ltx_citemacro_cite">Desmond et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib4" title="">2021</a>)</cite> are crucial, as is displaying a subset of evaluations to lessen users’ cognitive load and facilitate iterative refinement of evaluation criteria.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS2">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.2 </span>Structured and Customizable Templates</h3>
<div class="ltx_para" id="S6.SS2.p1">
<p class="ltx_p" id="S6.SS2.p1.1">For creative generation tasks, it’s crucial to employ diverse, custom criteria. To streamline this process, we propose providing standard criteria that are universally applicable across various use cases, supplemented by customizable templates. As illustrated in our design explorations (see Appendix Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A3.F3" title="Figure 3 ‣ Appendix C Recommended Designs ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">3</span></a>), users can select from predefined criteria dimensions (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A3.F3" title="Figure 3 ‣ Appendix C Recommended Designs ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">3</span></a>A) or utilize recommended templates for common scenarios (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A3.F3" title="Figure 3 ‣ Appendix C Recommended Designs ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">3</span></a>B). These templates are designed to be flexible, allowing easy adaptation to specific user needs.</p>
</div>
<div class="ltx_para" id="S6.SS2.p2">
<p class="ltx_p" id="S6.SS2.p2.1">Further enhancing customization, the proposed templates support hierarchical organization (see Appendix Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A3.F4" title="Figure 4 ‣ Appendix C Recommended Designs ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">4</span></a>), enabling the addition of new criteria dimensions (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A3.F4" title="Figure 4 ‣ Appendix C Recommended Designs ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">4</span></a>G), nesting of sub-criteria (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A3.F4" title="Figure 4 ‣ Appendix C Recommended Designs ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">4</span></a>F), and removal of unwanted elements (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A3.F4" title="Figure 4 ‣ Appendix C Recommended Designs ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">4</span></a>H). Users can also adjust scoring scales (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A3.F4" title="Figure 4 ‣ Appendix C Recommended Designs ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">4</span></a>E). This hierarchical structure, supported by findings from related works <cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib28" title="">2023</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib10" title="">2023c</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Stureborg et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib19" title="">2023</a>)</cite>, allows users to start with broad criteria and refine them to capture specific task nuances. To foster ongoing improvement and reuse, the system should enable users to save and share these templates (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A3.F4" title="Figure 4 ‣ Appendix C Recommended Designs ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">4</span></a>B). Considering the benefits of balanced evaluations, users should be able to adjust the weight of different criteria dimensions, aligning more closely with human preferences. The inclusion of reference examples within the templates (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A3.F4" title="Figure 4 ‣ Appendix C Recommended Designs ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">4</span></a>D) can further refine the criteria based on actual output data, enhancing the preference agreement process. This approach not only makes the criteria definition process more efficient but also ensures consistency and rigor in evaluating creative tasks, leading to more accurate and effective assessments.</p>
</div>
<div class="ltx_para" id="S6.SS2.p3">
<p class="ltx_p" id="S6.SS2.p3.1">Providing structured and customizable templates will not only expedite the process of criteria definition but also foster consistency and rigor in the evaluation of creative generation tasks, which will contribute to more accurate and effective evaluations.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS3">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.3 </span>Interactive Criteria Iteration</h3>
<div class="ltx_para" id="S6.SS3.p1">
<p class="ltx_p" id="S6.SS3.p1.1">Our findings revealed crafting effective criteria typically requires multiple iterations. Criteria components such as name, definition, scale, and examples often need definition and refinement as users evaluate outputs. Users include examples of both poor and excellent outputs to help LLM-as-Judges distinguish quality through few-shot learning techniques. Related work <cite class="ltx_cite ltx_citemacro_cite">Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib10" title="">2023c</a>)</cite> indicates that users often develop new criteria during evaluations. To facilitate this process, a real-time feedback system that allows users to immediately see the impact of criteria modifications would be useful. Additionally, a user-friendly interface that enables easy modification and experimentation with criteria could significantly improve the efficiency and customization of the evaluation process.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS4">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.4 </span>Ensure Consistency</h3>
<div class="ltx_para" id="S6.SS4.p1">
<p class="ltx_p" id="S6.SS4.p1.1">As human preferences may not be consistent within the same set, aligning with frequently changing preferences becomes a challenge. A self-consistency check mechanism can expedite this alignment. When refining criteria, any discrepancies between human and LLM-as-a-Judge evaluations should prompt a review of similar sample data post-calibration. Incorporating an automated consistency checker that flags potential criteria conflicts or inconsistencies could streamline the evaluation process by offering actionable solutions to address these inconsistencies. Leveraging the diversity of logical paths in complex reasoning tasks, as suggested by recent studies <cite class="ltx_cite ltx_citemacro_cite">Stanovich and West (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib18" title="">2000</a>)</cite>, the self-consistency CoT method <cite class="ltx_cite ltx_citemacro_cite">Wang et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib22" title="">2023b</a>)</cite> can generate multiple reasoning paths, selecting the most consistent answers by averaging over these paths, thus improving evaluation outcomes.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS5">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.5 </span>Support Different Setups</h3>
<div class="ltx_para" id="S6.SS5.p1">
<p class="ltx_p" id="S6.SS5.p1.1">Our findings emphasize the need for an LLM to function flexibly as a judging system throughout different project phases. It should support a variety of evaluation data configurations, including diverse model selections, prompts, and settings. While some evaluations may only compare outputs from a specific prompt and model setting, optimal performance often requires tailored prompts and settings for each model, involving substantial prompt engineering and comparison of different configurations. Thus, the system must not only evaluate common settings across various models but also assess various prompts and settings for select models, highlighting the importance of designing an adaptable LLM judging system.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS6">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.6 </span>Adaptable Reference-Based Evaluation</h3>
<div class="ltx_para" id="S6.SS6.p1">
<p class="ltx_p" id="S6.SS6.p1.1">Our user study findings showed that users often start projects without clear objectives, resulting in evaluations lacking reference data. Users interacting with the LLM-as-a-Judge system gradually accumulate reference data, either directly or from external sources, so it could be beneficial to design systems that incorporate human input to refine preference correspondence using expert-labeled data <cite class="ltx_cite ltx_citemacro_cite">Liu et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib15" title="">2023b</a>)</cite> or other collected references. This flexible approach enhances the system’s effectiveness and trustworthiness, ensuring it evolves in line with user preferences.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS7">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.7 </span>Enhance System Transparency</h3>
<div class="ltx_para" id="S6.SS7.p1">
<p class="ltx_p" id="S6.SS7.p1.1">Our findings indicate that users value transparency to comprehend the LLM’s role as a judge. This encompasses access to essential details like the specific prompt used (illustrated in Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A3.F5" title="Figure 5 ‣ Appendix C Recommended Designs ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">5</span></a>A) and the implementation of bias mitigation strategies. To design an effective LLM-as-a-Judge system, it is critical to make such information readily available. This can be facilitated by allowing users to view the prompt, enabling the system to explain evaluation results, and integrating visualization tools that demonstrate how user inputs affect the evaluation process.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS8">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.8 </span>Proactively Mitigate Potential Bias</h3>
<div class="ltx_para" id="S6.SS8.p1">
<p class="ltx_p" id="S6.SS8.p1.1">Considering the persistent challenge of bias, systems should implement bias mitigation strategies that include swapping answer order to reduce position bias <cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib28" title="">2023</a>)</cite> and treating inconsistent results as ties, or by randomly assigning positions in large datasets <cite class="ltx_cite ltx_citemacro_cite">Li et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib11" title="">2023</a>)</cite> <cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib28" title="">2023</a>)</cite>. For verbosity bias, the "repetitive list" attack technique <cite class="ltx_cite ltx_citemacro_cite">Zheng et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib28" title="">2023</a>)</cite> challenges LLMs to favor clarity over length in responses. Furthermore, enhancing LLMs’ abilities in mathematical and reasoning tasks can be achieved through Chain-of-Thought approaches <cite class="ltx_cite ltx_citemacro_cite">Wei et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib23" title="">2022</a>)</cite>, coupled with reference-guided evaluation where the LLM generates and then evaluates its own initial responses.</p>
</div>
</section>
<section class="ltx_subsection" id="S6.SS9">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">6.9 </span>Explore Further Automation</h3>
<div class="ltx_para" id="S6.SS9.p1">
<p class="ltx_p" id="S6.SS9.p1.1">Our study found that task prompts often contain criteria, suggesting the possibility of extracting them automatically for tailored guidelines. Related work also shows that users prefer automated prompt refinement over manual revisions <cite class="ltx_cite ltx_citemacro_cite">Kim et al. (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#bib.bib10" title="">2023c</a>)</cite>. Various suggestions(see Appendix Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A3.F5" title="Figure 5 ‣ Appendix C Recommended Designs ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">5</span></a>), such as rephrasing (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A3.F5" title="Figure 5 ‣ Appendix C Recommended Designs ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">5</span></a>A), adding reference examples (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A3.F5" title="Figure 5 ‣ Appendix C Recommended Designs ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">5</span></a>B), incorporating more scales (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A3.F5" title="Figure 5 ‣ Appendix C Recommended Designs ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">5</span></a>C), and introducing additional dimensions (Figure <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A3.F5" title="Figure 5 ‣ Appendix C Recommended Designs ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">5</span></a>D), could be proactively provided by the system for humans to review to further accelerate evaluation correspondence. While these areas show promise for further improving the efficiency of preference correspondence, considering the limitations of automation systems, it is essential to place humans in the loop to calibrate accuracy and trustworthiness.</p>
</div>
</section>
</section>
<section class="ltx_section" id="S7">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>
<div class="ltx_para" id="S7.p1">
<p class="ltx_p" id="S7.p1.1">We studied EvaluLLM, an AI-assisted tool utilizing LLMs alongside humans as judges for LLM-generated content. Our findings highlight the potential of LLMs as customizable judges and underscore the importance of interactive, transparent, and user-centered evaluation processes. Based on our findings, we offer design suggestions for practitioners that can help them build more effective , nuanced, adaptable, and user-friendly evaluation tools that meet diverse needs as compared to automated benchmarks. Inspired by our user research, we are currently in the process of rolling out an evolved AI-assisted evaluation tool to a larger user population to observe "usage in the wild."</p>
</div>
</section>
<section class="ltx_bibliography" id="bib">
<h2 class="ltx_title ltx_title_bibliography">References</h2>
<ul class="ltx_biblist">
<li class="ltx_bibitem" id="bib.bib1">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Cabrera et al. (2023)</span>
<span class="ltx_bibblock">
Ángel Alexander Cabrera, Erica Fu, Donald Bertucci, Kenneth Holstein, Ameet
Talwalkar, Jason I Hong, and Adam Perer. 2023.

</span>
<span class="ltx_bibblock">Zeno: An interactive framework for behavioral evaluation of machine
learning.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib1.1.1">Proceedings of the 2023 CHI Conference on Human Factors in
Computing Systems</em>, pages 1–14.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib2">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Chang et al. (2021)</span>
<span class="ltx_bibblock">
Ernie Chang, Xiaoyu Shen, Hui-Syuan Yeh, and Vera Demberg. 2021.

</span>
<span class="ltx_bibblock">On training instance selection for few-shot neural text generation.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib2.1.1">arXiv preprint arXiv:2107.03176</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib3">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Desmond et al. (2024)</span>
<span class="ltx_bibblock">
Michael Desmond, Zahra Ashktorab, Qian Pan, Casey Dugan, and James M. Johnson.
2024.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1145/3640544.3645216" title="">Evalullm: Llm
assisted evaluation of generative outputs</a>.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib3.1.1">Companion Proceedings of the 29th International Conference
on Intelligent User Interfaces</em>, IUI ’24 Companion, page 30–32, New York,
NY, USA. Association for Computing Machinery.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib4">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Desmond et al. (2021)</span>
<span class="ltx_bibblock">
Michael Desmond, Evelyn Duesterwald, Kristina Brimijoin, Michelle Brachman, and
Qian Pan. 2021.

</span>
<span class="ltx_bibblock">Semi-automated data labeling.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib4.1.1">NeurIPS 2020 Competition and Demonstration Track</em>, pages
156–169. PMLR.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib5">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Freitag et al. (2022)</span>
<span class="ltx_bibblock">
Markus Freitag, Ricardo Rei, Nitika Mathur, Chi-kiu Lo, Craig Stewart,
Eleftherios Avramidis, Tom Kocmi, George Foster, Alon Lavie, and André FT
Martins. 2022.

</span>
<span class="ltx_bibblock">Results of wmt22 metrics shared task: Stop using bleu–neural metrics
are better and more robust.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib5.1.1">Proceedings of the Seventh Conference on Machine Translation
(WMT)</em>, pages 46–68.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib6">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fu et al. (2023)</span>
<span class="ltx_bibblock">
Jinlan Fu, See-Kiong Ng, Zhengbao Jiang, and Pengfei Liu. 2023.

</span>
<span class="ltx_bibblock">Gptscore: Evaluate as you desire.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib6.1.1">arXiv preprint arXiv:2302.04166</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib7">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gehrmann et al. (2023)</span>
<span class="ltx_bibblock">
Sebastian Gehrmann, Elizabeth Clark, and Thibault Sellam. 2023.

</span>
<span class="ltx_bibblock">Repairing the cracked foundation: A survey of obstacles in evaluation
practices for generated text.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib7.1.1">Journal of Artificial Intelligence Research</em>, 77:103–166.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib8">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. (2023a)</span>
<span class="ltx_bibblock">
Seungone Kim, Jamin Shin, Yejin Cho, Joel Jang, Shayne Longpre, Hwaran Lee,
Sangdoo Yun, Seongjin Shin, Sungdong Kim, James Thorne, et al.
2023a.

</span>
<span class="ltx_bibblock">Prometheus: Inducing fine-grained evaluation capability in language
models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib8.1.1">arXiv preprint arXiv:2310.08491</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib9">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. (2023b)</span>
<span class="ltx_bibblock">
Tae Soo Kim, Yoonjoo Lee, Jamin Shin, Young-Ho Kim, and Juho Kim.
2023b.

</span>
<span class="ltx_bibblock">Evallm: Interactive evaluation of large language model prompts on
user-defined criteria.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib9.1.1">arXiv preprint arXiv:2309.13633</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib10">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kim et al. (2023c)</span>
<span class="ltx_bibblock">
Tae Soo Kim, Yoonjoo Lee, Jamin Shin, Young-Ho Kim, and Juho Kim.
2023c.

</span>
<span class="ltx_bibblock">Evallm: Interactive evaluation of large language model prompts on
user-defined criteria.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib10.1.1">arXiv preprint arXiv:2309.13633</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib11">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. (2023)</span>
<span class="ltx_bibblock">
Xuechen Li, Tianyi Zhang, Yann Dubois, Rohan Taori, Ishaan Gulrajani, Carlos
Guestrin, Percy Liang, and Tatsunori B Hashimoto. 2023.

</span>
<span class="ltx_bibblock">Alpacaeval: An automatic evaluator of instruction-following models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib11.1.1">GitHub repository</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib12">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liang et al. (2022)</span>
<span class="ltx_bibblock">
Percy Liang, Rishi Bommasani, Tony Lee, Dimitris Tsipras, Dilara Soylu,
Michihiro Yasunaga, Yian Zhang, Deepak Narayanan, Yuhuai Wu, Ananya Kumar,
et al. 2022.

</span>
<span class="ltx_bibblock">Holistic evaluation of language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib12.1.1">arXiv preprint arXiv:2211.09110</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib13">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lin (2004)</span>
<span class="ltx_bibblock">
Chin-Yew Lin. 2004.

</span>
<span class="ltx_bibblock">Rouge: A package for automatic evaluation of summaries.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib13.1.1">Text summarization branches out</em>, pages 74–81.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib14">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023a)</span>
<span class="ltx_bibblock">
Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu.
2023a.

</span>
<span class="ltx_bibblock">Gpteval: Nlg evaluation using gpt-4 with better human alignment.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib14.1.1">arXiv preprint arXiv:2303.16634</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib15">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Liu et al. (2023b)</span>
<span class="ltx_bibblock">
Yuxuan Liu, Tianchi Yang, Shaohan Huang, Zihan Zhang, Haizhen Huang, Furu Wei,
Weiwei Deng, Feng Sun, and Qi Zhang. 2023b.

</span>
<span class="ltx_bibblock">Calibrating llm-based evaluator.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib15.1.1">arXiv preprint arXiv:2309.13308</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib16">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Papineni et al. (2002)</span>
<span class="ltx_bibblock">
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002.

</span>
<span class="ltx_bibblock">Bleu: a method for automatic evaluation of machine translation.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib16.1.1">Proceedings of the 40th annual meeting of the Association
for Computational Linguistics</em>, pages 311–318.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib17">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Petridis et al. (2023)</span>
<span class="ltx_bibblock">
Savvas Petridis, Ben Wedin, James Wexler, Aaron Donsbach, Mahima Pushkarna,
Nitesh Goyal, Carrie J Cai, and Michael Terry. 2023.

</span>
<span class="ltx_bibblock">Constitutionmaker: Interactively critiquing large language models by
converting feedback into principles.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib17.1.1">arXiv preprint arXiv:2310.15428</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib18">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stanovich and West (2000)</span>
<span class="ltx_bibblock">
Keith E. Stanovich and Richard F. West. 2000.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://doi.org/10.1017/S0140525X00623439" title="">Advancing the
rationality debate</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib18.1.1">Behavioral and Brain Sciences</em>, 23(5):701–717.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib19">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Stureborg et al. (2023)</span>
<span class="ltx_bibblock">
Rickard Stureborg, Bhuwan Dhingra, and Jun Yang. 2023.

</span>
<span class="ltx_bibblock">Interface design for crowdsourcing hierarchical multi-label text
annotations.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib19.1.1">Proceedings of the 2023 CHI Conference on Human Factors in
Computing Systems</em>, pages 1–17.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib20">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Su et al. (2022)</span>
<span class="ltx_bibblock">
Hongjin Su, Jungo Kasai, Chen Henry Wu, Weijia Shi, Tianlu Wang, Jiayi Xin, Rui
Zhang, Mari Ostendorf, Luke Zettlemoyer, Noah A. Smith, and Tao Yu. 2022.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2209.01975" title="">Selective annotation makes
language models better few-shot learners</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib20.1.1">Preprint</em>, arXiv:2209.01975.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib21">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023a)</span>
<span class="ltx_bibblock">
Jiaan Wang, Yunlong Liang, Fandong Meng, Haoxiang Shi, Zhixu Li, Jinan Xu,
Jianfeng Qu, and Jie Zhou. 2023a.

</span>
<span class="ltx_bibblock">Is chatgpt a good nlg evaluator? a preliminary study.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib21.1.1">arXiv preprint arXiv:2303.04048</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib22">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang et al. (2023b)</span>
<span class="ltx_bibblock">
Xuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, Sharan Narang,
Aakanksha Chowdhery, and Denny Zhou. 2023b.

</span>
<span class="ltx_bibblock"><a class="ltx_ref ltx_href" href="https://arxiv.org/abs/2203.11171" title="">Self-consistency improves
chain of thought reasoning in language models</a>.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib22.1.1">Preprint</em>, arXiv:2203.11171.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib23">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei et al. (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V
Le, Denny Zhou, et al. 2022.

</span>
<span class="ltx_bibblock">Chain-of-thought prompting elicits reasoning in large language
models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib23.1.1">Advances in Neural Information Processing Systems</em>,
35:24824–24837.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib24">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wexler et al. (2019)</span>
<span class="ltx_bibblock">
James Wexler, Mahima Pushkarna, Tolga Bolukbasi, Martin Wattenberg, Fernanda
Viégas, and Jimbo Wilson. 2019.

</span>
<span class="ltx_bibblock">The what-if tool: Interactive probing of machine learning models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib24.1.1">IEEE transactions on visualization and computer graphics</em>,
26(1):56–65.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib25">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wu et al. (2019)</span>
<span class="ltx_bibblock">
Tongshuang Wu, Marco Tulio Ribeiro, Jeffrey Heer, and Daniel S Weld. 2019.

</span>
<span class="ltx_bibblock">Errudite: Scalable, reproducible, and testable error analysis.

</span>
<span class="ltx_bibblock">In <em class="ltx_emph ltx_font_italic" id="bib.bib25.1.1">Proceedings of the 57th Annual Meeting of the Association
for Computational Linguistics</em>, pages 747–763.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib26">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Xiao et al. (2023)</span>
<span class="ltx_bibblock">
Ziang Xiao, Susu Zhang, Vivian Lai, and Q Vera Liao. 2023.

</span>
<span class="ltx_bibblock">Evaluating nlg evaluation metrics: A measurement theory perspective.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib26.1.1">arXiv preprint arXiv:2305.14889</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib27">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yuan et al. (2024)</span>
<span class="ltx_bibblock">
Weizhe Yuan, Richard Yuanzhe Pang, Kyunghyun Cho, Sainbayar Sukhbaatar, Jing
Xu, and Jason Weston. 2024.

</span>
<span class="ltx_bibblock">Self-rewarding language models.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib27.1.1">arXiv preprint arXiv:2401.10020</em>.

</span>
</li>
<li class="ltx_bibitem" id="bib.bib28">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al. (2023)</span>
<span class="ltx_bibblock">
Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao
Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. 2023.

</span>
<span class="ltx_bibblock">Judging llm-as-a-judge with mt-bench and chatbot arena.

</span>
<span class="ltx_bibblock"><em class="ltx_emph ltx_font_italic" id="bib.bib28.1.1">arXiv preprint arXiv:2306.05685</em>.

</span>
</li>
</ul>
</section>
<section class="ltx_appendix" id="A1">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Participant Information</h2>
<div class="ltx_para" id="A1.p1">
<p class="ltx_p" id="A1.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A1.T1" title="Table 1 ‣ Appendix A Participant Information ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">1</span></a> shows the details of participants involved in the user study, predominantly comprising of industry experts such as data scientists, software engineers, and AI engineers. These professionals have practical experience in evaluating the performance of large language models in their projects over the last year.</p>
</div>
<figure class="ltx_table" id="A1.T1">
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A1.T1.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A1.T1.1.1.1">
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="A1.T1.1.1.1.1"><span class="ltx_text ltx_font_italic" id="A1.T1.1.1.1.1.1">ID</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="A1.T1.1.1.1.2"><span class="ltx_text ltx_font_italic" id="A1.T1.1.1.1.2.1">Gender</span></th>
<th class="ltx_td ltx_align_left ltx_th ltx_th_column" id="A1.T1.1.1.1.3"><span class="ltx_text ltx_font_italic" id="A1.T1.1.1.1.3.1">Job Role</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A1.T1.1.2.1">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.2.1.1">P1</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.2.1.2">Male</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.2.1.3">Lead Software Engineer/Data Scientist</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.3.2">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.3.2.1">P2</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.3.2.2">Male</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.3.2.3">Principle Data Scientist</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.4.3">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.4.3.1">P3</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.4.3.2">Male</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.4.3.3">Lead Software Engineer/Data Scientist</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.5.4">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.5.4.1">P4</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.5.4.2">Male</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.5.4.3">Data Scientist</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.6.5">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.6.5.1">P5</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.6.5.2">Male</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.6.5.3">AI Engineer/Data Scientist</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.7.6">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.7.6.1">P6</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.7.6.2">Female</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.7.6.3">Data Scientist</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.8.7">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.8.7.1">P7</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.8.7.2">Male</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.8.7.3">Senior Technical Manager/Data Scientist</td>
</tr>
<tr class="ltx_tr" id="A1.T1.1.9.8">
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.9.8.1">P8</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.9.8.2">Female</td>
<td class="ltx_td ltx_align_left ltx_border_t" id="A1.T1.1.9.8.3">Data Scientist</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Demographic information from participants in our user study.</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A2">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>Summary of Evaluation Themes and Examples</h2>
<div class="ltx_para" id="A2.p1">
<p class="ltx_p" id="A2.p1.1">Table <a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A2.T2" title="Table 2 ‣ Appendix B Summary of Evaluation Themes and Examples ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">2</span></a> provides further details on evaluation themes generated from the user study, along with corresponding examples from participants’ quotes.</p>
</div>
<figure class="ltx_table" id="A2.T2">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Table of evaluation themes and corresponding examples. Themes are grouped into three categories: use case challenges, evaluation criteria, and evaluation workflow. Quotes are provided to delineate themes. </figcaption>
<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle" id="A2.T2.1">
<thead class="ltx_thead">
<tr class="ltx_tr" id="A2.T2.1.1.1">
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A2.T2.1.1.1.1">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.1.1.1.1">
<span class="ltx_p" id="A2.T2.1.1.1.1.1.1" style="width:79.7pt;"><span class="ltx_text ltx_font_bold" id="A2.T2.1.1.1.1.1.1.1">Group</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A2.T2.1.1.1.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.1.1.2.1">
<span class="ltx_p" id="A2.T2.1.1.1.2.1.1" style="width:99.6pt;"><span class="ltx_text ltx_font_bold" id="A2.T2.1.1.1.2.1.1.1">Theme</span></span>
</span>
</th>
<th class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_tt" id="A2.T2.1.1.1.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.1.1.3.1">
<span class="ltx_p" id="A2.T2.1.1.1.3.1.1" style="width:261.8pt;"><span class="ltx_text ltx_font_bold" id="A2.T2.1.1.1.3.1.1.1">Example</span></span>
</span>
</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr" id="A2.T2.1.2.1">
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A2.T2.1.2.1.1">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.2.1.1.1">
<span class="ltx_p" id="A2.T2.1.2.1.1.1.1" style="width:79.7pt;">Use Case Challenges</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A2.T2.1.2.1.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.2.1.2.1">
<span class="ltx_p" id="A2.T2.1.2.1.2.1.1" style="width:99.6pt;">Absence of Specifications</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_t" id="A2.T2.1.2.1.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.2.1.3.1">
<span class="ltx_p" id="A2.T2.1.2.1.3.1.1" style="width:261.8pt;"><span class="ltx_text ltx_font_italic" id="A2.T2.1.2.1.3.1.1.1">“So we can compare using, metrics such as or BLEU, And this is like this other scenario, which unfortunately is more common, which is client doesn’t even know what they want.”</span> - P5</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T2.1.3.2">
<td class="ltx_td ltx_align_top" id="A2.T2.1.3.2.1"></td>
<td class="ltx_td ltx_align_top" id="A2.T2.1.3.2.2"></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.3.2.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.3.2.3.1">
<span class="ltx_p" id="A2.T2.1.3.2.3.1.1" style="width:261.8pt;"><span class="ltx_text ltx_font_italic" id="A2.T2.1.3.2.3.1.1.1">“It was like eighty-twenty, eighty percent of the time they don’t have it.”</span> - P5</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T2.1.4.3">
<td class="ltx_td ltx_align_top" id="A2.T2.1.4.3.1"></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.4.3.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.4.3.2.1">
<span class="ltx_p" id="A2.T2.1.4.3.2.1.1" style="width:99.6pt;">Support Comparison with Different Setup</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.4.3.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.4.3.3.1">
<span class="ltx_p" id="A2.T2.1.4.3.3.1.1" style="width:261.8pt;"><span class="ltx_text ltx_font_italic" id="A2.T2.1.4.3.3.1.1.1">“Say we had five different models and for each model we had 20 different configurations or something like that. Now that’s 100 different combinations. Um, we’d like the limited judge to be to run on like all hundred. Give us an overview. Which are the three that are actually worth looking at?”</span> - P2</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T2.1.5.4">
<td class="ltx_td ltx_align_top" id="A2.T2.1.5.4.1"></td>
<td class="ltx_td ltx_align_top" id="A2.T2.1.5.4.2"></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.5.4.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.5.4.3.1">
<span class="ltx_p" id="A2.T2.1.5.4.3.1.1" style="width:261.8pt;"><span class="ltx_text ltx_font_italic" id="A2.T2.1.5.4.3.1.1.1">“GPT 4 as a baseline and we’re just trying to see how close are we getting with these other models in order to replicate the performance.”</span> - P7</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T2.1.6.5">
<td class="ltx_td ltx_align_top" id="A2.T2.1.6.5.1"></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.6.5.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.6.5.2.1">
<span class="ltx_p" id="A2.T2.1.6.5.2.1.1" style="width:99.6pt;">Shifting Evaluation Priority</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.6.5.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.6.5.3.1">
<span class="ltx_p" id="A2.T2.1.6.5.3.1.1" style="width:261.8pt;"><span class="ltx_text ltx_font_italic" id="A2.T2.1.6.5.3.1.1.1">“I know that’s like a terrible metric [confusion matrix] to be used as the first one, but we have actually done this with a client because they asked us to do so. They’re looking for just accuracy.”</span> - P5</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T2.1.7.6">
<td class="ltx_td ltx_align_top" id="A2.T2.1.7.6.1"></td>
<td class="ltx_td ltx_align_top" id="A2.T2.1.7.6.2"></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.7.6.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.7.6.3.1">
<span class="ltx_p" id="A2.T2.1.7.6.3.1.1" style="width:261.8pt;"><span class="ltx_text ltx_font_italic" id="A2.T2.1.7.6.3.1.1.1">“GPT 4 as a baseline and we’re just trying to see how close are we getting with these other models in order to replicate the performance.”</span> - P7</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T2.1.8.7">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.8.7.1">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.8.7.1.1">
<span class="ltx_p" id="A2.T2.1.8.7.1.1.1" style="width:79.7pt;">Evaluation Criteria</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.8.7.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.8.7.2.1">
<span class="ltx_p" id="A2.T2.1.8.7.2.1.1" style="width:99.6pt;">Desire Structured and Customizable Templates</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.8.7.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.8.7.3.1">
<span class="ltx_p" id="A2.T2.1.8.7.3.1.1" style="width:261.8pt;"><span class="ltx_text ltx_font_italic" id="A2.T2.1.8.7.3.1.1.1">“A freeform text box is too simple. I would love there to be templates that I can utilize. And at the very least, be able to just edit so that I can get into my use case.”</span> - P7</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T2.1.9.8">
<td class="ltx_td ltx_align_top" id="A2.T2.1.9.8.1"></td>
<td class="ltx_td ltx_align_top" id="A2.T2.1.9.8.2"></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.9.8.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.9.8.3.1">
<span class="ltx_p" id="A2.T2.1.9.8.3.1.1" style="width:261.8pt;"><span class="ltx_text ltx_font_italic" id="A2.T2.1.9.8.3.1.1.1">“More examples might be nice.”</span> - P2</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T2.1.10.9">
<td class="ltx_td ltx_align_top" id="A2.T2.1.10.9.1"></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.10.9.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.10.9.2.1">
<span class="ltx_p" id="A2.T2.1.10.9.2.1.1" style="width:99.6pt;">Need for Multiple Rounds of Iterations</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.10.9.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.10.9.3.1">
<span class="ltx_p" id="A2.T2.1.10.9.3.1.1" style="width:261.8pt;"><span class="ltx_text ltx_font_italic" id="A2.T2.1.10.9.3.1.1.1">“It can be really hard to figure out how to express the evaluation criteria in a way that makes sense to the model. But it can also just be hard in your own mind to figure out what it means for a title to be good.”</span> - P2</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T2.1.11.10">
<td class="ltx_td ltx_align_top" id="A2.T2.1.11.10.1"></td>
<td class="ltx_td ltx_align_top" id="A2.T2.1.11.10.2"></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.11.10.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.11.10.3.1">
<span class="ltx_p" id="A2.T2.1.11.10.3.1.1" style="width:261.8pt;"><span class="ltx_text ltx_font_italic" id="A2.T2.1.11.10.3.1.1.1">“If I think, without having a clearer sense of what the evaluation is, sort of what a baseline evaluation is, it might be nice to have a couple of features of an evaluation that we could just select in like a checkbox. ”</span> - P3</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T2.1.12.11">
<td class="ltx_td ltx_align_top" id="A2.T2.1.12.11.1"></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.12.11.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.12.11.2.1">
<span class="ltx_p" id="A2.T2.1.12.11.2.1.1" style="width:99.6pt;">Display Performance for each Criteria Individually</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.12.11.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.12.11.3.1">
<span class="ltx_p" id="A2.T2.1.12.11.3.1.1" style="width:261.8pt;"><span class="ltx_text ltx_font_italic" id="A2.T2.1.12.11.3.1.1.1">”There might be times where you have to trade off on certain kinds of things and Win rate is not necessarily the best metric because there are multiple categories to define what it means to win.”</span> - P7</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T2.1.13.12">
<td class="ltx_td ltx_align_top" id="A2.T2.1.13.12.1"></td>
<td class="ltx_td ltx_align_top" id="A2.T2.1.13.12.2"></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.13.12.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.13.12.3.1">
<span class="ltx_p" id="A2.T2.1.13.12.3.1.1" style="width:261.8pt;"><span class="ltx_text ltx_font_italic" id="A2.T2.1.13.12.3.1.1.1">“So I’m covering a lot of ground there, and I know that’s hard for the model to deal with because now the model has to have a whole lot of different criteria, and it’s all drawn up by the ones, but that’s kind of what a good title headline is about.”</span> - P7</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T2.1.14.13">
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.14.13.1">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.14.13.1.1">
<span class="ltx_p" id="A2.T2.1.14.13.1.1.1" style="width:79.7pt;">Evaluation Workflow</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.14.13.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.14.13.2.1">
<span class="ltx_p" id="A2.T2.1.14.13.2.1.1" style="width:99.6pt;">Run Evaluation on Subset of Data First</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.14.13.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.14.13.3.1">
<span class="ltx_p" id="A2.T2.1.14.13.3.1.1" style="width:261.8pt;"><span class="ltx_text ltx_font_italic" id="A2.T2.1.14.13.3.1.1.1">“We don’t have a problem here because the data set is small. But, like, if there’s like, a 1000. Then it would it make sense to go through the entire batch and we find out your volume criteria needs to be tweaked.”</span> - P2</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T2.1.15.14">
<td class="ltx_td ltx_align_top" id="A2.T2.1.15.14.1"></td>
<td class="ltx_td ltx_align_top" id="A2.T2.1.15.14.2"></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.15.14.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.15.14.3.1">
<span class="ltx_p" id="A2.T2.1.15.14.3.1.1" style="width:261.8pt;"><span class="ltx_text ltx_font_italic" id="A2.T2.1.15.14.3.1.1.1">“I’d want to iterate on my judge enough for it to get a decent annotator agreement and then let it go wild.”</span> - P2</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T2.1.16.15">
<td class="ltx_td ltx_align_top" id="A2.T2.1.16.15.1"></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.16.15.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.16.15.2.1">
<span class="ltx_p" id="A2.T2.1.16.15.2.1.1" style="width:99.6pt;">Instant Feedback on Human-AI agreement</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.16.15.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.16.15.3.1">
<span class="ltx_p" id="A2.T2.1.16.15.3.1.1" style="width:261.8pt;"><span class="ltx_text ltx_font_italic" id="A2.T2.1.16.15.3.1.1.1">“Tell me when to quit.” </span>-P1</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T2.1.17.16">
<td class="ltx_td ltx_align_top" id="A2.T2.1.17.16.1"></td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.17.16.2">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.17.16.2.1">
<span class="ltx_p" id="A2.T2.1.17.16.2.1.1" style="width:99.6pt;">Ensuring Transparency for Trustworthy Evaluation</span>
</span>
</td>
<td class="ltx_td ltx_align_justify ltx_align_top" id="A2.T2.1.17.16.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.17.16.3.1">
<span class="ltx_p" id="A2.T2.1.17.16.3.1.1" style="width:261.8pt;"><span class="ltx_text ltx_font_italic" id="A2.T2.1.17.16.3.1.1.1">“So I definitely want, as we discussed earlier, a lot of transparency and exactly what is being sent to the models to generate the responses and then what is then being sent to the LLM as a judge.”</span> - P2</span>
</span>
</td>
</tr>
<tr class="ltx_tr" id="A2.T2.1.18.17">
<td class="ltx_td ltx_align_top ltx_border_bb" id="A2.T2.1.18.17.1"></td>
<td class="ltx_td ltx_align_top ltx_border_bb" id="A2.T2.1.18.17.2"></td>
<td class="ltx_td ltx_align_justify ltx_align_top ltx_border_bb" id="A2.T2.1.18.17.3">
<span class="ltx_inline-block ltx_align_top" id="A2.T2.1.18.17.3.1">
<span class="ltx_p" id="A2.T2.1.18.17.3.1.1" style="width:261.8pt;"><span class="ltx_text ltx_font_italic" id="A2.T2.1.18.17.3.1.1.1">“Maybe a small note on, like, you know what the prompt is, like, what the data set is and what the tool is doing.”</span> - P8</span>
</span>
</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section class="ltx_appendix" id="A3">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Recommended Designs</h2>
<div class="ltx_para" id="A3.p1">
<p class="ltx_p" id="A3.p1.1">Figure (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A3.F3" title="Figure 3 ‣ Appendix C Recommended Designs ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">3</span></a>)(<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A3.F4" title="Figure 4 ‣ Appendix C Recommended Designs ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">4</span></a>)(<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A3.F5" title="Figure 5 ‣ Appendix C Recommended Designs ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">5</span></a>) show design examples to help illustrate corresponding design recommendations.</p>
</div>
<figure class="ltx_figure" id="A3.F3"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="371" id="A3.F3.g1" src="extracted/5708510/StructureTemplate1.png" width="592"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Recommended design to (A) enable users to choose from a list of predefined custom metric modules and (B) enable users to create a set of evaluation criteria based on common use cases. </figcaption>
</figure>
<figure class="ltx_figure" id="A3.F4"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_square" height="538" id="A3.F4.g1" src="extracted/5708510/StructureTemplate2.png" width="592"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Recommended design to provide structured and customizable templates that support hierarchical, multi-dimensional evaluations. </figcaption>
</figure>
<figure class="ltx_figure" id="A3.F5"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="356" id="A3.F5.g1" src="extracted/5708510/SelfCritique.jpg" width="592"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Recommended design demonstrating the ability of users to leverage LLM-as-a-Judge for Criteria Iteration.</figcaption>
</figure>
</section>
<section class="ltx_appendix" id="A4">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix D </span>EvaluLLM Evaluation Workflow</h2>
<div class="ltx_para" id="A4.p1">
<p class="ltx_p" id="A4.p1.1">Figure (<a class="ltx_ref" href="https://arxiv.org/html/2407.03479v1#A4.F6" title="Figure 6 ‣ Appendix D EvaluLLM Evaluation Workflow ‣ Human-Centered Design Recommendations for LLM-as-a-Judge"><span class="ltx_text ltx_ref_tag">6</span></a>) shows the high-level overview of the EvaluLLM workflow, which consists of a Build, Review, and Inspect process.</p>
</div>
<figure class="ltx_figure" id="A4.F6"><img alt="Refer to caption" class="ltx_graphics ltx_centering ltx_img_landscape" height="306" id="A4.F6.g1" src="extracted/5708510/DIS_Overview.jpg" width="586"/>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>EvaluLLM evaluation workflow overview which consists of a Build, Review, and Inspect process.</figcaption>
</figure>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  on Wed Jul  3 19:42:33 2024 by <a class="ltx_LaTeXML_logo" href="http://dlmf.nist.gov/LaTeXML/"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img alt="Mascot Sammy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg=="/></a>
</div></footer>
</div>
</body>
</html>
