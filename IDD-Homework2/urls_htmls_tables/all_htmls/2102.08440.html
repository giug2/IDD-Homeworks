<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2102.08440] Scaling Neuroscience Research using Federated Learning</title><meta property="og:description" content="The amount of biomedical data continues to grow rapidly. However, the ability to analyze these data is limited due to privacy and regulatory concerns. Machine learning approaches that require data to be copied to a sin…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Scaling Neuroscience Research using Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Scaling Neuroscience Research using Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2102.08440">

<!--Generated on Thu Mar  7 02:11:04 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line" lang="en">
<h1 class="ltx_title ltx_title_document">Scaling Neuroscience Research using Federated Learning</h1>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p"><span id="id1.id1.1" class="ltx_text">The amount of biomedical data continues to grow rapidly. However, the ability to analyze these data is limited due to privacy and regulatory concerns. Machine learning approaches that require data to be copied to a single location are hampered by the challenges of data sharing. Federated Learning is a promising approach to learn a joint model over data silos. This architecture does not share any subject data across sites, only aggregated parameters, often in encrypted environments, thus satisfying privacy and regulatory requirements. Here, we describe our Federated Learning architecture and training policies. We demonstrate our approach on a brain age prediction model on structural MRI scans distributed across multiple sites with diverse amounts of data and subject (age) distributions.
In these heterogeneous environments, our Semi-Synchronous protocol provides faster convergence.</span></p>
</div>
<div id="p1" class="ltx_para">
<p id="p1.1" class="ltx_p"><span id="p1.1.1" class="ltx_text ltx_font_bold ltx_font_italic">Index Terms<span id="p1.1.1.1" class="ltx_text ltx_font_upright">— </span></span>
Deep Learning, Federated Learning</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Advances in computer technology, electronic medical records, and cost-efficient biomedical data acquisition, from sensors to genetic tests, allow healthcare organizations and biomedical research studies to collect increasing amounts of data. Analysis of these vast datasets using machine learning approaches promises novel discoveries. Unfortunately, privacy, security, and regulatory constraints make sharing datasets across studies or organizations extremely difficult, so that this promise is largely unfulfilled since joint analyses are limited.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">To address these challenges, Federated Learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> has emerged as a novel privacy-preserving distributed machine learning paradigm that enables large-scale cross-institutional analysis without the need to move the data out of its original location. Federated Learning allows institutions to collaboratively train a machine learning model (e.g., a neural network) by aggregating the parameters (e.g., gradients) of local models trained on local data. Since subject data is not shared, and parameters can be protected through encryption, privacy concerns are ameliorated. Even though Federated Learning was originally developed for mobile and edge devices, it is being increasingly applied in biomedical and healthcare domains <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib5" title="" class="ltx_ref">5</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>, <a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.
We developed a Federated Learning architecture and training policies resilient to data and computational heterogeneity, where different sites may have different data amounts, target distributions, and computational capabilities <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>, which are often characteristic of biomedical studies.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">Brain age prediction from brain structural MRIs is a challenging biomedical task. The difference between the predicted and chronological brain age values is a phenotype related to aging and brain disease. Recent work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite> has shown that deep learning methods can accurately predict an individual’s brain age. However, data scarcity limits the power of these methods, since privacy requirements make data sharing difficult. The
Federated Learning paradigm is a natural fit for these challenging learning environments.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Here, we present our Federated Learning (FL) architecture and an empirical evaluation of brain age prediction under homogeneous, and heterogeneous environments with different amounts of data, and with data not independently and identically distributed (Non-IID) across sites <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. We compare the effectiveness of the federated model to its centralized counterpart. We show that in heterogeneous environments, our communication-efficient Semi-Synchronous training policy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> provides faster convergence.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Federated Learning holds much promise in healthcare domains <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Silva et al. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> present an open-source FL framework for healthcare, supporting different models and optimization methods.
FL has been used for phenotype discovery <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>, for patient representation learning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, and for identifying similar patients across institutions <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">In biomedical imaging, Federated Learning has been applied to multiple tasks, including whole-brain segmentation of MRI T1 scans <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, brain tumor segmentation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>, multi-site fMRI classification and identification of disease biomarkers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>, and for identification of brain structural relationships across diseases and clinical cohorts using (federated) dimensionality reduction from shape features <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. COINSTAC <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> provides a privacy-preserving distributed data processing framework for brain imaging.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">Depending on the requirements and computational characteristics of the federated learning environment, the participating sites (learners) can be organized under different topologies <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. In a star topology (Figure <a href="#S3.F1" title="Figure 1 ‣ 3 Federated Learning ‣ Scaling Neuroscience Research using Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>), the learners communicate through a head server that is responsible for coordinating the federation training (e.g., our work and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>, <a href="#bib.bib16" title="" class="ltx_ref">16</a>, <a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite>). In a peer-to-peer topology <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, learners can communicate directly with each other without a distinguished coordinator.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p id="S2.p4.1" class="ltx_p">Most current FL approaches <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> compute the global model through a synchronous communication protocol. However, in heterogeneous environments, stragglers may slow down convergence. Our Semi-Synchronous protocol <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> counters this inefficiency by assigning more local computation to the underutilized learners to accelerate convergence.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p id="S2.p5.1" class="ltx_p">Preserving data privacy is critical in Federated Learning environments. Common methods for privacy protection are differential privacy <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> and homomorphic encryption <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. For example, the federated learning system for brain tumor segmentation in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite> used differential privacy techniques.
We are developing a homomorphic encryption approach in our architecture, but it is out of the scope of this paper.</p>
</div>
<div id="S2.p6" class="ltx_para">
<p id="S2.p6.1" class="ltx_p">Finally, our deep learning model for estimating brain age from structural MRI scans is closely related (albeit different) to <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>, <a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>.
However, we use Federated Learning to learn the joint model, as opposed to using majority voting and linear regression data blending to combine CNN brain age predictions from different data sources as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Federated Learning</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">Federated Learning operates over sites that do not share data, so the joint model is obtained through parameter sharing and mixing <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.
Figure <a href="#S3.F1" title="Figure 1 ‣ 3 Federated Learning ‣ Scaling Neuroscience Research using Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the typical Federated Learning architecture. Here, we consider that a single neural network, known to all the sites, is being optimized.
Each site (learner) trains the neural network on its own local private dataset and shares only the locally-learned parameters with a head server, the Federation controller, which is responsible for aggregating the local parameters to generate a community neural network, which is in turn sent back to the learners.</p>
</div>
<div id="S3.p2" class="ltx_para ltx_noindent">
<p id="S3.p2.1" class="ltx_p"><span id="S3.p2.1.1" class="ltx_text ltx_font_bold">Federated Optimization.</span> The primary goal in Federated Learning is to jointly learn a global/community model across a federation of N learners, with non-co-located data, by optimizing the global objective <math id="S3.p2.1.m1.1" class="ltx_Math" alttext="f(w)" display="inline"><semantics id="S3.p2.1.m1.1a"><mrow id="S3.p2.1.m1.1.2" xref="S3.p2.1.m1.1.2.cmml"><mi id="S3.p2.1.m1.1.2.2" xref="S3.p2.1.m1.1.2.2.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.p2.1.m1.1.2.1" xref="S3.p2.1.m1.1.2.1.cmml">​</mo><mrow id="S3.p2.1.m1.1.2.3.2" xref="S3.p2.1.m1.1.2.cmml"><mo stretchy="false" id="S3.p2.1.m1.1.2.3.2.1" xref="S3.p2.1.m1.1.2.cmml">(</mo><mi id="S3.p2.1.m1.1.1" xref="S3.p2.1.m1.1.1.cmml">w</mi><mo stretchy="false" id="S3.p2.1.m1.1.2.3.2.2" xref="S3.p2.1.m1.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.1.m1.1b"><apply id="S3.p2.1.m1.1.2.cmml" xref="S3.p2.1.m1.1.2"><times id="S3.p2.1.m1.1.2.1.cmml" xref="S3.p2.1.m1.1.2.1"></times><ci id="S3.p2.1.m1.1.2.2.cmml" xref="S3.p2.1.m1.1.2.2">𝑓</ci><ci id="S3.p2.1.m1.1.1.cmml" xref="S3.p2.1.m1.1.1">𝑤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.1.m1.1c">f(w)</annotation></semantics></math>:</p>
<table id="S3.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E1.m1.3" class="ltx_Math" alttext="w^{*}=\underset{w}{\mathrm{argmin}}f(w)\&gt;\&gt;\text{with}\&gt;\&gt;f(w)=\sum_{k=1}^{N}\frac{p_{k}}{\sum p_{k}}F_{k}(w)" display="block"><semantics id="S3.E1.m1.3a"><mrow id="S3.E1.m1.3.4" xref="S3.E1.m1.3.4.cmml"><msup id="S3.E1.m1.3.4.2" xref="S3.E1.m1.3.4.2.cmml"><mi id="S3.E1.m1.3.4.2.2" xref="S3.E1.m1.3.4.2.2.cmml">w</mi><mo id="S3.E1.m1.3.4.2.3" xref="S3.E1.m1.3.4.2.3.cmml">∗</mo></msup><mo id="S3.E1.m1.3.4.3" xref="S3.E1.m1.3.4.3.cmml">=</mo><mrow id="S3.E1.m1.3.4.4" xref="S3.E1.m1.3.4.4.cmml"><munder accentunder="true" id="S3.E1.m1.3.4.4.2" xref="S3.E1.m1.3.4.4.2.cmml"><mi id="S3.E1.m1.3.4.4.2.2" xref="S3.E1.m1.3.4.4.2.2.cmml">argmin</mi><mo id="S3.E1.m1.3.4.4.2.1" xref="S3.E1.m1.3.4.4.2.1.cmml">𝑤</mo></munder><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.4.4.1" xref="S3.E1.m1.3.4.4.1.cmml">​</mo><mi id="S3.E1.m1.3.4.4.3" xref="S3.E1.m1.3.4.4.3.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.4.4.1a" xref="S3.E1.m1.3.4.4.1.cmml">​</mo><mrow id="S3.E1.m1.3.4.4.4.2" xref="S3.E1.m1.3.4.4.cmml"><mo stretchy="false" id="S3.E1.m1.3.4.4.4.2.1" xref="S3.E1.m1.3.4.4.cmml">(</mo><mi id="S3.E1.m1.1.1" xref="S3.E1.m1.1.1.cmml">w</mi><mo stretchy="false" id="S3.E1.m1.3.4.4.4.2.2" xref="S3.E1.m1.3.4.4.cmml">)</mo></mrow><mo lspace="0.440em" rspace="0em" id="S3.E1.m1.3.4.4.1b" xref="S3.E1.m1.3.4.4.1.cmml">​</mo><mtext id="S3.E1.m1.3.4.4.5" xref="S3.E1.m1.3.4.4.5a.cmml">with</mtext><mo lspace="0.440em" rspace="0em" id="S3.E1.m1.3.4.4.1c" xref="S3.E1.m1.3.4.4.1.cmml">​</mo><mi id="S3.E1.m1.3.4.4.6" xref="S3.E1.m1.3.4.4.6.cmml">f</mi><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.4.4.1d" xref="S3.E1.m1.3.4.4.1.cmml">​</mo><mrow id="S3.E1.m1.3.4.4.7.2" xref="S3.E1.m1.3.4.4.cmml"><mo stretchy="false" id="S3.E1.m1.3.4.4.7.2.1" xref="S3.E1.m1.3.4.4.cmml">(</mo><mi id="S3.E1.m1.2.2" xref="S3.E1.m1.2.2.cmml">w</mi><mo stretchy="false" id="S3.E1.m1.3.4.4.7.2.2" xref="S3.E1.m1.3.4.4.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S3.E1.m1.3.4.5" xref="S3.E1.m1.3.4.5.cmml">=</mo><mrow id="S3.E1.m1.3.4.6" xref="S3.E1.m1.3.4.6.cmml"><munderover id="S3.E1.m1.3.4.6.1" xref="S3.E1.m1.3.4.6.1.cmml"><mo movablelimits="false" id="S3.E1.m1.3.4.6.1.2.2" xref="S3.E1.m1.3.4.6.1.2.2.cmml">∑</mo><mrow id="S3.E1.m1.3.4.6.1.2.3" xref="S3.E1.m1.3.4.6.1.2.3.cmml"><mi id="S3.E1.m1.3.4.6.1.2.3.2" xref="S3.E1.m1.3.4.6.1.2.3.2.cmml">k</mi><mo id="S3.E1.m1.3.4.6.1.2.3.1" xref="S3.E1.m1.3.4.6.1.2.3.1.cmml">=</mo><mn id="S3.E1.m1.3.4.6.1.2.3.3" xref="S3.E1.m1.3.4.6.1.2.3.3.cmml">1</mn></mrow><mi id="S3.E1.m1.3.4.6.1.3" xref="S3.E1.m1.3.4.6.1.3.cmml">N</mi></munderover><mrow id="S3.E1.m1.3.4.6.2" xref="S3.E1.m1.3.4.6.2.cmml"><mfrac id="S3.E1.m1.3.4.6.2.2" xref="S3.E1.m1.3.4.6.2.2.cmml"><msub id="S3.E1.m1.3.4.6.2.2.2" xref="S3.E1.m1.3.4.6.2.2.2.cmml"><mi id="S3.E1.m1.3.4.6.2.2.2.2" xref="S3.E1.m1.3.4.6.2.2.2.2.cmml">p</mi><mi id="S3.E1.m1.3.4.6.2.2.2.3" xref="S3.E1.m1.3.4.6.2.2.2.3.cmml">k</mi></msub><mrow id="S3.E1.m1.3.4.6.2.2.3" xref="S3.E1.m1.3.4.6.2.2.3.cmml"><mo id="S3.E1.m1.3.4.6.2.2.3.1" xref="S3.E1.m1.3.4.6.2.2.3.1.cmml">∑</mo><msub id="S3.E1.m1.3.4.6.2.2.3.2" xref="S3.E1.m1.3.4.6.2.2.3.2.cmml"><mi id="S3.E1.m1.3.4.6.2.2.3.2.2" xref="S3.E1.m1.3.4.6.2.2.3.2.2.cmml">p</mi><mi id="S3.E1.m1.3.4.6.2.2.3.2.3" xref="S3.E1.m1.3.4.6.2.2.3.2.3.cmml">k</mi></msub></mrow></mfrac><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.4.6.2.1" xref="S3.E1.m1.3.4.6.2.1.cmml">​</mo><msub id="S3.E1.m1.3.4.6.2.3" xref="S3.E1.m1.3.4.6.2.3.cmml"><mi id="S3.E1.m1.3.4.6.2.3.2" xref="S3.E1.m1.3.4.6.2.3.2.cmml">F</mi><mi id="S3.E1.m1.3.4.6.2.3.3" xref="S3.E1.m1.3.4.6.2.3.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S3.E1.m1.3.4.6.2.1a" xref="S3.E1.m1.3.4.6.2.1.cmml">​</mo><mrow id="S3.E1.m1.3.4.6.2.4.2" xref="S3.E1.m1.3.4.6.2.cmml"><mo stretchy="false" id="S3.E1.m1.3.4.6.2.4.2.1" xref="S3.E1.m1.3.4.6.2.cmml">(</mo><mi id="S3.E1.m1.3.3" xref="S3.E1.m1.3.3.cmml">w</mi><mo stretchy="false" id="S3.E1.m1.3.4.6.2.4.2.2" xref="S3.E1.m1.3.4.6.2.cmml">)</mo></mrow></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.E1.m1.3b"><apply id="S3.E1.m1.3.4.cmml" xref="S3.E1.m1.3.4"><and id="S3.E1.m1.3.4a.cmml" xref="S3.E1.m1.3.4"></and><apply id="S3.E1.m1.3.4b.cmml" xref="S3.E1.m1.3.4"><eq id="S3.E1.m1.3.4.3.cmml" xref="S3.E1.m1.3.4.3"></eq><apply id="S3.E1.m1.3.4.2.cmml" xref="S3.E1.m1.3.4.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.4.2.1.cmml" xref="S3.E1.m1.3.4.2">superscript</csymbol><ci id="S3.E1.m1.3.4.2.2.cmml" xref="S3.E1.m1.3.4.2.2">𝑤</ci><times id="S3.E1.m1.3.4.2.3.cmml" xref="S3.E1.m1.3.4.2.3"></times></apply><apply id="S3.E1.m1.3.4.4.cmml" xref="S3.E1.m1.3.4.4"><times id="S3.E1.m1.3.4.4.1.cmml" xref="S3.E1.m1.3.4.4.1"></times><apply id="S3.E1.m1.3.4.4.2.cmml" xref="S3.E1.m1.3.4.4.2"><ci id="S3.E1.m1.3.4.4.2.1.cmml" xref="S3.E1.m1.3.4.4.2.1">𝑤</ci><ci id="S3.E1.m1.3.4.4.2.2.cmml" xref="S3.E1.m1.3.4.4.2.2">argmin</ci></apply><ci id="S3.E1.m1.3.4.4.3.cmml" xref="S3.E1.m1.3.4.4.3">𝑓</ci><ci id="S3.E1.m1.1.1.cmml" xref="S3.E1.m1.1.1">𝑤</ci><ci id="S3.E1.m1.3.4.4.5a.cmml" xref="S3.E1.m1.3.4.4.5"><mtext id="S3.E1.m1.3.4.4.5.cmml" xref="S3.E1.m1.3.4.4.5">with</mtext></ci><ci id="S3.E1.m1.3.4.4.6.cmml" xref="S3.E1.m1.3.4.4.6">𝑓</ci><ci id="S3.E1.m1.2.2.cmml" xref="S3.E1.m1.2.2">𝑤</ci></apply></apply><apply id="S3.E1.m1.3.4c.cmml" xref="S3.E1.m1.3.4"><eq id="S3.E1.m1.3.4.5.cmml" xref="S3.E1.m1.3.4.5"></eq><share href="#S3.E1.m1.3.4.4.cmml" id="S3.E1.m1.3.4d.cmml" xref="S3.E1.m1.3.4"></share><apply id="S3.E1.m1.3.4.6.cmml" xref="S3.E1.m1.3.4.6"><apply id="S3.E1.m1.3.4.6.1.cmml" xref="S3.E1.m1.3.4.6.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.4.6.1.1.cmml" xref="S3.E1.m1.3.4.6.1">superscript</csymbol><apply id="S3.E1.m1.3.4.6.1.2.cmml" xref="S3.E1.m1.3.4.6.1"><csymbol cd="ambiguous" id="S3.E1.m1.3.4.6.1.2.1.cmml" xref="S3.E1.m1.3.4.6.1">subscript</csymbol><sum id="S3.E1.m1.3.4.6.1.2.2.cmml" xref="S3.E1.m1.3.4.6.1.2.2"></sum><apply id="S3.E1.m1.3.4.6.1.2.3.cmml" xref="S3.E1.m1.3.4.6.1.2.3"><eq id="S3.E1.m1.3.4.6.1.2.3.1.cmml" xref="S3.E1.m1.3.4.6.1.2.3.1"></eq><ci id="S3.E1.m1.3.4.6.1.2.3.2.cmml" xref="S3.E1.m1.3.4.6.1.2.3.2">𝑘</ci><cn type="integer" id="S3.E1.m1.3.4.6.1.2.3.3.cmml" xref="S3.E1.m1.3.4.6.1.2.3.3">1</cn></apply></apply><ci id="S3.E1.m1.3.4.6.1.3.cmml" xref="S3.E1.m1.3.4.6.1.3">𝑁</ci></apply><apply id="S3.E1.m1.3.4.6.2.cmml" xref="S3.E1.m1.3.4.6.2"><times id="S3.E1.m1.3.4.6.2.1.cmml" xref="S3.E1.m1.3.4.6.2.1"></times><apply id="S3.E1.m1.3.4.6.2.2.cmml" xref="S3.E1.m1.3.4.6.2.2"><divide id="S3.E1.m1.3.4.6.2.2.1.cmml" xref="S3.E1.m1.3.4.6.2.2"></divide><apply id="S3.E1.m1.3.4.6.2.2.2.cmml" xref="S3.E1.m1.3.4.6.2.2.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.4.6.2.2.2.1.cmml" xref="S3.E1.m1.3.4.6.2.2.2">subscript</csymbol><ci id="S3.E1.m1.3.4.6.2.2.2.2.cmml" xref="S3.E1.m1.3.4.6.2.2.2.2">𝑝</ci><ci id="S3.E1.m1.3.4.6.2.2.2.3.cmml" xref="S3.E1.m1.3.4.6.2.2.2.3">𝑘</ci></apply><apply id="S3.E1.m1.3.4.6.2.2.3.cmml" xref="S3.E1.m1.3.4.6.2.2.3"><sum id="S3.E1.m1.3.4.6.2.2.3.1.cmml" xref="S3.E1.m1.3.4.6.2.2.3.1"></sum><apply id="S3.E1.m1.3.4.6.2.2.3.2.cmml" xref="S3.E1.m1.3.4.6.2.2.3.2"><csymbol cd="ambiguous" id="S3.E1.m1.3.4.6.2.2.3.2.1.cmml" xref="S3.E1.m1.3.4.6.2.2.3.2">subscript</csymbol><ci id="S3.E1.m1.3.4.6.2.2.3.2.2.cmml" xref="S3.E1.m1.3.4.6.2.2.3.2.2">𝑝</ci><ci id="S3.E1.m1.3.4.6.2.2.3.2.3.cmml" xref="S3.E1.m1.3.4.6.2.2.3.2.3">𝑘</ci></apply></apply></apply><apply id="S3.E1.m1.3.4.6.2.3.cmml" xref="S3.E1.m1.3.4.6.2.3"><csymbol cd="ambiguous" id="S3.E1.m1.3.4.6.2.3.1.cmml" xref="S3.E1.m1.3.4.6.2.3">subscript</csymbol><ci id="S3.E1.m1.3.4.6.2.3.2.cmml" xref="S3.E1.m1.3.4.6.2.3.2">𝐹</ci><ci id="S3.E1.m1.3.4.6.2.3.3.cmml" xref="S3.E1.m1.3.4.6.2.3.3">𝑘</ci></apply><ci id="S3.E1.m1.3.3.cmml" xref="S3.E1.m1.3.3">𝑤</ci></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.E1.m1.3c">w^{*}=\underset{w}{\mathrm{argmin}}f(w)\&gt;\&gt;\text{with}\&gt;\&gt;f(w)=\sum_{k=1}^{N}\frac{p_{k}}{\sum p_{k}}F_{k}(w)</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
<p id="S3.p2.6" class="ltx_p">where <math id="S3.p2.2.m1.1" class="ltx_Math" alttext="p_{k}" display="inline"><semantics id="S3.p2.2.m1.1a"><msub id="S3.p2.2.m1.1.1" xref="S3.p2.2.m1.1.1.cmml"><mi id="S3.p2.2.m1.1.1.2" xref="S3.p2.2.m1.1.1.2.cmml">p</mi><mi id="S3.p2.2.m1.1.1.3" xref="S3.p2.2.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.2.m1.1b"><apply id="S3.p2.2.m1.1.1.cmml" xref="S3.p2.2.m1.1.1"><csymbol cd="ambiguous" id="S3.p2.2.m1.1.1.1.cmml" xref="S3.p2.2.m1.1.1">subscript</csymbol><ci id="S3.p2.2.m1.1.1.2.cmml" xref="S3.p2.2.m1.1.1.2">𝑝</ci><ci id="S3.p2.2.m1.1.1.3.cmml" xref="S3.p2.2.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.2.m1.1c">p_{k}</annotation></semantics></math> is the contribution value of a learner <math id="S3.p2.3.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.p2.3.m2.1a"><mi id="S3.p2.3.m2.1.1" xref="S3.p2.3.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.p2.3.m2.1b"><ci id="S3.p2.3.m2.1.1.cmml" xref="S3.p2.3.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.3.m2.1c">k</annotation></semantics></math> to the federation and <math id="S3.p2.4.m3.1" class="ltx_Math" alttext="F_{k}(w)" display="inline"><semantics id="S3.p2.4.m3.1a"><mrow id="S3.p2.4.m3.1.2" xref="S3.p2.4.m3.1.2.cmml"><msub id="S3.p2.4.m3.1.2.2" xref="S3.p2.4.m3.1.2.2.cmml"><mi id="S3.p2.4.m3.1.2.2.2" xref="S3.p2.4.m3.1.2.2.2.cmml">F</mi><mi id="S3.p2.4.m3.1.2.2.3" xref="S3.p2.4.m3.1.2.2.3.cmml">k</mi></msub><mo lspace="0em" rspace="0em" id="S3.p2.4.m3.1.2.1" xref="S3.p2.4.m3.1.2.1.cmml">​</mo><mrow id="S3.p2.4.m3.1.2.3.2" xref="S3.p2.4.m3.1.2.cmml"><mo stretchy="false" id="S3.p2.4.m3.1.2.3.2.1" xref="S3.p2.4.m3.1.2.cmml">(</mo><mi id="S3.p2.4.m3.1.1" xref="S3.p2.4.m3.1.1.cmml">w</mi><mo stretchy="false" id="S3.p2.4.m3.1.2.3.2.2" xref="S3.p2.4.m3.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.4.m3.1b"><apply id="S3.p2.4.m3.1.2.cmml" xref="S3.p2.4.m3.1.2"><times id="S3.p2.4.m3.1.2.1.cmml" xref="S3.p2.4.m3.1.2.1"></times><apply id="S3.p2.4.m3.1.2.2.cmml" xref="S3.p2.4.m3.1.2.2"><csymbol cd="ambiguous" id="S3.p2.4.m3.1.2.2.1.cmml" xref="S3.p2.4.m3.1.2.2">subscript</csymbol><ci id="S3.p2.4.m3.1.2.2.2.cmml" xref="S3.p2.4.m3.1.2.2.2">𝐹</ci><ci id="S3.p2.4.m3.1.2.2.3.cmml" xref="S3.p2.4.m3.1.2.2.3">𝑘</ci></apply><ci id="S3.p2.4.m3.1.1.cmml" xref="S3.p2.4.m3.1.1">𝑤</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.4.m3.1c">F_{k}(w)</annotation></semantics></math> its local objective function.
The contribution value <math id="S3.p2.5.m4.1" class="ltx_Math" alttext="p_{k}" display="inline"><semantics id="S3.p2.5.m4.1a"><msub id="S3.p2.5.m4.1.1" xref="S3.p2.5.m4.1.1.cmml"><mi id="S3.p2.5.m4.1.1.2" xref="S3.p2.5.m4.1.1.2.cmml">p</mi><mi id="S3.p2.5.m4.1.1.3" xref="S3.p2.5.m4.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p2.5.m4.1b"><apply id="S3.p2.5.m4.1.1.cmml" xref="S3.p2.5.m4.1.1"><csymbol cd="ambiguous" id="S3.p2.5.m4.1.1.1.cmml" xref="S3.p2.5.m4.1.1">subscript</csymbol><ci id="S3.p2.5.m4.1.1.2.cmml" xref="S3.p2.5.m4.1.1.2">𝑝</ci><ci id="S3.p2.5.m4.1.1.3.cmml" xref="S3.p2.5.m4.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.5.m4.1c">p_{k}</annotation></semantics></math> can be static, or dynamically defined at run time <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. In much recent work <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, the learners are weighted based on the number of local training examples (<math id="S3.p2.6.m5.1" class="ltx_Math" alttext="p_{k}=|D_{k}^{T}|" display="inline"><semantics id="S3.p2.6.m5.1a"><mrow id="S3.p2.6.m5.1.1" xref="S3.p2.6.m5.1.1.cmml"><msub id="S3.p2.6.m5.1.1.3" xref="S3.p2.6.m5.1.1.3.cmml"><mi id="S3.p2.6.m5.1.1.3.2" xref="S3.p2.6.m5.1.1.3.2.cmml">p</mi><mi id="S3.p2.6.m5.1.1.3.3" xref="S3.p2.6.m5.1.1.3.3.cmml">k</mi></msub><mo id="S3.p2.6.m5.1.1.2" xref="S3.p2.6.m5.1.1.2.cmml">=</mo><mrow id="S3.p2.6.m5.1.1.1.1" xref="S3.p2.6.m5.1.1.1.2.cmml"><mo stretchy="false" id="S3.p2.6.m5.1.1.1.1.2" xref="S3.p2.6.m5.1.1.1.2.1.cmml">|</mo><msubsup id="S3.p2.6.m5.1.1.1.1.1" xref="S3.p2.6.m5.1.1.1.1.1.cmml"><mi id="S3.p2.6.m5.1.1.1.1.1.2.2" xref="S3.p2.6.m5.1.1.1.1.1.2.2.cmml">D</mi><mi id="S3.p2.6.m5.1.1.1.1.1.2.3" xref="S3.p2.6.m5.1.1.1.1.1.2.3.cmml">k</mi><mi id="S3.p2.6.m5.1.1.1.1.1.3" xref="S3.p2.6.m5.1.1.1.1.1.3.cmml">T</mi></msubsup><mo stretchy="false" id="S3.p2.6.m5.1.1.1.1.3" xref="S3.p2.6.m5.1.1.1.2.1.cmml">|</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p2.6.m5.1b"><apply id="S3.p2.6.m5.1.1.cmml" xref="S3.p2.6.m5.1.1"><eq id="S3.p2.6.m5.1.1.2.cmml" xref="S3.p2.6.m5.1.1.2"></eq><apply id="S3.p2.6.m5.1.1.3.cmml" xref="S3.p2.6.m5.1.1.3"><csymbol cd="ambiguous" id="S3.p2.6.m5.1.1.3.1.cmml" xref="S3.p2.6.m5.1.1.3">subscript</csymbol><ci id="S3.p2.6.m5.1.1.3.2.cmml" xref="S3.p2.6.m5.1.1.3.2">𝑝</ci><ci id="S3.p2.6.m5.1.1.3.3.cmml" xref="S3.p2.6.m5.1.1.3.3">𝑘</ci></apply><apply id="S3.p2.6.m5.1.1.1.2.cmml" xref="S3.p2.6.m5.1.1.1.1"><abs id="S3.p2.6.m5.1.1.1.2.1.cmml" xref="S3.p2.6.m5.1.1.1.1.2"></abs><apply id="S3.p2.6.m5.1.1.1.1.1.cmml" xref="S3.p2.6.m5.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.6.m5.1.1.1.1.1.1.cmml" xref="S3.p2.6.m5.1.1.1.1.1">superscript</csymbol><apply id="S3.p2.6.m5.1.1.1.1.1.2.cmml" xref="S3.p2.6.m5.1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p2.6.m5.1.1.1.1.1.2.1.cmml" xref="S3.p2.6.m5.1.1.1.1.1">subscript</csymbol><ci id="S3.p2.6.m5.1.1.1.1.1.2.2.cmml" xref="S3.p2.6.m5.1.1.1.1.1.2.2">𝐷</ci><ci id="S3.p2.6.m5.1.1.1.1.1.2.3.cmml" xref="S3.p2.6.m5.1.1.1.1.1.2.3">𝑘</ci></apply><ci id="S3.p2.6.m5.1.1.1.1.1.3.cmml" xref="S3.p2.6.m5.1.1.1.1.1.3">𝑇</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p2.6.m5.1c">p_{k}=|D_{k}^{T}|</annotation></semantics></math>), since this is a good proxy for the value of a local model, but other methods that directly measure performance are possible <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
<figure id="S3.F1" class="ltx_figure"><img src="/html/2102.08440/assets/brainage_plots/BrainAgeFederationArchitecture.png" id="S3.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="328" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S3.F1.2.1.1" class="ltx_text ltx_font_bold">Fig. 1</span>: </span>Federated Learning Architecture</figcaption>
</figure>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p"><span id="S3.p3.1.1" class="ltx_text ltx_font_bold">Synchronous Training.</span> In the original Federated Learning algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, every learner performs a predefined number of local updates (batches or epochs) before reaching a synchronization point where it shares its local model with the federation. This computational approach, which we refer to as Synchronous Federated Average (<span id="S3.p3.1.2" class="ltx_text ltx_font_italic">SyncFedAvg</span>), has been extensively explored <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib12" title="" class="ltx_ref">12</a>, <a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>.</p>
</div>
<div id="S3.p4" class="ltx_para ltx_noindent">
<p id="S3.p4.2" class="ltx_p"><span id="S3.p4.2.1" class="ltx_text ltx_font_bold">Semi-Synchronous Training.</span> We introduced a Semi-Synchronous training protocol (<span id="S3.p4.2.2" class="ltx_text ltx_font_italic">SemiSync</span>) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite> where each learner trains for a given amount of time before synchronization. Each learner processes a variable number of data batches between synchronization points depending on its computational power and amount of data.
SemiSync parameterizes the synchronization period based on the time that it takes for the slowest learner in the federation to perform a single epoch. The number of local updates (batches) <math id="S3.p4.1.m1.1" class="ltx_Math" alttext="\mathcal{B}_{k}" display="inline"><semantics id="S3.p4.1.m1.1a"><msub id="S3.p4.1.m1.1.1" xref="S3.p4.1.m1.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S3.p4.1.m1.1.1.2" xref="S3.p4.1.m1.1.1.2.cmml">ℬ</mi><mi id="S3.p4.1.m1.1.1.3" xref="S3.p4.1.m1.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p4.1.m1.1b"><apply id="S3.p4.1.m1.1.1.cmml" xref="S3.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S3.p4.1.m1.1.1.1.cmml" xref="S3.p4.1.m1.1.1">subscript</csymbol><ci id="S3.p4.1.m1.1.1.2.cmml" xref="S3.p4.1.m1.1.1.2">ℬ</ci><ci id="S3.p4.1.m1.1.1.3.cmml" xref="S3.p4.1.m1.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.1.m1.1c">\mathcal{B}_{k}</annotation></semantics></math> a learner <math id="S3.p4.2.m2.1" class="ltx_Math" alttext="k" display="inline"><semantics id="S3.p4.2.m2.1a"><mi id="S3.p4.2.m2.1.1" xref="S3.p4.2.m2.1.1.cmml">k</mi><annotation-xml encoding="MathML-Content" id="S3.p4.2.m2.1b"><ci id="S3.p4.2.m2.1.1.cmml" xref="S3.p4.2.m2.1.1">𝑘</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.2.m2.1c">k</annotation></semantics></math> performs between synchronization points is computed as:</p>
<table id="S3.E2" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S3.E2.m1.39" class="ltx_math_unparsed" alttext="\begin{gathered}t_{max}(\lambda)=\lambda*\max\limits_{k\in N}{\{\frac{|D_{k}^{T}|}{\beta_{k}}*t_{\beta_{k}}\}},\lambda,\beta_{k},t_{\beta_{k}}&gt;0\\
\mathcal{B}_{k}=\dfrac{t_{max}}{t_{\beta_{k}}},\quad\forall k\in N\end{gathered}" display="block"><semantics id="S3.E2.m1.39a"><mtable displaystyle="true" rowspacing="0pt" id="S3.E2.m1.39.39.4"><mtr id="S3.E2.m1.39.39.4a"><mtd id="S3.E2.m1.39.39.4b"><mrow id="S3.E2.m1.37.37.2.37.28.28.28"><mrow id="S3.E2.m1.36.36.1.36.27.27.27.1"><mrow id="S3.E2.m1.36.36.1.36.27.27.27.1.3"><msub id="S3.E2.m1.36.36.1.36.27.27.27.1.3.2"><mi id="S3.E2.m1.1.1.1.1.1.1">t</mi><mrow id="S3.E2.m1.2.2.2.2.2.2.1"><mi id="S3.E2.m1.2.2.2.2.2.2.1.2">m</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.2.2.2.1.1">​</mo><mi id="S3.E2.m1.2.2.2.2.2.2.1.3">a</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.2.2.2.2.2.2.1.1a">​</mo><mi id="S3.E2.m1.2.2.2.2.2.2.1.4">x</mi></mrow></msub><mo lspace="0em" rspace="0em" id="S3.E2.m1.36.36.1.36.27.27.27.1.3.1">​</mo><mrow id="S3.E2.m1.36.36.1.36.27.27.27.1.3.3"><mo stretchy="false" id="S3.E2.m1.3.3.3.3.3.3">(</mo><mi id="S3.E2.m1.4.4.4.4.4.4">λ</mi><mo stretchy="false" id="S3.E2.m1.5.5.5.5.5.5">)</mo></mrow></mrow><mo id="S3.E2.m1.6.6.6.6.6.6">=</mo><mrow id="S3.E2.m1.36.36.1.36.27.27.27.1.2.2"><mrow id="S3.E2.m1.36.36.1.36.27.27.27.1.1.1.1"><mi id="S3.E2.m1.7.7.7.7.7.7">λ</mi><mo lspace="0.222em" rspace="0.222em" id="S3.E2.m1.8.8.8.8.8.8">∗</mo><mrow id="S3.E2.m1.36.36.1.36.27.27.27.1.1.1.1.2.2"><munder id="S3.E2.m1.36.36.1.36.27.27.27.1.1.1.1.1.1.1"><mi id="S3.E2.m1.9.9.9.9.9.9">max</mi><mrow id="S3.E2.m1.10.10.10.10.10.10.1"><mi id="S3.E2.m1.10.10.10.10.10.10.1.2">k</mi><mo id="S3.E2.m1.10.10.10.10.10.10.1.1">∈</mo><mi id="S3.E2.m1.10.10.10.10.10.10.1.3">N</mi></mrow></munder><mo id="S3.E2.m1.36.36.1.36.27.27.27.1.1.1.1.2.2a">⁡</mo><mrow id="S3.E2.m1.36.36.1.36.27.27.27.1.1.1.1.2.2.2"><mo stretchy="false" id="S3.E2.m1.11.11.11.11.11.11">{</mo><mrow id="S3.E2.m1.36.36.1.36.27.27.27.1.1.1.1.2.2.2.1"><mfrac id="S3.E2.m1.12.12.12.12.12.12"><mrow id="S3.E2.m1.12.12.12.12.12.12.1.1"><mo stretchy="false" id="S3.E2.m1.12.12.12.12.12.12.1.1.2">|</mo><msubsup id="S3.E2.m1.12.12.12.12.12.12.1.1.1"><mi id="S3.E2.m1.12.12.12.12.12.12.1.1.1.2.2">D</mi><mi id="S3.E2.m1.12.12.12.12.12.12.1.1.1.2.3">k</mi><mi id="S3.E2.m1.12.12.12.12.12.12.1.1.1.3">T</mi></msubsup><mo stretchy="false" id="S3.E2.m1.12.12.12.12.12.12.1.1.3">|</mo></mrow><msub id="S3.E2.m1.12.12.12.12.12.12.3"><mi id="S3.E2.m1.12.12.12.12.12.12.3.2">β</mi><mi id="S3.E2.m1.12.12.12.12.12.12.3.3">k</mi></msub></mfrac><mo lspace="0.222em" rspace="0.222em" id="S3.E2.m1.13.13.13.13.13.13">∗</mo><msub id="S3.E2.m1.36.36.1.36.27.27.27.1.1.1.1.2.2.2.1.1"><mi id="S3.E2.m1.14.14.14.14.14.14">t</mi><msub id="S3.E2.m1.15.15.15.15.15.15.1"><mi id="S3.E2.m1.15.15.15.15.15.15.1.2">β</mi><mi id="S3.E2.m1.15.15.15.15.15.15.1.3">k</mi></msub></msub></mrow><mo stretchy="false" id="S3.E2.m1.16.16.16.16.16.16">}</mo></mrow></mrow></mrow><mo id="S3.E2.m1.17.17.17.17.17.17">,</mo><mi id="S3.E2.m1.18.18.18.18.18.18">λ</mi><mo id="S3.E2.m1.19.19.19.19.19.19">,</mo><msub id="S3.E2.m1.36.36.1.36.27.27.27.1.2.2.2"><mi id="S3.E2.m1.20.20.20.20.20.20">β</mi><mi id="S3.E2.m1.21.21.21.21.21.21.1">k</mi></msub></mrow></mrow><mo id="S3.E2.m1.22.22.22.22.22.22">,</mo><mrow id="S3.E2.m1.37.37.2.37.28.28.28.2"><msub id="S3.E2.m1.37.37.2.37.28.28.28.2.1"><mi id="S3.E2.m1.23.23.23.23.23.23">t</mi><msub id="S3.E2.m1.24.24.24.24.24.24.1"><mi id="S3.E2.m1.24.24.24.24.24.24.1.2">β</mi><mi id="S3.E2.m1.24.24.24.24.24.24.1.3">k</mi></msub></msub><mo id="S3.E2.m1.25.25.25.25.25.25">&gt;</mo><mn id="S3.E2.m1.26.26.26.26.26.26">0</mn></mrow></mrow></mtd></mtr><mtr id="S3.E2.m1.39.39.4c"><mtd id="S3.E2.m1.39.39.4d"><mrow id="S3.E2.m1.39.39.4.39.11.11.11"><mrow id="S3.E2.m1.38.38.3.38.10.10.10.1"><msub id="S3.E2.m1.38.38.3.38.10.10.10.1.1"><mi class="ltx_font_mathcaligraphic" id="S3.E2.m1.27.27.27.1.1.1">ℬ</mi><mi id="S3.E2.m1.28.28.28.2.2.2.1">k</mi></msub><mo id="S3.E2.m1.29.29.29.3.3.3">=</mo><mfrac id="S3.E2.m1.30.30.30.4.4.4"><msub id="S3.E2.m1.30.30.30.4.4.4.2"><mi id="S3.E2.m1.30.30.30.4.4.4.2.2">t</mi><mrow id="S3.E2.m1.30.30.30.4.4.4.2.3"><mi id="S3.E2.m1.30.30.30.4.4.4.2.3.2">m</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.30.30.30.4.4.4.2.3.1">​</mo><mi id="S3.E2.m1.30.30.30.4.4.4.2.3.3">a</mi><mo lspace="0em" rspace="0em" id="S3.E2.m1.30.30.30.4.4.4.2.3.1a">​</mo><mi id="S3.E2.m1.30.30.30.4.4.4.2.3.4">x</mi></mrow></msub><msub id="S3.E2.m1.30.30.30.4.4.4.3"><mi id="S3.E2.m1.30.30.30.4.4.4.3.2">t</mi><msub id="S3.E2.m1.30.30.30.4.4.4.3.3"><mi id="S3.E2.m1.30.30.30.4.4.4.3.3.2">β</mi><mi id="S3.E2.m1.30.30.30.4.4.4.3.3.3">k</mi></msub></msub></mfrac></mrow><mo rspace="1.167em" id="S3.E2.m1.31.31.31.5.5.5">,</mo><mrow id="S3.E2.m1.39.39.4.39.11.11.11.2"><mrow id="S3.E2.m1.39.39.4.39.11.11.11.2.1"><mo rspace="0.167em" id="S3.E2.m1.32.32.32.6.6.6">∀</mo><mi id="S3.E2.m1.33.33.33.7.7.7">k</mi></mrow><mo id="S3.E2.m1.34.34.34.8.8.8">∈</mo><mi id="S3.E2.m1.35.35.35.9.9.9">N</mi></mrow></mrow></mtd></mtr></mtable><annotation encoding="application/x-tex" id="S3.E2.m1.39b">\begin{gathered}t_{max}(\lambda)=\lambda*\max\limits_{k\in N}{\{\frac{|D_{k}^{T}|}{\beta_{k}}*t_{\beta_{k}}\}},\lambda,\beta_{k},t_{\beta_{k}}&gt;0\\
\mathcal{B}_{k}=\dfrac{t_{max}}{t_{\beta_{k}}},\quad\forall k\in N\end{gathered}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(2)</span></td>
</tr></tbody>
</table>
<p id="S3.p4.7" class="ltx_p">where <math id="S3.p4.3.m1.1" class="ltx_Math" alttext="|D_{k}^{T}|" display="inline"><semantics id="S3.p4.3.m1.1a"><mrow id="S3.p4.3.m1.1.1.1" xref="S3.p4.3.m1.1.1.2.cmml"><mo stretchy="false" id="S3.p4.3.m1.1.1.1.2" xref="S3.p4.3.m1.1.1.2.1.cmml">|</mo><msubsup id="S3.p4.3.m1.1.1.1.1" xref="S3.p4.3.m1.1.1.1.1.cmml"><mi id="S3.p4.3.m1.1.1.1.1.2.2" xref="S3.p4.3.m1.1.1.1.1.2.2.cmml">D</mi><mi id="S3.p4.3.m1.1.1.1.1.2.3" xref="S3.p4.3.m1.1.1.1.1.2.3.cmml">k</mi><mi id="S3.p4.3.m1.1.1.1.1.3" xref="S3.p4.3.m1.1.1.1.1.3.cmml">T</mi></msubsup><mo stretchy="false" id="S3.p4.3.m1.1.1.1.3" xref="S3.p4.3.m1.1.1.2.1.cmml">|</mo></mrow><annotation-xml encoding="MathML-Content" id="S3.p4.3.m1.1b"><apply id="S3.p4.3.m1.1.1.2.cmml" xref="S3.p4.3.m1.1.1.1"><abs id="S3.p4.3.m1.1.1.2.1.cmml" xref="S3.p4.3.m1.1.1.1.2"></abs><apply id="S3.p4.3.m1.1.1.1.1.cmml" xref="S3.p4.3.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p4.3.m1.1.1.1.1.1.cmml" xref="S3.p4.3.m1.1.1.1.1">superscript</csymbol><apply id="S3.p4.3.m1.1.1.1.1.2.cmml" xref="S3.p4.3.m1.1.1.1.1"><csymbol cd="ambiguous" id="S3.p4.3.m1.1.1.1.1.2.1.cmml" xref="S3.p4.3.m1.1.1.1.1">subscript</csymbol><ci id="S3.p4.3.m1.1.1.1.1.2.2.cmml" xref="S3.p4.3.m1.1.1.1.1.2.2">𝐷</ci><ci id="S3.p4.3.m1.1.1.1.1.2.3.cmml" xref="S3.p4.3.m1.1.1.1.1.2.3">𝑘</ci></apply><ci id="S3.p4.3.m1.1.1.1.1.3.cmml" xref="S3.p4.3.m1.1.1.1.1.3">𝑇</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.3.m1.1c">|D_{k}^{T}|</annotation></semantics></math> is the number of local training examples, <math id="S3.p4.4.m2.1" class="ltx_Math" alttext="\beta_{k}" display="inline"><semantics id="S3.p4.4.m2.1a"><msub id="S3.p4.4.m2.1.1" xref="S3.p4.4.m2.1.1.cmml"><mi id="S3.p4.4.m2.1.1.2" xref="S3.p4.4.m2.1.1.2.cmml">β</mi><mi id="S3.p4.4.m2.1.1.3" xref="S3.p4.4.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S3.p4.4.m2.1b"><apply id="S3.p4.4.m2.1.1.cmml" xref="S3.p4.4.m2.1.1"><csymbol cd="ambiguous" id="S3.p4.4.m2.1.1.1.cmml" xref="S3.p4.4.m2.1.1">subscript</csymbol><ci id="S3.p4.4.m2.1.1.2.cmml" xref="S3.p4.4.m2.1.1.2">𝛽</ci><ci id="S3.p4.4.m2.1.1.3.cmml" xref="S3.p4.4.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.4.m2.1c">\beta_{k}</annotation></semantics></math> is the learner’s local batch size defined at global model initialization and <math id="S3.p4.5.m3.1" class="ltx_Math" alttext="t_{\beta_{k}}" display="inline"><semantics id="S3.p4.5.m3.1a"><msub id="S3.p4.5.m3.1.1" xref="S3.p4.5.m3.1.1.cmml"><mi id="S3.p4.5.m3.1.1.2" xref="S3.p4.5.m3.1.1.2.cmml">t</mi><msub id="S3.p4.5.m3.1.1.3" xref="S3.p4.5.m3.1.1.3.cmml"><mi id="S3.p4.5.m3.1.1.3.2" xref="S3.p4.5.m3.1.1.3.2.cmml">β</mi><mi id="S3.p4.5.m3.1.1.3.3" xref="S3.p4.5.m3.1.1.3.3.cmml">k</mi></msub></msub><annotation-xml encoding="MathML-Content" id="S3.p4.5.m3.1b"><apply id="S3.p4.5.m3.1.1.cmml" xref="S3.p4.5.m3.1.1"><csymbol cd="ambiguous" id="S3.p4.5.m3.1.1.1.cmml" xref="S3.p4.5.m3.1.1">subscript</csymbol><ci id="S3.p4.5.m3.1.1.2.cmml" xref="S3.p4.5.m3.1.1.2">𝑡</ci><apply id="S3.p4.5.m3.1.1.3.cmml" xref="S3.p4.5.m3.1.1.3"><csymbol cd="ambiguous" id="S3.p4.5.m3.1.1.3.1.cmml" xref="S3.p4.5.m3.1.1.3">subscript</csymbol><ci id="S3.p4.5.m3.1.1.3.2.cmml" xref="S3.p4.5.m3.1.1.3.2">𝛽</ci><ci id="S3.p4.5.m3.1.1.3.3.cmml" xref="S3.p4.5.m3.1.1.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.5.m3.1c">t_{\beta_{k}}</annotation></semantics></math> is the time it takes to perform a local batch (i.e., an update). The hyperparameter <math id="S3.p4.6.m4.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S3.p4.6.m4.1a"><mi id="S3.p4.6.m4.1.1" xref="S3.p4.6.m4.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.p4.6.m4.1b"><ci id="S3.p4.6.m4.1.1.cmml" xref="S3.p4.6.m4.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.6.m4.1c">\lambda</annotation></semantics></math> controls the communication frequency of the learners by adjusting the number of local updates per learner based on the time it takes for the slowest learner to perform <math id="S3.p4.7.m5.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S3.p4.7.m5.1a"><mi id="S3.p4.7.m5.1.1" xref="S3.p4.7.m5.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S3.p4.7.m5.1b"><ci id="S3.p4.7.m5.1.1.cmml" xref="S3.p4.7.m5.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p4.7.m5.1c">\lambda</annotation></semantics></math> local epochs.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.1" class="ltx_p">This training policy is particularly effective in federated learning settings where learners have homogeneous computational power, but heterogeneous amounts of data, as well as in settings where learners have heterogeneous computational power and/or heterogeneous amounts of data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Federated Brain Age Prediction</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">The learning task we investigate here is brain age prediction. Deep 3D convolutional regression networks have been used for brain age prediction <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. These networks extend the VGG and ResNet architectures to 3D images by replacing 2D convolution/maxpool operations with their 3D counterparts.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p"><span id="S4.p2.1.1" class="ltx_text ltx_font_bold">Neural Architecture.</span>
Figure <a href="#S4.F2" title="Figure 2 ‣ 4 Federated Brain Age Prediction ‣ Scaling Neuroscience Research using Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows the convolutional encoding network we trained for the brain age prediction task. The model architecture is similar to that in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> with the main difference being the replacement of the batch normalization (BatchNorm) layer with an instance normalization (InstanceNorm) layer. Collectively, the network consists of seven blocks, with the first five composed of a 3x3x3 3D convolutional layer (stride=1, padding=1), followed by an instance norm, a 2x2x2 max-pool (stride=2), with ReLU activation functions. The number of filters in the first block is 32 (and doubles until 256) with both layers 4 and 5 having 256 filters. The sixth block contains a 1x1x1 3D convolutional layer (stride=1, filters=64), followed by an instance norm and ReLU activation. The final, seventh, block contains an average pooling layer, a dropout layer (set to p=0.5 during training), and a 1x1x1 3D convolutional layer (stride=1). To train the model we used Mean Squared Error as loss function and Vanilla SGD as the network’s optimizer.</p>
</div>
<figure id="S4.F2" class="ltx_figure"><img src="/html/2102.08440/assets/brainage_plots/BrainAgeCNN_v2.png" id="S4.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="241" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S4.F2.2.1.1" class="ltx_text ltx_font_bold">Fig. 2</span>: </span>BrainAgeCNN</figcaption>
</figure>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p"><span id="S4.p3.1.1" class="ltx_text ltx_font_bold">Federated Model.</span> During federated training all learners train on their local data using the same neural architecture and hyperparameters (e.g., learning rate, batch size). Once a learner finishes its local training, it sends its local model parameters to the controller.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Experiments</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Our goal is to apply Federated Learning to hospital consortia, and to large research studies like Enigma (enigma.ini.usc.edu). As an initial step in a controlled environment, we analyzed brain MRI data from the UK Biobank <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite>, a large epidemiological study of 500,000 people residing in the United Kingdom, some with neuroimaging.
We explored several heterogeneous federated learning scenarios with different data distributions and amounts of data per learner and evaluated the performance and convergence rate of the federation.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p"><span id="S5.p2.1.1" class="ltx_text ltx_font_bold">NeuroImaging Data.</span> From the original UKBB dataset of 16,356 individuals with neuroimaging, we selected 10,446 who had no indication of neurological pathology, and no psychiatric diagnosis as defined by the ICD-10 criteria. The age range was 45-81 years (mean: 62.64; SD: 7.41; 47% women, 53% men). All image scans were evaluated with a manual quality control procedure, where scans with severe artifacts were discarded. The remaining scans were processed using a standard preprocessing pipeline with non-parametric intensity normalization for bias field correction1 and brain extraction using FreeSurfer and linear registration to a (2 mm)<sup id="S5.p2.1.2" class="ltx_sup">3</sup> UKBB minimum deformation template using FSL FLIRT. The final dimension of the registered images was 91x109x91.
The 10,446 records were split into 8356 for train and 2090 for test.</p>
</div>
<figure id="S5.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F3.sf1" class="ltx_figure ltx_figure_panel"><img src="/html/2102.08440/assets/brainage_plots/AgeBuckets_brainage_cnn5_federation_8FastLearners_atBDNF_SyncFedAvg_uniform_datasize_iid_v3.png" id="S5.F3.sf1.g1" class="ltx_graphics ltx_img_landscape" width="192" height="92" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Uniform &amp; IID 
<br class="ltx_break">Age Buckets</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F3.sf2" class="ltx_figure ltx_figure_panel"><img src="/html/2102.08440/assets/brainage_plots/AgeBuckets_brainage_cnn5_federation_8FastLearners_atBDNF_SyncFedAvg_uniform_datasize_noniid_v3.png" id="S5.F3.sf2.g1" class="ltx_graphics ltx_img_landscape" width="192" height="92" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Uniform &amp; Non-IID Age Buckets</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F3.sf3" class="ltx_figure ltx_figure_panel"><img src="/html/2102.08440/assets/brainage_plots/AgeBuckets_brainage_cnn5_federation_8FastLearners_atBDNF_SyncFedAvg_skewed_datasize_noniid_v3.png" id="S5.F3.sf3.g1" class="ltx_graphics ltx_img_landscape" width="192" height="94" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Skewed &amp; Non-IID Age Buckets</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S5.F3.sf4" class="ltx_figure ltx_figure_panel"><img src="/html/2102.08440/assets/brainage_plots/AgeDistributions_brainage_cnn5_federation_8FastLearners_atBDNF_SyncFedAvg_uniform_datasize_iid.png" id="S5.F3.sf4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="192" height="209" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(d) </span>Uniform &amp; IID 
<br class="ltx_break">Age Distribution</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F3.sf5" class="ltx_figure ltx_figure_panel"><img src="/html/2102.08440/assets/brainage_plots/AgeDistributions_brainage_cnn5_federation_8FastLearners_atBDNF_SyncFedAvg_uniform_datasize_noniid.png" id="S5.F3.sf5.g1" class="ltx_graphics ltx_centering ltx_img_square" width="192" height="209" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(e) </span>Uniform &amp; Non-IID Age Distribution</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F3.sf6" class="ltx_figure ltx_figure_panel"><img src="/html/2102.08440/assets/brainage_plots/AgeDistributions_brainage_cnn5_federation_8FastLearners_atBDNF_SyncFedAvg_skewed_datasize_noniid_v2.png" id="S5.F3.sf6.g1" class="ltx_graphics ltx_centering ltx_img_square" width="192" height="209" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(f) </span>Skewed &amp; Non-IID Age Distribution</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure"><span id="S5.F3.2.1.1" class="ltx_text ltx_font_bold">Fig. 3</span>: </span>UKBB Federation Data Distributions</figcaption>
</figure>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p"><span id="S5.p3.1.1" class="ltx_text ltx_font_bold">Data Distributions.</span> We define several challenging learning environments by partitioning the centralized UKBB neuroimaging training dataset (8356 records) across a federation of 8 learners.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Available at: <a target="_blank" href="https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/2RKAQP" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/2RKAQP</a></span></span></span>
Every environment was evaluated on the same test dataset (2090 records) and the learners used their allocated records for training.
As shown in Figure <a href="#S5.F3" title="Figure 3 ‣ 5 Experiments ‣ Scaling Neuroscience Research using Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>: panels (a, b, c) show the amount of data (and age buckets), and the corresponding (d, e, f) show the detailed age distribution of each of the 8 learners.
Figures <a href="#S5.F3" title="Figure 3 ‣ 5 Experiments ‣ Scaling Neuroscience Research using Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>(a,d) show a uniform (same amount of data per learner) and IID (all ages) distribution.
Figures <a href="#S5.F3" title="Figure 3 ‣ 5 Experiments ‣ Scaling Neuroscience Research using Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>(b,e) show a uniform, but non-IID (subset of ages) distribution.
Figures <a href="#S5.F3" title="Figure 3 ‣ 5 Experiments ‣ Scaling Neuroscience Research using Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>(c,f) show a skewed (different amount of data per learner) and non-IID distribution.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.7" class="ltx_p"><span id="S5.p4.7.1" class="ltx_text ltx_font_bold">Training Environment.</span> We established a federation of 8 learners by assigning one learner to each GPU of a server with 8 GeForce GTX 1080 Ti graphics cards (10 GB RAM each), 40 Intel(R) Xeon(R) CPU E5-2630 v4 @ 2.20GHz, and 128GB DDR4 RAM. All learners trained on the same CNN model (Fig. <a href="#S4.F2" title="Figure 2 ‣ 4 Federated Brain Age Prediction ‣ Scaling Neuroscience Research using Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). For both centralized and federated models, we used Vanilla SGD with a learning rate of <math id="S5.p4.1.m1.1" class="ltx_Math" alttext="5\text{x}10^{-5}" display="inline"><semantics id="S5.p4.1.m1.1a"><mrow id="S5.p4.1.m1.1.1" xref="S5.p4.1.m1.1.1.cmml"><mn id="S5.p4.1.m1.1.1.2" xref="S5.p4.1.m1.1.1.2.cmml">5</mn><mo lspace="0em" rspace="0em" id="S5.p4.1.m1.1.1.1" xref="S5.p4.1.m1.1.1.1.cmml">​</mo><mtext id="S5.p4.1.m1.1.1.3" xref="S5.p4.1.m1.1.1.3a.cmml">x</mtext><mo lspace="0em" rspace="0em" id="S5.p4.1.m1.1.1.1a" xref="S5.p4.1.m1.1.1.1.cmml">​</mo><msup id="S5.p4.1.m1.1.1.4" xref="S5.p4.1.m1.1.1.4.cmml"><mn id="S5.p4.1.m1.1.1.4.2" xref="S5.p4.1.m1.1.1.4.2.cmml">10</mn><mrow id="S5.p4.1.m1.1.1.4.3" xref="S5.p4.1.m1.1.1.4.3.cmml"><mo id="S5.p4.1.m1.1.1.4.3a" xref="S5.p4.1.m1.1.1.4.3.cmml">−</mo><mn id="S5.p4.1.m1.1.1.4.3.2" xref="S5.p4.1.m1.1.1.4.3.2.cmml">5</mn></mrow></msup></mrow><annotation-xml encoding="MathML-Content" id="S5.p4.1.m1.1b"><apply id="S5.p4.1.m1.1.1.cmml" xref="S5.p4.1.m1.1.1"><times id="S5.p4.1.m1.1.1.1.cmml" xref="S5.p4.1.m1.1.1.1"></times><cn type="integer" id="S5.p4.1.m1.1.1.2.cmml" xref="S5.p4.1.m1.1.1.2">5</cn><ci id="S5.p4.1.m1.1.1.3a.cmml" xref="S5.p4.1.m1.1.1.3"><mtext id="S5.p4.1.m1.1.1.3.cmml" xref="S5.p4.1.m1.1.1.3">x</mtext></ci><apply id="S5.p4.1.m1.1.1.4.cmml" xref="S5.p4.1.m1.1.1.4"><csymbol cd="ambiguous" id="S5.p4.1.m1.1.1.4.1.cmml" xref="S5.p4.1.m1.1.1.4">superscript</csymbol><cn type="integer" id="S5.p4.1.m1.1.1.4.2.cmml" xref="S5.p4.1.m1.1.1.4.2">10</cn><apply id="S5.p4.1.m1.1.1.4.3.cmml" xref="S5.p4.1.m1.1.1.4.3"><minus id="S5.p4.1.m1.1.1.4.3.1.cmml" xref="S5.p4.1.m1.1.1.4.3"></minus><cn type="integer" id="S5.p4.1.m1.1.1.4.3.2.cmml" xref="S5.p4.1.m1.1.1.4.3.2">5</cn></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.1.m1.1c">5\text{x}10^{-5}</annotation></semantics></math> and a batch size (<math id="S5.p4.2.m2.1" class="ltx_Math" alttext="\beta_{k}" display="inline"><semantics id="S5.p4.2.m2.1a"><msub id="S5.p4.2.m2.1.1" xref="S5.p4.2.m2.1.1.cmml"><mi id="S5.p4.2.m2.1.1.2" xref="S5.p4.2.m2.1.1.2.cmml">β</mi><mi id="S5.p4.2.m2.1.1.3" xref="S5.p4.2.m2.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S5.p4.2.m2.1b"><apply id="S5.p4.2.m2.1.1.cmml" xref="S5.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S5.p4.2.m2.1.1.1.cmml" xref="S5.p4.2.m2.1.1">subscript</csymbol><ci id="S5.p4.2.m2.1.1.2.cmml" xref="S5.p4.2.m2.1.1.2">𝛽</ci><ci id="S5.p4.2.m2.1.1.3.cmml" xref="S5.p4.2.m2.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.2.m2.1c">\beta_{k}</annotation></semantics></math>) of 1.
For SyncFedAvg, each learner runs 4 local epochs in all distributions.
For SemiSyncFedAvg, the time per batch (<math id="S5.p4.3.m3.1" class="ltx_Math" alttext="t_{\beta_{k}}" display="inline"><semantics id="S5.p4.3.m3.1a"><msub id="S5.p4.3.m3.1.1" xref="S5.p4.3.m3.1.1.cmml"><mi id="S5.p4.3.m3.1.1.2" xref="S5.p4.3.m3.1.1.2.cmml">t</mi><msub id="S5.p4.3.m3.1.1.3" xref="S5.p4.3.m3.1.1.3.cmml"><mi id="S5.p4.3.m3.1.1.3.2" xref="S5.p4.3.m3.1.1.3.2.cmml">β</mi><mi id="S5.p4.3.m3.1.1.3.3" xref="S5.p4.3.m3.1.1.3.3.cmml">k</mi></msub></msub><annotation-xml encoding="MathML-Content" id="S5.p4.3.m3.1b"><apply id="S5.p4.3.m3.1.1.cmml" xref="S5.p4.3.m3.1.1"><csymbol cd="ambiguous" id="S5.p4.3.m3.1.1.1.cmml" xref="S5.p4.3.m3.1.1">subscript</csymbol><ci id="S5.p4.3.m3.1.1.2.cmml" xref="S5.p4.3.m3.1.1.2">𝑡</ci><apply id="S5.p4.3.m3.1.1.3.cmml" xref="S5.p4.3.m3.1.1.3"><csymbol cd="ambiguous" id="S5.p4.3.m3.1.1.3.1.cmml" xref="S5.p4.3.m3.1.1.3">subscript</csymbol><ci id="S5.p4.3.m3.1.1.3.2.cmml" xref="S5.p4.3.m3.1.1.3.2">𝛽</ci><ci id="S5.p4.3.m3.1.1.3.3.cmml" xref="S5.p4.3.m3.1.1.3.3">𝑘</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.3.m3.1c">t_{\beta_{k}}</annotation></semantics></math>) for every learner is 120ms, the maximum time of a single epoch across all learners is 280secs (learner 1 that holds the largest partition: <math id="S5.p4.4.m4.1" class="ltx_Math" alttext="\sim" display="inline"><semantics id="S5.p4.4.m4.1a"><mo id="S5.p4.4.m4.1.1" xref="S5.p4.4.m4.1.1.cmml">∼</mo><annotation-xml encoding="MathML-Content" id="S5.p4.4.m4.1b"><csymbol cd="latexml" id="S5.p4.4.m4.1.1.cmml" xref="S5.p4.4.m4.1.1">similar-to</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.4.m4.1c">\sim</annotation></semantics></math>2,400 examples), thus for <math id="S5.p4.5.m5.1" class="ltx_Math" alttext="\lambda=4" display="inline"><semantics id="S5.p4.5.m5.1a"><mrow id="S5.p4.5.m5.1.1" xref="S5.p4.5.m5.1.1.cmml"><mi id="S5.p4.5.m5.1.1.2" xref="S5.p4.5.m5.1.1.2.cmml">λ</mi><mo id="S5.p4.5.m5.1.1.1" xref="S5.p4.5.m5.1.1.1.cmml">=</mo><mn id="S5.p4.5.m5.1.1.3" xref="S5.p4.5.m5.1.1.3.cmml">4</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p4.5.m5.1b"><apply id="S5.p4.5.m5.1.1.cmml" xref="S5.p4.5.m5.1.1"><eq id="S5.p4.5.m5.1.1.1.cmml" xref="S5.p4.5.m5.1.1.1"></eq><ci id="S5.p4.5.m5.1.1.2.cmml" xref="S5.p4.5.m5.1.1.2">𝜆</ci><cn type="integer" id="S5.p4.5.m5.1.1.3.cmml" xref="S5.p4.5.m5.1.1.3">4</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.5.m5.1c">\lambda=4</annotation></semantics></math> the maximum time (<math id="S5.p4.6.m6.1" class="ltx_Math" alttext="t_{max}" display="inline"><semantics id="S5.p4.6.m6.1a"><msub id="S5.p4.6.m6.1.1" xref="S5.p4.6.m6.1.1.cmml"><mi id="S5.p4.6.m6.1.1.2" xref="S5.p4.6.m6.1.1.2.cmml">t</mi><mrow id="S5.p4.6.m6.1.1.3" xref="S5.p4.6.m6.1.1.3.cmml"><mi id="S5.p4.6.m6.1.1.3.2" xref="S5.p4.6.m6.1.1.3.2.cmml">m</mi><mo lspace="0em" rspace="0em" id="S5.p4.6.m6.1.1.3.1" xref="S5.p4.6.m6.1.1.3.1.cmml">​</mo><mi id="S5.p4.6.m6.1.1.3.3" xref="S5.p4.6.m6.1.1.3.3.cmml">a</mi><mo lspace="0em" rspace="0em" id="S5.p4.6.m6.1.1.3.1a" xref="S5.p4.6.m6.1.1.3.1.cmml">​</mo><mi id="S5.p4.6.m6.1.1.3.4" xref="S5.p4.6.m6.1.1.3.4.cmml">x</mi></mrow></msub><annotation-xml encoding="MathML-Content" id="S5.p4.6.m6.1b"><apply id="S5.p4.6.m6.1.1.cmml" xref="S5.p4.6.m6.1.1"><csymbol cd="ambiguous" id="S5.p4.6.m6.1.1.1.cmml" xref="S5.p4.6.m6.1.1">subscript</csymbol><ci id="S5.p4.6.m6.1.1.2.cmml" xref="S5.p4.6.m6.1.1.2">𝑡</ci><apply id="S5.p4.6.m6.1.1.3.cmml" xref="S5.p4.6.m6.1.1.3"><times id="S5.p4.6.m6.1.1.3.1.cmml" xref="S5.p4.6.m6.1.1.3.1"></times><ci id="S5.p4.6.m6.1.1.3.2.cmml" xref="S5.p4.6.m6.1.1.3.2">𝑚</ci><ci id="S5.p4.6.m6.1.1.3.3.cmml" xref="S5.p4.6.m6.1.1.3.3">𝑎</ci><ci id="S5.p4.6.m6.1.1.3.4.cmml" xref="S5.p4.6.m6.1.1.3.4">𝑥</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.6.m6.1c">t_{max}</annotation></semantics></math>) is 1,120secs (cf. Eq. <a href="#S3.E2" title="In 3 Federated Learning ‣ Scaling Neuroscience Research using Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>). Finally, the assigned number of local updates (<math id="S5.p4.7.m7.1" class="ltx_Math" alttext="\mathcal{B}_{k}" display="inline"><semantics id="S5.p4.7.m7.1a"><msub id="S5.p4.7.m7.1.1" xref="S5.p4.7.m7.1.1.cmml"><mi class="ltx_font_mathcaligraphic" id="S5.p4.7.m7.1.1.2" xref="S5.p4.7.m7.1.1.2.cmml">ℬ</mi><mi id="S5.p4.7.m7.1.1.3" xref="S5.p4.7.m7.1.1.3.cmml">k</mi></msub><annotation-xml encoding="MathML-Content" id="S5.p4.7.m7.1b"><apply id="S5.p4.7.m7.1.1.cmml" xref="S5.p4.7.m7.1.1"><csymbol cd="ambiguous" id="S5.p4.7.m7.1.1.1.cmml" xref="S5.p4.7.m7.1.1">subscript</csymbol><ci id="S5.p4.7.m7.1.1.2.cmml" xref="S5.p4.7.m7.1.1.2">ℬ</ci><ci id="S5.p4.7.m7.1.1.3.cmml" xref="S5.p4.7.m7.1.1.3">𝑘</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p4.7.m7.1c">\mathcal{B}_{k}</annotation></semantics></math>) per learner is close to 9300. For all experiments, the random seed was 1990.</p>
</div>
<figure id="S5.F4" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F4.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2102.08440/assets/brainage_plots/ComprehensiveConvergenceRate_WallClockTime_v2.png" id="S5.F4.sf1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="264" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">(a) </span>Wall-Clock Time</figcaption>
</figure>
</div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_1">
<figure id="S5.F4.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2102.08440/assets/brainage_plots/ComprehensiveConvergenceRate_FederationRounds_v2.png" id="S5.F4.sf2.g1" class="ltx_graphics ltx_img_landscape" width="479" height="264" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Federation Rounds</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure"><span id="S5.F4.2.1.1" class="ltx_text ltx_font_bold">Fig. 4</span>: </span>UKBB Brain Age Federated Policies Performance</figcaption>
</figure>
<div id="S5.p5" class="ltx_para">
<p id="S5.p5.1" class="ltx_p"><span id="S5.p5.1.1" class="ltx_text ltx_font_bold">Evaluation.</span>
We compare the performance of brain age prediction in settings with uniform and skewed data sizes, and with IID and non-IID age distributions. Since we consider a homogeneous computational environment with 8 identical learners (GPUs) and the computational cost of each learner only depends on the amount of data, for uniform data sizes we only show results for the Synchronous Federated Average policy (SemiSync performs the same). For skewed data sizes, we show both synchronous and semi-synchronous policies.</p>
</div>
<div id="S5.p6" class="ltx_para">
<p id="S5.p6.1" class="ltx_p">Figure <a href="#S5.F4.sf1" title="In Figure 4 ‣ 5 Experiments ‣ Scaling Neuroscience Research using Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4a</span></a> shows the performance of the training policies over the different environments in terms of elapsed (wall-clock) time (i.e., the 8 learners running in parallel).
For the Uniform and IID setting, the federation reaches a Mean Absolute Error (MAE) value that is very close to the one achieved by the centralized model. More challenging Non-IID settings lower the performance, with a final error of 0.5 years over the centralized model (cf. Table <a href="#S5.T1" title="Table 1 ‣ 5 Experiments ‣ Scaling Neuroscience Research using Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>).
The Semi-Synchronous FedAvg policy has a faster convergence and slightly better final performance than Synchronous FedAvg. Even though the computational power of each learner is the same (identical GPUs), in the skewed data setting for the SyncFedAvg policy the learners with the smaller amounts of data remain idle until the learner with the most data finishes its allocated epochs. In contrast, the SemiSync policy continuously processes batches without any idle time. This additional computation results in the improved convergence in this setting.
</p>
</div>
<div id="S5.p7" class="ltx_para">
<p id="S5.p7.1" class="ltx_p">Figure <a href="#S5.F4.sf2" title="In Figure 4 ‣ 5 Experiments ‣ Scaling Neuroscience Research using Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4b</span></a> shows the performance in terms of federation rounds, which is a proxy for the communication cost of the policy.<span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>Note that the wall-clock time for each federation round depends on the data distribution. To process the 25 federation rounds in Figure <a href="#S5.F4.sf2" title="In Figure 4 ‣ 5 Experiments ‣ Scaling Neuroscience Research using Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4b</span></a>, SyncFedAvg takes 15,482 seconds in the Uniform and IID setting, 15,777 seconds in the Uniform and Non-IID setting, and 22,713 seconds in the Skewed and Non-IID setting. For 25 federations rounds in the Skewed and Non-IID setting SemiSyncFedAvg takes 23,048 seconds.
</span></span></span>
At the end of the allocated epochs for SyncFedAvg, or <math id="S5.p7.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S5.p7.1.m1.1a"><mi id="S5.p7.1.m1.1.1" xref="S5.p7.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S5.p7.1.m1.1b"><ci id="S5.p7.1.m1.1.1.cmml" xref="S5.p7.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p7.1.m1.1c">\lambda</annotation></semantics></math> time for SemiSyncFedAvg, all learners share their models with the Federation Controller, which then computes the community model and sends it back to the learners. Thus, the number of models exchanged through the network is twice the number of federation rounds times the number of learners. As before, SemiSyncFedAvg shows faster convergence in terms of communication cost than SyncFedAvg.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<table id="S5.T1.16.16" class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T1.16.16.17.1" class="ltx_tr">
<td id="S5.T1.16.16.17.1.1" class="ltx_td"></td>
<td id="S5.T1.16.16.17.1.2" class="ltx_td"></td>
<td id="S5.T1.16.16.17.1.3" class="ltx_td ltx_align_center"><span id="S5.T1.16.16.17.1.3.1" class="ltx_text ltx_font_bold" style="font-size:50%;">MSE</span></td>
<td id="S5.T1.16.16.17.1.4" class="ltx_td ltx_align_center"><span id="S5.T1.16.16.17.1.4.1" class="ltx_text ltx_font_bold" style="font-size:50%;">RMSE</span></td>
<td id="S5.T1.16.16.17.1.5" class="ltx_td ltx_align_center"><span id="S5.T1.16.16.17.1.5.1" class="ltx_text ltx_font_bold" style="font-size:50%;">MAE</span></td>
<td id="S5.T1.16.16.17.1.6" class="ltx_td ltx_align_center"><span id="S5.T1.16.16.17.1.6.1" class="ltx_text ltx_font_bold" style="font-size:50%;">Corr</span></td>
</tr>
<tr id="S5.T1.3.3.3" class="ltx_tr">
<td id="S5.T1.3.3.3.4" class="ltx_td ltx_align_left ltx_border_tt" colspan="2"><span id="S5.T1.3.3.3.4.1" class="ltx_text ltx_font_bold" style="font-size:50%;">Centralized Model</span></td>
<td id="S5.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S5.T1.1.1.1.1.1" class="ltx_text" style="font-size:50%;">12.885 </span><math id="S5.T1.1.1.1.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T1.1.1.1.1.m1.1a"><mo mathsize="50%" id="S5.T1.1.1.1.1.m1.1.1" xref="S5.T1.1.1.1.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T1.1.1.1.1.m1.1b"><csymbol cd="latexml" id="S5.T1.1.1.1.1.m1.1.1.cmml" xref="S5.T1.1.1.1.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.1.1.1.1.m1.1c">\pm</annotation></semantics></math><span id="S5.T1.1.1.1.1.2" class="ltx_text" style="font-size:50%;"> 0.021</span>
</td>
<td id="S5.T1.2.2.2.2" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S5.T1.2.2.2.2.1" class="ltx_text" style="font-size:50%;">3.589 </span><math id="S5.T1.2.2.2.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T1.2.2.2.2.m1.1a"><mo mathsize="50%" id="S5.T1.2.2.2.2.m1.1.1" xref="S5.T1.2.2.2.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T1.2.2.2.2.m1.1b"><csymbol cd="latexml" id="S5.T1.2.2.2.2.m1.1.1.cmml" xref="S5.T1.2.2.2.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.2.2.2.2.m1.1c">\pm</annotation></semantics></math><span id="S5.T1.2.2.2.2.2" class="ltx_text" style="font-size:50%;"> 0.003</span>
</td>
<td id="S5.T1.3.3.3.3" class="ltx_td ltx_align_center ltx_border_tt">
<span id="S5.T1.3.3.3.3.1" class="ltx_text" style="font-size:50%;">2.895 </span><math id="S5.T1.3.3.3.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T1.3.3.3.3.m1.1a"><mo mathsize="50%" id="S5.T1.3.3.3.3.m1.1.1" xref="S5.T1.3.3.3.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T1.3.3.3.3.m1.1b"><csymbol cd="latexml" id="S5.T1.3.3.3.3.m1.1.1.cmml" xref="S5.T1.3.3.3.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.3.3.3.3.m1.1c">\pm</annotation></semantics></math><span id="S5.T1.3.3.3.3.2" class="ltx_text" style="font-size:50%;"> 0.006</span>
</td>
<td id="S5.T1.3.3.3.5" class="ltx_td ltx_align_center ltx_border_tt"><span id="S5.T1.3.3.3.5.1" class="ltx_text" style="font-size:50%;">0.881</span></td>
</tr>
<tr id="S5.T1.16.16.18.2" class="ltx_tr">
<td id="S5.T1.16.16.18.2.1" class="ltx_td ltx_align_left ltx_border_tt" colspan="2"><span id="S5.T1.16.16.18.2.1.1" class="ltx_text ltx_font_bold" style="font-size:50%;">Federated Model</span></td>
<td id="S5.T1.16.16.18.2.2" class="ltx_td ltx_border_tt"></td>
<td id="S5.T1.16.16.18.2.3" class="ltx_td ltx_border_tt"></td>
<td id="S5.T1.16.16.18.2.4" class="ltx_td ltx_border_tt"></td>
<td id="S5.T1.16.16.18.2.5" class="ltx_td ltx_border_tt"></td>
</tr>
<tr id="S5.T1.16.16.19.3" class="ltx_tr">
<td id="S5.T1.16.16.19.3.1" class="ltx_td ltx_align_left"><span id="S5.T1.16.16.19.3.1.1" class="ltx_text ltx_font_bold" style="font-size:50%;">Data Distribution</span></td>
<td id="S5.T1.16.16.19.3.2" class="ltx_td ltx_align_left"><span id="S5.T1.16.16.19.3.2.1" class="ltx_text ltx_font_bold" style="font-size:50%;">Policy</span></td>
<td id="S5.T1.16.16.19.3.3" class="ltx_td"></td>
<td id="S5.T1.16.16.19.3.4" class="ltx_td"></td>
<td id="S5.T1.16.16.19.3.5" class="ltx_td"></td>
<td id="S5.T1.16.16.19.3.6" class="ltx_td"></td>
</tr>
<tr id="S5.T1.6.6.6" class="ltx_tr">
<td id="S5.T1.6.6.6.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T1.6.6.6.4.1" class="ltx_text ltx_font_bold" style="font-size:50%;">Uniform &amp; IID</span></td>
<td id="S5.T1.6.6.6.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T1.6.6.6.5.1" class="ltx_text" style="font-size:50%;">SyncFedAvg</span></td>
<td id="S5.T1.4.4.4.1" class="ltx_td ltx_align_center">
<span id="S5.T1.4.4.4.1.1" class="ltx_text" style="font-size:50%;">13.749 </span><math id="S5.T1.4.4.4.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T1.4.4.4.1.m1.1a"><mo mathsize="50%" id="S5.T1.4.4.4.1.m1.1.1" xref="S5.T1.4.4.4.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T1.4.4.4.1.m1.1b"><csymbol cd="latexml" id="S5.T1.4.4.4.1.m1.1.1.cmml" xref="S5.T1.4.4.4.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.4.4.4.1.m1.1c">\pm</annotation></semantics></math><span id="S5.T1.4.4.4.1.2" class="ltx_text" style="font-size:50%;"> 0.138</span>
</td>
<td id="S5.T1.5.5.5.2" class="ltx_td ltx_align_center">
<span id="S5.T1.5.5.5.2.1" class="ltx_text" style="font-size:50%;">3.707 </span><math id="S5.T1.5.5.5.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T1.5.5.5.2.m1.1a"><mo mathsize="50%" id="S5.T1.5.5.5.2.m1.1.1" xref="S5.T1.5.5.5.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T1.5.5.5.2.m1.1b"><csymbol cd="latexml" id="S5.T1.5.5.5.2.m1.1.1.cmml" xref="S5.T1.5.5.5.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.5.5.5.2.m1.1c">\pm</annotation></semantics></math><span id="S5.T1.5.5.5.2.2" class="ltx_text" style="font-size:50%;"> 0.018</span>
</td>
<td id="S5.T1.6.6.6.3" class="ltx_td ltx_align_center">
<span id="S5.T1.6.6.6.3.1" class="ltx_text" style="font-size:50%;">2.995 </span><math id="S5.T1.6.6.6.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T1.6.6.6.3.m1.1a"><mo mathsize="50%" id="S5.T1.6.6.6.3.m1.1.1" xref="S5.T1.6.6.6.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T1.6.6.6.3.m1.1b"><csymbol cd="latexml" id="S5.T1.6.6.6.3.m1.1.1.cmml" xref="S5.T1.6.6.6.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.6.6.6.3.m1.1c">\pm</annotation></semantics></math><span id="S5.T1.6.6.6.3.2" class="ltx_text" style="font-size:50%;"> 0.018</span>
</td>
<td id="S5.T1.6.6.6.6" class="ltx_td ltx_align_center"><span id="S5.T1.6.6.6.6.1" class="ltx_text" style="font-size:50%;">0.875</span></td>
</tr>
<tr id="S5.T1.9.9.9" class="ltx_tr">
<td id="S5.T1.9.9.9.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T1.9.9.9.4.1" class="ltx_text ltx_font_bold" style="font-size:50%;">Uniform &amp; Non-IID</span></td>
<td id="S5.T1.9.9.9.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T1.9.9.9.5.1" class="ltx_text" style="font-size:50%;">SyncFedAvg</span></td>
<td id="S5.T1.7.7.7.1" class="ltx_td ltx_align_center ltx_border_t">
<span id="S5.T1.7.7.7.1.1" class="ltx_text" style="font-size:50%;">19.853 </span><math id="S5.T1.7.7.7.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T1.7.7.7.1.m1.1a"><mo mathsize="50%" id="S5.T1.7.7.7.1.m1.1.1" xref="S5.T1.7.7.7.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T1.7.7.7.1.m1.1b"><csymbol cd="latexml" id="S5.T1.7.7.7.1.m1.1.1.cmml" xref="S5.T1.7.7.7.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.7.7.7.1.m1.1c">\pm</annotation></semantics></math><span id="S5.T1.7.7.7.1.2" class="ltx_text" style="font-size:50%;"> 1.347</span>
</td>
<td id="S5.T1.8.8.8.2" class="ltx_td ltx_align_center ltx_border_t">
<span id="S5.T1.8.8.8.2.1" class="ltx_text" style="font-size:50%;">4.453 </span><math id="S5.T1.8.8.8.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T1.8.8.8.2.m1.1a"><mo mathsize="50%" id="S5.T1.8.8.8.2.m1.1.1" xref="S5.T1.8.8.8.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T1.8.8.8.2.m1.1b"><csymbol cd="latexml" id="S5.T1.8.8.8.2.m1.1.1.cmml" xref="S5.T1.8.8.8.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.8.8.8.2.m1.1c">\pm</annotation></semantics></math><span id="S5.T1.8.8.8.2.2" class="ltx_text" style="font-size:50%;"> 0.151</span>
</td>
<td id="S5.T1.9.9.9.3" class="ltx_td ltx_align_center ltx_border_t">
<span id="S5.T1.9.9.9.3.1" class="ltx_text" style="font-size:50%;">3.625 </span><math id="S5.T1.9.9.9.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T1.9.9.9.3.m1.1a"><mo mathsize="50%" id="S5.T1.9.9.9.3.m1.1.1" xref="S5.T1.9.9.9.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T1.9.9.9.3.m1.1b"><csymbol cd="latexml" id="S5.T1.9.9.9.3.m1.1.1.cmml" xref="S5.T1.9.9.9.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.9.9.9.3.m1.1c">\pm</annotation></semantics></math><span id="S5.T1.9.9.9.3.2" class="ltx_text" style="font-size:50%;"> 0.135</span>
</td>
<td id="S5.T1.9.9.9.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T1.9.9.9.6.1" class="ltx_text" style="font-size:50%;">0.861</span></td>
</tr>
<tr id="S5.T1.12.12.12" class="ltx_tr">
<td id="S5.T1.12.12.12.4" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T1.12.12.12.4.1" class="ltx_text ltx_font_bold" style="font-size:50%;">Skewed &amp; Non-IID</span></td>
<td id="S5.T1.12.12.12.5" class="ltx_td ltx_align_left ltx_border_t"><span id="S5.T1.12.12.12.5.1" class="ltx_text" style="font-size:50%;">SyncFedAvg</span></td>
<td id="S5.T1.10.10.10.1" class="ltx_td ltx_align_center ltx_border_t">
<span id="S5.T1.10.10.10.1.1" class="ltx_text" style="font-size:50%;">19.148 </span><math id="S5.T1.10.10.10.1.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T1.10.10.10.1.m1.1a"><mo mathsize="50%" id="S5.T1.10.10.10.1.m1.1.1" xref="S5.T1.10.10.10.1.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T1.10.10.10.1.m1.1b"><csymbol cd="latexml" id="S5.T1.10.10.10.1.m1.1.1.cmml" xref="S5.T1.10.10.10.1.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.10.10.10.1.m1.1c">\pm</annotation></semantics></math><span id="S5.T1.10.10.10.1.2" class="ltx_text" style="font-size:50%;"> 0.086</span>
</td>
<td id="S5.T1.11.11.11.2" class="ltx_td ltx_align_center ltx_border_t">
<span id="S5.T1.11.11.11.2.1" class="ltx_text" style="font-size:50%;">4.376 </span><math id="S5.T1.11.11.11.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T1.11.11.11.2.m1.1a"><mo mathsize="50%" id="S5.T1.11.11.11.2.m1.1.1" xref="S5.T1.11.11.11.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T1.11.11.11.2.m1.1b"><csymbol cd="latexml" id="S5.T1.11.11.11.2.m1.1.1.cmml" xref="S5.T1.11.11.11.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.11.11.11.2.m1.1c">\pm</annotation></semantics></math><span id="S5.T1.11.11.11.2.2" class="ltx_text" style="font-size:50%;"> 0.009</span>
</td>
<td id="S5.T1.12.12.12.3" class="ltx_td ltx_align_center ltx_border_t">
<span id="S5.T1.12.12.12.3.1" class="ltx_text" style="font-size:50%;">3.553 </span><math id="S5.T1.12.12.12.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T1.12.12.12.3.m1.1a"><mo mathsize="50%" id="S5.T1.12.12.12.3.m1.1.1" xref="S5.T1.12.12.12.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T1.12.12.12.3.m1.1b"><csymbol cd="latexml" id="S5.T1.12.12.12.3.m1.1.1.cmml" xref="S5.T1.12.12.12.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.12.12.12.3.m1.1c">\pm</annotation></semantics></math><span id="S5.T1.12.12.12.3.2" class="ltx_text" style="font-size:50%;"> 0.003</span>
</td>
<td id="S5.T1.12.12.12.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T1.12.12.12.6.1" class="ltx_text" style="font-size:50%;">0.851</span></td>
</tr>
<tr id="S5.T1.16.16.16" class="ltx_tr">
<td id="S5.T1.16.16.16.5" class="ltx_td ltx_border_bb"></td>
<td id="S5.T1.13.13.13.1" class="ltx_td ltx_align_left ltx_border_bb">
<span id="S5.T1.13.13.13.1.1" class="ltx_text" style="font-size:50%;">SemiSync(</span><math id="S5.T1.13.13.13.1.m1.1" class="ltx_Math" alttext="\lambda" display="inline"><semantics id="S5.T1.13.13.13.1.m1.1a"><mi mathsize="50%" id="S5.T1.13.13.13.1.m1.1.1" xref="S5.T1.13.13.13.1.m1.1.1.cmml">λ</mi><annotation-xml encoding="MathML-Content" id="S5.T1.13.13.13.1.m1.1b"><ci id="S5.T1.13.13.13.1.m1.1.1.cmml" xref="S5.T1.13.13.13.1.m1.1.1">𝜆</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.13.13.13.1.m1.1c">\lambda</annotation></semantics></math><span id="S5.T1.13.13.13.1.2" class="ltx_text" style="font-size:50%;">=4)</span>
</td>
<td id="S5.T1.14.14.14.2" class="ltx_td ltx_align_center ltx_border_bb">
<span id="S5.T1.14.14.14.2.1" class="ltx_text" style="font-size:50%;">18.491 </span><math id="S5.T1.14.14.14.2.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T1.14.14.14.2.m1.1a"><mo mathsize="50%" id="S5.T1.14.14.14.2.m1.1.1" xref="S5.T1.14.14.14.2.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T1.14.14.14.2.m1.1b"><csymbol cd="latexml" id="S5.T1.14.14.14.2.m1.1.1.cmml" xref="S5.T1.14.14.14.2.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.14.14.14.2.m1.1c">\pm</annotation></semantics></math><span id="S5.T1.14.14.14.2.2" class="ltx_text" style="font-size:50%;"> 0.122</span>
</td>
<td id="S5.T1.15.15.15.3" class="ltx_td ltx_align_center ltx_border_bb">
<span id="S5.T1.15.15.15.3.1" class="ltx_text" style="font-size:50%;">4.311 </span><math id="S5.T1.15.15.15.3.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T1.15.15.15.3.m1.1a"><mo mathsize="50%" id="S5.T1.15.15.15.3.m1.1.1" xref="S5.T1.15.15.15.3.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T1.15.15.15.3.m1.1b"><csymbol cd="latexml" id="S5.T1.15.15.15.3.m1.1.1.cmml" xref="S5.T1.15.15.15.3.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.15.15.15.3.m1.1c">\pm</annotation></semantics></math><span id="S5.T1.15.15.15.3.2" class="ltx_text" style="font-size:50%;"> 0.015</span>
</td>
<td id="S5.T1.16.16.16.4" class="ltx_td ltx_align_center ltx_border_bb">
<span id="S5.T1.16.16.16.4.1" class="ltx_text" style="font-size:50%;">3.505 </span><math id="S5.T1.16.16.16.4.m1.1" class="ltx_Math" alttext="\pm" display="inline"><semantics id="S5.T1.16.16.16.4.m1.1a"><mo mathsize="50%" id="S5.T1.16.16.16.4.m1.1.1" xref="S5.T1.16.16.16.4.m1.1.1.cmml">±</mo><annotation-xml encoding="MathML-Content" id="S5.T1.16.16.16.4.m1.1b"><csymbol cd="latexml" id="S5.T1.16.16.16.4.m1.1.1.cmml" xref="S5.T1.16.16.16.4.m1.1.1">plus-or-minus</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S5.T1.16.16.16.4.m1.1c">\pm</annotation></semantics></math><span id="S5.T1.16.16.16.4.2" class="ltx_text" style="font-size:50%;"> 0.008</span>
</td>
<td id="S5.T1.16.16.16.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.16.16.16.6.1" class="ltx_text" style="font-size:50%;">0.864</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption" style="font-size:50%;"><span class="ltx_tag ltx_tag_table"><span id="S5.T1.20.1.1" class="ltx_text ltx_font_bold">Table 1</span>: </span>UKBB Evaluation. Mean and std values for 3 runs.</figcaption>
</figure>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We have demonstrated the effectiveness of the Federated Learning paradigm in the neuroimaging domain by collaboratively learning a global model for brain age prediction. We empirically evaluated the convergence of the federated model in statistically heterogeneous learning environments.
Our immediate future work includes investigating additional learning tasks, such as disease prediction,
and incorporating homomorphic encryption in the architecture
We simulated the non-IID case by subsampling UKB data, but we plan to examine the more realistic case where learners receive data from different scanning protocols and cohorts, which would exhibit natural acquisition and population differences. This will better show the different relative performance of the different training policies.
Finally, we plan to explore federated transfer learning in neuroimaging.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Acknowledgments</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">This research was supported in part by the Defense Advanced Research Projects Activity (DARPA) under contract HR00112090104, and in part by the National Institutes of Health (NIH) under grants U01AG068057 and RF1AG051710. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies or endorsements, either expressed or implied, of DARPA, NIH, or the U.S. Government.</p>
</div>
</section>
<section id="S8" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">8 </span>Compliance with Ethical Standards</h2>

<div id="S8.p1" class="ltx_para">
<p id="S8.p1.1" class="ltx_p">This is a study of previously collected, anonymized, de-identified data, available in a public repository.
Data access approved by UK Biobank under Application Number 11559.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera
y Arcas,

</span>
<span class="ltx_bibblock">“Communication-efficient learning of deep networks from
decentralized data,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">AISTATS</span>. PMLR, 2017.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
Qiang Yang, Yang Liu, Tianjian Chen, and Yongxin Tong,

</span>
<span class="ltx_bibblock">“Federated machine learning: Concept and applications,”

</span>
<span class="ltx_bibblock"><span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">ACM Transactions on Intelligent Systems and Technology (TIST)</span>,
vol. 10, no. 2, pp. 1–19, 2019.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
Junghye Lee, Jimeng Sun, Fei Wang, Shuang Wang, et al.,

</span>
<span class="ltx_bibblock">“Privacy-preserving patient similarity learning in a federated
environment: development and analysis,”

</span>
<span class="ltx_bibblock"><span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">JMIR Medical Informatics</span>, vol. 6, no. 2, pp. e20, 2018.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
Micah J Sheller, et al.,

</span>
<span class="ltx_bibblock">“Multi-institutional deep learning modeling without sharing patient
data: A feasibility study on brain tumor segmentation,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">Intl. MICCAI Brainlesion Workshop</span>. Springer, 2018.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
Santiago Silva, Boris A Gutman, Eduardo Romero, Paul M Thompson, Andre Altmann,
and Marco Lorenzi,

</span>
<span class="ltx_bibblock">“Federated learning in distributed medical databases: Meta-analysis
of large-scale subcortical brain data,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">16th Intl. Symp. on Biomedical Imaging</span>, IEEE 2019.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
Nicola Rieke, Jonny Hancox, Wenqi Li, Fausto Milletari, et al.,

</span>
<span class="ltx_bibblock">“The future of digital health with federated learning,”

</span>
<span class="ltx_bibblock"><span id="bib.bib6.1.1" class="ltx_text ltx_font_italic">npj Digital Medicine</span>, vol. 3, no. 119, 2020.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
Santiago Silva, Andre Altmann, et al.,

</span>
<span class="ltx_bibblock">“Fed-biomed: A general open-source frontend framework for federated
learning in healthcare,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">Intl. MICCAI DART/DCL Workshop</span>. Springer, 2018

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
Dimitris Stripelis and José Luis Ambite,

</span>
<span class="ltx_bibblock">“Semi-synchronous federated learning,”

</span>
<span class="ltx_bibblock"><span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">arXiv:2102.02849</span>, 2021.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
Dimitris Stripelis and José Luis Ambite,

</span>
<span class="ltx_bibblock">“Accelerating federated learning in heterogeneous data and
computational environments,”

</span>
<span class="ltx_bibblock"><span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">arXiv:2008.11281</span>, 2020.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
James H Cole, Rudra PK Poudel, Dimosthenis Tsagkrasoulis, et al.,

</span>
<span class="ltx_bibblock">“Predicting brain age with deep learning from raw imaging data
results in a reliable and heritable biomarker,”

</span>
<span class="ltx_bibblock"><span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">NeuroImage</span>, vol. 163, pp. 115–124, 2017.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
Benedikt Atli Jónsson, Gyda Bjornsdottir, TE Thorgeirsson, et al.,

</span>
<span class="ltx_bibblock">“Brain age prediction using deep learning uncovers associated
sequence variants,”

</span>
<span class="ltx_bibblock"><span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">Nature Communications</span>, vol. 10, no. 1, pp. 1–10, 2019.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and
Virginia Smith,

</span>
<span class="ltx_bibblock">“Federated optimization in heterogeneous networks,”

</span>
<span class="ltx_bibblock"><span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">MLSys</span>, 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Dianbo Liu, Dmitriy Dligach, and Timothy Miller,

</span>
<span class="ltx_bibblock">“Two-stage federated phenotyping and patient representation
learning,”

</span>
<span class="ltx_bibblock"><span id="bib.bib13.1.1" class="ltx_text ltx_font_italic">in BioNLP Workshop</span>, 2019.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Yejin Kim, Jimeng Sun, Hwanjo Yu, and Xiaoqian Jiang,

</span>
<span class="ltx_bibblock">“Federated tensor factorization for computational phenotyping,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">ACM SIGKDD</span>, 2017, pp. 887–895.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Abhijit Guha Roy, Shayan Siddiqui, et al.,

</span>
<span class="ltx_bibblock">“Braintorrent: A peer-to-peer environment for decentralized
federated learning,”

</span>
<span class="ltx_bibblock"><span id="bib.bib15.1.1" class="ltx_text ltx_font_italic">arXiv:1905.06731</span>, 2019.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
Wenqi Li, et al.,

</span>
<span class="ltx_bibblock">“Privacy-preserving federated brain tumour segmentation,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib16.1.1" class="ltx_text ltx_font_italic">Intl. Workshop on Machine Learning in Medical
Imaging</span>. Springer, 2019.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock">
Xiaoxiao Li, Yufeng Gu, Nicha Dvornek, et al.,

</span>
<span class="ltx_bibblock">“Multi-site fMRI analysis using privacy-preserving federated
learning and domain adaptation: ABIDE results,”

</span>
<span class="ltx_bibblock"><span id="bib.bib17.1.1" class="ltx_text ltx_font_italic">Medical Image Analysis</span>, vol. 65, 101765, 2020.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock">
Sergey M. Plis, et al.,

</span>
<span class="ltx_bibblock">“COINSTAC: A privacy enabled model and prototype for leveraging and
processing decentralized brain imaging data,”

</span>
<span class="ltx_bibblock"><span id="bib.bib18.1.1" class="ltx_text ltx_font_italic">Frontiers in Neuroscience</span>, vol. 10, pp. 365, 2016.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock">
Martin Abadi, Andy Chu, et al.,

</span>
<span class="ltx_bibblock">“Deep learning with differential privacy,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib19.1.1" class="ltx_text ltx_font_italic">ACM SIGSAC Conference on Computer and
Communications Security</span>, 2016.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock">
Chengliang Zhang, et al.,

</span>
<span class="ltx_bibblock">“Batchcrypt: Efficient homomorphic encryption for cross-silo
federated learning,”

</span>
<span class="ltx_bibblock">in <span id="bib.bib20.1.1" class="ltx_text ltx_font_italic">USENIX Annual Technical Conference</span>, 2020.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock">
Han Peng, Weikang Gong, Christian F. Beckmann, Andrea Vedaldi, and Stephen M.
Smith,

</span>
<span class="ltx_bibblock">“Accurate brain age prediction with lightweight deep neural
networks,”

</span>
<span class="ltx_bibblock"><span id="bib.bib21.1.1" class="ltx_text ltx_font_italic">Medical Image Analysis</span>, p. 101871, 2020.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock">
Keith Bonawitz, Hubert Eichner, et al.,

</span>
<span class="ltx_bibblock">“Towards federated learning at scale: System design,”

</span>
<span class="ltx_bibblock"><span id="bib.bib22.1.1" class="ltx_text ltx_font_italic">MLSys</span>, 2019.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock">
Karla L Miller, Fidel Alfaro-Almagro, et al.,

</span>
<span class="ltx_bibblock">“Multimodal population brain imaging in the UK biobank prospective
epidemiological study,”

</span>
<span class="ltx_bibblock"><span id="bib.bib23.1.1" class="ltx_text ltx_font_italic">Nature Neuroscience</span>, vol. 19, no. 11, pp. 1523–1536, 2016.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2102.08439" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2102.08440" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2102.08440">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2102.08440" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2102.08441" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Thu Mar  7 02:11:04 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
