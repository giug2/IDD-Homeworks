<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2407.15281] SynCPKL: Harnessing LLMs to Generate Synthetic Data for Commonsense Persona Knowledge Linking</title><meta property="og:description" content="Understanding rich dialogues often requires NLP systems to access relevant commonsense persona knowledge, but retrieving this knowledge is challenging due to complex contexts and the implicit nature of commonsense. Thiâ€¦">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="SynCPKL: Harnessing LLMs to Generate Synthetic Data for Commonsense Persona Knowledge Linking">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="SynCPKL: Harnessing LLMs to Generate Synthetic Data for Commonsense Persona Knowledge Linking">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2407.15281">

<!--Generated on Mon Aug  5 18:21:47 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">SynCPKL: Harnessing LLMs to Generate Synthetic Data for Commonsense Persona Knowledge Linking</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kuan-Yen Lin 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">iris19132@gmail.com</span>
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id2.id1" class="ltx_p">Understanding rich dialogues often requires NLP systems to access relevant commonsense persona knowledge, but retrieving this knowledge is challenging due to complex contexts and the implicit nature of commonsense. This paper presents our approach to the Commonsense Persona Knowledge Linking (CPKL) challenge, addressing the critical need for integrating persona and commonsense knowledge in open-domain dialogue systems.
We introduce SynCPKL Pipeline, a pipeline that leverages Large Language Models to generate high-quality synthetic datasets for training commonsense persona knowledge linkers.
To demonstrate the efficacy of our approach, we present SynCPKL, a new dataset specifically designed for this task.
Our experiments validate the effectiveness of SynCPKL for training commonsense persona knowledge linkers.
Additionally, our top-performing model, Derberta-SynCPKL, secured first place in the CPKL challenge by a 16% improvement in F1 score.
We released both SynCPKL and Derberta-SynCPKL at <a target="_blank" href="https://github.com/irislin1006/CPKL" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/irislin1006/CPKL</a>.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">The field of human-computer interaction has seen steady progress (<cite class="ltx_cite ltx_citemacro_citep">Lee etÂ al., <a href="#bib.bib11" title="" class="ltx_ref">2022a</a>; Zhou etÂ al., <a href="#bib.bib21" title="" class="ltx_ref">2023</a>; Han etÂ al., <a href="#bib.bib5" title="" class="ltx_ref">2023</a></cite>), particularly in open-domain dialogue systems (<cite class="ltx_cite ltx_citemacro_citep">Jang etÂ al., <a href="#bib.bib9" title="" class="ltx_ref">2023</a>; Zhang etÂ al., <a href="#bib.bib19" title="" class="ltx_ref">2023</a>; Bae etÂ al., <a href="#bib.bib2" title="" class="ltx_ref">2022</a>; Han etÂ al., <a href="#bib.bib6" title="" class="ltx_ref">2022</a></cite>). While Large Language Models (LLMs) have significantly improved the human-like quality of conversational agents (<cite class="ltx_cite ltx_citemacro_citep">Achiam etÂ al., <a href="#bib.bib1" title="" class="ltx_ref">2023</a>; Maharana etÂ al., <a href="#bib.bib15" title="" class="ltx_ref">2024</a></cite>), challenges persist in maintaining long-term memory, consistent persona attributes, and rich dialogue engagement. To address these issues, researchers are exploring the integration of persona and commonsense knowledge into dialogue systems (<cite class="ltx_cite ltx_citemacro_citep">Jandaghi etÂ al., <a href="#bib.bib8" title="" class="ltx_ref">2023</a>; Lee etÂ al., <a href="#bib.bib13" title="" class="ltx_ref">2022c</a></cite>). Notable efforts include the ComFact <cite class="ltx_cite ltx_citemacro_citep">(Gao etÂ al., <a href="#bib.bib4" title="" class="ltx_ref">2022</a>)</cite> benchmark for identifying situationally relevant commonsense facts, and PeaCok <cite class="ltx_cite ltx_citemacro_citep">(Gao etÂ al., <a href="#bib.bib3" title="" class="ltx_ref">2023</a>)</cite>, a world-level persona commonsense knowledge graph designed to enhance open-domain conversations.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">The extraction of pertinent persona-based commonsense information from existing knowledge bases presents significant challenges, stemming from the intricate and multifaceted nature of real-world conversations. This complexity is further compounded by the inherent subtlety and frequent ambiguity of commonsense knowledge itself. The nuanced interplay between dialogue context and persona-specific information often eludes traditional retrieval methods, highlighting the need for more sophisticated approaches.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To address these challenges, we present our innovative solution to the Commonsense Persona Knowledge Linking (CPKL) challenge (<cite class="ltx_cite ltx_citemacro_citep">Wakaki etÂ al., <a href="#bib.bib17" title="" class="ltx_ref">2024</a></cite>). This shared task calls for robust commonsense persona knowledge linkers capable of identifying and seamlessly integrating relevant commonsense facts associated with both speakers and listeners in dialogues. In addressing this challenge, we face a fundamental obstacle: the lack of high-quality annotated datasets for training and evaluating commonsense persona knowledge linkers. To overcome this problem, we propose leveraging the grokking capabilities of LLMs to generate synthetic datasets that capture the complexities of commonsense persona knowledge in dialogues. Our method, SynCPKL Pipeline, aims to distill the implicit understanding of personal and social dynamics embedded in LLMs into explicit and structured datasets suitable for training commonsense persona knowledge linkers (<cite class="ltx_cite ltx_citemacro_citep">Lee etÂ al., <a href="#bib.bib12" title="" class="ltx_ref">2022b</a></cite>).
This approach not only addresses the scarcity of suitable training data but also allows for the creation of brand-new tasks lacking pre-built datasets.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Using the SynCPKL pipeline, we present SynCPKL, a new dataset specifically designed for training commonsense persona knowledge linkers. Through our experiments and analysis, we demonstrate the efficacy of SynCPKL in this domain. To foster further research and innovation, we have made SynCPKL publicly available to the research community.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Furthermore, we showcase Derberta-SynCPKL, our best-performing model that achieved first place in the CPKL challenge. By open-sourcing this model, we aim to accelerate progress in the field and provide a strong baseline for future research. Derberta-SynCPKL demonstrates the practical application of our synthetic data approach, highlighting its potential to drive significant improvements in commonsense persona knowledge linking tasks.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Shared Task Setup</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">The Commonsense Persona Knowledge Linking for Dialogue (CPKL) challenge from the 6th Workshop on NLP for ConvAI aims to develop models that link relevant commonsense persona knowledge to open-domain dialogues. This task is crucial for enhancing NLP systemsâ€™ ability to ground rich dialogues in appropriate commonsense knowledge.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p">The challenge requires participants to create a model that determines whether a given persona commonsense fact is relevant to a speaker in a dialogue context. Each example consists of:</p>
<ul id="S2.I1" class="ltx_itemize">
<li id="S2.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i1.p1" class="ltx_para">
<p id="S2.I1.i1.p1.1" class="ltx_p">A dialogue between two speakers with a window size of 5 utterances ([<span id="S2.I1.i1.p1.1.1" class="ltx_text ltx_font_typewriter">ut-2</span>, <span id="S2.I1.i1.p1.1.2" class="ltx_text ltx_font_typewriter">ut-1</span>, <span id="S2.I1.i1.p1.1.3" class="ltx_text ltx_font_typewriter">ut</span>, <span id="S2.I1.i1.p1.1.4" class="ltx_text ltx_font_typewriter">ut+1</span>, <span id="S2.I1.i1.p1.1.5" class="ltx_text ltx_font_typewriter">ut+2</span>]), where the target speaker is associated with utterance <span id="S2.I1.i1.p1.1.6" class="ltx_text ltx_font_typewriter">ut</span>.</p>
</div>
</li>
<li id="S2.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S2.I1.i2.p1" class="ltx_para">
<p id="S2.I1.i2.p1.1" class="ltx_p">A persona commonsense fact triple (head, relation, tail) from the PeaCoK knowledge graph.</p>
</div>
</li>
</ul>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p">The task does not provide a training dataset, allowing participants to utilize any datasets they deem appropriate.
Evaluation is conducted on a closed test set using F1 score as the primary metric, with accuracy as a secondary measure.</p>
</div>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>PeaCoK Knowledge Graph</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">PeaCoK (Persona Commonsense Knowledge) is a large-scale knowledge graph designed to enhance dialogue systemsâ€™ consistency and engagement through persona-based commonsense knowledge.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.1" class="ltx_p">In PeaCoK, a persona fact is represented as a triple (head, relation, tail). The <span id="S2.SS1.p2.1.1" class="ltx_text ltx_font_italic">head</span> refers to the persona entity, such as "a singer". The <span id="S2.SS1.p2.1.2" class="ltx_text ltx_font_italic">relation</span> defines the type of connection between the head and the tail, such as "Characteristic", "Routine or Habit", "Goal or Plan", "Experience", or "Relationship". The <span id="S2.SS1.p2.1.3" class="ltx_text ltx_font_italic">tail</span> provides the specific attribute or detail related to the head persona, like "good at singing" for a singer. This structured representation allows for the integration of persona knowledge into dialogue systems, improving their ability to generate more contextually relevant and engaging responses.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Baseline Model</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">A baseline model is provided, which is based on the DeBERTa model <cite class="ltx_cite ltx_citemacro_citep">(He etÂ al., <a href="#bib.bib7" title="" class="ltx_ref">2020</a>)</cite> and finetuned on the ComFact dataset <cite class="ltx_cite ltx_citemacro_citep">(Gao etÂ al., <a href="#bib.bib4" title="" class="ltx_ref">2022</a>)</cite>, utilizing a different knowledge graph than PeaCoK. The baseline model evaluates the relevance of both head and tail entities separately, outputting a positive label (true) only if both entities are relevant to the dialogue context. For details about ComFact, refer to Appendix Sec.Â <a href="#A2" title="Appendix B ComFact: A Benchmark for Commonsense Fact Linking â€£ SynCPKL: Harnessing LLMs to Generate Synthetic Data for Commonsense Persona Knowledge Linking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">B</span></a>.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Methods</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">We present a novel approach to persona knowledge linking in dialogues, leveraging LLMs for efficient data generation and knowledge distillation. Our method employs a sophisticated pipeline that harnesses the reasoning capabilities of LLMs to create a high-quality labeled dataset. This approach enables our student model to effectively distill knowledge from the emergent abilities of LLMs, resulting in a robust system capable of linking persona facts to conversations with high accuracy.</p>
</div>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>SynCPKL Pipeline</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">Given the absence of a pre-existing dataset for this task, we developed the SynCPKL Pipeline to create a high-quality dataset for training a classifier. Our approach leverages the PeaCoK dataset for commonsense persona fact, and PersonaChat <cite class="ltx_cite ltx_citemacro_citep">(Zhang etÂ al., <a href="#bib.bib20" title="" class="ltx_ref">2018</a>)</cite> serves as the foundation for our conversation data <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>Previous efforts provided us with PersonaChat augmented with PeaCoK. The dataset can be found here: <a target="_blank" href="https://github.com/Silin159/PeaCoK-PersonaChat?tab=readme-ov-file" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/Silin159/PeaCoK-PersonaChat?tab=readme-ov-file</a></span></span></span>.</p>
</div>
<section id="S3.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.1 </span>Dataset Challenges and Quality Control</h4>

<div id="S3.SS1.SSS1.p1" class="ltx_para">
<p id="S3.SS1.SSS1.p1.1" class="ltx_p">Despite successfully identifying a suitable source dataset, several challenges emerged during our initial analysis.
The dataset comprises dialogues between two interlocutors, each associated with a distinct set of persona attributes. However, we observed various inconsistencies and noise within the data. Use Table <a href="#A2.T2" title="Table 2 â€£ Appendix B ComFact: A Benchmark for Commonsense Fact Linking â€£ SynCPKL: Harnessing LLMs to Generate Synthetic Data for Commonsense Persona Knowledge Linking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> in the Appendix as an example. The dialogue suffers from irrelevant persona facts that are either not utilized or poorly integrated into the conversation. For Persona 1, two facts ("I wish I could live forever" and "I only date people taller than me") are completely unused. For Persona 2, the mention of loving iced tea feels forced and doesnâ€™t contribute meaningfully to the dialogue.</p>
</div>
<div id="S3.SS1.SSS1.p2" class="ltx_para">
<p id="S3.SS1.SSS1.p2.1" class="ltx_p">These issues could potentially compromise the efficacy of models trained on this data, particularly for tasks focused on persona-based dialogue understanding.</p>
</div>
</section>
<section id="S3.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">3.1.2 </span>LLM-based Data Generation and Labeling</h4>

<div id="S3.SS1.SSS2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.p1.1" class="ltx_p">To address these challenges, we need a rigorous quality control process to create a dataset containing high-quality examples for accurately identifying the relevance of persona facts to a given conversation. Recent advancements in LLMs have demonstrated their potential as powerful labelers with human-like reasoning abilities <cite class="ltx_cite ltx_citemacro_citep">(Mitra etÂ al., <a href="#bib.bib16" title="" class="ltx_ref">2023</a>; Li etÂ al., <a href="#bib.bib14" title="" class="ltx_ref">2023</a>)</cite>. Leveraging this capability, we employed GPT-3.5-Turbo to generate synthetic data for our experiments.
Our data generation and labeling pipeline consists of the following key components:</p>
</div>
<section id="S3.SS1.SSS2.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Baseline Filtering to Prevent Imbalanced Data</h5>

<div id="S3.SS1.SSS2.Px1.p1" class="ltx_para">
<p id="S3.SS1.SSS2.Px1.p1.1" class="ltx_p">Our initial approach to creating training data employed a naive heuristic: positive pairs were formed using the original corresponding persona facts, while negative pairs were constructed using the other participantâ€™s persona facts. However, this method was prone to incorrect labeling. For instance, two personas might share a common fact, which our heuristic would erroneously label as negative. Moreover, this approach led to an imbalanced dataset dominated by negative examples.</p>
</div>
<div id="S3.SS1.SSS2.Px1.p2" class="ltx_para">
<p id="S3.SS1.SSS2.Px1.p2.1" class="ltx_p">To address these limitations, we developed a baseline filtering model. We fine-tuned a DeBERTa model on the ComFact dataset. This baseline model was then used to predict relevance scores for each persona fact-conversation pair. To determine an appropriate threshold for creating soft labels, we utilized the online private test set provided by the shared task organizers, ensuring alignment with the taskâ€™s objectives. This process resulted in a more balanced distribution of soft positive and negative labels before the official labeling.</p>
</div>
</section>
<section id="S3.SS1.SSS2.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Prompt Engineering and Iterative Refinement</h5>

<div id="S3.SS1.SSS2.Px2.p1" class="ltx_para">
<p id="S3.SS1.SSS2.Px2.p1.1" class="ltx_p">Our approach involved developing and evaluating multiple prompt templates, with Chain-of-Thought (CoT) prompting <cite class="ltx_cite ltx_citemacro_citep">(Wei etÂ al., <a href="#bib.bib18" title="" class="ltx_ref">2022</a>)</cite> proving most effective for GPT-3.5-Turbo. We iteratively processed and refined the dataset, starting with 10,000 examples and gradually expanding to 39,802 examples. This process included analyzing results, refining prompts based on observed patterns and errors, and continuously improving our prompting strategy to optimize data tagging performance.</p>
</div>
</section>
</section>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>SynCPKL Dataset</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.2" class="ltx_p">SynCPKL Pipeline demonstrates robust performance in curating a high-quality dataset, which we call SynCPKL. We generated two variants of the dataset:
(1) <span id="S3.SS2.p1.1.1" class="ltx_text ltx_font_bold">SynCPKL<sup id="S3.SS2.p1.1.1.1" class="ltx_sup"><span id="S3.SS2.p1.1.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">H</span></sup></span>: Using the <span id="S3.SS2.p1.2.3" class="ltx_text ltx_font_italic">head</span> entity as the persona fact for GPT-3.5-Turbo to tag.
(2) <span id="S3.SS2.p1.2.2" class="ltx_text ltx_font_bold">SynCPKL<sup id="S3.SS2.p1.2.2.1" class="ltx_sup"><span id="S3.SS2.p1.2.2.1.1" class="ltx_text ltx_font_medium ltx_font_italic">T</span></sup></span>: Using the <span id="S3.SS2.p1.2.4" class="ltx_text ltx_font_italic">tail</span> entity as the persona fact for GPT-3.5-Turbo to tag.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">Each variant comprises 39,802 examples, with identical matching between the two. In the final version of <span id="S3.SS2.p2.1.1" class="ltx_text ltx_font_bold">SynCPKL</span>, we combine both the relation head and tail as persona facts. An instance is labeled as true only when both the head and tail are independently verified as true.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments and Results</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We conducted a series of experiments to evaluate the performance of different models and input configurations on our persona-based knowledge-linking task. Our experiments utilized a subset of the private test set provided by the shared task organizers. Performance was measured using F1 score and accuracy (Acc).</p>
</div>
<figure id="S4.T1" class="ltx_table">
<table id="S4.T1.31" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S4.T1.31.32.1" class="ltx_tr">
<th id="S4.T1.31.32.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Version</th>
<th id="S4.T1.31.32.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">Dataset</th>
<th id="S4.T1.31.32.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">H</th>
<th id="S4.T1.31.32.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">T</th>
<th id="S4.T1.31.32.1.5" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">R</th>
<th id="S4.T1.31.32.1.6" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt">F1</th>
<th id="S4.T1.31.32.1.7" class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_tt">Acc</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S4.T1.3.3" class="ltx_tr">
<td id="S4.T1.3.3.4" class="ltx_td ltx_align_left ltx_border_t">Baseline</td>
<td id="S4.T1.3.3.5" class="ltx_td ltx_align_left ltx_border_t">ComFact</td>
<td id="S4.T1.1.1.1" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T1.1.1.1.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T1.1.1.1.m1.1a"><mi mathvariant="normal" id="S4.T1.1.1.1.m1.1.1" xref="S4.T1.1.1.1.m1.1.1.cmml">âœ“</mi><annotation-xml encoding="MathML-Content" id="S4.T1.1.1.1.m1.1b"><ci id="S4.T1.1.1.1.m1.1.1.cmml" xref="S4.T1.1.1.1.m1.1.1">âœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.1.1.1.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T1.2.2.2" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T1.2.2.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T1.2.2.2.m1.1a"><mi mathvariant="normal" id="S4.T1.2.2.2.m1.1.1" xref="S4.T1.2.2.2.m1.1.1.cmml">âœ“</mi><annotation-xml encoding="MathML-Content" id="S4.T1.2.2.2.m1.1b"><ci id="S4.T1.2.2.2.m1.1.1.cmml" xref="S4.T1.2.2.2.m1.1.1">âœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.2.2.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T1.3.3.3" class="ltx_td ltx_align_left ltx_border_t"><math id="S4.T1.3.3.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T1.3.3.3.m1.1a"><mo id="S4.T1.3.3.3.m1.1.1" xref="S4.T1.3.3.3.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.T1.3.3.3.m1.1b"><times id="S4.T1.3.3.3.m1.1.1.cmml" xref="S4.T1.3.3.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.3.3.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T1.3.3.6" class="ltx_td ltx_align_left ltx_border_t">0.382</td>
<td id="S4.T1.3.3.7" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">0.814</td>
</tr>
<tr id="S4.T1.8.8" class="ltx_tr">
<td id="S4.T1.4.4.1" class="ltx_td ltx_align_left"><math id="S4.T1.4.4.1.m1.1" class="ltx_Math" alttext="C^{H}" display="inline"><semantics id="S4.T1.4.4.1.m1.1a"><msup id="S4.T1.4.4.1.m1.1.1" xref="S4.T1.4.4.1.m1.1.1.cmml"><mi id="S4.T1.4.4.1.m1.1.1.2" xref="S4.T1.4.4.1.m1.1.1.2.cmml">C</mi><mi id="S4.T1.4.4.1.m1.1.1.3" xref="S4.T1.4.4.1.m1.1.1.3.cmml">H</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T1.4.4.1.m1.1b"><apply id="S4.T1.4.4.1.m1.1.1.cmml" xref="S4.T1.4.4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.4.4.1.m1.1.1.1.cmml" xref="S4.T1.4.4.1.m1.1.1">superscript</csymbol><ci id="S4.T1.4.4.1.m1.1.1.2.cmml" xref="S4.T1.4.4.1.m1.1.1.2">ğ¶</ci><ci id="S4.T1.4.4.1.m1.1.1.3.cmml" xref="S4.T1.4.4.1.m1.1.1.3">ğ»</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.4.4.1.m1.1c">C^{H}</annotation></semantics></math></td>
<td id="S4.T1.5.5.2" class="ltx_td ltx_align_left">SynCPKL<sup id="S4.T1.5.5.2.1" class="ltx_sup"><span id="S4.T1.5.5.2.1.1" class="ltx_text ltx_font_italic">H</span></sup>
</td>
<td id="S4.T1.6.6.3" class="ltx_td ltx_align_left"><math id="S4.T1.6.6.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T1.6.6.3.m1.1a"><mi mathvariant="normal" id="S4.T1.6.6.3.m1.1.1" xref="S4.T1.6.6.3.m1.1.1.cmml">âœ“</mi><annotation-xml encoding="MathML-Content" id="S4.T1.6.6.3.m1.1b"><ci id="S4.T1.6.6.3.m1.1.1.cmml" xref="S4.T1.6.6.3.m1.1.1">âœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.6.6.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T1.7.7.4" class="ltx_td ltx_align_left"><math id="S4.T1.7.7.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T1.7.7.4.m1.1a"><mo id="S4.T1.7.7.4.m1.1.1" xref="S4.T1.7.7.4.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.T1.7.7.4.m1.1b"><times id="S4.T1.7.7.4.m1.1.1.cmml" xref="S4.T1.7.7.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.7.7.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T1.8.8.5" class="ltx_td ltx_align_left"><math id="S4.T1.8.8.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T1.8.8.5.m1.1a"><mo id="S4.T1.8.8.5.m1.1.1" xref="S4.T1.8.8.5.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.T1.8.8.5.m1.1b"><times id="S4.T1.8.8.5.m1.1.1.cmml" xref="S4.T1.8.8.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.8.8.5.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T1.8.8.6" class="ltx_td ltx_align_left">0.547</td>
<td id="S4.T1.8.8.7" class="ltx_td ltx_nopad_r ltx_align_left">0.828</td>
</tr>
<tr id="S4.T1.13.13" class="ltx_tr">
<td id="S4.T1.9.9.1" class="ltx_td ltx_align_left"><math id="S4.T1.9.9.1.m1.1" class="ltx_Math" alttext="C^{t}" display="inline"><semantics id="S4.T1.9.9.1.m1.1a"><msup id="S4.T1.9.9.1.m1.1.1" xref="S4.T1.9.9.1.m1.1.1.cmml"><mi id="S4.T1.9.9.1.m1.1.1.2" xref="S4.T1.9.9.1.m1.1.1.2.cmml">C</mi><mi id="S4.T1.9.9.1.m1.1.1.3" xref="S4.T1.9.9.1.m1.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T1.9.9.1.m1.1b"><apply id="S4.T1.9.9.1.m1.1.1.cmml" xref="S4.T1.9.9.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.9.9.1.m1.1.1.1.cmml" xref="S4.T1.9.9.1.m1.1.1">superscript</csymbol><ci id="S4.T1.9.9.1.m1.1.1.2.cmml" xref="S4.T1.9.9.1.m1.1.1.2">ğ¶</ci><ci id="S4.T1.9.9.1.m1.1.1.3.cmml" xref="S4.T1.9.9.1.m1.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.9.9.1.m1.1c">C^{t}</annotation></semantics></math></td>
<td id="S4.T1.10.10.2" class="ltx_td ltx_align_left">SynCPKL<sup id="S4.T1.10.10.2.1" class="ltx_sup"><span id="S4.T1.10.10.2.1.1" class="ltx_text ltx_font_italic">T</span></sup>
</td>
<td id="S4.T1.11.11.3" class="ltx_td ltx_align_left"><math id="S4.T1.11.11.3.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T1.11.11.3.m1.1a"><mo id="S4.T1.11.11.3.m1.1.1" xref="S4.T1.11.11.3.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.T1.11.11.3.m1.1b"><times id="S4.T1.11.11.3.m1.1.1.cmml" xref="S4.T1.11.11.3.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.11.11.3.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T1.12.12.4" class="ltx_td ltx_align_left"><math id="S4.T1.12.12.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T1.12.12.4.m1.1a"><mi mathvariant="normal" id="S4.T1.12.12.4.m1.1.1" xref="S4.T1.12.12.4.m1.1.1.cmml">âœ“</mi><annotation-xml encoding="MathML-Content" id="S4.T1.12.12.4.m1.1b"><ci id="S4.T1.12.12.4.m1.1.1.cmml" xref="S4.T1.12.12.4.m1.1.1">âœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.12.12.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T1.13.13.5" class="ltx_td ltx_align_left"><math id="S4.T1.13.13.5.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T1.13.13.5.m1.1a"><mo id="S4.T1.13.13.5.m1.1.1" xref="S4.T1.13.13.5.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.T1.13.13.5.m1.1b"><times id="S4.T1.13.13.5.m1.1.1.cmml" xref="S4.T1.13.13.5.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.13.13.5.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T1.13.13.6" class="ltx_td ltx_align_left">0.299</td>
<td id="S4.T1.13.13.7" class="ltx_td ltx_nopad_r ltx_align_left">0.427</td>
</tr>
<tr id="S4.T1.19.19" class="ltx_tr">
<td id="S4.T1.16.16.3" class="ltx_td ltx_align_left">
<math id="S4.T1.14.14.1.m1.1" class="ltx_Math" alttext="C^{H}" display="inline"><semantics id="S4.T1.14.14.1.m1.1a"><msup id="S4.T1.14.14.1.m1.1.1" xref="S4.T1.14.14.1.m1.1.1.cmml"><mi id="S4.T1.14.14.1.m1.1.1.2" xref="S4.T1.14.14.1.m1.1.1.2.cmml">C</mi><mi id="S4.T1.14.14.1.m1.1.1.3" xref="S4.T1.14.14.1.m1.1.1.3.cmml">H</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T1.14.14.1.m1.1b"><apply id="S4.T1.14.14.1.m1.1.1.cmml" xref="S4.T1.14.14.1.m1.1.1"><csymbol cd="ambiguous" id="S4.T1.14.14.1.m1.1.1.1.cmml" xref="S4.T1.14.14.1.m1.1.1">superscript</csymbol><ci id="S4.T1.14.14.1.m1.1.1.2.cmml" xref="S4.T1.14.14.1.m1.1.1.2">ğ¶</ci><ci id="S4.T1.14.14.1.m1.1.1.3.cmml" xref="S4.T1.14.14.1.m1.1.1.3">ğ»</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.14.14.1.m1.1c">C^{H}</annotation></semantics></math> <math id="S4.T1.15.15.2.m2.1" class="ltx_Math" alttext="\land" display="inline"><semantics id="S4.T1.15.15.2.m2.1a"><mo id="S4.T1.15.15.2.m2.1.1" xref="S4.T1.15.15.2.m2.1.1.cmml">âˆ§</mo><annotation-xml encoding="MathML-Content" id="S4.T1.15.15.2.m2.1b"><and id="S4.T1.15.15.2.m2.1.1.cmml" xref="S4.T1.15.15.2.m2.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.15.15.2.m2.1c">\land</annotation></semantics></math> <math id="S4.T1.16.16.3.m3.1" class="ltx_Math" alttext="C^{t}" display="inline"><semantics id="S4.T1.16.16.3.m3.1a"><msup id="S4.T1.16.16.3.m3.1.1" xref="S4.T1.16.16.3.m3.1.1.cmml"><mi id="S4.T1.16.16.3.m3.1.1.2" xref="S4.T1.16.16.3.m3.1.1.2.cmml">C</mi><mi id="S4.T1.16.16.3.m3.1.1.3" xref="S4.T1.16.16.3.m3.1.1.3.cmml">t</mi></msup><annotation-xml encoding="MathML-Content" id="S4.T1.16.16.3.m3.1b"><apply id="S4.T1.16.16.3.m3.1.1.cmml" xref="S4.T1.16.16.3.m3.1.1"><csymbol cd="ambiguous" id="S4.T1.16.16.3.m3.1.1.1.cmml" xref="S4.T1.16.16.3.m3.1.1">superscript</csymbol><ci id="S4.T1.16.16.3.m3.1.1.2.cmml" xref="S4.T1.16.16.3.m3.1.1.2">ğ¶</ci><ci id="S4.T1.16.16.3.m3.1.1.3.cmml" xref="S4.T1.16.16.3.m3.1.1.3">ğ‘¡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.16.16.3.m3.1c">C^{t}</annotation></semantics></math>
</td>
<td id="S4.T1.19.19.7" class="ltx_td ltx_align_left">-</td>
<td id="S4.T1.17.17.4" class="ltx_td ltx_align_left"><math id="S4.T1.17.17.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T1.17.17.4.m1.1a"><mi mathvariant="normal" id="S4.T1.17.17.4.m1.1.1" xref="S4.T1.17.17.4.m1.1.1.cmml">âœ“</mi><annotation-xml encoding="MathML-Content" id="S4.T1.17.17.4.m1.1b"><ci id="S4.T1.17.17.4.m1.1.1.cmml" xref="S4.T1.17.17.4.m1.1.1">âœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.17.17.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T1.18.18.5" class="ltx_td ltx_align_left"><math id="S4.T1.18.18.5.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T1.18.18.5.m1.1a"><mi mathvariant="normal" id="S4.T1.18.18.5.m1.1.1" xref="S4.T1.18.18.5.m1.1.1.cmml">âœ“</mi><annotation-xml encoding="MathML-Content" id="S4.T1.18.18.5.m1.1b"><ci id="S4.T1.18.18.5.m1.1.1.cmml" xref="S4.T1.18.18.5.m1.1.1">âœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.18.18.5.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T1.19.19.6" class="ltx_td ltx_align_left"><math id="S4.T1.19.19.6.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T1.19.19.6.m1.1a"><mo id="S4.T1.19.19.6.m1.1.1" xref="S4.T1.19.19.6.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.T1.19.19.6.m1.1b"><times id="S4.T1.19.19.6.m1.1.1.cmml" xref="S4.T1.19.19.6.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.19.19.6.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T1.19.19.8" class="ltx_td ltx_align_left">0.548</td>
<td id="S4.T1.19.19.9" class="ltx_td ltx_nopad_r ltx_align_left">0.849</td>
</tr>
<tr id="S4.T1.23.23" class="ltx_tr">
<td id="S4.T1.20.20.1" class="ltx_td ltx_align_left"><math id="S4.T1.20.20.1.m1.2" class="ltx_Math" alttext="C^{H,T}" display="inline"><semantics id="S4.T1.20.20.1.m1.2a"><msup id="S4.T1.20.20.1.m1.2.3" xref="S4.T1.20.20.1.m1.2.3.cmml"><mi id="S4.T1.20.20.1.m1.2.3.2" xref="S4.T1.20.20.1.m1.2.3.2.cmml">C</mi><mrow id="S4.T1.20.20.1.m1.2.2.2.4" xref="S4.T1.20.20.1.m1.2.2.2.3.cmml"><mi id="S4.T1.20.20.1.m1.1.1.1.1" xref="S4.T1.20.20.1.m1.1.1.1.1.cmml">H</mi><mo id="S4.T1.20.20.1.m1.2.2.2.4.1" xref="S4.T1.20.20.1.m1.2.2.2.3.cmml">,</mo><mi id="S4.T1.20.20.1.m1.2.2.2.2" xref="S4.T1.20.20.1.m1.2.2.2.2.cmml">T</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.T1.20.20.1.m1.2b"><apply id="S4.T1.20.20.1.m1.2.3.cmml" xref="S4.T1.20.20.1.m1.2.3"><csymbol cd="ambiguous" id="S4.T1.20.20.1.m1.2.3.1.cmml" xref="S4.T1.20.20.1.m1.2.3">superscript</csymbol><ci id="S4.T1.20.20.1.m1.2.3.2.cmml" xref="S4.T1.20.20.1.m1.2.3.2">ğ¶</ci><list id="S4.T1.20.20.1.m1.2.2.2.3.cmml" xref="S4.T1.20.20.1.m1.2.2.2.4"><ci id="S4.T1.20.20.1.m1.1.1.1.1.cmml" xref="S4.T1.20.20.1.m1.1.1.1.1">ğ»</ci><ci id="S4.T1.20.20.1.m1.2.2.2.2.cmml" xref="S4.T1.20.20.1.m1.2.2.2.2">ğ‘‡</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.20.20.1.m1.2c">C^{H,T}</annotation></semantics></math></td>
<td id="S4.T1.23.23.5" class="ltx_td ltx_align_left">SynCPKL</td>
<td id="S4.T1.21.21.2" class="ltx_td ltx_align_left"><math id="S4.T1.21.21.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T1.21.21.2.m1.1a"><mi mathvariant="normal" id="S4.T1.21.21.2.m1.1.1" xref="S4.T1.21.21.2.m1.1.1.cmml">âœ“</mi><annotation-xml encoding="MathML-Content" id="S4.T1.21.21.2.m1.1b"><ci id="S4.T1.21.21.2.m1.1.1.cmml" xref="S4.T1.21.21.2.m1.1.1">âœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.21.21.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T1.22.22.3" class="ltx_td ltx_align_left"><math id="S4.T1.22.22.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T1.22.22.3.m1.1a"><mi mathvariant="normal" id="S4.T1.22.22.3.m1.1.1" xref="S4.T1.22.22.3.m1.1.1.cmml">âœ“</mi><annotation-xml encoding="MathML-Content" id="S4.T1.22.22.3.m1.1b"><ci id="S4.T1.22.22.3.m1.1.1.cmml" xref="S4.T1.22.22.3.m1.1.1">âœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.22.22.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T1.23.23.4" class="ltx_td ltx_align_left"><math id="S4.T1.23.23.4.m1.1" class="ltx_Math" alttext="\times" display="inline"><semantics id="S4.T1.23.23.4.m1.1a"><mo id="S4.T1.23.23.4.m1.1.1" xref="S4.T1.23.23.4.m1.1.1.cmml">Ã—</mo><annotation-xml encoding="MathML-Content" id="S4.T1.23.23.4.m1.1b"><times id="S4.T1.23.23.4.m1.1.1.cmml" xref="S4.T1.23.23.4.m1.1.1"></times></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.23.23.4.m1.1c">\times</annotation></semantics></math></td>
<td id="S4.T1.23.23.6" class="ltx_td ltx_align_left">0.554</td>
<td id="S4.T1.23.23.7" class="ltx_td ltx_nopad_r ltx_align_left">0.876</td>
</tr>
<tr id="S4.T1.27.27" class="ltx_tr">
<td id="S4.T1.24.24.1" class="ltx_td ltx_align_left">
<math id="S4.T1.24.24.1.m1.3" class="ltx_Math" alttext="C^{R,H,T}" display="inline"><semantics id="S4.T1.24.24.1.m1.3a"><msup id="S4.T1.24.24.1.m1.3.4" xref="S4.T1.24.24.1.m1.3.4.cmml"><mi id="S4.T1.24.24.1.m1.3.4.2" xref="S4.T1.24.24.1.m1.3.4.2.cmml">C</mi><mrow id="S4.T1.24.24.1.m1.3.3.3.5" xref="S4.T1.24.24.1.m1.3.3.3.4.cmml"><mi id="S4.T1.24.24.1.m1.1.1.1.1" xref="S4.T1.24.24.1.m1.1.1.1.1.cmml">R</mi><mo id="S4.T1.24.24.1.m1.3.3.3.5.1" xref="S4.T1.24.24.1.m1.3.3.3.4.cmml">,</mo><mi id="S4.T1.24.24.1.m1.2.2.2.2" xref="S4.T1.24.24.1.m1.2.2.2.2.cmml">H</mi><mo id="S4.T1.24.24.1.m1.3.3.3.5.2" xref="S4.T1.24.24.1.m1.3.3.3.4.cmml">,</mo><mi id="S4.T1.24.24.1.m1.3.3.3.3" xref="S4.T1.24.24.1.m1.3.3.3.3.cmml">T</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.T1.24.24.1.m1.3b"><apply id="S4.T1.24.24.1.m1.3.4.cmml" xref="S4.T1.24.24.1.m1.3.4"><csymbol cd="ambiguous" id="S4.T1.24.24.1.m1.3.4.1.cmml" xref="S4.T1.24.24.1.m1.3.4">superscript</csymbol><ci id="S4.T1.24.24.1.m1.3.4.2.cmml" xref="S4.T1.24.24.1.m1.3.4.2">ğ¶</ci><list id="S4.T1.24.24.1.m1.3.3.3.4.cmml" xref="S4.T1.24.24.1.m1.3.3.3.5"><ci id="S4.T1.24.24.1.m1.1.1.1.1.cmml" xref="S4.T1.24.24.1.m1.1.1.1.1">ğ‘…</ci><ci id="S4.T1.24.24.1.m1.2.2.2.2.cmml" xref="S4.T1.24.24.1.m1.2.2.2.2">ğ»</ci><ci id="S4.T1.24.24.1.m1.3.3.3.3.cmml" xref="S4.T1.24.24.1.m1.3.3.3.3">ğ‘‡</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.24.24.1.m1.3c">C^{R,H,T}</annotation></semantics></math>-NLI</td>
<td id="S4.T1.27.27.5" class="ltx_td ltx_align_left">SynCPKL</td>
<td id="S4.T1.25.25.2" class="ltx_td ltx_align_left"><math id="S4.T1.25.25.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T1.25.25.2.m1.1a"><mi mathvariant="normal" id="S4.T1.25.25.2.m1.1.1" xref="S4.T1.25.25.2.m1.1.1.cmml">âœ“</mi><annotation-xml encoding="MathML-Content" id="S4.T1.25.25.2.m1.1b"><ci id="S4.T1.25.25.2.m1.1.1.cmml" xref="S4.T1.25.25.2.m1.1.1">âœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.25.25.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T1.26.26.3" class="ltx_td ltx_align_left"><math id="S4.T1.26.26.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T1.26.26.3.m1.1a"><mi mathvariant="normal" id="S4.T1.26.26.3.m1.1.1" xref="S4.T1.26.26.3.m1.1.1.cmml">âœ“</mi><annotation-xml encoding="MathML-Content" id="S4.T1.26.26.3.m1.1b"><ci id="S4.T1.26.26.3.m1.1.1.cmml" xref="S4.T1.26.26.3.m1.1.1">âœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.26.26.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T1.27.27.4" class="ltx_td ltx_align_left"><math id="S4.T1.27.27.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T1.27.27.4.m1.1a"><mi mathvariant="normal" id="S4.T1.27.27.4.m1.1.1" xref="S4.T1.27.27.4.m1.1.1.cmml">âœ“</mi><annotation-xml encoding="MathML-Content" id="S4.T1.27.27.4.m1.1b"><ci id="S4.T1.27.27.4.m1.1.1.cmml" xref="S4.T1.27.27.4.m1.1.1">âœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.27.27.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T1.27.27.6" class="ltx_td ltx_align_left">0.554</td>
<td id="S4.T1.27.27.7" class="ltx_td ltx_nopad_r ltx_align_left">0.890</td>
</tr>
<tr id="S4.T1.31.31" class="ltx_tr">
<td id="S4.T1.28.28.1" class="ltx_td ltx_align_left ltx_border_bb"><math id="S4.T1.28.28.1.m1.3" class="ltx_Math" alttext="C^{R,H,T}" display="inline"><semantics id="S4.T1.28.28.1.m1.3a"><msup id="S4.T1.28.28.1.m1.3.4" xref="S4.T1.28.28.1.m1.3.4.cmml"><mi id="S4.T1.28.28.1.m1.3.4.2" xref="S4.T1.28.28.1.m1.3.4.2.cmml">C</mi><mrow id="S4.T1.28.28.1.m1.3.3.3.5" xref="S4.T1.28.28.1.m1.3.3.3.4.cmml"><mi id="S4.T1.28.28.1.m1.1.1.1.1" xref="S4.T1.28.28.1.m1.1.1.1.1.cmml">R</mi><mo id="S4.T1.28.28.1.m1.3.3.3.5.1" xref="S4.T1.28.28.1.m1.3.3.3.4.cmml">,</mo><mi id="S4.T1.28.28.1.m1.2.2.2.2" xref="S4.T1.28.28.1.m1.2.2.2.2.cmml">H</mi><mo id="S4.T1.28.28.1.m1.3.3.3.5.2" xref="S4.T1.28.28.1.m1.3.3.3.4.cmml">,</mo><mi id="S4.T1.28.28.1.m1.3.3.3.3" xref="S4.T1.28.28.1.m1.3.3.3.3.cmml">T</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.T1.28.28.1.m1.3b"><apply id="S4.T1.28.28.1.m1.3.4.cmml" xref="S4.T1.28.28.1.m1.3.4"><csymbol cd="ambiguous" id="S4.T1.28.28.1.m1.3.4.1.cmml" xref="S4.T1.28.28.1.m1.3.4">superscript</csymbol><ci id="S4.T1.28.28.1.m1.3.4.2.cmml" xref="S4.T1.28.28.1.m1.3.4.2">ğ¶</ci><list id="S4.T1.28.28.1.m1.3.3.3.4.cmml" xref="S4.T1.28.28.1.m1.3.3.3.5"><ci id="S4.T1.28.28.1.m1.1.1.1.1.cmml" xref="S4.T1.28.28.1.m1.1.1.1.1">ğ‘…</ci><ci id="S4.T1.28.28.1.m1.2.2.2.2.cmml" xref="S4.T1.28.28.1.m1.2.2.2.2">ğ»</ci><ci id="S4.T1.28.28.1.m1.3.3.3.3.cmml" xref="S4.T1.28.28.1.m1.3.3.3.3">ğ‘‡</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.28.28.1.m1.3c">C^{R,H,T}</annotation></semantics></math></td>
<td id="S4.T1.31.31.5" class="ltx_td ltx_align_left ltx_border_bb">SynCPKL</td>
<td id="S4.T1.29.29.2" class="ltx_td ltx_align_left ltx_border_bb"><math id="S4.T1.29.29.2.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T1.29.29.2.m1.1a"><mi mathvariant="normal" id="S4.T1.29.29.2.m1.1.1" xref="S4.T1.29.29.2.m1.1.1.cmml">âœ“</mi><annotation-xml encoding="MathML-Content" id="S4.T1.29.29.2.m1.1b"><ci id="S4.T1.29.29.2.m1.1.1.cmml" xref="S4.T1.29.29.2.m1.1.1">âœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.29.29.2.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T1.30.30.3" class="ltx_td ltx_align_left ltx_border_bb"><math id="S4.T1.30.30.3.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T1.30.30.3.m1.1a"><mi mathvariant="normal" id="S4.T1.30.30.3.m1.1.1" xref="S4.T1.30.30.3.m1.1.1.cmml">âœ“</mi><annotation-xml encoding="MathML-Content" id="S4.T1.30.30.3.m1.1b"><ci id="S4.T1.30.30.3.m1.1.1.cmml" xref="S4.T1.30.30.3.m1.1.1">âœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.30.30.3.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T1.31.31.4" class="ltx_td ltx_align_left ltx_border_bb"><math id="S4.T1.31.31.4.m1.1" class="ltx_Math" alttext="\checkmark" display="inline"><semantics id="S4.T1.31.31.4.m1.1a"><mi mathvariant="normal" id="S4.T1.31.31.4.m1.1.1" xref="S4.T1.31.31.4.m1.1.1.cmml">âœ“</mi><annotation-xml encoding="MathML-Content" id="S4.T1.31.31.4.m1.1b"><ci id="S4.T1.31.31.4.m1.1.1.cmml" xref="S4.T1.31.31.4.m1.1.1">âœ“</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.T1.31.31.4.m1.1c">\checkmark</annotation></semantics></math></td>
<td id="S4.T1.31.31.6" class="ltx_td ltx_align_left ltx_border_bb"><span id="S4.T1.31.31.6.1" class="ltx_text ltx_font_bold">0.572</span></td>
<td id="S4.T1.31.31.7" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb">0.881</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Different feature combinations of persona factsâ€™ results on the private test subset of the CPKL challenge.
</figcaption>
</figure>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Experimental Setup</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p id="S4.SS1.p1.1" class="ltx_p">We used DeBERTa-v3-large as our base model, with variations in the input representation of persona facts <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>The training was conducted on an NVIDIA RTX 3090 GPU with 24GB VRAM. The total training time on the full dataset was approximately 2 hours.</span></span></span>. We also included a comparison with a DeBERTa model fine-tuned for Natural Language Inference (NLI) <cite class="ltx_cite ltx_citemacro_citep">(Laurer etÂ al., <a href="#bib.bib10" title="" class="ltx_ref">2023</a>)</cite>.
The baseline model, trained on the ComFact dataset and based on DeBERTa-v3-large, was used for comparison.</p>
</div>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Feature Combination Analysis</h3>

<div id="S4.SS2.p1" class="ltx_para">
<p id="S4.SS2.p1.1" class="ltx_p">To investigate the impact of different input features on our modelâ€™s performance, we conducted an ablation study examining various combinations of <span id="S4.SS2.p1.1.1" class="ltx_text ltx_font_italic">head</span>, <span id="S4.SS2.p1.1.2" class="ltx_text ltx_font_italic">relation</span>, and <span id="S4.SS2.p1.1.3" class="ltx_text ltx_font_italic">tail</span> entities with the following configurations:</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.2" class="ltx_p">Head only (<math id="S4.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="C^{H}" display="inline"><semantics id="S4.I1.i1.p1.1.m1.1a"><msup id="S4.I1.i1.p1.1.m1.1.1" xref="S4.I1.i1.p1.1.m1.1.1.cmml"><mi id="S4.I1.i1.p1.1.m1.1.1.2" xref="S4.I1.i1.p1.1.m1.1.1.2.cmml">C</mi><mi id="S4.I1.i1.p1.1.m1.1.1.3" xref="S4.I1.i1.p1.1.m1.1.1.3.cmml">H</mi></msup><annotation-xml encoding="MathML-Content" id="S4.I1.i1.p1.1.m1.1b"><apply id="S4.I1.i1.p1.1.m1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.I1.i1.p1.1.m1.1.1.1.cmml" xref="S4.I1.i1.p1.1.m1.1.1">superscript</csymbol><ci id="S4.I1.i1.p1.1.m1.1.1.2.cmml" xref="S4.I1.i1.p1.1.m1.1.1.2">ğ¶</ci><ci id="S4.I1.i1.p1.1.m1.1.1.3.cmml" xref="S4.I1.i1.p1.1.m1.1.1.3">ğ»</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i1.p1.1.m1.1c">C^{H}</annotation></semantics></math>): A classifier trained on <span id="S4.I1.i1.p1.2.1" class="ltx_text ltx_font_bold">SynCPKL<sup id="S4.I1.i1.p1.2.1.1" class="ltx_sup"><span id="S4.I1.i1.p1.2.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">H</span></sup></span>, using only the <span id="S4.I1.i1.p1.2.2" class="ltx_text ltx_font_italic">head</span> entity.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.2" class="ltx_p">Tail only (<math id="S4.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="C^{T}" display="inline"><semantics id="S4.I1.i2.p1.1.m1.1a"><msup id="S4.I1.i2.p1.1.m1.1.1" xref="S4.I1.i2.p1.1.m1.1.1.cmml"><mi id="S4.I1.i2.p1.1.m1.1.1.2" xref="S4.I1.i2.p1.1.m1.1.1.2.cmml">C</mi><mi id="S4.I1.i2.p1.1.m1.1.1.3" xref="S4.I1.i2.p1.1.m1.1.1.3.cmml">T</mi></msup><annotation-xml encoding="MathML-Content" id="S4.I1.i2.p1.1.m1.1b"><apply id="S4.I1.i2.p1.1.m1.1.1.cmml" xref="S4.I1.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.I1.i2.p1.1.m1.1.1.1.cmml" xref="S4.I1.i2.p1.1.m1.1.1">superscript</csymbol><ci id="S4.I1.i2.p1.1.m1.1.1.2.cmml" xref="S4.I1.i2.p1.1.m1.1.1.2">ğ¶</ci><ci id="S4.I1.i2.p1.1.m1.1.1.3.cmml" xref="S4.I1.i2.p1.1.m1.1.1.3">ğ‘‡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i2.p1.1.m1.1c">C^{T}</annotation></semantics></math>): A classifier trained on <span id="S4.I1.i2.p1.2.1" class="ltx_text ltx_font_bold">SynCPKL<sup id="S4.I1.i2.p1.2.1.1" class="ltx_sup"><span id="S4.I1.i2.p1.2.1.1.1" class="ltx_text ltx_font_medium ltx_font_italic">T</span></sup></span>, using only the <span id="S4.I1.i2.p1.2.2" class="ltx_text ltx_font_italic">tail</span> entity.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.3" class="ltx_p">Head Classifier (<math id="S4.I1.i3.p1.1.m1.1" class="ltx_Math" alttext="C^{H}" display="inline"><semantics id="S4.I1.i3.p1.1.m1.1a"><msup id="S4.I1.i3.p1.1.m1.1.1" xref="S4.I1.i3.p1.1.m1.1.1.cmml"><mi id="S4.I1.i3.p1.1.m1.1.1.2" xref="S4.I1.i3.p1.1.m1.1.1.2.cmml">C</mi><mi id="S4.I1.i3.p1.1.m1.1.1.3" xref="S4.I1.i3.p1.1.m1.1.1.3.cmml">H</mi></msup><annotation-xml encoding="MathML-Content" id="S4.I1.i3.p1.1.m1.1b"><apply id="S4.I1.i3.p1.1.m1.1.1.cmml" xref="S4.I1.i3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S4.I1.i3.p1.1.m1.1.1.1.cmml" xref="S4.I1.i3.p1.1.m1.1.1">superscript</csymbol><ci id="S4.I1.i3.p1.1.m1.1.1.2.cmml" xref="S4.I1.i3.p1.1.m1.1.1.2">ğ¶</ci><ci id="S4.I1.i3.p1.1.m1.1.1.3.cmml" xref="S4.I1.i3.p1.1.m1.1.1.3">ğ»</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i3.p1.1.m1.1c">C^{H}</annotation></semantics></math>) <math id="S4.I1.i3.p1.2.m2.1" class="ltx_Math" alttext="\land" display="inline"><semantics id="S4.I1.i3.p1.2.m2.1a"><mo id="S4.I1.i3.p1.2.m2.1.1" xref="S4.I1.i3.p1.2.m2.1.1.cmml">âˆ§</mo><annotation-xml encoding="MathML-Content" id="S4.I1.i3.p1.2.m2.1b"><and id="S4.I1.i3.p1.2.m2.1.1.cmml" xref="S4.I1.i3.p1.2.m2.1.1"></and></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i3.p1.2.m2.1c">\land</annotation></semantics></math> Tail Classifier (<math id="S4.I1.i3.p1.3.m3.1" class="ltx_Math" alttext="C^{T}" display="inline"><semantics id="S4.I1.i3.p1.3.m3.1a"><msup id="S4.I1.i3.p1.3.m3.1.1" xref="S4.I1.i3.p1.3.m3.1.1.cmml"><mi id="S4.I1.i3.p1.3.m3.1.1.2" xref="S4.I1.i3.p1.3.m3.1.1.2.cmml">C</mi><mi id="S4.I1.i3.p1.3.m3.1.1.3" xref="S4.I1.i3.p1.3.m3.1.1.3.cmml">T</mi></msup><annotation-xml encoding="MathML-Content" id="S4.I1.i3.p1.3.m3.1b"><apply id="S4.I1.i3.p1.3.m3.1.1.cmml" xref="S4.I1.i3.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S4.I1.i3.p1.3.m3.1.1.1.cmml" xref="S4.I1.i3.p1.3.m3.1.1">superscript</csymbol><ci id="S4.I1.i3.p1.3.m3.1.1.2.cmml" xref="S4.I1.i3.p1.3.m3.1.1.2">ğ¶</ci><ci id="S4.I1.i3.p1.3.m3.1.1.3.cmml" xref="S4.I1.i3.p1.3.m3.1.1.3">ğ‘‡</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i3.p1.3.m3.1c">C^{T}</annotation></semantics></math>): Prediction is based on the <span id="S4.I1.i3.p1.3.1" class="ltx_text ltx_font_smallcaps">and</span> operation of models train on head and tail respectively.</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p">Head, Tail (<math id="S4.I1.i4.p1.1.m1.2" class="ltx_Math" alttext="C^{H,T}" display="inline"><semantics id="S4.I1.i4.p1.1.m1.2a"><msup id="S4.I1.i4.p1.1.m1.2.3" xref="S4.I1.i4.p1.1.m1.2.3.cmml"><mi id="S4.I1.i4.p1.1.m1.2.3.2" xref="S4.I1.i4.p1.1.m1.2.3.2.cmml">C</mi><mrow id="S4.I1.i4.p1.1.m1.2.2.2.4" xref="S4.I1.i4.p1.1.m1.2.2.2.3.cmml"><mi id="S4.I1.i4.p1.1.m1.1.1.1.1" xref="S4.I1.i4.p1.1.m1.1.1.1.1.cmml">H</mi><mo id="S4.I1.i4.p1.1.m1.2.2.2.4.1" xref="S4.I1.i4.p1.1.m1.2.2.2.3.cmml">,</mo><mi id="S4.I1.i4.p1.1.m1.2.2.2.2" xref="S4.I1.i4.p1.1.m1.2.2.2.2.cmml">T</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.I1.i4.p1.1.m1.2b"><apply id="S4.I1.i4.p1.1.m1.2.3.cmml" xref="S4.I1.i4.p1.1.m1.2.3"><csymbol cd="ambiguous" id="S4.I1.i4.p1.1.m1.2.3.1.cmml" xref="S4.I1.i4.p1.1.m1.2.3">superscript</csymbol><ci id="S4.I1.i4.p1.1.m1.2.3.2.cmml" xref="S4.I1.i4.p1.1.m1.2.3.2">ğ¶</ci><list id="S4.I1.i4.p1.1.m1.2.2.2.3.cmml" xref="S4.I1.i4.p1.1.m1.2.2.2.4"><ci id="S4.I1.i4.p1.1.m1.1.1.1.1.cmml" xref="S4.I1.i4.p1.1.m1.1.1.1.1">ğ»</ci><ci id="S4.I1.i4.p1.1.m1.2.2.2.2.cmml" xref="S4.I1.i4.p1.1.m1.2.2.2.2">ğ‘‡</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i4.p1.1.m1.2c">C^{H,T}</annotation></semantics></math>): A single classifier trained on <span id="S4.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">SynCPKL</span>, using both <span id="S4.I1.i4.p1.1.2" class="ltx_text ltx_font_italic">head</span> and <span id="S4.I1.i4.p1.1.3" class="ltx_text ltx_font_italic">tail</span> entities.</p>
</div>
</li>
<li id="S4.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="S4.I1.i5.p1" class="ltx_para">
<p id="S4.I1.i5.p1.1" class="ltx_p">Relation, Head, Tail (<math id="S4.I1.i5.p1.1.m1.3" class="ltx_Math" alttext="C^{R,H,T}" display="inline"><semantics id="S4.I1.i5.p1.1.m1.3a"><msup id="S4.I1.i5.p1.1.m1.3.4" xref="S4.I1.i5.p1.1.m1.3.4.cmml"><mi id="S4.I1.i5.p1.1.m1.3.4.2" xref="S4.I1.i5.p1.1.m1.3.4.2.cmml">C</mi><mrow id="S4.I1.i5.p1.1.m1.3.3.3.5" xref="S4.I1.i5.p1.1.m1.3.3.3.4.cmml"><mi id="S4.I1.i5.p1.1.m1.1.1.1.1" xref="S4.I1.i5.p1.1.m1.1.1.1.1.cmml">R</mi><mo id="S4.I1.i5.p1.1.m1.3.3.3.5.1" xref="S4.I1.i5.p1.1.m1.3.3.3.4.cmml">,</mo><mi id="S4.I1.i5.p1.1.m1.2.2.2.2" xref="S4.I1.i5.p1.1.m1.2.2.2.2.cmml">H</mi><mo id="S4.I1.i5.p1.1.m1.3.3.3.5.2" xref="S4.I1.i5.p1.1.m1.3.3.3.4.cmml">,</mo><mi id="S4.I1.i5.p1.1.m1.3.3.3.3" xref="S4.I1.i5.p1.1.m1.3.3.3.3.cmml">T</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.I1.i5.p1.1.m1.3b"><apply id="S4.I1.i5.p1.1.m1.3.4.cmml" xref="S4.I1.i5.p1.1.m1.3.4"><csymbol cd="ambiguous" id="S4.I1.i5.p1.1.m1.3.4.1.cmml" xref="S4.I1.i5.p1.1.m1.3.4">superscript</csymbol><ci id="S4.I1.i5.p1.1.m1.3.4.2.cmml" xref="S4.I1.i5.p1.1.m1.3.4.2">ğ¶</ci><list id="S4.I1.i5.p1.1.m1.3.3.3.4.cmml" xref="S4.I1.i5.p1.1.m1.3.3.3.5"><ci id="S4.I1.i5.p1.1.m1.1.1.1.1.cmml" xref="S4.I1.i5.p1.1.m1.1.1.1.1">ğ‘…</ci><ci id="S4.I1.i5.p1.1.m1.2.2.2.2.cmml" xref="S4.I1.i5.p1.1.m1.2.2.2.2">ğ»</ci><ci id="S4.I1.i5.p1.1.m1.3.3.3.3.cmml" xref="S4.I1.i5.p1.1.m1.3.3.3.3">ğ‘‡</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.I1.i5.p1.1.m1.3c">C^{R,H,T}</annotation></semantics></math>): A classifier trained on <span id="S4.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">SynCPKL</span>, using the complete triple (<span id="S4.I1.i5.p1.1.2" class="ltx_text ltx_font_italic">head</span>, <span id="S4.I1.i5.p1.1.3" class="ltx_text ltx_font_italic">relation</span>, <span id="S4.I1.i5.p1.1.4" class="ltx_text ltx_font_italic">tail</span>) as the persona fact.</p>
</div>
</li>
</ul>
</div>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Results &amp; Discussion</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p id="S4.SS3.p1.1" class="ltx_p">Table <a href="#S4.T1" title="Table 1 â€£ 4 Experiments and Results â€£ SynCPKL: Harnessing LLMs to Generate Synthetic Data for Commonsense Persona Knowledge Linking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> demonstrates that SynCPKL consistently outperforms Comfact across all metrics on the test subset, highlighting the efficacy of our synthetic data generation method.</p>
</div>
<div id="S4.SS3.p2" class="ltx_para">
<p id="S4.SS3.p2.1" class="ltx_p">Among the different feature combinations, the choice of Relation, Head, and Tail as persona fact yields the best overall performance (F1: 0.5729). This is intuitively straightforward that providing the model with complete information from KG is beneficial for accurate prediction.</p>
</div>
<div id="S4.SS3.p3" class="ltx_para">
<p id="S4.SS3.p3.2" class="ltx_p">However, an intriguing pattern emerges when we examine the performance of partial input configurations. Contrary to expectations, the "Head-only" model (<math id="S4.SS3.p3.1.m1.1" class="ltx_Math" alttext="C^{H}" display="inline"><semantics id="S4.SS3.p3.1.m1.1a"><msup id="S4.SS3.p3.1.m1.1.1" xref="S4.SS3.p3.1.m1.1.1.cmml"><mi id="S4.SS3.p3.1.m1.1.1.2" xref="S4.SS3.p3.1.m1.1.1.2.cmml">C</mi><mi id="S4.SS3.p3.1.m1.1.1.3" xref="S4.SS3.p3.1.m1.1.1.3.cmml">H</mi></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.1.m1.1b"><apply id="S4.SS3.p3.1.m1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S4.SS3.p3.1.m1.1.1.1.cmml" xref="S4.SS3.p3.1.m1.1.1">superscript</csymbol><ci id="S4.SS3.p3.1.m1.1.1.2.cmml" xref="S4.SS3.p3.1.m1.1.1.2">ğ¶</ci><ci id="S4.SS3.p3.1.m1.1.1.3.cmml" xref="S4.SS3.p3.1.m1.1.1.3">ğ»</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.1.m1.1c">C^{H}</annotation></semantics></math>â€™s F1: 0.547) performs comparably to the "Head, Tail" model (<math id="S4.SS3.p3.2.m2.2" class="ltx_Math" alttext="C^{H,T}" display="inline"><semantics id="S4.SS3.p3.2.m2.2a"><msup id="S4.SS3.p3.2.m2.2.3" xref="S4.SS3.p3.2.m2.2.3.cmml"><mi id="S4.SS3.p3.2.m2.2.3.2" xref="S4.SS3.p3.2.m2.2.3.2.cmml">C</mi><mrow id="S4.SS3.p3.2.m2.2.2.2.4" xref="S4.SS3.p3.2.m2.2.2.2.3.cmml"><mi id="S4.SS3.p3.2.m2.1.1.1.1" xref="S4.SS3.p3.2.m2.1.1.1.1.cmml">H</mi><mo id="S4.SS3.p3.2.m2.2.2.2.4.1" xref="S4.SS3.p3.2.m2.2.2.2.3.cmml">,</mo><mi id="S4.SS3.p3.2.m2.2.2.2.2" xref="S4.SS3.p3.2.m2.2.2.2.2.cmml">T</mi></mrow></msup><annotation-xml encoding="MathML-Content" id="S4.SS3.p3.2.m2.2b"><apply id="S4.SS3.p3.2.m2.2.3.cmml" xref="S4.SS3.p3.2.m2.2.3"><csymbol cd="ambiguous" id="S4.SS3.p3.2.m2.2.3.1.cmml" xref="S4.SS3.p3.2.m2.2.3">superscript</csymbol><ci id="S4.SS3.p3.2.m2.2.3.2.cmml" xref="S4.SS3.p3.2.m2.2.3.2">ğ¶</ci><list id="S4.SS3.p3.2.m2.2.2.2.3.cmml" xref="S4.SS3.p3.2.m2.2.2.2.4"><ci id="S4.SS3.p3.2.m2.1.1.1.1.cmml" xref="S4.SS3.p3.2.m2.1.1.1.1">ğ»</ci><ci id="S4.SS3.p3.2.m2.2.2.2.2.cmml" xref="S4.SS3.p3.2.m2.2.2.2.2">ğ‘‡</ci></list></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.SS3.p3.2.m2.2c">C^{H,T}</annotation></semantics></math>â€™s F1: 0.554), both approaching the performance of the best configuration. This suggests that, in our test set, correct prediction of the head entity often leads to correct overall prediction.</p>
</div>
<div id="S4.SS3.p4" class="ltx_para">
<p id="S4.SS3.p4.1" class="ltx_p">To investigate this phenomenon, we analyzed performance across different relation types (Table <a href="#A3.T3" title="Table 3 â€£ Data Quality Issues â€£ Appendix C Error Analysis â€£ SynCPKL: Harnessing LLMs to Generate Synthetic Data for Commonsense Persona Knowledge Linking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>). We found that the "Head-only" model underperforms our best model for all relations except <span id="S4.SS3.p4.1.1" class="ltx_text ltx_font_italic">characteristic</span>. This exception is logical, as the <span id="S4.SS3.p4.1.2" class="ltx_text ltx_font_italic">characteristic</span> relation often allows for inference of the tail entity from the head entity, even when the tail is not explicitly mentioned in the conversation.</p>
</div>
<div id="S4.SS3.p5" class="ltx_para">
<p id="S4.SS3.p5.1" class="ltx_p">The poor performance of the "Tail-only" model (F1: 0.299) further emphasizes the importance of the head entity in our task. This asymmetry in the importance of head and tail entities warrants further investigation and may inform future model designs and data collection strategies.</p>
</div>
<div id="S4.SS3.p6" class="ltx_para">
<p id="S4.SS3.p6.1" class="ltx_p">Regarding the choice of pre-trained models, we found that fine-tuning from the original DeBERTa model is more effective than fine-tuning from the DeBERTa-NLI model. While the NLI task seems conceptually aligned with our task objective, we hypothesize that it may impose an overly strict definition of entailment, potentially misclassifying some instances of commonsense reasoning as false pairs.</p>
</div>
<section id="S4.SS3.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Error Analysis.</h5>

<div id="S4.SS3.SSS0.Px1.p1" class="ltx_para">
<p id="S4.SS3.SSS0.Px1.p1.1" class="ltx_p">To gain deeper insights into the performance of our best-performing model, we conducted an error analysis. We randomly sampled 50 error cases from a total of 328 errors in our private test subset. This analysis revealed several key challenges for this task:
1. Over-reliance on head mentions
2. Difficulty handling implicit and conditional information
3. Data quality issues</p>
</div>
<div id="S4.SS3.SSS0.Px1.p2" class="ltx_para">
<p id="S4.SS3.SSS0.Px1.p2.1" class="ltx_p">These findings highlight the need for improved integration of head and tail information, enhanced reasoning capabilities for implicit and conditional relationships, and more rigorous data curation processes to advance the modelâ€™s performance in this complex task. See detailed error analysis in Appendix Sec.Â <a href="#A3" title="Appendix C Error Analysis â€£ SynCPKL: Harnessing LLMs to Generate Synthetic Data for Commonsense Persona Knowledge Linking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">C</span></a>.</p>
</div>
</section>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">In this work, we introduce a novel approach that leverages Large Language Models (LLMs) for synthetic data generation and knowledge distillation in commonsense persona knowledge linking for dialogues.
We present the first dataset, SynCPKL, in this task for PeaCok knowledge graph where SynCPKL is automatically constructed using our SynCPKL Pipeline. This pipeline offers a systematic and efficient method for utilizing LLMs in tasks lacking pre-existing datasets. Our comprehensive ablation studies reveal the most effective feature combinations and model configurations, showcasing superior reasoning capabilities for this complex task. Moreover, our final model, Deberta-SynCPKL, achieved first place in the CPKL challenge from the 6th Workshop on NLP for ConvAI.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Achiam etÂ al. (2023)</span>
<span class="ltx_bibblock">
OpenAIÂ Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, FlorenciaÂ Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haim ing Bao, MoÂ Bavarian, Jeff Belgum, Irwan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd, Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Benjamin Chess, Chester Cho, Casey Chu, HyungÂ Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux, Thomas Degry, Noah Deutsch, Damien Deville, Arka Dhar, David Dohan, Steve Dowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi, Liam Fedus, Niko Felix, Simâ€™onÂ Posada Fishman, Juston Forte, Isabella Fulford, Leo
Gao, Elie Georges, Christian Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Raphael Gontijo-Lopes, Jonathan Gordon, Morgan Grafstein, Scott Gray, Ryan Greene, Joshua Gross, ShixiangÂ Shane Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris, Yuchen He, Mike Heaton, Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele, Brandon Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn Jain, Joanne Jang, Angela Jiang, Roger Jiang, Haozhun Jin, Denny Jin, Shino Jomoto, Billie Jonn, Heewoo Jun, Tomer Kaftan, Lukasz Kaiser, Ali Kamali, Ingmar Kanitscheider, NitishÂ Shirish Keskar, Tabarak Khan, Logan Kilpatrick, JongÂ Wook Kim, Christina Kim, Yongjik Kim, Hendrik Kirchner, JamieÂ Ryan Kiros, Matthew Knight, Daniel Kokotajlo, Lukasz Kondraciuk, Andrew Kondrich, Aris Konstantinidis, Kyle Kosic, Gretchen Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Leung, Daniel Levy, ChakÂ Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz Litwin, Theresa Lopez,
Ryan Lowe, Patricia Lue, AnnaÂ Adeola Makanju, Kim Malfacini, Sam Manning, Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew, ScottÂ Mayer McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina, Aalok Mehta, Jacob Menick, Luke Metz, Andrey Mishchenko, Pamela Mishkin, Vinnie Monaco, Evan Morikawa, DanielÂ P. Mossing, Tong Mu, Mira Murati, Oleg Murk, David Mâ€™ely, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard Ngo, Hyeonwoo Noh, Ouyang Long, Cullen Oâ€™Keefe, JakubÂ W. Pachocki, Alex Paino, Joe Palermo, Ashley Pantuliano, Giambattista Parascandolo, Joel Parish, Emy Parparita, Alexandre Passos, Mikhail Pavlov, Andrew Peng, Adam Perelman, Filipe deÂ Avila BelbuteÂ Peres, Michael Petrov, HenriqueÂ PondÃ© deÂ OliveiraÂ Pinto, Michael Pokorny, Michelle Pokrass, VitchyrÂ H. Pong, Tolly Powell, Alethea Power, Boris Power, Elizabeth Proehl, Raul Puri, Alec Radford, Jack Rae, Aditya Ramesh, Cameron Raymond, Francis Real, Kendra Rimbach, Carl Ross, Bob
Rotsted, Henri Roussez, Nick Ryder, MarioÂ D. Saltarelli, Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr, John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin, Katarina Slama, Ian Sohl, BenjaminÂ D. Sokolowsky, Yang Song, Natalie Staudacher, FelipeÂ Petroski Such, Natalie Summers, Ilya Sutskever, Jie Tang, NikolasÂ A. Tezak, Madeleine Thompson, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston Tuggle, Nick Turley, Jerry Tworek, Juan FelipeÂ Cerâ€™on Uribe, Andrea Vallone, Arun Vijayvergiya, Chelsea Voss, CarrollÂ L. Wainwright, JustinÂ Jay Wang, Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei, CJÂ Weinmann, Akila Welihinda, Peter Welinder, Jiayi Weng, Lilian Weng, Matt Wiethoff, Dave Willner, Clemens Winter, Samuel Wolrich, Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qim ing Yuan, Wojciech Zaremba, Rowan Zellers, Chong
Zhang, Marvin Zhang, Shengjia Zhao, Tianhao Zheng, Juntang Zhuang, William Zhuk, and Barret Zoph. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:257532815" title="" class="ltx_ref ltx_href">Gpt-4 technical report</a>.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Bae etÂ al. (2022)</span>
<span class="ltx_bibblock">
Sanghwan Bae, Donghyun Kwak, Sungdong Kim, Dong hyun Ham, Soyoung Kang, Sang-Woo Lee, and WooÂ Chul Park. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:248496216" title="" class="ltx_ref ltx_href">Building a role specified open-domain dialogue system leveraging large-scale language models</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">North American Chapter of the Association for Computational Linguistics</em>.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao etÂ al. (2023)</span>
<span class="ltx_bibblock">
Silin Gao, Beatriz Borges, Soyoung Oh, Deniz Bayazit, Saya Kanno, Hiromi Wakaki, Yuki Mitsufuji, and Antoine Bosselut. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:258480238" title="" class="ltx_ref ltx_href">Peacok: Persona commonsense knowledge for consistent and engaging narratives</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">Annual Meeting of the Association for Computational Linguistics</em>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Gao etÂ al. (2022)</span>
<span class="ltx_bibblock">
Silin Gao, JenaÂ D. Hwang, Saya Kanno, Hiromi Wakaki, Yuki Mitsufuji, and Antoine Bosselut. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:253098370" title="" class="ltx_ref ltx_href">Comfact: A benchmark for linking contextual commonsense knowledge</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Conference on Empirical Methods in Natural Language Processing</em>.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han etÂ al. (2023)</span>
<span class="ltx_bibblock">
Jieun Han, Haneul Yoo, YooÂ Lae Kim, Jun-Hee Myung, Minsun Kim, Hyunseung Lim, Juho Kim, TakÂ Yeon Lee, Hwajung Hong, So-Yeon Ahn, and AliceÂ H. Oh. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:258823196" title="" class="ltx_ref ltx_href">Recipe: How to integrate chatgpt into efl writing education</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Proceedings of the Tenth ACM Conference on Learning @ Scale</em>.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Han etÂ al. (2022)</span>
<span class="ltx_bibblock">
Seungju Han, Beomsu Kim, JinÂ Yong Yoo, Seokjun Seo, Sangbum Kim, Enkhbayar Erdenee, and Buru Chang. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:248366298" title="" class="ltx_ref ltx_href">Meet your favorite character: Open-domain chatbot mimicking fictional characters with only a few utterances</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">North American Chapter of the Association for Computational Linguistics</em>.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">He etÂ al. (2020)</span>
<span class="ltx_bibblock">
Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. 2020.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:219531210" title="" class="ltx_ref ltx_href">Deberta: Decoding-enhanced bert with disentangled attention</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2006.03654.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jandaghi etÂ al. (2023)</span>
<span class="ltx_bibblock">
Pegah Jandaghi, XiangHai Sheng, Xinyi Bai, Jay Pujara, and Hakim Sidahmed. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:266335707" title="" class="ltx_ref ltx_href">Faithful persona-based conversational dataset generation with large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2312.10007.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jang etÂ al. (2023)</span>
<span class="ltx_bibblock">
Jihyoung Jang, Minseong Boo, and Hyounghun Kim. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:264406147" title="" class="ltx_ref ltx_href">Conversation chronicles: Towards diverse temporal and relational dynamics in multi-session conversations</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2310.13420.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Laurer etÂ al. (2023)</span>
<span class="ltx_bibblock">
Moritz Laurer, Wouter van Atteveldt, Andreu Casas, and Kasper Welbers. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://doi.org/10.48550/arXiv.2312.17543" title="" class="ltx_ref ltx_href">Building Efficient Universal Classifiers with Natural Language Inference</a>.

</span>
<span class="ltx_bibblock">ArXiv:2312.17543 [cs].

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee etÂ al. (2022a)</span>
<span class="ltx_bibblock">
Mina Lee, Percy Liang, and Qian Yang. 2022a.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:246016439" title="" class="ltx_ref ltx_href">Coauthor: Designing a human-ai collaborative writing dataset for exploring language model capabilities</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 2022 CHI Conference on Human Factors in Computing Systems</em>.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee etÂ al. (2022b)</span>
<span class="ltx_bibblock">
Young-Jun Lee, ByungSoo Ko, Han-Gyu Kim, and Ho-Jin Choi. 2022b.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:254408863" title="" class="ltx_ref ltx_href">Dialogcc: An automated pipeline for creating high-quality multi-modal dialogue dataset</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">North American Chapter of the Association for Computational Linguistics</em>.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Lee etÂ al. (2022c)</span>
<span class="ltx_bibblock">
Young-Jun Lee, Chae-Gyun Lim, Yunsu Choi, Ji-Hui Lm, and Ho-Jin Choi. 2022c.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:252819096" title="" class="ltx_ref ltx_href">Personachatgen: Generating personalized dialogues using gpt-3</a>.

</span>
<span class="ltx_bibblock">In <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">CCGPK</em>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li etÂ al. (2023)</span>
<span class="ltx_bibblock">
Yuan-Fang Li, SÃ©bastien Bubeck, Ronen Eldan, AllisonÂ Del Giorno, Suriya Gunasekar, and YinÂ Tat Lee. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:261696657" title="" class="ltx_ref ltx_href">Textbooks are all you need ii: phi-1.5 technical report</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2309.05463.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Maharana etÂ al. (2024)</span>
<span class="ltx_bibblock">
Adyasha Maharana, Dong-Ho Lee, S.Â Tulyakov, Mohit Bansal, Francesco Barbieri, and Yuwei Fang. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:268041615" title="" class="ltx_ref ltx_href">Evaluating very long-term conversational memory of llm agents</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2402.17753.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Mitra etÂ al. (2023)</span>
<span class="ltx_bibblock">
Arindam Mitra, LucianoÂ Del Corro, Shweti Mahajan, Andres Codas, Clarisse Simoes, Sahaj Agrawal, Xuxi Chen, Anastasia Razdaibiedina, Erik Jones, Kriti Aggarwal, Hamid Palangi, Guoqing Zheng, Corby Rosset, Hamed Khanpour, and Ahmed Awadallah. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:265295592" title="" class="ltx_ref ltx_href">Orca 2: Teaching small language models how to reason</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2311.11045.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wakaki etÂ al. (2024)</span>
<span class="ltx_bibblock">
Hiromi Wakaki, Yuki Mitsufuji, Yoshinori Maeda, Yukiko Nishimura, Silin Gao, Mengjie Zhao, Keiichi Yamada, and Antoine Bosselut. 2024.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:270559399" title="" class="ltx_ref ltx_href">Comperdial: Commonsense persona-grounded dialogue dataset and benchmark</a>.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wei etÂ al. (2022)</span>
<span class="ltx_bibblock">
Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, EdÂ Huai hsin Chi, F.Â Xia, Quoc Le, and Denny Zhou. 2022.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:246411621" title="" class="ltx_ref ltx_href">Chain of thought prompting elicits reasoning in large language models</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2201.11903.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2023)</span>
<span class="ltx_bibblock">
Qiang Zhang, Jason Naradowsky, and Yusuke Miyao. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:264439022" title="" class="ltx_ref ltx_href">Mind the gap between conversations for improved long-term dialogue generation</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2310.15415.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhang etÂ al. (2018)</span>
<span class="ltx_bibblock">
Saizheng Zhang, Emily Dinan, Jack Urbanek, Arthur Szlam, Douwe Kiela, and Jason Weston. 2018.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:6869582" title="" class="ltx_ref ltx_href">Personalizing dialogue agents: I have a dog, do you have pets too?</a>

</span>
<span class="ltx_bibblock"><em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/1801.07243.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhou etÂ al. (2023)</span>
<span class="ltx_bibblock">
Xuhui Zhou, Hao Zhu, Leena Mathur, Ruohong Zhang, Haofei Yu, Zhengyang Qi, Louis-Philippe Morency, Yonatan Bisk, Daniel Fried, Graham Neubig, and Maarten Sap. 2023.

</span>
<span class="ltx_bibblock"><a target="_blank" href="https://api.semanticscholar.org/CorpusID:264289186" title="" class="ltx_ref ltx_href">Sotopia: Interactive evaluation for social intelligence in language agents</a>.

</span>
<span class="ltx_bibblock"><em id="bib.bib21.1.1" class="ltx_emph ltx_font_italic">ArXiv</em>, abs/2310.11667.

</span>
</li>
</ul>
</section>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>An Example Conversation with Persona Facts</h2>

<div id="A1.p1" class="ltx_para">
<p id="A1.p1.1" class="ltx_p">TableÂ <a href="#A2.T2" title="Table 2 â€£ Appendix B ComFact: A Benchmark for Commonsense Fact Linking â€£ SynCPKL: Harnessing LLMs to Generate Synthetic Data for Commonsense Persona Knowledge Linking" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows a conversation between two people with their persona facts respectively.</p>
</div>
</section>
<section id="A2" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix B </span>ComFact: A Benchmark for Commonsense Fact Linking</h2>

<div id="A2.p1" class="ltx_para">
<p id="A2.p1.1" class="ltx_p">ComFact is a benchmark for commonsense fact-linking in dialogues and storytelling. It addresses the challenge of identifying situationally relevant knowledge from a knowledge graphs, which is different from PeaCok. In ComFact, each data point consists of a context from a dialogue and a set of commonsense facts that need to be linked to this context. These facts are structured as triples (a head entity, a relation, and a tail entity).</p>
</div>
<figure id="A2.T2" class="ltx_table">
<table id="A2.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A2.T2.1.1.1" class="ltx_tr">
<th id="A2.T2.1.1.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t" colspan="2"><span id="A2.T2.1.1.1.1.1" class="ltx_text ltx_font_bold">Persona Facts:</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A2.T2.1.2.1" class="ltx_tr">
<td id="A2.T2.1.2.1.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="A2.T2.1.2.1.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T2.1.2.1.1.1.1" class="ltx_p" style="width:195.1pt;"><span id="A2.T2.1.2.1.1.1.1.1" class="ltx_text ltx_font_bold">Persona 1</span></span>
</span>
</td>
<td id="A2.T2.1.2.1.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A2.T2.1.2.1.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T2.1.2.1.2.1.1" class="ltx_p" style="width:195.1pt;"><span id="A2.T2.1.2.1.2.1.1.1" class="ltx_text ltx_font_bold">Persona 2</span></span>
</span>
</td>
</tr>
<tr id="A2.T2.1.3.2" class="ltx_tr">
<td id="A2.T2.1.3.2.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t">
<span id="A2.T2.1.3.2.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T2.1.3.2.1.1.1" class="ltx_p" style="width:195.1pt;">- I wish I could live forever.</span>
</span>
</td>
<td id="A2.T2.1.3.2.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r ltx_border_t">
<span id="A2.T2.1.3.2.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T2.1.3.2.2.1.1" class="ltx_p" style="width:195.1pt;">- My mom is my best friend.</span>
</span>
</td>
</tr>
<tr id="A2.T2.1.4.3" class="ltx_tr">
<td id="A2.T2.1.4.3.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="A2.T2.1.4.3.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T2.1.4.3.1.1.1" class="ltx_p" style="width:195.1pt;">- I only date people taller than me.</span>
</span>
</td>
<td id="A2.T2.1.4.3.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="A2.T2.1.4.3.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T2.1.4.3.2.1.1" class="ltx_p" style="width:195.1pt;">- I have four sisters.</span>
</span>
</td>
</tr>
<tr id="A2.T2.1.5.4" class="ltx_tr">
<td id="A2.T2.1.5.4.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="A2.T2.1.5.4.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T2.1.5.4.1.1.1" class="ltx_p" style="width:195.1pt;">- I really like technology.</span>
</span>
</td>
<td id="A2.T2.1.5.4.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="A2.T2.1.5.4.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T2.1.5.4.2.1.1" class="ltx_p" style="width:195.1pt;">- I believe that mermaids are real.</span>
</span>
</td>
</tr>
<tr id="A2.T2.1.6.5" class="ltx_tr">
<td id="A2.T2.1.6.5.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r">
<span id="A2.T2.1.6.5.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T2.1.6.5.1.1.1" class="ltx_p" style="width:195.1pt;">- I like free diving.</span>
</span>
</td>
<td id="A2.T2.1.6.5.2" class="ltx_td ltx_align_justify ltx_align_top ltx_border_r">
<span id="A2.T2.1.6.5.2.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T2.1.6.5.2.1.1" class="ltx_p" style="width:195.1pt;">- I love iced tea.</span>
</span>
</td>
</tr>
<tr id="A2.T2.1.7.6" class="ltx_tr">
<td id="A2.T2.1.7.6.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_l ltx_border_r ltx_border_t" colspan="2"><span id="A2.T2.1.7.6.1.1" class="ltx_text ltx_font_bold">Conversation:</span></td>
</tr>
<tr id="A2.T2.1.8.7" class="ltx_tr">
<td id="A2.T2.1.8.7.1" class="ltx_td ltx_align_justify ltx_align_top ltx_border_b ltx_border_l ltx_border_r ltx_border_t" colspan="2">
<span id="A2.T2.1.8.7.1.1" class="ltx_inline-block ltx_align_top">
<span id="A2.T2.1.8.7.1.1.1" class="ltx_p" style="width:390.3pt;">
Persona1: Hi, how are you doing today?</span>
<span id="A2.T2.1.8.7.1.1.2" class="ltx_p">Persona2: I am spending time with my 4 sisters what are you up to</span>
<span id="A2.T2.1.8.7.1.1.3" class="ltx_p">Persona1: Wow, four sisters. Just watching game of thrones.</span>
<span id="A2.T2.1.8.7.1.1.4" class="ltx_p">Persona2: That is a good show I watch that while drinking iced tea</span>
<span id="A2.T2.1.8.7.1.1.5" class="ltx_p">Persona1: I agree. What do you do for a living?</span>
<span id="A2.T2.1.8.7.1.1.6" class="ltx_p">Persona2: Iâ€™m a researcher Iâ€™m researching the fact that mermaids are real</span>
<span id="A2.T2.1.8.7.1.1.7" class="ltx_p">Persona1: Interesting. Iâ€™m a website designer. Pretty much spend all my time on the computer.</span>
<span id="A2.T2.1.8.7.1.1.8" class="ltx_p">Persona2: Thatâ€™s cool my mom does the same thing</span>
<span id="A2.T2.1.8.7.1.1.9" class="ltx_p">Persona1: Thatâ€™s awesome. I have always had a love for technology.</span>
<span id="A2.T2.1.8.7.1.1.10" class="ltx_p">Persona2: Tell me more about yourself</span>
<span id="A2.T2.1.8.7.1.1.11" class="ltx_p">Persona1: I really enjoy free diving, how about you, have any hobbies?</span>
<span id="A2.T2.1.8.7.1.1.12" class="ltx_p">Persona2: I enjoy hanging with my mother sheâ€™s my best friend</span>
<span id="A2.T2.1.8.7.1.1.13" class="ltx_p">Persona1: Thatâ€™s nice. Moms are pretty cool too.</span>
<span id="A2.T2.1.8.7.1.1.14" class="ltx_p">Persona2: Iâ€™m also fascinated with mermaids</span>
</span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Example conversation between two personas</figcaption>
</figure>
</section>
<section id="A3" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix C </span>Error Analysis</h2>

<div id="A3.p1" class="ltx_para">
<p id="A3.p1.1" class="ltx_p">We conducted a comprehensive error analysis on our best-performing model to identify patterns in misclassifications and potential areas for improvement. This analysis involved manually reviewing a sample of incorrectly classified instances from the private test set.</p>
</div>
<div id="A3.p2" class="ltx_para">
<p id="A3.p2.1" class="ltx_p">We randomly sampled 50 error cases out of 328 total errors for our final model. Our observations are summarized as follows:</p>
</div>
<div id="A3.p3" class="ltx_para">
<ul id="A3.I1" class="ltx_itemize">
<li id="A3.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A3.I1.i1.p1" class="ltx_para">
<p id="A3.I1.i1.p1.1" class="ltx_p"><span id="A3.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Over-Reliance on <span id="A3.I1.i1.p1.1.1.1" class="ltx_text ltx_font_italic">Head</span> Mentions (10%):</span> In 5 cases, the model incorrectly suggested relatedness when the <span id="A3.I1.i1.p1.1.2" class="ltx_text ltx_font_italic">head</span> was directly mentioned in the conversation, but the <span id="A3.I1.i1.p1.1.3" class="ltx_text ltx_font_italic">tail</span> was unrelated. This suggests that the model may be overly reliant on <span id="A3.I1.i1.p1.1.4" class="ltx_text ltx_font_italic">head</span> matches and fails to adequately consider <span id="A3.I1.i1.p1.1.5" class="ltx_text ltx_font_italic">tail</span> information. For example, an utterance "I am a relay racer" matched the <span id="A3.I1.i1.p1.1.6" class="ltx_text ltx_font_italic">head</span> "personx is a relay racer", but the model failed to recognize that the <span id="A3.I1.i1.p1.1.7" class="ltx_text ltx_font_italic">tail</span> was unrelated.</p>
</div>
</li>
<li id="A3.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A3.I1.i2.p1" class="ltx_para">
<p id="A3.I1.i2.p1.1" class="ltx_p"><span id="A3.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Implicit <span id="A3.I1.i2.p1.1.1.1" class="ltx_text ltx_font_italic">Head</span> Mentions with Conditional Tail Relevance (12%):</span> In 6 cases, the <span id="A3.I1.i2.p1.1.2" class="ltx_text ltx_font_italic">head</span> was vaguely implied within the conversation, and the <span id="A3.I1.i2.p1.1.3" class="ltx_text ltx_font_italic">tail</span> could only be inferred if the <span id="A3.I1.i2.p1.1.4" class="ltx_text ltx_font_italic">head</span> were true. This highlights the challenge of handling implicit information and conditional reasoning. For instance, with the <span id="A3.I1.i2.p1.1.5" class="ltx_text ltx_font_italic">head</span> "personx is a calligrapher" and <span id="A3.I1.i2.p1.1.6" class="ltx_text ltx_font_italic">tail</span> "writes in a beautiful script", the model struggled to make the connection that being a calligrapher implies writing beautifully.</p>
</div>
</li>
<li id="A3.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A3.I1.i3.p1" class="ltx_para">
<p id="A3.I1.i3.p1.1" class="ltx_p"><span id="A3.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Ambiguous Implications (4%):</span> In 2 cases, both <span id="A3.I1.i3.p1.1.2" class="ltx_text ltx_font_italic">head</span> and <span id="A3.I1.i3.p1.1.3" class="ltx_text ltx_font_italic">tail</span> were very vaguely implied, presenting difficulties even for human annotators. This underscores the inherent ambiguity in some persona-based inferences and the potential for high disagreement in labeling.</p>
</div>
</li>
<li id="A3.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A3.I1.i4.p1" class="ltx_para">
<p id="A3.I1.i4.p1.1" class="ltx_p"><span id="A3.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Data quality issues (26%):</span> 13 cases exhibited data quality problems, primarily where the gold reference suggested truth without supporting evidence in the conversation. For example, a conversation implying PersonX was a businessman was paired with a <span id="A3.I1.i4.p1.1.2" class="ltx_text ltx_font_italic">head</span> "personx is a rich investor who becomes rich" and <span id="A3.I1.i4.p1.1.3" class="ltx_text ltx_font_italic">tail</span> "made a large return on investment", neither of which were explicitly supported. This highlights the need for more rigorous data curation and annotation processes.</p>
</div>
</li>
<li id="A3.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">â€¢</span> 
<div id="A3.I1.i5.p1" class="ltx_para">
<p id="A3.I1.i5.p1.1" class="ltx_p"><span id="A3.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Model prediction errors (48%):</span> 24 cases were clear model prediction errors, indicating room for improvement in the modelâ€™s core reasoning capabilities.</p>
</div>
</li>
</ul>
</div>
<div id="A3.p4" class="ltx_para">
<p id="A3.p4.1" class="ltx_p">Through the manual review, we identify a couple of insights:</p>
</div>
<section id="A3.SS0.SSS0.Px1" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Imbalance in Head-Tail Integration: Challenges in SynCPKL Labeling Strategy</h5>

<div id="A3.SS0.SSS0.Px1.p1" class="ltx_para">
<p id="A3.SS0.SSS0.Px1.p1.3" class="ltx_p">The model demonstrates a tendency to over-rely on head matches, indicating a critical challenge in effectively integrating both head and tail information. This imbalance may stem from our current labeling strategy for SynCPKL, which designates a positive label only when both SynCPKL<sup id="A3.SS0.SSS0.Px1.p1.3.1" class="ltx_sup"><span id="A3.SS0.SSS0.Px1.p1.3.1.1" class="ltx_text ltx_font_italic">H</span></sup> and SynCPKL<sup id="A3.SS0.SSS0.Px1.p1.3.2" class="ltx_sup"><span id="A3.SS0.SSS0.Px1.p1.3.2.1" class="ltx_text ltx_font_italic">T</span></sup> are true. We hypothesize that the SynCPKL<sup id="A3.SS0.SSS0.Px1.p1.3.3" class="ltx_sup"><span id="A3.SS0.SSS0.Px1.p1.3.3.1" class="ltx_text ltx_font_italic">T</span></sup> component may lack sufficient informational content, potentially leading to false negatives in the LLM predictions.</p>
</div>
</section>
<section id="A3.SS0.SSS0.Px2" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Head-Tail Interdependence</h5>

<div id="A3.SS0.SSS0.Px2.p1" class="ltx_para">
<p id="A3.SS0.SSS0.Px2.p1.1" class="ltx_p">The impact of different feature combinations exhibits significant variation across test subsets.
This is particularly evident in the "Tail only" configuration, which demonstrates markedly poor performance on the test subset (F1: 0.2992).
A plausible explanation for this lies in the inherent dependency of many tail entities on their corresponding head entities. For instance, consider a case where the <span id="A3.SS0.SSS0.Px2.p1.1.1" class="ltx_text ltx_font_italic">head</span> is "a singer" and the <span id="A3.SS0.SSS0.Px2.p1.1.2" class="ltx_text ltx_font_italic">tail</span> is "make music day to day." In such scenarios, the accuracy of the <span id="A3.SS0.SSS0.Px2.p1.1.3" class="ltx_text ltx_font_italic">tail</span> classification is often contingent upon the correct identification of <span id="A3.SS0.SSS0.Px2.p1.1.4" class="ltx_text ltx_font_italic">head</span> within the conversational context.
This interdependence suggests that isolated <span id="A3.SS0.SSS0.Px2.p1.1.5" class="ltx_text ltx_font_italic">tail</span> classification may be insufficient for robust performance, highlighting the importance of considering head-tail relationships in entity extraction tasks.</p>
</div>
</section>
<section id="A3.SS0.SSS0.Px3" class="ltx_paragraph">
<h5 class="ltx_title ltx_title_paragraph">Data Quality Issues</h5>

<div id="A3.SS0.SSS0.Px3.p1" class="ltx_para">
<p id="A3.SS0.SSS0.Px3.p1.1" class="ltx_p">Addressing issues in the training and evaluation data could lead to more reliable model performance and evaluation.</p>
</div>
<div id="A3.SS0.SSS0.Px3.p2" class="ltx_para">
<p id="A3.SS0.SSS0.Px3.p2.1" class="ltx_p">Our analysis indicates that while our model can distill some commonsense knowledge from LLMs, there are still significant opportunities to enhance its ability to effectively utilize LLM knowledge for this ambiguous task.</p>
</div>
<figure id="A3.T3" class="ltx_table">
<table id="A3.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A3.T3.1.1.1" class="ltx_tr">
<td id="A3.T3.1.1.1.1" class="ltx_td ltx_border_tt"></td>
<th id="A3.T3.1.1.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" colspan="2">Head-only</th>
<th id="A3.T3.1.1.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_tt" colspan="2">Deberta-SynCPKL</th>
</tr>
<tr id="A3.T3.1.2.2" class="ltx_tr">
<th id="A3.T3.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Relation</th>
<th id="A3.T3.1.2.2.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">F1</th>
<th id="A3.T3.1.2.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">Acc</th>
<th id="A3.T3.1.2.2.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_t">F1</th>
<th id="A3.T3.1.2.2.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_th ltx_th_column ltx_border_t">Acc</th>
</tr>
<tr id="A3.T3.1.3.3" class="ltx_tr">
<td id="A3.T3.1.3.3.1" class="ltx_td ltx_align_left ltx_border_t">characteristic</td>
<td id="A3.T3.1.3.3.2" class="ltx_td ltx_align_left ltx_border_t">0.5161</td>
<td id="A3.T3.1.3.3.3" class="ltx_td ltx_align_left ltx_border_t">0.8370</td>
<td id="A3.T3.1.3.3.4" class="ltx_td ltx_align_left ltx_border_t">0.4427</td>
<td id="A3.T3.1.3.3.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_t">0.8678</td>
</tr>
<tr id="A3.T3.1.4.4" class="ltx_tr">
<td id="A3.T3.1.4.4.1" class="ltx_td ltx_align_left">experience</td>
<td id="A3.T3.1.4.4.2" class="ltx_td ltx_align_left">0.5062</td>
<td id="A3.T3.1.4.4.3" class="ltx_td ltx_align_left">0.8357</td>
<td id="A3.T3.1.4.4.4" class="ltx_td ltx_align_left">0.5149</td>
<td id="A3.T3.1.4.4.5" class="ltx_td ltx_nopad_r ltx_align_left">0.8994</td>
</tr>
<tr id="A3.T3.1.5.5" class="ltx_tr">
<td id="A3.T3.1.5.5.1" class="ltx_td ltx_align_left">goal_plan</td>
<td id="A3.T3.1.5.5.2" class="ltx_td ltx_align_left">0.4656</td>
<td id="A3.T3.1.5.5.3" class="ltx_td ltx_align_left">0.7815</td>
<td id="A3.T3.1.5.5.4" class="ltx_td ltx_align_left">0.5024</td>
<td id="A3.T3.1.5.5.5" class="ltx_td ltx_nopad_r ltx_align_left">0.8592</td>
</tr>
<tr id="A3.T3.1.6.6" class="ltx_tr">
<td id="A3.T3.1.6.6.1" class="ltx_td ltx_align_left ltx_border_bb">routine_habit</td>
<td id="A3.T3.1.6.6.2" class="ltx_td ltx_align_left ltx_border_bb">0.6430</td>
<td id="A3.T3.1.6.6.3" class="ltx_td ltx_align_left ltx_border_bb">0.8551</td>
<td id="A3.T3.1.6.6.4" class="ltx_td ltx_align_left ltx_border_bb">0.6892</td>
<td id="A3.T3.1.6.6.5" class="ltx_td ltx_nopad_r ltx_align_left ltx_border_bb">0.8962</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Results based on different relation in the private test subset</figcaption>
</figure>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2407.15280" class="ar5iv-nav-button ar5iv-nav-button-prev">â—„</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2407.15281" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2407.15281">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2407.15281" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2407.15282" class="ar5iv-nav-button ar5iv-nav-button-next">â–º</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Aug  5 18:21:47 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "Ã—";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
