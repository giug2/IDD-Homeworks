<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2302.05076] XFL: A High Performace, Lightweighted Federated Learning Framework</title><meta property="og:description" content="This paper introduces XFL, an industrial-grade federated learning project. XFL supports training AI models collaboratively on
multiple devices, while utilizes homomorphic encryption, differential privacy, secure multi-…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="XFL: A High Performace, Lightweighted Federated Learning Framework">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="XFL: A High Performace, Lightweighted Federated Learning Framework">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2302.05076">

<!--Generated on Fri Mar  1 03:03:53 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="keywords" lang="en" content="">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line" lang="en">
<h1 class="ltx_title ltx_title_document">XFL: A High Performace, Lightweighted Federated Learning Framework</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">1<sup id="id1.1.id1" class="ltx_sup">st</sup> Hong Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id2.2.id1" class="ltx_text ltx_font_italic">    Basebit.ai     </span>
<br class="ltx_break">hong.wang@basebit.ai
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">2<sup id="id3.1.id1" class="ltx_sup">nd</sup> Yuanzhi Zhou
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id4.2.id1" class="ltx_text ltx_font_italic">    Basebit.ai     </span>
<br class="ltx_break">yuanzhi.zhou@basebit.ai
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">3<sup id="id5.1.id1" class="ltx_sup">rd</sup> Chi Zhang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id6.2.id1" class="ltx_text ltx_font_italic">    Basebit.ai     </span>
<br class="ltx_break">chi.zhang@basebit.ai
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">4<sup id="id7.1.id1" class="ltx_sup">th</sup> Chen Peng
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id8.2.id1" class="ltx_text ltx_font_italic">    Basebit.ai     </span>
<br class="ltx_break">chen.peng@basebit.ai
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">5<sup id="id9.1.id1" class="ltx_sup">th</sup> Mingxia Huang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id10.2.id1" class="ltx_text ltx_font_italic">    Basebit.ai     </span>
<br class="ltx_break">mingxia.huang@basebit.ai
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">6<sup id="id11.1.id1" class="ltx_sup">th</sup> Yi Liu
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id12.2.id1" class="ltx_text ltx_font_italic">    Basebit.ai     </span>
<br class="ltx_break">yi.liu@basebit.ai
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">7<sup id="id13.1.id1" class="ltx_sup">th</sup> Lintao Zhang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation"><span id="id14.2.id1" class="ltx_text ltx_font_italic">    Basebit.ai     </span>
<br class="ltx_break">lintao.zhang@basebit.ai
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id15.id1" class="ltx_p"><span id="id15.id1.1" class="ltx_text">This paper introduces XFL, an industrial-grade federated learning project. XFL supports training AI models collaboratively on
multiple devices, while utilizes homomorphic encryption, differential privacy, secure multi-party computation and other
security technologies ensuring no leakage of data. XFL provides an abundant algorithms library, integrating a large number
of pre-built, secure and outstanding federated learning algorithms, covering both the horizontally and vertically federated
learning scenarios. Numerical experiments have shown the prominent performace of these algorithms. XFL builds a concise
configuration interfaces with presettings for all federation algorithms, and supports the rapid deployment via docker containers.
Therefore, we believe XFL is the most user-friendly and easy-to-develop federated learning framework. XFL is open-sourced, and
both the code and documents are available at https://github.com/paritybit-ai/XFL.</span></p>
</div>
<div class="ltx_keywords">
<h6 class="ltx_title ltx_title_keywords">Index Terms: </h6>
<span id="id16.id1" class="ltx_text">
federated learning, privacy computing, encryption algorithms, distributed machine learning
</span>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">I </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introductio</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Data privacy and security has been widely awared of an important field to the wide application of artifical intelligence(AI).
Completing model training and inference under the premise of good privacy and data management is the key to expand the value of
AI technology. Since McMahan et al<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> proposed federated learning, it has been one of the most well-known solutions for
secure and privacy-preserving computing<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Federated learning attempts to utilize data from multiple
devices or silos to train AI models jointly. To make use of data distributed among multiple participants, traditional machine
learning algorithms need to be adapted to the federated scenes. Besides, to meet the requirements of privacy computing, machine
learning need to be reasonably combined with encryption methods. Therefore, a mature framework must have an algorithm library
covering comprehensive machine learning and encryption algorithms, which are exactly scarce in existing frameworks. Furthermore,
most federated learning frameworks are difficult for industrial production because they involves obscure knowledge and too many
hardware and software dependencies. The above problems have become a huge gap between the federated learning framework and a data
scientist who wants to apply it to a production.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">According to the data partition methods, there are usually two types of federated learning scenarios. The horizontal federated
learning scenario is that the datasets share the same feature space but differ in samples, while the vertical federated learning
refers to the scenario where the datasets are splitted by features. Many frameworks like TFF<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>, PySyft<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> and
Flower<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> have been proposed to deal with horizontal federated learning inspired by FedAvg<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>. There are also
some great efforts to build an all-in-one framework covering both horizontal and vertical scenarios, such as FATE<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> and
FedML<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. However, some benchmarks<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> have shown the performace of existing federated learning
algorithms and frameworks. Differences in performance and functionality prevent these frameworks from being widely used. In
addition, since most federated learning frameworks are developed based on academic research, powerful industrial-grade frameworks
are rare. For example, in the horizontal scenario, the aggregation algorithms implemented in the most of existing frameworks is
FedAvg, the original and simplest aggregation algorithm. Moreover, some frameworks can only accommodate two participants for
calculations, and cannot operate on large-scale datasets.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2302.05076/assets/architecture.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="628" height="298" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Architecture of XFL.</figcaption>
</figure>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">To build a bridge between AI and data, we introduce XFL: a high-performance, high-flexibility, high-applicability, lightweight,
open and easy-to-use federated learning framework. To meet the needs of privacy protection, one federated learning platform
must avoid direct and indirect leakage of users’ local data, and enable data scientists to train model legally and compliantly.
XFL applies secure communication protocols to ensure communication security, and supports a range of encryption algorithms:
homomorphic encryption, differential privacy, secure multi-party computation and other security technologies. Unavoidably, in
federated learning tasks, data scientists need to make trade-offs between security and efficiency, and the training process
inevitably involves communication bottleneck. XFL is optimized in these aspects and has outstanding performance in every
federation scenario. XFL can also tolerate high latency and frequent packet loss to cope with various unstable network
environments. XFL inclines to be the most user-friendly federated learning framework to help popularize privacy-preserving
techniques in machine learning. XFL is designed in an open and extensible way, which supports deployment on CPU and GPU, and can
be quickly deployed via docker. Deep learning frameworks Pytorch<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, Tensorflow<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>,
PaddlePaddle<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> and Jax<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite> are supported, and the XFL library contains all mainstream horizontal/vertical
federation algorithms to help data scientists solve training tasks in specific scenarios. Besides, data scientists can easily
develop their own algorithms or models to deal with highly customized problems, due to the lightweight and superior framework
design of XFL.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">This paper consists of the following parts: Section <a href="#S2" title="II Overview of XFL ‣ XFL: A High Performace, Lightweighted Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a> introduces the architecture of XFL and the possible roles of
participants in a training task. Section <a href="#S3" title="III Features of XFL ‣ XFL: A High Performace, Lightweighted Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a> lists the main advantages and features of XFL, and in section
<a href="#S4" title="IV Performance ‣ XFL: A High Performace, Lightweighted Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>, we designed some experiments to show the outstanding performance of XFL. Section <a href="#S5" title="V Conclusion ‣ XFL: A High Performace, Lightweighted Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">V</span></a> is the
conclusion of this paper.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">II </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Overview of XFL</span>
</h2>

<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS1.5.1.1" class="ltx_text">II-A</span> </span><span id="S2.SS1.6.2" class="ltx_text ltx_font_italic">Architecture</span>
</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.1" class="ltx_p">From a global perspective, XFL mainly consists of 4 layers. As the architecture shown in Fig. <a href="#S1.F1" title="Figure 1 ‣ I Introductio ‣ XFL: A High Performace, Lightweighted Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, from bottom to
top the 4 layers are:</p>
</div>
<section id="S2.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS1.5.1.1" class="ltx_text">II-A</span>1 </span>Support components</h4>

<div id="S2.SS1.SSS1.p1" class="ltx_para">
<p id="S2.SS1.SSS1.p1.1" class="ltx_p">This layer is the cornerstone on which we build the XFL framework. The widely used PRC framework, gRPC is used to support secure
communication, and redis, which is an in-memory high-throughput database, is used to construct a precise API for federated
learning communication process. HDFS and MySql are supported for dataset storage. Spark is used for large scale data computing
for some certain algorithms. XFL is compatible with the mainstream deep learning frameworks such as Pytorch, Tensorflow,
PaddlePaddle and Jax, meanwhile it supports hardwares such as GPU, ASIC or FPGA to accelerate the computation in federated
learning.</p>
</div>
</section>
<section id="S2.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS2.5.1.1" class="ltx_text">II-A</span>2 </span>Cryptograhic components</h4>

<div id="S2.SS1.SSS2.p1" class="ltx_para">
<p id="S2.SS1.SSS2.p1.1" class="ltx_p">Definitely, cryptography is one of the core modules in federated learning. XFL integrates several homomorphic encryption
algorithms, including Paillier<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> developed by us, and CKKS<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="" class="ltx_ref">18</a>, <a href="#bib.bib19" title="" class="ltx_ref">19</a>, <a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite>. Secure aggregation methods for
horizontal federated learning contain secure key exchange, secure presudo-random number generator and one-time-pad. Differential
privacy is implemented for some algorithms. Support for MPC is in plan.</p>
</div>
</section>
<section id="S2.SS1.SSS3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS3.5.1.1" class="ltx_text">II-A</span>3 </span>Models / Operators</h4>

<div id="S2.SS1.SSS3.p1" class="ltx_para">
<p id="S2.SS1.SSS3.p1.1" class="ltx_p">XFL presets abundant fedration algorithms, covering mainstream algorithms of supervised learning and unsupervised learning,
horizontal federation and vertical federation. Federated transfer learning is also in plan. A general horizontal federation
development framework and many secure aggregation methods such as FedAvg<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>, FedProx<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>,
Scaffold<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite> are provided. XFL supports a variety of deep learning frameworks. Data scientists can build their own
horizontal federated learning model at a very small cost without concerning about the realization of communication and encryption
methods.</p>
</div>
</section>
<section id="S2.SS1.SSS4" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection"><span id="S2.SS1.SSS4.5.1.1" class="ltx_text">II-A</span>4 </span>Management</h4>

<div id="S2.SS1.SSS4.p1" class="ltx_para">
<p id="S2.SS1.SSS4.p1.1" class="ltx_p">Support management of dataset and federated model. Provide a task schedulering, monitoring, and a module for logging.</p>
</div>
</section>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S2.SS2.5.1.1" class="ltx_text">II-B</span> </span><span id="S2.SS2.6.2" class="ltx_text ltx_font_italic">Roles</span>
</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.1" class="ltx_p">In the federated learning process, some of the existing federated learning frameworks limit the initiator to the party who owns
the label in vertical scenarios. We notice in a practical application scenario, any participant should be able to initiate
a federated learning task. A initiator could be one of the data providers who take part in the federated learning algorithm
directly, or even a party who doesn’t provide any data, but only intends to make use of the data from the other parties.
Therefore, XFL designs an independent initiator for FL tasks, which role is called scheduler as shown in Fig. <a href="#S2.F2" title="Figure 2 ‣ II-B Roles ‣ II Overview of XFL ‣ XFL: A High Performace, Lightweighted Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>. The
scheduler is responsible for delivering the algorithm configuration and notifying the participants to start a federated learning
task. Apart from the scheduler, XFL defines three types of trainers. Respectively, they are label trainer, trainer and assist
trainer. Both the label trainer and trainer can provide the features required for model training, but the label trainer must
provide the labels. Supplementarily, assist trainer only do auxiliary calculations during the training process without providing
any data. Not all roles of trainers are needed in a federated algorithm. For example, a typical horizontal federation is consist
of many label trainers and one assist trainer; in the vertical scenarios, there are many trainers and one label trainer,
meanwhile there may also be an assist trainer or not, which depends on the concrete design of the algorithm.</p>
</div>
<figure id="S2.F2" class="ltx_figure"><img src="/html/2302.05076/assets/roles.png" id="S2.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="338" height="148" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Roles in XFL.</figcaption>
</figure>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">III </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">Features of XFL</span>
</h2>

<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS1.5.1.1" class="ltx_text">III-A</span> </span><span id="S3.SS1.6.2" class="ltx_text ltx_font_italic">Easy to Use</span>
</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p id="S3.SS1.p1.1" class="ltx_p">In order to encourage users to experience the XFL framework and facilitate debugging algorithms, the standalone mode is supported
in XFL. The standalone mode allows users to execute and test all the federated learning algorithms integrated on XFL locally,
just by changing only a few network configurations. Moreover, XFL provides plenty of demos corresponding to the algorithms to
help a user get started better and faster.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p id="S3.SS1.p2.1" class="ltx_p">XFL supports task orchestration, where operators can be organized in a list to execute one by one. The local operators (as shown
in TABLE <a href="#S3.T1" title="Table I ‣ III-B Easy to Develop ‣ III Features of XFL ‣ XFL: A High Performace, Lightweighted Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>) can be connected to the federated operators to form a complete federated training process. For better
flexibility, the role of a party played in a task flow can vary in different stages, instead of being simply fixed. For instance,
as metioned in previous section, the role named scheduler can be changed to every one of the existing party involved in the
federated training task flow, or even another independent party.</p>
</div>
<div id="S3.SS1.p3" class="ltx_para">
<p id="S3.SS1.p3.1" class="ltx_p">On the other hand, XFL is designed to be quite lightweight. XFL runs well in a local self-built environment, as well as in a
container for easy deployment and migration.</p>
</div>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS2.5.1.1" class="ltx_text">III-B</span> </span><span id="S3.SS2.6.2" class="ltx_text ltx_font_italic">Easy to Develop</span>
</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p id="S3.SS2.p1.1" class="ltx_p">To develop a self-defined algorithm, one need to define a ”class” and implement a ”fit” method for each role involved in the
federation. XFL provides vivid templates and tools to help developers build their models or operators fast and smoothly, while
pay as little attention to the details of communication and encryption method as possible.</p>
</div>
<div id="S3.SS2.p2" class="ltx_para">
<p id="S3.SS2.p2.1" class="ltx_p">In horizontal federated learning, secure aggregation<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite> is a classic way to aggregate the gradients or
parameters, which is executed by an assist trainer in XFL. The templates for horizontal scenarios integrate the secure
aggregation flow internally, so developers don’t need to care about the implementation methods. These templates could help
accelerate the development, by referring to which developers can define the structure of their nerual networks and the training
process more easily. The templates also allow developers to insert custom codes or functions by the ”hook” method to enrich the
operator’s function. To help developers with different habits run a new operator faster, XFL offers templates for various deep
learning framework, including Pytorch, Tensorflow, PaddlePaddle, and Jax. In addition, XFL supports several configurable aggreation
methods such as FedAvg, FedProx and Scaffold.</p>
</div>
<div id="S3.SS2.p3" class="ltx_para">
<p id="S3.SS2.p3.1" class="ltx_p">In vertical federated learning, it is difficult to summarize a common process for most of the algorithms. Thus, developers need
to write encryption and commucation by their own. It is a good idea to refer to existing vertical operators in XFL before
developing a new operator. XFL offers cryptographic library such as paillier, key exchange protocol and some third-party tools
for developers to build a encryption block. A precise communcation module is also provided for developers to build a peer-to-peer
or broadcast channel.</p>
</div>
<figure id="S3.T1" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table I: </span>Algorithm list</figcaption>
<table id="S3.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T1.1.1.1" class="ltx_tr">
<th id="S3.T1.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Type</th>
<th id="S3.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Algorithms</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T1.1.2.1" class="ltx_tr">
<td id="S3.T1.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="6"><span id="S3.T1.1.2.1.1.1" class="ltx_text">Horizontal</span></td>
<td id="S3.T1.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">Linear Regression</td>
</tr>
<tr id="S3.T1.1.3.2" class="ltx_tr">
<td id="S3.T1.1.3.2.1" class="ltx_td ltx_align_center">Logistic Regression</td>
</tr>
<tr id="S3.T1.1.4.3" class="ltx_tr">
<td id="S3.T1.1.4.3.1" class="ltx_td ltx_align_center">ResNet</td>
</tr>
<tr id="S3.T1.1.5.4" class="ltx_tr">
<td id="S3.T1.1.5.4.1" class="ltx_td ltx_align_center">VGG</td>
</tr>
<tr id="S3.T1.1.6.5" class="ltx_tr">
<td id="S3.T1.1.6.5.1" class="ltx_td ltx_align_center">BERT</td>
</tr>
<tr id="S3.T1.1.7.6" class="ltx_tr">
<td id="S3.T1.1.7.6.1" class="ltx_td ltx_align_center">NbAFL</td>
</tr>
<tr id="S3.T1.1.8.7" class="ltx_tr">
<td id="S3.T1.1.8.7.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="7"><span id="S3.T1.1.8.7.1.1" class="ltx_text">Vertical</span></td>
<td id="S3.T1.1.8.7.2" class="ltx_td ltx_align_center ltx_border_t">Binning Woe IV</td>
</tr>
<tr id="S3.T1.1.9.8" class="ltx_tr">
<td id="S3.T1.1.9.8.1" class="ltx_td ltx_align_center">Pearson</td>
</tr>
<tr id="S3.T1.1.10.9" class="ltx_tr">
<td id="S3.T1.1.10.9.1" class="ltx_td ltx_align_center">Feature Selection</td>
</tr>
<tr id="S3.T1.1.11.10" class="ltx_tr">
<td id="S3.T1.1.11.10.1" class="ltx_td ltx_align_center">Logistic Regression<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>
</td>
</tr>
<tr id="S3.T1.1.12.11" class="ltx_tr">
<td id="S3.T1.1.12.11.1" class="ltx_td ltx_align_center">XGBoost<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>
</td>
</tr>
<tr id="S3.T1.1.13.12" class="ltx_tr">
<td id="S3.T1.1.13.12.1" class="ltx_td ltx_align_center">K-means</td>
</tr>
<tr id="S3.T1.1.14.13" class="ltx_tr">
<td id="S3.T1.1.14.13.1" class="ltx_td ltx_align_center">Sampler</td>
</tr>
<tr id="S3.T1.1.15.14" class="ltx_tr">
<td id="S3.T1.1.15.14.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="4"><span id="S3.T1.1.15.14.1.1" class="ltx_text">Local</span></td>
<td id="S3.T1.1.15.14.2" class="ltx_td ltx_align_center ltx_border_t">Normalization</td>
</tr>
<tr id="S3.T1.1.16.15" class="ltx_tr">
<td id="S3.T1.1.16.15.1" class="ltx_td ltx_align_center">Standard Scaler</td>
</tr>
<tr id="S3.T1.1.17.16" class="ltx_tr">
<td id="S3.T1.1.17.16.1" class="ltx_td ltx_align_center">Data Split</td>
</tr>
<tr id="S3.T1.1.18.17" class="ltx_tr">
<td id="S3.T1.1.18.17.1" class="ltx_td ltx_align_center ltx_border_bb">Feature Preprocess</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S3.T2" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table II: </span>Performace of XGBoost and Logistc Regression</figcaption>
<table id="S3.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T2.1.1.1" class="ltx_tr">
<th id="S3.T2.1.1.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Algorithm</th>
<th id="S3.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Num of parties</th>
<th id="S3.T2.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Num of trees/epochs</th>
<th id="S3.T2.1.1.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Total time(s)</th>
<th id="S3.T2.1.1.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Average time(s) per tree/epoch</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T2.1.2.1" class="ltx_tr">
<td id="S3.T2.1.2.1.1" class="ltx_td ltx_align_center ltx_border_t">XGBoost</td>
<td id="S3.T2.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">2</td>
<td id="S3.T2.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">103</td>
<td id="S3.T2.1.2.1.4" class="ltx_td ltx_align_center ltx_border_t">3743</td>
<td id="S3.T2.1.2.1.5" class="ltx_td ltx_align_center ltx_border_t">36.34</td>
</tr>
<tr id="S3.T2.1.3.2" class="ltx_tr">
<td id="S3.T2.1.3.2.1" class="ltx_td ltx_align_center">XGBoost</td>
<td id="S3.T2.1.3.2.2" class="ltx_td ltx_align_center">3</td>
<td id="S3.T2.1.3.2.3" class="ltx_td ltx_align_center">111</td>
<td id="S3.T2.1.3.2.4" class="ltx_td ltx_align_center">2913</td>
<td id="S3.T2.1.3.2.5" class="ltx_td ltx_align_center">26.24</td>
</tr>
<tr id="S3.T2.1.4.3" class="ltx_tr">
<td id="S3.T2.1.4.3.1" class="ltx_td ltx_align_center">Logistic Regression</td>
<td id="S3.T2.1.4.3.2" class="ltx_td ltx_align_center">2</td>
<td id="S3.T2.1.4.3.3" class="ltx_td ltx_align_center">2</td>
<td id="S3.T2.1.4.3.4" class="ltx_td ltx_align_center">1393</td>
<td id="S3.T2.1.4.3.5" class="ltx_td ltx_align_center">696.5</td>
</tr>
<tr id="S3.T2.1.5.4" class="ltx_tr">
<td id="S3.T2.1.5.4.1" class="ltx_td ltx_align_center ltx_border_bb">Logistic Regression</td>
<td id="S3.T2.1.5.4.2" class="ltx_td ltx_align_center ltx_border_bb">3</td>
<td id="S3.T2.1.5.4.3" class="ltx_td ltx_align_center ltx_border_bb">2</td>
<td id="S3.T2.1.5.4.4" class="ltx_td ltx_align_center ltx_border_bb">1399</td>
<td id="S3.T2.1.5.4.5" class="ltx_td ltx_align_center ltx_border_bb">699.5</td>
</tr>
</tbody>
</table>
</figure>
<figure id="S3.T3" class="ltx_table">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table III: </span>Experimental results under different aggregation algorithms.</figcaption>
<table id="S3.T3.4.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S3.T3.4.4.5.1" class="ltx_tr">
<th id="S3.T3.4.4.5.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Model</th>
<th id="S3.T3.4.4.5.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Algorithm</th>
<th id="S3.T3.4.4.5.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Data Distribution</th>
<th id="S3.T3.4.4.5.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Top-1 Acc</th>
<th id="S3.T3.4.4.5.1.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Num of Global Epochs(GEs) to reach high Acc</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S3.T3.4.4.6.1" class="ltx_tr">
<td id="S3.T3.4.4.6.1.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="9"><span id="S3.T3.4.4.6.1.1.1" class="ltx_text">ResNet50</span></td>
<td id="S3.T3.4.4.6.1.2" class="ltx_td ltx_align_center ltx_border_t">FedAvg</td>
<td id="S3.T3.4.4.6.1.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S3.T3.4.4.6.1.3.1" class="ltx_text">random</span></td>
<td id="S3.T3.4.4.6.1.4" class="ltx_td ltx_align_center ltx_border_t">0.93</td>
<td id="S3.T3.4.4.6.1.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.4.4.6.1.5.1" class="ltx_text ltx_font_bold">17 GEs to reach 0.90</span></td>
</tr>
<tr id="S3.T3.4.4.7.2" class="ltx_tr">
<td id="S3.T3.4.4.7.2.1" class="ltx_td ltx_align_center">FedProx</td>
<td id="S3.T3.4.4.7.2.2" class="ltx_td ltx_align_center">0.93</td>
<td id="S3.T3.4.4.7.2.3" class="ltx_td ltx_align_center">23 GEs to reach 0.90</td>
</tr>
<tr id="S3.T3.4.4.8.3" class="ltx_tr">
<td id="S3.T3.4.4.8.3.1" class="ltx_td ltx_align_center">Scaffold</td>
<td id="S3.T3.4.4.8.3.2" class="ltx_td ltx_align_center"><span id="S3.T3.4.4.8.3.2.1" class="ltx_text ltx_font_bold">0.93</span></td>
<td id="S3.T3.4.4.8.3.3" class="ltx_td ltx_align_center"><span id="S3.T3.4.4.8.3.3.1" class="ltx_text ltx_font_bold">17 GEs to reach 0.90</span></td>
</tr>
<tr id="S3.T3.1.1.1" class="ltx_tr">
<td id="S3.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_border_t">FedAvg</td>
<td id="S3.T3.1.1.1.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S3.T3.1.1.1.1.1" class="ltx_text">Dirichlet(<math id="S3.T3.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\beta=0.5" display="inline"><semantics id="S3.T3.1.1.1.1.1.m1.1a"><mrow id="S3.T3.1.1.1.1.1.m1.1.1" xref="S3.T3.1.1.1.1.1.m1.1.1.cmml"><mi id="S3.T3.1.1.1.1.1.m1.1.1.2" xref="S3.T3.1.1.1.1.1.m1.1.1.2.cmml">β</mi><mo id="S3.T3.1.1.1.1.1.m1.1.1.1" xref="S3.T3.1.1.1.1.1.m1.1.1.1.cmml">=</mo><mn id="S3.T3.1.1.1.1.1.m1.1.1.3" xref="S3.T3.1.1.1.1.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.1.1.1.1.1.m1.1b"><apply id="S3.T3.1.1.1.1.1.m1.1.1.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1"><eq id="S3.T3.1.1.1.1.1.m1.1.1.1.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.1"></eq><ci id="S3.T3.1.1.1.1.1.m1.1.1.2.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.2">𝛽</ci><cn type="float" id="S3.T3.1.1.1.1.1.m1.1.1.3.cmml" xref="S3.T3.1.1.1.1.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.1.1.1.1.1.m1.1c">\beta=0.5</annotation></semantics></math>)</span></td>
<td id="S3.T3.1.1.1.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.1.1.1.3.1" class="ltx_text ltx_font_bold">0.91</span></td>
<td id="S3.T3.1.1.1.4" class="ltx_td ltx_align_center ltx_border_t">18 GEs to reach 0.85</td>
</tr>
<tr id="S3.T3.4.4.9.4" class="ltx_tr">
<td id="S3.T3.4.4.9.4.1" class="ltx_td ltx_align_center">FedProx</td>
<td id="S3.T3.4.4.9.4.2" class="ltx_td ltx_align_center">0.91</td>
<td id="S3.T3.4.4.9.4.3" class="ltx_td ltx_align_center">19 GEs to reach 0.85</td>
</tr>
<tr id="S3.T3.4.4.10.5" class="ltx_tr">
<td id="S3.T3.4.4.10.5.1" class="ltx_td ltx_align_center">Scaffold</td>
<td id="S3.T3.4.4.10.5.2" class="ltx_td ltx_align_center">0.91</td>
<td id="S3.T3.4.4.10.5.3" class="ltx_td ltx_align_center"><span id="S3.T3.4.4.10.5.3.1" class="ltx_text ltx_font_bold">15 GEs to reach 0.85</span></td>
</tr>
<tr id="S3.T3.2.2.2" class="ltx_tr">
<td id="S3.T3.2.2.2.2" class="ltx_td ltx_align_center ltx_border_t">FedAvg</td>
<td id="S3.T3.2.2.2.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S3.T3.2.2.2.1.1" class="ltx_text">Dirichlet(<math id="S3.T3.2.2.2.1.1.m1.1" class="ltx_Math" alttext="\beta=0.1" display="inline"><semantics id="S3.T3.2.2.2.1.1.m1.1a"><mrow id="S3.T3.2.2.2.1.1.m1.1.1" xref="S3.T3.2.2.2.1.1.m1.1.1.cmml"><mi id="S3.T3.2.2.2.1.1.m1.1.1.2" xref="S3.T3.2.2.2.1.1.m1.1.1.2.cmml">β</mi><mo id="S3.T3.2.2.2.1.1.m1.1.1.1" xref="S3.T3.2.2.2.1.1.m1.1.1.1.cmml">=</mo><mn id="S3.T3.2.2.2.1.1.m1.1.1.3" xref="S3.T3.2.2.2.1.1.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.2.2.2.1.1.m1.1b"><apply id="S3.T3.2.2.2.1.1.m1.1.1.cmml" xref="S3.T3.2.2.2.1.1.m1.1.1"><eq id="S3.T3.2.2.2.1.1.m1.1.1.1.cmml" xref="S3.T3.2.2.2.1.1.m1.1.1.1"></eq><ci id="S3.T3.2.2.2.1.1.m1.1.1.2.cmml" xref="S3.T3.2.2.2.1.1.m1.1.1.2">𝛽</ci><cn type="float" id="S3.T3.2.2.2.1.1.m1.1.1.3.cmml" xref="S3.T3.2.2.2.1.1.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.2.2.2.1.1.m1.1c">\beta=0.1</annotation></semantics></math>)</span></td>
<td id="S3.T3.2.2.2.3" class="ltx_td ltx_align_center ltx_border_t">0.88</td>
<td id="S3.T3.2.2.2.4" class="ltx_td ltx_align_center ltx_border_t">33 GEs to reach 0.80</td>
</tr>
<tr id="S3.T3.4.4.11.6" class="ltx_tr">
<td id="S3.T3.4.4.11.6.1" class="ltx_td ltx_align_center">FedProx</td>
<td id="S3.T3.4.4.11.6.2" class="ltx_td ltx_align_center">0.88</td>
<td id="S3.T3.4.4.11.6.3" class="ltx_td ltx_align_center">24 GEs to reach 0.80</td>
</tr>
<tr id="S3.T3.4.4.12.7" class="ltx_tr">
<td id="S3.T3.4.4.12.7.1" class="ltx_td ltx_align_center">Scaffold</td>
<td id="S3.T3.4.4.12.7.2" class="ltx_td ltx_align_center"><span id="S3.T3.4.4.12.7.2.1" class="ltx_text ltx_font_bold">0.88</span></td>
<td id="S3.T3.4.4.12.7.3" class="ltx_td ltx_align_center"><span id="S3.T3.4.4.12.7.3.1" class="ltx_text ltx_font_bold">13 GEs to reach 0.80</span></td>
</tr>
<tr id="S3.T3.4.4.13.8" class="ltx_tr">
<td id="S3.T3.4.4.13.8.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="9"><span id="S3.T3.4.4.13.8.1.1" class="ltx_text">VGG11</span></td>
<td id="S3.T3.4.4.13.8.2" class="ltx_td ltx_align_center ltx_border_t">FedAvg</td>
<td id="S3.T3.4.4.13.8.3" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S3.T3.4.4.13.8.3.1" class="ltx_text">random</span></td>
<td id="S3.T3.4.4.13.8.4" class="ltx_td ltx_align_center ltx_border_t">0.92</td>
<td id="S3.T3.4.4.13.8.5" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.4.4.13.8.5.1" class="ltx_text ltx_font_bold">20 GEs to reach 0.90</span></td>
</tr>
<tr id="S3.T3.4.4.14.9" class="ltx_tr">
<td id="S3.T3.4.4.14.9.1" class="ltx_td ltx_align_center">FedProx</td>
<td id="S3.T3.4.4.14.9.2" class="ltx_td ltx_align_center">0.91</td>
<td id="S3.T3.4.4.14.9.3" class="ltx_td ltx_align_center">24 GEs to reach 0.90</td>
</tr>
<tr id="S3.T3.4.4.15.10" class="ltx_tr">
<td id="S3.T3.4.4.15.10.1" class="ltx_td ltx_align_center">Scaffold</td>
<td id="S3.T3.4.4.15.10.2" class="ltx_td ltx_align_center"><span id="S3.T3.4.4.15.10.2.1" class="ltx_text ltx_font_bold">0.92</span></td>
<td id="S3.T3.4.4.15.10.3" class="ltx_td ltx_align_center"><span id="S3.T3.4.4.15.10.3.1" class="ltx_text ltx_font_bold">20 GEs to reach 0.90</span></td>
</tr>
<tr id="S3.T3.3.3.3" class="ltx_tr">
<td id="S3.T3.3.3.3.2" class="ltx_td ltx_align_center ltx_border_t">FedAvg</td>
<td id="S3.T3.3.3.3.1" class="ltx_td ltx_align_center ltx_border_t" rowspan="3"><span id="S3.T3.3.3.3.1.1" class="ltx_text">Dirichlet(<math id="S3.T3.3.3.3.1.1.m1.1" class="ltx_Math" alttext="\beta=0.5" display="inline"><semantics id="S3.T3.3.3.3.1.1.m1.1a"><mrow id="S3.T3.3.3.3.1.1.m1.1.1" xref="S3.T3.3.3.3.1.1.m1.1.1.cmml"><mi id="S3.T3.3.3.3.1.1.m1.1.1.2" xref="S3.T3.3.3.3.1.1.m1.1.1.2.cmml">β</mi><mo id="S3.T3.3.3.3.1.1.m1.1.1.1" xref="S3.T3.3.3.3.1.1.m1.1.1.1.cmml">=</mo><mn id="S3.T3.3.3.3.1.1.m1.1.1.3" xref="S3.T3.3.3.3.1.1.m1.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.3.3.3.1.1.m1.1b"><apply id="S3.T3.3.3.3.1.1.m1.1.1.cmml" xref="S3.T3.3.3.3.1.1.m1.1.1"><eq id="S3.T3.3.3.3.1.1.m1.1.1.1.cmml" xref="S3.T3.3.3.3.1.1.m1.1.1.1"></eq><ci id="S3.T3.3.3.3.1.1.m1.1.1.2.cmml" xref="S3.T3.3.3.3.1.1.m1.1.1.2">𝛽</ci><cn type="float" id="S3.T3.3.3.3.1.1.m1.1.1.3.cmml" xref="S3.T3.3.3.3.1.1.m1.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.3.3.3.1.1.m1.1c">\beta=0.5</annotation></semantics></math>)</span></td>
<td id="S3.T3.3.3.3.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.3.3.3.3.1" class="ltx_text ltx_font_bold">0.90</span></td>
<td id="S3.T3.3.3.3.4" class="ltx_td ltx_align_center ltx_border_t">17 GEs to reach 0.85</td>
</tr>
<tr id="S3.T3.4.4.16.11" class="ltx_tr">
<td id="S3.T3.4.4.16.11.1" class="ltx_td ltx_align_center">FedProx</td>
<td id="S3.T3.4.4.16.11.2" class="ltx_td ltx_align_center">0.90</td>
<td id="S3.T3.4.4.16.11.3" class="ltx_td ltx_align_center">17 GEs to reach 0.85</td>
</tr>
<tr id="S3.T3.4.4.17.12" class="ltx_tr">
<td id="S3.T3.4.4.17.12.1" class="ltx_td ltx_align_center">Scaffold</td>
<td id="S3.T3.4.4.17.12.2" class="ltx_td ltx_align_center">0.90</td>
<td id="S3.T3.4.4.17.12.3" class="ltx_td ltx_align_center"><span id="S3.T3.4.4.17.12.3.1" class="ltx_text ltx_font_bold">12 GEs to reach 0.85</span></td>
</tr>
<tr id="S3.T3.4.4.4" class="ltx_tr">
<td id="S3.T3.4.4.4.2" class="ltx_td ltx_align_center ltx_border_t">FedAvg</td>
<td id="S3.T3.4.4.4.1" class="ltx_td ltx_align_center ltx_border_bb ltx_border_t" rowspan="3"><span id="S3.T3.4.4.4.1.1" class="ltx_text">Dirichlet(<math id="S3.T3.4.4.4.1.1.m1.1" class="ltx_Math" alttext="\beta=0.1" display="inline"><semantics id="S3.T3.4.4.4.1.1.m1.1a"><mrow id="S3.T3.4.4.4.1.1.m1.1.1" xref="S3.T3.4.4.4.1.1.m1.1.1.cmml"><mi id="S3.T3.4.4.4.1.1.m1.1.1.2" xref="S3.T3.4.4.4.1.1.m1.1.1.2.cmml">β</mi><mo id="S3.T3.4.4.4.1.1.m1.1.1.1" xref="S3.T3.4.4.4.1.1.m1.1.1.1.cmml">=</mo><mn id="S3.T3.4.4.4.1.1.m1.1.1.3" xref="S3.T3.4.4.4.1.1.m1.1.1.3.cmml">0.1</mn></mrow><annotation-xml encoding="MathML-Content" id="S3.T3.4.4.4.1.1.m1.1b"><apply id="S3.T3.4.4.4.1.1.m1.1.1.cmml" xref="S3.T3.4.4.4.1.1.m1.1.1"><eq id="S3.T3.4.4.4.1.1.m1.1.1.1.cmml" xref="S3.T3.4.4.4.1.1.m1.1.1.1"></eq><ci id="S3.T3.4.4.4.1.1.m1.1.1.2.cmml" xref="S3.T3.4.4.4.1.1.m1.1.1.2">𝛽</ci><cn type="float" id="S3.T3.4.4.4.1.1.m1.1.1.3.cmml" xref="S3.T3.4.4.4.1.1.m1.1.1.3">0.1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.T3.4.4.4.1.1.m1.1c">\beta=0.1</annotation></semantics></math>)</span></td>
<td id="S3.T3.4.4.4.3" class="ltx_td ltx_align_center ltx_border_t"><span id="S3.T3.4.4.4.3.1" class="ltx_text ltx_font_bold">0.88</span></td>
<td id="S3.T3.4.4.4.4" class="ltx_td ltx_align_center ltx_border_t">24 GEs to reach 0.80</td>
</tr>
<tr id="S3.T3.4.4.18.13" class="ltx_tr">
<td id="S3.T3.4.4.18.13.1" class="ltx_td ltx_align_center">FedProx</td>
<td id="S3.T3.4.4.18.13.2" class="ltx_td ltx_align_center">0.87</td>
<td id="S3.T3.4.4.18.13.3" class="ltx_td ltx_align_center">20 GEs to reach 0.80</td>
</tr>
<tr id="S3.T3.4.4.19.14" class="ltx_tr">
<td id="S3.T3.4.4.19.14.1" class="ltx_td ltx_align_center ltx_border_bb">Scaffold</td>
<td id="S3.T3.4.4.19.14.2" class="ltx_td ltx_align_center ltx_border_bb">0.87</td>
<td id="S3.T3.4.4.19.14.3" class="ltx_td ltx_align_center ltx_border_bb"><span id="S3.T3.4.4.19.14.3.1" class="ltx_text ltx_font_bold">11 GEs to reach 0.80</span></td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS3.5.1.1" class="ltx_text">III-C</span> </span><span id="S3.SS3.6.2" class="ltx_text ltx_font_italic">Privacy and Security</span>
</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p id="S3.SS3.p1.1" class="ltx_p">Privacy protection is the major concern of federated learning. But in most cases, it is neither practicable nor necessary to
protect the whole training process, which means a participant knows nothing except the output. Too strict privacy protection
usually results in low computing efficiency. XFL balances the security and efficiency in the distributed learning process,
by strictly protecting the input data and encrypting the intermediate data to ensure the sensitive privacy of every
participant cannot be accessed or infered by other participants. Besides, individual gradients are usually not allowed to be
exposed to prevent other parties or attackers from extrapolating the original data, no matter the rows or ids.</p>
</div>
<div id="S3.SS3.p2" class="ltx_para">
<p id="S3.SS3.p2.1" class="ltx_p">The federated algorithms in XFL is designed to meet the privacy requirements above. In terms of technology for privacy
protection, secure aggregation for horizontal federation consists of secure key exchange<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite>, secure presudo random
number generator<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> and one-time pad. Homomorphic encryption is supported for some vertical algorithms, MPC is also
in plan to support specific algorithms. All algorithms in XFL are based on the assumption that all parties are semi-honest, which
means they will excute the training process exactly but are curious to deduce some extra imformation. Collusion between parties
is not allowed for most of the algorithms.</p>
</div>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS4.5.1.1" class="ltx_text">III-D</span> </span><span id="S3.SS4.6.2" class="ltx_text ltx_font_italic">High Performace</span>
</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p id="S3.SS4.p1.1" class="ltx_p">Encryption algorithms are usually the performance bottleneck of federated learning. XFL adopts a number of self-developed methods
to improve the performance of cryptographic algorithms. For example, encryption by a security key in Paillier is much faster than
encryption by a public key. A DJN<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite> method for key generation and encryption has been utilized to further accelerate the
speed of the encryption. Fully homorphic encryption algorithm CKKS is applied to substitute Paillier for better performace,
because CKKS is more suitable for batch encryption. Moreover, a packing method is used for vertical XGBoost by packing two
plaintext to one to reduce nearly half of the calculation related to homomorphic encryption.</p>
</div>
<div id="S3.SS4.p2" class="ltx_para">
<p id="S3.SS4.p2.1" class="ltx_p">On the other hand, we have also optimized the performance of computing and communication from the perspective of engineering
design. In Section <a href="#S4" title="IV Performance ‣ XFL: A High Performace, Lightweighted Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">IV</span></a>, there are several experiments showing the performance of XFL.</p>
</div>
</section>
<section id="S3.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection"><span id="S3.SS5.5.1.1" class="ltx_text">III-E</span> </span><span id="S3.SS5.6.2" class="ltx_text ltx_font_italic">Supported Operators</span>
</h3>

<div id="S3.SS5.p1" class="ltx_para">
<p id="S3.SS5.p1.1" class="ltx_p">We release many pre-built horizontal models such as VGG<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite>, ResNet<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite> and BERT<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite>. NbAFL is an
experimental horizontal algorithm deploying differential privacy technology. XGBoost, logistic regression, K-means and other
algorithms are supported in vertical scenario. XFL supports not only conventional horizontal and vertical federated learning
algorithms, but also provides some local algorithms to help building a federation task. Non-federated algorithms such as
normalization, standard scalar are provided for local usage. The supported algorithms are listed in TABLE <a href="#S3.T1" title="Table I ‣ III-B Easy to Develop ‣ III Features of XFL ‣ XFL: A High Performace, Lightweighted Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">I</span></a>.
More algorithms will be released in the future.</p>
</div>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">IV </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">Performance</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">We demonstrate the efficiency of XFL by a series of experiments. In this part, we test the performance of vertical logistic
regression and XGBoost operators. The experimental dataset is Epsilon<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib30" title="" class="ltx_ref">30</a>]</cite>, where the training dataset contains 400000
samples and the validation dataset contains 100000 samples. The dataset consists of 2000 columns of features and 1 column of
label. Randomly, we choose 500 columns from the features and equally split them into 2 or 3 stacks, corresponding to 2 or 3
parties respectively. For each party, the basic hardware contains a 16-cores 2.3GHz CPU and a 256GB memory. The network
bandwidth is 1000Mb/s. We set a goal KS value on validation dataset for each operators, and record the total running time. The
goal KS value is 0.586 for XGBoost experiments, and 0.653 for logistic regression experiments. The main hyper-parameters in
XGBoost experiments are described as below: the tree depth equals to 2; the top rate of goss is 0.01; the other rate of goss is
0.02; the encryption method is Paillier and the key bit-length is 2048. In logistic regression experiments, the batch size is
2048 and the encryption method is CKKS. The results have been exhibited in TABLE <a href="#S3.T2" title="Table II ‣ III-B Easy to Develop ‣ III Features of XFL ‣ XFL: A High Performace, Lightweighted Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">II</span></a>. The performance of both
the algorithms is outstanding in all existing frameworks.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">In vertical federations, there is usually no loss of accuracy. However, this is not the case in horizontal federations. A number
of studies have pointed out that the accuracy of joint modeling is lower than that of local modeling when the data is non-IID
(non-independent-and-identically distributed)<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib2" title="" class="ltx_ref">2</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite>. Some experimentss<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="" class="ltx_ref">32</a>]</cite> have shown
different algorithms can improve the accuracy of horizontal federation with non-IID data, and the algorithms with excellent
performance has been implemented on XFL, such as FedProx and Scaffold. In this part, we conduct some experiments to show that
these algorithms can significantly improve the training efficiency and reduce the number of required global epochs.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.2" class="ltx_p">The typical horizontal federation learning in XFL mainly includes three steps: First, the server broadcast the global model to
all participants. Second, each participants conducts model training on the basis of local data. Finally, The server collects the
local models and aggregates them into a global model. Currently, XFL provides three aggregation methods: FedAvg, FedProx and
Scaffold. FedAvg is widely used because of its simplicity and efficiency, however, when the data in different participants is
non-IID, FedProx and Scaffold may achieve better results. To compare the above three aggregation algorithms when the data is
non-IID, we conduct experiments by utilizing the XFL framework. The experimental dataset is CIFAR-10<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="" class="ltx_ref">31</a>]</cite>, and the
models are ResNet50 and VGG11. There are two participants in each experiment. Each experiment contains 60 global epochs, and each
global epoch contains 5 local epochs. The hyper-parameter of FedProx is fixed to <math id="S4.p3.1.m1.1" class="ltx_Math" alttext="\mu=0.005" display="inline"><semantics id="S4.p3.1.m1.1a"><mrow id="S4.p3.1.m1.1.1" xref="S4.p3.1.m1.1.1.cmml"><mi id="S4.p3.1.m1.1.1.2" xref="S4.p3.1.m1.1.1.2.cmml">μ</mi><mo id="S4.p3.1.m1.1.1.1" xref="S4.p3.1.m1.1.1.1.cmml">=</mo><mn id="S4.p3.1.m1.1.1.3" xref="S4.p3.1.m1.1.1.3.cmml">0.005</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.1b"><apply id="S4.p3.1.m1.1.1.cmml" xref="S4.p3.1.m1.1.1"><eq id="S4.p3.1.m1.1.1.1.cmml" xref="S4.p3.1.m1.1.1.1"></eq><ci id="S4.p3.1.m1.1.1.2.cmml" xref="S4.p3.1.m1.1.1.2">𝜇</ci><cn type="float" id="S4.p3.1.m1.1.1.3.cmml" xref="S4.p3.1.m1.1.1.3">0.005</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.1c">\mu=0.005</annotation></semantics></math>. To achieve non-IID data, the
experiments adopt Dirichlet distribution method to split data. The smaller of <math id="S4.p3.2.m2.1" class="ltx_Math" alttext="\beta" display="inline"><semantics id="S4.p3.2.m2.1a"><mi id="S4.p3.2.m2.1.1" xref="S4.p3.2.m2.1.1.cmml">β</mi><annotation-xml encoding="MathML-Content" id="S4.p3.2.m2.1b"><ci id="S4.p3.2.m2.1.1.cmml" xref="S4.p3.2.m2.1.1">𝛽</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.2.m2.1c">\beta</annotation></semantics></math> means less coincidence of labels on each
side. The results are shown in TABLE <a href="#S3.T3" title="Table III ‣ III-B Easy to Develop ‣ III Features of XFL ‣ XFL: A High Performace, Lightweighted Federated Learning Framework" class="ltx_ref"><span class="ltx_text ltx_ref_tag">III</span></a>, where the bold font denotes the best performance. FedAvg always
performs well when the data is random distributed, i.e. the data is IID. However, its convergence rate becomes very slow when
the data is non-IID. In XFL, FedProx and Scaffold can be easily configured to achieve faster convergence. Especially, in this
group of experiments, Scaffold costs less than half of the global epochs of FedAvg to achieve the accuracy of 0.80.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">V </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">With the ever increasing legislation on privacy protection and the ever larger need for data access, the demand for
privacy-preserving computing is growing stronger. By combining decentralized machine learning with cryptography, federated
learning has become one of the hottest privacy computing technologies. Nevertheless, the wide adoption of federated learning is
stumped by technical and practical difficulties. XFL tries to solve this problem by providing a full-fledged, industry-grade,
easy-to-use and easy-to-develop federated learning library. XFL implements most of the popular federated learning
algorithms for both horizontal and vertical scenarios. It achieves high performance by using of mature architecture ready for
production. Also, to ease the development of new algorithms, the encryption, communication, and aggregation components of
federated learning has been made as plug-in-able as possible. With these design choices, XFL can be used both for experienced
machine learning engineers and novices who just want make their first federated learning application.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"> B. McMahan, E. Moore, D. Ramage et al. “Communication-Efficient Learning of Deep Networks from Decentralized Data.” In Proceedings of AISTATS, pp. 1273-1282, 2017.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"> P. Kairouz., H. B. McMahan, B. Avent et al. “Advances and open problems in federated learning.” arXiv preprint arXiv:1912.04977, 2019.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"> Q. Yang, Y. Liu, T. J. Chen et al. “Federated machine learning: Concept and applications.” CoRR, abs/1902.04885, 2019.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"> https://github.com/tensorflow/federated.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"> T. Ryffel, A. Trask, M. Dahl, et al. “A generic framework for privacy preserving deep learning.” arXiv preprint arXiv:1811.04017, 2018.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"> D. J. Beutel, T. Topal, A. Mathur, et al. “Flower: A friendly federated learning research framework.” arXiv preprint arXiv:2007.14390, 2020.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"> Y. Liu, T. Fan, T. Chen, et al. “FATE: An industrial grade platform for collaborative learning with data protection.” Journal of Machine Learning Research, 22(226):1-6, 2021.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"> C. He, S. Li, J. So, et al. “FedML: A research library and benchmark for federated machine learning.” arXiv preprint arXiv:2007.13518, 2020.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"> X. Liu, T. Shi, C. Xie, et al. “UniFed: A Benchmark for Federated Learning Frameworks.” arXiv preprint arXiv:2207.10308, 2022

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"> S. Caldas, S. M. K. Duddu, P. Wu, et al. “Leaf: A benchmark for federated settings.” arXiv preprint arXiv:1812.01097, 2018.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"> https://pytorch.org.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"> https://www.tensorflow.org.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"> https://www.paddlepaddle.org.cn.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"> https://github.com/google/jax.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"> K. Cheng, T. Fan, Y. Jin, et al. “Secureboost: A lossless federated learning framework.” IEEE Intelligent Systems, 2021, 36(6): 87-98.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"> S. Yang, B. Ren, X. Zhou, et al. “Parallel distributed logistic regression for vertical federated learning without third-party coordinator.” arXiv preprint arXiv:1911.09824, 2019.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"> P. Paillier. “Public-key cryptosystems based on composite degree residuosity classes.” International conference on the theory and applications of cryptographic techniques. Springer, Berlin, Heidelberg, 1999: 223-238.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"> J. H. Cheon, A. Kim, M. Kim, et al. “Homomorphic encryption for arithmetic of approximate numbers.” International conference on the theory and application of cryptology and information security. Springer, Cham, 2017: 409-437.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"> https://github.com/OpenMined/TenSEAL.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"> https://github.com/microsoft/SEAL.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"> I. Damgård, M. Jurik, J. B. Nielsen. “A generalization of Paillier’s public-key system with applications to electronic voting.” International Journal of Information Security, 2010, 9(6): 371-385.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"> D. Gillmor. “Negotiated finite field Diffie-Hellman ephemeral parameters for transport layer security (TLS).” 2016.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"> E. Barker, J. Kelsey. “NIST special publication 800-90a recommendation for random number generation using deterministic random bit generators.” 2012.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"> T. Li, A. K. Sahu, M. Zaheer et al. “Federated optimization in heterogeneous networks.” In MLSys, 2020.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"> S. P. Karimireddy, S. Kale, M. Mohri et al. “SCAFFOLD: Stochastic controlled averaging for on-device federated learning.” In Proceedings of the 37th International Conference on Machine Learning. PMLR, 2020.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"> K. Bonawitz, V. Ivanov, B. Kreuter et al. “Practical secure aggregation for privacy-preserving machine learning.” In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. 2017: 1175-1191.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"> K. Simonyan, A. Zisserman. “Very deep convolutional networks for large-scale image recognition.” arXiv preprint arXiv:1409.1556, 2014.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"> K. He, X. Zhang, S. Ren et al. “Deep residual learning for image recognition.” In Proceedings of the IEEE conference on computer vision and pattern recognition. 2016: 770-778.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"> J. Devlin, M. W. Chang, K. Lee et al. “Bert: Pre-training of deep bidirectional transformers for language understanding.” arXiv preprint arXiv:1810.04805, 2018.

</span>
</li>
<li id="bib.bib30" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"> https://catboost.ai/en/docs/concepts/python-reference_datasets_epsilon.

</span>
</li>
<li id="bib.bib31" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"> https://www.cs.toronto.edu/ kriz/cifar.html.

</span>
</li>
<li id="bib.bib32" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"> Q. Li, Y. Diao, Q. Chen et al. “Federated learning on non-iid data silos: An experimental study.” 2022 IEEE 38th International Conference on Data Engineering (ICDE). IEEE, 2022: 965-978.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2302.05075" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2302.05076" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2302.05076">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2302.05076" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2302.05077" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar  1 03:03:53 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
