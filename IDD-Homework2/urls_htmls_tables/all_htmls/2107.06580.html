<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2107.06580] iFedAvg – Interpretable Data-Interoperability for Federated Learning</title><meta property="og:description" content="Recently, the ever-growing demand for privacy-oriented machine learning has motivated researchers to develop federated and decentralized learning techniques, allowing individual clients to train models collaboratively …">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="iFedAvg – Interpretable Data-Interoperability for Federated Learning">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="iFedAvg – Interpretable Data-Interoperability for Federated Learning">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2107.06580">

<!--Generated on Tue Mar 19 13:19:24 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">iFedAvg – Interpretable Data-Interoperability
<br class="ltx_break">for Federated Learning</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
David Roschewitz 
<br class="ltx_break">ETH Zürich
<br class="ltx_break">Switzerland 
<br class="ltx_break"><span id="id1.1.id1" class="ltx_text ltx_font_typewriter">david.roschewitz@inf.ethz.ch</span> 
<br class="ltx_break">&amp;Mary-Anne Hartley 
<br class="ltx_break">EPFL, Lausanne 
<br class="ltx_break">Switzerland 
<br class="ltx_break"><span id="id2.2.id2" class="ltx_text ltx_font_typewriter">mary-anne.hartley@epfl.ch</span> 
<br class="ltx_break">Luca Corinzia 
<br class="ltx_break">ETH Zürich 
<br class="ltx_break">Switzerland 
<br class="ltx_break"><span id="id3.3.id3" class="ltx_text ltx_font_typewriter">luca.corinzia@inf.ethz.ch</span> 
<br class="ltx_break">&amp;Martin Jaggi 
<br class="ltx_break">EPFL, Lausanne 
<br class="ltx_break">Switzerland 
<br class="ltx_break"><span id="id4.4.id4" class="ltx_text ltx_font_typewriter">martin.jaggi@epfl.ch</span> 
<br class="ltx_break">
</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id5.id1" class="ltx_p">Recently, the ever-growing demand for privacy-oriented machine learning has motivated researchers to develop federated and decentralized learning techniques, allowing individual clients to train models collaboratively without disclosing their private datasets. However, widespread adoption has been limited in domains relying on high levels of user trust, where assessment of data compatibility is essential. In this work, we define and address low interoperability induced by underlying client data inconsistencies in federated learning for tabular data. The proposed method, <span id="id5.id1.1" class="ltx_text ltx_font_typewriter">iFedAvg</span>, builds on federated averaging adding local element-wise affine layers to allow for a personalized and granular understanding of the collaborative learning process. Thus, enabling the detection of outlier datasets in the federation and also learning the compensation for local data distribution shifts without sharing any original data. We evaluate <span id="id5.id1.2" class="ltx_text ltx_font_typewriter">iFedAvg</span> using several public benchmarks and a previously unstudied collection of real-world datasets from the 2014 - 2016 West African Ebola epidemic, jointly forming the largest such dataset in the world. In all evaluations, <span id="id5.id1.3" class="ltx_text ltx_font_typewriter">iFedAvg</span> achieves competitive average performance with negligible overhead. It additionally shows substantial improvement on outlier clients, highlighting increased robustness to individual dataset shifts. Most importantly, our method provides valuable client-specific insights at a fine-grained level to guide interoperable federated learning.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Institutions with sensitive data, such as hospitals, cannot typically share patient data due to privacy regulations. However, solely relying on in-house data can lead to models with poor generalization due to the limited, and potentially biased, input data. Federated learning (FL) partially addresses this issue by enabling various clients to contribute and benefit from a collaborative learning process without revealing their underlying data. In practice though, individual clients can benefit from the collaborative training only if their data is compatible with that of other participating institutions. This can lead to situations where the client data is not interoperable, and where joining the federated learning process yields no benefits or even has a detrimental effect. Furthermore, a lack of transparency of the federated learning process impairs the trust of the federation, limiting its adoption by more institutions.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">Thus, there is a clear need to address the interoperability of current federated learning approaches. Such methods should not only detect potential data shifts and automatically correct them but, more importantly, they should also be easily interpretable for stakeholders to visually assess the suitability of the collaboration.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">We study these challenges and propose a novel method for a setting inspired by a real-world medical dataset collected during the 2014-16 Ebola epidemic. The data was collected at different treatment centres, by various organizations in multiple countries generating an inherently heterogeneous dataset. In practice, no single agent would have access to the data of other agents, necessitating a federated learning approach. Further details are outlined in Section <a href="#S3" title="3 Federated Ebola dataset ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Our method is tailored to handle tabular datasets which are abundant in practice and for which feature-shifts are intuitive to understand.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">The fundamental approach that we consider is to learn a personalized data transformation for each client during the federated training procedure. This transformation can be viewed as a local re-normalization or embedding that makes clients more interoperable without ever exchanging data. Through deliberate design, our method attains unparalleled transparency, allowing fine-grained interpretation of the learned shifts for each feature of each client relative to their peers in the federation. This ability to compare data shifts across clients means that interoperability can be easily assessed.
For example, clients collecting data in pediatric, adult or geriatric medicine would not only have the "age" feature highlighted as responsible for their "outlier" status, but the directionality and relative magnitude of their outlier shifts can also be assessed.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Our main contributions are the following:</p>
<ol id="S1.I1" class="ltx_enumerate">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">1.</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We propose a novel framework, <span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> which detects and corrects interoperability issues in federated learning on tabular datasets.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">2.</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We present visualization tools for practitioners to assess the feature-wise compatibility to collaborative learning.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">3.</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">Finally, we demonstrate the potential of the proposed method on a previously unstudied collection of data from the West African Ebola epidemic and multiple public benchmarks.</p>
</div>
</li>
</ol>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p"><span id="S1.p6.1.1" class="ltx_text ltx_font_bold">Outlook</span>  In Section <a href="#S2" title="2 Interpretable and data-interoperable federated averaging ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> we outline our method, and we present a detailed introduction to the Ebola dataset in Section <a href="#S3" title="3 Federated Ebola dataset ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. Subsequently we present the experimental setup and results in Sections <a href="#S4" title="4 Experimental design ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> and <a href="#S5" title="5 Results ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>. We provide a discussion and conclusions in the last section.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p"><span id="S1.p7.1.1" class="ltx_text ltx_font_bold">Related Work</span>  The concept of federated learning was formulated by <cite class="ltx_cite ltx_citemacro_citet">McMahan et al. [<a href="#bib.bib20" title="" class="ltx_ref">20</a>]</cite> as “<em id="S1.p7.1.2" class="ltx_emph ltx_font_italic">collaborative machine learning without centralized training data</em>” alongside <span id="S1.p7.1.3" class="ltx_text ltx_font_italic">Federated Averaging</span> (<span id="S1.p7.1.4" class="ltx_text ltx_font_typewriter">FedAvg</span>). The method proved efficient in learning a single, global, gradient-based model from many clients’ data in a private fashion. However, this approach is impaired in the realistic setting with statistically heterogeneous client data <cite class="ltx_cite ltx_citemacro_citet">Zhao et al. [<a href="#bib.bib28" title="" class="ltx_ref">28</a>]</cite>. In order to address some of these shortcomings, multiple extensions have been proposed. For instance, <span id="S1.p7.1.5" class="ltx_text ltx_font_typewriter">FedProx</span> by <cite class="ltx_cite ltx_citemacro_citet">Li et al. [<a href="#bib.bib19" title="" class="ltx_ref">19</a>]</cite> allows for inexact local computations and regularizes client drift using an additive proximal term in the loss function. <cite class="ltx_cite ltx_citemacro_citet">Karimireddy et al. [<a href="#bib.bib17" title="" class="ltx_ref">17</a>]</cite> introduced <span id="S1.p7.1.6" class="ltx_text ltx_font_typewriter">SCAFFOLD</span>, which explicitly uses control variates to improve convergence.
From an optimizer perspective, SGD with server-side momentum has proven effective <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>, a result further investigated by <cite class="ltx_cite ltx_citemacro_citet">Reddi et al. [<a href="#bib.bib22" title="" class="ltx_ref">22</a>]</cite> that proposes the use of adaptive optimizers for federated learning such as <span id="S1.p7.1.7" class="ltx_text ltx_font_typewriter">FedAdam</span>. For a more comprehensive overview, we refer to the excellent review of federated learning by <cite class="ltx_cite ltx_citemacro_citet">Kairouz et al. [<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.</p>
</div>
<div id="S1.p8" class="ltx_para">
<p id="S1.p8.1" class="ltx_p">Learning a client-specific <span id="S1.p8.1.1" class="ltx_text ltx_font_italic">data transformation</span>, as we propose here, can be seen as a special case of training personalized models for each client as opposed to a single global model. In the area of personalized federated learning (PFL), various approaches have been identified. A relevant selection includes transfer learning, multi-task learning, meta-learning and personalization layers. Transfer and meta-learning focus on tuning an initial model, usually the global federated model, to each client. Techniques here include fine-tuning <cite class="ltx_cite ltx_citemacro_citet">Yu et al. [<a href="#bib.bib27" title="" class="ltx_ref">27</a>]</cite> and Model-Agnostic-Meta-Learning (MAML) <cite class="ltx_cite ltx_citemacro_citet">Jiang et al. [<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. <cite class="ltx_cite ltx_citemacro_citet">Fallah et al. [<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite> devise <span id="S1.p8.1.2" class="ltx_text ltx_font_typewriter">Per-FedAvg</span>, leveraging a second-order derivative to account for personalization throughout the process. Multi-task learning approaches focus on jointly learning multiple models for a variety of tasks with different levels of similarity. This can be applied to PFL, as in MOCHA <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib24" title="" class="ltx_ref">24</a>]</cite>, or using a Bayesian framework <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. Furthermore, personalization can be achieved by client-specific layers, as proposed by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>, who show that locally trained output layers are effective for image classification. Furthermore, <cite class="ltx_cite ltx_citemacro_citet">Deng et al. [<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> propose a method, <span id="S1.p8.1.3" class="ltx_text ltx_font_typewriter">APFL</span>, which actively optimizes a global and a local model, and blends the two models concurrently. The summary overview provided by <cite class="ltx_cite ltx_citemacro_citet">Kulkarni et al. [<a href="#bib.bib18" title="" class="ltx_ref">18</a>]</cite> includes additional approaches for PFL.</p>
</div>
<div id="S1.p9" class="ltx_para">
<p id="S1.p9.1" class="ltx_p">Understanding <span id="S1.p9.1.1" class="ltx_text ltx_font_italic">differences</span> between clients and interpreting the federated learning process as a whole is, to the best of our knowledge, a problem not previously investigated. Standard neural-network model-interpretation techniques such as LIME <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="" class="ltx_ref">23</a>]</cite> are, unfortunately, not immediately applicable to federated learning and thus would not fulfil our objectives. For vertically (i.e., feature-wise) partitioned data and tree-based models, SHAP-values have been investigated by <cite class="ltx_cite ltx_citemacro_citet">Zheng et al. [<a href="#bib.bib29" title="" class="ltx_ref">29</a>]</cite> and <cite class="ltx_cite ltx_citemacro_citet">Wang [<a href="#bib.bib25" title="" class="ltx_ref">25</a>]</cite>, but the approach is not applicable to our setting as we focus on a <span id="S1.p9.1.2" class="ltx_text ltx_font_italic">horizontally</span> (i.e., sample-wise) partitioned dataset. Furthermore, SHAP values learn feature-wise contributions to the model, rather than learning and compensating for potential data biases. <cite class="ltx_cite ltx_citemacro_citet">Imakura et al. [<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite> present an "interpretable non-model sharing collaborative data analysis method as a federated learning system". While retaining privacy, the authors assume having access to a shared public <span id="S1.p9.1.3" class="ltx_text ltx_font_italic">anchor</span> dataset and focus on model-interpretability only. Hence the need for a method allowing for interpretability at the process level enabling comparisons between clients.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Interpretable and data-interoperable federated averaging</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">Our proposed method, <span id="S2.p1.1.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> is designed not only as a personalized federated learning algorithm but as a component of a complete framework. Figure <a href="#S2.F1" title="Figure 1 ‣ 2 Interpretable and data-interoperable federated averaging ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> illustrates this entire workflow, highlighting how <span id="S2.p1.1.2" class="ltx_text ltx_font_typewriter">iFedAvg</span> enables each step. The following subsections outline the main aspects of the proposed method.</p>
</div>
<figure id="S2.F1" class="ltx_figure"><img src="/html/2107.06580/assets/x1.png" id="S2.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="456" height="290" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The three phases enabled by <span id="S2.F1.2.1" class="ltx_text ltx_font_typewriter">iFedAvg</span>. A) a novel model architecture that extracts feature-wise interoperability information deployable in a federated setting B) interpretable outputs allowing practitioners to detect and understand inter-client compatibility issues C) independent private interpretation performed after the training procedure.</figcaption>
</figure>
<section id="S2.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.1 </span>Architecture</h3>

<div id="S2.SS1.p1" class="ltx_para">
<p id="S2.SS1.p1.5" class="ltx_p">Let us denote an existing neural network model which could be shared among all clients as <math id="S2.SS1.p1.1.m1.1" class="ltx_Math" alttext="f_{\text{\tiny{shared}}}:\mathbb{R}^{D}\rightarrow\mathbb{R}^{K}" display="inline"><semantics id="S2.SS1.p1.1.m1.1a"><mrow id="S2.SS1.p1.1.m1.1.1" xref="S2.SS1.p1.1.m1.1.1.cmml"><msub id="S2.SS1.p1.1.m1.1.1.2" xref="S2.SS1.p1.1.m1.1.1.2.cmml"><mi id="S2.SS1.p1.1.m1.1.1.2.2" xref="S2.SS1.p1.1.m1.1.1.2.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS1.p1.1.m1.1.1.2.3" xref="S2.SS1.p1.1.m1.1.1.2.3a.cmml">shared</mtext></msub><mo lspace="0.278em" rspace="0.278em" id="S2.SS1.p1.1.m1.1.1.1" xref="S2.SS1.p1.1.m1.1.1.1.cmml">:</mo><mrow id="S2.SS1.p1.1.m1.1.1.3" xref="S2.SS1.p1.1.m1.1.1.3.cmml"><msup id="S2.SS1.p1.1.m1.1.1.3.2" xref="S2.SS1.p1.1.m1.1.1.3.2.cmml"><mi id="S2.SS1.p1.1.m1.1.1.3.2.2" xref="S2.SS1.p1.1.m1.1.1.3.2.2.cmml">ℝ</mi><mi id="S2.SS1.p1.1.m1.1.1.3.2.3" xref="S2.SS1.p1.1.m1.1.1.3.2.3.cmml">D</mi></msup><mo stretchy="false" id="S2.SS1.p1.1.m1.1.1.3.1" xref="S2.SS1.p1.1.m1.1.1.3.1.cmml">→</mo><msup id="S2.SS1.p1.1.m1.1.1.3.3" xref="S2.SS1.p1.1.m1.1.1.3.3.cmml"><mi id="S2.SS1.p1.1.m1.1.1.3.3.2" xref="S2.SS1.p1.1.m1.1.1.3.3.2.cmml">ℝ</mi><mi id="S2.SS1.p1.1.m1.1.1.3.3.3" xref="S2.SS1.p1.1.m1.1.1.3.3.3.cmml">K</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.1.m1.1b"><apply id="S2.SS1.p1.1.m1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1"><ci id="S2.SS1.p1.1.m1.1.1.1.cmml" xref="S2.SS1.p1.1.m1.1.1.1">:</ci><apply id="S2.SS1.p1.1.m1.1.1.2.cmml" xref="S2.SS1.p1.1.m1.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.1.1.2.1.cmml" xref="S2.SS1.p1.1.m1.1.1.2">subscript</csymbol><ci id="S2.SS1.p1.1.m1.1.1.2.2.cmml" xref="S2.SS1.p1.1.m1.1.1.2.2">𝑓</ci><ci id="S2.SS1.p1.1.m1.1.1.2.3a.cmml" xref="S2.SS1.p1.1.m1.1.1.2.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS1.p1.1.m1.1.1.2.3.cmml" xref="S2.SS1.p1.1.m1.1.1.2.3">shared</mtext></ci></apply><apply id="S2.SS1.p1.1.m1.1.1.3.cmml" xref="S2.SS1.p1.1.m1.1.1.3"><ci id="S2.SS1.p1.1.m1.1.1.3.1.cmml" xref="S2.SS1.p1.1.m1.1.1.3.1">→</ci><apply id="S2.SS1.p1.1.m1.1.1.3.2.cmml" xref="S2.SS1.p1.1.m1.1.1.3.2"><csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.1.1.3.2.1.cmml" xref="S2.SS1.p1.1.m1.1.1.3.2">superscript</csymbol><ci id="S2.SS1.p1.1.m1.1.1.3.2.2.cmml" xref="S2.SS1.p1.1.m1.1.1.3.2.2">ℝ</ci><ci id="S2.SS1.p1.1.m1.1.1.3.2.3.cmml" xref="S2.SS1.p1.1.m1.1.1.3.2.3">𝐷</ci></apply><apply id="S2.SS1.p1.1.m1.1.1.3.3.cmml" xref="S2.SS1.p1.1.m1.1.1.3.3"><csymbol cd="ambiguous" id="S2.SS1.p1.1.m1.1.1.3.3.1.cmml" xref="S2.SS1.p1.1.m1.1.1.3.3">superscript</csymbol><ci id="S2.SS1.p1.1.m1.1.1.3.3.2.cmml" xref="S2.SS1.p1.1.m1.1.1.3.3.2">ℝ</ci><ci id="S2.SS1.p1.1.m1.1.1.3.3.3.cmml" xref="S2.SS1.p1.1.m1.1.1.3.3.3">𝐾</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.1.m1.1c">f_{\text{\tiny{shared}}}:\mathbb{R}^{D}\rightarrow\mathbb{R}^{K}</annotation></semantics></math>. This model maps an input vector <math id="S2.SS1.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{x}\in\mathbb{R}^{D}" display="inline"><semantics id="S2.SS1.p1.2.m2.1a"><mrow id="S2.SS1.p1.2.m2.1.1" xref="S2.SS1.p1.2.m2.1.1.cmml"><mi id="S2.SS1.p1.2.m2.1.1.2" xref="S2.SS1.p1.2.m2.1.1.2.cmml">𝐱</mi><mo id="S2.SS1.p1.2.m2.1.1.1" xref="S2.SS1.p1.2.m2.1.1.1.cmml">∈</mo><msup id="S2.SS1.p1.2.m2.1.1.3" xref="S2.SS1.p1.2.m2.1.1.3.cmml"><mi id="S2.SS1.p1.2.m2.1.1.3.2" xref="S2.SS1.p1.2.m2.1.1.3.2.cmml">ℝ</mi><mi id="S2.SS1.p1.2.m2.1.1.3.3" xref="S2.SS1.p1.2.m2.1.1.3.3.cmml">D</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.2.m2.1b"><apply id="S2.SS1.p1.2.m2.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1"><in id="S2.SS1.p1.2.m2.1.1.1.cmml" xref="S2.SS1.p1.2.m2.1.1.1"></in><ci id="S2.SS1.p1.2.m2.1.1.2.cmml" xref="S2.SS1.p1.2.m2.1.1.2">𝐱</ci><apply id="S2.SS1.p1.2.m2.1.1.3.cmml" xref="S2.SS1.p1.2.m2.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p1.2.m2.1.1.3.1.cmml" xref="S2.SS1.p1.2.m2.1.1.3">superscript</csymbol><ci id="S2.SS1.p1.2.m2.1.1.3.2.cmml" xref="S2.SS1.p1.2.m2.1.1.3.2">ℝ</ci><ci id="S2.SS1.p1.2.m2.1.1.3.3.cmml" xref="S2.SS1.p1.2.m2.1.1.3.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.2.m2.1c">\mathbf{x}\in\mathbb{R}^{D}</annotation></semantics></math> to a target vector <math id="S2.SS1.p1.3.m3.1" class="ltx_Math" alttext="\mathbf{y}\in\mathbb{R}^{K}" display="inline"><semantics id="S2.SS1.p1.3.m3.1a"><mrow id="S2.SS1.p1.3.m3.1.1" xref="S2.SS1.p1.3.m3.1.1.cmml"><mi id="S2.SS1.p1.3.m3.1.1.2" xref="S2.SS1.p1.3.m3.1.1.2.cmml">𝐲</mi><mo id="S2.SS1.p1.3.m3.1.1.1" xref="S2.SS1.p1.3.m3.1.1.1.cmml">∈</mo><msup id="S2.SS1.p1.3.m3.1.1.3" xref="S2.SS1.p1.3.m3.1.1.3.cmml"><mi id="S2.SS1.p1.3.m3.1.1.3.2" xref="S2.SS1.p1.3.m3.1.1.3.2.cmml">ℝ</mi><mi id="S2.SS1.p1.3.m3.1.1.3.3" xref="S2.SS1.p1.3.m3.1.1.3.3.cmml">K</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.3.m3.1b"><apply id="S2.SS1.p1.3.m3.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1"><in id="S2.SS1.p1.3.m3.1.1.1.cmml" xref="S2.SS1.p1.3.m3.1.1.1"></in><ci id="S2.SS1.p1.3.m3.1.1.2.cmml" xref="S2.SS1.p1.3.m3.1.1.2">𝐲</ci><apply id="S2.SS1.p1.3.m3.1.1.3.cmml" xref="S2.SS1.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p1.3.m3.1.1.3.1.cmml" xref="S2.SS1.p1.3.m3.1.1.3">superscript</csymbol><ci id="S2.SS1.p1.3.m3.1.1.3.2.cmml" xref="S2.SS1.p1.3.m3.1.1.3.2">ℝ</ci><ci id="S2.SS1.p1.3.m3.1.1.3.3.cmml" xref="S2.SS1.p1.3.m3.1.1.3.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.3.m3.1c">\mathbf{y}\in\mathbb{R}^{K}</annotation></semantics></math>. We place no assumptions on the type or complexity of the <math id="S2.SS1.p1.4.m4.1" class="ltx_Math" alttext="f_{\text{\tiny{shared}}}" display="inline"><semantics id="S2.SS1.p1.4.m4.1a"><msub id="S2.SS1.p1.4.m4.1.1" xref="S2.SS1.p1.4.m4.1.1.cmml"><mi id="S2.SS1.p1.4.m4.1.1.2" xref="S2.SS1.p1.4.m4.1.1.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS1.p1.4.m4.1.1.3" xref="S2.SS1.p1.4.m4.1.1.3a.cmml">shared</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.4.m4.1b"><apply id="S2.SS1.p1.4.m4.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.4.m4.1.1.1.cmml" xref="S2.SS1.p1.4.m4.1.1">subscript</csymbol><ci id="S2.SS1.p1.4.m4.1.1.2.cmml" xref="S2.SS1.p1.4.m4.1.1.2">𝑓</ci><ci id="S2.SS1.p1.4.m4.1.1.3a.cmml" xref="S2.SS1.p1.4.m4.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS1.p1.4.m4.1.1.3.cmml" xref="S2.SS1.p1.4.m4.1.1.3">shared</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.4.m4.1c">f_{\text{\tiny{shared}}}</annotation></semantics></math>’s network as long as it can be trained using gradient-based optimizers and conforms to the definition above. The objective of our work is to devise an extension, allowing for <math id="S2.SS1.p1.5.m5.1" class="ltx_Math" alttext="f_{\text{\tiny{shared}}}" display="inline"><semantics id="S2.SS1.p1.5.m5.1a"><msub id="S2.SS1.p1.5.m5.1.1" xref="S2.SS1.p1.5.m5.1.1.cmml"><mi id="S2.SS1.p1.5.m5.1.1.2" xref="S2.SS1.p1.5.m5.1.1.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS1.p1.5.m5.1.1.3" xref="S2.SS1.p1.5.m5.1.1.3a.cmml">shared</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p1.5.m5.1b"><apply id="S2.SS1.p1.5.m5.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1"><csymbol cd="ambiguous" id="S2.SS1.p1.5.m5.1.1.1.cmml" xref="S2.SS1.p1.5.m5.1.1">subscript</csymbol><ci id="S2.SS1.p1.5.m5.1.1.2.cmml" xref="S2.SS1.p1.5.m5.1.1.2">𝑓</ci><ci id="S2.SS1.p1.5.m5.1.1.3a.cmml" xref="S2.SS1.p1.5.m5.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS1.p1.5.m5.1.1.3.cmml" xref="S2.SS1.p1.5.m5.1.1.3">shared</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p1.5.m5.1c">f_{\text{\tiny{shared}}}</annotation></semantics></math> to be more interoperable in a transparent fashion.</p>
</div>
<div id="S2.SS1.p2" class="ltx_para">
<p id="S2.SS1.p2.5" class="ltx_p"><span id="S2.SS1.p2.5.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> introduces personalization layers around the shared neural network, <math id="S2.SS1.p2.1.m1.1" class="ltx_Math" alttext="f_{\text{\tiny{shared}}}" display="inline"><semantics id="S2.SS1.p2.1.m1.1a"><msub id="S2.SS1.p2.1.m1.1.1" xref="S2.SS1.p2.1.m1.1.1.cmml"><mi id="S2.SS1.p2.1.m1.1.1.2" xref="S2.SS1.p2.1.m1.1.1.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS1.p2.1.m1.1.1.3" xref="S2.SS1.p2.1.m1.1.1.3a.cmml">shared</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.1.m1.1b"><apply id="S2.SS1.p2.1.m1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p2.1.m1.1.1.1.cmml" xref="S2.SS1.p2.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.p2.1.m1.1.1.2.cmml" xref="S2.SS1.p2.1.m1.1.1.2">𝑓</ci><ci id="S2.SS1.p2.1.m1.1.1.3a.cmml" xref="S2.SS1.p2.1.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS1.p2.1.m1.1.1.3.cmml" xref="S2.SS1.p2.1.m1.1.1.3">shared</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.1.m1.1c">f_{\text{\tiny{shared}}}</annotation></semantics></math>. The combined model is then specified as <math id="S2.SS1.p2.2.m2.1" class="ltx_Math" alttext="f_{\text{\tiny{out}}}\circ f_{\text{\tiny{shared}}}\circ f_{\text{\tiny{in}}}" display="inline"><semantics id="S2.SS1.p2.2.m2.1a"><mrow id="S2.SS1.p2.2.m2.1.1" xref="S2.SS1.p2.2.m2.1.1.cmml"><msub id="S2.SS1.p2.2.m2.1.1.2" xref="S2.SS1.p2.2.m2.1.1.2.cmml"><mi id="S2.SS1.p2.2.m2.1.1.2.2" xref="S2.SS1.p2.2.m2.1.1.2.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS1.p2.2.m2.1.1.2.3" xref="S2.SS1.p2.2.m2.1.1.2.3a.cmml">out</mtext></msub><mo lspace="0.222em" rspace="0.222em" id="S2.SS1.p2.2.m2.1.1.1" xref="S2.SS1.p2.2.m2.1.1.1.cmml">∘</mo><msub id="S2.SS1.p2.2.m2.1.1.3" xref="S2.SS1.p2.2.m2.1.1.3.cmml"><mi id="S2.SS1.p2.2.m2.1.1.3.2" xref="S2.SS1.p2.2.m2.1.1.3.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS1.p2.2.m2.1.1.3.3" xref="S2.SS1.p2.2.m2.1.1.3.3a.cmml">shared</mtext></msub><mo lspace="0.222em" rspace="0.222em" id="S2.SS1.p2.2.m2.1.1.1a" xref="S2.SS1.p2.2.m2.1.1.1.cmml">∘</mo><msub id="S2.SS1.p2.2.m2.1.1.4" xref="S2.SS1.p2.2.m2.1.1.4.cmml"><mi id="S2.SS1.p2.2.m2.1.1.4.2" xref="S2.SS1.p2.2.m2.1.1.4.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS1.p2.2.m2.1.1.4.3" xref="S2.SS1.p2.2.m2.1.1.4.3a.cmml">in</mtext></msub></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.2.m2.1b"><apply id="S2.SS1.p2.2.m2.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1"><compose id="S2.SS1.p2.2.m2.1.1.1.cmml" xref="S2.SS1.p2.2.m2.1.1.1"></compose><apply id="S2.SS1.p2.2.m2.1.1.2.cmml" xref="S2.SS1.p2.2.m2.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p2.2.m2.1.1.2.1.cmml" xref="S2.SS1.p2.2.m2.1.1.2">subscript</csymbol><ci id="S2.SS1.p2.2.m2.1.1.2.2.cmml" xref="S2.SS1.p2.2.m2.1.1.2.2">𝑓</ci><ci id="S2.SS1.p2.2.m2.1.1.2.3a.cmml" xref="S2.SS1.p2.2.m2.1.1.2.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS1.p2.2.m2.1.1.2.3.cmml" xref="S2.SS1.p2.2.m2.1.1.2.3">out</mtext></ci></apply><apply id="S2.SS1.p2.2.m2.1.1.3.cmml" xref="S2.SS1.p2.2.m2.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p2.2.m2.1.1.3.1.cmml" xref="S2.SS1.p2.2.m2.1.1.3">subscript</csymbol><ci id="S2.SS1.p2.2.m2.1.1.3.2.cmml" xref="S2.SS1.p2.2.m2.1.1.3.2">𝑓</ci><ci id="S2.SS1.p2.2.m2.1.1.3.3a.cmml" xref="S2.SS1.p2.2.m2.1.1.3.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS1.p2.2.m2.1.1.3.3.cmml" xref="S2.SS1.p2.2.m2.1.1.3.3">shared</mtext></ci></apply><apply id="S2.SS1.p2.2.m2.1.1.4.cmml" xref="S2.SS1.p2.2.m2.1.1.4"><csymbol cd="ambiguous" id="S2.SS1.p2.2.m2.1.1.4.1.cmml" xref="S2.SS1.p2.2.m2.1.1.4">subscript</csymbol><ci id="S2.SS1.p2.2.m2.1.1.4.2.cmml" xref="S2.SS1.p2.2.m2.1.1.4.2">𝑓</ci><ci id="S2.SS1.p2.2.m2.1.1.4.3a.cmml" xref="S2.SS1.p2.2.m2.1.1.4.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS1.p2.2.m2.1.1.4.3.cmml" xref="S2.SS1.p2.2.m2.1.1.4.3">in</mtext></ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.2.m2.1c">f_{\text{\tiny{out}}}\circ f_{\text{\tiny{shared}}}\circ f_{\text{\tiny{in}}}</annotation></semantics></math>, where <math id="S2.SS1.p2.3.m3.1" class="ltx_Math" alttext="\circ" display="inline"><semantics id="S2.SS1.p2.3.m3.1a"><mo id="S2.SS1.p2.3.m3.1.1" xref="S2.SS1.p2.3.m3.1.1.cmml">∘</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.3.m3.1b"><compose id="S2.SS1.p2.3.m3.1.1.cmml" xref="S2.SS1.p2.3.m3.1.1"></compose></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.3.m3.1c">\circ</annotation></semantics></math> indicates a composition. To retain the correct dimensionality, the input and output layers are as follows: <math id="S2.SS1.p2.4.m4.1" class="ltx_Math" alttext="f_{\text{\tiny{in}}}:\mathbb{R}^{D}\rightarrow\mathbb{R}^{D}" display="inline"><semantics id="S2.SS1.p2.4.m4.1a"><mrow id="S2.SS1.p2.4.m4.1.1" xref="S2.SS1.p2.4.m4.1.1.cmml"><msub id="S2.SS1.p2.4.m4.1.1.2" xref="S2.SS1.p2.4.m4.1.1.2.cmml"><mi id="S2.SS1.p2.4.m4.1.1.2.2" xref="S2.SS1.p2.4.m4.1.1.2.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS1.p2.4.m4.1.1.2.3" xref="S2.SS1.p2.4.m4.1.1.2.3a.cmml">in</mtext></msub><mo lspace="0.278em" rspace="0.278em" id="S2.SS1.p2.4.m4.1.1.1" xref="S2.SS1.p2.4.m4.1.1.1.cmml">:</mo><mrow id="S2.SS1.p2.4.m4.1.1.3" xref="S2.SS1.p2.4.m4.1.1.3.cmml"><msup id="S2.SS1.p2.4.m4.1.1.3.2" xref="S2.SS1.p2.4.m4.1.1.3.2.cmml"><mi id="S2.SS1.p2.4.m4.1.1.3.2.2" xref="S2.SS1.p2.4.m4.1.1.3.2.2.cmml">ℝ</mi><mi id="S2.SS1.p2.4.m4.1.1.3.2.3" xref="S2.SS1.p2.4.m4.1.1.3.2.3.cmml">D</mi></msup><mo stretchy="false" id="S2.SS1.p2.4.m4.1.1.3.1" xref="S2.SS1.p2.4.m4.1.1.3.1.cmml">→</mo><msup id="S2.SS1.p2.4.m4.1.1.3.3" xref="S2.SS1.p2.4.m4.1.1.3.3.cmml"><mi id="S2.SS1.p2.4.m4.1.1.3.3.2" xref="S2.SS1.p2.4.m4.1.1.3.3.2.cmml">ℝ</mi><mi id="S2.SS1.p2.4.m4.1.1.3.3.3" xref="S2.SS1.p2.4.m4.1.1.3.3.3.cmml">D</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.4.m4.1b"><apply id="S2.SS1.p2.4.m4.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1"><ci id="S2.SS1.p2.4.m4.1.1.1.cmml" xref="S2.SS1.p2.4.m4.1.1.1">:</ci><apply id="S2.SS1.p2.4.m4.1.1.2.cmml" xref="S2.SS1.p2.4.m4.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p2.4.m4.1.1.2.1.cmml" xref="S2.SS1.p2.4.m4.1.1.2">subscript</csymbol><ci id="S2.SS1.p2.4.m4.1.1.2.2.cmml" xref="S2.SS1.p2.4.m4.1.1.2.2">𝑓</ci><ci id="S2.SS1.p2.4.m4.1.1.2.3a.cmml" xref="S2.SS1.p2.4.m4.1.1.2.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS1.p2.4.m4.1.1.2.3.cmml" xref="S2.SS1.p2.4.m4.1.1.2.3">in</mtext></ci></apply><apply id="S2.SS1.p2.4.m4.1.1.3.cmml" xref="S2.SS1.p2.4.m4.1.1.3"><ci id="S2.SS1.p2.4.m4.1.1.3.1.cmml" xref="S2.SS1.p2.4.m4.1.1.3.1">→</ci><apply id="S2.SS1.p2.4.m4.1.1.3.2.cmml" xref="S2.SS1.p2.4.m4.1.1.3.2"><csymbol cd="ambiguous" id="S2.SS1.p2.4.m4.1.1.3.2.1.cmml" xref="S2.SS1.p2.4.m4.1.1.3.2">superscript</csymbol><ci id="S2.SS1.p2.4.m4.1.1.3.2.2.cmml" xref="S2.SS1.p2.4.m4.1.1.3.2.2">ℝ</ci><ci id="S2.SS1.p2.4.m4.1.1.3.2.3.cmml" xref="S2.SS1.p2.4.m4.1.1.3.2.3">𝐷</ci></apply><apply id="S2.SS1.p2.4.m4.1.1.3.3.cmml" xref="S2.SS1.p2.4.m4.1.1.3.3"><csymbol cd="ambiguous" id="S2.SS1.p2.4.m4.1.1.3.3.1.cmml" xref="S2.SS1.p2.4.m4.1.1.3.3">superscript</csymbol><ci id="S2.SS1.p2.4.m4.1.1.3.3.2.cmml" xref="S2.SS1.p2.4.m4.1.1.3.3.2">ℝ</ci><ci id="S2.SS1.p2.4.m4.1.1.3.3.3.cmml" xref="S2.SS1.p2.4.m4.1.1.3.3.3">𝐷</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.4.m4.1c">f_{\text{\tiny{in}}}:\mathbb{R}^{D}\rightarrow\mathbb{R}^{D}</annotation></semantics></math> and <math id="S2.SS1.p2.5.m5.1" class="ltx_Math" alttext="f_{\text{\tiny{out}}}:\mathbb{R}^{K}\rightarrow\mathbb{R}^{K}" display="inline"><semantics id="S2.SS1.p2.5.m5.1a"><mrow id="S2.SS1.p2.5.m5.1.1" xref="S2.SS1.p2.5.m5.1.1.cmml"><msub id="S2.SS1.p2.5.m5.1.1.2" xref="S2.SS1.p2.5.m5.1.1.2.cmml"><mi id="S2.SS1.p2.5.m5.1.1.2.2" xref="S2.SS1.p2.5.m5.1.1.2.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS1.p2.5.m5.1.1.2.3" xref="S2.SS1.p2.5.m5.1.1.2.3a.cmml">out</mtext></msub><mo lspace="0.278em" rspace="0.278em" id="S2.SS1.p2.5.m5.1.1.1" xref="S2.SS1.p2.5.m5.1.1.1.cmml">:</mo><mrow id="S2.SS1.p2.5.m5.1.1.3" xref="S2.SS1.p2.5.m5.1.1.3.cmml"><msup id="S2.SS1.p2.5.m5.1.1.3.2" xref="S2.SS1.p2.5.m5.1.1.3.2.cmml"><mi id="S2.SS1.p2.5.m5.1.1.3.2.2" xref="S2.SS1.p2.5.m5.1.1.3.2.2.cmml">ℝ</mi><mi id="S2.SS1.p2.5.m5.1.1.3.2.3" xref="S2.SS1.p2.5.m5.1.1.3.2.3.cmml">K</mi></msup><mo stretchy="false" id="S2.SS1.p2.5.m5.1.1.3.1" xref="S2.SS1.p2.5.m5.1.1.3.1.cmml">→</mo><msup id="S2.SS1.p2.5.m5.1.1.3.3" xref="S2.SS1.p2.5.m5.1.1.3.3.cmml"><mi id="S2.SS1.p2.5.m5.1.1.3.3.2" xref="S2.SS1.p2.5.m5.1.1.3.3.2.cmml">ℝ</mi><mi id="S2.SS1.p2.5.m5.1.1.3.3.3" xref="S2.SS1.p2.5.m5.1.1.3.3.3.cmml">K</mi></msup></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p2.5.m5.1b"><apply id="S2.SS1.p2.5.m5.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1"><ci id="S2.SS1.p2.5.m5.1.1.1.cmml" xref="S2.SS1.p2.5.m5.1.1.1">:</ci><apply id="S2.SS1.p2.5.m5.1.1.2.cmml" xref="S2.SS1.p2.5.m5.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p2.5.m5.1.1.2.1.cmml" xref="S2.SS1.p2.5.m5.1.1.2">subscript</csymbol><ci id="S2.SS1.p2.5.m5.1.1.2.2.cmml" xref="S2.SS1.p2.5.m5.1.1.2.2">𝑓</ci><ci id="S2.SS1.p2.5.m5.1.1.2.3a.cmml" xref="S2.SS1.p2.5.m5.1.1.2.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS1.p2.5.m5.1.1.2.3.cmml" xref="S2.SS1.p2.5.m5.1.1.2.3">out</mtext></ci></apply><apply id="S2.SS1.p2.5.m5.1.1.3.cmml" xref="S2.SS1.p2.5.m5.1.1.3"><ci id="S2.SS1.p2.5.m5.1.1.3.1.cmml" xref="S2.SS1.p2.5.m5.1.1.3.1">→</ci><apply id="S2.SS1.p2.5.m5.1.1.3.2.cmml" xref="S2.SS1.p2.5.m5.1.1.3.2"><csymbol cd="ambiguous" id="S2.SS1.p2.5.m5.1.1.3.2.1.cmml" xref="S2.SS1.p2.5.m5.1.1.3.2">superscript</csymbol><ci id="S2.SS1.p2.5.m5.1.1.3.2.2.cmml" xref="S2.SS1.p2.5.m5.1.1.3.2.2">ℝ</ci><ci id="S2.SS1.p2.5.m5.1.1.3.2.3.cmml" xref="S2.SS1.p2.5.m5.1.1.3.2.3">𝐾</ci></apply><apply id="S2.SS1.p2.5.m5.1.1.3.3.cmml" xref="S2.SS1.p2.5.m5.1.1.3.3"><csymbol cd="ambiguous" id="S2.SS1.p2.5.m5.1.1.3.3.1.cmml" xref="S2.SS1.p2.5.m5.1.1.3.3">superscript</csymbol><ci id="S2.SS1.p2.5.m5.1.1.3.3.2.cmml" xref="S2.SS1.p2.5.m5.1.1.3.3.2">ℝ</ci><ci id="S2.SS1.p2.5.m5.1.1.3.3.3.cmml" xref="S2.SS1.p2.5.m5.1.1.3.3.3">𝐾</ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p2.5.m5.1c">f_{\text{\tiny{out}}}:\mathbb{R}^{K}\rightarrow\mathbb{R}^{K}</annotation></semantics></math>.</p>
</div>
<div id="S2.SS1.p3" class="ltx_para">
<p id="S2.SS1.p3.2" class="ltx_p">In order to retain interpretability at the feature- and target-level, we propose the layers to simply be an element-wise learned normalization. We assume that numerical values are standardized for each client. Inspired by traditional standardization we explicitly define <math id="S2.SS1.p3.1.m1.1" class="ltx_Math" alttext="f_{\text{\tiny{in}}}" display="inline"><semantics id="S2.SS1.p3.1.m1.1a"><msub id="S2.SS1.p3.1.m1.1.1" xref="S2.SS1.p3.1.m1.1.1.cmml"><mi id="S2.SS1.p3.1.m1.1.1.2" xref="S2.SS1.p3.1.m1.1.1.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS1.p3.1.m1.1.1.3" xref="S2.SS1.p3.1.m1.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.1.m1.1b"><apply id="S2.SS1.p3.1.m1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.1.m1.1.1.1.cmml" xref="S2.SS1.p3.1.m1.1.1">subscript</csymbol><ci id="S2.SS1.p3.1.m1.1.1.2.cmml" xref="S2.SS1.p3.1.m1.1.1.2">𝑓</ci><ci id="S2.SS1.p3.1.m1.1.1.3a.cmml" xref="S2.SS1.p3.1.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS1.p3.1.m1.1.1.3.cmml" xref="S2.SS1.p3.1.m1.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.1.m1.1c">f_{\text{\tiny{in}}}</annotation></semantics></math>, with bias and weight vectors <math id="S2.SS1.p3.2.m2.2" class="ltx_Math" alttext="\mathbf{b}_{\text{\tiny{in}}},\mathbf{w}_{\text{\tiny{in}}}\in\mathbb{R}^{D}" display="inline"><semantics id="S2.SS1.p3.2.m2.2a"><mrow id="S2.SS1.p3.2.m2.2.2" xref="S2.SS1.p3.2.m2.2.2.cmml"><mrow id="S2.SS1.p3.2.m2.2.2.2.2" xref="S2.SS1.p3.2.m2.2.2.2.3.cmml"><msub id="S2.SS1.p3.2.m2.1.1.1.1.1" xref="S2.SS1.p3.2.m2.1.1.1.1.1.cmml"><mi id="S2.SS1.p3.2.m2.1.1.1.1.1.2" xref="S2.SS1.p3.2.m2.1.1.1.1.1.2.cmml">𝐛</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS1.p3.2.m2.1.1.1.1.1.3" xref="S2.SS1.p3.2.m2.1.1.1.1.1.3a.cmml">in</mtext></msub><mo id="S2.SS1.p3.2.m2.2.2.2.2.3" xref="S2.SS1.p3.2.m2.2.2.2.3.cmml">,</mo><msub id="S2.SS1.p3.2.m2.2.2.2.2.2" xref="S2.SS1.p3.2.m2.2.2.2.2.2.cmml"><mi id="S2.SS1.p3.2.m2.2.2.2.2.2.2" xref="S2.SS1.p3.2.m2.2.2.2.2.2.2.cmml">𝐰</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS1.p3.2.m2.2.2.2.2.2.3" xref="S2.SS1.p3.2.m2.2.2.2.2.2.3a.cmml">in</mtext></msub></mrow><mo id="S2.SS1.p3.2.m2.2.2.3" xref="S2.SS1.p3.2.m2.2.2.3.cmml">∈</mo><msup id="S2.SS1.p3.2.m2.2.2.4" xref="S2.SS1.p3.2.m2.2.2.4.cmml"><mi id="S2.SS1.p3.2.m2.2.2.4.2" xref="S2.SS1.p3.2.m2.2.2.4.2.cmml">ℝ</mi><mi id="S2.SS1.p3.2.m2.2.2.4.3" xref="S2.SS1.p3.2.m2.2.2.4.3.cmml">D</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p3.2.m2.2b"><apply id="S2.SS1.p3.2.m2.2.2.cmml" xref="S2.SS1.p3.2.m2.2.2"><in id="S2.SS1.p3.2.m2.2.2.3.cmml" xref="S2.SS1.p3.2.m2.2.2.3"></in><list id="S2.SS1.p3.2.m2.2.2.2.3.cmml" xref="S2.SS1.p3.2.m2.2.2.2.2"><apply id="S2.SS1.p3.2.m2.1.1.1.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p3.2.m2.1.1.1.1.1.1.cmml" xref="S2.SS1.p3.2.m2.1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p3.2.m2.1.1.1.1.1.2.cmml" xref="S2.SS1.p3.2.m2.1.1.1.1.1.2">𝐛</ci><ci id="S2.SS1.p3.2.m2.1.1.1.1.1.3a.cmml" xref="S2.SS1.p3.2.m2.1.1.1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS1.p3.2.m2.1.1.1.1.1.3.cmml" xref="S2.SS1.p3.2.m2.1.1.1.1.1.3">in</mtext></ci></apply><apply id="S2.SS1.p3.2.m2.2.2.2.2.2.cmml" xref="S2.SS1.p3.2.m2.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p3.2.m2.2.2.2.2.2.1.cmml" xref="S2.SS1.p3.2.m2.2.2.2.2.2">subscript</csymbol><ci id="S2.SS1.p3.2.m2.2.2.2.2.2.2.cmml" xref="S2.SS1.p3.2.m2.2.2.2.2.2.2">𝐰</ci><ci id="S2.SS1.p3.2.m2.2.2.2.2.2.3a.cmml" xref="S2.SS1.p3.2.m2.2.2.2.2.2.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS1.p3.2.m2.2.2.2.2.2.3.cmml" xref="S2.SS1.p3.2.m2.2.2.2.2.2.3">in</mtext></ci></apply></list><apply id="S2.SS1.p3.2.m2.2.2.4.cmml" xref="S2.SS1.p3.2.m2.2.2.4"><csymbol cd="ambiguous" id="S2.SS1.p3.2.m2.2.2.4.1.cmml" xref="S2.SS1.p3.2.m2.2.2.4">superscript</csymbol><ci id="S2.SS1.p3.2.m2.2.2.4.2.cmml" xref="S2.SS1.p3.2.m2.2.2.4.2">ℝ</ci><ci id="S2.SS1.p3.2.m2.2.2.4.3.cmml" xref="S2.SS1.p3.2.m2.2.2.4.3">𝐷</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p3.2.m2.2c">\mathbf{b}_{\text{\tiny{in}}},\mathbf{w}_{\text{\tiny{in}}}\in\mathbb{R}^{D}</annotation></semantics></math> as:</p>
</div>
<div id="S2.SS1.p4" class="ltx_para">
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.2" class="ltx_Math" alttext="f_{\text{\tiny{in}}}(\mathbf{x})=(\mathbf{x}+\mathbf{b}_{\text{\tiny{in}}})\odot\mathbf{w}_{\text{\tiny{in}}}\ ," display="block"><semantics id="S2.E1.m1.2a"><mrow id="S2.E1.m1.2.2.1" xref="S2.E1.m1.2.2.1.1.cmml"><mrow id="S2.E1.m1.2.2.1.1" xref="S2.E1.m1.2.2.1.1.cmml"><mrow id="S2.E1.m1.2.2.1.1.3" xref="S2.E1.m1.2.2.1.1.3.cmml"><msub id="S2.E1.m1.2.2.1.1.3.2" xref="S2.E1.m1.2.2.1.1.3.2.cmml"><mi id="S2.E1.m1.2.2.1.1.3.2.2" xref="S2.E1.m1.2.2.1.1.3.2.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.E1.m1.2.2.1.1.3.2.3" xref="S2.E1.m1.2.2.1.1.3.2.3a.cmml">in</mtext></msub><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.1.3.1" xref="S2.E1.m1.2.2.1.1.3.1.cmml">​</mo><mrow id="S2.E1.m1.2.2.1.1.3.3.2" xref="S2.E1.m1.2.2.1.1.3.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.1.1.3.3.2.1" xref="S2.E1.m1.2.2.1.1.3.cmml">(</mo><mi id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">𝐱</mi><mo stretchy="false" id="S2.E1.m1.2.2.1.1.3.3.2.2" xref="S2.E1.m1.2.2.1.1.3.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.2.2.1.1.2" xref="S2.E1.m1.2.2.1.1.2.cmml">=</mo><mrow id="S2.E1.m1.2.2.1.1.1" xref="S2.E1.m1.2.2.1.1.1.cmml"><mrow id="S2.E1.m1.2.2.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.2.2.1.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.2.2.1.1.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.1.1.2.cmml">𝐱</mi><mo id="S2.E1.m1.2.2.1.1.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.cmml">+</mo><msub id="S2.E1.m1.2.2.1.1.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.1.1.3.cmml"><mi id="S2.E1.m1.2.2.1.1.1.1.1.1.3.2" xref="S2.E1.m1.2.2.1.1.1.1.1.1.3.2.cmml">𝐛</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.E1.m1.2.2.1.1.1.1.1.1.3.3" xref="S2.E1.m1.2.2.1.1.1.1.1.1.3.3a.cmml">in</mtext></msub></mrow><mo rspace="0.055em" stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S2.E1.m1.2.2.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.2.cmml">⊙</mo><msub id="S2.E1.m1.2.2.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.3.cmml"><mi id="S2.E1.m1.2.2.1.1.1.3.2" xref="S2.E1.m1.2.2.1.1.1.3.2.cmml">𝐰</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.E1.m1.2.2.1.1.1.3.3" xref="S2.E1.m1.2.2.1.1.1.3.3a.cmml">in</mtext></msub></mrow></mrow><mo id="S2.E1.m1.2.2.1.2" xref="S2.E1.m1.2.2.1.1.cmml">,</mo></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.2b"><apply id="S2.E1.m1.2.2.1.1.cmml" xref="S2.E1.m1.2.2.1"><eq id="S2.E1.m1.2.2.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.2"></eq><apply id="S2.E1.m1.2.2.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.3"><times id="S2.E1.m1.2.2.1.1.3.1.cmml" xref="S2.E1.m1.2.2.1.1.3.1"></times><apply id="S2.E1.m1.2.2.1.1.3.2.cmml" xref="S2.E1.m1.2.2.1.1.3.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.3.2.1.cmml" xref="S2.E1.m1.2.2.1.1.3.2">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.3.2.2.cmml" xref="S2.E1.m1.2.2.1.1.3.2.2">𝑓</ci><ci id="S2.E1.m1.2.2.1.1.3.2.3a.cmml" xref="S2.E1.m1.2.2.1.1.3.2.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.E1.m1.2.2.1.1.3.2.3.cmml" xref="S2.E1.m1.2.2.1.1.3.2.3">in</mtext></ci></apply><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">𝐱</ci></apply><apply id="S2.E1.m1.2.2.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1"><csymbol cd="latexml" id="S2.E1.m1.2.2.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.2">direct-product</csymbol><apply id="S2.E1.m1.2.2.1.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1"><plus id="S2.E1.m1.2.2.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1"></plus><ci id="S2.E1.m1.2.2.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.2">𝐱</ci><apply id="S2.E1.m1.2.2.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.1.1.1.1.3.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.1.1.1.1.3.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.3.2">𝐛</ci><ci id="S2.E1.m1.2.2.1.1.1.1.1.1.3.3a.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.3.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.E1.m1.2.2.1.1.1.1.1.1.3.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.3.3">in</mtext></ci></apply></apply><apply id="S2.E1.m1.2.2.1.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.1.3"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.1.3.1.cmml" xref="S2.E1.m1.2.2.1.1.1.3">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.1.3.2.cmml" xref="S2.E1.m1.2.2.1.1.1.3.2">𝐰</ci><ci id="S2.E1.m1.2.2.1.1.1.3.3a.cmml" xref="S2.E1.m1.2.2.1.1.1.3.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.E1.m1.2.2.1.1.1.3.3.cmml" xref="S2.E1.m1.2.2.1.1.1.3.3">in</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.2c">f_{\text{\tiny{in}}}(\mathbf{x})=(\mathbf{x}+\mathbf{b}_{\text{\tiny{in}}})\odot\mathbf{w}_{\text{\tiny{in}}}\ ,</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
<div id="S2.SS1.p5" class="ltx_para">
<p id="S2.SS1.p5.7" class="ltx_p">where <math id="S2.SS1.p5.1.m1.1" class="ltx_Math" alttext="\odot" display="inline"><semantics id="S2.SS1.p5.1.m1.1a"><mo id="S2.SS1.p5.1.m1.1.1" xref="S2.SS1.p5.1.m1.1.1.cmml">⊙</mo><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.1.m1.1b"><csymbol cd="latexml" id="S2.SS1.p5.1.m1.1.1.cmml" xref="S2.SS1.p5.1.m1.1.1">direct-product</csymbol></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.1.m1.1c">\odot</annotation></semantics></math> refers to the element-wise multiplication. This construction does not allow the blending that a traditional <span id="S2.SS1.p5.7.1" class="ltx_text ltx_font_italic">fully-connected</span> layer permits. <math id="S2.SS1.p5.2.m2.1" class="ltx_Math" alttext="f_{\text{\tiny{in}}}" display="inline"><semantics id="S2.SS1.p5.2.m2.1a"><msub id="S2.SS1.p5.2.m2.1.1" xref="S2.SS1.p5.2.m2.1.1.cmml"><mi id="S2.SS1.p5.2.m2.1.1.2" xref="S2.SS1.p5.2.m2.1.1.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS1.p5.2.m2.1.1.3" xref="S2.SS1.p5.2.m2.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.2.m2.1b"><apply id="S2.SS1.p5.2.m2.1.1.cmml" xref="S2.SS1.p5.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS1.p5.2.m2.1.1.1.cmml" xref="S2.SS1.p5.2.m2.1.1">subscript</csymbol><ci id="S2.SS1.p5.2.m2.1.1.2.cmml" xref="S2.SS1.p5.2.m2.1.1.2">𝑓</ci><ci id="S2.SS1.p5.2.m2.1.1.3a.cmml" xref="S2.SS1.p5.2.m2.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS1.p5.2.m2.1.1.3.cmml" xref="S2.SS1.p5.2.m2.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.2.m2.1c">f_{\text{\tiny{in}}}</annotation></semantics></math> is initialized to be the identify function, namely setting <math id="S2.SS1.p5.3.m3.1" class="ltx_Math" alttext="\mathbf{b}_{\text{\tiny{in}}}=0" display="inline"><semantics id="S2.SS1.p5.3.m3.1a"><mrow id="S2.SS1.p5.3.m3.1.1" xref="S2.SS1.p5.3.m3.1.1.cmml"><msub id="S2.SS1.p5.3.m3.1.1.2" xref="S2.SS1.p5.3.m3.1.1.2.cmml"><mi id="S2.SS1.p5.3.m3.1.1.2.2" xref="S2.SS1.p5.3.m3.1.1.2.2.cmml">𝐛</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS1.p5.3.m3.1.1.2.3" xref="S2.SS1.p5.3.m3.1.1.2.3a.cmml">in</mtext></msub><mo id="S2.SS1.p5.3.m3.1.1.1" xref="S2.SS1.p5.3.m3.1.1.1.cmml">=</mo><mn id="S2.SS1.p5.3.m3.1.1.3" xref="S2.SS1.p5.3.m3.1.1.3.cmml">0</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.3.m3.1b"><apply id="S2.SS1.p5.3.m3.1.1.cmml" xref="S2.SS1.p5.3.m3.1.1"><eq id="S2.SS1.p5.3.m3.1.1.1.cmml" xref="S2.SS1.p5.3.m3.1.1.1"></eq><apply id="S2.SS1.p5.3.m3.1.1.2.cmml" xref="S2.SS1.p5.3.m3.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p5.3.m3.1.1.2.1.cmml" xref="S2.SS1.p5.3.m3.1.1.2">subscript</csymbol><ci id="S2.SS1.p5.3.m3.1.1.2.2.cmml" xref="S2.SS1.p5.3.m3.1.1.2.2">𝐛</ci><ci id="S2.SS1.p5.3.m3.1.1.2.3a.cmml" xref="S2.SS1.p5.3.m3.1.1.2.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS1.p5.3.m3.1.1.2.3.cmml" xref="S2.SS1.p5.3.m3.1.1.2.3">in</mtext></ci></apply><cn type="integer" id="S2.SS1.p5.3.m3.1.1.3.cmml" xref="S2.SS1.p5.3.m3.1.1.3">0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.3.m3.1c">\mathbf{b}_{\text{\tiny{in}}}=0</annotation></semantics></math> and <math id="S2.SS1.p5.4.m4.1" class="ltx_Math" alttext="\mathbf{w}_{\text{\tiny{in}}}=1" display="inline"><semantics id="S2.SS1.p5.4.m4.1a"><mrow id="S2.SS1.p5.4.m4.1.1" xref="S2.SS1.p5.4.m4.1.1.cmml"><msub id="S2.SS1.p5.4.m4.1.1.2" xref="S2.SS1.p5.4.m4.1.1.2.cmml"><mi id="S2.SS1.p5.4.m4.1.1.2.2" xref="S2.SS1.p5.4.m4.1.1.2.2.cmml">𝐰</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS1.p5.4.m4.1.1.2.3" xref="S2.SS1.p5.4.m4.1.1.2.3a.cmml">in</mtext></msub><mo id="S2.SS1.p5.4.m4.1.1.1" xref="S2.SS1.p5.4.m4.1.1.1.cmml">=</mo><mn id="S2.SS1.p5.4.m4.1.1.3" xref="S2.SS1.p5.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.4.m4.1b"><apply id="S2.SS1.p5.4.m4.1.1.cmml" xref="S2.SS1.p5.4.m4.1.1"><eq id="S2.SS1.p5.4.m4.1.1.1.cmml" xref="S2.SS1.p5.4.m4.1.1.1"></eq><apply id="S2.SS1.p5.4.m4.1.1.2.cmml" xref="S2.SS1.p5.4.m4.1.1.2"><csymbol cd="ambiguous" id="S2.SS1.p5.4.m4.1.1.2.1.cmml" xref="S2.SS1.p5.4.m4.1.1.2">subscript</csymbol><ci id="S2.SS1.p5.4.m4.1.1.2.2.cmml" xref="S2.SS1.p5.4.m4.1.1.2.2">𝐰</ci><ci id="S2.SS1.p5.4.m4.1.1.2.3a.cmml" xref="S2.SS1.p5.4.m4.1.1.2.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS1.p5.4.m4.1.1.2.3.cmml" xref="S2.SS1.p5.4.m4.1.1.2.3">in</mtext></ci></apply><cn type="integer" id="S2.SS1.p5.4.m4.1.1.3.cmml" xref="S2.SS1.p5.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.4.m4.1c">\mathbf{w}_{\text{\tiny{in}}}=1</annotation></semantics></math>. Similarly, we can define <math id="S2.SS1.p5.5.m5.2" class="ltx_Math" alttext="f_{\text{\tiny{out}}}(\mathbf{y})=(\mathbf{y}+\mathbf{b}_{\text{\tiny{out}}})\odot\mathbf{w}_{\text{\tiny{out}}}" display="inline"><semantics id="S2.SS1.p5.5.m5.2a"><mrow id="S2.SS1.p5.5.m5.2.2" xref="S2.SS1.p5.5.m5.2.2.cmml"><mrow id="S2.SS1.p5.5.m5.2.2.3" xref="S2.SS1.p5.5.m5.2.2.3.cmml"><msub id="S2.SS1.p5.5.m5.2.2.3.2" xref="S2.SS1.p5.5.m5.2.2.3.2.cmml"><mi id="S2.SS1.p5.5.m5.2.2.3.2.2" xref="S2.SS1.p5.5.m5.2.2.3.2.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS1.p5.5.m5.2.2.3.2.3" xref="S2.SS1.p5.5.m5.2.2.3.2.3a.cmml">out</mtext></msub><mo lspace="0em" rspace="0em" id="S2.SS1.p5.5.m5.2.2.3.1" xref="S2.SS1.p5.5.m5.2.2.3.1.cmml">​</mo><mrow id="S2.SS1.p5.5.m5.2.2.3.3.2" xref="S2.SS1.p5.5.m5.2.2.3.cmml"><mo stretchy="false" id="S2.SS1.p5.5.m5.2.2.3.3.2.1" xref="S2.SS1.p5.5.m5.2.2.3.cmml">(</mo><mi id="S2.SS1.p5.5.m5.1.1" xref="S2.SS1.p5.5.m5.1.1.cmml">𝐲</mi><mo stretchy="false" id="S2.SS1.p5.5.m5.2.2.3.3.2.2" xref="S2.SS1.p5.5.m5.2.2.3.cmml">)</mo></mrow></mrow><mo id="S2.SS1.p5.5.m5.2.2.2" xref="S2.SS1.p5.5.m5.2.2.2.cmml">=</mo><mrow id="S2.SS1.p5.5.m5.2.2.1" xref="S2.SS1.p5.5.m5.2.2.1.cmml"><mrow id="S2.SS1.p5.5.m5.2.2.1.1.1" xref="S2.SS1.p5.5.m5.2.2.1.1.1.1.cmml"><mo stretchy="false" id="S2.SS1.p5.5.m5.2.2.1.1.1.2" xref="S2.SS1.p5.5.m5.2.2.1.1.1.1.cmml">(</mo><mrow id="S2.SS1.p5.5.m5.2.2.1.1.1.1" xref="S2.SS1.p5.5.m5.2.2.1.1.1.1.cmml"><mi id="S2.SS1.p5.5.m5.2.2.1.1.1.1.2" xref="S2.SS1.p5.5.m5.2.2.1.1.1.1.2.cmml">𝐲</mi><mo id="S2.SS1.p5.5.m5.2.2.1.1.1.1.1" xref="S2.SS1.p5.5.m5.2.2.1.1.1.1.1.cmml">+</mo><msub id="S2.SS1.p5.5.m5.2.2.1.1.1.1.3" xref="S2.SS1.p5.5.m5.2.2.1.1.1.1.3.cmml"><mi id="S2.SS1.p5.5.m5.2.2.1.1.1.1.3.2" xref="S2.SS1.p5.5.m5.2.2.1.1.1.1.3.2.cmml">𝐛</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS1.p5.5.m5.2.2.1.1.1.1.3.3" xref="S2.SS1.p5.5.m5.2.2.1.1.1.1.3.3a.cmml">out</mtext></msub></mrow><mo rspace="0.055em" stretchy="false" id="S2.SS1.p5.5.m5.2.2.1.1.1.3" xref="S2.SS1.p5.5.m5.2.2.1.1.1.1.cmml">)</mo></mrow><mo rspace="0.222em" id="S2.SS1.p5.5.m5.2.2.1.2" xref="S2.SS1.p5.5.m5.2.2.1.2.cmml">⊙</mo><msub id="S2.SS1.p5.5.m5.2.2.1.3" xref="S2.SS1.p5.5.m5.2.2.1.3.cmml"><mi id="S2.SS1.p5.5.m5.2.2.1.3.2" xref="S2.SS1.p5.5.m5.2.2.1.3.2.cmml">𝐰</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS1.p5.5.m5.2.2.1.3.3" xref="S2.SS1.p5.5.m5.2.2.1.3.3a.cmml">out</mtext></msub></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.5.m5.2b"><apply id="S2.SS1.p5.5.m5.2.2.cmml" xref="S2.SS1.p5.5.m5.2.2"><eq id="S2.SS1.p5.5.m5.2.2.2.cmml" xref="S2.SS1.p5.5.m5.2.2.2"></eq><apply id="S2.SS1.p5.5.m5.2.2.3.cmml" xref="S2.SS1.p5.5.m5.2.2.3"><times id="S2.SS1.p5.5.m5.2.2.3.1.cmml" xref="S2.SS1.p5.5.m5.2.2.3.1"></times><apply id="S2.SS1.p5.5.m5.2.2.3.2.cmml" xref="S2.SS1.p5.5.m5.2.2.3.2"><csymbol cd="ambiguous" id="S2.SS1.p5.5.m5.2.2.3.2.1.cmml" xref="S2.SS1.p5.5.m5.2.2.3.2">subscript</csymbol><ci id="S2.SS1.p5.5.m5.2.2.3.2.2.cmml" xref="S2.SS1.p5.5.m5.2.2.3.2.2">𝑓</ci><ci id="S2.SS1.p5.5.m5.2.2.3.2.3a.cmml" xref="S2.SS1.p5.5.m5.2.2.3.2.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS1.p5.5.m5.2.2.3.2.3.cmml" xref="S2.SS1.p5.5.m5.2.2.3.2.3">out</mtext></ci></apply><ci id="S2.SS1.p5.5.m5.1.1.cmml" xref="S2.SS1.p5.5.m5.1.1">𝐲</ci></apply><apply id="S2.SS1.p5.5.m5.2.2.1.cmml" xref="S2.SS1.p5.5.m5.2.2.1"><csymbol cd="latexml" id="S2.SS1.p5.5.m5.2.2.1.2.cmml" xref="S2.SS1.p5.5.m5.2.2.1.2">direct-product</csymbol><apply id="S2.SS1.p5.5.m5.2.2.1.1.1.1.cmml" xref="S2.SS1.p5.5.m5.2.2.1.1.1"><plus id="S2.SS1.p5.5.m5.2.2.1.1.1.1.1.cmml" xref="S2.SS1.p5.5.m5.2.2.1.1.1.1.1"></plus><ci id="S2.SS1.p5.5.m5.2.2.1.1.1.1.2.cmml" xref="S2.SS1.p5.5.m5.2.2.1.1.1.1.2">𝐲</ci><apply id="S2.SS1.p5.5.m5.2.2.1.1.1.1.3.cmml" xref="S2.SS1.p5.5.m5.2.2.1.1.1.1.3"><csymbol cd="ambiguous" id="S2.SS1.p5.5.m5.2.2.1.1.1.1.3.1.cmml" xref="S2.SS1.p5.5.m5.2.2.1.1.1.1.3">subscript</csymbol><ci id="S2.SS1.p5.5.m5.2.2.1.1.1.1.3.2.cmml" xref="S2.SS1.p5.5.m5.2.2.1.1.1.1.3.2">𝐛</ci><ci id="S2.SS1.p5.5.m5.2.2.1.1.1.1.3.3a.cmml" xref="S2.SS1.p5.5.m5.2.2.1.1.1.1.3.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS1.p5.5.m5.2.2.1.1.1.1.3.3.cmml" xref="S2.SS1.p5.5.m5.2.2.1.1.1.1.3.3">out</mtext></ci></apply></apply><apply id="S2.SS1.p5.5.m5.2.2.1.3.cmml" xref="S2.SS1.p5.5.m5.2.2.1.3"><csymbol cd="ambiguous" id="S2.SS1.p5.5.m5.2.2.1.3.1.cmml" xref="S2.SS1.p5.5.m5.2.2.1.3">subscript</csymbol><ci id="S2.SS1.p5.5.m5.2.2.1.3.2.cmml" xref="S2.SS1.p5.5.m5.2.2.1.3.2">𝐰</ci><ci id="S2.SS1.p5.5.m5.2.2.1.3.3a.cmml" xref="S2.SS1.p5.5.m5.2.2.1.3.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS1.p5.5.m5.2.2.1.3.3.cmml" xref="S2.SS1.p5.5.m5.2.2.1.3.3">out</mtext></ci></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.5.m5.2c">f_{\text{\tiny{out}}}(\mathbf{y})=(\mathbf{y}+\mathbf{b}_{\text{\tiny{out}}})\odot\mathbf{w}_{\text{\tiny{out}}}</annotation></semantics></math>, with <math id="S2.SS1.p5.6.m6.2" class="ltx_Math" alttext="\mathbf{b}_{\text{\tiny{out}}},\mathbf{w}_{\text{\tiny{out}}}\in\mathbb{R}^{K}" display="inline"><semantics id="S2.SS1.p5.6.m6.2a"><mrow id="S2.SS1.p5.6.m6.2.2" xref="S2.SS1.p5.6.m6.2.2.cmml"><mrow id="S2.SS1.p5.6.m6.2.2.2.2" xref="S2.SS1.p5.6.m6.2.2.2.3.cmml"><msub id="S2.SS1.p5.6.m6.1.1.1.1.1" xref="S2.SS1.p5.6.m6.1.1.1.1.1.cmml"><mi id="S2.SS1.p5.6.m6.1.1.1.1.1.2" xref="S2.SS1.p5.6.m6.1.1.1.1.1.2.cmml">𝐛</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS1.p5.6.m6.1.1.1.1.1.3" xref="S2.SS1.p5.6.m6.1.1.1.1.1.3a.cmml">out</mtext></msub><mo id="S2.SS1.p5.6.m6.2.2.2.2.3" xref="S2.SS1.p5.6.m6.2.2.2.3.cmml">,</mo><msub id="S2.SS1.p5.6.m6.2.2.2.2.2" xref="S2.SS1.p5.6.m6.2.2.2.2.2.cmml"><mi id="S2.SS1.p5.6.m6.2.2.2.2.2.2" xref="S2.SS1.p5.6.m6.2.2.2.2.2.2.cmml">𝐰</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS1.p5.6.m6.2.2.2.2.2.3" xref="S2.SS1.p5.6.m6.2.2.2.2.2.3a.cmml">out</mtext></msub></mrow><mo id="S2.SS1.p5.6.m6.2.2.3" xref="S2.SS1.p5.6.m6.2.2.3.cmml">∈</mo><msup id="S2.SS1.p5.6.m6.2.2.4" xref="S2.SS1.p5.6.m6.2.2.4.cmml"><mi id="S2.SS1.p5.6.m6.2.2.4.2" xref="S2.SS1.p5.6.m6.2.2.4.2.cmml">ℝ</mi><mi id="S2.SS1.p5.6.m6.2.2.4.3" xref="S2.SS1.p5.6.m6.2.2.4.3.cmml">K</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.6.m6.2b"><apply id="S2.SS1.p5.6.m6.2.2.cmml" xref="S2.SS1.p5.6.m6.2.2"><in id="S2.SS1.p5.6.m6.2.2.3.cmml" xref="S2.SS1.p5.6.m6.2.2.3"></in><list id="S2.SS1.p5.6.m6.2.2.2.3.cmml" xref="S2.SS1.p5.6.m6.2.2.2.2"><apply id="S2.SS1.p5.6.m6.1.1.1.1.1.cmml" xref="S2.SS1.p5.6.m6.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.SS1.p5.6.m6.1.1.1.1.1.1.cmml" xref="S2.SS1.p5.6.m6.1.1.1.1.1">subscript</csymbol><ci id="S2.SS1.p5.6.m6.1.1.1.1.1.2.cmml" xref="S2.SS1.p5.6.m6.1.1.1.1.1.2">𝐛</ci><ci id="S2.SS1.p5.6.m6.1.1.1.1.1.3a.cmml" xref="S2.SS1.p5.6.m6.1.1.1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS1.p5.6.m6.1.1.1.1.1.3.cmml" xref="S2.SS1.p5.6.m6.1.1.1.1.1.3">out</mtext></ci></apply><apply id="S2.SS1.p5.6.m6.2.2.2.2.2.cmml" xref="S2.SS1.p5.6.m6.2.2.2.2.2"><csymbol cd="ambiguous" id="S2.SS1.p5.6.m6.2.2.2.2.2.1.cmml" xref="S2.SS1.p5.6.m6.2.2.2.2.2">subscript</csymbol><ci id="S2.SS1.p5.6.m6.2.2.2.2.2.2.cmml" xref="S2.SS1.p5.6.m6.2.2.2.2.2.2">𝐰</ci><ci id="S2.SS1.p5.6.m6.2.2.2.2.2.3a.cmml" xref="S2.SS1.p5.6.m6.2.2.2.2.2.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS1.p5.6.m6.2.2.2.2.2.3.cmml" xref="S2.SS1.p5.6.m6.2.2.2.2.2.3">out</mtext></ci></apply></list><apply id="S2.SS1.p5.6.m6.2.2.4.cmml" xref="S2.SS1.p5.6.m6.2.2.4"><csymbol cd="ambiguous" id="S2.SS1.p5.6.m6.2.2.4.1.cmml" xref="S2.SS1.p5.6.m6.2.2.4">superscript</csymbol><ci id="S2.SS1.p5.6.m6.2.2.4.2.cmml" xref="S2.SS1.p5.6.m6.2.2.4.2">ℝ</ci><ci id="S2.SS1.p5.6.m6.2.2.4.3.cmml" xref="S2.SS1.p5.6.m6.2.2.4.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.6.m6.2c">\mathbf{b}_{\text{\tiny{out}}},\mathbf{w}_{\text{\tiny{out}}}\in\mathbb{R}^{K}</annotation></semantics></math>. Furthermore, with only additional <math id="S2.SS1.p5.7.m7.1" class="ltx_Math" alttext="2D+2K" display="inline"><semantics id="S2.SS1.p5.7.m7.1a"><mrow id="S2.SS1.p5.7.m7.1.1" xref="S2.SS1.p5.7.m7.1.1.cmml"><mrow id="S2.SS1.p5.7.m7.1.1.2" xref="S2.SS1.p5.7.m7.1.1.2.cmml"><mn id="S2.SS1.p5.7.m7.1.1.2.2" xref="S2.SS1.p5.7.m7.1.1.2.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S2.SS1.p5.7.m7.1.1.2.1" xref="S2.SS1.p5.7.m7.1.1.2.1.cmml">​</mo><mi id="S2.SS1.p5.7.m7.1.1.2.3" xref="S2.SS1.p5.7.m7.1.1.2.3.cmml">D</mi></mrow><mo id="S2.SS1.p5.7.m7.1.1.1" xref="S2.SS1.p5.7.m7.1.1.1.cmml">+</mo><mrow id="S2.SS1.p5.7.m7.1.1.3" xref="S2.SS1.p5.7.m7.1.1.3.cmml"><mn id="S2.SS1.p5.7.m7.1.1.3.2" xref="S2.SS1.p5.7.m7.1.1.3.2.cmml">2</mn><mo lspace="0em" rspace="0em" id="S2.SS1.p5.7.m7.1.1.3.1" xref="S2.SS1.p5.7.m7.1.1.3.1.cmml">​</mo><mi id="S2.SS1.p5.7.m7.1.1.3.3" xref="S2.SS1.p5.7.m7.1.1.3.3.cmml">K</mi></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.SS1.p5.7.m7.1b"><apply id="S2.SS1.p5.7.m7.1.1.cmml" xref="S2.SS1.p5.7.m7.1.1"><plus id="S2.SS1.p5.7.m7.1.1.1.cmml" xref="S2.SS1.p5.7.m7.1.1.1"></plus><apply id="S2.SS1.p5.7.m7.1.1.2.cmml" xref="S2.SS1.p5.7.m7.1.1.2"><times id="S2.SS1.p5.7.m7.1.1.2.1.cmml" xref="S2.SS1.p5.7.m7.1.1.2.1"></times><cn type="integer" id="S2.SS1.p5.7.m7.1.1.2.2.cmml" xref="S2.SS1.p5.7.m7.1.1.2.2">2</cn><ci id="S2.SS1.p5.7.m7.1.1.2.3.cmml" xref="S2.SS1.p5.7.m7.1.1.2.3">𝐷</ci></apply><apply id="S2.SS1.p5.7.m7.1.1.3.cmml" xref="S2.SS1.p5.7.m7.1.1.3"><times id="S2.SS1.p5.7.m7.1.1.3.1.cmml" xref="S2.SS1.p5.7.m7.1.1.3.1"></times><cn type="integer" id="S2.SS1.p5.7.m7.1.1.3.2.cmml" xref="S2.SS1.p5.7.m7.1.1.3.2">2</cn><ci id="S2.SS1.p5.7.m7.1.1.3.3.cmml" xref="S2.SS1.p5.7.m7.1.1.3.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS1.p5.7.m7.1c">2D+2K</annotation></semantics></math> parameters, the memory cost is negligible.</p>
</div>
<div id="S2.SS1.p6" class="ltx_para">
<p id="S2.SS1.p6.1" class="ltx_p">At first glance, our approach appears analogous to the <span id="S2.SS1.p6.1.1" class="ltx_text ltx_font_italic">personalization layers</span> proposed by <cite class="ltx_cite ltx_citemacro_citet">Arivazhagan et al. [<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>. <span id="S2.SS1.p6.1.2" class="ltx_text ltx_font_typewriter">iFedAvg</span> differs however, in the purposeful placement and heavily restricted design of the layers which enable actionable insights to be extracted. Furthermore, this study does not solely analyze the personalization properties of the method, but focuses on revealing how the federated learning process deals with biases in underlying data as well as offering a means of compensating for them.</p>
</div>
</section>
<section id="S2.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.2 </span>Training</h3>

<div id="S2.SS2.p1" class="ltx_para">
<p id="S2.SS2.p1.3" class="ltx_p">Training <span id="S2.SS2.p1.3.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> does not differ substantially from <span id="S2.SS2.p1.3.2" class="ltx_text ltx_font_typewriter">FedAvg</span>. At each round, each client performs a local update using stochastic gradient descent (SGD) and locally retains the updates on <math id="S2.SS2.p1.1.m1.1" class="ltx_Math" alttext="f_{\text{\tiny{in}}}" display="inline"><semantics id="S2.SS2.p1.1.m1.1a"><msub id="S2.SS2.p1.1.m1.1.1" xref="S2.SS2.p1.1.m1.1.1.cmml"><mi id="S2.SS2.p1.1.m1.1.1.2" xref="S2.SS2.p1.1.m1.1.1.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS2.p1.1.m1.1.1.3" xref="S2.SS2.p1.1.m1.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.1.m1.1b"><apply id="S2.SS2.p1.1.m1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.1.m1.1.1.1.cmml" xref="S2.SS2.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS2.p1.1.m1.1.1.2.cmml" xref="S2.SS2.p1.1.m1.1.1.2">𝑓</ci><ci id="S2.SS2.p1.1.m1.1.1.3a.cmml" xref="S2.SS2.p1.1.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS2.p1.1.m1.1.1.3.cmml" xref="S2.SS2.p1.1.m1.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.1.m1.1c">f_{\text{\tiny{in}}}</annotation></semantics></math> and <math id="S2.SS2.p1.2.m2.1" class="ltx_Math" alttext="f_{\text{\tiny{out}}}" display="inline"><semantics id="S2.SS2.p1.2.m2.1a"><msub id="S2.SS2.p1.2.m2.1.1" xref="S2.SS2.p1.2.m2.1.1.cmml"><mi id="S2.SS2.p1.2.m2.1.1.2" xref="S2.SS2.p1.2.m2.1.1.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS2.p1.2.m2.1.1.3" xref="S2.SS2.p1.2.m2.1.1.3a.cmml">out</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.2.m2.1b"><apply id="S2.SS2.p1.2.m2.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.2.m2.1.1.1.cmml" xref="S2.SS2.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS2.p1.2.m2.1.1.2.cmml" xref="S2.SS2.p1.2.m2.1.1.2">𝑓</ci><ci id="S2.SS2.p1.2.m2.1.1.3a.cmml" xref="S2.SS2.p1.2.m2.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS2.p1.2.m2.1.1.3.cmml" xref="S2.SS2.p1.2.m2.1.1.3">out</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.2.m2.1c">f_{\text{\tiny{out}}}</annotation></semantics></math>. Updates for all weights of <math id="S2.SS2.p1.3.m3.1" class="ltx_Math" alttext="f_{\text{\tiny{shared}}}" display="inline"><semantics id="S2.SS2.p1.3.m3.1a"><msub id="S2.SS2.p1.3.m3.1.1" xref="S2.SS2.p1.3.m3.1.1.cmml"><mi id="S2.SS2.p1.3.m3.1.1.2" xref="S2.SS2.p1.3.m3.1.1.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS2.p1.3.m3.1.1.3" xref="S2.SS2.p1.3.m3.1.1.3a.cmml">shared</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS2.p1.3.m3.1b"><apply id="S2.SS2.p1.3.m3.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1"><csymbol cd="ambiguous" id="S2.SS2.p1.3.m3.1.1.1.cmml" xref="S2.SS2.p1.3.m3.1.1">subscript</csymbol><ci id="S2.SS2.p1.3.m3.1.1.2.cmml" xref="S2.SS2.p1.3.m3.1.1.2">𝑓</ci><ci id="S2.SS2.p1.3.m3.1.1.3a.cmml" xref="S2.SS2.p1.3.m3.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS2.p1.3.m3.1.1.3.cmml" xref="S2.SS2.p1.3.m3.1.1.3">shared</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS2.p1.3.m3.1c">f_{\text{\tiny{shared}}}</annotation></semantics></math> are disclosed to the server, which performs the standard <span id="S2.SS2.p1.3.3" class="ltx_text ltx_font_typewriter">FedAvg</span> aggregation step and broadcasts the new shared weights to all clients.</p>
</div>
<div id="S2.SS2.p2" class="ltx_para">
<p id="S2.SS2.p2.1" class="ltx_p">This procedure is significantly more efficient than other related personalization methods such as <span id="S2.SS2.p2.1.1" class="ltx_text ltx_font_typewriter">APFL</span> or <span id="S2.SS2.p2.1.2" class="ltx_text ltx_font_typewriter">Per-FedAvg</span>. From a performance perspective, neither a second backpropagation or a Hessian, respectively, need to be computed. A single iteration of SGD is able to update the entire <span id="S2.SS2.p2.1.3" class="ltx_text ltx_font_italic">combined</span> model at once. Furthermore, only a single copy of the network needs to be stored, which reduces the storage demands on each client, compared to <span id="S2.SS2.p2.1.4" class="ltx_text ltx_font_typewriter">APFL</span>.</p>
</div>
<div id="S2.SS2.p3" class="ltx_para">
<p id="S2.SS2.p3.1" class="ltx_p">Intuitively, these layers allow each client to learn a feature-shift as well as target-shift, with respect to the federation. As the central block of the neural network is shared, and therefore identical for each client, the personalized layers can be seen as learning the necessary transformation from the underlying private data to the model of the federation.</p>
</div>
</section>
<section id="S2.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">2.3 </span>Interpretable outputs</h3>

<div id="S2.SS3.p1" class="ltx_para">
<p id="S2.SS3.p1.2" class="ltx_p">The cornerstone of the interpretability of <span id="S2.SS3.p1.2.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> is the personalized layer design. The layers learn the local shifts necessary to be able to utilize the shared model block of the federation. Each client can, therefore, adjust their <span id="S2.SS3.p1.2.2" class="ltx_text ltx_font_italic">combined</span> model in a very restricted sense. This restriction-by-design means that each individual value in <math id="S2.SS3.p1.1.m1.1" class="ltx_Math" alttext="f_{\text{\tiny{in}}}" display="inline"><semantics id="S2.SS3.p1.1.m1.1a"><msub id="S2.SS3.p1.1.m1.1.1" xref="S2.SS3.p1.1.m1.1.1.cmml"><mi id="S2.SS3.p1.1.m1.1.1.2" xref="S2.SS3.p1.1.m1.1.1.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS3.p1.1.m1.1.1.3" xref="S2.SS3.p1.1.m1.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.1.m1.1b"><apply id="S2.SS3.p1.1.m1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.1.m1.1.1.1.cmml" xref="S2.SS3.p1.1.m1.1.1">subscript</csymbol><ci id="S2.SS3.p1.1.m1.1.1.2.cmml" xref="S2.SS3.p1.1.m1.1.1.2">𝑓</ci><ci id="S2.SS3.p1.1.m1.1.1.3a.cmml" xref="S2.SS3.p1.1.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS3.p1.1.m1.1.1.3.cmml" xref="S2.SS3.p1.1.m1.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.1.m1.1c">f_{\text{\tiny{in}}}</annotation></semantics></math> and <math id="S2.SS3.p1.2.m2.1" class="ltx_Math" alttext="f_{\text{\tiny{out}}}" display="inline"><semantics id="S2.SS3.p1.2.m2.1a"><msub id="S2.SS3.p1.2.m2.1.1" xref="S2.SS3.p1.2.m2.1.1.cmml"><mi id="S2.SS3.p1.2.m2.1.1.2" xref="S2.SS3.p1.2.m2.1.1.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S2.SS3.p1.2.m2.1.1.3" xref="S2.SS3.p1.2.m2.1.1.3a.cmml">out</mtext></msub><annotation-xml encoding="MathML-Content" id="S2.SS3.p1.2.m2.1b"><apply id="S2.SS3.p1.2.m2.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1"><csymbol cd="ambiguous" id="S2.SS3.p1.2.m2.1.1.1.cmml" xref="S2.SS3.p1.2.m2.1.1">subscript</csymbol><ci id="S2.SS3.p1.2.m2.1.1.2.cmml" xref="S2.SS3.p1.2.m2.1.1.2">𝑓</ci><ci id="S2.SS3.p1.2.m2.1.1.3a.cmml" xref="S2.SS3.p1.2.m2.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S2.SS3.p1.2.m2.1.1.3.cmml" xref="S2.SS3.p1.2.m2.1.1.3">out</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.SS3.p1.2.m2.1c">f_{\text{\tiny{out}}}</annotation></semantics></math> is directly interpretable.</p>
</div>
<div id="S2.SS3.p2" class="ltx_para">
<p id="S2.SS3.p2.1" class="ltx_p">For instance, following the example above, if the age of patients varies from client to client, clients are, at first, indistinguishable after standardization. With our method, however, the necessary personalized age shift can be learned seamlessly throughout the process and can be learned to correctly predict the diagnosis. The magnitude and direction of this shift is, by design, tied directly to the input feature, and provides unparalleled insights about each participant of the federation without sharing any original data.</p>
</div>
<div id="S2.SS3.p3" class="ltx_para">
<p id="S2.SS3.p3.1" class="ltx_p">A crucial distinction must be made between our method and comparing the underlying data distribution a-priori. Exchanging the datasets’ summary statistics can be a useful way to diagnose interoperability, but is limited in three critical ways. First, every feature must be analyzed for every client - in practice the needed effort might render this impossible. Second, revealing summary statistics might still be problematic from a data privacy perspective - personalized model weights are more secure in that regard. Third, <span id="S2.SS3.p3.1.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> only learns <span id="S2.SS3.p3.1.2" class="ltx_text ltx_font_italic">necessary</span> shifts which aid model performance, eliminating the necessity to investigate potential shifts for insignificant features.</p>
</div>
<div id="S2.SS3.p4" class="ltx_para">
<p id="S2.SS3.p4.1" class="ltx_p">The final step of our proposed architecture is a communication of the learned shifts to stakeholders. Large compensations could be an indicator of critical differences in data collection, calibration, missingness-not-at-random or otherwise. A decision on whether this means a client’s dataset is incompatible or, with the shift-adjustment, is suitable is left to domain experts. <span id="S2.SS3.p4.1.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> strives to be the best tool to make an informed decision for which clients and features to include in their federation. Significant deviations could then also allow targeted queries between users to better guide collaboration.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Federated Ebola dataset</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">The 2014-16 Ebola Virus Disease (EVD) epidemic in West Africa revealed the devastating consequences of inadequate data sharing during public health emergencies. Delays and poorly compatible datasets were held directly responsible for the slow response to the outbreak, ultimately exacerbating the epidemic <cite class="ltx_cite ltx_citemacro_citet">Georgetown University Medical Center [<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>.
In response, the Infectious Disease Data Observatory (IDDO) was established to collate and align the fragmented and poorly interoperable datasets into the largest central repository of Ebola data in the world (i.e., the Ebola Data Platform, EDP) to facilitate coordinated research <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">The commendable EDP initiative necessitated a laborious process of acquiring ethical approval as well as devising a common data sharing protocol. While this was ultimately highly successful, it took several years before being made available to researchers in 2019, well after it would have been useful in forming an evidence-based response to the crisis. Thus, the EDP is an ideal real-world use-case for exploring the potential of an interoperability-adjusted federated learning approach with the end goal of enabling secure real-time model sharing in rapidly evolving public health emergencies which suffer from poor response coordination.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">The EDP comprises tabular clinical data on 13552 anonymized patients treated at 16 Ebola Treatment Centres (ETCs) between January 2014 and December 2015. The ETCs were scattered across the three main affected countries of Sierra Leone, Guinea and Liberia which differ in language, geography, epidemiology, demographics and treatment protocols. Thus, there is high risk for bias ranging from natural variation (e.g., malaria prevalence) to measurement errors (e.g., different tools/protocols to quantify viral load) and misattribution (e.g., mislabelling or poor standardization) and variable missingness.
The collected data includes both categorical and continuous features such as demographic details (e.g., age, sex, location), clinical signs and symptoms (e.g., fever, coughing, headache), laboratory values (e.g., Ebola test results and quantitation of viral load) and outcomes for each patient (e.g., death vs recovery). Research on such data is often focused on making diagnostic and prognostic models to better allocate limited resources to the most critical patients and improve early case identification <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>, <a href="#bib.bib10" title="" class="ltx_ref">10</a>, <a href="#bib.bib3" title="" class="ltx_ref">3</a>, <a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p">However, these studies were performed on single datasets where statistical power is diluted in the small numbers of included patients.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.1" class="ltx_p">As a proof of concept, we replicate these studies, by learning diagnostic and prognostic classification tasks (respectively, EVD negative vs EVD positive and survival vs death in EVD positive cases). Here, the ETC site represents a client with its locally collected dataset and we thus explore the potential of <span id="S3.p5.1.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> to create a robust personalized predictive model while detecting and compensating for known interoperability issues between sites.</p>
</div>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.1" class="ltx_p">The ethical framework and anonymization protocols are published on the IDDO website <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. We provide further details such as sample sizes and class imbalance in Appendix <a href="#A1.SS5" title="A.5 Ebola dataset statistics ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.5</span></a>.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experimental design</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p"><span id="S4.p1.1.1" class="ltx_text ltx_font_bold">Evaluation</span>. To fairly evaluate <span id="S4.p1.1.2" class="ltx_text ltx_font_typewriter">iFedAvg</span>, we compare it to several state-of-the-art methods which have similar aims, and explore their limitations in a standardized realistic setting. Specifically, each client can choose to not partake in the federation, and simply train a local model. Likewise, vanilla federated averaging, <span id="S4.p1.1.3" class="ltx_text ltx_font_typewriter">FedAvg</span> is a valuable benchmark, as well as a more sophisticated personalized federated algorithm such as Adaptive Personalized Federated Learning, <span id="S4.p1.1.4" class="ltx_text ltx_font_typewriter">APFL</span>, proposed by <cite class="ltx_cite ltx_citemacro_citet">Deng et al. [<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>. An interesting non-personalized baseline is a single model trained on a centralized concatenation of all clients’ datasets (called in the following the Centralized method). While this is not a realistic scenario, it is currently the yardstick of many large scale data sharing efforts such as IDDO, which makes it a particularly appropriate benchmark for the Ebola dataset.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">Four datasets will serve as the foundation of our experiments:</p>
<ul id="S4.I1" class="ltx_itemize">
<li id="S4.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i1.p1" class="ltx_para">
<p id="S4.I1.i1.p1.1" class="ltx_p"><span id="S4.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Ebola Prognosis:</span> Predicting the survival of EVD-positive patients; <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i2.p1" class="ltx_para">
<p id="S4.I1.i2.p1.1" class="ltx_p"><span id="S4.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Ebola Diagnosis:</span> Predicting whether a patient triaged as "suspect" has EVD; <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>.</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i3.p1" class="ltx_para">
<p id="S4.I1.i3.p1.1" class="ltx_p"><span id="S4.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Vehicle Classification with Sensor Network (VSN):</span> Classifying the type of vehicle based on a network of 23 acoustic and seismic sensors; <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.</p>
</div>
</li>
<li id="S4.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S4.I1.i4.p1" class="ltx_para">
<p id="S4.I1.i4.p1.1" class="ltx_p"><span id="S4.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Human Activity Recognition (HAR):</span> Classifying the type of activity performed by 30 human subjects according to readings from body sensors; <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite>.</p>
</div>
</li>
</ul>
<p id="S4.p2.2" class="ltx_p">Every method outlined above is trained on each dataset, with each client retaining 33% or minimally 100 samples of its local data as a hold-out test. Performance metrics are computed locally on this hold-out set, retaining an understanding of personalized performance.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p"><span id="S4.p3.1.1" class="ltx_text ltx_font_bold">Preprocessing &amp; missing values</span>. The experimental setting assumes semantic interoperability, meaning all client datasets were aligned in feature nomenclature. All numerical values are standardized to mean 0 and standard deviation 1. In order to include missingness as an assessed feature of interoperability (i.e., to detect whether the bias is due to non-random missing values), missing continuous values were filled with 0s, binary features with the value 0.5 following standardization.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.2" class="ltx_p"><span id="S4.p4.2.1" class="ltx_text ltx_font_bold">Architecture</span>. For every method, an MLP model with identical architecture is used, only modifying the training regime for each algorithm. In the main experimental results we only enable <math id="S4.p4.1.m1.1" class="ltx_Math" alttext="f_{\text{\tiny{in}}}" display="inline"><semantics id="S4.p4.1.m1.1a"><msub id="S4.p4.1.m1.1.1" xref="S4.p4.1.m1.1.1.cmml"><mi id="S4.p4.1.m1.1.1.2" xref="S4.p4.1.m1.1.1.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S4.p4.1.m1.1.1.3" xref="S4.p4.1.m1.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.p4.1.m1.1b"><apply id="S4.p4.1.m1.1.1.cmml" xref="S4.p4.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p4.1.m1.1.1.1.cmml" xref="S4.p4.1.m1.1.1">subscript</csymbol><ci id="S4.p4.1.m1.1.1.2.cmml" xref="S4.p4.1.m1.1.1.2">𝑓</ci><ci id="S4.p4.1.m1.1.1.3a.cmml" xref="S4.p4.1.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S4.p4.1.m1.1.1.3.cmml" xref="S4.p4.1.m1.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.1.m1.1c">f_{\text{\tiny{in}}}</annotation></semantics></math> to investigate feature-shifts. For results and a thorough discussion of <span id="S4.p4.2.2" class="ltx_text ltx_font_typewriter">iFedAvg</span> with <math id="S4.p4.2.m2.1" class="ltx_Math" alttext="f_{\text{\tiny{out}}}" display="inline"><semantics id="S4.p4.2.m2.1a"><msub id="S4.p4.2.m2.1.1" xref="S4.p4.2.m2.1.1.cmml"><mi id="S4.p4.2.m2.1.1.2" xref="S4.p4.2.m2.1.1.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S4.p4.2.m2.1.1.3" xref="S4.p4.2.m2.1.1.3a.cmml">out</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.p4.2.m2.1b"><apply id="S4.p4.2.m2.1.1.cmml" xref="S4.p4.2.m2.1.1"><csymbol cd="ambiguous" id="S4.p4.2.m2.1.1.1.cmml" xref="S4.p4.2.m2.1.1">subscript</csymbol><ci id="S4.p4.2.m2.1.1.2.cmml" xref="S4.p4.2.m2.1.1.2">𝑓</ci><ci id="S4.p4.2.m2.1.1.3a.cmml" xref="S4.p4.2.m2.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S4.p4.2.m2.1.1.3.cmml" xref="S4.p4.2.m2.1.1.3">out</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.2.m2.1c">f_{\text{\tiny{out}}}</annotation></semantics></math>, we refer to Appendix <a href="#A1.SS4" title="A.4 Target shift layer ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.4</span></a>.</p>
</div>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.1" class="ltx_p"><span id="S4.p5.1.1" class="ltx_text ltx_font_bold">Training</span>. Each round, every client performs one training epoch on the local training data, with a weighted loss to account for class imbalance. For the shared part of the model, <math id="S4.p5.1.m1.1" class="ltx_Math" alttext="f_{\text{\tiny{shared}}}" display="inline"><semantics id="S4.p5.1.m1.1a"><msub id="S4.p5.1.m1.1.1" xref="S4.p5.1.m1.1.1.cmml"><mi id="S4.p5.1.m1.1.1.2" xref="S4.p5.1.m1.1.1.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S4.p5.1.m1.1.1.3" xref="S4.p5.1.m1.1.1.3a.cmml">shared</mtext></msub><annotation-xml encoding="MathML-Content" id="S4.p5.1.m1.1b"><apply id="S4.p5.1.m1.1.1.cmml" xref="S4.p5.1.m1.1.1"><csymbol cd="ambiguous" id="S4.p5.1.m1.1.1.1.cmml" xref="S4.p5.1.m1.1.1">subscript</csymbol><ci id="S4.p5.1.m1.1.1.2.cmml" xref="S4.p5.1.m1.1.1.2">𝑓</ci><ci id="S4.p5.1.m1.1.1.3a.cmml" xref="S4.p5.1.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S4.p5.1.m1.1.1.3.cmml" xref="S4.p5.1.m1.1.1.3">shared</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p5.1.m1.1c">f_{\text{\tiny{shared}}}</annotation></semantics></math>, uniform weighting of the updates across clients is performed. Every experiment is conducted on the same 5 random seeds, leading to identical initialization and train-test splitting. The code, implemented in PyTorch <cite class="ltx_cite ltx_citemacro_citep">[<a href="#bib.bib21" title="" class="ltx_ref">21</a>]</cite>, replicating the results on the public datasets, are available in a public code repository.<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span><a target="_blank" href="https://github.com/davidroschewitz/ifedavg" title="" class="ltx_ref ltx_href ltx_font_typewriter">github.com/davidroschewitz/ifedavg</a></span></span></span> Further details on the hyperparameters, pre-processing and the model architecture can be found in Appendix <a href="#A1.SS3" title="A.3 Hyperparameters and experimental setup ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.3</span></a>.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>

<section id="S5.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.1 </span>Performance</h3>

<div id="S5.SS1.p1" class="ltx_para">
<p id="S5.SS1.p1.1" class="ltx_p">From the perspective of a client choosing whether to participate in the federation, predictive performance is critical. In particular, attaining a collaborative model <span id="S5.SS1.p1.1.1" class="ltx_text ltx_font_italic">worse</span> than a locally trained one virtually rules out participation. Therefore, two aspects are interesting: the average metric across all clients and the worst-performing client in the federation.</p>
</div>
<div id="S5.SS1.p2" class="ltx_para">
<p id="S5.SS1.p2.1" class="ltx_p">Holistically, <span id="S5.SS1.p2.1.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> shows competitive performance compared with a state-of-the-art benchmark in distributed personalized learning algorithm, <span id="S5.SS1.p2.1.2" class="ltx_text ltx_font_typewriter">APFL</span>, and even outperforms both <span id="S5.SS1.p2.1.3" class="ltx_text ltx_font_typewriter">APFL</span>, local and centralized training in several instances. As anticipated, in the case of heterogeneous or non-IID datasets, such as Ebola diagnosis and VSN, <span id="S5.SS1.p2.1.4" class="ltx_text ltx_font_typewriter">iFedAvg</span> vastly outperforms <span id="S5.SS1.p2.1.5" class="ltx_text ltx_font_typewriter">FedAvg</span>. Personalization appears important to adapt to these settings. Table <a href="#S5.T1" title="Table 1 ‣ 5.1 Performance ‣ 5 Results ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the average F1 score for each dataset and algorithm.</p>
</div>
<figure id="S5.T1" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 1: </span>Mean (across all clients) performance (F1 score)</figcaption>
<table id="S5.T1.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T1.1.1.1" class="ltx_tr">
<th id="S5.T1.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S5.T1.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4">Method</th>
<td id="S5.T1.1.1.1.3" class="ltx_td ltx_border_tt"></td>
</tr>
<tr id="S5.T1.1.2.2" class="ltx_tr">
<th id="S5.T1.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row">Dataset</th>
<th id="S5.T1.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<span id="S5.T1.1.2.2.2.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> (ours)</th>
<th id="S5.T1.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.1.2.2.3.1" class="ltx_text ltx_font_typewriter">APFL</span></th>
<th id="S5.T1.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T1.1.2.2.4.1" class="ltx_text ltx_font_typewriter">FedAvg</span></th>
<th id="S5.T1.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Local</th>
<th id="S5.T1.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Centralized</th>
</tr>
<tr id="S5.T1.1.3.3" class="ltx_tr">
<th id="S5.T1.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Ebola Prognosis</th>
<td id="S5.T1.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t">0.669</td>
<td id="S5.T1.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t">0.653</td>
<td id="S5.T1.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t">0.670</td>
<td id="S5.T1.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t">0.662</td>
<td id="S5.T1.1.3.3.6" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T1.1.3.3.6.1" class="ltx_text ltx_font_bold">0.673</span></td>
</tr>
<tr id="S5.T1.1.4.4" class="ltx_tr">
<th id="S5.T1.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ebola Diagnosis</th>
<td id="S5.T1.1.4.4.2" class="ltx_td ltx_align_center"><span id="S5.T1.1.4.4.2.1" class="ltx_text ltx_font_bold">0.867</span></td>
<td id="S5.T1.1.4.4.3" class="ltx_td ltx_align_center">0.828</td>
<td id="S5.T1.1.4.4.4" class="ltx_td ltx_align_center">0.773</td>
<td id="S5.T1.1.4.4.5" class="ltx_td ltx_align_center">0.844</td>
<td id="S5.T1.1.4.4.6" class="ltx_td ltx_align_center">0.861</td>
</tr>
<tr id="S5.T1.1.5.5" class="ltx_tr">
<th id="S5.T1.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Vehicle Sensor Network</th>
<td id="S5.T1.1.5.5.2" class="ltx_td ltx_align_center">0.928</td>
<td id="S5.T1.1.5.5.3" class="ltx_td ltx_align_center">0.935</td>
<td id="S5.T1.1.5.5.4" class="ltx_td ltx_align_center">0.871</td>
<td id="S5.T1.1.5.5.5" class="ltx_td ltx_align_center">0.939</td>
<td id="S5.T1.1.5.5.6" class="ltx_td ltx_align_center"><span id="S5.T1.1.5.5.6.1" class="ltx_text ltx_font_bold">0.943</span></td>
</tr>
<tr id="S5.T1.1.6.6" class="ltx_tr">
<th id="S5.T1.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Human Activity Recognition</th>
<td id="S5.T1.1.6.6.2" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T1.1.6.6.2.1" class="ltx_text ltx_font_bold">0.994</span></td>
<td id="S5.T1.1.6.6.3" class="ltx_td ltx_align_center ltx_border_bb">0.992</td>
<td id="S5.T1.1.6.6.4" class="ltx_td ltx_align_center ltx_border_bb">0.967</td>
<td id="S5.T1.1.6.6.5" class="ltx_td ltx_align_center ltx_border_bb">0.993</td>
<td id="S5.T1.1.6.6.6" class="ltx_td ltx_align_center ltx_border_bb">0.988</td>
</tr>
</tbody>
</table>
</figure>
<div id="S5.SS1.p3" class="ltx_para">
<p id="S5.SS1.p3.1" class="ltx_p">Analyzing the worst-performing client highlights the low tail of the performance distribution. In Table <a href="#S5.T2" title="Table 2 ‣ 5.1 Performance ‣ 5 Results ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> we can observe that <span id="S5.SS1.p3.1.1" class="ltx_text ltx_font_typewriter">FedAvg</span> performs especially poorly in this worst case. Intuitively, the client with a significantly shifted data distribution is <span id="S5.SS1.p3.1.2" class="ltx_text ltx_font_italic">forced</span> to share the same global model, leading to inferior performance. This experiment highlights that <span id="S5.SS1.p3.1.3" class="ltx_text ltx_font_typewriter">iFedAvg</span> is an effective method to personalize collaborative learning and is especially robust for the worst performing client in the federation. Additional tables and visualizations highlighting the full distribution of client performances, seed variation and additional metrics can be found in Appendix <a href="#A1.SS1" title="A.1 Supplementary performance results ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.1</span></a>.</p>
</div>
<figure id="S5.T2" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 2: </span>Worst-performing client in federation (F1 score)</figcaption>
<table id="S5.T2.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="S5.T2.1.1.1" class="ltx_tr">
<th id="S5.T2.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="S5.T2.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4">Method</th>
<td id="S5.T2.1.1.1.3" class="ltx_td ltx_border_tt"></td>
</tr>
<tr id="S5.T2.1.2.2" class="ltx_tr">
<th id="S5.T2.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row">Dataset</th>
<th id="S5.T2.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<span id="S5.T2.1.2.2.2.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> (ours)</th>
<th id="S5.T2.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T2.1.2.2.3.1" class="ltx_text ltx_font_typewriter">APFL</span></th>
<th id="S5.T2.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="S5.T2.1.2.2.4.1" class="ltx_text ltx_font_typewriter">FedAvg</span></th>
<th id="S5.T2.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Local</th>
<th id="S5.T2.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Centralized</th>
</tr>
<tr id="S5.T2.1.3.3" class="ltx_tr">
<th id="S5.T2.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Ebola Prognosis</th>
<td id="S5.T2.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="S5.T2.1.3.3.2.1" class="ltx_text ltx_font_bold">0.581</span></td>
<td id="S5.T2.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t">0.546</td>
<td id="S5.T2.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t">0.575</td>
<td id="S5.T2.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t">0.560</td>
<td id="S5.T2.1.3.3.6" class="ltx_td ltx_align_center ltx_border_t">0.541</td>
</tr>
<tr id="S5.T2.1.4.4" class="ltx_tr">
<th id="S5.T2.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ebola Diagnosis</th>
<td id="S5.T2.1.4.4.2" class="ltx_td ltx_align_center"><span id="S5.T2.1.4.4.2.1" class="ltx_text ltx_font_bold">0.790</span></td>
<td id="S5.T2.1.4.4.3" class="ltx_td ltx_align_center">0.662</td>
<td id="S5.T2.1.4.4.4" class="ltx_td ltx_align_center">0.452</td>
<td id="S5.T2.1.4.4.5" class="ltx_td ltx_align_center">0.654</td>
<td id="S5.T2.1.4.4.6" class="ltx_td ltx_align_center">0.733</td>
</tr>
<tr id="S5.T2.1.5.5" class="ltx_tr">
<th id="S5.T2.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Vehicle Sensor Network</th>
<td id="S5.T2.1.5.5.2" class="ltx_td ltx_align_center">0.874</td>
<td id="S5.T2.1.5.5.3" class="ltx_td ltx_align_center">0.874</td>
<td id="S5.T2.1.5.5.4" class="ltx_td ltx_align_center">0.398</td>
<td id="S5.T2.1.5.5.5" class="ltx_td ltx_align_center"><span id="S5.T2.1.5.5.5.1" class="ltx_text ltx_font_bold">0.884</span></td>
<td id="S5.T2.1.5.5.6" class="ltx_td ltx_align_center">0.834</td>
</tr>
<tr id="S5.T2.1.6.6" class="ltx_tr">
<th id="S5.T2.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Human Activity Recognition</th>
<td id="S5.T2.1.6.6.2" class="ltx_td ltx_align_center ltx_border_bb">0.950</td>
<td id="S5.T2.1.6.6.3" class="ltx_td ltx_align_center ltx_border_bb">0.972</td>
<td id="S5.T2.1.6.6.4" class="ltx_td ltx_align_center ltx_border_bb">0.909</td>
<td id="S5.T2.1.6.6.5" class="ltx_td ltx_align_center ltx_border_bb"><span id="S5.T2.1.6.6.5.1" class="ltx_text ltx_font_bold">0.974</span></td>
<td id="S5.T2.1.6.6.6" class="ltx_td ltx_align_center ltx_border_bb">0.955</td>
</tr>
</tbody>
</table>
</figure>
</section>
<section id="S5.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">5.2 </span>Interpretability of <span id="S5.SS2.1.1" class="ltx_text ltx_font_typewriter">iFedAvg</span>
</h3>

<div id="S5.SS2.p1" class="ltx_para">
<p id="S5.SS2.p1.1" class="ltx_p">One of the key improvements our method provides is that each locally personalized layer is directly interpretable. While the absolute value of each weight does not itself imply an exact relationship with the underlying data, the magnitude, direction and, most importantly, the comparison with other clients’ local weights, provides unparalleled insights into the interoperabiltiy of the datasets in the federation.</p>
</div>
<div id="S5.SS2.p2" class="ltx_para">
<p id="S5.SS2.p2.2" class="ltx_p">For the most valuable interpretable results, all clients are assumed to be willing to share the weights of their locally trained personalized layers, <math id="S5.SS2.p2.1.m1.1" class="ltx_Math" alttext="\mathbf{b}_{\text{\tiny{in}}}" display="inline"><semantics id="S5.SS2.p2.1.m1.1a"><msub id="S5.SS2.p2.1.m1.1.1" xref="S5.SS2.p2.1.m1.1.1.cmml"><mi id="S5.SS2.p2.1.m1.1.1.2" xref="S5.SS2.p2.1.m1.1.1.2.cmml">𝐛</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S5.SS2.p2.1.m1.1.1.3" xref="S5.SS2.p2.1.m1.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.1.m1.1b"><apply id="S5.SS2.p2.1.m1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.1.m1.1.1.1.cmml" xref="S5.SS2.p2.1.m1.1.1">subscript</csymbol><ci id="S5.SS2.p2.1.m1.1.1.2.cmml" xref="S5.SS2.p2.1.m1.1.1.2">𝐛</ci><ci id="S5.SS2.p2.1.m1.1.1.3a.cmml" xref="S5.SS2.p2.1.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S5.SS2.p2.1.m1.1.1.3.cmml" xref="S5.SS2.p2.1.m1.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.1.m1.1c">\mathbf{b}_{\text{\tiny{in}}}</annotation></semantics></math> and <math id="S5.SS2.p2.2.m2.1" class="ltx_Math" alttext="\mathbf{w}_{\text{\tiny{in}}}" display="inline"><semantics id="S5.SS2.p2.2.m2.1a"><msub id="S5.SS2.p2.2.m2.1.1" xref="S5.SS2.p2.2.m2.1.1.cmml"><mi id="S5.SS2.p2.2.m2.1.1.2" xref="S5.SS2.p2.2.m2.1.1.2.cmml">𝐰</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S5.SS2.p2.2.m2.1.1.3" xref="S5.SS2.p2.2.m2.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.SS2.p2.2.m2.1b"><apply id="S5.SS2.p2.2.m2.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1"><csymbol cd="ambiguous" id="S5.SS2.p2.2.m2.1.1.1.cmml" xref="S5.SS2.p2.2.m2.1.1">subscript</csymbol><ci id="S5.SS2.p2.2.m2.1.1.2.cmml" xref="S5.SS2.p2.2.m2.1.1.2">𝐰</ci><ci id="S5.SS2.p2.2.m2.1.1.3a.cmml" xref="S5.SS2.p2.2.m2.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S5.SS2.p2.2.m2.1.1.3.cmml" xref="S5.SS2.p2.2.m2.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.SS2.p2.2.m2.1c">\mathbf{w}_{\text{\tiny{in}}}</annotation></semantics></math> for our experiments. In practice, this is a reasonable expectation, as raw data is not revealed and the insights might be critical for the clients.</p>
</div>
<div id="S5.SS2.p3" class="ltx_para">
<p id="S5.SS2.p3.1" class="ltx_p">In order to visually inspect the personalized shifts, we combine the weights into a heatmap for every feature and client to create a 2D matrix for each bias and weight. In the heatmap, we consider two types of shifts as <span id="S5.SS2.p3.1.1" class="ltx_text ltx_font_italic">significant</span>. First, when for a single feature, a client’s local weight differs from the mean by more than 2 standard deviations (SD). Second, if the average SD of a feature in question differs by more than 2 SD from the average SD across <span id="S5.SS2.p3.1.2" class="ltx_text ltx_font_italic">all features</span>.
We show an example of such a heatmap on the VSN dataset in Figure <a href="#S5.F2" title="Figure 2 ‣ 5.2 Interpretability of iFedAvg ‣ 5 Results ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, with the corresponding shift in the underlying data. Noteworthy is that our model detected the shift and indicated its direction without access to data of other clients, unlike the diagnosis histogram.</p>
</div>
<figure id="S5.F2" class="ltx_figure"><img src="/html/2107.06580/assets/x2.png" id="S5.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="456" height="207" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Input bias (<math id="S5.F2.2.m1.1" class="ltx_Math" alttext="\mathbf{b}_{\text{\tiny{in}}}" display="inline"><semantics id="S5.F2.2.m1.1b"><msub id="S5.F2.2.m1.1.1" xref="S5.F2.2.m1.1.1.cmml"><mi id="S5.F2.2.m1.1.1.2" xref="S5.F2.2.m1.1.1.2.cmml">𝐛</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S5.F2.2.m1.1.1.3" xref="S5.F2.2.m1.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.F2.2.m1.1c"><apply id="S5.F2.2.m1.1.1.cmml" xref="S5.F2.2.m1.1.1"><csymbol cd="ambiguous" id="S5.F2.2.m1.1.1.1.cmml" xref="S5.F2.2.m1.1.1">subscript</csymbol><ci id="S5.F2.2.m1.1.1.2.cmml" xref="S5.F2.2.m1.1.1.2">𝐛</ci><ci id="S5.F2.2.m1.1.1.3a.cmml" xref="S5.F2.2.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S5.F2.2.m1.1.1.3.cmml" xref="S5.F2.2.m1.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F2.2.m1.1d">\mathbf{b}_{\text{\tiny{in}}}</annotation></semantics></math>) heatmap across clients for the VSN dataset. A negative shift is detected for sensor number 5 in feature ‘0’ (left), which can be confirmed in the underlying distribution (right).</figcaption>
</figure>
<div id="S5.SS2.p4" class="ltx_para">
<p id="S5.SS2.p4.1" class="ltx_p">We further highlight the following examples of real-world shifts detected by our method:</p>
<ul id="S5.I1" class="ltx_itemize">
<li id="S5.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i1.p1" class="ltx_para">
<p id="S5.I1.i1.p1.1" class="ltx_p"><span id="S5.I1.i1.p1.1.1" class="ltx_text ltx_font_bold">Ebola Prognosis:</span> In Figure <a href="#S5.F3" title="Figure 3 ‣ 5.2 Interpretability of iFedAvg ‣ 5 Results ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, we show the heatmap for patient prognosis. Every client significantly modifies the <span id="S5.I1.i1.p1.1.2" class="ltx_text ltx_font_italic">CT Value</span> feature compared to other features. We can observe ETC Freetown’s distribution being more concentrated, and is therefore scaled by <span id="S5.I1.i1.p1.1.3" class="ltx_text ltx_font_typewriter">iFedAvg</span> to increase compatibility with the shared model.</p>
</div>
</li>
<li id="S5.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S5.I1.i2.p1" class="ltx_para">
<p id="S5.I1.i2.p1.1" class="ltx_p"><span id="S5.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Ebola Diagnosis:</span> Similarly, we can observe effects for categorical differences. Figure <a href="#S5.F4" title="Figure 4 ‣ 5.2 Interpretability of iFedAvg ‣ 5 Results ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> highlights that for ETC Foya, having the symptom of diarrhea is a clear indicator of positive Ebola infection (right in Figure). However this is confounded by systematic missingness for the diarrhea feature amongst EVD negative patients. <span id="S5.I1.i2.p1.1.2" class="ltx_text ltx_font_typewriter">iFedAvg</span> corrects and identifies this difference in data collection without ever sharing any underlying data (left in Figure).</p>
</div>
</li>
</ul>
</div>
<figure id="S5.F3" class="ltx_figure"><img src="/html/2107.06580/assets/x3.png" id="S5.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="456" height="206" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Heatmap of local input weights (<math id="S5.F3.2.m1.1" class="ltx_Math" alttext="\mathbf{w}_{\text{\tiny{in}}}" display="inline"><semantics id="S5.F3.2.m1.1b"><msub id="S5.F3.2.m1.1.1" xref="S5.F3.2.m1.1.1.cmml"><mi id="S5.F3.2.m1.1.1.2" xref="S5.F3.2.m1.1.1.2.cmml">𝐰</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S5.F3.2.m1.1.1.3" xref="S5.F3.2.m1.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.F3.2.m1.1c"><apply id="S5.F3.2.m1.1.1.cmml" xref="S5.F3.2.m1.1.1"><csymbol cd="ambiguous" id="S5.F3.2.m1.1.1.1.cmml" xref="S5.F3.2.m1.1.1">subscript</csymbol><ci id="S5.F3.2.m1.1.1.2.cmml" xref="S5.F3.2.m1.1.1.2">𝐰</ci><ci id="S5.F3.2.m1.1.1.3a.cmml" xref="S5.F3.2.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S5.F3.2.m1.1.1.3.cmml" xref="S5.F3.2.m1.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F3.2.m1.1d">\mathbf{w}_{\text{\tiny{in}}}</annotation></semantics></math>) for Ebola patient prognosis (left) and underlying distribution of CT values for ETC ‘Freetown’ compared to all remaining clients (right).</figcaption>
</figure>
<figure id="S5.F4" class="ltx_figure"><img src="/html/2107.06580/assets/x4.png" id="S5.F4.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="186" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Local input weights heatmap (<math id="S5.F4.2.m1.1" class="ltx_Math" alttext="\mathbf{w}_{\text{\tiny{in}}}" display="inline"><semantics id="S5.F4.2.m1.1b"><msub id="S5.F4.2.m1.1.1" xref="S5.F4.2.m1.1.1.cmml"><mi id="S5.F4.2.m1.1.1.2" xref="S5.F4.2.m1.1.1.2.cmml">𝐰</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="S5.F4.2.m1.1.1.3" xref="S5.F4.2.m1.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="S5.F4.2.m1.1c"><apply id="S5.F4.2.m1.1.1.cmml" xref="S5.F4.2.m1.1.1"><csymbol cd="ambiguous" id="S5.F4.2.m1.1.1.1.cmml" xref="S5.F4.2.m1.1.1">subscript</csymbol><ci id="S5.F4.2.m1.1.1.2.cmml" xref="S5.F4.2.m1.1.1.2">𝐰</ci><ci id="S5.F4.2.m1.1.1.3a.cmml" xref="S5.F4.2.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="S5.F4.2.m1.1.1.3.cmml" xref="S5.F4.2.m1.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F4.2.m1.1d">\mathbf{w}_{\text{\tiny{in}}}</annotation></semantics></math>) for EVD diagnosis (left) and proportion of recorded diarrhea in the patient, split by final diagnosis for ETC ‘Foya’ compared to all remaining clients (right).</figcaption>
</figure>
<div id="S5.SS2.p5" class="ltx_para">
<p id="S5.SS2.p5.1" class="ltx_p">In summary, we have shown that <span id="S5.SS2.p5.1.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> is able to detect and correct various types of data shifts across clients in a collaborative learning setting that would ordinarily cause hidden bias and confounding. For highly non-IID datasets, we find large shift compensations (i.e., many significant values in the heatmap visualizations). This behavior is expected, but could be an indication of a non negligible false-positive rate. Given the objective of highlighting <span id="S5.SS2.p5.1.2" class="ltx_text ltx_font_italic">potentially problematic</span> datasets and features, we believe this tradeoff is acceptable.</p>
</div>
<div id="S5.SS2.p6" class="ltx_para">
<p id="S5.SS2.p6.1" class="ltx_p">Interestingly, some of the personalized shifts detectable were indicative of data collection bias. Without a mechanism to flag such a shift, a personalized model trained by other methods would learn biased insights from data missing not-at-random (MNAR) and create poorly generalizable predictions. For example, let us recall the data collection of diarrhea presence for ETC Foya (Figure <a href="#S5.F4" title="Figure 4 ‣ 5.2 Interpretability of iFedAvg ‣ 5 Results ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). A locally trained or strongly personalized federated model would achieve excellent predictive performance as patients with diarrhea appear to be correlated with Ebola infection. This pattern does not hold overall, and if falsely learned could lead to misdiagnosis without detection. In instances precisely like this, <span id="S5.SS2.p6.1.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> proves invaluable in detecting local <span id="S5.SS2.p6.1.2" class="ltx_text ltx_font_italic">model biases</span>.</p>
</div>
<div id="S5.SS2.p7" class="ltx_para">
<p id="S5.SS2.p7.1" class="ltx_p">For various additional experimental results on the benchmark datasets as well as artificially introduced shifts and mutations confirming the efficacy of our method we refer to Appendix <a href="#A1.SS2" title="A.2 Supplementary interpretability results ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">A.2</span></a>.</p>
</div>
</section>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Conclusion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">We study interpretability and inter-client interoperability in federated learning and show how a feature-wise personalized learning approach addresses this challenge. Our framework, <span id="S6.p1.1.1" class="ltx_text ltx_font_typewriter">iFedAvg</span>, proposes a simple extension to federated averaging that creates interpretable data-interoperabilty between clients by personalizing models. The learned weights ultimately reveal novel insights about the federated learning process as a whole.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">On real-world datasets, <span id="S6.p2.1.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> is competitive with state-of-the-art personalized learning methods in terms of performance. The method vastly outperforms <span id="S6.p2.1.2" class="ltx_text ltx_font_typewriter">FedAvg</span> or centralized learning on poorly performing clients with significant data shifts. More critically, significant feature-wise shifts in the underlying client datasets are correctly detected and compensated for. Not only does this provide targeted guidance to practitioners interpreting the results, but it can aid assessments of the overall compatibility of a client with the federation. While some shifts might not be harmful to the model, overcompensating for local data biases can be detrimental. <span id="S6.p2.1.3" class="ltx_text ltx_font_typewriter">iFedAvg</span> visualizes these shifts, therefore generating the necessary transparency to best verify the reliability of model.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">We leave as future research the extension of our approach to other types of data (such as images) or learning a feature alignment mapping. Furthermore, studying <span id="S6.p3.1.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> with a large number of clients and partial participation would allow more widespread adoption in the future.</p>
</div>
<div id="S6.p4" class="ltx_para">
<p id="S6.p4.1" class="ltx_p">In conclusion, <span id="S6.p4.1.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> offers novel insights into the federated learning process of tabular datasets. It leverages these insights not only for interpretabilty, but to build personalized models that are further adjusted for the usually hidden interoperability issues between clients in a federation. These unique extensions of the federated learning process come at a negligible computational overhead and thus <span id="S6.p4.1.2" class="ltx_text ltx_font_typewriter">iFedAvg</span> is a promising approach for real world collaborative learning.</p>
</div>
<section id="S6.SSx1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">Broader impact</h3>

<div id="S6.SSx1.p1" class="ltx_para">
<p id="S6.SSx1.p1.1" class="ltx_p">This work is specifically designed to provide more guarantees of interoperability in federated learning and therefore incentivize collaboration, especially in fields with sensitive data and a high risk of collection bias. Equally we could disincentivize interoperable data collection by creating a shortcut that may undermine standardization efforts.
Interoperability is a pillar of the FAIR Guiding Principles for ethical scientific data stewardship, and this critical issue was highlighted as a key barrier by a WHO-commissioned investigation into the massive failings of the centralized Ebola response <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="" class="ltx_ref">26</a>]</cite>. Our work is specifically motivated by this use-case and is appropriately evaluated on a unique dataset collated from the largest number of distributed data collection sites during the notoriously poorly coordinated 2014-16 West African Ebola epidemic. By extrapolation, <span id="S6.SSx1.p1.1.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> can be seen as a first step to facilitating interpretable interoperability in collaborative analyses. Basing the architecture on a distributed learning system, we also attempt to address the issue of local data ownership and data privacy compared to centralized approaches. While the insights shared do not reveal sample level data, the client-level aggregate could be considered sensitive and may be abused to discriminate against clients. In this instance, concealing the identity of the client could be considered as a mitigation strategy.
Finally our simplified approach with low computational overhead makes this an accessible method for low-resource settings to build collaborative models whilst better securing patient privacy, intellectual property and statistical robustness to biases between collaborating datasets.</p>
</div>
</section>
</section>
<section id="Sx1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">Acknowledgements</h2>

<div id="Sx1.p1" class="ltx_para">
<p id="Sx1.p1.1" class="ltx_p">The authors would like to acknowledge all the patients whose data was used in this study. This work was inspired by the challenges of sensitive data management in health emergencies and using the Ebola dataset provided critical validation and context. The data was provided by the Ebola Data Platform hosted by the Infectious Diseases Data Observatory (IDDO), and the data contributors, who had no role in the production of these research outputs. The contributors are: Alliance for International Medical Action (ALIMA), International Medical Corps (IMC), Institute of Tropical Medicine Antwerp (ITM), Médecins Sans Frontières (MSF), Oxford University and Save the Children (SCI). We also thank Aiyu Liu for his work in preparing the Ebola dataset for analysis and Mélanie Bernhardt for her critical and insightful thoughts and generous support.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Anguita et al. [2013]</span>
<span class="ltx_bibblock">
D. Anguita, A. Ghio, L. Oneto, X. Parra, and J. L. Reyes-Ortiz.

</span>
<span class="ltx_bibblock">A public domain dataset for human activity recognition using
smartphones.

</span>
<span class="ltx_bibblock">In <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Esann</em>, volume 3, page 3, 2013.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Arivazhagan et al. [2019]</span>
<span class="ltx_bibblock">
M. G. Arivazhagan, V. Aggarwal, A. K. Singh, and S. Choudhary.

</span>
<span class="ltx_bibblock">Federated learning with personalization layers.

</span>
<span class="ltx_bibblock"><em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1912.00818</em>, 2019.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Colubri et al. [2019]</span>
<span class="ltx_bibblock">
A. Colubri, M. A. Hartley, M. Siakor, V. Wolfman, A. Felix, T. Sesay, J. G.
Shaffer, R. F. Garry, D. S. Grant, A. C. Levine, and P. C. Sabeti.

</span>
<span class="ltx_bibblock">Machine-learning Prognostic Models from the 2014–16 Ebola
Outbreak: Data-harmonization Challenges, Validation Strategies, and mHealth
Applications.

</span>
<span class="ltx_bibblock"><em id="bib.bib3.1.1" class="ltx_emph ltx_font_italic">EClinicalMedicine</em>, 11:54–64, may 2019.

</span>
<span class="ltx_bibblock">ISSN 25895370.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1016/j.eclinm.2019.06.003</span>.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Corinzia et al. [2019]</span>
<span class="ltx_bibblock">
L. Corinzia, A. Beuret, and J. M. Buhmann.

</span>
<span class="ltx_bibblock">Variational federated multi-task learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1906.06268</em>, 2019.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Deng et al. [2020]</span>
<span class="ltx_bibblock">
Y. Deng, M. M. Kamani, and M. Mahdavi.

</span>
<span class="ltx_bibblock">Adaptive personalized federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2003.13461</em>, 2020.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Duarte and Hu [2004]</span>
<span class="ltx_bibblock">
M. F. Duarte and Y. H. Hu.

</span>
<span class="ltx_bibblock">Vehicle classification in distributed sensor networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib6.1.1" class="ltx_emph ltx_font_italic">Journal of Parallel and Distributed Computing</em>, 64(7):826–838, 2004.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Fallah et al. [2020]</span>
<span class="ltx_bibblock">
A. Fallah, A. Mokhtari, and A. Ozdaglar.

</span>
<span class="ltx_bibblock">Personalized federated learning: A meta-learning approach.

</span>
<span class="ltx_bibblock"><em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.07948</em>, 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Georgetown University Medical Center [2018]</span>
<span class="ltx_bibblock">
Georgetown University Medical Center.

</span>
<span class="ltx_bibblock">Data Sharing during the West Africa Ebola Public Health Emergency:
Case Study Report.

</span>
<span class="ltx_bibblock">Technical report, Georgetown University Medical Center, 2018.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hartley et al. [2017a]</span>
<span class="ltx_bibblock">
M. A. Hartley, A. Young, A. M. Tran, H. H. Okoni-Williams, M. Suma, B. Mancuso,
A. Al-Dikhari, and M. Faouzi.

</span>
<span class="ltx_bibblock">Predicting Ebola Severity: A Clinical Prioritization Score for Ebola
Virus Disease.

</span>
<span class="ltx_bibblock"><em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">PLoS Neglected Tropical Diseases</em>, 11(2):e0005265, feb 2017a.

</span>
<span class="ltx_bibblock">ISSN 19352735.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1371/journal.pntd.0005265</span>.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hartley et al. [2017b]</span>
<span class="ltx_bibblock">
M. A. Hartley, A. Young, A. M. Tran, H. H. Okoni-Williams, M. Suma, B. Mancuso,
A. Al-Dikhari, and M. Faouzi.

</span>
<span class="ltx_bibblock">Predicting Ebola infection: A malaria-sensitive triage score for
Ebola virus disease.

</span>
<span class="ltx_bibblock"><em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">PLoS Neglected Tropical Diseases</em>, 11(2):e0005356, feb 2017b.

</span>
<span class="ltx_bibblock">ISSN 19352735.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1371/journal.pntd.0005356</span>.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Hsu et al. [2019]</span>
<span class="ltx_bibblock">
T.-M. H. Hsu, H. Qi, and M. Brown.

</span>
<span class="ltx_bibblock">Measuring the effects of non-identical data distribution for
federated visual classification.

</span>
<span class="ltx_bibblock"><em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.06335</em>, 2019.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Imakura et al. [2021]</span>
<span class="ltx_bibblock">
A. Imakura, H. Inaba, Y. Okada, and T. Sakurai.

</span>
<span class="ltx_bibblock">Interpretable collaborative data analysis on distributed data.

</span>
<span class="ltx_bibblock"><em id="bib.bib12.1.1" class="ltx_emph ltx_font_italic">Expert Systems with Applications</em>, 177:114891, 2021.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Infectious Disease Data Observatory (2021) [IDDO]</span>
<span class="ltx_bibblock">Infectious Disease Data Observatory (IDDO).

</span>
<span class="ltx_bibblock">Ebola Data Platform, 2021.

</span>
<span class="ltx_bibblock">URL <a target="_blank" href="https://www.iddo.org/research-themes/ebola" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://www.iddo.org/research-themes/ebola</a>.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jain et al. [2020]</span>
<span class="ltx_bibblock">
V. Jain, A. Charlett, and C. S. Brown.

</span>
<span class="ltx_bibblock">Meta-analysis of predictive symptoms for ebola virus disease.

</span>
<span class="ltx_bibblock"><em id="bib.bib14.1.1" class="ltx_emph ltx_font_italic">PLoS Neglected Tropical Diseases</em>, 14(10):1–15, oct 2020.

</span>
<span class="ltx_bibblock">ISSN 19352735.

</span>
<span class="ltx_bibblock">doi: <span class="ltx_ref ltx_nolink ltx_Url ltx_ref_self">10.1371/journal.pntd.0008799</span>.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Jiang et al. [2019]</span>
<span class="ltx_bibblock">
Y. Jiang, J. Konečnỳ, K. Rush, and S. Kannan.

</span>
<span class="ltx_bibblock">Improving federated learning personalization via model agnostic meta
learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1909.12488</em>, 2019.

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kairouz et al. [2019]</span>
<span class="ltx_bibblock">
P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji,
K. Bonawitz, Z. Charles, G. Cormode, R. Cummings, et al.

</span>
<span class="ltx_bibblock">Advances and open problems in federated learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1912.04977</em>, 2019.

</span>
</li>
<li id="bib.bib17" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Karimireddy et al. [2020]</span>
<span class="ltx_bibblock">
S. P. Karimireddy, S. Kale, M. Mohri, S. Reddi, S. Stich, and A. T. Suresh.

</span>
<span class="ltx_bibblock">Scaffold: Stochastic controlled averaging for federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib17.1.1" class="ltx_emph ltx_font_italic">International Conference on Machine Learning</em>, pages
5132–5143. PMLR, 2020.

</span>
</li>
<li id="bib.bib18" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Kulkarni et al. [2020]</span>
<span class="ltx_bibblock">
V. Kulkarni, M. Kulkarni, and A. Pant.

</span>
<span class="ltx_bibblock">Survey of personalization techniques for federated learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib18.1.1" class="ltx_emph ltx_font_italic">2020 Fourth World Conference on Smart Trends in Systems,
Security and Sustainability (WorldS4)</em>, pages 794–797. IEEE, 2020.

</span>
</li>
<li id="bib.bib19" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Li et al. [2018]</span>
<span class="ltx_bibblock">
T. Li, A. K. Sahu, M. Zaheer, M. Sanjabi, A. Talwalkar, and V. Smith.

</span>
<span class="ltx_bibblock">Federated optimization in heterogeneous networks.

</span>
<span class="ltx_bibblock"><em id="bib.bib19.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1812.06127</em>, 2018.

</span>
</li>
<li id="bib.bib20" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">McMahan et al. [2017]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas.

</span>
<span class="ltx_bibblock">Communication-efficient learning of deep networks from decentralized
data.

</span>
<span class="ltx_bibblock">In <em id="bib.bib20.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence and Statistics</em>, pages 1273–1282.
PMLR, 2017.

</span>
</li>
<li id="bib.bib21" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Paszke et al. [2019]</span>
<span class="ltx_bibblock">
A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan, T. Killeen,
Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison, A. Köpf, E. Yang, Z. DeVito,
M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner, L. Fang, J. Bai, and
S. Chintala.

</span>
<span class="ltx_bibblock">Pytorch: An imperative style, high-performance deep learning library,
2019.

</span>
</li>
<li id="bib.bib22" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Reddi et al. [2020]</span>
<span class="ltx_bibblock">
S. Reddi, Z. Charles, M. Zaheer, Z. Garrett, K. Rush, J. Konečnỳ,
S. Kumar, and H. B. McMahan.

</span>
<span class="ltx_bibblock">Adaptive federated optimization.

</span>
<span class="ltx_bibblock"><em id="bib.bib22.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2003.00295</em>, 2020.

</span>
</li>
<li id="bib.bib23" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Ribeiro et al. [2016]</span>
<span class="ltx_bibblock">
M. T. Ribeiro, S. Singh, and C. Guestrin.

</span>
<span class="ltx_bibblock">Model-agnostic interpretability of machine learning.

</span>
<span class="ltx_bibblock"><em id="bib.bib23.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1606.05386</em>, 2016.

</span>
</li>
<li id="bib.bib24" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Smith et al. [2017]</span>
<span class="ltx_bibblock">
V. Smith, C.-K. Chiang, M. Sanjabi, and A. Talwalkar.

</span>
<span class="ltx_bibblock">Federated multi-task learning.

</span>
<span class="ltx_bibblock">In <em id="bib.bib24.1.1" class="ltx_emph ltx_font_italic">Proceedings of the 31st International Conference on Neural
Information Processing Systems</em>, pages 4427–4437, 2017.

</span>
</li>
<li id="bib.bib25" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wang [2019]</span>
<span class="ltx_bibblock">
G. Wang.

</span>
<span class="ltx_bibblock">Interpret federated learning with shapley values.

</span>
<span class="ltx_bibblock"><em id="bib.bib25.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1905.04519</em>, 2019.

</span>
</li>
<li id="bib.bib26" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Wilkinson et al. [2016]</span>
<span class="ltx_bibblock">
M. D. Wilkinson, M. Dumontier, I. J. Aalbersberg, G. Appleton, M. Axton,
A. Baak, N. Blomberg, J.-W. Boiten, L. B. da Silva Santos, P. E. Bourne,
et al.

</span>
<span class="ltx_bibblock">Comment: The fair guiding principles for scientific data management
and stewardship.

</span>
<span class="ltx_bibblock"><em id="bib.bib26.1.1" class="ltx_emph ltx_font_italic">Scientific data</em>, 3:160018, 2016.

</span>
</li>
<li id="bib.bib27" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Yu et al. [2020]</span>
<span class="ltx_bibblock">
T. Yu, E. Bagdasaryan, and V. Shmatikov.

</span>
<span class="ltx_bibblock">Salvaging federated learning by local adaptation.

</span>
<span class="ltx_bibblock"><em id="bib.bib27.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2002.04758</em>, 2020.

</span>
</li>
<li id="bib.bib28" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zhao et al. [2018]</span>
<span class="ltx_bibblock">
Y. Zhao, M. Li, L. Lai, N. Suda, D. Civin, and V. Chandra.

</span>
<span class="ltx_bibblock">Federated learning with non-iid data.

</span>
<span class="ltx_bibblock"><em id="bib.bib28.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:1806.00582</em>, 2018.

</span>
</li>
<li id="bib.bib29" class="ltx_bibitem">
<span class="ltx_tag ltx_role_refnum ltx_tag_bibitem">Zheng et al. [2020]</span>
<span class="ltx_bibblock">
F. Zheng, K. Li, J. Tian, X. Xiang, et al.

</span>
<span class="ltx_bibblock">A vertical federated learning method for interpretable scorecard and
its application in credit scoring.

</span>
<span class="ltx_bibblock"><em id="bib.bib29.1.1" class="ltx_emph ltx_font_italic">arXiv preprint arXiv:2009.06218</em>, 2020.

</span>
</li>
</ul>
</section>
<div class="ltx_pagination ltx_role_newpage"></div>
<section id="A1" class="ltx_appendix">
<h2 class="ltx_title ltx_title_appendix">
<span class="ltx_tag ltx_tag_appendix">Appendix A </span>Appendix</h2>

<section id="A1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.1 </span>Supplementary performance results</h3>

<div id="A1.SS1.p1" class="ltx_para">
<p id="A1.SS1.p1.1" class="ltx_p">In addition to the main results in the paper, we provide the full distribution of performance metrics across clients as well as balanced accuracy and ROC AUC scores for each method. In the client performance distribution plots, the red error bars show the standard deviation (SD) of the median score of each random seed. We notice no particular pattern or single method with a distinctive behavior with regards to seed. The following two sections evaluate this experiment by F1 score and AUROC and .</p>
</div>
<section id="A1.SS1.SSS1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.1.1 </span>F1 Score</h4>

<div id="A1.SS1.SSS1.p1" class="ltx_para">
<p id="A1.SS1.SSS1.p1.1" class="ltx_p">Tables <a href="#S5.T1" title="Table 1 ‣ 5.1 Performance ‣ 5 Results ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> and <a href="#S5.T2" title="Table 2 ‣ 5.1 Performance ‣ 5 Results ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> (in the main text) show mean and worst-client performance on all datasets. Here, we show the distribution of client performances in violin plots for each dataset (EVD Prognosis: Figure <a href="#A1.F5" title="Figure 5 ‣ A.1.1 F1 Score ‣ A.1 Supplementary performance results ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, EVD Diagnosis: Figure <a href="#A1.F6" title="Figure 6 ‣ A.1.1 F1 Score ‣ A.1 Supplementary performance results ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, VSN: Figure <a href="#A1.F7" title="Figure 7 ‣ A.1.1 F1 Score ‣ A.1 Supplementary performance results ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, HAR: Figure <a href="#A1.F8" title="Figure 8 ‣ A.1.1 F1 Score ‣ A.1 Supplementary performance results ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>).</p>
</div>
<div id="A1.SS1.SSS1.p2" class="ltx_para">
<p id="A1.SS1.SSS1.p2.1" class="ltx_p">It is particularly apparent in these visualizations that <span id="A1.SS1.SSS1.p2.1.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> is robust to <span id="A1.SS1.SSS1.p2.1.2" class="ltx_text ltx_font_italic">poorly</span> performing clients. For every dataset our method outperforms <span id="A1.SS1.SSS1.p2.1.3" class="ltx_text ltx_font_typewriter">FedAvg</span>, and in most instances even outperforms <span id="A1.SS1.SSS1.p2.1.4" class="ltx_text ltx_font_typewriter">APFL</span>, Local or Centralized training. Furthermore, for the HAR dataset, while <span id="A1.SS1.SSS1.p2.1.5" class="ltx_text ltx_font_typewriter">iFedAvg</span> has a relatively low performing client, the overall distribution is skewed towards <math id="A1.SS1.SSS1.p2.1.m1.1" class="ltx_Math" alttext="1.0" display="inline"><semantics id="A1.SS1.SSS1.p2.1.m1.1a"><mn id="A1.SS1.SSS1.p2.1.m1.1.1" xref="A1.SS1.SSS1.p2.1.m1.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="A1.SS1.SSS1.p2.1.m1.1b"><cn type="float" id="A1.SS1.SSS1.p2.1.m1.1.1.cmml" xref="A1.SS1.SSS1.p2.1.m1.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS1.SSS1.p2.1.m1.1c">1.0</annotation></semantics></math>, indicating good overall performance. For this dataset, the seed-SD is also noticeably lower for our method compared to the benchmarks.</p>
</div>
<figure id="A1.F5" class="ltx_figure"><img src="/html/2107.06580/assets/x5.png" id="A1.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Distribution of client performances (F1 score) for the Ebola Prognosis dataset. Red error bars show the standard deviation (SD) of the median score of each random seed.</figcaption>
</figure>
<figure id="A1.F6" class="ltx_figure"><img src="/html/2107.06580/assets/x6.png" id="A1.F6.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>Distribution of client performances (F1 score) for the Ebola Diagnosis dataset. Red error bars show the standard deviation (SD) of the median score of each random seed.</figcaption>
</figure>
<figure id="A1.F7" class="ltx_figure"><img src="/html/2107.06580/assets/x7.png" id="A1.F7.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>Distribution of client performances (F1 score) for the Vehicle Sensor Network dataset.Red error bars show the standard deviation (SD) of the median score of each random seed.</figcaption>
</figure>
<figure id="A1.F8" class="ltx_figure"><img src="/html/2107.06580/assets/x8.png" id="A1.F8.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>Distribution of client performances (F1 score) for the Human Activity Recognition dataset. Red error bars show the standard deviation (SD) of the median score of each random seed.</figcaption>
</figure>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A1.SS1.SSS2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">
<span class="ltx_tag ltx_tag_subsubsection">A.1.2 </span>ROC AUC</h4>

<div id="A1.SS1.SSS2.p1" class="ltx_para">
<p id="A1.SS1.SSS2.p1.1" class="ltx_p">An additional metric which can be used to measure the performance of a classification model is the area under the curve of the receiver operating characteristic. We evaluate our method in the same fashion as previously; analyzing both the average performance across clients as well as the worst performing client in the federation. These results are displayed in Table <a href="#A1.T3" title="Table 3 ‣ A.1.2 ROC AUC ‣ A.1 Supplementary performance results ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> and <a href="#A1.T4" title="Table 4 ‣ A.1.2 ROC AUC ‣ A.1 Supplementary performance results ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<div id="A1.SS1.SSS2.p2" class="ltx_para">
<p id="A1.SS1.SSS2.p2.1" class="ltx_p">These graphs corroborate the findings in the main text, and highlight that the strong performance of <span id="A1.SS1.SSS2.p2.1.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> is independent of the chosen metric. Interestingly, the gap between our method and vanilla federated averaging shrinks marginally, which can be explained by the sensitivity of F1 score to individual incorrect samples.</p>
</div>
<figure id="A1.T3" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 3: </span>Mean (across all clients) performance (ROC AUC)</figcaption>
<table id="A1.T3.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A1.T3.1.1.1" class="ltx_tr">
<th id="A1.T3.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="A1.T3.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4">Method</th>
<td id="A1.T3.1.1.1.3" class="ltx_td ltx_border_tt"></td>
</tr>
<tr id="A1.T3.1.2.2" class="ltx_tr">
<th id="A1.T3.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row">Dataset</th>
<th id="A1.T3.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<span id="A1.T3.1.2.2.2.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> (ours)</th>
<th id="A1.T3.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="A1.T3.1.2.2.3.1" class="ltx_text ltx_font_typewriter">APFL</span></th>
<th id="A1.T3.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="A1.T3.1.2.2.4.1" class="ltx_text ltx_font_typewriter">FedAvg</span></th>
<th id="A1.T3.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Local</th>
<th id="A1.T3.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Centralized</th>
</tr>
<tr id="A1.T3.1.3.3" class="ltx_tr">
<th id="A1.T3.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Ebola Prognosis</th>
<td id="A1.T3.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t">0.725</td>
<td id="A1.T3.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t">0.704</td>
<td id="A1.T3.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T3.1.3.3.4.1" class="ltx_text ltx_font_bold">0.726</span></td>
<td id="A1.T3.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t">0.708</td>
<td id="A1.T3.1.3.3.6" class="ltx_td ltx_align_center ltx_border_t">0.74</td>
</tr>
<tr id="A1.T3.1.4.4" class="ltx_tr">
<th id="A1.T3.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ebola Diagnosis</th>
<td id="A1.T3.1.4.4.2" class="ltx_td ltx_align_center"><span id="A1.T3.1.4.4.2.1" class="ltx_text ltx_font_bold">0.909</span></td>
<td id="A1.T3.1.4.4.3" class="ltx_td ltx_align_center">0.860</td>
<td id="A1.T3.1.4.4.4" class="ltx_td ltx_align_center">0.879</td>
<td id="A1.T3.1.4.4.5" class="ltx_td ltx_align_center">0.870</td>
<td id="A1.T3.1.4.4.6" class="ltx_td ltx_align_center">0.901</td>
</tr>
<tr id="A1.T3.1.5.5" class="ltx_tr">
<th id="A1.T3.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Vehicle Sensor Network</th>
<td id="A1.T3.1.5.5.2" class="ltx_td ltx_align_center">0.975</td>
<td id="A1.T3.1.5.5.3" class="ltx_td ltx_align_center">0.978</td>
<td id="A1.T3.1.5.5.4" class="ltx_td ltx_align_center">0.921</td>
<td id="A1.T3.1.5.5.5" class="ltx_td ltx_align_center">0.982</td>
<td id="A1.T3.1.5.5.6" class="ltx_td ltx_align_center"><span id="A1.T3.1.5.5.6.1" class="ltx_text ltx_font_bold">0.986</span></td>
</tr>
<tr id="A1.T3.1.6.6" class="ltx_tr">
<th id="A1.T3.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Human Activity Recognition</th>
<td id="A1.T3.1.6.6.2" class="ltx_td ltx_align_center ltx_border_bb">1.00</td>
<td id="A1.T3.1.6.6.3" class="ltx_td ltx_align_center ltx_border_bb">1.00</td>
<td id="A1.T3.1.6.6.4" class="ltx_td ltx_align_center ltx_border_bb">0.999</td>
<td id="A1.T3.1.6.6.5" class="ltx_td ltx_align_center ltx_border_bb">1.00</td>
<td id="A1.T3.1.6.6.6" class="ltx_td ltx_align_center ltx_border_bb">1.00</td>
</tr>
</tbody>
</table>
</figure>
<figure id="A1.T4" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 4: </span>Worst-performing client in federation (ROC AUC)</figcaption>
<table id="A1.T4.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<tbody class="ltx_tbody">
<tr id="A1.T4.1.1.1" class="ltx_tr">
<th id="A1.T4.1.1.1.1" class="ltx_td ltx_th ltx_th_row ltx_border_tt"></th>
<th id="A1.T4.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt" colspan="4">Method</th>
<td id="A1.T4.1.1.1.3" class="ltx_td ltx_border_tt"></td>
</tr>
<tr id="A1.T4.1.2.2" class="ltx_tr">
<th id="A1.T4.1.2.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row">Dataset</th>
<th id="A1.T4.1.2.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">
<span id="A1.T4.1.2.2.2.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> (ours)</th>
<th id="A1.T4.1.2.2.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="A1.T4.1.2.2.3.1" class="ltx_text ltx_font_typewriter">APFL</span></th>
<th id="A1.T4.1.2.2.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t"><span id="A1.T4.1.2.2.4.1" class="ltx_text ltx_font_typewriter">FedAvg</span></th>
<th id="A1.T4.1.2.2.5" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Local</th>
<th id="A1.T4.1.2.2.6" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_t">Centralized</th>
</tr>
<tr id="A1.T4.1.3.3" class="ltx_tr">
<th id="A1.T4.1.3.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Ebola Prognosis</th>
<td id="A1.T4.1.3.3.2" class="ltx_td ltx_align_center ltx_border_t"><span id="A1.T4.1.3.3.2.1" class="ltx_text ltx_font_bold">0.628</span></td>
<td id="A1.T4.1.3.3.3" class="ltx_td ltx_align_center ltx_border_t">0.573</td>
<td id="A1.T4.1.3.3.4" class="ltx_td ltx_align_center ltx_border_t">0.608</td>
<td id="A1.T4.1.3.3.5" class="ltx_td ltx_align_center ltx_border_t">0.567</td>
<td id="A1.T4.1.3.3.6" class="ltx_td ltx_align_center ltx_border_t">0.581</td>
</tr>
<tr id="A1.T4.1.4.4" class="ltx_tr">
<th id="A1.T4.1.4.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ebola Diagnosis</th>
<td id="A1.T4.1.4.4.2" class="ltx_td ltx_align_center"><span id="A1.T4.1.4.4.2.1" class="ltx_text ltx_font_bold">0.799</span></td>
<td id="A1.T4.1.4.4.3" class="ltx_td ltx_align_center">0.694</td>
<td id="A1.T4.1.4.4.4" class="ltx_td ltx_align_center">0.770</td>
<td id="A1.T4.1.4.4.5" class="ltx_td ltx_align_center">0.689</td>
<td id="A1.T4.1.4.4.6" class="ltx_td ltx_align_center">0.740</td>
</tr>
<tr id="A1.T4.1.5.5" class="ltx_tr">
<th id="A1.T4.1.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Vehicle Sensor Network</th>
<td id="A1.T4.1.5.5.2" class="ltx_td ltx_align_center">0.930</td>
<td id="A1.T4.1.5.5.3" class="ltx_td ltx_align_center">0.936</td>
<td id="A1.T4.1.5.5.4" class="ltx_td ltx_align_center">0.124</td>
<td id="A1.T4.1.5.5.5" class="ltx_td ltx_align_center"><span id="A1.T4.1.5.5.5.1" class="ltx_text ltx_font_bold">0.950</span></td>
<td id="A1.T4.1.5.5.6" class="ltx_td ltx_align_center">0.935</td>
</tr>
<tr id="A1.T4.1.6.6" class="ltx_tr">
<th id="A1.T4.1.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Human Activity Recognition</th>
<td id="A1.T4.1.6.6.2" class="ltx_td ltx_align_center ltx_border_bb">0.996</td>
<td id="A1.T4.1.6.6.3" class="ltx_td ltx_align_center ltx_border_bb">0.997</td>
<td id="A1.T4.1.6.6.4" class="ltx_td ltx_align_center ltx_border_bb">0.991</td>
<td id="A1.T4.1.6.6.5" class="ltx_td ltx_align_center ltx_border_bb">0.997</td>
<td id="A1.T4.1.6.6.6" class="ltx_td ltx_align_center ltx_border_bb"><span id="A1.T4.1.6.6.6.1" class="ltx_text ltx_font_bold">0.998</span></td>
</tr>
</tbody>
</table>
</figure>
<div id="A1.SS1.SSS2.p3" class="ltx_para">
<p id="A1.SS1.SSS2.p3.1" class="ltx_p">Similarly to the F1 score metric, we present all distributions of ROC AUC performance as violin plots (EVD Prognosis: Figure <a href="#A1.F9" title="Figure 9 ‣ A.1.2 ROC AUC ‣ A.1 Supplementary performance results ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">9</span></a>, EVD Diagnosis: Figure<a href="#A1.F10" title="Figure 10 ‣ A.1.2 ROC AUC ‣ A.1 Supplementary performance results ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">10</span></a>, VSN: Figure <a href="#A1.F11" title="Figure 11 ‣ A.1.2 ROC AUC ‣ A.1 Supplementary performance results ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">11</span></a>, HAR: Figure <a href="#A1.F12" title="Figure 12 ‣ A.1.2 ROC AUC ‣ A.1 Supplementary performance results ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">12</span></a>). One instance that stands out is the relatively poor performance of <span id="A1.SS1.SSS2.p3.1.1" class="ltx_text ltx_font_typewriter">APFL</span> for EVD Prognosis and Diagnosis, as the personalized method does not manage to outperform vanilla federated averaging. We suspect that <span id="A1.SS1.SSS2.p3.1.2" class="ltx_text ltx_font_typewriter">APFL</span> is overfitting due to the strongly heterogeneous nature of the datasets, which can be observed in its similarity to Local training performance.</p>
</div>
<figure id="A1.F9" class="ltx_figure"><img src="/html/2107.06580/assets/x9.png" id="A1.F9.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 9: </span>Distribution of client performances (ROC AUC) for the Ebola Prognosis dataset.</figcaption>
</figure>
<figure id="A1.F10" class="ltx_figure"><img src="/html/2107.06580/assets/x10.png" id="A1.F10.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 10: </span>Distribution of client performances (ROC AUC) for the Ebola Diagnosis dataset.</figcaption>
</figure>
<figure id="A1.F11" class="ltx_figure"><img src="/html/2107.06580/assets/x11.png" id="A1.F11.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 11: </span>Distribution of client performances (ROC AUC) for the Vehicle Sensor Network dataset.</figcaption>
</figure>
<figure id="A1.F12" class="ltx_figure"><img src="/html/2107.06580/assets/x12.png" id="A1.F12.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="415" height="259" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 12: </span>Distribution of client performances (ROC AUC) for the Human Activity Recognition dataset.</figcaption>
</figure>
<div id="A1.SS1.SSS2.p4" class="ltx_para">
<p id="A1.SS1.SSS2.p4.1" class="ltx_p">In conclusion, <span id="A1.SS1.SSS2.p4.1.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> shows impressive performance in various settings and measured by different metrics. Especially on datasets which benefit from personalization due to one or multiple outlier clients, our method is particularly effective compared with vanilla federated averaging.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
</section>
<section id="A1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.2 </span>Supplementary interpretability results</h3>

<div id="A1.SS2.p1" class="ltx_para">
<p id="A1.SS2.p1.1" class="ltx_p">In this section, we show additional interpretability results of <span id="A1.SS2.p1.1.1" class="ltx_text ltx_font_typewriter">iFedAvg</span>, with the objective of highlighting the different types of shifts detected for various datasets. The list below serves as a reference to the corresponding figures.</p>
</div>
<div id="A1.SS2.p2" class="ltx_para">
<ul id="A1.I1" class="ltx_itemize">
<li id="A1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i1.p1" class="ltx_para">
<p id="A1.I1.i1.p1.3" class="ltx_p"><span id="A1.I1.i1.p1.3.1" class="ltx_text ltx_font_bold">Human Activity Recognition - underlying shifts:</span> In order to determine the directionality of detected shifts, we highlight two examples that are shown for <span id="A1.I1.i1.p1.3.2" class="ltx_text ltx_font_typewriter">iFedAvg</span>. For feature 77, we notice that all shifts are significant (‘x’ in the column), but two local weights for clients 14 and 15 are additionally significant (‘O’). We can see that the positive and negative shifts in bias (<math id="A1.I1.i1.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{b}_{\text{\tiny{in}}}" display="inline"><semantics id="A1.I1.i1.p1.1.m1.1a"><msub id="A1.I1.i1.p1.1.m1.1.1" xref="A1.I1.i1.p1.1.m1.1.1.cmml"><mi id="A1.I1.i1.p1.1.m1.1.1.2" xref="A1.I1.i1.p1.1.m1.1.1.2.cmml">𝐛</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.I1.i1.p1.1.m1.1.1.3" xref="A1.I1.i1.p1.1.m1.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.I1.i1.p1.1.m1.1b"><apply id="A1.I1.i1.p1.1.m1.1.1.cmml" xref="A1.I1.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.I1.i1.p1.1.m1.1.1.1.cmml" xref="A1.I1.i1.p1.1.m1.1.1">subscript</csymbol><ci id="A1.I1.i1.p1.1.m1.1.1.2.cmml" xref="A1.I1.i1.p1.1.m1.1.1.2">𝐛</ci><ci id="A1.I1.i1.p1.1.m1.1.1.3a.cmml" xref="A1.I1.i1.p1.1.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.I1.i1.p1.1.m1.1.1.3.cmml" xref="A1.I1.i1.p1.1.m1.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.I1.i1.p1.1.m1.1c">\mathbf{b}_{\text{\tiny{in}}}</annotation></semantics></math>) in grey and red, respectively, are noticeable in the underlying data. The histograms clearly show that the values of client 15 are skewed towards <math id="A1.I1.i1.p1.2.m2.1" class="ltx_Math" alttext="-1.0" display="inline"><semantics id="A1.I1.i1.p1.2.m2.1a"><mrow id="A1.I1.i1.p1.2.m2.1.1" xref="A1.I1.i1.p1.2.m2.1.1.cmml"><mo id="A1.I1.i1.p1.2.m2.1.1a" xref="A1.I1.i1.p1.2.m2.1.1.cmml">−</mo><mn id="A1.I1.i1.p1.2.m2.1.1.2" xref="A1.I1.i1.p1.2.m2.1.1.2.cmml">1.0</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.I1.i1.p1.2.m2.1b"><apply id="A1.I1.i1.p1.2.m2.1.1.cmml" xref="A1.I1.i1.p1.2.m2.1.1"><minus id="A1.I1.i1.p1.2.m2.1.1.1.cmml" xref="A1.I1.i1.p1.2.m2.1.1"></minus><cn type="float" id="A1.I1.i1.p1.2.m2.1.1.2.cmml" xref="A1.I1.i1.p1.2.m2.1.1.2">1.0</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.I1.i1.p1.2.m2.1c">-1.0</annotation></semantics></math> whereas for client 14 they are skewed towards <math id="A1.I1.i1.p1.3.m3.1" class="ltx_Math" alttext="1.0" display="inline"><semantics id="A1.I1.i1.p1.3.m3.1a"><mn id="A1.I1.i1.p1.3.m3.1.1" xref="A1.I1.i1.p1.3.m3.1.1.cmml">1.0</mn><annotation-xml encoding="MathML-Content" id="A1.I1.i1.p1.3.m3.1b"><cn type="float" id="A1.I1.i1.p1.3.m3.1.1.cmml" xref="A1.I1.i1.p1.3.m3.1.1">1.0</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.I1.i1.p1.3.m3.1c">1.0</annotation></semantics></math>. This example demonstrates that the learned local layers can indicate directionality correctly. Figure <a href="#A1.F13" title="Figure 13 ‣ 1st item ‣ A.2 Supplementary interpretability results ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">13</span></a> shows the bias heatmap as well as the histograms of both clients of interest.</p>
</div>
<figure id="A1.F13" class="ltx_figure"><img src="/html/2107.06580/assets/x13.png" id="A1.F13.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="456" height="361" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 13: </span>Heatmap of the biases (<math id="A1.F13.2.m1.1" class="ltx_Math" alttext="\mathbf{b}_{\text{\tiny{in}}}" display="inline"><semantics id="A1.F13.2.m1.1b"><msub id="A1.F13.2.m1.1.1" xref="A1.F13.2.m1.1.1.cmml"><mi id="A1.F13.2.m1.1.1.2" xref="A1.F13.2.m1.1.1.2.cmml">𝐛</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.F13.2.m1.1.1.3" xref="A1.F13.2.m1.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.F13.2.m1.1c"><apply id="A1.F13.2.m1.1.1.cmml" xref="A1.F13.2.m1.1.1"><csymbol cd="ambiguous" id="A1.F13.2.m1.1.1.1.cmml" xref="A1.F13.2.m1.1.1">subscript</csymbol><ci id="A1.F13.2.m1.1.1.2.cmml" xref="A1.F13.2.m1.1.1.2">𝐛</ci><ci id="A1.F13.2.m1.1.1.3a.cmml" xref="A1.F13.2.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.F13.2.m1.1.1.3.cmml" xref="A1.F13.2.m1.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F13.2.m1.1d">\mathbf{b}_{\text{\tiny{in}}}</annotation></semantics></math>) for the Human Activity Recognition dataset (left) and histograms of feature 77 for clients 15 and 14 (right).</figcaption>
</figure>
</li>
<li id="A1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i2.p1" class="ltx_para">
<p id="A1.I1.i2.p1.1" class="ltx_p"><span id="A1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">Human Activity Recognition - feature spread:</span> Highlighting another example on the HAR dataset, our method detects that for feature 50, client 16, a smaller weight is being applied. Investigating the underlying feature shows that, for this client, larger values are not being observed. While personalizing the local layers, <span id="A1.I1.i2.p1.1.2" class="ltx_text ltx_font_typewriter">iFedAvg</span> therefore is reducing the value of this feature. This could be indicative of <span id="A1.I1.i2.p1.1.3" class="ltx_text ltx_font_italic">feature deactivation</span> or simply a compensation for the downstream effect of this feature in the <span id="A1.I1.i2.p1.1.4" class="ltx_text ltx_font_italic">shared</span> part of the model. The histogram of the feature and heatmap of <math id="A1.I1.i2.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{w}_{\text{\tiny{in}}}" display="inline"><semantics id="A1.I1.i2.p1.1.m1.1a"><msub id="A1.I1.i2.p1.1.m1.1.1" xref="A1.I1.i2.p1.1.m1.1.1.cmml"><mi id="A1.I1.i2.p1.1.m1.1.1.2" xref="A1.I1.i2.p1.1.m1.1.1.2.cmml">𝐰</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.I1.i2.p1.1.m1.1.1.3" xref="A1.I1.i2.p1.1.m1.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.I1.i2.p1.1.m1.1b"><apply id="A1.I1.i2.p1.1.m1.1.1.cmml" xref="A1.I1.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.I1.i2.p1.1.m1.1.1.1.cmml" xref="A1.I1.i2.p1.1.m1.1.1">subscript</csymbol><ci id="A1.I1.i2.p1.1.m1.1.1.2.cmml" xref="A1.I1.i2.p1.1.m1.1.1.2">𝐰</ci><ci id="A1.I1.i2.p1.1.m1.1.1.3a.cmml" xref="A1.I1.i2.p1.1.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.I1.i2.p1.1.m1.1.1.3.cmml" xref="A1.I1.i2.p1.1.m1.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.I1.i2.p1.1.m1.1c">\mathbf{w}_{\text{\tiny{in}}}</annotation></semantics></math> can be seen in Figure <a href="#A1.F14" title="Figure 14 ‣ 2nd item ‣ A.2 Supplementary interpretability results ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">14</span></a>.</p>
</div>
<figure id="A1.F14" class="ltx_figure"><img src="" id="A1.F14.g1" class="ltx_graphics ltx_centering ltx_missing ltx_missing_image" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 14: </span>Heatmap of the weights (<math id="A1.F14.2.m1.1" class="ltx_Math" alttext="\mathbf{w}_{\text{\tiny{in}}}" display="inline"><semantics id="A1.F14.2.m1.1b"><msub id="A1.F14.2.m1.1.1" xref="A1.F14.2.m1.1.1.cmml"><mi id="A1.F14.2.m1.1.1.2" xref="A1.F14.2.m1.1.1.2.cmml">𝐰</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.F14.2.m1.1.1.3" xref="A1.F14.2.m1.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.F14.2.m1.1c"><apply id="A1.F14.2.m1.1.1.cmml" xref="A1.F14.2.m1.1.1"><csymbol cd="ambiguous" id="A1.F14.2.m1.1.1.1.cmml" xref="A1.F14.2.m1.1.1">subscript</csymbol><ci id="A1.F14.2.m1.1.1.2.cmml" xref="A1.F14.2.m1.1.1.2">𝐰</ci><ci id="A1.F14.2.m1.1.1.3a.cmml" xref="A1.F14.2.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.F14.2.m1.1.1.3.cmml" xref="A1.F14.2.m1.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F14.2.m1.1d">\mathbf{w}_{\text{\tiny{in}}}</annotation></semantics></math>) for the Human Activity Recognition dataset (left) and histograms of feature 50 for client 16 (right).</figcaption>
</figure>
</li>
<li id="A1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i3.p1" class="ltx_para">
<p id="A1.I1.i3.p1.1" class="ltx_p"><span id="A1.I1.i3.p1.1.1" class="ltx_text ltx_font_bold">Vehicle Sensor Network - Target-specific Stretch:</span> A particularly interesting example of shifts detected by <span id="A1.I1.i3.p1.1.2" class="ltx_text ltx_font_typewriter">iFedAvg</span> is one that is dependent on the target. For the VSN dataset, client 5 seems to have different values for feature 50 for the positive class, which is shown as significant in the heatmap. Client 19, albeit not significantly, has a slightly above average weight, and indeed for the negative target class has a differing underlying distribution. While the directionality of the weights in this instance do not directly indicate a shift for a particular target class, our method correctly identifies <span id="A1.I1.i3.p1.1.3" class="ltx_text ltx_font_italic">differences</span> in the underlying feature distribution. The heatmap and histograms of feature 50 for both clients and both target classes can be seen in Figure <a href="#A1.F15" title="Figure 15 ‣ 3rd item ‣ A.2 Supplementary interpretability results ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">15</span></a>.</p>
</div>
<figure id="A1.F15" class="ltx_figure"><img src="/html/2107.06580/assets/x15.png" id="A1.F15.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="456" height="306" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 15: </span>Heatmap of the weights (<math id="A1.F15.2.m1.1" class="ltx_Math" alttext="\mathbf{w}_{\text{\tiny{in}}}" display="inline"><semantics id="A1.F15.2.m1.1b"><msub id="A1.F15.2.m1.1.1" xref="A1.F15.2.m1.1.1.cmml"><mi id="A1.F15.2.m1.1.1.2" xref="A1.F15.2.m1.1.1.2.cmml">𝐰</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.F15.2.m1.1.1.3" xref="A1.F15.2.m1.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.F15.2.m1.1c"><apply id="A1.F15.2.m1.1.1.cmml" xref="A1.F15.2.m1.1.1"><csymbol cd="ambiguous" id="A1.F15.2.m1.1.1.1.cmml" xref="A1.F15.2.m1.1.1">subscript</csymbol><ci id="A1.F15.2.m1.1.1.2.cmml" xref="A1.F15.2.m1.1.1.2">𝐰</ci><ci id="A1.F15.2.m1.1.1.3a.cmml" xref="A1.F15.2.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.F15.2.m1.1.1.3.cmml" xref="A1.F15.2.m1.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F15.2.m1.1d">\mathbf{w}_{\text{\tiny{in}}}</annotation></semantics></math>) for the Vehicle Sensor Network dataset (left) and histograms of feature 50 for clients 19 and 5 split according to the target class (right).</figcaption>
</figure>
</li>
<li id="A1.I1.i4" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i4.p1" class="ltx_para">
<p id="A1.I1.i4.p1.1" class="ltx_p"><span id="A1.I1.i4.p1.1.1" class="ltx_text ltx_font_bold">Ebola Diagnosis - small underlying shifts:</span> Some of the discussed examples have been rather substantial and for features where many clients modify the bias or weight (marked by ‘x’ in the columns). Detecting and correcting, small shifts can be critical for a client if they are the only ones performing such a personalized compensation. For the Kalihun ETC, it appears as if the referral times, the time taken until a patient actually visits the treatment center, are slightly larger and <span id="A1.I1.i4.p1.1.2" class="ltx_text ltx_font_typewriter">iFedAvg</span> is compensating with a small but significant negative bias. For comparison, the histogram of an arbitrary ETC, Foya, is shown highlighting the difference in the underlying data. The heatmap and histograms are shown in Figure <a href="#A1.F16" title="Figure 16 ‣ 4th item ‣ A.2 Supplementary interpretability results ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">16</span></a></p>
</div>
<figure id="A1.F16" class="ltx_figure"><img src="/html/2107.06580/assets/x16.png" id="A1.F16.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="456" height="330" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 16: </span>Heatmap of the biases (<math id="A1.F16.2.m1.1" class="ltx_Math" alttext="\mathbf{b}_{\text{\tiny{in}}}" display="inline"><semantics id="A1.F16.2.m1.1b"><msub id="A1.F16.2.m1.1.1" xref="A1.F16.2.m1.1.1.cmml"><mi id="A1.F16.2.m1.1.1.2" xref="A1.F16.2.m1.1.1.2.cmml">𝐛</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.F16.2.m1.1.1.3" xref="A1.F16.2.m1.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.F16.2.m1.1c"><apply id="A1.F16.2.m1.1.1.cmml" xref="A1.F16.2.m1.1.1"><csymbol cd="ambiguous" id="A1.F16.2.m1.1.1.1.cmml" xref="A1.F16.2.m1.1.1">subscript</csymbol><ci id="A1.F16.2.m1.1.1.2.cmml" xref="A1.F16.2.m1.1.1.2">𝐛</ci><ci id="A1.F16.2.m1.1.1.3a.cmml" xref="A1.F16.2.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.F16.2.m1.1.1.3.cmml" xref="A1.F16.2.m1.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F16.2.m1.1d">\mathbf{b}_{\text{\tiny{in}}}</annotation></semantics></math>) for the Ebola Diagnosis dataset (left) and histograms of the referral time feature for ETCs Kalihun and Foya (right).</figcaption>
</figure>
</li>
<li id="A1.I1.i5" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I1.i5.p1" class="ltx_para">
<p id="A1.I1.i5.p1.1" class="ltx_p"><span id="A1.I1.i5.p1.1.1" class="ltx_text ltx_font_bold">Ebola Diagnosis - data collection differences:</span> As <span id="A1.I1.i5.p1.1.2" class="ltx_text ltx_font_italic">bias</span> in the local data could have catastrophic consequences, we highlight another example. For ETC Foya, whether a patient has a malaria co-infection only appears to be recorded for EVD-positive cases. Here, the ETC only records a malaria test in confirmed cases. For comparison, another ETC, Kalihun, is shown, which does not record malaria infection at all. Without explicitly detecting this effect, the personalized model might overfit in practice, with detrimental consequences. The heatmap and both histograms are shown in Figure <a href="#A1.F17" title="Figure 17 ‣ 5th item ‣ A.2 Supplementary interpretability results ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">17</span></a>.</p>
</div>
<figure id="A1.F17" class="ltx_figure"><img src="/html/2107.06580/assets/x17.png" id="A1.F17.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="456" height="277" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 17: </span>Heatmap of the weights (<math id="A1.F17.2.m1.1" class="ltx_Math" alttext="\mathbf{w}_{\text{\tiny{in}}}" display="inline"><semantics id="A1.F17.2.m1.1b"><msub id="A1.F17.2.m1.1.1" xref="A1.F17.2.m1.1.1.cmml"><mi id="A1.F17.2.m1.1.1.2" xref="A1.F17.2.m1.1.1.2.cmml">𝐰</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.F17.2.m1.1.1.3" xref="A1.F17.2.m1.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.F17.2.m1.1c"><apply id="A1.F17.2.m1.1.1.cmml" xref="A1.F17.2.m1.1.1"><csymbol cd="ambiguous" id="A1.F17.2.m1.1.1.1.cmml" xref="A1.F17.2.m1.1.1">subscript</csymbol><ci id="A1.F17.2.m1.1.1.2.cmml" xref="A1.F17.2.m1.1.1.2">𝐰</ci><ci id="A1.F17.2.m1.1.1.3a.cmml" xref="A1.F17.2.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.F17.2.m1.1.1.3.cmml" xref="A1.F17.2.m1.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F17.2.m1.1d">\mathbf{w}_{\text{\tiny{in}}}</annotation></semantics></math>) for the Ebola Diagnosis dataset (left) and histograms of the Malaria infection feature for ETCs Kalihun and Foya, split according to the target class (EVD- and EVD+) (right).</figcaption>
</figure>
</li>
</ul>
</div>
<div id="A1.SS2.p3" class="ltx_para">
<p id="A1.SS2.p3.1" class="ltx_p">The previous examples show that <span id="A1.SS2.p3.1.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> is able to detect and compensate for various types of discrepancies in the underlying local datasets. Some, however, might not be desirable, and therefore being able to identify, at a client and feature level, problematic values could help reduce model bias.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.3 </span>Hyperparameters and experimental setup</h3>

<div id="A1.SS3.p1" class="ltx_para">
<p id="A1.SS3.p1.4" class="ltx_p">In order to create the most comparable experiments, an identical network architecture was used for all experiments. This ensures that each method has the same number of parameters available in the base model. <span id="A1.SS3.p1.4.1" class="ltx_text ltx_font_typewriter">APFL</span>, of course, creates multiple copies of this model. We show the entire MLP architecture in Table <a href="#A1.T5" title="Table 5 ‣ A.3 Hyperparameters and experimental setup ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>, with <math id="A1.SS3.p1.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="A1.SS3.p1.1.m1.1a"><mi id="A1.SS3.p1.1.m1.1.1" xref="A1.SS3.p1.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="A1.SS3.p1.1.m1.1b"><ci id="A1.SS3.p1.1.m1.1.1.cmml" xref="A1.SS3.p1.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p1.1.m1.1c">D</annotation></semantics></math> the number of features and <math id="A1.SS3.p1.2.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="A1.SS3.p1.2.m2.1a"><mi id="A1.SS3.p1.2.m2.1.1" xref="A1.SS3.p1.2.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A1.SS3.p1.2.m2.1b"><ci id="A1.SS3.p1.2.m2.1.1.cmml" xref="A1.SS3.p1.2.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p1.2.m2.1c">K</annotation></semantics></math> the output dimension. <math id="A1.SS3.p1.3.m3.1" class="ltx_Math" alttext="K" display="inline"><semantics id="A1.SS3.p1.3.m3.1a"><mi id="A1.SS3.p1.3.m3.1.1" xref="A1.SS3.p1.3.m3.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A1.SS3.p1.3.m3.1b"><ci id="A1.SS3.p1.3.m3.1.1.cmml" xref="A1.SS3.p1.3.m3.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p1.3.m3.1c">K</annotation></semantics></math> is chosen to be the number of classes in our experiments, after which log-softmax is applied in conjunction with negative-log-likelihood loss. The class weights, used to weight the loss function, are computed as the inverse of class prevalence, scaled to sum to <math id="A1.SS3.p1.4.m4.1" class="ltx_Math" alttext="K" display="inline"><semantics id="A1.SS3.p1.4.m4.1a"><mi id="A1.SS3.p1.4.m4.1.1" xref="A1.SS3.p1.4.m4.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A1.SS3.p1.4.m4.1b"><ci id="A1.SS3.p1.4.m4.1.1.cmml" xref="A1.SS3.p1.4.m4.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p1.4.m4.1c">K</annotation></semantics></math>.</p>
</div>
<figure id="A1.T5" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 5: </span>Architecture of the MLP model used</figcaption>
<table id="A1.T5.8" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T5.8.9.1" class="ltx_tr">
<th id="A1.T5.8.9.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Type</th>
<th id="A1.T5.8.9.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Size (in, out)</th>
<th id="A1.T5.8.9.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Activation</th>
<th id="A1.T5.8.9.1.4" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Dropout</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T5.3.3" class="ltx_tr">
<th id="A1.T5.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t"><math id="A1.T5.1.1.1.m1.1" class="ltx_Math" alttext="f_{\text{\tiny{in}}}" display="inline"><semantics id="A1.T5.1.1.1.m1.1a"><msub id="A1.T5.1.1.1.m1.1.1" xref="A1.T5.1.1.1.m1.1.1.cmml"><mi id="A1.T5.1.1.1.m1.1.1.2" xref="A1.T5.1.1.1.m1.1.1.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.T5.1.1.1.m1.1.1.3" xref="A1.T5.1.1.1.m1.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T5.1.1.1.m1.1b"><apply id="A1.T5.1.1.1.m1.1.1.cmml" xref="A1.T5.1.1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T5.1.1.1.m1.1.1.1.cmml" xref="A1.T5.1.1.1.m1.1.1">subscript</csymbol><ci id="A1.T5.1.1.1.m1.1.1.2.cmml" xref="A1.T5.1.1.1.m1.1.1.2">𝑓</ci><ci id="A1.T5.1.1.1.m1.1.1.3a.cmml" xref="A1.T5.1.1.1.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.T5.1.1.1.m1.1.1.3.cmml" xref="A1.T5.1.1.1.m1.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.1.1.1.m1.1c">f_{\text{\tiny{in}}}</annotation></semantics></math></th>
<td id="A1.T5.3.3.3" class="ltx_td ltx_align_center ltx_border_t">(<math id="A1.T5.2.2.2.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="A1.T5.2.2.2.m1.1a"><mi id="A1.T5.2.2.2.m1.1.1" xref="A1.T5.2.2.2.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="A1.T5.2.2.2.m1.1b"><ci id="A1.T5.2.2.2.m1.1.1.cmml" xref="A1.T5.2.2.2.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.2.2.2.m1.1c">D</annotation></semantics></math>, <math id="A1.T5.3.3.3.m2.1" class="ltx_Math" alttext="D" display="inline"><semantics id="A1.T5.3.3.3.m2.1a"><mi id="A1.T5.3.3.3.m2.1.1" xref="A1.T5.3.3.3.m2.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="A1.T5.3.3.3.m2.1b"><ci id="A1.T5.3.3.3.m2.1.1.cmml" xref="A1.T5.3.3.3.m2.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.3.3.3.m2.1c">D</annotation></semantics></math>)</td>
<td id="A1.T5.3.3.4" class="ltx_td ltx_align_center ltx_border_t">-</td>
<td id="A1.T5.3.3.5" class="ltx_td ltx_align_center ltx_border_t">0.2</td>
</tr>
<tr id="A1.T5.4.4" class="ltx_tr">
<th id="A1.T5.4.4.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">Fully-connected</th>
<td id="A1.T5.4.4.1" class="ltx_td ltx_align_center">(<math id="A1.T5.4.4.1.m1.1" class="ltx_Math" alttext="D" display="inline"><semantics id="A1.T5.4.4.1.m1.1a"><mi id="A1.T5.4.4.1.m1.1.1" xref="A1.T5.4.4.1.m1.1.1.cmml">D</mi><annotation-xml encoding="MathML-Content" id="A1.T5.4.4.1.m1.1b"><ci id="A1.T5.4.4.1.m1.1.1.cmml" xref="A1.T5.4.4.1.m1.1.1">𝐷</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.4.4.1.m1.1c">D</annotation></semantics></math>, 128)</td>
<td id="A1.T5.4.4.3" class="ltx_td ltx_align_center">TanH</td>
<td id="A1.T5.4.4.4" class="ltx_td ltx_align_center">0.2</td>
</tr>
<tr id="A1.T5.8.10.1" class="ltx_tr">
<th id="A1.T5.8.10.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Fully-connected</th>
<td id="A1.T5.8.10.1.2" class="ltx_td ltx_align_center">(128, 64)</td>
<td id="A1.T5.8.10.1.3" class="ltx_td ltx_align_center">TanH</td>
<td id="A1.T5.8.10.1.4" class="ltx_td ltx_align_center">0.2</td>
</tr>
<tr id="A1.T5.5.5" class="ltx_tr">
<th id="A1.T5.5.5.2" class="ltx_td ltx_align_left ltx_th ltx_th_row">Fully-connected</th>
<td id="A1.T5.5.5.1" class="ltx_td ltx_align_center">(64, <math id="A1.T5.5.5.1.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="A1.T5.5.5.1.m1.1a"><mi id="A1.T5.5.5.1.m1.1.1" xref="A1.T5.5.5.1.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A1.T5.5.5.1.m1.1b"><ci id="A1.T5.5.5.1.m1.1.1.cmml" xref="A1.T5.5.5.1.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.5.5.1.m1.1c">K</annotation></semantics></math>)</td>
<td id="A1.T5.5.5.3" class="ltx_td ltx_align_center">-</td>
<td id="A1.T5.5.5.4" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="A1.T5.8.8" class="ltx_tr">
<th id="A1.T5.6.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb"><math id="A1.T5.6.6.1.m1.1" class="ltx_Math" alttext="f_{\text{\tiny{out}}}" display="inline"><semantics id="A1.T5.6.6.1.m1.1a"><msub id="A1.T5.6.6.1.m1.1.1" xref="A1.T5.6.6.1.m1.1.1.cmml"><mi id="A1.T5.6.6.1.m1.1.1.2" xref="A1.T5.6.6.1.m1.1.1.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.T5.6.6.1.m1.1.1.3" xref="A1.T5.6.6.1.m1.1.1.3a.cmml">out</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T5.6.6.1.m1.1b"><apply id="A1.T5.6.6.1.m1.1.1.cmml" xref="A1.T5.6.6.1.m1.1.1"><csymbol cd="ambiguous" id="A1.T5.6.6.1.m1.1.1.1.cmml" xref="A1.T5.6.6.1.m1.1.1">subscript</csymbol><ci id="A1.T5.6.6.1.m1.1.1.2.cmml" xref="A1.T5.6.6.1.m1.1.1.2">𝑓</ci><ci id="A1.T5.6.6.1.m1.1.1.3a.cmml" xref="A1.T5.6.6.1.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.T5.6.6.1.m1.1.1.3.cmml" xref="A1.T5.6.6.1.m1.1.1.3">out</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.6.6.1.m1.1c">f_{\text{\tiny{out}}}</annotation></semantics></math></th>
<td id="A1.T5.8.8.3" class="ltx_td ltx_align_center ltx_border_bb">(<math id="A1.T5.7.7.2.m1.1" class="ltx_Math" alttext="K" display="inline"><semantics id="A1.T5.7.7.2.m1.1a"><mi id="A1.T5.7.7.2.m1.1.1" xref="A1.T5.7.7.2.m1.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A1.T5.7.7.2.m1.1b"><ci id="A1.T5.7.7.2.m1.1.1.cmml" xref="A1.T5.7.7.2.m1.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.7.7.2.m1.1c">K</annotation></semantics></math>, <math id="A1.T5.8.8.3.m2.1" class="ltx_Math" alttext="K" display="inline"><semantics id="A1.T5.8.8.3.m2.1a"><mi id="A1.T5.8.8.3.m2.1.1" xref="A1.T5.8.8.3.m2.1.1.cmml">K</mi><annotation-xml encoding="MathML-Content" id="A1.T5.8.8.3.m2.1b"><ci id="A1.T5.8.8.3.m2.1.1.cmml" xref="A1.T5.8.8.3.m2.1.1">𝐾</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T5.8.8.3.m2.1c">K</annotation></semantics></math>)</td>
<td id="A1.T5.8.8.4" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="A1.T5.8.8.5" class="ltx_td ltx_align_center ltx_border_bb">-</td>
</tr>
</tbody>
</table>
</figure>
<div id="A1.SS3.p2" class="ltx_para">
<p id="A1.SS3.p2.8" class="ltx_p">Each experiment was conducted on the following seeds, which dictate the local train and holdout set splitting, network initialization and batch shuffling. <math id="A1.SS3.p2.1.m1.5" class="ltx_Math" alttext="2934384,10231938,8273,2019231,62739" display="inline"><semantics id="A1.SS3.p2.1.m1.5a"><mrow id="A1.SS3.p2.1.m1.5.6.2" xref="A1.SS3.p2.1.m1.5.6.1.cmml"><mn id="A1.SS3.p2.1.m1.1.1" xref="A1.SS3.p2.1.m1.1.1.cmml">2934384</mn><mo id="A1.SS3.p2.1.m1.5.6.2.1" xref="A1.SS3.p2.1.m1.5.6.1.cmml">,</mo><mn id="A1.SS3.p2.1.m1.2.2" xref="A1.SS3.p2.1.m1.2.2.cmml">10231938</mn><mo id="A1.SS3.p2.1.m1.5.6.2.2" xref="A1.SS3.p2.1.m1.5.6.1.cmml">,</mo><mn id="A1.SS3.p2.1.m1.3.3" xref="A1.SS3.p2.1.m1.3.3.cmml">8273</mn><mo id="A1.SS3.p2.1.m1.5.6.2.3" xref="A1.SS3.p2.1.m1.5.6.1.cmml">,</mo><mn id="A1.SS3.p2.1.m1.4.4" xref="A1.SS3.p2.1.m1.4.4.cmml">2019231</mn><mo id="A1.SS3.p2.1.m1.5.6.2.4" xref="A1.SS3.p2.1.m1.5.6.1.cmml">,</mo><mn id="A1.SS3.p2.1.m1.5.5" xref="A1.SS3.p2.1.m1.5.5.cmml">62739</mn></mrow><annotation-xml encoding="MathML-Content" id="A1.SS3.p2.1.m1.5b"><list id="A1.SS3.p2.1.m1.5.6.1.cmml" xref="A1.SS3.p2.1.m1.5.6.2"><cn type="integer" id="A1.SS3.p2.1.m1.1.1.cmml" xref="A1.SS3.p2.1.m1.1.1">2934384</cn><cn type="integer" id="A1.SS3.p2.1.m1.2.2.cmml" xref="A1.SS3.p2.1.m1.2.2">10231938</cn><cn type="integer" id="A1.SS3.p2.1.m1.3.3.cmml" xref="A1.SS3.p2.1.m1.3.3">8273</cn><cn type="integer" id="A1.SS3.p2.1.m1.4.4.cmml" xref="A1.SS3.p2.1.m1.4.4">2019231</cn><cn type="integer" id="A1.SS3.p2.1.m1.5.5.cmml" xref="A1.SS3.p2.1.m1.5.5">62739</cn></list></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p2.1.m1.5c">2934384,10231938,8273,2019231,62739</annotation></semantics></math>. The learning rate of SGD was set to <math id="A1.SS3.p2.2.m2.1" class="ltx_Math" alttext="0.002" display="inline"><semantics id="A1.SS3.p2.2.m2.1a"><mn id="A1.SS3.p2.2.m2.1.1" xref="A1.SS3.p2.2.m2.1.1.cmml">0.002</mn><annotation-xml encoding="MathML-Content" id="A1.SS3.p2.2.m2.1b"><cn type="float" id="A1.SS3.p2.2.m2.1.1.cmml" xref="A1.SS3.p2.2.m2.1.1">0.002</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p2.2.m2.1c">0.002</annotation></semantics></math> for all experiments and datasets, as this performed best across the board. The learning rate was decayed using a step function <math id="A1.SS3.p2.3.m3.1" class="ltx_Math" alttext="50" display="inline"><semantics id="A1.SS3.p2.3.m3.1a"><mn id="A1.SS3.p2.3.m3.1.1" xref="A1.SS3.p2.3.m3.1.1.cmml">50</mn><annotation-xml encoding="MathML-Content" id="A1.SS3.p2.3.m3.1b"><cn type="integer" id="A1.SS3.p2.3.m3.1.1.cmml" xref="A1.SS3.p2.3.m3.1.1">50</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p2.3.m3.1c">50</annotation></semantics></math> times, with a step of <math id="A1.SS3.p2.4.m4.1" class="ltx_Math" alttext="0.9" display="inline"><semantics id="A1.SS3.p2.4.m4.1a"><mn id="A1.SS3.p2.4.m4.1.1" xref="A1.SS3.p2.4.m4.1.1.cmml">0.9</mn><annotation-xml encoding="MathML-Content" id="A1.SS3.p2.4.m4.1b"><cn type="float" id="A1.SS3.p2.4.m4.1.1.cmml" xref="A1.SS3.p2.4.m4.1.1">0.9</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p2.4.m4.1c">0.9</annotation></semantics></math> for the entirety of the <math id="A1.SS3.p2.5.m5.1" class="ltx_Math" alttext="1000" display="inline"><semantics id="A1.SS3.p2.5.m5.1a"><mn id="A1.SS3.p2.5.m5.1.1" xref="A1.SS3.p2.5.m5.1.1.cmml">1000</mn><annotation-xml encoding="MathML-Content" id="A1.SS3.p2.5.m5.1b"><cn type="integer" id="A1.SS3.p2.5.m5.1.1.cmml" xref="A1.SS3.p2.5.m5.1.1">1000</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p2.5.m5.1c">1000</annotation></semantics></math> rounds. Client-side momentum with a value of <math id="A1.SS3.p2.6.m6.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="A1.SS3.p2.6.m6.1a"><mn id="A1.SS3.p2.6.m6.1.1" xref="A1.SS3.p2.6.m6.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="A1.SS3.p2.6.m6.1b"><cn type="float" id="A1.SS3.p2.6.m6.1.1.cmml" xref="A1.SS3.p2.6.m6.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p2.6.m6.1c">0.5</annotation></semantics></math> was enabled for all methods except <span id="A1.SS3.p2.8.1" class="ltx_text ltx_font_typewriter">APFL</span> as the authors do not discuss it. For <span id="A1.SS3.p2.8.2" class="ltx_text ltx_font_typewriter">APFL</span> the best <math id="A1.SS3.p2.7.m7.1" class="ltx_Math" alttext="\alpha" display="inline"><semantics id="A1.SS3.p2.7.m7.1a"><mi id="A1.SS3.p2.7.m7.1.1" xref="A1.SS3.p2.7.m7.1.1.cmml">α</mi><annotation-xml encoding="MathML-Content" id="A1.SS3.p2.7.m7.1b"><ci id="A1.SS3.p2.7.m7.1.1.cmml" xref="A1.SS3.p2.7.m7.1.1">𝛼</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p2.7.m7.1c">\alpha</annotation></semantics></math> was empirically found to be <math id="A1.SS3.p2.8.m8.1" class="ltx_Math" alttext="0.5" display="inline"><semantics id="A1.SS3.p2.8.m8.1a"><mn id="A1.SS3.p2.8.m8.1.1" xref="A1.SS3.p2.8.m8.1.1.cmml">0.5</mn><annotation-xml encoding="MathML-Content" id="A1.SS3.p2.8.m8.1b"><cn type="float" id="A1.SS3.p2.8.m8.1.1.cmml" xref="A1.SS3.p2.8.m8.1.1">0.5</cn></annotation-xml><annotation encoding="application/x-tex" id="A1.SS3.p2.8.m8.1c">0.5</annotation></semantics></math>. The F1 score was computed in a weighted fashion, ROC AUC with one-vs-one treatment for multi-class targets.</p>
</div>
<div id="A1.SS3.p3" class="ltx_para">
<p id="A1.SS3.p3.1" class="ltx_p">For both Ebola datasets, each client locally standardized the numerical features. For the VSN and HAR datasets, the original standardization of the benchmark datasets was retained. While there is no significant difference in the results, both modes are supported by <span id="A1.SS3.p3.1.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> and implemented in the opensourced code.</p>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A1.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.4 </span>Target shift layer </h3>

<div id="A1.SS4.p1" class="ltx_para">
<p id="A1.SS4.p1.2" class="ltx_p">Intuitively, the layer <math id="A1.SS4.p1.1.m1.1" class="ltx_Math" alttext="f_{\text{\tiny{out}}}" display="inline"><semantics id="A1.SS4.p1.1.m1.1a"><msub id="A1.SS4.p1.1.m1.1.1" xref="A1.SS4.p1.1.m1.1.1.cmml"><mi id="A1.SS4.p1.1.m1.1.1.2" xref="A1.SS4.p1.1.m1.1.1.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.SS4.p1.1.m1.1.1.3" xref="A1.SS4.p1.1.m1.1.1.3a.cmml">out</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.SS4.p1.1.m1.1b"><apply id="A1.SS4.p1.1.m1.1.1.cmml" xref="A1.SS4.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.SS4.p1.1.m1.1.1.1.cmml" xref="A1.SS4.p1.1.m1.1.1">subscript</csymbol><ci id="A1.SS4.p1.1.m1.1.1.2.cmml" xref="A1.SS4.p1.1.m1.1.1.2">𝑓</ci><ci id="A1.SS4.p1.1.m1.1.1.3a.cmml" xref="A1.SS4.p1.1.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.SS4.p1.1.m1.1.1.3.cmml" xref="A1.SS4.p1.1.m1.1.1.3">out</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.p1.1.m1.1c">f_{\text{\tiny{out}}}</annotation></semantics></math> acts as a personalized compensation of any differences in how the target differs for each client. For instance, one would hope to detect varying class imbalance and a less clear class distinction in this layer. Interpreting this layer is slightly less intuitive, as each value corresponds to a logit, not a real feature. Nonetheless we present results in this section of <span id="A1.SS4.p1.2.1" class="ltx_text ltx_font_typewriter">iFedAvg</span> with the training of local <math id="A1.SS4.p1.2.m2.1" class="ltx_Math" alttext="f_{\text{\tiny{out}}}" display="inline"><semantics id="A1.SS4.p1.2.m2.1a"><msub id="A1.SS4.p1.2.m2.1.1" xref="A1.SS4.p1.2.m2.1.1.cmml"><mi id="A1.SS4.p1.2.m2.1.1.2" xref="A1.SS4.p1.2.m2.1.1.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.SS4.p1.2.m2.1.1.3" xref="A1.SS4.p1.2.m2.1.1.3a.cmml">out</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.SS4.p1.2.m2.1b"><apply id="A1.SS4.p1.2.m2.1.1.cmml" xref="A1.SS4.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A1.SS4.p1.2.m2.1.1.1.cmml" xref="A1.SS4.p1.2.m2.1.1">subscript</csymbol><ci id="A1.SS4.p1.2.m2.1.1.2.cmml" xref="A1.SS4.p1.2.m2.1.1.2">𝑓</ci><ci id="A1.SS4.p1.2.m2.1.1.3a.cmml" xref="A1.SS4.p1.2.m2.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.SS4.p1.2.m2.1.1.3.cmml" xref="A1.SS4.p1.2.m2.1.1.3">out</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.SS4.p1.2.m2.1c">f_{\text{\tiny{out}}}</annotation></semantics></math> enabled.</p>
</div>
<div id="A1.SS4.p2" class="ltx_para">
<p id="A1.SS4.p2.1" class="ltx_p">First, we analyze the performance with the target layer enabled. As can be seen in Table <a href="#A1.T6" title="Table 6 ‣ A.4 Target shift layer ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>, for most datasets there is a marginal performance gain. This difference is not significant enough to warrant this layer as necessary, but also highlights that it is not detrimental.</p>
</div>
<figure id="A1.T6" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 6: </span>Performance difference with <math id="A1.T6.2.m1.1" class="ltx_Math" alttext="f_{\text{\tiny{out}}}" display="inline"><semantics id="A1.T6.2.m1.1b"><msub id="A1.T6.2.m1.1.1" xref="A1.T6.2.m1.1.1.cmml"><mi id="A1.T6.2.m1.1.1.2" xref="A1.T6.2.m1.1.1.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.T6.2.m1.1.1.3" xref="A1.T6.2.m1.1.1.3a.cmml">out</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.T6.2.m1.1c"><apply id="A1.T6.2.m1.1.1.cmml" xref="A1.T6.2.m1.1.1"><csymbol cd="ambiguous" id="A1.T6.2.m1.1.1.1.cmml" xref="A1.T6.2.m1.1.1">subscript</csymbol><ci id="A1.T6.2.m1.1.1.2.cmml" xref="A1.T6.2.m1.1.1.2">𝑓</ci><ci id="A1.T6.2.m1.1.1.3a.cmml" xref="A1.T6.2.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.T6.2.m1.1.1.3.cmml" xref="A1.T6.2.m1.1.1.3">out</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.2.m1.1d">f_{\text{\tiny{out}}}</annotation></semantics></math> enabled (F1 score)</figcaption>
<table id="A1.T6.4" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T6.4.2" class="ltx_tr">
<th id="A1.T6.4.2.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">Dataset</th>
<th id="A1.T6.3.1.1" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<math id="A1.T6.3.1.1.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="A1.T6.3.1.1.m1.1a"><mi mathvariant="normal" id="A1.T6.3.1.1.m1.1.1" xref="A1.T6.3.1.1.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T6.3.1.1.m1.1b"><ci id="A1.T6.3.1.1.m1.1.1.cmml" xref="A1.T6.3.1.1.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.3.1.1.m1.1c">\Delta</annotation></semantics></math> Average</th>
<th id="A1.T6.4.2.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">
<math id="A1.T6.4.2.2.m1.1" class="ltx_Math" alttext="\Delta" display="inline"><semantics id="A1.T6.4.2.2.m1.1a"><mi mathvariant="normal" id="A1.T6.4.2.2.m1.1.1" xref="A1.T6.4.2.2.m1.1.1.cmml">Δ</mi><annotation-xml encoding="MathML-Content" id="A1.T6.4.2.2.m1.1b"><ci id="A1.T6.4.2.2.m1.1.1.cmml" xref="A1.T6.4.2.2.m1.1.1">Δ</ci></annotation-xml><annotation encoding="application/x-tex" id="A1.T6.4.2.2.m1.1c">\Delta</annotation></semantics></math> Worst-performing client</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T6.4.3.1" class="ltx_tr">
<th id="A1.T6.4.3.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Ebola Prognosis</th>
<td id="A1.T6.4.3.1.2" class="ltx_td ltx_align_center ltx_border_t">+0.002</td>
<td id="A1.T6.4.3.1.3" class="ltx_td ltx_align_center ltx_border_t">+0.008</td>
</tr>
<tr id="A1.T6.4.4.2" class="ltx_tr">
<th id="A1.T6.4.4.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Ebola Diagnosis</th>
<td id="A1.T6.4.4.2.2" class="ltx_td ltx_align_center">+0.005</td>
<td id="A1.T6.4.4.2.3" class="ltx_td ltx_align_center">+0.008</td>
</tr>
<tr id="A1.T6.4.5.3" class="ltx_tr">
<th id="A1.T6.4.5.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Vehicle Sensor Network</th>
<td id="A1.T6.4.5.3.2" class="ltx_td ltx_align_center">+0.002</td>
<td id="A1.T6.4.5.3.3" class="ltx_td ltx_align_center">-</td>
</tr>
<tr id="A1.T6.4.6.4" class="ltx_tr">
<th id="A1.T6.4.6.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Human Activity Recognition</th>
<td id="A1.T6.4.6.4.2" class="ltx_td ltx_align_center ltx_border_bb">-</td>
<td id="A1.T6.4.6.4.3" class="ltx_td ltx_align_center ltx_border_bb">-0.013</td>
</tr>
</tbody>
</table>
</figure>
<div id="A1.SS4.p3" class="ltx_para">
<p id="A1.SS4.p3.1" class="ltx_p">We structure our analysis into the following three sections:</p>
<ul id="A1.I2" class="ltx_itemize">
<li id="A1.I2.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I2.i1.p1" class="ltx_para">
<p id="A1.I2.i1.p1.2" class="ltx_p"><span id="A1.I2.i1.p1.2.1" class="ltx_text ltx_font_bold">Overall results:</span> We show the heatmaps of <math id="A1.I2.i1.p1.1.m1.1" class="ltx_Math" alttext="\mathbf{b}_{\text{\tiny{out}}}" display="inline"><semantics id="A1.I2.i1.p1.1.m1.1a"><msub id="A1.I2.i1.p1.1.m1.1.1" xref="A1.I2.i1.p1.1.m1.1.1.cmml"><mi id="A1.I2.i1.p1.1.m1.1.1.2" xref="A1.I2.i1.p1.1.m1.1.1.2.cmml">𝐛</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.I2.i1.p1.1.m1.1.1.3" xref="A1.I2.i1.p1.1.m1.1.1.3a.cmml">out</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.I2.i1.p1.1.m1.1b"><apply id="A1.I2.i1.p1.1.m1.1.1.cmml" xref="A1.I2.i1.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.I2.i1.p1.1.m1.1.1.1.cmml" xref="A1.I2.i1.p1.1.m1.1.1">subscript</csymbol><ci id="A1.I2.i1.p1.1.m1.1.1.2.cmml" xref="A1.I2.i1.p1.1.m1.1.1.2">𝐛</ci><ci id="A1.I2.i1.p1.1.m1.1.1.3a.cmml" xref="A1.I2.i1.p1.1.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.I2.i1.p1.1.m1.1.1.3.cmml" xref="A1.I2.i1.p1.1.m1.1.1.3">out</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.I2.i1.p1.1.m1.1c">\mathbf{b}_{\text{\tiny{out}}}</annotation></semantics></math> and <math id="A1.I2.i1.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{w}_{\text{\tiny{out}}}" display="inline"><semantics id="A1.I2.i1.p1.2.m2.1a"><msub id="A1.I2.i1.p1.2.m2.1.1" xref="A1.I2.i1.p1.2.m2.1.1.cmml"><mi id="A1.I2.i1.p1.2.m2.1.1.2" xref="A1.I2.i1.p1.2.m2.1.1.2.cmml">𝐰</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.I2.i1.p1.2.m2.1.1.3" xref="A1.I2.i1.p1.2.m2.1.1.3a.cmml">out</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.I2.i1.p1.2.m2.1b"><apply id="A1.I2.i1.p1.2.m2.1.1.cmml" xref="A1.I2.i1.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A1.I2.i1.p1.2.m2.1.1.1.cmml" xref="A1.I2.i1.p1.2.m2.1.1">subscript</csymbol><ci id="A1.I2.i1.p1.2.m2.1.1.2.cmml" xref="A1.I2.i1.p1.2.m2.1.1.2">𝐰</ci><ci id="A1.I2.i1.p1.2.m2.1.1.3a.cmml" xref="A1.I2.i1.p1.2.m2.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.I2.i1.p1.2.m2.1.1.3.cmml" xref="A1.I2.i1.p1.2.m2.1.1.3">out</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.I2.i1.p1.2.m2.1c">\mathbf{w}_{\text{\tiny{out}}}</annotation></semantics></math> for EVD Diagnosis in Figure <a href="#A1.F18" title="Figure 18 ‣ 1st item ‣ A.4 Target shift layer ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">18</span></a>. Each column now no longer represents input features, but the logit of each target class (0 being negative, 1 being positive diagnosis). In addition to the setting with both the bias and weight being trained locally, we also explore enabling the personalized training on each independently. It is visually apparent, that there are many smaller deviations, but few stand out except the weight of class 1 and ETC Foya. These shifts are not directly correlated with easily visible characteristics such as positivity rate. Therefore, the learned shifts are more complex to diagnose, and should be used as an indicator of potentially other issues. This is an interesting future research avenue.</p>
</div>
<figure id="A1.F18" class="ltx_figure"><img src="/html/2107.06580/assets/x18.png" id="A1.F18.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="456" height="312" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 18: </span>Heatmap of biases and weights (<math id="A1.F18.3.m1.1" class="ltx_Math" alttext="\mathbf{b}_{\text{\tiny{out}}}" display="inline"><semantics id="A1.F18.3.m1.1b"><msub id="A1.F18.3.m1.1.1" xref="A1.F18.3.m1.1.1.cmml"><mi id="A1.F18.3.m1.1.1.2" xref="A1.F18.3.m1.1.1.2.cmml">𝐛</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.F18.3.m1.1.1.3" xref="A1.F18.3.m1.1.1.3a.cmml">out</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.F18.3.m1.1c"><apply id="A1.F18.3.m1.1.1.cmml" xref="A1.F18.3.m1.1.1"><csymbol cd="ambiguous" id="A1.F18.3.m1.1.1.1.cmml" xref="A1.F18.3.m1.1.1">subscript</csymbol><ci id="A1.F18.3.m1.1.1.2.cmml" xref="A1.F18.3.m1.1.1.2">𝐛</ci><ci id="A1.F18.3.m1.1.1.3a.cmml" xref="A1.F18.3.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.F18.3.m1.1.1.3.cmml" xref="A1.F18.3.m1.1.1.3">out</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F18.3.m1.1d">\mathbf{b}_{\text{\tiny{out}}}</annotation></semantics></math> and <math id="A1.F18.4.m2.1" class="ltx_Math" alttext="\mathbf{w}_{\text{\tiny{out}}}" display="inline"><semantics id="A1.F18.4.m2.1b"><msub id="A1.F18.4.m2.1.1" xref="A1.F18.4.m2.1.1.cmml"><mi id="A1.F18.4.m2.1.1.2" xref="A1.F18.4.m2.1.1.2.cmml">𝐰</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.F18.4.m2.1.1.3" xref="A1.F18.4.m2.1.1.3a.cmml">out</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.F18.4.m2.1c"><apply id="A1.F18.4.m2.1.1.cmml" xref="A1.F18.4.m2.1.1"><csymbol cd="ambiguous" id="A1.F18.4.m2.1.1.1.cmml" xref="A1.F18.4.m2.1.1">subscript</csymbol><ci id="A1.F18.4.m2.1.1.2.cmml" xref="A1.F18.4.m2.1.1.2">𝐰</ci><ci id="A1.F18.4.m2.1.1.3a.cmml" xref="A1.F18.4.m2.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.F18.4.m2.1.1.3.cmml" xref="A1.F18.4.m2.1.1.3">out</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F18.4.m2.1d">\mathbf{w}_{\text{\tiny{out}}}</annotation></semantics></math>) of the target layer for the Ebola Diagnosis dataset. Each column represents the positive and negative class. Three configurations are shown: 1) both bias and weight trained locally (left), 2) only bias trained locally (middle) and only weight trained locally (right).</figcaption>
</figure>
</li>
<li id="A1.I2.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I2.i2.p1" class="ltx_para">
<p id="A1.I2.i2.p1.3" class="ltx_p"><span id="A1.I2.i2.p1.3.1" class="ltx_text ltx_font_bold">Detecting mis-labeled targets:</span> While not as common as poorly standardized features, it is possible that due to a simple translation error, the label for a single client is flipped. With methods other than <span id="A1.I2.i2.p1.3.2" class="ltx_text ltx_font_typewriter">iFedAvg</span>, this would result in terrible performance, and no interpretable output to help detect the issue. With an enabled target layer, <math id="A1.I2.i2.p1.1.m1.1" class="ltx_Math" alttext="f_{\text{\tiny{out}}}" display="inline"><semantics id="A1.I2.i2.p1.1.m1.1a"><msub id="A1.I2.i2.p1.1.m1.1.1" xref="A1.I2.i2.p1.1.m1.1.1.cmml"><mi id="A1.I2.i2.p1.1.m1.1.1.2" xref="A1.I2.i2.p1.1.m1.1.1.2.cmml">f</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.I2.i2.p1.1.m1.1.1.3" xref="A1.I2.i2.p1.1.m1.1.1.3a.cmml">out</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.I2.i2.p1.1.m1.1b"><apply id="A1.I2.i2.p1.1.m1.1.1.cmml" xref="A1.I2.i2.p1.1.m1.1.1"><csymbol cd="ambiguous" id="A1.I2.i2.p1.1.m1.1.1.1.cmml" xref="A1.I2.i2.p1.1.m1.1.1">subscript</csymbol><ci id="A1.I2.i2.p1.1.m1.1.1.2.cmml" xref="A1.I2.i2.p1.1.m1.1.1.2">𝑓</ci><ci id="A1.I2.i2.p1.1.m1.1.1.3a.cmml" xref="A1.I2.i2.p1.1.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.I2.i2.p1.1.m1.1.1.3.cmml" xref="A1.I2.i2.p1.1.m1.1.1.3">out</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.I2.i2.p1.1.m1.1c">f_{\text{\tiny{out}}}</annotation></semantics></math>, this becomes quite trivial. Figure <a href="#A1.F19" title="Figure 19 ‣ 2nd item ‣ A.4 Target shift layer ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">19</span></a> shows the heatmap for EVD Diagnosis, where for ETC Kalihun, the label was artificially swapped. An interesting alternative definition of <math id="A1.I2.i2.p1.2.m2.1" class="ltx_Math" alttext="\mathbf{w}_{\text{\tiny{out}}}" display="inline"><semantics id="A1.I2.i2.p1.2.m2.1a"><msub id="A1.I2.i2.p1.2.m2.1.1" xref="A1.I2.i2.p1.2.m2.1.1.cmml"><mi id="A1.I2.i2.p1.2.m2.1.1.2" xref="A1.I2.i2.p1.2.m2.1.1.2.cmml">𝐰</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.I2.i2.p1.2.m2.1.1.3" xref="A1.I2.i2.p1.2.m2.1.1.3a.cmml">out</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.I2.i2.p1.2.m2.1b"><apply id="A1.I2.i2.p1.2.m2.1.1.cmml" xref="A1.I2.i2.p1.2.m2.1.1"><csymbol cd="ambiguous" id="A1.I2.i2.p1.2.m2.1.1.1.cmml" xref="A1.I2.i2.p1.2.m2.1.1">subscript</csymbol><ci id="A1.I2.i2.p1.2.m2.1.1.2.cmml" xref="A1.I2.i2.p1.2.m2.1.1.2">𝐰</ci><ci id="A1.I2.i2.p1.2.m2.1.1.3a.cmml" xref="A1.I2.i2.p1.2.m2.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.I2.i2.p1.2.m2.1.1.3.cmml" xref="A1.I2.i2.p1.2.m2.1.1.3">out</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.I2.i2.p1.2.m2.1c">\mathbf{w}_{\text{\tiny{out}}}</annotation></semantics></math> would be as a single scalar value, instead of a vector <math id="A1.I2.i2.p1.3.m3.1" class="ltx_Math" alttext="\in\mathbb{R}^{K}" display="inline"><semantics id="A1.I2.i2.p1.3.m3.1a"><mrow id="A1.I2.i2.p1.3.m3.1.1" xref="A1.I2.i2.p1.3.m3.1.1.cmml"><mi id="A1.I2.i2.p1.3.m3.1.1.2" xref="A1.I2.i2.p1.3.m3.1.1.2.cmml"></mi><mo id="A1.I2.i2.p1.3.m3.1.1.1" xref="A1.I2.i2.p1.3.m3.1.1.1.cmml">∈</mo><msup id="A1.I2.i2.p1.3.m3.1.1.3" xref="A1.I2.i2.p1.3.m3.1.1.3.cmml"><mi id="A1.I2.i2.p1.3.m3.1.1.3.2" xref="A1.I2.i2.p1.3.m3.1.1.3.2.cmml">ℝ</mi><mi id="A1.I2.i2.p1.3.m3.1.1.3.3" xref="A1.I2.i2.p1.3.m3.1.1.3.3.cmml">K</mi></msup></mrow><annotation-xml encoding="MathML-Content" id="A1.I2.i2.p1.3.m3.1b"><apply id="A1.I2.i2.p1.3.m3.1.1.cmml" xref="A1.I2.i2.p1.3.m3.1.1"><in id="A1.I2.i2.p1.3.m3.1.1.1.cmml" xref="A1.I2.i2.p1.3.m3.1.1.1"></in><csymbol cd="latexml" id="A1.I2.i2.p1.3.m3.1.1.2.cmml" xref="A1.I2.i2.p1.3.m3.1.1.2">absent</csymbol><apply id="A1.I2.i2.p1.3.m3.1.1.3.cmml" xref="A1.I2.i2.p1.3.m3.1.1.3"><csymbol cd="ambiguous" id="A1.I2.i2.p1.3.m3.1.1.3.1.cmml" xref="A1.I2.i2.p1.3.m3.1.1.3">superscript</csymbol><ci id="A1.I2.i2.p1.3.m3.1.1.3.2.cmml" xref="A1.I2.i2.p1.3.m3.1.1.3.2">ℝ</ci><ci id="A1.I2.i2.p1.3.m3.1.1.3.3.cmml" xref="A1.I2.i2.p1.3.m3.1.1.3.3">𝐾</ci></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.I2.i2.p1.3.m3.1c">\in\mathbb{R}^{K}</annotation></semantics></math>. This only allows each client a single multiplicative scaling of the last outputs. We show this setting in the right hand side of Figure <a href="#A1.F19" title="Figure 19 ‣ 2nd item ‣ A.4 Target shift layer ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">19</span></a>. As can be observed in both constellations, a large negative weight is learned, indicating that for one class, the label is inverted. This is particularly apparent in the scalar setting. With this information, a client in the federation would have a strong indication that an interoperability issue does not originate from the features, but from the target itself.</p>
</div>
<figure id="A1.F19" class="ltx_figure"><img src="/html/2107.06580/assets/x19.png" id="A1.F19.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="456" height="312" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 19: </span>Heatmap of biases and weights (<math id="A1.F19.5.m1.1" class="ltx_Math" alttext="\mathbf{b}_{\text{\tiny{out}}}" display="inline"><semantics id="A1.F19.5.m1.1b"><msub id="A1.F19.5.m1.1.1" xref="A1.F19.5.m1.1.1.cmml"><mi id="A1.F19.5.m1.1.1.2" xref="A1.F19.5.m1.1.1.2.cmml">𝐛</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.F19.5.m1.1.1.3" xref="A1.F19.5.m1.1.1.3a.cmml">out</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.F19.5.m1.1c"><apply id="A1.F19.5.m1.1.1.cmml" xref="A1.F19.5.m1.1.1"><csymbol cd="ambiguous" id="A1.F19.5.m1.1.1.1.cmml" xref="A1.F19.5.m1.1.1">subscript</csymbol><ci id="A1.F19.5.m1.1.1.2.cmml" xref="A1.F19.5.m1.1.1.2">𝐛</ci><ci id="A1.F19.5.m1.1.1.3a.cmml" xref="A1.F19.5.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.F19.5.m1.1.1.3.cmml" xref="A1.F19.5.m1.1.1.3">out</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F19.5.m1.1d">\mathbf{b}_{\text{\tiny{out}}}</annotation></semantics></math> and <math id="A1.F19.6.m2.1" class="ltx_Math" alttext="\mathbf{w}_{\text{\tiny{out}}}" display="inline"><semantics id="A1.F19.6.m2.1b"><msub id="A1.F19.6.m2.1.1" xref="A1.F19.6.m2.1.1.cmml"><mi id="A1.F19.6.m2.1.1.2" xref="A1.F19.6.m2.1.1.2.cmml">𝐰</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.F19.6.m2.1.1.3" xref="A1.F19.6.m2.1.1.3a.cmml">out</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.F19.6.m2.1c"><apply id="A1.F19.6.m2.1.1.cmml" xref="A1.F19.6.m2.1.1"><csymbol cd="ambiguous" id="A1.F19.6.m2.1.1.1.cmml" xref="A1.F19.6.m2.1.1">subscript</csymbol><ci id="A1.F19.6.m2.1.1.2.cmml" xref="A1.F19.6.m2.1.1.2">𝐰</ci><ci id="A1.F19.6.m2.1.1.3a.cmml" xref="A1.F19.6.m2.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.F19.6.m2.1.1.3.cmml" xref="A1.F19.6.m2.1.1.3">out</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F19.6.m2.1d">\mathbf{w}_{\text{\tiny{out}}}</annotation></semantics></math>) of the target layer for the Ebola Diagnosis dataset with an artificially introduced target flip for ETC Kalihun (marked). Two configurations are shown: 1) <math id="A1.F19.7.m3.1" class="ltx_Math" alttext="\mathbf{w}_{\text{\tiny{out}}}" display="inline"><semantics id="A1.F19.7.m3.1b"><msub id="A1.F19.7.m3.1.1" xref="A1.F19.7.m3.1.1.cmml"><mi id="A1.F19.7.m3.1.1.2" xref="A1.F19.7.m3.1.1.2.cmml">𝐰</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.F19.7.m3.1.1.3" xref="A1.F19.7.m3.1.1.3a.cmml">out</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.F19.7.m3.1c"><apply id="A1.F19.7.m3.1.1.cmml" xref="A1.F19.7.m3.1.1"><csymbol cd="ambiguous" id="A1.F19.7.m3.1.1.1.cmml" xref="A1.F19.7.m3.1.1">subscript</csymbol><ci id="A1.F19.7.m3.1.1.2.cmml" xref="A1.F19.7.m3.1.1.2">𝐰</ci><ci id="A1.F19.7.m3.1.1.3a.cmml" xref="A1.F19.7.m3.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.F19.7.m3.1.1.3.cmml" xref="A1.F19.7.m3.1.1.3">out</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F19.7.m3.1d">\mathbf{w}_{\text{\tiny{out}}}</annotation></semantics></math> is a vector, with a value for each target class (left) and <math id="A1.F19.8.m4.1" class="ltx_Math" alttext="\mathbf{w}_{\text{\tiny{out}}}" display="inline"><semantics id="A1.F19.8.m4.1b"><msub id="A1.F19.8.m4.1.1" xref="A1.F19.8.m4.1.1.cmml"><mi id="A1.F19.8.m4.1.1.2" xref="A1.F19.8.m4.1.1.2.cmml">𝐰</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.F19.8.m4.1.1.3" xref="A1.F19.8.m4.1.1.3a.cmml">out</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.F19.8.m4.1c"><apply id="A1.F19.8.m4.1.1.cmml" xref="A1.F19.8.m4.1.1"><csymbol cd="ambiguous" id="A1.F19.8.m4.1.1.1.cmml" xref="A1.F19.8.m4.1.1">subscript</csymbol><ci id="A1.F19.8.m4.1.1.2.cmml" xref="A1.F19.8.m4.1.1.2">𝐰</ci><ci id="A1.F19.8.m4.1.1.3a.cmml" xref="A1.F19.8.m4.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.F19.8.m4.1.1.3.cmml" xref="A1.F19.8.m4.1.1.3">out</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F19.8.m4.1d">\mathbf{w}_{\text{\tiny{out}}}</annotation></semantics></math> is a scalar with a single value (right).</figcaption>
</figure>
</li>
<li id="A1.I2.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="A1.I2.i3.p1" class="ltx_para">
<p id="A1.I2.i3.p1.1" class="ltx_p"><span id="A1.I2.i3.p1.1.1" class="ltx_text ltx_font_bold">Consistent feature weights:</span> An undesirable effect of enabling the personalized target layer learning would be an impact on the feature-wise interpretable results. We highlight how this effect is marginal in Figure <a href="#A1.F20" title="Figure 20 ‣ 3rd item ‣ A.4 Target shift layer ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">20</span></a>. Therefore, the target layer can be enabled for most use-cases, especially when a target-swap could occur.</p>
</div>
<figure id="A1.F20" class="ltx_figure"><img src="/html/2107.06580/assets/x20.png" id="A1.F20.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="456" height="225" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 20: </span>Heatmaps of the feature weights (<math id="A1.F20.2.m1.1" class="ltx_Math" alttext="\mathbf{w}_{\text{\tiny{in}}}" display="inline"><semantics id="A1.F20.2.m1.1b"><msub id="A1.F20.2.m1.1.1" xref="A1.F20.2.m1.1.1.cmml"><mi id="A1.F20.2.m1.1.1.2" xref="A1.F20.2.m1.1.1.2.cmml">𝐰</mi><mtext class="ltx_mathvariant_sans-serif" mathsize="71%" id="A1.F20.2.m1.1.1.3" xref="A1.F20.2.m1.1.1.3a.cmml">in</mtext></msub><annotation-xml encoding="MathML-Content" id="A1.F20.2.m1.1c"><apply id="A1.F20.2.m1.1.1.cmml" xref="A1.F20.2.m1.1.1"><csymbol cd="ambiguous" id="A1.F20.2.m1.1.1.1.cmml" xref="A1.F20.2.m1.1.1">subscript</csymbol><ci id="A1.F20.2.m1.1.1.2.cmml" xref="A1.F20.2.m1.1.1.2">𝐰</ci><ci id="A1.F20.2.m1.1.1.3a.cmml" xref="A1.F20.2.m1.1.1.3"><mtext class="ltx_mathvariant_sans-serif" mathsize="50%" id="A1.F20.2.m1.1.1.3.cmml" xref="A1.F20.2.m1.1.1.3">in</mtext></ci></apply></annotation-xml><annotation encoding="application/x-tex" id="A1.F20.2.m1.1d">\mathbf{w}_{\text{\tiny{in}}}</annotation></semantics></math>) for the Ebola Diagnosis dataset with local training of the target layer (bias and weight) disabled (top) and enabled (bottom)</figcaption>
</figure>
</li>
</ul>
</div>
<div class="ltx_pagination ltx_role_newpage"></div>
</section>
<section id="A1.SS5" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">A.5 </span>Ebola dataset statistics</h3>

<div id="A1.SS5.p1" class="ltx_para">
<p id="A1.SS5.p1.1" class="ltx_p">In Table <a href="#A1.T7" title="Table 7 ‣ A.5 Ebola dataset statistics ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> and <a href="#A1.T8" title="Table 8 ‣ A.5 Ebola dataset statistics ‣ Appendix A Appendix ‣ iFedAvg – Interpretable Data-Interoperability for Federated Learning" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> we show the number of samples at each treatment center. For prognosis, only patients where the outcome is known and a patient was confirmed EVD positive are considered. For diagnosis, only patients where an EVD test was performed and the minority class has at least 2% of samples are included. This leads to the fact that not the same ETCs are represented for both tasks. The reason being that some ETCs did not monitor mortality, or others only treated EVD+ cases.</p>
</div>
<figure id="A1.T7" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 7: </span>Ebola Prognosis dataset summary statistics</figcaption>
<table id="A1.T7.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T7.1.1.1" class="ltx_tr">
<th id="A1.T7.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">ETC</th>
<th id="A1.T7.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Number of samples</th>
<th id="A1.T7.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Mortality rate</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T7.1.2.1" class="ltx_tr">
<th id="A1.T7.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Guéckédou</th>
<td id="A1.T7.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">1366</td>
<td id="A1.T7.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">66.98%</td>
</tr>
<tr id="A1.T7.1.3.2" class="ltx_tr">
<th id="A1.T7.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Monrovia</th>
<td id="A1.T7.1.3.2.2" class="ltx_td ltx_align_center">1154</td>
<td id="A1.T7.1.3.2.3" class="ltx_td ltx_align_center">56.85%</td>
</tr>
<tr id="A1.T7.1.4.3" class="ltx_tr">
<th id="A1.T7.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Kalihun</th>
<td id="A1.T7.1.4.3.2" class="ltx_td ltx_align_center">852</td>
<td id="A1.T7.1.4.3.3" class="ltx_td ltx_align_center">44.37%</td>
</tr>
<tr id="A1.T7.1.5.4" class="ltx_tr">
<th id="A1.T7.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Donka (EJPDEJ)</th>
<td id="A1.T7.1.5.4.2" class="ltx_td ltx_align_center">748</td>
<td id="A1.T7.1.5.4.3" class="ltx_td ltx_align_center">49.87%</td>
</tr>
<tr id="A1.T7.1.6.5" class="ltx_tr">
<th id="A1.T7.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Foya</th>
<td id="A1.T7.1.6.5.2" class="ltx_td ltx_align_center">450</td>
<td id="A1.T7.1.6.5.3" class="ltx_td ltx_align_center">66.00%</td>
</tr>
<tr id="A1.T7.1.7.6" class="ltx_tr">
<th id="A1.T7.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Bo</th>
<td id="A1.T7.1.7.6.2" class="ltx_td ltx_align_center">440</td>
<td id="A1.T7.1.7.6.3" class="ltx_td ltx_align_center">38.63%</td>
</tr>
<tr id="A1.T7.1.8.7" class="ltx_tr">
<th id="A1.T7.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Donka (EFFVXT)</th>
<td id="A1.T7.1.8.7.2" class="ltx_td ltx_align_center">418</td>
<td id="A1.T7.1.8.7.3" class="ltx_td ltx_align_center">37.80%</td>
</tr>
<tr id="A1.T7.1.9.8" class="ltx_tr">
<th id="A1.T7.1.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Kerry-Town</th>
<td id="A1.T7.1.9.8.2" class="ltx_td ltx_align_center">263</td>
<td id="A1.T7.1.9.8.3" class="ltx_td ltx_align_center">42.59%</td>
</tr>
<tr id="A1.T7.1.10.9" class="ltx_tr">
<th id="A1.T7.1.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Port-Loko</th>
<td id="A1.T7.1.10.9.2" class="ltx_td ltx_align_center">181</td>
<td id="A1.T7.1.10.9.3" class="ltx_td ltx_align_center">65.75%</td>
</tr>
<tr id="A1.T7.1.11.10" class="ltx_tr">
<th id="A1.T7.1.11.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Makeni</th>
<td id="A1.T7.1.11.10.2" class="ltx_td ltx_align_center">176</td>
<td id="A1.T7.1.11.10.3" class="ltx_td ltx_align_center">56.82%</td>
</tr>
<tr id="A1.T7.1.12.11" class="ltx_tr">
<th id="A1.T7.1.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Bong</th>
<td id="A1.T7.1.12.11.2" class="ltx_td ltx_align_center">168</td>
<td id="A1.T7.1.12.11.3" class="ltx_td ltx_align_center">50.00%</td>
</tr>
<tr id="A1.T7.1.13.12" class="ltx_tr">
<th id="A1.T7.1.13.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Freetown</th>
<td id="A1.T7.1.13.12.2" class="ltx_td ltx_align_center ltx_border_bb">166</td>
<td id="A1.T7.1.13.12.3" class="ltx_td ltx_align_center ltx_border_bb">50.00%</td>
</tr>
</tbody>
</table>
</figure>
<figure id="A1.T8" class="ltx_table">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_table">Table 8: </span>Ebola Diagnosis dataset summary statistics</figcaption>
<table id="A1.T8.1" class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="A1.T8.1.1.1" class="ltx_tr">
<th id="A1.T8.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_th_row ltx_border_tt">ETC</th>
<th id="A1.T8.1.1.1.2" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Number of samples</th>
<th id="A1.T8.1.1.1.3" class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_tt">Positivity rate</th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="A1.T8.1.2.1" class="ltx_tr">
<th id="A1.T8.1.2.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_t">Donka</th>
<td id="A1.T8.1.2.1.2" class="ltx_td ltx_align_center ltx_border_t">1975</td>
<td id="A1.T8.1.2.1.3" class="ltx_td ltx_align_center ltx_border_t">37.87%</td>
</tr>
<tr id="A1.T8.1.3.2" class="ltx_tr">
<th id="A1.T8.1.3.2.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Guéckédou</th>
<td id="A1.T8.1.3.2.2" class="ltx_td ltx_align_center">1517</td>
<td id="A1.T8.1.3.2.3" class="ltx_td ltx_align_center">90.05%</td>
</tr>
<tr id="A1.T8.1.4.3" class="ltx_tr">
<th id="A1.T8.1.4.3.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Kalihun</th>
<td id="A1.T8.1.4.3.2" class="ltx_td ltx_align_center">1173</td>
<td id="A1.T8.1.4.3.3" class="ltx_td ltx_align_center">72.63%</td>
</tr>
<tr id="A1.T8.1.5.4" class="ltx_tr">
<th id="A1.T8.1.5.4.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Makeni</th>
<td id="A1.T8.1.5.4.2" class="ltx_td ltx_align_center">848</td>
<td id="A1.T8.1.5.4.3" class="ltx_td ltx_align_center">20.75%</td>
</tr>
<tr id="A1.T8.1.6.5" class="ltx_tr">
<th id="A1.T8.1.6.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Foya</th>
<td id="A1.T8.1.6.5.2" class="ltx_td ltx_align_center">564</td>
<td id="A1.T8.1.6.5.3" class="ltx_td ltx_align_center">79.79%</td>
</tr>
<tr id="A1.T8.1.7.6" class="ltx_tr">
<th id="A1.T8.1.7.6.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Bong</th>
<td id="A1.T8.1.7.6.2" class="ltx_td ltx_align_center">529</td>
<td id="A1.T8.1.7.6.3" class="ltx_td ltx_align_center">31.76%</td>
</tr>
<tr id="A1.T8.1.8.7" class="ltx_tr">
<th id="A1.T8.1.8.7.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Bo</th>
<td id="A1.T8.1.8.7.2" class="ltx_td ltx_align_center">519</td>
<td id="A1.T8.1.8.7.3" class="ltx_td ltx_align_center">84.78%</td>
</tr>
<tr id="A1.T8.1.9.8" class="ltx_tr">
<th id="A1.T8.1.9.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Port-Loko</th>
<td id="A1.T8.1.9.8.2" class="ltx_td ltx_align_center">477</td>
<td id="A1.T8.1.9.8.3" class="ltx_td ltx_align_center">37.95%</td>
</tr>
<tr id="A1.T8.1.10.9" class="ltx_tr">
<th id="A1.T8.1.10.9.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Kerry-Town</th>
<td id="A1.T8.1.10.9.2" class="ltx_td ltx_align_center">275</td>
<td id="A1.T8.1.10.9.3" class="ltx_td ltx_align_center">95.64%</td>
</tr>
<tr id="A1.T8.1.11.10" class="ltx_tr">
<th id="A1.T8.1.11.10.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Kambia</th>
<td id="A1.T8.1.11.10.2" class="ltx_td ltx_align_center">217</td>
<td id="A1.T8.1.11.10.3" class="ltx_td ltx_align_center">21.66%</td>
</tr>
<tr id="A1.T8.1.12.11" class="ltx_tr">
<th id="A1.T8.1.12.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row">Magburaka</th>
<td id="A1.T8.1.12.11.2" class="ltx_td ltx_align_center">155</td>
<td id="A1.T8.1.12.11.3" class="ltx_td ltx_align_center">29.03%</td>
</tr>
<tr id="A1.T8.1.13.12" class="ltx_tr">
<th id="A1.T8.1.13.12.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_bb">Nzérékoré</th>
<td id="A1.T8.1.13.12.2" class="ltx_td ltx_align_center ltx_border_bb">137</td>
<td id="A1.T8.1.13.12.3" class="ltx_td ltx_align_center ltx_border_bb">57.66%</td>
</tr>
</tbody>
</table>
</figure>
</section>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2107.06579" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2107.06580" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2107.06580">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2107.06580" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2107.06581" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Tue Mar 19 13:19:24 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
