<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2011.07516] 2CP: Decentralized Protocols to Transparently Evaluate Contributivity in Blockchain Federated Learning Environments</title><meta property="og:description" content="Federated Learning harnesses data from multiple sources to build a single model. While the initial model might belong solely to the actor bringing it to the network for training, determining the ownership of the traine…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="2CP: Decentralized Protocols to Transparently Evaluate Contributivity in Blockchain Federated Learning Environments">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="2CP: Decentralized Protocols to Transparently Evaluate Contributivity in Blockchain Federated Learning Environments">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2011.07516">

<!--Generated on Fri Mar 15 23:59:03 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">2CP: Decentralized Protocols to Transparently Evaluate Contributivity in Blockchain Federated Learning Environments</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Harry Cai


</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Imperial College London, UK
<br class="ltx_break">Vodafone
<br class="ltx_break">Email: harry.cai@hotmail.com
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Daniel Rueckert
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Imperial College London, UK
<br class="ltx_break">Technical University of Munich, Germany
<br class="ltx_break">Email: d.rueckert@imperial.ac.uk
</span></span></span>
<span class="ltx_author_before">  </span><span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Jonathan Passerat-Palmbach
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Imperial College London, UK
<br class="ltx_break">ConsenSys Health
<br class="ltx_break">Email: j.passerat-palmbach@imperial.ac.uk
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p">Federated Learning harnesses data from multiple sources to build a single model. While the initial model might belong solely to the actor bringing it to the network for training, determining the ownership of the trained model resulting from Federated Learning remains an open question. In this paper we explore how Blockchains (in particular Ethereum) can be used to determine the evolving ownership of a model trained with Federated Learning.</p>
<p id="id2.id2" class="ltx_p">Firstly, we use the <span id="id2.id2.1" class="ltx_text ltx_font_italic">step-by-step evaluation</span> metric to assess the relative contributivities of participants in a Federated Learning process. Next, we introduce <span id="id2.id2.2" class="ltx_text ltx_font_italic">2CP</span>, a framework comprising two novel protocols for Blockchained Federated Learning, which both reward contributors with shares in the final model based on their relative contributivity. The <span id="id2.id2.3" class="ltx_text ltx_font_italic">Crowdsource Protocol</span> allows an actor to bring a model forward for training, and use their own data to evaluate the contributions made to it. Potential trainers are guaranteed a fair share of the resulting model, even in a trustless setting. The <span id="id2.id2.4" class="ltx_text ltx_font_italic">Consortium Protocol</span> gives trainers the same guarantee even when no party owns the initial model and no evaluator is available.</p>
<p id="id3.id3" class="ltx_p">We conduct experiments with the MNIST dataset that reveal sound contributivity scores resulting from both Protocols by rewarding larger datasets with greater shares in the model. Our experiments also showed the necessity to pair 2CP with a robust model aggregation mechanism to discard low quality inputs coming from model poisoning attacks.</p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span><span id="S1.1.1" class="ltx_text ltx_font_smallcaps">Introduction</span>
</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Machine Learning allows organisations and researchers to build predictive models from sets of data. In certain circumstances, these predictive models have to be trained on data which is sensitive in nature. For example, models in healthcare settings often have to be trained on patients’ data, which is private and confidential. This leads to two problems: firstly, private data is more difficult to acquire because data owners may be reluctant to give away their data or to give consent for their data to be used for machine learning purposes. Secondly, the organisation training the model must keep hold of this data, which introduces security risks and considerations.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p"><span id="S1.p2.1.1" class="ltx_text ltx_font_italic">Federated Learning</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> is a technique allowing data owners to contribute their data to the development of machine learning models without revealing it. Broadly speaking, there are two main scenarios in which Federated Learning is useful.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">In the <span id="S1.p3.1.1" class="ltx_text ltx_font_bold">Crowdsource Setting</span>, an organisation or team of researchers wish to produce a machine learning model and decide on a set of model hyperparameters and a training protocol. They do not own enough data to train the model themselves, so must draw on the data from multiple outside sources. An example of this scenario would be Google, who train the language model behind Google Keyboard using textual input from users <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite>.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">In the <span id="S1.p4.1.1" class="ltx_text ltx_font_bold">Consortium Setting</span>, multiple organisations and/or individual data owners wish to combine data to train a model that performs better than any model they could train with only their own data. They collectively agree on a set of model hyperparameters and a training protocol. They also agree to share ownership of the resulting model, either by a pre-determined split or based on the value of their individual contributions. <span id="S1.p4.1.2" class="ltx_text ltx_font_italic">MELLODDY</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> is an example of this scenario.</p>
</div>
<section id="S1.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.1 </span><span id="S1.SS1.1.1" class="ltx_text ltx_font_italic">Data Contributivity for Shared Ownership</span>
</h3>

<div id="S1.SS1.p1" class="ltx_para">
<p id="S1.SS1.p1.1" class="ltx_p">Parties who collaborate to train a model may agree in advance how to split ownership of it, and any of its resulting utility and revenue. In many of these cases, some parties are able to make greater contributions than others, and would want to see this reflected in their shares. However, the relative value of each party is non-trivial to determine. One must consider many factors together, such as the <span id="S1.SS1.p1.1.1" class="ltx_text ltx_font_bold">size, quality, representativeness, or novelty</span> of their local datasets. We can also imagine that a dataset may be poor in isolation, but a valuable addition to other datasets in training a combined model. Conversely, datasets which happen to work well on their own may add little value, or even be a detriment, when combined with other datasets.</p>
</div>
<div id="S1.SS1.p2" class="ltx_para">
<p id="S1.SS1.p2.1" class="ltx_p">In summary, the relative value of collaborating parties’ datasets is nearly impossible to determine before training. Furthermore, in Federated Learning settings this problem is compounded by an insurmountable obstacle: parties cannot reveal their data to each other. Therefore, no party has any way to prove the value that their data would bring to the final shared model.</p>
</div>
<div id="S1.SS1.p3" class="ltx_para">
<p id="S1.SS1.p3.1" class="ltx_p">It follows that we should evaluate datasets retrospectively, rather than before the training process. An ideal way of dividing ownership of a trained model (or its profits) would be to split it according to the value that each participant contributes to the final performance of the model, ie. the <span id="S1.SS1.p3.1.1" class="ltx_text ltx_font_italic">contributivity</span> of their data. This value is objective and can be calculated after the training process is complete. In this case, we do not need to access any participant’s data or balance the aforementioned, competing factors. If there were such a protocol, each participant could confidently contribute to the model, with the knowledge that they will be fairly rewarded for it.</p>
</div>
</section>
<section id="S1.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.2 </span><span id="S1.SS2.1.1" class="ltx_text ltx_font_italic">The Role of Blockchains</span>
</h3>

<div id="S1.SS2.p1" class="ltx_para">
<p id="S1.SS2.p1.1" class="ltx_p">Currently, the most popular Federated Learning protocols <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>, <a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite> require a central organiser to execute the training protocol. This is not ideal in the consortium setting - typically, consortia of organisations may not fully trust each other, and may not be able to agree who acts as the central organiser.</p>
</div>
<div id="S1.SS2.p2" class="ltx_para">
<p id="S1.SS2.p2.1" class="ltx_p">Meanwhile, in both crowdsource and consortium settings, participants may need an incentive to participate in the training process. Owners of particularly large or otherwise valuable datasets may also wish to see this reflected in their rewards.</p>
</div>
<div id="S1.SS2.p3" class="ltx_para">
<p id="S1.SS2.p3.1" class="ltx_p">Blockchains allow multiple parties to keep a distributed, immutable and verifiable ledger of records. Meanwhile, blockchain smart contracts can automatically and trustlessly execute pre-determined agreements between them. This work explores how Blockchains - and in particular Ethereum <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite> - may be useful to design improved Federated Learning protocols which allow participants to: 1) Pool their resources while fulfilling their own data protection obligations; 2) Allocate shares in the resulting model based on the value of their individual contributions; 3) Enforce these agreements automatically and trustlessly.</p>
</div>
</section>
<section id="S1.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">1.3 </span><span id="S1.SS3.1.1" class="ltx_text ltx_font_italic">Summary of Contributions</span>
</h3>

<div id="S1.SS3.p1" class="ltx_para">
<ul id="S1.I1" class="ltx_itemize">
<li id="S1.I1.i1" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i1.p1" class="ltx_para">
<p id="S1.I1.i1.p1.1" class="ltx_p">We explain and advocate <span id="S1.I1.i1.p1.1.1" class="ltx_text ltx_font_italic">step-by-step evaluation</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> as a <span id="S1.I1.i1.p1.1.2" class="ltx_text ltx_font_italic">contributivity</span> measure, ie. the relative utility of participants in a Federated Learning process.</p>
</div>
</li>
<li id="S1.I1.i2" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i2.p1" class="ltx_para">
<p id="S1.I1.i2.p1.1" class="ltx_p">We describe two <span id="S1.I1.i2.p1.1.1" class="ltx_text ltx_font_bold">new protocols for blockchain-based Federated Learning</span>: the <span id="S1.I1.i2.p1.1.2" class="ltx_text ltx_font_italic">Crowdsource Protocol</span> (Section <a href="#S3" title="3 The Crowdsource Protocol ‣ 2CP: Decentralized Protocols to Transparently Evaluate Contributivity in Blockchain Federated Learning Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>) and the <span id="S1.I1.i2.p1.1.3" class="ltx_text ltx_font_italic">Consortium Protocol</span> (Section <a href="#S4" title="4 The Consortium Protocol ‣ 2CP: Decentralized Protocols to Transparently Evaluate Contributivity in Blockchain Federated Learning Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>). These are each suitable for the crowdsource and consortium settings respectively. Unlike existing protocols <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, the resulting model’s <span id="S1.I1.i2.p1.1.4" class="ltx_text ltx_font_bold">ownership is split according to contributivity</span>.</p>
</div>
</li>
<li id="S1.I1.i3" class="ltx_item" style="list-style-type:none;">
<span class="ltx_tag ltx_tag_item">•</span> 
<div id="S1.I1.i3.p1" class="ltx_para">
<p id="S1.I1.i3.p1.1" class="ltx_p">We develop <span id="S1.I1.i3.p1.1.1" class="ltx_text ltx_lst_identifier ltx_lst_language_python ltx_lstlisting ltx_font_typewriter ltx_framed ltx_framed_rectangle" style="background-color:#FFFFFF;border-color: #999999;">2CP</span>, a <span id="S1.I1.i3.p1.1.2" class="ltx_text ltx_font_bold">software framework</span> which implements both protocols, and use <span id="S1.I1.i3.p1.1.3" class="ltx_text ltx_lst_identifier ltx_lst_language_python ltx_lstlisting ltx_font_typewriter ltx_framed ltx_framed_rectangle" style="background-color:#FFFFFF;border-color: #999999;">2CP</span> in Section <a href="#S5" title="5 Experiments ‣ 2CP: Decentralized Protocols to Transparently Evaluate Contributivity in Blockchain Federated Learning Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> to run experiments using the MNIST dataset to assess the contributivity scores resulting from our protocols. Figure <a href="#S1.F1" title="Figure 1 ‣ 1.3 Summary of Contributions ‣ 1 Introduction ‣ 2CP: Decentralized Protocols to Transparently Evaluate Contributivity in Blockchain Federated Learning Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> shows the architecture of <span id="S1.I1.i3.p1.1.4" class="ltx_text ltx_lst_identifier ltx_lst_language_python ltx_lstlisting ltx_font_typewriter ltx_framed ltx_framed_rectangle" style="background-color:#FFFFFF;border-color: #999999;">2CP</span>.</p>
</div>
</li>
</ul>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="/html/2011.07516/assets/figures/client-architecture.png" id="S1.F1.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="429" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>The architecture of the software framework <span id="S1.F1.2.1" class="ltx_text ltx_lst_identifier ltx_lst_language_python ltx_lstlisting ltx_font_typewriter ltx_framed ltx_framed_rectangle" style="background-color:#FFFFFF;border-color: #999999;">2CP</span>. Double arrows represent communication channels. Local workers are considered to be PySyft <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> workers for the sake of our experiments but could be replaced by other Federated Learning frameworks.</figcaption>
</figure>
</section>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span><span id="S2.1.1" class="ltx_text ltx_font_smallcaps">Related Work</span>
</h2>

<section id="S2.SS0.SSSx1" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Data Contributivity</h4>

<div id="S2.SS0.SSSx1.p1" class="ltx_para">
<p id="S2.SS0.SSSx1.p1.1" class="ltx_p">In an open-source repository, Substra explore potential approaches for measuring the contributivity of participants’ data <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. Among the approaches they recommend, <span id="S2.SS0.SSSx1.p1.1.1" class="ltx_text ltx_font_bold">step-by-step evaluation</span> is the only one which is possible in a Federated Learning setting, and therefore the one we will base this work upon.</p>
</div>
<div id="S2.SS0.SSSx1.p2" class="ltx_para">
<p id="S2.SS0.SSSx1.p2.5" class="ltx_p">To get the contributivity score for client <math id="S2.SS0.SSSx1.p2.1.m1.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S2.SS0.SSSx1.p2.1.m1.1a"><mi id="S2.SS0.SSSx1.p2.1.m1.1.1" xref="S2.SS0.SSSx1.p2.1.m1.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSSx1.p2.1.m1.1b"><ci id="S2.SS0.SSSx1.p2.1.m1.1.1.cmml" xref="S2.SS0.SSSx1.p2.1.m1.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSSx1.p2.1.m1.1c">A</annotation></semantics></math> using step-by-step evaluation, we define a performance metric <math id="S2.SS0.SSSx1.p2.2.m2.1" class="ltx_Math" alttext="v" display="inline"><semantics id="S2.SS0.SSSx1.p2.2.m2.1a"><mi id="S2.SS0.SSSx1.p2.2.m2.1.1" xref="S2.SS0.SSSx1.p2.2.m2.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSSx1.p2.2.m2.1b"><ci id="S2.SS0.SSSx1.p2.2.m2.1.1.cmml" xref="S2.SS0.SSSx1.p2.2.m2.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSSx1.p2.2.m2.1c">v</annotation></semantics></math> (eg. negative test loss) and record the marginal performance gain <math id="S2.SS0.SSSx1.p2.3.m3.1" class="ltx_Math" alttext="A" display="inline"><semantics id="S2.SS0.SSSx1.p2.3.m3.1a"><mi id="S2.SS0.SSSx1.p2.3.m3.1.1" xref="S2.SS0.SSSx1.p2.3.m3.1.1.cmml">A</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSSx1.p2.3.m3.1b"><ci id="S2.SS0.SSSx1.p2.3.m3.1.1.cmml" xref="S2.SS0.SSSx1.p2.3.m3.1.1">𝐴</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSSx1.p2.3.m3.1c">A</annotation></semantics></math> makes to the model <math id="S2.SS0.SSSx1.p2.4.m4.1" class="ltx_Math" alttext="M" display="inline"><semantics id="S2.SS0.SSSx1.p2.4.m4.1a"><mi id="S2.SS0.SSSx1.p2.4.m4.1.1" xref="S2.SS0.SSSx1.p2.4.m4.1.1.cmml">M</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSSx1.p2.4.m4.1b"><ci id="S2.SS0.SSSx1.p2.4.m4.1.1.cmml" xref="S2.SS0.SSSx1.p2.4.m4.1.1">𝑀</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSSx1.p2.4.m4.1c">M</annotation></semantics></math> in each iteration <math id="S2.SS0.SSSx1.p2.5.m5.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S2.SS0.SSSx1.p2.5.m5.1a"><mi id="S2.SS0.SSSx1.p2.5.m5.1.1" xref="S2.SS0.SSSx1.p2.5.m5.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S2.SS0.SSSx1.p2.5.m5.1b"><ci id="S2.SS0.SSSx1.p2.5.m5.1.1.cmml" xref="S2.SS0.SSSx1.p2.5.m5.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S2.SS0.SSSx1.p2.5.m5.1c">i</annotation></semantics></math>, and sum these gains over every iteration in the training process as per Equation <a href="#S2.E1" title="In Data Contributivity ‣ 2 Related Work ‣ 2CP: Decentralized Protocols to Transparently Evaluate Contributivity in Blockchain Federated Learning Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>.</p>
</div>
<div id="S2.SS0.SSSx1.p3" class="ltx_para">
<table id="S2.E1" class="ltx_equation ltx_eqn_table">

<tbody><tr class="ltx_equation ltx_eqn_row ltx_align_baseline">
<td class="ltx_eqn_cell ltx_eqn_center_padleft"></td>
<td class="ltx_eqn_cell ltx_align_center"><math id="S2.E1.m1.2" class="ltx_Math" alttext="C(A)=\sum_{i}\bigg{(}v(M_{i})-v(M_{i+1}^{A})\bigg{)}" display="block"><semantics id="S2.E1.m1.2a"><mrow id="S2.E1.m1.2.2" xref="S2.E1.m1.2.2.cmml"><mrow id="S2.E1.m1.2.2.3" xref="S2.E1.m1.2.2.3.cmml"><mi id="S2.E1.m1.2.2.3.2" xref="S2.E1.m1.2.2.3.2.cmml">C</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.3.1" xref="S2.E1.m1.2.2.3.1.cmml">​</mo><mrow id="S2.E1.m1.2.2.3.3.2" xref="S2.E1.m1.2.2.3.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.3.3.2.1" xref="S2.E1.m1.2.2.3.cmml">(</mo><mi id="S2.E1.m1.1.1" xref="S2.E1.m1.1.1.cmml">A</mi><mo stretchy="false" id="S2.E1.m1.2.2.3.3.2.2" xref="S2.E1.m1.2.2.3.cmml">)</mo></mrow></mrow><mo rspace="0.111em" id="S2.E1.m1.2.2.2" xref="S2.E1.m1.2.2.2.cmml">=</mo><mrow id="S2.E1.m1.2.2.1" xref="S2.E1.m1.2.2.1.cmml"><munder id="S2.E1.m1.2.2.1.2" xref="S2.E1.m1.2.2.1.2.cmml"><mo movablelimits="false" rspace="0em" id="S2.E1.m1.2.2.1.2.2" xref="S2.E1.m1.2.2.1.2.2.cmml">∑</mo><mi id="S2.E1.m1.2.2.1.2.3" xref="S2.E1.m1.2.2.1.2.3.cmml">i</mi></munder><mrow id="S2.E1.m1.2.2.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.cmml"><mo maxsize="210%" minsize="210%" id="S2.E1.m1.2.2.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.cmml">(</mo><mrow id="S2.E1.m1.2.2.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.cmml"><mrow id="S2.E1.m1.2.2.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.cmml"><mi id="S2.E1.m1.2.2.1.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.1.3.cmml">v</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.1.2.cmml">​</mo><mrow id="S2.E1.m1.2.2.1.1.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml">(</mo><msub id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml"><mi id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.cmml">M</mi><mi id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml">i</mi></msub><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml">)</mo></mrow></mrow><mo id="S2.E1.m1.2.2.1.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.3.cmml">−</mo><mrow id="S2.E1.m1.2.2.1.1.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.2.cmml"><mi id="S2.E1.m1.2.2.1.1.1.1.2.3" xref="S2.E1.m1.2.2.1.1.1.1.2.3.cmml">v</mi><mo lspace="0em" rspace="0em" id="S2.E1.m1.2.2.1.1.1.1.2.2" xref="S2.E1.m1.2.2.1.1.1.1.2.2.cmml">​</mo><mrow id="S2.E1.m1.2.2.1.1.1.1.2.1.1" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.cmml"><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.2.1.1.2" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.cmml">(</mo><msubsup id="S2.E1.m1.2.2.1.1.1.1.2.1.1.1" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.cmml"><mi id="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.2" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.2.cmml">M</mi><mrow id="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.3" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.3.cmml"><mi id="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.3.2" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.3.2.cmml">i</mi><mo id="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.3.1" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.3.1.cmml">+</mo><mn id="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.3.3" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.3.3.cmml">1</mn></mrow><mi id="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.3.cmml">A</mi></msubsup><mo stretchy="false" id="S2.E1.m1.2.2.1.1.1.1.2.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.cmml">)</mo></mrow></mrow></mrow><mo maxsize="210%" minsize="210%" id="S2.E1.m1.2.2.1.1.1.3" xref="S2.E1.m1.2.2.1.1.1.1.cmml">)</mo></mrow></mrow></mrow><annotation-xml encoding="MathML-Content" id="S2.E1.m1.2b"><apply id="S2.E1.m1.2.2.cmml" xref="S2.E1.m1.2.2"><eq id="S2.E1.m1.2.2.2.cmml" xref="S2.E1.m1.2.2.2"></eq><apply id="S2.E1.m1.2.2.3.cmml" xref="S2.E1.m1.2.2.3"><times id="S2.E1.m1.2.2.3.1.cmml" xref="S2.E1.m1.2.2.3.1"></times><ci id="S2.E1.m1.2.2.3.2.cmml" xref="S2.E1.m1.2.2.3.2">𝐶</ci><ci id="S2.E1.m1.1.1.cmml" xref="S2.E1.m1.1.1">𝐴</ci></apply><apply id="S2.E1.m1.2.2.1.cmml" xref="S2.E1.m1.2.2.1"><apply id="S2.E1.m1.2.2.1.2.cmml" xref="S2.E1.m1.2.2.1.2"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.2.1.cmml" xref="S2.E1.m1.2.2.1.2">subscript</csymbol><sum id="S2.E1.m1.2.2.1.2.2.cmml" xref="S2.E1.m1.2.2.1.2.2"></sum><ci id="S2.E1.m1.2.2.1.2.3.cmml" xref="S2.E1.m1.2.2.1.2.3">𝑖</ci></apply><apply id="S2.E1.m1.2.2.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1"><minus id="S2.E1.m1.2.2.1.1.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.3"></minus><apply id="S2.E1.m1.2.2.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1"><times id="S2.E1.m1.2.2.1.1.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.2"></times><ci id="S2.E1.m1.2.2.1.1.1.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.3">𝑣</ci><apply id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.2">𝑀</ci><ci id="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.1.1.1.1.3">𝑖</ci></apply></apply><apply id="S2.E1.m1.2.2.1.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.2"><times id="S2.E1.m1.2.2.1.1.1.1.2.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.2.2"></times><ci id="S2.E1.m1.2.2.1.1.1.1.2.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.2.3">𝑣</ci><apply id="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1">superscript</csymbol><apply id="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1"><csymbol cd="ambiguous" id="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1">subscript</csymbol><ci id="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.2">𝑀</ci><apply id="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.3"><plus id="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.3.1.cmml" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.3.1"></plus><ci id="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.3.2.cmml" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.3.2">𝑖</ci><cn type="integer" id="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.3.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.2.3.3">1</cn></apply></apply><ci id="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.3.cmml" xref="S2.E1.m1.2.2.1.1.1.1.2.1.1.1.3">𝐴</ci></apply></apply></apply></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S2.E1.m1.2c">C(A)=\sum_{i}\bigg{(}v(M_{i})-v(M_{i+1}^{A})\bigg{)}</annotation></semantics></math></td>
<td class="ltx_eqn_cell ltx_eqn_center_padright"></td>
<td rowspan="1" class="ltx_eqn_cell ltx_eqn_eqno ltx_align_middle ltx_align_right"><span class="ltx_tag ltx_tag_equation ltx_align_right">(1)</span></td>
</tr></tbody>
</table>
</div>
</section>
<section id="S2.SS0.SSSx2" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Blockchains for Decentralised Federated Learning</h4>

<div id="S2.SS0.SSSx2.p1" class="ltx_para">
<p id="S2.SS0.SSSx2.p1.1" class="ltx_p">There are proposals for decentralised Federated Learning using Blockchains, with clients submitting model updates
as transactions to a blockchain <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>, <a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>. Storing the raw bytes of the models on-chain would be prohibitively expensive, so clients first upload them to IPFS (Inter Planetary File System) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> then record the CIDs (Content Identifiers - ie. addresses) on-chain instead.</p>
</div>
<div id="S2.SS0.SSSx2.p2" class="ltx_para">
<p id="S2.SS0.SSSx2.p2.1" class="ltx_p">Rather than rely on a central server (which could stall the entire process if it drops out or acts maliciously), clients perform the mean aggregation step at each training round independently and arrive at the same result.</p>
</div>
<div id="S2.SS0.SSSx2.p3" class="ltx_para">
<p id="S2.SS0.SSSx2.p3.1" class="ltx_p">The papers suggesting this architecture use specially designed blockchains, but we replicate them using Ethereum Smart Contracts.</p>
</div>
</section>
<section id="S2.SS0.SSSx3" class="ltx_subsubsection">
<h4 class="ltx_title ltx_title_subsubsection">Blockchains to Incentivise Federated Learning</h4>

<div id="S2.SS0.SSSx3.p1" class="ltx_para">
<p id="S2.SS0.SSSx3.p1.1" class="ltx_p">An alternative use of Blockchains in Federated Learning is to use the Blockchain network to record reputation values for each data owner <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. The Federated Learning process employs a model poisoning defence scheme, which detects and rejects malicious updates. These decisions are recorded on the blockchain, and values for <span id="S2.SS0.SSSx3.p1.1.1" class="ltx_text ltx_font_italic">belief</span>, <span id="S2.SS0.SSSx3.p1.1.2" class="ltx_text ltx_font_italic">disbelief</span> and <span id="S2.SS0.SSSx3.p1.1.3" class="ltx_text ltx_font_italic">uncertainty</span> calculated for each client. In future rounds, clients are chosen based on these values, and they earn a set reward for their contribution (if it is not classified as malicious).</p>
</div>
<div id="S2.SS0.SSSx3.p2" class="ltx_para">
<p id="S2.SS0.SSSx3.p2.1" class="ltx_p">Rather than with a flat rate, we intend to reward each update based on its contributivity to model performance.</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span><span id="S3.1.1" class="ltx_text ltx_font_smallcaps">The Crowdsource Protocol</span>
</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">For the scenario of the Crowdsource Protocol, we suppose that Alice (the <span id="S3.p1.1.1" class="ltx_text ltx_font_italic">evaluator</span>) has a high quality, well distributed and highly representative dataset for a machine learning task. Her dataset is not large enough to train an effective model for this task, but it is sufficient as a test set to evaluate a trained model. Bob, Carol and others (the <span id="S3.p1.1.2" class="ltx_text ltx_font_italic">trainers</span>) own suitable datasets to train Alice’s model but they are not willing to share them. They are willing to help Alice train a model using Federated Learning, but want to be fairly rewarded for their contributions. They are, of course, unable to reach consensus on how rewards should be split between them. Alice therefore calls upon Bob, Carol et al to train her model using the <span id="S3.p1.1.3" class="ltx_text ltx_font_italic">Crowdsource Protocol</span>.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">The protocol goes as follows:</p>
</div>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p"><span id="S3.p3.1.1" class="ltx_text ltx_font_bold">1)</span> Alice deploys the Crowdsource smart contract to the Ethereum blockchain, creates the genesis model, uploads it to IPFS then records its CID on the contract. She also sets the duration, in number of seconds, for each training round. Alternatively, anyone else with an Ethereum wallet could do this, then set Alice’s address as the evaluator. Either way, all parties can verify that the contract has been set up correctly and refuse to participate until it has.</p>
</div>
<div id="S3.p4" class="ltx_para">
<p id="S3.p4.1" class="ltx_p"><span id="S3.p4.1.1" class="ltx_text ltx_font_bold">2)</span> Once Alice’s transactions have been confirmed, the others can see the CID of the genesis model and proceed to download it from IPFS.</p>
</div>
<div id="S3.p5" class="ltx_para">
<p id="S3.p5.1" class="ltx_p"><span id="S3.p5.1.1" class="ltx_text ltx_font_bold">3)</span> Using their own data, the trainers each run iterations of training, upload their updated models to IPFS then record their CIDs on the contract. This all needs to be done within the duration of a single training round. The trainers then wait until the next training round starts.</p>
</div>
<div id="S3.p6" class="ltx_para">
<p id="S3.p6.1" class="ltx_p"><span id="S3.p6.1.1" class="ltx_text ltx_font_bold">4)</span> On commencement of the next training round, the trainers can see all the CIDs of the updates submitted in the previous training round. They each download these model updates from IPFS and calculate the mean aggregate of them. This is done independently, and they all arrive at the same result.</p>
</div>
<div id="S3.p7" class="ltx_para">
<p id="S3.p7.1" class="ltx_p"><span id="S3.p7.1.1" class="ltx_text ltx_font_bold">5)</span> The trainers start from their aggregate (this is the considered the <span id="S3.p7.1.2" class="ltx_text ltx_font_italic">global model</span> at the current training round), and repeat the previous steps 3-4 for either a pre-determined number of rounds, or until Alice is satisfied with the global model performance (as evaluated on her own data).</p>
</div>
<div id="S3.p8" class="ltx_para">
<p id="S3.p8.1" class="ltx_p"><span id="S3.p8.1.1" class="ltx_text ltx_font_bold">6)</span> The smart contract contains a full history of model updates in each round. Alice can now download all of these and calculate the contributivity of each of them. She assigns a number of <span id="S3.p8.1.2" class="ltx_text ltx_font_italic">tokens</span> to each update on the smart contract, as determined by their contributivity. Each token represents a unit of positive contribution to the model. Note that these tokens do not represent financial value nor affect model governance.</p>
</div>
<div id="S3.p9" class="ltx_para">
<p id="S3.p9.1" class="ltx_p">The smart contract also contains a record of the model updates each address has made. The tokens owned by each address is the sum of the tokens assigned to each of their updates. Each client’s shares in the final model is determined by the proportion of tokens they own.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2011.07516/assets/figures/fl-blocks-training.png" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="193" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Evaluator and clients interactions with the smart contract during the training process. Each block number <math id="S3.F2.3.m1.1" class="ltx_Math" alttext="n_{i}" display="inline"><semantics id="S3.F2.3.m1.1b"><msub id="S3.F2.3.m1.1.1" xref="S3.F2.3.m1.1.1.cmml"><mi id="S3.F2.3.m1.1.1.2" xref="S3.F2.3.m1.1.1.2.cmml">n</mi><mi id="S3.F2.3.m1.1.1.3" xref="S3.F2.3.m1.1.1.3.cmml">i</mi></msub><annotation-xml encoding="MathML-Content" id="S3.F2.3.m1.1c"><apply id="S3.F2.3.m1.1.1.cmml" xref="S3.F2.3.m1.1.1"><csymbol cd="ambiguous" id="S3.F2.3.m1.1.1.1.cmml" xref="S3.F2.3.m1.1.1">subscript</csymbol><ci id="S3.F2.3.m1.1.1.2.cmml" xref="S3.F2.3.m1.1.1.2">𝑛</ci><ci id="S3.F2.3.m1.1.1.3.cmml" xref="S3.F2.3.m1.1.1.3">𝑖</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.3.m1.1d">n_{i}</annotation></semantics></math> denotes the first block with a timestamp that falls within the time range for the training round <math id="S3.F2.4.m2.1" class="ltx_Math" alttext="i" display="inline"><semantics id="S3.F2.4.m2.1b"><mi id="S3.F2.4.m2.1.1" xref="S3.F2.4.m2.1.1.cmml">i</mi><annotation-xml encoding="MathML-Content" id="S3.F2.4.m2.1c"><ci id="S3.F2.4.m2.1.1.cmml" xref="S3.F2.4.m2.1.1">𝑖</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.F2.4.m2.1d">i</annotation></semantics></math>.</figcaption>
</figure>
<figure id="S3.F3" class="ltx_figure"><img src="/html/2011.07516/assets/figures/fl-blocks-evaluate.png" id="S3.F3.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="171" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>Evaluator interactions with the smart contract during the evaluation process. In this case the evaluator is retrospectively evaluating all updates up to and including the third training round, but they could also evaluate updates as each training round finishes.</figcaption>
</figure>
<div id="S3.p10" class="ltx_para">
<p id="S3.p10.1" class="ltx_p">Figure <a href="#S3.F2" title="Figure 2 ‣ 3 The Crowdsource Protocol ‣ 2CP: Decentralized Protocols to Transparently Evaluate Contributivity in Blockchain Federated Learning Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> shows how the evaluator and clients interact with the smart contract. Note that at each block, the smart contract contains the full history of the training process up to that training round. Evaluation can therefore be done in parallel with the training process, retrospectively after the training process, or somewhere in between. The evaluator does not have a time limit to submit their results and does not stall the training process.</p>
</div>
<div id="S3.p11" class="ltx_para">
<p id="S3.p11.1" class="ltx_p">We now need an objective performance metric <math id="S3.p11.1.m1.1" class="ltx_Math" alttext="v" display="inline"><semantics id="S3.p11.1.m1.1a"><mi id="S3.p11.1.m1.1.1" xref="S3.p11.1.m1.1.1.cmml">v</mi><annotation-xml encoding="MathML-Content" id="S3.p11.1.m1.1b"><ci id="S3.p11.1.m1.1.1.cmml" xref="S3.p11.1.m1.1.1">𝑣</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p11.1.m1.1c">v</annotation></semantics></math> for the trained model. Our metric is to evaluate the loss of the trained model against a varied, representative and highly accurate holdout test set. The test set must be unavailable to clients and trainers, and used only after the training process is complete, ie. can yield no further changes to the model. In the context of our scenario, Alice’s dataset would be used as the holdout test set. Outside of the Crowdsource setting, such an ideal test set is unlikely to exist, and we cannot use the Crowdsource Protocol.</p>
</div>
<div id="S3.p12" class="ltx_para">
<p id="S3.p12.2" class="ltx_p">With the performance metric established, it remains to choose a method for determining each participant’s contributivity <math id="S3.p12.1.m1.1" class="ltx_Math" alttext="C" display="inline"><semantics id="S3.p12.1.m1.1a"><mi id="S3.p12.1.m1.1.1" xref="S3.p12.1.m1.1.1.cmml">C</mi><annotation-xml encoding="MathML-Content" id="S3.p12.1.m1.1b"><ci id="S3.p12.1.m1.1.1.cmml" xref="S3.p12.1.m1.1.1">𝐶</ci></annotation-xml><annotation encoding="application/x-tex" id="S3.p12.1.m1.1c">C</annotation></semantics></math> towards the final model performance <math id="S3.p12.2.m2.1" class="ltx_Math" alttext="v(M)" display="inline"><semantics id="S3.p12.2.m2.1a"><mrow id="S3.p12.2.m2.1.2" xref="S3.p12.2.m2.1.2.cmml"><mi id="S3.p12.2.m2.1.2.2" xref="S3.p12.2.m2.1.2.2.cmml">v</mi><mo lspace="0em" rspace="0em" id="S3.p12.2.m2.1.2.1" xref="S3.p12.2.m2.1.2.1.cmml">​</mo><mrow id="S3.p12.2.m2.1.2.3.2" xref="S3.p12.2.m2.1.2.cmml"><mo stretchy="false" id="S3.p12.2.m2.1.2.3.2.1" xref="S3.p12.2.m2.1.2.cmml">(</mo><mi id="S3.p12.2.m2.1.1" xref="S3.p12.2.m2.1.1.cmml">M</mi><mo stretchy="false" id="S3.p12.2.m2.1.2.3.2.2" xref="S3.p12.2.m2.1.2.cmml">)</mo></mrow></mrow><annotation-xml encoding="MathML-Content" id="S3.p12.2.m2.1b"><apply id="S3.p12.2.m2.1.2.cmml" xref="S3.p12.2.m2.1.2"><times id="S3.p12.2.m2.1.2.1.cmml" xref="S3.p12.2.m2.1.2.1"></times><ci id="S3.p12.2.m2.1.2.2.cmml" xref="S3.p12.2.m2.1.2.2">𝑣</ci><ci id="S3.p12.2.m2.1.1.cmml" xref="S3.p12.2.m2.1.1">𝑀</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S3.p12.2.m2.1c">v(M)</annotation></semantics></math>. <span id="S3.p12.2.1" class="ltx_text ltx_font_bold">Step-by-step evaluation</span>, as described in Section <a href="#S2.SS0.SSSx1" title="Data Contributivity ‣ 2 Related Work ‣ 2CP: Decentralized Protocols to Transparently Evaluate Contributivity in Blockchain Federated Learning Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, is a suitable method for this. Unlike the other data valuation methods, it can be done in the Federated Learning setting, scores can be calculated retrospectively and do not require the training of any additional models. The computational costs for step-by-step evaluation also increase linearly with the number of clients, in contrast to idealistic approaches based on the Shapley value <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>.</p>
</div>
<div id="S3.p13" class="ltx_para">
<p id="S3.p13.1" class="ltx_p">We assume that clients’ cost of computation is relatively small compared to the value of their data, so every client is incentivised to train on their entire dataset in each iteration, in order to maximise expected performance and reward.</p>
</div>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span><span id="S4.1.1" class="ltx_text ltx_font_smallcaps">The Consortium Protocol</span>
</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">The scenario of the Consortium Protocol sees Alice, Bob, Carol et al each own datasets and form a <span id="S4.p1.1.1" class="ltx_text ltx_font_italic">consortium</span>, collaborating to train a Federated Learning model. As a consortium of equals, there is no natural candidate for the <span id="S4.p1.1.2" class="ltx_text ltx_font_italic">evaluator</span> role, and hence they cannot use the Crowdsource Protocol from Section <a href="#S3" title="3 The Crowdsource Protocol ‣ 2CP: Decentralized Protocols to Transparently Evaluate Contributivity in Blockchain Federated Learning Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. However, they would still like to split ownership of the resulting model according to the value of their contributions. They therefore make use of the <span id="S4.p1.1.3" class="ltx_text ltx_font_italic">Consortium Protocol</span>.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">The method for calculating data contributivity described in Section <a href="#S3" title="3 The Crowdsource Protocol ‣ 2CP: Decentralized Protocols to Transparently Evaluate Contributivity in Blockchain Federated Learning Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> relies on the existence of a holdout test set by which to evaluate models. In the Consortium setting such a holdout set does not exist. Furthermore, we assume that clients cannot be trusted to set aside any of their data to produce a combined holdout set. This is because we would expect clients to ‘cheat’ and train the model using their holdout data, knowing that this maximises their own contributivity score. As the data used to train local updates is kept secret, they would not be caught if they do this. We also cannot use round-robin based schemes where, for example, clients evaluate one round each in turns - again, because clients would use the same data for both training and evaluation. We therefore propose a new scheme, labelled as <span id="S4.p2.1.1" class="ltx_text ltx_font_bold">Parallel Cross Validation</span>, where clients can use their entire datasets both for training and evaluation.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.5" class="ltx_p">Parallel cross validation draws inspiration from the <span id="S4.p3.5.1" class="ltx_text ltx_font_italic">k-fold cross-validation</span> technique, where <math id="S4.p3.1.m1.1" class="ltx_Math" alttext="k=N" display="inline"><semantics id="S4.p3.1.m1.1a"><mrow id="S4.p3.1.m1.1.1" xref="S4.p3.1.m1.1.1.cmml"><mi id="S4.p3.1.m1.1.1.2" xref="S4.p3.1.m1.1.1.2.cmml">k</mi><mo id="S4.p3.1.m1.1.1.1" xref="S4.p3.1.m1.1.1.1.cmml">=</mo><mi id="S4.p3.1.m1.1.1.3" xref="S4.p3.1.m1.1.1.3.cmml">N</mi></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.1.m1.1b"><apply id="S4.p3.1.m1.1.1.cmml" xref="S4.p3.1.m1.1.1"><eq id="S4.p3.1.m1.1.1.1.cmml" xref="S4.p3.1.m1.1.1.1"></eq><ci id="S4.p3.1.m1.1.1.2.cmml" xref="S4.p3.1.m1.1.1.2">𝑘</ci><ci id="S4.p3.1.m1.1.1.3.cmml" xref="S4.p3.1.m1.1.1.3">𝑁</ci></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.1.m1.1c">k=N</annotation></semantics></math> and <math id="S4.p3.2.m2.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.p3.2.m2.1a"><mi id="S4.p3.2.m2.1.1" xref="S4.p3.2.m2.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.p3.2.m2.1b"><ci id="S4.p3.2.m2.1.1.cmml" xref="S4.p3.2.m2.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.2.m2.1c">N</annotation></semantics></math> is the number of clients. Each round, every client trains <math id="S4.p3.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.p3.3.m3.1a"><mi id="S4.p3.3.m3.1.1" xref="S4.p3.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.p3.3.m3.1b"><ci id="S4.p3.3.m3.1.1.cmml" xref="S4.p3.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.3.m3.1c">N</annotation></semantics></math> <span id="S4.p3.5.2" class="ltx_text ltx_font_italic">auxiliary models</span> (one for each coalition of <math id="S4.p3.4.m4.1" class="ltx_Math" alttext="N-1" display="inline"><semantics id="S4.p3.4.m4.1a"><mrow id="S4.p3.4.m4.1.1" xref="S4.p3.4.m4.1.1.cmml"><mi id="S4.p3.4.m4.1.1.2" xref="S4.p3.4.m4.1.1.2.cmml">N</mi><mo id="S4.p3.4.m4.1.1.1" xref="S4.p3.4.m4.1.1.1.cmml">−</mo><mn id="S4.p3.4.m4.1.1.3" xref="S4.p3.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p3.4.m4.1b"><apply id="S4.p3.4.m4.1.1.cmml" xref="S4.p3.4.m4.1.1"><minus id="S4.p3.4.m4.1.1.1.cmml" xref="S4.p3.4.m4.1.1.1"></minus><ci id="S4.p3.4.m4.1.1.2.cmml" xref="S4.p3.4.m4.1.1.2">𝑁</ci><cn type="integer" id="S4.p3.4.m4.1.1.3.cmml" xref="S4.p3.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.4.m4.1c">N-1</annotation></semantics></math> clients), and evaluates the one model trained by the coalition of all other clients excluding it. Every client also runs a training round on the <span id="S4.p3.5.3" class="ltx_text ltx_font_italic">main model</span>, which is trained by all <math id="S4.p3.5.m5.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.p3.5.m5.1a"><mi id="S4.p3.5.m5.1.1" xref="S4.p3.5.m5.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.p3.5.m5.1b"><ci id="S4.p3.5.m5.1.1.cmml" xref="S4.p3.5.m5.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p3.5.m5.1c">N</annotation></semantics></math> clients together. The contributivity of each client towards the main model is calculated by summing their contributivities across the auxiliary models. An illustration of the process is shown in Figure <a href="#S4.F4" title="Figure 4 ‣ 4 The Consortium Protocol ‣ 2CP: Decentralized Protocols to Transparently Evaluate Contributivity in Blockchain Federated Learning Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>.</p>
</div>
<figure id="S4.F4" class="ltx_figure"><img src="/html/2011.07516/assets/figures/parallel-cross-validation.png" id="S4.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="598" height="601" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Parallel cross-validation to determine contributivities of a model with no evaluator.</figcaption>
</figure>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.7" class="ltx_p">For a consortium of <math id="S4.p4.1.m1.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.p4.1.m1.1a"><mi id="S4.p4.1.m1.1.1" xref="S4.p4.1.m1.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.p4.1.m1.1b"><ci id="S4.p4.1.m1.1.1.cmml" xref="S4.p4.1.m1.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.1.m1.1c">N</annotation></semantics></math> members to run the Consortium Protocol, they essentially need to run the Crowdsourcing Protocol <math id="S4.p4.2.m2.1" class="ltx_Math" alttext="N+1" display="inline"><semantics id="S4.p4.2.m2.1a"><mrow id="S4.p4.2.m2.1.1" xref="S4.p4.2.m2.1.1.cmml"><mi id="S4.p4.2.m2.1.1.2" xref="S4.p4.2.m2.1.1.2.cmml">N</mi><mo id="S4.p4.2.m2.1.1.1" xref="S4.p4.2.m2.1.1.1.cmml">+</mo><mn id="S4.p4.2.m2.1.1.3" xref="S4.p4.2.m2.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.2.m2.1b"><apply id="S4.p4.2.m2.1.1.cmml" xref="S4.p4.2.m2.1.1"><plus id="S4.p4.2.m2.1.1.1.cmml" xref="S4.p4.2.m2.1.1.1"></plus><ci id="S4.p4.2.m2.1.1.2.cmml" xref="S4.p4.2.m2.1.1.2">𝑁</ci><cn type="integer" id="S4.p4.2.m2.1.1.3.cmml" xref="S4.p4.2.m2.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.2.m2.1c">N+1</annotation></semantics></math> times, either sequentially or in parallel. In each of the first <math id="S4.p4.3.m3.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.p4.3.m3.1a"><mi id="S4.p4.3.m3.1.1" xref="S4.p4.3.m3.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.p4.3.m3.1b"><ci id="S4.p4.3.m3.1.1.cmml" xref="S4.p4.3.m3.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.3.m3.1c">N</annotation></semantics></math> of these processes, a different coalition of <math id="S4.p4.4.m4.1" class="ltx_Math" alttext="N-1" display="inline"><semantics id="S4.p4.4.m4.1a"><mrow id="S4.p4.4.m4.1.1" xref="S4.p4.4.m4.1.1.cmml"><mi id="S4.p4.4.m4.1.1.2" xref="S4.p4.4.m4.1.1.2.cmml">N</mi><mo id="S4.p4.4.m4.1.1.1" xref="S4.p4.4.m4.1.1.1.cmml">−</mo><mn id="S4.p4.4.m4.1.1.3" xref="S4.p4.4.m4.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.4.m4.1b"><apply id="S4.p4.4.m4.1.1.cmml" xref="S4.p4.4.m4.1.1"><minus id="S4.p4.4.m4.1.1.1.cmml" xref="S4.p4.4.m4.1.1.1"></minus><ci id="S4.p4.4.m4.1.1.2.cmml" xref="S4.p4.4.m4.1.1.2">𝑁</ci><cn type="integer" id="S4.p4.4.m4.1.1.3.cmml" xref="S4.p4.4.m4.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.4.m4.1c">N-1</annotation></semantics></math> members trains an auxiliary model, and the remaining member acts as the evaluator. The evaluator uses their data as the holdout set and calculates the contributivity of each trainer. In the final process, all <math id="S4.p4.5.m5.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.p4.5.m5.1a"><mi id="S4.p4.5.m5.1.1" xref="S4.p4.5.m5.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.p4.5.m5.1b"><ci id="S4.p4.5.m5.1.1.cmml" xref="S4.p4.5.m5.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.5.m5.1c">N</annotation></semantics></math> members train the main model. Remember that we do not have a holdout set by which to evaluate the main model, or to calculate contributivities. Instead, we estimate its performance by averaging the performances of the other <math id="S4.p4.6.m6.1" class="ltx_Math" alttext="N" display="inline"><semantics id="S4.p4.6.m6.1a"><mi id="S4.p4.6.m6.1.1" xref="S4.p4.6.m6.1.1.cmml">N</mi><annotation-xml encoding="MathML-Content" id="S4.p4.6.m6.1b"><ci id="S4.p4.6.m6.1.1.cmml" xref="S4.p4.6.m6.1.1">𝑁</ci></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.6.m6.1c">N</annotation></semantics></math> auxiliary models. The contributivity of each trainer is the sum of their contributivities towards the <math id="S4.p4.7.m7.1" class="ltx_Math" alttext="N-1" display="inline"><semantics id="S4.p4.7.m7.1a"><mrow id="S4.p4.7.m7.1.1" xref="S4.p4.7.m7.1.1.cmml"><mi id="S4.p4.7.m7.1.1.2" xref="S4.p4.7.m7.1.1.2.cmml">N</mi><mo id="S4.p4.7.m7.1.1.1" xref="S4.p4.7.m7.1.1.1.cmml">−</mo><mn id="S4.p4.7.m7.1.1.3" xref="S4.p4.7.m7.1.1.3.cmml">1</mn></mrow><annotation-xml encoding="MathML-Content" id="S4.p4.7.m7.1b"><apply id="S4.p4.7.m7.1.1.cmml" xref="S4.p4.7.m7.1.1"><minus id="S4.p4.7.m7.1.1.1.cmml" xref="S4.p4.7.m7.1.1.1"></minus><ci id="S4.p4.7.m7.1.1.2.cmml" xref="S4.p4.7.m7.1.1.2">𝑁</ci><cn type="integer" id="S4.p4.7.m7.1.1.3.cmml" xref="S4.p4.7.m7.1.1.3">1</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S4.p4.7.m7.1c">N-1</annotation></semantics></math> auxiliary models they helped to train.</p>
</div>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.1" class="ltx_p">The Consortium Protocol exposes two limitations compared to the Crowdsource Protocol: <span id="S4.p5.1.1" class="ltx_text ltx_font_bold">1)</span> Unlike the Crowdsource Protocol, the Consortium Protocol is a closed process and participants must be determined beforehand. <span id="S4.p5.1.2" class="ltx_text ltx_font_bold">2)</span> The number of models that need to be trained increases linearly with the number of trainers. All but one of these models are used only for contributivity calculations.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="/html/2011.07516/assets/figures/consortium-contracts.png" id="S4.F5.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="598" height="315" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Suppose Alice, Bob and Carol are running the Consortium Protocol. Their Consortium contract orchestrates 4 Crowdsource contracts, which take charge of a model each.</figcaption>
</figure>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span><span id="S5.1.1" class="ltx_text ltx_font_smallcaps">Experiments</span>
</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p"><span id="S5.p1.1.1" class="ltx_text ltx_font_italic">MNIST</span> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite> is a labelled dataset of handwritten digits. All images are monochrome and <math id="S5.p1.1.m1.1" class="ltx_Math" alttext="28\times 28" display="inline"><semantics id="S5.p1.1.m1.1a"><mrow id="S5.p1.1.m1.1.1" xref="S5.p1.1.m1.1.1.cmml"><mn id="S5.p1.1.m1.1.1.2" xref="S5.p1.1.m1.1.1.2.cmml">28</mn><mo lspace="0.222em" rspace="0.222em" id="S5.p1.1.m1.1.1.1" xref="S5.p1.1.m1.1.1.1.cmml">×</mo><mn id="S5.p1.1.m1.1.1.3" xref="S5.p1.1.m1.1.1.3.cmml">28</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p1.1.m1.1b"><apply id="S5.p1.1.m1.1.1.cmml" xref="S5.p1.1.m1.1.1"><times id="S5.p1.1.m1.1.1.1.cmml" xref="S5.p1.1.m1.1.1.1"></times><cn type="integer" id="S5.p1.1.m1.1.1.2.cmml" xref="S5.p1.1.m1.1.1.2">28</cn><cn type="integer" id="S5.p1.1.m1.1.1.3.cmml" xref="S5.p1.1.m1.1.1.3">28</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p1.1.m1.1c">28\times 28</annotation></semantics></math> pixels. The dataset is split into a <span id="S5.p1.1.2" class="ltx_text ltx_font_italic">Train Set</span> of 60,000 images, and a <span id="S5.p1.1.3" class="ltx_text ltx_font_italic">Test Set</span> of 10,000 images.</p>
</div>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">In this section we run a series of experiments using MNIST, each with both protocols, as a validation of our contributivity metric. We present a small selection of results for illustrative purposes in the interest of space. The full set of results will be made available in the <span id="S5.p2.1.1" class="ltx_text ltx_lst_identifier ltx_lst_language_python ltx_lstlisting ltx_font_typewriter ltx_framed ltx_framed_rectangle" style="background-color:#FFFFFF;border-color: #999999;">2CP</span> repository. For Crowdsource, the entire Test Set is used as the holdout test set (belonging to Alice), while the Train Set is split between trainer clients (Bob <span id="S5.p2.1.2" class="ltx_text ltx_font_italic">et al</span>) in various ways. For Consortium, the Train Set is split between trainer clients in the same way, while the Test Set is not used. In all tests, the trainers ran 5 training rounds in which they trained the model using their whole dataset for 1 epoch, with a batch size of 32 and a learning rate of 0.01. In almost all tests, the final global model would achieve an accuracy rate of at least 0.9 on the test set.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">In our experiments, almost all tokens are given in the first few rounds. This is likely because our models converge almost fully within two rounds. We also observe very little difference in the relative shares of tokens given to clients between training rounds. A concern expressed about step by step evaluation is that scores might fluctuate wildly between rounds <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, but we have not observed this behaviour.</p>
</div>
<div id="S5.p4" class="ltx_para">
<p id="S5.p4.1" class="ltx_p">In <span id="S5.p4.1.1" class="ltx_text ltx_font_bold">MNIST Test A</span>, we split the Train Set randomly and equally between the trainer clients. One therefore expects that each trainer has similar, IID datasets with similar utilities. We vary the number of trainer clients between 2 and 7. As expected, in all cases the token count is split almost equally between clients, reflecting their equal contributions. Remarkably, the Consortium Protocol produces near identical results to Crowdsource at each round, despite its lack of access to Alice’s test set. Figure <a href="#S5.F6" title="Figure 6 ‣ 5 Experiments ‣ 2CP: Decentralized Protocols to Transparently Evaluate Contributivity in Blockchain Federated Learning Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> shows one such example.</p>
</div>
<figure id="S5.F6" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2011.07516/assets/figures/counts-crowdsource-equal-6-trainers.png" id="S5.F6.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="293" height="220" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2011.07516/assets/figures/counts-consortium-equal-6-trainers.png" id="S5.F6.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="293" height="220" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span><span id="S5.F6.2.1" class="ltx_text ltx_font_italic">MNIST Test A.</span> Results for the Crowdsource Protocol (left) and Consortium Protocol (right) with 6 clients of approximately equal value. As expected, all 6 clients are rewarded with similar token counts. We also see that both protocols yield near identical results, despite using different evaluation metrics.</figcaption>
</figure>
<div id="S5.p5" class="ltx_para">
<p id="S5.p5.1" class="ltx_p">In <span id="S5.p5.1.1" class="ltx_text ltx_font_bold">MNIST Test B</span>, the Train Set is split randomly, but in varying ratios. This experiment is intended to isolate the effect of having a smaller or larger dataset on the final token count. As expected, figure <a href="#S5.F7" title="Figure 7 ‣ 5 Experiments ‣ 2CP: Decentralized Protocols to Transparently Evaluate Contributivity in Blockchain Federated Learning Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a> shows that larger datasets are better rewarded. In all such experiments, the results from the Crowdsource and Consortium Protocols match each other closely.</p>
</div>
<figure id="S5.F7" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2011.07516/assets/figures/counts-crowdsource-sizes-2-1-1.png" id="S5.F7.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="293" height="220" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2011.07516/assets/figures/counts-consortium-sizes-2-1-1.png" id="S5.F7.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="293" height="220" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2011.07516/assets/figures/counts-crowdsource-sizes-6-5-4-3-2-1.png" id="S5.F7.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="293" height="220" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2011.07516/assets/figures/counts-consortium-sizes-6-5-4-3-2-1.png" id="S5.F7.g4" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="293" height="220" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span><span id="S5.F7.2.1" class="ltx_text ltx_font_italic">MNIST Test B.</span> A selection of results for the Crowdsource Protocol (left column) and Consortium Protocol (right column). In the first scenario (top row), the MNIST Train Set is split randomly between Bob, Carol and David in the ratios 2:1:1. Consequently, Bob is rewarded with a higher token count than Carol and David, who have similar token counts. In the second scenario (bottom row), the Train Set is split randomly between the trainers in the ratio 6:5:4:3:2:1. The resulting token counts reflect the dataset sizes.</figcaption>
</figure>
<figure id="S5.F8" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2011.07516/assets/figures/counts-crowdsource-flip-prob-0.5-0-0.png" id="S5.F8.g1" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="293" height="220" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2011.07516/assets/figures/counts-consortium-flip-prob-0.5-0-0.png" id="S5.F8.g2" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="293" height="220" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2011.07516/assets/figures/counts-crowdsource-flip-prob-0-0.1-0.2-0.3-0.4-0.5.png" id="S5.F8.g3" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="293" height="220" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2011.07516/assets/figures/counts-consortium-flip-prob-0-0.1-0.2-0.3-0.4-0.5.png" id="S5.F8.g4" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="293" height="220" alt="Refer to caption"></div>
<div class="ltx_flex_break"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2011.07516/assets/figures/counts-crowdsource-flip-prob-0-0.2-0.4-0.6-0.8.png" id="S5.F8.g5" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="293" height="220" alt="Refer to caption"></div>
<div class="ltx_flex_cell ltx_flex_size_2"><img src="/html/2011.07516/assets/figures/counts-consortium-flip-prob-0-0.2-0.4-0.6-0.8.png" id="S5.F8.g6" class="ltx_graphics ltx_centering ltx_figure_panel ltx_img_landscape" width="293" height="220" alt="Refer to caption"></div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span><span id="S5.F8.10.1" class="ltx_text ltx_font_italic">MNIST Test C.</span> A selection of results for the Crowdsource Protocol (left column) and Consortium Protocol (right column). The Train Set is split equally and randomly between clients, who each replace a proportion <math id="S5.F8.5.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S5.F8.5.m1.1b"><mi id="S5.F8.5.m1.1.1" xref="S5.F8.5.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S5.F8.5.m1.1c"><ci id="S5.F8.5.m1.1.1.cmml" xref="S5.F8.5.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F8.5.m1.1d">p</annotation></semantics></math> of their labels with random ones. Crowdsource is able to distinguish between differing <math id="S5.F8.6.m2.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S5.F8.6.m2.1b"><mi id="S5.F8.6.m2.1.1" xref="S5.F8.6.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S5.F8.6.m2.1c"><ci id="S5.F8.6.m2.1.1.cmml" xref="S5.F8.6.m2.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F8.6.m2.1d">p</annotation></semantics></math> values and penalises them accordingly. Consortium correctly penalises large values of <math id="S5.F8.7.m3.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S5.F8.7.m3.1b"><mi id="S5.F8.7.m3.1.1" xref="S5.F8.7.m3.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S5.F8.7.m3.1c"><ci id="S5.F8.7.m3.1.1.cmml" xref="S5.F8.7.m3.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.F8.7.m3.1d">p</annotation></semantics></math>, but it overvalues clients with slightly imperfect datasets (<math id="S5.F8.8.m4.1" class="ltx_Math" alttext="0&lt;p&lt;0.5" display="inline"><semantics id="S5.F8.8.m4.1b"><mrow id="S5.F8.8.m4.1.1" xref="S5.F8.8.m4.1.1.cmml"><mn id="S5.F8.8.m4.1.1.2" xref="S5.F8.8.m4.1.1.2.cmml">0</mn><mo id="S5.F8.8.m4.1.1.3" xref="S5.F8.8.m4.1.1.3.cmml">&lt;</mo><mi id="S5.F8.8.m4.1.1.4" xref="S5.F8.8.m4.1.1.4.cmml">p</mi><mo id="S5.F8.8.m4.1.1.5" xref="S5.F8.8.m4.1.1.5.cmml">&lt;</mo><mn id="S5.F8.8.m4.1.1.6" xref="S5.F8.8.m4.1.1.6.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.F8.8.m4.1c"><apply id="S5.F8.8.m4.1.1.cmml" xref="S5.F8.8.m4.1.1"><and id="S5.F8.8.m4.1.1a.cmml" xref="S5.F8.8.m4.1.1"></and><apply id="S5.F8.8.m4.1.1b.cmml" xref="S5.F8.8.m4.1.1"><lt id="S5.F8.8.m4.1.1.3.cmml" xref="S5.F8.8.m4.1.1.3"></lt><cn type="integer" id="S5.F8.8.m4.1.1.2.cmml" xref="S5.F8.8.m4.1.1.2">0</cn><ci id="S5.F8.8.m4.1.1.4.cmml" xref="S5.F8.8.m4.1.1.4">𝑝</ci></apply><apply id="S5.F8.8.m4.1.1c.cmml" xref="S5.F8.8.m4.1.1"><lt id="S5.F8.8.m4.1.1.5.cmml" xref="S5.F8.8.m4.1.1.5"></lt><share href="#S5.F8.8.m4.1.1.4.cmml" id="S5.F8.8.m4.1.1d.cmml" xref="S5.F8.8.m4.1.1"></share><cn type="float" id="S5.F8.8.m4.1.1.6.cmml" xref="S5.F8.8.m4.1.1.6">0.5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.F8.8.m4.1d">0&lt;p&lt;0.5</annotation></semantics></math>) at the expense of perfect ones. This may be a model poisoning effect from the imperfect datasets.</figcaption>
</figure>
<div id="S5.p6" class="ltx_para">
<p id="S5.p6.5" class="ltx_p">Finally, <span id="S5.p6.5.1" class="ltx_text ltx_font_bold">MNIST Test C</span> splits the Train Set as in A, but the trainers each replace a proportion <math id="S5.p6.1.m1.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S5.p6.1.m1.1a"><mi id="S5.p6.1.m1.1.1" xref="S5.p6.1.m1.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S5.p6.1.m1.1b"><ci id="S5.p6.1.m1.1.1.cmml" xref="S5.p6.1.m1.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p6.1.m1.1c">p</annotation></semantics></math> of their labels with a random one, simulating a label flipping attack to try poisoning the model. One therefore hopes that clients with higher <math id="S5.p6.2.m2.1" class="ltx_Math" alttext="p" display="inline"><semantics id="S5.p6.2.m2.1a"><mi id="S5.p6.2.m2.1.1" xref="S5.p6.2.m2.1.1.cmml">p</mi><annotation-xml encoding="MathML-Content" id="S5.p6.2.m2.1b"><ci id="S5.p6.2.m2.1.1.cmml" xref="S5.p6.2.m2.1.1">𝑝</ci></annotation-xml><annotation encoding="application/x-tex" id="S5.p6.2.m2.1c">p</annotation></semantics></math> values receive fewer tokens. In Figure <a href="#S5.F8" title="Figure 8 ‣ 5 Experiments ‣ 2CP: Decentralized Protocols to Transparently Evaluate Contributivity in Blockchain Federated Learning Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>, we can see that for Crowdsource, more label flipping does lead to fewer tokens, as it holds up less favourably to the unmodified holdout set. However, Figure <a href="#S5.F8" title="Figure 8 ‣ 5 Experiments ‣ 2CP: Decentralized Protocols to Transparently Evaluate Contributivity in Blockchain Federated Learning Environments" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a> also shows that for Consortium, a flip probability <math id="S5.p6.3.m3.1" class="ltx_Math" alttext="0&lt;p&lt;0.5" display="inline"><semantics id="S5.p6.3.m3.1a"><mrow id="S5.p6.3.m3.1.1" xref="S5.p6.3.m3.1.1.cmml"><mn id="S5.p6.3.m3.1.1.2" xref="S5.p6.3.m3.1.1.2.cmml">0</mn><mo id="S5.p6.3.m3.1.1.3" xref="S5.p6.3.m3.1.1.3.cmml">&lt;</mo><mi id="S5.p6.3.m3.1.1.4" xref="S5.p6.3.m3.1.1.4.cmml">p</mi><mo id="S5.p6.3.m3.1.1.5" xref="S5.p6.3.m3.1.1.5.cmml">&lt;</mo><mn id="S5.p6.3.m3.1.1.6" xref="S5.p6.3.m3.1.1.6.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p6.3.m3.1b"><apply id="S5.p6.3.m3.1.1.cmml" xref="S5.p6.3.m3.1.1"><and id="S5.p6.3.m3.1.1a.cmml" xref="S5.p6.3.m3.1.1"></and><apply id="S5.p6.3.m3.1.1b.cmml" xref="S5.p6.3.m3.1.1"><lt id="S5.p6.3.m3.1.1.3.cmml" xref="S5.p6.3.m3.1.1.3"></lt><cn type="integer" id="S5.p6.3.m3.1.1.2.cmml" xref="S5.p6.3.m3.1.1.2">0</cn><ci id="S5.p6.3.m3.1.1.4.cmml" xref="S5.p6.3.m3.1.1.4">𝑝</ci></apply><apply id="S5.p6.3.m3.1.1c.cmml" xref="S5.p6.3.m3.1.1"><lt id="S5.p6.3.m3.1.1.5.cmml" xref="S5.p6.3.m3.1.1.5"></lt><share href="#S5.p6.3.m3.1.1.4.cmml" id="S5.p6.3.m3.1.1d.cmml" xref="S5.p6.3.m3.1.1"></share><cn type="float" id="S5.p6.3.m3.1.1.6.cmml" xref="S5.p6.3.m3.1.1.6">0.5</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p6.3.m3.1c">0&lt;p&lt;0.5</annotation></semantics></math> actually increases eventual token shares at the expense of unmodified trainers. This quickly drops off to zero for <math id="S5.p6.4.m4.1" class="ltx_Math" alttext="p&gt;0.5" display="inline"><semantics id="S5.p6.4.m4.1a"><mrow id="S5.p6.4.m4.1.1" xref="S5.p6.4.m4.1.1.cmml"><mi id="S5.p6.4.m4.1.1.2" xref="S5.p6.4.m4.1.1.2.cmml">p</mi><mo id="S5.p6.4.m4.1.1.1" xref="S5.p6.4.m4.1.1.1.cmml">&gt;</mo><mn id="S5.p6.4.m4.1.1.3" xref="S5.p6.4.m4.1.1.3.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p6.4.m4.1b"><apply id="S5.p6.4.m4.1.1.cmml" xref="S5.p6.4.m4.1.1"><gt id="S5.p6.4.m4.1.1.1.cmml" xref="S5.p6.4.m4.1.1.1"></gt><ci id="S5.p6.4.m4.1.1.2.cmml" xref="S5.p6.4.m4.1.1.2">𝑝</ci><cn type="float" id="S5.p6.4.m4.1.1.3.cmml" xref="S5.p6.4.m4.1.1.3">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p6.4.m4.1c">p&gt;0.5</annotation></semantics></math>. Among our experiments, this effect is greatest when there are many flipped labels overall, and <math id="S5.p6.5.m5.1" class="ltx_Math" alttext="0.2&lt;p&lt;0.3" display="inline"><semantics id="S5.p6.5.m5.1a"><mrow id="S5.p6.5.m5.1.1" xref="S5.p6.5.m5.1.1.cmml"><mn id="S5.p6.5.m5.1.1.2" xref="S5.p6.5.m5.1.1.2.cmml">0.2</mn><mo id="S5.p6.5.m5.1.1.3" xref="S5.p6.5.m5.1.1.3.cmml">&lt;</mo><mi id="S5.p6.5.m5.1.1.4" xref="S5.p6.5.m5.1.1.4.cmml">p</mi><mo id="S5.p6.5.m5.1.1.5" xref="S5.p6.5.m5.1.1.5.cmml">&lt;</mo><mn id="S5.p6.5.m5.1.1.6" xref="S5.p6.5.m5.1.1.6.cmml">0.3</mn></mrow><annotation-xml encoding="MathML-Content" id="S5.p6.5.m5.1b"><apply id="S5.p6.5.m5.1.1.cmml" xref="S5.p6.5.m5.1.1"><and id="S5.p6.5.m5.1.1a.cmml" xref="S5.p6.5.m5.1.1"></and><apply id="S5.p6.5.m5.1.1b.cmml" xref="S5.p6.5.m5.1.1"><lt id="S5.p6.5.m5.1.1.3.cmml" xref="S5.p6.5.m5.1.1.3"></lt><cn type="float" id="S5.p6.5.m5.1.1.2.cmml" xref="S5.p6.5.m5.1.1.2">0.2</cn><ci id="S5.p6.5.m5.1.1.4.cmml" xref="S5.p6.5.m5.1.1.4">𝑝</ci></apply><apply id="S5.p6.5.m5.1.1c.cmml" xref="S5.p6.5.m5.1.1"><lt id="S5.p6.5.m5.1.1.5.cmml" xref="S5.p6.5.m5.1.1.5"></lt><share href="#S5.p6.5.m5.1.1.4.cmml" id="S5.p6.5.m5.1.1d.cmml" xref="S5.p6.5.m5.1.1"></share><cn type="float" id="S5.p6.5.m5.1.1.6.cmml" xref="S5.p6.5.m5.1.1.6">0.3</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S5.p6.5.m5.1c">0.2&lt;p&lt;0.3</annotation></semantics></math> is rewarded most. In these scenarios, these clients essentially amount to a Sybil attack for untargeted model poisoning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. The interpretation is that they have succeeded in diverting the model parameters to a sub-optimal local minimum, where unmodified trainers are punished for attempting to bring the model parameters away. Note that the early training rounds match the token shares from Crowdsource, which supports this theory. The Consortium measure should however be adjusted to avoid these situations.</p>
</div>
<div id="S5.p7" class="ltx_para">
<p id="S5.p7.1" class="ltx_p">This final experiment highlights the limitations of Federated Averaging. The Consortium protocol would thus benefit from being used in conjunction with a robust aggregation mechanism dismissing malicious updates as in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="" class="ltx_ref">16</a>]</cite>.</p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span><span id="S6.1.1" class="ltx_text ltx_font_smallcaps">Conclusion</span>
</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">In this paper, we have introduced and implemented two protocols to calculate the contributivity of each participant’s data set in a Federated Learning network. Both protocols are decentralised and maximise the fairness in the calculation.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">Our experiments showed that the contributivity scores resulting from the Crowdsource Protocol was sound when computed for the MNIST dataset. Clients with larger or higher quality datasets were rewarded with higher shares in the final model. Clients with less to contribute, but whose contributions would still be positive, are still given rewards for their participation. This result was obtained with a high quality holdout test set. The Consortium Protocol correctly rewarded larger datasets with higher scores, but our experiments revealed situations where low quality datasets were given higher scores than perfect ones.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">At the time of writing, our protocols and <span id="S6.p3.1.1" class="ltx_text ltx_lst_identifier ltx_lst_language_python ltx_lstlisting ltx_font_typewriter ltx_framed ltx_framed_rectangle" style="background-color:#FFFFFF;border-color: #999999;">2CP</span> are still under active development. It will be interesting to evaluate the two protocols when trainers have deliberately different and unique distributions of data, instead of being randomly sampled. Similarly, we want to understand the impact of privacy-preserving mechanisms such as Differential Privacy on the quality of the model updates, and hence on the contributivity scores and shares in the final model.</p>
</div>
<div id="S6.p4" class="ltx_para">
<p id="S6.p4.1" class="ltx_p"><span id="S6.p4.1.1" class="ltx_text ltx_lst_identifier ltx_lst_language_python ltx_lstlisting ltx_font_typewriter ltx_framed ltx_framed_rectangle" style="background-color:#FFFFFF;border-color: #999999;">2CP</span> does not yet support verified evaluation and verified training as described in this paper. The contributivity scheme only produces fair results if all clients follow the protocol honestly, or semi-honestly (honest but curious). Malicious clients can freely push bad and/or fake model updates, making the training process highly vulnerable to both untargeted and targeted model poisoning attacks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>. Future work will consequently focus on designing a verifiable evaluation and training procedure, as well as designing a penalty scheme to use in conjunction. From a technical standpoint, we aim to optimise the <span id="S6.p4.1.2" class="ltx_text ltx_lst_identifier ltx_lst_language_python ltx_lstlisting ltx_font_typewriter ltx_framed ltx_framed_rectangle" style="background-color:#FFFFFF;border-color: #999999;">2CP</span> framework for gas costs and scalability to make it suitable for public deployment on Ethereum and IPFS.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” in <em id="bib.bib1.1.1" class="ltx_emph ltx_font_italic">Artificial Intelligence and Statistics</em>.   PMLR, 2017, pp. 1273–1282.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
T. Yang, G. Andrew, H. Eichner, H. Sun, W. Li, N. Kong, D. Ramage, and
F. Beaufays, “Applied Federated Learning: Improving Google
Keyboard Query Suggestions,” <em id="bib.bib2.1.1" class="ltx_emph ltx_font_italic">arXiv:1812.02903 [cs, stat]</em>, Dec.
2018, arXiv: 1812.02903. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://arxiv.org/abs/1812.02903</span>

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
“MELLODDY.” [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://www.melloddy.eu</span>

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
K. Bonawitz, V. Ivanov, B. Kreuter, A. Marcedone, H. B. McMahan, S. Patel,
D. Ramage, A. Segal, and K. Seth, “Practical Secure Aggregation for
Privacy-Preserving Machine Learning,” in <em id="bib.bib4.1.1" class="ltx_emph ltx_font_italic">Proceedings of the
2017 ACM SIGSAC Conference on Computer and Communications
Security</em>, ser. CCS ’17.   Dallas,
Texas, USA: Association for Computing Machinery, Oct. 2017, pp. 1175–1191.
[Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://doi.org/10.1145/3133956.3133982</span>

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
G. Wood, “Ethereum: A secure decentralised generalised transaction ledger,”
<em id="bib.bib5.1.1" class="ltx_emph ltx_font_italic">Ethereum project yellow paper</em>, vol. 151, no. 2014, pp. 1–32, 2014.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
“SubstraFoundation/distributed-learning-contributivity,” Apr. 2020,
original-date: 2019-08-30T12:54:39Z. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://github.com/SubstraFoundation/distributed-learning-contributivity</span>

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
H. Kim, J. Park, M. Bennis, and S.-L. Kim, “Blockchained On-Device
Federated Learning,” <em id="bib.bib7.1.1" class="ltx_emph ltx_font_italic">IEEE Communications Letters</em>, vol. 24, no. 6,
pp. 1279–1283, Jun. 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
A. Nagar, “Privacy-Preserving Blockchain Based Federated Learning
with Differential Data Sharing,” <em id="bib.bib8.1.1" class="ltx_emph ltx_font_italic">arXiv:1912.04859 [cs]</em>, Dec.
2019, arXiv: 1912.04859. [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://arxiv.org/abs/1912.04859</span>

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
T. Ryffel, A. Trask, M. Dahl, B. Wagner, J. Mancuso, D. Rueckert, and
J. Passerat-Palmbach, “A generic framework for privacy preserving deep
learning,” <em id="bib.bib9.1.1" class="ltx_emph ltx_font_italic">arXiv:1811.04017 [cs, stat]</em>, Nov. 2018, arXiv: 1811.04017.
[Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://arxiv.org/abs/1811.04017</span>

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
J. Benet, “IPFS - Content Addressed, Versioned, P2P File
System,” <em id="bib.bib10.1.1" class="ltx_emph ltx_font_italic">arXiv:1407.3561 [cs]</em>, Jul. 2014, arXiv: 1407.3561.
[Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://arxiv.org/abs/1407.3561</span>

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
J. Kang, Z. Xiong, D. Niyato, S. Xie, and J. Zhang, “Incentive Mechanism for
Reliable Federated Learning: A Joint Optimization Approach to
Combining Reputation and Contract Theory,” <em id="bib.bib11.1.1" class="ltx_emph ltx_font_italic">IEEE Internet of
Things Journal</em>, 2019.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
L. S. Shapley, “Notes on the n-Person Game—II: The Value of an
n-Person Game,” 1951.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning
applied to document recognition,” <em id="bib.bib13.1.1" class="ltx_emph ltx_font_italic">Proceedings of the IEEE</em>, vol. 86,
no. 11, pp. 2278–2324, Nov. 1998, conference Name: Proceedings of the IEEE.

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
Substra Foundation, “Value Sharing in
Collaborative ML projects.” [Online]. Available:
<span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">https://docs.google.com/document/d/1dILvplN7h3-KB6OcHFNx9lSpAKyaBrwNaIRQ9j6XDT8</span>

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
P. Kairouz <em id="bib.bib15.1.1" class="ltx_emph ltx_font_italic">et al.</em>, “Advances and Open Problems in Federated
Learning,” <em id="bib.bib15.2.2" class="ltx_emph ltx_font_italic">arXiv:1912.04977 [cs, stat]</em>, Dec. 2019, arXiv:
1912.04977. [Online]. Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://arxiv.org/abs/1912.04977</span>

</span>
</li>
<li id="bib.bib16" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock">
L. Muñoz-González, K. T. Co, and E. C. Lupu, “Byzantine-Robust Federated
Machine Learning through Adaptive Model Averaging,”
<em id="bib.bib16.1.1" class="ltx_emph ltx_font_italic">arXiv:1909.05125 [cs, stat]</em>, Sep. 2019, arXiv: 1909.05125. [Online].
Available: <span class="ltx_ref ltx_nolink ltx_url ltx_font_typewriter ltx_ref_self">http://arxiv.org/abs/1909.05125</span>

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2011.07515" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2011.07516" class="ar5iv-text-button ar5iv-severity-ok">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2011.07516">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2011.07516" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2011.07517" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Fri Mar 15 23:59:03 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
