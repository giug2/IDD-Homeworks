<!DOCTYPE html><html lang="en">
<head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">
<title>[2206.12270] Using Autoencoders on Differentially Private Federated Learning GANs</title><meta property="og:description" content="Machine learning has been applied to almost all fields of computer science over the past decades. The introduction of GANs allowed for new possibilities in fields of medical research and text prediction. However, these…">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Using Autoencoders on Differentially Private Federated Learning GANs">
<meta name="twitter:image:src" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta name="twitter:image:alt" content="ar5iv logo">
<meta property="og:title" content="Using Autoencoders on Differentially Private Federated Learning GANs">
<meta property="og:site_name" content="ar5iv">
<meta property="og:image" content="https://ar5iv.labs.arxiv.org/assets/ar5iv_card.png">
<meta property="og:type" content="article">
<meta property="og:url" content="https://ar5iv.labs.arxiv.org/html/2206.12270">

<!--Generated on Mon Mar 11 17:46:29 2024 by LaTeXML (version 0.8.8) http://dlmf.nist.gov/LaTeXML/.-->
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

<script>
  function detectColorScheme(){
    var theme="light";
    var current_theme = localStorage.getItem("ar5iv_theme");
    if(current_theme){
      if(current_theme == "dark"){
        theme = "dark";
      } }
    else if(!window.matchMedia) { return false; }
    else if(window.matchMedia("(prefers-color-scheme: dark)").matches) {
      theme = "dark"; }
    if (theme=="dark") {
      document.documentElement.setAttribute("data-theme", "dark");
    } else {
      document.documentElement.setAttribute("data-theme", "light"); } }

  detectColorScheme();

  function toggleColorScheme(){
    var current_theme = localStorage.getItem("ar5iv_theme");
    if (current_theme) {
      if (current_theme == "light") {
        localStorage.setItem("ar5iv_theme", "dark"); }
      else {
        localStorage.setItem("ar5iv_theme", "light"); } }
    else {
        localStorage.setItem("ar5iv_theme", "dark"); }
    detectColorScheme(); }
</script>
<link media="all" rel="stylesheet" href="/assets/ar5iv-fonts.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv.0.8.0.min.css"><link media="all" rel="stylesheet" href="/assets/ar5iv-site.0.2.2.css">
</head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line" lang="en">
<h1 class="ltx_title ltx_title_document">
Using Autoencoders on Differentially Private Federated Learning GANs</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Gregor Schram
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Delft University of Technology
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Rui Wang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Delft University of Technology
</span></span></span>
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">Kaitai Liang
</span><span class="ltx_author_notes">
<span class="ltx_contact ltx_role_affiliation">Delft University of Technology
</span></span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p id="id1.id1" class="ltx_p"><span id="id1.id1.1" class="ltx_text">Machine learning has been applied to almost all fields of computer science over the past decades. The introduction of GANs allowed for new possibilities in fields of medical research and text prediction. However, these new fields work with ever more privacy-sensitive data. In order to maintain user privacy, a combination of federated learning, differential privacy and GANs can be used to work with private data without giving away a users’ privacy. Recently, two implementations of such combinations have been published: DP-Fed-Avg GAN and GS-WGAN. This paper compares their performance and introduces an alternative version of DP-Fed-Avg GAN that makes use of denoising techniques to combat the loss in accuracy that generally occurs when applying differential privacy and federated learning to GANs. We also compare the novel adaptation of denoised DP-Fed-Avg GAN to the state-of-the-art implementations in this field.</span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p id="S1.p1.1" class="ltx_p">Over the past two decades, machine learning and the broader field of artificial intelligence have grown exponentially. Nowadays, one may find these techniques applied everywhere, from fraudulent transaction detection by banks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="" class="ltx_ref">1</a>]</cite> to self-driving cars and advanced autocorrect and typing aids on smartphones. The expanded usage of these systems however comes at a cost: data. In general, an increase in accuracy of a machine learning model requires an increase in training data. This is problematic for multiple reasons, one of the reasons being the absence of sufficiently large datasets and another being the privacy invasions when using certain datasets.</p>
</div>
<div id="S1.p2" class="ltx_para">
<p id="S1.p2.1" class="ltx_p">For this first problem, Ian Goodfellow <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib2" title="" class="ltx_ref">2</a>]</cite> and his colleagues came up with the technique of Generative Adversarial Nets (GANs) in 2014. This technique makes two machine learning models compete, with one being a discriminator and the other trying to generate examples of data that did not exist in the training set previously to fool the discriminator. This process in the end results in a much more accurate discriminator while requiring a much smaller dataset to begin with.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p id="S1.p3.1" class="ltx_p">The second issue is one that has become more relevant in recent years as machine learning gets applied to more and more fields, the data it requires might be very privacy-sensitive. Think for example of medical data, pictures on a user’s phone, or all the text input generated on someone’s smartphone. Most people do not feel comfortable sharing this data with the large companies that often require it to improve their machine learning models. This is where Differential Privacy (DP) comes in, it was first brought up by Dwork and colleagues <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="" class="ltx_ref">3</a>]</cite> but some mathematics underlying the idea stem from Dalenius <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="" class="ltx_ref">4</a>]</cite>. Differential privacy ensures that analysis of a dataset as a whole can happen while preserving the privacy of any individuals’ data.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p id="S1.p4.1" class="ltx_p">Another problem arising with the use of machine learning on private data, especially when this data is coming from phones, is that the dataset is not centralized. Conventional machine learning requires the dataset to be completely accessible at all times. This is not a good requirement when dealing with private and decentralized data, again like pictures or text input on a phone. This is where Federated Learning (FL) comes into the picture. Federated learning allows private and decentralized data to stay on edge devices, like a phone, while still benefiting from all the data available to improve the models globally. The term as used in this paper was originally put forward by researchers at Google <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib5" title="" class="ltx_ref">5</a>]</cite>.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p id="S1.p5.1" class="ltx_p">Now that we understand the importance of differential privacy, federated learning and GANs we can also see why it is important to combine these. Differential privacy inherently makes a model less accurate which can be combatted by GANs, these however rely on centralized datasets which is why we need federated learning to apply it in real world use cases. The first paper combining these three techniques was only published two years ago by Sean Augenstein and his team at Google <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> with a real world use case being researched in the same year <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="" class="ltx_ref">7</a>]</cite>.</p>
</div>
<div id="S1.p6" class="ltx_para">
<p id="S1.p6.1" class="ltx_p">Since the convergence of these three techniques is very novel, this paper answers the question: Does adding a denoising step to DP-FL-GANs increase model accuracy while preserving privacy? This paper will first look at state-of-the-art techniques and add to them with a novel application of denoising for differential privacy.</p>
</div>
<div id="S1.p7" class="ltx_para">
<p id="S1.p7.1" class="ltx_p">This paper starts with an enumeration of related works in section 2. It then introduces a novel technique in section 3 and continues with an overview of the experiment setup in section 4. Section 5 gives an overview of the experiment results, while section 6 compares these to state-of-the-art implementations. Section 7 describes the ethics of this research, while section 8 contains the conclusions.</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related Work</h2>

<div id="S2.p1" class="ltx_para">
<p id="S2.p1.1" class="ltx_p">While the field of differentially private Generative Adversarial Nets (GANs) is quite developed and well researched, the subfield of federated solutions is very new and not well researched yet. A few implementations do exist, and we will be comparing our solution to those.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p id="S2.p2.1" class="ltx_p"><span id="S2.p2.1.1" class="ltx_text ltx_font_bold">DP-Fed-Avg GAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>.</span>
The first implementation and paper that proposed to apply differentially private GANs to a Federated Learning (FL) setting. The paper introduces the DP-Fed-Avg GAN algorithm, an adaptation of the Fed-Avg algorithm <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="" class="ltx_ref">8</a>]</cite>, to train both the discriminator and the generator in a federated setting while keeping user-level Differential Privacy (DP) guarantees under a trusted server. This trusted server is required because the averaging happens on the server and not on the edge devices.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p id="S2.p3.1" class="ltx_p"><span id="S2.p3.1.1" class="ltx_text ltx_font_bold">GS-WGAN <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</span>
This paper introduces a new way to use gradient information, enabling deeper models that can generate more useful samples representing a private dataset. Moreover, it allows this to be done both in a centralized and in a federated setting. In the federated setting, the proposed algorithm can provide user-level DP guarantees under an untrusted server, as gradient sanitization happens before sending the update. It also does not require rigorous hyperparameter tuning, something that DP-Fed-Avg GAN does require.</p>
</div>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>Proposed method</h2>

<div id="S3.p1" class="ltx_para">
<p id="S3.p1.1" class="ltx_p">This paper proposes to first apply Gaussian noise to local private training data and denoise it before training. Most Differential Privacy (DP) methods make use of Gaussian noise added to training data before training in order to enable user-level DP guarantees. The addition of noise inherently makes it more difficult for the Generative Adversarial Net (GAN) to generate and discriminate images reliably, the more noise one adds, the lower the accuracy of the GAN. Recently, there have been significant advances in noise removal on images <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="" class="ltx_ref">10</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="" class="ltx_ref">11</a>]</cite>. This noise removal will never lead back to the exact original image. This should preserve privacy as the original data is still permutated while resulting in higher accuracy due to more distinguishable training data.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p id="S3.p2.1" class="ltx_p">The originally proposed denoising algorithm was to be based on the work by Majed El Helou and Sabine Susstrunk <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. Later, we made the choice to focus on a simpler autoencoder, based on <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib13" title="" class="ltx_ref">13</a>]</cite>. We made this choice because our implementation works with the EMNIST dataset. This dataset is quite simple and uniform and thus does not benefit much from a very advanced algorithm as presented by <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="" class="ltx_ref">12</a>]</cite>. The usage of an autoencoder also makes the experiment run quicker and more reliable. The effectiveness of an autoencoder can be seen in figure <a href="#S3.F1" title="Figure 1 ‣ 3 Proposed method ‣ Using Autoencoders on Differentially Private Federated Learning GANs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>. As we can see, most of the noise is removed, making it easier to recognize the shape of the sample and thus making the training of the GAN more effective.</p>
</div>
<figure id="S3.F1" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F1.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2206.12270/assets/images/original.png" id="S3.F1.sf1.g1" class="ltx_graphics ltx_img_square" width="118" height="117" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Original sample</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F1.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2206.12270/assets/images/noised.png" id="S3.F1.sf2.g1" class="ltx_graphics ltx_img_square" width="118" height="117" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Sample with noise</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S3.F1.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2206.12270/assets/images/denoised.png" id="S3.F1.sf3.g1" class="ltx_graphics ltx_img_square" width="118" height="117" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>Sample after autodecoding</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>An illustration of the effectiveness of an autoencoder</figcaption>
</figure>
<div id="S3.p3" class="ltx_para">
<p id="S3.p3.1" class="ltx_p">As we can see in Figure <a href="#S3.F2" title="Figure 2 ‣ 3 Proposed method ‣ Using Autoencoders on Differentially Private Federated Learning GANs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a> our modified DP-Fed-Avg GAN algorithm goes through quite a few steps, the new step that we added has been highlighted. As one may understand from the flowchart, the removal of noise does not change the differential privacy level, as this happens after retraining the local GAN. Only when touching the input of the local GAN training session would this change.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="/html/2206.12270/assets/images/flowchart.jpeg" id="S3.F2.g1" class="ltx_graphics ltx_centering ltx_img_landscape" width="479" height="252" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>An overview of the steps in our modified DP-Fed-Avg GAN with noise removal</figcaption>
</figure>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiment Setup</h2>

<div id="S4.p1" class="ltx_para">
<p id="S4.p1.1" class="ltx_p">For our experiment, we first looked at the currently existing methods of Differential Privacy (DP) Federated Learning (FL) Generative Adversarial Nets (GANs). As of writing, two exist: DP-Fed-Avg GAN <span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">1</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">1</sup><span class="ltx_tag ltx_tag_note">1</span>https://github.com/google-research/federated/tree/master/gans</span></span></span> and GS-WGAN <span id="footnote2" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">2</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">2</sup><span class="ltx_tag ltx_tag_note">2</span>https://github.com/DingfanChen/GS-WGAN</span></span></span>. For both of these, the authors provided an implementation. These implementations were released with the intent to reproduce the results in the respective papers. Naturally, in order to compare these implementations against each other and against our implementation, we tried to reproduce the results produced in the respective papers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>.</p>
</div>
<div id="S4.p2" class="ltx_para">
<p id="S4.p2.1" class="ltx_p">We used <span id="S4.p2.1.1" class="ltx_text ltx_font_italic">conda</span> to create an environment for each of the solutions to run in isolation and to make sure that the setups were as close as possible to the ones used to generate the results in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> and <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite>. This ultimately allowed us to recreate some results of the DP-Fed-Avg GAN paper, but unfortunately we were not able to do this for the GS-WGAN paper as the provided code was incomplete and the federated setting was missing from it.</p>
</div>
<div id="S4.p3" class="ltx_para">
<p id="S4.p3.1" class="ltx_p">For the reproduction of the DP-Fed-Avg GAN results, we used the EMNIST dataset <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib14" title="" class="ltx_ref">14</a>]</cite>, this is an extension of MNIST <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="" class="ltx_ref">15</a>]</cite>, unlike MNIST it has letters as well as numbers and makes a distinction in capitalization, just like the original paper did. Since we are not interested in the practical use case of finding a bug, as introduced in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> we did not introduce said bug in the experiments we ran. In order to do this, we selected only users with an accuracy over 93%, and we set the image inversion probability to 0. Other than these values, we kept the exact same hyperparameters as used in the original paper.</p>
</div>
<div id="S4.p4" class="ltx_para">
<p id="S4.p4.1" class="ltx_p">For the new method proposed in section 3 we will make use of DP-Fed-Avg GAN. The reason we chose this algorithm as a base is that it is the only algorithm that has working code available, and implementing all the layers of GANs, FL and DP seemed unfeasible in the short timeframe of this research. Our method adds an extra step after each training round to remove noise on the intermediate results, which are also used in the next round, of the DP-Fed-Avg GAN. This extra step is based on the autoencoding algorithm described in <a href="#S3" title="3 Proposed method ‣ Using Autoencoders on Differentially Private Federated Learning GANs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. The code and setup instructions for our experiment can be found on GitHub<span id="footnote3" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">3</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">3</sup><span class="ltx_tag ltx_tag_note">3</span>https://github.com/gregor160300/federated</span></span></span>.</p>
</div>
<div id="S4.p5" class="ltx_para">
<p id="S4.p5.1" class="ltx_p">As the original algorithm uses the EMNIST dataset, we also use this for our implementation. This requires some slight modification to the denoising algorithm, as it is designed for the MNIST dataset. We will use the same hyperparameters described earlier. However, this time we will use different noise levels as this affects the effectiveness of the denoising algorithm and the overall accuracy of our GAN.</p>
</div>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Results</h2>

<div id="S5.p1" class="ltx_para">
<p id="S5.p1.1" class="ltx_p">Our implementation has a very similar approach for applying differential privacy to a federated learning Generative Adversarial Net (GAN) as the DP-Fed-Avg GAN algorithm, we actually reuse most of the code from the DP-Fed-Avg GAN paper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite>. The only thing we added on top of the DP-Fed-Avg GAN algorithm is a step to denoise the intermediate outputs of the GAN. This did not touch the Differential Privacy (DP) level of the GAN, this was also not the intent. The intent was to reach a higher accuracy on classification of generated output, as well as reduce the Frechet Inception Distance (FID). Unfortunately, our experiment failed.</p>
</div>
<figure id="S5.F3" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F3.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2206.12270/assets/images/no_dp_no_denoise_1000.png" id="S5.F3.sf1.g1" class="ltx_graphics ltx_img_square" width="118" height="118" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>No DP and no noise removal</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F3.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2206.12270/assets/images/dp_no_denoise_1000.png" id="S5.F3.sf2.g1" class="ltx_graphics ltx_img_square" width="118" height="118" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>DP but no noise removal</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_3">
<figure id="S5.F3.sf3" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2206.12270/assets/images/dp_denoise_1000.png" id="S5.F3.sf3.g1" class="ltx_graphics ltx_img_square" width="118" height="118" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(c) </span>DP and noise removal</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>An illustration of the impact of DP and denoising on the accuracy of the GAN</figcaption>
</figure>
<div id="S5.p2" class="ltx_para">
<p id="S5.p2.1" class="ltx_p">Let us first take a look at the GAN output after 1000 rounds of training in figure <a href="#S5.F3" title="Figure 3 ‣ 5 Results ‣ Using Autoencoders on Differentially Private Federated Learning GANs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>. We see in figure <a href="#S5.F3" title="Figure 3 ‣ 5 Results ‣ Using Autoencoders on Differentially Private Federated Learning GANs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>a that the generated images when not using differential privacy nor noise removal are quite readable. In <a href="#S5.F3" title="Figure 3 ‣ 5 Results ‣ Using Autoencoders on Differentially Private Federated Learning GANs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>b we see a slight degradation in the readability due to the addition of DP guarantees. In the results of our implementation in <a href="#S5.F3" title="Figure 3 ‣ 5 Results ‣ Using Autoencoders on Differentially Private Federated Learning GANs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>c we see that all outputs have some sort of gray layer on top of them making it less readable and thus increasing the FID and lowering the accuracy of classification based on these generated results.</p>
</div>
<div id="S5.p3" class="ltx_para">
<p id="S5.p3.1" class="ltx_p">The way the autoencoder works for noise removal is to train a network on noisy input and non-noisy input. It then learns to remove noise from a noisy image by recognizing the differences. It is however trained on one specific noise level, in our case 20%. This means that it will learn to reduce the noise best at 20% noise, however our results might have more or less noise. The autoencoder will still try to remove the noise, but white noise on a black background then just becomes a gray filter on top of the entire image as it is unsure how to remove the noise. Our concept of noise removal might work with an algorithm that is agnostic of the noise level. 
<br class="ltx_break"></p>
</div>
</section>
<section id="S6" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">6 </span>Discussion</h2>

<div id="S6.p1" class="ltx_para">
<p id="S6.p1.1" class="ltx_p">The current implementations of DP-Fed-Avg GAN and GS-WGAN both have corresponding papers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> with results. We will focus on the model accuracy of the results and the differential privacy, as these are integral to our problem of increasing accuracy while preserving privacy. Differential privacy is measured by a value, <math id="S6.p1.1.m1.1" class="ltx_Math" alttext="\epsilon" display="inline"><semantics id="S6.p1.1.m1.1a"><mi id="S6.p1.1.m1.1.1" xref="S6.p1.1.m1.1.1.cmml">ϵ</mi><annotation-xml encoding="MathML-Content" id="S6.p1.1.m1.1b"><ci id="S6.p1.1.m1.1.1.cmml" xref="S6.p1.1.m1.1.1">italic-ϵ</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.p1.1.m1.1c">\epsilon</annotation></semantics></math> this value ideally is between 0 and 1, the lower, the better. The accuracy is measured by the Frechet Inception Distance (FID) as Generative Adversarial Nets (GANs) do not do classification, we check the similarity of the generated results to the training samples. The lower the distance between the two, the better.</p>
</div>
<div id="S6.p2" class="ltx_para">
<p id="S6.p2.1" class="ltx_p">We will first take a look at the claimed performance of the DP-Fed-Avg GAN. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="" class="ltx_ref">6</a>]</cite> claims that the DP-Fed-Avg GAN reaches an epsilon of <math id="S6.p2.1.m1.1" class="ltx_Math" alttext="9.99\times 10^{6}" display="inline"><semantics id="S6.p2.1.m1.1a"><mrow id="S6.p2.1.m1.1.1" xref="S6.p2.1.m1.1.1.cmml"><mn id="S6.p2.1.m1.1.1.2" xref="S6.p2.1.m1.1.1.2.cmml">9.99</mn><mo lspace="0.222em" rspace="0.222em" id="S6.p2.1.m1.1.1.1" xref="S6.p2.1.m1.1.1.1.cmml">×</mo><msup id="S6.p2.1.m1.1.1.3" xref="S6.p2.1.m1.1.1.3.cmml"><mn id="S6.p2.1.m1.1.1.3.2" xref="S6.p2.1.m1.1.1.3.2.cmml">10</mn><mn id="S6.p2.1.m1.1.1.3.3" xref="S6.p2.1.m1.1.1.3.3.cmml">6</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S6.p2.1.m1.1b"><apply id="S6.p2.1.m1.1.1.cmml" xref="S6.p2.1.m1.1.1"><times id="S6.p2.1.m1.1.1.1.cmml" xref="S6.p2.1.m1.1.1.1"></times><cn type="float" id="S6.p2.1.m1.1.1.2.cmml" xref="S6.p2.1.m1.1.1.2">9.99</cn><apply id="S6.p2.1.m1.1.1.3.cmml" xref="S6.p2.1.m1.1.1.3"><csymbol cd="ambiguous" id="S6.p2.1.m1.1.1.3.1.cmml" xref="S6.p2.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S6.p2.1.m1.1.1.3.2.cmml" xref="S6.p2.1.m1.1.1.3.2">10</cn><cn type="integer" id="S6.p2.1.m1.1.1.3.3.cmml" xref="S6.p2.1.m1.1.1.3.3">6</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p2.1.m1.1c">9.99\times 10^{6}</annotation></semantics></math> in the simulation run in code. This is far above any useful privacy, as this basically means the chance that our GAN generates an actual training input (thus breaking privacy) is enormous. However, the researchers note that this is due to the small sample size of users (around 10 of a total of 3000) in the simulation. In a realistic scenario, with millions of users, they note an epsilon around the 1.4 mark. This is a much more practical privacy preservation level.
As for the FID, we see a claim around the 200 mark, which is not amazing, but considering the noise added for differential privacy, it is definitely acceptable.</p>
</div>
<div id="S6.p3" class="ltx_para">
<p id="S6.p3.1" class="ltx_p">The GS-WGAN paper <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="" class="ltx_ref">9</a>]</cite> claims quite different results. The epsilon value they manage to reach is <math id="S6.p3.1.m1.1" class="ltx_Math" alttext="5.99\times 10^{2}" display="inline"><semantics id="S6.p3.1.m1.1a"><mrow id="S6.p3.1.m1.1.1" xref="S6.p3.1.m1.1.1.cmml"><mn id="S6.p3.1.m1.1.1.2" xref="S6.p3.1.m1.1.1.2.cmml">5.99</mn><mo lspace="0.222em" rspace="0.222em" id="S6.p3.1.m1.1.1.1" xref="S6.p3.1.m1.1.1.1.cmml">×</mo><msup id="S6.p3.1.m1.1.1.3" xref="S6.p3.1.m1.1.1.3.cmml"><mn id="S6.p3.1.m1.1.1.3.2" xref="S6.p3.1.m1.1.1.3.2.cmml">10</mn><mn id="S6.p3.1.m1.1.1.3.3" xref="S6.p3.1.m1.1.1.3.3.cmml">2</mn></msup></mrow><annotation-xml encoding="MathML-Content" id="S6.p3.1.m1.1b"><apply id="S6.p3.1.m1.1.1.cmml" xref="S6.p3.1.m1.1.1"><times id="S6.p3.1.m1.1.1.1.cmml" xref="S6.p3.1.m1.1.1.1"></times><cn type="float" id="S6.p3.1.m1.1.1.2.cmml" xref="S6.p3.1.m1.1.1.2">5.99</cn><apply id="S6.p3.1.m1.1.1.3.cmml" xref="S6.p3.1.m1.1.1.3"><csymbol cd="ambiguous" id="S6.p3.1.m1.1.1.3.1.cmml" xref="S6.p3.1.m1.1.1.3">superscript</csymbol><cn type="integer" id="S6.p3.1.m1.1.1.3.2.cmml" xref="S6.p3.1.m1.1.1.3.2">10</cn><cn type="integer" id="S6.p3.1.m1.1.1.3.3.cmml" xref="S6.p3.1.m1.1.1.3.3">2</cn></apply></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.p3.1.m1.1c">5.99\times 10^{2}</annotation></semantics></math>, which is significantly lower than the value reached by the DP-Fed-Avg GAN. Note that this claim is also in the same simulated setup as the DP-Fed-Avg GAN, no claim is made however about the privacy level in a more realistic scenario. As for the FID, it is also significantly lower at just over 60, compared to the more than 200 with Fed-Avg GAN. Overall, GS-WGAN seems to be the more performant algorithm, both in terms of privacy preservation and GAN performance.</p>
</div>
<div id="S6.p4" class="ltx_para">
<p id="S6.p4.1" class="ltx_p">There is however one major sidenote to take on the GS-WGAN, that is that all these results should be taken at face value as there is no code available at the time of writing to reproduce these results. On the contrary, we were able to reproduce the results found in the DP-Fed-Avg GAN paper within a margin of error. The sidenote here being that we were only able to verify the performance of the simulation and not for the realistic setting. In summary, we thus have a quite performant unverified algorithm in GS-WGAN and a less performant, partially verified algorithm in DP-Fed-Avg GAN.</p>
</div>
<figure id="S6.T1" class="ltx_table">
<div id="S6.T1.14" class="ltx_inline-block ltx_align_center ltx_transformed_outer" style="width:433.6pt;height:127.2pt;vertical-align:-0.0pt;"><span class="ltx_transformed_inner" style="transform:translate(26.5pt,-7.8pt) scale(1.1394798783265,1.1394798783265) ;">
<table id="S6.T1.14.14" class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr id="S6.T1.14.14.15.1" class="ltx_tr">
<th id="S6.T1.14.14.15.1.1" class="ltx_td ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"></th>
<th id="S6.T1.14.14.15.1.2" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S6.T1.14.14.15.1.2.1" class="ltx_text ltx_font_bold">GS-WGAN*</span></th>
<th id="S6.T1.14.14.15.1.3" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S6.T1.14.14.15.1.3.1" class="ltx_text ltx_font_bold">DP-Fed-Avg GAN</span></th>
<th id="S6.T1.14.14.15.1.4" class="ltx_td ltx_align_left ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S6.T1.14.14.15.1.4.1" class="ltx_text ltx_font_bold">Ours</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr id="S6.T1.4.4.4" class="ltx_tr">
<th id="S6.T1.1.1.1.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">
<table id="S6.T1.1.1.1.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T1.1.1.1.1.1.1" class="ltx_tr">
<td id="S6.T1.1.1.1.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S6.T1.1.1.1.1.1.1.1.1" class="ltx_text ltx_font_bold">Frechet Inception Distance </span><math id="S6.T1.1.1.1.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T1.1.1.1.1.1.1.1.m1.1a"><mo stretchy="false" id="S6.T1.1.1.1.1.1.1.1.m1.1.1" xref="S6.T1.1.1.1.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T1.1.1.1.1.1.1.1.m1.1b"><ci id="S6.T1.1.1.1.1.1.1.1.m1.1.1.cmml" xref="S6.T1.1.1.1.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.1.1.1.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</td>
</tr>
</table>
</th>
<td id="S6.T1.2.2.2.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S6.T1.2.2.2.2.m1.1" class="ltx_Math" alttext="60" display="inline"><semantics id="S6.T1.2.2.2.2.m1.1a"><mn id="S6.T1.2.2.2.2.m1.1.1" xref="S6.T1.2.2.2.2.m1.1.1.cmml">60</mn><annotation-xml encoding="MathML-Content" id="S6.T1.2.2.2.2.m1.1b"><cn type="integer" id="S6.T1.2.2.2.2.m1.1.1.cmml" xref="S6.T1.2.2.2.2.m1.1.1">60</cn></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.2.2.2.2.m1.1c">60</annotation></semantics></math></td>
<td id="S6.T1.3.3.3.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S6.T1.3.3.3.3.m1.1" class="ltx_Math" alttext="0.2*10\textasciicircum{}3" display="inline"><semantics id="S6.T1.3.3.3.3.m1.1a"><mrow id="S6.T1.3.3.3.3.m1.1.1" xref="S6.T1.3.3.3.3.m1.1.1.cmml"><mrow id="S6.T1.3.3.3.3.m1.1.1.2" xref="S6.T1.3.3.3.3.m1.1.1.2.cmml"><mn id="S6.T1.3.3.3.3.m1.1.1.2.2" xref="S6.T1.3.3.3.3.m1.1.1.2.2.cmml">0.2</mn><mo lspace="0.222em" rspace="0.222em" id="S6.T1.3.3.3.3.m1.1.1.2.1" xref="S6.T1.3.3.3.3.m1.1.1.2.1.cmml">∗</mo><mn id="S6.T1.3.3.3.3.m1.1.1.2.3" xref="S6.T1.3.3.3.3.m1.1.1.2.3.cmml">10</mn></mrow><mo lspace="0em" rspace="0em" id="S6.T1.3.3.3.3.m1.1.1.1" xref="S6.T1.3.3.3.3.m1.1.1.1.cmml">​</mo><mi mathvariant="normal" id="S6.T1.3.3.3.3.m1.1.1.3" xref="S6.T1.3.3.3.3.m1.1.1.3.cmml">^</mi><mo lspace="0em" rspace="0em" id="S6.T1.3.3.3.3.m1.1.1.1a" xref="S6.T1.3.3.3.3.m1.1.1.1.cmml">​</mo><mn id="S6.T1.3.3.3.3.m1.1.1.4" xref="S6.T1.3.3.3.3.m1.1.1.4.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T1.3.3.3.3.m1.1b"><apply id="S6.T1.3.3.3.3.m1.1.1.cmml" xref="S6.T1.3.3.3.3.m1.1.1"><times id="S6.T1.3.3.3.3.m1.1.1.1.cmml" xref="S6.T1.3.3.3.3.m1.1.1.1"></times><apply id="S6.T1.3.3.3.3.m1.1.1.2.cmml" xref="S6.T1.3.3.3.3.m1.1.1.2"><times id="S6.T1.3.3.3.3.m1.1.1.2.1.cmml" xref="S6.T1.3.3.3.3.m1.1.1.2.1"></times><cn type="float" id="S6.T1.3.3.3.3.m1.1.1.2.2.cmml" xref="S6.T1.3.3.3.3.m1.1.1.2.2">0.2</cn><cn type="integer" id="S6.T1.3.3.3.3.m1.1.1.2.3.cmml" xref="S6.T1.3.3.3.3.m1.1.1.2.3">10</cn></apply><ci id="S6.T1.3.3.3.3.m1.1.1.3.cmml" xref="S6.T1.3.3.3.3.m1.1.1.3">^</ci><cn type="integer" id="S6.T1.3.3.3.3.m1.1.1.4.cmml" xref="S6.T1.3.3.3.3.m1.1.1.4">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.3.3.3.3.m1.1c">0.2*10\textasciicircum{}3</annotation></semantics></math></td>
<td id="S6.T1.4.4.4.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S6.T1.4.4.4.4.m1.1" class="ltx_Math" alttext="2.5*10\textasciicircum{}3" display="inline"><semantics id="S6.T1.4.4.4.4.m1.1a"><mrow id="S6.T1.4.4.4.4.m1.1.1" xref="S6.T1.4.4.4.4.m1.1.1.cmml"><mrow id="S6.T1.4.4.4.4.m1.1.1.2" xref="S6.T1.4.4.4.4.m1.1.1.2.cmml"><mn id="S6.T1.4.4.4.4.m1.1.1.2.2" xref="S6.T1.4.4.4.4.m1.1.1.2.2.cmml">2.5</mn><mo lspace="0.222em" rspace="0.222em" id="S6.T1.4.4.4.4.m1.1.1.2.1" xref="S6.T1.4.4.4.4.m1.1.1.2.1.cmml">∗</mo><mn id="S6.T1.4.4.4.4.m1.1.1.2.3" xref="S6.T1.4.4.4.4.m1.1.1.2.3.cmml">10</mn></mrow><mo lspace="0em" rspace="0em" id="S6.T1.4.4.4.4.m1.1.1.1" xref="S6.T1.4.4.4.4.m1.1.1.1.cmml">​</mo><mi mathvariant="normal" id="S6.T1.4.4.4.4.m1.1.1.3" xref="S6.T1.4.4.4.4.m1.1.1.3.cmml">^</mi><mo lspace="0em" rspace="0em" id="S6.T1.4.4.4.4.m1.1.1.1a" xref="S6.T1.4.4.4.4.m1.1.1.1.cmml">​</mo><mn id="S6.T1.4.4.4.4.m1.1.1.4" xref="S6.T1.4.4.4.4.m1.1.1.4.cmml">3</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T1.4.4.4.4.m1.1b"><apply id="S6.T1.4.4.4.4.m1.1.1.cmml" xref="S6.T1.4.4.4.4.m1.1.1"><times id="S6.T1.4.4.4.4.m1.1.1.1.cmml" xref="S6.T1.4.4.4.4.m1.1.1.1"></times><apply id="S6.T1.4.4.4.4.m1.1.1.2.cmml" xref="S6.T1.4.4.4.4.m1.1.1.2"><times id="S6.T1.4.4.4.4.m1.1.1.2.1.cmml" xref="S6.T1.4.4.4.4.m1.1.1.2.1"></times><cn type="float" id="S6.T1.4.4.4.4.m1.1.1.2.2.cmml" xref="S6.T1.4.4.4.4.m1.1.1.2.2">2.5</cn><cn type="integer" id="S6.T1.4.4.4.4.m1.1.1.2.3.cmml" xref="S6.T1.4.4.4.4.m1.1.1.2.3">10</cn></apply><ci id="S6.T1.4.4.4.4.m1.1.1.3.cmml" xref="S6.T1.4.4.4.4.m1.1.1.3">^</ci><cn type="integer" id="S6.T1.4.4.4.4.m1.1.1.4.cmml" xref="S6.T1.4.4.4.4.m1.1.1.4">3</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.4.4.4.4.m1.1c">2.5*10\textasciicircum{}3</annotation></semantics></math></td>
</tr>
<tr id="S6.T1.7.7.7" class="ltx_tr">
<th id="S6.T1.5.5.5.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">
<table id="S6.T1.5.5.5.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T1.5.5.5.1.1.1" class="ltx_tr">
<td id="S6.T1.5.5.5.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S6.T1.5.5.5.1.1.1.1.1" class="ltx_text ltx_font_bold">Generator loss </span><math id="S6.T1.5.5.5.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T1.5.5.5.1.1.1.1.m1.1a"><mo stretchy="false" id="S6.T1.5.5.5.1.1.1.1.m1.1.1" xref="S6.T1.5.5.5.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T1.5.5.5.1.1.1.1.m1.1b"><ci id="S6.T1.5.5.5.1.1.1.1.m1.1.1.cmml" xref="S6.T1.5.5.5.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.5.5.5.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</td>
</tr>
</table>
</th>
<td id="S6.T1.7.7.7.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Unknown</td>
<td id="S6.T1.6.6.6.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S6.T1.6.6.6.2.m1.1" class="ltx_Math" alttext="-0.6" display="inline"><semantics id="S6.T1.6.6.6.2.m1.1a"><mrow id="S6.T1.6.6.6.2.m1.1.1" xref="S6.T1.6.6.6.2.m1.1.1.cmml"><mo id="S6.T1.6.6.6.2.m1.1.1a" xref="S6.T1.6.6.6.2.m1.1.1.cmml">−</mo><mn id="S6.T1.6.6.6.2.m1.1.1.2" xref="S6.T1.6.6.6.2.m1.1.1.2.cmml">0.6</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T1.6.6.6.2.m1.1b"><apply id="S6.T1.6.6.6.2.m1.1.1.cmml" xref="S6.T1.6.6.6.2.m1.1.1"><minus id="S6.T1.6.6.6.2.m1.1.1.1.cmml" xref="S6.T1.6.6.6.2.m1.1.1"></minus><cn type="float" id="S6.T1.6.6.6.2.m1.1.1.2.cmml" xref="S6.T1.6.6.6.2.m1.1.1.2">0.6</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.6.6.6.2.m1.1c">-0.6</annotation></semantics></math></td>
<td id="S6.T1.7.7.7.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S6.T1.7.7.7.3.m1.1" class="ltx_Math" alttext="-0.5" display="inline"><semantics id="S6.T1.7.7.7.3.m1.1a"><mrow id="S6.T1.7.7.7.3.m1.1.1" xref="S6.T1.7.7.7.3.m1.1.1.cmml"><mo id="S6.T1.7.7.7.3.m1.1.1a" xref="S6.T1.7.7.7.3.m1.1.1.cmml">−</mo><mn id="S6.T1.7.7.7.3.m1.1.1.2" xref="S6.T1.7.7.7.3.m1.1.1.2.cmml">0.5</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T1.7.7.7.3.m1.1b"><apply id="S6.T1.7.7.7.3.m1.1.1.cmml" xref="S6.T1.7.7.7.3.m1.1.1"><minus id="S6.T1.7.7.7.3.m1.1.1.1.cmml" xref="S6.T1.7.7.7.3.m1.1.1"></minus><cn type="float" id="S6.T1.7.7.7.3.m1.1.1.2.cmml" xref="S6.T1.7.7.7.3.m1.1.1.2">0.5</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.7.7.7.3.m1.1c">-0.5</annotation></semantics></math></td>
</tr>
<tr id="S6.T1.10.10.10" class="ltx_tr">
<th id="S6.T1.8.8.8.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t">
<table id="S6.T1.8.8.8.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T1.8.8.8.1.1.1" class="ltx_tr">
<td id="S6.T1.8.8.8.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S6.T1.8.8.8.1.1.1.1.1" class="ltx_text ltx_font_bold">Classifier accuracy </span><math id="S6.T1.8.8.8.1.1.1.1.m1.1" class="ltx_Math" alttext="\uparrow" display="inline"><semantics id="S6.T1.8.8.8.1.1.1.1.m1.1a"><mo stretchy="false" id="S6.T1.8.8.8.1.1.1.1.m1.1.1" xref="S6.T1.8.8.8.1.1.1.1.m1.1.1.cmml">↑</mo><annotation-xml encoding="MathML-Content" id="S6.T1.8.8.8.1.1.1.1.m1.1b"><ci id="S6.T1.8.8.8.1.1.1.1.m1.1.1.cmml" xref="S6.T1.8.8.8.1.1.1.1.m1.1.1">↑</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.8.8.8.1.1.1.1.m1.1c">\uparrow</annotation></semantics></math>
</td>
</tr>
</table>
</th>
<td id="S6.T1.10.10.10.4" class="ltx_td ltx_align_left ltx_border_r ltx_border_t">Unknown</td>
<td id="S6.T1.9.9.9.2" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S6.T1.9.9.9.2.m1.1" class="ltx_Math" alttext="60\%" display="inline"><semantics id="S6.T1.9.9.9.2.m1.1a"><mrow id="S6.T1.9.9.9.2.m1.1.1" xref="S6.T1.9.9.9.2.m1.1.1.cmml"><mn id="S6.T1.9.9.9.2.m1.1.1.2" xref="S6.T1.9.9.9.2.m1.1.1.2.cmml">60</mn><mo id="S6.T1.9.9.9.2.m1.1.1.1" xref="S6.T1.9.9.9.2.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.T1.9.9.9.2.m1.1b"><apply id="S6.T1.9.9.9.2.m1.1.1.cmml" xref="S6.T1.9.9.9.2.m1.1.1"><csymbol cd="latexml" id="S6.T1.9.9.9.2.m1.1.1.1.cmml" xref="S6.T1.9.9.9.2.m1.1.1.1">percent</csymbol><cn type="integer" id="S6.T1.9.9.9.2.m1.1.1.2.cmml" xref="S6.T1.9.9.9.2.m1.1.1.2">60</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.9.9.9.2.m1.1c">60\%</annotation></semantics></math></td>
<td id="S6.T1.10.10.10.3" class="ltx_td ltx_align_left ltx_border_r ltx_border_t"><math id="S6.T1.10.10.10.3.m1.1" class="ltx_Math" alttext="18\%" display="inline"><semantics id="S6.T1.10.10.10.3.m1.1a"><mrow id="S6.T1.10.10.10.3.m1.1.1" xref="S6.T1.10.10.10.3.m1.1.1.cmml"><mn id="S6.T1.10.10.10.3.m1.1.1.2" xref="S6.T1.10.10.10.3.m1.1.1.2.cmml">18</mn><mo id="S6.T1.10.10.10.3.m1.1.1.1" xref="S6.T1.10.10.10.3.m1.1.1.1.cmml">%</mo></mrow><annotation-xml encoding="MathML-Content" id="S6.T1.10.10.10.3.m1.1b"><apply id="S6.T1.10.10.10.3.m1.1.1.cmml" xref="S6.T1.10.10.10.3.m1.1.1"><csymbol cd="latexml" id="S6.T1.10.10.10.3.m1.1.1.1.cmml" xref="S6.T1.10.10.10.3.m1.1.1.1">percent</csymbol><cn type="integer" id="S6.T1.10.10.10.3.m1.1.1.2.cmml" xref="S6.T1.10.10.10.3.m1.1.1.2">18</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.10.10.10.3.m1.1c">18\%</annotation></semantics></math></td>
</tr>
<tr id="S6.T1.14.14.14" class="ltx_tr">
<th id="S6.T1.11.11.11.1" class="ltx_td ltx_align_left ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r ltx_border_t">
<table id="S6.T1.11.11.11.1.1" class="ltx_tabular ltx_align_middle">
<tr id="S6.T1.11.11.11.1.1.1" class="ltx_tr">
<td id="S6.T1.11.11.11.1.1.1.1" class="ltx_td ltx_nopad_r ltx_align_left">
<span id="S6.T1.11.11.11.1.1.1.1.1" class="ltx_text ltx_font_bold">Epsilon </span><math id="S6.T1.11.11.11.1.1.1.1.m1.1" class="ltx_Math" alttext="\downarrow" display="inline"><semantics id="S6.T1.11.11.11.1.1.1.1.m1.1a"><mo stretchy="false" id="S6.T1.11.11.11.1.1.1.1.m1.1.1" xref="S6.T1.11.11.11.1.1.1.1.m1.1.1.cmml">↓</mo><annotation-xml encoding="MathML-Content" id="S6.T1.11.11.11.1.1.1.1.m1.1b"><ci id="S6.T1.11.11.11.1.1.1.1.m1.1.1.cmml" xref="S6.T1.11.11.11.1.1.1.1.m1.1.1">↓</ci></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.11.11.11.1.1.1.1.m1.1c">\downarrow</annotation></semantics></math>
</td>
</tr>
</table>
</th>
<td id="S6.T1.12.12.12.2" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t"><math id="S6.T1.12.12.12.2.m1.1" class="ltx_Math" alttext="5.99*10\textasciicircum{}2" display="inline"><semantics id="S6.T1.12.12.12.2.m1.1a"><mrow id="S6.T1.12.12.12.2.m1.1.1" xref="S6.T1.12.12.12.2.m1.1.1.cmml"><mrow id="S6.T1.12.12.12.2.m1.1.1.2" xref="S6.T1.12.12.12.2.m1.1.1.2.cmml"><mn id="S6.T1.12.12.12.2.m1.1.1.2.2" xref="S6.T1.12.12.12.2.m1.1.1.2.2.cmml">5.99</mn><mo lspace="0.222em" rspace="0.222em" id="S6.T1.12.12.12.2.m1.1.1.2.1" xref="S6.T1.12.12.12.2.m1.1.1.2.1.cmml">∗</mo><mn id="S6.T1.12.12.12.2.m1.1.1.2.3" xref="S6.T1.12.12.12.2.m1.1.1.2.3.cmml">10</mn></mrow><mo lspace="0em" rspace="0em" id="S6.T1.12.12.12.2.m1.1.1.1" xref="S6.T1.12.12.12.2.m1.1.1.1.cmml">​</mo><mi mathvariant="normal" id="S6.T1.12.12.12.2.m1.1.1.3" xref="S6.T1.12.12.12.2.m1.1.1.3.cmml">^</mi><mo lspace="0em" rspace="0em" id="S6.T1.12.12.12.2.m1.1.1.1a" xref="S6.T1.12.12.12.2.m1.1.1.1.cmml">​</mo><mn id="S6.T1.12.12.12.2.m1.1.1.4" xref="S6.T1.12.12.12.2.m1.1.1.4.cmml">2</mn></mrow><annotation-xml encoding="MathML-Content" id="S6.T1.12.12.12.2.m1.1b"><apply id="S6.T1.12.12.12.2.m1.1.1.cmml" xref="S6.T1.12.12.12.2.m1.1.1"><times id="S6.T1.12.12.12.2.m1.1.1.1.cmml" xref="S6.T1.12.12.12.2.m1.1.1.1"></times><apply id="S6.T1.12.12.12.2.m1.1.1.2.cmml" xref="S6.T1.12.12.12.2.m1.1.1.2"><times id="S6.T1.12.12.12.2.m1.1.1.2.1.cmml" xref="S6.T1.12.12.12.2.m1.1.1.2.1"></times><cn type="float" id="S6.T1.12.12.12.2.m1.1.1.2.2.cmml" xref="S6.T1.12.12.12.2.m1.1.1.2.2">5.99</cn><cn type="integer" id="S6.T1.12.12.12.2.m1.1.1.2.3.cmml" xref="S6.T1.12.12.12.2.m1.1.1.2.3">10</cn></apply><ci id="S6.T1.12.12.12.2.m1.1.1.3.cmml" xref="S6.T1.12.12.12.2.m1.1.1.3">^</ci><cn type="integer" id="S6.T1.12.12.12.2.m1.1.1.4.cmml" xref="S6.T1.12.12.12.2.m1.1.1.4">2</cn></apply></annotation-xml><annotation encoding="application/x-tex" id="S6.T1.12.12.12.2.m1.1c">5.99*10\textasciicircum{}2</annotation></semantics></math></td>
<td id="S6.T1.13.13.13.3" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t"><math id="S6.T1.13.13.13.3.m1.1" class="ltx_math_unparsed" alttext="9.99*10\textasciicircum{}6**" display="inline"><semantics id="S6.T1.13.13.13.3.m1.1a"><mrow id="S6.T1.13.13.13.3.m1.1b"><mn id="S6.T1.13.13.13.3.m1.1.1">9.99</mn><mo lspace="0.222em" rspace="0.222em" id="S6.T1.13.13.13.3.m1.1.2">∗</mo><mn id="S6.T1.13.13.13.3.m1.1.3">10</mn><mi mathvariant="normal" id="S6.T1.13.13.13.3.m1.1.4">^</mi><mn id="S6.T1.13.13.13.3.m1.1.5">6</mn><mo lspace="0.222em" rspace="0em" id="S6.T1.13.13.13.3.m1.1.6">∗</mo><mo lspace="0em" id="S6.T1.13.13.13.3.m1.1.7">∗</mo></mrow><annotation encoding="application/x-tex" id="S6.T1.13.13.13.3.m1.1c">9.99*10\textasciicircum{}6**</annotation></semantics></math></td>
<td id="S6.T1.14.14.14.4" class="ltx_td ltx_align_left ltx_border_b ltx_border_r ltx_border_t"><math id="S6.T1.14.14.14.4.m1.1" class="ltx_math_unparsed" alttext="9.99*10\textasciicircum{}6**" display="inline"><semantics id="S6.T1.14.14.14.4.m1.1a"><mrow id="S6.T1.14.14.14.4.m1.1b"><mn id="S6.T1.14.14.14.4.m1.1.1">9.99</mn><mo lspace="0.222em" rspace="0.222em" id="S6.T1.14.14.14.4.m1.1.2">∗</mo><mn id="S6.T1.14.14.14.4.m1.1.3">10</mn><mi mathvariant="normal" id="S6.T1.14.14.14.4.m1.1.4">^</mi><mn id="S6.T1.14.14.14.4.m1.1.5">6</mn><mo lspace="0.222em" rspace="0em" id="S6.T1.14.14.14.4.m1.1.6">∗</mo><mo lspace="0em" id="S6.T1.14.14.14.4.m1.1.7">∗</mo></mrow><annotation encoding="application/x-tex" id="S6.T1.14.14.14.4.m1.1c">9.99*10\textasciicircum{}6**</annotation></semantics></math></td>
</tr>
</tbody>
</table>
</span></div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>A performance comparison of our algorithm against GS-WGAN and DP-Fed-Avg GAN. <span id="S6.T1.16.1" class="ltx_text ltx_font_italic">* claimed, but unverified values used, ** experimental setting value, lower in real world scenarios</span></figcaption>
</figure>
<div id="S6.p5" class="ltx_para">
<p id="S6.p5.1" class="ltx_p">When we compare the performance of our method of applying an autoencoder to the DP-Fed-Avg GAN, we unfortunately see worse performance than both DP-Fed-Avg GAN and GS-WGAN. As we can see in Table <a href="#S6.T1" title="Table 1 ‣ 6 Discussion ‣ Using Autoencoders on Differentially Private Federated Learning GANs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a> the Epsilon value, which indicates the differential privacy level, stays the same from DP-Fed-Avg GAN to our modification of it, however the FID as well as the classifier accuracy is significantly lower. These lower values are most likely caused by the issue described in the Results section.</p>
</div>
<figure id="S6.F4" class="ltx_figure"><img src="/html/2206.12270/assets/images/fid.png" id="S6.F4.g1" class="ltx_graphics ltx_centering ltx_img_square" width="236" height="196" alt="Refer to caption">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>Frechet Inception Distance: Red = Fed-Avg GAN without DP, Light Blue = Ours, Blue = Fed-Avg GAN with DP</figcaption>
</figure>
<div id="S6.p6" class="ltx_para">
<p id="S6.p6.1" class="ltx_p">If we look into more detail at the performance over the 1000 iterations, we can see in Figure <a href="#S6.F4" title="Figure 4 ‣ 6 Discussion ‣ Using Autoencoders on Differentially Private Federated Learning GANs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> that the further we proceed, the lower our FID becomes. This makes sense intuitively, as the GAN will get better at creating results similar to its input with more training. What we also see is that this improvement goes much slower with our implementation than the others. This is logical, considering a gray blur is added in our results due to the failing denoising algorithm. In future research, one might try to run the algorithm for more iterations to see if the FID slowly keeps declining or plateaus.</p>
</div>
<figure id="S6.F5" class="ltx_figure">
<div class="ltx_flex_figure">
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F5.sf1" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2206.12270/assets/images/generator_loss.png" id="S6.F5.sf1.g1" class="ltx_graphics ltx_img_square" width="236" height="196" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(a) </span>Generator Loss: Red = Fed-Avg GAN without DP, Light Blue = Ours, Blue = Fed-Avg GAN with DP</figcaption>
</figure>
</div>
<div class="ltx_flex_cell ltx_flex_size_2">
<figure id="S6.F5.sf2" class="ltx_figure ltx_figure_panel ltx_align_center"><img src="/html/2206.12270/assets/images/classifier_score.png" id="S6.F5.sf2.g1" class="ltx_graphics ltx_img_square" width="236" height="196" alt="Refer to caption">
<figcaption class="ltx_caption"><span class="ltx_tag ltx_tag_figure">(b) </span>Classifier score: Red = Fed-Avg GAN without DP, Light Blue = Ours, Blue = Fed-Avg GAN with DP</figcaption>
</figure>
</div>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>Generator loss and classifier score</figcaption>
</figure>
<div id="S6.p7" class="ltx_para">
<p id="S6.p7.1" class="ltx_p">What is interesting to see is that the generator loss (see Figure <a href="#S6.F5" title="Figure 5 ‣ 6 Discussion ‣ Using Autoencoders on Differentially Private Federated Learning GANs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>a for our algorithm does not seem to be markedly higher or lower than the regular DP-Fed-Avg GAN. Unfortunately, we could not find a clear reason for this behavior. When we look at the classifier score (see Figure <a href="#S6.F5" title="Figure 5 ‣ 6 Discussion ‣ Using Autoencoders on Differentially Private Federated Learning GANs" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>b), remember a GAN has usually trains against a classifier, we see a notable decrease in accuracy with our implementation due to previous described issues with our experiment. Here again, it might be interesting to see how the accuracy progresses after 1000 rounds when doing future research into optimization of the DP-Fed-Avg GAN algorithm.</p>
</div>
</section>
<section id="S7" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">7 </span>Conclusion</h2>

<div id="S7.p1" class="ltx_para">
<p id="S7.p1.1" class="ltx_p">This paper introduced the idea of using autoencoders on differentially private federated learning GANs. This novel approach applied an autoencoder on top of the DP-Fed-Avg GAN. The idea is to reduce the noise on the GAN output and thus improve the readability of the output, making it easier to classify or spot weird outputs. Unfortunately, due to the autoencoder being trained at a specific noise level and the differential privacy calculations adding arbitrary levels of noise, this technique failed. The concept could still work when tried with a noise removal algorithm that does not require knowing the noise level upfront.</p>
</div>
<div id="S7.p2" class="ltx_para">
<p id="S7.p2.1" class="ltx_p">This paper also compared the performance of the novel approach to the existing GS-WGAN and DP-Fed-Avg GAN algorithms. These results showed that both in terms of privacy and generated results, the GS-WGAN algorithm is currently the best. The paper also addressed some questions with regard to the ethics of this research and the societal impact thereof.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography">References</h2>

<ul class="ltx_biblist">
<li id="bib.bib1" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock">
J. O. Awoyemi, A. O. Adetunmbi, and S. A. Oluwadare, “Credit card fraud
detection using machine learning techniques: A comparative analysis,” in
<span id="bib.bib1.1.1" class="ltx_text ltx_font_italic">2017 international conference on computing networking and informatics
(ICCNI)</span>, pp. 1–9, IEEE, 2017.

</span>
</li>
<li id="bib.bib2" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock">
I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair,
A. Courville, and Y. Bengio, “Generative adversarial nets,” <span id="bib.bib2.1.1" class="ltx_text ltx_font_italic">Advances
in neural information processing systems</span>, vol. 27, 2014.

</span>
</li>
<li id="bib.bib3" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock">
C. Dwork, F. McSherry, K. Nissim, and A. Smith, “Calibrating noise to
sensitivity in private data analysis,” in <span id="bib.bib3.1.1" class="ltx_text ltx_font_italic">Theory of cryptography
conference</span>, pp. 265–284, Springer, 2006.

</span>
</li>
<li id="bib.bib4" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock">
T. Dalenius, “Towards a methodology for statistical disclosure control,” <span id="bib.bib4.1.1" class="ltx_text ltx_font_italic">statistik Tidskrift</span>, vol. 15, no. 429-444, pp. 2–1, 1977.

</span>
</li>
<li id="bib.bib5" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock">
B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y Arcas,
“Communication-efficient learning of deep networks from decentralized
data,” in <span id="bib.bib5.1.1" class="ltx_text ltx_font_italic">Artificial intelligence and statistics</span>, pp. 1273–1282,
PMLR, 2017.

</span>
</li>
<li id="bib.bib6" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock">
S. Augenstein, B. McMahan, D. Ramage, S. Ramaswamy, P. Kairouz, M. Chen,
R. Mathews, and B. Aguera-Arcas, “Generative models for effective ml on
private, decentralized datasets,” 2019.

</span>
</li>
<li id="bib.bib7" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock">
S. Ramaswamy, O. Thakkar, R. Mathews, G. Andrew, H. B. McMahan, and
F. Beaufays, “Training production language models without memorizing user
data,” <span id="bib.bib7.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:2009.10031</span>, 2020.

</span>
</li>
<li id="bib.bib8" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock">
H. B. McMahan, D. Ramage, K. Talwar, and L. Zhang, “Learning differentially
private recurrent language models,” <span id="bib.bib8.1.1" class="ltx_text ltx_font_italic">arXiv preprint arXiv:1710.06963</span>,
2017.

</span>
</li>
<li id="bib.bib9" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock">
D. Chen, T. Orekondy, and M. Fritz, “Gs-wgan: A gradient-sanitized approach
for learning differentially private generators,” <span id="bib.bib9.1.1" class="ltx_text ltx_font_italic">Advances in Neural
Information Processing Systems</span>, vol. 33, pp. 12673–12684, 2020.

</span>
</li>
<li id="bib.bib10" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock">
K. Zhang, W. Zuo, Y. Chen, D. Meng, and L. Zhang, “Beyond a gaussian denoiser:
Residual learning of deep cnn for image denoising,” <span id="bib.bib10.1.1" class="ltx_text ltx_font_italic">IEEE transactions
on image processing</span>, vol. 26, no. 7, pp. 3142–3155, 2017.

</span>
</li>
<li id="bib.bib11" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock">
J. W. Soh and N. I. Cho, “Deep universal blind image denoising,” in <span id="bib.bib11.1.1" class="ltx_text ltx_font_italic">2020
25th International Conference on Pattern Recognition (ICPR)</span>, pp. 747–754,
IEEE, 2021.

</span>
</li>
<li id="bib.bib12" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock">
M. El Helou and S. Süsstrunk, “Blind universal Bayesian image denoising
with Gaussian noise level learning,” <span id="bib.bib12.1.1" class="ltx_text ltx_font_italic">IEEE Transactions on Image
Processing</span>, vol. 29, pp. 4885–4897, 2020.

</span>
</li>
<li id="bib.bib13" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock">
“Intro to autoencoders: Tensorflow core.”

</span>
</li>
<li id="bib.bib14" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock">
G. Cohen, S. Afshar, J. Tapson, and A. Van Schaik, “Emnist: Extending mnist to
handwritten letters,” in <span id="bib.bib14.1.1" class="ltx_text ltx_font_italic">2017 international joint conference on neural
networks (IJCNN)</span>, pp. 2921–2926, IEEE, 2017.

</span>
</li>
<li id="bib.bib15" class="ltx_bibitem">
<span class="ltx_tag ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock">
Y. LeCun and C. Cortes, “MNIST handwritten digit database,” 2010.

</span>
</li>
</ul>
</section>
</article>
</div>
<div class="ar5iv-footer"><a href="/html/2206.12269" class="ar5iv-nav-button ar5iv-nav-button-prev">◄</a>
    <a class="ar5iv-home-button" href="/"><img height="40" alt="ar5iv homepage" src="/assets/ar5iv.png"></a>
    <a href="/feeling_lucky" class="ar5iv-text-button">Feeling<br>lucky?</a>
    <a href="/log/2206.12270" class="ar5iv-text-button ar5iv-severity-warning">Conversion<br>report</a>
    <a class="ar5iv-text-button" target="_blank" href="https://github.com/dginev/ar5iv/issues/new?template=improve-article--arxiv-id-.md&title=Improve+article+2206.12270">Report<br>an issue</a>
    <a href="https://arxiv.org/abs/2206.12270" class="ar5iv-text-button arxiv-ui-theme">View&nbsp;original<br>on&nbsp;arXiv</a><a href="/html/2206.12271" class="ar5iv-nav-button ar5iv-nav-button-next">►</a>
</div><footer class="ltx_page_footer">
<a class="ar5iv-toggle-color-scheme" href="javascript:toggleColorScheme()" title="Toggle ar5iv color scheme"><span class="color-scheme-icon"></span></a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/license" target="_blank">Copyright</a>
<a class="ar5iv-footer-button" href="https://arxiv.org/help/policies/privacy_policy" target="_blank">Privacy Policy</a>

<div class="ltx_page_logo">Generated  on Mon Mar 11 17:46:29 2024 by <a target="_blank" href="http://dlmf.nist.gov/LaTeXML/" class="ltx_LaTeXML_logo"><span style="letter-spacing:-0.2em; margin-right:0.1em;">L<span class="ltx_font_smallcaps" style="position:relative; bottom:2.2pt;">a</span>T<span class="ltx_font_smallcaps" style="font-size:120%;position:relative; bottom:-0.2ex;">e</span></span><span style="font-size:90%; position:relative; bottom:-0.2ex;">XML</span><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="Mascot Sammy"></a>
</div></footer>
</div>

    <script>
      var canMathML = typeof(MathMLElement) == "function";
      if (!canMathML) {
        var body = document.querySelector("body");
        body.firstElementChild.setAttribute('style', 'opacity: 0;');
        var loading = document.createElement("div");
        loading.setAttribute("id", "mathjax-loading-spinner");
        var message = document.createElement("div");
        message.setAttribute("id", "mathjax-loading-message");
        message.innerText = "Typesetting Equations...";
        body.prepend(loading);
        body.prepend(message);

        var el = document.createElement("script");
        el.src = "https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js";
        document.querySelector("head").appendChild(el);

        window.MathJax = {
          startup: {
            pageReady: () => {
              return MathJax.startup.defaultPageReady().then(() => {
                body.removeChild(loading);
                body.removeChild(message);
                body.firstElementChild.removeAttribute('style');
              }); } } };
      }
    </script>
    <script>
    // Auxiliary function, building the preview feature when
    // an inline citation is clicked
    function clicked_cite(e) {
      e.preventDefault();
      let cite = this.closest('.ltx_cite');
      let next = cite.nextSibling;
      if (next && next.nodeType == Node.ELEMENT_NODE && next.getAttribute('class') == "ar5iv-bibitem-preview") {
        next.remove();
        return; }
      // Before adding a preview modal,
      // cleanup older previews, in case they're still open
      document.querySelectorAll('span.ar5iv-bibitem-preview').forEach(function(node) {
        node.remove();
      })

      // Create the preview
      preview = document.createElement('span');
      preview.setAttribute('class','ar5iv-bibitem-preview');
      let target = document.getElementById(this.getAttribute('href').slice(1));
      target.childNodes.forEach(function (child) {
        preview.append(child.cloneNode(true));
      });
      let close_x = document.createElement('button');
      close_x.setAttribute("aria-label","Close modal for bibliography item preview");
      close_x.textContent = "×";
      close_x.setAttribute('class', 'ar5iv-button-close-preview');
      close_x.setAttribute('onclick','this.parentNode.remove()');
      preview.append(close_x);
      preview.querySelectorAll('.ltx_tag_bibitem').forEach(function(node) {
        node.remove();
      });
      cite.parentNode.insertBefore(preview, cite.nextSibling);
      return;
    }
    // Global Document initialization:
    // - assign the preview feature to all inline citation links
    document.querySelectorAll(".ltx_cite .ltx_ref").forEach(function (link) {
      link.addEventListener("click", clicked_cite);
    });
    </script>
    </body>
</html>
